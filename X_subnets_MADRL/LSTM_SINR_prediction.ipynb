{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa94cabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "#import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import random\n",
    "import pdb\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pickle\n",
    "import scipy.io\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import pandas as pd\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "from tqdm import tqdm\n",
    "import matplotlib.animation as animation\n",
    "import glob\n",
    "from natsort import natsorted\n",
    "from PIL import Image\n",
    "\n",
    "def create_gif(pth, time_ind):\n",
    "    #files = glob.glob(r\"./imgs/*.png\")\n",
    "    files = glob.glob(os.path.join(pth,'*.png'))\n",
    "    files = natsorted(files)\n",
    "    image_array = []\n",
    "    \n",
    "    def update(i):\n",
    "        im.set_array(image_array[i])\n",
    "        return im, \n",
    "    \n",
    "    for my_file in files:\n",
    "\n",
    "        image = Image.open(my_file)\n",
    "        image_array.append(image)\n",
    "    \n",
    "    # Create the figure and axes objects\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Set the initial image\n",
    "    im = ax.imshow(image_array[0], animated=True)\n",
    "    \n",
    "    animation_fig = animation.FuncAnimation(fig, update, frames=len(image_array), interval=100, blit=True,repeat_delay=10,)\n",
    "\n",
    "    # Show the animation\n",
    "    #plt.show()\n",
    "\n",
    "    #animation_fig.save(\"./imgs/animated_{}.gif\".format(time_ind))\n",
    "    animation_fig.save(os.path.join(pth,'animated_{}.gif').format(time_ind))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e43846d",
   "metadata": {},
   "source": [
    "### Adding gamma_0 value for SINR computation ####\n",
    "\n",
    "$\\gamma = \\frac{|h|_s^2P_t}{|h|_i^2P_t + N_0B}$\n",
    "\n",
    "Assuming power transmitted power is same from all BSs then we have \n",
    "\n",
    "$\\gamma = \\frac{|h|_s^2}{|h|_i^2 + \\frac{1}{\\gamma_0}}$\n",
    "\n",
    "\n",
    "where $\\gamma_0 = P_t/N_0B$, you can assume P_t = 10 dBm, and the below calculations for $N_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dc46e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise_spectral_density_dBm -173.97722915699805\n",
      "thermal_noise_power(dBm) -103.97722915699808\n",
      "1/gamma_0 4.001999999999999e-12\n"
     ]
    }
   ],
   "source": [
    "## transmit power ###\n",
    "Pt_dBm = 10  # Transmit power in dBm\n",
    "\n",
    "#### Noise power ####\n",
    "k = 1.38e-23  # Boltzmann's constant\n",
    "T = 290       # Temperature in Kelvin\n",
    "B = 10e6       # Bandwidth in Hz\n",
    "\n",
    "# Calculate noise spectral density in Watts/Hz\n",
    "Noise_spectral_density = k * T\n",
    "\n",
    "# Convert noise spectral density to dBm/Hz\n",
    "# Convert to Watts first then to dBm (1 mW = 0.001 W)\n",
    "Noise_spectral_density_W = Noise_spectral_density * 1000  # Convert to mW\n",
    "Noise_spectral_density_dBm = 10 * np.log10(Noise_spectral_density_W)\n",
    "print('Noise_spectral_density_dBm', Noise_spectral_density_dBm)\n",
    "\n",
    "# Calculate total noise power in Watts then convert to dBm\n",
    "N_thermal = Noise_spectral_density * B  # Total noise power in Watts\n",
    "N_thermal_dBm = 10 * np.log10(N_thermal * 1000)  # Convert noise power to dBm\n",
    "print('thermal_noise_power(dBm)', N_thermal_dBm)\n",
    "\n",
    "##### gamma_0 in dB ############\n",
    "gamma_0_dB = Pt_dBm - N_thermal_dBm  # Calculate SNR in dB\n",
    "#print('gamma_0 (dB)', gamma_0_dB)\n",
    "\n",
    "##### gamma_0 ######\n",
    "gamma_0 = np.power(10, gamma_0_dB/10)\n",
    "print('1/gamma_0', 1/gamma_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b76f51e",
   "metadata": {},
   "source": [
    "### \n",
    "CDF of SINR computed for F($\\gamma$), for different channel realizations,\n",
    "below is when the the device is at a mean distance of 1m from the serving BS with a standard deviation of 0.1 m, and mean distance from the interfering BS at 4 meters with std of 0.1m "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a7ae1d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def return_cdf(a):\n",
    "    sorted_a = np.sort(a)\n",
    "    cdf = np.arange(1, len(sorted_a) + 1) / len(sorted_a)\n",
    "    return sorted_a, cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "471a7686",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Creating distances intra and inter ########\n",
    "M = 5 # number of sub-networks \n",
    "Ts = 10000 # number of time slots\n",
    "J = 5 # number of devices\n",
    "f_c = 1.3 #GHz\n",
    "N = 30\n",
    "TxRxds = np.zeros((Ts, M, M*J))\n",
    "d_intra = np.abs(np.random.normal(0.5,0.1,M*J))\n",
    "d_intra = np.reshape(d_intra, (M,J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3a24ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 9999/9999 [00:01<00:00, 8505.59it/s]\n"
     ]
    }
   ],
   "source": [
    "def generate_random_point(grid_size):\n",
    "    return np.random.uniform(0, grid_size, 2)\n",
    "\n",
    "def generate_random_velocity():\n",
    "    angle = np.random.uniform(0, 2 * np.pi)\n",
    "    velocity = 11.11  # 40 km/h in m/s\n",
    "    return np.array([velocity * np.cos(angle), velocity * np.sin(angle)])\n",
    "\n",
    "def is_within_grid(point, grid_size):\n",
    "    return all(0 <= coord <= grid_size for coord in point)\n",
    "\n",
    "def handle_boundary_collisions(point, grid_size):\n",
    "    angle = np.random.uniform(0, 2 * np.pi)\n",
    "    velocity = 11.11\n",
    "    if point[0] <= 0 or point[0] >= grid_size:\n",
    "        angle = np.pi - angle if point[0] <= 0 else -angle\n",
    "    if point[1] <= 0 or point[1] >= grid_size:\n",
    "        angle = -np.pi / 2 - angle if point[1] <= 0 else np.pi / 2 - angle\n",
    "    return np.array([velocity * np.cos(angle), velocity * np.sin(angle)])\n",
    "\n",
    "def handle_ap_collisions(points, velocities, min_distance):\n",
    "    for i in range(len(points)):\n",
    "        for j in range(i + 1, len(points)):\n",
    "            if np.linalg.norm(points[i] - points[j]) < min_distance:\n",
    "                # Adjust direction randomly for both APs\n",
    "                velocities[i] = generate_random_velocity()\n",
    "                velocities[j] = generate_random_velocity()\n",
    "    return velocities\n",
    "\n",
    "def update_positions(points, velocities, tau, grid_size, min_distance):\n",
    "    new_points = points + velocities * tau\n",
    "    for i, point in enumerate(new_points):\n",
    "        if not is_within_grid(point, grid_size):\n",
    "            velocities[i] = handle_boundary_collisions(point, grid_size)\n",
    "        new_points[i] = points[i] + velocities[i] * tau  # Recalculate with new velocity\n",
    "    velocities = handle_ap_collisions(new_points, velocities, min_distance)\n",
    "    return new_points, velocities\n",
    "\n",
    "# Initialize parameters\n",
    "grid_size = 20\n",
    "num_points = M\n",
    "min_distance = 2\n",
    "tau = 0.01  # time interval in seconds\n",
    "\n",
    "# Initialize points and velocities\n",
    "points = np.array([generate_random_point(grid_size) for _ in range(num_points)])\n",
    "velocities = np.array([generate_random_velocity() for _ in range(num_points)])\n",
    "init_cents = points\n",
    "# Simulation loop for 20 time steps\n",
    "pth = r'C:\\Users\\sriniva3\\OneDrive - Aalto University\\Simulations\\RL framework URLLC\\RL framework_V2.0_DDPG\\imgs'\n",
    "#Ts = 1000\n",
    "sub_net_cents = np.zeros((Ts+1, num_points, 2))\n",
    "sub_net_cents[0] = init_cents\n",
    "for step in tqdm(range(Ts-1)):\n",
    "    points, velocities = update_positions(points, velocities, tau, grid_size, min_distance)\n",
    "    sub_net_cents[step+1] = points\n",
    "    '''\n",
    "    # Plotting for visualization\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.scatter(points[:, 0], points[:, 1], c='red', label=f'Time Step {step+1}')\n",
    "    plt.xlim(0, grid_size)\n",
    "    plt.ylim(0, grid_size)\n",
    "    plt.grid(True)\n",
    "    plt.title(f'Access Points at Step {step+1}')\n",
    "    plt.xlabel('Meters')\n",
    "    plt.ylabel('Meters')\n",
    "    #plt.legend()\n",
    "    plt.savefig(os.path.join(pth, '{}.png'.format(step)))\n",
    "    plt.close()\n",
    "    #plt.show()\n",
    "    ''';\n",
    "#create_gif(pth, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f571f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_relative_locs = {}\n",
    "for i in range(M):\n",
    "    d_angle = np.random.uniform(0,2*np.pi,J) \n",
    "    d_r = np.random.uniform(0, 1, J)\n",
    "    d_relative_locs[i] = np.vstack([d_r*np.cos(d_angle), d_r*np.sin(d_angle)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cc676f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_euclid_dist(device_x_coord, device_y_coord, AP_x_coord, AP_y_coord):\n",
    "    device_coords = np.array([device_x_coord, device_y_coord])\n",
    "    AP_coords = np.array([AP_x_coord, AP_y_coord])\n",
    "    return np.linalg.norm(device_coords - AP_coords)\n",
    "\n",
    "x_coords_ts, y_coords_ts = {}, {}\n",
    "for ts in range(Ts):\n",
    "    coords = sub_net_cents[ts]\n",
    "    point_xs, point_ys = [], []\n",
    "    for k in d_relative_locs.keys():\n",
    "        point_x = d_relative_locs[k][0] + coords[k][0]\n",
    "        point_y = d_relative_locs[k][1] + coords[k][1]\n",
    "        #print(point_x, point_y)\n",
    "        point_xs.append(point_x)\n",
    "        point_ys.append(point_y)\n",
    "    #break    \n",
    "    x_coords_ts[ts] = point_xs\n",
    "    y_coords_ts[ts] = point_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e05a3ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TxRxds = np.zeros((Ts, M, M*J))\n",
    "for ts in range(Ts):\n",
    "    device_x_coords, device_y_coords = np.array(x_coords_ts[ts]), np.array(y_coords_ts[ts])\n",
    "    device_x_coords, device_y_coords = device_x_coords.flatten(), device_y_coords.flatten()\n",
    "    AP_x_coords, AP_y_coords = sub_net_cents[ts][:,0], sub_net_cents[ts][:,1]\n",
    "    \n",
    "    #for dx in device_x_coords \n",
    "    dists = np.zeros((M,M*J))\n",
    "    for i in range(AP_x_coords.shape[0]):\n",
    "        dist = []\n",
    "        for j in range(len(device_x_coords.flatten())):\n",
    "            #dist = []\n",
    "            #print(i,j)\n",
    "            dist.append(return_euclid_dist(device_x_coords[j], device_y_coords[j], AP_x_coords[i], AP_y_coords[i]))\n",
    "            #print(dist)\n",
    "        dists[i] = np.array(dist)\n",
    "    TxRxds[ts] = dists\n",
    "    #break\n",
    "\n",
    "#dist = return_euclid_dist(x_coords_ts[0], y_coords_ts[0], AP_x_coord, AP_y_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfd07bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([319595., 150298., 184248., 194347., 171806., 126134.,  80515.,\n",
       "         18592.,   3535.,    930.]),\n",
       " array([1.85634796e-02, 3.21010779e+00, 6.40165210e+00, 9.59319641e+00,\n",
       "        1.27847407e+01, 1.59762850e+01, 1.91678293e+01, 2.23593737e+01,\n",
       "        2.55509180e+01, 2.87424623e+01, 3.19340066e+01]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(TxRxds.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa0ed303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5, 25)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TxRxds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16618737",
   "metadata": {},
   "source": [
    "### Using Jakes model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4647ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [13:56<00:00,  3.59it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def return_jakes_coeffcients(fd_max, TimeVaris, n_links = 5, plot = True):\n",
    "    ff_gains, TimeSequences = [], []\n",
    "    rays = 100\n",
    "    for i in tqdm(range(n_links)):    \n",
    "        #TimeVaris = np.arange(0,50,0.0005)\n",
    "        #TimeVaris = np.arange(0,.2,0.005)\n",
    "        frequs = np.sort(np.array([np.round(fd_max*np.cos(2*np.pi*np.random.uniform(0,1))) for _ in range(rays)]))\n",
    "        phases = np.array([np.exp(1j*2*np.pi*np.random.uniform(0,1)) for _ in range(rays)])\n",
    "\n",
    "        TimeSequence = []\n",
    "        for t in TimeVaris:\n",
    "            tab = np.exp(1j*2*np.pi*frequs*t)\n",
    "            tabrot = tab*phases\n",
    "            fun = np.sum(tabrot)\n",
    "            TimeSequence.append(fun)\n",
    "        TimeSequence = np.array(TimeSequence)\n",
    "\n",
    "        #TimeSequence = TimeSequence/np.linalg.norm(TimeSequence)*np.sqrt(len(TimeSequence))\n",
    "        PowerSequence1 =  np.abs(TimeSequence)**2;\n",
    "        #plt.plot(TimeVaris[0:200], 10*np.log10(PowerSequence1)[0:200])\n",
    "        ff_gains.append(PowerSequence1)\n",
    "        TimeSequences.append(TimeSequence)\n",
    "    ff_gains = np.array(ff_gains)/rays\n",
    "    TimeSequences = np.array(TimeSequences)\n",
    "    if plot:\n",
    "        plt.plot(TimeVaris[0:200], 10*np.log10(ff_gains[0])[0:200])\n",
    "        plt.show()\n",
    "    return ff_gains, TimeSequences\n",
    "\n",
    "v = 40 #kmph \n",
    "v_ms = v*5/18\n",
    "c = 3*1e8\n",
    "tau = .01\n",
    "fd_max = v_ms*f_c*1e9/c\n",
    "TimeVaris = np.arange(0,5,0.0005)\n",
    "\n",
    "ff_gains, TimeSequences = return_jakes_coeffcients(fd_max, TimeVaris, n_links = M*(M-1)*J*N, plot = False)\n",
    "#plt.plot(TimeVaris[0:Ts], 10*np.log10(ff_gains.flatten()[0:Ts]))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc5f6e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save( 'ff_gains_3000.npy',ff_gains)\n",
    "#ff_gains = np.load('ff_gains_3000.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f53e824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############ fast fading coeffecients ########\n",
    "\n",
    "FastFadingChannels = np.random.normal(0,1/np.sqrt(2), M*J*N) + 1j*np.random.normal(0,1/np.sqrt(2), M*J*N)\n",
    "FastFadingChannels = np.reshape(FastFadingChannels,(M,J,N))\n",
    "FadingGains = np.abs(FastFadingChannels)**2\n",
    "#all_SINRsdB, all_MeansPerSubNW, all_DiffsFromMean = np.zeros((Ts, M*J)), np.zeros((Ts, M)), np.zeros((Ts, M*J))\n",
    "all_SINRsdB = np.zeros((Ts, M,J,N))\n",
    "alltime_WantedSigPerDev, alltime_InterfPowsPerDev = [], []\n",
    "for ts in range(Ts):\n",
    "    \n",
    "\n",
    "    #FadingGains.shape\n",
    "\n",
    "    all_fast_fading_gains = np.zeros((M,M*J,N))\n",
    "    for m in range(M):\n",
    "        jakes_coeffs = ff_gains[:,ts]\n",
    "        jakes_coeffs = np.reshape(jakes_coeffs,(M,(M-1)*J,N))\n",
    "        all_fast_fading_gains[m] = np.concatenate([FadingGains[m], jakes_coeffs[m]])\n",
    "    all_fast_fading_gains = np.array(all_fast_fading_gains)\n",
    "    \n",
    "    PL_los = 31.84 +21.5*np.log10(TxRxds[ts]) + 19*np.log10(f_c)\n",
    "    PL = 33+25.5*np.log10(TxRxds[ts])+20*np.log10(f_c)\n",
    "    PL_nlos = np.max((PL_los, PL), axis = 0)\n",
    "    PathGains = np.power(10, -PL_nlos/10)\n",
    "    PathGains = np.repeat(PathGains[:, :, np.newaxis], N, axis=2)\n",
    "\n",
    "    ##### Compute total path gains ########\n",
    "    #pdb.set_trace()\n",
    "    PathGainsTot = PathGains*all_fast_fading_gains\n",
    "\n",
    "    #### Compute WantedSigPerDev ######\n",
    "    WantedSigPerDev = np.zeros((M,J,N))\n",
    "    for m in range(M):\n",
    "        WantedSigPerDev[m] = PathGainsTot[m,m*J:(m+1)*J]\n",
    "    alltime_WantedSigPerDev.append(WantedSigPerDev)\n",
    "    InterfPowsPerDev = np.zeros((M,J,N))\n",
    "    for m in range(M):\n",
    "        Interferers = [i for i in range(M) if i!=m]\n",
    "        Devs = np.arange(m*J,(m+1)*J)\n",
    "        #print(Interferers, Devs)\n",
    "        InterfPowGains = PathGainsTot[np.ix_(Interferers, Devs)]\n",
    "        InterfPowsPerDev[m,] = np.sum(InterfPowGains, axis = 0)\n",
    "    alltime_InterfPowsPerDev.append(InterfPowsPerDev)\n",
    "    SINRs = WantedSigPerDev/(InterfPowsPerDev + 1/gamma_0);\n",
    "    SINRsdB = 10*np.log10(SINRs)\n",
    "    all_SINRsdB[ts,:] = SINRsdB\n",
    "alltime_WantedSigPerDev = np.array(alltime_WantedSigPerDev)\n",
    "alltime_InterfPowsPerDev = np.array(alltime_InterfPowsPerDev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a13dd931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WantedSigPerDev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a65cdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.665782185618824\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a1, cdf1 = return_cdf(all_SINRsdB.flatten())\n",
    "plt.figure(figsize= [5,3])\n",
    "#plt.ylim(np.min(cdf2))\n",
    "plt.semilogy(a1, cdf1, label = r'$F(\\gamma)$')\n",
    "plt.grid()\n",
    "plt.xlabel('SINR(dB)')\n",
    "plt.ylabel('CDF(log scale)')\n",
    "plt.legend()\n",
    "print(np.mean(all_SINRsdB.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a82219d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 25, 30)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PathGainsTot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b0a0fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5, 30)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InterfPowGains.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "751dbc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.477376376460374\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alltime_SINRsdB_combined = []\n",
    "all_SINRslin = np.power(10, all_SINRsdB/10)\n",
    "for ts in range(all_SINRsdB.shape[0]):\n",
    "    vals = all_SINRslin[ts,:,:,:]\n",
    "    SINRS_combined = np.min(vals, axis = 2)\n",
    "    SINRsdB_combined = 10*np.log10(SINRS_combined)\n",
    "    alltime_SINRsdB_combined.append(SINRsdB_combined)\n",
    "alltime_SINRsdB_combined = np.array(alltime_SINRsdB_combined)\n",
    "\n",
    "a1, cdf1 = return_cdf(alltime_SINRsdB_combined.flatten())\n",
    "plt.figure(figsize= [5,3])\n",
    "#plt.ylim(np.min(cdf2))\n",
    "plt.semilogy(a1, cdf1, label = r'$F(\\gamma)$')\n",
    "plt.grid()\n",
    "plt.xlabel('SINR(dB)')\n",
    "plt.ylabel('CDF(log scale)')\n",
    "plt.legend()\n",
    "print(np.mean(alltime_SINRsdB_combined.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92cc0e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5, 5, 30)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_SINRsdB.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c839a4bf",
   "metadata": {},
   "source": [
    "### The below model needs to be integrated with DRL framework trained paralelly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d4e4a",
   "metadata": {},
   "source": [
    "##### prediction of SINR at t given 10 previous time slots #########\n",
    "####### 10000 x 5x 5 x 30, 10000 is time slots, first 5 denotes the sub networks, 2nd 5 denotes the devices of a sub network, \n",
    "####### 30 denotes the channel resources. \n",
    "\n",
    "\n",
    "#### preparing data for a sub-network ########\n",
    "######## each sub-network will have one LSTM layer getting trained in parallel with the main DRL agent ########\n",
    "######### i.e., the LSTM layer is trained for a given example with a loss function and predicted SINR is given as the \n",
    "######### input to the DRL framework which is subsequently trained. This happens in an online fashion at every time-slot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa366cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## data for a sub-network \n",
    "lag = 10\n",
    "inp_data, out_data = [], []\n",
    "for i in range(M):\n",
    "    sinr_sub_nw = all_SINRsdB[:,0,:,:]\n",
    "    data_per_device = sinr_sub_nw[:,0,:]\n",
    "    for t in range(0, len(data_per_device)-lag):\n",
    "        inp_data.append(data_per_device[t:t+lag])\n",
    "        out_data.append(data_per_device[t+lag])\n",
    "\n",
    "    \n",
    "inp_data = np.array(inp_data)\n",
    "out_data = np.array(out_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cea5d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        \n",
    "        # Define the output layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        \n",
    "        # Initialize cell state with zeros\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93b6760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_no =47000\n",
    "inp_train_data = inp_data[0:samp_no]\n",
    "out_train_data = out_data[0:samp_no]\n",
    "inp_test_data = inp_data[samp_no:]\n",
    "out_test_data = out_data[samp_no:]\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "inp_train_data = torch.tensor(inp_train_data, dtype=torch.float32)\n",
    "out_train_data = torch.tensor(out_train_data, dtype=torch.float32)\n",
    "inp_test_data = torch.tensor(inp_test_data, dtype=torch.float32)\n",
    "out_test_data = torch.tensor(out_test_data, dtype=torch.float32)\n",
    "\n",
    "\n",
    "inp_test_data \n",
    "# Create a dataset and dataloader\n",
    "train_dataset = TensorDataset(inp_train_data, out_train_data)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "569dbfe4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [1/735], Loss: 360.2106\n",
      "Epoch [1/50], Step [2/735], Loss: 419.9127\n",
      "Epoch [1/50], Step [3/735], Loss: 460.9243\n",
      "Epoch [1/50], Step [4/735], Loss: 393.0578\n",
      "Epoch [1/50], Step [5/735], Loss: 349.0497\n",
      "Epoch [1/50], Step [6/735], Loss: 373.7418\n",
      "Epoch [1/50], Step [7/735], Loss: 429.3665\n",
      "Epoch [1/50], Step [8/735], Loss: 432.6199\n",
      "Epoch [1/50], Step [9/735], Loss: 462.6012\n",
      "Epoch [1/50], Step [10/735], Loss: 363.7121\n",
      "Epoch [1/50], Step [11/735], Loss: 423.8451\n",
      "Epoch [1/50], Step [12/735], Loss: 391.1205\n",
      "Epoch [1/50], Step [13/735], Loss: 353.3471\n",
      "Epoch [1/50], Step [14/735], Loss: 448.4174\n",
      "Epoch [1/50], Step [15/735], Loss: 397.7729\n",
      "Epoch [1/50], Step [16/735], Loss: 425.0495\n",
      "Epoch [1/50], Step [17/735], Loss: 388.6484\n",
      "Epoch [1/50], Step [18/735], Loss: 348.9367\n",
      "Epoch [1/50], Step [19/735], Loss: 420.4949\n",
      "Epoch [1/50], Step [20/735], Loss: 365.2315\n",
      "Epoch [1/50], Step [21/735], Loss: 382.2322\n",
      "Epoch [1/50], Step [22/735], Loss: 380.9889\n",
      "Epoch [1/50], Step [23/735], Loss: 385.1705\n",
      "Epoch [1/50], Step [24/735], Loss: 359.0921\n",
      "Epoch [1/50], Step [25/735], Loss: 354.5368\n",
      "Epoch [1/50], Step [26/735], Loss: 375.7181\n",
      "Epoch [1/50], Step [27/735], Loss: 380.4105\n",
      "Epoch [1/50], Step [28/735], Loss: 343.9193\n",
      "Epoch [1/50], Step [29/735], Loss: 337.7455\n",
      "Epoch [1/50], Step [30/735], Loss: 343.4301\n",
      "Epoch [1/50], Step [31/735], Loss: 364.9824\n",
      "Epoch [1/50], Step [32/735], Loss: 328.8009\n",
      "Epoch [1/50], Step [33/735], Loss: 354.8149\n",
      "Epoch [1/50], Step [34/735], Loss: 322.5391\n",
      "Epoch [1/50], Step [35/735], Loss: 356.2766\n",
      "Epoch [1/50], Step [36/735], Loss: 342.2682\n",
      "Epoch [1/50], Step [37/735], Loss: 305.1758\n",
      "Epoch [1/50], Step [38/735], Loss: 335.3177\n",
      "Epoch [1/50], Step [39/735], Loss: 369.6795\n",
      "Epoch [1/50], Step [40/735], Loss: 257.4546\n",
      "Epoch [1/50], Step [41/735], Loss: 306.1604\n",
      "Epoch [1/50], Step [42/735], Loss: 315.0665\n",
      "Epoch [1/50], Step [43/735], Loss: 299.8092\n",
      "Epoch [1/50], Step [44/735], Loss: 316.2762\n",
      "Epoch [1/50], Step [45/735], Loss: 286.2272\n",
      "Epoch [1/50], Step [46/735], Loss: 322.3837\n",
      "Epoch [1/50], Step [47/735], Loss: 285.9843\n",
      "Epoch [1/50], Step [48/735], Loss: 318.2893\n",
      "Epoch [1/50], Step [49/735], Loss: 254.7488\n",
      "Epoch [1/50], Step [50/735], Loss: 297.2121\n",
      "Epoch [1/50], Step [51/735], Loss: 313.4401\n",
      "Epoch [1/50], Step [52/735], Loss: 264.4531\n",
      "Epoch [1/50], Step [53/735], Loss: 258.7227\n",
      "Epoch [1/50], Step [54/735], Loss: 264.9373\n",
      "Epoch [1/50], Step [55/735], Loss: 304.8541\n",
      "Epoch [1/50], Step [56/735], Loss: 277.7422\n",
      "Epoch [1/50], Step [57/735], Loss: 256.3277\n",
      "Epoch [1/50], Step [58/735], Loss: 280.4310\n",
      "Epoch [1/50], Step [59/735], Loss: 262.3534\n",
      "Epoch [1/50], Step [60/735], Loss: 252.5607\n",
      "Epoch [1/50], Step [61/735], Loss: 235.0455\n",
      "Epoch [1/50], Step [62/735], Loss: 285.4712\n",
      "Epoch [1/50], Step [63/735], Loss: 271.9156\n",
      "Epoch [1/50], Step [64/735], Loss: 249.5836\n",
      "Epoch [1/50], Step [65/735], Loss: 228.5128\n",
      "Epoch [1/50], Step [66/735], Loss: 249.8034\n",
      "Epoch [1/50], Step [67/735], Loss: 194.2399\n",
      "Epoch [1/50], Step [68/735], Loss: 210.7462\n",
      "Epoch [1/50], Step [69/735], Loss: 224.6632\n",
      "Epoch [1/50], Step [70/735], Loss: 221.9740\n",
      "Epoch [1/50], Step [71/735], Loss: 198.7318\n",
      "Epoch [1/50], Step [72/735], Loss: 223.0668\n",
      "Epoch [1/50], Step [73/735], Loss: 228.6924\n",
      "Epoch [1/50], Step [74/735], Loss: 190.0389\n",
      "Epoch [1/50], Step [75/735], Loss: 205.7299\n",
      "Epoch [1/50], Step [76/735], Loss: 212.4224\n",
      "Epoch [1/50], Step [77/735], Loss: 211.6465\n",
      "Epoch [1/50], Step [78/735], Loss: 190.4009\n",
      "Epoch [1/50], Step [79/735], Loss: 191.9005\n",
      "Epoch [1/50], Step [80/735], Loss: 190.9564\n",
      "Epoch [1/50], Step [81/735], Loss: 191.2249\n",
      "Epoch [1/50], Step [82/735], Loss: 168.2649\n",
      "Epoch [1/50], Step [83/735], Loss: 175.6398\n",
      "Epoch [1/50], Step [84/735], Loss: 190.5883\n",
      "Epoch [1/50], Step [85/735], Loss: 184.9989\n",
      "Epoch [1/50], Step [86/735], Loss: 190.7225\n",
      "Epoch [1/50], Step [87/735], Loss: 153.6632\n",
      "Epoch [1/50], Step [88/735], Loss: 173.8006\n",
      "Epoch [1/50], Step [89/735], Loss: 172.5624\n",
      "Epoch [1/50], Step [90/735], Loss: 172.4961\n",
      "Epoch [1/50], Step [91/735], Loss: 193.4531\n",
      "Epoch [1/50], Step [92/735], Loss: 162.6552\n",
      "Epoch [1/50], Step [93/735], Loss: 174.4450\n",
      "Epoch [1/50], Step [94/735], Loss: 134.6501\n",
      "Epoch [1/50], Step [95/735], Loss: 153.2282\n",
      "Epoch [1/50], Step [96/735], Loss: 138.7147\n",
      "Epoch [1/50], Step [97/735], Loss: 117.9337\n",
      "Epoch [1/50], Step [98/735], Loss: 161.4924\n",
      "Epoch [1/50], Step [99/735], Loss: 144.6625\n",
      "Epoch [1/50], Step [100/735], Loss: 165.6718\n",
      "Epoch [1/50], Step [101/735], Loss: 131.6157\n",
      "Epoch [1/50], Step [102/735], Loss: 129.2566\n",
      "Epoch [1/50], Step [103/735], Loss: 137.3324\n",
      "Epoch [1/50], Step [104/735], Loss: 128.7417\n",
      "Epoch [1/50], Step [105/735], Loss: 116.9634\n",
      "Epoch [1/50], Step [106/735], Loss: 107.7912\n",
      "Epoch [1/50], Step [107/735], Loss: 130.1365\n",
      "Epoch [1/50], Step [108/735], Loss: 129.3335\n",
      "Epoch [1/50], Step [109/735], Loss: 125.3712\n",
      "Epoch [1/50], Step [110/735], Loss: 119.6740\n",
      "Epoch [1/50], Step [111/735], Loss: 118.8321\n",
      "Epoch [1/50], Step [112/735], Loss: 101.5141\n",
      "Epoch [1/50], Step [113/735], Loss: 106.5590\n",
      "Epoch [1/50], Step [114/735], Loss: 115.4697\n",
      "Epoch [1/50], Step [115/735], Loss: 107.1264\n",
      "Epoch [1/50], Step [116/735], Loss: 129.6589\n",
      "Epoch [1/50], Step [117/735], Loss: 110.1628\n",
      "Epoch [1/50], Step [118/735], Loss: 101.1748\n",
      "Epoch [1/50], Step [119/735], Loss: 115.1154\n",
      "Epoch [1/50], Step [120/735], Loss: 87.5691\n",
      "Epoch [1/50], Step [121/735], Loss: 102.6417\n",
      "Epoch [1/50], Step [122/735], Loss: 111.4905\n",
      "Epoch [1/50], Step [123/735], Loss: 86.4794\n",
      "Epoch [1/50], Step [124/735], Loss: 94.5650\n",
      "Epoch [1/50], Step [125/735], Loss: 91.2719\n",
      "Epoch [1/50], Step [126/735], Loss: 89.7062\n",
      "Epoch [1/50], Step [127/735], Loss: 83.4809\n",
      "Epoch [1/50], Step [128/735], Loss: 99.3066\n",
      "Epoch [1/50], Step [129/735], Loss: 82.3946\n",
      "Epoch [1/50], Step [130/735], Loss: 87.8971\n",
      "Epoch [1/50], Step [131/735], Loss: 76.9805\n",
      "Epoch [1/50], Step [132/735], Loss: 90.5074\n",
      "Epoch [1/50], Step [133/735], Loss: 80.7436\n",
      "Epoch [1/50], Step [134/735], Loss: 75.2061\n",
      "Epoch [1/50], Step [135/735], Loss: 70.3174\n",
      "Epoch [1/50], Step [136/735], Loss: 73.4498\n",
      "Epoch [1/50], Step [137/735], Loss: 85.4960\n",
      "Epoch [1/50], Step [138/735], Loss: 76.4706\n",
      "Epoch [1/50], Step [139/735], Loss: 74.6877\n",
      "Epoch [1/50], Step [140/735], Loss: 89.7160\n",
      "Epoch [1/50], Step [141/735], Loss: 90.6053\n",
      "Epoch [1/50], Step [142/735], Loss: 72.8666\n",
      "Epoch [1/50], Step [143/735], Loss: 70.2389\n",
      "Epoch [1/50], Step [144/735], Loss: 70.6923\n",
      "Epoch [1/50], Step [145/735], Loss: 75.1286\n",
      "Epoch [1/50], Step [146/735], Loss: 76.1106\n",
      "Epoch [1/50], Step [147/735], Loss: 60.3323\n",
      "Epoch [1/50], Step [148/735], Loss: 64.4123\n",
      "Epoch [1/50], Step [149/735], Loss: 65.0064\n",
      "Epoch [1/50], Step [150/735], Loss: 79.5490\n",
      "Epoch [1/50], Step [151/735], Loss: 47.7468\n",
      "Epoch [1/50], Step [152/735], Loss: 78.6955\n",
      "Epoch [1/50], Step [153/735], Loss: 71.9733\n",
      "Epoch [1/50], Step [154/735], Loss: 54.5912\n",
      "Epoch [1/50], Step [155/735], Loss: 63.6809\n",
      "Epoch [1/50], Step [156/735], Loss: 57.1718\n",
      "Epoch [1/50], Step [157/735], Loss: 68.1614\n",
      "Epoch [1/50], Step [158/735], Loss: 58.1884\n",
      "Epoch [1/50], Step [159/735], Loss: 58.1484\n",
      "Epoch [1/50], Step [160/735], Loss: 57.4638\n",
      "Epoch [1/50], Step [161/735], Loss: 57.8076\n",
      "Epoch [1/50], Step [162/735], Loss: 51.4861\n",
      "Epoch [1/50], Step [163/735], Loss: 43.2050\n",
      "Epoch [1/50], Step [164/735], Loss: 63.6640\n",
      "Epoch [1/50], Step [165/735], Loss: 59.9183\n",
      "Epoch [1/50], Step [166/735], Loss: 60.4581\n",
      "Epoch [1/50], Step [167/735], Loss: 56.9397\n",
      "Epoch [1/50], Step [168/735], Loss: 60.7552\n",
      "Epoch [1/50], Step [169/735], Loss: 53.5368\n",
      "Epoch [1/50], Step [170/735], Loss: 58.1471\n",
      "Epoch [1/50], Step [171/735], Loss: 53.9666\n",
      "Epoch [1/50], Step [172/735], Loss: 49.5262\n",
      "Epoch [1/50], Step [173/735], Loss: 57.4331\n",
      "Epoch [1/50], Step [174/735], Loss: 46.8996\n",
      "Epoch [1/50], Step [175/735], Loss: 52.0273\n",
      "Epoch [1/50], Step [176/735], Loss: 53.9236\n",
      "Epoch [1/50], Step [177/735], Loss: 43.5564\n",
      "Epoch [1/50], Step [178/735], Loss: 49.1061\n",
      "Epoch [1/50], Step [179/735], Loss: 52.0508\n",
      "Epoch [1/50], Step [180/735], Loss: 45.0720\n",
      "Epoch [1/50], Step [181/735], Loss: 51.3363\n",
      "Epoch [1/50], Step [182/735], Loss: 44.6477\n",
      "Epoch [1/50], Step [183/735], Loss: 38.6250\n",
      "Epoch [1/50], Step [184/735], Loss: 40.8481\n",
      "Epoch [1/50], Step [185/735], Loss: 45.7295\n",
      "Epoch [1/50], Step [186/735], Loss: 39.5285\n",
      "Epoch [1/50], Step [187/735], Loss: 48.3509\n",
      "Epoch [1/50], Step [188/735], Loss: 46.6373\n",
      "Epoch [1/50], Step [189/735], Loss: 41.6939\n",
      "Epoch [1/50], Step [190/735], Loss: 44.4865\n",
      "Epoch [1/50], Step [191/735], Loss: 40.0012\n",
      "Epoch [1/50], Step [192/735], Loss: 44.8241\n",
      "Epoch [1/50], Step [193/735], Loss: 37.8364\n",
      "Epoch [1/50], Step [194/735], Loss: 43.6407\n",
      "Epoch [1/50], Step [195/735], Loss: 38.4948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [196/735], Loss: 34.5719\n",
      "Epoch [1/50], Step [197/735], Loss: 36.4392\n",
      "Epoch [1/50], Step [198/735], Loss: 42.2020\n",
      "Epoch [1/50], Step [199/735], Loss: 39.2764\n",
      "Epoch [1/50], Step [200/735], Loss: 40.6987\n",
      "Epoch [1/50], Step [201/735], Loss: 34.2321\n",
      "Epoch [1/50], Step [202/735], Loss: 39.5953\n",
      "Epoch [1/50], Step [203/735], Loss: 29.2673\n",
      "Epoch [1/50], Step [204/735], Loss: 37.2505\n",
      "Epoch [1/50], Step [205/735], Loss: 37.9583\n",
      "Epoch [1/50], Step [206/735], Loss: 33.7463\n",
      "Epoch [1/50], Step [207/735], Loss: 24.7649\n",
      "Epoch [1/50], Step [208/735], Loss: 32.8536\n",
      "Epoch [1/50], Step [209/735], Loss: 27.6626\n",
      "Epoch [1/50], Step [210/735], Loss: 34.5913\n",
      "Epoch [1/50], Step [211/735], Loss: 31.6205\n",
      "Epoch [1/50], Step [212/735], Loss: 39.8463\n",
      "Epoch [1/50], Step [213/735], Loss: 34.5372\n",
      "Epoch [1/50], Step [214/735], Loss: 34.0405\n",
      "Epoch [1/50], Step [215/735], Loss: 32.5225\n",
      "Epoch [1/50], Step [216/735], Loss: 24.8937\n",
      "Epoch [1/50], Step [217/735], Loss: 27.9112\n",
      "Epoch [1/50], Step [218/735], Loss: 26.6333\n",
      "Epoch [1/50], Step [219/735], Loss: 33.9533\n",
      "Epoch [1/50], Step [220/735], Loss: 30.7458\n",
      "Epoch [1/50], Step [221/735], Loss: 25.5043\n",
      "Epoch [1/50], Step [222/735], Loss: 31.2094\n",
      "Epoch [1/50], Step [223/735], Loss: 30.5358\n",
      "Epoch [1/50], Step [224/735], Loss: 29.8370\n",
      "Epoch [1/50], Step [225/735], Loss: 24.1588\n",
      "Epoch [1/50], Step [226/735], Loss: 27.5249\n",
      "Epoch [1/50], Step [227/735], Loss: 24.3467\n",
      "Epoch [1/50], Step [228/735], Loss: 27.9293\n",
      "Epoch [1/50], Step [229/735], Loss: 24.2160\n",
      "Epoch [1/50], Step [230/735], Loss: 24.8129\n",
      "Epoch [1/50], Step [231/735], Loss: 23.4280\n",
      "Epoch [1/50], Step [232/735], Loss: 23.7403\n",
      "Epoch [1/50], Step [233/735], Loss: 25.0507\n",
      "Epoch [1/50], Step [234/735], Loss: 22.9226\n",
      "Epoch [1/50], Step [235/735], Loss: 23.9129\n",
      "Epoch [1/50], Step [236/735], Loss: 25.6510\n",
      "Epoch [1/50], Step [237/735], Loss: 23.7670\n",
      "Epoch [1/50], Step [238/735], Loss: 25.7826\n",
      "Epoch [1/50], Step [239/735], Loss: 23.4126\n",
      "Epoch [1/50], Step [240/735], Loss: 24.3904\n",
      "Epoch [1/50], Step [241/735], Loss: 26.8253\n",
      "Epoch [1/50], Step [242/735], Loss: 20.0098\n",
      "Epoch [1/50], Step [243/735], Loss: 20.2498\n",
      "Epoch [1/50], Step [244/735], Loss: 21.6772\n",
      "Epoch [1/50], Step [245/735], Loss: 22.0176\n",
      "Epoch [1/50], Step [246/735], Loss: 22.1505\n",
      "Epoch [1/50], Step [247/735], Loss: 20.8738\n",
      "Epoch [1/50], Step [248/735], Loss: 20.2348\n",
      "Epoch [1/50], Step [249/735], Loss: 22.3048\n",
      "Epoch [1/50], Step [250/735], Loss: 20.3522\n",
      "Epoch [1/50], Step [251/735], Loss: 24.3100\n",
      "Epoch [1/50], Step [252/735], Loss: 17.7867\n",
      "Epoch [1/50], Step [253/735], Loss: 21.9226\n",
      "Epoch [1/50], Step [254/735], Loss: 15.1306\n",
      "Epoch [1/50], Step [255/735], Loss: 15.4407\n",
      "Epoch [1/50], Step [256/735], Loss: 19.1845\n",
      "Epoch [1/50], Step [257/735], Loss: 22.9228\n",
      "Epoch [1/50], Step [258/735], Loss: 21.9727\n",
      "Epoch [1/50], Step [259/735], Loss: 16.2944\n",
      "Epoch [1/50], Step [260/735], Loss: 23.8175\n",
      "Epoch [1/50], Step [261/735], Loss: 17.8399\n",
      "Epoch [1/50], Step [262/735], Loss: 19.6172\n",
      "Epoch [1/50], Step [263/735], Loss: 15.6339\n",
      "Epoch [1/50], Step [264/735], Loss: 18.7845\n",
      "Epoch [1/50], Step [265/735], Loss: 22.8863\n",
      "Epoch [1/50], Step [266/735], Loss: 20.8262\n",
      "Epoch [1/50], Step [267/735], Loss: 16.5341\n",
      "Epoch [1/50], Step [268/735], Loss: 14.2199\n",
      "Epoch [1/50], Step [269/735], Loss: 19.2463\n",
      "Epoch [1/50], Step [270/735], Loss: 17.7956\n",
      "Epoch [1/50], Step [271/735], Loss: 16.8691\n",
      "Epoch [1/50], Step [272/735], Loss: 17.4149\n",
      "Epoch [1/50], Step [273/735], Loss: 15.7891\n",
      "Epoch [1/50], Step [274/735], Loss: 19.5093\n",
      "Epoch [1/50], Step [275/735], Loss: 17.3613\n",
      "Epoch [1/50], Step [276/735], Loss: 18.7606\n",
      "Epoch [1/50], Step [277/735], Loss: 14.6417\n",
      "Epoch [1/50], Step [278/735], Loss: 18.7056\n",
      "Epoch [1/50], Step [279/735], Loss: 18.9025\n",
      "Epoch [1/50], Step [280/735], Loss: 16.1688\n",
      "Epoch [1/50], Step [281/735], Loss: 15.9191\n",
      "Epoch [1/50], Step [282/735], Loss: 18.2019\n",
      "Epoch [1/50], Step [283/735], Loss: 17.8947\n",
      "Epoch [1/50], Step [284/735], Loss: 13.4144\n",
      "Epoch [1/50], Step [285/735], Loss: 14.1412\n",
      "Epoch [1/50], Step [286/735], Loss: 21.1884\n",
      "Epoch [1/50], Step [287/735], Loss: 17.0910\n",
      "Epoch [1/50], Step [288/735], Loss: 14.4802\n",
      "Epoch [1/50], Step [289/735], Loss: 18.2816\n",
      "Epoch [1/50], Step [290/735], Loss: 13.6539\n",
      "Epoch [1/50], Step [291/735], Loss: 9.8644\n",
      "Epoch [1/50], Step [292/735], Loss: 14.6161\n",
      "Epoch [1/50], Step [293/735], Loss: 13.0480\n",
      "Epoch [1/50], Step [294/735], Loss: 11.2197\n",
      "Epoch [1/50], Step [295/735], Loss: 18.4045\n",
      "Epoch [1/50], Step [296/735], Loss: 10.4196\n",
      "Epoch [1/50], Step [297/735], Loss: 14.1917\n",
      "Epoch [1/50], Step [298/735], Loss: 14.7242\n",
      "Epoch [1/50], Step [299/735], Loss: 12.5431\n",
      "Epoch [1/50], Step [300/735], Loss: 14.3962\n",
      "Epoch [1/50], Step [301/735], Loss: 15.0283\n",
      "Epoch [1/50], Step [302/735], Loss: 14.0347\n",
      "Epoch [1/50], Step [303/735], Loss: 12.7042\n",
      "Epoch [1/50], Step [304/735], Loss: 14.3380\n",
      "Epoch [1/50], Step [305/735], Loss: 12.3002\n",
      "Epoch [1/50], Step [306/735], Loss: 16.5922\n",
      "Epoch [1/50], Step [307/735], Loss: 15.0397\n",
      "Epoch [1/50], Step [308/735], Loss: 13.8133\n",
      "Epoch [1/50], Step [309/735], Loss: 9.8677\n",
      "Epoch [1/50], Step [310/735], Loss: 11.7583\n",
      "Epoch [1/50], Step [311/735], Loss: 15.4780\n",
      "Epoch [1/50], Step [312/735], Loss: 17.0446\n",
      "Epoch [1/50], Step [313/735], Loss: 14.2777\n",
      "Epoch [1/50], Step [314/735], Loss: 9.2846\n",
      "Epoch [1/50], Step [315/735], Loss: 12.6847\n",
      "Epoch [1/50], Step [316/735], Loss: 15.6321\n",
      "Epoch [1/50], Step [317/735], Loss: 10.6922\n",
      "Epoch [1/50], Step [318/735], Loss: 13.5990\n",
      "Epoch [1/50], Step [319/735], Loss: 11.0442\n",
      "Epoch [1/50], Step [320/735], Loss: 14.5398\n",
      "Epoch [1/50], Step [321/735], Loss: 16.3076\n",
      "Epoch [1/50], Step [322/735], Loss: 14.6163\n",
      "Epoch [1/50], Step [323/735], Loss: 13.3165\n",
      "Epoch [1/50], Step [324/735], Loss: 13.5436\n",
      "Epoch [1/50], Step [325/735], Loss: 12.6236\n",
      "Epoch [1/50], Step [326/735], Loss: 9.5259\n",
      "Epoch [1/50], Step [327/735], Loss: 10.4402\n",
      "Epoch [1/50], Step [328/735], Loss: 14.0487\n",
      "Epoch [1/50], Step [329/735], Loss: 13.1112\n",
      "Epoch [1/50], Step [330/735], Loss: 10.9420\n",
      "Epoch [1/50], Step [331/735], Loss: 14.1533\n",
      "Epoch [1/50], Step [332/735], Loss: 11.7413\n",
      "Epoch [1/50], Step [333/735], Loss: 11.4014\n",
      "Epoch [1/50], Step [334/735], Loss: 10.8485\n",
      "Epoch [1/50], Step [335/735], Loss: 14.1744\n",
      "Epoch [1/50], Step [336/735], Loss: 12.2628\n",
      "Epoch [1/50], Step [337/735], Loss: 11.6398\n",
      "Epoch [1/50], Step [338/735], Loss: 11.8299\n",
      "Epoch [1/50], Step [339/735], Loss: 12.9031\n",
      "Epoch [1/50], Step [340/735], Loss: 11.9970\n",
      "Epoch [1/50], Step [341/735], Loss: 11.9027\n",
      "Epoch [1/50], Step [342/735], Loss: 14.0319\n",
      "Epoch [1/50], Step [343/735], Loss: 11.5063\n",
      "Epoch [1/50], Step [344/735], Loss: 11.9163\n",
      "Epoch [1/50], Step [345/735], Loss: 10.2675\n",
      "Epoch [1/50], Step [346/735], Loss: 12.1971\n",
      "Epoch [1/50], Step [347/735], Loss: 11.7417\n",
      "Epoch [1/50], Step [348/735], Loss: 9.7022\n",
      "Epoch [1/50], Step [349/735], Loss: 9.4906\n",
      "Epoch [1/50], Step [350/735], Loss: 10.7827\n",
      "Epoch [1/50], Step [351/735], Loss: 10.8669\n",
      "Epoch [1/50], Step [352/735], Loss: 17.4187\n",
      "Epoch [1/50], Step [353/735], Loss: 8.6588\n",
      "Epoch [1/50], Step [354/735], Loss: 8.7614\n",
      "Epoch [1/50], Step [355/735], Loss: 11.8042\n",
      "Epoch [1/50], Step [356/735], Loss: 10.1023\n",
      "Epoch [1/50], Step [357/735], Loss: 10.0581\n",
      "Epoch [1/50], Step [358/735], Loss: 10.7137\n",
      "Epoch [1/50], Step [359/735], Loss: 14.9577\n",
      "Epoch [1/50], Step [360/735], Loss: 7.7376\n",
      "Epoch [1/50], Step [361/735], Loss: 10.8127\n",
      "Epoch [1/50], Step [362/735], Loss: 11.2724\n",
      "Epoch [1/50], Step [363/735], Loss: 9.7598\n",
      "Epoch [1/50], Step [364/735], Loss: 12.4430\n",
      "Epoch [1/50], Step [365/735], Loss: 11.6994\n",
      "Epoch [1/50], Step [366/735], Loss: 12.8606\n",
      "Epoch [1/50], Step [367/735], Loss: 9.3533\n",
      "Epoch [1/50], Step [368/735], Loss: 10.9591\n",
      "Epoch [1/50], Step [369/735], Loss: 8.8282\n",
      "Epoch [1/50], Step [370/735], Loss: 8.3089\n",
      "Epoch [1/50], Step [371/735], Loss: 9.8529\n",
      "Epoch [1/50], Step [372/735], Loss: 9.7294\n",
      "Epoch [1/50], Step [373/735], Loss: 8.6624\n",
      "Epoch [1/50], Step [374/735], Loss: 12.1215\n",
      "Epoch [1/50], Step [375/735], Loss: 9.1672\n",
      "Epoch [1/50], Step [376/735], Loss: 11.4477\n",
      "Epoch [1/50], Step [377/735], Loss: 8.9415\n",
      "Epoch [1/50], Step [378/735], Loss: 10.8020\n",
      "Epoch [1/50], Step [379/735], Loss: 10.8569\n",
      "Epoch [1/50], Step [380/735], Loss: 9.8870\n",
      "Epoch [1/50], Step [381/735], Loss: 8.9239\n",
      "Epoch [1/50], Step [382/735], Loss: 10.2976\n",
      "Epoch [1/50], Step [383/735], Loss: 8.1635\n",
      "Epoch [1/50], Step [384/735], Loss: 9.4421\n",
      "Epoch [1/50], Step [385/735], Loss: 7.8850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [386/735], Loss: 10.1100\n",
      "Epoch [1/50], Step [387/735], Loss: 9.7544\n",
      "Epoch [1/50], Step [388/735], Loss: 13.5454\n",
      "Epoch [1/50], Step [389/735], Loss: 12.2319\n",
      "Epoch [1/50], Step [390/735], Loss: 7.9498\n",
      "Epoch [1/50], Step [391/735], Loss: 18.9788\n",
      "Epoch [1/50], Step [392/735], Loss: 7.4606\n",
      "Epoch [1/50], Step [393/735], Loss: 11.2141\n",
      "Epoch [1/50], Step [394/735], Loss: 10.9117\n",
      "Epoch [1/50], Step [395/735], Loss: 9.1747\n",
      "Epoch [1/50], Step [396/735], Loss: 8.5345\n",
      "Epoch [1/50], Step [397/735], Loss: 10.9488\n",
      "Epoch [1/50], Step [398/735], Loss: 8.7787\n",
      "Epoch [1/50], Step [399/735], Loss: 8.0330\n",
      "Epoch [1/50], Step [400/735], Loss: 7.3957\n",
      "Epoch [1/50], Step [401/735], Loss: 10.3376\n",
      "Epoch [1/50], Step [402/735], Loss: 8.7961\n",
      "Epoch [1/50], Step [403/735], Loss: 9.5909\n",
      "Epoch [1/50], Step [404/735], Loss: 10.6753\n",
      "Epoch [1/50], Step [405/735], Loss: 6.8159\n",
      "Epoch [1/50], Step [406/735], Loss: 8.3551\n",
      "Epoch [1/50], Step [407/735], Loss: 9.5742\n",
      "Epoch [1/50], Step [408/735], Loss: 9.7315\n",
      "Epoch [1/50], Step [409/735], Loss: 8.3394\n",
      "Epoch [1/50], Step [410/735], Loss: 10.3794\n",
      "Epoch [1/50], Step [411/735], Loss: 9.4793\n",
      "Epoch [1/50], Step [412/735], Loss: 11.8981\n",
      "Epoch [1/50], Step [413/735], Loss: 8.2182\n",
      "Epoch [1/50], Step [414/735], Loss: 8.9788\n",
      "Epoch [1/50], Step [415/735], Loss: 8.9672\n",
      "Epoch [1/50], Step [416/735], Loss: 7.2866\n",
      "Epoch [1/50], Step [417/735], Loss: 8.9748\n",
      "Epoch [1/50], Step [418/735], Loss: 8.9375\n",
      "Epoch [1/50], Step [419/735], Loss: 7.7167\n",
      "Epoch [1/50], Step [420/735], Loss: 9.9517\n",
      "Epoch [1/50], Step [421/735], Loss: 7.4518\n",
      "Epoch [1/50], Step [422/735], Loss: 10.4531\n",
      "Epoch [1/50], Step [423/735], Loss: 9.3196\n",
      "Epoch [1/50], Step [424/735], Loss: 8.8012\n",
      "Epoch [1/50], Step [425/735], Loss: 8.6605\n",
      "Epoch [1/50], Step [426/735], Loss: 11.1093\n",
      "Epoch [1/50], Step [427/735], Loss: 6.8469\n",
      "Epoch [1/50], Step [428/735], Loss: 6.8030\n",
      "Epoch [1/50], Step [429/735], Loss: 8.6542\n",
      "Epoch [1/50], Step [430/735], Loss: 7.9646\n",
      "Epoch [1/50], Step [431/735], Loss: 7.0064\n",
      "Epoch [1/50], Step [432/735], Loss: 6.7501\n",
      "Epoch [1/50], Step [433/735], Loss: 6.1670\n",
      "Epoch [1/50], Step [434/735], Loss: 8.1708\n",
      "Epoch [1/50], Step [435/735], Loss: 9.6967\n",
      "Epoch [1/50], Step [436/735], Loss: 8.6758\n",
      "Epoch [1/50], Step [437/735], Loss: 8.6312\n",
      "Epoch [1/50], Step [438/735], Loss: 8.5991\n",
      "Epoch [1/50], Step [439/735], Loss: 8.0383\n",
      "Epoch [1/50], Step [440/735], Loss: 6.8131\n",
      "Epoch [1/50], Step [441/735], Loss: 9.3728\n",
      "Epoch [1/50], Step [442/735], Loss: 10.0686\n",
      "Epoch [1/50], Step [443/735], Loss: 6.9499\n",
      "Epoch [1/50], Step [444/735], Loss: 6.9712\n",
      "Epoch [1/50], Step [445/735], Loss: 7.2742\n",
      "Epoch [1/50], Step [446/735], Loss: 8.2757\n",
      "Epoch [1/50], Step [447/735], Loss: 6.7703\n",
      "Epoch [1/50], Step [448/735], Loss: 6.8123\n",
      "Epoch [1/50], Step [449/735], Loss: 7.9362\n",
      "Epoch [1/50], Step [450/735], Loss: 8.0965\n",
      "Epoch [1/50], Step [451/735], Loss: 7.5631\n",
      "Epoch [1/50], Step [452/735], Loss: 5.6300\n",
      "Epoch [1/50], Step [453/735], Loss: 10.1518\n",
      "Epoch [1/50], Step [454/735], Loss: 7.7815\n",
      "Epoch [1/50], Step [455/735], Loss: 10.0467\n",
      "Epoch [1/50], Step [456/735], Loss: 9.1628\n",
      "Epoch [1/50], Step [457/735], Loss: 5.8980\n",
      "Epoch [1/50], Step [458/735], Loss: 9.5001\n",
      "Epoch [1/50], Step [459/735], Loss: 7.4320\n",
      "Epoch [1/50], Step [460/735], Loss: 7.6143\n",
      "Epoch [1/50], Step [461/735], Loss: 4.3981\n",
      "Epoch [1/50], Step [462/735], Loss: 7.9126\n",
      "Epoch [1/50], Step [463/735], Loss: 7.1198\n",
      "Epoch [1/50], Step [464/735], Loss: 6.8882\n",
      "Epoch [1/50], Step [465/735], Loss: 5.9806\n",
      "Epoch [1/50], Step [466/735], Loss: 7.7106\n",
      "Epoch [1/50], Step [467/735], Loss: 7.2743\n",
      "Epoch [1/50], Step [468/735], Loss: 6.2919\n",
      "Epoch [1/50], Step [469/735], Loss: 10.1727\n",
      "Epoch [1/50], Step [470/735], Loss: 7.6532\n",
      "Epoch [1/50], Step [471/735], Loss: 6.8109\n",
      "Epoch [1/50], Step [472/735], Loss: 7.1692\n",
      "Epoch [1/50], Step [473/735], Loss: 6.4570\n",
      "Epoch [1/50], Step [474/735], Loss: 9.0383\n",
      "Epoch [1/50], Step [475/735], Loss: 5.7188\n",
      "Epoch [1/50], Step [476/735], Loss: 6.1187\n",
      "Epoch [1/50], Step [477/735], Loss: 6.2066\n",
      "Epoch [1/50], Step [478/735], Loss: 6.5746\n",
      "Epoch [1/50], Step [479/735], Loss: 6.3774\n",
      "Epoch [1/50], Step [480/735], Loss: 8.2023\n",
      "Epoch [1/50], Step [481/735], Loss: 7.9474\n",
      "Epoch [1/50], Step [482/735], Loss: 6.6764\n",
      "Epoch [1/50], Step [483/735], Loss: 6.2878\n",
      "Epoch [1/50], Step [484/735], Loss: 7.5568\n",
      "Epoch [1/50], Step [485/735], Loss: 13.9497\n",
      "Epoch [1/50], Step [486/735], Loss: 6.2139\n",
      "Epoch [1/50], Step [487/735], Loss: 6.4387\n",
      "Epoch [1/50], Step [488/735], Loss: 7.5158\n",
      "Epoch [1/50], Step [489/735], Loss: 6.1157\n",
      "Epoch [1/50], Step [490/735], Loss: 7.5069\n",
      "Epoch [1/50], Step [491/735], Loss: 7.2174\n",
      "Epoch [1/50], Step [492/735], Loss: 5.4513\n",
      "Epoch [1/50], Step [493/735], Loss: 6.0104\n",
      "Epoch [1/50], Step [494/735], Loss: 6.7130\n",
      "Epoch [1/50], Step [495/735], Loss: 8.2806\n",
      "Epoch [1/50], Step [496/735], Loss: 5.6957\n",
      "Epoch [1/50], Step [497/735], Loss: 5.8035\n",
      "Epoch [1/50], Step [498/735], Loss: 7.7441\n",
      "Epoch [1/50], Step [499/735], Loss: 6.5585\n",
      "Epoch [1/50], Step [500/735], Loss: 8.7423\n",
      "Epoch [1/50], Step [501/735], Loss: 7.0401\n",
      "Epoch [1/50], Step [502/735], Loss: 6.2507\n",
      "Epoch [1/50], Step [503/735], Loss: 5.8414\n",
      "Epoch [1/50], Step [504/735], Loss: 8.2650\n",
      "Epoch [1/50], Step [505/735], Loss: 7.3862\n",
      "Epoch [1/50], Step [506/735], Loss: 5.7074\n",
      "Epoch [1/50], Step [507/735], Loss: 7.1565\n",
      "Epoch [1/50], Step [508/735], Loss: 5.8434\n",
      "Epoch [1/50], Step [509/735], Loss: 6.0813\n",
      "Epoch [1/50], Step [510/735], Loss: 5.3011\n",
      "Epoch [1/50], Step [511/735], Loss: 5.6055\n",
      "Epoch [1/50], Step [512/735], Loss: 5.1614\n",
      "Epoch [1/50], Step [513/735], Loss: 5.9080\n",
      "Epoch [1/50], Step [514/735], Loss: 4.9687\n",
      "Epoch [1/50], Step [515/735], Loss: 4.5022\n",
      "Epoch [1/50], Step [516/735], Loss: 5.5744\n",
      "Epoch [1/50], Step [517/735], Loss: 6.6135\n",
      "Epoch [1/50], Step [518/735], Loss: 5.3179\n",
      "Epoch [1/50], Step [519/735], Loss: 6.1739\n",
      "Epoch [1/50], Step [520/735], Loss: 4.7026\n",
      "Epoch [1/50], Step [521/735], Loss: 10.6564\n",
      "Epoch [1/50], Step [522/735], Loss: 6.4289\n",
      "Epoch [1/50], Step [523/735], Loss: 5.4314\n",
      "Epoch [1/50], Step [524/735], Loss: 6.1672\n",
      "Epoch [1/50], Step [525/735], Loss: 6.9419\n",
      "Epoch [1/50], Step [526/735], Loss: 5.4687\n",
      "Epoch [1/50], Step [527/735], Loss: 5.4256\n",
      "Epoch [1/50], Step [528/735], Loss: 10.1753\n",
      "Epoch [1/50], Step [529/735], Loss: 5.5718\n",
      "Epoch [1/50], Step [530/735], Loss: 5.1842\n",
      "Epoch [1/50], Step [531/735], Loss: 5.2751\n",
      "Epoch [1/50], Step [532/735], Loss: 6.3621\n",
      "Epoch [1/50], Step [533/735], Loss: 5.5997\n",
      "Epoch [1/50], Step [534/735], Loss: 5.7838\n",
      "Epoch [1/50], Step [535/735], Loss: 4.5603\n",
      "Epoch [1/50], Step [536/735], Loss: 6.2600\n",
      "Epoch [1/50], Step [537/735], Loss: 5.9089\n",
      "Epoch [1/50], Step [538/735], Loss: 4.1384\n",
      "Epoch [1/50], Step [539/735], Loss: 5.2442\n",
      "Epoch [1/50], Step [540/735], Loss: 5.9279\n",
      "Epoch [1/50], Step [541/735], Loss: 5.7276\n",
      "Epoch [1/50], Step [542/735], Loss: 8.5946\n",
      "Epoch [1/50], Step [543/735], Loss: 5.7756\n",
      "Epoch [1/50], Step [544/735], Loss: 4.9738\n",
      "Epoch [1/50], Step [545/735], Loss: 5.5235\n",
      "Epoch [1/50], Step [546/735], Loss: 7.2375\n",
      "Epoch [1/50], Step [547/735], Loss: 4.9886\n",
      "Epoch [1/50], Step [548/735], Loss: 4.6342\n",
      "Epoch [1/50], Step [549/735], Loss: 4.0339\n",
      "Epoch [1/50], Step [550/735], Loss: 4.5232\n",
      "Epoch [1/50], Step [551/735], Loss: 6.2356\n",
      "Epoch [1/50], Step [552/735], Loss: 6.0741\n",
      "Epoch [1/50], Step [553/735], Loss: 8.9147\n",
      "Epoch [1/50], Step [554/735], Loss: 4.9751\n",
      "Epoch [1/50], Step [555/735], Loss: 4.2326\n",
      "Epoch [1/50], Step [556/735], Loss: 5.8844\n",
      "Epoch [1/50], Step [557/735], Loss: 6.3797\n",
      "Epoch [1/50], Step [558/735], Loss: 5.2295\n",
      "Epoch [1/50], Step [559/735], Loss: 5.4032\n",
      "Epoch [1/50], Step [560/735], Loss: 5.9062\n",
      "Epoch [1/50], Step [561/735], Loss: 4.0380\n",
      "Epoch [1/50], Step [562/735], Loss: 6.1722\n",
      "Epoch [1/50], Step [563/735], Loss: 6.6783\n",
      "Epoch [1/50], Step [564/735], Loss: 7.1594\n",
      "Epoch [1/50], Step [565/735], Loss: 5.1389\n",
      "Epoch [1/50], Step [566/735], Loss: 5.0303\n",
      "Epoch [1/50], Step [567/735], Loss: 7.0855\n",
      "Epoch [1/50], Step [568/735], Loss: 4.6485\n",
      "Epoch [1/50], Step [569/735], Loss: 5.2094\n",
      "Epoch [1/50], Step [570/735], Loss: 5.7518\n",
      "Epoch [1/50], Step [571/735], Loss: 5.7437\n",
      "Epoch [1/50], Step [572/735], Loss: 5.2392\n",
      "Epoch [1/50], Step [573/735], Loss: 5.1586\n",
      "Epoch [1/50], Step [574/735], Loss: 4.6517\n",
      "Epoch [1/50], Step [575/735], Loss: 5.7077\n",
      "Epoch [1/50], Step [576/735], Loss: 4.7719\n",
      "Epoch [1/50], Step [577/735], Loss: 4.6220\n",
      "Epoch [1/50], Step [578/735], Loss: 5.5388\n",
      "Epoch [1/50], Step [579/735], Loss: 5.4080\n",
      "Epoch [1/50], Step [580/735], Loss: 4.6581\n",
      "Epoch [1/50], Step [581/735], Loss: 4.7848\n",
      "Epoch [1/50], Step [582/735], Loss: 5.4584\n",
      "Epoch [1/50], Step [583/735], Loss: 4.5028\n",
      "Epoch [1/50], Step [584/735], Loss: 4.3517\n",
      "Epoch [1/50], Step [585/735], Loss: 5.5841\n",
      "Epoch [1/50], Step [586/735], Loss: 5.1410\n",
      "Epoch [1/50], Step [587/735], Loss: 5.2627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [588/735], Loss: 4.7540\n",
      "Epoch [1/50], Step [589/735], Loss: 4.2767\n",
      "Epoch [1/50], Step [590/735], Loss: 6.9269\n",
      "Epoch [1/50], Step [591/735], Loss: 5.0083\n",
      "Epoch [1/50], Step [592/735], Loss: 3.7854\n",
      "Epoch [1/50], Step [593/735], Loss: 5.0346\n",
      "Epoch [1/50], Step [594/735], Loss: 5.3034\n",
      "Epoch [1/50], Step [595/735], Loss: 5.9794\n",
      "Epoch [1/50], Step [596/735], Loss: 5.5145\n",
      "Epoch [1/50], Step [597/735], Loss: 4.9932\n",
      "Epoch [1/50], Step [598/735], Loss: 4.9878\n",
      "Epoch [1/50], Step [599/735], Loss: 4.1369\n",
      "Epoch [1/50], Step [600/735], Loss: 7.6992\n",
      "Epoch [1/50], Step [601/735], Loss: 4.8890\n",
      "Epoch [1/50], Step [602/735], Loss: 4.2851\n",
      "Epoch [1/50], Step [603/735], Loss: 4.7802\n",
      "Epoch [1/50], Step [604/735], Loss: 4.8132\n",
      "Epoch [1/50], Step [605/735], Loss: 4.2607\n",
      "Epoch [1/50], Step [606/735], Loss: 4.7504\n",
      "Epoch [1/50], Step [607/735], Loss: 3.6847\n",
      "Epoch [1/50], Step [608/735], Loss: 4.9891\n",
      "Epoch [1/50], Step [609/735], Loss: 3.5872\n",
      "Epoch [1/50], Step [610/735], Loss: 4.8545\n",
      "Epoch [1/50], Step [611/735], Loss: 6.3229\n",
      "Epoch [1/50], Step [612/735], Loss: 4.3659\n",
      "Epoch [1/50], Step [613/735], Loss: 3.7820\n",
      "Epoch [1/50], Step [614/735], Loss: 6.7766\n",
      "Epoch [1/50], Step [615/735], Loss: 4.8404\n",
      "Epoch [1/50], Step [616/735], Loss: 3.6886\n",
      "Epoch [1/50], Step [617/735], Loss: 4.2768\n",
      "Epoch [1/50], Step [618/735], Loss: 4.9231\n",
      "Epoch [1/50], Step [619/735], Loss: 5.6062\n",
      "Epoch [1/50], Step [620/735], Loss: 5.8659\n",
      "Epoch [1/50], Step [621/735], Loss: 3.6059\n",
      "Epoch [1/50], Step [622/735], Loss: 3.9674\n",
      "Epoch [1/50], Step [623/735], Loss: 4.7991\n",
      "Epoch [1/50], Step [624/735], Loss: 5.5869\n",
      "Epoch [1/50], Step [625/735], Loss: 3.8885\n",
      "Epoch [1/50], Step [626/735], Loss: 3.7568\n",
      "Epoch [1/50], Step [627/735], Loss: 3.7953\n",
      "Epoch [1/50], Step [628/735], Loss: 4.1421\n",
      "Epoch [1/50], Step [629/735], Loss: 4.9076\n",
      "Epoch [1/50], Step [630/735], Loss: 4.3466\n",
      "Epoch [1/50], Step [631/735], Loss: 5.4035\n",
      "Epoch [1/50], Step [632/735], Loss: 4.5760\n",
      "Epoch [1/50], Step [633/735], Loss: 4.8619\n",
      "Epoch [1/50], Step [634/735], Loss: 5.5156\n",
      "Epoch [1/50], Step [635/735], Loss: 3.9880\n",
      "Epoch [1/50], Step [636/735], Loss: 3.6857\n",
      "Epoch [1/50], Step [637/735], Loss: 4.6082\n",
      "Epoch [1/50], Step [638/735], Loss: 3.1263\n",
      "Epoch [1/50], Step [639/735], Loss: 4.0940\n",
      "Epoch [1/50], Step [640/735], Loss: 4.9128\n",
      "Epoch [1/50], Step [641/735], Loss: 3.7388\n",
      "Epoch [1/50], Step [642/735], Loss: 3.8626\n",
      "Epoch [1/50], Step [643/735], Loss: 2.7022\n",
      "Epoch [1/50], Step [644/735], Loss: 4.1882\n",
      "Epoch [1/50], Step [645/735], Loss: 4.0681\n",
      "Epoch [1/50], Step [646/735], Loss: 3.0418\n",
      "Epoch [1/50], Step [647/735], Loss: 4.3844\n",
      "Epoch [1/50], Step [648/735], Loss: 4.2886\n",
      "Epoch [1/50], Step [649/735], Loss: 3.5028\n",
      "Epoch [1/50], Step [650/735], Loss: 5.3140\n",
      "Epoch [1/50], Step [651/735], Loss: 4.0759\n",
      "Epoch [1/50], Step [652/735], Loss: 6.9122\n",
      "Epoch [1/50], Step [653/735], Loss: 4.9333\n",
      "Epoch [1/50], Step [654/735], Loss: 3.2702\n",
      "Epoch [1/50], Step [655/735], Loss: 3.2874\n",
      "Epoch [1/50], Step [656/735], Loss: 4.2530\n",
      "Epoch [1/50], Step [657/735], Loss: 3.3270\n",
      "Epoch [1/50], Step [658/735], Loss: 4.8499\n",
      "Epoch [1/50], Step [659/735], Loss: 4.3782\n",
      "Epoch [1/50], Step [660/735], Loss: 5.2384\n",
      "Epoch [1/50], Step [661/735], Loss: 3.4640\n",
      "Epoch [1/50], Step [662/735], Loss: 3.9588\n",
      "Epoch [1/50], Step [663/735], Loss: 3.3537\n",
      "Epoch [1/50], Step [664/735], Loss: 4.1925\n",
      "Epoch [1/50], Step [665/735], Loss: 4.1922\n",
      "Epoch [1/50], Step [666/735], Loss: 4.0935\n",
      "Epoch [1/50], Step [667/735], Loss: 4.2452\n",
      "Epoch [1/50], Step [668/735], Loss: 4.2721\n",
      "Epoch [1/50], Step [669/735], Loss: 3.0606\n",
      "Epoch [1/50], Step [670/735], Loss: 4.2902\n",
      "Epoch [1/50], Step [671/735], Loss: 2.8600\n",
      "Epoch [1/50], Step [672/735], Loss: 3.5331\n",
      "Epoch [1/50], Step [673/735], Loss: 4.6780\n",
      "Epoch [1/50], Step [674/735], Loss: 4.3120\n",
      "Epoch [1/50], Step [675/735], Loss: 4.1059\n",
      "Epoch [1/50], Step [676/735], Loss: 3.2147\n",
      "Epoch [1/50], Step [677/735], Loss: 2.8657\n",
      "Epoch [1/50], Step [678/735], Loss: 4.4539\n",
      "Epoch [1/50], Step [679/735], Loss: 3.6867\n",
      "Epoch [1/50], Step [680/735], Loss: 2.6516\n",
      "Epoch [1/50], Step [681/735], Loss: 4.5994\n",
      "Epoch [1/50], Step [682/735], Loss: 2.8667\n",
      "Epoch [1/50], Step [683/735], Loss: 3.4009\n",
      "Epoch [1/50], Step [684/735], Loss: 3.8217\n",
      "Epoch [1/50], Step [685/735], Loss: 4.9832\n",
      "Epoch [1/50], Step [686/735], Loss: 3.4676\n",
      "Epoch [1/50], Step [687/735], Loss: 3.4087\n",
      "Epoch [1/50], Step [688/735], Loss: 3.7602\n",
      "Epoch [1/50], Step [689/735], Loss: 3.8971\n",
      "Epoch [1/50], Step [690/735], Loss: 3.3855\n",
      "Epoch [1/50], Step [691/735], Loss: 3.7344\n",
      "Epoch [1/50], Step [692/735], Loss: 3.2656\n",
      "Epoch [1/50], Step [693/735], Loss: 4.1952\n",
      "Epoch [1/50], Step [694/735], Loss: 3.2181\n",
      "Epoch [1/50], Step [695/735], Loss: 5.2163\n",
      "Epoch [1/50], Step [696/735], Loss: 5.4243\n",
      "Epoch [1/50], Step [697/735], Loss: 3.2101\n",
      "Epoch [1/50], Step [698/735], Loss: 3.4252\n",
      "Epoch [1/50], Step [699/735], Loss: 3.5204\n",
      "Epoch [1/50], Step [700/735], Loss: 4.4896\n",
      "Epoch [1/50], Step [701/735], Loss: 2.7232\n",
      "Epoch [1/50], Step [702/735], Loss: 2.8404\n",
      "Epoch [1/50], Step [703/735], Loss: 2.5313\n",
      "Epoch [1/50], Step [704/735], Loss: 3.7992\n",
      "Epoch [1/50], Step [705/735], Loss: 3.8180\n",
      "Epoch [1/50], Step [706/735], Loss: 3.7676\n",
      "Epoch [1/50], Step [707/735], Loss: 5.0181\n",
      "Epoch [1/50], Step [708/735], Loss: 4.5192\n",
      "Epoch [1/50], Step [709/735], Loss: 4.2147\n",
      "Epoch [1/50], Step [710/735], Loss: 2.9120\n",
      "Epoch [1/50], Step [711/735], Loss: 4.2817\n",
      "Epoch [1/50], Step [712/735], Loss: 5.1691\n",
      "Epoch [1/50], Step [713/735], Loss: 11.3087\n",
      "Epoch [1/50], Step [714/735], Loss: 3.0371\n",
      "Epoch [1/50], Step [715/735], Loss: 3.9203\n",
      "Epoch [1/50], Step [716/735], Loss: 2.8409\n",
      "Epoch [1/50], Step [717/735], Loss: 3.5219\n",
      "Epoch [1/50], Step [718/735], Loss: 4.3759\n",
      "Epoch [1/50], Step [719/735], Loss: 5.0373\n",
      "Epoch [1/50], Step [720/735], Loss: 3.3781\n",
      "Epoch [1/50], Step [721/735], Loss: 3.0887\n",
      "Epoch [1/50], Step [722/735], Loss: 4.6595\n",
      "Epoch [1/50], Step [723/735], Loss: 5.2691\n",
      "Epoch [1/50], Step [724/735], Loss: 3.3020\n",
      "Epoch [1/50], Step [725/735], Loss: 4.1131\n",
      "Epoch [1/50], Step [726/735], Loss: 4.6365\n",
      "Epoch [1/50], Step [727/735], Loss: 3.1171\n",
      "Epoch [1/50], Step [728/735], Loss: 3.2276\n",
      "Epoch [1/50], Step [729/735], Loss: 3.7414\n",
      "Epoch [1/50], Step [730/735], Loss: 3.2104\n",
      "Epoch [1/50], Step [731/735], Loss: 2.7376\n",
      "Epoch [1/50], Step [732/735], Loss: 6.2895\n",
      "Epoch [1/50], Step [733/735], Loss: 3.0913\n",
      "Epoch [1/50], Step [734/735], Loss: 2.8175\n",
      "Epoch [1/50], Step [735/735], Loss: 2.7811\n",
      "Epoch [2/50], Step [1/735], Loss: 3.7615\n",
      "Epoch [2/50], Step [2/735], Loss: 4.0355\n",
      "Epoch [2/50], Step [3/735], Loss: 3.8307\n",
      "Epoch [2/50], Step [4/735], Loss: 4.4343\n",
      "Epoch [2/50], Step [5/735], Loss: 3.5492\n",
      "Epoch [2/50], Step [6/735], Loss: 3.5790\n",
      "Epoch [2/50], Step [7/735], Loss: 3.5277\n",
      "Epoch [2/50], Step [8/735], Loss: 3.5439\n",
      "Epoch [2/50], Step [9/735], Loss: 3.1736\n",
      "Epoch [2/50], Step [10/735], Loss: 3.0431\n",
      "Epoch [2/50], Step [11/735], Loss: 2.4301\n",
      "Epoch [2/50], Step [12/735], Loss: 3.9029\n",
      "Epoch [2/50], Step [13/735], Loss: 3.1948\n",
      "Epoch [2/50], Step [14/735], Loss: 3.3020\n",
      "Epoch [2/50], Step [15/735], Loss: 3.5586\n",
      "Epoch [2/50], Step [16/735], Loss: 3.5307\n",
      "Epoch [2/50], Step [17/735], Loss: 3.3568\n",
      "Epoch [2/50], Step [18/735], Loss: 4.2968\n",
      "Epoch [2/50], Step [19/735], Loss: 3.3226\n",
      "Epoch [2/50], Step [20/735], Loss: 4.1993\n",
      "Epoch [2/50], Step [21/735], Loss: 2.4659\n",
      "Epoch [2/50], Step [22/735], Loss: 3.0294\n",
      "Epoch [2/50], Step [23/735], Loss: 2.9883\n",
      "Epoch [2/50], Step [24/735], Loss: 3.0308\n",
      "Epoch [2/50], Step [25/735], Loss: 2.9898\n",
      "Epoch [2/50], Step [26/735], Loss: 3.0958\n",
      "Epoch [2/50], Step [27/735], Loss: 3.3654\n",
      "Epoch [2/50], Step [28/735], Loss: 2.9704\n",
      "Epoch [2/50], Step [29/735], Loss: 3.7905\n",
      "Epoch [2/50], Step [30/735], Loss: 3.2485\n",
      "Epoch [2/50], Step [31/735], Loss: 2.8727\n",
      "Epoch [2/50], Step [32/735], Loss: 4.3608\n",
      "Epoch [2/50], Step [33/735], Loss: 3.2224\n",
      "Epoch [2/50], Step [34/735], Loss: 3.4205\n",
      "Epoch [2/50], Step [35/735], Loss: 2.7398\n",
      "Epoch [2/50], Step [36/735], Loss: 3.1144\n",
      "Epoch [2/50], Step [37/735], Loss: 2.6095\n",
      "Epoch [2/50], Step [38/735], Loss: 3.0184\n",
      "Epoch [2/50], Step [39/735], Loss: 2.7763\n",
      "Epoch [2/50], Step [40/735], Loss: 3.3799\n",
      "Epoch [2/50], Step [41/735], Loss: 7.5785\n",
      "Epoch [2/50], Step [42/735], Loss: 2.8614\n",
      "Epoch [2/50], Step [43/735], Loss: 2.6740\n",
      "Epoch [2/50], Step [44/735], Loss: 2.9410\n",
      "Epoch [2/50], Step [45/735], Loss: 2.5075\n",
      "Epoch [2/50], Step [46/735], Loss: 10.0060\n",
      "Epoch [2/50], Step [47/735], Loss: 2.3236\n",
      "Epoch [2/50], Step [48/735], Loss: 2.3644\n",
      "Epoch [2/50], Step [49/735], Loss: 3.4520\n",
      "Epoch [2/50], Step [50/735], Loss: 2.3420\n",
      "Epoch [2/50], Step [51/735], Loss: 4.4688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Step [52/735], Loss: 2.8056\n",
      "Epoch [2/50], Step [53/735], Loss: 2.7527\n",
      "Epoch [2/50], Step [54/735], Loss: 2.2329\n",
      "Epoch [2/50], Step [55/735], Loss: 3.1465\n",
      "Epoch [2/50], Step [56/735], Loss: 3.3482\n",
      "Epoch [2/50], Step [57/735], Loss: 2.4447\n",
      "Epoch [2/50], Step [58/735], Loss: 2.0883\n",
      "Epoch [2/50], Step [59/735], Loss: 2.0060\n",
      "Epoch [2/50], Step [60/735], Loss: 2.5854\n",
      "Epoch [2/50], Step [61/735], Loss: 3.2410\n",
      "Epoch [2/50], Step [62/735], Loss: 2.1723\n",
      "Epoch [2/50], Step [63/735], Loss: 3.6038\n",
      "Epoch [2/50], Step [64/735], Loss: 1.9019\n",
      "Epoch [2/50], Step [65/735], Loss: 3.8567\n",
      "Epoch [2/50], Step [66/735], Loss: 3.4782\n",
      "Epoch [2/50], Step [67/735], Loss: 4.5999\n",
      "Epoch [2/50], Step [68/735], Loss: 2.9931\n",
      "Epoch [2/50], Step [69/735], Loss: 3.6723\n",
      "Epoch [2/50], Step [70/735], Loss: 4.0516\n",
      "Epoch [2/50], Step [71/735], Loss: 3.3371\n",
      "Epoch [2/50], Step [72/735], Loss: 2.0646\n",
      "Epoch [2/50], Step [73/735], Loss: 2.7681\n",
      "Epoch [2/50], Step [74/735], Loss: 5.2787\n",
      "Epoch [2/50], Step [75/735], Loss: 2.9538\n",
      "Epoch [2/50], Step [76/735], Loss: 2.5051\n",
      "Epoch [2/50], Step [77/735], Loss: 2.5144\n",
      "Epoch [2/50], Step [78/735], Loss: 2.0609\n",
      "Epoch [2/50], Step [79/735], Loss: 2.4574\n",
      "Epoch [2/50], Step [80/735], Loss: 2.8853\n",
      "Epoch [2/50], Step [81/735], Loss: 2.1342\n",
      "Epoch [2/50], Step [82/735], Loss: 2.5927\n",
      "Epoch [2/50], Step [83/735], Loss: 2.7913\n",
      "Epoch [2/50], Step [84/735], Loss: 2.5351\n",
      "Epoch [2/50], Step [85/735], Loss: 2.9669\n",
      "Epoch [2/50], Step [86/735], Loss: 3.2721\n",
      "Epoch [2/50], Step [87/735], Loss: 2.6005\n",
      "Epoch [2/50], Step [88/735], Loss: 3.2142\n",
      "Epoch [2/50], Step [89/735], Loss: 2.7887\n",
      "Epoch [2/50], Step [90/735], Loss: 1.9629\n",
      "Epoch [2/50], Step [91/735], Loss: 3.9708\n",
      "Epoch [2/50], Step [92/735], Loss: 3.3514\n",
      "Epoch [2/50], Step [93/735], Loss: 2.0344\n",
      "Epoch [2/50], Step [94/735], Loss: 2.5170\n",
      "Epoch [2/50], Step [95/735], Loss: 4.3140\n",
      "Epoch [2/50], Step [96/735], Loss: 2.9699\n",
      "Epoch [2/50], Step [97/735], Loss: 4.3875\n",
      "Epoch [2/50], Step [98/735], Loss: 1.9272\n",
      "Epoch [2/50], Step [99/735], Loss: 2.4144\n",
      "Epoch [2/50], Step [100/735], Loss: 2.8142\n",
      "Epoch [2/50], Step [101/735], Loss: 3.5236\n",
      "Epoch [2/50], Step [102/735], Loss: 2.4137\n",
      "Epoch [2/50], Step [103/735], Loss: 2.9132\n",
      "Epoch [2/50], Step [104/735], Loss: 2.4133\n",
      "Epoch [2/50], Step [105/735], Loss: 2.7340\n",
      "Epoch [2/50], Step [106/735], Loss: 2.8600\n",
      "Epoch [2/50], Step [107/735], Loss: 2.2716\n",
      "Epoch [2/50], Step [108/735], Loss: 2.4583\n",
      "Epoch [2/50], Step [109/735], Loss: 2.0631\n",
      "Epoch [2/50], Step [110/735], Loss: 2.6842\n",
      "Epoch [2/50], Step [111/735], Loss: 2.2342\n",
      "Epoch [2/50], Step [112/735], Loss: 2.8386\n",
      "Epoch [2/50], Step [113/735], Loss: 2.6093\n",
      "Epoch [2/50], Step [114/735], Loss: 1.8754\n",
      "Epoch [2/50], Step [115/735], Loss: 2.2776\n",
      "Epoch [2/50], Step [116/735], Loss: 2.9781\n",
      "Epoch [2/50], Step [117/735], Loss: 3.3933\n",
      "Epoch [2/50], Step [118/735], Loss: 1.9736\n",
      "Epoch [2/50], Step [119/735], Loss: 1.9348\n",
      "Epoch [2/50], Step [120/735], Loss: 2.1151\n",
      "Epoch [2/50], Step [121/735], Loss: 1.9846\n",
      "Epoch [2/50], Step [122/735], Loss: 3.5381\n",
      "Epoch [2/50], Step [123/735], Loss: 2.3519\n",
      "Epoch [2/50], Step [124/735], Loss: 3.5514\n",
      "Epoch [2/50], Step [125/735], Loss: 2.3195\n",
      "Epoch [2/50], Step [126/735], Loss: 2.0016\n",
      "Epoch [2/50], Step [127/735], Loss: 2.0290\n",
      "Epoch [2/50], Step [128/735], Loss: 2.3250\n",
      "Epoch [2/50], Step [129/735], Loss: 2.8708\n",
      "Epoch [2/50], Step [130/735], Loss: 2.1384\n",
      "Epoch [2/50], Step [131/735], Loss: 4.5192\n",
      "Epoch [2/50], Step [132/735], Loss: 2.8159\n",
      "Epoch [2/50], Step [133/735], Loss: 5.9125\n",
      "Epoch [2/50], Step [134/735], Loss: 2.3826\n",
      "Epoch [2/50], Step [135/735], Loss: 2.7689\n",
      "Epoch [2/50], Step [136/735], Loss: 2.0845\n",
      "Epoch [2/50], Step [137/735], Loss: 2.2609\n",
      "Epoch [2/50], Step [138/735], Loss: 3.1585\n",
      "Epoch [2/50], Step [139/735], Loss: 2.9166\n",
      "Epoch [2/50], Step [140/735], Loss: 8.0207\n",
      "Epoch [2/50], Step [141/735], Loss: 2.6555\n",
      "Epoch [2/50], Step [142/735], Loss: 3.0719\n",
      "Epoch [2/50], Step [143/735], Loss: 2.0369\n",
      "Epoch [2/50], Step [144/735], Loss: 3.0888\n",
      "Epoch [2/50], Step [145/735], Loss: 3.3665\n",
      "Epoch [2/50], Step [146/735], Loss: 3.6547\n",
      "Epoch [2/50], Step [147/735], Loss: 2.5879\n",
      "Epoch [2/50], Step [148/735], Loss: 2.6025\n",
      "Epoch [2/50], Step [149/735], Loss: 1.8247\n",
      "Epoch [2/50], Step [150/735], Loss: 3.5035\n",
      "Epoch [2/50], Step [151/735], Loss: 1.7201\n",
      "Epoch [2/50], Step [152/735], Loss: 2.0504\n",
      "Epoch [2/50], Step [153/735], Loss: 1.7702\n",
      "Epoch [2/50], Step [154/735], Loss: 1.8644\n",
      "Epoch [2/50], Step [155/735], Loss: 1.9220\n",
      "Epoch [2/50], Step [156/735], Loss: 1.9678\n",
      "Epoch [2/50], Step [157/735], Loss: 1.5135\n",
      "Epoch [2/50], Step [158/735], Loss: 2.4830\n",
      "Epoch [2/50], Step [159/735], Loss: 4.0550\n",
      "Epoch [2/50], Step [160/735], Loss: 2.1438\n",
      "Epoch [2/50], Step [161/735], Loss: 2.9754\n",
      "Epoch [2/50], Step [162/735], Loss: 2.4143\n",
      "Epoch [2/50], Step [163/735], Loss: 4.1094\n",
      "Epoch [2/50], Step [164/735], Loss: 2.2910\n",
      "Epoch [2/50], Step [165/735], Loss: 2.5107\n",
      "Epoch [2/50], Step [166/735], Loss: 2.8440\n",
      "Epoch [2/50], Step [167/735], Loss: 2.3911\n",
      "Epoch [2/50], Step [168/735], Loss: 1.7567\n",
      "Epoch [2/50], Step [169/735], Loss: 2.0226\n",
      "Epoch [2/50], Step [170/735], Loss: 2.1140\n",
      "Epoch [2/50], Step [171/735], Loss: 2.5215\n",
      "Epoch [2/50], Step [172/735], Loss: 1.7979\n",
      "Epoch [2/50], Step [173/735], Loss: 1.4257\n",
      "Epoch [2/50], Step [174/735], Loss: 2.5479\n",
      "Epoch [2/50], Step [175/735], Loss: 2.7646\n",
      "Epoch [2/50], Step [176/735], Loss: 1.8187\n",
      "Epoch [2/50], Step [177/735], Loss: 2.5467\n",
      "Epoch [2/50], Step [178/735], Loss: 1.6541\n",
      "Epoch [2/50], Step [179/735], Loss: 1.5612\n",
      "Epoch [2/50], Step [180/735], Loss: 2.1429\n",
      "Epoch [2/50], Step [181/735], Loss: 1.9842\n",
      "Epoch [2/50], Step [182/735], Loss: 3.2358\n",
      "Epoch [2/50], Step [183/735], Loss: 3.8568\n",
      "Epoch [2/50], Step [184/735], Loss: 2.2509\n",
      "Epoch [2/50], Step [185/735], Loss: 1.9949\n",
      "Epoch [2/50], Step [186/735], Loss: 2.8904\n",
      "Epoch [2/50], Step [187/735], Loss: 2.3838\n",
      "Epoch [2/50], Step [188/735], Loss: 1.4760\n",
      "Epoch [2/50], Step [189/735], Loss: 1.9557\n",
      "Epoch [2/50], Step [190/735], Loss: 2.1598\n",
      "Epoch [2/50], Step [191/735], Loss: 2.2131\n",
      "Epoch [2/50], Step [192/735], Loss: 1.9142\n",
      "Epoch [2/50], Step [193/735], Loss: 2.5063\n",
      "Epoch [2/50], Step [194/735], Loss: 1.2982\n",
      "Epoch [2/50], Step [195/735], Loss: 1.8086\n",
      "Epoch [2/50], Step [196/735], Loss: 2.0924\n",
      "Epoch [2/50], Step [197/735], Loss: 1.7476\n",
      "Epoch [2/50], Step [198/735], Loss: 1.6187\n",
      "Epoch [2/50], Step [199/735], Loss: 2.6903\n",
      "Epoch [2/50], Step [200/735], Loss: 2.1580\n",
      "Epoch [2/50], Step [201/735], Loss: 2.1706\n",
      "Epoch [2/50], Step [202/735], Loss: 1.4300\n",
      "Epoch [2/50], Step [203/735], Loss: 1.9854\n",
      "Epoch [2/50], Step [204/735], Loss: 1.6268\n",
      "Epoch [2/50], Step [205/735], Loss: 2.0045\n",
      "Epoch [2/50], Step [206/735], Loss: 2.6016\n",
      "Epoch [2/50], Step [207/735], Loss: 3.3560\n",
      "Epoch [2/50], Step [208/735], Loss: 1.5569\n",
      "Epoch [2/50], Step [209/735], Loss: 1.9638\n",
      "Epoch [2/50], Step [210/735], Loss: 2.0620\n",
      "Epoch [2/50], Step [211/735], Loss: 2.6213\n",
      "Epoch [2/50], Step [212/735], Loss: 2.2274\n",
      "Epoch [2/50], Step [213/735], Loss: 1.4854\n",
      "Epoch [2/50], Step [214/735], Loss: 1.9550\n",
      "Epoch [2/50], Step [215/735], Loss: 2.4556\n",
      "Epoch [2/50], Step [216/735], Loss: 1.4300\n",
      "Epoch [2/50], Step [217/735], Loss: 2.0468\n",
      "Epoch [2/50], Step [218/735], Loss: 4.0417\n",
      "Epoch [2/50], Step [219/735], Loss: 1.9050\n",
      "Epoch [2/50], Step [220/735], Loss: 2.1578\n",
      "Epoch [2/50], Step [221/735], Loss: 1.5521\n",
      "Epoch [2/50], Step [222/735], Loss: 2.0844\n",
      "Epoch [2/50], Step [223/735], Loss: 5.8499\n",
      "Epoch [2/50], Step [224/735], Loss: 2.0417\n",
      "Epoch [2/50], Step [225/735], Loss: 1.7685\n",
      "Epoch [2/50], Step [226/735], Loss: 1.8988\n",
      "Epoch [2/50], Step [227/735], Loss: 1.3801\n",
      "Epoch [2/50], Step [228/735], Loss: 2.4759\n",
      "Epoch [2/50], Step [229/735], Loss: 1.7396\n",
      "Epoch [2/50], Step [230/735], Loss: 3.2500\n",
      "Epoch [2/50], Step [231/735], Loss: 2.9351\n",
      "Epoch [2/50], Step [232/735], Loss: 2.8485\n",
      "Epoch [2/50], Step [233/735], Loss: 3.8480\n",
      "Epoch [2/50], Step [234/735], Loss: 1.2699\n",
      "Epoch [2/50], Step [235/735], Loss: 2.2009\n",
      "Epoch [2/50], Step [236/735], Loss: 1.0721\n",
      "Epoch [2/50], Step [237/735], Loss: 1.9425\n",
      "Epoch [2/50], Step [238/735], Loss: 1.8551\n",
      "Epoch [2/50], Step [239/735], Loss: 1.3334\n",
      "Epoch [2/50], Step [240/735], Loss: 1.8233\n",
      "Epoch [2/50], Step [241/735], Loss: 1.5979\n",
      "Epoch [2/50], Step [242/735], Loss: 2.4814\n",
      "Epoch [2/50], Step [243/735], Loss: 2.5357\n",
      "Epoch [2/50], Step [244/735], Loss: 1.4243\n",
      "Epoch [2/50], Step [245/735], Loss: 1.6943\n",
      "Epoch [2/50], Step [246/735], Loss: 2.1304\n",
      "Epoch [2/50], Step [247/735], Loss: 2.9497\n",
      "Epoch [2/50], Step [248/735], Loss: 2.7002\n",
      "Epoch [2/50], Step [249/735], Loss: 2.2896\n",
      "Epoch [2/50], Step [250/735], Loss: 1.3871\n",
      "Epoch [2/50], Step [251/735], Loss: 1.6558\n",
      "Epoch [2/50], Step [252/735], Loss: 1.1175\n",
      "Epoch [2/50], Step [253/735], Loss: 2.1084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Step [254/735], Loss: 1.5118\n",
      "Epoch [2/50], Step [255/735], Loss: 2.5394\n",
      "Epoch [2/50], Step [256/735], Loss: 7.9725\n",
      "Epoch [2/50], Step [257/735], Loss: 2.6612\n",
      "Epoch [2/50], Step [258/735], Loss: 1.3710\n",
      "Epoch [2/50], Step [259/735], Loss: 1.2406\n",
      "Epoch [2/50], Step [260/735], Loss: 2.0112\n",
      "Epoch [2/50], Step [261/735], Loss: 1.7846\n",
      "Epoch [2/50], Step [262/735], Loss: 1.7775\n",
      "Epoch [2/50], Step [263/735], Loss: 2.4635\n",
      "Epoch [2/50], Step [264/735], Loss: 1.6492\n",
      "Epoch [2/50], Step [265/735], Loss: 4.5329\n",
      "Epoch [2/50], Step [266/735], Loss: 1.5199\n",
      "Epoch [2/50], Step [267/735], Loss: 2.1455\n",
      "Epoch [2/50], Step [268/735], Loss: 2.2936\n",
      "Epoch [2/50], Step [269/735], Loss: 1.6967\n",
      "Epoch [2/50], Step [270/735], Loss: 2.0442\n",
      "Epoch [2/50], Step [271/735], Loss: 1.9008\n",
      "Epoch [2/50], Step [272/735], Loss: 1.6164\n",
      "Epoch [2/50], Step [273/735], Loss: 1.8225\n",
      "Epoch [2/50], Step [274/735], Loss: 1.8823\n",
      "Epoch [2/50], Step [275/735], Loss: 1.6507\n",
      "Epoch [2/50], Step [276/735], Loss: 2.0866\n",
      "Epoch [2/50], Step [277/735], Loss: 1.8451\n",
      "Epoch [2/50], Step [278/735], Loss: 1.5424\n",
      "Epoch [2/50], Step [279/735], Loss: 1.4379\n",
      "Epoch [2/50], Step [280/735], Loss: 2.1345\n",
      "Epoch [2/50], Step [281/735], Loss: 2.0263\n",
      "Epoch [2/50], Step [282/735], Loss: 1.5421\n",
      "Epoch [2/50], Step [283/735], Loss: 1.4753\n",
      "Epoch [2/50], Step [284/735], Loss: 2.1802\n",
      "Epoch [2/50], Step [285/735], Loss: 1.2083\n",
      "Epoch [2/50], Step [286/735], Loss: 1.2936\n",
      "Epoch [2/50], Step [287/735], Loss: 2.5388\n",
      "Epoch [2/50], Step [288/735], Loss: 1.2139\n",
      "Epoch [2/50], Step [289/735], Loss: 1.3040\n",
      "Epoch [2/50], Step [290/735], Loss: 2.0579\n",
      "Epoch [2/50], Step [291/735], Loss: 2.7479\n",
      "Epoch [2/50], Step [292/735], Loss: 2.5620\n",
      "Epoch [2/50], Step [293/735], Loss: 2.6114\n",
      "Epoch [2/50], Step [294/735], Loss: 1.6320\n",
      "Epoch [2/50], Step [295/735], Loss: 1.4884\n",
      "Epoch [2/50], Step [296/735], Loss: 1.2476\n",
      "Epoch [2/50], Step [297/735], Loss: 1.9102\n",
      "Epoch [2/50], Step [298/735], Loss: 1.2083\n",
      "Epoch [2/50], Step [299/735], Loss: 1.6450\n",
      "Epoch [2/50], Step [300/735], Loss: 1.1736\n",
      "Epoch [2/50], Step [301/735], Loss: 1.2530\n",
      "Epoch [2/50], Step [302/735], Loss: 1.6322\n",
      "Epoch [2/50], Step [303/735], Loss: 1.8932\n",
      "Epoch [2/50], Step [304/735], Loss: 1.3266\n",
      "Epoch [2/50], Step [305/735], Loss: 2.5699\n",
      "Epoch [2/50], Step [306/735], Loss: 2.3905\n",
      "Epoch [2/50], Step [307/735], Loss: 2.2221\n",
      "Epoch [2/50], Step [308/735], Loss: 1.1930\n",
      "Epoch [2/50], Step [309/735], Loss: 1.1496\n",
      "Epoch [2/50], Step [310/735], Loss: 1.7626\n",
      "Epoch [2/50], Step [311/735], Loss: 1.6054\n",
      "Epoch [2/50], Step [312/735], Loss: 1.3107\n",
      "Epoch [2/50], Step [313/735], Loss: 0.8921\n",
      "Epoch [2/50], Step [314/735], Loss: 1.6856\n",
      "Epoch [2/50], Step [315/735], Loss: 1.0301\n",
      "Epoch [2/50], Step [316/735], Loss: 1.0262\n",
      "Epoch [2/50], Step [317/735], Loss: 1.3483\n",
      "Epoch [2/50], Step [318/735], Loss: 2.6284\n",
      "Epoch [2/50], Step [319/735], Loss: 1.1694\n",
      "Epoch [2/50], Step [320/735], Loss: 3.0504\n",
      "Epoch [2/50], Step [321/735], Loss: 2.8391\n",
      "Epoch [2/50], Step [322/735], Loss: 2.1697\n",
      "Epoch [2/50], Step [323/735], Loss: 1.1708\n",
      "Epoch [2/50], Step [324/735], Loss: 1.8773\n",
      "Epoch [2/50], Step [325/735], Loss: 1.5914\n",
      "Epoch [2/50], Step [326/735], Loss: 2.5238\n",
      "Epoch [2/50], Step [327/735], Loss: 2.3259\n",
      "Epoch [2/50], Step [328/735], Loss: 2.7540\n",
      "Epoch [2/50], Step [329/735], Loss: 1.5973\n",
      "Epoch [2/50], Step [330/735], Loss: 1.7531\n",
      "Epoch [2/50], Step [331/735], Loss: 1.5126\n",
      "Epoch [2/50], Step [332/735], Loss: 1.3054\n",
      "Epoch [2/50], Step [333/735], Loss: 1.2220\n",
      "Epoch [2/50], Step [334/735], Loss: 1.9331\n",
      "Epoch [2/50], Step [335/735], Loss: 1.9193\n",
      "Epoch [2/50], Step [336/735], Loss: 1.4285\n",
      "Epoch [2/50], Step [337/735], Loss: 1.3379\n",
      "Epoch [2/50], Step [338/735], Loss: 1.6235\n",
      "Epoch [2/50], Step [339/735], Loss: 1.2473\n",
      "Epoch [2/50], Step [340/735], Loss: 1.7620\n",
      "Epoch [2/50], Step [341/735], Loss: 1.7456\n",
      "Epoch [2/50], Step [342/735], Loss: 1.9754\n",
      "Epoch [2/50], Step [343/735], Loss: 1.2437\n",
      "Epoch [2/50], Step [344/735], Loss: 1.0811\n",
      "Epoch [2/50], Step [345/735], Loss: 1.4725\n",
      "Epoch [2/50], Step [346/735], Loss: 1.3123\n",
      "Epoch [2/50], Step [347/735], Loss: 2.3549\n",
      "Epoch [2/50], Step [348/735], Loss: 1.4259\n",
      "Epoch [2/50], Step [349/735], Loss: 1.4081\n",
      "Epoch [2/50], Step [350/735], Loss: 0.7880\n",
      "Epoch [2/50], Step [351/735], Loss: 1.2151\n",
      "Epoch [2/50], Step [352/735], Loss: 2.8273\n",
      "Epoch [2/50], Step [353/735], Loss: 1.4003\n",
      "Epoch [2/50], Step [354/735], Loss: 1.8350\n",
      "Epoch [2/50], Step [355/735], Loss: 1.3224\n",
      "Epoch [2/50], Step [356/735], Loss: 1.2732\n",
      "Epoch [2/50], Step [357/735], Loss: 1.9438\n",
      "Epoch [2/50], Step [358/735], Loss: 1.4803\n",
      "Epoch [2/50], Step [359/735], Loss: 0.9397\n",
      "Epoch [2/50], Step [360/735], Loss: 1.8032\n",
      "Epoch [2/50], Step [361/735], Loss: 1.4235\n",
      "Epoch [2/50], Step [362/735], Loss: 1.3689\n",
      "Epoch [2/50], Step [363/735], Loss: 2.4135\n",
      "Epoch [2/50], Step [364/735], Loss: 2.5168\n",
      "Epoch [2/50], Step [365/735], Loss: 1.9859\n",
      "Epoch [2/50], Step [366/735], Loss: 1.5492\n",
      "Epoch [2/50], Step [367/735], Loss: 1.0427\n",
      "Epoch [2/50], Step [368/735], Loss: 1.0400\n",
      "Epoch [2/50], Step [369/735], Loss: 2.1191\n",
      "Epoch [2/50], Step [370/735], Loss: 1.1207\n",
      "Epoch [2/50], Step [371/735], Loss: 1.1580\n",
      "Epoch [2/50], Step [372/735], Loss: 0.8777\n",
      "Epoch [2/50], Step [373/735], Loss: 0.9490\n",
      "Epoch [2/50], Step [374/735], Loss: 1.8327\n",
      "Epoch [2/50], Step [375/735], Loss: 2.1492\n",
      "Epoch [2/50], Step [376/735], Loss: 1.3899\n",
      "Epoch [2/50], Step [377/735], Loss: 1.1174\n",
      "Epoch [2/50], Step [378/735], Loss: 1.6776\n",
      "Epoch [2/50], Step [379/735], Loss: 1.4455\n",
      "Epoch [2/50], Step [380/735], Loss: 1.1225\n",
      "Epoch [2/50], Step [381/735], Loss: 1.8613\n",
      "Epoch [2/50], Step [382/735], Loss: 4.7511\n",
      "Epoch [2/50], Step [383/735], Loss: 1.5438\n",
      "Epoch [2/50], Step [384/735], Loss: 1.4088\n",
      "Epoch [2/50], Step [385/735], Loss: 1.6934\n",
      "Epoch [2/50], Step [386/735], Loss: 0.9979\n",
      "Epoch [2/50], Step [387/735], Loss: 1.6266\n",
      "Epoch [2/50], Step [388/735], Loss: 4.0664\n",
      "Epoch [2/50], Step [389/735], Loss: 0.9469\n",
      "Epoch [2/50], Step [390/735], Loss: 1.4850\n",
      "Epoch [2/50], Step [391/735], Loss: 1.0247\n",
      "Epoch [2/50], Step [392/735], Loss: 1.8093\n",
      "Epoch [2/50], Step [393/735], Loss: 1.0968\n",
      "Epoch [2/50], Step [394/735], Loss: 2.2102\n",
      "Epoch [2/50], Step [395/735], Loss: 0.8867\n",
      "Epoch [2/50], Step [396/735], Loss: 0.8659\n",
      "Epoch [2/50], Step [397/735], Loss: 2.0647\n",
      "Epoch [2/50], Step [398/735], Loss: 2.0829\n",
      "Epoch [2/50], Step [399/735], Loss: 1.0238\n",
      "Epoch [2/50], Step [400/735], Loss: 1.2162\n",
      "Epoch [2/50], Step [401/735], Loss: 1.2904\n",
      "Epoch [2/50], Step [402/735], Loss: 1.4043\n",
      "Epoch [2/50], Step [403/735], Loss: 2.0532\n",
      "Epoch [2/50], Step [404/735], Loss: 0.9793\n",
      "Epoch [2/50], Step [405/735], Loss: 3.3605\n",
      "Epoch [2/50], Step [406/735], Loss: 1.3868\n",
      "Epoch [2/50], Step [407/735], Loss: 2.0879\n",
      "Epoch [2/50], Step [408/735], Loss: 2.6092\n",
      "Epoch [2/50], Step [409/735], Loss: 1.7413\n",
      "Epoch [2/50], Step [410/735], Loss: 4.1308\n",
      "Epoch [2/50], Step [411/735], Loss: 0.6677\n",
      "Epoch [2/50], Step [412/735], Loss: 1.8728\n",
      "Epoch [2/50], Step [413/735], Loss: 1.1062\n",
      "Epoch [2/50], Step [414/735], Loss: 1.2689\n",
      "Epoch [2/50], Step [415/735], Loss: 0.9942\n",
      "Epoch [2/50], Step [416/735], Loss: 1.5298\n",
      "Epoch [2/50], Step [417/735], Loss: 1.2814\n",
      "Epoch [2/50], Step [418/735], Loss: 1.2433\n",
      "Epoch [2/50], Step [419/735], Loss: 2.0547\n",
      "Epoch [2/50], Step [420/735], Loss: 2.8043\n",
      "Epoch [2/50], Step [421/735], Loss: 1.6733\n",
      "Epoch [2/50], Step [422/735], Loss: 1.0654\n",
      "Epoch [2/50], Step [423/735], Loss: 1.3309\n",
      "Epoch [2/50], Step [424/735], Loss: 1.8387\n",
      "Epoch [2/50], Step [425/735], Loss: 2.4017\n",
      "Epoch [2/50], Step [426/735], Loss: 1.1517\n",
      "Epoch [2/50], Step [427/735], Loss: 1.0144\n",
      "Epoch [2/50], Step [428/735], Loss: 1.4333\n",
      "Epoch [2/50], Step [429/735], Loss: 1.0636\n",
      "Epoch [2/50], Step [430/735], Loss: 1.2395\n",
      "Epoch [2/50], Step [431/735], Loss: 0.9006\n",
      "Epoch [2/50], Step [432/735], Loss: 1.6244\n",
      "Epoch [2/50], Step [433/735], Loss: 1.3635\n",
      "Epoch [2/50], Step [434/735], Loss: 1.5638\n",
      "Epoch [2/50], Step [435/735], Loss: 5.9861\n",
      "Epoch [2/50], Step [436/735], Loss: 1.4471\n",
      "Epoch [2/50], Step [437/735], Loss: 0.9294\n",
      "Epoch [2/50], Step [438/735], Loss: 1.8453\n",
      "Epoch [2/50], Step [439/735], Loss: 1.3696\n",
      "Epoch [2/50], Step [440/735], Loss: 1.0683\n",
      "Epoch [2/50], Step [441/735], Loss: 3.9315\n",
      "Epoch [2/50], Step [442/735], Loss: 1.9320\n",
      "Epoch [2/50], Step [443/735], Loss: 6.9408\n",
      "Epoch [2/50], Step [444/735], Loss: 0.7827\n",
      "Epoch [2/50], Step [445/735], Loss: 0.6521\n",
      "Epoch [2/50], Step [446/735], Loss: 1.0361\n",
      "Epoch [2/50], Step [447/735], Loss: 2.8509\n",
      "Epoch [2/50], Step [448/735], Loss: 2.6043\n",
      "Epoch [2/50], Step [449/735], Loss: 1.2609\n",
      "Epoch [2/50], Step [450/735], Loss: 1.8762\n",
      "Epoch [2/50], Step [451/735], Loss: 1.2695\n",
      "Epoch [2/50], Step [452/735], Loss: 1.2618\n",
      "Epoch [2/50], Step [453/735], Loss: 1.4468\n",
      "Epoch [2/50], Step [454/735], Loss: 1.3512\n",
      "Epoch [2/50], Step [455/735], Loss: 1.0683\n",
      "Epoch [2/50], Step [456/735], Loss: 1.8270\n",
      "Epoch [2/50], Step [457/735], Loss: 0.8944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Step [458/735], Loss: 0.7492\n",
      "Epoch [2/50], Step [459/735], Loss: 1.3506\n",
      "Epoch [2/50], Step [460/735], Loss: 0.9913\n",
      "Epoch [2/50], Step [461/735], Loss: 0.9662\n",
      "Epoch [2/50], Step [462/735], Loss: 1.4548\n",
      "Epoch [2/50], Step [463/735], Loss: 0.7168\n",
      "Epoch [2/50], Step [464/735], Loss: 1.2122\n",
      "Epoch [2/50], Step [465/735], Loss: 0.7508\n",
      "Epoch [2/50], Step [466/735], Loss: 1.0305\n",
      "Epoch [2/50], Step [467/735], Loss: 1.3538\n",
      "Epoch [2/50], Step [468/735], Loss: 0.9559\n",
      "Epoch [2/50], Step [469/735], Loss: 1.6418\n",
      "Epoch [2/50], Step [470/735], Loss: 1.3872\n",
      "Epoch [2/50], Step [471/735], Loss: 1.4857\n",
      "Epoch [2/50], Step [472/735], Loss: 1.6891\n",
      "Epoch [2/50], Step [473/735], Loss: 1.5200\n",
      "Epoch [2/50], Step [474/735], Loss: 0.8482\n",
      "Epoch [2/50], Step [475/735], Loss: 1.9498\n",
      "Epoch [2/50], Step [476/735], Loss: 2.4794\n",
      "Epoch [2/50], Step [477/735], Loss: 1.4110\n",
      "Epoch [2/50], Step [478/735], Loss: 1.9189\n",
      "Epoch [2/50], Step [479/735], Loss: 1.3614\n",
      "Epoch [2/50], Step [480/735], Loss: 1.0311\n",
      "Epoch [2/50], Step [481/735], Loss: 1.0577\n",
      "Epoch [2/50], Step [482/735], Loss: 0.8625\n",
      "Epoch [2/50], Step [483/735], Loss: 0.9071\n",
      "Epoch [2/50], Step [484/735], Loss: 1.4695\n",
      "Epoch [2/50], Step [485/735], Loss: 2.0567\n",
      "Epoch [2/50], Step [486/735], Loss: 1.6498\n",
      "Epoch [2/50], Step [487/735], Loss: 1.2783\n",
      "Epoch [2/50], Step [488/735], Loss: 0.9577\n",
      "Epoch [2/50], Step [489/735], Loss: 1.2006\n",
      "Epoch [2/50], Step [490/735], Loss: 0.8946\n",
      "Epoch [2/50], Step [491/735], Loss: 1.3361\n",
      "Epoch [2/50], Step [492/735], Loss: 0.9842\n",
      "Epoch [2/50], Step [493/735], Loss: 2.4760\n",
      "Epoch [2/50], Step [494/735], Loss: 2.6156\n",
      "Epoch [2/50], Step [495/735], Loss: 0.7113\n",
      "Epoch [2/50], Step [496/735], Loss: 2.0890\n",
      "Epoch [2/50], Step [497/735], Loss: 1.6957\n",
      "Epoch [2/50], Step [498/735], Loss: 1.1841\n",
      "Epoch [2/50], Step [499/735], Loss: 0.9720\n",
      "Epoch [2/50], Step [500/735], Loss: 0.7627\n",
      "Epoch [2/50], Step [501/735], Loss: 0.7526\n",
      "Epoch [2/50], Step [502/735], Loss: 0.9185\n",
      "Epoch [2/50], Step [503/735], Loss: 1.1265\n",
      "Epoch [2/50], Step [504/735], Loss: 1.6870\n",
      "Epoch [2/50], Step [505/735], Loss: 1.4828\n",
      "Epoch [2/50], Step [506/735], Loss: 0.9146\n",
      "Epoch [2/50], Step [507/735], Loss: 2.0889\n",
      "Epoch [2/50], Step [508/735], Loss: 1.3428\n",
      "Epoch [2/50], Step [509/735], Loss: 1.4016\n",
      "Epoch [2/50], Step [510/735], Loss: 1.9546\n",
      "Epoch [2/50], Step [511/735], Loss: 1.3198\n",
      "Epoch [2/50], Step [512/735], Loss: 1.2700\n",
      "Epoch [2/50], Step [513/735], Loss: 1.1562\n",
      "Epoch [2/50], Step [514/735], Loss: 0.9450\n",
      "Epoch [2/50], Step [515/735], Loss: 1.6033\n",
      "Epoch [2/50], Step [516/735], Loss: 0.9402\n",
      "Epoch [2/50], Step [517/735], Loss: 0.9654\n",
      "Epoch [2/50], Step [518/735], Loss: 1.3809\n",
      "Epoch [2/50], Step [519/735], Loss: 0.6150\n",
      "Epoch [2/50], Step [520/735], Loss: 1.5923\n",
      "Epoch [2/50], Step [521/735], Loss: 1.2621\n",
      "Epoch [2/50], Step [522/735], Loss: 1.1172\n",
      "Epoch [2/50], Step [523/735], Loss: 1.4099\n",
      "Epoch [2/50], Step [524/735], Loss: 1.0931\n",
      "Epoch [2/50], Step [525/735], Loss: 0.7859\n",
      "Epoch [2/50], Step [526/735], Loss: 0.8658\n",
      "Epoch [2/50], Step [527/735], Loss: 0.9322\n",
      "Epoch [2/50], Step [528/735], Loss: 4.0996\n",
      "Epoch [2/50], Step [529/735], Loss: 0.9658\n",
      "Epoch [2/50], Step [530/735], Loss: 1.1283\n",
      "Epoch [2/50], Step [531/735], Loss: 0.9759\n",
      "Epoch [2/50], Step [532/735], Loss: 0.9512\n",
      "Epoch [2/50], Step [533/735], Loss: 1.1924\n",
      "Epoch [2/50], Step [534/735], Loss: 1.5933\n",
      "Epoch [2/50], Step [535/735], Loss: 1.0485\n",
      "Epoch [2/50], Step [536/735], Loss: 0.9458\n",
      "Epoch [2/50], Step [537/735], Loss: 2.3262\n",
      "Epoch [2/50], Step [538/735], Loss: 3.2598\n",
      "Epoch [2/50], Step [539/735], Loss: 1.3350\n",
      "Epoch [2/50], Step [540/735], Loss: 1.1760\n",
      "Epoch [2/50], Step [541/735], Loss: 0.9514\n",
      "Epoch [2/50], Step [542/735], Loss: 1.6376\n",
      "Epoch [2/50], Step [543/735], Loss: 3.7813\n",
      "Epoch [2/50], Step [544/735], Loss: 0.7231\n",
      "Epoch [2/50], Step [545/735], Loss: 0.9423\n",
      "Epoch [2/50], Step [546/735], Loss: 0.9637\n",
      "Epoch [2/50], Step [547/735], Loss: 0.6668\n",
      "Epoch [2/50], Step [548/735], Loss: 1.1914\n",
      "Epoch [2/50], Step [549/735], Loss: 1.4056\n",
      "Epoch [2/50], Step [550/735], Loss: 1.0520\n",
      "Epoch [2/50], Step [551/735], Loss: 1.1820\n",
      "Epoch [2/50], Step [552/735], Loss: 1.1202\n",
      "Epoch [2/50], Step [553/735], Loss: 0.7437\n",
      "Epoch [2/50], Step [554/735], Loss: 1.2313\n",
      "Epoch [2/50], Step [555/735], Loss: 1.0003\n",
      "Epoch [2/50], Step [556/735], Loss: 0.5791\n",
      "Epoch [2/50], Step [557/735], Loss: 1.5041\n",
      "Epoch [2/50], Step [558/735], Loss: 1.1943\n",
      "Epoch [2/50], Step [559/735], Loss: 1.0235\n",
      "Epoch [2/50], Step [560/735], Loss: 1.6169\n",
      "Epoch [2/50], Step [561/735], Loss: 4.1328\n",
      "Epoch [2/50], Step [562/735], Loss: 1.4607\n",
      "Epoch [2/50], Step [563/735], Loss: 2.4404\n",
      "Epoch [2/50], Step [564/735], Loss: 1.8522\n",
      "Epoch [2/50], Step [565/735], Loss: 0.5000\n",
      "Epoch [2/50], Step [566/735], Loss: 1.2032\n",
      "Epoch [2/50], Step [567/735], Loss: 1.3244\n",
      "Epoch [2/50], Step [568/735], Loss: 0.7139\n",
      "Epoch [2/50], Step [569/735], Loss: 0.7587\n",
      "Epoch [2/50], Step [570/735], Loss: 1.3835\n",
      "Epoch [2/50], Step [571/735], Loss: 2.1306\n",
      "Epoch [2/50], Step [572/735], Loss: 2.1634\n",
      "Epoch [2/50], Step [573/735], Loss: 0.8313\n",
      "Epoch [2/50], Step [574/735], Loss: 0.9984\n",
      "Epoch [2/50], Step [575/735], Loss: 0.8277\n",
      "Epoch [2/50], Step [576/735], Loss: 2.2830\n",
      "Epoch [2/50], Step [577/735], Loss: 1.0126\n",
      "Epoch [2/50], Step [578/735], Loss: 1.1506\n",
      "Epoch [2/50], Step [579/735], Loss: 0.6854\n",
      "Epoch [2/50], Step [580/735], Loss: 0.5747\n",
      "Epoch [2/50], Step [581/735], Loss: 1.1374\n",
      "Epoch [2/50], Step [582/735], Loss: 1.1869\n",
      "Epoch [2/50], Step [583/735], Loss: 1.6840\n",
      "Epoch [2/50], Step [584/735], Loss: 1.2317\n",
      "Epoch [2/50], Step [585/735], Loss: 1.1062\n",
      "Epoch [2/50], Step [586/735], Loss: 1.0851\n",
      "Epoch [2/50], Step [587/735], Loss: 0.7127\n",
      "Epoch [2/50], Step [588/735], Loss: 0.6858\n",
      "Epoch [2/50], Step [589/735], Loss: 0.7799\n",
      "Epoch [2/50], Step [590/735], Loss: 1.3118\n",
      "Epoch [2/50], Step [591/735], Loss: 0.8411\n",
      "Epoch [2/50], Step [592/735], Loss: 0.6733\n",
      "Epoch [2/50], Step [593/735], Loss: 0.6345\n",
      "Epoch [2/50], Step [594/735], Loss: 0.7357\n",
      "Epoch [2/50], Step [595/735], Loss: 0.7938\n",
      "Epoch [2/50], Step [596/735], Loss: 0.6435\n",
      "Epoch [2/50], Step [597/735], Loss: 1.0009\n",
      "Epoch [2/50], Step [598/735], Loss: 0.8030\n",
      "Epoch [2/50], Step [599/735], Loss: 0.8559\n",
      "Epoch [2/50], Step [600/735], Loss: 0.6749\n",
      "Epoch [2/50], Step [601/735], Loss: 1.1039\n",
      "Epoch [2/50], Step [602/735], Loss: 1.5075\n",
      "Epoch [2/50], Step [603/735], Loss: 1.7928\n",
      "Epoch [2/50], Step [604/735], Loss: 0.9288\n",
      "Epoch [2/50], Step [605/735], Loss: 0.7123\n",
      "Epoch [2/50], Step [606/735], Loss: 1.2132\n",
      "Epoch [2/50], Step [607/735], Loss: 1.2188\n",
      "Epoch [2/50], Step [608/735], Loss: 0.9458\n",
      "Epoch [2/50], Step [609/735], Loss: 0.8127\n",
      "Epoch [2/50], Step [610/735], Loss: 0.6213\n",
      "Epoch [2/50], Step [611/735], Loss: 1.1559\n",
      "Epoch [2/50], Step [612/735], Loss: 1.3922\n",
      "Epoch [2/50], Step [613/735], Loss: 2.2173\n",
      "Epoch [2/50], Step [614/735], Loss: 1.0076\n",
      "Epoch [2/50], Step [615/735], Loss: 2.6420\n",
      "Epoch [2/50], Step [616/735], Loss: 1.7701\n",
      "Epoch [2/50], Step [617/735], Loss: 2.0896\n",
      "Epoch [2/50], Step [618/735], Loss: 0.8584\n",
      "Epoch [2/50], Step [619/735], Loss: 1.2375\n",
      "Epoch [2/50], Step [620/735], Loss: 0.6762\n",
      "Epoch [2/50], Step [621/735], Loss: 2.5428\n",
      "Epoch [2/50], Step [622/735], Loss: 0.9990\n",
      "Epoch [2/50], Step [623/735], Loss: 0.9526\n",
      "Epoch [2/50], Step [624/735], Loss: 1.1254\n",
      "Epoch [2/50], Step [625/735], Loss: 0.6421\n",
      "Epoch [2/50], Step [626/735], Loss: 0.8817\n",
      "Epoch [2/50], Step [627/735], Loss: 1.8300\n",
      "Epoch [2/50], Step [628/735], Loss: 0.5446\n",
      "Epoch [2/50], Step [629/735], Loss: 0.9485\n",
      "Epoch [2/50], Step [630/735], Loss: 1.0375\n",
      "Epoch [2/50], Step [631/735], Loss: 1.9781\n",
      "Epoch [2/50], Step [632/735], Loss: 2.3910\n",
      "Epoch [2/50], Step [633/735], Loss: 0.8554\n",
      "Epoch [2/50], Step [634/735], Loss: 0.7277\n",
      "Epoch [2/50], Step [635/735], Loss: 1.5775\n",
      "Epoch [2/50], Step [636/735], Loss: 0.8815\n",
      "Epoch [2/50], Step [637/735], Loss: 0.9075\n",
      "Epoch [2/50], Step [638/735], Loss: 1.1366\n",
      "Epoch [2/50], Step [639/735], Loss: 1.3470\n",
      "Epoch [2/50], Step [640/735], Loss: 0.8742\n",
      "Epoch [2/50], Step [641/735], Loss: 0.8004\n",
      "Epoch [2/50], Step [642/735], Loss: 0.9912\n",
      "Epoch [2/50], Step [643/735], Loss: 0.6146\n",
      "Epoch [2/50], Step [644/735], Loss: 1.2771\n",
      "Epoch [2/50], Step [645/735], Loss: 0.9263\n",
      "Epoch [2/50], Step [646/735], Loss: 3.7556\n",
      "Epoch [2/50], Step [647/735], Loss: 1.3250\n",
      "Epoch [2/50], Step [648/735], Loss: 1.0052\n",
      "Epoch [2/50], Step [649/735], Loss: 6.2972\n",
      "Epoch [2/50], Step [650/735], Loss: 0.6688\n",
      "Epoch [2/50], Step [651/735], Loss: 2.0016\n",
      "Epoch [2/50], Step [652/735], Loss: 1.5231\n",
      "Epoch [2/50], Step [653/735], Loss: 1.4258\n",
      "Epoch [2/50], Step [654/735], Loss: 2.3498\n",
      "Epoch [2/50], Step [655/735], Loss: 0.5847\n",
      "Epoch [2/50], Step [656/735], Loss: 1.0071\n",
      "Epoch [2/50], Step [657/735], Loss: 0.9260\n",
      "Epoch [2/50], Step [658/735], Loss: 1.8436\n",
      "Epoch [2/50], Step [659/735], Loss: 1.0479\n",
      "Epoch [2/50], Step [660/735], Loss: 1.6624\n",
      "Epoch [2/50], Step [661/735], Loss: 0.6848\n",
      "Epoch [2/50], Step [662/735], Loss: 2.0339\n",
      "Epoch [2/50], Step [663/735], Loss: 1.7863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Step [664/735], Loss: 1.4044\n",
      "Epoch [2/50], Step [665/735], Loss: 1.2387\n",
      "Epoch [2/50], Step [666/735], Loss: 1.3291\n",
      "Epoch [2/50], Step [667/735], Loss: 0.9719\n",
      "Epoch [2/50], Step [668/735], Loss: 0.8890\n",
      "Epoch [2/50], Step [669/735], Loss: 0.4742\n",
      "Epoch [2/50], Step [670/735], Loss: 0.7185\n",
      "Epoch [2/50], Step [671/735], Loss: 0.8016\n",
      "Epoch [2/50], Step [672/735], Loss: 1.2530\n",
      "Epoch [2/50], Step [673/735], Loss: 0.6350\n",
      "Epoch [2/50], Step [674/735], Loss: 1.7829\n",
      "Epoch [2/50], Step [675/735], Loss: 1.4239\n",
      "Epoch [2/50], Step [676/735], Loss: 1.2370\n",
      "Epoch [2/50], Step [677/735], Loss: 0.8508\n",
      "Epoch [2/50], Step [678/735], Loss: 0.7068\n",
      "Epoch [2/50], Step [679/735], Loss: 1.0493\n",
      "Epoch [2/50], Step [680/735], Loss: 0.8449\n",
      "Epoch [2/50], Step [681/735], Loss: 0.9825\n",
      "Epoch [2/50], Step [682/735], Loss: 1.1594\n",
      "Epoch [2/50], Step [683/735], Loss: 1.1758\n",
      "Epoch [2/50], Step [684/735], Loss: 0.7941\n",
      "Epoch [2/50], Step [685/735], Loss: 1.0227\n",
      "Epoch [2/50], Step [686/735], Loss: 0.8800\n",
      "Epoch [2/50], Step [687/735], Loss: 1.1751\n",
      "Epoch [2/50], Step [688/735], Loss: 0.8959\n",
      "Epoch [2/50], Step [689/735], Loss: 0.6129\n",
      "Epoch [2/50], Step [690/735], Loss: 1.6883\n",
      "Epoch [2/50], Step [691/735], Loss: 1.2548\n",
      "Epoch [2/50], Step [692/735], Loss: 0.8512\n",
      "Epoch [2/50], Step [693/735], Loss: 0.7092\n",
      "Epoch [2/50], Step [694/735], Loss: 0.9418\n",
      "Epoch [2/50], Step [695/735], Loss: 0.5296\n",
      "Epoch [2/50], Step [696/735], Loss: 4.0148\n",
      "Epoch [2/50], Step [697/735], Loss: 1.0881\n",
      "Epoch [2/50], Step [698/735], Loss: 0.5108\n",
      "Epoch [2/50], Step [699/735], Loss: 0.8185\n",
      "Epoch [2/50], Step [700/735], Loss: 1.7415\n",
      "Epoch [2/50], Step [701/735], Loss: 0.6684\n",
      "Epoch [2/50], Step [702/735], Loss: 0.8908\n",
      "Epoch [2/50], Step [703/735], Loss: 0.7856\n",
      "Epoch [2/50], Step [704/735], Loss: 0.5440\n",
      "Epoch [2/50], Step [705/735], Loss: 1.6262\n",
      "Epoch [2/50], Step [706/735], Loss: 1.7878\n",
      "Epoch [2/50], Step [707/735], Loss: 1.2424\n",
      "Epoch [2/50], Step [708/735], Loss: 0.6592\n",
      "Epoch [2/50], Step [709/735], Loss: 1.2585\n",
      "Epoch [2/50], Step [710/735], Loss: 1.3053\n",
      "Epoch [2/50], Step [711/735], Loss: 3.6157\n",
      "Epoch [2/50], Step [712/735], Loss: 0.7763\n",
      "Epoch [2/50], Step [713/735], Loss: 1.4283\n",
      "Epoch [2/50], Step [714/735], Loss: 0.5348\n",
      "Epoch [2/50], Step [715/735], Loss: 0.5739\n",
      "Epoch [2/50], Step [716/735], Loss: 0.6019\n",
      "Epoch [2/50], Step [717/735], Loss: 1.0018\n",
      "Epoch [2/50], Step [718/735], Loss: 0.5138\n",
      "Epoch [2/50], Step [719/735], Loss: 1.4613\n",
      "Epoch [2/50], Step [720/735], Loss: 0.7600\n",
      "Epoch [2/50], Step [721/735], Loss: 0.6619\n",
      "Epoch [2/50], Step [722/735], Loss: 1.0228\n",
      "Epoch [2/50], Step [723/735], Loss: 0.5723\n",
      "Epoch [2/50], Step [724/735], Loss: 0.6009\n",
      "Epoch [2/50], Step [725/735], Loss: 0.4986\n",
      "Epoch [2/50], Step [726/735], Loss: 1.4253\n",
      "Epoch [2/50], Step [727/735], Loss: 0.5110\n",
      "Epoch [2/50], Step [728/735], Loss: 1.4097\n",
      "Epoch [2/50], Step [729/735], Loss: 0.9956\n",
      "Epoch [2/50], Step [730/735], Loss: 0.6924\n",
      "Epoch [2/50], Step [731/735], Loss: 0.4542\n",
      "Epoch [2/50], Step [732/735], Loss: 0.7877\n",
      "Epoch [2/50], Step [733/735], Loss: 0.9758\n",
      "Epoch [2/50], Step [734/735], Loss: 1.3404\n",
      "Epoch [2/50], Step [735/735], Loss: 0.7839\n",
      "Epoch [3/50], Step [1/735], Loss: 0.9977\n",
      "Epoch [3/50], Step [2/735], Loss: 0.7992\n",
      "Epoch [3/50], Step [3/735], Loss: 0.4449\n",
      "Epoch [3/50], Step [4/735], Loss: 1.2794\n",
      "Epoch [3/50], Step [5/735], Loss: 1.0613\n",
      "Epoch [3/50], Step [6/735], Loss: 0.6240\n",
      "Epoch [3/50], Step [7/735], Loss: 1.3484\n",
      "Epoch [3/50], Step [8/735], Loss: 0.7705\n",
      "Epoch [3/50], Step [9/735], Loss: 6.1580\n",
      "Epoch [3/50], Step [10/735], Loss: 1.2304\n",
      "Epoch [3/50], Step [11/735], Loss: 0.6953\n",
      "Epoch [3/50], Step [12/735], Loss: 0.4548\n",
      "Epoch [3/50], Step [13/735], Loss: 0.4705\n",
      "Epoch [3/50], Step [14/735], Loss: 0.6034\n",
      "Epoch [3/50], Step [15/735], Loss: 0.5918\n",
      "Epoch [3/50], Step [16/735], Loss: 1.1215\n",
      "Epoch [3/50], Step [17/735], Loss: 0.9791\n",
      "Epoch [3/50], Step [18/735], Loss: 0.8229\n",
      "Epoch [3/50], Step [19/735], Loss: 1.9449\n",
      "Epoch [3/50], Step [20/735], Loss: 0.6948\n",
      "Epoch [3/50], Step [21/735], Loss: 0.6837\n",
      "Epoch [3/50], Step [22/735], Loss: 0.7247\n",
      "Epoch [3/50], Step [23/735], Loss: 0.6008\n",
      "Epoch [3/50], Step [24/735], Loss: 0.7303\n",
      "Epoch [3/50], Step [25/735], Loss: 1.4462\n",
      "Epoch [3/50], Step [26/735], Loss: 1.8780\n",
      "Epoch [3/50], Step [27/735], Loss: 0.6729\n",
      "Epoch [3/50], Step [28/735], Loss: 0.9096\n",
      "Epoch [3/50], Step [29/735], Loss: 0.9398\n",
      "Epoch [3/50], Step [30/735], Loss: 2.7454\n",
      "Epoch [3/50], Step [31/735], Loss: 0.3650\n",
      "Epoch [3/50], Step [32/735], Loss: 0.7857\n",
      "Epoch [3/50], Step [33/735], Loss: 0.8931\n",
      "Epoch [3/50], Step [34/735], Loss: 0.5881\n",
      "Epoch [3/50], Step [35/735], Loss: 0.6419\n",
      "Epoch [3/50], Step [36/735], Loss: 0.6147\n",
      "Epoch [3/50], Step [37/735], Loss: 0.7668\n",
      "Epoch [3/50], Step [38/735], Loss: 0.9933\n",
      "Epoch [3/50], Step [39/735], Loss: 0.8262\n",
      "Epoch [3/50], Step [40/735], Loss: 0.5009\n",
      "Epoch [3/50], Step [41/735], Loss: 0.9646\n",
      "Epoch [3/50], Step [42/735], Loss: 0.4117\n",
      "Epoch [3/50], Step [43/735], Loss: 0.6243\n",
      "Epoch [3/50], Step [44/735], Loss: 3.3086\n",
      "Epoch [3/50], Step [45/735], Loss: 1.2004\n",
      "Epoch [3/50], Step [46/735], Loss: 0.6482\n",
      "Epoch [3/50], Step [47/735], Loss: 1.3430\n",
      "Epoch [3/50], Step [48/735], Loss: 1.0109\n",
      "Epoch [3/50], Step [49/735], Loss: 0.9800\n",
      "Epoch [3/50], Step [50/735], Loss: 0.9090\n",
      "Epoch [3/50], Step [51/735], Loss: 2.1212\n",
      "Epoch [3/50], Step [52/735], Loss: 0.7344\n",
      "Epoch [3/50], Step [53/735], Loss: 0.6568\n",
      "Epoch [3/50], Step [54/735], Loss: 0.4546\n",
      "Epoch [3/50], Step [55/735], Loss: 0.8266\n",
      "Epoch [3/50], Step [56/735], Loss: 0.9854\n",
      "Epoch [3/50], Step [57/735], Loss: 0.4305\n",
      "Epoch [3/50], Step [58/735], Loss: 0.9189\n",
      "Epoch [3/50], Step [59/735], Loss: 1.4553\n",
      "Epoch [3/50], Step [60/735], Loss: 3.1704\n",
      "Epoch [3/50], Step [61/735], Loss: 1.2467\n",
      "Epoch [3/50], Step [62/735], Loss: 0.8317\n",
      "Epoch [3/50], Step [63/735], Loss: 0.4772\n",
      "Epoch [3/50], Step [64/735], Loss: 0.7505\n",
      "Epoch [3/50], Step [65/735], Loss: 0.7081\n",
      "Epoch [3/50], Step [66/735], Loss: 1.3974\n",
      "Epoch [3/50], Step [67/735], Loss: 1.6748\n",
      "Epoch [3/50], Step [68/735], Loss: 1.1827\n",
      "Epoch [3/50], Step [69/735], Loss: 0.9506\n",
      "Epoch [3/50], Step [70/735], Loss: 1.2246\n",
      "Epoch [3/50], Step [71/735], Loss: 1.6080\n",
      "Epoch [3/50], Step [72/735], Loss: 0.8999\n",
      "Epoch [3/50], Step [73/735], Loss: 0.3499\n",
      "Epoch [3/50], Step [74/735], Loss: 0.5844\n",
      "Epoch [3/50], Step [75/735], Loss: 1.1354\n",
      "Epoch [3/50], Step [76/735], Loss: 0.6743\n",
      "Epoch [3/50], Step [77/735], Loss: 1.4064\n",
      "Epoch [3/50], Step [78/735], Loss: 1.1654\n",
      "Epoch [3/50], Step [79/735], Loss: 1.1168\n",
      "Epoch [3/50], Step [80/735], Loss: 0.5086\n",
      "Epoch [3/50], Step [81/735], Loss: 0.5943\n",
      "Epoch [3/50], Step [82/735], Loss: 0.8984\n",
      "Epoch [3/50], Step [83/735], Loss: 0.9571\n",
      "Epoch [3/50], Step [84/735], Loss: 1.5136\n",
      "Epoch [3/50], Step [85/735], Loss: 0.6938\n",
      "Epoch [3/50], Step [86/735], Loss: 0.9161\n",
      "Epoch [3/50], Step [87/735], Loss: 0.7727\n",
      "Epoch [3/50], Step [88/735], Loss: 1.0686\n",
      "Epoch [3/50], Step [89/735], Loss: 0.7858\n",
      "Epoch [3/50], Step [90/735], Loss: 1.0672\n",
      "Epoch [3/50], Step [91/735], Loss: 1.1930\n",
      "Epoch [3/50], Step [92/735], Loss: 0.5509\n",
      "Epoch [3/50], Step [93/735], Loss: 0.6353\n",
      "Epoch [3/50], Step [94/735], Loss: 1.6912\n",
      "Epoch [3/50], Step [95/735], Loss: 0.6498\n",
      "Epoch [3/50], Step [96/735], Loss: 1.3112\n",
      "Epoch [3/50], Step [97/735], Loss: 1.2692\n",
      "Epoch [3/50], Step [98/735], Loss: 1.0875\n",
      "Epoch [3/50], Step [99/735], Loss: 0.8563\n",
      "Epoch [3/50], Step [100/735], Loss: 1.2700\n",
      "Epoch [3/50], Step [101/735], Loss: 0.5689\n",
      "Epoch [3/50], Step [102/735], Loss: 0.6311\n",
      "Epoch [3/50], Step [103/735], Loss: 1.6464\n",
      "Epoch [3/50], Step [104/735], Loss: 0.7114\n",
      "Epoch [3/50], Step [105/735], Loss: 0.7047\n",
      "Epoch [3/50], Step [106/735], Loss: 1.3228\n",
      "Epoch [3/50], Step [107/735], Loss: 0.9044\n",
      "Epoch [3/50], Step [108/735], Loss: 3.6931\n",
      "Epoch [3/50], Step [109/735], Loss: 1.5129\n",
      "Epoch [3/50], Step [110/735], Loss: 0.5295\n",
      "Epoch [3/50], Step [111/735], Loss: 0.5581\n",
      "Epoch [3/50], Step [112/735], Loss: 0.5411\n",
      "Epoch [3/50], Step [113/735], Loss: 0.6279\n",
      "Epoch [3/50], Step [114/735], Loss: 0.7055\n",
      "Epoch [3/50], Step [115/735], Loss: 1.0757\n",
      "Epoch [3/50], Step [116/735], Loss: 1.0761\n",
      "Epoch [3/50], Step [117/735], Loss: 0.5662\n",
      "Epoch [3/50], Step [118/735], Loss: 0.6401\n",
      "Epoch [3/50], Step [119/735], Loss: 3.4268\n",
      "Epoch [3/50], Step [120/735], Loss: 0.6363\n",
      "Epoch [3/50], Step [121/735], Loss: 1.0182\n",
      "Epoch [3/50], Step [122/735], Loss: 0.7065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Step [123/735], Loss: 0.6018\n",
      "Epoch [3/50], Step [124/735], Loss: 0.5953\n",
      "Epoch [3/50], Step [125/735], Loss: 0.9089\n",
      "Epoch [3/50], Step [126/735], Loss: 1.0033\n",
      "Epoch [3/50], Step [127/735], Loss: 0.9701\n",
      "Epoch [3/50], Step [128/735], Loss: 1.0314\n",
      "Epoch [3/50], Step [129/735], Loss: 0.4477\n",
      "Epoch [3/50], Step [130/735], Loss: 0.3828\n",
      "Epoch [3/50], Step [131/735], Loss: 1.4011\n",
      "Epoch [3/50], Step [132/735], Loss: 0.5713\n",
      "Epoch [3/50], Step [133/735], Loss: 2.0878\n",
      "Epoch [3/50], Step [134/735], Loss: 1.2895\n",
      "Epoch [3/50], Step [135/735], Loss: 1.2988\n",
      "Epoch [3/50], Step [136/735], Loss: 0.7587\n",
      "Epoch [3/50], Step [137/735], Loss: 0.6795\n",
      "Epoch [3/50], Step [138/735], Loss: 0.5851\n",
      "Epoch [3/50], Step [139/735], Loss: 0.3222\n",
      "Epoch [3/50], Step [140/735], Loss: 0.6459\n",
      "Epoch [3/50], Step [141/735], Loss: 0.7245\n",
      "Epoch [3/50], Step [142/735], Loss: 0.5650\n",
      "Epoch [3/50], Step [143/735], Loss: 0.5066\n",
      "Epoch [3/50], Step [144/735], Loss: 0.7564\n",
      "Epoch [3/50], Step [145/735], Loss: 1.0064\n",
      "Epoch [3/50], Step [146/735], Loss: 0.9161\n",
      "Epoch [3/50], Step [147/735], Loss: 0.7655\n",
      "Epoch [3/50], Step [148/735], Loss: 0.5197\n",
      "Epoch [3/50], Step [149/735], Loss: 0.7518\n",
      "Epoch [3/50], Step [150/735], Loss: 0.5096\n",
      "Epoch [3/50], Step [151/735], Loss: 0.5697\n",
      "Epoch [3/50], Step [152/735], Loss: 0.5018\n",
      "Epoch [3/50], Step [153/735], Loss: 0.8381\n",
      "Epoch [3/50], Step [154/735], Loss: 0.2769\n",
      "Epoch [3/50], Step [155/735], Loss: 1.0668\n",
      "Epoch [3/50], Step [156/735], Loss: 1.2576\n",
      "Epoch [3/50], Step [157/735], Loss: 1.1019\n",
      "Epoch [3/50], Step [158/735], Loss: 0.3866\n",
      "Epoch [3/50], Step [159/735], Loss: 1.5286\n",
      "Epoch [3/50], Step [160/735], Loss: 0.7624\n",
      "Epoch [3/50], Step [161/735], Loss: 0.7629\n",
      "Epoch [3/50], Step [162/735], Loss: 0.3216\n",
      "Epoch [3/50], Step [163/735], Loss: 0.6597\n",
      "Epoch [3/50], Step [164/735], Loss: 2.2389\n",
      "Epoch [3/50], Step [165/735], Loss: 0.5270\n",
      "Epoch [3/50], Step [166/735], Loss: 0.6225\n",
      "Epoch [3/50], Step [167/735], Loss: 1.4348\n",
      "Epoch [3/50], Step [168/735], Loss: 1.5213\n",
      "Epoch [3/50], Step [169/735], Loss: 1.9590\n",
      "Epoch [3/50], Step [170/735], Loss: 2.7643\n",
      "Epoch [3/50], Step [171/735], Loss: 0.6826\n",
      "Epoch [3/50], Step [172/735], Loss: 0.8182\n",
      "Epoch [3/50], Step [173/735], Loss: 0.3586\n",
      "Epoch [3/50], Step [174/735], Loss: 0.8784\n",
      "Epoch [3/50], Step [175/735], Loss: 0.5100\n",
      "Epoch [3/50], Step [176/735], Loss: 0.4567\n",
      "Epoch [3/50], Step [177/735], Loss: 0.9548\n",
      "Epoch [3/50], Step [178/735], Loss: 0.7561\n",
      "Epoch [3/50], Step [179/735], Loss: 0.5997\n",
      "Epoch [3/50], Step [180/735], Loss: 0.9135\n",
      "Epoch [3/50], Step [181/735], Loss: 0.9341\n",
      "Epoch [3/50], Step [182/735], Loss: 1.0300\n",
      "Epoch [3/50], Step [183/735], Loss: 1.0230\n",
      "Epoch [3/50], Step [184/735], Loss: 1.0995\n",
      "Epoch [3/50], Step [185/735], Loss: 0.9541\n",
      "Epoch [3/50], Step [186/735], Loss: 0.4689\n",
      "Epoch [3/50], Step [187/735], Loss: 0.3389\n",
      "Epoch [3/50], Step [188/735], Loss: 0.7839\n",
      "Epoch [3/50], Step [189/735], Loss: 0.8118\n",
      "Epoch [3/50], Step [190/735], Loss: 1.2146\n",
      "Epoch [3/50], Step [191/735], Loss: 0.6701\n",
      "Epoch [3/50], Step [192/735], Loss: 0.5627\n",
      "Epoch [3/50], Step [193/735], Loss: 0.7349\n",
      "Epoch [3/50], Step [194/735], Loss: 0.8267\n",
      "Epoch [3/50], Step [195/735], Loss: 1.9233\n",
      "Epoch [3/50], Step [196/735], Loss: 0.3449\n",
      "Epoch [3/50], Step [197/735], Loss: 0.5929\n",
      "Epoch [3/50], Step [198/735], Loss: 3.1235\n",
      "Epoch [3/50], Step [199/735], Loss: 0.6273\n",
      "Epoch [3/50], Step [200/735], Loss: 0.5646\n",
      "Epoch [3/50], Step [201/735], Loss: 0.4990\n",
      "Epoch [3/50], Step [202/735], Loss: 0.5193\n",
      "Epoch [3/50], Step [203/735], Loss: 0.4398\n",
      "Epoch [3/50], Step [204/735], Loss: 2.3197\n",
      "Epoch [3/50], Step [205/735], Loss: 0.6462\n",
      "Epoch [3/50], Step [206/735], Loss: 0.6454\n",
      "Epoch [3/50], Step [207/735], Loss: 1.9196\n",
      "Epoch [3/50], Step [208/735], Loss: 1.5871\n",
      "Epoch [3/50], Step [209/735], Loss: 2.1746\n",
      "Epoch [3/50], Step [210/735], Loss: 1.0807\n",
      "Epoch [3/50], Step [211/735], Loss: 0.8874\n",
      "Epoch [3/50], Step [212/735], Loss: 1.4762\n",
      "Epoch [3/50], Step [213/735], Loss: 0.8078\n",
      "Epoch [3/50], Step [214/735], Loss: 0.3674\n",
      "Epoch [3/50], Step [215/735], Loss: 1.0172\n",
      "Epoch [3/50], Step [216/735], Loss: 1.1904\n",
      "Epoch [3/50], Step [217/735], Loss: 1.7024\n",
      "Epoch [3/50], Step [218/735], Loss: 0.6471\n",
      "Epoch [3/50], Step [219/735], Loss: 2.2043\n",
      "Epoch [3/50], Step [220/735], Loss: 0.4877\n",
      "Epoch [3/50], Step [221/735], Loss: 1.2854\n",
      "Epoch [3/50], Step [222/735], Loss: 1.0552\n",
      "Epoch [3/50], Step [223/735], Loss: 0.3355\n",
      "Epoch [3/50], Step [224/735], Loss: 1.0882\n",
      "Epoch [3/50], Step [225/735], Loss: 0.2246\n",
      "Epoch [3/50], Step [226/735], Loss: 0.7549\n",
      "Epoch [3/50], Step [227/735], Loss: 0.6749\n",
      "Epoch [3/50], Step [228/735], Loss: 1.3323\n",
      "Epoch [3/50], Step [229/735], Loss: 0.4780\n",
      "Epoch [3/50], Step [230/735], Loss: 0.4381\n",
      "Epoch [3/50], Step [231/735], Loss: 1.1007\n",
      "Epoch [3/50], Step [232/735], Loss: 0.6521\n",
      "Epoch [3/50], Step [233/735], Loss: 0.3629\n",
      "Epoch [3/50], Step [234/735], Loss: 0.5246\n",
      "Epoch [3/50], Step [235/735], Loss: 2.2491\n",
      "Epoch [3/50], Step [236/735], Loss: 0.7634\n",
      "Epoch [3/50], Step [237/735], Loss: 0.5520\n",
      "Epoch [3/50], Step [238/735], Loss: 0.6246\n",
      "Epoch [3/50], Step [239/735], Loss: 0.4326\n",
      "Epoch [3/50], Step [240/735], Loss: 1.5734\n",
      "Epoch [3/50], Step [241/735], Loss: 0.6444\n",
      "Epoch [3/50], Step [242/735], Loss: 0.8128\n",
      "Epoch [3/50], Step [243/735], Loss: 1.5245\n",
      "Epoch [3/50], Step [244/735], Loss: 0.5684\n",
      "Epoch [3/50], Step [245/735], Loss: 2.6796\n",
      "Epoch [3/50], Step [246/735], Loss: 1.2394\n",
      "Epoch [3/50], Step [247/735], Loss: 5.8366\n",
      "Epoch [3/50], Step [248/735], Loss: 0.6544\n",
      "Epoch [3/50], Step [249/735], Loss: 0.8662\n",
      "Epoch [3/50], Step [250/735], Loss: 0.6912\n",
      "Epoch [3/50], Step [251/735], Loss: 0.7406\n",
      "Epoch [3/50], Step [252/735], Loss: 0.5521\n",
      "Epoch [3/50], Step [253/735], Loss: 0.8039\n",
      "Epoch [3/50], Step [254/735], Loss: 1.6819\n",
      "Epoch [3/50], Step [255/735], Loss: 1.6127\n",
      "Epoch [3/50], Step [256/735], Loss: 0.9644\n",
      "Epoch [3/50], Step [257/735], Loss: 0.8081\n",
      "Epoch [3/50], Step [258/735], Loss: 1.6015\n",
      "Epoch [3/50], Step [259/735], Loss: 0.3098\n",
      "Epoch [3/50], Step [260/735], Loss: 0.4390\n",
      "Epoch [3/50], Step [261/735], Loss: 1.0199\n",
      "Epoch [3/50], Step [262/735], Loss: 0.6513\n",
      "Epoch [3/50], Step [263/735], Loss: 2.2397\n",
      "Epoch [3/50], Step [264/735], Loss: 0.9031\n",
      "Epoch [3/50], Step [265/735], Loss: 0.5393\n",
      "Epoch [3/50], Step [266/735], Loss: 1.6730\n",
      "Epoch [3/50], Step [267/735], Loss: 0.7209\n",
      "Epoch [3/50], Step [268/735], Loss: 0.4529\n",
      "Epoch [3/50], Step [269/735], Loss: 0.8423\n",
      "Epoch [3/50], Step [270/735], Loss: 0.5530\n",
      "Epoch [3/50], Step [271/735], Loss: 0.3887\n",
      "Epoch [3/50], Step [272/735], Loss: 0.8591\n",
      "Epoch [3/50], Step [273/735], Loss: 0.3956\n",
      "Epoch [3/50], Step [274/735], Loss: 0.4902\n",
      "Epoch [3/50], Step [275/735], Loss: 0.5722\n",
      "Epoch [3/50], Step [276/735], Loss: 0.6347\n",
      "Epoch [3/50], Step [277/735], Loss: 0.6040\n",
      "Epoch [3/50], Step [278/735], Loss: 0.3345\n",
      "Epoch [3/50], Step [279/735], Loss: 0.7705\n",
      "Epoch [3/50], Step [280/735], Loss: 0.6083\n",
      "Epoch [3/50], Step [281/735], Loss: 0.6973\n",
      "Epoch [3/50], Step [282/735], Loss: 0.6924\n",
      "Epoch [3/50], Step [283/735], Loss: 0.4376\n",
      "Epoch [3/50], Step [284/735], Loss: 0.5205\n",
      "Epoch [3/50], Step [285/735], Loss: 0.5692\n",
      "Epoch [3/50], Step [286/735], Loss: 0.7839\n",
      "Epoch [3/50], Step [287/735], Loss: 1.1131\n",
      "Epoch [3/50], Step [288/735], Loss: 0.4559\n",
      "Epoch [3/50], Step [289/735], Loss: 1.1082\n",
      "Epoch [3/50], Step [290/735], Loss: 0.6797\n",
      "Epoch [3/50], Step [291/735], Loss: 0.6495\n",
      "Epoch [3/50], Step [292/735], Loss: 0.7117\n",
      "Epoch [3/50], Step [293/735], Loss: 0.3848\n",
      "Epoch [3/50], Step [294/735], Loss: 0.7325\n",
      "Epoch [3/50], Step [295/735], Loss: 1.3368\n",
      "Epoch [3/50], Step [296/735], Loss: 0.9950\n",
      "Epoch [3/50], Step [297/735], Loss: 0.7987\n",
      "Epoch [3/50], Step [298/735], Loss: 1.3113\n",
      "Epoch [3/50], Step [299/735], Loss: 0.3490\n",
      "Epoch [3/50], Step [300/735], Loss: 1.0649\n",
      "Epoch [3/50], Step [301/735], Loss: 0.6570\n",
      "Epoch [3/50], Step [302/735], Loss: 0.6099\n",
      "Epoch [3/50], Step [303/735], Loss: 1.3839\n",
      "Epoch [3/50], Step [304/735], Loss: 0.7786\n",
      "Epoch [3/50], Step [305/735], Loss: 0.3361\n",
      "Epoch [3/50], Step [306/735], Loss: 0.5636\n",
      "Epoch [3/50], Step [307/735], Loss: 0.7637\n",
      "Epoch [3/50], Step [308/735], Loss: 0.5499\n",
      "Epoch [3/50], Step [309/735], Loss: 0.4296\n",
      "Epoch [3/50], Step [310/735], Loss: 0.4490\n",
      "Epoch [3/50], Step [311/735], Loss: 0.5446\n",
      "Epoch [3/50], Step [312/735], Loss: 0.4643\n",
      "Epoch [3/50], Step [313/735], Loss: 0.3710\n",
      "Epoch [3/50], Step [314/735], Loss: 0.4311\n",
      "Epoch [3/50], Step [315/735], Loss: 0.9251\n",
      "Epoch [3/50], Step [316/735], Loss: 0.4256\n",
      "Epoch [3/50], Step [317/735], Loss: 0.5558\n",
      "Epoch [3/50], Step [318/735], Loss: 0.5800\n",
      "Epoch [3/50], Step [319/735], Loss: 0.2588\n",
      "Epoch [3/50], Step [320/735], Loss: 0.6083\n",
      "Epoch [3/50], Step [321/735], Loss: 0.3264\n",
      "Epoch [3/50], Step [322/735], Loss: 0.7779\n",
      "Epoch [3/50], Step [323/735], Loss: 0.3238\n",
      "Epoch [3/50], Step [324/735], Loss: 1.0565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Step [325/735], Loss: 0.3626\n",
      "Epoch [3/50], Step [326/735], Loss: 0.4525\n",
      "Epoch [3/50], Step [327/735], Loss: 0.6559\n",
      "Epoch [3/50], Step [328/735], Loss: 0.6844\n",
      "Epoch [3/50], Step [329/735], Loss: 0.4897\n",
      "Epoch [3/50], Step [330/735], Loss: 0.8145\n",
      "Epoch [3/50], Step [331/735], Loss: 0.5772\n",
      "Epoch [3/50], Step [332/735], Loss: 1.3225\n",
      "Epoch [3/50], Step [333/735], Loss: 0.3836\n",
      "Epoch [3/50], Step [334/735], Loss: 0.4778\n",
      "Epoch [3/50], Step [335/735], Loss: 1.0271\n",
      "Epoch [3/50], Step [336/735], Loss: 0.9793\n",
      "Epoch [3/50], Step [337/735], Loss: 0.4298\n",
      "Epoch [3/50], Step [338/735], Loss: 0.7914\n",
      "Epoch [3/50], Step [339/735], Loss: 0.6902\n",
      "Epoch [3/50], Step [340/735], Loss: 0.6282\n",
      "Epoch [3/50], Step [341/735], Loss: 0.5231\n",
      "Epoch [3/50], Step [342/735], Loss: 0.8152\n",
      "Epoch [3/50], Step [343/735], Loss: 0.3816\n",
      "Epoch [3/50], Step [344/735], Loss: 3.0619\n",
      "Epoch [3/50], Step [345/735], Loss: 1.4963\n",
      "Epoch [3/50], Step [346/735], Loss: 0.6020\n",
      "Epoch [3/50], Step [347/735], Loss: 0.5603\n",
      "Epoch [3/50], Step [348/735], Loss: 0.5419\n",
      "Epoch [3/50], Step [349/735], Loss: 0.8498\n",
      "Epoch [3/50], Step [350/735], Loss: 0.6981\n",
      "Epoch [3/50], Step [351/735], Loss: 0.6028\n",
      "Epoch [3/50], Step [352/735], Loss: 1.4361\n",
      "Epoch [3/50], Step [353/735], Loss: 0.4316\n",
      "Epoch [3/50], Step [354/735], Loss: 8.3290\n",
      "Epoch [3/50], Step [355/735], Loss: 0.5157\n",
      "Epoch [3/50], Step [356/735], Loss: 0.9987\n",
      "Epoch [3/50], Step [357/735], Loss: 0.5806\n",
      "Epoch [3/50], Step [358/735], Loss: 0.5263\n",
      "Epoch [3/50], Step [359/735], Loss: 0.7653\n",
      "Epoch [3/50], Step [360/735], Loss: 0.6439\n",
      "Epoch [3/50], Step [361/735], Loss: 0.3833\n",
      "Epoch [3/50], Step [362/735], Loss: 0.5472\n",
      "Epoch [3/50], Step [363/735], Loss: 0.3991\n",
      "Epoch [3/50], Step [364/735], Loss: 0.8319\n",
      "Epoch [3/50], Step [365/735], Loss: 1.1429\n",
      "Epoch [3/50], Step [366/735], Loss: 0.5643\n",
      "Epoch [3/50], Step [367/735], Loss: 0.8792\n",
      "Epoch [3/50], Step [368/735], Loss: 0.6900\n",
      "Epoch [3/50], Step [369/735], Loss: 1.2753\n",
      "Epoch [3/50], Step [370/735], Loss: 1.4126\n",
      "Epoch [3/50], Step [371/735], Loss: 1.4100\n",
      "Epoch [3/50], Step [372/735], Loss: 0.6593\n",
      "Epoch [3/50], Step [373/735], Loss: 0.2980\n",
      "Epoch [3/50], Step [374/735], Loss: 1.0408\n",
      "Epoch [3/50], Step [375/735], Loss: 0.4444\n",
      "Epoch [3/50], Step [376/735], Loss: 0.4049\n",
      "Epoch [3/50], Step [377/735], Loss: 1.2914\n",
      "Epoch [3/50], Step [378/735], Loss: 0.3891\n",
      "Epoch [3/50], Step [379/735], Loss: 0.6771\n",
      "Epoch [3/50], Step [380/735], Loss: 1.1972\n",
      "Epoch [3/50], Step [381/735], Loss: 0.7357\n",
      "Epoch [3/50], Step [382/735], Loss: 0.9821\n",
      "Epoch [3/50], Step [383/735], Loss: 0.4369\n",
      "Epoch [3/50], Step [384/735], Loss: 0.9026\n",
      "Epoch [3/50], Step [385/735], Loss: 0.9407\n",
      "Epoch [3/50], Step [386/735], Loss: 0.4770\n",
      "Epoch [3/50], Step [387/735], Loss: 0.4958\n",
      "Epoch [3/50], Step [388/735], Loss: 0.9684\n",
      "Epoch [3/50], Step [389/735], Loss: 1.0161\n",
      "Epoch [3/50], Step [390/735], Loss: 0.5251\n",
      "Epoch [3/50], Step [391/735], Loss: 0.6267\n",
      "Epoch [3/50], Step [392/735], Loss: 0.5976\n",
      "Epoch [3/50], Step [393/735], Loss: 0.3036\n",
      "Epoch [3/50], Step [394/735], Loss: 0.5996\n",
      "Epoch [3/50], Step [395/735], Loss: 0.6709\n",
      "Epoch [3/50], Step [396/735], Loss: 1.4854\n",
      "Epoch [3/50], Step [397/735], Loss: 0.4195\n",
      "Epoch [3/50], Step [398/735], Loss: 1.1837\n",
      "Epoch [3/50], Step [399/735], Loss: 0.6035\n",
      "Epoch [3/50], Step [400/735], Loss: 0.9912\n",
      "Epoch [3/50], Step [401/735], Loss: 0.6668\n",
      "Epoch [3/50], Step [402/735], Loss: 6.1972\n",
      "Epoch [3/50], Step [403/735], Loss: 2.1760\n",
      "Epoch [3/50], Step [404/735], Loss: 0.3708\n",
      "Epoch [3/50], Step [405/735], Loss: 1.0520\n",
      "Epoch [3/50], Step [406/735], Loss: 3.7626\n",
      "Epoch [3/50], Step [407/735], Loss: 0.3373\n",
      "Epoch [3/50], Step [408/735], Loss: 0.3325\n",
      "Epoch [3/50], Step [409/735], Loss: 1.3220\n",
      "Epoch [3/50], Step [410/735], Loss: 1.5814\n",
      "Epoch [3/50], Step [411/735], Loss: 0.4228\n",
      "Epoch [3/50], Step [412/735], Loss: 0.9348\n",
      "Epoch [3/50], Step [413/735], Loss: 0.3512\n",
      "Epoch [3/50], Step [414/735], Loss: 1.3928\n",
      "Epoch [3/50], Step [415/735], Loss: 0.6217\n",
      "Epoch [3/50], Step [416/735], Loss: 0.8884\n",
      "Epoch [3/50], Step [417/735], Loss: 0.7013\n",
      "Epoch [3/50], Step [418/735], Loss: 0.4702\n",
      "Epoch [3/50], Step [419/735], Loss: 0.4288\n",
      "Epoch [3/50], Step [420/735], Loss: 0.2516\n",
      "Epoch [3/50], Step [421/735], Loss: 0.4550\n",
      "Epoch [3/50], Step [422/735], Loss: 0.6905\n",
      "Epoch [3/50], Step [423/735], Loss: 0.6747\n",
      "Epoch [3/50], Step [424/735], Loss: 0.4348\n",
      "Epoch [3/50], Step [425/735], Loss: 0.5125\n",
      "Epoch [3/50], Step [426/735], Loss: 0.4602\n",
      "Epoch [3/50], Step [427/735], Loss: 0.5232\n",
      "Epoch [3/50], Step [428/735], Loss: 0.5203\n",
      "Epoch [3/50], Step [429/735], Loss: 0.9495\n",
      "Epoch [3/50], Step [430/735], Loss: 1.6165\n",
      "Epoch [3/50], Step [431/735], Loss: 1.7640\n",
      "Epoch [3/50], Step [432/735], Loss: 1.5889\n",
      "Epoch [3/50], Step [433/735], Loss: 0.7845\n",
      "Epoch [3/50], Step [434/735], Loss: 0.5072\n",
      "Epoch [3/50], Step [435/735], Loss: 1.1353\n",
      "Epoch [3/50], Step [436/735], Loss: 0.9864\n",
      "Epoch [3/50], Step [437/735], Loss: 0.4963\n",
      "Epoch [3/50], Step [438/735], Loss: 0.8249\n",
      "Epoch [3/50], Step [439/735], Loss: 0.3147\n",
      "Epoch [3/50], Step [440/735], Loss: 0.4933\n",
      "Epoch [3/50], Step [441/735], Loss: 0.4486\n",
      "Epoch [3/50], Step [442/735], Loss: 0.2047\n",
      "Epoch [3/50], Step [443/735], Loss: 2.4581\n",
      "Epoch [3/50], Step [444/735], Loss: 3.8721\n",
      "Epoch [3/50], Step [445/735], Loss: 1.5771\n",
      "Epoch [3/50], Step [446/735], Loss: 0.4644\n",
      "Epoch [3/50], Step [447/735], Loss: 0.6825\n",
      "Epoch [3/50], Step [448/735], Loss: 0.6834\n",
      "Epoch [3/50], Step [449/735], Loss: 0.5162\n",
      "Epoch [3/50], Step [450/735], Loss: 0.4036\n",
      "Epoch [3/50], Step [451/735], Loss: 0.5176\n",
      "Epoch [3/50], Step [452/735], Loss: 0.9897\n",
      "Epoch [3/50], Step [453/735], Loss: 0.4118\n",
      "Epoch [3/50], Step [454/735], Loss: 0.8498\n",
      "Epoch [3/50], Step [455/735], Loss: 0.5151\n",
      "Epoch [3/50], Step [456/735], Loss: 0.3380\n",
      "Epoch [3/50], Step [457/735], Loss: 0.3640\n",
      "Epoch [3/50], Step [458/735], Loss: 0.9205\n",
      "Epoch [3/50], Step [459/735], Loss: 0.4197\n",
      "Epoch [3/50], Step [460/735], Loss: 0.2812\n",
      "Epoch [3/50], Step [461/735], Loss: 0.3854\n",
      "Epoch [3/50], Step [462/735], Loss: 0.8742\n",
      "Epoch [3/50], Step [463/735], Loss: 0.3709\n",
      "Epoch [3/50], Step [464/735], Loss: 0.6836\n",
      "Epoch [3/50], Step [465/735], Loss: 0.5464\n",
      "Epoch [3/50], Step [466/735], Loss: 1.2376\n",
      "Epoch [3/50], Step [467/735], Loss: 0.5411\n",
      "Epoch [3/50], Step [468/735], Loss: 1.1931\n",
      "Epoch [3/50], Step [469/735], Loss: 0.6786\n",
      "Epoch [3/50], Step [470/735], Loss: 0.6902\n",
      "Epoch [3/50], Step [471/735], Loss: 1.5036\n",
      "Epoch [3/50], Step [472/735], Loss: 1.9756\n",
      "Epoch [3/50], Step [473/735], Loss: 0.7334\n",
      "Epoch [3/50], Step [474/735], Loss: 0.9139\n",
      "Epoch [3/50], Step [475/735], Loss: 0.5101\n",
      "Epoch [3/50], Step [476/735], Loss: 0.2464\n",
      "Epoch [3/50], Step [477/735], Loss: 0.3233\n",
      "Epoch [3/50], Step [478/735], Loss: 0.6566\n",
      "Epoch [3/50], Step [479/735], Loss: 0.5623\n",
      "Epoch [3/50], Step [480/735], Loss: 0.9272\n",
      "Epoch [3/50], Step [481/735], Loss: 0.5817\n",
      "Epoch [3/50], Step [482/735], Loss: 0.9430\n",
      "Epoch [3/50], Step [483/735], Loss: 0.5281\n",
      "Epoch [3/50], Step [484/735], Loss: 0.5896\n",
      "Epoch [3/50], Step [485/735], Loss: 0.4589\n",
      "Epoch [3/50], Step [486/735], Loss: 0.7259\n",
      "Epoch [3/50], Step [487/735], Loss: 0.6576\n",
      "Epoch [3/50], Step [488/735], Loss: 1.3578\n",
      "Epoch [3/50], Step [489/735], Loss: 0.4982\n",
      "Epoch [3/50], Step [490/735], Loss: 0.4020\n",
      "Epoch [3/50], Step [491/735], Loss: 0.6267\n",
      "Epoch [3/50], Step [492/735], Loss: 0.4501\n",
      "Epoch [3/50], Step [493/735], Loss: 0.5640\n",
      "Epoch [3/50], Step [494/735], Loss: 0.4640\n",
      "Epoch [3/50], Step [495/735], Loss: 0.4350\n",
      "Epoch [3/50], Step [496/735], Loss: 0.6051\n",
      "Epoch [3/50], Step [497/735], Loss: 0.3689\n",
      "Epoch [3/50], Step [498/735], Loss: 0.8636\n",
      "Epoch [3/50], Step [499/735], Loss: 0.2740\n",
      "Epoch [3/50], Step [500/735], Loss: 0.3885\n",
      "Epoch [3/50], Step [501/735], Loss: 1.3872\n",
      "Epoch [3/50], Step [502/735], Loss: 0.8262\n",
      "Epoch [3/50], Step [503/735], Loss: 0.2316\n",
      "Epoch [3/50], Step [504/735], Loss: 0.7662\n",
      "Epoch [3/50], Step [505/735], Loss: 0.4551\n",
      "Epoch [3/50], Step [506/735], Loss: 0.6687\n",
      "Epoch [3/50], Step [507/735], Loss: 1.1068\n",
      "Epoch [3/50], Step [508/735], Loss: 0.3937\n",
      "Epoch [3/50], Step [509/735], Loss: 0.6516\n",
      "Epoch [3/50], Step [510/735], Loss: 0.8216\n",
      "Epoch [3/50], Step [511/735], Loss: 0.6390\n",
      "Epoch [3/50], Step [512/735], Loss: 0.5116\n",
      "Epoch [3/50], Step [513/735], Loss: 0.6959\n",
      "Epoch [3/50], Step [514/735], Loss: 0.2769\n",
      "Epoch [3/50], Step [515/735], Loss: 0.6489\n",
      "Epoch [3/50], Step [516/735], Loss: 0.2961\n",
      "Epoch [3/50], Step [517/735], Loss: 0.2423\n",
      "Epoch [3/50], Step [518/735], Loss: 0.3672\n",
      "Epoch [3/50], Step [519/735], Loss: 0.6491\n",
      "Epoch [3/50], Step [520/735], Loss: 0.4573\n",
      "Epoch [3/50], Step [521/735], Loss: 0.5330\n",
      "Epoch [3/50], Step [522/735], Loss: 0.6778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Step [523/735], Loss: 0.6732\n",
      "Epoch [3/50], Step [524/735], Loss: 1.0302\n",
      "Epoch [3/50], Step [525/735], Loss: 1.7614\n",
      "Epoch [3/50], Step [526/735], Loss: 0.3762\n",
      "Epoch [3/50], Step [527/735], Loss: 0.4577\n",
      "Epoch [3/50], Step [528/735], Loss: 0.5969\n",
      "Epoch [3/50], Step [529/735], Loss: 0.4602\n",
      "Epoch [3/50], Step [530/735], Loss: 2.4991\n",
      "Epoch [3/50], Step [531/735], Loss: 1.7748\n",
      "Epoch [3/50], Step [532/735], Loss: 0.8853\n",
      "Epoch [3/50], Step [533/735], Loss: 0.3939\n",
      "Epoch [3/50], Step [534/735], Loss: 1.3662\n",
      "Epoch [3/50], Step [535/735], Loss: 0.3817\n",
      "Epoch [3/50], Step [536/735], Loss: 0.6075\n",
      "Epoch [3/50], Step [537/735], Loss: 2.7441\n",
      "Epoch [3/50], Step [538/735], Loss: 0.3647\n",
      "Epoch [3/50], Step [539/735], Loss: 1.5566\n",
      "Epoch [3/50], Step [540/735], Loss: 1.0377\n",
      "Epoch [3/50], Step [541/735], Loss: 0.6912\n",
      "Epoch [3/50], Step [542/735], Loss: 0.7751\n",
      "Epoch [3/50], Step [543/735], Loss: 0.4565\n",
      "Epoch [3/50], Step [544/735], Loss: 0.4947\n",
      "Epoch [3/50], Step [545/735], Loss: 0.8714\n",
      "Epoch [3/50], Step [546/735], Loss: 0.4711\n",
      "Epoch [3/50], Step [547/735], Loss: 0.7136\n",
      "Epoch [3/50], Step [548/735], Loss: 0.3452\n",
      "Epoch [3/50], Step [549/735], Loss: 1.7528\n",
      "Epoch [3/50], Step [550/735], Loss: 1.1029\n",
      "Epoch [3/50], Step [551/735], Loss: 0.5612\n",
      "Epoch [3/50], Step [552/735], Loss: 0.9231\n",
      "Epoch [3/50], Step [553/735], Loss: 0.3589\n",
      "Epoch [3/50], Step [554/735], Loss: 0.6876\n",
      "Epoch [3/50], Step [555/735], Loss: 0.6265\n",
      "Epoch [3/50], Step [556/735], Loss: 0.6943\n",
      "Epoch [3/50], Step [557/735], Loss: 1.5744\n",
      "Epoch [3/50], Step [558/735], Loss: 1.5424\n",
      "Epoch [3/50], Step [559/735], Loss: 0.5692\n",
      "Epoch [3/50], Step [560/735], Loss: 1.4036\n",
      "Epoch [3/50], Step [561/735], Loss: 0.7479\n",
      "Epoch [3/50], Step [562/735], Loss: 2.4421\n",
      "Epoch [3/50], Step [563/735], Loss: 0.5182\n",
      "Epoch [3/50], Step [564/735], Loss: 0.3215\n",
      "Epoch [3/50], Step [565/735], Loss: 0.4234\n",
      "Epoch [3/50], Step [566/735], Loss: 0.6800\n",
      "Epoch [3/50], Step [567/735], Loss: 0.1492\n",
      "Epoch [3/50], Step [568/735], Loss: 0.8200\n",
      "Epoch [3/50], Step [569/735], Loss: 0.4348\n",
      "Epoch [3/50], Step [570/735], Loss: 0.7941\n",
      "Epoch [3/50], Step [571/735], Loss: 0.5527\n",
      "Epoch [3/50], Step [572/735], Loss: 0.5224\n",
      "Epoch [3/50], Step [573/735], Loss: 0.5262\n",
      "Epoch [3/50], Step [574/735], Loss: 0.5021\n",
      "Epoch [3/50], Step [575/735], Loss: 0.2183\n",
      "Epoch [3/50], Step [576/735], Loss: 1.4417\n",
      "Epoch [3/50], Step [577/735], Loss: 0.7134\n",
      "Epoch [3/50], Step [578/735], Loss: 0.1806\n",
      "Epoch [3/50], Step [579/735], Loss: 0.9524\n",
      "Epoch [3/50], Step [580/735], Loss: 0.5294\n",
      "Epoch [3/50], Step [581/735], Loss: 0.3566\n",
      "Epoch [3/50], Step [582/735], Loss: 0.7473\n",
      "Epoch [3/50], Step [583/735], Loss: 1.2634\n",
      "Epoch [3/50], Step [584/735], Loss: 0.2631\n",
      "Epoch [3/50], Step [585/735], Loss: 0.7404\n",
      "Epoch [3/50], Step [586/735], Loss: 2.6604\n",
      "Epoch [3/50], Step [587/735], Loss: 0.5710\n",
      "Epoch [3/50], Step [588/735], Loss: 0.7737\n",
      "Epoch [3/50], Step [589/735], Loss: 0.4833\n",
      "Epoch [3/50], Step [590/735], Loss: 1.2696\n",
      "Epoch [3/50], Step [591/735], Loss: 6.2548\n",
      "Epoch [3/50], Step [592/735], Loss: 0.3529\n",
      "Epoch [3/50], Step [593/735], Loss: 2.2531\n",
      "Epoch [3/50], Step [594/735], Loss: 0.8280\n",
      "Epoch [3/50], Step [595/735], Loss: 0.6972\n",
      "Epoch [3/50], Step [596/735], Loss: 0.2208\n",
      "Epoch [3/50], Step [597/735], Loss: 0.9255\n",
      "Epoch [3/50], Step [598/735], Loss: 0.5416\n",
      "Epoch [3/50], Step [599/735], Loss: 0.9891\n",
      "Epoch [3/50], Step [600/735], Loss: 0.5347\n",
      "Epoch [3/50], Step [601/735], Loss: 0.5861\n",
      "Epoch [3/50], Step [602/735], Loss: 0.4506\n",
      "Epoch [3/50], Step [603/735], Loss: 0.9650\n",
      "Epoch [3/50], Step [604/735], Loss: 0.7588\n",
      "Epoch [3/50], Step [605/735], Loss: 2.1464\n",
      "Epoch [3/50], Step [606/735], Loss: 0.5135\n",
      "Epoch [3/50], Step [607/735], Loss: 0.4569\n",
      "Epoch [3/50], Step [608/735], Loss: 1.4526\n",
      "Epoch [3/50], Step [609/735], Loss: 0.6870\n",
      "Epoch [3/50], Step [610/735], Loss: 0.9356\n",
      "Epoch [3/50], Step [611/735], Loss: 0.5701\n",
      "Epoch [3/50], Step [612/735], Loss: 0.5592\n",
      "Epoch [3/50], Step [613/735], Loss: 0.1715\n",
      "Epoch [3/50], Step [614/735], Loss: 0.4827\n",
      "Epoch [3/50], Step [615/735], Loss: 0.3036\n",
      "Epoch [3/50], Step [616/735], Loss: 0.1721\n",
      "Epoch [3/50], Step [617/735], Loss: 0.5837\n",
      "Epoch [3/50], Step [618/735], Loss: 0.8003\n",
      "Epoch [3/50], Step [619/735], Loss: 0.5787\n",
      "Epoch [3/50], Step [620/735], Loss: 0.3253\n",
      "Epoch [3/50], Step [621/735], Loss: 0.4036\n",
      "Epoch [3/50], Step [622/735], Loss: 0.7778\n",
      "Epoch [3/50], Step [623/735], Loss: 1.1300\n",
      "Epoch [3/50], Step [624/735], Loss: 0.6432\n",
      "Epoch [3/50], Step [625/735], Loss: 0.5406\n",
      "Epoch [3/50], Step [626/735], Loss: 0.3030\n",
      "Epoch [3/50], Step [627/735], Loss: 0.7893\n",
      "Epoch [3/50], Step [628/735], Loss: 0.4476\n",
      "Epoch [3/50], Step [629/735], Loss: 0.8630\n",
      "Epoch [3/50], Step [630/735], Loss: 0.2848\n",
      "Epoch [3/50], Step [631/735], Loss: 1.3232\n",
      "Epoch [3/50], Step [632/735], Loss: 0.2612\n",
      "Epoch [3/50], Step [633/735], Loss: 0.6098\n",
      "Epoch [3/50], Step [634/735], Loss: 0.3619\n",
      "Epoch [3/50], Step [635/735], Loss: 0.4613\n",
      "Epoch [3/50], Step [636/735], Loss: 1.2887\n",
      "Epoch [3/50], Step [637/735], Loss: 0.4710\n",
      "Epoch [3/50], Step [638/735], Loss: 0.5207\n",
      "Epoch [3/50], Step [639/735], Loss: 0.2020\n",
      "Epoch [3/50], Step [640/735], Loss: 1.9611\n",
      "Epoch [3/50], Step [641/735], Loss: 0.3081\n",
      "Epoch [3/50], Step [642/735], Loss: 0.4278\n",
      "Epoch [3/50], Step [643/735], Loss: 0.5582\n",
      "Epoch [3/50], Step [644/735], Loss: 0.8301\n",
      "Epoch [3/50], Step [645/735], Loss: 0.3149\n",
      "Epoch [3/50], Step [646/735], Loss: 0.3941\n",
      "Epoch [3/50], Step [647/735], Loss: 0.5027\n",
      "Epoch [3/50], Step [648/735], Loss: 0.8559\n",
      "Epoch [3/50], Step [649/735], Loss: 0.4036\n",
      "Epoch [3/50], Step [650/735], Loss: 0.5691\n",
      "Epoch [3/50], Step [651/735], Loss: 0.6493\n",
      "Epoch [3/50], Step [652/735], Loss: 0.1783\n",
      "Epoch [3/50], Step [653/735], Loss: 0.9449\n",
      "Epoch [3/50], Step [654/735], Loss: 0.5161\n",
      "Epoch [3/50], Step [655/735], Loss: 0.3887\n",
      "Epoch [3/50], Step [656/735], Loss: 0.4908\n",
      "Epoch [3/50], Step [657/735], Loss: 0.7338\n",
      "Epoch [3/50], Step [658/735], Loss: 0.4997\n",
      "Epoch [3/50], Step [659/735], Loss: 1.8156\n",
      "Epoch [3/50], Step [660/735], Loss: 0.2679\n",
      "Epoch [3/50], Step [661/735], Loss: 0.6469\n",
      "Epoch [3/50], Step [662/735], Loss: 1.1192\n",
      "Epoch [3/50], Step [663/735], Loss: 2.0801\n",
      "Epoch [3/50], Step [664/735], Loss: 0.2724\n",
      "Epoch [3/50], Step [665/735], Loss: 0.5479\n",
      "Epoch [3/50], Step [666/735], Loss: 0.6276\n",
      "Epoch [3/50], Step [667/735], Loss: 0.4806\n",
      "Epoch [3/50], Step [668/735], Loss: 1.1609\n",
      "Epoch [3/50], Step [669/735], Loss: 0.6702\n",
      "Epoch [3/50], Step [670/735], Loss: 0.3694\n",
      "Epoch [3/50], Step [671/735], Loss: 0.3551\n",
      "Epoch [3/50], Step [672/735], Loss: 0.6016\n",
      "Epoch [3/50], Step [673/735], Loss: 0.1995\n",
      "Epoch [3/50], Step [674/735], Loss: 1.2662\n",
      "Epoch [3/50], Step [675/735], Loss: 0.5581\n",
      "Epoch [3/50], Step [676/735], Loss: 2.9770\n",
      "Epoch [3/50], Step [677/735], Loss: 0.9534\n",
      "Epoch [3/50], Step [678/735], Loss: 0.4299\n",
      "Epoch [3/50], Step [679/735], Loss: 0.5278\n",
      "Epoch [3/50], Step [680/735], Loss: 0.6336\n",
      "Epoch [3/50], Step [681/735], Loss: 0.5613\n",
      "Epoch [3/50], Step [682/735], Loss: 0.7498\n",
      "Epoch [3/50], Step [683/735], Loss: 0.8100\n",
      "Epoch [3/50], Step [684/735], Loss: 1.7817\n",
      "Epoch [3/50], Step [685/735], Loss: 0.7965\n",
      "Epoch [3/50], Step [686/735], Loss: 0.7699\n",
      "Epoch [3/50], Step [687/735], Loss: 0.7194\n",
      "Epoch [3/50], Step [688/735], Loss: 1.2996\n",
      "Epoch [3/50], Step [689/735], Loss: 0.1754\n",
      "Epoch [3/50], Step [690/735], Loss: 0.5326\n",
      "Epoch [3/50], Step [691/735], Loss: 0.9587\n",
      "Epoch [3/50], Step [692/735], Loss: 0.8041\n",
      "Epoch [3/50], Step [693/735], Loss: 0.6325\n",
      "Epoch [3/50], Step [694/735], Loss: 1.6142\n",
      "Epoch [3/50], Step [695/735], Loss: 0.5881\n",
      "Epoch [3/50], Step [696/735], Loss: 0.3851\n",
      "Epoch [3/50], Step [697/735], Loss: 0.2982\n",
      "Epoch [3/50], Step [698/735], Loss: 0.3173\n",
      "Epoch [3/50], Step [699/735], Loss: 0.8836\n",
      "Epoch [3/50], Step [700/735], Loss: 0.3434\n",
      "Epoch [3/50], Step [701/735], Loss: 0.6450\n",
      "Epoch [3/50], Step [702/735], Loss: 0.2034\n",
      "Epoch [3/50], Step [703/735], Loss: 1.4465\n",
      "Epoch [3/50], Step [704/735], Loss: 0.6901\n",
      "Epoch [3/50], Step [705/735], Loss: 0.7002\n",
      "Epoch [3/50], Step [706/735], Loss: 0.5488\n",
      "Epoch [3/50], Step [707/735], Loss: 0.7760\n",
      "Epoch [3/50], Step [708/735], Loss: 0.6014\n",
      "Epoch [3/50], Step [709/735], Loss: 0.4018\n",
      "Epoch [3/50], Step [710/735], Loss: 0.5682\n",
      "Epoch [3/50], Step [711/735], Loss: 1.2720\n",
      "Epoch [3/50], Step [712/735], Loss: 0.7608\n",
      "Epoch [3/50], Step [713/735], Loss: 0.3725\n",
      "Epoch [3/50], Step [714/735], Loss: 0.6550\n",
      "Epoch [3/50], Step [715/735], Loss: 0.2897\n",
      "Epoch [3/50], Step [716/735], Loss: 0.5555\n",
      "Epoch [3/50], Step [717/735], Loss: 0.4360\n",
      "Epoch [3/50], Step [718/735], Loss: 0.1716\n",
      "Epoch [3/50], Step [719/735], Loss: 1.1634\n",
      "Epoch [3/50], Step [720/735], Loss: 0.5377\n",
      "Epoch [3/50], Step [721/735], Loss: 0.4824\n",
      "Epoch [3/50], Step [722/735], Loss: 2.7339\n",
      "Epoch [3/50], Step [723/735], Loss: 1.3405\n",
      "Epoch [3/50], Step [724/735], Loss: 0.4234\n",
      "Epoch [3/50], Step [725/735], Loss: 0.2072\n",
      "Epoch [3/50], Step [726/735], Loss: 0.2765\n",
      "Epoch [3/50], Step [727/735], Loss: 0.3806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Step [728/735], Loss: 0.3766\n",
      "Epoch [3/50], Step [729/735], Loss: 0.3174\n",
      "Epoch [3/50], Step [730/735], Loss: 0.4805\n",
      "Epoch [3/50], Step [731/735], Loss: 0.1952\n",
      "Epoch [3/50], Step [732/735], Loss: 0.2244\n",
      "Epoch [3/50], Step [733/735], Loss: 0.4813\n",
      "Epoch [3/50], Step [734/735], Loss: 0.5831\n",
      "Epoch [3/50], Step [735/735], Loss: 0.1648\n",
      "Epoch [4/50], Step [1/735], Loss: 0.3501\n",
      "Epoch [4/50], Step [2/735], Loss: 0.2346\n",
      "Epoch [4/50], Step [3/735], Loss: 0.3955\n",
      "Epoch [4/50], Step [4/735], Loss: 0.6053\n",
      "Epoch [4/50], Step [5/735], Loss: 0.2598\n",
      "Epoch [4/50], Step [6/735], Loss: 0.6155\n",
      "Epoch [4/50], Step [7/735], Loss: 0.7914\n",
      "Epoch [4/50], Step [8/735], Loss: 5.3821\n",
      "Epoch [4/50], Step [9/735], Loss: 0.9160\n",
      "Epoch [4/50], Step [10/735], Loss: 0.3141\n",
      "Epoch [4/50], Step [11/735], Loss: 5.6722\n",
      "Epoch [4/50], Step [12/735], Loss: 0.6137\n",
      "Epoch [4/50], Step [13/735], Loss: 0.8754\n",
      "Epoch [4/50], Step [14/735], Loss: 0.8101\n",
      "Epoch [4/50], Step [15/735], Loss: 0.4000\n",
      "Epoch [4/50], Step [16/735], Loss: 0.3847\n",
      "Epoch [4/50], Step [17/735], Loss: 0.5775\n",
      "Epoch [4/50], Step [18/735], Loss: 0.8420\n",
      "Epoch [4/50], Step [19/735], Loss: 0.5070\n",
      "Epoch [4/50], Step [20/735], Loss: 0.5553\n",
      "Epoch [4/50], Step [21/735], Loss: 0.3551\n",
      "Epoch [4/50], Step [22/735], Loss: 2.3231\n",
      "Epoch [4/50], Step [23/735], Loss: 0.8559\n",
      "Epoch [4/50], Step [24/735], Loss: 0.5380\n",
      "Epoch [4/50], Step [25/735], Loss: 0.2771\n",
      "Epoch [4/50], Step [26/735], Loss: 0.3489\n",
      "Epoch [4/50], Step [27/735], Loss: 0.6613\n",
      "Epoch [4/50], Step [28/735], Loss: 0.5540\n",
      "Epoch [4/50], Step [29/735], Loss: 1.1952\n",
      "Epoch [4/50], Step [30/735], Loss: 0.1854\n",
      "Epoch [4/50], Step [31/735], Loss: 2.8747\n",
      "Epoch [4/50], Step [32/735], Loss: 0.5290\n",
      "Epoch [4/50], Step [33/735], Loss: 0.4595\n",
      "Epoch [4/50], Step [34/735], Loss: 0.2978\n",
      "Epoch [4/50], Step [35/735], Loss: 0.2847\n",
      "Epoch [4/50], Step [36/735], Loss: 0.7901\n",
      "Epoch [4/50], Step [37/735], Loss: 0.5238\n",
      "Epoch [4/50], Step [38/735], Loss: 0.2636\n",
      "Epoch [4/50], Step [39/735], Loss: 0.5656\n",
      "Epoch [4/50], Step [40/735], Loss: 0.7255\n",
      "Epoch [4/50], Step [41/735], Loss: 0.3817\n",
      "Epoch [4/50], Step [42/735], Loss: 0.9480\n",
      "Epoch [4/50], Step [43/735], Loss: 0.6770\n",
      "Epoch [4/50], Step [44/735], Loss: 0.2458\n",
      "Epoch [4/50], Step [45/735], Loss: 2.1196\n",
      "Epoch [4/50], Step [46/735], Loss: 0.4926\n",
      "Epoch [4/50], Step [47/735], Loss: 0.8389\n",
      "Epoch [4/50], Step [48/735], Loss: 0.5937\n",
      "Epoch [4/50], Step [49/735], Loss: 0.3246\n",
      "Epoch [4/50], Step [50/735], Loss: 0.8401\n",
      "Epoch [4/50], Step [51/735], Loss: 0.4720\n",
      "Epoch [4/50], Step [52/735], Loss: 0.7335\n",
      "Epoch [4/50], Step [53/735], Loss: 0.3438\n",
      "Epoch [4/50], Step [54/735], Loss: 0.3948\n",
      "Epoch [4/50], Step [55/735], Loss: 1.9308\n",
      "Epoch [4/50], Step [56/735], Loss: 0.6042\n",
      "Epoch [4/50], Step [57/735], Loss: 0.3017\n",
      "Epoch [4/50], Step [58/735], Loss: 0.5477\n",
      "Epoch [4/50], Step [59/735], Loss: 0.9328\n",
      "Epoch [4/50], Step [60/735], Loss: 0.7605\n",
      "Epoch [4/50], Step [61/735], Loss: 0.2877\n",
      "Epoch [4/50], Step [62/735], Loss: 0.3426\n",
      "Epoch [4/50], Step [63/735], Loss: 0.2135\n",
      "Epoch [4/50], Step [64/735], Loss: 0.1402\n",
      "Epoch [4/50], Step [65/735], Loss: 0.2005\n",
      "Epoch [4/50], Step [66/735], Loss: 0.4256\n",
      "Epoch [4/50], Step [67/735], Loss: 0.3137\n",
      "Epoch [4/50], Step [68/735], Loss: 0.9000\n",
      "Epoch [4/50], Step [69/735], Loss: 0.9143\n",
      "Epoch [4/50], Step [70/735], Loss: 0.8310\n",
      "Epoch [4/50], Step [71/735], Loss: 1.7630\n",
      "Epoch [4/50], Step [72/735], Loss: 0.6992\n",
      "Epoch [4/50], Step [73/735], Loss: 0.7468\n",
      "Epoch [4/50], Step [74/735], Loss: 0.6513\n",
      "Epoch [4/50], Step [75/735], Loss: 1.2681\n",
      "Epoch [4/50], Step [76/735], Loss: 1.3211\n",
      "Epoch [4/50], Step [77/735], Loss: 0.6993\n",
      "Epoch [4/50], Step [78/735], Loss: 1.0532\n",
      "Epoch [4/50], Step [79/735], Loss: 0.2207\n",
      "Epoch [4/50], Step [80/735], Loss: 0.2999\n",
      "Epoch [4/50], Step [81/735], Loss: 0.7386\n",
      "Epoch [4/50], Step [82/735], Loss: 0.9454\n",
      "Epoch [4/50], Step [83/735], Loss: 0.4109\n",
      "Epoch [4/50], Step [84/735], Loss: 0.3238\n",
      "Epoch [4/50], Step [85/735], Loss: 0.8315\n",
      "Epoch [4/50], Step [86/735], Loss: 0.2449\n",
      "Epoch [4/50], Step [87/735], Loss: 0.4296\n",
      "Epoch [4/50], Step [88/735], Loss: 0.5044\n",
      "Epoch [4/50], Step [89/735], Loss: 0.4302\n",
      "Epoch [4/50], Step [90/735], Loss: 0.3412\n",
      "Epoch [4/50], Step [91/735], Loss: 0.5543\n",
      "Epoch [4/50], Step [92/735], Loss: 0.3518\n",
      "Epoch [4/50], Step [93/735], Loss: 0.9486\n",
      "Epoch [4/50], Step [94/735], Loss: 0.5357\n",
      "Epoch [4/50], Step [95/735], Loss: 1.3442\n",
      "Epoch [4/50], Step [96/735], Loss: 1.4782\n",
      "Epoch [4/50], Step [97/735], Loss: 0.4941\n",
      "Epoch [4/50], Step [98/735], Loss: 0.3944\n",
      "Epoch [4/50], Step [99/735], Loss: 0.6638\n",
      "Epoch [4/50], Step [100/735], Loss: 0.9582\n",
      "Epoch [4/50], Step [101/735], Loss: 0.2457\n",
      "Epoch [4/50], Step [102/735], Loss: 0.2045\n",
      "Epoch [4/50], Step [103/735], Loss: 0.2139\n",
      "Epoch [4/50], Step [104/735], Loss: 2.9218\n",
      "Epoch [4/50], Step [105/735], Loss: 0.9299\n",
      "Epoch [4/50], Step [106/735], Loss: 0.9194\n",
      "Epoch [4/50], Step [107/735], Loss: 0.2518\n",
      "Epoch [4/50], Step [108/735], Loss: 0.8125\n",
      "Epoch [4/50], Step [109/735], Loss: 0.7411\n",
      "Epoch [4/50], Step [110/735], Loss: 0.3348\n",
      "Epoch [4/50], Step [111/735], Loss: 0.4969\n",
      "Epoch [4/50], Step [112/735], Loss: 0.4792\n",
      "Epoch [4/50], Step [113/735], Loss: 1.3191\n",
      "Epoch [4/50], Step [114/735], Loss: 2.2199\n",
      "Epoch [4/50], Step [115/735], Loss: 0.1628\n",
      "Epoch [4/50], Step [116/735], Loss: 0.3397\n",
      "Epoch [4/50], Step [117/735], Loss: 0.4804\n",
      "Epoch [4/50], Step [118/735], Loss: 0.4290\n",
      "Epoch [4/50], Step [119/735], Loss: 0.2966\n",
      "Epoch [4/50], Step [120/735], Loss: 1.4078\n",
      "Epoch [4/50], Step [121/735], Loss: 0.6960\n",
      "Epoch [4/50], Step [122/735], Loss: 0.7334\n",
      "Epoch [4/50], Step [123/735], Loss: 0.3537\n",
      "Epoch [4/50], Step [124/735], Loss: 2.0058\n",
      "Epoch [4/50], Step [125/735], Loss: 6.3837\n",
      "Epoch [4/50], Step [126/735], Loss: 0.6105\n",
      "Epoch [4/50], Step [127/735], Loss: 0.6366\n",
      "Epoch [4/50], Step [128/735], Loss: 0.6801\n",
      "Epoch [4/50], Step [129/735], Loss: 1.0914\n",
      "Epoch [4/50], Step [130/735], Loss: 0.6227\n",
      "Epoch [4/50], Step [131/735], Loss: 1.3621\n",
      "Epoch [4/50], Step [132/735], Loss: 0.3030\n",
      "Epoch [4/50], Step [133/735], Loss: 0.3343\n",
      "Epoch [4/50], Step [134/735], Loss: 0.5389\n",
      "Epoch [4/50], Step [135/735], Loss: 0.7340\n",
      "Epoch [4/50], Step [136/735], Loss: 0.2937\n",
      "Epoch [4/50], Step [137/735], Loss: 0.5240\n",
      "Epoch [4/50], Step [138/735], Loss: 0.9798\n",
      "Epoch [4/50], Step [139/735], Loss: 0.5319\n",
      "Epoch [4/50], Step [140/735], Loss: 1.7549\n",
      "Epoch [4/50], Step [141/735], Loss: 0.3260\n",
      "Epoch [4/50], Step [142/735], Loss: 0.3926\n",
      "Epoch [4/50], Step [143/735], Loss: 0.5583\n",
      "Epoch [4/50], Step [144/735], Loss: 0.2453\n",
      "Epoch [4/50], Step [145/735], Loss: 1.5957\n",
      "Epoch [4/50], Step [146/735], Loss: 0.2388\n",
      "Epoch [4/50], Step [147/735], Loss: 0.6537\n",
      "Epoch [4/50], Step [148/735], Loss: 0.3798\n",
      "Epoch [4/50], Step [149/735], Loss: 0.7029\n",
      "Epoch [4/50], Step [150/735], Loss: 0.4151\n",
      "Epoch [4/50], Step [151/735], Loss: 0.6051\n",
      "Epoch [4/50], Step [152/735], Loss: 0.3002\n",
      "Epoch [4/50], Step [153/735], Loss: 0.3829\n",
      "Epoch [4/50], Step [154/735], Loss: 0.7484\n",
      "Epoch [4/50], Step [155/735], Loss: 0.6283\n",
      "Epoch [4/50], Step [156/735], Loss: 0.3032\n",
      "Epoch [4/50], Step [157/735], Loss: 0.2163\n",
      "Epoch [4/50], Step [158/735], Loss: 0.5099\n",
      "Epoch [4/50], Step [159/735], Loss: 2.9253\n",
      "Epoch [4/50], Step [160/735], Loss: 0.2271\n",
      "Epoch [4/50], Step [161/735], Loss: 0.3986\n",
      "Epoch [4/50], Step [162/735], Loss: 1.0870\n",
      "Epoch [4/50], Step [163/735], Loss: 0.1690\n",
      "Epoch [4/50], Step [164/735], Loss: 0.5512\n",
      "Epoch [4/50], Step [165/735], Loss: 1.1745\n",
      "Epoch [4/50], Step [166/735], Loss: 0.9766\n",
      "Epoch [4/50], Step [167/735], Loss: 0.5544\n",
      "Epoch [4/50], Step [168/735], Loss: 0.3702\n",
      "Epoch [4/50], Step [169/735], Loss: 0.5258\n",
      "Epoch [4/50], Step [170/735], Loss: 0.5632\n",
      "Epoch [4/50], Step [171/735], Loss: 3.0480\n",
      "Epoch [4/50], Step [172/735], Loss: 0.5753\n",
      "Epoch [4/50], Step [173/735], Loss: 1.2507\n",
      "Epoch [4/50], Step [174/735], Loss: 0.9287\n",
      "Epoch [4/50], Step [175/735], Loss: 1.0890\n",
      "Epoch [4/50], Step [176/735], Loss: 0.5641\n",
      "Epoch [4/50], Step [177/735], Loss: 0.8004\n",
      "Epoch [4/50], Step [178/735], Loss: 0.3639\n",
      "Epoch [4/50], Step [179/735], Loss: 0.5679\n",
      "Epoch [4/50], Step [180/735], Loss: 0.5156\n",
      "Epoch [4/50], Step [181/735], Loss: 0.2061\n",
      "Epoch [4/50], Step [182/735], Loss: 0.4148\n",
      "Epoch [4/50], Step [183/735], Loss: 0.3859\n",
      "Epoch [4/50], Step [184/735], Loss: 0.5031\n",
      "Epoch [4/50], Step [185/735], Loss: 0.8832\n",
      "Epoch [4/50], Step [186/735], Loss: 0.5503\n",
      "Epoch [4/50], Step [187/735], Loss: 0.6180\n",
      "Epoch [4/50], Step [188/735], Loss: 0.7672\n",
      "Epoch [4/50], Step [189/735], Loss: 0.5117\n",
      "Epoch [4/50], Step [190/735], Loss: 0.5828\n",
      "Epoch [4/50], Step [191/735], Loss: 0.4477\n",
      "Epoch [4/50], Step [192/735], Loss: 0.6745\n",
      "Epoch [4/50], Step [193/735], Loss: 1.6007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Step [194/735], Loss: 0.8895\n",
      "Epoch [4/50], Step [195/735], Loss: 0.6220\n",
      "Epoch [4/50], Step [196/735], Loss: 0.7376\n",
      "Epoch [4/50], Step [197/735], Loss: 0.9686\n",
      "Epoch [4/50], Step [198/735], Loss: 0.7278\n",
      "Epoch [4/50], Step [199/735], Loss: 0.3740\n",
      "Epoch [4/50], Step [200/735], Loss: 0.1917\n",
      "Epoch [4/50], Step [201/735], Loss: 0.1994\n",
      "Epoch [4/50], Step [202/735], Loss: 1.7226\n",
      "Epoch [4/50], Step [203/735], Loss: 1.4621\n",
      "Epoch [4/50], Step [204/735], Loss: 0.4175\n",
      "Epoch [4/50], Step [205/735], Loss: 0.9448\n",
      "Epoch [4/50], Step [206/735], Loss: 1.3783\n",
      "Epoch [4/50], Step [207/735], Loss: 0.5307\n",
      "Epoch [4/50], Step [208/735], Loss: 0.5947\n",
      "Epoch [4/50], Step [209/735], Loss: 0.8427\n",
      "Epoch [4/50], Step [210/735], Loss: 0.5916\n",
      "Epoch [4/50], Step [211/735], Loss: 0.5531\n",
      "Epoch [4/50], Step [212/735], Loss: 0.5340\n",
      "Epoch [4/50], Step [213/735], Loss: 0.5265\n",
      "Epoch [4/50], Step [214/735], Loss: 0.9627\n",
      "Epoch [4/50], Step [215/735], Loss: 0.5205\n",
      "Epoch [4/50], Step [216/735], Loss: 0.5492\n",
      "Epoch [4/50], Step [217/735], Loss: 0.5574\n",
      "Epoch [4/50], Step [218/735], Loss: 2.4960\n",
      "Epoch [4/50], Step [219/735], Loss: 0.4384\n",
      "Epoch [4/50], Step [220/735], Loss: 0.6250\n",
      "Epoch [4/50], Step [221/735], Loss: 0.6439\n",
      "Epoch [4/50], Step [222/735], Loss: 0.3499\n",
      "Epoch [4/50], Step [223/735], Loss: 0.3903\n",
      "Epoch [4/50], Step [224/735], Loss: 0.2905\n",
      "Epoch [4/50], Step [225/735], Loss: 0.1610\n",
      "Epoch [4/50], Step [226/735], Loss: 0.4831\n",
      "Epoch [4/50], Step [227/735], Loss: 0.6832\n",
      "Epoch [4/50], Step [228/735], Loss: 0.3700\n",
      "Epoch [4/50], Step [229/735], Loss: 0.8759\n",
      "Epoch [4/50], Step [230/735], Loss: 0.2333\n",
      "Epoch [4/50], Step [231/735], Loss: 0.1603\n",
      "Epoch [4/50], Step [232/735], Loss: 3.6776\n",
      "Epoch [4/50], Step [233/735], Loss: 1.6995\n",
      "Epoch [4/50], Step [234/735], Loss: 0.9713\n",
      "Epoch [4/50], Step [235/735], Loss: 0.4957\n",
      "Epoch [4/50], Step [236/735], Loss: 0.5474\n",
      "Epoch [4/50], Step [237/735], Loss: 0.2767\n",
      "Epoch [4/50], Step [238/735], Loss: 1.1789\n",
      "Epoch [4/50], Step [239/735], Loss: 0.9260\n",
      "Epoch [4/50], Step [240/735], Loss: 0.3992\n",
      "Epoch [4/50], Step [241/735], Loss: 0.7807\n",
      "Epoch [4/50], Step [242/735], Loss: 0.7164\n",
      "Epoch [4/50], Step [243/735], Loss: 0.7875\n",
      "Epoch [4/50], Step [244/735], Loss: 0.5586\n",
      "Epoch [4/50], Step [245/735], Loss: 0.5378\n",
      "Epoch [4/50], Step [246/735], Loss: 0.3364\n",
      "Epoch [4/50], Step [247/735], Loss: 0.5382\n",
      "Epoch [4/50], Step [248/735], Loss: 0.9085\n",
      "Epoch [4/50], Step [249/735], Loss: 0.6297\n",
      "Epoch [4/50], Step [250/735], Loss: 0.7811\n",
      "Epoch [4/50], Step [251/735], Loss: 0.4171\n",
      "Epoch [4/50], Step [252/735], Loss: 0.4565\n",
      "Epoch [4/50], Step [253/735], Loss: 1.1129\n",
      "Epoch [4/50], Step [254/735], Loss: 0.3935\n",
      "Epoch [4/50], Step [255/735], Loss: 0.2167\n",
      "Epoch [4/50], Step [256/735], Loss: 0.3713\n",
      "Epoch [4/50], Step [257/735], Loss: 0.7397\n",
      "Epoch [4/50], Step [258/735], Loss: 0.5425\n",
      "Epoch [4/50], Step [259/735], Loss: 0.7824\n",
      "Epoch [4/50], Step [260/735], Loss: 0.7302\n",
      "Epoch [4/50], Step [261/735], Loss: 1.1925\n",
      "Epoch [4/50], Step [262/735], Loss: 0.4916\n",
      "Epoch [4/50], Step [263/735], Loss: 1.2910\n",
      "Epoch [4/50], Step [264/735], Loss: 0.3688\n",
      "Epoch [4/50], Step [265/735], Loss: 6.1938\n",
      "Epoch [4/50], Step [266/735], Loss: 0.1925\n",
      "Epoch [4/50], Step [267/735], Loss: 1.1070\n",
      "Epoch [4/50], Step [268/735], Loss: 0.3562\n",
      "Epoch [4/50], Step [269/735], Loss: 0.4229\n",
      "Epoch [4/50], Step [270/735], Loss: 1.0781\n",
      "Epoch [4/50], Step [271/735], Loss: 0.2895\n",
      "Epoch [4/50], Step [272/735], Loss: 0.3557\n",
      "Epoch [4/50], Step [273/735], Loss: 0.3203\n",
      "Epoch [4/50], Step [274/735], Loss: 0.3488\n",
      "Epoch [4/50], Step [275/735], Loss: 0.8558\n",
      "Epoch [4/50], Step [276/735], Loss: 0.3509\n",
      "Epoch [4/50], Step [277/735], Loss: 0.7838\n",
      "Epoch [4/50], Step [278/735], Loss: 0.3412\n",
      "Epoch [4/50], Step [279/735], Loss: 0.5587\n",
      "Epoch [4/50], Step [280/735], Loss: 0.3513\n",
      "Epoch [4/50], Step [281/735], Loss: 1.2896\n",
      "Epoch [4/50], Step [282/735], Loss: 0.2569\n",
      "Epoch [4/50], Step [283/735], Loss: 0.2968\n",
      "Epoch [4/50], Step [284/735], Loss: 0.5048\n",
      "Epoch [4/50], Step [285/735], Loss: 0.7478\n",
      "Epoch [4/50], Step [286/735], Loss: 0.5055\n",
      "Epoch [4/50], Step [287/735], Loss: 0.2821\n",
      "Epoch [4/50], Step [288/735], Loss: 2.1839\n",
      "Epoch [4/50], Step [289/735], Loss: 1.0352\n",
      "Epoch [4/50], Step [290/735], Loss: 1.4891\n",
      "Epoch [4/50], Step [291/735], Loss: 0.2306\n",
      "Epoch [4/50], Step [292/735], Loss: 1.0770\n",
      "Epoch [4/50], Step [293/735], Loss: 0.4292\n",
      "Epoch [4/50], Step [294/735], Loss: 0.2668\n",
      "Epoch [4/50], Step [295/735], Loss: 0.6666\n",
      "Epoch [4/50], Step [296/735], Loss: 0.5763\n",
      "Epoch [4/50], Step [297/735], Loss: 0.2396\n",
      "Epoch [4/50], Step [298/735], Loss: 1.0748\n",
      "Epoch [4/50], Step [299/735], Loss: 0.3863\n",
      "Epoch [4/50], Step [300/735], Loss: 0.5843\n",
      "Epoch [4/50], Step [301/735], Loss: 0.3016\n",
      "Epoch [4/50], Step [302/735], Loss: 0.6148\n",
      "Epoch [4/50], Step [303/735], Loss: 0.4968\n",
      "Epoch [4/50], Step [304/735], Loss: 0.4159\n",
      "Epoch [4/50], Step [305/735], Loss: 0.3881\n",
      "Epoch [4/50], Step [306/735], Loss: 0.1707\n",
      "Epoch [4/50], Step [307/735], Loss: 0.3368\n",
      "Epoch [4/50], Step [308/735], Loss: 0.5073\n",
      "Epoch [4/50], Step [309/735], Loss: 0.7702\n",
      "Epoch [4/50], Step [310/735], Loss: 0.3724\n",
      "Epoch [4/50], Step [311/735], Loss: 0.6557\n",
      "Epoch [4/50], Step [312/735], Loss: 0.5237\n",
      "Epoch [4/50], Step [313/735], Loss: 0.3785\n",
      "Epoch [4/50], Step [314/735], Loss: 1.1729\n",
      "Epoch [4/50], Step [315/735], Loss: 0.9996\n",
      "Epoch [4/50], Step [316/735], Loss: 0.1482\n",
      "Epoch [4/50], Step [317/735], Loss: 0.2357\n",
      "Epoch [4/50], Step [318/735], Loss: 0.2626\n",
      "Epoch [4/50], Step [319/735], Loss: 0.6823\n",
      "Epoch [4/50], Step [320/735], Loss: 0.3848\n",
      "Epoch [4/50], Step [321/735], Loss: 1.6563\n",
      "Epoch [4/50], Step [322/735], Loss: 0.3872\n",
      "Epoch [4/50], Step [323/735], Loss: 0.3570\n",
      "Epoch [4/50], Step [324/735], Loss: 1.2121\n",
      "Epoch [4/50], Step [325/735], Loss: 0.2919\n",
      "Epoch [4/50], Step [326/735], Loss: 0.5472\n",
      "Epoch [4/50], Step [327/735], Loss: 0.7830\n",
      "Epoch [4/50], Step [328/735], Loss: 0.6787\n",
      "Epoch [4/50], Step [329/735], Loss: 0.2293\n",
      "Epoch [4/50], Step [330/735], Loss: 0.9552\n",
      "Epoch [4/50], Step [331/735], Loss: 0.6586\n",
      "Epoch [4/50], Step [332/735], Loss: 1.1787\n",
      "Epoch [4/50], Step [333/735], Loss: 0.5570\n",
      "Epoch [4/50], Step [334/735], Loss: 0.3548\n",
      "Epoch [4/50], Step [335/735], Loss: 0.7516\n",
      "Epoch [4/50], Step [336/735], Loss: 0.3693\n",
      "Epoch [4/50], Step [337/735], Loss: 0.1928\n",
      "Epoch [4/50], Step [338/735], Loss: 0.3427\n",
      "Epoch [4/50], Step [339/735], Loss: 0.2952\n",
      "Epoch [4/50], Step [340/735], Loss: 0.3587\n",
      "Epoch [4/50], Step [341/735], Loss: 0.4544\n",
      "Epoch [4/50], Step [342/735], Loss: 0.6762\n",
      "Epoch [4/50], Step [343/735], Loss: 0.1738\n",
      "Epoch [4/50], Step [344/735], Loss: 0.3879\n",
      "Epoch [4/50], Step [345/735], Loss: 0.5538\n",
      "Epoch [4/50], Step [346/735], Loss: 0.4681\n",
      "Epoch [4/50], Step [347/735], Loss: 0.2091\n",
      "Epoch [4/50], Step [348/735], Loss: 0.2078\n",
      "Epoch [4/50], Step [349/735], Loss: 2.0062\n",
      "Epoch [4/50], Step [350/735], Loss: 1.0125\n",
      "Epoch [4/50], Step [351/735], Loss: 0.8713\n",
      "Epoch [4/50], Step [352/735], Loss: 0.4823\n",
      "Epoch [4/50], Step [353/735], Loss: 0.7469\n",
      "Epoch [4/50], Step [354/735], Loss: 0.2498\n",
      "Epoch [4/50], Step [355/735], Loss: 0.5668\n",
      "Epoch [4/50], Step [356/735], Loss: 0.3229\n",
      "Epoch [4/50], Step [357/735], Loss: 0.5145\n",
      "Epoch [4/50], Step [358/735], Loss: 0.6602\n",
      "Epoch [4/50], Step [359/735], Loss: 0.2355\n",
      "Epoch [4/50], Step [360/735], Loss: 0.7327\n",
      "Epoch [4/50], Step [361/735], Loss: 0.3121\n",
      "Epoch [4/50], Step [362/735], Loss: 0.4419\n",
      "Epoch [4/50], Step [363/735], Loss: 0.3386\n",
      "Epoch [4/50], Step [364/735], Loss: 0.3056\n",
      "Epoch [4/50], Step [365/735], Loss: 1.8297\n",
      "Epoch [4/50], Step [366/735], Loss: 0.3009\n",
      "Epoch [4/50], Step [367/735], Loss: 0.4651\n",
      "Epoch [4/50], Step [368/735], Loss: 0.5578\n",
      "Epoch [4/50], Step [369/735], Loss: 0.3831\n",
      "Epoch [4/50], Step [370/735], Loss: 0.2510\n",
      "Epoch [4/50], Step [371/735], Loss: 0.3604\n",
      "Epoch [4/50], Step [372/735], Loss: 0.2592\n",
      "Epoch [4/50], Step [373/735], Loss: 0.5173\n",
      "Epoch [4/50], Step [374/735], Loss: 0.9958\n",
      "Epoch [4/50], Step [375/735], Loss: 0.4045\n",
      "Epoch [4/50], Step [376/735], Loss: 0.9364\n",
      "Epoch [4/50], Step [377/735], Loss: 0.5230\n",
      "Epoch [4/50], Step [378/735], Loss: 0.2834\n",
      "Epoch [4/50], Step [379/735], Loss: 0.4017\n",
      "Epoch [4/50], Step [380/735], Loss: 0.5810\n",
      "Epoch [4/50], Step [381/735], Loss: 0.2667\n",
      "Epoch [4/50], Step [382/735], Loss: 0.3361\n",
      "Epoch [4/50], Step [383/735], Loss: 0.1228\n",
      "Epoch [4/50], Step [384/735], Loss: 0.2959\n",
      "Epoch [4/50], Step [385/735], Loss: 0.6423\n",
      "Epoch [4/50], Step [386/735], Loss: 2.6090\n",
      "Epoch [4/50], Step [387/735], Loss: 0.4039\n",
      "Epoch [4/50], Step [388/735], Loss: 0.8236\n",
      "Epoch [4/50], Step [389/735], Loss: 0.3425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Step [390/735], Loss: 0.2989\n",
      "Epoch [4/50], Step [391/735], Loss: 0.1911\n",
      "Epoch [4/50], Step [392/735], Loss: 0.3392\n",
      "Epoch [4/50], Step [393/735], Loss: 0.5328\n",
      "Epoch [4/50], Step [394/735], Loss: 0.9325\n",
      "Epoch [4/50], Step [395/735], Loss: 0.5170\n",
      "Epoch [4/50], Step [396/735], Loss: 0.2445\n",
      "Epoch [4/50], Step [397/735], Loss: 0.5239\n",
      "Epoch [4/50], Step [398/735], Loss: 0.7056\n",
      "Epoch [4/50], Step [399/735], Loss: 1.0331\n",
      "Epoch [4/50], Step [400/735], Loss: 1.4465\n",
      "Epoch [4/50], Step [401/735], Loss: 0.2357\n",
      "Epoch [4/50], Step [402/735], Loss: 1.0918\n",
      "Epoch [4/50], Step [403/735], Loss: 0.3113\n",
      "Epoch [4/50], Step [404/735], Loss: 0.3073\n",
      "Epoch [4/50], Step [405/735], Loss: 0.2336\n",
      "Epoch [4/50], Step [406/735], Loss: 0.9773\n",
      "Epoch [4/50], Step [407/735], Loss: 0.6935\n",
      "Epoch [4/50], Step [408/735], Loss: 0.6639\n",
      "Epoch [4/50], Step [409/735], Loss: 0.8302\n",
      "Epoch [4/50], Step [410/735], Loss: 0.6234\n",
      "Epoch [4/50], Step [411/735], Loss: 0.3576\n",
      "Epoch [4/50], Step [412/735], Loss: 0.9122\n",
      "Epoch [4/50], Step [413/735], Loss: 0.6325\n",
      "Epoch [4/50], Step [414/735], Loss: 0.4660\n",
      "Epoch [4/50], Step [415/735], Loss: 1.4370\n",
      "Epoch [4/50], Step [416/735], Loss: 0.2030\n",
      "Epoch [4/50], Step [417/735], Loss: 0.3777\n",
      "Epoch [4/50], Step [418/735], Loss: 0.4145\n",
      "Epoch [4/50], Step [419/735], Loss: 0.3489\n",
      "Epoch [4/50], Step [420/735], Loss: 0.3851\n",
      "Epoch [4/50], Step [421/735], Loss: 0.3654\n",
      "Epoch [4/50], Step [422/735], Loss: 0.4436\n",
      "Epoch [4/50], Step [423/735], Loss: 0.3390\n",
      "Epoch [4/50], Step [424/735], Loss: 1.7153\n",
      "Epoch [4/50], Step [425/735], Loss: 1.6443\n",
      "Epoch [4/50], Step [426/735], Loss: 0.2491\n",
      "Epoch [4/50], Step [427/735], Loss: 0.3562\n",
      "Epoch [4/50], Step [428/735], Loss: 0.7058\n",
      "Epoch [4/50], Step [429/735], Loss: 0.4090\n",
      "Epoch [4/50], Step [430/735], Loss: 0.7860\n",
      "Epoch [4/50], Step [431/735], Loss: 0.6589\n",
      "Epoch [4/50], Step [432/735], Loss: 1.2536\n",
      "Epoch [4/50], Step [433/735], Loss: 1.3742\n",
      "Epoch [4/50], Step [434/735], Loss: 0.5327\n",
      "Epoch [4/50], Step [435/735], Loss: 0.1846\n",
      "Epoch [4/50], Step [436/735], Loss: 0.2458\n",
      "Epoch [4/50], Step [437/735], Loss: 1.0765\n",
      "Epoch [4/50], Step [438/735], Loss: 0.3845\n",
      "Epoch [4/50], Step [439/735], Loss: 1.0153\n",
      "Epoch [4/50], Step [440/735], Loss: 0.7033\n",
      "Epoch [4/50], Step [441/735], Loss: 2.0166\n",
      "Epoch [4/50], Step [442/735], Loss: 0.2650\n",
      "Epoch [4/50], Step [443/735], Loss: 0.7119\n",
      "Epoch [4/50], Step [444/735], Loss: 0.3416\n",
      "Epoch [4/50], Step [445/735], Loss: 0.3513\n",
      "Epoch [4/50], Step [446/735], Loss: 1.2525\n",
      "Epoch [4/50], Step [447/735], Loss: 0.6541\n",
      "Epoch [4/50], Step [448/735], Loss: 1.0459\n",
      "Epoch [4/50], Step [449/735], Loss: 0.9068\n",
      "Epoch [4/50], Step [450/735], Loss: 0.2748\n",
      "Epoch [4/50], Step [451/735], Loss: 0.5203\n",
      "Epoch [4/50], Step [452/735], Loss: 0.4082\n",
      "Epoch [4/50], Step [453/735], Loss: 1.8928\n",
      "Epoch [4/50], Step [454/735], Loss: 0.4997\n",
      "Epoch [4/50], Step [455/735], Loss: 0.5849\n",
      "Epoch [4/50], Step [456/735], Loss: 0.3654\n",
      "Epoch [4/50], Step [457/735], Loss: 3.3122\n",
      "Epoch [4/50], Step [458/735], Loss: 0.3686\n",
      "Epoch [4/50], Step [459/735], Loss: 1.5724\n",
      "Epoch [4/50], Step [460/735], Loss: 0.2560\n",
      "Epoch [4/50], Step [461/735], Loss: 1.1536\n",
      "Epoch [4/50], Step [462/735], Loss: 0.1606\n",
      "Epoch [4/50], Step [463/735], Loss: 0.1806\n",
      "Epoch [4/50], Step [464/735], Loss: 0.5473\n",
      "Epoch [4/50], Step [465/735], Loss: 0.1920\n",
      "Epoch [4/50], Step [466/735], Loss: 0.4637\n",
      "Epoch [4/50], Step [467/735], Loss: 0.9718\n",
      "Epoch [4/50], Step [468/735], Loss: 0.4364\n",
      "Epoch [4/50], Step [469/735], Loss: 0.3933\n",
      "Epoch [4/50], Step [470/735], Loss: 0.4076\n",
      "Epoch [4/50], Step [471/735], Loss: 1.0770\n",
      "Epoch [4/50], Step [472/735], Loss: 1.0197\n",
      "Epoch [4/50], Step [473/735], Loss: 1.5699\n",
      "Epoch [4/50], Step [474/735], Loss: 1.6338\n",
      "Epoch [4/50], Step [475/735], Loss: 0.3949\n",
      "Epoch [4/50], Step [476/735], Loss: 0.9105\n",
      "Epoch [4/50], Step [477/735], Loss: 0.1061\n",
      "Epoch [4/50], Step [478/735], Loss: 0.3672\n",
      "Epoch [4/50], Step [479/735], Loss: 0.2754\n",
      "Epoch [4/50], Step [480/735], Loss: 0.4164\n",
      "Epoch [4/50], Step [481/735], Loss: 0.6314\n",
      "Epoch [4/50], Step [482/735], Loss: 0.3521\n",
      "Epoch [4/50], Step [483/735], Loss: 0.2401\n",
      "Epoch [4/50], Step [484/735], Loss: 0.4618\n",
      "Epoch [4/50], Step [485/735], Loss: 0.4391\n",
      "Epoch [4/50], Step [486/735], Loss: 0.5595\n",
      "Epoch [4/50], Step [487/735], Loss: 1.6518\n",
      "Epoch [4/50], Step [488/735], Loss: 0.2834\n",
      "Epoch [4/50], Step [489/735], Loss: 0.2752\n",
      "Epoch [4/50], Step [490/735], Loss: 0.4263\n",
      "Epoch [4/50], Step [491/735], Loss: 0.4297\n",
      "Epoch [4/50], Step [492/735], Loss: 0.7701\n",
      "Epoch [4/50], Step [493/735], Loss: 0.3049\n",
      "Epoch [4/50], Step [494/735], Loss: 0.4716\n",
      "Epoch [4/50], Step [495/735], Loss: 0.3354\n",
      "Epoch [4/50], Step [496/735], Loss: 0.1786\n",
      "Epoch [4/50], Step [497/735], Loss: 0.3054\n",
      "Epoch [4/50], Step [498/735], Loss: 1.3592\n",
      "Epoch [4/50], Step [499/735], Loss: 0.4081\n",
      "Epoch [4/50], Step [500/735], Loss: 0.2208\n",
      "Epoch [4/50], Step [501/735], Loss: 0.7098\n",
      "Epoch [4/50], Step [502/735], Loss: 1.4846\n",
      "Epoch [4/50], Step [503/735], Loss: 1.0631\n",
      "Epoch [4/50], Step [504/735], Loss: 0.1965\n",
      "Epoch [4/50], Step [505/735], Loss: 0.8273\n",
      "Epoch [4/50], Step [506/735], Loss: 0.2701\n",
      "Epoch [4/50], Step [507/735], Loss: 0.3237\n",
      "Epoch [4/50], Step [508/735], Loss: 0.1935\n",
      "Epoch [4/50], Step [509/735], Loss: 2.0061\n",
      "Epoch [4/50], Step [510/735], Loss: 0.3357\n",
      "Epoch [4/50], Step [511/735], Loss: 0.5798\n",
      "Epoch [4/50], Step [512/735], Loss: 0.7056\n",
      "Epoch [4/50], Step [513/735], Loss: 0.6379\n",
      "Epoch [4/50], Step [514/735], Loss: 0.1615\n",
      "Epoch [4/50], Step [515/735], Loss: 0.5109\n",
      "Epoch [4/50], Step [516/735], Loss: 1.2405\n",
      "Epoch [4/50], Step [517/735], Loss: 0.3380\n",
      "Epoch [4/50], Step [518/735], Loss: 0.1504\n",
      "Epoch [4/50], Step [519/735], Loss: 0.4700\n",
      "Epoch [4/50], Step [520/735], Loss: 0.4992\n",
      "Epoch [4/50], Step [521/735], Loss: 0.4274\n",
      "Epoch [4/50], Step [522/735], Loss: 0.1469\n",
      "Epoch [4/50], Step [523/735], Loss: 0.3640\n",
      "Epoch [4/50], Step [524/735], Loss: 0.1910\n",
      "Epoch [4/50], Step [525/735], Loss: 0.4082\n",
      "Epoch [4/50], Step [526/735], Loss: 0.6409\n",
      "Epoch [4/50], Step [527/735], Loss: 0.4162\n",
      "Epoch [4/50], Step [528/735], Loss: 0.9804\n",
      "Epoch [4/50], Step [529/735], Loss: 0.3901\n",
      "Epoch [4/50], Step [530/735], Loss: 0.1923\n",
      "Epoch [4/50], Step [531/735], Loss: 1.2945\n",
      "Epoch [4/50], Step [532/735], Loss: 0.3191\n",
      "Epoch [4/50], Step [533/735], Loss: 0.4131\n",
      "Epoch [4/50], Step [534/735], Loss: 0.5612\n",
      "Epoch [4/50], Step [535/735], Loss: 1.0437\n",
      "Epoch [4/50], Step [536/735], Loss: 0.7516\n",
      "Epoch [4/50], Step [537/735], Loss: 1.1405\n",
      "Epoch [4/50], Step [538/735], Loss: 1.0572\n",
      "Epoch [4/50], Step [539/735], Loss: 0.4054\n",
      "Epoch [4/50], Step [540/735], Loss: 0.1401\n",
      "Epoch [4/50], Step [541/735], Loss: 0.4816\n",
      "Epoch [4/50], Step [542/735], Loss: 0.3988\n",
      "Epoch [4/50], Step [543/735], Loss: 0.4401\n",
      "Epoch [4/50], Step [544/735], Loss: 0.6155\n",
      "Epoch [4/50], Step [545/735], Loss: 0.4661\n",
      "Epoch [4/50], Step [546/735], Loss: 0.5017\n",
      "Epoch [4/50], Step [547/735], Loss: 0.2676\n",
      "Epoch [4/50], Step [548/735], Loss: 0.3735\n",
      "Epoch [4/50], Step [549/735], Loss: 1.3832\n",
      "Epoch [4/50], Step [550/735], Loss: 0.3726\n",
      "Epoch [4/50], Step [551/735], Loss: 0.9631\n",
      "Epoch [4/50], Step [552/735], Loss: 0.1699\n",
      "Epoch [4/50], Step [553/735], Loss: 0.4546\n",
      "Epoch [4/50], Step [554/735], Loss: 0.3774\n",
      "Epoch [4/50], Step [555/735], Loss: 0.2217\n",
      "Epoch [4/50], Step [556/735], Loss: 0.3720\n",
      "Epoch [4/50], Step [557/735], Loss: 0.7450\n",
      "Epoch [4/50], Step [558/735], Loss: 0.5007\n",
      "Epoch [4/50], Step [559/735], Loss: 0.3359\n",
      "Epoch [4/50], Step [560/735], Loss: 0.3826\n",
      "Epoch [4/50], Step [561/735], Loss: 0.9888\n",
      "Epoch [4/50], Step [562/735], Loss: 0.3229\n",
      "Epoch [4/50], Step [563/735], Loss: 0.3737\n",
      "Epoch [4/50], Step [564/735], Loss: 0.6121\n",
      "Epoch [4/50], Step [565/735], Loss: 1.5408\n",
      "Epoch [4/50], Step [566/735], Loss: 0.3907\n",
      "Epoch [4/50], Step [567/735], Loss: 0.2982\n",
      "Epoch [4/50], Step [568/735], Loss: 0.2876\n",
      "Epoch [4/50], Step [569/735], Loss: 3.8910\n",
      "Epoch [4/50], Step [570/735], Loss: 0.3222\n",
      "Epoch [4/50], Step [571/735], Loss: 0.2148\n",
      "Epoch [4/50], Step [572/735], Loss: 0.7158\n",
      "Epoch [4/50], Step [573/735], Loss: 0.5672\n",
      "Epoch [4/50], Step [574/735], Loss: 0.7084\n",
      "Epoch [4/50], Step [575/735], Loss: 0.2395\n",
      "Epoch [4/50], Step [576/735], Loss: 0.6815\n",
      "Epoch [4/50], Step [577/735], Loss: 1.1237\n",
      "Epoch [4/50], Step [578/735], Loss: 0.1899\n",
      "Epoch [4/50], Step [579/735], Loss: 0.2809\n",
      "Epoch [4/50], Step [580/735], Loss: 0.5608\n",
      "Epoch [4/50], Step [581/735], Loss: 0.1934\n",
      "Epoch [4/50], Step [582/735], Loss: 0.5225\n",
      "Epoch [4/50], Step [583/735], Loss: 0.2132\n",
      "Epoch [4/50], Step [584/735], Loss: 0.2537\n",
      "Epoch [4/50], Step [585/735], Loss: 0.3518\n",
      "Epoch [4/50], Step [586/735], Loss: 0.2305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Step [587/735], Loss: 0.2803\n",
      "Epoch [4/50], Step [588/735], Loss: 0.2775\n",
      "Epoch [4/50], Step [589/735], Loss: 0.6128\n",
      "Epoch [4/50], Step [590/735], Loss: 0.3620\n",
      "Epoch [4/50], Step [591/735], Loss: 0.3198\n",
      "Epoch [4/50], Step [592/735], Loss: 2.7347\n",
      "Epoch [4/50], Step [593/735], Loss: 2.9540\n",
      "Epoch [4/50], Step [594/735], Loss: 0.5180\n",
      "Epoch [4/50], Step [595/735], Loss: 0.2564\n",
      "Epoch [4/50], Step [596/735], Loss: 0.2104\n",
      "Epoch [4/50], Step [597/735], Loss: 0.3600\n",
      "Epoch [4/50], Step [598/735], Loss: 0.6527\n",
      "Epoch [4/50], Step [599/735], Loss: 0.3096\n",
      "Epoch [4/50], Step [600/735], Loss: 0.3960\n",
      "Epoch [4/50], Step [601/735], Loss: 0.2906\n",
      "Epoch [4/50], Step [602/735], Loss: 2.0949\n",
      "Epoch [4/50], Step [603/735], Loss: 0.9289\n",
      "Epoch [4/50], Step [604/735], Loss: 1.2098\n",
      "Epoch [4/50], Step [605/735], Loss: 0.8614\n",
      "Epoch [4/50], Step [606/735], Loss: 0.2512\n",
      "Epoch [4/50], Step [607/735], Loss: 0.7562\n",
      "Epoch [4/50], Step [608/735], Loss: 1.5977\n",
      "Epoch [4/50], Step [609/735], Loss: 0.2937\n",
      "Epoch [4/50], Step [610/735], Loss: 2.1263\n",
      "Epoch [4/50], Step [611/735], Loss: 0.5911\n",
      "Epoch [4/50], Step [612/735], Loss: 0.2296\n",
      "Epoch [4/50], Step [613/735], Loss: 0.6533\n",
      "Epoch [4/50], Step [614/735], Loss: 0.2269\n",
      "Epoch [4/50], Step [615/735], Loss: 0.4955\n",
      "Epoch [4/50], Step [616/735], Loss: 0.7623\n",
      "Epoch [4/50], Step [617/735], Loss: 0.4093\n",
      "Epoch [4/50], Step [618/735], Loss: 5.4908\n",
      "Epoch [4/50], Step [619/735], Loss: 0.6673\n",
      "Epoch [4/50], Step [620/735], Loss: 0.6808\n",
      "Epoch [4/50], Step [621/735], Loss: 0.3515\n",
      "Epoch [4/50], Step [622/735], Loss: 0.1399\n",
      "Epoch [4/50], Step [623/735], Loss: 0.3233\n",
      "Epoch [4/50], Step [624/735], Loss: 0.8527\n",
      "Epoch [4/50], Step [625/735], Loss: 0.3874\n",
      "Epoch [4/50], Step [626/735], Loss: 0.3965\n",
      "Epoch [4/50], Step [627/735], Loss: 0.5665\n",
      "Epoch [4/50], Step [628/735], Loss: 0.7742\n",
      "Epoch [4/50], Step [629/735], Loss: 0.5804\n",
      "Epoch [4/50], Step [630/735], Loss: 0.5242\n",
      "Epoch [4/50], Step [631/735], Loss: 0.1713\n",
      "Epoch [4/50], Step [632/735], Loss: 0.2640\n",
      "Epoch [4/50], Step [633/735], Loss: 0.3629\n",
      "Epoch [4/50], Step [634/735], Loss: 0.3730\n",
      "Epoch [4/50], Step [635/735], Loss: 1.6423\n",
      "Epoch [4/50], Step [636/735], Loss: 0.8341\n",
      "Epoch [4/50], Step [637/735], Loss: 0.9681\n",
      "Epoch [4/50], Step [638/735], Loss: 0.5111\n",
      "Epoch [4/50], Step [639/735], Loss: 2.2899\n",
      "Epoch [4/50], Step [640/735], Loss: 0.6110\n",
      "Epoch [4/50], Step [641/735], Loss: 0.6762\n",
      "Epoch [4/50], Step [642/735], Loss: 0.8357\n",
      "Epoch [4/50], Step [643/735], Loss: 0.4472\n",
      "Epoch [4/50], Step [644/735], Loss: 0.1868\n",
      "Epoch [4/50], Step [645/735], Loss: 0.2568\n",
      "Epoch [4/50], Step [646/735], Loss: 0.5250\n",
      "Epoch [4/50], Step [647/735], Loss: 0.6440\n",
      "Epoch [4/50], Step [648/735], Loss: 0.5447\n",
      "Epoch [4/50], Step [649/735], Loss: 1.0030\n",
      "Epoch [4/50], Step [650/735], Loss: 0.3330\n",
      "Epoch [4/50], Step [651/735], Loss: 0.2771\n",
      "Epoch [4/50], Step [652/735], Loss: 0.8017\n",
      "Epoch [4/50], Step [653/735], Loss: 0.4225\n",
      "Epoch [4/50], Step [654/735], Loss: 1.3365\n",
      "Epoch [4/50], Step [655/735], Loss: 0.1710\n",
      "Epoch [4/50], Step [656/735], Loss: 0.8981\n",
      "Epoch [4/50], Step [657/735], Loss: 0.2264\n",
      "Epoch [4/50], Step [658/735], Loss: 0.8209\n",
      "Epoch [4/50], Step [659/735], Loss: 0.2848\n",
      "Epoch [4/50], Step [660/735], Loss: 0.5461\n",
      "Epoch [4/50], Step [661/735], Loss: 0.3661\n",
      "Epoch [4/50], Step [662/735], Loss: 0.3283\n",
      "Epoch [4/50], Step [663/735], Loss: 0.2440\n",
      "Epoch [4/50], Step [664/735], Loss: 0.3135\n",
      "Epoch [4/50], Step [665/735], Loss: 0.2085\n",
      "Epoch [4/50], Step [666/735], Loss: 1.1210\n",
      "Epoch [4/50], Step [667/735], Loss: 0.6144\n",
      "Epoch [4/50], Step [668/735], Loss: 0.3142\n",
      "Epoch [4/50], Step [669/735], Loss: 1.2395\n",
      "Epoch [4/50], Step [670/735], Loss: 1.2287\n",
      "Epoch [4/50], Step [671/735], Loss: 0.6765\n",
      "Epoch [4/50], Step [672/735], Loss: 0.2837\n",
      "Epoch [4/50], Step [673/735], Loss: 0.3275\n",
      "Epoch [4/50], Step [674/735], Loss: 1.1336\n",
      "Epoch [4/50], Step [675/735], Loss: 0.4968\n",
      "Epoch [4/50], Step [676/735], Loss: 0.4922\n",
      "Epoch [4/50], Step [677/735], Loss: 0.1237\n",
      "Epoch [4/50], Step [678/735], Loss: 0.2525\n",
      "Epoch [4/50], Step [679/735], Loss: 0.2915\n",
      "Epoch [4/50], Step [680/735], Loss: 0.7830\n",
      "Epoch [4/50], Step [681/735], Loss: 0.5973\n",
      "Epoch [4/50], Step [682/735], Loss: 0.1915\n",
      "Epoch [4/50], Step [683/735], Loss: 0.2667\n",
      "Epoch [4/50], Step [684/735], Loss: 0.2818\n",
      "Epoch [4/50], Step [685/735], Loss: 2.2195\n",
      "Epoch [4/50], Step [686/735], Loss: 0.6378\n",
      "Epoch [4/50], Step [687/735], Loss: 0.2764\n",
      "Epoch [4/50], Step [688/735], Loss: 0.5812\n",
      "Epoch [4/50], Step [689/735], Loss: 0.7512\n",
      "Epoch [4/50], Step [690/735], Loss: 0.5775\n",
      "Epoch [4/50], Step [691/735], Loss: 0.5447\n",
      "Epoch [4/50], Step [692/735], Loss: 0.5464\n",
      "Epoch [4/50], Step [693/735], Loss: 0.3138\n",
      "Epoch [4/50], Step [694/735], Loss: 0.1511\n",
      "Epoch [4/50], Step [695/735], Loss: 0.4965\n",
      "Epoch [4/50], Step [696/735], Loss: 0.2508\n",
      "Epoch [4/50], Step [697/735], Loss: 0.3696\n",
      "Epoch [4/50], Step [698/735], Loss: 0.6742\n",
      "Epoch [4/50], Step [699/735], Loss: 1.6915\n",
      "Epoch [4/50], Step [700/735], Loss: 0.2104\n",
      "Epoch [4/50], Step [701/735], Loss: 0.2510\n",
      "Epoch [4/50], Step [702/735], Loss: 0.3963\n",
      "Epoch [4/50], Step [703/735], Loss: 1.1086\n",
      "Epoch [4/50], Step [704/735], Loss: 0.5821\n",
      "Epoch [4/50], Step [705/735], Loss: 0.4299\n",
      "Epoch [4/50], Step [706/735], Loss: 0.3075\n",
      "Epoch [4/50], Step [707/735], Loss: 1.4699\n",
      "Epoch [4/50], Step [708/735], Loss: 0.2140\n",
      "Epoch [4/50], Step [709/735], Loss: 1.1197\n",
      "Epoch [4/50], Step [710/735], Loss: 0.3161\n",
      "Epoch [4/50], Step [711/735], Loss: 0.2520\n",
      "Epoch [4/50], Step [712/735], Loss: 1.4444\n",
      "Epoch [4/50], Step [713/735], Loss: 0.7249\n",
      "Epoch [4/50], Step [714/735], Loss: 1.2939\n",
      "Epoch [4/50], Step [715/735], Loss: 0.1610\n",
      "Epoch [4/50], Step [716/735], Loss: 0.5988\n",
      "Epoch [4/50], Step [717/735], Loss: 1.0197\n",
      "Epoch [4/50], Step [718/735], Loss: 0.5534\n",
      "Epoch [4/50], Step [719/735], Loss: 0.5238\n",
      "Epoch [4/50], Step [720/735], Loss: 0.7769\n",
      "Epoch [4/50], Step [721/735], Loss: 0.3235\n",
      "Epoch [4/50], Step [722/735], Loss: 1.1380\n",
      "Epoch [4/50], Step [723/735], Loss: 0.6316\n",
      "Epoch [4/50], Step [724/735], Loss: 0.4729\n",
      "Epoch [4/50], Step [725/735], Loss: 0.5875\n",
      "Epoch [4/50], Step [726/735], Loss: 0.3375\n",
      "Epoch [4/50], Step [727/735], Loss: 0.1908\n",
      "Epoch [4/50], Step [728/735], Loss: 0.5825\n",
      "Epoch [4/50], Step [729/735], Loss: 0.3482\n",
      "Epoch [4/50], Step [730/735], Loss: 0.9369\n",
      "Epoch [4/50], Step [731/735], Loss: 0.6990\n",
      "Epoch [4/50], Step [732/735], Loss: 0.4586\n",
      "Epoch [4/50], Step [733/735], Loss: 0.4030\n",
      "Epoch [4/50], Step [734/735], Loss: 0.1569\n",
      "Epoch [4/50], Step [735/735], Loss: 0.2027\n",
      "Epoch [5/50], Step [1/735], Loss: 0.3890\n",
      "Epoch [5/50], Step [2/735], Loss: 0.1920\n",
      "Epoch [5/50], Step [3/735], Loss: 1.1522\n",
      "Epoch [5/50], Step [4/735], Loss: 0.7361\n",
      "Epoch [5/50], Step [5/735], Loss: 0.6916\n",
      "Epoch [5/50], Step [6/735], Loss: 0.9137\n",
      "Epoch [5/50], Step [7/735], Loss: 0.6002\n",
      "Epoch [5/50], Step [8/735], Loss: 0.5727\n",
      "Epoch [5/50], Step [9/735], Loss: 0.3671\n",
      "Epoch [5/50], Step [10/735], Loss: 0.1788\n",
      "Epoch [5/50], Step [11/735], Loss: 0.4685\n",
      "Epoch [5/50], Step [12/735], Loss: 0.4751\n",
      "Epoch [5/50], Step [13/735], Loss: 0.3243\n",
      "Epoch [5/50], Step [14/735], Loss: 0.2912\n",
      "Epoch [5/50], Step [15/735], Loss: 0.4235\n",
      "Epoch [5/50], Step [16/735], Loss: 0.9091\n",
      "Epoch [5/50], Step [17/735], Loss: 0.9280\n",
      "Epoch [5/50], Step [18/735], Loss: 0.4651\n",
      "Epoch [5/50], Step [19/735], Loss: 3.0367\n",
      "Epoch [5/50], Step [20/735], Loss: 0.2318\n",
      "Epoch [5/50], Step [21/735], Loss: 0.5444\n",
      "Epoch [5/50], Step [22/735], Loss: 0.5596\n",
      "Epoch [5/50], Step [23/735], Loss: 0.4355\n",
      "Epoch [5/50], Step [24/735], Loss: 1.0642\n",
      "Epoch [5/50], Step [25/735], Loss: 3.0555\n",
      "Epoch [5/50], Step [26/735], Loss: 0.5668\n",
      "Epoch [5/50], Step [27/735], Loss: 0.4926\n",
      "Epoch [5/50], Step [28/735], Loss: 0.3730\n",
      "Epoch [5/50], Step [29/735], Loss: 0.3457\n",
      "Epoch [5/50], Step [30/735], Loss: 0.2369\n",
      "Epoch [5/50], Step [31/735], Loss: 0.7897\n",
      "Epoch [5/50], Step [32/735], Loss: 0.4779\n",
      "Epoch [5/50], Step [33/735], Loss: 0.1906\n",
      "Epoch [5/50], Step [34/735], Loss: 1.0816\n",
      "Epoch [5/50], Step [35/735], Loss: 0.7738\n",
      "Epoch [5/50], Step [36/735], Loss: 0.3644\n",
      "Epoch [5/50], Step [37/735], Loss: 0.2019\n",
      "Epoch [5/50], Step [38/735], Loss: 0.6046\n",
      "Epoch [5/50], Step [39/735], Loss: 1.6778\n",
      "Epoch [5/50], Step [40/735], Loss: 0.1617\n",
      "Epoch [5/50], Step [41/735], Loss: 1.0794\n",
      "Epoch [5/50], Step [42/735], Loss: 0.5302\n",
      "Epoch [5/50], Step [43/735], Loss: 1.2645\n",
      "Epoch [5/50], Step [44/735], Loss: 0.4577\n",
      "Epoch [5/50], Step [45/735], Loss: 0.8676\n",
      "Epoch [5/50], Step [46/735], Loss: 0.3285\n",
      "Epoch [5/50], Step [47/735], Loss: 0.1896\n",
      "Epoch [5/50], Step [48/735], Loss: 0.9661\n",
      "Epoch [5/50], Step [49/735], Loss: 0.2591\n",
      "Epoch [5/50], Step [50/735], Loss: 1.2609\n",
      "Epoch [5/50], Step [51/735], Loss: 0.3627\n",
      "Epoch [5/50], Step [52/735], Loss: 0.2600\n",
      "Epoch [5/50], Step [53/735], Loss: 0.2774\n",
      "Epoch [5/50], Step [54/735], Loss: 0.4120\n",
      "Epoch [5/50], Step [55/735], Loss: 0.8358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Step [56/735], Loss: 0.4434\n",
      "Epoch [5/50], Step [57/735], Loss: 0.3197\n",
      "Epoch [5/50], Step [58/735], Loss: 0.3272\n",
      "Epoch [5/50], Step [59/735], Loss: 0.2071\n",
      "Epoch [5/50], Step [60/735], Loss: 0.4953\n",
      "Epoch [5/50], Step [61/735], Loss: 0.2386\n",
      "Epoch [5/50], Step [62/735], Loss: 1.1492\n",
      "Epoch [5/50], Step [63/735], Loss: 0.4199\n",
      "Epoch [5/50], Step [64/735], Loss: 0.6565\n",
      "Epoch [5/50], Step [65/735], Loss: 1.2498\n",
      "Epoch [5/50], Step [66/735], Loss: 0.4859\n",
      "Epoch [5/50], Step [67/735], Loss: 0.9496\n",
      "Epoch [5/50], Step [68/735], Loss: 0.5879\n",
      "Epoch [5/50], Step [69/735], Loss: 0.4219\n",
      "Epoch [5/50], Step [70/735], Loss: 1.1540\n",
      "Epoch [5/50], Step [71/735], Loss: 0.7268\n",
      "Epoch [5/50], Step [72/735], Loss: 1.1251\n",
      "Epoch [5/50], Step [73/735], Loss: 0.5524\n",
      "Epoch [5/50], Step [74/735], Loss: 0.2129\n",
      "Epoch [5/50], Step [75/735], Loss: 1.4891\n",
      "Epoch [5/50], Step [76/735], Loss: 0.3044\n",
      "Epoch [5/50], Step [77/735], Loss: 0.9764\n",
      "Epoch [5/50], Step [78/735], Loss: 4.9570\n",
      "Epoch [5/50], Step [79/735], Loss: 0.2746\n",
      "Epoch [5/50], Step [80/735], Loss: 0.4905\n",
      "Epoch [5/50], Step [81/735], Loss: 0.3128\n",
      "Epoch [5/50], Step [82/735], Loss: 0.4673\n",
      "Epoch [5/50], Step [83/735], Loss: 0.1774\n",
      "Epoch [5/50], Step [84/735], Loss: 0.5409\n",
      "Epoch [5/50], Step [85/735], Loss: 1.0156\n",
      "Epoch [5/50], Step [86/735], Loss: 0.3297\n",
      "Epoch [5/50], Step [87/735], Loss: 1.2377\n",
      "Epoch [5/50], Step [88/735], Loss: 0.1405\n",
      "Epoch [5/50], Step [89/735], Loss: 0.2996\n",
      "Epoch [5/50], Step [90/735], Loss: 0.8000\n",
      "Epoch [5/50], Step [91/735], Loss: 0.4241\n",
      "Epoch [5/50], Step [92/735], Loss: 0.5578\n",
      "Epoch [5/50], Step [93/735], Loss: 0.6738\n",
      "Epoch [5/50], Step [94/735], Loss: 0.2150\n",
      "Epoch [5/50], Step [95/735], Loss: 0.3684\n",
      "Epoch [5/50], Step [96/735], Loss: 0.4382\n",
      "Epoch [5/50], Step [97/735], Loss: 0.5415\n",
      "Epoch [5/50], Step [98/735], Loss: 0.7657\n",
      "Epoch [5/50], Step [99/735], Loss: 0.7706\n",
      "Epoch [5/50], Step [100/735], Loss: 0.3363\n",
      "Epoch [5/50], Step [101/735], Loss: 0.4108\n",
      "Epoch [5/50], Step [102/735], Loss: 0.3586\n",
      "Epoch [5/50], Step [103/735], Loss: 0.1654\n",
      "Epoch [5/50], Step [104/735], Loss: 0.2931\n",
      "Epoch [5/50], Step [105/735], Loss: 0.2125\n",
      "Epoch [5/50], Step [106/735], Loss: 0.5375\n",
      "Epoch [5/50], Step [107/735], Loss: 0.9224\n",
      "Epoch [5/50], Step [108/735], Loss: 0.4598\n",
      "Epoch [5/50], Step [109/735], Loss: 0.8811\n",
      "Epoch [5/50], Step [110/735], Loss: 0.7678\n",
      "Epoch [5/50], Step [111/735], Loss: 0.6255\n",
      "Epoch [5/50], Step [112/735], Loss: 0.5763\n",
      "Epoch [5/50], Step [113/735], Loss: 0.2665\n",
      "Epoch [5/50], Step [114/735], Loss: 0.3968\n",
      "Epoch [5/50], Step [115/735], Loss: 0.4332\n",
      "Epoch [5/50], Step [116/735], Loss: 0.3961\n",
      "Epoch [5/50], Step [117/735], Loss: 0.6259\n",
      "Epoch [5/50], Step [118/735], Loss: 0.7819\n",
      "Epoch [5/50], Step [119/735], Loss: 0.4621\n",
      "Epoch [5/50], Step [120/735], Loss: 2.8057\n",
      "Epoch [5/50], Step [121/735], Loss: 0.6046\n",
      "Epoch [5/50], Step [122/735], Loss: 0.8385\n",
      "Epoch [5/50], Step [123/735], Loss: 0.1388\n",
      "Epoch [5/50], Step [124/735], Loss: 0.8311\n",
      "Epoch [5/50], Step [125/735], Loss: 0.3838\n",
      "Epoch [5/50], Step [126/735], Loss: 0.5516\n",
      "Epoch [5/50], Step [127/735], Loss: 0.8918\n",
      "Epoch [5/50], Step [128/735], Loss: 1.3032\n",
      "Epoch [5/50], Step [129/735], Loss: 1.2280\n",
      "Epoch [5/50], Step [130/735], Loss: 0.3253\n",
      "Epoch [5/50], Step [131/735], Loss: 0.4428\n",
      "Epoch [5/50], Step [132/735], Loss: 0.4889\n",
      "Epoch [5/50], Step [133/735], Loss: 0.7396\n",
      "Epoch [5/50], Step [134/735], Loss: 0.2657\n",
      "Epoch [5/50], Step [135/735], Loss: 0.9342\n",
      "Epoch [5/50], Step [136/735], Loss: 0.6541\n",
      "Epoch [5/50], Step [137/735], Loss: 0.8615\n",
      "Epoch [5/50], Step [138/735], Loss: 0.2264\n",
      "Epoch [5/50], Step [139/735], Loss: 1.1665\n",
      "Epoch [5/50], Step [140/735], Loss: 0.2798\n",
      "Epoch [5/50], Step [141/735], Loss: 0.2773\n",
      "Epoch [5/50], Step [142/735], Loss: 0.5622\n",
      "Epoch [5/50], Step [143/735], Loss: 0.3421\n",
      "Epoch [5/50], Step [144/735], Loss: 0.1900\n",
      "Epoch [5/50], Step [145/735], Loss: 0.6347\n",
      "Epoch [5/50], Step [146/735], Loss: 0.7931\n",
      "Epoch [5/50], Step [147/735], Loss: 0.1334\n",
      "Epoch [5/50], Step [148/735], Loss: 0.1533\n",
      "Epoch [5/50], Step [149/735], Loss: 0.5149\n",
      "Epoch [5/50], Step [150/735], Loss: 2.3756\n",
      "Epoch [5/50], Step [151/735], Loss: 0.2556\n",
      "Epoch [5/50], Step [152/735], Loss: 0.3386\n",
      "Epoch [5/50], Step [153/735], Loss: 0.2497\n",
      "Epoch [5/50], Step [154/735], Loss: 0.6784\n",
      "Epoch [5/50], Step [155/735], Loss: 1.0242\n",
      "Epoch [5/50], Step [156/735], Loss: 0.1593\n",
      "Epoch [5/50], Step [157/735], Loss: 0.4363\n",
      "Epoch [5/50], Step [158/735], Loss: 0.3150\n",
      "Epoch [5/50], Step [159/735], Loss: 1.5304\n",
      "Epoch [5/50], Step [160/735], Loss: 0.2003\n",
      "Epoch [5/50], Step [161/735], Loss: 0.9534\n",
      "Epoch [5/50], Step [162/735], Loss: 0.4708\n",
      "Epoch [5/50], Step [163/735], Loss: 0.7860\n",
      "Epoch [5/50], Step [164/735], Loss: 0.4610\n",
      "Epoch [5/50], Step [165/735], Loss: 0.2266\n",
      "Epoch [5/50], Step [166/735], Loss: 0.2025\n",
      "Epoch [5/50], Step [167/735], Loss: 0.3499\n",
      "Epoch [5/50], Step [168/735], Loss: 0.5867\n",
      "Epoch [5/50], Step [169/735], Loss: 0.4434\n",
      "Epoch [5/50], Step [170/735], Loss: 0.3969\n",
      "Epoch [5/50], Step [171/735], Loss: 0.4200\n",
      "Epoch [5/50], Step [172/735], Loss: 0.2551\n",
      "Epoch [5/50], Step [173/735], Loss: 0.2708\n",
      "Epoch [5/50], Step [174/735], Loss: 0.6576\n",
      "Epoch [5/50], Step [175/735], Loss: 0.6074\n",
      "Epoch [5/50], Step [176/735], Loss: 1.0018\n",
      "Epoch [5/50], Step [177/735], Loss: 0.4260\n",
      "Epoch [5/50], Step [178/735], Loss: 0.3304\n",
      "Epoch [5/50], Step [179/735], Loss: 0.7241\n",
      "Epoch [5/50], Step [180/735], Loss: 0.3620\n",
      "Epoch [5/50], Step [181/735], Loss: 0.2362\n",
      "Epoch [5/50], Step [182/735], Loss: 0.5403\n",
      "Epoch [5/50], Step [183/735], Loss: 0.5543\n",
      "Epoch [5/50], Step [184/735], Loss: 0.9740\n",
      "Epoch [5/50], Step [185/735], Loss: 0.5111\n",
      "Epoch [5/50], Step [186/735], Loss: 0.6015\n",
      "Epoch [5/50], Step [187/735], Loss: 0.4245\n",
      "Epoch [5/50], Step [188/735], Loss: 1.1043\n",
      "Epoch [5/50], Step [189/735], Loss: 0.6957\n",
      "Epoch [5/50], Step [190/735], Loss: 0.5428\n",
      "Epoch [5/50], Step [191/735], Loss: 0.1859\n",
      "Epoch [5/50], Step [192/735], Loss: 0.2203\n",
      "Epoch [5/50], Step [193/735], Loss: 1.0854\n",
      "Epoch [5/50], Step [194/735], Loss: 0.5754\n",
      "Epoch [5/50], Step [195/735], Loss: 0.2695\n",
      "Epoch [5/50], Step [196/735], Loss: 0.6139\n",
      "Epoch [5/50], Step [197/735], Loss: 0.6199\n",
      "Epoch [5/50], Step [198/735], Loss: 0.2536\n",
      "Epoch [5/50], Step [199/735], Loss: 0.3470\n",
      "Epoch [5/50], Step [200/735], Loss: 0.2168\n",
      "Epoch [5/50], Step [201/735], Loss: 0.3770\n",
      "Epoch [5/50], Step [202/735], Loss: 0.5979\n",
      "Epoch [5/50], Step [203/735], Loss: 0.2011\n",
      "Epoch [5/50], Step [204/735], Loss: 0.3172\n",
      "Epoch [5/50], Step [205/735], Loss: 0.1752\n",
      "Epoch [5/50], Step [206/735], Loss: 0.3368\n",
      "Epoch [5/50], Step [207/735], Loss: 0.4660\n",
      "Epoch [5/50], Step [208/735], Loss: 0.7693\n",
      "Epoch [5/50], Step [209/735], Loss: 0.6010\n",
      "Epoch [5/50], Step [210/735], Loss: 0.6612\n",
      "Epoch [5/50], Step [211/735], Loss: 5.6888\n",
      "Epoch [5/50], Step [212/735], Loss: 2.3177\n",
      "Epoch [5/50], Step [213/735], Loss: 0.2643\n",
      "Epoch [5/50], Step [214/735], Loss: 0.2853\n",
      "Epoch [5/50], Step [215/735], Loss: 0.2903\n",
      "Epoch [5/50], Step [216/735], Loss: 0.6500\n",
      "Epoch [5/50], Step [217/735], Loss: 0.4017\n",
      "Epoch [5/50], Step [218/735], Loss: 0.5071\n",
      "Epoch [5/50], Step [219/735], Loss: 0.5896\n",
      "Epoch [5/50], Step [220/735], Loss: 0.8654\n",
      "Epoch [5/50], Step [221/735], Loss: 0.4240\n",
      "Epoch [5/50], Step [222/735], Loss: 0.3693\n",
      "Epoch [5/50], Step [223/735], Loss: 1.3731\n",
      "Epoch [5/50], Step [224/735], Loss: 0.2808\n",
      "Epoch [5/50], Step [225/735], Loss: 0.3175\n",
      "Epoch [5/50], Step [226/735], Loss: 0.3373\n",
      "Epoch [5/50], Step [227/735], Loss: 0.4099\n",
      "Epoch [5/50], Step [228/735], Loss: 0.4152\n",
      "Epoch [5/50], Step [229/735], Loss: 0.8900\n",
      "Epoch [5/50], Step [230/735], Loss: 0.5995\n",
      "Epoch [5/50], Step [231/735], Loss: 0.1284\n",
      "Epoch [5/50], Step [232/735], Loss: 0.6509\n",
      "Epoch [5/50], Step [233/735], Loss: 0.9630\n",
      "Epoch [5/50], Step [234/735], Loss: 1.1795\n",
      "Epoch [5/50], Step [235/735], Loss: 0.2904\n",
      "Epoch [5/50], Step [236/735], Loss: 0.5171\n",
      "Epoch [5/50], Step [237/735], Loss: 0.2598\n",
      "Epoch [5/50], Step [238/735], Loss: 0.3318\n",
      "Epoch [5/50], Step [239/735], Loss: 0.2126\n",
      "Epoch [5/50], Step [240/735], Loss: 0.6111\n",
      "Epoch [5/50], Step [241/735], Loss: 0.9118\n",
      "Epoch [5/50], Step [242/735], Loss: 0.4953\n",
      "Epoch [5/50], Step [243/735], Loss: 1.0676\n",
      "Epoch [5/50], Step [244/735], Loss: 0.4740\n",
      "Epoch [5/50], Step [245/735], Loss: 0.1482\n",
      "Epoch [5/50], Step [246/735], Loss: 0.2402\n",
      "Epoch [5/50], Step [247/735], Loss: 0.2619\n",
      "Epoch [5/50], Step [248/735], Loss: 0.2922\n",
      "Epoch [5/50], Step [249/735], Loss: 0.4565\n",
      "Epoch [5/50], Step [250/735], Loss: 0.5871\n",
      "Epoch [5/50], Step [251/735], Loss: 0.1337\n",
      "Epoch [5/50], Step [252/735], Loss: 0.4240\n",
      "Epoch [5/50], Step [253/735], Loss: 0.9479\n",
      "Epoch [5/50], Step [254/735], Loss: 0.2165\n",
      "Epoch [5/50], Step [255/735], Loss: 1.8377\n",
      "Epoch [5/50], Step [256/735], Loss: 1.6829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Step [257/735], Loss: 0.5188\n",
      "Epoch [5/50], Step [258/735], Loss: 0.9980\n",
      "Epoch [5/50], Step [259/735], Loss: 0.4594\n",
      "Epoch [5/50], Step [260/735], Loss: 0.4410\n",
      "Epoch [5/50], Step [261/735], Loss: 0.9096\n",
      "Epoch [5/50], Step [262/735], Loss: 0.8371\n",
      "Epoch [5/50], Step [263/735], Loss: 0.9777\n",
      "Epoch [5/50], Step [264/735], Loss: 0.5950\n",
      "Epoch [5/50], Step [265/735], Loss: 0.7229\n",
      "Epoch [5/50], Step [266/735], Loss: 0.2835\n",
      "Epoch [5/50], Step [267/735], Loss: 0.4006\n",
      "Epoch [5/50], Step [268/735], Loss: 0.2377\n",
      "Epoch [5/50], Step [269/735], Loss: 1.0191\n",
      "Epoch [5/50], Step [270/735], Loss: 0.9894\n",
      "Epoch [5/50], Step [271/735], Loss: 1.2082\n",
      "Epoch [5/50], Step [272/735], Loss: 0.4905\n",
      "Epoch [5/50], Step [273/735], Loss: 0.3202\n",
      "Epoch [5/50], Step [274/735], Loss: 0.2978\n",
      "Epoch [5/50], Step [275/735], Loss: 0.4339\n",
      "Epoch [5/50], Step [276/735], Loss: 0.5334\n",
      "Epoch [5/50], Step [277/735], Loss: 0.2986\n",
      "Epoch [5/50], Step [278/735], Loss: 0.3957\n",
      "Epoch [5/50], Step [279/735], Loss: 0.4759\n",
      "Epoch [5/50], Step [280/735], Loss: 0.3853\n",
      "Epoch [5/50], Step [281/735], Loss: 0.4084\n",
      "Epoch [5/50], Step [282/735], Loss: 0.9678\n",
      "Epoch [5/50], Step [283/735], Loss: 0.5150\n",
      "Epoch [5/50], Step [284/735], Loss: 0.2592\n",
      "Epoch [5/50], Step [285/735], Loss: 0.2133\n",
      "Epoch [5/50], Step [286/735], Loss: 1.7502\n",
      "Epoch [5/50], Step [287/735], Loss: 0.4112\n",
      "Epoch [5/50], Step [288/735], Loss: 0.3978\n",
      "Epoch [5/50], Step [289/735], Loss: 0.2566\n",
      "Epoch [5/50], Step [290/735], Loss: 0.1635\n",
      "Epoch [5/50], Step [291/735], Loss: 1.4367\n",
      "Epoch [5/50], Step [292/735], Loss: 0.2730\n",
      "Epoch [5/50], Step [293/735], Loss: 0.5351\n",
      "Epoch [5/50], Step [294/735], Loss: 0.2517\n",
      "Epoch [5/50], Step [295/735], Loss: 0.5664\n",
      "Epoch [5/50], Step [296/735], Loss: 1.0128\n",
      "Epoch [5/50], Step [297/735], Loss: 0.3726\n",
      "Epoch [5/50], Step [298/735], Loss: 0.3677\n",
      "Epoch [5/50], Step [299/735], Loss: 2.0662\n",
      "Epoch [5/50], Step [300/735], Loss: 0.5120\n",
      "Epoch [5/50], Step [301/735], Loss: 0.1759\n",
      "Epoch [5/50], Step [302/735], Loss: 0.4830\n",
      "Epoch [5/50], Step [303/735], Loss: 0.1908\n",
      "Epoch [5/50], Step [304/735], Loss: 0.2655\n",
      "Epoch [5/50], Step [305/735], Loss: 0.4812\n",
      "Epoch [5/50], Step [306/735], Loss: 0.3065\n",
      "Epoch [5/50], Step [307/735], Loss: 0.3426\n",
      "Epoch [5/50], Step [308/735], Loss: 0.3288\n",
      "Epoch [5/50], Step [309/735], Loss: 1.0352\n",
      "Epoch [5/50], Step [310/735], Loss: 1.3862\n",
      "Epoch [5/50], Step [311/735], Loss: 0.4225\n",
      "Epoch [5/50], Step [312/735], Loss: 0.4833\n",
      "Epoch [5/50], Step [313/735], Loss: 0.2462\n",
      "Epoch [5/50], Step [314/735], Loss: 0.3801\n",
      "Epoch [5/50], Step [315/735], Loss: 0.5128\n",
      "Epoch [5/50], Step [316/735], Loss: 0.7108\n",
      "Epoch [5/50], Step [317/735], Loss: 0.4106\n",
      "Epoch [5/50], Step [318/735], Loss: 0.3338\n",
      "Epoch [5/50], Step [319/735], Loss: 0.6495\n",
      "Epoch [5/50], Step [320/735], Loss: 0.1414\n",
      "Epoch [5/50], Step [321/735], Loss: 0.3774\n",
      "Epoch [5/50], Step [322/735], Loss: 0.7095\n",
      "Epoch [5/50], Step [323/735], Loss: 0.4694\n",
      "Epoch [5/50], Step [324/735], Loss: 0.6596\n",
      "Epoch [5/50], Step [325/735], Loss: 0.4863\n",
      "Epoch [5/50], Step [326/735], Loss: 0.8422\n",
      "Epoch [5/50], Step [327/735], Loss: 0.2949\n",
      "Epoch [5/50], Step [328/735], Loss: 0.9958\n",
      "Epoch [5/50], Step [329/735], Loss: 0.4998\n",
      "Epoch [5/50], Step [330/735], Loss: 0.4643\n",
      "Epoch [5/50], Step [331/735], Loss: 0.1311\n",
      "Epoch [5/50], Step [332/735], Loss: 0.3033\n",
      "Epoch [5/50], Step [333/735], Loss: 0.7778\n",
      "Epoch [5/50], Step [334/735], Loss: 1.0680\n",
      "Epoch [5/50], Step [335/735], Loss: 0.4278\n",
      "Epoch [5/50], Step [336/735], Loss: 1.1205\n",
      "Epoch [5/50], Step [337/735], Loss: 0.2734\n",
      "Epoch [5/50], Step [338/735], Loss: 0.2663\n",
      "Epoch [5/50], Step [339/735], Loss: 0.1616\n",
      "Epoch [5/50], Step [340/735], Loss: 0.8431\n",
      "Epoch [5/50], Step [341/735], Loss: 0.9234\n",
      "Epoch [5/50], Step [342/735], Loss: 0.4592\n",
      "Epoch [5/50], Step [343/735], Loss: 2.0934\n",
      "Epoch [5/50], Step [344/735], Loss: 1.1037\n",
      "Epoch [5/50], Step [345/735], Loss: 0.5617\n",
      "Epoch [5/50], Step [346/735], Loss: 0.1496\n",
      "Epoch [5/50], Step [347/735], Loss: 0.2852\n",
      "Epoch [5/50], Step [348/735], Loss: 0.3505\n",
      "Epoch [5/50], Step [349/735], Loss: 0.2917\n",
      "Epoch [5/50], Step [350/735], Loss: 1.1658\n",
      "Epoch [5/50], Step [351/735], Loss: 1.0697\n",
      "Epoch [5/50], Step [352/735], Loss: 0.4906\n",
      "Epoch [5/50], Step [353/735], Loss: 0.6673\n",
      "Epoch [5/50], Step [354/735], Loss: 0.2818\n",
      "Epoch [5/50], Step [355/735], Loss: 0.4672\n",
      "Epoch [5/50], Step [356/735], Loss: 1.0761\n",
      "Epoch [5/50], Step [357/735], Loss: 0.2647\n",
      "Epoch [5/50], Step [358/735], Loss: 0.3766\n",
      "Epoch [5/50], Step [359/735], Loss: 0.3334\n",
      "Epoch [5/50], Step [360/735], Loss: 0.5923\n",
      "Epoch [5/50], Step [361/735], Loss: 0.4204\n",
      "Epoch [5/50], Step [362/735], Loss: 0.4347\n",
      "Epoch [5/50], Step [363/735], Loss: 1.7697\n",
      "Epoch [5/50], Step [364/735], Loss: 1.4883\n",
      "Epoch [5/50], Step [365/735], Loss: 0.6963\n",
      "Epoch [5/50], Step [366/735], Loss: 0.6874\n",
      "Epoch [5/50], Step [367/735], Loss: 2.3120\n",
      "Epoch [5/50], Step [368/735], Loss: 0.2592\n",
      "Epoch [5/50], Step [369/735], Loss: 0.6723\n",
      "Epoch [5/50], Step [370/735], Loss: 0.5343\n",
      "Epoch [5/50], Step [371/735], Loss: 0.7094\n",
      "Epoch [5/50], Step [372/735], Loss: 0.4816\n",
      "Epoch [5/50], Step [373/735], Loss: 0.5486\n",
      "Epoch [5/50], Step [374/735], Loss: 0.2428\n",
      "Epoch [5/50], Step [375/735], Loss: 0.2269\n",
      "Epoch [5/50], Step [376/735], Loss: 0.6522\n",
      "Epoch [5/50], Step [377/735], Loss: 0.5060\n",
      "Epoch [5/50], Step [378/735], Loss: 0.2442\n",
      "Epoch [5/50], Step [379/735], Loss: 0.2807\n",
      "Epoch [5/50], Step [380/735], Loss: 0.4324\n",
      "Epoch [5/50], Step [381/735], Loss: 0.6789\n",
      "Epoch [5/50], Step [382/735], Loss: 1.1607\n",
      "Epoch [5/50], Step [383/735], Loss: 0.8642\n",
      "Epoch [5/50], Step [384/735], Loss: 0.7531\n",
      "Epoch [5/50], Step [385/735], Loss: 0.1394\n",
      "Epoch [5/50], Step [386/735], Loss: 1.2240\n",
      "Epoch [5/50], Step [387/735], Loss: 0.3086\n",
      "Epoch [5/50], Step [388/735], Loss: 0.2087\n",
      "Epoch [5/50], Step [389/735], Loss: 0.5938\n",
      "Epoch [5/50], Step [390/735], Loss: 0.3905\n",
      "Epoch [5/50], Step [391/735], Loss: 0.6537\n",
      "Epoch [5/50], Step [392/735], Loss: 0.7889\n",
      "Epoch [5/50], Step [393/735], Loss: 1.7371\n",
      "Epoch [5/50], Step [394/735], Loss: 0.3205\n",
      "Epoch [5/50], Step [395/735], Loss: 1.0430\n",
      "Epoch [5/50], Step [396/735], Loss: 0.6613\n",
      "Epoch [5/50], Step [397/735], Loss: 0.3468\n",
      "Epoch [5/50], Step [398/735], Loss: 0.4432\n",
      "Epoch [5/50], Step [399/735], Loss: 0.6964\n",
      "Epoch [5/50], Step [400/735], Loss: 0.7122\n",
      "Epoch [5/50], Step [401/735], Loss: 1.2188\n",
      "Epoch [5/50], Step [402/735], Loss: 0.3053\n",
      "Epoch [5/50], Step [403/735], Loss: 0.1496\n",
      "Epoch [5/50], Step [404/735], Loss: 0.6454\n",
      "Epoch [5/50], Step [405/735], Loss: 0.1535\n",
      "Epoch [5/50], Step [406/735], Loss: 5.8886\n",
      "Epoch [5/50], Step [407/735], Loss: 0.5175\n",
      "Epoch [5/50], Step [408/735], Loss: 0.7454\n",
      "Epoch [5/50], Step [409/735], Loss: 0.4496\n",
      "Epoch [5/50], Step [410/735], Loss: 0.2575\n",
      "Epoch [5/50], Step [411/735], Loss: 0.2080\n",
      "Epoch [5/50], Step [412/735], Loss: 0.5251\n",
      "Epoch [5/50], Step [413/735], Loss: 5.7100\n",
      "Epoch [5/50], Step [414/735], Loss: 0.3058\n",
      "Epoch [5/50], Step [415/735], Loss: 0.2680\n",
      "Epoch [5/50], Step [416/735], Loss: 0.5333\n",
      "Epoch [5/50], Step [417/735], Loss: 0.6800\n",
      "Epoch [5/50], Step [418/735], Loss: 0.3890\n",
      "Epoch [5/50], Step [419/735], Loss: 0.3601\n",
      "Epoch [5/50], Step [420/735], Loss: 0.2991\n",
      "Epoch [5/50], Step [421/735], Loss: 0.3233\n",
      "Epoch [5/50], Step [422/735], Loss: 0.9593\n",
      "Epoch [5/50], Step [423/735], Loss: 0.1121\n",
      "Epoch [5/50], Step [424/735], Loss: 0.2016\n",
      "Epoch [5/50], Step [425/735], Loss: 0.9403\n",
      "Epoch [5/50], Step [426/735], Loss: 0.3159\n",
      "Epoch [5/50], Step [427/735], Loss: 0.4862\n",
      "Epoch [5/50], Step [428/735], Loss: 1.1204\n",
      "Epoch [5/50], Step [429/735], Loss: 0.2586\n",
      "Epoch [5/50], Step [430/735], Loss: 0.4080\n",
      "Epoch [5/50], Step [431/735], Loss: 0.2746\n",
      "Epoch [5/50], Step [432/735], Loss: 0.3171\n",
      "Epoch [5/50], Step [433/735], Loss: 0.2741\n",
      "Epoch [5/50], Step [434/735], Loss: 0.7061\n",
      "Epoch [5/50], Step [435/735], Loss: 0.1806\n",
      "Epoch [5/50], Step [436/735], Loss: 1.2486\n",
      "Epoch [5/50], Step [437/735], Loss: 0.4655\n",
      "Epoch [5/50], Step [438/735], Loss: 0.1263\n",
      "Epoch [5/50], Step [439/735], Loss: 0.2631\n",
      "Epoch [5/50], Step [440/735], Loss: 0.5002\n",
      "Epoch [5/50], Step [441/735], Loss: 0.6975\n",
      "Epoch [5/50], Step [442/735], Loss: 1.0430\n",
      "Epoch [5/50], Step [443/735], Loss: 0.5107\n",
      "Epoch [5/50], Step [444/735], Loss: 0.5350\n",
      "Epoch [5/50], Step [445/735], Loss: 1.0838\n",
      "Epoch [5/50], Step [446/735], Loss: 0.8543\n",
      "Epoch [5/50], Step [447/735], Loss: 0.3321\n",
      "Epoch [5/50], Step [448/735], Loss: 0.2320\n",
      "Epoch [5/50], Step [449/735], Loss: 0.2305\n",
      "Epoch [5/50], Step [450/735], Loss: 0.3169\n",
      "Epoch [5/50], Step [451/735], Loss: 0.3826\n",
      "Epoch [5/50], Step [452/735], Loss: 0.3378\n",
      "Epoch [5/50], Step [453/735], Loss: 0.1485\n",
      "Epoch [5/50], Step [454/735], Loss: 0.4183\n",
      "Epoch [5/50], Step [455/735], Loss: 0.1924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Step [456/735], Loss: 0.6307\n",
      "Epoch [5/50], Step [457/735], Loss: 0.6823\n",
      "Epoch [5/50], Step [458/735], Loss: 0.2662\n",
      "Epoch [5/50], Step [459/735], Loss: 0.7159\n",
      "Epoch [5/50], Step [460/735], Loss: 0.6222\n",
      "Epoch [5/50], Step [461/735], Loss: 0.5612\n",
      "Epoch [5/50], Step [462/735], Loss: 0.5026\n",
      "Epoch [5/50], Step [463/735], Loss: 0.1491\n",
      "Epoch [5/50], Step [464/735], Loss: 0.1937\n",
      "Epoch [5/50], Step [465/735], Loss: 0.4038\n",
      "Epoch [5/50], Step [466/735], Loss: 0.7329\n",
      "Epoch [5/50], Step [467/735], Loss: 0.2579\n",
      "Epoch [5/50], Step [468/735], Loss: 0.6122\n",
      "Epoch [5/50], Step [469/735], Loss: 0.4358\n",
      "Epoch [5/50], Step [470/735], Loss: 0.6443\n",
      "Epoch [5/50], Step [471/735], Loss: 1.4014\n",
      "Epoch [5/50], Step [472/735], Loss: 0.2555\n",
      "Epoch [5/50], Step [473/735], Loss: 0.4004\n",
      "Epoch [5/50], Step [474/735], Loss: 0.4463\n",
      "Epoch [5/50], Step [475/735], Loss: 0.4826\n",
      "Epoch [5/50], Step [476/735], Loss: 0.3596\n",
      "Epoch [5/50], Step [477/735], Loss: 0.2932\n",
      "Epoch [5/50], Step [478/735], Loss: 0.3483\n",
      "Epoch [5/50], Step [479/735], Loss: 1.0451\n",
      "Epoch [5/50], Step [480/735], Loss: 0.7830\n",
      "Epoch [5/50], Step [481/735], Loss: 2.0305\n",
      "Epoch [5/50], Step [482/735], Loss: 0.2486\n",
      "Epoch [5/50], Step [483/735], Loss: 0.1889\n",
      "Epoch [5/50], Step [484/735], Loss: 1.1044\n",
      "Epoch [5/50], Step [485/735], Loss: 0.7241\n",
      "Epoch [5/50], Step [486/735], Loss: 0.2923\n",
      "Epoch [5/50], Step [487/735], Loss: 0.1227\n",
      "Epoch [5/50], Step [488/735], Loss: 0.2633\n",
      "Epoch [5/50], Step [489/735], Loss: 0.6542\n",
      "Epoch [5/50], Step [490/735], Loss: 0.5767\n",
      "Epoch [5/50], Step [491/735], Loss: 0.1931\n",
      "Epoch [5/50], Step [492/735], Loss: 0.4357\n",
      "Epoch [5/50], Step [493/735], Loss: 0.4823\n",
      "Epoch [5/50], Step [494/735], Loss: 0.8930\n",
      "Epoch [5/50], Step [495/735], Loss: 0.3916\n",
      "Epoch [5/50], Step [496/735], Loss: 0.4881\n",
      "Epoch [5/50], Step [497/735], Loss: 0.1342\n",
      "Epoch [5/50], Step [498/735], Loss: 0.4327\n",
      "Epoch [5/50], Step [499/735], Loss: 0.1178\n",
      "Epoch [5/50], Step [500/735], Loss: 0.4130\n",
      "Epoch [5/50], Step [501/735], Loss: 2.7745\n",
      "Epoch [5/50], Step [502/735], Loss: 0.2423\n",
      "Epoch [5/50], Step [503/735], Loss: 0.3564\n",
      "Epoch [5/50], Step [504/735], Loss: 0.1627\n",
      "Epoch [5/50], Step [505/735], Loss: 1.8160\n",
      "Epoch [5/50], Step [506/735], Loss: 0.1404\n",
      "Epoch [5/50], Step [507/735], Loss: 0.1884\n",
      "Epoch [5/50], Step [508/735], Loss: 0.4080\n",
      "Epoch [5/50], Step [509/735], Loss: 0.3744\n",
      "Epoch [5/50], Step [510/735], Loss: 0.3964\n",
      "Epoch [5/50], Step [511/735], Loss: 0.3261\n",
      "Epoch [5/50], Step [512/735], Loss: 0.6253\n",
      "Epoch [5/50], Step [513/735], Loss: 0.3137\n",
      "Epoch [5/50], Step [514/735], Loss: 0.2726\n",
      "Epoch [5/50], Step [515/735], Loss: 0.1706\n",
      "Epoch [5/50], Step [516/735], Loss: 0.5990\n",
      "Epoch [5/50], Step [517/735], Loss: 0.1963\n",
      "Epoch [5/50], Step [518/735], Loss: 0.1076\n",
      "Epoch [5/50], Step [519/735], Loss: 0.5504\n",
      "Epoch [5/50], Step [520/735], Loss: 0.5835\n",
      "Epoch [5/50], Step [521/735], Loss: 0.4856\n",
      "Epoch [5/50], Step [522/735], Loss: 0.6500\n",
      "Epoch [5/50], Step [523/735], Loss: 0.4811\n",
      "Epoch [5/50], Step [524/735], Loss: 0.4932\n",
      "Epoch [5/50], Step [525/735], Loss: 0.4548\n",
      "Epoch [5/50], Step [526/735], Loss: 0.3896\n",
      "Epoch [5/50], Step [527/735], Loss: 0.3643\n",
      "Epoch [5/50], Step [528/735], Loss: 2.3383\n",
      "Epoch [5/50], Step [529/735], Loss: 0.2462\n",
      "Epoch [5/50], Step [530/735], Loss: 0.1561\n",
      "Epoch [5/50], Step [531/735], Loss: 0.2289\n",
      "Epoch [5/50], Step [532/735], Loss: 1.0876\n",
      "Epoch [5/50], Step [533/735], Loss: 0.2483\n",
      "Epoch [5/50], Step [534/735], Loss: 0.6064\n",
      "Epoch [5/50], Step [535/735], Loss: 0.3881\n",
      "Epoch [5/50], Step [536/735], Loss: 0.8057\n",
      "Epoch [5/50], Step [537/735], Loss: 0.3198\n",
      "Epoch [5/50], Step [538/735], Loss: 0.4256\n",
      "Epoch [5/50], Step [539/735], Loss: 0.2318\n",
      "Epoch [5/50], Step [540/735], Loss: 1.0440\n",
      "Epoch [5/50], Step [541/735], Loss: 0.1565\n",
      "Epoch [5/50], Step [542/735], Loss: 1.2218\n",
      "Epoch [5/50], Step [543/735], Loss: 2.1351\n",
      "Epoch [5/50], Step [544/735], Loss: 0.3296\n",
      "Epoch [5/50], Step [545/735], Loss: 0.6374\n",
      "Epoch [5/50], Step [546/735], Loss: 0.9871\n",
      "Epoch [5/50], Step [547/735], Loss: 0.1204\n",
      "Epoch [5/50], Step [548/735], Loss: 0.8065\n",
      "Epoch [5/50], Step [549/735], Loss: 0.5661\n",
      "Epoch [5/50], Step [550/735], Loss: 0.1503\n",
      "Epoch [5/50], Step [551/735], Loss: 0.2250\n",
      "Epoch [5/50], Step [552/735], Loss: 0.3015\n",
      "Epoch [5/50], Step [553/735], Loss: 0.4728\n",
      "Epoch [5/50], Step [554/735], Loss: 0.3164\n",
      "Epoch [5/50], Step [555/735], Loss: 0.2544\n",
      "Epoch [5/50], Step [556/735], Loss: 0.2589\n",
      "Epoch [5/50], Step [557/735], Loss: 0.7397\n",
      "Epoch [5/50], Step [558/735], Loss: 1.1480\n",
      "Epoch [5/50], Step [559/735], Loss: 2.8638\n",
      "Epoch [5/50], Step [560/735], Loss: 0.1149\n",
      "Epoch [5/50], Step [561/735], Loss: 0.3635\n",
      "Epoch [5/50], Step [562/735], Loss: 0.2285\n",
      "Epoch [5/50], Step [563/735], Loss: 0.5521\n",
      "Epoch [5/50], Step [564/735], Loss: 0.4855\n",
      "Epoch [5/50], Step [565/735], Loss: 0.9933\n",
      "Epoch [5/50], Step [566/735], Loss: 0.2596\n",
      "Epoch [5/50], Step [567/735], Loss: 0.3254\n",
      "Epoch [5/50], Step [568/735], Loss: 0.4061\n",
      "Epoch [5/50], Step [569/735], Loss: 0.3558\n",
      "Epoch [5/50], Step [570/735], Loss: 0.9519\n",
      "Epoch [5/50], Step [571/735], Loss: 0.5999\n",
      "Epoch [5/50], Step [572/735], Loss: 0.1479\n",
      "Epoch [5/50], Step [573/735], Loss: 0.8406\n",
      "Epoch [5/50], Step [574/735], Loss: 0.3610\n",
      "Epoch [5/50], Step [575/735], Loss: 0.5735\n",
      "Epoch [5/50], Step [576/735], Loss: 0.4993\n",
      "Epoch [5/50], Step [577/735], Loss: 0.4088\n",
      "Epoch [5/50], Step [578/735], Loss: 0.9447\n",
      "Epoch [5/50], Step [579/735], Loss: 0.7179\n",
      "Epoch [5/50], Step [580/735], Loss: 0.4865\n",
      "Epoch [5/50], Step [581/735], Loss: 0.1523\n",
      "Epoch [5/50], Step [582/735], Loss: 0.3619\n",
      "Epoch [5/50], Step [583/735], Loss: 1.9618\n",
      "Epoch [5/50], Step [584/735], Loss: 0.5953\n",
      "Epoch [5/50], Step [585/735], Loss: 0.4729\n",
      "Epoch [5/50], Step [586/735], Loss: 0.3786\n",
      "Epoch [5/50], Step [587/735], Loss: 0.6643\n",
      "Epoch [5/50], Step [588/735], Loss: 0.1868\n",
      "Epoch [5/50], Step [589/735], Loss: 0.3974\n",
      "Epoch [5/50], Step [590/735], Loss: 1.2066\n",
      "Epoch [5/50], Step [591/735], Loss: 0.4961\n",
      "Epoch [5/50], Step [592/735], Loss: 0.2426\n",
      "Epoch [5/50], Step [593/735], Loss: 5.5836\n",
      "Epoch [5/50], Step [594/735], Loss: 0.2069\n",
      "Epoch [5/50], Step [595/735], Loss: 2.2253\n",
      "Epoch [5/50], Step [596/735], Loss: 0.6548\n",
      "Epoch [5/50], Step [597/735], Loss: 0.3916\n",
      "Epoch [5/50], Step [598/735], Loss: 0.2275\n",
      "Epoch [5/50], Step [599/735], Loss: 0.5868\n",
      "Epoch [5/50], Step [600/735], Loss: 1.1850\n",
      "Epoch [5/50], Step [601/735], Loss: 0.7909\n",
      "Epoch [5/50], Step [602/735], Loss: 0.5059\n",
      "Epoch [5/50], Step [603/735], Loss: 0.2674\n",
      "Epoch [5/50], Step [604/735], Loss: 0.3064\n",
      "Epoch [5/50], Step [605/735], Loss: 1.0491\n",
      "Epoch [5/50], Step [606/735], Loss: 1.4310\n",
      "Epoch [5/50], Step [607/735], Loss: 1.0779\n",
      "Epoch [5/50], Step [608/735], Loss: 0.6996\n",
      "Epoch [5/50], Step [609/735], Loss: 0.2764\n",
      "Epoch [5/50], Step [610/735], Loss: 0.2820\n",
      "Epoch [5/50], Step [611/735], Loss: 0.3130\n",
      "Epoch [5/50], Step [612/735], Loss: 1.0738\n",
      "Epoch [5/50], Step [613/735], Loss: 0.3289\n",
      "Epoch [5/50], Step [614/735], Loss: 0.8119\n",
      "Epoch [5/50], Step [615/735], Loss: 0.2287\n",
      "Epoch [5/50], Step [616/735], Loss: 0.1934\n",
      "Epoch [5/50], Step [617/735], Loss: 0.9957\n",
      "Epoch [5/50], Step [618/735], Loss: 1.7244\n",
      "Epoch [5/50], Step [619/735], Loss: 0.7069\n",
      "Epoch [5/50], Step [620/735], Loss: 0.4440\n",
      "Epoch [5/50], Step [621/735], Loss: 0.1101\n",
      "Epoch [5/50], Step [622/735], Loss: 0.1815\n",
      "Epoch [5/50], Step [623/735], Loss: 0.3838\n",
      "Epoch [5/50], Step [624/735], Loss: 0.7623\n",
      "Epoch [5/50], Step [625/735], Loss: 0.3873\n",
      "Epoch [5/50], Step [626/735], Loss: 0.4279\n",
      "Epoch [5/50], Step [627/735], Loss: 0.3572\n",
      "Epoch [5/50], Step [628/735], Loss: 1.1315\n",
      "Epoch [5/50], Step [629/735], Loss: 1.0056\n",
      "Epoch [5/50], Step [630/735], Loss: 1.0564\n",
      "Epoch [5/50], Step [631/735], Loss: 0.4779\n",
      "Epoch [5/50], Step [632/735], Loss: 2.2027\n",
      "Epoch [5/50], Step [633/735], Loss: 0.4048\n",
      "Epoch [5/50], Step [634/735], Loss: 0.4418\n",
      "Epoch [5/50], Step [635/735], Loss: 0.6630\n",
      "Epoch [5/50], Step [636/735], Loss: 0.5407\n",
      "Epoch [5/50], Step [637/735], Loss: 0.6267\n",
      "Epoch [5/50], Step [638/735], Loss: 0.8913\n",
      "Epoch [5/50], Step [639/735], Loss: 0.5826\n",
      "Epoch [5/50], Step [640/735], Loss: 0.7705\n",
      "Epoch [5/50], Step [641/735], Loss: 0.4231\n",
      "Epoch [5/50], Step [642/735], Loss: 0.7972\n",
      "Epoch [5/50], Step [643/735], Loss: 0.7381\n",
      "Epoch [5/50], Step [644/735], Loss: 0.2721\n",
      "Epoch [5/50], Step [645/735], Loss: 0.7722\n",
      "Epoch [5/50], Step [646/735], Loss: 0.4654\n",
      "Epoch [5/50], Step [647/735], Loss: 0.5348\n",
      "Epoch [5/50], Step [648/735], Loss: 0.2400\n",
      "Epoch [5/50], Step [649/735], Loss: 1.3987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Step [650/735], Loss: 0.4036\n",
      "Epoch [5/50], Step [651/735], Loss: 0.3833\n",
      "Epoch [5/50], Step [652/735], Loss: 0.3635\n",
      "Epoch [5/50], Step [653/735], Loss: 0.4496\n",
      "Epoch [5/50], Step [654/735], Loss: 0.2999\n",
      "Epoch [5/50], Step [655/735], Loss: 0.2769\n",
      "Epoch [5/50], Step [656/735], Loss: 0.3237\n",
      "Epoch [5/50], Step [657/735], Loss: 0.8767\n",
      "Epoch [5/50], Step [658/735], Loss: 0.1934\n",
      "Epoch [5/50], Step [659/735], Loss: 0.2505\n",
      "Epoch [5/50], Step [660/735], Loss: 0.6097\n",
      "Epoch [5/50], Step [661/735], Loss: 0.1863\n",
      "Epoch [5/50], Step [662/735], Loss: 0.2839\n",
      "Epoch [5/50], Step [663/735], Loss: 0.5248\n",
      "Epoch [5/50], Step [664/735], Loss: 0.4119\n",
      "Epoch [5/50], Step [665/735], Loss: 0.2406\n",
      "Epoch [5/50], Step [666/735], Loss: 0.3467\n",
      "Epoch [5/50], Step [667/735], Loss: 0.1138\n",
      "Epoch [5/50], Step [668/735], Loss: 0.8906\n",
      "Epoch [5/50], Step [669/735], Loss: 0.6956\n",
      "Epoch [5/50], Step [670/735], Loss: 0.4146\n",
      "Epoch [5/50], Step [671/735], Loss: 0.1218\n",
      "Epoch [5/50], Step [672/735], Loss: 0.1093\n",
      "Epoch [5/50], Step [673/735], Loss: 0.2802\n",
      "Epoch [5/50], Step [674/735], Loss: 2.3885\n",
      "Epoch [5/50], Step [675/735], Loss: 0.5829\n",
      "Epoch [5/50], Step [676/735], Loss: 0.1761\n",
      "Epoch [5/50], Step [677/735], Loss: 0.2553\n",
      "Epoch [5/50], Step [678/735], Loss: 1.1325\n",
      "Epoch [5/50], Step [679/735], Loss: 0.6419\n",
      "Epoch [5/50], Step [680/735], Loss: 0.3755\n",
      "Epoch [5/50], Step [681/735], Loss: 0.3775\n",
      "Epoch [5/50], Step [682/735], Loss: 0.6014\n",
      "Epoch [5/50], Step [683/735], Loss: 0.3454\n",
      "Epoch [5/50], Step [684/735], Loss: 1.2063\n",
      "Epoch [5/50], Step [685/735], Loss: 0.2419\n",
      "Epoch [5/50], Step [686/735], Loss: 0.2939\n",
      "Epoch [5/50], Step [687/735], Loss: 1.5417\n",
      "Epoch [5/50], Step [688/735], Loss: 2.1196\n",
      "Epoch [5/50], Step [689/735], Loss: 1.2674\n",
      "Epoch [5/50], Step [690/735], Loss: 0.2492\n",
      "Epoch [5/50], Step [691/735], Loss: 0.1973\n",
      "Epoch [5/50], Step [692/735], Loss: 0.7121\n",
      "Epoch [5/50], Step [693/735], Loss: 0.5612\n",
      "Epoch [5/50], Step [694/735], Loss: 0.1541\n",
      "Epoch [5/50], Step [695/735], Loss: 0.3112\n",
      "Epoch [5/50], Step [696/735], Loss: 0.7204\n",
      "Epoch [5/50], Step [697/735], Loss: 0.1632\n",
      "Epoch [5/50], Step [698/735], Loss: 0.0888\n",
      "Epoch [5/50], Step [699/735], Loss: 0.2846\n",
      "Epoch [5/50], Step [700/735], Loss: 0.9639\n",
      "Epoch [5/50], Step [701/735], Loss: 0.7074\n",
      "Epoch [5/50], Step [702/735], Loss: 1.5769\n",
      "Epoch [5/50], Step [703/735], Loss: 0.3803\n",
      "Epoch [5/50], Step [704/735], Loss: 0.1845\n",
      "Epoch [5/50], Step [705/735], Loss: 0.4728\n",
      "Epoch [5/50], Step [706/735], Loss: 0.5554\n",
      "Epoch [5/50], Step [707/735], Loss: 0.3168\n",
      "Epoch [5/50], Step [708/735], Loss: 0.4027\n",
      "Epoch [5/50], Step [709/735], Loss: 0.2075\n",
      "Epoch [5/50], Step [710/735], Loss: 0.0999\n",
      "Epoch [5/50], Step [711/735], Loss: 0.3184\n",
      "Epoch [5/50], Step [712/735], Loss: 0.6233\n",
      "Epoch [5/50], Step [713/735], Loss: 0.9953\n",
      "Epoch [5/50], Step [714/735], Loss: 1.7162\n",
      "Epoch [5/50], Step [715/735], Loss: 0.7461\n",
      "Epoch [5/50], Step [716/735], Loss: 1.3706\n",
      "Epoch [5/50], Step [717/735], Loss: 0.2249\n",
      "Epoch [5/50], Step [718/735], Loss: 0.5166\n",
      "Epoch [5/50], Step [719/735], Loss: 0.6647\n",
      "Epoch [5/50], Step [720/735], Loss: 0.3481\n",
      "Epoch [5/50], Step [721/735], Loss: 0.3723\n",
      "Epoch [5/50], Step [722/735], Loss: 1.4962\n",
      "Epoch [5/50], Step [723/735], Loss: 0.3532\n",
      "Epoch [5/50], Step [724/735], Loss: 0.2673\n",
      "Epoch [5/50], Step [725/735], Loss: 0.4691\n",
      "Epoch [5/50], Step [726/735], Loss: 0.5495\n",
      "Epoch [5/50], Step [727/735], Loss: 0.1338\n",
      "Epoch [5/50], Step [728/735], Loss: 0.1829\n",
      "Epoch [5/50], Step [729/735], Loss: 0.8020\n",
      "Epoch [5/50], Step [730/735], Loss: 0.5163\n",
      "Epoch [5/50], Step [731/735], Loss: 0.3921\n",
      "Epoch [5/50], Step [732/735], Loss: 1.6340\n",
      "Epoch [5/50], Step [733/735], Loss: 1.1182\n",
      "Epoch [5/50], Step [734/735], Loss: 0.9191\n",
      "Epoch [5/50], Step [735/735], Loss: 0.7158\n",
      "Epoch [6/50], Step [1/735], Loss: 0.2447\n",
      "Epoch [6/50], Step [2/735], Loss: 1.4650\n",
      "Epoch [6/50], Step [3/735], Loss: 0.3428\n",
      "Epoch [6/50], Step [4/735], Loss: 0.5934\n",
      "Epoch [6/50], Step [5/735], Loss: 0.8009\n",
      "Epoch [6/50], Step [6/735], Loss: 0.4106\n",
      "Epoch [6/50], Step [7/735], Loss: 0.3462\n",
      "Epoch [6/50], Step [8/735], Loss: 0.3496\n",
      "Epoch [6/50], Step [9/735], Loss: 0.2627\n",
      "Epoch [6/50], Step [10/735], Loss: 0.3587\n",
      "Epoch [6/50], Step [11/735], Loss: 0.9171\n",
      "Epoch [6/50], Step [12/735], Loss: 0.2751\n",
      "Epoch [6/50], Step [13/735], Loss: 0.6411\n",
      "Epoch [6/50], Step [14/735], Loss: 5.8915\n",
      "Epoch [6/50], Step [15/735], Loss: 0.1477\n",
      "Epoch [6/50], Step [16/735], Loss: 0.4392\n",
      "Epoch [6/50], Step [17/735], Loss: 0.6558\n",
      "Epoch [6/50], Step [18/735], Loss: 0.3507\n",
      "Epoch [6/50], Step [19/735], Loss: 1.9111\n",
      "Epoch [6/50], Step [20/735], Loss: 0.2051\n",
      "Epoch [6/50], Step [21/735], Loss: 0.7031\n",
      "Epoch [6/50], Step [22/735], Loss: 0.3962\n",
      "Epoch [6/50], Step [23/735], Loss: 0.7593\n",
      "Epoch [6/50], Step [24/735], Loss: 0.4835\n",
      "Epoch [6/50], Step [25/735], Loss: 1.0822\n",
      "Epoch [6/50], Step [26/735], Loss: 0.2068\n",
      "Epoch [6/50], Step [27/735], Loss: 0.5018\n",
      "Epoch [6/50], Step [28/735], Loss: 2.0642\n",
      "Epoch [6/50], Step [29/735], Loss: 0.2878\n",
      "Epoch [6/50], Step [30/735], Loss: 0.6478\n",
      "Epoch [6/50], Step [31/735], Loss: 0.5671\n",
      "Epoch [6/50], Step [32/735], Loss: 0.5107\n",
      "Epoch [6/50], Step [33/735], Loss: 0.1989\n",
      "Epoch [6/50], Step [34/735], Loss: 0.1799\n",
      "Epoch [6/50], Step [35/735], Loss: 0.6893\n",
      "Epoch [6/50], Step [36/735], Loss: 0.1338\n",
      "Epoch [6/50], Step [37/735], Loss: 0.1685\n",
      "Epoch [6/50], Step [38/735], Loss: 0.9258\n",
      "Epoch [6/50], Step [39/735], Loss: 0.6640\n",
      "Epoch [6/50], Step [40/735], Loss: 0.3586\n",
      "Epoch [6/50], Step [41/735], Loss: 0.5652\n",
      "Epoch [6/50], Step [42/735], Loss: 0.2917\n",
      "Epoch [6/50], Step [43/735], Loss: 0.2739\n",
      "Epoch [6/50], Step [44/735], Loss: 0.3656\n",
      "Epoch [6/50], Step [45/735], Loss: 0.1859\n",
      "Epoch [6/50], Step [46/735], Loss: 0.8423\n",
      "Epoch [6/50], Step [47/735], Loss: 0.4942\n",
      "Epoch [6/50], Step [48/735], Loss: 0.6330\n",
      "Epoch [6/50], Step [49/735], Loss: 1.1390\n",
      "Epoch [6/50], Step [50/735], Loss: 0.2618\n",
      "Epoch [6/50], Step [51/735], Loss: 1.2538\n",
      "Epoch [6/50], Step [52/735], Loss: 0.5254\n",
      "Epoch [6/50], Step [53/735], Loss: 0.2177\n",
      "Epoch [6/50], Step [54/735], Loss: 0.7371\n",
      "Epoch [6/50], Step [55/735], Loss: 0.4165\n",
      "Epoch [6/50], Step [56/735], Loss: 0.2080\n",
      "Epoch [6/50], Step [57/735], Loss: 0.1748\n",
      "Epoch [6/50], Step [58/735], Loss: 0.2581\n",
      "Epoch [6/50], Step [59/735], Loss: 0.4693\n",
      "Epoch [6/50], Step [60/735], Loss: 0.1639\n",
      "Epoch [6/50], Step [61/735], Loss: 0.4353\n",
      "Epoch [6/50], Step [62/735], Loss: 0.2182\n",
      "Epoch [6/50], Step [63/735], Loss: 0.5193\n",
      "Epoch [6/50], Step [64/735], Loss: 0.3625\n",
      "Epoch [6/50], Step [65/735], Loss: 0.4104\n",
      "Epoch [6/50], Step [66/735], Loss: 0.1569\n",
      "Epoch [6/50], Step [67/735], Loss: 0.2366\n",
      "Epoch [6/50], Step [68/735], Loss: 0.4436\n",
      "Epoch [6/50], Step [69/735], Loss: 0.2084\n",
      "Epoch [6/50], Step [70/735], Loss: 0.8041\n",
      "Epoch [6/50], Step [71/735], Loss: 0.6191\n",
      "Epoch [6/50], Step [72/735], Loss: 0.7331\n",
      "Epoch [6/50], Step [73/735], Loss: 0.9104\n",
      "Epoch [6/50], Step [74/735], Loss: 1.3650\n",
      "Epoch [6/50], Step [75/735], Loss: 0.4066\n",
      "Epoch [6/50], Step [76/735], Loss: 0.7624\n",
      "Epoch [6/50], Step [77/735], Loss: 0.1677\n",
      "Epoch [6/50], Step [78/735], Loss: 0.2633\n",
      "Epoch [6/50], Step [79/735], Loss: 2.3029\n",
      "Epoch [6/50], Step [80/735], Loss: 0.7146\n",
      "Epoch [6/50], Step [81/735], Loss: 0.3205\n",
      "Epoch [6/50], Step [82/735], Loss: 0.5945\n",
      "Epoch [6/50], Step [83/735], Loss: 0.3972\n",
      "Epoch [6/50], Step [84/735], Loss: 0.1925\n",
      "Epoch [6/50], Step [85/735], Loss: 0.1870\n",
      "Epoch [6/50], Step [86/735], Loss: 1.0058\n",
      "Epoch [6/50], Step [87/735], Loss: 0.3207\n",
      "Epoch [6/50], Step [88/735], Loss: 0.6098\n",
      "Epoch [6/50], Step [89/735], Loss: 0.3643\n",
      "Epoch [6/50], Step [90/735], Loss: 0.2363\n",
      "Epoch [6/50], Step [91/735], Loss: 0.6823\n",
      "Epoch [6/50], Step [92/735], Loss: 0.3124\n",
      "Epoch [6/50], Step [93/735], Loss: 0.6041\n",
      "Epoch [6/50], Step [94/735], Loss: 0.7030\n",
      "Epoch [6/50], Step [95/735], Loss: 0.4242\n",
      "Epoch [6/50], Step [96/735], Loss: 0.1823\n",
      "Epoch [6/50], Step [97/735], Loss: 0.1066\n",
      "Epoch [6/50], Step [98/735], Loss: 0.6382\n",
      "Epoch [6/50], Step [99/735], Loss: 0.2559\n",
      "Epoch [6/50], Step [100/735], Loss: 0.2493\n",
      "Epoch [6/50], Step [101/735], Loss: 0.6535\n",
      "Epoch [6/50], Step [102/735], Loss: 0.4735\n",
      "Epoch [6/50], Step [103/735], Loss: 0.6943\n",
      "Epoch [6/50], Step [104/735], Loss: 0.3196\n",
      "Epoch [6/50], Step [105/735], Loss: 0.3343\n",
      "Epoch [6/50], Step [106/735], Loss: 0.2301\n",
      "Epoch [6/50], Step [107/735], Loss: 0.5869\n",
      "Epoch [6/50], Step [108/735], Loss: 2.4367\n",
      "Epoch [6/50], Step [109/735], Loss: 0.2093\n",
      "Epoch [6/50], Step [110/735], Loss: 0.1327\n",
      "Epoch [6/50], Step [111/735], Loss: 0.1042\n",
      "Epoch [6/50], Step [112/735], Loss: 0.5151\n",
      "Epoch [6/50], Step [113/735], Loss: 0.0950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Step [114/735], Loss: 0.2962\n",
      "Epoch [6/50], Step [115/735], Loss: 0.5557\n",
      "Epoch [6/50], Step [116/735], Loss: 0.3909\n",
      "Epoch [6/50], Step [117/735], Loss: 0.3125\n",
      "Epoch [6/50], Step [118/735], Loss: 0.1805\n",
      "Epoch [6/50], Step [119/735], Loss: 0.1597\n",
      "Epoch [6/50], Step [120/735], Loss: 0.7283\n",
      "Epoch [6/50], Step [121/735], Loss: 1.1534\n",
      "Epoch [6/50], Step [122/735], Loss: 0.4829\n",
      "Epoch [6/50], Step [123/735], Loss: 0.2947\n",
      "Epoch [6/50], Step [124/735], Loss: 0.2626\n",
      "Epoch [6/50], Step [125/735], Loss: 0.7577\n",
      "Epoch [6/50], Step [126/735], Loss: 0.5138\n",
      "Epoch [6/50], Step [127/735], Loss: 0.8943\n",
      "Epoch [6/50], Step [128/735], Loss: 0.1858\n",
      "Epoch [6/50], Step [129/735], Loss: 0.3177\n",
      "Epoch [6/50], Step [130/735], Loss: 0.3178\n",
      "Epoch [6/50], Step [131/735], Loss: 0.5995\n",
      "Epoch [6/50], Step [132/735], Loss: 0.4850\n",
      "Epoch [6/50], Step [133/735], Loss: 0.4016\n",
      "Epoch [6/50], Step [134/735], Loss: 0.3674\n",
      "Epoch [6/50], Step [135/735], Loss: 0.4900\n",
      "Epoch [6/50], Step [136/735], Loss: 0.0941\n",
      "Epoch [6/50], Step [137/735], Loss: 0.8640\n",
      "Epoch [6/50], Step [138/735], Loss: 0.2255\n",
      "Epoch [6/50], Step [139/735], Loss: 0.6785\n",
      "Epoch [6/50], Step [140/735], Loss: 0.2767\n",
      "Epoch [6/50], Step [141/735], Loss: 0.4445\n",
      "Epoch [6/50], Step [142/735], Loss: 0.2920\n",
      "Epoch [6/50], Step [143/735], Loss: 0.7363\n",
      "Epoch [6/50], Step [144/735], Loss: 0.2161\n",
      "Epoch [6/50], Step [145/735], Loss: 0.2057\n",
      "Epoch [6/50], Step [146/735], Loss: 0.5078\n",
      "Epoch [6/50], Step [147/735], Loss: 1.0369\n",
      "Epoch [6/50], Step [148/735], Loss: 0.2331\n",
      "Epoch [6/50], Step [149/735], Loss: 1.0399\n",
      "Epoch [6/50], Step [150/735], Loss: 0.2328\n",
      "Epoch [6/50], Step [151/735], Loss: 0.3794\n",
      "Epoch [6/50], Step [152/735], Loss: 0.2758\n",
      "Epoch [6/50], Step [153/735], Loss: 0.3891\n",
      "Epoch [6/50], Step [154/735], Loss: 0.2050\n",
      "Epoch [6/50], Step [155/735], Loss: 0.8842\n",
      "Epoch [6/50], Step [156/735], Loss: 0.5289\n",
      "Epoch [6/50], Step [157/735], Loss: 0.5331\n",
      "Epoch [6/50], Step [158/735], Loss: 0.3020\n",
      "Epoch [6/50], Step [159/735], Loss: 1.5127\n",
      "Epoch [6/50], Step [160/735], Loss: 0.1647\n",
      "Epoch [6/50], Step [161/735], Loss: 0.8763\n",
      "Epoch [6/50], Step [162/735], Loss: 0.4708\n",
      "Epoch [6/50], Step [163/735], Loss: 0.1660\n",
      "Epoch [6/50], Step [164/735], Loss: 0.8415\n",
      "Epoch [6/50], Step [165/735], Loss: 0.2443\n",
      "Epoch [6/50], Step [166/735], Loss: 0.4302\n",
      "Epoch [6/50], Step [167/735], Loss: 0.1924\n",
      "Epoch [6/50], Step [168/735], Loss: 0.4907\n",
      "Epoch [6/50], Step [169/735], Loss: 2.2176\n",
      "Epoch [6/50], Step [170/735], Loss: 0.7932\n",
      "Epoch [6/50], Step [171/735], Loss: 0.6651\n",
      "Epoch [6/50], Step [172/735], Loss: 1.7529\n",
      "Epoch [6/50], Step [173/735], Loss: 1.6015\n",
      "Epoch [6/50], Step [174/735], Loss: 0.2395\n",
      "Epoch [6/50], Step [175/735], Loss: 0.5880\n",
      "Epoch [6/50], Step [176/735], Loss: 0.1996\n",
      "Epoch [6/50], Step [177/735], Loss: 0.5056\n",
      "Epoch [6/50], Step [178/735], Loss: 0.3275\n",
      "Epoch [6/50], Step [179/735], Loss: 0.6569\n",
      "Epoch [6/50], Step [180/735], Loss: 0.4927\n",
      "Epoch [6/50], Step [181/735], Loss: 0.4405\n",
      "Epoch [6/50], Step [182/735], Loss: 0.2422\n",
      "Epoch [6/50], Step [183/735], Loss: 0.4166\n",
      "Epoch [6/50], Step [184/735], Loss: 6.6124\n",
      "Epoch [6/50], Step [185/735], Loss: 0.4619\n",
      "Epoch [6/50], Step [186/735], Loss: 0.4061\n",
      "Epoch [6/50], Step [187/735], Loss: 0.3563\n",
      "Epoch [6/50], Step [188/735], Loss: 0.3834\n",
      "Epoch [6/50], Step [189/735], Loss: 1.0720\n",
      "Epoch [6/50], Step [190/735], Loss: 0.2860\n",
      "Epoch [6/50], Step [191/735], Loss: 0.3329\n",
      "Epoch [6/50], Step [192/735], Loss: 0.5346\n",
      "Epoch [6/50], Step [193/735], Loss: 1.0016\n",
      "Epoch [6/50], Step [194/735], Loss: 0.6954\n",
      "Epoch [6/50], Step [195/735], Loss: 0.6023\n",
      "Epoch [6/50], Step [196/735], Loss: 0.2605\n",
      "Epoch [6/50], Step [197/735], Loss: 0.1142\n",
      "Epoch [6/50], Step [198/735], Loss: 0.4548\n",
      "Epoch [6/50], Step [199/735], Loss: 0.4860\n",
      "Epoch [6/50], Step [200/735], Loss: 0.2344\n",
      "Epoch [6/50], Step [201/735], Loss: 1.4179\n",
      "Epoch [6/50], Step [202/735], Loss: 0.9169\n",
      "Epoch [6/50], Step [203/735], Loss: 0.8328\n",
      "Epoch [6/50], Step [204/735], Loss: 0.4773\n",
      "Epoch [6/50], Step [205/735], Loss: 0.2448\n",
      "Epoch [6/50], Step [206/735], Loss: 0.5968\n",
      "Epoch [6/50], Step [207/735], Loss: 0.2021\n",
      "Epoch [6/50], Step [208/735], Loss: 0.1530\n",
      "Epoch [6/50], Step [209/735], Loss: 0.6373\n",
      "Epoch [6/50], Step [210/735], Loss: 1.3417\n",
      "Epoch [6/50], Step [211/735], Loss: 0.4364\n",
      "Epoch [6/50], Step [212/735], Loss: 0.5164\n",
      "Epoch [6/50], Step [213/735], Loss: 0.2589\n",
      "Epoch [6/50], Step [214/735], Loss: 0.4558\n",
      "Epoch [6/50], Step [215/735], Loss: 2.5181\n",
      "Epoch [6/50], Step [216/735], Loss: 0.5532\n",
      "Epoch [6/50], Step [217/735], Loss: 0.8204\n",
      "Epoch [6/50], Step [218/735], Loss: 0.4197\n",
      "Epoch [6/50], Step [219/735], Loss: 0.4059\n",
      "Epoch [6/50], Step [220/735], Loss: 0.3047\n",
      "Epoch [6/50], Step [221/735], Loss: 0.1560\n",
      "Epoch [6/50], Step [222/735], Loss: 1.4095\n",
      "Epoch [6/50], Step [223/735], Loss: 0.4648\n",
      "Epoch [6/50], Step [224/735], Loss: 0.5523\n",
      "Epoch [6/50], Step [225/735], Loss: 0.5897\n",
      "Epoch [6/50], Step [226/735], Loss: 0.1748\n",
      "Epoch [6/50], Step [227/735], Loss: 1.3810\n",
      "Epoch [6/50], Step [228/735], Loss: 1.1011\n",
      "Epoch [6/50], Step [229/735], Loss: 0.3659\n",
      "Epoch [6/50], Step [230/735], Loss: 0.8171\n",
      "Epoch [6/50], Step [231/735], Loss: 0.9608\n",
      "Epoch [6/50], Step [232/735], Loss: 0.1670\n",
      "Epoch [6/50], Step [233/735], Loss: 0.1419\n",
      "Epoch [6/50], Step [234/735], Loss: 0.3776\n",
      "Epoch [6/50], Step [235/735], Loss: 0.8508\n",
      "Epoch [6/50], Step [236/735], Loss: 1.0581\n",
      "Epoch [6/50], Step [237/735], Loss: 0.5955\n",
      "Epoch [6/50], Step [238/735], Loss: 0.2237\n",
      "Epoch [6/50], Step [239/735], Loss: 1.9349\n",
      "Epoch [6/50], Step [240/735], Loss: 0.5691\n",
      "Epoch [6/50], Step [241/735], Loss: 0.1533\n",
      "Epoch [6/50], Step [242/735], Loss: 0.4217\n",
      "Epoch [6/50], Step [243/735], Loss: 0.2169\n",
      "Epoch [6/50], Step [244/735], Loss: 2.8548\n",
      "Epoch [6/50], Step [245/735], Loss: 0.4980\n",
      "Epoch [6/50], Step [246/735], Loss: 0.2561\n",
      "Epoch [6/50], Step [247/735], Loss: 0.3111\n",
      "Epoch [6/50], Step [248/735], Loss: 0.3758\n",
      "Epoch [6/50], Step [249/735], Loss: 0.1869\n",
      "Epoch [6/50], Step [250/735], Loss: 0.3334\n",
      "Epoch [6/50], Step [251/735], Loss: 0.2845\n",
      "Epoch [6/50], Step [252/735], Loss: 0.4638\n",
      "Epoch [6/50], Step [253/735], Loss: 1.8840\n",
      "Epoch [6/50], Step [254/735], Loss: 0.7091\n",
      "Epoch [6/50], Step [255/735], Loss: 0.1267\n",
      "Epoch [6/50], Step [256/735], Loss: 0.4788\n",
      "Epoch [6/50], Step [257/735], Loss: 0.7253\n",
      "Epoch [6/50], Step [258/735], Loss: 1.0229\n",
      "Epoch [6/50], Step [259/735], Loss: 0.4704\n",
      "Epoch [6/50], Step [260/735], Loss: 0.5815\n",
      "Epoch [6/50], Step [261/735], Loss: 0.3854\n",
      "Epoch [6/50], Step [262/735], Loss: 0.4365\n",
      "Epoch [6/50], Step [263/735], Loss: 1.0948\n",
      "Epoch [6/50], Step [264/735], Loss: 0.4045\n",
      "Epoch [6/50], Step [265/735], Loss: 0.3428\n",
      "Epoch [6/50], Step [266/735], Loss: 0.1545\n",
      "Epoch [6/50], Step [267/735], Loss: 0.2012\n",
      "Epoch [6/50], Step [268/735], Loss: 0.3985\n",
      "Epoch [6/50], Step [269/735], Loss: 0.8505\n",
      "Epoch [6/50], Step [270/735], Loss: 0.5654\n",
      "Epoch [6/50], Step [271/735], Loss: 0.4823\n",
      "Epoch [6/50], Step [272/735], Loss: 0.4332\n",
      "Epoch [6/50], Step [273/735], Loss: 0.5796\n",
      "Epoch [6/50], Step [274/735], Loss: 0.3149\n",
      "Epoch [6/50], Step [275/735], Loss: 0.2854\n",
      "Epoch [6/50], Step [276/735], Loss: 0.8109\n",
      "Epoch [6/50], Step [277/735], Loss: 1.9230\n",
      "Epoch [6/50], Step [278/735], Loss: 0.2611\n",
      "Epoch [6/50], Step [279/735], Loss: 0.5476\n",
      "Epoch [6/50], Step [280/735], Loss: 1.1011\n",
      "Epoch [6/50], Step [281/735], Loss: 0.2113\n",
      "Epoch [6/50], Step [282/735], Loss: 0.3000\n",
      "Epoch [6/50], Step [283/735], Loss: 1.0708\n",
      "Epoch [6/50], Step [284/735], Loss: 0.3143\n",
      "Epoch [6/50], Step [285/735], Loss: 0.2128\n",
      "Epoch [6/50], Step [286/735], Loss: 0.2039\n",
      "Epoch [6/50], Step [287/735], Loss: 0.1439\n",
      "Epoch [6/50], Step [288/735], Loss: 0.2521\n",
      "Epoch [6/50], Step [289/735], Loss: 0.8742\n",
      "Epoch [6/50], Step [290/735], Loss: 0.4302\n",
      "Epoch [6/50], Step [291/735], Loss: 0.4829\n",
      "Epoch [6/50], Step [292/735], Loss: 0.9458\n",
      "Epoch [6/50], Step [293/735], Loss: 0.2134\n",
      "Epoch [6/50], Step [294/735], Loss: 0.4855\n",
      "Epoch [6/50], Step [295/735], Loss: 0.9258\n",
      "Epoch [6/50], Step [296/735], Loss: 0.1681\n",
      "Epoch [6/50], Step [297/735], Loss: 0.9120\n",
      "Epoch [6/50], Step [298/735], Loss: 1.1499\n",
      "Epoch [6/50], Step [299/735], Loss: 0.1677\n",
      "Epoch [6/50], Step [300/735], Loss: 0.3945\n",
      "Epoch [6/50], Step [301/735], Loss: 0.4175\n",
      "Epoch [6/50], Step [302/735], Loss: 0.1751\n",
      "Epoch [6/50], Step [303/735], Loss: 0.2223\n",
      "Epoch [6/50], Step [304/735], Loss: 0.2237\n",
      "Epoch [6/50], Step [305/735], Loss: 1.1505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Step [306/735], Loss: 0.3498\n",
      "Epoch [6/50], Step [307/735], Loss: 0.2725\n",
      "Epoch [6/50], Step [308/735], Loss: 0.3580\n",
      "Epoch [6/50], Step [309/735], Loss: 0.6167\n",
      "Epoch [6/50], Step [310/735], Loss: 1.1123\n",
      "Epoch [6/50], Step [311/735], Loss: 0.4933\n",
      "Epoch [6/50], Step [312/735], Loss: 0.3132\n",
      "Epoch [6/50], Step [313/735], Loss: 0.3105\n",
      "Epoch [6/50], Step [314/735], Loss: 0.1882\n",
      "Epoch [6/50], Step [315/735], Loss: 0.2110\n",
      "Epoch [6/50], Step [316/735], Loss: 0.5053\n",
      "Epoch [6/50], Step [317/735], Loss: 0.2742\n",
      "Epoch [6/50], Step [318/735], Loss: 0.4720\n",
      "Epoch [6/50], Step [319/735], Loss: 0.9006\n",
      "Epoch [6/50], Step [320/735], Loss: 0.2789\n",
      "Epoch [6/50], Step [321/735], Loss: 0.3364\n",
      "Epoch [6/50], Step [322/735], Loss: 3.7799\n",
      "Epoch [6/50], Step [323/735], Loss: 0.1074\n",
      "Epoch [6/50], Step [324/735], Loss: 0.9041\n",
      "Epoch [6/50], Step [325/735], Loss: 0.9175\n",
      "Epoch [6/50], Step [326/735], Loss: 0.9191\n",
      "Epoch [6/50], Step [327/735], Loss: 0.8635\n",
      "Epoch [6/50], Step [328/735], Loss: 0.4579\n",
      "Epoch [6/50], Step [329/735], Loss: 0.2227\n",
      "Epoch [6/50], Step [330/735], Loss: 0.6717\n",
      "Epoch [6/50], Step [331/735], Loss: 0.2477\n",
      "Epoch [6/50], Step [332/735], Loss: 0.8485\n",
      "Epoch [6/50], Step [333/735], Loss: 0.3433\n",
      "Epoch [6/50], Step [334/735], Loss: 0.1078\n",
      "Epoch [6/50], Step [335/735], Loss: 1.0664\n",
      "Epoch [6/50], Step [336/735], Loss: 0.8408\n",
      "Epoch [6/50], Step [337/735], Loss: 0.5768\n",
      "Epoch [6/50], Step [338/735], Loss: 0.2449\n",
      "Epoch [6/50], Step [339/735], Loss: 0.3534\n",
      "Epoch [6/50], Step [340/735], Loss: 0.3578\n",
      "Epoch [6/50], Step [341/735], Loss: 0.7587\n",
      "Epoch [6/50], Step [342/735], Loss: 0.2324\n",
      "Epoch [6/50], Step [343/735], Loss: 0.9388\n",
      "Epoch [6/50], Step [344/735], Loss: 0.5982\n",
      "Epoch [6/50], Step [345/735], Loss: 0.4060\n",
      "Epoch [6/50], Step [346/735], Loss: 0.2995\n",
      "Epoch [6/50], Step [347/735], Loss: 0.2339\n",
      "Epoch [6/50], Step [348/735], Loss: 0.3629\n",
      "Epoch [6/50], Step [349/735], Loss: 0.4909\n",
      "Epoch [6/50], Step [350/735], Loss: 0.6267\n",
      "Epoch [6/50], Step [351/735], Loss: 0.3455\n",
      "Epoch [6/50], Step [352/735], Loss: 0.2814\n",
      "Epoch [6/50], Step [353/735], Loss: 0.7926\n",
      "Epoch [6/50], Step [354/735], Loss: 0.4680\n",
      "Epoch [6/50], Step [355/735], Loss: 0.2625\n",
      "Epoch [6/50], Step [356/735], Loss: 0.7948\n",
      "Epoch [6/50], Step [357/735], Loss: 0.6405\n",
      "Epoch [6/50], Step [358/735], Loss: 1.7822\n",
      "Epoch [6/50], Step [359/735], Loss: 0.1317\n",
      "Epoch [6/50], Step [360/735], Loss: 0.4381\n",
      "Epoch [6/50], Step [361/735], Loss: 0.2029\n",
      "Epoch [6/50], Step [362/735], Loss: 0.5493\n",
      "Epoch [6/50], Step [363/735], Loss: 2.0188\n",
      "Epoch [6/50], Step [364/735], Loss: 1.1384\n",
      "Epoch [6/50], Step [365/735], Loss: 0.2452\n",
      "Epoch [6/50], Step [366/735], Loss: 0.3554\n",
      "Epoch [6/50], Step [367/735], Loss: 0.3297\n",
      "Epoch [6/50], Step [368/735], Loss: 0.3758\n",
      "Epoch [6/50], Step [369/735], Loss: 0.3625\n",
      "Epoch [6/50], Step [370/735], Loss: 0.4178\n",
      "Epoch [6/50], Step [371/735], Loss: 0.2894\n",
      "Epoch [6/50], Step [372/735], Loss: 0.7625\n",
      "Epoch [6/50], Step [373/735], Loss: 0.3007\n",
      "Epoch [6/50], Step [374/735], Loss: 0.3714\n",
      "Epoch [6/50], Step [375/735], Loss: 1.0391\n",
      "Epoch [6/50], Step [376/735], Loss: 0.1879\n",
      "Epoch [6/50], Step [377/735], Loss: 0.2874\n",
      "Epoch [6/50], Step [378/735], Loss: 0.2566\n",
      "Epoch [6/50], Step [379/735], Loss: 0.4254\n",
      "Epoch [6/50], Step [380/735], Loss: 0.4878\n",
      "Epoch [6/50], Step [381/735], Loss: 0.1235\n",
      "Epoch [6/50], Step [382/735], Loss: 0.4412\n",
      "Epoch [6/50], Step [383/735], Loss: 0.1831\n",
      "Epoch [6/50], Step [384/735], Loss: 0.7233\n",
      "Epoch [6/50], Step [385/735], Loss: 0.3380\n",
      "Epoch [6/50], Step [386/735], Loss: 0.5759\n",
      "Epoch [6/50], Step [387/735], Loss: 0.1481\n",
      "Epoch [6/50], Step [388/735], Loss: 0.3168\n",
      "Epoch [6/50], Step [389/735], Loss: 0.3750\n",
      "Epoch [6/50], Step [390/735], Loss: 0.8293\n",
      "Epoch [6/50], Step [391/735], Loss: 0.2646\n",
      "Epoch [6/50], Step [392/735], Loss: 0.3872\n",
      "Epoch [6/50], Step [393/735], Loss: 0.6227\n",
      "Epoch [6/50], Step [394/735], Loss: 0.3043\n",
      "Epoch [6/50], Step [395/735], Loss: 0.3642\n",
      "Epoch [6/50], Step [396/735], Loss: 1.1802\n",
      "Epoch [6/50], Step [397/735], Loss: 0.1069\n",
      "Epoch [6/50], Step [398/735], Loss: 0.7047\n",
      "Epoch [6/50], Step [399/735], Loss: 0.6998\n",
      "Epoch [6/50], Step [400/735], Loss: 0.3904\n",
      "Epoch [6/50], Step [401/735], Loss: 1.0496\n",
      "Epoch [6/50], Step [402/735], Loss: 0.3961\n",
      "Epoch [6/50], Step [403/735], Loss: 0.7744\n",
      "Epoch [6/50], Step [404/735], Loss: 0.3471\n",
      "Epoch [6/50], Step [405/735], Loss: 0.2038\n",
      "Epoch [6/50], Step [406/735], Loss: 0.3083\n",
      "Epoch [6/50], Step [407/735], Loss: 0.5875\n",
      "Epoch [6/50], Step [408/735], Loss: 0.2046\n",
      "Epoch [6/50], Step [409/735], Loss: 0.1518\n",
      "Epoch [6/50], Step [410/735], Loss: 0.2176\n",
      "Epoch [6/50], Step [411/735], Loss: 0.3932\n",
      "Epoch [6/50], Step [412/735], Loss: 0.5911\n",
      "Epoch [6/50], Step [413/735], Loss: 1.6511\n",
      "Epoch [6/50], Step [414/735], Loss: 0.7690\n",
      "Epoch [6/50], Step [415/735], Loss: 0.3647\n",
      "Epoch [6/50], Step [416/735], Loss: 0.1871\n",
      "Epoch [6/50], Step [417/735], Loss: 0.4831\n",
      "Epoch [6/50], Step [418/735], Loss: 1.0593\n",
      "Epoch [6/50], Step [419/735], Loss: 0.2606\n",
      "Epoch [6/50], Step [420/735], Loss: 0.1943\n",
      "Epoch [6/50], Step [421/735], Loss: 0.2166\n",
      "Epoch [6/50], Step [422/735], Loss: 1.8108\n",
      "Epoch [6/50], Step [423/735], Loss: 0.3297\n",
      "Epoch [6/50], Step [424/735], Loss: 1.2716\n",
      "Epoch [6/50], Step [425/735], Loss: 0.1975\n",
      "Epoch [6/50], Step [426/735], Loss: 0.4603\n",
      "Epoch [6/50], Step [427/735], Loss: 0.3048\n",
      "Epoch [6/50], Step [428/735], Loss: 0.6882\n",
      "Epoch [6/50], Step [429/735], Loss: 0.8556\n",
      "Epoch [6/50], Step [430/735], Loss: 0.5843\n",
      "Epoch [6/50], Step [431/735], Loss: 0.6316\n",
      "Epoch [6/50], Step [432/735], Loss: 0.3308\n",
      "Epoch [6/50], Step [433/735], Loss: 0.0901\n",
      "Epoch [6/50], Step [434/735], Loss: 0.2754\n",
      "Epoch [6/50], Step [435/735], Loss: 1.0156\n",
      "Epoch [6/50], Step [436/735], Loss: 0.3018\n",
      "Epoch [6/50], Step [437/735], Loss: 0.5628\n",
      "Epoch [6/50], Step [438/735], Loss: 0.3473\n",
      "Epoch [6/50], Step [439/735], Loss: 0.2290\n",
      "Epoch [6/50], Step [440/735], Loss: 0.4259\n",
      "Epoch [6/50], Step [441/735], Loss: 0.1637\n",
      "Epoch [6/50], Step [442/735], Loss: 1.0336\n",
      "Epoch [6/50], Step [443/735], Loss: 0.1749\n",
      "Epoch [6/50], Step [444/735], Loss: 0.1703\n",
      "Epoch [6/50], Step [445/735], Loss: 0.1544\n",
      "Epoch [6/50], Step [446/735], Loss: 1.3015\n",
      "Epoch [6/50], Step [447/735], Loss: 0.5432\n",
      "Epoch [6/50], Step [448/735], Loss: 0.1750\n",
      "Epoch [6/50], Step [449/735], Loss: 0.3526\n",
      "Epoch [6/50], Step [450/735], Loss: 0.2079\n",
      "Epoch [6/50], Step [451/735], Loss: 0.6772\n",
      "Epoch [6/50], Step [452/735], Loss: 0.1865\n",
      "Epoch [6/50], Step [453/735], Loss: 0.1959\n",
      "Epoch [6/50], Step [454/735], Loss: 0.2293\n",
      "Epoch [6/50], Step [455/735], Loss: 0.4608\n",
      "Epoch [6/50], Step [456/735], Loss: 0.1847\n",
      "Epoch [6/50], Step [457/735], Loss: 0.2163\n",
      "Epoch [6/50], Step [458/735], Loss: 0.2232\n",
      "Epoch [6/50], Step [459/735], Loss: 0.3791\n",
      "Epoch [6/50], Step [460/735], Loss: 0.2899\n",
      "Epoch [6/50], Step [461/735], Loss: 0.5046\n",
      "Epoch [6/50], Step [462/735], Loss: 0.2376\n",
      "Epoch [6/50], Step [463/735], Loss: 0.6410\n",
      "Epoch [6/50], Step [464/735], Loss: 0.2168\n",
      "Epoch [6/50], Step [465/735], Loss: 1.1322\n",
      "Epoch [6/50], Step [466/735], Loss: 0.6221\n",
      "Epoch [6/50], Step [467/735], Loss: 0.3352\n",
      "Epoch [6/50], Step [468/735], Loss: 0.5787\n",
      "Epoch [6/50], Step [469/735], Loss: 0.5513\n",
      "Epoch [6/50], Step [470/735], Loss: 0.2662\n",
      "Epoch [6/50], Step [471/735], Loss: 1.0628\n",
      "Epoch [6/50], Step [472/735], Loss: 0.3655\n",
      "Epoch [6/50], Step [473/735], Loss: 0.5520\n",
      "Epoch [6/50], Step [474/735], Loss: 2.0417\n",
      "Epoch [6/50], Step [475/735], Loss: 0.3000\n",
      "Epoch [6/50], Step [476/735], Loss: 0.6358\n",
      "Epoch [6/50], Step [477/735], Loss: 0.4842\n",
      "Epoch [6/50], Step [478/735], Loss: 0.7994\n",
      "Epoch [6/50], Step [479/735], Loss: 0.3992\n",
      "Epoch [6/50], Step [480/735], Loss: 0.4488\n",
      "Epoch [6/50], Step [481/735], Loss: 0.2348\n",
      "Epoch [6/50], Step [482/735], Loss: 1.5588\n",
      "Epoch [6/50], Step [483/735], Loss: 0.6683\n",
      "Epoch [6/50], Step [484/735], Loss: 0.3758\n",
      "Epoch [6/50], Step [485/735], Loss: 1.1254\n",
      "Epoch [6/50], Step [486/735], Loss: 0.2156\n",
      "Epoch [6/50], Step [487/735], Loss: 0.3773\n",
      "Epoch [6/50], Step [488/735], Loss: 0.2436\n",
      "Epoch [6/50], Step [489/735], Loss: 0.6115\n",
      "Epoch [6/50], Step [490/735], Loss: 0.9028\n",
      "Epoch [6/50], Step [491/735], Loss: 0.2734\n",
      "Epoch [6/50], Step [492/735], Loss: 0.5403\n",
      "Epoch [6/50], Step [493/735], Loss: 2.3863\n",
      "Epoch [6/50], Step [494/735], Loss: 0.1278\n",
      "Epoch [6/50], Step [495/735], Loss: 0.2380\n",
      "Epoch [6/50], Step [496/735], Loss: 0.4899\n",
      "Epoch [6/50], Step [497/735], Loss: 0.3367\n",
      "Epoch [6/50], Step [498/735], Loss: 0.4130\n",
      "Epoch [6/50], Step [499/735], Loss: 0.6463\n",
      "Epoch [6/50], Step [500/735], Loss: 4.4988\n",
      "Epoch [6/50], Step [501/735], Loss: 0.2686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Step [502/735], Loss: 2.1635\n",
      "Epoch [6/50], Step [503/735], Loss: 0.1760\n",
      "Epoch [6/50], Step [504/735], Loss: 0.2319\n",
      "Epoch [6/50], Step [505/735], Loss: 1.0941\n",
      "Epoch [6/50], Step [506/735], Loss: 0.9544\n",
      "Epoch [6/50], Step [507/735], Loss: 0.3846\n",
      "Epoch [6/50], Step [508/735], Loss: 5.8117\n",
      "Epoch [6/50], Step [509/735], Loss: 0.2035\n",
      "Epoch [6/50], Step [510/735], Loss: 0.3615\n",
      "Epoch [6/50], Step [511/735], Loss: 0.3157\n",
      "Epoch [6/50], Step [512/735], Loss: 0.6530\n",
      "Epoch [6/50], Step [513/735], Loss: 2.2853\n",
      "Epoch [6/50], Step [514/735], Loss: 0.4195\n",
      "Epoch [6/50], Step [515/735], Loss: 0.4503\n",
      "Epoch [6/50], Step [516/735], Loss: 0.2766\n",
      "Epoch [6/50], Step [517/735], Loss: 0.5027\n",
      "Epoch [6/50], Step [518/735], Loss: 0.5368\n",
      "Epoch [6/50], Step [519/735], Loss: 0.4770\n",
      "Epoch [6/50], Step [520/735], Loss: 0.6504\n",
      "Epoch [6/50], Step [521/735], Loss: 0.5573\n",
      "Epoch [6/50], Step [522/735], Loss: 0.1547\n",
      "Epoch [6/50], Step [523/735], Loss: 0.5767\n",
      "Epoch [6/50], Step [524/735], Loss: 0.3871\n",
      "Epoch [6/50], Step [525/735], Loss: 0.5173\n",
      "Epoch [6/50], Step [526/735], Loss: 0.2779\n",
      "Epoch [6/50], Step [527/735], Loss: 0.3452\n",
      "Epoch [6/50], Step [528/735], Loss: 0.1868\n",
      "Epoch [6/50], Step [529/735], Loss: 0.2103\n",
      "Epoch [6/50], Step [530/735], Loss: 0.8291\n",
      "Epoch [6/50], Step [531/735], Loss: 0.2019\n",
      "Epoch [6/50], Step [532/735], Loss: 0.8304\n",
      "Epoch [6/50], Step [533/735], Loss: 0.3569\n",
      "Epoch [6/50], Step [534/735], Loss: 0.3455\n",
      "Epoch [6/50], Step [535/735], Loss: 0.5136\n",
      "Epoch [6/50], Step [536/735], Loss: 0.3147\n",
      "Epoch [6/50], Step [537/735], Loss: 0.1321\n",
      "Epoch [6/50], Step [538/735], Loss: 0.8162\n",
      "Epoch [6/50], Step [539/735], Loss: 0.7933\n",
      "Epoch [6/50], Step [540/735], Loss: 0.2583\n",
      "Epoch [6/50], Step [541/735], Loss: 0.2730\n",
      "Epoch [6/50], Step [542/735], Loss: 0.2757\n",
      "Epoch [6/50], Step [543/735], Loss: 0.9428\n",
      "Epoch [6/50], Step [544/735], Loss: 0.8075\n",
      "Epoch [6/50], Step [545/735], Loss: 1.2854\n",
      "Epoch [6/50], Step [546/735], Loss: 0.2167\n",
      "Epoch [6/50], Step [547/735], Loss: 0.2482\n",
      "Epoch [6/50], Step [548/735], Loss: 1.8365\n",
      "Epoch [6/50], Step [549/735], Loss: 0.3038\n",
      "Epoch [6/50], Step [550/735], Loss: 0.2749\n",
      "Epoch [6/50], Step [551/735], Loss: 0.5649\n",
      "Epoch [6/50], Step [552/735], Loss: 0.3232\n",
      "Epoch [6/50], Step [553/735], Loss: 0.3137\n",
      "Epoch [6/50], Step [554/735], Loss: 0.2987\n",
      "Epoch [6/50], Step [555/735], Loss: 0.4399\n",
      "Epoch [6/50], Step [556/735], Loss: 0.3360\n",
      "Epoch [6/50], Step [557/735], Loss: 0.4676\n",
      "Epoch [6/50], Step [558/735], Loss: 0.1588\n",
      "Epoch [6/50], Step [559/735], Loss: 0.2967\n",
      "Epoch [6/50], Step [560/735], Loss: 0.3021\n",
      "Epoch [6/50], Step [561/735], Loss: 0.8877\n",
      "Epoch [6/50], Step [562/735], Loss: 0.5469\n",
      "Epoch [6/50], Step [563/735], Loss: 0.5499\n",
      "Epoch [6/50], Step [564/735], Loss: 0.2943\n",
      "Epoch [6/50], Step [565/735], Loss: 0.3448\n",
      "Epoch [6/50], Step [566/735], Loss: 0.9187\n",
      "Epoch [6/50], Step [567/735], Loss: 0.1806\n",
      "Epoch [6/50], Step [568/735], Loss: 0.1726\n",
      "Epoch [6/50], Step [569/735], Loss: 0.2117\n",
      "Epoch [6/50], Step [570/735], Loss: 1.1928\n",
      "Epoch [6/50], Step [571/735], Loss: 0.2272\n",
      "Epoch [6/50], Step [572/735], Loss: 1.6260\n",
      "Epoch [6/50], Step [573/735], Loss: 0.5650\n",
      "Epoch [6/50], Step [574/735], Loss: 0.8810\n",
      "Epoch [6/50], Step [575/735], Loss: 0.2868\n",
      "Epoch [6/50], Step [576/735], Loss: 0.5536\n",
      "Epoch [6/50], Step [577/735], Loss: 0.6355\n",
      "Epoch [6/50], Step [578/735], Loss: 0.4044\n",
      "Epoch [6/50], Step [579/735], Loss: 1.0950\n",
      "Epoch [6/50], Step [580/735], Loss: 0.2148\n",
      "Epoch [6/50], Step [581/735], Loss: 0.4737\n",
      "Epoch [6/50], Step [582/735], Loss: 1.5017\n",
      "Epoch [6/50], Step [583/735], Loss: 0.4879\n",
      "Epoch [6/50], Step [584/735], Loss: 0.1541\n",
      "Epoch [6/50], Step [585/735], Loss: 0.4050\n",
      "Epoch [6/50], Step [586/735], Loss: 0.4723\n",
      "Epoch [6/50], Step [587/735], Loss: 0.7041\n",
      "Epoch [6/50], Step [588/735], Loss: 0.5184\n",
      "Epoch [6/50], Step [589/735], Loss: 0.2943\n",
      "Epoch [6/50], Step [590/735], Loss: 0.5103\n",
      "Epoch [6/50], Step [591/735], Loss: 0.2506\n",
      "Epoch [6/50], Step [592/735], Loss: 0.5514\n",
      "Epoch [6/50], Step [593/735], Loss: 0.1843\n",
      "Epoch [6/50], Step [594/735], Loss: 0.3164\n",
      "Epoch [6/50], Step [595/735], Loss: 0.7844\n",
      "Epoch [6/50], Step [596/735], Loss: 0.3423\n",
      "Epoch [6/50], Step [597/735], Loss: 0.2098\n",
      "Epoch [6/50], Step [598/735], Loss: 0.6904\n",
      "Epoch [6/50], Step [599/735], Loss: 0.3913\n",
      "Epoch [6/50], Step [600/735], Loss: 0.6038\n",
      "Epoch [6/50], Step [601/735], Loss: 0.2737\n",
      "Epoch [6/50], Step [602/735], Loss: 0.2001\n",
      "Epoch [6/50], Step [603/735], Loss: 0.4458\n",
      "Epoch [6/50], Step [604/735], Loss: 0.8072\n",
      "Epoch [6/50], Step [605/735], Loss: 0.3307\n",
      "Epoch [6/50], Step [606/735], Loss: 0.1380\n",
      "Epoch [6/50], Step [607/735], Loss: 0.3725\n",
      "Epoch [6/50], Step [608/735], Loss: 0.1556\n",
      "Epoch [6/50], Step [609/735], Loss: 0.3657\n",
      "Epoch [6/50], Step [610/735], Loss: 0.2159\n",
      "Epoch [6/50], Step [611/735], Loss: 0.1655\n",
      "Epoch [6/50], Step [612/735], Loss: 0.2051\n",
      "Epoch [6/50], Step [613/735], Loss: 0.2796\n",
      "Epoch [6/50], Step [614/735], Loss: 0.6354\n",
      "Epoch [6/50], Step [615/735], Loss: 0.3596\n",
      "Epoch [6/50], Step [616/735], Loss: 0.5616\n",
      "Epoch [6/50], Step [617/735], Loss: 0.0781\n",
      "Epoch [6/50], Step [618/735], Loss: 0.4058\n",
      "Epoch [6/50], Step [619/735], Loss: 0.5044\n",
      "Epoch [6/50], Step [620/735], Loss: 0.4882\n",
      "Epoch [6/50], Step [621/735], Loss: 2.1687\n",
      "Epoch [6/50], Step [622/735], Loss: 0.1886\n",
      "Epoch [6/50], Step [623/735], Loss: 0.5851\n",
      "Epoch [6/50], Step [624/735], Loss: 0.2979\n",
      "Epoch [6/50], Step [625/735], Loss: 0.2969\n",
      "Epoch [6/50], Step [626/735], Loss: 0.2103\n",
      "Epoch [6/50], Step [627/735], Loss: 0.2536\n",
      "Epoch [6/50], Step [628/735], Loss: 0.1399\n",
      "Epoch [6/50], Step [629/735], Loss: 0.1362\n",
      "Epoch [6/50], Step [630/735], Loss: 1.0473\n",
      "Epoch [6/50], Step [631/735], Loss: 0.6124\n",
      "Epoch [6/50], Step [632/735], Loss: 0.4367\n",
      "Epoch [6/50], Step [633/735], Loss: 0.3166\n",
      "Epoch [6/50], Step [634/735], Loss: 0.4489\n",
      "Epoch [6/50], Step [635/735], Loss: 0.6975\n",
      "Epoch [6/50], Step [636/735], Loss: 0.5396\n",
      "Epoch [6/50], Step [637/735], Loss: 0.4021\n",
      "Epoch [6/50], Step [638/735], Loss: 0.2326\n",
      "Epoch [6/50], Step [639/735], Loss: 0.4390\n",
      "Epoch [6/50], Step [640/735], Loss: 1.4465\n",
      "Epoch [6/50], Step [641/735], Loss: 0.2662\n",
      "Epoch [6/50], Step [642/735], Loss: 0.5979\n",
      "Epoch [6/50], Step [643/735], Loss: 0.2300\n",
      "Epoch [6/50], Step [644/735], Loss: 0.4975\n",
      "Epoch [6/50], Step [645/735], Loss: 0.5094\n",
      "Epoch [6/50], Step [646/735], Loss: 0.5702\n",
      "Epoch [6/50], Step [647/735], Loss: 0.2623\n",
      "Epoch [6/50], Step [648/735], Loss: 0.3436\n",
      "Epoch [6/50], Step [649/735], Loss: 0.2276\n",
      "Epoch [6/50], Step [650/735], Loss: 0.9186\n",
      "Epoch [6/50], Step [651/735], Loss: 0.8736\n",
      "Epoch [6/50], Step [652/735], Loss: 1.0299\n",
      "Epoch [6/50], Step [653/735], Loss: 0.6089\n",
      "Epoch [6/50], Step [654/735], Loss: 0.1849\n",
      "Epoch [6/50], Step [655/735], Loss: 0.9241\n",
      "Epoch [6/50], Step [656/735], Loss: 0.1471\n",
      "Epoch [6/50], Step [657/735], Loss: 0.7742\n",
      "Epoch [6/50], Step [658/735], Loss: 0.8914\n",
      "Epoch [6/50], Step [659/735], Loss: 0.4405\n",
      "Epoch [6/50], Step [660/735], Loss: 0.2012\n",
      "Epoch [6/50], Step [661/735], Loss: 0.4190\n",
      "Epoch [6/50], Step [662/735], Loss: 5.7658\n",
      "Epoch [6/50], Step [663/735], Loss: 0.8572\n",
      "Epoch [6/50], Step [664/735], Loss: 0.2270\n",
      "Epoch [6/50], Step [665/735], Loss: 1.9166\n",
      "Epoch [6/50], Step [666/735], Loss: 0.2718\n",
      "Epoch [6/50], Step [667/735], Loss: 0.3726\n",
      "Epoch [6/50], Step [668/735], Loss: 0.3367\n",
      "Epoch [6/50], Step [669/735], Loss: 0.3296\n",
      "Epoch [6/50], Step [670/735], Loss: 0.3695\n",
      "Epoch [6/50], Step [671/735], Loss: 0.3308\n",
      "Epoch [6/50], Step [672/735], Loss: 1.3081\n",
      "Epoch [6/50], Step [673/735], Loss: 1.2106\n",
      "Epoch [6/50], Step [674/735], Loss: 0.1752\n",
      "Epoch [6/50], Step [675/735], Loss: 0.1131\n",
      "Epoch [6/50], Step [676/735], Loss: 2.5511\n",
      "Epoch [6/50], Step [677/735], Loss: 0.2843\n",
      "Epoch [6/50], Step [678/735], Loss: 0.9168\n",
      "Epoch [6/50], Step [679/735], Loss: 0.7657\n",
      "Epoch [6/50], Step [680/735], Loss: 1.1093\n",
      "Epoch [6/50], Step [681/735], Loss: 0.1409\n",
      "Epoch [6/50], Step [682/735], Loss: 0.3294\n",
      "Epoch [6/50], Step [683/735], Loss: 0.1587\n",
      "Epoch [6/50], Step [684/735], Loss: 0.2679\n",
      "Epoch [6/50], Step [685/735], Loss: 0.3856\n",
      "Epoch [6/50], Step [686/735], Loss: 1.6098\n",
      "Epoch [6/50], Step [687/735], Loss: 0.5490\n",
      "Epoch [6/50], Step [688/735], Loss: 0.2492\n",
      "Epoch [6/50], Step [689/735], Loss: 0.3368\n",
      "Epoch [6/50], Step [690/735], Loss: 0.3655\n",
      "Epoch [6/50], Step [691/735], Loss: 0.3325\n",
      "Epoch [6/50], Step [692/735], Loss: 1.1824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Step [693/735], Loss: 0.2965\n",
      "Epoch [6/50], Step [694/735], Loss: 0.2245\n",
      "Epoch [6/50], Step [695/735], Loss: 0.1250\n",
      "Epoch [6/50], Step [696/735], Loss: 0.4613\n",
      "Epoch [6/50], Step [697/735], Loss: 0.2849\n",
      "Epoch [6/50], Step [698/735], Loss: 0.2850\n",
      "Epoch [6/50], Step [699/735], Loss: 0.2412\n",
      "Epoch [6/50], Step [700/735], Loss: 0.6716\n",
      "Epoch [6/50], Step [701/735], Loss: 0.2857\n",
      "Epoch [6/50], Step [702/735], Loss: 1.0763\n",
      "Epoch [6/50], Step [703/735], Loss: 0.1443\n",
      "Epoch [6/50], Step [704/735], Loss: 0.9474\n",
      "Epoch [6/50], Step [705/735], Loss: 0.1916\n",
      "Epoch [6/50], Step [706/735], Loss: 0.6504\n",
      "Epoch [6/50], Step [707/735], Loss: 0.2208\n",
      "Epoch [6/50], Step [708/735], Loss: 0.2816\n",
      "Epoch [6/50], Step [709/735], Loss: 2.3276\n",
      "Epoch [6/50], Step [710/735], Loss: 0.2368\n",
      "Epoch [6/50], Step [711/735], Loss: 0.6775\n",
      "Epoch [6/50], Step [712/735], Loss: 0.7569\n",
      "Epoch [6/50], Step [713/735], Loss: 0.1094\n",
      "Epoch [6/50], Step [714/735], Loss: 1.1010\n",
      "Epoch [6/50], Step [715/735], Loss: 0.6003\n",
      "Epoch [6/50], Step [716/735], Loss: 0.3779\n",
      "Epoch [6/50], Step [717/735], Loss: 0.7166\n",
      "Epoch [6/50], Step [718/735], Loss: 0.7781\n",
      "Epoch [6/50], Step [719/735], Loss: 0.2741\n",
      "Epoch [6/50], Step [720/735], Loss: 0.1666\n",
      "Epoch [6/50], Step [721/735], Loss: 0.9411\n",
      "Epoch [6/50], Step [722/735], Loss: 0.4905\n",
      "Epoch [6/50], Step [723/735], Loss: 0.8988\n",
      "Epoch [6/50], Step [724/735], Loss: 0.7644\n",
      "Epoch [6/50], Step [725/735], Loss: 0.3079\n",
      "Epoch [6/50], Step [726/735], Loss: 0.4836\n",
      "Epoch [6/50], Step [727/735], Loss: 0.1630\n",
      "Epoch [6/50], Step [728/735], Loss: 5.4962\n",
      "Epoch [6/50], Step [729/735], Loss: 0.1581\n",
      "Epoch [6/50], Step [730/735], Loss: 0.2473\n",
      "Epoch [6/50], Step [731/735], Loss: 0.5118\n",
      "Epoch [6/50], Step [732/735], Loss: 0.3931\n",
      "Epoch [6/50], Step [733/735], Loss: 0.1609\n",
      "Epoch [6/50], Step [734/735], Loss: 0.1983\n",
      "Epoch [6/50], Step [735/735], Loss: 0.0947\n",
      "Epoch [7/50], Step [1/735], Loss: 0.8520\n",
      "Epoch [7/50], Step [2/735], Loss: 0.3525\n",
      "Epoch [7/50], Step [3/735], Loss: 0.3046\n",
      "Epoch [7/50], Step [4/735], Loss: 0.2364\n",
      "Epoch [7/50], Step [5/735], Loss: 6.3153\n",
      "Epoch [7/50], Step [6/735], Loss: 1.7127\n",
      "Epoch [7/50], Step [7/735], Loss: 0.7041\n",
      "Epoch [7/50], Step [8/735], Loss: 0.1778\n",
      "Epoch [7/50], Step [9/735], Loss: 0.6037\n",
      "Epoch [7/50], Step [10/735], Loss: 0.4280\n",
      "Epoch [7/50], Step [11/735], Loss: 0.7365\n",
      "Epoch [7/50], Step [12/735], Loss: 0.3203\n",
      "Epoch [7/50], Step [13/735], Loss: 1.3576\n",
      "Epoch [7/50], Step [14/735], Loss: 0.4069\n",
      "Epoch [7/50], Step [15/735], Loss: 0.6074\n",
      "Epoch [7/50], Step [16/735], Loss: 0.4023\n",
      "Epoch [7/50], Step [17/735], Loss: 0.5904\n",
      "Epoch [7/50], Step [18/735], Loss: 0.7203\n",
      "Epoch [7/50], Step [19/735], Loss: 0.3847\n",
      "Epoch [7/50], Step [20/735], Loss: 0.4880\n",
      "Epoch [7/50], Step [21/735], Loss: 0.2180\n",
      "Epoch [7/50], Step [22/735], Loss: 0.6721\n",
      "Epoch [7/50], Step [23/735], Loss: 0.3957\n",
      "Epoch [7/50], Step [24/735], Loss: 0.7269\n",
      "Epoch [7/50], Step [25/735], Loss: 0.2899\n",
      "Epoch [7/50], Step [26/735], Loss: 0.7478\n",
      "Epoch [7/50], Step [27/735], Loss: 0.4668\n",
      "Epoch [7/50], Step [28/735], Loss: 0.2467\n",
      "Epoch [7/50], Step [29/735], Loss: 0.1144\n",
      "Epoch [7/50], Step [30/735], Loss: 0.4949\n",
      "Epoch [7/50], Step [31/735], Loss: 0.2690\n",
      "Epoch [7/50], Step [32/735], Loss: 0.2053\n",
      "Epoch [7/50], Step [33/735], Loss: 0.5253\n",
      "Epoch [7/50], Step [34/735], Loss: 1.3675\n",
      "Epoch [7/50], Step [35/735], Loss: 0.5277\n",
      "Epoch [7/50], Step [36/735], Loss: 0.1698\n",
      "Epoch [7/50], Step [37/735], Loss: 0.2190\n",
      "Epoch [7/50], Step [38/735], Loss: 0.6780\n",
      "Epoch [7/50], Step [39/735], Loss: 1.4174\n",
      "Epoch [7/50], Step [40/735], Loss: 0.3125\n",
      "Epoch [7/50], Step [41/735], Loss: 0.5193\n",
      "Epoch [7/50], Step [42/735], Loss: 0.9038\n",
      "Epoch [7/50], Step [43/735], Loss: 0.3538\n",
      "Epoch [7/50], Step [44/735], Loss: 0.1573\n",
      "Epoch [7/50], Step [45/735], Loss: 0.2451\n",
      "Epoch [7/50], Step [46/735], Loss: 0.2442\n",
      "Epoch [7/50], Step [47/735], Loss: 0.1744\n",
      "Epoch [7/50], Step [48/735], Loss: 0.1073\n",
      "Epoch [7/50], Step [49/735], Loss: 1.7994\n",
      "Epoch [7/50], Step [50/735], Loss: 0.5503\n",
      "Epoch [7/50], Step [51/735], Loss: 0.7878\n",
      "Epoch [7/50], Step [52/735], Loss: 0.6041\n",
      "Epoch [7/50], Step [53/735], Loss: 0.8945\n",
      "Epoch [7/50], Step [54/735], Loss: 1.0798\n",
      "Epoch [7/50], Step [55/735], Loss: 2.6922\n",
      "Epoch [7/50], Step [56/735], Loss: 0.5826\n",
      "Epoch [7/50], Step [57/735], Loss: 0.4293\n",
      "Epoch [7/50], Step [58/735], Loss: 0.1946\n",
      "Epoch [7/50], Step [59/735], Loss: 0.2966\n",
      "Epoch [7/50], Step [60/735], Loss: 0.3087\n",
      "Epoch [7/50], Step [61/735], Loss: 0.5215\n",
      "Epoch [7/50], Step [62/735], Loss: 1.3486\n",
      "Epoch [7/50], Step [63/735], Loss: 0.6389\n",
      "Epoch [7/50], Step [64/735], Loss: 0.2328\n",
      "Epoch [7/50], Step [65/735], Loss: 0.2540\n",
      "Epoch [7/50], Step [66/735], Loss: 0.3137\n",
      "Epoch [7/50], Step [67/735], Loss: 0.4223\n",
      "Epoch [7/50], Step [68/735], Loss: 0.3697\n",
      "Epoch [7/50], Step [69/735], Loss: 0.2896\n",
      "Epoch [7/50], Step [70/735], Loss: 1.5116\n",
      "Epoch [7/50], Step [71/735], Loss: 0.7125\n",
      "Epoch [7/50], Step [72/735], Loss: 0.0699\n",
      "Epoch [7/50], Step [73/735], Loss: 0.1791\n",
      "Epoch [7/50], Step [74/735], Loss: 0.1299\n",
      "Epoch [7/50], Step [75/735], Loss: 0.3272\n",
      "Epoch [7/50], Step [76/735], Loss: 0.5288\n",
      "Epoch [7/50], Step [77/735], Loss: 1.3267\n",
      "Epoch [7/50], Step [78/735], Loss: 0.1662\n",
      "Epoch [7/50], Step [79/735], Loss: 0.3867\n",
      "Epoch [7/50], Step [80/735], Loss: 0.1908\n",
      "Epoch [7/50], Step [81/735], Loss: 1.0150\n",
      "Epoch [7/50], Step [82/735], Loss: 0.4492\n",
      "Epoch [7/50], Step [83/735], Loss: 0.6493\n",
      "Epoch [7/50], Step [84/735], Loss: 0.4518\n",
      "Epoch [7/50], Step [85/735], Loss: 0.1295\n",
      "Epoch [7/50], Step [86/735], Loss: 0.8303\n",
      "Epoch [7/50], Step [87/735], Loss: 0.8356\n",
      "Epoch [7/50], Step [88/735], Loss: 0.2124\n",
      "Epoch [7/50], Step [89/735], Loss: 5.6337\n",
      "Epoch [7/50], Step [90/735], Loss: 0.2892\n",
      "Epoch [7/50], Step [91/735], Loss: 0.8255\n",
      "Epoch [7/50], Step [92/735], Loss: 0.7906\n",
      "Epoch [7/50], Step [93/735], Loss: 0.4623\n",
      "Epoch [7/50], Step [94/735], Loss: 0.2786\n",
      "Epoch [7/50], Step [95/735], Loss: 0.2078\n",
      "Epoch [7/50], Step [96/735], Loss: 0.3466\n",
      "Epoch [7/50], Step [97/735], Loss: 0.5602\n",
      "Epoch [7/50], Step [98/735], Loss: 0.3558\n",
      "Epoch [7/50], Step [99/735], Loss: 1.1389\n",
      "Epoch [7/50], Step [100/735], Loss: 0.7606\n",
      "Epoch [7/50], Step [101/735], Loss: 1.0350\n",
      "Epoch [7/50], Step [102/735], Loss: 2.0299\n",
      "Epoch [7/50], Step [103/735], Loss: 0.4024\n",
      "Epoch [7/50], Step [104/735], Loss: 0.1940\n",
      "Epoch [7/50], Step [105/735], Loss: 0.3661\n",
      "Epoch [7/50], Step [106/735], Loss: 0.9058\n",
      "Epoch [7/50], Step [107/735], Loss: 1.5497\n",
      "Epoch [7/50], Step [108/735], Loss: 0.3785\n",
      "Epoch [7/50], Step [109/735], Loss: 0.2336\n",
      "Epoch [7/50], Step [110/735], Loss: 0.3621\n",
      "Epoch [7/50], Step [111/735], Loss: 0.1932\n",
      "Epoch [7/50], Step [112/735], Loss: 1.9284\n",
      "Epoch [7/50], Step [113/735], Loss: 0.1649\n",
      "Epoch [7/50], Step [114/735], Loss: 0.1741\n",
      "Epoch [7/50], Step [115/735], Loss: 0.3039\n",
      "Epoch [7/50], Step [116/735], Loss: 1.3899\n",
      "Epoch [7/50], Step [117/735], Loss: 0.4788\n",
      "Epoch [7/50], Step [118/735], Loss: 0.5130\n",
      "Epoch [7/50], Step [119/735], Loss: 0.3849\n",
      "Epoch [7/50], Step [120/735], Loss: 0.6389\n",
      "Epoch [7/50], Step [121/735], Loss: 1.8898\n",
      "Epoch [7/50], Step [122/735], Loss: 0.4573\n",
      "Epoch [7/50], Step [123/735], Loss: 0.3890\n",
      "Epoch [7/50], Step [124/735], Loss: 0.2208\n",
      "Epoch [7/50], Step [125/735], Loss: 0.8459\n",
      "Epoch [7/50], Step [126/735], Loss: 0.7557\n",
      "Epoch [7/50], Step [127/735], Loss: 0.6040\n",
      "Epoch [7/50], Step [128/735], Loss: 0.2343\n",
      "Epoch [7/50], Step [129/735], Loss: 0.2419\n",
      "Epoch [7/50], Step [130/735], Loss: 0.1358\n",
      "Epoch [7/50], Step [131/735], Loss: 0.2745\n",
      "Epoch [7/50], Step [132/735], Loss: 0.1625\n",
      "Epoch [7/50], Step [133/735], Loss: 0.6547\n",
      "Epoch [7/50], Step [134/735], Loss: 0.3255\n",
      "Epoch [7/50], Step [135/735], Loss: 0.3577\n",
      "Epoch [7/50], Step [136/735], Loss: 0.4280\n",
      "Epoch [7/50], Step [137/735], Loss: 0.1883\n",
      "Epoch [7/50], Step [138/735], Loss: 0.2843\n",
      "Epoch [7/50], Step [139/735], Loss: 0.1633\n",
      "Epoch [7/50], Step [140/735], Loss: 0.3265\n",
      "Epoch [7/50], Step [141/735], Loss: 1.1614\n",
      "Epoch [7/50], Step [142/735], Loss: 0.2303\n",
      "Epoch [7/50], Step [143/735], Loss: 0.7109\n",
      "Epoch [7/50], Step [144/735], Loss: 1.7397\n",
      "Epoch [7/50], Step [145/735], Loss: 0.6577\n",
      "Epoch [7/50], Step [146/735], Loss: 0.6302\n",
      "Epoch [7/50], Step [147/735], Loss: 0.2624\n",
      "Epoch [7/50], Step [148/735], Loss: 0.2989\n",
      "Epoch [7/50], Step [149/735], Loss: 0.4863\n",
      "Epoch [7/50], Step [150/735], Loss: 0.6389\n",
      "Epoch [7/50], Step [151/735], Loss: 0.1164\n",
      "Epoch [7/50], Step [152/735], Loss: 0.7512\n",
      "Epoch [7/50], Step [153/735], Loss: 0.3500\n",
      "Epoch [7/50], Step [154/735], Loss: 0.5058\n",
      "Epoch [7/50], Step [155/735], Loss: 1.0301\n",
      "Epoch [7/50], Step [156/735], Loss: 0.2654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Step [157/735], Loss: 0.4499\n",
      "Epoch [7/50], Step [158/735], Loss: 0.3016\n",
      "Epoch [7/50], Step [159/735], Loss: 1.4722\n",
      "Epoch [7/50], Step [160/735], Loss: 0.6309\n",
      "Epoch [7/50], Step [161/735], Loss: 0.5394\n",
      "Epoch [7/50], Step [162/735], Loss: 0.2892\n",
      "Epoch [7/50], Step [163/735], Loss: 0.2558\n",
      "Epoch [7/50], Step [164/735], Loss: 0.2649\n",
      "Epoch [7/50], Step [165/735], Loss: 0.3062\n",
      "Epoch [7/50], Step [166/735], Loss: 0.7199\n",
      "Epoch [7/50], Step [167/735], Loss: 0.0977\n",
      "Epoch [7/50], Step [168/735], Loss: 0.8539\n",
      "Epoch [7/50], Step [169/735], Loss: 0.3122\n",
      "Epoch [7/50], Step [170/735], Loss: 0.3531\n",
      "Epoch [7/50], Step [171/735], Loss: 0.1444\n",
      "Epoch [7/50], Step [172/735], Loss: 0.9172\n",
      "Epoch [7/50], Step [173/735], Loss: 0.2309\n",
      "Epoch [7/50], Step [174/735], Loss: 0.2667\n",
      "Epoch [7/50], Step [175/735], Loss: 0.4145\n",
      "Epoch [7/50], Step [176/735], Loss: 0.2641\n",
      "Epoch [7/50], Step [177/735], Loss: 1.2310\n",
      "Epoch [7/50], Step [178/735], Loss: 0.2435\n",
      "Epoch [7/50], Step [179/735], Loss: 3.1965\n",
      "Epoch [7/50], Step [180/735], Loss: 0.1142\n",
      "Epoch [7/50], Step [181/735], Loss: 0.8565\n",
      "Epoch [7/50], Step [182/735], Loss: 0.4105\n",
      "Epoch [7/50], Step [183/735], Loss: 0.3363\n",
      "Epoch [7/50], Step [184/735], Loss: 0.2451\n",
      "Epoch [7/50], Step [185/735], Loss: 0.3129\n",
      "Epoch [7/50], Step [186/735], Loss: 0.3725\n",
      "Epoch [7/50], Step [187/735], Loss: 0.3090\n",
      "Epoch [7/50], Step [188/735], Loss: 0.0765\n",
      "Epoch [7/50], Step [189/735], Loss: 0.1596\n",
      "Epoch [7/50], Step [190/735], Loss: 0.2720\n",
      "Epoch [7/50], Step [191/735], Loss: 0.8420\n",
      "Epoch [7/50], Step [192/735], Loss: 0.4879\n",
      "Epoch [7/50], Step [193/735], Loss: 0.2852\n",
      "Epoch [7/50], Step [194/735], Loss: 0.8871\n",
      "Epoch [7/50], Step [195/735], Loss: 0.5702\n",
      "Epoch [7/50], Step [196/735], Loss: 0.6707\n",
      "Epoch [7/50], Step [197/735], Loss: 0.2699\n",
      "Epoch [7/50], Step [198/735], Loss: 0.4401\n",
      "Epoch [7/50], Step [199/735], Loss: 0.5894\n",
      "Epoch [7/50], Step [200/735], Loss: 0.9690\n",
      "Epoch [7/50], Step [201/735], Loss: 0.4355\n",
      "Epoch [7/50], Step [202/735], Loss: 0.3912\n",
      "Epoch [7/50], Step [203/735], Loss: 0.3309\n",
      "Epoch [7/50], Step [204/735], Loss: 0.8537\n",
      "Epoch [7/50], Step [205/735], Loss: 0.2831\n",
      "Epoch [7/50], Step [206/735], Loss: 1.1705\n",
      "Epoch [7/50], Step [207/735], Loss: 0.2783\n",
      "Epoch [7/50], Step [208/735], Loss: 0.9260\n",
      "Epoch [7/50], Step [209/735], Loss: 0.1749\n",
      "Epoch [7/50], Step [210/735], Loss: 0.2190\n",
      "Epoch [7/50], Step [211/735], Loss: 0.5581\n",
      "Epoch [7/50], Step [212/735], Loss: 0.1808\n",
      "Epoch [7/50], Step [213/735], Loss: 0.2383\n",
      "Epoch [7/50], Step [214/735], Loss: 1.7012\n",
      "Epoch [7/50], Step [215/735], Loss: 0.2958\n",
      "Epoch [7/50], Step [216/735], Loss: 0.2680\n",
      "Epoch [7/50], Step [217/735], Loss: 0.7926\n",
      "Epoch [7/50], Step [218/735], Loss: 0.2937\n",
      "Epoch [7/50], Step [219/735], Loss: 0.2831\n",
      "Epoch [7/50], Step [220/735], Loss: 0.2378\n",
      "Epoch [7/50], Step [221/735], Loss: 0.2782\n",
      "Epoch [7/50], Step [222/735], Loss: 0.3510\n",
      "Epoch [7/50], Step [223/735], Loss: 0.2479\n",
      "Epoch [7/50], Step [224/735], Loss: 2.2088\n",
      "Epoch [7/50], Step [225/735], Loss: 0.2534\n",
      "Epoch [7/50], Step [226/735], Loss: 0.8404\n",
      "Epoch [7/50], Step [227/735], Loss: 0.3646\n",
      "Epoch [7/50], Step [228/735], Loss: 0.3247\n",
      "Epoch [7/50], Step [229/735], Loss: 0.5745\n",
      "Epoch [7/50], Step [230/735], Loss: 1.0931\n",
      "Epoch [7/50], Step [231/735], Loss: 0.2064\n",
      "Epoch [7/50], Step [232/735], Loss: 0.6109\n",
      "Epoch [7/50], Step [233/735], Loss: 0.2640\n",
      "Epoch [7/50], Step [234/735], Loss: 0.4184\n",
      "Epoch [7/50], Step [235/735], Loss: 0.7550\n",
      "Epoch [7/50], Step [236/735], Loss: 0.2348\n",
      "Epoch [7/50], Step [237/735], Loss: 0.7744\n",
      "Epoch [7/50], Step [238/735], Loss: 0.1442\n",
      "Epoch [7/50], Step [239/735], Loss: 0.1632\n",
      "Epoch [7/50], Step [240/735], Loss: 0.2063\n",
      "Epoch [7/50], Step [241/735], Loss: 0.6375\n",
      "Epoch [7/50], Step [242/735], Loss: 0.8829\n",
      "Epoch [7/50], Step [243/735], Loss: 0.2668\n",
      "Epoch [7/50], Step [244/735], Loss: 0.9926\n",
      "Epoch [7/50], Step [245/735], Loss: 0.2041\n",
      "Epoch [7/50], Step [246/735], Loss: 0.6803\n",
      "Epoch [7/50], Step [247/735], Loss: 0.6545\n",
      "Epoch [7/50], Step [248/735], Loss: 0.4101\n",
      "Epoch [7/50], Step [249/735], Loss: 0.2384\n",
      "Epoch [7/50], Step [250/735], Loss: 0.1056\n",
      "Epoch [7/50], Step [251/735], Loss: 0.2811\n",
      "Epoch [7/50], Step [252/735], Loss: 0.3487\n",
      "Epoch [7/50], Step [253/735], Loss: 0.6379\n",
      "Epoch [7/50], Step [254/735], Loss: 0.1569\n",
      "Epoch [7/50], Step [255/735], Loss: 0.1797\n",
      "Epoch [7/50], Step [256/735], Loss: 1.0379\n",
      "Epoch [7/50], Step [257/735], Loss: 2.4616\n",
      "Epoch [7/50], Step [258/735], Loss: 0.2468\n",
      "Epoch [7/50], Step [259/735], Loss: 0.4457\n",
      "Epoch [7/50], Step [260/735], Loss: 0.5663\n",
      "Epoch [7/50], Step [261/735], Loss: 0.2324\n",
      "Epoch [7/50], Step [262/735], Loss: 0.7521\n",
      "Epoch [7/50], Step [263/735], Loss: 0.6479\n",
      "Epoch [7/50], Step [264/735], Loss: 0.3215\n",
      "Epoch [7/50], Step [265/735], Loss: 0.1694\n",
      "Epoch [7/50], Step [266/735], Loss: 0.1539\n",
      "Epoch [7/50], Step [267/735], Loss: 0.1008\n",
      "Epoch [7/50], Step [268/735], Loss: 0.3472\n",
      "Epoch [7/50], Step [269/735], Loss: 0.3385\n",
      "Epoch [7/50], Step [270/735], Loss: 0.3817\n",
      "Epoch [7/50], Step [271/735], Loss: 0.1409\n",
      "Epoch [7/50], Step [272/735], Loss: 0.2639\n",
      "Epoch [7/50], Step [273/735], Loss: 0.2159\n",
      "Epoch [7/50], Step [274/735], Loss: 0.3825\n",
      "Epoch [7/50], Step [275/735], Loss: 0.1584\n",
      "Epoch [7/50], Step [276/735], Loss: 0.3357\n",
      "Epoch [7/50], Step [277/735], Loss: 0.4831\n",
      "Epoch [7/50], Step [278/735], Loss: 0.6847\n",
      "Epoch [7/50], Step [279/735], Loss: 0.4212\n",
      "Epoch [7/50], Step [280/735], Loss: 1.1507\n",
      "Epoch [7/50], Step [281/735], Loss: 0.6083\n",
      "Epoch [7/50], Step [282/735], Loss: 0.2243\n",
      "Epoch [7/50], Step [283/735], Loss: 0.2899\n",
      "Epoch [7/50], Step [284/735], Loss: 0.5194\n",
      "Epoch [7/50], Step [285/735], Loss: 0.5864\n",
      "Epoch [7/50], Step [286/735], Loss: 0.0811\n",
      "Epoch [7/50], Step [287/735], Loss: 0.1566\n",
      "Epoch [7/50], Step [288/735], Loss: 0.3015\n",
      "Epoch [7/50], Step [289/735], Loss: 0.3319\n",
      "Epoch [7/50], Step [290/735], Loss: 0.9832\n",
      "Epoch [7/50], Step [291/735], Loss: 0.3185\n",
      "Epoch [7/50], Step [292/735], Loss: 0.4109\n",
      "Epoch [7/50], Step [293/735], Loss: 0.3134\n",
      "Epoch [7/50], Step [294/735], Loss: 0.5551\n",
      "Epoch [7/50], Step [295/735], Loss: 0.1221\n",
      "Epoch [7/50], Step [296/735], Loss: 0.1904\n",
      "Epoch [7/50], Step [297/735], Loss: 0.3519\n",
      "Epoch [7/50], Step [298/735], Loss: 0.4604\n",
      "Epoch [7/50], Step [299/735], Loss: 0.3803\n",
      "Epoch [7/50], Step [300/735], Loss: 0.5643\n",
      "Epoch [7/50], Step [301/735], Loss: 0.6665\n",
      "Epoch [7/50], Step [302/735], Loss: 0.9731\n",
      "Epoch [7/50], Step [303/735], Loss: 0.5394\n",
      "Epoch [7/50], Step [304/735], Loss: 0.3644\n",
      "Epoch [7/50], Step [305/735], Loss: 0.8737\n",
      "Epoch [7/50], Step [306/735], Loss: 0.2301\n",
      "Epoch [7/50], Step [307/735], Loss: 0.4102\n",
      "Epoch [7/50], Step [308/735], Loss: 0.3233\n",
      "Epoch [7/50], Step [309/735], Loss: 0.2063\n",
      "Epoch [7/50], Step [310/735], Loss: 1.5760\n",
      "Epoch [7/50], Step [311/735], Loss: 0.3726\n",
      "Epoch [7/50], Step [312/735], Loss: 0.3921\n",
      "Epoch [7/50], Step [313/735], Loss: 0.5611\n",
      "Epoch [7/50], Step [314/735], Loss: 0.2246\n",
      "Epoch [7/50], Step [315/735], Loss: 0.4812\n",
      "Epoch [7/50], Step [316/735], Loss: 0.0998\n",
      "Epoch [7/50], Step [317/735], Loss: 0.3572\n",
      "Epoch [7/50], Step [318/735], Loss: 0.2458\n",
      "Epoch [7/50], Step [319/735], Loss: 1.4637\n",
      "Epoch [7/50], Step [320/735], Loss: 0.7143\n",
      "Epoch [7/50], Step [321/735], Loss: 1.0775\n",
      "Epoch [7/50], Step [322/735], Loss: 0.2853\n",
      "Epoch [7/50], Step [323/735], Loss: 0.7295\n",
      "Epoch [7/50], Step [324/735], Loss: 0.0755\n",
      "Epoch [7/50], Step [325/735], Loss: 0.1336\n",
      "Epoch [7/50], Step [326/735], Loss: 0.0804\n",
      "Epoch [7/50], Step [327/735], Loss: 0.1126\n",
      "Epoch [7/50], Step [328/735], Loss: 0.2015\n",
      "Epoch [7/50], Step [329/735], Loss: 0.3450\n",
      "Epoch [7/50], Step [330/735], Loss: 0.2965\n",
      "Epoch [7/50], Step [331/735], Loss: 0.1341\n",
      "Epoch [7/50], Step [332/735], Loss: 0.7773\n",
      "Epoch [7/50], Step [333/735], Loss: 0.5283\n",
      "Epoch [7/50], Step [334/735], Loss: 0.0972\n",
      "Epoch [7/50], Step [335/735], Loss: 0.1607\n",
      "Epoch [7/50], Step [336/735], Loss: 0.5615\n",
      "Epoch [7/50], Step [337/735], Loss: 0.5455\n",
      "Epoch [7/50], Step [338/735], Loss: 0.9179\n",
      "Epoch [7/50], Step [339/735], Loss: 0.2169\n",
      "Epoch [7/50], Step [340/735], Loss: 0.1764\n",
      "Epoch [7/50], Step [341/735], Loss: 0.1243\n",
      "Epoch [7/50], Step [342/735], Loss: 0.3078\n",
      "Epoch [7/50], Step [343/735], Loss: 1.1441\n",
      "Epoch [7/50], Step [344/735], Loss: 0.7876\n",
      "Epoch [7/50], Step [345/735], Loss: 0.2022\n",
      "Epoch [7/50], Step [346/735], Loss: 0.5700\n",
      "Epoch [7/50], Step [347/735], Loss: 1.4626\n",
      "Epoch [7/50], Step [348/735], Loss: 0.1962\n",
      "Epoch [7/50], Step [349/735], Loss: 0.1152\n",
      "Epoch [7/50], Step [350/735], Loss: 0.5184\n",
      "Epoch [7/50], Step [351/735], Loss: 0.2923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Step [352/735], Loss: 0.3584\n",
      "Epoch [7/50], Step [353/735], Loss: 0.4609\n",
      "Epoch [7/50], Step [354/735], Loss: 0.1785\n",
      "Epoch [7/50], Step [355/735], Loss: 0.5063\n",
      "Epoch [7/50], Step [356/735], Loss: 0.5826\n",
      "Epoch [7/50], Step [357/735], Loss: 1.1448\n",
      "Epoch [7/50], Step [358/735], Loss: 0.8287\n",
      "Epoch [7/50], Step [359/735], Loss: 2.6266\n",
      "Epoch [7/50], Step [360/735], Loss: 1.0542\n",
      "Epoch [7/50], Step [361/735], Loss: 0.8707\n",
      "Epoch [7/50], Step [362/735], Loss: 0.2166\n",
      "Epoch [7/50], Step [363/735], Loss: 1.0801\n",
      "Epoch [7/50], Step [364/735], Loss: 0.8386\n",
      "Epoch [7/50], Step [365/735], Loss: 0.7660\n",
      "Epoch [7/50], Step [366/735], Loss: 0.2976\n",
      "Epoch [7/50], Step [367/735], Loss: 0.4190\n",
      "Epoch [7/50], Step [368/735], Loss: 0.1678\n",
      "Epoch [7/50], Step [369/735], Loss: 0.9814\n",
      "Epoch [7/50], Step [370/735], Loss: 0.1907\n",
      "Epoch [7/50], Step [371/735], Loss: 0.1213\n",
      "Epoch [7/50], Step [372/735], Loss: 0.1625\n",
      "Epoch [7/50], Step [373/735], Loss: 0.1799\n",
      "Epoch [7/50], Step [374/735], Loss: 0.6523\n",
      "Epoch [7/50], Step [375/735], Loss: 1.2587\n",
      "Epoch [7/50], Step [376/735], Loss: 0.4547\n",
      "Epoch [7/50], Step [377/735], Loss: 0.8743\n",
      "Epoch [7/50], Step [378/735], Loss: 0.5417\n",
      "Epoch [7/50], Step [379/735], Loss: 0.1592\n",
      "Epoch [7/50], Step [380/735], Loss: 0.3470\n",
      "Epoch [7/50], Step [381/735], Loss: 0.2100\n",
      "Epoch [7/50], Step [382/735], Loss: 0.3974\n",
      "Epoch [7/50], Step [383/735], Loss: 2.1475\n",
      "Epoch [7/50], Step [384/735], Loss: 0.2920\n",
      "Epoch [7/50], Step [385/735], Loss: 0.2687\n",
      "Epoch [7/50], Step [386/735], Loss: 0.4300\n",
      "Epoch [7/50], Step [387/735], Loss: 0.7127\n",
      "Epoch [7/50], Step [388/735], Loss: 0.2059\n",
      "Epoch [7/50], Step [389/735], Loss: 1.7059\n",
      "Epoch [7/50], Step [390/735], Loss: 1.2542\n",
      "Epoch [7/50], Step [391/735], Loss: 0.9461\n",
      "Epoch [7/50], Step [392/735], Loss: 0.2877\n",
      "Epoch [7/50], Step [393/735], Loss: 0.2512\n",
      "Epoch [7/50], Step [394/735], Loss: 0.5478\n",
      "Epoch [7/50], Step [395/735], Loss: 0.4082\n",
      "Epoch [7/50], Step [396/735], Loss: 0.5698\n",
      "Epoch [7/50], Step [397/735], Loss: 0.1357\n",
      "Epoch [7/50], Step [398/735], Loss: 0.4036\n",
      "Epoch [7/50], Step [399/735], Loss: 0.1380\n",
      "Epoch [7/50], Step [400/735], Loss: 0.2461\n",
      "Epoch [7/50], Step [401/735], Loss: 0.2804\n",
      "Epoch [7/50], Step [402/735], Loss: 0.3341\n",
      "Epoch [7/50], Step [403/735], Loss: 0.6228\n",
      "Epoch [7/50], Step [404/735], Loss: 0.3399\n",
      "Epoch [7/50], Step [405/735], Loss: 0.3988\n",
      "Epoch [7/50], Step [406/735], Loss: 0.3160\n",
      "Epoch [7/50], Step [407/735], Loss: 0.4029\n",
      "Epoch [7/50], Step [408/735], Loss: 2.3775\n",
      "Epoch [7/50], Step [409/735], Loss: 0.7567\n",
      "Epoch [7/50], Step [410/735], Loss: 0.8152\n",
      "Epoch [7/50], Step [411/735], Loss: 0.9036\n",
      "Epoch [7/50], Step [412/735], Loss: 0.3905\n",
      "Epoch [7/50], Step [413/735], Loss: 0.8309\n",
      "Epoch [7/50], Step [414/735], Loss: 0.4555\n",
      "Epoch [7/50], Step [415/735], Loss: 0.4460\n",
      "Epoch [7/50], Step [416/735], Loss: 0.4411\n",
      "Epoch [7/50], Step [417/735], Loss: 0.4344\n",
      "Epoch [7/50], Step [418/735], Loss: 0.1296\n",
      "Epoch [7/50], Step [419/735], Loss: 0.4269\n",
      "Epoch [7/50], Step [420/735], Loss: 0.4379\n",
      "Epoch [7/50], Step [421/735], Loss: 0.9359\n",
      "Epoch [7/50], Step [422/735], Loss: 0.1059\n",
      "Epoch [7/50], Step [423/735], Loss: 0.4026\n",
      "Epoch [7/50], Step [424/735], Loss: 0.3037\n",
      "Epoch [7/50], Step [425/735], Loss: 0.0970\n",
      "Epoch [7/50], Step [426/735], Loss: 0.3100\n",
      "Epoch [7/50], Step [427/735], Loss: 0.1455\n",
      "Epoch [7/50], Step [428/735], Loss: 0.4310\n",
      "Epoch [7/50], Step [429/735], Loss: 0.3289\n",
      "Epoch [7/50], Step [430/735], Loss: 0.5324\n",
      "Epoch [7/50], Step [431/735], Loss: 0.3885\n",
      "Epoch [7/50], Step [432/735], Loss: 0.1238\n",
      "Epoch [7/50], Step [433/735], Loss: 0.2944\n",
      "Epoch [7/50], Step [434/735], Loss: 0.1443\n",
      "Epoch [7/50], Step [435/735], Loss: 0.3210\n",
      "Epoch [7/50], Step [436/735], Loss: 0.3689\n",
      "Epoch [7/50], Step [437/735], Loss: 0.5219\n",
      "Epoch [7/50], Step [438/735], Loss: 0.4145\n",
      "Epoch [7/50], Step [439/735], Loss: 0.3350\n",
      "Epoch [7/50], Step [440/735], Loss: 0.4159\n",
      "Epoch [7/50], Step [441/735], Loss: 0.2324\n",
      "Epoch [7/50], Step [442/735], Loss: 0.2761\n",
      "Epoch [7/50], Step [443/735], Loss: 5.0121\n",
      "Epoch [7/50], Step [444/735], Loss: 0.1645\n",
      "Epoch [7/50], Step [445/735], Loss: 0.7856\n",
      "Epoch [7/50], Step [446/735], Loss: 0.2603\n",
      "Epoch [7/50], Step [447/735], Loss: 0.1429\n",
      "Epoch [7/50], Step [448/735], Loss: 0.5531\n",
      "Epoch [7/50], Step [449/735], Loss: 0.3217\n",
      "Epoch [7/50], Step [450/735], Loss: 0.3770\n",
      "Epoch [7/50], Step [451/735], Loss: 1.0040\n",
      "Epoch [7/50], Step [452/735], Loss: 0.2051\n",
      "Epoch [7/50], Step [453/735], Loss: 0.5735\n",
      "Epoch [7/50], Step [454/735], Loss: 0.3845\n",
      "Epoch [7/50], Step [455/735], Loss: 0.4141\n",
      "Epoch [7/50], Step [456/735], Loss: 0.1141\n",
      "Epoch [7/50], Step [457/735], Loss: 0.1676\n",
      "Epoch [7/50], Step [458/735], Loss: 0.3132\n",
      "Epoch [7/50], Step [459/735], Loss: 0.3579\n",
      "Epoch [7/50], Step [460/735], Loss: 0.3435\n",
      "Epoch [7/50], Step [461/735], Loss: 0.6408\n",
      "Epoch [7/50], Step [462/735], Loss: 0.2219\n",
      "Epoch [7/50], Step [463/735], Loss: 0.1202\n",
      "Epoch [7/50], Step [464/735], Loss: 0.6157\n",
      "Epoch [7/50], Step [465/735], Loss: 0.5504\n",
      "Epoch [7/50], Step [466/735], Loss: 0.5510\n",
      "Epoch [7/50], Step [467/735], Loss: 2.7371\n",
      "Epoch [7/50], Step [468/735], Loss: 0.1222\n",
      "Epoch [7/50], Step [469/735], Loss: 0.3282\n",
      "Epoch [7/50], Step [470/735], Loss: 0.5534\n",
      "Epoch [7/50], Step [471/735], Loss: 0.9001\n",
      "Epoch [7/50], Step [472/735], Loss: 2.7528\n",
      "Epoch [7/50], Step [473/735], Loss: 0.2767\n",
      "Epoch [7/50], Step [474/735], Loss: 0.3901\n",
      "Epoch [7/50], Step [475/735], Loss: 0.2678\n",
      "Epoch [7/50], Step [476/735], Loss: 0.6633\n",
      "Epoch [7/50], Step [477/735], Loss: 0.2218\n",
      "Epoch [7/50], Step [478/735], Loss: 0.5289\n",
      "Epoch [7/50], Step [479/735], Loss: 0.7610\n",
      "Epoch [7/50], Step [480/735], Loss: 0.6833\n",
      "Epoch [7/50], Step [481/735], Loss: 0.5447\n",
      "Epoch [7/50], Step [482/735], Loss: 0.3329\n",
      "Epoch [7/50], Step [483/735], Loss: 0.1569\n",
      "Epoch [7/50], Step [484/735], Loss: 0.5199\n",
      "Epoch [7/50], Step [485/735], Loss: 0.2204\n",
      "Epoch [7/50], Step [486/735], Loss: 1.5392\n",
      "Epoch [7/50], Step [487/735], Loss: 0.5342\n",
      "Epoch [7/50], Step [488/735], Loss: 2.8455\n",
      "Epoch [7/50], Step [489/735], Loss: 0.1784\n",
      "Epoch [7/50], Step [490/735], Loss: 0.9586\n",
      "Epoch [7/50], Step [491/735], Loss: 0.3700\n",
      "Epoch [7/50], Step [492/735], Loss: 0.3266\n",
      "Epoch [7/50], Step [493/735], Loss: 0.3002\n",
      "Epoch [7/50], Step [494/735], Loss: 0.2441\n",
      "Epoch [7/50], Step [495/735], Loss: 0.8582\n",
      "Epoch [7/50], Step [496/735], Loss: 0.8017\n",
      "Epoch [7/50], Step [497/735], Loss: 0.4140\n",
      "Epoch [7/50], Step [498/735], Loss: 0.4366\n",
      "Epoch [7/50], Step [499/735], Loss: 4.6490\n",
      "Epoch [7/50], Step [500/735], Loss: 0.1882\n",
      "Epoch [7/50], Step [501/735], Loss: 0.3344\n",
      "Epoch [7/50], Step [502/735], Loss: 0.9866\n",
      "Epoch [7/50], Step [503/735], Loss: 0.6554\n",
      "Epoch [7/50], Step [504/735], Loss: 0.8465\n",
      "Epoch [7/50], Step [505/735], Loss: 0.1830\n",
      "Epoch [7/50], Step [506/735], Loss: 0.2286\n",
      "Epoch [7/50], Step [507/735], Loss: 0.2716\n",
      "Epoch [7/50], Step [508/735], Loss: 0.1256\n",
      "Epoch [7/50], Step [509/735], Loss: 0.4213\n",
      "Epoch [7/50], Step [510/735], Loss: 1.9114\n",
      "Epoch [7/50], Step [511/735], Loss: 0.7364\n",
      "Epoch [7/50], Step [512/735], Loss: 0.1988\n",
      "Epoch [7/50], Step [513/735], Loss: 0.3397\n",
      "Epoch [7/50], Step [514/735], Loss: 0.6231\n",
      "Epoch [7/50], Step [515/735], Loss: 0.7005\n",
      "Epoch [7/50], Step [516/735], Loss: 0.3929\n",
      "Epoch [7/50], Step [517/735], Loss: 0.5070\n",
      "Epoch [7/50], Step [518/735], Loss: 0.7207\n",
      "Epoch [7/50], Step [519/735], Loss: 0.3830\n",
      "Epoch [7/50], Step [520/735], Loss: 0.6435\n",
      "Epoch [7/50], Step [521/735], Loss: 0.5849\n",
      "Epoch [7/50], Step [522/735], Loss: 0.3774\n",
      "Epoch [7/50], Step [523/735], Loss: 0.2479\n",
      "Epoch [7/50], Step [524/735], Loss: 0.5372\n",
      "Epoch [7/50], Step [525/735], Loss: 0.6778\n",
      "Epoch [7/50], Step [526/735], Loss: 0.1583\n",
      "Epoch [7/50], Step [527/735], Loss: 0.3042\n",
      "Epoch [7/50], Step [528/735], Loss: 0.6241\n",
      "Epoch [7/50], Step [529/735], Loss: 0.5084\n",
      "Epoch [7/50], Step [530/735], Loss: 0.2472\n",
      "Epoch [7/50], Step [531/735], Loss: 0.2962\n",
      "Epoch [7/50], Step [532/735], Loss: 0.2402\n",
      "Epoch [7/50], Step [533/735], Loss: 0.6782\n",
      "Epoch [7/50], Step [534/735], Loss: 0.1905\n",
      "Epoch [7/50], Step [535/735], Loss: 0.3495\n",
      "Epoch [7/50], Step [536/735], Loss: 0.3401\n",
      "Epoch [7/50], Step [537/735], Loss: 0.6821\n",
      "Epoch [7/50], Step [538/735], Loss: 0.8536\n",
      "Epoch [7/50], Step [539/735], Loss: 0.2329\n",
      "Epoch [7/50], Step [540/735], Loss: 0.7845\n",
      "Epoch [7/50], Step [541/735], Loss: 0.3415\n",
      "Epoch [7/50], Step [542/735], Loss: 0.6985\n",
      "Epoch [7/50], Step [543/735], Loss: 0.4184\n",
      "Epoch [7/50], Step [544/735], Loss: 0.4353\n",
      "Epoch [7/50], Step [545/735], Loss: 0.9209\n",
      "Epoch [7/50], Step [546/735], Loss: 0.6354\n",
      "Epoch [7/50], Step [547/735], Loss: 0.3265\n",
      "Epoch [7/50], Step [548/735], Loss: 0.3820\n",
      "Epoch [7/50], Step [549/735], Loss: 0.2204\n",
      "Epoch [7/50], Step [550/735], Loss: 0.6381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Step [551/735], Loss: 0.4782\n",
      "Epoch [7/50], Step [552/735], Loss: 0.8920\n",
      "Epoch [7/50], Step [553/735], Loss: 0.1236\n",
      "Epoch [7/50], Step [554/735], Loss: 1.3978\n",
      "Epoch [7/50], Step [555/735], Loss: 0.2988\n",
      "Epoch [7/50], Step [556/735], Loss: 0.3005\n",
      "Epoch [7/50], Step [557/735], Loss: 0.4284\n",
      "Epoch [7/50], Step [558/735], Loss: 1.2850\n",
      "Epoch [7/50], Step [559/735], Loss: 0.5828\n",
      "Epoch [7/50], Step [560/735], Loss: 0.1210\n",
      "Epoch [7/50], Step [561/735], Loss: 0.3454\n",
      "Epoch [7/50], Step [562/735], Loss: 1.1369\n",
      "Epoch [7/50], Step [563/735], Loss: 1.7318\n",
      "Epoch [7/50], Step [564/735], Loss: 0.2905\n",
      "Epoch [7/50], Step [565/735], Loss: 0.4987\n",
      "Epoch [7/50], Step [566/735], Loss: 0.1686\n",
      "Epoch [7/50], Step [567/735], Loss: 0.3950\n",
      "Epoch [7/50], Step [568/735], Loss: 0.0773\n",
      "Epoch [7/50], Step [569/735], Loss: 0.4332\n",
      "Epoch [7/50], Step [570/735], Loss: 0.6578\n",
      "Epoch [7/50], Step [571/735], Loss: 0.1746\n",
      "Epoch [7/50], Step [572/735], Loss: 1.5501\n",
      "Epoch [7/50], Step [573/735], Loss: 0.7340\n",
      "Epoch [7/50], Step [574/735], Loss: 0.1514\n",
      "Epoch [7/50], Step [575/735], Loss: 0.3807\n",
      "Epoch [7/50], Step [576/735], Loss: 0.1157\n",
      "Epoch [7/50], Step [577/735], Loss: 0.4929\n",
      "Epoch [7/50], Step [578/735], Loss: 0.3511\n",
      "Epoch [7/50], Step [579/735], Loss: 0.1901\n",
      "Epoch [7/50], Step [580/735], Loss: 0.2140\n",
      "Epoch [7/50], Step [581/735], Loss: 0.2817\n",
      "Epoch [7/50], Step [582/735], Loss: 0.5249\n",
      "Epoch [7/50], Step [583/735], Loss: 0.2726\n",
      "Epoch [7/50], Step [584/735], Loss: 4.6834\n",
      "Epoch [7/50], Step [585/735], Loss: 0.2661\n",
      "Epoch [7/50], Step [586/735], Loss: 0.8441\n",
      "Epoch [7/50], Step [587/735], Loss: 0.1256\n",
      "Epoch [7/50], Step [588/735], Loss: 0.3237\n",
      "Epoch [7/50], Step [589/735], Loss: 0.8546\n",
      "Epoch [7/50], Step [590/735], Loss: 0.6371\n",
      "Epoch [7/50], Step [591/735], Loss: 0.3123\n",
      "Epoch [7/50], Step [592/735], Loss: 0.4902\n",
      "Epoch [7/50], Step [593/735], Loss: 0.1716\n",
      "Epoch [7/50], Step [594/735], Loss: 0.5620\n",
      "Epoch [7/50], Step [595/735], Loss: 0.2234\n",
      "Epoch [7/50], Step [596/735], Loss: 0.2956\n",
      "Epoch [7/50], Step [597/735], Loss: 0.9624\n",
      "Epoch [7/50], Step [598/735], Loss: 0.1676\n",
      "Epoch [7/50], Step [599/735], Loss: 0.2342\n",
      "Epoch [7/50], Step [600/735], Loss: 0.5819\n",
      "Epoch [7/50], Step [601/735], Loss: 0.1847\n",
      "Epoch [7/50], Step [602/735], Loss: 0.8735\n",
      "Epoch [7/50], Step [603/735], Loss: 0.4218\n",
      "Epoch [7/50], Step [604/735], Loss: 1.0948\n",
      "Epoch [7/50], Step [605/735], Loss: 0.3169\n",
      "Epoch [7/50], Step [606/735], Loss: 0.3074\n",
      "Epoch [7/50], Step [607/735], Loss: 0.5648\n",
      "Epoch [7/50], Step [608/735], Loss: 0.1970\n",
      "Epoch [7/50], Step [609/735], Loss: 0.2210\n",
      "Epoch [7/50], Step [610/735], Loss: 1.5063\n",
      "Epoch [7/50], Step [611/735], Loss: 0.3644\n",
      "Epoch [7/50], Step [612/735], Loss: 1.2045\n",
      "Epoch [7/50], Step [613/735], Loss: 0.3570\n",
      "Epoch [7/50], Step [614/735], Loss: 0.3421\n",
      "Epoch [7/50], Step [615/735], Loss: 0.3375\n",
      "Epoch [7/50], Step [616/735], Loss: 0.2716\n",
      "Epoch [7/50], Step [617/735], Loss: 0.5261\n",
      "Epoch [7/50], Step [618/735], Loss: 0.1602\n",
      "Epoch [7/50], Step [619/735], Loss: 0.3648\n",
      "Epoch [7/50], Step [620/735], Loss: 0.4658\n",
      "Epoch [7/50], Step [621/735], Loss: 1.2194\n",
      "Epoch [7/50], Step [622/735], Loss: 0.2719\n",
      "Epoch [7/50], Step [623/735], Loss: 0.3857\n",
      "Epoch [7/50], Step [624/735], Loss: 0.2320\n",
      "Epoch [7/50], Step [625/735], Loss: 0.1448\n",
      "Epoch [7/50], Step [626/735], Loss: 0.2314\n",
      "Epoch [7/50], Step [627/735], Loss: 0.6029\n",
      "Epoch [7/50], Step [628/735], Loss: 0.3675\n",
      "Epoch [7/50], Step [629/735], Loss: 0.6062\n",
      "Epoch [7/50], Step [630/735], Loss: 1.0905\n",
      "Epoch [7/50], Step [631/735], Loss: 0.3652\n",
      "Epoch [7/50], Step [632/735], Loss: 0.6121\n",
      "Epoch [7/50], Step [633/735], Loss: 0.1828\n",
      "Epoch [7/50], Step [634/735], Loss: 0.6229\n",
      "Epoch [7/50], Step [635/735], Loss: 0.1102\n",
      "Epoch [7/50], Step [636/735], Loss: 0.2527\n",
      "Epoch [7/50], Step [637/735], Loss: 0.6623\n",
      "Epoch [7/50], Step [638/735], Loss: 0.4447\n",
      "Epoch [7/50], Step [639/735], Loss: 0.4313\n",
      "Epoch [7/50], Step [640/735], Loss: 0.2226\n",
      "Epoch [7/50], Step [641/735], Loss: 0.2763\n",
      "Epoch [7/50], Step [642/735], Loss: 0.6096\n",
      "Epoch [7/50], Step [643/735], Loss: 0.6397\n",
      "Epoch [7/50], Step [644/735], Loss: 0.3385\n",
      "Epoch [7/50], Step [645/735], Loss: 1.3131\n",
      "Epoch [7/50], Step [646/735], Loss: 0.1645\n",
      "Epoch [7/50], Step [647/735], Loss: 0.5068\n",
      "Epoch [7/50], Step [648/735], Loss: 0.5016\n",
      "Epoch [7/50], Step [649/735], Loss: 0.1390\n",
      "Epoch [7/50], Step [650/735], Loss: 0.1557\n",
      "Epoch [7/50], Step [651/735], Loss: 0.2825\n",
      "Epoch [7/50], Step [652/735], Loss: 0.2462\n",
      "Epoch [7/50], Step [653/735], Loss: 0.1631\n",
      "Epoch [7/50], Step [654/735], Loss: 0.3075\n",
      "Epoch [7/50], Step [655/735], Loss: 0.5287\n",
      "Epoch [7/50], Step [656/735], Loss: 0.3794\n",
      "Epoch [7/50], Step [657/735], Loss: 0.3760\n",
      "Epoch [7/50], Step [658/735], Loss: 0.2828\n",
      "Epoch [7/50], Step [659/735], Loss: 0.4003\n",
      "Epoch [7/50], Step [660/735], Loss: 0.2684\n",
      "Epoch [7/50], Step [661/735], Loss: 0.1703\n",
      "Epoch [7/50], Step [662/735], Loss: 0.3026\n",
      "Epoch [7/50], Step [663/735], Loss: 0.5117\n",
      "Epoch [7/50], Step [664/735], Loss: 0.3411\n",
      "Epoch [7/50], Step [665/735], Loss: 0.4734\n",
      "Epoch [7/50], Step [666/735], Loss: 0.6475\n",
      "Epoch [7/50], Step [667/735], Loss: 0.9889\n",
      "Epoch [7/50], Step [668/735], Loss: 0.5212\n",
      "Epoch [7/50], Step [669/735], Loss: 0.3581\n",
      "Epoch [7/50], Step [670/735], Loss: 0.1623\n",
      "Epoch [7/50], Step [671/735], Loss: 0.7632\n",
      "Epoch [7/50], Step [672/735], Loss: 0.2320\n",
      "Epoch [7/50], Step [673/735], Loss: 0.2441\n",
      "Epoch [7/50], Step [674/735], Loss: 0.1887\n",
      "Epoch [7/50], Step [675/735], Loss: 1.1367\n",
      "Epoch [7/50], Step [676/735], Loss: 0.3543\n",
      "Epoch [7/50], Step [677/735], Loss: 0.1252\n",
      "Epoch [7/50], Step [678/735], Loss: 0.1016\n",
      "Epoch [7/50], Step [679/735], Loss: 0.4101\n",
      "Epoch [7/50], Step [680/735], Loss: 0.5576\n",
      "Epoch [7/50], Step [681/735], Loss: 0.4253\n",
      "Epoch [7/50], Step [682/735], Loss: 0.3706\n",
      "Epoch [7/50], Step [683/735], Loss: 0.2623\n",
      "Epoch [7/50], Step [684/735], Loss: 2.3326\n",
      "Epoch [7/50], Step [685/735], Loss: 0.5155\n",
      "Epoch [7/50], Step [686/735], Loss: 0.2660\n",
      "Epoch [7/50], Step [687/735], Loss: 0.3401\n",
      "Epoch [7/50], Step [688/735], Loss: 0.2707\n",
      "Epoch [7/50], Step [689/735], Loss: 1.1899\n",
      "Epoch [7/50], Step [690/735], Loss: 0.3442\n",
      "Epoch [7/50], Step [691/735], Loss: 0.4339\n",
      "Epoch [7/50], Step [692/735], Loss: 0.4683\n",
      "Epoch [7/50], Step [693/735], Loss: 0.3803\n",
      "Epoch [7/50], Step [694/735], Loss: 0.5074\n",
      "Epoch [7/50], Step [695/735], Loss: 0.3721\n",
      "Epoch [7/50], Step [696/735], Loss: 0.2931\n",
      "Epoch [7/50], Step [697/735], Loss: 0.1872\n",
      "Epoch [7/50], Step [698/735], Loss: 0.7455\n",
      "Epoch [7/50], Step [699/735], Loss: 0.4881\n",
      "Epoch [7/50], Step [700/735], Loss: 0.4546\n",
      "Epoch [7/50], Step [701/735], Loss: 0.1487\n",
      "Epoch [7/50], Step [702/735], Loss: 0.6436\n",
      "Epoch [7/50], Step [703/735], Loss: 0.8762\n",
      "Epoch [7/50], Step [704/735], Loss: 0.3666\n",
      "Epoch [7/50], Step [705/735], Loss: 0.4613\n",
      "Epoch [7/50], Step [706/735], Loss: 0.4243\n",
      "Epoch [7/50], Step [707/735], Loss: 0.2552\n",
      "Epoch [7/50], Step [708/735], Loss: 0.4859\n",
      "Epoch [7/50], Step [709/735], Loss: 0.3733\n",
      "Epoch [7/50], Step [710/735], Loss: 0.2729\n",
      "Epoch [7/50], Step [711/735], Loss: 0.3405\n",
      "Epoch [7/50], Step [712/735], Loss: 1.6086\n",
      "Epoch [7/50], Step [713/735], Loss: 0.0819\n",
      "Epoch [7/50], Step [714/735], Loss: 0.4890\n",
      "Epoch [7/50], Step [715/735], Loss: 0.3624\n",
      "Epoch [7/50], Step [716/735], Loss: 1.2181\n",
      "Epoch [7/50], Step [717/735], Loss: 0.2298\n",
      "Epoch [7/50], Step [718/735], Loss: 0.8776\n",
      "Epoch [7/50], Step [719/735], Loss: 0.3546\n",
      "Epoch [7/50], Step [720/735], Loss: 0.4620\n",
      "Epoch [7/50], Step [721/735], Loss: 0.6994\n",
      "Epoch [7/50], Step [722/735], Loss: 0.6214\n",
      "Epoch [7/50], Step [723/735], Loss: 1.2677\n",
      "Epoch [7/50], Step [724/735], Loss: 0.3267\n",
      "Epoch [7/50], Step [725/735], Loss: 0.8882\n",
      "Epoch [7/50], Step [726/735], Loss: 0.2304\n",
      "Epoch [7/50], Step [727/735], Loss: 1.0260\n",
      "Epoch [7/50], Step [728/735], Loss: 0.1373\n",
      "Epoch [7/50], Step [729/735], Loss: 0.8343\n",
      "Epoch [7/50], Step [730/735], Loss: 0.0584\n",
      "Epoch [7/50], Step [731/735], Loss: 0.7569\n",
      "Epoch [7/50], Step [732/735], Loss: 0.1503\n",
      "Epoch [7/50], Step [733/735], Loss: 0.1606\n",
      "Epoch [7/50], Step [734/735], Loss: 0.4462\n",
      "Epoch [7/50], Step [735/735], Loss: 0.0968\n",
      "Epoch [8/50], Step [1/735], Loss: 0.3053\n",
      "Epoch [8/50], Step [2/735], Loss: 0.3363\n",
      "Epoch [8/50], Step [3/735], Loss: 0.1557\n",
      "Epoch [8/50], Step [4/735], Loss: 0.4122\n",
      "Epoch [8/50], Step [5/735], Loss: 0.3942\n",
      "Epoch [8/50], Step [6/735], Loss: 0.0888\n",
      "Epoch [8/50], Step [7/735], Loss: 0.1963\n",
      "Epoch [8/50], Step [8/735], Loss: 0.3584\n",
      "Epoch [8/50], Step [9/735], Loss: 0.2443\n",
      "Epoch [8/50], Step [10/735], Loss: 0.1408\n",
      "Epoch [8/50], Step [11/735], Loss: 0.2902\n",
      "Epoch [8/50], Step [12/735], Loss: 0.3689\n",
      "Epoch [8/50], Step [13/735], Loss: 0.1712\n",
      "Epoch [8/50], Step [14/735], Loss: 0.5928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Step [15/735], Loss: 0.2657\n",
      "Epoch [8/50], Step [16/735], Loss: 0.4347\n",
      "Epoch [8/50], Step [17/735], Loss: 0.2813\n",
      "Epoch [8/50], Step [18/735], Loss: 0.1760\n",
      "Epoch [8/50], Step [19/735], Loss: 0.3240\n",
      "Epoch [8/50], Step [20/735], Loss: 0.2918\n",
      "Epoch [8/50], Step [21/735], Loss: 0.1657\n",
      "Epoch [8/50], Step [22/735], Loss: 1.8308\n",
      "Epoch [8/50], Step [23/735], Loss: 0.1785\n",
      "Epoch [8/50], Step [24/735], Loss: 0.3367\n",
      "Epoch [8/50], Step [25/735], Loss: 0.1626\n",
      "Epoch [8/50], Step [26/735], Loss: 0.5649\n",
      "Epoch [8/50], Step [27/735], Loss: 0.1951\n",
      "Epoch [8/50], Step [28/735], Loss: 0.2576\n",
      "Epoch [8/50], Step [29/735], Loss: 0.6185\n",
      "Epoch [8/50], Step [30/735], Loss: 0.2902\n",
      "Epoch [8/50], Step [31/735], Loss: 1.7375\n",
      "Epoch [8/50], Step [32/735], Loss: 1.5428\n",
      "Epoch [8/50], Step [33/735], Loss: 0.3895\n",
      "Epoch [8/50], Step [34/735], Loss: 0.3432\n",
      "Epoch [8/50], Step [35/735], Loss: 0.2992\n",
      "Epoch [8/50], Step [36/735], Loss: 0.5128\n",
      "Epoch [8/50], Step [37/735], Loss: 0.7787\n",
      "Epoch [8/50], Step [38/735], Loss: 0.1627\n",
      "Epoch [8/50], Step [39/735], Loss: 0.3768\n",
      "Epoch [8/50], Step [40/735], Loss: 0.3983\n",
      "Epoch [8/50], Step [41/735], Loss: 0.4206\n",
      "Epoch [8/50], Step [42/735], Loss: 0.7525\n",
      "Epoch [8/50], Step [43/735], Loss: 0.2152\n",
      "Epoch [8/50], Step [44/735], Loss: 0.4672\n",
      "Epoch [8/50], Step [45/735], Loss: 1.0698\n",
      "Epoch [8/50], Step [46/735], Loss: 0.2979\n",
      "Epoch [8/50], Step [47/735], Loss: 0.1726\n",
      "Epoch [8/50], Step [48/735], Loss: 1.1469\n",
      "Epoch [8/50], Step [49/735], Loss: 0.3683\n",
      "Epoch [8/50], Step [50/735], Loss: 0.5939\n",
      "Epoch [8/50], Step [51/735], Loss: 1.1319\n",
      "Epoch [8/50], Step [52/735], Loss: 0.2330\n",
      "Epoch [8/50], Step [53/735], Loss: 0.4359\n",
      "Epoch [8/50], Step [54/735], Loss: 0.2624\n",
      "Epoch [8/50], Step [55/735], Loss: 0.5800\n",
      "Epoch [8/50], Step [56/735], Loss: 0.3674\n",
      "Epoch [8/50], Step [57/735], Loss: 0.3922\n",
      "Epoch [8/50], Step [58/735], Loss: 0.1566\n",
      "Epoch [8/50], Step [59/735], Loss: 0.1297\n",
      "Epoch [8/50], Step [60/735], Loss: 0.2378\n",
      "Epoch [8/50], Step [61/735], Loss: 0.1807\n",
      "Epoch [8/50], Step [62/735], Loss: 0.4584\n",
      "Epoch [8/50], Step [63/735], Loss: 0.8619\n",
      "Epoch [8/50], Step [64/735], Loss: 0.5617\n",
      "Epoch [8/50], Step [65/735], Loss: 0.9822\n",
      "Epoch [8/50], Step [66/735], Loss: 1.0177\n",
      "Epoch [8/50], Step [67/735], Loss: 0.3621\n",
      "Epoch [8/50], Step [68/735], Loss: 0.5622\n",
      "Epoch [8/50], Step [69/735], Loss: 0.8459\n",
      "Epoch [8/50], Step [70/735], Loss: 0.7079\n",
      "Epoch [8/50], Step [71/735], Loss: 0.9445\n",
      "Epoch [8/50], Step [72/735], Loss: 0.9752\n",
      "Epoch [8/50], Step [73/735], Loss: 0.1884\n",
      "Epoch [8/50], Step [74/735], Loss: 0.3112\n",
      "Epoch [8/50], Step [75/735], Loss: 0.9519\n",
      "Epoch [8/50], Step [76/735], Loss: 0.2457\n",
      "Epoch [8/50], Step [77/735], Loss: 0.6530\n",
      "Epoch [8/50], Step [78/735], Loss: 0.2415\n",
      "Epoch [8/50], Step [79/735], Loss: 0.1727\n",
      "Epoch [8/50], Step [80/735], Loss: 0.1500\n",
      "Epoch [8/50], Step [81/735], Loss: 0.4081\n",
      "Epoch [8/50], Step [82/735], Loss: 0.9447\n",
      "Epoch [8/50], Step [83/735], Loss: 0.2046\n",
      "Epoch [8/50], Step [84/735], Loss: 0.2878\n",
      "Epoch [8/50], Step [85/735], Loss: 0.6649\n",
      "Epoch [8/50], Step [86/735], Loss: 0.2529\n",
      "Epoch [8/50], Step [87/735], Loss: 0.1405\n",
      "Epoch [8/50], Step [88/735], Loss: 0.2633\n",
      "Epoch [8/50], Step [89/735], Loss: 0.2918\n",
      "Epoch [8/50], Step [90/735], Loss: 0.7153\n",
      "Epoch [8/50], Step [91/735], Loss: 0.4228\n",
      "Epoch [8/50], Step [92/735], Loss: 0.4000\n",
      "Epoch [8/50], Step [93/735], Loss: 0.2154\n",
      "Epoch [8/50], Step [94/735], Loss: 0.1928\n",
      "Epoch [8/50], Step [95/735], Loss: 0.1203\n",
      "Epoch [8/50], Step [96/735], Loss: 0.3820\n",
      "Epoch [8/50], Step [97/735], Loss: 0.3379\n",
      "Epoch [8/50], Step [98/735], Loss: 0.4520\n",
      "Epoch [8/50], Step [99/735], Loss: 1.0356\n",
      "Epoch [8/50], Step [100/735], Loss: 0.2666\n",
      "Epoch [8/50], Step [101/735], Loss: 0.5825\n",
      "Epoch [8/50], Step [102/735], Loss: 0.9986\n",
      "Epoch [8/50], Step [103/735], Loss: 1.2893\n",
      "Epoch [8/50], Step [104/735], Loss: 0.7956\n",
      "Epoch [8/50], Step [105/735], Loss: 0.3558\n",
      "Epoch [8/50], Step [106/735], Loss: 0.3892\n",
      "Epoch [8/50], Step [107/735], Loss: 0.2002\n",
      "Epoch [8/50], Step [108/735], Loss: 0.1857\n",
      "Epoch [8/50], Step [109/735], Loss: 0.7141\n",
      "Epoch [8/50], Step [110/735], Loss: 1.0010\n",
      "Epoch [8/50], Step [111/735], Loss: 0.1237\n",
      "Epoch [8/50], Step [112/735], Loss: 0.1821\n",
      "Epoch [8/50], Step [113/735], Loss: 0.4779\n",
      "Epoch [8/50], Step [114/735], Loss: 0.2248\n",
      "Epoch [8/50], Step [115/735], Loss: 0.2473\n",
      "Epoch [8/50], Step [116/735], Loss: 0.2821\n",
      "Epoch [8/50], Step [117/735], Loss: 1.0186\n",
      "Epoch [8/50], Step [118/735], Loss: 1.7181\n",
      "Epoch [8/50], Step [119/735], Loss: 0.9960\n",
      "Epoch [8/50], Step [120/735], Loss: 0.4467\n",
      "Epoch [8/50], Step [121/735], Loss: 0.0918\n",
      "Epoch [8/50], Step [122/735], Loss: 0.2698\n",
      "Epoch [8/50], Step [123/735], Loss: 0.2415\n",
      "Epoch [8/50], Step [124/735], Loss: 0.4467\n",
      "Epoch [8/50], Step [125/735], Loss: 0.4308\n",
      "Epoch [8/50], Step [126/735], Loss: 2.4404\n",
      "Epoch [8/50], Step [127/735], Loss: 0.4965\n",
      "Epoch [8/50], Step [128/735], Loss: 0.1362\n",
      "Epoch [8/50], Step [129/735], Loss: 0.5661\n",
      "Epoch [8/50], Step [130/735], Loss: 0.7265\n",
      "Epoch [8/50], Step [131/735], Loss: 0.1463\n",
      "Epoch [8/50], Step [132/735], Loss: 0.4277\n",
      "Epoch [8/50], Step [133/735], Loss: 0.1962\n",
      "Epoch [8/50], Step [134/735], Loss: 0.2976\n",
      "Epoch [8/50], Step [135/735], Loss: 0.6823\n",
      "Epoch [8/50], Step [136/735], Loss: 0.2250\n",
      "Epoch [8/50], Step [137/735], Loss: 0.2352\n",
      "Epoch [8/50], Step [138/735], Loss: 0.7248\n",
      "Epoch [8/50], Step [139/735], Loss: 1.7753\n",
      "Epoch [8/50], Step [140/735], Loss: 0.2124\n",
      "Epoch [8/50], Step [141/735], Loss: 0.3458\n",
      "Epoch [8/50], Step [142/735], Loss: 0.3128\n",
      "Epoch [8/50], Step [143/735], Loss: 1.3159\n",
      "Epoch [8/50], Step [144/735], Loss: 0.2925\n",
      "Epoch [8/50], Step [145/735], Loss: 0.1089\n",
      "Epoch [8/50], Step [146/735], Loss: 0.2815\n",
      "Epoch [8/50], Step [147/735], Loss: 0.5741\n",
      "Epoch [8/50], Step [148/735], Loss: 0.8368\n",
      "Epoch [8/50], Step [149/735], Loss: 1.2831\n",
      "Epoch [8/50], Step [150/735], Loss: 0.3666\n",
      "Epoch [8/50], Step [151/735], Loss: 0.2516\n",
      "Epoch [8/50], Step [152/735], Loss: 0.9109\n",
      "Epoch [8/50], Step [153/735], Loss: 0.2309\n",
      "Epoch [8/50], Step [154/735], Loss: 0.5649\n",
      "Epoch [8/50], Step [155/735], Loss: 0.3680\n",
      "Epoch [8/50], Step [156/735], Loss: 0.3720\n",
      "Epoch [8/50], Step [157/735], Loss: 0.1563\n",
      "Epoch [8/50], Step [158/735], Loss: 0.3920\n",
      "Epoch [8/50], Step [159/735], Loss: 0.4110\n",
      "Epoch [8/50], Step [160/735], Loss: 0.2584\n",
      "Epoch [8/50], Step [161/735], Loss: 2.1600\n",
      "Epoch [8/50], Step [162/735], Loss: 6.3419\n",
      "Epoch [8/50], Step [163/735], Loss: 0.1265\n",
      "Epoch [8/50], Step [164/735], Loss: 1.1564\n",
      "Epoch [8/50], Step [165/735], Loss: 0.1290\n",
      "Epoch [8/50], Step [166/735], Loss: 0.3455\n",
      "Epoch [8/50], Step [167/735], Loss: 0.4175\n",
      "Epoch [8/50], Step [168/735], Loss: 0.2359\n",
      "Epoch [8/50], Step [169/735], Loss: 1.2273\n",
      "Epoch [8/50], Step [170/735], Loss: 0.8682\n",
      "Epoch [8/50], Step [171/735], Loss: 1.1862\n",
      "Epoch [8/50], Step [172/735], Loss: 0.3223\n",
      "Epoch [8/50], Step [173/735], Loss: 0.5110\n",
      "Epoch [8/50], Step [174/735], Loss: 0.4369\n",
      "Epoch [8/50], Step [175/735], Loss: 0.5912\n",
      "Epoch [8/50], Step [176/735], Loss: 0.9274\n",
      "Epoch [8/50], Step [177/735], Loss: 0.1766\n",
      "Epoch [8/50], Step [178/735], Loss: 0.4358\n",
      "Epoch [8/50], Step [179/735], Loss: 0.4370\n",
      "Epoch [8/50], Step [180/735], Loss: 0.2190\n",
      "Epoch [8/50], Step [181/735], Loss: 0.1517\n",
      "Epoch [8/50], Step [182/735], Loss: 0.2802\n",
      "Epoch [8/50], Step [183/735], Loss: 0.5711\n",
      "Epoch [8/50], Step [184/735], Loss: 0.7512\n",
      "Epoch [8/50], Step [185/735], Loss: 0.8160\n",
      "Epoch [8/50], Step [186/735], Loss: 0.4294\n",
      "Epoch [8/50], Step [187/735], Loss: 0.2054\n",
      "Epoch [8/50], Step [188/735], Loss: 1.2857\n",
      "Epoch [8/50], Step [189/735], Loss: 0.4146\n",
      "Epoch [8/50], Step [190/735], Loss: 0.2246\n",
      "Epoch [8/50], Step [191/735], Loss: 0.1354\n",
      "Epoch [8/50], Step [192/735], Loss: 0.5579\n",
      "Epoch [8/50], Step [193/735], Loss: 0.2362\n",
      "Epoch [8/50], Step [194/735], Loss: 0.1854\n",
      "Epoch [8/50], Step [195/735], Loss: 0.1823\n",
      "Epoch [8/50], Step [196/735], Loss: 0.4836\n",
      "Epoch [8/50], Step [197/735], Loss: 0.2196\n",
      "Epoch [8/50], Step [198/735], Loss: 0.3968\n",
      "Epoch [8/50], Step [199/735], Loss: 0.2689\n",
      "Epoch [8/50], Step [200/735], Loss: 0.5637\n",
      "Epoch [8/50], Step [201/735], Loss: 0.4948\n",
      "Epoch [8/50], Step [202/735], Loss: 0.0797\n",
      "Epoch [8/50], Step [203/735], Loss: 0.2306\n",
      "Epoch [8/50], Step [204/735], Loss: 0.1561\n",
      "Epoch [8/50], Step [205/735], Loss: 0.7165\n",
      "Epoch [8/50], Step [206/735], Loss: 0.2743\n",
      "Epoch [8/50], Step [207/735], Loss: 0.2837\n",
      "Epoch [8/50], Step [208/735], Loss: 0.4667\n",
      "Epoch [8/50], Step [209/735], Loss: 0.2557\n",
      "Epoch [8/50], Step [210/735], Loss: 0.1714\n",
      "Epoch [8/50], Step [211/735], Loss: 0.2610\n",
      "Epoch [8/50], Step [212/735], Loss: 0.1908\n",
      "Epoch [8/50], Step [213/735], Loss: 0.3972\n",
      "Epoch [8/50], Step [214/735], Loss: 0.3823\n",
      "Epoch [8/50], Step [215/735], Loss: 0.3097\n",
      "Epoch [8/50], Step [216/735], Loss: 0.0910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Step [217/735], Loss: 0.8395\n",
      "Epoch [8/50], Step [218/735], Loss: 0.4453\n",
      "Epoch [8/50], Step [219/735], Loss: 0.3390\n",
      "Epoch [8/50], Step [220/735], Loss: 0.1941\n",
      "Epoch [8/50], Step [221/735], Loss: 0.8129\n",
      "Epoch [8/50], Step [222/735], Loss: 0.5573\n",
      "Epoch [8/50], Step [223/735], Loss: 0.7427\n",
      "Epoch [8/50], Step [224/735], Loss: 0.4420\n",
      "Epoch [8/50], Step [225/735], Loss: 1.3334\n",
      "Epoch [8/50], Step [226/735], Loss: 0.3830\n",
      "Epoch [8/50], Step [227/735], Loss: 0.3616\n",
      "Epoch [8/50], Step [228/735], Loss: 0.7858\n",
      "Epoch [8/50], Step [229/735], Loss: 0.2536\n",
      "Epoch [8/50], Step [230/735], Loss: 0.3997\n",
      "Epoch [8/50], Step [231/735], Loss: 0.4669\n",
      "Epoch [8/50], Step [232/735], Loss: 0.9195\n",
      "Epoch [8/50], Step [233/735], Loss: 0.3066\n",
      "Epoch [8/50], Step [234/735], Loss: 0.8089\n",
      "Epoch [8/50], Step [235/735], Loss: 0.7349\n",
      "Epoch [8/50], Step [236/735], Loss: 1.2943\n",
      "Epoch [8/50], Step [237/735], Loss: 0.2157\n",
      "Epoch [8/50], Step [238/735], Loss: 0.3072\n",
      "Epoch [8/50], Step [239/735], Loss: 0.8755\n",
      "Epoch [8/50], Step [240/735], Loss: 0.1678\n",
      "Epoch [8/50], Step [241/735], Loss: 0.3576\n",
      "Epoch [8/50], Step [242/735], Loss: 0.1261\n",
      "Epoch [8/50], Step [243/735], Loss: 0.5028\n",
      "Epoch [8/50], Step [244/735], Loss: 0.2886\n",
      "Epoch [8/50], Step [245/735], Loss: 0.1943\n",
      "Epoch [8/50], Step [246/735], Loss: 0.1624\n",
      "Epoch [8/50], Step [247/735], Loss: 0.9099\n",
      "Epoch [8/50], Step [248/735], Loss: 0.3687\n",
      "Epoch [8/50], Step [249/735], Loss: 0.1316\n",
      "Epoch [8/50], Step [250/735], Loss: 0.1385\n",
      "Epoch [8/50], Step [251/735], Loss: 0.5774\n",
      "Epoch [8/50], Step [252/735], Loss: 0.3480\n",
      "Epoch [8/50], Step [253/735], Loss: 1.0243\n",
      "Epoch [8/50], Step [254/735], Loss: 0.2346\n",
      "Epoch [8/50], Step [255/735], Loss: 0.3728\n",
      "Epoch [8/50], Step [256/735], Loss: 0.7329\n",
      "Epoch [8/50], Step [257/735], Loss: 0.1735\n",
      "Epoch [8/50], Step [258/735], Loss: 0.2750\n",
      "Epoch [8/50], Step [259/735], Loss: 0.4160\n",
      "Epoch [8/50], Step [260/735], Loss: 2.1234\n",
      "Epoch [8/50], Step [261/735], Loss: 0.3185\n",
      "Epoch [8/50], Step [262/735], Loss: 0.5787\n",
      "Epoch [8/50], Step [263/735], Loss: 0.9998\n",
      "Epoch [8/50], Step [264/735], Loss: 1.6666\n",
      "Epoch [8/50], Step [265/735], Loss: 0.3167\n",
      "Epoch [8/50], Step [266/735], Loss: 0.3181\n",
      "Epoch [8/50], Step [267/735], Loss: 0.2255\n",
      "Epoch [8/50], Step [268/735], Loss: 0.4797\n",
      "Epoch [8/50], Step [269/735], Loss: 0.1899\n",
      "Epoch [8/50], Step [270/735], Loss: 0.3253\n",
      "Epoch [8/50], Step [271/735], Loss: 0.7325\n",
      "Epoch [8/50], Step [272/735], Loss: 0.5433\n",
      "Epoch [8/50], Step [273/735], Loss: 0.5218\n",
      "Epoch [8/50], Step [274/735], Loss: 0.1151\n",
      "Epoch [8/50], Step [275/735], Loss: 0.7200\n",
      "Epoch [8/50], Step [276/735], Loss: 0.3722\n",
      "Epoch [8/50], Step [277/735], Loss: 1.1794\n",
      "Epoch [8/50], Step [278/735], Loss: 0.6923\n",
      "Epoch [8/50], Step [279/735], Loss: 0.6017\n",
      "Epoch [8/50], Step [280/735], Loss: 2.8850\n",
      "Epoch [8/50], Step [281/735], Loss: 0.4751\n",
      "Epoch [8/50], Step [282/735], Loss: 1.1407\n",
      "Epoch [8/50], Step [283/735], Loss: 0.4257\n",
      "Epoch [8/50], Step [284/735], Loss: 0.5300\n",
      "Epoch [8/50], Step [285/735], Loss: 0.2574\n",
      "Epoch [8/50], Step [286/735], Loss: 0.2562\n",
      "Epoch [8/50], Step [287/735], Loss: 0.2311\n",
      "Epoch [8/50], Step [288/735], Loss: 0.3161\n",
      "Epoch [8/50], Step [289/735], Loss: 1.8849\n",
      "Epoch [8/50], Step [290/735], Loss: 0.8845\n",
      "Epoch [8/50], Step [291/735], Loss: 0.3540\n",
      "Epoch [8/50], Step [292/735], Loss: 0.3228\n",
      "Epoch [8/50], Step [293/735], Loss: 0.4126\n",
      "Epoch [8/50], Step [294/735], Loss: 0.5083\n",
      "Epoch [8/50], Step [295/735], Loss: 0.3558\n",
      "Epoch [8/50], Step [296/735], Loss: 0.3400\n",
      "Epoch [8/50], Step [297/735], Loss: 0.6470\n",
      "Epoch [8/50], Step [298/735], Loss: 0.2765\n",
      "Epoch [8/50], Step [299/735], Loss: 0.2254\n",
      "Epoch [8/50], Step [300/735], Loss: 0.2309\n",
      "Epoch [8/50], Step [301/735], Loss: 0.5774\n",
      "Epoch [8/50], Step [302/735], Loss: 0.2382\n",
      "Epoch [8/50], Step [303/735], Loss: 0.2153\n",
      "Epoch [8/50], Step [304/735], Loss: 0.8126\n",
      "Epoch [8/50], Step [305/735], Loss: 0.2382\n",
      "Epoch [8/50], Step [306/735], Loss: 0.1292\n",
      "Epoch [8/50], Step [307/735], Loss: 0.2694\n",
      "Epoch [8/50], Step [308/735], Loss: 1.1121\n",
      "Epoch [8/50], Step [309/735], Loss: 0.2467\n",
      "Epoch [8/50], Step [310/735], Loss: 0.1841\n",
      "Epoch [8/50], Step [311/735], Loss: 0.1647\n",
      "Epoch [8/50], Step [312/735], Loss: 0.3109\n",
      "Epoch [8/50], Step [313/735], Loss: 0.6034\n",
      "Epoch [8/50], Step [314/735], Loss: 0.7795\n",
      "Epoch [8/50], Step [315/735], Loss: 0.2709\n",
      "Epoch [8/50], Step [316/735], Loss: 0.1972\n",
      "Epoch [8/50], Step [317/735], Loss: 0.2580\n",
      "Epoch [8/50], Step [318/735], Loss: 0.6385\n",
      "Epoch [8/50], Step [319/735], Loss: 0.3538\n",
      "Epoch [8/50], Step [320/735], Loss: 0.2007\n",
      "Epoch [8/50], Step [321/735], Loss: 0.2823\n",
      "Epoch [8/50], Step [322/735], Loss: 0.9903\n",
      "Epoch [8/50], Step [323/735], Loss: 0.0948\n",
      "Epoch [8/50], Step [324/735], Loss: 0.3706\n",
      "Epoch [8/50], Step [325/735], Loss: 0.2259\n",
      "Epoch [8/50], Step [326/735], Loss: 0.8489\n",
      "Epoch [8/50], Step [327/735], Loss: 0.3395\n",
      "Epoch [8/50], Step [328/735], Loss: 0.3533\n",
      "Epoch [8/50], Step [329/735], Loss: 0.5202\n",
      "Epoch [8/50], Step [330/735], Loss: 0.4396\n",
      "Epoch [8/50], Step [331/735], Loss: 0.6355\n",
      "Epoch [8/50], Step [332/735], Loss: 0.2781\n",
      "Epoch [8/50], Step [333/735], Loss: 0.3501\n",
      "Epoch [8/50], Step [334/735], Loss: 0.1479\n",
      "Epoch [8/50], Step [335/735], Loss: 0.5177\n",
      "Epoch [8/50], Step [336/735], Loss: 0.7391\n",
      "Epoch [8/50], Step [337/735], Loss: 0.6879\n",
      "Epoch [8/50], Step [338/735], Loss: 0.5519\n",
      "Epoch [8/50], Step [339/735], Loss: 0.3207\n",
      "Epoch [8/50], Step [340/735], Loss: 0.7899\n",
      "Epoch [8/50], Step [341/735], Loss: 0.4897\n",
      "Epoch [8/50], Step [342/735], Loss: 0.1775\n",
      "Epoch [8/50], Step [343/735], Loss: 0.1299\n",
      "Epoch [8/50], Step [344/735], Loss: 0.1032\n",
      "Epoch [8/50], Step [345/735], Loss: 0.2709\n",
      "Epoch [8/50], Step [346/735], Loss: 0.2513\n",
      "Epoch [8/50], Step [347/735], Loss: 0.5698\n",
      "Epoch [8/50], Step [348/735], Loss: 0.4044\n",
      "Epoch [8/50], Step [349/735], Loss: 0.8207\n",
      "Epoch [8/50], Step [350/735], Loss: 0.4669\n",
      "Epoch [8/50], Step [351/735], Loss: 0.8801\n",
      "Epoch [8/50], Step [352/735], Loss: 1.6132\n",
      "Epoch [8/50], Step [353/735], Loss: 0.5294\n",
      "Epoch [8/50], Step [354/735], Loss: 0.1696\n",
      "Epoch [8/50], Step [355/735], Loss: 0.3891\n",
      "Epoch [8/50], Step [356/735], Loss: 1.2083\n",
      "Epoch [8/50], Step [357/735], Loss: 0.2632\n",
      "Epoch [8/50], Step [358/735], Loss: 0.4945\n",
      "Epoch [8/50], Step [359/735], Loss: 0.3517\n",
      "Epoch [8/50], Step [360/735], Loss: 0.2500\n",
      "Epoch [8/50], Step [361/735], Loss: 0.2732\n",
      "Epoch [8/50], Step [362/735], Loss: 1.4202\n",
      "Epoch [8/50], Step [363/735], Loss: 0.3732\n",
      "Epoch [8/50], Step [364/735], Loss: 0.4401\n",
      "Epoch [8/50], Step [365/735], Loss: 0.2335\n",
      "Epoch [8/50], Step [366/735], Loss: 0.0810\n",
      "Epoch [8/50], Step [367/735], Loss: 0.5706\n",
      "Epoch [8/50], Step [368/735], Loss: 0.4779\n",
      "Epoch [8/50], Step [369/735], Loss: 0.1495\n",
      "Epoch [8/50], Step [370/735], Loss: 0.3151\n",
      "Epoch [8/50], Step [371/735], Loss: 0.4073\n",
      "Epoch [8/50], Step [372/735], Loss: 0.2555\n",
      "Epoch [8/50], Step [373/735], Loss: 0.1905\n",
      "Epoch [8/50], Step [374/735], Loss: 0.3031\n",
      "Epoch [8/50], Step [375/735], Loss: 0.3267\n",
      "Epoch [8/50], Step [376/735], Loss: 0.2512\n",
      "Epoch [8/50], Step [377/735], Loss: 3.1246\n",
      "Epoch [8/50], Step [378/735], Loss: 0.3373\n",
      "Epoch [8/50], Step [379/735], Loss: 0.2494\n",
      "Epoch [8/50], Step [380/735], Loss: 0.2163\n",
      "Epoch [8/50], Step [381/735], Loss: 0.1684\n",
      "Epoch [8/50], Step [382/735], Loss: 1.2176\n",
      "Epoch [8/50], Step [383/735], Loss: 0.1120\n",
      "Epoch [8/50], Step [384/735], Loss: 0.5003\n",
      "Epoch [8/50], Step [385/735], Loss: 0.3257\n",
      "Epoch [8/50], Step [386/735], Loss: 0.8829\n",
      "Epoch [8/50], Step [387/735], Loss: 0.6837\n",
      "Epoch [8/50], Step [388/735], Loss: 0.1701\n",
      "Epoch [8/50], Step [389/735], Loss: 0.3421\n",
      "Epoch [8/50], Step [390/735], Loss: 0.4501\n",
      "Epoch [8/50], Step [391/735], Loss: 0.4935\n",
      "Epoch [8/50], Step [392/735], Loss: 0.4004\n",
      "Epoch [8/50], Step [393/735], Loss: 0.4570\n",
      "Epoch [8/50], Step [394/735], Loss: 1.2381\n",
      "Epoch [8/50], Step [395/735], Loss: 0.0448\n",
      "Epoch [8/50], Step [396/735], Loss: 0.4830\n",
      "Epoch [8/50], Step [397/735], Loss: 0.4840\n",
      "Epoch [8/50], Step [398/735], Loss: 0.4395\n",
      "Epoch [8/50], Step [399/735], Loss: 5.5819\n",
      "Epoch [8/50], Step [400/735], Loss: 0.9076\n",
      "Epoch [8/50], Step [401/735], Loss: 2.6175\n",
      "Epoch [8/50], Step [402/735], Loss: 0.7827\n",
      "Epoch [8/50], Step [403/735], Loss: 0.1088\n",
      "Epoch [8/50], Step [404/735], Loss: 0.7520\n",
      "Epoch [8/50], Step [405/735], Loss: 0.5279\n",
      "Epoch [8/50], Step [406/735], Loss: 0.2217\n",
      "Epoch [8/50], Step [407/735], Loss: 0.4943\n",
      "Epoch [8/50], Step [408/735], Loss: 0.1248\n",
      "Epoch [8/50], Step [409/735], Loss: 0.2096\n",
      "Epoch [8/50], Step [410/735], Loss: 0.4925\n",
      "Epoch [8/50], Step [411/735], Loss: 0.4678\n",
      "Epoch [8/50], Step [412/735], Loss: 0.2782\n",
      "Epoch [8/50], Step [413/735], Loss: 0.2340\n",
      "Epoch [8/50], Step [414/735], Loss: 0.6223\n",
      "Epoch [8/50], Step [415/735], Loss: 0.8782\n",
      "Epoch [8/50], Step [416/735], Loss: 0.3510\n",
      "Epoch [8/50], Step [417/735], Loss: 0.0707\n",
      "Epoch [8/50], Step [418/735], Loss: 0.4414\n",
      "Epoch [8/50], Step [419/735], Loss: 0.2601\n",
      "Epoch [8/50], Step [420/735], Loss: 0.1020\n",
      "Epoch [8/50], Step [421/735], Loss: 0.4188\n",
      "Epoch [8/50], Step [422/735], Loss: 0.1551\n",
      "Epoch [8/50], Step [423/735], Loss: 0.3568\n",
      "Epoch [8/50], Step [424/735], Loss: 1.0139\n",
      "Epoch [8/50], Step [425/735], Loss: 0.1715\n",
      "Epoch [8/50], Step [426/735], Loss: 0.4401\n",
      "Epoch [8/50], Step [427/735], Loss: 0.0925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Step [428/735], Loss: 0.5697\n",
      "Epoch [8/50], Step [429/735], Loss: 0.4808\n",
      "Epoch [8/50], Step [430/735], Loss: 0.2355\n",
      "Epoch [8/50], Step [431/735], Loss: 0.4218\n",
      "Epoch [8/50], Step [432/735], Loss: 0.7371\n",
      "Epoch [8/50], Step [433/735], Loss: 0.2808\n",
      "Epoch [8/50], Step [434/735], Loss: 0.2473\n",
      "Epoch [8/50], Step [435/735], Loss: 0.2742\n",
      "Epoch [8/50], Step [436/735], Loss: 0.3502\n",
      "Epoch [8/50], Step [437/735], Loss: 0.1926\n",
      "Epoch [8/50], Step [438/735], Loss: 0.4510\n",
      "Epoch [8/50], Step [439/735], Loss: 0.1267\n",
      "Epoch [8/50], Step [440/735], Loss: 1.0057\n",
      "Epoch [8/50], Step [441/735], Loss: 0.7570\n",
      "Epoch [8/50], Step [442/735], Loss: 0.4386\n",
      "Epoch [8/50], Step [443/735], Loss: 0.2835\n",
      "Epoch [8/50], Step [444/735], Loss: 1.0586\n",
      "Epoch [8/50], Step [445/735], Loss: 0.3411\n",
      "Epoch [8/50], Step [446/735], Loss: 2.3675\n",
      "Epoch [8/50], Step [447/735], Loss: 0.8901\n",
      "Epoch [8/50], Step [448/735], Loss: 0.3194\n",
      "Epoch [8/50], Step [449/735], Loss: 0.3995\n",
      "Epoch [8/50], Step [450/735], Loss: 0.5300\n",
      "Epoch [8/50], Step [451/735], Loss: 0.6259\n",
      "Epoch [8/50], Step [452/735], Loss: 0.5183\n",
      "Epoch [8/50], Step [453/735], Loss: 0.3966\n",
      "Epoch [8/50], Step [454/735], Loss: 0.3311\n",
      "Epoch [8/50], Step [455/735], Loss: 0.3541\n",
      "Epoch [8/50], Step [456/735], Loss: 0.4091\n",
      "Epoch [8/50], Step [457/735], Loss: 0.2329\n",
      "Epoch [8/50], Step [458/735], Loss: 0.4826\n",
      "Epoch [8/50], Step [459/735], Loss: 0.5998\n",
      "Epoch [8/50], Step [460/735], Loss: 0.5009\n",
      "Epoch [8/50], Step [461/735], Loss: 0.4861\n",
      "Epoch [8/50], Step [462/735], Loss: 0.4411\n",
      "Epoch [8/50], Step [463/735], Loss: 0.2027\n",
      "Epoch [8/50], Step [464/735], Loss: 0.0841\n",
      "Epoch [8/50], Step [465/735], Loss: 0.0981\n",
      "Epoch [8/50], Step [466/735], Loss: 0.3639\n",
      "Epoch [8/50], Step [467/735], Loss: 0.1130\n",
      "Epoch [8/50], Step [468/735], Loss: 0.8203\n",
      "Epoch [8/50], Step [469/735], Loss: 0.3427\n",
      "Epoch [8/50], Step [470/735], Loss: 0.2223\n",
      "Epoch [8/50], Step [471/735], Loss: 0.3477\n",
      "Epoch [8/50], Step [472/735], Loss: 0.3305\n",
      "Epoch [8/50], Step [473/735], Loss: 0.6828\n",
      "Epoch [8/50], Step [474/735], Loss: 1.5585\n",
      "Epoch [8/50], Step [475/735], Loss: 0.5688\n",
      "Epoch [8/50], Step [476/735], Loss: 0.1598\n",
      "Epoch [8/50], Step [477/735], Loss: 0.4938\n",
      "Epoch [8/50], Step [478/735], Loss: 0.4756\n",
      "Epoch [8/50], Step [479/735], Loss: 0.4173\n",
      "Epoch [8/50], Step [480/735], Loss: 0.2921\n",
      "Epoch [8/50], Step [481/735], Loss: 0.4566\n",
      "Epoch [8/50], Step [482/735], Loss: 0.2424\n",
      "Epoch [8/50], Step [483/735], Loss: 0.5571\n",
      "Epoch [8/50], Step [484/735], Loss: 0.7225\n",
      "Epoch [8/50], Step [485/735], Loss: 0.2058\n",
      "Epoch [8/50], Step [486/735], Loss: 1.0060\n",
      "Epoch [8/50], Step [487/735], Loss: 0.1061\n",
      "Epoch [8/50], Step [488/735], Loss: 0.4612\n",
      "Epoch [8/50], Step [489/735], Loss: 0.5980\n",
      "Epoch [8/50], Step [490/735], Loss: 0.1080\n",
      "Epoch [8/50], Step [491/735], Loss: 1.4370\n",
      "Epoch [8/50], Step [492/735], Loss: 0.5914\n",
      "Epoch [8/50], Step [493/735], Loss: 1.1187\n",
      "Epoch [8/50], Step [494/735], Loss: 0.4034\n",
      "Epoch [8/50], Step [495/735], Loss: 0.5110\n",
      "Epoch [8/50], Step [496/735], Loss: 0.4331\n",
      "Epoch [8/50], Step [497/735], Loss: 0.2614\n",
      "Epoch [8/50], Step [498/735], Loss: 0.2586\n",
      "Epoch [8/50], Step [499/735], Loss: 0.2630\n",
      "Epoch [8/50], Step [500/735], Loss: 0.1474\n",
      "Epoch [8/50], Step [501/735], Loss: 0.1901\n",
      "Epoch [8/50], Step [502/735], Loss: 0.4668\n",
      "Epoch [8/50], Step [503/735], Loss: 0.3083\n",
      "Epoch [8/50], Step [504/735], Loss: 0.6777\n",
      "Epoch [8/50], Step [505/735], Loss: 0.2710\n",
      "Epoch [8/50], Step [506/735], Loss: 0.1234\n",
      "Epoch [8/50], Step [507/735], Loss: 0.3508\n",
      "Epoch [8/50], Step [508/735], Loss: 0.4690\n",
      "Epoch [8/50], Step [509/735], Loss: 0.3490\n",
      "Epoch [8/50], Step [510/735], Loss: 0.2661\n",
      "Epoch [8/50], Step [511/735], Loss: 0.1981\n",
      "Epoch [8/50], Step [512/735], Loss: 0.2408\n",
      "Epoch [8/50], Step [513/735], Loss: 0.2132\n",
      "Epoch [8/50], Step [514/735], Loss: 0.3034\n",
      "Epoch [8/50], Step [515/735], Loss: 0.3031\n",
      "Epoch [8/50], Step [516/735], Loss: 0.1687\n",
      "Epoch [8/50], Step [517/735], Loss: 0.5667\n",
      "Epoch [8/50], Step [518/735], Loss: 0.8135\n",
      "Epoch [8/50], Step [519/735], Loss: 0.4747\n",
      "Epoch [8/50], Step [520/735], Loss: 0.3094\n",
      "Epoch [8/50], Step [521/735], Loss: 0.1965\n",
      "Epoch [8/50], Step [522/735], Loss: 0.2794\n",
      "Epoch [8/50], Step [523/735], Loss: 0.7762\n",
      "Epoch [8/50], Step [524/735], Loss: 2.1929\n",
      "Epoch [8/50], Step [525/735], Loss: 2.6277\n",
      "Epoch [8/50], Step [526/735], Loss: 0.4529\n",
      "Epoch [8/50], Step [527/735], Loss: 0.3777\n",
      "Epoch [8/50], Step [528/735], Loss: 0.5167\n",
      "Epoch [8/50], Step [529/735], Loss: 0.1115\n",
      "Epoch [8/50], Step [530/735], Loss: 0.2700\n",
      "Epoch [8/50], Step [531/735], Loss: 0.2544\n",
      "Epoch [8/50], Step [532/735], Loss: 0.4073\n",
      "Epoch [8/50], Step [533/735], Loss: 0.7257\n",
      "Epoch [8/50], Step [534/735], Loss: 0.8533\n",
      "Epoch [8/50], Step [535/735], Loss: 0.1065\n",
      "Epoch [8/50], Step [536/735], Loss: 0.1789\n",
      "Epoch [8/50], Step [537/735], Loss: 0.6839\n",
      "Epoch [8/50], Step [538/735], Loss: 0.0857\n",
      "Epoch [8/50], Step [539/735], Loss: 0.1180\n",
      "Epoch [8/50], Step [540/735], Loss: 0.4963\n",
      "Epoch [8/50], Step [541/735], Loss: 0.3549\n",
      "Epoch [8/50], Step [542/735], Loss: 0.2124\n",
      "Epoch [8/50], Step [543/735], Loss: 1.6839\n",
      "Epoch [8/50], Step [544/735], Loss: 1.0557\n",
      "Epoch [8/50], Step [545/735], Loss: 1.4053\n",
      "Epoch [8/50], Step [546/735], Loss: 0.0850\n",
      "Epoch [8/50], Step [547/735], Loss: 0.1531\n",
      "Epoch [8/50], Step [548/735], Loss: 0.4149\n",
      "Epoch [8/50], Step [549/735], Loss: 0.3706\n",
      "Epoch [8/50], Step [550/735], Loss: 0.1627\n",
      "Epoch [8/50], Step [551/735], Loss: 0.3192\n",
      "Epoch [8/50], Step [552/735], Loss: 0.2001\n",
      "Epoch [8/50], Step [553/735], Loss: 0.4307\n",
      "Epoch [8/50], Step [554/735], Loss: 0.1718\n",
      "Epoch [8/50], Step [555/735], Loss: 1.4817\n",
      "Epoch [8/50], Step [556/735], Loss: 0.3654\n",
      "Epoch [8/50], Step [557/735], Loss: 0.4256\n",
      "Epoch [8/50], Step [558/735], Loss: 0.2427\n",
      "Epoch [8/50], Step [559/735], Loss: 0.6723\n",
      "Epoch [8/50], Step [560/735], Loss: 0.2704\n",
      "Epoch [8/50], Step [561/735], Loss: 0.1191\n",
      "Epoch [8/50], Step [562/735], Loss: 0.5146\n",
      "Epoch [8/50], Step [563/735], Loss: 0.0560\n",
      "Epoch [8/50], Step [564/735], Loss: 0.1377\n",
      "Epoch [8/50], Step [565/735], Loss: 0.4585\n",
      "Epoch [8/50], Step [566/735], Loss: 0.3400\n",
      "Epoch [8/50], Step [567/735], Loss: 0.2818\n",
      "Epoch [8/50], Step [568/735], Loss: 0.2343\n",
      "Epoch [8/50], Step [569/735], Loss: 0.2972\n",
      "Epoch [8/50], Step [570/735], Loss: 0.4772\n",
      "Epoch [8/50], Step [571/735], Loss: 1.3599\n",
      "Epoch [8/50], Step [572/735], Loss: 0.5254\n",
      "Epoch [8/50], Step [573/735], Loss: 0.3630\n",
      "Epoch [8/50], Step [574/735], Loss: 0.6308\n",
      "Epoch [8/50], Step [575/735], Loss: 0.3395\n",
      "Epoch [8/50], Step [576/735], Loss: 0.3133\n",
      "Epoch [8/50], Step [577/735], Loss: 0.7098\n",
      "Epoch [8/50], Step [578/735], Loss: 0.4479\n",
      "Epoch [8/50], Step [579/735], Loss: 0.5230\n",
      "Epoch [8/50], Step [580/735], Loss: 0.1433\n",
      "Epoch [8/50], Step [581/735], Loss: 0.2985\n",
      "Epoch [8/50], Step [582/735], Loss: 0.3872\n",
      "Epoch [8/50], Step [583/735], Loss: 0.3288\n",
      "Epoch [8/50], Step [584/735], Loss: 0.6555\n",
      "Epoch [8/50], Step [585/735], Loss: 0.2766\n",
      "Epoch [8/50], Step [586/735], Loss: 0.9369\n",
      "Epoch [8/50], Step [587/735], Loss: 0.1717\n",
      "Epoch [8/50], Step [588/735], Loss: 0.8900\n",
      "Epoch [8/50], Step [589/735], Loss: 0.5979\n",
      "Epoch [8/50], Step [590/735], Loss: 0.1937\n",
      "Epoch [8/50], Step [591/735], Loss: 0.2733\n",
      "Epoch [8/50], Step [592/735], Loss: 4.9886\n",
      "Epoch [8/50], Step [593/735], Loss: 0.5267\n",
      "Epoch [8/50], Step [594/735], Loss: 0.2225\n",
      "Epoch [8/50], Step [595/735], Loss: 0.6675\n",
      "Epoch [8/50], Step [596/735], Loss: 0.1089\n",
      "Epoch [8/50], Step [597/735], Loss: 1.2770\n",
      "Epoch [8/50], Step [598/735], Loss: 1.3380\n",
      "Epoch [8/50], Step [599/735], Loss: 0.2042\n",
      "Epoch [8/50], Step [600/735], Loss: 0.6866\n",
      "Epoch [8/50], Step [601/735], Loss: 0.5030\n",
      "Epoch [8/50], Step [602/735], Loss: 0.2471\n",
      "Epoch [8/50], Step [603/735], Loss: 0.2898\n",
      "Epoch [8/50], Step [604/735], Loss: 0.0955\n",
      "Epoch [8/50], Step [605/735], Loss: 0.7431\n",
      "Epoch [8/50], Step [606/735], Loss: 0.7520\n",
      "Epoch [8/50], Step [607/735], Loss: 0.9148\n",
      "Epoch [8/50], Step [608/735], Loss: 0.4714\n",
      "Epoch [8/50], Step [609/735], Loss: 1.0903\n",
      "Epoch [8/50], Step [610/735], Loss: 0.4629\n",
      "Epoch [8/50], Step [611/735], Loss: 0.7115\n",
      "Epoch [8/50], Step [612/735], Loss: 0.1183\n",
      "Epoch [8/50], Step [613/735], Loss: 0.0492\n",
      "Epoch [8/50], Step [614/735], Loss: 0.3090\n",
      "Epoch [8/50], Step [615/735], Loss: 0.3168\n",
      "Epoch [8/50], Step [616/735], Loss: 0.3997\n",
      "Epoch [8/50], Step [617/735], Loss: 0.0612\n",
      "Epoch [8/50], Step [618/735], Loss: 0.2420\n",
      "Epoch [8/50], Step [619/735], Loss: 0.6532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Step [620/735], Loss: 0.4352\n",
      "Epoch [8/50], Step [621/735], Loss: 0.6857\n",
      "Epoch [8/50], Step [622/735], Loss: 0.1880\n",
      "Epoch [8/50], Step [623/735], Loss: 0.1261\n",
      "Epoch [8/50], Step [624/735], Loss: 0.6425\n",
      "Epoch [8/50], Step [625/735], Loss: 0.2155\n",
      "Epoch [8/50], Step [626/735], Loss: 1.8538\n",
      "Epoch [8/50], Step [627/735], Loss: 1.3333\n",
      "Epoch [8/50], Step [628/735], Loss: 0.4013\n",
      "Epoch [8/50], Step [629/735], Loss: 0.4262\n",
      "Epoch [8/50], Step [630/735], Loss: 0.6405\n",
      "Epoch [8/50], Step [631/735], Loss: 0.3835\n",
      "Epoch [8/50], Step [632/735], Loss: 0.7284\n",
      "Epoch [8/50], Step [633/735], Loss: 0.3482\n",
      "Epoch [8/50], Step [634/735], Loss: 0.1779\n",
      "Epoch [8/50], Step [635/735], Loss: 0.2452\n",
      "Epoch [8/50], Step [636/735], Loss: 0.3463\n",
      "Epoch [8/50], Step [637/735], Loss: 0.7845\n",
      "Epoch [8/50], Step [638/735], Loss: 1.7632\n",
      "Epoch [8/50], Step [639/735], Loss: 0.5639\n",
      "Epoch [8/50], Step [640/735], Loss: 0.1565\n",
      "Epoch [8/50], Step [641/735], Loss: 0.0889\n",
      "Epoch [8/50], Step [642/735], Loss: 0.0743\n",
      "Epoch [8/50], Step [643/735], Loss: 0.2859\n",
      "Epoch [8/50], Step [644/735], Loss: 2.8592\n",
      "Epoch [8/50], Step [645/735], Loss: 0.2484\n",
      "Epoch [8/50], Step [646/735], Loss: 0.1046\n",
      "Epoch [8/50], Step [647/735], Loss: 0.4166\n",
      "Epoch [8/50], Step [648/735], Loss: 5.3478\n",
      "Epoch [8/50], Step [649/735], Loss: 0.3050\n",
      "Epoch [8/50], Step [650/735], Loss: 0.2804\n",
      "Epoch [8/50], Step [651/735], Loss: 0.9285\n",
      "Epoch [8/50], Step [652/735], Loss: 0.9421\n",
      "Epoch [8/50], Step [653/735], Loss: 0.5240\n",
      "Epoch [8/50], Step [654/735], Loss: 0.2427\n",
      "Epoch [8/50], Step [655/735], Loss: 0.4131\n",
      "Epoch [8/50], Step [656/735], Loss: 0.1175\n",
      "Epoch [8/50], Step [657/735], Loss: 0.3714\n",
      "Epoch [8/50], Step [658/735], Loss: 1.9276\n",
      "Epoch [8/50], Step [659/735], Loss: 0.1162\n",
      "Epoch [8/50], Step [660/735], Loss: 0.1528\n",
      "Epoch [8/50], Step [661/735], Loss: 0.1517\n",
      "Epoch [8/50], Step [662/735], Loss: 0.5766\n",
      "Epoch [8/50], Step [663/735], Loss: 1.3220\n",
      "Epoch [8/50], Step [664/735], Loss: 0.1795\n",
      "Epoch [8/50], Step [665/735], Loss: 0.3407\n",
      "Epoch [8/50], Step [666/735], Loss: 4.5659\n",
      "Epoch [8/50], Step [667/735], Loss: 0.5317\n",
      "Epoch [8/50], Step [668/735], Loss: 0.1565\n",
      "Epoch [8/50], Step [669/735], Loss: 1.7378\n",
      "Epoch [8/50], Step [670/735], Loss: 0.3037\n",
      "Epoch [8/50], Step [671/735], Loss: 0.3904\n",
      "Epoch [8/50], Step [672/735], Loss: 0.3250\n",
      "Epoch [8/50], Step [673/735], Loss: 0.4574\n",
      "Epoch [8/50], Step [674/735], Loss: 0.1554\n",
      "Epoch [8/50], Step [675/735], Loss: 0.1438\n",
      "Epoch [8/50], Step [676/735], Loss: 0.1042\n",
      "Epoch [8/50], Step [677/735], Loss: 0.1756\n",
      "Epoch [8/50], Step [678/735], Loss: 0.5456\n",
      "Epoch [8/50], Step [679/735], Loss: 0.6864\n",
      "Epoch [8/50], Step [680/735], Loss: 0.7617\n",
      "Epoch [8/50], Step [681/735], Loss: 0.3160\n",
      "Epoch [8/50], Step [682/735], Loss: 0.6826\n",
      "Epoch [8/50], Step [683/735], Loss: 0.1264\n",
      "Epoch [8/50], Step [684/735], Loss: 0.9038\n",
      "Epoch [8/50], Step [685/735], Loss: 1.1500\n",
      "Epoch [8/50], Step [686/735], Loss: 0.5814\n",
      "Epoch [8/50], Step [687/735], Loss: 0.2962\n",
      "Epoch [8/50], Step [688/735], Loss: 0.1146\n",
      "Epoch [8/50], Step [689/735], Loss: 0.3053\n",
      "Epoch [8/50], Step [690/735], Loss: 0.4135\n",
      "Epoch [8/50], Step [691/735], Loss: 0.4123\n",
      "Epoch [8/50], Step [692/735], Loss: 0.2834\n",
      "Epoch [8/50], Step [693/735], Loss: 1.6637\n",
      "Epoch [8/50], Step [694/735], Loss: 0.1079\n",
      "Epoch [8/50], Step [695/735], Loss: 0.1361\n",
      "Epoch [8/50], Step [696/735], Loss: 0.4525\n",
      "Epoch [8/50], Step [697/735], Loss: 0.5726\n",
      "Epoch [8/50], Step [698/735], Loss: 0.2578\n",
      "Epoch [8/50], Step [699/735], Loss: 0.1625\n",
      "Epoch [8/50], Step [700/735], Loss: 0.2654\n",
      "Epoch [8/50], Step [701/735], Loss: 0.3689\n",
      "Epoch [8/50], Step [702/735], Loss: 1.6604\n",
      "Epoch [8/50], Step [703/735], Loss: 0.4440\n",
      "Epoch [8/50], Step [704/735], Loss: 1.3081\n",
      "Epoch [8/50], Step [705/735], Loss: 0.4285\n",
      "Epoch [8/50], Step [706/735], Loss: 0.3368\n",
      "Epoch [8/50], Step [707/735], Loss: 1.3065\n",
      "Epoch [8/50], Step [708/735], Loss: 0.3326\n",
      "Epoch [8/50], Step [709/735], Loss: 0.5654\n",
      "Epoch [8/50], Step [710/735], Loss: 0.6005\n",
      "Epoch [8/50], Step [711/735], Loss: 0.3658\n",
      "Epoch [8/50], Step [712/735], Loss: 0.8009\n",
      "Epoch [8/50], Step [713/735], Loss: 0.6693\n",
      "Epoch [8/50], Step [714/735], Loss: 0.3271\n",
      "Epoch [8/50], Step [715/735], Loss: 0.2786\n",
      "Epoch [8/50], Step [716/735], Loss: 0.1761\n",
      "Epoch [8/50], Step [717/735], Loss: 0.7024\n",
      "Epoch [8/50], Step [718/735], Loss: 0.3649\n",
      "Epoch [8/50], Step [719/735], Loss: 0.0773\n",
      "Epoch [8/50], Step [720/735], Loss: 1.1367\n",
      "Epoch [8/50], Step [721/735], Loss: 0.7239\n",
      "Epoch [8/50], Step [722/735], Loss: 0.3857\n",
      "Epoch [8/50], Step [723/735], Loss: 0.4040\n",
      "Epoch [8/50], Step [724/735], Loss: 0.4198\n",
      "Epoch [8/50], Step [725/735], Loss: 0.4442\n",
      "Epoch [8/50], Step [726/735], Loss: 0.8424\n",
      "Epoch [8/50], Step [727/735], Loss: 0.2221\n",
      "Epoch [8/50], Step [728/735], Loss: 1.7686\n",
      "Epoch [8/50], Step [729/735], Loss: 0.4610\n",
      "Epoch [8/50], Step [730/735], Loss: 0.7380\n",
      "Epoch [8/50], Step [731/735], Loss: 0.1657\n",
      "Epoch [8/50], Step [732/735], Loss: 0.7040\n",
      "Epoch [8/50], Step [733/735], Loss: 0.3662\n",
      "Epoch [8/50], Step [734/735], Loss: 0.2203\n",
      "Epoch [8/50], Step [735/735], Loss: 0.3019\n",
      "Epoch [9/50], Step [1/735], Loss: 0.2709\n",
      "Epoch [9/50], Step [2/735], Loss: 0.5816\n",
      "Epoch [9/50], Step [3/735], Loss: 0.2892\n",
      "Epoch [9/50], Step [4/735], Loss: 0.7509\n",
      "Epoch [9/50], Step [5/735], Loss: 0.4775\n",
      "Epoch [9/50], Step [6/735], Loss: 0.2914\n",
      "Epoch [9/50], Step [7/735], Loss: 0.2957\n",
      "Epoch [9/50], Step [8/735], Loss: 0.3366\n",
      "Epoch [9/50], Step [9/735], Loss: 0.3474\n",
      "Epoch [9/50], Step [10/735], Loss: 1.0640\n",
      "Epoch [9/50], Step [11/735], Loss: 0.1855\n",
      "Epoch [9/50], Step [12/735], Loss: 0.3865\n",
      "Epoch [9/50], Step [13/735], Loss: 0.1582\n",
      "Epoch [9/50], Step [14/735], Loss: 0.1860\n",
      "Epoch [9/50], Step [15/735], Loss: 0.2794\n",
      "Epoch [9/50], Step [16/735], Loss: 0.1816\n",
      "Epoch [9/50], Step [17/735], Loss: 0.9496\n",
      "Epoch [9/50], Step [18/735], Loss: 0.1544\n",
      "Epoch [9/50], Step [19/735], Loss: 0.1336\n",
      "Epoch [9/50], Step [20/735], Loss: 0.3292\n",
      "Epoch [9/50], Step [21/735], Loss: 0.2042\n",
      "Epoch [9/50], Step [22/735], Loss: 1.4524\n",
      "Epoch [9/50], Step [23/735], Loss: 0.2178\n",
      "Epoch [9/50], Step [24/735], Loss: 0.3454\n",
      "Epoch [9/50], Step [25/735], Loss: 0.4326\n",
      "Epoch [9/50], Step [26/735], Loss: 0.6343\n",
      "Epoch [9/50], Step [27/735], Loss: 0.3285\n",
      "Epoch [9/50], Step [28/735], Loss: 0.6219\n",
      "Epoch [9/50], Step [29/735], Loss: 0.7151\n",
      "Epoch [9/50], Step [30/735], Loss: 0.2293\n",
      "Epoch [9/50], Step [31/735], Loss: 0.5628\n",
      "Epoch [9/50], Step [32/735], Loss: 0.8755\n",
      "Epoch [9/50], Step [33/735], Loss: 1.7525\n",
      "Epoch [9/50], Step [34/735], Loss: 0.1852\n",
      "Epoch [9/50], Step [35/735], Loss: 0.3703\n",
      "Epoch [9/50], Step [36/735], Loss: 0.6764\n",
      "Epoch [9/50], Step [37/735], Loss: 0.2854\n",
      "Epoch [9/50], Step [38/735], Loss: 0.3991\n",
      "Epoch [9/50], Step [39/735], Loss: 0.3626\n",
      "Epoch [9/50], Step [40/735], Loss: 0.5624\n",
      "Epoch [9/50], Step [41/735], Loss: 0.5240\n",
      "Epoch [9/50], Step [42/735], Loss: 0.3291\n",
      "Epoch [9/50], Step [43/735], Loss: 0.2907\n",
      "Epoch [9/50], Step [44/735], Loss: 0.4666\n",
      "Epoch [9/50], Step [45/735], Loss: 0.0786\n",
      "Epoch [9/50], Step [46/735], Loss: 0.3176\n",
      "Epoch [9/50], Step [47/735], Loss: 0.4659\n",
      "Epoch [9/50], Step [48/735], Loss: 0.1151\n",
      "Epoch [9/50], Step [49/735], Loss: 0.8338\n",
      "Epoch [9/50], Step [50/735], Loss: 0.2095\n",
      "Epoch [9/50], Step [51/735], Loss: 0.5113\n",
      "Epoch [9/50], Step [52/735], Loss: 0.1910\n",
      "Epoch [9/50], Step [53/735], Loss: 0.1856\n",
      "Epoch [9/50], Step [54/735], Loss: 1.9182\n",
      "Epoch [9/50], Step [55/735], Loss: 0.5245\n",
      "Epoch [9/50], Step [56/735], Loss: 2.0555\n",
      "Epoch [9/50], Step [57/735], Loss: 0.1616\n",
      "Epoch [9/50], Step [58/735], Loss: 0.3906\n",
      "Epoch [9/50], Step [59/735], Loss: 1.4676\n",
      "Epoch [9/50], Step [60/735], Loss: 0.8877\n",
      "Epoch [9/50], Step [61/735], Loss: 0.1220\n",
      "Epoch [9/50], Step [62/735], Loss: 0.3835\n",
      "Epoch [9/50], Step [63/735], Loss: 0.3174\n",
      "Epoch [9/50], Step [64/735], Loss: 0.1632\n",
      "Epoch [9/50], Step [65/735], Loss: 0.4394\n",
      "Epoch [9/50], Step [66/735], Loss: 0.2862\n",
      "Epoch [9/50], Step [67/735], Loss: 0.3187\n",
      "Epoch [9/50], Step [68/735], Loss: 0.1299\n",
      "Epoch [9/50], Step [69/735], Loss: 0.4521\n",
      "Epoch [9/50], Step [70/735], Loss: 0.5002\n",
      "Epoch [9/50], Step [71/735], Loss: 0.7129\n",
      "Epoch [9/50], Step [72/735], Loss: 1.7132\n",
      "Epoch [9/50], Step [73/735], Loss: 5.3403\n",
      "Epoch [9/50], Step [74/735], Loss: 0.4153\n",
      "Epoch [9/50], Step [75/735], Loss: 0.3001\n",
      "Epoch [9/50], Step [76/735], Loss: 1.9713\n",
      "Epoch [9/50], Step [77/735], Loss: 0.5331\n",
      "Epoch [9/50], Step [78/735], Loss: 0.4494\n",
      "Epoch [9/50], Step [79/735], Loss: 0.2484\n",
      "Epoch [9/50], Step [80/735], Loss: 0.7077\n",
      "Epoch [9/50], Step [81/735], Loss: 0.8280\n",
      "Epoch [9/50], Step [82/735], Loss: 0.3084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Step [83/735], Loss: 0.6891\n",
      "Epoch [9/50], Step [84/735], Loss: 1.1389\n",
      "Epoch [9/50], Step [85/735], Loss: 0.6960\n",
      "Epoch [9/50], Step [86/735], Loss: 0.2090\n",
      "Epoch [9/50], Step [87/735], Loss: 0.2590\n",
      "Epoch [9/50], Step [88/735], Loss: 1.2056\n",
      "Epoch [9/50], Step [89/735], Loss: 0.1327\n",
      "Epoch [9/50], Step [90/735], Loss: 0.3470\n",
      "Epoch [9/50], Step [91/735], Loss: 1.0980\n",
      "Epoch [9/50], Step [92/735], Loss: 0.8098\n",
      "Epoch [9/50], Step [93/735], Loss: 1.4768\n",
      "Epoch [9/50], Step [94/735], Loss: 0.3781\n",
      "Epoch [9/50], Step [95/735], Loss: 0.1025\n",
      "Epoch [9/50], Step [96/735], Loss: 0.7682\n",
      "Epoch [9/50], Step [97/735], Loss: 0.8595\n",
      "Epoch [9/50], Step [98/735], Loss: 0.5234\n",
      "Epoch [9/50], Step [99/735], Loss: 0.7582\n",
      "Epoch [9/50], Step [100/735], Loss: 0.2687\n",
      "Epoch [9/50], Step [101/735], Loss: 0.5332\n",
      "Epoch [9/50], Step [102/735], Loss: 0.2143\n",
      "Epoch [9/50], Step [103/735], Loss: 0.1848\n",
      "Epoch [9/50], Step [104/735], Loss: 0.4110\n",
      "Epoch [9/50], Step [105/735], Loss: 0.3977\n",
      "Epoch [9/50], Step [106/735], Loss: 0.1900\n",
      "Epoch [9/50], Step [107/735], Loss: 0.1958\n",
      "Epoch [9/50], Step [108/735], Loss: 0.1406\n",
      "Epoch [9/50], Step [109/735], Loss: 1.9684\n",
      "Epoch [9/50], Step [110/735], Loss: 0.3705\n",
      "Epoch [9/50], Step [111/735], Loss: 0.0841\n",
      "Epoch [9/50], Step [112/735], Loss: 0.1815\n",
      "Epoch [9/50], Step [113/735], Loss: 0.7343\n",
      "Epoch [9/50], Step [114/735], Loss: 0.1168\n",
      "Epoch [9/50], Step [115/735], Loss: 0.2493\n",
      "Epoch [9/50], Step [116/735], Loss: 0.5499\n",
      "Epoch [9/50], Step [117/735], Loss: 0.8353\n",
      "Epoch [9/50], Step [118/735], Loss: 0.2099\n",
      "Epoch [9/50], Step [119/735], Loss: 0.3944\n",
      "Epoch [9/50], Step [120/735], Loss: 0.2614\n",
      "Epoch [9/50], Step [121/735], Loss: 0.7202\n",
      "Epoch [9/50], Step [122/735], Loss: 0.2833\n",
      "Epoch [9/50], Step [123/735], Loss: 0.5590\n",
      "Epoch [9/50], Step [124/735], Loss: 0.4434\n",
      "Epoch [9/50], Step [125/735], Loss: 0.3072\n",
      "Epoch [9/50], Step [126/735], Loss: 0.2799\n",
      "Epoch [9/50], Step [127/735], Loss: 0.0944\n",
      "Epoch [9/50], Step [128/735], Loss: 0.4718\n",
      "Epoch [9/50], Step [129/735], Loss: 0.1843\n",
      "Epoch [9/50], Step [130/735], Loss: 0.3088\n",
      "Epoch [9/50], Step [131/735], Loss: 0.2319\n",
      "Epoch [9/50], Step [132/735], Loss: 0.2880\n",
      "Epoch [9/50], Step [133/735], Loss: 0.1181\n",
      "Epoch [9/50], Step [134/735], Loss: 0.4101\n",
      "Epoch [9/50], Step [135/735], Loss: 0.1811\n",
      "Epoch [9/50], Step [136/735], Loss: 0.6324\n",
      "Epoch [9/50], Step [137/735], Loss: 0.5591\n",
      "Epoch [9/50], Step [138/735], Loss: 0.3520\n",
      "Epoch [9/50], Step [139/735], Loss: 0.2117\n",
      "Epoch [9/50], Step [140/735], Loss: 0.2588\n",
      "Epoch [9/50], Step [141/735], Loss: 1.0885\n",
      "Epoch [9/50], Step [142/735], Loss: 0.2024\n",
      "Epoch [9/50], Step [143/735], Loss: 0.6072\n",
      "Epoch [9/50], Step [144/735], Loss: 0.5897\n",
      "Epoch [9/50], Step [145/735], Loss: 0.1732\n",
      "Epoch [9/50], Step [146/735], Loss: 0.2708\n",
      "Epoch [9/50], Step [147/735], Loss: 0.2369\n",
      "Epoch [9/50], Step [148/735], Loss: 0.7737\n",
      "Epoch [9/50], Step [149/735], Loss: 0.4472\n",
      "Epoch [9/50], Step [150/735], Loss: 0.3503\n",
      "Epoch [9/50], Step [151/735], Loss: 0.6993\n",
      "Epoch [9/50], Step [152/735], Loss: 0.8711\n",
      "Epoch [9/50], Step [153/735], Loss: 0.3432\n",
      "Epoch [9/50], Step [154/735], Loss: 0.2108\n",
      "Epoch [9/50], Step [155/735], Loss: 0.6570\n",
      "Epoch [9/50], Step [156/735], Loss: 1.1371\n",
      "Epoch [9/50], Step [157/735], Loss: 0.4231\n",
      "Epoch [9/50], Step [158/735], Loss: 0.4531\n",
      "Epoch [9/50], Step [159/735], Loss: 0.1996\n",
      "Epoch [9/50], Step [160/735], Loss: 0.4023\n",
      "Epoch [9/50], Step [161/735], Loss: 0.2900\n",
      "Epoch [9/50], Step [162/735], Loss: 1.0674\n",
      "Epoch [9/50], Step [163/735], Loss: 1.9740\n",
      "Epoch [9/50], Step [164/735], Loss: 0.2546\n",
      "Epoch [9/50], Step [165/735], Loss: 0.2313\n",
      "Epoch [9/50], Step [166/735], Loss: 0.3496\n",
      "Epoch [9/50], Step [167/735], Loss: 0.6126\n",
      "Epoch [9/50], Step [168/735], Loss: 0.2878\n",
      "Epoch [9/50], Step [169/735], Loss: 0.2033\n",
      "Epoch [9/50], Step [170/735], Loss: 0.2410\n",
      "Epoch [9/50], Step [171/735], Loss: 0.2845\n",
      "Epoch [9/50], Step [172/735], Loss: 0.1582\n",
      "Epoch [9/50], Step [173/735], Loss: 1.1027\n",
      "Epoch [9/50], Step [174/735], Loss: 0.4761\n",
      "Epoch [9/50], Step [175/735], Loss: 0.2017\n",
      "Epoch [9/50], Step [176/735], Loss: 1.2701\n",
      "Epoch [9/50], Step [177/735], Loss: 0.5626\n",
      "Epoch [9/50], Step [178/735], Loss: 0.2799\n",
      "Epoch [9/50], Step [179/735], Loss: 0.6093\n",
      "Epoch [9/50], Step [180/735], Loss: 0.4001\n",
      "Epoch [9/50], Step [181/735], Loss: 0.6029\n",
      "Epoch [9/50], Step [182/735], Loss: 0.4026\n",
      "Epoch [9/50], Step [183/735], Loss: 0.4510\n",
      "Epoch [9/50], Step [184/735], Loss: 0.0924\n",
      "Epoch [9/50], Step [185/735], Loss: 0.5551\n",
      "Epoch [9/50], Step [186/735], Loss: 0.1174\n",
      "Epoch [9/50], Step [187/735], Loss: 1.0158\n",
      "Epoch [9/50], Step [188/735], Loss: 0.2936\n",
      "Epoch [9/50], Step [189/735], Loss: 0.3192\n",
      "Epoch [9/50], Step [190/735], Loss: 0.3012\n",
      "Epoch [9/50], Step [191/735], Loss: 0.2354\n",
      "Epoch [9/50], Step [192/735], Loss: 0.9573\n",
      "Epoch [9/50], Step [193/735], Loss: 0.2713\n",
      "Epoch [9/50], Step [194/735], Loss: 0.2203\n",
      "Epoch [9/50], Step [195/735], Loss: 0.2933\n",
      "Epoch [9/50], Step [196/735], Loss: 0.3390\n",
      "Epoch [9/50], Step [197/735], Loss: 0.3180\n",
      "Epoch [9/50], Step [198/735], Loss: 0.8027\n",
      "Epoch [9/50], Step [199/735], Loss: 0.3413\n",
      "Epoch [9/50], Step [200/735], Loss: 0.3363\n",
      "Epoch [9/50], Step [201/735], Loss: 0.5088\n",
      "Epoch [9/50], Step [202/735], Loss: 0.7000\n",
      "Epoch [9/50], Step [203/735], Loss: 0.4879\n",
      "Epoch [9/50], Step [204/735], Loss: 0.3710\n",
      "Epoch [9/50], Step [205/735], Loss: 0.4121\n",
      "Epoch [9/50], Step [206/735], Loss: 0.6697\n",
      "Epoch [9/50], Step [207/735], Loss: 0.1490\n",
      "Epoch [9/50], Step [208/735], Loss: 0.2600\n",
      "Epoch [9/50], Step [209/735], Loss: 0.0661\n",
      "Epoch [9/50], Step [210/735], Loss: 0.7526\n",
      "Epoch [9/50], Step [211/735], Loss: 0.4643\n",
      "Epoch [9/50], Step [212/735], Loss: 0.2035\n",
      "Epoch [9/50], Step [213/735], Loss: 0.5860\n",
      "Epoch [9/50], Step [214/735], Loss: 0.1363\n",
      "Epoch [9/50], Step [215/735], Loss: 0.1366\n",
      "Epoch [9/50], Step [216/735], Loss: 0.3504\n",
      "Epoch [9/50], Step [217/735], Loss: 0.2919\n",
      "Epoch [9/50], Step [218/735], Loss: 0.3182\n",
      "Epoch [9/50], Step [219/735], Loss: 0.8351\n",
      "Epoch [9/50], Step [220/735], Loss: 0.4813\n",
      "Epoch [9/50], Step [221/735], Loss: 0.3123\n",
      "Epoch [9/50], Step [222/735], Loss: 0.2923\n",
      "Epoch [9/50], Step [223/735], Loss: 0.8164\n",
      "Epoch [9/50], Step [224/735], Loss: 0.2317\n",
      "Epoch [9/50], Step [225/735], Loss: 0.2513\n",
      "Epoch [9/50], Step [226/735], Loss: 0.3212\n",
      "Epoch [9/50], Step [227/735], Loss: 0.1349\n",
      "Epoch [9/50], Step [228/735], Loss: 2.0819\n",
      "Epoch [9/50], Step [229/735], Loss: 0.8093\n",
      "Epoch [9/50], Step [230/735], Loss: 0.2693\n",
      "Epoch [9/50], Step [231/735], Loss: 0.9567\n",
      "Epoch [9/50], Step [232/735], Loss: 0.3427\n",
      "Epoch [9/50], Step [233/735], Loss: 0.4831\n",
      "Epoch [9/50], Step [234/735], Loss: 0.3763\n",
      "Epoch [9/50], Step [235/735], Loss: 0.6879\n",
      "Epoch [9/50], Step [236/735], Loss: 0.4725\n",
      "Epoch [9/50], Step [237/735], Loss: 0.2084\n",
      "Epoch [9/50], Step [238/735], Loss: 0.3303\n",
      "Epoch [9/50], Step [239/735], Loss: 0.1577\n",
      "Epoch [9/50], Step [240/735], Loss: 0.3864\n",
      "Epoch [9/50], Step [241/735], Loss: 0.2732\n",
      "Epoch [9/50], Step [242/735], Loss: 0.2459\n",
      "Epoch [9/50], Step [243/735], Loss: 0.1732\n",
      "Epoch [9/50], Step [244/735], Loss: 0.6429\n",
      "Epoch [9/50], Step [245/735], Loss: 0.2554\n",
      "Epoch [9/50], Step [246/735], Loss: 0.5093\n",
      "Epoch [9/50], Step [247/735], Loss: 0.5945\n",
      "Epoch [9/50], Step [248/735], Loss: 0.2050\n",
      "Epoch [9/50], Step [249/735], Loss: 0.1613\n",
      "Epoch [9/50], Step [250/735], Loss: 0.4011\n",
      "Epoch [9/50], Step [251/735], Loss: 0.4269\n",
      "Epoch [9/50], Step [252/735], Loss: 0.4969\n",
      "Epoch [9/50], Step [253/735], Loss: 0.1051\n",
      "Epoch [9/50], Step [254/735], Loss: 0.6343\n",
      "Epoch [9/50], Step [255/735], Loss: 0.3178\n",
      "Epoch [9/50], Step [256/735], Loss: 0.2877\n",
      "Epoch [9/50], Step [257/735], Loss: 0.9489\n",
      "Epoch [9/50], Step [258/735], Loss: 0.1686\n",
      "Epoch [9/50], Step [259/735], Loss: 0.6378\n",
      "Epoch [9/50], Step [260/735], Loss: 0.2893\n",
      "Epoch [9/50], Step [261/735], Loss: 0.2381\n",
      "Epoch [9/50], Step [262/735], Loss: 0.3209\n",
      "Epoch [9/50], Step [263/735], Loss: 2.5197\n",
      "Epoch [9/50], Step [264/735], Loss: 0.1384\n",
      "Epoch [9/50], Step [265/735], Loss: 0.6464\n",
      "Epoch [9/50], Step [266/735], Loss: 0.8460\n",
      "Epoch [9/50], Step [267/735], Loss: 0.5264\n",
      "Epoch [9/50], Step [268/735], Loss: 0.4002\n",
      "Epoch [9/50], Step [269/735], Loss: 0.5993\n",
      "Epoch [9/50], Step [270/735], Loss: 0.3154\n",
      "Epoch [9/50], Step [271/735], Loss: 0.9206\n",
      "Epoch [9/50], Step [272/735], Loss: 0.3541\n",
      "Epoch [9/50], Step [273/735], Loss: 1.3332\n",
      "Epoch [9/50], Step [274/735], Loss: 1.0753\n",
      "Epoch [9/50], Step [275/735], Loss: 0.7253\n",
      "Epoch [9/50], Step [276/735], Loss: 1.2380\n",
      "Epoch [9/50], Step [277/735], Loss: 0.6823\n",
      "Epoch [9/50], Step [278/735], Loss: 0.9306\n",
      "Epoch [9/50], Step [279/735], Loss: 0.1910\n",
      "Epoch [9/50], Step [280/735], Loss: 0.8774\n",
      "Epoch [9/50], Step [281/735], Loss: 0.7751\n",
      "Epoch [9/50], Step [282/735], Loss: 0.8316\n",
      "Epoch [9/50], Step [283/735], Loss: 0.2649\n",
      "Epoch [9/50], Step [284/735], Loss: 0.6437\n",
      "Epoch [9/50], Step [285/735], Loss: 0.8116\n",
      "Epoch [9/50], Step [286/735], Loss: 0.1560\n",
      "Epoch [9/50], Step [287/735], Loss: 0.1631\n",
      "Epoch [9/50], Step [288/735], Loss: 0.8790\n",
      "Epoch [9/50], Step [289/735], Loss: 0.9418\n",
      "Epoch [9/50], Step [290/735], Loss: 0.2713\n",
      "Epoch [9/50], Step [291/735], Loss: 0.7322\n",
      "Epoch [9/50], Step [292/735], Loss: 0.2827\n",
      "Epoch [9/50], Step [293/735], Loss: 0.3346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Step [294/735], Loss: 0.1985\n",
      "Epoch [9/50], Step [295/735], Loss: 0.6484\n",
      "Epoch [9/50], Step [296/735], Loss: 0.4181\n",
      "Epoch [9/50], Step [297/735], Loss: 0.6238\n",
      "Epoch [9/50], Step [298/735], Loss: 0.1522\n",
      "Epoch [9/50], Step [299/735], Loss: 0.4057\n",
      "Epoch [9/50], Step [300/735], Loss: 0.2374\n",
      "Epoch [9/50], Step [301/735], Loss: 0.4472\n",
      "Epoch [9/50], Step [302/735], Loss: 0.3458\n",
      "Epoch [9/50], Step [303/735], Loss: 0.8469\n",
      "Epoch [9/50], Step [304/735], Loss: 5.3777\n",
      "Epoch [9/50], Step [305/735], Loss: 0.1670\n",
      "Epoch [9/50], Step [306/735], Loss: 0.5528\n",
      "Epoch [9/50], Step [307/735], Loss: 0.6745\n",
      "Epoch [9/50], Step [308/735], Loss: 0.1929\n",
      "Epoch [9/50], Step [309/735], Loss: 0.3470\n",
      "Epoch [9/50], Step [310/735], Loss: 0.5754\n",
      "Epoch [9/50], Step [311/735], Loss: 0.8525\n",
      "Epoch [9/50], Step [312/735], Loss: 0.3948\n",
      "Epoch [9/50], Step [313/735], Loss: 0.4605\n",
      "Epoch [9/50], Step [314/735], Loss: 1.4044\n",
      "Epoch [9/50], Step [315/735], Loss: 0.0949\n",
      "Epoch [9/50], Step [316/735], Loss: 2.2613\n",
      "Epoch [9/50], Step [317/735], Loss: 0.4619\n",
      "Epoch [9/50], Step [318/735], Loss: 0.3225\n",
      "Epoch [9/50], Step [319/735], Loss: 5.1207\n",
      "Epoch [9/50], Step [320/735], Loss: 0.7583\n",
      "Epoch [9/50], Step [321/735], Loss: 0.3226\n",
      "Epoch [9/50], Step [322/735], Loss: 0.2149\n",
      "Epoch [9/50], Step [323/735], Loss: 0.8959\n",
      "Epoch [9/50], Step [324/735], Loss: 0.3298\n",
      "Epoch [9/50], Step [325/735], Loss: 1.3828\n",
      "Epoch [9/50], Step [326/735], Loss: 0.5214\n",
      "Epoch [9/50], Step [327/735], Loss: 1.0429\n",
      "Epoch [9/50], Step [328/735], Loss: 0.1238\n",
      "Epoch [9/50], Step [329/735], Loss: 0.8392\n",
      "Epoch [9/50], Step [330/735], Loss: 0.7094\n",
      "Epoch [9/50], Step [331/735], Loss: 0.5160\n",
      "Epoch [9/50], Step [332/735], Loss: 0.1014\n",
      "Epoch [9/50], Step [333/735], Loss: 0.3598\n",
      "Epoch [9/50], Step [334/735], Loss: 0.0820\n",
      "Epoch [9/50], Step [335/735], Loss: 0.3185\n",
      "Epoch [9/50], Step [336/735], Loss: 0.2160\n",
      "Epoch [9/50], Step [337/735], Loss: 0.2808\n",
      "Epoch [9/50], Step [338/735], Loss: 0.4010\n",
      "Epoch [9/50], Step [339/735], Loss: 0.8988\n",
      "Epoch [9/50], Step [340/735], Loss: 0.3385\n",
      "Epoch [9/50], Step [341/735], Loss: 0.1292\n",
      "Epoch [9/50], Step [342/735], Loss: 0.2430\n",
      "Epoch [9/50], Step [343/735], Loss: 1.1853\n",
      "Epoch [9/50], Step [344/735], Loss: 1.7381\n",
      "Epoch [9/50], Step [345/735], Loss: 0.2386\n",
      "Epoch [9/50], Step [346/735], Loss: 0.1526\n",
      "Epoch [9/50], Step [347/735], Loss: 0.1789\n",
      "Epoch [9/50], Step [348/735], Loss: 0.6039\n",
      "Epoch [9/50], Step [349/735], Loss: 0.5521\n",
      "Epoch [9/50], Step [350/735], Loss: 0.0715\n",
      "Epoch [9/50], Step [351/735], Loss: 0.1239\n",
      "Epoch [9/50], Step [352/735], Loss: 0.0835\n",
      "Epoch [9/50], Step [353/735], Loss: 1.7181\n",
      "Epoch [9/50], Step [354/735], Loss: 1.5854\n",
      "Epoch [9/50], Step [355/735], Loss: 0.3376\n",
      "Epoch [9/50], Step [356/735], Loss: 0.7645\n",
      "Epoch [9/50], Step [357/735], Loss: 0.3931\n",
      "Epoch [9/50], Step [358/735], Loss: 0.2394\n",
      "Epoch [9/50], Step [359/735], Loss: 0.4354\n",
      "Epoch [9/50], Step [360/735], Loss: 0.4073\n",
      "Epoch [9/50], Step [361/735], Loss: 0.8646\n",
      "Epoch [9/50], Step [362/735], Loss: 0.3226\n",
      "Epoch [9/50], Step [363/735], Loss: 0.1992\n",
      "Epoch [9/50], Step [364/735], Loss: 0.2354\n",
      "Epoch [9/50], Step [365/735], Loss: 1.3226\n",
      "Epoch [9/50], Step [366/735], Loss: 0.3288\n",
      "Epoch [9/50], Step [367/735], Loss: 0.1296\n",
      "Epoch [9/50], Step [368/735], Loss: 0.7205\n",
      "Epoch [9/50], Step [369/735], Loss: 0.1089\n",
      "Epoch [9/50], Step [370/735], Loss: 0.5272\n",
      "Epoch [9/50], Step [371/735], Loss: 2.1269\n",
      "Epoch [9/50], Step [372/735], Loss: 0.1775\n",
      "Epoch [9/50], Step [373/735], Loss: 0.2806\n",
      "Epoch [9/50], Step [374/735], Loss: 0.1578\n",
      "Epoch [9/50], Step [375/735], Loss: 0.1545\n",
      "Epoch [9/50], Step [376/735], Loss: 2.5888\n",
      "Epoch [9/50], Step [377/735], Loss: 1.1010\n",
      "Epoch [9/50], Step [378/735], Loss: 0.2277\n",
      "Epoch [9/50], Step [379/735], Loss: 0.2027\n",
      "Epoch [9/50], Step [380/735], Loss: 0.9666\n",
      "Epoch [9/50], Step [381/735], Loss: 0.1026\n",
      "Epoch [9/50], Step [382/735], Loss: 0.3815\n",
      "Epoch [9/50], Step [383/735], Loss: 0.0797\n",
      "Epoch [9/50], Step [384/735], Loss: 0.5483\n",
      "Epoch [9/50], Step [385/735], Loss: 1.8284\n",
      "Epoch [9/50], Step [386/735], Loss: 0.1434\n",
      "Epoch [9/50], Step [387/735], Loss: 0.4712\n",
      "Epoch [9/50], Step [388/735], Loss: 0.6169\n",
      "Epoch [9/50], Step [389/735], Loss: 0.8038\n",
      "Epoch [9/50], Step [390/735], Loss: 0.3704\n",
      "Epoch [9/50], Step [391/735], Loss: 0.4560\n",
      "Epoch [9/50], Step [392/735], Loss: 0.7776\n",
      "Epoch [9/50], Step [393/735], Loss: 0.5753\n",
      "Epoch [9/50], Step [394/735], Loss: 0.1245\n",
      "Epoch [9/50], Step [395/735], Loss: 0.4113\n",
      "Epoch [9/50], Step [396/735], Loss: 0.2593\n",
      "Epoch [9/50], Step [397/735], Loss: 0.0790\n",
      "Epoch [9/50], Step [398/735], Loss: 0.2067\n",
      "Epoch [9/50], Step [399/735], Loss: 0.6203\n",
      "Epoch [9/50], Step [400/735], Loss: 0.7182\n",
      "Epoch [9/50], Step [401/735], Loss: 0.4273\n",
      "Epoch [9/50], Step [402/735], Loss: 0.4145\n",
      "Epoch [9/50], Step [403/735], Loss: 0.7319\n",
      "Epoch [9/50], Step [404/735], Loss: 0.2035\n",
      "Epoch [9/50], Step [405/735], Loss: 0.2914\n",
      "Epoch [9/50], Step [406/735], Loss: 0.9028\n",
      "Epoch [9/50], Step [407/735], Loss: 0.6036\n",
      "Epoch [9/50], Step [408/735], Loss: 0.3625\n",
      "Epoch [9/50], Step [409/735], Loss: 0.8582\n",
      "Epoch [9/50], Step [410/735], Loss: 1.5997\n",
      "Epoch [9/50], Step [411/735], Loss: 0.2039\n",
      "Epoch [9/50], Step [412/735], Loss: 0.3799\n",
      "Epoch [9/50], Step [413/735], Loss: 1.3046\n",
      "Epoch [9/50], Step [414/735], Loss: 1.0679\n",
      "Epoch [9/50], Step [415/735], Loss: 0.2368\n",
      "Epoch [9/50], Step [416/735], Loss: 0.3356\n",
      "Epoch [9/50], Step [417/735], Loss: 1.0475\n",
      "Epoch [9/50], Step [418/735], Loss: 1.0896\n",
      "Epoch [9/50], Step [419/735], Loss: 0.3550\n",
      "Epoch [9/50], Step [420/735], Loss: 1.2841\n",
      "Epoch [9/50], Step [421/735], Loss: 0.0542\n",
      "Epoch [9/50], Step [422/735], Loss: 0.5561\n",
      "Epoch [9/50], Step [423/735], Loss: 0.9416\n",
      "Epoch [9/50], Step [424/735], Loss: 0.3163\n",
      "Epoch [9/50], Step [425/735], Loss: 0.2456\n",
      "Epoch [9/50], Step [426/735], Loss: 0.2947\n",
      "Epoch [9/50], Step [427/735], Loss: 0.8373\n",
      "Epoch [9/50], Step [428/735], Loss: 0.5324\n",
      "Epoch [9/50], Step [429/735], Loss: 0.2669\n",
      "Epoch [9/50], Step [430/735], Loss: 0.2302\n",
      "Epoch [9/50], Step [431/735], Loss: 0.5272\n",
      "Epoch [9/50], Step [432/735], Loss: 0.1283\n",
      "Epoch [9/50], Step [433/735], Loss: 0.4720\n",
      "Epoch [9/50], Step [434/735], Loss: 0.1595\n",
      "Epoch [9/50], Step [435/735], Loss: 0.3465\n",
      "Epoch [9/50], Step [436/735], Loss: 0.3433\n",
      "Epoch [9/50], Step [437/735], Loss: 0.5853\n",
      "Epoch [9/50], Step [438/735], Loss: 0.3438\n",
      "Epoch [9/50], Step [439/735], Loss: 0.2188\n",
      "Epoch [9/50], Step [440/735], Loss: 0.6589\n",
      "Epoch [9/50], Step [441/735], Loss: 0.6276\n",
      "Epoch [9/50], Step [442/735], Loss: 0.2548\n",
      "Epoch [9/50], Step [443/735], Loss: 0.2257\n",
      "Epoch [9/50], Step [444/735], Loss: 0.6363\n",
      "Epoch [9/50], Step [445/735], Loss: 0.2896\n",
      "Epoch [9/50], Step [446/735], Loss: 1.1181\n",
      "Epoch [9/50], Step [447/735], Loss: 0.3636\n",
      "Epoch [9/50], Step [448/735], Loss: 0.8659\n",
      "Epoch [9/50], Step [449/735], Loss: 0.0562\n",
      "Epoch [9/50], Step [450/735], Loss: 0.3760\n",
      "Epoch [9/50], Step [451/735], Loss: 0.1699\n",
      "Epoch [9/50], Step [452/735], Loss: 1.9175\n",
      "Epoch [9/50], Step [453/735], Loss: 0.1415\n",
      "Epoch [9/50], Step [454/735], Loss: 0.1774\n",
      "Epoch [9/50], Step [455/735], Loss: 0.2223\n",
      "Epoch [9/50], Step [456/735], Loss: 0.2121\n",
      "Epoch [9/50], Step [457/735], Loss: 1.0268\n",
      "Epoch [9/50], Step [458/735], Loss: 0.2133\n",
      "Epoch [9/50], Step [459/735], Loss: 0.3770\n",
      "Epoch [9/50], Step [460/735], Loss: 0.1356\n",
      "Epoch [9/50], Step [461/735], Loss: 0.5626\n",
      "Epoch [9/50], Step [462/735], Loss: 0.2307\n",
      "Epoch [9/50], Step [463/735], Loss: 0.5604\n",
      "Epoch [9/50], Step [464/735], Loss: 0.2577\n",
      "Epoch [9/50], Step [465/735], Loss: 0.4592\n",
      "Epoch [9/50], Step [466/735], Loss: 0.4281\n",
      "Epoch [9/50], Step [467/735], Loss: 0.2503\n",
      "Epoch [9/50], Step [468/735], Loss: 0.2148\n",
      "Epoch [9/50], Step [469/735], Loss: 5.9109\n",
      "Epoch [9/50], Step [470/735], Loss: 0.2599\n",
      "Epoch [9/50], Step [471/735], Loss: 0.3128\n",
      "Epoch [9/50], Step [472/735], Loss: 0.1041\n",
      "Epoch [9/50], Step [473/735], Loss: 0.5965\n",
      "Epoch [9/50], Step [474/735], Loss: 0.2426\n",
      "Epoch [9/50], Step [475/735], Loss: 0.5451\n",
      "Epoch [9/50], Step [476/735], Loss: 0.2696\n",
      "Epoch [9/50], Step [477/735], Loss: 2.1530\n",
      "Epoch [9/50], Step [478/735], Loss: 0.1903\n",
      "Epoch [9/50], Step [479/735], Loss: 1.6719\n",
      "Epoch [9/50], Step [480/735], Loss: 0.5367\n",
      "Epoch [9/50], Step [481/735], Loss: 0.2234\n",
      "Epoch [9/50], Step [482/735], Loss: 0.1914\n",
      "Epoch [9/50], Step [483/735], Loss: 0.2598\n",
      "Epoch [9/50], Step [484/735], Loss: 1.2490\n",
      "Epoch [9/50], Step [485/735], Loss: 0.8047\n",
      "Epoch [9/50], Step [486/735], Loss: 0.7194\n",
      "Epoch [9/50], Step [487/735], Loss: 0.3684\n",
      "Epoch [9/50], Step [488/735], Loss: 0.1737\n",
      "Epoch [9/50], Step [489/735], Loss: 0.9750\n",
      "Epoch [9/50], Step [490/735], Loss: 0.1918\n",
      "Epoch [9/50], Step [491/735], Loss: 0.1917\n",
      "Epoch [9/50], Step [492/735], Loss: 0.5275\n",
      "Epoch [9/50], Step [493/735], Loss: 0.3387\n",
      "Epoch [9/50], Step [494/735], Loss: 0.2015\n",
      "Epoch [9/50], Step [495/735], Loss: 0.4414\n",
      "Epoch [9/50], Step [496/735], Loss: 0.4504\n",
      "Epoch [9/50], Step [497/735], Loss: 0.4652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Step [498/735], Loss: 0.2653\n",
      "Epoch [9/50], Step [499/735], Loss: 0.2233\n",
      "Epoch [9/50], Step [500/735], Loss: 0.4265\n",
      "Epoch [9/50], Step [501/735], Loss: 0.3669\n",
      "Epoch [9/50], Step [502/735], Loss: 0.7152\n",
      "Epoch [9/50], Step [503/735], Loss: 0.2607\n",
      "Epoch [9/50], Step [504/735], Loss: 0.4459\n",
      "Epoch [9/50], Step [505/735], Loss: 0.2535\n",
      "Epoch [9/50], Step [506/735], Loss: 0.4188\n",
      "Epoch [9/50], Step [507/735], Loss: 0.6296\n",
      "Epoch [9/50], Step [508/735], Loss: 0.4855\n",
      "Epoch [9/50], Step [509/735], Loss: 0.0785\n",
      "Epoch [9/50], Step [510/735], Loss: 0.3167\n",
      "Epoch [9/50], Step [511/735], Loss: 0.0854\n",
      "Epoch [9/50], Step [512/735], Loss: 0.4522\n",
      "Epoch [9/50], Step [513/735], Loss: 0.2341\n",
      "Epoch [9/50], Step [514/735], Loss: 0.4294\n",
      "Epoch [9/50], Step [515/735], Loss: 0.2678\n",
      "Epoch [9/50], Step [516/735], Loss: 0.1370\n",
      "Epoch [9/50], Step [517/735], Loss: 0.4720\n",
      "Epoch [9/50], Step [518/735], Loss: 0.5185\n",
      "Epoch [9/50], Step [519/735], Loss: 0.1886\n",
      "Epoch [9/50], Step [520/735], Loss: 0.8618\n",
      "Epoch [9/50], Step [521/735], Loss: 0.0776\n",
      "Epoch [9/50], Step [522/735], Loss: 0.4734\n",
      "Epoch [9/50], Step [523/735], Loss: 0.5148\n",
      "Epoch [9/50], Step [524/735], Loss: 0.5462\n",
      "Epoch [9/50], Step [525/735], Loss: 0.3942\n",
      "Epoch [9/50], Step [526/735], Loss: 0.2405\n",
      "Epoch [9/50], Step [527/735], Loss: 1.1988\n",
      "Epoch [9/50], Step [528/735], Loss: 0.1400\n",
      "Epoch [9/50], Step [529/735], Loss: 0.2331\n",
      "Epoch [9/50], Step [530/735], Loss: 0.4422\n",
      "Epoch [9/50], Step [531/735], Loss: 0.3694\n",
      "Epoch [9/50], Step [532/735], Loss: 0.3022\n",
      "Epoch [9/50], Step [533/735], Loss: 0.1710\n",
      "Epoch [9/50], Step [534/735], Loss: 5.5221\n",
      "Epoch [9/50], Step [535/735], Loss: 0.5911\n",
      "Epoch [9/50], Step [536/735], Loss: 0.3307\n",
      "Epoch [9/50], Step [537/735], Loss: 0.1788\n",
      "Epoch [9/50], Step [538/735], Loss: 0.4596\n",
      "Epoch [9/50], Step [539/735], Loss: 0.2536\n",
      "Epoch [9/50], Step [540/735], Loss: 0.4273\n",
      "Epoch [9/50], Step [541/735], Loss: 0.3352\n",
      "Epoch [9/50], Step [542/735], Loss: 1.2594\n",
      "Epoch [9/50], Step [543/735], Loss: 0.2508\n",
      "Epoch [9/50], Step [544/735], Loss: 0.8674\n",
      "Epoch [9/50], Step [545/735], Loss: 0.1013\n",
      "Epoch [9/50], Step [546/735], Loss: 0.8669\n",
      "Epoch [9/50], Step [547/735], Loss: 0.5820\n",
      "Epoch [9/50], Step [548/735], Loss: 0.2016\n",
      "Epoch [9/50], Step [549/735], Loss: 0.7142\n",
      "Epoch [9/50], Step [550/735], Loss: 0.3911\n",
      "Epoch [9/50], Step [551/735], Loss: 0.1478\n",
      "Epoch [9/50], Step [552/735], Loss: 0.1695\n",
      "Epoch [9/50], Step [553/735], Loss: 0.8719\n",
      "Epoch [9/50], Step [554/735], Loss: 0.7277\n",
      "Epoch [9/50], Step [555/735], Loss: 0.6218\n",
      "Epoch [9/50], Step [556/735], Loss: 0.5524\n",
      "Epoch [9/50], Step [557/735], Loss: 0.2100\n",
      "Epoch [9/50], Step [558/735], Loss: 0.4431\n",
      "Epoch [9/50], Step [559/735], Loss: 1.4279\n",
      "Epoch [9/50], Step [560/735], Loss: 0.7730\n",
      "Epoch [9/50], Step [561/735], Loss: 0.2106\n",
      "Epoch [9/50], Step [562/735], Loss: 0.0914\n",
      "Epoch [9/50], Step [563/735], Loss: 0.4450\n",
      "Epoch [9/50], Step [564/735], Loss: 0.1427\n",
      "Epoch [9/50], Step [565/735], Loss: 0.2738\n",
      "Epoch [9/50], Step [566/735], Loss: 0.5823\n",
      "Epoch [9/50], Step [567/735], Loss: 0.1534\n",
      "Epoch [9/50], Step [568/735], Loss: 1.2324\n",
      "Epoch [9/50], Step [569/735], Loss: 0.1700\n",
      "Epoch [9/50], Step [570/735], Loss: 0.6055\n",
      "Epoch [9/50], Step [571/735], Loss: 0.3320\n",
      "Epoch [9/50], Step [572/735], Loss: 0.5063\n",
      "Epoch [9/50], Step [573/735], Loss: 0.9532\n",
      "Epoch [9/50], Step [574/735], Loss: 0.2687\n",
      "Epoch [9/50], Step [575/735], Loss: 0.1472\n",
      "Epoch [9/50], Step [576/735], Loss: 0.2213\n",
      "Epoch [9/50], Step [577/735], Loss: 0.7575\n",
      "Epoch [9/50], Step [578/735], Loss: 0.4060\n",
      "Epoch [9/50], Step [579/735], Loss: 0.3070\n",
      "Epoch [9/50], Step [580/735], Loss: 0.7778\n",
      "Epoch [9/50], Step [581/735], Loss: 0.7987\n",
      "Epoch [9/50], Step [582/735], Loss: 0.1820\n",
      "Epoch [9/50], Step [583/735], Loss: 0.4786\n",
      "Epoch [9/50], Step [584/735], Loss: 0.6035\n",
      "Epoch [9/50], Step [585/735], Loss: 0.6711\n",
      "Epoch [9/50], Step [586/735], Loss: 0.4972\n",
      "Epoch [9/50], Step [587/735], Loss: 0.4808\n",
      "Epoch [9/50], Step [588/735], Loss: 0.5205\n",
      "Epoch [9/50], Step [589/735], Loss: 0.2356\n",
      "Epoch [9/50], Step [590/735], Loss: 0.9157\n",
      "Epoch [9/50], Step [591/735], Loss: 0.2137\n",
      "Epoch [9/50], Step [592/735], Loss: 0.6328\n",
      "Epoch [9/50], Step [593/735], Loss: 0.1979\n",
      "Epoch [9/50], Step [594/735], Loss: 0.7592\n",
      "Epoch [9/50], Step [595/735], Loss: 0.2089\n",
      "Epoch [9/50], Step [596/735], Loss: 0.3869\n",
      "Epoch [9/50], Step [597/735], Loss: 1.6581\n",
      "Epoch [9/50], Step [598/735], Loss: 0.2081\n",
      "Epoch [9/50], Step [599/735], Loss: 0.0781\n",
      "Epoch [9/50], Step [600/735], Loss: 0.5222\n",
      "Epoch [9/50], Step [601/735], Loss: 0.1739\n",
      "Epoch [9/50], Step [602/735], Loss: 0.0729\n",
      "Epoch [9/50], Step [603/735], Loss: 0.5315\n",
      "Epoch [9/50], Step [604/735], Loss: 0.2094\n",
      "Epoch [9/50], Step [605/735], Loss: 0.2854\n",
      "Epoch [9/50], Step [606/735], Loss: 0.4074\n",
      "Epoch [9/50], Step [607/735], Loss: 0.2391\n",
      "Epoch [9/50], Step [608/735], Loss: 0.4438\n",
      "Epoch [9/50], Step [609/735], Loss: 0.4081\n",
      "Epoch [9/50], Step [610/735], Loss: 0.3153\n",
      "Epoch [9/50], Step [611/735], Loss: 0.6497\n",
      "Epoch [9/50], Step [612/735], Loss: 1.1307\n",
      "Epoch [9/50], Step [613/735], Loss: 0.2642\n",
      "Epoch [9/50], Step [614/735], Loss: 0.7059\n",
      "Epoch [9/50], Step [615/735], Loss: 0.8485\n",
      "Epoch [9/50], Step [616/735], Loss: 0.3328\n",
      "Epoch [9/50], Step [617/735], Loss: 0.4431\n",
      "Epoch [9/50], Step [618/735], Loss: 1.4413\n",
      "Epoch [9/50], Step [619/735], Loss: 0.5329\n",
      "Epoch [9/50], Step [620/735], Loss: 0.3861\n",
      "Epoch [9/50], Step [621/735], Loss: 0.1530\n",
      "Epoch [9/50], Step [622/735], Loss: 0.4722\n",
      "Epoch [9/50], Step [623/735], Loss: 0.6065\n",
      "Epoch [9/50], Step [624/735], Loss: 0.2845\n",
      "Epoch [9/50], Step [625/735], Loss: 0.6111\n",
      "Epoch [9/50], Step [626/735], Loss: 0.4457\n",
      "Epoch [9/50], Step [627/735], Loss: 0.5096\n",
      "Epoch [9/50], Step [628/735], Loss: 0.1576\n",
      "Epoch [9/50], Step [629/735], Loss: 0.3725\n",
      "Epoch [9/50], Step [630/735], Loss: 0.3358\n",
      "Epoch [9/50], Step [631/735], Loss: 0.2441\n",
      "Epoch [9/50], Step [632/735], Loss: 0.4212\n",
      "Epoch [9/50], Step [633/735], Loss: 0.2300\n",
      "Epoch [9/50], Step [634/735], Loss: 0.9806\n",
      "Epoch [9/50], Step [635/735], Loss: 0.2450\n",
      "Epoch [9/50], Step [636/735], Loss: 0.3733\n",
      "Epoch [9/50], Step [637/735], Loss: 0.7947\n",
      "Epoch [9/50], Step [638/735], Loss: 0.2870\n",
      "Epoch [9/50], Step [639/735], Loss: 0.2207\n",
      "Epoch [9/50], Step [640/735], Loss: 0.2343\n",
      "Epoch [9/50], Step [641/735], Loss: 0.2704\n",
      "Epoch [9/50], Step [642/735], Loss: 0.1904\n",
      "Epoch [9/50], Step [643/735], Loss: 1.1389\n",
      "Epoch [9/50], Step [644/735], Loss: 0.1083\n",
      "Epoch [9/50], Step [645/735], Loss: 0.4945\n",
      "Epoch [9/50], Step [646/735], Loss: 2.1742\n",
      "Epoch [9/50], Step [647/735], Loss: 0.3187\n",
      "Epoch [9/50], Step [648/735], Loss: 0.2832\n",
      "Epoch [9/50], Step [649/735], Loss: 0.5326\n",
      "Epoch [9/50], Step [650/735], Loss: 0.2346\n",
      "Epoch [9/50], Step [651/735], Loss: 0.2854\n",
      "Epoch [9/50], Step [652/735], Loss: 0.6066\n",
      "Epoch [9/50], Step [653/735], Loss: 1.3058\n",
      "Epoch [9/50], Step [654/735], Loss: 0.2361\n",
      "Epoch [9/50], Step [655/735], Loss: 0.1447\n",
      "Epoch [9/50], Step [656/735], Loss: 0.1043\n",
      "Epoch [9/50], Step [657/735], Loss: 1.1285\n",
      "Epoch [9/50], Step [658/735], Loss: 0.7257\n",
      "Epoch [9/50], Step [659/735], Loss: 0.2402\n",
      "Epoch [9/50], Step [660/735], Loss: 1.0694\n",
      "Epoch [9/50], Step [661/735], Loss: 0.1499\n",
      "Epoch [9/50], Step [662/735], Loss: 0.4800\n",
      "Epoch [9/50], Step [663/735], Loss: 0.5968\n",
      "Epoch [9/50], Step [664/735], Loss: 0.3922\n",
      "Epoch [9/50], Step [665/735], Loss: 0.6325\n",
      "Epoch [9/50], Step [666/735], Loss: 0.3902\n",
      "Epoch [9/50], Step [667/735], Loss: 0.3250\n",
      "Epoch [9/50], Step [668/735], Loss: 0.2541\n",
      "Epoch [9/50], Step [669/735], Loss: 0.8552\n",
      "Epoch [9/50], Step [670/735], Loss: 0.2799\n",
      "Epoch [9/50], Step [671/735], Loss: 0.0885\n",
      "Epoch [9/50], Step [672/735], Loss: 0.3344\n",
      "Epoch [9/50], Step [673/735], Loss: 0.3388\n",
      "Epoch [9/50], Step [674/735], Loss: 0.8218\n",
      "Epoch [9/50], Step [675/735], Loss: 0.7981\n",
      "Epoch [9/50], Step [676/735], Loss: 0.4963\n",
      "Epoch [9/50], Step [677/735], Loss: 2.1117\n",
      "Epoch [9/50], Step [678/735], Loss: 0.2447\n",
      "Epoch [9/50], Step [679/735], Loss: 0.1193\n",
      "Epoch [9/50], Step [680/735], Loss: 0.2294\n",
      "Epoch [9/50], Step [681/735], Loss: 0.4070\n",
      "Epoch [9/50], Step [682/735], Loss: 0.5682\n",
      "Epoch [9/50], Step [683/735], Loss: 0.3826\n",
      "Epoch [9/50], Step [684/735], Loss: 0.2671\n",
      "Epoch [9/50], Step [685/735], Loss: 0.2801\n",
      "Epoch [9/50], Step [686/735], Loss: 0.4438\n",
      "Epoch [9/50], Step [687/735], Loss: 0.0932\n",
      "Epoch [9/50], Step [688/735], Loss: 0.2543\n",
      "Epoch [9/50], Step [689/735], Loss: 0.1014\n",
      "Epoch [9/50], Step [690/735], Loss: 0.6970\n",
      "Epoch [9/50], Step [691/735], Loss: 0.1756\n",
      "Epoch [9/50], Step [692/735], Loss: 0.7992\n",
      "Epoch [9/50], Step [693/735], Loss: 0.2931\n",
      "Epoch [9/50], Step [694/735], Loss: 0.4757\n",
      "Epoch [9/50], Step [695/735], Loss: 0.5626\n",
      "Epoch [9/50], Step [696/735], Loss: 0.1340\n",
      "Epoch [9/50], Step [697/735], Loss: 0.2623\n",
      "Epoch [9/50], Step [698/735], Loss: 0.1556\n",
      "Epoch [9/50], Step [699/735], Loss: 0.0942\n",
      "Epoch [9/50], Step [700/735], Loss: 0.3817\n",
      "Epoch [9/50], Step [701/735], Loss: 0.6423\n",
      "Epoch [9/50], Step [702/735], Loss: 0.2808\n",
      "Epoch [9/50], Step [703/735], Loss: 0.6556\n",
      "Epoch [9/50], Step [704/735], Loss: 0.2268\n",
      "Epoch [9/50], Step [705/735], Loss: 0.1395\n",
      "Epoch [9/50], Step [706/735], Loss: 0.1178\n",
      "Epoch [9/50], Step [707/735], Loss: 0.2686\n",
      "Epoch [9/50], Step [708/735], Loss: 0.4132\n",
      "Epoch [9/50], Step [709/735], Loss: 0.2828\n",
      "Epoch [9/50], Step [710/735], Loss: 0.3784\n",
      "Epoch [9/50], Step [711/735], Loss: 0.2986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Step [712/735], Loss: 0.1259\n",
      "Epoch [9/50], Step [713/735], Loss: 0.3610\n",
      "Epoch [9/50], Step [714/735], Loss: 0.4096\n",
      "Epoch [9/50], Step [715/735], Loss: 0.3180\n",
      "Epoch [9/50], Step [716/735], Loss: 0.3638\n",
      "Epoch [9/50], Step [717/735], Loss: 0.2021\n",
      "Epoch [9/50], Step [718/735], Loss: 0.4487\n",
      "Epoch [9/50], Step [719/735], Loss: 0.7826\n",
      "Epoch [9/50], Step [720/735], Loss: 0.5970\n",
      "Epoch [9/50], Step [721/735], Loss: 0.2348\n",
      "Epoch [9/50], Step [722/735], Loss: 0.6136\n",
      "Epoch [9/50], Step [723/735], Loss: 0.1403\n",
      "Epoch [9/50], Step [724/735], Loss: 0.4516\n",
      "Epoch [9/50], Step [725/735], Loss: 0.3789\n",
      "Epoch [9/50], Step [726/735], Loss: 0.2422\n",
      "Epoch [9/50], Step [727/735], Loss: 0.6754\n",
      "Epoch [9/50], Step [728/735], Loss: 0.4092\n",
      "Epoch [9/50], Step [729/735], Loss: 0.1673\n",
      "Epoch [9/50], Step [730/735], Loss: 0.1524\n",
      "Epoch [9/50], Step [731/735], Loss: 0.5041\n",
      "Epoch [9/50], Step [732/735], Loss: 0.6199\n",
      "Epoch [9/50], Step [733/735], Loss: 0.3364\n",
      "Epoch [9/50], Step [734/735], Loss: 0.3954\n",
      "Epoch [9/50], Step [735/735], Loss: 0.1625\n",
      "Epoch [10/50], Step [1/735], Loss: 0.7743\n",
      "Epoch [10/50], Step [2/735], Loss: 0.9617\n",
      "Epoch [10/50], Step [3/735], Loss: 0.0863\n",
      "Epoch [10/50], Step [4/735], Loss: 0.6127\n",
      "Epoch [10/50], Step [5/735], Loss: 0.2658\n",
      "Epoch [10/50], Step [6/735], Loss: 0.7737\n",
      "Epoch [10/50], Step [7/735], Loss: 0.1156\n",
      "Epoch [10/50], Step [8/735], Loss: 0.2548\n",
      "Epoch [10/50], Step [9/735], Loss: 0.2433\n",
      "Epoch [10/50], Step [10/735], Loss: 0.2136\n",
      "Epoch [10/50], Step [11/735], Loss: 1.1901\n",
      "Epoch [10/50], Step [12/735], Loss: 0.7714\n",
      "Epoch [10/50], Step [13/735], Loss: 0.4252\n",
      "Epoch [10/50], Step [14/735], Loss: 0.2110\n",
      "Epoch [10/50], Step [15/735], Loss: 0.4182\n",
      "Epoch [10/50], Step [16/735], Loss: 0.0982\n",
      "Epoch [10/50], Step [17/735], Loss: 0.8165\n",
      "Epoch [10/50], Step [18/735], Loss: 0.8618\n",
      "Epoch [10/50], Step [19/735], Loss: 0.4312\n",
      "Epoch [10/50], Step [20/735], Loss: 0.3389\n",
      "Epoch [10/50], Step [21/735], Loss: 0.2950\n",
      "Epoch [10/50], Step [22/735], Loss: 0.6188\n",
      "Epoch [10/50], Step [23/735], Loss: 0.3618\n",
      "Epoch [10/50], Step [24/735], Loss: 0.2958\n",
      "Epoch [10/50], Step [25/735], Loss: 0.2078\n",
      "Epoch [10/50], Step [26/735], Loss: 0.5732\n",
      "Epoch [10/50], Step [27/735], Loss: 0.6856\n",
      "Epoch [10/50], Step [28/735], Loss: 0.1996\n",
      "Epoch [10/50], Step [29/735], Loss: 0.6656\n",
      "Epoch [10/50], Step [30/735], Loss: 0.8349\n",
      "Epoch [10/50], Step [31/735], Loss: 0.9632\n",
      "Epoch [10/50], Step [32/735], Loss: 0.1614\n",
      "Epoch [10/50], Step [33/735], Loss: 0.5172\n",
      "Epoch [10/50], Step [34/735], Loss: 0.2091\n",
      "Epoch [10/50], Step [35/735], Loss: 0.8489\n",
      "Epoch [10/50], Step [36/735], Loss: 0.6299\n",
      "Epoch [10/50], Step [37/735], Loss: 0.5696\n",
      "Epoch [10/50], Step [38/735], Loss: 0.3493\n",
      "Epoch [10/50], Step [39/735], Loss: 0.0747\n",
      "Epoch [10/50], Step [40/735], Loss: 0.8326\n",
      "Epoch [10/50], Step [41/735], Loss: 1.1251\n",
      "Epoch [10/50], Step [42/735], Loss: 0.6095\n",
      "Epoch [10/50], Step [43/735], Loss: 0.2034\n",
      "Epoch [10/50], Step [44/735], Loss: 0.3384\n",
      "Epoch [10/50], Step [45/735], Loss: 0.7763\n",
      "Epoch [10/50], Step [46/735], Loss: 0.4909\n",
      "Epoch [10/50], Step [47/735], Loss: 0.3274\n",
      "Epoch [10/50], Step [48/735], Loss: 0.4345\n",
      "Epoch [10/50], Step [49/735], Loss: 0.3317\n",
      "Epoch [10/50], Step [50/735], Loss: 0.6751\n",
      "Epoch [10/50], Step [51/735], Loss: 0.3117\n",
      "Epoch [10/50], Step [52/735], Loss: 0.2078\n",
      "Epoch [10/50], Step [53/735], Loss: 0.8123\n",
      "Epoch [10/50], Step [54/735], Loss: 0.1136\n",
      "Epoch [10/50], Step [55/735], Loss: 0.5758\n",
      "Epoch [10/50], Step [56/735], Loss: 0.5530\n",
      "Epoch [10/50], Step [57/735], Loss: 0.6038\n",
      "Epoch [10/50], Step [58/735], Loss: 0.7189\n",
      "Epoch [10/50], Step [59/735], Loss: 0.1835\n",
      "Epoch [10/50], Step [60/735], Loss: 0.4019\n",
      "Epoch [10/50], Step [61/735], Loss: 0.5020\n",
      "Epoch [10/50], Step [62/735], Loss: 0.2552\n",
      "Epoch [10/50], Step [63/735], Loss: 0.2940\n",
      "Epoch [10/50], Step [64/735], Loss: 0.4331\n",
      "Epoch [10/50], Step [65/735], Loss: 0.1376\n",
      "Epoch [10/50], Step [66/735], Loss: 0.7333\n",
      "Epoch [10/50], Step [67/735], Loss: 0.1752\n",
      "Epoch [10/50], Step [68/735], Loss: 0.9280\n",
      "Epoch [10/50], Step [69/735], Loss: 0.5541\n",
      "Epoch [10/50], Step [70/735], Loss: 0.8080\n",
      "Epoch [10/50], Step [71/735], Loss: 0.3215\n",
      "Epoch [10/50], Step [72/735], Loss: 0.3603\n",
      "Epoch [10/50], Step [73/735], Loss: 0.1291\n",
      "Epoch [10/50], Step [74/735], Loss: 0.4202\n",
      "Epoch [10/50], Step [75/735], Loss: 0.1624\n",
      "Epoch [10/50], Step [76/735], Loss: 0.1453\n",
      "Epoch [10/50], Step [77/735], Loss: 0.1832\n",
      "Epoch [10/50], Step [78/735], Loss: 0.8240\n",
      "Epoch [10/50], Step [79/735], Loss: 0.1683\n",
      "Epoch [10/50], Step [80/735], Loss: 0.5066\n",
      "Epoch [10/50], Step [81/735], Loss: 0.3167\n",
      "Epoch [10/50], Step [82/735], Loss: 0.1811\n",
      "Epoch [10/50], Step [83/735], Loss: 1.9977\n",
      "Epoch [10/50], Step [84/735], Loss: 0.3866\n",
      "Epoch [10/50], Step [85/735], Loss: 0.2696\n",
      "Epoch [10/50], Step [86/735], Loss: 0.7031\n",
      "Epoch [10/50], Step [87/735], Loss: 0.3566\n",
      "Epoch [10/50], Step [88/735], Loss: 0.3147\n",
      "Epoch [10/50], Step [89/735], Loss: 2.1228\n",
      "Epoch [10/50], Step [90/735], Loss: 0.2301\n",
      "Epoch [10/50], Step [91/735], Loss: 0.2849\n",
      "Epoch [10/50], Step [92/735], Loss: 1.1421\n",
      "Epoch [10/50], Step [93/735], Loss: 0.1904\n",
      "Epoch [10/50], Step [94/735], Loss: 0.2643\n",
      "Epoch [10/50], Step [95/735], Loss: 0.3481\n",
      "Epoch [10/50], Step [96/735], Loss: 0.2074\n",
      "Epoch [10/50], Step [97/735], Loss: 0.2044\n",
      "Epoch [10/50], Step [98/735], Loss: 0.5511\n",
      "Epoch [10/50], Step [99/735], Loss: 0.1251\n",
      "Epoch [10/50], Step [100/735], Loss: 0.2392\n",
      "Epoch [10/50], Step [101/735], Loss: 0.1980\n",
      "Epoch [10/50], Step [102/735], Loss: 0.5604\n",
      "Epoch [10/50], Step [103/735], Loss: 0.0814\n",
      "Epoch [10/50], Step [104/735], Loss: 0.2167\n",
      "Epoch [10/50], Step [105/735], Loss: 0.2394\n",
      "Epoch [10/50], Step [106/735], Loss: 0.1470\n",
      "Epoch [10/50], Step [107/735], Loss: 0.2008\n",
      "Epoch [10/50], Step [108/735], Loss: 0.1165\n",
      "Epoch [10/50], Step [109/735], Loss: 0.4791\n",
      "Epoch [10/50], Step [110/735], Loss: 0.6567\n",
      "Epoch [10/50], Step [111/735], Loss: 0.1366\n",
      "Epoch [10/50], Step [112/735], Loss: 0.2153\n",
      "Epoch [10/50], Step [113/735], Loss: 0.2215\n",
      "Epoch [10/50], Step [114/735], Loss: 0.3570\n",
      "Epoch [10/50], Step [115/735], Loss: 0.1903\n",
      "Epoch [10/50], Step [116/735], Loss: 0.0493\n",
      "Epoch [10/50], Step [117/735], Loss: 0.1747\n",
      "Epoch [10/50], Step [118/735], Loss: 0.5148\n",
      "Epoch [10/50], Step [119/735], Loss: 0.2813\n",
      "Epoch [10/50], Step [120/735], Loss: 0.2880\n",
      "Epoch [10/50], Step [121/735], Loss: 0.5669\n",
      "Epoch [10/50], Step [122/735], Loss: 0.2179\n",
      "Epoch [10/50], Step [123/735], Loss: 0.5016\n",
      "Epoch [10/50], Step [124/735], Loss: 0.2413\n",
      "Epoch [10/50], Step [125/735], Loss: 0.1523\n",
      "Epoch [10/50], Step [126/735], Loss: 0.2947\n",
      "Epoch [10/50], Step [127/735], Loss: 0.1930\n",
      "Epoch [10/50], Step [128/735], Loss: 0.8159\n",
      "Epoch [10/50], Step [129/735], Loss: 0.4872\n",
      "Epoch [10/50], Step [130/735], Loss: 0.1786\n",
      "Epoch [10/50], Step [131/735], Loss: 0.3069\n",
      "Epoch [10/50], Step [132/735], Loss: 0.7693\n",
      "Epoch [10/50], Step [133/735], Loss: 2.6715\n",
      "Epoch [10/50], Step [134/735], Loss: 0.1064\n",
      "Epoch [10/50], Step [135/735], Loss: 0.1509\n",
      "Epoch [10/50], Step [136/735], Loss: 0.6250\n",
      "Epoch [10/50], Step [137/735], Loss: 0.4334\n",
      "Epoch [10/50], Step [138/735], Loss: 0.4643\n",
      "Epoch [10/50], Step [139/735], Loss: 0.4093\n",
      "Epoch [10/50], Step [140/735], Loss: 0.1467\n",
      "Epoch [10/50], Step [141/735], Loss: 0.7013\n",
      "Epoch [10/50], Step [142/735], Loss: 0.4084\n",
      "Epoch [10/50], Step [143/735], Loss: 2.0183\n",
      "Epoch [10/50], Step [144/735], Loss: 0.0598\n",
      "Epoch [10/50], Step [145/735], Loss: 0.3386\n",
      "Epoch [10/50], Step [146/735], Loss: 0.2132\n",
      "Epoch [10/50], Step [147/735], Loss: 0.2941\n",
      "Epoch [10/50], Step [148/735], Loss: 0.1652\n",
      "Epoch [10/50], Step [149/735], Loss: 1.3536\n",
      "Epoch [10/50], Step [150/735], Loss: 5.6969\n",
      "Epoch [10/50], Step [151/735], Loss: 0.2734\n",
      "Epoch [10/50], Step [152/735], Loss: 0.1345\n",
      "Epoch [10/50], Step [153/735], Loss: 0.2792\n",
      "Epoch [10/50], Step [154/735], Loss: 4.8651\n",
      "Epoch [10/50], Step [155/735], Loss: 0.1808\n",
      "Epoch [10/50], Step [156/735], Loss: 0.2892\n",
      "Epoch [10/50], Step [157/735], Loss: 1.1611\n",
      "Epoch [10/50], Step [158/735], Loss: 0.3805\n",
      "Epoch [10/50], Step [159/735], Loss: 0.6605\n",
      "Epoch [10/50], Step [160/735], Loss: 0.0978\n",
      "Epoch [10/50], Step [161/735], Loss: 0.5733\n",
      "Epoch [10/50], Step [162/735], Loss: 0.4695\n",
      "Epoch [10/50], Step [163/735], Loss: 0.3734\n",
      "Epoch [10/50], Step [164/735], Loss: 0.1058\n",
      "Epoch [10/50], Step [165/735], Loss: 0.2761\n",
      "Epoch [10/50], Step [166/735], Loss: 0.2101\n",
      "Epoch [10/50], Step [167/735], Loss: 0.0738\n",
      "Epoch [10/50], Step [168/735], Loss: 0.3501\n",
      "Epoch [10/50], Step [169/735], Loss: 0.3239\n",
      "Epoch [10/50], Step [170/735], Loss: 0.2371\n",
      "Epoch [10/50], Step [171/735], Loss: 0.5702\n",
      "Epoch [10/50], Step [172/735], Loss: 0.2361\n",
      "Epoch [10/50], Step [173/735], Loss: 0.1059\n",
      "Epoch [10/50], Step [174/735], Loss: 0.4325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Step [175/735], Loss: 0.3306\n",
      "Epoch [10/50], Step [176/735], Loss: 0.2643\n",
      "Epoch [10/50], Step [177/735], Loss: 0.1433\n",
      "Epoch [10/50], Step [178/735], Loss: 0.4744\n",
      "Epoch [10/50], Step [179/735], Loss: 0.3758\n",
      "Epoch [10/50], Step [180/735], Loss: 0.1136\n",
      "Epoch [10/50], Step [181/735], Loss: 0.2030\n",
      "Epoch [10/50], Step [182/735], Loss: 5.3338\n",
      "Epoch [10/50], Step [183/735], Loss: 0.3326\n",
      "Epoch [10/50], Step [184/735], Loss: 0.3973\n",
      "Epoch [10/50], Step [185/735], Loss: 0.2275\n",
      "Epoch [10/50], Step [186/735], Loss: 0.9269\n",
      "Epoch [10/50], Step [187/735], Loss: 0.3491\n",
      "Epoch [10/50], Step [188/735], Loss: 0.3184\n",
      "Epoch [10/50], Step [189/735], Loss: 0.1276\n",
      "Epoch [10/50], Step [190/735], Loss: 0.2473\n",
      "Epoch [10/50], Step [191/735], Loss: 0.1690\n",
      "Epoch [10/50], Step [192/735], Loss: 0.3738\n",
      "Epoch [10/50], Step [193/735], Loss: 0.2346\n",
      "Epoch [10/50], Step [194/735], Loss: 0.5094\n",
      "Epoch [10/50], Step [195/735], Loss: 1.2039\n",
      "Epoch [10/50], Step [196/735], Loss: 0.1658\n",
      "Epoch [10/50], Step [197/735], Loss: 0.4959\n",
      "Epoch [10/50], Step [198/735], Loss: 0.2457\n",
      "Epoch [10/50], Step [199/735], Loss: 0.3557\n",
      "Epoch [10/50], Step [200/735], Loss: 0.2496\n",
      "Epoch [10/50], Step [201/735], Loss: 0.5141\n",
      "Epoch [10/50], Step [202/735], Loss: 0.7549\n",
      "Epoch [10/50], Step [203/735], Loss: 0.4726\n",
      "Epoch [10/50], Step [204/735], Loss: 0.9972\n",
      "Epoch [10/50], Step [205/735], Loss: 0.1513\n",
      "Epoch [10/50], Step [206/735], Loss: 0.3422\n",
      "Epoch [10/50], Step [207/735], Loss: 0.1639\n",
      "Epoch [10/50], Step [208/735], Loss: 1.8742\n",
      "Epoch [10/50], Step [209/735], Loss: 0.2687\n",
      "Epoch [10/50], Step [210/735], Loss: 0.3256\n",
      "Epoch [10/50], Step [211/735], Loss: 0.1368\n",
      "Epoch [10/50], Step [212/735], Loss: 0.2429\n",
      "Epoch [10/50], Step [213/735], Loss: 0.3522\n",
      "Epoch [10/50], Step [214/735], Loss: 0.3826\n",
      "Epoch [10/50], Step [215/735], Loss: 0.1322\n",
      "Epoch [10/50], Step [216/735], Loss: 0.2687\n",
      "Epoch [10/50], Step [217/735], Loss: 0.1984\n",
      "Epoch [10/50], Step [218/735], Loss: 0.6549\n",
      "Epoch [10/50], Step [219/735], Loss: 0.3712\n",
      "Epoch [10/50], Step [220/735], Loss: 0.2448\n",
      "Epoch [10/50], Step [221/735], Loss: 0.3925\n",
      "Epoch [10/50], Step [222/735], Loss: 0.4211\n",
      "Epoch [10/50], Step [223/735], Loss: 0.1165\n",
      "Epoch [10/50], Step [224/735], Loss: 0.3307\n",
      "Epoch [10/50], Step [225/735], Loss: 0.3097\n",
      "Epoch [10/50], Step [226/735], Loss: 0.2014\n",
      "Epoch [10/50], Step [227/735], Loss: 0.1930\n",
      "Epoch [10/50], Step [228/735], Loss: 0.1676\n",
      "Epoch [10/50], Step [229/735], Loss: 0.2021\n",
      "Epoch [10/50], Step [230/735], Loss: 0.8616\n",
      "Epoch [10/50], Step [231/735], Loss: 2.4554\n",
      "Epoch [10/50], Step [232/735], Loss: 0.2354\n",
      "Epoch [10/50], Step [233/735], Loss: 0.2067\n",
      "Epoch [10/50], Step [234/735], Loss: 0.2569\n",
      "Epoch [10/50], Step [235/735], Loss: 1.1528\n",
      "Epoch [10/50], Step [236/735], Loss: 0.8209\n",
      "Epoch [10/50], Step [237/735], Loss: 0.6334\n",
      "Epoch [10/50], Step [238/735], Loss: 1.0421\n",
      "Epoch [10/50], Step [239/735], Loss: 0.3692\n",
      "Epoch [10/50], Step [240/735], Loss: 0.4828\n",
      "Epoch [10/50], Step [241/735], Loss: 1.0384\n",
      "Epoch [10/50], Step [242/735], Loss: 0.1637\n",
      "Epoch [10/50], Step [243/735], Loss: 0.5879\n",
      "Epoch [10/50], Step [244/735], Loss: 2.1386\n",
      "Epoch [10/50], Step [245/735], Loss: 0.4774\n",
      "Epoch [10/50], Step [246/735], Loss: 0.3168\n",
      "Epoch [10/50], Step [247/735], Loss: 0.6179\n",
      "Epoch [10/50], Step [248/735], Loss: 0.1085\n",
      "Epoch [10/50], Step [249/735], Loss: 1.8681\n",
      "Epoch [10/50], Step [250/735], Loss: 0.2591\n",
      "Epoch [10/50], Step [251/735], Loss: 0.7771\n",
      "Epoch [10/50], Step [252/735], Loss: 0.1962\n",
      "Epoch [10/50], Step [253/735], Loss: 0.4637\n",
      "Epoch [10/50], Step [254/735], Loss: 0.1669\n",
      "Epoch [10/50], Step [255/735], Loss: 0.3576\n",
      "Epoch [10/50], Step [256/735], Loss: 0.2266\n",
      "Epoch [10/50], Step [257/735], Loss: 0.3969\n",
      "Epoch [10/50], Step [258/735], Loss: 0.2295\n",
      "Epoch [10/50], Step [259/735], Loss: 0.0854\n",
      "Epoch [10/50], Step [260/735], Loss: 0.3712\n",
      "Epoch [10/50], Step [261/735], Loss: 1.1003\n",
      "Epoch [10/50], Step [262/735], Loss: 1.1592\n",
      "Epoch [10/50], Step [263/735], Loss: 0.2821\n",
      "Epoch [10/50], Step [264/735], Loss: 0.2260\n",
      "Epoch [10/50], Step [265/735], Loss: 0.6240\n",
      "Epoch [10/50], Step [266/735], Loss: 0.6040\n",
      "Epoch [10/50], Step [267/735], Loss: 5.5521\n",
      "Epoch [10/50], Step [268/735], Loss: 0.3626\n",
      "Epoch [10/50], Step [269/735], Loss: 0.3858\n",
      "Epoch [10/50], Step [270/735], Loss: 0.2769\n",
      "Epoch [10/50], Step [271/735], Loss: 0.2230\n",
      "Epoch [10/50], Step [272/735], Loss: 0.3059\n",
      "Epoch [10/50], Step [273/735], Loss: 0.1549\n",
      "Epoch [10/50], Step [274/735], Loss: 0.4298\n",
      "Epoch [10/50], Step [275/735], Loss: 0.4152\n",
      "Epoch [10/50], Step [276/735], Loss: 0.4910\n",
      "Epoch [10/50], Step [277/735], Loss: 0.4089\n",
      "Epoch [10/50], Step [278/735], Loss: 0.2449\n",
      "Epoch [10/50], Step [279/735], Loss: 0.3835\n",
      "Epoch [10/50], Step [280/735], Loss: 0.3830\n",
      "Epoch [10/50], Step [281/735], Loss: 0.0723\n",
      "Epoch [10/50], Step [282/735], Loss: 0.3095\n",
      "Epoch [10/50], Step [283/735], Loss: 0.2361\n",
      "Epoch [10/50], Step [284/735], Loss: 0.8285\n",
      "Epoch [10/50], Step [285/735], Loss: 0.4479\n",
      "Epoch [10/50], Step [286/735], Loss: 0.2560\n",
      "Epoch [10/50], Step [287/735], Loss: 0.3401\n",
      "Epoch [10/50], Step [288/735], Loss: 0.7499\n",
      "Epoch [10/50], Step [289/735], Loss: 0.3820\n",
      "Epoch [10/50], Step [290/735], Loss: 0.7700\n",
      "Epoch [10/50], Step [291/735], Loss: 0.1848\n",
      "Epoch [10/50], Step [292/735], Loss: 0.1292\n",
      "Epoch [10/50], Step [293/735], Loss: 1.3883\n",
      "Epoch [10/50], Step [294/735], Loss: 0.2477\n",
      "Epoch [10/50], Step [295/735], Loss: 0.3873\n",
      "Epoch [10/50], Step [296/735], Loss: 0.2479\n",
      "Epoch [10/50], Step [297/735], Loss: 0.6042\n",
      "Epoch [10/50], Step [298/735], Loss: 0.1486\n",
      "Epoch [10/50], Step [299/735], Loss: 0.1665\n",
      "Epoch [10/50], Step [300/735], Loss: 0.4825\n",
      "Epoch [10/50], Step [301/735], Loss: 0.1446\n",
      "Epoch [10/50], Step [302/735], Loss: 0.2236\n",
      "Epoch [10/50], Step [303/735], Loss: 0.2713\n",
      "Epoch [10/50], Step [304/735], Loss: 0.7927\n",
      "Epoch [10/50], Step [305/735], Loss: 0.4870\n",
      "Epoch [10/50], Step [306/735], Loss: 0.1072\n",
      "Epoch [10/50], Step [307/735], Loss: 0.1990\n",
      "Epoch [10/50], Step [308/735], Loss: 0.1932\n",
      "Epoch [10/50], Step [309/735], Loss: 0.4853\n",
      "Epoch [10/50], Step [310/735], Loss: 0.3560\n",
      "Epoch [10/50], Step [311/735], Loss: 0.6890\n",
      "Epoch [10/50], Step [312/735], Loss: 0.1970\n",
      "Epoch [10/50], Step [313/735], Loss: 0.2488\n",
      "Epoch [10/50], Step [314/735], Loss: 0.5191\n",
      "Epoch [10/50], Step [315/735], Loss: 0.4906\n",
      "Epoch [10/50], Step [316/735], Loss: 0.1867\n",
      "Epoch [10/50], Step [317/735], Loss: 0.1196\n",
      "Epoch [10/50], Step [318/735], Loss: 0.2298\n",
      "Epoch [10/50], Step [319/735], Loss: 0.2718\n",
      "Epoch [10/50], Step [320/735], Loss: 2.4692\n",
      "Epoch [10/50], Step [321/735], Loss: 0.2260\n",
      "Epoch [10/50], Step [322/735], Loss: 0.1964\n",
      "Epoch [10/50], Step [323/735], Loss: 0.6438\n",
      "Epoch [10/50], Step [324/735], Loss: 0.5847\n",
      "Epoch [10/50], Step [325/735], Loss: 0.1397\n",
      "Epoch [10/50], Step [326/735], Loss: 1.0753\n",
      "Epoch [10/50], Step [327/735], Loss: 0.5694\n",
      "Epoch [10/50], Step [328/735], Loss: 0.1055\n",
      "Epoch [10/50], Step [329/735], Loss: 0.6348\n",
      "Epoch [10/50], Step [330/735], Loss: 0.2904\n",
      "Epoch [10/50], Step [331/735], Loss: 0.1185\n",
      "Epoch [10/50], Step [332/735], Loss: 1.2449\n",
      "Epoch [10/50], Step [333/735], Loss: 0.4777\n",
      "Epoch [10/50], Step [334/735], Loss: 0.4131\n",
      "Epoch [10/50], Step [335/735], Loss: 0.3629\n",
      "Epoch [10/50], Step [336/735], Loss: 0.3627\n",
      "Epoch [10/50], Step [337/735], Loss: 0.9593\n",
      "Epoch [10/50], Step [338/735], Loss: 1.0819\n",
      "Epoch [10/50], Step [339/735], Loss: 0.6718\n",
      "Epoch [10/50], Step [340/735], Loss: 0.1530\n",
      "Epoch [10/50], Step [341/735], Loss: 0.2853\n",
      "Epoch [10/50], Step [342/735], Loss: 0.5538\n",
      "Epoch [10/50], Step [343/735], Loss: 0.1260\n",
      "Epoch [10/50], Step [344/735], Loss: 0.9184\n",
      "Epoch [10/50], Step [345/735], Loss: 0.5346\n",
      "Epoch [10/50], Step [346/735], Loss: 0.3308\n",
      "Epoch [10/50], Step [347/735], Loss: 0.2341\n",
      "Epoch [10/50], Step [348/735], Loss: 0.3916\n",
      "Epoch [10/50], Step [349/735], Loss: 0.7850\n",
      "Epoch [10/50], Step [350/735], Loss: 0.2201\n",
      "Epoch [10/50], Step [351/735], Loss: 0.3487\n",
      "Epoch [10/50], Step [352/735], Loss: 0.5252\n",
      "Epoch [10/50], Step [353/735], Loss: 1.1347\n",
      "Epoch [10/50], Step [354/735], Loss: 0.5062\n",
      "Epoch [10/50], Step [355/735], Loss: 1.3280\n",
      "Epoch [10/50], Step [356/735], Loss: 0.7573\n",
      "Epoch [10/50], Step [357/735], Loss: 0.3000\n",
      "Epoch [10/50], Step [358/735], Loss: 0.1433\n",
      "Epoch [10/50], Step [359/735], Loss: 0.1077\n",
      "Epoch [10/50], Step [360/735], Loss: 0.9412\n",
      "Epoch [10/50], Step [361/735], Loss: 0.0734\n",
      "Epoch [10/50], Step [362/735], Loss: 0.1271\n",
      "Epoch [10/50], Step [363/735], Loss: 0.6523\n",
      "Epoch [10/50], Step [364/735], Loss: 0.1461\n",
      "Epoch [10/50], Step [365/735], Loss: 0.8476\n",
      "Epoch [10/50], Step [366/735], Loss: 0.8945\n",
      "Epoch [10/50], Step [367/735], Loss: 0.9369\n",
      "Epoch [10/50], Step [368/735], Loss: 0.2519\n",
      "Epoch [10/50], Step [369/735], Loss: 0.3683\n",
      "Epoch [10/50], Step [370/735], Loss: 0.1646\n",
      "Epoch [10/50], Step [371/735], Loss: 0.3007\n",
      "Epoch [10/50], Step [372/735], Loss: 0.4908\n",
      "Epoch [10/50], Step [373/735], Loss: 1.4757\n",
      "Epoch [10/50], Step [374/735], Loss: 0.2942\n",
      "Epoch [10/50], Step [375/735], Loss: 0.7702\n",
      "Epoch [10/50], Step [376/735], Loss: 1.2002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Step [377/735], Loss: 0.4740\n",
      "Epoch [10/50], Step [378/735], Loss: 0.2750\n",
      "Epoch [10/50], Step [379/735], Loss: 0.7820\n",
      "Epoch [10/50], Step [380/735], Loss: 0.2469\n",
      "Epoch [10/50], Step [381/735], Loss: 0.6066\n",
      "Epoch [10/50], Step [382/735], Loss: 0.1000\n",
      "Epoch [10/50], Step [383/735], Loss: 0.3710\n",
      "Epoch [10/50], Step [384/735], Loss: 0.2953\n",
      "Epoch [10/50], Step [385/735], Loss: 0.3867\n",
      "Epoch [10/50], Step [386/735], Loss: 0.4633\n",
      "Epoch [10/50], Step [387/735], Loss: 0.1336\n",
      "Epoch [10/50], Step [388/735], Loss: 0.3923\n",
      "Epoch [10/50], Step [389/735], Loss: 0.2049\n",
      "Epoch [10/50], Step [390/735], Loss: 0.6171\n",
      "Epoch [10/50], Step [391/735], Loss: 0.4593\n",
      "Epoch [10/50], Step [392/735], Loss: 0.4003\n",
      "Epoch [10/50], Step [393/735], Loss: 0.1607\n",
      "Epoch [10/50], Step [394/735], Loss: 0.1151\n",
      "Epoch [10/50], Step [395/735], Loss: 0.2360\n",
      "Epoch [10/50], Step [396/735], Loss: 0.1314\n",
      "Epoch [10/50], Step [397/735], Loss: 0.1537\n",
      "Epoch [10/50], Step [398/735], Loss: 0.1301\n",
      "Epoch [10/50], Step [399/735], Loss: 0.2081\n",
      "Epoch [10/50], Step [400/735], Loss: 0.6863\n",
      "Epoch [10/50], Step [401/735], Loss: 0.1037\n",
      "Epoch [10/50], Step [402/735], Loss: 0.1056\n",
      "Epoch [10/50], Step [403/735], Loss: 0.4581\n",
      "Epoch [10/50], Step [404/735], Loss: 1.1325\n",
      "Epoch [10/50], Step [405/735], Loss: 0.7721\n",
      "Epoch [10/50], Step [406/735], Loss: 0.2390\n",
      "Epoch [10/50], Step [407/735], Loss: 0.6696\n",
      "Epoch [10/50], Step [408/735], Loss: 0.4018\n",
      "Epoch [10/50], Step [409/735], Loss: 0.2154\n",
      "Epoch [10/50], Step [410/735], Loss: 0.5060\n",
      "Epoch [10/50], Step [411/735], Loss: 0.3399\n",
      "Epoch [10/50], Step [412/735], Loss: 0.1711\n",
      "Epoch [10/50], Step [413/735], Loss: 0.7782\n",
      "Epoch [10/50], Step [414/735], Loss: 0.3203\n",
      "Epoch [10/50], Step [415/735], Loss: 0.5993\n",
      "Epoch [10/50], Step [416/735], Loss: 0.1463\n",
      "Epoch [10/50], Step [417/735], Loss: 0.4434\n",
      "Epoch [10/50], Step [418/735], Loss: 0.4669\n",
      "Epoch [10/50], Step [419/735], Loss: 1.4100\n",
      "Epoch [10/50], Step [420/735], Loss: 0.1217\n",
      "Epoch [10/50], Step [421/735], Loss: 0.9432\n",
      "Epoch [10/50], Step [422/735], Loss: 0.1960\n",
      "Epoch [10/50], Step [423/735], Loss: 0.4125\n",
      "Epoch [10/50], Step [424/735], Loss: 0.4267\n",
      "Epoch [10/50], Step [425/735], Loss: 0.1557\n",
      "Epoch [10/50], Step [426/735], Loss: 1.2896\n",
      "Epoch [10/50], Step [427/735], Loss: 0.5798\n",
      "Epoch [10/50], Step [428/735], Loss: 0.2233\n",
      "Epoch [10/50], Step [429/735], Loss: 0.7052\n",
      "Epoch [10/50], Step [430/735], Loss: 0.5124\n",
      "Epoch [10/50], Step [431/735], Loss: 0.3973\n",
      "Epoch [10/50], Step [432/735], Loss: 1.0196\n",
      "Epoch [10/50], Step [433/735], Loss: 2.5053\n",
      "Epoch [10/50], Step [434/735], Loss: 0.1463\n",
      "Epoch [10/50], Step [435/735], Loss: 0.6877\n",
      "Epoch [10/50], Step [436/735], Loss: 0.3674\n",
      "Epoch [10/50], Step [437/735], Loss: 0.6179\n",
      "Epoch [10/50], Step [438/735], Loss: 0.4574\n",
      "Epoch [10/50], Step [439/735], Loss: 0.4005\n",
      "Epoch [10/50], Step [440/735], Loss: 0.3499\n",
      "Epoch [10/50], Step [441/735], Loss: 0.6271\n",
      "Epoch [10/50], Step [442/735], Loss: 1.6119\n",
      "Epoch [10/50], Step [443/735], Loss: 1.4774\n",
      "Epoch [10/50], Step [444/735], Loss: 0.3668\n",
      "Epoch [10/50], Step [445/735], Loss: 0.7499\n",
      "Epoch [10/50], Step [446/735], Loss: 0.3061\n",
      "Epoch [10/50], Step [447/735], Loss: 0.5829\n",
      "Epoch [10/50], Step [448/735], Loss: 0.2376\n",
      "Epoch [10/50], Step [449/735], Loss: 0.1710\n",
      "Epoch [10/50], Step [450/735], Loss: 0.5077\n",
      "Epoch [10/50], Step [451/735], Loss: 0.2914\n",
      "Epoch [10/50], Step [452/735], Loss: 0.3275\n",
      "Epoch [10/50], Step [453/735], Loss: 0.8304\n",
      "Epoch [10/50], Step [454/735], Loss: 0.2738\n",
      "Epoch [10/50], Step [455/735], Loss: 0.8574\n",
      "Epoch [10/50], Step [456/735], Loss: 0.5623\n",
      "Epoch [10/50], Step [457/735], Loss: 0.5861\n",
      "Epoch [10/50], Step [458/735], Loss: 0.3147\n",
      "Epoch [10/50], Step [459/735], Loss: 0.9274\n",
      "Epoch [10/50], Step [460/735], Loss: 0.3082\n",
      "Epoch [10/50], Step [461/735], Loss: 0.1675\n",
      "Epoch [10/50], Step [462/735], Loss: 0.1524\n",
      "Epoch [10/50], Step [463/735], Loss: 0.6371\n",
      "Epoch [10/50], Step [464/735], Loss: 0.9942\n",
      "Epoch [10/50], Step [465/735], Loss: 0.9755\n",
      "Epoch [10/50], Step [466/735], Loss: 0.3830\n",
      "Epoch [10/50], Step [467/735], Loss: 2.1349\n",
      "Epoch [10/50], Step [468/735], Loss: 0.5006\n",
      "Epoch [10/50], Step [469/735], Loss: 0.4227\n",
      "Epoch [10/50], Step [470/735], Loss: 0.2577\n",
      "Epoch [10/50], Step [471/735], Loss: 0.3911\n",
      "Epoch [10/50], Step [472/735], Loss: 0.3763\n",
      "Epoch [10/50], Step [473/735], Loss: 0.5457\n",
      "Epoch [10/50], Step [474/735], Loss: 0.2275\n",
      "Epoch [10/50], Step [475/735], Loss: 0.6573\n",
      "Epoch [10/50], Step [476/735], Loss: 0.3612\n",
      "Epoch [10/50], Step [477/735], Loss: 0.4846\n",
      "Epoch [10/50], Step [478/735], Loss: 0.6140\n",
      "Epoch [10/50], Step [479/735], Loss: 0.4741\n",
      "Epoch [10/50], Step [480/735], Loss: 0.1877\n",
      "Epoch [10/50], Step [481/735], Loss: 0.4446\n",
      "Epoch [10/50], Step [482/735], Loss: 1.1669\n",
      "Epoch [10/50], Step [483/735], Loss: 0.4982\n",
      "Epoch [10/50], Step [484/735], Loss: 0.5024\n",
      "Epoch [10/50], Step [485/735], Loss: 0.5688\n",
      "Epoch [10/50], Step [486/735], Loss: 0.0962\n",
      "Epoch [10/50], Step [487/735], Loss: 0.2384\n",
      "Epoch [10/50], Step [488/735], Loss: 0.2413\n",
      "Epoch [10/50], Step [489/735], Loss: 0.1690\n",
      "Epoch [10/50], Step [490/735], Loss: 0.3267\n",
      "Epoch [10/50], Step [491/735], Loss: 0.1964\n",
      "Epoch [10/50], Step [492/735], Loss: 1.0662\n",
      "Epoch [10/50], Step [493/735], Loss: 0.1041\n",
      "Epoch [10/50], Step [494/735], Loss: 0.2716\n",
      "Epoch [10/50], Step [495/735], Loss: 1.5157\n",
      "Epoch [10/50], Step [496/735], Loss: 6.7549\n",
      "Epoch [10/50], Step [497/735], Loss: 0.2974\n",
      "Epoch [10/50], Step [498/735], Loss: 0.4460\n",
      "Epoch [10/50], Step [499/735], Loss: 0.2504\n",
      "Epoch [10/50], Step [500/735], Loss: 0.2617\n",
      "Epoch [10/50], Step [501/735], Loss: 0.2325\n",
      "Epoch [10/50], Step [502/735], Loss: 0.3167\n",
      "Epoch [10/50], Step [503/735], Loss: 0.8942\n",
      "Epoch [10/50], Step [504/735], Loss: 0.3657\n",
      "Epoch [10/50], Step [505/735], Loss: 0.3842\n",
      "Epoch [10/50], Step [506/735], Loss: 2.2511\n",
      "Epoch [10/50], Step [507/735], Loss: 0.4403\n",
      "Epoch [10/50], Step [508/735], Loss: 0.2050\n",
      "Epoch [10/50], Step [509/735], Loss: 0.3980\n",
      "Epoch [10/50], Step [510/735], Loss: 0.4632\n",
      "Epoch [10/50], Step [511/735], Loss: 0.0890\n",
      "Epoch [10/50], Step [512/735], Loss: 0.1585\n",
      "Epoch [10/50], Step [513/735], Loss: 0.7116\n",
      "Epoch [10/50], Step [514/735], Loss: 0.3055\n",
      "Epoch [10/50], Step [515/735], Loss: 0.2832\n",
      "Epoch [10/50], Step [516/735], Loss: 1.1567\n",
      "Epoch [10/50], Step [517/735], Loss: 0.1432\n",
      "Epoch [10/50], Step [518/735], Loss: 0.2418\n",
      "Epoch [10/50], Step [519/735], Loss: 0.4373\n",
      "Epoch [10/50], Step [520/735], Loss: 0.1307\n",
      "Epoch [10/50], Step [521/735], Loss: 0.8526\n",
      "Epoch [10/50], Step [522/735], Loss: 0.1424\n",
      "Epoch [10/50], Step [523/735], Loss: 0.8954\n",
      "Epoch [10/50], Step [524/735], Loss: 0.4231\n",
      "Epoch [10/50], Step [525/735], Loss: 0.1642\n",
      "Epoch [10/50], Step [526/735], Loss: 0.1626\n",
      "Epoch [10/50], Step [527/735], Loss: 0.8077\n",
      "Epoch [10/50], Step [528/735], Loss: 0.5744\n",
      "Epoch [10/50], Step [529/735], Loss: 0.4215\n",
      "Epoch [10/50], Step [530/735], Loss: 0.3955\n",
      "Epoch [10/50], Step [531/735], Loss: 0.2426\n",
      "Epoch [10/50], Step [532/735], Loss: 0.1214\n",
      "Epoch [10/50], Step [533/735], Loss: 0.5659\n",
      "Epoch [10/50], Step [534/735], Loss: 0.2826\n",
      "Epoch [10/50], Step [535/735], Loss: 0.5248\n",
      "Epoch [10/50], Step [536/735], Loss: 0.6408\n",
      "Epoch [10/50], Step [537/735], Loss: 0.2783\n",
      "Epoch [10/50], Step [538/735], Loss: 0.1843\n",
      "Epoch [10/50], Step [539/735], Loss: 1.5662\n",
      "Epoch [10/50], Step [540/735], Loss: 0.4949\n",
      "Epoch [10/50], Step [541/735], Loss: 1.1004\n",
      "Epoch [10/50], Step [542/735], Loss: 0.1241\n",
      "Epoch [10/50], Step [543/735], Loss: 0.3396\n",
      "Epoch [10/50], Step [544/735], Loss: 0.2416\n",
      "Epoch [10/50], Step [545/735], Loss: 0.1896\n",
      "Epoch [10/50], Step [546/735], Loss: 0.1641\n",
      "Epoch [10/50], Step [547/735], Loss: 0.5657\n",
      "Epoch [10/50], Step [548/735], Loss: 0.3256\n",
      "Epoch [10/50], Step [549/735], Loss: 0.3043\n",
      "Epoch [10/50], Step [550/735], Loss: 1.3778\n",
      "Epoch [10/50], Step [551/735], Loss: 0.4015\n",
      "Epoch [10/50], Step [552/735], Loss: 0.3699\n",
      "Epoch [10/50], Step [553/735], Loss: 0.4760\n",
      "Epoch [10/50], Step [554/735], Loss: 0.0830\n",
      "Epoch [10/50], Step [555/735], Loss: 0.1411\n",
      "Epoch [10/50], Step [556/735], Loss: 0.2947\n",
      "Epoch [10/50], Step [557/735], Loss: 0.3461\n",
      "Epoch [10/50], Step [558/735], Loss: 3.7479\n",
      "Epoch [10/50], Step [559/735], Loss: 0.5737\n",
      "Epoch [10/50], Step [560/735], Loss: 0.1448\n",
      "Epoch [10/50], Step [561/735], Loss: 2.4568\n",
      "Epoch [10/50], Step [562/735], Loss: 0.4969\n",
      "Epoch [10/50], Step [563/735], Loss: 0.2989\n",
      "Epoch [10/50], Step [564/735], Loss: 0.4848\n",
      "Epoch [10/50], Step [565/735], Loss: 0.9923\n",
      "Epoch [10/50], Step [566/735], Loss: 1.2701\n",
      "Epoch [10/50], Step [567/735], Loss: 0.8006\n",
      "Epoch [10/50], Step [568/735], Loss: 0.4197\n",
      "Epoch [10/50], Step [569/735], Loss: 0.2303\n",
      "Epoch [10/50], Step [570/735], Loss: 1.0913\n",
      "Epoch [10/50], Step [571/735], Loss: 0.4995\n",
      "Epoch [10/50], Step [572/735], Loss: 0.1935\n",
      "Epoch [10/50], Step [573/735], Loss: 0.3079\n",
      "Epoch [10/50], Step [574/735], Loss: 1.0409\n",
      "Epoch [10/50], Step [575/735], Loss: 0.4911\n",
      "Epoch [10/50], Step [576/735], Loss: 0.4260\n",
      "Epoch [10/50], Step [577/735], Loss: 0.1770\n",
      "Epoch [10/50], Step [578/735], Loss: 1.3538\n",
      "Epoch [10/50], Step [579/735], Loss: 0.0542\n",
      "Epoch [10/50], Step [580/735], Loss: 0.2559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Step [581/735], Loss: 0.2916\n",
      "Epoch [10/50], Step [582/735], Loss: 0.9019\n",
      "Epoch [10/50], Step [583/735], Loss: 0.2048\n",
      "Epoch [10/50], Step [584/735], Loss: 0.1513\n",
      "Epoch [10/50], Step [585/735], Loss: 0.2887\n",
      "Epoch [10/50], Step [586/735], Loss: 0.1940\n",
      "Epoch [10/50], Step [587/735], Loss: 0.3003\n",
      "Epoch [10/50], Step [588/735], Loss: 0.0865\n",
      "Epoch [10/50], Step [589/735], Loss: 0.1223\n",
      "Epoch [10/50], Step [590/735], Loss: 0.6152\n",
      "Epoch [10/50], Step [591/735], Loss: 1.0105\n",
      "Epoch [10/50], Step [592/735], Loss: 0.3584\n",
      "Epoch [10/50], Step [593/735], Loss: 0.9341\n",
      "Epoch [10/50], Step [594/735], Loss: 0.8340\n",
      "Epoch [10/50], Step [595/735], Loss: 0.1126\n",
      "Epoch [10/50], Step [596/735], Loss: 0.4466\n",
      "Epoch [10/50], Step [597/735], Loss: 0.2929\n",
      "Epoch [10/50], Step [598/735], Loss: 0.1492\n",
      "Epoch [10/50], Step [599/735], Loss: 0.2515\n",
      "Epoch [10/50], Step [600/735], Loss: 0.1096\n",
      "Epoch [10/50], Step [601/735], Loss: 0.2687\n",
      "Epoch [10/50], Step [602/735], Loss: 0.2849\n",
      "Epoch [10/50], Step [603/735], Loss: 0.9570\n",
      "Epoch [10/50], Step [604/735], Loss: 0.6247\n",
      "Epoch [10/50], Step [605/735], Loss: 0.4897\n",
      "Epoch [10/50], Step [606/735], Loss: 1.4801\n",
      "Epoch [10/50], Step [607/735], Loss: 0.8351\n",
      "Epoch [10/50], Step [608/735], Loss: 0.2413\n",
      "Epoch [10/50], Step [609/735], Loss: 0.3939\n",
      "Epoch [10/50], Step [610/735], Loss: 0.6005\n",
      "Epoch [10/50], Step [611/735], Loss: 0.1948\n",
      "Epoch [10/50], Step [612/735], Loss: 0.3301\n",
      "Epoch [10/50], Step [613/735], Loss: 0.5017\n",
      "Epoch [10/50], Step [614/735], Loss: 0.1489\n",
      "Epoch [10/50], Step [615/735], Loss: 0.1901\n",
      "Epoch [10/50], Step [616/735], Loss: 0.7422\n",
      "Epoch [10/50], Step [617/735], Loss: 0.1746\n",
      "Epoch [10/50], Step [618/735], Loss: 1.7188\n",
      "Epoch [10/50], Step [619/735], Loss: 0.1742\n",
      "Epoch [10/50], Step [620/735], Loss: 0.8946\n",
      "Epoch [10/50], Step [621/735], Loss: 0.1533\n",
      "Epoch [10/50], Step [622/735], Loss: 0.3166\n",
      "Epoch [10/50], Step [623/735], Loss: 0.5759\n",
      "Epoch [10/50], Step [624/735], Loss: 0.5253\n",
      "Epoch [10/50], Step [625/735], Loss: 0.9587\n",
      "Epoch [10/50], Step [626/735], Loss: 0.2532\n",
      "Epoch [10/50], Step [627/735], Loss: 0.4867\n",
      "Epoch [10/50], Step [628/735], Loss: 0.3650\n",
      "Epoch [10/50], Step [629/735], Loss: 0.9096\n",
      "Epoch [10/50], Step [630/735], Loss: 0.3836\n",
      "Epoch [10/50], Step [631/735], Loss: 0.5477\n",
      "Epoch [10/50], Step [632/735], Loss: 0.3110\n",
      "Epoch [10/50], Step [633/735], Loss: 0.1326\n",
      "Epoch [10/50], Step [634/735], Loss: 0.1674\n",
      "Epoch [10/50], Step [635/735], Loss: 1.3230\n",
      "Epoch [10/50], Step [636/735], Loss: 0.3687\n",
      "Epoch [10/50], Step [637/735], Loss: 0.3023\n",
      "Epoch [10/50], Step [638/735], Loss: 0.3383\n",
      "Epoch [10/50], Step [639/735], Loss: 0.7787\n",
      "Epoch [10/50], Step [640/735], Loss: 0.5634\n",
      "Epoch [10/50], Step [641/735], Loss: 0.7549\n",
      "Epoch [10/50], Step [642/735], Loss: 0.3047\n",
      "Epoch [10/50], Step [643/735], Loss: 0.6651\n",
      "Epoch [10/50], Step [644/735], Loss: 0.3071\n",
      "Epoch [10/50], Step [645/735], Loss: 0.1563\n",
      "Epoch [10/50], Step [646/735], Loss: 0.4526\n",
      "Epoch [10/50], Step [647/735], Loss: 1.4353\n",
      "Epoch [10/50], Step [648/735], Loss: 0.2215\n",
      "Epoch [10/50], Step [649/735], Loss: 0.3845\n",
      "Epoch [10/50], Step [650/735], Loss: 0.5495\n",
      "Epoch [10/50], Step [651/735], Loss: 0.4275\n",
      "Epoch [10/50], Step [652/735], Loss: 0.2524\n",
      "Epoch [10/50], Step [653/735], Loss: 0.2395\n",
      "Epoch [10/50], Step [654/735], Loss: 0.3580\n",
      "Epoch [10/50], Step [655/735], Loss: 0.9191\n",
      "Epoch [10/50], Step [656/735], Loss: 0.6528\n",
      "Epoch [10/50], Step [657/735], Loss: 0.6866\n",
      "Epoch [10/50], Step [658/735], Loss: 0.3231\n",
      "Epoch [10/50], Step [659/735], Loss: 0.1084\n",
      "Epoch [10/50], Step [660/735], Loss: 0.1866\n",
      "Epoch [10/50], Step [661/735], Loss: 0.1038\n",
      "Epoch [10/50], Step [662/735], Loss: 0.6016\n",
      "Epoch [10/50], Step [663/735], Loss: 0.2384\n",
      "Epoch [10/50], Step [664/735], Loss: 0.5612\n",
      "Epoch [10/50], Step [665/735], Loss: 0.2149\n",
      "Epoch [10/50], Step [666/735], Loss: 0.8095\n",
      "Epoch [10/50], Step [667/735], Loss: 0.3127\n",
      "Epoch [10/50], Step [668/735], Loss: 0.2700\n",
      "Epoch [10/50], Step [669/735], Loss: 0.5772\n",
      "Epoch [10/50], Step [670/735], Loss: 0.5324\n",
      "Epoch [10/50], Step [671/735], Loss: 0.1688\n",
      "Epoch [10/50], Step [672/735], Loss: 0.2993\n",
      "Epoch [10/50], Step [673/735], Loss: 0.2514\n",
      "Epoch [10/50], Step [674/735], Loss: 0.3526\n",
      "Epoch [10/50], Step [675/735], Loss: 0.4381\n",
      "Epoch [10/50], Step [676/735], Loss: 0.2626\n",
      "Epoch [10/50], Step [677/735], Loss: 0.2662\n",
      "Epoch [10/50], Step [678/735], Loss: 0.2146\n",
      "Epoch [10/50], Step [679/735], Loss: 0.6380\n",
      "Epoch [10/50], Step [680/735], Loss: 0.3101\n",
      "Epoch [10/50], Step [681/735], Loss: 0.0626\n",
      "Epoch [10/50], Step [682/735], Loss: 0.2526\n",
      "Epoch [10/50], Step [683/735], Loss: 0.2132\n",
      "Epoch [10/50], Step [684/735], Loss: 0.3022\n",
      "Epoch [10/50], Step [685/735], Loss: 1.6433\n",
      "Epoch [10/50], Step [686/735], Loss: 0.3455\n",
      "Epoch [10/50], Step [687/735], Loss: 0.0989\n",
      "Epoch [10/50], Step [688/735], Loss: 1.0353\n",
      "Epoch [10/50], Step [689/735], Loss: 0.7251\n",
      "Epoch [10/50], Step [690/735], Loss: 0.2850\n",
      "Epoch [10/50], Step [691/735], Loss: 0.3456\n",
      "Epoch [10/50], Step [692/735], Loss: 1.0123\n",
      "Epoch [10/50], Step [693/735], Loss: 0.0947\n",
      "Epoch [10/50], Step [694/735], Loss: 0.2325\n",
      "Epoch [10/50], Step [695/735], Loss: 0.4225\n",
      "Epoch [10/50], Step [696/735], Loss: 0.4867\n",
      "Epoch [10/50], Step [697/735], Loss: 0.9615\n",
      "Epoch [10/50], Step [698/735], Loss: 0.1253\n",
      "Epoch [10/50], Step [699/735], Loss: 0.3682\n",
      "Epoch [10/50], Step [700/735], Loss: 0.5960\n",
      "Epoch [10/50], Step [701/735], Loss: 0.1516\n",
      "Epoch [10/50], Step [702/735], Loss: 0.3717\n",
      "Epoch [10/50], Step [703/735], Loss: 0.4633\n",
      "Epoch [10/50], Step [704/735], Loss: 0.2944\n",
      "Epoch [10/50], Step [705/735], Loss: 0.4053\n",
      "Epoch [10/50], Step [706/735], Loss: 0.2122\n",
      "Epoch [10/50], Step [707/735], Loss: 0.1281\n",
      "Epoch [10/50], Step [708/735], Loss: 0.3399\n",
      "Epoch [10/50], Step [709/735], Loss: 0.6851\n",
      "Epoch [10/50], Step [710/735], Loss: 0.3653\n",
      "Epoch [10/50], Step [711/735], Loss: 0.8971\n",
      "Epoch [10/50], Step [712/735], Loss: 1.1611\n",
      "Epoch [10/50], Step [713/735], Loss: 0.2002\n",
      "Epoch [10/50], Step [714/735], Loss: 0.8485\n",
      "Epoch [10/50], Step [715/735], Loss: 1.0746\n",
      "Epoch [10/50], Step [716/735], Loss: 0.2013\n",
      "Epoch [10/50], Step [717/735], Loss: 1.2536\n",
      "Epoch [10/50], Step [718/735], Loss: 0.5473\n",
      "Epoch [10/50], Step [719/735], Loss: 0.1045\n",
      "Epoch [10/50], Step [720/735], Loss: 0.0992\n",
      "Epoch [10/50], Step [721/735], Loss: 0.1477\n",
      "Epoch [10/50], Step [722/735], Loss: 2.4425\n",
      "Epoch [10/50], Step [723/735], Loss: 0.5502\n",
      "Epoch [10/50], Step [724/735], Loss: 0.3587\n",
      "Epoch [10/50], Step [725/735], Loss: 0.2573\n",
      "Epoch [10/50], Step [726/735], Loss: 0.1742\n",
      "Epoch [10/50], Step [727/735], Loss: 0.7843\n",
      "Epoch [10/50], Step [728/735], Loss: 2.5567\n",
      "Epoch [10/50], Step [729/735], Loss: 0.2368\n",
      "Epoch [10/50], Step [730/735], Loss: 0.2552\n",
      "Epoch [10/50], Step [731/735], Loss: 0.4337\n",
      "Epoch [10/50], Step [732/735], Loss: 0.5743\n",
      "Epoch [10/50], Step [733/735], Loss: 0.1124\n",
      "Epoch [10/50], Step [734/735], Loss: 0.3986\n",
      "Epoch [10/50], Step [735/735], Loss: 0.2337\n",
      "Epoch [11/50], Step [1/735], Loss: 0.7164\n",
      "Epoch [11/50], Step [2/735], Loss: 0.6429\n",
      "Epoch [11/50], Step [3/735], Loss: 0.5179\n",
      "Epoch [11/50], Step [4/735], Loss: 0.3768\n",
      "Epoch [11/50], Step [5/735], Loss: 0.3944\n",
      "Epoch [11/50], Step [6/735], Loss: 0.2229\n",
      "Epoch [11/50], Step [7/735], Loss: 0.3008\n",
      "Epoch [11/50], Step [8/735], Loss: 0.2374\n",
      "Epoch [11/50], Step [9/735], Loss: 0.4285\n",
      "Epoch [11/50], Step [10/735], Loss: 0.7520\n",
      "Epoch [11/50], Step [11/735], Loss: 0.2099\n",
      "Epoch [11/50], Step [12/735], Loss: 1.2424\n",
      "Epoch [11/50], Step [13/735], Loss: 0.3050\n",
      "Epoch [11/50], Step [14/735], Loss: 0.4100\n",
      "Epoch [11/50], Step [15/735], Loss: 0.2271\n",
      "Epoch [11/50], Step [16/735], Loss: 0.5322\n",
      "Epoch [11/50], Step [17/735], Loss: 0.4335\n",
      "Epoch [11/50], Step [18/735], Loss: 0.4442\n",
      "Epoch [11/50], Step [19/735], Loss: 0.4351\n",
      "Epoch [11/50], Step [20/735], Loss: 0.2010\n",
      "Epoch [11/50], Step [21/735], Loss: 0.9773\n",
      "Epoch [11/50], Step [22/735], Loss: 1.9313\n",
      "Epoch [11/50], Step [23/735], Loss: 0.1480\n",
      "Epoch [11/50], Step [24/735], Loss: 0.8380\n",
      "Epoch [11/50], Step [25/735], Loss: 1.0986\n",
      "Epoch [11/50], Step [26/735], Loss: 0.2358\n",
      "Epoch [11/50], Step [27/735], Loss: 0.1661\n",
      "Epoch [11/50], Step [28/735], Loss: 0.9669\n",
      "Epoch [11/50], Step [29/735], Loss: 0.2660\n",
      "Epoch [11/50], Step [30/735], Loss: 0.4142\n",
      "Epoch [11/50], Step [31/735], Loss: 0.2520\n",
      "Epoch [11/50], Step [32/735], Loss: 0.1845\n",
      "Epoch [11/50], Step [33/735], Loss: 0.4195\n",
      "Epoch [11/50], Step [34/735], Loss: 0.1562\n",
      "Epoch [11/50], Step [35/735], Loss: 0.4062\n",
      "Epoch [11/50], Step [36/735], Loss: 1.7193\n",
      "Epoch [11/50], Step [37/735], Loss: 0.5581\n",
      "Epoch [11/50], Step [38/735], Loss: 0.2744\n",
      "Epoch [11/50], Step [39/735], Loss: 0.1822\n",
      "Epoch [11/50], Step [40/735], Loss: 0.2621\n",
      "Epoch [11/50], Step [41/735], Loss: 0.4921\n",
      "Epoch [11/50], Step [42/735], Loss: 0.1729\n",
      "Epoch [11/50], Step [43/735], Loss: 0.9235\n",
      "Epoch [11/50], Step [44/735], Loss: 0.6009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Step [45/735], Loss: 0.3763\n",
      "Epoch [11/50], Step [46/735], Loss: 0.0842\n",
      "Epoch [11/50], Step [47/735], Loss: 0.3857\n",
      "Epoch [11/50], Step [48/735], Loss: 0.8050\n",
      "Epoch [11/50], Step [49/735], Loss: 0.3512\n",
      "Epoch [11/50], Step [50/735], Loss: 0.8479\n",
      "Epoch [11/50], Step [51/735], Loss: 0.1447\n",
      "Epoch [11/50], Step [52/735], Loss: 0.2919\n",
      "Epoch [11/50], Step [53/735], Loss: 0.1268\n",
      "Epoch [11/50], Step [54/735], Loss: 0.2380\n",
      "Epoch [11/50], Step [55/735], Loss: 0.4049\n",
      "Epoch [11/50], Step [56/735], Loss: 0.4997\n",
      "Epoch [11/50], Step [57/735], Loss: 1.8056\n",
      "Epoch [11/50], Step [58/735], Loss: 0.5892\n",
      "Epoch [11/50], Step [59/735], Loss: 0.3898\n",
      "Epoch [11/50], Step [60/735], Loss: 0.2016\n",
      "Epoch [11/50], Step [61/735], Loss: 0.6841\n",
      "Epoch [11/50], Step [62/735], Loss: 0.4053\n",
      "Epoch [11/50], Step [63/735], Loss: 0.4311\n",
      "Epoch [11/50], Step [64/735], Loss: 0.3856\n",
      "Epoch [11/50], Step [65/735], Loss: 0.6057\n",
      "Epoch [11/50], Step [66/735], Loss: 0.2658\n",
      "Epoch [11/50], Step [67/735], Loss: 0.6068\n",
      "Epoch [11/50], Step [68/735], Loss: 0.1587\n",
      "Epoch [11/50], Step [69/735], Loss: 0.6238\n",
      "Epoch [11/50], Step [70/735], Loss: 0.3081\n",
      "Epoch [11/50], Step [71/735], Loss: 1.5643\n",
      "Epoch [11/50], Step [72/735], Loss: 1.1236\n",
      "Epoch [11/50], Step [73/735], Loss: 0.0803\n",
      "Epoch [11/50], Step [74/735], Loss: 0.2994\n",
      "Epoch [11/50], Step [75/735], Loss: 0.1656\n",
      "Epoch [11/50], Step [76/735], Loss: 0.5225\n",
      "Epoch [11/50], Step [77/735], Loss: 0.3017\n",
      "Epoch [11/50], Step [78/735], Loss: 0.1622\n",
      "Epoch [11/50], Step [79/735], Loss: 0.9868\n",
      "Epoch [11/50], Step [80/735], Loss: 0.5881\n",
      "Epoch [11/50], Step [81/735], Loss: 0.2028\n",
      "Epoch [11/50], Step [82/735], Loss: 0.0846\n",
      "Epoch [11/50], Step [83/735], Loss: 0.8484\n",
      "Epoch [11/50], Step [84/735], Loss: 0.2199\n",
      "Epoch [11/50], Step [85/735], Loss: 0.2493\n",
      "Epoch [11/50], Step [86/735], Loss: 0.8173\n",
      "Epoch [11/50], Step [87/735], Loss: 0.4063\n",
      "Epoch [11/50], Step [88/735], Loss: 0.3156\n",
      "Epoch [11/50], Step [89/735], Loss: 0.7071\n",
      "Epoch [11/50], Step [90/735], Loss: 0.2732\n",
      "Epoch [11/50], Step [91/735], Loss: 0.1245\n",
      "Epoch [11/50], Step [92/735], Loss: 0.5578\n",
      "Epoch [11/50], Step [93/735], Loss: 0.3367\n",
      "Epoch [11/50], Step [94/735], Loss: 0.1512\n",
      "Epoch [11/50], Step [95/735], Loss: 0.0848\n",
      "Epoch [11/50], Step [96/735], Loss: 0.1683\n",
      "Epoch [11/50], Step [97/735], Loss: 0.1525\n",
      "Epoch [11/50], Step [98/735], Loss: 0.4295\n",
      "Epoch [11/50], Step [99/735], Loss: 0.5257\n",
      "Epoch [11/50], Step [100/735], Loss: 0.2627\n",
      "Epoch [11/50], Step [101/735], Loss: 0.5644\n",
      "Epoch [11/50], Step [102/735], Loss: 0.1308\n",
      "Epoch [11/50], Step [103/735], Loss: 0.4338\n",
      "Epoch [11/50], Step [104/735], Loss: 0.3099\n",
      "Epoch [11/50], Step [105/735], Loss: 0.1179\n",
      "Epoch [11/50], Step [106/735], Loss: 0.7058\n",
      "Epoch [11/50], Step [107/735], Loss: 0.1293\n",
      "Epoch [11/50], Step [108/735], Loss: 0.5201\n",
      "Epoch [11/50], Step [109/735], Loss: 0.9705\n",
      "Epoch [11/50], Step [110/735], Loss: 0.8253\n",
      "Epoch [11/50], Step [111/735], Loss: 0.2251\n",
      "Epoch [11/50], Step [112/735], Loss: 0.2709\n",
      "Epoch [11/50], Step [113/735], Loss: 0.4539\n",
      "Epoch [11/50], Step [114/735], Loss: 0.3481\n",
      "Epoch [11/50], Step [115/735], Loss: 0.1109\n",
      "Epoch [11/50], Step [116/735], Loss: 0.5083\n",
      "Epoch [11/50], Step [117/735], Loss: 0.4666\n",
      "Epoch [11/50], Step [118/735], Loss: 0.1562\n",
      "Epoch [11/50], Step [119/735], Loss: 0.8559\n",
      "Epoch [11/50], Step [120/735], Loss: 0.3914\n",
      "Epoch [11/50], Step [121/735], Loss: 0.3500\n",
      "Epoch [11/50], Step [122/735], Loss: 0.0864\n",
      "Epoch [11/50], Step [123/735], Loss: 0.0920\n",
      "Epoch [11/50], Step [124/735], Loss: 0.1217\n",
      "Epoch [11/50], Step [125/735], Loss: 0.0926\n",
      "Epoch [11/50], Step [126/735], Loss: 0.4950\n",
      "Epoch [11/50], Step [127/735], Loss: 0.4759\n",
      "Epoch [11/50], Step [128/735], Loss: 0.6063\n",
      "Epoch [11/50], Step [129/735], Loss: 0.6755\n",
      "Epoch [11/50], Step [130/735], Loss: 0.2461\n",
      "Epoch [11/50], Step [131/735], Loss: 0.8942\n",
      "Epoch [11/50], Step [132/735], Loss: 0.4412\n",
      "Epoch [11/50], Step [133/735], Loss: 5.3134\n",
      "Epoch [11/50], Step [134/735], Loss: 0.3358\n",
      "Epoch [11/50], Step [135/735], Loss: 0.3150\n",
      "Epoch [11/50], Step [136/735], Loss: 0.2554\n",
      "Epoch [11/50], Step [137/735], Loss: 0.4612\n",
      "Epoch [11/50], Step [138/735], Loss: 0.2389\n",
      "Epoch [11/50], Step [139/735], Loss: 2.4610\n",
      "Epoch [11/50], Step [140/735], Loss: 0.5683\n",
      "Epoch [11/50], Step [141/735], Loss: 0.7379\n",
      "Epoch [11/50], Step [142/735], Loss: 0.2001\n",
      "Epoch [11/50], Step [143/735], Loss: 0.2047\n",
      "Epoch [11/50], Step [144/735], Loss: 0.5956\n",
      "Epoch [11/50], Step [145/735], Loss: 0.3734\n",
      "Epoch [11/50], Step [146/735], Loss: 0.8922\n",
      "Epoch [11/50], Step [147/735], Loss: 0.2639\n",
      "Epoch [11/50], Step [148/735], Loss: 0.2104\n",
      "Epoch [11/50], Step [149/735], Loss: 0.0487\n",
      "Epoch [11/50], Step [150/735], Loss: 0.4441\n",
      "Epoch [11/50], Step [151/735], Loss: 0.1038\n",
      "Epoch [11/50], Step [152/735], Loss: 0.2259\n",
      "Epoch [11/50], Step [153/735], Loss: 0.6611\n",
      "Epoch [11/50], Step [154/735], Loss: 0.0743\n",
      "Epoch [11/50], Step [155/735], Loss: 0.4999\n",
      "Epoch [11/50], Step [156/735], Loss: 0.1055\n",
      "Epoch [11/50], Step [157/735], Loss: 0.4725\n",
      "Epoch [11/50], Step [158/735], Loss: 0.1921\n",
      "Epoch [11/50], Step [159/735], Loss: 0.1022\n",
      "Epoch [11/50], Step [160/735], Loss: 5.4103\n",
      "Epoch [11/50], Step [161/735], Loss: 0.1944\n",
      "Epoch [11/50], Step [162/735], Loss: 0.3468\n",
      "Epoch [11/50], Step [163/735], Loss: 0.5711\n",
      "Epoch [11/50], Step [164/735], Loss: 1.9637\n",
      "Epoch [11/50], Step [165/735], Loss: 0.1500\n",
      "Epoch [11/50], Step [166/735], Loss: 0.0911\n",
      "Epoch [11/50], Step [167/735], Loss: 0.1363\n",
      "Epoch [11/50], Step [168/735], Loss: 0.3984\n",
      "Epoch [11/50], Step [169/735], Loss: 0.3233\n",
      "Epoch [11/50], Step [170/735], Loss: 1.8866\n",
      "Epoch [11/50], Step [171/735], Loss: 0.1994\n",
      "Epoch [11/50], Step [172/735], Loss: 0.6842\n",
      "Epoch [11/50], Step [173/735], Loss: 0.1247\n",
      "Epoch [11/50], Step [174/735], Loss: 0.6149\n",
      "Epoch [11/50], Step [175/735], Loss: 1.4434\n",
      "Epoch [11/50], Step [176/735], Loss: 0.5638\n",
      "Epoch [11/50], Step [177/735], Loss: 0.1031\n",
      "Epoch [11/50], Step [178/735], Loss: 0.3860\n",
      "Epoch [11/50], Step [179/735], Loss: 0.3061\n",
      "Epoch [11/50], Step [180/735], Loss: 0.3128\n",
      "Epoch [11/50], Step [181/735], Loss: 0.3637\n",
      "Epoch [11/50], Step [182/735], Loss: 0.1515\n",
      "Epoch [11/50], Step [183/735], Loss: 0.1078\n",
      "Epoch [11/50], Step [184/735], Loss: 0.6119\n",
      "Epoch [11/50], Step [185/735], Loss: 0.1140\n",
      "Epoch [11/50], Step [186/735], Loss: 0.1819\n",
      "Epoch [11/50], Step [187/735], Loss: 0.3496\n",
      "Epoch [11/50], Step [188/735], Loss: 0.1179\n",
      "Epoch [11/50], Step [189/735], Loss: 0.3035\n",
      "Epoch [11/50], Step [190/735], Loss: 0.1041\n",
      "Epoch [11/50], Step [191/735], Loss: 0.1835\n",
      "Epoch [11/50], Step [192/735], Loss: 0.3204\n",
      "Epoch [11/50], Step [193/735], Loss: 0.2940\n",
      "Epoch [11/50], Step [194/735], Loss: 0.2579\n",
      "Epoch [11/50], Step [195/735], Loss: 0.1947\n",
      "Epoch [11/50], Step [196/735], Loss: 0.5273\n",
      "Epoch [11/50], Step [197/735], Loss: 0.5846\n",
      "Epoch [11/50], Step [198/735], Loss: 2.1463\n",
      "Epoch [11/50], Step [199/735], Loss: 0.4793\n",
      "Epoch [11/50], Step [200/735], Loss: 0.8927\n",
      "Epoch [11/50], Step [201/735], Loss: 0.5683\n",
      "Epoch [11/50], Step [202/735], Loss: 0.1557\n",
      "Epoch [11/50], Step [203/735], Loss: 0.4913\n",
      "Epoch [11/50], Step [204/735], Loss: 0.2890\n",
      "Epoch [11/50], Step [205/735], Loss: 0.1721\n",
      "Epoch [11/50], Step [206/735], Loss: 0.8043\n",
      "Epoch [11/50], Step [207/735], Loss: 0.1317\n",
      "Epoch [11/50], Step [208/735], Loss: 0.2314\n",
      "Epoch [11/50], Step [209/735], Loss: 0.4616\n",
      "Epoch [11/50], Step [210/735], Loss: 0.1732\n",
      "Epoch [11/50], Step [211/735], Loss: 0.0861\n",
      "Epoch [11/50], Step [212/735], Loss: 0.1489\n",
      "Epoch [11/50], Step [213/735], Loss: 0.1173\n",
      "Epoch [11/50], Step [214/735], Loss: 0.5236\n",
      "Epoch [11/50], Step [215/735], Loss: 0.4611\n",
      "Epoch [11/50], Step [216/735], Loss: 0.2361\n",
      "Epoch [11/50], Step [217/735], Loss: 0.1980\n",
      "Epoch [11/50], Step [218/735], Loss: 1.0666\n",
      "Epoch [11/50], Step [219/735], Loss: 0.1688\n",
      "Epoch [11/50], Step [220/735], Loss: 0.3151\n",
      "Epoch [11/50], Step [221/735], Loss: 0.4066\n",
      "Epoch [11/50], Step [222/735], Loss: 0.8301\n",
      "Epoch [11/50], Step [223/735], Loss: 1.1173\n",
      "Epoch [11/50], Step [224/735], Loss: 0.3708\n",
      "Epoch [11/50], Step [225/735], Loss: 0.3401\n",
      "Epoch [11/50], Step [226/735], Loss: 0.2776\n",
      "Epoch [11/50], Step [227/735], Loss: 0.3244\n",
      "Epoch [11/50], Step [228/735], Loss: 0.7779\n",
      "Epoch [11/50], Step [229/735], Loss: 0.8909\n",
      "Epoch [11/50], Step [230/735], Loss: 0.5213\n",
      "Epoch [11/50], Step [231/735], Loss: 0.2338\n",
      "Epoch [11/50], Step [232/735], Loss: 0.1372\n",
      "Epoch [11/50], Step [233/735], Loss: 0.1886\n",
      "Epoch [11/50], Step [234/735], Loss: 0.5014\n",
      "Epoch [11/50], Step [235/735], Loss: 0.5296\n",
      "Epoch [11/50], Step [236/735], Loss: 0.0414\n",
      "Epoch [11/50], Step [237/735], Loss: 0.1473\n",
      "Epoch [11/50], Step [238/735], Loss: 0.2762\n",
      "Epoch [11/50], Step [239/735], Loss: 0.5446\n",
      "Epoch [11/50], Step [240/735], Loss: 0.2703\n",
      "Epoch [11/50], Step [241/735], Loss: 0.1575\n",
      "Epoch [11/50], Step [242/735], Loss: 0.7206\n",
      "Epoch [11/50], Step [243/735], Loss: 0.1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Step [244/735], Loss: 0.2160\n",
      "Epoch [11/50], Step [245/735], Loss: 0.2838\n",
      "Epoch [11/50], Step [246/735], Loss: 0.4071\n",
      "Epoch [11/50], Step [247/735], Loss: 0.1012\n",
      "Epoch [11/50], Step [248/735], Loss: 0.5059\n",
      "Epoch [11/50], Step [249/735], Loss: 0.1693\n",
      "Epoch [11/50], Step [250/735], Loss: 0.6926\n",
      "Epoch [11/50], Step [251/735], Loss: 0.3388\n",
      "Epoch [11/50], Step [252/735], Loss: 0.3421\n",
      "Epoch [11/50], Step [253/735], Loss: 0.4979\n",
      "Epoch [11/50], Step [254/735], Loss: 0.3656\n",
      "Epoch [11/50], Step [255/735], Loss: 0.2303\n",
      "Epoch [11/50], Step [256/735], Loss: 0.6692\n",
      "Epoch [11/50], Step [257/735], Loss: 0.3499\n",
      "Epoch [11/50], Step [258/735], Loss: 0.2211\n",
      "Epoch [11/50], Step [259/735], Loss: 0.1446\n",
      "Epoch [11/50], Step [260/735], Loss: 0.6626\n",
      "Epoch [11/50], Step [261/735], Loss: 0.0993\n",
      "Epoch [11/50], Step [262/735], Loss: 0.4276\n",
      "Epoch [11/50], Step [263/735], Loss: 1.0105\n",
      "Epoch [11/50], Step [264/735], Loss: 0.4068\n",
      "Epoch [11/50], Step [265/735], Loss: 0.9109\n",
      "Epoch [11/50], Step [266/735], Loss: 0.3307\n",
      "Epoch [11/50], Step [267/735], Loss: 0.4726\n",
      "Epoch [11/50], Step [268/735], Loss: 0.3140\n",
      "Epoch [11/50], Step [269/735], Loss: 0.2501\n",
      "Epoch [11/50], Step [270/735], Loss: 0.4957\n",
      "Epoch [11/50], Step [271/735], Loss: 0.8522\n",
      "Epoch [11/50], Step [272/735], Loss: 0.1506\n",
      "Epoch [11/50], Step [273/735], Loss: 0.3198\n",
      "Epoch [11/50], Step [274/735], Loss: 0.2410\n",
      "Epoch [11/50], Step [275/735], Loss: 0.1638\n",
      "Epoch [11/50], Step [276/735], Loss: 1.0184\n",
      "Epoch [11/50], Step [277/735], Loss: 0.4395\n",
      "Epoch [11/50], Step [278/735], Loss: 0.2950\n",
      "Epoch [11/50], Step [279/735], Loss: 0.5001\n",
      "Epoch [11/50], Step [280/735], Loss: 0.3341\n",
      "Epoch [11/50], Step [281/735], Loss: 1.2368\n",
      "Epoch [11/50], Step [282/735], Loss: 0.1614\n",
      "Epoch [11/50], Step [283/735], Loss: 0.6677\n",
      "Epoch [11/50], Step [284/735], Loss: 0.9631\n",
      "Epoch [11/50], Step [285/735], Loss: 0.0959\n",
      "Epoch [11/50], Step [286/735], Loss: 0.7467\n",
      "Epoch [11/50], Step [287/735], Loss: 0.1293\n",
      "Epoch [11/50], Step [288/735], Loss: 0.4040\n",
      "Epoch [11/50], Step [289/735], Loss: 0.2472\n",
      "Epoch [11/50], Step [290/735], Loss: 0.5384\n",
      "Epoch [11/50], Step [291/735], Loss: 0.8916\n",
      "Epoch [11/50], Step [292/735], Loss: 0.2613\n",
      "Epoch [11/50], Step [293/735], Loss: 0.9685\n",
      "Epoch [11/50], Step [294/735], Loss: 0.1121\n",
      "Epoch [11/50], Step [295/735], Loss: 0.1592\n",
      "Epoch [11/50], Step [296/735], Loss: 0.0864\n",
      "Epoch [11/50], Step [297/735], Loss: 0.3950\n",
      "Epoch [11/50], Step [298/735], Loss: 0.4831\n",
      "Epoch [11/50], Step [299/735], Loss: 0.3087\n",
      "Epoch [11/50], Step [300/735], Loss: 1.7379\n",
      "Epoch [11/50], Step [301/735], Loss: 0.8030\n",
      "Epoch [11/50], Step [302/735], Loss: 0.2726\n",
      "Epoch [11/50], Step [303/735], Loss: 1.2034\n",
      "Epoch [11/50], Step [304/735], Loss: 2.4146\n",
      "Epoch [11/50], Step [305/735], Loss: 0.4146\n",
      "Epoch [11/50], Step [306/735], Loss: 0.6787\n",
      "Epoch [11/50], Step [307/735], Loss: 0.2715\n",
      "Epoch [11/50], Step [308/735], Loss: 0.3935\n",
      "Epoch [11/50], Step [309/735], Loss: 1.6762\n",
      "Epoch [11/50], Step [310/735], Loss: 0.9317\n",
      "Epoch [11/50], Step [311/735], Loss: 0.1709\n",
      "Epoch [11/50], Step [312/735], Loss: 0.1957\n",
      "Epoch [11/50], Step [313/735], Loss: 0.3002\n",
      "Epoch [11/50], Step [314/735], Loss: 0.5184\n",
      "Epoch [11/50], Step [315/735], Loss: 0.5905\n",
      "Epoch [11/50], Step [316/735], Loss: 0.4101\n",
      "Epoch [11/50], Step [317/735], Loss: 1.8639\n",
      "Epoch [11/50], Step [318/735], Loss: 0.2602\n",
      "Epoch [11/50], Step [319/735], Loss: 0.1084\n",
      "Epoch [11/50], Step [320/735], Loss: 0.2366\n",
      "Epoch [11/50], Step [321/735], Loss: 0.6190\n",
      "Epoch [11/50], Step [322/735], Loss: 0.4476\n",
      "Epoch [11/50], Step [323/735], Loss: 0.2950\n",
      "Epoch [11/50], Step [324/735], Loss: 0.3880\n",
      "Epoch [11/50], Step [325/735], Loss: 0.6212\n",
      "Epoch [11/50], Step [326/735], Loss: 0.6569\n",
      "Epoch [11/50], Step [327/735], Loss: 0.9957\n",
      "Epoch [11/50], Step [328/735], Loss: 0.4837\n",
      "Epoch [11/50], Step [329/735], Loss: 0.4971\n",
      "Epoch [11/50], Step [330/735], Loss: 2.4131\n",
      "Epoch [11/50], Step [331/735], Loss: 1.6147\n",
      "Epoch [11/50], Step [332/735], Loss: 0.1664\n",
      "Epoch [11/50], Step [333/735], Loss: 0.9532\n",
      "Epoch [11/50], Step [334/735], Loss: 0.4308\n",
      "Epoch [11/50], Step [335/735], Loss: 0.9503\n",
      "Epoch [11/50], Step [336/735], Loss: 0.5143\n",
      "Epoch [11/50], Step [337/735], Loss: 0.1852\n",
      "Epoch [11/50], Step [338/735], Loss: 0.0806\n",
      "Epoch [11/50], Step [339/735], Loss: 0.8037\n",
      "Epoch [11/50], Step [340/735], Loss: 0.1148\n",
      "Epoch [11/50], Step [341/735], Loss: 0.0560\n",
      "Epoch [11/50], Step [342/735], Loss: 0.3866\n",
      "Epoch [11/50], Step [343/735], Loss: 0.1370\n",
      "Epoch [11/50], Step [344/735], Loss: 0.3837\n",
      "Epoch [11/50], Step [345/735], Loss: 0.3567\n",
      "Epoch [11/50], Step [346/735], Loss: 0.2343\n",
      "Epoch [11/50], Step [347/735], Loss: 0.1426\n",
      "Epoch [11/50], Step [348/735], Loss: 0.5665\n",
      "Epoch [11/50], Step [349/735], Loss: 0.5720\n",
      "Epoch [11/50], Step [350/735], Loss: 1.4925\n",
      "Epoch [11/50], Step [351/735], Loss: 0.5142\n",
      "Epoch [11/50], Step [352/735], Loss: 0.4208\n",
      "Epoch [11/50], Step [353/735], Loss: 0.6583\n",
      "Epoch [11/50], Step [354/735], Loss: 0.1245\n",
      "Epoch [11/50], Step [355/735], Loss: 0.1684\n",
      "Epoch [11/50], Step [356/735], Loss: 0.1516\n",
      "Epoch [11/50], Step [357/735], Loss: 0.3416\n",
      "Epoch [11/50], Step [358/735], Loss: 1.1812\n",
      "Epoch [11/50], Step [359/735], Loss: 0.1584\n",
      "Epoch [11/50], Step [360/735], Loss: 0.5536\n",
      "Epoch [11/50], Step [361/735], Loss: 0.4912\n",
      "Epoch [11/50], Step [362/735], Loss: 0.3956\n",
      "Epoch [11/50], Step [363/735], Loss: 0.6140\n",
      "Epoch [11/50], Step [364/735], Loss: 0.9135\n",
      "Epoch [11/50], Step [365/735], Loss: 0.3189\n",
      "Epoch [11/50], Step [366/735], Loss: 0.1681\n",
      "Epoch [11/50], Step [367/735], Loss: 0.2303\n",
      "Epoch [11/50], Step [368/735], Loss: 0.8862\n",
      "Epoch [11/50], Step [369/735], Loss: 0.1259\n",
      "Epoch [11/50], Step [370/735], Loss: 0.8242\n",
      "Epoch [11/50], Step [371/735], Loss: 0.4281\n",
      "Epoch [11/50], Step [372/735], Loss: 0.3021\n",
      "Epoch [11/50], Step [373/735], Loss: 0.8691\n",
      "Epoch [11/50], Step [374/735], Loss: 0.8051\n",
      "Epoch [11/50], Step [375/735], Loss: 1.7991\n",
      "Epoch [11/50], Step [376/735], Loss: 0.3759\n",
      "Epoch [11/50], Step [377/735], Loss: 0.0690\n",
      "Epoch [11/50], Step [378/735], Loss: 0.5347\n",
      "Epoch [11/50], Step [379/735], Loss: 0.6493\n",
      "Epoch [11/50], Step [380/735], Loss: 0.0875\n",
      "Epoch [11/50], Step [381/735], Loss: 0.5398\n",
      "Epoch [11/50], Step [382/735], Loss: 0.3012\n",
      "Epoch [11/50], Step [383/735], Loss: 1.0544\n",
      "Epoch [11/50], Step [384/735], Loss: 0.0618\n",
      "Epoch [11/50], Step [385/735], Loss: 0.4271\n",
      "Epoch [11/50], Step [386/735], Loss: 0.0662\n",
      "Epoch [11/50], Step [387/735], Loss: 0.3377\n",
      "Epoch [11/50], Step [388/735], Loss: 0.1049\n",
      "Epoch [11/50], Step [389/735], Loss: 0.1460\n",
      "Epoch [11/50], Step [390/735], Loss: 0.3663\n",
      "Epoch [11/50], Step [391/735], Loss: 0.3514\n",
      "Epoch [11/50], Step [392/735], Loss: 0.2164\n",
      "Epoch [11/50], Step [393/735], Loss: 0.1652\n",
      "Epoch [11/50], Step [394/735], Loss: 0.5075\n",
      "Epoch [11/50], Step [395/735], Loss: 0.0981\n",
      "Epoch [11/50], Step [396/735], Loss: 0.6450\n",
      "Epoch [11/50], Step [397/735], Loss: 0.1472\n",
      "Epoch [11/50], Step [398/735], Loss: 5.1155\n",
      "Epoch [11/50], Step [399/735], Loss: 0.1167\n",
      "Epoch [11/50], Step [400/735], Loss: 0.2144\n",
      "Epoch [11/50], Step [401/735], Loss: 0.4084\n",
      "Epoch [11/50], Step [402/735], Loss: 0.2020\n",
      "Epoch [11/50], Step [403/735], Loss: 0.2083\n",
      "Epoch [11/50], Step [404/735], Loss: 0.3743\n",
      "Epoch [11/50], Step [405/735], Loss: 0.6955\n",
      "Epoch [11/50], Step [406/735], Loss: 0.2708\n",
      "Epoch [11/50], Step [407/735], Loss: 0.1840\n",
      "Epoch [11/50], Step [408/735], Loss: 0.3464\n",
      "Epoch [11/50], Step [409/735], Loss: 0.2986\n",
      "Epoch [11/50], Step [410/735], Loss: 0.1784\n",
      "Epoch [11/50], Step [411/735], Loss: 0.1951\n",
      "Epoch [11/50], Step [412/735], Loss: 0.1956\n",
      "Epoch [11/50], Step [413/735], Loss: 0.2785\n",
      "Epoch [11/50], Step [414/735], Loss: 0.1405\n",
      "Epoch [11/50], Step [415/735], Loss: 0.1741\n",
      "Epoch [11/50], Step [416/735], Loss: 0.4973\n",
      "Epoch [11/50], Step [417/735], Loss: 0.2929\n",
      "Epoch [11/50], Step [418/735], Loss: 0.4245\n",
      "Epoch [11/50], Step [419/735], Loss: 0.2554\n",
      "Epoch [11/50], Step [420/735], Loss: 0.2389\n",
      "Epoch [11/50], Step [421/735], Loss: 0.2755\n",
      "Epoch [11/50], Step [422/735], Loss: 5.0531\n",
      "Epoch [11/50], Step [423/735], Loss: 0.6065\n",
      "Epoch [11/50], Step [424/735], Loss: 0.5583\n",
      "Epoch [11/50], Step [425/735], Loss: 0.2220\n",
      "Epoch [11/50], Step [426/735], Loss: 0.9561\n",
      "Epoch [11/50], Step [427/735], Loss: 0.2654\n",
      "Epoch [11/50], Step [428/735], Loss: 0.3525\n",
      "Epoch [11/50], Step [429/735], Loss: 0.3229\n",
      "Epoch [11/50], Step [430/735], Loss: 1.5842\n",
      "Epoch [11/50], Step [431/735], Loss: 0.6830\n",
      "Epoch [11/50], Step [432/735], Loss: 0.3476\n",
      "Epoch [11/50], Step [433/735], Loss: 0.6432\n",
      "Epoch [11/50], Step [434/735], Loss: 0.1633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Step [435/735], Loss: 0.2063\n",
      "Epoch [11/50], Step [436/735], Loss: 0.3781\n",
      "Epoch [11/50], Step [437/735], Loss: 0.6586\n",
      "Epoch [11/50], Step [438/735], Loss: 0.1520\n",
      "Epoch [11/50], Step [439/735], Loss: 0.5501\n",
      "Epoch [11/50], Step [440/735], Loss: 0.2794\n",
      "Epoch [11/50], Step [441/735], Loss: 0.6588\n",
      "Epoch [11/50], Step [442/735], Loss: 1.0887\n",
      "Epoch [11/50], Step [443/735], Loss: 0.3205\n",
      "Epoch [11/50], Step [444/735], Loss: 0.2411\n",
      "Epoch [11/50], Step [445/735], Loss: 0.2980\n",
      "Epoch [11/50], Step [446/735], Loss: 0.5222\n",
      "Epoch [11/50], Step [447/735], Loss: 0.3059\n",
      "Epoch [11/50], Step [448/735], Loss: 0.1555\n",
      "Epoch [11/50], Step [449/735], Loss: 0.4004\n",
      "Epoch [11/50], Step [450/735], Loss: 0.0821\n",
      "Epoch [11/50], Step [451/735], Loss: 0.3868\n",
      "Epoch [11/50], Step [452/735], Loss: 0.5177\n",
      "Epoch [11/50], Step [453/735], Loss: 0.2158\n",
      "Epoch [11/50], Step [454/735], Loss: 0.4663\n",
      "Epoch [11/50], Step [455/735], Loss: 0.3636\n",
      "Epoch [11/50], Step [456/735], Loss: 0.7447\n",
      "Epoch [11/50], Step [457/735], Loss: 0.7241\n",
      "Epoch [11/50], Step [458/735], Loss: 0.2842\n",
      "Epoch [11/50], Step [459/735], Loss: 1.5272\n",
      "Epoch [11/50], Step [460/735], Loss: 0.1358\n",
      "Epoch [11/50], Step [461/735], Loss: 0.1424\n",
      "Epoch [11/50], Step [462/735], Loss: 0.5309\n",
      "Epoch [11/50], Step [463/735], Loss: 0.3107\n",
      "Epoch [11/50], Step [464/735], Loss: 1.3669\n",
      "Epoch [11/50], Step [465/735], Loss: 0.1366\n",
      "Epoch [11/50], Step [466/735], Loss: 0.0985\n",
      "Epoch [11/50], Step [467/735], Loss: 0.0971\n",
      "Epoch [11/50], Step [468/735], Loss: 0.4996\n",
      "Epoch [11/50], Step [469/735], Loss: 1.5457\n",
      "Epoch [11/50], Step [470/735], Loss: 1.6431\n",
      "Epoch [11/50], Step [471/735], Loss: 0.2593\n",
      "Epoch [11/50], Step [472/735], Loss: 0.4097\n",
      "Epoch [11/50], Step [473/735], Loss: 0.6086\n",
      "Epoch [11/50], Step [474/735], Loss: 0.3658\n",
      "Epoch [11/50], Step [475/735], Loss: 0.6087\n",
      "Epoch [11/50], Step [476/735], Loss: 0.8802\n",
      "Epoch [11/50], Step [477/735], Loss: 0.4211\n",
      "Epoch [11/50], Step [478/735], Loss: 0.3654\n",
      "Epoch [11/50], Step [479/735], Loss: 0.0896\n",
      "Epoch [11/50], Step [480/735], Loss: 0.8716\n",
      "Epoch [11/50], Step [481/735], Loss: 0.2194\n",
      "Epoch [11/50], Step [482/735], Loss: 0.7964\n",
      "Epoch [11/50], Step [483/735], Loss: 4.4595\n",
      "Epoch [11/50], Step [484/735], Loss: 0.3161\n",
      "Epoch [11/50], Step [485/735], Loss: 0.3089\n",
      "Epoch [11/50], Step [486/735], Loss: 0.2009\n",
      "Epoch [11/50], Step [487/735], Loss: 0.7216\n",
      "Epoch [11/50], Step [488/735], Loss: 0.4488\n",
      "Epoch [11/50], Step [489/735], Loss: 0.2940\n",
      "Epoch [11/50], Step [490/735], Loss: 0.2473\n",
      "Epoch [11/50], Step [491/735], Loss: 0.6523\n",
      "Epoch [11/50], Step [492/735], Loss: 0.4437\n",
      "Epoch [11/50], Step [493/735], Loss: 0.1916\n",
      "Epoch [11/50], Step [494/735], Loss: 0.2457\n",
      "Epoch [11/50], Step [495/735], Loss: 2.9865\n",
      "Epoch [11/50], Step [496/735], Loss: 0.1570\n",
      "Epoch [11/50], Step [497/735], Loss: 0.8939\n",
      "Epoch [11/50], Step [498/735], Loss: 0.3030\n",
      "Epoch [11/50], Step [499/735], Loss: 0.3104\n",
      "Epoch [11/50], Step [500/735], Loss: 0.6967\n",
      "Epoch [11/50], Step [501/735], Loss: 0.4420\n",
      "Epoch [11/50], Step [502/735], Loss: 0.2552\n",
      "Epoch [11/50], Step [503/735], Loss: 1.3678\n",
      "Epoch [11/50], Step [504/735], Loss: 1.0601\n",
      "Epoch [11/50], Step [505/735], Loss: 0.3681\n",
      "Epoch [11/50], Step [506/735], Loss: 0.6343\n",
      "Epoch [11/50], Step [507/735], Loss: 0.4161\n",
      "Epoch [11/50], Step [508/735], Loss: 0.6502\n",
      "Epoch [11/50], Step [509/735], Loss: 1.2921\n",
      "Epoch [11/50], Step [510/735], Loss: 0.1967\n",
      "Epoch [11/50], Step [511/735], Loss: 0.4491\n",
      "Epoch [11/50], Step [512/735], Loss: 0.1951\n",
      "Epoch [11/50], Step [513/735], Loss: 0.2944\n",
      "Epoch [11/50], Step [514/735], Loss: 0.3773\n",
      "Epoch [11/50], Step [515/735], Loss: 0.1615\n",
      "Epoch [11/50], Step [516/735], Loss: 0.1858\n",
      "Epoch [11/50], Step [517/735], Loss: 0.2315\n",
      "Epoch [11/50], Step [518/735], Loss: 0.4951\n",
      "Epoch [11/50], Step [519/735], Loss: 0.6542\n",
      "Epoch [11/50], Step [520/735], Loss: 0.6261\n",
      "Epoch [11/50], Step [521/735], Loss: 0.5759\n",
      "Epoch [11/50], Step [522/735], Loss: 0.1551\n",
      "Epoch [11/50], Step [523/735], Loss: 0.4312\n",
      "Epoch [11/50], Step [524/735], Loss: 0.6746\n",
      "Epoch [11/50], Step [525/735], Loss: 0.9700\n",
      "Epoch [11/50], Step [526/735], Loss: 0.4100\n",
      "Epoch [11/50], Step [527/735], Loss: 0.1992\n",
      "Epoch [11/50], Step [528/735], Loss: 0.1522\n",
      "Epoch [11/50], Step [529/735], Loss: 0.2343\n",
      "Epoch [11/50], Step [530/735], Loss: 0.2328\n",
      "Epoch [11/50], Step [531/735], Loss: 0.4008\n",
      "Epoch [11/50], Step [532/735], Loss: 0.3568\n",
      "Epoch [11/50], Step [533/735], Loss: 0.2435\n",
      "Epoch [11/50], Step [534/735], Loss: 0.4454\n",
      "Epoch [11/50], Step [535/735], Loss: 1.4712\n",
      "Epoch [11/50], Step [536/735], Loss: 0.1660\n",
      "Epoch [11/50], Step [537/735], Loss: 0.4158\n",
      "Epoch [11/50], Step [538/735], Loss: 0.2692\n",
      "Epoch [11/50], Step [539/735], Loss: 0.5199\n",
      "Epoch [11/50], Step [540/735], Loss: 0.0909\n",
      "Epoch [11/50], Step [541/735], Loss: 0.5018\n",
      "Epoch [11/50], Step [542/735], Loss: 0.3233\n",
      "Epoch [11/50], Step [543/735], Loss: 0.2365\n",
      "Epoch [11/50], Step [544/735], Loss: 0.1765\n",
      "Epoch [11/50], Step [545/735], Loss: 0.2670\n",
      "Epoch [11/50], Step [546/735], Loss: 0.3137\n",
      "Epoch [11/50], Step [547/735], Loss: 0.8005\n",
      "Epoch [11/50], Step [548/735], Loss: 0.2537\n",
      "Epoch [11/50], Step [549/735], Loss: 0.3837\n",
      "Epoch [11/50], Step [550/735], Loss: 0.7762\n",
      "Epoch [11/50], Step [551/735], Loss: 0.1145\n",
      "Epoch [11/50], Step [552/735], Loss: 0.2499\n",
      "Epoch [11/50], Step [553/735], Loss: 0.2755\n",
      "Epoch [11/50], Step [554/735], Loss: 0.1397\n",
      "Epoch [11/50], Step [555/735], Loss: 0.8212\n",
      "Epoch [11/50], Step [556/735], Loss: 2.1900\n",
      "Epoch [11/50], Step [557/735], Loss: 0.1405\n",
      "Epoch [11/50], Step [558/735], Loss: 0.4229\n",
      "Epoch [11/50], Step [559/735], Loss: 0.3558\n",
      "Epoch [11/50], Step [560/735], Loss: 0.2200\n",
      "Epoch [11/50], Step [561/735], Loss: 0.4491\n",
      "Epoch [11/50], Step [562/735], Loss: 0.1988\n",
      "Epoch [11/50], Step [563/735], Loss: 0.2440\n",
      "Epoch [11/50], Step [564/735], Loss: 0.1048\n",
      "Epoch [11/50], Step [565/735], Loss: 0.3880\n",
      "Epoch [11/50], Step [566/735], Loss: 0.3675\n",
      "Epoch [11/50], Step [567/735], Loss: 0.2360\n",
      "Epoch [11/50], Step [568/735], Loss: 0.7839\n",
      "Epoch [11/50], Step [569/735], Loss: 0.2778\n",
      "Epoch [11/50], Step [570/735], Loss: 0.1312\n",
      "Epoch [11/50], Step [571/735], Loss: 0.6591\n",
      "Epoch [11/50], Step [572/735], Loss: 0.4615\n",
      "Epoch [11/50], Step [573/735], Loss: 0.3059\n",
      "Epoch [11/50], Step [574/735], Loss: 0.0983\n",
      "Epoch [11/50], Step [575/735], Loss: 0.7212\n",
      "Epoch [11/50], Step [576/735], Loss: 1.9007\n",
      "Epoch [11/50], Step [577/735], Loss: 0.2797\n",
      "Epoch [11/50], Step [578/735], Loss: 0.4643\n",
      "Epoch [11/50], Step [579/735], Loss: 0.6352\n",
      "Epoch [11/50], Step [580/735], Loss: 1.3382\n",
      "Epoch [11/50], Step [581/735], Loss: 0.1703\n",
      "Epoch [11/50], Step [582/735], Loss: 0.3198\n",
      "Epoch [11/50], Step [583/735], Loss: 0.3529\n",
      "Epoch [11/50], Step [584/735], Loss: 0.2966\n",
      "Epoch [11/50], Step [585/735], Loss: 0.9052\n",
      "Epoch [11/50], Step [586/735], Loss: 1.3945\n",
      "Epoch [11/50], Step [587/735], Loss: 0.6027\n",
      "Epoch [11/50], Step [588/735], Loss: 0.5814\n",
      "Epoch [11/50], Step [589/735], Loss: 0.2121\n",
      "Epoch [11/50], Step [590/735], Loss: 0.8099\n",
      "Epoch [11/50], Step [591/735], Loss: 0.2428\n",
      "Epoch [11/50], Step [592/735], Loss: 0.2977\n",
      "Epoch [11/50], Step [593/735], Loss: 0.2024\n",
      "Epoch [11/50], Step [594/735], Loss: 0.2131\n",
      "Epoch [11/50], Step [595/735], Loss: 0.8814\n",
      "Epoch [11/50], Step [596/735], Loss: 0.4480\n",
      "Epoch [11/50], Step [597/735], Loss: 0.1059\n",
      "Epoch [11/50], Step [598/735], Loss: 0.9636\n",
      "Epoch [11/50], Step [599/735], Loss: 0.4051\n",
      "Epoch [11/50], Step [600/735], Loss: 0.5103\n",
      "Epoch [11/50], Step [601/735], Loss: 0.0988\n",
      "Epoch [11/50], Step [602/735], Loss: 0.1426\n",
      "Epoch [11/50], Step [603/735], Loss: 0.2990\n",
      "Epoch [11/50], Step [604/735], Loss: 0.4337\n",
      "Epoch [11/50], Step [605/735], Loss: 0.3244\n",
      "Epoch [11/50], Step [606/735], Loss: 1.3957\n",
      "Epoch [11/50], Step [607/735], Loss: 0.5669\n",
      "Epoch [11/50], Step [608/735], Loss: 0.3319\n",
      "Epoch [11/50], Step [609/735], Loss: 0.2311\n",
      "Epoch [11/50], Step [610/735], Loss: 0.1131\n",
      "Epoch [11/50], Step [611/735], Loss: 0.2222\n",
      "Epoch [11/50], Step [612/735], Loss: 0.7439\n",
      "Epoch [11/50], Step [613/735], Loss: 0.1741\n",
      "Epoch [11/50], Step [614/735], Loss: 0.2033\n",
      "Epoch [11/50], Step [615/735], Loss: 0.3358\n",
      "Epoch [11/50], Step [616/735], Loss: 0.2852\n",
      "Epoch [11/50], Step [617/735], Loss: 0.5342\n",
      "Epoch [11/50], Step [618/735], Loss: 0.4109\n",
      "Epoch [11/50], Step [619/735], Loss: 0.2667\n",
      "Epoch [11/50], Step [620/735], Loss: 0.6281\n",
      "Epoch [11/50], Step [621/735], Loss: 0.5279\n",
      "Epoch [11/50], Step [622/735], Loss: 0.1725\n",
      "Epoch [11/50], Step [623/735], Loss: 0.3708\n",
      "Epoch [11/50], Step [624/735], Loss: 0.3701\n",
      "Epoch [11/50], Step [625/735], Loss: 1.0862\n",
      "Epoch [11/50], Step [626/735], Loss: 0.1599\n",
      "Epoch [11/50], Step [627/735], Loss: 0.3322\n",
      "Epoch [11/50], Step [628/735], Loss: 0.1964\n",
      "Epoch [11/50], Step [629/735], Loss: 0.2193\n",
      "Epoch [11/50], Step [630/735], Loss: 0.2838\n",
      "Epoch [11/50], Step [631/735], Loss: 0.6553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Step [632/735], Loss: 0.7125\n",
      "Epoch [11/50], Step [633/735], Loss: 0.7811\n",
      "Epoch [11/50], Step [634/735], Loss: 0.1127\n",
      "Epoch [11/50], Step [635/735], Loss: 1.8710\n",
      "Epoch [11/50], Step [636/735], Loss: 0.4423\n",
      "Epoch [11/50], Step [637/735], Loss: 0.4944\n",
      "Epoch [11/50], Step [638/735], Loss: 0.1759\n",
      "Epoch [11/50], Step [639/735], Loss: 0.2961\n",
      "Epoch [11/50], Step [640/735], Loss: 0.3983\n",
      "Epoch [11/50], Step [641/735], Loss: 0.2934\n",
      "Epoch [11/50], Step [642/735], Loss: 0.3682\n",
      "Epoch [11/50], Step [643/735], Loss: 0.5443\n",
      "Epoch [11/50], Step [644/735], Loss: 0.4147\n",
      "Epoch [11/50], Step [645/735], Loss: 0.3324\n",
      "Epoch [11/50], Step [646/735], Loss: 0.6275\n",
      "Epoch [11/50], Step [647/735], Loss: 0.2255\n",
      "Epoch [11/50], Step [648/735], Loss: 0.5565\n",
      "Epoch [11/50], Step [649/735], Loss: 0.5314\n",
      "Epoch [11/50], Step [650/735], Loss: 0.1653\n",
      "Epoch [11/50], Step [651/735], Loss: 0.1297\n",
      "Epoch [11/50], Step [652/735], Loss: 1.0651\n",
      "Epoch [11/50], Step [653/735], Loss: 0.3386\n",
      "Epoch [11/50], Step [654/735], Loss: 0.7552\n",
      "Epoch [11/50], Step [655/735], Loss: 0.3047\n",
      "Epoch [11/50], Step [656/735], Loss: 0.4918\n",
      "Epoch [11/50], Step [657/735], Loss: 1.1562\n",
      "Epoch [11/50], Step [658/735], Loss: 0.3640\n",
      "Epoch [11/50], Step [659/735], Loss: 0.1464\n",
      "Epoch [11/50], Step [660/735], Loss: 0.8404\n",
      "Epoch [11/50], Step [661/735], Loss: 0.7498\n",
      "Epoch [11/50], Step [662/735], Loss: 0.3242\n",
      "Epoch [11/50], Step [663/735], Loss: 0.4580\n",
      "Epoch [11/50], Step [664/735], Loss: 0.6635\n",
      "Epoch [11/50], Step [665/735], Loss: 0.3466\n",
      "Epoch [11/50], Step [666/735], Loss: 0.4638\n",
      "Epoch [11/50], Step [667/735], Loss: 1.1597\n",
      "Epoch [11/50], Step [668/735], Loss: 0.5884\n",
      "Epoch [11/50], Step [669/735], Loss: 1.8059\n",
      "Epoch [11/50], Step [670/735], Loss: 0.4933\n",
      "Epoch [11/50], Step [671/735], Loss: 0.9498\n",
      "Epoch [11/50], Step [672/735], Loss: 0.1168\n",
      "Epoch [11/50], Step [673/735], Loss: 0.2520\n",
      "Epoch [11/50], Step [674/735], Loss: 0.4904\n",
      "Epoch [11/50], Step [675/735], Loss: 0.4242\n",
      "Epoch [11/50], Step [676/735], Loss: 1.0054\n",
      "Epoch [11/50], Step [677/735], Loss: 0.2962\n",
      "Epoch [11/50], Step [678/735], Loss: 0.3043\n",
      "Epoch [11/50], Step [679/735], Loss: 0.4026\n",
      "Epoch [11/50], Step [680/735], Loss: 0.1912\n",
      "Epoch [11/50], Step [681/735], Loss: 0.4528\n",
      "Epoch [11/50], Step [682/735], Loss: 0.5209\n",
      "Epoch [11/50], Step [683/735], Loss: 0.7260\n",
      "Epoch [11/50], Step [684/735], Loss: 0.1229\n",
      "Epoch [11/50], Step [685/735], Loss: 0.3330\n",
      "Epoch [11/50], Step [686/735], Loss: 0.3628\n",
      "Epoch [11/50], Step [687/735], Loss: 0.1706\n",
      "Epoch [11/50], Step [688/735], Loss: 0.4710\n",
      "Epoch [11/50], Step [689/735], Loss: 0.7086\n",
      "Epoch [11/50], Step [690/735], Loss: 0.5994\n",
      "Epoch [11/50], Step [691/735], Loss: 0.5409\n",
      "Epoch [11/50], Step [692/735], Loss: 0.2169\n",
      "Epoch [11/50], Step [693/735], Loss: 0.3504\n",
      "Epoch [11/50], Step [694/735], Loss: 0.2647\n",
      "Epoch [11/50], Step [695/735], Loss: 0.1831\n",
      "Epoch [11/50], Step [696/735], Loss: 0.1672\n",
      "Epoch [11/50], Step [697/735], Loss: 0.2047\n",
      "Epoch [11/50], Step [698/735], Loss: 0.1593\n",
      "Epoch [11/50], Step [699/735], Loss: 0.2243\n",
      "Epoch [11/50], Step [700/735], Loss: 0.2702\n",
      "Epoch [11/50], Step [701/735], Loss: 0.2807\n",
      "Epoch [11/50], Step [702/735], Loss: 0.8932\n",
      "Epoch [11/50], Step [703/735], Loss: 0.1618\n",
      "Epoch [11/50], Step [704/735], Loss: 0.3641\n",
      "Epoch [11/50], Step [705/735], Loss: 0.2376\n",
      "Epoch [11/50], Step [706/735], Loss: 0.2900\n",
      "Epoch [11/50], Step [707/735], Loss: 0.1717\n",
      "Epoch [11/50], Step [708/735], Loss: 1.1221\n",
      "Epoch [11/50], Step [709/735], Loss: 0.4674\n",
      "Epoch [11/50], Step [710/735], Loss: 0.8402\n",
      "Epoch [11/50], Step [711/735], Loss: 0.3659\n",
      "Epoch [11/50], Step [712/735], Loss: 0.1079\n",
      "Epoch [11/50], Step [713/735], Loss: 0.8793\n",
      "Epoch [11/50], Step [714/735], Loss: 1.8978\n",
      "Epoch [11/50], Step [715/735], Loss: 0.3402\n",
      "Epoch [11/50], Step [716/735], Loss: 0.6441\n",
      "Epoch [11/50], Step [717/735], Loss: 0.4922\n",
      "Epoch [11/50], Step [718/735], Loss: 1.2017\n",
      "Epoch [11/50], Step [719/735], Loss: 0.1132\n",
      "Epoch [11/50], Step [720/735], Loss: 1.0191\n",
      "Epoch [11/50], Step [721/735], Loss: 0.6362\n",
      "Epoch [11/50], Step [722/735], Loss: 0.3879\n",
      "Epoch [11/50], Step [723/735], Loss: 0.3399\n",
      "Epoch [11/50], Step [724/735], Loss: 0.4254\n",
      "Epoch [11/50], Step [725/735], Loss: 0.1343\n",
      "Epoch [11/50], Step [726/735], Loss: 0.3312\n",
      "Epoch [11/50], Step [727/735], Loss: 0.3811\n",
      "Epoch [11/50], Step [728/735], Loss: 0.0929\n",
      "Epoch [11/50], Step [729/735], Loss: 0.7218\n",
      "Epoch [11/50], Step [730/735], Loss: 0.3993\n",
      "Epoch [11/50], Step [731/735], Loss: 0.4767\n",
      "Epoch [11/50], Step [732/735], Loss: 0.8885\n",
      "Epoch [11/50], Step [733/735], Loss: 2.3634\n",
      "Epoch [11/50], Step [734/735], Loss: 0.8604\n",
      "Epoch [11/50], Step [735/735], Loss: 0.7535\n",
      "Epoch [12/50], Step [1/735], Loss: 0.5281\n",
      "Epoch [12/50], Step [2/735], Loss: 0.3962\n",
      "Epoch [12/50], Step [3/735], Loss: 0.5421\n",
      "Epoch [12/50], Step [4/735], Loss: 0.5137\n",
      "Epoch [12/50], Step [5/735], Loss: 0.4797\n",
      "Epoch [12/50], Step [6/735], Loss: 0.2557\n",
      "Epoch [12/50], Step [7/735], Loss: 0.5464\n",
      "Epoch [12/50], Step [8/735], Loss: 0.4103\n",
      "Epoch [12/50], Step [9/735], Loss: 0.4730\n",
      "Epoch [12/50], Step [10/735], Loss: 0.1695\n",
      "Epoch [12/50], Step [11/735], Loss: 0.1336\n",
      "Epoch [12/50], Step [12/735], Loss: 0.6012\n",
      "Epoch [12/50], Step [13/735], Loss: 0.0948\n",
      "Epoch [12/50], Step [14/735], Loss: 1.2685\n",
      "Epoch [12/50], Step [15/735], Loss: 0.2630\n",
      "Epoch [12/50], Step [16/735], Loss: 0.4460\n",
      "Epoch [12/50], Step [17/735], Loss: 0.2203\n",
      "Epoch [12/50], Step [18/735], Loss: 0.1737\n",
      "Epoch [12/50], Step [19/735], Loss: 0.6968\n",
      "Epoch [12/50], Step [20/735], Loss: 0.3486\n",
      "Epoch [12/50], Step [21/735], Loss: 0.3824\n",
      "Epoch [12/50], Step [22/735], Loss: 0.1870\n",
      "Epoch [12/50], Step [23/735], Loss: 0.9196\n",
      "Epoch [12/50], Step [24/735], Loss: 0.4923\n",
      "Epoch [12/50], Step [25/735], Loss: 0.4231\n",
      "Epoch [12/50], Step [26/735], Loss: 0.2624\n",
      "Epoch [12/50], Step [27/735], Loss: 0.3382\n",
      "Epoch [12/50], Step [28/735], Loss: 0.2325\n",
      "Epoch [12/50], Step [29/735], Loss: 0.4624\n",
      "Epoch [12/50], Step [30/735], Loss: 0.5675\n",
      "Epoch [12/50], Step [31/735], Loss: 1.2338\n",
      "Epoch [12/50], Step [32/735], Loss: 0.1685\n",
      "Epoch [12/50], Step [33/735], Loss: 0.2248\n",
      "Epoch [12/50], Step [34/735], Loss: 0.3743\n",
      "Epoch [12/50], Step [35/735], Loss: 0.1473\n",
      "Epoch [12/50], Step [36/735], Loss: 0.5088\n",
      "Epoch [12/50], Step [37/735], Loss: 0.3698\n",
      "Epoch [12/50], Step [38/735], Loss: 0.3633\n",
      "Epoch [12/50], Step [39/735], Loss: 0.3632\n",
      "Epoch [12/50], Step [40/735], Loss: 0.1889\n",
      "Epoch [12/50], Step [41/735], Loss: 0.2465\n",
      "Epoch [12/50], Step [42/735], Loss: 0.1454\n",
      "Epoch [12/50], Step [43/735], Loss: 0.4638\n",
      "Epoch [12/50], Step [44/735], Loss: 0.4157\n",
      "Epoch [12/50], Step [45/735], Loss: 0.1307\n",
      "Epoch [12/50], Step [46/735], Loss: 0.8904\n",
      "Epoch [12/50], Step [47/735], Loss: 0.1730\n",
      "Epoch [12/50], Step [48/735], Loss: 0.3656\n",
      "Epoch [12/50], Step [49/735], Loss: 0.3630\n",
      "Epoch [12/50], Step [50/735], Loss: 0.3922\n",
      "Epoch [12/50], Step [51/735], Loss: 0.1273\n",
      "Epoch [12/50], Step [52/735], Loss: 0.4074\n",
      "Epoch [12/50], Step [53/735], Loss: 0.3059\n",
      "Epoch [12/50], Step [54/735], Loss: 0.2460\n",
      "Epoch [12/50], Step [55/735], Loss: 0.2662\n",
      "Epoch [12/50], Step [56/735], Loss: 0.4369\n",
      "Epoch [12/50], Step [57/735], Loss: 0.1988\n",
      "Epoch [12/50], Step [58/735], Loss: 0.1449\n",
      "Epoch [12/50], Step [59/735], Loss: 0.3233\n",
      "Epoch [12/50], Step [60/735], Loss: 0.4475\n",
      "Epoch [12/50], Step [61/735], Loss: 0.2399\n",
      "Epoch [12/50], Step [62/735], Loss: 0.2260\n",
      "Epoch [12/50], Step [63/735], Loss: 0.6641\n",
      "Epoch [12/50], Step [64/735], Loss: 5.5497\n",
      "Epoch [12/50], Step [65/735], Loss: 0.6726\n",
      "Epoch [12/50], Step [66/735], Loss: 0.6755\n",
      "Epoch [12/50], Step [67/735], Loss: 0.3078\n",
      "Epoch [12/50], Step [68/735], Loss: 0.7434\n",
      "Epoch [12/50], Step [69/735], Loss: 0.4263\n",
      "Epoch [12/50], Step [70/735], Loss: 0.3072\n",
      "Epoch [12/50], Step [71/735], Loss: 0.3768\n",
      "Epoch [12/50], Step [72/735], Loss: 0.3170\n",
      "Epoch [12/50], Step [73/735], Loss: 0.4378\n",
      "Epoch [12/50], Step [74/735], Loss: 0.7789\n",
      "Epoch [12/50], Step [75/735], Loss: 0.3639\n",
      "Epoch [12/50], Step [76/735], Loss: 0.6406\n",
      "Epoch [12/50], Step [77/735], Loss: 0.2348\n",
      "Epoch [12/50], Step [78/735], Loss: 0.1734\n",
      "Epoch [12/50], Step [79/735], Loss: 0.5454\n",
      "Epoch [12/50], Step [80/735], Loss: 0.1614\n",
      "Epoch [12/50], Step [81/735], Loss: 0.3994\n",
      "Epoch [12/50], Step [82/735], Loss: 0.0656\n",
      "Epoch [12/50], Step [83/735], Loss: 0.4040\n",
      "Epoch [12/50], Step [84/735], Loss: 0.3620\n",
      "Epoch [12/50], Step [85/735], Loss: 0.1822\n",
      "Epoch [12/50], Step [86/735], Loss: 0.3991\n",
      "Epoch [12/50], Step [87/735], Loss: 0.4004\n",
      "Epoch [12/50], Step [88/735], Loss: 0.1786\n",
      "Epoch [12/50], Step [89/735], Loss: 1.6837\n",
      "Epoch [12/50], Step [90/735], Loss: 0.1544\n",
      "Epoch [12/50], Step [91/735], Loss: 0.1764\n",
      "Epoch [12/50], Step [92/735], Loss: 0.5278\n",
      "Epoch [12/50], Step [93/735], Loss: 0.8374\n",
      "Epoch [12/50], Step [94/735], Loss: 0.3148\n",
      "Epoch [12/50], Step [95/735], Loss: 0.2867\n",
      "Epoch [12/50], Step [96/735], Loss: 0.4257\n",
      "Epoch [12/50], Step [97/735], Loss: 0.4968\n",
      "Epoch [12/50], Step [98/735], Loss: 0.4646\n",
      "Epoch [12/50], Step [99/735], Loss: 0.3188\n",
      "Epoch [12/50], Step [100/735], Loss: 0.5387\n",
      "Epoch [12/50], Step [101/735], Loss: 0.5342\n",
      "Epoch [12/50], Step [102/735], Loss: 1.0583\n",
      "Epoch [12/50], Step [103/735], Loss: 0.1561\n",
      "Epoch [12/50], Step [104/735], Loss: 0.6790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Step [105/735], Loss: 0.5356\n",
      "Epoch [12/50], Step [106/735], Loss: 0.1128\n",
      "Epoch [12/50], Step [107/735], Loss: 0.1963\n",
      "Epoch [12/50], Step [108/735], Loss: 0.2539\n",
      "Epoch [12/50], Step [109/735], Loss: 0.3459\n",
      "Epoch [12/50], Step [110/735], Loss: 0.3797\n",
      "Epoch [12/50], Step [111/735], Loss: 0.5449\n",
      "Epoch [12/50], Step [112/735], Loss: 0.3451\n",
      "Epoch [12/50], Step [113/735], Loss: 0.2303\n",
      "Epoch [12/50], Step [114/735], Loss: 0.3705\n",
      "Epoch [12/50], Step [115/735], Loss: 0.1469\n",
      "Epoch [12/50], Step [116/735], Loss: 0.3032\n",
      "Epoch [12/50], Step [117/735], Loss: 0.1829\n",
      "Epoch [12/50], Step [118/735], Loss: 0.2178\n",
      "Epoch [12/50], Step [119/735], Loss: 0.3522\n",
      "Epoch [12/50], Step [120/735], Loss: 0.3793\n",
      "Epoch [12/50], Step [121/735], Loss: 0.8660\n",
      "Epoch [12/50], Step [122/735], Loss: 0.3310\n",
      "Epoch [12/50], Step [123/735], Loss: 0.3369\n",
      "Epoch [12/50], Step [124/735], Loss: 0.1689\n",
      "Epoch [12/50], Step [125/735], Loss: 0.9805\n",
      "Epoch [12/50], Step [126/735], Loss: 0.8736\n",
      "Epoch [12/50], Step [127/735], Loss: 0.2913\n",
      "Epoch [12/50], Step [128/735], Loss: 0.2882\n",
      "Epoch [12/50], Step [129/735], Loss: 0.3925\n",
      "Epoch [12/50], Step [130/735], Loss: 0.1989\n",
      "Epoch [12/50], Step [131/735], Loss: 0.1197\n",
      "Epoch [12/50], Step [132/735], Loss: 0.2066\n",
      "Epoch [12/50], Step [133/735], Loss: 0.1398\n",
      "Epoch [12/50], Step [134/735], Loss: 0.4055\n",
      "Epoch [12/50], Step [135/735], Loss: 1.0524\n",
      "Epoch [12/50], Step [136/735], Loss: 1.0013\n",
      "Epoch [12/50], Step [137/735], Loss: 0.6527\n",
      "Epoch [12/50], Step [138/735], Loss: 0.3935\n",
      "Epoch [12/50], Step [139/735], Loss: 0.4612\n",
      "Epoch [12/50], Step [140/735], Loss: 0.1301\n",
      "Epoch [12/50], Step [141/735], Loss: 0.1540\n",
      "Epoch [12/50], Step [142/735], Loss: 0.5911\n",
      "Epoch [12/50], Step [143/735], Loss: 0.5640\n",
      "Epoch [12/50], Step [144/735], Loss: 0.1981\n",
      "Epoch [12/50], Step [145/735], Loss: 0.7260\n",
      "Epoch [12/50], Step [146/735], Loss: 0.1101\n",
      "Epoch [12/50], Step [147/735], Loss: 0.2955\n",
      "Epoch [12/50], Step [148/735], Loss: 0.6091\n",
      "Epoch [12/50], Step [149/735], Loss: 0.3423\n",
      "Epoch [12/50], Step [150/735], Loss: 0.1777\n",
      "Epoch [12/50], Step [151/735], Loss: 0.4550\n",
      "Epoch [12/50], Step [152/735], Loss: 0.2908\n",
      "Epoch [12/50], Step [153/735], Loss: 0.1306\n",
      "Epoch [12/50], Step [154/735], Loss: 0.1510\n",
      "Epoch [12/50], Step [155/735], Loss: 0.7281\n",
      "Epoch [12/50], Step [156/735], Loss: 0.5670\n",
      "Epoch [12/50], Step [157/735], Loss: 0.2578\n",
      "Epoch [12/50], Step [158/735], Loss: 0.4095\n",
      "Epoch [12/50], Step [159/735], Loss: 0.1180\n",
      "Epoch [12/50], Step [160/735], Loss: 2.1038\n",
      "Epoch [12/50], Step [161/735], Loss: 0.5373\n",
      "Epoch [12/50], Step [162/735], Loss: 0.1613\n",
      "Epoch [12/50], Step [163/735], Loss: 0.5761\n",
      "Epoch [12/50], Step [164/735], Loss: 0.1646\n",
      "Epoch [12/50], Step [165/735], Loss: 0.4288\n",
      "Epoch [12/50], Step [166/735], Loss: 0.6601\n",
      "Epoch [12/50], Step [167/735], Loss: 0.2548\n",
      "Epoch [12/50], Step [168/735], Loss: 0.2762\n",
      "Epoch [12/50], Step [169/735], Loss: 0.3747\n",
      "Epoch [12/50], Step [170/735], Loss: 0.5359\n",
      "Epoch [12/50], Step [171/735], Loss: 0.1888\n",
      "Epoch [12/50], Step [172/735], Loss: 0.4436\n",
      "Epoch [12/50], Step [173/735], Loss: 0.7273\n",
      "Epoch [12/50], Step [174/735], Loss: 0.5211\n",
      "Epoch [12/50], Step [175/735], Loss: 0.1833\n",
      "Epoch [12/50], Step [176/735], Loss: 0.3443\n",
      "Epoch [12/50], Step [177/735], Loss: 0.3625\n",
      "Epoch [12/50], Step [178/735], Loss: 0.2628\n",
      "Epoch [12/50], Step [179/735], Loss: 0.7610\n",
      "Epoch [12/50], Step [180/735], Loss: 0.7294\n",
      "Epoch [12/50], Step [181/735], Loss: 0.5697\n",
      "Epoch [12/50], Step [182/735], Loss: 0.3291\n",
      "Epoch [12/50], Step [183/735], Loss: 0.3078\n",
      "Epoch [12/50], Step [184/735], Loss: 0.7563\n",
      "Epoch [12/50], Step [185/735], Loss: 0.0853\n",
      "Epoch [12/50], Step [186/735], Loss: 0.2902\n",
      "Epoch [12/50], Step [187/735], Loss: 0.4867\n",
      "Epoch [12/50], Step [188/735], Loss: 0.2664\n",
      "Epoch [12/50], Step [189/735], Loss: 0.2226\n",
      "Epoch [12/50], Step [190/735], Loss: 0.6891\n",
      "Epoch [12/50], Step [191/735], Loss: 0.6871\n",
      "Epoch [12/50], Step [192/735], Loss: 0.1572\n",
      "Epoch [12/50], Step [193/735], Loss: 0.2940\n",
      "Epoch [12/50], Step [194/735], Loss: 0.2784\n",
      "Epoch [12/50], Step [195/735], Loss: 0.0950\n",
      "Epoch [12/50], Step [196/735], Loss: 0.4583\n",
      "Epoch [12/50], Step [197/735], Loss: 0.1434\n",
      "Epoch [12/50], Step [198/735], Loss: 0.2599\n",
      "Epoch [12/50], Step [199/735], Loss: 0.2059\n",
      "Epoch [12/50], Step [200/735], Loss: 0.5767\n",
      "Epoch [12/50], Step [201/735], Loss: 0.7725\n",
      "Epoch [12/50], Step [202/735], Loss: 0.1934\n",
      "Epoch [12/50], Step [203/735], Loss: 0.4347\n",
      "Epoch [12/50], Step [204/735], Loss: 0.7053\n",
      "Epoch [12/50], Step [205/735], Loss: 0.3026\n",
      "Epoch [12/50], Step [206/735], Loss: 0.2662\n",
      "Epoch [12/50], Step [207/735], Loss: 0.4243\n",
      "Epoch [12/50], Step [208/735], Loss: 0.1586\n",
      "Epoch [12/50], Step [209/735], Loss: 1.9757\n",
      "Epoch [12/50], Step [210/735], Loss: 0.2657\n",
      "Epoch [12/50], Step [211/735], Loss: 0.3242\n",
      "Epoch [12/50], Step [212/735], Loss: 0.4892\n",
      "Epoch [12/50], Step [213/735], Loss: 0.3328\n",
      "Epoch [12/50], Step [214/735], Loss: 0.3322\n",
      "Epoch [12/50], Step [215/735], Loss: 0.0987\n",
      "Epoch [12/50], Step [216/735], Loss: 0.4829\n",
      "Epoch [12/50], Step [217/735], Loss: 0.1325\n",
      "Epoch [12/50], Step [218/735], Loss: 1.2291\n",
      "Epoch [12/50], Step [219/735], Loss: 0.1597\n",
      "Epoch [12/50], Step [220/735], Loss: 0.3583\n",
      "Epoch [12/50], Step [221/735], Loss: 0.8396\n",
      "Epoch [12/50], Step [222/735], Loss: 0.8779\n",
      "Epoch [12/50], Step [223/735], Loss: 0.3087\n",
      "Epoch [12/50], Step [224/735], Loss: 0.0836\n",
      "Epoch [12/50], Step [225/735], Loss: 0.0662\n",
      "Epoch [12/50], Step [226/735], Loss: 0.2779\n",
      "Epoch [12/50], Step [227/735], Loss: 0.1923\n",
      "Epoch [12/50], Step [228/735], Loss: 0.3532\n",
      "Epoch [12/50], Step [229/735], Loss: 0.0900\n",
      "Epoch [12/50], Step [230/735], Loss: 0.2574\n",
      "Epoch [12/50], Step [231/735], Loss: 0.3841\n",
      "Epoch [12/50], Step [232/735], Loss: 0.3767\n",
      "Epoch [12/50], Step [233/735], Loss: 0.0995\n",
      "Epoch [12/50], Step [234/735], Loss: 1.0628\n",
      "Epoch [12/50], Step [235/735], Loss: 1.1912\n",
      "Epoch [12/50], Step [236/735], Loss: 1.2049\n",
      "Epoch [12/50], Step [237/735], Loss: 0.4077\n",
      "Epoch [12/50], Step [238/735], Loss: 1.1411\n",
      "Epoch [12/50], Step [239/735], Loss: 0.1050\n",
      "Epoch [12/50], Step [240/735], Loss: 0.1032\n",
      "Epoch [12/50], Step [241/735], Loss: 0.4172\n",
      "Epoch [12/50], Step [242/735], Loss: 0.1790\n",
      "Epoch [12/50], Step [243/735], Loss: 0.0564\n",
      "Epoch [12/50], Step [244/735], Loss: 0.7915\n",
      "Epoch [12/50], Step [245/735], Loss: 0.1356\n",
      "Epoch [12/50], Step [246/735], Loss: 0.2515\n",
      "Epoch [12/50], Step [247/735], Loss: 0.3780\n",
      "Epoch [12/50], Step [248/735], Loss: 0.1017\n",
      "Epoch [12/50], Step [249/735], Loss: 0.7180\n",
      "Epoch [12/50], Step [250/735], Loss: 0.9554\n",
      "Epoch [12/50], Step [251/735], Loss: 0.3135\n",
      "Epoch [12/50], Step [252/735], Loss: 0.4177\n",
      "Epoch [12/50], Step [253/735], Loss: 0.6774\n",
      "Epoch [12/50], Step [254/735], Loss: 0.0647\n",
      "Epoch [12/50], Step [255/735], Loss: 0.1303\n",
      "Epoch [12/50], Step [256/735], Loss: 0.3751\n",
      "Epoch [12/50], Step [257/735], Loss: 0.0773\n",
      "Epoch [12/50], Step [258/735], Loss: 0.3593\n",
      "Epoch [12/50], Step [259/735], Loss: 0.4500\n",
      "Epoch [12/50], Step [260/735], Loss: 0.2274\n",
      "Epoch [12/50], Step [261/735], Loss: 0.1727\n",
      "Epoch [12/50], Step [262/735], Loss: 0.2224\n",
      "Epoch [12/50], Step [263/735], Loss: 0.1687\n",
      "Epoch [12/50], Step [264/735], Loss: 0.3618\n",
      "Epoch [12/50], Step [265/735], Loss: 2.5318\n",
      "Epoch [12/50], Step [266/735], Loss: 0.1169\n",
      "Epoch [12/50], Step [267/735], Loss: 0.6515\n",
      "Epoch [12/50], Step [268/735], Loss: 0.5401\n",
      "Epoch [12/50], Step [269/735], Loss: 0.1646\n",
      "Epoch [12/50], Step [270/735], Loss: 0.4319\n",
      "Epoch [12/50], Step [271/735], Loss: 0.2914\n",
      "Epoch [12/50], Step [272/735], Loss: 0.2779\n",
      "Epoch [12/50], Step [273/735], Loss: 0.1822\n",
      "Epoch [12/50], Step [274/735], Loss: 0.1004\n",
      "Epoch [12/50], Step [275/735], Loss: 0.3425\n",
      "Epoch [12/50], Step [276/735], Loss: 2.4031\n",
      "Epoch [12/50], Step [277/735], Loss: 0.8677\n",
      "Epoch [12/50], Step [278/735], Loss: 1.9109\n",
      "Epoch [12/50], Step [279/735], Loss: 0.3139\n",
      "Epoch [12/50], Step [280/735], Loss: 0.3104\n",
      "Epoch [12/50], Step [281/735], Loss: 0.7574\n",
      "Epoch [12/50], Step [282/735], Loss: 0.5015\n",
      "Epoch [12/50], Step [283/735], Loss: 0.8378\n",
      "Epoch [12/50], Step [284/735], Loss: 0.2639\n",
      "Epoch [12/50], Step [285/735], Loss: 0.7494\n",
      "Epoch [12/50], Step [286/735], Loss: 1.7759\n",
      "Epoch [12/50], Step [287/735], Loss: 0.4089\n",
      "Epoch [12/50], Step [288/735], Loss: 0.5105\n",
      "Epoch [12/50], Step [289/735], Loss: 1.2534\n",
      "Epoch [12/50], Step [290/735], Loss: 0.5980\n",
      "Epoch [12/50], Step [291/735], Loss: 0.4888\n",
      "Epoch [12/50], Step [292/735], Loss: 0.4877\n",
      "Epoch [12/50], Step [293/735], Loss: 0.2140\n",
      "Epoch [12/50], Step [294/735], Loss: 0.8886\n",
      "Epoch [12/50], Step [295/735], Loss: 0.3398\n",
      "Epoch [12/50], Step [296/735], Loss: 0.5241\n",
      "Epoch [12/50], Step [297/735], Loss: 0.3022\n",
      "Epoch [12/50], Step [298/735], Loss: 0.4467\n",
      "Epoch [12/50], Step [299/735], Loss: 0.7082\n",
      "Epoch [12/50], Step [300/735], Loss: 0.2572\n",
      "Epoch [12/50], Step [301/735], Loss: 1.9515\n",
      "Epoch [12/50], Step [302/735], Loss: 0.5720\n",
      "Epoch [12/50], Step [303/735], Loss: 0.1535\n",
      "Epoch [12/50], Step [304/735], Loss: 0.4263\n",
      "Epoch [12/50], Step [305/735], Loss: 0.5193\n",
      "Epoch [12/50], Step [306/735], Loss: 0.1476\n",
      "Epoch [12/50], Step [307/735], Loss: 0.5067\n",
      "Epoch [12/50], Step [308/735], Loss: 0.4351\n",
      "Epoch [12/50], Step [309/735], Loss: 0.5490\n",
      "Epoch [12/50], Step [310/735], Loss: 5.7080\n",
      "Epoch [12/50], Step [311/735], Loss: 0.1741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Step [312/735], Loss: 0.6295\n",
      "Epoch [12/50], Step [313/735], Loss: 0.4331\n",
      "Epoch [12/50], Step [314/735], Loss: 0.2207\n",
      "Epoch [12/50], Step [315/735], Loss: 0.4363\n",
      "Epoch [12/50], Step [316/735], Loss: 0.2619\n",
      "Epoch [12/50], Step [317/735], Loss: 0.5416\n",
      "Epoch [12/50], Step [318/735], Loss: 0.3316\n",
      "Epoch [12/50], Step [319/735], Loss: 0.9023\n",
      "Epoch [12/50], Step [320/735], Loss: 0.1190\n",
      "Epoch [12/50], Step [321/735], Loss: 0.2727\n",
      "Epoch [12/50], Step [322/735], Loss: 0.3462\n",
      "Epoch [12/50], Step [323/735], Loss: 0.3336\n",
      "Epoch [12/50], Step [324/735], Loss: 0.1007\n",
      "Epoch [12/50], Step [325/735], Loss: 0.1495\n",
      "Epoch [12/50], Step [326/735], Loss: 0.2745\n",
      "Epoch [12/50], Step [327/735], Loss: 0.2157\n",
      "Epoch [12/50], Step [328/735], Loss: 0.2204\n",
      "Epoch [12/50], Step [329/735], Loss: 1.3278\n",
      "Epoch [12/50], Step [330/735], Loss: 2.0271\n",
      "Epoch [12/50], Step [331/735], Loss: 0.6940\n",
      "Epoch [12/50], Step [332/735], Loss: 0.2173\n",
      "Epoch [12/50], Step [333/735], Loss: 0.6198\n",
      "Epoch [12/50], Step [334/735], Loss: 0.1600\n",
      "Epoch [12/50], Step [335/735], Loss: 0.0776\n",
      "Epoch [12/50], Step [336/735], Loss: 0.2219\n",
      "Epoch [12/50], Step [337/735], Loss: 0.2688\n",
      "Epoch [12/50], Step [338/735], Loss: 0.5175\n",
      "Epoch [12/50], Step [339/735], Loss: 0.5167\n",
      "Epoch [12/50], Step [340/735], Loss: 0.4188\n",
      "Epoch [12/50], Step [341/735], Loss: 0.6292\n",
      "Epoch [12/50], Step [342/735], Loss: 0.0910\n",
      "Epoch [12/50], Step [343/735], Loss: 0.0484\n",
      "Epoch [12/50], Step [344/735], Loss: 1.6151\n",
      "Epoch [12/50], Step [345/735], Loss: 1.8269\n",
      "Epoch [12/50], Step [346/735], Loss: 0.1857\n",
      "Epoch [12/50], Step [347/735], Loss: 0.2782\n",
      "Epoch [12/50], Step [348/735], Loss: 1.6938\n",
      "Epoch [12/50], Step [349/735], Loss: 0.6050\n",
      "Epoch [12/50], Step [350/735], Loss: 1.2810\n",
      "Epoch [12/50], Step [351/735], Loss: 0.8287\n",
      "Epoch [12/50], Step [352/735], Loss: 1.1035\n",
      "Epoch [12/50], Step [353/735], Loss: 0.6388\n",
      "Epoch [12/50], Step [354/735], Loss: 0.3279\n",
      "Epoch [12/50], Step [355/735], Loss: 0.1291\n",
      "Epoch [12/50], Step [356/735], Loss: 0.3015\n",
      "Epoch [12/50], Step [357/735], Loss: 0.2794\n",
      "Epoch [12/50], Step [358/735], Loss: 0.4137\n",
      "Epoch [12/50], Step [359/735], Loss: 0.6985\n",
      "Epoch [12/50], Step [360/735], Loss: 0.4443\n",
      "Epoch [12/50], Step [361/735], Loss: 0.4349\n",
      "Epoch [12/50], Step [362/735], Loss: 0.7932\n",
      "Epoch [12/50], Step [363/735], Loss: 0.1703\n",
      "Epoch [12/50], Step [364/735], Loss: 0.3917\n",
      "Epoch [12/50], Step [365/735], Loss: 0.1197\n",
      "Epoch [12/50], Step [366/735], Loss: 0.3191\n",
      "Epoch [12/50], Step [367/735], Loss: 0.9146\n",
      "Epoch [12/50], Step [368/735], Loss: 0.6075\n",
      "Epoch [12/50], Step [369/735], Loss: 0.4133\n",
      "Epoch [12/50], Step [370/735], Loss: 0.0832\n",
      "Epoch [12/50], Step [371/735], Loss: 0.2103\n",
      "Epoch [12/50], Step [372/735], Loss: 0.0574\n",
      "Epoch [12/50], Step [373/735], Loss: 0.2446\n",
      "Epoch [12/50], Step [374/735], Loss: 0.9009\n",
      "Epoch [12/50], Step [375/735], Loss: 0.1780\n",
      "Epoch [12/50], Step [376/735], Loss: 1.2278\n",
      "Epoch [12/50], Step [377/735], Loss: 0.1513\n",
      "Epoch [12/50], Step [378/735], Loss: 0.2981\n",
      "Epoch [12/50], Step [379/735], Loss: 0.2196\n",
      "Epoch [12/50], Step [380/735], Loss: 0.5102\n",
      "Epoch [12/50], Step [381/735], Loss: 0.2247\n",
      "Epoch [12/50], Step [382/735], Loss: 0.5837\n",
      "Epoch [12/50], Step [383/735], Loss: 0.4465\n",
      "Epoch [12/50], Step [384/735], Loss: 0.7030\n",
      "Epoch [12/50], Step [385/735], Loss: 0.3452\n",
      "Epoch [12/50], Step [386/735], Loss: 0.3583\n",
      "Epoch [12/50], Step [387/735], Loss: 0.5012\n",
      "Epoch [12/50], Step [388/735], Loss: 0.1358\n",
      "Epoch [12/50], Step [389/735], Loss: 0.2646\n",
      "Epoch [12/50], Step [390/735], Loss: 0.6958\n",
      "Epoch [12/50], Step [391/735], Loss: 0.1689\n",
      "Epoch [12/50], Step [392/735], Loss: 0.3162\n",
      "Epoch [12/50], Step [393/735], Loss: 0.4874\n",
      "Epoch [12/50], Step [394/735], Loss: 0.1536\n",
      "Epoch [12/50], Step [395/735], Loss: 0.2116\n",
      "Epoch [12/50], Step [396/735], Loss: 0.4992\n",
      "Epoch [12/50], Step [397/735], Loss: 0.2974\n",
      "Epoch [12/50], Step [398/735], Loss: 0.3910\n",
      "Epoch [12/50], Step [399/735], Loss: 0.6720\n",
      "Epoch [12/50], Step [400/735], Loss: 0.3801\n",
      "Epoch [12/50], Step [401/735], Loss: 0.3108\n",
      "Epoch [12/50], Step [402/735], Loss: 0.4955\n",
      "Epoch [12/50], Step [403/735], Loss: 0.2877\n",
      "Epoch [12/50], Step [404/735], Loss: 0.6697\n",
      "Epoch [12/50], Step [405/735], Loss: 0.4221\n",
      "Epoch [12/50], Step [406/735], Loss: 0.4719\n",
      "Epoch [12/50], Step [407/735], Loss: 0.7809\n",
      "Epoch [12/50], Step [408/735], Loss: 0.1331\n",
      "Epoch [12/50], Step [409/735], Loss: 0.1616\n",
      "Epoch [12/50], Step [410/735], Loss: 0.0982\n",
      "Epoch [12/50], Step [411/735], Loss: 0.3049\n",
      "Epoch [12/50], Step [412/735], Loss: 0.1143\n",
      "Epoch [12/50], Step [413/735], Loss: 0.1635\n",
      "Epoch [12/50], Step [414/735], Loss: 0.6015\n",
      "Epoch [12/50], Step [415/735], Loss: 0.1233\n",
      "Epoch [12/50], Step [416/735], Loss: 0.8193\n",
      "Epoch [12/50], Step [417/735], Loss: 0.2112\n",
      "Epoch [12/50], Step [418/735], Loss: 0.2772\n",
      "Epoch [12/50], Step [419/735], Loss: 0.1014\n",
      "Epoch [12/50], Step [420/735], Loss: 0.5154\n",
      "Epoch [12/50], Step [421/735], Loss: 1.2900\n",
      "Epoch [12/50], Step [422/735], Loss: 0.4155\n",
      "Epoch [12/50], Step [423/735], Loss: 0.1695\n",
      "Epoch [12/50], Step [424/735], Loss: 0.7502\n",
      "Epoch [12/50], Step [425/735], Loss: 0.1277\n",
      "Epoch [12/50], Step [426/735], Loss: 0.9161\n",
      "Epoch [12/50], Step [427/735], Loss: 1.3397\n",
      "Epoch [12/50], Step [428/735], Loss: 0.5328\n",
      "Epoch [12/50], Step [429/735], Loss: 0.3616\n",
      "Epoch [12/50], Step [430/735], Loss: 0.6906\n",
      "Epoch [12/50], Step [431/735], Loss: 0.2217\n",
      "Epoch [12/50], Step [432/735], Loss: 0.9646\n",
      "Epoch [12/50], Step [433/735], Loss: 0.6311\n",
      "Epoch [12/50], Step [434/735], Loss: 0.3363\n",
      "Epoch [12/50], Step [435/735], Loss: 0.3938\n",
      "Epoch [12/50], Step [436/735], Loss: 0.5282\n",
      "Epoch [12/50], Step [437/735], Loss: 0.4227\n",
      "Epoch [12/50], Step [438/735], Loss: 0.5421\n",
      "Epoch [12/50], Step [439/735], Loss: 0.3204\n",
      "Epoch [12/50], Step [440/735], Loss: 0.1258\n",
      "Epoch [12/50], Step [441/735], Loss: 0.1395\n",
      "Epoch [12/50], Step [442/735], Loss: 0.3592\n",
      "Epoch [12/50], Step [443/735], Loss: 0.6603\n",
      "Epoch [12/50], Step [444/735], Loss: 0.4774\n",
      "Epoch [12/50], Step [445/735], Loss: 0.8732\n",
      "Epoch [12/50], Step [446/735], Loss: 0.5140\n",
      "Epoch [12/50], Step [447/735], Loss: 0.6108\n",
      "Epoch [12/50], Step [448/735], Loss: 0.4013\n",
      "Epoch [12/50], Step [449/735], Loss: 0.3333\n",
      "Epoch [12/50], Step [450/735], Loss: 0.2889\n",
      "Epoch [12/50], Step [451/735], Loss: 0.4402\n",
      "Epoch [12/50], Step [452/735], Loss: 0.3174\n",
      "Epoch [12/50], Step [453/735], Loss: 0.2852\n",
      "Epoch [12/50], Step [454/735], Loss: 0.9004\n",
      "Epoch [12/50], Step [455/735], Loss: 0.2546\n",
      "Epoch [12/50], Step [456/735], Loss: 0.1191\n",
      "Epoch [12/50], Step [457/735], Loss: 0.3713\n",
      "Epoch [12/50], Step [458/735], Loss: 0.4693\n",
      "Epoch [12/50], Step [459/735], Loss: 0.3331\n",
      "Epoch [12/50], Step [460/735], Loss: 1.2418\n",
      "Epoch [12/50], Step [461/735], Loss: 0.3330\n",
      "Epoch [12/50], Step [462/735], Loss: 0.7433\n",
      "Epoch [12/50], Step [463/735], Loss: 0.7228\n",
      "Epoch [12/50], Step [464/735], Loss: 0.2558\n",
      "Epoch [12/50], Step [465/735], Loss: 0.2094\n",
      "Epoch [12/50], Step [466/735], Loss: 0.3883\n",
      "Epoch [12/50], Step [467/735], Loss: 0.2081\n",
      "Epoch [12/50], Step [468/735], Loss: 0.2113\n",
      "Epoch [12/50], Step [469/735], Loss: 0.3031\n",
      "Epoch [12/50], Step [470/735], Loss: 0.1986\n",
      "Epoch [12/50], Step [471/735], Loss: 0.2164\n",
      "Epoch [12/50], Step [472/735], Loss: 1.2676\n",
      "Epoch [12/50], Step [473/735], Loss: 0.8550\n",
      "Epoch [12/50], Step [474/735], Loss: 0.1812\n",
      "Epoch [12/50], Step [475/735], Loss: 0.6721\n",
      "Epoch [12/50], Step [476/735], Loss: 0.2166\n",
      "Epoch [12/50], Step [477/735], Loss: 0.1450\n",
      "Epoch [12/50], Step [478/735], Loss: 1.7919\n",
      "Epoch [12/50], Step [479/735], Loss: 0.1998\n",
      "Epoch [12/50], Step [480/735], Loss: 0.2335\n",
      "Epoch [12/50], Step [481/735], Loss: 0.2967\n",
      "Epoch [12/50], Step [482/735], Loss: 0.7958\n",
      "Epoch [12/50], Step [483/735], Loss: 0.6012\n",
      "Epoch [12/50], Step [484/735], Loss: 0.0861\n",
      "Epoch [12/50], Step [485/735], Loss: 0.9571\n",
      "Epoch [12/50], Step [486/735], Loss: 0.8200\n",
      "Epoch [12/50], Step [487/735], Loss: 0.5250\n",
      "Epoch [12/50], Step [488/735], Loss: 0.5177\n",
      "Epoch [12/50], Step [489/735], Loss: 0.7174\n",
      "Epoch [12/50], Step [490/735], Loss: 0.7722\n",
      "Epoch [12/50], Step [491/735], Loss: 0.2866\n",
      "Epoch [12/50], Step [492/735], Loss: 2.6334\n",
      "Epoch [12/50], Step [493/735], Loss: 0.3689\n",
      "Epoch [12/50], Step [494/735], Loss: 0.2469\n",
      "Epoch [12/50], Step [495/735], Loss: 0.5630\n",
      "Epoch [12/50], Step [496/735], Loss: 0.6166\n",
      "Epoch [12/50], Step [497/735], Loss: 0.1269\n",
      "Epoch [12/50], Step [498/735], Loss: 0.6296\n",
      "Epoch [12/50], Step [499/735], Loss: 0.7821\n",
      "Epoch [12/50], Step [500/735], Loss: 0.2535\n",
      "Epoch [12/50], Step [501/735], Loss: 1.1373\n",
      "Epoch [12/50], Step [502/735], Loss: 0.2878\n",
      "Epoch [12/50], Step [503/735], Loss: 0.4489\n",
      "Epoch [12/50], Step [504/735], Loss: 0.2177\n",
      "Epoch [12/50], Step [505/735], Loss: 0.1265\n",
      "Epoch [12/50], Step [506/735], Loss: 0.5299\n",
      "Epoch [12/50], Step [507/735], Loss: 0.3737\n",
      "Epoch [12/50], Step [508/735], Loss: 0.5898\n",
      "Epoch [12/50], Step [509/735], Loss: 0.6920\n",
      "Epoch [12/50], Step [510/735], Loss: 0.1045\n",
      "Epoch [12/50], Step [511/735], Loss: 0.4805\n",
      "Epoch [12/50], Step [512/735], Loss: 0.3845\n",
      "Epoch [12/50], Step [513/735], Loss: 0.5610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Step [514/735], Loss: 0.7632\n",
      "Epoch [12/50], Step [515/735], Loss: 0.1047\n",
      "Epoch [12/50], Step [516/735], Loss: 0.5773\n",
      "Epoch [12/50], Step [517/735], Loss: 0.1257\n",
      "Epoch [12/50], Step [518/735], Loss: 0.2628\n",
      "Epoch [12/50], Step [519/735], Loss: 0.3557\n",
      "Epoch [12/50], Step [520/735], Loss: 1.4571\n",
      "Epoch [12/50], Step [521/735], Loss: 0.3016\n",
      "Epoch [12/50], Step [522/735], Loss: 1.7331\n",
      "Epoch [12/50], Step [523/735], Loss: 0.2879\n",
      "Epoch [12/50], Step [524/735], Loss: 1.0439\n",
      "Epoch [12/50], Step [525/735], Loss: 0.2136\n",
      "Epoch [12/50], Step [526/735], Loss: 0.1272\n",
      "Epoch [12/50], Step [527/735], Loss: 0.3165\n",
      "Epoch [12/50], Step [528/735], Loss: 0.2911\n",
      "Epoch [12/50], Step [529/735], Loss: 0.5465\n",
      "Epoch [12/50], Step [530/735], Loss: 1.6899\n",
      "Epoch [12/50], Step [531/735], Loss: 0.6147\n",
      "Epoch [12/50], Step [532/735], Loss: 0.8829\n",
      "Epoch [12/50], Step [533/735], Loss: 0.1266\n",
      "Epoch [12/50], Step [534/735], Loss: 0.4249\n",
      "Epoch [12/50], Step [535/735], Loss: 0.5680\n",
      "Epoch [12/50], Step [536/735], Loss: 0.3262\n",
      "Epoch [12/50], Step [537/735], Loss: 0.2264\n",
      "Epoch [12/50], Step [538/735], Loss: 0.4277\n",
      "Epoch [12/50], Step [539/735], Loss: 5.1651\n",
      "Epoch [12/50], Step [540/735], Loss: 0.2765\n",
      "Epoch [12/50], Step [541/735], Loss: 0.1367\n",
      "Epoch [12/50], Step [542/735], Loss: 0.2473\n",
      "Epoch [12/50], Step [543/735], Loss: 0.0810\n",
      "Epoch [12/50], Step [544/735], Loss: 0.1753\n",
      "Epoch [12/50], Step [545/735], Loss: 0.1666\n",
      "Epoch [12/50], Step [546/735], Loss: 0.4026\n",
      "Epoch [12/50], Step [547/735], Loss: 0.6744\n",
      "Epoch [12/50], Step [548/735], Loss: 0.1182\n",
      "Epoch [12/50], Step [549/735], Loss: 1.7799\n",
      "Epoch [12/50], Step [550/735], Loss: 0.3180\n",
      "Epoch [12/50], Step [551/735], Loss: 0.6254\n",
      "Epoch [12/50], Step [552/735], Loss: 0.1787\n",
      "Epoch [12/50], Step [553/735], Loss: 0.1422\n",
      "Epoch [12/50], Step [554/735], Loss: 0.8446\n",
      "Epoch [12/50], Step [555/735], Loss: 0.3215\n",
      "Epoch [12/50], Step [556/735], Loss: 4.8381\n",
      "Epoch [12/50], Step [557/735], Loss: 0.2715\n",
      "Epoch [12/50], Step [558/735], Loss: 0.6858\n",
      "Epoch [12/50], Step [559/735], Loss: 0.3508\n",
      "Epoch [12/50], Step [560/735], Loss: 1.2603\n",
      "Epoch [12/50], Step [561/735], Loss: 0.7097\n",
      "Epoch [12/50], Step [562/735], Loss: 0.1681\n",
      "Epoch [12/50], Step [563/735], Loss: 0.6107\n",
      "Epoch [12/50], Step [564/735], Loss: 0.3938\n",
      "Epoch [12/50], Step [565/735], Loss: 0.1664\n",
      "Epoch [12/50], Step [566/735], Loss: 0.1948\n",
      "Epoch [12/50], Step [567/735], Loss: 0.2306\n",
      "Epoch [12/50], Step [568/735], Loss: 0.1856\n",
      "Epoch [12/50], Step [569/735], Loss: 0.2526\n",
      "Epoch [12/50], Step [570/735], Loss: 0.8735\n",
      "Epoch [12/50], Step [571/735], Loss: 1.3404\n",
      "Epoch [12/50], Step [572/735], Loss: 0.4986\n",
      "Epoch [12/50], Step [573/735], Loss: 0.3496\n",
      "Epoch [12/50], Step [574/735], Loss: 0.4150\n",
      "Epoch [12/50], Step [575/735], Loss: 0.2326\n",
      "Epoch [12/50], Step [576/735], Loss: 0.1442\n",
      "Epoch [12/50], Step [577/735], Loss: 0.9953\n",
      "Epoch [12/50], Step [578/735], Loss: 0.1165\n",
      "Epoch [12/50], Step [579/735], Loss: 0.6342\n",
      "Epoch [12/50], Step [580/735], Loss: 0.6140\n",
      "Epoch [12/50], Step [581/735], Loss: 0.4706\n",
      "Epoch [12/50], Step [582/735], Loss: 0.2217\n",
      "Epoch [12/50], Step [583/735], Loss: 0.2116\n",
      "Epoch [12/50], Step [584/735], Loss: 0.6327\n",
      "Epoch [12/50], Step [585/735], Loss: 0.8117\n",
      "Epoch [12/50], Step [586/735], Loss: 0.3014\n",
      "Epoch [12/50], Step [587/735], Loss: 0.5899\n",
      "Epoch [12/50], Step [588/735], Loss: 0.3251\n",
      "Epoch [12/50], Step [589/735], Loss: 0.1079\n",
      "Epoch [12/50], Step [590/735], Loss: 0.4977\n",
      "Epoch [12/50], Step [591/735], Loss: 1.0728\n",
      "Epoch [12/50], Step [592/735], Loss: 0.4795\n",
      "Epoch [12/50], Step [593/735], Loss: 0.1825\n",
      "Epoch [12/50], Step [594/735], Loss: 0.1891\n",
      "Epoch [12/50], Step [595/735], Loss: 0.5076\n",
      "Epoch [12/50], Step [596/735], Loss: 0.7875\n",
      "Epoch [12/50], Step [597/735], Loss: 0.2225\n",
      "Epoch [12/50], Step [598/735], Loss: 0.1651\n",
      "Epoch [12/50], Step [599/735], Loss: 0.1956\n",
      "Epoch [12/50], Step [600/735], Loss: 0.2895\n",
      "Epoch [12/50], Step [601/735], Loss: 0.7079\n",
      "Epoch [12/50], Step [602/735], Loss: 0.5470\n",
      "Epoch [12/50], Step [603/735], Loss: 0.8294\n",
      "Epoch [12/50], Step [604/735], Loss: 4.6128\n",
      "Epoch [12/50], Step [605/735], Loss: 1.2588\n",
      "Epoch [12/50], Step [606/735], Loss: 0.0787\n",
      "Epoch [12/50], Step [607/735], Loss: 0.3300\n",
      "Epoch [12/50], Step [608/735], Loss: 0.4702\n",
      "Epoch [12/50], Step [609/735], Loss: 0.1506\n",
      "Epoch [12/50], Step [610/735], Loss: 0.1552\n",
      "Epoch [12/50], Step [611/735], Loss: 1.4854\n",
      "Epoch [12/50], Step [612/735], Loss: 0.5136\n",
      "Epoch [12/50], Step [613/735], Loss: 0.1852\n",
      "Epoch [12/50], Step [614/735], Loss: 0.7765\n",
      "Epoch [12/50], Step [615/735], Loss: 1.0298\n",
      "Epoch [12/50], Step [616/735], Loss: 0.3406\n",
      "Epoch [12/50], Step [617/735], Loss: 0.1907\n",
      "Epoch [12/50], Step [618/735], Loss: 0.6736\n",
      "Epoch [12/50], Step [619/735], Loss: 0.9191\n",
      "Epoch [12/50], Step [620/735], Loss: 0.6941\n",
      "Epoch [12/50], Step [621/735], Loss: 1.3012\n",
      "Epoch [12/50], Step [622/735], Loss: 0.3918\n",
      "Epoch [12/50], Step [623/735], Loss: 0.4612\n",
      "Epoch [12/50], Step [624/735], Loss: 0.2643\n",
      "Epoch [12/50], Step [625/735], Loss: 0.7970\n",
      "Epoch [12/50], Step [626/735], Loss: 1.9895\n",
      "Epoch [12/50], Step [627/735], Loss: 0.2704\n",
      "Epoch [12/50], Step [628/735], Loss: 0.3261\n",
      "Epoch [12/50], Step [629/735], Loss: 0.6461\n",
      "Epoch [12/50], Step [630/735], Loss: 0.3691\n",
      "Epoch [12/50], Step [631/735], Loss: 0.7234\n",
      "Epoch [12/50], Step [632/735], Loss: 0.2116\n",
      "Epoch [12/50], Step [633/735], Loss: 0.3306\n",
      "Epoch [12/50], Step [634/735], Loss: 0.1717\n",
      "Epoch [12/50], Step [635/735], Loss: 0.5744\n",
      "Epoch [12/50], Step [636/735], Loss: 0.1108\n",
      "Epoch [12/50], Step [637/735], Loss: 0.3098\n",
      "Epoch [12/50], Step [638/735], Loss: 0.2134\n",
      "Epoch [12/50], Step [639/735], Loss: 0.5534\n",
      "Epoch [12/50], Step [640/735], Loss: 0.2987\n",
      "Epoch [12/50], Step [641/735], Loss: 0.3772\n",
      "Epoch [12/50], Step [642/735], Loss: 0.5617\n",
      "Epoch [12/50], Step [643/735], Loss: 0.3475\n",
      "Epoch [12/50], Step [644/735], Loss: 0.4342\n",
      "Epoch [12/50], Step [645/735], Loss: 0.1433\n",
      "Epoch [12/50], Step [646/735], Loss: 0.3131\n",
      "Epoch [12/50], Step [647/735], Loss: 0.1387\n",
      "Epoch [12/50], Step [648/735], Loss: 0.2658\n",
      "Epoch [12/50], Step [649/735], Loss: 0.2736\n",
      "Epoch [12/50], Step [650/735], Loss: 0.5629\n",
      "Epoch [12/50], Step [651/735], Loss: 0.1779\n",
      "Epoch [12/50], Step [652/735], Loss: 0.8698\n",
      "Epoch [12/50], Step [653/735], Loss: 0.2234\n",
      "Epoch [12/50], Step [654/735], Loss: 0.1901\n",
      "Epoch [12/50], Step [655/735], Loss: 0.7134\n",
      "Epoch [12/50], Step [656/735], Loss: 0.7481\n",
      "Epoch [12/50], Step [657/735], Loss: 0.2902\n",
      "Epoch [12/50], Step [658/735], Loss: 0.3618\n",
      "Epoch [12/50], Step [659/735], Loss: 0.0974\n",
      "Epoch [12/50], Step [660/735], Loss: 0.2668\n",
      "Epoch [12/50], Step [661/735], Loss: 0.4947\n",
      "Epoch [12/50], Step [662/735], Loss: 0.2122\n",
      "Epoch [12/50], Step [663/735], Loss: 1.0128\n",
      "Epoch [12/50], Step [664/735], Loss: 0.8781\n",
      "Epoch [12/50], Step [665/735], Loss: 0.2815\n",
      "Epoch [12/50], Step [666/735], Loss: 0.3177\n",
      "Epoch [12/50], Step [667/735], Loss: 0.2091\n",
      "Epoch [12/50], Step [668/735], Loss: 0.1781\n",
      "Epoch [12/50], Step [669/735], Loss: 0.0701\n",
      "Epoch [12/50], Step [670/735], Loss: 1.5555\n",
      "Epoch [12/50], Step [671/735], Loss: 0.3679\n",
      "Epoch [12/50], Step [672/735], Loss: 0.2496\n",
      "Epoch [12/50], Step [673/735], Loss: 2.0669\n",
      "Epoch [12/50], Step [674/735], Loss: 0.4430\n",
      "Epoch [12/50], Step [675/735], Loss: 0.3430\n",
      "Epoch [12/50], Step [676/735], Loss: 0.2346\n",
      "Epoch [12/50], Step [677/735], Loss: 0.2008\n",
      "Epoch [12/50], Step [678/735], Loss: 0.6522\n",
      "Epoch [12/50], Step [679/735], Loss: 0.1382\n",
      "Epoch [12/50], Step [680/735], Loss: 0.9801\n",
      "Epoch [12/50], Step [681/735], Loss: 0.1219\n",
      "Epoch [12/50], Step [682/735], Loss: 0.2774\n",
      "Epoch [12/50], Step [683/735], Loss: 0.3066\n",
      "Epoch [12/50], Step [684/735], Loss: 0.2513\n",
      "Epoch [12/50], Step [685/735], Loss: 0.1705\n",
      "Epoch [12/50], Step [686/735], Loss: 0.3156\n",
      "Epoch [12/50], Step [687/735], Loss: 0.0679\n",
      "Epoch [12/50], Step [688/735], Loss: 0.2196\n",
      "Epoch [12/50], Step [689/735], Loss: 0.5614\n",
      "Epoch [12/50], Step [690/735], Loss: 0.5152\n",
      "Epoch [12/50], Step [691/735], Loss: 0.5573\n",
      "Epoch [12/50], Step [692/735], Loss: 0.4183\n",
      "Epoch [12/50], Step [693/735], Loss: 0.2629\n",
      "Epoch [12/50], Step [694/735], Loss: 0.3628\n",
      "Epoch [12/50], Step [695/735], Loss: 0.1138\n",
      "Epoch [12/50], Step [696/735], Loss: 0.3330\n",
      "Epoch [12/50], Step [697/735], Loss: 2.6367\n",
      "Epoch [12/50], Step [698/735], Loss: 1.6581\n",
      "Epoch [12/50], Step [699/735], Loss: 0.2496\n",
      "Epoch [12/50], Step [700/735], Loss: 0.8650\n",
      "Epoch [12/50], Step [701/735], Loss: 0.5179\n",
      "Epoch [12/50], Step [702/735], Loss: 0.3354\n",
      "Epoch [12/50], Step [703/735], Loss: 0.1158\n",
      "Epoch [12/50], Step [704/735], Loss: 0.2365\n",
      "Epoch [12/50], Step [705/735], Loss: 1.1380\n",
      "Epoch [12/50], Step [706/735], Loss: 1.0607\n",
      "Epoch [12/50], Step [707/735], Loss: 0.5302\n",
      "Epoch [12/50], Step [708/735], Loss: 0.0884\n",
      "Epoch [12/50], Step [709/735], Loss: 0.3179\n",
      "Epoch [12/50], Step [710/735], Loss: 0.2052\n",
      "Epoch [12/50], Step [711/735], Loss: 0.4245\n",
      "Epoch [12/50], Step [712/735], Loss: 1.3963\n",
      "Epoch [12/50], Step [713/735], Loss: 0.2136\n",
      "Epoch [12/50], Step [714/735], Loss: 0.7799\n",
      "Epoch [12/50], Step [715/735], Loss: 0.9380\n",
      "Epoch [12/50], Step [716/735], Loss: 0.5828\n",
      "Epoch [12/50], Step [717/735], Loss: 0.1033\n",
      "Epoch [12/50], Step [718/735], Loss: 0.1547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Step [719/735], Loss: 0.8182\n",
      "Epoch [12/50], Step [720/735], Loss: 0.8403\n",
      "Epoch [12/50], Step [721/735], Loss: 0.6623\n",
      "Epoch [12/50], Step [722/735], Loss: 0.2489\n",
      "Epoch [12/50], Step [723/735], Loss: 0.4384\n",
      "Epoch [12/50], Step [724/735], Loss: 0.4377\n",
      "Epoch [12/50], Step [725/735], Loss: 0.6268\n",
      "Epoch [12/50], Step [726/735], Loss: 0.4685\n",
      "Epoch [12/50], Step [727/735], Loss: 0.2037\n",
      "Epoch [12/50], Step [728/735], Loss: 0.2378\n",
      "Epoch [12/50], Step [729/735], Loss: 0.1226\n",
      "Epoch [12/50], Step [730/735], Loss: 0.5401\n",
      "Epoch [12/50], Step [731/735], Loss: 0.0642\n",
      "Epoch [12/50], Step [732/735], Loss: 0.5603\n",
      "Epoch [12/50], Step [733/735], Loss: 0.2555\n",
      "Epoch [12/50], Step [734/735], Loss: 0.3872\n",
      "Epoch [12/50], Step [735/735], Loss: 0.1516\n",
      "Epoch [13/50], Step [1/735], Loss: 0.7471\n",
      "Epoch [13/50], Step [2/735], Loss: 0.3091\n",
      "Epoch [13/50], Step [3/735], Loss: 0.3323\n",
      "Epoch [13/50], Step [4/735], Loss: 0.2397\n",
      "Epoch [13/50], Step [5/735], Loss: 0.1916\n",
      "Epoch [13/50], Step [6/735], Loss: 0.3834\n",
      "Epoch [13/50], Step [7/735], Loss: 0.2616\n",
      "Epoch [13/50], Step [8/735], Loss: 0.6922\n",
      "Epoch [13/50], Step [9/735], Loss: 0.4110\n",
      "Epoch [13/50], Step [10/735], Loss: 0.2320\n",
      "Epoch [13/50], Step [11/735], Loss: 0.1920\n",
      "Epoch [13/50], Step [12/735], Loss: 0.1699\n",
      "Epoch [13/50], Step [13/735], Loss: 0.1547\n",
      "Epoch [13/50], Step [14/735], Loss: 0.7286\n",
      "Epoch [13/50], Step [15/735], Loss: 1.2041\n",
      "Epoch [13/50], Step [16/735], Loss: 0.3286\n",
      "Epoch [13/50], Step [17/735], Loss: 0.6599\n",
      "Epoch [13/50], Step [18/735], Loss: 0.2071\n",
      "Epoch [13/50], Step [19/735], Loss: 0.3373\n",
      "Epoch [13/50], Step [20/735], Loss: 0.1234\n",
      "Epoch [13/50], Step [21/735], Loss: 0.1543\n",
      "Epoch [13/50], Step [22/735], Loss: 0.6638\n",
      "Epoch [13/50], Step [23/735], Loss: 0.1281\n",
      "Epoch [13/50], Step [24/735], Loss: 0.1392\n",
      "Epoch [13/50], Step [25/735], Loss: 0.2966\n",
      "Epoch [13/50], Step [26/735], Loss: 0.4525\n",
      "Epoch [13/50], Step [27/735], Loss: 0.1339\n",
      "Epoch [13/50], Step [28/735], Loss: 1.9967\n",
      "Epoch [13/50], Step [29/735], Loss: 0.1906\n",
      "Epoch [13/50], Step [30/735], Loss: 1.0108\n",
      "Epoch [13/50], Step [31/735], Loss: 0.2418\n",
      "Epoch [13/50], Step [32/735], Loss: 0.1199\n",
      "Epoch [13/50], Step [33/735], Loss: 0.2082\n",
      "Epoch [13/50], Step [34/735], Loss: 0.2806\n",
      "Epoch [13/50], Step [35/735], Loss: 0.1977\n",
      "Epoch [13/50], Step [36/735], Loss: 0.4326\n",
      "Epoch [13/50], Step [37/735], Loss: 0.2185\n",
      "Epoch [13/50], Step [38/735], Loss: 0.2263\n",
      "Epoch [13/50], Step [39/735], Loss: 0.1926\n",
      "Epoch [13/50], Step [40/735], Loss: 0.5391\n",
      "Epoch [13/50], Step [41/735], Loss: 0.3352\n",
      "Epoch [13/50], Step [42/735], Loss: 0.3675\n",
      "Epoch [13/50], Step [43/735], Loss: 0.1364\n",
      "Epoch [13/50], Step [44/735], Loss: 0.1117\n",
      "Epoch [13/50], Step [45/735], Loss: 0.0810\n",
      "Epoch [13/50], Step [46/735], Loss: 0.2963\n",
      "Epoch [13/50], Step [47/735], Loss: 0.4107\n",
      "Epoch [13/50], Step [48/735], Loss: 0.1591\n",
      "Epoch [13/50], Step [49/735], Loss: 0.2360\n",
      "Epoch [13/50], Step [50/735], Loss: 0.2592\n",
      "Epoch [13/50], Step [51/735], Loss: 0.0998\n",
      "Epoch [13/50], Step [52/735], Loss: 0.6014\n",
      "Epoch [13/50], Step [53/735], Loss: 0.1892\n",
      "Epoch [13/50], Step [54/735], Loss: 0.4815\n",
      "Epoch [13/50], Step [55/735], Loss: 1.1583\n",
      "Epoch [13/50], Step [56/735], Loss: 0.0840\n",
      "Epoch [13/50], Step [57/735], Loss: 0.3847\n",
      "Epoch [13/50], Step [58/735], Loss: 0.3329\n",
      "Epoch [13/50], Step [59/735], Loss: 0.4329\n",
      "Epoch [13/50], Step [60/735], Loss: 0.4459\n",
      "Epoch [13/50], Step [61/735], Loss: 0.2847\n",
      "Epoch [13/50], Step [62/735], Loss: 0.6756\n",
      "Epoch [13/50], Step [63/735], Loss: 0.0769\n",
      "Epoch [13/50], Step [64/735], Loss: 0.7174\n",
      "Epoch [13/50], Step [65/735], Loss: 0.1442\n",
      "Epoch [13/50], Step [66/735], Loss: 0.4306\n",
      "Epoch [13/50], Step [67/735], Loss: 0.2368\n",
      "Epoch [13/50], Step [68/735], Loss: 0.5551\n",
      "Epoch [13/50], Step [69/735], Loss: 1.0902\n",
      "Epoch [13/50], Step [70/735], Loss: 0.4416\n",
      "Epoch [13/50], Step [71/735], Loss: 0.9036\n",
      "Epoch [13/50], Step [72/735], Loss: 0.3623\n",
      "Epoch [13/50], Step [73/735], Loss: 0.5460\n",
      "Epoch [13/50], Step [74/735], Loss: 0.2008\n",
      "Epoch [13/50], Step [75/735], Loss: 0.2376\n",
      "Epoch [13/50], Step [76/735], Loss: 1.3702\n",
      "Epoch [13/50], Step [77/735], Loss: 0.2858\n",
      "Epoch [13/50], Step [78/735], Loss: 0.5388\n",
      "Epoch [13/50], Step [79/735], Loss: 0.0867\n",
      "Epoch [13/50], Step [80/735], Loss: 0.4446\n",
      "Epoch [13/50], Step [81/735], Loss: 0.0824\n",
      "Epoch [13/50], Step [82/735], Loss: 0.1701\n",
      "Epoch [13/50], Step [83/735], Loss: 0.1842\n",
      "Epoch [13/50], Step [84/735], Loss: 0.7829\n",
      "Epoch [13/50], Step [85/735], Loss: 0.2036\n",
      "Epoch [13/50], Step [86/735], Loss: 0.5775\n",
      "Epoch [13/50], Step [87/735], Loss: 0.2483\n",
      "Epoch [13/50], Step [88/735], Loss: 0.1902\n",
      "Epoch [13/50], Step [89/735], Loss: 0.2791\n",
      "Epoch [13/50], Step [90/735], Loss: 0.8477\n",
      "Epoch [13/50], Step [91/735], Loss: 0.2712\n",
      "Epoch [13/50], Step [92/735], Loss: 0.8515\n",
      "Epoch [13/50], Step [93/735], Loss: 0.2301\n",
      "Epoch [13/50], Step [94/735], Loss: 0.2183\n",
      "Epoch [13/50], Step [95/735], Loss: 0.3076\n",
      "Epoch [13/50], Step [96/735], Loss: 1.8760\n",
      "Epoch [13/50], Step [97/735], Loss: 0.6264\n",
      "Epoch [13/50], Step [98/735], Loss: 0.2001\n",
      "Epoch [13/50], Step [99/735], Loss: 0.1437\n",
      "Epoch [13/50], Step [100/735], Loss: 0.6725\n",
      "Epoch [13/50], Step [101/735], Loss: 0.6272\n",
      "Epoch [13/50], Step [102/735], Loss: 0.9367\n",
      "Epoch [13/50], Step [103/735], Loss: 0.4289\n",
      "Epoch [13/50], Step [104/735], Loss: 0.4119\n",
      "Epoch [13/50], Step [105/735], Loss: 0.3999\n",
      "Epoch [13/50], Step [106/735], Loss: 0.1768\n",
      "Epoch [13/50], Step [107/735], Loss: 0.7738\n",
      "Epoch [13/50], Step [108/735], Loss: 1.6133\n",
      "Epoch [13/50], Step [109/735], Loss: 0.3677\n",
      "Epoch [13/50], Step [110/735], Loss: 0.4378\n",
      "Epoch [13/50], Step [111/735], Loss: 0.1455\n",
      "Epoch [13/50], Step [112/735], Loss: 0.6215\n",
      "Epoch [13/50], Step [113/735], Loss: 0.0991\n",
      "Epoch [13/50], Step [114/735], Loss: 0.2405\n",
      "Epoch [13/50], Step [115/735], Loss: 0.2342\n",
      "Epoch [13/50], Step [116/735], Loss: 1.8205\n",
      "Epoch [13/50], Step [117/735], Loss: 0.3905\n",
      "Epoch [13/50], Step [118/735], Loss: 0.8005\n",
      "Epoch [13/50], Step [119/735], Loss: 0.1381\n",
      "Epoch [13/50], Step [120/735], Loss: 0.5318\n",
      "Epoch [13/50], Step [121/735], Loss: 0.0518\n",
      "Epoch [13/50], Step [122/735], Loss: 0.4673\n",
      "Epoch [13/50], Step [123/735], Loss: 0.2186\n",
      "Epoch [13/50], Step [124/735], Loss: 0.4542\n",
      "Epoch [13/50], Step [125/735], Loss: 0.2279\n",
      "Epoch [13/50], Step [126/735], Loss: 0.1750\n",
      "Epoch [13/50], Step [127/735], Loss: 0.9107\n",
      "Epoch [13/50], Step [128/735], Loss: 0.2579\n",
      "Epoch [13/50], Step [129/735], Loss: 0.3356\n",
      "Epoch [13/50], Step [130/735], Loss: 0.7552\n",
      "Epoch [13/50], Step [131/735], Loss: 0.4181\n",
      "Epoch [13/50], Step [132/735], Loss: 0.3313\n",
      "Epoch [13/50], Step [133/735], Loss: 0.6324\n",
      "Epoch [13/50], Step [134/735], Loss: 0.1619\n",
      "Epoch [13/50], Step [135/735], Loss: 0.3801\n",
      "Epoch [13/50], Step [136/735], Loss: 0.5090\n",
      "Epoch [13/50], Step [137/735], Loss: 0.3347\n",
      "Epoch [13/50], Step [138/735], Loss: 0.9976\n",
      "Epoch [13/50], Step [139/735], Loss: 0.6527\n",
      "Epoch [13/50], Step [140/735], Loss: 0.7258\n",
      "Epoch [13/50], Step [141/735], Loss: 0.0869\n",
      "Epoch [13/50], Step [142/735], Loss: 0.4464\n",
      "Epoch [13/50], Step [143/735], Loss: 0.1330\n",
      "Epoch [13/50], Step [144/735], Loss: 0.4120\n",
      "Epoch [13/50], Step [145/735], Loss: 0.4945\n",
      "Epoch [13/50], Step [146/735], Loss: 0.6876\n",
      "Epoch [13/50], Step [147/735], Loss: 0.1569\n",
      "Epoch [13/50], Step [148/735], Loss: 0.2710\n",
      "Epoch [13/50], Step [149/735], Loss: 0.3594\n",
      "Epoch [13/50], Step [150/735], Loss: 0.2943\n",
      "Epoch [13/50], Step [151/735], Loss: 0.1643\n",
      "Epoch [13/50], Step [152/735], Loss: 0.4361\n",
      "Epoch [13/50], Step [153/735], Loss: 1.3373\n",
      "Epoch [13/50], Step [154/735], Loss: 0.7444\n",
      "Epoch [13/50], Step [155/735], Loss: 0.3664\n",
      "Epoch [13/50], Step [156/735], Loss: 0.3142\n",
      "Epoch [13/50], Step [157/735], Loss: 0.2461\n",
      "Epoch [13/50], Step [158/735], Loss: 0.3457\n",
      "Epoch [13/50], Step [159/735], Loss: 0.7627\n",
      "Epoch [13/50], Step [160/735], Loss: 0.1622\n",
      "Epoch [13/50], Step [161/735], Loss: 0.1728\n",
      "Epoch [13/50], Step [162/735], Loss: 0.4745\n",
      "Epoch [13/50], Step [163/735], Loss: 0.8529\n",
      "Epoch [13/50], Step [164/735], Loss: 0.4490\n",
      "Epoch [13/50], Step [165/735], Loss: 0.2314\n",
      "Epoch [13/50], Step [166/735], Loss: 0.2452\n",
      "Epoch [13/50], Step [167/735], Loss: 0.4442\n",
      "Epoch [13/50], Step [168/735], Loss: 0.1574\n",
      "Epoch [13/50], Step [169/735], Loss: 0.6355\n",
      "Epoch [13/50], Step [170/735], Loss: 0.5125\n",
      "Epoch [13/50], Step [171/735], Loss: 0.2668\n",
      "Epoch [13/50], Step [172/735], Loss: 0.9601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Step [173/735], Loss: 1.0081\n",
      "Epoch [13/50], Step [174/735], Loss: 1.7845\n",
      "Epoch [13/50], Step [175/735], Loss: 0.1830\n",
      "Epoch [13/50], Step [176/735], Loss: 0.2241\n",
      "Epoch [13/50], Step [177/735], Loss: 0.3724\n",
      "Epoch [13/50], Step [178/735], Loss: 0.3474\n",
      "Epoch [13/50], Step [179/735], Loss: 0.2295\n",
      "Epoch [13/50], Step [180/735], Loss: 0.5587\n",
      "Epoch [13/50], Step [181/735], Loss: 0.2650\n",
      "Epoch [13/50], Step [182/735], Loss: 0.7845\n",
      "Epoch [13/50], Step [183/735], Loss: 1.0053\n",
      "Epoch [13/50], Step [184/735], Loss: 0.1880\n",
      "Epoch [13/50], Step [185/735], Loss: 0.4776\n",
      "Epoch [13/50], Step [186/735], Loss: 0.1396\n",
      "Epoch [13/50], Step [187/735], Loss: 0.4443\n",
      "Epoch [13/50], Step [188/735], Loss: 0.7949\n",
      "Epoch [13/50], Step [189/735], Loss: 0.6342\n",
      "Epoch [13/50], Step [190/735], Loss: 0.7040\n",
      "Epoch [13/50], Step [191/735], Loss: 0.7628\n",
      "Epoch [13/50], Step [192/735], Loss: 0.2108\n",
      "Epoch [13/50], Step [193/735], Loss: 0.3340\n",
      "Epoch [13/50], Step [194/735], Loss: 0.3592\n",
      "Epoch [13/50], Step [195/735], Loss: 5.9524\n",
      "Epoch [13/50], Step [196/735], Loss: 0.8478\n",
      "Epoch [13/50], Step [197/735], Loss: 0.9663\n",
      "Epoch [13/50], Step [198/735], Loss: 0.3005\n",
      "Epoch [13/50], Step [199/735], Loss: 0.2399\n",
      "Epoch [13/50], Step [200/735], Loss: 0.0969\n",
      "Epoch [13/50], Step [201/735], Loss: 5.3493\n",
      "Epoch [13/50], Step [202/735], Loss: 0.3142\n",
      "Epoch [13/50], Step [203/735], Loss: 0.3541\n",
      "Epoch [13/50], Step [204/735], Loss: 0.5112\n",
      "Epoch [13/50], Step [205/735], Loss: 0.5687\n",
      "Epoch [13/50], Step [206/735], Loss: 0.3094\n",
      "Epoch [13/50], Step [207/735], Loss: 0.7723\n",
      "Epoch [13/50], Step [208/735], Loss: 0.3982\n",
      "Epoch [13/50], Step [209/735], Loss: 0.2545\n",
      "Epoch [13/50], Step [210/735], Loss: 0.8631\n",
      "Epoch [13/50], Step [211/735], Loss: 0.7747\n",
      "Epoch [13/50], Step [212/735], Loss: 0.3110\n",
      "Epoch [13/50], Step [213/735], Loss: 0.6098\n",
      "Epoch [13/50], Step [214/735], Loss: 0.2250\n",
      "Epoch [13/50], Step [215/735], Loss: 0.1765\n",
      "Epoch [13/50], Step [216/735], Loss: 1.4120\n",
      "Epoch [13/50], Step [217/735], Loss: 0.2601\n",
      "Epoch [13/50], Step [218/735], Loss: 0.1834\n",
      "Epoch [13/50], Step [219/735], Loss: 0.2086\n",
      "Epoch [13/50], Step [220/735], Loss: 0.2234\n",
      "Epoch [13/50], Step [221/735], Loss: 0.0783\n",
      "Epoch [13/50], Step [222/735], Loss: 1.0609\n",
      "Epoch [13/50], Step [223/735], Loss: 2.1863\n",
      "Epoch [13/50], Step [224/735], Loss: 0.4473\n",
      "Epoch [13/50], Step [225/735], Loss: 0.0779\n",
      "Epoch [13/50], Step [226/735], Loss: 0.5968\n",
      "Epoch [13/50], Step [227/735], Loss: 0.3569\n",
      "Epoch [13/50], Step [228/735], Loss: 0.3042\n",
      "Epoch [13/50], Step [229/735], Loss: 0.3542\n",
      "Epoch [13/50], Step [230/735], Loss: 0.3383\n",
      "Epoch [13/50], Step [231/735], Loss: 0.7238\n",
      "Epoch [13/50], Step [232/735], Loss: 0.5040\n",
      "Epoch [13/50], Step [233/735], Loss: 0.8952\n",
      "Epoch [13/50], Step [234/735], Loss: 0.4397\n",
      "Epoch [13/50], Step [235/735], Loss: 0.2048\n",
      "Epoch [13/50], Step [236/735], Loss: 0.1724\n",
      "Epoch [13/50], Step [237/735], Loss: 0.3709\n",
      "Epoch [13/50], Step [238/735], Loss: 0.4593\n",
      "Epoch [13/50], Step [239/735], Loss: 0.3865\n",
      "Epoch [13/50], Step [240/735], Loss: 0.3646\n",
      "Epoch [13/50], Step [241/735], Loss: 1.2161\n",
      "Epoch [13/50], Step [242/735], Loss: 0.5897\n",
      "Epoch [13/50], Step [243/735], Loss: 0.9702\n",
      "Epoch [13/50], Step [244/735], Loss: 0.2176\n",
      "Epoch [13/50], Step [245/735], Loss: 0.3180\n",
      "Epoch [13/50], Step [246/735], Loss: 0.2329\n",
      "Epoch [13/50], Step [247/735], Loss: 0.5697\n",
      "Epoch [13/50], Step [248/735], Loss: 0.3634\n",
      "Epoch [13/50], Step [249/735], Loss: 0.4810\n",
      "Epoch [13/50], Step [250/735], Loss: 0.1511\n",
      "Epoch [13/50], Step [251/735], Loss: 0.2772\n",
      "Epoch [13/50], Step [252/735], Loss: 0.3041\n",
      "Epoch [13/50], Step [253/735], Loss: 0.3914\n",
      "Epoch [13/50], Step [254/735], Loss: 0.3312\n",
      "Epoch [13/50], Step [255/735], Loss: 1.0849\n",
      "Epoch [13/50], Step [256/735], Loss: 0.4197\n",
      "Epoch [13/50], Step [257/735], Loss: 0.6321\n",
      "Epoch [13/50], Step [258/735], Loss: 0.3195\n",
      "Epoch [13/50], Step [259/735], Loss: 0.2886\n",
      "Epoch [13/50], Step [260/735], Loss: 0.1525\n",
      "Epoch [13/50], Step [261/735], Loss: 4.9854\n",
      "Epoch [13/50], Step [262/735], Loss: 0.1293\n",
      "Epoch [13/50], Step [263/735], Loss: 0.2989\n",
      "Epoch [13/50], Step [264/735], Loss: 0.2508\n",
      "Epoch [13/50], Step [265/735], Loss: 0.6009\n",
      "Epoch [13/50], Step [266/735], Loss: 0.3564\n",
      "Epoch [13/50], Step [267/735], Loss: 0.6105\n",
      "Epoch [13/50], Step [268/735], Loss: 1.6238\n",
      "Epoch [13/50], Step [269/735], Loss: 0.2126\n",
      "Epoch [13/50], Step [270/735], Loss: 0.1116\n",
      "Epoch [13/50], Step [271/735], Loss: 0.1903\n",
      "Epoch [13/50], Step [272/735], Loss: 0.7797\n",
      "Epoch [13/50], Step [273/735], Loss: 0.1521\n",
      "Epoch [13/50], Step [274/735], Loss: 0.6014\n",
      "Epoch [13/50], Step [275/735], Loss: 0.6544\n",
      "Epoch [13/50], Step [276/735], Loss: 0.4048\n",
      "Epoch [13/50], Step [277/735], Loss: 0.7670\n",
      "Epoch [13/50], Step [278/735], Loss: 0.3160\n",
      "Epoch [13/50], Step [279/735], Loss: 0.1115\n",
      "Epoch [13/50], Step [280/735], Loss: 0.3263\n",
      "Epoch [13/50], Step [281/735], Loss: 0.2825\n",
      "Epoch [13/50], Step [282/735], Loss: 0.1729\n",
      "Epoch [13/50], Step [283/735], Loss: 1.8054\n",
      "Epoch [13/50], Step [284/735], Loss: 0.2190\n",
      "Epoch [13/50], Step [285/735], Loss: 0.4297\n",
      "Epoch [13/50], Step [286/735], Loss: 1.9932\n",
      "Epoch [13/50], Step [287/735], Loss: 0.3344\n",
      "Epoch [13/50], Step [288/735], Loss: 0.1536\n",
      "Epoch [13/50], Step [289/735], Loss: 0.0701\n",
      "Epoch [13/50], Step [290/735], Loss: 0.4174\n",
      "Epoch [13/50], Step [291/735], Loss: 0.3585\n",
      "Epoch [13/50], Step [292/735], Loss: 0.1367\n",
      "Epoch [13/50], Step [293/735], Loss: 0.4478\n",
      "Epoch [13/50], Step [294/735], Loss: 0.7646\n",
      "Epoch [13/50], Step [295/735], Loss: 0.5310\n",
      "Epoch [13/50], Step [296/735], Loss: 0.2209\n",
      "Epoch [13/50], Step [297/735], Loss: 0.1836\n",
      "Epoch [13/50], Step [298/735], Loss: 0.2539\n",
      "Epoch [13/50], Step [299/735], Loss: 0.6040\n",
      "Epoch [13/50], Step [300/735], Loss: 0.4058\n",
      "Epoch [13/50], Step [301/735], Loss: 0.2461\n",
      "Epoch [13/50], Step [302/735], Loss: 0.5355\n",
      "Epoch [13/50], Step [303/735], Loss: 1.9423\n",
      "Epoch [13/50], Step [304/735], Loss: 0.6439\n",
      "Epoch [13/50], Step [305/735], Loss: 0.4176\n",
      "Epoch [13/50], Step [306/735], Loss: 0.1207\n",
      "Epoch [13/50], Step [307/735], Loss: 0.7721\n",
      "Epoch [13/50], Step [308/735], Loss: 1.5815\n",
      "Epoch [13/50], Step [309/735], Loss: 0.1584\n",
      "Epoch [13/50], Step [310/735], Loss: 0.2117\n",
      "Epoch [13/50], Step [311/735], Loss: 0.2526\n",
      "Epoch [13/50], Step [312/735], Loss: 0.5988\n",
      "Epoch [13/50], Step [313/735], Loss: 1.3693\n",
      "Epoch [13/50], Step [314/735], Loss: 0.1185\n",
      "Epoch [13/50], Step [315/735], Loss: 0.2859\n",
      "Epoch [13/50], Step [316/735], Loss: 0.7047\n",
      "Epoch [13/50], Step [317/735], Loss: 0.1620\n",
      "Epoch [13/50], Step [318/735], Loss: 0.1974\n",
      "Epoch [13/50], Step [319/735], Loss: 0.1664\n",
      "Epoch [13/50], Step [320/735], Loss: 0.1189\n",
      "Epoch [13/50], Step [321/735], Loss: 0.6328\n",
      "Epoch [13/50], Step [322/735], Loss: 0.2889\n",
      "Epoch [13/50], Step [323/735], Loss: 0.6136\n",
      "Epoch [13/50], Step [324/735], Loss: 0.0893\n",
      "Epoch [13/50], Step [325/735], Loss: 0.9683\n",
      "Epoch [13/50], Step [326/735], Loss: 0.0944\n",
      "Epoch [13/50], Step [327/735], Loss: 0.2381\n",
      "Epoch [13/50], Step [328/735], Loss: 0.5203\n",
      "Epoch [13/50], Step [329/735], Loss: 0.1584\n",
      "Epoch [13/50], Step [330/735], Loss: 0.0601\n",
      "Epoch [13/50], Step [331/735], Loss: 0.7749\n",
      "Epoch [13/50], Step [332/735], Loss: 1.7890\n",
      "Epoch [13/50], Step [333/735], Loss: 0.1993\n",
      "Epoch [13/50], Step [334/735], Loss: 1.0923\n",
      "Epoch [13/50], Step [335/735], Loss: 0.1974\n",
      "Epoch [13/50], Step [336/735], Loss: 0.4206\n",
      "Epoch [13/50], Step [337/735], Loss: 0.0970\n",
      "Epoch [13/50], Step [338/735], Loss: 0.7574\n",
      "Epoch [13/50], Step [339/735], Loss: 0.2313\n",
      "Epoch [13/50], Step [340/735], Loss: 0.1628\n",
      "Epoch [13/50], Step [341/735], Loss: 0.1587\n",
      "Epoch [13/50], Step [342/735], Loss: 0.0941\n",
      "Epoch [13/50], Step [343/735], Loss: 0.2545\n",
      "Epoch [13/50], Step [344/735], Loss: 0.0881\n",
      "Epoch [13/50], Step [345/735], Loss: 0.6762\n",
      "Epoch [13/50], Step [346/735], Loss: 0.6866\n",
      "Epoch [13/50], Step [347/735], Loss: 0.1415\n",
      "Epoch [13/50], Step [348/735], Loss: 0.2036\n",
      "Epoch [13/50], Step [349/735], Loss: 4.9216\n",
      "Epoch [13/50], Step [350/735], Loss: 0.2385\n",
      "Epoch [13/50], Step [351/735], Loss: 1.0909\n",
      "Epoch [13/50], Step [352/735], Loss: 0.7258\n",
      "Epoch [13/50], Step [353/735], Loss: 0.7659\n",
      "Epoch [13/50], Step [354/735], Loss: 0.4499\n",
      "Epoch [13/50], Step [355/735], Loss: 0.8724\n",
      "Epoch [13/50], Step [356/735], Loss: 0.6451\n",
      "Epoch [13/50], Step [357/735], Loss: 0.7177\n",
      "Epoch [13/50], Step [358/735], Loss: 0.1056\n",
      "Epoch [13/50], Step [359/735], Loss: 0.5424\n",
      "Epoch [13/50], Step [360/735], Loss: 0.1985\n",
      "Epoch [13/50], Step [361/735], Loss: 0.1628\n",
      "Epoch [13/50], Step [362/735], Loss: 0.0648\n",
      "Epoch [13/50], Step [363/735], Loss: 0.5989\n",
      "Epoch [13/50], Step [364/735], Loss: 0.2907\n",
      "Epoch [13/50], Step [365/735], Loss: 0.2698\n",
      "Epoch [13/50], Step [366/735], Loss: 0.2861\n",
      "Epoch [13/50], Step [367/735], Loss: 0.0937\n",
      "Epoch [13/50], Step [368/735], Loss: 0.2212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Step [369/735], Loss: 0.4730\n",
      "Epoch [13/50], Step [370/735], Loss: 0.1748\n",
      "Epoch [13/50], Step [371/735], Loss: 0.3823\n",
      "Epoch [13/50], Step [372/735], Loss: 0.2176\n",
      "Epoch [13/50], Step [373/735], Loss: 0.1359\n",
      "Epoch [13/50], Step [374/735], Loss: 1.0450\n",
      "Epoch [13/50], Step [375/735], Loss: 0.2112\n",
      "Epoch [13/50], Step [376/735], Loss: 0.2056\n",
      "Epoch [13/50], Step [377/735], Loss: 0.3065\n",
      "Epoch [13/50], Step [378/735], Loss: 0.2775\n",
      "Epoch [13/50], Step [379/735], Loss: 0.0661\n",
      "Epoch [13/50], Step [380/735], Loss: 1.2540\n",
      "Epoch [13/50], Step [381/735], Loss: 0.2710\n",
      "Epoch [13/50], Step [382/735], Loss: 0.2183\n",
      "Epoch [13/50], Step [383/735], Loss: 0.7501\n",
      "Epoch [13/50], Step [384/735], Loss: 0.9122\n",
      "Epoch [13/50], Step [385/735], Loss: 0.2699\n",
      "Epoch [13/50], Step [386/735], Loss: 0.2792\n",
      "Epoch [13/50], Step [387/735], Loss: 0.3731\n",
      "Epoch [13/50], Step [388/735], Loss: 0.2574\n",
      "Epoch [13/50], Step [389/735], Loss: 0.7112\n",
      "Epoch [13/50], Step [390/735], Loss: 0.3206\n",
      "Epoch [13/50], Step [391/735], Loss: 0.2366\n",
      "Epoch [13/50], Step [392/735], Loss: 0.3018\n",
      "Epoch [13/50], Step [393/735], Loss: 0.3771\n",
      "Epoch [13/50], Step [394/735], Loss: 0.3131\n",
      "Epoch [13/50], Step [395/735], Loss: 0.1488\n",
      "Epoch [13/50], Step [396/735], Loss: 0.1762\n",
      "Epoch [13/50], Step [397/735], Loss: 0.1814\n",
      "Epoch [13/50], Step [398/735], Loss: 0.2646\n",
      "Epoch [13/50], Step [399/735], Loss: 0.1446\n",
      "Epoch [13/50], Step [400/735], Loss: 0.1625\n",
      "Epoch [13/50], Step [401/735], Loss: 0.3965\n",
      "Epoch [13/50], Step [402/735], Loss: 0.3554\n",
      "Epoch [13/50], Step [403/735], Loss: 0.1677\n",
      "Epoch [13/50], Step [404/735], Loss: 0.1026\n",
      "Epoch [13/50], Step [405/735], Loss: 0.5697\n",
      "Epoch [13/50], Step [406/735], Loss: 0.4060\n",
      "Epoch [13/50], Step [407/735], Loss: 0.1090\n",
      "Epoch [13/50], Step [408/735], Loss: 0.2702\n",
      "Epoch [13/50], Step [409/735], Loss: 0.2678\n",
      "Epoch [13/50], Step [410/735], Loss: 0.7519\n",
      "Epoch [13/50], Step [411/735], Loss: 0.6571\n",
      "Epoch [13/50], Step [412/735], Loss: 0.1904\n",
      "Epoch [13/50], Step [413/735], Loss: 0.3043\n",
      "Epoch [13/50], Step [414/735], Loss: 0.4994\n",
      "Epoch [13/50], Step [415/735], Loss: 0.4514\n",
      "Epoch [13/50], Step [416/735], Loss: 0.1846\n",
      "Epoch [13/50], Step [417/735], Loss: 0.2293\n",
      "Epoch [13/50], Step [418/735], Loss: 0.9107\n",
      "Epoch [13/50], Step [419/735], Loss: 0.0842\n",
      "Epoch [13/50], Step [420/735], Loss: 0.5355\n",
      "Epoch [13/50], Step [421/735], Loss: 0.2197\n",
      "Epoch [13/50], Step [422/735], Loss: 1.0354\n",
      "Epoch [13/50], Step [423/735], Loss: 1.2930\n",
      "Epoch [13/50], Step [424/735], Loss: 0.2594\n",
      "Epoch [13/50], Step [425/735], Loss: 0.0691\n",
      "Epoch [13/50], Step [426/735], Loss: 0.1759\n",
      "Epoch [13/50], Step [427/735], Loss: 0.2417\n",
      "Epoch [13/50], Step [428/735], Loss: 0.0614\n",
      "Epoch [13/50], Step [429/735], Loss: 0.4635\n",
      "Epoch [13/50], Step [430/735], Loss: 0.3661\n",
      "Epoch [13/50], Step [431/735], Loss: 0.4365\n",
      "Epoch [13/50], Step [432/735], Loss: 0.3906\n",
      "Epoch [13/50], Step [433/735], Loss: 0.6156\n",
      "Epoch [13/50], Step [434/735], Loss: 0.2833\n",
      "Epoch [13/50], Step [435/735], Loss: 0.6129\n",
      "Epoch [13/50], Step [436/735], Loss: 0.0879\n",
      "Epoch [13/50], Step [437/735], Loss: 0.1485\n",
      "Epoch [13/50], Step [438/735], Loss: 0.1766\n",
      "Epoch [13/50], Step [439/735], Loss: 0.9416\n",
      "Epoch [13/50], Step [440/735], Loss: 0.1259\n",
      "Epoch [13/50], Step [441/735], Loss: 0.1749\n",
      "Epoch [13/50], Step [442/735], Loss: 0.1360\n",
      "Epoch [13/50], Step [443/735], Loss: 0.5620\n",
      "Epoch [13/50], Step [444/735], Loss: 1.2212\n",
      "Epoch [13/50], Step [445/735], Loss: 0.4657\n",
      "Epoch [13/50], Step [446/735], Loss: 0.5045\n",
      "Epoch [13/50], Step [447/735], Loss: 5.0967\n",
      "Epoch [13/50], Step [448/735], Loss: 0.5411\n",
      "Epoch [13/50], Step [449/735], Loss: 0.2824\n",
      "Epoch [13/50], Step [450/735], Loss: 0.2124\n",
      "Epoch [13/50], Step [451/735], Loss: 0.3840\n",
      "Epoch [13/50], Step [452/735], Loss: 0.2097\n",
      "Epoch [13/50], Step [453/735], Loss: 0.6874\n",
      "Epoch [13/50], Step [454/735], Loss: 0.6903\n",
      "Epoch [13/50], Step [455/735], Loss: 0.5558\n",
      "Epoch [13/50], Step [456/735], Loss: 0.4094\n",
      "Epoch [13/50], Step [457/735], Loss: 1.1127\n",
      "Epoch [13/50], Step [458/735], Loss: 0.5511\n",
      "Epoch [13/50], Step [459/735], Loss: 0.5299\n",
      "Epoch [13/50], Step [460/735], Loss: 0.7756\n",
      "Epoch [13/50], Step [461/735], Loss: 0.3707\n",
      "Epoch [13/50], Step [462/735], Loss: 0.2449\n",
      "Epoch [13/50], Step [463/735], Loss: 0.7397\n",
      "Epoch [13/50], Step [464/735], Loss: 1.7260\n",
      "Epoch [13/50], Step [465/735], Loss: 0.1353\n",
      "Epoch [13/50], Step [466/735], Loss: 0.2538\n",
      "Epoch [13/50], Step [467/735], Loss: 0.2888\n",
      "Epoch [13/50], Step [468/735], Loss: 0.2889\n",
      "Epoch [13/50], Step [469/735], Loss: 0.3020\n",
      "Epoch [13/50], Step [470/735], Loss: 0.4008\n",
      "Epoch [13/50], Step [471/735], Loss: 0.6166\n",
      "Epoch [13/50], Step [472/735], Loss: 0.1824\n",
      "Epoch [13/50], Step [473/735], Loss: 0.4169\n",
      "Epoch [13/50], Step [474/735], Loss: 0.0798\n",
      "Epoch [13/50], Step [475/735], Loss: 0.3003\n",
      "Epoch [13/50], Step [476/735], Loss: 0.2657\n",
      "Epoch [13/50], Step [477/735], Loss: 0.5652\n",
      "Epoch [13/50], Step [478/735], Loss: 0.4462\n",
      "Epoch [13/50], Step [479/735], Loss: 0.3612\n",
      "Epoch [13/50], Step [480/735], Loss: 0.2851\n",
      "Epoch [13/50], Step [481/735], Loss: 0.2333\n",
      "Epoch [13/50], Step [482/735], Loss: 0.6123\n",
      "Epoch [13/50], Step [483/735], Loss: 0.3026\n",
      "Epoch [13/50], Step [484/735], Loss: 0.1414\n",
      "Epoch [13/50], Step [485/735], Loss: 0.5102\n",
      "Epoch [13/50], Step [486/735], Loss: 0.2793\n",
      "Epoch [13/50], Step [487/735], Loss: 0.4590\n",
      "Epoch [13/50], Step [488/735], Loss: 0.3059\n",
      "Epoch [13/50], Step [489/735], Loss: 0.8934\n",
      "Epoch [13/50], Step [490/735], Loss: 0.4085\n",
      "Epoch [13/50], Step [491/735], Loss: 0.4963\n",
      "Epoch [13/50], Step [492/735], Loss: 0.3655\n",
      "Epoch [13/50], Step [493/735], Loss: 1.6178\n",
      "Epoch [13/50], Step [494/735], Loss: 0.2871\n",
      "Epoch [13/50], Step [495/735], Loss: 0.3900\n",
      "Epoch [13/50], Step [496/735], Loss: 0.1839\n",
      "Epoch [13/50], Step [497/735], Loss: 0.1993\n",
      "Epoch [13/50], Step [498/735], Loss: 0.3898\n",
      "Epoch [13/50], Step [499/735], Loss: 0.4227\n",
      "Epoch [13/50], Step [500/735], Loss: 0.3131\n",
      "Epoch [13/50], Step [501/735], Loss: 0.3172\n",
      "Epoch [13/50], Step [502/735], Loss: 0.6609\n",
      "Epoch [13/50], Step [503/735], Loss: 0.6724\n",
      "Epoch [13/50], Step [504/735], Loss: 1.0454\n",
      "Epoch [13/50], Step [505/735], Loss: 1.3799\n",
      "Epoch [13/50], Step [506/735], Loss: 0.1133\n",
      "Epoch [13/50], Step [507/735], Loss: 2.5380\n",
      "Epoch [13/50], Step [508/735], Loss: 1.7269\n",
      "Epoch [13/50], Step [509/735], Loss: 0.1790\n",
      "Epoch [13/50], Step [510/735], Loss: 0.3316\n",
      "Epoch [13/50], Step [511/735], Loss: 0.1048\n",
      "Epoch [13/50], Step [512/735], Loss: 0.2136\n",
      "Epoch [13/50], Step [513/735], Loss: 0.2874\n",
      "Epoch [13/50], Step [514/735], Loss: 0.2167\n",
      "Epoch [13/50], Step [515/735], Loss: 0.2761\n",
      "Epoch [13/50], Step [516/735], Loss: 0.0764\n",
      "Epoch [13/50], Step [517/735], Loss: 0.2821\n",
      "Epoch [13/50], Step [518/735], Loss: 0.2306\n",
      "Epoch [13/50], Step [519/735], Loss: 0.5469\n",
      "Epoch [13/50], Step [520/735], Loss: 0.3214\n",
      "Epoch [13/50], Step [521/735], Loss: 0.3793\n",
      "Epoch [13/50], Step [522/735], Loss: 0.5863\n",
      "Epoch [13/50], Step [523/735], Loss: 0.3430\n",
      "Epoch [13/50], Step [524/735], Loss: 0.0852\n",
      "Epoch [13/50], Step [525/735], Loss: 0.5269\n",
      "Epoch [13/50], Step [526/735], Loss: 1.0571\n",
      "Epoch [13/50], Step [527/735], Loss: 0.2687\n",
      "Epoch [13/50], Step [528/735], Loss: 0.1463\n",
      "Epoch [13/50], Step [529/735], Loss: 0.7121\n",
      "Epoch [13/50], Step [530/735], Loss: 0.1516\n",
      "Epoch [13/50], Step [531/735], Loss: 0.2606\n",
      "Epoch [13/50], Step [532/735], Loss: 0.3161\n",
      "Epoch [13/50], Step [533/735], Loss: 0.5361\n",
      "Epoch [13/50], Step [534/735], Loss: 0.5896\n",
      "Epoch [13/50], Step [535/735], Loss: 0.4648\n",
      "Epoch [13/50], Step [536/735], Loss: 0.2533\n",
      "Epoch [13/50], Step [537/735], Loss: 0.3048\n",
      "Epoch [13/50], Step [538/735], Loss: 0.5076\n",
      "Epoch [13/50], Step [539/735], Loss: 0.7816\n",
      "Epoch [13/50], Step [540/735], Loss: 0.3768\n",
      "Epoch [13/50], Step [541/735], Loss: 0.8584\n",
      "Epoch [13/50], Step [542/735], Loss: 0.2730\n",
      "Epoch [13/50], Step [543/735], Loss: 0.7544\n",
      "Epoch [13/50], Step [544/735], Loss: 0.3095\n",
      "Epoch [13/50], Step [545/735], Loss: 0.2471\n",
      "Epoch [13/50], Step [546/735], Loss: 0.7284\n",
      "Epoch [13/50], Step [547/735], Loss: 0.4304\n",
      "Epoch [13/50], Step [548/735], Loss: 0.1098\n",
      "Epoch [13/50], Step [549/735], Loss: 0.4947\n",
      "Epoch [13/50], Step [550/735], Loss: 0.2650\n",
      "Epoch [13/50], Step [551/735], Loss: 0.3550\n",
      "Epoch [13/50], Step [552/735], Loss: 0.4137\n",
      "Epoch [13/50], Step [553/735], Loss: 0.3418\n",
      "Epoch [13/50], Step [554/735], Loss: 0.1154\n",
      "Epoch [13/50], Step [555/735], Loss: 0.1907\n",
      "Epoch [13/50], Step [556/735], Loss: 0.0842\n",
      "Epoch [13/50], Step [557/735], Loss: 0.3490\n",
      "Epoch [13/50], Step [558/735], Loss: 0.9501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Step [559/735], Loss: 0.4119\n",
      "Epoch [13/50], Step [560/735], Loss: 2.0337\n",
      "Epoch [13/50], Step [561/735], Loss: 0.8673\n",
      "Epoch [13/50], Step [562/735], Loss: 0.2651\n",
      "Epoch [13/50], Step [563/735], Loss: 0.3930\n",
      "Epoch [13/50], Step [564/735], Loss: 0.4489\n",
      "Epoch [13/50], Step [565/735], Loss: 0.2314\n",
      "Epoch [13/50], Step [566/735], Loss: 0.3371\n",
      "Epoch [13/50], Step [567/735], Loss: 0.1462\n",
      "Epoch [13/50], Step [568/735], Loss: 0.3539\n",
      "Epoch [13/50], Step [569/735], Loss: 1.2552\n",
      "Epoch [13/50], Step [570/735], Loss: 0.0729\n",
      "Epoch [13/50], Step [571/735], Loss: 1.3346\n",
      "Epoch [13/50], Step [572/735], Loss: 0.1793\n",
      "Epoch [13/50], Step [573/735], Loss: 0.1622\n",
      "Epoch [13/50], Step [574/735], Loss: 0.4769\n",
      "Epoch [13/50], Step [575/735], Loss: 0.0842\n",
      "Epoch [13/50], Step [576/735], Loss: 0.2896\n",
      "Epoch [13/50], Step [577/735], Loss: 0.9746\n",
      "Epoch [13/50], Step [578/735], Loss: 0.3759\n",
      "Epoch [13/50], Step [579/735], Loss: 0.4832\n",
      "Epoch [13/50], Step [580/735], Loss: 0.2989\n",
      "Epoch [13/50], Step [581/735], Loss: 0.1073\n",
      "Epoch [13/50], Step [582/735], Loss: 0.1554\n",
      "Epoch [13/50], Step [583/735], Loss: 0.1812\n",
      "Epoch [13/50], Step [584/735], Loss: 0.3454\n",
      "Epoch [13/50], Step [585/735], Loss: 0.2794\n",
      "Epoch [13/50], Step [586/735], Loss: 0.4635\n",
      "Epoch [13/50], Step [587/735], Loss: 1.1542\n",
      "Epoch [13/50], Step [588/735], Loss: 0.3407\n",
      "Epoch [13/50], Step [589/735], Loss: 0.1995\n",
      "Epoch [13/50], Step [590/735], Loss: 0.5362\n",
      "Epoch [13/50], Step [591/735], Loss: 0.3417\n",
      "Epoch [13/50], Step [592/735], Loss: 0.8765\n",
      "Epoch [13/50], Step [593/735], Loss: 1.0510\n",
      "Epoch [13/50], Step [594/735], Loss: 0.2431\n",
      "Epoch [13/50], Step [595/735], Loss: 1.0040\n",
      "Epoch [13/50], Step [596/735], Loss: 0.5408\n",
      "Epoch [13/50], Step [597/735], Loss: 0.0814\n",
      "Epoch [13/50], Step [598/735], Loss: 0.1918\n",
      "Epoch [13/50], Step [599/735], Loss: 0.3096\n",
      "Epoch [13/50], Step [600/735], Loss: 0.1769\n",
      "Epoch [13/50], Step [601/735], Loss: 0.2274\n",
      "Epoch [13/50], Step [602/735], Loss: 0.5253\n",
      "Epoch [13/50], Step [603/735], Loss: 0.5133\n",
      "Epoch [13/50], Step [604/735], Loss: 0.3036\n",
      "Epoch [13/50], Step [605/735], Loss: 0.1823\n",
      "Epoch [13/50], Step [606/735], Loss: 0.2868\n",
      "Epoch [13/50], Step [607/735], Loss: 0.5851\n",
      "Epoch [13/50], Step [608/735], Loss: 0.3960\n",
      "Epoch [13/50], Step [609/735], Loss: 1.5108\n",
      "Epoch [13/50], Step [610/735], Loss: 0.5879\n",
      "Epoch [13/50], Step [611/735], Loss: 0.1423\n",
      "Epoch [13/50], Step [612/735], Loss: 0.1161\n",
      "Epoch [13/50], Step [613/735], Loss: 0.1282\n",
      "Epoch [13/50], Step [614/735], Loss: 0.1521\n",
      "Epoch [13/50], Step [615/735], Loss: 0.6002\n",
      "Epoch [13/50], Step [616/735], Loss: 0.4877\n",
      "Epoch [13/50], Step [617/735], Loss: 0.2945\n",
      "Epoch [13/50], Step [618/735], Loss: 0.6780\n",
      "Epoch [13/50], Step [619/735], Loss: 0.4704\n",
      "Epoch [13/50], Step [620/735], Loss: 0.2928\n",
      "Epoch [13/50], Step [621/735], Loss: 0.8443\n",
      "Epoch [13/50], Step [622/735], Loss: 1.0366\n",
      "Epoch [13/50], Step [623/735], Loss: 0.3268\n",
      "Epoch [13/50], Step [624/735], Loss: 1.0300\n",
      "Epoch [13/50], Step [625/735], Loss: 0.1658\n",
      "Epoch [13/50], Step [626/735], Loss: 0.3202\n",
      "Epoch [13/50], Step [627/735], Loss: 1.2899\n",
      "Epoch [13/50], Step [628/735], Loss: 0.4311\n",
      "Epoch [13/50], Step [629/735], Loss: 0.5156\n",
      "Epoch [13/50], Step [630/735], Loss: 0.4513\n",
      "Epoch [13/50], Step [631/735], Loss: 0.2006\n",
      "Epoch [13/50], Step [632/735], Loss: 0.4273\n",
      "Epoch [13/50], Step [633/735], Loss: 0.5447\n",
      "Epoch [13/50], Step [634/735], Loss: 2.1176\n",
      "Epoch [13/50], Step [635/735], Loss: 0.1243\n",
      "Epoch [13/50], Step [636/735], Loss: 0.5837\n",
      "Epoch [13/50], Step [637/735], Loss: 0.3191\n",
      "Epoch [13/50], Step [638/735], Loss: 0.3267\n",
      "Epoch [13/50], Step [639/735], Loss: 0.4131\n",
      "Epoch [13/50], Step [640/735], Loss: 0.1210\n",
      "Epoch [13/50], Step [641/735], Loss: 1.3111\n",
      "Epoch [13/50], Step [642/735], Loss: 0.0970\n",
      "Epoch [13/50], Step [643/735], Loss: 0.3948\n",
      "Epoch [13/50], Step [644/735], Loss: 0.6047\n",
      "Epoch [13/50], Step [645/735], Loss: 0.5209\n",
      "Epoch [13/50], Step [646/735], Loss: 0.2266\n",
      "Epoch [13/50], Step [647/735], Loss: 0.3695\n",
      "Epoch [13/50], Step [648/735], Loss: 0.5117\n",
      "Epoch [13/50], Step [649/735], Loss: 0.3519\n",
      "Epoch [13/50], Step [650/735], Loss: 0.2558\n",
      "Epoch [13/50], Step [651/735], Loss: 0.6830\n",
      "Epoch [13/50], Step [652/735], Loss: 0.9815\n",
      "Epoch [13/50], Step [653/735], Loss: 0.6261\n",
      "Epoch [13/50], Step [654/735], Loss: 0.3963\n",
      "Epoch [13/50], Step [655/735], Loss: 0.4578\n",
      "Epoch [13/50], Step [656/735], Loss: 0.4088\n",
      "Epoch [13/50], Step [657/735], Loss: 0.2124\n",
      "Epoch [13/50], Step [658/735], Loss: 0.4229\n",
      "Epoch [13/50], Step [659/735], Loss: 0.4472\n",
      "Epoch [13/50], Step [660/735], Loss: 0.6460\n",
      "Epoch [13/50], Step [661/735], Loss: 0.2079\n",
      "Epoch [13/50], Step [662/735], Loss: 0.2091\n",
      "Epoch [13/50], Step [663/735], Loss: 1.7054\n",
      "Epoch [13/50], Step [664/735], Loss: 0.4709\n",
      "Epoch [13/50], Step [665/735], Loss: 0.1195\n",
      "Epoch [13/50], Step [666/735], Loss: 1.9134\n",
      "Epoch [13/50], Step [667/735], Loss: 0.2645\n",
      "Epoch [13/50], Step [668/735], Loss: 0.1913\n",
      "Epoch [13/50], Step [669/735], Loss: 0.2493\n",
      "Epoch [13/50], Step [670/735], Loss: 0.1222\n",
      "Epoch [13/50], Step [671/735], Loss: 2.2206\n",
      "Epoch [13/50], Step [672/735], Loss: 0.3060\n",
      "Epoch [13/50], Step [673/735], Loss: 2.2091\n",
      "Epoch [13/50], Step [674/735], Loss: 0.0671\n",
      "Epoch [13/50], Step [675/735], Loss: 0.1193\n",
      "Epoch [13/50], Step [676/735], Loss: 0.1509\n",
      "Epoch [13/50], Step [677/735], Loss: 0.0767\n",
      "Epoch [13/50], Step [678/735], Loss: 0.4818\n",
      "Epoch [13/50], Step [679/735], Loss: 0.2708\n",
      "Epoch [13/50], Step [680/735], Loss: 0.8980\n",
      "Epoch [13/50], Step [681/735], Loss: 0.2415\n",
      "Epoch [13/50], Step [682/735], Loss: 0.4475\n",
      "Epoch [13/50], Step [683/735], Loss: 0.6291\n",
      "Epoch [13/50], Step [684/735], Loss: 0.4767\n",
      "Epoch [13/50], Step [685/735], Loss: 0.5573\n",
      "Epoch [13/50], Step [686/735], Loss: 0.4078\n",
      "Epoch [13/50], Step [687/735], Loss: 0.3760\n",
      "Epoch [13/50], Step [688/735], Loss: 0.2787\n",
      "Epoch [13/50], Step [689/735], Loss: 1.5730\n",
      "Epoch [13/50], Step [690/735], Loss: 0.0944\n",
      "Epoch [13/50], Step [691/735], Loss: 0.1428\n",
      "Epoch [13/50], Step [692/735], Loss: 0.6773\n",
      "Epoch [13/50], Step [693/735], Loss: 1.5843\n",
      "Epoch [13/50], Step [694/735], Loss: 0.3743\n",
      "Epoch [13/50], Step [695/735], Loss: 0.2134\n",
      "Epoch [13/50], Step [696/735], Loss: 0.1822\n",
      "Epoch [13/50], Step [697/735], Loss: 0.3071\n",
      "Epoch [13/50], Step [698/735], Loss: 0.6757\n",
      "Epoch [13/50], Step [699/735], Loss: 0.2287\n",
      "Epoch [13/50], Step [700/735], Loss: 0.1873\n",
      "Epoch [13/50], Step [701/735], Loss: 0.0650\n",
      "Epoch [13/50], Step [702/735], Loss: 0.0909\n",
      "Epoch [13/50], Step [703/735], Loss: 0.1036\n",
      "Epoch [13/50], Step [704/735], Loss: 0.2714\n",
      "Epoch [13/50], Step [705/735], Loss: 0.0596\n",
      "Epoch [13/50], Step [706/735], Loss: 0.4708\n",
      "Epoch [13/50], Step [707/735], Loss: 1.4987\n",
      "Epoch [13/50], Step [708/735], Loss: 0.3901\n",
      "Epoch [13/50], Step [709/735], Loss: 0.2509\n",
      "Epoch [13/50], Step [710/735], Loss: 0.5172\n",
      "Epoch [13/50], Step [711/735], Loss: 0.2309\n",
      "Epoch [13/50], Step [712/735], Loss: 0.5010\n",
      "Epoch [13/50], Step [713/735], Loss: 0.1113\n",
      "Epoch [13/50], Step [714/735], Loss: 0.2387\n",
      "Epoch [13/50], Step [715/735], Loss: 0.2888\n",
      "Epoch [13/50], Step [716/735], Loss: 0.7095\n",
      "Epoch [13/50], Step [717/735], Loss: 0.3517\n",
      "Epoch [13/50], Step [718/735], Loss: 0.5838\n",
      "Epoch [13/50], Step [719/735], Loss: 0.3024\n",
      "Epoch [13/50], Step [720/735], Loss: 0.2317\n",
      "Epoch [13/50], Step [721/735], Loss: 0.3024\n",
      "Epoch [13/50], Step [722/735], Loss: 0.3954\n",
      "Epoch [13/50], Step [723/735], Loss: 0.4287\n",
      "Epoch [13/50], Step [724/735], Loss: 0.5330\n",
      "Epoch [13/50], Step [725/735], Loss: 0.2423\n",
      "Epoch [13/50], Step [726/735], Loss: 0.3734\n",
      "Epoch [13/50], Step [727/735], Loss: 0.3900\n",
      "Epoch [13/50], Step [728/735], Loss: 2.2605\n",
      "Epoch [13/50], Step [729/735], Loss: 0.0997\n",
      "Epoch [13/50], Step [730/735], Loss: 0.3357\n",
      "Epoch [13/50], Step [731/735], Loss: 0.1813\n",
      "Epoch [13/50], Step [732/735], Loss: 0.7421\n",
      "Epoch [13/50], Step [733/735], Loss: 0.4600\n",
      "Epoch [13/50], Step [734/735], Loss: 0.4155\n",
      "Epoch [13/50], Step [735/735], Loss: 0.3642\n",
      "Epoch [14/50], Step [1/735], Loss: 1.6775\n",
      "Epoch [14/50], Step [2/735], Loss: 0.5295\n",
      "Epoch [14/50], Step [3/735], Loss: 0.8034\n",
      "Epoch [14/50], Step [4/735], Loss: 0.2512\n",
      "Epoch [14/50], Step [5/735], Loss: 0.2219\n",
      "Epoch [14/50], Step [6/735], Loss: 0.2214\n",
      "Epoch [14/50], Step [7/735], Loss: 0.4044\n",
      "Epoch [14/50], Step [8/735], Loss: 0.3916\n",
      "Epoch [14/50], Step [9/735], Loss: 0.9114\n",
      "Epoch [14/50], Step [10/735], Loss: 0.1632\n",
      "Epoch [14/50], Step [11/735], Loss: 1.0804\n",
      "Epoch [14/50], Step [12/735], Loss: 0.2527\n",
      "Epoch [14/50], Step [13/735], Loss: 0.0635\n",
      "Epoch [14/50], Step [14/735], Loss: 0.2816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Step [15/735], Loss: 0.7722\n",
      "Epoch [14/50], Step [16/735], Loss: 0.0796\n",
      "Epoch [14/50], Step [17/735], Loss: 0.2846\n",
      "Epoch [14/50], Step [18/735], Loss: 0.5688\n",
      "Epoch [14/50], Step [19/735], Loss: 0.4791\n",
      "Epoch [14/50], Step [20/735], Loss: 0.3629\n",
      "Epoch [14/50], Step [21/735], Loss: 0.3545\n",
      "Epoch [14/50], Step [22/735], Loss: 0.2700\n",
      "Epoch [14/50], Step [23/735], Loss: 0.3173\n",
      "Epoch [14/50], Step [24/735], Loss: 0.6529\n",
      "Epoch [14/50], Step [25/735], Loss: 0.0927\n",
      "Epoch [14/50], Step [26/735], Loss: 0.3190\n",
      "Epoch [14/50], Step [27/735], Loss: 0.1505\n",
      "Epoch [14/50], Step [28/735], Loss: 0.1989\n",
      "Epoch [14/50], Step [29/735], Loss: 0.2965\n",
      "Epoch [14/50], Step [30/735], Loss: 1.1038\n",
      "Epoch [14/50], Step [31/735], Loss: 0.2428\n",
      "Epoch [14/50], Step [32/735], Loss: 0.1233\n",
      "Epoch [14/50], Step [33/735], Loss: 0.2418\n",
      "Epoch [14/50], Step [34/735], Loss: 0.2398\n",
      "Epoch [14/50], Step [35/735], Loss: 0.1436\n",
      "Epoch [14/50], Step [36/735], Loss: 0.9900\n",
      "Epoch [14/50], Step [37/735], Loss: 0.2094\n",
      "Epoch [14/50], Step [38/735], Loss: 0.1172\n",
      "Epoch [14/50], Step [39/735], Loss: 0.3065\n",
      "Epoch [14/50], Step [40/735], Loss: 0.3015\n",
      "Epoch [14/50], Step [41/735], Loss: 0.2016\n",
      "Epoch [14/50], Step [42/735], Loss: 0.1946\n",
      "Epoch [14/50], Step [43/735], Loss: 0.2984\n",
      "Epoch [14/50], Step [44/735], Loss: 0.1290\n",
      "Epoch [14/50], Step [45/735], Loss: 0.2963\n",
      "Epoch [14/50], Step [46/735], Loss: 0.5972\n",
      "Epoch [14/50], Step [47/735], Loss: 0.3083\n",
      "Epoch [14/50], Step [48/735], Loss: 0.1726\n",
      "Epoch [14/50], Step [49/735], Loss: 0.4400\n",
      "Epoch [14/50], Step [50/735], Loss: 3.0350\n",
      "Epoch [14/50], Step [51/735], Loss: 0.6308\n",
      "Epoch [14/50], Step [52/735], Loss: 0.6310\n",
      "Epoch [14/50], Step [53/735], Loss: 1.4041\n",
      "Epoch [14/50], Step [54/735], Loss: 2.1858\n",
      "Epoch [14/50], Step [55/735], Loss: 0.1172\n",
      "Epoch [14/50], Step [56/735], Loss: 0.1560\n",
      "Epoch [14/50], Step [57/735], Loss: 0.1252\n",
      "Epoch [14/50], Step [58/735], Loss: 0.2756\n",
      "Epoch [14/50], Step [59/735], Loss: 0.2771\n",
      "Epoch [14/50], Step [60/735], Loss: 0.2823\n",
      "Epoch [14/50], Step [61/735], Loss: 0.4318\n",
      "Epoch [14/50], Step [62/735], Loss: 0.5048\n",
      "Epoch [14/50], Step [63/735], Loss: 0.2067\n",
      "Epoch [14/50], Step [64/735], Loss: 0.2130\n",
      "Epoch [14/50], Step [65/735], Loss: 0.2148\n",
      "Epoch [14/50], Step [66/735], Loss: 0.4426\n",
      "Epoch [14/50], Step [67/735], Loss: 0.1753\n",
      "Epoch [14/50], Step [68/735], Loss: 0.4117\n",
      "Epoch [14/50], Step [69/735], Loss: 0.2459\n",
      "Epoch [14/50], Step [70/735], Loss: 0.2521\n",
      "Epoch [14/50], Step [71/735], Loss: 0.2779\n",
      "Epoch [14/50], Step [72/735], Loss: 0.1243\n",
      "Epoch [14/50], Step [73/735], Loss: 0.1574\n",
      "Epoch [14/50], Step [74/735], Loss: 0.1593\n",
      "Epoch [14/50], Step [75/735], Loss: 0.5852\n",
      "Epoch [14/50], Step [76/735], Loss: 0.2624\n",
      "Epoch [14/50], Step [77/735], Loss: 0.1649\n",
      "Epoch [14/50], Step [78/735], Loss: 1.7376\n",
      "Epoch [14/50], Step [79/735], Loss: 0.2101\n",
      "Epoch [14/50], Step [80/735], Loss: 0.1917\n",
      "Epoch [14/50], Step [81/735], Loss: 0.5023\n",
      "Epoch [14/50], Step [82/735], Loss: 0.5922\n",
      "Epoch [14/50], Step [83/735], Loss: 0.5071\n",
      "Epoch [14/50], Step [84/735], Loss: 0.7031\n",
      "Epoch [14/50], Step [85/735], Loss: 0.1793\n",
      "Epoch [14/50], Step [86/735], Loss: 0.0962\n",
      "Epoch [14/50], Step [87/735], Loss: 0.1073\n",
      "Epoch [14/50], Step [88/735], Loss: 0.2230\n",
      "Epoch [14/50], Step [89/735], Loss: 0.4364\n",
      "Epoch [14/50], Step [90/735], Loss: 0.3623\n",
      "Epoch [14/50], Step [91/735], Loss: 0.2421\n",
      "Epoch [14/50], Step [92/735], Loss: 0.2772\n",
      "Epoch [14/50], Step [93/735], Loss: 0.7587\n",
      "Epoch [14/50], Step [94/735], Loss: 0.6477\n",
      "Epoch [14/50], Step [95/735], Loss: 0.1721\n",
      "Epoch [14/50], Step [96/735], Loss: 0.3224\n",
      "Epoch [14/50], Step [97/735], Loss: 0.1891\n",
      "Epoch [14/50], Step [98/735], Loss: 0.2529\n",
      "Epoch [14/50], Step [99/735], Loss: 0.1806\n",
      "Epoch [14/50], Step [100/735], Loss: 0.1236\n",
      "Epoch [14/50], Step [101/735], Loss: 0.7395\n",
      "Epoch [14/50], Step [102/735], Loss: 1.1845\n",
      "Epoch [14/50], Step [103/735], Loss: 0.5735\n",
      "Epoch [14/50], Step [104/735], Loss: 0.2151\n",
      "Epoch [14/50], Step [105/735], Loss: 0.3136\n",
      "Epoch [14/50], Step [106/735], Loss: 0.5581\n",
      "Epoch [14/50], Step [107/735], Loss: 0.1077\n",
      "Epoch [14/50], Step [108/735], Loss: 0.3041\n",
      "Epoch [14/50], Step [109/735], Loss: 0.1386\n",
      "Epoch [14/50], Step [110/735], Loss: 0.1453\n",
      "Epoch [14/50], Step [111/735], Loss: 0.3159\n",
      "Epoch [14/50], Step [112/735], Loss: 0.1498\n",
      "Epoch [14/50], Step [113/735], Loss: 0.3228\n",
      "Epoch [14/50], Step [114/735], Loss: 0.2018\n",
      "Epoch [14/50], Step [115/735], Loss: 0.2643\n",
      "Epoch [14/50], Step [116/735], Loss: 1.3444\n",
      "Epoch [14/50], Step [117/735], Loss: 0.7751\n",
      "Epoch [14/50], Step [118/735], Loss: 0.9373\n",
      "Epoch [14/50], Step [119/735], Loss: 0.7656\n",
      "Epoch [14/50], Step [120/735], Loss: 0.4902\n",
      "Epoch [14/50], Step [121/735], Loss: 0.2924\n",
      "Epoch [14/50], Step [122/735], Loss: 0.4814\n",
      "Epoch [14/50], Step [123/735], Loss: 0.0769\n",
      "Epoch [14/50], Step [124/735], Loss: 0.3347\n",
      "Epoch [14/50], Step [125/735], Loss: 0.2737\n",
      "Epoch [14/50], Step [126/735], Loss: 0.1162\n",
      "Epoch [14/50], Step [127/735], Loss: 0.4006\n",
      "Epoch [14/50], Step [128/735], Loss: 0.2675\n",
      "Epoch [14/50], Step [129/735], Loss: 1.9251\n",
      "Epoch [14/50], Step [130/735], Loss: 0.7414\n",
      "Epoch [14/50], Step [131/735], Loss: 0.3078\n",
      "Epoch [14/50], Step [132/735], Loss: 0.6634\n",
      "Epoch [14/50], Step [133/735], Loss: 0.3998\n",
      "Epoch [14/50], Step [134/735], Loss: 0.1220\n",
      "Epoch [14/50], Step [135/735], Loss: 0.3785\n",
      "Epoch [14/50], Step [136/735], Loss: 0.2138\n",
      "Epoch [14/50], Step [137/735], Loss: 0.1730\n",
      "Epoch [14/50], Step [138/735], Loss: 0.8732\n",
      "Epoch [14/50], Step [139/735], Loss: 0.2664\n",
      "Epoch [14/50], Step [140/735], Loss: 1.0146\n",
      "Epoch [14/50], Step [141/735], Loss: 0.7567\n",
      "Epoch [14/50], Step [142/735], Loss: 0.4698\n",
      "Epoch [14/50], Step [143/735], Loss: 1.3587\n",
      "Epoch [14/50], Step [144/735], Loss: 0.2508\n",
      "Epoch [14/50], Step [145/735], Loss: 0.7165\n",
      "Epoch [14/50], Step [146/735], Loss: 0.1775\n",
      "Epoch [14/50], Step [147/735], Loss: 0.0747\n",
      "Epoch [14/50], Step [148/735], Loss: 0.5392\n",
      "Epoch [14/50], Step [149/735], Loss: 0.1974\n",
      "Epoch [14/50], Step [150/735], Loss: 0.2535\n",
      "Epoch [14/50], Step [151/735], Loss: 0.4021\n",
      "Epoch [14/50], Step [152/735], Loss: 0.3692\n",
      "Epoch [14/50], Step [153/735], Loss: 0.4629\n",
      "Epoch [14/50], Step [154/735], Loss: 0.2889\n",
      "Epoch [14/50], Step [155/735], Loss: 0.8855\n",
      "Epoch [14/50], Step [156/735], Loss: 0.2578\n",
      "Epoch [14/50], Step [157/735], Loss: 0.4573\n",
      "Epoch [14/50], Step [158/735], Loss: 0.5153\n",
      "Epoch [14/50], Step [159/735], Loss: 0.2390\n",
      "Epoch [14/50], Step [160/735], Loss: 0.5495\n",
      "Epoch [14/50], Step [161/735], Loss: 1.3841\n",
      "Epoch [14/50], Step [162/735], Loss: 0.2799\n",
      "Epoch [14/50], Step [163/735], Loss: 0.2999\n",
      "Epoch [14/50], Step [164/735], Loss: 0.3382\n",
      "Epoch [14/50], Step [165/735], Loss: 0.2562\n",
      "Epoch [14/50], Step [166/735], Loss: 0.1709\n",
      "Epoch [14/50], Step [167/735], Loss: 0.2508\n",
      "Epoch [14/50], Step [168/735], Loss: 0.2294\n",
      "Epoch [14/50], Step [169/735], Loss: 0.5147\n",
      "Epoch [14/50], Step [170/735], Loss: 0.8750\n",
      "Epoch [14/50], Step [171/735], Loss: 0.3195\n",
      "Epoch [14/50], Step [172/735], Loss: 0.4615\n",
      "Epoch [14/50], Step [173/735], Loss: 0.4112\n",
      "Epoch [14/50], Step [174/735], Loss: 0.7889\n",
      "Epoch [14/50], Step [175/735], Loss: 0.2519\n",
      "Epoch [14/50], Step [176/735], Loss: 2.2128\n",
      "Epoch [14/50], Step [177/735], Loss: 1.0765\n",
      "Epoch [14/50], Step [178/735], Loss: 0.5901\n",
      "Epoch [14/50], Step [179/735], Loss: 0.1090\n",
      "Epoch [14/50], Step [180/735], Loss: 0.3490\n",
      "Epoch [14/50], Step [181/735], Loss: 0.4714\n",
      "Epoch [14/50], Step [182/735], Loss: 1.6133\n",
      "Epoch [14/50], Step [183/735], Loss: 0.9137\n",
      "Epoch [14/50], Step [184/735], Loss: 0.2370\n",
      "Epoch [14/50], Step [185/735], Loss: 0.1633\n",
      "Epoch [14/50], Step [186/735], Loss: 0.3690\n",
      "Epoch [14/50], Step [187/735], Loss: 0.0829\n",
      "Epoch [14/50], Step [188/735], Loss: 0.3765\n",
      "Epoch [14/50], Step [189/735], Loss: 0.2009\n",
      "Epoch [14/50], Step [190/735], Loss: 0.3571\n",
      "Epoch [14/50], Step [191/735], Loss: 0.2332\n",
      "Epoch [14/50], Step [192/735], Loss: 0.1529\n",
      "Epoch [14/50], Step [193/735], Loss: 0.2829\n",
      "Epoch [14/50], Step [194/735], Loss: 0.3908\n",
      "Epoch [14/50], Step [195/735], Loss: 0.1188\n",
      "Epoch [14/50], Step [196/735], Loss: 0.5935\n",
      "Epoch [14/50], Step [197/735], Loss: 0.8440\n",
      "Epoch [14/50], Step [198/735], Loss: 0.2956\n",
      "Epoch [14/50], Step [199/735], Loss: 0.2099\n",
      "Epoch [14/50], Step [200/735], Loss: 0.8338\n",
      "Epoch [14/50], Step [201/735], Loss: 0.9826\n",
      "Epoch [14/50], Step [202/735], Loss: 0.0779\n",
      "Epoch [14/50], Step [203/735], Loss: 0.1839\n",
      "Epoch [14/50], Step [204/735], Loss: 1.0138\n",
      "Epoch [14/50], Step [205/735], Loss: 0.3299\n",
      "Epoch [14/50], Step [206/735], Loss: 1.3965\n",
      "Epoch [14/50], Step [207/735], Loss: 0.4283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Step [208/735], Loss: 0.3238\n",
      "Epoch [14/50], Step [209/735], Loss: 0.2851\n",
      "Epoch [14/50], Step [210/735], Loss: 0.1080\n",
      "Epoch [14/50], Step [211/735], Loss: 0.1228\n",
      "Epoch [14/50], Step [212/735], Loss: 1.0199\n",
      "Epoch [14/50], Step [213/735], Loss: 0.6161\n",
      "Epoch [14/50], Step [214/735], Loss: 0.1596\n",
      "Epoch [14/50], Step [215/735], Loss: 0.1532\n",
      "Epoch [14/50], Step [216/735], Loss: 0.3596\n",
      "Epoch [14/50], Step [217/735], Loss: 0.5892\n",
      "Epoch [14/50], Step [218/735], Loss: 0.3183\n",
      "Epoch [14/50], Step [219/735], Loss: 0.2098\n",
      "Epoch [14/50], Step [220/735], Loss: 0.2210\n",
      "Epoch [14/50], Step [221/735], Loss: 1.1168\n",
      "Epoch [14/50], Step [222/735], Loss: 0.3052\n",
      "Epoch [14/50], Step [223/735], Loss: 1.1039\n",
      "Epoch [14/50], Step [224/735], Loss: 0.2251\n",
      "Epoch [14/50], Step [225/735], Loss: 0.4232\n",
      "Epoch [14/50], Step [226/735], Loss: 0.0939\n",
      "Epoch [14/50], Step [227/735], Loss: 5.8493\n",
      "Epoch [14/50], Step [228/735], Loss: 0.8636\n",
      "Epoch [14/50], Step [229/735], Loss: 0.3675\n",
      "Epoch [14/50], Step [230/735], Loss: 0.4515\n",
      "Epoch [14/50], Step [231/735], Loss: 0.3392\n",
      "Epoch [14/50], Step [232/735], Loss: 0.3036\n",
      "Epoch [14/50], Step [233/735], Loss: 0.6406\n",
      "Epoch [14/50], Step [234/735], Loss: 0.4866\n",
      "Epoch [14/50], Step [235/735], Loss: 0.3759\n",
      "Epoch [14/50], Step [236/735], Loss: 0.6881\n",
      "Epoch [14/50], Step [237/735], Loss: 0.2382\n",
      "Epoch [14/50], Step [238/735], Loss: 0.8065\n",
      "Epoch [14/50], Step [239/735], Loss: 0.3475\n",
      "Epoch [14/50], Step [240/735], Loss: 0.7464\n",
      "Epoch [14/50], Step [241/735], Loss: 0.4374\n",
      "Epoch [14/50], Step [242/735], Loss: 0.4630\n",
      "Epoch [14/50], Step [243/735], Loss: 0.5358\n",
      "Epoch [14/50], Step [244/735], Loss: 0.3847\n",
      "Epoch [14/50], Step [245/735], Loss: 0.7770\n",
      "Epoch [14/50], Step [246/735], Loss: 0.5652\n",
      "Epoch [14/50], Step [247/735], Loss: 0.2462\n",
      "Epoch [14/50], Step [248/735], Loss: 0.5101\n",
      "Epoch [14/50], Step [249/735], Loss: 0.2370\n",
      "Epoch [14/50], Step [250/735], Loss: 0.0436\n",
      "Epoch [14/50], Step [251/735], Loss: 0.8942\n",
      "Epoch [14/50], Step [252/735], Loss: 0.1730\n",
      "Epoch [14/50], Step [253/735], Loss: 0.7531\n",
      "Epoch [14/50], Step [254/735], Loss: 0.5569\n",
      "Epoch [14/50], Step [255/735], Loss: 1.0934\n",
      "Epoch [14/50], Step [256/735], Loss: 0.6374\n",
      "Epoch [14/50], Step [257/735], Loss: 1.4511\n",
      "Epoch [14/50], Step [258/735], Loss: 0.1970\n",
      "Epoch [14/50], Step [259/735], Loss: 0.2366\n",
      "Epoch [14/50], Step [260/735], Loss: 0.1569\n",
      "Epoch [14/50], Step [261/735], Loss: 0.2077\n",
      "Epoch [14/50], Step [262/735], Loss: 0.1102\n",
      "Epoch [14/50], Step [263/735], Loss: 1.5288\n",
      "Epoch [14/50], Step [264/735], Loss: 0.3847\n",
      "Epoch [14/50], Step [265/735], Loss: 0.2511\n",
      "Epoch [14/50], Step [266/735], Loss: 0.1638\n",
      "Epoch [14/50], Step [267/735], Loss: 0.4421\n",
      "Epoch [14/50], Step [268/735], Loss: 0.3129\n",
      "Epoch [14/50], Step [269/735], Loss: 0.4782\n",
      "Epoch [14/50], Step [270/735], Loss: 0.1295\n",
      "Epoch [14/50], Step [271/735], Loss: 0.9619\n",
      "Epoch [14/50], Step [272/735], Loss: 0.1107\n",
      "Epoch [14/50], Step [273/735], Loss: 0.2639\n",
      "Epoch [14/50], Step [274/735], Loss: 0.9042\n",
      "Epoch [14/50], Step [275/735], Loss: 0.4070\n",
      "Epoch [14/50], Step [276/735], Loss: 1.6835\n",
      "Epoch [14/50], Step [277/735], Loss: 0.3009\n",
      "Epoch [14/50], Step [278/735], Loss: 0.6027\n",
      "Epoch [14/50], Step [279/735], Loss: 0.5327\n",
      "Epoch [14/50], Step [280/735], Loss: 0.3954\n",
      "Epoch [14/50], Step [281/735], Loss: 0.1859\n",
      "Epoch [14/50], Step [282/735], Loss: 0.2291\n",
      "Epoch [14/50], Step [283/735], Loss: 0.3965\n",
      "Epoch [14/50], Step [284/735], Loss: 0.6477\n",
      "Epoch [14/50], Step [285/735], Loss: 0.6799\n",
      "Epoch [14/50], Step [286/735], Loss: 0.1212\n",
      "Epoch [14/50], Step [287/735], Loss: 0.1925\n",
      "Epoch [14/50], Step [288/735], Loss: 0.1442\n",
      "Epoch [14/50], Step [289/735], Loss: 0.4738\n",
      "Epoch [14/50], Step [290/735], Loss: 0.2893\n",
      "Epoch [14/50], Step [291/735], Loss: 0.4946\n",
      "Epoch [14/50], Step [292/735], Loss: 0.3743\n",
      "Epoch [14/50], Step [293/735], Loss: 0.7547\n",
      "Epoch [14/50], Step [294/735], Loss: 0.4901\n",
      "Epoch [14/50], Step [295/735], Loss: 0.1560\n",
      "Epoch [14/50], Step [296/735], Loss: 0.2309\n",
      "Epoch [14/50], Step [297/735], Loss: 0.1755\n",
      "Epoch [14/50], Step [298/735], Loss: 0.3071\n",
      "Epoch [14/50], Step [299/735], Loss: 1.3118\n",
      "Epoch [14/50], Step [300/735], Loss: 0.4419\n",
      "Epoch [14/50], Step [301/735], Loss: 0.2562\n",
      "Epoch [14/50], Step [302/735], Loss: 0.9708\n",
      "Epoch [14/50], Step [303/735], Loss: 0.4797\n",
      "Epoch [14/50], Step [304/735], Loss: 0.2287\n",
      "Epoch [14/50], Step [305/735], Loss: 0.1209\n",
      "Epoch [14/50], Step [306/735], Loss: 0.2775\n",
      "Epoch [14/50], Step [307/735], Loss: 0.4134\n",
      "Epoch [14/50], Step [308/735], Loss: 0.2551\n",
      "Epoch [14/50], Step [309/735], Loss: 0.2650\n",
      "Epoch [14/50], Step [310/735], Loss: 0.2041\n",
      "Epoch [14/50], Step [311/735], Loss: 0.2023\n",
      "Epoch [14/50], Step [312/735], Loss: 0.3887\n",
      "Epoch [14/50], Step [313/735], Loss: 0.6009\n",
      "Epoch [14/50], Step [314/735], Loss: 0.2292\n",
      "Epoch [14/50], Step [315/735], Loss: 0.9024\n",
      "Epoch [14/50], Step [316/735], Loss: 0.4987\n",
      "Epoch [14/50], Step [317/735], Loss: 1.0659\n",
      "Epoch [14/50], Step [318/735], Loss: 0.4782\n",
      "Epoch [14/50], Step [319/735], Loss: 0.2931\n",
      "Epoch [14/50], Step [320/735], Loss: 0.5928\n",
      "Epoch [14/50], Step [321/735], Loss: 0.4801\n",
      "Epoch [14/50], Step [322/735], Loss: 0.3482\n",
      "Epoch [14/50], Step [323/735], Loss: 0.4226\n",
      "Epoch [14/50], Step [324/735], Loss: 0.2053\n",
      "Epoch [14/50], Step [325/735], Loss: 0.3175\n",
      "Epoch [14/50], Step [326/735], Loss: 0.4019\n",
      "Epoch [14/50], Step [327/735], Loss: 0.4971\n",
      "Epoch [14/50], Step [328/735], Loss: 5.2249\n",
      "Epoch [14/50], Step [329/735], Loss: 0.7168\n",
      "Epoch [14/50], Step [330/735], Loss: 0.4815\n",
      "Epoch [14/50], Step [331/735], Loss: 0.5503\n",
      "Epoch [14/50], Step [332/735], Loss: 0.1114\n",
      "Epoch [14/50], Step [333/735], Loss: 0.2252\n",
      "Epoch [14/50], Step [334/735], Loss: 0.5325\n",
      "Epoch [14/50], Step [335/735], Loss: 4.9918\n",
      "Epoch [14/50], Step [336/735], Loss: 1.4114\n",
      "Epoch [14/50], Step [337/735], Loss: 1.7633\n",
      "Epoch [14/50], Step [338/735], Loss: 0.3309\n",
      "Epoch [14/50], Step [339/735], Loss: 0.4625\n",
      "Epoch [14/50], Step [340/735], Loss: 0.3730\n",
      "Epoch [14/50], Step [341/735], Loss: 0.2056\n",
      "Epoch [14/50], Step [342/735], Loss: 0.3758\n",
      "Epoch [14/50], Step [343/735], Loss: 0.2444\n",
      "Epoch [14/50], Step [344/735], Loss: 1.4297\n",
      "Epoch [14/50], Step [345/735], Loss: 0.1876\n",
      "Epoch [14/50], Step [346/735], Loss: 0.2677\n",
      "Epoch [14/50], Step [347/735], Loss: 0.3896\n",
      "Epoch [14/50], Step [348/735], Loss: 0.4664\n",
      "Epoch [14/50], Step [349/735], Loss: 0.2015\n",
      "Epoch [14/50], Step [350/735], Loss: 1.8548\n",
      "Epoch [14/50], Step [351/735], Loss: 0.4703\n",
      "Epoch [14/50], Step [352/735], Loss: 0.3812\n",
      "Epoch [14/50], Step [353/735], Loss: 0.2413\n",
      "Epoch [14/50], Step [354/735], Loss: 0.0915\n",
      "Epoch [14/50], Step [355/735], Loss: 0.5074\n",
      "Epoch [14/50], Step [356/735], Loss: 0.4433\n",
      "Epoch [14/50], Step [357/735], Loss: 0.3742\n",
      "Epoch [14/50], Step [358/735], Loss: 0.4827\n",
      "Epoch [14/50], Step [359/735], Loss: 0.3633\n",
      "Epoch [14/50], Step [360/735], Loss: 0.5595\n",
      "Epoch [14/50], Step [361/735], Loss: 0.2044\n",
      "Epoch [14/50], Step [362/735], Loss: 0.4783\n",
      "Epoch [14/50], Step [363/735], Loss: 0.2767\n",
      "Epoch [14/50], Step [364/735], Loss: 0.4701\n",
      "Epoch [14/50], Step [365/735], Loss: 0.1363\n",
      "Epoch [14/50], Step [366/735], Loss: 0.2387\n",
      "Epoch [14/50], Step [367/735], Loss: 0.7219\n",
      "Epoch [14/50], Step [368/735], Loss: 0.7701\n",
      "Epoch [14/50], Step [369/735], Loss: 0.1237\n",
      "Epoch [14/50], Step [370/735], Loss: 0.3452\n",
      "Epoch [14/50], Step [371/735], Loss: 0.2084\n",
      "Epoch [14/50], Step [372/735], Loss: 0.1489\n",
      "Epoch [14/50], Step [373/735], Loss: 0.4220\n",
      "Epoch [14/50], Step [374/735], Loss: 0.2768\n",
      "Epoch [14/50], Step [375/735], Loss: 0.6571\n",
      "Epoch [14/50], Step [376/735], Loss: 0.2964\n",
      "Epoch [14/50], Step [377/735], Loss: 0.2923\n",
      "Epoch [14/50], Step [378/735], Loss: 1.0960\n",
      "Epoch [14/50], Step [379/735], Loss: 1.6591\n",
      "Epoch [14/50], Step [380/735], Loss: 0.4614\n",
      "Epoch [14/50], Step [381/735], Loss: 2.0253\n",
      "Epoch [14/50], Step [382/735], Loss: 0.9879\n",
      "Epoch [14/50], Step [383/735], Loss: 0.2782\n",
      "Epoch [14/50], Step [384/735], Loss: 0.8058\n",
      "Epoch [14/50], Step [385/735], Loss: 0.1813\n",
      "Epoch [14/50], Step [386/735], Loss: 0.5374\n",
      "Epoch [14/50], Step [387/735], Loss: 0.3042\n",
      "Epoch [14/50], Step [388/735], Loss: 0.5064\n",
      "Epoch [14/50], Step [389/735], Loss: 0.4215\n",
      "Epoch [14/50], Step [390/735], Loss: 0.3628\n",
      "Epoch [14/50], Step [391/735], Loss: 0.1734\n",
      "Epoch [14/50], Step [392/735], Loss: 0.8641\n",
      "Epoch [14/50], Step [393/735], Loss: 0.3053\n",
      "Epoch [14/50], Step [394/735], Loss: 0.3923\n",
      "Epoch [14/50], Step [395/735], Loss: 0.3921\n",
      "Epoch [14/50], Step [396/735], Loss: 0.1705\n",
      "Epoch [14/50], Step [397/735], Loss: 0.5599\n",
      "Epoch [14/50], Step [398/735], Loss: 1.2821\n",
      "Epoch [14/50], Step [399/735], Loss: 0.7556\n",
      "Epoch [14/50], Step [400/735], Loss: 0.3764\n",
      "Epoch [14/50], Step [401/735], Loss: 0.6697\n",
      "Epoch [14/50], Step [402/735], Loss: 0.6157\n",
      "Epoch [14/50], Step [403/735], Loss: 0.3779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Step [404/735], Loss: 0.3232\n",
      "Epoch [14/50], Step [405/735], Loss: 1.2021\n",
      "Epoch [14/50], Step [406/735], Loss: 0.1884\n",
      "Epoch [14/50], Step [407/735], Loss: 0.2704\n",
      "Epoch [14/50], Step [408/735], Loss: 0.1484\n",
      "Epoch [14/50], Step [409/735], Loss: 0.2136\n",
      "Epoch [14/50], Step [410/735], Loss: 0.2056\n",
      "Epoch [14/50], Step [411/735], Loss: 0.3484\n",
      "Epoch [14/50], Step [412/735], Loss: 1.6566\n",
      "Epoch [14/50], Step [413/735], Loss: 0.0683\n",
      "Epoch [14/50], Step [414/735], Loss: 0.1596\n",
      "Epoch [14/50], Step [415/735], Loss: 0.4959\n",
      "Epoch [14/50], Step [416/735], Loss: 0.1739\n",
      "Epoch [14/50], Step [417/735], Loss: 0.5284\n",
      "Epoch [14/50], Step [418/735], Loss: 0.3874\n",
      "Epoch [14/50], Step [419/735], Loss: 0.3049\n",
      "Epoch [14/50], Step [420/735], Loss: 0.3296\n",
      "Epoch [14/50], Step [421/735], Loss: 1.2084\n",
      "Epoch [14/50], Step [422/735], Loss: 0.2458\n",
      "Epoch [14/50], Step [423/735], Loss: 0.1635\n",
      "Epoch [14/50], Step [424/735], Loss: 0.1605\n",
      "Epoch [14/50], Step [425/735], Loss: 0.6282\n",
      "Epoch [14/50], Step [426/735], Loss: 0.7222\n",
      "Epoch [14/50], Step [427/735], Loss: 0.1734\n",
      "Epoch [14/50], Step [428/735], Loss: 0.2038\n",
      "Epoch [14/50], Step [429/735], Loss: 0.5225\n",
      "Epoch [14/50], Step [430/735], Loss: 0.4136\n",
      "Epoch [14/50], Step [431/735], Loss: 0.1439\n",
      "Epoch [14/50], Step [432/735], Loss: 0.3090\n",
      "Epoch [14/50], Step [433/735], Loss: 0.2136\n",
      "Epoch [14/50], Step [434/735], Loss: 1.0848\n",
      "Epoch [14/50], Step [435/735], Loss: 0.1546\n",
      "Epoch [14/50], Step [436/735], Loss: 0.4520\n",
      "Epoch [14/50], Step [437/735], Loss: 0.4309\n",
      "Epoch [14/50], Step [438/735], Loss: 0.8259\n",
      "Epoch [14/50], Step [439/735], Loss: 0.4900\n",
      "Epoch [14/50], Step [440/735], Loss: 0.3768\n",
      "Epoch [14/50], Step [441/735], Loss: 0.2841\n",
      "Epoch [14/50], Step [442/735], Loss: 0.1647\n",
      "Epoch [14/50], Step [443/735], Loss: 0.3611\n",
      "Epoch [14/50], Step [444/735], Loss: 0.1638\n",
      "Epoch [14/50], Step [445/735], Loss: 0.1864\n",
      "Epoch [14/50], Step [446/735], Loss: 0.9716\n",
      "Epoch [14/50], Step [447/735], Loss: 0.4303\n",
      "Epoch [14/50], Step [448/735], Loss: 0.4413\n",
      "Epoch [14/50], Step [449/735], Loss: 0.1627\n",
      "Epoch [14/50], Step [450/735], Loss: 0.4375\n",
      "Epoch [14/50], Step [451/735], Loss: 0.1584\n",
      "Epoch [14/50], Step [452/735], Loss: 0.5855\n",
      "Epoch [14/50], Step [453/735], Loss: 0.4013\n",
      "Epoch [14/50], Step [454/735], Loss: 0.6650\n",
      "Epoch [14/50], Step [455/735], Loss: 0.7007\n",
      "Epoch [14/50], Step [456/735], Loss: 0.0680\n",
      "Epoch [14/50], Step [457/735], Loss: 0.1275\n",
      "Epoch [14/50], Step [458/735], Loss: 0.2658\n",
      "Epoch [14/50], Step [459/735], Loss: 0.1743\n",
      "Epoch [14/50], Step [460/735], Loss: 0.2156\n",
      "Epoch [14/50], Step [461/735], Loss: 2.5125\n",
      "Epoch [14/50], Step [462/735], Loss: 0.1690\n",
      "Epoch [14/50], Step [463/735], Loss: 0.7674\n",
      "Epoch [14/50], Step [464/735], Loss: 0.4567\n",
      "Epoch [14/50], Step [465/735], Loss: 0.2194\n",
      "Epoch [14/50], Step [466/735], Loss: 0.2400\n",
      "Epoch [14/50], Step [467/735], Loss: 0.5143\n",
      "Epoch [14/50], Step [468/735], Loss: 0.3620\n",
      "Epoch [14/50], Step [469/735], Loss: 0.7912\n",
      "Epoch [14/50], Step [470/735], Loss: 0.4310\n",
      "Epoch [14/50], Step [471/735], Loss: 0.2867\n",
      "Epoch [14/50], Step [472/735], Loss: 0.2363\n",
      "Epoch [14/50], Step [473/735], Loss: 0.0945\n",
      "Epoch [14/50], Step [474/735], Loss: 0.2905\n",
      "Epoch [14/50], Step [475/735], Loss: 0.6797\n",
      "Epoch [14/50], Step [476/735], Loss: 0.2982\n",
      "Epoch [14/50], Step [477/735], Loss: 0.8132\n",
      "Epoch [14/50], Step [478/735], Loss: 0.1297\n",
      "Epoch [14/50], Step [479/735], Loss: 0.1888\n",
      "Epoch [14/50], Step [480/735], Loss: 0.3043\n",
      "Epoch [14/50], Step [481/735], Loss: 0.9029\n",
      "Epoch [14/50], Step [482/735], Loss: 0.2006\n",
      "Epoch [14/50], Step [483/735], Loss: 0.0901\n",
      "Epoch [14/50], Step [484/735], Loss: 0.3417\n",
      "Epoch [14/50], Step [485/735], Loss: 0.0654\n",
      "Epoch [14/50], Step [486/735], Loss: 0.4662\n",
      "Epoch [14/50], Step [487/735], Loss: 0.3010\n",
      "Epoch [14/50], Step [488/735], Loss: 0.3689\n",
      "Epoch [14/50], Step [489/735], Loss: 0.0726\n",
      "Epoch [14/50], Step [490/735], Loss: 0.4673\n",
      "Epoch [14/50], Step [491/735], Loss: 0.4940\n",
      "Epoch [14/50], Step [492/735], Loss: 0.2773\n",
      "Epoch [14/50], Step [493/735], Loss: 0.1761\n",
      "Epoch [14/50], Step [494/735], Loss: 0.0824\n",
      "Epoch [14/50], Step [495/735], Loss: 0.3656\n",
      "Epoch [14/50], Step [496/735], Loss: 0.3746\n",
      "Epoch [14/50], Step [497/735], Loss: 0.1697\n",
      "Epoch [14/50], Step [498/735], Loss: 0.3163\n",
      "Epoch [14/50], Step [499/735], Loss: 0.7343\n",
      "Epoch [14/50], Step [500/735], Loss: 1.4475\n",
      "Epoch [14/50], Step [501/735], Loss: 0.5480\n",
      "Epoch [14/50], Step [502/735], Loss: 0.1214\n",
      "Epoch [14/50], Step [503/735], Loss: 0.5313\n",
      "Epoch [14/50], Step [504/735], Loss: 0.1964\n",
      "Epoch [14/50], Step [505/735], Loss: 0.2609\n",
      "Epoch [14/50], Step [506/735], Loss: 0.1704\n",
      "Epoch [14/50], Step [507/735], Loss: 0.3833\n",
      "Epoch [14/50], Step [508/735], Loss: 2.2098\n",
      "Epoch [14/50], Step [509/735], Loss: 0.1715\n",
      "Epoch [14/50], Step [510/735], Loss: 0.3229\n",
      "Epoch [14/50], Step [511/735], Loss: 0.2195\n",
      "Epoch [14/50], Step [512/735], Loss: 0.1886\n",
      "Epoch [14/50], Step [513/735], Loss: 0.7074\n",
      "Epoch [14/50], Step [514/735], Loss: 1.2208\n",
      "Epoch [14/50], Step [515/735], Loss: 0.3754\n",
      "Epoch [14/50], Step [516/735], Loss: 0.3572\n",
      "Epoch [14/50], Step [517/735], Loss: 0.5572\n",
      "Epoch [14/50], Step [518/735], Loss: 0.9094\n",
      "Epoch [14/50], Step [519/735], Loss: 0.1974\n",
      "Epoch [14/50], Step [520/735], Loss: 0.1361\n",
      "Epoch [14/50], Step [521/735], Loss: 0.4046\n",
      "Epoch [14/50], Step [522/735], Loss: 0.3246\n",
      "Epoch [14/50], Step [523/735], Loss: 0.4314\n",
      "Epoch [14/50], Step [524/735], Loss: 0.2561\n",
      "Epoch [14/50], Step [525/735], Loss: 0.1848\n",
      "Epoch [14/50], Step [526/735], Loss: 0.1057\n",
      "Epoch [14/50], Step [527/735], Loss: 0.2032\n",
      "Epoch [14/50], Step [528/735], Loss: 0.3357\n",
      "Epoch [14/50], Step [529/735], Loss: 0.3134\n",
      "Epoch [14/50], Step [530/735], Loss: 0.2701\n",
      "Epoch [14/50], Step [531/735], Loss: 0.2584\n",
      "Epoch [14/50], Step [532/735], Loss: 0.1585\n",
      "Epoch [14/50], Step [533/735], Loss: 0.9443\n",
      "Epoch [14/50], Step [534/735], Loss: 0.0915\n",
      "Epoch [14/50], Step [535/735], Loss: 0.4612\n",
      "Epoch [14/50], Step [536/735], Loss: 0.1440\n",
      "Epoch [14/50], Step [537/735], Loss: 0.7298\n",
      "Epoch [14/50], Step [538/735], Loss: 0.3876\n",
      "Epoch [14/50], Step [539/735], Loss: 0.7999\n",
      "Epoch [14/50], Step [540/735], Loss: 1.3435\n",
      "Epoch [14/50], Step [541/735], Loss: 0.6103\n",
      "Epoch [14/50], Step [542/735], Loss: 0.2195\n",
      "Epoch [14/50], Step [543/735], Loss: 0.3519\n",
      "Epoch [14/50], Step [544/735], Loss: 0.3472\n",
      "Epoch [14/50], Step [545/735], Loss: 0.3546\n",
      "Epoch [14/50], Step [546/735], Loss: 0.0393\n",
      "Epoch [14/50], Step [547/735], Loss: 0.7996\n",
      "Epoch [14/50], Step [548/735], Loss: 0.4783\n",
      "Epoch [14/50], Step [549/735], Loss: 0.6771\n",
      "Epoch [14/50], Step [550/735], Loss: 0.3058\n",
      "Epoch [14/50], Step [551/735], Loss: 2.5823\n",
      "Epoch [14/50], Step [552/735], Loss: 0.5164\n",
      "Epoch [14/50], Step [553/735], Loss: 0.4589\n",
      "Epoch [14/50], Step [554/735], Loss: 0.6157\n",
      "Epoch [14/50], Step [555/735], Loss: 0.5668\n",
      "Epoch [14/50], Step [556/735], Loss: 0.5849\n",
      "Epoch [14/50], Step [557/735], Loss: 0.7785\n",
      "Epoch [14/50], Step [558/735], Loss: 0.4630\n",
      "Epoch [14/50], Step [559/735], Loss: 0.3343\n",
      "Epoch [14/50], Step [560/735], Loss: 0.1168\n",
      "Epoch [14/50], Step [561/735], Loss: 0.5571\n",
      "Epoch [14/50], Step [562/735], Loss: 0.4098\n",
      "Epoch [14/50], Step [563/735], Loss: 0.1169\n",
      "Epoch [14/50], Step [564/735], Loss: 0.7155\n",
      "Epoch [14/50], Step [565/735], Loss: 0.5134\n",
      "Epoch [14/50], Step [566/735], Loss: 0.2664\n",
      "Epoch [14/50], Step [567/735], Loss: 0.4496\n",
      "Epoch [14/50], Step [568/735], Loss: 0.3908\n",
      "Epoch [14/50], Step [569/735], Loss: 0.2122\n",
      "Epoch [14/50], Step [570/735], Loss: 0.8456\n",
      "Epoch [14/50], Step [571/735], Loss: 0.1984\n",
      "Epoch [14/50], Step [572/735], Loss: 0.3589\n",
      "Epoch [14/50], Step [573/735], Loss: 0.1223\n",
      "Epoch [14/50], Step [574/735], Loss: 0.1419\n",
      "Epoch [14/50], Step [575/735], Loss: 0.4469\n",
      "Epoch [14/50], Step [576/735], Loss: 0.3581\n",
      "Epoch [14/50], Step [577/735], Loss: 0.6572\n",
      "Epoch [14/50], Step [578/735], Loss: 0.3902\n",
      "Epoch [14/50], Step [579/735], Loss: 0.4482\n",
      "Epoch [14/50], Step [580/735], Loss: 0.9427\n",
      "Epoch [14/50], Step [581/735], Loss: 0.7097\n",
      "Epoch [14/50], Step [582/735], Loss: 0.1866\n",
      "Epoch [14/50], Step [583/735], Loss: 0.2938\n",
      "Epoch [14/50], Step [584/735], Loss: 0.2647\n",
      "Epoch [14/50], Step [585/735], Loss: 0.2800\n",
      "Epoch [14/50], Step [586/735], Loss: 0.4586\n",
      "Epoch [14/50], Step [587/735], Loss: 1.6260\n",
      "Epoch [14/50], Step [588/735], Loss: 0.3780\n",
      "Epoch [14/50], Step [589/735], Loss: 0.7964\n",
      "Epoch [14/50], Step [590/735], Loss: 0.6457\n",
      "Epoch [14/50], Step [591/735], Loss: 0.3009\n",
      "Epoch [14/50], Step [592/735], Loss: 1.0052\n",
      "Epoch [14/50], Step [593/735], Loss: 0.5273\n",
      "Epoch [14/50], Step [594/735], Loss: 5.1839\n",
      "Epoch [14/50], Step [595/735], Loss: 0.2764\n",
      "Epoch [14/50], Step [596/735], Loss: 0.3108\n",
      "Epoch [14/50], Step [597/735], Loss: 0.4855\n",
      "Epoch [14/50], Step [598/735], Loss: 0.4402\n",
      "Epoch [14/50], Step [599/735], Loss: 0.0596\n",
      "Epoch [14/50], Step [600/735], Loss: 0.2124\n",
      "Epoch [14/50], Step [601/735], Loss: 0.3583\n",
      "Epoch [14/50], Step [602/735], Loss: 0.3286\n",
      "Epoch [14/50], Step [603/735], Loss: 0.2368\n",
      "Epoch [14/50], Step [604/735], Loss: 0.3345\n",
      "Epoch [14/50], Step [605/735], Loss: 1.4784\n",
      "Epoch [14/50], Step [606/735], Loss: 0.1603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Step [607/735], Loss: 0.2853\n",
      "Epoch [14/50], Step [608/735], Loss: 0.1006\n",
      "Epoch [14/50], Step [609/735], Loss: 0.1186\n",
      "Epoch [14/50], Step [610/735], Loss: 1.9445\n",
      "Epoch [14/50], Step [611/735], Loss: 0.3066\n",
      "Epoch [14/50], Step [612/735], Loss: 0.1201\n",
      "Epoch [14/50], Step [613/735], Loss: 0.3182\n",
      "Epoch [14/50], Step [614/735], Loss: 0.2696\n",
      "Epoch [14/50], Step [615/735], Loss: 0.5269\n",
      "Epoch [14/50], Step [616/735], Loss: 0.2111\n",
      "Epoch [14/50], Step [617/735], Loss: 0.2672\n",
      "Epoch [14/50], Step [618/735], Loss: 1.7302\n",
      "Epoch [14/50], Step [619/735], Loss: 0.2166\n",
      "Epoch [14/50], Step [620/735], Loss: 0.4083\n",
      "Epoch [14/50], Step [621/735], Loss: 0.5337\n",
      "Epoch [14/50], Step [622/735], Loss: 0.6186\n",
      "Epoch [14/50], Step [623/735], Loss: 0.4638\n",
      "Epoch [14/50], Step [624/735], Loss: 0.2315\n",
      "Epoch [14/50], Step [625/735], Loss: 0.2280\n",
      "Epoch [14/50], Step [626/735], Loss: 0.8185\n",
      "Epoch [14/50], Step [627/735], Loss: 0.3299\n",
      "Epoch [14/50], Step [628/735], Loss: 2.1194\n",
      "Epoch [14/50], Step [629/735], Loss: 0.5059\n",
      "Epoch [14/50], Step [630/735], Loss: 0.2468\n",
      "Epoch [14/50], Step [631/735], Loss: 0.7496\n",
      "Epoch [14/50], Step [632/735], Loss: 1.0194\n",
      "Epoch [14/50], Step [633/735], Loss: 0.1285\n",
      "Epoch [14/50], Step [634/735], Loss: 0.3441\n",
      "Epoch [14/50], Step [635/735], Loss: 0.6003\n",
      "Epoch [14/50], Step [636/735], Loss: 0.1043\n",
      "Epoch [14/50], Step [637/735], Loss: 0.4400\n",
      "Epoch [14/50], Step [638/735], Loss: 0.3057\n",
      "Epoch [14/50], Step [639/735], Loss: 0.4154\n",
      "Epoch [14/50], Step [640/735], Loss: 0.7506\n",
      "Epoch [14/50], Step [641/735], Loss: 0.7434\n",
      "Epoch [14/50], Step [642/735], Loss: 0.3559\n",
      "Epoch [14/50], Step [643/735], Loss: 0.2892\n",
      "Epoch [14/50], Step [644/735], Loss: 0.1889\n",
      "Epoch [14/50], Step [645/735], Loss: 0.0833\n",
      "Epoch [14/50], Step [646/735], Loss: 1.0137\n",
      "Epoch [14/50], Step [647/735], Loss: 0.2184\n",
      "Epoch [14/50], Step [648/735], Loss: 0.2581\n",
      "Epoch [14/50], Step [649/735], Loss: 0.2710\n",
      "Epoch [14/50], Step [650/735], Loss: 0.1902\n",
      "Epoch [14/50], Step [651/735], Loss: 0.6935\n",
      "Epoch [14/50], Step [652/735], Loss: 0.3988\n",
      "Epoch [14/50], Step [653/735], Loss: 0.7636\n",
      "Epoch [14/50], Step [654/735], Loss: 0.2568\n",
      "Epoch [14/50], Step [655/735], Loss: 0.4305\n",
      "Epoch [14/50], Step [656/735], Loss: 0.1281\n",
      "Epoch [14/50], Step [657/735], Loss: 0.2692\n",
      "Epoch [14/50], Step [658/735], Loss: 0.1840\n",
      "Epoch [14/50], Step [659/735], Loss: 0.0815\n",
      "Epoch [14/50], Step [660/735], Loss: 0.2190\n",
      "Epoch [14/50], Step [661/735], Loss: 0.2835\n",
      "Epoch [14/50], Step [662/735], Loss: 4.9951\n",
      "Epoch [14/50], Step [663/735], Loss: 0.3713\n",
      "Epoch [14/50], Step [664/735], Loss: 0.8100\n",
      "Epoch [14/50], Step [665/735], Loss: 0.4087\n",
      "Epoch [14/50], Step [666/735], Loss: 0.4019\n",
      "Epoch [14/50], Step [667/735], Loss: 0.5142\n",
      "Epoch [14/50], Step [668/735], Loss: 0.1433\n",
      "Epoch [14/50], Step [669/735], Loss: 0.3840\n",
      "Epoch [14/50], Step [670/735], Loss: 0.3125\n",
      "Epoch [14/50], Step [671/735], Loss: 0.1730\n",
      "Epoch [14/50], Step [672/735], Loss: 0.2044\n",
      "Epoch [14/50], Step [673/735], Loss: 0.3730\n",
      "Epoch [14/50], Step [674/735], Loss: 0.3387\n",
      "Epoch [14/50], Step [675/735], Loss: 0.2944\n",
      "Epoch [14/50], Step [676/735], Loss: 0.2639\n",
      "Epoch [14/50], Step [677/735], Loss: 0.4724\n",
      "Epoch [14/50], Step [678/735], Loss: 0.4881\n",
      "Epoch [14/50], Step [679/735], Loss: 0.2549\n",
      "Epoch [14/50], Step [680/735], Loss: 0.7338\n",
      "Epoch [14/50], Step [681/735], Loss: 0.3240\n",
      "Epoch [14/50], Step [682/735], Loss: 0.2260\n",
      "Epoch [14/50], Step [683/735], Loss: 1.0028\n",
      "Epoch [14/50], Step [684/735], Loss: 0.2841\n",
      "Epoch [14/50], Step [685/735], Loss: 0.5499\n",
      "Epoch [14/50], Step [686/735], Loss: 0.3381\n",
      "Epoch [14/50], Step [687/735], Loss: 0.7698\n",
      "Epoch [14/50], Step [688/735], Loss: 0.1506\n",
      "Epoch [14/50], Step [689/735], Loss: 0.6257\n",
      "Epoch [14/50], Step [690/735], Loss: 0.9573\n",
      "Epoch [14/50], Step [691/735], Loss: 0.1359\n",
      "Epoch [14/50], Step [692/735], Loss: 0.5030\n",
      "Epoch [14/50], Step [693/735], Loss: 0.1495\n",
      "Epoch [14/50], Step [694/735], Loss: 0.3955\n",
      "Epoch [14/50], Step [695/735], Loss: 0.1060\n",
      "Epoch [14/50], Step [696/735], Loss: 0.4476\n",
      "Epoch [14/50], Step [697/735], Loss: 1.2841\n",
      "Epoch [14/50], Step [698/735], Loss: 0.1015\n",
      "Epoch [14/50], Step [699/735], Loss: 1.8644\n",
      "Epoch [14/50], Step [700/735], Loss: 1.0510\n",
      "Epoch [14/50], Step [701/735], Loss: 0.6299\n",
      "Epoch [14/50], Step [702/735], Loss: 1.3264\n",
      "Epoch [14/50], Step [703/735], Loss: 0.5383\n",
      "Epoch [14/50], Step [704/735], Loss: 0.1890\n",
      "Epoch [14/50], Step [705/735], Loss: 0.1381\n",
      "Epoch [14/50], Step [706/735], Loss: 0.2311\n",
      "Epoch [14/50], Step [707/735], Loss: 0.1068\n",
      "Epoch [14/50], Step [708/735], Loss: 0.4769\n",
      "Epoch [14/50], Step [709/735], Loss: 0.2724\n",
      "Epoch [14/50], Step [710/735], Loss: 0.4735\n",
      "Epoch [14/50], Step [711/735], Loss: 0.1052\n",
      "Epoch [14/50], Step [712/735], Loss: 0.4391\n",
      "Epoch [14/50], Step [713/735], Loss: 0.4097\n",
      "Epoch [14/50], Step [714/735], Loss: 0.2933\n",
      "Epoch [14/50], Step [715/735], Loss: 0.3427\n",
      "Epoch [14/50], Step [716/735], Loss: 0.1702\n",
      "Epoch [14/50], Step [717/735], Loss: 0.5061\n",
      "Epoch [14/50], Step [718/735], Loss: 0.2615\n",
      "Epoch [14/50], Step [719/735], Loss: 0.4642\n",
      "Epoch [14/50], Step [720/735], Loss: 0.8434\n",
      "Epoch [14/50], Step [721/735], Loss: 0.3148\n",
      "Epoch [14/50], Step [722/735], Loss: 0.2201\n",
      "Epoch [14/50], Step [723/735], Loss: 0.5043\n",
      "Epoch [14/50], Step [724/735], Loss: 0.4484\n",
      "Epoch [14/50], Step [725/735], Loss: 0.2300\n",
      "Epoch [14/50], Step [726/735], Loss: 0.7118\n",
      "Epoch [14/50], Step [727/735], Loss: 1.7055\n",
      "Epoch [14/50], Step [728/735], Loss: 0.4253\n",
      "Epoch [14/50], Step [729/735], Loss: 1.0861\n",
      "Epoch [14/50], Step [730/735], Loss: 0.1281\n",
      "Epoch [14/50], Step [731/735], Loss: 0.7641\n",
      "Epoch [14/50], Step [732/735], Loss: 0.1851\n",
      "Epoch [14/50], Step [733/735], Loss: 0.8020\n",
      "Epoch [14/50], Step [734/735], Loss: 0.8448\n",
      "Epoch [14/50], Step [735/735], Loss: 0.0735\n",
      "Epoch [15/50], Step [1/735], Loss: 0.2032\n",
      "Epoch [15/50], Step [2/735], Loss: 0.4127\n",
      "Epoch [15/50], Step [3/735], Loss: 0.5615\n",
      "Epoch [15/50], Step [4/735], Loss: 0.4342\n",
      "Epoch [15/50], Step [5/735], Loss: 0.2403\n",
      "Epoch [15/50], Step [6/735], Loss: 0.3175\n",
      "Epoch [15/50], Step [7/735], Loss: 0.1728\n",
      "Epoch [15/50], Step [8/735], Loss: 0.4575\n",
      "Epoch [15/50], Step [9/735], Loss: 0.7756\n",
      "Epoch [15/50], Step [10/735], Loss: 0.1528\n",
      "Epoch [15/50], Step [11/735], Loss: 0.7836\n",
      "Epoch [15/50], Step [12/735], Loss: 0.4308\n",
      "Epoch [15/50], Step [13/735], Loss: 0.1095\n",
      "Epoch [15/50], Step [14/735], Loss: 0.1597\n",
      "Epoch [15/50], Step [15/735], Loss: 0.6584\n",
      "Epoch [15/50], Step [16/735], Loss: 0.5875\n",
      "Epoch [15/50], Step [17/735], Loss: 0.2359\n",
      "Epoch [15/50], Step [18/735], Loss: 0.1055\n",
      "Epoch [15/50], Step [19/735], Loss: 0.5198\n",
      "Epoch [15/50], Step [20/735], Loss: 0.1869\n",
      "Epoch [15/50], Step [21/735], Loss: 0.2167\n",
      "Epoch [15/50], Step [22/735], Loss: 0.2218\n",
      "Epoch [15/50], Step [23/735], Loss: 0.3662\n",
      "Epoch [15/50], Step [24/735], Loss: 0.6396\n",
      "Epoch [15/50], Step [25/735], Loss: 0.3936\n",
      "Epoch [15/50], Step [26/735], Loss: 0.3218\n",
      "Epoch [15/50], Step [27/735], Loss: 0.1582\n",
      "Epoch [15/50], Step [28/735], Loss: 0.1417\n",
      "Epoch [15/50], Step [29/735], Loss: 0.0694\n",
      "Epoch [15/50], Step [30/735], Loss: 0.1452\n",
      "Epoch [15/50], Step [31/735], Loss: 0.4122\n",
      "Epoch [15/50], Step [32/735], Loss: 0.5518\n",
      "Epoch [15/50], Step [33/735], Loss: 0.1720\n",
      "Epoch [15/50], Step [34/735], Loss: 0.1321\n",
      "Epoch [15/50], Step [35/735], Loss: 0.3322\n",
      "Epoch [15/50], Step [36/735], Loss: 0.5086\n",
      "Epoch [15/50], Step [37/735], Loss: 0.2578\n",
      "Epoch [15/50], Step [38/735], Loss: 0.2493\n",
      "Epoch [15/50], Step [39/735], Loss: 0.4576\n",
      "Epoch [15/50], Step [40/735], Loss: 0.7009\n",
      "Epoch [15/50], Step [41/735], Loss: 0.4149\n",
      "Epoch [15/50], Step [42/735], Loss: 0.4605\n",
      "Epoch [15/50], Step [43/735], Loss: 0.8276\n",
      "Epoch [15/50], Step [44/735], Loss: 0.1252\n",
      "Epoch [15/50], Step [45/735], Loss: 0.2008\n",
      "Epoch [15/50], Step [46/735], Loss: 0.2291\n",
      "Epoch [15/50], Step [47/735], Loss: 0.2312\n",
      "Epoch [15/50], Step [48/735], Loss: 0.3474\n",
      "Epoch [15/50], Step [49/735], Loss: 0.1292\n",
      "Epoch [15/50], Step [50/735], Loss: 0.6429\n",
      "Epoch [15/50], Step [51/735], Loss: 0.4192\n",
      "Epoch [15/50], Step [52/735], Loss: 0.3650\n",
      "Epoch [15/50], Step [53/735], Loss: 0.4980\n",
      "Epoch [15/50], Step [54/735], Loss: 0.1071\n",
      "Epoch [15/50], Step [55/735], Loss: 0.4718\n",
      "Epoch [15/50], Step [56/735], Loss: 0.9950\n",
      "Epoch [15/50], Step [57/735], Loss: 0.8970\n",
      "Epoch [15/50], Step [58/735], Loss: 0.6823\n",
      "Epoch [15/50], Step [59/735], Loss: 0.1530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Step [60/735], Loss: 0.1571\n",
      "Epoch [15/50], Step [61/735], Loss: 0.0854\n",
      "Epoch [15/50], Step [62/735], Loss: 0.2227\n",
      "Epoch [15/50], Step [63/735], Loss: 0.1673\n",
      "Epoch [15/50], Step [64/735], Loss: 0.7982\n",
      "Epoch [15/50], Step [65/735], Loss: 0.2574\n",
      "Epoch [15/50], Step [66/735], Loss: 0.4462\n",
      "Epoch [15/50], Step [67/735], Loss: 0.5108\n",
      "Epoch [15/50], Step [68/735], Loss: 0.1640\n",
      "Epoch [15/50], Step [69/735], Loss: 0.4170\n",
      "Epoch [15/50], Step [70/735], Loss: 0.7247\n",
      "Epoch [15/50], Step [71/735], Loss: 0.4701\n",
      "Epoch [15/50], Step [72/735], Loss: 0.4485\n",
      "Epoch [15/50], Step [73/735], Loss: 1.3164\n",
      "Epoch [15/50], Step [74/735], Loss: 0.0897\n",
      "Epoch [15/50], Step [75/735], Loss: 0.2699\n",
      "Epoch [15/50], Step [76/735], Loss: 0.2551\n",
      "Epoch [15/50], Step [77/735], Loss: 0.0991\n",
      "Epoch [15/50], Step [78/735], Loss: 0.6695\n",
      "Epoch [15/50], Step [79/735], Loss: 1.1570\n",
      "Epoch [15/50], Step [80/735], Loss: 0.2962\n",
      "Epoch [15/50], Step [81/735], Loss: 0.4750\n",
      "Epoch [15/50], Step [82/735], Loss: 1.3226\n",
      "Epoch [15/50], Step [83/735], Loss: 0.3898\n",
      "Epoch [15/50], Step [84/735], Loss: 0.9111\n",
      "Epoch [15/50], Step [85/735], Loss: 0.4424\n",
      "Epoch [15/50], Step [86/735], Loss: 0.1088\n",
      "Epoch [15/50], Step [87/735], Loss: 0.5759\n",
      "Epoch [15/50], Step [88/735], Loss: 0.7382\n",
      "Epoch [15/50], Step [89/735], Loss: 0.1638\n",
      "Epoch [15/50], Step [90/735], Loss: 0.1562\n",
      "Epoch [15/50], Step [91/735], Loss: 0.8415\n",
      "Epoch [15/50], Step [92/735], Loss: 0.2406\n",
      "Epoch [15/50], Step [93/735], Loss: 0.5267\n",
      "Epoch [15/50], Step [94/735], Loss: 0.4282\n",
      "Epoch [15/50], Step [95/735], Loss: 2.2482\n",
      "Epoch [15/50], Step [96/735], Loss: 0.3129\n",
      "Epoch [15/50], Step [97/735], Loss: 0.3609\n",
      "Epoch [15/50], Step [98/735], Loss: 0.4173\n",
      "Epoch [15/50], Step [99/735], Loss: 0.7847\n",
      "Epoch [15/50], Step [100/735], Loss: 0.8378\n",
      "Epoch [15/50], Step [101/735], Loss: 0.1988\n",
      "Epoch [15/50], Step [102/735], Loss: 1.0072\n",
      "Epoch [15/50], Step [103/735], Loss: 0.1975\n",
      "Epoch [15/50], Step [104/735], Loss: 1.0349\n",
      "Epoch [15/50], Step [105/735], Loss: 0.3724\n",
      "Epoch [15/50], Step [106/735], Loss: 0.1188\n",
      "Epoch [15/50], Step [107/735], Loss: 1.8463\n",
      "Epoch [15/50], Step [108/735], Loss: 0.2072\n",
      "Epoch [15/50], Step [109/735], Loss: 0.2573\n",
      "Epoch [15/50], Step [110/735], Loss: 0.2452\n",
      "Epoch [15/50], Step [111/735], Loss: 0.3454\n",
      "Epoch [15/50], Step [112/735], Loss: 0.2957\n",
      "Epoch [15/50], Step [113/735], Loss: 0.6558\n",
      "Epoch [15/50], Step [114/735], Loss: 0.2663\n",
      "Epoch [15/50], Step [115/735], Loss: 0.3426\n",
      "Epoch [15/50], Step [116/735], Loss: 0.4505\n",
      "Epoch [15/50], Step [117/735], Loss: 0.3979\n",
      "Epoch [15/50], Step [118/735], Loss: 0.6863\n",
      "Epoch [15/50], Step [119/735], Loss: 0.7530\n",
      "Epoch [15/50], Step [120/735], Loss: 0.3914\n",
      "Epoch [15/50], Step [121/735], Loss: 0.6534\n",
      "Epoch [15/50], Step [122/735], Loss: 0.7160\n",
      "Epoch [15/50], Step [123/735], Loss: 0.2927\n",
      "Epoch [15/50], Step [124/735], Loss: 0.2150\n",
      "Epoch [15/50], Step [125/735], Loss: 0.6166\n",
      "Epoch [15/50], Step [126/735], Loss: 0.2192\n",
      "Epoch [15/50], Step [127/735], Loss: 0.1480\n",
      "Epoch [15/50], Step [128/735], Loss: 0.2001\n",
      "Epoch [15/50], Step [129/735], Loss: 0.1779\n",
      "Epoch [15/50], Step [130/735], Loss: 0.6014\n",
      "Epoch [15/50], Step [131/735], Loss: 0.1124\n",
      "Epoch [15/50], Step [132/735], Loss: 0.2215\n",
      "Epoch [15/50], Step [133/735], Loss: 0.4924\n",
      "Epoch [15/50], Step [134/735], Loss: 0.9500\n",
      "Epoch [15/50], Step [135/735], Loss: 0.2545\n",
      "Epoch [15/50], Step [136/735], Loss: 0.7771\n",
      "Epoch [15/50], Step [137/735], Loss: 1.1578\n",
      "Epoch [15/50], Step [138/735], Loss: 0.5059\n",
      "Epoch [15/50], Step [139/735], Loss: 0.1409\n",
      "Epoch [15/50], Step [140/735], Loss: 0.4965\n",
      "Epoch [15/50], Step [141/735], Loss: 0.1278\n",
      "Epoch [15/50], Step [142/735], Loss: 0.3427\n",
      "Epoch [15/50], Step [143/735], Loss: 0.3950\n",
      "Epoch [15/50], Step [144/735], Loss: 0.4669\n",
      "Epoch [15/50], Step [145/735], Loss: 1.0150\n",
      "Epoch [15/50], Step [146/735], Loss: 0.2900\n",
      "Epoch [15/50], Step [147/735], Loss: 1.8722\n",
      "Epoch [15/50], Step [148/735], Loss: 0.6691\n",
      "Epoch [15/50], Step [149/735], Loss: 0.4031\n",
      "Epoch [15/50], Step [150/735], Loss: 0.8608\n",
      "Epoch [15/50], Step [151/735], Loss: 0.2043\n",
      "Epoch [15/50], Step [152/735], Loss: 0.1066\n",
      "Epoch [15/50], Step [153/735], Loss: 0.2389\n",
      "Epoch [15/50], Step [154/735], Loss: 0.3438\n",
      "Epoch [15/50], Step [155/735], Loss: 0.0846\n",
      "Epoch [15/50], Step [156/735], Loss: 0.4887\n",
      "Epoch [15/50], Step [157/735], Loss: 0.1792\n",
      "Epoch [15/50], Step [158/735], Loss: 1.6818\n",
      "Epoch [15/50], Step [159/735], Loss: 0.5512\n",
      "Epoch [15/50], Step [160/735], Loss: 0.3087\n",
      "Epoch [15/50], Step [161/735], Loss: 0.3970\n",
      "Epoch [15/50], Step [162/735], Loss: 0.2258\n",
      "Epoch [15/50], Step [163/735], Loss: 0.3513\n",
      "Epoch [15/50], Step [164/735], Loss: 0.4900\n",
      "Epoch [15/50], Step [165/735], Loss: 1.5906\n",
      "Epoch [15/50], Step [166/735], Loss: 1.9995\n",
      "Epoch [15/50], Step [167/735], Loss: 0.4276\n",
      "Epoch [15/50], Step [168/735], Loss: 0.3047\n",
      "Epoch [15/50], Step [169/735], Loss: 0.2968\n",
      "Epoch [15/50], Step [170/735], Loss: 0.7057\n",
      "Epoch [15/50], Step [171/735], Loss: 0.3664\n",
      "Epoch [15/50], Step [172/735], Loss: 0.4318\n",
      "Epoch [15/50], Step [173/735], Loss: 1.0843\n",
      "Epoch [15/50], Step [174/735], Loss: 1.1536\n",
      "Epoch [15/50], Step [175/735], Loss: 0.5213\n",
      "Epoch [15/50], Step [176/735], Loss: 0.1454\n",
      "Epoch [15/50], Step [177/735], Loss: 0.1725\n",
      "Epoch [15/50], Step [178/735], Loss: 0.3340\n",
      "Epoch [15/50], Step [179/735], Loss: 0.3931\n",
      "Epoch [15/50], Step [180/735], Loss: 0.9718\n",
      "Epoch [15/50], Step [181/735], Loss: 0.2494\n",
      "Epoch [15/50], Step [182/735], Loss: 1.2077\n",
      "Epoch [15/50], Step [183/735], Loss: 1.1157\n",
      "Epoch [15/50], Step [184/735], Loss: 0.2044\n",
      "Epoch [15/50], Step [185/735], Loss: 0.3133\n",
      "Epoch [15/50], Step [186/735], Loss: 1.4876\n",
      "Epoch [15/50], Step [187/735], Loss: 0.2613\n",
      "Epoch [15/50], Step [188/735], Loss: 0.1770\n",
      "Epoch [15/50], Step [189/735], Loss: 0.4492\n",
      "Epoch [15/50], Step [190/735], Loss: 0.2099\n",
      "Epoch [15/50], Step [191/735], Loss: 0.4186\n",
      "Epoch [15/50], Step [192/735], Loss: 0.2794\n",
      "Epoch [15/50], Step [193/735], Loss: 0.0897\n",
      "Epoch [15/50], Step [194/735], Loss: 0.1179\n",
      "Epoch [15/50], Step [195/735], Loss: 0.4338\n",
      "Epoch [15/50], Step [196/735], Loss: 0.7000\n",
      "Epoch [15/50], Step [197/735], Loss: 0.6199\n",
      "Epoch [15/50], Step [198/735], Loss: 0.1415\n",
      "Epoch [15/50], Step [199/735], Loss: 0.1720\n",
      "Epoch [15/50], Step [200/735], Loss: 0.5369\n",
      "Epoch [15/50], Step [201/735], Loss: 0.4969\n",
      "Epoch [15/50], Step [202/735], Loss: 0.2195\n",
      "Epoch [15/50], Step [203/735], Loss: 0.5907\n",
      "Epoch [15/50], Step [204/735], Loss: 0.8416\n",
      "Epoch [15/50], Step [205/735], Loss: 0.3599\n",
      "Epoch [15/50], Step [206/735], Loss: 0.7480\n",
      "Epoch [15/50], Step [207/735], Loss: 0.1060\n",
      "Epoch [15/50], Step [208/735], Loss: 0.2351\n",
      "Epoch [15/50], Step [209/735], Loss: 0.2810\n",
      "Epoch [15/50], Step [210/735], Loss: 0.2972\n",
      "Epoch [15/50], Step [211/735], Loss: 0.1465\n",
      "Epoch [15/50], Step [212/735], Loss: 1.3270\n",
      "Epoch [15/50], Step [213/735], Loss: 0.6580\n",
      "Epoch [15/50], Step [214/735], Loss: 0.2260\n",
      "Epoch [15/50], Step [215/735], Loss: 0.4560\n",
      "Epoch [15/50], Step [216/735], Loss: 0.2525\n",
      "Epoch [15/50], Step [217/735], Loss: 0.8154\n",
      "Epoch [15/50], Step [218/735], Loss: 0.3638\n",
      "Epoch [15/50], Step [219/735], Loss: 0.0536\n",
      "Epoch [15/50], Step [220/735], Loss: 0.3671\n",
      "Epoch [15/50], Step [221/735], Loss: 0.4090\n",
      "Epoch [15/50], Step [222/735], Loss: 0.5268\n",
      "Epoch [15/50], Step [223/735], Loss: 0.4524\n",
      "Epoch [15/50], Step [224/735], Loss: 1.1327\n",
      "Epoch [15/50], Step [225/735], Loss: 1.5339\n",
      "Epoch [15/50], Step [226/735], Loss: 0.1523\n",
      "Epoch [15/50], Step [227/735], Loss: 0.1810\n",
      "Epoch [15/50], Step [228/735], Loss: 0.9904\n",
      "Epoch [15/50], Step [229/735], Loss: 0.0585\n",
      "Epoch [15/50], Step [230/735], Loss: 0.5718\n",
      "Epoch [15/50], Step [231/735], Loss: 0.7198\n",
      "Epoch [15/50], Step [232/735], Loss: 1.0265\n",
      "Epoch [15/50], Step [233/735], Loss: 0.7933\n",
      "Epoch [15/50], Step [234/735], Loss: 0.3049\n",
      "Epoch [15/50], Step [235/735], Loss: 0.5321\n",
      "Epoch [15/50], Step [236/735], Loss: 0.6195\n",
      "Epoch [15/50], Step [237/735], Loss: 0.2664\n",
      "Epoch [15/50], Step [238/735], Loss: 0.4917\n",
      "Epoch [15/50], Step [239/735], Loss: 0.4401\n",
      "Epoch [15/50], Step [240/735], Loss: 0.2556\n",
      "Epoch [15/50], Step [241/735], Loss: 0.4369\n",
      "Epoch [15/50], Step [242/735], Loss: 0.9520\n",
      "Epoch [15/50], Step [243/735], Loss: 0.4160\n",
      "Epoch [15/50], Step [244/735], Loss: 0.2356\n",
      "Epoch [15/50], Step [245/735], Loss: 0.2390\n",
      "Epoch [15/50], Step [246/735], Loss: 0.4502\n",
      "Epoch [15/50], Step [247/735], Loss: 0.2606\n",
      "Epoch [15/50], Step [248/735], Loss: 0.3307\n",
      "Epoch [15/50], Step [249/735], Loss: 0.1299\n",
      "Epoch [15/50], Step [250/735], Loss: 0.6165\n",
      "Epoch [15/50], Step [251/735], Loss: 0.2209\n",
      "Epoch [15/50], Step [252/735], Loss: 0.5318\n",
      "Epoch [15/50], Step [253/735], Loss: 0.3274\n",
      "Epoch [15/50], Step [254/735], Loss: 0.1535\n",
      "Epoch [15/50], Step [255/735], Loss: 0.1926\n",
      "Epoch [15/50], Step [256/735], Loss: 0.0963\n",
      "Epoch [15/50], Step [257/735], Loss: 0.6352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Step [258/735], Loss: 0.1715\n",
      "Epoch [15/50], Step [259/735], Loss: 0.3794\n",
      "Epoch [15/50], Step [260/735], Loss: 0.5589\n",
      "Epoch [15/50], Step [261/735], Loss: 0.1586\n",
      "Epoch [15/50], Step [262/735], Loss: 0.5717\n",
      "Epoch [15/50], Step [263/735], Loss: 1.5232\n",
      "Epoch [15/50], Step [264/735], Loss: 0.8169\n",
      "Epoch [15/50], Step [265/735], Loss: 0.1694\n",
      "Epoch [15/50], Step [266/735], Loss: 0.1119\n",
      "Epoch [15/50], Step [267/735], Loss: 0.9301\n",
      "Epoch [15/50], Step [268/735], Loss: 0.4127\n",
      "Epoch [15/50], Step [269/735], Loss: 0.0394\n",
      "Epoch [15/50], Step [270/735], Loss: 0.0567\n",
      "Epoch [15/50], Step [271/735], Loss: 0.7332\n",
      "Epoch [15/50], Step [272/735], Loss: 0.6877\n",
      "Epoch [15/50], Step [273/735], Loss: 0.3403\n",
      "Epoch [15/50], Step [274/735], Loss: 1.2529\n",
      "Epoch [15/50], Step [275/735], Loss: 0.3142\n",
      "Epoch [15/50], Step [276/735], Loss: 0.3344\n",
      "Epoch [15/50], Step [277/735], Loss: 0.6446\n",
      "Epoch [15/50], Step [278/735], Loss: 0.5089\n",
      "Epoch [15/50], Step [279/735], Loss: 0.1070\n",
      "Epoch [15/50], Step [280/735], Loss: 0.9728\n",
      "Epoch [15/50], Step [281/735], Loss: 0.3025\n",
      "Epoch [15/50], Step [282/735], Loss: 0.2420\n",
      "Epoch [15/50], Step [283/735], Loss: 0.3280\n",
      "Epoch [15/50], Step [284/735], Loss: 1.5588\n",
      "Epoch [15/50], Step [285/735], Loss: 0.2929\n",
      "Epoch [15/50], Step [286/735], Loss: 0.2041\n",
      "Epoch [15/50], Step [287/735], Loss: 0.4039\n",
      "Epoch [15/50], Step [288/735], Loss: 0.0277\n",
      "Epoch [15/50], Step [289/735], Loss: 0.1475\n",
      "Epoch [15/50], Step [290/735], Loss: 0.1629\n",
      "Epoch [15/50], Step [291/735], Loss: 0.1886\n",
      "Epoch [15/50], Step [292/735], Loss: 0.3329\n",
      "Epoch [15/50], Step [293/735], Loss: 0.1125\n",
      "Epoch [15/50], Step [294/735], Loss: 0.5097\n",
      "Epoch [15/50], Step [295/735], Loss: 0.3273\n",
      "Epoch [15/50], Step [296/735], Loss: 0.1241\n",
      "Epoch [15/50], Step [297/735], Loss: 0.4109\n",
      "Epoch [15/50], Step [298/735], Loss: 0.2157\n",
      "Epoch [15/50], Step [299/735], Loss: 0.5909\n",
      "Epoch [15/50], Step [300/735], Loss: 0.2610\n",
      "Epoch [15/50], Step [301/735], Loss: 1.1623\n",
      "Epoch [15/50], Step [302/735], Loss: 0.1751\n",
      "Epoch [15/50], Step [303/735], Loss: 0.2607\n",
      "Epoch [15/50], Step [304/735], Loss: 0.1889\n",
      "Epoch [15/50], Step [305/735], Loss: 0.0595\n",
      "Epoch [15/50], Step [306/735], Loss: 0.1603\n",
      "Epoch [15/50], Step [307/735], Loss: 1.1002\n",
      "Epoch [15/50], Step [308/735], Loss: 0.2103\n",
      "Epoch [15/50], Step [309/735], Loss: 0.1359\n",
      "Epoch [15/50], Step [310/735], Loss: 0.1341\n",
      "Epoch [15/50], Step [311/735], Loss: 0.1121\n",
      "Epoch [15/50], Step [312/735], Loss: 0.4697\n",
      "Epoch [15/50], Step [313/735], Loss: 0.1962\n",
      "Epoch [15/50], Step [314/735], Loss: 0.1725\n",
      "Epoch [15/50], Step [315/735], Loss: 0.2022\n",
      "Epoch [15/50], Step [316/735], Loss: 0.0965\n",
      "Epoch [15/50], Step [317/735], Loss: 0.2165\n",
      "Epoch [15/50], Step [318/735], Loss: 0.1852\n",
      "Epoch [15/50], Step [319/735], Loss: 0.0649\n",
      "Epoch [15/50], Step [320/735], Loss: 0.4055\n",
      "Epoch [15/50], Step [321/735], Loss: 0.2794\n",
      "Epoch [15/50], Step [322/735], Loss: 0.1860\n",
      "Epoch [15/50], Step [323/735], Loss: 0.6259\n",
      "Epoch [15/50], Step [324/735], Loss: 0.1801\n",
      "Epoch [15/50], Step [325/735], Loss: 0.3617\n",
      "Epoch [15/50], Step [326/735], Loss: 0.5167\n",
      "Epoch [15/50], Step [327/735], Loss: 0.3187\n",
      "Epoch [15/50], Step [328/735], Loss: 0.4652\n",
      "Epoch [15/50], Step [329/735], Loss: 0.3656\n",
      "Epoch [15/50], Step [330/735], Loss: 0.1682\n",
      "Epoch [15/50], Step [331/735], Loss: 0.6655\n",
      "Epoch [15/50], Step [332/735], Loss: 0.5000\n",
      "Epoch [15/50], Step [333/735], Loss: 0.0783\n",
      "Epoch [15/50], Step [334/735], Loss: 0.2443\n",
      "Epoch [15/50], Step [335/735], Loss: 0.3493\n",
      "Epoch [15/50], Step [336/735], Loss: 0.1172\n",
      "Epoch [15/50], Step [337/735], Loss: 0.2259\n",
      "Epoch [15/50], Step [338/735], Loss: 0.3628\n",
      "Epoch [15/50], Step [339/735], Loss: 0.2903\n",
      "Epoch [15/50], Step [340/735], Loss: 0.3456\n",
      "Epoch [15/50], Step [341/735], Loss: 0.7013\n",
      "Epoch [15/50], Step [342/735], Loss: 0.1557\n",
      "Epoch [15/50], Step [343/735], Loss: 2.3634\n",
      "Epoch [15/50], Step [344/735], Loss: 0.9111\n",
      "Epoch [15/50], Step [345/735], Loss: 0.1769\n",
      "Epoch [15/50], Step [346/735], Loss: 0.1642\n",
      "Epoch [15/50], Step [347/735], Loss: 0.6884\n",
      "Epoch [15/50], Step [348/735], Loss: 0.1582\n",
      "Epoch [15/50], Step [349/735], Loss: 0.2606\n",
      "Epoch [15/50], Step [350/735], Loss: 0.3120\n",
      "Epoch [15/50], Step [351/735], Loss: 0.9703\n",
      "Epoch [15/50], Step [352/735], Loss: 0.1710\n",
      "Epoch [15/50], Step [353/735], Loss: 0.0796\n",
      "Epoch [15/50], Step [354/735], Loss: 0.1990\n",
      "Epoch [15/50], Step [355/735], Loss: 0.5634\n",
      "Epoch [15/50], Step [356/735], Loss: 0.5064\n",
      "Epoch [15/50], Step [357/735], Loss: 0.2057\n",
      "Epoch [15/50], Step [358/735], Loss: 0.4281\n",
      "Epoch [15/50], Step [359/735], Loss: 0.0864\n",
      "Epoch [15/50], Step [360/735], Loss: 1.4198\n",
      "Epoch [15/50], Step [361/735], Loss: 0.1449\n",
      "Epoch [15/50], Step [362/735], Loss: 0.0896\n",
      "Epoch [15/50], Step [363/735], Loss: 0.9859\n",
      "Epoch [15/50], Step [364/735], Loss: 0.7076\n",
      "Epoch [15/50], Step [365/735], Loss: 0.3027\n",
      "Epoch [15/50], Step [366/735], Loss: 0.1776\n",
      "Epoch [15/50], Step [367/735], Loss: 0.7044\n",
      "Epoch [15/50], Step [368/735], Loss: 0.5734\n",
      "Epoch [15/50], Step [369/735], Loss: 0.2474\n",
      "Epoch [15/50], Step [370/735], Loss: 0.3888\n",
      "Epoch [15/50], Step [371/735], Loss: 0.2194\n",
      "Epoch [15/50], Step [372/735], Loss: 0.2596\n",
      "Epoch [15/50], Step [373/735], Loss: 1.3701\n",
      "Epoch [15/50], Step [374/735], Loss: 0.5390\n",
      "Epoch [15/50], Step [375/735], Loss: 0.7245\n",
      "Epoch [15/50], Step [376/735], Loss: 0.9211\n",
      "Epoch [15/50], Step [377/735], Loss: 0.6674\n",
      "Epoch [15/50], Step [378/735], Loss: 0.4562\n",
      "Epoch [15/50], Step [379/735], Loss: 0.2095\n",
      "Epoch [15/50], Step [380/735], Loss: 0.7922\n",
      "Epoch [15/50], Step [381/735], Loss: 0.7769\n",
      "Epoch [15/50], Step [382/735], Loss: 0.6760\n",
      "Epoch [15/50], Step [383/735], Loss: 0.1598\n",
      "Epoch [15/50], Step [384/735], Loss: 1.1314\n",
      "Epoch [15/50], Step [385/735], Loss: 0.2088\n",
      "Epoch [15/50], Step [386/735], Loss: 0.6170\n",
      "Epoch [15/50], Step [387/735], Loss: 0.7450\n",
      "Epoch [15/50], Step [388/735], Loss: 0.9716\n",
      "Epoch [15/50], Step [389/735], Loss: 1.0967\n",
      "Epoch [15/50], Step [390/735], Loss: 0.4035\n",
      "Epoch [15/50], Step [391/735], Loss: 0.1514\n",
      "Epoch [15/50], Step [392/735], Loss: 0.6285\n",
      "Epoch [15/50], Step [393/735], Loss: 0.5521\n",
      "Epoch [15/50], Step [394/735], Loss: 0.0817\n",
      "Epoch [15/50], Step [395/735], Loss: 0.8981\n",
      "Epoch [15/50], Step [396/735], Loss: 0.1322\n",
      "Epoch [15/50], Step [397/735], Loss: 0.3447\n",
      "Epoch [15/50], Step [398/735], Loss: 0.3213\n",
      "Epoch [15/50], Step [399/735], Loss: 0.2789\n",
      "Epoch [15/50], Step [400/735], Loss: 0.2907\n",
      "Epoch [15/50], Step [401/735], Loss: 0.2717\n",
      "Epoch [15/50], Step [402/735], Loss: 0.1916\n",
      "Epoch [15/50], Step [403/735], Loss: 0.7154\n",
      "Epoch [15/50], Step [404/735], Loss: 0.6885\n",
      "Epoch [15/50], Step [405/735], Loss: 0.1565\n",
      "Epoch [15/50], Step [406/735], Loss: 0.0790\n",
      "Epoch [15/50], Step [407/735], Loss: 0.2385\n",
      "Epoch [15/50], Step [408/735], Loss: 0.4043\n",
      "Epoch [15/50], Step [409/735], Loss: 1.1154\n",
      "Epoch [15/50], Step [410/735], Loss: 0.7451\n",
      "Epoch [15/50], Step [411/735], Loss: 0.3860\n",
      "Epoch [15/50], Step [412/735], Loss: 1.2225\n",
      "Epoch [15/50], Step [413/735], Loss: 0.7786\n",
      "Epoch [15/50], Step [414/735], Loss: 0.5374\n",
      "Epoch [15/50], Step [415/735], Loss: 0.8249\n",
      "Epoch [15/50], Step [416/735], Loss: 0.1024\n",
      "Epoch [15/50], Step [417/735], Loss: 0.2210\n",
      "Epoch [15/50], Step [418/735], Loss: 0.3489\n",
      "Epoch [15/50], Step [419/735], Loss: 0.1472\n",
      "Epoch [15/50], Step [420/735], Loss: 0.4626\n",
      "Epoch [15/50], Step [421/735], Loss: 0.3469\n",
      "Epoch [15/50], Step [422/735], Loss: 0.7273\n",
      "Epoch [15/50], Step [423/735], Loss: 0.3573\n",
      "Epoch [15/50], Step [424/735], Loss: 0.2971\n",
      "Epoch [15/50], Step [425/735], Loss: 0.0871\n",
      "Epoch [15/50], Step [426/735], Loss: 0.3029\n",
      "Epoch [15/50], Step [427/735], Loss: 0.8128\n",
      "Epoch [15/50], Step [428/735], Loss: 0.2962\n",
      "Epoch [15/50], Step [429/735], Loss: 0.3447\n",
      "Epoch [15/50], Step [430/735], Loss: 0.1825\n",
      "Epoch [15/50], Step [431/735], Loss: 0.2664\n",
      "Epoch [15/50], Step [432/735], Loss: 2.2356\n",
      "Epoch [15/50], Step [433/735], Loss: 0.3995\n",
      "Epoch [15/50], Step [434/735], Loss: 0.4558\n",
      "Epoch [15/50], Step [435/735], Loss: 0.1323\n",
      "Epoch [15/50], Step [436/735], Loss: 0.1260\n",
      "Epoch [15/50], Step [437/735], Loss: 0.8144\n",
      "Epoch [15/50], Step [438/735], Loss: 0.7087\n",
      "Epoch [15/50], Step [439/735], Loss: 0.1215\n",
      "Epoch [15/50], Step [440/735], Loss: 0.4853\n",
      "Epoch [15/50], Step [441/735], Loss: 0.0862\n",
      "Epoch [15/50], Step [442/735], Loss: 0.5400\n",
      "Epoch [15/50], Step [443/735], Loss: 0.4059\n",
      "Epoch [15/50], Step [444/735], Loss: 0.0777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Step [445/735], Loss: 0.0828\n",
      "Epoch [15/50], Step [446/735], Loss: 0.6470\n",
      "Epoch [15/50], Step [447/735], Loss: 0.1531\n",
      "Epoch [15/50], Step [448/735], Loss: 0.4833\n",
      "Epoch [15/50], Step [449/735], Loss: 0.2003\n",
      "Epoch [15/50], Step [450/735], Loss: 0.8144\n",
      "Epoch [15/50], Step [451/735], Loss: 0.8695\n",
      "Epoch [15/50], Step [452/735], Loss: 0.6287\n",
      "Epoch [15/50], Step [453/735], Loss: 0.4642\n",
      "Epoch [15/50], Step [454/735], Loss: 0.2246\n",
      "Epoch [15/50], Step [455/735], Loss: 0.9413\n",
      "Epoch [15/50], Step [456/735], Loss: 0.4200\n",
      "Epoch [15/50], Step [457/735], Loss: 0.2303\n",
      "Epoch [15/50], Step [458/735], Loss: 0.3834\n",
      "Epoch [15/50], Step [459/735], Loss: 0.2012\n",
      "Epoch [15/50], Step [460/735], Loss: 0.7200\n",
      "Epoch [15/50], Step [461/735], Loss: 0.1506\n",
      "Epoch [15/50], Step [462/735], Loss: 0.2701\n",
      "Epoch [15/50], Step [463/735], Loss: 0.1373\n",
      "Epoch [15/50], Step [464/735], Loss: 0.1600\n",
      "Epoch [15/50], Step [465/735], Loss: 0.9060\n",
      "Epoch [15/50], Step [466/735], Loss: 0.6376\n",
      "Epoch [15/50], Step [467/735], Loss: 0.6728\n",
      "Epoch [15/50], Step [468/735], Loss: 0.2867\n",
      "Epoch [15/50], Step [469/735], Loss: 0.2532\n",
      "Epoch [15/50], Step [470/735], Loss: 0.3061\n",
      "Epoch [15/50], Step [471/735], Loss: 0.9270\n",
      "Epoch [15/50], Step [472/735], Loss: 0.8078\n",
      "Epoch [15/50], Step [473/735], Loss: 0.2908\n",
      "Epoch [15/50], Step [474/735], Loss: 0.1503\n",
      "Epoch [15/50], Step [475/735], Loss: 0.2617\n",
      "Epoch [15/50], Step [476/735], Loss: 0.5908\n",
      "Epoch [15/50], Step [477/735], Loss: 0.2693\n",
      "Epoch [15/50], Step [478/735], Loss: 0.5266\n",
      "Epoch [15/50], Step [479/735], Loss: 0.2416\n",
      "Epoch [15/50], Step [480/735], Loss: 0.1732\n",
      "Epoch [15/50], Step [481/735], Loss: 0.4303\n",
      "Epoch [15/50], Step [482/735], Loss: 0.9167\n",
      "Epoch [15/50], Step [483/735], Loss: 1.1433\n",
      "Epoch [15/50], Step [484/735], Loss: 0.2913\n",
      "Epoch [15/50], Step [485/735], Loss: 0.4806\n",
      "Epoch [15/50], Step [486/735], Loss: 0.4340\n",
      "Epoch [15/50], Step [487/735], Loss: 0.6315\n",
      "Epoch [15/50], Step [488/735], Loss: 0.4313\n",
      "Epoch [15/50], Step [489/735], Loss: 0.3965\n",
      "Epoch [15/50], Step [490/735], Loss: 0.5440\n",
      "Epoch [15/50], Step [491/735], Loss: 0.7785\n",
      "Epoch [15/50], Step [492/735], Loss: 1.0609\n",
      "Epoch [15/50], Step [493/735], Loss: 0.0792\n",
      "Epoch [15/50], Step [494/735], Loss: 1.3663\n",
      "Epoch [15/50], Step [495/735], Loss: 0.2205\n",
      "Epoch [15/50], Step [496/735], Loss: 0.4328\n",
      "Epoch [15/50], Step [497/735], Loss: 0.4165\n",
      "Epoch [15/50], Step [498/735], Loss: 0.2664\n",
      "Epoch [15/50], Step [499/735], Loss: 0.3990\n",
      "Epoch [15/50], Step [500/735], Loss: 0.3121\n",
      "Epoch [15/50], Step [501/735], Loss: 1.0185\n",
      "Epoch [15/50], Step [502/735], Loss: 0.4553\n",
      "Epoch [15/50], Step [503/735], Loss: 0.2463\n",
      "Epoch [15/50], Step [504/735], Loss: 0.3834\n",
      "Epoch [15/50], Step [505/735], Loss: 0.1833\n",
      "Epoch [15/50], Step [506/735], Loss: 0.1660\n",
      "Epoch [15/50], Step [507/735], Loss: 0.4093\n",
      "Epoch [15/50], Step [508/735], Loss: 0.2255\n",
      "Epoch [15/50], Step [509/735], Loss: 0.1793\n",
      "Epoch [15/50], Step [510/735], Loss: 0.2603\n",
      "Epoch [15/50], Step [511/735], Loss: 0.4343\n",
      "Epoch [15/50], Step [512/735], Loss: 0.6372\n",
      "Epoch [15/50], Step [513/735], Loss: 0.0996\n",
      "Epoch [15/50], Step [514/735], Loss: 0.1370\n",
      "Epoch [15/50], Step [515/735], Loss: 0.1767\n",
      "Epoch [15/50], Step [516/735], Loss: 1.5864\n",
      "Epoch [15/50], Step [517/735], Loss: 0.2484\n",
      "Epoch [15/50], Step [518/735], Loss: 0.3997\n",
      "Epoch [15/50], Step [519/735], Loss: 0.3755\n",
      "Epoch [15/50], Step [520/735], Loss: 0.4351\n",
      "Epoch [15/50], Step [521/735], Loss: 0.0842\n",
      "Epoch [15/50], Step [522/735], Loss: 0.7090\n",
      "Epoch [15/50], Step [523/735], Loss: 0.3241\n",
      "Epoch [15/50], Step [524/735], Loss: 0.3612\n",
      "Epoch [15/50], Step [525/735], Loss: 1.3494\n",
      "Epoch [15/50], Step [526/735], Loss: 0.2909\n",
      "Epoch [15/50], Step [527/735], Loss: 0.2898\n",
      "Epoch [15/50], Step [528/735], Loss: 0.2053\n",
      "Epoch [15/50], Step [529/735], Loss: 0.3149\n",
      "Epoch [15/50], Step [530/735], Loss: 0.1982\n",
      "Epoch [15/50], Step [531/735], Loss: 0.0541\n",
      "Epoch [15/50], Step [532/735], Loss: 0.6788\n",
      "Epoch [15/50], Step [533/735], Loss: 0.2835\n",
      "Epoch [15/50], Step [534/735], Loss: 0.5028\n",
      "Epoch [15/50], Step [535/735], Loss: 0.6200\n",
      "Epoch [15/50], Step [536/735], Loss: 0.9490\n",
      "Epoch [15/50], Step [537/735], Loss: 0.1301\n",
      "Epoch [15/50], Step [538/735], Loss: 0.1338\n",
      "Epoch [15/50], Step [539/735], Loss: 0.2446\n",
      "Epoch [15/50], Step [540/735], Loss: 0.3581\n",
      "Epoch [15/50], Step [541/735], Loss: 0.2561\n",
      "Epoch [15/50], Step [542/735], Loss: 0.1057\n",
      "Epoch [15/50], Step [543/735], Loss: 0.0994\n",
      "Epoch [15/50], Step [544/735], Loss: 0.1832\n",
      "Epoch [15/50], Step [545/735], Loss: 0.5743\n",
      "Epoch [15/50], Step [546/735], Loss: 0.2399\n",
      "Epoch [15/50], Step [547/735], Loss: 1.2120\n",
      "Epoch [15/50], Step [548/735], Loss: 0.3595\n",
      "Epoch [15/50], Step [549/735], Loss: 0.0993\n",
      "Epoch [15/50], Step [550/735], Loss: 0.1627\n",
      "Epoch [15/50], Step [551/735], Loss: 0.1808\n",
      "Epoch [15/50], Step [552/735], Loss: 2.3094\n",
      "Epoch [15/50], Step [553/735], Loss: 0.2121\n",
      "Epoch [15/50], Step [554/735], Loss: 0.3909\n",
      "Epoch [15/50], Step [555/735], Loss: 0.3052\n",
      "Epoch [15/50], Step [556/735], Loss: 0.2538\n",
      "Epoch [15/50], Step [557/735], Loss: 0.8982\n",
      "Epoch [15/50], Step [558/735], Loss: 0.4898\n",
      "Epoch [15/50], Step [559/735], Loss: 0.7151\n",
      "Epoch [15/50], Step [560/735], Loss: 0.5862\n",
      "Epoch [15/50], Step [561/735], Loss: 0.2918\n",
      "Epoch [15/50], Step [562/735], Loss: 0.2779\n",
      "Epoch [15/50], Step [563/735], Loss: 0.5464\n",
      "Epoch [15/50], Step [564/735], Loss: 1.5036\n",
      "Epoch [15/50], Step [565/735], Loss: 0.4589\n",
      "Epoch [15/50], Step [566/735], Loss: 0.1516\n",
      "Epoch [15/50], Step [567/735], Loss: 0.3194\n",
      "Epoch [15/50], Step [568/735], Loss: 0.3888\n",
      "Epoch [15/50], Step [569/735], Loss: 0.0683\n",
      "Epoch [15/50], Step [570/735], Loss: 0.5478\n",
      "Epoch [15/50], Step [571/735], Loss: 5.0740\n",
      "Epoch [15/50], Step [572/735], Loss: 0.1962\n",
      "Epoch [15/50], Step [573/735], Loss: 0.3175\n",
      "Epoch [15/50], Step [574/735], Loss: 0.1400\n",
      "Epoch [15/50], Step [575/735], Loss: 0.4583\n",
      "Epoch [15/50], Step [576/735], Loss: 0.0771\n",
      "Epoch [15/50], Step [577/735], Loss: 0.9985\n",
      "Epoch [15/50], Step [578/735], Loss: 0.3988\n",
      "Epoch [15/50], Step [579/735], Loss: 1.8039\n",
      "Epoch [15/50], Step [580/735], Loss: 0.7700\n",
      "Epoch [15/50], Step [581/735], Loss: 1.3108\n",
      "Epoch [15/50], Step [582/735], Loss: 0.3536\n",
      "Epoch [15/50], Step [583/735], Loss: 2.0470\n",
      "Epoch [15/50], Step [584/735], Loss: 0.4808\n",
      "Epoch [15/50], Step [585/735], Loss: 0.1133\n",
      "Epoch [15/50], Step [586/735], Loss: 0.4850\n",
      "Epoch [15/50], Step [587/735], Loss: 0.1707\n",
      "Epoch [15/50], Step [588/735], Loss: 0.3279\n",
      "Epoch [15/50], Step [589/735], Loss: 0.2877\n",
      "Epoch [15/50], Step [590/735], Loss: 0.4583\n",
      "Epoch [15/50], Step [591/735], Loss: 0.2072\n",
      "Epoch [15/50], Step [592/735], Loss: 0.7222\n",
      "Epoch [15/50], Step [593/735], Loss: 0.2247\n",
      "Epoch [15/50], Step [594/735], Loss: 1.3178\n",
      "Epoch [15/50], Step [595/735], Loss: 0.1402\n",
      "Epoch [15/50], Step [596/735], Loss: 0.3936\n",
      "Epoch [15/50], Step [597/735], Loss: 0.1414\n",
      "Epoch [15/50], Step [598/735], Loss: 0.0929\n",
      "Epoch [15/50], Step [599/735], Loss: 0.2126\n",
      "Epoch [15/50], Step [600/735], Loss: 0.5907\n",
      "Epoch [15/50], Step [601/735], Loss: 0.5185\n",
      "Epoch [15/50], Step [602/735], Loss: 0.1703\n",
      "Epoch [15/50], Step [603/735], Loss: 0.6901\n",
      "Epoch [15/50], Step [604/735], Loss: 0.2743\n",
      "Epoch [15/50], Step [605/735], Loss: 0.4324\n",
      "Epoch [15/50], Step [606/735], Loss: 0.1000\n",
      "Epoch [15/50], Step [607/735], Loss: 1.3386\n",
      "Epoch [15/50], Step [608/735], Loss: 0.1676\n",
      "Epoch [15/50], Step [609/735], Loss: 0.7813\n",
      "Epoch [15/50], Step [610/735], Loss: 0.4018\n",
      "Epoch [15/50], Step [611/735], Loss: 0.6130\n",
      "Epoch [15/50], Step [612/735], Loss: 0.3325\n",
      "Epoch [15/50], Step [613/735], Loss: 0.0819\n",
      "Epoch [15/50], Step [614/735], Loss: 0.1264\n",
      "Epoch [15/50], Step [615/735], Loss: 0.2459\n",
      "Epoch [15/50], Step [616/735], Loss: 0.1488\n",
      "Epoch [15/50], Step [617/735], Loss: 0.2766\n",
      "Epoch [15/50], Step [618/735], Loss: 0.2040\n",
      "Epoch [15/50], Step [619/735], Loss: 0.5445\n",
      "Epoch [15/50], Step [620/735], Loss: 0.3155\n",
      "Epoch [15/50], Step [621/735], Loss: 0.3678\n",
      "Epoch [15/50], Step [622/735], Loss: 0.1176\n",
      "Epoch [15/50], Step [623/735], Loss: 0.9743\n",
      "Epoch [15/50], Step [624/735], Loss: 0.9907\n",
      "Epoch [15/50], Step [625/735], Loss: 0.3498\n",
      "Epoch [15/50], Step [626/735], Loss: 0.2463\n",
      "Epoch [15/50], Step [627/735], Loss: 0.0832\n",
      "Epoch [15/50], Step [628/735], Loss: 0.1231\n",
      "Epoch [15/50], Step [629/735], Loss: 0.5014\n",
      "Epoch [15/50], Step [630/735], Loss: 0.6504\n",
      "Epoch [15/50], Step [631/735], Loss: 0.4109\n",
      "Epoch [15/50], Step [632/735], Loss: 0.7552\n",
      "Epoch [15/50], Step [633/735], Loss: 0.1833\n",
      "Epoch [15/50], Step [634/735], Loss: 1.3691\n",
      "Epoch [15/50], Step [635/735], Loss: 0.8612\n",
      "Epoch [15/50], Step [636/735], Loss: 0.2610\n",
      "Epoch [15/50], Step [637/735], Loss: 0.3192\n",
      "Epoch [15/50], Step [638/735], Loss: 0.5659\n",
      "Epoch [15/50], Step [639/735], Loss: 0.4454\n",
      "Epoch [15/50], Step [640/735], Loss: 0.3218\n",
      "Epoch [15/50], Step [641/735], Loss: 0.5618\n",
      "Epoch [15/50], Step [642/735], Loss: 0.1704\n",
      "Epoch [15/50], Step [643/735], Loss: 0.1374\n",
      "Epoch [15/50], Step [644/735], Loss: 0.2972\n",
      "Epoch [15/50], Step [645/735], Loss: 0.2594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Step [646/735], Loss: 0.6154\n",
      "Epoch [15/50], Step [647/735], Loss: 0.7683\n",
      "Epoch [15/50], Step [648/735], Loss: 0.6109\n",
      "Epoch [15/50], Step [649/735], Loss: 1.5601\n",
      "Epoch [15/50], Step [650/735], Loss: 0.2331\n",
      "Epoch [15/50], Step [651/735], Loss: 0.2663\n",
      "Epoch [15/50], Step [652/735], Loss: 0.3169\n",
      "Epoch [15/50], Step [653/735], Loss: 0.2493\n",
      "Epoch [15/50], Step [654/735], Loss: 0.1376\n",
      "Epoch [15/50], Step [655/735], Loss: 0.1903\n",
      "Epoch [15/50], Step [656/735], Loss: 0.4812\n",
      "Epoch [15/50], Step [657/735], Loss: 0.4353\n",
      "Epoch [15/50], Step [658/735], Loss: 0.5305\n",
      "Epoch [15/50], Step [659/735], Loss: 0.2779\n",
      "Epoch [15/50], Step [660/735], Loss: 0.5260\n",
      "Epoch [15/50], Step [661/735], Loss: 0.4215\n",
      "Epoch [15/50], Step [662/735], Loss: 0.1601\n",
      "Epoch [15/50], Step [663/735], Loss: 0.2228\n",
      "Epoch [15/50], Step [664/735], Loss: 0.5890\n",
      "Epoch [15/50], Step [665/735], Loss: 0.7957\n",
      "Epoch [15/50], Step [666/735], Loss: 0.3013\n",
      "Epoch [15/50], Step [667/735], Loss: 0.4762\n",
      "Epoch [15/50], Step [668/735], Loss: 0.3667\n",
      "Epoch [15/50], Step [669/735], Loss: 0.7087\n",
      "Epoch [15/50], Step [670/735], Loss: 0.5736\n",
      "Epoch [15/50], Step [671/735], Loss: 0.1655\n",
      "Epoch [15/50], Step [672/735], Loss: 0.2510\n",
      "Epoch [15/50], Step [673/735], Loss: 1.4529\n",
      "Epoch [15/50], Step [674/735], Loss: 0.1815\n",
      "Epoch [15/50], Step [675/735], Loss: 1.0802\n",
      "Epoch [15/50], Step [676/735], Loss: 0.9274\n",
      "Epoch [15/50], Step [677/735], Loss: 5.6139\n",
      "Epoch [15/50], Step [678/735], Loss: 0.0510\n",
      "Epoch [15/50], Step [679/735], Loss: 0.0374\n",
      "Epoch [15/50], Step [680/735], Loss: 0.1917\n",
      "Epoch [15/50], Step [681/735], Loss: 0.2735\n",
      "Epoch [15/50], Step [682/735], Loss: 1.1367\n",
      "Epoch [15/50], Step [683/735], Loss: 0.1118\n",
      "Epoch [15/50], Step [684/735], Loss: 0.2255\n",
      "Epoch [15/50], Step [685/735], Loss: 0.9692\n",
      "Epoch [15/50], Step [686/735], Loss: 0.4732\n",
      "Epoch [15/50], Step [687/735], Loss: 0.1471\n",
      "Epoch [15/50], Step [688/735], Loss: 0.1501\n",
      "Epoch [15/50], Step [689/735], Loss: 0.3016\n",
      "Epoch [15/50], Step [690/735], Loss: 0.2810\n",
      "Epoch [15/50], Step [691/735], Loss: 0.2488\n",
      "Epoch [15/50], Step [692/735], Loss: 0.1788\n",
      "Epoch [15/50], Step [693/735], Loss: 0.0787\n",
      "Epoch [15/50], Step [694/735], Loss: 0.3268\n",
      "Epoch [15/50], Step [695/735], Loss: 0.3293\n",
      "Epoch [15/50], Step [696/735], Loss: 0.7489\n",
      "Epoch [15/50], Step [697/735], Loss: 0.3165\n",
      "Epoch [15/50], Step [698/735], Loss: 0.8522\n",
      "Epoch [15/50], Step [699/735], Loss: 0.1172\n",
      "Epoch [15/50], Step [700/735], Loss: 0.3079\n",
      "Epoch [15/50], Step [701/735], Loss: 0.3233\n",
      "Epoch [15/50], Step [702/735], Loss: 0.2516\n",
      "Epoch [15/50], Step [703/735], Loss: 0.1941\n",
      "Epoch [15/50], Step [704/735], Loss: 0.3232\n",
      "Epoch [15/50], Step [705/735], Loss: 0.2883\n",
      "Epoch [15/50], Step [706/735], Loss: 0.3015\n",
      "Epoch [15/50], Step [707/735], Loss: 0.1542\n",
      "Epoch [15/50], Step [708/735], Loss: 0.9853\n",
      "Epoch [15/50], Step [709/735], Loss: 0.2492\n",
      "Epoch [15/50], Step [710/735], Loss: 1.5838\n",
      "Epoch [15/50], Step [711/735], Loss: 0.2502\n",
      "Epoch [15/50], Step [712/735], Loss: 0.1422\n",
      "Epoch [15/50], Step [713/735], Loss: 0.2899\n",
      "Epoch [15/50], Step [714/735], Loss: 0.1741\n",
      "Epoch [15/50], Step [715/735], Loss: 6.0180\n",
      "Epoch [15/50], Step [716/735], Loss: 0.1347\n",
      "Epoch [15/50], Step [717/735], Loss: 0.0766\n",
      "Epoch [15/50], Step [718/735], Loss: 0.0334\n",
      "Epoch [15/50], Step [719/735], Loss: 0.4797\n",
      "Epoch [15/50], Step [720/735], Loss: 0.5831\n",
      "Epoch [15/50], Step [721/735], Loss: 0.2828\n",
      "Epoch [15/50], Step [722/735], Loss: 0.3675\n",
      "Epoch [15/50], Step [723/735], Loss: 0.2221\n",
      "Epoch [15/50], Step [724/735], Loss: 0.0720\n",
      "Epoch [15/50], Step [725/735], Loss: 0.0812\n",
      "Epoch [15/50], Step [726/735], Loss: 0.3701\n",
      "Epoch [15/50], Step [727/735], Loss: 0.2405\n",
      "Epoch [15/50], Step [728/735], Loss: 5.9592\n",
      "Epoch [15/50], Step [729/735], Loss: 0.6519\n",
      "Epoch [15/50], Step [730/735], Loss: 0.8431\n",
      "Epoch [15/50], Step [731/735], Loss: 0.2104\n",
      "Epoch [15/50], Step [732/735], Loss: 0.1624\n",
      "Epoch [15/50], Step [733/735], Loss: 4.4939\n",
      "Epoch [15/50], Step [734/735], Loss: 0.7366\n",
      "Epoch [15/50], Step [735/735], Loss: 0.4664\n",
      "Epoch [16/50], Step [1/735], Loss: 1.3951\n",
      "Epoch [16/50], Step [2/735], Loss: 0.2086\n",
      "Epoch [16/50], Step [3/735], Loss: 0.4698\n",
      "Epoch [16/50], Step [4/735], Loss: 0.1877\n",
      "Epoch [16/50], Step [5/735], Loss: 0.2395\n",
      "Epoch [16/50], Step [6/735], Loss: 0.4436\n",
      "Epoch [16/50], Step [7/735], Loss: 0.5957\n",
      "Epoch [16/50], Step [8/735], Loss: 0.6754\n",
      "Epoch [16/50], Step [9/735], Loss: 0.1571\n",
      "Epoch [16/50], Step [10/735], Loss: 0.1002\n",
      "Epoch [16/50], Step [11/735], Loss: 0.0884\n",
      "Epoch [16/50], Step [12/735], Loss: 0.1950\n",
      "Epoch [16/50], Step [13/735], Loss: 0.2606\n",
      "Epoch [16/50], Step [14/735], Loss: 0.2653\n",
      "Epoch [16/50], Step [15/735], Loss: 0.2669\n",
      "Epoch [16/50], Step [16/735], Loss: 0.4163\n",
      "Epoch [16/50], Step [17/735], Loss: 0.2876\n",
      "Epoch [16/50], Step [18/735], Loss: 1.0268\n",
      "Epoch [16/50], Step [19/735], Loss: 0.1697\n",
      "Epoch [16/50], Step [20/735], Loss: 0.3769\n",
      "Epoch [16/50], Step [21/735], Loss: 0.1291\n",
      "Epoch [16/50], Step [22/735], Loss: 0.3067\n",
      "Epoch [16/50], Step [23/735], Loss: 0.1861\n",
      "Epoch [16/50], Step [24/735], Loss: 0.4876\n",
      "Epoch [16/50], Step [25/735], Loss: 0.2861\n",
      "Epoch [16/50], Step [26/735], Loss: 0.7805\n",
      "Epoch [16/50], Step [27/735], Loss: 0.1605\n",
      "Epoch [16/50], Step [28/735], Loss: 0.4836\n",
      "Epoch [16/50], Step [29/735], Loss: 0.2553\n",
      "Epoch [16/50], Step [30/735], Loss: 0.3687\n",
      "Epoch [16/50], Step [31/735], Loss: 0.3112\n",
      "Epoch [16/50], Step [32/735], Loss: 0.6723\n",
      "Epoch [16/50], Step [33/735], Loss: 0.3433\n",
      "Epoch [16/50], Step [34/735], Loss: 0.2963\n",
      "Epoch [16/50], Step [35/735], Loss: 1.3820\n",
      "Epoch [16/50], Step [36/735], Loss: 0.2882\n",
      "Epoch [16/50], Step [37/735], Loss: 0.2901\n",
      "Epoch [16/50], Step [38/735], Loss: 1.2191\n",
      "Epoch [16/50], Step [39/735], Loss: 0.8221\n",
      "Epoch [16/50], Step [40/735], Loss: 0.7406\n",
      "Epoch [16/50], Step [41/735], Loss: 0.2276\n",
      "Epoch [16/50], Step [42/735], Loss: 0.4133\n",
      "Epoch [16/50], Step [43/735], Loss: 0.5751\n",
      "Epoch [16/50], Step [44/735], Loss: 0.3213\n",
      "Epoch [16/50], Step [45/735], Loss: 0.1448\n",
      "Epoch [16/50], Step [46/735], Loss: 0.1398\n",
      "Epoch [16/50], Step [47/735], Loss: 0.3422\n",
      "Epoch [16/50], Step [48/735], Loss: 0.4295\n",
      "Epoch [16/50], Step [49/735], Loss: 0.1066\n",
      "Epoch [16/50], Step [50/735], Loss: 0.0992\n",
      "Epoch [16/50], Step [51/735], Loss: 0.1769\n",
      "Epoch [16/50], Step [52/735], Loss: 0.1263\n",
      "Epoch [16/50], Step [53/735], Loss: 1.6892\n",
      "Epoch [16/50], Step [54/735], Loss: 0.7497\n",
      "Epoch [16/50], Step [55/735], Loss: 0.2651\n",
      "Epoch [16/50], Step [56/735], Loss: 0.2380\n",
      "Epoch [16/50], Step [57/735], Loss: 0.3227\n",
      "Epoch [16/50], Step [58/735], Loss: 0.2535\n",
      "Epoch [16/50], Step [59/735], Loss: 0.1460\n",
      "Epoch [16/50], Step [60/735], Loss: 0.2459\n",
      "Epoch [16/50], Step [61/735], Loss: 0.2141\n",
      "Epoch [16/50], Step [62/735], Loss: 0.1806\n",
      "Epoch [16/50], Step [63/735], Loss: 0.2986\n",
      "Epoch [16/50], Step [64/735], Loss: 0.3475\n",
      "Epoch [16/50], Step [65/735], Loss: 0.6256\n",
      "Epoch [16/50], Step [66/735], Loss: 0.2915\n",
      "Epoch [16/50], Step [67/735], Loss: 0.4785\n",
      "Epoch [16/50], Step [68/735], Loss: 0.7321\n",
      "Epoch [16/50], Step [69/735], Loss: 0.0912\n",
      "Epoch [16/50], Step [70/735], Loss: 0.5122\n",
      "Epoch [16/50], Step [71/735], Loss: 0.1710\n",
      "Epoch [16/50], Step [72/735], Loss: 0.5576\n",
      "Epoch [16/50], Step [73/735], Loss: 0.2596\n",
      "Epoch [16/50], Step [74/735], Loss: 0.6032\n",
      "Epoch [16/50], Step [75/735], Loss: 1.1339\n",
      "Epoch [16/50], Step [76/735], Loss: 1.5975\n",
      "Epoch [16/50], Step [77/735], Loss: 0.1721\n",
      "Epoch [16/50], Step [78/735], Loss: 0.1666\n",
      "Epoch [16/50], Step [79/735], Loss: 0.1391\n",
      "Epoch [16/50], Step [80/735], Loss: 0.3281\n",
      "Epoch [16/50], Step [81/735], Loss: 0.7122\n",
      "Epoch [16/50], Step [82/735], Loss: 5.1265\n",
      "Epoch [16/50], Step [83/735], Loss: 0.4632\n",
      "Epoch [16/50], Step [84/735], Loss: 0.2567\n",
      "Epoch [16/50], Step [85/735], Loss: 0.1576\n",
      "Epoch [16/50], Step [86/735], Loss: 0.2942\n",
      "Epoch [16/50], Step [87/735], Loss: 0.4489\n",
      "Epoch [16/50], Step [88/735], Loss: 0.5617\n",
      "Epoch [16/50], Step [89/735], Loss: 0.2649\n",
      "Epoch [16/50], Step [90/735], Loss: 0.3366\n",
      "Epoch [16/50], Step [91/735], Loss: 0.2657\n",
      "Epoch [16/50], Step [92/735], Loss: 0.3562\n",
      "Epoch [16/50], Step [93/735], Loss: 0.4099\n",
      "Epoch [16/50], Step [94/735], Loss: 0.1258\n",
      "Epoch [16/50], Step [95/735], Loss: 0.1081\n",
      "Epoch [16/50], Step [96/735], Loss: 0.2683\n",
      "Epoch [16/50], Step [97/735], Loss: 1.6838\n",
      "Epoch [16/50], Step [98/735], Loss: 0.2238\n",
      "Epoch [16/50], Step [99/735], Loss: 0.4488\n",
      "Epoch [16/50], Step [100/735], Loss: 0.4179\n",
      "Epoch [16/50], Step [101/735], Loss: 0.5106\n",
      "Epoch [16/50], Step [102/735], Loss: 1.0204\n",
      "Epoch [16/50], Step [103/735], Loss: 0.3785\n",
      "Epoch [16/50], Step [104/735], Loss: 0.6128\n",
      "Epoch [16/50], Step [105/735], Loss: 0.2133\n",
      "Epoch [16/50], Step [106/735], Loss: 0.2664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Step [107/735], Loss: 0.3536\n",
      "Epoch [16/50], Step [108/735], Loss: 0.4676\n",
      "Epoch [16/50], Step [109/735], Loss: 0.6542\n",
      "Epoch [16/50], Step [110/735], Loss: 0.4768\n",
      "Epoch [16/50], Step [111/735], Loss: 0.2698\n",
      "Epoch [16/50], Step [112/735], Loss: 0.1834\n",
      "Epoch [16/50], Step [113/735], Loss: 0.2932\n",
      "Epoch [16/50], Step [114/735], Loss: 0.1156\n",
      "Epoch [16/50], Step [115/735], Loss: 0.3556\n",
      "Epoch [16/50], Step [116/735], Loss: 0.2775\n",
      "Epoch [16/50], Step [117/735], Loss: 0.2175\n",
      "Epoch [16/50], Step [118/735], Loss: 1.9952\n",
      "Epoch [16/50], Step [119/735], Loss: 0.1197\n",
      "Epoch [16/50], Step [120/735], Loss: 0.2831\n",
      "Epoch [16/50], Step [121/735], Loss: 0.2490\n",
      "Epoch [16/50], Step [122/735], Loss: 0.7147\n",
      "Epoch [16/50], Step [123/735], Loss: 0.2377\n",
      "Epoch [16/50], Step [124/735], Loss: 0.4565\n",
      "Epoch [16/50], Step [125/735], Loss: 1.6587\n",
      "Epoch [16/50], Step [126/735], Loss: 0.3194\n",
      "Epoch [16/50], Step [127/735], Loss: 0.5191\n",
      "Epoch [16/50], Step [128/735], Loss: 0.4518\n",
      "Epoch [16/50], Step [129/735], Loss: 0.1903\n",
      "Epoch [16/50], Step [130/735], Loss: 0.1428\n",
      "Epoch [16/50], Step [131/735], Loss: 0.4839\n",
      "Epoch [16/50], Step [132/735], Loss: 0.7675\n",
      "Epoch [16/50], Step [133/735], Loss: 0.2534\n",
      "Epoch [16/50], Step [134/735], Loss: 0.2102\n",
      "Epoch [16/50], Step [135/735], Loss: 0.3217\n",
      "Epoch [16/50], Step [136/735], Loss: 0.4728\n",
      "Epoch [16/50], Step [137/735], Loss: 0.4467\n",
      "Epoch [16/50], Step [138/735], Loss: 0.2104\n",
      "Epoch [16/50], Step [139/735], Loss: 0.4280\n",
      "Epoch [16/50], Step [140/735], Loss: 0.8412\n",
      "Epoch [16/50], Step [141/735], Loss: 0.6808\n",
      "Epoch [16/50], Step [142/735], Loss: 0.2578\n",
      "Epoch [16/50], Step [143/735], Loss: 0.4043\n",
      "Epoch [16/50], Step [144/735], Loss: 0.4214\n",
      "Epoch [16/50], Step [145/735], Loss: 0.4410\n",
      "Epoch [16/50], Step [146/735], Loss: 0.1051\n",
      "Epoch [16/50], Step [147/735], Loss: 0.4657\n",
      "Epoch [16/50], Step [148/735], Loss: 0.1693\n",
      "Epoch [16/50], Step [149/735], Loss: 0.4546\n",
      "Epoch [16/50], Step [150/735], Loss: 0.2092\n",
      "Epoch [16/50], Step [151/735], Loss: 0.3055\n",
      "Epoch [16/50], Step [152/735], Loss: 0.1872\n",
      "Epoch [16/50], Step [153/735], Loss: 0.2410\n",
      "Epoch [16/50], Step [154/735], Loss: 0.3340\n",
      "Epoch [16/50], Step [155/735], Loss: 0.0789\n",
      "Epoch [16/50], Step [156/735], Loss: 0.1943\n",
      "Epoch [16/50], Step [157/735], Loss: 0.1691\n",
      "Epoch [16/50], Step [158/735], Loss: 0.5278\n",
      "Epoch [16/50], Step [159/735], Loss: 0.1698\n",
      "Epoch [16/50], Step [160/735], Loss: 0.2693\n",
      "Epoch [16/50], Step [161/735], Loss: 0.8881\n",
      "Epoch [16/50], Step [162/735], Loss: 1.1808\n",
      "Epoch [16/50], Step [163/735], Loss: 0.6624\n",
      "Epoch [16/50], Step [164/735], Loss: 0.3322\n",
      "Epoch [16/50], Step [165/735], Loss: 0.2418\n",
      "Epoch [16/50], Step [166/735], Loss: 0.7891\n",
      "Epoch [16/50], Step [167/735], Loss: 0.2033\n",
      "Epoch [16/50], Step [168/735], Loss: 0.1383\n",
      "Epoch [16/50], Step [169/735], Loss: 0.1352\n",
      "Epoch [16/50], Step [170/735], Loss: 0.5579\n",
      "Epoch [16/50], Step [171/735], Loss: 0.1567\n",
      "Epoch [16/50], Step [172/735], Loss: 0.2431\n",
      "Epoch [16/50], Step [173/735], Loss: 0.4345\n",
      "Epoch [16/50], Step [174/735], Loss: 0.4140\n",
      "Epoch [16/50], Step [175/735], Loss: 0.0966\n",
      "Epoch [16/50], Step [176/735], Loss: 0.2912\n",
      "Epoch [16/50], Step [177/735], Loss: 1.0538\n",
      "Epoch [16/50], Step [178/735], Loss: 0.6917\n",
      "Epoch [16/50], Step [179/735], Loss: 0.1881\n",
      "Epoch [16/50], Step [180/735], Loss: 0.4519\n",
      "Epoch [16/50], Step [181/735], Loss: 0.7358\n",
      "Epoch [16/50], Step [182/735], Loss: 0.1663\n",
      "Epoch [16/50], Step [183/735], Loss: 1.1260\n",
      "Epoch [16/50], Step [184/735], Loss: 0.5552\n",
      "Epoch [16/50], Step [185/735], Loss: 1.7857\n",
      "Epoch [16/50], Step [186/735], Loss: 0.4169\n",
      "Epoch [16/50], Step [187/735], Loss: 0.4493\n",
      "Epoch [16/50], Step [188/735], Loss: 1.7334\n",
      "Epoch [16/50], Step [189/735], Loss: 0.3219\n",
      "Epoch [16/50], Step [190/735], Loss: 0.3644\n",
      "Epoch [16/50], Step [191/735], Loss: 0.0888\n",
      "Epoch [16/50], Step [192/735], Loss: 0.8569\n",
      "Epoch [16/50], Step [193/735], Loss: 0.1657\n",
      "Epoch [16/50], Step [194/735], Loss: 0.9985\n",
      "Epoch [16/50], Step [195/735], Loss: 0.4556\n",
      "Epoch [16/50], Step [196/735], Loss: 0.4310\n",
      "Epoch [16/50], Step [197/735], Loss: 0.7149\n",
      "Epoch [16/50], Step [198/735], Loss: 0.6519\n",
      "Epoch [16/50], Step [199/735], Loss: 0.4124\n",
      "Epoch [16/50], Step [200/735], Loss: 0.2192\n",
      "Epoch [16/50], Step [201/735], Loss: 0.3071\n",
      "Epoch [16/50], Step [202/735], Loss: 0.2331\n",
      "Epoch [16/50], Step [203/735], Loss: 1.6658\n",
      "Epoch [16/50], Step [204/735], Loss: 1.0461\n",
      "Epoch [16/50], Step [205/735], Loss: 1.2616\n",
      "Epoch [16/50], Step [206/735], Loss: 0.1275\n",
      "Epoch [16/50], Step [207/735], Loss: 0.6344\n",
      "Epoch [16/50], Step [208/735], Loss: 0.4247\n",
      "Epoch [16/50], Step [209/735], Loss: 0.3933\n",
      "Epoch [16/50], Step [210/735], Loss: 1.9179\n",
      "Epoch [16/50], Step [211/735], Loss: 0.1584\n",
      "Epoch [16/50], Step [212/735], Loss: 0.3818\n",
      "Epoch [16/50], Step [213/735], Loss: 0.4979\n",
      "Epoch [16/50], Step [214/735], Loss: 0.1697\n",
      "Epoch [16/50], Step [215/735], Loss: 0.6893\n",
      "Epoch [16/50], Step [216/735], Loss: 1.1343\n",
      "Epoch [16/50], Step [217/735], Loss: 0.0566\n",
      "Epoch [16/50], Step [218/735], Loss: 0.6830\n",
      "Epoch [16/50], Step [219/735], Loss: 0.0901\n",
      "Epoch [16/50], Step [220/735], Loss: 0.5251\n",
      "Epoch [16/50], Step [221/735], Loss: 0.9245\n",
      "Epoch [16/50], Step [222/735], Loss: 0.1445\n",
      "Epoch [16/50], Step [223/735], Loss: 0.1460\n",
      "Epoch [16/50], Step [224/735], Loss: 0.2206\n",
      "Epoch [16/50], Step [225/735], Loss: 0.4572\n",
      "Epoch [16/50], Step [226/735], Loss: 0.3840\n",
      "Epoch [16/50], Step [227/735], Loss: 0.4902\n",
      "Epoch [16/50], Step [228/735], Loss: 0.4901\n",
      "Epoch [16/50], Step [229/735], Loss: 0.3318\n",
      "Epoch [16/50], Step [230/735], Loss: 0.1671\n",
      "Epoch [16/50], Step [231/735], Loss: 0.2292\n",
      "Epoch [16/50], Step [232/735], Loss: 0.2505\n",
      "Epoch [16/50], Step [233/735], Loss: 0.3808\n",
      "Epoch [16/50], Step [234/735], Loss: 0.3976\n",
      "Epoch [16/50], Step [235/735], Loss: 0.3349\n",
      "Epoch [16/50], Step [236/735], Loss: 4.4204\n",
      "Epoch [16/50], Step [237/735], Loss: 0.1979\n",
      "Epoch [16/50], Step [238/735], Loss: 0.5960\n",
      "Epoch [16/50], Step [239/735], Loss: 1.1967\n",
      "Epoch [16/50], Step [240/735], Loss: 0.8569\n",
      "Epoch [16/50], Step [241/735], Loss: 0.1999\n",
      "Epoch [16/50], Step [242/735], Loss: 0.2349\n",
      "Epoch [16/50], Step [243/735], Loss: 0.6302\n",
      "Epoch [16/50], Step [244/735], Loss: 0.6857\n",
      "Epoch [16/50], Step [245/735], Loss: 0.3154\n",
      "Epoch [16/50], Step [246/735], Loss: 0.2032\n",
      "Epoch [16/50], Step [247/735], Loss: 0.3783\n",
      "Epoch [16/50], Step [248/735], Loss: 0.8992\n",
      "Epoch [16/50], Step [249/735], Loss: 0.2337\n",
      "Epoch [16/50], Step [250/735], Loss: 0.9646\n",
      "Epoch [16/50], Step [251/735], Loss: 0.3516\n",
      "Epoch [16/50], Step [252/735], Loss: 0.3166\n",
      "Epoch [16/50], Step [253/735], Loss: 0.3274\n",
      "Epoch [16/50], Step [254/735], Loss: 0.2216\n",
      "Epoch [16/50], Step [255/735], Loss: 0.2034\n",
      "Epoch [16/50], Step [256/735], Loss: 0.5481\n",
      "Epoch [16/50], Step [257/735], Loss: 0.2266\n",
      "Epoch [16/50], Step [258/735], Loss: 0.2545\n",
      "Epoch [16/50], Step [259/735], Loss: 0.4249\n",
      "Epoch [16/50], Step [260/735], Loss: 0.6999\n",
      "Epoch [16/50], Step [261/735], Loss: 0.1591\n",
      "Epoch [16/50], Step [262/735], Loss: 0.3272\n",
      "Epoch [16/50], Step [263/735], Loss: 1.1704\n",
      "Epoch [16/50], Step [264/735], Loss: 0.8696\n",
      "Epoch [16/50], Step [265/735], Loss: 0.1601\n",
      "Epoch [16/50], Step [266/735], Loss: 2.0547\n",
      "Epoch [16/50], Step [267/735], Loss: 0.5867\n",
      "Epoch [16/50], Step [268/735], Loss: 0.3095\n",
      "Epoch [16/50], Step [269/735], Loss: 0.6538\n",
      "Epoch [16/50], Step [270/735], Loss: 0.1362\n",
      "Epoch [16/50], Step [271/735], Loss: 1.0319\n",
      "Epoch [16/50], Step [272/735], Loss: 0.3861\n",
      "Epoch [16/50], Step [273/735], Loss: 1.4792\n",
      "Epoch [16/50], Step [274/735], Loss: 1.0805\n",
      "Epoch [16/50], Step [275/735], Loss: 0.1024\n",
      "Epoch [16/50], Step [276/735], Loss: 0.3998\n",
      "Epoch [16/50], Step [277/735], Loss: 0.3537\n",
      "Epoch [16/50], Step [278/735], Loss: 0.2881\n",
      "Epoch [16/50], Step [279/735], Loss: 0.6295\n",
      "Epoch [16/50], Step [280/735], Loss: 0.1845\n",
      "Epoch [16/50], Step [281/735], Loss: 0.5433\n",
      "Epoch [16/50], Step [282/735], Loss: 0.2705\n",
      "Epoch [16/50], Step [283/735], Loss: 0.4533\n",
      "Epoch [16/50], Step [284/735], Loss: 0.4561\n",
      "Epoch [16/50], Step [285/735], Loss: 0.0632\n",
      "Epoch [16/50], Step [286/735], Loss: 0.1285\n",
      "Epoch [16/50], Step [287/735], Loss: 0.2060\n",
      "Epoch [16/50], Step [288/735], Loss: 0.2273\n",
      "Epoch [16/50], Step [289/735], Loss: 0.4296\n",
      "Epoch [16/50], Step [290/735], Loss: 0.2760\n",
      "Epoch [16/50], Step [291/735], Loss: 1.6688\n",
      "Epoch [16/50], Step [292/735], Loss: 1.6018\n",
      "Epoch [16/50], Step [293/735], Loss: 0.1134\n",
      "Epoch [16/50], Step [294/735], Loss: 0.7546\n",
      "Epoch [16/50], Step [295/735], Loss: 0.7200\n",
      "Epoch [16/50], Step [296/735], Loss: 0.2495\n",
      "Epoch [16/50], Step [297/735], Loss: 0.8660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Step [298/735], Loss: 0.1232\n",
      "Epoch [16/50], Step [299/735], Loss: 0.2506\n",
      "Epoch [16/50], Step [300/735], Loss: 0.2103\n",
      "Epoch [16/50], Step [301/735], Loss: 0.1869\n",
      "Epoch [16/50], Step [302/735], Loss: 0.1126\n",
      "Epoch [16/50], Step [303/735], Loss: 0.3634\n",
      "Epoch [16/50], Step [304/735], Loss: 0.9791\n",
      "Epoch [16/50], Step [305/735], Loss: 0.9321\n",
      "Epoch [16/50], Step [306/735], Loss: 0.2229\n",
      "Epoch [16/50], Step [307/735], Loss: 0.3110\n",
      "Epoch [16/50], Step [308/735], Loss: 0.8661\n",
      "Epoch [16/50], Step [309/735], Loss: 0.7211\n",
      "Epoch [16/50], Step [310/735], Loss: 0.6209\n",
      "Epoch [16/50], Step [311/735], Loss: 0.6763\n",
      "Epoch [16/50], Step [312/735], Loss: 0.0777\n",
      "Epoch [16/50], Step [313/735], Loss: 0.7800\n",
      "Epoch [16/50], Step [314/735], Loss: 0.2654\n",
      "Epoch [16/50], Step [315/735], Loss: 0.0798\n",
      "Epoch [16/50], Step [316/735], Loss: 0.2536\n",
      "Epoch [16/50], Step [317/735], Loss: 0.2394\n",
      "Epoch [16/50], Step [318/735], Loss: 0.1559\n",
      "Epoch [16/50], Step [319/735], Loss: 0.0855\n",
      "Epoch [16/50], Step [320/735], Loss: 0.4971\n",
      "Epoch [16/50], Step [321/735], Loss: 0.4193\n",
      "Epoch [16/50], Step [322/735], Loss: 0.5883\n",
      "Epoch [16/50], Step [323/735], Loss: 1.0933\n",
      "Epoch [16/50], Step [324/735], Loss: 1.3174\n",
      "Epoch [16/50], Step [325/735], Loss: 0.4912\n",
      "Epoch [16/50], Step [326/735], Loss: 0.2509\n",
      "Epoch [16/50], Step [327/735], Loss: 0.3627\n",
      "Epoch [16/50], Step [328/735], Loss: 0.8300\n",
      "Epoch [16/50], Step [329/735], Loss: 0.4116\n",
      "Epoch [16/50], Step [330/735], Loss: 0.7584\n",
      "Epoch [16/50], Step [331/735], Loss: 0.5394\n",
      "Epoch [16/50], Step [332/735], Loss: 0.2442\n",
      "Epoch [16/50], Step [333/735], Loss: 0.1403\n",
      "Epoch [16/50], Step [334/735], Loss: 1.0931\n",
      "Epoch [16/50], Step [335/735], Loss: 0.1204\n",
      "Epoch [16/50], Step [336/735], Loss: 0.5872\n",
      "Epoch [16/50], Step [337/735], Loss: 0.1918\n",
      "Epoch [16/50], Step [338/735], Loss: 2.0344\n",
      "Epoch [16/50], Step [339/735], Loss: 0.7419\n",
      "Epoch [16/50], Step [340/735], Loss: 0.3047\n",
      "Epoch [16/50], Step [341/735], Loss: 0.2658\n",
      "Epoch [16/50], Step [342/735], Loss: 0.3501\n",
      "Epoch [16/50], Step [343/735], Loss: 0.7469\n",
      "Epoch [16/50], Step [344/735], Loss: 0.4548\n",
      "Epoch [16/50], Step [345/735], Loss: 0.3480\n",
      "Epoch [16/50], Step [346/735], Loss: 0.9855\n",
      "Epoch [16/50], Step [347/735], Loss: 0.3776\n",
      "Epoch [16/50], Step [348/735], Loss: 0.2400\n",
      "Epoch [16/50], Step [349/735], Loss: 0.2312\n",
      "Epoch [16/50], Step [350/735], Loss: 0.4686\n",
      "Epoch [16/50], Step [351/735], Loss: 0.5068\n",
      "Epoch [16/50], Step [352/735], Loss: 0.6026\n",
      "Epoch [16/50], Step [353/735], Loss: 0.1561\n",
      "Epoch [16/50], Step [354/735], Loss: 0.1277\n",
      "Epoch [16/50], Step [355/735], Loss: 0.2534\n",
      "Epoch [16/50], Step [356/735], Loss: 0.1946\n",
      "Epoch [16/50], Step [357/735], Loss: 0.4337\n",
      "Epoch [16/50], Step [358/735], Loss: 0.0959\n",
      "Epoch [16/50], Step [359/735], Loss: 0.1667\n",
      "Epoch [16/50], Step [360/735], Loss: 1.7241\n",
      "Epoch [16/50], Step [361/735], Loss: 0.2150\n",
      "Epoch [16/50], Step [362/735], Loss: 0.1071\n",
      "Epoch [16/50], Step [363/735], Loss: 1.2278\n",
      "Epoch [16/50], Step [364/735], Loss: 1.4938\n",
      "Epoch [16/50], Step [365/735], Loss: 0.2822\n",
      "Epoch [16/50], Step [366/735], Loss: 0.2557\n",
      "Epoch [16/50], Step [367/735], Loss: 0.6146\n",
      "Epoch [16/50], Step [368/735], Loss: 0.2740\n",
      "Epoch [16/50], Step [369/735], Loss: 0.4220\n",
      "Epoch [16/50], Step [370/735], Loss: 0.4600\n",
      "Epoch [16/50], Step [371/735], Loss: 0.3222\n",
      "Epoch [16/50], Step [372/735], Loss: 0.4275\n",
      "Epoch [16/50], Step [373/735], Loss: 0.3198\n",
      "Epoch [16/50], Step [374/735], Loss: 0.1516\n",
      "Epoch [16/50], Step [375/735], Loss: 0.2501\n",
      "Epoch [16/50], Step [376/735], Loss: 0.2498\n",
      "Epoch [16/50], Step [377/735], Loss: 1.0506\n",
      "Epoch [16/50], Step [378/735], Loss: 4.9685\n",
      "Epoch [16/50], Step [379/735], Loss: 0.7522\n",
      "Epoch [16/50], Step [380/735], Loss: 0.1050\n",
      "Epoch [16/50], Step [381/735], Loss: 0.7657\n",
      "Epoch [16/50], Step [382/735], Loss: 0.9971\n",
      "Epoch [16/50], Step [383/735], Loss: 0.6514\n",
      "Epoch [16/50], Step [384/735], Loss: 0.3807\n",
      "Epoch [16/50], Step [385/735], Loss: 0.7491\n",
      "Epoch [16/50], Step [386/735], Loss: 0.1809\n",
      "Epoch [16/50], Step [387/735], Loss: 0.9684\n",
      "Epoch [16/50], Step [388/735], Loss: 0.1266\n",
      "Epoch [16/50], Step [389/735], Loss: 0.5773\n",
      "Epoch [16/50], Step [390/735], Loss: 1.2460\n",
      "Epoch [16/50], Step [391/735], Loss: 0.1859\n",
      "Epoch [16/50], Step [392/735], Loss: 0.8454\n",
      "Epoch [16/50], Step [393/735], Loss: 0.3834\n",
      "Epoch [16/50], Step [394/735], Loss: 0.1946\n",
      "Epoch [16/50], Step [395/735], Loss: 0.1448\n",
      "Epoch [16/50], Step [396/735], Loss: 0.2581\n",
      "Epoch [16/50], Step [397/735], Loss: 0.1291\n",
      "Epoch [16/50], Step [398/735], Loss: 0.1069\n",
      "Epoch [16/50], Step [399/735], Loss: 0.2890\n",
      "Epoch [16/50], Step [400/735], Loss: 0.4218\n",
      "Epoch [16/50], Step [401/735], Loss: 0.2352\n",
      "Epoch [16/50], Step [402/735], Loss: 0.3937\n",
      "Epoch [16/50], Step [403/735], Loss: 0.1316\n",
      "Epoch [16/50], Step [404/735], Loss: 0.4636\n",
      "Epoch [16/50], Step [405/735], Loss: 0.1462\n",
      "Epoch [16/50], Step [406/735], Loss: 0.4647\n",
      "Epoch [16/50], Step [407/735], Loss: 0.4553\n",
      "Epoch [16/50], Step [408/735], Loss: 1.1405\n",
      "Epoch [16/50], Step [409/735], Loss: 0.2761\n",
      "Epoch [16/50], Step [410/735], Loss: 0.2341\n",
      "Epoch [16/50], Step [411/735], Loss: 1.0377\n",
      "Epoch [16/50], Step [412/735], Loss: 0.0762\n",
      "Epoch [16/50], Step [413/735], Loss: 0.0603\n",
      "Epoch [16/50], Step [414/735], Loss: 0.6148\n",
      "Epoch [16/50], Step [415/735], Loss: 0.6853\n",
      "Epoch [16/50], Step [416/735], Loss: 0.1376\n",
      "Epoch [16/50], Step [417/735], Loss: 0.2439\n",
      "Epoch [16/50], Step [418/735], Loss: 1.0104\n",
      "Epoch [16/50], Step [419/735], Loss: 0.7590\n",
      "Epoch [16/50], Step [420/735], Loss: 0.4475\n",
      "Epoch [16/50], Step [421/735], Loss: 0.5277\n",
      "Epoch [16/50], Step [422/735], Loss: 0.3157\n",
      "Epoch [16/50], Step [423/735], Loss: 0.2827\n",
      "Epoch [16/50], Step [424/735], Loss: 0.1323\n",
      "Epoch [16/50], Step [425/735], Loss: 0.4655\n",
      "Epoch [16/50], Step [426/735], Loss: 0.0774\n",
      "Epoch [16/50], Step [427/735], Loss: 0.3910\n",
      "Epoch [16/50], Step [428/735], Loss: 0.5955\n",
      "Epoch [16/50], Step [429/735], Loss: 0.1635\n",
      "Epoch [16/50], Step [430/735], Loss: 0.1759\n",
      "Epoch [16/50], Step [431/735], Loss: 0.1324\n",
      "Epoch [16/50], Step [432/735], Loss: 0.3218\n",
      "Epoch [16/50], Step [433/735], Loss: 0.1654\n",
      "Epoch [16/50], Step [434/735], Loss: 0.0513\n",
      "Epoch [16/50], Step [435/735], Loss: 0.2715\n",
      "Epoch [16/50], Step [436/735], Loss: 0.5116\n",
      "Epoch [16/50], Step [437/735], Loss: 0.1950\n",
      "Epoch [16/50], Step [438/735], Loss: 0.4896\n",
      "Epoch [16/50], Step [439/735], Loss: 0.6940\n",
      "Epoch [16/50], Step [440/735], Loss: 0.1269\n",
      "Epoch [16/50], Step [441/735], Loss: 4.5587\n",
      "Epoch [16/50], Step [442/735], Loss: 0.2985\n",
      "Epoch [16/50], Step [443/735], Loss: 0.4581\n",
      "Epoch [16/50], Step [444/735], Loss: 0.1937\n",
      "Epoch [16/50], Step [445/735], Loss: 0.8476\n",
      "Epoch [16/50], Step [446/735], Loss: 0.2331\n",
      "Epoch [16/50], Step [447/735], Loss: 0.2073\n",
      "Epoch [16/50], Step [448/735], Loss: 0.4305\n",
      "Epoch [16/50], Step [449/735], Loss: 0.2759\n",
      "Epoch [16/50], Step [450/735], Loss: 0.2224\n",
      "Epoch [16/50], Step [451/735], Loss: 0.1583\n",
      "Epoch [16/50], Step [452/735], Loss: 0.3070\n",
      "Epoch [16/50], Step [453/735], Loss: 0.3567\n",
      "Epoch [16/50], Step [454/735], Loss: 0.5054\n",
      "Epoch [16/50], Step [455/735], Loss: 0.9983\n",
      "Epoch [16/50], Step [456/735], Loss: 0.2313\n",
      "Epoch [16/50], Step [457/735], Loss: 0.5983\n",
      "Epoch [16/50], Step [458/735], Loss: 0.0853\n",
      "Epoch [16/50], Step [459/735], Loss: 0.5048\n",
      "Epoch [16/50], Step [460/735], Loss: 0.1250\n",
      "Epoch [16/50], Step [461/735], Loss: 0.3379\n",
      "Epoch [16/50], Step [462/735], Loss: 0.1537\n",
      "Epoch [16/50], Step [463/735], Loss: 1.3485\n",
      "Epoch [16/50], Step [464/735], Loss: 0.5712\n",
      "Epoch [16/50], Step [465/735], Loss: 0.0791\n",
      "Epoch [16/50], Step [466/735], Loss: 0.1011\n",
      "Epoch [16/50], Step [467/735], Loss: 0.2357\n",
      "Epoch [16/50], Step [468/735], Loss: 0.6070\n",
      "Epoch [16/50], Step [469/735], Loss: 0.2681\n",
      "Epoch [16/50], Step [470/735], Loss: 0.4580\n",
      "Epoch [16/50], Step [471/735], Loss: 2.2076\n",
      "Epoch [16/50], Step [472/735], Loss: 0.1717\n",
      "Epoch [16/50], Step [473/735], Loss: 0.0964\n",
      "Epoch [16/50], Step [474/735], Loss: 0.2129\n",
      "Epoch [16/50], Step [475/735], Loss: 0.1567\n",
      "Epoch [16/50], Step [476/735], Loss: 0.5901\n",
      "Epoch [16/50], Step [477/735], Loss: 0.1425\n",
      "Epoch [16/50], Step [478/735], Loss: 0.3559\n",
      "Epoch [16/50], Step [479/735], Loss: 0.1155\n",
      "Epoch [16/50], Step [480/735], Loss: 0.2568\n",
      "Epoch [16/50], Step [481/735], Loss: 0.3441\n",
      "Epoch [16/50], Step [482/735], Loss: 0.1015\n",
      "Epoch [16/50], Step [483/735], Loss: 1.6793\n",
      "Epoch [16/50], Step [484/735], Loss: 0.2431\n",
      "Epoch [16/50], Step [485/735], Loss: 0.0949\n",
      "Epoch [16/50], Step [486/735], Loss: 0.4394\n",
      "Epoch [16/50], Step [487/735], Loss: 0.2102\n",
      "Epoch [16/50], Step [488/735], Loss: 1.0616\n",
      "Epoch [16/50], Step [489/735], Loss: 0.4975\n",
      "Epoch [16/50], Step [490/735], Loss: 0.2254\n",
      "Epoch [16/50], Step [491/735], Loss: 0.3661\n",
      "Epoch [16/50], Step [492/735], Loss: 0.9090\n",
      "Epoch [16/50], Step [493/735], Loss: 0.3834\n",
      "Epoch [16/50], Step [494/735], Loss: 0.3358\n",
      "Epoch [16/50], Step [495/735], Loss: 0.5073\n",
      "Epoch [16/50], Step [496/735], Loss: 0.3086\n",
      "Epoch [16/50], Step [497/735], Loss: 0.0871\n",
      "Epoch [16/50], Step [498/735], Loss: 0.0971\n",
      "Epoch [16/50], Step [499/735], Loss: 0.2926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Step [500/735], Loss: 0.3756\n",
      "Epoch [16/50], Step [501/735], Loss: 0.4308\n",
      "Epoch [16/50], Step [502/735], Loss: 0.8058\n",
      "Epoch [16/50], Step [503/735], Loss: 0.5002\n",
      "Epoch [16/50], Step [504/735], Loss: 0.2848\n",
      "Epoch [16/50], Step [505/735], Loss: 0.1616\n",
      "Epoch [16/50], Step [506/735], Loss: 0.1656\n",
      "Epoch [16/50], Step [507/735], Loss: 0.1409\n",
      "Epoch [16/50], Step [508/735], Loss: 0.1192\n",
      "Epoch [16/50], Step [509/735], Loss: 1.6078\n",
      "Epoch [16/50], Step [510/735], Loss: 0.5076\n",
      "Epoch [16/50], Step [511/735], Loss: 0.1842\n",
      "Epoch [16/50], Step [512/735], Loss: 0.6299\n",
      "Epoch [16/50], Step [513/735], Loss: 0.2865\n",
      "Epoch [16/50], Step [514/735], Loss: 0.3466\n",
      "Epoch [16/50], Step [515/735], Loss: 0.3561\n",
      "Epoch [16/50], Step [516/735], Loss: 0.3079\n",
      "Epoch [16/50], Step [517/735], Loss: 0.4190\n",
      "Epoch [16/50], Step [518/735], Loss: 0.1633\n",
      "Epoch [16/50], Step [519/735], Loss: 0.1132\n",
      "Epoch [16/50], Step [520/735], Loss: 0.2965\n",
      "Epoch [16/50], Step [521/735], Loss: 0.2802\n",
      "Epoch [16/50], Step [522/735], Loss: 0.7904\n",
      "Epoch [16/50], Step [523/735], Loss: 0.2586\n",
      "Epoch [16/50], Step [524/735], Loss: 0.4488\n",
      "Epoch [16/50], Step [525/735], Loss: 0.8299\n",
      "Epoch [16/50], Step [526/735], Loss: 0.1022\n",
      "Epoch [16/50], Step [527/735], Loss: 0.4640\n",
      "Epoch [16/50], Step [528/735], Loss: 0.6840\n",
      "Epoch [16/50], Step [529/735], Loss: 0.2550\n",
      "Epoch [16/50], Step [530/735], Loss: 0.2322\n",
      "Epoch [16/50], Step [531/735], Loss: 0.3577\n",
      "Epoch [16/50], Step [532/735], Loss: 0.3541\n",
      "Epoch [16/50], Step [533/735], Loss: 0.4649\n",
      "Epoch [16/50], Step [534/735], Loss: 0.2566\n",
      "Epoch [16/50], Step [535/735], Loss: 0.2319\n",
      "Epoch [16/50], Step [536/735], Loss: 0.5377\n",
      "Epoch [16/50], Step [537/735], Loss: 0.5467\n",
      "Epoch [16/50], Step [538/735], Loss: 0.4119\n",
      "Epoch [16/50], Step [539/735], Loss: 0.2295\n",
      "Epoch [16/50], Step [540/735], Loss: 0.2749\n",
      "Epoch [16/50], Step [541/735], Loss: 0.4326\n",
      "Epoch [16/50], Step [542/735], Loss: 0.3010\n",
      "Epoch [16/50], Step [543/735], Loss: 0.3195\n",
      "Epoch [16/50], Step [544/735], Loss: 0.2173\n",
      "Epoch [16/50], Step [545/735], Loss: 0.7975\n",
      "Epoch [16/50], Step [546/735], Loss: 0.1944\n",
      "Epoch [16/50], Step [547/735], Loss: 1.1601\n",
      "Epoch [16/50], Step [548/735], Loss: 0.2249\n",
      "Epoch [16/50], Step [549/735], Loss: 0.1649\n",
      "Epoch [16/50], Step [550/735], Loss: 0.0754\n",
      "Epoch [16/50], Step [551/735], Loss: 0.3055\n",
      "Epoch [16/50], Step [552/735], Loss: 0.4054\n",
      "Epoch [16/50], Step [553/735], Loss: 0.1865\n",
      "Epoch [16/50], Step [554/735], Loss: 0.3043\n",
      "Epoch [16/50], Step [555/735], Loss: 1.1967\n",
      "Epoch [16/50], Step [556/735], Loss: 0.3205\n",
      "Epoch [16/50], Step [557/735], Loss: 0.4589\n",
      "Epoch [16/50], Step [558/735], Loss: 0.2496\n",
      "Epoch [16/50], Step [559/735], Loss: 0.2317\n",
      "Epoch [16/50], Step [560/735], Loss: 0.2119\n",
      "Epoch [16/50], Step [561/735], Loss: 0.1622\n",
      "Epoch [16/50], Step [562/735], Loss: 0.3602\n",
      "Epoch [16/50], Step [563/735], Loss: 0.2700\n",
      "Epoch [16/50], Step [564/735], Loss: 0.4478\n",
      "Epoch [16/50], Step [565/735], Loss: 0.3993\n",
      "Epoch [16/50], Step [566/735], Loss: 0.2865\n",
      "Epoch [16/50], Step [567/735], Loss: 0.2556\n",
      "Epoch [16/50], Step [568/735], Loss: 0.5166\n",
      "Epoch [16/50], Step [569/735], Loss: 0.6521\n",
      "Epoch [16/50], Step [570/735], Loss: 0.1218\n",
      "Epoch [16/50], Step [571/735], Loss: 1.1421\n",
      "Epoch [16/50], Step [572/735], Loss: 0.0957\n",
      "Epoch [16/50], Step [573/735], Loss: 0.1728\n",
      "Epoch [16/50], Step [574/735], Loss: 0.1964\n",
      "Epoch [16/50], Step [575/735], Loss: 0.1122\n",
      "Epoch [16/50], Step [576/735], Loss: 0.0702\n",
      "Epoch [16/50], Step [577/735], Loss: 0.1102\n",
      "Epoch [16/50], Step [578/735], Loss: 0.1907\n",
      "Epoch [16/50], Step [579/735], Loss: 0.1625\n",
      "Epoch [16/50], Step [580/735], Loss: 2.1953\n",
      "Epoch [16/50], Step [581/735], Loss: 0.7608\n",
      "Epoch [16/50], Step [582/735], Loss: 0.0917\n",
      "Epoch [16/50], Step [583/735], Loss: 0.0493\n",
      "Epoch [16/50], Step [584/735], Loss: 0.5162\n",
      "Epoch [16/50], Step [585/735], Loss: 0.1431\n",
      "Epoch [16/50], Step [586/735], Loss: 0.1543\n",
      "Epoch [16/50], Step [587/735], Loss: 0.1460\n",
      "Epoch [16/50], Step [588/735], Loss: 0.2293\n",
      "Epoch [16/50], Step [589/735], Loss: 0.3022\n",
      "Epoch [16/50], Step [590/735], Loss: 0.2824\n",
      "Epoch [16/50], Step [591/735], Loss: 1.0417\n",
      "Epoch [16/50], Step [592/735], Loss: 0.1721\n",
      "Epoch [16/50], Step [593/735], Loss: 0.5737\n",
      "Epoch [16/50], Step [594/735], Loss: 0.1571\n",
      "Epoch [16/50], Step [595/735], Loss: 0.1031\n",
      "Epoch [16/50], Step [596/735], Loss: 1.3701\n",
      "Epoch [16/50], Step [597/735], Loss: 0.0922\n",
      "Epoch [16/50], Step [598/735], Loss: 0.1074\n",
      "Epoch [16/50], Step [599/735], Loss: 1.0553\n",
      "Epoch [16/50], Step [600/735], Loss: 0.1690\n",
      "Epoch [16/50], Step [601/735], Loss: 0.1150\n",
      "Epoch [16/50], Step [602/735], Loss: 0.2862\n",
      "Epoch [16/50], Step [603/735], Loss: 0.6012\n",
      "Epoch [16/50], Step [604/735], Loss: 0.8824\n",
      "Epoch [16/50], Step [605/735], Loss: 0.2966\n",
      "Epoch [16/50], Step [606/735], Loss: 0.2284\n",
      "Epoch [16/50], Step [607/735], Loss: 0.6117\n",
      "Epoch [16/50], Step [608/735], Loss: 0.0587\n",
      "Epoch [16/50], Step [609/735], Loss: 1.0159\n",
      "Epoch [16/50], Step [610/735], Loss: 0.1775\n",
      "Epoch [16/50], Step [611/735], Loss: 0.5361\n",
      "Epoch [16/50], Step [612/735], Loss: 0.5910\n",
      "Epoch [16/50], Step [613/735], Loss: 0.2101\n",
      "Epoch [16/50], Step [614/735], Loss: 0.3171\n",
      "Epoch [16/50], Step [615/735], Loss: 0.5906\n",
      "Epoch [16/50], Step [616/735], Loss: 0.1286\n",
      "Epoch [16/50], Step [617/735], Loss: 0.3810\n",
      "Epoch [16/50], Step [618/735], Loss: 0.0677\n",
      "Epoch [16/50], Step [619/735], Loss: 0.0793\n",
      "Epoch [16/50], Step [620/735], Loss: 0.2301\n",
      "Epoch [16/50], Step [621/735], Loss: 0.2836\n",
      "Epoch [16/50], Step [622/735], Loss: 0.7535\n",
      "Epoch [16/50], Step [623/735], Loss: 2.1727\n",
      "Epoch [16/50], Step [624/735], Loss: 0.6636\n",
      "Epoch [16/50], Step [625/735], Loss: 0.7644\n",
      "Epoch [16/50], Step [626/735], Loss: 0.2860\n",
      "Epoch [16/50], Step [627/735], Loss: 0.1842\n",
      "Epoch [16/50], Step [628/735], Loss: 0.3414\n",
      "Epoch [16/50], Step [629/735], Loss: 0.1994\n",
      "Epoch [16/50], Step [630/735], Loss: 0.2030\n",
      "Epoch [16/50], Step [631/735], Loss: 0.4877\n",
      "Epoch [16/50], Step [632/735], Loss: 0.2792\n",
      "Epoch [16/50], Step [633/735], Loss: 2.2590\n",
      "Epoch [16/50], Step [634/735], Loss: 0.2077\n",
      "Epoch [16/50], Step [635/735], Loss: 0.2505\n",
      "Epoch [16/50], Step [636/735], Loss: 0.1589\n",
      "Epoch [16/50], Step [637/735], Loss: 0.5460\n",
      "Epoch [16/50], Step [638/735], Loss: 0.5529\n",
      "Epoch [16/50], Step [639/735], Loss: 0.3722\n",
      "Epoch [16/50], Step [640/735], Loss: 0.2516\n",
      "Epoch [16/50], Step [641/735], Loss: 0.2791\n",
      "Epoch [16/50], Step [642/735], Loss: 0.5233\n",
      "Epoch [16/50], Step [643/735], Loss: 0.4767\n",
      "Epoch [16/50], Step [644/735], Loss: 0.6087\n",
      "Epoch [16/50], Step [645/735], Loss: 0.2451\n",
      "Epoch [16/50], Step [646/735], Loss: 0.1853\n",
      "Epoch [16/50], Step [647/735], Loss: 0.7814\n",
      "Epoch [16/50], Step [648/735], Loss: 0.8108\n",
      "Epoch [16/50], Step [649/735], Loss: 0.6704\n",
      "Epoch [16/50], Step [650/735], Loss: 0.1429\n",
      "Epoch [16/50], Step [651/735], Loss: 0.4262\n",
      "Epoch [16/50], Step [652/735], Loss: 0.1117\n",
      "Epoch [16/50], Step [653/735], Loss: 0.9322\n",
      "Epoch [16/50], Step [654/735], Loss: 0.4608\n",
      "Epoch [16/50], Step [655/735], Loss: 0.2198\n",
      "Epoch [16/50], Step [656/735], Loss: 0.2048\n",
      "Epoch [16/50], Step [657/735], Loss: 0.7477\n",
      "Epoch [16/50], Step [658/735], Loss: 0.5433\n",
      "Epoch [16/50], Step [659/735], Loss: 0.3926\n",
      "Epoch [16/50], Step [660/735], Loss: 0.1712\n",
      "Epoch [16/50], Step [661/735], Loss: 0.2530\n",
      "Epoch [16/50], Step [662/735], Loss: 0.2071\n",
      "Epoch [16/50], Step [663/735], Loss: 1.0628\n",
      "Epoch [16/50], Step [664/735], Loss: 0.6545\n",
      "Epoch [16/50], Step [665/735], Loss: 0.3755\n",
      "Epoch [16/50], Step [666/735], Loss: 0.1978\n",
      "Epoch [16/50], Step [667/735], Loss: 0.4506\n",
      "Epoch [16/50], Step [668/735], Loss: 0.3240\n",
      "Epoch [16/50], Step [669/735], Loss: 0.1721\n",
      "Epoch [16/50], Step [670/735], Loss: 0.1760\n",
      "Epoch [16/50], Step [671/735], Loss: 0.3667\n",
      "Epoch [16/50], Step [672/735], Loss: 0.1192\n",
      "Epoch [16/50], Step [673/735], Loss: 0.2603\n",
      "Epoch [16/50], Step [674/735], Loss: 1.7732\n",
      "Epoch [16/50], Step [675/735], Loss: 0.8775\n",
      "Epoch [16/50], Step [676/735], Loss: 0.2981\n",
      "Epoch [16/50], Step [677/735], Loss: 0.3424\n",
      "Epoch [16/50], Step [678/735], Loss: 1.0343\n",
      "Epoch [16/50], Step [679/735], Loss: 0.7707\n",
      "Epoch [16/50], Step [680/735], Loss: 1.0889\n",
      "Epoch [16/50], Step [681/735], Loss: 1.4533\n",
      "Epoch [16/50], Step [682/735], Loss: 0.3697\n",
      "Epoch [16/50], Step [683/735], Loss: 0.4116\n",
      "Epoch [16/50], Step [684/735], Loss: 1.1127\n",
      "Epoch [16/50], Step [685/735], Loss: 0.2731\n",
      "Epoch [16/50], Step [686/735], Loss: 0.2831\n",
      "Epoch [16/50], Step [687/735], Loss: 0.1420\n",
      "Epoch [16/50], Step [688/735], Loss: 0.0567\n",
      "Epoch [16/50], Step [689/735], Loss: 1.0279\n",
      "Epoch [16/50], Step [690/735], Loss: 0.2144\n",
      "Epoch [16/50], Step [691/735], Loss: 0.5297\n",
      "Epoch [16/50], Step [692/735], Loss: 0.1012\n",
      "Epoch [16/50], Step [693/735], Loss: 0.3345\n",
      "Epoch [16/50], Step [694/735], Loss: 0.6054\n",
      "Epoch [16/50], Step [695/735], Loss: 0.1302\n",
      "Epoch [16/50], Step [696/735], Loss: 0.3228\n",
      "Epoch [16/50], Step [697/735], Loss: 0.3130\n",
      "Epoch [16/50], Step [698/735], Loss: 0.8619\n",
      "Epoch [16/50], Step [699/735], Loss: 0.9275\n",
      "Epoch [16/50], Step [700/735], Loss: 0.1618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Step [701/735], Loss: 0.1778\n",
      "Epoch [16/50], Step [702/735], Loss: 0.3729\n",
      "Epoch [16/50], Step [703/735], Loss: 0.1008\n",
      "Epoch [16/50], Step [704/735], Loss: 0.1817\n",
      "Epoch [16/50], Step [705/735], Loss: 0.1618\n",
      "Epoch [16/50], Step [706/735], Loss: 0.4916\n",
      "Epoch [16/50], Step [707/735], Loss: 0.9842\n",
      "Epoch [16/50], Step [708/735], Loss: 0.1886\n",
      "Epoch [16/50], Step [709/735], Loss: 0.2638\n",
      "Epoch [16/50], Step [710/735], Loss: 0.7446\n",
      "Epoch [16/50], Step [711/735], Loss: 0.4590\n",
      "Epoch [16/50], Step [712/735], Loss: 0.3750\n",
      "Epoch [16/50], Step [713/735], Loss: 1.0629\n",
      "Epoch [16/50], Step [714/735], Loss: 0.4525\n",
      "Epoch [16/50], Step [715/735], Loss: 0.1312\n",
      "Epoch [16/50], Step [716/735], Loss: 0.6665\n",
      "Epoch [16/50], Step [717/735], Loss: 0.1826\n",
      "Epoch [16/50], Step [718/735], Loss: 2.1642\n",
      "Epoch [16/50], Step [719/735], Loss: 0.6464\n",
      "Epoch [16/50], Step [720/735], Loss: 0.6974\n",
      "Epoch [16/50], Step [721/735], Loss: 0.1156\n",
      "Epoch [16/50], Step [722/735], Loss: 0.2485\n",
      "Epoch [16/50], Step [723/735], Loss: 0.2759\n",
      "Epoch [16/50], Step [724/735], Loss: 1.5781\n",
      "Epoch [16/50], Step [725/735], Loss: 0.5810\n",
      "Epoch [16/50], Step [726/735], Loss: 0.1001\n",
      "Epoch [16/50], Step [727/735], Loss: 0.1221\n",
      "Epoch [16/50], Step [728/735], Loss: 5.1911\n",
      "Epoch [16/50], Step [729/735], Loss: 0.1411\n",
      "Epoch [16/50], Step [730/735], Loss: 0.3214\n",
      "Epoch [16/50], Step [731/735], Loss: 0.3020\n",
      "Epoch [16/50], Step [732/735], Loss: 0.6459\n",
      "Epoch [16/50], Step [733/735], Loss: 0.7800\n",
      "Epoch [16/50], Step [734/735], Loss: 0.1089\n",
      "Epoch [16/50], Step [735/735], Loss: 0.1083\n",
      "Epoch [17/50], Step [1/735], Loss: 0.2163\n",
      "Epoch [17/50], Step [2/735], Loss: 0.3090\n",
      "Epoch [17/50], Step [3/735], Loss: 0.3226\n",
      "Epoch [17/50], Step [4/735], Loss: 0.5021\n",
      "Epoch [17/50], Step [5/735], Loss: 1.3134\n",
      "Epoch [17/50], Step [6/735], Loss: 0.4819\n",
      "Epoch [17/50], Step [7/735], Loss: 0.3452\n",
      "Epoch [17/50], Step [8/735], Loss: 0.2650\n",
      "Epoch [17/50], Step [9/735], Loss: 0.2408\n",
      "Epoch [17/50], Step [10/735], Loss: 0.4808\n",
      "Epoch [17/50], Step [11/735], Loss: 0.1688\n",
      "Epoch [17/50], Step [12/735], Loss: 0.3009\n",
      "Epoch [17/50], Step [13/735], Loss: 1.8876\n",
      "Epoch [17/50], Step [14/735], Loss: 0.3022\n",
      "Epoch [17/50], Step [15/735], Loss: 1.4407\n",
      "Epoch [17/50], Step [16/735], Loss: 0.5215\n",
      "Epoch [17/50], Step [17/735], Loss: 0.3236\n",
      "Epoch [17/50], Step [18/735], Loss: 0.1785\n",
      "Epoch [17/50], Step [19/735], Loss: 0.2265\n",
      "Epoch [17/50], Step [20/735], Loss: 0.1568\n",
      "Epoch [17/50], Step [21/735], Loss: 0.2536\n",
      "Epoch [17/50], Step [22/735], Loss: 2.1449\n",
      "Epoch [17/50], Step [23/735], Loss: 1.2309\n",
      "Epoch [17/50], Step [24/735], Loss: 0.6321\n",
      "Epoch [17/50], Step [25/735], Loss: 0.6020\n",
      "Epoch [17/50], Step [26/735], Loss: 0.4624\n",
      "Epoch [17/50], Step [27/735], Loss: 0.2819\n",
      "Epoch [17/50], Step [28/735], Loss: 0.1448\n",
      "Epoch [17/50], Step [29/735], Loss: 0.1583\n",
      "Epoch [17/50], Step [30/735], Loss: 0.5123\n",
      "Epoch [17/50], Step [31/735], Loss: 0.3605\n",
      "Epoch [17/50], Step [32/735], Loss: 0.1804\n",
      "Epoch [17/50], Step [33/735], Loss: 0.3626\n",
      "Epoch [17/50], Step [34/735], Loss: 0.1527\n",
      "Epoch [17/50], Step [35/735], Loss: 1.8414\n",
      "Epoch [17/50], Step [36/735], Loss: 0.7585\n",
      "Epoch [17/50], Step [37/735], Loss: 0.2776\n",
      "Epoch [17/50], Step [38/735], Loss: 0.1266\n",
      "Epoch [17/50], Step [39/735], Loss: 0.5431\n",
      "Epoch [17/50], Step [40/735], Loss: 0.3173\n",
      "Epoch [17/50], Step [41/735], Loss: 0.8008\n",
      "Epoch [17/50], Step [42/735], Loss: 0.2078\n",
      "Epoch [17/50], Step [43/735], Loss: 0.0677\n",
      "Epoch [17/50], Step [44/735], Loss: 0.6820\n",
      "Epoch [17/50], Step [45/735], Loss: 0.3738\n",
      "Epoch [17/50], Step [46/735], Loss: 0.4817\n",
      "Epoch [17/50], Step [47/735], Loss: 0.8930\n",
      "Epoch [17/50], Step [48/735], Loss: 0.6207\n",
      "Epoch [17/50], Step [49/735], Loss: 0.3526\n",
      "Epoch [17/50], Step [50/735], Loss: 0.1913\n",
      "Epoch [17/50], Step [51/735], Loss: 0.4390\n",
      "Epoch [17/50], Step [52/735], Loss: 0.1375\n",
      "Epoch [17/50], Step [53/735], Loss: 0.2034\n",
      "Epoch [17/50], Step [54/735], Loss: 0.6247\n",
      "Epoch [17/50], Step [55/735], Loss: 1.3387\n",
      "Epoch [17/50], Step [56/735], Loss: 0.4671\n",
      "Epoch [17/50], Step [57/735], Loss: 0.3423\n",
      "Epoch [17/50], Step [58/735], Loss: 0.4483\n",
      "Epoch [17/50], Step [59/735], Loss: 0.1747\n",
      "Epoch [17/50], Step [60/735], Loss: 0.9936\n",
      "Epoch [17/50], Step [61/735], Loss: 0.2307\n",
      "Epoch [17/50], Step [62/735], Loss: 4.8034\n",
      "Epoch [17/50], Step [63/735], Loss: 0.5762\n",
      "Epoch [17/50], Step [64/735], Loss: 0.2839\n",
      "Epoch [17/50], Step [65/735], Loss: 0.3417\n",
      "Epoch [17/50], Step [66/735], Loss: 0.3754\n",
      "Epoch [17/50], Step [67/735], Loss: 1.7153\n",
      "Epoch [17/50], Step [68/735], Loss: 0.1758\n",
      "Epoch [17/50], Step [69/735], Loss: 0.5384\n",
      "Epoch [17/50], Step [70/735], Loss: 0.5341\n",
      "Epoch [17/50], Step [71/735], Loss: 0.7712\n",
      "Epoch [17/50], Step [72/735], Loss: 0.3951\n",
      "Epoch [17/50], Step [73/735], Loss: 0.3936\n",
      "Epoch [17/50], Step [74/735], Loss: 0.7371\n",
      "Epoch [17/50], Step [75/735], Loss: 0.4628\n",
      "Epoch [17/50], Step [76/735], Loss: 0.1331\n",
      "Epoch [17/50], Step [77/735], Loss: 0.1394\n",
      "Epoch [17/50], Step [78/735], Loss: 0.2432\n",
      "Epoch [17/50], Step [79/735], Loss: 0.3305\n",
      "Epoch [17/50], Step [80/735], Loss: 0.3357\n",
      "Epoch [17/50], Step [81/735], Loss: 0.1904\n",
      "Epoch [17/50], Step [82/735], Loss: 1.1191\n",
      "Epoch [17/50], Step [83/735], Loss: 0.3165\n",
      "Epoch [17/50], Step [84/735], Loss: 0.4655\n",
      "Epoch [17/50], Step [85/735], Loss: 0.2289\n",
      "Epoch [17/50], Step [86/735], Loss: 0.2755\n",
      "Epoch [17/50], Step [87/735], Loss: 0.1718\n",
      "Epoch [17/50], Step [88/735], Loss: 0.3115\n",
      "Epoch [17/50], Step [89/735], Loss: 0.6638\n",
      "Epoch [17/50], Step [90/735], Loss: 1.0903\n",
      "Epoch [17/50], Step [91/735], Loss: 0.2092\n",
      "Epoch [17/50], Step [92/735], Loss: 0.2116\n",
      "Epoch [17/50], Step [93/735], Loss: 1.1643\n",
      "Epoch [17/50], Step [94/735], Loss: 0.4003\n",
      "Epoch [17/50], Step [95/735], Loss: 0.0834\n",
      "Epoch [17/50], Step [96/735], Loss: 0.3265\n",
      "Epoch [17/50], Step [97/735], Loss: 0.4986\n",
      "Epoch [17/50], Step [98/735], Loss: 0.2094\n",
      "Epoch [17/50], Step [99/735], Loss: 0.2160\n",
      "Epoch [17/50], Step [100/735], Loss: 0.2568\n",
      "Epoch [17/50], Step [101/735], Loss: 0.0911\n",
      "Epoch [17/50], Step [102/735], Loss: 0.0788\n",
      "Epoch [17/50], Step [103/735], Loss: 0.2387\n",
      "Epoch [17/50], Step [104/735], Loss: 0.6501\n",
      "Epoch [17/50], Step [105/735], Loss: 0.5489\n",
      "Epoch [17/50], Step [106/735], Loss: 0.5042\n",
      "Epoch [17/50], Step [107/735], Loss: 0.0629\n",
      "Epoch [17/50], Step [108/735], Loss: 0.4741\n",
      "Epoch [17/50], Step [109/735], Loss: 1.2771\n",
      "Epoch [17/50], Step [110/735], Loss: 0.8142\n",
      "Epoch [17/50], Step [111/735], Loss: 0.7280\n",
      "Epoch [17/50], Step [112/735], Loss: 0.1525\n",
      "Epoch [17/50], Step [113/735], Loss: 0.1551\n",
      "Epoch [17/50], Step [114/735], Loss: 0.4247\n",
      "Epoch [17/50], Step [115/735], Loss: 0.3845\n",
      "Epoch [17/50], Step [116/735], Loss: 0.0816\n",
      "Epoch [17/50], Step [117/735], Loss: 0.1162\n",
      "Epoch [17/50], Step [118/735], Loss: 0.2894\n",
      "Epoch [17/50], Step [119/735], Loss: 1.1609\n",
      "Epoch [17/50], Step [120/735], Loss: 0.1788\n",
      "Epoch [17/50], Step [121/735], Loss: 0.4243\n",
      "Epoch [17/50], Step [122/735], Loss: 0.2679\n",
      "Epoch [17/50], Step [123/735], Loss: 1.6578\n",
      "Epoch [17/50], Step [124/735], Loss: 1.2783\n",
      "Epoch [17/50], Step [125/735], Loss: 0.6304\n",
      "Epoch [17/50], Step [126/735], Loss: 1.2145\n",
      "Epoch [17/50], Step [127/735], Loss: 0.1968\n",
      "Epoch [17/50], Step [128/735], Loss: 0.2604\n",
      "Epoch [17/50], Step [129/735], Loss: 0.1385\n",
      "Epoch [17/50], Step [130/735], Loss: 0.2105\n",
      "Epoch [17/50], Step [131/735], Loss: 0.7334\n",
      "Epoch [17/50], Step [132/735], Loss: 0.2333\n",
      "Epoch [17/50], Step [133/735], Loss: 0.3006\n",
      "Epoch [17/50], Step [134/735], Loss: 0.4966\n",
      "Epoch [17/50], Step [135/735], Loss: 0.7312\n",
      "Epoch [17/50], Step [136/735], Loss: 0.4147\n",
      "Epoch [17/50], Step [137/735], Loss: 0.2774\n",
      "Epoch [17/50], Step [138/735], Loss: 0.2142\n",
      "Epoch [17/50], Step [139/735], Loss: 0.2131\n",
      "Epoch [17/50], Step [140/735], Loss: 0.3494\n",
      "Epoch [17/50], Step [141/735], Loss: 0.5351\n",
      "Epoch [17/50], Step [142/735], Loss: 0.6480\n",
      "Epoch [17/50], Step [143/735], Loss: 0.4442\n",
      "Epoch [17/50], Step [144/735], Loss: 0.4327\n",
      "Epoch [17/50], Step [145/735], Loss: 0.5064\n",
      "Epoch [17/50], Step [146/735], Loss: 0.3363\n",
      "Epoch [17/50], Step [147/735], Loss: 0.1572\n",
      "Epoch [17/50], Step [148/735], Loss: 0.6540\n",
      "Epoch [17/50], Step [149/735], Loss: 0.1369\n",
      "Epoch [17/50], Step [150/735], Loss: 0.5639\n",
      "Epoch [17/50], Step [151/735], Loss: 1.0636\n",
      "Epoch [17/50], Step [152/735], Loss: 0.5916\n",
      "Epoch [17/50], Step [153/735], Loss: 1.2602\n",
      "Epoch [17/50], Step [154/735], Loss: 0.4970\n",
      "Epoch [17/50], Step [155/735], Loss: 0.8926\n",
      "Epoch [17/50], Step [156/735], Loss: 0.2486\n",
      "Epoch [17/50], Step [157/735], Loss: 0.8130\n",
      "Epoch [17/50], Step [158/735], Loss: 0.1360\n",
      "Epoch [17/50], Step [159/735], Loss: 0.4539\n",
      "Epoch [17/50], Step [160/735], Loss: 0.5024\n",
      "Epoch [17/50], Step [161/735], Loss: 0.4486\n",
      "Epoch [17/50], Step [162/735], Loss: 0.2515\n",
      "Epoch [17/50], Step [163/735], Loss: 1.4867\n",
      "Epoch [17/50], Step [164/735], Loss: 0.5090\n",
      "Epoch [17/50], Step [165/735], Loss: 0.0815\n",
      "Epoch [17/50], Step [166/735], Loss: 0.1349\n",
      "Epoch [17/50], Step [167/735], Loss: 0.3789\n",
      "Epoch [17/50], Step [168/735], Loss: 0.0987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Step [169/735], Loss: 0.4677\n",
      "Epoch [17/50], Step [170/735], Loss: 0.2748\n",
      "Epoch [17/50], Step [171/735], Loss: 0.9234\n",
      "Epoch [17/50], Step [172/735], Loss: 0.7522\n",
      "Epoch [17/50], Step [173/735], Loss: 0.3284\n",
      "Epoch [17/50], Step [174/735], Loss: 0.3643\n",
      "Epoch [17/50], Step [175/735], Loss: 2.0883\n",
      "Epoch [17/50], Step [176/735], Loss: 5.0466\n",
      "Epoch [17/50], Step [177/735], Loss: 0.7841\n",
      "Epoch [17/50], Step [178/735], Loss: 0.2879\n",
      "Epoch [17/50], Step [179/735], Loss: 0.4912\n",
      "Epoch [17/50], Step [180/735], Loss: 0.3470\n",
      "Epoch [17/50], Step [181/735], Loss: 0.1852\n",
      "Epoch [17/50], Step [182/735], Loss: 0.8167\n",
      "Epoch [17/50], Step [183/735], Loss: 0.2494\n",
      "Epoch [17/50], Step [184/735], Loss: 1.0141\n",
      "Epoch [17/50], Step [185/735], Loss: 0.3326\n",
      "Epoch [17/50], Step [186/735], Loss: 0.1766\n",
      "Epoch [17/50], Step [187/735], Loss: 0.1215\n",
      "Epoch [17/50], Step [188/735], Loss: 1.8715\n",
      "Epoch [17/50], Step [189/735], Loss: 0.4827\n",
      "Epoch [17/50], Step [190/735], Loss: 0.4135\n",
      "Epoch [17/50], Step [191/735], Loss: 0.2357\n",
      "Epoch [17/50], Step [192/735], Loss: 0.1401\n",
      "Epoch [17/50], Step [193/735], Loss: 0.1202\n",
      "Epoch [17/50], Step [194/735], Loss: 0.4022\n",
      "Epoch [17/50], Step [195/735], Loss: 0.1648\n",
      "Epoch [17/50], Step [196/735], Loss: 1.0403\n",
      "Epoch [17/50], Step [197/735], Loss: 0.7319\n",
      "Epoch [17/50], Step [198/735], Loss: 0.2419\n",
      "Epoch [17/50], Step [199/735], Loss: 1.0129\n",
      "Epoch [17/50], Step [200/735], Loss: 4.8749\n",
      "Epoch [17/50], Step [201/735], Loss: 0.2978\n",
      "Epoch [17/50], Step [202/735], Loss: 0.3766\n",
      "Epoch [17/50], Step [203/735], Loss: 0.3968\n",
      "Epoch [17/50], Step [204/735], Loss: 0.4838\n",
      "Epoch [17/50], Step [205/735], Loss: 0.9464\n",
      "Epoch [17/50], Step [206/735], Loss: 0.1056\n",
      "Epoch [17/50], Step [207/735], Loss: 0.2582\n",
      "Epoch [17/50], Step [208/735], Loss: 0.2107\n",
      "Epoch [17/50], Step [209/735], Loss: 0.2197\n",
      "Epoch [17/50], Step [210/735], Loss: 0.1141\n",
      "Epoch [17/50], Step [211/735], Loss: 0.4612\n",
      "Epoch [17/50], Step [212/735], Loss: 0.1463\n",
      "Epoch [17/50], Step [213/735], Loss: 0.3237\n",
      "Epoch [17/50], Step [214/735], Loss: 0.7293\n",
      "Epoch [17/50], Step [215/735], Loss: 0.3053\n",
      "Epoch [17/50], Step [216/735], Loss: 0.2772\n",
      "Epoch [17/50], Step [217/735], Loss: 0.3584\n",
      "Epoch [17/50], Step [218/735], Loss: 0.5006\n",
      "Epoch [17/50], Step [219/735], Loss: 1.2239\n",
      "Epoch [17/50], Step [220/735], Loss: 0.1840\n",
      "Epoch [17/50], Step [221/735], Loss: 1.0261\n",
      "Epoch [17/50], Step [222/735], Loss: 0.4218\n",
      "Epoch [17/50], Step [223/735], Loss: 1.1136\n",
      "Epoch [17/50], Step [224/735], Loss: 0.1638\n",
      "Epoch [17/50], Step [225/735], Loss: 0.1566\n",
      "Epoch [17/50], Step [226/735], Loss: 0.2726\n",
      "Epoch [17/50], Step [227/735], Loss: 0.5179\n",
      "Epoch [17/50], Step [228/735], Loss: 0.3226\n",
      "Epoch [17/50], Step [229/735], Loss: 0.2150\n",
      "Epoch [17/50], Step [230/735], Loss: 0.8143\n",
      "Epoch [17/50], Step [231/735], Loss: 0.2503\n",
      "Epoch [17/50], Step [232/735], Loss: 0.4134\n",
      "Epoch [17/50], Step [233/735], Loss: 0.1059\n",
      "Epoch [17/50], Step [234/735], Loss: 0.3733\n",
      "Epoch [17/50], Step [235/735], Loss: 0.1095\n",
      "Epoch [17/50], Step [236/735], Loss: 0.0635\n",
      "Epoch [17/50], Step [237/735], Loss: 0.3830\n",
      "Epoch [17/50], Step [238/735], Loss: 0.1898\n",
      "Epoch [17/50], Step [239/735], Loss: 0.2830\n",
      "Epoch [17/50], Step [240/735], Loss: 0.5907\n",
      "Epoch [17/50], Step [241/735], Loss: 0.2849\n",
      "Epoch [17/50], Step [242/735], Loss: 0.2451\n",
      "Epoch [17/50], Step [243/735], Loss: 0.1130\n",
      "Epoch [17/50], Step [244/735], Loss: 0.5243\n",
      "Epoch [17/50], Step [245/735], Loss: 0.5030\n",
      "Epoch [17/50], Step [246/735], Loss: 0.8788\n",
      "Epoch [17/50], Step [247/735], Loss: 0.3673\n",
      "Epoch [17/50], Step [248/735], Loss: 0.3993\n",
      "Epoch [17/50], Step [249/735], Loss: 0.2047\n",
      "Epoch [17/50], Step [250/735], Loss: 0.9972\n",
      "Epoch [17/50], Step [251/735], Loss: 0.1136\n",
      "Epoch [17/50], Step [252/735], Loss: 0.2040\n",
      "Epoch [17/50], Step [253/735], Loss: 0.4862\n",
      "Epoch [17/50], Step [254/735], Loss: 0.4408\n",
      "Epoch [17/50], Step [255/735], Loss: 1.0762\n",
      "Epoch [17/50], Step [256/735], Loss: 0.1142\n",
      "Epoch [17/50], Step [257/735], Loss: 0.1933\n",
      "Epoch [17/50], Step [258/735], Loss: 1.9670\n",
      "Epoch [17/50], Step [259/735], Loss: 0.1665\n",
      "Epoch [17/50], Step [260/735], Loss: 0.5254\n",
      "Epoch [17/50], Step [261/735], Loss: 0.1752\n",
      "Epoch [17/50], Step [262/735], Loss: 0.1576\n",
      "Epoch [17/50], Step [263/735], Loss: 0.2402\n",
      "Epoch [17/50], Step [264/735], Loss: 0.3858\n",
      "Epoch [17/50], Step [265/735], Loss: 0.2061\n",
      "Epoch [17/50], Step [266/735], Loss: 0.4092\n",
      "Epoch [17/50], Step [267/735], Loss: 0.5245\n",
      "Epoch [17/50], Step [268/735], Loss: 0.4051\n",
      "Epoch [17/50], Step [269/735], Loss: 0.2328\n",
      "Epoch [17/50], Step [270/735], Loss: 0.6661\n",
      "Epoch [17/50], Step [271/735], Loss: 0.2475\n",
      "Epoch [17/50], Step [272/735], Loss: 0.4621\n",
      "Epoch [17/50], Step [273/735], Loss: 0.2383\n",
      "Epoch [17/50], Step [274/735], Loss: 0.1729\n",
      "Epoch [17/50], Step [275/735], Loss: 0.4816\n",
      "Epoch [17/50], Step [276/735], Loss: 0.1005\n",
      "Epoch [17/50], Step [277/735], Loss: 0.2166\n",
      "Epoch [17/50], Step [278/735], Loss: 0.8094\n",
      "Epoch [17/50], Step [279/735], Loss: 0.3079\n",
      "Epoch [17/50], Step [280/735], Loss: 0.5624\n",
      "Epoch [17/50], Step [281/735], Loss: 0.4311\n",
      "Epoch [17/50], Step [282/735], Loss: 0.9853\n",
      "Epoch [17/50], Step [283/735], Loss: 0.3921\n",
      "Epoch [17/50], Step [284/735], Loss: 0.5378\n",
      "Epoch [17/50], Step [285/735], Loss: 0.6785\n",
      "Epoch [17/50], Step [286/735], Loss: 0.3721\n",
      "Epoch [17/50], Step [287/735], Loss: 0.2728\n",
      "Epoch [17/50], Step [288/735], Loss: 0.2712\n",
      "Epoch [17/50], Step [289/735], Loss: 1.7146\n",
      "Epoch [17/50], Step [290/735], Loss: 0.0943\n",
      "Epoch [17/50], Step [291/735], Loss: 0.3096\n",
      "Epoch [17/50], Step [292/735], Loss: 0.2865\n",
      "Epoch [17/50], Step [293/735], Loss: 0.1303\n",
      "Epoch [17/50], Step [294/735], Loss: 0.1056\n",
      "Epoch [17/50], Step [295/735], Loss: 0.4346\n",
      "Epoch [17/50], Step [296/735], Loss: 0.2431\n",
      "Epoch [17/50], Step [297/735], Loss: 0.3242\n",
      "Epoch [17/50], Step [298/735], Loss: 1.0546\n",
      "Epoch [17/50], Step [299/735], Loss: 0.2316\n",
      "Epoch [17/50], Step [300/735], Loss: 0.1171\n",
      "Epoch [17/50], Step [301/735], Loss: 2.3394\n",
      "Epoch [17/50], Step [302/735], Loss: 0.4219\n",
      "Epoch [17/50], Step [303/735], Loss: 0.4162\n",
      "Epoch [17/50], Step [304/735], Loss: 0.2716\n",
      "Epoch [17/50], Step [305/735], Loss: 0.4493\n",
      "Epoch [17/50], Step [306/735], Loss: 0.2469\n",
      "Epoch [17/50], Step [307/735], Loss: 1.1960\n",
      "Epoch [17/50], Step [308/735], Loss: 1.6252\n",
      "Epoch [17/50], Step [309/735], Loss: 1.0776\n",
      "Epoch [17/50], Step [310/735], Loss: 0.3769\n",
      "Epoch [17/50], Step [311/735], Loss: 0.3047\n",
      "Epoch [17/50], Step [312/735], Loss: 0.3572\n",
      "Epoch [17/50], Step [313/735], Loss: 0.1968\n",
      "Epoch [17/50], Step [314/735], Loss: 0.2163\n",
      "Epoch [17/50], Step [315/735], Loss: 4.8177\n",
      "Epoch [17/50], Step [316/735], Loss: 0.7475\n",
      "Epoch [17/50], Step [317/735], Loss: 0.0935\n",
      "Epoch [17/50], Step [318/735], Loss: 0.3146\n",
      "Epoch [17/50], Step [319/735], Loss: 0.2389\n",
      "Epoch [17/50], Step [320/735], Loss: 0.1634\n",
      "Epoch [17/50], Step [321/735], Loss: 0.1748\n",
      "Epoch [17/50], Step [322/735], Loss: 0.4250\n",
      "Epoch [17/50], Step [323/735], Loss: 0.3037\n",
      "Epoch [17/50], Step [324/735], Loss: 0.1497\n",
      "Epoch [17/50], Step [325/735], Loss: 0.5846\n",
      "Epoch [17/50], Step [326/735], Loss: 0.0916\n",
      "Epoch [17/50], Step [327/735], Loss: 0.6883\n",
      "Epoch [17/50], Step [328/735], Loss: 0.2810\n",
      "Epoch [17/50], Step [329/735], Loss: 0.1141\n",
      "Epoch [17/50], Step [330/735], Loss: 0.2568\n",
      "Epoch [17/50], Step [331/735], Loss: 0.2102\n",
      "Epoch [17/50], Step [332/735], Loss: 0.1327\n",
      "Epoch [17/50], Step [333/735], Loss: 0.4329\n",
      "Epoch [17/50], Step [334/735], Loss: 0.1605\n",
      "Epoch [17/50], Step [335/735], Loss: 0.6359\n",
      "Epoch [17/50], Step [336/735], Loss: 1.0022\n",
      "Epoch [17/50], Step [337/735], Loss: 0.2248\n",
      "Epoch [17/50], Step [338/735], Loss: 0.2720\n",
      "Epoch [17/50], Step [339/735], Loss: 0.2396\n",
      "Epoch [17/50], Step [340/735], Loss: 0.3176\n",
      "Epoch [17/50], Step [341/735], Loss: 0.6711\n",
      "Epoch [17/50], Step [342/735], Loss: 0.2216\n",
      "Epoch [17/50], Step [343/735], Loss: 0.4057\n",
      "Epoch [17/50], Step [344/735], Loss: 0.3611\n",
      "Epoch [17/50], Step [345/735], Loss: 0.8767\n",
      "Epoch [17/50], Step [346/735], Loss: 0.5120\n",
      "Epoch [17/50], Step [347/735], Loss: 0.2220\n",
      "Epoch [17/50], Step [348/735], Loss: 0.3808\n",
      "Epoch [17/50], Step [349/735], Loss: 0.3531\n",
      "Epoch [17/50], Step [350/735], Loss: 0.8654\n",
      "Epoch [17/50], Step [351/735], Loss: 0.0974\n",
      "Epoch [17/50], Step [352/735], Loss: 0.1293\n",
      "Epoch [17/50], Step [353/735], Loss: 0.0686\n",
      "Epoch [17/50], Step [354/735], Loss: 0.8017\n",
      "Epoch [17/50], Step [355/735], Loss: 0.1328\n",
      "Epoch [17/50], Step [356/735], Loss: 0.2244\n",
      "Epoch [17/50], Step [357/735], Loss: 0.6482\n",
      "Epoch [17/50], Step [358/735], Loss: 0.4087\n",
      "Epoch [17/50], Step [359/735], Loss: 0.4262\n",
      "Epoch [17/50], Step [360/735], Loss: 0.3246\n",
      "Epoch [17/50], Step [361/735], Loss: 0.4517\n",
      "Epoch [17/50], Step [362/735], Loss: 0.2112\n",
      "Epoch [17/50], Step [363/735], Loss: 0.1687\n",
      "Epoch [17/50], Step [364/735], Loss: 0.6105\n",
      "Epoch [17/50], Step [365/735], Loss: 1.4732\n",
      "Epoch [17/50], Step [366/735], Loss: 0.0697\n",
      "Epoch [17/50], Step [367/735], Loss: 0.2102\n",
      "Epoch [17/50], Step [368/735], Loss: 0.1092\n",
      "Epoch [17/50], Step [369/735], Loss: 0.0540\n",
      "Epoch [17/50], Step [370/735], Loss: 0.4878\n",
      "Epoch [17/50], Step [371/735], Loss: 0.4560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Step [372/735], Loss: 1.5257\n",
      "Epoch [17/50], Step [373/735], Loss: 0.1495\n",
      "Epoch [17/50], Step [374/735], Loss: 0.1218\n",
      "Epoch [17/50], Step [375/735], Loss: 0.1546\n",
      "Epoch [17/50], Step [376/735], Loss: 0.1973\n",
      "Epoch [17/50], Step [377/735], Loss: 0.9738\n",
      "Epoch [17/50], Step [378/735], Loss: 0.2778\n",
      "Epoch [17/50], Step [379/735], Loss: 0.4050\n",
      "Epoch [17/50], Step [380/735], Loss: 0.8414\n",
      "Epoch [17/50], Step [381/735], Loss: 0.1753\n",
      "Epoch [17/50], Step [382/735], Loss: 0.5905\n",
      "Epoch [17/50], Step [383/735], Loss: 0.6976\n",
      "Epoch [17/50], Step [384/735], Loss: 0.2511\n",
      "Epoch [17/50], Step [385/735], Loss: 0.2243\n",
      "Epoch [17/50], Step [386/735], Loss: 0.3667\n",
      "Epoch [17/50], Step [387/735], Loss: 0.1351\n",
      "Epoch [17/50], Step [388/735], Loss: 0.8886\n",
      "Epoch [17/50], Step [389/735], Loss: 0.0878\n",
      "Epoch [17/50], Step [390/735], Loss: 0.2871\n",
      "Epoch [17/50], Step [391/735], Loss: 0.0673\n",
      "Epoch [17/50], Step [392/735], Loss: 0.9713\n",
      "Epoch [17/50], Step [393/735], Loss: 0.1456\n",
      "Epoch [17/50], Step [394/735], Loss: 0.1769\n",
      "Epoch [17/50], Step [395/735], Loss: 0.4335\n",
      "Epoch [17/50], Step [396/735], Loss: 0.6764\n",
      "Epoch [17/50], Step [397/735], Loss: 0.1396\n",
      "Epoch [17/50], Step [398/735], Loss: 2.8356\n",
      "Epoch [17/50], Step [399/735], Loss: 0.2355\n",
      "Epoch [17/50], Step [400/735], Loss: 0.3408\n",
      "Epoch [17/50], Step [401/735], Loss: 2.6686\n",
      "Epoch [17/50], Step [402/735], Loss: 0.1518\n",
      "Epoch [17/50], Step [403/735], Loss: 0.9214\n",
      "Epoch [17/50], Step [404/735], Loss: 0.2412\n",
      "Epoch [17/50], Step [405/735], Loss: 0.3189\n",
      "Epoch [17/50], Step [406/735], Loss: 0.4693\n",
      "Epoch [17/50], Step [407/735], Loss: 1.9840\n",
      "Epoch [17/50], Step [408/735], Loss: 0.1276\n",
      "Epoch [17/50], Step [409/735], Loss: 0.6169\n",
      "Epoch [17/50], Step [410/735], Loss: 0.4221\n",
      "Epoch [17/50], Step [411/735], Loss: 0.2728\n",
      "Epoch [17/50], Step [412/735], Loss: 0.2356\n",
      "Epoch [17/50], Step [413/735], Loss: 0.1319\n",
      "Epoch [17/50], Step [414/735], Loss: 0.1311\n",
      "Epoch [17/50], Step [415/735], Loss: 0.6610\n",
      "Epoch [17/50], Step [416/735], Loss: 0.2297\n",
      "Epoch [17/50], Step [417/735], Loss: 0.2167\n",
      "Epoch [17/50], Step [418/735], Loss: 0.2836\n",
      "Epoch [17/50], Step [419/735], Loss: 1.3151\n",
      "Epoch [17/50], Step [420/735], Loss: 0.1131\n",
      "Epoch [17/50], Step [421/735], Loss: 0.2684\n",
      "Epoch [17/50], Step [422/735], Loss: 0.2651\n",
      "Epoch [17/50], Step [423/735], Loss: 0.3505\n",
      "Epoch [17/50], Step [424/735], Loss: 0.1944\n",
      "Epoch [17/50], Step [425/735], Loss: 0.6883\n",
      "Epoch [17/50], Step [426/735], Loss: 0.4593\n",
      "Epoch [17/50], Step [427/735], Loss: 0.3297\n",
      "Epoch [17/50], Step [428/735], Loss: 0.6223\n",
      "Epoch [17/50], Step [429/735], Loss: 0.1192\n",
      "Epoch [17/50], Step [430/735], Loss: 0.6516\n",
      "Epoch [17/50], Step [431/735], Loss: 0.9138\n",
      "Epoch [17/50], Step [432/735], Loss: 0.2578\n",
      "Epoch [17/50], Step [433/735], Loss: 0.4718\n",
      "Epoch [17/50], Step [434/735], Loss: 0.4372\n",
      "Epoch [17/50], Step [435/735], Loss: 0.2732\n",
      "Epoch [17/50], Step [436/735], Loss: 0.0944\n",
      "Epoch [17/50], Step [437/735], Loss: 0.2154\n",
      "Epoch [17/50], Step [438/735], Loss: 0.1099\n",
      "Epoch [17/50], Step [439/735], Loss: 0.2647\n",
      "Epoch [17/50], Step [440/735], Loss: 0.4623\n",
      "Epoch [17/50], Step [441/735], Loss: 0.1997\n",
      "Epoch [17/50], Step [442/735], Loss: 0.1536\n",
      "Epoch [17/50], Step [443/735], Loss: 0.5213\n",
      "Epoch [17/50], Step [444/735], Loss: 0.1047\n",
      "Epoch [17/50], Step [445/735], Loss: 0.4695\n",
      "Epoch [17/50], Step [446/735], Loss: 0.9604\n",
      "Epoch [17/50], Step [447/735], Loss: 0.9143\n",
      "Epoch [17/50], Step [448/735], Loss: 0.2259\n",
      "Epoch [17/50], Step [449/735], Loss: 0.3039\n",
      "Epoch [17/50], Step [450/735], Loss: 0.1547\n",
      "Epoch [17/50], Step [451/735], Loss: 0.8896\n",
      "Epoch [17/50], Step [452/735], Loss: 0.3370\n",
      "Epoch [17/50], Step [453/735], Loss: 1.6755\n",
      "Epoch [17/50], Step [454/735], Loss: 0.5722\n",
      "Epoch [17/50], Step [455/735], Loss: 4.8889\n",
      "Epoch [17/50], Step [456/735], Loss: 0.5006\n",
      "Epoch [17/50], Step [457/735], Loss: 0.1394\n",
      "Epoch [17/50], Step [458/735], Loss: 0.1511\n",
      "Epoch [17/50], Step [459/735], Loss: 0.1345\n",
      "Epoch [17/50], Step [460/735], Loss: 1.3308\n",
      "Epoch [17/50], Step [461/735], Loss: 0.1327\n",
      "Epoch [17/50], Step [462/735], Loss: 0.3547\n",
      "Epoch [17/50], Step [463/735], Loss: 0.5842\n",
      "Epoch [17/50], Step [464/735], Loss: 0.3201\n",
      "Epoch [17/50], Step [465/735], Loss: 0.6198\n",
      "Epoch [17/50], Step [466/735], Loss: 0.2231\n",
      "Epoch [17/50], Step [467/735], Loss: 0.2479\n",
      "Epoch [17/50], Step [468/735], Loss: 0.3389\n",
      "Epoch [17/50], Step [469/735], Loss: 0.1559\n",
      "Epoch [17/50], Step [470/735], Loss: 1.5493\n",
      "Epoch [17/50], Step [471/735], Loss: 0.3448\n",
      "Epoch [17/50], Step [472/735], Loss: 0.3396\n",
      "Epoch [17/50], Step [473/735], Loss: 0.1921\n",
      "Epoch [17/50], Step [474/735], Loss: 0.3260\n",
      "Epoch [17/50], Step [475/735], Loss: 0.2388\n",
      "Epoch [17/50], Step [476/735], Loss: 0.2545\n",
      "Epoch [17/50], Step [477/735], Loss: 0.5526\n",
      "Epoch [17/50], Step [478/735], Loss: 0.6210\n",
      "Epoch [17/50], Step [479/735], Loss: 0.2600\n",
      "Epoch [17/50], Step [480/735], Loss: 0.5279\n",
      "Epoch [17/50], Step [481/735], Loss: 0.4759\n",
      "Epoch [17/50], Step [482/735], Loss: 0.8109\n",
      "Epoch [17/50], Step [483/735], Loss: 0.3231\n",
      "Epoch [17/50], Step [484/735], Loss: 0.2130\n",
      "Epoch [17/50], Step [485/735], Loss: 0.6391\n",
      "Epoch [17/50], Step [486/735], Loss: 0.8598\n",
      "Epoch [17/50], Step [487/735], Loss: 1.2064\n",
      "Epoch [17/50], Step [488/735], Loss: 0.1697\n",
      "Epoch [17/50], Step [489/735], Loss: 0.3907\n",
      "Epoch [17/50], Step [490/735], Loss: 0.3262\n",
      "Epoch [17/50], Step [491/735], Loss: 0.1038\n",
      "Epoch [17/50], Step [492/735], Loss: 0.5527\n",
      "Epoch [17/50], Step [493/735], Loss: 0.0829\n",
      "Epoch [17/50], Step [494/735], Loss: 0.1370\n",
      "Epoch [17/50], Step [495/735], Loss: 0.2755\n",
      "Epoch [17/50], Step [496/735], Loss: 0.2556\n",
      "Epoch [17/50], Step [497/735], Loss: 0.6601\n",
      "Epoch [17/50], Step [498/735], Loss: 1.0880\n",
      "Epoch [17/50], Step [499/735], Loss: 0.1218\n",
      "Epoch [17/50], Step [500/735], Loss: 0.4104\n",
      "Epoch [17/50], Step [501/735], Loss: 0.9618\n",
      "Epoch [17/50], Step [502/735], Loss: 0.5373\n",
      "Epoch [17/50], Step [503/735], Loss: 0.3630\n",
      "Epoch [17/50], Step [504/735], Loss: 0.4271\n",
      "Epoch [17/50], Step [505/735], Loss: 0.3170\n",
      "Epoch [17/50], Step [506/735], Loss: 0.3092\n",
      "Epoch [17/50], Step [507/735], Loss: 0.0859\n",
      "Epoch [17/50], Step [508/735], Loss: 0.7262\n",
      "Epoch [17/50], Step [509/735], Loss: 0.1341\n",
      "Epoch [17/50], Step [510/735], Loss: 0.2518\n",
      "Epoch [17/50], Step [511/735], Loss: 0.7319\n",
      "Epoch [17/50], Step [512/735], Loss: 0.2117\n",
      "Epoch [17/50], Step [513/735], Loss: 0.6233\n",
      "Epoch [17/50], Step [514/735], Loss: 0.0927\n",
      "Epoch [17/50], Step [515/735], Loss: 0.5100\n",
      "Epoch [17/50], Step [516/735], Loss: 0.1058\n",
      "Epoch [17/50], Step [517/735], Loss: 0.2486\n",
      "Epoch [17/50], Step [518/735], Loss: 0.2296\n",
      "Epoch [17/50], Step [519/735], Loss: 1.0456\n",
      "Epoch [17/50], Step [520/735], Loss: 0.5785\n",
      "Epoch [17/50], Step [521/735], Loss: 0.2228\n",
      "Epoch [17/50], Step [522/735], Loss: 0.3305\n",
      "Epoch [17/50], Step [523/735], Loss: 0.5669\n",
      "Epoch [17/50], Step [524/735], Loss: 0.6445\n",
      "Epoch [17/50], Step [525/735], Loss: 0.2921\n",
      "Epoch [17/50], Step [526/735], Loss: 0.1507\n",
      "Epoch [17/50], Step [527/735], Loss: 0.0851\n",
      "Epoch [17/50], Step [528/735], Loss: 0.2916\n",
      "Epoch [17/50], Step [529/735], Loss: 0.1516\n",
      "Epoch [17/50], Step [530/735], Loss: 0.4017\n",
      "Epoch [17/50], Step [531/735], Loss: 0.1323\n",
      "Epoch [17/50], Step [532/735], Loss: 0.0994\n",
      "Epoch [17/50], Step [533/735], Loss: 0.4691\n",
      "Epoch [17/50], Step [534/735], Loss: 0.2289\n",
      "Epoch [17/50], Step [535/735], Loss: 0.6319\n",
      "Epoch [17/50], Step [536/735], Loss: 0.3805\n",
      "Epoch [17/50], Step [537/735], Loss: 0.1865\n",
      "Epoch [17/50], Step [538/735], Loss: 0.2914\n",
      "Epoch [17/50], Step [539/735], Loss: 1.4653\n",
      "Epoch [17/50], Step [540/735], Loss: 0.1079\n",
      "Epoch [17/50], Step [541/735], Loss: 0.2829\n",
      "Epoch [17/50], Step [542/735], Loss: 0.6114\n",
      "Epoch [17/50], Step [543/735], Loss: 0.4408\n",
      "Epoch [17/50], Step [544/735], Loss: 0.2926\n",
      "Epoch [17/50], Step [545/735], Loss: 0.7334\n",
      "Epoch [17/50], Step [546/735], Loss: 0.3444\n",
      "Epoch [17/50], Step [547/735], Loss: 0.1880\n",
      "Epoch [17/50], Step [548/735], Loss: 0.5868\n",
      "Epoch [17/50], Step [549/735], Loss: 0.2754\n",
      "Epoch [17/50], Step [550/735], Loss: 0.2790\n",
      "Epoch [17/50], Step [551/735], Loss: 0.2531\n",
      "Epoch [17/50], Step [552/735], Loss: 0.3895\n",
      "Epoch [17/50], Step [553/735], Loss: 0.6324\n",
      "Epoch [17/50], Step [554/735], Loss: 0.6021\n",
      "Epoch [17/50], Step [555/735], Loss: 1.2242\n",
      "Epoch [17/50], Step [556/735], Loss: 0.5891\n",
      "Epoch [17/50], Step [557/735], Loss: 0.0934\n",
      "Epoch [17/50], Step [558/735], Loss: 0.4638\n",
      "Epoch [17/50], Step [559/735], Loss: 0.0453\n",
      "Epoch [17/50], Step [560/735], Loss: 0.1756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Step [561/735], Loss: 1.2328\n",
      "Epoch [17/50], Step [562/735], Loss: 0.2710\n",
      "Epoch [17/50], Step [563/735], Loss: 0.2399\n",
      "Epoch [17/50], Step [564/735], Loss: 0.4996\n",
      "Epoch [17/50], Step [565/735], Loss: 0.3624\n",
      "Epoch [17/50], Step [566/735], Loss: 0.2549\n",
      "Epoch [17/50], Step [567/735], Loss: 0.8619\n",
      "Epoch [17/50], Step [568/735], Loss: 0.6350\n",
      "Epoch [17/50], Step [569/735], Loss: 0.2187\n",
      "Epoch [17/50], Step [570/735], Loss: 0.4892\n",
      "Epoch [17/50], Step [571/735], Loss: 0.8268\n",
      "Epoch [17/50], Step [572/735], Loss: 0.1166\n",
      "Epoch [17/50], Step [573/735], Loss: 0.5944\n",
      "Epoch [17/50], Step [574/735], Loss: 0.2939\n",
      "Epoch [17/50], Step [575/735], Loss: 0.0748\n",
      "Epoch [17/50], Step [576/735], Loss: 0.4882\n",
      "Epoch [17/50], Step [577/735], Loss: 0.3726\n",
      "Epoch [17/50], Step [578/735], Loss: 0.4967\n",
      "Epoch [17/50], Step [579/735], Loss: 0.9707\n",
      "Epoch [17/50], Step [580/735], Loss: 0.1208\n",
      "Epoch [17/50], Step [581/735], Loss: 0.1401\n",
      "Epoch [17/50], Step [582/735], Loss: 0.3455\n",
      "Epoch [17/50], Step [583/735], Loss: 0.0812\n",
      "Epoch [17/50], Step [584/735], Loss: 0.1684\n",
      "Epoch [17/50], Step [585/735], Loss: 0.8692\n",
      "Epoch [17/50], Step [586/735], Loss: 0.1282\n",
      "Epoch [17/50], Step [587/735], Loss: 0.4027\n",
      "Epoch [17/50], Step [588/735], Loss: 0.2674\n",
      "Epoch [17/50], Step [589/735], Loss: 0.1368\n",
      "Epoch [17/50], Step [590/735], Loss: 0.9528\n",
      "Epoch [17/50], Step [591/735], Loss: 0.4724\n",
      "Epoch [17/50], Step [592/735], Loss: 0.0837\n",
      "Epoch [17/50], Step [593/735], Loss: 0.1003\n",
      "Epoch [17/50], Step [594/735], Loss: 0.5501\n",
      "Epoch [17/50], Step [595/735], Loss: 0.1657\n",
      "Epoch [17/50], Step [596/735], Loss: 0.5035\n",
      "Epoch [17/50], Step [597/735], Loss: 0.1630\n",
      "Epoch [17/50], Step [598/735], Loss: 0.2402\n",
      "Epoch [17/50], Step [599/735], Loss: 0.5014\n",
      "Epoch [17/50], Step [600/735], Loss: 0.3411\n",
      "Epoch [17/50], Step [601/735], Loss: 0.7330\n",
      "Epoch [17/50], Step [602/735], Loss: 0.5274\n",
      "Epoch [17/50], Step [603/735], Loss: 0.7167\n",
      "Epoch [17/50], Step [604/735], Loss: 0.1784\n",
      "Epoch [17/50], Step [605/735], Loss: 0.1466\n",
      "Epoch [17/50], Step [606/735], Loss: 0.3411\n",
      "Epoch [17/50], Step [607/735], Loss: 0.7987\n",
      "Epoch [17/50], Step [608/735], Loss: 0.1086\n",
      "Epoch [17/50], Step [609/735], Loss: 0.3861\n",
      "Epoch [17/50], Step [610/735], Loss: 0.1683\n",
      "Epoch [17/50], Step [611/735], Loss: 0.0804\n",
      "Epoch [17/50], Step [612/735], Loss: 0.4838\n",
      "Epoch [17/50], Step [613/735], Loss: 0.1725\n",
      "Epoch [17/50], Step [614/735], Loss: 0.4182\n",
      "Epoch [17/50], Step [615/735], Loss: 0.7324\n",
      "Epoch [17/50], Step [616/735], Loss: 0.2249\n",
      "Epoch [17/50], Step [617/735], Loss: 0.1928\n",
      "Epoch [17/50], Step [618/735], Loss: 0.6866\n",
      "Epoch [17/50], Step [619/735], Loss: 0.5166\n",
      "Epoch [17/50], Step [620/735], Loss: 0.7104\n",
      "Epoch [17/50], Step [621/735], Loss: 0.3218\n",
      "Epoch [17/50], Step [622/735], Loss: 0.1782\n",
      "Epoch [17/50], Step [623/735], Loss: 0.9455\n",
      "Epoch [17/50], Step [624/735], Loss: 0.4032\n",
      "Epoch [17/50], Step [625/735], Loss: 0.1088\n",
      "Epoch [17/50], Step [626/735], Loss: 0.0905\n",
      "Epoch [17/50], Step [627/735], Loss: 0.2323\n",
      "Epoch [17/50], Step [628/735], Loss: 0.4076\n",
      "Epoch [17/50], Step [629/735], Loss: 0.1617\n",
      "Epoch [17/50], Step [630/735], Loss: 0.3367\n",
      "Epoch [17/50], Step [631/735], Loss: 0.3516\n",
      "Epoch [17/50], Step [632/735], Loss: 0.4216\n",
      "Epoch [17/50], Step [633/735], Loss: 0.7703\n",
      "Epoch [17/50], Step [634/735], Loss: 0.1594\n",
      "Epoch [17/50], Step [635/735], Loss: 0.4087\n",
      "Epoch [17/50], Step [636/735], Loss: 1.0763\n",
      "Epoch [17/50], Step [637/735], Loss: 0.1229\n",
      "Epoch [17/50], Step [638/735], Loss: 0.5540\n",
      "Epoch [17/50], Step [639/735], Loss: 0.1553\n",
      "Epoch [17/50], Step [640/735], Loss: 0.5407\n",
      "Epoch [17/50], Step [641/735], Loss: 0.7355\n",
      "Epoch [17/50], Step [642/735], Loss: 0.1528\n",
      "Epoch [17/50], Step [643/735], Loss: 0.3853\n",
      "Epoch [17/50], Step [644/735], Loss: 0.2342\n",
      "Epoch [17/50], Step [645/735], Loss: 0.3150\n",
      "Epoch [17/50], Step [646/735], Loss: 1.2667\n",
      "Epoch [17/50], Step [647/735], Loss: 0.6208\n",
      "Epoch [17/50], Step [648/735], Loss: 0.3255\n",
      "Epoch [17/50], Step [649/735], Loss: 0.1753\n",
      "Epoch [17/50], Step [650/735], Loss: 0.1842\n",
      "Epoch [17/50], Step [651/735], Loss: 0.6767\n",
      "Epoch [17/50], Step [652/735], Loss: 0.0781\n",
      "Epoch [17/50], Step [653/735], Loss: 0.7203\n",
      "Epoch [17/50], Step [654/735], Loss: 0.2016\n",
      "Epoch [17/50], Step [655/735], Loss: 0.1642\n",
      "Epoch [17/50], Step [656/735], Loss: 0.1005\n",
      "Epoch [17/50], Step [657/735], Loss: 0.5671\n",
      "Epoch [17/50], Step [658/735], Loss: 0.2253\n",
      "Epoch [17/50], Step [659/735], Loss: 0.7759\n",
      "Epoch [17/50], Step [660/735], Loss: 0.0935\n",
      "Epoch [17/50], Step [661/735], Loss: 0.0635\n",
      "Epoch [17/50], Step [662/735], Loss: 0.7354\n",
      "Epoch [17/50], Step [663/735], Loss: 0.3117\n",
      "Epoch [17/50], Step [664/735], Loss: 0.3185\n",
      "Epoch [17/50], Step [665/735], Loss: 0.4671\n",
      "Epoch [17/50], Step [666/735], Loss: 0.2335\n",
      "Epoch [17/50], Step [667/735], Loss: 1.3140\n",
      "Epoch [17/50], Step [668/735], Loss: 0.6258\n",
      "Epoch [17/50], Step [669/735], Loss: 0.1926\n",
      "Epoch [17/50], Step [670/735], Loss: 0.7962\n",
      "Epoch [17/50], Step [671/735], Loss: 0.2652\n",
      "Epoch [17/50], Step [672/735], Loss: 0.0735\n",
      "Epoch [17/50], Step [673/735], Loss: 0.7426\n",
      "Epoch [17/50], Step [674/735], Loss: 0.1299\n",
      "Epoch [17/50], Step [675/735], Loss: 0.8628\n",
      "Epoch [17/50], Step [676/735], Loss: 0.9569\n",
      "Epoch [17/50], Step [677/735], Loss: 0.4470\n",
      "Epoch [17/50], Step [678/735], Loss: 0.1859\n",
      "Epoch [17/50], Step [679/735], Loss: 0.3184\n",
      "Epoch [17/50], Step [680/735], Loss: 0.8703\n",
      "Epoch [17/50], Step [681/735], Loss: 0.0835\n",
      "Epoch [17/50], Step [682/735], Loss: 0.3588\n",
      "Epoch [17/50], Step [683/735], Loss: 0.3521\n",
      "Epoch [17/50], Step [684/735], Loss: 0.2683\n",
      "Epoch [17/50], Step [685/735], Loss: 0.3330\n",
      "Epoch [17/50], Step [686/735], Loss: 0.3249\n",
      "Epoch [17/50], Step [687/735], Loss: 0.2367\n",
      "Epoch [17/50], Step [688/735], Loss: 0.1012\n",
      "Epoch [17/50], Step [689/735], Loss: 0.2135\n",
      "Epoch [17/50], Step [690/735], Loss: 0.4101\n",
      "Epoch [17/50], Step [691/735], Loss: 0.1077\n",
      "Epoch [17/50], Step [692/735], Loss: 0.3716\n",
      "Epoch [17/50], Step [693/735], Loss: 0.2161\n",
      "Epoch [17/50], Step [694/735], Loss: 0.2699\n",
      "Epoch [17/50], Step [695/735], Loss: 0.1650\n",
      "Epoch [17/50], Step [696/735], Loss: 0.1822\n",
      "Epoch [17/50], Step [697/735], Loss: 0.0859\n",
      "Epoch [17/50], Step [698/735], Loss: 0.2169\n",
      "Epoch [17/50], Step [699/735], Loss: 0.3364\n",
      "Epoch [17/50], Step [700/735], Loss: 0.2633\n",
      "Epoch [17/50], Step [701/735], Loss: 0.4360\n",
      "Epoch [17/50], Step [702/735], Loss: 0.5800\n",
      "Epoch [17/50], Step [703/735], Loss: 0.1180\n",
      "Epoch [17/50], Step [704/735], Loss: 0.3851\n",
      "Epoch [17/50], Step [705/735], Loss: 0.0878\n",
      "Epoch [17/50], Step [706/735], Loss: 0.2224\n",
      "Epoch [17/50], Step [707/735], Loss: 0.1419\n",
      "Epoch [17/50], Step [708/735], Loss: 0.6042\n",
      "Epoch [17/50], Step [709/735], Loss: 0.2802\n",
      "Epoch [17/50], Step [710/735], Loss: 0.9659\n",
      "Epoch [17/50], Step [711/735], Loss: 0.1175\n",
      "Epoch [17/50], Step [712/735], Loss: 0.5799\n",
      "Epoch [17/50], Step [713/735], Loss: 0.2836\n",
      "Epoch [17/50], Step [714/735], Loss: 0.1339\n",
      "Epoch [17/50], Step [715/735], Loss: 0.2425\n",
      "Epoch [17/50], Step [716/735], Loss: 0.3869\n",
      "Epoch [17/50], Step [717/735], Loss: 0.5919\n",
      "Epoch [17/50], Step [718/735], Loss: 0.1894\n",
      "Epoch [17/50], Step [719/735], Loss: 0.8809\n",
      "Epoch [17/50], Step [720/735], Loss: 0.1571\n",
      "Epoch [17/50], Step [721/735], Loss: 0.9683\n",
      "Epoch [17/50], Step [722/735], Loss: 0.3665\n",
      "Epoch [17/50], Step [723/735], Loss: 0.2285\n",
      "Epoch [17/50], Step [724/735], Loss: 0.2409\n",
      "Epoch [17/50], Step [725/735], Loss: 0.4778\n",
      "Epoch [17/50], Step [726/735], Loss: 0.2957\n",
      "Epoch [17/50], Step [727/735], Loss: 0.3580\n",
      "Epoch [17/50], Step [728/735], Loss: 0.2138\n",
      "Epoch [17/50], Step [729/735], Loss: 0.4382\n",
      "Epoch [17/50], Step [730/735], Loss: 0.3135\n",
      "Epoch [17/50], Step [731/735], Loss: 0.2883\n",
      "Epoch [17/50], Step [732/735], Loss: 0.2805\n",
      "Epoch [17/50], Step [733/735], Loss: 0.1019\n",
      "Epoch [17/50], Step [734/735], Loss: 0.4842\n",
      "Epoch [17/50], Step [735/735], Loss: 0.4945\n",
      "Epoch [18/50], Step [1/735], Loss: 0.2186\n",
      "Epoch [18/50], Step [2/735], Loss: 0.3945\n",
      "Epoch [18/50], Step [3/735], Loss: 0.0584\n",
      "Epoch [18/50], Step [4/735], Loss: 0.1001\n",
      "Epoch [18/50], Step [5/735], Loss: 0.5043\n",
      "Epoch [18/50], Step [6/735], Loss: 0.7540\n",
      "Epoch [18/50], Step [7/735], Loss: 0.2836\n",
      "Epoch [18/50], Step [8/735], Loss: 0.5833\n",
      "Epoch [18/50], Step [9/735], Loss: 0.1478\n",
      "Epoch [18/50], Step [10/735], Loss: 0.5191\n",
      "Epoch [18/50], Step [11/735], Loss: 0.2996\n",
      "Epoch [18/50], Step [12/735], Loss: 2.5278\n",
      "Epoch [18/50], Step [13/735], Loss: 1.2341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Step [14/735], Loss: 0.3976\n",
      "Epoch [18/50], Step [15/735], Loss: 0.3545\n",
      "Epoch [18/50], Step [16/735], Loss: 0.2299\n",
      "Epoch [18/50], Step [17/735], Loss: 1.1103\n",
      "Epoch [18/50], Step [18/735], Loss: 0.1982\n",
      "Epoch [18/50], Step [19/735], Loss: 0.9339\n",
      "Epoch [18/50], Step [20/735], Loss: 0.5577\n",
      "Epoch [18/50], Step [21/735], Loss: 0.2878\n",
      "Epoch [18/50], Step [22/735], Loss: 0.5117\n",
      "Epoch [18/50], Step [23/735], Loss: 0.4133\n",
      "Epoch [18/50], Step [24/735], Loss: 1.4835\n",
      "Epoch [18/50], Step [25/735], Loss: 0.6102\n",
      "Epoch [18/50], Step [26/735], Loss: 0.2803\n",
      "Epoch [18/50], Step [27/735], Loss: 0.2837\n",
      "Epoch [18/50], Step [28/735], Loss: 0.3951\n",
      "Epoch [18/50], Step [29/735], Loss: 0.3851\n",
      "Epoch [18/50], Step [30/735], Loss: 0.3000\n",
      "Epoch [18/50], Step [31/735], Loss: 0.5384\n",
      "Epoch [18/50], Step [32/735], Loss: 0.4742\n",
      "Epoch [18/50], Step [33/735], Loss: 0.2173\n",
      "Epoch [18/50], Step [34/735], Loss: 0.3165\n",
      "Epoch [18/50], Step [35/735], Loss: 0.1999\n",
      "Epoch [18/50], Step [36/735], Loss: 0.3530\n",
      "Epoch [18/50], Step [37/735], Loss: 0.7743\n",
      "Epoch [18/50], Step [38/735], Loss: 0.2857\n",
      "Epoch [18/50], Step [39/735], Loss: 0.1604\n",
      "Epoch [18/50], Step [40/735], Loss: 0.4486\n",
      "Epoch [18/50], Step [41/735], Loss: 0.1572\n",
      "Epoch [18/50], Step [42/735], Loss: 0.4671\n",
      "Epoch [18/50], Step [43/735], Loss: 0.2159\n",
      "Epoch [18/50], Step [44/735], Loss: 0.1152\n",
      "Epoch [18/50], Step [45/735], Loss: 0.6081\n",
      "Epoch [18/50], Step [46/735], Loss: 0.7548\n",
      "Epoch [18/50], Step [47/735], Loss: 0.2986\n",
      "Epoch [18/50], Step [48/735], Loss: 0.5366\n",
      "Epoch [18/50], Step [49/735], Loss: 0.4797\n",
      "Epoch [18/50], Step [50/735], Loss: 0.0882\n",
      "Epoch [18/50], Step [51/735], Loss: 0.4316\n",
      "Epoch [18/50], Step [52/735], Loss: 0.1759\n",
      "Epoch [18/50], Step [53/735], Loss: 0.5865\n",
      "Epoch [18/50], Step [54/735], Loss: 0.1061\n",
      "Epoch [18/50], Step [55/735], Loss: 0.7580\n",
      "Epoch [18/50], Step [56/735], Loss: 0.2362\n",
      "Epoch [18/50], Step [57/735], Loss: 0.3317\n",
      "Epoch [18/50], Step [58/735], Loss: 0.4198\n",
      "Epoch [18/50], Step [59/735], Loss: 0.3819\n",
      "Epoch [18/50], Step [60/735], Loss: 0.6378\n",
      "Epoch [18/50], Step [61/735], Loss: 0.3929\n",
      "Epoch [18/50], Step [62/735], Loss: 0.2112\n",
      "Epoch [18/50], Step [63/735], Loss: 0.4450\n",
      "Epoch [18/50], Step [64/735], Loss: 0.3139\n",
      "Epoch [18/50], Step [65/735], Loss: 0.0756\n",
      "Epoch [18/50], Step [66/735], Loss: 0.1167\n",
      "Epoch [18/50], Step [67/735], Loss: 0.1958\n",
      "Epoch [18/50], Step [68/735], Loss: 0.6245\n",
      "Epoch [18/50], Step [69/735], Loss: 0.8763\n",
      "Epoch [18/50], Step [70/735], Loss: 0.2576\n",
      "Epoch [18/50], Step [71/735], Loss: 0.7460\n",
      "Epoch [18/50], Step [72/735], Loss: 0.2951\n",
      "Epoch [18/50], Step [73/735], Loss: 0.5311\n",
      "Epoch [18/50], Step [74/735], Loss: 0.2099\n",
      "Epoch [18/50], Step [75/735], Loss: 0.1570\n",
      "Epoch [18/50], Step [76/735], Loss: 0.4328\n",
      "Epoch [18/50], Step [77/735], Loss: 0.4305\n",
      "Epoch [18/50], Step [78/735], Loss: 0.1243\n",
      "Epoch [18/50], Step [79/735], Loss: 0.0669\n",
      "Epoch [18/50], Step [80/735], Loss: 0.3144\n",
      "Epoch [18/50], Step [81/735], Loss: 0.4309\n",
      "Epoch [18/50], Step [82/735], Loss: 0.4140\n",
      "Epoch [18/50], Step [83/735], Loss: 0.3498\n",
      "Epoch [18/50], Step [84/735], Loss: 0.5581\n",
      "Epoch [18/50], Step [85/735], Loss: 0.2454\n",
      "Epoch [18/50], Step [86/735], Loss: 1.1708\n",
      "Epoch [18/50], Step [87/735], Loss: 0.2301\n",
      "Epoch [18/50], Step [88/735], Loss: 0.2793\n",
      "Epoch [18/50], Step [89/735], Loss: 0.6921\n",
      "Epoch [18/50], Step [90/735], Loss: 0.2942\n",
      "Epoch [18/50], Step [91/735], Loss: 0.6210\n",
      "Epoch [18/50], Step [92/735], Loss: 0.2366\n",
      "Epoch [18/50], Step [93/735], Loss: 0.4533\n",
      "Epoch [18/50], Step [94/735], Loss: 0.1525\n",
      "Epoch [18/50], Step [95/735], Loss: 0.2577\n",
      "Epoch [18/50], Step [96/735], Loss: 0.3612\n",
      "Epoch [18/50], Step [97/735], Loss: 0.6048\n",
      "Epoch [18/50], Step [98/735], Loss: 0.3432\n",
      "Epoch [18/50], Step [99/735], Loss: 0.3742\n",
      "Epoch [18/50], Step [100/735], Loss: 0.4739\n",
      "Epoch [18/50], Step [101/735], Loss: 0.2658\n",
      "Epoch [18/50], Step [102/735], Loss: 0.3806\n",
      "Epoch [18/50], Step [103/735], Loss: 1.5276\n",
      "Epoch [18/50], Step [104/735], Loss: 0.1120\n",
      "Epoch [18/50], Step [105/735], Loss: 0.2295\n",
      "Epoch [18/50], Step [106/735], Loss: 0.2645\n",
      "Epoch [18/50], Step [107/735], Loss: 0.4777\n",
      "Epoch [18/50], Step [108/735], Loss: 0.5427\n",
      "Epoch [18/50], Step [109/735], Loss: 0.6944\n",
      "Epoch [18/50], Step [110/735], Loss: 0.4454\n",
      "Epoch [18/50], Step [111/735], Loss: 0.3620\n",
      "Epoch [18/50], Step [112/735], Loss: 0.1312\n",
      "Epoch [18/50], Step [113/735], Loss: 0.2565\n",
      "Epoch [18/50], Step [114/735], Loss: 0.2166\n",
      "Epoch [18/50], Step [115/735], Loss: 2.3980\n",
      "Epoch [18/50], Step [116/735], Loss: 0.1701\n",
      "Epoch [18/50], Step [117/735], Loss: 0.0364\n",
      "Epoch [18/50], Step [118/735], Loss: 0.2279\n",
      "Epoch [18/50], Step [119/735], Loss: 0.2653\n",
      "Epoch [18/50], Step [120/735], Loss: 0.2880\n",
      "Epoch [18/50], Step [121/735], Loss: 0.3854\n",
      "Epoch [18/50], Step [122/735], Loss: 0.5407\n",
      "Epoch [18/50], Step [123/735], Loss: 0.6892\n",
      "Epoch [18/50], Step [124/735], Loss: 0.0820\n",
      "Epoch [18/50], Step [125/735], Loss: 0.1418\n",
      "Epoch [18/50], Step [126/735], Loss: 3.3066\n",
      "Epoch [18/50], Step [127/735], Loss: 0.3301\n",
      "Epoch [18/50], Step [128/735], Loss: 0.1218\n",
      "Epoch [18/50], Step [129/735], Loss: 0.2777\n",
      "Epoch [18/50], Step [130/735], Loss: 0.6277\n",
      "Epoch [18/50], Step [131/735], Loss: 0.5052\n",
      "Epoch [18/50], Step [132/735], Loss: 0.5166\n",
      "Epoch [18/50], Step [133/735], Loss: 0.1423\n",
      "Epoch [18/50], Step [134/735], Loss: 0.5764\n",
      "Epoch [18/50], Step [135/735], Loss: 0.4854\n",
      "Epoch [18/50], Step [136/735], Loss: 0.3815\n",
      "Epoch [18/50], Step [137/735], Loss: 0.7220\n",
      "Epoch [18/50], Step [138/735], Loss: 0.4337\n",
      "Epoch [18/50], Step [139/735], Loss: 0.3390\n",
      "Epoch [18/50], Step [140/735], Loss: 0.2316\n",
      "Epoch [18/50], Step [141/735], Loss: 0.5436\n",
      "Epoch [18/50], Step [142/735], Loss: 0.2220\n",
      "Epoch [18/50], Step [143/735], Loss: 0.3252\n",
      "Epoch [18/50], Step [144/735], Loss: 0.3045\n",
      "Epoch [18/50], Step [145/735], Loss: 0.6084\n",
      "Epoch [18/50], Step [146/735], Loss: 0.2786\n",
      "Epoch [18/50], Step [147/735], Loss: 0.0572\n",
      "Epoch [18/50], Step [148/735], Loss: 0.2011\n",
      "Epoch [18/50], Step [149/735], Loss: 0.3465\n",
      "Epoch [18/50], Step [150/735], Loss: 0.3707\n",
      "Epoch [18/50], Step [151/735], Loss: 0.5872\n",
      "Epoch [18/50], Step [152/735], Loss: 0.3458\n",
      "Epoch [18/50], Step [153/735], Loss: 0.2901\n",
      "Epoch [18/50], Step [154/735], Loss: 0.4121\n",
      "Epoch [18/50], Step [155/735], Loss: 0.8268\n",
      "Epoch [18/50], Step [156/735], Loss: 0.4027\n",
      "Epoch [18/50], Step [157/735], Loss: 0.0655\n",
      "Epoch [18/50], Step [158/735], Loss: 0.3983\n",
      "Epoch [18/50], Step [159/735], Loss: 0.1626\n",
      "Epoch [18/50], Step [160/735], Loss: 0.1908\n",
      "Epoch [18/50], Step [161/735], Loss: 4.8019\n",
      "Epoch [18/50], Step [162/735], Loss: 0.3750\n",
      "Epoch [18/50], Step [163/735], Loss: 0.6365\n",
      "Epoch [18/50], Step [164/735], Loss: 0.2863\n",
      "Epoch [18/50], Step [165/735], Loss: 0.5614\n",
      "Epoch [18/50], Step [166/735], Loss: 0.0681\n",
      "Epoch [18/50], Step [167/735], Loss: 0.1685\n",
      "Epoch [18/50], Step [168/735], Loss: 0.2733\n",
      "Epoch [18/50], Step [169/735], Loss: 0.6284\n",
      "Epoch [18/50], Step [170/735], Loss: 0.2082\n",
      "Epoch [18/50], Step [171/735], Loss: 0.1013\n",
      "Epoch [18/50], Step [172/735], Loss: 0.1636\n",
      "Epoch [18/50], Step [173/735], Loss: 0.3589\n",
      "Epoch [18/50], Step [174/735], Loss: 1.0324\n",
      "Epoch [18/50], Step [175/735], Loss: 0.3153\n",
      "Epoch [18/50], Step [176/735], Loss: 0.7871\n",
      "Epoch [18/50], Step [177/735], Loss: 0.6097\n",
      "Epoch [18/50], Step [178/735], Loss: 0.0688\n",
      "Epoch [18/50], Step [179/735], Loss: 0.4039\n",
      "Epoch [18/50], Step [180/735], Loss: 0.2041\n",
      "Epoch [18/50], Step [181/735], Loss: 0.0799\n",
      "Epoch [18/50], Step [182/735], Loss: 0.4359\n",
      "Epoch [18/50], Step [183/735], Loss: 0.4690\n",
      "Epoch [18/50], Step [184/735], Loss: 1.6296\n",
      "Epoch [18/50], Step [185/735], Loss: 0.5387\n",
      "Epoch [18/50], Step [186/735], Loss: 0.1266\n",
      "Epoch [18/50], Step [187/735], Loss: 0.2800\n",
      "Epoch [18/50], Step [188/735], Loss: 0.8212\n",
      "Epoch [18/50], Step [189/735], Loss: 0.6361\n",
      "Epoch [18/50], Step [190/735], Loss: 1.4157\n",
      "Epoch [18/50], Step [191/735], Loss: 0.1103\n",
      "Epoch [18/50], Step [192/735], Loss: 0.2069\n",
      "Epoch [18/50], Step [193/735], Loss: 0.5227\n",
      "Epoch [18/50], Step [194/735], Loss: 1.4328\n",
      "Epoch [18/50], Step [195/735], Loss: 0.0730\n",
      "Epoch [18/50], Step [196/735], Loss: 0.1130\n",
      "Epoch [18/50], Step [197/735], Loss: 0.4116\n",
      "Epoch [18/50], Step [198/735], Loss: 0.2056\n",
      "Epoch [18/50], Step [199/735], Loss: 0.2051\n",
      "Epoch [18/50], Step [200/735], Loss: 0.2849\n",
      "Epoch [18/50], Step [201/735], Loss: 0.2157\n",
      "Epoch [18/50], Step [202/735], Loss: 0.2573\n",
      "Epoch [18/50], Step [203/735], Loss: 0.3612\n",
      "Epoch [18/50], Step [204/735], Loss: 1.2272\n",
      "Epoch [18/50], Step [205/735], Loss: 0.3576\n",
      "Epoch [18/50], Step [206/735], Loss: 0.9923\n",
      "Epoch [18/50], Step [207/735], Loss: 1.2013\n",
      "Epoch [18/50], Step [208/735], Loss: 0.1759\n",
      "Epoch [18/50], Step [209/735], Loss: 0.5278\n",
      "Epoch [18/50], Step [210/735], Loss: 0.4459\n",
      "Epoch [18/50], Step [211/735], Loss: 0.3885\n",
      "Epoch [18/50], Step [212/735], Loss: 0.7927\n",
      "Epoch [18/50], Step [213/735], Loss: 0.2867\n",
      "Epoch [18/50], Step [214/735], Loss: 0.5758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Step [215/735], Loss: 0.2473\n",
      "Epoch [18/50], Step [216/735], Loss: 0.5229\n",
      "Epoch [18/50], Step [217/735], Loss: 0.3047\n",
      "Epoch [18/50], Step [218/735], Loss: 1.9003\n",
      "Epoch [18/50], Step [219/735], Loss: 0.6010\n",
      "Epoch [18/50], Step [220/735], Loss: 0.1886\n",
      "Epoch [18/50], Step [221/735], Loss: 0.1684\n",
      "Epoch [18/50], Step [222/735], Loss: 0.3463\n",
      "Epoch [18/50], Step [223/735], Loss: 1.2769\n",
      "Epoch [18/50], Step [224/735], Loss: 5.0425\n",
      "Epoch [18/50], Step [225/735], Loss: 0.1213\n",
      "Epoch [18/50], Step [226/735], Loss: 0.3549\n",
      "Epoch [18/50], Step [227/735], Loss: 0.3855\n",
      "Epoch [18/50], Step [228/735], Loss: 0.3490\n",
      "Epoch [18/50], Step [229/735], Loss: 0.2714\n",
      "Epoch [18/50], Step [230/735], Loss: 0.2160\n",
      "Epoch [18/50], Step [231/735], Loss: 4.5610\n",
      "Epoch [18/50], Step [232/735], Loss: 1.0012\n",
      "Epoch [18/50], Step [233/735], Loss: 0.3025\n",
      "Epoch [18/50], Step [234/735], Loss: 0.2245\n",
      "Epoch [18/50], Step [235/735], Loss: 0.5675\n",
      "Epoch [18/50], Step [236/735], Loss: 0.5897\n",
      "Epoch [18/50], Step [237/735], Loss: 0.4343\n",
      "Epoch [18/50], Step [238/735], Loss: 0.3254\n",
      "Epoch [18/50], Step [239/735], Loss: 0.1983\n",
      "Epoch [18/50], Step [240/735], Loss: 0.5048\n",
      "Epoch [18/50], Step [241/735], Loss: 0.4314\n",
      "Epoch [18/50], Step [242/735], Loss: 0.1616\n",
      "Epoch [18/50], Step [243/735], Loss: 0.2281\n",
      "Epoch [18/50], Step [244/735], Loss: 0.2788\n",
      "Epoch [18/50], Step [245/735], Loss: 0.5019\n",
      "Epoch [18/50], Step [246/735], Loss: 0.6570\n",
      "Epoch [18/50], Step [247/735], Loss: 0.6017\n",
      "Epoch [18/50], Step [248/735], Loss: 0.5197\n",
      "Epoch [18/50], Step [249/735], Loss: 0.3933\n",
      "Epoch [18/50], Step [250/735], Loss: 0.1690\n",
      "Epoch [18/50], Step [251/735], Loss: 0.1401\n",
      "Epoch [18/50], Step [252/735], Loss: 0.4830\n",
      "Epoch [18/50], Step [253/735], Loss: 0.1005\n",
      "Epoch [18/50], Step [254/735], Loss: 0.3177\n",
      "Epoch [18/50], Step [255/735], Loss: 0.5663\n",
      "Epoch [18/50], Step [256/735], Loss: 0.1101\n",
      "Epoch [18/50], Step [257/735], Loss: 0.5224\n",
      "Epoch [18/50], Step [258/735], Loss: 5.2134\n",
      "Epoch [18/50], Step [259/735], Loss: 0.3166\n",
      "Epoch [18/50], Step [260/735], Loss: 0.0891\n",
      "Epoch [18/50], Step [261/735], Loss: 0.1404\n",
      "Epoch [18/50], Step [262/735], Loss: 1.3230\n",
      "Epoch [18/50], Step [263/735], Loss: 0.5751\n",
      "Epoch [18/50], Step [264/735], Loss: 0.1569\n",
      "Epoch [18/50], Step [265/735], Loss: 0.5812\n",
      "Epoch [18/50], Step [266/735], Loss: 0.1294\n",
      "Epoch [18/50], Step [267/735], Loss: 0.3379\n",
      "Epoch [18/50], Step [268/735], Loss: 0.2472\n",
      "Epoch [18/50], Step [269/735], Loss: 0.4813\n",
      "Epoch [18/50], Step [270/735], Loss: 0.2830\n",
      "Epoch [18/50], Step [271/735], Loss: 0.4713\n",
      "Epoch [18/50], Step [272/735], Loss: 0.2259\n",
      "Epoch [18/50], Step [273/735], Loss: 0.3092\n",
      "Epoch [18/50], Step [274/735], Loss: 0.8261\n",
      "Epoch [18/50], Step [275/735], Loss: 0.1988\n",
      "Epoch [18/50], Step [276/735], Loss: 0.5137\n",
      "Epoch [18/50], Step [277/735], Loss: 0.2362\n",
      "Epoch [18/50], Step [278/735], Loss: 0.5627\n",
      "Epoch [18/50], Step [279/735], Loss: 1.2179\n",
      "Epoch [18/50], Step [280/735], Loss: 0.4786\n",
      "Epoch [18/50], Step [281/735], Loss: 1.1566\n",
      "Epoch [18/50], Step [282/735], Loss: 0.8315\n",
      "Epoch [18/50], Step [283/735], Loss: 0.1794\n",
      "Epoch [18/50], Step [284/735], Loss: 0.6809\n",
      "Epoch [18/50], Step [285/735], Loss: 0.4615\n",
      "Epoch [18/50], Step [286/735], Loss: 0.6540\n",
      "Epoch [18/50], Step [287/735], Loss: 0.1694\n",
      "Epoch [18/50], Step [288/735], Loss: 0.1651\n",
      "Epoch [18/50], Step [289/735], Loss: 0.2481\n",
      "Epoch [18/50], Step [290/735], Loss: 0.0619\n",
      "Epoch [18/50], Step [291/735], Loss: 0.2919\n",
      "Epoch [18/50], Step [292/735], Loss: 0.2213\n",
      "Epoch [18/50], Step [293/735], Loss: 0.3542\n",
      "Epoch [18/50], Step [294/735], Loss: 0.3076\n",
      "Epoch [18/50], Step [295/735], Loss: 0.2654\n",
      "Epoch [18/50], Step [296/735], Loss: 0.5129\n",
      "Epoch [18/50], Step [297/735], Loss: 0.4108\n",
      "Epoch [18/50], Step [298/735], Loss: 0.4841\n",
      "Epoch [18/50], Step [299/735], Loss: 0.9022\n",
      "Epoch [18/50], Step [300/735], Loss: 0.6216\n",
      "Epoch [18/50], Step [301/735], Loss: 0.1851\n",
      "Epoch [18/50], Step [302/735], Loss: 0.6119\n",
      "Epoch [18/50], Step [303/735], Loss: 0.1215\n",
      "Epoch [18/50], Step [304/735], Loss: 0.2236\n",
      "Epoch [18/50], Step [305/735], Loss: 0.2990\n",
      "Epoch [18/50], Step [306/735], Loss: 0.4274\n",
      "Epoch [18/50], Step [307/735], Loss: 0.2911\n",
      "Epoch [18/50], Step [308/735], Loss: 0.1696\n",
      "Epoch [18/50], Step [309/735], Loss: 0.8578\n",
      "Epoch [18/50], Step [310/735], Loss: 0.4782\n",
      "Epoch [18/50], Step [311/735], Loss: 0.4528\n",
      "Epoch [18/50], Step [312/735], Loss: 0.1673\n",
      "Epoch [18/50], Step [313/735], Loss: 0.1051\n",
      "Epoch [18/50], Step [314/735], Loss: 0.3588\n",
      "Epoch [18/50], Step [315/735], Loss: 0.2542\n",
      "Epoch [18/50], Step [316/735], Loss: 0.6366\n",
      "Epoch [18/50], Step [317/735], Loss: 0.6424\n",
      "Epoch [18/50], Step [318/735], Loss: 0.1076\n",
      "Epoch [18/50], Step [319/735], Loss: 0.6426\n",
      "Epoch [18/50], Step [320/735], Loss: 0.4319\n",
      "Epoch [18/50], Step [321/735], Loss: 0.0823\n",
      "Epoch [18/50], Step [322/735], Loss: 0.6922\n",
      "Epoch [18/50], Step [323/735], Loss: 0.5549\n",
      "Epoch [18/50], Step [324/735], Loss: 0.7836\n",
      "Epoch [18/50], Step [325/735], Loss: 0.1577\n",
      "Epoch [18/50], Step [326/735], Loss: 0.8270\n",
      "Epoch [18/50], Step [327/735], Loss: 0.2652\n",
      "Epoch [18/50], Step [328/735], Loss: 0.0542\n",
      "Epoch [18/50], Step [329/735], Loss: 0.1932\n",
      "Epoch [18/50], Step [330/735], Loss: 1.1910\n",
      "Epoch [18/50], Step [331/735], Loss: 0.1107\n",
      "Epoch [18/50], Step [332/735], Loss: 0.0939\n",
      "Epoch [18/50], Step [333/735], Loss: 0.6189\n",
      "Epoch [18/50], Step [334/735], Loss: 1.6971\n",
      "Epoch [18/50], Step [335/735], Loss: 0.3291\n",
      "Epoch [18/50], Step [336/735], Loss: 0.3040\n",
      "Epoch [18/50], Step [337/735], Loss: 0.4917\n",
      "Epoch [18/50], Step [338/735], Loss: 0.8135\n",
      "Epoch [18/50], Step [339/735], Loss: 1.5257\n",
      "Epoch [18/50], Step [340/735], Loss: 0.1561\n",
      "Epoch [18/50], Step [341/735], Loss: 0.5974\n",
      "Epoch [18/50], Step [342/735], Loss: 0.5937\n",
      "Epoch [18/50], Step [343/735], Loss: 0.0522\n",
      "Epoch [18/50], Step [344/735], Loss: 0.9000\n",
      "Epoch [18/50], Step [345/735], Loss: 0.6168\n",
      "Epoch [18/50], Step [346/735], Loss: 0.9442\n",
      "Epoch [18/50], Step [347/735], Loss: 0.1762\n",
      "Epoch [18/50], Step [348/735], Loss: 0.1240\n",
      "Epoch [18/50], Step [349/735], Loss: 0.1856\n",
      "Epoch [18/50], Step [350/735], Loss: 0.2067\n",
      "Epoch [18/50], Step [351/735], Loss: 0.3181\n",
      "Epoch [18/50], Step [352/735], Loss: 0.2346\n",
      "Epoch [18/50], Step [353/735], Loss: 0.3008\n",
      "Epoch [18/50], Step [354/735], Loss: 0.1219\n",
      "Epoch [18/50], Step [355/735], Loss: 0.5657\n",
      "Epoch [18/50], Step [356/735], Loss: 0.3031\n",
      "Epoch [18/50], Step [357/735], Loss: 0.2498\n",
      "Epoch [18/50], Step [358/735], Loss: 0.3372\n",
      "Epoch [18/50], Step [359/735], Loss: 0.4478\n",
      "Epoch [18/50], Step [360/735], Loss: 0.4090\n",
      "Epoch [18/50], Step [361/735], Loss: 0.4150\n",
      "Epoch [18/50], Step [362/735], Loss: 0.8061\n",
      "Epoch [18/50], Step [363/735], Loss: 0.4372\n",
      "Epoch [18/50], Step [364/735], Loss: 0.1362\n",
      "Epoch [18/50], Step [365/735], Loss: 0.3301\n",
      "Epoch [18/50], Step [366/735], Loss: 0.4955\n",
      "Epoch [18/50], Step [367/735], Loss: 0.2758\n",
      "Epoch [18/50], Step [368/735], Loss: 0.0874\n",
      "Epoch [18/50], Step [369/735], Loss: 0.1452\n",
      "Epoch [18/50], Step [370/735], Loss: 0.5242\n",
      "Epoch [18/50], Step [371/735], Loss: 1.6542\n",
      "Epoch [18/50], Step [372/735], Loss: 0.3216\n",
      "Epoch [18/50], Step [373/735], Loss: 0.0814\n",
      "Epoch [18/50], Step [374/735], Loss: 1.2054\n",
      "Epoch [18/50], Step [375/735], Loss: 0.3722\n",
      "Epoch [18/50], Step [376/735], Loss: 0.9297\n",
      "Epoch [18/50], Step [377/735], Loss: 0.3115\n",
      "Epoch [18/50], Step [378/735], Loss: 0.2859\n",
      "Epoch [18/50], Step [379/735], Loss: 0.3403\n",
      "Epoch [18/50], Step [380/735], Loss: 0.3305\n",
      "Epoch [18/50], Step [381/735], Loss: 0.2508\n",
      "Epoch [18/50], Step [382/735], Loss: 0.2771\n",
      "Epoch [18/50], Step [383/735], Loss: 0.2365\n",
      "Epoch [18/50], Step [384/735], Loss: 0.5819\n",
      "Epoch [18/50], Step [385/735], Loss: 0.1518\n",
      "Epoch [18/50], Step [386/735], Loss: 0.6318\n",
      "Epoch [18/50], Step [387/735], Loss: 0.4278\n",
      "Epoch [18/50], Step [388/735], Loss: 0.4480\n",
      "Epoch [18/50], Step [389/735], Loss: 0.4946\n",
      "Epoch [18/50], Step [390/735], Loss: 0.0776\n",
      "Epoch [18/50], Step [391/735], Loss: 0.0886\n",
      "Epoch [18/50], Step [392/735], Loss: 0.6350\n",
      "Epoch [18/50], Step [393/735], Loss: 0.4984\n",
      "Epoch [18/50], Step [394/735], Loss: 0.2775\n",
      "Epoch [18/50], Step [395/735], Loss: 0.1753\n",
      "Epoch [18/50], Step [396/735], Loss: 0.1155\n",
      "Epoch [18/50], Step [397/735], Loss: 0.2156\n",
      "Epoch [18/50], Step [398/735], Loss: 0.1940\n",
      "Epoch [18/50], Step [399/735], Loss: 0.2260\n",
      "Epoch [18/50], Step [400/735], Loss: 0.3168\n",
      "Epoch [18/50], Step [401/735], Loss: 0.2604\n",
      "Epoch [18/50], Step [402/735], Loss: 0.1667\n",
      "Epoch [18/50], Step [403/735], Loss: 0.2389\n",
      "Epoch [18/50], Step [404/735], Loss: 0.1107\n",
      "Epoch [18/50], Step [405/735], Loss: 0.3858\n",
      "Epoch [18/50], Step [406/735], Loss: 0.0558\n",
      "Epoch [18/50], Step [407/735], Loss: 0.3669\n",
      "Epoch [18/50], Step [408/735], Loss: 0.4821\n",
      "Epoch [18/50], Step [409/735], Loss: 0.2046\n",
      "Epoch [18/50], Step [410/735], Loss: 0.7228\n",
      "Epoch [18/50], Step [411/735], Loss: 0.3407\n",
      "Epoch [18/50], Step [412/735], Loss: 0.4395\n",
      "Epoch [18/50], Step [413/735], Loss: 0.1154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Step [414/735], Loss: 0.1402\n",
      "Epoch [18/50], Step [415/735], Loss: 0.2506\n",
      "Epoch [18/50], Step [416/735], Loss: 0.1612\n",
      "Epoch [18/50], Step [417/735], Loss: 0.2438\n",
      "Epoch [18/50], Step [418/735], Loss: 0.0905\n",
      "Epoch [18/50], Step [419/735], Loss: 0.5648\n",
      "Epoch [18/50], Step [420/735], Loss: 1.3304\n",
      "Epoch [18/50], Step [421/735], Loss: 0.3317\n",
      "Epoch [18/50], Step [422/735], Loss: 0.1967\n",
      "Epoch [18/50], Step [423/735], Loss: 0.1644\n",
      "Epoch [18/50], Step [424/735], Loss: 0.5164\n",
      "Epoch [18/50], Step [425/735], Loss: 0.9435\n",
      "Epoch [18/50], Step [426/735], Loss: 0.4911\n",
      "Epoch [18/50], Step [427/735], Loss: 0.3437\n",
      "Epoch [18/50], Step [428/735], Loss: 0.4215\n",
      "Epoch [18/50], Step [429/735], Loss: 0.2714\n",
      "Epoch [18/50], Step [430/735], Loss: 0.3282\n",
      "Epoch [18/50], Step [431/735], Loss: 0.0792\n",
      "Epoch [18/50], Step [432/735], Loss: 0.8820\n",
      "Epoch [18/50], Step [433/735], Loss: 0.2968\n",
      "Epoch [18/50], Step [434/735], Loss: 0.1656\n",
      "Epoch [18/50], Step [435/735], Loss: 0.2788\n",
      "Epoch [18/50], Step [436/735], Loss: 0.1228\n",
      "Epoch [18/50], Step [437/735], Loss: 2.0790\n",
      "Epoch [18/50], Step [438/735], Loss: 0.7543\n",
      "Epoch [18/50], Step [439/735], Loss: 0.7762\n",
      "Epoch [18/50], Step [440/735], Loss: 0.0578\n",
      "Epoch [18/50], Step [441/735], Loss: 0.8108\n",
      "Epoch [18/50], Step [442/735], Loss: 0.6202\n",
      "Epoch [18/50], Step [443/735], Loss: 0.3046\n",
      "Epoch [18/50], Step [444/735], Loss: 0.6398\n",
      "Epoch [18/50], Step [445/735], Loss: 0.2764\n",
      "Epoch [18/50], Step [446/735], Loss: 0.0834\n",
      "Epoch [18/50], Step [447/735], Loss: 0.9192\n",
      "Epoch [18/50], Step [448/735], Loss: 0.3189\n",
      "Epoch [18/50], Step [449/735], Loss: 0.6390\n",
      "Epoch [18/50], Step [450/735], Loss: 0.2863\n",
      "Epoch [18/50], Step [451/735], Loss: 0.2237\n",
      "Epoch [18/50], Step [452/735], Loss: 1.3115\n",
      "Epoch [18/50], Step [453/735], Loss: 1.1474\n",
      "Epoch [18/50], Step [454/735], Loss: 0.8783\n",
      "Epoch [18/50], Step [455/735], Loss: 0.3542\n",
      "Epoch [18/50], Step [456/735], Loss: 0.1115\n",
      "Epoch [18/50], Step [457/735], Loss: 0.2110\n",
      "Epoch [18/50], Step [458/735], Loss: 0.0789\n",
      "Epoch [18/50], Step [459/735], Loss: 0.3398\n",
      "Epoch [18/50], Step [460/735], Loss: 0.8930\n",
      "Epoch [18/50], Step [461/735], Loss: 0.4312\n",
      "Epoch [18/50], Step [462/735], Loss: 0.8720\n",
      "Epoch [18/50], Step [463/735], Loss: 0.2043\n",
      "Epoch [18/50], Step [464/735], Loss: 0.4282\n",
      "Epoch [18/50], Step [465/735], Loss: 0.4400\n",
      "Epoch [18/50], Step [466/735], Loss: 0.2447\n",
      "Epoch [18/50], Step [467/735], Loss: 0.4674\n",
      "Epoch [18/50], Step [468/735], Loss: 0.3005\n",
      "Epoch [18/50], Step [469/735], Loss: 0.2995\n",
      "Epoch [18/50], Step [470/735], Loss: 1.3113\n",
      "Epoch [18/50], Step [471/735], Loss: 0.3753\n",
      "Epoch [18/50], Step [472/735], Loss: 0.3193\n",
      "Epoch [18/50], Step [473/735], Loss: 0.2248\n",
      "Epoch [18/50], Step [474/735], Loss: 0.4352\n",
      "Epoch [18/50], Step [475/735], Loss: 0.2832\n",
      "Epoch [18/50], Step [476/735], Loss: 1.3945\n",
      "Epoch [18/50], Step [477/735], Loss: 0.3308\n",
      "Epoch [18/50], Step [478/735], Loss: 0.1852\n",
      "Epoch [18/50], Step [479/735], Loss: 0.4317\n",
      "Epoch [18/50], Step [480/735], Loss: 0.7539\n",
      "Epoch [18/50], Step [481/735], Loss: 0.1834\n",
      "Epoch [18/50], Step [482/735], Loss: 0.2434\n",
      "Epoch [18/50], Step [483/735], Loss: 0.8287\n",
      "Epoch [18/50], Step [484/735], Loss: 0.6585\n",
      "Epoch [18/50], Step [485/735], Loss: 0.2912\n",
      "Epoch [18/50], Step [486/735], Loss: 0.8862\n",
      "Epoch [18/50], Step [487/735], Loss: 0.4444\n",
      "Epoch [18/50], Step [488/735], Loss: 0.3868\n",
      "Epoch [18/50], Step [489/735], Loss: 0.4124\n",
      "Epoch [18/50], Step [490/735], Loss: 0.1978\n",
      "Epoch [18/50], Step [491/735], Loss: 0.7117\n",
      "Epoch [18/50], Step [492/735], Loss: 0.2563\n",
      "Epoch [18/50], Step [493/735], Loss: 0.3515\n",
      "Epoch [18/50], Step [494/735], Loss: 0.1111\n",
      "Epoch [18/50], Step [495/735], Loss: 0.1372\n",
      "Epoch [18/50], Step [496/735], Loss: 0.5429\n",
      "Epoch [18/50], Step [497/735], Loss: 0.2297\n",
      "Epoch [18/50], Step [498/735], Loss: 0.4946\n",
      "Epoch [18/50], Step [499/735], Loss: 0.4734\n",
      "Epoch [18/50], Step [500/735], Loss: 0.3812\n",
      "Epoch [18/50], Step [501/735], Loss: 0.2814\n",
      "Epoch [18/50], Step [502/735], Loss: 0.2203\n",
      "Epoch [18/50], Step [503/735], Loss: 0.1923\n",
      "Epoch [18/50], Step [504/735], Loss: 1.1903\n",
      "Epoch [18/50], Step [505/735], Loss: 0.7795\n",
      "Epoch [18/50], Step [506/735], Loss: 0.4033\n",
      "Epoch [18/50], Step [507/735], Loss: 0.5812\n",
      "Epoch [18/50], Step [508/735], Loss: 1.2177\n",
      "Epoch [18/50], Step [509/735], Loss: 0.3234\n",
      "Epoch [18/50], Step [510/735], Loss: 0.7236\n",
      "Epoch [18/50], Step [511/735], Loss: 0.9484\n",
      "Epoch [18/50], Step [512/735], Loss: 0.2876\n",
      "Epoch [18/50], Step [513/735], Loss: 0.5626\n",
      "Epoch [18/50], Step [514/735], Loss: 0.5042\n",
      "Epoch [18/50], Step [515/735], Loss: 0.2859\n",
      "Epoch [18/50], Step [516/735], Loss: 0.7831\n",
      "Epoch [18/50], Step [517/735], Loss: 0.9320\n",
      "Epoch [18/50], Step [518/735], Loss: 0.3412\n",
      "Epoch [18/50], Step [519/735], Loss: 0.3295\n",
      "Epoch [18/50], Step [520/735], Loss: 0.5512\n",
      "Epoch [18/50], Step [521/735], Loss: 0.6596\n",
      "Epoch [18/50], Step [522/735], Loss: 0.3894\n",
      "Epoch [18/50], Step [523/735], Loss: 0.4548\n",
      "Epoch [18/50], Step [524/735], Loss: 0.4484\n",
      "Epoch [18/50], Step [525/735], Loss: 0.4192\n",
      "Epoch [18/50], Step [526/735], Loss: 0.3743\n",
      "Epoch [18/50], Step [527/735], Loss: 0.5069\n",
      "Epoch [18/50], Step [528/735], Loss: 0.2583\n",
      "Epoch [18/50], Step [529/735], Loss: 0.5915\n",
      "Epoch [18/50], Step [530/735], Loss: 1.2160\n",
      "Epoch [18/50], Step [531/735], Loss: 0.3277\n",
      "Epoch [18/50], Step [532/735], Loss: 0.3456\n",
      "Epoch [18/50], Step [533/735], Loss: 0.1877\n",
      "Epoch [18/50], Step [534/735], Loss: 0.6687\n",
      "Epoch [18/50], Step [535/735], Loss: 0.5608\n",
      "Epoch [18/50], Step [536/735], Loss: 0.2314\n",
      "Epoch [18/50], Step [537/735], Loss: 0.1425\n",
      "Epoch [18/50], Step [538/735], Loss: 1.1491\n",
      "Epoch [18/50], Step [539/735], Loss: 0.2646\n",
      "Epoch [18/50], Step [540/735], Loss: 0.9643\n",
      "Epoch [18/50], Step [541/735], Loss: 0.5523\n",
      "Epoch [18/50], Step [542/735], Loss: 0.0726\n",
      "Epoch [18/50], Step [543/735], Loss: 0.7763\n",
      "Epoch [18/50], Step [544/735], Loss: 0.1203\n",
      "Epoch [18/50], Step [545/735], Loss: 0.1522\n",
      "Epoch [18/50], Step [546/735], Loss: 0.7299\n",
      "Epoch [18/50], Step [547/735], Loss: 0.4339\n",
      "Epoch [18/50], Step [548/735], Loss: 2.6816\n",
      "Epoch [18/50], Step [549/735], Loss: 0.5046\n",
      "Epoch [18/50], Step [550/735], Loss: 0.5736\n",
      "Epoch [18/50], Step [551/735], Loss: 0.2599\n",
      "Epoch [18/50], Step [552/735], Loss: 0.6366\n",
      "Epoch [18/50], Step [553/735], Loss: 1.0840\n",
      "Epoch [18/50], Step [554/735], Loss: 0.2534\n",
      "Epoch [18/50], Step [555/735], Loss: 0.5450\n",
      "Epoch [18/50], Step [556/735], Loss: 0.3843\n",
      "Epoch [18/50], Step [557/735], Loss: 0.5222\n",
      "Epoch [18/50], Step [558/735], Loss: 0.1217\n",
      "Epoch [18/50], Step [559/735], Loss: 0.0888\n",
      "Epoch [18/50], Step [560/735], Loss: 0.3817\n",
      "Epoch [18/50], Step [561/735], Loss: 0.1762\n",
      "Epoch [18/50], Step [562/735], Loss: 0.7300\n",
      "Epoch [18/50], Step [563/735], Loss: 0.1144\n",
      "Epoch [18/50], Step [564/735], Loss: 0.1594\n",
      "Epoch [18/50], Step [565/735], Loss: 1.9006\n",
      "Epoch [18/50], Step [566/735], Loss: 0.6006\n",
      "Epoch [18/50], Step [567/735], Loss: 0.3077\n",
      "Epoch [18/50], Step [568/735], Loss: 0.7183\n",
      "Epoch [18/50], Step [569/735], Loss: 0.5818\n",
      "Epoch [18/50], Step [570/735], Loss: 0.6305\n",
      "Epoch [18/50], Step [571/735], Loss: 0.3663\n",
      "Epoch [18/50], Step [572/735], Loss: 0.1004\n",
      "Epoch [18/50], Step [573/735], Loss: 0.4389\n",
      "Epoch [18/50], Step [574/735], Loss: 0.0988\n",
      "Epoch [18/50], Step [575/735], Loss: 0.3894\n",
      "Epoch [18/50], Step [576/735], Loss: 0.1532\n",
      "Epoch [18/50], Step [577/735], Loss: 0.7298\n",
      "Epoch [18/50], Step [578/735], Loss: 0.0935\n",
      "Epoch [18/50], Step [579/735], Loss: 0.0988\n",
      "Epoch [18/50], Step [580/735], Loss: 0.4166\n",
      "Epoch [18/50], Step [581/735], Loss: 0.2025\n",
      "Epoch [18/50], Step [582/735], Loss: 1.7205\n",
      "Epoch [18/50], Step [583/735], Loss: 0.1380\n",
      "Epoch [18/50], Step [584/735], Loss: 0.4819\n",
      "Epoch [18/50], Step [585/735], Loss: 0.3004\n",
      "Epoch [18/50], Step [586/735], Loss: 0.1781\n",
      "Epoch [18/50], Step [587/735], Loss: 0.3865\n",
      "Epoch [18/50], Step [588/735], Loss: 0.5819\n",
      "Epoch [18/50], Step [589/735], Loss: 0.0648\n",
      "Epoch [18/50], Step [590/735], Loss: 0.2506\n",
      "Epoch [18/50], Step [591/735], Loss: 0.2691\n",
      "Epoch [18/50], Step [592/735], Loss: 0.2557\n",
      "Epoch [18/50], Step [593/735], Loss: 0.2282\n",
      "Epoch [18/50], Step [594/735], Loss: 0.4967\n",
      "Epoch [18/50], Step [595/735], Loss: 0.7826\n",
      "Epoch [18/50], Step [596/735], Loss: 0.1879\n",
      "Epoch [18/50], Step [597/735], Loss: 0.6499\n",
      "Epoch [18/50], Step [598/735], Loss: 1.0266\n",
      "Epoch [18/50], Step [599/735], Loss: 0.2827\n",
      "Epoch [18/50], Step [600/735], Loss: 0.7417\n",
      "Epoch [18/50], Step [601/735], Loss: 0.1469\n",
      "Epoch [18/50], Step [602/735], Loss: 0.1559\n",
      "Epoch [18/50], Step [603/735], Loss: 0.9640\n",
      "Epoch [18/50], Step [604/735], Loss: 0.6932\n",
      "Epoch [18/50], Step [605/735], Loss: 0.6554\n",
      "Epoch [18/50], Step [606/735], Loss: 1.2149\n",
      "Epoch [18/50], Step [607/735], Loss: 0.0699\n",
      "Epoch [18/50], Step [608/735], Loss: 0.2601\n",
      "Epoch [18/50], Step [609/735], Loss: 0.1268\n",
      "Epoch [18/50], Step [610/735], Loss: 0.4678\n",
      "Epoch [18/50], Step [611/735], Loss: 0.5597\n",
      "Epoch [18/50], Step [612/735], Loss: 0.1671\n",
      "Epoch [18/50], Step [613/735], Loss: 1.0121\n",
      "Epoch [18/50], Step [614/735], Loss: 0.4451\n",
      "Epoch [18/50], Step [615/735], Loss: 0.1421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Step [616/735], Loss: 0.6857\n",
      "Epoch [18/50], Step [617/735], Loss: 0.1162\n",
      "Epoch [18/50], Step [618/735], Loss: 0.3171\n",
      "Epoch [18/50], Step [619/735], Loss: 0.1513\n",
      "Epoch [18/50], Step [620/735], Loss: 0.2565\n",
      "Epoch [18/50], Step [621/735], Loss: 0.4563\n",
      "Epoch [18/50], Step [622/735], Loss: 0.7422\n",
      "Epoch [18/50], Step [623/735], Loss: 0.3005\n",
      "Epoch [18/50], Step [624/735], Loss: 0.3483\n",
      "Epoch [18/50], Step [625/735], Loss: 0.4904\n",
      "Epoch [18/50], Step [626/735], Loss: 0.2336\n",
      "Epoch [18/50], Step [627/735], Loss: 0.1205\n",
      "Epoch [18/50], Step [628/735], Loss: 0.4799\n",
      "Epoch [18/50], Step [629/735], Loss: 0.3488\n",
      "Epoch [18/50], Step [630/735], Loss: 0.2332\n",
      "Epoch [18/50], Step [631/735], Loss: 0.7327\n",
      "Epoch [18/50], Step [632/735], Loss: 0.6796\n",
      "Epoch [18/50], Step [633/735], Loss: 0.9992\n",
      "Epoch [18/50], Step [634/735], Loss: 0.0763\n",
      "Epoch [18/50], Step [635/735], Loss: 0.1271\n",
      "Epoch [18/50], Step [636/735], Loss: 0.2016\n",
      "Epoch [18/50], Step [637/735], Loss: 0.5392\n",
      "Epoch [18/50], Step [638/735], Loss: 0.6769\n",
      "Epoch [18/50], Step [639/735], Loss: 0.1675\n",
      "Epoch [18/50], Step [640/735], Loss: 0.1703\n",
      "Epoch [18/50], Step [641/735], Loss: 0.6169\n",
      "Epoch [18/50], Step [642/735], Loss: 0.4358\n",
      "Epoch [18/50], Step [643/735], Loss: 0.8437\n",
      "Epoch [18/50], Step [644/735], Loss: 0.2855\n",
      "Epoch [18/50], Step [645/735], Loss: 0.2268\n",
      "Epoch [18/50], Step [646/735], Loss: 0.4121\n",
      "Epoch [18/50], Step [647/735], Loss: 0.4782\n",
      "Epoch [18/50], Step [648/735], Loss: 0.2767\n",
      "Epoch [18/50], Step [649/735], Loss: 0.2105\n",
      "Epoch [18/50], Step [650/735], Loss: 0.4565\n",
      "Epoch [18/50], Step [651/735], Loss: 0.1911\n",
      "Epoch [18/50], Step [652/735], Loss: 0.3743\n",
      "Epoch [18/50], Step [653/735], Loss: 0.5063\n",
      "Epoch [18/50], Step [654/735], Loss: 0.5857\n",
      "Epoch [18/50], Step [655/735], Loss: 0.0737\n",
      "Epoch [18/50], Step [656/735], Loss: 0.8288\n",
      "Epoch [18/50], Step [657/735], Loss: 0.5256\n",
      "Epoch [18/50], Step [658/735], Loss: 0.3138\n",
      "Epoch [18/50], Step [659/735], Loss: 0.2028\n",
      "Epoch [18/50], Step [660/735], Loss: 0.2190\n",
      "Epoch [18/50], Step [661/735], Loss: 0.3168\n",
      "Epoch [18/50], Step [662/735], Loss: 5.0251\n",
      "Epoch [18/50], Step [663/735], Loss: 0.5101\n",
      "Epoch [18/50], Step [664/735], Loss: 0.1710\n",
      "Epoch [18/50], Step [665/735], Loss: 0.9678\n",
      "Epoch [18/50], Step [666/735], Loss: 0.1575\n",
      "Epoch [18/50], Step [667/735], Loss: 0.4819\n",
      "Epoch [18/50], Step [668/735], Loss: 0.1388\n",
      "Epoch [18/50], Step [669/735], Loss: 0.5147\n",
      "Epoch [18/50], Step [670/735], Loss: 1.1593\n",
      "Epoch [18/50], Step [671/735], Loss: 0.7987\n",
      "Epoch [18/50], Step [672/735], Loss: 0.1195\n",
      "Epoch [18/50], Step [673/735], Loss: 0.4890\n",
      "Epoch [18/50], Step [674/735], Loss: 0.4940\n",
      "Epoch [18/50], Step [675/735], Loss: 0.3256\n",
      "Epoch [18/50], Step [676/735], Loss: 0.1394\n",
      "Epoch [18/50], Step [677/735], Loss: 0.2137\n",
      "Epoch [18/50], Step [678/735], Loss: 0.5703\n",
      "Epoch [18/50], Step [679/735], Loss: 0.2160\n",
      "Epoch [18/50], Step [680/735], Loss: 0.2829\n",
      "Epoch [18/50], Step [681/735], Loss: 0.3161\n",
      "Epoch [18/50], Step [682/735], Loss: 0.3527\n",
      "Epoch [18/50], Step [683/735], Loss: 0.2488\n",
      "Epoch [18/50], Step [684/735], Loss: 0.3247\n",
      "Epoch [18/50], Step [685/735], Loss: 0.2100\n",
      "Epoch [18/50], Step [686/735], Loss: 0.5622\n",
      "Epoch [18/50], Step [687/735], Loss: 0.0706\n",
      "Epoch [18/50], Step [688/735], Loss: 0.0916\n",
      "Epoch [18/50], Step [689/735], Loss: 0.7465\n",
      "Epoch [18/50], Step [690/735], Loss: 0.2414\n",
      "Epoch [18/50], Step [691/735], Loss: 0.1042\n",
      "Epoch [18/50], Step [692/735], Loss: 0.1740\n",
      "Epoch [18/50], Step [693/735], Loss: 0.8722\n",
      "Epoch [18/50], Step [694/735], Loss: 0.1551\n",
      "Epoch [18/50], Step [695/735], Loss: 0.2948\n",
      "Epoch [18/50], Step [696/735], Loss: 0.7778\n",
      "Epoch [18/50], Step [697/735], Loss: 0.4310\n",
      "Epoch [18/50], Step [698/735], Loss: 0.5360\n",
      "Epoch [18/50], Step [699/735], Loss: 0.2431\n",
      "Epoch [18/50], Step [700/735], Loss: 0.1122\n",
      "Epoch [18/50], Step [701/735], Loss: 0.3326\n",
      "Epoch [18/50], Step [702/735], Loss: 0.2689\n",
      "Epoch [18/50], Step [703/735], Loss: 0.3390\n",
      "Epoch [18/50], Step [704/735], Loss: 0.7069\n",
      "Epoch [18/50], Step [705/735], Loss: 0.9119\n",
      "Epoch [18/50], Step [706/735], Loss: 0.1898\n",
      "Epoch [18/50], Step [707/735], Loss: 0.6784\n",
      "Epoch [18/50], Step [708/735], Loss: 0.4841\n",
      "Epoch [18/50], Step [709/735], Loss: 0.8578\n",
      "Epoch [18/50], Step [710/735], Loss: 0.0803\n",
      "Epoch [18/50], Step [711/735], Loss: 0.0771\n",
      "Epoch [18/50], Step [712/735], Loss: 0.5876\n",
      "Epoch [18/50], Step [713/735], Loss: 0.2733\n",
      "Epoch [18/50], Step [714/735], Loss: 0.6355\n",
      "Epoch [18/50], Step [715/735], Loss: 0.2734\n",
      "Epoch [18/50], Step [716/735], Loss: 0.5849\n",
      "Epoch [18/50], Step [717/735], Loss: 0.8226\n",
      "Epoch [18/50], Step [718/735], Loss: 0.4585\n",
      "Epoch [18/50], Step [719/735], Loss: 0.3633\n",
      "Epoch [18/50], Step [720/735], Loss: 0.0819\n",
      "Epoch [18/50], Step [721/735], Loss: 0.2551\n",
      "Epoch [18/50], Step [722/735], Loss: 0.5419\n",
      "Epoch [18/50], Step [723/735], Loss: 0.3430\n",
      "Epoch [18/50], Step [724/735], Loss: 0.1612\n",
      "Epoch [18/50], Step [725/735], Loss: 0.2663\n",
      "Epoch [18/50], Step [726/735], Loss: 0.3125\n",
      "Epoch [18/50], Step [727/735], Loss: 0.2155\n",
      "Epoch [18/50], Step [728/735], Loss: 0.2539\n",
      "Epoch [18/50], Step [729/735], Loss: 0.3035\n",
      "Epoch [18/50], Step [730/735], Loss: 0.5066\n",
      "Epoch [18/50], Step [731/735], Loss: 0.2424\n",
      "Epoch [18/50], Step [732/735], Loss: 0.5123\n",
      "Epoch [18/50], Step [733/735], Loss: 0.7661\n",
      "Epoch [18/50], Step [734/735], Loss: 0.1738\n",
      "Epoch [18/50], Step [735/735], Loss: 0.8126\n",
      "Epoch [19/50], Step [1/735], Loss: 0.1755\n",
      "Epoch [19/50], Step [2/735], Loss: 1.0946\n",
      "Epoch [19/50], Step [3/735], Loss: 0.3480\n",
      "Epoch [19/50], Step [4/735], Loss: 0.4031\n",
      "Epoch [19/50], Step [5/735], Loss: 0.0403\n",
      "Epoch [19/50], Step [6/735], Loss: 0.1848\n",
      "Epoch [19/50], Step [7/735], Loss: 0.2162\n",
      "Epoch [19/50], Step [8/735], Loss: 0.2093\n",
      "Epoch [19/50], Step [9/735], Loss: 0.3569\n",
      "Epoch [19/50], Step [10/735], Loss: 0.7524\n",
      "Epoch [19/50], Step [11/735], Loss: 0.1314\n",
      "Epoch [19/50], Step [12/735], Loss: 0.3631\n",
      "Epoch [19/50], Step [13/735], Loss: 0.2198\n",
      "Epoch [19/50], Step [14/735], Loss: 0.6213\n",
      "Epoch [19/50], Step [15/735], Loss: 0.2988\n",
      "Epoch [19/50], Step [16/735], Loss: 0.3289\n",
      "Epoch [19/50], Step [17/735], Loss: 0.4146\n",
      "Epoch [19/50], Step [18/735], Loss: 1.6650\n",
      "Epoch [19/50], Step [19/735], Loss: 0.8025\n",
      "Epoch [19/50], Step [20/735], Loss: 0.1804\n",
      "Epoch [19/50], Step [21/735], Loss: 1.8682\n",
      "Epoch [19/50], Step [22/735], Loss: 0.1170\n",
      "Epoch [19/50], Step [23/735], Loss: 0.3868\n",
      "Epoch [19/50], Step [24/735], Loss: 1.6953\n",
      "Epoch [19/50], Step [25/735], Loss: 1.2409\n",
      "Epoch [19/50], Step [26/735], Loss: 0.3337\n",
      "Epoch [19/50], Step [27/735], Loss: 0.1201\n",
      "Epoch [19/50], Step [28/735], Loss: 0.2547\n",
      "Epoch [19/50], Step [29/735], Loss: 0.4912\n",
      "Epoch [19/50], Step [30/735], Loss: 0.7512\n",
      "Epoch [19/50], Step [31/735], Loss: 0.8489\n",
      "Epoch [19/50], Step [32/735], Loss: 0.1428\n",
      "Epoch [19/50], Step [33/735], Loss: 0.3389\n",
      "Epoch [19/50], Step [34/735], Loss: 0.3355\n",
      "Epoch [19/50], Step [35/735], Loss: 0.2970\n",
      "Epoch [19/50], Step [36/735], Loss: 0.1862\n",
      "Epoch [19/50], Step [37/735], Loss: 0.2297\n",
      "Epoch [19/50], Step [38/735], Loss: 0.1171\n",
      "Epoch [19/50], Step [39/735], Loss: 0.3339\n",
      "Epoch [19/50], Step [40/735], Loss: 0.5328\n",
      "Epoch [19/50], Step [41/735], Loss: 0.1920\n",
      "Epoch [19/50], Step [42/735], Loss: 1.4024\n",
      "Epoch [19/50], Step [43/735], Loss: 0.2973\n",
      "Epoch [19/50], Step [44/735], Loss: 0.6589\n",
      "Epoch [19/50], Step [45/735], Loss: 0.2883\n",
      "Epoch [19/50], Step [46/735], Loss: 0.3666\n",
      "Epoch [19/50], Step [47/735], Loss: 0.1047\n",
      "Epoch [19/50], Step [48/735], Loss: 0.1924\n",
      "Epoch [19/50], Step [49/735], Loss: 0.3824\n",
      "Epoch [19/50], Step [50/735], Loss: 0.2691\n",
      "Epoch [19/50], Step [51/735], Loss: 0.6972\n",
      "Epoch [19/50], Step [52/735], Loss: 0.8271\n",
      "Epoch [19/50], Step [53/735], Loss: 0.0689\n",
      "Epoch [19/50], Step [54/735], Loss: 0.3374\n",
      "Epoch [19/50], Step [55/735], Loss: 0.0607\n",
      "Epoch [19/50], Step [56/735], Loss: 0.1643\n",
      "Epoch [19/50], Step [57/735], Loss: 0.2688\n",
      "Epoch [19/50], Step [58/735], Loss: 0.2055\n",
      "Epoch [19/50], Step [59/735], Loss: 0.0784\n",
      "Epoch [19/50], Step [60/735], Loss: 0.2425\n",
      "Epoch [19/50], Step [61/735], Loss: 0.5197\n",
      "Epoch [19/50], Step [62/735], Loss: 0.1487\n",
      "Epoch [19/50], Step [63/735], Loss: 0.5280\n",
      "Epoch [19/50], Step [64/735], Loss: 0.2207\n",
      "Epoch [19/50], Step [65/735], Loss: 0.1393\n",
      "Epoch [19/50], Step [66/735], Loss: 0.6699\n",
      "Epoch [19/50], Step [67/735], Loss: 0.0683\n",
      "Epoch [19/50], Step [68/735], Loss: 0.2631\n",
      "Epoch [19/50], Step [69/735], Loss: 0.0890\n",
      "Epoch [19/50], Step [70/735], Loss: 0.2736\n",
      "Epoch [19/50], Step [71/735], Loss: 0.2923\n",
      "Epoch [19/50], Step [72/735], Loss: 1.4120\n",
      "Epoch [19/50], Step [73/735], Loss: 0.1227\n",
      "Epoch [19/50], Step [74/735], Loss: 0.2953\n",
      "Epoch [19/50], Step [75/735], Loss: 0.3607\n",
      "Epoch [19/50], Step [76/735], Loss: 0.4271\n",
      "Epoch [19/50], Step [77/735], Loss: 2.0697\n",
      "Epoch [19/50], Step [78/735], Loss: 0.3523\n",
      "Epoch [19/50], Step [79/735], Loss: 0.7974\n",
      "Epoch [19/50], Step [80/735], Loss: 0.1504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Step [81/735], Loss: 0.1155\n",
      "Epoch [19/50], Step [82/735], Loss: 0.2912\n",
      "Epoch [19/50], Step [83/735], Loss: 0.3534\n",
      "Epoch [19/50], Step [84/735], Loss: 0.2774\n",
      "Epoch [19/50], Step [85/735], Loss: 0.7733\n",
      "Epoch [19/50], Step [86/735], Loss: 0.1096\n",
      "Epoch [19/50], Step [87/735], Loss: 0.2816\n",
      "Epoch [19/50], Step [88/735], Loss: 0.7976\n",
      "Epoch [19/50], Step [89/735], Loss: 0.3683\n",
      "Epoch [19/50], Step [90/735], Loss: 0.9969\n",
      "Epoch [19/50], Step [91/735], Loss: 0.2103\n",
      "Epoch [19/50], Step [92/735], Loss: 0.1906\n",
      "Epoch [19/50], Step [93/735], Loss: 0.1948\n",
      "Epoch [19/50], Step [94/735], Loss: 0.1110\n",
      "Epoch [19/50], Step [95/735], Loss: 0.0519\n",
      "Epoch [19/50], Step [96/735], Loss: 0.1937\n",
      "Epoch [19/50], Step [97/735], Loss: 1.6404\n",
      "Epoch [19/50], Step [98/735], Loss: 0.1395\n",
      "Epoch [19/50], Step [99/735], Loss: 0.6144\n",
      "Epoch [19/50], Step [100/735], Loss: 1.6971\n",
      "Epoch [19/50], Step [101/735], Loss: 0.1266\n",
      "Epoch [19/50], Step [102/735], Loss: 0.6035\n",
      "Epoch [19/50], Step [103/735], Loss: 0.2449\n",
      "Epoch [19/50], Step [104/735], Loss: 0.0891\n",
      "Epoch [19/50], Step [105/735], Loss: 0.2320\n",
      "Epoch [19/50], Step [106/735], Loss: 0.1218\n",
      "Epoch [19/50], Step [107/735], Loss: 0.1006\n",
      "Epoch [19/50], Step [108/735], Loss: 0.1883\n",
      "Epoch [19/50], Step [109/735], Loss: 0.4715\n",
      "Epoch [19/50], Step [110/735], Loss: 0.0597\n",
      "Epoch [19/50], Step [111/735], Loss: 0.2805\n",
      "Epoch [19/50], Step [112/735], Loss: 0.2181\n",
      "Epoch [19/50], Step [113/735], Loss: 0.1098\n",
      "Epoch [19/50], Step [114/735], Loss: 0.2914\n",
      "Epoch [19/50], Step [115/735], Loss: 0.1033\n",
      "Epoch [19/50], Step [116/735], Loss: 0.9646\n",
      "Epoch [19/50], Step [117/735], Loss: 0.3024\n",
      "Epoch [19/50], Step [118/735], Loss: 0.8281\n",
      "Epoch [19/50], Step [119/735], Loss: 0.4971\n",
      "Epoch [19/50], Step [120/735], Loss: 0.1509\n",
      "Epoch [19/50], Step [121/735], Loss: 1.1355\n",
      "Epoch [19/50], Step [122/735], Loss: 0.1714\n",
      "Epoch [19/50], Step [123/735], Loss: 0.1667\n",
      "Epoch [19/50], Step [124/735], Loss: 0.3471\n",
      "Epoch [19/50], Step [125/735], Loss: 0.0731\n",
      "Epoch [19/50], Step [126/735], Loss: 0.3274\n",
      "Epoch [19/50], Step [127/735], Loss: 0.3824\n",
      "Epoch [19/50], Step [128/735], Loss: 0.7549\n",
      "Epoch [19/50], Step [129/735], Loss: 0.3507\n",
      "Epoch [19/50], Step [130/735], Loss: 0.1766\n",
      "Epoch [19/50], Step [131/735], Loss: 0.3710\n",
      "Epoch [19/50], Step [132/735], Loss: 0.2243\n",
      "Epoch [19/50], Step [133/735], Loss: 0.3065\n",
      "Epoch [19/50], Step [134/735], Loss: 0.5095\n",
      "Epoch [19/50], Step [135/735], Loss: 0.2166\n",
      "Epoch [19/50], Step [136/735], Loss: 0.3117\n",
      "Epoch [19/50], Step [137/735], Loss: 0.0636\n",
      "Epoch [19/50], Step [138/735], Loss: 0.1675\n",
      "Epoch [19/50], Step [139/735], Loss: 0.5997\n",
      "Epoch [19/50], Step [140/735], Loss: 0.1872\n",
      "Epoch [19/50], Step [141/735], Loss: 0.2399\n",
      "Epoch [19/50], Step [142/735], Loss: 0.3347\n",
      "Epoch [19/50], Step [143/735], Loss: 0.8725\n",
      "Epoch [19/50], Step [144/735], Loss: 0.2183\n",
      "Epoch [19/50], Step [145/735], Loss: 0.9697\n",
      "Epoch [19/50], Step [146/735], Loss: 0.7132\n",
      "Epoch [19/50], Step [147/735], Loss: 0.2321\n",
      "Epoch [19/50], Step [148/735], Loss: 1.2100\n",
      "Epoch [19/50], Step [149/735], Loss: 0.6727\n",
      "Epoch [19/50], Step [150/735], Loss: 0.2493\n",
      "Epoch [19/50], Step [151/735], Loss: 0.1325\n",
      "Epoch [19/50], Step [152/735], Loss: 0.3310\n",
      "Epoch [19/50], Step [153/735], Loss: 0.5820\n",
      "Epoch [19/50], Step [154/735], Loss: 0.3159\n",
      "Epoch [19/50], Step [155/735], Loss: 0.0874\n",
      "Epoch [19/50], Step [156/735], Loss: 0.0697\n",
      "Epoch [19/50], Step [157/735], Loss: 0.2117\n",
      "Epoch [19/50], Step [158/735], Loss: 0.4591\n",
      "Epoch [19/50], Step [159/735], Loss: 0.4307\n",
      "Epoch [19/50], Step [160/735], Loss: 0.2646\n",
      "Epoch [19/50], Step [161/735], Loss: 0.1304\n",
      "Epoch [19/50], Step [162/735], Loss: 0.4417\n",
      "Epoch [19/50], Step [163/735], Loss: 0.2078\n",
      "Epoch [19/50], Step [164/735], Loss: 1.2593\n",
      "Epoch [19/50], Step [165/735], Loss: 0.1970\n",
      "Epoch [19/50], Step [166/735], Loss: 0.6709\n",
      "Epoch [19/50], Step [167/735], Loss: 0.1424\n",
      "Epoch [19/50], Step [168/735], Loss: 0.2255\n",
      "Epoch [19/50], Step [169/735], Loss: 0.3045\n",
      "Epoch [19/50], Step [170/735], Loss: 0.2582\n",
      "Epoch [19/50], Step [171/735], Loss: 0.2218\n",
      "Epoch [19/50], Step [172/735], Loss: 0.5271\n",
      "Epoch [19/50], Step [173/735], Loss: 0.3937\n",
      "Epoch [19/50], Step [174/735], Loss: 0.5520\n",
      "Epoch [19/50], Step [175/735], Loss: 0.2727\n",
      "Epoch [19/50], Step [176/735], Loss: 0.2096\n",
      "Epoch [19/50], Step [177/735], Loss: 0.2549\n",
      "Epoch [19/50], Step [178/735], Loss: 0.1088\n",
      "Epoch [19/50], Step [179/735], Loss: 0.1121\n",
      "Epoch [19/50], Step [180/735], Loss: 0.3019\n",
      "Epoch [19/50], Step [181/735], Loss: 0.4033\n",
      "Epoch [19/50], Step [182/735], Loss: 0.5435\n",
      "Epoch [19/50], Step [183/735], Loss: 5.2269\n",
      "Epoch [19/50], Step [184/735], Loss: 0.8110\n",
      "Epoch [19/50], Step [185/735], Loss: 0.4317\n",
      "Epoch [19/50], Step [186/735], Loss: 0.3607\n",
      "Epoch [19/50], Step [187/735], Loss: 0.3456\n",
      "Epoch [19/50], Step [188/735], Loss: 0.2598\n",
      "Epoch [19/50], Step [189/735], Loss: 0.3312\n",
      "Epoch [19/50], Step [190/735], Loss: 0.4166\n",
      "Epoch [19/50], Step [191/735], Loss: 0.4779\n",
      "Epoch [19/50], Step [192/735], Loss: 0.2543\n",
      "Epoch [19/50], Step [193/735], Loss: 0.6577\n",
      "Epoch [19/50], Step [194/735], Loss: 0.2134\n",
      "Epoch [19/50], Step [195/735], Loss: 0.1611\n",
      "Epoch [19/50], Step [196/735], Loss: 0.5403\n",
      "Epoch [19/50], Step [197/735], Loss: 0.1497\n",
      "Epoch [19/50], Step [198/735], Loss: 0.2171\n",
      "Epoch [19/50], Step [199/735], Loss: 0.2309\n",
      "Epoch [19/50], Step [200/735], Loss: 0.2215\n",
      "Epoch [19/50], Step [201/735], Loss: 0.1137\n",
      "Epoch [19/50], Step [202/735], Loss: 0.5209\n",
      "Epoch [19/50], Step [203/735], Loss: 0.4181\n",
      "Epoch [19/50], Step [204/735], Loss: 0.4238\n",
      "Epoch [19/50], Step [205/735], Loss: 0.3191\n",
      "Epoch [19/50], Step [206/735], Loss: 0.1080\n",
      "Epoch [19/50], Step [207/735], Loss: 0.3912\n",
      "Epoch [19/50], Step [208/735], Loss: 0.1714\n",
      "Epoch [19/50], Step [209/735], Loss: 0.1253\n",
      "Epoch [19/50], Step [210/735], Loss: 0.2851\n",
      "Epoch [19/50], Step [211/735], Loss: 0.1895\n",
      "Epoch [19/50], Step [212/735], Loss: 0.8956\n",
      "Epoch [19/50], Step [213/735], Loss: 0.2292\n",
      "Epoch [19/50], Step [214/735], Loss: 2.5473\n",
      "Epoch [19/50], Step [215/735], Loss: 0.2583\n",
      "Epoch [19/50], Step [216/735], Loss: 0.2080\n",
      "Epoch [19/50], Step [217/735], Loss: 0.1979\n",
      "Epoch [19/50], Step [218/735], Loss: 0.0641\n",
      "Epoch [19/50], Step [219/735], Loss: 0.2955\n",
      "Epoch [19/50], Step [220/735], Loss: 0.8523\n",
      "Epoch [19/50], Step [221/735], Loss: 0.2595\n",
      "Epoch [19/50], Step [222/735], Loss: 0.0907\n",
      "Epoch [19/50], Step [223/735], Loss: 0.3286\n",
      "Epoch [19/50], Step [224/735], Loss: 0.4344\n",
      "Epoch [19/50], Step [225/735], Loss: 0.5679\n",
      "Epoch [19/50], Step [226/735], Loss: 0.2537\n",
      "Epoch [19/50], Step [227/735], Loss: 0.1821\n",
      "Epoch [19/50], Step [228/735], Loss: 0.2669\n",
      "Epoch [19/50], Step [229/735], Loss: 0.1983\n",
      "Epoch [19/50], Step [230/735], Loss: 0.2128\n",
      "Epoch [19/50], Step [231/735], Loss: 0.1416\n",
      "Epoch [19/50], Step [232/735], Loss: 0.3180\n",
      "Epoch [19/50], Step [233/735], Loss: 0.2611\n",
      "Epoch [19/50], Step [234/735], Loss: 0.5437\n",
      "Epoch [19/50], Step [235/735], Loss: 1.9037\n",
      "Epoch [19/50], Step [236/735], Loss: 0.2722\n",
      "Epoch [19/50], Step [237/735], Loss: 0.2048\n",
      "Epoch [19/50], Step [238/735], Loss: 0.3913\n",
      "Epoch [19/50], Step [239/735], Loss: 0.5046\n",
      "Epoch [19/50], Step [240/735], Loss: 0.3883\n",
      "Epoch [19/50], Step [241/735], Loss: 0.2449\n",
      "Epoch [19/50], Step [242/735], Loss: 0.1889\n",
      "Epoch [19/50], Step [243/735], Loss: 0.8256\n",
      "Epoch [19/50], Step [244/735], Loss: 2.0711\n",
      "Epoch [19/50], Step [245/735], Loss: 0.1400\n",
      "Epoch [19/50], Step [246/735], Loss: 0.0994\n",
      "Epoch [19/50], Step [247/735], Loss: 0.1731\n",
      "Epoch [19/50], Step [248/735], Loss: 0.9123\n",
      "Epoch [19/50], Step [249/735], Loss: 0.2557\n",
      "Epoch [19/50], Step [250/735], Loss: 0.1665\n",
      "Epoch [19/50], Step [251/735], Loss: 0.4897\n",
      "Epoch [19/50], Step [252/735], Loss: 0.1305\n",
      "Epoch [19/50], Step [253/735], Loss: 0.3819\n",
      "Epoch [19/50], Step [254/735], Loss: 0.2082\n",
      "Epoch [19/50], Step [255/735], Loss: 0.3360\n",
      "Epoch [19/50], Step [256/735], Loss: 0.4302\n",
      "Epoch [19/50], Step [257/735], Loss: 0.3009\n",
      "Epoch [19/50], Step [258/735], Loss: 0.3450\n",
      "Epoch [19/50], Step [259/735], Loss: 0.2997\n",
      "Epoch [19/50], Step [260/735], Loss: 0.2900\n",
      "Epoch [19/50], Step [261/735], Loss: 0.2574\n",
      "Epoch [19/50], Step [262/735], Loss: 0.5699\n",
      "Epoch [19/50], Step [263/735], Loss: 0.1359\n",
      "Epoch [19/50], Step [264/735], Loss: 0.2049\n",
      "Epoch [19/50], Step [265/735], Loss: 0.3190\n",
      "Epoch [19/50], Step [266/735], Loss: 0.6407\n",
      "Epoch [19/50], Step [267/735], Loss: 0.1750\n",
      "Epoch [19/50], Step [268/735], Loss: 0.4358\n",
      "Epoch [19/50], Step [269/735], Loss: 0.2599\n",
      "Epoch [19/50], Step [270/735], Loss: 0.1313\n",
      "Epoch [19/50], Step [271/735], Loss: 0.2581\n",
      "Epoch [19/50], Step [272/735], Loss: 0.2411\n",
      "Epoch [19/50], Step [273/735], Loss: 0.4410\n",
      "Epoch [19/50], Step [274/735], Loss: 0.8102\n",
      "Epoch [19/50], Step [275/735], Loss: 0.2434\n",
      "Epoch [19/50], Step [276/735], Loss: 0.5423\n",
      "Epoch [19/50], Step [277/735], Loss: 0.5366\n",
      "Epoch [19/50], Step [278/735], Loss: 0.4273\n",
      "Epoch [19/50], Step [279/735], Loss: 0.2209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Step [280/735], Loss: 0.5022\n",
      "Epoch [19/50], Step [281/735], Loss: 0.4415\n",
      "Epoch [19/50], Step [282/735], Loss: 0.1461\n",
      "Epoch [19/50], Step [283/735], Loss: 0.2916\n",
      "Epoch [19/50], Step [284/735], Loss: 0.4422\n",
      "Epoch [19/50], Step [285/735], Loss: 0.6843\n",
      "Epoch [19/50], Step [286/735], Loss: 0.8931\n",
      "Epoch [19/50], Step [287/735], Loss: 0.4370\n",
      "Epoch [19/50], Step [288/735], Loss: 0.6350\n",
      "Epoch [19/50], Step [289/735], Loss: 0.1012\n",
      "Epoch [19/50], Step [290/735], Loss: 0.5494\n",
      "Epoch [19/50], Step [291/735], Loss: 0.4368\n",
      "Epoch [19/50], Step [292/735], Loss: 0.3386\n",
      "Epoch [19/50], Step [293/735], Loss: 0.3540\n",
      "Epoch [19/50], Step [294/735], Loss: 0.1187\n",
      "Epoch [19/50], Step [295/735], Loss: 0.5602\n",
      "Epoch [19/50], Step [296/735], Loss: 0.2684\n",
      "Epoch [19/50], Step [297/735], Loss: 0.4739\n",
      "Epoch [19/50], Step [298/735], Loss: 0.4129\n",
      "Epoch [19/50], Step [299/735], Loss: 0.5910\n",
      "Epoch [19/50], Step [300/735], Loss: 0.5714\n",
      "Epoch [19/50], Step [301/735], Loss: 0.5162\n",
      "Epoch [19/50], Step [302/735], Loss: 1.1392\n",
      "Epoch [19/50], Step [303/735], Loss: 0.2139\n",
      "Epoch [19/50], Step [304/735], Loss: 0.0795\n",
      "Epoch [19/50], Step [305/735], Loss: 0.1618\n",
      "Epoch [19/50], Step [306/735], Loss: 0.1196\n",
      "Epoch [19/50], Step [307/735], Loss: 0.7533\n",
      "Epoch [19/50], Step [308/735], Loss: 0.1458\n",
      "Epoch [19/50], Step [309/735], Loss: 0.0861\n",
      "Epoch [19/50], Step [310/735], Loss: 0.2091\n",
      "Epoch [19/50], Step [311/735], Loss: 0.3440\n",
      "Epoch [19/50], Step [312/735], Loss: 1.0483\n",
      "Epoch [19/50], Step [313/735], Loss: 0.5337\n",
      "Epoch [19/50], Step [314/735], Loss: 0.2236\n",
      "Epoch [19/50], Step [315/735], Loss: 0.3212\n",
      "Epoch [19/50], Step [316/735], Loss: 0.3797\n",
      "Epoch [19/50], Step [317/735], Loss: 0.8612\n",
      "Epoch [19/50], Step [318/735], Loss: 0.5140\n",
      "Epoch [19/50], Step [319/735], Loss: 0.4175\n",
      "Epoch [19/50], Step [320/735], Loss: 0.7403\n",
      "Epoch [19/50], Step [321/735], Loss: 0.4299\n",
      "Epoch [19/50], Step [322/735], Loss: 5.3471\n",
      "Epoch [19/50], Step [323/735], Loss: 1.0009\n",
      "Epoch [19/50], Step [324/735], Loss: 2.0119\n",
      "Epoch [19/50], Step [325/735], Loss: 0.5772\n",
      "Epoch [19/50], Step [326/735], Loss: 2.1303\n",
      "Epoch [19/50], Step [327/735], Loss: 0.2206\n",
      "Epoch [19/50], Step [328/735], Loss: 0.2214\n",
      "Epoch [19/50], Step [329/735], Loss: 0.9850\n",
      "Epoch [19/50], Step [330/735], Loss: 0.3492\n",
      "Epoch [19/50], Step [331/735], Loss: 0.3040\n",
      "Epoch [19/50], Step [332/735], Loss: 0.2899\n",
      "Epoch [19/50], Step [333/735], Loss: 0.4977\n",
      "Epoch [19/50], Step [334/735], Loss: 0.2198\n",
      "Epoch [19/50], Step [335/735], Loss: 0.4623\n",
      "Epoch [19/50], Step [336/735], Loss: 0.3837\n",
      "Epoch [19/50], Step [337/735], Loss: 0.1354\n",
      "Epoch [19/50], Step [338/735], Loss: 0.4738\n",
      "Epoch [19/50], Step [339/735], Loss: 0.8606\n",
      "Epoch [19/50], Step [340/735], Loss: 1.8360\n",
      "Epoch [19/50], Step [341/735], Loss: 1.0067\n",
      "Epoch [19/50], Step [342/735], Loss: 0.1873\n",
      "Epoch [19/50], Step [343/735], Loss: 0.7766\n",
      "Epoch [19/50], Step [344/735], Loss: 0.0854\n",
      "Epoch [19/50], Step [345/735], Loss: 0.3789\n",
      "Epoch [19/50], Step [346/735], Loss: 0.1690\n",
      "Epoch [19/50], Step [347/735], Loss: 0.2648\n",
      "Epoch [19/50], Step [348/735], Loss: 0.1125\n",
      "Epoch [19/50], Step [349/735], Loss: 0.2408\n",
      "Epoch [19/50], Step [350/735], Loss: 0.5369\n",
      "Epoch [19/50], Step [351/735], Loss: 1.1205\n",
      "Epoch [19/50], Step [352/735], Loss: 0.1813\n",
      "Epoch [19/50], Step [353/735], Loss: 0.1695\n",
      "Epoch [19/50], Step [354/735], Loss: 0.5512\n",
      "Epoch [19/50], Step [355/735], Loss: 1.3153\n",
      "Epoch [19/50], Step [356/735], Loss: 0.2648\n",
      "Epoch [19/50], Step [357/735], Loss: 0.2781\n",
      "Epoch [19/50], Step [358/735], Loss: 0.1787\n",
      "Epoch [19/50], Step [359/735], Loss: 0.3444\n",
      "Epoch [19/50], Step [360/735], Loss: 0.4440\n",
      "Epoch [19/50], Step [361/735], Loss: 1.0613\n",
      "Epoch [19/50], Step [362/735], Loss: 0.2737\n",
      "Epoch [19/50], Step [363/735], Loss: 0.3691\n",
      "Epoch [19/50], Step [364/735], Loss: 7.0588\n",
      "Epoch [19/50], Step [365/735], Loss: 0.1505\n",
      "Epoch [19/50], Step [366/735], Loss: 0.1970\n",
      "Epoch [19/50], Step [367/735], Loss: 0.2817\n",
      "Epoch [19/50], Step [368/735], Loss: 1.9936\n",
      "Epoch [19/50], Step [369/735], Loss: 0.2304\n",
      "Epoch [19/50], Step [370/735], Loss: 0.8766\n",
      "Epoch [19/50], Step [371/735], Loss: 0.3584\n",
      "Epoch [19/50], Step [372/735], Loss: 0.6590\n",
      "Epoch [19/50], Step [373/735], Loss: 0.3841\n",
      "Epoch [19/50], Step [374/735], Loss: 1.0880\n",
      "Epoch [19/50], Step [375/735], Loss: 0.1838\n",
      "Epoch [19/50], Step [376/735], Loss: 0.2353\n",
      "Epoch [19/50], Step [377/735], Loss: 0.2175\n",
      "Epoch [19/50], Step [378/735], Loss: 1.2695\n",
      "Epoch [19/50], Step [379/735], Loss: 0.8324\n",
      "Epoch [19/50], Step [380/735], Loss: 0.0865\n",
      "Epoch [19/50], Step [381/735], Loss: 0.1392\n",
      "Epoch [19/50], Step [382/735], Loss: 0.5528\n",
      "Epoch [19/50], Step [383/735], Loss: 0.5353\n",
      "Epoch [19/50], Step [384/735], Loss: 0.5656\n",
      "Epoch [19/50], Step [385/735], Loss: 0.1378\n",
      "Epoch [19/50], Step [386/735], Loss: 0.6423\n",
      "Epoch [19/50], Step [387/735], Loss: 1.3151\n",
      "Epoch [19/50], Step [388/735], Loss: 1.2165\n",
      "Epoch [19/50], Step [389/735], Loss: 0.2782\n",
      "Epoch [19/50], Step [390/735], Loss: 0.2132\n",
      "Epoch [19/50], Step [391/735], Loss: 0.3238\n",
      "Epoch [19/50], Step [392/735], Loss: 0.5745\n",
      "Epoch [19/50], Step [393/735], Loss: 0.1478\n",
      "Epoch [19/50], Step [394/735], Loss: 0.2526\n",
      "Epoch [19/50], Step [395/735], Loss: 0.0851\n",
      "Epoch [19/50], Step [396/735], Loss: 0.1870\n",
      "Epoch [19/50], Step [397/735], Loss: 1.1183\n",
      "Epoch [19/50], Step [398/735], Loss: 0.5182\n",
      "Epoch [19/50], Step [399/735], Loss: 0.5829\n",
      "Epoch [19/50], Step [400/735], Loss: 1.2387\n",
      "Epoch [19/50], Step [401/735], Loss: 0.6594\n",
      "Epoch [19/50], Step [402/735], Loss: 0.2845\n",
      "Epoch [19/50], Step [403/735], Loss: 0.1963\n",
      "Epoch [19/50], Step [404/735], Loss: 0.3434\n",
      "Epoch [19/50], Step [405/735], Loss: 0.5256\n",
      "Epoch [19/50], Step [406/735], Loss: 0.9523\n",
      "Epoch [19/50], Step [407/735], Loss: 0.8286\n",
      "Epoch [19/50], Step [408/735], Loss: 0.4502\n",
      "Epoch [19/50], Step [409/735], Loss: 0.1730\n",
      "Epoch [19/50], Step [410/735], Loss: 0.3157\n",
      "Epoch [19/50], Step [411/735], Loss: 0.4980\n",
      "Epoch [19/50], Step [412/735], Loss: 0.2354\n",
      "Epoch [19/50], Step [413/735], Loss: 0.6666\n",
      "Epoch [19/50], Step [414/735], Loss: 0.2225\n",
      "Epoch [19/50], Step [415/735], Loss: 0.2488\n",
      "Epoch [19/50], Step [416/735], Loss: 0.1633\n",
      "Epoch [19/50], Step [417/735], Loss: 0.1788\n",
      "Epoch [19/50], Step [418/735], Loss: 0.2126\n",
      "Epoch [19/50], Step [419/735], Loss: 0.2773\n",
      "Epoch [19/50], Step [420/735], Loss: 0.0643\n",
      "Epoch [19/50], Step [421/735], Loss: 0.2026\n",
      "Epoch [19/50], Step [422/735], Loss: 0.6570\n",
      "Epoch [19/50], Step [423/735], Loss: 0.1736\n",
      "Epoch [19/50], Step [424/735], Loss: 0.6172\n",
      "Epoch [19/50], Step [425/735], Loss: 0.1362\n",
      "Epoch [19/50], Step [426/735], Loss: 0.3471\n",
      "Epoch [19/50], Step [427/735], Loss: 0.1892\n",
      "Epoch [19/50], Step [428/735], Loss: 0.6759\n",
      "Epoch [19/50], Step [429/735], Loss: 0.9013\n",
      "Epoch [19/50], Step [430/735], Loss: 0.1717\n",
      "Epoch [19/50], Step [431/735], Loss: 0.4060\n",
      "Epoch [19/50], Step [432/735], Loss: 0.1499\n",
      "Epoch [19/50], Step [433/735], Loss: 0.1216\n",
      "Epoch [19/50], Step [434/735], Loss: 0.1859\n",
      "Epoch [19/50], Step [435/735], Loss: 1.0108\n",
      "Epoch [19/50], Step [436/735], Loss: 0.1673\n",
      "Epoch [19/50], Step [437/735], Loss: 1.1551\n",
      "Epoch [19/50], Step [438/735], Loss: 0.3368\n",
      "Epoch [19/50], Step [439/735], Loss: 0.5105\n",
      "Epoch [19/50], Step [440/735], Loss: 0.5618\n",
      "Epoch [19/50], Step [441/735], Loss: 0.3366\n",
      "Epoch [19/50], Step [442/735], Loss: 0.3603\n",
      "Epoch [19/50], Step [443/735], Loss: 0.1603\n",
      "Epoch [19/50], Step [444/735], Loss: 0.1088\n",
      "Epoch [19/50], Step [445/735], Loss: 0.1722\n",
      "Epoch [19/50], Step [446/735], Loss: 0.1165\n",
      "Epoch [19/50], Step [447/735], Loss: 0.2253\n",
      "Epoch [19/50], Step [448/735], Loss: 0.5174\n",
      "Epoch [19/50], Step [449/735], Loss: 0.0975\n",
      "Epoch [19/50], Step [450/735], Loss: 0.5857\n",
      "Epoch [19/50], Step [451/735], Loss: 0.0556\n",
      "Epoch [19/50], Step [452/735], Loss: 0.2212\n",
      "Epoch [19/50], Step [453/735], Loss: 0.2283\n",
      "Epoch [19/50], Step [454/735], Loss: 0.2711\n",
      "Epoch [19/50], Step [455/735], Loss: 0.5059\n",
      "Epoch [19/50], Step [456/735], Loss: 0.4480\n",
      "Epoch [19/50], Step [457/735], Loss: 0.3903\n",
      "Epoch [19/50], Step [458/735], Loss: 0.1102\n",
      "Epoch [19/50], Step [459/735], Loss: 0.2700\n",
      "Epoch [19/50], Step [460/735], Loss: 0.5115\n",
      "Epoch [19/50], Step [461/735], Loss: 0.1874\n",
      "Epoch [19/50], Step [462/735], Loss: 0.2996\n",
      "Epoch [19/50], Step [463/735], Loss: 0.4211\n",
      "Epoch [19/50], Step [464/735], Loss: 0.9453\n",
      "Epoch [19/50], Step [465/735], Loss: 0.4576\n",
      "Epoch [19/50], Step [466/735], Loss: 0.5295\n",
      "Epoch [19/50], Step [467/735], Loss: 0.7868\n",
      "Epoch [19/50], Step [468/735], Loss: 5.3505\n",
      "Epoch [19/50], Step [469/735], Loss: 0.5975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Step [470/735], Loss: 1.5402\n",
      "Epoch [19/50], Step [471/735], Loss: 0.3846\n",
      "Epoch [19/50], Step [472/735], Loss: 0.4602\n",
      "Epoch [19/50], Step [473/735], Loss: 0.3628\n",
      "Epoch [19/50], Step [474/735], Loss: 0.5701\n",
      "Epoch [19/50], Step [475/735], Loss: 0.3170\n",
      "Epoch [19/50], Step [476/735], Loss: 0.5559\n",
      "Epoch [19/50], Step [477/735], Loss: 0.0950\n",
      "Epoch [19/50], Step [478/735], Loss: 0.1229\n",
      "Epoch [19/50], Step [479/735], Loss: 0.8488\n",
      "Epoch [19/50], Step [480/735], Loss: 0.2473\n",
      "Epoch [19/50], Step [481/735], Loss: 0.5935\n",
      "Epoch [19/50], Step [482/735], Loss: 0.3019\n",
      "Epoch [19/50], Step [483/735], Loss: 0.8956\n",
      "Epoch [19/50], Step [484/735], Loss: 0.2545\n",
      "Epoch [19/50], Step [485/735], Loss: 0.5646\n",
      "Epoch [19/50], Step [486/735], Loss: 0.7248\n",
      "Epoch [19/50], Step [487/735], Loss: 0.2257\n",
      "Epoch [19/50], Step [488/735], Loss: 0.4605\n",
      "Epoch [19/50], Step [489/735], Loss: 0.2707\n",
      "Epoch [19/50], Step [490/735], Loss: 0.6378\n",
      "Epoch [19/50], Step [491/735], Loss: 0.0821\n",
      "Epoch [19/50], Step [492/735], Loss: 0.0691\n",
      "Epoch [19/50], Step [493/735], Loss: 0.6314\n",
      "Epoch [19/50], Step [494/735], Loss: 0.2363\n",
      "Epoch [19/50], Step [495/735], Loss: 0.3869\n",
      "Epoch [19/50], Step [496/735], Loss: 0.3408\n",
      "Epoch [19/50], Step [497/735], Loss: 0.3088\n",
      "Epoch [19/50], Step [498/735], Loss: 0.1331\n",
      "Epoch [19/50], Step [499/735], Loss: 0.2745\n",
      "Epoch [19/50], Step [500/735], Loss: 1.5681\n",
      "Epoch [19/50], Step [501/735], Loss: 0.3426\n",
      "Epoch [19/50], Step [502/735], Loss: 0.4761\n",
      "Epoch [19/50], Step [503/735], Loss: 0.1922\n",
      "Epoch [19/50], Step [504/735], Loss: 0.5299\n",
      "Epoch [19/50], Step [505/735], Loss: 0.2381\n",
      "Epoch [19/50], Step [506/735], Loss: 0.0793\n",
      "Epoch [19/50], Step [507/735], Loss: 1.0480\n",
      "Epoch [19/50], Step [508/735], Loss: 0.5195\n",
      "Epoch [19/50], Step [509/735], Loss: 1.2415\n",
      "Epoch [19/50], Step [510/735], Loss: 0.4748\n",
      "Epoch [19/50], Step [511/735], Loss: 0.3900\n",
      "Epoch [19/50], Step [512/735], Loss: 0.3473\n",
      "Epoch [19/50], Step [513/735], Loss: 0.4790\n",
      "Epoch [19/50], Step [514/735], Loss: 0.2308\n",
      "Epoch [19/50], Step [515/735], Loss: 0.4538\n",
      "Epoch [19/50], Step [516/735], Loss: 0.3470\n",
      "Epoch [19/50], Step [517/735], Loss: 0.4662\n",
      "Epoch [19/50], Step [518/735], Loss: 0.3151\n",
      "Epoch [19/50], Step [519/735], Loss: 0.2858\n",
      "Epoch [19/50], Step [520/735], Loss: 0.6924\n",
      "Epoch [19/50], Step [521/735], Loss: 0.1178\n",
      "Epoch [19/50], Step [522/735], Loss: 0.0660\n",
      "Epoch [19/50], Step [523/735], Loss: 0.5349\n",
      "Epoch [19/50], Step [524/735], Loss: 0.3715\n",
      "Epoch [19/50], Step [525/735], Loss: 0.8616\n",
      "Epoch [19/50], Step [526/735], Loss: 0.1219\n",
      "Epoch [19/50], Step [527/735], Loss: 0.6808\n",
      "Epoch [19/50], Step [528/735], Loss: 0.1825\n",
      "Epoch [19/50], Step [529/735], Loss: 0.1618\n",
      "Epoch [19/50], Step [530/735], Loss: 0.2225\n",
      "Epoch [19/50], Step [531/735], Loss: 0.0716\n",
      "Epoch [19/50], Step [532/735], Loss: 0.3481\n",
      "Epoch [19/50], Step [533/735], Loss: 0.1681\n",
      "Epoch [19/50], Step [534/735], Loss: 0.1199\n",
      "Epoch [19/50], Step [535/735], Loss: 0.1282\n",
      "Epoch [19/50], Step [536/735], Loss: 0.1479\n",
      "Epoch [19/50], Step [537/735], Loss: 0.5230\n",
      "Epoch [19/50], Step [538/735], Loss: 0.2421\n",
      "Epoch [19/50], Step [539/735], Loss: 0.8337\n",
      "Epoch [19/50], Step [540/735], Loss: 0.2082\n",
      "Epoch [19/50], Step [541/735], Loss: 0.2640\n",
      "Epoch [19/50], Step [542/735], Loss: 0.4807\n",
      "Epoch [19/50], Step [543/735], Loss: 0.4193\n",
      "Epoch [19/50], Step [544/735], Loss: 0.1331\n",
      "Epoch [19/50], Step [545/735], Loss: 0.6775\n",
      "Epoch [19/50], Step [546/735], Loss: 0.2744\n",
      "Epoch [19/50], Step [547/735], Loss: 0.6166\n",
      "Epoch [19/50], Step [548/735], Loss: 0.4190\n",
      "Epoch [19/50], Step [549/735], Loss: 0.2335\n",
      "Epoch [19/50], Step [550/735], Loss: 0.2017\n",
      "Epoch [19/50], Step [551/735], Loss: 0.1529\n",
      "Epoch [19/50], Step [552/735], Loss: 1.1751\n",
      "Epoch [19/50], Step [553/735], Loss: 0.4674\n",
      "Epoch [19/50], Step [554/735], Loss: 0.1125\n",
      "Epoch [19/50], Step [555/735], Loss: 0.2098\n",
      "Epoch [19/50], Step [556/735], Loss: 0.1542\n",
      "Epoch [19/50], Step [557/735], Loss: 0.2658\n",
      "Epoch [19/50], Step [558/735], Loss: 0.4180\n",
      "Epoch [19/50], Step [559/735], Loss: 1.2755\n",
      "Epoch [19/50], Step [560/735], Loss: 0.6974\n",
      "Epoch [19/50], Step [561/735], Loss: 0.0853\n",
      "Epoch [19/50], Step [562/735], Loss: 0.9490\n",
      "Epoch [19/50], Step [563/735], Loss: 0.2629\n",
      "Epoch [19/50], Step [564/735], Loss: 0.2778\n",
      "Epoch [19/50], Step [565/735], Loss: 0.3457\n",
      "Epoch [19/50], Step [566/735], Loss: 0.1787\n",
      "Epoch [19/50], Step [567/735], Loss: 0.2750\n",
      "Epoch [19/50], Step [568/735], Loss: 0.3492\n",
      "Epoch [19/50], Step [569/735], Loss: 0.1463\n",
      "Epoch [19/50], Step [570/735], Loss: 0.2310\n",
      "Epoch [19/50], Step [571/735], Loss: 0.4802\n",
      "Epoch [19/50], Step [572/735], Loss: 0.5783\n",
      "Epoch [19/50], Step [573/735], Loss: 0.2333\n",
      "Epoch [19/50], Step [574/735], Loss: 1.1888\n",
      "Epoch [19/50], Step [575/735], Loss: 0.2131\n",
      "Epoch [19/50], Step [576/735], Loss: 0.2394\n",
      "Epoch [19/50], Step [577/735], Loss: 0.1184\n",
      "Epoch [19/50], Step [578/735], Loss: 0.1920\n",
      "Epoch [19/50], Step [579/735], Loss: 0.1317\n",
      "Epoch [19/50], Step [580/735], Loss: 0.1140\n",
      "Epoch [19/50], Step [581/735], Loss: 0.0869\n",
      "Epoch [19/50], Step [582/735], Loss: 0.3395\n",
      "Epoch [19/50], Step [583/735], Loss: 0.2297\n",
      "Epoch [19/50], Step [584/735], Loss: 0.1291\n",
      "Epoch [19/50], Step [585/735], Loss: 0.6074\n",
      "Epoch [19/50], Step [586/735], Loss: 0.0994\n",
      "Epoch [19/50], Step [587/735], Loss: 0.3666\n",
      "Epoch [19/50], Step [588/735], Loss: 0.5441\n",
      "Epoch [19/50], Step [589/735], Loss: 0.3140\n",
      "Epoch [19/50], Step [590/735], Loss: 0.6318\n",
      "Epoch [19/50], Step [591/735], Loss: 0.1386\n",
      "Epoch [19/50], Step [592/735], Loss: 0.8607\n",
      "Epoch [19/50], Step [593/735], Loss: 0.1190\n",
      "Epoch [19/50], Step [594/735], Loss: 0.2097\n",
      "Epoch [19/50], Step [595/735], Loss: 0.3703\n",
      "Epoch [19/50], Step [596/735], Loss: 0.9142\n",
      "Epoch [19/50], Step [597/735], Loss: 0.2985\n",
      "Epoch [19/50], Step [598/735], Loss: 0.3209\n",
      "Epoch [19/50], Step [599/735], Loss: 0.2076\n",
      "Epoch [19/50], Step [600/735], Loss: 0.7210\n",
      "Epoch [19/50], Step [601/735], Loss: 0.2185\n",
      "Epoch [19/50], Step [602/735], Loss: 0.2588\n",
      "Epoch [19/50], Step [603/735], Loss: 0.1289\n",
      "Epoch [19/50], Step [604/735], Loss: 1.7617\n",
      "Epoch [19/50], Step [605/735], Loss: 0.1289\n",
      "Epoch [19/50], Step [606/735], Loss: 0.9835\n",
      "Epoch [19/50], Step [607/735], Loss: 0.0755\n",
      "Epoch [19/50], Step [608/735], Loss: 0.0916\n",
      "Epoch [19/50], Step [609/735], Loss: 0.4192\n",
      "Epoch [19/50], Step [610/735], Loss: 0.0909\n",
      "Epoch [19/50], Step [611/735], Loss: 0.1849\n",
      "Epoch [19/50], Step [612/735], Loss: 0.7663\n",
      "Epoch [19/50], Step [613/735], Loss: 0.1438\n",
      "Epoch [19/50], Step [614/735], Loss: 0.4895\n",
      "Epoch [19/50], Step [615/735], Loss: 0.3431\n",
      "Epoch [19/50], Step [616/735], Loss: 0.1689\n",
      "Epoch [19/50], Step [617/735], Loss: 0.2026\n",
      "Epoch [19/50], Step [618/735], Loss: 0.2083\n",
      "Epoch [19/50], Step [619/735], Loss: 0.5662\n",
      "Epoch [19/50], Step [620/735], Loss: 0.4372\n",
      "Epoch [19/50], Step [621/735], Loss: 0.2060\n",
      "Epoch [19/50], Step [622/735], Loss: 0.2514\n",
      "Epoch [19/50], Step [623/735], Loss: 0.4957\n",
      "Epoch [19/50], Step [624/735], Loss: 0.5531\n",
      "Epoch [19/50], Step [625/735], Loss: 0.1592\n",
      "Epoch [19/50], Step [626/735], Loss: 0.1758\n",
      "Epoch [19/50], Step [627/735], Loss: 0.3150\n",
      "Epoch [19/50], Step [628/735], Loss: 0.3700\n",
      "Epoch [19/50], Step [629/735], Loss: 0.3105\n",
      "Epoch [19/50], Step [630/735], Loss: 1.3710\n",
      "Epoch [19/50], Step [631/735], Loss: 0.5423\n",
      "Epoch [19/50], Step [632/735], Loss: 1.1097\n",
      "Epoch [19/50], Step [633/735], Loss: 0.0849\n",
      "Epoch [19/50], Step [634/735], Loss: 0.0950\n",
      "Epoch [19/50], Step [635/735], Loss: 0.4991\n",
      "Epoch [19/50], Step [636/735], Loss: 0.4541\n",
      "Epoch [19/50], Step [637/735], Loss: 0.2452\n",
      "Epoch [19/50], Step [638/735], Loss: 0.0621\n",
      "Epoch [19/50], Step [639/735], Loss: 0.1899\n",
      "Epoch [19/50], Step [640/735], Loss: 1.8386\n",
      "Epoch [19/50], Step [641/735], Loss: 0.2466\n",
      "Epoch [19/50], Step [642/735], Loss: 0.1535\n",
      "Epoch [19/50], Step [643/735], Loss: 0.3706\n",
      "Epoch [19/50], Step [644/735], Loss: 0.1347\n",
      "Epoch [19/50], Step [645/735], Loss: 0.8435\n",
      "Epoch [19/50], Step [646/735], Loss: 0.1245\n",
      "Epoch [19/50], Step [647/735], Loss: 0.2392\n",
      "Epoch [19/50], Step [648/735], Loss: 0.1942\n",
      "Epoch [19/50], Step [649/735], Loss: 0.1231\n",
      "Epoch [19/50], Step [650/735], Loss: 0.1477\n",
      "Epoch [19/50], Step [651/735], Loss: 0.0638\n",
      "Epoch [19/50], Step [652/735], Loss: 0.1328\n",
      "Epoch [19/50], Step [653/735], Loss: 0.4023\n",
      "Epoch [19/50], Step [654/735], Loss: 0.1291\n",
      "Epoch [19/50], Step [655/735], Loss: 0.3004\n",
      "Epoch [19/50], Step [656/735], Loss: 0.0947\n",
      "Epoch [19/50], Step [657/735], Loss: 0.4353\n",
      "Epoch [19/50], Step [658/735], Loss: 0.1997\n",
      "Epoch [19/50], Step [659/735], Loss: 0.2411\n",
      "Epoch [19/50], Step [660/735], Loss: 0.0839\n",
      "Epoch [19/50], Step [661/735], Loss: 0.6217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Step [662/735], Loss: 1.0301\n",
      "Epoch [19/50], Step [663/735], Loss: 0.2189\n",
      "Epoch [19/50], Step [664/735], Loss: 0.5595\n",
      "Epoch [19/50], Step [665/735], Loss: 0.2461\n",
      "Epoch [19/50], Step [666/735], Loss: 0.9720\n",
      "Epoch [19/50], Step [667/735], Loss: 0.0825\n",
      "Epoch [19/50], Step [668/735], Loss: 0.3378\n",
      "Epoch [19/50], Step [669/735], Loss: 1.7655\n",
      "Epoch [19/50], Step [670/735], Loss: 0.4951\n",
      "Epoch [19/50], Step [671/735], Loss: 0.3765\n",
      "Epoch [19/50], Step [672/735], Loss: 0.5075\n",
      "Epoch [19/50], Step [673/735], Loss: 0.3539\n",
      "Epoch [19/50], Step [674/735], Loss: 0.5913\n",
      "Epoch [19/50], Step [675/735], Loss: 0.2894\n",
      "Epoch [19/50], Step [676/735], Loss: 0.3018\n",
      "Epoch [19/50], Step [677/735], Loss: 0.7501\n",
      "Epoch [19/50], Step [678/735], Loss: 0.1540\n",
      "Epoch [19/50], Step [679/735], Loss: 0.1491\n",
      "Epoch [19/50], Step [680/735], Loss: 0.6103\n",
      "Epoch [19/50], Step [681/735], Loss: 0.1698\n",
      "Epoch [19/50], Step [682/735], Loss: 0.0366\n",
      "Epoch [19/50], Step [683/735], Loss: 0.5980\n",
      "Epoch [19/50], Step [684/735], Loss: 0.3899\n",
      "Epoch [19/50], Step [685/735], Loss: 0.5113\n",
      "Epoch [19/50], Step [686/735], Loss: 0.8899\n",
      "Epoch [19/50], Step [687/735], Loss: 0.3811\n",
      "Epoch [19/50], Step [688/735], Loss: 0.5125\n",
      "Epoch [19/50], Step [689/735], Loss: 0.6581\n",
      "Epoch [19/50], Step [690/735], Loss: 0.3178\n",
      "Epoch [19/50], Step [691/735], Loss: 0.3818\n",
      "Epoch [19/50], Step [692/735], Loss: 1.3365\n",
      "Epoch [19/50], Step [693/735], Loss: 0.6644\n",
      "Epoch [19/50], Step [694/735], Loss: 0.3785\n",
      "Epoch [19/50], Step [695/735], Loss: 0.7428\n",
      "Epoch [19/50], Step [696/735], Loss: 0.2026\n",
      "Epoch [19/50], Step [697/735], Loss: 0.3345\n",
      "Epoch [19/50], Step [698/735], Loss: 5.0824\n",
      "Epoch [19/50], Step [699/735], Loss: 0.4515\n",
      "Epoch [19/50], Step [700/735], Loss: 0.4832\n",
      "Epoch [19/50], Step [701/735], Loss: 0.1859\n",
      "Epoch [19/50], Step [702/735], Loss: 0.8793\n",
      "Epoch [19/50], Step [703/735], Loss: 0.2677\n",
      "Epoch [19/50], Step [704/735], Loss: 0.2236\n",
      "Epoch [19/50], Step [705/735], Loss: 0.4815\n",
      "Epoch [19/50], Step [706/735], Loss: 0.1565\n",
      "Epoch [19/50], Step [707/735], Loss: 0.3648\n",
      "Epoch [19/50], Step [708/735], Loss: 0.2828\n",
      "Epoch [19/50], Step [709/735], Loss: 0.2793\n",
      "Epoch [19/50], Step [710/735], Loss: 0.2961\n",
      "Epoch [19/50], Step [711/735], Loss: 0.1991\n",
      "Epoch [19/50], Step [712/735], Loss: 0.0555\n",
      "Epoch [19/50], Step [713/735], Loss: 0.0545\n",
      "Epoch [19/50], Step [714/735], Loss: 0.0888\n",
      "Epoch [19/50], Step [715/735], Loss: 0.0626\n",
      "Epoch [19/50], Step [716/735], Loss: 0.2621\n",
      "Epoch [19/50], Step [717/735], Loss: 0.1877\n",
      "Epoch [19/50], Step [718/735], Loss: 0.2350\n",
      "Epoch [19/50], Step [719/735], Loss: 0.5135\n",
      "Epoch [19/50], Step [720/735], Loss: 0.1388\n",
      "Epoch [19/50], Step [721/735], Loss: 0.2423\n",
      "Epoch [19/50], Step [722/735], Loss: 0.2854\n",
      "Epoch [19/50], Step [723/735], Loss: 0.6553\n",
      "Epoch [19/50], Step [724/735], Loss: 0.4209\n",
      "Epoch [19/50], Step [725/735], Loss: 0.1772\n",
      "Epoch [19/50], Step [726/735], Loss: 0.2868\n",
      "Epoch [19/50], Step [727/735], Loss: 0.1928\n",
      "Epoch [19/50], Step [728/735], Loss: 0.0865\n",
      "Epoch [19/50], Step [729/735], Loss: 0.9788\n",
      "Epoch [19/50], Step [730/735], Loss: 0.5189\n",
      "Epoch [19/50], Step [731/735], Loss: 0.1195\n",
      "Epoch [19/50], Step [732/735], Loss: 0.1736\n",
      "Epoch [19/50], Step [733/735], Loss: 0.1619\n",
      "Epoch [19/50], Step [734/735], Loss: 0.9334\n",
      "Epoch [19/50], Step [735/735], Loss: 0.9290\n",
      "Epoch [20/50], Step [1/735], Loss: 0.1667\n",
      "Epoch [20/50], Step [2/735], Loss: 0.0970\n",
      "Epoch [20/50], Step [3/735], Loss: 0.5693\n",
      "Epoch [20/50], Step [4/735], Loss: 0.5758\n",
      "Epoch [20/50], Step [5/735], Loss: 0.4173\n",
      "Epoch [20/50], Step [6/735], Loss: 0.6156\n",
      "Epoch [20/50], Step [7/735], Loss: 0.4394\n",
      "Epoch [20/50], Step [8/735], Loss: 0.3885\n",
      "Epoch [20/50], Step [9/735], Loss: 0.2829\n",
      "Epoch [20/50], Step [10/735], Loss: 0.0598\n",
      "Epoch [20/50], Step [11/735], Loss: 0.4368\n",
      "Epoch [20/50], Step [12/735], Loss: 0.3128\n",
      "Epoch [20/50], Step [13/735], Loss: 0.2566\n",
      "Epoch [20/50], Step [14/735], Loss: 0.3454\n",
      "Epoch [20/50], Step [15/735], Loss: 0.1629\n",
      "Epoch [20/50], Step [16/735], Loss: 0.6840\n",
      "Epoch [20/50], Step [17/735], Loss: 1.5500\n",
      "Epoch [20/50], Step [18/735], Loss: 0.4458\n",
      "Epoch [20/50], Step [19/735], Loss: 0.4060\n",
      "Epoch [20/50], Step [20/735], Loss: 0.5869\n",
      "Epoch [20/50], Step [21/735], Loss: 0.3397\n",
      "Epoch [20/50], Step [22/735], Loss: 0.4523\n",
      "Epoch [20/50], Step [23/735], Loss: 0.3655\n",
      "Epoch [20/50], Step [24/735], Loss: 1.3969\n",
      "Epoch [20/50], Step [25/735], Loss: 0.0808\n",
      "Epoch [20/50], Step [26/735], Loss: 0.3314\n",
      "Epoch [20/50], Step [27/735], Loss: 0.1947\n",
      "Epoch [20/50], Step [28/735], Loss: 0.7067\n",
      "Epoch [20/50], Step [29/735], Loss: 0.1489\n",
      "Epoch [20/50], Step [30/735], Loss: 0.7103\n",
      "Epoch [20/50], Step [31/735], Loss: 0.4554\n",
      "Epoch [20/50], Step [32/735], Loss: 0.1480\n",
      "Epoch [20/50], Step [33/735], Loss: 0.2031\n",
      "Epoch [20/50], Step [34/735], Loss: 0.1423\n",
      "Epoch [20/50], Step [35/735], Loss: 0.3229\n",
      "Epoch [20/50], Step [36/735], Loss: 0.3466\n",
      "Epoch [20/50], Step [37/735], Loss: 0.2243\n",
      "Epoch [20/50], Step [38/735], Loss: 0.3244\n",
      "Epoch [20/50], Step [39/735], Loss: 0.7098\n",
      "Epoch [20/50], Step [40/735], Loss: 0.4503\n",
      "Epoch [20/50], Step [41/735], Loss: 0.2886\n",
      "Epoch [20/50], Step [42/735], Loss: 0.4931\n",
      "Epoch [20/50], Step [43/735], Loss: 0.0717\n",
      "Epoch [20/50], Step [44/735], Loss: 0.5155\n",
      "Epoch [20/50], Step [45/735], Loss: 0.5808\n",
      "Epoch [20/50], Step [46/735], Loss: 0.3146\n",
      "Epoch [20/50], Step [47/735], Loss: 0.1999\n",
      "Epoch [20/50], Step [48/735], Loss: 0.3170\n",
      "Epoch [20/50], Step [49/735], Loss: 0.1327\n",
      "Epoch [20/50], Step [50/735], Loss: 1.0073\n",
      "Epoch [20/50], Step [51/735], Loss: 0.5217\n",
      "Epoch [20/50], Step [52/735], Loss: 0.1796\n",
      "Epoch [20/50], Step [53/735], Loss: 1.1355\n",
      "Epoch [20/50], Step [54/735], Loss: 0.4437\n",
      "Epoch [20/50], Step [55/735], Loss: 0.3222\n",
      "Epoch [20/50], Step [56/735], Loss: 0.4961\n",
      "Epoch [20/50], Step [57/735], Loss: 0.8882\n",
      "Epoch [20/50], Step [58/735], Loss: 0.1122\n",
      "Epoch [20/50], Step [59/735], Loss: 0.0769\n",
      "Epoch [20/50], Step [60/735], Loss: 0.3094\n",
      "Epoch [20/50], Step [61/735], Loss: 0.2371\n",
      "Epoch [20/50], Step [62/735], Loss: 0.2608\n",
      "Epoch [20/50], Step [63/735], Loss: 0.4305\n",
      "Epoch [20/50], Step [64/735], Loss: 1.4018\n",
      "Epoch [20/50], Step [65/735], Loss: 0.1756\n",
      "Epoch [20/50], Step [66/735], Loss: 0.3933\n",
      "Epoch [20/50], Step [67/735], Loss: 0.2502\n",
      "Epoch [20/50], Step [68/735], Loss: 0.1165\n",
      "Epoch [20/50], Step [69/735], Loss: 0.2061\n",
      "Epoch [20/50], Step [70/735], Loss: 0.4911\n",
      "Epoch [20/50], Step [71/735], Loss: 0.1819\n",
      "Epoch [20/50], Step [72/735], Loss: 0.4575\n",
      "Epoch [20/50], Step [73/735], Loss: 0.5446\n",
      "Epoch [20/50], Step [74/735], Loss: 0.1553\n",
      "Epoch [20/50], Step [75/735], Loss: 0.3133\n",
      "Epoch [20/50], Step [76/735], Loss: 0.3777\n",
      "Epoch [20/50], Step [77/735], Loss: 0.5414\n",
      "Epoch [20/50], Step [78/735], Loss: 0.1054\n",
      "Epoch [20/50], Step [79/735], Loss: 0.2721\n",
      "Epoch [20/50], Step [80/735], Loss: 0.2907\n",
      "Epoch [20/50], Step [81/735], Loss: 0.4578\n",
      "Epoch [20/50], Step [82/735], Loss: 0.9766\n",
      "Epoch [20/50], Step [83/735], Loss: 0.2028\n",
      "Epoch [20/50], Step [84/735], Loss: 0.2718\n",
      "Epoch [20/50], Step [85/735], Loss: 0.0380\n",
      "Epoch [20/50], Step [86/735], Loss: 0.4018\n",
      "Epoch [20/50], Step [87/735], Loss: 0.1144\n",
      "Epoch [20/50], Step [88/735], Loss: 0.5416\n",
      "Epoch [20/50], Step [89/735], Loss: 0.6603\n",
      "Epoch [20/50], Step [90/735], Loss: 0.4464\n",
      "Epoch [20/50], Step [91/735], Loss: 1.2866\n",
      "Epoch [20/50], Step [92/735], Loss: 0.5789\n",
      "Epoch [20/50], Step [93/735], Loss: 0.5679\n",
      "Epoch [20/50], Step [94/735], Loss: 0.1924\n",
      "Epoch [20/50], Step [95/735], Loss: 0.1494\n",
      "Epoch [20/50], Step [96/735], Loss: 0.2276\n",
      "Epoch [20/50], Step [97/735], Loss: 0.3317\n",
      "Epoch [20/50], Step [98/735], Loss: 0.1637\n",
      "Epoch [20/50], Step [99/735], Loss: 0.7232\n",
      "Epoch [20/50], Step [100/735], Loss: 0.2118\n",
      "Epoch [20/50], Step [101/735], Loss: 0.2314\n",
      "Epoch [20/50], Step [102/735], Loss: 0.5989\n",
      "Epoch [20/50], Step [103/735], Loss: 0.4337\n",
      "Epoch [20/50], Step [104/735], Loss: 0.1155\n",
      "Epoch [20/50], Step [105/735], Loss: 0.4319\n",
      "Epoch [20/50], Step [106/735], Loss: 0.2758\n",
      "Epoch [20/50], Step [107/735], Loss: 0.1323\n",
      "Epoch [20/50], Step [108/735], Loss: 0.1416\n",
      "Epoch [20/50], Step [109/735], Loss: 0.4018\n",
      "Epoch [20/50], Step [110/735], Loss: 0.5591\n",
      "Epoch [20/50], Step [111/735], Loss: 0.4358\n",
      "Epoch [20/50], Step [112/735], Loss: 0.9463\n",
      "Epoch [20/50], Step [113/735], Loss: 0.6978\n",
      "Epoch [20/50], Step [114/735], Loss: 0.5296\n",
      "Epoch [20/50], Step [115/735], Loss: 0.4340\n",
      "Epoch [20/50], Step [116/735], Loss: 0.4498\n",
      "Epoch [20/50], Step [117/735], Loss: 0.3991\n",
      "Epoch [20/50], Step [118/735], Loss: 0.6461\n",
      "Epoch [20/50], Step [119/735], Loss: 0.7031\n",
      "Epoch [20/50], Step [120/735], Loss: 1.4307\n",
      "Epoch [20/50], Step [121/735], Loss: 0.1699\n",
      "Epoch [20/50], Step [122/735], Loss: 0.0746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Step [123/735], Loss: 0.3574\n",
      "Epoch [20/50], Step [124/735], Loss: 0.0995\n",
      "Epoch [20/50], Step [125/735], Loss: 0.4347\n",
      "Epoch [20/50], Step [126/735], Loss: 0.5604\n",
      "Epoch [20/50], Step [127/735], Loss: 0.2453\n",
      "Epoch [20/50], Step [128/735], Loss: 0.4823\n",
      "Epoch [20/50], Step [129/735], Loss: 0.1993\n",
      "Epoch [20/50], Step [130/735], Loss: 0.9508\n",
      "Epoch [20/50], Step [131/735], Loss: 0.2832\n",
      "Epoch [20/50], Step [132/735], Loss: 0.3266\n",
      "Epoch [20/50], Step [133/735], Loss: 0.5606\n",
      "Epoch [20/50], Step [134/735], Loss: 0.1270\n",
      "Epoch [20/50], Step [135/735], Loss: 0.4636\n",
      "Epoch [20/50], Step [136/735], Loss: 0.4170\n",
      "Epoch [20/50], Step [137/735], Loss: 0.0699\n",
      "Epoch [20/50], Step [138/735], Loss: 0.2416\n",
      "Epoch [20/50], Step [139/735], Loss: 1.9663\n",
      "Epoch [20/50], Step [140/735], Loss: 0.2528\n",
      "Epoch [20/50], Step [141/735], Loss: 0.3544\n",
      "Epoch [20/50], Step [142/735], Loss: 0.3037\n",
      "Epoch [20/50], Step [143/735], Loss: 0.1187\n",
      "Epoch [20/50], Step [144/735], Loss: 0.2984\n",
      "Epoch [20/50], Step [145/735], Loss: 0.2364\n",
      "Epoch [20/50], Step [146/735], Loss: 0.2815\n",
      "Epoch [20/50], Step [147/735], Loss: 0.2350\n",
      "Epoch [20/50], Step [148/735], Loss: 0.6124\n",
      "Epoch [20/50], Step [149/735], Loss: 0.3123\n",
      "Epoch [20/50], Step [150/735], Loss: 0.1161\n",
      "Epoch [20/50], Step [151/735], Loss: 0.2860\n",
      "Epoch [20/50], Step [152/735], Loss: 0.2821\n",
      "Epoch [20/50], Step [153/735], Loss: 0.2924\n",
      "Epoch [20/50], Step [154/735], Loss: 0.2598\n",
      "Epoch [20/50], Step [155/735], Loss: 0.5466\n",
      "Epoch [20/50], Step [156/735], Loss: 0.4110\n",
      "Epoch [20/50], Step [157/735], Loss: 0.1728\n",
      "Epoch [20/50], Step [158/735], Loss: 0.8560\n",
      "Epoch [20/50], Step [159/735], Loss: 0.2364\n",
      "Epoch [20/50], Step [160/735], Loss: 0.3852\n",
      "Epoch [20/50], Step [161/735], Loss: 0.1780\n",
      "Epoch [20/50], Step [162/735], Loss: 0.3067\n",
      "Epoch [20/50], Step [163/735], Loss: 0.5235\n",
      "Epoch [20/50], Step [164/735], Loss: 0.2276\n",
      "Epoch [20/50], Step [165/735], Loss: 0.6794\n",
      "Epoch [20/50], Step [166/735], Loss: 0.2270\n",
      "Epoch [20/50], Step [167/735], Loss: 0.3420\n",
      "Epoch [20/50], Step [168/735], Loss: 0.3741\n",
      "Epoch [20/50], Step [169/735], Loss: 0.6199\n",
      "Epoch [20/50], Step [170/735], Loss: 0.5801\n",
      "Epoch [20/50], Step [171/735], Loss: 0.4996\n",
      "Epoch [20/50], Step [172/735], Loss: 1.0042\n",
      "Epoch [20/50], Step [173/735], Loss: 0.3191\n",
      "Epoch [20/50], Step [174/735], Loss: 0.3786\n",
      "Epoch [20/50], Step [175/735], Loss: 1.2831\n",
      "Epoch [20/50], Step [176/735], Loss: 0.1140\n",
      "Epoch [20/50], Step [177/735], Loss: 0.2588\n",
      "Epoch [20/50], Step [178/735], Loss: 0.2075\n",
      "Epoch [20/50], Step [179/735], Loss: 0.3309\n",
      "Epoch [20/50], Step [180/735], Loss: 0.7477\n",
      "Epoch [20/50], Step [181/735], Loss: 0.9236\n",
      "Epoch [20/50], Step [182/735], Loss: 0.2255\n",
      "Epoch [20/50], Step [183/735], Loss: 0.3820\n",
      "Epoch [20/50], Step [184/735], Loss: 0.5908\n",
      "Epoch [20/50], Step [185/735], Loss: 0.3557\n",
      "Epoch [20/50], Step [186/735], Loss: 0.1963\n",
      "Epoch [20/50], Step [187/735], Loss: 1.7168\n",
      "Epoch [20/50], Step [188/735], Loss: 0.2258\n",
      "Epoch [20/50], Step [189/735], Loss: 0.2102\n",
      "Epoch [20/50], Step [190/735], Loss: 0.3740\n",
      "Epoch [20/50], Step [191/735], Loss: 1.6952\n",
      "Epoch [20/50], Step [192/735], Loss: 0.0786\n",
      "Epoch [20/50], Step [193/735], Loss: 0.2891\n",
      "Epoch [20/50], Step [194/735], Loss: 0.4123\n",
      "Epoch [20/50], Step [195/735], Loss: 0.7596\n",
      "Epoch [20/50], Step [196/735], Loss: 0.5663\n",
      "Epoch [20/50], Step [197/735], Loss: 0.2524\n",
      "Epoch [20/50], Step [198/735], Loss: 3.9585\n",
      "Epoch [20/50], Step [199/735], Loss: 1.0110\n",
      "Epoch [20/50], Step [200/735], Loss: 0.7226\n",
      "Epoch [20/50], Step [201/735], Loss: 0.3458\n",
      "Epoch [20/50], Step [202/735], Loss: 0.4543\n",
      "Epoch [20/50], Step [203/735], Loss: 0.1991\n",
      "Epoch [20/50], Step [204/735], Loss: 0.9326\n",
      "Epoch [20/50], Step [205/735], Loss: 0.1951\n",
      "Epoch [20/50], Step [206/735], Loss: 0.2508\n",
      "Epoch [20/50], Step [207/735], Loss: 0.2198\n",
      "Epoch [20/50], Step [208/735], Loss: 0.1542\n",
      "Epoch [20/50], Step [209/735], Loss: 0.6469\n",
      "Epoch [20/50], Step [210/735], Loss: 0.2455\n",
      "Epoch [20/50], Step [211/735], Loss: 0.4415\n",
      "Epoch [20/50], Step [212/735], Loss: 0.3156\n",
      "Epoch [20/50], Step [213/735], Loss: 0.3940\n",
      "Epoch [20/50], Step [214/735], Loss: 0.4048\n",
      "Epoch [20/50], Step [215/735], Loss: 1.1185\n",
      "Epoch [20/50], Step [216/735], Loss: 0.0884\n",
      "Epoch [20/50], Step [217/735], Loss: 0.3419\n",
      "Epoch [20/50], Step [218/735], Loss: 0.5415\n",
      "Epoch [20/50], Step [219/735], Loss: 0.1020\n",
      "Epoch [20/50], Step [220/735], Loss: 0.2966\n",
      "Epoch [20/50], Step [221/735], Loss: 0.3306\n",
      "Epoch [20/50], Step [222/735], Loss: 0.6262\n",
      "Epoch [20/50], Step [223/735], Loss: 1.6796\n",
      "Epoch [20/50], Step [224/735], Loss: 1.5767\n",
      "Epoch [20/50], Step [225/735], Loss: 0.7201\n",
      "Epoch [20/50], Step [226/735], Loss: 0.1596\n",
      "Epoch [20/50], Step [227/735], Loss: 0.2947\n",
      "Epoch [20/50], Step [228/735], Loss: 0.1346\n",
      "Epoch [20/50], Step [229/735], Loss: 0.2470\n",
      "Epoch [20/50], Step [230/735], Loss: 0.3556\n",
      "Epoch [20/50], Step [231/735], Loss: 0.2006\n",
      "Epoch [20/50], Step [232/735], Loss: 0.5031\n",
      "Epoch [20/50], Step [233/735], Loss: 0.3214\n",
      "Epoch [20/50], Step [234/735], Loss: 0.7251\n",
      "Epoch [20/50], Step [235/735], Loss: 0.5642\n",
      "Epoch [20/50], Step [236/735], Loss: 0.1439\n",
      "Epoch [20/50], Step [237/735], Loss: 0.2145\n",
      "Epoch [20/50], Step [238/735], Loss: 1.2554\n",
      "Epoch [20/50], Step [239/735], Loss: 0.2420\n",
      "Epoch [20/50], Step [240/735], Loss: 1.6849\n",
      "Epoch [20/50], Step [241/735], Loss: 0.3680\n",
      "Epoch [20/50], Step [242/735], Loss: 0.7808\n",
      "Epoch [20/50], Step [243/735], Loss: 0.3455\n",
      "Epoch [20/50], Step [244/735], Loss: 0.2047\n",
      "Epoch [20/50], Step [245/735], Loss: 0.2170\n",
      "Epoch [20/50], Step [246/735], Loss: 0.3149\n",
      "Epoch [20/50], Step [247/735], Loss: 0.3045\n",
      "Epoch [20/50], Step [248/735], Loss: 0.2489\n",
      "Epoch [20/50], Step [249/735], Loss: 0.4094\n",
      "Epoch [20/50], Step [250/735], Loss: 0.2885\n",
      "Epoch [20/50], Step [251/735], Loss: 0.1748\n",
      "Epoch [20/50], Step [252/735], Loss: 0.2161\n",
      "Epoch [20/50], Step [253/735], Loss: 0.0985\n",
      "Epoch [20/50], Step [254/735], Loss: 0.6510\n",
      "Epoch [20/50], Step [255/735], Loss: 0.0268\n",
      "Epoch [20/50], Step [256/735], Loss: 0.2588\n",
      "Epoch [20/50], Step [257/735], Loss: 0.1310\n",
      "Epoch [20/50], Step [258/735], Loss: 0.2613\n",
      "Epoch [20/50], Step [259/735], Loss: 0.3196\n",
      "Epoch [20/50], Step [260/735], Loss: 0.5814\n",
      "Epoch [20/50], Step [261/735], Loss: 0.4510\n",
      "Epoch [20/50], Step [262/735], Loss: 0.7217\n",
      "Epoch [20/50], Step [263/735], Loss: 0.3136\n",
      "Epoch [20/50], Step [264/735], Loss: 0.2603\n",
      "Epoch [20/50], Step [265/735], Loss: 0.9853\n",
      "Epoch [20/50], Step [266/735], Loss: 0.4267\n",
      "Epoch [20/50], Step [267/735], Loss: 0.2511\n",
      "Epoch [20/50], Step [268/735], Loss: 0.1962\n",
      "Epoch [20/50], Step [269/735], Loss: 0.1549\n",
      "Epoch [20/50], Step [270/735], Loss: 0.1940\n",
      "Epoch [20/50], Step [271/735], Loss: 0.2728\n",
      "Epoch [20/50], Step [272/735], Loss: 0.5328\n",
      "Epoch [20/50], Step [273/735], Loss: 0.5440\n",
      "Epoch [20/50], Step [274/735], Loss: 0.1855\n",
      "Epoch [20/50], Step [275/735], Loss: 0.2509\n",
      "Epoch [20/50], Step [276/735], Loss: 0.9586\n",
      "Epoch [20/50], Step [277/735], Loss: 0.0964\n",
      "Epoch [20/50], Step [278/735], Loss: 1.0031\n",
      "Epoch [20/50], Step [279/735], Loss: 0.1494\n",
      "Epoch [20/50], Step [280/735], Loss: 0.1348\n",
      "Epoch [20/50], Step [281/735], Loss: 0.4918\n",
      "Epoch [20/50], Step [282/735], Loss: 0.4679\n",
      "Epoch [20/50], Step [283/735], Loss: 0.2647\n",
      "Epoch [20/50], Step [284/735], Loss: 0.3764\n",
      "Epoch [20/50], Step [285/735], Loss: 0.7340\n",
      "Epoch [20/50], Step [286/735], Loss: 0.4603\n",
      "Epoch [20/50], Step [287/735], Loss: 0.6044\n",
      "Epoch [20/50], Step [288/735], Loss: 0.2350\n",
      "Epoch [20/50], Step [289/735], Loss: 0.9333\n",
      "Epoch [20/50], Step [290/735], Loss: 0.8143\n",
      "Epoch [20/50], Step [291/735], Loss: 1.0363\n",
      "Epoch [20/50], Step [292/735], Loss: 0.2372\n",
      "Epoch [20/50], Step [293/735], Loss: 0.0928\n",
      "Epoch [20/50], Step [294/735], Loss: 0.1059\n",
      "Epoch [20/50], Step [295/735], Loss: 0.9674\n",
      "Epoch [20/50], Step [296/735], Loss: 0.5810\n",
      "Epoch [20/50], Step [297/735], Loss: 0.2550\n",
      "Epoch [20/50], Step [298/735], Loss: 0.0932\n",
      "Epoch [20/50], Step [299/735], Loss: 0.1310\n",
      "Epoch [20/50], Step [300/735], Loss: 0.0660\n",
      "Epoch [20/50], Step [301/735], Loss: 0.6163\n",
      "Epoch [20/50], Step [302/735], Loss: 0.2852\n",
      "Epoch [20/50], Step [303/735], Loss: 0.2343\n",
      "Epoch [20/50], Step [304/735], Loss: 0.4156\n",
      "Epoch [20/50], Step [305/735], Loss: 0.1486\n",
      "Epoch [20/50], Step [306/735], Loss: 0.1541\n",
      "Epoch [20/50], Step [307/735], Loss: 0.1741\n",
      "Epoch [20/50], Step [308/735], Loss: 0.2196\n",
      "Epoch [20/50], Step [309/735], Loss: 0.5681\n",
      "Epoch [20/50], Step [310/735], Loss: 1.6786\n",
      "Epoch [20/50], Step [311/735], Loss: 0.5884\n",
      "Epoch [20/50], Step [312/735], Loss: 0.4235\n",
      "Epoch [20/50], Step [313/735], Loss: 0.1227\n",
      "Epoch [20/50], Step [314/735], Loss: 0.1903\n",
      "Epoch [20/50], Step [315/735], Loss: 0.2776\n",
      "Epoch [20/50], Step [316/735], Loss: 0.0341\n",
      "Epoch [20/50], Step [317/735], Loss: 0.2448\n",
      "Epoch [20/50], Step [318/735], Loss: 0.3915\n",
      "Epoch [20/50], Step [319/735], Loss: 0.0937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Step [320/735], Loss: 0.2494\n",
      "Epoch [20/50], Step [321/735], Loss: 0.2328\n",
      "Epoch [20/50], Step [322/735], Loss: 0.1929\n",
      "Epoch [20/50], Step [323/735], Loss: 0.5781\n",
      "Epoch [20/50], Step [324/735], Loss: 0.2152\n",
      "Epoch [20/50], Step [325/735], Loss: 0.3354\n",
      "Epoch [20/50], Step [326/735], Loss: 0.2024\n",
      "Epoch [20/50], Step [327/735], Loss: 0.6551\n",
      "Epoch [20/50], Step [328/735], Loss: 0.2505\n",
      "Epoch [20/50], Step [329/735], Loss: 0.1365\n",
      "Epoch [20/50], Step [330/735], Loss: 0.4853\n",
      "Epoch [20/50], Step [331/735], Loss: 0.3190\n",
      "Epoch [20/50], Step [332/735], Loss: 0.4862\n",
      "Epoch [20/50], Step [333/735], Loss: 2.0598\n",
      "Epoch [20/50], Step [334/735], Loss: 0.3784\n",
      "Epoch [20/50], Step [335/735], Loss: 0.7373\n",
      "Epoch [20/50], Step [336/735], Loss: 0.1367\n",
      "Epoch [20/50], Step [337/735], Loss: 0.2628\n",
      "Epoch [20/50], Step [338/735], Loss: 0.5438\n",
      "Epoch [20/50], Step [339/735], Loss: 0.4634\n",
      "Epoch [20/50], Step [340/735], Loss: 0.4676\n",
      "Epoch [20/50], Step [341/735], Loss: 0.3093\n",
      "Epoch [20/50], Step [342/735], Loss: 0.5899\n",
      "Epoch [20/50], Step [343/735], Loss: 0.1194\n",
      "Epoch [20/50], Step [344/735], Loss: 0.2451\n",
      "Epoch [20/50], Step [345/735], Loss: 0.0680\n",
      "Epoch [20/50], Step [346/735], Loss: 0.5524\n",
      "Epoch [20/50], Step [347/735], Loss: 0.6665\n",
      "Epoch [20/50], Step [348/735], Loss: 1.6733\n",
      "Epoch [20/50], Step [349/735], Loss: 0.7025\n",
      "Epoch [20/50], Step [350/735], Loss: 1.2088\n",
      "Epoch [20/50], Step [351/735], Loss: 0.1531\n",
      "Epoch [20/50], Step [352/735], Loss: 0.1273\n",
      "Epoch [20/50], Step [353/735], Loss: 0.3405\n",
      "Epoch [20/50], Step [354/735], Loss: 0.2263\n",
      "Epoch [20/50], Step [355/735], Loss: 0.4143\n",
      "Epoch [20/50], Step [356/735], Loss: 0.1073\n",
      "Epoch [20/50], Step [357/735], Loss: 0.0779\n",
      "Epoch [20/50], Step [358/735], Loss: 0.3183\n",
      "Epoch [20/50], Step [359/735], Loss: 0.2518\n",
      "Epoch [20/50], Step [360/735], Loss: 0.2552\n",
      "Epoch [20/50], Step [361/735], Loss: 0.3441\n",
      "Epoch [20/50], Step [362/735], Loss: 0.3636\n",
      "Epoch [20/50], Step [363/735], Loss: 0.1139\n",
      "Epoch [20/50], Step [364/735], Loss: 0.4639\n",
      "Epoch [20/50], Step [365/735], Loss: 0.1716\n",
      "Epoch [20/50], Step [366/735], Loss: 0.1855\n",
      "Epoch [20/50], Step [367/735], Loss: 0.1742\n",
      "Epoch [20/50], Step [368/735], Loss: 4.5938\n",
      "Epoch [20/50], Step [369/735], Loss: 0.4609\n",
      "Epoch [20/50], Step [370/735], Loss: 0.4208\n",
      "Epoch [20/50], Step [371/735], Loss: 0.3676\n",
      "Epoch [20/50], Step [372/735], Loss: 0.4042\n",
      "Epoch [20/50], Step [373/735], Loss: 1.3004\n",
      "Epoch [20/50], Step [374/735], Loss: 0.4992\n",
      "Epoch [20/50], Step [375/735], Loss: 0.1974\n",
      "Epoch [20/50], Step [376/735], Loss: 0.1200\n",
      "Epoch [20/50], Step [377/735], Loss: 0.1122\n",
      "Epoch [20/50], Step [378/735], Loss: 0.3296\n",
      "Epoch [20/50], Step [379/735], Loss: 0.4672\n",
      "Epoch [20/50], Step [380/735], Loss: 0.2208\n",
      "Epoch [20/50], Step [381/735], Loss: 4.3791\n",
      "Epoch [20/50], Step [382/735], Loss: 0.6590\n",
      "Epoch [20/50], Step [383/735], Loss: 0.1835\n",
      "Epoch [20/50], Step [384/735], Loss: 0.0910\n",
      "Epoch [20/50], Step [385/735], Loss: 0.6554\n",
      "Epoch [20/50], Step [386/735], Loss: 0.4136\n",
      "Epoch [20/50], Step [387/735], Loss: 0.2862\n",
      "Epoch [20/50], Step [388/735], Loss: 0.2891\n",
      "Epoch [20/50], Step [389/735], Loss: 0.0947\n",
      "Epoch [20/50], Step [390/735], Loss: 0.6947\n",
      "Epoch [20/50], Step [391/735], Loss: 1.8554\n",
      "Epoch [20/50], Step [392/735], Loss: 0.2175\n",
      "Epoch [20/50], Step [393/735], Loss: 0.6773\n",
      "Epoch [20/50], Step [394/735], Loss: 0.6452\n",
      "Epoch [20/50], Step [395/735], Loss: 0.1670\n",
      "Epoch [20/50], Step [396/735], Loss: 0.2427\n",
      "Epoch [20/50], Step [397/735], Loss: 0.3818\n",
      "Epoch [20/50], Step [398/735], Loss: 0.2924\n",
      "Epoch [20/50], Step [399/735], Loss: 0.8007\n",
      "Epoch [20/50], Step [400/735], Loss: 1.4195\n",
      "Epoch [20/50], Step [401/735], Loss: 0.3701\n",
      "Epoch [20/50], Step [402/735], Loss: 0.2368\n",
      "Epoch [20/50], Step [403/735], Loss: 0.1037\n",
      "Epoch [20/50], Step [404/735], Loss: 0.3514\n",
      "Epoch [20/50], Step [405/735], Loss: 0.5532\n",
      "Epoch [20/50], Step [406/735], Loss: 0.7911\n",
      "Epoch [20/50], Step [407/735], Loss: 0.7621\n",
      "Epoch [20/50], Step [408/735], Loss: 0.2586\n",
      "Epoch [20/50], Step [409/735], Loss: 0.4432\n",
      "Epoch [20/50], Step [410/735], Loss: 0.1733\n",
      "Epoch [20/50], Step [411/735], Loss: 0.2677\n",
      "Epoch [20/50], Step [412/735], Loss: 0.5231\n",
      "Epoch [20/50], Step [413/735], Loss: 0.3408\n",
      "Epoch [20/50], Step [414/735], Loss: 0.0719\n",
      "Epoch [20/50], Step [415/735], Loss: 0.0686\n",
      "Epoch [20/50], Step [416/735], Loss: 0.7990\n",
      "Epoch [20/50], Step [417/735], Loss: 0.0975\n",
      "Epoch [20/50], Step [418/735], Loss: 0.2058\n",
      "Epoch [20/50], Step [419/735], Loss: 0.3803\n",
      "Epoch [20/50], Step [420/735], Loss: 0.3883\n",
      "Epoch [20/50], Step [421/735], Loss: 0.1425\n",
      "Epoch [20/50], Step [422/735], Loss: 0.5625\n",
      "Epoch [20/50], Step [423/735], Loss: 1.1101\n",
      "Epoch [20/50], Step [424/735], Loss: 0.3522\n",
      "Epoch [20/50], Step [425/735], Loss: 0.5696\n",
      "Epoch [20/50], Step [426/735], Loss: 0.0659\n",
      "Epoch [20/50], Step [427/735], Loss: 0.2707\n",
      "Epoch [20/50], Step [428/735], Loss: 0.3057\n",
      "Epoch [20/50], Step [429/735], Loss: 0.2257\n",
      "Epoch [20/50], Step [430/735], Loss: 0.7138\n",
      "Epoch [20/50], Step [431/735], Loss: 0.1549\n",
      "Epoch [20/50], Step [432/735], Loss: 0.1362\n",
      "Epoch [20/50], Step [433/735], Loss: 0.2785\n",
      "Epoch [20/50], Step [434/735], Loss: 0.1339\n",
      "Epoch [20/50], Step [435/735], Loss: 0.5160\n",
      "Epoch [20/50], Step [436/735], Loss: 0.3395\n",
      "Epoch [20/50], Step [437/735], Loss: 0.2687\n",
      "Epoch [20/50], Step [438/735], Loss: 0.2971\n",
      "Epoch [20/50], Step [439/735], Loss: 0.3143\n",
      "Epoch [20/50], Step [440/735], Loss: 0.0652\n",
      "Epoch [20/50], Step [441/735], Loss: 0.3244\n",
      "Epoch [20/50], Step [442/735], Loss: 1.1620\n",
      "Epoch [20/50], Step [443/735], Loss: 0.1769\n",
      "Epoch [20/50], Step [444/735], Loss: 2.1461\n",
      "Epoch [20/50], Step [445/735], Loss: 0.3932\n",
      "Epoch [20/50], Step [446/735], Loss: 1.4905\n",
      "Epoch [20/50], Step [447/735], Loss: 1.0640\n",
      "Epoch [20/50], Step [448/735], Loss: 1.0691\n",
      "Epoch [20/50], Step [449/735], Loss: 0.4070\n",
      "Epoch [20/50], Step [450/735], Loss: 0.9462\n",
      "Epoch [20/50], Step [451/735], Loss: 0.2144\n",
      "Epoch [20/50], Step [452/735], Loss: 0.3990\n",
      "Epoch [20/50], Step [453/735], Loss: 0.2929\n",
      "Epoch [20/50], Step [454/735], Loss: 0.0456\n",
      "Epoch [20/50], Step [455/735], Loss: 0.3954\n",
      "Epoch [20/50], Step [456/735], Loss: 0.1915\n",
      "Epoch [20/50], Step [457/735], Loss: 0.1029\n",
      "Epoch [20/50], Step [458/735], Loss: 0.4257\n",
      "Epoch [20/50], Step [459/735], Loss: 0.4545\n",
      "Epoch [20/50], Step [460/735], Loss: 0.3749\n",
      "Epoch [20/50], Step [461/735], Loss: 0.2462\n",
      "Epoch [20/50], Step [462/735], Loss: 0.1975\n",
      "Epoch [20/50], Step [463/735], Loss: 0.4153\n",
      "Epoch [20/50], Step [464/735], Loss: 0.1624\n",
      "Epoch [20/50], Step [465/735], Loss: 0.2637\n",
      "Epoch [20/50], Step [466/735], Loss: 0.6177\n",
      "Epoch [20/50], Step [467/735], Loss: 0.3166\n",
      "Epoch [20/50], Step [468/735], Loss: 0.7283\n",
      "Epoch [20/50], Step [469/735], Loss: 0.4586\n",
      "Epoch [20/50], Step [470/735], Loss: 0.1750\n",
      "Epoch [20/50], Step [471/735], Loss: 0.1957\n",
      "Epoch [20/50], Step [472/735], Loss: 0.1585\n",
      "Epoch [20/50], Step [473/735], Loss: 0.6186\n",
      "Epoch [20/50], Step [474/735], Loss: 0.2924\n",
      "Epoch [20/50], Step [475/735], Loss: 0.3977\n",
      "Epoch [20/50], Step [476/735], Loss: 0.2069\n",
      "Epoch [20/50], Step [477/735], Loss: 0.2849\n",
      "Epoch [20/50], Step [478/735], Loss: 0.7173\n",
      "Epoch [20/50], Step [479/735], Loss: 1.9421\n",
      "Epoch [20/50], Step [480/735], Loss: 0.2770\n",
      "Epoch [20/50], Step [481/735], Loss: 0.1581\n",
      "Epoch [20/50], Step [482/735], Loss: 0.2480\n",
      "Epoch [20/50], Step [483/735], Loss: 0.3106\n",
      "Epoch [20/50], Step [484/735], Loss: 0.1918\n",
      "Epoch [20/50], Step [485/735], Loss: 0.4643\n",
      "Epoch [20/50], Step [486/735], Loss: 0.3254\n",
      "Epoch [20/50], Step [487/735], Loss: 0.5538\n",
      "Epoch [20/50], Step [488/735], Loss: 0.7978\n",
      "Epoch [20/50], Step [489/735], Loss: 0.3072\n",
      "Epoch [20/50], Step [490/735], Loss: 0.7198\n",
      "Epoch [20/50], Step [491/735], Loss: 0.4438\n",
      "Epoch [20/50], Step [492/735], Loss: 0.1365\n",
      "Epoch [20/50], Step [493/735], Loss: 0.2281\n",
      "Epoch [20/50], Step [494/735], Loss: 0.7539\n",
      "Epoch [20/50], Step [495/735], Loss: 0.3023\n",
      "Epoch [20/50], Step [496/735], Loss: 0.0967\n",
      "Epoch [20/50], Step [497/735], Loss: 0.2099\n",
      "Epoch [20/50], Step [498/735], Loss: 0.5023\n",
      "Epoch [20/50], Step [499/735], Loss: 0.1491\n",
      "Epoch [20/50], Step [500/735], Loss: 0.3332\n",
      "Epoch [20/50], Step [501/735], Loss: 0.1770\n",
      "Epoch [20/50], Step [502/735], Loss: 0.3626\n",
      "Epoch [20/50], Step [503/735], Loss: 2.0630\n",
      "Epoch [20/50], Step [504/735], Loss: 0.3740\n",
      "Epoch [20/50], Step [505/735], Loss: 0.2574\n",
      "Epoch [20/50], Step [506/735], Loss: 0.1898\n",
      "Epoch [20/50], Step [507/735], Loss: 0.3571\n",
      "Epoch [20/50], Step [508/735], Loss: 0.1157\n",
      "Epoch [20/50], Step [509/735], Loss: 1.0978\n",
      "Epoch [20/50], Step [510/735], Loss: 0.3506\n",
      "Epoch [20/50], Step [511/735], Loss: 0.3967\n",
      "Epoch [20/50], Step [512/735], Loss: 0.1798\n",
      "Epoch [20/50], Step [513/735], Loss: 0.2422\n",
      "Epoch [20/50], Step [514/735], Loss: 0.4974\n",
      "Epoch [20/50], Step [515/735], Loss: 0.7032\n",
      "Epoch [20/50], Step [516/735], Loss: 1.7833\n",
      "Epoch [20/50], Step [517/735], Loss: 0.3572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Step [518/735], Loss: 0.5399\n",
      "Epoch [20/50], Step [519/735], Loss: 0.1175\n",
      "Epoch [20/50], Step [520/735], Loss: 0.7502\n",
      "Epoch [20/50], Step [521/735], Loss: 1.3569\n",
      "Epoch [20/50], Step [522/735], Loss: 0.1361\n",
      "Epoch [20/50], Step [523/735], Loss: 0.1246\n",
      "Epoch [20/50], Step [524/735], Loss: 0.6707\n",
      "Epoch [20/50], Step [525/735], Loss: 0.0984\n",
      "Epoch [20/50], Step [526/735], Loss: 1.2494\n",
      "Epoch [20/50], Step [527/735], Loss: 0.3110\n",
      "Epoch [20/50], Step [528/735], Loss: 0.3016\n",
      "Epoch [20/50], Step [529/735], Loss: 0.1799\n",
      "Epoch [20/50], Step [530/735], Loss: 0.5517\n",
      "Epoch [20/50], Step [531/735], Loss: 0.3978\n",
      "Epoch [20/50], Step [532/735], Loss: 0.0991\n",
      "Epoch [20/50], Step [533/735], Loss: 0.2120\n",
      "Epoch [20/50], Step [534/735], Loss: 0.2255\n",
      "Epoch [20/50], Step [535/735], Loss: 0.6278\n",
      "Epoch [20/50], Step [536/735], Loss: 0.4825\n",
      "Epoch [20/50], Step [537/735], Loss: 0.2255\n",
      "Epoch [20/50], Step [538/735], Loss: 0.2087\n",
      "Epoch [20/50], Step [539/735], Loss: 0.4480\n",
      "Epoch [20/50], Step [540/735], Loss: 0.3829\n",
      "Epoch [20/50], Step [541/735], Loss: 0.7744\n",
      "Epoch [20/50], Step [542/735], Loss: 1.1146\n",
      "Epoch [20/50], Step [543/735], Loss: 0.3222\n",
      "Epoch [20/50], Step [544/735], Loss: 0.3023\n",
      "Epoch [20/50], Step [545/735], Loss: 0.3650\n",
      "Epoch [20/50], Step [546/735], Loss: 0.2730\n",
      "Epoch [20/50], Step [547/735], Loss: 1.1621\n",
      "Epoch [20/50], Step [548/735], Loss: 0.3826\n",
      "Epoch [20/50], Step [549/735], Loss: 0.2837\n",
      "Epoch [20/50], Step [550/735], Loss: 0.4716\n",
      "Epoch [20/50], Step [551/735], Loss: 1.7100\n",
      "Epoch [20/50], Step [552/735], Loss: 0.7640\n",
      "Epoch [20/50], Step [553/735], Loss: 0.9137\n",
      "Epoch [20/50], Step [554/735], Loss: 0.7131\n",
      "Epoch [20/50], Step [555/735], Loss: 4.8443\n",
      "Epoch [20/50], Step [556/735], Loss: 0.4363\n",
      "Epoch [20/50], Step [557/735], Loss: 0.1250\n",
      "Epoch [20/50], Step [558/735], Loss: 0.4405\n",
      "Epoch [20/50], Step [559/735], Loss: 0.4170\n",
      "Epoch [20/50], Step [560/735], Loss: 0.2142\n",
      "Epoch [20/50], Step [561/735], Loss: 0.3850\n",
      "Epoch [20/50], Step [562/735], Loss: 0.2194\n",
      "Epoch [20/50], Step [563/735], Loss: 0.2403\n",
      "Epoch [20/50], Step [564/735], Loss: 0.1005\n",
      "Epoch [20/50], Step [565/735], Loss: 0.4215\n",
      "Epoch [20/50], Step [566/735], Loss: 0.7033\n",
      "Epoch [20/50], Step [567/735], Loss: 0.3482\n",
      "Epoch [20/50], Step [568/735], Loss: 0.1643\n",
      "Epoch [20/50], Step [569/735], Loss: 4.4432\n",
      "Epoch [20/50], Step [570/735], Loss: 0.4579\n",
      "Epoch [20/50], Step [571/735], Loss: 0.0695\n",
      "Epoch [20/50], Step [572/735], Loss: 0.4254\n",
      "Epoch [20/50], Step [573/735], Loss: 0.1601\n",
      "Epoch [20/50], Step [574/735], Loss: 0.2018\n",
      "Epoch [20/50], Step [575/735], Loss: 0.4067\n",
      "Epoch [20/50], Step [576/735], Loss: 0.3155\n",
      "Epoch [20/50], Step [577/735], Loss: 0.0799\n",
      "Epoch [20/50], Step [578/735], Loss: 0.3828\n",
      "Epoch [20/50], Step [579/735], Loss: 0.1518\n",
      "Epoch [20/50], Step [580/735], Loss: 0.3110\n",
      "Epoch [20/50], Step [581/735], Loss: 0.8603\n",
      "Epoch [20/50], Step [582/735], Loss: 0.2468\n",
      "Epoch [20/50], Step [583/735], Loss: 0.2219\n",
      "Epoch [20/50], Step [584/735], Loss: 0.2001\n",
      "Epoch [20/50], Step [585/735], Loss: 0.2474\n",
      "Epoch [20/50], Step [586/735], Loss: 0.7246\n",
      "Epoch [20/50], Step [587/735], Loss: 0.6286\n",
      "Epoch [20/50], Step [588/735], Loss: 0.2544\n",
      "Epoch [20/50], Step [589/735], Loss: 0.1298\n",
      "Epoch [20/50], Step [590/735], Loss: 0.1384\n",
      "Epoch [20/50], Step [591/735], Loss: 0.2805\n",
      "Epoch [20/50], Step [592/735], Loss: 0.2171\n",
      "Epoch [20/50], Step [593/735], Loss: 0.3659\n",
      "Epoch [20/50], Step [594/735], Loss: 0.3462\n",
      "Epoch [20/50], Step [595/735], Loss: 1.9692\n",
      "Epoch [20/50], Step [596/735], Loss: 0.6556\n",
      "Epoch [20/50], Step [597/735], Loss: 0.4185\n",
      "Epoch [20/50], Step [598/735], Loss: 0.3240\n",
      "Epoch [20/50], Step [599/735], Loss: 0.5054\n",
      "Epoch [20/50], Step [600/735], Loss: 0.4287\n",
      "Epoch [20/50], Step [601/735], Loss: 0.7921\n",
      "Epoch [20/50], Step [602/735], Loss: 0.4525\n",
      "Epoch [20/50], Step [603/735], Loss: 0.6830\n",
      "Epoch [20/50], Step [604/735], Loss: 0.6154\n",
      "Epoch [20/50], Step [605/735], Loss: 0.1610\n",
      "Epoch [20/50], Step [606/735], Loss: 0.8460\n",
      "Epoch [20/50], Step [607/735], Loss: 0.2150\n",
      "Epoch [20/50], Step [608/735], Loss: 1.3169\n",
      "Epoch [20/50], Step [609/735], Loss: 0.2322\n",
      "Epoch [20/50], Step [610/735], Loss: 0.8945\n",
      "Epoch [20/50], Step [611/735], Loss: 0.2354\n",
      "Epoch [20/50], Step [612/735], Loss: 0.8008\n",
      "Epoch [20/50], Step [613/735], Loss: 0.6355\n",
      "Epoch [20/50], Step [614/735], Loss: 0.2106\n",
      "Epoch [20/50], Step [615/735], Loss: 0.2845\n",
      "Epoch [20/50], Step [616/735], Loss: 0.8987\n",
      "Epoch [20/50], Step [617/735], Loss: 0.0760\n",
      "Epoch [20/50], Step [618/735], Loss: 0.6917\n",
      "Epoch [20/50], Step [619/735], Loss: 0.1202\n",
      "Epoch [20/50], Step [620/735], Loss: 0.7821\n",
      "Epoch [20/50], Step [621/735], Loss: 0.6364\n",
      "Epoch [20/50], Step [622/735], Loss: 0.0719\n",
      "Epoch [20/50], Step [623/735], Loss: 0.3889\n",
      "Epoch [20/50], Step [624/735], Loss: 0.6512\n",
      "Epoch [20/50], Step [625/735], Loss: 0.5123\n",
      "Epoch [20/50], Step [626/735], Loss: 0.2027\n",
      "Epoch [20/50], Step [627/735], Loss: 0.1478\n",
      "Epoch [20/50], Step [628/735], Loss: 0.7300\n",
      "Epoch [20/50], Step [629/735], Loss: 0.2135\n",
      "Epoch [20/50], Step [630/735], Loss: 0.6700\n",
      "Epoch [20/50], Step [631/735], Loss: 0.0883\n",
      "Epoch [20/50], Step [632/735], Loss: 0.1346\n",
      "Epoch [20/50], Step [633/735], Loss: 0.3370\n",
      "Epoch [20/50], Step [634/735], Loss: 0.3919\n",
      "Epoch [20/50], Step [635/735], Loss: 0.1070\n",
      "Epoch [20/50], Step [636/735], Loss: 0.3346\n",
      "Epoch [20/50], Step [637/735], Loss: 0.2137\n",
      "Epoch [20/50], Step [638/735], Loss: 0.1151\n",
      "Epoch [20/50], Step [639/735], Loss: 0.5906\n",
      "Epoch [20/50], Step [640/735], Loss: 0.3551\n",
      "Epoch [20/50], Step [641/735], Loss: 0.4377\n",
      "Epoch [20/50], Step [642/735], Loss: 0.4004\n",
      "Epoch [20/50], Step [643/735], Loss: 0.5485\n",
      "Epoch [20/50], Step [644/735], Loss: 0.1163\n",
      "Epoch [20/50], Step [645/735], Loss: 0.3300\n",
      "Epoch [20/50], Step [646/735], Loss: 0.2905\n",
      "Epoch [20/50], Step [647/735], Loss: 0.3031\n",
      "Epoch [20/50], Step [648/735], Loss: 0.1360\n",
      "Epoch [20/50], Step [649/735], Loss: 0.2284\n",
      "Epoch [20/50], Step [650/735], Loss: 0.4252\n",
      "Epoch [20/50], Step [651/735], Loss: 0.1060\n",
      "Epoch [20/50], Step [652/735], Loss: 0.6268\n",
      "Epoch [20/50], Step [653/735], Loss: 0.0510\n",
      "Epoch [20/50], Step [654/735], Loss: 1.1185\n",
      "Epoch [20/50], Step [655/735], Loss: 0.0700\n",
      "Epoch [20/50], Step [656/735], Loss: 0.1232\n",
      "Epoch [20/50], Step [657/735], Loss: 0.1774\n",
      "Epoch [20/50], Step [658/735], Loss: 0.3792\n",
      "Epoch [20/50], Step [659/735], Loss: 0.6036\n",
      "Epoch [20/50], Step [660/735], Loss: 1.1572\n",
      "Epoch [20/50], Step [661/735], Loss: 0.2274\n",
      "Epoch [20/50], Step [662/735], Loss: 0.3292\n",
      "Epoch [20/50], Step [663/735], Loss: 0.3274\n",
      "Epoch [20/50], Step [664/735], Loss: 0.2352\n",
      "Epoch [20/50], Step [665/735], Loss: 0.3128\n",
      "Epoch [20/50], Step [666/735], Loss: 0.3204\n",
      "Epoch [20/50], Step [667/735], Loss: 0.3565\n",
      "Epoch [20/50], Step [668/735], Loss: 0.3356\n",
      "Epoch [20/50], Step [669/735], Loss: 0.4974\n",
      "Epoch [20/50], Step [670/735], Loss: 0.5031\n",
      "Epoch [20/50], Step [671/735], Loss: 0.3285\n",
      "Epoch [20/50], Step [672/735], Loss: 0.2622\n",
      "Epoch [20/50], Step [673/735], Loss: 0.4059\n",
      "Epoch [20/50], Step [674/735], Loss: 0.3866\n",
      "Epoch [20/50], Step [675/735], Loss: 0.2569\n",
      "Epoch [20/50], Step [676/735], Loss: 0.1063\n",
      "Epoch [20/50], Step [677/735], Loss: 0.3246\n",
      "Epoch [20/50], Step [678/735], Loss: 0.3531\n",
      "Epoch [20/50], Step [679/735], Loss: 0.0889\n",
      "Epoch [20/50], Step [680/735], Loss: 0.2500\n",
      "Epoch [20/50], Step [681/735], Loss: 0.1210\n",
      "Epoch [20/50], Step [682/735], Loss: 0.1217\n",
      "Epoch [20/50], Step [683/735], Loss: 0.2268\n",
      "Epoch [20/50], Step [684/735], Loss: 0.3673\n",
      "Epoch [20/50], Step [685/735], Loss: 0.0398\n",
      "Epoch [20/50], Step [686/735], Loss: 0.3952\n",
      "Epoch [20/50], Step [687/735], Loss: 0.2898\n",
      "Epoch [20/50], Step [688/735], Loss: 0.0646\n",
      "Epoch [20/50], Step [689/735], Loss: 0.2528\n",
      "Epoch [20/50], Step [690/735], Loss: 0.2994\n",
      "Epoch [20/50], Step [691/735], Loss: 0.2955\n",
      "Epoch [20/50], Step [692/735], Loss: 0.4633\n",
      "Epoch [20/50], Step [693/735], Loss: 0.7226\n",
      "Epoch [20/50], Step [694/735], Loss: 0.1745\n",
      "Epoch [20/50], Step [695/735], Loss: 0.3307\n",
      "Epoch [20/50], Step [696/735], Loss: 0.8990\n",
      "Epoch [20/50], Step [697/735], Loss: 0.0517\n",
      "Epoch [20/50], Step [698/735], Loss: 1.1605\n",
      "Epoch [20/50], Step [699/735], Loss: 0.1175\n",
      "Epoch [20/50], Step [700/735], Loss: 0.4089\n",
      "Epoch [20/50], Step [701/735], Loss: 0.5443\n",
      "Epoch [20/50], Step [702/735], Loss: 0.2451\n",
      "Epoch [20/50], Step [703/735], Loss: 0.4873\n",
      "Epoch [20/50], Step [704/735], Loss: 0.2128\n",
      "Epoch [20/50], Step [705/735], Loss: 0.4538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Step [706/735], Loss: 0.0873\n",
      "Epoch [20/50], Step [707/735], Loss: 0.1504\n",
      "Epoch [20/50], Step [708/735], Loss: 0.1785\n",
      "Epoch [20/50], Step [709/735], Loss: 0.7571\n",
      "Epoch [20/50], Step [710/735], Loss: 0.2488\n",
      "Epoch [20/50], Step [711/735], Loss: 0.1569\n",
      "Epoch [20/50], Step [712/735], Loss: 0.5414\n",
      "Epoch [20/50], Step [713/735], Loss: 0.3527\n",
      "Epoch [20/50], Step [714/735], Loss: 0.0845\n",
      "Epoch [20/50], Step [715/735], Loss: 0.1540\n",
      "Epoch [20/50], Step [716/735], Loss: 0.2543\n",
      "Epoch [20/50], Step [717/735], Loss: 0.3371\n",
      "Epoch [20/50], Step [718/735], Loss: 0.3196\n",
      "Epoch [20/50], Step [719/735], Loss: 0.1508\n",
      "Epoch [20/50], Step [720/735], Loss: 0.3947\n",
      "Epoch [20/50], Step [721/735], Loss: 0.4013\n",
      "Epoch [20/50], Step [722/735], Loss: 0.1968\n",
      "Epoch [20/50], Step [723/735], Loss: 0.2313\n",
      "Epoch [20/50], Step [724/735], Loss: 0.6449\n",
      "Epoch [20/50], Step [725/735], Loss: 0.7137\n",
      "Epoch [20/50], Step [726/735], Loss: 0.1946\n",
      "Epoch [20/50], Step [727/735], Loss: 0.2217\n",
      "Epoch [20/50], Step [728/735], Loss: 0.1698\n",
      "Epoch [20/50], Step [729/735], Loss: 0.1896\n",
      "Epoch [20/50], Step [730/735], Loss: 0.7879\n",
      "Epoch [20/50], Step [731/735], Loss: 0.0714\n",
      "Epoch [20/50], Step [732/735], Loss: 0.1181\n",
      "Epoch [20/50], Step [733/735], Loss: 0.1345\n",
      "Epoch [20/50], Step [734/735], Loss: 0.1855\n",
      "Epoch [20/50], Step [735/735], Loss: 1.5249\n",
      "Epoch [21/50], Step [1/735], Loss: 0.4082\n",
      "Epoch [21/50], Step [2/735], Loss: 0.2352\n",
      "Epoch [21/50], Step [3/735], Loss: 0.3215\n",
      "Epoch [21/50], Step [4/735], Loss: 0.2945\n",
      "Epoch [21/50], Step [5/735], Loss: 0.1517\n",
      "Epoch [21/50], Step [6/735], Loss: 0.3818\n",
      "Epoch [21/50], Step [7/735], Loss: 0.1868\n",
      "Epoch [21/50], Step [8/735], Loss: 0.2248\n",
      "Epoch [21/50], Step [9/735], Loss: 0.4144\n",
      "Epoch [21/50], Step [10/735], Loss: 1.2421\n",
      "Epoch [21/50], Step [11/735], Loss: 0.5971\n",
      "Epoch [21/50], Step [12/735], Loss: 0.0874\n",
      "Epoch [21/50], Step [13/735], Loss: 0.0461\n",
      "Epoch [21/50], Step [14/735], Loss: 0.2558\n",
      "Epoch [21/50], Step [15/735], Loss: 0.4704\n",
      "Epoch [21/50], Step [16/735], Loss: 0.0467\n",
      "Epoch [21/50], Step [17/735], Loss: 0.2913\n",
      "Epoch [21/50], Step [18/735], Loss: 0.1634\n",
      "Epoch [21/50], Step [19/735], Loss: 0.5965\n",
      "Epoch [21/50], Step [20/735], Loss: 0.2148\n",
      "Epoch [21/50], Step [21/735], Loss: 0.1496\n",
      "Epoch [21/50], Step [22/735], Loss: 0.4766\n",
      "Epoch [21/50], Step [23/735], Loss: 0.7190\n",
      "Epoch [21/50], Step [24/735], Loss: 0.1437\n",
      "Epoch [21/50], Step [25/735], Loss: 0.1773\n",
      "Epoch [21/50], Step [26/735], Loss: 0.6814\n",
      "Epoch [21/50], Step [27/735], Loss: 0.3816\n",
      "Epoch [21/50], Step [28/735], Loss: 0.6925\n",
      "Epoch [21/50], Step [29/735], Loss: 0.1319\n",
      "Epoch [21/50], Step [30/735], Loss: 0.1422\n",
      "Epoch [21/50], Step [31/735], Loss: 0.6042\n",
      "Epoch [21/50], Step [32/735], Loss: 1.0079\n",
      "Epoch [21/50], Step [33/735], Loss: 0.5103\n",
      "Epoch [21/50], Step [34/735], Loss: 0.6772\n",
      "Epoch [21/50], Step [35/735], Loss: 0.3549\n",
      "Epoch [21/50], Step [36/735], Loss: 0.0847\n",
      "Epoch [21/50], Step [37/735], Loss: 0.6178\n",
      "Epoch [21/50], Step [38/735], Loss: 0.3232\n",
      "Epoch [21/50], Step [39/735], Loss: 0.2938\n",
      "Epoch [21/50], Step [40/735], Loss: 0.2531\n",
      "Epoch [21/50], Step [41/735], Loss: 0.2605\n",
      "Epoch [21/50], Step [42/735], Loss: 0.4746\n",
      "Epoch [21/50], Step [43/735], Loss: 0.2711\n",
      "Epoch [21/50], Step [44/735], Loss: 0.1844\n",
      "Epoch [21/50], Step [45/735], Loss: 0.3311\n",
      "Epoch [21/50], Step [46/735], Loss: 0.0596\n",
      "Epoch [21/50], Step [47/735], Loss: 0.2085\n",
      "Epoch [21/50], Step [48/735], Loss: 0.6806\n",
      "Epoch [21/50], Step [49/735], Loss: 0.1208\n",
      "Epoch [21/50], Step [50/735], Loss: 0.1132\n",
      "Epoch [21/50], Step [51/735], Loss: 0.5630\n",
      "Epoch [21/50], Step [52/735], Loss: 0.4083\n",
      "Epoch [21/50], Step [53/735], Loss: 0.5092\n",
      "Epoch [21/50], Step [54/735], Loss: 1.3428\n",
      "Epoch [21/50], Step [55/735], Loss: 0.1941\n",
      "Epoch [21/50], Step [56/735], Loss: 0.0783\n",
      "Epoch [21/50], Step [57/735], Loss: 0.1986\n",
      "Epoch [21/50], Step [58/735], Loss: 0.0843\n",
      "Epoch [21/50], Step [59/735], Loss: 0.1697\n",
      "Epoch [21/50], Step [60/735], Loss: 0.1083\n",
      "Epoch [21/50], Step [61/735], Loss: 0.5863\n",
      "Epoch [21/50], Step [62/735], Loss: 0.2764\n",
      "Epoch [21/50], Step [63/735], Loss: 0.2857\n",
      "Epoch [21/50], Step [64/735], Loss: 0.1658\n",
      "Epoch [21/50], Step [65/735], Loss: 0.9998\n",
      "Epoch [21/50], Step [66/735], Loss: 2.0381\n",
      "Epoch [21/50], Step [67/735], Loss: 0.2294\n",
      "Epoch [21/50], Step [68/735], Loss: 0.2391\n",
      "Epoch [21/50], Step [69/735], Loss: 0.4505\n",
      "Epoch [21/50], Step [70/735], Loss: 0.1949\n",
      "Epoch [21/50], Step [71/735], Loss: 0.2377\n",
      "Epoch [21/50], Step [72/735], Loss: 0.6475\n",
      "Epoch [21/50], Step [73/735], Loss: 0.1568\n",
      "Epoch [21/50], Step [74/735], Loss: 0.1934\n",
      "Epoch [21/50], Step [75/735], Loss: 0.4831\n",
      "Epoch [21/50], Step [76/735], Loss: 0.1748\n",
      "Epoch [21/50], Step [77/735], Loss: 0.1010\n",
      "Epoch [21/50], Step [78/735], Loss: 0.4764\n",
      "Epoch [21/50], Step [79/735], Loss: 0.1672\n",
      "Epoch [21/50], Step [80/735], Loss: 0.1714\n",
      "Epoch [21/50], Step [81/735], Loss: 0.3486\n",
      "Epoch [21/50], Step [82/735], Loss: 0.1374\n",
      "Epoch [21/50], Step [83/735], Loss: 1.5342\n",
      "Epoch [21/50], Step [84/735], Loss: 0.4760\n",
      "Epoch [21/50], Step [85/735], Loss: 0.1868\n",
      "Epoch [21/50], Step [86/735], Loss: 0.5314\n",
      "Epoch [21/50], Step [87/735], Loss: 0.0957\n",
      "Epoch [21/50], Step [88/735], Loss: 0.2257\n",
      "Epoch [21/50], Step [89/735], Loss: 0.0815\n",
      "Epoch [21/50], Step [90/735], Loss: 0.1690\n",
      "Epoch [21/50], Step [91/735], Loss: 0.3266\n",
      "Epoch [21/50], Step [92/735], Loss: 0.7408\n",
      "Epoch [21/50], Step [93/735], Loss: 0.0821\n",
      "Epoch [21/50], Step [94/735], Loss: 0.5816\n",
      "Epoch [21/50], Step [95/735], Loss: 0.3350\n",
      "Epoch [21/50], Step [96/735], Loss: 0.1524\n",
      "Epoch [21/50], Step [97/735], Loss: 0.4196\n",
      "Epoch [21/50], Step [98/735], Loss: 0.3230\n",
      "Epoch [21/50], Step [99/735], Loss: 1.0002\n",
      "Epoch [21/50], Step [100/735], Loss: 0.3337\n",
      "Epoch [21/50], Step [101/735], Loss: 0.2881\n",
      "Epoch [21/50], Step [102/735], Loss: 0.4467\n",
      "Epoch [21/50], Step [103/735], Loss: 0.6065\n",
      "Epoch [21/50], Step [104/735], Loss: 0.2562\n",
      "Epoch [21/50], Step [105/735], Loss: 0.7137\n",
      "Epoch [21/50], Step [106/735], Loss: 0.6554\n",
      "Epoch [21/50], Step [107/735], Loss: 0.2730\n",
      "Epoch [21/50], Step [108/735], Loss: 0.8390\n",
      "Epoch [21/50], Step [109/735], Loss: 0.3225\n",
      "Epoch [21/50], Step [110/735], Loss: 0.7756\n",
      "Epoch [21/50], Step [111/735], Loss: 0.3106\n",
      "Epoch [21/50], Step [112/735], Loss: 0.0794\n",
      "Epoch [21/50], Step [113/735], Loss: 0.3412\n",
      "Epoch [21/50], Step [114/735], Loss: 0.1521\n",
      "Epoch [21/50], Step [115/735], Loss: 0.6358\n",
      "Epoch [21/50], Step [116/735], Loss: 0.1560\n",
      "Epoch [21/50], Step [117/735], Loss: 0.1819\n",
      "Epoch [21/50], Step [118/735], Loss: 0.8374\n",
      "Epoch [21/50], Step [119/735], Loss: 0.3629\n",
      "Epoch [21/50], Step [120/735], Loss: 0.6224\n",
      "Epoch [21/50], Step [121/735], Loss: 0.1899\n",
      "Epoch [21/50], Step [122/735], Loss: 0.1476\n",
      "Epoch [21/50], Step [123/735], Loss: 0.2483\n",
      "Epoch [21/50], Step [124/735], Loss: 0.3285\n",
      "Epoch [21/50], Step [125/735], Loss: 0.1186\n",
      "Epoch [21/50], Step [126/735], Loss: 0.2534\n",
      "Epoch [21/50], Step [127/735], Loss: 0.1706\n",
      "Epoch [21/50], Step [128/735], Loss: 0.3058\n",
      "Epoch [21/50], Step [129/735], Loss: 0.2909\n",
      "Epoch [21/50], Step [130/735], Loss: 0.5573\n",
      "Epoch [21/50], Step [131/735], Loss: 1.4221\n",
      "Epoch [21/50], Step [132/735], Loss: 0.5371\n",
      "Epoch [21/50], Step [133/735], Loss: 0.7148\n",
      "Epoch [21/50], Step [134/735], Loss: 0.1889\n",
      "Epoch [21/50], Step [135/735], Loss: 0.0998\n",
      "Epoch [21/50], Step [136/735], Loss: 0.0880\n",
      "Epoch [21/50], Step [137/735], Loss: 0.0781\n",
      "Epoch [21/50], Step [138/735], Loss: 0.2383\n",
      "Epoch [21/50], Step [139/735], Loss: 0.5845\n",
      "Epoch [21/50], Step [140/735], Loss: 0.1625\n",
      "Epoch [21/50], Step [141/735], Loss: 0.2915\n",
      "Epoch [21/50], Step [142/735], Loss: 0.0845\n",
      "Epoch [21/50], Step [143/735], Loss: 0.1124\n",
      "Epoch [21/50], Step [144/735], Loss: 0.4379\n",
      "Epoch [21/50], Step [145/735], Loss: 0.4595\n",
      "Epoch [21/50], Step [146/735], Loss: 0.1036\n",
      "Epoch [21/50], Step [147/735], Loss: 0.3881\n",
      "Epoch [21/50], Step [148/735], Loss: 0.0817\n",
      "Epoch [21/50], Step [149/735], Loss: 0.3515\n",
      "Epoch [21/50], Step [150/735], Loss: 1.8757\n",
      "Epoch [21/50], Step [151/735], Loss: 0.5125\n",
      "Epoch [21/50], Step [152/735], Loss: 0.4458\n",
      "Epoch [21/50], Step [153/735], Loss: 0.5498\n",
      "Epoch [21/50], Step [154/735], Loss: 0.3105\n",
      "Epoch [21/50], Step [155/735], Loss: 0.5705\n",
      "Epoch [21/50], Step [156/735], Loss: 0.3043\n",
      "Epoch [21/50], Step [157/735], Loss: 0.2571\n",
      "Epoch [21/50], Step [158/735], Loss: 0.2882\n",
      "Epoch [21/50], Step [159/735], Loss: 0.2057\n",
      "Epoch [21/50], Step [160/735], Loss: 0.3537\n",
      "Epoch [21/50], Step [161/735], Loss: 0.1426\n",
      "Epoch [21/50], Step [162/735], Loss: 0.2956\n",
      "Epoch [21/50], Step [163/735], Loss: 1.0150\n",
      "Epoch [21/50], Step [164/735], Loss: 1.1519\n",
      "Epoch [21/50], Step [165/735], Loss: 0.7329\n",
      "Epoch [21/50], Step [166/735], Loss: 0.2758\n",
      "Epoch [21/50], Step [167/735], Loss: 0.2264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Step [168/735], Loss: 0.6077\n",
      "Epoch [21/50], Step [169/735], Loss: 0.4188\n",
      "Epoch [21/50], Step [170/735], Loss: 0.2823\n",
      "Epoch [21/50], Step [171/735], Loss: 0.5071\n",
      "Epoch [21/50], Step [172/735], Loss: 0.2111\n",
      "Epoch [21/50], Step [173/735], Loss: 1.7735\n",
      "Epoch [21/50], Step [174/735], Loss: 0.4420\n",
      "Epoch [21/50], Step [175/735], Loss: 0.3102\n",
      "Epoch [21/50], Step [176/735], Loss: 0.3019\n",
      "Epoch [21/50], Step [177/735], Loss: 0.8187\n",
      "Epoch [21/50], Step [178/735], Loss: 0.2052\n",
      "Epoch [21/50], Step [179/735], Loss: 0.2163\n",
      "Epoch [21/50], Step [180/735], Loss: 0.1362\n",
      "Epoch [21/50], Step [181/735], Loss: 0.7375\n",
      "Epoch [21/50], Step [182/735], Loss: 0.4238\n",
      "Epoch [21/50], Step [183/735], Loss: 0.1188\n",
      "Epoch [21/50], Step [184/735], Loss: 0.1877\n",
      "Epoch [21/50], Step [185/735], Loss: 0.3362\n",
      "Epoch [21/50], Step [186/735], Loss: 0.9397\n",
      "Epoch [21/50], Step [187/735], Loss: 0.3288\n",
      "Epoch [21/50], Step [188/735], Loss: 0.4507\n",
      "Epoch [21/50], Step [189/735], Loss: 0.2828\n",
      "Epoch [21/50], Step [190/735], Loss: 0.3404\n",
      "Epoch [21/50], Step [191/735], Loss: 0.0991\n",
      "Epoch [21/50], Step [192/735], Loss: 0.5244\n",
      "Epoch [21/50], Step [193/735], Loss: 0.3290\n",
      "Epoch [21/50], Step [194/735], Loss: 0.4006\n",
      "Epoch [21/50], Step [195/735], Loss: 0.1223\n",
      "Epoch [21/50], Step [196/735], Loss: 0.2924\n",
      "Epoch [21/50], Step [197/735], Loss: 0.6798\n",
      "Epoch [21/50], Step [198/735], Loss: 0.2812\n",
      "Epoch [21/50], Step [199/735], Loss: 0.6506\n",
      "Epoch [21/50], Step [200/735], Loss: 0.1943\n",
      "Epoch [21/50], Step [201/735], Loss: 1.2935\n",
      "Epoch [21/50], Step [202/735], Loss: 0.4758\n",
      "Epoch [21/50], Step [203/735], Loss: 0.3094\n",
      "Epoch [21/50], Step [204/735], Loss: 0.6869\n",
      "Epoch [21/50], Step [205/735], Loss: 0.5585\n",
      "Epoch [21/50], Step [206/735], Loss: 0.9019\n",
      "Epoch [21/50], Step [207/735], Loss: 0.5617\n",
      "Epoch [21/50], Step [208/735], Loss: 0.2248\n",
      "Epoch [21/50], Step [209/735], Loss: 0.0934\n",
      "Epoch [21/50], Step [210/735], Loss: 0.2651\n",
      "Epoch [21/50], Step [211/735], Loss: 0.1559\n",
      "Epoch [21/50], Step [212/735], Loss: 0.2404\n",
      "Epoch [21/50], Step [213/735], Loss: 0.1234\n",
      "Epoch [21/50], Step [214/735], Loss: 0.6145\n",
      "Epoch [21/50], Step [215/735], Loss: 1.1997\n",
      "Epoch [21/50], Step [216/735], Loss: 0.7591\n",
      "Epoch [21/50], Step [217/735], Loss: 0.2640\n",
      "Epoch [21/50], Step [218/735], Loss: 0.4722\n",
      "Epoch [21/50], Step [219/735], Loss: 0.3197\n",
      "Epoch [21/50], Step [220/735], Loss: 0.1938\n",
      "Epoch [21/50], Step [221/735], Loss: 0.2771\n",
      "Epoch [21/50], Step [222/735], Loss: 1.0290\n",
      "Epoch [21/50], Step [223/735], Loss: 0.4319\n",
      "Epoch [21/50], Step [224/735], Loss: 0.6581\n",
      "Epoch [21/50], Step [225/735], Loss: 1.2778\n",
      "Epoch [21/50], Step [226/735], Loss: 0.3298\n",
      "Epoch [21/50], Step [227/735], Loss: 0.2072\n",
      "Epoch [21/50], Step [228/735], Loss: 0.9756\n",
      "Epoch [21/50], Step [229/735], Loss: 0.5298\n",
      "Epoch [21/50], Step [230/735], Loss: 1.4961\n",
      "Epoch [21/50], Step [231/735], Loss: 0.0579\n",
      "Epoch [21/50], Step [232/735], Loss: 0.7454\n",
      "Epoch [21/50], Step [233/735], Loss: 0.2073\n",
      "Epoch [21/50], Step [234/735], Loss: 5.8168\n",
      "Epoch [21/50], Step [235/735], Loss: 0.7117\n",
      "Epoch [21/50], Step [236/735], Loss: 0.1220\n",
      "Epoch [21/50], Step [237/735], Loss: 0.3091\n",
      "Epoch [21/50], Step [238/735], Loss: 0.6577\n",
      "Epoch [21/50], Step [239/735], Loss: 0.2292\n",
      "Epoch [21/50], Step [240/735], Loss: 0.9834\n",
      "Epoch [21/50], Step [241/735], Loss: 0.4659\n",
      "Epoch [21/50], Step [242/735], Loss: 0.3230\n",
      "Epoch [21/50], Step [243/735], Loss: 0.3281\n",
      "Epoch [21/50], Step [244/735], Loss: 0.3728\n",
      "Epoch [21/50], Step [245/735], Loss: 0.1421\n",
      "Epoch [21/50], Step [246/735], Loss: 0.3910\n",
      "Epoch [21/50], Step [247/735], Loss: 0.1403\n",
      "Epoch [21/50], Step [248/735], Loss: 0.8800\n",
      "Epoch [21/50], Step [249/735], Loss: 0.1450\n",
      "Epoch [21/50], Step [250/735], Loss: 0.2512\n",
      "Epoch [21/50], Step [251/735], Loss: 0.3314\n",
      "Epoch [21/50], Step [252/735], Loss: 0.5048\n",
      "Epoch [21/50], Step [253/735], Loss: 0.3883\n",
      "Epoch [21/50], Step [254/735], Loss: 0.5159\n",
      "Epoch [21/50], Step [255/735], Loss: 0.4543\n",
      "Epoch [21/50], Step [256/735], Loss: 0.3540\n",
      "Epoch [21/50], Step [257/735], Loss: 0.2163\n",
      "Epoch [21/50], Step [258/735], Loss: 0.5371\n",
      "Epoch [21/50], Step [259/735], Loss: 0.3741\n",
      "Epoch [21/50], Step [260/735], Loss: 0.1852\n",
      "Epoch [21/50], Step [261/735], Loss: 0.0708\n",
      "Epoch [21/50], Step [262/735], Loss: 0.9574\n",
      "Epoch [21/50], Step [263/735], Loss: 0.9271\n",
      "Epoch [21/50], Step [264/735], Loss: 0.4014\n",
      "Epoch [21/50], Step [265/735], Loss: 0.1845\n",
      "Epoch [21/50], Step [266/735], Loss: 0.4301\n",
      "Epoch [21/50], Step [267/735], Loss: 0.4329\n",
      "Epoch [21/50], Step [268/735], Loss: 0.3356\n",
      "Epoch [21/50], Step [269/735], Loss: 0.7410\n",
      "Epoch [21/50], Step [270/735], Loss: 0.3526\n",
      "Epoch [21/50], Step [271/735], Loss: 0.3333\n",
      "Epoch [21/50], Step [272/735], Loss: 0.1076\n",
      "Epoch [21/50], Step [273/735], Loss: 0.2569\n",
      "Epoch [21/50], Step [274/735], Loss: 0.1944\n",
      "Epoch [21/50], Step [275/735], Loss: 0.1058\n",
      "Epoch [21/50], Step [276/735], Loss: 0.4474\n",
      "Epoch [21/50], Step [277/735], Loss: 0.1906\n",
      "Epoch [21/50], Step [278/735], Loss: 0.6182\n",
      "Epoch [21/50], Step [279/735], Loss: 0.7641\n",
      "Epoch [21/50], Step [280/735], Loss: 0.3684\n",
      "Epoch [21/50], Step [281/735], Loss: 0.2901\n",
      "Epoch [21/50], Step [282/735], Loss: 0.1318\n",
      "Epoch [21/50], Step [283/735], Loss: 0.5293\n",
      "Epoch [21/50], Step [284/735], Loss: 0.1403\n",
      "Epoch [21/50], Step [285/735], Loss: 0.2441\n",
      "Epoch [21/50], Step [286/735], Loss: 0.4049\n",
      "Epoch [21/50], Step [287/735], Loss: 0.3514\n",
      "Epoch [21/50], Step [288/735], Loss: 0.1191\n",
      "Epoch [21/50], Step [289/735], Loss: 0.3225\n",
      "Epoch [21/50], Step [290/735], Loss: 0.0677\n",
      "Epoch [21/50], Step [291/735], Loss: 0.2044\n",
      "Epoch [21/50], Step [292/735], Loss: 0.4159\n",
      "Epoch [21/50], Step [293/735], Loss: 1.0589\n",
      "Epoch [21/50], Step [294/735], Loss: 0.3185\n",
      "Epoch [21/50], Step [295/735], Loss: 0.6657\n",
      "Epoch [21/50], Step [296/735], Loss: 0.1363\n",
      "Epoch [21/50], Step [297/735], Loss: 0.2743\n",
      "Epoch [21/50], Step [298/735], Loss: 0.6902\n",
      "Epoch [21/50], Step [299/735], Loss: 0.1305\n",
      "Epoch [21/50], Step [300/735], Loss: 0.8624\n",
      "Epoch [21/50], Step [301/735], Loss: 0.0995\n",
      "Epoch [21/50], Step [302/735], Loss: 0.0987\n",
      "Epoch [21/50], Step [303/735], Loss: 0.2245\n",
      "Epoch [21/50], Step [304/735], Loss: 0.4655\n",
      "Epoch [21/50], Step [305/735], Loss: 0.0508\n",
      "Epoch [21/50], Step [306/735], Loss: 0.8190\n",
      "Epoch [21/50], Step [307/735], Loss: 0.2462\n",
      "Epoch [21/50], Step [308/735], Loss: 0.4461\n",
      "Epoch [21/50], Step [309/735], Loss: 0.3108\n",
      "Epoch [21/50], Step [310/735], Loss: 0.1550\n",
      "Epoch [21/50], Step [311/735], Loss: 0.6069\n",
      "Epoch [21/50], Step [312/735], Loss: 0.1378\n",
      "Epoch [21/50], Step [313/735], Loss: 1.3713\n",
      "Epoch [21/50], Step [314/735], Loss: 0.5576\n",
      "Epoch [21/50], Step [315/735], Loss: 0.7580\n",
      "Epoch [21/50], Step [316/735], Loss: 0.2203\n",
      "Epoch [21/50], Step [317/735], Loss: 0.1484\n",
      "Epoch [21/50], Step [318/735], Loss: 0.1834\n",
      "Epoch [21/50], Step [319/735], Loss: 0.1310\n",
      "Epoch [21/50], Step [320/735], Loss: 0.3484\n",
      "Epoch [21/50], Step [321/735], Loss: 0.7308\n",
      "Epoch [21/50], Step [322/735], Loss: 1.7127\n",
      "Epoch [21/50], Step [323/735], Loss: 0.2258\n",
      "Epoch [21/50], Step [324/735], Loss: 0.1775\n",
      "Epoch [21/50], Step [325/735], Loss: 0.5088\n",
      "Epoch [21/50], Step [326/735], Loss: 0.1082\n",
      "Epoch [21/50], Step [327/735], Loss: 0.5745\n",
      "Epoch [21/50], Step [328/735], Loss: 0.6064\n",
      "Epoch [21/50], Step [329/735], Loss: 0.2240\n",
      "Epoch [21/50], Step [330/735], Loss: 0.2995\n",
      "Epoch [21/50], Step [331/735], Loss: 0.1737\n",
      "Epoch [21/50], Step [332/735], Loss: 0.3777\n",
      "Epoch [21/50], Step [333/735], Loss: 0.5582\n",
      "Epoch [21/50], Step [334/735], Loss: 0.1878\n",
      "Epoch [21/50], Step [335/735], Loss: 0.1604\n",
      "Epoch [21/50], Step [336/735], Loss: 0.5106\n",
      "Epoch [21/50], Step [337/735], Loss: 1.0025\n",
      "Epoch [21/50], Step [338/735], Loss: 0.2933\n",
      "Epoch [21/50], Step [339/735], Loss: 0.1609\n",
      "Epoch [21/50], Step [340/735], Loss: 0.3625\n",
      "Epoch [21/50], Step [341/735], Loss: 0.2739\n",
      "Epoch [21/50], Step [342/735], Loss: 0.1877\n",
      "Epoch [21/50], Step [343/735], Loss: 0.2894\n",
      "Epoch [21/50], Step [344/735], Loss: 0.1513\n",
      "Epoch [21/50], Step [345/735], Loss: 0.1284\n",
      "Epoch [21/50], Step [346/735], Loss: 0.7367\n",
      "Epoch [21/50], Step [347/735], Loss: 0.5016\n",
      "Epoch [21/50], Step [348/735], Loss: 0.4935\n",
      "Epoch [21/50], Step [349/735], Loss: 0.2519\n",
      "Epoch [21/50], Step [350/735], Loss: 0.4753\n",
      "Epoch [21/50], Step [351/735], Loss: 0.5084\n",
      "Epoch [21/50], Step [352/735], Loss: 0.6493\n",
      "Epoch [21/50], Step [353/735], Loss: 0.3947\n",
      "Epoch [21/50], Step [354/735], Loss: 0.1750\n",
      "Epoch [21/50], Step [355/735], Loss: 0.1923\n",
      "Epoch [21/50], Step [356/735], Loss: 0.3512\n",
      "Epoch [21/50], Step [357/735], Loss: 0.4130\n",
      "Epoch [21/50], Step [358/735], Loss: 0.4178\n",
      "Epoch [21/50], Step [359/735], Loss: 0.4974\n",
      "Epoch [21/50], Step [360/735], Loss: 1.2272\n",
      "Epoch [21/50], Step [361/735], Loss: 0.2057\n",
      "Epoch [21/50], Step [362/735], Loss: 0.0932\n",
      "Epoch [21/50], Step [363/735], Loss: 0.1969\n",
      "Epoch [21/50], Step [364/735], Loss: 1.1064\n",
      "Epoch [21/50], Step [365/735], Loss: 1.2454\n",
      "Epoch [21/50], Step [366/735], Loss: 0.3414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Step [367/735], Loss: 0.1447\n",
      "Epoch [21/50], Step [368/735], Loss: 0.5306\n",
      "Epoch [21/50], Step [369/735], Loss: 0.1372\n",
      "Epoch [21/50], Step [370/735], Loss: 0.2667\n",
      "Epoch [21/50], Step [371/735], Loss: 0.2629\n",
      "Epoch [21/50], Step [372/735], Loss: 0.2851\n",
      "Epoch [21/50], Step [373/735], Loss: 0.7761\n",
      "Epoch [21/50], Step [374/735], Loss: 0.1183\n",
      "Epoch [21/50], Step [375/735], Loss: 0.2061\n",
      "Epoch [21/50], Step [376/735], Loss: 0.1049\n",
      "Epoch [21/50], Step [377/735], Loss: 0.5341\n",
      "Epoch [21/50], Step [378/735], Loss: 0.1060\n",
      "Epoch [21/50], Step [379/735], Loss: 0.2096\n",
      "Epoch [21/50], Step [380/735], Loss: 0.1086\n",
      "Epoch [21/50], Step [381/735], Loss: 0.2253\n",
      "Epoch [21/50], Step [382/735], Loss: 0.0625\n",
      "Epoch [21/50], Step [383/735], Loss: 0.2824\n",
      "Epoch [21/50], Step [384/735], Loss: 0.2122\n",
      "Epoch [21/50], Step [385/735], Loss: 0.4891\n",
      "Epoch [21/50], Step [386/735], Loss: 0.4502\n",
      "Epoch [21/50], Step [387/735], Loss: 0.4266\n",
      "Epoch [21/50], Step [388/735], Loss: 0.4675\n",
      "Epoch [21/50], Step [389/735], Loss: 0.1582\n",
      "Epoch [21/50], Step [390/735], Loss: 5.2490\n",
      "Epoch [21/50], Step [391/735], Loss: 0.1778\n",
      "Epoch [21/50], Step [392/735], Loss: 0.8184\n",
      "Epoch [21/50], Step [393/735], Loss: 0.1229\n",
      "Epoch [21/50], Step [394/735], Loss: 1.4515\n",
      "Epoch [21/50], Step [395/735], Loss: 0.2177\n",
      "Epoch [21/50], Step [396/735], Loss: 0.1417\n",
      "Epoch [21/50], Step [397/735], Loss: 0.2302\n",
      "Epoch [21/50], Step [398/735], Loss: 0.4298\n",
      "Epoch [21/50], Step [399/735], Loss: 0.6072\n",
      "Epoch [21/50], Step [400/735], Loss: 0.5705\n",
      "Epoch [21/50], Step [401/735], Loss: 0.1917\n",
      "Epoch [21/50], Step [402/735], Loss: 1.1156\n",
      "Epoch [21/50], Step [403/735], Loss: 0.3510\n",
      "Epoch [21/50], Step [404/735], Loss: 1.1921\n",
      "Epoch [21/50], Step [405/735], Loss: 0.4300\n",
      "Epoch [21/50], Step [406/735], Loss: 0.7004\n",
      "Epoch [21/50], Step [407/735], Loss: 0.1147\n",
      "Epoch [21/50], Step [408/735], Loss: 0.2948\n",
      "Epoch [21/50], Step [409/735], Loss: 0.2436\n",
      "Epoch [21/50], Step [410/735], Loss: 1.3803\n",
      "Epoch [21/50], Step [411/735], Loss: 0.1677\n",
      "Epoch [21/50], Step [412/735], Loss: 0.2877\n",
      "Epoch [21/50], Step [413/735], Loss: 0.2665\n",
      "Epoch [21/50], Step [414/735], Loss: 0.5546\n",
      "Epoch [21/50], Step [415/735], Loss: 0.6102\n",
      "Epoch [21/50], Step [416/735], Loss: 0.1455\n",
      "Epoch [21/50], Step [417/735], Loss: 0.4322\n",
      "Epoch [21/50], Step [418/735], Loss: 0.2993\n",
      "Epoch [21/50], Step [419/735], Loss: 0.2491\n",
      "Epoch [21/50], Step [420/735], Loss: 0.1503\n",
      "Epoch [21/50], Step [421/735], Loss: 0.6377\n",
      "Epoch [21/50], Step [422/735], Loss: 1.1103\n",
      "Epoch [21/50], Step [423/735], Loss: 0.3606\n",
      "Epoch [21/50], Step [424/735], Loss: 0.8544\n",
      "Epoch [21/50], Step [425/735], Loss: 0.1075\n",
      "Epoch [21/50], Step [426/735], Loss: 0.3043\n",
      "Epoch [21/50], Step [427/735], Loss: 0.2604\n",
      "Epoch [21/50], Step [428/735], Loss: 0.2201\n",
      "Epoch [21/50], Step [429/735], Loss: 1.3960\n",
      "Epoch [21/50], Step [430/735], Loss: 0.2021\n",
      "Epoch [21/50], Step [431/735], Loss: 0.1048\n",
      "Epoch [21/50], Step [432/735], Loss: 0.3060\n",
      "Epoch [21/50], Step [433/735], Loss: 0.4772\n",
      "Epoch [21/50], Step [434/735], Loss: 1.2059\n",
      "Epoch [21/50], Step [435/735], Loss: 0.1060\n",
      "Epoch [21/50], Step [436/735], Loss: 1.3312\n",
      "Epoch [21/50], Step [437/735], Loss: 0.2548\n",
      "Epoch [21/50], Step [438/735], Loss: 0.4272\n",
      "Epoch [21/50], Step [439/735], Loss: 1.4367\n",
      "Epoch [21/50], Step [440/735], Loss: 0.3210\n",
      "Epoch [21/50], Step [441/735], Loss: 0.2182\n",
      "Epoch [21/50], Step [442/735], Loss: 0.1489\n",
      "Epoch [21/50], Step [443/735], Loss: 0.1811\n",
      "Epoch [21/50], Step [444/735], Loss: 0.2590\n",
      "Epoch [21/50], Step [445/735], Loss: 0.2980\n",
      "Epoch [21/50], Step [446/735], Loss: 0.3036\n",
      "Epoch [21/50], Step [447/735], Loss: 0.4413\n",
      "Epoch [21/50], Step [448/735], Loss: 1.6209\n",
      "Epoch [21/50], Step [449/735], Loss: 0.4409\n",
      "Epoch [21/50], Step [450/735], Loss: 0.2104\n",
      "Epoch [21/50], Step [451/735], Loss: 0.1595\n",
      "Epoch [21/50], Step [452/735], Loss: 0.9340\n",
      "Epoch [21/50], Step [453/735], Loss: 0.3985\n",
      "Epoch [21/50], Step [454/735], Loss: 0.1976\n",
      "Epoch [21/50], Step [455/735], Loss: 0.1741\n",
      "Epoch [21/50], Step [456/735], Loss: 0.1664\n",
      "Epoch [21/50], Step [457/735], Loss: 1.3440\n",
      "Epoch [21/50], Step [458/735], Loss: 0.0810\n",
      "Epoch [21/50], Step [459/735], Loss: 0.3284\n",
      "Epoch [21/50], Step [460/735], Loss: 0.1433\n",
      "Epoch [21/50], Step [461/735], Loss: 0.5551\n",
      "Epoch [21/50], Step [462/735], Loss: 0.5262\n",
      "Epoch [21/50], Step [463/735], Loss: 0.3085\n",
      "Epoch [21/50], Step [464/735], Loss: 0.2934\n",
      "Epoch [21/50], Step [465/735], Loss: 4.8923\n",
      "Epoch [21/50], Step [466/735], Loss: 0.4144\n",
      "Epoch [21/50], Step [467/735], Loss: 0.3971\n",
      "Epoch [21/50], Step [468/735], Loss: 0.2771\n",
      "Epoch [21/50], Step [469/735], Loss: 0.1647\n",
      "Epoch [21/50], Step [470/735], Loss: 0.0849\n",
      "Epoch [21/50], Step [471/735], Loss: 0.1925\n",
      "Epoch [21/50], Step [472/735], Loss: 0.1879\n",
      "Epoch [21/50], Step [473/735], Loss: 1.3246\n",
      "Epoch [21/50], Step [474/735], Loss: 0.2576\n",
      "Epoch [21/50], Step [475/735], Loss: 0.9222\n",
      "Epoch [21/50], Step [476/735], Loss: 1.0491\n",
      "Epoch [21/50], Step [477/735], Loss: 0.8084\n",
      "Epoch [21/50], Step [478/735], Loss: 1.3843\n",
      "Epoch [21/50], Step [479/735], Loss: 0.8532\n",
      "Epoch [21/50], Step [480/735], Loss: 0.3599\n",
      "Epoch [21/50], Step [481/735], Loss: 0.2791\n",
      "Epoch [21/50], Step [482/735], Loss: 0.2781\n",
      "Epoch [21/50], Step [483/735], Loss: 0.9824\n",
      "Epoch [21/50], Step [484/735], Loss: 0.5039\n",
      "Epoch [21/50], Step [485/735], Loss: 0.1315\n",
      "Epoch [21/50], Step [486/735], Loss: 0.6787\n",
      "Epoch [21/50], Step [487/735], Loss: 0.3423\n",
      "Epoch [21/50], Step [488/735], Loss: 0.3841\n",
      "Epoch [21/50], Step [489/735], Loss: 0.1000\n",
      "Epoch [21/50], Step [490/735], Loss: 0.3787\n",
      "Epoch [21/50], Step [491/735], Loss: 0.2450\n",
      "Epoch [21/50], Step [492/735], Loss: 0.3546\n",
      "Epoch [21/50], Step [493/735], Loss: 0.4079\n",
      "Epoch [21/50], Step [494/735], Loss: 0.5619\n",
      "Epoch [21/50], Step [495/735], Loss: 0.3000\n",
      "Epoch [21/50], Step [496/735], Loss: 0.1210\n",
      "Epoch [21/50], Step [497/735], Loss: 0.1314\n",
      "Epoch [21/50], Step [498/735], Loss: 0.1428\n",
      "Epoch [21/50], Step [499/735], Loss: 0.4848\n",
      "Epoch [21/50], Step [500/735], Loss: 0.2000\n",
      "Epoch [21/50], Step [501/735], Loss: 0.3017\n",
      "Epoch [21/50], Step [502/735], Loss: 0.3389\n",
      "Epoch [21/50], Step [503/735], Loss: 0.1955\n",
      "Epoch [21/50], Step [504/735], Loss: 1.5610\n",
      "Epoch [21/50], Step [505/735], Loss: 0.2633\n",
      "Epoch [21/50], Step [506/735], Loss: 0.1175\n",
      "Epoch [21/50], Step [507/735], Loss: 0.5325\n",
      "Epoch [21/50], Step [508/735], Loss: 0.5759\n",
      "Epoch [21/50], Step [509/735], Loss: 0.5338\n",
      "Epoch [21/50], Step [510/735], Loss: 0.6249\n",
      "Epoch [21/50], Step [511/735], Loss: 0.2444\n",
      "Epoch [21/50], Step [512/735], Loss: 0.6232\n",
      "Epoch [21/50], Step [513/735], Loss: 0.3229\n",
      "Epoch [21/50], Step [514/735], Loss: 0.1409\n",
      "Epoch [21/50], Step [515/735], Loss: 0.9754\n",
      "Epoch [21/50], Step [516/735], Loss: 1.0216\n",
      "Epoch [21/50], Step [517/735], Loss: 0.1485\n",
      "Epoch [21/50], Step [518/735], Loss: 0.1567\n",
      "Epoch [21/50], Step [519/735], Loss: 0.2140\n",
      "Epoch [21/50], Step [520/735], Loss: 0.0391\n",
      "Epoch [21/50], Step [521/735], Loss: 0.6012\n",
      "Epoch [21/50], Step [522/735], Loss: 0.1462\n",
      "Epoch [21/50], Step [523/735], Loss: 0.1396\n",
      "Epoch [21/50], Step [524/735], Loss: 0.1335\n",
      "Epoch [21/50], Step [525/735], Loss: 0.5568\n",
      "Epoch [21/50], Step [526/735], Loss: 0.1765\n",
      "Epoch [21/50], Step [527/735], Loss: 0.6839\n",
      "Epoch [21/50], Step [528/735], Loss: 0.7641\n",
      "Epoch [21/50], Step [529/735], Loss: 4.9889\n",
      "Epoch [21/50], Step [530/735], Loss: 0.0589\n",
      "Epoch [21/50], Step [531/735], Loss: 0.6885\n",
      "Epoch [21/50], Step [532/735], Loss: 0.2761\n",
      "Epoch [21/50], Step [533/735], Loss: 0.3304\n",
      "Epoch [21/50], Step [534/735], Loss: 0.3125\n",
      "Epoch [21/50], Step [535/735], Loss: 0.5870\n",
      "Epoch [21/50], Step [536/735], Loss: 0.5118\n",
      "Epoch [21/50], Step [537/735], Loss: 0.4096\n",
      "Epoch [21/50], Step [538/735], Loss: 0.4988\n",
      "Epoch [21/50], Step [539/735], Loss: 0.3160\n",
      "Epoch [21/50], Step [540/735], Loss: 0.4672\n",
      "Epoch [21/50], Step [541/735], Loss: 0.2969\n",
      "Epoch [21/50], Step [542/735], Loss: 0.3418\n",
      "Epoch [21/50], Step [543/735], Loss: 0.2655\n",
      "Epoch [21/50], Step [544/735], Loss: 0.3849\n",
      "Epoch [21/50], Step [545/735], Loss: 0.4648\n",
      "Epoch [21/50], Step [546/735], Loss: 0.2085\n",
      "Epoch [21/50], Step [547/735], Loss: 0.1385\n",
      "Epoch [21/50], Step [548/735], Loss: 0.2064\n",
      "Epoch [21/50], Step [549/735], Loss: 0.4174\n",
      "Epoch [21/50], Step [550/735], Loss: 0.4289\n",
      "Epoch [21/50], Step [551/735], Loss: 0.5577\n",
      "Epoch [21/50], Step [552/735], Loss: 0.9398\n",
      "Epoch [21/50], Step [553/735], Loss: 0.7695\n",
      "Epoch [21/50], Step [554/735], Loss: 0.5953\n",
      "Epoch [21/50], Step [555/735], Loss: 0.2042\n",
      "Epoch [21/50], Step [556/735], Loss: 0.1865\n",
      "Epoch [21/50], Step [557/735], Loss: 0.1321\n",
      "Epoch [21/50], Step [558/735], Loss: 1.3621\n",
      "Epoch [21/50], Step [559/735], Loss: 0.3507\n",
      "Epoch [21/50], Step [560/735], Loss: 0.1043\n",
      "Epoch [21/50], Step [561/735], Loss: 0.2553\n",
      "Epoch [21/50], Step [562/735], Loss: 0.2748\n",
      "Epoch [21/50], Step [563/735], Loss: 0.1144\n",
      "Epoch [21/50], Step [564/735], Loss: 0.2324\n",
      "Epoch [21/50], Step [565/735], Loss: 0.2149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Step [566/735], Loss: 0.5348\n",
      "Epoch [21/50], Step [567/735], Loss: 1.1544\n",
      "Epoch [21/50], Step [568/735], Loss: 0.2744\n",
      "Epoch [21/50], Step [569/735], Loss: 0.2031\n",
      "Epoch [21/50], Step [570/735], Loss: 0.5362\n",
      "Epoch [21/50], Step [571/735], Loss: 0.4191\n",
      "Epoch [21/50], Step [572/735], Loss: 0.2454\n",
      "Epoch [21/50], Step [573/735], Loss: 0.1446\n",
      "Epoch [21/50], Step [574/735], Loss: 0.6170\n",
      "Epoch [21/50], Step [575/735], Loss: 0.1420\n",
      "Epoch [21/50], Step [576/735], Loss: 0.2262\n",
      "Epoch [21/50], Step [577/735], Loss: 0.2623\n",
      "Epoch [21/50], Step [578/735], Loss: 0.2245\n",
      "Epoch [21/50], Step [579/735], Loss: 0.0882\n",
      "Epoch [21/50], Step [580/735], Loss: 0.4645\n",
      "Epoch [21/50], Step [581/735], Loss: 0.4174\n",
      "Epoch [21/50], Step [582/735], Loss: 0.1984\n",
      "Epoch [21/50], Step [583/735], Loss: 0.1600\n",
      "Epoch [21/50], Step [584/735], Loss: 0.0729\n",
      "Epoch [21/50], Step [585/735], Loss: 1.5151\n",
      "Epoch [21/50], Step [586/735], Loss: 0.2128\n",
      "Epoch [21/50], Step [587/735], Loss: 0.3877\n",
      "Epoch [21/50], Step [588/735], Loss: 0.1057\n",
      "Epoch [21/50], Step [589/735], Loss: 0.6453\n",
      "Epoch [21/50], Step [590/735], Loss: 4.3326\n",
      "Epoch [21/50], Step [591/735], Loss: 0.3465\n",
      "Epoch [21/50], Step [592/735], Loss: 0.1386\n",
      "Epoch [21/50], Step [593/735], Loss: 0.8517\n",
      "Epoch [21/50], Step [594/735], Loss: 0.3849\n",
      "Epoch [21/50], Step [595/735], Loss: 0.4081\n",
      "Epoch [21/50], Step [596/735], Loss: 0.1718\n",
      "Epoch [21/50], Step [597/735], Loss: 0.2082\n",
      "Epoch [21/50], Step [598/735], Loss: 0.7180\n",
      "Epoch [21/50], Step [599/735], Loss: 0.3570\n",
      "Epoch [21/50], Step [600/735], Loss: 0.4310\n",
      "Epoch [21/50], Step [601/735], Loss: 0.3375\n",
      "Epoch [21/50], Step [602/735], Loss: 0.3537\n",
      "Epoch [21/50], Step [603/735], Loss: 1.0068\n",
      "Epoch [21/50], Step [604/735], Loss: 0.3118\n",
      "Epoch [21/50], Step [605/735], Loss: 0.2878\n",
      "Epoch [21/50], Step [606/735], Loss: 0.2250\n",
      "Epoch [21/50], Step [607/735], Loss: 0.3515\n",
      "Epoch [21/50], Step [608/735], Loss: 0.6360\n",
      "Epoch [21/50], Step [609/735], Loss: 0.1599\n",
      "Epoch [21/50], Step [610/735], Loss: 1.2425\n",
      "Epoch [21/50], Step [611/735], Loss: 0.7530\n",
      "Epoch [21/50], Step [612/735], Loss: 0.1849\n",
      "Epoch [21/50], Step [613/735], Loss: 0.1221\n",
      "Epoch [21/50], Step [614/735], Loss: 0.1595\n",
      "Epoch [21/50], Step [615/735], Loss: 0.7298\n",
      "Epoch [21/50], Step [616/735], Loss: 0.2309\n",
      "Epoch [21/50], Step [617/735], Loss: 0.5816\n",
      "Epoch [21/50], Step [618/735], Loss: 0.0836\n",
      "Epoch [21/50], Step [619/735], Loss: 0.2123\n",
      "Epoch [21/50], Step [620/735], Loss: 0.3353\n",
      "Epoch [21/50], Step [621/735], Loss: 0.2715\n",
      "Epoch [21/50], Step [622/735], Loss: 0.4307\n",
      "Epoch [21/50], Step [623/735], Loss: 0.8563\n",
      "Epoch [21/50], Step [624/735], Loss: 0.3388\n",
      "Epoch [21/50], Step [625/735], Loss: 0.6961\n",
      "Epoch [21/50], Step [626/735], Loss: 0.3587\n",
      "Epoch [21/50], Step [627/735], Loss: 0.3056\n",
      "Epoch [21/50], Step [628/735], Loss: 0.2193\n",
      "Epoch [21/50], Step [629/735], Loss: 0.2158\n",
      "Epoch [21/50], Step [630/735], Loss: 0.3662\n",
      "Epoch [21/50], Step [631/735], Loss: 0.3579\n",
      "Epoch [21/50], Step [632/735], Loss: 0.5034\n",
      "Epoch [21/50], Step [633/735], Loss: 0.2830\n",
      "Epoch [21/50], Step [634/735], Loss: 0.4003\n",
      "Epoch [21/50], Step [635/735], Loss: 0.4777\n",
      "Epoch [21/50], Step [636/735], Loss: 0.8174\n",
      "Epoch [21/50], Step [637/735], Loss: 0.6858\n",
      "Epoch [21/50], Step [638/735], Loss: 0.1469\n",
      "Epoch [21/50], Step [639/735], Loss: 0.4157\n",
      "Epoch [21/50], Step [640/735], Loss: 0.3237\n",
      "Epoch [21/50], Step [641/735], Loss: 0.4496\n",
      "Epoch [21/50], Step [642/735], Loss: 0.4833\n",
      "Epoch [21/50], Step [643/735], Loss: 0.2632\n",
      "Epoch [21/50], Step [644/735], Loss: 0.2675\n",
      "Epoch [21/50], Step [645/735], Loss: 0.3149\n",
      "Epoch [21/50], Step [646/735], Loss: 0.7890\n",
      "Epoch [21/50], Step [647/735], Loss: 0.1025\n",
      "Epoch [21/50], Step [648/735], Loss: 0.3306\n",
      "Epoch [21/50], Step [649/735], Loss: 0.3061\n",
      "Epoch [21/50], Step [650/735], Loss: 0.5464\n",
      "Epoch [21/50], Step [651/735], Loss: 1.2396\n",
      "Epoch [21/50], Step [652/735], Loss: 0.2162\n",
      "Epoch [21/50], Step [653/735], Loss: 0.1688\n",
      "Epoch [21/50], Step [654/735], Loss: 0.5638\n",
      "Epoch [21/50], Step [655/735], Loss: 0.1549\n",
      "Epoch [21/50], Step [656/735], Loss: 0.1703\n",
      "Epoch [21/50], Step [657/735], Loss: 1.5080\n",
      "Epoch [21/50], Step [658/735], Loss: 0.3325\n",
      "Epoch [21/50], Step [659/735], Loss: 0.7918\n",
      "Epoch [21/50], Step [660/735], Loss: 0.2215\n",
      "Epoch [21/50], Step [661/735], Loss: 0.3447\n",
      "Epoch [21/50], Step [662/735], Loss: 0.8421\n",
      "Epoch [21/50], Step [663/735], Loss: 0.6439\n",
      "Epoch [21/50], Step [664/735], Loss: 0.2988\n",
      "Epoch [21/50], Step [665/735], Loss: 0.2252\n",
      "Epoch [21/50], Step [666/735], Loss: 0.2636\n",
      "Epoch [21/50], Step [667/735], Loss: 0.2491\n",
      "Epoch [21/50], Step [668/735], Loss: 0.1382\n",
      "Epoch [21/50], Step [669/735], Loss: 0.4385\n",
      "Epoch [21/50], Step [670/735], Loss: 0.3294\n",
      "Epoch [21/50], Step [671/735], Loss: 0.1581\n",
      "Epoch [21/50], Step [672/735], Loss: 0.1917\n",
      "Epoch [21/50], Step [673/735], Loss: 0.3242\n",
      "Epoch [21/50], Step [674/735], Loss: 0.2179\n",
      "Epoch [21/50], Step [675/735], Loss: 0.4600\n",
      "Epoch [21/50], Step [676/735], Loss: 0.3913\n",
      "Epoch [21/50], Step [677/735], Loss: 0.2714\n",
      "Epoch [21/50], Step [678/735], Loss: 0.2345\n",
      "Epoch [21/50], Step [679/735], Loss: 0.3321\n",
      "Epoch [21/50], Step [680/735], Loss: 0.0620\n",
      "Epoch [21/50], Step [681/735], Loss: 0.2781\n",
      "Epoch [21/50], Step [682/735], Loss: 0.9496\n",
      "Epoch [21/50], Step [683/735], Loss: 0.4482\n",
      "Epoch [21/50], Step [684/735], Loss: 0.6041\n",
      "Epoch [21/50], Step [685/735], Loss: 0.1499\n",
      "Epoch [21/50], Step [686/735], Loss: 0.2955\n",
      "Epoch [21/50], Step [687/735], Loss: 0.2234\n",
      "Epoch [21/50], Step [688/735], Loss: 0.3834\n",
      "Epoch [21/50], Step [689/735], Loss: 0.2140\n",
      "Epoch [21/50], Step [690/735], Loss: 0.3574\n",
      "Epoch [21/50], Step [691/735], Loss: 0.1362\n",
      "Epoch [21/50], Step [692/735], Loss: 0.4308\n",
      "Epoch [21/50], Step [693/735], Loss: 0.1891\n",
      "Epoch [21/50], Step [694/735], Loss: 0.3209\n",
      "Epoch [21/50], Step [695/735], Loss: 0.2031\n",
      "Epoch [21/50], Step [696/735], Loss: 0.4100\n",
      "Epoch [21/50], Step [697/735], Loss: 0.1964\n",
      "Epoch [21/50], Step [698/735], Loss: 0.5284\n",
      "Epoch [21/50], Step [699/735], Loss: 0.3156\n",
      "Epoch [21/50], Step [700/735], Loss: 0.2208\n",
      "Epoch [21/50], Step [701/735], Loss: 1.0546\n",
      "Epoch [21/50], Step [702/735], Loss: 0.6525\n",
      "Epoch [21/50], Step [703/735], Loss: 0.6634\n",
      "Epoch [21/50], Step [704/735], Loss: 0.1505\n",
      "Epoch [21/50], Step [705/735], Loss: 0.6573\n",
      "Epoch [21/50], Step [706/735], Loss: 0.3288\n",
      "Epoch [21/50], Step [707/735], Loss: 0.1481\n",
      "Epoch [21/50], Step [708/735], Loss: 0.2470\n",
      "Epoch [21/50], Step [709/735], Loss: 0.6063\n",
      "Epoch [21/50], Step [710/735], Loss: 0.2328\n",
      "Epoch [21/50], Step [711/735], Loss: 0.2794\n",
      "Epoch [21/50], Step [712/735], Loss: 0.9400\n",
      "Epoch [21/50], Step [713/735], Loss: 0.1517\n",
      "Epoch [21/50], Step [714/735], Loss: 1.0409\n",
      "Epoch [21/50], Step [715/735], Loss: 0.7210\n",
      "Epoch [21/50], Step [716/735], Loss: 0.9154\n",
      "Epoch [21/50], Step [717/735], Loss: 0.3759\n",
      "Epoch [21/50], Step [718/735], Loss: 0.5773\n",
      "Epoch [21/50], Step [719/735], Loss: 0.2619\n",
      "Epoch [21/50], Step [720/735], Loss: 0.1274\n",
      "Epoch [21/50], Step [721/735], Loss: 0.9890\n",
      "Epoch [21/50], Step [722/735], Loss: 0.2117\n",
      "Epoch [21/50], Step [723/735], Loss: 0.4134\n",
      "Epoch [21/50], Step [724/735], Loss: 0.1522\n",
      "Epoch [21/50], Step [725/735], Loss: 0.2630\n",
      "Epoch [21/50], Step [726/735], Loss: 0.6637\n",
      "Epoch [21/50], Step [727/735], Loss: 1.0045\n",
      "Epoch [21/50], Step [728/735], Loss: 0.1643\n",
      "Epoch [21/50], Step [729/735], Loss: 1.2112\n",
      "Epoch [21/50], Step [730/735], Loss: 0.3421\n",
      "Epoch [21/50], Step [731/735], Loss: 0.1472\n",
      "Epoch [21/50], Step [732/735], Loss: 0.2925\n",
      "Epoch [21/50], Step [733/735], Loss: 0.4565\n",
      "Epoch [21/50], Step [734/735], Loss: 0.2673\n",
      "Epoch [21/50], Step [735/735], Loss: 0.2527\n",
      "Epoch [22/50], Step [1/735], Loss: 0.7823\n",
      "Epoch [22/50], Step [2/735], Loss: 0.2083\n",
      "Epoch [22/50], Step [3/735], Loss: 0.3150\n",
      "Epoch [22/50], Step [4/735], Loss: 0.3044\n",
      "Epoch [22/50], Step [5/735], Loss: 0.4362\n",
      "Epoch [22/50], Step [6/735], Loss: 0.4509\n",
      "Epoch [22/50], Step [7/735], Loss: 0.0796\n",
      "Epoch [22/50], Step [8/735], Loss: 0.1693\n",
      "Epoch [22/50], Step [9/735], Loss: 0.2244\n",
      "Epoch [22/50], Step [10/735], Loss: 0.4346\n",
      "Epoch [22/50], Step [11/735], Loss: 1.6610\n",
      "Epoch [22/50], Step [12/735], Loss: 0.3699\n",
      "Epoch [22/50], Step [13/735], Loss: 0.1845\n",
      "Epoch [22/50], Step [14/735], Loss: 0.3520\n",
      "Epoch [22/50], Step [15/735], Loss: 0.4901\n",
      "Epoch [22/50], Step [16/735], Loss: 0.3460\n",
      "Epoch [22/50], Step [17/735], Loss: 0.1554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Step [18/735], Loss: 0.1837\n",
      "Epoch [22/50], Step [19/735], Loss: 0.8395\n",
      "Epoch [22/50], Step [20/735], Loss: 0.9068\n",
      "Epoch [22/50], Step [21/735], Loss: 0.3994\n",
      "Epoch [22/50], Step [22/735], Loss: 0.4696\n",
      "Epoch [22/50], Step [23/735], Loss: 0.2638\n",
      "Epoch [22/50], Step [24/735], Loss: 0.3026\n",
      "Epoch [22/50], Step [25/735], Loss: 0.3527\n",
      "Epoch [22/50], Step [26/735], Loss: 0.1235\n",
      "Epoch [22/50], Step [27/735], Loss: 0.0949\n",
      "Epoch [22/50], Step [28/735], Loss: 1.0170\n",
      "Epoch [22/50], Step [29/735], Loss: 0.5535\n",
      "Epoch [22/50], Step [30/735], Loss: 0.2954\n",
      "Epoch [22/50], Step [31/735], Loss: 1.7196\n",
      "Epoch [22/50], Step [32/735], Loss: 0.4765\n",
      "Epoch [22/50], Step [33/735], Loss: 0.2625\n",
      "Epoch [22/50], Step [34/735], Loss: 0.1751\n",
      "Epoch [22/50], Step [35/735], Loss: 0.5382\n",
      "Epoch [22/50], Step [36/735], Loss: 0.2767\n",
      "Epoch [22/50], Step [37/735], Loss: 0.1979\n",
      "Epoch [22/50], Step [38/735], Loss: 0.1343\n",
      "Epoch [22/50], Step [39/735], Loss: 0.3484\n",
      "Epoch [22/50], Step [40/735], Loss: 0.5728\n",
      "Epoch [22/50], Step [41/735], Loss: 0.2820\n",
      "Epoch [22/50], Step [42/735], Loss: 0.4774\n",
      "Epoch [22/50], Step [43/735], Loss: 0.1813\n",
      "Epoch [22/50], Step [44/735], Loss: 2.9430\n",
      "Epoch [22/50], Step [45/735], Loss: 0.2213\n",
      "Epoch [22/50], Step [46/735], Loss: 0.2039\n",
      "Epoch [22/50], Step [47/735], Loss: 0.1175\n",
      "Epoch [22/50], Step [48/735], Loss: 0.3312\n",
      "Epoch [22/50], Step [49/735], Loss: 0.7442\n",
      "Epoch [22/50], Step [50/735], Loss: 0.3369\n",
      "Epoch [22/50], Step [51/735], Loss: 0.8561\n",
      "Epoch [22/50], Step [52/735], Loss: 4.6912\n",
      "Epoch [22/50], Step [53/735], Loss: 0.3119\n",
      "Epoch [22/50], Step [54/735], Loss: 1.0874\n",
      "Epoch [22/50], Step [55/735], Loss: 0.5235\n",
      "Epoch [22/50], Step [56/735], Loss: 0.6640\n",
      "Epoch [22/50], Step [57/735], Loss: 0.2070\n",
      "Epoch [22/50], Step [58/735], Loss: 2.6324\n",
      "Epoch [22/50], Step [59/735], Loss: 0.3177\n",
      "Epoch [22/50], Step [60/735], Loss: 0.4883\n",
      "Epoch [22/50], Step [61/735], Loss: 0.9542\n",
      "Epoch [22/50], Step [62/735], Loss: 0.2619\n",
      "Epoch [22/50], Step [63/735], Loss: 0.1688\n",
      "Epoch [22/50], Step [64/735], Loss: 0.1987\n",
      "Epoch [22/50], Step [65/735], Loss: 0.1615\n",
      "Epoch [22/50], Step [66/735], Loss: 0.4354\n",
      "Epoch [22/50], Step [67/735], Loss: 1.7314\n",
      "Epoch [22/50], Step [68/735], Loss: 0.2094\n",
      "Epoch [22/50], Step [69/735], Loss: 0.4929\n",
      "Epoch [22/50], Step [70/735], Loss: 0.5321\n",
      "Epoch [22/50], Step [71/735], Loss: 0.1997\n",
      "Epoch [22/50], Step [72/735], Loss: 0.0935\n",
      "Epoch [22/50], Step [73/735], Loss: 0.2152\n",
      "Epoch [22/50], Step [74/735], Loss: 0.1596\n",
      "Epoch [22/50], Step [75/735], Loss: 0.4190\n",
      "Epoch [22/50], Step [76/735], Loss: 0.3658\n",
      "Epoch [22/50], Step [77/735], Loss: 0.2271\n",
      "Epoch [22/50], Step [78/735], Loss: 0.1428\n",
      "Epoch [22/50], Step [79/735], Loss: 0.4033\n",
      "Epoch [22/50], Step [80/735], Loss: 0.2815\n",
      "Epoch [22/50], Step [81/735], Loss: 0.4305\n",
      "Epoch [22/50], Step [82/735], Loss: 0.2591\n",
      "Epoch [22/50], Step [83/735], Loss: 0.3552\n",
      "Epoch [22/50], Step [84/735], Loss: 0.1793\n",
      "Epoch [22/50], Step [85/735], Loss: 0.4804\n",
      "Epoch [22/50], Step [86/735], Loss: 0.2094\n",
      "Epoch [22/50], Step [87/735], Loss: 0.6972\n",
      "Epoch [22/50], Step [88/735], Loss: 0.1845\n",
      "Epoch [22/50], Step [89/735], Loss: 0.1160\n",
      "Epoch [22/50], Step [90/735], Loss: 0.2666\n",
      "Epoch [22/50], Step [91/735], Loss: 0.3241\n",
      "Epoch [22/50], Step [92/735], Loss: 0.3841\n",
      "Epoch [22/50], Step [93/735], Loss: 0.2522\n",
      "Epoch [22/50], Step [94/735], Loss: 0.4482\n",
      "Epoch [22/50], Step [95/735], Loss: 0.2882\n",
      "Epoch [22/50], Step [96/735], Loss: 0.1845\n",
      "Epoch [22/50], Step [97/735], Loss: 0.3045\n",
      "Epoch [22/50], Step [98/735], Loss: 0.2542\n",
      "Epoch [22/50], Step [99/735], Loss: 0.2383\n",
      "Epoch [22/50], Step [100/735], Loss: 0.7488\n",
      "Epoch [22/50], Step [101/735], Loss: 0.1867\n",
      "Epoch [22/50], Step [102/735], Loss: 0.1685\n",
      "Epoch [22/50], Step [103/735], Loss: 0.1831\n",
      "Epoch [22/50], Step [104/735], Loss: 0.5081\n",
      "Epoch [22/50], Step [105/735], Loss: 0.3834\n",
      "Epoch [22/50], Step [106/735], Loss: 0.2243\n",
      "Epoch [22/50], Step [107/735], Loss: 0.1652\n",
      "Epoch [22/50], Step [108/735], Loss: 0.2996\n",
      "Epoch [22/50], Step [109/735], Loss: 0.1346\n",
      "Epoch [22/50], Step [110/735], Loss: 0.9169\n",
      "Epoch [22/50], Step [111/735], Loss: 0.2133\n",
      "Epoch [22/50], Step [112/735], Loss: 0.8944\n",
      "Epoch [22/50], Step [113/735], Loss: 0.5220\n",
      "Epoch [22/50], Step [114/735], Loss: 0.4447\n",
      "Epoch [22/50], Step [115/735], Loss: 0.5069\n",
      "Epoch [22/50], Step [116/735], Loss: 1.6797\n",
      "Epoch [22/50], Step [117/735], Loss: 0.1580\n",
      "Epoch [22/50], Step [118/735], Loss: 0.3529\n",
      "Epoch [22/50], Step [119/735], Loss: 0.2414\n",
      "Epoch [22/50], Step [120/735], Loss: 0.3232\n",
      "Epoch [22/50], Step [121/735], Loss: 0.0839\n",
      "Epoch [22/50], Step [122/735], Loss: 0.3866\n",
      "Epoch [22/50], Step [123/735], Loss: 0.1444\n",
      "Epoch [22/50], Step [124/735], Loss: 0.7896\n",
      "Epoch [22/50], Step [125/735], Loss: 0.4774\n",
      "Epoch [22/50], Step [126/735], Loss: 0.2271\n",
      "Epoch [22/50], Step [127/735], Loss: 0.0970\n",
      "Epoch [22/50], Step [128/735], Loss: 0.2371\n",
      "Epoch [22/50], Step [129/735], Loss: 0.4365\n",
      "Epoch [22/50], Step [130/735], Loss: 0.1694\n",
      "Epoch [22/50], Step [131/735], Loss: 0.2711\n",
      "Epoch [22/50], Step [132/735], Loss: 0.2685\n",
      "Epoch [22/50], Step [133/735], Loss: 0.1926\n",
      "Epoch [22/50], Step [134/735], Loss: 1.1819\n",
      "Epoch [22/50], Step [135/735], Loss: 0.2064\n",
      "Epoch [22/50], Step [136/735], Loss: 0.8339\n",
      "Epoch [22/50], Step [137/735], Loss: 0.9868\n",
      "Epoch [22/50], Step [138/735], Loss: 0.2169\n",
      "Epoch [22/50], Step [139/735], Loss: 1.4580\n",
      "Epoch [22/50], Step [140/735], Loss: 0.1526\n",
      "Epoch [22/50], Step [141/735], Loss: 0.1760\n",
      "Epoch [22/50], Step [142/735], Loss: 0.6188\n",
      "Epoch [22/50], Step [143/735], Loss: 0.1399\n",
      "Epoch [22/50], Step [144/735], Loss: 0.5391\n",
      "Epoch [22/50], Step [145/735], Loss: 0.3978\n",
      "Epoch [22/50], Step [146/735], Loss: 0.1482\n",
      "Epoch [22/50], Step [147/735], Loss: 0.2141\n",
      "Epoch [22/50], Step [148/735], Loss: 0.6702\n",
      "Epoch [22/50], Step [149/735], Loss: 0.2936\n",
      "Epoch [22/50], Step [150/735], Loss: 0.2903\n",
      "Epoch [22/50], Step [151/735], Loss: 0.2257\n",
      "Epoch [22/50], Step [152/735], Loss: 0.3729\n",
      "Epoch [22/50], Step [153/735], Loss: 0.3374\n",
      "Epoch [22/50], Step [154/735], Loss: 0.3676\n",
      "Epoch [22/50], Step [155/735], Loss: 0.4246\n",
      "Epoch [22/50], Step [156/735], Loss: 0.6406\n",
      "Epoch [22/50], Step [157/735], Loss: 0.0759\n",
      "Epoch [22/50], Step [158/735], Loss: 0.5907\n",
      "Epoch [22/50], Step [159/735], Loss: 1.5023\n",
      "Epoch [22/50], Step [160/735], Loss: 0.4541\n",
      "Epoch [22/50], Step [161/735], Loss: 0.6989\n",
      "Epoch [22/50], Step [162/735], Loss: 0.5957\n",
      "Epoch [22/50], Step [163/735], Loss: 0.6914\n",
      "Epoch [22/50], Step [164/735], Loss: 0.2862\n",
      "Epoch [22/50], Step [165/735], Loss: 0.9544\n",
      "Epoch [22/50], Step [166/735], Loss: 0.3582\n",
      "Epoch [22/50], Step [167/735], Loss: 0.7041\n",
      "Epoch [22/50], Step [168/735], Loss: 0.1737\n",
      "Epoch [22/50], Step [169/735], Loss: 0.6968\n",
      "Epoch [22/50], Step [170/735], Loss: 0.8128\n",
      "Epoch [22/50], Step [171/735], Loss: 0.4593\n",
      "Epoch [22/50], Step [172/735], Loss: 0.4401\n",
      "Epoch [22/50], Step [173/735], Loss: 0.8158\n",
      "Epoch [22/50], Step [174/735], Loss: 0.5313\n",
      "Epoch [22/50], Step [175/735], Loss: 0.2203\n",
      "Epoch [22/50], Step [176/735], Loss: 0.5666\n",
      "Epoch [22/50], Step [177/735], Loss: 0.2946\n",
      "Epoch [22/50], Step [178/735], Loss: 0.1461\n",
      "Epoch [22/50], Step [179/735], Loss: 0.3576\n",
      "Epoch [22/50], Step [180/735], Loss: 0.1921\n",
      "Epoch [22/50], Step [181/735], Loss: 0.5246\n",
      "Epoch [22/50], Step [182/735], Loss: 0.4640\n",
      "Epoch [22/50], Step [183/735], Loss: 0.3901\n",
      "Epoch [22/50], Step [184/735], Loss: 0.5361\n",
      "Epoch [22/50], Step [185/735], Loss: 0.2968\n",
      "Epoch [22/50], Step [186/735], Loss: 0.2226\n",
      "Epoch [22/50], Step [187/735], Loss: 0.1710\n",
      "Epoch [22/50], Step [188/735], Loss: 0.3739\n",
      "Epoch [22/50], Step [189/735], Loss: 0.8661\n",
      "Epoch [22/50], Step [190/735], Loss: 0.2531\n",
      "Epoch [22/50], Step [191/735], Loss: 0.5039\n",
      "Epoch [22/50], Step [192/735], Loss: 0.1988\n",
      "Epoch [22/50], Step [193/735], Loss: 0.3080\n",
      "Epoch [22/50], Step [194/735], Loss: 0.1813\n",
      "Epoch [22/50], Step [195/735], Loss: 0.1172\n",
      "Epoch [22/50], Step [196/735], Loss: 0.3643\n",
      "Epoch [22/50], Step [197/735], Loss: 0.4936\n",
      "Epoch [22/50], Step [198/735], Loss: 0.1948\n",
      "Epoch [22/50], Step [199/735], Loss: 0.2476\n",
      "Epoch [22/50], Step [200/735], Loss: 0.1307\n",
      "Epoch [22/50], Step [201/735], Loss: 0.8648\n",
      "Epoch [22/50], Step [202/735], Loss: 0.2037\n",
      "Epoch [22/50], Step [203/735], Loss: 0.1840\n",
      "Epoch [22/50], Step [204/735], Loss: 0.3585\n",
      "Epoch [22/50], Step [205/735], Loss: 0.2761\n",
      "Epoch [22/50], Step [206/735], Loss: 0.0556\n",
      "Epoch [22/50], Step [207/735], Loss: 0.3771\n",
      "Epoch [22/50], Step [208/735], Loss: 4.2849\n",
      "Epoch [22/50], Step [209/735], Loss: 0.1310\n",
      "Epoch [22/50], Step [210/735], Loss: 0.1346\n",
      "Epoch [22/50], Step [211/735], Loss: 0.1056\n",
      "Epoch [22/50], Step [212/735], Loss: 0.3360\n",
      "Epoch [22/50], Step [213/735], Loss: 0.2958\n",
      "Epoch [22/50], Step [214/735], Loss: 1.2536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Step [215/735], Loss: 0.2928\n",
      "Epoch [22/50], Step [216/735], Loss: 0.1153\n",
      "Epoch [22/50], Step [217/735], Loss: 0.1024\n",
      "Epoch [22/50], Step [218/735], Loss: 0.6520\n",
      "Epoch [22/50], Step [219/735], Loss: 0.4081\n",
      "Epoch [22/50], Step [220/735], Loss: 0.2892\n",
      "Epoch [22/50], Step [221/735], Loss: 0.4821\n",
      "Epoch [22/50], Step [222/735], Loss: 0.3824\n",
      "Epoch [22/50], Step [223/735], Loss: 1.6600\n",
      "Epoch [22/50], Step [224/735], Loss: 1.3589\n",
      "Epoch [22/50], Step [225/735], Loss: 1.3766\n",
      "Epoch [22/50], Step [226/735], Loss: 0.0756\n",
      "Epoch [22/50], Step [227/735], Loss: 0.1847\n",
      "Epoch [22/50], Step [228/735], Loss: 0.5928\n",
      "Epoch [22/50], Step [229/735], Loss: 0.4083\n",
      "Epoch [22/50], Step [230/735], Loss: 1.0581\n",
      "Epoch [22/50], Step [231/735], Loss: 0.3593\n",
      "Epoch [22/50], Step [232/735], Loss: 0.6522\n",
      "Epoch [22/50], Step [233/735], Loss: 0.2211\n",
      "Epoch [22/50], Step [234/735], Loss: 0.3275\n",
      "Epoch [22/50], Step [235/735], Loss: 0.9411\n",
      "Epoch [22/50], Step [236/735], Loss: 0.4455\n",
      "Epoch [22/50], Step [237/735], Loss: 0.8361\n",
      "Epoch [22/50], Step [238/735], Loss: 0.1893\n",
      "Epoch [22/50], Step [239/735], Loss: 0.6509\n",
      "Epoch [22/50], Step [240/735], Loss: 0.2641\n",
      "Epoch [22/50], Step [241/735], Loss: 0.5583\n",
      "Epoch [22/50], Step [242/735], Loss: 1.5091\n",
      "Epoch [22/50], Step [243/735], Loss: 0.0383\n",
      "Epoch [22/50], Step [244/735], Loss: 0.1430\n",
      "Epoch [22/50], Step [245/735], Loss: 0.1034\n",
      "Epoch [22/50], Step [246/735], Loss: 0.1007\n",
      "Epoch [22/50], Step [247/735], Loss: 0.8983\n",
      "Epoch [22/50], Step [248/735], Loss: 0.0873\n",
      "Epoch [22/50], Step [249/735], Loss: 0.3633\n",
      "Epoch [22/50], Step [250/735], Loss: 0.2647\n",
      "Epoch [22/50], Step [251/735], Loss: 0.7240\n",
      "Epoch [22/50], Step [252/735], Loss: 0.2075\n",
      "Epoch [22/50], Step [253/735], Loss: 0.2157\n",
      "Epoch [22/50], Step [254/735], Loss: 0.0643\n",
      "Epoch [22/50], Step [255/735], Loss: 0.5614\n",
      "Epoch [22/50], Step [256/735], Loss: 0.1842\n",
      "Epoch [22/50], Step [257/735], Loss: 0.3739\n",
      "Epoch [22/50], Step [258/735], Loss: 0.2224\n",
      "Epoch [22/50], Step [259/735], Loss: 0.3197\n",
      "Epoch [22/50], Step [260/735], Loss: 0.0822\n",
      "Epoch [22/50], Step [261/735], Loss: 0.1141\n",
      "Epoch [22/50], Step [262/735], Loss: 1.2827\n",
      "Epoch [22/50], Step [263/735], Loss: 1.1281\n",
      "Epoch [22/50], Step [264/735], Loss: 0.4940\n",
      "Epoch [22/50], Step [265/735], Loss: 0.2450\n",
      "Epoch [22/50], Step [266/735], Loss: 0.1771\n",
      "Epoch [22/50], Step [267/735], Loss: 0.3284\n",
      "Epoch [22/50], Step [268/735], Loss: 0.2091\n",
      "Epoch [22/50], Step [269/735], Loss: 1.5429\n",
      "Epoch [22/50], Step [270/735], Loss: 1.0426\n",
      "Epoch [22/50], Step [271/735], Loss: 0.1572\n",
      "Epoch [22/50], Step [272/735], Loss: 0.7236\n",
      "Epoch [22/50], Step [273/735], Loss: 0.2942\n",
      "Epoch [22/50], Step [274/735], Loss: 0.1812\n",
      "Epoch [22/50], Step [275/735], Loss: 0.1794\n",
      "Epoch [22/50], Step [276/735], Loss: 0.2527\n",
      "Epoch [22/50], Step [277/735], Loss: 0.0441\n",
      "Epoch [22/50], Step [278/735], Loss: 0.5693\n",
      "Epoch [22/50], Step [279/735], Loss: 0.1201\n",
      "Epoch [22/50], Step [280/735], Loss: 0.6283\n",
      "Epoch [22/50], Step [281/735], Loss: 0.2044\n",
      "Epoch [22/50], Step [282/735], Loss: 0.1391\n",
      "Epoch [22/50], Step [283/735], Loss: 0.4668\n",
      "Epoch [22/50], Step [284/735], Loss: 0.6105\n",
      "Epoch [22/50], Step [285/735], Loss: 0.4880\n",
      "Epoch [22/50], Step [286/735], Loss: 0.1617\n",
      "Epoch [22/50], Step [287/735], Loss: 0.7277\n",
      "Epoch [22/50], Step [288/735], Loss: 0.3122\n",
      "Epoch [22/50], Step [289/735], Loss: 0.3795\n",
      "Epoch [22/50], Step [290/735], Loss: 0.2932\n",
      "Epoch [22/50], Step [291/735], Loss: 0.4597\n",
      "Epoch [22/50], Step [292/735], Loss: 0.5504\n",
      "Epoch [22/50], Step [293/735], Loss: 0.5500\n",
      "Epoch [22/50], Step [294/735], Loss: 0.2543\n",
      "Epoch [22/50], Step [295/735], Loss: 0.3894\n",
      "Epoch [22/50], Step [296/735], Loss: 0.7514\n",
      "Epoch [22/50], Step [297/735], Loss: 0.2531\n",
      "Epoch [22/50], Step [298/735], Loss: 0.2961\n",
      "Epoch [22/50], Step [299/735], Loss: 0.2719\n",
      "Epoch [22/50], Step [300/735], Loss: 0.0574\n",
      "Epoch [22/50], Step [301/735], Loss: 1.1085\n",
      "Epoch [22/50], Step [302/735], Loss: 1.3627\n",
      "Epoch [22/50], Step [303/735], Loss: 0.3996\n",
      "Epoch [22/50], Step [304/735], Loss: 0.3612\n",
      "Epoch [22/50], Step [305/735], Loss: 1.0063\n",
      "Epoch [22/50], Step [306/735], Loss: 1.0264\n",
      "Epoch [22/50], Step [307/735], Loss: 0.4203\n",
      "Epoch [22/50], Step [308/735], Loss: 0.3739\n",
      "Epoch [22/50], Step [309/735], Loss: 0.1577\n",
      "Epoch [22/50], Step [310/735], Loss: 0.3352\n",
      "Epoch [22/50], Step [311/735], Loss: 0.6082\n",
      "Epoch [22/50], Step [312/735], Loss: 0.1170\n",
      "Epoch [22/50], Step [313/735], Loss: 0.1081\n",
      "Epoch [22/50], Step [314/735], Loss: 0.0866\n",
      "Epoch [22/50], Step [315/735], Loss: 0.4688\n",
      "Epoch [22/50], Step [316/735], Loss: 0.1356\n",
      "Epoch [22/50], Step [317/735], Loss: 0.3130\n",
      "Epoch [22/50], Step [318/735], Loss: 0.3877\n",
      "Epoch [22/50], Step [319/735], Loss: 0.5982\n",
      "Epoch [22/50], Step [320/735], Loss: 0.4621\n",
      "Epoch [22/50], Step [321/735], Loss: 0.3962\n",
      "Epoch [22/50], Step [322/735], Loss: 0.4574\n",
      "Epoch [22/50], Step [323/735], Loss: 0.3055\n",
      "Epoch [22/50], Step [324/735], Loss: 0.3970\n",
      "Epoch [22/50], Step [325/735], Loss: 0.2781\n",
      "Epoch [22/50], Step [326/735], Loss: 0.6421\n",
      "Epoch [22/50], Step [327/735], Loss: 0.4164\n",
      "Epoch [22/50], Step [328/735], Loss: 0.0944\n",
      "Epoch [22/50], Step [329/735], Loss: 0.2197\n",
      "Epoch [22/50], Step [330/735], Loss: 0.3759\n",
      "Epoch [22/50], Step [331/735], Loss: 0.3463\n",
      "Epoch [22/50], Step [332/735], Loss: 0.4084\n",
      "Epoch [22/50], Step [333/735], Loss: 0.2193\n",
      "Epoch [22/50], Step [334/735], Loss: 0.0742\n",
      "Epoch [22/50], Step [335/735], Loss: 0.2016\n",
      "Epoch [22/50], Step [336/735], Loss: 0.4190\n",
      "Epoch [22/50], Step [337/735], Loss: 0.0791\n",
      "Epoch [22/50], Step [338/735], Loss: 0.1410\n",
      "Epoch [22/50], Step [339/735], Loss: 0.5580\n",
      "Epoch [22/50], Step [340/735], Loss: 0.1879\n",
      "Epoch [22/50], Step [341/735], Loss: 0.1131\n",
      "Epoch [22/50], Step [342/735], Loss: 0.7363\n",
      "Epoch [22/50], Step [343/735], Loss: 0.0946\n",
      "Epoch [22/50], Step [344/735], Loss: 0.2917\n",
      "Epoch [22/50], Step [345/735], Loss: 0.4529\n",
      "Epoch [22/50], Step [346/735], Loss: 0.1178\n",
      "Epoch [22/50], Step [347/735], Loss: 0.1178\n",
      "Epoch [22/50], Step [348/735], Loss: 0.9803\n",
      "Epoch [22/50], Step [349/735], Loss: 0.5203\n",
      "Epoch [22/50], Step [350/735], Loss: 0.5644\n",
      "Epoch [22/50], Step [351/735], Loss: 0.1724\n",
      "Epoch [22/50], Step [352/735], Loss: 0.2284\n",
      "Epoch [22/50], Step [353/735], Loss: 0.3276\n",
      "Epoch [22/50], Step [354/735], Loss: 0.4421\n",
      "Epoch [22/50], Step [355/735], Loss: 0.6350\n",
      "Epoch [22/50], Step [356/735], Loss: 0.2950\n",
      "Epoch [22/50], Step [357/735], Loss: 0.2329\n",
      "Epoch [22/50], Step [358/735], Loss: 0.2916\n",
      "Epoch [22/50], Step [359/735], Loss: 0.3792\n",
      "Epoch [22/50], Step [360/735], Loss: 0.5093\n",
      "Epoch [22/50], Step [361/735], Loss: 0.2269\n",
      "Epoch [22/50], Step [362/735], Loss: 0.1868\n",
      "Epoch [22/50], Step [363/735], Loss: 0.3865\n",
      "Epoch [22/50], Step [364/735], Loss: 0.8141\n",
      "Epoch [22/50], Step [365/735], Loss: 0.0619\n",
      "Epoch [22/50], Step [366/735], Loss: 0.1004\n",
      "Epoch [22/50], Step [367/735], Loss: 2.0487\n",
      "Epoch [22/50], Step [368/735], Loss: 0.4730\n",
      "Epoch [22/50], Step [369/735], Loss: 0.4418\n",
      "Epoch [22/50], Step [370/735], Loss: 0.7061\n",
      "Epoch [22/50], Step [371/735], Loss: 0.1266\n",
      "Epoch [22/50], Step [372/735], Loss: 0.0915\n",
      "Epoch [22/50], Step [373/735], Loss: 0.1948\n",
      "Epoch [22/50], Step [374/735], Loss: 0.6830\n",
      "Epoch [22/50], Step [375/735], Loss: 0.3066\n",
      "Epoch [22/50], Step [376/735], Loss: 0.2531\n",
      "Epoch [22/50], Step [377/735], Loss: 0.5054\n",
      "Epoch [22/50], Step [378/735], Loss: 0.3050\n",
      "Epoch [22/50], Step [379/735], Loss: 0.3737\n",
      "Epoch [22/50], Step [380/735], Loss: 0.2201\n",
      "Epoch [22/50], Step [381/735], Loss: 0.1617\n",
      "Epoch [22/50], Step [382/735], Loss: 0.3267\n",
      "Epoch [22/50], Step [383/735], Loss: 0.3829\n",
      "Epoch [22/50], Step [384/735], Loss: 0.4691\n",
      "Epoch [22/50], Step [385/735], Loss: 0.4075\n",
      "Epoch [22/50], Step [386/735], Loss: 0.1815\n",
      "Epoch [22/50], Step [387/735], Loss: 0.6733\n",
      "Epoch [22/50], Step [388/735], Loss: 0.1916\n",
      "Epoch [22/50], Step [389/735], Loss: 0.1352\n",
      "Epoch [22/50], Step [390/735], Loss: 0.1093\n",
      "Epoch [22/50], Step [391/735], Loss: 0.1627\n",
      "Epoch [22/50], Step [392/735], Loss: 0.6091\n",
      "Epoch [22/50], Step [393/735], Loss: 0.1224\n",
      "Epoch [22/50], Step [394/735], Loss: 0.0689\n",
      "Epoch [22/50], Step [395/735], Loss: 0.0650\n",
      "Epoch [22/50], Step [396/735], Loss: 0.2229\n",
      "Epoch [22/50], Step [397/735], Loss: 0.1749\n",
      "Epoch [22/50], Step [398/735], Loss: 0.3471\n",
      "Epoch [22/50], Step [399/735], Loss: 0.3544\n",
      "Epoch [22/50], Step [400/735], Loss: 0.9565\n",
      "Epoch [22/50], Step [401/735], Loss: 0.1712\n",
      "Epoch [22/50], Step [402/735], Loss: 0.3082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Step [403/735], Loss: 0.6693\n",
      "Epoch [22/50], Step [404/735], Loss: 0.1808\n",
      "Epoch [22/50], Step [405/735], Loss: 0.8430\n",
      "Epoch [22/50], Step [406/735], Loss: 0.3471\n",
      "Epoch [22/50], Step [407/735], Loss: 0.5859\n",
      "Epoch [22/50], Step [408/735], Loss: 0.2150\n",
      "Epoch [22/50], Step [409/735], Loss: 0.2354\n",
      "Epoch [22/50], Step [410/735], Loss: 0.1100\n",
      "Epoch [22/50], Step [411/735], Loss: 0.1863\n",
      "Epoch [22/50], Step [412/735], Loss: 0.7631\n",
      "Epoch [22/50], Step [413/735], Loss: 0.2417\n",
      "Epoch [22/50], Step [414/735], Loss: 0.4211\n",
      "Epoch [22/50], Step [415/735], Loss: 1.2402\n",
      "Epoch [22/50], Step [416/735], Loss: 0.6190\n",
      "Epoch [22/50], Step [417/735], Loss: 0.2812\n",
      "Epoch [22/50], Step [418/735], Loss: 0.3657\n",
      "Epoch [22/50], Step [419/735], Loss: 0.2820\n",
      "Epoch [22/50], Step [420/735], Loss: 0.3328\n",
      "Epoch [22/50], Step [421/735], Loss: 1.2504\n",
      "Epoch [22/50], Step [422/735], Loss: 0.5410\n",
      "Epoch [22/50], Step [423/735], Loss: 0.2087\n",
      "Epoch [22/50], Step [424/735], Loss: 0.3074\n",
      "Epoch [22/50], Step [425/735], Loss: 0.2717\n",
      "Epoch [22/50], Step [426/735], Loss: 0.1116\n",
      "Epoch [22/50], Step [427/735], Loss: 0.7131\n",
      "Epoch [22/50], Step [428/735], Loss: 0.1858\n",
      "Epoch [22/50], Step [429/735], Loss: 0.1957\n",
      "Epoch [22/50], Step [430/735], Loss: 0.2291\n",
      "Epoch [22/50], Step [431/735], Loss: 0.4181\n",
      "Epoch [22/50], Step [432/735], Loss: 4.2866\n",
      "Epoch [22/50], Step [433/735], Loss: 0.2872\n",
      "Epoch [22/50], Step [434/735], Loss: 0.2382\n",
      "Epoch [22/50], Step [435/735], Loss: 0.1216\n",
      "Epoch [22/50], Step [436/735], Loss: 0.2347\n",
      "Epoch [22/50], Step [437/735], Loss: 0.1813\n",
      "Epoch [22/50], Step [438/735], Loss: 0.1506\n",
      "Epoch [22/50], Step [439/735], Loss: 0.1196\n",
      "Epoch [22/50], Step [440/735], Loss: 0.2536\n",
      "Epoch [22/50], Step [441/735], Loss: 0.0547\n",
      "Epoch [22/50], Step [442/735], Loss: 0.3174\n",
      "Epoch [22/50], Step [443/735], Loss: 0.2992\n",
      "Epoch [22/50], Step [444/735], Loss: 0.0954\n",
      "Epoch [22/50], Step [445/735], Loss: 0.4580\n",
      "Epoch [22/50], Step [446/735], Loss: 0.3480\n",
      "Epoch [22/50], Step [447/735], Loss: 0.3007\n",
      "Epoch [22/50], Step [448/735], Loss: 0.4769\n",
      "Epoch [22/50], Step [449/735], Loss: 0.5059\n",
      "Epoch [22/50], Step [450/735], Loss: 0.2709\n",
      "Epoch [22/50], Step [451/735], Loss: 0.2332\n",
      "Epoch [22/50], Step [452/735], Loss: 0.7764\n",
      "Epoch [22/50], Step [453/735], Loss: 0.2743\n",
      "Epoch [22/50], Step [454/735], Loss: 0.1161\n",
      "Epoch [22/50], Step [455/735], Loss: 0.1632\n",
      "Epoch [22/50], Step [456/735], Loss: 0.7259\n",
      "Epoch [22/50], Step [457/735], Loss: 0.2252\n",
      "Epoch [22/50], Step [458/735], Loss: 0.1230\n",
      "Epoch [22/50], Step [459/735], Loss: 0.9606\n",
      "Epoch [22/50], Step [460/735], Loss: 0.6005\n",
      "Epoch [22/50], Step [461/735], Loss: 0.3127\n",
      "Epoch [22/50], Step [462/735], Loss: 0.2654\n",
      "Epoch [22/50], Step [463/735], Loss: 0.2070\n",
      "Epoch [22/50], Step [464/735], Loss: 0.2318\n",
      "Epoch [22/50], Step [465/735], Loss: 0.4044\n",
      "Epoch [22/50], Step [466/735], Loss: 0.2867\n",
      "Epoch [22/50], Step [467/735], Loss: 0.2602\n",
      "Epoch [22/50], Step [468/735], Loss: 0.3430\n",
      "Epoch [22/50], Step [469/735], Loss: 0.2787\n",
      "Epoch [22/50], Step [470/735], Loss: 0.9062\n",
      "Epoch [22/50], Step [471/735], Loss: 0.3466\n",
      "Epoch [22/50], Step [472/735], Loss: 0.1454\n",
      "Epoch [22/50], Step [473/735], Loss: 0.1208\n",
      "Epoch [22/50], Step [474/735], Loss: 0.0681\n",
      "Epoch [22/50], Step [475/735], Loss: 0.1334\n",
      "Epoch [22/50], Step [476/735], Loss: 0.0881\n",
      "Epoch [22/50], Step [477/735], Loss: 0.1825\n",
      "Epoch [22/50], Step [478/735], Loss: 0.4601\n",
      "Epoch [22/50], Step [479/735], Loss: 0.2522\n",
      "Epoch [22/50], Step [480/735], Loss: 0.0735\n",
      "Epoch [22/50], Step [481/735], Loss: 0.5070\n",
      "Epoch [22/50], Step [482/735], Loss: 0.4734\n",
      "Epoch [22/50], Step [483/735], Loss: 1.4270\n",
      "Epoch [22/50], Step [484/735], Loss: 0.2532\n",
      "Epoch [22/50], Step [485/735], Loss: 0.2587\n",
      "Epoch [22/50], Step [486/735], Loss: 0.4297\n",
      "Epoch [22/50], Step [487/735], Loss: 0.1075\n",
      "Epoch [22/50], Step [488/735], Loss: 0.3899\n",
      "Epoch [22/50], Step [489/735], Loss: 1.5972\n",
      "Epoch [22/50], Step [490/735], Loss: 0.4289\n",
      "Epoch [22/50], Step [491/735], Loss: 0.4852\n",
      "Epoch [22/50], Step [492/735], Loss: 0.2615\n",
      "Epoch [22/50], Step [493/735], Loss: 0.4844\n",
      "Epoch [22/50], Step [494/735], Loss: 0.1840\n",
      "Epoch [22/50], Step [495/735], Loss: 0.1937\n",
      "Epoch [22/50], Step [496/735], Loss: 0.1150\n",
      "Epoch [22/50], Step [497/735], Loss: 0.3239\n",
      "Epoch [22/50], Step [498/735], Loss: 0.3164\n",
      "Epoch [22/50], Step [499/735], Loss: 0.0620\n",
      "Epoch [22/50], Step [500/735], Loss: 0.7316\n",
      "Epoch [22/50], Step [501/735], Loss: 0.1710\n",
      "Epoch [22/50], Step [502/735], Loss: 0.2818\n",
      "Epoch [22/50], Step [503/735], Loss: 1.3569\n",
      "Epoch [22/50], Step [504/735], Loss: 0.2602\n",
      "Epoch [22/50], Step [505/735], Loss: 1.4691\n",
      "Epoch [22/50], Step [506/735], Loss: 0.3452\n",
      "Epoch [22/50], Step [507/735], Loss: 0.3346\n",
      "Epoch [22/50], Step [508/735], Loss: 0.4499\n",
      "Epoch [22/50], Step [509/735], Loss: 0.2373\n",
      "Epoch [22/50], Step [510/735], Loss: 0.0860\n",
      "Epoch [22/50], Step [511/735], Loss: 0.1044\n",
      "Epoch [22/50], Step [512/735], Loss: 0.1676\n",
      "Epoch [22/50], Step [513/735], Loss: 0.8375\n",
      "Epoch [22/50], Step [514/735], Loss: 1.1736\n",
      "Epoch [22/50], Step [515/735], Loss: 0.2109\n",
      "Epoch [22/50], Step [516/735], Loss: 0.6761\n",
      "Epoch [22/50], Step [517/735], Loss: 0.1897\n",
      "Epoch [22/50], Step [518/735], Loss: 0.1826\n",
      "Epoch [22/50], Step [519/735], Loss: 0.2351\n",
      "Epoch [22/50], Step [520/735], Loss: 0.2415\n",
      "Epoch [22/50], Step [521/735], Loss: 0.4601\n",
      "Epoch [22/50], Step [522/735], Loss: 0.2521\n",
      "Epoch [22/50], Step [523/735], Loss: 1.1673\n",
      "Epoch [22/50], Step [524/735], Loss: 0.0304\n",
      "Epoch [22/50], Step [525/735], Loss: 0.3162\n",
      "Epoch [22/50], Step [526/735], Loss: 0.2266\n",
      "Epoch [22/50], Step [527/735], Loss: 0.2135\n",
      "Epoch [22/50], Step [528/735], Loss: 0.3609\n",
      "Epoch [22/50], Step [529/735], Loss: 0.2169\n",
      "Epoch [22/50], Step [530/735], Loss: 0.1919\n",
      "Epoch [22/50], Step [531/735], Loss: 0.1527\n",
      "Epoch [22/50], Step [532/735], Loss: 0.5839\n",
      "Epoch [22/50], Step [533/735], Loss: 0.4406\n",
      "Epoch [22/50], Step [534/735], Loss: 4.7104\n",
      "Epoch [22/50], Step [535/735], Loss: 0.4417\n",
      "Epoch [22/50], Step [536/735], Loss: 0.3999\n",
      "Epoch [22/50], Step [537/735], Loss: 1.0829\n",
      "Epoch [22/50], Step [538/735], Loss: 1.4943\n",
      "Epoch [22/50], Step [539/735], Loss: 0.2668\n",
      "Epoch [22/50], Step [540/735], Loss: 0.1239\n",
      "Epoch [22/50], Step [541/735], Loss: 0.1569\n",
      "Epoch [22/50], Step [542/735], Loss: 0.2108\n",
      "Epoch [22/50], Step [543/735], Loss: 0.1181\n",
      "Epoch [22/50], Step [544/735], Loss: 0.1248\n",
      "Epoch [22/50], Step [545/735], Loss: 0.3158\n",
      "Epoch [22/50], Step [546/735], Loss: 0.5719\n",
      "Epoch [22/50], Step [547/735], Loss: 0.1127\n",
      "Epoch [22/50], Step [548/735], Loss: 0.4168\n",
      "Epoch [22/50], Step [549/735], Loss: 0.3740\n",
      "Epoch [22/50], Step [550/735], Loss: 0.1552\n",
      "Epoch [22/50], Step [551/735], Loss: 0.4284\n",
      "Epoch [22/50], Step [552/735], Loss: 0.2905\n",
      "Epoch [22/50], Step [553/735], Loss: 0.6902\n",
      "Epoch [22/50], Step [554/735], Loss: 0.5447\n",
      "Epoch [22/50], Step [555/735], Loss: 0.2382\n",
      "Epoch [22/50], Step [556/735], Loss: 0.2268\n",
      "Epoch [22/50], Step [557/735], Loss: 0.8304\n",
      "Epoch [22/50], Step [558/735], Loss: 0.6792\n",
      "Epoch [22/50], Step [559/735], Loss: 0.2865\n",
      "Epoch [22/50], Step [560/735], Loss: 0.6323\n",
      "Epoch [22/50], Step [561/735], Loss: 1.4662\n",
      "Epoch [22/50], Step [562/735], Loss: 0.2740\n",
      "Epoch [22/50], Step [563/735], Loss: 1.3023\n",
      "Epoch [22/50], Step [564/735], Loss: 0.2366\n",
      "Epoch [22/50], Step [565/735], Loss: 1.0534\n",
      "Epoch [22/50], Step [566/735], Loss: 0.8624\n",
      "Epoch [22/50], Step [567/735], Loss: 0.2160\n",
      "Epoch [22/50], Step [568/735], Loss: 0.2361\n",
      "Epoch [22/50], Step [569/735], Loss: 0.2308\n",
      "Epoch [22/50], Step [570/735], Loss: 0.2291\n",
      "Epoch [22/50], Step [571/735], Loss: 0.2126\n",
      "Epoch [22/50], Step [572/735], Loss: 0.0892\n",
      "Epoch [22/50], Step [573/735], Loss: 0.0963\n",
      "Epoch [22/50], Step [574/735], Loss: 0.2904\n",
      "Epoch [22/50], Step [575/735], Loss: 0.4565\n",
      "Epoch [22/50], Step [576/735], Loss: 0.5379\n",
      "Epoch [22/50], Step [577/735], Loss: 0.2239\n",
      "Epoch [22/50], Step [578/735], Loss: 0.4183\n",
      "Epoch [22/50], Step [579/735], Loss: 0.1510\n",
      "Epoch [22/50], Step [580/735], Loss: 0.2120\n",
      "Epoch [22/50], Step [581/735], Loss: 0.3265\n",
      "Epoch [22/50], Step [582/735], Loss: 0.3919\n",
      "Epoch [22/50], Step [583/735], Loss: 0.2977\n",
      "Epoch [22/50], Step [584/735], Loss: 0.2573\n",
      "Epoch [22/50], Step [585/735], Loss: 0.2139\n",
      "Epoch [22/50], Step [586/735], Loss: 0.2016\n",
      "Epoch [22/50], Step [587/735], Loss: 0.2682\n",
      "Epoch [22/50], Step [588/735], Loss: 0.2211\n",
      "Epoch [22/50], Step [589/735], Loss: 0.2543\n",
      "Epoch [22/50], Step [590/735], Loss: 0.3137\n",
      "Epoch [22/50], Step [591/735], Loss: 0.2508\n",
      "Epoch [22/50], Step [592/735], Loss: 0.1926\n",
      "Epoch [22/50], Step [593/735], Loss: 1.7556\n",
      "Epoch [22/50], Step [594/735], Loss: 0.8823\n",
      "Epoch [22/50], Step [595/735], Loss: 0.1310\n",
      "Epoch [22/50], Step [596/735], Loss: 0.1807\n",
      "Epoch [22/50], Step [597/735], Loss: 0.1741\n",
      "Epoch [22/50], Step [598/735], Loss: 0.2032\n",
      "Epoch [22/50], Step [599/735], Loss: 0.5126\n",
      "Epoch [22/50], Step [600/735], Loss: 0.2135\n",
      "Epoch [22/50], Step [601/735], Loss: 0.2300\n",
      "Epoch [22/50], Step [602/735], Loss: 0.0468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Step [603/735], Loss: 1.0697\n",
      "Epoch [22/50], Step [604/735], Loss: 0.8256\n",
      "Epoch [22/50], Step [605/735], Loss: 0.5539\n",
      "Epoch [22/50], Step [606/735], Loss: 0.8520\n",
      "Epoch [22/50], Step [607/735], Loss: 5.2197\n",
      "Epoch [22/50], Step [608/735], Loss: 1.4294\n",
      "Epoch [22/50], Step [609/735], Loss: 0.2658\n",
      "Epoch [22/50], Step [610/735], Loss: 0.5458\n",
      "Epoch [22/50], Step [611/735], Loss: 1.2165\n",
      "Epoch [22/50], Step [612/735], Loss: 0.1353\n",
      "Epoch [22/50], Step [613/735], Loss: 0.6866\n",
      "Epoch [22/50], Step [614/735], Loss: 0.4263\n",
      "Epoch [22/50], Step [615/735], Loss: 0.3661\n",
      "Epoch [22/50], Step [616/735], Loss: 0.3155\n",
      "Epoch [22/50], Step [617/735], Loss: 0.1823\n",
      "Epoch [22/50], Step [618/735], Loss: 0.5187\n",
      "Epoch [22/50], Step [619/735], Loss: 0.3084\n",
      "Epoch [22/50], Step [620/735], Loss: 0.5647\n",
      "Epoch [22/50], Step [621/735], Loss: 0.2258\n",
      "Epoch [22/50], Step [622/735], Loss: 0.1756\n",
      "Epoch [22/50], Step [623/735], Loss: 0.1031\n",
      "Epoch [22/50], Step [624/735], Loss: 0.4275\n",
      "Epoch [22/50], Step [625/735], Loss: 0.2735\n",
      "Epoch [22/50], Step [626/735], Loss: 0.4709\n",
      "Epoch [22/50], Step [627/735], Loss: 0.2906\n",
      "Epoch [22/50], Step [628/735], Loss: 0.2796\n",
      "Epoch [22/50], Step [629/735], Loss: 1.6970\n",
      "Epoch [22/50], Step [630/735], Loss: 0.3033\n",
      "Epoch [22/50], Step [631/735], Loss: 0.9834\n",
      "Epoch [22/50], Step [632/735], Loss: 0.3234\n",
      "Epoch [22/50], Step [633/735], Loss: 0.1674\n",
      "Epoch [22/50], Step [634/735], Loss: 0.2369\n",
      "Epoch [22/50], Step [635/735], Loss: 0.9190\n",
      "Epoch [22/50], Step [636/735], Loss: 0.4391\n",
      "Epoch [22/50], Step [637/735], Loss: 0.9551\n",
      "Epoch [22/50], Step [638/735], Loss: 0.2032\n",
      "Epoch [22/50], Step [639/735], Loss: 0.7807\n",
      "Epoch [22/50], Step [640/735], Loss: 0.5340\n",
      "Epoch [22/50], Step [641/735], Loss: 0.2519\n",
      "Epoch [22/50], Step [642/735], Loss: 0.3017\n",
      "Epoch [22/50], Step [643/735], Loss: 0.2059\n",
      "Epoch [22/50], Step [644/735], Loss: 0.1936\n",
      "Epoch [22/50], Step [645/735], Loss: 0.0593\n",
      "Epoch [22/50], Step [646/735], Loss: 0.2694\n",
      "Epoch [22/50], Step [647/735], Loss: 0.4628\n",
      "Epoch [22/50], Step [648/735], Loss: 0.4429\n",
      "Epoch [22/50], Step [649/735], Loss: 0.9477\n",
      "Epoch [22/50], Step [650/735], Loss: 0.0650\n",
      "Epoch [22/50], Step [651/735], Loss: 0.0753\n",
      "Epoch [22/50], Step [652/735], Loss: 0.5303\n",
      "Epoch [22/50], Step [653/735], Loss: 0.3171\n",
      "Epoch [22/50], Step [654/735], Loss: 0.1932\n",
      "Epoch [22/50], Step [655/735], Loss: 0.8881\n",
      "Epoch [22/50], Step [656/735], Loss: 0.2299\n",
      "Epoch [22/50], Step [657/735], Loss: 0.3459\n",
      "Epoch [22/50], Step [658/735], Loss: 0.3858\n",
      "Epoch [22/50], Step [659/735], Loss: 0.2262\n",
      "Epoch [22/50], Step [660/735], Loss: 0.5076\n",
      "Epoch [22/50], Step [661/735], Loss: 0.2549\n",
      "Epoch [22/50], Step [662/735], Loss: 0.1650\n",
      "Epoch [22/50], Step [663/735], Loss: 0.0654\n",
      "Epoch [22/50], Step [664/735], Loss: 0.8988\n",
      "Epoch [22/50], Step [665/735], Loss: 0.6238\n",
      "Epoch [22/50], Step [666/735], Loss: 0.2189\n",
      "Epoch [22/50], Step [667/735], Loss: 0.1829\n",
      "Epoch [22/50], Step [668/735], Loss: 0.1777\n",
      "Epoch [22/50], Step [669/735], Loss: 0.8805\n",
      "Epoch [22/50], Step [670/735], Loss: 0.1932\n",
      "Epoch [22/50], Step [671/735], Loss: 0.1378\n",
      "Epoch [22/50], Step [672/735], Loss: 0.4337\n",
      "Epoch [22/50], Step [673/735], Loss: 0.1310\n",
      "Epoch [22/50], Step [674/735], Loss: 0.1983\n",
      "Epoch [22/50], Step [675/735], Loss: 0.5857\n",
      "Epoch [22/50], Step [676/735], Loss: 0.1753\n",
      "Epoch [22/50], Step [677/735], Loss: 0.1791\n",
      "Epoch [22/50], Step [678/735], Loss: 0.8092\n",
      "Epoch [22/50], Step [679/735], Loss: 0.1748\n",
      "Epoch [22/50], Step [680/735], Loss: 0.3757\n",
      "Epoch [22/50], Step [681/735], Loss: 0.3167\n",
      "Epoch [22/50], Step [682/735], Loss: 0.5402\n",
      "Epoch [22/50], Step [683/735], Loss: 0.2943\n",
      "Epoch [22/50], Step [684/735], Loss: 0.3967\n",
      "Epoch [22/50], Step [685/735], Loss: 0.3637\n",
      "Epoch [22/50], Step [686/735], Loss: 0.2736\n",
      "Epoch [22/50], Step [687/735], Loss: 0.6917\n",
      "Epoch [22/50], Step [688/735], Loss: 0.1359\n",
      "Epoch [22/50], Step [689/735], Loss: 0.2471\n",
      "Epoch [22/50], Step [690/735], Loss: 0.7526\n",
      "Epoch [22/50], Step [691/735], Loss: 0.7374\n",
      "Epoch [22/50], Step [692/735], Loss: 0.0829\n",
      "Epoch [22/50], Step [693/735], Loss: 0.1636\n",
      "Epoch [22/50], Step [694/735], Loss: 0.5195\n",
      "Epoch [22/50], Step [695/735], Loss: 0.1227\n",
      "Epoch [22/50], Step [696/735], Loss: 0.1818\n",
      "Epoch [22/50], Step [697/735], Loss: 0.4356\n",
      "Epoch [22/50], Step [698/735], Loss: 0.0844\n",
      "Epoch [22/50], Step [699/735], Loss: 0.0778\n",
      "Epoch [22/50], Step [700/735], Loss: 0.5930\n",
      "Epoch [22/50], Step [701/735], Loss: 0.1009\n",
      "Epoch [22/50], Step [702/735], Loss: 0.1820\n",
      "Epoch [22/50], Step [703/735], Loss: 0.5839\n",
      "Epoch [22/50], Step [704/735], Loss: 0.3697\n",
      "Epoch [22/50], Step [705/735], Loss: 0.2999\n",
      "Epoch [22/50], Step [706/735], Loss: 0.4506\n",
      "Epoch [22/50], Step [707/735], Loss: 0.2447\n",
      "Epoch [22/50], Step [708/735], Loss: 0.2884\n",
      "Epoch [22/50], Step [709/735], Loss: 0.0599\n",
      "Epoch [22/50], Step [710/735], Loss: 0.2453\n",
      "Epoch [22/50], Step [711/735], Loss: 0.6347\n",
      "Epoch [22/50], Step [712/735], Loss: 0.4269\n",
      "Epoch [22/50], Step [713/735], Loss: 0.3283\n",
      "Epoch [22/50], Step [714/735], Loss: 0.1385\n",
      "Epoch [22/50], Step [715/735], Loss: 0.4585\n",
      "Epoch [22/50], Step [716/735], Loss: 0.1264\n",
      "Epoch [22/50], Step [717/735], Loss: 0.4581\n",
      "Epoch [22/50], Step [718/735], Loss: 0.2531\n",
      "Epoch [22/50], Step [719/735], Loss: 0.4223\n",
      "Epoch [22/50], Step [720/735], Loss: 0.1081\n",
      "Epoch [22/50], Step [721/735], Loss: 0.0790\n",
      "Epoch [22/50], Step [722/735], Loss: 0.6222\n",
      "Epoch [22/50], Step [723/735], Loss: 0.1623\n",
      "Epoch [22/50], Step [724/735], Loss: 0.3933\n",
      "Epoch [22/50], Step [725/735], Loss: 0.6271\n",
      "Epoch [22/50], Step [726/735], Loss: 0.1404\n",
      "Epoch [22/50], Step [727/735], Loss: 0.2023\n",
      "Epoch [22/50], Step [728/735], Loss: 0.3850\n",
      "Epoch [22/50], Step [729/735], Loss: 0.2397\n",
      "Epoch [22/50], Step [730/735], Loss: 0.1125\n",
      "Epoch [22/50], Step [731/735], Loss: 0.2682\n",
      "Epoch [22/50], Step [732/735], Loss: 0.1138\n",
      "Epoch [22/50], Step [733/735], Loss: 0.0704\n",
      "Epoch [22/50], Step [734/735], Loss: 0.2574\n",
      "Epoch [22/50], Step [735/735], Loss: 0.0855\n",
      "Epoch [23/50], Step [1/735], Loss: 0.5740\n",
      "Epoch [23/50], Step [2/735], Loss: 0.7469\n",
      "Epoch [23/50], Step [3/735], Loss: 0.1541\n",
      "Epoch [23/50], Step [4/735], Loss: 0.1389\n",
      "Epoch [23/50], Step [5/735], Loss: 0.2073\n",
      "Epoch [23/50], Step [6/735], Loss: 0.1927\n",
      "Epoch [23/50], Step [7/735], Loss: 0.1564\n",
      "Epoch [23/50], Step [8/735], Loss: 0.2759\n",
      "Epoch [23/50], Step [9/735], Loss: 1.2946\n",
      "Epoch [23/50], Step [10/735], Loss: 0.2330\n",
      "Epoch [23/50], Step [11/735], Loss: 0.1545\n",
      "Epoch [23/50], Step [12/735], Loss: 0.1781\n",
      "Epoch [23/50], Step [13/735], Loss: 0.1176\n",
      "Epoch [23/50], Step [14/735], Loss: 0.2858\n",
      "Epoch [23/50], Step [15/735], Loss: 0.4595\n",
      "Epoch [23/50], Step [16/735], Loss: 0.7994\n",
      "Epoch [23/50], Step [17/735], Loss: 0.3436\n",
      "Epoch [23/50], Step [18/735], Loss: 0.4253\n",
      "Epoch [23/50], Step [19/735], Loss: 0.2730\n",
      "Epoch [23/50], Step [20/735], Loss: 0.0946\n",
      "Epoch [23/50], Step [21/735], Loss: 0.1779\n",
      "Epoch [23/50], Step [22/735], Loss: 0.2219\n",
      "Epoch [23/50], Step [23/735], Loss: 0.1509\n",
      "Epoch [23/50], Step [24/735], Loss: 1.1624\n",
      "Epoch [23/50], Step [25/735], Loss: 0.1910\n",
      "Epoch [23/50], Step [26/735], Loss: 0.1501\n",
      "Epoch [23/50], Step [27/735], Loss: 0.1154\n",
      "Epoch [23/50], Step [28/735], Loss: 0.4975\n",
      "Epoch [23/50], Step [29/735], Loss: 0.1404\n",
      "Epoch [23/50], Step [30/735], Loss: 0.0860\n",
      "Epoch [23/50], Step [31/735], Loss: 0.6250\n",
      "Epoch [23/50], Step [32/735], Loss: 0.7282\n",
      "Epoch [23/50], Step [33/735], Loss: 0.5475\n",
      "Epoch [23/50], Step [34/735], Loss: 0.1527\n",
      "Epoch [23/50], Step [35/735], Loss: 0.5688\n",
      "Epoch [23/50], Step [36/735], Loss: 0.3758\n",
      "Epoch [23/50], Step [37/735], Loss: 0.1925\n",
      "Epoch [23/50], Step [38/735], Loss: 0.3546\n",
      "Epoch [23/50], Step [39/735], Loss: 0.5235\n",
      "Epoch [23/50], Step [40/735], Loss: 0.3607\n",
      "Epoch [23/50], Step [41/735], Loss: 0.7086\n",
      "Epoch [23/50], Step [42/735], Loss: 0.2766\n",
      "Epoch [23/50], Step [43/735], Loss: 0.3627\n",
      "Epoch [23/50], Step [44/735], Loss: 0.0736\n",
      "Epoch [23/50], Step [45/735], Loss: 0.1172\n",
      "Epoch [23/50], Step [46/735], Loss: 0.9213\n",
      "Epoch [23/50], Step [47/735], Loss: 0.2065\n",
      "Epoch [23/50], Step [48/735], Loss: 1.5790\n",
      "Epoch [23/50], Step [49/735], Loss: 0.1161\n",
      "Epoch [23/50], Step [50/735], Loss: 0.2681\n",
      "Epoch [23/50], Step [51/735], Loss: 0.7274\n",
      "Epoch [23/50], Step [52/735], Loss: 0.5989\n",
      "Epoch [23/50], Step [53/735], Loss: 0.3394\n",
      "Epoch [23/50], Step [54/735], Loss: 0.4174\n",
      "Epoch [23/50], Step [55/735], Loss: 0.7804\n",
      "Epoch [23/50], Step [56/735], Loss: 1.2200\n",
      "Epoch [23/50], Step [57/735], Loss: 0.1077\n",
      "Epoch [23/50], Step [58/735], Loss: 0.1763\n",
      "Epoch [23/50], Step [59/735], Loss: 0.1557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Step [60/735], Loss: 0.4189\n",
      "Epoch [23/50], Step [61/735], Loss: 0.1634\n",
      "Epoch [23/50], Step [62/735], Loss: 0.4892\n",
      "Epoch [23/50], Step [63/735], Loss: 0.4989\n",
      "Epoch [23/50], Step [64/735], Loss: 0.1894\n",
      "Epoch [23/50], Step [65/735], Loss: 0.1631\n",
      "Epoch [23/50], Step [66/735], Loss: 0.5294\n",
      "Epoch [23/50], Step [67/735], Loss: 0.2330\n",
      "Epoch [23/50], Step [68/735], Loss: 0.1045\n",
      "Epoch [23/50], Step [69/735], Loss: 0.2994\n",
      "Epoch [23/50], Step [70/735], Loss: 0.4972\n",
      "Epoch [23/50], Step [71/735], Loss: 4.6845\n",
      "Epoch [23/50], Step [72/735], Loss: 0.3778\n",
      "Epoch [23/50], Step [73/735], Loss: 0.1144\n",
      "Epoch [23/50], Step [74/735], Loss: 0.6543\n",
      "Epoch [23/50], Step [75/735], Loss: 0.0788\n",
      "Epoch [23/50], Step [76/735], Loss: 0.4028\n",
      "Epoch [23/50], Step [77/735], Loss: 0.4917\n",
      "Epoch [23/50], Step [78/735], Loss: 0.3977\n",
      "Epoch [23/50], Step [79/735], Loss: 0.2669\n",
      "Epoch [23/50], Step [80/735], Loss: 0.1434\n",
      "Epoch [23/50], Step [81/735], Loss: 0.6977\n",
      "Epoch [23/50], Step [82/735], Loss: 0.6658\n",
      "Epoch [23/50], Step [83/735], Loss: 0.9165\n",
      "Epoch [23/50], Step [84/735], Loss: 0.1539\n",
      "Epoch [23/50], Step [85/735], Loss: 0.3951\n",
      "Epoch [23/50], Step [86/735], Loss: 0.3265\n",
      "Epoch [23/50], Step [87/735], Loss: 0.5980\n",
      "Epoch [23/50], Step [88/735], Loss: 0.1929\n",
      "Epoch [23/50], Step [89/735], Loss: 0.2868\n",
      "Epoch [23/50], Step [90/735], Loss: 0.3152\n",
      "Epoch [23/50], Step [91/735], Loss: 0.4223\n",
      "Epoch [23/50], Step [92/735], Loss: 0.2628\n",
      "Epoch [23/50], Step [93/735], Loss: 0.2547\n",
      "Epoch [23/50], Step [94/735], Loss: 0.3896\n",
      "Epoch [23/50], Step [95/735], Loss: 0.2524\n",
      "Epoch [23/50], Step [96/735], Loss: 0.4488\n",
      "Epoch [23/50], Step [97/735], Loss: 0.2704\n",
      "Epoch [23/50], Step [98/735], Loss: 0.7201\n",
      "Epoch [23/50], Step [99/735], Loss: 1.3851\n",
      "Epoch [23/50], Step [100/735], Loss: 0.1660\n",
      "Epoch [23/50], Step [101/735], Loss: 0.1489\n",
      "Epoch [23/50], Step [102/735], Loss: 0.2453\n",
      "Epoch [23/50], Step [103/735], Loss: 0.3456\n",
      "Epoch [23/50], Step [104/735], Loss: 0.1141\n",
      "Epoch [23/50], Step [105/735], Loss: 4.3635\n",
      "Epoch [23/50], Step [106/735], Loss: 0.2844\n",
      "Epoch [23/50], Step [107/735], Loss: 0.8019\n",
      "Epoch [23/50], Step [108/735], Loss: 0.1398\n",
      "Epoch [23/50], Step [109/735], Loss: 0.4833\n",
      "Epoch [23/50], Step [110/735], Loss: 0.7191\n",
      "Epoch [23/50], Step [111/735], Loss: 0.3652\n",
      "Epoch [23/50], Step [112/735], Loss: 0.5562\n",
      "Epoch [23/50], Step [113/735], Loss: 0.3344\n",
      "Epoch [23/50], Step [114/735], Loss: 0.5860\n",
      "Epoch [23/50], Step [115/735], Loss: 0.1828\n",
      "Epoch [23/50], Step [116/735], Loss: 0.3640\n",
      "Epoch [23/50], Step [117/735], Loss: 0.5523\n",
      "Epoch [23/50], Step [118/735], Loss: 0.3206\n",
      "Epoch [23/50], Step [119/735], Loss: 0.9892\n",
      "Epoch [23/50], Step [120/735], Loss: 0.1838\n",
      "Epoch [23/50], Step [121/735], Loss: 0.3126\n",
      "Epoch [23/50], Step [122/735], Loss: 0.4769\n",
      "Epoch [23/50], Step [123/735], Loss: 0.6669\n",
      "Epoch [23/50], Step [124/735], Loss: 0.4135\n",
      "Epoch [23/50], Step [125/735], Loss: 0.3898\n",
      "Epoch [23/50], Step [126/735], Loss: 0.7036\n",
      "Epoch [23/50], Step [127/735], Loss: 0.2845\n",
      "Epoch [23/50], Step [128/735], Loss: 0.1414\n",
      "Epoch [23/50], Step [129/735], Loss: 0.2060\n",
      "Epoch [23/50], Step [130/735], Loss: 0.4448\n",
      "Epoch [23/50], Step [131/735], Loss: 0.3608\n",
      "Epoch [23/50], Step [132/735], Loss: 0.1840\n",
      "Epoch [23/50], Step [133/735], Loss: 0.1668\n",
      "Epoch [23/50], Step [134/735], Loss: 0.2113\n",
      "Epoch [23/50], Step [135/735], Loss: 0.8916\n",
      "Epoch [23/50], Step [136/735], Loss: 0.9390\n",
      "Epoch [23/50], Step [137/735], Loss: 0.3750\n",
      "Epoch [23/50], Step [138/735], Loss: 0.7481\n",
      "Epoch [23/50], Step [139/735], Loss: 0.7036\n",
      "Epoch [23/50], Step [140/735], Loss: 0.1298\n",
      "Epoch [23/50], Step [141/735], Loss: 0.2800\n",
      "Epoch [23/50], Step [142/735], Loss: 0.9222\n",
      "Epoch [23/50], Step [143/735], Loss: 0.2466\n",
      "Epoch [23/50], Step [144/735], Loss: 0.5566\n",
      "Epoch [23/50], Step [145/735], Loss: 0.6035\n",
      "Epoch [23/50], Step [146/735], Loss: 0.2396\n",
      "Epoch [23/50], Step [147/735], Loss: 0.4368\n",
      "Epoch [23/50], Step [148/735], Loss: 0.1446\n",
      "Epoch [23/50], Step [149/735], Loss: 0.0781\n",
      "Epoch [23/50], Step [150/735], Loss: 0.3738\n",
      "Epoch [23/50], Step [151/735], Loss: 0.3386\n",
      "Epoch [23/50], Step [152/735], Loss: 0.1246\n",
      "Epoch [23/50], Step [153/735], Loss: 0.6023\n",
      "Epoch [23/50], Step [154/735], Loss: 0.7458\n",
      "Epoch [23/50], Step [155/735], Loss: 0.3518\n",
      "Epoch [23/50], Step [156/735], Loss: 0.3551\n",
      "Epoch [23/50], Step [157/735], Loss: 0.2071\n",
      "Epoch [23/50], Step [158/735], Loss: 0.1083\n",
      "Epoch [23/50], Step [159/735], Loss: 0.1468\n",
      "Epoch [23/50], Step [160/735], Loss: 0.4061\n",
      "Epoch [23/50], Step [161/735], Loss: 0.1757\n",
      "Epoch [23/50], Step [162/735], Loss: 0.4039\n",
      "Epoch [23/50], Step [163/735], Loss: 0.7077\n",
      "Epoch [23/50], Step [164/735], Loss: 0.1180\n",
      "Epoch [23/50], Step [165/735], Loss: 1.8388\n",
      "Epoch [23/50], Step [166/735], Loss: 0.3166\n",
      "Epoch [23/50], Step [167/735], Loss: 0.0868\n",
      "Epoch [23/50], Step [168/735], Loss: 0.1172\n",
      "Epoch [23/50], Step [169/735], Loss: 0.0773\n",
      "Epoch [23/50], Step [170/735], Loss: 0.0818\n",
      "Epoch [23/50], Step [171/735], Loss: 0.2152\n",
      "Epoch [23/50], Step [172/735], Loss: 0.3044\n",
      "Epoch [23/50], Step [173/735], Loss: 0.4916\n",
      "Epoch [23/50], Step [174/735], Loss: 0.1621\n",
      "Epoch [23/50], Step [175/735], Loss: 0.3449\n",
      "Epoch [23/50], Step [176/735], Loss: 0.2076\n",
      "Epoch [23/50], Step [177/735], Loss: 0.2403\n",
      "Epoch [23/50], Step [178/735], Loss: 0.8549\n",
      "Epoch [23/50], Step [179/735], Loss: 0.2015\n",
      "Epoch [23/50], Step [180/735], Loss: 0.1654\n",
      "Epoch [23/50], Step [181/735], Loss: 0.1616\n",
      "Epoch [23/50], Step [182/735], Loss: 0.3244\n",
      "Epoch [23/50], Step [183/735], Loss: 0.6431\n",
      "Epoch [23/50], Step [184/735], Loss: 0.1635\n",
      "Epoch [23/50], Step [185/735], Loss: 0.4123\n",
      "Epoch [23/50], Step [186/735], Loss: 0.0877\n",
      "Epoch [23/50], Step [187/735], Loss: 0.1023\n",
      "Epoch [23/50], Step [188/735], Loss: 0.2178\n",
      "Epoch [23/50], Step [189/735], Loss: 0.0609\n",
      "Epoch [23/50], Step [190/735], Loss: 0.7238\n",
      "Epoch [23/50], Step [191/735], Loss: 0.1229\n",
      "Epoch [23/50], Step [192/735], Loss: 0.3944\n",
      "Epoch [23/50], Step [193/735], Loss: 0.1132\n",
      "Epoch [23/50], Step [194/735], Loss: 0.1216\n",
      "Epoch [23/50], Step [195/735], Loss: 1.5013\n",
      "Epoch [23/50], Step [196/735], Loss: 1.0363\n",
      "Epoch [23/50], Step [197/735], Loss: 0.6736\n",
      "Epoch [23/50], Step [198/735], Loss: 0.2434\n",
      "Epoch [23/50], Step [199/735], Loss: 0.5593\n",
      "Epoch [23/50], Step [200/735], Loss: 0.3889\n",
      "Epoch [23/50], Step [201/735], Loss: 0.5824\n",
      "Epoch [23/50], Step [202/735], Loss: 0.4025\n",
      "Epoch [23/50], Step [203/735], Loss: 0.2826\n",
      "Epoch [23/50], Step [204/735], Loss: 0.4109\n",
      "Epoch [23/50], Step [205/735], Loss: 0.0648\n",
      "Epoch [23/50], Step [206/735], Loss: 0.1790\n",
      "Epoch [23/50], Step [207/735], Loss: 0.4904\n",
      "Epoch [23/50], Step [208/735], Loss: 0.3260\n",
      "Epoch [23/50], Step [209/735], Loss: 0.2094\n",
      "Epoch [23/50], Step [210/735], Loss: 0.2074\n",
      "Epoch [23/50], Step [211/735], Loss: 0.7192\n",
      "Epoch [23/50], Step [212/735], Loss: 0.2977\n",
      "Epoch [23/50], Step [213/735], Loss: 0.0583\n",
      "Epoch [23/50], Step [214/735], Loss: 0.1731\n",
      "Epoch [23/50], Step [215/735], Loss: 0.4677\n",
      "Epoch [23/50], Step [216/735], Loss: 0.1399\n",
      "Epoch [23/50], Step [217/735], Loss: 0.4285\n",
      "Epoch [23/50], Step [218/735], Loss: 0.6637\n",
      "Epoch [23/50], Step [219/735], Loss: 0.1372\n",
      "Epoch [23/50], Step [220/735], Loss: 0.3502\n",
      "Epoch [23/50], Step [221/735], Loss: 0.3874\n",
      "Epoch [23/50], Step [222/735], Loss: 0.0819\n",
      "Epoch [23/50], Step [223/735], Loss: 0.0812\n",
      "Epoch [23/50], Step [224/735], Loss: 0.2373\n",
      "Epoch [23/50], Step [225/735], Loss: 0.1769\n",
      "Epoch [23/50], Step [226/735], Loss: 0.2360\n",
      "Epoch [23/50], Step [227/735], Loss: 0.2965\n",
      "Epoch [23/50], Step [228/735], Loss: 0.3311\n",
      "Epoch [23/50], Step [229/735], Loss: 0.0631\n",
      "Epoch [23/50], Step [230/735], Loss: 0.5108\n",
      "Epoch [23/50], Step [231/735], Loss: 0.3830\n",
      "Epoch [23/50], Step [232/735], Loss: 0.7402\n",
      "Epoch [23/50], Step [233/735], Loss: 0.1982\n",
      "Epoch [23/50], Step [234/735], Loss: 0.6223\n",
      "Epoch [23/50], Step [235/735], Loss: 0.3187\n",
      "Epoch [23/50], Step [236/735], Loss: 0.4961\n",
      "Epoch [23/50], Step [237/735], Loss: 0.1549\n",
      "Epoch [23/50], Step [238/735], Loss: 0.0766\n",
      "Epoch [23/50], Step [239/735], Loss: 1.1512\n",
      "Epoch [23/50], Step [240/735], Loss: 0.4785\n",
      "Epoch [23/50], Step [241/735], Loss: 0.3592\n",
      "Epoch [23/50], Step [242/735], Loss: 0.4462\n",
      "Epoch [23/50], Step [243/735], Loss: 0.1081\n",
      "Epoch [23/50], Step [244/735], Loss: 0.4064\n",
      "Epoch [23/50], Step [245/735], Loss: 0.9648\n",
      "Epoch [23/50], Step [246/735], Loss: 0.3165\n",
      "Epoch [23/50], Step [247/735], Loss: 0.5743\n",
      "Epoch [23/50], Step [248/735], Loss: 0.3147\n",
      "Epoch [23/50], Step [249/735], Loss: 0.3375\n",
      "Epoch [23/50], Step [250/735], Loss: 1.6323\n",
      "Epoch [23/50], Step [251/735], Loss: 0.1582\n",
      "Epoch [23/50], Step [252/735], Loss: 0.2220\n",
      "Epoch [23/50], Step [253/735], Loss: 0.0591\n",
      "Epoch [23/50], Step [254/735], Loss: 0.1471\n",
      "Epoch [23/50], Step [255/735], Loss: 0.7530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Step [256/735], Loss: 0.6821\n",
      "Epoch [23/50], Step [257/735], Loss: 1.2797\n",
      "Epoch [23/50], Step [258/735], Loss: 1.0369\n",
      "Epoch [23/50], Step [259/735], Loss: 0.0703\n",
      "Epoch [23/50], Step [260/735], Loss: 1.0945\n",
      "Epoch [23/50], Step [261/735], Loss: 0.9130\n",
      "Epoch [23/50], Step [262/735], Loss: 0.2841\n",
      "Epoch [23/50], Step [263/735], Loss: 0.2319\n",
      "Epoch [23/50], Step [264/735], Loss: 0.1352\n",
      "Epoch [23/50], Step [265/735], Loss: 0.1633\n",
      "Epoch [23/50], Step [266/735], Loss: 0.5291\n",
      "Epoch [23/50], Step [267/735], Loss: 0.6995\n",
      "Epoch [23/50], Step [268/735], Loss: 0.0892\n",
      "Epoch [23/50], Step [269/735], Loss: 0.1830\n",
      "Epoch [23/50], Step [270/735], Loss: 0.4414\n",
      "Epoch [23/50], Step [271/735], Loss: 0.4616\n",
      "Epoch [23/50], Step [272/735], Loss: 0.2359\n",
      "Epoch [23/50], Step [273/735], Loss: 0.2117\n",
      "Epoch [23/50], Step [274/735], Loss: 0.1405\n",
      "Epoch [23/50], Step [275/735], Loss: 0.4845\n",
      "Epoch [23/50], Step [276/735], Loss: 0.6766\n",
      "Epoch [23/50], Step [277/735], Loss: 0.2119\n",
      "Epoch [23/50], Step [278/735], Loss: 0.2934\n",
      "Epoch [23/50], Step [279/735], Loss: 0.4021\n",
      "Epoch [23/50], Step [280/735], Loss: 0.1361\n",
      "Epoch [23/50], Step [281/735], Loss: 0.3030\n",
      "Epoch [23/50], Step [282/735], Loss: 1.4149\n",
      "Epoch [23/50], Step [283/735], Loss: 0.4104\n",
      "Epoch [23/50], Step [284/735], Loss: 0.1119\n",
      "Epoch [23/50], Step [285/735], Loss: 0.2553\n",
      "Epoch [23/50], Step [286/735], Loss: 0.5444\n",
      "Epoch [23/50], Step [287/735], Loss: 0.2072\n",
      "Epoch [23/50], Step [288/735], Loss: 0.1811\n",
      "Epoch [23/50], Step [289/735], Loss: 0.0500\n",
      "Epoch [23/50], Step [290/735], Loss: 0.2815\n",
      "Epoch [23/50], Step [291/735], Loss: 0.2038\n",
      "Epoch [23/50], Step [292/735], Loss: 0.3794\n",
      "Epoch [23/50], Step [293/735], Loss: 0.4070\n",
      "Epoch [23/50], Step [294/735], Loss: 0.7419\n",
      "Epoch [23/50], Step [295/735], Loss: 0.2705\n",
      "Epoch [23/50], Step [296/735], Loss: 0.5290\n",
      "Epoch [23/50], Step [297/735], Loss: 0.4046\n",
      "Epoch [23/50], Step [298/735], Loss: 0.1139\n",
      "Epoch [23/50], Step [299/735], Loss: 0.4042\n",
      "Epoch [23/50], Step [300/735], Loss: 0.2218\n",
      "Epoch [23/50], Step [301/735], Loss: 0.3719\n",
      "Epoch [23/50], Step [302/735], Loss: 0.2370\n",
      "Epoch [23/50], Step [303/735], Loss: 0.1692\n",
      "Epoch [23/50], Step [304/735], Loss: 0.3853\n",
      "Epoch [23/50], Step [305/735], Loss: 0.2693\n",
      "Epoch [23/50], Step [306/735], Loss: 0.2570\n",
      "Epoch [23/50], Step [307/735], Loss: 0.3263\n",
      "Epoch [23/50], Step [308/735], Loss: 0.5133\n",
      "Epoch [23/50], Step [309/735], Loss: 0.6629\n",
      "Epoch [23/50], Step [310/735], Loss: 0.5434\n",
      "Epoch [23/50], Step [311/735], Loss: 0.5131\n",
      "Epoch [23/50], Step [312/735], Loss: 0.1019\n",
      "Epoch [23/50], Step [313/735], Loss: 0.5735\n",
      "Epoch [23/50], Step [314/735], Loss: 0.1109\n",
      "Epoch [23/50], Step [315/735], Loss: 0.2664\n",
      "Epoch [23/50], Step [316/735], Loss: 0.1999\n",
      "Epoch [23/50], Step [317/735], Loss: 0.6143\n",
      "Epoch [23/50], Step [318/735], Loss: 0.3322\n",
      "Epoch [23/50], Step [319/735], Loss: 0.6891\n",
      "Epoch [23/50], Step [320/735], Loss: 0.1476\n",
      "Epoch [23/50], Step [321/735], Loss: 5.2624\n",
      "Epoch [23/50], Step [322/735], Loss: 1.0401\n",
      "Epoch [23/50], Step [323/735], Loss: 0.1300\n",
      "Epoch [23/50], Step [324/735], Loss: 0.1177\n",
      "Epoch [23/50], Step [325/735], Loss: 0.4535\n",
      "Epoch [23/50], Step [326/735], Loss: 0.5131\n",
      "Epoch [23/50], Step [327/735], Loss: 0.4336\n",
      "Epoch [23/50], Step [328/735], Loss: 0.0772\n",
      "Epoch [23/50], Step [329/735], Loss: 0.8219\n",
      "Epoch [23/50], Step [330/735], Loss: 0.1243\n",
      "Epoch [23/50], Step [331/735], Loss: 0.4174\n",
      "Epoch [23/50], Step [332/735], Loss: 0.1977\n",
      "Epoch [23/50], Step [333/735], Loss: 0.5705\n",
      "Epoch [23/50], Step [334/735], Loss: 0.3500\n",
      "Epoch [23/50], Step [335/735], Loss: 0.1323\n",
      "Epoch [23/50], Step [336/735], Loss: 0.2673\n",
      "Epoch [23/50], Step [337/735], Loss: 0.3356\n",
      "Epoch [23/50], Step [338/735], Loss: 0.1976\n",
      "Epoch [23/50], Step [339/735], Loss: 0.1774\n",
      "Epoch [23/50], Step [340/735], Loss: 0.3589\n",
      "Epoch [23/50], Step [341/735], Loss: 0.3068\n",
      "Epoch [23/50], Step [342/735], Loss: 1.1828\n",
      "Epoch [23/50], Step [343/735], Loss: 0.1914\n",
      "Epoch [23/50], Step [344/735], Loss: 0.1744\n",
      "Epoch [23/50], Step [345/735], Loss: 0.6933\n",
      "Epoch [23/50], Step [346/735], Loss: 0.1194\n",
      "Epoch [23/50], Step [347/735], Loss: 0.3175\n",
      "Epoch [23/50], Step [348/735], Loss: 0.3285\n",
      "Epoch [23/50], Step [349/735], Loss: 0.3589\n",
      "Epoch [23/50], Step [350/735], Loss: 0.2379\n",
      "Epoch [23/50], Step [351/735], Loss: 0.6780\n",
      "Epoch [23/50], Step [352/735], Loss: 0.2712\n",
      "Epoch [23/50], Step [353/735], Loss: 0.2804\n",
      "Epoch [23/50], Step [354/735], Loss: 0.3839\n",
      "Epoch [23/50], Step [355/735], Loss: 0.1937\n",
      "Epoch [23/50], Step [356/735], Loss: 1.5348\n",
      "Epoch [23/50], Step [357/735], Loss: 0.3737\n",
      "Epoch [23/50], Step [358/735], Loss: 1.0164\n",
      "Epoch [23/50], Step [359/735], Loss: 0.6422\n",
      "Epoch [23/50], Step [360/735], Loss: 0.9529\n",
      "Epoch [23/50], Step [361/735], Loss: 0.4365\n",
      "Epoch [23/50], Step [362/735], Loss: 0.4107\n",
      "Epoch [23/50], Step [363/735], Loss: 0.2170\n",
      "Epoch [23/50], Step [364/735], Loss: 0.1753\n",
      "Epoch [23/50], Step [365/735], Loss: 0.1759\n",
      "Epoch [23/50], Step [366/735], Loss: 1.1074\n",
      "Epoch [23/50], Step [367/735], Loss: 0.4399\n",
      "Epoch [23/50], Step [368/735], Loss: 0.2590\n",
      "Epoch [23/50], Step [369/735], Loss: 0.8679\n",
      "Epoch [23/50], Step [370/735], Loss: 0.1107\n",
      "Epoch [23/50], Step [371/735], Loss: 0.6488\n",
      "Epoch [23/50], Step [372/735], Loss: 0.3172\n",
      "Epoch [23/50], Step [373/735], Loss: 0.2357\n",
      "Epoch [23/50], Step [374/735], Loss: 0.6565\n",
      "Epoch [23/50], Step [375/735], Loss: 0.2992\n",
      "Epoch [23/50], Step [376/735], Loss: 0.1958\n",
      "Epoch [23/50], Step [377/735], Loss: 2.2597\n",
      "Epoch [23/50], Step [378/735], Loss: 1.1353\n",
      "Epoch [23/50], Step [379/735], Loss: 0.1408\n",
      "Epoch [23/50], Step [380/735], Loss: 0.5694\n",
      "Epoch [23/50], Step [381/735], Loss: 0.4176\n",
      "Epoch [23/50], Step [382/735], Loss: 0.1463\n",
      "Epoch [23/50], Step [383/735], Loss: 0.2643\n",
      "Epoch [23/50], Step [384/735], Loss: 0.8126\n",
      "Epoch [23/50], Step [385/735], Loss: 0.3429\n",
      "Epoch [23/50], Step [386/735], Loss: 1.4784\n",
      "Epoch [23/50], Step [387/735], Loss: 0.8376\n",
      "Epoch [23/50], Step [388/735], Loss: 0.3186\n",
      "Epoch [23/50], Step [389/735], Loss: 0.1253\n",
      "Epoch [23/50], Step [390/735], Loss: 0.3673\n",
      "Epoch [23/50], Step [391/735], Loss: 0.1716\n",
      "Epoch [23/50], Step [392/735], Loss: 0.3728\n",
      "Epoch [23/50], Step [393/735], Loss: 0.1369\n",
      "Epoch [23/50], Step [394/735], Loss: 0.7709\n",
      "Epoch [23/50], Step [395/735], Loss: 0.1802\n",
      "Epoch [23/50], Step [396/735], Loss: 0.1911\n",
      "Epoch [23/50], Step [397/735], Loss: 0.6126\n",
      "Epoch [23/50], Step [398/735], Loss: 0.0771\n",
      "Epoch [23/50], Step [399/735], Loss: 0.4457\n",
      "Epoch [23/50], Step [400/735], Loss: 0.1634\n",
      "Epoch [23/50], Step [401/735], Loss: 0.1741\n",
      "Epoch [23/50], Step [402/735], Loss: 0.4196\n",
      "Epoch [23/50], Step [403/735], Loss: 0.7318\n",
      "Epoch [23/50], Step [404/735], Loss: 0.1619\n",
      "Epoch [23/50], Step [405/735], Loss: 0.1973\n",
      "Epoch [23/50], Step [406/735], Loss: 0.1675\n",
      "Epoch [23/50], Step [407/735], Loss: 0.2327\n",
      "Epoch [23/50], Step [408/735], Loss: 0.7993\n",
      "Epoch [23/50], Step [409/735], Loss: 0.1877\n",
      "Epoch [23/50], Step [410/735], Loss: 0.2054\n",
      "Epoch [23/50], Step [411/735], Loss: 0.3137\n",
      "Epoch [23/50], Step [412/735], Loss: 0.4198\n",
      "Epoch [23/50], Step [413/735], Loss: 0.5628\n",
      "Epoch [23/50], Step [414/735], Loss: 0.3023\n",
      "Epoch [23/50], Step [415/735], Loss: 0.7368\n",
      "Epoch [23/50], Step [416/735], Loss: 0.4820\n",
      "Epoch [23/50], Step [417/735], Loss: 0.7568\n",
      "Epoch [23/50], Step [418/735], Loss: 0.2332\n",
      "Epoch [23/50], Step [419/735], Loss: 0.1910\n",
      "Epoch [23/50], Step [420/735], Loss: 0.1832\n",
      "Epoch [23/50], Step [421/735], Loss: 0.4064\n",
      "Epoch [23/50], Step [422/735], Loss: 0.3882\n",
      "Epoch [23/50], Step [423/735], Loss: 0.2161\n",
      "Epoch [23/50], Step [424/735], Loss: 0.2773\n",
      "Epoch [23/50], Step [425/735], Loss: 0.5264\n",
      "Epoch [23/50], Step [426/735], Loss: 0.3198\n",
      "Epoch [23/50], Step [427/735], Loss: 0.3197\n",
      "Epoch [23/50], Step [428/735], Loss: 0.1092\n",
      "Epoch [23/50], Step [429/735], Loss: 0.3412\n",
      "Epoch [23/50], Step [430/735], Loss: 0.5230\n",
      "Epoch [23/50], Step [431/735], Loss: 0.8076\n",
      "Epoch [23/50], Step [432/735], Loss: 0.3891\n",
      "Epoch [23/50], Step [433/735], Loss: 0.2078\n",
      "Epoch [23/50], Step [434/735], Loss: 0.8893\n",
      "Epoch [23/50], Step [435/735], Loss: 0.0864\n",
      "Epoch [23/50], Step [436/735], Loss: 0.5055\n",
      "Epoch [23/50], Step [437/735], Loss: 0.1240\n",
      "Epoch [23/50], Step [438/735], Loss: 0.2127\n",
      "Epoch [23/50], Step [439/735], Loss: 0.6384\n",
      "Epoch [23/50], Step [440/735], Loss: 0.2374\n",
      "Epoch [23/50], Step [441/735], Loss: 0.1602\n",
      "Epoch [23/50], Step [442/735], Loss: 0.2439\n",
      "Epoch [23/50], Step [443/735], Loss: 1.3357\n",
      "Epoch [23/50], Step [444/735], Loss: 0.1428\n",
      "Epoch [23/50], Step [445/735], Loss: 0.1721\n",
      "Epoch [23/50], Step [446/735], Loss: 0.1986\n",
      "Epoch [23/50], Step [447/735], Loss: 0.1472\n",
      "Epoch [23/50], Step [448/735], Loss: 0.1695\n",
      "Epoch [23/50], Step [449/735], Loss: 1.5533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Step [450/735], Loss: 0.0936\n",
      "Epoch [23/50], Step [451/735], Loss: 0.2883\n",
      "Epoch [23/50], Step [452/735], Loss: 0.2190\n",
      "Epoch [23/50], Step [453/735], Loss: 0.3530\n",
      "Epoch [23/50], Step [454/735], Loss: 0.9704\n",
      "Epoch [23/50], Step [455/735], Loss: 0.1805\n",
      "Epoch [23/50], Step [456/735], Loss: 0.5099\n",
      "Epoch [23/50], Step [457/735], Loss: 0.1334\n",
      "Epoch [23/50], Step [458/735], Loss: 0.2146\n",
      "Epoch [23/50], Step [459/735], Loss: 0.3303\n",
      "Epoch [23/50], Step [460/735], Loss: 0.8232\n",
      "Epoch [23/50], Step [461/735], Loss: 0.3781\n",
      "Epoch [23/50], Step [462/735], Loss: 0.2195\n",
      "Epoch [23/50], Step [463/735], Loss: 0.0813\n",
      "Epoch [23/50], Step [464/735], Loss: 0.5588\n",
      "Epoch [23/50], Step [465/735], Loss: 0.2148\n",
      "Epoch [23/50], Step [466/735], Loss: 0.3999\n",
      "Epoch [23/50], Step [467/735], Loss: 0.3909\n",
      "Epoch [23/50], Step [468/735], Loss: 1.3015\n",
      "Epoch [23/50], Step [469/735], Loss: 0.2382\n",
      "Epoch [23/50], Step [470/735], Loss: 0.2648\n",
      "Epoch [23/50], Step [471/735], Loss: 0.0944\n",
      "Epoch [23/50], Step [472/735], Loss: 0.2397\n",
      "Epoch [23/50], Step [473/735], Loss: 0.3567\n",
      "Epoch [23/50], Step [474/735], Loss: 0.7848\n",
      "Epoch [23/50], Step [475/735], Loss: 0.1192\n",
      "Epoch [23/50], Step [476/735], Loss: 1.7850\n",
      "Epoch [23/50], Step [477/735], Loss: 0.2789\n",
      "Epoch [23/50], Step [478/735], Loss: 0.1678\n",
      "Epoch [23/50], Step [479/735], Loss: 1.0544\n",
      "Epoch [23/50], Step [480/735], Loss: 0.0902\n",
      "Epoch [23/50], Step [481/735], Loss: 0.2654\n",
      "Epoch [23/50], Step [482/735], Loss: 0.2755\n",
      "Epoch [23/50], Step [483/735], Loss: 0.2092\n",
      "Epoch [23/50], Step [484/735], Loss: 0.1043\n",
      "Epoch [23/50], Step [485/735], Loss: 0.1361\n",
      "Epoch [23/50], Step [486/735], Loss: 0.1837\n",
      "Epoch [23/50], Step [487/735], Loss: 0.7930\n",
      "Epoch [23/50], Step [488/735], Loss: 0.2251\n",
      "Epoch [23/50], Step [489/735], Loss: 1.6098\n",
      "Epoch [23/50], Step [490/735], Loss: 0.2833\n",
      "Epoch [23/50], Step [491/735], Loss: 0.2215\n",
      "Epoch [23/50], Step [492/735], Loss: 0.6776\n",
      "Epoch [23/50], Step [493/735], Loss: 0.5721\n",
      "Epoch [23/50], Step [494/735], Loss: 0.1957\n",
      "Epoch [23/50], Step [495/735], Loss: 0.6038\n",
      "Epoch [23/50], Step [496/735], Loss: 0.2072\n",
      "Epoch [23/50], Step [497/735], Loss: 0.1375\n",
      "Epoch [23/50], Step [498/735], Loss: 0.2253\n",
      "Epoch [23/50], Step [499/735], Loss: 0.3986\n",
      "Epoch [23/50], Step [500/735], Loss: 0.6454\n",
      "Epoch [23/50], Step [501/735], Loss: 0.2119\n",
      "Epoch [23/50], Step [502/735], Loss: 0.2629\n",
      "Epoch [23/50], Step [503/735], Loss: 0.5112\n",
      "Epoch [23/50], Step [504/735], Loss: 0.1795\n",
      "Epoch [23/50], Step [505/735], Loss: 0.8401\n",
      "Epoch [23/50], Step [506/735], Loss: 0.1373\n",
      "Epoch [23/50], Step [507/735], Loss: 0.2494\n",
      "Epoch [23/50], Step [508/735], Loss: 0.2868\n",
      "Epoch [23/50], Step [509/735], Loss: 0.3077\n",
      "Epoch [23/50], Step [510/735], Loss: 0.2192\n",
      "Epoch [23/50], Step [511/735], Loss: 0.3040\n",
      "Epoch [23/50], Step [512/735], Loss: 0.5503\n",
      "Epoch [23/50], Step [513/735], Loss: 0.4710\n",
      "Epoch [23/50], Step [514/735], Loss: 1.2479\n",
      "Epoch [23/50], Step [515/735], Loss: 0.2024\n",
      "Epoch [23/50], Step [516/735], Loss: 0.3812\n",
      "Epoch [23/50], Step [517/735], Loss: 0.1504\n",
      "Epoch [23/50], Step [518/735], Loss: 0.2199\n",
      "Epoch [23/50], Step [519/735], Loss: 0.2756\n",
      "Epoch [23/50], Step [520/735], Loss: 0.1419\n",
      "Epoch [23/50], Step [521/735], Loss: 5.0598\n",
      "Epoch [23/50], Step [522/735], Loss: 0.4791\n",
      "Epoch [23/50], Step [523/735], Loss: 0.4741\n",
      "Epoch [23/50], Step [524/735], Loss: 0.1605\n",
      "Epoch [23/50], Step [525/735], Loss: 0.2108\n",
      "Epoch [23/50], Step [526/735], Loss: 0.3772\n",
      "Epoch [23/50], Step [527/735], Loss: 0.2554\n",
      "Epoch [23/50], Step [528/735], Loss: 0.0610\n",
      "Epoch [23/50], Step [529/735], Loss: 0.8541\n",
      "Epoch [23/50], Step [530/735], Loss: 0.0808\n",
      "Epoch [23/50], Step [531/735], Loss: 0.3630\n",
      "Epoch [23/50], Step [532/735], Loss: 0.2112\n",
      "Epoch [23/50], Step [533/735], Loss: 0.4393\n",
      "Epoch [23/50], Step [534/735], Loss: 0.2621\n",
      "Epoch [23/50], Step [535/735], Loss: 0.5901\n",
      "Epoch [23/50], Step [536/735], Loss: 0.2101\n",
      "Epoch [23/50], Step [537/735], Loss: 0.2951\n",
      "Epoch [23/50], Step [538/735], Loss: 0.1883\n",
      "Epoch [23/50], Step [539/735], Loss: 0.4594\n",
      "Epoch [23/50], Step [540/735], Loss: 0.1142\n",
      "Epoch [23/50], Step [541/735], Loss: 0.2005\n",
      "Epoch [23/50], Step [542/735], Loss: 0.2976\n",
      "Epoch [23/50], Step [543/735], Loss: 0.4981\n",
      "Epoch [23/50], Step [544/735], Loss: 0.1935\n",
      "Epoch [23/50], Step [545/735], Loss: 0.1515\n",
      "Epoch [23/50], Step [546/735], Loss: 0.7786\n",
      "Epoch [23/50], Step [547/735], Loss: 0.1953\n",
      "Epoch [23/50], Step [548/735], Loss: 1.1985\n",
      "Epoch [23/50], Step [549/735], Loss: 0.1819\n",
      "Epoch [23/50], Step [550/735], Loss: 0.1768\n",
      "Epoch [23/50], Step [551/735], Loss: 0.7166\n",
      "Epoch [23/50], Step [552/735], Loss: 0.8062\n",
      "Epoch [23/50], Step [553/735], Loss: 0.3393\n",
      "Epoch [23/50], Step [554/735], Loss: 0.1970\n",
      "Epoch [23/50], Step [555/735], Loss: 0.1108\n",
      "Epoch [23/50], Step [556/735], Loss: 0.3194\n",
      "Epoch [23/50], Step [557/735], Loss: 0.2494\n",
      "Epoch [23/50], Step [558/735], Loss: 0.5192\n",
      "Epoch [23/50], Step [559/735], Loss: 0.2114\n",
      "Epoch [23/50], Step [560/735], Loss: 0.2941\n",
      "Epoch [23/50], Step [561/735], Loss: 0.1721\n",
      "Epoch [23/50], Step [562/735], Loss: 0.2358\n",
      "Epoch [23/50], Step [563/735], Loss: 0.0631\n",
      "Epoch [23/50], Step [564/735], Loss: 0.2693\n",
      "Epoch [23/50], Step [565/735], Loss: 0.6403\n",
      "Epoch [23/50], Step [566/735], Loss: 0.3505\n",
      "Epoch [23/50], Step [567/735], Loss: 0.2220\n",
      "Epoch [23/50], Step [568/735], Loss: 0.4521\n",
      "Epoch [23/50], Step [569/735], Loss: 0.3827\n",
      "Epoch [23/50], Step [570/735], Loss: 1.3063\n",
      "Epoch [23/50], Step [571/735], Loss: 1.3275\n",
      "Epoch [23/50], Step [572/735], Loss: 0.5275\n",
      "Epoch [23/50], Step [573/735], Loss: 0.1530\n",
      "Epoch [23/50], Step [574/735], Loss: 1.0750\n",
      "Epoch [23/50], Step [575/735], Loss: 0.3977\n",
      "Epoch [23/50], Step [576/735], Loss: 0.0790\n",
      "Epoch [23/50], Step [577/735], Loss: 0.2933\n",
      "Epoch [23/50], Step [578/735], Loss: 0.4091\n",
      "Epoch [23/50], Step [579/735], Loss: 0.4085\n",
      "Epoch [23/50], Step [580/735], Loss: 0.3369\n",
      "Epoch [23/50], Step [581/735], Loss: 0.1707\n",
      "Epoch [23/50], Step [582/735], Loss: 0.1324\n",
      "Epoch [23/50], Step [583/735], Loss: 0.8553\n",
      "Epoch [23/50], Step [584/735], Loss: 0.1395\n",
      "Epoch [23/50], Step [585/735], Loss: 5.3404\n",
      "Epoch [23/50], Step [586/735], Loss: 0.7221\n",
      "Epoch [23/50], Step [587/735], Loss: 0.5053\n",
      "Epoch [23/50], Step [588/735], Loss: 0.0922\n",
      "Epoch [23/50], Step [589/735], Loss: 0.5252\n",
      "Epoch [23/50], Step [590/735], Loss: 0.2715\n",
      "Epoch [23/50], Step [591/735], Loss: 0.1210\n",
      "Epoch [23/50], Step [592/735], Loss: 0.2616\n",
      "Epoch [23/50], Step [593/735], Loss: 0.3942\n",
      "Epoch [23/50], Step [594/735], Loss: 1.0657\n",
      "Epoch [23/50], Step [595/735], Loss: 0.6054\n",
      "Epoch [23/50], Step [596/735], Loss: 0.3137\n",
      "Epoch [23/50], Step [597/735], Loss: 0.1871\n",
      "Epoch [23/50], Step [598/735], Loss: 0.4897\n",
      "Epoch [23/50], Step [599/735], Loss: 0.3669\n",
      "Epoch [23/50], Step [600/735], Loss: 0.2199\n",
      "Epoch [23/50], Step [601/735], Loss: 0.2178\n",
      "Epoch [23/50], Step [602/735], Loss: 0.2659\n",
      "Epoch [23/50], Step [603/735], Loss: 0.2962\n",
      "Epoch [23/50], Step [604/735], Loss: 0.4111\n",
      "Epoch [23/50], Step [605/735], Loss: 0.2823\n",
      "Epoch [23/50], Step [606/735], Loss: 0.2268\n",
      "Epoch [23/50], Step [607/735], Loss: 1.2149\n",
      "Epoch [23/50], Step [608/735], Loss: 0.4032\n",
      "Epoch [23/50], Step [609/735], Loss: 0.4607\n",
      "Epoch [23/50], Step [610/735], Loss: 0.8227\n",
      "Epoch [23/50], Step [611/735], Loss: 0.4826\n",
      "Epoch [23/50], Step [612/735], Loss: 0.1418\n",
      "Epoch [23/50], Step [613/735], Loss: 1.7804\n",
      "Epoch [23/50], Step [614/735], Loss: 0.2108\n",
      "Epoch [23/50], Step [615/735], Loss: 1.6514\n",
      "Epoch [23/50], Step [616/735], Loss: 0.1071\n",
      "Epoch [23/50], Step [617/735], Loss: 0.2393\n",
      "Epoch [23/50], Step [618/735], Loss: 1.2460\n",
      "Epoch [23/50], Step [619/735], Loss: 0.2382\n",
      "Epoch [23/50], Step [620/735], Loss: 0.2310\n",
      "Epoch [23/50], Step [621/735], Loss: 0.5259\n",
      "Epoch [23/50], Step [622/735], Loss: 0.6028\n",
      "Epoch [23/50], Step [623/735], Loss: 0.3156\n",
      "Epoch [23/50], Step [624/735], Loss: 0.3797\n",
      "Epoch [23/50], Step [625/735], Loss: 0.4581\n",
      "Epoch [23/50], Step [626/735], Loss: 0.4186\n",
      "Epoch [23/50], Step [627/735], Loss: 0.1886\n",
      "Epoch [23/50], Step [628/735], Loss: 0.0806\n",
      "Epoch [23/50], Step [629/735], Loss: 0.4481\n",
      "Epoch [23/50], Step [630/735], Loss: 0.4826\n",
      "Epoch [23/50], Step [631/735], Loss: 0.0701\n",
      "Epoch [23/50], Step [632/735], Loss: 0.4341\n",
      "Epoch [23/50], Step [633/735], Loss: 0.3240\n",
      "Epoch [23/50], Step [634/735], Loss: 0.1465\n",
      "Epoch [23/50], Step [635/735], Loss: 0.2294\n",
      "Epoch [23/50], Step [636/735], Loss: 0.1919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Step [637/735], Loss: 0.1472\n",
      "Epoch [23/50], Step [638/735], Loss: 0.1766\n",
      "Epoch [23/50], Step [639/735], Loss: 0.2513\n",
      "Epoch [23/50], Step [640/735], Loss: 0.4531\n",
      "Epoch [23/50], Step [641/735], Loss: 0.2360\n",
      "Epoch [23/50], Step [642/735], Loss: 0.1001\n",
      "Epoch [23/50], Step [643/735], Loss: 0.1930\n",
      "Epoch [23/50], Step [644/735], Loss: 0.2035\n",
      "Epoch [23/50], Step [645/735], Loss: 1.0354\n",
      "Epoch [23/50], Step [646/735], Loss: 0.1581\n",
      "Epoch [23/50], Step [647/735], Loss: 0.7609\n",
      "Epoch [23/50], Step [648/735], Loss: 0.1679\n",
      "Epoch [23/50], Step [649/735], Loss: 0.0417\n",
      "Epoch [23/50], Step [650/735], Loss: 0.0801\n",
      "Epoch [23/50], Step [651/735], Loss: 0.2494\n",
      "Epoch [23/50], Step [652/735], Loss: 0.2762\n",
      "Epoch [23/50], Step [653/735], Loss: 0.3074\n",
      "Epoch [23/50], Step [654/735], Loss: 0.1972\n",
      "Epoch [23/50], Step [655/735], Loss: 0.1192\n",
      "Epoch [23/50], Step [656/735], Loss: 0.5276\n",
      "Epoch [23/50], Step [657/735], Loss: 0.1297\n",
      "Epoch [23/50], Step [658/735], Loss: 0.2950\n",
      "Epoch [23/50], Step [659/735], Loss: 0.1464\n",
      "Epoch [23/50], Step [660/735], Loss: 1.2790\n",
      "Epoch [23/50], Step [661/735], Loss: 0.1994\n",
      "Epoch [23/50], Step [662/735], Loss: 0.8788\n",
      "Epoch [23/50], Step [663/735], Loss: 0.1149\n",
      "Epoch [23/50], Step [664/735], Loss: 0.1286\n",
      "Epoch [23/50], Step [665/735], Loss: 0.5085\n",
      "Epoch [23/50], Step [666/735], Loss: 0.3949\n",
      "Epoch [23/50], Step [667/735], Loss: 0.2723\n",
      "Epoch [23/50], Step [668/735], Loss: 0.3037\n",
      "Epoch [23/50], Step [669/735], Loss: 0.4776\n",
      "Epoch [23/50], Step [670/735], Loss: 0.3182\n",
      "Epoch [23/50], Step [671/735], Loss: 0.3494\n",
      "Epoch [23/50], Step [672/735], Loss: 0.1210\n",
      "Epoch [23/50], Step [673/735], Loss: 0.4497\n",
      "Epoch [23/50], Step [674/735], Loss: 0.1324\n",
      "Epoch [23/50], Step [675/735], Loss: 0.6324\n",
      "Epoch [23/50], Step [676/735], Loss: 0.4894\n",
      "Epoch [23/50], Step [677/735], Loss: 0.4553\n",
      "Epoch [23/50], Step [678/735], Loss: 0.8796\n",
      "Epoch [23/50], Step [679/735], Loss: 0.3369\n",
      "Epoch [23/50], Step [680/735], Loss: 0.3350\n",
      "Epoch [23/50], Step [681/735], Loss: 0.2340\n",
      "Epoch [23/50], Step [682/735], Loss: 0.2233\n",
      "Epoch [23/50], Step [683/735], Loss: 1.0598\n",
      "Epoch [23/50], Step [684/735], Loss: 0.6261\n",
      "Epoch [23/50], Step [685/735], Loss: 0.1337\n",
      "Epoch [23/50], Step [686/735], Loss: 1.1974\n",
      "Epoch [23/50], Step [687/735], Loss: 0.2020\n",
      "Epoch [23/50], Step [688/735], Loss: 0.1802\n",
      "Epoch [23/50], Step [689/735], Loss: 0.5842\n",
      "Epoch [23/50], Step [690/735], Loss: 0.2005\n",
      "Epoch [23/50], Step [691/735], Loss: 0.0989\n",
      "Epoch [23/50], Step [692/735], Loss: 0.4112\n",
      "Epoch [23/50], Step [693/735], Loss: 0.2960\n",
      "Epoch [23/50], Step [694/735], Loss: 0.4151\n",
      "Epoch [23/50], Step [695/735], Loss: 0.5050\n",
      "Epoch [23/50], Step [696/735], Loss: 0.1580\n",
      "Epoch [23/50], Step [697/735], Loss: 1.4242\n",
      "Epoch [23/50], Step [698/735], Loss: 0.2023\n",
      "Epoch [23/50], Step [699/735], Loss: 0.6022\n",
      "Epoch [23/50], Step [700/735], Loss: 0.1126\n",
      "Epoch [23/50], Step [701/735], Loss: 0.5039\n",
      "Epoch [23/50], Step [702/735], Loss: 0.2869\n",
      "Epoch [23/50], Step [703/735], Loss: 0.3899\n",
      "Epoch [23/50], Step [704/735], Loss: 0.1729\n",
      "Epoch [23/50], Step [705/735], Loss: 0.2490\n",
      "Epoch [23/50], Step [706/735], Loss: 0.3504\n",
      "Epoch [23/50], Step [707/735], Loss: 0.2524\n",
      "Epoch [23/50], Step [708/735], Loss: 0.8681\n",
      "Epoch [23/50], Step [709/735], Loss: 0.1693\n",
      "Epoch [23/50], Step [710/735], Loss: 0.3452\n",
      "Epoch [23/50], Step [711/735], Loss: 0.6227\n",
      "Epoch [23/50], Step [712/735], Loss: 0.6943\n",
      "Epoch [23/50], Step [713/735], Loss: 0.2681\n",
      "Epoch [23/50], Step [714/735], Loss: 0.6212\n",
      "Epoch [23/50], Step [715/735], Loss: 0.7577\n",
      "Epoch [23/50], Step [716/735], Loss: 0.2001\n",
      "Epoch [23/50], Step [717/735], Loss: 0.3869\n",
      "Epoch [23/50], Step [718/735], Loss: 0.2837\n",
      "Epoch [23/50], Step [719/735], Loss: 0.2560\n",
      "Epoch [23/50], Step [720/735], Loss: 0.9829\n",
      "Epoch [23/50], Step [721/735], Loss: 0.0948\n",
      "Epoch [23/50], Step [722/735], Loss: 0.2785\n",
      "Epoch [23/50], Step [723/735], Loss: 1.0341\n",
      "Epoch [23/50], Step [724/735], Loss: 0.1969\n",
      "Epoch [23/50], Step [725/735], Loss: 0.3453\n",
      "Epoch [23/50], Step [726/735], Loss: 0.0813\n",
      "Epoch [23/50], Step [727/735], Loss: 0.4504\n",
      "Epoch [23/50], Step [728/735], Loss: 0.3246\n",
      "Epoch [23/50], Step [729/735], Loss: 0.2807\n",
      "Epoch [23/50], Step [730/735], Loss: 0.3448\n",
      "Epoch [23/50], Step [731/735], Loss: 1.6123\n",
      "Epoch [23/50], Step [732/735], Loss: 0.3729\n",
      "Epoch [23/50], Step [733/735], Loss: 1.0303\n",
      "Epoch [23/50], Step [734/735], Loss: 0.1785\n",
      "Epoch [23/50], Step [735/735], Loss: 0.0372\n",
      "Epoch [24/50], Step [1/735], Loss: 0.1581\n",
      "Epoch [24/50], Step [2/735], Loss: 0.2042\n",
      "Epoch [24/50], Step [3/735], Loss: 0.4661\n",
      "Epoch [24/50], Step [4/735], Loss: 0.1724\n",
      "Epoch [24/50], Step [5/735], Loss: 0.2480\n",
      "Epoch [24/50], Step [6/735], Loss: 0.7238\n",
      "Epoch [24/50], Step [7/735], Loss: 0.1369\n",
      "Epoch [24/50], Step [8/735], Loss: 0.6296\n",
      "Epoch [24/50], Step [9/735], Loss: 0.9165\n",
      "Epoch [24/50], Step [10/735], Loss: 0.1702\n",
      "Epoch [24/50], Step [11/735], Loss: 0.1958\n",
      "Epoch [24/50], Step [12/735], Loss: 0.3811\n",
      "Epoch [24/50], Step [13/735], Loss: 0.2763\n",
      "Epoch [24/50], Step [14/735], Loss: 0.5798\n",
      "Epoch [24/50], Step [15/735], Loss: 0.1418\n",
      "Epoch [24/50], Step [16/735], Loss: 0.2355\n",
      "Epoch [24/50], Step [17/735], Loss: 0.7760\n",
      "Epoch [24/50], Step [18/735], Loss: 0.2330\n",
      "Epoch [24/50], Step [19/735], Loss: 0.1690\n",
      "Epoch [24/50], Step [20/735], Loss: 1.6995\n",
      "Epoch [24/50], Step [21/735], Loss: 0.3032\n",
      "Epoch [24/50], Step [22/735], Loss: 0.4487\n",
      "Epoch [24/50], Step [23/735], Loss: 0.3436\n",
      "Epoch [24/50], Step [24/735], Loss: 0.4884\n",
      "Epoch [24/50], Step [25/735], Loss: 0.3889\n",
      "Epoch [24/50], Step [26/735], Loss: 0.6342\n",
      "Epoch [24/50], Step [27/735], Loss: 0.6123\n",
      "Epoch [24/50], Step [28/735], Loss: 0.1329\n",
      "Epoch [24/50], Step [29/735], Loss: 0.3053\n",
      "Epoch [24/50], Step [30/735], Loss: 0.1079\n",
      "Epoch [24/50], Step [31/735], Loss: 0.9899\n",
      "Epoch [24/50], Step [32/735], Loss: 0.3276\n",
      "Epoch [24/50], Step [33/735], Loss: 0.1661\n",
      "Epoch [24/50], Step [34/735], Loss: 0.1557\n",
      "Epoch [24/50], Step [35/735], Loss: 0.5954\n",
      "Epoch [24/50], Step [36/735], Loss: 0.4110\n",
      "Epoch [24/50], Step [37/735], Loss: 0.0446\n",
      "Epoch [24/50], Step [38/735], Loss: 0.4252\n",
      "Epoch [24/50], Step [39/735], Loss: 0.1852\n",
      "Epoch [24/50], Step [40/735], Loss: 0.9678\n",
      "Epoch [24/50], Step [41/735], Loss: 0.4714\n",
      "Epoch [24/50], Step [42/735], Loss: 0.6751\n",
      "Epoch [24/50], Step [43/735], Loss: 0.4031\n",
      "Epoch [24/50], Step [44/735], Loss: 0.1313\n",
      "Epoch [24/50], Step [45/735], Loss: 0.7296\n",
      "Epoch [24/50], Step [46/735], Loss: 1.1158\n",
      "Epoch [24/50], Step [47/735], Loss: 0.1122\n",
      "Epoch [24/50], Step [48/735], Loss: 0.2628\n",
      "Epoch [24/50], Step [49/735], Loss: 0.1996\n",
      "Epoch [24/50], Step [50/735], Loss: 0.5377\n",
      "Epoch [24/50], Step [51/735], Loss: 0.1662\n",
      "Epoch [24/50], Step [52/735], Loss: 0.5175\n",
      "Epoch [24/50], Step [53/735], Loss: 0.1264\n",
      "Epoch [24/50], Step [54/735], Loss: 0.2942\n",
      "Epoch [24/50], Step [55/735], Loss: 0.4579\n",
      "Epoch [24/50], Step [56/735], Loss: 0.3347\n",
      "Epoch [24/50], Step [57/735], Loss: 0.3783\n",
      "Epoch [24/50], Step [58/735], Loss: 0.6396\n",
      "Epoch [24/50], Step [59/735], Loss: 1.2592\n",
      "Epoch [24/50], Step [60/735], Loss: 0.5050\n",
      "Epoch [24/50], Step [61/735], Loss: 0.2335\n",
      "Epoch [24/50], Step [62/735], Loss: 0.3071\n",
      "Epoch [24/50], Step [63/735], Loss: 0.1084\n",
      "Epoch [24/50], Step [64/735], Loss: 0.1016\n",
      "Epoch [24/50], Step [65/735], Loss: 0.1866\n",
      "Epoch [24/50], Step [66/735], Loss: 0.2476\n",
      "Epoch [24/50], Step [67/735], Loss: 0.1014\n",
      "Epoch [24/50], Step [68/735], Loss: 0.1820\n",
      "Epoch [24/50], Step [69/735], Loss: 1.7033\n",
      "Epoch [24/50], Step [70/735], Loss: 0.2770\n",
      "Epoch [24/50], Step [71/735], Loss: 0.9745\n",
      "Epoch [24/50], Step [72/735], Loss: 0.4786\n",
      "Epoch [24/50], Step [73/735], Loss: 0.0979\n",
      "Epoch [24/50], Step [74/735], Loss: 0.0918\n",
      "Epoch [24/50], Step [75/735], Loss: 0.3762\n",
      "Epoch [24/50], Step [76/735], Loss: 0.3769\n",
      "Epoch [24/50], Step [77/735], Loss: 0.4455\n",
      "Epoch [24/50], Step [78/735], Loss: 0.6948\n",
      "Epoch [24/50], Step [79/735], Loss: 0.4248\n",
      "Epoch [24/50], Step [80/735], Loss: 0.2936\n",
      "Epoch [24/50], Step [81/735], Loss: 0.1391\n",
      "Epoch [24/50], Step [82/735], Loss: 0.4616\n",
      "Epoch [24/50], Step [83/735], Loss: 0.5763\n",
      "Epoch [24/50], Step [84/735], Loss: 0.2520\n",
      "Epoch [24/50], Step [85/735], Loss: 0.1825\n",
      "Epoch [24/50], Step [86/735], Loss: 0.3053\n",
      "Epoch [24/50], Step [87/735], Loss: 0.6242\n",
      "Epoch [24/50], Step [88/735], Loss: 0.2698\n",
      "Epoch [24/50], Step [89/735], Loss: 0.1815\n",
      "Epoch [24/50], Step [90/735], Loss: 0.7261\n",
      "Epoch [24/50], Step [91/735], Loss: 0.3218\n",
      "Epoch [24/50], Step [92/735], Loss: 0.3528\n",
      "Epoch [24/50], Step [93/735], Loss: 0.1550\n",
      "Epoch [24/50], Step [94/735], Loss: 0.0859\n",
      "Epoch [24/50], Step [95/735], Loss: 0.0874\n",
      "Epoch [24/50], Step [96/735], Loss: 1.0899\n",
      "Epoch [24/50], Step [97/735], Loss: 0.2916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Step [98/735], Loss: 0.2565\n",
      "Epoch [24/50], Step [99/735], Loss: 0.0547\n",
      "Epoch [24/50], Step [100/735], Loss: 0.2857\n",
      "Epoch [24/50], Step [101/735], Loss: 0.3488\n",
      "Epoch [24/50], Step [102/735], Loss: 0.6001\n",
      "Epoch [24/50], Step [103/735], Loss: 0.5211\n",
      "Epoch [24/50], Step [104/735], Loss: 0.1788\n",
      "Epoch [24/50], Step [105/735], Loss: 0.2101\n",
      "Epoch [24/50], Step [106/735], Loss: 0.2530\n",
      "Epoch [24/50], Step [107/735], Loss: 0.3715\n",
      "Epoch [24/50], Step [108/735], Loss: 0.1824\n",
      "Epoch [24/50], Step [109/735], Loss: 0.4868\n",
      "Epoch [24/50], Step [110/735], Loss: 0.8904\n",
      "Epoch [24/50], Step [111/735], Loss: 0.0696\n",
      "Epoch [24/50], Step [112/735], Loss: 0.1801\n",
      "Epoch [24/50], Step [113/735], Loss: 0.1436\n",
      "Epoch [24/50], Step [114/735], Loss: 1.2459\n",
      "Epoch [24/50], Step [115/735], Loss: 0.2367\n",
      "Epoch [24/50], Step [116/735], Loss: 0.3050\n",
      "Epoch [24/50], Step [117/735], Loss: 0.2420\n",
      "Epoch [24/50], Step [118/735], Loss: 0.1294\n",
      "Epoch [24/50], Step [119/735], Loss: 0.1135\n",
      "Epoch [24/50], Step [120/735], Loss: 0.4448\n",
      "Epoch [24/50], Step [121/735], Loss: 0.8595\n",
      "Epoch [24/50], Step [122/735], Loss: 0.3492\n",
      "Epoch [24/50], Step [123/735], Loss: 0.2968\n",
      "Epoch [24/50], Step [124/735], Loss: 0.1045\n",
      "Epoch [24/50], Step [125/735], Loss: 0.0912\n",
      "Epoch [24/50], Step [126/735], Loss: 0.1862\n",
      "Epoch [24/50], Step [127/735], Loss: 0.1484\n",
      "Epoch [24/50], Step [128/735], Loss: 0.1846\n",
      "Epoch [24/50], Step [129/735], Loss: 0.1685\n",
      "Epoch [24/50], Step [130/735], Loss: 0.2773\n",
      "Epoch [24/50], Step [131/735], Loss: 0.1385\n",
      "Epoch [24/50], Step [132/735], Loss: 0.2014\n",
      "Epoch [24/50], Step [133/735], Loss: 0.2506\n",
      "Epoch [24/50], Step [134/735], Loss: 0.0504\n",
      "Epoch [24/50], Step [135/735], Loss: 0.1766\n",
      "Epoch [24/50], Step [136/735], Loss: 0.3185\n",
      "Epoch [24/50], Step [137/735], Loss: 0.6153\n",
      "Epoch [24/50], Step [138/735], Loss: 0.1208\n",
      "Epoch [24/50], Step [139/735], Loss: 0.2901\n",
      "Epoch [24/50], Step [140/735], Loss: 0.5942\n",
      "Epoch [24/50], Step [141/735], Loss: 0.3435\n",
      "Epoch [24/50], Step [142/735], Loss: 0.0355\n",
      "Epoch [24/50], Step [143/735], Loss: 0.1505\n",
      "Epoch [24/50], Step [144/735], Loss: 0.1307\n",
      "Epoch [24/50], Step [145/735], Loss: 0.8820\n",
      "Epoch [24/50], Step [146/735], Loss: 0.1685\n",
      "Epoch [24/50], Step [147/735], Loss: 0.5863\n",
      "Epoch [24/50], Step [148/735], Loss: 0.4062\n",
      "Epoch [24/50], Step [149/735], Loss: 0.1690\n",
      "Epoch [24/50], Step [150/735], Loss: 0.1667\n",
      "Epoch [24/50], Step [151/735], Loss: 0.6224\n",
      "Epoch [24/50], Step [152/735], Loss: 0.2312\n",
      "Epoch [24/50], Step [153/735], Loss: 5.6915\n",
      "Epoch [24/50], Step [154/735], Loss: 0.1202\n",
      "Epoch [24/50], Step [155/735], Loss: 0.3336\n",
      "Epoch [24/50], Step [156/735], Loss: 0.2100\n",
      "Epoch [24/50], Step [157/735], Loss: 0.1184\n",
      "Epoch [24/50], Step [158/735], Loss: 0.0496\n",
      "Epoch [24/50], Step [159/735], Loss: 0.6529\n",
      "Epoch [24/50], Step [160/735], Loss: 0.1876\n",
      "Epoch [24/50], Step [161/735], Loss: 0.7669\n",
      "Epoch [24/50], Step [162/735], Loss: 0.2782\n",
      "Epoch [24/50], Step [163/735], Loss: 1.7843\n",
      "Epoch [24/50], Step [164/735], Loss: 0.2865\n",
      "Epoch [24/50], Step [165/735], Loss: 0.1797\n",
      "Epoch [24/50], Step [166/735], Loss: 0.2667\n",
      "Epoch [24/50], Step [167/735], Loss: 0.1933\n",
      "Epoch [24/50], Step [168/735], Loss: 0.2867\n",
      "Epoch [24/50], Step [169/735], Loss: 0.3433\n",
      "Epoch [24/50], Step [170/735], Loss: 0.5100\n",
      "Epoch [24/50], Step [171/735], Loss: 0.8428\n",
      "Epoch [24/50], Step [172/735], Loss: 0.3590\n",
      "Epoch [24/50], Step [173/735], Loss: 0.3294\n",
      "Epoch [24/50], Step [174/735], Loss: 0.1584\n",
      "Epoch [24/50], Step [175/735], Loss: 0.1907\n",
      "Epoch [24/50], Step [176/735], Loss: 0.1644\n",
      "Epoch [24/50], Step [177/735], Loss: 0.4957\n",
      "Epoch [24/50], Step [178/735], Loss: 0.5204\n",
      "Epoch [24/50], Step [179/735], Loss: 0.1421\n",
      "Epoch [24/50], Step [180/735], Loss: 0.3139\n",
      "Epoch [24/50], Step [181/735], Loss: 0.1981\n",
      "Epoch [24/50], Step [182/735], Loss: 0.6302\n",
      "Epoch [24/50], Step [183/735], Loss: 0.2672\n",
      "Epoch [24/50], Step [184/735], Loss: 0.5299\n",
      "Epoch [24/50], Step [185/735], Loss: 0.6638\n",
      "Epoch [24/50], Step [186/735], Loss: 0.2048\n",
      "Epoch [24/50], Step [187/735], Loss: 0.7935\n",
      "Epoch [24/50], Step [188/735], Loss: 0.9180\n",
      "Epoch [24/50], Step [189/735], Loss: 0.3189\n",
      "Epoch [24/50], Step [190/735], Loss: 0.2183\n",
      "Epoch [24/50], Step [191/735], Loss: 0.4897\n",
      "Epoch [24/50], Step [192/735], Loss: 0.2025\n",
      "Epoch [24/50], Step [193/735], Loss: 0.2545\n",
      "Epoch [24/50], Step [194/735], Loss: 0.6001\n",
      "Epoch [24/50], Step [195/735], Loss: 0.9162\n",
      "Epoch [24/50], Step [196/735], Loss: 0.4936\n",
      "Epoch [24/50], Step [197/735], Loss: 0.2429\n",
      "Epoch [24/50], Step [198/735], Loss: 0.2912\n",
      "Epoch [24/50], Step [199/735], Loss: 0.1827\n",
      "Epoch [24/50], Step [200/735], Loss: 0.1180\n",
      "Epoch [24/50], Step [201/735], Loss: 0.3626\n",
      "Epoch [24/50], Step [202/735], Loss: 0.3768\n",
      "Epoch [24/50], Step [203/735], Loss: 0.4246\n",
      "Epoch [24/50], Step [204/735], Loss: 0.3270\n",
      "Epoch [24/50], Step [205/735], Loss: 0.1923\n",
      "Epoch [24/50], Step [206/735], Loss: 0.8371\n",
      "Epoch [24/50], Step [207/735], Loss: 0.0991\n",
      "Epoch [24/50], Step [208/735], Loss: 0.6904\n",
      "Epoch [24/50], Step [209/735], Loss: 0.3285\n",
      "Epoch [24/50], Step [210/735], Loss: 0.3867\n",
      "Epoch [24/50], Step [211/735], Loss: 0.1419\n",
      "Epoch [24/50], Step [212/735], Loss: 0.3047\n",
      "Epoch [24/50], Step [213/735], Loss: 0.1110\n",
      "Epoch [24/50], Step [214/735], Loss: 0.1031\n",
      "Epoch [24/50], Step [215/735], Loss: 0.0724\n",
      "Epoch [24/50], Step [216/735], Loss: 0.2901\n",
      "Epoch [24/50], Step [217/735], Loss: 0.1563\n",
      "Epoch [24/50], Step [218/735], Loss: 0.1213\n",
      "Epoch [24/50], Step [219/735], Loss: 0.0920\n",
      "Epoch [24/50], Step [220/735], Loss: 0.5546\n",
      "Epoch [24/50], Step [221/735], Loss: 0.2439\n",
      "Epoch [24/50], Step [222/735], Loss: 0.3363\n",
      "Epoch [24/50], Step [223/735], Loss: 0.1490\n",
      "Epoch [24/50], Step [224/735], Loss: 0.6053\n",
      "Epoch [24/50], Step [225/735], Loss: 0.8331\n",
      "Epoch [24/50], Step [226/735], Loss: 0.2126\n",
      "Epoch [24/50], Step [227/735], Loss: 0.2759\n",
      "Epoch [24/50], Step [228/735], Loss: 0.1146\n",
      "Epoch [24/50], Step [229/735], Loss: 0.2725\n",
      "Epoch [24/50], Step [230/735], Loss: 0.6064\n",
      "Epoch [24/50], Step [231/735], Loss: 0.6978\n",
      "Epoch [24/50], Step [232/735], Loss: 0.1903\n",
      "Epoch [24/50], Step [233/735], Loss: 0.6681\n",
      "Epoch [24/50], Step [234/735], Loss: 0.7484\n",
      "Epoch [24/50], Step [235/735], Loss: 0.3506\n",
      "Epoch [24/50], Step [236/735], Loss: 0.3213\n",
      "Epoch [24/50], Step [237/735], Loss: 0.3052\n",
      "Epoch [24/50], Step [238/735], Loss: 0.1244\n",
      "Epoch [24/50], Step [239/735], Loss: 0.5010\n",
      "Epoch [24/50], Step [240/735], Loss: 0.2675\n",
      "Epoch [24/50], Step [241/735], Loss: 0.2674\n",
      "Epoch [24/50], Step [242/735], Loss: 0.9169\n",
      "Epoch [24/50], Step [243/735], Loss: 1.2818\n",
      "Epoch [24/50], Step [244/735], Loss: 0.3266\n",
      "Epoch [24/50], Step [245/735], Loss: 0.1237\n",
      "Epoch [24/50], Step [246/735], Loss: 0.3286\n",
      "Epoch [24/50], Step [247/735], Loss: 0.5235\n",
      "Epoch [24/50], Step [248/735], Loss: 0.2723\n",
      "Epoch [24/50], Step [249/735], Loss: 0.2603\n",
      "Epoch [24/50], Step [250/735], Loss: 0.2039\n",
      "Epoch [24/50], Step [251/735], Loss: 0.4356\n",
      "Epoch [24/50], Step [252/735], Loss: 1.0548\n",
      "Epoch [24/50], Step [253/735], Loss: 0.8785\n",
      "Epoch [24/50], Step [254/735], Loss: 0.1199\n",
      "Epoch [24/50], Step [255/735], Loss: 0.0544\n",
      "Epoch [24/50], Step [256/735], Loss: 0.3606\n",
      "Epoch [24/50], Step [257/735], Loss: 0.3214\n",
      "Epoch [24/50], Step [258/735], Loss: 0.2498\n",
      "Epoch [24/50], Step [259/735], Loss: 0.4492\n",
      "Epoch [24/50], Step [260/735], Loss: 0.1892\n",
      "Epoch [24/50], Step [261/735], Loss: 0.2271\n",
      "Epoch [24/50], Step [262/735], Loss: 0.7162\n",
      "Epoch [24/50], Step [263/735], Loss: 0.3520\n",
      "Epoch [24/50], Step [264/735], Loss: 0.2667\n",
      "Epoch [24/50], Step [265/735], Loss: 0.6621\n",
      "Epoch [24/50], Step [266/735], Loss: 0.2093\n",
      "Epoch [24/50], Step [267/735], Loss: 0.1802\n",
      "Epoch [24/50], Step [268/735], Loss: 0.6494\n",
      "Epoch [24/50], Step [269/735], Loss: 0.3512\n",
      "Epoch [24/50], Step [270/735], Loss: 0.3264\n",
      "Epoch [24/50], Step [271/735], Loss: 0.4986\n",
      "Epoch [24/50], Step [272/735], Loss: 0.6912\n",
      "Epoch [24/50], Step [273/735], Loss: 0.3116\n",
      "Epoch [24/50], Step [274/735], Loss: 0.2816\n",
      "Epoch [24/50], Step [275/735], Loss: 0.2163\n",
      "Epoch [24/50], Step [276/735], Loss: 0.2405\n",
      "Epoch [24/50], Step [277/735], Loss: 1.4925\n",
      "Epoch [24/50], Step [278/735], Loss: 1.1901\n",
      "Epoch [24/50], Step [279/735], Loss: 0.6301\n",
      "Epoch [24/50], Step [280/735], Loss: 0.3923\n",
      "Epoch [24/50], Step [281/735], Loss: 0.3041\n",
      "Epoch [24/50], Step [282/735], Loss: 0.1153\n",
      "Epoch [24/50], Step [283/735], Loss: 0.3242\n",
      "Epoch [24/50], Step [284/735], Loss: 0.7739\n",
      "Epoch [24/50], Step [285/735], Loss: 0.7183\n",
      "Epoch [24/50], Step [286/735], Loss: 0.5577\n",
      "Epoch [24/50], Step [287/735], Loss: 0.1767\n",
      "Epoch [24/50], Step [288/735], Loss: 0.0510\n",
      "Epoch [24/50], Step [289/735], Loss: 0.4997\n",
      "Epoch [24/50], Step [290/735], Loss: 0.2313\n",
      "Epoch [24/50], Step [291/735], Loss: 0.3765\n",
      "Epoch [24/50], Step [292/735], Loss: 0.2120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Step [293/735], Loss: 0.3389\n",
      "Epoch [24/50], Step [294/735], Loss: 1.6638\n",
      "Epoch [24/50], Step [295/735], Loss: 0.2981\n",
      "Epoch [24/50], Step [296/735], Loss: 0.1354\n",
      "Epoch [24/50], Step [297/735], Loss: 0.3658\n",
      "Epoch [24/50], Step [298/735], Loss: 0.7095\n",
      "Epoch [24/50], Step [299/735], Loss: 0.3358\n",
      "Epoch [24/50], Step [300/735], Loss: 0.4345\n",
      "Epoch [24/50], Step [301/735], Loss: 0.2352\n",
      "Epoch [24/50], Step [302/735], Loss: 0.6557\n",
      "Epoch [24/50], Step [303/735], Loss: 0.1610\n",
      "Epoch [24/50], Step [304/735], Loss: 0.4545\n",
      "Epoch [24/50], Step [305/735], Loss: 0.3924\n",
      "Epoch [24/50], Step [306/735], Loss: 0.2180\n",
      "Epoch [24/50], Step [307/735], Loss: 0.3821\n",
      "Epoch [24/50], Step [308/735], Loss: 0.8822\n",
      "Epoch [24/50], Step [309/735], Loss: 0.1124\n",
      "Epoch [24/50], Step [310/735], Loss: 0.1898\n",
      "Epoch [24/50], Step [311/735], Loss: 0.8938\n",
      "Epoch [24/50], Step [312/735], Loss: 0.3028\n",
      "Epoch [24/50], Step [313/735], Loss: 1.6617\n",
      "Epoch [24/50], Step [314/735], Loss: 0.2571\n",
      "Epoch [24/50], Step [315/735], Loss: 0.2157\n",
      "Epoch [24/50], Step [316/735], Loss: 0.6460\n",
      "Epoch [24/50], Step [317/735], Loss: 1.1291\n",
      "Epoch [24/50], Step [318/735], Loss: 0.4801\n",
      "Epoch [24/50], Step [319/735], Loss: 0.3396\n",
      "Epoch [24/50], Step [320/735], Loss: 0.1414\n",
      "Epoch [24/50], Step [321/735], Loss: 1.0064\n",
      "Epoch [24/50], Step [322/735], Loss: 0.1499\n",
      "Epoch [24/50], Step [323/735], Loss: 0.1517\n",
      "Epoch [24/50], Step [324/735], Loss: 0.2193\n",
      "Epoch [24/50], Step [325/735], Loss: 0.2458\n",
      "Epoch [24/50], Step [326/735], Loss: 0.3062\n",
      "Epoch [24/50], Step [327/735], Loss: 1.0779\n",
      "Epoch [24/50], Step [328/735], Loss: 0.0961\n",
      "Epoch [24/50], Step [329/735], Loss: 0.1833\n",
      "Epoch [24/50], Step [330/735], Loss: 0.6684\n",
      "Epoch [24/50], Step [331/735], Loss: 0.4657\n",
      "Epoch [24/50], Step [332/735], Loss: 0.6952\n",
      "Epoch [24/50], Step [333/735], Loss: 1.8959\n",
      "Epoch [24/50], Step [334/735], Loss: 0.3917\n",
      "Epoch [24/50], Step [335/735], Loss: 0.1002\n",
      "Epoch [24/50], Step [336/735], Loss: 0.1687\n",
      "Epoch [24/50], Step [337/735], Loss: 0.2131\n",
      "Epoch [24/50], Step [338/735], Loss: 0.4219\n",
      "Epoch [24/50], Step [339/735], Loss: 0.2295\n",
      "Epoch [24/50], Step [340/735], Loss: 4.8823\n",
      "Epoch [24/50], Step [341/735], Loss: 0.2871\n",
      "Epoch [24/50], Step [342/735], Loss: 0.3680\n",
      "Epoch [24/50], Step [343/735], Loss: 0.6859\n",
      "Epoch [24/50], Step [344/735], Loss: 0.4032\n",
      "Epoch [24/50], Step [345/735], Loss: 0.6919\n",
      "Epoch [24/50], Step [346/735], Loss: 0.4234\n",
      "Epoch [24/50], Step [347/735], Loss: 0.1295\n",
      "Epoch [24/50], Step [348/735], Loss: 0.5084\n",
      "Epoch [24/50], Step [349/735], Loss: 0.2317\n",
      "Epoch [24/50], Step [350/735], Loss: 1.0097\n",
      "Epoch [24/50], Step [351/735], Loss: 0.3725\n",
      "Epoch [24/50], Step [352/735], Loss: 0.3708\n",
      "Epoch [24/50], Step [353/735], Loss: 0.1402\n",
      "Epoch [24/50], Step [354/735], Loss: 0.2977\n",
      "Epoch [24/50], Step [355/735], Loss: 0.2270\n",
      "Epoch [24/50], Step [356/735], Loss: 0.2400\n",
      "Epoch [24/50], Step [357/735], Loss: 0.6782\n",
      "Epoch [24/50], Step [358/735], Loss: 0.1804\n",
      "Epoch [24/50], Step [359/735], Loss: 0.8176\n",
      "Epoch [24/50], Step [360/735], Loss: 0.7290\n",
      "Epoch [24/50], Step [361/735], Loss: 0.4303\n",
      "Epoch [24/50], Step [362/735], Loss: 0.3447\n",
      "Epoch [24/50], Step [363/735], Loss: 0.1040\n",
      "Epoch [24/50], Step [364/735], Loss: 0.5849\n",
      "Epoch [24/50], Step [365/735], Loss: 0.5383\n",
      "Epoch [24/50], Step [366/735], Loss: 0.1759\n",
      "Epoch [24/50], Step [367/735], Loss: 0.1570\n",
      "Epoch [24/50], Step [368/735], Loss: 0.2171\n",
      "Epoch [24/50], Step [369/735], Loss: 0.2881\n",
      "Epoch [24/50], Step [370/735], Loss: 0.1643\n",
      "Epoch [24/50], Step [371/735], Loss: 0.2638\n",
      "Epoch [24/50], Step [372/735], Loss: 0.4984\n",
      "Epoch [24/50], Step [373/735], Loss: 0.5942\n",
      "Epoch [24/50], Step [374/735], Loss: 0.5979\n",
      "Epoch [24/50], Step [375/735], Loss: 0.5681\n",
      "Epoch [24/50], Step [376/735], Loss: 0.4804\n",
      "Epoch [24/50], Step [377/735], Loss: 1.7327\n",
      "Epoch [24/50], Step [378/735], Loss: 0.3059\n",
      "Epoch [24/50], Step [379/735], Loss: 0.3502\n",
      "Epoch [24/50], Step [380/735], Loss: 0.2399\n",
      "Epoch [24/50], Step [381/735], Loss: 0.7520\n",
      "Epoch [24/50], Step [382/735], Loss: 0.6574\n",
      "Epoch [24/50], Step [383/735], Loss: 0.2853\n",
      "Epoch [24/50], Step [384/735], Loss: 0.3059\n",
      "Epoch [24/50], Step [385/735], Loss: 0.3609\n",
      "Epoch [24/50], Step [386/735], Loss: 0.2038\n",
      "Epoch [24/50], Step [387/735], Loss: 0.7188\n",
      "Epoch [24/50], Step [388/735], Loss: 0.8687\n",
      "Epoch [24/50], Step [389/735], Loss: 0.2133\n",
      "Epoch [24/50], Step [390/735], Loss: 0.4685\n",
      "Epoch [24/50], Step [391/735], Loss: 0.1275\n",
      "Epoch [24/50], Step [392/735], Loss: 0.1456\n",
      "Epoch [24/50], Step [393/735], Loss: 0.4669\n",
      "Epoch [24/50], Step [394/735], Loss: 0.1387\n",
      "Epoch [24/50], Step [395/735], Loss: 0.0850\n",
      "Epoch [24/50], Step [396/735], Loss: 0.3491\n",
      "Epoch [24/50], Step [397/735], Loss: 0.0861\n",
      "Epoch [24/50], Step [398/735], Loss: 0.3567\n",
      "Epoch [24/50], Step [399/735], Loss: 0.3113\n",
      "Epoch [24/50], Step [400/735], Loss: 0.2913\n",
      "Epoch [24/50], Step [401/735], Loss: 0.4696\n",
      "Epoch [24/50], Step [402/735], Loss: 0.2780\n",
      "Epoch [24/50], Step [403/735], Loss: 1.5554\n",
      "Epoch [24/50], Step [404/735], Loss: 0.3364\n",
      "Epoch [24/50], Step [405/735], Loss: 0.2419\n",
      "Epoch [24/50], Step [406/735], Loss: 0.3780\n",
      "Epoch [24/50], Step [407/735], Loss: 0.1573\n",
      "Epoch [24/50], Step [408/735], Loss: 0.1414\n",
      "Epoch [24/50], Step [409/735], Loss: 0.4719\n",
      "Epoch [24/50], Step [410/735], Loss: 1.0786\n",
      "Epoch [24/50], Step [411/735], Loss: 0.2137\n",
      "Epoch [24/50], Step [412/735], Loss: 0.3927\n",
      "Epoch [24/50], Step [413/735], Loss: 0.6258\n",
      "Epoch [24/50], Step [414/735], Loss: 0.7135\n",
      "Epoch [24/50], Step [415/735], Loss: 0.3128\n",
      "Epoch [24/50], Step [416/735], Loss: 0.3546\n",
      "Epoch [24/50], Step [417/735], Loss: 0.2253\n",
      "Epoch [24/50], Step [418/735], Loss: 0.4387\n",
      "Epoch [24/50], Step [419/735], Loss: 2.0393\n",
      "Epoch [24/50], Step [420/735], Loss: 5.7236\n",
      "Epoch [24/50], Step [421/735], Loss: 0.1820\n",
      "Epoch [24/50], Step [422/735], Loss: 0.2728\n",
      "Epoch [24/50], Step [423/735], Loss: 0.2580\n",
      "Epoch [24/50], Step [424/735], Loss: 0.4549\n",
      "Epoch [24/50], Step [425/735], Loss: 0.1893\n",
      "Epoch [24/50], Step [426/735], Loss: 0.4460\n",
      "Epoch [24/50], Step [427/735], Loss: 0.0984\n",
      "Epoch [24/50], Step [428/735], Loss: 0.7747\n",
      "Epoch [24/50], Step [429/735], Loss: 0.3418\n",
      "Epoch [24/50], Step [430/735], Loss: 0.3917\n",
      "Epoch [24/50], Step [431/735], Loss: 0.9164\n",
      "Epoch [24/50], Step [432/735], Loss: 0.8477\n",
      "Epoch [24/50], Step [433/735], Loss: 0.1992\n",
      "Epoch [24/50], Step [434/735], Loss: 0.3886\n",
      "Epoch [24/50], Step [435/735], Loss: 0.4517\n",
      "Epoch [24/50], Step [436/735], Loss: 0.4197\n",
      "Epoch [24/50], Step [437/735], Loss: 0.5007\n",
      "Epoch [24/50], Step [438/735], Loss: 0.2790\n",
      "Epoch [24/50], Step [439/735], Loss: 0.2008\n",
      "Epoch [24/50], Step [440/735], Loss: 0.4794\n",
      "Epoch [24/50], Step [441/735], Loss: 0.5530\n",
      "Epoch [24/50], Step [442/735], Loss: 0.5307\n",
      "Epoch [24/50], Step [443/735], Loss: 0.5305\n",
      "Epoch [24/50], Step [444/735], Loss: 0.3898\n",
      "Epoch [24/50], Step [445/735], Loss: 0.3929\n",
      "Epoch [24/50], Step [446/735], Loss: 0.4677\n",
      "Epoch [24/50], Step [447/735], Loss: 0.5671\n",
      "Epoch [24/50], Step [448/735], Loss: 0.3625\n",
      "Epoch [24/50], Step [449/735], Loss: 0.1787\n",
      "Epoch [24/50], Step [450/735], Loss: 0.4224\n",
      "Epoch [24/50], Step [451/735], Loss: 0.2489\n",
      "Epoch [24/50], Step [452/735], Loss: 0.2212\n",
      "Epoch [24/50], Step [453/735], Loss: 0.1042\n",
      "Epoch [24/50], Step [454/735], Loss: 0.7405\n",
      "Epoch [24/50], Step [455/735], Loss: 1.0756\n",
      "Epoch [24/50], Step [456/735], Loss: 0.2604\n",
      "Epoch [24/50], Step [457/735], Loss: 0.0565\n",
      "Epoch [24/50], Step [458/735], Loss: 0.5167\n",
      "Epoch [24/50], Step [459/735], Loss: 0.5159\n",
      "Epoch [24/50], Step [460/735], Loss: 0.4525\n",
      "Epoch [24/50], Step [461/735], Loss: 0.1690\n",
      "Epoch [24/50], Step [462/735], Loss: 0.1855\n",
      "Epoch [24/50], Step [463/735], Loss: 0.0798\n",
      "Epoch [24/50], Step [464/735], Loss: 0.8645\n",
      "Epoch [24/50], Step [465/735], Loss: 0.2455\n",
      "Epoch [24/50], Step [466/735], Loss: 0.6798\n",
      "Epoch [24/50], Step [467/735], Loss: 0.3028\n",
      "Epoch [24/50], Step [468/735], Loss: 0.0823\n",
      "Epoch [24/50], Step [469/735], Loss: 0.1718\n",
      "Epoch [24/50], Step [470/735], Loss: 0.8071\n",
      "Epoch [24/50], Step [471/735], Loss: 0.4804\n",
      "Epoch [24/50], Step [472/735], Loss: 0.1072\n",
      "Epoch [24/50], Step [473/735], Loss: 0.6153\n",
      "Epoch [24/50], Step [474/735], Loss: 0.1375\n",
      "Epoch [24/50], Step [475/735], Loss: 0.3371\n",
      "Epoch [24/50], Step [476/735], Loss: 0.2579\n",
      "Epoch [24/50], Step [477/735], Loss: 0.2521\n",
      "Epoch [24/50], Step [478/735], Loss: 0.4053\n",
      "Epoch [24/50], Step [479/735], Loss: 0.2402\n",
      "Epoch [24/50], Step [480/735], Loss: 0.1748\n",
      "Epoch [24/50], Step [481/735], Loss: 0.6297\n",
      "Epoch [24/50], Step [482/735], Loss: 0.7640\n",
      "Epoch [24/50], Step [483/735], Loss: 0.4630\n",
      "Epoch [24/50], Step [484/735], Loss: 0.1789\n",
      "Epoch [24/50], Step [485/735], Loss: 0.4533\n",
      "Epoch [24/50], Step [486/735], Loss: 0.2346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Step [487/735], Loss: 0.3356\n",
      "Epoch [24/50], Step [488/735], Loss: 0.1585\n",
      "Epoch [24/50], Step [489/735], Loss: 1.2355\n",
      "Epoch [24/50], Step [490/735], Loss: 0.2921\n",
      "Epoch [24/50], Step [491/735], Loss: 0.1507\n",
      "Epoch [24/50], Step [492/735], Loss: 0.1791\n",
      "Epoch [24/50], Step [493/735], Loss: 0.0718\n",
      "Epoch [24/50], Step [494/735], Loss: 0.2944\n",
      "Epoch [24/50], Step [495/735], Loss: 2.1756\n",
      "Epoch [24/50], Step [496/735], Loss: 0.1822\n",
      "Epoch [24/50], Step [497/735], Loss: 0.8685\n",
      "Epoch [24/50], Step [498/735], Loss: 0.2128\n",
      "Epoch [24/50], Step [499/735], Loss: 0.1752\n",
      "Epoch [24/50], Step [500/735], Loss: 0.1903\n",
      "Epoch [24/50], Step [501/735], Loss: 0.1773\n",
      "Epoch [24/50], Step [502/735], Loss: 0.3283\n",
      "Epoch [24/50], Step [503/735], Loss: 0.2877\n",
      "Epoch [24/50], Step [504/735], Loss: 0.0975\n",
      "Epoch [24/50], Step [505/735], Loss: 0.0803\n",
      "Epoch [24/50], Step [506/735], Loss: 0.3275\n",
      "Epoch [24/50], Step [507/735], Loss: 0.2242\n",
      "Epoch [24/50], Step [508/735], Loss: 0.6565\n",
      "Epoch [24/50], Step [509/735], Loss: 0.3393\n",
      "Epoch [24/50], Step [510/735], Loss: 0.1387\n",
      "Epoch [24/50], Step [511/735], Loss: 0.1632\n",
      "Epoch [24/50], Step [512/735], Loss: 0.5568\n",
      "Epoch [24/50], Step [513/735], Loss: 0.1348\n",
      "Epoch [24/50], Step [514/735], Loss: 0.1936\n",
      "Epoch [24/50], Step [515/735], Loss: 0.8015\n",
      "Epoch [24/50], Step [516/735], Loss: 0.3622\n",
      "Epoch [24/50], Step [517/735], Loss: 0.3684\n",
      "Epoch [24/50], Step [518/735], Loss: 0.0542\n",
      "Epoch [24/50], Step [519/735], Loss: 0.3833\n",
      "Epoch [24/50], Step [520/735], Loss: 0.4471\n",
      "Epoch [24/50], Step [521/735], Loss: 0.2546\n",
      "Epoch [24/50], Step [522/735], Loss: 0.3608\n",
      "Epoch [24/50], Step [523/735], Loss: 0.3344\n",
      "Epoch [24/50], Step [524/735], Loss: 0.7729\n",
      "Epoch [24/50], Step [525/735], Loss: 0.0798\n",
      "Epoch [24/50], Step [526/735], Loss: 0.1909\n",
      "Epoch [24/50], Step [527/735], Loss: 0.2795\n",
      "Epoch [24/50], Step [528/735], Loss: 0.4561\n",
      "Epoch [24/50], Step [529/735], Loss: 0.6792\n",
      "Epoch [24/50], Step [530/735], Loss: 0.5079\n",
      "Epoch [24/50], Step [531/735], Loss: 0.6151\n",
      "Epoch [24/50], Step [532/735], Loss: 0.2285\n",
      "Epoch [24/50], Step [533/735], Loss: 1.3081\n",
      "Epoch [24/50], Step [534/735], Loss: 0.2549\n",
      "Epoch [24/50], Step [535/735], Loss: 0.1271\n",
      "Epoch [24/50], Step [536/735], Loss: 1.0303\n",
      "Epoch [24/50], Step [537/735], Loss: 0.5194\n",
      "Epoch [24/50], Step [538/735], Loss: 0.6880\n",
      "Epoch [24/50], Step [539/735], Loss: 0.3537\n",
      "Epoch [24/50], Step [540/735], Loss: 0.1158\n",
      "Epoch [24/50], Step [541/735], Loss: 0.3561\n",
      "Epoch [24/50], Step [542/735], Loss: 0.2123\n",
      "Epoch [24/50], Step [543/735], Loss: 0.2834\n",
      "Epoch [24/50], Step [544/735], Loss: 0.5150\n",
      "Epoch [24/50], Step [545/735], Loss: 0.9388\n",
      "Epoch [24/50], Step [546/735], Loss: 0.1396\n",
      "Epoch [24/50], Step [547/735], Loss: 1.8241\n",
      "Epoch [24/50], Step [548/735], Loss: 0.5088\n",
      "Epoch [24/50], Step [549/735], Loss: 0.7619\n",
      "Epoch [24/50], Step [550/735], Loss: 0.2883\n",
      "Epoch [24/50], Step [551/735], Loss: 0.1068\n",
      "Epoch [24/50], Step [552/735], Loss: 0.3597\n",
      "Epoch [24/50], Step [553/735], Loss: 0.2494\n",
      "Epoch [24/50], Step [554/735], Loss: 0.2559\n",
      "Epoch [24/50], Step [555/735], Loss: 0.4223\n",
      "Epoch [24/50], Step [556/735], Loss: 0.7820\n",
      "Epoch [24/50], Step [557/735], Loss: 0.2683\n",
      "Epoch [24/50], Step [558/735], Loss: 0.2937\n",
      "Epoch [24/50], Step [559/735], Loss: 0.4213\n",
      "Epoch [24/50], Step [560/735], Loss: 1.0690\n",
      "Epoch [24/50], Step [561/735], Loss: 0.1900\n",
      "Epoch [24/50], Step [562/735], Loss: 0.1716\n",
      "Epoch [24/50], Step [563/735], Loss: 0.5024\n",
      "Epoch [24/50], Step [564/735], Loss: 0.4810\n",
      "Epoch [24/50], Step [565/735], Loss: 0.1181\n",
      "Epoch [24/50], Step [566/735], Loss: 0.9656\n",
      "Epoch [24/50], Step [567/735], Loss: 0.4840\n",
      "Epoch [24/50], Step [568/735], Loss: 0.5206\n",
      "Epoch [24/50], Step [569/735], Loss: 0.7342\n",
      "Epoch [24/50], Step [570/735], Loss: 0.4047\n",
      "Epoch [24/50], Step [571/735], Loss: 5.1108\n",
      "Epoch [24/50], Step [572/735], Loss: 0.1334\n",
      "Epoch [24/50], Step [573/735], Loss: 0.5586\n",
      "Epoch [24/50], Step [574/735], Loss: 1.2039\n",
      "Epoch [24/50], Step [575/735], Loss: 0.1232\n",
      "Epoch [24/50], Step [576/735], Loss: 0.1512\n",
      "Epoch [24/50], Step [577/735], Loss: 0.4221\n",
      "Epoch [24/50], Step [578/735], Loss: 0.3476\n",
      "Epoch [24/50], Step [579/735], Loss: 1.4951\n",
      "Epoch [24/50], Step [580/735], Loss: 0.3549\n",
      "Epoch [24/50], Step [581/735], Loss: 0.1539\n",
      "Epoch [24/50], Step [582/735], Loss: 0.5537\n",
      "Epoch [24/50], Step [583/735], Loss: 0.4674\n",
      "Epoch [24/50], Step [584/735], Loss: 0.6245\n",
      "Epoch [24/50], Step [585/735], Loss: 1.0782\n",
      "Epoch [24/50], Step [586/735], Loss: 0.6164\n",
      "Epoch [24/50], Step [587/735], Loss: 0.0760\n",
      "Epoch [24/50], Step [588/735], Loss: 0.3795\n",
      "Epoch [24/50], Step [589/735], Loss: 0.7325\n",
      "Epoch [24/50], Step [590/735], Loss: 0.7304\n",
      "Epoch [24/50], Step [591/735], Loss: 0.6898\n",
      "Epoch [24/50], Step [592/735], Loss: 0.3640\n",
      "Epoch [24/50], Step [593/735], Loss: 0.4663\n",
      "Epoch [24/50], Step [594/735], Loss: 0.4903\n",
      "Epoch [24/50], Step [595/735], Loss: 0.3295\n",
      "Epoch [24/50], Step [596/735], Loss: 0.1198\n",
      "Epoch [24/50], Step [597/735], Loss: 0.3038\n",
      "Epoch [24/50], Step [598/735], Loss: 0.3707\n",
      "Epoch [24/50], Step [599/735], Loss: 0.2287\n",
      "Epoch [24/50], Step [600/735], Loss: 0.2248\n",
      "Epoch [24/50], Step [601/735], Loss: 0.3454\n",
      "Epoch [24/50], Step [602/735], Loss: 0.2042\n",
      "Epoch [24/50], Step [603/735], Loss: 0.1821\n",
      "Epoch [24/50], Step [604/735], Loss: 0.3602\n",
      "Epoch [24/50], Step [605/735], Loss: 0.5013\n",
      "Epoch [24/50], Step [606/735], Loss: 5.3219\n",
      "Epoch [24/50], Step [607/735], Loss: 1.3788\n",
      "Epoch [24/50], Step [608/735], Loss: 0.2566\n",
      "Epoch [24/50], Step [609/735], Loss: 1.3840\n",
      "Epoch [24/50], Step [610/735], Loss: 0.1537\n",
      "Epoch [24/50], Step [611/735], Loss: 0.1863\n",
      "Epoch [24/50], Step [612/735], Loss: 0.5794\n",
      "Epoch [24/50], Step [613/735], Loss: 0.4463\n",
      "Epoch [24/50], Step [614/735], Loss: 0.3463\n",
      "Epoch [24/50], Step [615/735], Loss: 0.9351\n",
      "Epoch [24/50], Step [616/735], Loss: 0.8943\n",
      "Epoch [24/50], Step [617/735], Loss: 0.3582\n",
      "Epoch [24/50], Step [618/735], Loss: 0.3313\n",
      "Epoch [24/50], Step [619/735], Loss: 0.1858\n",
      "Epoch [24/50], Step [620/735], Loss: 0.3352\n",
      "Epoch [24/50], Step [621/735], Loss: 0.1445\n",
      "Epoch [24/50], Step [622/735], Loss: 0.1032\n",
      "Epoch [24/50], Step [623/735], Loss: 0.2916\n",
      "Epoch [24/50], Step [624/735], Loss: 0.2501\n",
      "Epoch [24/50], Step [625/735], Loss: 1.7521\n",
      "Epoch [24/50], Step [626/735], Loss: 0.4794\n",
      "Epoch [24/50], Step [627/735], Loss: 0.2258\n",
      "Epoch [24/50], Step [628/735], Loss: 0.5134\n",
      "Epoch [24/50], Step [629/735], Loss: 0.1088\n",
      "Epoch [24/50], Step [630/735], Loss: 0.1058\n",
      "Epoch [24/50], Step [631/735], Loss: 0.2726\n",
      "Epoch [24/50], Step [632/735], Loss: 0.5027\n",
      "Epoch [24/50], Step [633/735], Loss: 0.3911\n",
      "Epoch [24/50], Step [634/735], Loss: 0.3013\n",
      "Epoch [24/50], Step [635/735], Loss: 0.7460\n",
      "Epoch [24/50], Step [636/735], Loss: 0.4501\n",
      "Epoch [24/50], Step [637/735], Loss: 0.8809\n",
      "Epoch [24/50], Step [638/735], Loss: 0.1502\n",
      "Epoch [24/50], Step [639/735], Loss: 0.2817\n",
      "Epoch [24/50], Step [640/735], Loss: 0.5842\n",
      "Epoch [24/50], Step [641/735], Loss: 0.0607\n",
      "Epoch [24/50], Step [642/735], Loss: 0.1933\n",
      "Epoch [24/50], Step [643/735], Loss: 0.4258\n",
      "Epoch [24/50], Step [644/735], Loss: 0.4346\n",
      "Epoch [24/50], Step [645/735], Loss: 0.2720\n",
      "Epoch [24/50], Step [646/735], Loss: 0.3487\n",
      "Epoch [24/50], Step [647/735], Loss: 1.3714\n",
      "Epoch [24/50], Step [648/735], Loss: 0.4044\n",
      "Epoch [24/50], Step [649/735], Loss: 0.2721\n",
      "Epoch [24/50], Step [650/735], Loss: 0.3214\n",
      "Epoch [24/50], Step [651/735], Loss: 0.3877\n",
      "Epoch [24/50], Step [652/735], Loss: 0.2816\n",
      "Epoch [24/50], Step [653/735], Loss: 0.1653\n",
      "Epoch [24/50], Step [654/735], Loss: 0.6228\n",
      "Epoch [24/50], Step [655/735], Loss: 0.2101\n",
      "Epoch [24/50], Step [656/735], Loss: 0.6555\n",
      "Epoch [24/50], Step [657/735], Loss: 0.2066\n",
      "Epoch [24/50], Step [658/735], Loss: 0.3999\n",
      "Epoch [24/50], Step [659/735], Loss: 0.3561\n",
      "Epoch [24/50], Step [660/735], Loss: 0.9611\n",
      "Epoch [24/50], Step [661/735], Loss: 0.2363\n",
      "Epoch [24/50], Step [662/735], Loss: 0.1503\n",
      "Epoch [24/50], Step [663/735], Loss: 0.2320\n",
      "Epoch [24/50], Step [664/735], Loss: 0.2973\n",
      "Epoch [24/50], Step [665/735], Loss: 0.5107\n",
      "Epoch [24/50], Step [666/735], Loss: 0.5275\n",
      "Epoch [24/50], Step [667/735], Loss: 0.5360\n",
      "Epoch [24/50], Step [668/735], Loss: 0.4553\n",
      "Epoch [24/50], Step [669/735], Loss: 0.2590\n",
      "Epoch [24/50], Step [670/735], Loss: 0.2485\n",
      "Epoch [24/50], Step [671/735], Loss: 0.3366\n",
      "Epoch [24/50], Step [672/735], Loss: 0.5310\n",
      "Epoch [24/50], Step [673/735], Loss: 0.4308\n",
      "Epoch [24/50], Step [674/735], Loss: 0.2567\n",
      "Epoch [24/50], Step [675/735], Loss: 0.2542\n",
      "Epoch [24/50], Step [676/735], Loss: 0.4636\n",
      "Epoch [24/50], Step [677/735], Loss: 0.0327\n",
      "Epoch [24/50], Step [678/735], Loss: 0.1946\n",
      "Epoch [24/50], Step [679/735], Loss: 0.2015\n",
      "Epoch [24/50], Step [680/735], Loss: 0.3315\n",
      "Epoch [24/50], Step [681/735], Loss: 0.2366\n",
      "Epoch [24/50], Step [682/735], Loss: 0.1742\n",
      "Epoch [24/50], Step [683/735], Loss: 0.3081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Step [684/735], Loss: 0.6233\n",
      "Epoch [24/50], Step [685/735], Loss: 0.1138\n",
      "Epoch [24/50], Step [686/735], Loss: 0.2410\n",
      "Epoch [24/50], Step [687/735], Loss: 0.0494\n",
      "Epoch [24/50], Step [688/735], Loss: 0.4796\n",
      "Epoch [24/50], Step [689/735], Loss: 0.4073\n",
      "Epoch [24/50], Step [690/735], Loss: 0.1210\n",
      "Epoch [24/50], Step [691/735], Loss: 0.5317\n",
      "Epoch [24/50], Step [692/735], Loss: 0.5383\n",
      "Epoch [24/50], Step [693/735], Loss: 0.1135\n",
      "Epoch [24/50], Step [694/735], Loss: 0.1404\n",
      "Epoch [24/50], Step [695/735], Loss: 0.0740\n",
      "Epoch [24/50], Step [696/735], Loss: 0.9570\n",
      "Epoch [24/50], Step [697/735], Loss: 0.5857\n",
      "Epoch [24/50], Step [698/735], Loss: 0.1550\n",
      "Epoch [24/50], Step [699/735], Loss: 0.1744\n",
      "Epoch [24/50], Step [700/735], Loss: 0.0878\n",
      "Epoch [24/50], Step [701/735], Loss: 0.1893\n",
      "Epoch [24/50], Step [702/735], Loss: 0.5191\n",
      "Epoch [24/50], Step [703/735], Loss: 0.0897\n",
      "Epoch [24/50], Step [704/735], Loss: 0.0335\n",
      "Epoch [24/50], Step [705/735], Loss: 0.4277\n",
      "Epoch [24/50], Step [706/735], Loss: 0.2007\n",
      "Epoch [24/50], Step [707/735], Loss: 0.5604\n",
      "Epoch [24/50], Step [708/735], Loss: 0.0931\n",
      "Epoch [24/50], Step [709/735], Loss: 0.2135\n",
      "Epoch [24/50], Step [710/735], Loss: 0.2380\n",
      "Epoch [24/50], Step [711/735], Loss: 0.1790\n",
      "Epoch [24/50], Step [712/735], Loss: 0.4910\n",
      "Epoch [24/50], Step [713/735], Loss: 0.1264\n",
      "Epoch [24/50], Step [714/735], Loss: 0.3765\n",
      "Epoch [24/50], Step [715/735], Loss: 0.2066\n",
      "Epoch [24/50], Step [716/735], Loss: 0.2149\n",
      "Epoch [24/50], Step [717/735], Loss: 0.2213\n",
      "Epoch [24/50], Step [718/735], Loss: 0.2227\n",
      "Epoch [24/50], Step [719/735], Loss: 0.0442\n",
      "Epoch [24/50], Step [720/735], Loss: 0.1916\n",
      "Epoch [24/50], Step [721/735], Loss: 0.3870\n",
      "Epoch [24/50], Step [722/735], Loss: 0.1041\n",
      "Epoch [24/50], Step [723/735], Loss: 0.6093\n",
      "Epoch [24/50], Step [724/735], Loss: 0.3828\n",
      "Epoch [24/50], Step [725/735], Loss: 0.1094\n",
      "Epoch [24/50], Step [726/735], Loss: 0.0740\n",
      "Epoch [24/50], Step [727/735], Loss: 0.1545\n",
      "Epoch [24/50], Step [728/735], Loss: 0.2182\n",
      "Epoch [24/50], Step [729/735], Loss: 0.2424\n",
      "Epoch [24/50], Step [730/735], Loss: 0.3842\n",
      "Epoch [24/50], Step [731/735], Loss: 0.3780\n",
      "Epoch [24/50], Step [732/735], Loss: 0.8029\n",
      "Epoch [24/50], Step [733/735], Loss: 0.1427\n",
      "Epoch [24/50], Step [734/735], Loss: 0.1520\n",
      "Epoch [24/50], Step [735/735], Loss: 0.2520\n",
      "Epoch [25/50], Step [1/735], Loss: 0.6238\n",
      "Epoch [25/50], Step [2/735], Loss: 0.1432\n",
      "Epoch [25/50], Step [3/735], Loss: 0.1661\n",
      "Epoch [25/50], Step [4/735], Loss: 0.1856\n",
      "Epoch [25/50], Step [5/735], Loss: 0.5763\n",
      "Epoch [25/50], Step [6/735], Loss: 0.3757\n",
      "Epoch [25/50], Step [7/735], Loss: 1.4204\n",
      "Epoch [25/50], Step [8/735], Loss: 0.4189\n",
      "Epoch [25/50], Step [9/735], Loss: 1.0470\n",
      "Epoch [25/50], Step [10/735], Loss: 0.2797\n",
      "Epoch [25/50], Step [11/735], Loss: 0.3849\n",
      "Epoch [25/50], Step [12/735], Loss: 0.1008\n",
      "Epoch [25/50], Step [13/735], Loss: 0.7449\n",
      "Epoch [25/50], Step [14/735], Loss: 0.2036\n",
      "Epoch [25/50], Step [15/735], Loss: 1.1374\n",
      "Epoch [25/50], Step [16/735], Loss: 0.3875\n",
      "Epoch [25/50], Step [17/735], Loss: 1.1492\n",
      "Epoch [25/50], Step [18/735], Loss: 0.1318\n",
      "Epoch [25/50], Step [19/735], Loss: 0.5220\n",
      "Epoch [25/50], Step [20/735], Loss: 0.1479\n",
      "Epoch [25/50], Step [21/735], Loss: 0.2539\n",
      "Epoch [25/50], Step [22/735], Loss: 0.2096\n",
      "Epoch [25/50], Step [23/735], Loss: 0.3603\n",
      "Epoch [25/50], Step [24/735], Loss: 1.1538\n",
      "Epoch [25/50], Step [25/735], Loss: 0.6625\n",
      "Epoch [25/50], Step [26/735], Loss: 0.1025\n",
      "Epoch [25/50], Step [27/735], Loss: 0.2096\n",
      "Epoch [25/50], Step [28/735], Loss: 0.3288\n",
      "Epoch [25/50], Step [29/735], Loss: 0.5188\n",
      "Epoch [25/50], Step [30/735], Loss: 0.5248\n",
      "Epoch [25/50], Step [31/735], Loss: 0.2044\n",
      "Epoch [25/50], Step [32/735], Loss: 0.5833\n",
      "Epoch [25/50], Step [33/735], Loss: 0.3193\n",
      "Epoch [25/50], Step [34/735], Loss: 0.1666\n",
      "Epoch [25/50], Step [35/735], Loss: 0.5188\n",
      "Epoch [25/50], Step [36/735], Loss: 0.2366\n",
      "Epoch [25/50], Step [37/735], Loss: 0.0985\n",
      "Epoch [25/50], Step [38/735], Loss: 0.0870\n",
      "Epoch [25/50], Step [39/735], Loss: 0.3455\n",
      "Epoch [25/50], Step [40/735], Loss: 0.1294\n",
      "Epoch [25/50], Step [41/735], Loss: 0.7740\n",
      "Epoch [25/50], Step [42/735], Loss: 0.5474\n",
      "Epoch [25/50], Step [43/735], Loss: 0.3510\n",
      "Epoch [25/50], Step [44/735], Loss: 0.5551\n",
      "Epoch [25/50], Step [45/735], Loss: 0.5498\n",
      "Epoch [25/50], Step [46/735], Loss: 0.1822\n",
      "Epoch [25/50], Step [47/735], Loss: 0.3514\n",
      "Epoch [25/50], Step [48/735], Loss: 0.9017\n",
      "Epoch [25/50], Step [49/735], Loss: 0.1969\n",
      "Epoch [25/50], Step [50/735], Loss: 0.2334\n",
      "Epoch [25/50], Step [51/735], Loss: 0.4379\n",
      "Epoch [25/50], Step [52/735], Loss: 0.5676\n",
      "Epoch [25/50], Step [53/735], Loss: 0.5394\n",
      "Epoch [25/50], Step [54/735], Loss: 0.6011\n",
      "Epoch [25/50], Step [55/735], Loss: 0.6022\n",
      "Epoch [25/50], Step [56/735], Loss: 0.5841\n",
      "Epoch [25/50], Step [57/735], Loss: 0.2885\n",
      "Epoch [25/50], Step [58/735], Loss: 0.2161\n",
      "Epoch [25/50], Step [59/735], Loss: 0.2737\n",
      "Epoch [25/50], Step [60/735], Loss: 0.1836\n",
      "Epoch [25/50], Step [61/735], Loss: 0.2373\n",
      "Epoch [25/50], Step [62/735], Loss: 0.2271\n",
      "Epoch [25/50], Step [63/735], Loss: 0.3008\n",
      "Epoch [25/50], Step [64/735], Loss: 1.5795\n",
      "Epoch [25/50], Step [65/735], Loss: 0.2557\n",
      "Epoch [25/50], Step [66/735], Loss: 1.0452\n",
      "Epoch [25/50], Step [67/735], Loss: 0.2168\n",
      "Epoch [25/50], Step [68/735], Loss: 0.0969\n",
      "Epoch [25/50], Step [69/735], Loss: 0.0859\n",
      "Epoch [25/50], Step [70/735], Loss: 0.0748\n",
      "Epoch [25/50], Step [71/735], Loss: 0.6395\n",
      "Epoch [25/50], Step [72/735], Loss: 0.5859\n",
      "Epoch [25/50], Step [73/735], Loss: 0.2227\n",
      "Epoch [25/50], Step [74/735], Loss: 0.2651\n",
      "Epoch [25/50], Step [75/735], Loss: 0.3827\n",
      "Epoch [25/50], Step [76/735], Loss: 0.0535\n",
      "Epoch [25/50], Step [77/735], Loss: 0.5648\n",
      "Epoch [25/50], Step [78/735], Loss: 0.3956\n",
      "Epoch [25/50], Step [79/735], Loss: 0.1187\n",
      "Epoch [25/50], Step [80/735], Loss: 0.3366\n",
      "Epoch [25/50], Step [81/735], Loss: 0.4751\n",
      "Epoch [25/50], Step [82/735], Loss: 0.6170\n",
      "Epoch [25/50], Step [83/735], Loss: 0.2848\n",
      "Epoch [25/50], Step [84/735], Loss: 0.2167\n",
      "Epoch [25/50], Step [85/735], Loss: 0.2506\n",
      "Epoch [25/50], Step [86/735], Loss: 0.2454\n",
      "Epoch [25/50], Step [87/735], Loss: 0.3843\n",
      "Epoch [25/50], Step [88/735], Loss: 0.3413\n",
      "Epoch [25/50], Step [89/735], Loss: 0.2830\n",
      "Epoch [25/50], Step [90/735], Loss: 0.2914\n",
      "Epoch [25/50], Step [91/735], Loss: 0.4294\n",
      "Epoch [25/50], Step [92/735], Loss: 0.5957\n",
      "Epoch [25/50], Step [93/735], Loss: 0.7151\n",
      "Epoch [25/50], Step [94/735], Loss: 0.3245\n",
      "Epoch [25/50], Step [95/735], Loss: 0.2652\n",
      "Epoch [25/50], Step [96/735], Loss: 0.3538\n",
      "Epoch [25/50], Step [97/735], Loss: 0.3627\n",
      "Epoch [25/50], Step [98/735], Loss: 0.2238\n",
      "Epoch [25/50], Step [99/735], Loss: 0.4651\n",
      "Epoch [25/50], Step [100/735], Loss: 0.4950\n",
      "Epoch [25/50], Step [101/735], Loss: 0.2913\n",
      "Epoch [25/50], Step [102/735], Loss: 0.7522\n",
      "Epoch [25/50], Step [103/735], Loss: 5.0131\n",
      "Epoch [25/50], Step [104/735], Loss: 0.2176\n",
      "Epoch [25/50], Step [105/735], Loss: 0.2317\n",
      "Epoch [25/50], Step [106/735], Loss: 0.1622\n",
      "Epoch [25/50], Step [107/735], Loss: 0.2794\n",
      "Epoch [25/50], Step [108/735], Loss: 0.2946\n",
      "Epoch [25/50], Step [109/735], Loss: 0.5943\n",
      "Epoch [25/50], Step [110/735], Loss: 0.5103\n",
      "Epoch [25/50], Step [111/735], Loss: 0.7982\n",
      "Epoch [25/50], Step [112/735], Loss: 1.3764\n",
      "Epoch [25/50], Step [113/735], Loss: 0.1139\n",
      "Epoch [25/50], Step [114/735], Loss: 0.3564\n",
      "Epoch [25/50], Step [115/735], Loss: 0.2244\n",
      "Epoch [25/50], Step [116/735], Loss: 0.3848\n",
      "Epoch [25/50], Step [117/735], Loss: 0.2066\n",
      "Epoch [25/50], Step [118/735], Loss: 0.4843\n",
      "Epoch [25/50], Step [119/735], Loss: 0.0750\n",
      "Epoch [25/50], Step [120/735], Loss: 0.5183\n",
      "Epoch [25/50], Step [121/735], Loss: 0.1090\n",
      "Epoch [25/50], Step [122/735], Loss: 0.2233\n",
      "Epoch [25/50], Step [123/735], Loss: 0.1100\n",
      "Epoch [25/50], Step [124/735], Loss: 0.1168\n",
      "Epoch [25/50], Step [125/735], Loss: 0.3153\n",
      "Epoch [25/50], Step [126/735], Loss: 0.0862\n",
      "Epoch [25/50], Step [127/735], Loss: 0.2665\n",
      "Epoch [25/50], Step [128/735], Loss: 0.1427\n",
      "Epoch [25/50], Step [129/735], Loss: 0.1689\n",
      "Epoch [25/50], Step [130/735], Loss: 0.3838\n",
      "Epoch [25/50], Step [131/735], Loss: 0.1491\n",
      "Epoch [25/50], Step [132/735], Loss: 0.1582\n",
      "Epoch [25/50], Step [133/735], Loss: 0.9937\n",
      "Epoch [25/50], Step [134/735], Loss: 0.9028\n",
      "Epoch [25/50], Step [135/735], Loss: 0.3339\n",
      "Epoch [25/50], Step [136/735], Loss: 0.4422\n",
      "Epoch [25/50], Step [137/735], Loss: 1.2337\n",
      "Epoch [25/50], Step [138/735], Loss: 0.2271\n",
      "Epoch [25/50], Step [139/735], Loss: 0.5454\n",
      "Epoch [25/50], Step [140/735], Loss: 0.1569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Step [141/735], Loss: 0.8681\n",
      "Epoch [25/50], Step [142/735], Loss: 0.2851\n",
      "Epoch [25/50], Step [143/735], Loss: 0.3436\n",
      "Epoch [25/50], Step [144/735], Loss: 0.3541\n",
      "Epoch [25/50], Step [145/735], Loss: 0.3999\n",
      "Epoch [25/50], Step [146/735], Loss: 0.2187\n",
      "Epoch [25/50], Step [147/735], Loss: 0.3955\n",
      "Epoch [25/50], Step [148/735], Loss: 0.5534\n",
      "Epoch [25/50], Step [149/735], Loss: 0.0646\n",
      "Epoch [25/50], Step [150/735], Loss: 0.2098\n",
      "Epoch [25/50], Step [151/735], Loss: 0.3588\n",
      "Epoch [25/50], Step [152/735], Loss: 0.1474\n",
      "Epoch [25/50], Step [153/735], Loss: 0.7419\n",
      "Epoch [25/50], Step [154/735], Loss: 0.1980\n",
      "Epoch [25/50], Step [155/735], Loss: 0.0864\n",
      "Epoch [25/50], Step [156/735], Loss: 0.1958\n",
      "Epoch [25/50], Step [157/735], Loss: 0.7177\n",
      "Epoch [25/50], Step [158/735], Loss: 0.2166\n",
      "Epoch [25/50], Step [159/735], Loss: 0.2244\n",
      "Epoch [25/50], Step [160/735], Loss: 0.2188\n",
      "Epoch [25/50], Step [161/735], Loss: 0.2874\n",
      "Epoch [25/50], Step [162/735], Loss: 0.1524\n",
      "Epoch [25/50], Step [163/735], Loss: 0.1017\n",
      "Epoch [25/50], Step [164/735], Loss: 0.4383\n",
      "Epoch [25/50], Step [165/735], Loss: 0.4626\n",
      "Epoch [25/50], Step [166/735], Loss: 0.3251\n",
      "Epoch [25/50], Step [167/735], Loss: 0.1488\n",
      "Epoch [25/50], Step [168/735], Loss: 0.1980\n",
      "Epoch [25/50], Step [169/735], Loss: 0.1384\n",
      "Epoch [25/50], Step [170/735], Loss: 0.2285\n",
      "Epoch [25/50], Step [171/735], Loss: 0.1953\n",
      "Epoch [25/50], Step [172/735], Loss: 0.3589\n",
      "Epoch [25/50], Step [173/735], Loss: 0.1118\n",
      "Epoch [25/50], Step [174/735], Loss: 0.0761\n",
      "Epoch [25/50], Step [175/735], Loss: 0.2855\n",
      "Epoch [25/50], Step [176/735], Loss: 0.3737\n",
      "Epoch [25/50], Step [177/735], Loss: 0.2797\n",
      "Epoch [25/50], Step [178/735], Loss: 0.1289\n",
      "Epoch [25/50], Step [179/735], Loss: 0.1431\n",
      "Epoch [25/50], Step [180/735], Loss: 0.8708\n",
      "Epoch [25/50], Step [181/735], Loss: 0.9838\n",
      "Epoch [25/50], Step [182/735], Loss: 0.5057\n",
      "Epoch [25/50], Step [183/735], Loss: 0.0711\n",
      "Epoch [25/50], Step [184/735], Loss: 0.1095\n",
      "Epoch [25/50], Step [185/735], Loss: 0.3766\n",
      "Epoch [25/50], Step [186/735], Loss: 0.3764\n",
      "Epoch [25/50], Step [187/735], Loss: 0.4516\n",
      "Epoch [25/50], Step [188/735], Loss: 0.1057\n",
      "Epoch [25/50], Step [189/735], Loss: 0.1019\n",
      "Epoch [25/50], Step [190/735], Loss: 0.5112\n",
      "Epoch [25/50], Step [191/735], Loss: 0.1578\n",
      "Epoch [25/50], Step [192/735], Loss: 0.1567\n",
      "Epoch [25/50], Step [193/735], Loss: 0.1975\n",
      "Epoch [25/50], Step [194/735], Loss: 0.1505\n",
      "Epoch [25/50], Step [195/735], Loss: 0.5996\n",
      "Epoch [25/50], Step [196/735], Loss: 0.4731\n",
      "Epoch [25/50], Step [197/735], Loss: 0.1381\n",
      "Epoch [25/50], Step [198/735], Loss: 0.1386\n",
      "Epoch [25/50], Step [199/735], Loss: 0.7093\n",
      "Epoch [25/50], Step [200/735], Loss: 0.1633\n",
      "Epoch [25/50], Step [201/735], Loss: 0.3693\n",
      "Epoch [25/50], Step [202/735], Loss: 0.1422\n",
      "Epoch [25/50], Step [203/735], Loss: 0.4322\n",
      "Epoch [25/50], Step [204/735], Loss: 1.0624\n",
      "Epoch [25/50], Step [205/735], Loss: 0.6800\n",
      "Epoch [25/50], Step [206/735], Loss: 0.5021\n",
      "Epoch [25/50], Step [207/735], Loss: 0.7228\n",
      "Epoch [25/50], Step [208/735], Loss: 0.4998\n",
      "Epoch [25/50], Step [209/735], Loss: 2.1985\n",
      "Epoch [25/50], Step [210/735], Loss: 0.7925\n",
      "Epoch [25/50], Step [211/735], Loss: 0.3439\n",
      "Epoch [25/50], Step [212/735], Loss: 0.6912\n",
      "Epoch [25/50], Step [213/735], Loss: 0.0987\n",
      "Epoch [25/50], Step [214/735], Loss: 0.4656\n",
      "Epoch [25/50], Step [215/735], Loss: 0.2615\n",
      "Epoch [25/50], Step [216/735], Loss: 0.1886\n",
      "Epoch [25/50], Step [217/735], Loss: 0.0998\n",
      "Epoch [25/50], Step [218/735], Loss: 0.1976\n",
      "Epoch [25/50], Step [219/735], Loss: 0.0924\n",
      "Epoch [25/50], Step [220/735], Loss: 0.4214\n",
      "Epoch [25/50], Step [221/735], Loss: 0.7832\n",
      "Epoch [25/50], Step [222/735], Loss: 0.1468\n",
      "Epoch [25/50], Step [223/735], Loss: 0.1580\n",
      "Epoch [25/50], Step [224/735], Loss: 0.5017\n",
      "Epoch [25/50], Step [225/735], Loss: 0.2357\n",
      "Epoch [25/50], Step [226/735], Loss: 0.3234\n",
      "Epoch [25/50], Step [227/735], Loss: 0.2957\n",
      "Epoch [25/50], Step [228/735], Loss: 0.1290\n",
      "Epoch [25/50], Step [229/735], Loss: 0.1127\n",
      "Epoch [25/50], Step [230/735], Loss: 0.3002\n",
      "Epoch [25/50], Step [231/735], Loss: 0.7304\n",
      "Epoch [25/50], Step [232/735], Loss: 1.0773\n",
      "Epoch [25/50], Step [233/735], Loss: 0.2225\n",
      "Epoch [25/50], Step [234/735], Loss: 0.4321\n",
      "Epoch [25/50], Step [235/735], Loss: 0.1516\n",
      "Epoch [25/50], Step [236/735], Loss: 0.6289\n",
      "Epoch [25/50], Step [237/735], Loss: 0.1728\n",
      "Epoch [25/50], Step [238/735], Loss: 0.4377\n",
      "Epoch [25/50], Step [239/735], Loss: 0.2329\n",
      "Epoch [25/50], Step [240/735], Loss: 0.3544\n",
      "Epoch [25/50], Step [241/735], Loss: 0.1132\n",
      "Epoch [25/50], Step [242/735], Loss: 0.2364\n",
      "Epoch [25/50], Step [243/735], Loss: 0.3574\n",
      "Epoch [25/50], Step [244/735], Loss: 0.2837\n",
      "Epoch [25/50], Step [245/735], Loss: 1.2493\n",
      "Epoch [25/50], Step [246/735], Loss: 0.7197\n",
      "Epoch [25/50], Step [247/735], Loss: 0.5204\n",
      "Epoch [25/50], Step [248/735], Loss: 0.3902\n",
      "Epoch [25/50], Step [249/735], Loss: 0.2085\n",
      "Epoch [25/50], Step [250/735], Loss: 0.3532\n",
      "Epoch [25/50], Step [251/735], Loss: 0.1835\n",
      "Epoch [25/50], Step [252/735], Loss: 0.4220\n",
      "Epoch [25/50], Step [253/735], Loss: 0.4488\n",
      "Epoch [25/50], Step [254/735], Loss: 0.4534\n",
      "Epoch [25/50], Step [255/735], Loss: 1.6622\n",
      "Epoch [25/50], Step [256/735], Loss: 0.5643\n",
      "Epoch [25/50], Step [257/735], Loss: 0.3830\n",
      "Epoch [25/50], Step [258/735], Loss: 0.4187\n",
      "Epoch [25/50], Step [259/735], Loss: 0.2826\n",
      "Epoch [25/50], Step [260/735], Loss: 0.4516\n",
      "Epoch [25/50], Step [261/735], Loss: 0.2747\n",
      "Epoch [25/50], Step [262/735], Loss: 0.2496\n",
      "Epoch [25/50], Step [263/735], Loss: 5.1409\n",
      "Epoch [25/50], Step [264/735], Loss: 0.3733\n",
      "Epoch [25/50], Step [265/735], Loss: 0.1587\n",
      "Epoch [25/50], Step [266/735], Loss: 0.1798\n",
      "Epoch [25/50], Step [267/735], Loss: 0.6348\n",
      "Epoch [25/50], Step [268/735], Loss: 0.7952\n",
      "Epoch [25/50], Step [269/735], Loss: 0.5591\n",
      "Epoch [25/50], Step [270/735], Loss: 0.2431\n",
      "Epoch [25/50], Step [271/735], Loss: 0.1525\n",
      "Epoch [25/50], Step [272/735], Loss: 0.3564\n",
      "Epoch [25/50], Step [273/735], Loss: 1.2193\n",
      "Epoch [25/50], Step [274/735], Loss: 0.1779\n",
      "Epoch [25/50], Step [275/735], Loss: 0.3581\n",
      "Epoch [25/50], Step [276/735], Loss: 0.6348\n",
      "Epoch [25/50], Step [277/735], Loss: 0.4593\n",
      "Epoch [25/50], Step [278/735], Loss: 0.1150\n",
      "Epoch [25/50], Step [279/735], Loss: 0.2240\n",
      "Epoch [25/50], Step [280/735], Loss: 0.1477\n",
      "Epoch [25/50], Step [281/735], Loss: 0.6503\n",
      "Epoch [25/50], Step [282/735], Loss: 0.1924\n",
      "Epoch [25/50], Step [283/735], Loss: 0.0732\n",
      "Epoch [25/50], Step [284/735], Loss: 0.1077\n",
      "Epoch [25/50], Step [285/735], Loss: 0.4762\n",
      "Epoch [25/50], Step [286/735], Loss: 0.1518\n",
      "Epoch [25/50], Step [287/735], Loss: 0.2894\n",
      "Epoch [25/50], Step [288/735], Loss: 0.0875\n",
      "Epoch [25/50], Step [289/735], Loss: 0.3365\n",
      "Epoch [25/50], Step [290/735], Loss: 0.3128\n",
      "Epoch [25/50], Step [291/735], Loss: 0.0705\n",
      "Epoch [25/50], Step [292/735], Loss: 0.0751\n",
      "Epoch [25/50], Step [293/735], Loss: 0.0728\n",
      "Epoch [25/50], Step [294/735], Loss: 0.4156\n",
      "Epoch [25/50], Step [295/735], Loss: 0.2747\n",
      "Epoch [25/50], Step [296/735], Loss: 0.3481\n",
      "Epoch [25/50], Step [297/735], Loss: 0.0876\n",
      "Epoch [25/50], Step [298/735], Loss: 0.0756\n",
      "Epoch [25/50], Step [299/735], Loss: 0.1172\n",
      "Epoch [25/50], Step [300/735], Loss: 0.0469\n",
      "Epoch [25/50], Step [301/735], Loss: 0.2080\n",
      "Epoch [25/50], Step [302/735], Loss: 0.1193\n",
      "Epoch [25/50], Step [303/735], Loss: 1.5995\n",
      "Epoch [25/50], Step [304/735], Loss: 0.1411\n",
      "Epoch [25/50], Step [305/735], Loss: 0.2940\n",
      "Epoch [25/50], Step [306/735], Loss: 0.5023\n",
      "Epoch [25/50], Step [307/735], Loss: 0.5332\n",
      "Epoch [25/50], Step [308/735], Loss: 0.1288\n",
      "Epoch [25/50], Step [309/735], Loss: 0.4675\n",
      "Epoch [25/50], Step [310/735], Loss: 0.1686\n",
      "Epoch [25/50], Step [311/735], Loss: 0.9688\n",
      "Epoch [25/50], Step [312/735], Loss: 0.4504\n",
      "Epoch [25/50], Step [313/735], Loss: 0.2163\n",
      "Epoch [25/50], Step [314/735], Loss: 0.2179\n",
      "Epoch [25/50], Step [315/735], Loss: 0.6462\n",
      "Epoch [25/50], Step [316/735], Loss: 0.1625\n",
      "Epoch [25/50], Step [317/735], Loss: 0.1440\n",
      "Epoch [25/50], Step [318/735], Loss: 0.1369\n",
      "Epoch [25/50], Step [319/735], Loss: 0.2710\n",
      "Epoch [25/50], Step [320/735], Loss: 1.4090\n",
      "Epoch [25/50], Step [321/735], Loss: 0.0672\n",
      "Epoch [25/50], Step [322/735], Loss: 0.3015\n",
      "Epoch [25/50], Step [323/735], Loss: 0.2042\n",
      "Epoch [25/50], Step [324/735], Loss: 0.2394\n",
      "Epoch [25/50], Step [325/735], Loss: 0.2336\n",
      "Epoch [25/50], Step [326/735], Loss: 0.0833\n",
      "Epoch [25/50], Step [327/735], Loss: 0.2008\n",
      "Epoch [25/50], Step [328/735], Loss: 0.3498\n",
      "Epoch [25/50], Step [329/735], Loss: 0.2553\n",
      "Epoch [25/50], Step [330/735], Loss: 0.1941\n",
      "Epoch [25/50], Step [331/735], Loss: 0.2293\n",
      "Epoch [25/50], Step [332/735], Loss: 0.3112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Step [333/735], Loss: 0.3654\n",
      "Epoch [25/50], Step [334/735], Loss: 0.2126\n",
      "Epoch [25/50], Step [335/735], Loss: 0.6606\n",
      "Epoch [25/50], Step [336/735], Loss: 0.6041\n",
      "Epoch [25/50], Step [337/735], Loss: 0.4911\n",
      "Epoch [25/50], Step [338/735], Loss: 0.6388\n",
      "Epoch [25/50], Step [339/735], Loss: 0.5032\n",
      "Epoch [25/50], Step [340/735], Loss: 0.2607\n",
      "Epoch [25/50], Step [341/735], Loss: 0.1341\n",
      "Epoch [25/50], Step [342/735], Loss: 0.1042\n",
      "Epoch [25/50], Step [343/735], Loss: 0.2179\n",
      "Epoch [25/50], Step [344/735], Loss: 0.3173\n",
      "Epoch [25/50], Step [345/735], Loss: 0.3007\n",
      "Epoch [25/50], Step [346/735], Loss: 0.4359\n",
      "Epoch [25/50], Step [347/735], Loss: 0.2139\n",
      "Epoch [25/50], Step [348/735], Loss: 0.3153\n",
      "Epoch [25/50], Step [349/735], Loss: 0.1532\n",
      "Epoch [25/50], Step [350/735], Loss: 0.4770\n",
      "Epoch [25/50], Step [351/735], Loss: 0.1090\n",
      "Epoch [25/50], Step [352/735], Loss: 0.3373\n",
      "Epoch [25/50], Step [353/735], Loss: 0.6525\n",
      "Epoch [25/50], Step [354/735], Loss: 0.5932\n",
      "Epoch [25/50], Step [355/735], Loss: 0.2398\n",
      "Epoch [25/50], Step [356/735], Loss: 0.4326\n",
      "Epoch [25/50], Step [357/735], Loss: 5.3497\n",
      "Epoch [25/50], Step [358/735], Loss: 0.5794\n",
      "Epoch [25/50], Step [359/735], Loss: 0.1999\n",
      "Epoch [25/50], Step [360/735], Loss: 0.6512\n",
      "Epoch [25/50], Step [361/735], Loss: 0.5918\n",
      "Epoch [25/50], Step [362/735], Loss: 0.4366\n",
      "Epoch [25/50], Step [363/735], Loss: 0.2520\n",
      "Epoch [25/50], Step [364/735], Loss: 0.5210\n",
      "Epoch [25/50], Step [365/735], Loss: 0.3009\n",
      "Epoch [25/50], Step [366/735], Loss: 1.3404\n",
      "Epoch [25/50], Step [367/735], Loss: 0.3304\n",
      "Epoch [25/50], Step [368/735], Loss: 0.4118\n",
      "Epoch [25/50], Step [369/735], Loss: 0.3339\n",
      "Epoch [25/50], Step [370/735], Loss: 0.6768\n",
      "Epoch [25/50], Step [371/735], Loss: 0.6937\n",
      "Epoch [25/50], Step [372/735], Loss: 0.1215\n",
      "Epoch [25/50], Step [373/735], Loss: 0.2491\n",
      "Epoch [25/50], Step [374/735], Loss: 0.3711\n",
      "Epoch [25/50], Step [375/735], Loss: 0.5073\n",
      "Epoch [25/50], Step [376/735], Loss: 0.3663\n",
      "Epoch [25/50], Step [377/735], Loss: 0.4799\n",
      "Epoch [25/50], Step [378/735], Loss: 1.8294\n",
      "Epoch [25/50], Step [379/735], Loss: 0.3962\n",
      "Epoch [25/50], Step [380/735], Loss: 1.0424\n",
      "Epoch [25/50], Step [381/735], Loss: 1.1391\n",
      "Epoch [25/50], Step [382/735], Loss: 0.1103\n",
      "Epoch [25/50], Step [383/735], Loss: 0.2776\n",
      "Epoch [25/50], Step [384/735], Loss: 0.1357\n",
      "Epoch [25/50], Step [385/735], Loss: 0.4670\n",
      "Epoch [25/50], Step [386/735], Loss: 0.4302\n",
      "Epoch [25/50], Step [387/735], Loss: 0.0534\n",
      "Epoch [25/50], Step [388/735], Loss: 0.1655\n",
      "Epoch [25/50], Step [389/735], Loss: 0.3088\n",
      "Epoch [25/50], Step [390/735], Loss: 0.2023\n",
      "Epoch [25/50], Step [391/735], Loss: 0.3664\n",
      "Epoch [25/50], Step [392/735], Loss: 0.5072\n",
      "Epoch [25/50], Step [393/735], Loss: 1.5197\n",
      "Epoch [25/50], Step [394/735], Loss: 0.2081\n",
      "Epoch [25/50], Step [395/735], Loss: 0.2273\n",
      "Epoch [25/50], Step [396/735], Loss: 0.1616\n",
      "Epoch [25/50], Step [397/735], Loss: 0.4627\n",
      "Epoch [25/50], Step [398/735], Loss: 0.1481\n",
      "Epoch [25/50], Step [399/735], Loss: 0.1889\n",
      "Epoch [25/50], Step [400/735], Loss: 0.3683\n",
      "Epoch [25/50], Step [401/735], Loss: 0.1153\n",
      "Epoch [25/50], Step [402/735], Loss: 0.4916\n",
      "Epoch [25/50], Step [403/735], Loss: 0.3264\n",
      "Epoch [25/50], Step [404/735], Loss: 0.5556\n",
      "Epoch [25/50], Step [405/735], Loss: 0.1462\n",
      "Epoch [25/50], Step [406/735], Loss: 0.3563\n",
      "Epoch [25/50], Step [407/735], Loss: 0.0870\n",
      "Epoch [25/50], Step [408/735], Loss: 0.4279\n",
      "Epoch [25/50], Step [409/735], Loss: 0.2084\n",
      "Epoch [25/50], Step [410/735], Loss: 0.1621\n",
      "Epoch [25/50], Step [411/735], Loss: 1.4737\n",
      "Epoch [25/50], Step [412/735], Loss: 0.3639\n",
      "Epoch [25/50], Step [413/735], Loss: 0.2933\n",
      "Epoch [25/50], Step [414/735], Loss: 0.1566\n",
      "Epoch [25/50], Step [415/735], Loss: 0.0544\n",
      "Epoch [25/50], Step [416/735], Loss: 0.3493\n",
      "Epoch [25/50], Step [417/735], Loss: 0.2310\n",
      "Epoch [25/50], Step [418/735], Loss: 0.4009\n",
      "Epoch [25/50], Step [419/735], Loss: 0.3773\n",
      "Epoch [25/50], Step [420/735], Loss: 0.1110\n",
      "Epoch [25/50], Step [421/735], Loss: 0.2603\n",
      "Epoch [25/50], Step [422/735], Loss: 0.7459\n",
      "Epoch [25/50], Step [423/735], Loss: 0.1679\n",
      "Epoch [25/50], Step [424/735], Loss: 0.2411\n",
      "Epoch [25/50], Step [425/735], Loss: 0.1088\n",
      "Epoch [25/50], Step [426/735], Loss: 0.2881\n",
      "Epoch [25/50], Step [427/735], Loss: 0.4772\n",
      "Epoch [25/50], Step [428/735], Loss: 0.2189\n",
      "Epoch [25/50], Step [429/735], Loss: 0.1743\n",
      "Epoch [25/50], Step [430/735], Loss: 0.4859\n",
      "Epoch [25/50], Step [431/735], Loss: 0.3994\n",
      "Epoch [25/50], Step [432/735], Loss: 0.1464\n",
      "Epoch [25/50], Step [433/735], Loss: 0.2382\n",
      "Epoch [25/50], Step [434/735], Loss: 0.4158\n",
      "Epoch [25/50], Step [435/735], Loss: 0.3585\n",
      "Epoch [25/50], Step [436/735], Loss: 0.1265\n",
      "Epoch [25/50], Step [437/735], Loss: 0.7865\n",
      "Epoch [25/50], Step [438/735], Loss: 0.1948\n",
      "Epoch [25/50], Step [439/735], Loss: 0.5289\n",
      "Epoch [25/50], Step [440/735], Loss: 0.1086\n",
      "Epoch [25/50], Step [441/735], Loss: 0.1111\n",
      "Epoch [25/50], Step [442/735], Loss: 1.2226\n",
      "Epoch [25/50], Step [443/735], Loss: 0.1947\n",
      "Epoch [25/50], Step [444/735], Loss: 0.4486\n",
      "Epoch [25/50], Step [445/735], Loss: 0.2204\n",
      "Epoch [25/50], Step [446/735], Loss: 0.1011\n",
      "Epoch [25/50], Step [447/735], Loss: 0.1633\n",
      "Epoch [25/50], Step [448/735], Loss: 0.4754\n",
      "Epoch [25/50], Step [449/735], Loss: 0.1378\n",
      "Epoch [25/50], Step [450/735], Loss: 0.2200\n",
      "Epoch [25/50], Step [451/735], Loss: 0.4796\n",
      "Epoch [25/50], Step [452/735], Loss: 0.3494\n",
      "Epoch [25/50], Step [453/735], Loss: 0.1693\n",
      "Epoch [25/50], Step [454/735], Loss: 0.1797\n",
      "Epoch [25/50], Step [455/735], Loss: 0.2102\n",
      "Epoch [25/50], Step [456/735], Loss: 0.3764\n",
      "Epoch [25/50], Step [457/735], Loss: 0.3570\n",
      "Epoch [25/50], Step [458/735], Loss: 0.3839\n",
      "Epoch [25/50], Step [459/735], Loss: 0.7016\n",
      "Epoch [25/50], Step [460/735], Loss: 0.1381\n",
      "Epoch [25/50], Step [461/735], Loss: 0.1191\n",
      "Epoch [25/50], Step [462/735], Loss: 0.5670\n",
      "Epoch [25/50], Step [463/735], Loss: 0.3020\n",
      "Epoch [25/50], Step [464/735], Loss: 0.0652\n",
      "Epoch [25/50], Step [465/735], Loss: 0.1244\n",
      "Epoch [25/50], Step [466/735], Loss: 0.2432\n",
      "Epoch [25/50], Step [467/735], Loss: 0.5246\n",
      "Epoch [25/50], Step [468/735], Loss: 0.5202\n",
      "Epoch [25/50], Step [469/735], Loss: 0.1332\n",
      "Epoch [25/50], Step [470/735], Loss: 0.8383\n",
      "Epoch [25/50], Step [471/735], Loss: 0.4163\n",
      "Epoch [25/50], Step [472/735], Loss: 0.3027\n",
      "Epoch [25/50], Step [473/735], Loss: 0.2843\n",
      "Epoch [25/50], Step [474/735], Loss: 0.1211\n",
      "Epoch [25/50], Step [475/735], Loss: 0.2778\n",
      "Epoch [25/50], Step [476/735], Loss: 0.2403\n",
      "Epoch [25/50], Step [477/735], Loss: 0.4496\n",
      "Epoch [25/50], Step [478/735], Loss: 0.3584\n",
      "Epoch [25/50], Step [479/735], Loss: 0.1257\n",
      "Epoch [25/50], Step [480/735], Loss: 0.4527\n",
      "Epoch [25/50], Step [481/735], Loss: 0.2835\n",
      "Epoch [25/50], Step [482/735], Loss: 0.6963\n",
      "Epoch [25/50], Step [483/735], Loss: 0.3618\n",
      "Epoch [25/50], Step [484/735], Loss: 0.7293\n",
      "Epoch [25/50], Step [485/735], Loss: 0.2899\n",
      "Epoch [25/50], Step [486/735], Loss: 0.3317\n",
      "Epoch [25/50], Step [487/735], Loss: 0.1801\n",
      "Epoch [25/50], Step [488/735], Loss: 0.1703\n",
      "Epoch [25/50], Step [489/735], Loss: 0.8397\n",
      "Epoch [25/50], Step [490/735], Loss: 0.6790\n",
      "Epoch [25/50], Step [491/735], Loss: 0.5915\n",
      "Epoch [25/50], Step [492/735], Loss: 0.4113\n",
      "Epoch [25/50], Step [493/735], Loss: 0.5478\n",
      "Epoch [25/50], Step [494/735], Loss: 0.7668\n",
      "Epoch [25/50], Step [495/735], Loss: 0.5313\n",
      "Epoch [25/50], Step [496/735], Loss: 0.2385\n",
      "Epoch [25/50], Step [497/735], Loss: 0.5342\n",
      "Epoch [25/50], Step [498/735], Loss: 0.6266\n",
      "Epoch [25/50], Step [499/735], Loss: 0.3876\n",
      "Epoch [25/50], Step [500/735], Loss: 0.8846\n",
      "Epoch [25/50], Step [501/735], Loss: 1.0780\n",
      "Epoch [25/50], Step [502/735], Loss: 0.3151\n",
      "Epoch [25/50], Step [503/735], Loss: 0.2658\n",
      "Epoch [25/50], Step [504/735], Loss: 0.5139\n",
      "Epoch [25/50], Step [505/735], Loss: 0.4050\n",
      "Epoch [25/50], Step [506/735], Loss: 0.5874\n",
      "Epoch [25/50], Step [507/735], Loss: 0.3772\n",
      "Epoch [25/50], Step [508/735], Loss: 1.2352\n",
      "Epoch [25/50], Step [509/735], Loss: 0.4287\n",
      "Epoch [25/50], Step [510/735], Loss: 0.5593\n",
      "Epoch [25/50], Step [511/735], Loss: 0.2613\n",
      "Epoch [25/50], Step [512/735], Loss: 0.1652\n",
      "Epoch [25/50], Step [513/735], Loss: 0.1327\n",
      "Epoch [25/50], Step [514/735], Loss: 0.2291\n",
      "Epoch [25/50], Step [515/735], Loss: 0.3689\n",
      "Epoch [25/50], Step [516/735], Loss: 5.0998\n",
      "Epoch [25/50], Step [517/735], Loss: 0.2550\n",
      "Epoch [25/50], Step [518/735], Loss: 0.1750\n",
      "Epoch [25/50], Step [519/735], Loss: 0.3628\n",
      "Epoch [25/50], Step [520/735], Loss: 0.7193\n",
      "Epoch [25/50], Step [521/735], Loss: 0.1785\n",
      "Epoch [25/50], Step [522/735], Loss: 0.2596\n",
      "Epoch [25/50], Step [523/735], Loss: 0.2398\n",
      "Epoch [25/50], Step [524/735], Loss: 0.1408\n",
      "Epoch [25/50], Step [525/735], Loss: 0.2495\n",
      "Epoch [25/50], Step [526/735], Loss: 0.2198\n",
      "Epoch [25/50], Step [527/735], Loss: 0.3240\n",
      "Epoch [25/50], Step [528/735], Loss: 1.2344\n",
      "Epoch [25/50], Step [529/735], Loss: 0.1777\n",
      "Epoch [25/50], Step [530/735], Loss: 0.1089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Step [531/735], Loss: 0.2038\n",
      "Epoch [25/50], Step [532/735], Loss: 0.3234\n",
      "Epoch [25/50], Step [533/735], Loss: 0.6104\n",
      "Epoch [25/50], Step [534/735], Loss: 0.4606\n",
      "Epoch [25/50], Step [535/735], Loss: 0.9037\n",
      "Epoch [25/50], Step [536/735], Loss: 0.3220\n",
      "Epoch [25/50], Step [537/735], Loss: 0.4055\n",
      "Epoch [25/50], Step [538/735], Loss: 1.3758\n",
      "Epoch [25/50], Step [539/735], Loss: 0.4476\n",
      "Epoch [25/50], Step [540/735], Loss: 0.3763\n",
      "Epoch [25/50], Step [541/735], Loss: 0.2241\n",
      "Epoch [25/50], Step [542/735], Loss: 0.3825\n",
      "Epoch [25/50], Step [543/735], Loss: 0.4098\n",
      "Epoch [25/50], Step [544/735], Loss: 0.5066\n",
      "Epoch [25/50], Step [545/735], Loss: 0.1892\n",
      "Epoch [25/50], Step [546/735], Loss: 0.5416\n",
      "Epoch [25/50], Step [547/735], Loss: 0.8881\n",
      "Epoch [25/50], Step [548/735], Loss: 0.1042\n",
      "Epoch [25/50], Step [549/735], Loss: 0.1722\n",
      "Epoch [25/50], Step [550/735], Loss: 1.6425\n",
      "Epoch [25/50], Step [551/735], Loss: 0.4128\n",
      "Epoch [25/50], Step [552/735], Loss: 0.3296\n",
      "Epoch [25/50], Step [553/735], Loss: 0.2028\n",
      "Epoch [25/50], Step [554/735], Loss: 0.5222\n",
      "Epoch [25/50], Step [555/735], Loss: 0.2885\n",
      "Epoch [25/50], Step [556/735], Loss: 0.0967\n",
      "Epoch [25/50], Step [557/735], Loss: 1.0404\n",
      "Epoch [25/50], Step [558/735], Loss: 0.3315\n",
      "Epoch [25/50], Step [559/735], Loss: 0.1855\n",
      "Epoch [25/50], Step [560/735], Loss: 0.4708\n",
      "Epoch [25/50], Step [561/735], Loss: 0.7109\n",
      "Epoch [25/50], Step [562/735], Loss: 0.2953\n",
      "Epoch [25/50], Step [563/735], Loss: 0.3094\n",
      "Epoch [25/50], Step [564/735], Loss: 0.2581\n",
      "Epoch [25/50], Step [565/735], Loss: 0.3706\n",
      "Epoch [25/50], Step [566/735], Loss: 0.2060\n",
      "Epoch [25/50], Step [567/735], Loss: 0.3082\n",
      "Epoch [25/50], Step [568/735], Loss: 0.0701\n",
      "Epoch [25/50], Step [569/735], Loss: 0.5215\n",
      "Epoch [25/50], Step [570/735], Loss: 0.2049\n",
      "Epoch [25/50], Step [571/735], Loss: 0.2102\n",
      "Epoch [25/50], Step [572/735], Loss: 0.1034\n",
      "Epoch [25/50], Step [573/735], Loss: 0.1458\n",
      "Epoch [25/50], Step [574/735], Loss: 5.3631\n",
      "Epoch [25/50], Step [575/735], Loss: 0.2266\n",
      "Epoch [25/50], Step [576/735], Loss: 1.4124\n",
      "Epoch [25/50], Step [577/735], Loss: 0.1238\n",
      "Epoch [25/50], Step [578/735], Loss: 0.2934\n",
      "Epoch [25/50], Step [579/735], Loss: 0.2906\n",
      "Epoch [25/50], Step [580/735], Loss: 0.2723\n",
      "Epoch [25/50], Step [581/735], Loss: 0.4554\n",
      "Epoch [25/50], Step [582/735], Loss: 0.1333\n",
      "Epoch [25/50], Step [583/735], Loss: 0.4680\n",
      "Epoch [25/50], Step [584/735], Loss: 0.2179\n",
      "Epoch [25/50], Step [585/735], Loss: 0.3370\n",
      "Epoch [25/50], Step [586/735], Loss: 0.1812\n",
      "Epoch [25/50], Step [587/735], Loss: 0.4631\n",
      "Epoch [25/50], Step [588/735], Loss: 0.4373\n",
      "Epoch [25/50], Step [589/735], Loss: 0.1353\n",
      "Epoch [25/50], Step [590/735], Loss: 0.3134\n",
      "Epoch [25/50], Step [591/735], Loss: 0.1260\n",
      "Epoch [25/50], Step [592/735], Loss: 0.1946\n",
      "Epoch [25/50], Step [593/735], Loss: 0.1146\n",
      "Epoch [25/50], Step [594/735], Loss: 0.1690\n",
      "Epoch [25/50], Step [595/735], Loss: 0.0859\n",
      "Epoch [25/50], Step [596/735], Loss: 0.1438\n",
      "Epoch [25/50], Step [597/735], Loss: 0.9572\n",
      "Epoch [25/50], Step [598/735], Loss: 0.1527\n",
      "Epoch [25/50], Step [599/735], Loss: 0.1650\n",
      "Epoch [25/50], Step [600/735], Loss: 0.7298\n",
      "Epoch [25/50], Step [601/735], Loss: 0.1718\n",
      "Epoch [25/50], Step [602/735], Loss: 0.5473\n",
      "Epoch [25/50], Step [603/735], Loss: 0.2905\n",
      "Epoch [25/50], Step [604/735], Loss: 0.2050\n",
      "Epoch [25/50], Step [605/735], Loss: 0.3089\n",
      "Epoch [25/50], Step [606/735], Loss: 0.5408\n",
      "Epoch [25/50], Step [607/735], Loss: 0.2939\n",
      "Epoch [25/50], Step [608/735], Loss: 0.5329\n",
      "Epoch [25/50], Step [609/735], Loss: 0.1318\n",
      "Epoch [25/50], Step [610/735], Loss: 0.3220\n",
      "Epoch [25/50], Step [611/735], Loss: 0.2712\n",
      "Epoch [25/50], Step [612/735], Loss: 0.0740\n",
      "Epoch [25/50], Step [613/735], Loss: 0.2475\n",
      "Epoch [25/50], Step [614/735], Loss: 0.4814\n",
      "Epoch [25/50], Step [615/735], Loss: 0.6605\n",
      "Epoch [25/50], Step [616/735], Loss: 0.2682\n",
      "Epoch [25/50], Step [617/735], Loss: 0.0781\n",
      "Epoch [25/50], Step [618/735], Loss: 0.4625\n",
      "Epoch [25/50], Step [619/735], Loss: 0.1034\n",
      "Epoch [25/50], Step [620/735], Loss: 0.7610\n",
      "Epoch [25/50], Step [621/735], Loss: 1.1307\n",
      "Epoch [25/50], Step [622/735], Loss: 0.0798\n",
      "Epoch [25/50], Step [623/735], Loss: 0.1410\n",
      "Epoch [25/50], Step [624/735], Loss: 0.3924\n",
      "Epoch [25/50], Step [625/735], Loss: 1.0041\n",
      "Epoch [25/50], Step [626/735], Loss: 0.1755\n",
      "Epoch [25/50], Step [627/735], Loss: 0.4737\n",
      "Epoch [25/50], Step [628/735], Loss: 0.2139\n",
      "Epoch [25/50], Step [629/735], Loss: 0.5018\n",
      "Epoch [25/50], Step [630/735], Loss: 0.8593\n",
      "Epoch [25/50], Step [631/735], Loss: 0.1498\n",
      "Epoch [25/50], Step [632/735], Loss: 0.1136\n",
      "Epoch [25/50], Step [633/735], Loss: 1.0242\n",
      "Epoch [25/50], Step [634/735], Loss: 0.4929\n",
      "Epoch [25/50], Step [635/735], Loss: 0.3512\n",
      "Epoch [25/50], Step [636/735], Loss: 0.2180\n",
      "Epoch [25/50], Step [637/735], Loss: 0.2044\n",
      "Epoch [25/50], Step [638/735], Loss: 1.0444\n",
      "Epoch [25/50], Step [639/735], Loss: 0.1592\n",
      "Epoch [25/50], Step [640/735], Loss: 0.2143\n",
      "Epoch [25/50], Step [641/735], Loss: 0.2947\n",
      "Epoch [25/50], Step [642/735], Loss: 0.6676\n",
      "Epoch [25/50], Step [643/735], Loss: 0.1685\n",
      "Epoch [25/50], Step [644/735], Loss: 0.2220\n",
      "Epoch [25/50], Step [645/735], Loss: 1.1533\n",
      "Epoch [25/50], Step [646/735], Loss: 0.3071\n",
      "Epoch [25/50], Step [647/735], Loss: 0.4079\n",
      "Epoch [25/50], Step [648/735], Loss: 0.1428\n",
      "Epoch [25/50], Step [649/735], Loss: 1.6963\n",
      "Epoch [25/50], Step [650/735], Loss: 0.1548\n",
      "Epoch [25/50], Step [651/735], Loss: 0.4131\n",
      "Epoch [25/50], Step [652/735], Loss: 0.3384\n",
      "Epoch [25/50], Step [653/735], Loss: 0.2575\n",
      "Epoch [25/50], Step [654/735], Loss: 0.1798\n",
      "Epoch [25/50], Step [655/735], Loss: 0.1462\n",
      "Epoch [25/50], Step [656/735], Loss: 0.4837\n",
      "Epoch [25/50], Step [657/735], Loss: 0.2340\n",
      "Epoch [25/50], Step [658/735], Loss: 0.0956\n",
      "Epoch [25/50], Step [659/735], Loss: 0.1017\n",
      "Epoch [25/50], Step [660/735], Loss: 0.1289\n",
      "Epoch [25/50], Step [661/735], Loss: 0.5405\n",
      "Epoch [25/50], Step [662/735], Loss: 0.1250\n",
      "Epoch [25/50], Step [663/735], Loss: 0.3011\n",
      "Epoch [25/50], Step [664/735], Loss: 0.6205\n",
      "Epoch [25/50], Step [665/735], Loss: 0.4510\n",
      "Epoch [25/50], Step [666/735], Loss: 0.3239\n",
      "Epoch [25/50], Step [667/735], Loss: 0.1172\n",
      "Epoch [25/50], Step [668/735], Loss: 0.2499\n",
      "Epoch [25/50], Step [669/735], Loss: 0.2515\n",
      "Epoch [25/50], Step [670/735], Loss: 0.5573\n",
      "Epoch [25/50], Step [671/735], Loss: 0.6812\n",
      "Epoch [25/50], Step [672/735], Loss: 0.2455\n",
      "Epoch [25/50], Step [673/735], Loss: 0.3849\n",
      "Epoch [25/50], Step [674/735], Loss: 0.8827\n",
      "Epoch [25/50], Step [675/735], Loss: 0.6009\n",
      "Epoch [25/50], Step [676/735], Loss: 0.8818\n",
      "Epoch [25/50], Step [677/735], Loss: 0.4492\n",
      "Epoch [25/50], Step [678/735], Loss: 0.6086\n",
      "Epoch [25/50], Step [679/735], Loss: 0.3143\n",
      "Epoch [25/50], Step [680/735], Loss: 0.5103\n",
      "Epoch [25/50], Step [681/735], Loss: 0.5584\n",
      "Epoch [25/50], Step [682/735], Loss: 0.1599\n",
      "Epoch [25/50], Step [683/735], Loss: 0.2724\n",
      "Epoch [25/50], Step [684/735], Loss: 0.5494\n",
      "Epoch [25/50], Step [685/735], Loss: 0.3292\n",
      "Epoch [25/50], Step [686/735], Loss: 0.3904\n",
      "Epoch [25/50], Step [687/735], Loss: 0.3547\n",
      "Epoch [25/50], Step [688/735], Loss: 0.3768\n",
      "Epoch [25/50], Step [689/735], Loss: 0.3226\n",
      "Epoch [25/50], Step [690/735], Loss: 0.4251\n",
      "Epoch [25/50], Step [691/735], Loss: 0.1464\n",
      "Epoch [25/50], Step [692/735], Loss: 0.1376\n",
      "Epoch [25/50], Step [693/735], Loss: 0.4604\n",
      "Epoch [25/50], Step [694/735], Loss: 0.1352\n",
      "Epoch [25/50], Step [695/735], Loss: 0.5891\n",
      "Epoch [25/50], Step [696/735], Loss: 0.1878\n",
      "Epoch [25/50], Step [697/735], Loss: 0.3493\n",
      "Epoch [25/50], Step [698/735], Loss: 0.2609\n",
      "Epoch [25/50], Step [699/735], Loss: 0.3100\n",
      "Epoch [25/50], Step [700/735], Loss: 1.3526\n",
      "Epoch [25/50], Step [701/735], Loss: 0.2900\n",
      "Epoch [25/50], Step [702/735], Loss: 0.2144\n",
      "Epoch [25/50], Step [703/735], Loss: 0.2285\n",
      "Epoch [25/50], Step [704/735], Loss: 0.7262\n",
      "Epoch [25/50], Step [705/735], Loss: 0.3926\n",
      "Epoch [25/50], Step [706/735], Loss: 0.2688\n",
      "Epoch [25/50], Step [707/735], Loss: 0.1795\n",
      "Epoch [25/50], Step [708/735], Loss: 0.0970\n",
      "Epoch [25/50], Step [709/735], Loss: 0.3634\n",
      "Epoch [25/50], Step [710/735], Loss: 0.2719\n",
      "Epoch [25/50], Step [711/735], Loss: 0.1015\n",
      "Epoch [25/50], Step [712/735], Loss: 0.7012\n",
      "Epoch [25/50], Step [713/735], Loss: 0.6305\n",
      "Epoch [25/50], Step [714/735], Loss: 0.5907\n",
      "Epoch [25/50], Step [715/735], Loss: 0.1629\n",
      "Epoch [25/50], Step [716/735], Loss: 0.1087\n",
      "Epoch [25/50], Step [717/735], Loss: 0.6279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Step [718/735], Loss: 0.1192\n",
      "Epoch [25/50], Step [719/735], Loss: 0.5345\n",
      "Epoch [25/50], Step [720/735], Loss: 0.3091\n",
      "Epoch [25/50], Step [721/735], Loss: 0.2393\n",
      "Epoch [25/50], Step [722/735], Loss: 0.2079\n",
      "Epoch [25/50], Step [723/735], Loss: 0.1317\n",
      "Epoch [25/50], Step [724/735], Loss: 0.2145\n",
      "Epoch [25/50], Step [725/735], Loss: 0.5707\n",
      "Epoch [25/50], Step [726/735], Loss: 0.4327\n",
      "Epoch [25/50], Step [727/735], Loss: 0.3756\n",
      "Epoch [25/50], Step [728/735], Loss: 0.2418\n",
      "Epoch [25/50], Step [729/735], Loss: 0.1976\n",
      "Epoch [25/50], Step [730/735], Loss: 0.1028\n",
      "Epoch [25/50], Step [731/735], Loss: 0.4498\n",
      "Epoch [25/50], Step [732/735], Loss: 1.9827\n",
      "Epoch [25/50], Step [733/735], Loss: 0.7449\n",
      "Epoch [25/50], Step [734/735], Loss: 0.1834\n",
      "Epoch [25/50], Step [735/735], Loss: 2.9023\n",
      "Epoch [26/50], Step [1/735], Loss: 0.1672\n",
      "Epoch [26/50], Step [2/735], Loss: 0.2074\n",
      "Epoch [26/50], Step [3/735], Loss: 0.4005\n",
      "Epoch [26/50], Step [4/735], Loss: 0.2875\n",
      "Epoch [26/50], Step [5/735], Loss: 0.2435\n",
      "Epoch [26/50], Step [6/735], Loss: 0.7568\n",
      "Epoch [26/50], Step [7/735], Loss: 0.1092\n",
      "Epoch [26/50], Step [8/735], Loss: 0.5646\n",
      "Epoch [26/50], Step [9/735], Loss: 0.4475\n",
      "Epoch [26/50], Step [10/735], Loss: 0.4059\n",
      "Epoch [26/50], Step [11/735], Loss: 0.7102\n",
      "Epoch [26/50], Step [12/735], Loss: 0.4221\n",
      "Epoch [26/50], Step [13/735], Loss: 0.7031\n",
      "Epoch [26/50], Step [14/735], Loss: 0.1937\n",
      "Epoch [26/50], Step [15/735], Loss: 0.1498\n",
      "Epoch [26/50], Step [16/735], Loss: 0.2731\n",
      "Epoch [26/50], Step [17/735], Loss: 0.4488\n",
      "Epoch [26/50], Step [18/735], Loss: 0.2982\n",
      "Epoch [26/50], Step [19/735], Loss: 0.5996\n",
      "Epoch [26/50], Step [20/735], Loss: 0.2512\n",
      "Epoch [26/50], Step [21/735], Loss: 0.5751\n",
      "Epoch [26/50], Step [22/735], Loss: 0.3889\n",
      "Epoch [26/50], Step [23/735], Loss: 0.3064\n",
      "Epoch [26/50], Step [24/735], Loss: 0.0809\n",
      "Epoch [26/50], Step [25/735], Loss: 0.3293\n",
      "Epoch [26/50], Step [26/735], Loss: 0.6802\n",
      "Epoch [26/50], Step [27/735], Loss: 0.2109\n",
      "Epoch [26/50], Step [28/735], Loss: 0.3120\n",
      "Epoch [26/50], Step [29/735], Loss: 0.4279\n",
      "Epoch [26/50], Step [30/735], Loss: 0.8573\n",
      "Epoch [26/50], Step [31/735], Loss: 0.3655\n",
      "Epoch [26/50], Step [32/735], Loss: 0.5316\n",
      "Epoch [26/50], Step [33/735], Loss: 0.3720\n",
      "Epoch [26/50], Step [34/735], Loss: 0.3762\n",
      "Epoch [26/50], Step [35/735], Loss: 0.0930\n",
      "Epoch [26/50], Step [36/735], Loss: 0.2722\n",
      "Epoch [26/50], Step [37/735], Loss: 0.2864\n",
      "Epoch [26/50], Step [38/735], Loss: 0.2083\n",
      "Epoch [26/50], Step [39/735], Loss: 0.7881\n",
      "Epoch [26/50], Step [40/735], Loss: 0.4166\n",
      "Epoch [26/50], Step [41/735], Loss: 0.3081\n",
      "Epoch [26/50], Step [42/735], Loss: 0.0981\n",
      "Epoch [26/50], Step [43/735], Loss: 0.2156\n",
      "Epoch [26/50], Step [44/735], Loss: 0.1629\n",
      "Epoch [26/50], Step [45/735], Loss: 0.0651\n",
      "Epoch [26/50], Step [46/735], Loss: 0.1107\n",
      "Epoch [26/50], Step [47/735], Loss: 0.1682\n",
      "Epoch [26/50], Step [48/735], Loss: 0.1479\n",
      "Epoch [26/50], Step [49/735], Loss: 0.7262\n",
      "Epoch [26/50], Step [50/735], Loss: 0.6438\n",
      "Epoch [26/50], Step [51/735], Loss: 0.4460\n",
      "Epoch [26/50], Step [52/735], Loss: 0.6866\n",
      "Epoch [26/50], Step [53/735], Loss: 0.1996\n",
      "Epoch [26/50], Step [54/735], Loss: 0.0663\n",
      "Epoch [26/50], Step [55/735], Loss: 0.3837\n",
      "Epoch [26/50], Step [56/735], Loss: 0.0994\n",
      "Epoch [26/50], Step [57/735], Loss: 1.1299\n",
      "Epoch [26/50], Step [58/735], Loss: 0.3076\n",
      "Epoch [26/50], Step [59/735], Loss: 0.8384\n",
      "Epoch [26/50], Step [60/735], Loss: 0.3768\n",
      "Epoch [26/50], Step [61/735], Loss: 0.3586\n",
      "Epoch [26/50], Step [62/735], Loss: 0.4443\n",
      "Epoch [26/50], Step [63/735], Loss: 0.5843\n",
      "Epoch [26/50], Step [64/735], Loss: 0.0625\n",
      "Epoch [26/50], Step [65/735], Loss: 0.7614\n",
      "Epoch [26/50], Step [66/735], Loss: 0.1375\n",
      "Epoch [26/50], Step [67/735], Loss: 0.3114\n",
      "Epoch [26/50], Step [68/735], Loss: 0.7766\n",
      "Epoch [26/50], Step [69/735], Loss: 0.2153\n",
      "Epoch [26/50], Step [70/735], Loss: 0.1949\n",
      "Epoch [26/50], Step [71/735], Loss: 0.9087\n",
      "Epoch [26/50], Step [72/735], Loss: 0.2517\n",
      "Epoch [26/50], Step [73/735], Loss: 0.4592\n",
      "Epoch [26/50], Step [74/735], Loss: 0.7078\n",
      "Epoch [26/50], Step [75/735], Loss: 0.1922\n",
      "Epoch [26/50], Step [76/735], Loss: 0.1530\n",
      "Epoch [26/50], Step [77/735], Loss: 0.6344\n",
      "Epoch [26/50], Step [78/735], Loss: 0.4853\n",
      "Epoch [26/50], Step [79/735], Loss: 1.9277\n",
      "Epoch [26/50], Step [80/735], Loss: 0.2247\n",
      "Epoch [26/50], Step [81/735], Loss: 0.1542\n",
      "Epoch [26/50], Step [82/735], Loss: 0.1547\n",
      "Epoch [26/50], Step [83/735], Loss: 1.3655\n",
      "Epoch [26/50], Step [84/735], Loss: 0.5608\n",
      "Epoch [26/50], Step [85/735], Loss: 0.3337\n",
      "Epoch [26/50], Step [86/735], Loss: 0.9191\n",
      "Epoch [26/50], Step [87/735], Loss: 0.1263\n",
      "Epoch [26/50], Step [88/735], Loss: 0.4544\n",
      "Epoch [26/50], Step [89/735], Loss: 0.2253\n",
      "Epoch [26/50], Step [90/735], Loss: 0.4304\n",
      "Epoch [26/50], Step [91/735], Loss: 0.4158\n",
      "Epoch [26/50], Step [92/735], Loss: 0.2638\n",
      "Epoch [26/50], Step [93/735], Loss: 0.1750\n",
      "Epoch [26/50], Step [94/735], Loss: 0.3966\n",
      "Epoch [26/50], Step [95/735], Loss: 0.1418\n",
      "Epoch [26/50], Step [96/735], Loss: 1.3177\n",
      "Epoch [26/50], Step [97/735], Loss: 0.1782\n",
      "Epoch [26/50], Step [98/735], Loss: 0.0806\n",
      "Epoch [26/50], Step [99/735], Loss: 0.4789\n",
      "Epoch [26/50], Step [100/735], Loss: 0.3527\n",
      "Epoch [26/50], Step [101/735], Loss: 0.7828\n",
      "Epoch [26/50], Step [102/735], Loss: 0.2521\n",
      "Epoch [26/50], Step [103/735], Loss: 0.2359\n",
      "Epoch [26/50], Step [104/735], Loss: 0.7991\n",
      "Epoch [26/50], Step [105/735], Loss: 0.1158\n",
      "Epoch [26/50], Step [106/735], Loss: 0.1395\n",
      "Epoch [26/50], Step [107/735], Loss: 0.1340\n",
      "Epoch [26/50], Step [108/735], Loss: 0.3555\n",
      "Epoch [26/50], Step [109/735], Loss: 0.4729\n",
      "Epoch [26/50], Step [110/735], Loss: 0.2110\n",
      "Epoch [26/50], Step [111/735], Loss: 0.1218\n",
      "Epoch [26/50], Step [112/735], Loss: 0.2742\n",
      "Epoch [26/50], Step [113/735], Loss: 0.2534\n",
      "Epoch [26/50], Step [114/735], Loss: 0.2788\n",
      "Epoch [26/50], Step [115/735], Loss: 0.7247\n",
      "Epoch [26/50], Step [116/735], Loss: 0.2445\n",
      "Epoch [26/50], Step [117/735], Loss: 0.1759\n",
      "Epoch [26/50], Step [118/735], Loss: 0.1343\n",
      "Epoch [26/50], Step [119/735], Loss: 0.3762\n",
      "Epoch [26/50], Step [120/735], Loss: 0.7853\n",
      "Epoch [26/50], Step [121/735], Loss: 0.1607\n",
      "Epoch [26/50], Step [122/735], Loss: 0.2435\n",
      "Epoch [26/50], Step [123/735], Loss: 0.1317\n",
      "Epoch [26/50], Step [124/735], Loss: 0.3607\n",
      "Epoch [26/50], Step [125/735], Loss: 0.1542\n",
      "Epoch [26/50], Step [126/735], Loss: 0.1756\n",
      "Epoch [26/50], Step [127/735], Loss: 0.8216\n",
      "Epoch [26/50], Step [128/735], Loss: 0.2103\n",
      "Epoch [26/50], Step [129/735], Loss: 0.3174\n",
      "Epoch [26/50], Step [130/735], Loss: 0.1423\n",
      "Epoch [26/50], Step [131/735], Loss: 0.3942\n",
      "Epoch [26/50], Step [132/735], Loss: 0.7112\n",
      "Epoch [26/50], Step [133/735], Loss: 0.4543\n",
      "Epoch [26/50], Step [134/735], Loss: 0.1515\n",
      "Epoch [26/50], Step [135/735], Loss: 0.2960\n",
      "Epoch [26/50], Step [136/735], Loss: 0.3998\n",
      "Epoch [26/50], Step [137/735], Loss: 0.2153\n",
      "Epoch [26/50], Step [138/735], Loss: 0.3089\n",
      "Epoch [26/50], Step [139/735], Loss: 0.1262\n",
      "Epoch [26/50], Step [140/735], Loss: 1.6048\n",
      "Epoch [26/50], Step [141/735], Loss: 0.4394\n",
      "Epoch [26/50], Step [142/735], Loss: 0.6920\n",
      "Epoch [26/50], Step [143/735], Loss: 0.2151\n",
      "Epoch [26/50], Step [144/735], Loss: 0.2501\n",
      "Epoch [26/50], Step [145/735], Loss: 0.6496\n",
      "Epoch [26/50], Step [146/735], Loss: 0.4919\n",
      "Epoch [26/50], Step [147/735], Loss: 0.8651\n",
      "Epoch [26/50], Step [148/735], Loss: 0.3044\n",
      "Epoch [26/50], Step [149/735], Loss: 0.2650\n",
      "Epoch [26/50], Step [150/735], Loss: 0.1613\n",
      "Epoch [26/50], Step [151/735], Loss: 0.2078\n",
      "Epoch [26/50], Step [152/735], Loss: 0.1759\n",
      "Epoch [26/50], Step [153/735], Loss: 0.4712\n",
      "Epoch [26/50], Step [154/735], Loss: 0.2599\n",
      "Epoch [26/50], Step [155/735], Loss: 0.2718\n",
      "Epoch [26/50], Step [156/735], Loss: 0.0958\n",
      "Epoch [26/50], Step [157/735], Loss: 0.1772\n",
      "Epoch [26/50], Step [158/735], Loss: 0.3618\n",
      "Epoch [26/50], Step [159/735], Loss: 0.3127\n",
      "Epoch [26/50], Step [160/735], Loss: 0.1012\n",
      "Epoch [26/50], Step [161/735], Loss: 0.1523\n",
      "Epoch [26/50], Step [162/735], Loss: 0.1217\n",
      "Epoch [26/50], Step [163/735], Loss: 0.3378\n",
      "Epoch [26/50], Step [164/735], Loss: 0.2312\n",
      "Epoch [26/50], Step [165/735], Loss: 0.2063\n",
      "Epoch [26/50], Step [166/735], Loss: 1.1326\n",
      "Epoch [26/50], Step [167/735], Loss: 0.3551\n",
      "Epoch [26/50], Step [168/735], Loss: 0.5374\n",
      "Epoch [26/50], Step [169/735], Loss: 0.3788\n",
      "Epoch [26/50], Step [170/735], Loss: 0.2749\n",
      "Epoch [26/50], Step [171/735], Loss: 0.8541\n",
      "Epoch [26/50], Step [172/735], Loss: 0.2999\n",
      "Epoch [26/50], Step [173/735], Loss: 4.6795\n",
      "Epoch [26/50], Step [174/735], Loss: 0.2702\n",
      "Epoch [26/50], Step [175/735], Loss: 0.1242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Step [176/735], Loss: 0.3372\n",
      "Epoch [26/50], Step [177/735], Loss: 0.1786\n",
      "Epoch [26/50], Step [178/735], Loss: 0.3050\n",
      "Epoch [26/50], Step [179/735], Loss: 0.6833\n",
      "Epoch [26/50], Step [180/735], Loss: 0.2966\n",
      "Epoch [26/50], Step [181/735], Loss: 0.4807\n",
      "Epoch [26/50], Step [182/735], Loss: 0.1588\n",
      "Epoch [26/50], Step [183/735], Loss: 0.3791\n",
      "Epoch [26/50], Step [184/735], Loss: 0.2486\n",
      "Epoch [26/50], Step [185/735], Loss: 0.0589\n",
      "Epoch [26/50], Step [186/735], Loss: 0.5965\n",
      "Epoch [26/50], Step [187/735], Loss: 0.5858\n",
      "Epoch [26/50], Step [188/735], Loss: 0.2910\n",
      "Epoch [26/50], Step [189/735], Loss: 0.5198\n",
      "Epoch [26/50], Step [190/735], Loss: 1.2128\n",
      "Epoch [26/50], Step [191/735], Loss: 0.1450\n",
      "Epoch [26/50], Step [192/735], Loss: 0.2706\n",
      "Epoch [26/50], Step [193/735], Loss: 0.3352\n",
      "Epoch [26/50], Step [194/735], Loss: 0.3960\n",
      "Epoch [26/50], Step [195/735], Loss: 0.2112\n",
      "Epoch [26/50], Step [196/735], Loss: 0.7500\n",
      "Epoch [26/50], Step [197/735], Loss: 0.3154\n",
      "Epoch [26/50], Step [198/735], Loss: 0.2537\n",
      "Epoch [26/50], Step [199/735], Loss: 0.1528\n",
      "Epoch [26/50], Step [200/735], Loss: 0.3998\n",
      "Epoch [26/50], Step [201/735], Loss: 0.2517\n",
      "Epoch [26/50], Step [202/735], Loss: 0.2428\n",
      "Epoch [26/50], Step [203/735], Loss: 0.2176\n",
      "Epoch [26/50], Step [204/735], Loss: 0.2634\n",
      "Epoch [26/50], Step [205/735], Loss: 0.4361\n",
      "Epoch [26/50], Step [206/735], Loss: 0.5585\n",
      "Epoch [26/50], Step [207/735], Loss: 0.3236\n",
      "Epoch [26/50], Step [208/735], Loss: 0.4014\n",
      "Epoch [26/50], Step [209/735], Loss: 0.2447\n",
      "Epoch [26/50], Step [210/735], Loss: 0.2107\n",
      "Epoch [26/50], Step [211/735], Loss: 0.0962\n",
      "Epoch [26/50], Step [212/735], Loss: 0.2126\n",
      "Epoch [26/50], Step [213/735], Loss: 0.1030\n",
      "Epoch [26/50], Step [214/735], Loss: 0.3473\n",
      "Epoch [26/50], Step [215/735], Loss: 0.4404\n",
      "Epoch [26/50], Step [216/735], Loss: 0.2938\n",
      "Epoch [26/50], Step [217/735], Loss: 0.0979\n",
      "Epoch [26/50], Step [218/735], Loss: 0.2375\n",
      "Epoch [26/50], Step [219/735], Loss: 0.1135\n",
      "Epoch [26/50], Step [220/735], Loss: 0.1944\n",
      "Epoch [26/50], Step [221/735], Loss: 0.1317\n",
      "Epoch [26/50], Step [222/735], Loss: 0.1114\n",
      "Epoch [26/50], Step [223/735], Loss: 0.0657\n",
      "Epoch [26/50], Step [224/735], Loss: 0.0537\n",
      "Epoch [26/50], Step [225/735], Loss: 0.4590\n",
      "Epoch [26/50], Step [226/735], Loss: 0.5232\n",
      "Epoch [26/50], Step [227/735], Loss: 0.0658\n",
      "Epoch [26/50], Step [228/735], Loss: 0.3639\n",
      "Epoch [26/50], Step [229/735], Loss: 0.3970\n",
      "Epoch [26/50], Step [230/735], Loss: 0.4015\n",
      "Epoch [26/50], Step [231/735], Loss: 0.3420\n",
      "Epoch [26/50], Step [232/735], Loss: 0.5578\n",
      "Epoch [26/50], Step [233/735], Loss: 0.5485\n",
      "Epoch [26/50], Step [234/735], Loss: 0.1977\n",
      "Epoch [26/50], Step [235/735], Loss: 0.1176\n",
      "Epoch [26/50], Step [236/735], Loss: 0.0762\n",
      "Epoch [26/50], Step [237/735], Loss: 0.3578\n",
      "Epoch [26/50], Step [238/735], Loss: 0.0967\n",
      "Epoch [26/50], Step [239/735], Loss: 0.3307\n",
      "Epoch [26/50], Step [240/735], Loss: 0.2399\n",
      "Epoch [26/50], Step [241/735], Loss: 0.2602\n",
      "Epoch [26/50], Step [242/735], Loss: 0.2435\n",
      "Epoch [26/50], Step [243/735], Loss: 0.2061\n",
      "Epoch [26/50], Step [244/735], Loss: 0.3660\n",
      "Epoch [26/50], Step [245/735], Loss: 0.3041\n",
      "Epoch [26/50], Step [246/735], Loss: 0.3141\n",
      "Epoch [26/50], Step [247/735], Loss: 0.1283\n",
      "Epoch [26/50], Step [248/735], Loss: 0.3099\n",
      "Epoch [26/50], Step [249/735], Loss: 0.1920\n",
      "Epoch [26/50], Step [250/735], Loss: 0.3052\n",
      "Epoch [26/50], Step [251/735], Loss: 0.5072\n",
      "Epoch [26/50], Step [252/735], Loss: 0.1603\n",
      "Epoch [26/50], Step [253/735], Loss: 0.8104\n",
      "Epoch [26/50], Step [254/735], Loss: 0.1104\n",
      "Epoch [26/50], Step [255/735], Loss: 0.4868\n",
      "Epoch [26/50], Step [256/735], Loss: 0.1188\n",
      "Epoch [26/50], Step [257/735], Loss: 1.4637\n",
      "Epoch [26/50], Step [258/735], Loss: 0.4649\n",
      "Epoch [26/50], Step [259/735], Loss: 0.4994\n",
      "Epoch [26/50], Step [260/735], Loss: 0.1324\n",
      "Epoch [26/50], Step [261/735], Loss: 0.0621\n",
      "Epoch [26/50], Step [262/735], Loss: 0.1842\n",
      "Epoch [26/50], Step [263/735], Loss: 0.0411\n",
      "Epoch [26/50], Step [264/735], Loss: 0.5960\n",
      "Epoch [26/50], Step [265/735], Loss: 0.2759\n",
      "Epoch [26/50], Step [266/735], Loss: 0.4864\n",
      "Epoch [26/50], Step [267/735], Loss: 0.5659\n",
      "Epoch [26/50], Step [268/735], Loss: 0.1475\n",
      "Epoch [26/50], Step [269/735], Loss: 0.2465\n",
      "Epoch [26/50], Step [270/735], Loss: 0.7167\n",
      "Epoch [26/50], Step [271/735], Loss: 0.2244\n",
      "Epoch [26/50], Step [272/735], Loss: 0.3370\n",
      "Epoch [26/50], Step [273/735], Loss: 0.4484\n",
      "Epoch [26/50], Step [274/735], Loss: 0.2138\n",
      "Epoch [26/50], Step [275/735], Loss: 0.1099\n",
      "Epoch [26/50], Step [276/735], Loss: 0.5274\n",
      "Epoch [26/50], Step [277/735], Loss: 0.7444\n",
      "Epoch [26/50], Step [278/735], Loss: 0.2178\n",
      "Epoch [26/50], Step [279/735], Loss: 0.6811\n",
      "Epoch [26/50], Step [280/735], Loss: 0.4405\n",
      "Epoch [26/50], Step [281/735], Loss: 0.1894\n",
      "Epoch [26/50], Step [282/735], Loss: 0.0849\n",
      "Epoch [26/50], Step [283/735], Loss: 0.1083\n",
      "Epoch [26/50], Step [284/735], Loss: 0.2287\n",
      "Epoch [26/50], Step [285/735], Loss: 0.2818\n",
      "Epoch [26/50], Step [286/735], Loss: 0.7922\n",
      "Epoch [26/50], Step [287/735], Loss: 0.1438\n",
      "Epoch [26/50], Step [288/735], Loss: 0.2966\n",
      "Epoch [26/50], Step [289/735], Loss: 0.0830\n",
      "Epoch [26/50], Step [290/735], Loss: 0.5699\n",
      "Epoch [26/50], Step [291/735], Loss: 1.3101\n",
      "Epoch [26/50], Step [292/735], Loss: 0.1150\n",
      "Epoch [26/50], Step [293/735], Loss: 0.2599\n",
      "Epoch [26/50], Step [294/735], Loss: 1.4779\n",
      "Epoch [26/50], Step [295/735], Loss: 0.2127\n",
      "Epoch [26/50], Step [296/735], Loss: 0.1135\n",
      "Epoch [26/50], Step [297/735], Loss: 0.3641\n",
      "Epoch [26/50], Step [298/735], Loss: 0.8731\n",
      "Epoch [26/50], Step [299/735], Loss: 0.2895\n",
      "Epoch [26/50], Step [300/735], Loss: 0.2482\n",
      "Epoch [26/50], Step [301/735], Loss: 0.6777\n",
      "Epoch [26/50], Step [302/735], Loss: 0.4078\n",
      "Epoch [26/50], Step [303/735], Loss: 0.2398\n",
      "Epoch [26/50], Step [304/735], Loss: 0.0899\n",
      "Epoch [26/50], Step [305/735], Loss: 0.1435\n",
      "Epoch [26/50], Step [306/735], Loss: 0.4643\n",
      "Epoch [26/50], Step [307/735], Loss: 0.1699\n",
      "Epoch [26/50], Step [308/735], Loss: 0.3369\n",
      "Epoch [26/50], Step [309/735], Loss: 0.2996\n",
      "Epoch [26/50], Step [310/735], Loss: 0.4479\n",
      "Epoch [26/50], Step [311/735], Loss: 0.7800\n",
      "Epoch [26/50], Step [312/735], Loss: 0.4105\n",
      "Epoch [26/50], Step [313/735], Loss: 0.6569\n",
      "Epoch [26/50], Step [314/735], Loss: 1.6080\n",
      "Epoch [26/50], Step [315/735], Loss: 0.6446\n",
      "Epoch [26/50], Step [316/735], Loss: 0.2716\n",
      "Epoch [26/50], Step [317/735], Loss: 0.6279\n",
      "Epoch [26/50], Step [318/735], Loss: 0.5071\n",
      "Epoch [26/50], Step [319/735], Loss: 0.2731\n",
      "Epoch [26/50], Step [320/735], Loss: 0.8110\n",
      "Epoch [26/50], Step [321/735], Loss: 0.3386\n",
      "Epoch [26/50], Step [322/735], Loss: 0.4006\n",
      "Epoch [26/50], Step [323/735], Loss: 0.2210\n",
      "Epoch [26/50], Step [324/735], Loss: 0.0944\n",
      "Epoch [26/50], Step [325/735], Loss: 0.2459\n",
      "Epoch [26/50], Step [326/735], Loss: 0.1952\n",
      "Epoch [26/50], Step [327/735], Loss: 0.2206\n",
      "Epoch [26/50], Step [328/735], Loss: 0.2174\n",
      "Epoch [26/50], Step [329/735], Loss: 0.1731\n",
      "Epoch [26/50], Step [330/735], Loss: 0.3312\n",
      "Epoch [26/50], Step [331/735], Loss: 0.0791\n",
      "Epoch [26/50], Step [332/735], Loss: 0.6910\n",
      "Epoch [26/50], Step [333/735], Loss: 0.2050\n",
      "Epoch [26/50], Step [334/735], Loss: 0.0944\n",
      "Epoch [26/50], Step [335/735], Loss: 1.0359\n",
      "Epoch [26/50], Step [336/735], Loss: 0.6541\n",
      "Epoch [26/50], Step [337/735], Loss: 0.2048\n",
      "Epoch [26/50], Step [338/735], Loss: 0.5680\n",
      "Epoch [26/50], Step [339/735], Loss: 0.1085\n",
      "Epoch [26/50], Step [340/735], Loss: 0.4352\n",
      "Epoch [26/50], Step [341/735], Loss: 0.4462\n",
      "Epoch [26/50], Step [342/735], Loss: 0.2461\n",
      "Epoch [26/50], Step [343/735], Loss: 0.5471\n",
      "Epoch [26/50], Step [344/735], Loss: 0.3436\n",
      "Epoch [26/50], Step [345/735], Loss: 0.3220\n",
      "Epoch [26/50], Step [346/735], Loss: 0.2894\n",
      "Epoch [26/50], Step [347/735], Loss: 0.2406\n",
      "Epoch [26/50], Step [348/735], Loss: 0.0696\n",
      "Epoch [26/50], Step [349/735], Loss: 0.1583\n",
      "Epoch [26/50], Step [350/735], Loss: 0.2755\n",
      "Epoch [26/50], Step [351/735], Loss: 0.3782\n",
      "Epoch [26/50], Step [352/735], Loss: 0.4211\n",
      "Epoch [26/50], Step [353/735], Loss: 0.4095\n",
      "Epoch [26/50], Step [354/735], Loss: 0.1585\n",
      "Epoch [26/50], Step [355/735], Loss: 0.2832\n",
      "Epoch [26/50], Step [356/735], Loss: 0.7069\n",
      "Epoch [26/50], Step [357/735], Loss: 0.2340\n",
      "Epoch [26/50], Step [358/735], Loss: 0.2304\n",
      "Epoch [26/50], Step [359/735], Loss: 0.1415\n",
      "Epoch [26/50], Step [360/735], Loss: 0.4922\n",
      "Epoch [26/50], Step [361/735], Loss: 0.3842\n",
      "Epoch [26/50], Step [362/735], Loss: 0.1594\n",
      "Epoch [26/50], Step [363/735], Loss: 0.2526\n",
      "Epoch [26/50], Step [364/735], Loss: 0.6707\n",
      "Epoch [26/50], Step [365/735], Loss: 0.3103\n",
      "Epoch [26/50], Step [366/735], Loss: 0.2197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Step [367/735], Loss: 0.0845\n",
      "Epoch [26/50], Step [368/735], Loss: 0.3537\n",
      "Epoch [26/50], Step [369/735], Loss: 0.1831\n",
      "Epoch [26/50], Step [370/735], Loss: 0.1850\n",
      "Epoch [26/50], Step [371/735], Loss: 0.0673\n",
      "Epoch [26/50], Step [372/735], Loss: 0.2455\n",
      "Epoch [26/50], Step [373/735], Loss: 0.2952\n",
      "Epoch [26/50], Step [374/735], Loss: 0.1972\n",
      "Epoch [26/50], Step [375/735], Loss: 0.3373\n",
      "Epoch [26/50], Step [376/735], Loss: 0.3713\n",
      "Epoch [26/50], Step [377/735], Loss: 0.2752\n",
      "Epoch [26/50], Step [378/735], Loss: 0.1758\n",
      "Epoch [26/50], Step [379/735], Loss: 0.1230\n",
      "Epoch [26/50], Step [380/735], Loss: 0.8341\n",
      "Epoch [26/50], Step [381/735], Loss: 0.1776\n",
      "Epoch [26/50], Step [382/735], Loss: 0.0548\n",
      "Epoch [26/50], Step [383/735], Loss: 0.0540\n",
      "Epoch [26/50], Step [384/735], Loss: 0.2289\n",
      "Epoch [26/50], Step [385/735], Loss: 0.1469\n",
      "Epoch [26/50], Step [386/735], Loss: 0.3252\n",
      "Epoch [26/50], Step [387/735], Loss: 0.5015\n",
      "Epoch [26/50], Step [388/735], Loss: 0.1069\n",
      "Epoch [26/50], Step [389/735], Loss: 0.5154\n",
      "Epoch [26/50], Step [390/735], Loss: 0.4086\n",
      "Epoch [26/50], Step [391/735], Loss: 0.1983\n",
      "Epoch [26/50], Step [392/735], Loss: 0.2022\n",
      "Epoch [26/50], Step [393/735], Loss: 0.6661\n",
      "Epoch [26/50], Step [394/735], Loss: 0.2093\n",
      "Epoch [26/50], Step [395/735], Loss: 0.0407\n",
      "Epoch [26/50], Step [396/735], Loss: 1.1589\n",
      "Epoch [26/50], Step [397/735], Loss: 0.1625\n",
      "Epoch [26/50], Step [398/735], Loss: 0.1162\n",
      "Epoch [26/50], Step [399/735], Loss: 0.3985\n",
      "Epoch [26/50], Step [400/735], Loss: 0.4882\n",
      "Epoch [26/50], Step [401/735], Loss: 0.1578\n",
      "Epoch [26/50], Step [402/735], Loss: 0.1563\n",
      "Epoch [26/50], Step [403/735], Loss: 0.1442\n",
      "Epoch [26/50], Step [404/735], Loss: 0.5185\n",
      "Epoch [26/50], Step [405/735], Loss: 1.2651\n",
      "Epoch [26/50], Step [406/735], Loss: 0.1022\n",
      "Epoch [26/50], Step [407/735], Loss: 0.1803\n",
      "Epoch [26/50], Step [408/735], Loss: 0.0871\n",
      "Epoch [26/50], Step [409/735], Loss: 0.3632\n",
      "Epoch [26/50], Step [410/735], Loss: 0.3002\n",
      "Epoch [26/50], Step [411/735], Loss: 0.3557\n",
      "Epoch [26/50], Step [412/735], Loss: 0.2666\n",
      "Epoch [26/50], Step [413/735], Loss: 0.2278\n",
      "Epoch [26/50], Step [414/735], Loss: 0.1448\n",
      "Epoch [26/50], Step [415/735], Loss: 0.3510\n",
      "Epoch [26/50], Step [416/735], Loss: 0.4879\n",
      "Epoch [26/50], Step [417/735], Loss: 0.4444\n",
      "Epoch [26/50], Step [418/735], Loss: 0.4263\n",
      "Epoch [26/50], Step [419/735], Loss: 0.0847\n",
      "Epoch [26/50], Step [420/735], Loss: 0.8450\n",
      "Epoch [26/50], Step [421/735], Loss: 1.1064\n",
      "Epoch [26/50], Step [422/735], Loss: 0.1262\n",
      "Epoch [26/50], Step [423/735], Loss: 0.7939\n",
      "Epoch [26/50], Step [424/735], Loss: 0.3431\n",
      "Epoch [26/50], Step [425/735], Loss: 0.1881\n",
      "Epoch [26/50], Step [426/735], Loss: 0.4206\n",
      "Epoch [26/50], Step [427/735], Loss: 0.1948\n",
      "Epoch [26/50], Step [428/735], Loss: 0.6476\n",
      "Epoch [26/50], Step [429/735], Loss: 0.3159\n",
      "Epoch [26/50], Step [430/735], Loss: 0.4385\n",
      "Epoch [26/50], Step [431/735], Loss: 0.4647\n",
      "Epoch [26/50], Step [432/735], Loss: 0.3578\n",
      "Epoch [26/50], Step [433/735], Loss: 0.1462\n",
      "Epoch [26/50], Step [434/735], Loss: 0.3900\n",
      "Epoch [26/50], Step [435/735], Loss: 0.0524\n",
      "Epoch [26/50], Step [436/735], Loss: 0.8692\n",
      "Epoch [26/50], Step [437/735], Loss: 1.3042\n",
      "Epoch [26/50], Step [438/735], Loss: 0.3560\n",
      "Epoch [26/50], Step [439/735], Loss: 0.0837\n",
      "Epoch [26/50], Step [440/735], Loss: 0.6117\n",
      "Epoch [26/50], Step [441/735], Loss: 1.0042\n",
      "Epoch [26/50], Step [442/735], Loss: 0.3084\n",
      "Epoch [26/50], Step [443/735], Loss: 0.1541\n",
      "Epoch [26/50], Step [444/735], Loss: 0.4445\n",
      "Epoch [26/50], Step [445/735], Loss: 0.5260\n",
      "Epoch [26/50], Step [446/735], Loss: 0.6306\n",
      "Epoch [26/50], Step [447/735], Loss: 1.4179\n",
      "Epoch [26/50], Step [448/735], Loss: 0.2202\n",
      "Epoch [26/50], Step [449/735], Loss: 0.2060\n",
      "Epoch [26/50], Step [450/735], Loss: 0.1114\n",
      "Epoch [26/50], Step [451/735], Loss: 0.9399\n",
      "Epoch [26/50], Step [452/735], Loss: 0.1558\n",
      "Epoch [26/50], Step [453/735], Loss: 0.1777\n",
      "Epoch [26/50], Step [454/735], Loss: 0.3850\n",
      "Epoch [26/50], Step [455/735], Loss: 0.2428\n",
      "Epoch [26/50], Step [456/735], Loss: 0.6130\n",
      "Epoch [26/50], Step [457/735], Loss: 0.3626\n",
      "Epoch [26/50], Step [458/735], Loss: 0.1139\n",
      "Epoch [26/50], Step [459/735], Loss: 0.3086\n",
      "Epoch [26/50], Step [460/735], Loss: 0.6915\n",
      "Epoch [26/50], Step [461/735], Loss: 0.2804\n",
      "Epoch [26/50], Step [462/735], Loss: 0.2007\n",
      "Epoch [26/50], Step [463/735], Loss: 0.1392\n",
      "Epoch [26/50], Step [464/735], Loss: 4.3278\n",
      "Epoch [26/50], Step [465/735], Loss: 0.4203\n",
      "Epoch [26/50], Step [466/735], Loss: 0.1716\n",
      "Epoch [26/50], Step [467/735], Loss: 0.6112\n",
      "Epoch [26/50], Step [468/735], Loss: 0.3547\n",
      "Epoch [26/50], Step [469/735], Loss: 0.5862\n",
      "Epoch [26/50], Step [470/735], Loss: 0.1011\n",
      "Epoch [26/50], Step [471/735], Loss: 0.0878\n",
      "Epoch [26/50], Step [472/735], Loss: 0.1075\n",
      "Epoch [26/50], Step [473/735], Loss: 0.9770\n",
      "Epoch [26/50], Step [474/735], Loss: 0.8769\n",
      "Epoch [26/50], Step [475/735], Loss: 0.2047\n",
      "Epoch [26/50], Step [476/735], Loss: 0.2594\n",
      "Epoch [26/50], Step [477/735], Loss: 0.6857\n",
      "Epoch [26/50], Step [478/735], Loss: 1.6600\n",
      "Epoch [26/50], Step [479/735], Loss: 0.3221\n",
      "Epoch [26/50], Step [480/735], Loss: 0.5586\n",
      "Epoch [26/50], Step [481/735], Loss: 0.4863\n",
      "Epoch [26/50], Step [482/735], Loss: 0.1017\n",
      "Epoch [26/50], Step [483/735], Loss: 0.2710\n",
      "Epoch [26/50], Step [484/735], Loss: 4.2052\n",
      "Epoch [26/50], Step [485/735], Loss: 0.0826\n",
      "Epoch [26/50], Step [486/735], Loss: 0.2455\n",
      "Epoch [26/50], Step [487/735], Loss: 1.0192\n",
      "Epoch [26/50], Step [488/735], Loss: 0.3596\n",
      "Epoch [26/50], Step [489/735], Loss: 0.2787\n",
      "Epoch [26/50], Step [490/735], Loss: 0.5767\n",
      "Epoch [26/50], Step [491/735], Loss: 0.5028\n",
      "Epoch [26/50], Step [492/735], Loss: 0.1633\n",
      "Epoch [26/50], Step [493/735], Loss: 0.1092\n",
      "Epoch [26/50], Step [494/735], Loss: 0.1019\n",
      "Epoch [26/50], Step [495/735], Loss: 4.1408\n",
      "Epoch [26/50], Step [496/735], Loss: 0.6380\n",
      "Epoch [26/50], Step [497/735], Loss: 0.4667\n",
      "Epoch [26/50], Step [498/735], Loss: 0.1768\n",
      "Epoch [26/50], Step [499/735], Loss: 0.3000\n",
      "Epoch [26/50], Step [500/735], Loss: 0.2086\n",
      "Epoch [26/50], Step [501/735], Loss: 0.4846\n",
      "Epoch [26/50], Step [502/735], Loss: 0.3705\n",
      "Epoch [26/50], Step [503/735], Loss: 0.2093\n",
      "Epoch [26/50], Step [504/735], Loss: 0.8623\n",
      "Epoch [26/50], Step [505/735], Loss: 0.2813\n",
      "Epoch [26/50], Step [506/735], Loss: 0.2328\n",
      "Epoch [26/50], Step [507/735], Loss: 0.2101\n",
      "Epoch [26/50], Step [508/735], Loss: 0.1863\n",
      "Epoch [26/50], Step [509/735], Loss: 0.4112\n",
      "Epoch [26/50], Step [510/735], Loss: 0.2276\n",
      "Epoch [26/50], Step [511/735], Loss: 0.2402\n",
      "Epoch [26/50], Step [512/735], Loss: 0.5844\n",
      "Epoch [26/50], Step [513/735], Loss: 0.2311\n",
      "Epoch [26/50], Step [514/735], Loss: 0.5975\n",
      "Epoch [26/50], Step [515/735], Loss: 0.1910\n",
      "Epoch [26/50], Step [516/735], Loss: 0.2071\n",
      "Epoch [26/50], Step [517/735], Loss: 0.3573\n",
      "Epoch [26/50], Step [518/735], Loss: 0.3103\n",
      "Epoch [26/50], Step [519/735], Loss: 0.1676\n",
      "Epoch [26/50], Step [520/735], Loss: 0.2216\n",
      "Epoch [26/50], Step [521/735], Loss: 0.0478\n",
      "Epoch [26/50], Step [522/735], Loss: 0.8628\n",
      "Epoch [26/50], Step [523/735], Loss: 0.3268\n",
      "Epoch [26/50], Step [524/735], Loss: 1.4853\n",
      "Epoch [26/50], Step [525/735], Loss: 0.1178\n",
      "Epoch [26/50], Step [526/735], Loss: 0.4645\n",
      "Epoch [26/50], Step [527/735], Loss: 0.1363\n",
      "Epoch [26/50], Step [528/735], Loss: 0.0747\n",
      "Epoch [26/50], Step [529/735], Loss: 1.7551\n",
      "Epoch [26/50], Step [530/735], Loss: 0.0838\n",
      "Epoch [26/50], Step [531/735], Loss: 0.5530\n",
      "Epoch [26/50], Step [532/735], Loss: 0.1651\n",
      "Epoch [26/50], Step [533/735], Loss: 0.4215\n",
      "Epoch [26/50], Step [534/735], Loss: 0.1974\n",
      "Epoch [26/50], Step [535/735], Loss: 0.1616\n",
      "Epoch [26/50], Step [536/735], Loss: 0.4050\n",
      "Epoch [26/50], Step [537/735], Loss: 1.2441\n",
      "Epoch [26/50], Step [538/735], Loss: 0.1033\n",
      "Epoch [26/50], Step [539/735], Loss: 0.5885\n",
      "Epoch [26/50], Step [540/735], Loss: 0.4812\n",
      "Epoch [26/50], Step [541/735], Loss: 0.3142\n",
      "Epoch [26/50], Step [542/735], Loss: 0.4009\n",
      "Epoch [26/50], Step [543/735], Loss: 0.6076\n",
      "Epoch [26/50], Step [544/735], Loss: 0.1756\n",
      "Epoch [26/50], Step [545/735], Loss: 0.7129\n",
      "Epoch [26/50], Step [546/735], Loss: 1.1295\n",
      "Epoch [26/50], Step [547/735], Loss: 0.1867\n",
      "Epoch [26/50], Step [548/735], Loss: 0.4100\n",
      "Epoch [26/50], Step [549/735], Loss: 0.3257\n",
      "Epoch [26/50], Step [550/735], Loss: 0.4602\n",
      "Epoch [26/50], Step [551/735], Loss: 0.2014\n",
      "Epoch [26/50], Step [552/735], Loss: 0.1815\n",
      "Epoch [26/50], Step [553/735], Loss: 0.2511\n",
      "Epoch [26/50], Step [554/735], Loss: 0.3204\n",
      "Epoch [26/50], Step [555/735], Loss: 0.1884\n",
      "Epoch [26/50], Step [556/735], Loss: 0.5498\n",
      "Epoch [26/50], Step [557/735], Loss: 0.1555\n",
      "Epoch [26/50], Step [558/735], Loss: 0.3019\n",
      "Epoch [26/50], Step [559/735], Loss: 0.0932\n",
      "Epoch [26/50], Step [560/735], Loss: 0.1693\n",
      "Epoch [26/50], Step [561/735], Loss: 0.7198\n",
      "Epoch [26/50], Step [562/735], Loss: 0.5710\n",
      "Epoch [26/50], Step [563/735], Loss: 0.1746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Step [564/735], Loss: 0.1039\n",
      "Epoch [26/50], Step [565/735], Loss: 0.4643\n",
      "Epoch [26/50], Step [566/735], Loss: 0.2401\n",
      "Epoch [26/50], Step [567/735], Loss: 0.2690\n",
      "Epoch [26/50], Step [568/735], Loss: 0.3473\n",
      "Epoch [26/50], Step [569/735], Loss: 0.2827\n",
      "Epoch [26/50], Step [570/735], Loss: 0.3274\n",
      "Epoch [26/50], Step [571/735], Loss: 0.3838\n",
      "Epoch [26/50], Step [572/735], Loss: 0.6689\n",
      "Epoch [26/50], Step [573/735], Loss: 0.1165\n",
      "Epoch [26/50], Step [574/735], Loss: 0.8326\n",
      "Epoch [26/50], Step [575/735], Loss: 0.4122\n",
      "Epoch [26/50], Step [576/735], Loss: 0.2079\n",
      "Epoch [26/50], Step [577/735], Loss: 0.3775\n",
      "Epoch [26/50], Step [578/735], Loss: 1.0577\n",
      "Epoch [26/50], Step [579/735], Loss: 0.4094\n",
      "Epoch [26/50], Step [580/735], Loss: 0.2271\n",
      "Epoch [26/50], Step [581/735], Loss: 0.1684\n",
      "Epoch [26/50], Step [582/735], Loss: 0.7657\n",
      "Epoch [26/50], Step [583/735], Loss: 0.4979\n",
      "Epoch [26/50], Step [584/735], Loss: 0.2414\n",
      "Epoch [26/50], Step [585/735], Loss: 0.0559\n",
      "Epoch [26/50], Step [586/735], Loss: 0.3308\n",
      "Epoch [26/50], Step [587/735], Loss: 1.0291\n",
      "Epoch [26/50], Step [588/735], Loss: 0.4284\n",
      "Epoch [26/50], Step [589/735], Loss: 0.2392\n",
      "Epoch [26/50], Step [590/735], Loss: 0.3227\n",
      "Epoch [26/50], Step [591/735], Loss: 0.1272\n",
      "Epoch [26/50], Step [592/735], Loss: 0.1005\n",
      "Epoch [26/50], Step [593/735], Loss: 0.5197\n",
      "Epoch [26/50], Step [594/735], Loss: 0.7728\n",
      "Epoch [26/50], Step [595/735], Loss: 0.0765\n",
      "Epoch [26/50], Step [596/735], Loss: 0.4396\n",
      "Epoch [26/50], Step [597/735], Loss: 0.2086\n",
      "Epoch [26/50], Step [598/735], Loss: 0.3313\n",
      "Epoch [26/50], Step [599/735], Loss: 0.2594\n",
      "Epoch [26/50], Step [600/735], Loss: 0.1332\n",
      "Epoch [26/50], Step [601/735], Loss: 0.2032\n",
      "Epoch [26/50], Step [602/735], Loss: 0.3792\n",
      "Epoch [26/50], Step [603/735], Loss: 0.1240\n",
      "Epoch [26/50], Step [604/735], Loss: 0.3321\n",
      "Epoch [26/50], Step [605/735], Loss: 0.5301\n",
      "Epoch [26/50], Step [606/735], Loss: 0.2947\n",
      "Epoch [26/50], Step [607/735], Loss: 0.4208\n",
      "Epoch [26/50], Step [608/735], Loss: 0.1712\n",
      "Epoch [26/50], Step [609/735], Loss: 0.4202\n",
      "Epoch [26/50], Step [610/735], Loss: 0.5314\n",
      "Epoch [26/50], Step [611/735], Loss: 0.2589\n",
      "Epoch [26/50], Step [612/735], Loss: 0.8813\n",
      "Epoch [26/50], Step [613/735], Loss: 1.6385\n",
      "Epoch [26/50], Step [614/735], Loss: 0.2320\n",
      "Epoch [26/50], Step [615/735], Loss: 0.7403\n",
      "Epoch [26/50], Step [616/735], Loss: 0.3337\n",
      "Epoch [26/50], Step [617/735], Loss: 0.0539\n",
      "Epoch [26/50], Step [618/735], Loss: 0.2851\n",
      "Epoch [26/50], Step [619/735], Loss: 0.9461\n",
      "Epoch [26/50], Step [620/735], Loss: 0.2417\n",
      "Epoch [26/50], Step [621/735], Loss: 0.2674\n",
      "Epoch [26/50], Step [622/735], Loss: 0.3051\n",
      "Epoch [26/50], Step [623/735], Loss: 0.2494\n",
      "Epoch [26/50], Step [624/735], Loss: 0.2253\n",
      "Epoch [26/50], Step [625/735], Loss: 0.2459\n",
      "Epoch [26/50], Step [626/735], Loss: 0.1495\n",
      "Epoch [26/50], Step [627/735], Loss: 1.1196\n",
      "Epoch [26/50], Step [628/735], Loss: 0.4079\n",
      "Epoch [26/50], Step [629/735], Loss: 0.1794\n",
      "Epoch [26/50], Step [630/735], Loss: 0.0934\n",
      "Epoch [26/50], Step [631/735], Loss: 0.2208\n",
      "Epoch [26/50], Step [632/735], Loss: 0.1793\n",
      "Epoch [26/50], Step [633/735], Loss: 0.3142\n",
      "Epoch [26/50], Step [634/735], Loss: 0.5086\n",
      "Epoch [26/50], Step [635/735], Loss: 1.2488\n",
      "Epoch [26/50], Step [636/735], Loss: 0.1584\n",
      "Epoch [26/50], Step [637/735], Loss: 0.1775\n",
      "Epoch [26/50], Step [638/735], Loss: 0.1400\n",
      "Epoch [26/50], Step [639/735], Loss: 0.2691\n",
      "Epoch [26/50], Step [640/735], Loss: 0.4224\n",
      "Epoch [26/50], Step [641/735], Loss: 0.6007\n",
      "Epoch [26/50], Step [642/735], Loss: 0.5533\n",
      "Epoch [26/50], Step [643/735], Loss: 0.2290\n",
      "Epoch [26/50], Step [644/735], Loss: 0.2041\n",
      "Epoch [26/50], Step [645/735], Loss: 0.1107\n",
      "Epoch [26/50], Step [646/735], Loss: 0.1046\n",
      "Epoch [26/50], Step [647/735], Loss: 0.3982\n",
      "Epoch [26/50], Step [648/735], Loss: 0.2940\n",
      "Epoch [26/50], Step [649/735], Loss: 0.7412\n",
      "Epoch [26/50], Step [650/735], Loss: 0.2069\n",
      "Epoch [26/50], Step [651/735], Loss: 0.3342\n",
      "Epoch [26/50], Step [652/735], Loss: 0.2240\n",
      "Epoch [26/50], Step [653/735], Loss: 0.3823\n",
      "Epoch [26/50], Step [654/735], Loss: 2.0781\n",
      "Epoch [26/50], Step [655/735], Loss: 0.3481\n",
      "Epoch [26/50], Step [656/735], Loss: 0.1380\n",
      "Epoch [26/50], Step [657/735], Loss: 0.4451\n",
      "Epoch [26/50], Step [658/735], Loss: 0.1661\n",
      "Epoch [26/50], Step [659/735], Loss: 0.6284\n",
      "Epoch [26/50], Step [660/735], Loss: 0.2089\n",
      "Epoch [26/50], Step [661/735], Loss: 0.4428\n",
      "Epoch [26/50], Step [662/735], Loss: 0.0809\n",
      "Epoch [26/50], Step [663/735], Loss: 0.0874\n",
      "Epoch [26/50], Step [664/735], Loss: 0.8888\n",
      "Epoch [26/50], Step [665/735], Loss: 0.1928\n",
      "Epoch [26/50], Step [666/735], Loss: 0.1371\n",
      "Epoch [26/50], Step [667/735], Loss: 0.4398\n",
      "Epoch [26/50], Step [668/735], Loss: 0.4760\n",
      "Epoch [26/50], Step [669/735], Loss: 0.1607\n",
      "Epoch [26/50], Step [670/735], Loss: 0.3738\n",
      "Epoch [26/50], Step [671/735], Loss: 0.1773\n",
      "Epoch [26/50], Step [672/735], Loss: 1.0285\n",
      "Epoch [26/50], Step [673/735], Loss: 0.2700\n",
      "Epoch [26/50], Step [674/735], Loss: 0.1856\n",
      "Epoch [26/50], Step [675/735], Loss: 0.2326\n",
      "Epoch [26/50], Step [676/735], Loss: 0.1426\n",
      "Epoch [26/50], Step [677/735], Loss: 0.1185\n",
      "Epoch [26/50], Step [678/735], Loss: 0.1485\n",
      "Epoch [26/50], Step [679/735], Loss: 0.3778\n",
      "Epoch [26/50], Step [680/735], Loss: 0.1207\n",
      "Epoch [26/50], Step [681/735], Loss: 0.1897\n",
      "Epoch [26/50], Step [682/735], Loss: 0.2771\n",
      "Epoch [26/50], Step [683/735], Loss: 0.1408\n",
      "Epoch [26/50], Step [684/735], Loss: 0.4413\n",
      "Epoch [26/50], Step [685/735], Loss: 5.6552\n",
      "Epoch [26/50], Step [686/735], Loss: 1.2240\n",
      "Epoch [26/50], Step [687/735], Loss: 0.2598\n",
      "Epoch [26/50], Step [688/735], Loss: 0.1382\n",
      "Epoch [26/50], Step [689/735], Loss: 0.2004\n",
      "Epoch [26/50], Step [690/735], Loss: 0.3819\n",
      "Epoch [26/50], Step [691/735], Loss: 0.1349\n",
      "Epoch [26/50], Step [692/735], Loss: 0.0910\n",
      "Epoch [26/50], Step [693/735], Loss: 0.0805\n",
      "Epoch [26/50], Step [694/735], Loss: 0.1589\n",
      "Epoch [26/50], Step [695/735], Loss: 0.1142\n",
      "Epoch [26/50], Step [696/735], Loss: 0.1640\n",
      "Epoch [26/50], Step [697/735], Loss: 0.9115\n",
      "Epoch [26/50], Step [698/735], Loss: 0.2147\n",
      "Epoch [26/50], Step [699/735], Loss: 0.2588\n",
      "Epoch [26/50], Step [700/735], Loss: 0.3174\n",
      "Epoch [26/50], Step [701/735], Loss: 0.3070\n",
      "Epoch [26/50], Step [702/735], Loss: 0.0966\n",
      "Epoch [26/50], Step [703/735], Loss: 0.3836\n",
      "Epoch [26/50], Step [704/735], Loss: 0.4815\n",
      "Epoch [26/50], Step [705/735], Loss: 0.4849\n",
      "Epoch [26/50], Step [706/735], Loss: 0.2266\n",
      "Epoch [26/50], Step [707/735], Loss: 0.3607\n",
      "Epoch [26/50], Step [708/735], Loss: 0.6956\n",
      "Epoch [26/50], Step [709/735], Loss: 0.4864\n",
      "Epoch [26/50], Step [710/735], Loss: 0.8157\n",
      "Epoch [26/50], Step [711/735], Loss: 0.2431\n",
      "Epoch [26/50], Step [712/735], Loss: 0.3043\n",
      "Epoch [26/50], Step [713/735], Loss: 0.6056\n",
      "Epoch [26/50], Step [714/735], Loss: 0.6852\n",
      "Epoch [26/50], Step [715/735], Loss: 0.0686\n",
      "Epoch [26/50], Step [716/735], Loss: 0.4662\n",
      "Epoch [26/50], Step [717/735], Loss: 0.7738\n",
      "Epoch [26/50], Step [718/735], Loss: 0.3403\n",
      "Epoch [26/50], Step [719/735], Loss: 0.4608\n",
      "Epoch [26/50], Step [720/735], Loss: 0.2597\n",
      "Epoch [26/50], Step [721/735], Loss: 0.2576\n",
      "Epoch [26/50], Step [722/735], Loss: 0.4475\n",
      "Epoch [26/50], Step [723/735], Loss: 0.0718\n",
      "Epoch [26/50], Step [724/735], Loss: 0.4511\n",
      "Epoch [26/50], Step [725/735], Loss: 0.1032\n",
      "Epoch [26/50], Step [726/735], Loss: 1.2715\n",
      "Epoch [26/50], Step [727/735], Loss: 0.4172\n",
      "Epoch [26/50], Step [728/735], Loss: 0.1402\n",
      "Epoch [26/50], Step [729/735], Loss: 0.1982\n",
      "Epoch [26/50], Step [730/735], Loss: 0.1724\n",
      "Epoch [26/50], Step [731/735], Loss: 0.2264\n",
      "Epoch [26/50], Step [732/735], Loss: 0.1764\n",
      "Epoch [26/50], Step [733/735], Loss: 0.2334\n",
      "Epoch [26/50], Step [734/735], Loss: 0.3507\n",
      "Epoch [26/50], Step [735/735], Loss: 0.1625\n",
      "Epoch [27/50], Step [1/735], Loss: 0.2712\n",
      "Epoch [27/50], Step [2/735], Loss: 0.5736\n",
      "Epoch [27/50], Step [3/735], Loss: 0.0943\n",
      "Epoch [27/50], Step [4/735], Loss: 0.4543\n",
      "Epoch [27/50], Step [5/735], Loss: 0.4935\n",
      "Epoch [27/50], Step [6/735], Loss: 0.4319\n",
      "Epoch [27/50], Step [7/735], Loss: 0.2558\n",
      "Epoch [27/50], Step [8/735], Loss: 0.4018\n",
      "Epoch [27/50], Step [9/735], Loss: 0.1164\n",
      "Epoch [27/50], Step [10/735], Loss: 0.2655\n",
      "Epoch [27/50], Step [11/735], Loss: 0.2554\n",
      "Epoch [27/50], Step [12/735], Loss: 0.2509\n",
      "Epoch [27/50], Step [13/735], Loss: 0.5515\n",
      "Epoch [27/50], Step [14/735], Loss: 0.4076\n",
      "Epoch [27/50], Step [15/735], Loss: 0.2378\n",
      "Epoch [27/50], Step [16/735], Loss: 0.1372\n",
      "Epoch [27/50], Step [17/735], Loss: 0.3541\n",
      "Epoch [27/50], Step [18/735], Loss: 0.3489\n",
      "Epoch [27/50], Step [19/735], Loss: 0.4766\n",
      "Epoch [27/50], Step [20/735], Loss: 0.2068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Step [21/735], Loss: 0.5305\n",
      "Epoch [27/50], Step [22/735], Loss: 0.2193\n",
      "Epoch [27/50], Step [23/735], Loss: 0.3716\n",
      "Epoch [27/50], Step [24/735], Loss: 1.5362\n",
      "Epoch [27/50], Step [25/735], Loss: 0.5506\n",
      "Epoch [27/50], Step [26/735], Loss: 0.1319\n",
      "Epoch [27/50], Step [27/735], Loss: 0.2632\n",
      "Epoch [27/50], Step [28/735], Loss: 0.1407\n",
      "Epoch [27/50], Step [29/735], Loss: 0.5428\n",
      "Epoch [27/50], Step [30/735], Loss: 0.5223\n",
      "Epoch [27/50], Step [31/735], Loss: 0.3740\n",
      "Epoch [27/50], Step [32/735], Loss: 0.2412\n",
      "Epoch [27/50], Step [33/735], Loss: 0.7471\n",
      "Epoch [27/50], Step [34/735], Loss: 0.1158\n",
      "Epoch [27/50], Step [35/735], Loss: 0.2185\n",
      "Epoch [27/50], Step [36/735], Loss: 0.1677\n",
      "Epoch [27/50], Step [37/735], Loss: 0.2511\n",
      "Epoch [27/50], Step [38/735], Loss: 0.4528\n",
      "Epoch [27/50], Step [39/735], Loss: 0.3793\n",
      "Epoch [27/50], Step [40/735], Loss: 0.7195\n",
      "Epoch [27/50], Step [41/735], Loss: 0.7014\n",
      "Epoch [27/50], Step [42/735], Loss: 0.3824\n",
      "Epoch [27/50], Step [43/735], Loss: 0.5015\n",
      "Epoch [27/50], Step [44/735], Loss: 0.4892\n",
      "Epoch [27/50], Step [45/735], Loss: 0.2215\n",
      "Epoch [27/50], Step [46/735], Loss: 0.6184\n",
      "Epoch [27/50], Step [47/735], Loss: 0.1689\n",
      "Epoch [27/50], Step [48/735], Loss: 0.4833\n",
      "Epoch [27/50], Step [49/735], Loss: 0.1962\n",
      "Epoch [27/50], Step [50/735], Loss: 0.8315\n",
      "Epoch [27/50], Step [51/735], Loss: 0.1726\n",
      "Epoch [27/50], Step [52/735], Loss: 0.1519\n",
      "Epoch [27/50], Step [53/735], Loss: 0.3995\n",
      "Epoch [27/50], Step [54/735], Loss: 0.1927\n",
      "Epoch [27/50], Step [55/735], Loss: 0.7762\n",
      "Epoch [27/50], Step [56/735], Loss: 0.3679\n",
      "Epoch [27/50], Step [57/735], Loss: 0.2154\n",
      "Epoch [27/50], Step [58/735], Loss: 0.3542\n",
      "Epoch [27/50], Step [59/735], Loss: 0.3829\n",
      "Epoch [27/50], Step [60/735], Loss: 0.0925\n",
      "Epoch [27/50], Step [61/735], Loss: 0.2093\n",
      "Epoch [27/50], Step [62/735], Loss: 0.3183\n",
      "Epoch [27/50], Step [63/735], Loss: 0.0990\n",
      "Epoch [27/50], Step [64/735], Loss: 0.2027\n",
      "Epoch [27/50], Step [65/735], Loss: 0.3266\n",
      "Epoch [27/50], Step [66/735], Loss: 0.5166\n",
      "Epoch [27/50], Step [67/735], Loss: 0.1626\n",
      "Epoch [27/50], Step [68/735], Loss: 0.1603\n",
      "Epoch [27/50], Step [69/735], Loss: 0.0775\n",
      "Epoch [27/50], Step [70/735], Loss: 0.1196\n",
      "Epoch [27/50], Step [71/735], Loss: 0.3757\n",
      "Epoch [27/50], Step [72/735], Loss: 0.8388\n",
      "Epoch [27/50], Step [73/735], Loss: 0.4336\n",
      "Epoch [27/50], Step [74/735], Loss: 0.1024\n",
      "Epoch [27/50], Step [75/735], Loss: 0.0630\n",
      "Epoch [27/50], Step [76/735], Loss: 0.4288\n",
      "Epoch [27/50], Step [77/735], Loss: 0.6635\n",
      "Epoch [27/50], Step [78/735], Loss: 0.7106\n",
      "Epoch [27/50], Step [79/735], Loss: 0.1937\n",
      "Epoch [27/50], Step [80/735], Loss: 0.8190\n",
      "Epoch [27/50], Step [81/735], Loss: 0.2673\n",
      "Epoch [27/50], Step [82/735], Loss: 0.7204\n",
      "Epoch [27/50], Step [83/735], Loss: 0.2289\n",
      "Epoch [27/50], Step [84/735], Loss: 0.3758\n",
      "Epoch [27/50], Step [85/735], Loss: 0.2962\n",
      "Epoch [27/50], Step [86/735], Loss: 1.1551\n",
      "Epoch [27/50], Step [87/735], Loss: 0.1058\n",
      "Epoch [27/50], Step [88/735], Loss: 0.1258\n",
      "Epoch [27/50], Step [89/735], Loss: 0.2579\n",
      "Epoch [27/50], Step [90/735], Loss: 0.1550\n",
      "Epoch [27/50], Step [91/735], Loss: 0.5941\n",
      "Epoch [27/50], Step [92/735], Loss: 0.1159\n",
      "Epoch [27/50], Step [93/735], Loss: 0.3850\n",
      "Epoch [27/50], Step [94/735], Loss: 0.8267\n",
      "Epoch [27/50], Step [95/735], Loss: 0.7211\n",
      "Epoch [27/50], Step [96/735], Loss: 0.4597\n",
      "Epoch [27/50], Step [97/735], Loss: 0.4304\n",
      "Epoch [27/50], Step [98/735], Loss: 0.2322\n",
      "Epoch [27/50], Step [99/735], Loss: 0.2875\n",
      "Epoch [27/50], Step [100/735], Loss: 0.1389\n",
      "Epoch [27/50], Step [101/735], Loss: 0.8676\n",
      "Epoch [27/50], Step [102/735], Loss: 0.5910\n",
      "Epoch [27/50], Step [103/735], Loss: 0.2666\n",
      "Epoch [27/50], Step [104/735], Loss: 0.0697\n",
      "Epoch [27/50], Step [105/735], Loss: 0.2602\n",
      "Epoch [27/50], Step [106/735], Loss: 0.2597\n",
      "Epoch [27/50], Step [107/735], Loss: 0.2444\n",
      "Epoch [27/50], Step [108/735], Loss: 0.6024\n",
      "Epoch [27/50], Step [109/735], Loss: 0.8680\n",
      "Epoch [27/50], Step [110/735], Loss: 0.1626\n",
      "Epoch [27/50], Step [111/735], Loss: 0.1404\n",
      "Epoch [27/50], Step [112/735], Loss: 1.4591\n",
      "Epoch [27/50], Step [113/735], Loss: 0.4781\n",
      "Epoch [27/50], Step [114/735], Loss: 0.7961\n",
      "Epoch [27/50], Step [115/735], Loss: 0.1145\n",
      "Epoch [27/50], Step [116/735], Loss: 0.3013\n",
      "Epoch [27/50], Step [117/735], Loss: 0.3670\n",
      "Epoch [27/50], Step [118/735], Loss: 0.3101\n",
      "Epoch [27/50], Step [119/735], Loss: 0.3370\n",
      "Epoch [27/50], Step [120/735], Loss: 0.4912\n",
      "Epoch [27/50], Step [121/735], Loss: 0.6557\n",
      "Epoch [27/50], Step [122/735], Loss: 0.0917\n",
      "Epoch [27/50], Step [123/735], Loss: 0.1456\n",
      "Epoch [27/50], Step [124/735], Loss: 0.3174\n",
      "Epoch [27/50], Step [125/735], Loss: 0.3425\n",
      "Epoch [27/50], Step [126/735], Loss: 0.1155\n",
      "Epoch [27/50], Step [127/735], Loss: 0.1086\n",
      "Epoch [27/50], Step [128/735], Loss: 1.3993\n",
      "Epoch [27/50], Step [129/735], Loss: 0.1249\n",
      "Epoch [27/50], Step [130/735], Loss: 0.2751\n",
      "Epoch [27/50], Step [131/735], Loss: 0.7473\n",
      "Epoch [27/50], Step [132/735], Loss: 0.7421\n",
      "Epoch [27/50], Step [133/735], Loss: 0.2048\n",
      "Epoch [27/50], Step [134/735], Loss: 0.1979\n",
      "Epoch [27/50], Step [135/735], Loss: 0.2927\n",
      "Epoch [27/50], Step [136/735], Loss: 1.3720\n",
      "Epoch [27/50], Step [137/735], Loss: 0.2949\n",
      "Epoch [27/50], Step [138/735], Loss: 0.2597\n",
      "Epoch [27/50], Step [139/735], Loss: 0.2897\n",
      "Epoch [27/50], Step [140/735], Loss: 0.2874\n",
      "Epoch [27/50], Step [141/735], Loss: 0.1838\n",
      "Epoch [27/50], Step [142/735], Loss: 0.3023\n",
      "Epoch [27/50], Step [143/735], Loss: 0.2917\n",
      "Epoch [27/50], Step [144/735], Loss: 0.2389\n",
      "Epoch [27/50], Step [145/735], Loss: 0.5006\n",
      "Epoch [27/50], Step [146/735], Loss: 0.2751\n",
      "Epoch [27/50], Step [147/735], Loss: 0.2283\n",
      "Epoch [27/50], Step [148/735], Loss: 0.3155\n",
      "Epoch [27/50], Step [149/735], Loss: 0.5596\n",
      "Epoch [27/50], Step [150/735], Loss: 0.1585\n",
      "Epoch [27/50], Step [151/735], Loss: 0.1875\n",
      "Epoch [27/50], Step [152/735], Loss: 0.2888\n",
      "Epoch [27/50], Step [153/735], Loss: 1.5033\n",
      "Epoch [27/50], Step [154/735], Loss: 0.2435\n",
      "Epoch [27/50], Step [155/735], Loss: 0.2720\n",
      "Epoch [27/50], Step [156/735], Loss: 0.5334\n",
      "Epoch [27/50], Step [157/735], Loss: 0.5090\n",
      "Epoch [27/50], Step [158/735], Loss: 0.4835\n",
      "Epoch [27/50], Step [159/735], Loss: 0.4657\n",
      "Epoch [27/50], Step [160/735], Loss: 0.4454\n",
      "Epoch [27/50], Step [161/735], Loss: 0.5280\n",
      "Epoch [27/50], Step [162/735], Loss: 0.1489\n",
      "Epoch [27/50], Step [163/735], Loss: 0.1304\n",
      "Epoch [27/50], Step [164/735], Loss: 0.2506\n",
      "Epoch [27/50], Step [165/735], Loss: 0.6743\n",
      "Epoch [27/50], Step [166/735], Loss: 0.1477\n",
      "Epoch [27/50], Step [167/735], Loss: 0.2896\n",
      "Epoch [27/50], Step [168/735], Loss: 0.3117\n",
      "Epoch [27/50], Step [169/735], Loss: 0.7378\n",
      "Epoch [27/50], Step [170/735], Loss: 0.0777\n",
      "Epoch [27/50], Step [171/735], Loss: 0.0794\n",
      "Epoch [27/50], Step [172/735], Loss: 0.3629\n",
      "Epoch [27/50], Step [173/735], Loss: 0.2492\n",
      "Epoch [27/50], Step [174/735], Loss: 0.1994\n",
      "Epoch [27/50], Step [175/735], Loss: 0.1797\n",
      "Epoch [27/50], Step [176/735], Loss: 0.6306\n",
      "Epoch [27/50], Step [177/735], Loss: 0.3761\n",
      "Epoch [27/50], Step [178/735], Loss: 0.6207\n",
      "Epoch [27/50], Step [179/735], Loss: 0.2540\n",
      "Epoch [27/50], Step [180/735], Loss: 0.4474\n",
      "Epoch [27/50], Step [181/735], Loss: 0.2011\n",
      "Epoch [27/50], Step [182/735], Loss: 0.2860\n",
      "Epoch [27/50], Step [183/735], Loss: 0.2697\n",
      "Epoch [27/50], Step [184/735], Loss: 0.7350\n",
      "Epoch [27/50], Step [185/735], Loss: 0.1940\n",
      "Epoch [27/50], Step [186/735], Loss: 0.4617\n",
      "Epoch [27/50], Step [187/735], Loss: 0.1338\n",
      "Epoch [27/50], Step [188/735], Loss: 0.1543\n",
      "Epoch [27/50], Step [189/735], Loss: 0.9282\n",
      "Epoch [27/50], Step [190/735], Loss: 0.7478\n",
      "Epoch [27/50], Step [191/735], Loss: 0.2288\n",
      "Epoch [27/50], Step [192/735], Loss: 0.3917\n",
      "Epoch [27/50], Step [193/735], Loss: 0.3365\n",
      "Epoch [27/50], Step [194/735], Loss: 0.1932\n",
      "Epoch [27/50], Step [195/735], Loss: 0.1494\n",
      "Epoch [27/50], Step [196/735], Loss: 0.4086\n",
      "Epoch [27/50], Step [197/735], Loss: 0.2861\n",
      "Epoch [27/50], Step [198/735], Loss: 0.1159\n",
      "Epoch [27/50], Step [199/735], Loss: 1.2103\n",
      "Epoch [27/50], Step [200/735], Loss: 0.3954\n",
      "Epoch [27/50], Step [201/735], Loss: 0.0956\n",
      "Epoch [27/50], Step [202/735], Loss: 0.7701\n",
      "Epoch [27/50], Step [203/735], Loss: 0.3081\n",
      "Epoch [27/50], Step [204/735], Loss: 0.0999\n",
      "Epoch [27/50], Step [205/735], Loss: 0.0923\n",
      "Epoch [27/50], Step [206/735], Loss: 0.2865\n",
      "Epoch [27/50], Step [207/735], Loss: 0.2382\n",
      "Epoch [27/50], Step [208/735], Loss: 0.9065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Step [209/735], Loss: 0.3318\n",
      "Epoch [27/50], Step [210/735], Loss: 0.1255\n",
      "Epoch [27/50], Step [211/735], Loss: 0.0968\n",
      "Epoch [27/50], Step [212/735], Loss: 0.6874\n",
      "Epoch [27/50], Step [213/735], Loss: 0.4329\n",
      "Epoch [27/50], Step [214/735], Loss: 0.2230\n",
      "Epoch [27/50], Step [215/735], Loss: 0.1967\n",
      "Epoch [27/50], Step [216/735], Loss: 0.8543\n",
      "Epoch [27/50], Step [217/735], Loss: 1.2460\n",
      "Epoch [27/50], Step [218/735], Loss: 0.2093\n",
      "Epoch [27/50], Step [219/735], Loss: 0.6045\n",
      "Epoch [27/50], Step [220/735], Loss: 0.1086\n",
      "Epoch [27/50], Step [221/735], Loss: 0.1481\n",
      "Epoch [27/50], Step [222/735], Loss: 0.6860\n",
      "Epoch [27/50], Step [223/735], Loss: 0.2476\n",
      "Epoch [27/50], Step [224/735], Loss: 0.1621\n",
      "Epoch [27/50], Step [225/735], Loss: 0.3060\n",
      "Epoch [27/50], Step [226/735], Loss: 0.1600\n",
      "Epoch [27/50], Step [227/735], Loss: 1.1663\n",
      "Epoch [27/50], Step [228/735], Loss: 0.0789\n",
      "Epoch [27/50], Step [229/735], Loss: 0.4011\n",
      "Epoch [27/50], Step [230/735], Loss: 0.2087\n",
      "Epoch [27/50], Step [231/735], Loss: 0.3305\n",
      "Epoch [27/50], Step [232/735], Loss: 0.3101\n",
      "Epoch [27/50], Step [233/735], Loss: 0.1367\n",
      "Epoch [27/50], Step [234/735], Loss: 0.6822\n",
      "Epoch [27/50], Step [235/735], Loss: 0.2150\n",
      "Epoch [27/50], Step [236/735], Loss: 0.2977\n",
      "Epoch [27/50], Step [237/735], Loss: 0.6214\n",
      "Epoch [27/50], Step [238/735], Loss: 0.0935\n",
      "Epoch [27/50], Step [239/735], Loss: 0.4504\n",
      "Epoch [27/50], Step [240/735], Loss: 0.0832\n",
      "Epoch [27/50], Step [241/735], Loss: 0.2695\n",
      "Epoch [27/50], Step [242/735], Loss: 0.2247\n",
      "Epoch [27/50], Step [243/735], Loss: 0.4631\n",
      "Epoch [27/50], Step [244/735], Loss: 0.1233\n",
      "Epoch [27/50], Step [245/735], Loss: 0.2478\n",
      "Epoch [27/50], Step [246/735], Loss: 0.1171\n",
      "Epoch [27/50], Step [247/735], Loss: 0.0518\n",
      "Epoch [27/50], Step [248/735], Loss: 0.3838\n",
      "Epoch [27/50], Step [249/735], Loss: 0.5559\n",
      "Epoch [27/50], Step [250/735], Loss: 0.1901\n",
      "Epoch [27/50], Step [251/735], Loss: 0.3083\n",
      "Epoch [27/50], Step [252/735], Loss: 0.3992\n",
      "Epoch [27/50], Step [253/735], Loss: 0.8450\n",
      "Epoch [27/50], Step [254/735], Loss: 0.1887\n",
      "Epoch [27/50], Step [255/735], Loss: 0.4570\n",
      "Epoch [27/50], Step [256/735], Loss: 0.1706\n",
      "Epoch [27/50], Step [257/735], Loss: 0.1515\n",
      "Epoch [27/50], Step [258/735], Loss: 0.7865\n",
      "Epoch [27/50], Step [259/735], Loss: 0.8026\n",
      "Epoch [27/50], Step [260/735], Loss: 0.3789\n",
      "Epoch [27/50], Step [261/735], Loss: 0.5910\n",
      "Epoch [27/50], Step [262/735], Loss: 0.6481\n",
      "Epoch [27/50], Step [263/735], Loss: 0.4972\n",
      "Epoch [27/50], Step [264/735], Loss: 0.6239\n",
      "Epoch [27/50], Step [265/735], Loss: 0.2951\n",
      "Epoch [27/50], Step [266/735], Loss: 0.2153\n",
      "Epoch [27/50], Step [267/735], Loss: 0.1626\n",
      "Epoch [27/50], Step [268/735], Loss: 0.2799\n",
      "Epoch [27/50], Step [269/735], Loss: 0.4174\n",
      "Epoch [27/50], Step [270/735], Loss: 1.2018\n",
      "Epoch [27/50], Step [271/735], Loss: 0.6239\n",
      "Epoch [27/50], Step [272/735], Loss: 1.0686\n",
      "Epoch [27/50], Step [273/735], Loss: 1.0747\n",
      "Epoch [27/50], Step [274/735], Loss: 1.4783\n",
      "Epoch [27/50], Step [275/735], Loss: 0.2388\n",
      "Epoch [27/50], Step [276/735], Loss: 0.1916\n",
      "Epoch [27/50], Step [277/735], Loss: 0.4051\n",
      "Epoch [27/50], Step [278/735], Loss: 0.0953\n",
      "Epoch [27/50], Step [279/735], Loss: 0.2617\n",
      "Epoch [27/50], Step [280/735], Loss: 0.2571\n",
      "Epoch [27/50], Step [281/735], Loss: 0.8915\n",
      "Epoch [27/50], Step [282/735], Loss: 0.4369\n",
      "Epoch [27/50], Step [283/735], Loss: 0.2426\n",
      "Epoch [27/50], Step [284/735], Loss: 0.5925\n",
      "Epoch [27/50], Step [285/735], Loss: 1.0982\n",
      "Epoch [27/50], Step [286/735], Loss: 0.1400\n",
      "Epoch [27/50], Step [287/735], Loss: 0.2557\n",
      "Epoch [27/50], Step [288/735], Loss: 0.4003\n",
      "Epoch [27/50], Step [289/735], Loss: 0.5465\n",
      "Epoch [27/50], Step [290/735], Loss: 0.3983\n",
      "Epoch [27/50], Step [291/735], Loss: 0.4946\n",
      "Epoch [27/50], Step [292/735], Loss: 0.2947\n",
      "Epoch [27/50], Step [293/735], Loss: 0.5842\n",
      "Epoch [27/50], Step [294/735], Loss: 0.6981\n",
      "Epoch [27/50], Step [295/735], Loss: 0.1607\n",
      "Epoch [27/50], Step [296/735], Loss: 0.6485\n",
      "Epoch [27/50], Step [297/735], Loss: 0.1317\n",
      "Epoch [27/50], Step [298/735], Loss: 0.9569\n",
      "Epoch [27/50], Step [299/735], Loss: 0.0493\n",
      "Epoch [27/50], Step [300/735], Loss: 0.6354\n",
      "Epoch [27/50], Step [301/735], Loss: 0.4293\n",
      "Epoch [27/50], Step [302/735], Loss: 0.1389\n",
      "Epoch [27/50], Step [303/735], Loss: 0.1541\n",
      "Epoch [27/50], Step [304/735], Loss: 0.2588\n",
      "Epoch [27/50], Step [305/735], Loss: 0.1624\n",
      "Epoch [27/50], Step [306/735], Loss: 0.1570\n",
      "Epoch [27/50], Step [307/735], Loss: 0.2166\n",
      "Epoch [27/50], Step [308/735], Loss: 0.3291\n",
      "Epoch [27/50], Step [309/735], Loss: 0.2652\n",
      "Epoch [27/50], Step [310/735], Loss: 0.1067\n",
      "Epoch [27/50], Step [311/735], Loss: 0.4750\n",
      "Epoch [27/50], Step [312/735], Loss: 0.1947\n",
      "Epoch [27/50], Step [313/735], Loss: 0.2525\n",
      "Epoch [27/50], Step [314/735], Loss: 0.4370\n",
      "Epoch [27/50], Step [315/735], Loss: 0.1712\n",
      "Epoch [27/50], Step [316/735], Loss: 0.3218\n",
      "Epoch [27/50], Step [317/735], Loss: 0.3302\n",
      "Epoch [27/50], Step [318/735], Loss: 0.5015\n",
      "Epoch [27/50], Step [319/735], Loss: 0.4193\n",
      "Epoch [27/50], Step [320/735], Loss: 0.1627\n",
      "Epoch [27/50], Step [321/735], Loss: 0.0648\n",
      "Epoch [27/50], Step [322/735], Loss: 0.3400\n",
      "Epoch [27/50], Step [323/735], Loss: 0.5517\n",
      "Epoch [27/50], Step [324/735], Loss: 0.1169\n",
      "Epoch [27/50], Step [325/735], Loss: 0.6543\n",
      "Epoch [27/50], Step [326/735], Loss: 0.1652\n",
      "Epoch [27/50], Step [327/735], Loss: 0.3991\n",
      "Epoch [27/50], Step [328/735], Loss: 0.5398\n",
      "Epoch [27/50], Step [329/735], Loss: 0.1357\n",
      "Epoch [27/50], Step [330/735], Loss: 0.0838\n",
      "Epoch [27/50], Step [331/735], Loss: 1.4704\n",
      "Epoch [27/50], Step [332/735], Loss: 0.2536\n",
      "Epoch [27/50], Step [333/735], Loss: 0.3106\n",
      "Epoch [27/50], Step [334/735], Loss: 0.2613\n",
      "Epoch [27/50], Step [335/735], Loss: 0.1549\n",
      "Epoch [27/50], Step [336/735], Loss: 0.2848\n",
      "Epoch [27/50], Step [337/735], Loss: 0.1648\n",
      "Epoch [27/50], Step [338/735], Loss: 0.2134\n",
      "Epoch [27/50], Step [339/735], Loss: 0.2869\n",
      "Epoch [27/50], Step [340/735], Loss: 0.1541\n",
      "Epoch [27/50], Step [341/735], Loss: 0.0973\n",
      "Epoch [27/50], Step [342/735], Loss: 0.4713\n",
      "Epoch [27/50], Step [343/735], Loss: 0.2577\n",
      "Epoch [27/50], Step [344/735], Loss: 0.2589\n",
      "Epoch [27/50], Step [345/735], Loss: 0.4905\n",
      "Epoch [27/50], Step [346/735], Loss: 0.0972\n",
      "Epoch [27/50], Step [347/735], Loss: 0.1220\n",
      "Epoch [27/50], Step [348/735], Loss: 0.6373\n",
      "Epoch [27/50], Step [349/735], Loss: 0.0994\n",
      "Epoch [27/50], Step [350/735], Loss: 0.1428\n",
      "Epoch [27/50], Step [351/735], Loss: 0.2563\n",
      "Epoch [27/50], Step [352/735], Loss: 0.3718\n",
      "Epoch [27/50], Step [353/735], Loss: 0.1451\n",
      "Epoch [27/50], Step [354/735], Loss: 0.1179\n",
      "Epoch [27/50], Step [355/735], Loss: 1.2127\n",
      "Epoch [27/50], Step [356/735], Loss: 0.4532\n",
      "Epoch [27/50], Step [357/735], Loss: 0.2990\n",
      "Epoch [27/50], Step [358/735], Loss: 0.0920\n",
      "Epoch [27/50], Step [359/735], Loss: 0.3157\n",
      "Epoch [27/50], Step [360/735], Loss: 0.4017\n",
      "Epoch [27/50], Step [361/735], Loss: 0.1667\n",
      "Epoch [27/50], Step [362/735], Loss: 0.2472\n",
      "Epoch [27/50], Step [363/735], Loss: 0.6344\n",
      "Epoch [27/50], Step [364/735], Loss: 0.1060\n",
      "Epoch [27/50], Step [365/735], Loss: 0.9158\n",
      "Epoch [27/50], Step [366/735], Loss: 0.2940\n",
      "Epoch [27/50], Step [367/735], Loss: 0.2166\n",
      "Epoch [27/50], Step [368/735], Loss: 0.3797\n",
      "Epoch [27/50], Step [369/735], Loss: 0.2107\n",
      "Epoch [27/50], Step [370/735], Loss: 0.5814\n",
      "Epoch [27/50], Step [371/735], Loss: 0.3368\n",
      "Epoch [27/50], Step [372/735], Loss: 0.4699\n",
      "Epoch [27/50], Step [373/735], Loss: 0.2503\n",
      "Epoch [27/50], Step [374/735], Loss: 0.1161\n",
      "Epoch [27/50], Step [375/735], Loss: 0.3599\n",
      "Epoch [27/50], Step [376/735], Loss: 0.2829\n",
      "Epoch [27/50], Step [377/735], Loss: 0.1172\n",
      "Epoch [27/50], Step [378/735], Loss: 0.1374\n",
      "Epoch [27/50], Step [379/735], Loss: 0.4404\n",
      "Epoch [27/50], Step [380/735], Loss: 0.6301\n",
      "Epoch [27/50], Step [381/735], Loss: 0.4421\n",
      "Epoch [27/50], Step [382/735], Loss: 0.6763\n",
      "Epoch [27/50], Step [383/735], Loss: 1.2196\n",
      "Epoch [27/50], Step [384/735], Loss: 0.2479\n",
      "Epoch [27/50], Step [385/735], Loss: 0.4121\n",
      "Epoch [27/50], Step [386/735], Loss: 5.4593\n",
      "Epoch [27/50], Step [387/735], Loss: 0.4708\n",
      "Epoch [27/50], Step [388/735], Loss: 0.6017\n",
      "Epoch [27/50], Step [389/735], Loss: 0.7133\n",
      "Epoch [27/50], Step [390/735], Loss: 1.4851\n",
      "Epoch [27/50], Step [391/735], Loss: 0.3208\n",
      "Epoch [27/50], Step [392/735], Loss: 0.3525\n",
      "Epoch [27/50], Step [393/735], Loss: 0.5963\n",
      "Epoch [27/50], Step [394/735], Loss: 0.2253\n",
      "Epoch [27/50], Step [395/735], Loss: 0.1647\n",
      "Epoch [27/50], Step [396/735], Loss: 0.2149\n",
      "Epoch [27/50], Step [397/735], Loss: 0.6475\n",
      "Epoch [27/50], Step [398/735], Loss: 0.1304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Step [399/735], Loss: 0.1949\n",
      "Epoch [27/50], Step [400/735], Loss: 0.2549\n",
      "Epoch [27/50], Step [401/735], Loss: 0.3442\n",
      "Epoch [27/50], Step [402/735], Loss: 1.9948\n",
      "Epoch [27/50], Step [403/735], Loss: 0.3562\n",
      "Epoch [27/50], Step [404/735], Loss: 0.2776\n",
      "Epoch [27/50], Step [405/735], Loss: 0.5302\n",
      "Epoch [27/50], Step [406/735], Loss: 0.2844\n",
      "Epoch [27/50], Step [407/735], Loss: 0.2058\n",
      "Epoch [27/50], Step [408/735], Loss: 0.2728\n",
      "Epoch [27/50], Step [409/735], Loss: 0.0761\n",
      "Epoch [27/50], Step [410/735], Loss: 0.1850\n",
      "Epoch [27/50], Step [411/735], Loss: 0.5181\n",
      "Epoch [27/50], Step [412/735], Loss: 0.1506\n",
      "Epoch [27/50], Step [413/735], Loss: 0.1816\n",
      "Epoch [27/50], Step [414/735], Loss: 4.9074\n",
      "Epoch [27/50], Step [415/735], Loss: 0.5090\n",
      "Epoch [27/50], Step [416/735], Loss: 0.5628\n",
      "Epoch [27/50], Step [417/735], Loss: 0.1490\n",
      "Epoch [27/50], Step [418/735], Loss: 0.3525\n",
      "Epoch [27/50], Step [419/735], Loss: 0.2915\n",
      "Epoch [27/50], Step [420/735], Loss: 0.5729\n",
      "Epoch [27/50], Step [421/735], Loss: 0.1274\n",
      "Epoch [27/50], Step [422/735], Loss: 0.2071\n",
      "Epoch [27/50], Step [423/735], Loss: 0.3256\n",
      "Epoch [27/50], Step [424/735], Loss: 0.1836\n",
      "Epoch [27/50], Step [425/735], Loss: 0.1137\n",
      "Epoch [27/50], Step [426/735], Loss: 0.0970\n",
      "Epoch [27/50], Step [427/735], Loss: 0.2492\n",
      "Epoch [27/50], Step [428/735], Loss: 0.2352\n",
      "Epoch [27/50], Step [429/735], Loss: 0.3229\n",
      "Epoch [27/50], Step [430/735], Loss: 0.1813\n",
      "Epoch [27/50], Step [431/735], Loss: 1.0986\n",
      "Epoch [27/50], Step [432/735], Loss: 0.2163\n",
      "Epoch [27/50], Step [433/735], Loss: 0.1219\n",
      "Epoch [27/50], Step [434/735], Loss: 0.4020\n",
      "Epoch [27/50], Step [435/735], Loss: 0.2528\n",
      "Epoch [27/50], Step [436/735], Loss: 0.4194\n",
      "Epoch [27/50], Step [437/735], Loss: 0.4737\n",
      "Epoch [27/50], Step [438/735], Loss: 0.7813\n",
      "Epoch [27/50], Step [439/735], Loss: 0.2666\n",
      "Epoch [27/50], Step [440/735], Loss: 0.2668\n",
      "Epoch [27/50], Step [441/735], Loss: 0.2674\n",
      "Epoch [27/50], Step [442/735], Loss: 0.0754\n",
      "Epoch [27/50], Step [443/735], Loss: 0.3303\n",
      "Epoch [27/50], Step [444/735], Loss: 0.1466\n",
      "Epoch [27/50], Step [445/735], Loss: 1.1476\n",
      "Epoch [27/50], Step [446/735], Loss: 0.2352\n",
      "Epoch [27/50], Step [447/735], Loss: 1.2398\n",
      "Epoch [27/50], Step [448/735], Loss: 0.4372\n",
      "Epoch [27/50], Step [449/735], Loss: 0.8182\n",
      "Epoch [27/50], Step [450/735], Loss: 0.4199\n",
      "Epoch [27/50], Step [451/735], Loss: 0.1436\n",
      "Epoch [27/50], Step [452/735], Loss: 0.2282\n",
      "Epoch [27/50], Step [453/735], Loss: 0.1134\n",
      "Epoch [27/50], Step [454/735], Loss: 0.3784\n",
      "Epoch [27/50], Step [455/735], Loss: 0.1572\n",
      "Epoch [27/50], Step [456/735], Loss: 0.1942\n",
      "Epoch [27/50], Step [457/735], Loss: 0.1996\n",
      "Epoch [27/50], Step [458/735], Loss: 0.3475\n",
      "Epoch [27/50], Step [459/735], Loss: 0.1688\n",
      "Epoch [27/50], Step [460/735], Loss: 0.2778\n",
      "Epoch [27/50], Step [461/735], Loss: 0.4134\n",
      "Epoch [27/50], Step [462/735], Loss: 0.7017\n",
      "Epoch [27/50], Step [463/735], Loss: 0.6343\n",
      "Epoch [27/50], Step [464/735], Loss: 0.1866\n",
      "Epoch [27/50], Step [465/735], Loss: 1.1503\n",
      "Epoch [27/50], Step [466/735], Loss: 0.3398\n",
      "Epoch [27/50], Step [467/735], Loss: 0.2326\n",
      "Epoch [27/50], Step [468/735], Loss: 0.3728\n",
      "Epoch [27/50], Step [469/735], Loss: 0.5993\n",
      "Epoch [27/50], Step [470/735], Loss: 0.1617\n",
      "Epoch [27/50], Step [471/735], Loss: 0.2210\n",
      "Epoch [27/50], Step [472/735], Loss: 0.1828\n",
      "Epoch [27/50], Step [473/735], Loss: 0.1637\n",
      "Epoch [27/50], Step [474/735], Loss: 0.7013\n",
      "Epoch [27/50], Step [475/735], Loss: 0.2513\n",
      "Epoch [27/50], Step [476/735], Loss: 0.2054\n",
      "Epoch [27/50], Step [477/735], Loss: 0.4428\n",
      "Epoch [27/50], Step [478/735], Loss: 0.2528\n",
      "Epoch [27/50], Step [479/735], Loss: 0.2554\n",
      "Epoch [27/50], Step [480/735], Loss: 0.1794\n",
      "Epoch [27/50], Step [481/735], Loss: 0.1289\n",
      "Epoch [27/50], Step [482/735], Loss: 0.6515\n",
      "Epoch [27/50], Step [483/735], Loss: 0.3197\n",
      "Epoch [27/50], Step [484/735], Loss: 0.4383\n",
      "Epoch [27/50], Step [485/735], Loss: 0.0976\n",
      "Epoch [27/50], Step [486/735], Loss: 0.4028\n",
      "Epoch [27/50], Step [487/735], Loss: 0.4909\n",
      "Epoch [27/50], Step [488/735], Loss: 0.4475\n",
      "Epoch [27/50], Step [489/735], Loss: 0.3799\n",
      "Epoch [27/50], Step [490/735], Loss: 0.4679\n",
      "Epoch [27/50], Step [491/735], Loss: 0.0923\n",
      "Epoch [27/50], Step [492/735], Loss: 0.1020\n",
      "Epoch [27/50], Step [493/735], Loss: 0.2667\n",
      "Epoch [27/50], Step [494/735], Loss: 0.0755\n",
      "Epoch [27/50], Step [495/735], Loss: 0.1174\n",
      "Epoch [27/50], Step [496/735], Loss: 0.6187\n",
      "Epoch [27/50], Step [497/735], Loss: 0.4639\n",
      "Epoch [27/50], Step [498/735], Loss: 0.5271\n",
      "Epoch [27/50], Step [499/735], Loss: 0.4689\n",
      "Epoch [27/50], Step [500/735], Loss: 0.1735\n",
      "Epoch [27/50], Step [501/735], Loss: 0.0656\n",
      "Epoch [27/50], Step [502/735], Loss: 0.4516\n",
      "Epoch [27/50], Step [503/735], Loss: 0.8127\n",
      "Epoch [27/50], Step [504/735], Loss: 0.6565\n",
      "Epoch [27/50], Step [505/735], Loss: 0.2478\n",
      "Epoch [27/50], Step [506/735], Loss: 0.4077\n",
      "Epoch [27/50], Step [507/735], Loss: 0.2265\n",
      "Epoch [27/50], Step [508/735], Loss: 0.9150\n",
      "Epoch [27/50], Step [509/735], Loss: 0.1615\n",
      "Epoch [27/50], Step [510/735], Loss: 0.7190\n",
      "Epoch [27/50], Step [511/735], Loss: 0.2106\n",
      "Epoch [27/50], Step [512/735], Loss: 0.3546\n",
      "Epoch [27/50], Step [513/735], Loss: 0.1452\n",
      "Epoch [27/50], Step [514/735], Loss: 0.6914\n",
      "Epoch [27/50], Step [515/735], Loss: 0.6177\n",
      "Epoch [27/50], Step [516/735], Loss: 0.2489\n",
      "Epoch [27/50], Step [517/735], Loss: 0.1027\n",
      "Epoch [27/50], Step [518/735], Loss: 1.2867\n",
      "Epoch [27/50], Step [519/735], Loss: 0.1918\n",
      "Epoch [27/50], Step [520/735], Loss: 0.1577\n",
      "Epoch [27/50], Step [521/735], Loss: 0.3105\n",
      "Epoch [27/50], Step [522/735], Loss: 0.4759\n",
      "Epoch [27/50], Step [523/735], Loss: 0.1093\n",
      "Epoch [27/50], Step [524/735], Loss: 0.2818\n",
      "Epoch [27/50], Step [525/735], Loss: 0.1825\n",
      "Epoch [27/50], Step [526/735], Loss: 0.0998\n",
      "Epoch [27/50], Step [527/735], Loss: 0.0861\n",
      "Epoch [27/50], Step [528/735], Loss: 0.4646\n",
      "Epoch [27/50], Step [529/735], Loss: 0.0851\n",
      "Epoch [27/50], Step [530/735], Loss: 0.2239\n",
      "Epoch [27/50], Step [531/735], Loss: 0.1619\n",
      "Epoch [27/50], Step [532/735], Loss: 0.5394\n",
      "Epoch [27/50], Step [533/735], Loss: 0.1171\n",
      "Epoch [27/50], Step [534/735], Loss: 0.4355\n",
      "Epoch [27/50], Step [535/735], Loss: 0.3396\n",
      "Epoch [27/50], Step [536/735], Loss: 0.2818\n",
      "Epoch [27/50], Step [537/735], Loss: 0.2606\n",
      "Epoch [27/50], Step [538/735], Loss: 1.2071\n",
      "Epoch [27/50], Step [539/735], Loss: 0.2364\n",
      "Epoch [27/50], Step [540/735], Loss: 0.1911\n",
      "Epoch [27/50], Step [541/735], Loss: 0.5041\n",
      "Epoch [27/50], Step [542/735], Loss: 0.4055\n",
      "Epoch [27/50], Step [543/735], Loss: 0.2671\n",
      "Epoch [27/50], Step [544/735], Loss: 0.4675\n",
      "Epoch [27/50], Step [545/735], Loss: 0.0804\n",
      "Epoch [27/50], Step [546/735], Loss: 0.5022\n",
      "Epoch [27/50], Step [547/735], Loss: 0.2775\n",
      "Epoch [27/50], Step [548/735], Loss: 0.1834\n",
      "Epoch [27/50], Step [549/735], Loss: 0.2498\n",
      "Epoch [27/50], Step [550/735], Loss: 0.2431\n",
      "Epoch [27/50], Step [551/735], Loss: 0.8767\n",
      "Epoch [27/50], Step [552/735], Loss: 0.7172\n",
      "Epoch [27/50], Step [553/735], Loss: 0.3021\n",
      "Epoch [27/50], Step [554/735], Loss: 1.2624\n",
      "Epoch [27/50], Step [555/735], Loss: 0.1946\n",
      "Epoch [27/50], Step [556/735], Loss: 0.3694\n",
      "Epoch [27/50], Step [557/735], Loss: 0.4886\n",
      "Epoch [27/50], Step [558/735], Loss: 0.1767\n",
      "Epoch [27/50], Step [559/735], Loss: 0.0574\n",
      "Epoch [27/50], Step [560/735], Loss: 0.3225\n",
      "Epoch [27/50], Step [561/735], Loss: 0.2889\n",
      "Epoch [27/50], Step [562/735], Loss: 0.3081\n",
      "Epoch [27/50], Step [563/735], Loss: 0.2812\n",
      "Epoch [27/50], Step [564/735], Loss: 0.4230\n",
      "Epoch [27/50], Step [565/735], Loss: 0.1657\n",
      "Epoch [27/50], Step [566/735], Loss: 4.8318\n",
      "Epoch [27/50], Step [567/735], Loss: 0.3775\n",
      "Epoch [27/50], Step [568/735], Loss: 0.2429\n",
      "Epoch [27/50], Step [569/735], Loss: 0.4154\n",
      "Epoch [27/50], Step [570/735], Loss: 0.2220\n",
      "Epoch [27/50], Step [571/735], Loss: 0.2239\n",
      "Epoch [27/50], Step [572/735], Loss: 0.2900\n",
      "Epoch [27/50], Step [573/735], Loss: 0.3515\n",
      "Epoch [27/50], Step [574/735], Loss: 0.3909\n",
      "Epoch [27/50], Step [575/735], Loss: 1.0070\n",
      "Epoch [27/50], Step [576/735], Loss: 0.1344\n",
      "Epoch [27/50], Step [577/735], Loss: 5.1211\n",
      "Epoch [27/50], Step [578/735], Loss: 0.0916\n",
      "Epoch [27/50], Step [579/735], Loss: 0.1222\n",
      "Epoch [27/50], Step [580/735], Loss: 0.4661\n",
      "Epoch [27/50], Step [581/735], Loss: 0.0601\n",
      "Epoch [27/50], Step [582/735], Loss: 0.9232\n",
      "Epoch [27/50], Step [583/735], Loss: 0.1766\n",
      "Epoch [27/50], Step [584/735], Loss: 0.2055\n",
      "Epoch [27/50], Step [585/735], Loss: 0.6037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Step [586/735], Loss: 0.3229\n",
      "Epoch [27/50], Step [587/735], Loss: 0.3132\n",
      "Epoch [27/50], Step [588/735], Loss: 0.2518\n",
      "Epoch [27/50], Step [589/735], Loss: 0.1920\n",
      "Epoch [27/50], Step [590/735], Loss: 0.0946\n",
      "Epoch [27/50], Step [591/735], Loss: 0.7816\n",
      "Epoch [27/50], Step [592/735], Loss: 0.0653\n",
      "Epoch [27/50], Step [593/735], Loss: 0.1596\n",
      "Epoch [27/50], Step [594/735], Loss: 4.7048\n",
      "Epoch [27/50], Step [595/735], Loss: 0.5653\n",
      "Epoch [27/50], Step [596/735], Loss: 0.8304\n",
      "Epoch [27/50], Step [597/735], Loss: 1.0745\n",
      "Epoch [27/50], Step [598/735], Loss: 0.2156\n",
      "Epoch [27/50], Step [599/735], Loss: 0.4790\n",
      "Epoch [27/50], Step [600/735], Loss: 0.9105\n",
      "Epoch [27/50], Step [601/735], Loss: 0.1360\n",
      "Epoch [27/50], Step [602/735], Loss: 0.2520\n",
      "Epoch [27/50], Step [603/735], Loss: 0.1543\n",
      "Epoch [27/50], Step [604/735], Loss: 0.2964\n",
      "Epoch [27/50], Step [605/735], Loss: 0.8064\n",
      "Epoch [27/50], Step [606/735], Loss: 0.1498\n",
      "Epoch [27/50], Step [607/735], Loss: 0.3230\n",
      "Epoch [27/50], Step [608/735], Loss: 0.3368\n",
      "Epoch [27/50], Step [609/735], Loss: 0.2235\n",
      "Epoch [27/50], Step [610/735], Loss: 0.2244\n",
      "Epoch [27/50], Step [611/735], Loss: 0.0902\n",
      "Epoch [27/50], Step [612/735], Loss: 0.1816\n",
      "Epoch [27/50], Step [613/735], Loss: 0.2305\n",
      "Epoch [27/50], Step [614/735], Loss: 0.3241\n",
      "Epoch [27/50], Step [615/735], Loss: 0.0946\n",
      "Epoch [27/50], Step [616/735], Loss: 0.2907\n",
      "Epoch [27/50], Step [617/735], Loss: 0.3451\n",
      "Epoch [27/50], Step [618/735], Loss: 0.3004\n",
      "Epoch [27/50], Step [619/735], Loss: 0.3298\n",
      "Epoch [27/50], Step [620/735], Loss: 0.1568\n",
      "Epoch [27/50], Step [621/735], Loss: 0.7453\n",
      "Epoch [27/50], Step [622/735], Loss: 0.5644\n",
      "Epoch [27/50], Step [623/735], Loss: 0.4963\n",
      "Epoch [27/50], Step [624/735], Loss: 0.1371\n",
      "Epoch [27/50], Step [625/735], Loss: 0.5607\n",
      "Epoch [27/50], Step [626/735], Loss: 0.1292\n",
      "Epoch [27/50], Step [627/735], Loss: 0.1799\n",
      "Epoch [27/50], Step [628/735], Loss: 0.3986\n",
      "Epoch [27/50], Step [629/735], Loss: 0.1033\n",
      "Epoch [27/50], Step [630/735], Loss: 0.0909\n",
      "Epoch [27/50], Step [631/735], Loss: 0.8880\n",
      "Epoch [27/50], Step [632/735], Loss: 0.2805\n",
      "Epoch [27/50], Step [633/735], Loss: 0.4994\n",
      "Epoch [27/50], Step [634/735], Loss: 0.2209\n",
      "Epoch [27/50], Step [635/735], Loss: 0.2807\n",
      "Epoch [27/50], Step [636/735], Loss: 0.2762\n",
      "Epoch [27/50], Step [637/735], Loss: 0.1834\n",
      "Epoch [27/50], Step [638/735], Loss: 0.3971\n",
      "Epoch [27/50], Step [639/735], Loss: 0.3198\n",
      "Epoch [27/50], Step [640/735], Loss: 0.3906\n",
      "Epoch [27/50], Step [641/735], Loss: 0.4583\n",
      "Epoch [27/50], Step [642/735], Loss: 0.2536\n",
      "Epoch [27/50], Step [643/735], Loss: 0.2359\n",
      "Epoch [27/50], Step [644/735], Loss: 0.2573\n",
      "Epoch [27/50], Step [645/735], Loss: 0.3112\n",
      "Epoch [27/50], Step [646/735], Loss: 0.3105\n",
      "Epoch [27/50], Step [647/735], Loss: 0.1780\n",
      "Epoch [27/50], Step [648/735], Loss: 0.3598\n",
      "Epoch [27/50], Step [649/735], Loss: 0.4630\n",
      "Epoch [27/50], Step [650/735], Loss: 0.3587\n",
      "Epoch [27/50], Step [651/735], Loss: 0.4876\n",
      "Epoch [27/50], Step [652/735], Loss: 0.1975\n",
      "Epoch [27/50], Step [653/735], Loss: 1.8460\n",
      "Epoch [27/50], Step [654/735], Loss: 0.5099\n",
      "Epoch [27/50], Step [655/735], Loss: 0.1001\n",
      "Epoch [27/50], Step [656/735], Loss: 0.4567\n",
      "Epoch [27/50], Step [657/735], Loss: 0.1671\n",
      "Epoch [27/50], Step [658/735], Loss: 0.4109\n",
      "Epoch [27/50], Step [659/735], Loss: 1.0645\n",
      "Epoch [27/50], Step [660/735], Loss: 0.1708\n",
      "Epoch [27/50], Step [661/735], Loss: 0.2901\n",
      "Epoch [27/50], Step [662/735], Loss: 0.5649\n",
      "Epoch [27/50], Step [663/735], Loss: 0.5474\n",
      "Epoch [27/50], Step [664/735], Loss: 0.3578\n",
      "Epoch [27/50], Step [665/735], Loss: 0.3916\n",
      "Epoch [27/50], Step [666/735], Loss: 0.3136\n",
      "Epoch [27/50], Step [667/735], Loss: 0.6167\n",
      "Epoch [27/50], Step [668/735], Loss: 0.1083\n",
      "Epoch [27/50], Step [669/735], Loss: 0.1384\n",
      "Epoch [27/50], Step [670/735], Loss: 0.1843\n",
      "Epoch [27/50], Step [671/735], Loss: 0.6326\n",
      "Epoch [27/50], Step [672/735], Loss: 0.2000\n",
      "Epoch [27/50], Step [673/735], Loss: 0.6278\n",
      "Epoch [27/50], Step [674/735], Loss: 0.4303\n",
      "Epoch [27/50], Step [675/735], Loss: 0.8423\n",
      "Epoch [27/50], Step [676/735], Loss: 0.0536\n",
      "Epoch [27/50], Step [677/735], Loss: 0.0804\n",
      "Epoch [27/50], Step [678/735], Loss: 0.1105\n",
      "Epoch [27/50], Step [679/735], Loss: 0.1275\n",
      "Epoch [27/50], Step [680/735], Loss: 0.2143\n",
      "Epoch [27/50], Step [681/735], Loss: 0.3214\n",
      "Epoch [27/50], Step [682/735], Loss: 0.7860\n",
      "Epoch [27/50], Step [683/735], Loss: 0.3248\n",
      "Epoch [27/50], Step [684/735], Loss: 0.0731\n",
      "Epoch [27/50], Step [685/735], Loss: 0.5998\n",
      "Epoch [27/50], Step [686/735], Loss: 0.2847\n",
      "Epoch [27/50], Step [687/735], Loss: 0.3950\n",
      "Epoch [27/50], Step [688/735], Loss: 1.1520\n",
      "Epoch [27/50], Step [689/735], Loss: 0.4212\n",
      "Epoch [27/50], Step [690/735], Loss: 0.1854\n",
      "Epoch [27/50], Step [691/735], Loss: 0.1922\n",
      "Epoch [27/50], Step [692/735], Loss: 0.5140\n",
      "Epoch [27/50], Step [693/735], Loss: 0.4353\n",
      "Epoch [27/50], Step [694/735], Loss: 0.1049\n",
      "Epoch [27/50], Step [695/735], Loss: 0.1754\n",
      "Epoch [27/50], Step [696/735], Loss: 0.5485\n",
      "Epoch [27/50], Step [697/735], Loss: 0.0812\n",
      "Epoch [27/50], Step [698/735], Loss: 0.7146\n",
      "Epoch [27/50], Step [699/735], Loss: 0.3470\n",
      "Epoch [27/50], Step [700/735], Loss: 0.2336\n",
      "Epoch [27/50], Step [701/735], Loss: 0.1547\n",
      "Epoch [27/50], Step [702/735], Loss: 0.2673\n",
      "Epoch [27/50], Step [703/735], Loss: 0.2233\n",
      "Epoch [27/50], Step [704/735], Loss: 0.3964\n",
      "Epoch [27/50], Step [705/735], Loss: 0.6410\n",
      "Epoch [27/50], Step [706/735], Loss: 0.3686\n",
      "Epoch [27/50], Step [707/735], Loss: 0.2690\n",
      "Epoch [27/50], Step [708/735], Loss: 0.3516\n",
      "Epoch [27/50], Step [709/735], Loss: 0.4154\n",
      "Epoch [27/50], Step [710/735], Loss: 0.1513\n",
      "Epoch [27/50], Step [711/735], Loss: 0.6921\n",
      "Epoch [27/50], Step [712/735], Loss: 0.2295\n",
      "Epoch [27/50], Step [713/735], Loss: 0.1489\n",
      "Epoch [27/50], Step [714/735], Loss: 0.2974\n",
      "Epoch [27/50], Step [715/735], Loss: 0.1170\n",
      "Epoch [27/50], Step [716/735], Loss: 0.3870\n",
      "Epoch [27/50], Step [717/735], Loss: 0.5014\n",
      "Epoch [27/50], Step [718/735], Loss: 0.3549\n",
      "Epoch [27/50], Step [719/735], Loss: 0.6485\n",
      "Epoch [27/50], Step [720/735], Loss: 0.1078\n",
      "Epoch [27/50], Step [721/735], Loss: 0.1842\n",
      "Epoch [27/50], Step [722/735], Loss: 0.8161\n",
      "Epoch [27/50], Step [723/735], Loss: 1.7342\n",
      "Epoch [27/50], Step [724/735], Loss: 0.1628\n",
      "Epoch [27/50], Step [725/735], Loss: 0.1260\n",
      "Epoch [27/50], Step [726/735], Loss: 0.2165\n",
      "Epoch [27/50], Step [727/735], Loss: 0.3300\n",
      "Epoch [27/50], Step [728/735], Loss: 0.1336\n",
      "Epoch [27/50], Step [729/735], Loss: 0.4189\n",
      "Epoch [27/50], Step [730/735], Loss: 0.4063\n",
      "Epoch [27/50], Step [731/735], Loss: 0.1180\n",
      "Epoch [27/50], Step [732/735], Loss: 0.1939\n",
      "Epoch [27/50], Step [733/735], Loss: 0.2894\n",
      "Epoch [27/50], Step [734/735], Loss: 0.3717\n",
      "Epoch [27/50], Step [735/735], Loss: 0.1923\n",
      "Epoch [28/50], Step [1/735], Loss: 0.1490\n",
      "Epoch [28/50], Step [2/735], Loss: 0.1726\n",
      "Epoch [28/50], Step [3/735], Loss: 1.3680\n",
      "Epoch [28/50], Step [4/735], Loss: 0.1512\n",
      "Epoch [28/50], Step [5/735], Loss: 1.1354\n",
      "Epoch [28/50], Step [6/735], Loss: 0.2056\n",
      "Epoch [28/50], Step [7/735], Loss: 0.1485\n",
      "Epoch [28/50], Step [8/735], Loss: 0.2832\n",
      "Epoch [28/50], Step [9/735], Loss: 0.3676\n",
      "Epoch [28/50], Step [10/735], Loss: 0.1736\n",
      "Epoch [28/50], Step [11/735], Loss: 0.2429\n",
      "Epoch [28/50], Step [12/735], Loss: 0.4376\n",
      "Epoch [28/50], Step [13/735], Loss: 0.2204\n",
      "Epoch [28/50], Step [14/735], Loss: 0.1692\n",
      "Epoch [28/50], Step [15/735], Loss: 0.7641\n",
      "Epoch [28/50], Step [16/735], Loss: 0.7413\n",
      "Epoch [28/50], Step [17/735], Loss: 0.1712\n",
      "Epoch [28/50], Step [18/735], Loss: 0.1080\n",
      "Epoch [28/50], Step [19/735], Loss: 0.2459\n",
      "Epoch [28/50], Step [20/735], Loss: 0.2975\n",
      "Epoch [28/50], Step [21/735], Loss: 0.2644\n",
      "Epoch [28/50], Step [22/735], Loss: 0.3385\n",
      "Epoch [28/50], Step [23/735], Loss: 1.0186\n",
      "Epoch [28/50], Step [24/735], Loss: 0.3482\n",
      "Epoch [28/50], Step [25/735], Loss: 0.6718\n",
      "Epoch [28/50], Step [26/735], Loss: 0.1557\n",
      "Epoch [28/50], Step [27/735], Loss: 0.2243\n",
      "Epoch [28/50], Step [28/735], Loss: 0.2470\n",
      "Epoch [28/50], Step [29/735], Loss: 0.1542\n",
      "Epoch [28/50], Step [30/735], Loss: 1.0296\n",
      "Epoch [28/50], Step [31/735], Loss: 0.2720\n",
      "Epoch [28/50], Step [32/735], Loss: 0.5736\n",
      "Epoch [28/50], Step [33/735], Loss: 0.5170\n",
      "Epoch [28/50], Step [34/735], Loss: 0.2579\n",
      "Epoch [28/50], Step [35/735], Loss: 0.1233\n",
      "Epoch [28/50], Step [36/735], Loss: 0.2105\n",
      "Epoch [28/50], Step [37/735], Loss: 0.5121\n",
      "Epoch [28/50], Step [38/735], Loss: 0.1075\n",
      "Epoch [28/50], Step [39/735], Loss: 0.1474\n",
      "Epoch [28/50], Step [40/735], Loss: 0.5043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Step [41/735], Loss: 0.3633\n",
      "Epoch [28/50], Step [42/735], Loss: 0.3509\n",
      "Epoch [28/50], Step [43/735], Loss: 0.0707\n",
      "Epoch [28/50], Step [44/735], Loss: 0.2371\n",
      "Epoch [28/50], Step [45/735], Loss: 0.7260\n",
      "Epoch [28/50], Step [46/735], Loss: 0.0780\n",
      "Epoch [28/50], Step [47/735], Loss: 0.3216\n",
      "Epoch [28/50], Step [48/735], Loss: 0.5270\n",
      "Epoch [28/50], Step [49/735], Loss: 0.4655\n",
      "Epoch [28/50], Step [50/735], Loss: 0.4872\n",
      "Epoch [28/50], Step [51/735], Loss: 0.6300\n",
      "Epoch [28/50], Step [52/735], Loss: 0.3265\n",
      "Epoch [28/50], Step [53/735], Loss: 0.4427\n",
      "Epoch [28/50], Step [54/735], Loss: 0.2344\n",
      "Epoch [28/50], Step [55/735], Loss: 0.2938\n",
      "Epoch [28/50], Step [56/735], Loss: 0.3125\n",
      "Epoch [28/50], Step [57/735], Loss: 0.4079\n",
      "Epoch [28/50], Step [58/735], Loss: 0.2574\n",
      "Epoch [28/50], Step [59/735], Loss: 0.7287\n",
      "Epoch [28/50], Step [60/735], Loss: 0.1270\n",
      "Epoch [28/50], Step [61/735], Loss: 0.3291\n",
      "Epoch [28/50], Step [62/735], Loss: 0.1477\n",
      "Epoch [28/50], Step [63/735], Loss: 0.5282\n",
      "Epoch [28/50], Step [64/735], Loss: 0.0883\n",
      "Epoch [28/50], Step [65/735], Loss: 0.2440\n",
      "Epoch [28/50], Step [66/735], Loss: 0.2833\n",
      "Epoch [28/50], Step [67/735], Loss: 0.4783\n",
      "Epoch [28/50], Step [68/735], Loss: 0.4830\n",
      "Epoch [28/50], Step [69/735], Loss: 0.5181\n",
      "Epoch [28/50], Step [70/735], Loss: 0.5392\n",
      "Epoch [28/50], Step [71/735], Loss: 0.2912\n",
      "Epoch [28/50], Step [72/735], Loss: 0.2403\n",
      "Epoch [28/50], Step [73/735], Loss: 0.3461\n",
      "Epoch [28/50], Step [74/735], Loss: 0.4995\n",
      "Epoch [28/50], Step [75/735], Loss: 0.6602\n",
      "Epoch [28/50], Step [76/735], Loss: 0.4672\n",
      "Epoch [28/50], Step [77/735], Loss: 0.4267\n",
      "Epoch [28/50], Step [78/735], Loss: 0.1679\n",
      "Epoch [28/50], Step [79/735], Loss: 0.3893\n",
      "Epoch [28/50], Step [80/735], Loss: 0.2100\n",
      "Epoch [28/50], Step [81/735], Loss: 0.4736\n",
      "Epoch [28/50], Step [82/735], Loss: 0.1642\n",
      "Epoch [28/50], Step [83/735], Loss: 0.0826\n",
      "Epoch [28/50], Step [84/735], Loss: 0.3767\n",
      "Epoch [28/50], Step [85/735], Loss: 0.1357\n",
      "Epoch [28/50], Step [86/735], Loss: 0.4184\n",
      "Epoch [28/50], Step [87/735], Loss: 0.4624\n",
      "Epoch [28/50], Step [88/735], Loss: 0.1110\n",
      "Epoch [28/50], Step [89/735], Loss: 0.2639\n",
      "Epoch [28/50], Step [90/735], Loss: 0.1355\n",
      "Epoch [28/50], Step [91/735], Loss: 0.6771\n",
      "Epoch [28/50], Step [92/735], Loss: 0.1426\n",
      "Epoch [28/50], Step [93/735], Loss: 0.1863\n",
      "Epoch [28/50], Step [94/735], Loss: 0.4667\n",
      "Epoch [28/50], Step [95/735], Loss: 0.0663\n",
      "Epoch [28/50], Step [96/735], Loss: 0.1824\n",
      "Epoch [28/50], Step [97/735], Loss: 0.3222\n",
      "Epoch [28/50], Step [98/735], Loss: 0.9684\n",
      "Epoch [28/50], Step [99/735], Loss: 0.3810\n",
      "Epoch [28/50], Step [100/735], Loss: 0.3107\n",
      "Epoch [28/50], Step [101/735], Loss: 0.4789\n",
      "Epoch [28/50], Step [102/735], Loss: 0.1084\n",
      "Epoch [28/50], Step [103/735], Loss: 0.3877\n",
      "Epoch [28/50], Step [104/735], Loss: 1.2818\n",
      "Epoch [28/50], Step [105/735], Loss: 0.2384\n",
      "Epoch [28/50], Step [106/735], Loss: 0.4011\n",
      "Epoch [28/50], Step [107/735], Loss: 0.2225\n",
      "Epoch [28/50], Step [108/735], Loss: 0.0801\n",
      "Epoch [28/50], Step [109/735], Loss: 0.3535\n",
      "Epoch [28/50], Step [110/735], Loss: 0.2698\n",
      "Epoch [28/50], Step [111/735], Loss: 0.0626\n",
      "Epoch [28/50], Step [112/735], Loss: 0.1839\n",
      "Epoch [28/50], Step [113/735], Loss: 0.6658\n",
      "Epoch [28/50], Step [114/735], Loss: 0.7687\n",
      "Epoch [28/50], Step [115/735], Loss: 0.1633\n",
      "Epoch [28/50], Step [116/735], Loss: 0.1082\n",
      "Epoch [28/50], Step [117/735], Loss: 0.0640\n",
      "Epoch [28/50], Step [118/735], Loss: 0.6053\n",
      "Epoch [28/50], Step [119/735], Loss: 0.7468\n",
      "Epoch [28/50], Step [120/735], Loss: 0.1466\n",
      "Epoch [28/50], Step [121/735], Loss: 0.4265\n",
      "Epoch [28/50], Step [122/735], Loss: 0.1557\n",
      "Epoch [28/50], Step [123/735], Loss: 0.2299\n",
      "Epoch [28/50], Step [124/735], Loss: 0.1074\n",
      "Epoch [28/50], Step [125/735], Loss: 0.2589\n",
      "Epoch [28/50], Step [126/735], Loss: 0.1253\n",
      "Epoch [28/50], Step [127/735], Loss: 0.2806\n",
      "Epoch [28/50], Step [128/735], Loss: 0.0841\n",
      "Epoch [28/50], Step [129/735], Loss: 0.4338\n",
      "Epoch [28/50], Step [130/735], Loss: 0.3565\n",
      "Epoch [28/50], Step [131/735], Loss: 0.3893\n",
      "Epoch [28/50], Step [132/735], Loss: 0.2364\n",
      "Epoch [28/50], Step [133/735], Loss: 0.4162\n",
      "Epoch [28/50], Step [134/735], Loss: 0.3784\n",
      "Epoch [28/50], Step [135/735], Loss: 0.3344\n",
      "Epoch [28/50], Step [136/735], Loss: 0.2154\n",
      "Epoch [28/50], Step [137/735], Loss: 0.7071\n",
      "Epoch [28/50], Step [138/735], Loss: 0.8717\n",
      "Epoch [28/50], Step [139/735], Loss: 0.5585\n",
      "Epoch [28/50], Step [140/735], Loss: 0.1488\n",
      "Epoch [28/50], Step [141/735], Loss: 0.3173\n",
      "Epoch [28/50], Step [142/735], Loss: 0.2834\n",
      "Epoch [28/50], Step [143/735], Loss: 0.2760\n",
      "Epoch [28/50], Step [144/735], Loss: 0.2576\n",
      "Epoch [28/50], Step [145/735], Loss: 0.2842\n",
      "Epoch [28/50], Step [146/735], Loss: 0.3890\n",
      "Epoch [28/50], Step [147/735], Loss: 0.4176\n",
      "Epoch [28/50], Step [148/735], Loss: 0.1422\n",
      "Epoch [28/50], Step [149/735], Loss: 0.3614\n",
      "Epoch [28/50], Step [150/735], Loss: 0.6095\n",
      "Epoch [28/50], Step [151/735], Loss: 0.2288\n",
      "Epoch [28/50], Step [152/735], Loss: 0.9276\n",
      "Epoch [28/50], Step [153/735], Loss: 0.5665\n",
      "Epoch [28/50], Step [154/735], Loss: 0.5452\n",
      "Epoch [28/50], Step [155/735], Loss: 0.1938\n",
      "Epoch [28/50], Step [156/735], Loss: 0.3807\n",
      "Epoch [28/50], Step [157/735], Loss: 0.2682\n",
      "Epoch [28/50], Step [158/735], Loss: 0.2669\n",
      "Epoch [28/50], Step [159/735], Loss: 0.0870\n",
      "Epoch [28/50], Step [160/735], Loss: 0.2546\n",
      "Epoch [28/50], Step [161/735], Loss: 0.2541\n",
      "Epoch [28/50], Step [162/735], Loss: 0.5945\n",
      "Epoch [28/50], Step [163/735], Loss: 0.3005\n",
      "Epoch [28/50], Step [164/735], Loss: 0.3034\n",
      "Epoch [28/50], Step [165/735], Loss: 0.1631\n",
      "Epoch [28/50], Step [166/735], Loss: 0.3361\n",
      "Epoch [28/50], Step [167/735], Loss: 0.0863\n",
      "Epoch [28/50], Step [168/735], Loss: 0.1795\n",
      "Epoch [28/50], Step [169/735], Loss: 0.2571\n",
      "Epoch [28/50], Step [170/735], Loss: 0.5160\n",
      "Epoch [28/50], Step [171/735], Loss: 0.2094\n",
      "Epoch [28/50], Step [172/735], Loss: 0.0529\n",
      "Epoch [28/50], Step [173/735], Loss: 1.1854\n",
      "Epoch [28/50], Step [174/735], Loss: 0.9947\n",
      "Epoch [28/50], Step [175/735], Loss: 0.1411\n",
      "Epoch [28/50], Step [176/735], Loss: 0.5528\n",
      "Epoch [28/50], Step [177/735], Loss: 0.3186\n",
      "Epoch [28/50], Step [178/735], Loss: 0.4260\n",
      "Epoch [28/50], Step [179/735], Loss: 0.9403\n",
      "Epoch [28/50], Step [180/735], Loss: 0.2616\n",
      "Epoch [28/50], Step [181/735], Loss: 0.6379\n",
      "Epoch [28/50], Step [182/735], Loss: 1.0606\n",
      "Epoch [28/50], Step [183/735], Loss: 0.4103\n",
      "Epoch [28/50], Step [184/735], Loss: 0.0808\n",
      "Epoch [28/50], Step [185/735], Loss: 0.1681\n",
      "Epoch [28/50], Step [186/735], Loss: 0.0902\n",
      "Epoch [28/50], Step [187/735], Loss: 0.7041\n",
      "Epoch [28/50], Step [188/735], Loss: 0.4963\n",
      "Epoch [28/50], Step [189/735], Loss: 0.2168\n",
      "Epoch [28/50], Step [190/735], Loss: 0.0836\n",
      "Epoch [28/50], Step [191/735], Loss: 0.6502\n",
      "Epoch [28/50], Step [192/735], Loss: 0.1746\n",
      "Epoch [28/50], Step [193/735], Loss: 1.2760\n",
      "Epoch [28/50], Step [194/735], Loss: 0.4571\n",
      "Epoch [28/50], Step [195/735], Loss: 0.2509\n",
      "Epoch [28/50], Step [196/735], Loss: 0.0562\n",
      "Epoch [28/50], Step [197/735], Loss: 0.4775\n",
      "Epoch [28/50], Step [198/735], Loss: 0.2193\n",
      "Epoch [28/50], Step [199/735], Loss: 0.2343\n",
      "Epoch [28/50], Step [200/735], Loss: 0.3726\n",
      "Epoch [28/50], Step [201/735], Loss: 1.5589\n",
      "Epoch [28/50], Step [202/735], Loss: 1.5279\n",
      "Epoch [28/50], Step [203/735], Loss: 0.6922\n",
      "Epoch [28/50], Step [204/735], Loss: 0.1415\n",
      "Epoch [28/50], Step [205/735], Loss: 0.3420\n",
      "Epoch [28/50], Step [206/735], Loss: 2.2365\n",
      "Epoch [28/50], Step [207/735], Loss: 0.2955\n",
      "Epoch [28/50], Step [208/735], Loss: 0.3193\n",
      "Epoch [28/50], Step [209/735], Loss: 0.1164\n",
      "Epoch [28/50], Step [210/735], Loss: 1.1215\n",
      "Epoch [28/50], Step [211/735], Loss: 1.2753\n",
      "Epoch [28/50], Step [212/735], Loss: 0.9720\n",
      "Epoch [28/50], Step [213/735], Loss: 0.6521\n",
      "Epoch [28/50], Step [214/735], Loss: 0.3550\n",
      "Epoch [28/50], Step [215/735], Loss: 0.2296\n",
      "Epoch [28/50], Step [216/735], Loss: 0.4864\n",
      "Epoch [28/50], Step [217/735], Loss: 0.5871\n",
      "Epoch [28/50], Step [218/735], Loss: 0.8510\n",
      "Epoch [28/50], Step [219/735], Loss: 1.0334\n",
      "Epoch [28/50], Step [220/735], Loss: 0.3429\n",
      "Epoch [28/50], Step [221/735], Loss: 0.1352\n",
      "Epoch [28/50], Step [222/735], Loss: 0.2420\n",
      "Epoch [28/50], Step [223/735], Loss: 0.6756\n",
      "Epoch [28/50], Step [224/735], Loss: 0.4011\n",
      "Epoch [28/50], Step [225/735], Loss: 0.1465\n",
      "Epoch [28/50], Step [226/735], Loss: 0.3869\n",
      "Epoch [28/50], Step [227/735], Loss: 0.3607\n",
      "Epoch [28/50], Step [228/735], Loss: 0.5610\n",
      "Epoch [28/50], Step [229/735], Loss: 0.3338\n",
      "Epoch [28/50], Step [230/735], Loss: 0.2700\n",
      "Epoch [28/50], Step [231/735], Loss: 0.1741\n",
      "Epoch [28/50], Step [232/735], Loss: 0.3760\n",
      "Epoch [28/50], Step [233/735], Loss: 0.3314\n",
      "Epoch [28/50], Step [234/735], Loss: 0.5522\n",
      "Epoch [28/50], Step [235/735], Loss: 0.1674\n",
      "Epoch [28/50], Step [236/735], Loss: 0.0847\n",
      "Epoch [28/50], Step [237/735], Loss: 0.4189\n",
      "Epoch [28/50], Step [238/735], Loss: 0.3415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Step [239/735], Loss: 0.4246\n",
      "Epoch [28/50], Step [240/735], Loss: 0.6386\n",
      "Epoch [28/50], Step [241/735], Loss: 0.1708\n",
      "Epoch [28/50], Step [242/735], Loss: 0.2397\n",
      "Epoch [28/50], Step [243/735], Loss: 0.1709\n",
      "Epoch [28/50], Step [244/735], Loss: 0.3155\n",
      "Epoch [28/50], Step [245/735], Loss: 0.1223\n",
      "Epoch [28/50], Step [246/735], Loss: 0.0659\n",
      "Epoch [28/50], Step [247/735], Loss: 0.1037\n",
      "Epoch [28/50], Step [248/735], Loss: 0.1043\n",
      "Epoch [28/50], Step [249/735], Loss: 0.4257\n",
      "Epoch [28/50], Step [250/735], Loss: 0.1160\n",
      "Epoch [28/50], Step [251/735], Loss: 0.3352\n",
      "Epoch [28/50], Step [252/735], Loss: 0.4661\n",
      "Epoch [28/50], Step [253/735], Loss: 0.2505\n",
      "Epoch [28/50], Step [254/735], Loss: 1.4275\n",
      "Epoch [28/50], Step [255/735], Loss: 0.8744\n",
      "Epoch [28/50], Step [256/735], Loss: 0.1663\n",
      "Epoch [28/50], Step [257/735], Loss: 0.2175\n",
      "Epoch [28/50], Step [258/735], Loss: 0.5502\n",
      "Epoch [28/50], Step [259/735], Loss: 0.6596\n",
      "Epoch [28/50], Step [260/735], Loss: 0.3020\n",
      "Epoch [28/50], Step [261/735], Loss: 0.4877\n",
      "Epoch [28/50], Step [262/735], Loss: 0.1305\n",
      "Epoch [28/50], Step [263/735], Loss: 0.7708\n",
      "Epoch [28/50], Step [264/735], Loss: 1.0731\n",
      "Epoch [28/50], Step [265/735], Loss: 0.5167\n",
      "Epoch [28/50], Step [266/735], Loss: 0.7490\n",
      "Epoch [28/50], Step [267/735], Loss: 0.2902\n",
      "Epoch [28/50], Step [268/735], Loss: 0.2075\n",
      "Epoch [28/50], Step [269/735], Loss: 0.1523\n",
      "Epoch [28/50], Step [270/735], Loss: 0.1986\n",
      "Epoch [28/50], Step [271/735], Loss: 0.1823\n",
      "Epoch [28/50], Step [272/735], Loss: 0.5869\n",
      "Epoch [28/50], Step [273/735], Loss: 0.3542\n",
      "Epoch [28/50], Step [274/735], Loss: 0.1577\n",
      "Epoch [28/50], Step [275/735], Loss: 0.3982\n",
      "Epoch [28/50], Step [276/735], Loss: 0.5387\n",
      "Epoch [28/50], Step [277/735], Loss: 0.1760\n",
      "Epoch [28/50], Step [278/735], Loss: 0.3330\n",
      "Epoch [28/50], Step [279/735], Loss: 0.3898\n",
      "Epoch [28/50], Step [280/735], Loss: 0.1715\n",
      "Epoch [28/50], Step [281/735], Loss: 0.3068\n",
      "Epoch [28/50], Step [282/735], Loss: 0.3704\n",
      "Epoch [28/50], Step [283/735], Loss: 0.0922\n",
      "Epoch [28/50], Step [284/735], Loss: 0.2245\n",
      "Epoch [28/50], Step [285/735], Loss: 0.3071\n",
      "Epoch [28/50], Step [286/735], Loss: 0.1571\n",
      "Epoch [28/50], Step [287/735], Loss: 0.1076\n",
      "Epoch [28/50], Step [288/735], Loss: 0.2142\n",
      "Epoch [28/50], Step [289/735], Loss: 0.1460\n",
      "Epoch [28/50], Step [290/735], Loss: 0.2875\n",
      "Epoch [28/50], Step [291/735], Loss: 0.6536\n",
      "Epoch [28/50], Step [292/735], Loss: 2.3268\n",
      "Epoch [28/50], Step [293/735], Loss: 0.0388\n",
      "Epoch [28/50], Step [294/735], Loss: 0.1862\n",
      "Epoch [28/50], Step [295/735], Loss: 0.3061\n",
      "Epoch [28/50], Step [296/735], Loss: 0.5806\n",
      "Epoch [28/50], Step [297/735], Loss: 0.5089\n",
      "Epoch [28/50], Step [298/735], Loss: 0.7011\n",
      "Epoch [28/50], Step [299/735], Loss: 0.2040\n",
      "Epoch [28/50], Step [300/735], Loss: 0.2440\n",
      "Epoch [28/50], Step [301/735], Loss: 0.5314\n",
      "Epoch [28/50], Step [302/735], Loss: 0.1309\n",
      "Epoch [28/50], Step [303/735], Loss: 0.2522\n",
      "Epoch [28/50], Step [304/735], Loss: 0.1331\n",
      "Epoch [28/50], Step [305/735], Loss: 0.0840\n",
      "Epoch [28/50], Step [306/735], Loss: 0.0916\n",
      "Epoch [28/50], Step [307/735], Loss: 0.3925\n",
      "Epoch [28/50], Step [308/735], Loss: 0.2049\n",
      "Epoch [28/50], Step [309/735], Loss: 0.3567\n",
      "Epoch [28/50], Step [310/735], Loss: 0.4607\n",
      "Epoch [28/50], Step [311/735], Loss: 0.2626\n",
      "Epoch [28/50], Step [312/735], Loss: 1.2314\n",
      "Epoch [28/50], Step [313/735], Loss: 0.3698\n",
      "Epoch [28/50], Step [314/735], Loss: 0.4876\n",
      "Epoch [28/50], Step [315/735], Loss: 0.4020\n",
      "Epoch [28/50], Step [316/735], Loss: 0.1661\n",
      "Epoch [28/50], Step [317/735], Loss: 0.1912\n",
      "Epoch [28/50], Step [318/735], Loss: 0.2091\n",
      "Epoch [28/50], Step [319/735], Loss: 0.4739\n",
      "Epoch [28/50], Step [320/735], Loss: 0.3373\n",
      "Epoch [28/50], Step [321/735], Loss: 0.3319\n",
      "Epoch [28/50], Step [322/735], Loss: 0.1557\n",
      "Epoch [28/50], Step [323/735], Loss: 0.2458\n",
      "Epoch [28/50], Step [324/735], Loss: 0.1458\n",
      "Epoch [28/50], Step [325/735], Loss: 0.3532\n",
      "Epoch [28/50], Step [326/735], Loss: 0.0451\n",
      "Epoch [28/50], Step [327/735], Loss: 0.3054\n",
      "Epoch [28/50], Step [328/735], Loss: 0.2020\n",
      "Epoch [28/50], Step [329/735], Loss: 0.2775\n",
      "Epoch [28/50], Step [330/735], Loss: 0.4590\n",
      "Epoch [28/50], Step [331/735], Loss: 0.3915\n",
      "Epoch [28/50], Step [332/735], Loss: 0.1639\n",
      "Epoch [28/50], Step [333/735], Loss: 0.1969\n",
      "Epoch [28/50], Step [334/735], Loss: 0.0983\n",
      "Epoch [28/50], Step [335/735], Loss: 0.3077\n",
      "Epoch [28/50], Step [336/735], Loss: 0.1412\n",
      "Epoch [28/50], Step [337/735], Loss: 0.2299\n",
      "Epoch [28/50], Step [338/735], Loss: 1.0087\n",
      "Epoch [28/50], Step [339/735], Loss: 0.1151\n",
      "Epoch [28/50], Step [340/735], Loss: 0.3945\n",
      "Epoch [28/50], Step [341/735], Loss: 0.0796\n",
      "Epoch [28/50], Step [342/735], Loss: 0.5658\n",
      "Epoch [28/50], Step [343/735], Loss: 0.5036\n",
      "Epoch [28/50], Step [344/735], Loss: 1.0063\n",
      "Epoch [28/50], Step [345/735], Loss: 0.6457\n",
      "Epoch [28/50], Step [346/735], Loss: 1.0035\n",
      "Epoch [28/50], Step [347/735], Loss: 0.2147\n",
      "Epoch [28/50], Step [348/735], Loss: 0.3921\n",
      "Epoch [28/50], Step [349/735], Loss: 0.2512\n",
      "Epoch [28/50], Step [350/735], Loss: 0.1856\n",
      "Epoch [28/50], Step [351/735], Loss: 0.5606\n",
      "Epoch [28/50], Step [352/735], Loss: 0.3279\n",
      "Epoch [28/50], Step [353/735], Loss: 0.1767\n",
      "Epoch [28/50], Step [354/735], Loss: 0.1757\n",
      "Epoch [28/50], Step [355/735], Loss: 0.4109\n",
      "Epoch [28/50], Step [356/735], Loss: 0.3327\n",
      "Epoch [28/50], Step [357/735], Loss: 0.1201\n",
      "Epoch [28/50], Step [358/735], Loss: 5.2375\n",
      "Epoch [28/50], Step [359/735], Loss: 0.2389\n",
      "Epoch [28/50], Step [360/735], Loss: 0.2505\n",
      "Epoch [28/50], Step [361/735], Loss: 0.3954\n",
      "Epoch [28/50], Step [362/735], Loss: 0.5424\n",
      "Epoch [28/50], Step [363/735], Loss: 0.3727\n",
      "Epoch [28/50], Step [364/735], Loss: 0.1941\n",
      "Epoch [28/50], Step [365/735], Loss: 0.5189\n",
      "Epoch [28/50], Step [366/735], Loss: 0.7487\n",
      "Epoch [28/50], Step [367/735], Loss: 0.3858\n",
      "Epoch [28/50], Step [368/735], Loss: 0.1873\n",
      "Epoch [28/50], Step [369/735], Loss: 0.2480\n",
      "Epoch [28/50], Step [370/735], Loss: 0.3270\n",
      "Epoch [28/50], Step [371/735], Loss: 0.7326\n",
      "Epoch [28/50], Step [372/735], Loss: 0.3439\n",
      "Epoch [28/50], Step [373/735], Loss: 0.4944\n",
      "Epoch [28/50], Step [374/735], Loss: 0.3125\n",
      "Epoch [28/50], Step [375/735], Loss: 0.2264\n",
      "Epoch [28/50], Step [376/735], Loss: 0.2397\n",
      "Epoch [28/50], Step [377/735], Loss: 0.4640\n",
      "Epoch [28/50], Step [378/735], Loss: 0.1430\n",
      "Epoch [28/50], Step [379/735], Loss: 0.1103\n",
      "Epoch [28/50], Step [380/735], Loss: 1.2515\n",
      "Epoch [28/50], Step [381/735], Loss: 0.5757\n",
      "Epoch [28/50], Step [382/735], Loss: 0.1786\n",
      "Epoch [28/50], Step [383/735], Loss: 0.2372\n",
      "Epoch [28/50], Step [384/735], Loss: 0.1430\n",
      "Epoch [28/50], Step [385/735], Loss: 0.2227\n",
      "Epoch [28/50], Step [386/735], Loss: 0.1642\n",
      "Epoch [28/50], Step [387/735], Loss: 0.5486\n",
      "Epoch [28/50], Step [388/735], Loss: 1.0862\n",
      "Epoch [28/50], Step [389/735], Loss: 0.2168\n",
      "Epoch [28/50], Step [390/735], Loss: 0.4516\n",
      "Epoch [28/50], Step [391/735], Loss: 0.2391\n",
      "Epoch [28/50], Step [392/735], Loss: 0.4263\n",
      "Epoch [28/50], Step [393/735], Loss: 0.0947\n",
      "Epoch [28/50], Step [394/735], Loss: 0.3461\n",
      "Epoch [28/50], Step [395/735], Loss: 1.1558\n",
      "Epoch [28/50], Step [396/735], Loss: 0.7913\n",
      "Epoch [28/50], Step [397/735], Loss: 0.3852\n",
      "Epoch [28/50], Step [398/735], Loss: 0.3304\n",
      "Epoch [28/50], Step [399/735], Loss: 1.4207\n",
      "Epoch [28/50], Step [400/735], Loss: 0.1175\n",
      "Epoch [28/50], Step [401/735], Loss: 0.2787\n",
      "Epoch [28/50], Step [402/735], Loss: 0.0795\n",
      "Epoch [28/50], Step [403/735], Loss: 0.3208\n",
      "Epoch [28/50], Step [404/735], Loss: 0.4537\n",
      "Epoch [28/50], Step [405/735], Loss: 0.3642\n",
      "Epoch [28/50], Step [406/735], Loss: 1.2671\n",
      "Epoch [28/50], Step [407/735], Loss: 0.1921\n",
      "Epoch [28/50], Step [408/735], Loss: 0.9796\n",
      "Epoch [28/50], Step [409/735], Loss: 1.3021\n",
      "Epoch [28/50], Step [410/735], Loss: 1.0233\n",
      "Epoch [28/50], Step [411/735], Loss: 0.5298\n",
      "Epoch [28/50], Step [412/735], Loss: 0.5049\n",
      "Epoch [28/50], Step [413/735], Loss: 0.9340\n",
      "Epoch [28/50], Step [414/735], Loss: 0.8336\n",
      "Epoch [28/50], Step [415/735], Loss: 0.4179\n",
      "Epoch [28/50], Step [416/735], Loss: 0.2255\n",
      "Epoch [28/50], Step [417/735], Loss: 0.4950\n",
      "Epoch [28/50], Step [418/735], Loss: 0.4000\n",
      "Epoch [28/50], Step [419/735], Loss: 0.5513\n",
      "Epoch [28/50], Step [420/735], Loss: 0.3104\n",
      "Epoch [28/50], Step [421/735], Loss: 0.4415\n",
      "Epoch [28/50], Step [422/735], Loss: 0.3270\n",
      "Epoch [28/50], Step [423/735], Loss: 0.5750\n",
      "Epoch [28/50], Step [424/735], Loss: 0.3232\n",
      "Epoch [28/50], Step [425/735], Loss: 0.1235\n",
      "Epoch [28/50], Step [426/735], Loss: 0.2504\n",
      "Epoch [28/50], Step [427/735], Loss: 0.6606\n",
      "Epoch [28/50], Step [428/735], Loss: 0.8821\n",
      "Epoch [28/50], Step [429/735], Loss: 0.4716\n",
      "Epoch [28/50], Step [430/735], Loss: 0.2193\n",
      "Epoch [28/50], Step [431/735], Loss: 0.3829\n",
      "Epoch [28/50], Step [432/735], Loss: 0.3819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Step [433/735], Loss: 0.1615\n",
      "Epoch [28/50], Step [434/735], Loss: 0.4012\n",
      "Epoch [28/50], Step [435/735], Loss: 0.0832\n",
      "Epoch [28/50], Step [436/735], Loss: 0.3946\n",
      "Epoch [28/50], Step [437/735], Loss: 0.2394\n",
      "Epoch [28/50], Step [438/735], Loss: 0.5496\n",
      "Epoch [28/50], Step [439/735], Loss: 0.3743\n",
      "Epoch [28/50], Step [440/735], Loss: 0.3651\n",
      "Epoch [28/50], Step [441/735], Loss: 0.7750\n",
      "Epoch [28/50], Step [442/735], Loss: 0.4952\n",
      "Epoch [28/50], Step [443/735], Loss: 1.2170\n",
      "Epoch [28/50], Step [444/735], Loss: 0.2604\n",
      "Epoch [28/50], Step [445/735], Loss: 0.2940\n",
      "Epoch [28/50], Step [446/735], Loss: 0.1470\n",
      "Epoch [28/50], Step [447/735], Loss: 0.2128\n",
      "Epoch [28/50], Step [448/735], Loss: 0.2091\n",
      "Epoch [28/50], Step [449/735], Loss: 0.1884\n",
      "Epoch [28/50], Step [450/735], Loss: 0.1328\n",
      "Epoch [28/50], Step [451/735], Loss: 0.1974\n",
      "Epoch [28/50], Step [452/735], Loss: 0.2780\n",
      "Epoch [28/50], Step [453/735], Loss: 0.4214\n",
      "Epoch [28/50], Step [454/735], Loss: 0.4903\n",
      "Epoch [28/50], Step [455/735], Loss: 0.2848\n",
      "Epoch [28/50], Step [456/735], Loss: 0.4557\n",
      "Epoch [28/50], Step [457/735], Loss: 0.6903\n",
      "Epoch [28/50], Step [458/735], Loss: 1.6717\n",
      "Epoch [28/50], Step [459/735], Loss: 0.4520\n",
      "Epoch [28/50], Step [460/735], Loss: 0.5229\n",
      "Epoch [28/50], Step [461/735], Loss: 0.3348\n",
      "Epoch [28/50], Step [462/735], Loss: 0.0773\n",
      "Epoch [28/50], Step [463/735], Loss: 0.4081\n",
      "Epoch [28/50], Step [464/735], Loss: 0.3424\n",
      "Epoch [28/50], Step [465/735], Loss: 0.1635\n",
      "Epoch [28/50], Step [466/735], Loss: 0.3048\n",
      "Epoch [28/50], Step [467/735], Loss: 0.7608\n",
      "Epoch [28/50], Step [468/735], Loss: 0.4163\n",
      "Epoch [28/50], Step [469/735], Loss: 0.4462\n",
      "Epoch [28/50], Step [470/735], Loss: 0.2632\n",
      "Epoch [28/50], Step [471/735], Loss: 0.4579\n",
      "Epoch [28/50], Step [472/735], Loss: 0.2523\n",
      "Epoch [28/50], Step [473/735], Loss: 0.1809\n",
      "Epoch [28/50], Step [474/735], Loss: 0.2563\n",
      "Epoch [28/50], Step [475/735], Loss: 0.1113\n",
      "Epoch [28/50], Step [476/735], Loss: 0.2709\n",
      "Epoch [28/50], Step [477/735], Loss: 0.2282\n",
      "Epoch [28/50], Step [478/735], Loss: 0.8889\n",
      "Epoch [28/50], Step [479/735], Loss: 0.5718\n",
      "Epoch [28/50], Step [480/735], Loss: 0.1725\n",
      "Epoch [28/50], Step [481/735], Loss: 0.2986\n",
      "Epoch [28/50], Step [482/735], Loss: 0.1124\n",
      "Epoch [28/50], Step [483/735], Loss: 0.6009\n",
      "Epoch [28/50], Step [484/735], Loss: 0.1991\n",
      "Epoch [28/50], Step [485/735], Loss: 0.3699\n",
      "Epoch [28/50], Step [486/735], Loss: 0.3758\n",
      "Epoch [28/50], Step [487/735], Loss: 0.5174\n",
      "Epoch [28/50], Step [488/735], Loss: 0.2832\n",
      "Epoch [28/50], Step [489/735], Loss: 0.1531\n",
      "Epoch [28/50], Step [490/735], Loss: 0.1224\n",
      "Epoch [28/50], Step [491/735], Loss: 0.0719\n",
      "Epoch [28/50], Step [492/735], Loss: 0.2997\n",
      "Epoch [28/50], Step [493/735], Loss: 0.2023\n",
      "Epoch [28/50], Step [494/735], Loss: 0.0807\n",
      "Epoch [28/50], Step [495/735], Loss: 0.0909\n",
      "Epoch [28/50], Step [496/735], Loss: 0.0582\n",
      "Epoch [28/50], Step [497/735], Loss: 0.6111\n",
      "Epoch [28/50], Step [498/735], Loss: 0.4888\n",
      "Epoch [28/50], Step [499/735], Loss: 0.4785\n",
      "Epoch [28/50], Step [500/735], Loss: 0.3702\n",
      "Epoch [28/50], Step [501/735], Loss: 0.2822\n",
      "Epoch [28/50], Step [502/735], Loss: 0.4116\n",
      "Epoch [28/50], Step [503/735], Loss: 0.3080\n",
      "Epoch [28/50], Step [504/735], Loss: 0.3862\n",
      "Epoch [28/50], Step [505/735], Loss: 0.7137\n",
      "Epoch [28/50], Step [506/735], Loss: 0.2022\n",
      "Epoch [28/50], Step [507/735], Loss: 0.1913\n",
      "Epoch [28/50], Step [508/735], Loss: 0.1447\n",
      "Epoch [28/50], Step [509/735], Loss: 0.3973\n",
      "Epoch [28/50], Step [510/735], Loss: 0.1687\n",
      "Epoch [28/50], Step [511/735], Loss: 0.2700\n",
      "Epoch [28/50], Step [512/735], Loss: 0.6919\n",
      "Epoch [28/50], Step [513/735], Loss: 0.6388\n",
      "Epoch [28/50], Step [514/735], Loss: 0.2414\n",
      "Epoch [28/50], Step [515/735], Loss: 0.1753\n",
      "Epoch [28/50], Step [516/735], Loss: 0.4526\n",
      "Epoch [28/50], Step [517/735], Loss: 1.1375\n",
      "Epoch [28/50], Step [518/735], Loss: 0.2887\n",
      "Epoch [28/50], Step [519/735], Loss: 0.4971\n",
      "Epoch [28/50], Step [520/735], Loss: 0.3579\n",
      "Epoch [28/50], Step [521/735], Loss: 0.2240\n",
      "Epoch [28/50], Step [522/735], Loss: 0.1519\n",
      "Epoch [28/50], Step [523/735], Loss: 0.3546\n",
      "Epoch [28/50], Step [524/735], Loss: 0.2387\n",
      "Epoch [28/50], Step [525/735], Loss: 0.3005\n",
      "Epoch [28/50], Step [526/735], Loss: 0.3192\n",
      "Epoch [28/50], Step [527/735], Loss: 0.5499\n",
      "Epoch [28/50], Step [528/735], Loss: 0.1794\n",
      "Epoch [28/50], Step [529/735], Loss: 0.1027\n",
      "Epoch [28/50], Step [530/735], Loss: 0.4810\n",
      "Epoch [28/50], Step [531/735], Loss: 0.3676\n",
      "Epoch [28/50], Step [532/735], Loss: 0.1101\n",
      "Epoch [28/50], Step [533/735], Loss: 0.2267\n",
      "Epoch [28/50], Step [534/735], Loss: 0.4637\n",
      "Epoch [28/50], Step [535/735], Loss: 1.0340\n",
      "Epoch [28/50], Step [536/735], Loss: 0.3075\n",
      "Epoch [28/50], Step [537/735], Loss: 0.3943\n",
      "Epoch [28/50], Step [538/735], Loss: 0.0892\n",
      "Epoch [28/50], Step [539/735], Loss: 0.8204\n",
      "Epoch [28/50], Step [540/735], Loss: 0.8819\n",
      "Epoch [28/50], Step [541/735], Loss: 0.2720\n",
      "Epoch [28/50], Step [542/735], Loss: 0.1017\n",
      "Epoch [28/50], Step [543/735], Loss: 0.1614\n",
      "Epoch [28/50], Step [544/735], Loss: 0.4916\n",
      "Epoch [28/50], Step [545/735], Loss: 0.4641\n",
      "Epoch [28/50], Step [546/735], Loss: 0.4361\n",
      "Epoch [28/50], Step [547/735], Loss: 0.1132\n",
      "Epoch [28/50], Step [548/735], Loss: 0.0899\n",
      "Epoch [28/50], Step [549/735], Loss: 0.3134\n",
      "Epoch [28/50], Step [550/735], Loss: 0.5453\n",
      "Epoch [28/50], Step [551/735], Loss: 0.5238\n",
      "Epoch [28/50], Step [552/735], Loss: 0.1780\n",
      "Epoch [28/50], Step [553/735], Loss: 0.2899\n",
      "Epoch [28/50], Step [554/735], Loss: 1.2955\n",
      "Epoch [28/50], Step [555/735], Loss: 0.5871\n",
      "Epoch [28/50], Step [556/735], Loss: 0.4872\n",
      "Epoch [28/50], Step [557/735], Loss: 0.6636\n",
      "Epoch [28/50], Step [558/735], Loss: 0.2538\n",
      "Epoch [28/50], Step [559/735], Loss: 0.1305\n",
      "Epoch [28/50], Step [560/735], Loss: 0.4184\n",
      "Epoch [28/50], Step [561/735], Loss: 0.2920\n",
      "Epoch [28/50], Step [562/735], Loss: 0.2266\n",
      "Epoch [28/50], Step [563/735], Loss: 0.8948\n",
      "Epoch [28/50], Step [564/735], Loss: 0.4430\n",
      "Epoch [28/50], Step [565/735], Loss: 0.2319\n",
      "Epoch [28/50], Step [566/735], Loss: 0.7415\n",
      "Epoch [28/50], Step [567/735], Loss: 0.4902\n",
      "Epoch [28/50], Step [568/735], Loss: 0.5831\n",
      "Epoch [28/50], Step [569/735], Loss: 0.2371\n",
      "Epoch [28/50], Step [570/735], Loss: 0.0811\n",
      "Epoch [28/50], Step [571/735], Loss: 0.5518\n",
      "Epoch [28/50], Step [572/735], Loss: 0.1359\n",
      "Epoch [28/50], Step [573/735], Loss: 0.0829\n",
      "Epoch [28/50], Step [574/735], Loss: 0.1232\n",
      "Epoch [28/50], Step [575/735], Loss: 0.6616\n",
      "Epoch [28/50], Step [576/735], Loss: 0.2122\n",
      "Epoch [28/50], Step [577/735], Loss: 0.3770\n",
      "Epoch [28/50], Step [578/735], Loss: 0.2133\n",
      "Epoch [28/50], Step [579/735], Loss: 0.3507\n",
      "Epoch [28/50], Step [580/735], Loss: 0.1066\n",
      "Epoch [28/50], Step [581/735], Loss: 0.8376\n",
      "Epoch [28/50], Step [582/735], Loss: 0.3989\n",
      "Epoch [28/50], Step [583/735], Loss: 0.1306\n",
      "Epoch [28/50], Step [584/735], Loss: 0.2201\n",
      "Epoch [28/50], Step [585/735], Loss: 0.7730\n",
      "Epoch [28/50], Step [586/735], Loss: 0.1398\n",
      "Epoch [28/50], Step [587/735], Loss: 0.3424\n",
      "Epoch [28/50], Step [588/735], Loss: 0.1049\n",
      "Epoch [28/50], Step [589/735], Loss: 0.2499\n",
      "Epoch [28/50], Step [590/735], Loss: 0.3295\n",
      "Epoch [28/50], Step [591/735], Loss: 0.8570\n",
      "Epoch [28/50], Step [592/735], Loss: 0.0783\n",
      "Epoch [28/50], Step [593/735], Loss: 0.2411\n",
      "Epoch [28/50], Step [594/735], Loss: 0.1408\n",
      "Epoch [28/50], Step [595/735], Loss: 0.2963\n",
      "Epoch [28/50], Step [596/735], Loss: 0.2939\n",
      "Epoch [28/50], Step [597/735], Loss: 0.3043\n",
      "Epoch [28/50], Step [598/735], Loss: 0.2350\n",
      "Epoch [28/50], Step [599/735], Loss: 0.4971\n",
      "Epoch [28/50], Step [600/735], Loss: 0.4491\n",
      "Epoch [28/50], Step [601/735], Loss: 0.2026\n",
      "Epoch [28/50], Step [602/735], Loss: 0.3211\n",
      "Epoch [28/50], Step [603/735], Loss: 1.2476\n",
      "Epoch [28/50], Step [604/735], Loss: 0.1677\n",
      "Epoch [28/50], Step [605/735], Loss: 0.0687\n",
      "Epoch [28/50], Step [606/735], Loss: 0.0815\n",
      "Epoch [28/50], Step [607/735], Loss: 0.0953\n",
      "Epoch [28/50], Step [608/735], Loss: 0.1528\n",
      "Epoch [28/50], Step [609/735], Loss: 0.4746\n",
      "Epoch [28/50], Step [610/735], Loss: 0.1750\n",
      "Epoch [28/50], Step [611/735], Loss: 0.3229\n",
      "Epoch [28/50], Step [612/735], Loss: 0.3063\n",
      "Epoch [28/50], Step [613/735], Loss: 0.2421\n",
      "Epoch [28/50], Step [614/735], Loss: 0.2498\n",
      "Epoch [28/50], Step [615/735], Loss: 0.1083\n",
      "Epoch [28/50], Step [616/735], Loss: 0.6061\n",
      "Epoch [28/50], Step [617/735], Loss: 0.1160\n",
      "Epoch [28/50], Step [618/735], Loss: 1.0519\n",
      "Epoch [28/50], Step [619/735], Loss: 0.6201\n",
      "Epoch [28/50], Step [620/735], Loss: 0.0301\n",
      "Epoch [28/50], Step [621/735], Loss: 3.9377\n",
      "Epoch [28/50], Step [622/735], Loss: 1.1803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Step [623/735], Loss: 0.7835\n",
      "Epoch [28/50], Step [624/735], Loss: 0.2447\n",
      "Epoch [28/50], Step [625/735], Loss: 0.3436\n",
      "Epoch [28/50], Step [626/735], Loss: 0.4743\n",
      "Epoch [28/50], Step [627/735], Loss: 0.1409\n",
      "Epoch [28/50], Step [628/735], Loss: 0.1472\n",
      "Epoch [28/50], Step [629/735], Loss: 0.6144\n",
      "Epoch [28/50], Step [630/735], Loss: 0.1374\n",
      "Epoch [28/50], Step [631/735], Loss: 0.7310\n",
      "Epoch [28/50], Step [632/735], Loss: 0.1921\n",
      "Epoch [28/50], Step [633/735], Loss: 0.5090\n",
      "Epoch [28/50], Step [634/735], Loss: 0.1306\n",
      "Epoch [28/50], Step [635/735], Loss: 0.1520\n",
      "Epoch [28/50], Step [636/735], Loss: 0.1205\n",
      "Epoch [28/50], Step [637/735], Loss: 0.1539\n",
      "Epoch [28/50], Step [638/735], Loss: 0.1416\n",
      "Epoch [28/50], Step [639/735], Loss: 0.2572\n",
      "Epoch [28/50], Step [640/735], Loss: 0.2669\n",
      "Epoch [28/50], Step [641/735], Loss: 0.5365\n",
      "Epoch [28/50], Step [642/735], Loss: 0.1063\n",
      "Epoch [28/50], Step [643/735], Loss: 0.2763\n",
      "Epoch [28/50], Step [644/735], Loss: 0.2137\n",
      "Epoch [28/50], Step [645/735], Loss: 0.4693\n",
      "Epoch [28/50], Step [646/735], Loss: 0.3443\n",
      "Epoch [28/50], Step [647/735], Loss: 0.1124\n",
      "Epoch [28/50], Step [648/735], Loss: 0.4028\n",
      "Epoch [28/50], Step [649/735], Loss: 0.7046\n",
      "Epoch [28/50], Step [650/735], Loss: 0.5753\n",
      "Epoch [28/50], Step [651/735], Loss: 0.1637\n",
      "Epoch [28/50], Step [652/735], Loss: 0.1932\n",
      "Epoch [28/50], Step [653/735], Loss: 0.1997\n",
      "Epoch [28/50], Step [654/735], Loss: 0.0642\n",
      "Epoch [28/50], Step [655/735], Loss: 0.2774\n",
      "Epoch [28/50], Step [656/735], Loss: 0.5868\n",
      "Epoch [28/50], Step [657/735], Loss: 0.2405\n",
      "Epoch [28/50], Step [658/735], Loss: 0.1379\n",
      "Epoch [28/50], Step [659/735], Loss: 0.4746\n",
      "Epoch [28/50], Step [660/735], Loss: 0.2218\n",
      "Epoch [28/50], Step [661/735], Loss: 0.9363\n",
      "Epoch [28/50], Step [662/735], Loss: 0.2649\n",
      "Epoch [28/50], Step [663/735], Loss: 0.3568\n",
      "Epoch [28/50], Step [664/735], Loss: 0.5355\n",
      "Epoch [28/50], Step [665/735], Loss: 0.3560\n",
      "Epoch [28/50], Step [666/735], Loss: 0.4410\n",
      "Epoch [28/50], Step [667/735], Loss: 0.7068\n",
      "Epoch [28/50], Step [668/735], Loss: 0.4324\n",
      "Epoch [28/50], Step [669/735], Loss: 0.7237\n",
      "Epoch [28/50], Step [670/735], Loss: 0.2707\n",
      "Epoch [28/50], Step [671/735], Loss: 0.4881\n",
      "Epoch [28/50], Step [672/735], Loss: 0.2564\n",
      "Epoch [28/50], Step [673/735], Loss: 0.3064\n",
      "Epoch [28/50], Step [674/735], Loss: 0.6426\n",
      "Epoch [28/50], Step [675/735], Loss: 0.4042\n",
      "Epoch [28/50], Step [676/735], Loss: 4.4027\n",
      "Epoch [28/50], Step [677/735], Loss: 0.5673\n",
      "Epoch [28/50], Step [678/735], Loss: 0.0482\n",
      "Epoch [28/50], Step [679/735], Loss: 0.3113\n",
      "Epoch [28/50], Step [680/735], Loss: 0.1050\n",
      "Epoch [28/50], Step [681/735], Loss: 0.1844\n",
      "Epoch [28/50], Step [682/735], Loss: 0.1880\n",
      "Epoch [28/50], Step [683/735], Loss: 0.2518\n",
      "Epoch [28/50], Step [684/735], Loss: 0.1372\n",
      "Epoch [28/50], Step [685/735], Loss: 0.2102\n",
      "Epoch [28/50], Step [686/735], Loss: 0.2379\n",
      "Epoch [28/50], Step [687/735], Loss: 0.2298\n",
      "Epoch [28/50], Step [688/735], Loss: 0.2226\n",
      "Epoch [28/50], Step [689/735], Loss: 0.2181\n",
      "Epoch [28/50], Step [690/735], Loss: 0.4046\n",
      "Epoch [28/50], Step [691/735], Loss: 0.1452\n",
      "Epoch [28/50], Step [692/735], Loss: 0.5740\n",
      "Epoch [28/50], Step [693/735], Loss: 0.2479\n",
      "Epoch [28/50], Step [694/735], Loss: 0.3757\n",
      "Epoch [28/50], Step [695/735], Loss: 0.0964\n",
      "Epoch [28/50], Step [696/735], Loss: 0.1664\n",
      "Epoch [28/50], Step [697/735], Loss: 0.2383\n",
      "Epoch [28/50], Step [698/735], Loss: 0.3437\n",
      "Epoch [28/50], Step [699/735], Loss: 0.1203\n",
      "Epoch [28/50], Step [700/735], Loss: 0.0751\n",
      "Epoch [28/50], Step [701/735], Loss: 0.3415\n",
      "Epoch [28/50], Step [702/735], Loss: 0.0794\n",
      "Epoch [28/50], Step [703/735], Loss: 0.3122\n",
      "Epoch [28/50], Step [704/735], Loss: 0.0911\n",
      "Epoch [28/50], Step [705/735], Loss: 0.2267\n",
      "Epoch [28/50], Step [706/735], Loss: 4.7683\n",
      "Epoch [28/50], Step [707/735], Loss: 0.8613\n",
      "Epoch [28/50], Step [708/735], Loss: 1.7613\n",
      "Epoch [28/50], Step [709/735], Loss: 0.4282\n",
      "Epoch [28/50], Step [710/735], Loss: 0.2046\n",
      "Epoch [28/50], Step [711/735], Loss: 0.0850\n",
      "Epoch [28/50], Step [712/735], Loss: 0.2579\n",
      "Epoch [28/50], Step [713/735], Loss: 0.1332\n",
      "Epoch [28/50], Step [714/735], Loss: 0.1727\n",
      "Epoch [28/50], Step [715/735], Loss: 0.3300\n",
      "Epoch [28/50], Step [716/735], Loss: 0.6784\n",
      "Epoch [28/50], Step [717/735], Loss: 0.5164\n",
      "Epoch [28/50], Step [718/735], Loss: 0.3253\n",
      "Epoch [28/50], Step [719/735], Loss: 0.1778\n",
      "Epoch [28/50], Step [720/735], Loss: 0.3198\n",
      "Epoch [28/50], Step [721/735], Loss: 0.4470\n",
      "Epoch [28/50], Step [722/735], Loss: 0.0964\n",
      "Epoch [28/50], Step [723/735], Loss: 3.6369\n",
      "Epoch [28/50], Step [724/735], Loss: 0.1484\n",
      "Epoch [28/50], Step [725/735], Loss: 0.5504\n",
      "Epoch [28/50], Step [726/735], Loss: 0.3852\n",
      "Epoch [28/50], Step [727/735], Loss: 1.3753\n",
      "Epoch [28/50], Step [728/735], Loss: 0.2447\n",
      "Epoch [28/50], Step [729/735], Loss: 0.2309\n",
      "Epoch [28/50], Step [730/735], Loss: 0.2968\n",
      "Epoch [28/50], Step [731/735], Loss: 0.1867\n",
      "Epoch [28/50], Step [732/735], Loss: 0.4589\n",
      "Epoch [28/50], Step [733/735], Loss: 0.2444\n",
      "Epoch [28/50], Step [734/735], Loss: 0.2774\n",
      "Epoch [28/50], Step [735/735], Loss: 0.2874\n",
      "Epoch [29/50], Step [1/735], Loss: 0.4702\n",
      "Epoch [29/50], Step [2/735], Loss: 1.1221\n",
      "Epoch [29/50], Step [3/735], Loss: 0.1734\n",
      "Epoch [29/50], Step [4/735], Loss: 0.3456\n",
      "Epoch [29/50], Step [5/735], Loss: 0.5871\n",
      "Epoch [29/50], Step [6/735], Loss: 0.3876\n",
      "Epoch [29/50], Step [7/735], Loss: 0.4133\n",
      "Epoch [29/50], Step [8/735], Loss: 0.4763\n",
      "Epoch [29/50], Step [9/735], Loss: 0.2580\n",
      "Epoch [29/50], Step [10/735], Loss: 0.5073\n",
      "Epoch [29/50], Step [11/735], Loss: 0.3551\n",
      "Epoch [29/50], Step [12/735], Loss: 0.3808\n",
      "Epoch [29/50], Step [13/735], Loss: 0.3579\n",
      "Epoch [29/50], Step [14/735], Loss: 0.5136\n",
      "Epoch [29/50], Step [15/735], Loss: 0.9949\n",
      "Epoch [29/50], Step [16/735], Loss: 0.4628\n",
      "Epoch [29/50], Step [17/735], Loss: 0.3088\n",
      "Epoch [29/50], Step [18/735], Loss: 0.6933\n",
      "Epoch [29/50], Step [19/735], Loss: 0.5245\n",
      "Epoch [29/50], Step [20/735], Loss: 0.2050\n",
      "Epoch [29/50], Step [21/735], Loss: 0.3143\n",
      "Epoch [29/50], Step [22/735], Loss: 0.4910\n",
      "Epoch [29/50], Step [23/735], Loss: 0.2157\n",
      "Epoch [29/50], Step [24/735], Loss: 4.0513\n",
      "Epoch [29/50], Step [25/735], Loss: 0.2055\n",
      "Epoch [29/50], Step [26/735], Loss: 0.2769\n",
      "Epoch [29/50], Step [27/735], Loss: 0.8840\n",
      "Epoch [29/50], Step [28/735], Loss: 0.8879\n",
      "Epoch [29/50], Step [29/735], Loss: 0.2845\n",
      "Epoch [29/50], Step [30/735], Loss: 0.0903\n",
      "Epoch [29/50], Step [31/735], Loss: 0.1789\n",
      "Epoch [29/50], Step [32/735], Loss: 0.3130\n",
      "Epoch [29/50], Step [33/735], Loss: 0.3790\n",
      "Epoch [29/50], Step [34/735], Loss: 0.1046\n",
      "Epoch [29/50], Step [35/735], Loss: 0.1201\n",
      "Epoch [29/50], Step [36/735], Loss: 0.1205\n",
      "Epoch [29/50], Step [37/735], Loss: 0.6524\n",
      "Epoch [29/50], Step [38/735], Loss: 0.1062\n",
      "Epoch [29/50], Step [39/735], Loss: 0.2765\n",
      "Epoch [29/50], Step [40/735], Loss: 0.9906\n",
      "Epoch [29/50], Step [41/735], Loss: 0.1482\n",
      "Epoch [29/50], Step [42/735], Loss: 0.3965\n",
      "Epoch [29/50], Step [43/735], Loss: 0.4104\n",
      "Epoch [29/50], Step [44/735], Loss: 0.1746\n",
      "Epoch [29/50], Step [45/735], Loss: 0.2241\n",
      "Epoch [29/50], Step [46/735], Loss: 0.1091\n",
      "Epoch [29/50], Step [47/735], Loss: 0.0757\n",
      "Epoch [29/50], Step [48/735], Loss: 0.2497\n",
      "Epoch [29/50], Step [49/735], Loss: 0.2506\n",
      "Epoch [29/50], Step [50/735], Loss: 0.2688\n",
      "Epoch [29/50], Step [51/735], Loss: 0.1224\n",
      "Epoch [29/50], Step [52/735], Loss: 0.6429\n",
      "Epoch [29/50], Step [53/735], Loss: 0.2744\n",
      "Epoch [29/50], Step [54/735], Loss: 0.2825\n",
      "Epoch [29/50], Step [55/735], Loss: 0.2663\n",
      "Epoch [29/50], Step [56/735], Loss: 0.0977\n",
      "Epoch [29/50], Step [57/735], Loss: 0.1628\n",
      "Epoch [29/50], Step [58/735], Loss: 0.2194\n",
      "Epoch [29/50], Step [59/735], Loss: 0.0592\n",
      "Epoch [29/50], Step [60/735], Loss: 0.1418\n",
      "Epoch [29/50], Step [61/735], Loss: 0.2112\n",
      "Epoch [29/50], Step [62/735], Loss: 0.3299\n",
      "Epoch [29/50], Step [63/735], Loss: 0.3280\n",
      "Epoch [29/50], Step [64/735], Loss: 1.1197\n",
      "Epoch [29/50], Step [65/735], Loss: 0.3202\n",
      "Epoch [29/50], Step [66/735], Loss: 0.2991\n",
      "Epoch [29/50], Step [67/735], Loss: 0.5070\n",
      "Epoch [29/50], Step [68/735], Loss: 0.2500\n",
      "Epoch [29/50], Step [69/735], Loss: 0.1525\n",
      "Epoch [29/50], Step [70/735], Loss: 0.2322\n",
      "Epoch [29/50], Step [71/735], Loss: 1.1285\n",
      "Epoch [29/50], Step [72/735], Loss: 0.3227\n",
      "Epoch [29/50], Step [73/735], Loss: 0.2530\n",
      "Epoch [29/50], Step [74/735], Loss: 0.2491\n",
      "Epoch [29/50], Step [75/735], Loss: 0.1451\n",
      "Epoch [29/50], Step [76/735], Loss: 0.5916\n",
      "Epoch [29/50], Step [77/735], Loss: 0.0827\n",
      "Epoch [29/50], Step [78/735], Loss: 0.4127\n",
      "Epoch [29/50], Step [79/735], Loss: 0.2895\n",
      "Epoch [29/50], Step [80/735], Loss: 0.2154\n",
      "Epoch [29/50], Step [81/735], Loss: 0.0621\n",
      "Epoch [29/50], Step [82/735], Loss: 0.2055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Step [83/735], Loss: 0.3139\n",
      "Epoch [29/50], Step [84/735], Loss: 0.2756\n",
      "Epoch [29/50], Step [85/735], Loss: 0.1428\n",
      "Epoch [29/50], Step [86/735], Loss: 0.5832\n",
      "Epoch [29/50], Step [87/735], Loss: 0.2102\n",
      "Epoch [29/50], Step [88/735], Loss: 0.2180\n",
      "Epoch [29/50], Step [89/735], Loss: 0.1168\n",
      "Epoch [29/50], Step [90/735], Loss: 0.4634\n",
      "Epoch [29/50], Step [91/735], Loss: 0.3358\n",
      "Epoch [29/50], Step [92/735], Loss: 0.2027\n",
      "Epoch [29/50], Step [93/735], Loss: 0.7579\n",
      "Epoch [29/50], Step [94/735], Loss: 0.1451\n",
      "Epoch [29/50], Step [95/735], Loss: 0.6755\n",
      "Epoch [29/50], Step [96/735], Loss: 0.2085\n",
      "Epoch [29/50], Step [97/735], Loss: 0.3029\n",
      "Epoch [29/50], Step [98/735], Loss: 0.1829\n",
      "Epoch [29/50], Step [99/735], Loss: 0.3585\n",
      "Epoch [29/50], Step [100/735], Loss: 0.1726\n",
      "Epoch [29/50], Step [101/735], Loss: 0.3930\n",
      "Epoch [29/50], Step [102/735], Loss: 0.2569\n",
      "Epoch [29/50], Step [103/735], Loss: 0.4983\n",
      "Epoch [29/50], Step [104/735], Loss: 0.1548\n",
      "Epoch [29/50], Step [105/735], Loss: 0.2059\n",
      "Epoch [29/50], Step [106/735], Loss: 0.2244\n",
      "Epoch [29/50], Step [107/735], Loss: 0.4382\n",
      "Epoch [29/50], Step [108/735], Loss: 0.3663\n",
      "Epoch [29/50], Step [109/735], Loss: 0.3699\n",
      "Epoch [29/50], Step [110/735], Loss: 0.9334\n",
      "Epoch [29/50], Step [111/735], Loss: 0.2266\n",
      "Epoch [29/50], Step [112/735], Loss: 0.3039\n",
      "Epoch [29/50], Step [113/735], Loss: 0.2382\n",
      "Epoch [29/50], Step [114/735], Loss: 0.1749\n",
      "Epoch [29/50], Step [115/735], Loss: 0.1912\n",
      "Epoch [29/50], Step [116/735], Loss: 0.1040\n",
      "Epoch [29/50], Step [117/735], Loss: 0.1648\n",
      "Epoch [29/50], Step [118/735], Loss: 0.2906\n",
      "Epoch [29/50], Step [119/735], Loss: 0.2629\n",
      "Epoch [29/50], Step [120/735], Loss: 0.3394\n",
      "Epoch [29/50], Step [121/735], Loss: 0.2835\n",
      "Epoch [29/50], Step [122/735], Loss: 0.3235\n",
      "Epoch [29/50], Step [123/735], Loss: 0.2251\n",
      "Epoch [29/50], Step [124/735], Loss: 0.9778\n",
      "Epoch [29/50], Step [125/735], Loss: 0.1611\n",
      "Epoch [29/50], Step [126/735], Loss: 0.3903\n",
      "Epoch [29/50], Step [127/735], Loss: 0.2403\n",
      "Epoch [29/50], Step [128/735], Loss: 0.3504\n",
      "Epoch [29/50], Step [129/735], Loss: 0.2358\n",
      "Epoch [29/50], Step [130/735], Loss: 0.1782\n",
      "Epoch [29/50], Step [131/735], Loss: 0.2489\n",
      "Epoch [29/50], Step [132/735], Loss: 0.2687\n",
      "Epoch [29/50], Step [133/735], Loss: 0.2990\n",
      "Epoch [29/50], Step [134/735], Loss: 0.7014\n",
      "Epoch [29/50], Step [135/735], Loss: 0.3266\n",
      "Epoch [29/50], Step [136/735], Loss: 0.3394\n",
      "Epoch [29/50], Step [137/735], Loss: 0.2236\n",
      "Epoch [29/50], Step [138/735], Loss: 0.3400\n",
      "Epoch [29/50], Step [139/735], Loss: 0.5068\n",
      "Epoch [29/50], Step [140/735], Loss: 0.2170\n",
      "Epoch [29/50], Step [141/735], Loss: 0.8170\n",
      "Epoch [29/50], Step [142/735], Loss: 0.1831\n",
      "Epoch [29/50], Step [143/735], Loss: 0.2500\n",
      "Epoch [29/50], Step [144/735], Loss: 0.9333\n",
      "Epoch [29/50], Step [145/735], Loss: 0.2089\n",
      "Epoch [29/50], Step [146/735], Loss: 0.2091\n",
      "Epoch [29/50], Step [147/735], Loss: 0.2209\n",
      "Epoch [29/50], Step [148/735], Loss: 0.1100\n",
      "Epoch [29/50], Step [149/735], Loss: 0.2990\n",
      "Epoch [29/50], Step [150/735], Loss: 0.5948\n",
      "Epoch [29/50], Step [151/735], Loss: 0.1012\n",
      "Epoch [29/50], Step [152/735], Loss: 0.5704\n",
      "Epoch [29/50], Step [153/735], Loss: 0.1725\n",
      "Epoch [29/50], Step [154/735], Loss: 0.4563\n",
      "Epoch [29/50], Step [155/735], Loss: 0.2308\n",
      "Epoch [29/50], Step [156/735], Loss: 0.2023\n",
      "Epoch [29/50], Step [157/735], Loss: 0.8218\n",
      "Epoch [29/50], Step [158/735], Loss: 0.2590\n",
      "Epoch [29/50], Step [159/735], Loss: 0.1287\n",
      "Epoch [29/50], Step [160/735], Loss: 0.2389\n",
      "Epoch [29/50], Step [161/735], Loss: 0.1557\n",
      "Epoch [29/50], Step [162/735], Loss: 0.4949\n",
      "Epoch [29/50], Step [163/735], Loss: 0.2141\n",
      "Epoch [29/50], Step [164/735], Loss: 0.1610\n",
      "Epoch [29/50], Step [165/735], Loss: 0.8495\n",
      "Epoch [29/50], Step [166/735], Loss: 0.5322\n",
      "Epoch [29/50], Step [167/735], Loss: 0.2162\n",
      "Epoch [29/50], Step [168/735], Loss: 0.2708\n",
      "Epoch [29/50], Step [169/735], Loss: 0.1829\n",
      "Epoch [29/50], Step [170/735], Loss: 0.4905\n",
      "Epoch [29/50], Step [171/735], Loss: 0.1239\n",
      "Epoch [29/50], Step [172/735], Loss: 0.3415\n",
      "Epoch [29/50], Step [173/735], Loss: 0.1929\n",
      "Epoch [29/50], Step [174/735], Loss: 0.3355\n",
      "Epoch [29/50], Step [175/735], Loss: 0.1519\n",
      "Epoch [29/50], Step [176/735], Loss: 0.3908\n",
      "Epoch [29/50], Step [177/735], Loss: 0.1820\n",
      "Epoch [29/50], Step [178/735], Loss: 0.4039\n",
      "Epoch [29/50], Step [179/735], Loss: 0.1861\n",
      "Epoch [29/50], Step [180/735], Loss: 0.1755\n",
      "Epoch [29/50], Step [181/735], Loss: 0.2353\n",
      "Epoch [29/50], Step [182/735], Loss: 0.2725\n",
      "Epoch [29/50], Step [183/735], Loss: 0.2363\n",
      "Epoch [29/50], Step [184/735], Loss: 0.2237\n",
      "Epoch [29/50], Step [185/735], Loss: 0.3660\n",
      "Epoch [29/50], Step [186/735], Loss: 0.2216\n",
      "Epoch [29/50], Step [187/735], Loss: 0.2809\n",
      "Epoch [29/50], Step [188/735], Loss: 0.0736\n",
      "Epoch [29/50], Step [189/735], Loss: 0.2312\n",
      "Epoch [29/50], Step [190/735], Loss: 0.6695\n",
      "Epoch [29/50], Step [191/735], Loss: 0.2032\n",
      "Epoch [29/50], Step [192/735], Loss: 0.2997\n",
      "Epoch [29/50], Step [193/735], Loss: 0.3328\n",
      "Epoch [29/50], Step [194/735], Loss: 0.4076\n",
      "Epoch [29/50], Step [195/735], Loss: 0.5457\n",
      "Epoch [29/50], Step [196/735], Loss: 0.5664\n",
      "Epoch [29/50], Step [197/735], Loss: 1.2636\n",
      "Epoch [29/50], Step [198/735], Loss: 0.2433\n",
      "Epoch [29/50], Step [199/735], Loss: 0.3104\n",
      "Epoch [29/50], Step [200/735], Loss: 0.9720\n",
      "Epoch [29/50], Step [201/735], Loss: 0.5090\n",
      "Epoch [29/50], Step [202/735], Loss: 0.1214\n",
      "Epoch [29/50], Step [203/735], Loss: 0.1861\n",
      "Epoch [29/50], Step [204/735], Loss: 0.3532\n",
      "Epoch [29/50], Step [205/735], Loss: 0.2101\n",
      "Epoch [29/50], Step [206/735], Loss: 0.5324\n",
      "Epoch [29/50], Step [207/735], Loss: 0.2884\n",
      "Epoch [29/50], Step [208/735], Loss: 0.4608\n",
      "Epoch [29/50], Step [209/735], Loss: 0.1621\n",
      "Epoch [29/50], Step [210/735], Loss: 0.2773\n",
      "Epoch [29/50], Step [211/735], Loss: 0.9216\n",
      "Epoch [29/50], Step [212/735], Loss: 0.1627\n",
      "Epoch [29/50], Step [213/735], Loss: 0.6017\n",
      "Epoch [29/50], Step [214/735], Loss: 0.6868\n",
      "Epoch [29/50], Step [215/735], Loss: 0.8635\n",
      "Epoch [29/50], Step [216/735], Loss: 0.1513\n",
      "Epoch [29/50], Step [217/735], Loss: 0.4617\n",
      "Epoch [29/50], Step [218/735], Loss: 0.2769\n",
      "Epoch [29/50], Step [219/735], Loss: 0.2250\n",
      "Epoch [29/50], Step [220/735], Loss: 0.3870\n",
      "Epoch [29/50], Step [221/735], Loss: 1.0947\n",
      "Epoch [29/50], Step [222/735], Loss: 0.9846\n",
      "Epoch [29/50], Step [223/735], Loss: 0.0955\n",
      "Epoch [29/50], Step [224/735], Loss: 0.1468\n",
      "Epoch [29/50], Step [225/735], Loss: 0.1198\n",
      "Epoch [29/50], Step [226/735], Loss: 0.1705\n",
      "Epoch [29/50], Step [227/735], Loss: 0.2369\n",
      "Epoch [29/50], Step [228/735], Loss: 0.4099\n",
      "Epoch [29/50], Step [229/735], Loss: 0.1214\n",
      "Epoch [29/50], Step [230/735], Loss: 0.2579\n",
      "Epoch [29/50], Step [231/735], Loss: 0.6769\n",
      "Epoch [29/50], Step [232/735], Loss: 0.1202\n",
      "Epoch [29/50], Step [233/735], Loss: 0.2191\n",
      "Epoch [29/50], Step [234/735], Loss: 0.1619\n",
      "Epoch [29/50], Step [235/735], Loss: 0.3964\n",
      "Epoch [29/50], Step [236/735], Loss: 0.2978\n",
      "Epoch [29/50], Step [237/735], Loss: 0.3691\n",
      "Epoch [29/50], Step [238/735], Loss: 0.1084\n",
      "Epoch [29/50], Step [239/735], Loss: 0.3014\n",
      "Epoch [29/50], Step [240/735], Loss: 0.1028\n",
      "Epoch [29/50], Step [241/735], Loss: 0.4032\n",
      "Epoch [29/50], Step [242/735], Loss: 0.3783\n",
      "Epoch [29/50], Step [243/735], Loss: 0.3288\n",
      "Epoch [29/50], Step [244/735], Loss: 0.0796\n",
      "Epoch [29/50], Step [245/735], Loss: 0.1327\n",
      "Epoch [29/50], Step [246/735], Loss: 0.1772\n",
      "Epoch [29/50], Step [247/735], Loss: 0.2919\n",
      "Epoch [29/50], Step [248/735], Loss: 0.3106\n",
      "Epoch [29/50], Step [249/735], Loss: 0.4132\n",
      "Epoch [29/50], Step [250/735], Loss: 0.4466\n",
      "Epoch [29/50], Step [251/735], Loss: 0.6971\n",
      "Epoch [29/50], Step [252/735], Loss: 0.4742\n",
      "Epoch [29/50], Step [253/735], Loss: 0.2865\n",
      "Epoch [29/50], Step [254/735], Loss: 0.9544\n",
      "Epoch [29/50], Step [255/735], Loss: 0.1465\n",
      "Epoch [29/50], Step [256/735], Loss: 0.0767\n",
      "Epoch [29/50], Step [257/735], Loss: 0.1889\n",
      "Epoch [29/50], Step [258/735], Loss: 0.1987\n",
      "Epoch [29/50], Step [259/735], Loss: 0.1550\n",
      "Epoch [29/50], Step [260/735], Loss: 0.2380\n",
      "Epoch [29/50], Step [261/735], Loss: 0.8664\n",
      "Epoch [29/50], Step [262/735], Loss: 0.0534\n",
      "Epoch [29/50], Step [263/735], Loss: 0.5962\n",
      "Epoch [29/50], Step [264/735], Loss: 0.7167\n",
      "Epoch [29/50], Step [265/735], Loss: 0.1260\n",
      "Epoch [29/50], Step [266/735], Loss: 0.2112\n",
      "Epoch [29/50], Step [267/735], Loss: 0.2693\n",
      "Epoch [29/50], Step [268/735], Loss: 0.8845\n",
      "Epoch [29/50], Step [269/735], Loss: 0.5451\n",
      "Epoch [29/50], Step [270/735], Loss: 0.5957\n",
      "Epoch [29/50], Step [271/735], Loss: 0.1774\n",
      "Epoch [29/50], Step [272/735], Loss: 0.1125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Step [273/735], Loss: 0.6077\n",
      "Epoch [29/50], Step [274/735], Loss: 0.3236\n",
      "Epoch [29/50], Step [275/735], Loss: 0.0677\n",
      "Epoch [29/50], Step [276/735], Loss: 0.1810\n",
      "Epoch [29/50], Step [277/735], Loss: 0.5499\n",
      "Epoch [29/50], Step [278/735], Loss: 0.1547\n",
      "Epoch [29/50], Step [279/735], Loss: 0.3544\n",
      "Epoch [29/50], Step [280/735], Loss: 4.8134\n",
      "Epoch [29/50], Step [281/735], Loss: 0.2643\n",
      "Epoch [29/50], Step [282/735], Loss: 0.4387\n",
      "Epoch [29/50], Step [283/735], Loss: 0.6192\n",
      "Epoch [29/50], Step [284/735], Loss: 0.1284\n",
      "Epoch [29/50], Step [285/735], Loss: 0.3472\n",
      "Epoch [29/50], Step [286/735], Loss: 0.0641\n",
      "Epoch [29/50], Step [287/735], Loss: 0.2313\n",
      "Epoch [29/50], Step [288/735], Loss: 0.3144\n",
      "Epoch [29/50], Step [289/735], Loss: 0.7581\n",
      "Epoch [29/50], Step [290/735], Loss: 0.3295\n",
      "Epoch [29/50], Step [291/735], Loss: 0.6625\n",
      "Epoch [29/50], Step [292/735], Loss: 0.2663\n",
      "Epoch [29/50], Step [293/735], Loss: 0.3255\n",
      "Epoch [29/50], Step [294/735], Loss: 0.2385\n",
      "Epoch [29/50], Step [295/735], Loss: 0.2486\n",
      "Epoch [29/50], Step [296/735], Loss: 0.3242\n",
      "Epoch [29/50], Step [297/735], Loss: 2.1549\n",
      "Epoch [29/50], Step [298/735], Loss: 0.3282\n",
      "Epoch [29/50], Step [299/735], Loss: 0.3572\n",
      "Epoch [29/50], Step [300/735], Loss: 0.2030\n",
      "Epoch [29/50], Step [301/735], Loss: 0.7132\n",
      "Epoch [29/50], Step [302/735], Loss: 0.2846\n",
      "Epoch [29/50], Step [303/735], Loss: 0.5315\n",
      "Epoch [29/50], Step [304/735], Loss: 0.1637\n",
      "Epoch [29/50], Step [305/735], Loss: 0.2242\n",
      "Epoch [29/50], Step [306/735], Loss: 0.0675\n",
      "Epoch [29/50], Step [307/735], Loss: 0.3617\n",
      "Epoch [29/50], Step [308/735], Loss: 0.3656\n",
      "Epoch [29/50], Step [309/735], Loss: 2.6445\n",
      "Epoch [29/50], Step [310/735], Loss: 0.2982\n",
      "Epoch [29/50], Step [311/735], Loss: 0.1992\n",
      "Epoch [29/50], Step [312/735], Loss: 0.3975\n",
      "Epoch [29/50], Step [313/735], Loss: 0.2193\n",
      "Epoch [29/50], Step [314/735], Loss: 0.3931\n",
      "Epoch [29/50], Step [315/735], Loss: 1.0252\n",
      "Epoch [29/50], Step [316/735], Loss: 0.1333\n",
      "Epoch [29/50], Step [317/735], Loss: 0.1125\n",
      "Epoch [29/50], Step [318/735], Loss: 0.2073\n",
      "Epoch [29/50], Step [319/735], Loss: 0.9374\n",
      "Epoch [29/50], Step [320/735], Loss: 0.4760\n",
      "Epoch [29/50], Step [321/735], Loss: 0.2696\n",
      "Epoch [29/50], Step [322/735], Loss: 0.1525\n",
      "Epoch [29/50], Step [323/735], Loss: 0.3078\n",
      "Epoch [29/50], Step [324/735], Loss: 0.2151\n",
      "Epoch [29/50], Step [325/735], Loss: 0.3389\n",
      "Epoch [29/50], Step [326/735], Loss: 0.3194\n",
      "Epoch [29/50], Step [327/735], Loss: 0.3985\n",
      "Epoch [29/50], Step [328/735], Loss: 0.1696\n",
      "Epoch [29/50], Step [329/735], Loss: 1.2269\n",
      "Epoch [29/50], Step [330/735], Loss: 0.6220\n",
      "Epoch [29/50], Step [331/735], Loss: 0.3399\n",
      "Epoch [29/50], Step [332/735], Loss: 1.1140\n",
      "Epoch [29/50], Step [333/735], Loss: 0.3166\n",
      "Epoch [29/50], Step [334/735], Loss: 0.2238\n",
      "Epoch [29/50], Step [335/735], Loss: 0.7809\n",
      "Epoch [29/50], Step [336/735], Loss: 0.7553\n",
      "Epoch [29/50], Step [337/735], Loss: 0.1166\n",
      "Epoch [29/50], Step [338/735], Loss: 0.0980\n",
      "Epoch [29/50], Step [339/735], Loss: 0.2210\n",
      "Epoch [29/50], Step [340/735], Loss: 0.6016\n",
      "Epoch [29/50], Step [341/735], Loss: 0.1712\n",
      "Epoch [29/50], Step [342/735], Loss: 0.2738\n",
      "Epoch [29/50], Step [343/735], Loss: 0.4299\n",
      "Epoch [29/50], Step [344/735], Loss: 0.1200\n",
      "Epoch [29/50], Step [345/735], Loss: 0.4800\n",
      "Epoch [29/50], Step [346/735], Loss: 0.0577\n",
      "Epoch [29/50], Step [347/735], Loss: 0.2930\n",
      "Epoch [29/50], Step [348/735], Loss: 0.0605\n",
      "Epoch [29/50], Step [349/735], Loss: 0.2293\n",
      "Epoch [29/50], Step [350/735], Loss: 0.4428\n",
      "Epoch [29/50], Step [351/735], Loss: 0.6389\n",
      "Epoch [29/50], Step [352/735], Loss: 1.0098\n",
      "Epoch [29/50], Step [353/735], Loss: 0.6221\n",
      "Epoch [29/50], Step [354/735], Loss: 0.1801\n",
      "Epoch [29/50], Step [355/735], Loss: 0.9605\n",
      "Epoch [29/50], Step [356/735], Loss: 0.3290\n",
      "Epoch [29/50], Step [357/735], Loss: 0.1890\n",
      "Epoch [29/50], Step [358/735], Loss: 0.4718\n",
      "Epoch [29/50], Step [359/735], Loss: 0.1476\n",
      "Epoch [29/50], Step [360/735], Loss: 0.3676\n",
      "Epoch [29/50], Step [361/735], Loss: 0.7987\n",
      "Epoch [29/50], Step [362/735], Loss: 0.1669\n",
      "Epoch [29/50], Step [363/735], Loss: 0.5466\n",
      "Epoch [29/50], Step [364/735], Loss: 0.6465\n",
      "Epoch [29/50], Step [365/735], Loss: 0.2921\n",
      "Epoch [29/50], Step [366/735], Loss: 0.3800\n",
      "Epoch [29/50], Step [367/735], Loss: 0.2447\n",
      "Epoch [29/50], Step [368/735], Loss: 0.3385\n",
      "Epoch [29/50], Step [369/735], Loss: 1.2817\n",
      "Epoch [29/50], Step [370/735], Loss: 0.4824\n",
      "Epoch [29/50], Step [371/735], Loss: 0.4676\n",
      "Epoch [29/50], Step [372/735], Loss: 0.2905\n",
      "Epoch [29/50], Step [373/735], Loss: 0.2029\n",
      "Epoch [29/50], Step [374/735], Loss: 0.1983\n",
      "Epoch [29/50], Step [375/735], Loss: 0.3726\n",
      "Epoch [29/50], Step [376/735], Loss: 0.1553\n",
      "Epoch [29/50], Step [377/735], Loss: 0.3427\n",
      "Epoch [29/50], Step [378/735], Loss: 0.3448\n",
      "Epoch [29/50], Step [379/735], Loss: 0.3252\n",
      "Epoch [29/50], Step [380/735], Loss: 0.1338\n",
      "Epoch [29/50], Step [381/735], Loss: 0.1534\n",
      "Epoch [29/50], Step [382/735], Loss: 0.4496\n",
      "Epoch [29/50], Step [383/735], Loss: 0.3517\n",
      "Epoch [29/50], Step [384/735], Loss: 0.2921\n",
      "Epoch [29/50], Step [385/735], Loss: 0.1320\n",
      "Epoch [29/50], Step [386/735], Loss: 0.6879\n",
      "Epoch [29/50], Step [387/735], Loss: 0.6956\n",
      "Epoch [29/50], Step [388/735], Loss: 0.4256\n",
      "Epoch [29/50], Step [389/735], Loss: 0.2490\n",
      "Epoch [29/50], Step [390/735], Loss: 0.1851\n",
      "Epoch [29/50], Step [391/735], Loss: 0.1629\n",
      "Epoch [29/50], Step [392/735], Loss: 1.0131\n",
      "Epoch [29/50], Step [393/735], Loss: 0.2032\n",
      "Epoch [29/50], Step [394/735], Loss: 0.5043\n",
      "Epoch [29/50], Step [395/735], Loss: 0.3087\n",
      "Epoch [29/50], Step [396/735], Loss: 0.6961\n",
      "Epoch [29/50], Step [397/735], Loss: 0.5291\n",
      "Epoch [29/50], Step [398/735], Loss: 0.0899\n",
      "Epoch [29/50], Step [399/735], Loss: 0.5393\n",
      "Epoch [29/50], Step [400/735], Loss: 0.2161\n",
      "Epoch [29/50], Step [401/735], Loss: 0.1152\n",
      "Epoch [29/50], Step [402/735], Loss: 0.4063\n",
      "Epoch [29/50], Step [403/735], Loss: 0.4237\n",
      "Epoch [29/50], Step [404/735], Loss: 0.1107\n",
      "Epoch [29/50], Step [405/735], Loss: 0.2375\n",
      "Epoch [29/50], Step [406/735], Loss: 0.4048\n",
      "Epoch [29/50], Step [407/735], Loss: 0.1387\n",
      "Epoch [29/50], Step [408/735], Loss: 0.3134\n",
      "Epoch [29/50], Step [409/735], Loss: 0.1916\n",
      "Epoch [29/50], Step [410/735], Loss: 2.2855\n",
      "Epoch [29/50], Step [411/735], Loss: 0.7261\n",
      "Epoch [29/50], Step [412/735], Loss: 0.2241\n",
      "Epoch [29/50], Step [413/735], Loss: 0.7159\n",
      "Epoch [29/50], Step [414/735], Loss: 0.8090\n",
      "Epoch [29/50], Step [415/735], Loss: 0.4264\n",
      "Epoch [29/50], Step [416/735], Loss: 0.2834\n",
      "Epoch [29/50], Step [417/735], Loss: 0.5249\n",
      "Epoch [29/50], Step [418/735], Loss: 0.5371\n",
      "Epoch [29/50], Step [419/735], Loss: 0.4312\n",
      "Epoch [29/50], Step [420/735], Loss: 0.3211\n",
      "Epoch [29/50], Step [421/735], Loss: 4.9215\n",
      "Epoch [29/50], Step [422/735], Loss: 0.2292\n",
      "Epoch [29/50], Step [423/735], Loss: 0.4507\n",
      "Epoch [29/50], Step [424/735], Loss: 0.2991\n",
      "Epoch [29/50], Step [425/735], Loss: 1.3612\n",
      "Epoch [29/50], Step [426/735], Loss: 0.4982\n",
      "Epoch [29/50], Step [427/735], Loss: 0.3849\n",
      "Epoch [29/50], Step [428/735], Loss: 0.2343\n",
      "Epoch [29/50], Step [429/735], Loss: 0.3311\n",
      "Epoch [29/50], Step [430/735], Loss: 0.4496\n",
      "Epoch [29/50], Step [431/735], Loss: 0.3667\n",
      "Epoch [29/50], Step [432/735], Loss: 0.3948\n",
      "Epoch [29/50], Step [433/735], Loss: 0.1396\n",
      "Epoch [29/50], Step [434/735], Loss: 0.1357\n",
      "Epoch [29/50], Step [435/735], Loss: 0.4667\n",
      "Epoch [29/50], Step [436/735], Loss: 0.2527\n",
      "Epoch [29/50], Step [437/735], Loss: 0.0669\n",
      "Epoch [29/50], Step [438/735], Loss: 0.3737\n",
      "Epoch [29/50], Step [439/735], Loss: 0.3345\n",
      "Epoch [29/50], Step [440/735], Loss: 0.4296\n",
      "Epoch [29/50], Step [441/735], Loss: 0.2257\n",
      "Epoch [29/50], Step [442/735], Loss: 0.2198\n",
      "Epoch [29/50], Step [443/735], Loss: 0.4931\n",
      "Epoch [29/50], Step [444/735], Loss: 0.2805\n",
      "Epoch [29/50], Step [445/735], Loss: 0.2092\n",
      "Epoch [29/50], Step [446/735], Loss: 0.8898\n",
      "Epoch [29/50], Step [447/735], Loss: 0.3461\n",
      "Epoch [29/50], Step [448/735], Loss: 0.2555\n",
      "Epoch [29/50], Step [449/735], Loss: 0.3078\n",
      "Epoch [29/50], Step [450/735], Loss: 0.2879\n",
      "Epoch [29/50], Step [451/735], Loss: 0.5591\n",
      "Epoch [29/50], Step [452/735], Loss: 0.1857\n",
      "Epoch [29/50], Step [453/735], Loss: 0.2351\n",
      "Epoch [29/50], Step [454/735], Loss: 0.2839\n",
      "Epoch [29/50], Step [455/735], Loss: 0.5895\n",
      "Epoch [29/50], Step [456/735], Loss: 0.0365\n",
      "Epoch [29/50], Step [457/735], Loss: 0.2305\n",
      "Epoch [29/50], Step [458/735], Loss: 0.7106\n",
      "Epoch [29/50], Step [459/735], Loss: 0.2927\n",
      "Epoch [29/50], Step [460/735], Loss: 0.4290\n",
      "Epoch [29/50], Step [461/735], Loss: 0.0425\n",
      "Epoch [29/50], Step [462/735], Loss: 0.2371\n",
      "Epoch [29/50], Step [463/735], Loss: 0.7942\n",
      "Epoch [29/50], Step [464/735], Loss: 0.3731\n",
      "Epoch [29/50], Step [465/735], Loss: 0.7031\n",
      "Epoch [29/50], Step [466/735], Loss: 0.2940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Step [467/735], Loss: 1.9633\n",
      "Epoch [29/50], Step [468/735], Loss: 0.5597\n",
      "Epoch [29/50], Step [469/735], Loss: 0.4295\n",
      "Epoch [29/50], Step [470/735], Loss: 0.9791\n",
      "Epoch [29/50], Step [471/735], Loss: 1.4214\n",
      "Epoch [29/50], Step [472/735], Loss: 0.4666\n",
      "Epoch [29/50], Step [473/735], Loss: 0.1966\n",
      "Epoch [29/50], Step [474/735], Loss: 0.1784\n",
      "Epoch [29/50], Step [475/735], Loss: 0.2342\n",
      "Epoch [29/50], Step [476/735], Loss: 0.2274\n",
      "Epoch [29/50], Step [477/735], Loss: 0.8861\n",
      "Epoch [29/50], Step [478/735], Loss: 0.2184\n",
      "Epoch [29/50], Step [479/735], Loss: 0.1952\n",
      "Epoch [29/50], Step [480/735], Loss: 0.1919\n",
      "Epoch [29/50], Step [481/735], Loss: 0.6330\n",
      "Epoch [29/50], Step [482/735], Loss: 0.5125\n",
      "Epoch [29/50], Step [483/735], Loss: 0.1314\n",
      "Epoch [29/50], Step [484/735], Loss: 0.0555\n",
      "Epoch [29/50], Step [485/735], Loss: 0.1593\n",
      "Epoch [29/50], Step [486/735], Loss: 0.2165\n",
      "Epoch [29/50], Step [487/735], Loss: 0.3035\n",
      "Epoch [29/50], Step [488/735], Loss: 0.2375\n",
      "Epoch [29/50], Step [489/735], Loss: 0.1439\n",
      "Epoch [29/50], Step [490/735], Loss: 0.0441\n",
      "Epoch [29/50], Step [491/735], Loss: 0.2431\n",
      "Epoch [29/50], Step [492/735], Loss: 0.1174\n",
      "Epoch [29/50], Step [493/735], Loss: 0.2625\n",
      "Epoch [29/50], Step [494/735], Loss: 0.8022\n",
      "Epoch [29/50], Step [495/735], Loss: 0.0832\n",
      "Epoch [29/50], Step [496/735], Loss: 0.0908\n",
      "Epoch [29/50], Step [497/735], Loss: 0.4800\n",
      "Epoch [29/50], Step [498/735], Loss: 0.2026\n",
      "Epoch [29/50], Step [499/735], Loss: 0.2976\n",
      "Epoch [29/50], Step [500/735], Loss: 0.2129\n",
      "Epoch [29/50], Step [501/735], Loss: 0.4203\n",
      "Epoch [29/50], Step [502/735], Loss: 0.4825\n",
      "Epoch [29/50], Step [503/735], Loss: 0.5468\n",
      "Epoch [29/50], Step [504/735], Loss: 1.2489\n",
      "Epoch [29/50], Step [505/735], Loss: 0.3552\n",
      "Epoch [29/50], Step [506/735], Loss: 0.1637\n",
      "Epoch [29/50], Step [507/735], Loss: 0.1209\n",
      "Epoch [29/50], Step [508/735], Loss: 0.4060\n",
      "Epoch [29/50], Step [509/735], Loss: 0.5008\n",
      "Epoch [29/50], Step [510/735], Loss: 0.2310\n",
      "Epoch [29/50], Step [511/735], Loss: 0.1966\n",
      "Epoch [29/50], Step [512/735], Loss: 0.1775\n",
      "Epoch [29/50], Step [513/735], Loss: 0.0749\n",
      "Epoch [29/50], Step [514/735], Loss: 0.3421\n",
      "Epoch [29/50], Step [515/735], Loss: 0.1991\n",
      "Epoch [29/50], Step [516/735], Loss: 0.2903\n",
      "Epoch [29/50], Step [517/735], Loss: 0.2262\n",
      "Epoch [29/50], Step [518/735], Loss: 0.9908\n",
      "Epoch [29/50], Step [519/735], Loss: 0.1258\n",
      "Epoch [29/50], Step [520/735], Loss: 0.4958\n",
      "Epoch [29/50], Step [521/735], Loss: 0.3329\n",
      "Epoch [29/50], Step [522/735], Loss: 0.1764\n",
      "Epoch [29/50], Step [523/735], Loss: 0.8150\n",
      "Epoch [29/50], Step [524/735], Loss: 0.2108\n",
      "Epoch [29/50], Step [525/735], Loss: 0.1898\n",
      "Epoch [29/50], Step [526/735], Loss: 0.1814\n",
      "Epoch [29/50], Step [527/735], Loss: 0.1248\n",
      "Epoch [29/50], Step [528/735], Loss: 0.1573\n",
      "Epoch [29/50], Step [529/735], Loss: 0.2997\n",
      "Epoch [29/50], Step [530/735], Loss: 0.6475\n",
      "Epoch [29/50], Step [531/735], Loss: 0.1158\n",
      "Epoch [29/50], Step [532/735], Loss: 0.4984\n",
      "Epoch [29/50], Step [533/735], Loss: 0.1721\n",
      "Epoch [29/50], Step [534/735], Loss: 0.2217\n",
      "Epoch [29/50], Step [535/735], Loss: 0.5187\n",
      "Epoch [29/50], Step [536/735], Loss: 0.9094\n",
      "Epoch [29/50], Step [537/735], Loss: 0.0978\n",
      "Epoch [29/50], Step [538/735], Loss: 0.1358\n",
      "Epoch [29/50], Step [539/735], Loss: 0.3108\n",
      "Epoch [29/50], Step [540/735], Loss: 0.6739\n",
      "Epoch [29/50], Step [541/735], Loss: 0.2220\n",
      "Epoch [29/50], Step [542/735], Loss: 0.2493\n",
      "Epoch [29/50], Step [543/735], Loss: 0.2856\n",
      "Epoch [29/50], Step [544/735], Loss: 0.3729\n",
      "Epoch [29/50], Step [545/735], Loss: 0.5112\n",
      "Epoch [29/50], Step [546/735], Loss: 0.3034\n",
      "Epoch [29/50], Step [547/735], Loss: 0.1142\n",
      "Epoch [29/50], Step [548/735], Loss: 0.1018\n",
      "Epoch [29/50], Step [549/735], Loss: 1.0033\n",
      "Epoch [29/50], Step [550/735], Loss: 0.2225\n",
      "Epoch [29/50], Step [551/735], Loss: 0.3801\n",
      "Epoch [29/50], Step [552/735], Loss: 0.0491\n",
      "Epoch [29/50], Step [553/735], Loss: 0.1206\n",
      "Epoch [29/50], Step [554/735], Loss: 0.5096\n",
      "Epoch [29/50], Step [555/735], Loss: 0.1408\n",
      "Epoch [29/50], Step [556/735], Loss: 0.1161\n",
      "Epoch [29/50], Step [557/735], Loss: 0.1381\n",
      "Epoch [29/50], Step [558/735], Loss: 0.1532\n",
      "Epoch [29/50], Step [559/735], Loss: 0.4030\n",
      "Epoch [29/50], Step [560/735], Loss: 4.6051\n",
      "Epoch [29/50], Step [561/735], Loss: 0.1155\n",
      "Epoch [29/50], Step [562/735], Loss: 4.0169\n",
      "Epoch [29/50], Step [563/735], Loss: 0.7446\n",
      "Epoch [29/50], Step [564/735], Loss: 0.4575\n",
      "Epoch [29/50], Step [565/735], Loss: 0.2978\n",
      "Epoch [29/50], Step [566/735], Loss: 0.3205\n",
      "Epoch [29/50], Step [567/735], Loss: 0.2313\n",
      "Epoch [29/50], Step [568/735], Loss: 0.2740\n",
      "Epoch [29/50], Step [569/735], Loss: 0.1091\n",
      "Epoch [29/50], Step [570/735], Loss: 0.0725\n",
      "Epoch [29/50], Step [571/735], Loss: 0.2687\n",
      "Epoch [29/50], Step [572/735], Loss: 1.0235\n",
      "Epoch [29/50], Step [573/735], Loss: 0.8040\n",
      "Epoch [29/50], Step [574/735], Loss: 0.4695\n",
      "Epoch [29/50], Step [575/735], Loss: 0.1889\n",
      "Epoch [29/50], Step [576/735], Loss: 0.1146\n",
      "Epoch [29/50], Step [577/735], Loss: 0.2423\n",
      "Epoch [29/50], Step [578/735], Loss: 0.1737\n",
      "Epoch [29/50], Step [579/735], Loss: 0.2310\n",
      "Epoch [29/50], Step [580/735], Loss: 0.1609\n",
      "Epoch [29/50], Step [581/735], Loss: 0.1324\n",
      "Epoch [29/50], Step [582/735], Loss: 0.2817\n",
      "Epoch [29/50], Step [583/735], Loss: 0.2326\n",
      "Epoch [29/50], Step [584/735], Loss: 0.1775\n",
      "Epoch [29/50], Step [585/735], Loss: 0.1489\n",
      "Epoch [29/50], Step [586/735], Loss: 0.2214\n",
      "Epoch [29/50], Step [587/735], Loss: 0.4484\n",
      "Epoch [29/50], Step [588/735], Loss: 0.3623\n",
      "Epoch [29/50], Step [589/735], Loss: 0.4210\n",
      "Epoch [29/50], Step [590/735], Loss: 0.2418\n",
      "Epoch [29/50], Step [591/735], Loss: 0.2157\n",
      "Epoch [29/50], Step [592/735], Loss: 0.9717\n",
      "Epoch [29/50], Step [593/735], Loss: 0.3972\n",
      "Epoch [29/50], Step [594/735], Loss: 0.2043\n",
      "Epoch [29/50], Step [595/735], Loss: 0.2246\n",
      "Epoch [29/50], Step [596/735], Loss: 0.1536\n",
      "Epoch [29/50], Step [597/735], Loss: 0.6462\n",
      "Epoch [29/50], Step [598/735], Loss: 0.3265\n",
      "Epoch [29/50], Step [599/735], Loss: 0.6666\n",
      "Epoch [29/50], Step [600/735], Loss: 0.2137\n",
      "Epoch [29/50], Step [601/735], Loss: 0.2024\n",
      "Epoch [29/50], Step [602/735], Loss: 0.4233\n",
      "Epoch [29/50], Step [603/735], Loss: 0.2085\n",
      "Epoch [29/50], Step [604/735], Loss: 0.1634\n",
      "Epoch [29/50], Step [605/735], Loss: 1.1459\n",
      "Epoch [29/50], Step [606/735], Loss: 0.3339\n",
      "Epoch [29/50], Step [607/735], Loss: 0.5893\n",
      "Epoch [29/50], Step [608/735], Loss: 0.4148\n",
      "Epoch [29/50], Step [609/735], Loss: 0.4688\n",
      "Epoch [29/50], Step [610/735], Loss: 0.1333\n",
      "Epoch [29/50], Step [611/735], Loss: 0.1640\n",
      "Epoch [29/50], Step [612/735], Loss: 0.4435\n",
      "Epoch [29/50], Step [613/735], Loss: 0.1937\n",
      "Epoch [29/50], Step [614/735], Loss: 0.6424\n",
      "Epoch [29/50], Step [615/735], Loss: 0.1678\n",
      "Epoch [29/50], Step [616/735], Loss: 0.1948\n",
      "Epoch [29/50], Step [617/735], Loss: 0.3263\n",
      "Epoch [29/50], Step [618/735], Loss: 0.1980\n",
      "Epoch [29/50], Step [619/735], Loss: 1.1762\n",
      "Epoch [29/50], Step [620/735], Loss: 0.1420\n",
      "Epoch [29/50], Step [621/735], Loss: 0.2554\n",
      "Epoch [29/50], Step [622/735], Loss: 1.4202\n",
      "Epoch [29/50], Step [623/735], Loss: 0.2865\n",
      "Epoch [29/50], Step [624/735], Loss: 1.3631\n",
      "Epoch [29/50], Step [625/735], Loss: 0.3913\n",
      "Epoch [29/50], Step [626/735], Loss: 0.1837\n",
      "Epoch [29/50], Step [627/735], Loss: 0.2705\n",
      "Epoch [29/50], Step [628/735], Loss: 0.1195\n",
      "Epoch [29/50], Step [629/735], Loss: 0.1183\n",
      "Epoch [29/50], Step [630/735], Loss: 0.1373\n",
      "Epoch [29/50], Step [631/735], Loss: 1.0739\n",
      "Epoch [29/50], Step [632/735], Loss: 0.2975\n",
      "Epoch [29/50], Step [633/735], Loss: 0.2047\n",
      "Epoch [29/50], Step [634/735], Loss: 0.3482\n",
      "Epoch [29/50], Step [635/735], Loss: 1.0810\n",
      "Epoch [29/50], Step [636/735], Loss: 0.0666\n",
      "Epoch [29/50], Step [637/735], Loss: 0.6365\n",
      "Epoch [29/50], Step [638/735], Loss: 0.0661\n",
      "Epoch [29/50], Step [639/735], Loss: 0.2692\n",
      "Epoch [29/50], Step [640/735], Loss: 0.3194\n",
      "Epoch [29/50], Step [641/735], Loss: 0.6388\n",
      "Epoch [29/50], Step [642/735], Loss: 0.2179\n",
      "Epoch [29/50], Step [643/735], Loss: 0.3076\n",
      "Epoch [29/50], Step [644/735], Loss: 0.1648\n",
      "Epoch [29/50], Step [645/735], Loss: 0.1791\n",
      "Epoch [29/50], Step [646/735], Loss: 0.0954\n",
      "Epoch [29/50], Step [647/735], Loss: 0.6131\n",
      "Epoch [29/50], Step [648/735], Loss: 0.2842\n",
      "Epoch [29/50], Step [649/735], Loss: 0.3298\n",
      "Epoch [29/50], Step [650/735], Loss: 0.1025\n",
      "Epoch [29/50], Step [651/735], Loss: 0.0347\n",
      "Epoch [29/50], Step [652/735], Loss: 0.4298\n",
      "Epoch [29/50], Step [653/735], Loss: 0.2490\n",
      "Epoch [29/50], Step [654/735], Loss: 0.1978\n",
      "Epoch [29/50], Step [655/735], Loss: 0.3120\n",
      "Epoch [29/50], Step [656/735], Loss: 0.3808\n",
      "Epoch [29/50], Step [657/735], Loss: 0.3210\n",
      "Epoch [29/50], Step [658/735], Loss: 0.8120\n",
      "Epoch [29/50], Step [659/735], Loss: 0.4121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Step [660/735], Loss: 0.1146\n",
      "Epoch [29/50], Step [661/735], Loss: 0.2782\n",
      "Epoch [29/50], Step [662/735], Loss: 0.1741\n",
      "Epoch [29/50], Step [663/735], Loss: 0.3879\n",
      "Epoch [29/50], Step [664/735], Loss: 0.2731\n",
      "Epoch [29/50], Step [665/735], Loss: 0.2113\n",
      "Epoch [29/50], Step [666/735], Loss: 0.2175\n",
      "Epoch [29/50], Step [667/735], Loss: 0.5515\n",
      "Epoch [29/50], Step [668/735], Loss: 0.2626\n",
      "Epoch [29/50], Step [669/735], Loss: 0.3665\n",
      "Epoch [29/50], Step [670/735], Loss: 0.2396\n",
      "Epoch [29/50], Step [671/735], Loss: 0.4645\n",
      "Epoch [29/50], Step [672/735], Loss: 0.2985\n",
      "Epoch [29/50], Step [673/735], Loss: 0.3065\n",
      "Epoch [29/50], Step [674/735], Loss: 0.2219\n",
      "Epoch [29/50], Step [675/735], Loss: 0.2337\n",
      "Epoch [29/50], Step [676/735], Loss: 0.1492\n",
      "Epoch [29/50], Step [677/735], Loss: 0.4169\n",
      "Epoch [29/50], Step [678/735], Loss: 0.8227\n",
      "Epoch [29/50], Step [679/735], Loss: 0.3736\n",
      "Epoch [29/50], Step [680/735], Loss: 1.3438\n",
      "Epoch [29/50], Step [681/735], Loss: 0.0718\n",
      "Epoch [29/50], Step [682/735], Loss: 0.1399\n",
      "Epoch [29/50], Step [683/735], Loss: 0.3685\n",
      "Epoch [29/50], Step [684/735], Loss: 0.1703\n",
      "Epoch [29/50], Step [685/735], Loss: 0.2479\n",
      "Epoch [29/50], Step [686/735], Loss: 0.2197\n",
      "Epoch [29/50], Step [687/735], Loss: 0.5287\n",
      "Epoch [29/50], Step [688/735], Loss: 0.0833\n",
      "Epoch [29/50], Step [689/735], Loss: 0.3178\n",
      "Epoch [29/50], Step [690/735], Loss: 0.4229\n",
      "Epoch [29/50], Step [691/735], Loss: 0.2509\n",
      "Epoch [29/50], Step [692/735], Loss: 0.4104\n",
      "Epoch [29/50], Step [693/735], Loss: 0.5218\n",
      "Epoch [29/50], Step [694/735], Loss: 0.1666\n",
      "Epoch [29/50], Step [695/735], Loss: 0.8437\n",
      "Epoch [29/50], Step [696/735], Loss: 0.4389\n",
      "Epoch [29/50], Step [697/735], Loss: 0.1248\n",
      "Epoch [29/50], Step [698/735], Loss: 0.2365\n",
      "Epoch [29/50], Step [699/735], Loss: 0.2056\n",
      "Epoch [29/50], Step [700/735], Loss: 0.1590\n",
      "Epoch [29/50], Step [701/735], Loss: 0.7223\n",
      "Epoch [29/50], Step [702/735], Loss: 0.9782\n",
      "Epoch [29/50], Step [703/735], Loss: 0.2243\n",
      "Epoch [29/50], Step [704/735], Loss: 0.3481\n",
      "Epoch [29/50], Step [705/735], Loss: 0.4130\n",
      "Epoch [29/50], Step [706/735], Loss: 0.0586\n",
      "Epoch [29/50], Step [707/735], Loss: 0.1463\n",
      "Epoch [29/50], Step [708/735], Loss: 0.2562\n",
      "Epoch [29/50], Step [709/735], Loss: 0.7025\n",
      "Epoch [29/50], Step [710/735], Loss: 0.0570\n",
      "Epoch [29/50], Step [711/735], Loss: 0.1866\n",
      "Epoch [29/50], Step [712/735], Loss: 0.2736\n",
      "Epoch [29/50], Step [713/735], Loss: 0.1522\n",
      "Epoch [29/50], Step [714/735], Loss: 0.4650\n",
      "Epoch [29/50], Step [715/735], Loss: 0.4857\n",
      "Epoch [29/50], Step [716/735], Loss: 0.3895\n",
      "Epoch [29/50], Step [717/735], Loss: 0.2242\n",
      "Epoch [29/50], Step [718/735], Loss: 0.2905\n",
      "Epoch [29/50], Step [719/735], Loss: 0.9845\n",
      "Epoch [29/50], Step [720/735], Loss: 0.4509\n",
      "Epoch [29/50], Step [721/735], Loss: 0.2994\n",
      "Epoch [29/50], Step [722/735], Loss: 0.2758\n",
      "Epoch [29/50], Step [723/735], Loss: 0.1519\n",
      "Epoch [29/50], Step [724/735], Loss: 0.1565\n",
      "Epoch [29/50], Step [725/735], Loss: 0.4137\n",
      "Epoch [29/50], Step [726/735], Loss: 0.0815\n",
      "Epoch [29/50], Step [727/735], Loss: 0.7672\n",
      "Epoch [29/50], Step [728/735], Loss: 0.2604\n",
      "Epoch [29/50], Step [729/735], Loss: 0.0923\n",
      "Epoch [29/50], Step [730/735], Loss: 0.2561\n",
      "Epoch [29/50], Step [731/735], Loss: 0.1450\n",
      "Epoch [29/50], Step [732/735], Loss: 0.1455\n",
      "Epoch [29/50], Step [733/735], Loss: 0.7871\n",
      "Epoch [29/50], Step [734/735], Loss: 0.1134\n",
      "Epoch [29/50], Step [735/735], Loss: 0.1019\n",
      "Epoch [30/50], Step [1/735], Loss: 0.2874\n",
      "Epoch [30/50], Step [2/735], Loss: 0.1149\n",
      "Epoch [30/50], Step [3/735], Loss: 0.2524\n",
      "Epoch [30/50], Step [4/735], Loss: 0.2737\n",
      "Epoch [30/50], Step [5/735], Loss: 0.7521\n",
      "Epoch [30/50], Step [6/735], Loss: 0.1859\n",
      "Epoch [30/50], Step [7/735], Loss: 0.1869\n",
      "Epoch [30/50], Step [8/735], Loss: 0.9203\n",
      "Epoch [30/50], Step [9/735], Loss: 0.4691\n",
      "Epoch [30/50], Step [10/735], Loss: 0.2433\n",
      "Epoch [30/50], Step [11/735], Loss: 0.7869\n",
      "Epoch [30/50], Step [12/735], Loss: 0.2918\n",
      "Epoch [30/50], Step [13/735], Loss: 0.1961\n",
      "Epoch [30/50], Step [14/735], Loss: 0.6524\n",
      "Epoch [30/50], Step [15/735], Loss: 0.0881\n",
      "Epoch [30/50], Step [16/735], Loss: 0.2726\n",
      "Epoch [30/50], Step [17/735], Loss: 0.5762\n",
      "Epoch [30/50], Step [18/735], Loss: 0.1764\n",
      "Epoch [30/50], Step [19/735], Loss: 0.1650\n",
      "Epoch [30/50], Step [20/735], Loss: 0.6929\n",
      "Epoch [30/50], Step [21/735], Loss: 0.9984\n",
      "Epoch [30/50], Step [22/735], Loss: 0.2391\n",
      "Epoch [30/50], Step [23/735], Loss: 0.3571\n",
      "Epoch [30/50], Step [24/735], Loss: 0.0924\n",
      "Epoch [30/50], Step [25/735], Loss: 0.1746\n",
      "Epoch [30/50], Step [26/735], Loss: 0.4277\n",
      "Epoch [30/50], Step [27/735], Loss: 0.1480\n",
      "Epoch [30/50], Step [28/735], Loss: 0.1469\n",
      "Epoch [30/50], Step [29/735], Loss: 4.9580\n",
      "Epoch [30/50], Step [30/735], Loss: 0.1189\n",
      "Epoch [30/50], Step [31/735], Loss: 0.4090\n",
      "Epoch [30/50], Step [32/735], Loss: 0.5480\n",
      "Epoch [30/50], Step [33/735], Loss: 0.1159\n",
      "Epoch [30/50], Step [34/735], Loss: 0.3066\n",
      "Epoch [30/50], Step [35/735], Loss: 0.6209\n",
      "Epoch [30/50], Step [36/735], Loss: 0.1737\n",
      "Epoch [30/50], Step [37/735], Loss: 0.2515\n",
      "Epoch [30/50], Step [38/735], Loss: 0.0928\n",
      "Epoch [30/50], Step [39/735], Loss: 0.1674\n",
      "Epoch [30/50], Step [40/735], Loss: 0.1977\n",
      "Epoch [30/50], Step [41/735], Loss: 0.3998\n",
      "Epoch [30/50], Step [42/735], Loss: 0.0914\n",
      "Epoch [30/50], Step [43/735], Loss: 0.1691\n",
      "Epoch [30/50], Step [44/735], Loss: 0.1947\n",
      "Epoch [30/50], Step [45/735], Loss: 0.3008\n",
      "Epoch [30/50], Step [46/735], Loss: 1.4471\n",
      "Epoch [30/50], Step [47/735], Loss: 0.1105\n",
      "Epoch [30/50], Step [48/735], Loss: 0.5851\n",
      "Epoch [30/50], Step [49/735], Loss: 0.6608\n",
      "Epoch [30/50], Step [50/735], Loss: 0.5118\n",
      "Epoch [30/50], Step [51/735], Loss: 0.7722\n",
      "Epoch [30/50], Step [52/735], Loss: 0.2258\n",
      "Epoch [30/50], Step [53/735], Loss: 0.3606\n",
      "Epoch [30/50], Step [54/735], Loss: 0.6060\n",
      "Epoch [30/50], Step [55/735], Loss: 0.1610\n",
      "Epoch [30/50], Step [56/735], Loss: 0.3010\n",
      "Epoch [30/50], Step [57/735], Loss: 0.1561\n",
      "Epoch [30/50], Step [58/735], Loss: 0.4026\n",
      "Epoch [30/50], Step [59/735], Loss: 0.1261\n",
      "Epoch [30/50], Step [60/735], Loss: 0.1634\n",
      "Epoch [30/50], Step [61/735], Loss: 0.3155\n",
      "Epoch [30/50], Step [62/735], Loss: 1.0230\n",
      "Epoch [30/50], Step [63/735], Loss: 0.2908\n",
      "Epoch [30/50], Step [64/735], Loss: 0.5471\n",
      "Epoch [30/50], Step [65/735], Loss: 0.1513\n",
      "Epoch [30/50], Step [66/735], Loss: 0.5217\n",
      "Epoch [30/50], Step [67/735], Loss: 0.2202\n",
      "Epoch [30/50], Step [68/735], Loss: 0.6182\n",
      "Epoch [30/50], Step [69/735], Loss: 1.0226\n",
      "Epoch [30/50], Step [70/735], Loss: 0.1726\n",
      "Epoch [30/50], Step [71/735], Loss: 0.2957\n",
      "Epoch [30/50], Step [72/735], Loss: 0.1881\n",
      "Epoch [30/50], Step [73/735], Loss: 0.2226\n",
      "Epoch [30/50], Step [74/735], Loss: 0.3294\n",
      "Epoch [30/50], Step [75/735], Loss: 0.2805\n",
      "Epoch [30/50], Step [76/735], Loss: 0.1146\n",
      "Epoch [30/50], Step [77/735], Loss: 0.2413\n",
      "Epoch [30/50], Step [78/735], Loss: 0.2564\n",
      "Epoch [30/50], Step [79/735], Loss: 0.3679\n",
      "Epoch [30/50], Step [80/735], Loss: 0.3813\n",
      "Epoch [30/50], Step [81/735], Loss: 0.1028\n",
      "Epoch [30/50], Step [82/735], Loss: 0.0740\n",
      "Epoch [30/50], Step [83/735], Loss: 0.1185\n",
      "Epoch [30/50], Step [84/735], Loss: 0.4229\n",
      "Epoch [30/50], Step [85/735], Loss: 0.0673\n",
      "Epoch [30/50], Step [86/735], Loss: 0.3510\n",
      "Epoch [30/50], Step [87/735], Loss: 0.1495\n",
      "Epoch [30/50], Step [88/735], Loss: 0.3827\n",
      "Epoch [30/50], Step [89/735], Loss: 0.1624\n",
      "Epoch [30/50], Step [90/735], Loss: 0.0573\n",
      "Epoch [30/50], Step [91/735], Loss: 0.2595\n",
      "Epoch [30/50], Step [92/735], Loss: 0.1471\n",
      "Epoch [30/50], Step [93/735], Loss: 0.2064\n",
      "Epoch [30/50], Step [94/735], Loss: 0.2476\n",
      "Epoch [30/50], Step [95/735], Loss: 1.2234\n",
      "Epoch [30/50], Step [96/735], Loss: 0.5445\n",
      "Epoch [30/50], Step [97/735], Loss: 0.5012\n",
      "Epoch [30/50], Step [98/735], Loss: 0.2577\n",
      "Epoch [30/50], Step [99/735], Loss: 0.2217\n",
      "Epoch [30/50], Step [100/735], Loss: 0.4128\n",
      "Epoch [30/50], Step [101/735], Loss: 0.1110\n",
      "Epoch [30/50], Step [102/735], Loss: 0.2068\n",
      "Epoch [30/50], Step [103/735], Loss: 0.1249\n",
      "Epoch [30/50], Step [104/735], Loss: 0.0928\n",
      "Epoch [30/50], Step [105/735], Loss: 0.4722\n",
      "Epoch [30/50], Step [106/735], Loss: 0.1327\n",
      "Epoch [30/50], Step [107/735], Loss: 0.4455\n",
      "Epoch [30/50], Step [108/735], Loss: 1.0457\n",
      "Epoch [30/50], Step [109/735], Loss: 0.5145\n",
      "Epoch [30/50], Step [110/735], Loss: 0.6854\n",
      "Epoch [30/50], Step [111/735], Loss: 0.1842\n",
      "Epoch [30/50], Step [112/735], Loss: 0.3238\n",
      "Epoch [30/50], Step [113/735], Loss: 0.2240\n",
      "Epoch [30/50], Step [114/735], Loss: 0.0788\n",
      "Epoch [30/50], Step [115/735], Loss: 0.1682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Step [116/735], Loss: 0.1837\n",
      "Epoch [30/50], Step [117/735], Loss: 0.7756\n",
      "Epoch [30/50], Step [118/735], Loss: 0.0420\n",
      "Epoch [30/50], Step [119/735], Loss: 0.2645\n",
      "Epoch [30/50], Step [120/735], Loss: 0.2643\n",
      "Epoch [30/50], Step [121/735], Loss: 0.3602\n",
      "Epoch [30/50], Step [122/735], Loss: 0.2253\n",
      "Epoch [30/50], Step [123/735], Loss: 0.3318\n",
      "Epoch [30/50], Step [124/735], Loss: 0.9922\n",
      "Epoch [30/50], Step [125/735], Loss: 0.1512\n",
      "Epoch [30/50], Step [126/735], Loss: 0.1118\n",
      "Epoch [30/50], Step [127/735], Loss: 0.2753\n",
      "Epoch [30/50], Step [128/735], Loss: 0.0391\n",
      "Epoch [30/50], Step [129/735], Loss: 0.1613\n",
      "Epoch [30/50], Step [130/735], Loss: 0.0943\n",
      "Epoch [30/50], Step [131/735], Loss: 0.3045\n",
      "Epoch [30/50], Step [132/735], Loss: 0.3563\n",
      "Epoch [30/50], Step [133/735], Loss: 0.4515\n",
      "Epoch [30/50], Step [134/735], Loss: 0.2640\n",
      "Epoch [30/50], Step [135/735], Loss: 0.6690\n",
      "Epoch [30/50], Step [136/735], Loss: 0.9911\n",
      "Epoch [30/50], Step [137/735], Loss: 0.5168\n",
      "Epoch [30/50], Step [138/735], Loss: 0.2137\n",
      "Epoch [30/50], Step [139/735], Loss: 0.9093\n",
      "Epoch [30/50], Step [140/735], Loss: 0.1729\n",
      "Epoch [30/50], Step [141/735], Loss: 0.6465\n",
      "Epoch [30/50], Step [142/735], Loss: 0.6058\n",
      "Epoch [30/50], Step [143/735], Loss: 0.0642\n",
      "Epoch [30/50], Step [144/735], Loss: 0.2983\n",
      "Epoch [30/50], Step [145/735], Loss: 0.1961\n",
      "Epoch [30/50], Step [146/735], Loss: 0.5270\n",
      "Epoch [30/50], Step [147/735], Loss: 0.2897\n",
      "Epoch [30/50], Step [148/735], Loss: 0.6882\n",
      "Epoch [30/50], Step [149/735], Loss: 0.3278\n",
      "Epoch [30/50], Step [150/735], Loss: 0.3359\n",
      "Epoch [30/50], Step [151/735], Loss: 0.5422\n",
      "Epoch [30/50], Step [152/735], Loss: 0.2942\n",
      "Epoch [30/50], Step [153/735], Loss: 0.2029\n",
      "Epoch [30/50], Step [154/735], Loss: 0.1042\n",
      "Epoch [30/50], Step [155/735], Loss: 0.0957\n",
      "Epoch [30/50], Step [156/735], Loss: 0.8299\n",
      "Epoch [30/50], Step [157/735], Loss: 0.1456\n",
      "Epoch [30/50], Step [158/735], Loss: 0.1612\n",
      "Epoch [30/50], Step [159/735], Loss: 0.3070\n",
      "Epoch [30/50], Step [160/735], Loss: 0.1113\n",
      "Epoch [30/50], Step [161/735], Loss: 0.4504\n",
      "Epoch [30/50], Step [162/735], Loss: 0.4305\n",
      "Epoch [30/50], Step [163/735], Loss: 0.5452\n",
      "Epoch [30/50], Step [164/735], Loss: 0.7920\n",
      "Epoch [30/50], Step [165/735], Loss: 0.5899\n",
      "Epoch [30/50], Step [166/735], Loss: 0.1012\n",
      "Epoch [30/50], Step [167/735], Loss: 0.2237\n",
      "Epoch [30/50], Step [168/735], Loss: 0.2022\n",
      "Epoch [30/50], Step [169/735], Loss: 0.2240\n",
      "Epoch [30/50], Step [170/735], Loss: 1.1429\n",
      "Epoch [30/50], Step [171/735], Loss: 0.6834\n",
      "Epoch [30/50], Step [172/735], Loss: 0.2488\n",
      "Epoch [30/50], Step [173/735], Loss: 0.1897\n",
      "Epoch [30/50], Step [174/735], Loss: 0.8800\n",
      "Epoch [30/50], Step [175/735], Loss: 0.2231\n",
      "Epoch [30/50], Step [176/735], Loss: 0.2006\n",
      "Epoch [30/50], Step [177/735], Loss: 0.9499\n",
      "Epoch [30/50], Step [178/735], Loss: 0.2382\n",
      "Epoch [30/50], Step [179/735], Loss: 0.3322\n",
      "Epoch [30/50], Step [180/735], Loss: 0.1402\n",
      "Epoch [30/50], Step [181/735], Loss: 0.0748\n",
      "Epoch [30/50], Step [182/735], Loss: 0.4540\n",
      "Epoch [30/50], Step [183/735], Loss: 0.0507\n",
      "Epoch [30/50], Step [184/735], Loss: 0.1457\n",
      "Epoch [30/50], Step [185/735], Loss: 0.4398\n",
      "Epoch [30/50], Step [186/735], Loss: 0.2922\n",
      "Epoch [30/50], Step [187/735], Loss: 0.5699\n",
      "Epoch [30/50], Step [188/735], Loss: 0.0835\n",
      "Epoch [30/50], Step [189/735], Loss: 0.3595\n",
      "Epoch [30/50], Step [190/735], Loss: 0.2316\n",
      "Epoch [30/50], Step [191/735], Loss: 0.5778\n",
      "Epoch [30/50], Step [192/735], Loss: 0.3143\n",
      "Epoch [30/50], Step [193/735], Loss: 0.0721\n",
      "Epoch [30/50], Step [194/735], Loss: 0.2501\n",
      "Epoch [30/50], Step [195/735], Loss: 0.4563\n",
      "Epoch [30/50], Step [196/735], Loss: 0.1681\n",
      "Epoch [30/50], Step [197/735], Loss: 0.2829\n",
      "Epoch [30/50], Step [198/735], Loss: 0.5969\n",
      "Epoch [30/50], Step [199/735], Loss: 0.5962\n",
      "Epoch [30/50], Step [200/735], Loss: 0.1187\n",
      "Epoch [30/50], Step [201/735], Loss: 0.9587\n",
      "Epoch [30/50], Step [202/735], Loss: 0.1171\n",
      "Epoch [30/50], Step [203/735], Loss: 0.5296\n",
      "Epoch [30/50], Step [204/735], Loss: 0.4051\n",
      "Epoch [30/50], Step [205/735], Loss: 0.3579\n",
      "Epoch [30/50], Step [206/735], Loss: 0.2828\n",
      "Epoch [30/50], Step [207/735], Loss: 0.2317\n",
      "Epoch [30/50], Step [208/735], Loss: 0.2044\n",
      "Epoch [30/50], Step [209/735], Loss: 0.3687\n",
      "Epoch [30/50], Step [210/735], Loss: 0.1401\n",
      "Epoch [30/50], Step [211/735], Loss: 0.4908\n",
      "Epoch [30/50], Step [212/735], Loss: 0.1042\n",
      "Epoch [30/50], Step [213/735], Loss: 0.1207\n",
      "Epoch [30/50], Step [214/735], Loss: 0.3221\n",
      "Epoch [30/50], Step [215/735], Loss: 0.5696\n",
      "Epoch [30/50], Step [216/735], Loss: 0.0450\n",
      "Epoch [30/50], Step [217/735], Loss: 0.4197\n",
      "Epoch [30/50], Step [218/735], Loss: 0.2164\n",
      "Epoch [30/50], Step [219/735], Loss: 0.3692\n",
      "Epoch [30/50], Step [220/735], Loss: 0.6180\n",
      "Epoch [30/50], Step [221/735], Loss: 0.3084\n",
      "Epoch [30/50], Step [222/735], Loss: 0.6222\n",
      "Epoch [30/50], Step [223/735], Loss: 0.3153\n",
      "Epoch [30/50], Step [224/735], Loss: 1.1251\n",
      "Epoch [30/50], Step [225/735], Loss: 0.1875\n",
      "Epoch [30/50], Step [226/735], Loss: 0.1468\n",
      "Epoch [30/50], Step [227/735], Loss: 0.2832\n",
      "Epoch [30/50], Step [228/735], Loss: 0.2523\n",
      "Epoch [30/50], Step [229/735], Loss: 0.3071\n",
      "Epoch [30/50], Step [230/735], Loss: 0.2793\n",
      "Epoch [30/50], Step [231/735], Loss: 0.6880\n",
      "Epoch [30/50], Step [232/735], Loss: 0.3859\n",
      "Epoch [30/50], Step [233/735], Loss: 0.2377\n",
      "Epoch [30/50], Step [234/735], Loss: 0.4715\n",
      "Epoch [30/50], Step [235/735], Loss: 0.7092\n",
      "Epoch [30/50], Step [236/735], Loss: 0.2970\n",
      "Epoch [30/50], Step [237/735], Loss: 0.9098\n",
      "Epoch [30/50], Step [238/735], Loss: 1.2370\n",
      "Epoch [30/50], Step [239/735], Loss: 0.1335\n",
      "Epoch [30/50], Step [240/735], Loss: 0.1802\n",
      "Epoch [30/50], Step [241/735], Loss: 0.3817\n",
      "Epoch [30/50], Step [242/735], Loss: 0.2668\n",
      "Epoch [30/50], Step [243/735], Loss: 1.1564\n",
      "Epoch [30/50], Step [244/735], Loss: 0.3009\n",
      "Epoch [30/50], Step [245/735], Loss: 0.1802\n",
      "Epoch [30/50], Step [246/735], Loss: 0.4112\n",
      "Epoch [30/50], Step [247/735], Loss: 0.3911\n",
      "Epoch [30/50], Step [248/735], Loss: 0.0991\n",
      "Epoch [30/50], Step [249/735], Loss: 0.3537\n",
      "Epoch [30/50], Step [250/735], Loss: 0.1851\n",
      "Epoch [30/50], Step [251/735], Loss: 0.5002\n",
      "Epoch [30/50], Step [252/735], Loss: 0.6642\n",
      "Epoch [30/50], Step [253/735], Loss: 0.6290\n",
      "Epoch [30/50], Step [254/735], Loss: 0.1628\n",
      "Epoch [30/50], Step [255/735], Loss: 0.3676\n",
      "Epoch [30/50], Step [256/735], Loss: 0.4339\n",
      "Epoch [30/50], Step [257/735], Loss: 0.3086\n",
      "Epoch [30/50], Step [258/735], Loss: 0.3167\n",
      "Epoch [30/50], Step [259/735], Loss: 0.7909\n",
      "Epoch [30/50], Step [260/735], Loss: 0.3141\n",
      "Epoch [30/50], Step [261/735], Loss: 0.2538\n",
      "Epoch [30/50], Step [262/735], Loss: 0.3121\n",
      "Epoch [30/50], Step [263/735], Loss: 0.1837\n",
      "Epoch [30/50], Step [264/735], Loss: 0.1265\n",
      "Epoch [30/50], Step [265/735], Loss: 0.2995\n",
      "Epoch [30/50], Step [266/735], Loss: 0.1558\n",
      "Epoch [30/50], Step [267/735], Loss: 0.4228\n",
      "Epoch [30/50], Step [268/735], Loss: 0.1804\n",
      "Epoch [30/50], Step [269/735], Loss: 0.0415\n",
      "Epoch [30/50], Step [270/735], Loss: 0.2875\n",
      "Epoch [30/50], Step [271/735], Loss: 0.4585\n",
      "Epoch [30/50], Step [272/735], Loss: 0.0682\n",
      "Epoch [30/50], Step [273/735], Loss: 0.1636\n",
      "Epoch [30/50], Step [274/735], Loss: 0.1650\n",
      "Epoch [30/50], Step [275/735], Loss: 0.6025\n",
      "Epoch [30/50], Step [276/735], Loss: 0.1757\n",
      "Epoch [30/50], Step [277/735], Loss: 0.9370\n",
      "Epoch [30/50], Step [278/735], Loss: 0.2435\n",
      "Epoch [30/50], Step [279/735], Loss: 0.1918\n",
      "Epoch [30/50], Step [280/735], Loss: 0.0700\n",
      "Epoch [30/50], Step [281/735], Loss: 0.2300\n",
      "Epoch [30/50], Step [282/735], Loss: 0.4542\n",
      "Epoch [30/50], Step [283/735], Loss: 1.1684\n",
      "Epoch [30/50], Step [284/735], Loss: 0.2828\n",
      "Epoch [30/50], Step [285/735], Loss: 0.1319\n",
      "Epoch [30/50], Step [286/735], Loss: 0.1815\n",
      "Epoch [30/50], Step [287/735], Loss: 0.2177\n",
      "Epoch [30/50], Step [288/735], Loss: 0.0254\n",
      "Epoch [30/50], Step [289/735], Loss: 0.1884\n",
      "Epoch [30/50], Step [290/735], Loss: 0.2466\n",
      "Epoch [30/50], Step [291/735], Loss: 0.8473\n",
      "Epoch [30/50], Step [292/735], Loss: 0.1409\n",
      "Epoch [30/50], Step [293/735], Loss: 0.3201\n",
      "Epoch [30/50], Step [294/735], Loss: 0.2313\n",
      "Epoch [30/50], Step [295/735], Loss: 0.2697\n",
      "Epoch [30/50], Step [296/735], Loss: 0.1227\n",
      "Epoch [30/50], Step [297/735], Loss: 0.3990\n",
      "Epoch [30/50], Step [298/735], Loss: 0.2108\n",
      "Epoch [30/50], Step [299/735], Loss: 0.2533\n",
      "Epoch [30/50], Step [300/735], Loss: 0.3525\n",
      "Epoch [30/50], Step [301/735], Loss: 0.3781\n",
      "Epoch [30/50], Step [302/735], Loss: 0.2040\n",
      "Epoch [30/50], Step [303/735], Loss: 0.4832\n",
      "Epoch [30/50], Step [304/735], Loss: 0.1753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Step [305/735], Loss: 0.2754\n",
      "Epoch [30/50], Step [306/735], Loss: 0.2455\n",
      "Epoch [30/50], Step [307/735], Loss: 0.2810\n",
      "Epoch [30/50], Step [308/735], Loss: 0.1983\n",
      "Epoch [30/50], Step [309/735], Loss: 0.9368\n",
      "Epoch [30/50], Step [310/735], Loss: 0.3036\n",
      "Epoch [30/50], Step [311/735], Loss: 0.2769\n",
      "Epoch [30/50], Step [312/735], Loss: 0.6514\n",
      "Epoch [30/50], Step [313/735], Loss: 0.1193\n",
      "Epoch [30/50], Step [314/735], Loss: 0.4361\n",
      "Epoch [30/50], Step [315/735], Loss: 0.3330\n",
      "Epoch [30/50], Step [316/735], Loss: 0.0715\n",
      "Epoch [30/50], Step [317/735], Loss: 0.1469\n",
      "Epoch [30/50], Step [318/735], Loss: 0.1203\n",
      "Epoch [30/50], Step [319/735], Loss: 0.3577\n",
      "Epoch [30/50], Step [320/735], Loss: 0.2130\n",
      "Epoch [30/50], Step [321/735], Loss: 0.5540\n",
      "Epoch [30/50], Step [322/735], Loss: 0.3845\n",
      "Epoch [30/50], Step [323/735], Loss: 0.3156\n",
      "Epoch [30/50], Step [324/735], Loss: 0.4975\n",
      "Epoch [30/50], Step [325/735], Loss: 0.2233\n",
      "Epoch [30/50], Step [326/735], Loss: 0.1847\n",
      "Epoch [30/50], Step [327/735], Loss: 0.2443\n",
      "Epoch [30/50], Step [328/735], Loss: 0.2175\n",
      "Epoch [30/50], Step [329/735], Loss: 0.1135\n",
      "Epoch [30/50], Step [330/735], Loss: 0.5860\n",
      "Epoch [30/50], Step [331/735], Loss: 5.2104\n",
      "Epoch [30/50], Step [332/735], Loss: 0.1829\n",
      "Epoch [30/50], Step [333/735], Loss: 0.1092\n",
      "Epoch [30/50], Step [334/735], Loss: 0.2121\n",
      "Epoch [30/50], Step [335/735], Loss: 0.5077\n",
      "Epoch [30/50], Step [336/735], Loss: 0.1419\n",
      "Epoch [30/50], Step [337/735], Loss: 0.4315\n",
      "Epoch [30/50], Step [338/735], Loss: 0.2990\n",
      "Epoch [30/50], Step [339/735], Loss: 0.2765\n",
      "Epoch [30/50], Step [340/735], Loss: 0.9177\n",
      "Epoch [30/50], Step [341/735], Loss: 1.5052\n",
      "Epoch [30/50], Step [342/735], Loss: 0.1613\n",
      "Epoch [30/50], Step [343/735], Loss: 0.1965\n",
      "Epoch [30/50], Step [344/735], Loss: 0.4924\n",
      "Epoch [30/50], Step [345/735], Loss: 0.3639\n",
      "Epoch [30/50], Step [346/735], Loss: 0.3904\n",
      "Epoch [30/50], Step [347/735], Loss: 0.3833\n",
      "Epoch [30/50], Step [348/735], Loss: 0.4228\n",
      "Epoch [30/50], Step [349/735], Loss: 0.2645\n",
      "Epoch [30/50], Step [350/735], Loss: 0.5321\n",
      "Epoch [30/50], Step [351/735], Loss: 1.0280\n",
      "Epoch [30/50], Step [352/735], Loss: 0.1548\n",
      "Epoch [30/50], Step [353/735], Loss: 0.8721\n",
      "Epoch [30/50], Step [354/735], Loss: 0.3485\n",
      "Epoch [30/50], Step [355/735], Loss: 0.7220\n",
      "Epoch [30/50], Step [356/735], Loss: 0.2105\n",
      "Epoch [30/50], Step [357/735], Loss: 0.1910\n",
      "Epoch [30/50], Step [358/735], Loss: 0.1270\n",
      "Epoch [30/50], Step [359/735], Loss: 0.3060\n",
      "Epoch [30/50], Step [360/735], Loss: 0.4479\n",
      "Epoch [30/50], Step [361/735], Loss: 0.2204\n",
      "Epoch [30/50], Step [362/735], Loss: 0.1629\n",
      "Epoch [30/50], Step [363/735], Loss: 0.5487\n",
      "Epoch [30/50], Step [364/735], Loss: 0.4924\n",
      "Epoch [30/50], Step [365/735], Loss: 0.1137\n",
      "Epoch [30/50], Step [366/735], Loss: 0.2861\n",
      "Epoch [30/50], Step [367/735], Loss: 0.9392\n",
      "Epoch [30/50], Step [368/735], Loss: 0.4443\n",
      "Epoch [30/50], Step [369/735], Loss: 0.1182\n",
      "Epoch [30/50], Step [370/735], Loss: 0.6157\n",
      "Epoch [30/50], Step [371/735], Loss: 0.2985\n",
      "Epoch [30/50], Step [372/735], Loss: 0.1779\n",
      "Epoch [30/50], Step [373/735], Loss: 0.6936\n",
      "Epoch [30/50], Step [374/735], Loss: 0.2287\n",
      "Epoch [30/50], Step [375/735], Loss: 0.2205\n",
      "Epoch [30/50], Step [376/735], Loss: 0.1493\n",
      "Epoch [30/50], Step [377/735], Loss: 0.2690\n",
      "Epoch [30/50], Step [378/735], Loss: 0.4038\n",
      "Epoch [30/50], Step [379/735], Loss: 0.2426\n",
      "Epoch [30/50], Step [380/735], Loss: 0.3075\n",
      "Epoch [30/50], Step [381/735], Loss: 0.1137\n",
      "Epoch [30/50], Step [382/735], Loss: 0.1630\n",
      "Epoch [30/50], Step [383/735], Loss: 0.2459\n",
      "Epoch [30/50], Step [384/735], Loss: 0.2189\n",
      "Epoch [30/50], Step [385/735], Loss: 0.3210\n",
      "Epoch [30/50], Step [386/735], Loss: 0.1981\n",
      "Epoch [30/50], Step [387/735], Loss: 0.1836\n",
      "Epoch [30/50], Step [388/735], Loss: 0.1310\n",
      "Epoch [30/50], Step [389/735], Loss: 1.0483\n",
      "Epoch [30/50], Step [390/735], Loss: 0.4623\n",
      "Epoch [30/50], Step [391/735], Loss: 0.1364\n",
      "Epoch [30/50], Step [392/735], Loss: 0.3401\n",
      "Epoch [30/50], Step [393/735], Loss: 0.7725\n",
      "Epoch [30/50], Step [394/735], Loss: 0.1662\n",
      "Epoch [30/50], Step [395/735], Loss: 0.3074\n",
      "Epoch [30/50], Step [396/735], Loss: 0.3742\n",
      "Epoch [30/50], Step [397/735], Loss: 0.3834\n",
      "Epoch [30/50], Step [398/735], Loss: 0.2639\n",
      "Epoch [30/50], Step [399/735], Loss: 0.3768\n",
      "Epoch [30/50], Step [400/735], Loss: 1.3186\n",
      "Epoch [30/50], Step [401/735], Loss: 0.5464\n",
      "Epoch [30/50], Step [402/735], Loss: 0.2535\n",
      "Epoch [30/50], Step [403/735], Loss: 0.1084\n",
      "Epoch [30/50], Step [404/735], Loss: 0.3336\n",
      "Epoch [30/50], Step [405/735], Loss: 0.5080\n",
      "Epoch [30/50], Step [406/735], Loss: 0.1669\n",
      "Epoch [30/50], Step [407/735], Loss: 0.2516\n",
      "Epoch [30/50], Step [408/735], Loss: 1.7440\n",
      "Epoch [30/50], Step [409/735], Loss: 0.1790\n",
      "Epoch [30/50], Step [410/735], Loss: 0.3919\n",
      "Epoch [30/50], Step [411/735], Loss: 0.4330\n",
      "Epoch [30/50], Step [412/735], Loss: 0.1883\n",
      "Epoch [30/50], Step [413/735], Loss: 0.8187\n",
      "Epoch [30/50], Step [414/735], Loss: 0.5514\n",
      "Epoch [30/50], Step [415/735], Loss: 0.2867\n",
      "Epoch [30/50], Step [416/735], Loss: 0.1633\n",
      "Epoch [30/50], Step [417/735], Loss: 0.0379\n",
      "Epoch [30/50], Step [418/735], Loss: 0.0535\n",
      "Epoch [30/50], Step [419/735], Loss: 0.2733\n",
      "Epoch [30/50], Step [420/735], Loss: 0.3039\n",
      "Epoch [30/50], Step [421/735], Loss: 0.4390\n",
      "Epoch [30/50], Step [422/735], Loss: 0.1993\n",
      "Epoch [30/50], Step [423/735], Loss: 0.4553\n",
      "Epoch [30/50], Step [424/735], Loss: 0.1833\n",
      "Epoch [30/50], Step [425/735], Loss: 0.4761\n",
      "Epoch [30/50], Step [426/735], Loss: 0.5335\n",
      "Epoch [30/50], Step [427/735], Loss: 0.3571\n",
      "Epoch [30/50], Step [428/735], Loss: 0.5030\n",
      "Epoch [30/50], Step [429/735], Loss: 0.0869\n",
      "Epoch [30/50], Step [430/735], Loss: 0.2474\n",
      "Epoch [30/50], Step [431/735], Loss: 0.5318\n",
      "Epoch [30/50], Step [432/735], Loss: 0.1331\n",
      "Epoch [30/50], Step [433/735], Loss: 0.2440\n",
      "Epoch [30/50], Step [434/735], Loss: 0.1992\n",
      "Epoch [30/50], Step [435/735], Loss: 0.1326\n",
      "Epoch [30/50], Step [436/735], Loss: 0.3948\n",
      "Epoch [30/50], Step [437/735], Loss: 0.0678\n",
      "Epoch [30/50], Step [438/735], Loss: 0.3339\n",
      "Epoch [30/50], Step [439/735], Loss: 0.1697\n",
      "Epoch [30/50], Step [440/735], Loss: 0.5785\n",
      "Epoch [30/50], Step [441/735], Loss: 0.9587\n",
      "Epoch [30/50], Step [442/735], Loss: 0.1573\n",
      "Epoch [30/50], Step [443/735], Loss: 0.4823\n",
      "Epoch [30/50], Step [444/735], Loss: 0.4738\n",
      "Epoch [30/50], Step [445/735], Loss: 0.6253\n",
      "Epoch [30/50], Step [446/735], Loss: 0.1750\n",
      "Epoch [30/50], Step [447/735], Loss: 0.1762\n",
      "Epoch [30/50], Step [448/735], Loss: 0.4156\n",
      "Epoch [30/50], Step [449/735], Loss: 0.4553\n",
      "Epoch [30/50], Step [450/735], Loss: 0.2592\n",
      "Epoch [30/50], Step [451/735], Loss: 0.2022\n",
      "Epoch [30/50], Step [452/735], Loss: 0.5145\n",
      "Epoch [30/50], Step [453/735], Loss: 0.3337\n",
      "Epoch [30/50], Step [454/735], Loss: 0.2031\n",
      "Epoch [30/50], Step [455/735], Loss: 0.2718\n",
      "Epoch [30/50], Step [456/735], Loss: 0.2735\n",
      "Epoch [30/50], Step [457/735], Loss: 0.4164\n",
      "Epoch [30/50], Step [458/735], Loss: 0.2997\n",
      "Epoch [30/50], Step [459/735], Loss: 0.4661\n",
      "Epoch [30/50], Step [460/735], Loss: 0.1501\n",
      "Epoch [30/50], Step [461/735], Loss: 0.2597\n",
      "Epoch [30/50], Step [462/735], Loss: 0.5971\n",
      "Epoch [30/50], Step [463/735], Loss: 0.2594\n",
      "Epoch [30/50], Step [464/735], Loss: 1.2552\n",
      "Epoch [30/50], Step [465/735], Loss: 0.2118\n",
      "Epoch [30/50], Step [466/735], Loss: 0.3481\n",
      "Epoch [30/50], Step [467/735], Loss: 1.0992\n",
      "Epoch [30/50], Step [468/735], Loss: 0.2811\n",
      "Epoch [30/50], Step [469/735], Loss: 0.2305\n",
      "Epoch [30/50], Step [470/735], Loss: 0.7032\n",
      "Epoch [30/50], Step [471/735], Loss: 0.0732\n",
      "Epoch [30/50], Step [472/735], Loss: 0.1165\n",
      "Epoch [30/50], Step [473/735], Loss: 0.0896\n",
      "Epoch [30/50], Step [474/735], Loss: 0.4193\n",
      "Epoch [30/50], Step [475/735], Loss: 0.1249\n",
      "Epoch [30/50], Step [476/735], Loss: 0.3887\n",
      "Epoch [30/50], Step [477/735], Loss: 0.1792\n",
      "Epoch [30/50], Step [478/735], Loss: 0.2207\n",
      "Epoch [30/50], Step [479/735], Loss: 0.0991\n",
      "Epoch [30/50], Step [480/735], Loss: 0.5520\n",
      "Epoch [30/50], Step [481/735], Loss: 0.3648\n",
      "Epoch [30/50], Step [482/735], Loss: 0.1871\n",
      "Epoch [30/50], Step [483/735], Loss: 0.7746\n",
      "Epoch [30/50], Step [484/735], Loss: 0.1830\n",
      "Epoch [30/50], Step [485/735], Loss: 0.7544\n",
      "Epoch [30/50], Step [486/735], Loss: 0.1240\n",
      "Epoch [30/50], Step [487/735], Loss: 0.1477\n",
      "Epoch [30/50], Step [488/735], Loss: 0.1646\n",
      "Epoch [30/50], Step [489/735], Loss: 0.1820\n",
      "Epoch [30/50], Step [490/735], Loss: 0.2021\n",
      "Epoch [30/50], Step [491/735], Loss: 0.1397\n",
      "Epoch [30/50], Step [492/735], Loss: 2.0111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Step [493/735], Loss: 0.4058\n",
      "Epoch [30/50], Step [494/735], Loss: 0.2463\n",
      "Epoch [30/50], Step [495/735], Loss: 0.1599\n",
      "Epoch [30/50], Step [496/735], Loss: 0.2803\n",
      "Epoch [30/50], Step [497/735], Loss: 0.1007\n",
      "Epoch [30/50], Step [498/735], Loss: 0.4237\n",
      "Epoch [30/50], Step [499/735], Loss: 0.1190\n",
      "Epoch [30/50], Step [500/735], Loss: 0.3553\n",
      "Epoch [30/50], Step [501/735], Loss: 0.1874\n",
      "Epoch [30/50], Step [502/735], Loss: 0.2246\n",
      "Epoch [30/50], Step [503/735], Loss: 1.1476\n",
      "Epoch [30/50], Step [504/735], Loss: 0.1580\n",
      "Epoch [30/50], Step [505/735], Loss: 0.0527\n",
      "Epoch [30/50], Step [506/735], Loss: 0.1271\n",
      "Epoch [30/50], Step [507/735], Loss: 0.3914\n",
      "Epoch [30/50], Step [508/735], Loss: 0.1077\n",
      "Epoch [30/50], Step [509/735], Loss: 0.3894\n",
      "Epoch [30/50], Step [510/735], Loss: 0.0788\n",
      "Epoch [30/50], Step [511/735], Loss: 0.5861\n",
      "Epoch [30/50], Step [512/735], Loss: 0.1312\n",
      "Epoch [30/50], Step [513/735], Loss: 0.4345\n",
      "Epoch [30/50], Step [514/735], Loss: 0.2094\n",
      "Epoch [30/50], Step [515/735], Loss: 0.1770\n",
      "Epoch [30/50], Step [516/735], Loss: 0.4414\n",
      "Epoch [30/50], Step [517/735], Loss: 0.4949\n",
      "Epoch [30/50], Step [518/735], Loss: 0.1727\n",
      "Epoch [30/50], Step [519/735], Loss: 0.3209\n",
      "Epoch [30/50], Step [520/735], Loss: 0.5257\n",
      "Epoch [30/50], Step [521/735], Loss: 0.2077\n",
      "Epoch [30/50], Step [522/735], Loss: 0.3025\n",
      "Epoch [30/50], Step [523/735], Loss: 0.2167\n",
      "Epoch [30/50], Step [524/735], Loss: 0.6011\n",
      "Epoch [30/50], Step [525/735], Loss: 0.6728\n",
      "Epoch [30/50], Step [526/735], Loss: 0.2482\n",
      "Epoch [30/50], Step [527/735], Loss: 1.2531\n",
      "Epoch [30/50], Step [528/735], Loss: 0.4905\n",
      "Epoch [30/50], Step [529/735], Loss: 0.0939\n",
      "Epoch [30/50], Step [530/735], Loss: 0.2749\n",
      "Epoch [30/50], Step [531/735], Loss: 0.9453\n",
      "Epoch [30/50], Step [532/735], Loss: 0.4733\n",
      "Epoch [30/50], Step [533/735], Loss: 0.0740\n",
      "Epoch [30/50], Step [534/735], Loss: 0.1731\n",
      "Epoch [30/50], Step [535/735], Loss: 0.1562\n",
      "Epoch [30/50], Step [536/735], Loss: 0.2761\n",
      "Epoch [30/50], Step [537/735], Loss: 0.1525\n",
      "Epoch [30/50], Step [538/735], Loss: 0.2655\n",
      "Epoch [30/50], Step [539/735], Loss: 0.1375\n",
      "Epoch [30/50], Step [540/735], Loss: 0.8349\n",
      "Epoch [30/50], Step [541/735], Loss: 1.2979\n",
      "Epoch [30/50], Step [542/735], Loss: 0.1226\n",
      "Epoch [30/50], Step [543/735], Loss: 0.2303\n",
      "Epoch [30/50], Step [544/735], Loss: 0.6851\n",
      "Epoch [30/50], Step [545/735], Loss: 0.3435\n",
      "Epoch [30/50], Step [546/735], Loss: 0.4508\n",
      "Epoch [30/50], Step [547/735], Loss: 0.0752\n",
      "Epoch [30/50], Step [548/735], Loss: 0.2382\n",
      "Epoch [30/50], Step [549/735], Loss: 0.4126\n",
      "Epoch [30/50], Step [550/735], Loss: 0.2204\n",
      "Epoch [30/50], Step [551/735], Loss: 0.5189\n",
      "Epoch [30/50], Step [552/735], Loss: 0.2246\n",
      "Epoch [30/50], Step [553/735], Loss: 0.3255\n",
      "Epoch [30/50], Step [554/735], Loss: 0.2054\n",
      "Epoch [30/50], Step [555/735], Loss: 0.1490\n",
      "Epoch [30/50], Step [556/735], Loss: 0.4204\n",
      "Epoch [30/50], Step [557/735], Loss: 0.2520\n",
      "Epoch [30/50], Step [558/735], Loss: 0.2416\n",
      "Epoch [30/50], Step [559/735], Loss: 0.2071\n",
      "Epoch [30/50], Step [560/735], Loss: 0.4099\n",
      "Epoch [30/50], Step [561/735], Loss: 0.3258\n",
      "Epoch [30/50], Step [562/735], Loss: 0.6978\n",
      "Epoch [30/50], Step [563/735], Loss: 0.3128\n",
      "Epoch [30/50], Step [564/735], Loss: 0.3878\n",
      "Epoch [30/50], Step [565/735], Loss: 0.2761\n",
      "Epoch [30/50], Step [566/735], Loss: 0.4092\n",
      "Epoch [30/50], Step [567/735], Loss: 0.4854\n",
      "Epoch [30/50], Step [568/735], Loss: 0.2780\n",
      "Epoch [30/50], Step [569/735], Loss: 0.8681\n",
      "Epoch [30/50], Step [570/735], Loss: 0.0985\n",
      "Epoch [30/50], Step [571/735], Loss: 0.6721\n",
      "Epoch [30/50], Step [572/735], Loss: 0.8150\n",
      "Epoch [30/50], Step [573/735], Loss: 0.2489\n",
      "Epoch [30/50], Step [574/735], Loss: 0.4138\n",
      "Epoch [30/50], Step [575/735], Loss: 0.4374\n",
      "Epoch [30/50], Step [576/735], Loss: 0.3726\n",
      "Epoch [30/50], Step [577/735], Loss: 0.2457\n",
      "Epoch [30/50], Step [578/735], Loss: 0.5149\n",
      "Epoch [30/50], Step [579/735], Loss: 0.4695\n",
      "Epoch [30/50], Step [580/735], Loss: 0.1515\n",
      "Epoch [30/50], Step [581/735], Loss: 1.1582\n",
      "Epoch [30/50], Step [582/735], Loss: 0.4839\n",
      "Epoch [30/50], Step [583/735], Loss: 0.1199\n",
      "Epoch [30/50], Step [584/735], Loss: 0.1489\n",
      "Epoch [30/50], Step [585/735], Loss: 4.3502\n",
      "Epoch [30/50], Step [586/735], Loss: 0.1828\n",
      "Epoch [30/50], Step [587/735], Loss: 0.1374\n",
      "Epoch [30/50], Step [588/735], Loss: 0.1905\n",
      "Epoch [30/50], Step [589/735], Loss: 0.4961\n",
      "Epoch [30/50], Step [590/735], Loss: 0.4518\n",
      "Epoch [30/50], Step [591/735], Loss: 0.2329\n",
      "Epoch [30/50], Step [592/735], Loss: 0.1056\n",
      "Epoch [30/50], Step [593/735], Loss: 0.2061\n",
      "Epoch [30/50], Step [594/735], Loss: 0.2075\n",
      "Epoch [30/50], Step [595/735], Loss: 0.7536\n",
      "Epoch [30/50], Step [596/735], Loss: 0.2465\n",
      "Epoch [30/50], Step [597/735], Loss: 0.0954\n",
      "Epoch [30/50], Step [598/735], Loss: 0.5437\n",
      "Epoch [30/50], Step [599/735], Loss: 1.0274\n",
      "Epoch [30/50], Step [600/735], Loss: 0.1539\n",
      "Epoch [30/50], Step [601/735], Loss: 0.2710\n",
      "Epoch [30/50], Step [602/735], Loss: 0.4509\n",
      "Epoch [30/50], Step [603/735], Loss: 0.2764\n",
      "Epoch [30/50], Step [604/735], Loss: 0.4452\n",
      "Epoch [30/50], Step [605/735], Loss: 0.4631\n",
      "Epoch [30/50], Step [606/735], Loss: 0.8628\n",
      "Epoch [30/50], Step [607/735], Loss: 0.3513\n",
      "Epoch [30/50], Step [608/735], Loss: 0.4783\n",
      "Epoch [30/50], Step [609/735], Loss: 0.0803\n",
      "Epoch [30/50], Step [610/735], Loss: 0.3308\n",
      "Epoch [30/50], Step [611/735], Loss: 0.3086\n",
      "Epoch [30/50], Step [612/735], Loss: 0.4706\n",
      "Epoch [30/50], Step [613/735], Loss: 0.5237\n",
      "Epoch [30/50], Step [614/735], Loss: 0.3938\n",
      "Epoch [30/50], Step [615/735], Loss: 0.3285\n",
      "Epoch [30/50], Step [616/735], Loss: 0.9267\n",
      "Epoch [30/50], Step [617/735], Loss: 4.3059\n",
      "Epoch [30/50], Step [618/735], Loss: 0.4197\n",
      "Epoch [30/50], Step [619/735], Loss: 0.1996\n",
      "Epoch [30/50], Step [620/735], Loss: 1.0975\n",
      "Epoch [30/50], Step [621/735], Loss: 0.3286\n",
      "Epoch [30/50], Step [622/735], Loss: 0.2521\n",
      "Epoch [30/50], Step [623/735], Loss: 0.3031\n",
      "Epoch [30/50], Step [624/735], Loss: 0.2398\n",
      "Epoch [30/50], Step [625/735], Loss: 0.1297\n",
      "Epoch [30/50], Step [626/735], Loss: 0.2109\n",
      "Epoch [30/50], Step [627/735], Loss: 3.6778\n",
      "Epoch [30/50], Step [628/735], Loss: 0.4053\n",
      "Epoch [30/50], Step [629/735], Loss: 0.2939\n",
      "Epoch [30/50], Step [630/735], Loss: 0.3709\n",
      "Epoch [30/50], Step [631/735], Loss: 0.2621\n",
      "Epoch [30/50], Step [632/735], Loss: 1.2824\n",
      "Epoch [30/50], Step [633/735], Loss: 0.4863\n",
      "Epoch [30/50], Step [634/735], Loss: 0.4792\n",
      "Epoch [30/50], Step [635/735], Loss: 0.2056\n",
      "Epoch [30/50], Step [636/735], Loss: 0.4216\n",
      "Epoch [30/50], Step [637/735], Loss: 0.1404\n",
      "Epoch [30/50], Step [638/735], Loss: 0.0817\n",
      "Epoch [30/50], Step [639/735], Loss: 0.0854\n",
      "Epoch [30/50], Step [640/735], Loss: 0.4232\n",
      "Epoch [30/50], Step [641/735], Loss: 0.3380\n",
      "Epoch [30/50], Step [642/735], Loss: 0.4164\n",
      "Epoch [30/50], Step [643/735], Loss: 0.4232\n",
      "Epoch [30/50], Step [644/735], Loss: 0.4726\n",
      "Epoch [30/50], Step [645/735], Loss: 0.9033\n",
      "Epoch [30/50], Step [646/735], Loss: 0.2435\n",
      "Epoch [30/50], Step [647/735], Loss: 0.3064\n",
      "Epoch [30/50], Step [648/735], Loss: 0.1814\n",
      "Epoch [30/50], Step [649/735], Loss: 0.1526\n",
      "Epoch [30/50], Step [650/735], Loss: 0.2429\n",
      "Epoch [30/50], Step [651/735], Loss: 1.0820\n",
      "Epoch [30/50], Step [652/735], Loss: 0.1159\n",
      "Epoch [30/50], Step [653/735], Loss: 0.0635\n",
      "Epoch [30/50], Step [654/735], Loss: 0.1253\n",
      "Epoch [30/50], Step [655/735], Loss: 0.2475\n",
      "Epoch [30/50], Step [656/735], Loss: 0.0885\n",
      "Epoch [30/50], Step [657/735], Loss: 0.1440\n",
      "Epoch [30/50], Step [658/735], Loss: 0.2452\n",
      "Epoch [30/50], Step [659/735], Loss: 0.2360\n",
      "Epoch [30/50], Step [660/735], Loss: 0.1872\n",
      "Epoch [30/50], Step [661/735], Loss: 0.1155\n",
      "Epoch [30/50], Step [662/735], Loss: 0.2287\n",
      "Epoch [30/50], Step [663/735], Loss: 0.1264\n",
      "Epoch [30/50], Step [664/735], Loss: 1.0088\n",
      "Epoch [30/50], Step [665/735], Loss: 0.1076\n",
      "Epoch [30/50], Step [666/735], Loss: 0.7292\n",
      "Epoch [30/50], Step [667/735], Loss: 0.1684\n",
      "Epoch [30/50], Step [668/735], Loss: 0.2845\n",
      "Epoch [30/50], Step [669/735], Loss: 0.1095\n",
      "Epoch [30/50], Step [670/735], Loss: 0.2079\n",
      "Epoch [30/50], Step [671/735], Loss: 0.3876\n",
      "Epoch [30/50], Step [672/735], Loss: 1.3047\n",
      "Epoch [30/50], Step [673/735], Loss: 0.1437\n",
      "Epoch [30/50], Step [674/735], Loss: 0.1038\n",
      "Epoch [30/50], Step [675/735], Loss: 0.6307\n",
      "Epoch [30/50], Step [676/735], Loss: 0.0546\n",
      "Epoch [30/50], Step [677/735], Loss: 0.4656\n",
      "Epoch [30/50], Step [678/735], Loss: 0.1599\n",
      "Epoch [30/50], Step [679/735], Loss: 0.6771\n",
      "Epoch [30/50], Step [680/735], Loss: 0.2289\n",
      "Epoch [30/50], Step [681/735], Loss: 0.1967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Step [682/735], Loss: 0.5938\n",
      "Epoch [30/50], Step [683/735], Loss: 0.0552\n",
      "Epoch [30/50], Step [684/735], Loss: 0.1251\n",
      "Epoch [30/50], Step [685/735], Loss: 0.2747\n",
      "Epoch [30/50], Step [686/735], Loss: 0.3056\n",
      "Epoch [30/50], Step [687/735], Loss: 0.6661\n",
      "Epoch [30/50], Step [688/735], Loss: 0.1248\n",
      "Epoch [30/50], Step [689/735], Loss: 0.1970\n",
      "Epoch [30/50], Step [690/735], Loss: 0.2143\n",
      "Epoch [30/50], Step [691/735], Loss: 0.1960\n",
      "Epoch [30/50], Step [692/735], Loss: 0.7369\n",
      "Epoch [30/50], Step [693/735], Loss: 1.0252\n",
      "Epoch [30/50], Step [694/735], Loss: 0.0986\n",
      "Epoch [30/50], Step [695/735], Loss: 0.1373\n",
      "Epoch [30/50], Step [696/735], Loss: 0.1594\n",
      "Epoch [30/50], Step [697/735], Loss: 0.4788\n",
      "Epoch [30/50], Step [698/735], Loss: 0.3802\n",
      "Epoch [30/50], Step [699/735], Loss: 0.1498\n",
      "Epoch [30/50], Step [700/735], Loss: 0.2058\n",
      "Epoch [30/50], Step [701/735], Loss: 0.1410\n",
      "Epoch [30/50], Step [702/735], Loss: 0.3079\n",
      "Epoch [30/50], Step [703/735], Loss: 0.1341\n",
      "Epoch [30/50], Step [704/735], Loss: 0.4823\n",
      "Epoch [30/50], Step [705/735], Loss: 0.1416\n",
      "Epoch [30/50], Step [706/735], Loss: 0.7534\n",
      "Epoch [30/50], Step [707/735], Loss: 0.1732\n",
      "Epoch [30/50], Step [708/735], Loss: 0.3147\n",
      "Epoch [30/50], Step [709/735], Loss: 0.1934\n",
      "Epoch [30/50], Step [710/735], Loss: 0.0750\n",
      "Epoch [30/50], Step [711/735], Loss: 1.8035\n",
      "Epoch [30/50], Step [712/735], Loss: 0.2713\n",
      "Epoch [30/50], Step [713/735], Loss: 0.2035\n",
      "Epoch [30/50], Step [714/735], Loss: 0.3474\n",
      "Epoch [30/50], Step [715/735], Loss: 0.4492\n",
      "Epoch [30/50], Step [716/735], Loss: 0.3766\n",
      "Epoch [30/50], Step [717/735], Loss: 0.2502\n",
      "Epoch [30/50], Step [718/735], Loss: 0.5314\n",
      "Epoch [30/50], Step [719/735], Loss: 0.9606\n",
      "Epoch [30/50], Step [720/735], Loss: 0.2355\n",
      "Epoch [30/50], Step [721/735], Loss: 0.1587\n",
      "Epoch [30/50], Step [722/735], Loss: 0.4124\n",
      "Epoch [30/50], Step [723/735], Loss: 0.2502\n",
      "Epoch [30/50], Step [724/735], Loss: 0.0905\n",
      "Epoch [30/50], Step [725/735], Loss: 0.4410\n",
      "Epoch [30/50], Step [726/735], Loss: 0.8826\n",
      "Epoch [30/50], Step [727/735], Loss: 0.1879\n",
      "Epoch [30/50], Step [728/735], Loss: 1.1781\n",
      "Epoch [30/50], Step [729/735], Loss: 0.6431\n",
      "Epoch [30/50], Step [730/735], Loss: 0.2094\n",
      "Epoch [30/50], Step [731/735], Loss: 0.3263\n",
      "Epoch [30/50], Step [732/735], Loss: 0.2612\n",
      "Epoch [30/50], Step [733/735], Loss: 0.4209\n",
      "Epoch [30/50], Step [734/735], Loss: 0.2482\n",
      "Epoch [30/50], Step [735/735], Loss: 0.1275\n",
      "Epoch [31/50], Step [1/735], Loss: 0.1807\n",
      "Epoch [31/50], Step [2/735], Loss: 0.1704\n",
      "Epoch [31/50], Step [3/735], Loss: 0.0527\n",
      "Epoch [31/50], Step [4/735], Loss: 0.1750\n",
      "Epoch [31/50], Step [5/735], Loss: 0.0359\n",
      "Epoch [31/50], Step [6/735], Loss: 0.1370\n",
      "Epoch [31/50], Step [7/735], Loss: 0.6432\n",
      "Epoch [31/50], Step [8/735], Loss: 0.2887\n",
      "Epoch [31/50], Step [9/735], Loss: 0.1267\n",
      "Epoch [31/50], Step [10/735], Loss: 0.2922\n",
      "Epoch [31/50], Step [11/735], Loss: 0.0992\n",
      "Epoch [31/50], Step [12/735], Loss: 0.1568\n",
      "Epoch [31/50], Step [13/735], Loss: 0.1907\n",
      "Epoch [31/50], Step [14/735], Loss: 0.5288\n",
      "Epoch [31/50], Step [15/735], Loss: 0.4137\n",
      "Epoch [31/50], Step [16/735], Loss: 0.0472\n",
      "Epoch [31/50], Step [17/735], Loss: 0.4166\n",
      "Epoch [31/50], Step [18/735], Loss: 0.1120\n",
      "Epoch [31/50], Step [19/735], Loss: 0.2092\n",
      "Epoch [31/50], Step [20/735], Loss: 0.2400\n",
      "Epoch [31/50], Step [21/735], Loss: 0.8780\n",
      "Epoch [31/50], Step [22/735], Loss: 0.2309\n",
      "Epoch [31/50], Step [23/735], Loss: 0.1031\n",
      "Epoch [31/50], Step [24/735], Loss: 0.1522\n",
      "Epoch [31/50], Step [25/735], Loss: 0.3530\n",
      "Epoch [31/50], Step [26/735], Loss: 0.2267\n",
      "Epoch [31/50], Step [27/735], Loss: 0.2132\n",
      "Epoch [31/50], Step [28/735], Loss: 0.1057\n",
      "Epoch [31/50], Step [29/735], Loss: 0.1537\n",
      "Epoch [31/50], Step [30/735], Loss: 0.2528\n",
      "Epoch [31/50], Step [31/735], Loss: 0.6013\n",
      "Epoch [31/50], Step [32/735], Loss: 0.2089\n",
      "Epoch [31/50], Step [33/735], Loss: 0.2116\n",
      "Epoch [31/50], Step [34/735], Loss: 0.2458\n",
      "Epoch [31/50], Step [35/735], Loss: 0.2489\n",
      "Epoch [31/50], Step [36/735], Loss: 0.2086\n",
      "Epoch [31/50], Step [37/735], Loss: 0.4597\n",
      "Epoch [31/50], Step [38/735], Loss: 0.1650\n",
      "Epoch [31/50], Step [39/735], Loss: 0.4070\n",
      "Epoch [31/50], Step [40/735], Loss: 0.2906\n",
      "Epoch [31/50], Step [41/735], Loss: 0.2975\n",
      "Epoch [31/50], Step [42/735], Loss: 0.2010\n",
      "Epoch [31/50], Step [43/735], Loss: 0.1046\n",
      "Epoch [31/50], Step [44/735], Loss: 0.4397\n",
      "Epoch [31/50], Step [45/735], Loss: 0.3749\n",
      "Epoch [31/50], Step [46/735], Loss: 0.1422\n",
      "Epoch [31/50], Step [47/735], Loss: 1.1527\n",
      "Epoch [31/50], Step [48/735], Loss: 0.5274\n",
      "Epoch [31/50], Step [49/735], Loss: 0.1779\n",
      "Epoch [31/50], Step [50/735], Loss: 0.5867\n",
      "Epoch [31/50], Step [51/735], Loss: 0.0951\n",
      "Epoch [31/50], Step [52/735], Loss: 0.9339\n",
      "Epoch [31/50], Step [53/735], Loss: 0.2870\n",
      "Epoch [31/50], Step [54/735], Loss: 0.2477\n",
      "Epoch [31/50], Step [55/735], Loss: 0.1783\n",
      "Epoch [31/50], Step [56/735], Loss: 0.2369\n",
      "Epoch [31/50], Step [57/735], Loss: 0.3141\n",
      "Epoch [31/50], Step [58/735], Loss: 0.3381\n",
      "Epoch [31/50], Step [59/735], Loss: 0.4638\n",
      "Epoch [31/50], Step [60/735], Loss: 0.2339\n",
      "Epoch [31/50], Step [61/735], Loss: 0.2071\n",
      "Epoch [31/50], Step [62/735], Loss: 0.2978\n",
      "Epoch [31/50], Step [63/735], Loss: 0.5049\n",
      "Epoch [31/50], Step [64/735], Loss: 0.2064\n",
      "Epoch [31/50], Step [65/735], Loss: 0.1930\n",
      "Epoch [31/50], Step [66/735], Loss: 0.2497\n",
      "Epoch [31/50], Step [67/735], Loss: 0.2351\n",
      "Epoch [31/50], Step [68/735], Loss: 0.1292\n",
      "Epoch [31/50], Step [69/735], Loss: 0.2976\n",
      "Epoch [31/50], Step [70/735], Loss: 0.5526\n",
      "Epoch [31/50], Step [71/735], Loss: 0.1873\n",
      "Epoch [31/50], Step [72/735], Loss: 1.7891\n",
      "Epoch [31/50], Step [73/735], Loss: 0.2811\n",
      "Epoch [31/50], Step [74/735], Loss: 0.7059\n",
      "Epoch [31/50], Step [75/735], Loss: 0.2633\n",
      "Epoch [31/50], Step [76/735], Loss: 0.6818\n",
      "Epoch [31/50], Step [77/735], Loss: 0.3912\n",
      "Epoch [31/50], Step [78/735], Loss: 0.0687\n",
      "Epoch [31/50], Step [79/735], Loss: 0.0574\n",
      "Epoch [31/50], Step [80/735], Loss: 0.1731\n",
      "Epoch [31/50], Step [81/735], Loss: 0.6236\n",
      "Epoch [31/50], Step [82/735], Loss: 0.2075\n",
      "Epoch [31/50], Step [83/735], Loss: 0.3793\n",
      "Epoch [31/50], Step [84/735], Loss: 0.3061\n",
      "Epoch [31/50], Step [85/735], Loss: 0.2468\n",
      "Epoch [31/50], Step [86/735], Loss: 0.6413\n",
      "Epoch [31/50], Step [87/735], Loss: 0.2119\n",
      "Epoch [31/50], Step [88/735], Loss: 0.8055\n",
      "Epoch [31/50], Step [89/735], Loss: 0.3837\n",
      "Epoch [31/50], Step [90/735], Loss: 0.3677\n",
      "Epoch [31/50], Step [91/735], Loss: 0.1849\n",
      "Epoch [31/50], Step [92/735], Loss: 0.1284\n",
      "Epoch [31/50], Step [93/735], Loss: 0.3006\n",
      "Epoch [31/50], Step [94/735], Loss: 0.5174\n",
      "Epoch [31/50], Step [95/735], Loss: 0.2389\n",
      "Epoch [31/50], Step [96/735], Loss: 0.2014\n",
      "Epoch [31/50], Step [97/735], Loss: 0.1971\n",
      "Epoch [31/50], Step [98/735], Loss: 0.4286\n",
      "Epoch [31/50], Step [99/735], Loss: 0.1682\n",
      "Epoch [31/50], Step [100/735], Loss: 0.5106\n",
      "Epoch [31/50], Step [101/735], Loss: 0.5524\n",
      "Epoch [31/50], Step [102/735], Loss: 0.0787\n",
      "Epoch [31/50], Step [103/735], Loss: 0.3800\n",
      "Epoch [31/50], Step [104/735], Loss: 0.2792\n",
      "Epoch [31/50], Step [105/735], Loss: 0.2216\n",
      "Epoch [31/50], Step [106/735], Loss: 0.3842\n",
      "Epoch [31/50], Step [107/735], Loss: 0.3692\n",
      "Epoch [31/50], Step [108/735], Loss: 0.9262\n",
      "Epoch [31/50], Step [109/735], Loss: 4.3222\n",
      "Epoch [31/50], Step [110/735], Loss: 0.0915\n",
      "Epoch [31/50], Step [111/735], Loss: 0.2591\n",
      "Epoch [31/50], Step [112/735], Loss: 0.2569\n",
      "Epoch [31/50], Step [113/735], Loss: 0.2904\n",
      "Epoch [31/50], Step [114/735], Loss: 0.2705\n",
      "Epoch [31/50], Step [115/735], Loss: 0.1163\n",
      "Epoch [31/50], Step [116/735], Loss: 0.1106\n",
      "Epoch [31/50], Step [117/735], Loss: 0.7536\n",
      "Epoch [31/50], Step [118/735], Loss: 0.2510\n",
      "Epoch [31/50], Step [119/735], Loss: 0.4162\n",
      "Epoch [31/50], Step [120/735], Loss: 0.2265\n",
      "Epoch [31/50], Step [121/735], Loss: 0.8833\n",
      "Epoch [31/50], Step [122/735], Loss: 0.2063\n",
      "Epoch [31/50], Step [123/735], Loss: 0.0753\n",
      "Epoch [31/50], Step [124/735], Loss: 0.2766\n",
      "Epoch [31/50], Step [125/735], Loss: 1.2601\n",
      "Epoch [31/50], Step [126/735], Loss: 0.2022\n",
      "Epoch [31/50], Step [127/735], Loss: 0.1215\n",
      "Epoch [31/50], Step [128/735], Loss: 0.1749\n",
      "Epoch [31/50], Step [129/735], Loss: 0.2728\n",
      "Epoch [31/50], Step [130/735], Loss: 1.1595\n",
      "Epoch [31/50], Step [131/735], Loss: 0.1540\n",
      "Epoch [31/50], Step [132/735], Loss: 0.3323\n",
      "Epoch [31/50], Step [133/735], Loss: 0.4397\n",
      "Epoch [31/50], Step [134/735], Loss: 0.1806\n",
      "Epoch [31/50], Step [135/735], Loss: 0.1466\n",
      "Epoch [31/50], Step [136/735], Loss: 0.3091\n",
      "Epoch [31/50], Step [137/735], Loss: 0.1212\n",
      "Epoch [31/50], Step [138/735], Loss: 0.6125\n",
      "Epoch [31/50], Step [139/735], Loss: 0.0653\n",
      "Epoch [31/50], Step [140/735], Loss: 0.3316\n",
      "Epoch [31/50], Step [141/735], Loss: 0.4053\n",
      "Epoch [31/50], Step [142/735], Loss: 0.2679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Step [143/735], Loss: 0.7611\n",
      "Epoch [31/50], Step [144/735], Loss: 0.1231\n",
      "Epoch [31/50], Step [145/735], Loss: 0.2133\n",
      "Epoch [31/50], Step [146/735], Loss: 0.1833\n",
      "Epoch [31/50], Step [147/735], Loss: 0.3998\n",
      "Epoch [31/50], Step [148/735], Loss: 0.3264\n",
      "Epoch [31/50], Step [149/735], Loss: 0.3103\n",
      "Epoch [31/50], Step [150/735], Loss: 0.1026\n",
      "Epoch [31/50], Step [151/735], Loss: 0.1346\n",
      "Epoch [31/50], Step [152/735], Loss: 0.0859\n",
      "Epoch [31/50], Step [153/735], Loss: 0.2659\n",
      "Epoch [31/50], Step [154/735], Loss: 0.5456\n",
      "Epoch [31/50], Step [155/735], Loss: 0.4815\n",
      "Epoch [31/50], Step [156/735], Loss: 0.3325\n",
      "Epoch [31/50], Step [157/735], Loss: 0.5090\n",
      "Epoch [31/50], Step [158/735], Loss: 0.2949\n",
      "Epoch [31/50], Step [159/735], Loss: 0.5603\n",
      "Epoch [31/50], Step [160/735], Loss: 1.8742\n",
      "Epoch [31/50], Step [161/735], Loss: 0.4997\n",
      "Epoch [31/50], Step [162/735], Loss: 0.4057\n",
      "Epoch [31/50], Step [163/735], Loss: 0.4669\n",
      "Epoch [31/50], Step [164/735], Loss: 0.1526\n",
      "Epoch [31/50], Step [165/735], Loss: 0.0745\n",
      "Epoch [31/50], Step [166/735], Loss: 0.1886\n",
      "Epoch [31/50], Step [167/735], Loss: 0.3193\n",
      "Epoch [31/50], Step [168/735], Loss: 0.4367\n",
      "Epoch [31/50], Step [169/735], Loss: 4.3910\n",
      "Epoch [31/50], Step [170/735], Loss: 0.4349\n",
      "Epoch [31/50], Step [171/735], Loss: 0.2830\n",
      "Epoch [31/50], Step [172/735], Loss: 0.1210\n",
      "Epoch [31/50], Step [173/735], Loss: 0.1881\n",
      "Epoch [31/50], Step [174/735], Loss: 0.2992\n",
      "Epoch [31/50], Step [175/735], Loss: 0.1225\n",
      "Epoch [31/50], Step [176/735], Loss: 0.5513\n",
      "Epoch [31/50], Step [177/735], Loss: 0.3171\n",
      "Epoch [31/50], Step [178/735], Loss: 0.5788\n",
      "Epoch [31/50], Step [179/735], Loss: 0.5815\n",
      "Epoch [31/50], Step [180/735], Loss: 0.5368\n",
      "Epoch [31/50], Step [181/735], Loss: 0.1000\n",
      "Epoch [31/50], Step [182/735], Loss: 0.2666\n",
      "Epoch [31/50], Step [183/735], Loss: 0.5198\n",
      "Epoch [31/50], Step [184/735], Loss: 0.4855\n",
      "Epoch [31/50], Step [185/735], Loss: 0.4272\n",
      "Epoch [31/50], Step [186/735], Loss: 0.1258\n",
      "Epoch [31/50], Step [187/735], Loss: 0.2691\n",
      "Epoch [31/50], Step [188/735], Loss: 0.4014\n",
      "Epoch [31/50], Step [189/735], Loss: 0.4519\n",
      "Epoch [31/50], Step [190/735], Loss: 0.2282\n",
      "Epoch [31/50], Step [191/735], Loss: 0.2291\n",
      "Epoch [31/50], Step [192/735], Loss: 0.5031\n",
      "Epoch [31/50], Step [193/735], Loss: 0.2003\n",
      "Epoch [31/50], Step [194/735], Loss: 0.6719\n",
      "Epoch [31/50], Step [195/735], Loss: 0.8016\n",
      "Epoch [31/50], Step [196/735], Loss: 0.1992\n",
      "Epoch [31/50], Step [197/735], Loss: 0.1214\n",
      "Epoch [31/50], Step [198/735], Loss: 0.3115\n",
      "Epoch [31/50], Step [199/735], Loss: 0.4603\n",
      "Epoch [31/50], Step [200/735], Loss: 0.2006\n",
      "Epoch [31/50], Step [201/735], Loss: 0.1736\n",
      "Epoch [31/50], Step [202/735], Loss: 0.9592\n",
      "Epoch [31/50], Step [203/735], Loss: 0.1809\n",
      "Epoch [31/50], Step [204/735], Loss: 0.1233\n",
      "Epoch [31/50], Step [205/735], Loss: 0.4494\n",
      "Epoch [31/50], Step [206/735], Loss: 0.7011\n",
      "Epoch [31/50], Step [207/735], Loss: 0.0403\n",
      "Epoch [31/50], Step [208/735], Loss: 0.1521\n",
      "Epoch [31/50], Step [209/735], Loss: 0.4508\n",
      "Epoch [31/50], Step [210/735], Loss: 0.0905\n",
      "Epoch [31/50], Step [211/735], Loss: 0.1651\n",
      "Epoch [31/50], Step [212/735], Loss: 0.1928\n",
      "Epoch [31/50], Step [213/735], Loss: 0.2280\n",
      "Epoch [31/50], Step [214/735], Loss: 0.2956\n",
      "Epoch [31/50], Step [215/735], Loss: 0.2786\n",
      "Epoch [31/50], Step [216/735], Loss: 0.5056\n",
      "Epoch [31/50], Step [217/735], Loss: 0.1317\n",
      "Epoch [31/50], Step [218/735], Loss: 0.3226\n",
      "Epoch [31/50], Step [219/735], Loss: 0.3456\n",
      "Epoch [31/50], Step [220/735], Loss: 0.2004\n",
      "Epoch [31/50], Step [221/735], Loss: 0.4232\n",
      "Epoch [31/50], Step [222/735], Loss: 0.4729\n",
      "Epoch [31/50], Step [223/735], Loss: 0.9699\n",
      "Epoch [31/50], Step [224/735], Loss: 0.0967\n",
      "Epoch [31/50], Step [225/735], Loss: 0.2728\n",
      "Epoch [31/50], Step [226/735], Loss: 0.2037\n",
      "Epoch [31/50], Step [227/735], Loss: 0.2911\n",
      "Epoch [31/50], Step [228/735], Loss: 0.1909\n",
      "Epoch [31/50], Step [229/735], Loss: 0.1041\n",
      "Epoch [31/50], Step [230/735], Loss: 0.2649\n",
      "Epoch [31/50], Step [231/735], Loss: 0.1896\n",
      "Epoch [31/50], Step [232/735], Loss: 0.2203\n",
      "Epoch [31/50], Step [233/735], Loss: 0.4774\n",
      "Epoch [31/50], Step [234/735], Loss: 0.3258\n",
      "Epoch [31/50], Step [235/735], Loss: 0.1732\n",
      "Epoch [31/50], Step [236/735], Loss: 1.0339\n",
      "Epoch [31/50], Step [237/735], Loss: 0.1248\n",
      "Epoch [31/50], Step [238/735], Loss: 0.3799\n",
      "Epoch [31/50], Step [239/735], Loss: 0.3000\n",
      "Epoch [31/50], Step [240/735], Loss: 0.1669\n",
      "Epoch [31/50], Step [241/735], Loss: 0.2777\n",
      "Epoch [31/50], Step [242/735], Loss: 1.0705\n",
      "Epoch [31/50], Step [243/735], Loss: 0.3617\n",
      "Epoch [31/50], Step [244/735], Loss: 0.1236\n",
      "Epoch [31/50], Step [245/735], Loss: 0.2993\n",
      "Epoch [31/50], Step [246/735], Loss: 0.7357\n",
      "Epoch [31/50], Step [247/735], Loss: 0.2828\n",
      "Epoch [31/50], Step [248/735], Loss: 0.7859\n",
      "Epoch [31/50], Step [249/735], Loss: 0.3507\n",
      "Epoch [31/50], Step [250/735], Loss: 0.2250\n",
      "Epoch [31/50], Step [251/735], Loss: 0.4958\n",
      "Epoch [31/50], Step [252/735], Loss: 0.2255\n",
      "Epoch [31/50], Step [253/735], Loss: 0.6425\n",
      "Epoch [31/50], Step [254/735], Loss: 0.2460\n",
      "Epoch [31/50], Step [255/735], Loss: 0.3708\n",
      "Epoch [31/50], Step [256/735], Loss: 1.1304\n",
      "Epoch [31/50], Step [257/735], Loss: 0.5769\n",
      "Epoch [31/50], Step [258/735], Loss: 0.4133\n",
      "Epoch [31/50], Step [259/735], Loss: 0.1744\n",
      "Epoch [31/50], Step [260/735], Loss: 0.1661\n",
      "Epoch [31/50], Step [261/735], Loss: 0.4050\n",
      "Epoch [31/50], Step [262/735], Loss: 0.4533\n",
      "Epoch [31/50], Step [263/735], Loss: 0.1434\n",
      "Epoch [31/50], Step [264/735], Loss: 1.0549\n",
      "Epoch [31/50], Step [265/735], Loss: 0.2769\n",
      "Epoch [31/50], Step [266/735], Loss: 0.0807\n",
      "Epoch [31/50], Step [267/735], Loss: 0.2906\n",
      "Epoch [31/50], Step [268/735], Loss: 0.4558\n",
      "Epoch [31/50], Step [269/735], Loss: 0.1609\n",
      "Epoch [31/50], Step [270/735], Loss: 0.5578\n",
      "Epoch [31/50], Step [271/735], Loss: 0.2930\n",
      "Epoch [31/50], Step [272/735], Loss: 0.4889\n",
      "Epoch [31/50], Step [273/735], Loss: 0.2146\n",
      "Epoch [31/50], Step [274/735], Loss: 0.4330\n",
      "Epoch [31/50], Step [275/735], Loss: 0.5386\n",
      "Epoch [31/50], Step [276/735], Loss: 0.0855\n",
      "Epoch [31/50], Step [277/735], Loss: 0.3541\n",
      "Epoch [31/50], Step [278/735], Loss: 0.5673\n",
      "Epoch [31/50], Step [279/735], Loss: 0.9449\n",
      "Epoch [31/50], Step [280/735], Loss: 0.0479\n",
      "Epoch [31/50], Step [281/735], Loss: 0.7410\n",
      "Epoch [31/50], Step [282/735], Loss: 0.6115\n",
      "Epoch [31/50], Step [283/735], Loss: 0.8356\n",
      "Epoch [31/50], Step [284/735], Loss: 0.9497\n",
      "Epoch [31/50], Step [285/735], Loss: 0.1872\n",
      "Epoch [31/50], Step [286/735], Loss: 0.3005\n",
      "Epoch [31/50], Step [287/735], Loss: 0.4354\n",
      "Epoch [31/50], Step [288/735], Loss: 0.4904\n",
      "Epoch [31/50], Step [289/735], Loss: 0.1124\n",
      "Epoch [31/50], Step [290/735], Loss: 0.4414\n",
      "Epoch [31/50], Step [291/735], Loss: 0.4037\n",
      "Epoch [31/50], Step [292/735], Loss: 0.3520\n",
      "Epoch [31/50], Step [293/735], Loss: 0.6639\n",
      "Epoch [31/50], Step [294/735], Loss: 0.3983\n",
      "Epoch [31/50], Step [295/735], Loss: 0.3251\n",
      "Epoch [31/50], Step [296/735], Loss: 0.3204\n",
      "Epoch [31/50], Step [297/735], Loss: 0.1162\n",
      "Epoch [31/50], Step [298/735], Loss: 0.2296\n",
      "Epoch [31/50], Step [299/735], Loss: 0.1614\n",
      "Epoch [31/50], Step [300/735], Loss: 0.1757\n",
      "Epoch [31/50], Step [301/735], Loss: 0.1228\n",
      "Epoch [31/50], Step [302/735], Loss: 0.2031\n",
      "Epoch [31/50], Step [303/735], Loss: 0.2686\n",
      "Epoch [31/50], Step [304/735], Loss: 4.2332\n",
      "Epoch [31/50], Step [305/735], Loss: 0.3431\n",
      "Epoch [31/50], Step [306/735], Loss: 0.1964\n",
      "Epoch [31/50], Step [307/735], Loss: 0.4076\n",
      "Epoch [31/50], Step [308/735], Loss: 0.4009\n",
      "Epoch [31/50], Step [309/735], Loss: 1.0278\n",
      "Epoch [31/50], Step [310/735], Loss: 0.4009\n",
      "Epoch [31/50], Step [311/735], Loss: 1.1468\n",
      "Epoch [31/50], Step [312/735], Loss: 0.5833\n",
      "Epoch [31/50], Step [313/735], Loss: 0.3119\n",
      "Epoch [31/50], Step [314/735], Loss: 0.1566\n",
      "Epoch [31/50], Step [315/735], Loss: 0.1428\n",
      "Epoch [31/50], Step [316/735], Loss: 0.1505\n",
      "Epoch [31/50], Step [317/735], Loss: 0.8470\n",
      "Epoch [31/50], Step [318/735], Loss: 0.0501\n",
      "Epoch [31/50], Step [319/735], Loss: 0.1396\n",
      "Epoch [31/50], Step [320/735], Loss: 0.2315\n",
      "Epoch [31/50], Step [321/735], Loss: 0.6762\n",
      "Epoch [31/50], Step [322/735], Loss: 0.4195\n",
      "Epoch [31/50], Step [323/735], Loss: 0.4608\n",
      "Epoch [31/50], Step [324/735], Loss: 0.2047\n",
      "Epoch [31/50], Step [325/735], Loss: 0.2895\n",
      "Epoch [31/50], Step [326/735], Loss: 0.0594\n",
      "Epoch [31/50], Step [327/735], Loss: 0.2846\n",
      "Epoch [31/50], Step [328/735], Loss: 0.3572\n",
      "Epoch [31/50], Step [329/735], Loss: 0.1455\n",
      "Epoch [31/50], Step [330/735], Loss: 0.0294\n",
      "Epoch [31/50], Step [331/735], Loss: 0.1542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Step [332/735], Loss: 0.0713\n",
      "Epoch [31/50], Step [333/735], Loss: 0.2355\n",
      "Epoch [31/50], Step [334/735], Loss: 0.3130\n",
      "Epoch [31/50], Step [335/735], Loss: 0.2538\n",
      "Epoch [31/50], Step [336/735], Loss: 0.6851\n",
      "Epoch [31/50], Step [337/735], Loss: 0.0716\n",
      "Epoch [31/50], Step [338/735], Loss: 0.2280\n",
      "Epoch [31/50], Step [339/735], Loss: 0.2875\n",
      "Epoch [31/50], Step [340/735], Loss: 0.2475\n",
      "Epoch [31/50], Step [341/735], Loss: 0.0978\n",
      "Epoch [31/50], Step [342/735], Loss: 0.3692\n",
      "Epoch [31/50], Step [343/735], Loss: 0.5105\n",
      "Epoch [31/50], Step [344/735], Loss: 0.1309\n",
      "Epoch [31/50], Step [345/735], Loss: 0.0924\n",
      "Epoch [31/50], Step [346/735], Loss: 0.6022\n",
      "Epoch [31/50], Step [347/735], Loss: 0.7052\n",
      "Epoch [31/50], Step [348/735], Loss: 0.1447\n",
      "Epoch [31/50], Step [349/735], Loss: 0.1856\n",
      "Epoch [31/50], Step [350/735], Loss: 0.1825\n",
      "Epoch [31/50], Step [351/735], Loss: 0.2859\n",
      "Epoch [31/50], Step [352/735], Loss: 0.1015\n",
      "Epoch [31/50], Step [353/735], Loss: 0.7316\n",
      "Epoch [31/50], Step [354/735], Loss: 0.6440\n",
      "Epoch [31/50], Step [355/735], Loss: 0.2033\n",
      "Epoch [31/50], Step [356/735], Loss: 1.0644\n",
      "Epoch [31/50], Step [357/735], Loss: 0.3840\n",
      "Epoch [31/50], Step [358/735], Loss: 0.3534\n",
      "Epoch [31/50], Step [359/735], Loss: 0.1138\n",
      "Epoch [31/50], Step [360/735], Loss: 0.4357\n",
      "Epoch [31/50], Step [361/735], Loss: 0.3541\n",
      "Epoch [31/50], Step [362/735], Loss: 2.0368\n",
      "Epoch [31/50], Step [363/735], Loss: 0.4927\n",
      "Epoch [31/50], Step [364/735], Loss: 0.0951\n",
      "Epoch [31/50], Step [365/735], Loss: 0.1538\n",
      "Epoch [31/50], Step [366/735], Loss: 0.1151\n",
      "Epoch [31/50], Step [367/735], Loss: 0.3449\n",
      "Epoch [31/50], Step [368/735], Loss: 0.2183\n",
      "Epoch [31/50], Step [369/735], Loss: 0.1190\n",
      "Epoch [31/50], Step [370/735], Loss: 0.2986\n",
      "Epoch [31/50], Step [371/735], Loss: 0.1272\n",
      "Epoch [31/50], Step [372/735], Loss: 0.7434\n",
      "Epoch [31/50], Step [373/735], Loss: 0.0708\n",
      "Epoch [31/50], Step [374/735], Loss: 0.3214\n",
      "Epoch [31/50], Step [375/735], Loss: 0.2048\n",
      "Epoch [31/50], Step [376/735], Loss: 0.0895\n",
      "Epoch [31/50], Step [377/735], Loss: 0.1094\n",
      "Epoch [31/50], Step [378/735], Loss: 0.1579\n",
      "Epoch [31/50], Step [379/735], Loss: 0.3368\n",
      "Epoch [31/50], Step [380/735], Loss: 0.2164\n",
      "Epoch [31/50], Step [381/735], Loss: 0.1646\n",
      "Epoch [31/50], Step [382/735], Loss: 1.1368\n",
      "Epoch [31/50], Step [383/735], Loss: 0.3896\n",
      "Epoch [31/50], Step [384/735], Loss: 0.4102\n",
      "Epoch [31/50], Step [385/735], Loss: 0.1781\n",
      "Epoch [31/50], Step [386/735], Loss: 0.5957\n",
      "Epoch [31/50], Step [387/735], Loss: 0.1245\n",
      "Epoch [31/50], Step [388/735], Loss: 0.0828\n",
      "Epoch [31/50], Step [389/735], Loss: 0.4596\n",
      "Epoch [31/50], Step [390/735], Loss: 0.3212\n",
      "Epoch [31/50], Step [391/735], Loss: 0.0642\n",
      "Epoch [31/50], Step [392/735], Loss: 0.1686\n",
      "Epoch [31/50], Step [393/735], Loss: 0.6326\n",
      "Epoch [31/50], Step [394/735], Loss: 0.2723\n",
      "Epoch [31/50], Step [395/735], Loss: 0.5825\n",
      "Epoch [31/50], Step [396/735], Loss: 0.3606\n",
      "Epoch [31/50], Step [397/735], Loss: 0.3679\n",
      "Epoch [31/50], Step [398/735], Loss: 0.1743\n",
      "Epoch [31/50], Step [399/735], Loss: 0.3133\n",
      "Epoch [31/50], Step [400/735], Loss: 0.2685\n",
      "Epoch [31/50], Step [401/735], Loss: 0.1856\n",
      "Epoch [31/50], Step [402/735], Loss: 0.1776\n",
      "Epoch [31/50], Step [403/735], Loss: 0.7925\n",
      "Epoch [31/50], Step [404/735], Loss: 0.1571\n",
      "Epoch [31/50], Step [405/735], Loss: 0.6065\n",
      "Epoch [31/50], Step [406/735], Loss: 0.2620\n",
      "Epoch [31/50], Step [407/735], Loss: 0.2474\n",
      "Epoch [31/50], Step [408/735], Loss: 0.7597\n",
      "Epoch [31/50], Step [409/735], Loss: 0.2218\n",
      "Epoch [31/50], Step [410/735], Loss: 0.1597\n",
      "Epoch [31/50], Step [411/735], Loss: 0.0829\n",
      "Epoch [31/50], Step [412/735], Loss: 0.0762\n",
      "Epoch [31/50], Step [413/735], Loss: 0.1543\n",
      "Epoch [31/50], Step [414/735], Loss: 0.2155\n",
      "Epoch [31/50], Step [415/735], Loss: 0.1241\n",
      "Epoch [31/50], Step [416/735], Loss: 0.5992\n",
      "Epoch [31/50], Step [417/735], Loss: 0.1334\n",
      "Epoch [31/50], Step [418/735], Loss: 0.1910\n",
      "Epoch [31/50], Step [419/735], Loss: 0.6763\n",
      "Epoch [31/50], Step [420/735], Loss: 0.3523\n",
      "Epoch [31/50], Step [421/735], Loss: 0.1208\n",
      "Epoch [31/50], Step [422/735], Loss: 0.3832\n",
      "Epoch [31/50], Step [423/735], Loss: 0.1524\n",
      "Epoch [31/50], Step [424/735], Loss: 0.1287\n",
      "Epoch [31/50], Step [425/735], Loss: 0.7817\n",
      "Epoch [31/50], Step [426/735], Loss: 0.3220\n",
      "Epoch [31/50], Step [427/735], Loss: 0.2478\n",
      "Epoch [31/50], Step [428/735], Loss: 0.2451\n",
      "Epoch [31/50], Step [429/735], Loss: 0.1025\n",
      "Epoch [31/50], Step [430/735], Loss: 0.7994\n",
      "Epoch [31/50], Step [431/735], Loss: 0.8778\n",
      "Epoch [31/50], Step [432/735], Loss: 0.1355\n",
      "Epoch [31/50], Step [433/735], Loss: 0.2090\n",
      "Epoch [31/50], Step [434/735], Loss: 0.4994\n",
      "Epoch [31/50], Step [435/735], Loss: 0.2916\n",
      "Epoch [31/50], Step [436/735], Loss: 0.1615\n",
      "Epoch [31/50], Step [437/735], Loss: 0.0521\n",
      "Epoch [31/50], Step [438/735], Loss: 0.1846\n",
      "Epoch [31/50], Step [439/735], Loss: 0.6429\n",
      "Epoch [31/50], Step [440/735], Loss: 0.5369\n",
      "Epoch [31/50], Step [441/735], Loss: 0.5225\n",
      "Epoch [31/50], Step [442/735], Loss: 0.0538\n",
      "Epoch [31/50], Step [443/735], Loss: 0.3946\n",
      "Epoch [31/50], Step [444/735], Loss: 0.1695\n",
      "Epoch [31/50], Step [445/735], Loss: 0.2483\n",
      "Epoch [31/50], Step [446/735], Loss: 1.3329\n",
      "Epoch [31/50], Step [447/735], Loss: 0.1397\n",
      "Epoch [31/50], Step [448/735], Loss: 0.3503\n",
      "Epoch [31/50], Step [449/735], Loss: 0.3481\n",
      "Epoch [31/50], Step [450/735], Loss: 0.2342\n",
      "Epoch [31/50], Step [451/735], Loss: 0.1790\n",
      "Epoch [31/50], Step [452/735], Loss: 0.3373\n",
      "Epoch [31/50], Step [453/735], Loss: 0.1807\n",
      "Epoch [31/50], Step [454/735], Loss: 0.3453\n",
      "Epoch [31/50], Step [455/735], Loss: 0.2209\n",
      "Epoch [31/50], Step [456/735], Loss: 0.1970\n",
      "Epoch [31/50], Step [457/735], Loss: 0.2910\n",
      "Epoch [31/50], Step [458/735], Loss: 0.1356\n",
      "Epoch [31/50], Step [459/735], Loss: 0.1740\n",
      "Epoch [31/50], Step [460/735], Loss: 0.1131\n",
      "Epoch [31/50], Step [461/735], Loss: 0.1832\n",
      "Epoch [31/50], Step [462/735], Loss: 0.7583\n",
      "Epoch [31/50], Step [463/735], Loss: 0.1166\n",
      "Epoch [31/50], Step [464/735], Loss: 0.2078\n",
      "Epoch [31/50], Step [465/735], Loss: 0.0705\n",
      "Epoch [31/50], Step [466/735], Loss: 0.5096\n",
      "Epoch [31/50], Step [467/735], Loss: 0.1655\n",
      "Epoch [31/50], Step [468/735], Loss: 0.2178\n",
      "Epoch [31/50], Step [469/735], Loss: 1.4625\n",
      "Epoch [31/50], Step [470/735], Loss: 0.1664\n",
      "Epoch [31/50], Step [471/735], Loss: 0.7048\n",
      "Epoch [31/50], Step [472/735], Loss: 0.2787\n",
      "Epoch [31/50], Step [473/735], Loss: 0.1549\n",
      "Epoch [31/50], Step [474/735], Loss: 0.2036\n",
      "Epoch [31/50], Step [475/735], Loss: 0.4628\n",
      "Epoch [31/50], Step [476/735], Loss: 0.2647\n",
      "Epoch [31/50], Step [477/735], Loss: 0.1167\n",
      "Epoch [31/50], Step [478/735], Loss: 0.3631\n",
      "Epoch [31/50], Step [479/735], Loss: 0.1828\n",
      "Epoch [31/50], Step [480/735], Loss: 0.3162\n",
      "Epoch [31/50], Step [481/735], Loss: 0.3007\n",
      "Epoch [31/50], Step [482/735], Loss: 0.0787\n",
      "Epoch [31/50], Step [483/735], Loss: 0.3259\n",
      "Epoch [31/50], Step [484/735], Loss: 0.4311\n",
      "Epoch [31/50], Step [485/735], Loss: 0.5245\n",
      "Epoch [31/50], Step [486/735], Loss: 0.5862\n",
      "Epoch [31/50], Step [487/735], Loss: 0.0603\n",
      "Epoch [31/50], Step [488/735], Loss: 0.5621\n",
      "Epoch [31/50], Step [489/735], Loss: 0.1569\n",
      "Epoch [31/50], Step [490/735], Loss: 0.5311\n",
      "Epoch [31/50], Step [491/735], Loss: 0.0822\n",
      "Epoch [31/50], Step [492/735], Loss: 0.1750\n",
      "Epoch [31/50], Step [493/735], Loss: 0.2156\n",
      "Epoch [31/50], Step [494/735], Loss: 0.9925\n",
      "Epoch [31/50], Step [495/735], Loss: 0.2994\n",
      "Epoch [31/50], Step [496/735], Loss: 0.1652\n",
      "Epoch [31/50], Step [497/735], Loss: 0.4406\n",
      "Epoch [31/50], Step [498/735], Loss: 0.1677\n",
      "Epoch [31/50], Step [499/735], Loss: 0.5185\n",
      "Epoch [31/50], Step [500/735], Loss: 0.1662\n",
      "Epoch [31/50], Step [501/735], Loss: 0.2862\n",
      "Epoch [31/50], Step [502/735], Loss: 0.3830\n",
      "Epoch [31/50], Step [503/735], Loss: 1.2961\n",
      "Epoch [31/50], Step [504/735], Loss: 0.3203\n",
      "Epoch [31/50], Step [505/735], Loss: 0.5394\n",
      "Epoch [31/50], Step [506/735], Loss: 0.3767\n",
      "Epoch [31/50], Step [507/735], Loss: 0.2372\n",
      "Epoch [31/50], Step [508/735], Loss: 0.1324\n",
      "Epoch [31/50], Step [509/735], Loss: 1.4262\n",
      "Epoch [31/50], Step [510/735], Loss: 0.4045\n",
      "Epoch [31/50], Step [511/735], Loss: 0.2639\n",
      "Epoch [31/50], Step [512/735], Loss: 0.6638\n",
      "Epoch [31/50], Step [513/735], Loss: 0.4410\n",
      "Epoch [31/50], Step [514/735], Loss: 0.2448\n",
      "Epoch [31/50], Step [515/735], Loss: 0.4555\n",
      "Epoch [31/50], Step [516/735], Loss: 0.1334\n",
      "Epoch [31/50], Step [517/735], Loss: 0.5521\n",
      "Epoch [31/50], Step [518/735], Loss: 0.6429\n",
      "Epoch [31/50], Step [519/735], Loss: 0.3732\n",
      "Epoch [31/50], Step [520/735], Loss: 0.9990\n",
      "Epoch [31/50], Step [521/735], Loss: 0.5503\n",
      "Epoch [31/50], Step [522/735], Loss: 0.3243\n",
      "Epoch [31/50], Step [523/735], Loss: 0.1319\n",
      "Epoch [31/50], Step [524/735], Loss: 0.4363\n",
      "Epoch [31/50], Step [525/735], Loss: 0.1362\n",
      "Epoch [31/50], Step [526/735], Loss: 0.6067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Step [527/735], Loss: 0.4334\n",
      "Epoch [31/50], Step [528/735], Loss: 0.5774\n",
      "Epoch [31/50], Step [529/735], Loss: 0.9983\n",
      "Epoch [31/50], Step [530/735], Loss: 0.1675\n",
      "Epoch [31/50], Step [531/735], Loss: 1.4794\n",
      "Epoch [31/50], Step [532/735], Loss: 0.4906\n",
      "Epoch [31/50], Step [533/735], Loss: 0.5956\n",
      "Epoch [31/50], Step [534/735], Loss: 0.3613\n",
      "Epoch [31/50], Step [535/735], Loss: 0.1559\n",
      "Epoch [31/50], Step [536/735], Loss: 0.5902\n",
      "Epoch [31/50], Step [537/735], Loss: 0.0768\n",
      "Epoch [31/50], Step [538/735], Loss: 0.4282\n",
      "Epoch [31/50], Step [539/735], Loss: 0.1535\n",
      "Epoch [31/50], Step [540/735], Loss: 0.2814\n",
      "Epoch [31/50], Step [541/735], Loss: 0.2889\n",
      "Epoch [31/50], Step [542/735], Loss: 0.3614\n",
      "Epoch [31/50], Step [543/735], Loss: 0.3104\n",
      "Epoch [31/50], Step [544/735], Loss: 0.3308\n",
      "Epoch [31/50], Step [545/735], Loss: 0.2789\n",
      "Epoch [31/50], Step [546/735], Loss: 0.7262\n",
      "Epoch [31/50], Step [547/735], Loss: 0.7480\n",
      "Epoch [31/50], Step [548/735], Loss: 0.5351\n",
      "Epoch [31/50], Step [549/735], Loss: 0.2293\n",
      "Epoch [31/50], Step [550/735], Loss: 0.2683\n",
      "Epoch [31/50], Step [551/735], Loss: 0.5082\n",
      "Epoch [31/50], Step [552/735], Loss: 0.0912\n",
      "Epoch [31/50], Step [553/735], Loss: 0.6812\n",
      "Epoch [31/50], Step [554/735], Loss: 0.0982\n",
      "Epoch [31/50], Step [555/735], Loss: 0.5053\n",
      "Epoch [31/50], Step [556/735], Loss: 0.2121\n",
      "Epoch [31/50], Step [557/735], Loss: 0.3457\n",
      "Epoch [31/50], Step [558/735], Loss: 0.3204\n",
      "Epoch [31/50], Step [559/735], Loss: 0.6789\n",
      "Epoch [31/50], Step [560/735], Loss: 0.4221\n",
      "Epoch [31/50], Step [561/735], Loss: 0.2681\n",
      "Epoch [31/50], Step [562/735], Loss: 0.2626\n",
      "Epoch [31/50], Step [563/735], Loss: 0.2581\n",
      "Epoch [31/50], Step [564/735], Loss: 4.7036\n",
      "Epoch [31/50], Step [565/735], Loss: 0.3549\n",
      "Epoch [31/50], Step [566/735], Loss: 0.1648\n",
      "Epoch [31/50], Step [567/735], Loss: 0.8268\n",
      "Epoch [31/50], Step [568/735], Loss: 0.3069\n",
      "Epoch [31/50], Step [569/735], Loss: 0.4639\n",
      "Epoch [31/50], Step [570/735], Loss: 4.1486\n",
      "Epoch [31/50], Step [571/735], Loss: 0.1138\n",
      "Epoch [31/50], Step [572/735], Loss: 0.4621\n",
      "Epoch [31/50], Step [573/735], Loss: 0.7601\n",
      "Epoch [31/50], Step [574/735], Loss: 0.2809\n",
      "Epoch [31/50], Step [575/735], Loss: 0.1116\n",
      "Epoch [31/50], Step [576/735], Loss: 0.2455\n",
      "Epoch [31/50], Step [577/735], Loss: 0.3972\n",
      "Epoch [31/50], Step [578/735], Loss: 0.2222\n",
      "Epoch [31/50], Step [579/735], Loss: 0.1191\n",
      "Epoch [31/50], Step [580/735], Loss: 0.4694\n",
      "Epoch [31/50], Step [581/735], Loss: 0.0980\n",
      "Epoch [31/50], Step [582/735], Loss: 0.4278\n",
      "Epoch [31/50], Step [583/735], Loss: 0.1593\n",
      "Epoch [31/50], Step [584/735], Loss: 0.3946\n",
      "Epoch [31/50], Step [585/735], Loss: 0.4400\n",
      "Epoch [31/50], Step [586/735], Loss: 0.0746\n",
      "Epoch [31/50], Step [587/735], Loss: 0.8885\n",
      "Epoch [31/50], Step [588/735], Loss: 0.4368\n",
      "Epoch [31/50], Step [589/735], Loss: 0.3515\n",
      "Epoch [31/50], Step [590/735], Loss: 0.1339\n",
      "Epoch [31/50], Step [591/735], Loss: 0.9152\n",
      "Epoch [31/50], Step [592/735], Loss: 0.2532\n",
      "Epoch [31/50], Step [593/735], Loss: 0.3569\n",
      "Epoch [31/50], Step [594/735], Loss: 0.3263\n",
      "Epoch [31/50], Step [595/735], Loss: 0.5430\n",
      "Epoch [31/50], Step [596/735], Loss: 0.4814\n",
      "Epoch [31/50], Step [597/735], Loss: 0.1654\n",
      "Epoch [31/50], Step [598/735], Loss: 0.5245\n",
      "Epoch [31/50], Step [599/735], Loss: 0.6581\n",
      "Epoch [31/50], Step [600/735], Loss: 0.1273\n",
      "Epoch [31/50], Step [601/735], Loss: 0.4495\n",
      "Epoch [31/50], Step [602/735], Loss: 0.4062\n",
      "Epoch [31/50], Step [603/735], Loss: 0.2523\n",
      "Epoch [31/50], Step [604/735], Loss: 0.9325\n",
      "Epoch [31/50], Step [605/735], Loss: 0.3046\n",
      "Epoch [31/50], Step [606/735], Loss: 0.4189\n",
      "Epoch [31/50], Step [607/735], Loss: 1.4188\n",
      "Epoch [31/50], Step [608/735], Loss: 0.3034\n",
      "Epoch [31/50], Step [609/735], Loss: 0.1016\n",
      "Epoch [31/50], Step [610/735], Loss: 0.3175\n",
      "Epoch [31/50], Step [611/735], Loss: 0.1441\n",
      "Epoch [31/50], Step [612/735], Loss: 0.1758\n",
      "Epoch [31/50], Step [613/735], Loss: 1.8867\n",
      "Epoch [31/50], Step [614/735], Loss: 0.3539\n",
      "Epoch [31/50], Step [615/735], Loss: 0.2448\n",
      "Epoch [31/50], Step [616/735], Loss: 0.1962\n",
      "Epoch [31/50], Step [617/735], Loss: 0.6773\n",
      "Epoch [31/50], Step [618/735], Loss: 0.0786\n",
      "Epoch [31/50], Step [619/735], Loss: 0.6220\n",
      "Epoch [31/50], Step [620/735], Loss: 0.0495\n",
      "Epoch [31/50], Step [621/735], Loss: 0.2671\n",
      "Epoch [31/50], Step [622/735], Loss: 0.9285\n",
      "Epoch [31/50], Step [623/735], Loss: 0.6192\n",
      "Epoch [31/50], Step [624/735], Loss: 1.1302\n",
      "Epoch [31/50], Step [625/735], Loss: 0.2276\n",
      "Epoch [31/50], Step [626/735], Loss: 0.3315\n",
      "Epoch [31/50], Step [627/735], Loss: 0.4349\n",
      "Epoch [31/50], Step [628/735], Loss: 0.5285\n",
      "Epoch [31/50], Step [629/735], Loss: 0.2553\n",
      "Epoch [31/50], Step [630/735], Loss: 0.1076\n",
      "Epoch [31/50], Step [631/735], Loss: 0.4242\n",
      "Epoch [31/50], Step [632/735], Loss: 0.3765\n",
      "Epoch [31/50], Step [633/735], Loss: 0.1346\n",
      "Epoch [31/50], Step [634/735], Loss: 0.3187\n",
      "Epoch [31/50], Step [635/735], Loss: 0.5112\n",
      "Epoch [31/50], Step [636/735], Loss: 0.6509\n",
      "Epoch [31/50], Step [637/735], Loss: 0.5991\n",
      "Epoch [31/50], Step [638/735], Loss: 0.3445\n",
      "Epoch [31/50], Step [639/735], Loss: 0.1029\n",
      "Epoch [31/50], Step [640/735], Loss: 0.1374\n",
      "Epoch [31/50], Step [641/735], Loss: 0.1039\n",
      "Epoch [31/50], Step [642/735], Loss: 0.3021\n",
      "Epoch [31/50], Step [643/735], Loss: 0.2244\n",
      "Epoch [31/50], Step [644/735], Loss: 0.1537\n",
      "Epoch [31/50], Step [645/735], Loss: 0.2679\n",
      "Epoch [31/50], Step [646/735], Loss: 0.0955\n",
      "Epoch [31/50], Step [647/735], Loss: 0.2811\n",
      "Epoch [31/50], Step [648/735], Loss: 0.1344\n",
      "Epoch [31/50], Step [649/735], Loss: 0.1910\n",
      "Epoch [31/50], Step [650/735], Loss: 0.2199\n",
      "Epoch [31/50], Step [651/735], Loss: 0.1617\n",
      "Epoch [31/50], Step [652/735], Loss: 0.9200\n",
      "Epoch [31/50], Step [653/735], Loss: 0.3211\n",
      "Epoch [31/50], Step [654/735], Loss: 0.3325\n",
      "Epoch [31/50], Step [655/735], Loss: 0.0421\n",
      "Epoch [31/50], Step [656/735], Loss: 0.2611\n",
      "Epoch [31/50], Step [657/735], Loss: 1.2147\n",
      "Epoch [31/50], Step [658/735], Loss: 0.1553\n",
      "Epoch [31/50], Step [659/735], Loss: 0.1680\n",
      "Epoch [31/50], Step [660/735], Loss: 0.1619\n",
      "Epoch [31/50], Step [661/735], Loss: 0.1159\n",
      "Epoch [31/50], Step [662/735], Loss: 0.3225\n",
      "Epoch [31/50], Step [663/735], Loss: 0.3285\n",
      "Epoch [31/50], Step [664/735], Loss: 0.3399\n",
      "Epoch [31/50], Step [665/735], Loss: 0.2759\n",
      "Epoch [31/50], Step [666/735], Loss: 0.6536\n",
      "Epoch [31/50], Step [667/735], Loss: 0.2141\n",
      "Epoch [31/50], Step [668/735], Loss: 0.6096\n",
      "Epoch [31/50], Step [669/735], Loss: 0.2434\n",
      "Epoch [31/50], Step [670/735], Loss: 0.4397\n",
      "Epoch [31/50], Step [671/735], Loss: 0.1823\n",
      "Epoch [31/50], Step [672/735], Loss: 0.3617\n",
      "Epoch [31/50], Step [673/735], Loss: 0.3829\n",
      "Epoch [31/50], Step [674/735], Loss: 0.2697\n",
      "Epoch [31/50], Step [675/735], Loss: 1.1697\n",
      "Epoch [31/50], Step [676/735], Loss: 1.2789\n",
      "Epoch [31/50], Step [677/735], Loss: 0.3945\n",
      "Epoch [31/50], Step [678/735], Loss: 0.0844\n",
      "Epoch [31/50], Step [679/735], Loss: 0.4886\n",
      "Epoch [31/50], Step [680/735], Loss: 0.2216\n",
      "Epoch [31/50], Step [681/735], Loss: 0.3447\n",
      "Epoch [31/50], Step [682/735], Loss: 0.3971\n",
      "Epoch [31/50], Step [683/735], Loss: 0.0804\n",
      "Epoch [31/50], Step [684/735], Loss: 0.2094\n",
      "Epoch [31/50], Step [685/735], Loss: 0.1406\n",
      "Epoch [31/50], Step [686/735], Loss: 0.4490\n",
      "Epoch [31/50], Step [687/735], Loss: 0.1775\n",
      "Epoch [31/50], Step [688/735], Loss: 0.1190\n",
      "Epoch [31/50], Step [689/735], Loss: 0.2935\n",
      "Epoch [31/50], Step [690/735], Loss: 0.1989\n",
      "Epoch [31/50], Step [691/735], Loss: 0.6460\n",
      "Epoch [31/50], Step [692/735], Loss: 0.5796\n",
      "Epoch [31/50], Step [693/735], Loss: 0.1261\n",
      "Epoch [31/50], Step [694/735], Loss: 0.2044\n",
      "Epoch [31/50], Step [695/735], Loss: 0.0770\n",
      "Epoch [31/50], Step [696/735], Loss: 0.3045\n",
      "Epoch [31/50], Step [697/735], Loss: 0.1138\n",
      "Epoch [31/50], Step [698/735], Loss: 0.3564\n",
      "Epoch [31/50], Step [699/735], Loss: 0.1384\n",
      "Epoch [31/50], Step [700/735], Loss: 0.2229\n",
      "Epoch [31/50], Step [701/735], Loss: 0.3370\n",
      "Epoch [31/50], Step [702/735], Loss: 0.2984\n",
      "Epoch [31/50], Step [703/735], Loss: 0.8403\n",
      "Epoch [31/50], Step [704/735], Loss: 0.2585\n",
      "Epoch [31/50], Step [705/735], Loss: 0.4281\n",
      "Epoch [31/50], Step [706/735], Loss: 0.2936\n",
      "Epoch [31/50], Step [707/735], Loss: 0.3268\n",
      "Epoch [31/50], Step [708/735], Loss: 0.4522\n",
      "Epoch [31/50], Step [709/735], Loss: 0.1267\n",
      "Epoch [31/50], Step [710/735], Loss: 0.4059\n",
      "Epoch [31/50], Step [711/735], Loss: 0.1206\n",
      "Epoch [31/50], Step [712/735], Loss: 0.2430\n",
      "Epoch [31/50], Step [713/735], Loss: 0.4311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Step [714/735], Loss: 0.4804\n",
      "Epoch [31/50], Step [715/735], Loss: 0.3974\n",
      "Epoch [31/50], Step [716/735], Loss: 0.3395\n",
      "Epoch [31/50], Step [717/735], Loss: 0.1478\n",
      "Epoch [31/50], Step [718/735], Loss: 0.4392\n",
      "Epoch [31/50], Step [719/735], Loss: 0.2591\n",
      "Epoch [31/50], Step [720/735], Loss: 0.3342\n",
      "Epoch [31/50], Step [721/735], Loss: 0.6022\n",
      "Epoch [31/50], Step [722/735], Loss: 0.5464\n",
      "Epoch [31/50], Step [723/735], Loss: 0.5214\n",
      "Epoch [31/50], Step [724/735], Loss: 0.2289\n",
      "Epoch [31/50], Step [725/735], Loss: 0.2742\n",
      "Epoch [31/50], Step [726/735], Loss: 0.4384\n",
      "Epoch [31/50], Step [727/735], Loss: 0.2537\n",
      "Epoch [31/50], Step [728/735], Loss: 0.2072\n",
      "Epoch [31/50], Step [729/735], Loss: 0.4717\n",
      "Epoch [31/50], Step [730/735], Loss: 0.2062\n",
      "Epoch [31/50], Step [731/735], Loss: 0.6438\n",
      "Epoch [31/50], Step [732/735], Loss: 0.3235\n",
      "Epoch [31/50], Step [733/735], Loss: 0.6011\n",
      "Epoch [31/50], Step [734/735], Loss: 0.4462\n",
      "Epoch [31/50], Step [735/735], Loss: 0.3359\n",
      "Epoch [32/50], Step [1/735], Loss: 0.2107\n",
      "Epoch [32/50], Step [2/735], Loss: 0.3325\n",
      "Epoch [32/50], Step [3/735], Loss: 0.1696\n",
      "Epoch [32/50], Step [4/735], Loss: 0.1160\n",
      "Epoch [32/50], Step [5/735], Loss: 0.2055\n",
      "Epoch [32/50], Step [6/735], Loss: 0.3867\n",
      "Epoch [32/50], Step [7/735], Loss: 0.1634\n",
      "Epoch [32/50], Step [8/735], Loss: 0.3194\n",
      "Epoch [32/50], Step [9/735], Loss: 0.1105\n",
      "Epoch [32/50], Step [10/735], Loss: 0.0874\n",
      "Epoch [32/50], Step [11/735], Loss: 0.2954\n",
      "Epoch [32/50], Step [12/735], Loss: 0.2094\n",
      "Epoch [32/50], Step [13/735], Loss: 0.1870\n",
      "Epoch [32/50], Step [14/735], Loss: 0.3230\n",
      "Epoch [32/50], Step [15/735], Loss: 0.2835\n",
      "Epoch [32/50], Step [16/735], Loss: 0.0822\n",
      "Epoch [32/50], Step [17/735], Loss: 0.4094\n",
      "Epoch [32/50], Step [18/735], Loss: 0.1823\n",
      "Epoch [32/50], Step [19/735], Loss: 0.0724\n",
      "Epoch [32/50], Step [20/735], Loss: 0.2602\n",
      "Epoch [32/50], Step [21/735], Loss: 0.8807\n",
      "Epoch [32/50], Step [22/735], Loss: 0.3726\n",
      "Epoch [32/50], Step [23/735], Loss: 0.2879\n",
      "Epoch [32/50], Step [24/735], Loss: 0.5059\n",
      "Epoch [32/50], Step [25/735], Loss: 0.2188\n",
      "Epoch [32/50], Step [26/735], Loss: 0.5636\n",
      "Epoch [32/50], Step [27/735], Loss: 0.2495\n",
      "Epoch [32/50], Step [28/735], Loss: 0.2193\n",
      "Epoch [32/50], Step [29/735], Loss: 0.4376\n",
      "Epoch [32/50], Step [30/735], Loss: 0.1892\n",
      "Epoch [32/50], Step [31/735], Loss: 0.5063\n",
      "Epoch [32/50], Step [32/735], Loss: 1.1667\n",
      "Epoch [32/50], Step [33/735], Loss: 0.3406\n",
      "Epoch [32/50], Step [34/735], Loss: 0.4517\n",
      "Epoch [32/50], Step [35/735], Loss: 0.2044\n",
      "Epoch [32/50], Step [36/735], Loss: 0.2470\n",
      "Epoch [32/50], Step [37/735], Loss: 0.3228\n",
      "Epoch [32/50], Step [38/735], Loss: 0.5709\n",
      "Epoch [32/50], Step [39/735], Loss: 0.1101\n",
      "Epoch [32/50], Step [40/735], Loss: 0.2373\n",
      "Epoch [32/50], Step [41/735], Loss: 0.1768\n",
      "Epoch [32/50], Step [42/735], Loss: 0.2833\n",
      "Epoch [32/50], Step [43/735], Loss: 0.4126\n",
      "Epoch [32/50], Step [44/735], Loss: 0.1743\n",
      "Epoch [32/50], Step [45/735], Loss: 0.1492\n",
      "Epoch [32/50], Step [46/735], Loss: 0.2460\n",
      "Epoch [32/50], Step [47/735], Loss: 0.2686\n",
      "Epoch [32/50], Step [48/735], Loss: 0.4437\n",
      "Epoch [32/50], Step [49/735], Loss: 0.4001\n",
      "Epoch [32/50], Step [50/735], Loss: 0.2558\n",
      "Epoch [32/50], Step [51/735], Loss: 0.4528\n",
      "Epoch [32/50], Step [52/735], Loss: 0.6144\n",
      "Epoch [32/50], Step [53/735], Loss: 0.1373\n",
      "Epoch [32/50], Step [54/735], Loss: 0.3132\n",
      "Epoch [32/50], Step [55/735], Loss: 0.4481\n",
      "Epoch [32/50], Step [56/735], Loss: 0.4273\n",
      "Epoch [32/50], Step [57/735], Loss: 0.2582\n",
      "Epoch [32/50], Step [58/735], Loss: 0.1692\n",
      "Epoch [32/50], Step [59/735], Loss: 0.4931\n",
      "Epoch [32/50], Step [60/735], Loss: 0.3214\n",
      "Epoch [32/50], Step [61/735], Loss: 0.3946\n",
      "Epoch [32/50], Step [62/735], Loss: 0.3206\n",
      "Epoch [32/50], Step [63/735], Loss: 0.1492\n",
      "Epoch [32/50], Step [64/735], Loss: 0.1038\n",
      "Epoch [32/50], Step [65/735], Loss: 0.2663\n",
      "Epoch [32/50], Step [66/735], Loss: 0.3028\n",
      "Epoch [32/50], Step [67/735], Loss: 0.1909\n",
      "Epoch [32/50], Step [68/735], Loss: 0.1152\n",
      "Epoch [32/50], Step [69/735], Loss: 0.3755\n",
      "Epoch [32/50], Step [70/735], Loss: 0.4553\n",
      "Epoch [32/50], Step [71/735], Loss: 0.0763\n",
      "Epoch [32/50], Step [72/735], Loss: 0.1116\n",
      "Epoch [32/50], Step [73/735], Loss: 0.7031\n",
      "Epoch [32/50], Step [74/735], Loss: 0.1485\n",
      "Epoch [32/50], Step [75/735], Loss: 0.1636\n",
      "Epoch [32/50], Step [76/735], Loss: 0.1855\n",
      "Epoch [32/50], Step [77/735], Loss: 0.2708\n",
      "Epoch [32/50], Step [78/735], Loss: 0.2396\n",
      "Epoch [32/50], Step [79/735], Loss: 0.3131\n",
      "Epoch [32/50], Step [80/735], Loss: 0.7773\n",
      "Epoch [32/50], Step [81/735], Loss: 0.5849\n",
      "Epoch [32/50], Step [82/735], Loss: 0.1353\n",
      "Epoch [32/50], Step [83/735], Loss: 0.1589\n",
      "Epoch [32/50], Step [84/735], Loss: 0.1154\n",
      "Epoch [32/50], Step [85/735], Loss: 0.6751\n",
      "Epoch [32/50], Step [86/735], Loss: 0.3397\n",
      "Epoch [32/50], Step [87/735], Loss: 0.0711\n",
      "Epoch [32/50], Step [88/735], Loss: 0.4445\n",
      "Epoch [32/50], Step [89/735], Loss: 0.0973\n",
      "Epoch [32/50], Step [90/735], Loss: 0.1094\n",
      "Epoch [32/50], Step [91/735], Loss: 0.2884\n",
      "Epoch [32/50], Step [92/735], Loss: 0.3353\n",
      "Epoch [32/50], Step [93/735], Loss: 0.1906\n",
      "Epoch [32/50], Step [94/735], Loss: 0.4565\n",
      "Epoch [32/50], Step [95/735], Loss: 0.6099\n",
      "Epoch [32/50], Step [96/735], Loss: 0.3559\n",
      "Epoch [32/50], Step [97/735], Loss: 0.3566\n",
      "Epoch [32/50], Step [98/735], Loss: 0.4352\n",
      "Epoch [32/50], Step [99/735], Loss: 0.2117\n",
      "Epoch [32/50], Step [100/735], Loss: 0.2418\n",
      "Epoch [32/50], Step [101/735], Loss: 0.4040\n",
      "Epoch [32/50], Step [102/735], Loss: 0.1929\n",
      "Epoch [32/50], Step [103/735], Loss: 0.1673\n",
      "Epoch [32/50], Step [104/735], Loss: 0.1086\n",
      "Epoch [32/50], Step [105/735], Loss: 0.4013\n",
      "Epoch [32/50], Step [106/735], Loss: 0.0899\n",
      "Epoch [32/50], Step [107/735], Loss: 0.3363\n",
      "Epoch [32/50], Step [108/735], Loss: 0.7209\n",
      "Epoch [32/50], Step [109/735], Loss: 0.3400\n",
      "Epoch [32/50], Step [110/735], Loss: 0.3223\n",
      "Epoch [32/50], Step [111/735], Loss: 0.1334\n",
      "Epoch [32/50], Step [112/735], Loss: 0.0976\n",
      "Epoch [32/50], Step [113/735], Loss: 0.1081\n",
      "Epoch [32/50], Step [114/735], Loss: 0.1269\n",
      "Epoch [32/50], Step [115/735], Loss: 0.0896\n",
      "Epoch [32/50], Step [116/735], Loss: 0.2437\n",
      "Epoch [32/50], Step [117/735], Loss: 0.1895\n",
      "Epoch [32/50], Step [118/735], Loss: 0.4363\n",
      "Epoch [32/50], Step [119/735], Loss: 1.4170\n",
      "Epoch [32/50], Step [120/735], Loss: 0.4591\n",
      "Epoch [32/50], Step [121/735], Loss: 0.5496\n",
      "Epoch [32/50], Step [122/735], Loss: 0.1358\n",
      "Epoch [32/50], Step [123/735], Loss: 0.7792\n",
      "Epoch [32/50], Step [124/735], Loss: 0.2012\n",
      "Epoch [32/50], Step [125/735], Loss: 0.2900\n",
      "Epoch [32/50], Step [126/735], Loss: 0.2487\n",
      "Epoch [32/50], Step [127/735], Loss: 0.2637\n",
      "Epoch [32/50], Step [128/735], Loss: 0.2612\n",
      "Epoch [32/50], Step [129/735], Loss: 0.7061\n",
      "Epoch [32/50], Step [130/735], Loss: 0.2661\n",
      "Epoch [32/50], Step [131/735], Loss: 2.5750\n",
      "Epoch [32/50], Step [132/735], Loss: 0.0894\n",
      "Epoch [32/50], Step [133/735], Loss: 0.2938\n",
      "Epoch [32/50], Step [134/735], Loss: 0.3819\n",
      "Epoch [32/50], Step [135/735], Loss: 0.5327\n",
      "Epoch [32/50], Step [136/735], Loss: 0.0801\n",
      "Epoch [32/50], Step [137/735], Loss: 0.2739\n",
      "Epoch [32/50], Step [138/735], Loss: 0.1166\n",
      "Epoch [32/50], Step [139/735], Loss: 0.2177\n",
      "Epoch [32/50], Step [140/735], Loss: 0.1193\n",
      "Epoch [32/50], Step [141/735], Loss: 0.6806\n",
      "Epoch [32/50], Step [142/735], Loss: 0.0911\n",
      "Epoch [32/50], Step [143/735], Loss: 0.3753\n",
      "Epoch [32/50], Step [144/735], Loss: 0.3932\n",
      "Epoch [32/50], Step [145/735], Loss: 0.5121\n",
      "Epoch [32/50], Step [146/735], Loss: 0.1030\n",
      "Epoch [32/50], Step [147/735], Loss: 0.2828\n",
      "Epoch [32/50], Step [148/735], Loss: 0.2483\n",
      "Epoch [32/50], Step [149/735], Loss: 0.2818\n",
      "Epoch [32/50], Step [150/735], Loss: 0.4027\n",
      "Epoch [32/50], Step [151/735], Loss: 0.3381\n",
      "Epoch [32/50], Step [152/735], Loss: 0.1818\n",
      "Epoch [32/50], Step [153/735], Loss: 0.4144\n",
      "Epoch [32/50], Step [154/735], Loss: 0.2108\n",
      "Epoch [32/50], Step [155/735], Loss: 0.0906\n",
      "Epoch [32/50], Step [156/735], Loss: 0.1601\n",
      "Epoch [32/50], Step [157/735], Loss: 0.4076\n",
      "Epoch [32/50], Step [158/735], Loss: 0.2752\n",
      "Epoch [32/50], Step [159/735], Loss: 0.9031\n",
      "Epoch [32/50], Step [160/735], Loss: 0.1779\n",
      "Epoch [32/50], Step [161/735], Loss: 0.0982\n",
      "Epoch [32/50], Step [162/735], Loss: 0.4105\n",
      "Epoch [32/50], Step [163/735], Loss: 0.1372\n",
      "Epoch [32/50], Step [164/735], Loss: 0.1273\n",
      "Epoch [32/50], Step [165/735], Loss: 0.2049\n",
      "Epoch [32/50], Step [166/735], Loss: 0.3451\n",
      "Epoch [32/50], Step [167/735], Loss: 0.1429\n",
      "Epoch [32/50], Step [168/735], Loss: 0.1934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Step [169/735], Loss: 0.4243\n",
      "Epoch [32/50], Step [170/735], Loss: 0.2008\n",
      "Epoch [32/50], Step [171/735], Loss: 0.1204\n",
      "Epoch [32/50], Step [172/735], Loss: 0.7886\n",
      "Epoch [32/50], Step [173/735], Loss: 0.2075\n",
      "Epoch [32/50], Step [174/735], Loss: 0.1548\n",
      "Epoch [32/50], Step [175/735], Loss: 0.2169\n",
      "Epoch [32/50], Step [176/735], Loss: 0.2744\n",
      "Epoch [32/50], Step [177/735], Loss: 0.1139\n",
      "Epoch [32/50], Step [178/735], Loss: 0.2148\n",
      "Epoch [32/50], Step [179/735], Loss: 0.2674\n",
      "Epoch [32/50], Step [180/735], Loss: 0.4954\n",
      "Epoch [32/50], Step [181/735], Loss: 0.2042\n",
      "Epoch [32/50], Step [182/735], Loss: 0.4045\n",
      "Epoch [32/50], Step [183/735], Loss: 0.2754\n",
      "Epoch [32/50], Step [184/735], Loss: 0.2823\n",
      "Epoch [32/50], Step [185/735], Loss: 0.2473\n",
      "Epoch [32/50], Step [186/735], Loss: 0.1813\n",
      "Epoch [32/50], Step [187/735], Loss: 0.1653\n",
      "Epoch [32/50], Step [188/735], Loss: 0.0988\n",
      "Epoch [32/50], Step [189/735], Loss: 0.3331\n",
      "Epoch [32/50], Step [190/735], Loss: 0.4403\n",
      "Epoch [32/50], Step [191/735], Loss: 0.2709\n",
      "Epoch [32/50], Step [192/735], Loss: 0.9009\n",
      "Epoch [32/50], Step [193/735], Loss: 0.3813\n",
      "Epoch [32/50], Step [194/735], Loss: 1.2609\n",
      "Epoch [32/50], Step [195/735], Loss: 0.6922\n",
      "Epoch [32/50], Step [196/735], Loss: 0.6641\n",
      "Epoch [32/50], Step [197/735], Loss: 0.3021\n",
      "Epoch [32/50], Step [198/735], Loss: 0.1716\n",
      "Epoch [32/50], Step [199/735], Loss: 0.6361\n",
      "Epoch [32/50], Step [200/735], Loss: 0.1372\n",
      "Epoch [32/50], Step [201/735], Loss: 0.5743\n",
      "Epoch [32/50], Step [202/735], Loss: 0.1598\n",
      "Epoch [32/50], Step [203/735], Loss: 0.4866\n",
      "Epoch [32/50], Step [204/735], Loss: 0.3842\n",
      "Epoch [32/50], Step [205/735], Loss: 0.2471\n",
      "Epoch [32/50], Step [206/735], Loss: 0.7995\n",
      "Epoch [32/50], Step [207/735], Loss: 0.1169\n",
      "Epoch [32/50], Step [208/735], Loss: 0.1133\n",
      "Epoch [32/50], Step [209/735], Loss: 0.2659\n",
      "Epoch [32/50], Step [210/735], Loss: 0.2918\n",
      "Epoch [32/50], Step [211/735], Loss: 0.7971\n",
      "Epoch [32/50], Step [212/735], Loss: 0.5908\n",
      "Epoch [32/50], Step [213/735], Loss: 0.3775\n",
      "Epoch [32/50], Step [214/735], Loss: 0.1845\n",
      "Epoch [32/50], Step [215/735], Loss: 0.2854\n",
      "Epoch [32/50], Step [216/735], Loss: 0.1481\n",
      "Epoch [32/50], Step [217/735], Loss: 0.5623\n",
      "Epoch [32/50], Step [218/735], Loss: 0.1077\n",
      "Epoch [32/50], Step [219/735], Loss: 0.1881\n",
      "Epoch [32/50], Step [220/735], Loss: 0.0741\n",
      "Epoch [32/50], Step [221/735], Loss: 0.4140\n",
      "Epoch [32/50], Step [222/735], Loss: 0.0354\n",
      "Epoch [32/50], Step [223/735], Loss: 0.1768\n",
      "Epoch [32/50], Step [224/735], Loss: 0.2575\n",
      "Epoch [32/50], Step [225/735], Loss: 0.6016\n",
      "Epoch [32/50], Step [226/735], Loss: 0.1119\n",
      "Epoch [32/50], Step [227/735], Loss: 0.0494\n",
      "Epoch [32/50], Step [228/735], Loss: 0.2854\n",
      "Epoch [32/50], Step [229/735], Loss: 0.1095\n",
      "Epoch [32/50], Step [230/735], Loss: 0.1846\n",
      "Epoch [32/50], Step [231/735], Loss: 0.1286\n",
      "Epoch [32/50], Step [232/735], Loss: 0.2844\n",
      "Epoch [32/50], Step [233/735], Loss: 0.8147\n",
      "Epoch [32/50], Step [234/735], Loss: 0.1629\n",
      "Epoch [32/50], Step [235/735], Loss: 0.0756\n",
      "Epoch [32/50], Step [236/735], Loss: 0.3244\n",
      "Epoch [32/50], Step [237/735], Loss: 0.1228\n",
      "Epoch [32/50], Step [238/735], Loss: 0.4055\n",
      "Epoch [32/50], Step [239/735], Loss: 0.3145\n",
      "Epoch [32/50], Step [240/735], Loss: 0.2639\n",
      "Epoch [32/50], Step [241/735], Loss: 0.3281\n",
      "Epoch [32/50], Step [242/735], Loss: 1.0721\n",
      "Epoch [32/50], Step [243/735], Loss: 0.1186\n",
      "Epoch [32/50], Step [244/735], Loss: 0.4453\n",
      "Epoch [32/50], Step [245/735], Loss: 0.1382\n",
      "Epoch [32/50], Step [246/735], Loss: 0.6563\n",
      "Epoch [32/50], Step [247/735], Loss: 0.6073\n",
      "Epoch [32/50], Step [248/735], Loss: 0.4393\n",
      "Epoch [32/50], Step [249/735], Loss: 0.2282\n",
      "Epoch [32/50], Step [250/735], Loss: 0.4204\n",
      "Epoch [32/50], Step [251/735], Loss: 0.2125\n",
      "Epoch [32/50], Step [252/735], Loss: 0.5328\n",
      "Epoch [32/50], Step [253/735], Loss: 0.2819\n",
      "Epoch [32/50], Step [254/735], Loss: 0.2021\n",
      "Epoch [32/50], Step [255/735], Loss: 0.5531\n",
      "Epoch [32/50], Step [256/735], Loss: 0.2177\n",
      "Epoch [32/50], Step [257/735], Loss: 0.1039\n",
      "Epoch [32/50], Step [258/735], Loss: 0.4458\n",
      "Epoch [32/50], Step [259/735], Loss: 0.3689\n",
      "Epoch [32/50], Step [260/735], Loss: 1.1821\n",
      "Epoch [32/50], Step [261/735], Loss: 0.5262\n",
      "Epoch [32/50], Step [262/735], Loss: 0.1941\n",
      "Epoch [32/50], Step [263/735], Loss: 0.4711\n",
      "Epoch [32/50], Step [264/735], Loss: 1.3163\n",
      "Epoch [32/50], Step [265/735], Loss: 0.0591\n",
      "Epoch [32/50], Step [266/735], Loss: 0.7994\n",
      "Epoch [32/50], Step [267/735], Loss: 0.8126\n",
      "Epoch [32/50], Step [268/735], Loss: 0.1992\n",
      "Epoch [32/50], Step [269/735], Loss: 0.5542\n",
      "Epoch [32/50], Step [270/735], Loss: 0.3181\n",
      "Epoch [32/50], Step [271/735], Loss: 0.8473\n",
      "Epoch [32/50], Step [272/735], Loss: 0.3319\n",
      "Epoch [32/50], Step [273/735], Loss: 0.1923\n",
      "Epoch [32/50], Step [274/735], Loss: 0.5650\n",
      "Epoch [32/50], Step [275/735], Loss: 0.3455\n",
      "Epoch [32/50], Step [276/735], Loss: 3.9997\n",
      "Epoch [32/50], Step [277/735], Loss: 0.2250\n",
      "Epoch [32/50], Step [278/735], Loss: 0.7450\n",
      "Epoch [32/50], Step [279/735], Loss: 0.2731\n",
      "Epoch [32/50], Step [280/735], Loss: 0.4884\n",
      "Epoch [32/50], Step [281/735], Loss: 1.6352\n",
      "Epoch [32/50], Step [282/735], Loss: 0.3017\n",
      "Epoch [32/50], Step [283/735], Loss: 1.5786\n",
      "Epoch [32/50], Step [284/735], Loss: 0.5964\n",
      "Epoch [32/50], Step [285/735], Loss: 0.3720\n",
      "Epoch [32/50], Step [286/735], Loss: 3.7979\n",
      "Epoch [32/50], Step [287/735], Loss: 0.6855\n",
      "Epoch [32/50], Step [288/735], Loss: 0.2421\n",
      "Epoch [32/50], Step [289/735], Loss: 1.0089\n",
      "Epoch [32/50], Step [290/735], Loss: 0.3630\n",
      "Epoch [32/50], Step [291/735], Loss: 0.4025\n",
      "Epoch [32/50], Step [292/735], Loss: 0.1068\n",
      "Epoch [32/50], Step [293/735], Loss: 0.1660\n",
      "Epoch [32/50], Step [294/735], Loss: 0.1315\n",
      "Epoch [32/50], Step [295/735], Loss: 0.0740\n",
      "Epoch [32/50], Step [296/735], Loss: 0.3317\n",
      "Epoch [32/50], Step [297/735], Loss: 0.5427\n",
      "Epoch [32/50], Step [298/735], Loss: 0.0956\n",
      "Epoch [32/50], Step [299/735], Loss: 0.5157\n",
      "Epoch [32/50], Step [300/735], Loss: 0.6432\n",
      "Epoch [32/50], Step [301/735], Loss: 0.2492\n",
      "Epoch [32/50], Step [302/735], Loss: 0.5864\n",
      "Epoch [32/50], Step [303/735], Loss: 0.3299\n",
      "Epoch [32/50], Step [304/735], Loss: 0.4978\n",
      "Epoch [32/50], Step [305/735], Loss: 0.3630\n",
      "Epoch [32/50], Step [306/735], Loss: 0.1142\n",
      "Epoch [32/50], Step [307/735], Loss: 0.2318\n",
      "Epoch [32/50], Step [308/735], Loss: 0.1905\n",
      "Epoch [32/50], Step [309/735], Loss: 0.2432\n",
      "Epoch [32/50], Step [310/735], Loss: 0.8682\n",
      "Epoch [32/50], Step [311/735], Loss: 0.2553\n",
      "Epoch [32/50], Step [312/735], Loss: 0.2213\n",
      "Epoch [32/50], Step [313/735], Loss: 0.3854\n",
      "Epoch [32/50], Step [314/735], Loss: 0.2343\n",
      "Epoch [32/50], Step [315/735], Loss: 0.2346\n",
      "Epoch [32/50], Step [316/735], Loss: 0.2708\n",
      "Epoch [32/50], Step [317/735], Loss: 0.1784\n",
      "Epoch [32/50], Step [318/735], Loss: 0.1282\n",
      "Epoch [32/50], Step [319/735], Loss: 0.2975\n",
      "Epoch [32/50], Step [320/735], Loss: 0.3721\n",
      "Epoch [32/50], Step [321/735], Loss: 1.8660\n",
      "Epoch [32/50], Step [322/735], Loss: 0.1393\n",
      "Epoch [32/50], Step [323/735], Loss: 0.4223\n",
      "Epoch [32/50], Step [324/735], Loss: 0.2278\n",
      "Epoch [32/50], Step [325/735], Loss: 0.1711\n",
      "Epoch [32/50], Step [326/735], Loss: 0.4211\n",
      "Epoch [32/50], Step [327/735], Loss: 0.2894\n",
      "Epoch [32/50], Step [328/735], Loss: 0.1570\n",
      "Epoch [32/50], Step [329/735], Loss: 0.4668\n",
      "Epoch [32/50], Step [330/735], Loss: 0.4398\n",
      "Epoch [32/50], Step [331/735], Loss: 0.3638\n",
      "Epoch [32/50], Step [332/735], Loss: 0.1062\n",
      "Epoch [32/50], Step [333/735], Loss: 0.3339\n",
      "Epoch [32/50], Step [334/735], Loss: 0.3070\n",
      "Epoch [32/50], Step [335/735], Loss: 0.3346\n",
      "Epoch [32/50], Step [336/735], Loss: 0.1169\n",
      "Epoch [32/50], Step [337/735], Loss: 0.1470\n",
      "Epoch [32/50], Step [338/735], Loss: 0.2727\n",
      "Epoch [32/50], Step [339/735], Loss: 0.2827\n",
      "Epoch [32/50], Step [340/735], Loss: 0.2605\n",
      "Epoch [32/50], Step [341/735], Loss: 0.2199\n",
      "Epoch [32/50], Step [342/735], Loss: 0.1682\n",
      "Epoch [32/50], Step [343/735], Loss: 0.6646\n",
      "Epoch [32/50], Step [344/735], Loss: 0.1713\n",
      "Epoch [32/50], Step [345/735], Loss: 0.4081\n",
      "Epoch [32/50], Step [346/735], Loss: 0.1255\n",
      "Epoch [32/50], Step [347/735], Loss: 0.1320\n",
      "Epoch [32/50], Step [348/735], Loss: 0.3172\n",
      "Epoch [32/50], Step [349/735], Loss: 0.2428\n",
      "Epoch [32/50], Step [350/735], Loss: 0.1408\n",
      "Epoch [32/50], Step [351/735], Loss: 0.3021\n",
      "Epoch [32/50], Step [352/735], Loss: 0.1386\n",
      "Epoch [32/50], Step [353/735], Loss: 0.1129\n",
      "Epoch [32/50], Step [354/735], Loss: 0.2374\n",
      "Epoch [32/50], Step [355/735], Loss: 0.2177\n",
      "Epoch [32/50], Step [356/735], Loss: 0.4603\n",
      "Epoch [32/50], Step [357/735], Loss: 0.0664\n",
      "Epoch [32/50], Step [358/735], Loss: 0.1151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Step [359/735], Loss: 0.1679\n",
      "Epoch [32/50], Step [360/735], Loss: 0.4047\n",
      "Epoch [32/50], Step [361/735], Loss: 0.3062\n",
      "Epoch [32/50], Step [362/735], Loss: 0.1415\n",
      "Epoch [32/50], Step [363/735], Loss: 0.3779\n",
      "Epoch [32/50], Step [364/735], Loss: 0.1991\n",
      "Epoch [32/50], Step [365/735], Loss: 0.2775\n",
      "Epoch [32/50], Step [366/735], Loss: 0.6152\n",
      "Epoch [32/50], Step [367/735], Loss: 0.3644\n",
      "Epoch [32/50], Step [368/735], Loss: 0.5006\n",
      "Epoch [32/50], Step [369/735], Loss: 0.1002\n",
      "Epoch [32/50], Step [370/735], Loss: 0.8216\n",
      "Epoch [32/50], Step [371/735], Loss: 0.3480\n",
      "Epoch [32/50], Step [372/735], Loss: 0.3469\n",
      "Epoch [32/50], Step [373/735], Loss: 0.2478\n",
      "Epoch [32/50], Step [374/735], Loss: 4.2813\n",
      "Epoch [32/50], Step [375/735], Loss: 0.1768\n",
      "Epoch [32/50], Step [376/735], Loss: 1.0758\n",
      "Epoch [32/50], Step [377/735], Loss: 0.7666\n",
      "Epoch [32/50], Step [378/735], Loss: 0.3784\n",
      "Epoch [32/50], Step [379/735], Loss: 0.2076\n",
      "Epoch [32/50], Step [380/735], Loss: 0.3401\n",
      "Epoch [32/50], Step [381/735], Loss: 0.3610\n",
      "Epoch [32/50], Step [382/735], Loss: 0.3899\n",
      "Epoch [32/50], Step [383/735], Loss: 1.1737\n",
      "Epoch [32/50], Step [384/735], Loss: 0.2353\n",
      "Epoch [32/50], Step [385/735], Loss: 0.3582\n",
      "Epoch [32/50], Step [386/735], Loss: 0.1233\n",
      "Epoch [32/50], Step [387/735], Loss: 0.1201\n",
      "Epoch [32/50], Step [388/735], Loss: 0.0748\n",
      "Epoch [32/50], Step [389/735], Loss: 0.3774\n",
      "Epoch [32/50], Step [390/735], Loss: 0.4541\n",
      "Epoch [32/50], Step [391/735], Loss: 0.4545\n",
      "Epoch [32/50], Step [392/735], Loss: 0.2405\n",
      "Epoch [32/50], Step [393/735], Loss: 0.9692\n",
      "Epoch [32/50], Step [394/735], Loss: 0.1461\n",
      "Epoch [32/50], Step [395/735], Loss: 0.3221\n",
      "Epoch [32/50], Step [396/735], Loss: 0.6052\n",
      "Epoch [32/50], Step [397/735], Loss: 1.0913\n",
      "Epoch [32/50], Step [398/735], Loss: 0.1637\n",
      "Epoch [32/50], Step [399/735], Loss: 0.1913\n",
      "Epoch [32/50], Step [400/735], Loss: 1.1976\n",
      "Epoch [32/50], Step [401/735], Loss: 0.2064\n",
      "Epoch [32/50], Step [402/735], Loss: 0.4210\n",
      "Epoch [32/50], Step [403/735], Loss: 0.1054\n",
      "Epoch [32/50], Step [404/735], Loss: 0.3894\n",
      "Epoch [32/50], Step [405/735], Loss: 0.2922\n",
      "Epoch [32/50], Step [406/735], Loss: 0.3220\n",
      "Epoch [32/50], Step [407/735], Loss: 0.2618\n",
      "Epoch [32/50], Step [408/735], Loss: 0.4129\n",
      "Epoch [32/50], Step [409/735], Loss: 0.2629\n",
      "Epoch [32/50], Step [410/735], Loss: 0.2975\n",
      "Epoch [32/50], Step [411/735], Loss: 0.1030\n",
      "Epoch [32/50], Step [412/735], Loss: 0.1942\n",
      "Epoch [32/50], Step [413/735], Loss: 0.9778\n",
      "Epoch [32/50], Step [414/735], Loss: 0.3417\n",
      "Epoch [32/50], Step [415/735], Loss: 0.2601\n",
      "Epoch [32/50], Step [416/735], Loss: 0.4361\n",
      "Epoch [32/50], Step [417/735], Loss: 0.1697\n",
      "Epoch [32/50], Step [418/735], Loss: 0.2105\n",
      "Epoch [32/50], Step [419/735], Loss: 0.5048\n",
      "Epoch [32/50], Step [420/735], Loss: 0.2582\n",
      "Epoch [32/50], Step [421/735], Loss: 0.1489\n",
      "Epoch [32/50], Step [422/735], Loss: 0.1652\n",
      "Epoch [32/50], Step [423/735], Loss: 0.4711\n",
      "Epoch [32/50], Step [424/735], Loss: 0.2130\n",
      "Epoch [32/50], Step [425/735], Loss: 0.7445\n",
      "Epoch [32/50], Step [426/735], Loss: 0.1074\n",
      "Epoch [32/50], Step [427/735], Loss: 0.0533\n",
      "Epoch [32/50], Step [428/735], Loss: 0.3255\n",
      "Epoch [32/50], Step [429/735], Loss: 0.1586\n",
      "Epoch [32/50], Step [430/735], Loss: 0.5356\n",
      "Epoch [32/50], Step [431/735], Loss: 0.4433\n",
      "Epoch [32/50], Step [432/735], Loss: 0.0933\n",
      "Epoch [32/50], Step [433/735], Loss: 0.1206\n",
      "Epoch [32/50], Step [434/735], Loss: 0.1169\n",
      "Epoch [32/50], Step [435/735], Loss: 0.2462\n",
      "Epoch [32/50], Step [436/735], Loss: 0.1816\n",
      "Epoch [32/50], Step [437/735], Loss: 0.3555\n",
      "Epoch [32/50], Step [438/735], Loss: 0.6918\n",
      "Epoch [32/50], Step [439/735], Loss: 0.3992\n",
      "Epoch [32/50], Step [440/735], Loss: 0.4419\n",
      "Epoch [32/50], Step [441/735], Loss: 0.1371\n",
      "Epoch [32/50], Step [442/735], Loss: 0.2883\n",
      "Epoch [32/50], Step [443/735], Loss: 0.4801\n",
      "Epoch [32/50], Step [444/735], Loss: 0.4140\n",
      "Epoch [32/50], Step [445/735], Loss: 0.2659\n",
      "Epoch [32/50], Step [446/735], Loss: 0.2464\n",
      "Epoch [32/50], Step [447/735], Loss: 0.3211\n",
      "Epoch [32/50], Step [448/735], Loss: 0.1755\n",
      "Epoch [32/50], Step [449/735], Loss: 1.4630\n",
      "Epoch [32/50], Step [450/735], Loss: 0.1793\n",
      "Epoch [32/50], Step [451/735], Loss: 0.2897\n",
      "Epoch [32/50], Step [452/735], Loss: 0.5956\n",
      "Epoch [32/50], Step [453/735], Loss: 0.0831\n",
      "Epoch [32/50], Step [454/735], Loss: 0.3557\n",
      "Epoch [32/50], Step [455/735], Loss: 0.5206\n",
      "Epoch [32/50], Step [456/735], Loss: 0.2299\n",
      "Epoch [32/50], Step [457/735], Loss: 0.1110\n",
      "Epoch [32/50], Step [458/735], Loss: 0.2348\n",
      "Epoch [32/50], Step [459/735], Loss: 0.5029\n",
      "Epoch [32/50], Step [460/735], Loss: 0.2033\n",
      "Epoch [32/50], Step [461/735], Loss: 0.1029\n",
      "Epoch [32/50], Step [462/735], Loss: 0.0775\n",
      "Epoch [32/50], Step [463/735], Loss: 0.5987\n",
      "Epoch [32/50], Step [464/735], Loss: 0.4230\n",
      "Epoch [32/50], Step [465/735], Loss: 0.3517\n",
      "Epoch [32/50], Step [466/735], Loss: 0.3268\n",
      "Epoch [32/50], Step [467/735], Loss: 0.2739\n",
      "Epoch [32/50], Step [468/735], Loss: 0.2029\n",
      "Epoch [32/50], Step [469/735], Loss: 0.2998\n",
      "Epoch [32/50], Step [470/735], Loss: 0.4135\n",
      "Epoch [32/50], Step [471/735], Loss: 0.1198\n",
      "Epoch [32/50], Step [472/735], Loss: 0.2928\n",
      "Epoch [32/50], Step [473/735], Loss: 0.5093\n",
      "Epoch [32/50], Step [474/735], Loss: 0.3560\n",
      "Epoch [32/50], Step [475/735], Loss: 0.2769\n",
      "Epoch [32/50], Step [476/735], Loss: 0.6842\n",
      "Epoch [32/50], Step [477/735], Loss: 0.4577\n",
      "Epoch [32/50], Step [478/735], Loss: 0.2530\n",
      "Epoch [32/50], Step [479/735], Loss: 0.1375\n",
      "Epoch [32/50], Step [480/735], Loss: 0.1063\n",
      "Epoch [32/50], Step [481/735], Loss: 1.8599\n",
      "Epoch [32/50], Step [482/735], Loss: 0.1587\n",
      "Epoch [32/50], Step [483/735], Loss: 0.1426\n",
      "Epoch [32/50], Step [484/735], Loss: 0.0937\n",
      "Epoch [32/50], Step [485/735], Loss: 0.1657\n",
      "Epoch [32/50], Step [486/735], Loss: 0.1955\n",
      "Epoch [32/50], Step [487/735], Loss: 0.5835\n",
      "Epoch [32/50], Step [488/735], Loss: 0.4280\n",
      "Epoch [32/50], Step [489/735], Loss: 0.2464\n",
      "Epoch [32/50], Step [490/735], Loss: 0.2984\n",
      "Epoch [32/50], Step [491/735], Loss: 0.3780\n",
      "Epoch [32/50], Step [492/735], Loss: 0.6778\n",
      "Epoch [32/50], Step [493/735], Loss: 0.2181\n",
      "Epoch [32/50], Step [494/735], Loss: 0.1274\n",
      "Epoch [32/50], Step [495/735], Loss: 0.3713\n",
      "Epoch [32/50], Step [496/735], Loss: 0.1648\n",
      "Epoch [32/50], Step [497/735], Loss: 0.2876\n",
      "Epoch [32/50], Step [498/735], Loss: 0.2034\n",
      "Epoch [32/50], Step [499/735], Loss: 0.2084\n",
      "Epoch [32/50], Step [500/735], Loss: 0.1537\n",
      "Epoch [32/50], Step [501/735], Loss: 0.1844\n",
      "Epoch [32/50], Step [502/735], Loss: 0.2723\n",
      "Epoch [32/50], Step [503/735], Loss: 0.1325\n",
      "Epoch [32/50], Step [504/735], Loss: 0.1981\n",
      "Epoch [32/50], Step [505/735], Loss: 0.3334\n",
      "Epoch [32/50], Step [506/735], Loss: 0.3929\n",
      "Epoch [32/50], Step [507/735], Loss: 0.1141\n",
      "Epoch [32/50], Step [508/735], Loss: 0.2145\n",
      "Epoch [32/50], Step [509/735], Loss: 0.1405\n",
      "Epoch [32/50], Step [510/735], Loss: 0.0916\n",
      "Epoch [32/50], Step [511/735], Loss: 0.5446\n",
      "Epoch [32/50], Step [512/735], Loss: 0.1403\n",
      "Epoch [32/50], Step [513/735], Loss: 0.6061\n",
      "Epoch [32/50], Step [514/735], Loss: 0.1387\n",
      "Epoch [32/50], Step [515/735], Loss: 0.1045\n",
      "Epoch [32/50], Step [516/735], Loss: 0.1069\n",
      "Epoch [32/50], Step [517/735], Loss: 0.1851\n",
      "Epoch [32/50], Step [518/735], Loss: 0.3373\n",
      "Epoch [32/50], Step [519/735], Loss: 0.1728\n",
      "Epoch [32/50], Step [520/735], Loss: 0.5357\n",
      "Epoch [32/50], Step [521/735], Loss: 0.6000\n",
      "Epoch [32/50], Step [522/735], Loss: 0.1155\n",
      "Epoch [32/50], Step [523/735], Loss: 0.3657\n",
      "Epoch [32/50], Step [524/735], Loss: 0.2319\n",
      "Epoch [32/50], Step [525/735], Loss: 0.0933\n",
      "Epoch [32/50], Step [526/735], Loss: 0.4525\n",
      "Epoch [32/50], Step [527/735], Loss: 0.0802\n",
      "Epoch [32/50], Step [528/735], Loss: 0.0969\n",
      "Epoch [32/50], Step [529/735], Loss: 0.2810\n",
      "Epoch [32/50], Step [530/735], Loss: 0.2536\n",
      "Epoch [32/50], Step [531/735], Loss: 0.9893\n",
      "Epoch [32/50], Step [532/735], Loss: 0.2587\n",
      "Epoch [32/50], Step [533/735], Loss: 0.2679\n",
      "Epoch [32/50], Step [534/735], Loss: 0.3864\n",
      "Epoch [32/50], Step [535/735], Loss: 0.4028\n",
      "Epoch [32/50], Step [536/735], Loss: 1.5951\n",
      "Epoch [32/50], Step [537/735], Loss: 0.6614\n",
      "Epoch [32/50], Step [538/735], Loss: 0.3126\n",
      "Epoch [32/50], Step [539/735], Loss: 0.2784\n",
      "Epoch [32/50], Step [540/735], Loss: 0.2613\n",
      "Epoch [32/50], Step [541/735], Loss: 0.1614\n",
      "Epoch [32/50], Step [542/735], Loss: 0.9347\n",
      "Epoch [32/50], Step [543/735], Loss: 0.2577\n",
      "Epoch [32/50], Step [544/735], Loss: 0.5469\n",
      "Epoch [32/50], Step [545/735], Loss: 0.1519\n",
      "Epoch [32/50], Step [546/735], Loss: 0.2521\n",
      "Epoch [32/50], Step [547/735], Loss: 0.2311\n",
      "Epoch [32/50], Step [548/735], Loss: 0.7371\n",
      "Epoch [32/50], Step [549/735], Loss: 0.2669\n",
      "Epoch [32/50], Step [550/735], Loss: 1.0469\n",
      "Epoch [32/50], Step [551/735], Loss: 0.1372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Step [552/735], Loss: 0.1744\n",
      "Epoch [32/50], Step [553/735], Loss: 0.3511\n",
      "Epoch [32/50], Step [554/735], Loss: 0.6907\n",
      "Epoch [32/50], Step [555/735], Loss: 0.4910\n",
      "Epoch [32/50], Step [556/735], Loss: 0.2374\n",
      "Epoch [32/50], Step [557/735], Loss: 0.2171\n",
      "Epoch [32/50], Step [558/735], Loss: 0.2841\n",
      "Epoch [32/50], Step [559/735], Loss: 0.3571\n",
      "Epoch [32/50], Step [560/735], Loss: 0.1863\n",
      "Epoch [32/50], Step [561/735], Loss: 0.1877\n",
      "Epoch [32/50], Step [562/735], Loss: 0.2518\n",
      "Epoch [32/50], Step [563/735], Loss: 0.2075\n",
      "Epoch [32/50], Step [564/735], Loss: 0.2660\n",
      "Epoch [32/50], Step [565/735], Loss: 0.2673\n",
      "Epoch [32/50], Step [566/735], Loss: 0.0798\n",
      "Epoch [32/50], Step [567/735], Loss: 0.1787\n",
      "Epoch [32/50], Step [568/735], Loss: 0.4220\n",
      "Epoch [32/50], Step [569/735], Loss: 0.4509\n",
      "Epoch [32/50], Step [570/735], Loss: 0.2419\n",
      "Epoch [32/50], Step [571/735], Loss: 0.4276\n",
      "Epoch [32/50], Step [572/735], Loss: 0.3653\n",
      "Epoch [32/50], Step [573/735], Loss: 0.4341\n",
      "Epoch [32/50], Step [574/735], Loss: 0.2715\n",
      "Epoch [32/50], Step [575/735], Loss: 0.3660\n",
      "Epoch [32/50], Step [576/735], Loss: 0.3863\n",
      "Epoch [32/50], Step [577/735], Loss: 0.1691\n",
      "Epoch [32/50], Step [578/735], Loss: 0.2422\n",
      "Epoch [32/50], Step [579/735], Loss: 0.3400\n",
      "Epoch [32/50], Step [580/735], Loss: 0.7620\n",
      "Epoch [32/50], Step [581/735], Loss: 0.1654\n",
      "Epoch [32/50], Step [582/735], Loss: 0.2947\n",
      "Epoch [32/50], Step [583/735], Loss: 0.1665\n",
      "Epoch [32/50], Step [584/735], Loss: 0.4292\n",
      "Epoch [32/50], Step [585/735], Loss: 0.3223\n",
      "Epoch [32/50], Step [586/735], Loss: 0.2028\n",
      "Epoch [32/50], Step [587/735], Loss: 0.1397\n",
      "Epoch [32/50], Step [588/735], Loss: 0.1916\n",
      "Epoch [32/50], Step [589/735], Loss: 0.0537\n",
      "Epoch [32/50], Step [590/735], Loss: 0.2652\n",
      "Epoch [32/50], Step [591/735], Loss: 0.4193\n",
      "Epoch [32/50], Step [592/735], Loss: 0.3083\n",
      "Epoch [32/50], Step [593/735], Loss: 0.2820\n",
      "Epoch [32/50], Step [594/735], Loss: 0.3172\n",
      "Epoch [32/50], Step [595/735], Loss: 0.2160\n",
      "Epoch [32/50], Step [596/735], Loss: 0.4884\n",
      "Epoch [32/50], Step [597/735], Loss: 0.8043\n",
      "Epoch [32/50], Step [598/735], Loss: 0.3427\n",
      "Epoch [32/50], Step [599/735], Loss: 0.6478\n",
      "Epoch [32/50], Step [600/735], Loss: 0.2880\n",
      "Epoch [32/50], Step [601/735], Loss: 0.2439\n",
      "Epoch [32/50], Step [602/735], Loss: 0.5099\n",
      "Epoch [32/50], Step [603/735], Loss: 0.5090\n",
      "Epoch [32/50], Step [604/735], Loss: 0.2570\n",
      "Epoch [32/50], Step [605/735], Loss: 0.1803\n",
      "Epoch [32/50], Step [606/735], Loss: 0.1606\n",
      "Epoch [32/50], Step [607/735], Loss: 0.2793\n",
      "Epoch [32/50], Step [608/735], Loss: 0.3741\n",
      "Epoch [32/50], Step [609/735], Loss: 1.3284\n",
      "Epoch [32/50], Step [610/735], Loss: 0.0549\n",
      "Epoch [32/50], Step [611/735], Loss: 0.1606\n",
      "Epoch [32/50], Step [612/735], Loss: 0.3917\n",
      "Epoch [32/50], Step [613/735], Loss: 0.1508\n",
      "Epoch [32/50], Step [614/735], Loss: 0.1675\n",
      "Epoch [32/50], Step [615/735], Loss: 0.2401\n",
      "Epoch [32/50], Step [616/735], Loss: 0.3642\n",
      "Epoch [32/50], Step [617/735], Loss: 0.7151\n",
      "Epoch [32/50], Step [618/735], Loss: 0.2336\n",
      "Epoch [32/50], Step [619/735], Loss: 0.1810\n",
      "Epoch [32/50], Step [620/735], Loss: 0.7036\n",
      "Epoch [32/50], Step [621/735], Loss: 0.9875\n",
      "Epoch [32/50], Step [622/735], Loss: 0.6738\n",
      "Epoch [32/50], Step [623/735], Loss: 0.1585\n",
      "Epoch [32/50], Step [624/735], Loss: 0.2159\n",
      "Epoch [32/50], Step [625/735], Loss: 0.2748\n",
      "Epoch [32/50], Step [626/735], Loss: 1.4910\n",
      "Epoch [32/50], Step [627/735], Loss: 0.2174\n",
      "Epoch [32/50], Step [628/735], Loss: 0.7700\n",
      "Epoch [32/50], Step [629/735], Loss: 0.2476\n",
      "Epoch [32/50], Step [630/735], Loss: 0.2478\n",
      "Epoch [32/50], Step [631/735], Loss: 0.4590\n",
      "Epoch [32/50], Step [632/735], Loss: 0.2693\n",
      "Epoch [32/50], Step [633/735], Loss: 0.6462\n",
      "Epoch [32/50], Step [634/735], Loss: 0.4345\n",
      "Epoch [32/50], Step [635/735], Loss: 0.9483\n",
      "Epoch [32/50], Step [636/735], Loss: 0.2807\n",
      "Epoch [32/50], Step [637/735], Loss: 0.1826\n",
      "Epoch [32/50], Step [638/735], Loss: 0.2551\n",
      "Epoch [32/50], Step [639/735], Loss: 0.1548\n",
      "Epoch [32/50], Step [640/735], Loss: 4.9749\n",
      "Epoch [32/50], Step [641/735], Loss: 0.1736\n",
      "Epoch [32/50], Step [642/735], Loss: 0.4623\n",
      "Epoch [32/50], Step [643/735], Loss: 0.3020\n",
      "Epoch [32/50], Step [644/735], Loss: 0.3918\n",
      "Epoch [32/50], Step [645/735], Loss: 0.1685\n",
      "Epoch [32/50], Step [646/735], Loss: 0.6312\n",
      "Epoch [32/50], Step [647/735], Loss: 0.5585\n",
      "Epoch [32/50], Step [648/735], Loss: 0.3513\n",
      "Epoch [32/50], Step [649/735], Loss: 0.4229\n",
      "Epoch [32/50], Step [650/735], Loss: 0.8005\n",
      "Epoch [32/50], Step [651/735], Loss: 0.4288\n",
      "Epoch [32/50], Step [652/735], Loss: 0.4021\n",
      "Epoch [32/50], Step [653/735], Loss: 0.1793\n",
      "Epoch [32/50], Step [654/735], Loss: 0.8061\n",
      "Epoch [32/50], Step [655/735], Loss: 0.2183\n",
      "Epoch [32/50], Step [656/735], Loss: 0.9037\n",
      "Epoch [32/50], Step [657/735], Loss: 0.3112\n",
      "Epoch [32/50], Step [658/735], Loss: 0.1110\n",
      "Epoch [32/50], Step [659/735], Loss: 0.1974\n",
      "Epoch [32/50], Step [660/735], Loss: 0.3153\n",
      "Epoch [32/50], Step [661/735], Loss: 0.1395\n",
      "Epoch [32/50], Step [662/735], Loss: 0.2881\n",
      "Epoch [32/50], Step [663/735], Loss: 0.3518\n",
      "Epoch [32/50], Step [664/735], Loss: 0.1938\n",
      "Epoch [32/50], Step [665/735], Loss: 0.2315\n",
      "Epoch [32/50], Step [666/735], Loss: 0.1834\n",
      "Epoch [32/50], Step [667/735], Loss: 0.1592\n",
      "Epoch [32/50], Step [668/735], Loss: 0.4341\n",
      "Epoch [32/50], Step [669/735], Loss: 0.4626\n",
      "Epoch [32/50], Step [670/735], Loss: 0.3338\n",
      "Epoch [32/50], Step [671/735], Loss: 0.6762\n",
      "Epoch [32/50], Step [672/735], Loss: 0.2158\n",
      "Epoch [32/50], Step [673/735], Loss: 0.0960\n",
      "Epoch [32/50], Step [674/735], Loss: 0.1599\n",
      "Epoch [32/50], Step [675/735], Loss: 0.3209\n",
      "Epoch [32/50], Step [676/735], Loss: 0.3785\n",
      "Epoch [32/50], Step [677/735], Loss: 0.1080\n",
      "Epoch [32/50], Step [678/735], Loss: 0.1859\n",
      "Epoch [32/50], Step [679/735], Loss: 0.1995\n",
      "Epoch [32/50], Step [680/735], Loss: 0.2255\n",
      "Epoch [32/50], Step [681/735], Loss: 0.2347\n",
      "Epoch [32/50], Step [682/735], Loss: 0.2434\n",
      "Epoch [32/50], Step [683/735], Loss: 0.1345\n",
      "Epoch [32/50], Step [684/735], Loss: 0.2545\n",
      "Epoch [32/50], Step [685/735], Loss: 0.0958\n",
      "Epoch [32/50], Step [686/735], Loss: 0.3634\n",
      "Epoch [32/50], Step [687/735], Loss: 0.1651\n",
      "Epoch [32/50], Step [688/735], Loss: 0.3075\n",
      "Epoch [32/50], Step [689/735], Loss: 0.1568\n",
      "Epoch [32/50], Step [690/735], Loss: 0.0748\n",
      "Epoch [32/50], Step [691/735], Loss: 0.1152\n",
      "Epoch [32/50], Step [692/735], Loss: 0.1517\n",
      "Epoch [32/50], Step [693/735], Loss: 0.5123\n",
      "Epoch [32/50], Step [694/735], Loss: 0.2243\n",
      "Epoch [32/50], Step [695/735], Loss: 0.1700\n",
      "Epoch [32/50], Step [696/735], Loss: 0.3719\n",
      "Epoch [32/50], Step [697/735], Loss: 0.2770\n",
      "Epoch [32/50], Step [698/735], Loss: 0.3328\n",
      "Epoch [32/50], Step [699/735], Loss: 0.0697\n",
      "Epoch [32/50], Step [700/735], Loss: 0.4275\n",
      "Epoch [32/50], Step [701/735], Loss: 0.3254\n",
      "Epoch [32/50], Step [702/735], Loss: 0.3095\n",
      "Epoch [32/50], Step [703/735], Loss: 3.9585\n",
      "Epoch [32/50], Step [704/735], Loss: 0.1116\n",
      "Epoch [32/50], Step [705/735], Loss: 0.1823\n",
      "Epoch [32/50], Step [706/735], Loss: 0.1512\n",
      "Epoch [32/50], Step [707/735], Loss: 0.3078\n",
      "Epoch [32/50], Step [708/735], Loss: 0.1391\n",
      "Epoch [32/50], Step [709/735], Loss: 0.3224\n",
      "Epoch [32/50], Step [710/735], Loss: 0.5840\n",
      "Epoch [32/50], Step [711/735], Loss: 0.3684\n",
      "Epoch [32/50], Step [712/735], Loss: 0.7309\n",
      "Epoch [32/50], Step [713/735], Loss: 0.1273\n",
      "Epoch [32/50], Step [714/735], Loss: 0.1330\n",
      "Epoch [32/50], Step [715/735], Loss: 0.0565\n",
      "Epoch [32/50], Step [716/735], Loss: 0.1707\n",
      "Epoch [32/50], Step [717/735], Loss: 0.0894\n",
      "Epoch [32/50], Step [718/735], Loss: 0.9043\n",
      "Epoch [32/50], Step [719/735], Loss: 0.4356\n",
      "Epoch [32/50], Step [720/735], Loss: 0.2767\n",
      "Epoch [32/50], Step [721/735], Loss: 0.2463\n",
      "Epoch [32/50], Step [722/735], Loss: 0.3369\n",
      "Epoch [32/50], Step [723/735], Loss: 0.4156\n",
      "Epoch [32/50], Step [724/735], Loss: 0.3094\n",
      "Epoch [32/50], Step [725/735], Loss: 0.1068\n",
      "Epoch [32/50], Step [726/735], Loss: 0.1473\n",
      "Epoch [32/50], Step [727/735], Loss: 0.2812\n",
      "Epoch [32/50], Step [728/735], Loss: 0.1566\n",
      "Epoch [32/50], Step [729/735], Loss: 0.4926\n",
      "Epoch [32/50], Step [730/735], Loss: 1.6808\n",
      "Epoch [32/50], Step [731/735], Loss: 0.1314\n",
      "Epoch [32/50], Step [732/735], Loss: 0.2586\n",
      "Epoch [32/50], Step [733/735], Loss: 0.1714\n",
      "Epoch [32/50], Step [734/735], Loss: 0.4544\n",
      "Epoch [32/50], Step [735/735], Loss: 0.1179\n",
      "Epoch [33/50], Step [1/735], Loss: 0.0898\n",
      "Epoch [33/50], Step [2/735], Loss: 0.8433\n",
      "Epoch [33/50], Step [3/735], Loss: 0.5571\n",
      "Epoch [33/50], Step [4/735], Loss: 0.1327\n",
      "Epoch [33/50], Step [5/735], Loss: 0.1733\n",
      "Epoch [33/50], Step [6/735], Loss: 0.1523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Step [7/735], Loss: 0.1544\n",
      "Epoch [33/50], Step [8/735], Loss: 0.0882\n",
      "Epoch [33/50], Step [9/735], Loss: 0.6287\n",
      "Epoch [33/50], Step [10/735], Loss: 0.5068\n",
      "Epoch [33/50], Step [11/735], Loss: 0.1248\n",
      "Epoch [33/50], Step [12/735], Loss: 0.1928\n",
      "Epoch [33/50], Step [13/735], Loss: 0.1607\n",
      "Epoch [33/50], Step [14/735], Loss: 0.1738\n",
      "Epoch [33/50], Step [15/735], Loss: 0.5025\n",
      "Epoch [33/50], Step [16/735], Loss: 0.1974\n",
      "Epoch [33/50], Step [17/735], Loss: 0.6387\n",
      "Epoch [33/50], Step [18/735], Loss: 0.1823\n",
      "Epoch [33/50], Step [19/735], Loss: 0.7311\n",
      "Epoch [33/50], Step [20/735], Loss: 0.4702\n",
      "Epoch [33/50], Step [21/735], Loss: 0.3147\n",
      "Epoch [33/50], Step [22/735], Loss: 0.4914\n",
      "Epoch [33/50], Step [23/735], Loss: 0.2798\n",
      "Epoch [33/50], Step [24/735], Loss: 0.2291\n",
      "Epoch [33/50], Step [25/735], Loss: 0.1387\n",
      "Epoch [33/50], Step [26/735], Loss: 4.6216\n",
      "Epoch [33/50], Step [27/735], Loss: 0.2179\n",
      "Epoch [33/50], Step [28/735], Loss: 0.2780\n",
      "Epoch [33/50], Step [29/735], Loss: 1.1897\n",
      "Epoch [33/50], Step [30/735], Loss: 0.3962\n",
      "Epoch [33/50], Step [31/735], Loss: 0.0763\n",
      "Epoch [33/50], Step [32/735], Loss: 0.2356\n",
      "Epoch [33/50], Step [33/735], Loss: 0.3283\n",
      "Epoch [33/50], Step [34/735], Loss: 3.9910\n",
      "Epoch [33/50], Step [35/735], Loss: 0.2821\n",
      "Epoch [33/50], Step [36/735], Loss: 0.1535\n",
      "Epoch [33/50], Step [37/735], Loss: 0.6450\n",
      "Epoch [33/50], Step [38/735], Loss: 0.1518\n",
      "Epoch [33/50], Step [39/735], Loss: 0.8677\n",
      "Epoch [33/50], Step [40/735], Loss: 0.2935\n",
      "Epoch [33/50], Step [41/735], Loss: 0.3124\n",
      "Epoch [33/50], Step [42/735], Loss: 0.0836\n",
      "Epoch [33/50], Step [43/735], Loss: 0.3847\n",
      "Epoch [33/50], Step [44/735], Loss: 3.4784\n",
      "Epoch [33/50], Step [45/735], Loss: 0.2797\n",
      "Epoch [33/50], Step [46/735], Loss: 1.0829\n",
      "Epoch [33/50], Step [47/735], Loss: 0.1875\n",
      "Epoch [33/50], Step [48/735], Loss: 0.2318\n",
      "Epoch [33/50], Step [49/735], Loss: 0.6784\n",
      "Epoch [33/50], Step [50/735], Loss: 0.3347\n",
      "Epoch [33/50], Step [51/735], Loss: 0.2587\n",
      "Epoch [33/50], Step [52/735], Loss: 0.4153\n",
      "Epoch [33/50], Step [53/735], Loss: 0.2740\n",
      "Epoch [33/50], Step [54/735], Loss: 0.2046\n",
      "Epoch [33/50], Step [55/735], Loss: 0.3732\n",
      "Epoch [33/50], Step [56/735], Loss: 0.5974\n",
      "Epoch [33/50], Step [57/735], Loss: 0.2098\n",
      "Epoch [33/50], Step [58/735], Loss: 0.2144\n",
      "Epoch [33/50], Step [59/735], Loss: 0.1780\n",
      "Epoch [33/50], Step [60/735], Loss: 0.1766\n",
      "Epoch [33/50], Step [61/735], Loss: 0.2506\n",
      "Epoch [33/50], Step [62/735], Loss: 0.1295\n",
      "Epoch [33/50], Step [63/735], Loss: 0.2726\n",
      "Epoch [33/50], Step [64/735], Loss: 0.1901\n",
      "Epoch [33/50], Step [65/735], Loss: 0.0871\n",
      "Epoch [33/50], Step [66/735], Loss: 0.2304\n",
      "Epoch [33/50], Step [67/735], Loss: 0.1973\n",
      "Epoch [33/50], Step [68/735], Loss: 0.1346\n",
      "Epoch [33/50], Step [69/735], Loss: 0.3780\n",
      "Epoch [33/50], Step [70/735], Loss: 0.1425\n",
      "Epoch [33/50], Step [71/735], Loss: 0.2407\n",
      "Epoch [33/50], Step [72/735], Loss: 0.0785\n",
      "Epoch [33/50], Step [73/735], Loss: 0.2093\n",
      "Epoch [33/50], Step [74/735], Loss: 0.1393\n",
      "Epoch [33/50], Step [75/735], Loss: 0.1282\n",
      "Epoch [33/50], Step [76/735], Loss: 0.1827\n",
      "Epoch [33/50], Step [77/735], Loss: 0.2919\n",
      "Epoch [33/50], Step [78/735], Loss: 0.4492\n",
      "Epoch [33/50], Step [79/735], Loss: 0.1178\n",
      "Epoch [33/50], Step [80/735], Loss: 0.1632\n",
      "Epoch [33/50], Step [81/735], Loss: 0.2538\n",
      "Epoch [33/50], Step [82/735], Loss: 0.5162\n",
      "Epoch [33/50], Step [83/735], Loss: 0.2173\n",
      "Epoch [33/50], Step [84/735], Loss: 0.2656\n",
      "Epoch [33/50], Step [85/735], Loss: 0.1265\n",
      "Epoch [33/50], Step [86/735], Loss: 0.0963\n",
      "Epoch [33/50], Step [87/735], Loss: 0.1812\n",
      "Epoch [33/50], Step [88/735], Loss: 0.4401\n",
      "Epoch [33/50], Step [89/735], Loss: 0.0596\n",
      "Epoch [33/50], Step [90/735], Loss: 0.1516\n",
      "Epoch [33/50], Step [91/735], Loss: 0.4662\n",
      "Epoch [33/50], Step [92/735], Loss: 0.3076\n",
      "Epoch [33/50], Step [93/735], Loss: 0.2096\n",
      "Epoch [33/50], Step [94/735], Loss: 0.2604\n",
      "Epoch [33/50], Step [95/735], Loss: 0.2272\n",
      "Epoch [33/50], Step [96/735], Loss: 0.2468\n",
      "Epoch [33/50], Step [97/735], Loss: 0.1791\n",
      "Epoch [33/50], Step [98/735], Loss: 0.2249\n",
      "Epoch [33/50], Step [99/735], Loss: 0.3541\n",
      "Epoch [33/50], Step [100/735], Loss: 0.1340\n",
      "Epoch [33/50], Step [101/735], Loss: 0.3403\n",
      "Epoch [33/50], Step [102/735], Loss: 0.1460\n",
      "Epoch [33/50], Step [103/735], Loss: 0.2187\n",
      "Epoch [33/50], Step [104/735], Loss: 0.2073\n",
      "Epoch [33/50], Step [105/735], Loss: 0.1960\n",
      "Epoch [33/50], Step [106/735], Loss: 0.1620\n",
      "Epoch [33/50], Step [107/735], Loss: 0.4659\n",
      "Epoch [33/50], Step [108/735], Loss: 0.2377\n",
      "Epoch [33/50], Step [109/735], Loss: 0.1831\n",
      "Epoch [33/50], Step [110/735], Loss: 0.2982\n",
      "Epoch [33/50], Step [111/735], Loss: 3.8265\n",
      "Epoch [33/50], Step [112/735], Loss: 0.6238\n",
      "Epoch [33/50], Step [113/735], Loss: 0.8877\n",
      "Epoch [33/50], Step [114/735], Loss: 1.1028\n",
      "Epoch [33/50], Step [115/735], Loss: 0.3433\n",
      "Epoch [33/50], Step [116/735], Loss: 1.6193\n",
      "Epoch [33/50], Step [117/735], Loss: 0.2657\n",
      "Epoch [33/50], Step [118/735], Loss: 0.5813\n",
      "Epoch [33/50], Step [119/735], Loss: 0.3533\n",
      "Epoch [33/50], Step [120/735], Loss: 0.3702\n",
      "Epoch [33/50], Step [121/735], Loss: 0.3024\n",
      "Epoch [33/50], Step [122/735], Loss: 0.3809\n",
      "Epoch [33/50], Step [123/735], Loss: 0.3044\n",
      "Epoch [33/50], Step [124/735], Loss: 0.6860\n",
      "Epoch [33/50], Step [125/735], Loss: 0.3649\n",
      "Epoch [33/50], Step [126/735], Loss: 0.1199\n",
      "Epoch [33/50], Step [127/735], Loss: 2.0294\n",
      "Epoch [33/50], Step [128/735], Loss: 0.2507\n",
      "Epoch [33/50], Step [129/735], Loss: 0.6522\n",
      "Epoch [33/50], Step [130/735], Loss: 0.1887\n",
      "Epoch [33/50], Step [131/735], Loss: 0.6241\n",
      "Epoch [33/50], Step [132/735], Loss: 1.2545\n",
      "Epoch [33/50], Step [133/735], Loss: 0.3588\n",
      "Epoch [33/50], Step [134/735], Loss: 0.9591\n",
      "Epoch [33/50], Step [135/735], Loss: 0.1504\n",
      "Epoch [33/50], Step [136/735], Loss: 0.1979\n",
      "Epoch [33/50], Step [137/735], Loss: 0.3806\n",
      "Epoch [33/50], Step [138/735], Loss: 0.3015\n",
      "Epoch [33/50], Step [139/735], Loss: 0.2913\n",
      "Epoch [33/50], Step [140/735], Loss: 0.3906\n",
      "Epoch [33/50], Step [141/735], Loss: 0.1966\n",
      "Epoch [33/50], Step [142/735], Loss: 0.2210\n",
      "Epoch [33/50], Step [143/735], Loss: 0.7931\n",
      "Epoch [33/50], Step [144/735], Loss: 0.1969\n",
      "Epoch [33/50], Step [145/735], Loss: 0.1659\n",
      "Epoch [33/50], Step [146/735], Loss: 0.3427\n",
      "Epoch [33/50], Step [147/735], Loss: 0.1946\n",
      "Epoch [33/50], Step [148/735], Loss: 1.2260\n",
      "Epoch [33/50], Step [149/735], Loss: 0.5947\n",
      "Epoch [33/50], Step [150/735], Loss: 1.0191\n",
      "Epoch [33/50], Step [151/735], Loss: 0.1770\n",
      "Epoch [33/50], Step [152/735], Loss: 0.4899\n",
      "Epoch [33/50], Step [153/735], Loss: 0.2629\n",
      "Epoch [33/50], Step [154/735], Loss: 0.2825\n",
      "Epoch [33/50], Step [155/735], Loss: 0.2260\n",
      "Epoch [33/50], Step [156/735], Loss: 1.2576\n",
      "Epoch [33/50], Step [157/735], Loss: 0.1332\n",
      "Epoch [33/50], Step [158/735], Loss: 0.9976\n",
      "Epoch [33/50], Step [159/735], Loss: 0.7124\n",
      "Epoch [33/50], Step [160/735], Loss: 0.2632\n",
      "Epoch [33/50], Step [161/735], Loss: 0.3166\n",
      "Epoch [33/50], Step [162/735], Loss: 0.8290\n",
      "Epoch [33/50], Step [163/735], Loss: 0.3020\n",
      "Epoch [33/50], Step [164/735], Loss: 0.1549\n",
      "Epoch [33/50], Step [165/735], Loss: 0.4103\n",
      "Epoch [33/50], Step [166/735], Loss: 0.6193\n",
      "Epoch [33/50], Step [167/735], Loss: 0.3076\n",
      "Epoch [33/50], Step [168/735], Loss: 0.2005\n",
      "Epoch [33/50], Step [169/735], Loss: 0.3613\n",
      "Epoch [33/50], Step [170/735], Loss: 0.2749\n",
      "Epoch [33/50], Step [171/735], Loss: 0.3209\n",
      "Epoch [33/50], Step [172/735], Loss: 0.0783\n",
      "Epoch [33/50], Step [173/735], Loss: 0.1611\n",
      "Epoch [33/50], Step [174/735], Loss: 0.2905\n",
      "Epoch [33/50], Step [175/735], Loss: 0.7869\n",
      "Epoch [33/50], Step [176/735], Loss: 0.4398\n",
      "Epoch [33/50], Step [177/735], Loss: 0.0895\n",
      "Epoch [33/50], Step [178/735], Loss: 0.6340\n",
      "Epoch [33/50], Step [179/735], Loss: 0.1474\n",
      "Epoch [33/50], Step [180/735], Loss: 0.1172\n",
      "Epoch [33/50], Step [181/735], Loss: 0.2179\n",
      "Epoch [33/50], Step [182/735], Loss: 0.2273\n",
      "Epoch [33/50], Step [183/735], Loss: 0.1484\n",
      "Epoch [33/50], Step [184/735], Loss: 0.2907\n",
      "Epoch [33/50], Step [185/735], Loss: 0.2567\n",
      "Epoch [33/50], Step [186/735], Loss: 0.1203\n",
      "Epoch [33/50], Step [187/735], Loss: 0.1940\n",
      "Epoch [33/50], Step [188/735], Loss: 0.3770\n",
      "Epoch [33/50], Step [189/735], Loss: 0.1633\n",
      "Epoch [33/50], Step [190/735], Loss: 0.2548\n",
      "Epoch [33/50], Step [191/735], Loss: 0.2032\n",
      "Epoch [33/50], Step [192/735], Loss: 0.2375\n",
      "Epoch [33/50], Step [193/735], Loss: 0.9902\n",
      "Epoch [33/50], Step [194/735], Loss: 0.2769\n",
      "Epoch [33/50], Step [195/735], Loss: 0.0769\n",
      "Epoch [33/50], Step [196/735], Loss: 0.2676\n",
      "Epoch [33/50], Step [197/735], Loss: 0.1058\n",
      "Epoch [33/50], Step [198/735], Loss: 0.2346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Step [199/735], Loss: 0.1124\n",
      "Epoch [33/50], Step [200/735], Loss: 0.1914\n",
      "Epoch [33/50], Step [201/735], Loss: 0.1680\n",
      "Epoch [33/50], Step [202/735], Loss: 0.4407\n",
      "Epoch [33/50], Step [203/735], Loss: 0.2284\n",
      "Epoch [33/50], Step [204/735], Loss: 0.4813\n",
      "Epoch [33/50], Step [205/735], Loss: 0.2918\n",
      "Epoch [33/50], Step [206/735], Loss: 0.1408\n",
      "Epoch [33/50], Step [207/735], Loss: 0.5910\n",
      "Epoch [33/50], Step [208/735], Loss: 0.7418\n",
      "Epoch [33/50], Step [209/735], Loss: 0.2973\n",
      "Epoch [33/50], Step [210/735], Loss: 0.1119\n",
      "Epoch [33/50], Step [211/735], Loss: 0.4012\n",
      "Epoch [33/50], Step [212/735], Loss: 0.2019\n",
      "Epoch [33/50], Step [213/735], Loss: 0.1503\n",
      "Epoch [33/50], Step [214/735], Loss: 0.2320\n",
      "Epoch [33/50], Step [215/735], Loss: 1.5901\n",
      "Epoch [33/50], Step [216/735], Loss: 0.2469\n",
      "Epoch [33/50], Step [217/735], Loss: 0.2275\n",
      "Epoch [33/50], Step [218/735], Loss: 0.2420\n",
      "Epoch [33/50], Step [219/735], Loss: 0.3202\n",
      "Epoch [33/50], Step [220/735], Loss: 0.1435\n",
      "Epoch [33/50], Step [221/735], Loss: 0.6458\n",
      "Epoch [33/50], Step [222/735], Loss: 0.7449\n",
      "Epoch [33/50], Step [223/735], Loss: 0.2017\n",
      "Epoch [33/50], Step [224/735], Loss: 0.2320\n",
      "Epoch [33/50], Step [225/735], Loss: 0.3009\n",
      "Epoch [33/50], Step [226/735], Loss: 0.3173\n",
      "Epoch [33/50], Step [227/735], Loss: 0.2873\n",
      "Epoch [33/50], Step [228/735], Loss: 0.6615\n",
      "Epoch [33/50], Step [229/735], Loss: 0.5231\n",
      "Epoch [33/50], Step [230/735], Loss: 0.5341\n",
      "Epoch [33/50], Step [231/735], Loss: 0.1695\n",
      "Epoch [33/50], Step [232/735], Loss: 0.2299\n",
      "Epoch [33/50], Step [233/735], Loss: 0.4166\n",
      "Epoch [33/50], Step [234/735], Loss: 0.6903\n",
      "Epoch [33/50], Step [235/735], Loss: 0.4115\n",
      "Epoch [33/50], Step [236/735], Loss: 0.2929\n",
      "Epoch [33/50], Step [237/735], Loss: 0.1431\n",
      "Epoch [33/50], Step [238/735], Loss: 0.2723\n",
      "Epoch [33/50], Step [239/735], Loss: 0.2444\n",
      "Epoch [33/50], Step [240/735], Loss: 0.2048\n",
      "Epoch [33/50], Step [241/735], Loss: 0.1228\n",
      "Epoch [33/50], Step [242/735], Loss: 0.1377\n",
      "Epoch [33/50], Step [243/735], Loss: 0.2503\n",
      "Epoch [33/50], Step [244/735], Loss: 0.3171\n",
      "Epoch [33/50], Step [245/735], Loss: 0.2595\n",
      "Epoch [33/50], Step [246/735], Loss: 0.1616\n",
      "Epoch [33/50], Step [247/735], Loss: 0.5720\n",
      "Epoch [33/50], Step [248/735], Loss: 0.2030\n",
      "Epoch [33/50], Step [249/735], Loss: 0.0655\n",
      "Epoch [33/50], Step [250/735], Loss: 0.0761\n",
      "Epoch [33/50], Step [251/735], Loss: 0.1373\n",
      "Epoch [33/50], Step [252/735], Loss: 0.3907\n",
      "Epoch [33/50], Step [253/735], Loss: 0.1679\n",
      "Epoch [33/50], Step [254/735], Loss: 0.1893\n",
      "Epoch [33/50], Step [255/735], Loss: 0.5362\n",
      "Epoch [33/50], Step [256/735], Loss: 0.2779\n",
      "Epoch [33/50], Step [257/735], Loss: 0.1302\n",
      "Epoch [33/50], Step [258/735], Loss: 0.2840\n",
      "Epoch [33/50], Step [259/735], Loss: 1.2345\n",
      "Epoch [33/50], Step [260/735], Loss: 0.3003\n",
      "Epoch [33/50], Step [261/735], Loss: 0.2111\n",
      "Epoch [33/50], Step [262/735], Loss: 0.2854\n",
      "Epoch [33/50], Step [263/735], Loss: 0.3208\n",
      "Epoch [33/50], Step [264/735], Loss: 0.1926\n",
      "Epoch [33/50], Step [265/735], Loss: 0.3423\n",
      "Epoch [33/50], Step [266/735], Loss: 0.1042\n",
      "Epoch [33/50], Step [267/735], Loss: 0.2699\n",
      "Epoch [33/50], Step [268/735], Loss: 0.3364\n",
      "Epoch [33/50], Step [269/735], Loss: 0.1469\n",
      "Epoch [33/50], Step [270/735], Loss: 0.3255\n",
      "Epoch [33/50], Step [271/735], Loss: 0.1235\n",
      "Epoch [33/50], Step [272/735], Loss: 0.5251\n",
      "Epoch [33/50], Step [273/735], Loss: 0.1726\n",
      "Epoch [33/50], Step [274/735], Loss: 0.8340\n",
      "Epoch [33/50], Step [275/735], Loss: 0.3312\n",
      "Epoch [33/50], Step [276/735], Loss: 0.5565\n",
      "Epoch [33/50], Step [277/735], Loss: 0.3532\n",
      "Epoch [33/50], Step [278/735], Loss: 1.0130\n",
      "Epoch [33/50], Step [279/735], Loss: 0.5837\n",
      "Epoch [33/50], Step [280/735], Loss: 0.2104\n",
      "Epoch [33/50], Step [281/735], Loss: 0.4426\n",
      "Epoch [33/50], Step [282/735], Loss: 0.2339\n",
      "Epoch [33/50], Step [283/735], Loss: 0.4925\n",
      "Epoch [33/50], Step [284/735], Loss: 0.2296\n",
      "Epoch [33/50], Step [285/735], Loss: 0.2166\n",
      "Epoch [33/50], Step [286/735], Loss: 0.3747\n",
      "Epoch [33/50], Step [287/735], Loss: 0.2324\n",
      "Epoch [33/50], Step [288/735], Loss: 0.3672\n",
      "Epoch [33/50], Step [289/735], Loss: 0.1512\n",
      "Epoch [33/50], Step [290/735], Loss: 0.5132\n",
      "Epoch [33/50], Step [291/735], Loss: 0.0873\n",
      "Epoch [33/50], Step [292/735], Loss: 0.3809\n",
      "Epoch [33/50], Step [293/735], Loss: 0.6375\n",
      "Epoch [33/50], Step [294/735], Loss: 0.1928\n",
      "Epoch [33/50], Step [295/735], Loss: 0.2766\n",
      "Epoch [33/50], Step [296/735], Loss: 0.2287\n",
      "Epoch [33/50], Step [297/735], Loss: 0.2685\n",
      "Epoch [33/50], Step [298/735], Loss: 1.2593\n",
      "Epoch [33/50], Step [299/735], Loss: 0.1241\n",
      "Epoch [33/50], Step [300/735], Loss: 0.2591\n",
      "Epoch [33/50], Step [301/735], Loss: 0.1713\n",
      "Epoch [33/50], Step [302/735], Loss: 0.7175\n",
      "Epoch [33/50], Step [303/735], Loss: 0.2125\n",
      "Epoch [33/50], Step [304/735], Loss: 0.2128\n",
      "Epoch [33/50], Step [305/735], Loss: 0.1475\n",
      "Epoch [33/50], Step [306/735], Loss: 1.4823\n",
      "Epoch [33/50], Step [307/735], Loss: 0.3071\n",
      "Epoch [33/50], Step [308/735], Loss: 0.3911\n",
      "Epoch [33/50], Step [309/735], Loss: 0.6387\n",
      "Epoch [33/50], Step [310/735], Loss: 0.5337\n",
      "Epoch [33/50], Step [311/735], Loss: 0.1199\n",
      "Epoch [33/50], Step [312/735], Loss: 0.4447\n",
      "Epoch [33/50], Step [313/735], Loss: 0.4792\n",
      "Epoch [33/50], Step [314/735], Loss: 0.1600\n",
      "Epoch [33/50], Step [315/735], Loss: 0.2198\n",
      "Epoch [33/50], Step [316/735], Loss: 0.3396\n",
      "Epoch [33/50], Step [317/735], Loss: 0.2294\n",
      "Epoch [33/50], Step [318/735], Loss: 0.4371\n",
      "Epoch [33/50], Step [319/735], Loss: 0.5037\n",
      "Epoch [33/50], Step [320/735], Loss: 0.2982\n",
      "Epoch [33/50], Step [321/735], Loss: 0.3848\n",
      "Epoch [33/50], Step [322/735], Loss: 0.5479\n",
      "Epoch [33/50], Step [323/735], Loss: 0.2673\n",
      "Epoch [33/50], Step [324/735], Loss: 0.1848\n",
      "Epoch [33/50], Step [325/735], Loss: 0.2492\n",
      "Epoch [33/50], Step [326/735], Loss: 0.0875\n",
      "Epoch [33/50], Step [327/735], Loss: 0.2347\n",
      "Epoch [33/50], Step [328/735], Loss: 0.3225\n",
      "Epoch [33/50], Step [329/735], Loss: 0.4953\n",
      "Epoch [33/50], Step [330/735], Loss: 0.1414\n",
      "Epoch [33/50], Step [331/735], Loss: 0.3115\n",
      "Epoch [33/50], Step [332/735], Loss: 0.3563\n",
      "Epoch [33/50], Step [333/735], Loss: 0.1128\n",
      "Epoch [33/50], Step [334/735], Loss: 0.2864\n",
      "Epoch [33/50], Step [335/735], Loss: 0.6564\n",
      "Epoch [33/50], Step [336/735], Loss: 0.0662\n",
      "Epoch [33/50], Step [337/735], Loss: 0.0559\n",
      "Epoch [33/50], Step [338/735], Loss: 0.3148\n",
      "Epoch [33/50], Step [339/735], Loss: 0.4512\n",
      "Epoch [33/50], Step [340/735], Loss: 0.1775\n",
      "Epoch [33/50], Step [341/735], Loss: 0.2575\n",
      "Epoch [33/50], Step [342/735], Loss: 0.2204\n",
      "Epoch [33/50], Step [343/735], Loss: 0.4385\n",
      "Epoch [33/50], Step [344/735], Loss: 0.4821\n",
      "Epoch [33/50], Step [345/735], Loss: 0.1107\n",
      "Epoch [33/50], Step [346/735], Loss: 0.4146\n",
      "Epoch [33/50], Step [347/735], Loss: 0.1676\n",
      "Epoch [33/50], Step [348/735], Loss: 0.5353\n",
      "Epoch [33/50], Step [349/735], Loss: 0.2275\n",
      "Epoch [33/50], Step [350/735], Loss: 0.1395\n",
      "Epoch [33/50], Step [351/735], Loss: 0.9818\n",
      "Epoch [33/50], Step [352/735], Loss: 0.1582\n",
      "Epoch [33/50], Step [353/735], Loss: 0.1709\n",
      "Epoch [33/50], Step [354/735], Loss: 0.1620\n",
      "Epoch [33/50], Step [355/735], Loss: 0.1059\n",
      "Epoch [33/50], Step [356/735], Loss: 0.1271\n",
      "Epoch [33/50], Step [357/735], Loss: 0.3151\n",
      "Epoch [33/50], Step [358/735], Loss: 0.4343\n",
      "Epoch [33/50], Step [359/735], Loss: 0.2814\n",
      "Epoch [33/50], Step [360/735], Loss: 0.1671\n",
      "Epoch [33/50], Step [361/735], Loss: 0.1721\n",
      "Epoch [33/50], Step [362/735], Loss: 0.1601\n",
      "Epoch [33/50], Step [363/735], Loss: 0.3482\n",
      "Epoch [33/50], Step [364/735], Loss: 0.0862\n",
      "Epoch [33/50], Step [365/735], Loss: 0.3001\n",
      "Epoch [33/50], Step [366/735], Loss: 0.1058\n",
      "Epoch [33/50], Step [367/735], Loss: 0.4880\n",
      "Epoch [33/50], Step [368/735], Loss: 0.1024\n",
      "Epoch [33/50], Step [369/735], Loss: 0.2133\n",
      "Epoch [33/50], Step [370/735], Loss: 0.3625\n",
      "Epoch [33/50], Step [371/735], Loss: 0.2515\n",
      "Epoch [33/50], Step [372/735], Loss: 0.1683\n",
      "Epoch [33/50], Step [373/735], Loss: 0.2453\n",
      "Epoch [33/50], Step [374/735], Loss: 0.4497\n",
      "Epoch [33/50], Step [375/735], Loss: 0.3414\n",
      "Epoch [33/50], Step [376/735], Loss: 0.2133\n",
      "Epoch [33/50], Step [377/735], Loss: 0.1697\n",
      "Epoch [33/50], Step [378/735], Loss: 0.0589\n",
      "Epoch [33/50], Step [379/735], Loss: 3.5044\n",
      "Epoch [33/50], Step [380/735], Loss: 0.2892\n",
      "Epoch [33/50], Step [381/735], Loss: 0.2224\n",
      "Epoch [33/50], Step [382/735], Loss: 1.5569\n",
      "Epoch [33/50], Step [383/735], Loss: 0.3187\n",
      "Epoch [33/50], Step [384/735], Loss: 0.2983\n",
      "Epoch [33/50], Step [385/735], Loss: 0.1923\n",
      "Epoch [33/50], Step [386/735], Loss: 0.2281\n",
      "Epoch [33/50], Step [387/735], Loss: 0.1183\n",
      "Epoch [33/50], Step [388/735], Loss: 0.1378\n",
      "Epoch [33/50], Step [389/735], Loss: 0.1515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Step [390/735], Loss: 0.1805\n",
      "Epoch [33/50], Step [391/735], Loss: 0.5282\n",
      "Epoch [33/50], Step [392/735], Loss: 0.3839\n",
      "Epoch [33/50], Step [393/735], Loss: 0.3753\n",
      "Epoch [33/50], Step [394/735], Loss: 0.4034\n",
      "Epoch [33/50], Step [395/735], Loss: 0.0760\n",
      "Epoch [33/50], Step [396/735], Loss: 0.3041\n",
      "Epoch [33/50], Step [397/735], Loss: 0.1828\n",
      "Epoch [33/50], Step [398/735], Loss: 0.3870\n",
      "Epoch [33/50], Step [399/735], Loss: 0.5580\n",
      "Epoch [33/50], Step [400/735], Loss: 0.3894\n",
      "Epoch [33/50], Step [401/735], Loss: 0.5412\n",
      "Epoch [33/50], Step [402/735], Loss: 0.2278\n",
      "Epoch [33/50], Step [403/735], Loss: 0.3357\n",
      "Epoch [33/50], Step [404/735], Loss: 0.1191\n",
      "Epoch [33/50], Step [405/735], Loss: 0.3617\n",
      "Epoch [33/50], Step [406/735], Loss: 0.3754\n",
      "Epoch [33/50], Step [407/735], Loss: 0.6738\n",
      "Epoch [33/50], Step [408/735], Loss: 0.3610\n",
      "Epoch [33/50], Step [409/735], Loss: 0.2361\n",
      "Epoch [33/50], Step [410/735], Loss: 0.2668\n",
      "Epoch [33/50], Step [411/735], Loss: 0.4601\n",
      "Epoch [33/50], Step [412/735], Loss: 0.0665\n",
      "Epoch [33/50], Step [413/735], Loss: 0.7697\n",
      "Epoch [33/50], Step [414/735], Loss: 0.4539\n",
      "Epoch [33/50], Step [415/735], Loss: 0.1551\n",
      "Epoch [33/50], Step [416/735], Loss: 0.2670\n",
      "Epoch [33/50], Step [417/735], Loss: 0.2247\n",
      "Epoch [33/50], Step [418/735], Loss: 1.0204\n",
      "Epoch [33/50], Step [419/735], Loss: 0.2083\n",
      "Epoch [33/50], Step [420/735], Loss: 0.5016\n",
      "Epoch [33/50], Step [421/735], Loss: 0.1990\n",
      "Epoch [33/50], Step [422/735], Loss: 0.4201\n",
      "Epoch [33/50], Step [423/735], Loss: 0.4986\n",
      "Epoch [33/50], Step [424/735], Loss: 0.3723\n",
      "Epoch [33/50], Step [425/735], Loss: 0.1585\n",
      "Epoch [33/50], Step [426/735], Loss: 0.1616\n",
      "Epoch [33/50], Step [427/735], Loss: 0.1780\n",
      "Epoch [33/50], Step [428/735], Loss: 0.3324\n",
      "Epoch [33/50], Step [429/735], Loss: 0.4191\n",
      "Epoch [33/50], Step [430/735], Loss: 0.3524\n",
      "Epoch [33/50], Step [431/735], Loss: 0.0598\n",
      "Epoch [33/50], Step [432/735], Loss: 0.1922\n",
      "Epoch [33/50], Step [433/735], Loss: 0.1902\n",
      "Epoch [33/50], Step [434/735], Loss: 0.3213\n",
      "Epoch [33/50], Step [435/735], Loss: 0.9964\n",
      "Epoch [33/50], Step [436/735], Loss: 0.3536\n",
      "Epoch [33/50], Step [437/735], Loss: 0.2017\n",
      "Epoch [33/50], Step [438/735], Loss: 0.3249\n",
      "Epoch [33/50], Step [439/735], Loss: 0.2363\n",
      "Epoch [33/50], Step [440/735], Loss: 0.7684\n",
      "Epoch [33/50], Step [441/735], Loss: 0.3328\n",
      "Epoch [33/50], Step [442/735], Loss: 0.5343\n",
      "Epoch [33/50], Step [443/735], Loss: 0.7128\n",
      "Epoch [33/50], Step [444/735], Loss: 0.3720\n",
      "Epoch [33/50], Step [445/735], Loss: 0.4130\n",
      "Epoch [33/50], Step [446/735], Loss: 0.3273\n",
      "Epoch [33/50], Step [447/735], Loss: 0.6289\n",
      "Epoch [33/50], Step [448/735], Loss: 0.2600\n",
      "Epoch [33/50], Step [449/735], Loss: 0.3169\n",
      "Epoch [33/50], Step [450/735], Loss: 0.4682\n",
      "Epoch [33/50], Step [451/735], Loss: 0.0826\n",
      "Epoch [33/50], Step [452/735], Loss: 0.4850\n",
      "Epoch [33/50], Step [453/735], Loss: 0.2563\n",
      "Epoch [33/50], Step [454/735], Loss: 0.1945\n",
      "Epoch [33/50], Step [455/735], Loss: 0.2503\n",
      "Epoch [33/50], Step [456/735], Loss: 0.2647\n",
      "Epoch [33/50], Step [457/735], Loss: 0.4364\n",
      "Epoch [33/50], Step [458/735], Loss: 0.4516\n",
      "Epoch [33/50], Step [459/735], Loss: 0.4322\n",
      "Epoch [33/50], Step [460/735], Loss: 0.1000\n",
      "Epoch [33/50], Step [461/735], Loss: 0.2182\n",
      "Epoch [33/50], Step [462/735], Loss: 0.1872\n",
      "Epoch [33/50], Step [463/735], Loss: 0.3689\n",
      "Epoch [33/50], Step [464/735], Loss: 0.1182\n",
      "Epoch [33/50], Step [465/735], Loss: 0.1907\n",
      "Epoch [33/50], Step [466/735], Loss: 0.3838\n",
      "Epoch [33/50], Step [467/735], Loss: 0.3455\n",
      "Epoch [33/50], Step [468/735], Loss: 0.2846\n",
      "Epoch [33/50], Step [469/735], Loss: 0.0819\n",
      "Epoch [33/50], Step [470/735], Loss: 1.5306\n",
      "Epoch [33/50], Step [471/735], Loss: 0.3071\n",
      "Epoch [33/50], Step [472/735], Loss: 0.2194\n",
      "Epoch [33/50], Step [473/735], Loss: 0.1943\n",
      "Epoch [33/50], Step [474/735], Loss: 0.2444\n",
      "Epoch [33/50], Step [475/735], Loss: 0.2555\n",
      "Epoch [33/50], Step [476/735], Loss: 0.1958\n",
      "Epoch [33/50], Step [477/735], Loss: 0.5498\n",
      "Epoch [33/50], Step [478/735], Loss: 0.2094\n",
      "Epoch [33/50], Step [479/735], Loss: 0.6983\n",
      "Epoch [33/50], Step [480/735], Loss: 0.3021\n",
      "Epoch [33/50], Step [481/735], Loss: 0.6251\n",
      "Epoch [33/50], Step [482/735], Loss: 0.1745\n",
      "Epoch [33/50], Step [483/735], Loss: 1.7021\n",
      "Epoch [33/50], Step [484/735], Loss: 0.8288\n",
      "Epoch [33/50], Step [485/735], Loss: 1.0043\n",
      "Epoch [33/50], Step [486/735], Loss: 0.1764\n",
      "Epoch [33/50], Step [487/735], Loss: 0.2371\n",
      "Epoch [33/50], Step [488/735], Loss: 0.1798\n",
      "Epoch [33/50], Step [489/735], Loss: 0.2651\n",
      "Epoch [33/50], Step [490/735], Loss: 0.5276\n",
      "Epoch [33/50], Step [491/735], Loss: 0.2381\n",
      "Epoch [33/50], Step [492/735], Loss: 0.2042\n",
      "Epoch [33/50], Step [493/735], Loss: 0.1843\n",
      "Epoch [33/50], Step [494/735], Loss: 0.0703\n",
      "Epoch [33/50], Step [495/735], Loss: 0.4706\n",
      "Epoch [33/50], Step [496/735], Loss: 0.4347\n",
      "Epoch [33/50], Step [497/735], Loss: 0.1880\n",
      "Epoch [33/50], Step [498/735], Loss: 1.2662\n",
      "Epoch [33/50], Step [499/735], Loss: 0.1709\n",
      "Epoch [33/50], Step [500/735], Loss: 0.4056\n",
      "Epoch [33/50], Step [501/735], Loss: 0.4039\n",
      "Epoch [33/50], Step [502/735], Loss: 0.4958\n",
      "Epoch [33/50], Step [503/735], Loss: 0.1078\n",
      "Epoch [33/50], Step [504/735], Loss: 0.6393\n",
      "Epoch [33/50], Step [505/735], Loss: 0.2076\n",
      "Epoch [33/50], Step [506/735], Loss: 0.1385\n",
      "Epoch [33/50], Step [507/735], Loss: 0.7876\n",
      "Epoch [33/50], Step [508/735], Loss: 0.2058\n",
      "Epoch [33/50], Step [509/735], Loss: 0.1145\n",
      "Epoch [33/50], Step [510/735], Loss: 0.3841\n",
      "Epoch [33/50], Step [511/735], Loss: 0.3977\n",
      "Epoch [33/50], Step [512/735], Loss: 0.1456\n",
      "Epoch [33/50], Step [513/735], Loss: 1.1265\n",
      "Epoch [33/50], Step [514/735], Loss: 0.1000\n",
      "Epoch [33/50], Step [515/735], Loss: 0.2308\n",
      "Epoch [33/50], Step [516/735], Loss: 0.3113\n",
      "Epoch [33/50], Step [517/735], Loss: 0.1575\n",
      "Epoch [33/50], Step [518/735], Loss: 0.0423\n",
      "Epoch [33/50], Step [519/735], Loss: 0.4147\n",
      "Epoch [33/50], Step [520/735], Loss: 0.4594\n",
      "Epoch [33/50], Step [521/735], Loss: 0.1497\n",
      "Epoch [33/50], Step [522/735], Loss: 0.3132\n",
      "Epoch [33/50], Step [523/735], Loss: 0.1792\n",
      "Epoch [33/50], Step [524/735], Loss: 0.2422\n",
      "Epoch [33/50], Step [525/735], Loss: 0.2274\n",
      "Epoch [33/50], Step [526/735], Loss: 0.2045\n",
      "Epoch [33/50], Step [527/735], Loss: 0.2275\n",
      "Epoch [33/50], Step [528/735], Loss: 0.2794\n",
      "Epoch [33/50], Step [529/735], Loss: 0.2343\n",
      "Epoch [33/50], Step [530/735], Loss: 0.2299\n",
      "Epoch [33/50], Step [531/735], Loss: 0.1850\n",
      "Epoch [33/50], Step [532/735], Loss: 0.2639\n",
      "Epoch [33/50], Step [533/735], Loss: 0.0868\n",
      "Epoch [33/50], Step [534/735], Loss: 0.2224\n",
      "Epoch [33/50], Step [535/735], Loss: 0.2923\n",
      "Epoch [33/50], Step [536/735], Loss: 0.1488\n",
      "Epoch [33/50], Step [537/735], Loss: 0.7157\n",
      "Epoch [33/50], Step [538/735], Loss: 0.7722\n",
      "Epoch [33/50], Step [539/735], Loss: 0.1567\n",
      "Epoch [33/50], Step [540/735], Loss: 0.3189\n",
      "Epoch [33/50], Step [541/735], Loss: 0.3573\n",
      "Epoch [33/50], Step [542/735], Loss: 0.4467\n",
      "Epoch [33/50], Step [543/735], Loss: 0.4015\n",
      "Epoch [33/50], Step [544/735], Loss: 0.2692\n",
      "Epoch [33/50], Step [545/735], Loss: 0.1201\n",
      "Epoch [33/50], Step [546/735], Loss: 0.1272\n",
      "Epoch [33/50], Step [547/735], Loss: 0.3782\n",
      "Epoch [33/50], Step [548/735], Loss: 0.3962\n",
      "Epoch [33/50], Step [549/735], Loss: 0.6090\n",
      "Epoch [33/50], Step [550/735], Loss: 0.1826\n",
      "Epoch [33/50], Step [551/735], Loss: 0.4821\n",
      "Epoch [33/50], Step [552/735], Loss: 0.3984\n",
      "Epoch [33/50], Step [553/735], Loss: 0.6199\n",
      "Epoch [33/50], Step [554/735], Loss: 0.4210\n",
      "Epoch [33/50], Step [555/735], Loss: 0.2449\n",
      "Epoch [33/50], Step [556/735], Loss: 0.3307\n",
      "Epoch [33/50], Step [557/735], Loss: 0.2866\n",
      "Epoch [33/50], Step [558/735], Loss: 0.6026\n",
      "Epoch [33/50], Step [559/735], Loss: 0.2497\n",
      "Epoch [33/50], Step [560/735], Loss: 0.3974\n",
      "Epoch [33/50], Step [561/735], Loss: 0.5562\n",
      "Epoch [33/50], Step [562/735], Loss: 0.5484\n",
      "Epoch [33/50], Step [563/735], Loss: 0.1194\n",
      "Epoch [33/50], Step [564/735], Loss: 0.1845\n",
      "Epoch [33/50], Step [565/735], Loss: 0.4812\n",
      "Epoch [33/50], Step [566/735], Loss: 0.8455\n",
      "Epoch [33/50], Step [567/735], Loss: 0.2659\n",
      "Epoch [33/50], Step [568/735], Loss: 0.2394\n",
      "Epoch [33/50], Step [569/735], Loss: 0.3156\n",
      "Epoch [33/50], Step [570/735], Loss: 0.4683\n",
      "Epoch [33/50], Step [571/735], Loss: 0.0765\n",
      "Epoch [33/50], Step [572/735], Loss: 0.4746\n",
      "Epoch [33/50], Step [573/735], Loss: 0.2375\n",
      "Epoch [33/50], Step [574/735], Loss: 0.3721\n",
      "Epoch [33/50], Step [575/735], Loss: 0.2386\n",
      "Epoch [33/50], Step [576/735], Loss: 0.2687\n",
      "Epoch [33/50], Step [577/735], Loss: 0.0819\n",
      "Epoch [33/50], Step [578/735], Loss: 0.1845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Step [579/735], Loss: 0.6698\n",
      "Epoch [33/50], Step [580/735], Loss: 0.2743\n",
      "Epoch [33/50], Step [581/735], Loss: 0.2561\n",
      "Epoch [33/50], Step [582/735], Loss: 0.2352\n",
      "Epoch [33/50], Step [583/735], Loss: 0.2850\n",
      "Epoch [33/50], Step [584/735], Loss: 0.6561\n",
      "Epoch [33/50], Step [585/735], Loss: 0.0902\n",
      "Epoch [33/50], Step [586/735], Loss: 0.4889\n",
      "Epoch [33/50], Step [587/735], Loss: 0.1100\n",
      "Epoch [33/50], Step [588/735], Loss: 0.0730\n",
      "Epoch [33/50], Step [589/735], Loss: 0.1891\n",
      "Epoch [33/50], Step [590/735], Loss: 0.2963\n",
      "Epoch [33/50], Step [591/735], Loss: 0.6423\n",
      "Epoch [33/50], Step [592/735], Loss: 0.1645\n",
      "Epoch [33/50], Step [593/735], Loss: 0.2537\n",
      "Epoch [33/50], Step [594/735], Loss: 0.2523\n",
      "Epoch [33/50], Step [595/735], Loss: 0.2628\n",
      "Epoch [33/50], Step [596/735], Loss: 0.0888\n",
      "Epoch [33/50], Step [597/735], Loss: 1.0569\n",
      "Epoch [33/50], Step [598/735], Loss: 0.2847\n",
      "Epoch [33/50], Step [599/735], Loss: 0.1561\n",
      "Epoch [33/50], Step [600/735], Loss: 0.1939\n",
      "Epoch [33/50], Step [601/735], Loss: 0.1542\n",
      "Epoch [33/50], Step [602/735], Loss: 0.2338\n",
      "Epoch [33/50], Step [603/735], Loss: 0.2128\n",
      "Epoch [33/50], Step [604/735], Loss: 0.0376\n",
      "Epoch [33/50], Step [605/735], Loss: 0.1513\n",
      "Epoch [33/50], Step [606/735], Loss: 0.2294\n",
      "Epoch [33/50], Step [607/735], Loss: 0.7351\n",
      "Epoch [33/50], Step [608/735], Loss: 0.2890\n",
      "Epoch [33/50], Step [609/735], Loss: 0.4609\n",
      "Epoch [33/50], Step [610/735], Loss: 0.2282\n",
      "Epoch [33/50], Step [611/735], Loss: 0.5662\n",
      "Epoch [33/50], Step [612/735], Loss: 0.1569\n",
      "Epoch [33/50], Step [613/735], Loss: 0.8995\n",
      "Epoch [33/50], Step [614/735], Loss: 0.2878\n",
      "Epoch [33/50], Step [615/735], Loss: 0.3634\n",
      "Epoch [33/50], Step [616/735], Loss: 0.6685\n",
      "Epoch [33/50], Step [617/735], Loss: 0.4578\n",
      "Epoch [33/50], Step [618/735], Loss: 0.1597\n",
      "Epoch [33/50], Step [619/735], Loss: 0.3262\n",
      "Epoch [33/50], Step [620/735], Loss: 0.1485\n",
      "Epoch [33/50], Step [621/735], Loss: 0.9088\n",
      "Epoch [33/50], Step [622/735], Loss: 0.2703\n",
      "Epoch [33/50], Step [623/735], Loss: 0.1213\n",
      "Epoch [33/50], Step [624/735], Loss: 1.4842\n",
      "Epoch [33/50], Step [625/735], Loss: 0.2969\n",
      "Epoch [33/50], Step [626/735], Loss: 0.3542\n",
      "Epoch [33/50], Step [627/735], Loss: 0.1170\n",
      "Epoch [33/50], Step [628/735], Loss: 0.1616\n",
      "Epoch [33/50], Step [629/735], Loss: 0.4450\n",
      "Epoch [33/50], Step [630/735], Loss: 0.2310\n",
      "Epoch [33/50], Step [631/735], Loss: 0.5233\n",
      "Epoch [33/50], Step [632/735], Loss: 0.2731\n",
      "Epoch [33/50], Step [633/735], Loss: 0.3212\n",
      "Epoch [33/50], Step [634/735], Loss: 0.3828\n",
      "Epoch [33/50], Step [635/735], Loss: 0.5024\n",
      "Epoch [33/50], Step [636/735], Loss: 0.2303\n",
      "Epoch [33/50], Step [637/735], Loss: 0.1573\n",
      "Epoch [33/50], Step [638/735], Loss: 0.2016\n",
      "Epoch [33/50], Step [639/735], Loss: 0.3511\n",
      "Epoch [33/50], Step [640/735], Loss: 0.2495\n",
      "Epoch [33/50], Step [641/735], Loss: 0.2583\n",
      "Epoch [33/50], Step [642/735], Loss: 0.1709\n",
      "Epoch [33/50], Step [643/735], Loss: 0.6858\n",
      "Epoch [33/50], Step [644/735], Loss: 0.7436\n",
      "Epoch [33/50], Step [645/735], Loss: 0.2001\n",
      "Epoch [33/50], Step [646/735], Loss: 0.4334\n",
      "Epoch [33/50], Step [647/735], Loss: 0.3105\n",
      "Epoch [33/50], Step [648/735], Loss: 0.4329\n",
      "Epoch [33/50], Step [649/735], Loss: 0.4485\n",
      "Epoch [33/50], Step [650/735], Loss: 0.1878\n",
      "Epoch [33/50], Step [651/735], Loss: 0.1625\n",
      "Epoch [33/50], Step [652/735], Loss: 0.0937\n",
      "Epoch [33/50], Step [653/735], Loss: 1.3246\n",
      "Epoch [33/50], Step [654/735], Loss: 0.2156\n",
      "Epoch [33/50], Step [655/735], Loss: 0.4075\n",
      "Epoch [33/50], Step [656/735], Loss: 0.5841\n",
      "Epoch [33/50], Step [657/735], Loss: 0.1981\n",
      "Epoch [33/50], Step [658/735], Loss: 0.4083\n",
      "Epoch [33/50], Step [659/735], Loss: 0.1944\n",
      "Epoch [33/50], Step [660/735], Loss: 0.1582\n",
      "Epoch [33/50], Step [661/735], Loss: 0.6092\n",
      "Epoch [33/50], Step [662/735], Loss: 0.2310\n",
      "Epoch [33/50], Step [663/735], Loss: 0.3228\n",
      "Epoch [33/50], Step [664/735], Loss: 0.2519\n",
      "Epoch [33/50], Step [665/735], Loss: 0.6478\n",
      "Epoch [33/50], Step [666/735], Loss: 0.3234\n",
      "Epoch [33/50], Step [667/735], Loss: 0.3619\n",
      "Epoch [33/50], Step [668/735], Loss: 0.1886\n",
      "Epoch [33/50], Step [669/735], Loss: 0.3116\n",
      "Epoch [33/50], Step [670/735], Loss: 0.3060\n",
      "Epoch [33/50], Step [671/735], Loss: 0.3130\n",
      "Epoch [33/50], Step [672/735], Loss: 0.2276\n",
      "Epoch [33/50], Step [673/735], Loss: 0.6055\n",
      "Epoch [33/50], Step [674/735], Loss: 0.3798\n",
      "Epoch [33/50], Step [675/735], Loss: 0.1763\n",
      "Epoch [33/50], Step [676/735], Loss: 0.2171\n",
      "Epoch [33/50], Step [677/735], Loss: 0.1210\n",
      "Epoch [33/50], Step [678/735], Loss: 0.0679\n",
      "Epoch [33/50], Step [679/735], Loss: 0.1073\n",
      "Epoch [33/50], Step [680/735], Loss: 0.2265\n",
      "Epoch [33/50], Step [681/735], Loss: 0.0675\n",
      "Epoch [33/50], Step [682/735], Loss: 0.1402\n",
      "Epoch [33/50], Step [683/735], Loss: 0.1771\n",
      "Epoch [33/50], Step [684/735], Loss: 0.6004\n",
      "Epoch [33/50], Step [685/735], Loss: 0.6600\n",
      "Epoch [33/50], Step [686/735], Loss: 0.7726\n",
      "Epoch [33/50], Step [687/735], Loss: 0.6283\n",
      "Epoch [33/50], Step [688/735], Loss: 0.2388\n",
      "Epoch [33/50], Step [689/735], Loss: 0.2980\n",
      "Epoch [33/50], Step [690/735], Loss: 0.2542\n",
      "Epoch [33/50], Step [691/735], Loss: 0.4188\n",
      "Epoch [33/50], Step [692/735], Loss: 0.0427\n",
      "Epoch [33/50], Step [693/735], Loss: 0.4061\n",
      "Epoch [33/50], Step [694/735], Loss: 0.1302\n",
      "Epoch [33/50], Step [695/735], Loss: 0.2007\n",
      "Epoch [33/50], Step [696/735], Loss: 0.4253\n",
      "Epoch [33/50], Step [697/735], Loss: 0.2220\n",
      "Epoch [33/50], Step [698/735], Loss: 0.4462\n",
      "Epoch [33/50], Step [699/735], Loss: 0.2972\n",
      "Epoch [33/50], Step [700/735], Loss: 0.1678\n",
      "Epoch [33/50], Step [701/735], Loss: 0.1258\n",
      "Epoch [33/50], Step [702/735], Loss: 0.3484\n",
      "Epoch [33/50], Step [703/735], Loss: 0.4388\n",
      "Epoch [33/50], Step [704/735], Loss: 0.0918\n",
      "Epoch [33/50], Step [705/735], Loss: 0.1444\n",
      "Epoch [33/50], Step [706/735], Loss: 0.2527\n",
      "Epoch [33/50], Step [707/735], Loss: 0.0743\n",
      "Epoch [33/50], Step [708/735], Loss: 0.1470\n",
      "Epoch [33/50], Step [709/735], Loss: 0.5615\n",
      "Epoch [33/50], Step [710/735], Loss: 0.1364\n",
      "Epoch [33/50], Step [711/735], Loss: 0.1550\n",
      "Epoch [33/50], Step [712/735], Loss: 0.2023\n",
      "Epoch [33/50], Step [713/735], Loss: 0.3856\n",
      "Epoch [33/50], Step [714/735], Loss: 0.2048\n",
      "Epoch [33/50], Step [715/735], Loss: 0.6060\n",
      "Epoch [33/50], Step [716/735], Loss: 1.0974\n",
      "Epoch [33/50], Step [717/735], Loss: 0.2507\n",
      "Epoch [33/50], Step [718/735], Loss: 0.7178\n",
      "Epoch [33/50], Step [719/735], Loss: 0.6329\n",
      "Epoch [33/50], Step [720/735], Loss: 0.1141\n",
      "Epoch [33/50], Step [721/735], Loss: 0.2931\n",
      "Epoch [33/50], Step [722/735], Loss: 0.2900\n",
      "Epoch [33/50], Step [723/735], Loss: 0.4616\n",
      "Epoch [33/50], Step [724/735], Loss: 0.1631\n",
      "Epoch [33/50], Step [725/735], Loss: 0.1588\n",
      "Epoch [33/50], Step [726/735], Loss: 0.3900\n",
      "Epoch [33/50], Step [727/735], Loss: 0.1112\n",
      "Epoch [33/50], Step [728/735], Loss: 0.1472\n",
      "Epoch [33/50], Step [729/735], Loss: 0.2461\n",
      "Epoch [33/50], Step [730/735], Loss: 0.1741\n",
      "Epoch [33/50], Step [731/735], Loss: 0.1689\n",
      "Epoch [33/50], Step [732/735], Loss: 0.1848\n",
      "Epoch [33/50], Step [733/735], Loss: 0.3814\n",
      "Epoch [33/50], Step [734/735], Loss: 0.2949\n",
      "Epoch [33/50], Step [735/735], Loss: 0.0192\n",
      "Epoch [34/50], Step [1/735], Loss: 0.1332\n",
      "Epoch [34/50], Step [2/735], Loss: 0.1193\n",
      "Epoch [34/50], Step [3/735], Loss: 0.1573\n",
      "Epoch [34/50], Step [4/735], Loss: 0.7613\n",
      "Epoch [34/50], Step [5/735], Loss: 0.3340\n",
      "Epoch [34/50], Step [6/735], Loss: 0.4805\n",
      "Epoch [34/50], Step [7/735], Loss: 0.4366\n",
      "Epoch [34/50], Step [8/735], Loss: 0.1807\n",
      "Epoch [34/50], Step [9/735], Loss: 0.1292\n",
      "Epoch [34/50], Step [10/735], Loss: 0.0958\n",
      "Epoch [34/50], Step [11/735], Loss: 0.1187\n",
      "Epoch [34/50], Step [12/735], Loss: 0.0754\n",
      "Epoch [34/50], Step [13/735], Loss: 0.3171\n",
      "Epoch [34/50], Step [14/735], Loss: 0.5027\n",
      "Epoch [34/50], Step [15/735], Loss: 0.2102\n",
      "Epoch [34/50], Step [16/735], Loss: 0.3969\n",
      "Epoch [34/50], Step [17/735], Loss: 0.4737\n",
      "Epoch [34/50], Step [18/735], Loss: 0.1231\n",
      "Epoch [34/50], Step [19/735], Loss: 3.3889\n",
      "Epoch [34/50], Step [20/735], Loss: 0.1335\n",
      "Epoch [34/50], Step [21/735], Loss: 0.1220\n",
      "Epoch [34/50], Step [22/735], Loss: 0.1143\n",
      "Epoch [34/50], Step [23/735], Loss: 0.1022\n",
      "Epoch [34/50], Step [24/735], Loss: 0.1823\n",
      "Epoch [34/50], Step [25/735], Loss: 0.1319\n",
      "Epoch [34/50], Step [26/735], Loss: 0.3565\n",
      "Epoch [34/50], Step [27/735], Loss: 1.1625\n",
      "Epoch [34/50], Step [28/735], Loss: 0.1629\n",
      "Epoch [34/50], Step [29/735], Loss: 0.5586\n",
      "Epoch [34/50], Step [30/735], Loss: 0.4674\n",
      "Epoch [34/50], Step [31/735], Loss: 0.2659\n",
      "Epoch [34/50], Step [32/735], Loss: 0.4754\n",
      "Epoch [34/50], Step [33/735], Loss: 0.1178\n",
      "Epoch [34/50], Step [34/735], Loss: 0.4268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Step [35/735], Loss: 0.6583\n",
      "Epoch [34/50], Step [36/735], Loss: 0.1460\n",
      "Epoch [34/50], Step [37/735], Loss: 0.2311\n",
      "Epoch [34/50], Step [38/735], Loss: 0.4641\n",
      "Epoch [34/50], Step [39/735], Loss: 0.1047\n",
      "Epoch [34/50], Step [40/735], Loss: 0.1389\n",
      "Epoch [34/50], Step [41/735], Loss: 0.5409\n",
      "Epoch [34/50], Step [42/735], Loss: 0.7459\n",
      "Epoch [34/50], Step [43/735], Loss: 0.1924\n",
      "Epoch [34/50], Step [44/735], Loss: 0.1630\n",
      "Epoch [34/50], Step [45/735], Loss: 0.3330\n",
      "Epoch [34/50], Step [46/735], Loss: 0.0621\n",
      "Epoch [34/50], Step [47/735], Loss: 0.1708\n",
      "Epoch [34/50], Step [48/735], Loss: 0.2580\n",
      "Epoch [34/50], Step [49/735], Loss: 0.2641\n",
      "Epoch [34/50], Step [50/735], Loss: 0.2207\n",
      "Epoch [34/50], Step [51/735], Loss: 0.2778\n",
      "Epoch [34/50], Step [52/735], Loss: 0.2198\n",
      "Epoch [34/50], Step [53/735], Loss: 0.2472\n",
      "Epoch [34/50], Step [54/735], Loss: 0.2658\n",
      "Epoch [34/50], Step [55/735], Loss: 0.1732\n",
      "Epoch [34/50], Step [56/735], Loss: 0.1805\n",
      "Epoch [34/50], Step [57/735], Loss: 0.4837\n",
      "Epoch [34/50], Step [58/735], Loss: 0.1180\n",
      "Epoch [34/50], Step [59/735], Loss: 0.5500\n",
      "Epoch [34/50], Step [60/735], Loss: 0.1165\n",
      "Epoch [34/50], Step [61/735], Loss: 0.2030\n",
      "Epoch [34/50], Step [62/735], Loss: 0.2424\n",
      "Epoch [34/50], Step [63/735], Loss: 0.3403\n",
      "Epoch [34/50], Step [64/735], Loss: 0.1630\n",
      "Epoch [34/50], Step [65/735], Loss: 0.1916\n",
      "Epoch [34/50], Step [66/735], Loss: 0.3772\n",
      "Epoch [34/50], Step [67/735], Loss: 0.4301\n",
      "Epoch [34/50], Step [68/735], Loss: 0.8664\n",
      "Epoch [34/50], Step [69/735], Loss: 0.3427\n",
      "Epoch [34/50], Step [70/735], Loss: 0.2586\n",
      "Epoch [34/50], Step [71/735], Loss: 0.5515\n",
      "Epoch [34/50], Step [72/735], Loss: 0.3294\n",
      "Epoch [34/50], Step [73/735], Loss: 0.3745\n",
      "Epoch [34/50], Step [74/735], Loss: 0.6630\n",
      "Epoch [34/50], Step [75/735], Loss: 0.3058\n",
      "Epoch [34/50], Step [76/735], Loss: 0.1809\n",
      "Epoch [34/50], Step [77/735], Loss: 0.3200\n",
      "Epoch [34/50], Step [78/735], Loss: 0.7997\n",
      "Epoch [34/50], Step [79/735], Loss: 0.3299\n",
      "Epoch [34/50], Step [80/735], Loss: 0.1106\n",
      "Epoch [34/50], Step [81/735], Loss: 0.2027\n",
      "Epoch [34/50], Step [82/735], Loss: 0.1419\n",
      "Epoch [34/50], Step [83/735], Loss: 0.0840\n",
      "Epoch [34/50], Step [84/735], Loss: 0.2018\n",
      "Epoch [34/50], Step [85/735], Loss: 0.5064\n",
      "Epoch [34/50], Step [86/735], Loss: 0.2677\n",
      "Epoch [34/50], Step [87/735], Loss: 0.1995\n",
      "Epoch [34/50], Step [88/735], Loss: 0.2199\n",
      "Epoch [34/50], Step [89/735], Loss: 0.2135\n",
      "Epoch [34/50], Step [90/735], Loss: 0.1708\n",
      "Epoch [34/50], Step [91/735], Loss: 0.2637\n",
      "Epoch [34/50], Step [92/735], Loss: 0.7387\n",
      "Epoch [34/50], Step [93/735], Loss: 0.1636\n",
      "Epoch [34/50], Step [94/735], Loss: 0.0841\n",
      "Epoch [34/50], Step [95/735], Loss: 0.4986\n",
      "Epoch [34/50], Step [96/735], Loss: 0.2636\n",
      "Epoch [34/50], Step [97/735], Loss: 0.3212\n",
      "Epoch [34/50], Step [98/735], Loss: 0.8230\n",
      "Epoch [34/50], Step [99/735], Loss: 0.8677\n",
      "Epoch [34/50], Step [100/735], Loss: 0.1450\n",
      "Epoch [34/50], Step [101/735], Loss: 0.8430\n",
      "Epoch [34/50], Step [102/735], Loss: 0.1918\n",
      "Epoch [34/50], Step [103/735], Loss: 0.0960\n",
      "Epoch [34/50], Step [104/735], Loss: 0.2927\n",
      "Epoch [34/50], Step [105/735], Loss: 0.2862\n",
      "Epoch [34/50], Step [106/735], Loss: 0.1338\n",
      "Epoch [34/50], Step [107/735], Loss: 0.2858\n",
      "Epoch [34/50], Step [108/735], Loss: 0.2966\n",
      "Epoch [34/50], Step [109/735], Loss: 0.3531\n",
      "Epoch [34/50], Step [110/735], Loss: 0.2762\n",
      "Epoch [34/50], Step [111/735], Loss: 0.5116\n",
      "Epoch [34/50], Step [112/735], Loss: 0.3563\n",
      "Epoch [34/50], Step [113/735], Loss: 0.2263\n",
      "Epoch [34/50], Step [114/735], Loss: 0.2138\n",
      "Epoch [34/50], Step [115/735], Loss: 0.2578\n",
      "Epoch [34/50], Step [116/735], Loss: 0.1889\n",
      "Epoch [34/50], Step [117/735], Loss: 0.1889\n",
      "Epoch [34/50], Step [118/735], Loss: 0.3085\n",
      "Epoch [34/50], Step [119/735], Loss: 0.6801\n",
      "Epoch [34/50], Step [120/735], Loss: 0.4519\n",
      "Epoch [34/50], Step [121/735], Loss: 0.2465\n",
      "Epoch [34/50], Step [122/735], Loss: 0.5634\n",
      "Epoch [34/50], Step [123/735], Loss: 0.7875\n",
      "Epoch [34/50], Step [124/735], Loss: 0.1949\n",
      "Epoch [34/50], Step [125/735], Loss: 0.4800\n",
      "Epoch [34/50], Step [126/735], Loss: 0.4798\n",
      "Epoch [34/50], Step [127/735], Loss: 0.4771\n",
      "Epoch [34/50], Step [128/735], Loss: 1.0504\n",
      "Epoch [34/50], Step [129/735], Loss: 0.1981\n",
      "Epoch [34/50], Step [130/735], Loss: 0.3050\n",
      "Epoch [34/50], Step [131/735], Loss: 0.7180\n",
      "Epoch [34/50], Step [132/735], Loss: 0.9275\n",
      "Epoch [34/50], Step [133/735], Loss: 0.7151\n",
      "Epoch [34/50], Step [134/735], Loss: 0.2175\n",
      "Epoch [34/50], Step [135/735], Loss: 0.3245\n",
      "Epoch [34/50], Step [136/735], Loss: 0.8616\n",
      "Epoch [34/50], Step [137/735], Loss: 0.9226\n",
      "Epoch [34/50], Step [138/735], Loss: 0.3020\n",
      "Epoch [34/50], Step [139/735], Loss: 0.5508\n",
      "Epoch [34/50], Step [140/735], Loss: 0.4843\n",
      "Epoch [34/50], Step [141/735], Loss: 0.2190\n",
      "Epoch [34/50], Step [142/735], Loss: 0.2752\n",
      "Epoch [34/50], Step [143/735], Loss: 0.3628\n",
      "Epoch [34/50], Step [144/735], Loss: 0.1445\n",
      "Epoch [34/50], Step [145/735], Loss: 0.2016\n",
      "Epoch [34/50], Step [146/735], Loss: 0.1626\n",
      "Epoch [34/50], Step [147/735], Loss: 0.3320\n",
      "Epoch [34/50], Step [148/735], Loss: 0.1644\n",
      "Epoch [34/50], Step [149/735], Loss: 0.1251\n",
      "Epoch [34/50], Step [150/735], Loss: 0.4269\n",
      "Epoch [34/50], Step [151/735], Loss: 0.5184\n",
      "Epoch [34/50], Step [152/735], Loss: 0.3894\n",
      "Epoch [34/50], Step [153/735], Loss: 0.3957\n",
      "Epoch [34/50], Step [154/735], Loss: 0.1876\n",
      "Epoch [34/50], Step [155/735], Loss: 0.4142\n",
      "Epoch [34/50], Step [156/735], Loss: 0.2044\n",
      "Epoch [34/50], Step [157/735], Loss: 0.3476\n",
      "Epoch [34/50], Step [158/735], Loss: 0.6860\n",
      "Epoch [34/50], Step [159/735], Loss: 0.2283\n",
      "Epoch [34/50], Step [160/735], Loss: 0.1055\n",
      "Epoch [34/50], Step [161/735], Loss: 0.1119\n",
      "Epoch [34/50], Step [162/735], Loss: 0.2189\n",
      "Epoch [34/50], Step [163/735], Loss: 0.3012\n",
      "Epoch [34/50], Step [164/735], Loss: 0.1102\n",
      "Epoch [34/50], Step [165/735], Loss: 0.2489\n",
      "Epoch [34/50], Step [166/735], Loss: 0.1697\n",
      "Epoch [34/50], Step [167/735], Loss: 0.4093\n",
      "Epoch [34/50], Step [168/735], Loss: 0.6428\n",
      "Epoch [34/50], Step [169/735], Loss: 0.1013\n",
      "Epoch [34/50], Step [170/735], Loss: 0.1565\n",
      "Epoch [34/50], Step [171/735], Loss: 0.4602\n",
      "Epoch [34/50], Step [172/735], Loss: 0.1620\n",
      "Epoch [34/50], Step [173/735], Loss: 0.4113\n",
      "Epoch [34/50], Step [174/735], Loss: 0.2602\n",
      "Epoch [34/50], Step [175/735], Loss: 0.2056\n",
      "Epoch [34/50], Step [176/735], Loss: 0.4755\n",
      "Epoch [34/50], Step [177/735], Loss: 0.1090\n",
      "Epoch [34/50], Step [178/735], Loss: 0.3095\n",
      "Epoch [34/50], Step [179/735], Loss: 0.3309\n",
      "Epoch [34/50], Step [180/735], Loss: 0.2654\n",
      "Epoch [34/50], Step [181/735], Loss: 0.1061\n",
      "Epoch [34/50], Step [182/735], Loss: 0.1149\n",
      "Epoch [34/50], Step [183/735], Loss: 0.0926\n",
      "Epoch [34/50], Step [184/735], Loss: 0.5906\n",
      "Epoch [34/50], Step [185/735], Loss: 0.0881\n",
      "Epoch [34/50], Step [186/735], Loss: 0.3007\n",
      "Epoch [34/50], Step [187/735], Loss: 0.1130\n",
      "Epoch [34/50], Step [188/735], Loss: 0.2191\n",
      "Epoch [34/50], Step [189/735], Loss: 0.0770\n",
      "Epoch [34/50], Step [190/735], Loss: 0.1774\n",
      "Epoch [34/50], Step [191/735], Loss: 0.4819\n",
      "Epoch [34/50], Step [192/735], Loss: 0.3898\n",
      "Epoch [34/50], Step [193/735], Loss: 0.3391\n",
      "Epoch [34/50], Step [194/735], Loss: 0.2791\n",
      "Epoch [34/50], Step [195/735], Loss: 0.1143\n",
      "Epoch [34/50], Step [196/735], Loss: 0.5611\n",
      "Epoch [34/50], Step [197/735], Loss: 0.7203\n",
      "Epoch [34/50], Step [198/735], Loss: 0.0945\n",
      "Epoch [34/50], Step [199/735], Loss: 0.3679\n",
      "Epoch [34/50], Step [200/735], Loss: 0.1020\n",
      "Epoch [34/50], Step [201/735], Loss: 0.3504\n",
      "Epoch [34/50], Step [202/735], Loss: 0.2652\n",
      "Epoch [34/50], Step [203/735], Loss: 0.8685\n",
      "Epoch [34/50], Step [204/735], Loss: 0.3490\n",
      "Epoch [34/50], Step [205/735], Loss: 0.0504\n",
      "Epoch [34/50], Step [206/735], Loss: 0.2818\n",
      "Epoch [34/50], Step [207/735], Loss: 0.3524\n",
      "Epoch [34/50], Step [208/735], Loss: 0.5317\n",
      "Epoch [34/50], Step [209/735], Loss: 0.2347\n",
      "Epoch [34/50], Step [210/735], Loss: 0.0520\n",
      "Epoch [34/50], Step [211/735], Loss: 0.0368\n",
      "Epoch [34/50], Step [212/735], Loss: 0.2048\n",
      "Epoch [34/50], Step [213/735], Loss: 0.2903\n",
      "Epoch [34/50], Step [214/735], Loss: 0.1647\n",
      "Epoch [34/50], Step [215/735], Loss: 0.2118\n",
      "Epoch [34/50], Step [216/735], Loss: 0.0252\n",
      "Epoch [34/50], Step [217/735], Loss: 0.0833\n",
      "Epoch [34/50], Step [218/735], Loss: 0.1734\n",
      "Epoch [34/50], Step [219/735], Loss: 0.5624\n",
      "Epoch [34/50], Step [220/735], Loss: 0.2517\n",
      "Epoch [34/50], Step [221/735], Loss: 0.3126\n",
      "Epoch [34/50], Step [222/735], Loss: 0.4808\n",
      "Epoch [34/50], Step [223/735], Loss: 0.3920\n",
      "Epoch [34/50], Step [224/735], Loss: 0.5318\n",
      "Epoch [34/50], Step [225/735], Loss: 0.0932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Step [226/735], Loss: 0.9490\n",
      "Epoch [34/50], Step [227/735], Loss: 0.2962\n",
      "Epoch [34/50], Step [228/735], Loss: 0.1163\n",
      "Epoch [34/50], Step [229/735], Loss: 0.3797\n",
      "Epoch [34/50], Step [230/735], Loss: 0.3424\n",
      "Epoch [34/50], Step [231/735], Loss: 0.1382\n",
      "Epoch [34/50], Step [232/735], Loss: 0.2686\n",
      "Epoch [34/50], Step [233/735], Loss: 0.1310\n",
      "Epoch [34/50], Step [234/735], Loss: 0.1673\n",
      "Epoch [34/50], Step [235/735], Loss: 0.2568\n",
      "Epoch [34/50], Step [236/735], Loss: 0.1012\n",
      "Epoch [34/50], Step [237/735], Loss: 0.5491\n",
      "Epoch [34/50], Step [238/735], Loss: 0.4732\n",
      "Epoch [34/50], Step [239/735], Loss: 0.3834\n",
      "Epoch [34/50], Step [240/735], Loss: 0.2236\n",
      "Epoch [34/50], Step [241/735], Loss: 0.2661\n",
      "Epoch [34/50], Step [242/735], Loss: 0.1816\n",
      "Epoch [34/50], Step [243/735], Loss: 0.1708\n",
      "Epoch [34/50], Step [244/735], Loss: 0.9524\n",
      "Epoch [34/50], Step [245/735], Loss: 0.2034\n",
      "Epoch [34/50], Step [246/735], Loss: 0.1412\n",
      "Epoch [34/50], Step [247/735], Loss: 0.4486\n",
      "Epoch [34/50], Step [248/735], Loss: 0.5757\n",
      "Epoch [34/50], Step [249/735], Loss: 0.2134\n",
      "Epoch [34/50], Step [250/735], Loss: 0.2173\n",
      "Epoch [34/50], Step [251/735], Loss: 0.4917\n",
      "Epoch [34/50], Step [252/735], Loss: 1.1415\n",
      "Epoch [34/50], Step [253/735], Loss: 0.3402\n",
      "Epoch [34/50], Step [254/735], Loss: 0.4123\n",
      "Epoch [34/50], Step [255/735], Loss: 0.2979\n",
      "Epoch [34/50], Step [256/735], Loss: 0.7454\n",
      "Epoch [34/50], Step [257/735], Loss: 0.1393\n",
      "Epoch [34/50], Step [258/735], Loss: 0.3936\n",
      "Epoch [34/50], Step [259/735], Loss: 0.6199\n",
      "Epoch [34/50], Step [260/735], Loss: 0.4606\n",
      "Epoch [34/50], Step [261/735], Loss: 0.2331\n",
      "Epoch [34/50], Step [262/735], Loss: 0.1189\n",
      "Epoch [34/50], Step [263/735], Loss: 0.2982\n",
      "Epoch [34/50], Step [264/735], Loss: 0.4486\n",
      "Epoch [34/50], Step [265/735], Loss: 0.1378\n",
      "Epoch [34/50], Step [266/735], Loss: 0.2467\n",
      "Epoch [34/50], Step [267/735], Loss: 0.1754\n",
      "Epoch [34/50], Step [268/735], Loss: 0.3715\n",
      "Epoch [34/50], Step [269/735], Loss: 0.1992\n",
      "Epoch [34/50], Step [270/735], Loss: 0.1586\n",
      "Epoch [34/50], Step [271/735], Loss: 1.0006\n",
      "Epoch [34/50], Step [272/735], Loss: 0.0877\n",
      "Epoch [34/50], Step [273/735], Loss: 0.2757\n",
      "Epoch [34/50], Step [274/735], Loss: 0.2170\n",
      "Epoch [34/50], Step [275/735], Loss: 0.7059\n",
      "Epoch [34/50], Step [276/735], Loss: 0.1825\n",
      "Epoch [34/50], Step [277/735], Loss: 0.2730\n",
      "Epoch [34/50], Step [278/735], Loss: 0.3144\n",
      "Epoch [34/50], Step [279/735], Loss: 0.3201\n",
      "Epoch [34/50], Step [280/735], Loss: 0.7100\n",
      "Epoch [34/50], Step [281/735], Loss: 0.7179\n",
      "Epoch [34/50], Step [282/735], Loss: 0.3567\n",
      "Epoch [34/50], Step [283/735], Loss: 0.2496\n",
      "Epoch [34/50], Step [284/735], Loss: 4.1174\n",
      "Epoch [34/50], Step [285/735], Loss: 0.2722\n",
      "Epoch [34/50], Step [286/735], Loss: 0.2415\n",
      "Epoch [34/50], Step [287/735], Loss: 0.2444\n",
      "Epoch [34/50], Step [288/735], Loss: 0.1595\n",
      "Epoch [34/50], Step [289/735], Loss: 0.5156\n",
      "Epoch [34/50], Step [290/735], Loss: 0.1423\n",
      "Epoch [34/50], Step [291/735], Loss: 0.2205\n",
      "Epoch [34/50], Step [292/735], Loss: 0.4792\n",
      "Epoch [34/50], Step [293/735], Loss: 0.5236\n",
      "Epoch [34/50], Step [294/735], Loss: 0.9876\n",
      "Epoch [34/50], Step [295/735], Loss: 0.2526\n",
      "Epoch [34/50], Step [296/735], Loss: 0.2047\n",
      "Epoch [34/50], Step [297/735], Loss: 0.7160\n",
      "Epoch [34/50], Step [298/735], Loss: 0.3153\n",
      "Epoch [34/50], Step [299/735], Loss: 0.5837\n",
      "Epoch [34/50], Step [300/735], Loss: 0.2626\n",
      "Epoch [34/50], Step [301/735], Loss: 0.3711\n",
      "Epoch [34/50], Step [302/735], Loss: 0.1199\n",
      "Epoch [34/50], Step [303/735], Loss: 0.8981\n",
      "Epoch [34/50], Step [304/735], Loss: 0.2998\n",
      "Epoch [34/50], Step [305/735], Loss: 0.3121\n",
      "Epoch [34/50], Step [306/735], Loss: 0.0914\n",
      "Epoch [34/50], Step [307/735], Loss: 0.3291\n",
      "Epoch [34/50], Step [308/735], Loss: 0.2516\n",
      "Epoch [34/50], Step [309/735], Loss: 0.1988\n",
      "Epoch [34/50], Step [310/735], Loss: 0.3750\n",
      "Epoch [34/50], Step [311/735], Loss: 0.2842\n",
      "Epoch [34/50], Step [312/735], Loss: 0.2996\n",
      "Epoch [34/50], Step [313/735], Loss: 0.2992\n",
      "Epoch [34/50], Step [314/735], Loss: 0.1474\n",
      "Epoch [34/50], Step [315/735], Loss: 0.2432\n",
      "Epoch [34/50], Step [316/735], Loss: 0.2988\n",
      "Epoch [34/50], Step [317/735], Loss: 0.4241\n",
      "Epoch [34/50], Step [318/735], Loss: 0.6485\n",
      "Epoch [34/50], Step [319/735], Loss: 0.1654\n",
      "Epoch [34/50], Step [320/735], Loss: 0.4439\n",
      "Epoch [34/50], Step [321/735], Loss: 0.1841\n",
      "Epoch [34/50], Step [322/735], Loss: 0.0743\n",
      "Epoch [34/50], Step [323/735], Loss: 0.4711\n",
      "Epoch [34/50], Step [324/735], Loss: 0.4176\n",
      "Epoch [34/50], Step [325/735], Loss: 0.1413\n",
      "Epoch [34/50], Step [326/735], Loss: 0.1594\n",
      "Epoch [34/50], Step [327/735], Loss: 0.2838\n",
      "Epoch [34/50], Step [328/735], Loss: 0.4477\n",
      "Epoch [34/50], Step [329/735], Loss: 0.2910\n",
      "Epoch [34/50], Step [330/735], Loss: 0.1796\n",
      "Epoch [34/50], Step [331/735], Loss: 0.2291\n",
      "Epoch [34/50], Step [332/735], Loss: 0.0933\n",
      "Epoch [34/50], Step [333/735], Loss: 0.4705\n",
      "Epoch [34/50], Step [334/735], Loss: 0.2029\n",
      "Epoch [34/50], Step [335/735], Loss: 1.3047\n",
      "Epoch [34/50], Step [336/735], Loss: 0.1881\n",
      "Epoch [34/50], Step [337/735], Loss: 0.1928\n",
      "Epoch [34/50], Step [338/735], Loss: 0.6172\n",
      "Epoch [34/50], Step [339/735], Loss: 0.0680\n",
      "Epoch [34/50], Step [340/735], Loss: 0.2618\n",
      "Epoch [34/50], Step [341/735], Loss: 0.7430\n",
      "Epoch [34/50], Step [342/735], Loss: 0.2049\n",
      "Epoch [34/50], Step [343/735], Loss: 0.0427\n",
      "Epoch [34/50], Step [344/735], Loss: 0.2426\n",
      "Epoch [34/50], Step [345/735], Loss: 0.3560\n",
      "Epoch [34/50], Step [346/735], Loss: 0.2045\n",
      "Epoch [34/50], Step [347/735], Loss: 3.9905\n",
      "Epoch [34/50], Step [348/735], Loss: 0.6487\n",
      "Epoch [34/50], Step [349/735], Loss: 0.1351\n",
      "Epoch [34/50], Step [350/735], Loss: 0.2202\n",
      "Epoch [34/50], Step [351/735], Loss: 0.3321\n",
      "Epoch [34/50], Step [352/735], Loss: 0.3029\n",
      "Epoch [34/50], Step [353/735], Loss: 0.2006\n",
      "Epoch [34/50], Step [354/735], Loss: 0.2381\n",
      "Epoch [34/50], Step [355/735], Loss: 0.1817\n",
      "Epoch [34/50], Step [356/735], Loss: 0.3347\n",
      "Epoch [34/50], Step [357/735], Loss: 0.6505\n",
      "Epoch [34/50], Step [358/735], Loss: 0.4787\n",
      "Epoch [34/50], Step [359/735], Loss: 0.3983\n",
      "Epoch [34/50], Step [360/735], Loss: 0.2632\n",
      "Epoch [34/50], Step [361/735], Loss: 0.2958\n",
      "Epoch [34/50], Step [362/735], Loss: 0.2345\n",
      "Epoch [34/50], Step [363/735], Loss: 0.1399\n",
      "Epoch [34/50], Step [364/735], Loss: 0.2626\n",
      "Epoch [34/50], Step [365/735], Loss: 0.1425\n",
      "Epoch [34/50], Step [366/735], Loss: 0.1891\n",
      "Epoch [34/50], Step [367/735], Loss: 0.1746\n",
      "Epoch [34/50], Step [368/735], Loss: 0.2736\n",
      "Epoch [34/50], Step [369/735], Loss: 0.6750\n",
      "Epoch [34/50], Step [370/735], Loss: 0.5741\n",
      "Epoch [34/50], Step [371/735], Loss: 0.5224\n",
      "Epoch [34/50], Step [372/735], Loss: 0.3936\n",
      "Epoch [34/50], Step [373/735], Loss: 0.1815\n",
      "Epoch [34/50], Step [374/735], Loss: 0.4882\n",
      "Epoch [34/50], Step [375/735], Loss: 0.0468\n",
      "Epoch [34/50], Step [376/735], Loss: 0.0434\n",
      "Epoch [34/50], Step [377/735], Loss: 0.2286\n",
      "Epoch [34/50], Step [378/735], Loss: 0.2113\n",
      "Epoch [34/50], Step [379/735], Loss: 0.5252\n",
      "Epoch [34/50], Step [380/735], Loss: 0.1419\n",
      "Epoch [34/50], Step [381/735], Loss: 0.1190\n",
      "Epoch [34/50], Step [382/735], Loss: 0.1019\n",
      "Epoch [34/50], Step [383/735], Loss: 0.1673\n",
      "Epoch [34/50], Step [384/735], Loss: 0.1462\n",
      "Epoch [34/50], Step [385/735], Loss: 0.6647\n",
      "Epoch [34/50], Step [386/735], Loss: 0.2945\n",
      "Epoch [34/50], Step [387/735], Loss: 0.3071\n",
      "Epoch [34/50], Step [388/735], Loss: 0.3827\n",
      "Epoch [34/50], Step [389/735], Loss: 0.1574\n",
      "Epoch [34/50], Step [390/735], Loss: 0.0953\n",
      "Epoch [34/50], Step [391/735], Loss: 0.9689\n",
      "Epoch [34/50], Step [392/735], Loss: 0.5441\n",
      "Epoch [34/50], Step [393/735], Loss: 0.1878\n",
      "Epoch [34/50], Step [394/735], Loss: 0.1927\n",
      "Epoch [34/50], Step [395/735], Loss: 0.0700\n",
      "Epoch [34/50], Step [396/735], Loss: 0.3249\n",
      "Epoch [34/50], Step [397/735], Loss: 0.4526\n",
      "Epoch [34/50], Step [398/735], Loss: 0.7084\n",
      "Epoch [34/50], Step [399/735], Loss: 0.2195\n",
      "Epoch [34/50], Step [400/735], Loss: 0.3005\n",
      "Epoch [34/50], Step [401/735], Loss: 0.3614\n",
      "Epoch [34/50], Step [402/735], Loss: 0.5573\n",
      "Epoch [34/50], Step [403/735], Loss: 0.3759\n",
      "Epoch [34/50], Step [404/735], Loss: 0.2198\n",
      "Epoch [34/50], Step [405/735], Loss: 0.3588\n",
      "Epoch [34/50], Step [406/735], Loss: 0.2184\n",
      "Epoch [34/50], Step [407/735], Loss: 0.3137\n",
      "Epoch [34/50], Step [408/735], Loss: 0.1037\n",
      "Epoch [34/50], Step [409/735], Loss: 0.2600\n",
      "Epoch [34/50], Step [410/735], Loss: 0.3212\n",
      "Epoch [34/50], Step [411/735], Loss: 0.4836\n",
      "Epoch [34/50], Step [412/735], Loss: 0.0865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Step [413/735], Loss: 0.1525\n",
      "Epoch [34/50], Step [414/735], Loss: 0.1141\n",
      "Epoch [34/50], Step [415/735], Loss: 0.6634\n",
      "Epoch [34/50], Step [416/735], Loss: 0.2064\n",
      "Epoch [34/50], Step [417/735], Loss: 0.3232\n",
      "Epoch [34/50], Step [418/735], Loss: 0.3836\n",
      "Epoch [34/50], Step [419/735], Loss: 0.4050\n",
      "Epoch [34/50], Step [420/735], Loss: 0.1325\n",
      "Epoch [34/50], Step [421/735], Loss: 0.3904\n",
      "Epoch [34/50], Step [422/735], Loss: 0.8145\n",
      "Epoch [34/50], Step [423/735], Loss: 0.3913\n",
      "Epoch [34/50], Step [424/735], Loss: 0.3106\n",
      "Epoch [34/50], Step [425/735], Loss: 0.6496\n",
      "Epoch [34/50], Step [426/735], Loss: 0.5568\n",
      "Epoch [34/50], Step [427/735], Loss: 0.2195\n",
      "Epoch [34/50], Step [428/735], Loss: 0.4375\n",
      "Epoch [34/50], Step [429/735], Loss: 0.2822\n",
      "Epoch [34/50], Step [430/735], Loss: 0.2981\n",
      "Epoch [34/50], Step [431/735], Loss: 0.2760\n",
      "Epoch [34/50], Step [432/735], Loss: 0.1236\n",
      "Epoch [34/50], Step [433/735], Loss: 0.2074\n",
      "Epoch [34/50], Step [434/735], Loss: 0.1638\n",
      "Epoch [34/50], Step [435/735], Loss: 0.1760\n",
      "Epoch [34/50], Step [436/735], Loss: 0.5822\n",
      "Epoch [34/50], Step [437/735], Loss: 0.5975\n",
      "Epoch [34/50], Step [438/735], Loss: 0.1260\n",
      "Epoch [34/50], Step [439/735], Loss: 0.0566\n",
      "Epoch [34/50], Step [440/735], Loss: 0.2291\n",
      "Epoch [34/50], Step [441/735], Loss: 0.3838\n",
      "Epoch [34/50], Step [442/735], Loss: 0.1312\n",
      "Epoch [34/50], Step [443/735], Loss: 0.3209\n",
      "Epoch [34/50], Step [444/735], Loss: 0.2262\n",
      "Epoch [34/50], Step [445/735], Loss: 0.0898\n",
      "Epoch [34/50], Step [446/735], Loss: 4.0510\n",
      "Epoch [34/50], Step [447/735], Loss: 0.2230\n",
      "Epoch [34/50], Step [448/735], Loss: 0.1314\n",
      "Epoch [34/50], Step [449/735], Loss: 0.2313\n",
      "Epoch [34/50], Step [450/735], Loss: 0.2283\n",
      "Epoch [34/50], Step [451/735], Loss: 0.2033\n",
      "Epoch [34/50], Step [452/735], Loss: 0.2098\n",
      "Epoch [34/50], Step [453/735], Loss: 0.4553\n",
      "Epoch [34/50], Step [454/735], Loss: 1.3184\n",
      "Epoch [34/50], Step [455/735], Loss: 0.1348\n",
      "Epoch [34/50], Step [456/735], Loss: 0.6254\n",
      "Epoch [34/50], Step [457/735], Loss: 0.0586\n",
      "Epoch [34/50], Step [458/735], Loss: 0.0811\n",
      "Epoch [34/50], Step [459/735], Loss: 0.6337\n",
      "Epoch [34/50], Step [460/735], Loss: 0.0632\n",
      "Epoch [34/50], Step [461/735], Loss: 0.6644\n",
      "Epoch [34/50], Step [462/735], Loss: 0.3562\n",
      "Epoch [34/50], Step [463/735], Loss: 0.6667\n",
      "Epoch [34/50], Step [464/735], Loss: 0.2059\n",
      "Epoch [34/50], Step [465/735], Loss: 0.2156\n",
      "Epoch [34/50], Step [466/735], Loss: 0.2426\n",
      "Epoch [34/50], Step [467/735], Loss: 0.2405\n",
      "Epoch [34/50], Step [468/735], Loss: 0.2679\n",
      "Epoch [34/50], Step [469/735], Loss: 0.1315\n",
      "Epoch [34/50], Step [470/735], Loss: 0.2417\n",
      "Epoch [34/50], Step [471/735], Loss: 0.3340\n",
      "Epoch [34/50], Step [472/735], Loss: 0.2628\n",
      "Epoch [34/50], Step [473/735], Loss: 0.0690\n",
      "Epoch [34/50], Step [474/735], Loss: 0.6236\n",
      "Epoch [34/50], Step [475/735], Loss: 0.3952\n",
      "Epoch [34/50], Step [476/735], Loss: 0.5127\n",
      "Epoch [34/50], Step [477/735], Loss: 0.4685\n",
      "Epoch [34/50], Step [478/735], Loss: 0.4147\n",
      "Epoch [34/50], Step [479/735], Loss: 0.4624\n",
      "Epoch [34/50], Step [480/735], Loss: 0.3108\n",
      "Epoch [34/50], Step [481/735], Loss: 0.4732\n",
      "Epoch [34/50], Step [482/735], Loss: 0.1610\n",
      "Epoch [34/50], Step [483/735], Loss: 0.1356\n",
      "Epoch [34/50], Step [484/735], Loss: 0.4408\n",
      "Epoch [34/50], Step [485/735], Loss: 0.3455\n",
      "Epoch [34/50], Step [486/735], Loss: 0.4893\n",
      "Epoch [34/50], Step [487/735], Loss: 0.4319\n",
      "Epoch [34/50], Step [488/735], Loss: 0.4728\n",
      "Epoch [34/50], Step [489/735], Loss: 0.2588\n",
      "Epoch [34/50], Step [490/735], Loss: 0.2948\n",
      "Epoch [34/50], Step [491/735], Loss: 0.7400\n",
      "Epoch [34/50], Step [492/735], Loss: 0.2003\n",
      "Epoch [34/50], Step [493/735], Loss: 0.1553\n",
      "Epoch [34/50], Step [494/735], Loss: 0.5020\n",
      "Epoch [34/50], Step [495/735], Loss: 0.6308\n",
      "Epoch [34/50], Step [496/735], Loss: 0.5969\n",
      "Epoch [34/50], Step [497/735], Loss: 0.8434\n",
      "Epoch [34/50], Step [498/735], Loss: 0.3714\n",
      "Epoch [34/50], Step [499/735], Loss: 0.1667\n",
      "Epoch [34/50], Step [500/735], Loss: 0.4556\n",
      "Epoch [34/50], Step [501/735], Loss: 0.1914\n",
      "Epoch [34/50], Step [502/735], Loss: 0.2612\n",
      "Epoch [34/50], Step [503/735], Loss: 0.3106\n",
      "Epoch [34/50], Step [504/735], Loss: 0.2219\n",
      "Epoch [34/50], Step [505/735], Loss: 0.3429\n",
      "Epoch [34/50], Step [506/735], Loss: 0.1034\n",
      "Epoch [34/50], Step [507/735], Loss: 0.1208\n",
      "Epoch [34/50], Step [508/735], Loss: 0.2576\n",
      "Epoch [34/50], Step [509/735], Loss: 0.1501\n",
      "Epoch [34/50], Step [510/735], Loss: 0.2393\n",
      "Epoch [34/50], Step [511/735], Loss: 0.1831\n",
      "Epoch [34/50], Step [512/735], Loss: 0.2261\n",
      "Epoch [34/50], Step [513/735], Loss: 0.0976\n",
      "Epoch [34/50], Step [514/735], Loss: 0.5303\n",
      "Epoch [34/50], Step [515/735], Loss: 0.4196\n",
      "Epoch [34/50], Step [516/735], Loss: 0.3091\n",
      "Epoch [34/50], Step [517/735], Loss: 0.5410\n",
      "Epoch [34/50], Step [518/735], Loss: 0.0913\n",
      "Epoch [34/50], Step [519/735], Loss: 0.1781\n",
      "Epoch [34/50], Step [520/735], Loss: 0.2676\n",
      "Epoch [34/50], Step [521/735], Loss: 0.2842\n",
      "Epoch [34/50], Step [522/735], Loss: 0.4148\n",
      "Epoch [34/50], Step [523/735], Loss: 0.0675\n",
      "Epoch [34/50], Step [524/735], Loss: 0.1969\n",
      "Epoch [34/50], Step [525/735], Loss: 0.2711\n",
      "Epoch [34/50], Step [526/735], Loss: 0.4103\n",
      "Epoch [34/50], Step [527/735], Loss: 0.0601\n",
      "Epoch [34/50], Step [528/735], Loss: 0.1282\n",
      "Epoch [34/50], Step [529/735], Loss: 0.1382\n",
      "Epoch [34/50], Step [530/735], Loss: 0.2226\n",
      "Epoch [34/50], Step [531/735], Loss: 0.2115\n",
      "Epoch [34/50], Step [532/735], Loss: 0.1845\n",
      "Epoch [34/50], Step [533/735], Loss: 0.8156\n",
      "Epoch [34/50], Step [534/735], Loss: 0.4190\n",
      "Epoch [34/50], Step [535/735], Loss: 0.2162\n",
      "Epoch [34/50], Step [536/735], Loss: 0.3456\n",
      "Epoch [34/50], Step [537/735], Loss: 0.3275\n",
      "Epoch [34/50], Step [538/735], Loss: 0.4657\n",
      "Epoch [34/50], Step [539/735], Loss: 0.1447\n",
      "Epoch [34/50], Step [540/735], Loss: 3.6160\n",
      "Epoch [34/50], Step [541/735], Loss: 0.1460\n",
      "Epoch [34/50], Step [542/735], Loss: 0.4449\n",
      "Epoch [34/50], Step [543/735], Loss: 0.1822\n",
      "Epoch [34/50], Step [544/735], Loss: 0.1593\n",
      "Epoch [34/50], Step [545/735], Loss: 0.2859\n",
      "Epoch [34/50], Step [546/735], Loss: 0.1658\n",
      "Epoch [34/50], Step [547/735], Loss: 0.3405\n",
      "Epoch [34/50], Step [548/735], Loss: 0.2331\n",
      "Epoch [34/50], Step [549/735], Loss: 0.5137\n",
      "Epoch [34/50], Step [550/735], Loss: 0.2694\n",
      "Epoch [34/50], Step [551/735], Loss: 0.2656\n",
      "Epoch [34/50], Step [552/735], Loss: 0.1577\n",
      "Epoch [34/50], Step [553/735], Loss: 0.2414\n",
      "Epoch [34/50], Step [554/735], Loss: 0.4019\n",
      "Epoch [34/50], Step [555/735], Loss: 0.2517\n",
      "Epoch [34/50], Step [556/735], Loss: 0.0754\n",
      "Epoch [34/50], Step [557/735], Loss: 0.1607\n",
      "Epoch [34/50], Step [558/735], Loss: 0.3115\n",
      "Epoch [34/50], Step [559/735], Loss: 0.6084\n",
      "Epoch [34/50], Step [560/735], Loss: 0.2329\n",
      "Epoch [34/50], Step [561/735], Loss: 0.1755\n",
      "Epoch [34/50], Step [562/735], Loss: 0.3239\n",
      "Epoch [34/50], Step [563/735], Loss: 0.3546\n",
      "Epoch [34/50], Step [564/735], Loss: 0.1833\n",
      "Epoch [34/50], Step [565/735], Loss: 0.2738\n",
      "Epoch [34/50], Step [566/735], Loss: 0.1867\n",
      "Epoch [34/50], Step [567/735], Loss: 0.1752\n",
      "Epoch [34/50], Step [568/735], Loss: 0.0993\n",
      "Epoch [34/50], Step [569/735], Loss: 0.1831\n",
      "Epoch [34/50], Step [570/735], Loss: 0.1011\n",
      "Epoch [34/50], Step [571/735], Loss: 0.3352\n",
      "Epoch [34/50], Step [572/735], Loss: 0.1615\n",
      "Epoch [34/50], Step [573/735], Loss: 0.1530\n",
      "Epoch [34/50], Step [574/735], Loss: 0.3880\n",
      "Epoch [34/50], Step [575/735], Loss: 0.2696\n",
      "Epoch [34/50], Step [576/735], Loss: 0.3139\n",
      "Epoch [34/50], Step [577/735], Loss: 0.1616\n",
      "Epoch [34/50], Step [578/735], Loss: 0.0817\n",
      "Epoch [34/50], Step [579/735], Loss: 0.1834\n",
      "Epoch [34/50], Step [580/735], Loss: 0.1586\n",
      "Epoch [34/50], Step [581/735], Loss: 0.9462\n",
      "Epoch [34/50], Step [582/735], Loss: 0.4333\n",
      "Epoch [34/50], Step [583/735], Loss: 0.1602\n",
      "Epoch [34/50], Step [584/735], Loss: 0.1167\n",
      "Epoch [34/50], Step [585/735], Loss: 0.1690\n",
      "Epoch [34/50], Step [586/735], Loss: 0.0726\n",
      "Epoch [34/50], Step [587/735], Loss: 0.3685\n",
      "Epoch [34/50], Step [588/735], Loss: 0.2675\n",
      "Epoch [34/50], Step [589/735], Loss: 0.1212\n",
      "Epoch [34/50], Step [590/735], Loss: 0.2040\n",
      "Epoch [34/50], Step [591/735], Loss: 0.1091\n",
      "Epoch [34/50], Step [592/735], Loss: 0.4354\n",
      "Epoch [34/50], Step [593/735], Loss: 0.1535\n",
      "Epoch [34/50], Step [594/735], Loss: 0.1771\n",
      "Epoch [34/50], Step [595/735], Loss: 0.4124\n",
      "Epoch [34/50], Step [596/735], Loss: 0.3281\n",
      "Epoch [34/50], Step [597/735], Loss: 0.3469\n",
      "Epoch [34/50], Step [598/735], Loss: 0.2535\n",
      "Epoch [34/50], Step [599/735], Loss: 0.1323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Step [600/735], Loss: 0.2083\n",
      "Epoch [34/50], Step [601/735], Loss: 1.1621\n",
      "Epoch [34/50], Step [602/735], Loss: 0.0946\n",
      "Epoch [34/50], Step [603/735], Loss: 0.3979\n",
      "Epoch [34/50], Step [604/735], Loss: 0.1796\n",
      "Epoch [34/50], Step [605/735], Loss: 0.2521\n",
      "Epoch [34/50], Step [606/735], Loss: 0.3054\n",
      "Epoch [34/50], Step [607/735], Loss: 0.7153\n",
      "Epoch [34/50], Step [608/735], Loss: 0.4678\n",
      "Epoch [34/50], Step [609/735], Loss: 1.1605\n",
      "Epoch [34/50], Step [610/735], Loss: 0.5080\n",
      "Epoch [34/50], Step [611/735], Loss: 0.2584\n",
      "Epoch [34/50], Step [612/735], Loss: 0.4043\n",
      "Epoch [34/50], Step [613/735], Loss: 0.4940\n",
      "Epoch [34/50], Step [614/735], Loss: 0.2094\n",
      "Epoch [34/50], Step [615/735], Loss: 0.1409\n",
      "Epoch [34/50], Step [616/735], Loss: 0.1212\n",
      "Epoch [34/50], Step [617/735], Loss: 0.4907\n",
      "Epoch [34/50], Step [618/735], Loss: 0.2434\n",
      "Epoch [34/50], Step [619/735], Loss: 0.0842\n",
      "Epoch [34/50], Step [620/735], Loss: 0.3962\n",
      "Epoch [34/50], Step [621/735], Loss: 0.4462\n",
      "Epoch [34/50], Step [622/735], Loss: 0.2017\n",
      "Epoch [34/50], Step [623/735], Loss: 0.2765\n",
      "Epoch [34/50], Step [624/735], Loss: 0.7731\n",
      "Epoch [34/50], Step [625/735], Loss: 0.1310\n",
      "Epoch [34/50], Step [626/735], Loss: 0.4967\n",
      "Epoch [34/50], Step [627/735], Loss: 0.4207\n",
      "Epoch [34/50], Step [628/735], Loss: 0.2057\n",
      "Epoch [34/50], Step [629/735], Loss: 0.3619\n",
      "Epoch [34/50], Step [630/735], Loss: 0.1426\n",
      "Epoch [34/50], Step [631/735], Loss: 0.4223\n",
      "Epoch [34/50], Step [632/735], Loss: 0.2092\n",
      "Epoch [34/50], Step [633/735], Loss: 0.7394\n",
      "Epoch [34/50], Step [634/735], Loss: 0.4409\n",
      "Epoch [34/50], Step [635/735], Loss: 0.1066\n",
      "Epoch [34/50], Step [636/735], Loss: 0.3350\n",
      "Epoch [34/50], Step [637/735], Loss: 0.2141\n",
      "Epoch [34/50], Step [638/735], Loss: 0.3442\n",
      "Epoch [34/50], Step [639/735], Loss: 0.0994\n",
      "Epoch [34/50], Step [640/735], Loss: 0.2534\n",
      "Epoch [34/50], Step [641/735], Loss: 0.2471\n",
      "Epoch [34/50], Step [642/735], Loss: 0.7187\n",
      "Epoch [34/50], Step [643/735], Loss: 0.3194\n",
      "Epoch [34/50], Step [644/735], Loss: 0.0562\n",
      "Epoch [34/50], Step [645/735], Loss: 0.0358\n",
      "Epoch [34/50], Step [646/735], Loss: 0.2386\n",
      "Epoch [34/50], Step [647/735], Loss: 0.5172\n",
      "Epoch [34/50], Step [648/735], Loss: 0.2348\n",
      "Epoch [34/50], Step [649/735], Loss: 0.0893\n",
      "Epoch [34/50], Step [650/735], Loss: 0.4490\n",
      "Epoch [34/50], Step [651/735], Loss: 0.4569\n",
      "Epoch [34/50], Step [652/735], Loss: 0.1535\n",
      "Epoch [34/50], Step [653/735], Loss: 0.5057\n",
      "Epoch [34/50], Step [654/735], Loss: 0.3423\n",
      "Epoch [34/50], Step [655/735], Loss: 0.2416\n",
      "Epoch [34/50], Step [656/735], Loss: 0.2300\n",
      "Epoch [34/50], Step [657/735], Loss: 0.7966\n",
      "Epoch [34/50], Step [658/735], Loss: 0.3099\n",
      "Epoch [34/50], Step [659/735], Loss: 0.2074\n",
      "Epoch [34/50], Step [660/735], Loss: 0.2668\n",
      "Epoch [34/50], Step [661/735], Loss: 0.4707\n",
      "Epoch [34/50], Step [662/735], Loss: 0.2387\n",
      "Epoch [34/50], Step [663/735], Loss: 0.2746\n",
      "Epoch [34/50], Step [664/735], Loss: 0.5188\n",
      "Epoch [34/50], Step [665/735], Loss: 0.9155\n",
      "Epoch [34/50], Step [666/735], Loss: 0.3473\n",
      "Epoch [34/50], Step [667/735], Loss: 0.2252\n",
      "Epoch [34/50], Step [668/735], Loss: 0.3600\n",
      "Epoch [34/50], Step [669/735], Loss: 0.2376\n",
      "Epoch [34/50], Step [670/735], Loss: 0.3137\n",
      "Epoch [34/50], Step [671/735], Loss: 0.0899\n",
      "Epoch [34/50], Step [672/735], Loss: 0.1932\n",
      "Epoch [34/50], Step [673/735], Loss: 0.2269\n",
      "Epoch [34/50], Step [674/735], Loss: 0.1657\n",
      "Epoch [34/50], Step [675/735], Loss: 0.1576\n",
      "Epoch [34/50], Step [676/735], Loss: 0.1970\n",
      "Epoch [34/50], Step [677/735], Loss: 0.2524\n",
      "Epoch [34/50], Step [678/735], Loss: 0.3991\n",
      "Epoch [34/50], Step [679/735], Loss: 0.4564\n",
      "Epoch [34/50], Step [680/735], Loss: 0.2482\n",
      "Epoch [34/50], Step [681/735], Loss: 0.3451\n",
      "Epoch [34/50], Step [682/735], Loss: 0.0734\n",
      "Epoch [34/50], Step [683/735], Loss: 0.9586\n",
      "Epoch [34/50], Step [684/735], Loss: 0.2183\n",
      "Epoch [34/50], Step [685/735], Loss: 0.2674\n",
      "Epoch [34/50], Step [686/735], Loss: 0.9676\n",
      "Epoch [34/50], Step [687/735], Loss: 0.4617\n",
      "Epoch [34/50], Step [688/735], Loss: 0.2107\n",
      "Epoch [34/50], Step [689/735], Loss: 0.1902\n",
      "Epoch [34/50], Step [690/735], Loss: 0.1025\n",
      "Epoch [34/50], Step [691/735], Loss: 0.2364\n",
      "Epoch [34/50], Step [692/735], Loss: 0.1204\n",
      "Epoch [34/50], Step [693/735], Loss: 0.1079\n",
      "Epoch [34/50], Step [694/735], Loss: 0.2116\n",
      "Epoch [34/50], Step [695/735], Loss: 0.3175\n",
      "Epoch [34/50], Step [696/735], Loss: 0.7425\n",
      "Epoch [34/50], Step [697/735], Loss: 0.7526\n",
      "Epoch [34/50], Step [698/735], Loss: 0.5361\n",
      "Epoch [34/50], Step [699/735], Loss: 0.2419\n",
      "Epoch [34/50], Step [700/735], Loss: 0.4317\n",
      "Epoch [34/50], Step [701/735], Loss: 0.8365\n",
      "Epoch [34/50], Step [702/735], Loss: 0.2193\n",
      "Epoch [34/50], Step [703/735], Loss: 0.7125\n",
      "Epoch [34/50], Step [704/735], Loss: 0.2571\n",
      "Epoch [34/50], Step [705/735], Loss: 0.4044\n",
      "Epoch [34/50], Step [706/735], Loss: 0.6331\n",
      "Epoch [34/50], Step [707/735], Loss: 0.3510\n",
      "Epoch [34/50], Step [708/735], Loss: 0.6916\n",
      "Epoch [34/50], Step [709/735], Loss: 0.4931\n",
      "Epoch [34/50], Step [710/735], Loss: 0.2472\n",
      "Epoch [34/50], Step [711/735], Loss: 0.1233\n",
      "Epoch [34/50], Step [712/735], Loss: 0.2409\n",
      "Epoch [34/50], Step [713/735], Loss: 0.2595\n",
      "Epoch [34/50], Step [714/735], Loss: 0.2226\n",
      "Epoch [34/50], Step [715/735], Loss: 0.4085\n",
      "Epoch [34/50], Step [716/735], Loss: 0.3532\n",
      "Epoch [34/50], Step [717/735], Loss: 0.3065\n",
      "Epoch [34/50], Step [718/735], Loss: 0.4749\n",
      "Epoch [34/50], Step [719/735], Loss: 0.5133\n",
      "Epoch [34/50], Step [720/735], Loss: 0.2605\n",
      "Epoch [34/50], Step [721/735], Loss: 0.4854\n",
      "Epoch [34/50], Step [722/735], Loss: 0.4365\n",
      "Epoch [34/50], Step [723/735], Loss: 0.0719\n",
      "Epoch [34/50], Step [724/735], Loss: 0.4328\n",
      "Epoch [34/50], Step [725/735], Loss: 0.3830\n",
      "Epoch [34/50], Step [726/735], Loss: 0.1776\n",
      "Epoch [34/50], Step [727/735], Loss: 0.3326\n",
      "Epoch [34/50], Step [728/735], Loss: 0.4686\n",
      "Epoch [34/50], Step [729/735], Loss: 0.4582\n",
      "Epoch [34/50], Step [730/735], Loss: 0.0985\n",
      "Epoch [34/50], Step [731/735], Loss: 0.1918\n",
      "Epoch [34/50], Step [732/735], Loss: 0.1517\n",
      "Epoch [34/50], Step [733/735], Loss: 0.0478\n",
      "Epoch [34/50], Step [734/735], Loss: 0.3365\n",
      "Epoch [34/50], Step [735/735], Loss: 0.0563\n",
      "Epoch [35/50], Step [1/735], Loss: 0.0825\n",
      "Epoch [35/50], Step [2/735], Loss: 0.1517\n",
      "Epoch [35/50], Step [3/735], Loss: 0.2564\n",
      "Epoch [35/50], Step [4/735], Loss: 0.4182\n",
      "Epoch [35/50], Step [5/735], Loss: 0.4785\n",
      "Epoch [35/50], Step [6/735], Loss: 0.1938\n",
      "Epoch [35/50], Step [7/735], Loss: 0.3141\n",
      "Epoch [35/50], Step [8/735], Loss: 0.4950\n",
      "Epoch [35/50], Step [9/735], Loss: 0.2208\n",
      "Epoch [35/50], Step [10/735], Loss: 0.1728\n",
      "Epoch [35/50], Step [11/735], Loss: 0.2897\n",
      "Epoch [35/50], Step [12/735], Loss: 0.1753\n",
      "Epoch [35/50], Step [13/735], Loss: 0.1740\n",
      "Epoch [35/50], Step [14/735], Loss: 0.0827\n",
      "Epoch [35/50], Step [15/735], Loss: 0.4452\n",
      "Epoch [35/50], Step [16/735], Loss: 0.1981\n",
      "Epoch [35/50], Step [17/735], Loss: 0.4225\n",
      "Epoch [35/50], Step [18/735], Loss: 0.1765\n",
      "Epoch [35/50], Step [19/735], Loss: 0.1427\n",
      "Epoch [35/50], Step [20/735], Loss: 0.2577\n",
      "Epoch [35/50], Step [21/735], Loss: 0.2330\n",
      "Epoch [35/50], Step [22/735], Loss: 0.0780\n",
      "Epoch [35/50], Step [23/735], Loss: 4.3709\n",
      "Epoch [35/50], Step [24/735], Loss: 0.6719\n",
      "Epoch [35/50], Step [25/735], Loss: 0.6327\n",
      "Epoch [35/50], Step [26/735], Loss: 0.6085\n",
      "Epoch [35/50], Step [27/735], Loss: 0.6583\n",
      "Epoch [35/50], Step [28/735], Loss: 0.1144\n",
      "Epoch [35/50], Step [29/735], Loss: 0.1831\n",
      "Epoch [35/50], Step [30/735], Loss: 0.5981\n",
      "Epoch [35/50], Step [31/735], Loss: 0.1419\n",
      "Epoch [35/50], Step [32/735], Loss: 0.4401\n",
      "Epoch [35/50], Step [33/735], Loss: 0.2790\n",
      "Epoch [35/50], Step [34/735], Loss: 0.2220\n",
      "Epoch [35/50], Step [35/735], Loss: 0.0842\n",
      "Epoch [35/50], Step [36/735], Loss: 0.5555\n",
      "Epoch [35/50], Step [37/735], Loss: 0.4353\n",
      "Epoch [35/50], Step [38/735], Loss: 0.3968\n",
      "Epoch [35/50], Step [39/735], Loss: 0.1283\n",
      "Epoch [35/50], Step [40/735], Loss: 0.2094\n",
      "Epoch [35/50], Step [41/735], Loss: 0.0828\n",
      "Epoch [35/50], Step [42/735], Loss: 0.1715\n",
      "Epoch [35/50], Step [43/735], Loss: 0.3436\n",
      "Epoch [35/50], Step [44/735], Loss: 0.3008\n",
      "Epoch [35/50], Step [45/735], Loss: 0.6485\n",
      "Epoch [35/50], Step [46/735], Loss: 0.1615\n",
      "Epoch [35/50], Step [47/735], Loss: 0.0748\n",
      "Epoch [35/50], Step [48/735], Loss: 0.3627\n",
      "Epoch [35/50], Step [49/735], Loss: 0.2780\n",
      "Epoch [35/50], Step [50/735], Loss: 3.3129\n",
      "Epoch [35/50], Step [51/735], Loss: 0.2218\n",
      "Epoch [35/50], Step [52/735], Loss: 0.1755\n",
      "Epoch [35/50], Step [53/735], Loss: 0.4610\n",
      "Epoch [35/50], Step [54/735], Loss: 0.3317\n",
      "Epoch [35/50], Step [55/735], Loss: 0.7735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Step [56/735], Loss: 0.3910\n",
      "Epoch [35/50], Step [57/735], Loss: 0.6560\n",
      "Epoch [35/50], Step [58/735], Loss: 0.0637\n",
      "Epoch [35/50], Step [59/735], Loss: 0.2130\n",
      "Epoch [35/50], Step [60/735], Loss: 0.1724\n",
      "Epoch [35/50], Step [61/735], Loss: 0.3862\n",
      "Epoch [35/50], Step [62/735], Loss: 0.4549\n",
      "Epoch [35/50], Step [63/735], Loss: 0.6838\n",
      "Epoch [35/50], Step [64/735], Loss: 0.3619\n",
      "Epoch [35/50], Step [65/735], Loss: 0.1125\n",
      "Epoch [35/50], Step [66/735], Loss: 0.4853\n",
      "Epoch [35/50], Step [67/735], Loss: 0.1463\n",
      "Epoch [35/50], Step [68/735], Loss: 0.1395\n",
      "Epoch [35/50], Step [69/735], Loss: 0.1450\n",
      "Epoch [35/50], Step [70/735], Loss: 0.2437\n",
      "Epoch [35/50], Step [71/735], Loss: 0.2443\n",
      "Epoch [35/50], Step [72/735], Loss: 0.3594\n",
      "Epoch [35/50], Step [73/735], Loss: 0.6469\n",
      "Epoch [35/50], Step [74/735], Loss: 0.3079\n",
      "Epoch [35/50], Step [75/735], Loss: 0.2075\n",
      "Epoch [35/50], Step [76/735], Loss: 0.1574\n",
      "Epoch [35/50], Step [77/735], Loss: 0.3898\n",
      "Epoch [35/50], Step [78/735], Loss: 0.4328\n",
      "Epoch [35/50], Step [79/735], Loss: 0.2541\n",
      "Epoch [35/50], Step [80/735], Loss: 0.2613\n",
      "Epoch [35/50], Step [81/735], Loss: 0.2424\n",
      "Epoch [35/50], Step [82/735], Loss: 0.2077\n",
      "Epoch [35/50], Step [83/735], Loss: 0.3963\n",
      "Epoch [35/50], Step [84/735], Loss: 0.2819\n",
      "Epoch [35/50], Step [85/735], Loss: 0.2712\n",
      "Epoch [35/50], Step [86/735], Loss: 0.3944\n",
      "Epoch [35/50], Step [87/735], Loss: 0.1380\n",
      "Epoch [35/50], Step [88/735], Loss: 0.2266\n",
      "Epoch [35/50], Step [89/735], Loss: 0.2417\n",
      "Epoch [35/50], Step [90/735], Loss: 0.1033\n",
      "Epoch [35/50], Step [91/735], Loss: 0.1434\n",
      "Epoch [35/50], Step [92/735], Loss: 0.1595\n",
      "Epoch [35/50], Step [93/735], Loss: 0.2971\n",
      "Epoch [35/50], Step [94/735], Loss: 0.6544\n",
      "Epoch [35/50], Step [95/735], Loss: 0.1944\n",
      "Epoch [35/50], Step [96/735], Loss: 0.0516\n",
      "Epoch [35/50], Step [97/735], Loss: 0.1635\n",
      "Epoch [35/50], Step [98/735], Loss: 0.3107\n",
      "Epoch [35/50], Step [99/735], Loss: 0.2294\n",
      "Epoch [35/50], Step [100/735], Loss: 0.1309\n",
      "Epoch [35/50], Step [101/735], Loss: 0.3016\n",
      "Epoch [35/50], Step [102/735], Loss: 0.1367\n",
      "Epoch [35/50], Step [103/735], Loss: 0.1057\n",
      "Epoch [35/50], Step [104/735], Loss: 0.3728\n",
      "Epoch [35/50], Step [105/735], Loss: 0.4504\n",
      "Epoch [35/50], Step [106/735], Loss: 0.4176\n",
      "Epoch [35/50], Step [107/735], Loss: 0.4460\n",
      "Epoch [35/50], Step [108/735], Loss: 0.1235\n",
      "Epoch [35/50], Step [109/735], Loss: 0.3011\n",
      "Epoch [35/50], Step [110/735], Loss: 0.3501\n",
      "Epoch [35/50], Step [111/735], Loss: 0.7398\n",
      "Epoch [35/50], Step [112/735], Loss: 0.2580\n",
      "Epoch [35/50], Step [113/735], Loss: 0.6977\n",
      "Epoch [35/50], Step [114/735], Loss: 0.2071\n",
      "Epoch [35/50], Step [115/735], Loss: 0.3149\n",
      "Epoch [35/50], Step [116/735], Loss: 0.4171\n",
      "Epoch [35/50], Step [117/735], Loss: 0.2018\n",
      "Epoch [35/50], Step [118/735], Loss: 0.1418\n",
      "Epoch [35/50], Step [119/735], Loss: 0.4112\n",
      "Epoch [35/50], Step [120/735], Loss: 0.3414\n",
      "Epoch [35/50], Step [121/735], Loss: 0.1474\n",
      "Epoch [35/50], Step [122/735], Loss: 0.7983\n",
      "Epoch [35/50], Step [123/735], Loss: 0.6269\n",
      "Epoch [35/50], Step [124/735], Loss: 0.0856\n",
      "Epoch [35/50], Step [125/735], Loss: 0.2879\n",
      "Epoch [35/50], Step [126/735], Loss: 0.2020\n",
      "Epoch [35/50], Step [127/735], Loss: 0.1748\n",
      "Epoch [35/50], Step [128/735], Loss: 0.3117\n",
      "Epoch [35/50], Step [129/735], Loss: 0.4421\n",
      "Epoch [35/50], Step [130/735], Loss: 0.1361\n",
      "Epoch [35/50], Step [131/735], Loss: 0.4565\n",
      "Epoch [35/50], Step [132/735], Loss: 0.4563\n",
      "Epoch [35/50], Step [133/735], Loss: 0.4375\n",
      "Epoch [35/50], Step [134/735], Loss: 0.3631\n",
      "Epoch [35/50], Step [135/735], Loss: 0.0656\n",
      "Epoch [35/50], Step [136/735], Loss: 0.3186\n",
      "Epoch [35/50], Step [137/735], Loss: 0.4557\n",
      "Epoch [35/50], Step [138/735], Loss: 0.2608\n",
      "Epoch [35/50], Step [139/735], Loss: 0.1246\n",
      "Epoch [35/50], Step [140/735], Loss: 0.7332\n",
      "Epoch [35/50], Step [141/735], Loss: 0.3072\n",
      "Epoch [35/50], Step [142/735], Loss: 0.1987\n",
      "Epoch [35/50], Step [143/735], Loss: 0.4280\n",
      "Epoch [35/50], Step [144/735], Loss: 0.0535\n",
      "Epoch [35/50], Step [145/735], Loss: 0.2851\n",
      "Epoch [35/50], Step [146/735], Loss: 0.2961\n",
      "Epoch [35/50], Step [147/735], Loss: 0.4534\n",
      "Epoch [35/50], Step [148/735], Loss: 0.0526\n",
      "Epoch [35/50], Step [149/735], Loss: 0.2181\n",
      "Epoch [35/50], Step [150/735], Loss: 0.3159\n",
      "Epoch [35/50], Step [151/735], Loss: 0.2046\n",
      "Epoch [35/50], Step [152/735], Loss: 0.1310\n",
      "Epoch [35/50], Step [153/735], Loss: 0.4859\n",
      "Epoch [35/50], Step [154/735], Loss: 0.0446\n",
      "Epoch [35/50], Step [155/735], Loss: 0.1335\n",
      "Epoch [35/50], Step [156/735], Loss: 0.2788\n",
      "Epoch [35/50], Step [157/735], Loss: 0.3522\n",
      "Epoch [35/50], Step [158/735], Loss: 0.0518\n",
      "Epoch [35/50], Step [159/735], Loss: 0.3080\n",
      "Epoch [35/50], Step [160/735], Loss: 0.0865\n",
      "Epoch [35/50], Step [161/735], Loss: 0.2642\n",
      "Epoch [35/50], Step [162/735], Loss: 0.5489\n",
      "Epoch [35/50], Step [163/735], Loss: 0.3583\n",
      "Epoch [35/50], Step [164/735], Loss: 0.1594\n",
      "Epoch [35/50], Step [165/735], Loss: 0.3369\n",
      "Epoch [35/50], Step [166/735], Loss: 0.5323\n",
      "Epoch [35/50], Step [167/735], Loss: 0.2968\n",
      "Epoch [35/50], Step [168/735], Loss: 0.3366\n",
      "Epoch [35/50], Step [169/735], Loss: 0.2267\n",
      "Epoch [35/50], Step [170/735], Loss: 0.1209\n",
      "Epoch [35/50], Step [171/735], Loss: 0.1835\n",
      "Epoch [35/50], Step [172/735], Loss: 0.4086\n",
      "Epoch [35/50], Step [173/735], Loss: 0.3178\n",
      "Epoch [35/50], Step [174/735], Loss: 0.1747\n",
      "Epoch [35/50], Step [175/735], Loss: 0.1580\n",
      "Epoch [35/50], Step [176/735], Loss: 0.1177\n",
      "Epoch [35/50], Step [177/735], Loss: 0.6584\n",
      "Epoch [35/50], Step [178/735], Loss: 0.2129\n",
      "Epoch [35/50], Step [179/735], Loss: 0.6064\n",
      "Epoch [35/50], Step [180/735], Loss: 0.0910\n",
      "Epoch [35/50], Step [181/735], Loss: 0.4117\n",
      "Epoch [35/50], Step [182/735], Loss: 1.7142\n",
      "Epoch [35/50], Step [183/735], Loss: 0.1318\n",
      "Epoch [35/50], Step [184/735], Loss: 0.7998\n",
      "Epoch [35/50], Step [185/735], Loss: 0.1766\n",
      "Epoch [35/50], Step [186/735], Loss: 0.2888\n",
      "Epoch [35/50], Step [187/735], Loss: 0.6591\n",
      "Epoch [35/50], Step [188/735], Loss: 0.1214\n",
      "Epoch [35/50], Step [189/735], Loss: 0.2100\n",
      "Epoch [35/50], Step [190/735], Loss: 0.2765\n",
      "Epoch [35/50], Step [191/735], Loss: 0.2856\n",
      "Epoch [35/50], Step [192/735], Loss: 0.3647\n",
      "Epoch [35/50], Step [193/735], Loss: 0.1450\n",
      "Epoch [35/50], Step [194/735], Loss: 0.1896\n",
      "Epoch [35/50], Step [195/735], Loss: 0.3744\n",
      "Epoch [35/50], Step [196/735], Loss: 0.2187\n",
      "Epoch [35/50], Step [197/735], Loss: 0.3160\n",
      "Epoch [35/50], Step [198/735], Loss: 1.2636\n",
      "Epoch [35/50], Step [199/735], Loss: 0.1659\n",
      "Epoch [35/50], Step [200/735], Loss: 0.1311\n",
      "Epoch [35/50], Step [201/735], Loss: 0.1390\n",
      "Epoch [35/50], Step [202/735], Loss: 0.5383\n",
      "Epoch [35/50], Step [203/735], Loss: 0.2495\n",
      "Epoch [35/50], Step [204/735], Loss: 0.5771\n",
      "Epoch [35/50], Step [205/735], Loss: 0.3751\n",
      "Epoch [35/50], Step [206/735], Loss: 0.3218\n",
      "Epoch [35/50], Step [207/735], Loss: 3.6425\n",
      "Epoch [35/50], Step [208/735], Loss: 0.0876\n",
      "Epoch [35/50], Step [209/735], Loss: 0.1341\n",
      "Epoch [35/50], Step [210/735], Loss: 0.1939\n",
      "Epoch [35/50], Step [211/735], Loss: 0.1543\n",
      "Epoch [35/50], Step [212/735], Loss: 0.1743\n",
      "Epoch [35/50], Step [213/735], Loss: 0.7924\n",
      "Epoch [35/50], Step [214/735], Loss: 0.2666\n",
      "Epoch [35/50], Step [215/735], Loss: 0.1521\n",
      "Epoch [35/50], Step [216/735], Loss: 0.1205\n",
      "Epoch [35/50], Step [217/735], Loss: 0.1620\n",
      "Epoch [35/50], Step [218/735], Loss: 0.5297\n",
      "Epoch [35/50], Step [219/735], Loss: 0.1275\n",
      "Epoch [35/50], Step [220/735], Loss: 0.3929\n",
      "Epoch [35/50], Step [221/735], Loss: 0.0899\n",
      "Epoch [35/50], Step [222/735], Loss: 0.2614\n",
      "Epoch [35/50], Step [223/735], Loss: 0.4527\n",
      "Epoch [35/50], Step [224/735], Loss: 0.1091\n",
      "Epoch [35/50], Step [225/735], Loss: 0.3726\n",
      "Epoch [35/50], Step [226/735], Loss: 0.1405\n",
      "Epoch [35/50], Step [227/735], Loss: 0.4413\n",
      "Epoch [35/50], Step [228/735], Loss: 0.6019\n",
      "Epoch [35/50], Step [229/735], Loss: 0.1287\n",
      "Epoch [35/50], Step [230/735], Loss: 0.3813\n",
      "Epoch [35/50], Step [231/735], Loss: 0.3762\n",
      "Epoch [35/50], Step [232/735], Loss: 0.1458\n",
      "Epoch [35/50], Step [233/735], Loss: 0.1350\n",
      "Epoch [35/50], Step [234/735], Loss: 0.1687\n",
      "Epoch [35/50], Step [235/735], Loss: 0.1748\n",
      "Epoch [35/50], Step [236/735], Loss: 0.1465\n",
      "Epoch [35/50], Step [237/735], Loss: 0.5513\n",
      "Epoch [35/50], Step [238/735], Loss: 0.1960\n",
      "Epoch [35/50], Step [239/735], Loss: 0.1869\n",
      "Epoch [35/50], Step [240/735], Loss: 0.4233\n",
      "Epoch [35/50], Step [241/735], Loss: 0.7554\n",
      "Epoch [35/50], Step [242/735], Loss: 0.1846\n",
      "Epoch [35/50], Step [243/735], Loss: 0.1396\n",
      "Epoch [35/50], Step [244/735], Loss: 0.3600\n",
      "Epoch [35/50], Step [245/735], Loss: 0.3429\n",
      "Epoch [35/50], Step [246/735], Loss: 0.1109\n",
      "Epoch [35/50], Step [247/735], Loss: 0.1063\n",
      "Epoch [35/50], Step [248/735], Loss: 0.3941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Step [249/735], Loss: 0.4899\n",
      "Epoch [35/50], Step [250/735], Loss: 0.2614\n",
      "Epoch [35/50], Step [251/735], Loss: 0.2186\n",
      "Epoch [35/50], Step [252/735], Loss: 0.1102\n",
      "Epoch [35/50], Step [253/735], Loss: 0.3221\n",
      "Epoch [35/50], Step [254/735], Loss: 0.6665\n",
      "Epoch [35/50], Step [255/735], Loss: 0.0990\n",
      "Epoch [35/50], Step [256/735], Loss: 0.2551\n",
      "Epoch [35/50], Step [257/735], Loss: 0.5458\n",
      "Epoch [35/50], Step [258/735], Loss: 0.2004\n",
      "Epoch [35/50], Step [259/735], Loss: 0.2533\n",
      "Epoch [35/50], Step [260/735], Loss: 0.1846\n",
      "Epoch [35/50], Step [261/735], Loss: 0.4027\n",
      "Epoch [35/50], Step [262/735], Loss: 0.0763\n",
      "Epoch [35/50], Step [263/735], Loss: 0.0723\n",
      "Epoch [35/50], Step [264/735], Loss: 0.4881\n",
      "Epoch [35/50], Step [265/735], Loss: 0.2133\n",
      "Epoch [35/50], Step [266/735], Loss: 0.2127\n",
      "Epoch [35/50], Step [267/735], Loss: 0.1573\n",
      "Epoch [35/50], Step [268/735], Loss: 0.2667\n",
      "Epoch [35/50], Step [269/735], Loss: 0.1179\n",
      "Epoch [35/50], Step [270/735], Loss: 0.5575\n",
      "Epoch [35/50], Step [271/735], Loss: 0.6700\n",
      "Epoch [35/50], Step [272/735], Loss: 1.0856\n",
      "Epoch [35/50], Step [273/735], Loss: 0.3679\n",
      "Epoch [35/50], Step [274/735], Loss: 0.2395\n",
      "Epoch [35/50], Step [275/735], Loss: 0.1871\n",
      "Epoch [35/50], Step [276/735], Loss: 0.2561\n",
      "Epoch [35/50], Step [277/735], Loss: 0.3615\n",
      "Epoch [35/50], Step [278/735], Loss: 0.9911\n",
      "Epoch [35/50], Step [279/735], Loss: 0.2251\n",
      "Epoch [35/50], Step [280/735], Loss: 0.2029\n",
      "Epoch [35/50], Step [281/735], Loss: 0.2974\n",
      "Epoch [35/50], Step [282/735], Loss: 0.2716\n",
      "Epoch [35/50], Step [283/735], Loss: 0.2099\n",
      "Epoch [35/50], Step [284/735], Loss: 0.1891\n",
      "Epoch [35/50], Step [285/735], Loss: 0.2093\n",
      "Epoch [35/50], Step [286/735], Loss: 0.2527\n",
      "Epoch [35/50], Step [287/735], Loss: 0.4669\n",
      "Epoch [35/50], Step [288/735], Loss: 0.1083\n",
      "Epoch [35/50], Step [289/735], Loss: 0.2967\n",
      "Epoch [35/50], Step [290/735], Loss: 0.1094\n",
      "Epoch [35/50], Step [291/735], Loss: 0.1005\n",
      "Epoch [35/50], Step [292/735], Loss: 0.1699\n",
      "Epoch [35/50], Step [293/735], Loss: 0.6538\n",
      "Epoch [35/50], Step [294/735], Loss: 0.2801\n",
      "Epoch [35/50], Step [295/735], Loss: 0.2552\n",
      "Epoch [35/50], Step [296/735], Loss: 0.0925\n",
      "Epoch [35/50], Step [297/735], Loss: 0.1498\n",
      "Epoch [35/50], Step [298/735], Loss: 0.3313\n",
      "Epoch [35/50], Step [299/735], Loss: 0.1624\n",
      "Epoch [35/50], Step [300/735], Loss: 0.1050\n",
      "Epoch [35/50], Step [301/735], Loss: 0.4703\n",
      "Epoch [35/50], Step [302/735], Loss: 0.1433\n",
      "Epoch [35/50], Step [303/735], Loss: 1.5659\n",
      "Epoch [35/50], Step [304/735], Loss: 0.3183\n",
      "Epoch [35/50], Step [305/735], Loss: 0.2512\n",
      "Epoch [35/50], Step [306/735], Loss: 0.4304\n",
      "Epoch [35/50], Step [307/735], Loss: 0.1913\n",
      "Epoch [35/50], Step [308/735], Loss: 0.1004\n",
      "Epoch [35/50], Step [309/735], Loss: 0.0711\n",
      "Epoch [35/50], Step [310/735], Loss: 0.3942\n",
      "Epoch [35/50], Step [311/735], Loss: 1.1763\n",
      "Epoch [35/50], Step [312/735], Loss: 0.4242\n",
      "Epoch [35/50], Step [313/735], Loss: 0.3822\n",
      "Epoch [35/50], Step [314/735], Loss: 0.6876\n",
      "Epoch [35/50], Step [315/735], Loss: 0.1781\n",
      "Epoch [35/50], Step [316/735], Loss: 0.1825\n",
      "Epoch [35/50], Step [317/735], Loss: 0.1773\n",
      "Epoch [35/50], Step [318/735], Loss: 0.6667\n",
      "Epoch [35/50], Step [319/735], Loss: 0.8728\n",
      "Epoch [35/50], Step [320/735], Loss: 0.1218\n",
      "Epoch [35/50], Step [321/735], Loss: 0.1855\n",
      "Epoch [35/50], Step [322/735], Loss: 0.1917\n",
      "Epoch [35/50], Step [323/735], Loss: 0.3110\n",
      "Epoch [35/50], Step [324/735], Loss: 0.0968\n",
      "Epoch [35/50], Step [325/735], Loss: 0.0306\n",
      "Epoch [35/50], Step [326/735], Loss: 0.4930\n",
      "Epoch [35/50], Step [327/735], Loss: 0.3122\n",
      "Epoch [35/50], Step [328/735], Loss: 0.1132\n",
      "Epoch [35/50], Step [329/735], Loss: 0.4557\n",
      "Epoch [35/50], Step [330/735], Loss: 0.3513\n",
      "Epoch [35/50], Step [331/735], Loss: 3.1700\n",
      "Epoch [35/50], Step [332/735], Loss: 0.6396\n",
      "Epoch [35/50], Step [333/735], Loss: 0.3840\n",
      "Epoch [35/50], Step [334/735], Loss: 0.3322\n",
      "Epoch [35/50], Step [335/735], Loss: 0.2211\n",
      "Epoch [35/50], Step [336/735], Loss: 0.3704\n",
      "Epoch [35/50], Step [337/735], Loss: 0.3562\n",
      "Epoch [35/50], Step [338/735], Loss: 0.0932\n",
      "Epoch [35/50], Step [339/735], Loss: 0.1069\n",
      "Epoch [35/50], Step [340/735], Loss: 0.1551\n",
      "Epoch [35/50], Step [341/735], Loss: 0.4852\n",
      "Epoch [35/50], Step [342/735], Loss: 0.3891\n",
      "Epoch [35/50], Step [343/735], Loss: 0.2332\n",
      "Epoch [35/50], Step [344/735], Loss: 0.2792\n",
      "Epoch [35/50], Step [345/735], Loss: 0.4129\n",
      "Epoch [35/50], Step [346/735], Loss: 0.1544\n",
      "Epoch [35/50], Step [347/735], Loss: 0.0772\n",
      "Epoch [35/50], Step [348/735], Loss: 0.2429\n",
      "Epoch [35/50], Step [349/735], Loss: 0.1056\n",
      "Epoch [35/50], Step [350/735], Loss: 0.0729\n",
      "Epoch [35/50], Step [351/735], Loss: 0.5992\n",
      "Epoch [35/50], Step [352/735], Loss: 0.3421\n",
      "Epoch [35/50], Step [353/735], Loss: 0.5317\n",
      "Epoch [35/50], Step [354/735], Loss: 0.6015\n",
      "Epoch [35/50], Step [355/735], Loss: 0.2329\n",
      "Epoch [35/50], Step [356/735], Loss: 0.3385\n",
      "Epoch [35/50], Step [357/735], Loss: 0.1292\n",
      "Epoch [35/50], Step [358/735], Loss: 0.5191\n",
      "Epoch [35/50], Step [359/735], Loss: 0.3124\n",
      "Epoch [35/50], Step [360/735], Loss: 0.2894\n",
      "Epoch [35/50], Step [361/735], Loss: 0.2885\n",
      "Epoch [35/50], Step [362/735], Loss: 0.3550\n",
      "Epoch [35/50], Step [363/735], Loss: 0.2228\n",
      "Epoch [35/50], Step [364/735], Loss: 0.3684\n",
      "Epoch [35/50], Step [365/735], Loss: 0.3091\n",
      "Epoch [35/50], Step [366/735], Loss: 0.3516\n",
      "Epoch [35/50], Step [367/735], Loss: 0.0809\n",
      "Epoch [35/50], Step [368/735], Loss: 0.1232\n",
      "Epoch [35/50], Step [369/735], Loss: 0.3173\n",
      "Epoch [35/50], Step [370/735], Loss: 0.3116\n",
      "Epoch [35/50], Step [371/735], Loss: 0.2474\n",
      "Epoch [35/50], Step [372/735], Loss: 0.6025\n",
      "Epoch [35/50], Step [373/735], Loss: 0.1402\n",
      "Epoch [35/50], Step [374/735], Loss: 0.1553\n",
      "Epoch [35/50], Step [375/735], Loss: 0.1617\n",
      "Epoch [35/50], Step [376/735], Loss: 0.2138\n",
      "Epoch [35/50], Step [377/735], Loss: 0.2267\n",
      "Epoch [35/50], Step [378/735], Loss: 0.2755\n",
      "Epoch [35/50], Step [379/735], Loss: 0.1225\n",
      "Epoch [35/50], Step [380/735], Loss: 0.1707\n",
      "Epoch [35/50], Step [381/735], Loss: 0.3323\n",
      "Epoch [35/50], Step [382/735], Loss: 0.4566\n",
      "Epoch [35/50], Step [383/735], Loss: 0.1396\n",
      "Epoch [35/50], Step [384/735], Loss: 0.3936\n",
      "Epoch [35/50], Step [385/735], Loss: 0.0719\n",
      "Epoch [35/50], Step [386/735], Loss: 0.1432\n",
      "Epoch [35/50], Step [387/735], Loss: 0.0629\n",
      "Epoch [35/50], Step [388/735], Loss: 0.2379\n",
      "Epoch [35/50], Step [389/735], Loss: 0.6053\n",
      "Epoch [35/50], Step [390/735], Loss: 0.2655\n",
      "Epoch [35/50], Step [391/735], Loss: 0.0766\n",
      "Epoch [35/50], Step [392/735], Loss: 0.6550\n",
      "Epoch [35/50], Step [393/735], Loss: 0.1875\n",
      "Epoch [35/50], Step [394/735], Loss: 0.3229\n",
      "Epoch [35/50], Step [395/735], Loss: 0.2089\n",
      "Epoch [35/50], Step [396/735], Loss: 0.2885\n",
      "Epoch [35/50], Step [397/735], Loss: 0.2947\n",
      "Epoch [35/50], Step [398/735], Loss: 0.2175\n",
      "Epoch [35/50], Step [399/735], Loss: 0.3249\n",
      "Epoch [35/50], Step [400/735], Loss: 0.1086\n",
      "Epoch [35/50], Step [401/735], Loss: 0.8242\n",
      "Epoch [35/50], Step [402/735], Loss: 0.4044\n",
      "Epoch [35/50], Step [403/735], Loss: 0.1703\n",
      "Epoch [35/50], Step [404/735], Loss: 3.2742\n",
      "Epoch [35/50], Step [405/735], Loss: 0.7100\n",
      "Epoch [35/50], Step [406/735], Loss: 0.2075\n",
      "Epoch [35/50], Step [407/735], Loss: 0.2418\n",
      "Epoch [35/50], Step [408/735], Loss: 0.2355\n",
      "Epoch [35/50], Step [409/735], Loss: 0.2994\n",
      "Epoch [35/50], Step [410/735], Loss: 0.1618\n",
      "Epoch [35/50], Step [411/735], Loss: 1.2265\n",
      "Epoch [35/50], Step [412/735], Loss: 0.1987\n",
      "Epoch [35/50], Step [413/735], Loss: 0.1375\n",
      "Epoch [35/50], Step [414/735], Loss: 0.3795\n",
      "Epoch [35/50], Step [415/735], Loss: 0.2782\n",
      "Epoch [35/50], Step [416/735], Loss: 0.2523\n",
      "Epoch [35/50], Step [417/735], Loss: 0.3583\n",
      "Epoch [35/50], Step [418/735], Loss: 0.2152\n",
      "Epoch [35/50], Step [419/735], Loss: 0.3596\n",
      "Epoch [35/50], Step [420/735], Loss: 0.3510\n",
      "Epoch [35/50], Step [421/735], Loss: 0.2857\n",
      "Epoch [35/50], Step [422/735], Loss: 0.4057\n",
      "Epoch [35/50], Step [423/735], Loss: 0.3176\n",
      "Epoch [35/50], Step [424/735], Loss: 0.3027\n",
      "Epoch [35/50], Step [425/735], Loss: 0.7040\n",
      "Epoch [35/50], Step [426/735], Loss: 0.0921\n",
      "Epoch [35/50], Step [427/735], Loss: 0.4316\n",
      "Epoch [35/50], Step [428/735], Loss: 0.1743\n",
      "Epoch [35/50], Step [429/735], Loss: 0.3458\n",
      "Epoch [35/50], Step [430/735], Loss: 0.8159\n",
      "Epoch [35/50], Step [431/735], Loss: 0.8271\n",
      "Epoch [35/50], Step [432/735], Loss: 0.2341\n",
      "Epoch [35/50], Step [433/735], Loss: 0.1610\n",
      "Epoch [35/50], Step [434/735], Loss: 0.4457\n",
      "Epoch [35/50], Step [435/735], Loss: 1.6510\n",
      "Epoch [35/50], Step [436/735], Loss: 0.2937\n",
      "Epoch [35/50], Step [437/735], Loss: 0.1370\n",
      "Epoch [35/50], Step [438/735], Loss: 0.2424\n",
      "Epoch [35/50], Step [439/735], Loss: 0.3747\n",
      "Epoch [35/50], Step [440/735], Loss: 0.3238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Step [441/735], Loss: 0.2015\n",
      "Epoch [35/50], Step [442/735], Loss: 0.2394\n",
      "Epoch [35/50], Step [443/735], Loss: 0.2598\n",
      "Epoch [35/50], Step [444/735], Loss: 0.0874\n",
      "Epoch [35/50], Step [445/735], Loss: 0.2747\n",
      "Epoch [35/50], Step [446/735], Loss: 0.7151\n",
      "Epoch [35/50], Step [447/735], Loss: 0.5122\n",
      "Epoch [35/50], Step [448/735], Loss: 0.2291\n",
      "Epoch [35/50], Step [449/735], Loss: 0.2026\n",
      "Epoch [35/50], Step [450/735], Loss: 0.2511\n",
      "Epoch [35/50], Step [451/735], Loss: 0.2873\n",
      "Epoch [35/50], Step [452/735], Loss: 1.0175\n",
      "Epoch [35/50], Step [453/735], Loss: 0.1829\n",
      "Epoch [35/50], Step [454/735], Loss: 0.5330\n",
      "Epoch [35/50], Step [455/735], Loss: 0.2194\n",
      "Epoch [35/50], Step [456/735], Loss: 0.1522\n",
      "Epoch [35/50], Step [457/735], Loss: 0.2620\n",
      "Epoch [35/50], Step [458/735], Loss: 0.1948\n",
      "Epoch [35/50], Step [459/735], Loss: 0.2670\n",
      "Epoch [35/50], Step [460/735], Loss: 0.1937\n",
      "Epoch [35/50], Step [461/735], Loss: 0.7703\n",
      "Epoch [35/50], Step [462/735], Loss: 0.4681\n",
      "Epoch [35/50], Step [463/735], Loss: 0.1772\n",
      "Epoch [35/50], Step [464/735], Loss: 0.4563\n",
      "Epoch [35/50], Step [465/735], Loss: 0.1228\n",
      "Epoch [35/50], Step [466/735], Loss: 1.3221\n",
      "Epoch [35/50], Step [467/735], Loss: 0.1394\n",
      "Epoch [35/50], Step [468/735], Loss: 0.1991\n",
      "Epoch [35/50], Step [469/735], Loss: 0.5287\n",
      "Epoch [35/50], Step [470/735], Loss: 0.4507\n",
      "Epoch [35/50], Step [471/735], Loss: 0.5438\n",
      "Epoch [35/50], Step [472/735], Loss: 0.5198\n",
      "Epoch [35/50], Step [473/735], Loss: 1.5976\n",
      "Epoch [35/50], Step [474/735], Loss: 0.1664\n",
      "Epoch [35/50], Step [475/735], Loss: 0.5010\n",
      "Epoch [35/50], Step [476/735], Loss: 0.5896\n",
      "Epoch [35/50], Step [477/735], Loss: 0.3245\n",
      "Epoch [35/50], Step [478/735], Loss: 0.2416\n",
      "Epoch [35/50], Step [479/735], Loss: 0.1573\n",
      "Epoch [35/50], Step [480/735], Loss: 0.1537\n",
      "Epoch [35/50], Step [481/735], Loss: 0.2250\n",
      "Epoch [35/50], Step [482/735], Loss: 0.2268\n",
      "Epoch [35/50], Step [483/735], Loss: 0.3543\n",
      "Epoch [35/50], Step [484/735], Loss: 0.3608\n",
      "Epoch [35/50], Step [485/735], Loss: 0.2520\n",
      "Epoch [35/50], Step [486/735], Loss: 0.2138\n",
      "Epoch [35/50], Step [487/735], Loss: 0.0839\n",
      "Epoch [35/50], Step [488/735], Loss: 0.2884\n",
      "Epoch [35/50], Step [489/735], Loss: 0.2020\n",
      "Epoch [35/50], Step [490/735], Loss: 0.7044\n",
      "Epoch [35/50], Step [491/735], Loss: 0.9487\n",
      "Epoch [35/50], Step [492/735], Loss: 0.1274\n",
      "Epoch [35/50], Step [493/735], Loss: 0.0848\n",
      "Epoch [35/50], Step [494/735], Loss: 0.3647\n",
      "Epoch [35/50], Step [495/735], Loss: 0.4927\n",
      "Epoch [35/50], Step [496/735], Loss: 0.1884\n",
      "Epoch [35/50], Step [497/735], Loss: 0.6213\n",
      "Epoch [35/50], Step [498/735], Loss: 0.4439\n",
      "Epoch [35/50], Step [499/735], Loss: 0.3448\n",
      "Epoch [35/50], Step [500/735], Loss: 0.1984\n",
      "Epoch [35/50], Step [501/735], Loss: 0.2532\n",
      "Epoch [35/50], Step [502/735], Loss: 0.5110\n",
      "Epoch [35/50], Step [503/735], Loss: 0.1955\n",
      "Epoch [35/50], Step [504/735], Loss: 0.1795\n",
      "Epoch [35/50], Step [505/735], Loss: 0.2717\n",
      "Epoch [35/50], Step [506/735], Loss: 0.4401\n",
      "Epoch [35/50], Step [507/735], Loss: 0.0550\n",
      "Epoch [35/50], Step [508/735], Loss: 0.1402\n",
      "Epoch [35/50], Step [509/735], Loss: 0.2125\n",
      "Epoch [35/50], Step [510/735], Loss: 0.1828\n",
      "Epoch [35/50], Step [511/735], Loss: 0.1236\n",
      "Epoch [35/50], Step [512/735], Loss: 0.0943\n",
      "Epoch [35/50], Step [513/735], Loss: 0.3935\n",
      "Epoch [35/50], Step [514/735], Loss: 0.1601\n",
      "Epoch [35/50], Step [515/735], Loss: 0.1158\n",
      "Epoch [35/50], Step [516/735], Loss: 0.3292\n",
      "Epoch [35/50], Step [517/735], Loss: 0.8338\n",
      "Epoch [35/50], Step [518/735], Loss: 0.1926\n",
      "Epoch [35/50], Step [519/735], Loss: 0.2908\n",
      "Epoch [35/50], Step [520/735], Loss: 0.2260\n",
      "Epoch [35/50], Step [521/735], Loss: 0.1769\n",
      "Epoch [35/50], Step [522/735], Loss: 0.1847\n",
      "Epoch [35/50], Step [523/735], Loss: 0.3570\n",
      "Epoch [35/50], Step [524/735], Loss: 0.2319\n",
      "Epoch [35/50], Step [525/735], Loss: 0.5873\n",
      "Epoch [35/50], Step [526/735], Loss: 0.5161\n",
      "Epoch [35/50], Step [527/735], Loss: 0.4292\n",
      "Epoch [35/50], Step [528/735], Loss: 0.3127\n",
      "Epoch [35/50], Step [529/735], Loss: 0.7106\n",
      "Epoch [35/50], Step [530/735], Loss: 0.1724\n",
      "Epoch [35/50], Step [531/735], Loss: 0.2749\n",
      "Epoch [35/50], Step [532/735], Loss: 0.3151\n",
      "Epoch [35/50], Step [533/735], Loss: 0.2971\n",
      "Epoch [35/50], Step [534/735], Loss: 0.0941\n",
      "Epoch [35/50], Step [535/735], Loss: 0.2385\n",
      "Epoch [35/50], Step [536/735], Loss: 0.3528\n",
      "Epoch [35/50], Step [537/735], Loss: 0.9808\n",
      "Epoch [35/50], Step [538/735], Loss: 0.1230\n",
      "Epoch [35/50], Step [539/735], Loss: 0.1518\n",
      "Epoch [35/50], Step [540/735], Loss: 0.1503\n",
      "Epoch [35/50], Step [541/735], Loss: 0.2998\n",
      "Epoch [35/50], Step [542/735], Loss: 0.1964\n",
      "Epoch [35/50], Step [543/735], Loss: 0.1113\n",
      "Epoch [35/50], Step [544/735], Loss: 0.0623\n",
      "Epoch [35/50], Step [545/735], Loss: 0.1780\n",
      "Epoch [35/50], Step [546/735], Loss: 0.1170\n",
      "Epoch [35/50], Step [547/735], Loss: 0.2275\n",
      "Epoch [35/50], Step [548/735], Loss: 0.1600\n",
      "Epoch [35/50], Step [549/735], Loss: 0.2110\n",
      "Epoch [35/50], Step [550/735], Loss: 0.2224\n",
      "Epoch [35/50], Step [551/735], Loss: 0.2571\n",
      "Epoch [35/50], Step [552/735], Loss: 0.2647\n",
      "Epoch [35/50], Step [553/735], Loss: 0.4209\n",
      "Epoch [35/50], Step [554/735], Loss: 0.2211\n",
      "Epoch [35/50], Step [555/735], Loss: 0.7967\n",
      "Epoch [35/50], Step [556/735], Loss: 0.0954\n",
      "Epoch [35/50], Step [557/735], Loss: 0.4516\n",
      "Epoch [35/50], Step [558/735], Loss: 0.4759\n",
      "Epoch [35/50], Step [559/735], Loss: 0.4367\n",
      "Epoch [35/50], Step [560/735], Loss: 0.0843\n",
      "Epoch [35/50], Step [561/735], Loss: 0.2952\n",
      "Epoch [35/50], Step [562/735], Loss: 0.1932\n",
      "Epoch [35/50], Step [563/735], Loss: 0.2004\n",
      "Epoch [35/50], Step [564/735], Loss: 1.6311\n",
      "Epoch [35/50], Step [565/735], Loss: 0.1096\n",
      "Epoch [35/50], Step [566/735], Loss: 0.0922\n",
      "Epoch [35/50], Step [567/735], Loss: 0.8030\n",
      "Epoch [35/50], Step [568/735], Loss: 0.0802\n",
      "Epoch [35/50], Step [569/735], Loss: 0.1341\n",
      "Epoch [35/50], Step [570/735], Loss: 0.0777\n",
      "Epoch [35/50], Step [571/735], Loss: 0.2107\n",
      "Epoch [35/50], Step [572/735], Loss: 0.3165\n",
      "Epoch [35/50], Step [573/735], Loss: 0.1588\n",
      "Epoch [35/50], Step [574/735], Loss: 0.3097\n",
      "Epoch [35/50], Step [575/735], Loss: 0.1391\n",
      "Epoch [35/50], Step [576/735], Loss: 0.3959\n",
      "Epoch [35/50], Step [577/735], Loss: 0.1315\n",
      "Epoch [35/50], Step [578/735], Loss: 0.8236\n",
      "Epoch [35/50], Step [579/735], Loss: 0.1779\n",
      "Epoch [35/50], Step [580/735], Loss: 0.1447\n",
      "Epoch [35/50], Step [581/735], Loss: 0.6446\n",
      "Epoch [35/50], Step [582/735], Loss: 0.2172\n",
      "Epoch [35/50], Step [583/735], Loss: 0.0881\n",
      "Epoch [35/50], Step [584/735], Loss: 0.2920\n",
      "Epoch [35/50], Step [585/735], Loss: 0.2256\n",
      "Epoch [35/50], Step [586/735], Loss: 0.1661\n",
      "Epoch [35/50], Step [587/735], Loss: 0.1503\n",
      "Epoch [35/50], Step [588/735], Loss: 0.3313\n",
      "Epoch [35/50], Step [589/735], Loss: 0.1669\n",
      "Epoch [35/50], Step [590/735], Loss: 0.6179\n",
      "Epoch [35/50], Step [591/735], Loss: 0.2863\n",
      "Epoch [35/50], Step [592/735], Loss: 0.3865\n",
      "Epoch [35/50], Step [593/735], Loss: 0.2979\n",
      "Epoch [35/50], Step [594/735], Loss: 0.2166\n",
      "Epoch [35/50], Step [595/735], Loss: 0.2196\n",
      "Epoch [35/50], Step [596/735], Loss: 0.0739\n",
      "Epoch [35/50], Step [597/735], Loss: 0.6169\n",
      "Epoch [35/50], Step [598/735], Loss: 0.6375\n",
      "Epoch [35/50], Step [599/735], Loss: 0.2099\n",
      "Epoch [35/50], Step [600/735], Loss: 0.1990\n",
      "Epoch [35/50], Step [601/735], Loss: 0.1065\n",
      "Epoch [35/50], Step [602/735], Loss: 0.6343\n",
      "Epoch [35/50], Step [603/735], Loss: 0.4351\n",
      "Epoch [35/50], Step [604/735], Loss: 0.1040\n",
      "Epoch [35/50], Step [605/735], Loss: 0.4706\n",
      "Epoch [35/50], Step [606/735], Loss: 0.5935\n",
      "Epoch [35/50], Step [607/735], Loss: 0.4705\n",
      "Epoch [35/50], Step [608/735], Loss: 0.4053\n",
      "Epoch [35/50], Step [609/735], Loss: 0.0876\n",
      "Epoch [35/50], Step [610/735], Loss: 0.3590\n",
      "Epoch [35/50], Step [611/735], Loss: 0.5026\n",
      "Epoch [35/50], Step [612/735], Loss: 0.4305\n",
      "Epoch [35/50], Step [613/735], Loss: 0.1881\n",
      "Epoch [35/50], Step [614/735], Loss: 0.2655\n",
      "Epoch [35/50], Step [615/735], Loss: 0.0816\n",
      "Epoch [35/50], Step [616/735], Loss: 0.3197\n",
      "Epoch [35/50], Step [617/735], Loss: 0.2812\n",
      "Epoch [35/50], Step [618/735], Loss: 0.2883\n",
      "Epoch [35/50], Step [619/735], Loss: 0.1862\n",
      "Epoch [35/50], Step [620/735], Loss: 0.1097\n",
      "Epoch [35/50], Step [621/735], Loss: 0.3523\n",
      "Epoch [35/50], Step [622/735], Loss: 0.2822\n",
      "Epoch [35/50], Step [623/735], Loss: 0.5141\n",
      "Epoch [35/50], Step [624/735], Loss: 0.3577\n",
      "Epoch [35/50], Step [625/735], Loss: 0.1609\n",
      "Epoch [35/50], Step [626/735], Loss: 0.2686\n",
      "Epoch [35/50], Step [627/735], Loss: 0.3196\n",
      "Epoch [35/50], Step [628/735], Loss: 0.4027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Step [629/735], Loss: 0.3437\n",
      "Epoch [35/50], Step [630/735], Loss: 0.2953\n",
      "Epoch [35/50], Step [631/735], Loss: 0.3543\n",
      "Epoch [35/50], Step [632/735], Loss: 0.2621\n",
      "Epoch [35/50], Step [633/735], Loss: 0.1385\n",
      "Epoch [35/50], Step [634/735], Loss: 0.5288\n",
      "Epoch [35/50], Step [635/735], Loss: 0.2294\n",
      "Epoch [35/50], Step [636/735], Loss: 0.2831\n",
      "Epoch [35/50], Step [637/735], Loss: 0.1775\n",
      "Epoch [35/50], Step [638/735], Loss: 0.3722\n",
      "Epoch [35/50], Step [639/735], Loss: 0.2779\n",
      "Epoch [35/50], Step [640/735], Loss: 0.8199\n",
      "Epoch [35/50], Step [641/735], Loss: 0.2868\n",
      "Epoch [35/50], Step [642/735], Loss: 0.2091\n",
      "Epoch [35/50], Step [643/735], Loss: 0.3860\n",
      "Epoch [35/50], Step [644/735], Loss: 0.1937\n",
      "Epoch [35/50], Step [645/735], Loss: 0.4127\n",
      "Epoch [35/50], Step [646/735], Loss: 0.4351\n",
      "Epoch [35/50], Step [647/735], Loss: 0.2009\n",
      "Epoch [35/50], Step [648/735], Loss: 0.1217\n",
      "Epoch [35/50], Step [649/735], Loss: 0.1000\n",
      "Epoch [35/50], Step [650/735], Loss: 0.6495\n",
      "Epoch [35/50], Step [651/735], Loss: 0.2017\n",
      "Epoch [35/50], Step [652/735], Loss: 1.1209\n",
      "Epoch [35/50], Step [653/735], Loss: 0.4211\n",
      "Epoch [35/50], Step [654/735], Loss: 0.1918\n",
      "Epoch [35/50], Step [655/735], Loss: 0.3073\n",
      "Epoch [35/50], Step [656/735], Loss: 0.7873\n",
      "Epoch [35/50], Step [657/735], Loss: 0.1278\n",
      "Epoch [35/50], Step [658/735], Loss: 0.3143\n",
      "Epoch [35/50], Step [659/735], Loss: 0.2922\n",
      "Epoch [35/50], Step [660/735], Loss: 0.0767\n",
      "Epoch [35/50], Step [661/735], Loss: 0.0533\n",
      "Epoch [35/50], Step [662/735], Loss: 0.1212\n",
      "Epoch [35/50], Step [663/735], Loss: 0.5581\n",
      "Epoch [35/50], Step [664/735], Loss: 1.1580\n",
      "Epoch [35/50], Step [665/735], Loss: 0.2863\n",
      "Epoch [35/50], Step [666/735], Loss: 0.2585\n",
      "Epoch [35/50], Step [667/735], Loss: 0.3646\n",
      "Epoch [35/50], Step [668/735], Loss: 0.6544\n",
      "Epoch [35/50], Step [669/735], Loss: 0.2238\n",
      "Epoch [35/50], Step [670/735], Loss: 0.2512\n",
      "Epoch [35/50], Step [671/735], Loss: 0.5743\n",
      "Epoch [35/50], Step [672/735], Loss: 0.1443\n",
      "Epoch [35/50], Step [673/735], Loss: 0.1453\n",
      "Epoch [35/50], Step [674/735], Loss: 0.1722\n",
      "Epoch [35/50], Step [675/735], Loss: 0.1866\n",
      "Epoch [35/50], Step [676/735], Loss: 0.5736\n",
      "Epoch [35/50], Step [677/735], Loss: 0.1920\n",
      "Epoch [35/50], Step [678/735], Loss: 0.2538\n",
      "Epoch [35/50], Step [679/735], Loss: 0.2278\n",
      "Epoch [35/50], Step [680/735], Loss: 0.1567\n",
      "Epoch [35/50], Step [681/735], Loss: 0.1501\n",
      "Epoch [35/50], Step [682/735], Loss: 0.7475\n",
      "Epoch [35/50], Step [683/735], Loss: 0.1964\n",
      "Epoch [35/50], Step [684/735], Loss: 0.6761\n",
      "Epoch [35/50], Step [685/735], Loss: 0.4288\n",
      "Epoch [35/50], Step [686/735], Loss: 0.1104\n",
      "Epoch [35/50], Step [687/735], Loss: 0.5121\n",
      "Epoch [35/50], Step [688/735], Loss: 0.2432\n",
      "Epoch [35/50], Step [689/735], Loss: 0.3029\n",
      "Epoch [35/50], Step [690/735], Loss: 0.0999\n",
      "Epoch [35/50], Step [691/735], Loss: 0.3736\n",
      "Epoch [35/50], Step [692/735], Loss: 0.4127\n",
      "Epoch [35/50], Step [693/735], Loss: 1.2421\n",
      "Epoch [35/50], Step [694/735], Loss: 0.2131\n",
      "Epoch [35/50], Step [695/735], Loss: 0.4007\n",
      "Epoch [35/50], Step [696/735], Loss: 0.1634\n",
      "Epoch [35/50], Step [697/735], Loss: 0.0416\n",
      "Epoch [35/50], Step [698/735], Loss: 0.2319\n",
      "Epoch [35/50], Step [699/735], Loss: 0.1838\n",
      "Epoch [35/50], Step [700/735], Loss: 0.1857\n",
      "Epoch [35/50], Step [701/735], Loss: 0.5502\n",
      "Epoch [35/50], Step [702/735], Loss: 0.1044\n",
      "Epoch [35/50], Step [703/735], Loss: 0.2598\n",
      "Epoch [35/50], Step [704/735], Loss: 0.6666\n",
      "Epoch [35/50], Step [705/735], Loss: 0.4307\n",
      "Epoch [35/50], Step [706/735], Loss: 0.3060\n",
      "Epoch [35/50], Step [707/735], Loss: 0.2293\n",
      "Epoch [35/50], Step [708/735], Loss: 0.1955\n",
      "Epoch [35/50], Step [709/735], Loss: 1.0158\n",
      "Epoch [35/50], Step [710/735], Loss: 0.1189\n",
      "Epoch [35/50], Step [711/735], Loss: 0.0901\n",
      "Epoch [35/50], Step [712/735], Loss: 0.3452\n",
      "Epoch [35/50], Step [713/735], Loss: 0.3272\n",
      "Epoch [35/50], Step [714/735], Loss: 0.2897\n",
      "Epoch [35/50], Step [715/735], Loss: 0.7793\n",
      "Epoch [35/50], Step [716/735], Loss: 0.6116\n",
      "Epoch [35/50], Step [717/735], Loss: 0.3830\n",
      "Epoch [35/50], Step [718/735], Loss: 0.3364\n",
      "Epoch [35/50], Step [719/735], Loss: 0.2495\n",
      "Epoch [35/50], Step [720/735], Loss: 0.9848\n",
      "Epoch [35/50], Step [721/735], Loss: 0.1949\n",
      "Epoch [35/50], Step [722/735], Loss: 0.1376\n",
      "Epoch [35/50], Step [723/735], Loss: 0.2334\n",
      "Epoch [35/50], Step [724/735], Loss: 0.2485\n",
      "Epoch [35/50], Step [725/735], Loss: 0.1962\n",
      "Epoch [35/50], Step [726/735], Loss: 0.2933\n",
      "Epoch [35/50], Step [727/735], Loss: 0.1635\n",
      "Epoch [35/50], Step [728/735], Loss: 0.2137\n",
      "Epoch [35/50], Step [729/735], Loss: 0.2551\n",
      "Epoch [35/50], Step [730/735], Loss: 0.2170\n",
      "Epoch [35/50], Step [731/735], Loss: 0.3196\n",
      "Epoch [35/50], Step [732/735], Loss: 0.4184\n",
      "Epoch [35/50], Step [733/735], Loss: 0.7142\n",
      "Epoch [35/50], Step [734/735], Loss: 0.1676\n",
      "Epoch [35/50], Step [735/735], Loss: 0.5103\n",
      "Epoch [36/50], Step [1/735], Loss: 0.4571\n",
      "Epoch [36/50], Step [2/735], Loss: 0.4197\n",
      "Epoch [36/50], Step [3/735], Loss: 0.2267\n",
      "Epoch [36/50], Step [4/735], Loss: 0.2840\n",
      "Epoch [36/50], Step [5/735], Loss: 0.7431\n",
      "Epoch [36/50], Step [6/735], Loss: 0.3204\n",
      "Epoch [36/50], Step [7/735], Loss: 0.2243\n",
      "Epoch [36/50], Step [8/735], Loss: 0.1299\n",
      "Epoch [36/50], Step [9/735], Loss: 0.0616\n",
      "Epoch [36/50], Step [10/735], Loss: 0.0879\n",
      "Epoch [36/50], Step [11/735], Loss: 0.4007\n",
      "Epoch [36/50], Step [12/735], Loss: 0.2673\n",
      "Epoch [36/50], Step [13/735], Loss: 0.1968\n",
      "Epoch [36/50], Step [14/735], Loss: 0.1605\n",
      "Epoch [36/50], Step [15/735], Loss: 0.4707\n",
      "Epoch [36/50], Step [16/735], Loss: 0.2215\n",
      "Epoch [36/50], Step [17/735], Loss: 0.1101\n",
      "Epoch [36/50], Step [18/735], Loss: 0.1423\n",
      "Epoch [36/50], Step [19/735], Loss: 0.2399\n",
      "Epoch [36/50], Step [20/735], Loss: 0.7271\n",
      "Epoch [36/50], Step [21/735], Loss: 0.1437\n",
      "Epoch [36/50], Step [22/735], Loss: 0.1716\n",
      "Epoch [36/50], Step [23/735], Loss: 0.3243\n",
      "Epoch [36/50], Step [24/735], Loss: 0.4505\n",
      "Epoch [36/50], Step [25/735], Loss: 4.6417\n",
      "Epoch [36/50], Step [26/735], Loss: 0.2803\n",
      "Epoch [36/50], Step [27/735], Loss: 0.5008\n",
      "Epoch [36/50], Step [28/735], Loss: 0.1462\n",
      "Epoch [36/50], Step [29/735], Loss: 0.2088\n",
      "Epoch [36/50], Step [30/735], Loss: 0.3217\n",
      "Epoch [36/50], Step [31/735], Loss: 0.5499\n",
      "Epoch [36/50], Step [32/735], Loss: 0.2582\n",
      "Epoch [36/50], Step [33/735], Loss: 0.2181\n",
      "Epoch [36/50], Step [34/735], Loss: 1.0838\n",
      "Epoch [36/50], Step [35/735], Loss: 0.3915\n",
      "Epoch [36/50], Step [36/735], Loss: 0.2474\n",
      "Epoch [36/50], Step [37/735], Loss: 0.2545\n",
      "Epoch [36/50], Step [38/735], Loss: 0.1818\n",
      "Epoch [36/50], Step [39/735], Loss: 0.1660\n",
      "Epoch [36/50], Step [40/735], Loss: 0.0992\n",
      "Epoch [36/50], Step [41/735], Loss: 0.2288\n",
      "Epoch [36/50], Step [42/735], Loss: 0.4291\n",
      "Epoch [36/50], Step [43/735], Loss: 0.3706\n",
      "Epoch [36/50], Step [44/735], Loss: 0.4513\n",
      "Epoch [36/50], Step [45/735], Loss: 0.3257\n",
      "Epoch [36/50], Step [46/735], Loss: 0.3589\n",
      "Epoch [36/50], Step [47/735], Loss: 0.1006\n",
      "Epoch [36/50], Step [48/735], Loss: 0.2244\n",
      "Epoch [36/50], Step [49/735], Loss: 0.3389\n",
      "Epoch [36/50], Step [50/735], Loss: 0.6282\n",
      "Epoch [36/50], Step [51/735], Loss: 0.1455\n",
      "Epoch [36/50], Step [52/735], Loss: 0.1137\n",
      "Epoch [36/50], Step [53/735], Loss: 0.0849\n",
      "Epoch [36/50], Step [54/735], Loss: 0.3248\n",
      "Epoch [36/50], Step [55/735], Loss: 0.6032\n",
      "Epoch [36/50], Step [56/735], Loss: 0.3997\n",
      "Epoch [36/50], Step [57/735], Loss: 0.2310\n",
      "Epoch [36/50], Step [58/735], Loss: 0.0654\n",
      "Epoch [36/50], Step [59/735], Loss: 0.4972\n",
      "Epoch [36/50], Step [60/735], Loss: 0.2511\n",
      "Epoch [36/50], Step [61/735], Loss: 0.2685\n",
      "Epoch [36/50], Step [62/735], Loss: 0.9828\n",
      "Epoch [36/50], Step [63/735], Loss: 0.4683\n",
      "Epoch [36/50], Step [64/735], Loss: 0.1999\n",
      "Epoch [36/50], Step [65/735], Loss: 0.0723\n",
      "Epoch [36/50], Step [66/735], Loss: 0.3944\n",
      "Epoch [36/50], Step [67/735], Loss: 0.0892\n",
      "Epoch [36/50], Step [68/735], Loss: 0.0965\n",
      "Epoch [36/50], Step [69/735], Loss: 0.3716\n",
      "Epoch [36/50], Step [70/735], Loss: 0.7053\n",
      "Epoch [36/50], Step [71/735], Loss: 0.2984\n",
      "Epoch [36/50], Step [72/735], Loss: 0.1313\n",
      "Epoch [36/50], Step [73/735], Loss: 0.9286\n",
      "Epoch [36/50], Step [74/735], Loss: 0.2224\n",
      "Epoch [36/50], Step [75/735], Loss: 0.2910\n",
      "Epoch [36/50], Step [76/735], Loss: 0.0668\n",
      "Epoch [36/50], Step [77/735], Loss: 0.9735\n",
      "Epoch [36/50], Step [78/735], Loss: 0.3523\n",
      "Epoch [36/50], Step [79/735], Loss: 0.2171\n",
      "Epoch [36/50], Step [80/735], Loss: 0.3992\n",
      "Epoch [36/50], Step [81/735], Loss: 0.2631\n",
      "Epoch [36/50], Step [82/735], Loss: 0.2288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Step [83/735], Loss: 0.1097\n",
      "Epoch [36/50], Step [84/735], Loss: 0.1620\n",
      "Epoch [36/50], Step [85/735], Loss: 0.0850\n",
      "Epoch [36/50], Step [86/735], Loss: 0.1632\n",
      "Epoch [36/50], Step [87/735], Loss: 0.1752\n",
      "Epoch [36/50], Step [88/735], Loss: 0.1911\n",
      "Epoch [36/50], Step [89/735], Loss: 0.0900\n",
      "Epoch [36/50], Step [90/735], Loss: 0.2889\n",
      "Epoch [36/50], Step [91/735], Loss: 0.4344\n",
      "Epoch [36/50], Step [92/735], Loss: 4.1371\n",
      "Epoch [36/50], Step [93/735], Loss: 0.2754\n",
      "Epoch [36/50], Step [94/735], Loss: 0.3662\n",
      "Epoch [36/50], Step [95/735], Loss: 0.3584\n",
      "Epoch [36/50], Step [96/735], Loss: 0.4205\n",
      "Epoch [36/50], Step [97/735], Loss: 0.0886\n",
      "Epoch [36/50], Step [98/735], Loss: 0.2402\n",
      "Epoch [36/50], Step [99/735], Loss: 0.1882\n",
      "Epoch [36/50], Step [100/735], Loss: 0.2910\n",
      "Epoch [36/50], Step [101/735], Loss: 0.4374\n",
      "Epoch [36/50], Step [102/735], Loss: 0.0844\n",
      "Epoch [36/50], Step [103/735], Loss: 0.2921\n",
      "Epoch [36/50], Step [104/735], Loss: 0.0996\n",
      "Epoch [36/50], Step [105/735], Loss: 0.1705\n",
      "Epoch [36/50], Step [106/735], Loss: 0.2068\n",
      "Epoch [36/50], Step [107/735], Loss: 0.2563\n",
      "Epoch [36/50], Step [108/735], Loss: 0.9284\n",
      "Epoch [36/50], Step [109/735], Loss: 0.3341\n",
      "Epoch [36/50], Step [110/735], Loss: 0.1808\n",
      "Epoch [36/50], Step [111/735], Loss: 0.5469\n",
      "Epoch [36/50], Step [112/735], Loss: 0.2520\n",
      "Epoch [36/50], Step [113/735], Loss: 0.5231\n",
      "Epoch [36/50], Step [114/735], Loss: 0.6690\n",
      "Epoch [36/50], Step [115/735], Loss: 0.0703\n",
      "Epoch [36/50], Step [116/735], Loss: 0.6527\n",
      "Epoch [36/50], Step [117/735], Loss: 0.0723\n",
      "Epoch [36/50], Step [118/735], Loss: 0.1265\n",
      "Epoch [36/50], Step [119/735], Loss: 0.8270\n",
      "Epoch [36/50], Step [120/735], Loss: 0.4694\n",
      "Epoch [36/50], Step [121/735], Loss: 0.1013\n",
      "Epoch [36/50], Step [122/735], Loss: 0.1433\n",
      "Epoch [36/50], Step [123/735], Loss: 0.0445\n",
      "Epoch [36/50], Step [124/735], Loss: 0.1972\n",
      "Epoch [36/50], Step [125/735], Loss: 0.1988\n",
      "Epoch [36/50], Step [126/735], Loss: 0.2424\n",
      "Epoch [36/50], Step [127/735], Loss: 0.4289\n",
      "Epoch [36/50], Step [128/735], Loss: 0.1252\n",
      "Epoch [36/50], Step [129/735], Loss: 0.3335\n",
      "Epoch [36/50], Step [130/735], Loss: 0.3825\n",
      "Epoch [36/50], Step [131/735], Loss: 0.1831\n",
      "Epoch [36/50], Step [132/735], Loss: 1.0061\n",
      "Epoch [36/50], Step [133/735], Loss: 0.4028\n",
      "Epoch [36/50], Step [134/735], Loss: 0.1327\n",
      "Epoch [36/50], Step [135/735], Loss: 0.2586\n",
      "Epoch [36/50], Step [136/735], Loss: 0.5323\n",
      "Epoch [36/50], Step [137/735], Loss: 0.2260\n",
      "Epoch [36/50], Step [138/735], Loss: 0.3894\n",
      "Epoch [36/50], Step [139/735], Loss: 0.4440\n",
      "Epoch [36/50], Step [140/735], Loss: 0.3543\n",
      "Epoch [36/50], Step [141/735], Loss: 0.3841\n",
      "Epoch [36/50], Step [142/735], Loss: 0.2722\n",
      "Epoch [36/50], Step [143/735], Loss: 0.2472\n",
      "Epoch [36/50], Step [144/735], Loss: 0.2799\n",
      "Epoch [36/50], Step [145/735], Loss: 0.2707\n",
      "Epoch [36/50], Step [146/735], Loss: 0.2052\n",
      "Epoch [36/50], Step [147/735], Loss: 0.1613\n",
      "Epoch [36/50], Step [148/735], Loss: 0.3801\n",
      "Epoch [36/50], Step [149/735], Loss: 0.2795\n",
      "Epoch [36/50], Step [150/735], Loss: 0.1815\n",
      "Epoch [36/50], Step [151/735], Loss: 0.2598\n",
      "Epoch [36/50], Step [152/735], Loss: 0.4048\n",
      "Epoch [36/50], Step [153/735], Loss: 0.5245\n",
      "Epoch [36/50], Step [154/735], Loss: 0.2300\n",
      "Epoch [36/50], Step [155/735], Loss: 0.3472\n",
      "Epoch [36/50], Step [156/735], Loss: 0.2083\n",
      "Epoch [36/50], Step [157/735], Loss: 0.4812\n",
      "Epoch [36/50], Step [158/735], Loss: 0.2802\n",
      "Epoch [36/50], Step [159/735], Loss: 0.7366\n",
      "Epoch [36/50], Step [160/735], Loss: 0.6532\n",
      "Epoch [36/50], Step [161/735], Loss: 0.4226\n",
      "Epoch [36/50], Step [162/735], Loss: 0.1133\n",
      "Epoch [36/50], Step [163/735], Loss: 1.0061\n",
      "Epoch [36/50], Step [164/735], Loss: 0.1436\n",
      "Epoch [36/50], Step [165/735], Loss: 0.2884\n",
      "Epoch [36/50], Step [166/735], Loss: 0.2827\n",
      "Epoch [36/50], Step [167/735], Loss: 0.2495\n",
      "Epoch [36/50], Step [168/735], Loss: 0.3945\n",
      "Epoch [36/50], Step [169/735], Loss: 0.2291\n",
      "Epoch [36/50], Step [170/735], Loss: 0.4780\n",
      "Epoch [36/50], Step [171/735], Loss: 0.3841\n",
      "Epoch [36/50], Step [172/735], Loss: 0.1179\n",
      "Epoch [36/50], Step [173/735], Loss: 0.2060\n",
      "Epoch [36/50], Step [174/735], Loss: 0.7193\n",
      "Epoch [36/50], Step [175/735], Loss: 0.8757\n",
      "Epoch [36/50], Step [176/735], Loss: 0.2474\n",
      "Epoch [36/50], Step [177/735], Loss: 0.1258\n",
      "Epoch [36/50], Step [178/735], Loss: 0.2495\n",
      "Epoch [36/50], Step [179/735], Loss: 0.1130\n",
      "Epoch [36/50], Step [180/735], Loss: 0.4155\n",
      "Epoch [36/50], Step [181/735], Loss: 0.6349\n",
      "Epoch [36/50], Step [182/735], Loss: 0.4267\n",
      "Epoch [36/50], Step [183/735], Loss: 0.4920\n",
      "Epoch [36/50], Step [184/735], Loss: 0.4791\n",
      "Epoch [36/50], Step [185/735], Loss: 0.3777\n",
      "Epoch [36/50], Step [186/735], Loss: 0.3886\n",
      "Epoch [36/50], Step [187/735], Loss: 0.1312\n",
      "Epoch [36/50], Step [188/735], Loss: 0.8108\n",
      "Epoch [36/50], Step [189/735], Loss: 0.3741\n",
      "Epoch [36/50], Step [190/735], Loss: 0.1526\n",
      "Epoch [36/50], Step [191/735], Loss: 0.3888\n",
      "Epoch [36/50], Step [192/735], Loss: 0.1450\n",
      "Epoch [36/50], Step [193/735], Loss: 0.2709\n",
      "Epoch [36/50], Step [194/735], Loss: 0.7601\n",
      "Epoch [36/50], Step [195/735], Loss: 0.1804\n",
      "Epoch [36/50], Step [196/735], Loss: 0.3840\n",
      "Epoch [36/50], Step [197/735], Loss: 0.1263\n",
      "Epoch [36/50], Step [198/735], Loss: 0.3402\n",
      "Epoch [36/50], Step [199/735], Loss: 0.1993\n",
      "Epoch [36/50], Step [200/735], Loss: 0.1582\n",
      "Epoch [36/50], Step [201/735], Loss: 0.2291\n",
      "Epoch [36/50], Step [202/735], Loss: 0.2382\n",
      "Epoch [36/50], Step [203/735], Loss: 0.1356\n",
      "Epoch [36/50], Step [204/735], Loss: 0.2671\n",
      "Epoch [36/50], Step [205/735], Loss: 0.3653\n",
      "Epoch [36/50], Step [206/735], Loss: 0.0395\n",
      "Epoch [36/50], Step [207/735], Loss: 0.2126\n",
      "Epoch [36/50], Step [208/735], Loss: 0.1037\n",
      "Epoch [36/50], Step [209/735], Loss: 0.1500\n",
      "Epoch [36/50], Step [210/735], Loss: 0.5463\n",
      "Epoch [36/50], Step [211/735], Loss: 0.2410\n",
      "Epoch [36/50], Step [212/735], Loss: 0.3381\n",
      "Epoch [36/50], Step [213/735], Loss: 0.1323\n",
      "Epoch [36/50], Step [214/735], Loss: 0.5034\n",
      "Epoch [36/50], Step [215/735], Loss: 0.1523\n",
      "Epoch [36/50], Step [216/735], Loss: 0.1839\n",
      "Epoch [36/50], Step [217/735], Loss: 0.4096\n",
      "Epoch [36/50], Step [218/735], Loss: 0.8257\n",
      "Epoch [36/50], Step [219/735], Loss: 0.4959\n",
      "Epoch [36/50], Step [220/735], Loss: 0.0924\n",
      "Epoch [36/50], Step [221/735], Loss: 0.1769\n",
      "Epoch [36/50], Step [222/735], Loss: 0.2589\n",
      "Epoch [36/50], Step [223/735], Loss: 0.3316\n",
      "Epoch [36/50], Step [224/735], Loss: 0.1949\n",
      "Epoch [36/50], Step [225/735], Loss: 0.4458\n",
      "Epoch [36/50], Step [226/735], Loss: 0.5094\n",
      "Epoch [36/50], Step [227/735], Loss: 0.1226\n",
      "Epoch [36/50], Step [228/735], Loss: 0.1841\n",
      "Epoch [36/50], Step [229/735], Loss: 0.2781\n",
      "Epoch [36/50], Step [230/735], Loss: 0.2576\n",
      "Epoch [36/50], Step [231/735], Loss: 0.2784\n",
      "Epoch [36/50], Step [232/735], Loss: 0.2137\n",
      "Epoch [36/50], Step [233/735], Loss: 0.2332\n",
      "Epoch [36/50], Step [234/735], Loss: 0.4723\n",
      "Epoch [36/50], Step [235/735], Loss: 0.2051\n",
      "Epoch [36/50], Step [236/735], Loss: 0.3251\n",
      "Epoch [36/50], Step [237/735], Loss: 0.4156\n",
      "Epoch [36/50], Step [238/735], Loss: 0.1979\n",
      "Epoch [36/50], Step [239/735], Loss: 0.0873\n",
      "Epoch [36/50], Step [240/735], Loss: 0.1833\n",
      "Epoch [36/50], Step [241/735], Loss: 0.3815\n",
      "Epoch [36/50], Step [242/735], Loss: 0.3783\n",
      "Epoch [36/50], Step [243/735], Loss: 0.6174\n",
      "Epoch [36/50], Step [244/735], Loss: 0.7293\n",
      "Epoch [36/50], Step [245/735], Loss: 0.6123\n",
      "Epoch [36/50], Step [246/735], Loss: 0.1352\n",
      "Epoch [36/50], Step [247/735], Loss: 0.0892\n",
      "Epoch [36/50], Step [248/735], Loss: 0.1313\n",
      "Epoch [36/50], Step [249/735], Loss: 0.1631\n",
      "Epoch [36/50], Step [250/735], Loss: 0.2528\n",
      "Epoch [36/50], Step [251/735], Loss: 0.2816\n",
      "Epoch [36/50], Step [252/735], Loss: 0.1361\n",
      "Epoch [36/50], Step [253/735], Loss: 0.1971\n",
      "Epoch [36/50], Step [254/735], Loss: 0.1309\n",
      "Epoch [36/50], Step [255/735], Loss: 0.0855\n",
      "Epoch [36/50], Step [256/735], Loss: 0.0714\n",
      "Epoch [36/50], Step [257/735], Loss: 0.2388\n",
      "Epoch [36/50], Step [258/735], Loss: 0.2349\n",
      "Epoch [36/50], Step [259/735], Loss: 0.1061\n",
      "Epoch [36/50], Step [260/735], Loss: 0.5790\n",
      "Epoch [36/50], Step [261/735], Loss: 0.1933\n",
      "Epoch [36/50], Step [262/735], Loss: 0.2406\n",
      "Epoch [36/50], Step [263/735], Loss: 0.3269\n",
      "Epoch [36/50], Step [264/735], Loss: 0.2281\n",
      "Epoch [36/50], Step [265/735], Loss: 0.5062\n",
      "Epoch [36/50], Step [266/735], Loss: 0.1230\n",
      "Epoch [36/50], Step [267/735], Loss: 0.0505\n",
      "Epoch [36/50], Step [268/735], Loss: 0.1618\n",
      "Epoch [36/50], Step [269/735], Loss: 0.7155\n",
      "Epoch [36/50], Step [270/735], Loss: 0.1887\n",
      "Epoch [36/50], Step [271/735], Loss: 0.4193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Step [272/735], Loss: 0.1873\n",
      "Epoch [36/50], Step [273/735], Loss: 0.4100\n",
      "Epoch [36/50], Step [274/735], Loss: 0.3231\n",
      "Epoch [36/50], Step [275/735], Loss: 0.4506\n",
      "Epoch [36/50], Step [276/735], Loss: 0.1118\n",
      "Epoch [36/50], Step [277/735], Loss: 0.3819\n",
      "Epoch [36/50], Step [278/735], Loss: 0.1640\n",
      "Epoch [36/50], Step [279/735], Loss: 0.1095\n",
      "Epoch [36/50], Step [280/735], Loss: 0.5558\n",
      "Epoch [36/50], Step [281/735], Loss: 0.4042\n",
      "Epoch [36/50], Step [282/735], Loss: 0.1986\n",
      "Epoch [36/50], Step [283/735], Loss: 0.0885\n",
      "Epoch [36/50], Step [284/735], Loss: 0.3397\n",
      "Epoch [36/50], Step [285/735], Loss: 0.1867\n",
      "Epoch [36/50], Step [286/735], Loss: 0.3750\n",
      "Epoch [36/50], Step [287/735], Loss: 0.1810\n",
      "Epoch [36/50], Step [288/735], Loss: 0.6725\n",
      "Epoch [36/50], Step [289/735], Loss: 0.2734\n",
      "Epoch [36/50], Step [290/735], Loss: 0.2896\n",
      "Epoch [36/50], Step [291/735], Loss: 0.3744\n",
      "Epoch [36/50], Step [292/735], Loss: 0.6300\n",
      "Epoch [36/50], Step [293/735], Loss: 0.4579\n",
      "Epoch [36/50], Step [294/735], Loss: 0.5660\n",
      "Epoch [36/50], Step [295/735], Loss: 0.7436\n",
      "Epoch [36/50], Step [296/735], Loss: 0.1877\n",
      "Epoch [36/50], Step [297/735], Loss: 0.1497\n",
      "Epoch [36/50], Step [298/735], Loss: 0.2322\n",
      "Epoch [36/50], Step [299/735], Loss: 0.2893\n",
      "Epoch [36/50], Step [300/735], Loss: 0.2818\n",
      "Epoch [36/50], Step [301/735], Loss: 0.2202\n",
      "Epoch [36/50], Step [302/735], Loss: 0.2042\n",
      "Epoch [36/50], Step [303/735], Loss: 0.3700\n",
      "Epoch [36/50], Step [304/735], Loss: 1.0784\n",
      "Epoch [36/50], Step [305/735], Loss: 0.3465\n",
      "Epoch [36/50], Step [306/735], Loss: 0.1338\n",
      "Epoch [36/50], Step [307/735], Loss: 0.5495\n",
      "Epoch [36/50], Step [308/735], Loss: 0.4626\n",
      "Epoch [36/50], Step [309/735], Loss: 0.2481\n",
      "Epoch [36/50], Step [310/735], Loss: 0.4430\n",
      "Epoch [36/50], Step [311/735], Loss: 0.3000\n",
      "Epoch [36/50], Step [312/735], Loss: 0.2651\n",
      "Epoch [36/50], Step [313/735], Loss: 0.4040\n",
      "Epoch [36/50], Step [314/735], Loss: 0.2344\n",
      "Epoch [36/50], Step [315/735], Loss: 0.2502\n",
      "Epoch [36/50], Step [316/735], Loss: 0.4551\n",
      "Epoch [36/50], Step [317/735], Loss: 0.1485\n",
      "Epoch [36/50], Step [318/735], Loss: 0.1494\n",
      "Epoch [36/50], Step [319/735], Loss: 0.5366\n",
      "Epoch [36/50], Step [320/735], Loss: 0.5084\n",
      "Epoch [36/50], Step [321/735], Loss: 0.0749\n",
      "Epoch [36/50], Step [322/735], Loss: 0.2532\n",
      "Epoch [36/50], Step [323/735], Loss: 0.5865\n",
      "Epoch [36/50], Step [324/735], Loss: 0.1149\n",
      "Epoch [36/50], Step [325/735], Loss: 0.2663\n",
      "Epoch [36/50], Step [326/735], Loss: 0.5589\n",
      "Epoch [36/50], Step [327/735], Loss: 0.5904\n",
      "Epoch [36/50], Step [328/735], Loss: 0.2291\n",
      "Epoch [36/50], Step [329/735], Loss: 0.1457\n",
      "Epoch [36/50], Step [330/735], Loss: 0.3059\n",
      "Epoch [36/50], Step [331/735], Loss: 0.1914\n",
      "Epoch [36/50], Step [332/735], Loss: 0.0477\n",
      "Epoch [36/50], Step [333/735], Loss: 0.6436\n",
      "Epoch [36/50], Step [334/735], Loss: 0.1229\n",
      "Epoch [36/50], Step [335/735], Loss: 0.1920\n",
      "Epoch [36/50], Step [336/735], Loss: 0.0808\n",
      "Epoch [36/50], Step [337/735], Loss: 0.2809\n",
      "Epoch [36/50], Step [338/735], Loss: 0.0895\n",
      "Epoch [36/50], Step [339/735], Loss: 0.2090\n",
      "Epoch [36/50], Step [340/735], Loss: 0.0598\n",
      "Epoch [36/50], Step [341/735], Loss: 0.1980\n",
      "Epoch [36/50], Step [342/735], Loss: 0.0918\n",
      "Epoch [36/50], Step [343/735], Loss: 3.6017\n",
      "Epoch [36/50], Step [344/735], Loss: 0.2382\n",
      "Epoch [36/50], Step [345/735], Loss: 0.6361\n",
      "Epoch [36/50], Step [346/735], Loss: 0.5750\n",
      "Epoch [36/50], Step [347/735], Loss: 0.3704\n",
      "Epoch [36/50], Step [348/735], Loss: 0.3770\n",
      "Epoch [36/50], Step [349/735], Loss: 0.2288\n",
      "Epoch [36/50], Step [350/735], Loss: 0.1880\n",
      "Epoch [36/50], Step [351/735], Loss: 0.1021\n",
      "Epoch [36/50], Step [352/735], Loss: 0.3330\n",
      "Epoch [36/50], Step [353/735], Loss: 0.1583\n",
      "Epoch [36/50], Step [354/735], Loss: 0.2639\n",
      "Epoch [36/50], Step [355/735], Loss: 0.6517\n",
      "Epoch [36/50], Step [356/735], Loss: 0.4942\n",
      "Epoch [36/50], Step [357/735], Loss: 0.4196\n",
      "Epoch [36/50], Step [358/735], Loss: 0.2293\n",
      "Epoch [36/50], Step [359/735], Loss: 0.1840\n",
      "Epoch [36/50], Step [360/735], Loss: 0.3099\n",
      "Epoch [36/50], Step [361/735], Loss: 0.2225\n",
      "Epoch [36/50], Step [362/735], Loss: 0.0902\n",
      "Epoch [36/50], Step [363/735], Loss: 0.3786\n",
      "Epoch [36/50], Step [364/735], Loss: 0.4446\n",
      "Epoch [36/50], Step [365/735], Loss: 0.2575\n",
      "Epoch [36/50], Step [366/735], Loss: 0.2160\n",
      "Epoch [36/50], Step [367/735], Loss: 0.2352\n",
      "Epoch [36/50], Step [368/735], Loss: 0.3421\n",
      "Epoch [36/50], Step [369/735], Loss: 0.3034\n",
      "Epoch [36/50], Step [370/735], Loss: 0.2907\n",
      "Epoch [36/50], Step [371/735], Loss: 0.2460\n",
      "Epoch [36/50], Step [372/735], Loss: 0.1165\n",
      "Epoch [36/50], Step [373/735], Loss: 0.4591\n",
      "Epoch [36/50], Step [374/735], Loss: 0.7951\n",
      "Epoch [36/50], Step [375/735], Loss: 0.1233\n",
      "Epoch [36/50], Step [376/735], Loss: 0.5440\n",
      "Epoch [36/50], Step [377/735], Loss: 0.2005\n",
      "Epoch [36/50], Step [378/735], Loss: 0.1280\n",
      "Epoch [36/50], Step [379/735], Loss: 0.2648\n",
      "Epoch [36/50], Step [380/735], Loss: 0.1099\n",
      "Epoch [36/50], Step [381/735], Loss: 0.6081\n",
      "Epoch [36/50], Step [382/735], Loss: 0.1648\n",
      "Epoch [36/50], Step [383/735], Loss: 0.2613\n",
      "Epoch [36/50], Step [384/735], Loss: 0.9149\n",
      "Epoch [36/50], Step [385/735], Loss: 0.3692\n",
      "Epoch [36/50], Step [386/735], Loss: 0.1693\n",
      "Epoch [36/50], Step [387/735], Loss: 0.3897\n",
      "Epoch [36/50], Step [388/735], Loss: 0.2384\n",
      "Epoch [36/50], Step [389/735], Loss: 0.4534\n",
      "Epoch [36/50], Step [390/735], Loss: 0.2051\n",
      "Epoch [36/50], Step [391/735], Loss: 0.2700\n",
      "Epoch [36/50], Step [392/735], Loss: 0.4741\n",
      "Epoch [36/50], Step [393/735], Loss: 0.3375\n",
      "Epoch [36/50], Step [394/735], Loss: 0.2587\n",
      "Epoch [36/50], Step [395/735], Loss: 1.1568\n",
      "Epoch [36/50], Step [396/735], Loss: 0.4477\n",
      "Epoch [36/50], Step [397/735], Loss: 0.0944\n",
      "Epoch [36/50], Step [398/735], Loss: 0.3242\n",
      "Epoch [36/50], Step [399/735], Loss: 0.4135\n",
      "Epoch [36/50], Step [400/735], Loss: 0.1993\n",
      "Epoch [36/50], Step [401/735], Loss: 0.3279\n",
      "Epoch [36/50], Step [402/735], Loss: 0.4231\n",
      "Epoch [36/50], Step [403/735], Loss: 0.1265\n",
      "Epoch [36/50], Step [404/735], Loss: 0.4427\n",
      "Epoch [36/50], Step [405/735], Loss: 0.3138\n",
      "Epoch [36/50], Step [406/735], Loss: 0.0886\n",
      "Epoch [36/50], Step [407/735], Loss: 0.2818\n",
      "Epoch [36/50], Step [408/735], Loss: 0.2485\n",
      "Epoch [36/50], Step [409/735], Loss: 0.2388\n",
      "Epoch [36/50], Step [410/735], Loss: 0.1895\n",
      "Epoch [36/50], Step [411/735], Loss: 0.3460\n",
      "Epoch [36/50], Step [412/735], Loss: 0.4803\n",
      "Epoch [36/50], Step [413/735], Loss: 0.2851\n",
      "Epoch [36/50], Step [414/735], Loss: 0.1355\n",
      "Epoch [36/50], Step [415/735], Loss: 0.5546\n",
      "Epoch [36/50], Step [416/735], Loss: 0.2851\n",
      "Epoch [36/50], Step [417/735], Loss: 0.3095\n",
      "Epoch [36/50], Step [418/735], Loss: 0.3681\n",
      "Epoch [36/50], Step [419/735], Loss: 0.2086\n",
      "Epoch [36/50], Step [420/735], Loss: 0.2897\n",
      "Epoch [36/50], Step [421/735], Loss: 0.2043\n",
      "Epoch [36/50], Step [422/735], Loss: 0.1250\n",
      "Epoch [36/50], Step [423/735], Loss: 0.1696\n",
      "Epoch [36/50], Step [424/735], Loss: 0.2202\n",
      "Epoch [36/50], Step [425/735], Loss: 0.1657\n",
      "Epoch [36/50], Step [426/735], Loss: 0.5246\n",
      "Epoch [36/50], Step [427/735], Loss: 0.3960\n",
      "Epoch [36/50], Step [428/735], Loss: 0.3359\n",
      "Epoch [36/50], Step [429/735], Loss: 0.1952\n",
      "Epoch [36/50], Step [430/735], Loss: 0.0765\n",
      "Epoch [36/50], Step [431/735], Loss: 0.7620\n",
      "Epoch [36/50], Step [432/735], Loss: 0.5213\n",
      "Epoch [36/50], Step [433/735], Loss: 0.5085\n",
      "Epoch [36/50], Step [434/735], Loss: 0.3763\n",
      "Epoch [36/50], Step [435/735], Loss: 0.4803\n",
      "Epoch [36/50], Step [436/735], Loss: 0.3745\n",
      "Epoch [36/50], Step [437/735], Loss: 0.1645\n",
      "Epoch [36/50], Step [438/735], Loss: 0.1683\n",
      "Epoch [36/50], Step [439/735], Loss: 0.2146\n",
      "Epoch [36/50], Step [440/735], Loss: 0.3695\n",
      "Epoch [36/50], Step [441/735], Loss: 0.3707\n",
      "Epoch [36/50], Step [442/735], Loss: 0.1995\n",
      "Epoch [36/50], Step [443/735], Loss: 1.6870\n",
      "Epoch [36/50], Step [444/735], Loss: 0.6062\n",
      "Epoch [36/50], Step [445/735], Loss: 0.4337\n",
      "Epoch [36/50], Step [446/735], Loss: 0.1730\n",
      "Epoch [36/50], Step [447/735], Loss: 0.5690\n",
      "Epoch [36/50], Step [448/735], Loss: 0.1695\n",
      "Epoch [36/50], Step [449/735], Loss: 0.1452\n",
      "Epoch [36/50], Step [450/735], Loss: 0.1264\n",
      "Epoch [36/50], Step [451/735], Loss: 0.2296\n",
      "Epoch [36/50], Step [452/735], Loss: 0.2153\n",
      "Epoch [36/50], Step [453/735], Loss: 0.1821\n",
      "Epoch [36/50], Step [454/735], Loss: 0.1111\n",
      "Epoch [36/50], Step [455/735], Loss: 0.9864\n",
      "Epoch [36/50], Step [456/735], Loss: 0.3500\n",
      "Epoch [36/50], Step [457/735], Loss: 0.2511\n",
      "Epoch [36/50], Step [458/735], Loss: 0.0900\n",
      "Epoch [36/50], Step [459/735], Loss: 0.3876\n",
      "Epoch [36/50], Step [460/735], Loss: 0.6716\n",
      "Epoch [36/50], Step [461/735], Loss: 0.0689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Step [462/735], Loss: 0.8892\n",
      "Epoch [36/50], Step [463/735], Loss: 0.6880\n",
      "Epoch [36/50], Step [464/735], Loss: 0.4034\n",
      "Epoch [36/50], Step [465/735], Loss: 0.1982\n",
      "Epoch [36/50], Step [466/735], Loss: 1.0951\n",
      "Epoch [36/50], Step [467/735], Loss: 0.1211\n",
      "Epoch [36/50], Step [468/735], Loss: 0.1236\n",
      "Epoch [36/50], Step [469/735], Loss: 0.3927\n",
      "Epoch [36/50], Step [470/735], Loss: 0.4255\n",
      "Epoch [36/50], Step [471/735], Loss: 0.1893\n",
      "Epoch [36/50], Step [472/735], Loss: 0.3561\n",
      "Epoch [36/50], Step [473/735], Loss: 0.2686\n",
      "Epoch [36/50], Step [474/735], Loss: 0.1295\n",
      "Epoch [36/50], Step [475/735], Loss: 0.1370\n",
      "Epoch [36/50], Step [476/735], Loss: 0.2450\n",
      "Epoch [36/50], Step [477/735], Loss: 0.4706\n",
      "Epoch [36/50], Step [478/735], Loss: 0.2617\n",
      "Epoch [36/50], Step [479/735], Loss: 0.1100\n",
      "Epoch [36/50], Step [480/735], Loss: 0.2826\n",
      "Epoch [36/50], Step [481/735], Loss: 0.0908\n",
      "Epoch [36/50], Step [482/735], Loss: 0.2230\n",
      "Epoch [36/50], Step [483/735], Loss: 0.2049\n",
      "Epoch [36/50], Step [484/735], Loss: 0.2557\n",
      "Epoch [36/50], Step [485/735], Loss: 0.4306\n",
      "Epoch [36/50], Step [486/735], Loss: 0.1546\n",
      "Epoch [36/50], Step [487/735], Loss: 0.3472\n",
      "Epoch [36/50], Step [488/735], Loss: 0.0912\n",
      "Epoch [36/50], Step [489/735], Loss: 0.0725\n",
      "Epoch [36/50], Step [490/735], Loss: 0.1186\n",
      "Epoch [36/50], Step [491/735], Loss: 0.1961\n",
      "Epoch [36/50], Step [492/735], Loss: 0.2043\n",
      "Epoch [36/50], Step [493/735], Loss: 0.2812\n",
      "Epoch [36/50], Step [494/735], Loss: 0.6760\n",
      "Epoch [36/50], Step [495/735], Loss: 0.2512\n",
      "Epoch [36/50], Step [496/735], Loss: 0.8461\n",
      "Epoch [36/50], Step [497/735], Loss: 0.5051\n",
      "Epoch [36/50], Step [498/735], Loss: 0.1088\n",
      "Epoch [36/50], Step [499/735], Loss: 0.1744\n",
      "Epoch [36/50], Step [500/735], Loss: 0.2208\n",
      "Epoch [36/50], Step [501/735], Loss: 0.1408\n",
      "Epoch [36/50], Step [502/735], Loss: 0.1838\n",
      "Epoch [36/50], Step [503/735], Loss: 0.3411\n",
      "Epoch [36/50], Step [504/735], Loss: 0.2563\n",
      "Epoch [36/50], Step [505/735], Loss: 1.1572\n",
      "Epoch [36/50], Step [506/735], Loss: 0.1982\n",
      "Epoch [36/50], Step [507/735], Loss: 0.1478\n",
      "Epoch [36/50], Step [508/735], Loss: 0.1339\n",
      "Epoch [36/50], Step [509/735], Loss: 0.0912\n",
      "Epoch [36/50], Step [510/735], Loss: 0.6146\n",
      "Epoch [36/50], Step [511/735], Loss: 0.1094\n",
      "Epoch [36/50], Step [512/735], Loss: 0.5487\n",
      "Epoch [36/50], Step [513/735], Loss: 0.2754\n",
      "Epoch [36/50], Step [514/735], Loss: 3.7777\n",
      "Epoch [36/50], Step [515/735], Loss: 0.1844\n",
      "Epoch [36/50], Step [516/735], Loss: 0.1599\n",
      "Epoch [36/50], Step [517/735], Loss: 0.1849\n",
      "Epoch [36/50], Step [518/735], Loss: 0.1678\n",
      "Epoch [36/50], Step [519/735], Loss: 0.2847\n",
      "Epoch [36/50], Step [520/735], Loss: 0.6253\n",
      "Epoch [36/50], Step [521/735], Loss: 0.3952\n",
      "Epoch [36/50], Step [522/735], Loss: 0.5357\n",
      "Epoch [36/50], Step [523/735], Loss: 0.2225\n",
      "Epoch [36/50], Step [524/735], Loss: 0.2291\n",
      "Epoch [36/50], Step [525/735], Loss: 0.6684\n",
      "Epoch [36/50], Step [526/735], Loss: 0.1632\n",
      "Epoch [36/50], Step [527/735], Loss: 0.2424\n",
      "Epoch [36/50], Step [528/735], Loss: 0.2954\n",
      "Epoch [36/50], Step [529/735], Loss: 0.2839\n",
      "Epoch [36/50], Step [530/735], Loss: 0.2534\n",
      "Epoch [36/50], Step [531/735], Loss: 0.1979\n",
      "Epoch [36/50], Step [532/735], Loss: 0.3430\n",
      "Epoch [36/50], Step [533/735], Loss: 0.8369\n",
      "Epoch [36/50], Step [534/735], Loss: 0.7792\n",
      "Epoch [36/50], Step [535/735], Loss: 0.5608\n",
      "Epoch [36/50], Step [536/735], Loss: 0.6060\n",
      "Epoch [36/50], Step [537/735], Loss: 0.1106\n",
      "Epoch [36/50], Step [538/735], Loss: 0.3030\n",
      "Epoch [36/50], Step [539/735], Loss: 0.2898\n",
      "Epoch [36/50], Step [540/735], Loss: 0.1897\n",
      "Epoch [36/50], Step [541/735], Loss: 0.1746\n",
      "Epoch [36/50], Step [542/735], Loss: 0.3116\n",
      "Epoch [36/50], Step [543/735], Loss: 0.2047\n",
      "Epoch [36/50], Step [544/735], Loss: 0.3318\n",
      "Epoch [36/50], Step [545/735], Loss: 0.1213\n",
      "Epoch [36/50], Step [546/735], Loss: 0.1973\n",
      "Epoch [36/50], Step [547/735], Loss: 0.5597\n",
      "Epoch [36/50], Step [548/735], Loss: 0.1162\n",
      "Epoch [36/50], Step [549/735], Loss: 0.7121\n",
      "Epoch [36/50], Step [550/735], Loss: 0.0922\n",
      "Epoch [36/50], Step [551/735], Loss: 0.1593\n",
      "Epoch [36/50], Step [552/735], Loss: 3.3880\n",
      "Epoch [36/50], Step [553/735], Loss: 0.4616\n",
      "Epoch [36/50], Step [554/735], Loss: 0.2372\n",
      "Epoch [36/50], Step [555/735], Loss: 0.3202\n",
      "Epoch [36/50], Step [556/735], Loss: 0.3486\n",
      "Epoch [36/50], Step [557/735], Loss: 0.3401\n",
      "Epoch [36/50], Step [558/735], Loss: 0.4028\n",
      "Epoch [36/50], Step [559/735], Loss: 0.3015\n",
      "Epoch [36/50], Step [560/735], Loss: 0.3497\n",
      "Epoch [36/50], Step [561/735], Loss: 0.2562\n",
      "Epoch [36/50], Step [562/735], Loss: 0.4814\n",
      "Epoch [36/50], Step [563/735], Loss: 0.1815\n",
      "Epoch [36/50], Step [564/735], Loss: 0.3797\n",
      "Epoch [36/50], Step [565/735], Loss: 0.3415\n",
      "Epoch [36/50], Step [566/735], Loss: 0.4669\n",
      "Epoch [36/50], Step [567/735], Loss: 0.3219\n",
      "Epoch [36/50], Step [568/735], Loss: 0.2622\n",
      "Epoch [36/50], Step [569/735], Loss: 0.2963\n",
      "Epoch [36/50], Step [570/735], Loss: 0.3404\n",
      "Epoch [36/50], Step [571/735], Loss: 0.1744\n",
      "Epoch [36/50], Step [572/735], Loss: 0.0988\n",
      "Epoch [36/50], Step [573/735], Loss: 0.2903\n",
      "Epoch [36/50], Step [574/735], Loss: 0.1289\n",
      "Epoch [36/50], Step [575/735], Loss: 0.0839\n",
      "Epoch [36/50], Step [576/735], Loss: 0.3748\n",
      "Epoch [36/50], Step [577/735], Loss: 0.4413\n",
      "Epoch [36/50], Step [578/735], Loss: 0.2515\n",
      "Epoch [36/50], Step [579/735], Loss: 0.3194\n",
      "Epoch [36/50], Step [580/735], Loss: 0.4475\n",
      "Epoch [36/50], Step [581/735], Loss: 0.1975\n",
      "Epoch [36/50], Step [582/735], Loss: 0.3776\n",
      "Epoch [36/50], Step [583/735], Loss: 0.1015\n",
      "Epoch [36/50], Step [584/735], Loss: 0.2671\n",
      "Epoch [36/50], Step [585/735], Loss: 0.3283\n",
      "Epoch [36/50], Step [586/735], Loss: 1.0227\n",
      "Epoch [36/50], Step [587/735], Loss: 0.2315\n",
      "Epoch [36/50], Step [588/735], Loss: 0.1764\n",
      "Epoch [36/50], Step [589/735], Loss: 0.3190\n",
      "Epoch [36/50], Step [590/735], Loss: 0.3240\n",
      "Epoch [36/50], Step [591/735], Loss: 0.5753\n",
      "Epoch [36/50], Step [592/735], Loss: 0.5761\n",
      "Epoch [36/50], Step [593/735], Loss: 0.1613\n",
      "Epoch [36/50], Step [594/735], Loss: 0.3451\n",
      "Epoch [36/50], Step [595/735], Loss: 0.3006\n",
      "Epoch [36/50], Step [596/735], Loss: 0.2740\n",
      "Epoch [36/50], Step [597/735], Loss: 0.0953\n",
      "Epoch [36/50], Step [598/735], Loss: 0.2766\n",
      "Epoch [36/50], Step [599/735], Loss: 0.2833\n",
      "Epoch [36/50], Step [600/735], Loss: 0.2381\n",
      "Epoch [36/50], Step [601/735], Loss: 0.4601\n",
      "Epoch [36/50], Step [602/735], Loss: 0.6276\n",
      "Epoch [36/50], Step [603/735], Loss: 0.1632\n",
      "Epoch [36/50], Step [604/735], Loss: 0.5802\n",
      "Epoch [36/50], Step [605/735], Loss: 0.4503\n",
      "Epoch [36/50], Step [606/735], Loss: 0.1812\n",
      "Epoch [36/50], Step [607/735], Loss: 0.1265\n",
      "Epoch [36/50], Step [608/735], Loss: 0.9250\n",
      "Epoch [36/50], Step [609/735], Loss: 0.1260\n",
      "Epoch [36/50], Step [610/735], Loss: 1.3976\n",
      "Epoch [36/50], Step [611/735], Loss: 0.3034\n",
      "Epoch [36/50], Step [612/735], Loss: 0.5300\n",
      "Epoch [36/50], Step [613/735], Loss: 0.2566\n",
      "Epoch [36/50], Step [614/735], Loss: 0.2458\n",
      "Epoch [36/50], Step [615/735], Loss: 0.4601\n",
      "Epoch [36/50], Step [616/735], Loss: 0.3481\n",
      "Epoch [36/50], Step [617/735], Loss: 0.2071\n",
      "Epoch [36/50], Step [618/735], Loss: 0.6568\n",
      "Epoch [36/50], Step [619/735], Loss: 0.9414\n",
      "Epoch [36/50], Step [620/735], Loss: 0.3763\n",
      "Epoch [36/50], Step [621/735], Loss: 0.1514\n",
      "Epoch [36/50], Step [622/735], Loss: 0.1934\n",
      "Epoch [36/50], Step [623/735], Loss: 0.1646\n",
      "Epoch [36/50], Step [624/735], Loss: 0.2724\n",
      "Epoch [36/50], Step [625/735], Loss: 0.3003\n",
      "Epoch [36/50], Step [626/735], Loss: 0.2525\n",
      "Epoch [36/50], Step [627/735], Loss: 0.1380\n",
      "Epoch [36/50], Step [628/735], Loss: 0.2186\n",
      "Epoch [36/50], Step [629/735], Loss: 0.3123\n",
      "Epoch [36/50], Step [630/735], Loss: 0.4925\n",
      "Epoch [36/50], Step [631/735], Loss: 0.2307\n",
      "Epoch [36/50], Step [632/735], Loss: 0.2204\n",
      "Epoch [36/50], Step [633/735], Loss: 0.2086\n",
      "Epoch [36/50], Step [634/735], Loss: 0.3174\n",
      "Epoch [36/50], Step [635/735], Loss: 0.3388\n",
      "Epoch [36/50], Step [636/735], Loss: 0.0905\n",
      "Epoch [36/50], Step [637/735], Loss: 0.2724\n",
      "Epoch [36/50], Step [638/735], Loss: 0.2816\n",
      "Epoch [36/50], Step [639/735], Loss: 0.3797\n",
      "Epoch [36/50], Step [640/735], Loss: 0.5659\n",
      "Epoch [36/50], Step [641/735], Loss: 0.1051\n",
      "Epoch [36/50], Step [642/735], Loss: 0.2818\n",
      "Epoch [36/50], Step [643/735], Loss: 0.3414\n",
      "Epoch [36/50], Step [644/735], Loss: 0.1360\n",
      "Epoch [36/50], Step [645/735], Loss: 0.2672\n",
      "Epoch [36/50], Step [646/735], Loss: 0.2231\n",
      "Epoch [36/50], Step [647/735], Loss: 0.4459\n",
      "Epoch [36/50], Step [648/735], Loss: 0.0842\n",
      "Epoch [36/50], Step [649/735], Loss: 0.2412\n",
      "Epoch [36/50], Step [650/735], Loss: 0.1919\n",
      "Epoch [36/50], Step [651/735], Loss: 0.2474\n",
      "Epoch [36/50], Step [652/735], Loss: 0.1780\n",
      "Epoch [36/50], Step [653/735], Loss: 0.2107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Step [654/735], Loss: 0.0933\n",
      "Epoch [36/50], Step [655/735], Loss: 0.1493\n",
      "Epoch [36/50], Step [656/735], Loss: 0.3647\n",
      "Epoch [36/50], Step [657/735], Loss: 0.1854\n",
      "Epoch [36/50], Step [658/735], Loss: 0.3959\n",
      "Epoch [36/50], Step [659/735], Loss: 0.6459\n",
      "Epoch [36/50], Step [660/735], Loss: 0.1387\n",
      "Epoch [36/50], Step [661/735], Loss: 0.1476\n",
      "Epoch [36/50], Step [662/735], Loss: 0.3324\n",
      "Epoch [36/50], Step [663/735], Loss: 0.0927\n",
      "Epoch [36/50], Step [664/735], Loss: 0.2595\n",
      "Epoch [36/50], Step [665/735], Loss: 0.0478\n",
      "Epoch [36/50], Step [666/735], Loss: 0.0625\n",
      "Epoch [36/50], Step [667/735], Loss: 0.3644\n",
      "Epoch [36/50], Step [668/735], Loss: 0.1994\n",
      "Epoch [36/50], Step [669/735], Loss: 0.0858\n",
      "Epoch [36/50], Step [670/735], Loss: 0.3257\n",
      "Epoch [36/50], Step [671/735], Loss: 0.1049\n",
      "Epoch [36/50], Step [672/735], Loss: 0.0696\n",
      "Epoch [36/50], Step [673/735], Loss: 0.1254\n",
      "Epoch [36/50], Step [674/735], Loss: 1.6229\n",
      "Epoch [36/50], Step [675/735], Loss: 0.4252\n",
      "Epoch [36/50], Step [676/735], Loss: 0.2472\n",
      "Epoch [36/50], Step [677/735], Loss: 0.3121\n",
      "Epoch [36/50], Step [678/735], Loss: 0.9400\n",
      "Epoch [36/50], Step [679/735], Loss: 0.2355\n",
      "Epoch [36/50], Step [680/735], Loss: 0.3722\n",
      "Epoch [36/50], Step [681/735], Loss: 0.1908\n",
      "Epoch [36/50], Step [682/735], Loss: 0.1388\n",
      "Epoch [36/50], Step [683/735], Loss: 0.5769\n",
      "Epoch [36/50], Step [684/735], Loss: 0.5685\n",
      "Epoch [36/50], Step [685/735], Loss: 0.4034\n",
      "Epoch [36/50], Step [686/735], Loss: 0.3775\n",
      "Epoch [36/50], Step [687/735], Loss: 0.3247\n",
      "Epoch [36/50], Step [688/735], Loss: 0.2970\n",
      "Epoch [36/50], Step [689/735], Loss: 0.1292\n",
      "Epoch [36/50], Step [690/735], Loss: 0.2774\n",
      "Epoch [36/50], Step [691/735], Loss: 0.1314\n",
      "Epoch [36/50], Step [692/735], Loss: 0.3032\n",
      "Epoch [36/50], Step [693/735], Loss: 0.5943\n",
      "Epoch [36/50], Step [694/735], Loss: 0.3798\n",
      "Epoch [36/50], Step [695/735], Loss: 0.3689\n",
      "Epoch [36/50], Step [696/735], Loss: 0.3144\n",
      "Epoch [36/50], Step [697/735], Loss: 0.4583\n",
      "Epoch [36/50], Step [698/735], Loss: 0.4954\n",
      "Epoch [36/50], Step [699/735], Loss: 0.3021\n",
      "Epoch [36/50], Step [700/735], Loss: 0.2904\n",
      "Epoch [36/50], Step [701/735], Loss: 0.3038\n",
      "Epoch [36/50], Step [702/735], Loss: 0.3421\n",
      "Epoch [36/50], Step [703/735], Loss: 0.3010\n",
      "Epoch [36/50], Step [704/735], Loss: 0.5771\n",
      "Epoch [36/50], Step [705/735], Loss: 0.2873\n",
      "Epoch [36/50], Step [706/735], Loss: 0.2127\n",
      "Epoch [36/50], Step [707/735], Loss: 0.2296\n",
      "Epoch [36/50], Step [708/735], Loss: 0.1666\n",
      "Epoch [36/50], Step [709/735], Loss: 0.4035\n",
      "Epoch [36/50], Step [710/735], Loss: 0.8323\n",
      "Epoch [36/50], Step [711/735], Loss: 0.1746\n",
      "Epoch [36/50], Step [712/735], Loss: 0.1602\n",
      "Epoch [36/50], Step [713/735], Loss: 0.8108\n",
      "Epoch [36/50], Step [714/735], Loss: 1.1156\n",
      "Epoch [36/50], Step [715/735], Loss: 0.4568\n",
      "Epoch [36/50], Step [716/735], Loss: 0.9455\n",
      "Epoch [36/50], Step [717/735], Loss: 0.3087\n",
      "Epoch [36/50], Step [718/735], Loss: 0.4255\n",
      "Epoch [36/50], Step [719/735], Loss: 0.2496\n",
      "Epoch [36/50], Step [720/735], Loss: 0.9708\n",
      "Epoch [36/50], Step [721/735], Loss: 0.2883\n",
      "Epoch [36/50], Step [722/735], Loss: 0.5917\n",
      "Epoch [36/50], Step [723/735], Loss: 0.1832\n",
      "Epoch [36/50], Step [724/735], Loss: 0.3924\n",
      "Epoch [36/50], Step [725/735], Loss: 0.5977\n",
      "Epoch [36/50], Step [726/735], Loss: 0.2896\n",
      "Epoch [36/50], Step [727/735], Loss: 0.1157\n",
      "Epoch [36/50], Step [728/735], Loss: 0.2566\n",
      "Epoch [36/50], Step [729/735], Loss: 0.3863\n",
      "Epoch [36/50], Step [730/735], Loss: 0.3998\n",
      "Epoch [36/50], Step [731/735], Loss: 0.3504\n",
      "Epoch [36/50], Step [732/735], Loss: 0.1962\n",
      "Epoch [36/50], Step [733/735], Loss: 0.1551\n",
      "Epoch [36/50], Step [734/735], Loss: 0.2353\n",
      "Epoch [36/50], Step [735/735], Loss: 0.2919\n",
      "Epoch [37/50], Step [1/735], Loss: 0.2186\n",
      "Epoch [37/50], Step [2/735], Loss: 0.0810\n",
      "Epoch [37/50], Step [3/735], Loss: 0.2827\n",
      "Epoch [37/50], Step [4/735], Loss: 0.2151\n",
      "Epoch [37/50], Step [5/735], Loss: 0.7794\n",
      "Epoch [37/50], Step [6/735], Loss: 0.1216\n",
      "Epoch [37/50], Step [7/735], Loss: 0.1305\n",
      "Epoch [37/50], Step [8/735], Loss: 0.9406\n",
      "Epoch [37/50], Step [9/735], Loss: 0.4413\n",
      "Epoch [37/50], Step [10/735], Loss: 0.3711\n",
      "Epoch [37/50], Step [11/735], Loss: 0.5845\n",
      "Epoch [37/50], Step [12/735], Loss: 0.2429\n",
      "Epoch [37/50], Step [13/735], Loss: 0.2723\n",
      "Epoch [37/50], Step [14/735], Loss: 0.1758\n",
      "Epoch [37/50], Step [15/735], Loss: 0.0972\n",
      "Epoch [37/50], Step [16/735], Loss: 0.6357\n",
      "Epoch [37/50], Step [17/735], Loss: 0.8731\n",
      "Epoch [37/50], Step [18/735], Loss: 0.1096\n",
      "Epoch [37/50], Step [19/735], Loss: 0.4477\n",
      "Epoch [37/50], Step [20/735], Loss: 0.5070\n",
      "Epoch [37/50], Step [21/735], Loss: 0.0969\n",
      "Epoch [37/50], Step [22/735], Loss: 0.1236\n",
      "Epoch [37/50], Step [23/735], Loss: 0.3667\n",
      "Epoch [37/50], Step [24/735], Loss: 0.2607\n",
      "Epoch [37/50], Step [25/735], Loss: 0.2696\n",
      "Epoch [37/50], Step [26/735], Loss: 0.3007\n",
      "Epoch [37/50], Step [27/735], Loss: 0.4377\n",
      "Epoch [37/50], Step [28/735], Loss: 0.7197\n",
      "Epoch [37/50], Step [29/735], Loss: 0.4997\n",
      "Epoch [37/50], Step [30/735], Loss: 0.3878\n",
      "Epoch [37/50], Step [31/735], Loss: 0.3099\n",
      "Epoch [37/50], Step [32/735], Loss: 0.3585\n",
      "Epoch [37/50], Step [33/735], Loss: 0.2450\n",
      "Epoch [37/50], Step [34/735], Loss: 0.2189\n",
      "Epoch [37/50], Step [35/735], Loss: 0.3302\n",
      "Epoch [37/50], Step [36/735], Loss: 0.2624\n",
      "Epoch [37/50], Step [37/735], Loss: 0.7035\n",
      "Epoch [37/50], Step [38/735], Loss: 0.1391\n",
      "Epoch [37/50], Step [39/735], Loss: 0.3496\n",
      "Epoch [37/50], Step [40/735], Loss: 0.1105\n",
      "Epoch [37/50], Step [41/735], Loss: 0.1224\n",
      "Epoch [37/50], Step [42/735], Loss: 0.0908\n",
      "Epoch [37/50], Step [43/735], Loss: 1.1855\n",
      "Epoch [37/50], Step [44/735], Loss: 0.2613\n",
      "Epoch [37/50], Step [45/735], Loss: 0.2120\n",
      "Epoch [37/50], Step [46/735], Loss: 0.3245\n",
      "Epoch [37/50], Step [47/735], Loss: 0.3432\n",
      "Epoch [37/50], Step [48/735], Loss: 0.5018\n",
      "Epoch [37/50], Step [49/735], Loss: 1.0258\n",
      "Epoch [37/50], Step [50/735], Loss: 0.1774\n",
      "Epoch [37/50], Step [51/735], Loss: 0.1991\n",
      "Epoch [37/50], Step [52/735], Loss: 0.3904\n",
      "Epoch [37/50], Step [53/735], Loss: 0.6571\n",
      "Epoch [37/50], Step [54/735], Loss: 0.3485\n",
      "Epoch [37/50], Step [55/735], Loss: 0.7889\n",
      "Epoch [37/50], Step [56/735], Loss: 0.3486\n",
      "Epoch [37/50], Step [57/735], Loss: 0.3776\n",
      "Epoch [37/50], Step [58/735], Loss: 0.2218\n",
      "Epoch [37/50], Step [59/735], Loss: 0.4459\n",
      "Epoch [37/50], Step [60/735], Loss: 0.1131\n",
      "Epoch [37/50], Step [61/735], Loss: 0.2504\n",
      "Epoch [37/50], Step [62/735], Loss: 0.1360\n",
      "Epoch [37/50], Step [63/735], Loss: 0.1852\n",
      "Epoch [37/50], Step [64/735], Loss: 0.1140\n",
      "Epoch [37/50], Step [65/735], Loss: 0.1669\n",
      "Epoch [37/50], Step [66/735], Loss: 0.1515\n",
      "Epoch [37/50], Step [67/735], Loss: 0.7624\n",
      "Epoch [37/50], Step [68/735], Loss: 0.1336\n",
      "Epoch [37/50], Step [69/735], Loss: 0.3948\n",
      "Epoch [37/50], Step [70/735], Loss: 0.2407\n",
      "Epoch [37/50], Step [71/735], Loss: 0.6210\n",
      "Epoch [37/50], Step [72/735], Loss: 0.6271\n",
      "Epoch [37/50], Step [73/735], Loss: 0.2660\n",
      "Epoch [37/50], Step [74/735], Loss: 0.4310\n",
      "Epoch [37/50], Step [75/735], Loss: 0.1029\n",
      "Epoch [37/50], Step [76/735], Loss: 0.1677\n",
      "Epoch [37/50], Step [77/735], Loss: 0.4888\n",
      "Epoch [37/50], Step [78/735], Loss: 0.1547\n",
      "Epoch [37/50], Step [79/735], Loss: 0.1366\n",
      "Epoch [37/50], Step [80/735], Loss: 0.3402\n",
      "Epoch [37/50], Step [81/735], Loss: 0.5951\n",
      "Epoch [37/50], Step [82/735], Loss: 0.2579\n",
      "Epoch [37/50], Step [83/735], Loss: 0.1102\n",
      "Epoch [37/50], Step [84/735], Loss: 0.4965\n",
      "Epoch [37/50], Step [85/735], Loss: 0.3114\n",
      "Epoch [37/50], Step [86/735], Loss: 0.9589\n",
      "Epoch [37/50], Step [87/735], Loss: 0.1077\n",
      "Epoch [37/50], Step [88/735], Loss: 0.1657\n",
      "Epoch [37/50], Step [89/735], Loss: 0.2040\n",
      "Epoch [37/50], Step [90/735], Loss: 0.6913\n",
      "Epoch [37/50], Step [91/735], Loss: 0.1793\n",
      "Epoch [37/50], Step [92/735], Loss: 0.3028\n",
      "Epoch [37/50], Step [93/735], Loss: 0.4719\n",
      "Epoch [37/50], Step [94/735], Loss: 0.2814\n",
      "Epoch [37/50], Step [95/735], Loss: 0.1481\n",
      "Epoch [37/50], Step [96/735], Loss: 0.1224\n",
      "Epoch [37/50], Step [97/735], Loss: 0.3510\n",
      "Epoch [37/50], Step [98/735], Loss: 0.2942\n",
      "Epoch [37/50], Step [99/735], Loss: 0.1340\n",
      "Epoch [37/50], Step [100/735], Loss: 0.4220\n",
      "Epoch [37/50], Step [101/735], Loss: 0.1977\n",
      "Epoch [37/50], Step [102/735], Loss: 0.7799\n",
      "Epoch [37/50], Step [103/735], Loss: 0.0729\n",
      "Epoch [37/50], Step [104/735], Loss: 0.3180\n",
      "Epoch [37/50], Step [105/735], Loss: 0.2551\n",
      "Epoch [37/50], Step [106/735], Loss: 0.1947\n",
      "Epoch [37/50], Step [107/735], Loss: 0.2560\n",
      "Epoch [37/50], Step [108/735], Loss: 0.2193\n",
      "Epoch [37/50], Step [109/735], Loss: 0.2563\n",
      "Epoch [37/50], Step [110/735], Loss: 0.3030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Step [111/735], Loss: 0.5446\n",
      "Epoch [37/50], Step [112/735], Loss: 0.3113\n",
      "Epoch [37/50], Step [113/735], Loss: 0.2536\n",
      "Epoch [37/50], Step [114/735], Loss: 0.1188\n",
      "Epoch [37/50], Step [115/735], Loss: 0.2354\n",
      "Epoch [37/50], Step [116/735], Loss: 0.6718\n",
      "Epoch [37/50], Step [117/735], Loss: 0.4048\n",
      "Epoch [37/50], Step [118/735], Loss: 0.1549\n",
      "Epoch [37/50], Step [119/735], Loss: 0.2805\n",
      "Epoch [37/50], Step [120/735], Loss: 0.1014\n",
      "Epoch [37/50], Step [121/735], Loss: 0.3164\n",
      "Epoch [37/50], Step [122/735], Loss: 0.2094\n",
      "Epoch [37/50], Step [123/735], Loss: 0.1480\n",
      "Epoch [37/50], Step [124/735], Loss: 0.1300\n",
      "Epoch [37/50], Step [125/735], Loss: 0.3076\n",
      "Epoch [37/50], Step [126/735], Loss: 0.3204\n",
      "Epoch [37/50], Step [127/735], Loss: 0.2247\n",
      "Epoch [37/50], Step [128/735], Loss: 0.1242\n",
      "Epoch [37/50], Step [129/735], Loss: 0.4623\n",
      "Epoch [37/50], Step [130/735], Loss: 0.3245\n",
      "Epoch [37/50], Step [131/735], Loss: 0.2229\n",
      "Epoch [37/50], Step [132/735], Loss: 0.1515\n",
      "Epoch [37/50], Step [133/735], Loss: 0.0608\n",
      "Epoch [37/50], Step [134/735], Loss: 0.3073\n",
      "Epoch [37/50], Step [135/735], Loss: 0.3692\n",
      "Epoch [37/50], Step [136/735], Loss: 0.3079\n",
      "Epoch [37/50], Step [137/735], Loss: 0.2322\n",
      "Epoch [37/50], Step [138/735], Loss: 0.2543\n",
      "Epoch [37/50], Step [139/735], Loss: 0.2459\n",
      "Epoch [37/50], Step [140/735], Loss: 1.5441\n",
      "Epoch [37/50], Step [141/735], Loss: 0.0989\n",
      "Epoch [37/50], Step [142/735], Loss: 0.0904\n",
      "Epoch [37/50], Step [143/735], Loss: 0.3884\n",
      "Epoch [37/50], Step [144/735], Loss: 0.2369\n",
      "Epoch [37/50], Step [145/735], Loss: 0.1178\n",
      "Epoch [37/50], Step [146/735], Loss: 0.1880\n",
      "Epoch [37/50], Step [147/735], Loss: 0.0944\n",
      "Epoch [37/50], Step [148/735], Loss: 0.2106\n",
      "Epoch [37/50], Step [149/735], Loss: 0.3313\n",
      "Epoch [37/50], Step [150/735], Loss: 0.1754\n",
      "Epoch [37/50], Step [151/735], Loss: 0.1009\n",
      "Epoch [37/50], Step [152/735], Loss: 0.5549\n",
      "Epoch [37/50], Step [153/735], Loss: 0.2751\n",
      "Epoch [37/50], Step [154/735], Loss: 1.0810\n",
      "Epoch [37/50], Step [155/735], Loss: 0.3660\n",
      "Epoch [37/50], Step [156/735], Loss: 0.1276\n",
      "Epoch [37/50], Step [157/735], Loss: 0.3655\n",
      "Epoch [37/50], Step [158/735], Loss: 0.3316\n",
      "Epoch [37/50], Step [159/735], Loss: 0.5554\n",
      "Epoch [37/50], Step [160/735], Loss: 0.4236\n",
      "Epoch [37/50], Step [161/735], Loss: 0.4269\n",
      "Epoch [37/50], Step [162/735], Loss: 0.3492\n",
      "Epoch [37/50], Step [163/735], Loss: 0.2100\n",
      "Epoch [37/50], Step [164/735], Loss: 0.0783\n",
      "Epoch [37/50], Step [165/735], Loss: 0.2432\n",
      "Epoch [37/50], Step [166/735], Loss: 0.2157\n",
      "Epoch [37/50], Step [167/735], Loss: 0.1468\n",
      "Epoch [37/50], Step [168/735], Loss: 0.2063\n",
      "Epoch [37/50], Step [169/735], Loss: 0.2617\n",
      "Epoch [37/50], Step [170/735], Loss: 0.4619\n",
      "Epoch [37/50], Step [171/735], Loss: 1.0003\n",
      "Epoch [37/50], Step [172/735], Loss: 0.2757\n",
      "Epoch [37/50], Step [173/735], Loss: 1.0191\n",
      "Epoch [37/50], Step [174/735], Loss: 0.5129\n",
      "Epoch [37/50], Step [175/735], Loss: 0.2939\n",
      "Epoch [37/50], Step [176/735], Loss: 0.0485\n",
      "Epoch [37/50], Step [177/735], Loss: 0.3107\n",
      "Epoch [37/50], Step [178/735], Loss: 0.3409\n",
      "Epoch [37/50], Step [179/735], Loss: 0.1116\n",
      "Epoch [37/50], Step [180/735], Loss: 0.3433\n",
      "Epoch [37/50], Step [181/735], Loss: 0.4635\n",
      "Epoch [37/50], Step [182/735], Loss: 0.1181\n",
      "Epoch [37/50], Step [183/735], Loss: 0.5775\n",
      "Epoch [37/50], Step [184/735], Loss: 0.4133\n",
      "Epoch [37/50], Step [185/735], Loss: 0.1535\n",
      "Epoch [37/50], Step [186/735], Loss: 0.1629\n",
      "Epoch [37/50], Step [187/735], Loss: 0.1700\n",
      "Epoch [37/50], Step [188/735], Loss: 0.0759\n",
      "Epoch [37/50], Step [189/735], Loss: 0.1296\n",
      "Epoch [37/50], Step [190/735], Loss: 0.2505\n",
      "Epoch [37/50], Step [191/735], Loss: 0.2474\n",
      "Epoch [37/50], Step [192/735], Loss: 0.8972\n",
      "Epoch [37/50], Step [193/735], Loss: 0.2693\n",
      "Epoch [37/50], Step [194/735], Loss: 0.5001\n",
      "Epoch [37/50], Step [195/735], Loss: 0.1720\n",
      "Epoch [37/50], Step [196/735], Loss: 0.4922\n",
      "Epoch [37/50], Step [197/735], Loss: 0.3800\n",
      "Epoch [37/50], Step [198/735], Loss: 0.1688\n",
      "Epoch [37/50], Step [199/735], Loss: 0.4110\n",
      "Epoch [37/50], Step [200/735], Loss: 0.1759\n",
      "Epoch [37/50], Step [201/735], Loss: 0.2986\n",
      "Epoch [37/50], Step [202/735], Loss: 0.1540\n",
      "Epoch [37/50], Step [203/735], Loss: 0.4040\n",
      "Epoch [37/50], Step [204/735], Loss: 0.2031\n",
      "Epoch [37/50], Step [205/735], Loss: 0.2452\n",
      "Epoch [37/50], Step [206/735], Loss: 0.1042\n",
      "Epoch [37/50], Step [207/735], Loss: 0.2233\n",
      "Epoch [37/50], Step [208/735], Loss: 0.2810\n",
      "Epoch [37/50], Step [209/735], Loss: 0.4263\n",
      "Epoch [37/50], Step [210/735], Loss: 0.1600\n",
      "Epoch [37/50], Step [211/735], Loss: 0.2341\n",
      "Epoch [37/50], Step [212/735], Loss: 0.1423\n",
      "Epoch [37/50], Step [213/735], Loss: 1.9653\n",
      "Epoch [37/50], Step [214/735], Loss: 0.1856\n",
      "Epoch [37/50], Step [215/735], Loss: 0.0600\n",
      "Epoch [37/50], Step [216/735], Loss: 0.3068\n",
      "Epoch [37/50], Step [217/735], Loss: 0.2083\n",
      "Epoch [37/50], Step [218/735], Loss: 0.6455\n",
      "Epoch [37/50], Step [219/735], Loss: 0.1067\n",
      "Epoch [37/50], Step [220/735], Loss: 0.1756\n",
      "Epoch [37/50], Step [221/735], Loss: 0.1556\n",
      "Epoch [37/50], Step [222/735], Loss: 0.2417\n",
      "Epoch [37/50], Step [223/735], Loss: 0.0615\n",
      "Epoch [37/50], Step [224/735], Loss: 0.8077\n",
      "Epoch [37/50], Step [225/735], Loss: 0.0494\n",
      "Epoch [37/50], Step [226/735], Loss: 0.1575\n",
      "Epoch [37/50], Step [227/735], Loss: 0.1132\n",
      "Epoch [37/50], Step [228/735], Loss: 0.3630\n",
      "Epoch [37/50], Step [229/735], Loss: 0.2524\n",
      "Epoch [37/50], Step [230/735], Loss: 0.3861\n",
      "Epoch [37/50], Step [231/735], Loss: 0.1068\n",
      "Epoch [37/50], Step [232/735], Loss: 0.2340\n",
      "Epoch [37/50], Step [233/735], Loss: 0.7114\n",
      "Epoch [37/50], Step [234/735], Loss: 0.1203\n",
      "Epoch [37/50], Step [235/735], Loss: 0.4011\n",
      "Epoch [37/50], Step [236/735], Loss: 0.0932\n",
      "Epoch [37/50], Step [237/735], Loss: 0.3693\n",
      "Epoch [37/50], Step [238/735], Loss: 0.2574\n",
      "Epoch [37/50], Step [239/735], Loss: 0.4908\n",
      "Epoch [37/50], Step [240/735], Loss: 0.0913\n",
      "Epoch [37/50], Step [241/735], Loss: 0.3067\n",
      "Epoch [37/50], Step [242/735], Loss: 0.1217\n",
      "Epoch [37/50], Step [243/735], Loss: 0.5515\n",
      "Epoch [37/50], Step [244/735], Loss: 0.0383\n",
      "Epoch [37/50], Step [245/735], Loss: 0.1594\n",
      "Epoch [37/50], Step [246/735], Loss: 0.9121\n",
      "Epoch [37/50], Step [247/735], Loss: 0.9052\n",
      "Epoch [37/50], Step [248/735], Loss: 0.1393\n",
      "Epoch [37/50], Step [249/735], Loss: 0.1050\n",
      "Epoch [37/50], Step [250/735], Loss: 0.2625\n",
      "Epoch [37/50], Step [251/735], Loss: 0.2212\n",
      "Epoch [37/50], Step [252/735], Loss: 0.1899\n",
      "Epoch [37/50], Step [253/735], Loss: 0.7947\n",
      "Epoch [37/50], Step [254/735], Loss: 0.7069\n",
      "Epoch [37/50], Step [255/735], Loss: 0.2015\n",
      "Epoch [37/50], Step [256/735], Loss: 0.2538\n",
      "Epoch [37/50], Step [257/735], Loss: 0.0803\n",
      "Epoch [37/50], Step [258/735], Loss: 0.5495\n",
      "Epoch [37/50], Step [259/735], Loss: 0.2057\n",
      "Epoch [37/50], Step [260/735], Loss: 0.4455\n",
      "Epoch [37/50], Step [261/735], Loss: 0.3075\n",
      "Epoch [37/50], Step [262/735], Loss: 0.5652\n",
      "Epoch [37/50], Step [263/735], Loss: 0.5271\n",
      "Epoch [37/50], Step [264/735], Loss: 0.1753\n",
      "Epoch [37/50], Step [265/735], Loss: 0.1864\n",
      "Epoch [37/50], Step [266/735], Loss: 0.5405\n",
      "Epoch [37/50], Step [267/735], Loss: 0.2664\n",
      "Epoch [37/50], Step [268/735], Loss: 0.1380\n",
      "Epoch [37/50], Step [269/735], Loss: 0.5115\n",
      "Epoch [37/50], Step [270/735], Loss: 0.4593\n",
      "Epoch [37/50], Step [271/735], Loss: 0.0915\n",
      "Epoch [37/50], Step [272/735], Loss: 0.2064\n",
      "Epoch [37/50], Step [273/735], Loss: 0.9188\n",
      "Epoch [37/50], Step [274/735], Loss: 0.9303\n",
      "Epoch [37/50], Step [275/735], Loss: 0.2509\n",
      "Epoch [37/50], Step [276/735], Loss: 0.3061\n",
      "Epoch [37/50], Step [277/735], Loss: 0.2123\n",
      "Epoch [37/50], Step [278/735], Loss: 0.2258\n",
      "Epoch [37/50], Step [279/735], Loss: 0.1590\n",
      "Epoch [37/50], Step [280/735], Loss: 0.1467\n",
      "Epoch [37/50], Step [281/735], Loss: 0.2931\n",
      "Epoch [37/50], Step [282/735], Loss: 0.0733\n",
      "Epoch [37/50], Step [283/735], Loss: 0.2392\n",
      "Epoch [37/50], Step [284/735], Loss: 0.1185\n",
      "Epoch [37/50], Step [285/735], Loss: 0.2352\n",
      "Epoch [37/50], Step [286/735], Loss: 0.3316\n",
      "Epoch [37/50], Step [287/735], Loss: 0.6405\n",
      "Epoch [37/50], Step [288/735], Loss: 0.3418\n",
      "Epoch [37/50], Step [289/735], Loss: 0.3198\n",
      "Epoch [37/50], Step [290/735], Loss: 0.5184\n",
      "Epoch [37/50], Step [291/735], Loss: 0.1496\n",
      "Epoch [37/50], Step [292/735], Loss: 0.3762\n",
      "Epoch [37/50], Step [293/735], Loss: 0.2608\n",
      "Epoch [37/50], Step [294/735], Loss: 0.2030\n",
      "Epoch [37/50], Step [295/735], Loss: 1.0621\n",
      "Epoch [37/50], Step [296/735], Loss: 0.1818\n",
      "Epoch [37/50], Step [297/735], Loss: 0.1549\n",
      "Epoch [37/50], Step [298/735], Loss: 0.1101\n",
      "Epoch [37/50], Step [299/735], Loss: 0.3790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Step [300/735], Loss: 0.1750\n",
      "Epoch [37/50], Step [301/735], Loss: 0.4731\n",
      "Epoch [37/50], Step [302/735], Loss: 0.2077\n",
      "Epoch [37/50], Step [303/735], Loss: 0.1014\n",
      "Epoch [37/50], Step [304/735], Loss: 0.6492\n",
      "Epoch [37/50], Step [305/735], Loss: 0.6412\n",
      "Epoch [37/50], Step [306/735], Loss: 0.2898\n",
      "Epoch [37/50], Step [307/735], Loss: 0.3978\n",
      "Epoch [37/50], Step [308/735], Loss: 0.2111\n",
      "Epoch [37/50], Step [309/735], Loss: 0.0751\n",
      "Epoch [37/50], Step [310/735], Loss: 0.1617\n",
      "Epoch [37/50], Step [311/735], Loss: 0.4346\n",
      "Epoch [37/50], Step [312/735], Loss: 0.2735\n",
      "Epoch [37/50], Step [313/735], Loss: 0.0718\n",
      "Epoch [37/50], Step [314/735], Loss: 0.6702\n",
      "Epoch [37/50], Step [315/735], Loss: 0.3350\n",
      "Epoch [37/50], Step [316/735], Loss: 0.2399\n",
      "Epoch [37/50], Step [317/735], Loss: 0.4198\n",
      "Epoch [37/50], Step [318/735], Loss: 0.9694\n",
      "Epoch [37/50], Step [319/735], Loss: 0.2761\n",
      "Epoch [37/50], Step [320/735], Loss: 0.1101\n",
      "Epoch [37/50], Step [321/735], Loss: 0.1124\n",
      "Epoch [37/50], Step [322/735], Loss: 0.2607\n",
      "Epoch [37/50], Step [323/735], Loss: 0.1070\n",
      "Epoch [37/50], Step [324/735], Loss: 0.4987\n",
      "Epoch [37/50], Step [325/735], Loss: 0.4013\n",
      "Epoch [37/50], Step [326/735], Loss: 0.4304\n",
      "Epoch [37/50], Step [327/735], Loss: 0.4822\n",
      "Epoch [37/50], Step [328/735], Loss: 0.1489\n",
      "Epoch [37/50], Step [329/735], Loss: 0.1590\n",
      "Epoch [37/50], Step [330/735], Loss: 0.3957\n",
      "Epoch [37/50], Step [331/735], Loss: 0.3300\n",
      "Epoch [37/50], Step [332/735], Loss: 0.3223\n",
      "Epoch [37/50], Step [333/735], Loss: 0.2725\n",
      "Epoch [37/50], Step [334/735], Loss: 0.1937\n",
      "Epoch [37/50], Step [335/735], Loss: 0.5491\n",
      "Epoch [37/50], Step [336/735], Loss: 0.2193\n",
      "Epoch [37/50], Step [337/735], Loss: 0.0592\n",
      "Epoch [37/50], Step [338/735], Loss: 0.2177\n",
      "Epoch [37/50], Step [339/735], Loss: 0.2140\n",
      "Epoch [37/50], Step [340/735], Loss: 0.3274\n",
      "Epoch [37/50], Step [341/735], Loss: 0.2212\n",
      "Epoch [37/50], Step [342/735], Loss: 0.7999\n",
      "Epoch [37/50], Step [343/735], Loss: 0.3474\n",
      "Epoch [37/50], Step [344/735], Loss: 0.1910\n",
      "Epoch [37/50], Step [345/735], Loss: 0.2038\n",
      "Epoch [37/50], Step [346/735], Loss: 0.3078\n",
      "Epoch [37/50], Step [347/735], Loss: 0.1950\n",
      "Epoch [37/50], Step [348/735], Loss: 0.8031\n",
      "Epoch [37/50], Step [349/735], Loss: 0.3200\n",
      "Epoch [37/50], Step [350/735], Loss: 0.2064\n",
      "Epoch [37/50], Step [351/735], Loss: 0.2491\n",
      "Epoch [37/50], Step [352/735], Loss: 0.5161\n",
      "Epoch [37/50], Step [353/735], Loss: 0.4192\n",
      "Epoch [37/50], Step [354/735], Loss: 0.0912\n",
      "Epoch [37/50], Step [355/735], Loss: 0.2429\n",
      "Epoch [37/50], Step [356/735], Loss: 0.2194\n",
      "Epoch [37/50], Step [357/735], Loss: 0.1958\n",
      "Epoch [37/50], Step [358/735], Loss: 0.3165\n",
      "Epoch [37/50], Step [359/735], Loss: 0.1091\n",
      "Epoch [37/50], Step [360/735], Loss: 0.2317\n",
      "Epoch [37/50], Step [361/735], Loss: 0.2006\n",
      "Epoch [37/50], Step [362/735], Loss: 0.3628\n",
      "Epoch [37/50], Step [363/735], Loss: 0.1289\n",
      "Epoch [37/50], Step [364/735], Loss: 1.1524\n",
      "Epoch [37/50], Step [365/735], Loss: 0.0794\n",
      "Epoch [37/50], Step [366/735], Loss: 0.1373\n",
      "Epoch [37/50], Step [367/735], Loss: 0.1915\n",
      "Epoch [37/50], Step [368/735], Loss: 0.1032\n",
      "Epoch [37/50], Step [369/735], Loss: 0.4827\n",
      "Epoch [37/50], Step [370/735], Loss: 0.1508\n",
      "Epoch [37/50], Step [371/735], Loss: 0.4958\n",
      "Epoch [37/50], Step [372/735], Loss: 0.1098\n",
      "Epoch [37/50], Step [373/735], Loss: 0.1247\n",
      "Epoch [37/50], Step [374/735], Loss: 0.0935\n",
      "Epoch [37/50], Step [375/735], Loss: 0.5768\n",
      "Epoch [37/50], Step [376/735], Loss: 0.5235\n",
      "Epoch [37/50], Step [377/735], Loss: 0.1356\n",
      "Epoch [37/50], Step [378/735], Loss: 0.2059\n",
      "Epoch [37/50], Step [379/735], Loss: 0.4420\n",
      "Epoch [37/50], Step [380/735], Loss: 0.2540\n",
      "Epoch [37/50], Step [381/735], Loss: 0.4756\n",
      "Epoch [37/50], Step [382/735], Loss: 0.1261\n",
      "Epoch [37/50], Step [383/735], Loss: 0.6017\n",
      "Epoch [37/50], Step [384/735], Loss: 0.1479\n",
      "Epoch [37/50], Step [385/735], Loss: 0.0953\n",
      "Epoch [37/50], Step [386/735], Loss: 0.8985\n",
      "Epoch [37/50], Step [387/735], Loss: 0.3002\n",
      "Epoch [37/50], Step [388/735], Loss: 0.2269\n",
      "Epoch [37/50], Step [389/735], Loss: 0.3850\n",
      "Epoch [37/50], Step [390/735], Loss: 0.4438\n",
      "Epoch [37/50], Step [391/735], Loss: 0.4685\n",
      "Epoch [37/50], Step [392/735], Loss: 0.1117\n",
      "Epoch [37/50], Step [393/735], Loss: 0.2127\n",
      "Epoch [37/50], Step [394/735], Loss: 0.5323\n",
      "Epoch [37/50], Step [395/735], Loss: 0.2274\n",
      "Epoch [37/50], Step [396/735], Loss: 0.1039\n",
      "Epoch [37/50], Step [397/735], Loss: 0.0674\n",
      "Epoch [37/50], Step [398/735], Loss: 0.2693\n",
      "Epoch [37/50], Step [399/735], Loss: 0.3031\n",
      "Epoch [37/50], Step [400/735], Loss: 3.5782\n",
      "Epoch [37/50], Step [401/735], Loss: 0.0474\n",
      "Epoch [37/50], Step [402/735], Loss: 1.0747\n",
      "Epoch [37/50], Step [403/735], Loss: 1.0686\n",
      "Epoch [37/50], Step [404/735], Loss: 0.5048\n",
      "Epoch [37/50], Step [405/735], Loss: 0.1302\n",
      "Epoch [37/50], Step [406/735], Loss: 0.2148\n",
      "Epoch [37/50], Step [407/735], Loss: 0.1302\n",
      "Epoch [37/50], Step [408/735], Loss: 0.1245\n",
      "Epoch [37/50], Step [409/735], Loss: 0.8205\n",
      "Epoch [37/50], Step [410/735], Loss: 0.1761\n",
      "Epoch [37/50], Step [411/735], Loss: 0.2666\n",
      "Epoch [37/50], Step [412/735], Loss: 0.0911\n",
      "Epoch [37/50], Step [413/735], Loss: 0.5932\n",
      "Epoch [37/50], Step [414/735], Loss: 0.0851\n",
      "Epoch [37/50], Step [415/735], Loss: 0.0704\n",
      "Epoch [37/50], Step [416/735], Loss: 0.1365\n",
      "Epoch [37/50], Step [417/735], Loss: 0.2564\n",
      "Epoch [37/50], Step [418/735], Loss: 0.4045\n",
      "Epoch [37/50], Step [419/735], Loss: 0.3753\n",
      "Epoch [37/50], Step [420/735], Loss: 0.4954\n",
      "Epoch [37/50], Step [421/735], Loss: 0.5894\n",
      "Epoch [37/50], Step [422/735], Loss: 1.3470\n",
      "Epoch [37/50], Step [423/735], Loss: 0.3704\n",
      "Epoch [37/50], Step [424/735], Loss: 0.2424\n",
      "Epoch [37/50], Step [425/735], Loss: 0.3795\n",
      "Epoch [37/50], Step [426/735], Loss: 0.4048\n",
      "Epoch [37/50], Step [427/735], Loss: 0.1673\n",
      "Epoch [37/50], Step [428/735], Loss: 0.2387\n",
      "Epoch [37/50], Step [429/735], Loss: 0.0847\n",
      "Epoch [37/50], Step [430/735], Loss: 0.3744\n",
      "Epoch [37/50], Step [431/735], Loss: 0.1310\n",
      "Epoch [37/50], Step [432/735], Loss: 0.1892\n",
      "Epoch [37/50], Step [433/735], Loss: 0.2228\n",
      "Epoch [37/50], Step [434/735], Loss: 0.1821\n",
      "Epoch [37/50], Step [435/735], Loss: 0.2719\n",
      "Epoch [37/50], Step [436/735], Loss: 0.4471\n",
      "Epoch [37/50], Step [437/735], Loss: 0.2496\n",
      "Epoch [37/50], Step [438/735], Loss: 0.1668\n",
      "Epoch [37/50], Step [439/735], Loss: 0.2160\n",
      "Epoch [37/50], Step [440/735], Loss: 0.2437\n",
      "Epoch [37/50], Step [441/735], Loss: 0.1426\n",
      "Epoch [37/50], Step [442/735], Loss: 0.8117\n",
      "Epoch [37/50], Step [443/735], Loss: 0.2090\n",
      "Epoch [37/50], Step [444/735], Loss: 0.4464\n",
      "Epoch [37/50], Step [445/735], Loss: 0.1425\n",
      "Epoch [37/50], Step [446/735], Loss: 0.1481\n",
      "Epoch [37/50], Step [447/735], Loss: 0.2260\n",
      "Epoch [37/50], Step [448/735], Loss: 0.2122\n",
      "Epoch [37/50], Step [449/735], Loss: 0.6855\n",
      "Epoch [37/50], Step [450/735], Loss: 0.4992\n",
      "Epoch [37/50], Step [451/735], Loss: 0.3870\n",
      "Epoch [37/50], Step [452/735], Loss: 0.7506\n",
      "Epoch [37/50], Step [453/735], Loss: 0.2817\n",
      "Epoch [37/50], Step [454/735], Loss: 0.5054\n",
      "Epoch [37/50], Step [455/735], Loss: 0.0882\n",
      "Epoch [37/50], Step [456/735], Loss: 0.3309\n",
      "Epoch [37/50], Step [457/735], Loss: 0.1982\n",
      "Epoch [37/50], Step [458/735], Loss: 0.4452\n",
      "Epoch [37/50], Step [459/735], Loss: 0.2478\n",
      "Epoch [37/50], Step [460/735], Loss: 0.6303\n",
      "Epoch [37/50], Step [461/735], Loss: 0.2370\n",
      "Epoch [37/50], Step [462/735], Loss: 0.5684\n",
      "Epoch [37/50], Step [463/735], Loss: 0.4580\n",
      "Epoch [37/50], Step [464/735], Loss: 0.2761\n",
      "Epoch [37/50], Step [465/735], Loss: 4.1131\n",
      "Epoch [37/50], Step [466/735], Loss: 0.1743\n",
      "Epoch [37/50], Step [467/735], Loss: 0.5824\n",
      "Epoch [37/50], Step [468/735], Loss: 0.1295\n",
      "Epoch [37/50], Step [469/735], Loss: 0.2717\n",
      "Epoch [37/50], Step [470/735], Loss: 0.2083\n",
      "Epoch [37/50], Step [471/735], Loss: 0.3304\n",
      "Epoch [37/50], Step [472/735], Loss: 0.4300\n",
      "Epoch [37/50], Step [473/735], Loss: 0.2361\n",
      "Epoch [37/50], Step [474/735], Loss: 0.4280\n",
      "Epoch [37/50], Step [475/735], Loss: 0.2446\n",
      "Epoch [37/50], Step [476/735], Loss: 0.2250\n",
      "Epoch [37/50], Step [477/735], Loss: 0.0445\n",
      "Epoch [37/50], Step [478/735], Loss: 0.2037\n",
      "Epoch [37/50], Step [479/735], Loss: 0.4124\n",
      "Epoch [37/50], Step [480/735], Loss: 0.1850\n",
      "Epoch [37/50], Step [481/735], Loss: 0.4472\n",
      "Epoch [37/50], Step [482/735], Loss: 0.1984\n",
      "Epoch [37/50], Step [483/735], Loss: 0.2448\n",
      "Epoch [37/50], Step [484/735], Loss: 0.2547\n",
      "Epoch [37/50], Step [485/735], Loss: 0.2370\n",
      "Epoch [37/50], Step [486/735], Loss: 0.2533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Step [487/735], Loss: 0.2002\n",
      "Epoch [37/50], Step [488/735], Loss: 0.2174\n",
      "Epoch [37/50], Step [489/735], Loss: 0.3114\n",
      "Epoch [37/50], Step [490/735], Loss: 0.4198\n",
      "Epoch [37/50], Step [491/735], Loss: 0.1008\n",
      "Epoch [37/50], Step [492/735], Loss: 0.0512\n",
      "Epoch [37/50], Step [493/735], Loss: 0.6552\n",
      "Epoch [37/50], Step [494/735], Loss: 0.1966\n",
      "Epoch [37/50], Step [495/735], Loss: 0.2164\n",
      "Epoch [37/50], Step [496/735], Loss: 0.4408\n",
      "Epoch [37/50], Step [497/735], Loss: 0.3624\n",
      "Epoch [37/50], Step [498/735], Loss: 0.2668\n",
      "Epoch [37/50], Step [499/735], Loss: 0.5432\n",
      "Epoch [37/50], Step [500/735], Loss: 0.2629\n",
      "Epoch [37/50], Step [501/735], Loss: 0.2383\n",
      "Epoch [37/50], Step [502/735], Loss: 0.3665\n",
      "Epoch [37/50], Step [503/735], Loss: 0.3491\n",
      "Epoch [37/50], Step [504/735], Loss: 0.6707\n",
      "Epoch [37/50], Step [505/735], Loss: 0.2881\n",
      "Epoch [37/50], Step [506/735], Loss: 0.2833\n",
      "Epoch [37/50], Step [507/735], Loss: 0.1042\n",
      "Epoch [37/50], Step [508/735], Loss: 0.1209\n",
      "Epoch [37/50], Step [509/735], Loss: 0.4050\n",
      "Epoch [37/50], Step [510/735], Loss: 0.4139\n",
      "Epoch [37/50], Step [511/735], Loss: 0.0546\n",
      "Epoch [37/50], Step [512/735], Loss: 0.2072\n",
      "Epoch [37/50], Step [513/735], Loss: 0.0967\n",
      "Epoch [37/50], Step [514/735], Loss: 0.3607\n",
      "Epoch [37/50], Step [515/735], Loss: 0.6305\n",
      "Epoch [37/50], Step [516/735], Loss: 0.3628\n",
      "Epoch [37/50], Step [517/735], Loss: 3.3283\n",
      "Epoch [37/50], Step [518/735], Loss: 0.3106\n",
      "Epoch [37/50], Step [519/735], Loss: 0.5264\n",
      "Epoch [37/50], Step [520/735], Loss: 0.3682\n",
      "Epoch [37/50], Step [521/735], Loss: 0.0985\n",
      "Epoch [37/50], Step [522/735], Loss: 0.4409\n",
      "Epoch [37/50], Step [523/735], Loss: 0.2569\n",
      "Epoch [37/50], Step [524/735], Loss: 0.2698\n",
      "Epoch [37/50], Step [525/735], Loss: 0.5223\n",
      "Epoch [37/50], Step [526/735], Loss: 0.1690\n",
      "Epoch [37/50], Step [527/735], Loss: 0.3113\n",
      "Epoch [37/50], Step [528/735], Loss: 0.2452\n",
      "Epoch [37/50], Step [529/735], Loss: 0.5188\n",
      "Epoch [37/50], Step [530/735], Loss: 0.3725\n",
      "Epoch [37/50], Step [531/735], Loss: 0.0983\n",
      "Epoch [37/50], Step [532/735], Loss: 0.3517\n",
      "Epoch [37/50], Step [533/735], Loss: 0.1087\n",
      "Epoch [37/50], Step [534/735], Loss: 0.2253\n",
      "Epoch [37/50], Step [535/735], Loss: 0.4409\n",
      "Epoch [37/50], Step [536/735], Loss: 0.0858\n",
      "Epoch [37/50], Step [537/735], Loss: 0.0721\n",
      "Epoch [37/50], Step [538/735], Loss: 0.1832\n",
      "Epoch [37/50], Step [539/735], Loss: 0.1797\n",
      "Epoch [37/50], Step [540/735], Loss: 0.5308\n",
      "Epoch [37/50], Step [541/735], Loss: 0.7973\n",
      "Epoch [37/50], Step [542/735], Loss: 0.0740\n",
      "Epoch [37/50], Step [543/735], Loss: 0.9034\n",
      "Epoch [37/50], Step [544/735], Loss: 0.3009\n",
      "Epoch [37/50], Step [545/735], Loss: 0.2032\n",
      "Epoch [37/50], Step [546/735], Loss: 0.2847\n",
      "Epoch [37/50], Step [547/735], Loss: 0.3648\n",
      "Epoch [37/50], Step [548/735], Loss: 0.5069\n",
      "Epoch [37/50], Step [549/735], Loss: 0.1770\n",
      "Epoch [37/50], Step [550/735], Loss: 0.5027\n",
      "Epoch [37/50], Step [551/735], Loss: 0.3879\n",
      "Epoch [37/50], Step [552/735], Loss: 0.0985\n",
      "Epoch [37/50], Step [553/735], Loss: 0.5668\n",
      "Epoch [37/50], Step [554/735], Loss: 0.1414\n",
      "Epoch [37/50], Step [555/735], Loss: 0.2826\n",
      "Epoch [37/50], Step [556/735], Loss: 0.1775\n",
      "Epoch [37/50], Step [557/735], Loss: 0.1801\n",
      "Epoch [37/50], Step [558/735], Loss: 1.4634\n",
      "Epoch [37/50], Step [559/735], Loss: 0.3468\n",
      "Epoch [37/50], Step [560/735], Loss: 0.1965\n",
      "Epoch [37/50], Step [561/735], Loss: 0.3129\n",
      "Epoch [37/50], Step [562/735], Loss: 1.0263\n",
      "Epoch [37/50], Step [563/735], Loss: 1.1499\n",
      "Epoch [37/50], Step [564/735], Loss: 0.0870\n",
      "Epoch [37/50], Step [565/735], Loss: 0.2656\n",
      "Epoch [37/50], Step [566/735], Loss: 0.2563\n",
      "Epoch [37/50], Step [567/735], Loss: 0.2220\n",
      "Epoch [37/50], Step [568/735], Loss: 0.3356\n",
      "Epoch [37/50], Step [569/735], Loss: 0.1725\n",
      "Epoch [37/50], Step [570/735], Loss: 1.2760\n",
      "Epoch [37/50], Step [571/735], Loss: 0.2804\n",
      "Epoch [37/50], Step [572/735], Loss: 0.2265\n",
      "Epoch [37/50], Step [573/735], Loss: 0.1331\n",
      "Epoch [37/50], Step [574/735], Loss: 0.3401\n",
      "Epoch [37/50], Step [575/735], Loss: 0.0862\n",
      "Epoch [37/50], Step [576/735], Loss: 0.1233\n",
      "Epoch [37/50], Step [577/735], Loss: 0.4493\n",
      "Epoch [37/50], Step [578/735], Loss: 0.1517\n",
      "Epoch [37/50], Step [579/735], Loss: 0.1705\n",
      "Epoch [37/50], Step [580/735], Loss: 0.2825\n",
      "Epoch [37/50], Step [581/735], Loss: 0.1402\n",
      "Epoch [37/50], Step [582/735], Loss: 0.1412\n",
      "Epoch [37/50], Step [583/735], Loss: 0.2768\n",
      "Epoch [37/50], Step [584/735], Loss: 0.3039\n",
      "Epoch [37/50], Step [585/735], Loss: 0.2386\n",
      "Epoch [37/50], Step [586/735], Loss: 0.3261\n",
      "Epoch [37/50], Step [587/735], Loss: 0.2584\n",
      "Epoch [37/50], Step [588/735], Loss: 0.3607\n",
      "Epoch [37/50], Step [589/735], Loss: 0.3603\n",
      "Epoch [37/50], Step [590/735], Loss: 0.2374\n",
      "Epoch [37/50], Step [591/735], Loss: 0.1781\n",
      "Epoch [37/50], Step [592/735], Loss: 0.2536\n",
      "Epoch [37/50], Step [593/735], Loss: 0.1329\n",
      "Epoch [37/50], Step [594/735], Loss: 0.1380\n",
      "Epoch [37/50], Step [595/735], Loss: 0.4061\n",
      "Epoch [37/50], Step [596/735], Loss: 0.2498\n",
      "Epoch [37/50], Step [597/735], Loss: 0.4177\n",
      "Epoch [37/50], Step [598/735], Loss: 0.1290\n",
      "Epoch [37/50], Step [599/735], Loss: 0.1369\n",
      "Epoch [37/50], Step [600/735], Loss: 0.2639\n",
      "Epoch [37/50], Step [601/735], Loss: 0.3238\n",
      "Epoch [37/50], Step [602/735], Loss: 0.2430\n",
      "Epoch [37/50], Step [603/735], Loss: 0.8577\n",
      "Epoch [37/50], Step [604/735], Loss: 0.0890\n",
      "Epoch [37/50], Step [605/735], Loss: 0.0832\n",
      "Epoch [37/50], Step [606/735], Loss: 0.1212\n",
      "Epoch [37/50], Step [607/735], Loss: 0.3537\n",
      "Epoch [37/50], Step [608/735], Loss: 0.1704\n",
      "Epoch [37/50], Step [609/735], Loss: 0.1296\n",
      "Epoch [37/50], Step [610/735], Loss: 0.2907\n",
      "Epoch [37/50], Step [611/735], Loss: 0.1098\n",
      "Epoch [37/50], Step [612/735], Loss: 0.3051\n",
      "Epoch [37/50], Step [613/735], Loss: 0.0465\n",
      "Epoch [37/50], Step [614/735], Loss: 0.0771\n",
      "Epoch [37/50], Step [615/735], Loss: 0.2214\n",
      "Epoch [37/50], Step [616/735], Loss: 0.2766\n",
      "Epoch [37/50], Step [617/735], Loss: 0.2824\n",
      "Epoch [37/50], Step [618/735], Loss: 0.2608\n",
      "Epoch [37/50], Step [619/735], Loss: 0.1263\n",
      "Epoch [37/50], Step [620/735], Loss: 0.3372\n",
      "Epoch [37/50], Step [621/735], Loss: 0.1854\n",
      "Epoch [37/50], Step [622/735], Loss: 0.2967\n",
      "Epoch [37/50], Step [623/735], Loss: 0.0779\n",
      "Epoch [37/50], Step [624/735], Loss: 0.3161\n",
      "Epoch [37/50], Step [625/735], Loss: 0.1189\n",
      "Epoch [37/50], Step [626/735], Loss: 0.0982\n",
      "Epoch [37/50], Step [627/735], Loss: 0.1052\n",
      "Epoch [37/50], Step [628/735], Loss: 0.7787\n",
      "Epoch [37/50], Step [629/735], Loss: 0.1358\n",
      "Epoch [37/50], Step [630/735], Loss: 0.2194\n",
      "Epoch [37/50], Step [631/735], Loss: 0.2253\n",
      "Epoch [37/50], Step [632/735], Loss: 0.3324\n",
      "Epoch [37/50], Step [633/735], Loss: 0.1939\n",
      "Epoch [37/50], Step [634/735], Loss: 0.7094\n",
      "Epoch [37/50], Step [635/735], Loss: 0.9671\n",
      "Epoch [37/50], Step [636/735], Loss: 0.1736\n",
      "Epoch [37/50], Step [637/735], Loss: 0.6088\n",
      "Epoch [37/50], Step [638/735], Loss: 0.3484\n",
      "Epoch [37/50], Step [639/735], Loss: 0.3472\n",
      "Epoch [37/50], Step [640/735], Loss: 0.5387\n",
      "Epoch [37/50], Step [641/735], Loss: 0.3491\n",
      "Epoch [37/50], Step [642/735], Loss: 0.2340\n",
      "Epoch [37/50], Step [643/735], Loss: 0.0787\n",
      "Epoch [37/50], Step [644/735], Loss: 0.1354\n",
      "Epoch [37/50], Step [645/735], Loss: 0.1894\n",
      "Epoch [37/50], Step [646/735], Loss: 0.3307\n",
      "Epoch [37/50], Step [647/735], Loss: 0.5942\n",
      "Epoch [37/50], Step [648/735], Loss: 0.3455\n",
      "Epoch [37/50], Step [649/735], Loss: 0.1966\n",
      "Epoch [37/50], Step [650/735], Loss: 0.2939\n",
      "Epoch [37/50], Step [651/735], Loss: 0.2031\n",
      "Epoch [37/50], Step [652/735], Loss: 0.1536\n",
      "Epoch [37/50], Step [653/735], Loss: 0.3608\n",
      "Epoch [37/50], Step [654/735], Loss: 0.3506\n",
      "Epoch [37/50], Step [655/735], Loss: 0.7838\n",
      "Epoch [37/50], Step [656/735], Loss: 0.2543\n",
      "Epoch [37/50], Step [657/735], Loss: 0.5749\n",
      "Epoch [37/50], Step [658/735], Loss: 0.2478\n",
      "Epoch [37/50], Step [659/735], Loss: 0.4004\n",
      "Epoch [37/50], Step [660/735], Loss: 0.1872\n",
      "Epoch [37/50], Step [661/735], Loss: 0.1842\n",
      "Epoch [37/50], Step [662/735], Loss: 0.3035\n",
      "Epoch [37/50], Step [663/735], Loss: 0.6621\n",
      "Epoch [37/50], Step [664/735], Loss: 0.1427\n",
      "Epoch [37/50], Step [665/735], Loss: 0.2543\n",
      "Epoch [37/50], Step [666/735], Loss: 0.4068\n",
      "Epoch [37/50], Step [667/735], Loss: 0.1101\n",
      "Epoch [37/50], Step [668/735], Loss: 0.5377\n",
      "Epoch [37/50], Step [669/735], Loss: 1.1652\n",
      "Epoch [37/50], Step [670/735], Loss: 0.6457\n",
      "Epoch [37/50], Step [671/735], Loss: 0.5376\n",
      "Epoch [37/50], Step [672/735], Loss: 0.4788\n",
      "Epoch [37/50], Step [673/735], Loss: 0.2438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Step [674/735], Loss: 0.3077\n",
      "Epoch [37/50], Step [675/735], Loss: 0.4096\n",
      "Epoch [37/50], Step [676/735], Loss: 0.1430\n",
      "Epoch [37/50], Step [677/735], Loss: 0.1385\n",
      "Epoch [37/50], Step [678/735], Loss: 1.0705\n",
      "Epoch [37/50], Step [679/735], Loss: 0.2428\n",
      "Epoch [37/50], Step [680/735], Loss: 0.1854\n",
      "Epoch [37/50], Step [681/735], Loss: 0.3580\n",
      "Epoch [37/50], Step [682/735], Loss: 0.2240\n",
      "Epoch [37/50], Step [683/735], Loss: 4.3978\n",
      "Epoch [37/50], Step [684/735], Loss: 0.2505\n",
      "Epoch [37/50], Step [685/735], Loss: 0.0841\n",
      "Epoch [37/50], Step [686/735], Loss: 0.4037\n",
      "Epoch [37/50], Step [687/735], Loss: 0.3035\n",
      "Epoch [37/50], Step [688/735], Loss: 0.2149\n",
      "Epoch [37/50], Step [689/735], Loss: 0.2072\n",
      "Epoch [37/50], Step [690/735], Loss: 0.2285\n",
      "Epoch [37/50], Step [691/735], Loss: 0.2145\n",
      "Epoch [37/50], Step [692/735], Loss: 0.1245\n",
      "Epoch [37/50], Step [693/735], Loss: 0.1839\n",
      "Epoch [37/50], Step [694/735], Loss: 0.2013\n",
      "Epoch [37/50], Step [695/735], Loss: 0.2688\n",
      "Epoch [37/50], Step [696/735], Loss: 0.0767\n",
      "Epoch [37/50], Step [697/735], Loss: 0.2996\n",
      "Epoch [37/50], Step [698/735], Loss: 0.2536\n",
      "Epoch [37/50], Step [699/735], Loss: 0.0739\n",
      "Epoch [37/50], Step [700/735], Loss: 0.4542\n",
      "Epoch [37/50], Step [701/735], Loss: 0.3726\n",
      "Epoch [37/50], Step [702/735], Loss: 0.3086\n",
      "Epoch [37/50], Step [703/735], Loss: 0.1060\n",
      "Epoch [37/50], Step [704/735], Loss: 0.9537\n",
      "Epoch [37/50], Step [705/735], Loss: 0.3173\n",
      "Epoch [37/50], Step [706/735], Loss: 0.2718\n",
      "Epoch [37/50], Step [707/735], Loss: 0.1920\n",
      "Epoch [37/50], Step [708/735], Loss: 0.5168\n",
      "Epoch [37/50], Step [709/735], Loss: 0.1149\n",
      "Epoch [37/50], Step [710/735], Loss: 0.3050\n",
      "Epoch [37/50], Step [711/735], Loss: 0.2569\n",
      "Epoch [37/50], Step [712/735], Loss: 0.3401\n",
      "Epoch [37/50], Step [713/735], Loss: 0.4217\n",
      "Epoch [37/50], Step [714/735], Loss: 0.6386\n",
      "Epoch [37/50], Step [715/735], Loss: 0.1336\n",
      "Epoch [37/50], Step [716/735], Loss: 4.2796\n",
      "Epoch [37/50], Step [717/735], Loss: 0.1790\n",
      "Epoch [37/50], Step [718/735], Loss: 0.2518\n",
      "Epoch [37/50], Step [719/735], Loss: 0.1024\n",
      "Epoch [37/50], Step [720/735], Loss: 0.0908\n",
      "Epoch [37/50], Step [721/735], Loss: 0.2266\n",
      "Epoch [37/50], Step [722/735], Loss: 0.2041\n",
      "Epoch [37/50], Step [723/735], Loss: 0.3166\n",
      "Epoch [37/50], Step [724/735], Loss: 0.4041\n",
      "Epoch [37/50], Step [725/735], Loss: 0.3934\n",
      "Epoch [37/50], Step [726/735], Loss: 0.1178\n",
      "Epoch [37/50], Step [727/735], Loss: 0.1615\n",
      "Epoch [37/50], Step [728/735], Loss: 0.3476\n",
      "Epoch [37/50], Step [729/735], Loss: 0.2104\n",
      "Epoch [37/50], Step [730/735], Loss: 0.1787\n",
      "Epoch [37/50], Step [731/735], Loss: 0.2720\n",
      "Epoch [37/50], Step [732/735], Loss: 0.3833\n",
      "Epoch [37/50], Step [733/735], Loss: 0.1933\n",
      "Epoch [37/50], Step [734/735], Loss: 0.2374\n",
      "Epoch [37/50], Step [735/735], Loss: 0.1933\n",
      "Epoch [38/50], Step [1/735], Loss: 0.2854\n",
      "Epoch [38/50], Step [2/735], Loss: 0.6541\n",
      "Epoch [38/50], Step [3/735], Loss: 0.1128\n",
      "Epoch [38/50], Step [4/735], Loss: 0.0389\n",
      "Epoch [38/50], Step [5/735], Loss: 0.4227\n",
      "Epoch [38/50], Step [6/735], Loss: 0.1313\n",
      "Epoch [38/50], Step [7/735], Loss: 0.1053\n",
      "Epoch [38/50], Step [8/735], Loss: 0.1170\n",
      "Epoch [38/50], Step [9/735], Loss: 0.0982\n",
      "Epoch [38/50], Step [10/735], Loss: 0.2026\n",
      "Epoch [38/50], Step [11/735], Loss: 0.2534\n",
      "Epoch [38/50], Step [12/735], Loss: 0.3574\n",
      "Epoch [38/50], Step [13/735], Loss: 0.8883\n",
      "Epoch [38/50], Step [14/735], Loss: 0.0893\n",
      "Epoch [38/50], Step [15/735], Loss: 0.0281\n",
      "Epoch [38/50], Step [16/735], Loss: 0.2857\n",
      "Epoch [38/50], Step [17/735], Loss: 0.6572\n",
      "Epoch [38/50], Step [18/735], Loss: 0.0833\n",
      "Epoch [38/50], Step [19/735], Loss: 0.1042\n",
      "Epoch [38/50], Step [20/735], Loss: 0.2286\n",
      "Epoch [38/50], Step [21/735], Loss: 0.1698\n",
      "Epoch [38/50], Step [22/735], Loss: 0.1460\n",
      "Epoch [38/50], Step [23/735], Loss: 0.2279\n",
      "Epoch [38/50], Step [24/735], Loss: 0.9432\n",
      "Epoch [38/50], Step [25/735], Loss: 0.6813\n",
      "Epoch [38/50], Step [26/735], Loss: 0.2405\n",
      "Epoch [38/50], Step [27/735], Loss: 0.4615\n",
      "Epoch [38/50], Step [28/735], Loss: 0.2841\n",
      "Epoch [38/50], Step [29/735], Loss: 0.3954\n",
      "Epoch [38/50], Step [30/735], Loss: 0.3460\n",
      "Epoch [38/50], Step [31/735], Loss: 0.2736\n",
      "Epoch [38/50], Step [32/735], Loss: 0.2404\n",
      "Epoch [38/50], Step [33/735], Loss: 0.1229\n",
      "Epoch [38/50], Step [34/735], Loss: 0.1556\n",
      "Epoch [38/50], Step [35/735], Loss: 0.2691\n",
      "Epoch [38/50], Step [36/735], Loss: 0.2254\n",
      "Epoch [38/50], Step [37/735], Loss: 0.4171\n",
      "Epoch [38/50], Step [38/735], Loss: 1.6351\n",
      "Epoch [38/50], Step [39/735], Loss: 0.2510\n",
      "Epoch [38/50], Step [40/735], Loss: 0.3606\n",
      "Epoch [38/50], Step [41/735], Loss: 0.1632\n",
      "Epoch [38/50], Step [42/735], Loss: 0.1880\n",
      "Epoch [38/50], Step [43/735], Loss: 0.2046\n",
      "Epoch [38/50], Step [44/735], Loss: 0.1149\n",
      "Epoch [38/50], Step [45/735], Loss: 0.3083\n",
      "Epoch [38/50], Step [46/735], Loss: 0.1881\n",
      "Epoch [38/50], Step [47/735], Loss: 0.3692\n",
      "Epoch [38/50], Step [48/735], Loss: 0.3050\n",
      "Epoch [38/50], Step [49/735], Loss: 0.2342\n",
      "Epoch [38/50], Step [50/735], Loss: 0.1442\n",
      "Epoch [38/50], Step [51/735], Loss: 0.3111\n",
      "Epoch [38/50], Step [52/735], Loss: 0.3802\n",
      "Epoch [38/50], Step [53/735], Loss: 0.5272\n",
      "Epoch [38/50], Step [54/735], Loss: 0.2356\n",
      "Epoch [38/50], Step [55/735], Loss: 0.1261\n",
      "Epoch [38/50], Step [56/735], Loss: 0.9083\n",
      "Epoch [38/50], Step [57/735], Loss: 0.1872\n",
      "Epoch [38/50], Step [58/735], Loss: 0.6233\n",
      "Epoch [38/50], Step [59/735], Loss: 0.5212\n",
      "Epoch [38/50], Step [60/735], Loss: 0.2884\n",
      "Epoch [38/50], Step [61/735], Loss: 0.0994\n",
      "Epoch [38/50], Step [62/735], Loss: 0.4280\n",
      "Epoch [38/50], Step [63/735], Loss: 0.2229\n",
      "Epoch [38/50], Step [64/735], Loss: 0.4480\n",
      "Epoch [38/50], Step [65/735], Loss: 0.2586\n",
      "Epoch [38/50], Step [66/735], Loss: 0.2905\n",
      "Epoch [38/50], Step [67/735], Loss: 0.3359\n",
      "Epoch [38/50], Step [68/735], Loss: 0.6734\n",
      "Epoch [38/50], Step [69/735], Loss: 0.2907\n",
      "Epoch [38/50], Step [70/735], Loss: 0.1750\n",
      "Epoch [38/50], Step [71/735], Loss: 0.3298\n",
      "Epoch [38/50], Step [72/735], Loss: 0.1751\n",
      "Epoch [38/50], Step [73/735], Loss: 0.2235\n",
      "Epoch [38/50], Step [74/735], Loss: 0.5787\n",
      "Epoch [38/50], Step [75/735], Loss: 0.1276\n",
      "Epoch [38/50], Step [76/735], Loss: 0.4361\n",
      "Epoch [38/50], Step [77/735], Loss: 0.6242\n",
      "Epoch [38/50], Step [78/735], Loss: 0.2363\n",
      "Epoch [38/50], Step [79/735], Loss: 0.2055\n",
      "Epoch [38/50], Step [80/735], Loss: 0.2874\n",
      "Epoch [38/50], Step [81/735], Loss: 0.1969\n",
      "Epoch [38/50], Step [82/735], Loss: 0.1489\n",
      "Epoch [38/50], Step [83/735], Loss: 0.1947\n",
      "Epoch [38/50], Step [84/735], Loss: 0.4661\n",
      "Epoch [38/50], Step [85/735], Loss: 0.3581\n",
      "Epoch [38/50], Step [86/735], Loss: 0.4553\n",
      "Epoch [38/50], Step [87/735], Loss: 1.0831\n",
      "Epoch [38/50], Step [88/735], Loss: 0.2214\n",
      "Epoch [38/50], Step [89/735], Loss: 0.1282\n",
      "Epoch [38/50], Step [90/735], Loss: 0.3881\n",
      "Epoch [38/50], Step [91/735], Loss: 0.2134\n",
      "Epoch [38/50], Step [92/735], Loss: 0.2751\n",
      "Epoch [38/50], Step [93/735], Loss: 0.3625\n",
      "Epoch [38/50], Step [94/735], Loss: 0.5984\n",
      "Epoch [38/50], Step [95/735], Loss: 0.2184\n",
      "Epoch [38/50], Step [96/735], Loss: 0.4210\n",
      "Epoch [38/50], Step [97/735], Loss: 0.2256\n",
      "Epoch [38/50], Step [98/735], Loss: 0.7656\n",
      "Epoch [38/50], Step [99/735], Loss: 0.4170\n",
      "Epoch [38/50], Step [100/735], Loss: 0.1519\n",
      "Epoch [38/50], Step [101/735], Loss: 0.3234\n",
      "Epoch [38/50], Step [102/735], Loss: 0.1119\n",
      "Epoch [38/50], Step [103/735], Loss: 0.1290\n",
      "Epoch [38/50], Step [104/735], Loss: 0.3129\n",
      "Epoch [38/50], Step [105/735], Loss: 0.5214\n",
      "Epoch [38/50], Step [106/735], Loss: 0.2997\n",
      "Epoch [38/50], Step [107/735], Loss: 0.8633\n",
      "Epoch [38/50], Step [108/735], Loss: 0.1222\n",
      "Epoch [38/50], Step [109/735], Loss: 0.4618\n",
      "Epoch [38/50], Step [110/735], Loss: 0.2549\n",
      "Epoch [38/50], Step [111/735], Loss: 0.1697\n",
      "Epoch [38/50], Step [112/735], Loss: 0.3253\n",
      "Epoch [38/50], Step [113/735], Loss: 0.2596\n",
      "Epoch [38/50], Step [114/735], Loss: 0.2480\n",
      "Epoch [38/50], Step [115/735], Loss: 0.3198\n",
      "Epoch [38/50], Step [116/735], Loss: 0.4651\n",
      "Epoch [38/50], Step [117/735], Loss: 0.4870\n",
      "Epoch [38/50], Step [118/735], Loss: 0.3039\n",
      "Epoch [38/50], Step [119/735], Loss: 0.1397\n",
      "Epoch [38/50], Step [120/735], Loss: 0.1517\n",
      "Epoch [38/50], Step [121/735], Loss: 0.0634\n",
      "Epoch [38/50], Step [122/735], Loss: 0.2572\n",
      "Epoch [38/50], Step [123/735], Loss: 0.5524\n",
      "Epoch [38/50], Step [124/735], Loss: 0.0708\n",
      "Epoch [38/50], Step [125/735], Loss: 0.2180\n",
      "Epoch [38/50], Step [126/735], Loss: 0.0686\n",
      "Epoch [38/50], Step [127/735], Loss: 0.2194\n",
      "Epoch [38/50], Step [128/735], Loss: 0.2268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Step [129/735], Loss: 0.3821\n",
      "Epoch [38/50], Step [130/735], Loss: 0.3540\n",
      "Epoch [38/50], Step [131/735], Loss: 0.1495\n",
      "Epoch [38/50], Step [132/735], Loss: 0.1934\n",
      "Epoch [38/50], Step [133/735], Loss: 0.0836\n",
      "Epoch [38/50], Step [134/735], Loss: 0.3031\n",
      "Epoch [38/50], Step [135/735], Loss: 0.0934\n",
      "Epoch [38/50], Step [136/735], Loss: 0.2432\n",
      "Epoch [38/50], Step [137/735], Loss: 0.0903\n",
      "Epoch [38/50], Step [138/735], Loss: 0.1665\n",
      "Epoch [38/50], Step [139/735], Loss: 0.8236\n",
      "Epoch [38/50], Step [140/735], Loss: 0.3473\n",
      "Epoch [38/50], Step [141/735], Loss: 0.4317\n",
      "Epoch [38/50], Step [142/735], Loss: 0.0838\n",
      "Epoch [38/50], Step [143/735], Loss: 0.2315\n",
      "Epoch [38/50], Step [144/735], Loss: 0.3336\n",
      "Epoch [38/50], Step [145/735], Loss: 0.1887\n",
      "Epoch [38/50], Step [146/735], Loss: 0.3662\n",
      "Epoch [38/50], Step [147/735], Loss: 0.4084\n",
      "Epoch [38/50], Step [148/735], Loss: 0.2890\n",
      "Epoch [38/50], Step [149/735], Loss: 0.2596\n",
      "Epoch [38/50], Step [150/735], Loss: 0.4642\n",
      "Epoch [38/50], Step [151/735], Loss: 0.3425\n",
      "Epoch [38/50], Step [152/735], Loss: 0.2759\n",
      "Epoch [38/50], Step [153/735], Loss: 0.1673\n",
      "Epoch [38/50], Step [154/735], Loss: 0.1880\n",
      "Epoch [38/50], Step [155/735], Loss: 0.1822\n",
      "Epoch [38/50], Step [156/735], Loss: 0.2582\n",
      "Epoch [38/50], Step [157/735], Loss: 0.2378\n",
      "Epoch [38/50], Step [158/735], Loss: 0.2041\n",
      "Epoch [38/50], Step [159/735], Loss: 0.2196\n",
      "Epoch [38/50], Step [160/735], Loss: 0.2598\n",
      "Epoch [38/50], Step [161/735], Loss: 0.4054\n",
      "Epoch [38/50], Step [162/735], Loss: 0.3193\n",
      "Epoch [38/50], Step [163/735], Loss: 0.0793\n",
      "Epoch [38/50], Step [164/735], Loss: 0.2980\n",
      "Epoch [38/50], Step [165/735], Loss: 0.1285\n",
      "Epoch [38/50], Step [166/735], Loss: 0.3223\n",
      "Epoch [38/50], Step [167/735], Loss: 0.2707\n",
      "Epoch [38/50], Step [168/735], Loss: 0.3407\n",
      "Epoch [38/50], Step [169/735], Loss: 0.2161\n",
      "Epoch [38/50], Step [170/735], Loss: 0.2592\n",
      "Epoch [38/50], Step [171/735], Loss: 0.6054\n",
      "Epoch [38/50], Step [172/735], Loss: 0.2470\n",
      "Epoch [38/50], Step [173/735], Loss: 0.2437\n",
      "Epoch [38/50], Step [174/735], Loss: 0.4391\n",
      "Epoch [38/50], Step [175/735], Loss: 0.3480\n",
      "Epoch [38/50], Step [176/735], Loss: 0.3049\n",
      "Epoch [38/50], Step [177/735], Loss: 0.2772\n",
      "Epoch [38/50], Step [178/735], Loss: 0.2420\n",
      "Epoch [38/50], Step [179/735], Loss: 0.2018\n",
      "Epoch [38/50], Step [180/735], Loss: 0.2054\n",
      "Epoch [38/50], Step [181/735], Loss: 0.1442\n",
      "Epoch [38/50], Step [182/735], Loss: 0.2364\n",
      "Epoch [38/50], Step [183/735], Loss: 0.3068\n",
      "Epoch [38/50], Step [184/735], Loss: 0.1470\n",
      "Epoch [38/50], Step [185/735], Loss: 0.2714\n",
      "Epoch [38/50], Step [186/735], Loss: 0.1523\n",
      "Epoch [38/50], Step [187/735], Loss: 0.4412\n",
      "Epoch [38/50], Step [188/735], Loss: 0.1491\n",
      "Epoch [38/50], Step [189/735], Loss: 0.1218\n",
      "Epoch [38/50], Step [190/735], Loss: 0.1572\n",
      "Epoch [38/50], Step [191/735], Loss: 0.1939\n",
      "Epoch [38/50], Step [192/735], Loss: 0.0782\n",
      "Epoch [38/50], Step [193/735], Loss: 0.6334\n",
      "Epoch [38/50], Step [194/735], Loss: 0.1133\n",
      "Epoch [38/50], Step [195/735], Loss: 0.1608\n",
      "Epoch [38/50], Step [196/735], Loss: 0.4154\n",
      "Epoch [38/50], Step [197/735], Loss: 0.3422\n",
      "Epoch [38/50], Step [198/735], Loss: 0.3712\n",
      "Epoch [38/50], Step [199/735], Loss: 0.1174\n",
      "Epoch [38/50], Step [200/735], Loss: 0.1755\n",
      "Epoch [38/50], Step [201/735], Loss: 0.1799\n",
      "Epoch [38/50], Step [202/735], Loss: 0.1942\n",
      "Epoch [38/50], Step [203/735], Loss: 0.9993\n",
      "Epoch [38/50], Step [204/735], Loss: 0.4514\n",
      "Epoch [38/50], Step [205/735], Loss: 0.1074\n",
      "Epoch [38/50], Step [206/735], Loss: 0.1323\n",
      "Epoch [38/50], Step [207/735], Loss: 0.2089\n",
      "Epoch [38/50], Step [208/735], Loss: 0.4595\n",
      "Epoch [38/50], Step [209/735], Loss: 0.1743\n",
      "Epoch [38/50], Step [210/735], Loss: 0.1663\n",
      "Epoch [38/50], Step [211/735], Loss: 0.4924\n",
      "Epoch [38/50], Step [212/735], Loss: 0.0939\n",
      "Epoch [38/50], Step [213/735], Loss: 0.3444\n",
      "Epoch [38/50], Step [214/735], Loss: 0.1604\n",
      "Epoch [38/50], Step [215/735], Loss: 0.0916\n",
      "Epoch [38/50], Step [216/735], Loss: 0.5483\n",
      "Epoch [38/50], Step [217/735], Loss: 0.2978\n",
      "Epoch [38/50], Step [218/735], Loss: 0.0836\n",
      "Epoch [38/50], Step [219/735], Loss: 0.1093\n",
      "Epoch [38/50], Step [220/735], Loss: 0.2494\n",
      "Epoch [38/50], Step [221/735], Loss: 0.2787\n",
      "Epoch [38/50], Step [222/735], Loss: 0.2030\n",
      "Epoch [38/50], Step [223/735], Loss: 0.2423\n",
      "Epoch [38/50], Step [224/735], Loss: 0.7142\n",
      "Epoch [38/50], Step [225/735], Loss: 0.2784\n",
      "Epoch [38/50], Step [226/735], Loss: 0.1618\n",
      "Epoch [38/50], Step [227/735], Loss: 0.2013\n",
      "Epoch [38/50], Step [228/735], Loss: 0.1086\n",
      "Epoch [38/50], Step [229/735], Loss: 0.2491\n",
      "Epoch [38/50], Step [230/735], Loss: 0.6503\n",
      "Epoch [38/50], Step [231/735], Loss: 0.1812\n",
      "Epoch [38/50], Step [232/735], Loss: 0.2055\n",
      "Epoch [38/50], Step [233/735], Loss: 0.0556\n",
      "Epoch [38/50], Step [234/735], Loss: 0.2644\n",
      "Epoch [38/50], Step [235/735], Loss: 0.3062\n",
      "Epoch [38/50], Step [236/735], Loss: 0.2347\n",
      "Epoch [38/50], Step [237/735], Loss: 0.4996\n",
      "Epoch [38/50], Step [238/735], Loss: 0.6613\n",
      "Epoch [38/50], Step [239/735], Loss: 0.1227\n",
      "Epoch [38/50], Step [240/735], Loss: 0.2307\n",
      "Epoch [38/50], Step [241/735], Loss: 0.2539\n",
      "Epoch [38/50], Step [242/735], Loss: 0.0679\n",
      "Epoch [38/50], Step [243/735], Loss: 0.4171\n",
      "Epoch [38/50], Step [244/735], Loss: 0.4362\n",
      "Epoch [38/50], Step [245/735], Loss: 0.7429\n",
      "Epoch [38/50], Step [246/735], Loss: 0.2823\n",
      "Epoch [38/50], Step [247/735], Loss: 0.1634\n",
      "Epoch [38/50], Step [248/735], Loss: 0.1101\n",
      "Epoch [38/50], Step [249/735], Loss: 0.1947\n",
      "Epoch [38/50], Step [250/735], Loss: 0.3887\n",
      "Epoch [38/50], Step [251/735], Loss: 0.0912\n",
      "Epoch [38/50], Step [252/735], Loss: 0.6627\n",
      "Epoch [38/50], Step [253/735], Loss: 0.1459\n",
      "Epoch [38/50], Step [254/735], Loss: 0.1998\n",
      "Epoch [38/50], Step [255/735], Loss: 0.2539\n",
      "Epoch [38/50], Step [256/735], Loss: 0.1411\n",
      "Epoch [38/50], Step [257/735], Loss: 0.0539\n",
      "Epoch [38/50], Step [258/735], Loss: 0.2194\n",
      "Epoch [38/50], Step [259/735], Loss: 0.2936\n",
      "Epoch [38/50], Step [260/735], Loss: 0.2436\n",
      "Epoch [38/50], Step [261/735], Loss: 0.3518\n",
      "Epoch [38/50], Step [262/735], Loss: 0.2468\n",
      "Epoch [38/50], Step [263/735], Loss: 0.0644\n",
      "Epoch [38/50], Step [264/735], Loss: 0.4520\n",
      "Epoch [38/50], Step [265/735], Loss: 0.7980\n",
      "Epoch [38/50], Step [266/735], Loss: 0.6789\n",
      "Epoch [38/50], Step [267/735], Loss: 0.1658\n",
      "Epoch [38/50], Step [268/735], Loss: 0.8451\n",
      "Epoch [38/50], Step [269/735], Loss: 0.1870\n",
      "Epoch [38/50], Step [270/735], Loss: 0.2845\n",
      "Epoch [38/50], Step [271/735], Loss: 0.1555\n",
      "Epoch [38/50], Step [272/735], Loss: 0.1283\n",
      "Epoch [38/50], Step [273/735], Loss: 0.2084\n",
      "Epoch [38/50], Step [274/735], Loss: 0.3856\n",
      "Epoch [38/50], Step [275/735], Loss: 0.8729\n",
      "Epoch [38/50], Step [276/735], Loss: 0.1203\n",
      "Epoch [38/50], Step [277/735], Loss: 0.2660\n",
      "Epoch [38/50], Step [278/735], Loss: 0.1381\n",
      "Epoch [38/50], Step [279/735], Loss: 0.3231\n",
      "Epoch [38/50], Step [280/735], Loss: 0.1273\n",
      "Epoch [38/50], Step [281/735], Loss: 0.1803\n",
      "Epoch [38/50], Step [282/735], Loss: 0.1601\n",
      "Epoch [38/50], Step [283/735], Loss: 0.1680\n",
      "Epoch [38/50], Step [284/735], Loss: 0.3082\n",
      "Epoch [38/50], Step [285/735], Loss: 0.4952\n",
      "Epoch [38/50], Step [286/735], Loss: 0.2047\n",
      "Epoch [38/50], Step [287/735], Loss: 0.0631\n",
      "Epoch [38/50], Step [288/735], Loss: 0.5457\n",
      "Epoch [38/50], Step [289/735], Loss: 0.4198\n",
      "Epoch [38/50], Step [290/735], Loss: 0.0678\n",
      "Epoch [38/50], Step [291/735], Loss: 0.5932\n",
      "Epoch [38/50], Step [292/735], Loss: 4.1103\n",
      "Epoch [38/50], Step [293/735], Loss: 0.6014\n",
      "Epoch [38/50], Step [294/735], Loss: 0.2347\n",
      "Epoch [38/50], Step [295/735], Loss: 0.1243\n",
      "Epoch [38/50], Step [296/735], Loss: 0.3096\n",
      "Epoch [38/50], Step [297/735], Loss: 0.2929\n",
      "Epoch [38/50], Step [298/735], Loss: 0.3266\n",
      "Epoch [38/50], Step [299/735], Loss: 0.5260\n",
      "Epoch [38/50], Step [300/735], Loss: 0.3157\n",
      "Epoch [38/50], Step [301/735], Loss: 0.1306\n",
      "Epoch [38/50], Step [302/735], Loss: 0.3647\n",
      "Epoch [38/50], Step [303/735], Loss: 0.2638\n",
      "Epoch [38/50], Step [304/735], Loss: 0.3872\n",
      "Epoch [38/50], Step [305/735], Loss: 0.3866\n",
      "Epoch [38/50], Step [306/735], Loss: 0.0575\n",
      "Epoch [38/50], Step [307/735], Loss: 0.3241\n",
      "Epoch [38/50], Step [308/735], Loss: 0.2341\n",
      "Epoch [38/50], Step [309/735], Loss: 0.1757\n",
      "Epoch [38/50], Step [310/735], Loss: 0.1541\n",
      "Epoch [38/50], Step [311/735], Loss: 0.3120\n",
      "Epoch [38/50], Step [312/735], Loss: 0.1107\n",
      "Epoch [38/50], Step [313/735], Loss: 0.0967\n",
      "Epoch [38/50], Step [314/735], Loss: 0.6590\n",
      "Epoch [38/50], Step [315/735], Loss: 0.1449\n",
      "Epoch [38/50], Step [316/735], Loss: 0.4134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Step [317/735], Loss: 0.4326\n",
      "Epoch [38/50], Step [318/735], Loss: 0.1868\n",
      "Epoch [38/50], Step [319/735], Loss: 0.2600\n",
      "Epoch [38/50], Step [320/735], Loss: 0.1489\n",
      "Epoch [38/50], Step [321/735], Loss: 0.4152\n",
      "Epoch [38/50], Step [322/735], Loss: 0.1444\n",
      "Epoch [38/50], Step [323/735], Loss: 0.3317\n",
      "Epoch [38/50], Step [324/735], Loss: 0.3369\n",
      "Epoch [38/50], Step [325/735], Loss: 0.3391\n",
      "Epoch [38/50], Step [326/735], Loss: 0.4039\n",
      "Epoch [38/50], Step [327/735], Loss: 0.9103\n",
      "Epoch [38/50], Step [328/735], Loss: 0.7815\n",
      "Epoch [38/50], Step [329/735], Loss: 0.0781\n",
      "Epoch [38/50], Step [330/735], Loss: 0.7589\n",
      "Epoch [38/50], Step [331/735], Loss: 0.1843\n",
      "Epoch [38/50], Step [332/735], Loss: 0.2881\n",
      "Epoch [38/50], Step [333/735], Loss: 0.3216\n",
      "Epoch [38/50], Step [334/735], Loss: 0.1414\n",
      "Epoch [38/50], Step [335/735], Loss: 0.2087\n",
      "Epoch [38/50], Step [336/735], Loss: 0.5150\n",
      "Epoch [38/50], Step [337/735], Loss: 0.4541\n",
      "Epoch [38/50], Step [338/735], Loss: 0.4396\n",
      "Epoch [38/50], Step [339/735], Loss: 0.4043\n",
      "Epoch [38/50], Step [340/735], Loss: 0.1096\n",
      "Epoch [38/50], Step [341/735], Loss: 0.1985\n",
      "Epoch [38/50], Step [342/735], Loss: 0.2852\n",
      "Epoch [38/50], Step [343/735], Loss: 0.1253\n",
      "Epoch [38/50], Step [344/735], Loss: 0.3374\n",
      "Epoch [38/50], Step [345/735], Loss: 0.1045\n",
      "Epoch [38/50], Step [346/735], Loss: 0.1786\n",
      "Epoch [38/50], Step [347/735], Loss: 0.0907\n",
      "Epoch [38/50], Step [348/735], Loss: 0.7557\n",
      "Epoch [38/50], Step [349/735], Loss: 0.1712\n",
      "Epoch [38/50], Step [350/735], Loss: 0.9190\n",
      "Epoch [38/50], Step [351/735], Loss: 0.1189\n",
      "Epoch [38/50], Step [352/735], Loss: 0.1446\n",
      "Epoch [38/50], Step [353/735], Loss: 0.2798\n",
      "Epoch [38/50], Step [354/735], Loss: 0.2564\n",
      "Epoch [38/50], Step [355/735], Loss: 0.2611\n",
      "Epoch [38/50], Step [356/735], Loss: 0.5980\n",
      "Epoch [38/50], Step [357/735], Loss: 0.2019\n",
      "Epoch [38/50], Step [358/735], Loss: 0.1486\n",
      "Epoch [38/50], Step [359/735], Loss: 0.1627\n",
      "Epoch [38/50], Step [360/735], Loss: 0.1234\n",
      "Epoch [38/50], Step [361/735], Loss: 0.1399\n",
      "Epoch [38/50], Step [362/735], Loss: 0.4106\n",
      "Epoch [38/50], Step [363/735], Loss: 0.1358\n",
      "Epoch [38/50], Step [364/735], Loss: 0.5263\n",
      "Epoch [38/50], Step [365/735], Loss: 0.3324\n",
      "Epoch [38/50], Step [366/735], Loss: 0.1060\n",
      "Epoch [38/50], Step [367/735], Loss: 0.1974\n",
      "Epoch [38/50], Step [368/735], Loss: 0.2445\n",
      "Epoch [38/50], Step [369/735], Loss: 0.3116\n",
      "Epoch [38/50], Step [370/735], Loss: 0.4627\n",
      "Epoch [38/50], Step [371/735], Loss: 0.1249\n",
      "Epoch [38/50], Step [372/735], Loss: 0.2846\n",
      "Epoch [38/50], Step [373/735], Loss: 0.1887\n",
      "Epoch [38/50], Step [374/735], Loss: 0.3531\n",
      "Epoch [38/50], Step [375/735], Loss: 0.3515\n",
      "Epoch [38/50], Step [376/735], Loss: 0.2601\n",
      "Epoch [38/50], Step [377/735], Loss: 0.0955\n",
      "Epoch [38/50], Step [378/735], Loss: 0.4689\n",
      "Epoch [38/50], Step [379/735], Loss: 0.1572\n",
      "Epoch [38/50], Step [380/735], Loss: 0.2738\n",
      "Epoch [38/50], Step [381/735], Loss: 0.2857\n",
      "Epoch [38/50], Step [382/735], Loss: 0.4455\n",
      "Epoch [38/50], Step [383/735], Loss: 0.1826\n",
      "Epoch [38/50], Step [384/735], Loss: 0.3483\n",
      "Epoch [38/50], Step [385/735], Loss: 0.1280\n",
      "Epoch [38/50], Step [386/735], Loss: 0.3356\n",
      "Epoch [38/50], Step [387/735], Loss: 0.2207\n",
      "Epoch [38/50], Step [388/735], Loss: 0.2938\n",
      "Epoch [38/50], Step [389/735], Loss: 0.3065\n",
      "Epoch [38/50], Step [390/735], Loss: 0.2165\n",
      "Epoch [38/50], Step [391/735], Loss: 0.2450\n",
      "Epoch [38/50], Step [392/735], Loss: 0.2760\n",
      "Epoch [38/50], Step [393/735], Loss: 0.1424\n",
      "Epoch [38/50], Step [394/735], Loss: 0.1195\n",
      "Epoch [38/50], Step [395/735], Loss: 0.1556\n",
      "Epoch [38/50], Step [396/735], Loss: 0.1797\n",
      "Epoch [38/50], Step [397/735], Loss: 0.0874\n",
      "Epoch [38/50], Step [398/735], Loss: 0.2947\n",
      "Epoch [38/50], Step [399/735], Loss: 0.0508\n",
      "Epoch [38/50], Step [400/735], Loss: 0.8527\n",
      "Epoch [38/50], Step [401/735], Loss: 0.1389\n",
      "Epoch [38/50], Step [402/735], Loss: 0.5578\n",
      "Epoch [38/50], Step [403/735], Loss: 0.1929\n",
      "Epoch [38/50], Step [404/735], Loss: 0.4325\n",
      "Epoch [38/50], Step [405/735], Loss: 0.2439\n",
      "Epoch [38/50], Step [406/735], Loss: 0.1914\n",
      "Epoch [38/50], Step [407/735], Loss: 0.3704\n",
      "Epoch [38/50], Step [408/735], Loss: 0.2893\n",
      "Epoch [38/50], Step [409/735], Loss: 0.4052\n",
      "Epoch [38/50], Step [410/735], Loss: 0.1417\n",
      "Epoch [38/50], Step [411/735], Loss: 0.1263\n",
      "Epoch [38/50], Step [412/735], Loss: 0.2240\n",
      "Epoch [38/50], Step [413/735], Loss: 1.1013\n",
      "Epoch [38/50], Step [414/735], Loss: 0.1796\n",
      "Epoch [38/50], Step [415/735], Loss: 0.1082\n",
      "Epoch [38/50], Step [416/735], Loss: 0.9751\n",
      "Epoch [38/50], Step [417/735], Loss: 0.2395\n",
      "Epoch [38/50], Step [418/735], Loss: 0.0971\n",
      "Epoch [38/50], Step [419/735], Loss: 0.3722\n",
      "Epoch [38/50], Step [420/735], Loss: 0.1045\n",
      "Epoch [38/50], Step [421/735], Loss: 0.4671\n",
      "Epoch [38/50], Step [422/735], Loss: 0.4010\n",
      "Epoch [38/50], Step [423/735], Loss: 0.2034\n",
      "Epoch [38/50], Step [424/735], Loss: 0.0283\n",
      "Epoch [38/50], Step [425/735], Loss: 0.1229\n",
      "Epoch [38/50], Step [426/735], Loss: 0.6651\n",
      "Epoch [38/50], Step [427/735], Loss: 0.4335\n",
      "Epoch [38/50], Step [428/735], Loss: 0.1401\n",
      "Epoch [38/50], Step [429/735], Loss: 0.1033\n",
      "Epoch [38/50], Step [430/735], Loss: 0.3632\n",
      "Epoch [38/50], Step [431/735], Loss: 1.0489\n",
      "Epoch [38/50], Step [432/735], Loss: 0.1546\n",
      "Epoch [38/50], Step [433/735], Loss: 3.2741\n",
      "Epoch [38/50], Step [434/735], Loss: 0.3414\n",
      "Epoch [38/50], Step [435/735], Loss: 0.3434\n",
      "Epoch [38/50], Step [436/735], Loss: 0.3640\n",
      "Epoch [38/50], Step [437/735], Loss: 0.2163\n",
      "Epoch [38/50], Step [438/735], Loss: 0.2719\n",
      "Epoch [38/50], Step [439/735], Loss: 0.3186\n",
      "Epoch [38/50], Step [440/735], Loss: 0.5153\n",
      "Epoch [38/50], Step [441/735], Loss: 0.3991\n",
      "Epoch [38/50], Step [442/735], Loss: 0.3579\n",
      "Epoch [38/50], Step [443/735], Loss: 0.3403\n",
      "Epoch [38/50], Step [444/735], Loss: 0.5099\n",
      "Epoch [38/50], Step [445/735], Loss: 0.0763\n",
      "Epoch [38/50], Step [446/735], Loss: 0.2075\n",
      "Epoch [38/50], Step [447/735], Loss: 0.2581\n",
      "Epoch [38/50], Step [448/735], Loss: 0.1312\n",
      "Epoch [38/50], Step [449/735], Loss: 0.7333\n",
      "Epoch [38/50], Step [450/735], Loss: 0.2104\n",
      "Epoch [38/50], Step [451/735], Loss: 0.1483\n",
      "Epoch [38/50], Step [452/735], Loss: 0.1851\n",
      "Epoch [38/50], Step [453/735], Loss: 0.3852\n",
      "Epoch [38/50], Step [454/735], Loss: 0.1920\n",
      "Epoch [38/50], Step [455/735], Loss: 0.2936\n",
      "Epoch [38/50], Step [456/735], Loss: 0.4225\n",
      "Epoch [38/50], Step [457/735], Loss: 0.5390\n",
      "Epoch [38/50], Step [458/735], Loss: 0.1519\n",
      "Epoch [38/50], Step [459/735], Loss: 0.3455\n",
      "Epoch [38/50], Step [460/735], Loss: 0.1867\n",
      "Epoch [38/50], Step [461/735], Loss: 0.3154\n",
      "Epoch [38/50], Step [462/735], Loss: 0.0765\n",
      "Epoch [38/50], Step [463/735], Loss: 0.1703\n",
      "Epoch [38/50], Step [464/735], Loss: 0.1114\n",
      "Epoch [38/50], Step [465/735], Loss: 0.2683\n",
      "Epoch [38/50], Step [466/735], Loss: 0.8551\n",
      "Epoch [38/50], Step [467/735], Loss: 0.4125\n",
      "Epoch [38/50], Step [468/735], Loss: 0.3601\n",
      "Epoch [38/50], Step [469/735], Loss: 0.5264\n",
      "Epoch [38/50], Step [470/735], Loss: 0.3289\n",
      "Epoch [38/50], Step [471/735], Loss: 0.1442\n",
      "Epoch [38/50], Step [472/735], Loss: 0.2055\n",
      "Epoch [38/50], Step [473/735], Loss: 0.2413\n",
      "Epoch [38/50], Step [474/735], Loss: 0.1457\n",
      "Epoch [38/50], Step [475/735], Loss: 0.1507\n",
      "Epoch [38/50], Step [476/735], Loss: 0.2513\n",
      "Epoch [38/50], Step [477/735], Loss: 0.2655\n",
      "Epoch [38/50], Step [478/735], Loss: 0.1970\n",
      "Epoch [38/50], Step [479/735], Loss: 0.5916\n",
      "Epoch [38/50], Step [480/735], Loss: 1.0451\n",
      "Epoch [38/50], Step [481/735], Loss: 0.2014\n",
      "Epoch [38/50], Step [482/735], Loss: 0.3085\n",
      "Epoch [38/50], Step [483/735], Loss: 0.0624\n",
      "Epoch [38/50], Step [484/735], Loss: 0.4132\n",
      "Epoch [38/50], Step [485/735], Loss: 0.1261\n",
      "Epoch [38/50], Step [486/735], Loss: 0.2461\n",
      "Epoch [38/50], Step [487/735], Loss: 0.4806\n",
      "Epoch [38/50], Step [488/735], Loss: 0.4869\n",
      "Epoch [38/50], Step [489/735], Loss: 0.2476\n",
      "Epoch [38/50], Step [490/735], Loss: 0.5910\n",
      "Epoch [38/50], Step [491/735], Loss: 0.4446\n",
      "Epoch [38/50], Step [492/735], Loss: 0.1221\n",
      "Epoch [38/50], Step [493/735], Loss: 0.1083\n",
      "Epoch [38/50], Step [494/735], Loss: 0.1964\n",
      "Epoch [38/50], Step [495/735], Loss: 0.2110\n",
      "Epoch [38/50], Step [496/735], Loss: 0.3842\n",
      "Epoch [38/50], Step [497/735], Loss: 0.3652\n",
      "Epoch [38/50], Step [498/735], Loss: 0.0847\n",
      "Epoch [38/50], Step [499/735], Loss: 0.4567\n",
      "Epoch [38/50], Step [500/735], Loss: 1.5117\n",
      "Epoch [38/50], Step [501/735], Loss: 0.3117\n",
      "Epoch [38/50], Step [502/735], Loss: 0.5349\n",
      "Epoch [38/50], Step [503/735], Loss: 0.1588\n",
      "Epoch [38/50], Step [504/735], Loss: 0.3374\n",
      "Epoch [38/50], Step [505/735], Loss: 0.3888\n",
      "Epoch [38/50], Step [506/735], Loss: 0.0777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Step [507/735], Loss: 0.3066\n",
      "Epoch [38/50], Step [508/735], Loss: 0.1350\n",
      "Epoch [38/50], Step [509/735], Loss: 0.1862\n",
      "Epoch [38/50], Step [510/735], Loss: 0.3395\n",
      "Epoch [38/50], Step [511/735], Loss: 0.1866\n",
      "Epoch [38/50], Step [512/735], Loss: 0.0530\n",
      "Epoch [38/50], Step [513/735], Loss: 0.1625\n",
      "Epoch [38/50], Step [514/735], Loss: 0.2052\n",
      "Epoch [38/50], Step [515/735], Loss: 0.0723\n",
      "Epoch [38/50], Step [516/735], Loss: 0.4088\n",
      "Epoch [38/50], Step [517/735], Loss: 0.5252\n",
      "Epoch [38/50], Step [518/735], Loss: 0.8605\n",
      "Epoch [38/50], Step [519/735], Loss: 0.1275\n",
      "Epoch [38/50], Step [520/735], Loss: 0.2300\n",
      "Epoch [38/50], Step [521/735], Loss: 0.3490\n",
      "Epoch [38/50], Step [522/735], Loss: 0.1028\n",
      "Epoch [38/50], Step [523/735], Loss: 0.1242\n",
      "Epoch [38/50], Step [524/735], Loss: 0.3683\n",
      "Epoch [38/50], Step [525/735], Loss: 0.1618\n",
      "Epoch [38/50], Step [526/735], Loss: 0.1420\n",
      "Epoch [38/50], Step [527/735], Loss: 0.3295\n",
      "Epoch [38/50], Step [528/735], Loss: 0.2827\n",
      "Epoch [38/50], Step [529/735], Loss: 0.2044\n",
      "Epoch [38/50], Step [530/735], Loss: 0.0621\n",
      "Epoch [38/50], Step [531/735], Loss: 0.2623\n",
      "Epoch [38/50], Step [532/735], Loss: 0.6516\n",
      "Epoch [38/50], Step [533/735], Loss: 0.1358\n",
      "Epoch [38/50], Step [534/735], Loss: 0.4496\n",
      "Epoch [38/50], Step [535/735], Loss: 0.1232\n",
      "Epoch [38/50], Step [536/735], Loss: 0.4977\n",
      "Epoch [38/50], Step [537/735], Loss: 0.2061\n",
      "Epoch [38/50], Step [538/735], Loss: 0.3957\n",
      "Epoch [38/50], Step [539/735], Loss: 0.3910\n",
      "Epoch [38/50], Step [540/735], Loss: 0.4486\n",
      "Epoch [38/50], Step [541/735], Loss: 1.3880\n",
      "Epoch [38/50], Step [542/735], Loss: 0.2623\n",
      "Epoch [38/50], Step [543/735], Loss: 0.3662\n",
      "Epoch [38/50], Step [544/735], Loss: 0.9734\n",
      "Epoch [38/50], Step [545/735], Loss: 0.2274\n",
      "Epoch [38/50], Step [546/735], Loss: 0.0650\n",
      "Epoch [38/50], Step [547/735], Loss: 0.0592\n",
      "Epoch [38/50], Step [548/735], Loss: 0.1837\n",
      "Epoch [38/50], Step [549/735], Loss: 0.2541\n",
      "Epoch [38/50], Step [550/735], Loss: 0.2110\n",
      "Epoch [38/50], Step [551/735], Loss: 0.8786\n",
      "Epoch [38/50], Step [552/735], Loss: 0.1387\n",
      "Epoch [38/50], Step [553/735], Loss: 0.4361\n",
      "Epoch [38/50], Step [554/735], Loss: 0.3900\n",
      "Epoch [38/50], Step [555/735], Loss: 0.4796\n",
      "Epoch [38/50], Step [556/735], Loss: 0.7803\n",
      "Epoch [38/50], Step [557/735], Loss: 2.9176\n",
      "Epoch [38/50], Step [558/735], Loss: 0.2459\n",
      "Epoch [38/50], Step [559/735], Loss: 0.1191\n",
      "Epoch [38/50], Step [560/735], Loss: 0.2970\n",
      "Epoch [38/50], Step [561/735], Loss: 0.1654\n",
      "Epoch [38/50], Step [562/735], Loss: 0.2463\n",
      "Epoch [38/50], Step [563/735], Loss: 0.3132\n",
      "Epoch [38/50], Step [564/735], Loss: 0.5030\n",
      "Epoch [38/50], Step [565/735], Loss: 0.2033\n",
      "Epoch [38/50], Step [566/735], Loss: 0.6976\n",
      "Epoch [38/50], Step [567/735], Loss: 0.3796\n",
      "Epoch [38/50], Step [568/735], Loss: 0.1792\n",
      "Epoch [38/50], Step [569/735], Loss: 0.1136\n",
      "Epoch [38/50], Step [570/735], Loss: 0.4245\n",
      "Epoch [38/50], Step [571/735], Loss: 0.3258\n",
      "Epoch [38/50], Step [572/735], Loss: 0.1804\n",
      "Epoch [38/50], Step [573/735], Loss: 0.1861\n",
      "Epoch [38/50], Step [574/735], Loss: 0.1131\n",
      "Epoch [38/50], Step [575/735], Loss: 0.1799\n",
      "Epoch [38/50], Step [576/735], Loss: 0.3550\n",
      "Epoch [38/50], Step [577/735], Loss: 0.3715\n",
      "Epoch [38/50], Step [578/735], Loss: 0.4410\n",
      "Epoch [38/50], Step [579/735], Loss: 0.2756\n",
      "Epoch [38/50], Step [580/735], Loss: 0.2781\n",
      "Epoch [38/50], Step [581/735], Loss: 0.6514\n",
      "Epoch [38/50], Step [582/735], Loss: 0.2873\n",
      "Epoch [38/50], Step [583/735], Loss: 0.0691\n",
      "Epoch [38/50], Step [584/735], Loss: 0.3066\n",
      "Epoch [38/50], Step [585/735], Loss: 0.2697\n",
      "Epoch [38/50], Step [586/735], Loss: 0.8082\n",
      "Epoch [38/50], Step [587/735], Loss: 0.2337\n",
      "Epoch [38/50], Step [588/735], Loss: 0.5489\n",
      "Epoch [38/50], Step [589/735], Loss: 0.4704\n",
      "Epoch [38/50], Step [590/735], Loss: 0.5432\n",
      "Epoch [38/50], Step [591/735], Loss: 0.1145\n",
      "Epoch [38/50], Step [592/735], Loss: 0.7083\n",
      "Epoch [38/50], Step [593/735], Loss: 0.1715\n",
      "Epoch [38/50], Step [594/735], Loss: 0.1375\n",
      "Epoch [38/50], Step [595/735], Loss: 0.3360\n",
      "Epoch [38/50], Step [596/735], Loss: 3.9564\n",
      "Epoch [38/50], Step [597/735], Loss: 0.3213\n",
      "Epoch [38/50], Step [598/735], Loss: 0.2324\n",
      "Epoch [38/50], Step [599/735], Loss: 0.9081\n",
      "Epoch [38/50], Step [600/735], Loss: 0.6579\n",
      "Epoch [38/50], Step [601/735], Loss: 0.2090\n",
      "Epoch [38/50], Step [602/735], Loss: 0.5547\n",
      "Epoch [38/50], Step [603/735], Loss: 0.1915\n",
      "Epoch [38/50], Step [604/735], Loss: 0.2316\n",
      "Epoch [38/50], Step [605/735], Loss: 0.4254\n",
      "Epoch [38/50], Step [606/735], Loss: 0.7389\n",
      "Epoch [38/50], Step [607/735], Loss: 0.1059\n",
      "Epoch [38/50], Step [608/735], Loss: 0.7447\n",
      "Epoch [38/50], Step [609/735], Loss: 0.0928\n",
      "Epoch [38/50], Step [610/735], Loss: 0.3219\n",
      "Epoch [38/50], Step [611/735], Loss: 0.1941\n",
      "Epoch [38/50], Step [612/735], Loss: 0.2573\n",
      "Epoch [38/50], Step [613/735], Loss: 0.2214\n",
      "Epoch [38/50], Step [614/735], Loss: 0.3025\n",
      "Epoch [38/50], Step [615/735], Loss: 0.2770\n",
      "Epoch [38/50], Step [616/735], Loss: 0.3242\n",
      "Epoch [38/50], Step [617/735], Loss: 0.3782\n",
      "Epoch [38/50], Step [618/735], Loss: 0.5972\n",
      "Epoch [38/50], Step [619/735], Loss: 0.1376\n",
      "Epoch [38/50], Step [620/735], Loss: 0.0623\n",
      "Epoch [38/50], Step [621/735], Loss: 0.2323\n",
      "Epoch [38/50], Step [622/735], Loss: 0.8366\n",
      "Epoch [38/50], Step [623/735], Loss: 0.2769\n",
      "Epoch [38/50], Step [624/735], Loss: 0.0777\n",
      "Epoch [38/50], Step [625/735], Loss: 0.3609\n",
      "Epoch [38/50], Step [626/735], Loss: 0.1225\n",
      "Epoch [38/50], Step [627/735], Loss: 0.2242\n",
      "Epoch [38/50], Step [628/735], Loss: 0.2658\n",
      "Epoch [38/50], Step [629/735], Loss: 0.2106\n",
      "Epoch [38/50], Step [630/735], Loss: 0.1703\n",
      "Epoch [38/50], Step [631/735], Loss: 0.2768\n",
      "Epoch [38/50], Step [632/735], Loss: 0.3460\n",
      "Epoch [38/50], Step [633/735], Loss: 0.4143\n",
      "Epoch [38/50], Step [634/735], Loss: 0.1339\n",
      "Epoch [38/50], Step [635/735], Loss: 0.4363\n",
      "Epoch [38/50], Step [636/735], Loss: 0.2147\n",
      "Epoch [38/50], Step [637/735], Loss: 0.3362\n",
      "Epoch [38/50], Step [638/735], Loss: 0.5868\n",
      "Epoch [38/50], Step [639/735], Loss: 0.0738\n",
      "Epoch [38/50], Step [640/735], Loss: 0.1628\n",
      "Epoch [38/50], Step [641/735], Loss: 0.2483\n",
      "Epoch [38/50], Step [642/735], Loss: 0.4021\n",
      "Epoch [38/50], Step [643/735], Loss: 0.8302\n",
      "Epoch [38/50], Step [644/735], Loss: 0.0773\n",
      "Epoch [38/50], Step [645/735], Loss: 0.1168\n",
      "Epoch [38/50], Step [646/735], Loss: 3.0481\n",
      "Epoch [38/50], Step [647/735], Loss: 0.2866\n",
      "Epoch [38/50], Step [648/735], Loss: 1.0727\n",
      "Epoch [38/50], Step [649/735], Loss: 0.1810\n",
      "Epoch [38/50], Step [650/735], Loss: 0.0781\n",
      "Epoch [38/50], Step [651/735], Loss: 0.4053\n",
      "Epoch [38/50], Step [652/735], Loss: 0.3697\n",
      "Epoch [38/50], Step [653/735], Loss: 0.1496\n",
      "Epoch [38/50], Step [654/735], Loss: 0.6635\n",
      "Epoch [38/50], Step [655/735], Loss: 0.3871\n",
      "Epoch [38/50], Step [656/735], Loss: 0.1016\n",
      "Epoch [38/50], Step [657/735], Loss: 0.0982\n",
      "Epoch [38/50], Step [658/735], Loss: 0.1819\n",
      "Epoch [38/50], Step [659/735], Loss: 0.2785\n",
      "Epoch [38/50], Step [660/735], Loss: 0.1560\n",
      "Epoch [38/50], Step [661/735], Loss: 0.0867\n",
      "Epoch [38/50], Step [662/735], Loss: 0.3286\n",
      "Epoch [38/50], Step [663/735], Loss: 0.1825\n",
      "Epoch [38/50], Step [664/735], Loss: 0.1378\n",
      "Epoch [38/50], Step [665/735], Loss: 0.1815\n",
      "Epoch [38/50], Step [666/735], Loss: 0.0941\n",
      "Epoch [38/50], Step [667/735], Loss: 0.2344\n",
      "Epoch [38/50], Step [668/735], Loss: 0.2353\n",
      "Epoch [38/50], Step [669/735], Loss: 0.2488\n",
      "Epoch [38/50], Step [670/735], Loss: 0.1928\n",
      "Epoch [38/50], Step [671/735], Loss: 0.4224\n",
      "Epoch [38/50], Step [672/735], Loss: 0.2873\n",
      "Epoch [38/50], Step [673/735], Loss: 0.1697\n",
      "Epoch [38/50], Step [674/735], Loss: 0.1512\n",
      "Epoch [38/50], Step [675/735], Loss: 0.2208\n",
      "Epoch [38/50], Step [676/735], Loss: 0.2078\n",
      "Epoch [38/50], Step [677/735], Loss: 0.1195\n",
      "Epoch [38/50], Step [678/735], Loss: 0.1699\n",
      "Epoch [38/50], Step [679/735], Loss: 0.4460\n",
      "Epoch [38/50], Step [680/735], Loss: 0.3228\n",
      "Epoch [38/50], Step [681/735], Loss: 0.2779\n",
      "Epoch [38/50], Step [682/735], Loss: 0.2141\n",
      "Epoch [38/50], Step [683/735], Loss: 0.2067\n",
      "Epoch [38/50], Step [684/735], Loss: 0.4621\n",
      "Epoch [38/50], Step [685/735], Loss: 0.6072\n",
      "Epoch [38/50], Step [686/735], Loss: 0.4727\n",
      "Epoch [38/50], Step [687/735], Loss: 0.5528\n",
      "Epoch [38/50], Step [688/735], Loss: 0.6548\n",
      "Epoch [38/50], Step [689/735], Loss: 0.2195\n",
      "Epoch [38/50], Step [690/735], Loss: 0.1175\n",
      "Epoch [38/50], Step [691/735], Loss: 0.1794\n",
      "Epoch [38/50], Step [692/735], Loss: 0.3188\n",
      "Epoch [38/50], Step [693/735], Loss: 0.3049\n",
      "Epoch [38/50], Step [694/735], Loss: 0.1977\n",
      "Epoch [38/50], Step [695/735], Loss: 0.0834\n",
      "Epoch [38/50], Step [696/735], Loss: 0.1954\n",
      "Epoch [38/50], Step [697/735], Loss: 0.1070\n",
      "Epoch [38/50], Step [698/735], Loss: 0.8952\n",
      "Epoch [38/50], Step [699/735], Loss: 0.3265\n",
      "Epoch [38/50], Step [700/735], Loss: 0.2945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Step [701/735], Loss: 0.1157\n",
      "Epoch [38/50], Step [702/735], Loss: 0.0962\n",
      "Epoch [38/50], Step [703/735], Loss: 0.0793\n",
      "Epoch [38/50], Step [704/735], Loss: 0.2735\n",
      "Epoch [38/50], Step [705/735], Loss: 0.3217\n",
      "Epoch [38/50], Step [706/735], Loss: 0.3025\n",
      "Epoch [38/50], Step [707/735], Loss: 0.4887\n",
      "Epoch [38/50], Step [708/735], Loss: 0.3308\n",
      "Epoch [38/50], Step [709/735], Loss: 0.3622\n",
      "Epoch [38/50], Step [710/735], Loss: 0.5380\n",
      "Epoch [38/50], Step [711/735], Loss: 0.2945\n",
      "Epoch [38/50], Step [712/735], Loss: 0.3213\n",
      "Epoch [38/50], Step [713/735], Loss: 0.2060\n",
      "Epoch [38/50], Step [714/735], Loss: 0.1291\n",
      "Epoch [38/50], Step [715/735], Loss: 0.1987\n",
      "Epoch [38/50], Step [716/735], Loss: 0.2916\n",
      "Epoch [38/50], Step [717/735], Loss: 0.3775\n",
      "Epoch [38/50], Step [718/735], Loss: 0.1256\n",
      "Epoch [38/50], Step [719/735], Loss: 0.1328\n",
      "Epoch [38/50], Step [720/735], Loss: 0.3412\n",
      "Epoch [38/50], Step [721/735], Loss: 0.5737\n",
      "Epoch [38/50], Step [722/735], Loss: 0.2506\n",
      "Epoch [38/50], Step [723/735], Loss: 0.6111\n",
      "Epoch [38/50], Step [724/735], Loss: 0.5704\n",
      "Epoch [38/50], Step [725/735], Loss: 0.1571\n",
      "Epoch [38/50], Step [726/735], Loss: 0.6435\n",
      "Epoch [38/50], Step [727/735], Loss: 0.1885\n",
      "Epoch [38/50], Step [728/735], Loss: 0.2967\n",
      "Epoch [38/50], Step [729/735], Loss: 0.2086\n",
      "Epoch [38/50], Step [730/735], Loss: 0.1439\n",
      "Epoch [38/50], Step [731/735], Loss: 0.2139\n",
      "Epoch [38/50], Step [732/735], Loss: 0.1596\n",
      "Epoch [38/50], Step [733/735], Loss: 0.5993\n",
      "Epoch [38/50], Step [734/735], Loss: 0.1772\n",
      "Epoch [38/50], Step [735/735], Loss: 0.5431\n",
      "Epoch [39/50], Step [1/735], Loss: 0.5668\n",
      "Epoch [39/50], Step [2/735], Loss: 0.0652\n",
      "Epoch [39/50], Step [3/735], Loss: 0.1266\n",
      "Epoch [39/50], Step [4/735], Loss: 0.1825\n",
      "Epoch [39/50], Step [5/735], Loss: 0.3072\n",
      "Epoch [39/50], Step [6/735], Loss: 0.2307\n",
      "Epoch [39/50], Step [7/735], Loss: 0.3275\n",
      "Epoch [39/50], Step [8/735], Loss: 0.2926\n",
      "Epoch [39/50], Step [9/735], Loss: 0.2328\n",
      "Epoch [39/50], Step [10/735], Loss: 0.2307\n",
      "Epoch [39/50], Step [11/735], Loss: 0.4880\n",
      "Epoch [39/50], Step [12/735], Loss: 1.1432\n",
      "Epoch [39/50], Step [13/735], Loss: 0.2215\n",
      "Epoch [39/50], Step [14/735], Loss: 1.0622\n",
      "Epoch [39/50], Step [15/735], Loss: 0.4782\n",
      "Epoch [39/50], Step [16/735], Loss: 0.2544\n",
      "Epoch [39/50], Step [17/735], Loss: 0.1098\n",
      "Epoch [39/50], Step [18/735], Loss: 0.3388\n",
      "Epoch [39/50], Step [19/735], Loss: 0.3428\n",
      "Epoch [39/50], Step [20/735], Loss: 0.1907\n",
      "Epoch [39/50], Step [21/735], Loss: 0.2840\n",
      "Epoch [39/50], Step [22/735], Loss: 0.2205\n",
      "Epoch [39/50], Step [23/735], Loss: 0.1259\n",
      "Epoch [39/50], Step [24/735], Loss: 0.1875\n",
      "Epoch [39/50], Step [25/735], Loss: 0.2328\n",
      "Epoch [39/50], Step [26/735], Loss: 0.2510\n",
      "Epoch [39/50], Step [27/735], Loss: 0.0957\n",
      "Epoch [39/50], Step [28/735], Loss: 0.7322\n",
      "Epoch [39/50], Step [29/735], Loss: 0.2160\n",
      "Epoch [39/50], Step [30/735], Loss: 0.3214\n",
      "Epoch [39/50], Step [31/735], Loss: 0.3722\n",
      "Epoch [39/50], Step [32/735], Loss: 0.1673\n",
      "Epoch [39/50], Step [33/735], Loss: 0.1557\n",
      "Epoch [39/50], Step [34/735], Loss: 0.0437\n",
      "Epoch [39/50], Step [35/735], Loss: 0.4054\n",
      "Epoch [39/50], Step [36/735], Loss: 0.1789\n",
      "Epoch [39/50], Step [37/735], Loss: 0.6563\n",
      "Epoch [39/50], Step [38/735], Loss: 0.2016\n",
      "Epoch [39/50], Step [39/735], Loss: 0.0718\n",
      "Epoch [39/50], Step [40/735], Loss: 0.5792\n",
      "Epoch [39/50], Step [41/735], Loss: 0.1640\n",
      "Epoch [39/50], Step [42/735], Loss: 0.1397\n",
      "Epoch [39/50], Step [43/735], Loss: 0.0555\n",
      "Epoch [39/50], Step [44/735], Loss: 0.2115\n",
      "Epoch [39/50], Step [45/735], Loss: 0.9016\n",
      "Epoch [39/50], Step [46/735], Loss: 0.2504\n",
      "Epoch [39/50], Step [47/735], Loss: 0.2662\n",
      "Epoch [39/50], Step [48/735], Loss: 0.2485\n",
      "Epoch [39/50], Step [49/735], Loss: 0.2552\n",
      "Epoch [39/50], Step [50/735], Loss: 0.3935\n",
      "Epoch [39/50], Step [51/735], Loss: 0.7814\n",
      "Epoch [39/50], Step [52/735], Loss: 0.0590\n",
      "Epoch [39/50], Step [53/735], Loss: 0.2774\n",
      "Epoch [39/50], Step [54/735], Loss: 0.3425\n",
      "Epoch [39/50], Step [55/735], Loss: 0.7764\n",
      "Epoch [39/50], Step [56/735], Loss: 0.1302\n",
      "Epoch [39/50], Step [57/735], Loss: 0.4415\n",
      "Epoch [39/50], Step [58/735], Loss: 0.2561\n",
      "Epoch [39/50], Step [59/735], Loss: 0.3112\n",
      "Epoch [39/50], Step [60/735], Loss: 0.1326\n",
      "Epoch [39/50], Step [61/735], Loss: 0.9555\n",
      "Epoch [39/50], Step [62/735], Loss: 0.4661\n",
      "Epoch [39/50], Step [63/735], Loss: 0.0386\n",
      "Epoch [39/50], Step [64/735], Loss: 0.2842\n",
      "Epoch [39/50], Step [65/735], Loss: 0.4618\n",
      "Epoch [39/50], Step [66/735], Loss: 0.2870\n",
      "Epoch [39/50], Step [67/735], Loss: 0.1804\n",
      "Epoch [39/50], Step [68/735], Loss: 0.2137\n",
      "Epoch [39/50], Step [69/735], Loss: 0.1880\n",
      "Epoch [39/50], Step [70/735], Loss: 0.3090\n",
      "Epoch [39/50], Step [71/735], Loss: 0.3669\n",
      "Epoch [39/50], Step [72/735], Loss: 0.4402\n",
      "Epoch [39/50], Step [73/735], Loss: 0.1275\n",
      "Epoch [39/50], Step [74/735], Loss: 0.1589\n",
      "Epoch [39/50], Step [75/735], Loss: 0.4780\n",
      "Epoch [39/50], Step [76/735], Loss: 0.2674\n",
      "Epoch [39/50], Step [77/735], Loss: 0.3145\n",
      "Epoch [39/50], Step [78/735], Loss: 0.3910\n",
      "Epoch [39/50], Step [79/735], Loss: 0.5775\n",
      "Epoch [39/50], Step [80/735], Loss: 0.2041\n",
      "Epoch [39/50], Step [81/735], Loss: 0.8828\n",
      "Epoch [39/50], Step [82/735], Loss: 0.6477\n",
      "Epoch [39/50], Step [83/735], Loss: 0.1108\n",
      "Epoch [39/50], Step [84/735], Loss: 0.4130\n",
      "Epoch [39/50], Step [85/735], Loss: 0.2269\n",
      "Epoch [39/50], Step [86/735], Loss: 0.1493\n",
      "Epoch [39/50], Step [87/735], Loss: 0.1946\n",
      "Epoch [39/50], Step [88/735], Loss: 0.3365\n",
      "Epoch [39/50], Step [89/735], Loss: 0.2893\n",
      "Epoch [39/50], Step [90/735], Loss: 0.3271\n",
      "Epoch [39/50], Step [91/735], Loss: 0.2329\n",
      "Epoch [39/50], Step [92/735], Loss: 0.1756\n",
      "Epoch [39/50], Step [93/735], Loss: 0.1566\n",
      "Epoch [39/50], Step [94/735], Loss: 0.1487\n",
      "Epoch [39/50], Step [95/735], Loss: 0.2443\n",
      "Epoch [39/50], Step [96/735], Loss: 0.2411\n",
      "Epoch [39/50], Step [97/735], Loss: 0.4149\n",
      "Epoch [39/50], Step [98/735], Loss: 0.2192\n",
      "Epoch [39/50], Step [99/735], Loss: 0.3319\n",
      "Epoch [39/50], Step [100/735], Loss: 0.4156\n",
      "Epoch [39/50], Step [101/735], Loss: 0.3548\n",
      "Epoch [39/50], Step [102/735], Loss: 0.3516\n",
      "Epoch [39/50], Step [103/735], Loss: 0.3654\n",
      "Epoch [39/50], Step [104/735], Loss: 0.3418\n",
      "Epoch [39/50], Step [105/735], Loss: 0.1123\n",
      "Epoch [39/50], Step [106/735], Loss: 0.2243\n",
      "Epoch [39/50], Step [107/735], Loss: 0.2392\n",
      "Epoch [39/50], Step [108/735], Loss: 0.1997\n",
      "Epoch [39/50], Step [109/735], Loss: 0.1293\n",
      "Epoch [39/50], Step [110/735], Loss: 0.1968\n",
      "Epoch [39/50], Step [111/735], Loss: 0.4430\n",
      "Epoch [39/50], Step [112/735], Loss: 0.4799\n",
      "Epoch [39/50], Step [113/735], Loss: 0.3343\n",
      "Epoch [39/50], Step [114/735], Loss: 0.2286\n",
      "Epoch [39/50], Step [115/735], Loss: 0.2249\n",
      "Epoch [39/50], Step [116/735], Loss: 0.4741\n",
      "Epoch [39/50], Step [117/735], Loss: 0.1617\n",
      "Epoch [39/50], Step [118/735], Loss: 1.5411\n",
      "Epoch [39/50], Step [119/735], Loss: 0.3907\n",
      "Epoch [39/50], Step [120/735], Loss: 0.3237\n",
      "Epoch [39/50], Step [121/735], Loss: 0.2991\n",
      "Epoch [39/50], Step [122/735], Loss: 0.1767\n",
      "Epoch [39/50], Step [123/735], Loss: 0.6754\n",
      "Epoch [39/50], Step [124/735], Loss: 0.2296\n",
      "Epoch [39/50], Step [125/735], Loss: 0.7385\n",
      "Epoch [39/50], Step [126/735], Loss: 0.4879\n",
      "Epoch [39/50], Step [127/735], Loss: 0.1848\n",
      "Epoch [39/50], Step [128/735], Loss: 0.2733\n",
      "Epoch [39/50], Step [129/735], Loss: 0.2823\n",
      "Epoch [39/50], Step [130/735], Loss: 0.9453\n",
      "Epoch [39/50], Step [131/735], Loss: 0.3909\n",
      "Epoch [39/50], Step [132/735], Loss: 0.1386\n",
      "Epoch [39/50], Step [133/735], Loss: 0.2367\n",
      "Epoch [39/50], Step [134/735], Loss: 0.6231\n",
      "Epoch [39/50], Step [135/735], Loss: 0.1271\n",
      "Epoch [39/50], Step [136/735], Loss: 0.1071\n",
      "Epoch [39/50], Step [137/735], Loss: 0.3587\n",
      "Epoch [39/50], Step [138/735], Loss: 0.4097\n",
      "Epoch [39/50], Step [139/735], Loss: 0.2451\n",
      "Epoch [39/50], Step [140/735], Loss: 0.2374\n",
      "Epoch [39/50], Step [141/735], Loss: 0.0587\n",
      "Epoch [39/50], Step [142/735], Loss: 0.7366\n",
      "Epoch [39/50], Step [143/735], Loss: 0.2948\n",
      "Epoch [39/50], Step [144/735], Loss: 0.4554\n",
      "Epoch [39/50], Step [145/735], Loss: 0.0968\n",
      "Epoch [39/50], Step [146/735], Loss: 0.2850\n",
      "Epoch [39/50], Step [147/735], Loss: 0.1810\n",
      "Epoch [39/50], Step [148/735], Loss: 0.1594\n",
      "Epoch [39/50], Step [149/735], Loss: 0.1327\n",
      "Epoch [39/50], Step [150/735], Loss: 0.3195\n",
      "Epoch [39/50], Step [151/735], Loss: 0.1941\n",
      "Epoch [39/50], Step [152/735], Loss: 0.1526\n",
      "Epoch [39/50], Step [153/735], Loss: 0.0939\n",
      "Epoch [39/50], Step [154/735], Loss: 0.2594\n",
      "Epoch [39/50], Step [155/735], Loss: 0.3431\n",
      "Epoch [39/50], Step [156/735], Loss: 0.1648\n",
      "Epoch [39/50], Step [157/735], Loss: 0.2627\n",
      "Epoch [39/50], Step [158/735], Loss: 0.2563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Step [159/735], Loss: 0.3949\n",
      "Epoch [39/50], Step [160/735], Loss: 0.3742\n",
      "Epoch [39/50], Step [161/735], Loss: 0.1523\n",
      "Epoch [39/50], Step [162/735], Loss: 0.2675\n",
      "Epoch [39/50], Step [163/735], Loss: 0.0677\n",
      "Epoch [39/50], Step [164/735], Loss: 0.7488\n",
      "Epoch [39/50], Step [165/735], Loss: 0.1340\n",
      "Epoch [39/50], Step [166/735], Loss: 0.7102\n",
      "Epoch [39/50], Step [167/735], Loss: 0.2136\n",
      "Epoch [39/50], Step [168/735], Loss: 0.0886\n",
      "Epoch [39/50], Step [169/735], Loss: 0.3015\n",
      "Epoch [39/50], Step [170/735], Loss: 0.2345\n",
      "Epoch [39/50], Step [171/735], Loss: 0.2230\n",
      "Epoch [39/50], Step [172/735], Loss: 0.1480\n",
      "Epoch [39/50], Step [173/735], Loss: 0.1679\n",
      "Epoch [39/50], Step [174/735], Loss: 0.1412\n",
      "Epoch [39/50], Step [175/735], Loss: 0.3334\n",
      "Epoch [39/50], Step [176/735], Loss: 0.2022\n",
      "Epoch [39/50], Step [177/735], Loss: 0.1107\n",
      "Epoch [39/50], Step [178/735], Loss: 0.4937\n",
      "Epoch [39/50], Step [179/735], Loss: 0.2295\n",
      "Epoch [39/50], Step [180/735], Loss: 0.1955\n",
      "Epoch [39/50], Step [181/735], Loss: 3.4041\n",
      "Epoch [39/50], Step [182/735], Loss: 0.4830\n",
      "Epoch [39/50], Step [183/735], Loss: 0.2176\n",
      "Epoch [39/50], Step [184/735], Loss: 0.1194\n",
      "Epoch [39/50], Step [185/735], Loss: 0.3914\n",
      "Epoch [39/50], Step [186/735], Loss: 0.4338\n",
      "Epoch [39/50], Step [187/735], Loss: 0.1772\n",
      "Epoch [39/50], Step [188/735], Loss: 0.2280\n",
      "Epoch [39/50], Step [189/735], Loss: 0.1849\n",
      "Epoch [39/50], Step [190/735], Loss: 0.0738\n",
      "Epoch [39/50], Step [191/735], Loss: 0.1667\n",
      "Epoch [39/50], Step [192/735], Loss: 0.0607\n",
      "Epoch [39/50], Step [193/735], Loss: 0.1491\n",
      "Epoch [39/50], Step [194/735], Loss: 0.2076\n",
      "Epoch [39/50], Step [195/735], Loss: 0.2172\n",
      "Epoch [39/50], Step [196/735], Loss: 0.2403\n",
      "Epoch [39/50], Step [197/735], Loss: 0.4082\n",
      "Epoch [39/50], Step [198/735], Loss: 0.5841\n",
      "Epoch [39/50], Step [199/735], Loss: 0.0993\n",
      "Epoch [39/50], Step [200/735], Loss: 0.2155\n",
      "Epoch [39/50], Step [201/735], Loss: 0.2584\n",
      "Epoch [39/50], Step [202/735], Loss: 0.3582\n",
      "Epoch [39/50], Step [203/735], Loss: 0.1168\n",
      "Epoch [39/50], Step [204/735], Loss: 0.3780\n",
      "Epoch [39/50], Step [205/735], Loss: 0.2870\n",
      "Epoch [39/50], Step [206/735], Loss: 0.1397\n",
      "Epoch [39/50], Step [207/735], Loss: 0.2394\n",
      "Epoch [39/50], Step [208/735], Loss: 0.3611\n",
      "Epoch [39/50], Step [209/735], Loss: 0.1959\n",
      "Epoch [39/50], Step [210/735], Loss: 0.3457\n",
      "Epoch [39/50], Step [211/735], Loss: 0.5071\n",
      "Epoch [39/50], Step [212/735], Loss: 0.6241\n",
      "Epoch [39/50], Step [213/735], Loss: 0.1403\n",
      "Epoch [39/50], Step [214/735], Loss: 0.2412\n",
      "Epoch [39/50], Step [215/735], Loss: 0.2689\n",
      "Epoch [39/50], Step [216/735], Loss: 0.1674\n",
      "Epoch [39/50], Step [217/735], Loss: 3.1330\n",
      "Epoch [39/50], Step [218/735], Loss: 0.0803\n",
      "Epoch [39/50], Step [219/735], Loss: 0.8929\n",
      "Epoch [39/50], Step [220/735], Loss: 0.0767\n",
      "Epoch [39/50], Step [221/735], Loss: 1.2527\n",
      "Epoch [39/50], Step [222/735], Loss: 0.2460\n",
      "Epoch [39/50], Step [223/735], Loss: 0.1289\n",
      "Epoch [39/50], Step [224/735], Loss: 0.4008\n",
      "Epoch [39/50], Step [225/735], Loss: 0.7166\n",
      "Epoch [39/50], Step [226/735], Loss: 0.2535\n",
      "Epoch [39/50], Step [227/735], Loss: 0.0799\n",
      "Epoch [39/50], Step [228/735], Loss: 0.8092\n",
      "Epoch [39/50], Step [229/735], Loss: 0.2684\n",
      "Epoch [39/50], Step [230/735], Loss: 0.1082\n",
      "Epoch [39/50], Step [231/735], Loss: 0.1441\n",
      "Epoch [39/50], Step [232/735], Loss: 0.1100\n",
      "Epoch [39/50], Step [233/735], Loss: 0.1681\n",
      "Epoch [39/50], Step [234/735], Loss: 0.1792\n",
      "Epoch [39/50], Step [235/735], Loss: 0.3371\n",
      "Epoch [39/50], Step [236/735], Loss: 0.2062\n",
      "Epoch [39/50], Step [237/735], Loss: 0.3969\n",
      "Epoch [39/50], Step [238/735], Loss: 0.2165\n",
      "Epoch [39/50], Step [239/735], Loss: 0.1860\n",
      "Epoch [39/50], Step [240/735], Loss: 0.3634\n",
      "Epoch [39/50], Step [241/735], Loss: 0.2973\n",
      "Epoch [39/50], Step [242/735], Loss: 0.3601\n",
      "Epoch [39/50], Step [243/735], Loss: 0.2116\n",
      "Epoch [39/50], Step [244/735], Loss: 0.3460\n",
      "Epoch [39/50], Step [245/735], Loss: 0.9270\n",
      "Epoch [39/50], Step [246/735], Loss: 0.2003\n",
      "Epoch [39/50], Step [247/735], Loss: 0.3366\n",
      "Epoch [39/50], Step [248/735], Loss: 0.2168\n",
      "Epoch [39/50], Step [249/735], Loss: 0.2476\n",
      "Epoch [39/50], Step [250/735], Loss: 0.2439\n",
      "Epoch [39/50], Step [251/735], Loss: 0.1487\n",
      "Epoch [39/50], Step [252/735], Loss: 0.2690\n",
      "Epoch [39/50], Step [253/735], Loss: 0.0804\n",
      "Epoch [39/50], Step [254/735], Loss: 0.1719\n",
      "Epoch [39/50], Step [255/735], Loss: 0.9993\n",
      "Epoch [39/50], Step [256/735], Loss: 0.1740\n",
      "Epoch [39/50], Step [257/735], Loss: 0.3285\n",
      "Epoch [39/50], Step [258/735], Loss: 0.1094\n",
      "Epoch [39/50], Step [259/735], Loss: 0.4179\n",
      "Epoch [39/50], Step [260/735], Loss: 0.3618\n",
      "Epoch [39/50], Step [261/735], Loss: 0.0753\n",
      "Epoch [39/50], Step [262/735], Loss: 0.2903\n",
      "Epoch [39/50], Step [263/735], Loss: 0.3929\n",
      "Epoch [39/50], Step [264/735], Loss: 0.9654\n",
      "Epoch [39/50], Step [265/735], Loss: 0.2451\n",
      "Epoch [39/50], Step [266/735], Loss: 0.2725\n",
      "Epoch [39/50], Step [267/735], Loss: 0.0716\n",
      "Epoch [39/50], Step [268/735], Loss: 0.3451\n",
      "Epoch [39/50], Step [269/735], Loss: 0.1812\n",
      "Epoch [39/50], Step [270/735], Loss: 0.1248\n",
      "Epoch [39/50], Step [271/735], Loss: 0.0860\n",
      "Epoch [39/50], Step [272/735], Loss: 0.7102\n",
      "Epoch [39/50], Step [273/735], Loss: 0.3816\n",
      "Epoch [39/50], Step [274/735], Loss: 0.4129\n",
      "Epoch [39/50], Step [275/735], Loss: 0.0936\n",
      "Epoch [39/50], Step [276/735], Loss: 0.7888\n",
      "Epoch [39/50], Step [277/735], Loss: 0.4475\n",
      "Epoch [39/50], Step [278/735], Loss: 0.2642\n",
      "Epoch [39/50], Step [279/735], Loss: 0.6573\n",
      "Epoch [39/50], Step [280/735], Loss: 0.1649\n",
      "Epoch [39/50], Step [281/735], Loss: 0.1561\n",
      "Epoch [39/50], Step [282/735], Loss: 0.0901\n",
      "Epoch [39/50], Step [283/735], Loss: 0.2863\n",
      "Epoch [39/50], Step [284/735], Loss: 0.1410\n",
      "Epoch [39/50], Step [285/735], Loss: 0.3378\n",
      "Epoch [39/50], Step [286/735], Loss: 0.4532\n",
      "Epoch [39/50], Step [287/735], Loss: 0.2923\n",
      "Epoch [39/50], Step [288/735], Loss: 0.1170\n",
      "Epoch [39/50], Step [289/735], Loss: 0.4052\n",
      "Epoch [39/50], Step [290/735], Loss: 0.0924\n",
      "Epoch [39/50], Step [291/735], Loss: 0.2761\n",
      "Epoch [39/50], Step [292/735], Loss: 0.2363\n",
      "Epoch [39/50], Step [293/735], Loss: 0.3188\n",
      "Epoch [39/50], Step [294/735], Loss: 0.2031\n",
      "Epoch [39/50], Step [295/735], Loss: 0.1342\n",
      "Epoch [39/50], Step [296/735], Loss: 0.1391\n",
      "Epoch [39/50], Step [297/735], Loss: 0.1736\n",
      "Epoch [39/50], Step [298/735], Loss: 0.2421\n",
      "Epoch [39/50], Step [299/735], Loss: 0.2613\n",
      "Epoch [39/50], Step [300/735], Loss: 0.3406\n",
      "Epoch [39/50], Step [301/735], Loss: 0.2232\n",
      "Epoch [39/50], Step [302/735], Loss: 0.1514\n",
      "Epoch [39/50], Step [303/735], Loss: 0.4570\n",
      "Epoch [39/50], Step [304/735], Loss: 0.2209\n",
      "Epoch [39/50], Step [305/735], Loss: 0.1504\n",
      "Epoch [39/50], Step [306/735], Loss: 0.1740\n",
      "Epoch [39/50], Step [307/735], Loss: 0.3616\n",
      "Epoch [39/50], Step [308/735], Loss: 0.4298\n",
      "Epoch [39/50], Step [309/735], Loss: 0.5641\n",
      "Epoch [39/50], Step [310/735], Loss: 0.9291\n",
      "Epoch [39/50], Step [311/735], Loss: 1.1927\n",
      "Epoch [39/50], Step [312/735], Loss: 0.3027\n",
      "Epoch [39/50], Step [313/735], Loss: 0.0826\n",
      "Epoch [39/50], Step [314/735], Loss: 0.3608\n",
      "Epoch [39/50], Step [315/735], Loss: 0.4657\n",
      "Epoch [39/50], Step [316/735], Loss: 0.1039\n",
      "Epoch [39/50], Step [317/735], Loss: 0.6344\n",
      "Epoch [39/50], Step [318/735], Loss: 0.9347\n",
      "Epoch [39/50], Step [319/735], Loss: 0.3866\n",
      "Epoch [39/50], Step [320/735], Loss: 0.0571\n",
      "Epoch [39/50], Step [321/735], Loss: 0.2733\n",
      "Epoch [39/50], Step [322/735], Loss: 0.0795\n",
      "Epoch [39/50], Step [323/735], Loss: 0.1745\n",
      "Epoch [39/50], Step [324/735], Loss: 0.0632\n",
      "Epoch [39/50], Step [325/735], Loss: 0.2335\n",
      "Epoch [39/50], Step [326/735], Loss: 0.1503\n",
      "Epoch [39/50], Step [327/735], Loss: 0.3245\n",
      "Epoch [39/50], Step [328/735], Loss: 0.1308\n",
      "Epoch [39/50], Step [329/735], Loss: 0.2470\n",
      "Epoch [39/50], Step [330/735], Loss: 0.2288\n",
      "Epoch [39/50], Step [331/735], Loss: 0.3976\n",
      "Epoch [39/50], Step [332/735], Loss: 0.2356\n",
      "Epoch [39/50], Step [333/735], Loss: 0.2200\n",
      "Epoch [39/50], Step [334/735], Loss: 0.3107\n",
      "Epoch [39/50], Step [335/735], Loss: 0.3278\n",
      "Epoch [39/50], Step [336/735], Loss: 0.0763\n",
      "Epoch [39/50], Step [337/735], Loss: 0.2077\n",
      "Epoch [39/50], Step [338/735], Loss: 0.1367\n",
      "Epoch [39/50], Step [339/735], Loss: 0.1713\n",
      "Epoch [39/50], Step [340/735], Loss: 0.2992\n",
      "Epoch [39/50], Step [341/735], Loss: 0.2604\n",
      "Epoch [39/50], Step [342/735], Loss: 0.4705\n",
      "Epoch [39/50], Step [343/735], Loss: 0.1406\n",
      "Epoch [39/50], Step [344/735], Loss: 0.4137\n",
      "Epoch [39/50], Step [345/735], Loss: 0.8341\n",
      "Epoch [39/50], Step [346/735], Loss: 0.5286\n",
      "Epoch [39/50], Step [347/735], Loss: 0.5174\n",
      "Epoch [39/50], Step [348/735], Loss: 0.5145\n",
      "Epoch [39/50], Step [349/735], Loss: 0.5192\n",
      "Epoch [39/50], Step [350/735], Loss: 0.1540\n",
      "Epoch [39/50], Step [351/735], Loss: 0.0681\n",
      "Epoch [39/50], Step [352/735], Loss: 0.1462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Step [353/735], Loss: 0.2724\n",
      "Epoch [39/50], Step [354/735], Loss: 0.3412\n",
      "Epoch [39/50], Step [355/735], Loss: 0.1330\n",
      "Epoch [39/50], Step [356/735], Loss: 0.3889\n",
      "Epoch [39/50], Step [357/735], Loss: 0.1116\n",
      "Epoch [39/50], Step [358/735], Loss: 0.3347\n",
      "Epoch [39/50], Step [359/735], Loss: 0.2208\n",
      "Epoch [39/50], Step [360/735], Loss: 0.2069\n",
      "Epoch [39/50], Step [361/735], Loss: 1.0158\n",
      "Epoch [39/50], Step [362/735], Loss: 0.1530\n",
      "Epoch [39/50], Step [363/735], Loss: 0.4049\n",
      "Epoch [39/50], Step [364/735], Loss: 0.3910\n",
      "Epoch [39/50], Step [365/735], Loss: 0.1538\n",
      "Epoch [39/50], Step [366/735], Loss: 0.1629\n",
      "Epoch [39/50], Step [367/735], Loss: 0.5045\n",
      "Epoch [39/50], Step [368/735], Loss: 0.2572\n",
      "Epoch [39/50], Step [369/735], Loss: 0.4737\n",
      "Epoch [39/50], Step [370/735], Loss: 0.0837\n",
      "Epoch [39/50], Step [371/735], Loss: 0.3939\n",
      "Epoch [39/50], Step [372/735], Loss: 0.0719\n",
      "Epoch [39/50], Step [373/735], Loss: 0.3143\n",
      "Epoch [39/50], Step [374/735], Loss: 0.2652\n",
      "Epoch [39/50], Step [375/735], Loss: 0.8675\n",
      "Epoch [39/50], Step [376/735], Loss: 0.3868\n",
      "Epoch [39/50], Step [377/735], Loss: 0.2899\n",
      "Epoch [39/50], Step [378/735], Loss: 0.1300\n",
      "Epoch [39/50], Step [379/735], Loss: 0.3602\n",
      "Epoch [39/50], Step [380/735], Loss: 0.3155\n",
      "Epoch [39/50], Step [381/735], Loss: 0.3250\n",
      "Epoch [39/50], Step [382/735], Loss: 0.1464\n",
      "Epoch [39/50], Step [383/735], Loss: 0.1688\n",
      "Epoch [39/50], Step [384/735], Loss: 0.3284\n",
      "Epoch [39/50], Step [385/735], Loss: 0.4526\n",
      "Epoch [39/50], Step [386/735], Loss: 0.0751\n",
      "Epoch [39/50], Step [387/735], Loss: 0.1103\n",
      "Epoch [39/50], Step [388/735], Loss: 0.1320\n",
      "Epoch [39/50], Step [389/735], Loss: 0.5201\n",
      "Epoch [39/50], Step [390/735], Loss: 0.2701\n",
      "Epoch [39/50], Step [391/735], Loss: 0.3189\n",
      "Epoch [39/50], Step [392/735], Loss: 0.1619\n",
      "Epoch [39/50], Step [393/735], Loss: 0.2157\n",
      "Epoch [39/50], Step [394/735], Loss: 0.2458\n",
      "Epoch [39/50], Step [395/735], Loss: 0.9209\n",
      "Epoch [39/50], Step [396/735], Loss: 0.1415\n",
      "Epoch [39/50], Step [397/735], Loss: 0.3163\n",
      "Epoch [39/50], Step [398/735], Loss: 0.2647\n",
      "Epoch [39/50], Step [399/735], Loss: 0.5445\n",
      "Epoch [39/50], Step [400/735], Loss: 0.5349\n",
      "Epoch [39/50], Step [401/735], Loss: 0.4723\n",
      "Epoch [39/50], Step [402/735], Loss: 0.0374\n",
      "Epoch [39/50], Step [403/735], Loss: 0.1830\n",
      "Epoch [39/50], Step [404/735], Loss: 0.1579\n",
      "Epoch [39/50], Step [405/735], Loss: 0.1992\n",
      "Epoch [39/50], Step [406/735], Loss: 0.2952\n",
      "Epoch [39/50], Step [407/735], Loss: 0.2567\n",
      "Epoch [39/50], Step [408/735], Loss: 0.2179\n",
      "Epoch [39/50], Step [409/735], Loss: 0.1341\n",
      "Epoch [39/50], Step [410/735], Loss: 0.2283\n",
      "Epoch [39/50], Step [411/735], Loss: 0.4892\n",
      "Epoch [39/50], Step [412/735], Loss: 0.1067\n",
      "Epoch [39/50], Step [413/735], Loss: 0.3590\n",
      "Epoch [39/50], Step [414/735], Loss: 0.1108\n",
      "Epoch [39/50], Step [415/735], Loss: 3.3393\n",
      "Epoch [39/50], Step [416/735], Loss: 0.3540\n",
      "Epoch [39/50], Step [417/735], Loss: 0.4628\n",
      "Epoch [39/50], Step [418/735], Loss: 0.1516\n",
      "Epoch [39/50], Step [419/735], Loss: 0.2044\n",
      "Epoch [39/50], Step [420/735], Loss: 0.7129\n",
      "Epoch [39/50], Step [421/735], Loss: 0.5694\n",
      "Epoch [39/50], Step [422/735], Loss: 0.1117\n",
      "Epoch [39/50], Step [423/735], Loss: 0.5786\n",
      "Epoch [39/50], Step [424/735], Loss: 0.3896\n",
      "Epoch [39/50], Step [425/735], Loss: 0.1428\n",
      "Epoch [39/50], Step [426/735], Loss: 0.2730\n",
      "Epoch [39/50], Step [427/735], Loss: 0.1870\n",
      "Epoch [39/50], Step [428/735], Loss: 0.3213\n",
      "Epoch [39/50], Step [429/735], Loss: 0.1399\n",
      "Epoch [39/50], Step [430/735], Loss: 0.3609\n",
      "Epoch [39/50], Step [431/735], Loss: 0.5932\n",
      "Epoch [39/50], Step [432/735], Loss: 0.5752\n",
      "Epoch [39/50], Step [433/735], Loss: 0.1722\n",
      "Epoch [39/50], Step [434/735], Loss: 0.1969\n",
      "Epoch [39/50], Step [435/735], Loss: 0.2042\n",
      "Epoch [39/50], Step [436/735], Loss: 0.1715\n",
      "Epoch [39/50], Step [437/735], Loss: 0.1913\n",
      "Epoch [39/50], Step [438/735], Loss: 0.2391\n",
      "Epoch [39/50], Step [439/735], Loss: 0.5882\n",
      "Epoch [39/50], Step [440/735], Loss: 0.4743\n",
      "Epoch [39/50], Step [441/735], Loss: 0.2243\n",
      "Epoch [39/50], Step [442/735], Loss: 0.3408\n",
      "Epoch [39/50], Step [443/735], Loss: 0.1367\n",
      "Epoch [39/50], Step [444/735], Loss: 0.2012\n",
      "Epoch [39/50], Step [445/735], Loss: 0.0675\n",
      "Epoch [39/50], Step [446/735], Loss: 0.2521\n",
      "Epoch [39/50], Step [447/735], Loss: 0.4604\n",
      "Epoch [39/50], Step [448/735], Loss: 0.2311\n",
      "Epoch [39/50], Step [449/735], Loss: 0.1325\n",
      "Epoch [39/50], Step [450/735], Loss: 0.6515\n",
      "Epoch [39/50], Step [451/735], Loss: 0.2971\n",
      "Epoch [39/50], Step [452/735], Loss: 0.3499\n",
      "Epoch [39/50], Step [453/735], Loss: 0.3781\n",
      "Epoch [39/50], Step [454/735], Loss: 0.4062\n",
      "Epoch [39/50], Step [455/735], Loss: 0.3752\n",
      "Epoch [39/50], Step [456/735], Loss: 0.3387\n",
      "Epoch [39/50], Step [457/735], Loss: 0.4593\n",
      "Epoch [39/50], Step [458/735], Loss: 0.2924\n",
      "Epoch [39/50], Step [459/735], Loss: 0.5095\n",
      "Epoch [39/50], Step [460/735], Loss: 0.8900\n",
      "Epoch [39/50], Step [461/735], Loss: 0.5344\n",
      "Epoch [39/50], Step [462/735], Loss: 0.4790\n",
      "Epoch [39/50], Step [463/735], Loss: 0.2616\n",
      "Epoch [39/50], Step [464/735], Loss: 0.1463\n",
      "Epoch [39/50], Step [465/735], Loss: 0.5032\n",
      "Epoch [39/50], Step [466/735], Loss: 0.5080\n",
      "Epoch [39/50], Step [467/735], Loss: 0.4408\n",
      "Epoch [39/50], Step [468/735], Loss: 0.3582\n",
      "Epoch [39/50], Step [469/735], Loss: 0.4517\n",
      "Epoch [39/50], Step [470/735], Loss: 0.7930\n",
      "Epoch [39/50], Step [471/735], Loss: 0.3924\n",
      "Epoch [39/50], Step [472/735], Loss: 0.2993\n",
      "Epoch [39/50], Step [473/735], Loss: 0.1264\n",
      "Epoch [39/50], Step [474/735], Loss: 0.1216\n",
      "Epoch [39/50], Step [475/735], Loss: 0.2012\n",
      "Epoch [39/50], Step [476/735], Loss: 0.4809\n",
      "Epoch [39/50], Step [477/735], Loss: 0.2202\n",
      "Epoch [39/50], Step [478/735], Loss: 0.3085\n",
      "Epoch [39/50], Step [479/735], Loss: 0.1894\n",
      "Epoch [39/50], Step [480/735], Loss: 0.1612\n",
      "Epoch [39/50], Step [481/735], Loss: 0.2963\n",
      "Epoch [39/50], Step [482/735], Loss: 0.3300\n",
      "Epoch [39/50], Step [483/735], Loss: 0.0903\n",
      "Epoch [39/50], Step [484/735], Loss: 0.2306\n",
      "Epoch [39/50], Step [485/735], Loss: 0.2819\n",
      "Epoch [39/50], Step [486/735], Loss: 0.0570\n",
      "Epoch [39/50], Step [487/735], Loss: 0.3562\n",
      "Epoch [39/50], Step [488/735], Loss: 0.1580\n",
      "Epoch [39/50], Step [489/735], Loss: 0.4232\n",
      "Epoch [39/50], Step [490/735], Loss: 0.5818\n",
      "Epoch [39/50], Step [491/735], Loss: 0.2236\n",
      "Epoch [39/50], Step [492/735], Loss: 0.2654\n",
      "Epoch [39/50], Step [493/735], Loss: 0.4564\n",
      "Epoch [39/50], Step [494/735], Loss: 0.2962\n",
      "Epoch [39/50], Step [495/735], Loss: 0.0845\n",
      "Epoch [39/50], Step [496/735], Loss: 0.5085\n",
      "Epoch [39/50], Step [497/735], Loss: 0.6491\n",
      "Epoch [39/50], Step [498/735], Loss: 0.1081\n",
      "Epoch [39/50], Step [499/735], Loss: 0.1614\n",
      "Epoch [39/50], Step [500/735], Loss: 0.2636\n",
      "Epoch [39/50], Step [501/735], Loss: 0.1538\n",
      "Epoch [39/50], Step [502/735], Loss: 0.2665\n",
      "Epoch [39/50], Step [503/735], Loss: 0.5629\n",
      "Epoch [39/50], Step [504/735], Loss: 0.0949\n",
      "Epoch [39/50], Step [505/735], Loss: 0.0548\n",
      "Epoch [39/50], Step [506/735], Loss: 0.2380\n",
      "Epoch [39/50], Step [507/735], Loss: 0.1786\n",
      "Epoch [39/50], Step [508/735], Loss: 0.2178\n",
      "Epoch [39/50], Step [509/735], Loss: 0.2722\n",
      "Epoch [39/50], Step [510/735], Loss: 0.2379\n",
      "Epoch [39/50], Step [511/735], Loss: 0.5467\n",
      "Epoch [39/50], Step [512/735], Loss: 0.1888\n",
      "Epoch [39/50], Step [513/735], Loss: 0.1621\n",
      "Epoch [39/50], Step [514/735], Loss: 0.2298\n",
      "Epoch [39/50], Step [515/735], Loss: 0.1602\n",
      "Epoch [39/50], Step [516/735], Loss: 0.0725\n",
      "Epoch [39/50], Step [517/735], Loss: 0.2007\n",
      "Epoch [39/50], Step [518/735], Loss: 0.0549\n",
      "Epoch [39/50], Step [519/735], Loss: 0.1907\n",
      "Epoch [39/50], Step [520/735], Loss: 0.1193\n",
      "Epoch [39/50], Step [521/735], Loss: 0.2073\n",
      "Epoch [39/50], Step [522/735], Loss: 0.1154\n",
      "Epoch [39/50], Step [523/735], Loss: 0.6363\n",
      "Epoch [39/50], Step [524/735], Loss: 0.0486\n",
      "Epoch [39/50], Step [525/735], Loss: 0.2361\n",
      "Epoch [39/50], Step [526/735], Loss: 0.2802\n",
      "Epoch [39/50], Step [527/735], Loss: 0.0902\n",
      "Epoch [39/50], Step [528/735], Loss: 0.3736\n",
      "Epoch [39/50], Step [529/735], Loss: 0.1144\n",
      "Epoch [39/50], Step [530/735], Loss: 0.1527\n",
      "Epoch [39/50], Step [531/735], Loss: 1.1563\n",
      "Epoch [39/50], Step [532/735], Loss: 0.1235\n",
      "Epoch [39/50], Step [533/735], Loss: 0.5085\n",
      "Epoch [39/50], Step [534/735], Loss: 0.2520\n",
      "Epoch [39/50], Step [535/735], Loss: 0.1725\n",
      "Epoch [39/50], Step [536/735], Loss: 0.1815\n",
      "Epoch [39/50], Step [537/735], Loss: 0.2372\n",
      "Epoch [39/50], Step [538/735], Loss: 0.0951\n",
      "Epoch [39/50], Step [539/735], Loss: 0.2272\n",
      "Epoch [39/50], Step [540/735], Loss: 0.2512\n",
      "Epoch [39/50], Step [541/735], Loss: 0.3665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Step [542/735], Loss: 0.1430\n",
      "Epoch [39/50], Step [543/735], Loss: 0.1899\n",
      "Epoch [39/50], Step [544/735], Loss: 0.1473\n",
      "Epoch [39/50], Step [545/735], Loss: 0.1295\n",
      "Epoch [39/50], Step [546/735], Loss: 2.9827\n",
      "Epoch [39/50], Step [547/735], Loss: 0.4170\n",
      "Epoch [39/50], Step [548/735], Loss: 0.8315\n",
      "Epoch [39/50], Step [549/735], Loss: 0.3595\n",
      "Epoch [39/50], Step [550/735], Loss: 0.4325\n",
      "Epoch [39/50], Step [551/735], Loss: 0.2503\n",
      "Epoch [39/50], Step [552/735], Loss: 0.1204\n",
      "Epoch [39/50], Step [553/735], Loss: 0.2093\n",
      "Epoch [39/50], Step [554/735], Loss: 0.0756\n",
      "Epoch [39/50], Step [555/735], Loss: 0.3113\n",
      "Epoch [39/50], Step [556/735], Loss: 2.7175\n",
      "Epoch [39/50], Step [557/735], Loss: 0.0670\n",
      "Epoch [39/50], Step [558/735], Loss: 0.3165\n",
      "Epoch [39/50], Step [559/735], Loss: 0.2356\n",
      "Epoch [39/50], Step [560/735], Loss: 0.3912\n",
      "Epoch [39/50], Step [561/735], Loss: 0.1201\n",
      "Epoch [39/50], Step [562/735], Loss: 0.3427\n",
      "Epoch [39/50], Step [563/735], Loss: 0.2465\n",
      "Epoch [39/50], Step [564/735], Loss: 0.2902\n",
      "Epoch [39/50], Step [565/735], Loss: 0.7084\n",
      "Epoch [39/50], Step [566/735], Loss: 0.3603\n",
      "Epoch [39/50], Step [567/735], Loss: 0.2297\n",
      "Epoch [39/50], Step [568/735], Loss: 0.1225\n",
      "Epoch [39/50], Step [569/735], Loss: 0.3941\n",
      "Epoch [39/50], Step [570/735], Loss: 0.1846\n",
      "Epoch [39/50], Step [571/735], Loss: 0.3436\n",
      "Epoch [39/50], Step [572/735], Loss: 0.1322\n",
      "Epoch [39/50], Step [573/735], Loss: 0.2510\n",
      "Epoch [39/50], Step [574/735], Loss: 0.0838\n",
      "Epoch [39/50], Step [575/735], Loss: 0.5794\n",
      "Epoch [39/50], Step [576/735], Loss: 0.0914\n",
      "Epoch [39/50], Step [577/735], Loss: 0.1883\n",
      "Epoch [39/50], Step [578/735], Loss: 0.0734\n",
      "Epoch [39/50], Step [579/735], Loss: 0.2428\n",
      "Epoch [39/50], Step [580/735], Loss: 0.1935\n",
      "Epoch [39/50], Step [581/735], Loss: 0.2142\n",
      "Epoch [39/50], Step [582/735], Loss: 0.1683\n",
      "Epoch [39/50], Step [583/735], Loss: 0.4911\n",
      "Epoch [39/50], Step [584/735], Loss: 0.3132\n",
      "Epoch [39/50], Step [585/735], Loss: 0.2311\n",
      "Epoch [39/50], Step [586/735], Loss: 0.4924\n",
      "Epoch [39/50], Step [587/735], Loss: 0.3177\n",
      "Epoch [39/50], Step [588/735], Loss: 0.2710\n",
      "Epoch [39/50], Step [589/735], Loss: 0.4346\n",
      "Epoch [39/50], Step [590/735], Loss: 0.1349\n",
      "Epoch [39/50], Step [591/735], Loss: 0.1907\n",
      "Epoch [39/50], Step [592/735], Loss: 0.2556\n",
      "Epoch [39/50], Step [593/735], Loss: 0.1950\n",
      "Epoch [39/50], Step [594/735], Loss: 0.7149\n",
      "Epoch [39/50], Step [595/735], Loss: 0.5042\n",
      "Epoch [39/50], Step [596/735], Loss: 0.7114\n",
      "Epoch [39/50], Step [597/735], Loss: 0.3277\n",
      "Epoch [39/50], Step [598/735], Loss: 0.3303\n",
      "Epoch [39/50], Step [599/735], Loss: 0.0832\n",
      "Epoch [39/50], Step [600/735], Loss: 0.1107\n",
      "Epoch [39/50], Step [601/735], Loss: 0.4088\n",
      "Epoch [39/50], Step [602/735], Loss: 0.3683\n",
      "Epoch [39/50], Step [603/735], Loss: 0.3147\n",
      "Epoch [39/50], Step [604/735], Loss: 0.2965\n",
      "Epoch [39/50], Step [605/735], Loss: 0.2667\n",
      "Epoch [39/50], Step [606/735], Loss: 0.1287\n",
      "Epoch [39/50], Step [607/735], Loss: 0.1738\n",
      "Epoch [39/50], Step [608/735], Loss: 0.4767\n",
      "Epoch [39/50], Step [609/735], Loss: 0.3258\n",
      "Epoch [39/50], Step [610/735], Loss: 0.5608\n",
      "Epoch [39/50], Step [611/735], Loss: 0.2777\n",
      "Epoch [39/50], Step [612/735], Loss: 0.3058\n",
      "Epoch [39/50], Step [613/735], Loss: 0.1322\n",
      "Epoch [39/50], Step [614/735], Loss: 0.2041\n",
      "Epoch [39/50], Step [615/735], Loss: 0.0470\n",
      "Epoch [39/50], Step [616/735], Loss: 0.1289\n",
      "Epoch [39/50], Step [617/735], Loss: 0.3368\n",
      "Epoch [39/50], Step [618/735], Loss: 0.1429\n",
      "Epoch [39/50], Step [619/735], Loss: 0.2276\n",
      "Epoch [39/50], Step [620/735], Loss: 0.2252\n",
      "Epoch [39/50], Step [621/735], Loss: 0.5175\n",
      "Epoch [39/50], Step [622/735], Loss: 0.3815\n",
      "Epoch [39/50], Step [623/735], Loss: 0.2022\n",
      "Epoch [39/50], Step [624/735], Loss: 0.0902\n",
      "Epoch [39/50], Step [625/735], Loss: 0.0606\n",
      "Epoch [39/50], Step [626/735], Loss: 0.1039\n",
      "Epoch [39/50], Step [627/735], Loss: 0.4176\n",
      "Epoch [39/50], Step [628/735], Loss: 0.1945\n",
      "Epoch [39/50], Step [629/735], Loss: 0.2066\n",
      "Epoch [39/50], Step [630/735], Loss: 0.4132\n",
      "Epoch [39/50], Step [631/735], Loss: 0.9309\n",
      "Epoch [39/50], Step [632/735], Loss: 0.1843\n",
      "Epoch [39/50], Step [633/735], Loss: 0.1526\n",
      "Epoch [39/50], Step [634/735], Loss: 0.1818\n",
      "Epoch [39/50], Step [635/735], Loss: 0.5423\n",
      "Epoch [39/50], Step [636/735], Loss: 0.0786\n",
      "Epoch [39/50], Step [637/735], Loss: 0.2090\n",
      "Epoch [39/50], Step [638/735], Loss: 0.3303\n",
      "Epoch [39/50], Step [639/735], Loss: 0.0868\n",
      "Epoch [39/50], Step [640/735], Loss: 0.1671\n",
      "Epoch [39/50], Step [641/735], Loss: 0.2090\n",
      "Epoch [39/50], Step [642/735], Loss: 1.0158\n",
      "Epoch [39/50], Step [643/735], Loss: 0.5131\n",
      "Epoch [39/50], Step [644/735], Loss: 0.8868\n",
      "Epoch [39/50], Step [645/735], Loss: 0.0917\n",
      "Epoch [39/50], Step [646/735], Loss: 0.1203\n",
      "Epoch [39/50], Step [647/735], Loss: 0.1619\n",
      "Epoch [39/50], Step [648/735], Loss: 0.2842\n",
      "Epoch [39/50], Step [649/735], Loss: 0.2155\n",
      "Epoch [39/50], Step [650/735], Loss: 0.2217\n",
      "Epoch [39/50], Step [651/735], Loss: 0.0584\n",
      "Epoch [39/50], Step [652/735], Loss: 0.1818\n",
      "Epoch [39/50], Step [653/735], Loss: 0.2035\n",
      "Epoch [39/50], Step [654/735], Loss: 0.1815\n",
      "Epoch [39/50], Step [655/735], Loss: 0.4264\n",
      "Epoch [39/50], Step [656/735], Loss: 0.2303\n",
      "Epoch [39/50], Step [657/735], Loss: 0.0940\n",
      "Epoch [39/50], Step [658/735], Loss: 0.9606\n",
      "Epoch [39/50], Step [659/735], Loss: 0.3186\n",
      "Epoch [39/50], Step [660/735], Loss: 0.6201\n",
      "Epoch [39/50], Step [661/735], Loss: 0.0995\n",
      "Epoch [39/50], Step [662/735], Loss: 0.1568\n",
      "Epoch [39/50], Step [663/735], Loss: 0.1293\n",
      "Epoch [39/50], Step [664/735], Loss: 0.4143\n",
      "Epoch [39/50], Step [665/735], Loss: 1.4146\n",
      "Epoch [39/50], Step [666/735], Loss: 0.4535\n",
      "Epoch [39/50], Step [667/735], Loss: 0.8446\n",
      "Epoch [39/50], Step [668/735], Loss: 0.1640\n",
      "Epoch [39/50], Step [669/735], Loss: 0.3816\n",
      "Epoch [39/50], Step [670/735], Loss: 0.2097\n",
      "Epoch [39/50], Step [671/735], Loss: 0.2626\n",
      "Epoch [39/50], Step [672/735], Loss: 0.3403\n",
      "Epoch [39/50], Step [673/735], Loss: 0.0734\n",
      "Epoch [39/50], Step [674/735], Loss: 0.3020\n",
      "Epoch [39/50], Step [675/735], Loss: 0.6919\n",
      "Epoch [39/50], Step [676/735], Loss: 0.1252\n",
      "Epoch [39/50], Step [677/735], Loss: 0.3666\n",
      "Epoch [39/50], Step [678/735], Loss: 0.3409\n",
      "Epoch [39/50], Step [679/735], Loss: 0.3268\n",
      "Epoch [39/50], Step [680/735], Loss: 0.2594\n",
      "Epoch [39/50], Step [681/735], Loss: 0.1999\n",
      "Epoch [39/50], Step [682/735], Loss: 0.1663\n",
      "Epoch [39/50], Step [683/735], Loss: 0.2267\n",
      "Epoch [39/50], Step [684/735], Loss: 0.1230\n",
      "Epoch [39/50], Step [685/735], Loss: 0.2747\n",
      "Epoch [39/50], Step [686/735], Loss: 0.2034\n",
      "Epoch [39/50], Step [687/735], Loss: 0.6286\n",
      "Epoch [39/50], Step [688/735], Loss: 0.1496\n",
      "Epoch [39/50], Step [689/735], Loss: 0.6940\n",
      "Epoch [39/50], Step [690/735], Loss: 0.2537\n",
      "Epoch [39/50], Step [691/735], Loss: 0.0824\n",
      "Epoch [39/50], Step [692/735], Loss: 0.1941\n",
      "Epoch [39/50], Step [693/735], Loss: 0.3379\n",
      "Epoch [39/50], Step [694/735], Loss: 0.1022\n",
      "Epoch [39/50], Step [695/735], Loss: 0.1648\n",
      "Epoch [39/50], Step [696/735], Loss: 0.3925\n",
      "Epoch [39/50], Step [697/735], Loss: 0.2180\n",
      "Epoch [39/50], Step [698/735], Loss: 0.2963\n",
      "Epoch [39/50], Step [699/735], Loss: 0.2012\n",
      "Epoch [39/50], Step [700/735], Loss: 0.1829\n",
      "Epoch [39/50], Step [701/735], Loss: 0.7470\n",
      "Epoch [39/50], Step [702/735], Loss: 0.8739\n",
      "Epoch [39/50], Step [703/735], Loss: 0.7187\n",
      "Epoch [39/50], Step [704/735], Loss: 0.4082\n",
      "Epoch [39/50], Step [705/735], Loss: 0.1733\n",
      "Epoch [39/50], Step [706/735], Loss: 0.1834\n",
      "Epoch [39/50], Step [707/735], Loss: 0.0695\n",
      "Epoch [39/50], Step [708/735], Loss: 0.1651\n",
      "Epoch [39/50], Step [709/735], Loss: 0.0742\n",
      "Epoch [39/50], Step [710/735], Loss: 0.1864\n",
      "Epoch [39/50], Step [711/735], Loss: 0.4196\n",
      "Epoch [39/50], Step [712/735], Loss: 0.2260\n",
      "Epoch [39/50], Step [713/735], Loss: 0.2665\n",
      "Epoch [39/50], Step [714/735], Loss: 0.1554\n",
      "Epoch [39/50], Step [715/735], Loss: 0.0698\n",
      "Epoch [39/50], Step [716/735], Loss: 0.1398\n",
      "Epoch [39/50], Step [717/735], Loss: 0.1491\n",
      "Epoch [39/50], Step [718/735], Loss: 0.3314\n",
      "Epoch [39/50], Step [719/735], Loss: 0.3832\n",
      "Epoch [39/50], Step [720/735], Loss: 0.3971\n",
      "Epoch [39/50], Step [721/735], Loss: 0.5283\n",
      "Epoch [39/50], Step [722/735], Loss: 0.1407\n",
      "Epoch [39/50], Step [723/735], Loss: 0.3830\n",
      "Epoch [39/50], Step [724/735], Loss: 0.7694\n",
      "Epoch [39/50], Step [725/735], Loss: 0.2492\n",
      "Epoch [39/50], Step [726/735], Loss: 0.1364\n",
      "Epoch [39/50], Step [727/735], Loss: 0.1881\n",
      "Epoch [39/50], Step [728/735], Loss: 0.2354\n",
      "Epoch [39/50], Step [729/735], Loss: 0.3699\n",
      "Epoch [39/50], Step [730/735], Loss: 0.2746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Step [731/735], Loss: 0.4676\n",
      "Epoch [39/50], Step [732/735], Loss: 0.1372\n",
      "Epoch [39/50], Step [733/735], Loss: 0.1514\n",
      "Epoch [39/50], Step [734/735], Loss: 0.2364\n",
      "Epoch [39/50], Step [735/735], Loss: 0.6892\n",
      "Epoch [40/50], Step [1/735], Loss: 0.4318\n",
      "Epoch [40/50], Step [2/735], Loss: 0.1538\n",
      "Epoch [40/50], Step [3/735], Loss: 0.1009\n",
      "Epoch [40/50], Step [4/735], Loss: 0.1420\n",
      "Epoch [40/50], Step [5/735], Loss: 0.2225\n",
      "Epoch [40/50], Step [6/735], Loss: 0.1076\n",
      "Epoch [40/50], Step [7/735], Loss: 0.1884\n",
      "Epoch [40/50], Step [8/735], Loss: 0.4198\n",
      "Epoch [40/50], Step [9/735], Loss: 0.2650\n",
      "Epoch [40/50], Step [10/735], Loss: 0.3436\n",
      "Epoch [40/50], Step [11/735], Loss: 0.3423\n",
      "Epoch [40/50], Step [12/735], Loss: 0.1415\n",
      "Epoch [40/50], Step [13/735], Loss: 0.2434\n",
      "Epoch [40/50], Step [14/735], Loss: 0.3978\n",
      "Epoch [40/50], Step [15/735], Loss: 0.1641\n",
      "Epoch [40/50], Step [16/735], Loss: 0.2260\n",
      "Epoch [40/50], Step [17/735], Loss: 0.1413\n",
      "Epoch [40/50], Step [18/735], Loss: 0.4696\n",
      "Epoch [40/50], Step [19/735], Loss: 0.5326\n",
      "Epoch [40/50], Step [20/735], Loss: 0.1754\n",
      "Epoch [40/50], Step [21/735], Loss: 0.4066\n",
      "Epoch [40/50], Step [22/735], Loss: 0.2221\n",
      "Epoch [40/50], Step [23/735], Loss: 0.4420\n",
      "Epoch [40/50], Step [24/735], Loss: 0.2719\n",
      "Epoch [40/50], Step [25/735], Loss: 0.1474\n",
      "Epoch [40/50], Step [26/735], Loss: 0.3383\n",
      "Epoch [40/50], Step [27/735], Loss: 0.2163\n",
      "Epoch [40/50], Step [28/735], Loss: 0.0576\n",
      "Epoch [40/50], Step [29/735], Loss: 0.0927\n",
      "Epoch [40/50], Step [30/735], Loss: 0.3582\n",
      "Epoch [40/50], Step [31/735], Loss: 0.0711\n",
      "Epoch [40/50], Step [32/735], Loss: 0.1367\n",
      "Epoch [40/50], Step [33/735], Loss: 0.2030\n",
      "Epoch [40/50], Step [34/735], Loss: 0.1410\n",
      "Epoch [40/50], Step [35/735], Loss: 0.2688\n",
      "Epoch [40/50], Step [36/735], Loss: 0.6832\n",
      "Epoch [40/50], Step [37/735], Loss: 0.4792\n",
      "Epoch [40/50], Step [38/735], Loss: 0.1111\n",
      "Epoch [40/50], Step [39/735], Loss: 0.1405\n",
      "Epoch [40/50], Step [40/735], Loss: 0.1888\n",
      "Epoch [40/50], Step [41/735], Loss: 0.0887\n",
      "Epoch [40/50], Step [42/735], Loss: 0.4007\n",
      "Epoch [40/50], Step [43/735], Loss: 0.1808\n",
      "Epoch [40/50], Step [44/735], Loss: 0.2640\n",
      "Epoch [40/50], Step [45/735], Loss: 0.4565\n",
      "Epoch [40/50], Step [46/735], Loss: 0.1575\n",
      "Epoch [40/50], Step [47/735], Loss: 0.2215\n",
      "Epoch [40/50], Step [48/735], Loss: 0.0937\n",
      "Epoch [40/50], Step [49/735], Loss: 0.2809\n",
      "Epoch [40/50], Step [50/735], Loss: 0.1549\n",
      "Epoch [40/50], Step [51/735], Loss: 0.5828\n",
      "Epoch [40/50], Step [52/735], Loss: 0.2057\n",
      "Epoch [40/50], Step [53/735], Loss: 0.3171\n",
      "Epoch [40/50], Step [54/735], Loss: 0.3247\n",
      "Epoch [40/50], Step [55/735], Loss: 0.3877\n",
      "Epoch [40/50], Step [56/735], Loss: 0.3841\n",
      "Epoch [40/50], Step [57/735], Loss: 0.1000\n",
      "Epoch [40/50], Step [58/735], Loss: 0.1801\n",
      "Epoch [40/50], Step [59/735], Loss: 0.2237\n",
      "Epoch [40/50], Step [60/735], Loss: 0.5467\n",
      "Epoch [40/50], Step [61/735], Loss: 0.0917\n",
      "Epoch [40/50], Step [62/735], Loss: 0.1205\n",
      "Epoch [40/50], Step [63/735], Loss: 0.0646\n",
      "Epoch [40/50], Step [64/735], Loss: 0.5522\n",
      "Epoch [40/50], Step [65/735], Loss: 0.3209\n",
      "Epoch [40/50], Step [66/735], Loss: 0.3730\n",
      "Epoch [40/50], Step [67/735], Loss: 0.3545\n",
      "Epoch [40/50], Step [68/735], Loss: 0.1352\n",
      "Epoch [40/50], Step [69/735], Loss: 0.1240\n",
      "Epoch [40/50], Step [70/735], Loss: 0.5582\n",
      "Epoch [40/50], Step [71/735], Loss: 0.2427\n",
      "Epoch [40/50], Step [72/735], Loss: 0.0896\n",
      "Epoch [40/50], Step [73/735], Loss: 0.2647\n",
      "Epoch [40/50], Step [74/735], Loss: 0.2999\n",
      "Epoch [40/50], Step [75/735], Loss: 0.0650\n",
      "Epoch [40/50], Step [76/735], Loss: 0.0703\n",
      "Epoch [40/50], Step [77/735], Loss: 0.2684\n",
      "Epoch [40/50], Step [78/735], Loss: 0.2442\n",
      "Epoch [40/50], Step [79/735], Loss: 0.3454\n",
      "Epoch [40/50], Step [80/735], Loss: 0.2751\n",
      "Epoch [40/50], Step [81/735], Loss: 0.1838\n",
      "Epoch [40/50], Step [82/735], Loss: 0.2334\n",
      "Epoch [40/50], Step [83/735], Loss: 0.1478\n",
      "Epoch [40/50], Step [84/735], Loss: 0.1246\n",
      "Epoch [40/50], Step [85/735], Loss: 0.2862\n",
      "Epoch [40/50], Step [86/735], Loss: 0.3890\n",
      "Epoch [40/50], Step [87/735], Loss: 0.1170\n",
      "Epoch [40/50], Step [88/735], Loss: 0.1792\n",
      "Epoch [40/50], Step [89/735], Loss: 0.3391\n",
      "Epoch [40/50], Step [90/735], Loss: 0.1645\n",
      "Epoch [40/50], Step [91/735], Loss: 0.5484\n",
      "Epoch [40/50], Step [92/735], Loss: 0.1318\n",
      "Epoch [40/50], Step [93/735], Loss: 0.1944\n",
      "Epoch [40/50], Step [94/735], Loss: 0.2065\n",
      "Epoch [40/50], Step [95/735], Loss: 0.2496\n",
      "Epoch [40/50], Step [96/735], Loss: 0.1880\n",
      "Epoch [40/50], Step [97/735], Loss: 0.3916\n",
      "Epoch [40/50], Step [98/735], Loss: 0.1046\n",
      "Epoch [40/50], Step [99/735], Loss: 0.2003\n",
      "Epoch [40/50], Step [100/735], Loss: 0.1185\n",
      "Epoch [40/50], Step [101/735], Loss: 0.1651\n",
      "Epoch [40/50], Step [102/735], Loss: 0.4599\n",
      "Epoch [40/50], Step [103/735], Loss: 0.1563\n",
      "Epoch [40/50], Step [104/735], Loss: 0.7232\n",
      "Epoch [40/50], Step [105/735], Loss: 0.1096\n",
      "Epoch [40/50], Step [106/735], Loss: 0.3165\n",
      "Epoch [40/50], Step [107/735], Loss: 0.0637\n",
      "Epoch [40/50], Step [108/735], Loss: 0.1453\n",
      "Epoch [40/50], Step [109/735], Loss: 0.1720\n",
      "Epoch [40/50], Step [110/735], Loss: 0.1524\n",
      "Epoch [40/50], Step [111/735], Loss: 0.1785\n",
      "Epoch [40/50], Step [112/735], Loss: 0.3458\n",
      "Epoch [40/50], Step [113/735], Loss: 0.1144\n",
      "Epoch [40/50], Step [114/735], Loss: 0.1945\n",
      "Epoch [40/50], Step [115/735], Loss: 0.1071\n",
      "Epoch [40/50], Step [116/735], Loss: 0.2407\n",
      "Epoch [40/50], Step [117/735], Loss: 0.1568\n",
      "Epoch [40/50], Step [118/735], Loss: 0.1375\n",
      "Epoch [40/50], Step [119/735], Loss: 0.5770\n",
      "Epoch [40/50], Step [120/735], Loss: 0.2705\n",
      "Epoch [40/50], Step [121/735], Loss: 0.2327\n",
      "Epoch [40/50], Step [122/735], Loss: 0.6624\n",
      "Epoch [40/50], Step [123/735], Loss: 0.1516\n",
      "Epoch [40/50], Step [124/735], Loss: 0.1830\n",
      "Epoch [40/50], Step [125/735], Loss: 0.3578\n",
      "Epoch [40/50], Step [126/735], Loss: 0.2274\n",
      "Epoch [40/50], Step [127/735], Loss: 0.3502\n",
      "Epoch [40/50], Step [128/735], Loss: 0.1505\n",
      "Epoch [40/50], Step [129/735], Loss: 0.2713\n",
      "Epoch [40/50], Step [130/735], Loss: 0.1573\n",
      "Epoch [40/50], Step [131/735], Loss: 0.2174\n",
      "Epoch [40/50], Step [132/735], Loss: 0.4129\n",
      "Epoch [40/50], Step [133/735], Loss: 0.2131\n",
      "Epoch [40/50], Step [134/735], Loss: 0.1286\n",
      "Epoch [40/50], Step [135/735], Loss: 0.1227\n",
      "Epoch [40/50], Step [136/735], Loss: 0.3112\n",
      "Epoch [40/50], Step [137/735], Loss: 0.7274\n",
      "Epoch [40/50], Step [138/735], Loss: 0.2418\n",
      "Epoch [40/50], Step [139/735], Loss: 0.2031\n",
      "Epoch [40/50], Step [140/735], Loss: 0.1268\n",
      "Epoch [40/50], Step [141/735], Loss: 1.5477\n",
      "Epoch [40/50], Step [142/735], Loss: 0.1646\n",
      "Epoch [40/50], Step [143/735], Loss: 0.1045\n",
      "Epoch [40/50], Step [144/735], Loss: 0.3164\n",
      "Epoch [40/50], Step [145/735], Loss: 0.0908\n",
      "Epoch [40/50], Step [146/735], Loss: 0.1502\n",
      "Epoch [40/50], Step [147/735], Loss: 0.1847\n",
      "Epoch [40/50], Step [148/735], Loss: 0.1981\n",
      "Epoch [40/50], Step [149/735], Loss: 0.1576\n",
      "Epoch [40/50], Step [150/735], Loss: 0.3226\n",
      "Epoch [40/50], Step [151/735], Loss: 0.1602\n",
      "Epoch [40/50], Step [152/735], Loss: 0.4410\n",
      "Epoch [40/50], Step [153/735], Loss: 0.5823\n",
      "Epoch [40/50], Step [154/735], Loss: 0.1387\n",
      "Epoch [40/50], Step [155/735], Loss: 0.2189\n",
      "Epoch [40/50], Step [156/735], Loss: 0.0875\n",
      "Epoch [40/50], Step [157/735], Loss: 0.2338\n",
      "Epoch [40/50], Step [158/735], Loss: 0.1131\n",
      "Epoch [40/50], Step [159/735], Loss: 0.9179\n",
      "Epoch [40/50], Step [160/735], Loss: 0.1000\n",
      "Epoch [40/50], Step [161/735], Loss: 0.1168\n",
      "Epoch [40/50], Step [162/735], Loss: 0.1806\n",
      "Epoch [40/50], Step [163/735], Loss: 0.3801\n",
      "Epoch [40/50], Step [164/735], Loss: 0.1191\n",
      "Epoch [40/50], Step [165/735], Loss: 0.0981\n",
      "Epoch [40/50], Step [166/735], Loss: 0.1287\n",
      "Epoch [40/50], Step [167/735], Loss: 0.8131\n",
      "Epoch [40/50], Step [168/735], Loss: 0.1901\n",
      "Epoch [40/50], Step [169/735], Loss: 0.0679\n",
      "Epoch [40/50], Step [170/735], Loss: 0.2240\n",
      "Epoch [40/50], Step [171/735], Loss: 0.2672\n",
      "Epoch [40/50], Step [172/735], Loss: 0.0541\n",
      "Epoch [40/50], Step [173/735], Loss: 0.0843\n",
      "Epoch [40/50], Step [174/735], Loss: 0.4333\n",
      "Epoch [40/50], Step [175/735], Loss: 0.2542\n",
      "Epoch [40/50], Step [176/735], Loss: 0.2301\n",
      "Epoch [40/50], Step [177/735], Loss: 0.4652\n",
      "Epoch [40/50], Step [178/735], Loss: 0.1562\n",
      "Epoch [40/50], Step [179/735], Loss: 0.0991\n",
      "Epoch [40/50], Step [180/735], Loss: 0.1097\n",
      "Epoch [40/50], Step [181/735], Loss: 0.3573\n",
      "Epoch [40/50], Step [182/735], Loss: 0.2372\n",
      "Epoch [40/50], Step [183/735], Loss: 0.0371\n",
      "Epoch [40/50], Step [184/735], Loss: 0.0589\n",
      "Epoch [40/50], Step [185/735], Loss: 0.3949\n",
      "Epoch [40/50], Step [186/735], Loss: 0.1301\n",
      "Epoch [40/50], Step [187/735], Loss: 0.2984\n",
      "Epoch [40/50], Step [188/735], Loss: 0.3824\n",
      "Epoch [40/50], Step [189/735], Loss: 0.0788\n",
      "Epoch [40/50], Step [190/735], Loss: 0.3088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Step [191/735], Loss: 0.2845\n",
      "Epoch [40/50], Step [192/735], Loss: 0.2167\n",
      "Epoch [40/50], Step [193/735], Loss: 0.2391\n",
      "Epoch [40/50], Step [194/735], Loss: 0.1420\n",
      "Epoch [40/50], Step [195/735], Loss: 0.1195\n",
      "Epoch [40/50], Step [196/735], Loss: 0.1660\n",
      "Epoch [40/50], Step [197/735], Loss: 0.3893\n",
      "Epoch [40/50], Step [198/735], Loss: 0.1561\n",
      "Epoch [40/50], Step [199/735], Loss: 0.2888\n",
      "Epoch [40/50], Step [200/735], Loss: 0.3273\n",
      "Epoch [40/50], Step [201/735], Loss: 0.0445\n",
      "Epoch [40/50], Step [202/735], Loss: 0.1802\n",
      "Epoch [40/50], Step [203/735], Loss: 0.2909\n",
      "Epoch [40/50], Step [204/735], Loss: 0.3330\n",
      "Epoch [40/50], Step [205/735], Loss: 0.2154\n",
      "Epoch [40/50], Step [206/735], Loss: 0.3924\n",
      "Epoch [40/50], Step [207/735], Loss: 0.2939\n",
      "Epoch [40/50], Step [208/735], Loss: 0.2190\n",
      "Epoch [40/50], Step [209/735], Loss: 0.4224\n",
      "Epoch [40/50], Step [210/735], Loss: 0.5725\n",
      "Epoch [40/50], Step [211/735], Loss: 0.3380\n",
      "Epoch [40/50], Step [212/735], Loss: 0.1409\n",
      "Epoch [40/50], Step [213/735], Loss: 0.7611\n",
      "Epoch [40/50], Step [214/735], Loss: 0.2440\n",
      "Epoch [40/50], Step [215/735], Loss: 0.1758\n",
      "Epoch [40/50], Step [216/735], Loss: 0.0701\n",
      "Epoch [40/50], Step [217/735], Loss: 0.2051\n",
      "Epoch [40/50], Step [218/735], Loss: 0.0607\n",
      "Epoch [40/50], Step [219/735], Loss: 0.2566\n",
      "Epoch [40/50], Step [220/735], Loss: 0.3023\n",
      "Epoch [40/50], Step [221/735], Loss: 0.0864\n",
      "Epoch [40/50], Step [222/735], Loss: 1.0319\n",
      "Epoch [40/50], Step [223/735], Loss: 0.5144\n",
      "Epoch [40/50], Step [224/735], Loss: 0.3417\n",
      "Epoch [40/50], Step [225/735], Loss: 0.1316\n",
      "Epoch [40/50], Step [226/735], Loss: 0.5400\n",
      "Epoch [40/50], Step [227/735], Loss: 0.3643\n",
      "Epoch [40/50], Step [228/735], Loss: 0.6779\n",
      "Epoch [40/50], Step [229/735], Loss: 0.4808\n",
      "Epoch [40/50], Step [230/735], Loss: 0.2823\n",
      "Epoch [40/50], Step [231/735], Loss: 0.2067\n",
      "Epoch [40/50], Step [232/735], Loss: 0.2023\n",
      "Epoch [40/50], Step [233/735], Loss: 0.1063\n",
      "Epoch [40/50], Step [234/735], Loss: 0.1596\n",
      "Epoch [40/50], Step [235/735], Loss: 0.4062\n",
      "Epoch [40/50], Step [236/735], Loss: 0.2103\n",
      "Epoch [40/50], Step [237/735], Loss: 0.1091\n",
      "Epoch [40/50], Step [238/735], Loss: 0.7288\n",
      "Epoch [40/50], Step [239/735], Loss: 0.2319\n",
      "Epoch [40/50], Step [240/735], Loss: 0.4401\n",
      "Epoch [40/50], Step [241/735], Loss: 0.2933\n",
      "Epoch [40/50], Step [242/735], Loss: 0.2437\n",
      "Epoch [40/50], Step [243/735], Loss: 0.3202\n",
      "Epoch [40/50], Step [244/735], Loss: 0.2570\n",
      "Epoch [40/50], Step [245/735], Loss: 0.5419\n",
      "Epoch [40/50], Step [246/735], Loss: 0.1116\n",
      "Epoch [40/50], Step [247/735], Loss: 0.1955\n",
      "Epoch [40/50], Step [248/735], Loss: 0.1385\n",
      "Epoch [40/50], Step [249/735], Loss: 0.4099\n",
      "Epoch [40/50], Step [250/735], Loss: 0.5711\n",
      "Epoch [40/50], Step [251/735], Loss: 0.3357\n",
      "Epoch [40/50], Step [252/735], Loss: 0.1489\n",
      "Epoch [40/50], Step [253/735], Loss: 0.0878\n",
      "Epoch [40/50], Step [254/735], Loss: 0.2072\n",
      "Epoch [40/50], Step [255/735], Loss: 0.1423\n",
      "Epoch [40/50], Step [256/735], Loss: 0.3308\n",
      "Epoch [40/50], Step [257/735], Loss: 0.4237\n",
      "Epoch [40/50], Step [258/735], Loss: 0.2538\n",
      "Epoch [40/50], Step [259/735], Loss: 0.0580\n",
      "Epoch [40/50], Step [260/735], Loss: 0.0870\n",
      "Epoch [40/50], Step [261/735], Loss: 0.0446\n",
      "Epoch [40/50], Step [262/735], Loss: 0.1285\n",
      "Epoch [40/50], Step [263/735], Loss: 0.5651\n",
      "Epoch [40/50], Step [264/735], Loss: 0.1650\n",
      "Epoch [40/50], Step [265/735], Loss: 0.3433\n",
      "Epoch [40/50], Step [266/735], Loss: 1.3700\n",
      "Epoch [40/50], Step [267/735], Loss: 0.1339\n",
      "Epoch [40/50], Step [268/735], Loss: 0.3349\n",
      "Epoch [40/50], Step [269/735], Loss: 0.2203\n",
      "Epoch [40/50], Step [270/735], Loss: 0.3599\n",
      "Epoch [40/50], Step [271/735], Loss: 0.2445\n",
      "Epoch [40/50], Step [272/735], Loss: 0.0708\n",
      "Epoch [40/50], Step [273/735], Loss: 0.1779\n",
      "Epoch [40/50], Step [274/735], Loss: 0.0656\n",
      "Epoch [40/50], Step [275/735], Loss: 0.1841\n",
      "Epoch [40/50], Step [276/735], Loss: 0.0954\n",
      "Epoch [40/50], Step [277/735], Loss: 0.2062\n",
      "Epoch [40/50], Step [278/735], Loss: 0.2059\n",
      "Epoch [40/50], Step [279/735], Loss: 0.5677\n",
      "Epoch [40/50], Step [280/735], Loss: 0.1327\n",
      "Epoch [40/50], Step [281/735], Loss: 0.3650\n",
      "Epoch [40/50], Step [282/735], Loss: 0.1698\n",
      "Epoch [40/50], Step [283/735], Loss: 0.2983\n",
      "Epoch [40/50], Step [284/735], Loss: 0.3790\n",
      "Epoch [40/50], Step [285/735], Loss: 0.4183\n",
      "Epoch [40/50], Step [286/735], Loss: 0.1487\n",
      "Epoch [40/50], Step [287/735], Loss: 0.2305\n",
      "Epoch [40/50], Step [288/735], Loss: 0.1427\n",
      "Epoch [40/50], Step [289/735], Loss: 0.5986\n",
      "Epoch [40/50], Step [290/735], Loss: 0.1538\n",
      "Epoch [40/50], Step [291/735], Loss: 0.2448\n",
      "Epoch [40/50], Step [292/735], Loss: 0.6586\n",
      "Epoch [40/50], Step [293/735], Loss: 0.2057\n",
      "Epoch [40/50], Step [294/735], Loss: 0.4704\n",
      "Epoch [40/50], Step [295/735], Loss: 0.1686\n",
      "Epoch [40/50], Step [296/735], Loss: 0.5907\n",
      "Epoch [40/50], Step [297/735], Loss: 0.4843\n",
      "Epoch [40/50], Step [298/735], Loss: 0.1368\n",
      "Epoch [40/50], Step [299/735], Loss: 0.3213\n",
      "Epoch [40/50], Step [300/735], Loss: 0.2884\n",
      "Epoch [40/50], Step [301/735], Loss: 0.0941\n",
      "Epoch [40/50], Step [302/735], Loss: 0.3054\n",
      "Epoch [40/50], Step [303/735], Loss: 0.2078\n",
      "Epoch [40/50], Step [304/735], Loss: 0.3753\n",
      "Epoch [40/50], Step [305/735], Loss: 0.0797\n",
      "Epoch [40/50], Step [306/735], Loss: 0.1629\n",
      "Epoch [40/50], Step [307/735], Loss: 0.2576\n",
      "Epoch [40/50], Step [308/735], Loss: 0.2203\n",
      "Epoch [40/50], Step [309/735], Loss: 0.3869\n",
      "Epoch [40/50], Step [310/735], Loss: 0.5716\n",
      "Epoch [40/50], Step [311/735], Loss: 0.4337\n",
      "Epoch [40/50], Step [312/735], Loss: 0.2096\n",
      "Epoch [40/50], Step [313/735], Loss: 0.1660\n",
      "Epoch [40/50], Step [314/735], Loss: 0.1649\n",
      "Epoch [40/50], Step [315/735], Loss: 0.1366\n",
      "Epoch [40/50], Step [316/735], Loss: 0.4078\n",
      "Epoch [40/50], Step [317/735], Loss: 0.1617\n",
      "Epoch [40/50], Step [318/735], Loss: 0.1186\n",
      "Epoch [40/50], Step [319/735], Loss: 0.4708\n",
      "Epoch [40/50], Step [320/735], Loss: 0.1056\n",
      "Epoch [40/50], Step [321/735], Loss: 0.6865\n",
      "Epoch [40/50], Step [322/735], Loss: 0.3647\n",
      "Epoch [40/50], Step [323/735], Loss: 1.0807\n",
      "Epoch [40/50], Step [324/735], Loss: 0.4141\n",
      "Epoch [40/50], Step [325/735], Loss: 0.3908\n",
      "Epoch [40/50], Step [326/735], Loss: 0.1241\n",
      "Epoch [40/50], Step [327/735], Loss: 0.0578\n",
      "Epoch [40/50], Step [328/735], Loss: 0.2625\n",
      "Epoch [40/50], Step [329/735], Loss: 0.2600\n",
      "Epoch [40/50], Step [330/735], Loss: 0.3150\n",
      "Epoch [40/50], Step [331/735], Loss: 0.3674\n",
      "Epoch [40/50], Step [332/735], Loss: 0.4653\n",
      "Epoch [40/50], Step [333/735], Loss: 0.1691\n",
      "Epoch [40/50], Step [334/735], Loss: 0.1167\n",
      "Epoch [40/50], Step [335/735], Loss: 0.2397\n",
      "Epoch [40/50], Step [336/735], Loss: 0.2913\n",
      "Epoch [40/50], Step [337/735], Loss: 0.2592\n",
      "Epoch [40/50], Step [338/735], Loss: 0.1220\n",
      "Epoch [40/50], Step [339/735], Loss: 0.3498\n",
      "Epoch [40/50], Step [340/735], Loss: 0.3329\n",
      "Epoch [40/50], Step [341/735], Loss: 0.5810\n",
      "Epoch [40/50], Step [342/735], Loss: 0.1774\n",
      "Epoch [40/50], Step [343/735], Loss: 0.3669\n",
      "Epoch [40/50], Step [344/735], Loss: 0.7071\n",
      "Epoch [40/50], Step [345/735], Loss: 0.5297\n",
      "Epoch [40/50], Step [346/735], Loss: 0.5167\n",
      "Epoch [40/50], Step [347/735], Loss: 0.2285\n",
      "Epoch [40/50], Step [348/735], Loss: 0.3202\n",
      "Epoch [40/50], Step [349/735], Loss: 0.4286\n",
      "Epoch [40/50], Step [350/735], Loss: 0.1158\n",
      "Epoch [40/50], Step [351/735], Loss: 0.2396\n",
      "Epoch [40/50], Step [352/735], Loss: 0.4787\n",
      "Epoch [40/50], Step [353/735], Loss: 0.4600\n",
      "Epoch [40/50], Step [354/735], Loss: 0.1702\n",
      "Epoch [40/50], Step [355/735], Loss: 0.1628\n",
      "Epoch [40/50], Step [356/735], Loss: 0.2639\n",
      "Epoch [40/50], Step [357/735], Loss: 0.2148\n",
      "Epoch [40/50], Step [358/735], Loss: 0.1498\n",
      "Epoch [40/50], Step [359/735], Loss: 0.1369\n",
      "Epoch [40/50], Step [360/735], Loss: 0.3069\n",
      "Epoch [40/50], Step [361/735], Loss: 0.1505\n",
      "Epoch [40/50], Step [362/735], Loss: 0.6270\n",
      "Epoch [40/50], Step [363/735], Loss: 0.1960\n",
      "Epoch [40/50], Step [364/735], Loss: 1.2970\n",
      "Epoch [40/50], Step [365/735], Loss: 0.3944\n",
      "Epoch [40/50], Step [366/735], Loss: 0.2031\n",
      "Epoch [40/50], Step [367/735], Loss: 0.1503\n",
      "Epoch [40/50], Step [368/735], Loss: 0.4984\n",
      "Epoch [40/50], Step [369/735], Loss: 0.6129\n",
      "Epoch [40/50], Step [370/735], Loss: 0.3191\n",
      "Epoch [40/50], Step [371/735], Loss: 0.1515\n",
      "Epoch [40/50], Step [372/735], Loss: 0.3253\n",
      "Epoch [40/50], Step [373/735], Loss: 0.0921\n",
      "Epoch [40/50], Step [374/735], Loss: 0.3993\n",
      "Epoch [40/50], Step [375/735], Loss: 0.5999\n",
      "Epoch [40/50], Step [376/735], Loss: 1.3115\n",
      "Epoch [40/50], Step [377/735], Loss: 0.1330\n",
      "Epoch [40/50], Step [378/735], Loss: 0.3608\n",
      "Epoch [40/50], Step [379/735], Loss: 0.2655\n",
      "Epoch [40/50], Step [380/735], Loss: 0.4414\n",
      "Epoch [40/50], Step [381/735], Loss: 0.6015\n",
      "Epoch [40/50], Step [382/735], Loss: 0.2154\n",
      "Epoch [40/50], Step [383/735], Loss: 0.1588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Step [384/735], Loss: 0.3200\n",
      "Epoch [40/50], Step [385/735], Loss: 0.0512\n",
      "Epoch [40/50], Step [386/735], Loss: 0.1086\n",
      "Epoch [40/50], Step [387/735], Loss: 0.5005\n",
      "Epoch [40/50], Step [388/735], Loss: 0.1944\n",
      "Epoch [40/50], Step [389/735], Loss: 1.1605\n",
      "Epoch [40/50], Step [390/735], Loss: 0.5154\n",
      "Epoch [40/50], Step [391/735], Loss: 0.9400\n",
      "Epoch [40/50], Step [392/735], Loss: 0.3067\n",
      "Epoch [40/50], Step [393/735], Loss: 0.1219\n",
      "Epoch [40/50], Step [394/735], Loss: 0.5502\n",
      "Epoch [40/50], Step [395/735], Loss: 0.3637\n",
      "Epoch [40/50], Step [396/735], Loss: 0.2793\n",
      "Epoch [40/50], Step [397/735], Loss: 0.5074\n",
      "Epoch [40/50], Step [398/735], Loss: 0.2324\n",
      "Epoch [40/50], Step [399/735], Loss: 0.1205\n",
      "Epoch [40/50], Step [400/735], Loss: 0.2504\n",
      "Epoch [40/50], Step [401/735], Loss: 0.2360\n",
      "Epoch [40/50], Step [402/735], Loss: 0.2559\n",
      "Epoch [40/50], Step [403/735], Loss: 0.2008\n",
      "Epoch [40/50], Step [404/735], Loss: 0.7883\n",
      "Epoch [40/50], Step [405/735], Loss: 0.1318\n",
      "Epoch [40/50], Step [406/735], Loss: 0.4051\n",
      "Epoch [40/50], Step [407/735], Loss: 0.1728\n",
      "Epoch [40/50], Step [408/735], Loss: 0.2327\n",
      "Epoch [40/50], Step [409/735], Loss: 0.4518\n",
      "Epoch [40/50], Step [410/735], Loss: 0.7892\n",
      "Epoch [40/50], Step [411/735], Loss: 0.2040\n",
      "Epoch [40/50], Step [412/735], Loss: 0.2808\n",
      "Epoch [40/50], Step [413/735], Loss: 0.2094\n",
      "Epoch [40/50], Step [414/735], Loss: 0.4817\n",
      "Epoch [40/50], Step [415/735], Loss: 0.1500\n",
      "Epoch [40/50], Step [416/735], Loss: 0.3828\n",
      "Epoch [40/50], Step [417/735], Loss: 0.3542\n",
      "Epoch [40/50], Step [418/735], Loss: 0.2897\n",
      "Epoch [40/50], Step [419/735], Loss: 0.2801\n",
      "Epoch [40/50], Step [420/735], Loss: 0.1437\n",
      "Epoch [40/50], Step [421/735], Loss: 0.3201\n",
      "Epoch [40/50], Step [422/735], Loss: 0.1457\n",
      "Epoch [40/50], Step [423/735], Loss: 0.4588\n",
      "Epoch [40/50], Step [424/735], Loss: 0.1591\n",
      "Epoch [40/50], Step [425/735], Loss: 0.1687\n",
      "Epoch [40/50], Step [426/735], Loss: 0.1063\n",
      "Epoch [40/50], Step [427/735], Loss: 0.3569\n",
      "Epoch [40/50], Step [428/735], Loss: 0.1429\n",
      "Epoch [40/50], Step [429/735], Loss: 0.3664\n",
      "Epoch [40/50], Step [430/735], Loss: 0.2696\n",
      "Epoch [40/50], Step [431/735], Loss: 0.1673\n",
      "Epoch [40/50], Step [432/735], Loss: 0.2404\n",
      "Epoch [40/50], Step [433/735], Loss: 1.0319\n",
      "Epoch [40/50], Step [434/735], Loss: 0.1453\n",
      "Epoch [40/50], Step [435/735], Loss: 0.4347\n",
      "Epoch [40/50], Step [436/735], Loss: 0.5580\n",
      "Epoch [40/50], Step [437/735], Loss: 0.4742\n",
      "Epoch [40/50], Step [438/735], Loss: 0.2584\n",
      "Epoch [40/50], Step [439/735], Loss: 3.5537\n",
      "Epoch [40/50], Step [440/735], Loss: 0.2637\n",
      "Epoch [40/50], Step [441/735], Loss: 0.2630\n",
      "Epoch [40/50], Step [442/735], Loss: 0.3722\n",
      "Epoch [40/50], Step [443/735], Loss: 0.1791\n",
      "Epoch [40/50], Step [444/735], Loss: 0.3925\n",
      "Epoch [40/50], Step [445/735], Loss: 0.5366\n",
      "Epoch [40/50], Step [446/735], Loss: 0.6829\n",
      "Epoch [40/50], Step [447/735], Loss: 0.5190\n",
      "Epoch [40/50], Step [448/735], Loss: 0.2422\n",
      "Epoch [40/50], Step [449/735], Loss: 0.1732\n",
      "Epoch [40/50], Step [450/735], Loss: 3.3718\n",
      "Epoch [40/50], Step [451/735], Loss: 1.0686\n",
      "Epoch [40/50], Step [452/735], Loss: 0.8871\n",
      "Epoch [40/50], Step [453/735], Loss: 0.5289\n",
      "Epoch [40/50], Step [454/735], Loss: 0.2149\n",
      "Epoch [40/50], Step [455/735], Loss: 0.5190\n",
      "Epoch [40/50], Step [456/735], Loss: 0.2622\n",
      "Epoch [40/50], Step [457/735], Loss: 0.1237\n",
      "Epoch [40/50], Step [458/735], Loss: 0.2195\n",
      "Epoch [40/50], Step [459/735], Loss: 0.5538\n",
      "Epoch [40/50], Step [460/735], Loss: 0.1687\n",
      "Epoch [40/50], Step [461/735], Loss: 0.1999\n",
      "Epoch [40/50], Step [462/735], Loss: 0.2683\n",
      "Epoch [40/50], Step [463/735], Loss: 0.4474\n",
      "Epoch [40/50], Step [464/735], Loss: 0.1825\n",
      "Epoch [40/50], Step [465/735], Loss: 0.3602\n",
      "Epoch [40/50], Step [466/735], Loss: 0.1700\n",
      "Epoch [40/50], Step [467/735], Loss: 0.1962\n",
      "Epoch [40/50], Step [468/735], Loss: 0.8102\n",
      "Epoch [40/50], Step [469/735], Loss: 0.0734\n",
      "Epoch [40/50], Step [470/735], Loss: 0.3745\n",
      "Epoch [40/50], Step [471/735], Loss: 0.4004\n",
      "Epoch [40/50], Step [472/735], Loss: 0.2333\n",
      "Epoch [40/50], Step [473/735], Loss: 0.9211\n",
      "Epoch [40/50], Step [474/735], Loss: 0.4485\n",
      "Epoch [40/50], Step [475/735], Loss: 0.0552\n",
      "Epoch [40/50], Step [476/735], Loss: 0.5718\n",
      "Epoch [40/50], Step [477/735], Loss: 0.1451\n",
      "Epoch [40/50], Step [478/735], Loss: 0.2775\n",
      "Epoch [40/50], Step [479/735], Loss: 3.0328\n",
      "Epoch [40/50], Step [480/735], Loss: 0.2048\n",
      "Epoch [40/50], Step [481/735], Loss: 0.1504\n",
      "Epoch [40/50], Step [482/735], Loss: 0.1174\n",
      "Epoch [40/50], Step [483/735], Loss: 0.5798\n",
      "Epoch [40/50], Step [484/735], Loss: 0.7427\n",
      "Epoch [40/50], Step [485/735], Loss: 3.3124\n",
      "Epoch [40/50], Step [486/735], Loss: 0.3032\n",
      "Epoch [40/50], Step [487/735], Loss: 0.8601\n",
      "Epoch [40/50], Step [488/735], Loss: 0.2706\n",
      "Epoch [40/50], Step [489/735], Loss: 0.5423\n",
      "Epoch [40/50], Step [490/735], Loss: 0.3247\n",
      "Epoch [40/50], Step [491/735], Loss: 1.0182\n",
      "Epoch [40/50], Step [492/735], Loss: 0.3570\n",
      "Epoch [40/50], Step [493/735], Loss: 0.3708\n",
      "Epoch [40/50], Step [494/735], Loss: 0.2301\n",
      "Epoch [40/50], Step [495/735], Loss: 0.3528\n",
      "Epoch [40/50], Step [496/735], Loss: 0.8707\n",
      "Epoch [40/50], Step [497/735], Loss: 0.3896\n",
      "Epoch [40/50], Step [498/735], Loss: 0.3275\n",
      "Epoch [40/50], Step [499/735], Loss: 0.4949\n",
      "Epoch [40/50], Step [500/735], Loss: 0.2032\n",
      "Epoch [40/50], Step [501/735], Loss: 0.4799\n",
      "Epoch [40/50], Step [502/735], Loss: 0.1213\n",
      "Epoch [40/50], Step [503/735], Loss: 0.1381\n",
      "Epoch [40/50], Step [504/735], Loss: 0.7331\n",
      "Epoch [40/50], Step [505/735], Loss: 0.2494\n",
      "Epoch [40/50], Step [506/735], Loss: 0.1577\n",
      "Epoch [40/50], Step [507/735], Loss: 0.2711\n",
      "Epoch [40/50], Step [508/735], Loss: 0.1979\n",
      "Epoch [40/50], Step [509/735], Loss: 0.1843\n",
      "Epoch [40/50], Step [510/735], Loss: 0.3957\n",
      "Epoch [40/50], Step [511/735], Loss: 0.2157\n",
      "Epoch [40/50], Step [512/735], Loss: 0.1612\n",
      "Epoch [40/50], Step [513/735], Loss: 0.1259\n",
      "Epoch [40/50], Step [514/735], Loss: 0.2294\n",
      "Epoch [40/50], Step [515/735], Loss: 0.1869\n",
      "Epoch [40/50], Step [516/735], Loss: 0.0935\n",
      "Epoch [40/50], Step [517/735], Loss: 0.1524\n",
      "Epoch [40/50], Step [518/735], Loss: 0.0774\n",
      "Epoch [40/50], Step [519/735], Loss: 0.6598\n",
      "Epoch [40/50], Step [520/735], Loss: 0.1139\n",
      "Epoch [40/50], Step [521/735], Loss: 0.4475\n",
      "Epoch [40/50], Step [522/735], Loss: 0.1861\n",
      "Epoch [40/50], Step [523/735], Loss: 0.2071\n",
      "Epoch [40/50], Step [524/735], Loss: 0.4327\n",
      "Epoch [40/50], Step [525/735], Loss: 0.2009\n",
      "Epoch [40/50], Step [526/735], Loss: 0.0838\n",
      "Epoch [40/50], Step [527/735], Loss: 0.2828\n",
      "Epoch [40/50], Step [528/735], Loss: 0.1977\n",
      "Epoch [40/50], Step [529/735], Loss: 0.2978\n",
      "Epoch [40/50], Step [530/735], Loss: 0.3289\n",
      "Epoch [40/50], Step [531/735], Loss: 0.7591\n",
      "Epoch [40/50], Step [532/735], Loss: 0.3953\n",
      "Epoch [40/50], Step [533/735], Loss: 0.2021\n",
      "Epoch [40/50], Step [534/735], Loss: 0.3793\n",
      "Epoch [40/50], Step [535/735], Loss: 0.2877\n",
      "Epoch [40/50], Step [536/735], Loss: 0.1040\n",
      "Epoch [40/50], Step [537/735], Loss: 1.0496\n",
      "Epoch [40/50], Step [538/735], Loss: 0.7075\n",
      "Epoch [40/50], Step [539/735], Loss: 0.4568\n",
      "Epoch [40/50], Step [540/735], Loss: 0.2129\n",
      "Epoch [40/50], Step [541/735], Loss: 0.3988\n",
      "Epoch [40/50], Step [542/735], Loss: 0.1116\n",
      "Epoch [40/50], Step [543/735], Loss: 0.4192\n",
      "Epoch [40/50], Step [544/735], Loss: 0.6132\n",
      "Epoch [40/50], Step [545/735], Loss: 0.3393\n",
      "Epoch [40/50], Step [546/735], Loss: 0.2416\n",
      "Epoch [40/50], Step [547/735], Loss: 0.3368\n",
      "Epoch [40/50], Step [548/735], Loss: 0.1592\n",
      "Epoch [40/50], Step [549/735], Loss: 0.1728\n",
      "Epoch [40/50], Step [550/735], Loss: 0.3740\n",
      "Epoch [40/50], Step [551/735], Loss: 0.2147\n",
      "Epoch [40/50], Step [552/735], Loss: 0.3975\n",
      "Epoch [40/50], Step [553/735], Loss: 0.2166\n",
      "Epoch [40/50], Step [554/735], Loss: 0.5249\n",
      "Epoch [40/50], Step [555/735], Loss: 0.3450\n",
      "Epoch [40/50], Step [556/735], Loss: 0.1298\n",
      "Epoch [40/50], Step [557/735], Loss: 0.8187\n",
      "Epoch [40/50], Step [558/735], Loss: 0.3816\n",
      "Epoch [40/50], Step [559/735], Loss: 0.0415\n",
      "Epoch [40/50], Step [560/735], Loss: 0.8966\n",
      "Epoch [40/50], Step [561/735], Loss: 0.6230\n",
      "Epoch [40/50], Step [562/735], Loss: 0.1497\n",
      "Epoch [40/50], Step [563/735], Loss: 0.1674\n",
      "Epoch [40/50], Step [564/735], Loss: 0.8079\n",
      "Epoch [40/50], Step [565/735], Loss: 0.7838\n",
      "Epoch [40/50], Step [566/735], Loss: 0.1554\n",
      "Epoch [40/50], Step [567/735], Loss: 0.3800\n",
      "Epoch [40/50], Step [568/735], Loss: 0.2754\n",
      "Epoch [40/50], Step [569/735], Loss: 0.0936\n",
      "Epoch [40/50], Step [570/735], Loss: 0.2940\n",
      "Epoch [40/50], Step [571/735], Loss: 0.3838\n",
      "Epoch [40/50], Step [572/735], Loss: 0.4027\n",
      "Epoch [40/50], Step [573/735], Loss: 0.5540\n",
      "Epoch [40/50], Step [574/735], Loss: 0.2403\n",
      "Epoch [40/50], Step [575/735], Loss: 0.2128\n",
      "Epoch [40/50], Step [576/735], Loss: 0.2163\n",
      "Epoch [40/50], Step [577/735], Loss: 0.4893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Step [578/735], Loss: 0.3408\n",
      "Epoch [40/50], Step [579/735], Loss: 0.5640\n",
      "Epoch [40/50], Step [580/735], Loss: 0.2556\n",
      "Epoch [40/50], Step [581/735], Loss: 0.2293\n",
      "Epoch [40/50], Step [582/735], Loss: 0.1740\n",
      "Epoch [40/50], Step [583/735], Loss: 0.1573\n",
      "Epoch [40/50], Step [584/735], Loss: 0.1935\n",
      "Epoch [40/50], Step [585/735], Loss: 0.1903\n",
      "Epoch [40/50], Step [586/735], Loss: 1.1622\n",
      "Epoch [40/50], Step [587/735], Loss: 0.2513\n",
      "Epoch [40/50], Step [588/735], Loss: 0.2244\n",
      "Epoch [40/50], Step [589/735], Loss: 0.3259\n",
      "Epoch [40/50], Step [590/735], Loss: 0.5602\n",
      "Epoch [40/50], Step [591/735], Loss: 0.0833\n",
      "Epoch [40/50], Step [592/735], Loss: 0.3651\n",
      "Epoch [40/50], Step [593/735], Loss: 0.2816\n",
      "Epoch [40/50], Step [594/735], Loss: 0.3914\n",
      "Epoch [40/50], Step [595/735], Loss: 0.5389\n",
      "Epoch [40/50], Step [596/735], Loss: 0.3091\n",
      "Epoch [40/50], Step [597/735], Loss: 0.1757\n",
      "Epoch [40/50], Step [598/735], Loss: 0.5853\n",
      "Epoch [40/50], Step [599/735], Loss: 0.1739\n",
      "Epoch [40/50], Step [600/735], Loss: 0.0952\n",
      "Epoch [40/50], Step [601/735], Loss: 0.5524\n",
      "Epoch [40/50], Step [602/735], Loss: 0.1938\n",
      "Epoch [40/50], Step [603/735], Loss: 0.1410\n",
      "Epoch [40/50], Step [604/735], Loss: 0.2819\n",
      "Epoch [40/50], Step [605/735], Loss: 0.1409\n",
      "Epoch [40/50], Step [606/735], Loss: 0.3280\n",
      "Epoch [40/50], Step [607/735], Loss: 0.1426\n",
      "Epoch [40/50], Step [608/735], Loss: 0.3525\n",
      "Epoch [40/50], Step [609/735], Loss: 0.1642\n",
      "Epoch [40/50], Step [610/735], Loss: 0.2097\n",
      "Epoch [40/50], Step [611/735], Loss: 0.8798\n",
      "Epoch [40/50], Step [612/735], Loss: 0.0828\n",
      "Epoch [40/50], Step [613/735], Loss: 0.4718\n",
      "Epoch [40/50], Step [614/735], Loss: 0.4150\n",
      "Epoch [40/50], Step [615/735], Loss: 0.4607\n",
      "Epoch [40/50], Step [616/735], Loss: 0.1097\n",
      "Epoch [40/50], Step [617/735], Loss: 0.1089\n",
      "Epoch [40/50], Step [618/735], Loss: 0.7568\n",
      "Epoch [40/50], Step [619/735], Loss: 0.1361\n",
      "Epoch [40/50], Step [620/735], Loss: 0.4559\n",
      "Epoch [40/50], Step [621/735], Loss: 0.7446\n",
      "Epoch [40/50], Step [622/735], Loss: 0.1350\n",
      "Epoch [40/50], Step [623/735], Loss: 0.4567\n",
      "Epoch [40/50], Step [624/735], Loss: 0.2968\n",
      "Epoch [40/50], Step [625/735], Loss: 0.1605\n",
      "Epoch [40/50], Step [626/735], Loss: 0.4521\n",
      "Epoch [40/50], Step [627/735], Loss: 0.2592\n",
      "Epoch [40/50], Step [628/735], Loss: 0.3359\n",
      "Epoch [40/50], Step [629/735], Loss: 0.1958\n",
      "Epoch [40/50], Step [630/735], Loss: 0.4870\n",
      "Epoch [40/50], Step [631/735], Loss: 0.8947\n",
      "Epoch [40/50], Step [632/735], Loss: 0.3241\n",
      "Epoch [40/50], Step [633/735], Loss: 0.3638\n",
      "Epoch [40/50], Step [634/735], Loss: 0.7338\n",
      "Epoch [40/50], Step [635/735], Loss: 0.0993\n",
      "Epoch [40/50], Step [636/735], Loss: 0.1030\n",
      "Epoch [40/50], Step [637/735], Loss: 0.1436\n",
      "Epoch [40/50], Step [638/735], Loss: 0.1273\n",
      "Epoch [40/50], Step [639/735], Loss: 0.2530\n",
      "Epoch [40/50], Step [640/735], Loss: 0.1915\n",
      "Epoch [40/50], Step [641/735], Loss: 0.0509\n",
      "Epoch [40/50], Step [642/735], Loss: 0.1727\n",
      "Epoch [40/50], Step [643/735], Loss: 0.2660\n",
      "Epoch [40/50], Step [644/735], Loss: 0.4073\n",
      "Epoch [40/50], Step [645/735], Loss: 0.1745\n",
      "Epoch [40/50], Step [646/735], Loss: 0.6581\n",
      "Epoch [40/50], Step [647/735], Loss: 0.2088\n",
      "Epoch [40/50], Step [648/735], Loss: 0.1587\n",
      "Epoch [40/50], Step [649/735], Loss: 0.1318\n",
      "Epoch [40/50], Step [650/735], Loss: 0.2746\n",
      "Epoch [40/50], Step [651/735], Loss: 0.1014\n",
      "Epoch [40/50], Step [652/735], Loss: 0.8171\n",
      "Epoch [40/50], Step [653/735], Loss: 0.4694\n",
      "Epoch [40/50], Step [654/735], Loss: 0.2162\n",
      "Epoch [40/50], Step [655/735], Loss: 0.2937\n",
      "Epoch [40/50], Step [656/735], Loss: 0.3532\n",
      "Epoch [40/50], Step [657/735], Loss: 0.3442\n",
      "Epoch [40/50], Step [658/735], Loss: 0.3112\n",
      "Epoch [40/50], Step [659/735], Loss: 0.1566\n",
      "Epoch [40/50], Step [660/735], Loss: 0.3798\n",
      "Epoch [40/50], Step [661/735], Loss: 0.1981\n",
      "Epoch [40/50], Step [662/735], Loss: 0.2562\n",
      "Epoch [40/50], Step [663/735], Loss: 0.2317\n",
      "Epoch [40/50], Step [664/735], Loss: 0.1680\n",
      "Epoch [40/50], Step [665/735], Loss: 0.5506\n",
      "Epoch [40/50], Step [666/735], Loss: 0.5178\n",
      "Epoch [40/50], Step [667/735], Loss: 0.4530\n",
      "Epoch [40/50], Step [668/735], Loss: 0.3004\n",
      "Epoch [40/50], Step [669/735], Loss: 0.6155\n",
      "Epoch [40/50], Step [670/735], Loss: 0.2954\n",
      "Epoch [40/50], Step [671/735], Loss: 0.1936\n",
      "Epoch [40/50], Step [672/735], Loss: 0.4905\n",
      "Epoch [40/50], Step [673/735], Loss: 0.0519\n",
      "Epoch [40/50], Step [674/735], Loss: 0.6381\n",
      "Epoch [40/50], Step [675/735], Loss: 0.1334\n",
      "Epoch [40/50], Step [676/735], Loss: 0.3044\n",
      "Epoch [40/50], Step [677/735], Loss: 0.1232\n",
      "Epoch [40/50], Step [678/735], Loss: 0.3138\n",
      "Epoch [40/50], Step [679/735], Loss: 0.1683\n",
      "Epoch [40/50], Step [680/735], Loss: 0.0893\n",
      "Epoch [40/50], Step [681/735], Loss: 0.2651\n",
      "Epoch [40/50], Step [682/735], Loss: 0.1347\n",
      "Epoch [40/50], Step [683/735], Loss: 0.1652\n",
      "Epoch [40/50], Step [684/735], Loss: 0.0873\n",
      "Epoch [40/50], Step [685/735], Loss: 0.1317\n",
      "Epoch [40/50], Step [686/735], Loss: 0.2311\n",
      "Epoch [40/50], Step [687/735], Loss: 0.2812\n",
      "Epoch [40/50], Step [688/735], Loss: 0.1897\n",
      "Epoch [40/50], Step [689/735], Loss: 0.1575\n",
      "Epoch [40/50], Step [690/735], Loss: 0.2305\n",
      "Epoch [40/50], Step [691/735], Loss: 0.2884\n",
      "Epoch [40/50], Step [692/735], Loss: 0.2860\n",
      "Epoch [40/50], Step [693/735], Loss: 0.1381\n",
      "Epoch [40/50], Step [694/735], Loss: 0.3002\n",
      "Epoch [40/50], Step [695/735], Loss: 0.3784\n",
      "Epoch [40/50], Step [696/735], Loss: 0.1597\n",
      "Epoch [40/50], Step [697/735], Loss: 0.2355\n",
      "Epoch [40/50], Step [698/735], Loss: 0.3251\n",
      "Epoch [40/50], Step [699/735], Loss: 0.1947\n",
      "Epoch [40/50], Step [700/735], Loss: 0.2270\n",
      "Epoch [40/50], Step [701/735], Loss: 0.1452\n",
      "Epoch [40/50], Step [702/735], Loss: 0.1503\n",
      "Epoch [40/50], Step [703/735], Loss: 0.3577\n",
      "Epoch [40/50], Step [704/735], Loss: 0.1484\n",
      "Epoch [40/50], Step [705/735], Loss: 0.5130\n",
      "Epoch [40/50], Step [706/735], Loss: 0.0855\n",
      "Epoch [40/50], Step [707/735], Loss: 0.1696\n",
      "Epoch [40/50], Step [708/735], Loss: 0.3413\n",
      "Epoch [40/50], Step [709/735], Loss: 0.3006\n",
      "Epoch [40/50], Step [710/735], Loss: 0.1624\n",
      "Epoch [40/50], Step [711/735], Loss: 0.6453\n",
      "Epoch [40/50], Step [712/735], Loss: 0.5290\n",
      "Epoch [40/50], Step [713/735], Loss: 0.9356\n",
      "Epoch [40/50], Step [714/735], Loss: 0.1526\n",
      "Epoch [40/50], Step [715/735], Loss: 0.3144\n",
      "Epoch [40/50], Step [716/735], Loss: 0.2153\n",
      "Epoch [40/50], Step [717/735], Loss: 0.2919\n",
      "Epoch [40/50], Step [718/735], Loss: 0.1581\n",
      "Epoch [40/50], Step [719/735], Loss: 0.1285\n",
      "Epoch [40/50], Step [720/735], Loss: 0.2299\n",
      "Epoch [40/50], Step [721/735], Loss: 0.1361\n",
      "Epoch [40/50], Step [722/735], Loss: 0.1880\n",
      "Epoch [40/50], Step [723/735], Loss: 0.0933\n",
      "Epoch [40/50], Step [724/735], Loss: 0.1912\n",
      "Epoch [40/50], Step [725/735], Loss: 0.1591\n",
      "Epoch [40/50], Step [726/735], Loss: 0.0961\n",
      "Epoch [40/50], Step [727/735], Loss: 0.2342\n",
      "Epoch [40/50], Step [728/735], Loss: 0.0692\n",
      "Epoch [40/50], Step [729/735], Loss: 0.3324\n",
      "Epoch [40/50], Step [730/735], Loss: 0.1484\n",
      "Epoch [40/50], Step [731/735], Loss: 0.1214\n",
      "Epoch [40/50], Step [732/735], Loss: 0.1462\n",
      "Epoch [40/50], Step [733/735], Loss: 3.8663\n",
      "Epoch [40/50], Step [734/735], Loss: 0.1388\n",
      "Epoch [40/50], Step [735/735], Loss: 0.9928\n",
      "Epoch [41/50], Step [1/735], Loss: 0.3005\n",
      "Epoch [41/50], Step [2/735], Loss: 0.2494\n",
      "Epoch [41/50], Step [3/735], Loss: 0.3296\n",
      "Epoch [41/50], Step [4/735], Loss: 0.2412\n",
      "Epoch [41/50], Step [5/735], Loss: 0.4133\n",
      "Epoch [41/50], Step [6/735], Loss: 0.2690\n",
      "Epoch [41/50], Step [7/735], Loss: 0.2184\n",
      "Epoch [41/50], Step [8/735], Loss: 0.4633\n",
      "Epoch [41/50], Step [9/735], Loss: 0.2462\n",
      "Epoch [41/50], Step [10/735], Loss: 0.0514\n",
      "Epoch [41/50], Step [11/735], Loss: 0.3317\n",
      "Epoch [41/50], Step [12/735], Loss: 0.2604\n",
      "Epoch [41/50], Step [13/735], Loss: 0.1030\n",
      "Epoch [41/50], Step [14/735], Loss: 0.5187\n",
      "Epoch [41/50], Step [15/735], Loss: 0.0898\n",
      "Epoch [41/50], Step [16/735], Loss: 0.1700\n",
      "Epoch [41/50], Step [17/735], Loss: 0.3329\n",
      "Epoch [41/50], Step [18/735], Loss: 0.3541\n",
      "Epoch [41/50], Step [19/735], Loss: 0.1591\n",
      "Epoch [41/50], Step [20/735], Loss: 0.1528\n",
      "Epoch [41/50], Step [21/735], Loss: 0.7363\n",
      "Epoch [41/50], Step [22/735], Loss: 0.1780\n",
      "Epoch [41/50], Step [23/735], Loss: 0.1811\n",
      "Epoch [41/50], Step [24/735], Loss: 0.1712\n",
      "Epoch [41/50], Step [25/735], Loss: 0.1505\n",
      "Epoch [41/50], Step [26/735], Loss: 0.2633\n",
      "Epoch [41/50], Step [27/735], Loss: 0.3438\n",
      "Epoch [41/50], Step [28/735], Loss: 0.1389\n",
      "Epoch [41/50], Step [29/735], Loss: 0.4195\n",
      "Epoch [41/50], Step [30/735], Loss: 0.3673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Step [31/735], Loss: 0.3677\n",
      "Epoch [41/50], Step [32/735], Loss: 0.1291\n",
      "Epoch [41/50], Step [33/735], Loss: 0.2582\n",
      "Epoch [41/50], Step [34/735], Loss: 0.3138\n",
      "Epoch [41/50], Step [35/735], Loss: 0.1454\n",
      "Epoch [41/50], Step [36/735], Loss: 0.1978\n",
      "Epoch [41/50], Step [37/735], Loss: 0.3531\n",
      "Epoch [41/50], Step [38/735], Loss: 0.3044\n",
      "Epoch [41/50], Step [39/735], Loss: 0.0763\n",
      "Epoch [41/50], Step [40/735], Loss: 0.4874\n",
      "Epoch [41/50], Step [41/735], Loss: 0.2912\n",
      "Epoch [41/50], Step [42/735], Loss: 0.2405\n",
      "Epoch [41/50], Step [43/735], Loss: 0.1711\n",
      "Epoch [41/50], Step [44/735], Loss: 0.4278\n",
      "Epoch [41/50], Step [45/735], Loss: 0.0974\n",
      "Epoch [41/50], Step [46/735], Loss: 0.1787\n",
      "Epoch [41/50], Step [47/735], Loss: 0.0903\n",
      "Epoch [41/50], Step [48/735], Loss: 0.8119\n",
      "Epoch [41/50], Step [49/735], Loss: 0.2341\n",
      "Epoch [41/50], Step [50/735], Loss: 0.0740\n",
      "Epoch [41/50], Step [51/735], Loss: 0.2733\n",
      "Epoch [41/50], Step [52/735], Loss: 0.1547\n",
      "Epoch [41/50], Step [53/735], Loss: 0.0832\n",
      "Epoch [41/50], Step [54/735], Loss: 0.5725\n",
      "Epoch [41/50], Step [55/735], Loss: 0.0976\n",
      "Epoch [41/50], Step [56/735], Loss: 0.1508\n",
      "Epoch [41/50], Step [57/735], Loss: 0.2272\n",
      "Epoch [41/50], Step [58/735], Loss: 0.2824\n",
      "Epoch [41/50], Step [59/735], Loss: 0.1886\n",
      "Epoch [41/50], Step [60/735], Loss: 0.4517\n",
      "Epoch [41/50], Step [61/735], Loss: 0.2496\n",
      "Epoch [41/50], Step [62/735], Loss: 0.1226\n",
      "Epoch [41/50], Step [63/735], Loss: 0.1588\n",
      "Epoch [41/50], Step [64/735], Loss: 0.3947\n",
      "Epoch [41/50], Step [65/735], Loss: 1.0585\n",
      "Epoch [41/50], Step [66/735], Loss: 0.1287\n",
      "Epoch [41/50], Step [67/735], Loss: 0.2344\n",
      "Epoch [41/50], Step [68/735], Loss: 0.1816\n",
      "Epoch [41/50], Step [69/735], Loss: 2.9426\n",
      "Epoch [41/50], Step [70/735], Loss: 0.1740\n",
      "Epoch [41/50], Step [71/735], Loss: 0.3072\n",
      "Epoch [41/50], Step [72/735], Loss: 0.0959\n",
      "Epoch [41/50], Step [73/735], Loss: 0.1016\n",
      "Epoch [41/50], Step [74/735], Loss: 0.1883\n",
      "Epoch [41/50], Step [75/735], Loss: 0.2690\n",
      "Epoch [41/50], Step [76/735], Loss: 1.0833\n",
      "Epoch [41/50], Step [77/735], Loss: 0.1359\n",
      "Epoch [41/50], Step [78/735], Loss: 0.6167\n",
      "Epoch [41/50], Step [79/735], Loss: 0.3831\n",
      "Epoch [41/50], Step [80/735], Loss: 0.3172\n",
      "Epoch [41/50], Step [81/735], Loss: 0.0812\n",
      "Epoch [41/50], Step [82/735], Loss: 0.1359\n",
      "Epoch [41/50], Step [83/735], Loss: 0.3411\n",
      "Epoch [41/50], Step [84/735], Loss: 0.2893\n",
      "Epoch [41/50], Step [85/735], Loss: 0.3260\n",
      "Epoch [41/50], Step [86/735], Loss: 0.3059\n",
      "Epoch [41/50], Step [87/735], Loss: 0.3926\n",
      "Epoch [41/50], Step [88/735], Loss: 0.2452\n",
      "Epoch [41/50], Step [89/735], Loss: 0.2389\n",
      "Epoch [41/50], Step [90/735], Loss: 0.0790\n",
      "Epoch [41/50], Step [91/735], Loss: 0.0803\n",
      "Epoch [41/50], Step [92/735], Loss: 0.4644\n",
      "Epoch [41/50], Step [93/735], Loss: 0.2305\n",
      "Epoch [41/50], Step [94/735], Loss: 0.1042\n",
      "Epoch [41/50], Step [95/735], Loss: 2.5928\n",
      "Epoch [41/50], Step [96/735], Loss: 0.1919\n",
      "Epoch [41/50], Step [97/735], Loss: 0.2164\n",
      "Epoch [41/50], Step [98/735], Loss: 0.4394\n",
      "Epoch [41/50], Step [99/735], Loss: 0.1630\n",
      "Epoch [41/50], Step [100/735], Loss: 0.0951\n",
      "Epoch [41/50], Step [101/735], Loss: 0.3696\n",
      "Epoch [41/50], Step [102/735], Loss: 0.2911\n",
      "Epoch [41/50], Step [103/735], Loss: 0.1381\n",
      "Epoch [41/50], Step [104/735], Loss: 0.2802\n",
      "Epoch [41/50], Step [105/735], Loss: 0.6661\n",
      "Epoch [41/50], Step [106/735], Loss: 0.2341\n",
      "Epoch [41/50], Step [107/735], Loss: 0.3458\n",
      "Epoch [41/50], Step [108/735], Loss: 0.3120\n",
      "Epoch [41/50], Step [109/735], Loss: 0.4136\n",
      "Epoch [41/50], Step [110/735], Loss: 0.1969\n",
      "Epoch [41/50], Step [111/735], Loss: 0.8027\n",
      "Epoch [41/50], Step [112/735], Loss: 0.0932\n",
      "Epoch [41/50], Step [113/735], Loss: 0.1514\n",
      "Epoch [41/50], Step [114/735], Loss: 0.1147\n",
      "Epoch [41/50], Step [115/735], Loss: 0.1578\n",
      "Epoch [41/50], Step [116/735], Loss: 0.2988\n",
      "Epoch [41/50], Step [117/735], Loss: 0.1153\n",
      "Epoch [41/50], Step [118/735], Loss: 0.1912\n",
      "Epoch [41/50], Step [119/735], Loss: 0.2645\n",
      "Epoch [41/50], Step [120/735], Loss: 0.1640\n",
      "Epoch [41/50], Step [121/735], Loss: 0.3158\n",
      "Epoch [41/50], Step [122/735], Loss: 0.2932\n",
      "Epoch [41/50], Step [123/735], Loss: 0.1846\n",
      "Epoch [41/50], Step [124/735], Loss: 0.2232\n",
      "Epoch [41/50], Step [125/735], Loss: 0.4887\n",
      "Epoch [41/50], Step [126/735], Loss: 0.4792\n",
      "Epoch [41/50], Step [127/735], Loss: 0.1147\n",
      "Epoch [41/50], Step [128/735], Loss: 0.9814\n",
      "Epoch [41/50], Step [129/735], Loss: 0.2882\n",
      "Epoch [41/50], Step [130/735], Loss: 0.1517\n",
      "Epoch [41/50], Step [131/735], Loss: 0.1266\n",
      "Epoch [41/50], Step [132/735], Loss: 0.2191\n",
      "Epoch [41/50], Step [133/735], Loss: 0.2964\n",
      "Epoch [41/50], Step [134/735], Loss: 0.2295\n",
      "Epoch [41/50], Step [135/735], Loss: 0.2364\n",
      "Epoch [41/50], Step [136/735], Loss: 0.2043\n",
      "Epoch [41/50], Step [137/735], Loss: 0.3995\n",
      "Epoch [41/50], Step [138/735], Loss: 0.1940\n",
      "Epoch [41/50], Step [139/735], Loss: 0.0703\n",
      "Epoch [41/50], Step [140/735], Loss: 0.2183\n",
      "Epoch [41/50], Step [141/735], Loss: 0.2043\n",
      "Epoch [41/50], Step [142/735], Loss: 0.2677\n",
      "Epoch [41/50], Step [143/735], Loss: 0.2230\n",
      "Epoch [41/50], Step [144/735], Loss: 0.5843\n",
      "Epoch [41/50], Step [145/735], Loss: 0.1853\n",
      "Epoch [41/50], Step [146/735], Loss: 0.2355\n",
      "Epoch [41/50], Step [147/735], Loss: 0.1633\n",
      "Epoch [41/50], Step [148/735], Loss: 0.1297\n",
      "Epoch [41/50], Step [149/735], Loss: 0.4144\n",
      "Epoch [41/50], Step [150/735], Loss: 0.1852\n",
      "Epoch [41/50], Step [151/735], Loss: 1.2123\n",
      "Epoch [41/50], Step [152/735], Loss: 0.1382\n",
      "Epoch [41/50], Step [153/735], Loss: 0.6556\n",
      "Epoch [41/50], Step [154/735], Loss: 0.4804\n",
      "Epoch [41/50], Step [155/735], Loss: 0.7384\n",
      "Epoch [41/50], Step [156/735], Loss: 0.2091\n",
      "Epoch [41/50], Step [157/735], Loss: 0.1105\n",
      "Epoch [41/50], Step [158/735], Loss: 0.9246\n",
      "Epoch [41/50], Step [159/735], Loss: 0.4547\n",
      "Epoch [41/50], Step [160/735], Loss: 0.4237\n",
      "Epoch [41/50], Step [161/735], Loss: 0.1335\n",
      "Epoch [41/50], Step [162/735], Loss: 0.2344\n",
      "Epoch [41/50], Step [163/735], Loss: 0.2870\n",
      "Epoch [41/50], Step [164/735], Loss: 0.0707\n",
      "Epoch [41/50], Step [165/735], Loss: 0.3092\n",
      "Epoch [41/50], Step [166/735], Loss: 0.5841\n",
      "Epoch [41/50], Step [167/735], Loss: 0.2420\n",
      "Epoch [41/50], Step [168/735], Loss: 0.2141\n",
      "Epoch [41/50], Step [169/735], Loss: 0.1033\n",
      "Epoch [41/50], Step [170/735], Loss: 0.2769\n",
      "Epoch [41/50], Step [171/735], Loss: 0.1945\n",
      "Epoch [41/50], Step [172/735], Loss: 0.2415\n",
      "Epoch [41/50], Step [173/735], Loss: 0.7609\n",
      "Epoch [41/50], Step [174/735], Loss: 0.3233\n",
      "Epoch [41/50], Step [175/735], Loss: 0.7951\n",
      "Epoch [41/50], Step [176/735], Loss: 0.5981\n",
      "Epoch [41/50], Step [177/735], Loss: 0.5795\n",
      "Epoch [41/50], Step [178/735], Loss: 0.4258\n",
      "Epoch [41/50], Step [179/735], Loss: 0.2145\n",
      "Epoch [41/50], Step [180/735], Loss: 0.2597\n",
      "Epoch [41/50], Step [181/735], Loss: 0.9340\n",
      "Epoch [41/50], Step [182/735], Loss: 0.2613\n",
      "Epoch [41/50], Step [183/735], Loss: 0.5223\n",
      "Epoch [41/50], Step [184/735], Loss: 0.2553\n",
      "Epoch [41/50], Step [185/735], Loss: 0.2107\n",
      "Epoch [41/50], Step [186/735], Loss: 1.3440\n",
      "Epoch [41/50], Step [187/735], Loss: 0.3562\n",
      "Epoch [41/50], Step [188/735], Loss: 0.0545\n",
      "Epoch [41/50], Step [189/735], Loss: 0.1890\n",
      "Epoch [41/50], Step [190/735], Loss: 0.3016\n",
      "Epoch [41/50], Step [191/735], Loss: 0.1683\n",
      "Epoch [41/50], Step [192/735], Loss: 0.2672\n",
      "Epoch [41/50], Step [193/735], Loss: 0.3191\n",
      "Epoch [41/50], Step [194/735], Loss: 0.0590\n",
      "Epoch [41/50], Step [195/735], Loss: 0.5066\n",
      "Epoch [41/50], Step [196/735], Loss: 0.2943\n",
      "Epoch [41/50], Step [197/735], Loss: 0.4960\n",
      "Epoch [41/50], Step [198/735], Loss: 3.6694\n",
      "Epoch [41/50], Step [199/735], Loss: 0.2049\n",
      "Epoch [41/50], Step [200/735], Loss: 0.5377\n",
      "Epoch [41/50], Step [201/735], Loss: 0.2843\n",
      "Epoch [41/50], Step [202/735], Loss: 0.1965\n",
      "Epoch [41/50], Step [203/735], Loss: 0.1004\n",
      "Epoch [41/50], Step [204/735], Loss: 0.2273\n",
      "Epoch [41/50], Step [205/735], Loss: 0.2605\n",
      "Epoch [41/50], Step [206/735], Loss: 0.1778\n",
      "Epoch [41/50], Step [207/735], Loss: 0.1303\n",
      "Epoch [41/50], Step [208/735], Loss: 0.1097\n",
      "Epoch [41/50], Step [209/735], Loss: 0.4220\n",
      "Epoch [41/50], Step [210/735], Loss: 0.1635\n",
      "Epoch [41/50], Step [211/735], Loss: 0.8158\n",
      "Epoch [41/50], Step [212/735], Loss: 0.6230\n",
      "Epoch [41/50], Step [213/735], Loss: 0.9068\n",
      "Epoch [41/50], Step [214/735], Loss: 0.2370\n",
      "Epoch [41/50], Step [215/735], Loss: 0.1221\n",
      "Epoch [41/50], Step [216/735], Loss: 0.2297\n",
      "Epoch [41/50], Step [217/735], Loss: 0.3310\n",
      "Epoch [41/50], Step [218/735], Loss: 0.8041\n",
      "Epoch [41/50], Step [219/735], Loss: 0.2154\n",
      "Epoch [41/50], Step [220/735], Loss: 0.2751\n",
      "Epoch [41/50], Step [221/735], Loss: 0.1269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Step [222/735], Loss: 0.1942\n",
      "Epoch [41/50], Step [223/735], Loss: 0.0658\n",
      "Epoch [41/50], Step [224/735], Loss: 0.5282\n",
      "Epoch [41/50], Step [225/735], Loss: 0.2764\n",
      "Epoch [41/50], Step [226/735], Loss: 0.1160\n",
      "Epoch [41/50], Step [227/735], Loss: 0.0754\n",
      "Epoch [41/50], Step [228/735], Loss: 0.3882\n",
      "Epoch [41/50], Step [229/735], Loss: 0.1561\n",
      "Epoch [41/50], Step [230/735], Loss: 0.3439\n",
      "Epoch [41/50], Step [231/735], Loss: 0.3903\n",
      "Epoch [41/50], Step [232/735], Loss: 0.2611\n",
      "Epoch [41/50], Step [233/735], Loss: 0.2414\n",
      "Epoch [41/50], Step [234/735], Loss: 0.1201\n",
      "Epoch [41/50], Step [235/735], Loss: 0.1670\n",
      "Epoch [41/50], Step [236/735], Loss: 0.1321\n",
      "Epoch [41/50], Step [237/735], Loss: 0.2922\n",
      "Epoch [41/50], Step [238/735], Loss: 0.8826\n",
      "Epoch [41/50], Step [239/735], Loss: 0.2184\n",
      "Epoch [41/50], Step [240/735], Loss: 0.5983\n",
      "Epoch [41/50], Step [241/735], Loss: 0.3937\n",
      "Epoch [41/50], Step [242/735], Loss: 0.2464\n",
      "Epoch [41/50], Step [243/735], Loss: 0.1399\n",
      "Epoch [41/50], Step [244/735], Loss: 0.2682\n",
      "Epoch [41/50], Step [245/735], Loss: 0.2695\n",
      "Epoch [41/50], Step [246/735], Loss: 0.3685\n",
      "Epoch [41/50], Step [247/735], Loss: 0.3678\n",
      "Epoch [41/50], Step [248/735], Loss: 0.2457\n",
      "Epoch [41/50], Step [249/735], Loss: 0.2688\n",
      "Epoch [41/50], Step [250/735], Loss: 0.2756\n",
      "Epoch [41/50], Step [251/735], Loss: 0.2581\n",
      "Epoch [41/50], Step [252/735], Loss: 0.1957\n",
      "Epoch [41/50], Step [253/735], Loss: 0.1402\n",
      "Epoch [41/50], Step [254/735], Loss: 0.1611\n",
      "Epoch [41/50], Step [255/735], Loss: 0.9574\n",
      "Epoch [41/50], Step [256/735], Loss: 0.1590\n",
      "Epoch [41/50], Step [257/735], Loss: 0.7080\n",
      "Epoch [41/50], Step [258/735], Loss: 0.2149\n",
      "Epoch [41/50], Step [259/735], Loss: 0.2730\n",
      "Epoch [41/50], Step [260/735], Loss: 0.1940\n",
      "Epoch [41/50], Step [261/735], Loss: 0.1092\n",
      "Epoch [41/50], Step [262/735], Loss: 0.2308\n",
      "Epoch [41/50], Step [263/735], Loss: 0.3112\n",
      "Epoch [41/50], Step [264/735], Loss: 0.2358\n",
      "Epoch [41/50], Step [265/735], Loss: 0.4376\n",
      "Epoch [41/50], Step [266/735], Loss: 0.2216\n",
      "Epoch [41/50], Step [267/735], Loss: 0.7816\n",
      "Epoch [41/50], Step [268/735], Loss: 0.1352\n",
      "Epoch [41/50], Step [269/735], Loss: 0.1997\n",
      "Epoch [41/50], Step [270/735], Loss: 0.6544\n",
      "Epoch [41/50], Step [271/735], Loss: 0.1210\n",
      "Epoch [41/50], Step [272/735], Loss: 0.1751\n",
      "Epoch [41/50], Step [273/735], Loss: 0.4032\n",
      "Epoch [41/50], Step [274/735], Loss: 0.6772\n",
      "Epoch [41/50], Step [275/735], Loss: 0.2291\n",
      "Epoch [41/50], Step [276/735], Loss: 0.2646\n",
      "Epoch [41/50], Step [277/735], Loss: 0.1854\n",
      "Epoch [41/50], Step [278/735], Loss: 0.4540\n",
      "Epoch [41/50], Step [279/735], Loss: 0.1685\n",
      "Epoch [41/50], Step [280/735], Loss: 0.3789\n",
      "Epoch [41/50], Step [281/735], Loss: 0.2151\n",
      "Epoch [41/50], Step [282/735], Loss: 0.1827\n",
      "Epoch [41/50], Step [283/735], Loss: 0.2038\n",
      "Epoch [41/50], Step [284/735], Loss: 0.5331\n",
      "Epoch [41/50], Step [285/735], Loss: 0.2178\n",
      "Epoch [41/50], Step [286/735], Loss: 0.1389\n",
      "Epoch [41/50], Step [287/735], Loss: 0.3414\n",
      "Epoch [41/50], Step [288/735], Loss: 0.2768\n",
      "Epoch [41/50], Step [289/735], Loss: 0.1481\n",
      "Epoch [41/50], Step [290/735], Loss: 0.1520\n",
      "Epoch [41/50], Step [291/735], Loss: 0.5137\n",
      "Epoch [41/50], Step [292/735], Loss: 0.0949\n",
      "Epoch [41/50], Step [293/735], Loss: 0.1461\n",
      "Epoch [41/50], Step [294/735], Loss: 0.2351\n",
      "Epoch [41/50], Step [295/735], Loss: 0.2587\n",
      "Epoch [41/50], Step [296/735], Loss: 0.1434\n",
      "Epoch [41/50], Step [297/735], Loss: 0.3423\n",
      "Epoch [41/50], Step [298/735], Loss: 0.2202\n",
      "Epoch [41/50], Step [299/735], Loss: 0.1336\n",
      "Epoch [41/50], Step [300/735], Loss: 0.3965\n",
      "Epoch [41/50], Step [301/735], Loss: 0.6275\n",
      "Epoch [41/50], Step [302/735], Loss: 0.2029\n",
      "Epoch [41/50], Step [303/735], Loss: 0.1250\n",
      "Epoch [41/50], Step [304/735], Loss: 0.0681\n",
      "Epoch [41/50], Step [305/735], Loss: 0.0485\n",
      "Epoch [41/50], Step [306/735], Loss: 0.1721\n",
      "Epoch [41/50], Step [307/735], Loss: 0.1049\n",
      "Epoch [41/50], Step [308/735], Loss: 0.2386\n",
      "Epoch [41/50], Step [309/735], Loss: 0.1434\n",
      "Epoch [41/50], Step [310/735], Loss: 0.3048\n",
      "Epoch [41/50], Step [311/735], Loss: 0.3190\n",
      "Epoch [41/50], Step [312/735], Loss: 0.0656\n",
      "Epoch [41/50], Step [313/735], Loss: 0.3805\n",
      "Epoch [41/50], Step [314/735], Loss: 0.1463\n",
      "Epoch [41/50], Step [315/735], Loss: 0.0750\n",
      "Epoch [41/50], Step [316/735], Loss: 0.1712\n",
      "Epoch [41/50], Step [317/735], Loss: 0.4108\n",
      "Epoch [41/50], Step [318/735], Loss: 0.1381\n",
      "Epoch [41/50], Step [319/735], Loss: 0.2044\n",
      "Epoch [41/50], Step [320/735], Loss: 0.3258\n",
      "Epoch [41/50], Step [321/735], Loss: 0.2709\n",
      "Epoch [41/50], Step [322/735], Loss: 0.2215\n",
      "Epoch [41/50], Step [323/735], Loss: 0.2250\n",
      "Epoch [41/50], Step [324/735], Loss: 0.9226\n",
      "Epoch [41/50], Step [325/735], Loss: 0.2236\n",
      "Epoch [41/50], Step [326/735], Loss: 0.5337\n",
      "Epoch [41/50], Step [327/735], Loss: 0.2678\n",
      "Epoch [41/50], Step [328/735], Loss: 0.2570\n",
      "Epoch [41/50], Step [329/735], Loss: 0.1849\n",
      "Epoch [41/50], Step [330/735], Loss: 0.6893\n",
      "Epoch [41/50], Step [331/735], Loss: 0.6268\n",
      "Epoch [41/50], Step [332/735], Loss: 0.2637\n",
      "Epoch [41/50], Step [333/735], Loss: 0.2094\n",
      "Epoch [41/50], Step [334/735], Loss: 0.2896\n",
      "Epoch [41/50], Step [335/735], Loss: 0.1328\n",
      "Epoch [41/50], Step [336/735], Loss: 0.3616\n",
      "Epoch [41/50], Step [337/735], Loss: 0.3545\n",
      "Epoch [41/50], Step [338/735], Loss: 0.1511\n",
      "Epoch [41/50], Step [339/735], Loss: 0.1664\n",
      "Epoch [41/50], Step [340/735], Loss: 0.0754\n",
      "Epoch [41/50], Step [341/735], Loss: 0.1924\n",
      "Epoch [41/50], Step [342/735], Loss: 0.1170\n",
      "Epoch [41/50], Step [343/735], Loss: 0.2183\n",
      "Epoch [41/50], Step [344/735], Loss: 0.0957\n",
      "Epoch [41/50], Step [345/735], Loss: 0.2868\n",
      "Epoch [41/50], Step [346/735], Loss: 0.6286\n",
      "Epoch [41/50], Step [347/735], Loss: 0.0800\n",
      "Epoch [41/50], Step [348/735], Loss: 0.0934\n",
      "Epoch [41/50], Step [349/735], Loss: 0.4348\n",
      "Epoch [41/50], Step [350/735], Loss: 0.1388\n",
      "Epoch [41/50], Step [351/735], Loss: 0.3706\n",
      "Epoch [41/50], Step [352/735], Loss: 0.0706\n",
      "Epoch [41/50], Step [353/735], Loss: 0.2374\n",
      "Epoch [41/50], Step [354/735], Loss: 0.1934\n",
      "Epoch [41/50], Step [355/735], Loss: 0.7162\n",
      "Epoch [41/50], Step [356/735], Loss: 0.2320\n",
      "Epoch [41/50], Step [357/735], Loss: 0.1949\n",
      "Epoch [41/50], Step [358/735], Loss: 0.5943\n",
      "Epoch [41/50], Step [359/735], Loss: 0.7006\n",
      "Epoch [41/50], Step [360/735], Loss: 0.4146\n",
      "Epoch [41/50], Step [361/735], Loss: 0.3379\n",
      "Epoch [41/50], Step [362/735], Loss: 0.2770\n",
      "Epoch [41/50], Step [363/735], Loss: 0.2275\n",
      "Epoch [41/50], Step [364/735], Loss: 0.1486\n",
      "Epoch [41/50], Step [365/735], Loss: 0.3974\n",
      "Epoch [41/50], Step [366/735], Loss: 0.1516\n",
      "Epoch [41/50], Step [367/735], Loss: 0.1500\n",
      "Epoch [41/50], Step [368/735], Loss: 0.2301\n",
      "Epoch [41/50], Step [369/735], Loss: 0.1238\n",
      "Epoch [41/50], Step [370/735], Loss: 0.2165\n",
      "Epoch [41/50], Step [371/735], Loss: 0.5151\n",
      "Epoch [41/50], Step [372/735], Loss: 0.6106\n",
      "Epoch [41/50], Step [373/735], Loss: 0.2758\n",
      "Epoch [41/50], Step [374/735], Loss: 0.2892\n",
      "Epoch [41/50], Step [375/735], Loss: 0.3326\n",
      "Epoch [41/50], Step [376/735], Loss: 0.2703\n",
      "Epoch [41/50], Step [377/735], Loss: 0.2871\n",
      "Epoch [41/50], Step [378/735], Loss: 0.3122\n",
      "Epoch [41/50], Step [379/735], Loss: 0.2379\n",
      "Epoch [41/50], Step [380/735], Loss: 0.2946\n",
      "Epoch [41/50], Step [381/735], Loss: 0.2522\n",
      "Epoch [41/50], Step [382/735], Loss: 0.2562\n",
      "Epoch [41/50], Step [383/735], Loss: 0.2659\n",
      "Epoch [41/50], Step [384/735], Loss: 0.0473\n",
      "Epoch [41/50], Step [385/735], Loss: 0.1615\n",
      "Epoch [41/50], Step [386/735], Loss: 0.1264\n",
      "Epoch [41/50], Step [387/735], Loss: 0.2810\n",
      "Epoch [41/50], Step [388/735], Loss: 0.0668\n",
      "Epoch [41/50], Step [389/735], Loss: 0.4144\n",
      "Epoch [41/50], Step [390/735], Loss: 0.9698\n",
      "Epoch [41/50], Step [391/735], Loss: 0.3761\n",
      "Epoch [41/50], Step [392/735], Loss: 0.2794\n",
      "Epoch [41/50], Step [393/735], Loss: 0.3161\n",
      "Epoch [41/50], Step [394/735], Loss: 1.1206\n",
      "Epoch [41/50], Step [395/735], Loss: 0.0607\n",
      "Epoch [41/50], Step [396/735], Loss: 0.3725\n",
      "Epoch [41/50], Step [397/735], Loss: 0.3987\n",
      "Epoch [41/50], Step [398/735], Loss: 0.4014\n",
      "Epoch [41/50], Step [399/735], Loss: 0.1597\n",
      "Epoch [41/50], Step [400/735], Loss: 0.1232\n",
      "Epoch [41/50], Step [401/735], Loss: 0.1104\n",
      "Epoch [41/50], Step [402/735], Loss: 0.1965\n",
      "Epoch [41/50], Step [403/735], Loss: 3.5819\n",
      "Epoch [41/50], Step [404/735], Loss: 0.5401\n",
      "Epoch [41/50], Step [405/735], Loss: 0.0704\n",
      "Epoch [41/50], Step [406/735], Loss: 0.4220\n",
      "Epoch [41/50], Step [407/735], Loss: 0.1266\n",
      "Epoch [41/50], Step [408/735], Loss: 0.6840\n",
      "Epoch [41/50], Step [409/735], Loss: 0.0742\n",
      "Epoch [41/50], Step [410/735], Loss: 0.1551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Step [411/735], Loss: 0.1050\n",
      "Epoch [41/50], Step [412/735], Loss: 0.2068\n",
      "Epoch [41/50], Step [413/735], Loss: 0.4629\n",
      "Epoch [41/50], Step [414/735], Loss: 0.4421\n",
      "Epoch [41/50], Step [415/735], Loss: 0.0945\n",
      "Epoch [41/50], Step [416/735], Loss: 0.3299\n",
      "Epoch [41/50], Step [417/735], Loss: 0.1673\n",
      "Epoch [41/50], Step [418/735], Loss: 0.1461\n",
      "Epoch [41/50], Step [419/735], Loss: 0.0598\n",
      "Epoch [41/50], Step [420/735], Loss: 0.4467\n",
      "Epoch [41/50], Step [421/735], Loss: 0.5180\n",
      "Epoch [41/50], Step [422/735], Loss: 0.4807\n",
      "Epoch [41/50], Step [423/735], Loss: 0.2834\n",
      "Epoch [41/50], Step [424/735], Loss: 0.2900\n",
      "Epoch [41/50], Step [425/735], Loss: 0.3192\n",
      "Epoch [41/50], Step [426/735], Loss: 0.6174\n",
      "Epoch [41/50], Step [427/735], Loss: 0.4558\n",
      "Epoch [41/50], Step [428/735], Loss: 0.3720\n",
      "Epoch [41/50], Step [429/735], Loss: 0.3602\n",
      "Epoch [41/50], Step [430/735], Loss: 0.5145\n",
      "Epoch [41/50], Step [431/735], Loss: 0.1241\n",
      "Epoch [41/50], Step [432/735], Loss: 0.0985\n",
      "Epoch [41/50], Step [433/735], Loss: 0.2626\n",
      "Epoch [41/50], Step [434/735], Loss: 0.2728\n",
      "Epoch [41/50], Step [435/735], Loss: 0.5228\n",
      "Epoch [41/50], Step [436/735], Loss: 0.1969\n",
      "Epoch [41/50], Step [437/735], Loss: 0.9106\n",
      "Epoch [41/50], Step [438/735], Loss: 0.2901\n",
      "Epoch [41/50], Step [439/735], Loss: 0.1067\n",
      "Epoch [41/50], Step [440/735], Loss: 0.1757\n",
      "Epoch [41/50], Step [441/735], Loss: 0.7277\n",
      "Epoch [41/50], Step [442/735], Loss: 0.4057\n",
      "Epoch [41/50], Step [443/735], Loss: 0.0623\n",
      "Epoch [41/50], Step [444/735], Loss: 0.4321\n",
      "Epoch [41/50], Step [445/735], Loss: 0.1383\n",
      "Epoch [41/50], Step [446/735], Loss: 0.0949\n",
      "Epoch [41/50], Step [447/735], Loss: 0.1593\n",
      "Epoch [41/50], Step [448/735], Loss: 0.7048\n",
      "Epoch [41/50], Step [449/735], Loss: 2.5081\n",
      "Epoch [41/50], Step [450/735], Loss: 0.1128\n",
      "Epoch [41/50], Step [451/735], Loss: 0.3467\n",
      "Epoch [41/50], Step [452/735], Loss: 0.5124\n",
      "Epoch [41/50], Step [453/735], Loss: 0.2026\n",
      "Epoch [41/50], Step [454/735], Loss: 1.4954\n",
      "Epoch [41/50], Step [455/735], Loss: 0.2442\n",
      "Epoch [41/50], Step [456/735], Loss: 0.3003\n",
      "Epoch [41/50], Step [457/735], Loss: 0.1466\n",
      "Epoch [41/50], Step [458/735], Loss: 0.3914\n",
      "Epoch [41/50], Step [459/735], Loss: 0.1693\n",
      "Epoch [41/50], Step [460/735], Loss: 0.5784\n",
      "Epoch [41/50], Step [461/735], Loss: 0.3342\n",
      "Epoch [41/50], Step [462/735], Loss: 0.2614\n",
      "Epoch [41/50], Step [463/735], Loss: 0.6028\n",
      "Epoch [41/50], Step [464/735], Loss: 0.6468\n",
      "Epoch [41/50], Step [465/735], Loss: 0.3105\n",
      "Epoch [41/50], Step [466/735], Loss: 0.1426\n",
      "Epoch [41/50], Step [467/735], Loss: 1.0481\n",
      "Epoch [41/50], Step [468/735], Loss: 0.1765\n",
      "Epoch [41/50], Step [469/735], Loss: 0.1701\n",
      "Epoch [41/50], Step [470/735], Loss: 0.0882\n",
      "Epoch [41/50], Step [471/735], Loss: 0.1068\n",
      "Epoch [41/50], Step [472/735], Loss: 0.2566\n",
      "Epoch [41/50], Step [473/735], Loss: 0.1867\n",
      "Epoch [41/50], Step [474/735], Loss: 0.5441\n",
      "Epoch [41/50], Step [475/735], Loss: 0.1928\n",
      "Epoch [41/50], Step [476/735], Loss: 1.3367\n",
      "Epoch [41/50], Step [477/735], Loss: 0.2372\n",
      "Epoch [41/50], Step [478/735], Loss: 0.3509\n",
      "Epoch [41/50], Step [479/735], Loss: 0.0968\n",
      "Epoch [41/50], Step [480/735], Loss: 0.2221\n",
      "Epoch [41/50], Step [481/735], Loss: 0.2098\n",
      "Epoch [41/50], Step [482/735], Loss: 0.7996\n",
      "Epoch [41/50], Step [483/735], Loss: 0.2220\n",
      "Epoch [41/50], Step [484/735], Loss: 0.3611\n",
      "Epoch [41/50], Step [485/735], Loss: 0.6132\n",
      "Epoch [41/50], Step [486/735], Loss: 0.6498\n",
      "Epoch [41/50], Step [487/735], Loss: 0.1199\n",
      "Epoch [41/50], Step [488/735], Loss: 0.2139\n",
      "Epoch [41/50], Step [489/735], Loss: 0.4622\n",
      "Epoch [41/50], Step [490/735], Loss: 0.3289\n",
      "Epoch [41/50], Step [491/735], Loss: 0.6341\n",
      "Epoch [41/50], Step [492/735], Loss: 0.2703\n",
      "Epoch [41/50], Step [493/735], Loss: 0.4946\n",
      "Epoch [41/50], Step [494/735], Loss: 0.4299\n",
      "Epoch [41/50], Step [495/735], Loss: 0.3138\n",
      "Epoch [41/50], Step [496/735], Loss: 0.4182\n",
      "Epoch [41/50], Step [497/735], Loss: 0.4052\n",
      "Epoch [41/50], Step [498/735], Loss: 0.1317\n",
      "Epoch [41/50], Step [499/735], Loss: 0.1889\n",
      "Epoch [41/50], Step [500/735], Loss: 1.1946\n",
      "Epoch [41/50], Step [501/735], Loss: 0.3892\n",
      "Epoch [41/50], Step [502/735], Loss: 0.3613\n",
      "Epoch [41/50], Step [503/735], Loss: 0.3615\n",
      "Epoch [41/50], Step [504/735], Loss: 0.1474\n",
      "Epoch [41/50], Step [505/735], Loss: 0.3888\n",
      "Epoch [41/50], Step [506/735], Loss: 0.1702\n",
      "Epoch [41/50], Step [507/735], Loss: 0.0852\n",
      "Epoch [41/50], Step [508/735], Loss: 0.4136\n",
      "Epoch [41/50], Step [509/735], Loss: 0.1968\n",
      "Epoch [41/50], Step [510/735], Loss: 0.3558\n",
      "Epoch [41/50], Step [511/735], Loss: 0.1154\n",
      "Epoch [41/50], Step [512/735], Loss: 0.6705\n",
      "Epoch [41/50], Step [513/735], Loss: 0.4434\n",
      "Epoch [41/50], Step [514/735], Loss: 0.3256\n",
      "Epoch [41/50], Step [515/735], Loss: 0.1781\n",
      "Epoch [41/50], Step [516/735], Loss: 0.7059\n",
      "Epoch [41/50], Step [517/735], Loss: 0.5521\n",
      "Epoch [41/50], Step [518/735], Loss: 0.2342\n",
      "Epoch [41/50], Step [519/735], Loss: 0.1876\n",
      "Epoch [41/50], Step [520/735], Loss: 0.3317\n",
      "Epoch [41/50], Step [521/735], Loss: 0.2243\n",
      "Epoch [41/50], Step [522/735], Loss: 0.2984\n",
      "Epoch [41/50], Step [523/735], Loss: 0.7020\n",
      "Epoch [41/50], Step [524/735], Loss: 0.9341\n",
      "Epoch [41/50], Step [525/735], Loss: 0.1987\n",
      "Epoch [41/50], Step [526/735], Loss: 0.2029\n",
      "Epoch [41/50], Step [527/735], Loss: 0.1354\n",
      "Epoch [41/50], Step [528/735], Loss: 0.1265\n",
      "Epoch [41/50], Step [529/735], Loss: 0.1397\n",
      "Epoch [41/50], Step [530/735], Loss: 0.1129\n",
      "Epoch [41/50], Step [531/735], Loss: 0.3371\n",
      "Epoch [41/50], Step [532/735], Loss: 0.3570\n",
      "Epoch [41/50], Step [533/735], Loss: 0.1280\n",
      "Epoch [41/50], Step [534/735], Loss: 0.2689\n",
      "Epoch [41/50], Step [535/735], Loss: 0.2656\n",
      "Epoch [41/50], Step [536/735], Loss: 0.9602\n",
      "Epoch [41/50], Step [537/735], Loss: 0.4745\n",
      "Epoch [41/50], Step [538/735], Loss: 0.1035\n",
      "Epoch [41/50], Step [539/735], Loss: 0.1236\n",
      "Epoch [41/50], Step [540/735], Loss: 0.3277\n",
      "Epoch [41/50], Step [541/735], Loss: 1.0369\n",
      "Epoch [41/50], Step [542/735], Loss: 0.3599\n",
      "Epoch [41/50], Step [543/735], Loss: 0.1855\n",
      "Epoch [41/50], Step [544/735], Loss: 0.0948\n",
      "Epoch [41/50], Step [545/735], Loss: 0.2557\n",
      "Epoch [41/50], Step [546/735], Loss: 0.3872\n",
      "Epoch [41/50], Step [547/735], Loss: 0.2839\n",
      "Epoch [41/50], Step [548/735], Loss: 0.9076\n",
      "Epoch [41/50], Step [549/735], Loss: 0.1982\n",
      "Epoch [41/50], Step [550/735], Loss: 0.1405\n",
      "Epoch [41/50], Step [551/735], Loss: 0.6900\n",
      "Epoch [41/50], Step [552/735], Loss: 0.7110\n",
      "Epoch [41/50], Step [553/735], Loss: 0.7142\n",
      "Epoch [41/50], Step [554/735], Loss: 0.2382\n",
      "Epoch [41/50], Step [555/735], Loss: 0.5112\n",
      "Epoch [41/50], Step [556/735], Loss: 0.5359\n",
      "Epoch [41/50], Step [557/735], Loss: 0.2345\n",
      "Epoch [41/50], Step [558/735], Loss: 0.3450\n",
      "Epoch [41/50], Step [559/735], Loss: 0.3306\n",
      "Epoch [41/50], Step [560/735], Loss: 0.3508\n",
      "Epoch [41/50], Step [561/735], Loss: 0.6278\n",
      "Epoch [41/50], Step [562/735], Loss: 0.2878\n",
      "Epoch [41/50], Step [563/735], Loss: 0.1627\n",
      "Epoch [41/50], Step [564/735], Loss: 0.2790\n",
      "Epoch [41/50], Step [565/735], Loss: 0.1551\n",
      "Epoch [41/50], Step [566/735], Loss: 0.4133\n",
      "Epoch [41/50], Step [567/735], Loss: 0.0815\n",
      "Epoch [41/50], Step [568/735], Loss: 0.4046\n",
      "Epoch [41/50], Step [569/735], Loss: 0.0894\n",
      "Epoch [41/50], Step [570/735], Loss: 0.2779\n",
      "Epoch [41/50], Step [571/735], Loss: 0.1687\n",
      "Epoch [41/50], Step [572/735], Loss: 0.2629\n",
      "Epoch [41/50], Step [573/735], Loss: 0.2102\n",
      "Epoch [41/50], Step [574/735], Loss: 0.1868\n",
      "Epoch [41/50], Step [575/735], Loss: 0.4494\n",
      "Epoch [41/50], Step [576/735], Loss: 0.5023\n",
      "Epoch [41/50], Step [577/735], Loss: 0.3703\n",
      "Epoch [41/50], Step [578/735], Loss: 0.4642\n",
      "Epoch [41/50], Step [579/735], Loss: 0.4518\n",
      "Epoch [41/50], Step [580/735], Loss: 0.1887\n",
      "Epoch [41/50], Step [581/735], Loss: 0.1880\n",
      "Epoch [41/50], Step [582/735], Loss: 0.1648\n",
      "Epoch [41/50], Step [583/735], Loss: 0.2042\n",
      "Epoch [41/50], Step [584/735], Loss: 0.2376\n",
      "Epoch [41/50], Step [585/735], Loss: 0.4707\n",
      "Epoch [41/50], Step [586/735], Loss: 0.1810\n",
      "Epoch [41/50], Step [587/735], Loss: 0.0821\n",
      "Epoch [41/50], Step [588/735], Loss: 0.0896\n",
      "Epoch [41/50], Step [589/735], Loss: 0.0894\n",
      "Epoch [41/50], Step [590/735], Loss: 0.3072\n",
      "Epoch [41/50], Step [591/735], Loss: 0.0847\n",
      "Epoch [41/50], Step [592/735], Loss: 0.3362\n",
      "Epoch [41/50], Step [593/735], Loss: 0.1789\n",
      "Epoch [41/50], Step [594/735], Loss: 0.1951\n",
      "Epoch [41/50], Step [595/735], Loss: 0.3822\n",
      "Epoch [41/50], Step [596/735], Loss: 0.7545\n",
      "Epoch [41/50], Step [597/735], Loss: 0.2756\n",
      "Epoch [41/50], Step [598/735], Loss: 0.1771\n",
      "Epoch [41/50], Step [599/735], Loss: 0.1869\n",
      "Epoch [41/50], Step [600/735], Loss: 0.3487\n",
      "Epoch [41/50], Step [601/735], Loss: 0.2356\n",
      "Epoch [41/50], Step [602/735], Loss: 0.1033\n",
      "Epoch [41/50], Step [603/735], Loss: 0.0935\n",
      "Epoch [41/50], Step [604/735], Loss: 0.1248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Step [605/735], Loss: 0.7875\n",
      "Epoch [41/50], Step [606/735], Loss: 0.1926\n",
      "Epoch [41/50], Step [607/735], Loss: 0.2422\n",
      "Epoch [41/50], Step [608/735], Loss: 0.2251\n",
      "Epoch [41/50], Step [609/735], Loss: 0.1955\n",
      "Epoch [41/50], Step [610/735], Loss: 0.6737\n",
      "Epoch [41/50], Step [611/735], Loss: 0.1845\n",
      "Epoch [41/50], Step [612/735], Loss: 0.3111\n",
      "Epoch [41/50], Step [613/735], Loss: 0.0754\n",
      "Epoch [41/50], Step [614/735], Loss: 0.2762\n",
      "Epoch [41/50], Step [615/735], Loss: 0.3329\n",
      "Epoch [41/50], Step [616/735], Loss: 0.3768\n",
      "Epoch [41/50], Step [617/735], Loss: 0.1378\n",
      "Epoch [41/50], Step [618/735], Loss: 0.3117\n",
      "Epoch [41/50], Step [619/735], Loss: 0.5603\n",
      "Epoch [41/50], Step [620/735], Loss: 0.7882\n",
      "Epoch [41/50], Step [621/735], Loss: 0.1936\n",
      "Epoch [41/50], Step [622/735], Loss: 0.1929\n",
      "Epoch [41/50], Step [623/735], Loss: 0.2703\n",
      "Epoch [41/50], Step [624/735], Loss: 0.2744\n",
      "Epoch [41/50], Step [625/735], Loss: 0.3016\n",
      "Epoch [41/50], Step [626/735], Loss: 0.3927\n",
      "Epoch [41/50], Step [627/735], Loss: 0.1537\n",
      "Epoch [41/50], Step [628/735], Loss: 0.1028\n",
      "Epoch [41/50], Step [629/735], Loss: 0.1596\n",
      "Epoch [41/50], Step [630/735], Loss: 0.5092\n",
      "Epoch [41/50], Step [631/735], Loss: 0.2288\n",
      "Epoch [41/50], Step [632/735], Loss: 0.1110\n",
      "Epoch [41/50], Step [633/735], Loss: 0.3195\n",
      "Epoch [41/50], Step [634/735], Loss: 0.3019\n",
      "Epoch [41/50], Step [635/735], Loss: 0.1204\n",
      "Epoch [41/50], Step [636/735], Loss: 0.1727\n",
      "Epoch [41/50], Step [637/735], Loss: 0.3463\n",
      "Epoch [41/50], Step [638/735], Loss: 0.6785\n",
      "Epoch [41/50], Step [639/735], Loss: 0.1446\n",
      "Epoch [41/50], Step [640/735], Loss: 0.2656\n",
      "Epoch [41/50], Step [641/735], Loss: 0.1786\n",
      "Epoch [41/50], Step [642/735], Loss: 0.3886\n",
      "Epoch [41/50], Step [643/735], Loss: 0.1789\n",
      "Epoch [41/50], Step [644/735], Loss: 0.5507\n",
      "Epoch [41/50], Step [645/735], Loss: 0.4311\n",
      "Epoch [41/50], Step [646/735], Loss: 0.1200\n",
      "Epoch [41/50], Step [647/735], Loss: 0.2248\n",
      "Epoch [41/50], Step [648/735], Loss: 0.1191\n",
      "Epoch [41/50], Step [649/735], Loss: 0.2478\n",
      "Epoch [41/50], Step [650/735], Loss: 0.2776\n",
      "Epoch [41/50], Step [651/735], Loss: 0.2403\n",
      "Epoch [41/50], Step [652/735], Loss: 0.1655\n",
      "Epoch [41/50], Step [653/735], Loss: 0.1811\n",
      "Epoch [41/50], Step [654/735], Loss: 0.1067\n",
      "Epoch [41/50], Step [655/735], Loss: 0.3080\n",
      "Epoch [41/50], Step [656/735], Loss: 0.1372\n",
      "Epoch [41/50], Step [657/735], Loss: 0.4285\n",
      "Epoch [41/50], Step [658/735], Loss: 0.1643\n",
      "Epoch [41/50], Step [659/735], Loss: 0.1868\n",
      "Epoch [41/50], Step [660/735], Loss: 0.5148\n",
      "Epoch [41/50], Step [661/735], Loss: 0.2006\n",
      "Epoch [41/50], Step [662/735], Loss: 0.2718\n",
      "Epoch [41/50], Step [663/735], Loss: 0.1557\n",
      "Epoch [41/50], Step [664/735], Loss: 0.2563\n",
      "Epoch [41/50], Step [665/735], Loss: 0.6421\n",
      "Epoch [41/50], Step [666/735], Loss: 0.3547\n",
      "Epoch [41/50], Step [667/735], Loss: 0.1419\n",
      "Epoch [41/50], Step [668/735], Loss: 0.1693\n",
      "Epoch [41/50], Step [669/735], Loss: 0.2035\n",
      "Epoch [41/50], Step [670/735], Loss: 0.0943\n",
      "Epoch [41/50], Step [671/735], Loss: 0.7884\n",
      "Epoch [41/50], Step [672/735], Loss: 0.1817\n",
      "Epoch [41/50], Step [673/735], Loss: 0.0657\n",
      "Epoch [41/50], Step [674/735], Loss: 0.1134\n",
      "Epoch [41/50], Step [675/735], Loss: 0.1471\n",
      "Epoch [41/50], Step [676/735], Loss: 0.3475\n",
      "Epoch [41/50], Step [677/735], Loss: 0.2555\n",
      "Epoch [41/50], Step [678/735], Loss: 0.4451\n",
      "Epoch [41/50], Step [679/735], Loss: 0.3455\n",
      "Epoch [41/50], Step [680/735], Loss: 0.1382\n",
      "Epoch [41/50], Step [681/735], Loss: 0.0584\n",
      "Epoch [41/50], Step [682/735], Loss: 0.2288\n",
      "Epoch [41/50], Step [683/735], Loss: 0.9723\n",
      "Epoch [41/50], Step [684/735], Loss: 0.1485\n",
      "Epoch [41/50], Step [685/735], Loss: 0.3269\n",
      "Epoch [41/50], Step [686/735], Loss: 0.0779\n",
      "Epoch [41/50], Step [687/735], Loss: 0.1895\n",
      "Epoch [41/50], Step [688/735], Loss: 0.6808\n",
      "Epoch [41/50], Step [689/735], Loss: 0.0950\n",
      "Epoch [41/50], Step [690/735], Loss: 0.4009\n",
      "Epoch [41/50], Step [691/735], Loss: 0.1102\n",
      "Epoch [41/50], Step [692/735], Loss: 0.1866\n",
      "Epoch [41/50], Step [693/735], Loss: 0.3540\n",
      "Epoch [41/50], Step [694/735], Loss: 0.3738\n",
      "Epoch [41/50], Step [695/735], Loss: 0.0907\n",
      "Epoch [41/50], Step [696/735], Loss: 0.2104\n",
      "Epoch [41/50], Step [697/735], Loss: 0.1452\n",
      "Epoch [41/50], Step [698/735], Loss: 0.8934\n",
      "Epoch [41/50], Step [699/735], Loss: 0.0550\n",
      "Epoch [41/50], Step [700/735], Loss: 0.3484\n",
      "Epoch [41/50], Step [701/735], Loss: 0.2014\n",
      "Epoch [41/50], Step [702/735], Loss: 0.3334\n",
      "Epoch [41/50], Step [703/735], Loss: 0.2914\n",
      "Epoch [41/50], Step [704/735], Loss: 0.1333\n",
      "Epoch [41/50], Step [705/735], Loss: 0.0497\n",
      "Epoch [41/50], Step [706/735], Loss: 0.2151\n",
      "Epoch [41/50], Step [707/735], Loss: 0.2887\n",
      "Epoch [41/50], Step [708/735], Loss: 0.3005\n",
      "Epoch [41/50], Step [709/735], Loss: 0.0923\n",
      "Epoch [41/50], Step [710/735], Loss: 0.9403\n",
      "Epoch [41/50], Step [711/735], Loss: 0.3227\n",
      "Epoch [41/50], Step [712/735], Loss: 0.1801\n",
      "Epoch [41/50], Step [713/735], Loss: 0.2894\n",
      "Epoch [41/50], Step [714/735], Loss: 0.3718\n",
      "Epoch [41/50], Step [715/735], Loss: 0.3322\n",
      "Epoch [41/50], Step [716/735], Loss: 0.4192\n",
      "Epoch [41/50], Step [717/735], Loss: 0.2227\n",
      "Epoch [41/50], Step [718/735], Loss: 0.2177\n",
      "Epoch [41/50], Step [719/735], Loss: 0.1352\n",
      "Epoch [41/50], Step [720/735], Loss: 0.1692\n",
      "Epoch [41/50], Step [721/735], Loss: 0.4883\n",
      "Epoch [41/50], Step [722/735], Loss: 0.1393\n",
      "Epoch [41/50], Step [723/735], Loss: 0.1761\n",
      "Epoch [41/50], Step [724/735], Loss: 0.1400\n",
      "Epoch [41/50], Step [725/735], Loss: 0.1249\n",
      "Epoch [41/50], Step [726/735], Loss: 0.2468\n",
      "Epoch [41/50], Step [727/735], Loss: 0.1655\n",
      "Epoch [41/50], Step [728/735], Loss: 0.6594\n",
      "Epoch [41/50], Step [729/735], Loss: 0.1963\n",
      "Epoch [41/50], Step [730/735], Loss: 0.1822\n",
      "Epoch [41/50], Step [731/735], Loss: 0.1332\n",
      "Epoch [41/50], Step [732/735], Loss: 0.1160\n",
      "Epoch [41/50], Step [733/735], Loss: 0.6436\n",
      "Epoch [41/50], Step [734/735], Loss: 0.4775\n",
      "Epoch [41/50], Step [735/735], Loss: 0.0611\n",
      "Epoch [42/50], Step [1/735], Loss: 0.2607\n",
      "Epoch [42/50], Step [2/735], Loss: 0.0748\n",
      "Epoch [42/50], Step [3/735], Loss: 0.1769\n",
      "Epoch [42/50], Step [4/735], Loss: 0.1866\n",
      "Epoch [42/50], Step [5/735], Loss: 0.1974\n",
      "Epoch [42/50], Step [6/735], Loss: 0.1558\n",
      "Epoch [42/50], Step [7/735], Loss: 0.4532\n",
      "Epoch [42/50], Step [8/735], Loss: 0.1616\n",
      "Epoch [42/50], Step [9/735], Loss: 0.3352\n",
      "Epoch [42/50], Step [10/735], Loss: 1.0056\n",
      "Epoch [42/50], Step [11/735], Loss: 0.4431\n",
      "Epoch [42/50], Step [12/735], Loss: 0.4579\n",
      "Epoch [42/50], Step [13/735], Loss: 0.2027\n",
      "Epoch [42/50], Step [14/735], Loss: 0.1592\n",
      "Epoch [42/50], Step [15/735], Loss: 0.3071\n",
      "Epoch [42/50], Step [16/735], Loss: 0.3140\n",
      "Epoch [42/50], Step [17/735], Loss: 0.5677\n",
      "Epoch [42/50], Step [18/735], Loss: 0.1274\n",
      "Epoch [42/50], Step [19/735], Loss: 0.1941\n",
      "Epoch [42/50], Step [20/735], Loss: 0.3047\n",
      "Epoch [42/50], Step [21/735], Loss: 0.2798\n",
      "Epoch [42/50], Step [22/735], Loss: 0.1776\n",
      "Epoch [42/50], Step [23/735], Loss: 3.3316\n",
      "Epoch [42/50], Step [24/735], Loss: 0.2555\n",
      "Epoch [42/50], Step [25/735], Loss: 0.1609\n",
      "Epoch [42/50], Step [26/735], Loss: 0.2897\n",
      "Epoch [42/50], Step [27/735], Loss: 0.5354\n",
      "Epoch [42/50], Step [28/735], Loss: 0.2972\n",
      "Epoch [42/50], Step [29/735], Loss: 0.2636\n",
      "Epoch [42/50], Step [30/735], Loss: 0.1134\n",
      "Epoch [42/50], Step [31/735], Loss: 0.1400\n",
      "Epoch [42/50], Step [32/735], Loss: 0.3686\n",
      "Epoch [42/50], Step [33/735], Loss: 0.9113\n",
      "Epoch [42/50], Step [34/735], Loss: 0.2455\n",
      "Epoch [42/50], Step [35/735], Loss: 0.3707\n",
      "Epoch [42/50], Step [36/735], Loss: 0.1747\n",
      "Epoch [42/50], Step [37/735], Loss: 0.3126\n",
      "Epoch [42/50], Step [38/735], Loss: 0.1971\n",
      "Epoch [42/50], Step [39/735], Loss: 0.1799\n",
      "Epoch [42/50], Step [40/735], Loss: 0.1682\n",
      "Epoch [42/50], Step [41/735], Loss: 0.2854\n",
      "Epoch [42/50], Step [42/735], Loss: 0.2134\n",
      "Epoch [42/50], Step [43/735], Loss: 0.1615\n",
      "Epoch [42/50], Step [44/735], Loss: 0.2302\n",
      "Epoch [42/50], Step [45/735], Loss: 2.7333\n",
      "Epoch [42/50], Step [46/735], Loss: 0.1729\n",
      "Epoch [42/50], Step [47/735], Loss: 0.2317\n",
      "Epoch [42/50], Step [48/735], Loss: 0.5246\n",
      "Epoch [42/50], Step [49/735], Loss: 0.4274\n",
      "Epoch [42/50], Step [50/735], Loss: 0.1725\n",
      "Epoch [42/50], Step [51/735], Loss: 0.2173\n",
      "Epoch [42/50], Step [52/735], Loss: 0.2830\n",
      "Epoch [42/50], Step [53/735], Loss: 0.1182\n",
      "Epoch [42/50], Step [54/735], Loss: 0.1292\n",
      "Epoch [42/50], Step [55/735], Loss: 0.0960\n",
      "Epoch [42/50], Step [56/735], Loss: 0.0538\n",
      "Epoch [42/50], Step [57/735], Loss: 0.1925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Step [58/735], Loss: 0.1065\n",
      "Epoch [42/50], Step [59/735], Loss: 0.5291\n",
      "Epoch [42/50], Step [60/735], Loss: 0.2975\n",
      "Epoch [42/50], Step [61/735], Loss: 0.7401\n",
      "Epoch [42/50], Step [62/735], Loss: 0.2115\n",
      "Epoch [42/50], Step [63/735], Loss: 0.1639\n",
      "Epoch [42/50], Step [64/735], Loss: 0.1216\n",
      "Epoch [42/50], Step [65/735], Loss: 0.2907\n",
      "Epoch [42/50], Step [66/735], Loss: 0.3129\n",
      "Epoch [42/50], Step [67/735], Loss: 0.2783\n",
      "Epoch [42/50], Step [68/735], Loss: 0.1637\n",
      "Epoch [42/50], Step [69/735], Loss: 0.8260\n",
      "Epoch [42/50], Step [70/735], Loss: 0.0998\n",
      "Epoch [42/50], Step [71/735], Loss: 0.1207\n",
      "Epoch [42/50], Step [72/735], Loss: 0.3251\n",
      "Epoch [42/50], Step [73/735], Loss: 0.1072\n",
      "Epoch [42/50], Step [74/735], Loss: 0.2422\n",
      "Epoch [42/50], Step [75/735], Loss: 0.3601\n",
      "Epoch [42/50], Step [76/735], Loss: 0.1398\n",
      "Epoch [42/50], Step [77/735], Loss: 0.1988\n",
      "Epoch [42/50], Step [78/735], Loss: 0.3437\n",
      "Epoch [42/50], Step [79/735], Loss: 0.1161\n",
      "Epoch [42/50], Step [80/735], Loss: 0.1487\n",
      "Epoch [42/50], Step [81/735], Loss: 0.2283\n",
      "Epoch [42/50], Step [82/735], Loss: 0.6275\n",
      "Epoch [42/50], Step [83/735], Loss: 0.4524\n",
      "Epoch [42/50], Step [84/735], Loss: 0.1355\n",
      "Epoch [42/50], Step [85/735], Loss: 0.0925\n",
      "Epoch [42/50], Step [86/735], Loss: 0.2547\n",
      "Epoch [42/50], Step [87/735], Loss: 0.4618\n",
      "Epoch [42/50], Step [88/735], Loss: 0.3075\n",
      "Epoch [42/50], Step [89/735], Loss: 0.1210\n",
      "Epoch [42/50], Step [90/735], Loss: 0.1183\n",
      "Epoch [42/50], Step [91/735], Loss: 0.2479\n",
      "Epoch [42/50], Step [92/735], Loss: 0.1888\n",
      "Epoch [42/50], Step [93/735], Loss: 0.1852\n",
      "Epoch [42/50], Step [94/735], Loss: 0.4257\n",
      "Epoch [42/50], Step [95/735], Loss: 0.1462\n",
      "Epoch [42/50], Step [96/735], Loss: 0.1547\n",
      "Epoch [42/50], Step [97/735], Loss: 1.4209\n",
      "Epoch [42/50], Step [98/735], Loss: 1.0589\n",
      "Epoch [42/50], Step [99/735], Loss: 0.1679\n",
      "Epoch [42/50], Step [100/735], Loss: 0.1233\n",
      "Epoch [42/50], Step [101/735], Loss: 0.5404\n",
      "Epoch [42/50], Step [102/735], Loss: 0.5448\n",
      "Epoch [42/50], Step [103/735], Loss: 0.2544\n",
      "Epoch [42/50], Step [104/735], Loss: 0.1431\n",
      "Epoch [42/50], Step [105/735], Loss: 0.3433\n",
      "Epoch [42/50], Step [106/735], Loss: 0.1798\n",
      "Epoch [42/50], Step [107/735], Loss: 0.2654\n",
      "Epoch [42/50], Step [108/735], Loss: 0.2098\n",
      "Epoch [42/50], Step [109/735], Loss: 0.0566\n",
      "Epoch [42/50], Step [110/735], Loss: 0.2437\n",
      "Epoch [42/50], Step [111/735], Loss: 0.1057\n",
      "Epoch [42/50], Step [112/735], Loss: 0.3561\n",
      "Epoch [42/50], Step [113/735], Loss: 0.0268\n",
      "Epoch [42/50], Step [114/735], Loss: 0.2471\n",
      "Epoch [42/50], Step [115/735], Loss: 0.1763\n",
      "Epoch [42/50], Step [116/735], Loss: 0.3775\n",
      "Epoch [42/50], Step [117/735], Loss: 0.1355\n",
      "Epoch [42/50], Step [118/735], Loss: 0.2974\n",
      "Epoch [42/50], Step [119/735], Loss: 0.0400\n",
      "Epoch [42/50], Step [120/735], Loss: 0.1636\n",
      "Epoch [42/50], Step [121/735], Loss: 0.1256\n",
      "Epoch [42/50], Step [122/735], Loss: 0.4099\n",
      "Epoch [42/50], Step [123/735], Loss: 0.1317\n",
      "Epoch [42/50], Step [124/735], Loss: 0.0873\n",
      "Epoch [42/50], Step [125/735], Loss: 0.3666\n",
      "Epoch [42/50], Step [126/735], Loss: 0.1239\n",
      "Epoch [42/50], Step [127/735], Loss: 0.2173\n",
      "Epoch [42/50], Step [128/735], Loss: 0.3600\n",
      "Epoch [42/50], Step [129/735], Loss: 0.2706\n",
      "Epoch [42/50], Step [130/735], Loss: 0.1305\n",
      "Epoch [42/50], Step [131/735], Loss: 0.1267\n",
      "Epoch [42/50], Step [132/735], Loss: 0.3437\n",
      "Epoch [42/50], Step [133/735], Loss: 0.1333\n",
      "Epoch [42/50], Step [134/735], Loss: 0.0762\n",
      "Epoch [42/50], Step [135/735], Loss: 0.1384\n",
      "Epoch [42/50], Step [136/735], Loss: 0.2906\n",
      "Epoch [42/50], Step [137/735], Loss: 0.2139\n",
      "Epoch [42/50], Step [138/735], Loss: 0.0352\n",
      "Epoch [42/50], Step [139/735], Loss: 0.2094\n",
      "Epoch [42/50], Step [140/735], Loss: 0.1124\n",
      "Epoch [42/50], Step [141/735], Loss: 0.2079\n",
      "Epoch [42/50], Step [142/735], Loss: 0.1707\n",
      "Epoch [42/50], Step [143/735], Loss: 0.0689\n",
      "Epoch [42/50], Step [144/735], Loss: 0.1835\n",
      "Epoch [42/50], Step [145/735], Loss: 0.1595\n",
      "Epoch [42/50], Step [146/735], Loss: 0.1429\n",
      "Epoch [42/50], Step [147/735], Loss: 0.1324\n",
      "Epoch [42/50], Step [148/735], Loss: 0.9062\n",
      "Epoch [42/50], Step [149/735], Loss: 0.4177\n",
      "Epoch [42/50], Step [150/735], Loss: 0.0708\n",
      "Epoch [42/50], Step [151/735], Loss: 0.1167\n",
      "Epoch [42/50], Step [152/735], Loss: 0.1294\n",
      "Epoch [42/50], Step [153/735], Loss: 0.2750\n",
      "Epoch [42/50], Step [154/735], Loss: 1.0492\n",
      "Epoch [42/50], Step [155/735], Loss: 0.7871\n",
      "Epoch [42/50], Step [156/735], Loss: 0.2487\n",
      "Epoch [42/50], Step [157/735], Loss: 0.3088\n",
      "Epoch [42/50], Step [158/735], Loss: 0.2053\n",
      "Epoch [42/50], Step [159/735], Loss: 0.1725\n",
      "Epoch [42/50], Step [160/735], Loss: 0.0475\n",
      "Epoch [42/50], Step [161/735], Loss: 1.0171\n",
      "Epoch [42/50], Step [162/735], Loss: 0.1209\n",
      "Epoch [42/50], Step [163/735], Loss: 0.2805\n",
      "Epoch [42/50], Step [164/735], Loss: 0.3920\n",
      "Epoch [42/50], Step [165/735], Loss: 0.1565\n",
      "Epoch [42/50], Step [166/735], Loss: 0.1869\n",
      "Epoch [42/50], Step [167/735], Loss: 0.3203\n",
      "Epoch [42/50], Step [168/735], Loss: 0.2356\n",
      "Epoch [42/50], Step [169/735], Loss: 0.9084\n",
      "Epoch [42/50], Step [170/735], Loss: 0.6172\n",
      "Epoch [42/50], Step [171/735], Loss: 0.1446\n",
      "Epoch [42/50], Step [172/735], Loss: 0.3242\n",
      "Epoch [42/50], Step [173/735], Loss: 0.2302\n",
      "Epoch [42/50], Step [174/735], Loss: 0.2603\n",
      "Epoch [42/50], Step [175/735], Loss: 0.1146\n",
      "Epoch [42/50], Step [176/735], Loss: 0.2000\n",
      "Epoch [42/50], Step [177/735], Loss: 0.3976\n",
      "Epoch [42/50], Step [178/735], Loss: 0.4513\n",
      "Epoch [42/50], Step [179/735], Loss: 0.3712\n",
      "Epoch [42/50], Step [180/735], Loss: 0.1929\n",
      "Epoch [42/50], Step [181/735], Loss: 0.4416\n",
      "Epoch [42/50], Step [182/735], Loss: 0.1042\n",
      "Epoch [42/50], Step [183/735], Loss: 0.1990\n",
      "Epoch [42/50], Step [184/735], Loss: 0.2801\n",
      "Epoch [42/50], Step [185/735], Loss: 0.1650\n",
      "Epoch [42/50], Step [186/735], Loss: 0.3298\n",
      "Epoch [42/50], Step [187/735], Loss: 2.7821\n",
      "Epoch [42/50], Step [188/735], Loss: 0.2958\n",
      "Epoch [42/50], Step [189/735], Loss: 0.2326\n",
      "Epoch [42/50], Step [190/735], Loss: 0.1393\n",
      "Epoch [42/50], Step [191/735], Loss: 0.2750\n",
      "Epoch [42/50], Step [192/735], Loss: 0.3168\n",
      "Epoch [42/50], Step [193/735], Loss: 0.2176\n",
      "Epoch [42/50], Step [194/735], Loss: 0.2479\n",
      "Epoch [42/50], Step [195/735], Loss: 0.1485\n",
      "Epoch [42/50], Step [196/735], Loss: 0.0443\n",
      "Epoch [42/50], Step [197/735], Loss: 0.2466\n",
      "Epoch [42/50], Step [198/735], Loss: 0.2857\n",
      "Epoch [42/50], Step [199/735], Loss: 0.1863\n",
      "Epoch [42/50], Step [200/735], Loss: 0.1944\n",
      "Epoch [42/50], Step [201/735], Loss: 0.0740\n",
      "Epoch [42/50], Step [202/735], Loss: 0.1111\n",
      "Epoch [42/50], Step [203/735], Loss: 0.0998\n",
      "Epoch [42/50], Step [204/735], Loss: 0.6406\n",
      "Epoch [42/50], Step [205/735], Loss: 0.5223\n",
      "Epoch [42/50], Step [206/735], Loss: 0.0616\n",
      "Epoch [42/50], Step [207/735], Loss: 0.1361\n",
      "Epoch [42/50], Step [208/735], Loss: 0.1461\n",
      "Epoch [42/50], Step [209/735], Loss: 0.8740\n",
      "Epoch [42/50], Step [210/735], Loss: 0.2778\n",
      "Epoch [42/50], Step [211/735], Loss: 0.3638\n",
      "Epoch [42/50], Step [212/735], Loss: 0.1089\n",
      "Epoch [42/50], Step [213/735], Loss: 0.4513\n",
      "Epoch [42/50], Step [214/735], Loss: 0.4791\n",
      "Epoch [42/50], Step [215/735], Loss: 0.6746\n",
      "Epoch [42/50], Step [216/735], Loss: 0.6952\n",
      "Epoch [42/50], Step [217/735], Loss: 0.9102\n",
      "Epoch [42/50], Step [218/735], Loss: 0.5162\n",
      "Epoch [42/50], Step [219/735], Loss: 0.0729\n",
      "Epoch [42/50], Step [220/735], Loss: 2.2947\n",
      "Epoch [42/50], Step [221/735], Loss: 0.5271\n",
      "Epoch [42/50], Step [222/735], Loss: 0.0715\n",
      "Epoch [42/50], Step [223/735], Loss: 0.3784\n",
      "Epoch [42/50], Step [224/735], Loss: 0.1344\n",
      "Epoch [42/50], Step [225/735], Loss: 0.2319\n",
      "Epoch [42/50], Step [226/735], Loss: 0.4784\n",
      "Epoch [42/50], Step [227/735], Loss: 0.1914\n",
      "Epoch [42/50], Step [228/735], Loss: 0.1022\n",
      "Epoch [42/50], Step [229/735], Loss: 0.0970\n",
      "Epoch [42/50], Step [230/735], Loss: 0.3813\n",
      "Epoch [42/50], Step [231/735], Loss: 0.1949\n",
      "Epoch [42/50], Step [232/735], Loss: 0.1346\n",
      "Epoch [42/50], Step [233/735], Loss: 0.2612\n",
      "Epoch [42/50], Step [234/735], Loss: 0.3569\n",
      "Epoch [42/50], Step [235/735], Loss: 0.2668\n",
      "Epoch [42/50], Step [236/735], Loss: 0.4794\n",
      "Epoch [42/50], Step [237/735], Loss: 0.2371\n",
      "Epoch [42/50], Step [238/735], Loss: 0.7038\n",
      "Epoch [42/50], Step [239/735], Loss: 0.4939\n",
      "Epoch [42/50], Step [240/735], Loss: 0.4045\n",
      "Epoch [42/50], Step [241/735], Loss: 0.1392\n",
      "Epoch [42/50], Step [242/735], Loss: 0.5958\n",
      "Epoch [42/50], Step [243/735], Loss: 0.1871\n",
      "Epoch [42/50], Step [244/735], Loss: 0.2143\n",
      "Epoch [42/50], Step [245/735], Loss: 0.2975\n",
      "Epoch [42/50], Step [246/735], Loss: 0.3155\n",
      "Epoch [42/50], Step [247/735], Loss: 0.4756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Step [248/735], Loss: 0.6580\n",
      "Epoch [42/50], Step [249/735], Loss: 0.2828\n",
      "Epoch [42/50], Step [250/735], Loss: 0.1346\n",
      "Epoch [42/50], Step [251/735], Loss: 0.3362\n",
      "Epoch [42/50], Step [252/735], Loss: 0.5180\n",
      "Epoch [42/50], Step [253/735], Loss: 0.1556\n",
      "Epoch [42/50], Step [254/735], Loss: 0.5629\n",
      "Epoch [42/50], Step [255/735], Loss: 0.2733\n",
      "Epoch [42/50], Step [256/735], Loss: 0.2163\n",
      "Epoch [42/50], Step [257/735], Loss: 0.1093\n",
      "Epoch [42/50], Step [258/735], Loss: 0.1925\n",
      "Epoch [42/50], Step [259/735], Loss: 0.3162\n",
      "Epoch [42/50], Step [260/735], Loss: 0.1561\n",
      "Epoch [42/50], Step [261/735], Loss: 0.0873\n",
      "Epoch [42/50], Step [262/735], Loss: 0.7184\n",
      "Epoch [42/50], Step [263/735], Loss: 0.0693\n",
      "Epoch [42/50], Step [264/735], Loss: 0.4174\n",
      "Epoch [42/50], Step [265/735], Loss: 1.1389\n",
      "Epoch [42/50], Step [266/735], Loss: 0.5447\n",
      "Epoch [42/50], Step [267/735], Loss: 0.5108\n",
      "Epoch [42/50], Step [268/735], Loss: 0.5109\n",
      "Epoch [42/50], Step [269/735], Loss: 0.1171\n",
      "Epoch [42/50], Step [270/735], Loss: 0.2405\n",
      "Epoch [42/50], Step [271/735], Loss: 0.5271\n",
      "Epoch [42/50], Step [272/735], Loss: 0.2776\n",
      "Epoch [42/50], Step [273/735], Loss: 0.3144\n",
      "Epoch [42/50], Step [274/735], Loss: 0.2391\n",
      "Epoch [42/50], Step [275/735], Loss: 0.3188\n",
      "Epoch [42/50], Step [276/735], Loss: 0.5864\n",
      "Epoch [42/50], Step [277/735], Loss: 0.4028\n",
      "Epoch [42/50], Step [278/735], Loss: 0.4991\n",
      "Epoch [42/50], Step [279/735], Loss: 0.2723\n",
      "Epoch [42/50], Step [280/735], Loss: 0.3012\n",
      "Epoch [42/50], Step [281/735], Loss: 0.1584\n",
      "Epoch [42/50], Step [282/735], Loss: 0.3110\n",
      "Epoch [42/50], Step [283/735], Loss: 0.8206\n",
      "Epoch [42/50], Step [284/735], Loss: 0.3079\n",
      "Epoch [42/50], Step [285/735], Loss: 0.0751\n",
      "Epoch [42/50], Step [286/735], Loss: 0.3542\n",
      "Epoch [42/50], Step [287/735], Loss: 0.4978\n",
      "Epoch [42/50], Step [288/735], Loss: 0.3099\n",
      "Epoch [42/50], Step [289/735], Loss: 0.3946\n",
      "Epoch [42/50], Step [290/735], Loss: 0.1098\n",
      "Epoch [42/50], Step [291/735], Loss: 0.0661\n",
      "Epoch [42/50], Step [292/735], Loss: 0.1517\n",
      "Epoch [42/50], Step [293/735], Loss: 0.3455\n",
      "Epoch [42/50], Step [294/735], Loss: 0.3570\n",
      "Epoch [42/50], Step [295/735], Loss: 0.1845\n",
      "Epoch [42/50], Step [296/735], Loss: 0.2303\n",
      "Epoch [42/50], Step [297/735], Loss: 0.3695\n",
      "Epoch [42/50], Step [298/735], Loss: 0.1123\n",
      "Epoch [42/50], Step [299/735], Loss: 0.1193\n",
      "Epoch [42/50], Step [300/735], Loss: 0.1191\n",
      "Epoch [42/50], Step [301/735], Loss: 0.2367\n",
      "Epoch [42/50], Step [302/735], Loss: 0.1977\n",
      "Epoch [42/50], Step [303/735], Loss: 0.2977\n",
      "Epoch [42/50], Step [304/735], Loss: 0.1613\n",
      "Epoch [42/50], Step [305/735], Loss: 0.1830\n",
      "Epoch [42/50], Step [306/735], Loss: 0.3051\n",
      "Epoch [42/50], Step [307/735], Loss: 0.2793\n",
      "Epoch [42/50], Step [308/735], Loss: 0.2265\n",
      "Epoch [42/50], Step [309/735], Loss: 0.1930\n",
      "Epoch [42/50], Step [310/735], Loss: 0.2722\n",
      "Epoch [42/50], Step [311/735], Loss: 0.2758\n",
      "Epoch [42/50], Step [312/735], Loss: 0.1392\n",
      "Epoch [42/50], Step [313/735], Loss: 0.3862\n",
      "Epoch [42/50], Step [314/735], Loss: 0.4088\n",
      "Epoch [42/50], Step [315/735], Loss: 0.3400\n",
      "Epoch [42/50], Step [316/735], Loss: 0.5236\n",
      "Epoch [42/50], Step [317/735], Loss: 0.4689\n",
      "Epoch [42/50], Step [318/735], Loss: 0.1195\n",
      "Epoch [42/50], Step [319/735], Loss: 0.3286\n",
      "Epoch [42/50], Step [320/735], Loss: 0.1471\n",
      "Epoch [42/50], Step [321/735], Loss: 0.1587\n",
      "Epoch [42/50], Step [322/735], Loss: 0.3486\n",
      "Epoch [42/50], Step [323/735], Loss: 0.2874\n",
      "Epoch [42/50], Step [324/735], Loss: 0.3030\n",
      "Epoch [42/50], Step [325/735], Loss: 0.3648\n",
      "Epoch [42/50], Step [326/735], Loss: 0.1640\n",
      "Epoch [42/50], Step [327/735], Loss: 0.1526\n",
      "Epoch [42/50], Step [328/735], Loss: 0.2563\n",
      "Epoch [42/50], Step [329/735], Loss: 0.0879\n",
      "Epoch [42/50], Step [330/735], Loss: 0.1764\n",
      "Epoch [42/50], Step [331/735], Loss: 0.1721\n",
      "Epoch [42/50], Step [332/735], Loss: 0.1289\n",
      "Epoch [42/50], Step [333/735], Loss: 0.8616\n",
      "Epoch [42/50], Step [334/735], Loss: 0.4553\n",
      "Epoch [42/50], Step [335/735], Loss: 0.0548\n",
      "Epoch [42/50], Step [336/735], Loss: 0.1998\n",
      "Epoch [42/50], Step [337/735], Loss: 0.5558\n",
      "Epoch [42/50], Step [338/735], Loss: 0.3611\n",
      "Epoch [42/50], Step [339/735], Loss: 0.5005\n",
      "Epoch [42/50], Step [340/735], Loss: 0.1976\n",
      "Epoch [42/50], Step [341/735], Loss: 0.2801\n",
      "Epoch [42/50], Step [342/735], Loss: 0.3497\n",
      "Epoch [42/50], Step [343/735], Loss: 0.6573\n",
      "Epoch [42/50], Step [344/735], Loss: 0.6133\n",
      "Epoch [42/50], Step [345/735], Loss: 0.2505\n",
      "Epoch [42/50], Step [346/735], Loss: 0.2456\n",
      "Epoch [42/50], Step [347/735], Loss: 0.1274\n",
      "Epoch [42/50], Step [348/735], Loss: 0.2069\n",
      "Epoch [42/50], Step [349/735], Loss: 0.0838\n",
      "Epoch [42/50], Step [350/735], Loss: 0.0783\n",
      "Epoch [42/50], Step [351/735], Loss: 0.2427\n",
      "Epoch [42/50], Step [352/735], Loss: 0.1966\n",
      "Epoch [42/50], Step [353/735], Loss: 0.6337\n",
      "Epoch [42/50], Step [354/735], Loss: 0.2805\n",
      "Epoch [42/50], Step [355/735], Loss: 0.8014\n",
      "Epoch [42/50], Step [356/735], Loss: 0.2292\n",
      "Epoch [42/50], Step [357/735], Loss: 0.1631\n",
      "Epoch [42/50], Step [358/735], Loss: 0.1614\n",
      "Epoch [42/50], Step [359/735], Loss: 0.1387\n",
      "Epoch [42/50], Step [360/735], Loss: 0.1818\n",
      "Epoch [42/50], Step [361/735], Loss: 0.6027\n",
      "Epoch [42/50], Step [362/735], Loss: 0.1174\n",
      "Epoch [42/50], Step [363/735], Loss: 0.7388\n",
      "Epoch [42/50], Step [364/735], Loss: 0.1687\n",
      "Epoch [42/50], Step [365/735], Loss: 0.3673\n",
      "Epoch [42/50], Step [366/735], Loss: 0.6660\n",
      "Epoch [42/50], Step [367/735], Loss: 0.1249\n",
      "Epoch [42/50], Step [368/735], Loss: 0.0922\n",
      "Epoch [42/50], Step [369/735], Loss: 0.2561\n",
      "Epoch [42/50], Step [370/735], Loss: 0.3888\n",
      "Epoch [42/50], Step [371/735], Loss: 0.2070\n",
      "Epoch [42/50], Step [372/735], Loss: 0.1548\n",
      "Epoch [42/50], Step [373/735], Loss: 0.3851\n",
      "Epoch [42/50], Step [374/735], Loss: 0.2099\n",
      "Epoch [42/50], Step [375/735], Loss: 0.6015\n",
      "Epoch [42/50], Step [376/735], Loss: 0.7067\n",
      "Epoch [42/50], Step [377/735], Loss: 0.3771\n",
      "Epoch [42/50], Step [378/735], Loss: 0.3524\n",
      "Epoch [42/50], Step [379/735], Loss: 0.3004\n",
      "Epoch [42/50], Step [380/735], Loss: 0.0617\n",
      "Epoch [42/50], Step [381/735], Loss: 0.2150\n",
      "Epoch [42/50], Step [382/735], Loss: 0.5681\n",
      "Epoch [42/50], Step [383/735], Loss: 0.5881\n",
      "Epoch [42/50], Step [384/735], Loss: 0.2181\n",
      "Epoch [42/50], Step [385/735], Loss: 0.2692\n",
      "Epoch [42/50], Step [386/735], Loss: 0.5641\n",
      "Epoch [42/50], Step [387/735], Loss: 0.4179\n",
      "Epoch [42/50], Step [388/735], Loss: 0.1526\n",
      "Epoch [42/50], Step [389/735], Loss: 0.0906\n",
      "Epoch [42/50], Step [390/735], Loss: 0.3034\n",
      "Epoch [42/50], Step [391/735], Loss: 0.2729\n",
      "Epoch [42/50], Step [392/735], Loss: 0.1799\n",
      "Epoch [42/50], Step [393/735], Loss: 0.3195\n",
      "Epoch [42/50], Step [394/735], Loss: 0.0636\n",
      "Epoch [42/50], Step [395/735], Loss: 0.4420\n",
      "Epoch [42/50], Step [396/735], Loss: 0.3402\n",
      "Epoch [42/50], Step [397/735], Loss: 0.3589\n",
      "Epoch [42/50], Step [398/735], Loss: 0.0926\n",
      "Epoch [42/50], Step [399/735], Loss: 0.1956\n",
      "Epoch [42/50], Step [400/735], Loss: 0.4565\n",
      "Epoch [42/50], Step [401/735], Loss: 0.5109\n",
      "Epoch [42/50], Step [402/735], Loss: 0.3224\n",
      "Epoch [42/50], Step [403/735], Loss: 0.2400\n",
      "Epoch [42/50], Step [404/735], Loss: 0.1969\n",
      "Epoch [42/50], Step [405/735], Loss: 0.3834\n",
      "Epoch [42/50], Step [406/735], Loss: 0.1992\n",
      "Epoch [42/50], Step [407/735], Loss: 0.3866\n",
      "Epoch [42/50], Step [408/735], Loss: 0.1517\n",
      "Epoch [42/50], Step [409/735], Loss: 0.3472\n",
      "Epoch [42/50], Step [410/735], Loss: 0.2863\n",
      "Epoch [42/50], Step [411/735], Loss: 0.9608\n",
      "Epoch [42/50], Step [412/735], Loss: 0.1151\n",
      "Epoch [42/50], Step [413/735], Loss: 0.3487\n",
      "Epoch [42/50], Step [414/735], Loss: 0.1625\n",
      "Epoch [42/50], Step [415/735], Loss: 0.2921\n",
      "Epoch [42/50], Step [416/735], Loss: 0.2990\n",
      "Epoch [42/50], Step [417/735], Loss: 0.3881\n",
      "Epoch [42/50], Step [418/735], Loss: 0.1102\n",
      "Epoch [42/50], Step [419/735], Loss: 0.1989\n",
      "Epoch [42/50], Step [420/735], Loss: 0.3132\n",
      "Epoch [42/50], Step [421/735], Loss: 0.2137\n",
      "Epoch [42/50], Step [422/735], Loss: 0.2185\n",
      "Epoch [42/50], Step [423/735], Loss: 0.1483\n",
      "Epoch [42/50], Step [424/735], Loss: 0.2114\n",
      "Epoch [42/50], Step [425/735], Loss: 0.3501\n",
      "Epoch [42/50], Step [426/735], Loss: 0.3549\n",
      "Epoch [42/50], Step [427/735], Loss: 0.1071\n",
      "Epoch [42/50], Step [428/735], Loss: 0.1959\n",
      "Epoch [42/50], Step [429/735], Loss: 0.0904\n",
      "Epoch [42/50], Step [430/735], Loss: 0.0586\n",
      "Epoch [42/50], Step [431/735], Loss: 0.4180\n",
      "Epoch [42/50], Step [432/735], Loss: 0.2065\n",
      "Epoch [42/50], Step [433/735], Loss: 0.2177\n",
      "Epoch [42/50], Step [434/735], Loss: 0.1889\n",
      "Epoch [42/50], Step [435/735], Loss: 0.1261\n",
      "Epoch [42/50], Step [436/735], Loss: 0.1752\n",
      "Epoch [42/50], Step [437/735], Loss: 0.4931\n",
      "Epoch [42/50], Step [438/735], Loss: 0.1355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Step [439/735], Loss: 0.4259\n",
      "Epoch [42/50], Step [440/735], Loss: 0.0673\n",
      "Epoch [42/50], Step [441/735], Loss: 0.3132\n",
      "Epoch [42/50], Step [442/735], Loss: 0.1580\n",
      "Epoch [42/50], Step [443/735], Loss: 0.4486\n",
      "Epoch [42/50], Step [444/735], Loss: 0.5645\n",
      "Epoch [42/50], Step [445/735], Loss: 0.1148\n",
      "Epoch [42/50], Step [446/735], Loss: 0.2883\n",
      "Epoch [42/50], Step [447/735], Loss: 0.2355\n",
      "Epoch [42/50], Step [448/735], Loss: 0.6690\n",
      "Epoch [42/50], Step [449/735], Loss: 0.0857\n",
      "Epoch [42/50], Step [450/735], Loss: 0.4740\n",
      "Epoch [42/50], Step [451/735], Loss: 0.4455\n",
      "Epoch [42/50], Step [452/735], Loss: 0.5085\n",
      "Epoch [42/50], Step [453/735], Loss: 0.2471\n",
      "Epoch [42/50], Step [454/735], Loss: 0.2817\n",
      "Epoch [42/50], Step [455/735], Loss: 0.2991\n",
      "Epoch [42/50], Step [456/735], Loss: 0.0852\n",
      "Epoch [42/50], Step [457/735], Loss: 0.1408\n",
      "Epoch [42/50], Step [458/735], Loss: 0.3627\n",
      "Epoch [42/50], Step [459/735], Loss: 0.2225\n",
      "Epoch [42/50], Step [460/735], Loss: 0.2345\n",
      "Epoch [42/50], Step [461/735], Loss: 0.0818\n",
      "Epoch [42/50], Step [462/735], Loss: 0.1292\n",
      "Epoch [42/50], Step [463/735], Loss: 0.4396\n",
      "Epoch [42/50], Step [464/735], Loss: 0.1125\n",
      "Epoch [42/50], Step [465/735], Loss: 0.3956\n",
      "Epoch [42/50], Step [466/735], Loss: 0.1700\n",
      "Epoch [42/50], Step [467/735], Loss: 0.0995\n",
      "Epoch [42/50], Step [468/735], Loss: 0.2168\n",
      "Epoch [42/50], Step [469/735], Loss: 0.2186\n",
      "Epoch [42/50], Step [470/735], Loss: 0.2137\n",
      "Epoch [42/50], Step [471/735], Loss: 0.1264\n",
      "Epoch [42/50], Step [472/735], Loss: 0.2259\n",
      "Epoch [42/50], Step [473/735], Loss: 0.0667\n",
      "Epoch [42/50], Step [474/735], Loss: 0.1106\n",
      "Epoch [42/50], Step [475/735], Loss: 0.4349\n",
      "Epoch [42/50], Step [476/735], Loss: 0.5095\n",
      "Epoch [42/50], Step [477/735], Loss: 0.1319\n",
      "Epoch [42/50], Step [478/735], Loss: 0.4030\n",
      "Epoch [42/50], Step [479/735], Loss: 0.2586\n",
      "Epoch [42/50], Step [480/735], Loss: 0.3193\n",
      "Epoch [42/50], Step [481/735], Loss: 0.1690\n",
      "Epoch [42/50], Step [482/735], Loss: 0.5454\n",
      "Epoch [42/50], Step [483/735], Loss: 0.4556\n",
      "Epoch [42/50], Step [484/735], Loss: 0.0844\n",
      "Epoch [42/50], Step [485/735], Loss: 0.3976\n",
      "Epoch [42/50], Step [486/735], Loss: 0.3047\n",
      "Epoch [42/50], Step [487/735], Loss: 0.1703\n",
      "Epoch [42/50], Step [488/735], Loss: 0.0829\n",
      "Epoch [42/50], Step [489/735], Loss: 0.3392\n",
      "Epoch [42/50], Step [490/735], Loss: 0.2188\n",
      "Epoch [42/50], Step [491/735], Loss: 0.0860\n",
      "Epoch [42/50], Step [492/735], Loss: 0.2613\n",
      "Epoch [42/50], Step [493/735], Loss: 0.1677\n",
      "Epoch [42/50], Step [494/735], Loss: 0.2859\n",
      "Epoch [42/50], Step [495/735], Loss: 0.1247\n",
      "Epoch [42/50], Step [496/735], Loss: 0.3210\n",
      "Epoch [42/50], Step [497/735], Loss: 0.0746\n",
      "Epoch [42/50], Step [498/735], Loss: 0.3440\n",
      "Epoch [42/50], Step [499/735], Loss: 0.2328\n",
      "Epoch [42/50], Step [500/735], Loss: 0.1043\n",
      "Epoch [42/50], Step [501/735], Loss: 0.5057\n",
      "Epoch [42/50], Step [502/735], Loss: 0.0461\n",
      "Epoch [42/50], Step [503/735], Loss: 0.1758\n",
      "Epoch [42/50], Step [504/735], Loss: 0.1559\n",
      "Epoch [42/50], Step [505/735], Loss: 0.1709\n",
      "Epoch [42/50], Step [506/735], Loss: 0.2338\n",
      "Epoch [42/50], Step [507/735], Loss: 0.2154\n",
      "Epoch [42/50], Step [508/735], Loss: 0.5123\n",
      "Epoch [42/50], Step [509/735], Loss: 0.0863\n",
      "Epoch [42/50], Step [510/735], Loss: 0.1731\n",
      "Epoch [42/50], Step [511/735], Loss: 0.8464\n",
      "Epoch [42/50], Step [512/735], Loss: 0.4832\n",
      "Epoch [42/50], Step [513/735], Loss: 0.2777\n",
      "Epoch [42/50], Step [514/735], Loss: 0.2333\n",
      "Epoch [42/50], Step [515/735], Loss: 0.0510\n",
      "Epoch [42/50], Step [516/735], Loss: 0.7156\n",
      "Epoch [42/50], Step [517/735], Loss: 0.1190\n",
      "Epoch [42/50], Step [518/735], Loss: 0.1027\n",
      "Epoch [42/50], Step [519/735], Loss: 0.0980\n",
      "Epoch [42/50], Step [520/735], Loss: 0.2262\n",
      "Epoch [42/50], Step [521/735], Loss: 0.0864\n",
      "Epoch [42/50], Step [522/735], Loss: 0.1348\n",
      "Epoch [42/50], Step [523/735], Loss: 0.5585\n",
      "Epoch [42/50], Step [524/735], Loss: 0.1753\n",
      "Epoch [42/50], Step [525/735], Loss: 0.1364\n",
      "Epoch [42/50], Step [526/735], Loss: 0.3652\n",
      "Epoch [42/50], Step [527/735], Loss: 0.2493\n",
      "Epoch [42/50], Step [528/735], Loss: 0.6859\n",
      "Epoch [42/50], Step [529/735], Loss: 0.1716\n",
      "Epoch [42/50], Step [530/735], Loss: 0.1636\n",
      "Epoch [42/50], Step [531/735], Loss: 0.3388\n",
      "Epoch [42/50], Step [532/735], Loss: 0.1105\n",
      "Epoch [42/50], Step [533/735], Loss: 0.1429\n",
      "Epoch [42/50], Step [534/735], Loss: 0.5681\n",
      "Epoch [42/50], Step [535/735], Loss: 0.1782\n",
      "Epoch [42/50], Step [536/735], Loss: 0.3097\n",
      "Epoch [42/50], Step [537/735], Loss: 1.0600\n",
      "Epoch [42/50], Step [538/735], Loss: 0.2429\n",
      "Epoch [42/50], Step [539/735], Loss: 0.0875\n",
      "Epoch [42/50], Step [540/735], Loss: 0.1602\n",
      "Epoch [42/50], Step [541/735], Loss: 0.2398\n",
      "Epoch [42/50], Step [542/735], Loss: 0.2159\n",
      "Epoch [42/50], Step [543/735], Loss: 0.3088\n",
      "Epoch [42/50], Step [544/735], Loss: 0.1546\n",
      "Epoch [42/50], Step [545/735], Loss: 0.6304\n",
      "Epoch [42/50], Step [546/735], Loss: 0.1777\n",
      "Epoch [42/50], Step [547/735], Loss: 0.2354\n",
      "Epoch [42/50], Step [548/735], Loss: 0.1706\n",
      "Epoch [42/50], Step [549/735], Loss: 0.5742\n",
      "Epoch [42/50], Step [550/735], Loss: 3.7710\n",
      "Epoch [42/50], Step [551/735], Loss: 0.1912\n",
      "Epoch [42/50], Step [552/735], Loss: 0.0814\n",
      "Epoch [42/50], Step [553/735], Loss: 0.1772\n",
      "Epoch [42/50], Step [554/735], Loss: 0.1275\n",
      "Epoch [42/50], Step [555/735], Loss: 0.4497\n",
      "Epoch [42/50], Step [556/735], Loss: 0.4951\n",
      "Epoch [42/50], Step [557/735], Loss: 0.1371\n",
      "Epoch [42/50], Step [558/735], Loss: 0.4705\n",
      "Epoch [42/50], Step [559/735], Loss: 0.1170\n",
      "Epoch [42/50], Step [560/735], Loss: 0.3103\n",
      "Epoch [42/50], Step [561/735], Loss: 0.0749\n",
      "Epoch [42/50], Step [562/735], Loss: 0.6281\n",
      "Epoch [42/50], Step [563/735], Loss: 0.1473\n",
      "Epoch [42/50], Step [564/735], Loss: 0.1962\n",
      "Epoch [42/50], Step [565/735], Loss: 0.2138\n",
      "Epoch [42/50], Step [566/735], Loss: 0.4354\n",
      "Epoch [42/50], Step [567/735], Loss: 0.0997\n",
      "Epoch [42/50], Step [568/735], Loss: 0.6423\n",
      "Epoch [42/50], Step [569/735], Loss: 0.2990\n",
      "Epoch [42/50], Step [570/735], Loss: 0.3700\n",
      "Epoch [42/50], Step [571/735], Loss: 0.3541\n",
      "Epoch [42/50], Step [572/735], Loss: 1.0169\n",
      "Epoch [42/50], Step [573/735], Loss: 0.1786\n",
      "Epoch [42/50], Step [574/735], Loss: 0.2570\n",
      "Epoch [42/50], Step [575/735], Loss: 0.3316\n",
      "Epoch [42/50], Step [576/735], Loss: 0.2192\n",
      "Epoch [42/50], Step [577/735], Loss: 0.1173\n",
      "Epoch [42/50], Step [578/735], Loss: 0.2368\n",
      "Epoch [42/50], Step [579/735], Loss: 0.3302\n",
      "Epoch [42/50], Step [580/735], Loss: 0.0891\n",
      "Epoch [42/50], Step [581/735], Loss: 0.0941\n",
      "Epoch [42/50], Step [582/735], Loss: 0.1470\n",
      "Epoch [42/50], Step [583/735], Loss: 0.2012\n",
      "Epoch [42/50], Step [584/735], Loss: 0.3523\n",
      "Epoch [42/50], Step [585/735], Loss: 0.2540\n",
      "Epoch [42/50], Step [586/735], Loss: 0.2743\n",
      "Epoch [42/50], Step [587/735], Loss: 0.3737\n",
      "Epoch [42/50], Step [588/735], Loss: 0.2762\n",
      "Epoch [42/50], Step [589/735], Loss: 0.1708\n",
      "Epoch [42/50], Step [590/735], Loss: 0.2722\n",
      "Epoch [42/50], Step [591/735], Loss: 0.3074\n",
      "Epoch [42/50], Step [592/735], Loss: 0.7664\n",
      "Epoch [42/50], Step [593/735], Loss: 0.6245\n",
      "Epoch [42/50], Step [594/735], Loss: 0.1605\n",
      "Epoch [42/50], Step [595/735], Loss: 0.2322\n",
      "Epoch [42/50], Step [596/735], Loss: 0.1564\n",
      "Epoch [42/50], Step [597/735], Loss: 0.2855\n",
      "Epoch [42/50], Step [598/735], Loss: 0.2395\n",
      "Epoch [42/50], Step [599/735], Loss: 0.1441\n",
      "Epoch [42/50], Step [600/735], Loss: 0.3212\n",
      "Epoch [42/50], Step [601/735], Loss: 0.5399\n",
      "Epoch [42/50], Step [602/735], Loss: 0.1427\n",
      "Epoch [42/50], Step [603/735], Loss: 0.2684\n",
      "Epoch [42/50], Step [604/735], Loss: 0.7110\n",
      "Epoch [42/50], Step [605/735], Loss: 0.0570\n",
      "Epoch [42/50], Step [606/735], Loss: 0.1856\n",
      "Epoch [42/50], Step [607/735], Loss: 0.4568\n",
      "Epoch [42/50], Step [608/735], Loss: 0.4709\n",
      "Epoch [42/50], Step [609/735], Loss: 0.2722\n",
      "Epoch [42/50], Step [610/735], Loss: 0.1218\n",
      "Epoch [42/50], Step [611/735], Loss: 0.0832\n",
      "Epoch [42/50], Step [612/735], Loss: 0.2851\n",
      "Epoch [42/50], Step [613/735], Loss: 0.3372\n",
      "Epoch [42/50], Step [614/735], Loss: 0.3461\n",
      "Epoch [42/50], Step [615/735], Loss: 0.1172\n",
      "Epoch [42/50], Step [616/735], Loss: 0.5816\n",
      "Epoch [42/50], Step [617/735], Loss: 0.5635\n",
      "Epoch [42/50], Step [618/735], Loss: 0.2641\n",
      "Epoch [42/50], Step [619/735], Loss: 0.3343\n",
      "Epoch [42/50], Step [620/735], Loss: 0.3673\n",
      "Epoch [42/50], Step [621/735], Loss: 0.2646\n",
      "Epoch [42/50], Step [622/735], Loss: 0.1686\n",
      "Epoch [42/50], Step [623/735], Loss: 0.4150\n",
      "Epoch [42/50], Step [624/735], Loss: 0.5251\n",
      "Epoch [42/50], Step [625/735], Loss: 0.5013\n",
      "Epoch [42/50], Step [626/735], Loss: 0.5014\n",
      "Epoch [42/50], Step [627/735], Loss: 0.3406\n",
      "Epoch [42/50], Step [628/735], Loss: 0.4709\n",
      "Epoch [42/50], Step [629/735], Loss: 0.1457\n",
      "Epoch [42/50], Step [630/735], Loss: 0.0635\n",
      "Epoch [42/50], Step [631/735], Loss: 0.4796\n",
      "Epoch [42/50], Step [632/735], Loss: 0.5819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Step [633/735], Loss: 0.1982\n",
      "Epoch [42/50], Step [634/735], Loss: 0.1220\n",
      "Epoch [42/50], Step [635/735], Loss: 0.1690\n",
      "Epoch [42/50], Step [636/735], Loss: 0.3016\n",
      "Epoch [42/50], Step [637/735], Loss: 0.1210\n",
      "Epoch [42/50], Step [638/735], Loss: 0.2255\n",
      "Epoch [42/50], Step [639/735], Loss: 0.1555\n",
      "Epoch [42/50], Step [640/735], Loss: 0.6109\n",
      "Epoch [42/50], Step [641/735], Loss: 0.2019\n",
      "Epoch [42/50], Step [642/735], Loss: 0.5570\n",
      "Epoch [42/50], Step [643/735], Loss: 0.2921\n",
      "Epoch [42/50], Step [644/735], Loss: 0.2462\n",
      "Epoch [42/50], Step [645/735], Loss: 0.2761\n",
      "Epoch [42/50], Step [646/735], Loss: 0.0884\n",
      "Epoch [42/50], Step [647/735], Loss: 0.1642\n",
      "Epoch [42/50], Step [648/735], Loss: 0.4900\n",
      "Epoch [42/50], Step [649/735], Loss: 0.2923\n",
      "Epoch [42/50], Step [650/735], Loss: 0.3854\n",
      "Epoch [42/50], Step [651/735], Loss: 0.0705\n",
      "Epoch [42/50], Step [652/735], Loss: 0.1363\n",
      "Epoch [42/50], Step [653/735], Loss: 0.2578\n",
      "Epoch [42/50], Step [654/735], Loss: 0.1876\n",
      "Epoch [42/50], Step [655/735], Loss: 0.2485\n",
      "Epoch [42/50], Step [656/735], Loss: 0.3816\n",
      "Epoch [42/50], Step [657/735], Loss: 0.3235\n",
      "Epoch [42/50], Step [658/735], Loss: 0.1792\n",
      "Epoch [42/50], Step [659/735], Loss: 0.7854\n",
      "Epoch [42/50], Step [660/735], Loss: 0.0469\n",
      "Epoch [42/50], Step [661/735], Loss: 1.1750\n",
      "Epoch [42/50], Step [662/735], Loss: 0.1480\n",
      "Epoch [42/50], Step [663/735], Loss: 0.0986\n",
      "Epoch [42/50], Step [664/735], Loss: 0.1169\n",
      "Epoch [42/50], Step [665/735], Loss: 0.3457\n",
      "Epoch [42/50], Step [666/735], Loss: 0.0665\n",
      "Epoch [42/50], Step [667/735], Loss: 0.1250\n",
      "Epoch [42/50], Step [668/735], Loss: 0.2689\n",
      "Epoch [42/50], Step [669/735], Loss: 0.1047\n",
      "Epoch [42/50], Step [670/735], Loss: 0.3340\n",
      "Epoch [42/50], Step [671/735], Loss: 0.3585\n",
      "Epoch [42/50], Step [672/735], Loss: 0.2394\n",
      "Epoch [42/50], Step [673/735], Loss: 0.2565\n",
      "Epoch [42/50], Step [674/735], Loss: 0.3467\n",
      "Epoch [42/50], Step [675/735], Loss: 0.1624\n",
      "Epoch [42/50], Step [676/735], Loss: 0.3847\n",
      "Epoch [42/50], Step [677/735], Loss: 0.6746\n",
      "Epoch [42/50], Step [678/735], Loss: 0.6038\n",
      "Epoch [42/50], Step [679/735], Loss: 0.1543\n",
      "Epoch [42/50], Step [680/735], Loss: 0.1327\n",
      "Epoch [42/50], Step [681/735], Loss: 0.2935\n",
      "Epoch [42/50], Step [682/735], Loss: 0.1536\n",
      "Epoch [42/50], Step [683/735], Loss: 0.0829\n",
      "Epoch [42/50], Step [684/735], Loss: 0.2145\n",
      "Epoch [42/50], Step [685/735], Loss: 0.9593\n",
      "Epoch [42/50], Step [686/735], Loss: 0.3002\n",
      "Epoch [42/50], Step [687/735], Loss: 0.1905\n",
      "Epoch [42/50], Step [688/735], Loss: 0.1382\n",
      "Epoch [42/50], Step [689/735], Loss: 0.1952\n",
      "Epoch [42/50], Step [690/735], Loss: 0.5806\n",
      "Epoch [42/50], Step [691/735], Loss: 0.1785\n",
      "Epoch [42/50], Step [692/735], Loss: 0.1869\n",
      "Epoch [42/50], Step [693/735], Loss: 0.2627\n",
      "Epoch [42/50], Step [694/735], Loss: 0.6233\n",
      "Epoch [42/50], Step [695/735], Loss: 0.1055\n",
      "Epoch [42/50], Step [696/735], Loss: 0.1949\n",
      "Epoch [42/50], Step [697/735], Loss: 0.7241\n",
      "Epoch [42/50], Step [698/735], Loss: 0.2550\n",
      "Epoch [42/50], Step [699/735], Loss: 0.3137\n",
      "Epoch [42/50], Step [700/735], Loss: 0.1602\n",
      "Epoch [42/50], Step [701/735], Loss: 0.5783\n",
      "Epoch [42/50], Step [702/735], Loss: 0.3203\n",
      "Epoch [42/50], Step [703/735], Loss: 0.4947\n",
      "Epoch [42/50], Step [704/735], Loss: 0.1537\n",
      "Epoch [42/50], Step [705/735], Loss: 0.1076\n",
      "Epoch [42/50], Step [706/735], Loss: 0.1307\n",
      "Epoch [42/50], Step [707/735], Loss: 0.2673\n",
      "Epoch [42/50], Step [708/735], Loss: 0.1793\n",
      "Epoch [42/50], Step [709/735], Loss: 0.5752\n",
      "Epoch [42/50], Step [710/735], Loss: 0.0968\n",
      "Epoch [42/50], Step [711/735], Loss: 0.1868\n",
      "Epoch [42/50], Step [712/735], Loss: 0.2513\n",
      "Epoch [42/50], Step [713/735], Loss: 0.4393\n",
      "Epoch [42/50], Step [714/735], Loss: 0.2080\n",
      "Epoch [42/50], Step [715/735], Loss: 1.2866\n",
      "Epoch [42/50], Step [716/735], Loss: 0.1665\n",
      "Epoch [42/50], Step [717/735], Loss: 0.2526\n",
      "Epoch [42/50], Step [718/735], Loss: 0.2904\n",
      "Epoch [42/50], Step [719/735], Loss: 0.2247\n",
      "Epoch [42/50], Step [720/735], Loss: 0.3177\n",
      "Epoch [42/50], Step [721/735], Loss: 0.2636\n",
      "Epoch [42/50], Step [722/735], Loss: 0.3347\n",
      "Epoch [42/50], Step [723/735], Loss: 1.2590\n",
      "Epoch [42/50], Step [724/735], Loss: 0.1024\n",
      "Epoch [42/50], Step [725/735], Loss: 0.0886\n",
      "Epoch [42/50], Step [726/735], Loss: 0.2222\n",
      "Epoch [42/50], Step [727/735], Loss: 0.1232\n",
      "Epoch [42/50], Step [728/735], Loss: 0.2515\n",
      "Epoch [42/50], Step [729/735], Loss: 0.4310\n",
      "Epoch [42/50], Step [730/735], Loss: 0.2950\n",
      "Epoch [42/50], Step [731/735], Loss: 1.2352\n",
      "Epoch [42/50], Step [732/735], Loss: 0.1280\n",
      "Epoch [42/50], Step [733/735], Loss: 0.1018\n",
      "Epoch [42/50], Step [734/735], Loss: 0.2411\n",
      "Epoch [42/50], Step [735/735], Loss: 0.0416\n",
      "Epoch [43/50], Step [1/735], Loss: 0.3192\n",
      "Epoch [43/50], Step [2/735], Loss: 0.1809\n",
      "Epoch [43/50], Step [3/735], Loss: 1.0366\n",
      "Epoch [43/50], Step [4/735], Loss: 1.7359\n",
      "Epoch [43/50], Step [5/735], Loss: 0.2904\n",
      "Epoch [43/50], Step [6/735], Loss: 0.7559\n",
      "Epoch [43/50], Step [7/735], Loss: 0.0911\n",
      "Epoch [43/50], Step [8/735], Loss: 0.5160\n",
      "Epoch [43/50], Step [9/735], Loss: 0.2545\n",
      "Epoch [43/50], Step [10/735], Loss: 0.1308\n",
      "Epoch [43/50], Step [11/735], Loss: 0.1559\n",
      "Epoch [43/50], Step [12/735], Loss: 0.2919\n",
      "Epoch [43/50], Step [13/735], Loss: 0.5127\n",
      "Epoch [43/50], Step [14/735], Loss: 0.5315\n",
      "Epoch [43/50], Step [15/735], Loss: 0.1678\n",
      "Epoch [43/50], Step [16/735], Loss: 0.1965\n",
      "Epoch [43/50], Step [17/735], Loss: 0.2958\n",
      "Epoch [43/50], Step [18/735], Loss: 0.2360\n",
      "Epoch [43/50], Step [19/735], Loss: 0.1920\n",
      "Epoch [43/50], Step [20/735], Loss: 0.4338\n",
      "Epoch [43/50], Step [21/735], Loss: 0.1778\n",
      "Epoch [43/50], Step [22/735], Loss: 0.4697\n",
      "Epoch [43/50], Step [23/735], Loss: 0.4019\n",
      "Epoch [43/50], Step [24/735], Loss: 0.1539\n",
      "Epoch [43/50], Step [25/735], Loss: 0.3457\n",
      "Epoch [43/50], Step [26/735], Loss: 0.0590\n",
      "Epoch [43/50], Step [27/735], Loss: 0.1858\n",
      "Epoch [43/50], Step [28/735], Loss: 0.0894\n",
      "Epoch [43/50], Step [29/735], Loss: 0.1484\n",
      "Epoch [43/50], Step [30/735], Loss: 0.8457\n",
      "Epoch [43/50], Step [31/735], Loss: 0.4332\n",
      "Epoch [43/50], Step [32/735], Loss: 0.2899\n",
      "Epoch [43/50], Step [33/735], Loss: 0.2593\n",
      "Epoch [43/50], Step [34/735], Loss: 0.2722\n",
      "Epoch [43/50], Step [35/735], Loss: 0.4665\n",
      "Epoch [43/50], Step [36/735], Loss: 0.5418\n",
      "Epoch [43/50], Step [37/735], Loss: 0.1898\n",
      "Epoch [43/50], Step [38/735], Loss: 0.7788\n",
      "Epoch [43/50], Step [39/735], Loss: 0.4313\n",
      "Epoch [43/50], Step [40/735], Loss: 0.3530\n",
      "Epoch [43/50], Step [41/735], Loss: 0.7226\n",
      "Epoch [43/50], Step [42/735], Loss: 0.7101\n",
      "Epoch [43/50], Step [43/735], Loss: 0.2500\n",
      "Epoch [43/50], Step [44/735], Loss: 0.1344\n",
      "Epoch [43/50], Step [45/735], Loss: 0.9461\n",
      "Epoch [43/50], Step [46/735], Loss: 0.2259\n",
      "Epoch [43/50], Step [47/735], Loss: 0.0996\n",
      "Epoch [43/50], Step [48/735], Loss: 0.3662\n",
      "Epoch [43/50], Step [49/735], Loss: 0.2240\n",
      "Epoch [43/50], Step [50/735], Loss: 0.1225\n",
      "Epoch [43/50], Step [51/735], Loss: 0.4205\n",
      "Epoch [43/50], Step [52/735], Loss: 0.6633\n",
      "Epoch [43/50], Step [53/735], Loss: 0.2297\n",
      "Epoch [43/50], Step [54/735], Loss: 0.1887\n",
      "Epoch [43/50], Step [55/735], Loss: 0.2117\n",
      "Epoch [43/50], Step [56/735], Loss: 0.2065\n",
      "Epoch [43/50], Step [57/735], Loss: 0.2631\n",
      "Epoch [43/50], Step [58/735], Loss: 0.2385\n",
      "Epoch [43/50], Step [59/735], Loss: 0.6911\n",
      "Epoch [43/50], Step [60/735], Loss: 0.3510\n",
      "Epoch [43/50], Step [61/735], Loss: 0.4305\n",
      "Epoch [43/50], Step [62/735], Loss: 0.5475\n",
      "Epoch [43/50], Step [63/735], Loss: 0.2488\n",
      "Epoch [43/50], Step [64/735], Loss: 0.0815\n",
      "Epoch [43/50], Step [65/735], Loss: 0.1725\n",
      "Epoch [43/50], Step [66/735], Loss: 0.2844\n",
      "Epoch [43/50], Step [67/735], Loss: 0.1691\n",
      "Epoch [43/50], Step [68/735], Loss: 0.0985\n",
      "Epoch [43/50], Step [69/735], Loss: 0.1455\n",
      "Epoch [43/50], Step [70/735], Loss: 0.2918\n",
      "Epoch [43/50], Step [71/735], Loss: 0.1187\n",
      "Epoch [43/50], Step [72/735], Loss: 0.2098\n",
      "Epoch [43/50], Step [73/735], Loss: 0.4871\n",
      "Epoch [43/50], Step [74/735], Loss: 0.0741\n",
      "Epoch [43/50], Step [75/735], Loss: 0.2258\n",
      "Epoch [43/50], Step [76/735], Loss: 0.2488\n",
      "Epoch [43/50], Step [77/735], Loss: 0.1992\n",
      "Epoch [43/50], Step [78/735], Loss: 0.2203\n",
      "Epoch [43/50], Step [79/735], Loss: 0.0867\n",
      "Epoch [43/50], Step [80/735], Loss: 0.2961\n",
      "Epoch [43/50], Step [81/735], Loss: 0.3720\n",
      "Epoch [43/50], Step [82/735], Loss: 0.8722\n",
      "Epoch [43/50], Step [83/735], Loss: 0.3383\n",
      "Epoch [43/50], Step [84/735], Loss: 0.1364\n",
      "Epoch [43/50], Step [85/735], Loss: 0.2559\n",
      "Epoch [43/50], Step [86/735], Loss: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Step [87/735], Loss: 0.4624\n",
      "Epoch [43/50], Step [88/735], Loss: 0.1111\n",
      "Epoch [43/50], Step [89/735], Loss: 0.1494\n",
      "Epoch [43/50], Step [90/735], Loss: 0.0663\n",
      "Epoch [43/50], Step [91/735], Loss: 0.1527\n",
      "Epoch [43/50], Step [92/735], Loss: 0.1484\n",
      "Epoch [43/50], Step [93/735], Loss: 0.1950\n",
      "Epoch [43/50], Step [94/735], Loss: 0.5110\n",
      "Epoch [43/50], Step [95/735], Loss: 0.1722\n",
      "Epoch [43/50], Step [96/735], Loss: 0.2442\n",
      "Epoch [43/50], Step [97/735], Loss: 0.6069\n",
      "Epoch [43/50], Step [98/735], Loss: 0.2577\n",
      "Epoch [43/50], Step [99/735], Loss: 0.5431\n",
      "Epoch [43/50], Step [100/735], Loss: 0.0824\n",
      "Epoch [43/50], Step [101/735], Loss: 0.0754\n",
      "Epoch [43/50], Step [102/735], Loss: 0.2073\n",
      "Epoch [43/50], Step [103/735], Loss: 0.2201\n",
      "Epoch [43/50], Step [104/735], Loss: 0.2414\n",
      "Epoch [43/50], Step [105/735], Loss: 0.1242\n",
      "Epoch [43/50], Step [106/735], Loss: 0.7218\n",
      "Epoch [43/50], Step [107/735], Loss: 0.1346\n",
      "Epoch [43/50], Step [108/735], Loss: 0.1746\n",
      "Epoch [43/50], Step [109/735], Loss: 0.4003\n",
      "Epoch [43/50], Step [110/735], Loss: 0.0925\n",
      "Epoch [43/50], Step [111/735], Loss: 0.3356\n",
      "Epoch [43/50], Step [112/735], Loss: 0.2323\n",
      "Epoch [43/50], Step [113/735], Loss: 0.0802\n",
      "Epoch [43/50], Step [114/735], Loss: 0.1785\n",
      "Epoch [43/50], Step [115/735], Loss: 0.4607\n",
      "Epoch [43/50], Step [116/735], Loss: 0.0787\n",
      "Epoch [43/50], Step [117/735], Loss: 0.6601\n",
      "Epoch [43/50], Step [118/735], Loss: 0.3083\n",
      "Epoch [43/50], Step [119/735], Loss: 0.8335\n",
      "Epoch [43/50], Step [120/735], Loss: 0.2147\n",
      "Epoch [43/50], Step [121/735], Loss: 0.6040\n",
      "Epoch [43/50], Step [122/735], Loss: 0.2530\n",
      "Epoch [43/50], Step [123/735], Loss: 0.2805\n",
      "Epoch [43/50], Step [124/735], Loss: 0.2458\n",
      "Epoch [43/50], Step [125/735], Loss: 0.2219\n",
      "Epoch [43/50], Step [126/735], Loss: 0.1668\n",
      "Epoch [43/50], Step [127/735], Loss: 0.2632\n",
      "Epoch [43/50], Step [128/735], Loss: 0.2183\n",
      "Epoch [43/50], Step [129/735], Loss: 0.2057\n",
      "Epoch [43/50], Step [130/735], Loss: 0.3877\n",
      "Epoch [43/50], Step [131/735], Loss: 0.4447\n",
      "Epoch [43/50], Step [132/735], Loss: 0.4845\n",
      "Epoch [43/50], Step [133/735], Loss: 0.3840\n",
      "Epoch [43/50], Step [134/735], Loss: 0.1916\n",
      "Epoch [43/50], Step [135/735], Loss: 0.4331\n",
      "Epoch [43/50], Step [136/735], Loss: 0.7801\n",
      "Epoch [43/50], Step [137/735], Loss: 0.1541\n",
      "Epoch [43/50], Step [138/735], Loss: 0.1945\n",
      "Epoch [43/50], Step [139/735], Loss: 0.1688\n",
      "Epoch [43/50], Step [140/735], Loss: 0.4717\n",
      "Epoch [43/50], Step [141/735], Loss: 0.2125\n",
      "Epoch [43/50], Step [142/735], Loss: 0.4945\n",
      "Epoch [43/50], Step [143/735], Loss: 0.7912\n",
      "Epoch [43/50], Step [144/735], Loss: 0.4194\n",
      "Epoch [43/50], Step [145/735], Loss: 0.2926\n",
      "Epoch [43/50], Step [146/735], Loss: 0.3288\n",
      "Epoch [43/50], Step [147/735], Loss: 0.1130\n",
      "Epoch [43/50], Step [148/735], Loss: 0.1414\n",
      "Epoch [43/50], Step [149/735], Loss: 0.1763\n",
      "Epoch [43/50], Step [150/735], Loss: 0.2837\n",
      "Epoch [43/50], Step [151/735], Loss: 0.2975\n",
      "Epoch [43/50], Step [152/735], Loss: 0.2799\n",
      "Epoch [43/50], Step [153/735], Loss: 0.4961\n",
      "Epoch [43/50], Step [154/735], Loss: 0.2191\n",
      "Epoch [43/50], Step [155/735], Loss: 0.6683\n",
      "Epoch [43/50], Step [156/735], Loss: 0.3686\n",
      "Epoch [43/50], Step [157/735], Loss: 0.5202\n",
      "Epoch [43/50], Step [158/735], Loss: 0.1572\n",
      "Epoch [43/50], Step [159/735], Loss: 0.2527\n",
      "Epoch [43/50], Step [160/735], Loss: 0.2317\n",
      "Epoch [43/50], Step [161/735], Loss: 0.4053\n",
      "Epoch [43/50], Step [162/735], Loss: 0.4999\n",
      "Epoch [43/50], Step [163/735], Loss: 0.2463\n",
      "Epoch [43/50], Step [164/735], Loss: 0.1101\n",
      "Epoch [43/50], Step [165/735], Loss: 0.1352\n",
      "Epoch [43/50], Step [166/735], Loss: 0.0355\n",
      "Epoch [43/50], Step [167/735], Loss: 0.2833\n",
      "Epoch [43/50], Step [168/735], Loss: 0.3771\n",
      "Epoch [43/50], Step [169/735], Loss: 0.1342\n",
      "Epoch [43/50], Step [170/735], Loss: 0.3697\n",
      "Epoch [43/50], Step [171/735], Loss: 0.5920\n",
      "Epoch [43/50], Step [172/735], Loss: 0.1382\n",
      "Epoch [43/50], Step [173/735], Loss: 0.0603\n",
      "Epoch [43/50], Step [174/735], Loss: 0.2003\n",
      "Epoch [43/50], Step [175/735], Loss: 0.2264\n",
      "Epoch [43/50], Step [176/735], Loss: 0.1569\n",
      "Epoch [43/50], Step [177/735], Loss: 0.6659\n",
      "Epoch [43/50], Step [178/735], Loss: 0.9288\n",
      "Epoch [43/50], Step [179/735], Loss: 0.2013\n",
      "Epoch [43/50], Step [180/735], Loss: 0.2140\n",
      "Epoch [43/50], Step [181/735], Loss: 0.2683\n",
      "Epoch [43/50], Step [182/735], Loss: 0.2230\n",
      "Epoch [43/50], Step [183/735], Loss: 0.5168\n",
      "Epoch [43/50], Step [184/735], Loss: 0.2978\n",
      "Epoch [43/50], Step [185/735], Loss: 0.0740\n",
      "Epoch [43/50], Step [186/735], Loss: 0.1826\n",
      "Epoch [43/50], Step [187/735], Loss: 0.2429\n",
      "Epoch [43/50], Step [188/735], Loss: 0.3225\n",
      "Epoch [43/50], Step [189/735], Loss: 0.2926\n",
      "Epoch [43/50], Step [190/735], Loss: 0.5373\n",
      "Epoch [43/50], Step [191/735], Loss: 0.6341\n",
      "Epoch [43/50], Step [192/735], Loss: 0.1536\n",
      "Epoch [43/50], Step [193/735], Loss: 0.1797\n",
      "Epoch [43/50], Step [194/735], Loss: 0.7562\n",
      "Epoch [43/50], Step [195/735], Loss: 0.2083\n",
      "Epoch [43/50], Step [196/735], Loss: 0.0513\n",
      "Epoch [43/50], Step [197/735], Loss: 0.1669\n",
      "Epoch [43/50], Step [198/735], Loss: 0.2200\n",
      "Epoch [43/50], Step [199/735], Loss: 0.1298\n",
      "Epoch [43/50], Step [200/735], Loss: 0.2322\n",
      "Epoch [43/50], Step [201/735], Loss: 0.0561\n",
      "Epoch [43/50], Step [202/735], Loss: 0.2428\n",
      "Epoch [43/50], Step [203/735], Loss: 0.5954\n",
      "Epoch [43/50], Step [204/735], Loss: 0.1967\n",
      "Epoch [43/50], Step [205/735], Loss: 0.1882\n",
      "Epoch [43/50], Step [206/735], Loss: 0.3291\n",
      "Epoch [43/50], Step [207/735], Loss: 0.5153\n",
      "Epoch [43/50], Step [208/735], Loss: 0.5497\n",
      "Epoch [43/50], Step [209/735], Loss: 0.1903\n",
      "Epoch [43/50], Step [210/735], Loss: 0.1272\n",
      "Epoch [43/50], Step [211/735], Loss: 0.1582\n",
      "Epoch [43/50], Step [212/735], Loss: 0.8665\n",
      "Epoch [43/50], Step [213/735], Loss: 0.2837\n",
      "Epoch [43/50], Step [214/735], Loss: 0.3528\n",
      "Epoch [43/50], Step [215/735], Loss: 1.3110\n",
      "Epoch [43/50], Step [216/735], Loss: 0.5876\n",
      "Epoch [43/50], Step [217/735], Loss: 0.2095\n",
      "Epoch [43/50], Step [218/735], Loss: 0.4451\n",
      "Epoch [43/50], Step [219/735], Loss: 0.2262\n",
      "Epoch [43/50], Step [220/735], Loss: 0.1505\n",
      "Epoch [43/50], Step [221/735], Loss: 0.0582\n",
      "Epoch [43/50], Step [222/735], Loss: 0.2161\n",
      "Epoch [43/50], Step [223/735], Loss: 0.7595\n",
      "Epoch [43/50], Step [224/735], Loss: 0.4173\n",
      "Epoch [43/50], Step [225/735], Loss: 0.3832\n",
      "Epoch [43/50], Step [226/735], Loss: 0.1509\n",
      "Epoch [43/50], Step [227/735], Loss: 0.4305\n",
      "Epoch [43/50], Step [228/735], Loss: 0.3168\n",
      "Epoch [43/50], Step [229/735], Loss: 0.2954\n",
      "Epoch [43/50], Step [230/735], Loss: 0.8967\n",
      "Epoch [43/50], Step [231/735], Loss: 0.4363\n",
      "Epoch [43/50], Step [232/735], Loss: 0.3075\n",
      "Epoch [43/50], Step [233/735], Loss: 0.8413\n",
      "Epoch [43/50], Step [234/735], Loss: 0.3034\n",
      "Epoch [43/50], Step [235/735], Loss: 0.1638\n",
      "Epoch [43/50], Step [236/735], Loss: 0.6135\n",
      "Epoch [43/50], Step [237/735], Loss: 0.2261\n",
      "Epoch [43/50], Step [238/735], Loss: 3.2876\n",
      "Epoch [43/50], Step [239/735], Loss: 0.2684\n",
      "Epoch [43/50], Step [240/735], Loss: 0.5469\n",
      "Epoch [43/50], Step [241/735], Loss: 0.3065\n",
      "Epoch [43/50], Step [242/735], Loss: 0.5715\n",
      "Epoch [43/50], Step [243/735], Loss: 0.3724\n",
      "Epoch [43/50], Step [244/735], Loss: 0.2934\n",
      "Epoch [43/50], Step [245/735], Loss: 0.1879\n",
      "Epoch [43/50], Step [246/735], Loss: 0.5937\n",
      "Epoch [43/50], Step [247/735], Loss: 0.3235\n",
      "Epoch [43/50], Step [248/735], Loss: 0.2224\n",
      "Epoch [43/50], Step [249/735], Loss: 0.1644\n",
      "Epoch [43/50], Step [250/735], Loss: 0.1839\n",
      "Epoch [43/50], Step [251/735], Loss: 0.3070\n",
      "Epoch [43/50], Step [252/735], Loss: 0.4005\n",
      "Epoch [43/50], Step [253/735], Loss: 0.2756\n",
      "Epoch [43/50], Step [254/735], Loss: 0.3270\n",
      "Epoch [43/50], Step [255/735], Loss: 0.1580\n",
      "Epoch [43/50], Step [256/735], Loss: 0.4196\n",
      "Epoch [43/50], Step [257/735], Loss: 0.5033\n",
      "Epoch [43/50], Step [258/735], Loss: 0.3391\n",
      "Epoch [43/50], Step [259/735], Loss: 0.4306\n",
      "Epoch [43/50], Step [260/735], Loss: 0.1942\n",
      "Epoch [43/50], Step [261/735], Loss: 0.2161\n",
      "Epoch [43/50], Step [262/735], Loss: 0.1146\n",
      "Epoch [43/50], Step [263/735], Loss: 0.1299\n",
      "Epoch [43/50], Step [264/735], Loss: 0.2929\n",
      "Epoch [43/50], Step [265/735], Loss: 0.0967\n",
      "Epoch [43/50], Step [266/735], Loss: 0.1394\n",
      "Epoch [43/50], Step [267/735], Loss: 0.2087\n",
      "Epoch [43/50], Step [268/735], Loss: 0.3690\n",
      "Epoch [43/50], Step [269/735], Loss: 0.2864\n",
      "Epoch [43/50], Step [270/735], Loss: 0.1346\n",
      "Epoch [43/50], Step [271/735], Loss: 0.0833\n",
      "Epoch [43/50], Step [272/735], Loss: 0.1256\n",
      "Epoch [43/50], Step [273/735], Loss: 0.1629\n",
      "Epoch [43/50], Step [274/735], Loss: 0.4035\n",
      "Epoch [43/50], Step [275/735], Loss: 0.1492\n",
      "Epoch [43/50], Step [276/735], Loss: 0.2572\n",
      "Epoch [43/50], Step [277/735], Loss: 0.2276\n",
      "Epoch [43/50], Step [278/735], Loss: 0.0646\n",
      "Epoch [43/50], Step [279/735], Loss: 0.4144\n",
      "Epoch [43/50], Step [280/735], Loss: 0.0625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Step [281/735], Loss: 0.2138\n",
      "Epoch [43/50], Step [282/735], Loss: 1.3914\n",
      "Epoch [43/50], Step [283/735], Loss: 0.4999\n",
      "Epoch [43/50], Step [284/735], Loss: 0.2033\n",
      "Epoch [43/50], Step [285/735], Loss: 0.3600\n",
      "Epoch [43/50], Step [286/735], Loss: 0.1983\n",
      "Epoch [43/50], Step [287/735], Loss: 0.4071\n",
      "Epoch [43/50], Step [288/735], Loss: 0.2618\n",
      "Epoch [43/50], Step [289/735], Loss: 0.1908\n",
      "Epoch [43/50], Step [290/735], Loss: 0.1363\n",
      "Epoch [43/50], Step [291/735], Loss: 0.2940\n",
      "Epoch [43/50], Step [292/735], Loss: 0.4145\n",
      "Epoch [43/50], Step [293/735], Loss: 0.3393\n",
      "Epoch [43/50], Step [294/735], Loss: 0.3406\n",
      "Epoch [43/50], Step [295/735], Loss: 0.1183\n",
      "Epoch [43/50], Step [296/735], Loss: 0.2750\n",
      "Epoch [43/50], Step [297/735], Loss: 2.9328\n",
      "Epoch [43/50], Step [298/735], Loss: 0.1227\n",
      "Epoch [43/50], Step [299/735], Loss: 0.1507\n",
      "Epoch [43/50], Step [300/735], Loss: 0.6242\n",
      "Epoch [43/50], Step [301/735], Loss: 0.2513\n",
      "Epoch [43/50], Step [302/735], Loss: 0.1259\n",
      "Epoch [43/50], Step [303/735], Loss: 0.4179\n",
      "Epoch [43/50], Step [304/735], Loss: 0.1270\n",
      "Epoch [43/50], Step [305/735], Loss: 0.1743\n",
      "Epoch [43/50], Step [306/735], Loss: 0.2989\n",
      "Epoch [43/50], Step [307/735], Loss: 0.1656\n",
      "Epoch [43/50], Step [308/735], Loss: 0.1806\n",
      "Epoch [43/50], Step [309/735], Loss: 0.2783\n",
      "Epoch [43/50], Step [310/735], Loss: 0.2893\n",
      "Epoch [43/50], Step [311/735], Loss: 0.4014\n",
      "Epoch [43/50], Step [312/735], Loss: 0.1237\n",
      "Epoch [43/50], Step [313/735], Loss: 1.1488\n",
      "Epoch [43/50], Step [314/735], Loss: 0.1778\n",
      "Epoch [43/50], Step [315/735], Loss: 0.3750\n",
      "Epoch [43/50], Step [316/735], Loss: 0.3304\n",
      "Epoch [43/50], Step [317/735], Loss: 0.2943\n",
      "Epoch [43/50], Step [318/735], Loss: 0.2150\n",
      "Epoch [43/50], Step [319/735], Loss: 0.1933\n",
      "Epoch [43/50], Step [320/735], Loss: 0.1680\n",
      "Epoch [43/50], Step [321/735], Loss: 0.5698\n",
      "Epoch [43/50], Step [322/735], Loss: 0.2123\n",
      "Epoch [43/50], Step [323/735], Loss: 0.2810\n",
      "Epoch [43/50], Step [324/735], Loss: 0.2559\n",
      "Epoch [43/50], Step [325/735], Loss: 0.1559\n",
      "Epoch [43/50], Step [326/735], Loss: 0.1566\n",
      "Epoch [43/50], Step [327/735], Loss: 0.0829\n",
      "Epoch [43/50], Step [328/735], Loss: 0.1943\n",
      "Epoch [43/50], Step [329/735], Loss: 0.2025\n",
      "Epoch [43/50], Step [330/735], Loss: 0.1371\n",
      "Epoch [43/50], Step [331/735], Loss: 0.1791\n",
      "Epoch [43/50], Step [332/735], Loss: 0.2275\n",
      "Epoch [43/50], Step [333/735], Loss: 1.0839\n",
      "Epoch [43/50], Step [334/735], Loss: 0.1015\n",
      "Epoch [43/50], Step [335/735], Loss: 0.0862\n",
      "Epoch [43/50], Step [336/735], Loss: 0.2447\n",
      "Epoch [43/50], Step [337/735], Loss: 0.2106\n",
      "Epoch [43/50], Step [338/735], Loss: 0.2142\n",
      "Epoch [43/50], Step [339/735], Loss: 0.1186\n",
      "Epoch [43/50], Step [340/735], Loss: 0.1458\n",
      "Epoch [43/50], Step [341/735], Loss: 0.1553\n",
      "Epoch [43/50], Step [342/735], Loss: 0.1262\n",
      "Epoch [43/50], Step [343/735], Loss: 0.0784\n",
      "Epoch [43/50], Step [344/735], Loss: 0.0932\n",
      "Epoch [43/50], Step [345/735], Loss: 0.2978\n",
      "Epoch [43/50], Step [346/735], Loss: 0.0628\n",
      "Epoch [43/50], Step [347/735], Loss: 0.4432\n",
      "Epoch [43/50], Step [348/735], Loss: 1.4444\n",
      "Epoch [43/50], Step [349/735], Loss: 0.3963\n",
      "Epoch [43/50], Step [350/735], Loss: 0.3280\n",
      "Epoch [43/50], Step [351/735], Loss: 0.8252\n",
      "Epoch [43/50], Step [352/735], Loss: 0.3761\n",
      "Epoch [43/50], Step [353/735], Loss: 2.9988\n",
      "Epoch [43/50], Step [354/735], Loss: 0.1207\n",
      "Epoch [43/50], Step [355/735], Loss: 0.2415\n",
      "Epoch [43/50], Step [356/735], Loss: 0.0783\n",
      "Epoch [43/50], Step [357/735], Loss: 0.6206\n",
      "Epoch [43/50], Step [358/735], Loss: 0.2499\n",
      "Epoch [43/50], Step [359/735], Loss: 0.8200\n",
      "Epoch [43/50], Step [360/735], Loss: 0.1746\n",
      "Epoch [43/50], Step [361/735], Loss: 0.1687\n",
      "Epoch [43/50], Step [362/735], Loss: 0.2267\n",
      "Epoch [43/50], Step [363/735], Loss: 0.2177\n",
      "Epoch [43/50], Step [364/735], Loss: 0.1948\n",
      "Epoch [43/50], Step [365/735], Loss: 0.2175\n",
      "Epoch [43/50], Step [366/735], Loss: 0.6265\n",
      "Epoch [43/50], Step [367/735], Loss: 0.2164\n",
      "Epoch [43/50], Step [368/735], Loss: 0.1030\n",
      "Epoch [43/50], Step [369/735], Loss: 0.1578\n",
      "Epoch [43/50], Step [370/735], Loss: 0.3951\n",
      "Epoch [43/50], Step [371/735], Loss: 0.1660\n",
      "Epoch [43/50], Step [372/735], Loss: 0.2362\n",
      "Epoch [43/50], Step [373/735], Loss: 0.2438\n",
      "Epoch [43/50], Step [374/735], Loss: 0.2457\n",
      "Epoch [43/50], Step [375/735], Loss: 0.3290\n",
      "Epoch [43/50], Step [376/735], Loss: 0.1111\n",
      "Epoch [43/50], Step [377/735], Loss: 0.1308\n",
      "Epoch [43/50], Step [378/735], Loss: 0.0990\n",
      "Epoch [43/50], Step [379/735], Loss: 0.2759\n",
      "Epoch [43/50], Step [380/735], Loss: 0.6328\n",
      "Epoch [43/50], Step [381/735], Loss: 0.3869\n",
      "Epoch [43/50], Step [382/735], Loss: 0.1046\n",
      "Epoch [43/50], Step [383/735], Loss: 0.2451\n",
      "Epoch [43/50], Step [384/735], Loss: 0.4583\n",
      "Epoch [43/50], Step [385/735], Loss: 0.1168\n",
      "Epoch [43/50], Step [386/735], Loss: 0.0548\n",
      "Epoch [43/50], Step [387/735], Loss: 0.1561\n",
      "Epoch [43/50], Step [388/735], Loss: 0.1245\n",
      "Epoch [43/50], Step [389/735], Loss: 0.2628\n",
      "Epoch [43/50], Step [390/735], Loss: 0.1409\n",
      "Epoch [43/50], Step [391/735], Loss: 0.1919\n",
      "Epoch [43/50], Step [392/735], Loss: 0.0779\n",
      "Epoch [43/50], Step [393/735], Loss: 0.1759\n",
      "Epoch [43/50], Step [394/735], Loss: 0.5547\n",
      "Epoch [43/50], Step [395/735], Loss: 0.6986\n",
      "Epoch [43/50], Step [396/735], Loss: 1.0469\n",
      "Epoch [43/50], Step [397/735], Loss: 0.2094\n",
      "Epoch [43/50], Step [398/735], Loss: 0.1109\n",
      "Epoch [43/50], Step [399/735], Loss: 0.2237\n",
      "Epoch [43/50], Step [400/735], Loss: 0.2683\n",
      "Epoch [43/50], Step [401/735], Loss: 0.6821\n",
      "Epoch [43/50], Step [402/735], Loss: 0.1334\n",
      "Epoch [43/50], Step [403/735], Loss: 0.3858\n",
      "Epoch [43/50], Step [404/735], Loss: 0.1612\n",
      "Epoch [43/50], Step [405/735], Loss: 0.1356\n",
      "Epoch [43/50], Step [406/735], Loss: 0.7707\n",
      "Epoch [43/50], Step [407/735], Loss: 0.4283\n",
      "Epoch [43/50], Step [408/735], Loss: 0.2051\n",
      "Epoch [43/50], Step [409/735], Loss: 0.3077\n",
      "Epoch [43/50], Step [410/735], Loss: 0.4417\n",
      "Epoch [43/50], Step [411/735], Loss: 0.1001\n",
      "Epoch [43/50], Step [412/735], Loss: 0.2017\n",
      "Epoch [43/50], Step [413/735], Loss: 0.1953\n",
      "Epoch [43/50], Step [414/735], Loss: 0.1637\n",
      "Epoch [43/50], Step [415/735], Loss: 0.1361\n",
      "Epoch [43/50], Step [416/735], Loss: 3.3990\n",
      "Epoch [43/50], Step [417/735], Loss: 0.2024\n",
      "Epoch [43/50], Step [418/735], Loss: 0.2763\n",
      "Epoch [43/50], Step [419/735], Loss: 0.1743\n",
      "Epoch [43/50], Step [420/735], Loss: 0.2083\n",
      "Epoch [43/50], Step [421/735], Loss: 0.3860\n",
      "Epoch [43/50], Step [422/735], Loss: 0.3226\n",
      "Epoch [43/50], Step [423/735], Loss: 0.0826\n",
      "Epoch [43/50], Step [424/735], Loss: 0.2440\n",
      "Epoch [43/50], Step [425/735], Loss: 0.2453\n",
      "Epoch [43/50], Step [426/735], Loss: 0.5786\n",
      "Epoch [43/50], Step [427/735], Loss: 0.1567\n",
      "Epoch [43/50], Step [428/735], Loss: 0.2202\n",
      "Epoch [43/50], Step [429/735], Loss: 0.0676\n",
      "Epoch [43/50], Step [430/735], Loss: 0.2711\n",
      "Epoch [43/50], Step [431/735], Loss: 0.0890\n",
      "Epoch [43/50], Step [432/735], Loss: 0.3614\n",
      "Epoch [43/50], Step [433/735], Loss: 0.0804\n",
      "Epoch [43/50], Step [434/735], Loss: 0.3264\n",
      "Epoch [43/50], Step [435/735], Loss: 0.4643\n",
      "Epoch [43/50], Step [436/735], Loss: 0.0749\n",
      "Epoch [43/50], Step [437/735], Loss: 0.2467\n",
      "Epoch [43/50], Step [438/735], Loss: 0.2777\n",
      "Epoch [43/50], Step [439/735], Loss: 0.5081\n",
      "Epoch [43/50], Step [440/735], Loss: 0.0877\n",
      "Epoch [43/50], Step [441/735], Loss: 0.0562\n",
      "Epoch [43/50], Step [442/735], Loss: 0.1073\n",
      "Epoch [43/50], Step [443/735], Loss: 0.1255\n",
      "Epoch [43/50], Step [444/735], Loss: 0.1851\n",
      "Epoch [43/50], Step [445/735], Loss: 0.1415\n",
      "Epoch [43/50], Step [446/735], Loss: 0.3473\n",
      "Epoch [43/50], Step [447/735], Loss: 0.4730\n",
      "Epoch [43/50], Step [448/735], Loss: 0.1331\n",
      "Epoch [43/50], Step [449/735], Loss: 0.2482\n",
      "Epoch [43/50], Step [450/735], Loss: 0.4779\n",
      "Epoch [43/50], Step [451/735], Loss: 0.0887\n",
      "Epoch [43/50], Step [452/735], Loss: 0.6806\n",
      "Epoch [43/50], Step [453/735], Loss: 0.2091\n",
      "Epoch [43/50], Step [454/735], Loss: 0.2444\n",
      "Epoch [43/50], Step [455/735], Loss: 0.1016\n",
      "Epoch [43/50], Step [456/735], Loss: 0.2659\n",
      "Epoch [43/50], Step [457/735], Loss: 0.1295\n",
      "Epoch [43/50], Step [458/735], Loss: 0.1232\n",
      "Epoch [43/50], Step [459/735], Loss: 0.2825\n",
      "Epoch [43/50], Step [460/735], Loss: 0.5178\n",
      "Epoch [43/50], Step [461/735], Loss: 0.1198\n",
      "Epoch [43/50], Step [462/735], Loss: 0.2383\n",
      "Epoch [43/50], Step [463/735], Loss: 0.2079\n",
      "Epoch [43/50], Step [464/735], Loss: 0.3362\n",
      "Epoch [43/50], Step [465/735], Loss: 0.0863\n",
      "Epoch [43/50], Step [466/735], Loss: 0.1463\n",
      "Epoch [43/50], Step [467/735], Loss: 0.1764\n",
      "Epoch [43/50], Step [468/735], Loss: 0.1955\n",
      "Epoch [43/50], Step [469/735], Loss: 0.0639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Step [470/735], Loss: 0.1661\n",
      "Epoch [43/50], Step [471/735], Loss: 0.2132\n",
      "Epoch [43/50], Step [472/735], Loss: 0.2871\n",
      "Epoch [43/50], Step [473/735], Loss: 0.3823\n",
      "Epoch [43/50], Step [474/735], Loss: 0.2818\n",
      "Epoch [43/50], Step [475/735], Loss: 0.1478\n",
      "Epoch [43/50], Step [476/735], Loss: 0.1818\n",
      "Epoch [43/50], Step [477/735], Loss: 0.2519\n",
      "Epoch [43/50], Step [478/735], Loss: 0.4377\n",
      "Epoch [43/50], Step [479/735], Loss: 0.3363\n",
      "Epoch [43/50], Step [480/735], Loss: 0.4542\n",
      "Epoch [43/50], Step [481/735], Loss: 0.2354\n",
      "Epoch [43/50], Step [482/735], Loss: 0.0829\n",
      "Epoch [43/50], Step [483/735], Loss: 0.4488\n",
      "Epoch [43/50], Step [484/735], Loss: 0.2237\n",
      "Epoch [43/50], Step [485/735], Loss: 0.1720\n",
      "Epoch [43/50], Step [486/735], Loss: 0.0976\n",
      "Epoch [43/50], Step [487/735], Loss: 0.0570\n",
      "Epoch [43/50], Step [488/735], Loss: 0.2504\n",
      "Epoch [43/50], Step [489/735], Loss: 0.0827\n",
      "Epoch [43/50], Step [490/735], Loss: 0.1563\n",
      "Epoch [43/50], Step [491/735], Loss: 0.5239\n",
      "Epoch [43/50], Step [492/735], Loss: 0.1171\n",
      "Epoch [43/50], Step [493/735], Loss: 0.3018\n",
      "Epoch [43/50], Step [494/735], Loss: 0.1106\n",
      "Epoch [43/50], Step [495/735], Loss: 0.4652\n",
      "Epoch [43/50], Step [496/735], Loss: 0.1477\n",
      "Epoch [43/50], Step [497/735], Loss: 0.1632\n",
      "Epoch [43/50], Step [498/735], Loss: 0.1687\n",
      "Epoch [43/50], Step [499/735], Loss: 0.4315\n",
      "Epoch [43/50], Step [500/735], Loss: 0.1993\n",
      "Epoch [43/50], Step [501/735], Loss: 0.5382\n",
      "Epoch [43/50], Step [502/735], Loss: 0.1426\n",
      "Epoch [43/50], Step [503/735], Loss: 0.4249\n",
      "Epoch [43/50], Step [504/735], Loss: 0.2477\n",
      "Epoch [43/50], Step [505/735], Loss: 0.2786\n",
      "Epoch [43/50], Step [506/735], Loss: 0.4054\n",
      "Epoch [43/50], Step [507/735], Loss: 0.4344\n",
      "Epoch [43/50], Step [508/735], Loss: 0.2508\n",
      "Epoch [43/50], Step [509/735], Loss: 0.4035\n",
      "Epoch [43/50], Step [510/735], Loss: 0.1116\n",
      "Epoch [43/50], Step [511/735], Loss: 0.1171\n",
      "Epoch [43/50], Step [512/735], Loss: 0.2512\n",
      "Epoch [43/50], Step [513/735], Loss: 0.2419\n",
      "Epoch [43/50], Step [514/735], Loss: 0.2918\n",
      "Epoch [43/50], Step [515/735], Loss: 0.7215\n",
      "Epoch [43/50], Step [516/735], Loss: 0.1077\n",
      "Epoch [43/50], Step [517/735], Loss: 0.2444\n",
      "Epoch [43/50], Step [518/735], Loss: 0.1677\n",
      "Epoch [43/50], Step [519/735], Loss: 0.2539\n",
      "Epoch [43/50], Step [520/735], Loss: 0.2173\n",
      "Epoch [43/50], Step [521/735], Loss: 0.1269\n",
      "Epoch [43/50], Step [522/735], Loss: 0.3147\n",
      "Epoch [43/50], Step [523/735], Loss: 0.1263\n",
      "Epoch [43/50], Step [524/735], Loss: 0.1492\n",
      "Epoch [43/50], Step [525/735], Loss: 0.3631\n",
      "Epoch [43/50], Step [526/735], Loss: 0.5045\n",
      "Epoch [43/50], Step [527/735], Loss: 0.8422\n",
      "Epoch [43/50], Step [528/735], Loss: 0.1047\n",
      "Epoch [43/50], Step [529/735], Loss: 0.1880\n",
      "Epoch [43/50], Step [530/735], Loss: 0.1524\n",
      "Epoch [43/50], Step [531/735], Loss: 0.1758\n",
      "Epoch [43/50], Step [532/735], Loss: 0.2940\n",
      "Epoch [43/50], Step [533/735], Loss: 0.0774\n",
      "Epoch [43/50], Step [534/735], Loss: 0.1163\n",
      "Epoch [43/50], Step [535/735], Loss: 0.1576\n",
      "Epoch [43/50], Step [536/735], Loss: 0.0951\n",
      "Epoch [43/50], Step [537/735], Loss: 0.2791\n",
      "Epoch [43/50], Step [538/735], Loss: 0.2491\n",
      "Epoch [43/50], Step [539/735], Loss: 0.1397\n",
      "Epoch [43/50], Step [540/735], Loss: 0.2731\n",
      "Epoch [43/50], Step [541/735], Loss: 0.1545\n",
      "Epoch [43/50], Step [542/735], Loss: 0.2458\n",
      "Epoch [43/50], Step [543/735], Loss: 0.0905\n",
      "Epoch [43/50], Step [544/735], Loss: 0.1189\n",
      "Epoch [43/50], Step [545/735], Loss: 0.2477\n",
      "Epoch [43/50], Step [546/735], Loss: 0.1709\n",
      "Epoch [43/50], Step [547/735], Loss: 0.2580\n",
      "Epoch [43/50], Step [548/735], Loss: 0.2675\n",
      "Epoch [43/50], Step [549/735], Loss: 0.0332\n",
      "Epoch [43/50], Step [550/735], Loss: 0.2052\n",
      "Epoch [43/50], Step [551/735], Loss: 0.2527\n",
      "Epoch [43/50], Step [552/735], Loss: 0.2323\n",
      "Epoch [43/50], Step [553/735], Loss: 0.0955\n",
      "Epoch [43/50], Step [554/735], Loss: 0.6833\n",
      "Epoch [43/50], Step [555/735], Loss: 0.4545\n",
      "Epoch [43/50], Step [556/735], Loss: 0.5678\n",
      "Epoch [43/50], Step [557/735], Loss: 0.1877\n",
      "Epoch [43/50], Step [558/735], Loss: 0.1864\n",
      "Epoch [43/50], Step [559/735], Loss: 0.0931\n",
      "Epoch [43/50], Step [560/735], Loss: 0.2432\n",
      "Epoch [43/50], Step [561/735], Loss: 0.1209\n",
      "Epoch [43/50], Step [562/735], Loss: 0.1677\n",
      "Epoch [43/50], Step [563/735], Loss: 0.3058\n",
      "Epoch [43/50], Step [564/735], Loss: 0.2014\n",
      "Epoch [43/50], Step [565/735], Loss: 0.2579\n",
      "Epoch [43/50], Step [566/735], Loss: 0.1762\n",
      "Epoch [43/50], Step [567/735], Loss: 0.1634\n",
      "Epoch [43/50], Step [568/735], Loss: 0.3148\n",
      "Epoch [43/50], Step [569/735], Loss: 0.3121\n",
      "Epoch [43/50], Step [570/735], Loss: 0.1177\n",
      "Epoch [43/50], Step [571/735], Loss: 0.1669\n",
      "Epoch [43/50], Step [572/735], Loss: 0.1537\n",
      "Epoch [43/50], Step [573/735], Loss: 0.1424\n",
      "Epoch [43/50], Step [574/735], Loss: 2.8294\n",
      "Epoch [43/50], Step [575/735], Loss: 0.1139\n",
      "Epoch [43/50], Step [576/735], Loss: 0.0666\n",
      "Epoch [43/50], Step [577/735], Loss: 0.1052\n",
      "Epoch [43/50], Step [578/735], Loss: 0.5905\n",
      "Epoch [43/50], Step [579/735], Loss: 0.1604\n",
      "Epoch [43/50], Step [580/735], Loss: 0.7702\n",
      "Epoch [43/50], Step [581/735], Loss: 0.2174\n",
      "Epoch [43/50], Step [582/735], Loss: 0.7323\n",
      "Epoch [43/50], Step [583/735], Loss: 0.0596\n",
      "Epoch [43/50], Step [584/735], Loss: 0.1181\n",
      "Epoch [43/50], Step [585/735], Loss: 0.2399\n",
      "Epoch [43/50], Step [586/735], Loss: 0.2952\n",
      "Epoch [43/50], Step [587/735], Loss: 0.2383\n",
      "Epoch [43/50], Step [588/735], Loss: 0.0713\n",
      "Epoch [43/50], Step [589/735], Loss: 0.1062\n",
      "Epoch [43/50], Step [590/735], Loss: 0.8216\n",
      "Epoch [43/50], Step [591/735], Loss: 0.1795\n",
      "Epoch [43/50], Step [592/735], Loss: 1.4362\n",
      "Epoch [43/50], Step [593/735], Loss: 0.0858\n",
      "Epoch [43/50], Step [594/735], Loss: 0.3411\n",
      "Epoch [43/50], Step [595/735], Loss: 0.1081\n",
      "Epoch [43/50], Step [596/735], Loss: 0.2462\n",
      "Epoch [43/50], Step [597/735], Loss: 0.1485\n",
      "Epoch [43/50], Step [598/735], Loss: 0.2522\n",
      "Epoch [43/50], Step [599/735], Loss: 0.2658\n",
      "Epoch [43/50], Step [600/735], Loss: 0.1099\n",
      "Epoch [43/50], Step [601/735], Loss: 0.2525\n",
      "Epoch [43/50], Step [602/735], Loss: 0.4991\n",
      "Epoch [43/50], Step [603/735], Loss: 0.1915\n",
      "Epoch [43/50], Step [604/735], Loss: 0.3780\n",
      "Epoch [43/50], Step [605/735], Loss: 0.4147\n",
      "Epoch [43/50], Step [606/735], Loss: 0.3529\n",
      "Epoch [43/50], Step [607/735], Loss: 0.0831\n",
      "Epoch [43/50], Step [608/735], Loss: 0.3282\n",
      "Epoch [43/50], Step [609/735], Loss: 0.0255\n",
      "Epoch [43/50], Step [610/735], Loss: 0.2739\n",
      "Epoch [43/50], Step [611/735], Loss: 0.1549\n",
      "Epoch [43/50], Step [612/735], Loss: 0.1650\n",
      "Epoch [43/50], Step [613/735], Loss: 0.0570\n",
      "Epoch [43/50], Step [614/735], Loss: 0.9189\n",
      "Epoch [43/50], Step [615/735], Loss: 0.0455\n",
      "Epoch [43/50], Step [616/735], Loss: 0.2351\n",
      "Epoch [43/50], Step [617/735], Loss: 0.2244\n",
      "Epoch [43/50], Step [618/735], Loss: 0.2003\n",
      "Epoch [43/50], Step [619/735], Loss: 0.2242\n",
      "Epoch [43/50], Step [620/735], Loss: 0.3631\n",
      "Epoch [43/50], Step [621/735], Loss: 0.0917\n",
      "Epoch [43/50], Step [622/735], Loss: 0.4291\n",
      "Epoch [43/50], Step [623/735], Loss: 0.3163\n",
      "Epoch [43/50], Step [624/735], Loss: 0.1550\n",
      "Epoch [43/50], Step [625/735], Loss: 0.1931\n",
      "Epoch [43/50], Step [626/735], Loss: 0.0948\n",
      "Epoch [43/50], Step [627/735], Loss: 0.2079\n",
      "Epoch [43/50], Step [628/735], Loss: 0.2857\n",
      "Epoch [43/50], Step [629/735], Loss: 0.1489\n",
      "Epoch [43/50], Step [630/735], Loss: 0.4382\n",
      "Epoch [43/50], Step [631/735], Loss: 0.1496\n",
      "Epoch [43/50], Step [632/735], Loss: 0.1415\n",
      "Epoch [43/50], Step [633/735], Loss: 0.2931\n",
      "Epoch [43/50], Step [634/735], Loss: 0.2216\n",
      "Epoch [43/50], Step [635/735], Loss: 0.2321\n",
      "Epoch [43/50], Step [636/735], Loss: 0.0802\n",
      "Epoch [43/50], Step [637/735], Loss: 0.2243\n",
      "Epoch [43/50], Step [638/735], Loss: 0.1141\n",
      "Epoch [43/50], Step [639/735], Loss: 0.1591\n",
      "Epoch [43/50], Step [640/735], Loss: 0.4060\n",
      "Epoch [43/50], Step [641/735], Loss: 0.0579\n",
      "Epoch [43/50], Step [642/735], Loss: 0.1180\n",
      "Epoch [43/50], Step [643/735], Loss: 0.1344\n",
      "Epoch [43/50], Step [644/735], Loss: 0.5113\n",
      "Epoch [43/50], Step [645/735], Loss: 0.4323\n",
      "Epoch [43/50], Step [646/735], Loss: 0.0569\n",
      "Epoch [43/50], Step [647/735], Loss: 0.1906\n",
      "Epoch [43/50], Step [648/735], Loss: 0.2402\n",
      "Epoch [43/50], Step [649/735], Loss: 0.1060\n",
      "Epoch [43/50], Step [650/735], Loss: 0.2845\n",
      "Epoch [43/50], Step [651/735], Loss: 0.6349\n",
      "Epoch [43/50], Step [652/735], Loss: 0.3170\n",
      "Epoch [43/50], Step [653/735], Loss: 0.0966\n",
      "Epoch [43/50], Step [654/735], Loss: 0.0764\n",
      "Epoch [43/50], Step [655/735], Loss: 0.2902\n",
      "Epoch [43/50], Step [656/735], Loss: 0.1552\n",
      "Epoch [43/50], Step [657/735], Loss: 0.3288\n",
      "Epoch [43/50], Step [658/735], Loss: 0.5220\n",
      "Epoch [43/50], Step [659/735], Loss: 0.0410\n",
      "Epoch [43/50], Step [660/735], Loss: 0.4257\n",
      "Epoch [43/50], Step [661/735], Loss: 0.1346\n",
      "Epoch [43/50], Step [662/735], Loss: 0.1393\n",
      "Epoch [43/50], Step [663/735], Loss: 0.5358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Step [664/735], Loss: 0.3275\n",
      "Epoch [43/50], Step [665/735], Loss: 0.2120\n",
      "Epoch [43/50], Step [666/735], Loss: 0.4106\n",
      "Epoch [43/50], Step [667/735], Loss: 0.0748\n",
      "Epoch [43/50], Step [668/735], Loss: 0.1343\n",
      "Epoch [43/50], Step [669/735], Loss: 0.1720\n",
      "Epoch [43/50], Step [670/735], Loss: 0.7537\n",
      "Epoch [43/50], Step [671/735], Loss: 0.2145\n",
      "Epoch [43/50], Step [672/735], Loss: 0.2788\n",
      "Epoch [43/50], Step [673/735], Loss: 0.5335\n",
      "Epoch [43/50], Step [674/735], Loss: 0.1470\n",
      "Epoch [43/50], Step [675/735], Loss: 0.2295\n",
      "Epoch [43/50], Step [676/735], Loss: 0.0532\n",
      "Epoch [43/50], Step [677/735], Loss: 0.2219\n",
      "Epoch [43/50], Step [678/735], Loss: 0.4287\n",
      "Epoch [43/50], Step [679/735], Loss: 0.2217\n",
      "Epoch [43/50], Step [680/735], Loss: 0.2405\n",
      "Epoch [43/50], Step [681/735], Loss: 0.2282\n",
      "Epoch [43/50], Step [682/735], Loss: 0.2380\n",
      "Epoch [43/50], Step [683/735], Loss: 0.1808\n",
      "Epoch [43/50], Step [684/735], Loss: 0.4596\n",
      "Epoch [43/50], Step [685/735], Loss: 0.2109\n",
      "Epoch [43/50], Step [686/735], Loss: 0.5191\n",
      "Epoch [43/50], Step [687/735], Loss: 0.1135\n",
      "Epoch [43/50], Step [688/735], Loss: 0.1219\n",
      "Epoch [43/50], Step [689/735], Loss: 0.0824\n",
      "Epoch [43/50], Step [690/735], Loss: 0.3560\n",
      "Epoch [43/50], Step [691/735], Loss: 0.4458\n",
      "Epoch [43/50], Step [692/735], Loss: 0.3266\n",
      "Epoch [43/50], Step [693/735], Loss: 0.1402\n",
      "Epoch [43/50], Step [694/735], Loss: 0.2171\n",
      "Epoch [43/50], Step [695/735], Loss: 0.2590\n",
      "Epoch [43/50], Step [696/735], Loss: 0.4357\n",
      "Epoch [43/50], Step [697/735], Loss: 0.2461\n",
      "Epoch [43/50], Step [698/735], Loss: 0.2005\n",
      "Epoch [43/50], Step [699/735], Loss: 0.3212\n",
      "Epoch [43/50], Step [700/735], Loss: 0.3418\n",
      "Epoch [43/50], Step [701/735], Loss: 0.4764\n",
      "Epoch [43/50], Step [702/735], Loss: 0.2223\n",
      "Epoch [43/50], Step [703/735], Loss: 0.4109\n",
      "Epoch [43/50], Step [704/735], Loss: 0.3312\n",
      "Epoch [43/50], Step [705/735], Loss: 0.3196\n",
      "Epoch [43/50], Step [706/735], Loss: 0.1917\n",
      "Epoch [43/50], Step [707/735], Loss: 0.1829\n",
      "Epoch [43/50], Step [708/735], Loss: 0.1420\n",
      "Epoch [43/50], Step [709/735], Loss: 0.4759\n",
      "Epoch [43/50], Step [710/735], Loss: 0.3200\n",
      "Epoch [43/50], Step [711/735], Loss: 0.5116\n",
      "Epoch [43/50], Step [712/735], Loss: 0.1193\n",
      "Epoch [43/50], Step [713/735], Loss: 0.2862\n",
      "Epoch [43/50], Step [714/735], Loss: 0.3121\n",
      "Epoch [43/50], Step [715/735], Loss: 0.1822\n",
      "Epoch [43/50], Step [716/735], Loss: 0.1135\n",
      "Epoch [43/50], Step [717/735], Loss: 0.8821\n",
      "Epoch [43/50], Step [718/735], Loss: 0.3357\n",
      "Epoch [43/50], Step [719/735], Loss: 0.5816\n",
      "Epoch [43/50], Step [720/735], Loss: 0.4023\n",
      "Epoch [43/50], Step [721/735], Loss: 0.2201\n",
      "Epoch [43/50], Step [722/735], Loss: 0.2292\n",
      "Epoch [43/50], Step [723/735], Loss: 0.1547\n",
      "Epoch [43/50], Step [724/735], Loss: 0.6008\n",
      "Epoch [43/50], Step [725/735], Loss: 1.8475\n",
      "Epoch [43/50], Step [726/735], Loss: 0.3812\n",
      "Epoch [43/50], Step [727/735], Loss: 0.4521\n",
      "Epoch [43/50], Step [728/735], Loss: 0.3607\n",
      "Epoch [43/50], Step [729/735], Loss: 0.2351\n",
      "Epoch [43/50], Step [730/735], Loss: 0.3968\n",
      "Epoch [43/50], Step [731/735], Loss: 0.2258\n",
      "Epoch [43/50], Step [732/735], Loss: 0.1113\n",
      "Epoch [43/50], Step [733/735], Loss: 0.4256\n",
      "Epoch [43/50], Step [734/735], Loss: 0.2695\n",
      "Epoch [43/50], Step [735/735], Loss: 0.0576\n",
      "Epoch [44/50], Step [1/735], Loss: 0.1045\n",
      "Epoch [44/50], Step [2/735], Loss: 0.3116\n",
      "Epoch [44/50], Step [3/735], Loss: 0.3778\n",
      "Epoch [44/50], Step [4/735], Loss: 0.2264\n",
      "Epoch [44/50], Step [5/735], Loss: 0.1675\n",
      "Epoch [44/50], Step [6/735], Loss: 0.1681\n",
      "Epoch [44/50], Step [7/735], Loss: 0.3167\n",
      "Epoch [44/50], Step [8/735], Loss: 0.4651\n",
      "Epoch [44/50], Step [9/735], Loss: 0.1329\n",
      "Epoch [44/50], Step [10/735], Loss: 0.6115\n",
      "Epoch [44/50], Step [11/735], Loss: 0.0811\n",
      "Epoch [44/50], Step [12/735], Loss: 0.2376\n",
      "Epoch [44/50], Step [13/735], Loss: 0.2277\n",
      "Epoch [44/50], Step [14/735], Loss: 0.4967\n",
      "Epoch [44/50], Step [15/735], Loss: 0.1735\n",
      "Epoch [44/50], Step [16/735], Loss: 0.3282\n",
      "Epoch [44/50], Step [17/735], Loss: 0.3549\n",
      "Epoch [44/50], Step [18/735], Loss: 0.3584\n",
      "Epoch [44/50], Step [19/735], Loss: 0.3813\n",
      "Epoch [44/50], Step [20/735], Loss: 0.6358\n",
      "Epoch [44/50], Step [21/735], Loss: 0.4642\n",
      "Epoch [44/50], Step [22/735], Loss: 0.1530\n",
      "Epoch [44/50], Step [23/735], Loss: 0.3795\n",
      "Epoch [44/50], Step [24/735], Loss: 0.3807\n",
      "Epoch [44/50], Step [25/735], Loss: 0.1177\n",
      "Epoch [44/50], Step [26/735], Loss: 0.3414\n",
      "Epoch [44/50], Step [27/735], Loss: 0.3265\n",
      "Epoch [44/50], Step [28/735], Loss: 0.0821\n",
      "Epoch [44/50], Step [29/735], Loss: 0.2730\n",
      "Epoch [44/50], Step [30/735], Loss: 0.3371\n",
      "Epoch [44/50], Step [31/735], Loss: 0.4693\n",
      "Epoch [44/50], Step [32/735], Loss: 0.0637\n",
      "Epoch [44/50], Step [33/735], Loss: 0.7463\n",
      "Epoch [44/50], Step [34/735], Loss: 0.2472\n",
      "Epoch [44/50], Step [35/735], Loss: 0.2791\n",
      "Epoch [44/50], Step [36/735], Loss: 0.4971\n",
      "Epoch [44/50], Step [37/735], Loss: 0.3243\n",
      "Epoch [44/50], Step [38/735], Loss: 0.9665\n",
      "Epoch [44/50], Step [39/735], Loss: 0.1510\n",
      "Epoch [44/50], Step [40/735], Loss: 0.4939\n",
      "Epoch [44/50], Step [41/735], Loss: 0.2129\n",
      "Epoch [44/50], Step [42/735], Loss: 0.2222\n",
      "Epoch [44/50], Step [43/735], Loss: 0.0811\n",
      "Epoch [44/50], Step [44/735], Loss: 0.3968\n",
      "Epoch [44/50], Step [45/735], Loss: 0.1814\n",
      "Epoch [44/50], Step [46/735], Loss: 0.1085\n",
      "Epoch [44/50], Step [47/735], Loss: 0.0846\n",
      "Epoch [44/50], Step [48/735], Loss: 0.2721\n",
      "Epoch [44/50], Step [49/735], Loss: 0.1833\n",
      "Epoch [44/50], Step [50/735], Loss: 0.3361\n",
      "Epoch [44/50], Step [51/735], Loss: 0.2162\n",
      "Epoch [44/50], Step [52/735], Loss: 0.0882\n",
      "Epoch [44/50], Step [53/735], Loss: 0.2485\n",
      "Epoch [44/50], Step [54/735], Loss: 0.1001\n",
      "Epoch [44/50], Step [55/735], Loss: 0.5268\n",
      "Epoch [44/50], Step [56/735], Loss: 0.1234\n",
      "Epoch [44/50], Step [57/735], Loss: 0.0732\n",
      "Epoch [44/50], Step [58/735], Loss: 0.3786\n",
      "Epoch [44/50], Step [59/735], Loss: 0.2205\n",
      "Epoch [44/50], Step [60/735], Loss: 0.1438\n",
      "Epoch [44/50], Step [61/735], Loss: 0.1087\n",
      "Epoch [44/50], Step [62/735], Loss: 0.0678\n",
      "Epoch [44/50], Step [63/735], Loss: 0.1981\n",
      "Epoch [44/50], Step [64/735], Loss: 0.4056\n",
      "Epoch [44/50], Step [65/735], Loss: 0.3995\n",
      "Epoch [44/50], Step [66/735], Loss: 0.1259\n",
      "Epoch [44/50], Step [67/735], Loss: 0.1531\n",
      "Epoch [44/50], Step [68/735], Loss: 0.1997\n",
      "Epoch [44/50], Step [69/735], Loss: 0.5341\n",
      "Epoch [44/50], Step [70/735], Loss: 0.1501\n",
      "Epoch [44/50], Step [71/735], Loss: 0.0667\n",
      "Epoch [44/50], Step [72/735], Loss: 0.2492\n",
      "Epoch [44/50], Step [73/735], Loss: 0.1346\n",
      "Epoch [44/50], Step [74/735], Loss: 0.0561\n",
      "Epoch [44/50], Step [75/735], Loss: 0.3423\n",
      "Epoch [44/50], Step [76/735], Loss: 0.0889\n",
      "Epoch [44/50], Step [77/735], Loss: 0.2283\n",
      "Epoch [44/50], Step [78/735], Loss: 0.1938\n",
      "Epoch [44/50], Step [79/735], Loss: 0.1043\n",
      "Epoch [44/50], Step [80/735], Loss: 0.3372\n",
      "Epoch [44/50], Step [81/735], Loss: 0.1719\n",
      "Epoch [44/50], Step [82/735], Loss: 0.2107\n",
      "Epoch [44/50], Step [83/735], Loss: 0.0555\n",
      "Epoch [44/50], Step [84/735], Loss: 0.5068\n",
      "Epoch [44/50], Step [85/735], Loss: 0.3005\n",
      "Epoch [44/50], Step [86/735], Loss: 0.1200\n",
      "Epoch [44/50], Step [87/735], Loss: 0.1959\n",
      "Epoch [44/50], Step [88/735], Loss: 0.3007\n",
      "Epoch [44/50], Step [89/735], Loss: 0.1338\n",
      "Epoch [44/50], Step [90/735], Loss: 0.0475\n",
      "Epoch [44/50], Step [91/735], Loss: 0.1157\n",
      "Epoch [44/50], Step [92/735], Loss: 0.1841\n",
      "Epoch [44/50], Step [93/735], Loss: 0.1621\n",
      "Epoch [44/50], Step [94/735], Loss: 0.0754\n",
      "Epoch [44/50], Step [95/735], Loss: 0.2025\n",
      "Epoch [44/50], Step [96/735], Loss: 0.2067\n",
      "Epoch [44/50], Step [97/735], Loss: 0.1633\n",
      "Epoch [44/50], Step [98/735], Loss: 0.5715\n",
      "Epoch [44/50], Step [99/735], Loss: 0.1476\n",
      "Epoch [44/50], Step [100/735], Loss: 0.1179\n",
      "Epoch [44/50], Step [101/735], Loss: 0.2819\n",
      "Epoch [44/50], Step [102/735], Loss: 0.1816\n",
      "Epoch [44/50], Step [103/735], Loss: 0.1893\n",
      "Epoch [44/50], Step [104/735], Loss: 0.3982\n",
      "Epoch [44/50], Step [105/735], Loss: 0.1141\n",
      "Epoch [44/50], Step [106/735], Loss: 0.2190\n",
      "Epoch [44/50], Step [107/735], Loss: 0.6298\n",
      "Epoch [44/50], Step [108/735], Loss: 0.1079\n",
      "Epoch [44/50], Step [109/735], Loss: 0.0736\n",
      "Epoch [44/50], Step [110/735], Loss: 0.4013\n",
      "Epoch [44/50], Step [111/735], Loss: 0.1218\n",
      "Epoch [44/50], Step [112/735], Loss: 0.2277\n",
      "Epoch [44/50], Step [113/735], Loss: 0.1501\n",
      "Epoch [44/50], Step [114/735], Loss: 0.2705\n",
      "Epoch [44/50], Step [115/735], Loss: 0.8029\n",
      "Epoch [44/50], Step [116/735], Loss: 0.3098\n",
      "Epoch [44/50], Step [117/735], Loss: 0.1384\n",
      "Epoch [44/50], Step [118/735], Loss: 0.3931\n",
      "Epoch [44/50], Step [119/735], Loss: 0.3565\n",
      "Epoch [44/50], Step [120/735], Loss: 0.1191\n",
      "Epoch [44/50], Step [121/735], Loss: 0.0433\n",
      "Epoch [44/50], Step [122/735], Loss: 0.1756\n",
      "Epoch [44/50], Step [123/735], Loss: 1.5093\n",
      "Epoch [44/50], Step [124/735], Loss: 0.9362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Step [125/735], Loss: 0.2854\n",
      "Epoch [44/50], Step [126/735], Loss: 0.3082\n",
      "Epoch [44/50], Step [127/735], Loss: 0.1342\n",
      "Epoch [44/50], Step [128/735], Loss: 0.4968\n",
      "Epoch [44/50], Step [129/735], Loss: 0.1535\n",
      "Epoch [44/50], Step [130/735], Loss: 0.1912\n",
      "Epoch [44/50], Step [131/735], Loss: 0.5334\n",
      "Epoch [44/50], Step [132/735], Loss: 0.4117\n",
      "Epoch [44/50], Step [133/735], Loss: 0.4919\n",
      "Epoch [44/50], Step [134/735], Loss: 0.0651\n",
      "Epoch [44/50], Step [135/735], Loss: 0.0704\n",
      "Epoch [44/50], Step [136/735], Loss: 0.3605\n",
      "Epoch [44/50], Step [137/735], Loss: 0.1747\n",
      "Epoch [44/50], Step [138/735], Loss: 0.2624\n",
      "Epoch [44/50], Step [139/735], Loss: 0.1292\n",
      "Epoch [44/50], Step [140/735], Loss: 0.1028\n",
      "Epoch [44/50], Step [141/735], Loss: 0.0761\n",
      "Epoch [44/50], Step [142/735], Loss: 0.3479\n",
      "Epoch [44/50], Step [143/735], Loss: 0.2930\n",
      "Epoch [44/50], Step [144/735], Loss: 0.2333\n",
      "Epoch [44/50], Step [145/735], Loss: 0.2870\n",
      "Epoch [44/50], Step [146/735], Loss: 0.2030\n",
      "Epoch [44/50], Step [147/735], Loss: 0.7778\n",
      "Epoch [44/50], Step [148/735], Loss: 0.3875\n",
      "Epoch [44/50], Step [149/735], Loss: 0.6491\n",
      "Epoch [44/50], Step [150/735], Loss: 0.0990\n",
      "Epoch [44/50], Step [151/735], Loss: 3.0941\n",
      "Epoch [44/50], Step [152/735], Loss: 0.3437\n",
      "Epoch [44/50], Step [153/735], Loss: 0.3872\n",
      "Epoch [44/50], Step [154/735], Loss: 0.2931\n",
      "Epoch [44/50], Step [155/735], Loss: 0.4505\n",
      "Epoch [44/50], Step [156/735], Loss: 0.3577\n",
      "Epoch [44/50], Step [157/735], Loss: 0.1175\n",
      "Epoch [44/50], Step [158/735], Loss: 0.5881\n",
      "Epoch [44/50], Step [159/735], Loss: 0.3984\n",
      "Epoch [44/50], Step [160/735], Loss: 0.5709\n",
      "Epoch [44/50], Step [161/735], Loss: 0.0629\n",
      "Epoch [44/50], Step [162/735], Loss: 0.7686\n",
      "Epoch [44/50], Step [163/735], Loss: 0.1660\n",
      "Epoch [44/50], Step [164/735], Loss: 0.5309\n",
      "Epoch [44/50], Step [165/735], Loss: 0.2170\n",
      "Epoch [44/50], Step [166/735], Loss: 0.3849\n",
      "Epoch [44/50], Step [167/735], Loss: 0.4019\n",
      "Epoch [44/50], Step [168/735], Loss: 0.1547\n",
      "Epoch [44/50], Step [169/735], Loss: 0.0606\n",
      "Epoch [44/50], Step [170/735], Loss: 0.1324\n",
      "Epoch [44/50], Step [171/735], Loss: 0.2560\n",
      "Epoch [44/50], Step [172/735], Loss: 0.2371\n",
      "Epoch [44/50], Step [173/735], Loss: 0.1269\n",
      "Epoch [44/50], Step [174/735], Loss: 0.8601\n",
      "Epoch [44/50], Step [175/735], Loss: 0.0998\n",
      "Epoch [44/50], Step [176/735], Loss: 0.1166\n",
      "Epoch [44/50], Step [177/735], Loss: 0.1629\n",
      "Epoch [44/50], Step [178/735], Loss: 0.1055\n",
      "Epoch [44/50], Step [179/735], Loss: 0.0746\n",
      "Epoch [44/50], Step [180/735], Loss: 0.1358\n",
      "Epoch [44/50], Step [181/735], Loss: 0.0630\n",
      "Epoch [44/50], Step [182/735], Loss: 0.2228\n",
      "Epoch [44/50], Step [183/735], Loss: 0.3493\n",
      "Epoch [44/50], Step [184/735], Loss: 0.1083\n",
      "Epoch [44/50], Step [185/735], Loss: 0.2550\n",
      "Epoch [44/50], Step [186/735], Loss: 0.2619\n",
      "Epoch [44/50], Step [187/735], Loss: 0.6700\n",
      "Epoch [44/50], Step [188/735], Loss: 0.1764\n",
      "Epoch [44/50], Step [189/735], Loss: 0.1484\n",
      "Epoch [44/50], Step [190/735], Loss: 3.1418\n",
      "Epoch [44/50], Step [191/735], Loss: 0.4389\n",
      "Epoch [44/50], Step [192/735], Loss: 1.2625\n",
      "Epoch [44/50], Step [193/735], Loss: 0.1502\n",
      "Epoch [44/50], Step [194/735], Loss: 0.0821\n",
      "Epoch [44/50], Step [195/735], Loss: 0.1809\n",
      "Epoch [44/50], Step [196/735], Loss: 0.0686\n",
      "Epoch [44/50], Step [197/735], Loss: 0.3568\n",
      "Epoch [44/50], Step [198/735], Loss: 0.0484\n",
      "Epoch [44/50], Step [199/735], Loss: 0.1025\n",
      "Epoch [44/50], Step [200/735], Loss: 0.8884\n",
      "Epoch [44/50], Step [201/735], Loss: 0.3792\n",
      "Epoch [44/50], Step [202/735], Loss: 0.2078\n",
      "Epoch [44/50], Step [203/735], Loss: 0.1294\n",
      "Epoch [44/50], Step [204/735], Loss: 0.1175\n",
      "Epoch [44/50], Step [205/735], Loss: 0.2160\n",
      "Epoch [44/50], Step [206/735], Loss: 0.5666\n",
      "Epoch [44/50], Step [207/735], Loss: 0.1171\n",
      "Epoch [44/50], Step [208/735], Loss: 0.2215\n",
      "Epoch [44/50], Step [209/735], Loss: 0.1133\n",
      "Epoch [44/50], Step [210/735], Loss: 0.1929\n",
      "Epoch [44/50], Step [211/735], Loss: 0.2839\n",
      "Epoch [44/50], Step [212/735], Loss: 0.4529\n",
      "Epoch [44/50], Step [213/735], Loss: 0.1201\n",
      "Epoch [44/50], Step [214/735], Loss: 0.1315\n",
      "Epoch [44/50], Step [215/735], Loss: 0.1081\n",
      "Epoch [44/50], Step [216/735], Loss: 0.2556\n",
      "Epoch [44/50], Step [217/735], Loss: 0.1648\n",
      "Epoch [44/50], Step [218/735], Loss: 0.4989\n",
      "Epoch [44/50], Step [219/735], Loss: 0.1146\n",
      "Epoch [44/50], Step [220/735], Loss: 0.1656\n",
      "Epoch [44/50], Step [221/735], Loss: 0.4023\n",
      "Epoch [44/50], Step [222/735], Loss: 0.6263\n",
      "Epoch [44/50], Step [223/735], Loss: 0.1015\n",
      "Epoch [44/50], Step [224/735], Loss: 0.1833\n",
      "Epoch [44/50], Step [225/735], Loss: 0.2508\n",
      "Epoch [44/50], Step [226/735], Loss: 0.1093\n",
      "Epoch [44/50], Step [227/735], Loss: 0.1880\n",
      "Epoch [44/50], Step [228/735], Loss: 0.2892\n",
      "Epoch [44/50], Step [229/735], Loss: 0.1165\n",
      "Epoch [44/50], Step [230/735], Loss: 0.1015\n",
      "Epoch [44/50], Step [231/735], Loss: 0.0543\n",
      "Epoch [44/50], Step [232/735], Loss: 0.3776\n",
      "Epoch [44/50], Step [233/735], Loss: 0.1603\n",
      "Epoch [44/50], Step [234/735], Loss: 0.1441\n",
      "Epoch [44/50], Step [235/735], Loss: 0.0527\n",
      "Epoch [44/50], Step [236/735], Loss: 0.1407\n",
      "Epoch [44/50], Step [237/735], Loss: 0.2343\n",
      "Epoch [44/50], Step [238/735], Loss: 0.6677\n",
      "Epoch [44/50], Step [239/735], Loss: 0.3546\n",
      "Epoch [44/50], Step [240/735], Loss: 0.2116\n",
      "Epoch [44/50], Step [241/735], Loss: 0.1593\n",
      "Epoch [44/50], Step [242/735], Loss: 0.2299\n",
      "Epoch [44/50], Step [243/735], Loss: 0.1799\n",
      "Epoch [44/50], Step [244/735], Loss: 0.1665\n",
      "Epoch [44/50], Step [245/735], Loss: 0.2077\n",
      "Epoch [44/50], Step [246/735], Loss: 0.1531\n",
      "Epoch [44/50], Step [247/735], Loss: 0.3382\n",
      "Epoch [44/50], Step [248/735], Loss: 0.4265\n",
      "Epoch [44/50], Step [249/735], Loss: 0.3107\n",
      "Epoch [44/50], Step [250/735], Loss: 0.1013\n",
      "Epoch [44/50], Step [251/735], Loss: 0.0861\n",
      "Epoch [44/50], Step [252/735], Loss: 0.2812\n",
      "Epoch [44/50], Step [253/735], Loss: 0.1190\n",
      "Epoch [44/50], Step [254/735], Loss: 0.3394\n",
      "Epoch [44/50], Step [255/735], Loss: 0.6222\n",
      "Epoch [44/50], Step [256/735], Loss: 0.4272\n",
      "Epoch [44/50], Step [257/735], Loss: 0.2449\n",
      "Epoch [44/50], Step [258/735], Loss: 0.6474\n",
      "Epoch [44/50], Step [259/735], Loss: 0.3666\n",
      "Epoch [44/50], Step [260/735], Loss: 0.1900\n",
      "Epoch [44/50], Step [261/735], Loss: 0.0968\n",
      "Epoch [44/50], Step [262/735], Loss: 0.0995\n",
      "Epoch [44/50], Step [263/735], Loss: 0.2106\n",
      "Epoch [44/50], Step [264/735], Loss: 0.7923\n",
      "Epoch [44/50], Step [265/735], Loss: 0.3752\n",
      "Epoch [44/50], Step [266/735], Loss: 0.1393\n",
      "Epoch [44/50], Step [267/735], Loss: 0.6918\n",
      "Epoch [44/50], Step [268/735], Loss: 2.5465\n",
      "Epoch [44/50], Step [269/735], Loss: 0.1075\n",
      "Epoch [44/50], Step [270/735], Loss: 0.2477\n",
      "Epoch [44/50], Step [271/735], Loss: 0.5669\n",
      "Epoch [44/50], Step [272/735], Loss: 0.0697\n",
      "Epoch [44/50], Step [273/735], Loss: 0.0399\n",
      "Epoch [44/50], Step [274/735], Loss: 0.1066\n",
      "Epoch [44/50], Step [275/735], Loss: 0.4199\n",
      "Epoch [44/50], Step [276/735], Loss: 0.2924\n",
      "Epoch [44/50], Step [277/735], Loss: 0.2672\n",
      "Epoch [44/50], Step [278/735], Loss: 0.1327\n",
      "Epoch [44/50], Step [279/735], Loss: 0.1848\n",
      "Epoch [44/50], Step [280/735], Loss: 0.2649\n",
      "Epoch [44/50], Step [281/735], Loss: 0.2470\n",
      "Epoch [44/50], Step [282/735], Loss: 0.4770\n",
      "Epoch [44/50], Step [283/735], Loss: 0.0912\n",
      "Epoch [44/50], Step [284/735], Loss: 0.1513\n",
      "Epoch [44/50], Step [285/735], Loss: 0.3085\n",
      "Epoch [44/50], Step [286/735], Loss: 0.1215\n",
      "Epoch [44/50], Step [287/735], Loss: 0.2887\n",
      "Epoch [44/50], Step [288/735], Loss: 0.3681\n",
      "Epoch [44/50], Step [289/735], Loss: 0.2571\n",
      "Epoch [44/50], Step [290/735], Loss: 0.0885\n",
      "Epoch [44/50], Step [291/735], Loss: 0.1387\n",
      "Epoch [44/50], Step [292/735], Loss: 0.4458\n",
      "Epoch [44/50], Step [293/735], Loss: 0.1648\n",
      "Epoch [44/50], Step [294/735], Loss: 0.2456\n",
      "Epoch [44/50], Step [295/735], Loss: 0.1664\n",
      "Epoch [44/50], Step [296/735], Loss: 0.3917\n",
      "Epoch [44/50], Step [297/735], Loss: 0.1380\n",
      "Epoch [44/50], Step [298/735], Loss: 0.1596\n",
      "Epoch [44/50], Step [299/735], Loss: 0.2547\n",
      "Epoch [44/50], Step [300/735], Loss: 0.1696\n",
      "Epoch [44/50], Step [301/735], Loss: 0.1598\n",
      "Epoch [44/50], Step [302/735], Loss: 0.0539\n",
      "Epoch [44/50], Step [303/735], Loss: 0.1790\n",
      "Epoch [44/50], Step [304/735], Loss: 0.3718\n",
      "Epoch [44/50], Step [305/735], Loss: 0.0227\n",
      "Epoch [44/50], Step [306/735], Loss: 0.3403\n",
      "Epoch [44/50], Step [307/735], Loss: 0.3394\n",
      "Epoch [44/50], Step [308/735], Loss: 0.1836\n",
      "Epoch [44/50], Step [309/735], Loss: 0.1404\n",
      "Epoch [44/50], Step [310/735], Loss: 0.2375\n",
      "Epoch [44/50], Step [311/735], Loss: 0.2941\n",
      "Epoch [44/50], Step [312/735], Loss: 0.1347\n",
      "Epoch [44/50], Step [313/735], Loss: 0.3442\n",
      "Epoch [44/50], Step [314/735], Loss: 0.2527\n",
      "Epoch [44/50], Step [315/735], Loss: 0.4449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Step [316/735], Loss: 0.2664\n",
      "Epoch [44/50], Step [317/735], Loss: 0.1879\n",
      "Epoch [44/50], Step [318/735], Loss: 0.7999\n",
      "Epoch [44/50], Step [319/735], Loss: 0.1518\n",
      "Epoch [44/50], Step [320/735], Loss: 0.2220\n",
      "Epoch [44/50], Step [321/735], Loss: 0.4017\n",
      "Epoch [44/50], Step [322/735], Loss: 0.5098\n",
      "Epoch [44/50], Step [323/735], Loss: 0.1255\n",
      "Epoch [44/50], Step [324/735], Loss: 0.1894\n",
      "Epoch [44/50], Step [325/735], Loss: 0.4967\n",
      "Epoch [44/50], Step [326/735], Loss: 0.3604\n",
      "Epoch [44/50], Step [327/735], Loss: 0.3608\n",
      "Epoch [44/50], Step [328/735], Loss: 0.1338\n",
      "Epoch [44/50], Step [329/735], Loss: 0.3254\n",
      "Epoch [44/50], Step [330/735], Loss: 0.2117\n",
      "Epoch [44/50], Step [331/735], Loss: 0.1249\n",
      "Epoch [44/50], Step [332/735], Loss: 0.4581\n",
      "Epoch [44/50], Step [333/735], Loss: 0.1200\n",
      "Epoch [44/50], Step [334/735], Loss: 0.4153\n",
      "Epoch [44/50], Step [335/735], Loss: 0.5517\n",
      "Epoch [44/50], Step [336/735], Loss: 0.2747\n",
      "Epoch [44/50], Step [337/735], Loss: 0.8868\n",
      "Epoch [44/50], Step [338/735], Loss: 0.1535\n",
      "Epoch [44/50], Step [339/735], Loss: 0.1821\n",
      "Epoch [44/50], Step [340/735], Loss: 0.1066\n",
      "Epoch [44/50], Step [341/735], Loss: 1.1902\n",
      "Epoch [44/50], Step [342/735], Loss: 0.5573\n",
      "Epoch [44/50], Step [343/735], Loss: 0.1930\n",
      "Epoch [44/50], Step [344/735], Loss: 0.2289\n",
      "Epoch [44/50], Step [345/735], Loss: 0.4165\n",
      "Epoch [44/50], Step [346/735], Loss: 0.2518\n",
      "Epoch [44/50], Step [347/735], Loss: 0.1767\n",
      "Epoch [44/50], Step [348/735], Loss: 0.3087\n",
      "Epoch [44/50], Step [349/735], Loss: 0.7665\n",
      "Epoch [44/50], Step [350/735], Loss: 0.1546\n",
      "Epoch [44/50], Step [351/735], Loss: 0.7186\n",
      "Epoch [44/50], Step [352/735], Loss: 0.1844\n",
      "Epoch [44/50], Step [353/735], Loss: 0.2690\n",
      "Epoch [44/50], Step [354/735], Loss: 0.2569\n",
      "Epoch [44/50], Step [355/735], Loss: 0.1079\n",
      "Epoch [44/50], Step [356/735], Loss: 0.1588\n",
      "Epoch [44/50], Step [357/735], Loss: 0.2518\n",
      "Epoch [44/50], Step [358/735], Loss: 0.2733\n",
      "Epoch [44/50], Step [359/735], Loss: 0.2076\n",
      "Epoch [44/50], Step [360/735], Loss: 0.2321\n",
      "Epoch [44/50], Step [361/735], Loss: 0.2459\n",
      "Epoch [44/50], Step [362/735], Loss: 0.1279\n",
      "Epoch [44/50], Step [363/735], Loss: 0.3461\n",
      "Epoch [44/50], Step [364/735], Loss: 0.3500\n",
      "Epoch [44/50], Step [365/735], Loss: 0.1940\n",
      "Epoch [44/50], Step [366/735], Loss: 0.2100\n",
      "Epoch [44/50], Step [367/735], Loss: 0.4612\n",
      "Epoch [44/50], Step [368/735], Loss: 0.2483\n",
      "Epoch [44/50], Step [369/735], Loss: 0.2892\n",
      "Epoch [44/50], Step [370/735], Loss: 0.2097\n",
      "Epoch [44/50], Step [371/735], Loss: 0.1317\n",
      "Epoch [44/50], Step [372/735], Loss: 0.0805\n",
      "Epoch [44/50], Step [373/735], Loss: 0.4055\n",
      "Epoch [44/50], Step [374/735], Loss: 0.2430\n",
      "Epoch [44/50], Step [375/735], Loss: 0.2357\n",
      "Epoch [44/50], Step [376/735], Loss: 0.5017\n",
      "Epoch [44/50], Step [377/735], Loss: 0.3058\n",
      "Epoch [44/50], Step [378/735], Loss: 0.3401\n",
      "Epoch [44/50], Step [379/735], Loss: 0.4968\n",
      "Epoch [44/50], Step [380/735], Loss: 0.0653\n",
      "Epoch [44/50], Step [381/735], Loss: 0.2287\n",
      "Epoch [44/50], Step [382/735], Loss: 0.1328\n",
      "Epoch [44/50], Step [383/735], Loss: 0.2249\n",
      "Epoch [44/50], Step [384/735], Loss: 0.2033\n",
      "Epoch [44/50], Step [385/735], Loss: 0.1200\n",
      "Epoch [44/50], Step [386/735], Loss: 0.2250\n",
      "Epoch [44/50], Step [387/735], Loss: 0.2076\n",
      "Epoch [44/50], Step [388/735], Loss: 0.1457\n",
      "Epoch [44/50], Step [389/735], Loss: 0.2286\n",
      "Epoch [44/50], Step [390/735], Loss: 0.4371\n",
      "Epoch [44/50], Step [391/735], Loss: 0.2185\n",
      "Epoch [44/50], Step [392/735], Loss: 0.5844\n",
      "Epoch [44/50], Step [393/735], Loss: 0.1553\n",
      "Epoch [44/50], Step [394/735], Loss: 0.1541\n",
      "Epoch [44/50], Step [395/735], Loss: 0.1743\n",
      "Epoch [44/50], Step [396/735], Loss: 0.0760\n",
      "Epoch [44/50], Step [397/735], Loss: 0.1345\n",
      "Epoch [44/50], Step [398/735], Loss: 0.2783\n",
      "Epoch [44/50], Step [399/735], Loss: 0.1003\n",
      "Epoch [44/50], Step [400/735], Loss: 0.1587\n",
      "Epoch [44/50], Step [401/735], Loss: 0.4808\n",
      "Epoch [44/50], Step [402/735], Loss: 0.5603\n",
      "Epoch [44/50], Step [403/735], Loss: 0.1477\n",
      "Epoch [44/50], Step [404/735], Loss: 0.1062\n",
      "Epoch [44/50], Step [405/735], Loss: 0.1947\n",
      "Epoch [44/50], Step [406/735], Loss: 0.0919\n",
      "Epoch [44/50], Step [407/735], Loss: 0.2831\n",
      "Epoch [44/50], Step [408/735], Loss: 0.3755\n",
      "Epoch [44/50], Step [409/735], Loss: 0.2108\n",
      "Epoch [44/50], Step [410/735], Loss: 1.3330\n",
      "Epoch [44/50], Step [411/735], Loss: 0.1185\n",
      "Epoch [44/50], Step [412/735], Loss: 0.1135\n",
      "Epoch [44/50], Step [413/735], Loss: 0.2512\n",
      "Epoch [44/50], Step [414/735], Loss: 0.1897\n",
      "Epoch [44/50], Step [415/735], Loss: 0.1177\n",
      "Epoch [44/50], Step [416/735], Loss: 0.0895\n",
      "Epoch [44/50], Step [417/735], Loss: 0.5130\n",
      "Epoch [44/50], Step [418/735], Loss: 0.1324\n",
      "Epoch [44/50], Step [419/735], Loss: 0.1521\n",
      "Epoch [44/50], Step [420/735], Loss: 0.1488\n",
      "Epoch [44/50], Step [421/735], Loss: 0.2534\n",
      "Epoch [44/50], Step [422/735], Loss: 0.0783\n",
      "Epoch [44/50], Step [423/735], Loss: 0.5747\n",
      "Epoch [44/50], Step [424/735], Loss: 0.1814\n",
      "Epoch [44/50], Step [425/735], Loss: 0.1060\n",
      "Epoch [44/50], Step [426/735], Loss: 0.4430\n",
      "Epoch [44/50], Step [427/735], Loss: 0.2475\n",
      "Epoch [44/50], Step [428/735], Loss: 0.0971\n",
      "Epoch [44/50], Step [429/735], Loss: 0.2327\n",
      "Epoch [44/50], Step [430/735], Loss: 0.7046\n",
      "Epoch [44/50], Step [431/735], Loss: 0.3030\n",
      "Epoch [44/50], Step [432/735], Loss: 0.2269\n",
      "Epoch [44/50], Step [433/735], Loss: 0.1396\n",
      "Epoch [44/50], Step [434/735], Loss: 0.0991\n",
      "Epoch [44/50], Step [435/735], Loss: 0.1918\n",
      "Epoch [44/50], Step [436/735], Loss: 0.1701\n",
      "Epoch [44/50], Step [437/735], Loss: 0.1011\n",
      "Epoch [44/50], Step [438/735], Loss: 0.1161\n",
      "Epoch [44/50], Step [439/735], Loss: 0.1744\n",
      "Epoch [44/50], Step [440/735], Loss: 0.1770\n",
      "Epoch [44/50], Step [441/735], Loss: 0.3745\n",
      "Epoch [44/50], Step [442/735], Loss: 0.1382\n",
      "Epoch [44/50], Step [443/735], Loss: 0.3137\n",
      "Epoch [44/50], Step [444/735], Loss: 0.4037\n",
      "Epoch [44/50], Step [445/735], Loss: 0.1690\n",
      "Epoch [44/50], Step [446/735], Loss: 0.1677\n",
      "Epoch [44/50], Step [447/735], Loss: 0.2183\n",
      "Epoch [44/50], Step [448/735], Loss: 0.1528\n",
      "Epoch [44/50], Step [449/735], Loss: 0.4236\n",
      "Epoch [44/50], Step [450/735], Loss: 0.2476\n",
      "Epoch [44/50], Step [451/735], Loss: 0.4732\n",
      "Epoch [44/50], Step [452/735], Loss: 0.1942\n",
      "Epoch [44/50], Step [453/735], Loss: 0.1124\n",
      "Epoch [44/50], Step [454/735], Loss: 0.2354\n",
      "Epoch [44/50], Step [455/735], Loss: 0.1019\n",
      "Epoch [44/50], Step [456/735], Loss: 0.0852\n",
      "Epoch [44/50], Step [457/735], Loss: 0.1510\n",
      "Epoch [44/50], Step [458/735], Loss: 0.2024\n",
      "Epoch [44/50], Step [459/735], Loss: 0.2943\n",
      "Epoch [44/50], Step [460/735], Loss: 0.3307\n",
      "Epoch [44/50], Step [461/735], Loss: 0.1502\n",
      "Epoch [44/50], Step [462/735], Loss: 0.5130\n",
      "Epoch [44/50], Step [463/735], Loss: 0.1757\n",
      "Epoch [44/50], Step [464/735], Loss: 0.1987\n",
      "Epoch [44/50], Step [465/735], Loss: 0.1789\n",
      "Epoch [44/50], Step [466/735], Loss: 0.1553\n",
      "Epoch [44/50], Step [467/735], Loss: 0.0928\n",
      "Epoch [44/50], Step [468/735], Loss: 0.1387\n",
      "Epoch [44/50], Step [469/735], Loss: 0.4066\n",
      "Epoch [44/50], Step [470/735], Loss: 0.3283\n",
      "Epoch [44/50], Step [471/735], Loss: 0.0955\n",
      "Epoch [44/50], Step [472/735], Loss: 0.1214\n",
      "Epoch [44/50], Step [473/735], Loss: 0.0512\n",
      "Epoch [44/50], Step [474/735], Loss: 0.1946\n",
      "Epoch [44/50], Step [475/735], Loss: 0.2344\n",
      "Epoch [44/50], Step [476/735], Loss: 0.1138\n",
      "Epoch [44/50], Step [477/735], Loss: 0.0746\n",
      "Epoch [44/50], Step [478/735], Loss: 0.2292\n",
      "Epoch [44/50], Step [479/735], Loss: 0.0988\n",
      "Epoch [44/50], Step [480/735], Loss: 0.3078\n",
      "Epoch [44/50], Step [481/735], Loss: 0.6750\n",
      "Epoch [44/50], Step [482/735], Loss: 0.2099\n",
      "Epoch [44/50], Step [483/735], Loss: 0.1609\n",
      "Epoch [44/50], Step [484/735], Loss: 0.1799\n",
      "Epoch [44/50], Step [485/735], Loss: 0.4780\n",
      "Epoch [44/50], Step [486/735], Loss: 0.1181\n",
      "Epoch [44/50], Step [487/735], Loss: 0.2259\n",
      "Epoch [44/50], Step [488/735], Loss: 0.1105\n",
      "Epoch [44/50], Step [489/735], Loss: 0.1776\n",
      "Epoch [44/50], Step [490/735], Loss: 0.1882\n",
      "Epoch [44/50], Step [491/735], Loss: 0.2152\n",
      "Epoch [44/50], Step [492/735], Loss: 0.3772\n",
      "Epoch [44/50], Step [493/735], Loss: 0.2213\n",
      "Epoch [44/50], Step [494/735], Loss: 0.1508\n",
      "Epoch [44/50], Step [495/735], Loss: 0.0738\n",
      "Epoch [44/50], Step [496/735], Loss: 0.3183\n",
      "Epoch [44/50], Step [497/735], Loss: 0.4135\n",
      "Epoch [44/50], Step [498/735], Loss: 0.0496\n",
      "Epoch [44/50], Step [499/735], Loss: 0.9715\n",
      "Epoch [44/50], Step [500/735], Loss: 0.2194\n",
      "Epoch [44/50], Step [501/735], Loss: 0.7543\n",
      "Epoch [44/50], Step [502/735], Loss: 0.4024\n",
      "Epoch [44/50], Step [503/735], Loss: 0.1480\n",
      "Epoch [44/50], Step [504/735], Loss: 0.5048\n",
      "Epoch [44/50], Step [505/735], Loss: 0.9079\n",
      "Epoch [44/50], Step [506/735], Loss: 0.3650\n",
      "Epoch [44/50], Step [507/735], Loss: 0.1295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Step [508/735], Loss: 0.2442\n",
      "Epoch [44/50], Step [509/735], Loss: 0.1271\n",
      "Epoch [44/50], Step [510/735], Loss: 0.3332\n",
      "Epoch [44/50], Step [511/735], Loss: 0.3313\n",
      "Epoch [44/50], Step [512/735], Loss: 0.3430\n",
      "Epoch [44/50], Step [513/735], Loss: 0.4697\n",
      "Epoch [44/50], Step [514/735], Loss: 0.2553\n",
      "Epoch [44/50], Step [515/735], Loss: 0.2531\n",
      "Epoch [44/50], Step [516/735], Loss: 0.3448\n",
      "Epoch [44/50], Step [517/735], Loss: 0.2774\n",
      "Epoch [44/50], Step [518/735], Loss: 0.3805\n",
      "Epoch [44/50], Step [519/735], Loss: 0.1885\n",
      "Epoch [44/50], Step [520/735], Loss: 0.2918\n",
      "Epoch [44/50], Step [521/735], Loss: 0.2168\n",
      "Epoch [44/50], Step [522/735], Loss: 0.2039\n",
      "Epoch [44/50], Step [523/735], Loss: 0.1123\n",
      "Epoch [44/50], Step [524/735], Loss: 0.2026\n",
      "Epoch [44/50], Step [525/735], Loss: 0.4308\n",
      "Epoch [44/50], Step [526/735], Loss: 0.3110\n",
      "Epoch [44/50], Step [527/735], Loss: 0.2098\n",
      "Epoch [44/50], Step [528/735], Loss: 0.2895\n",
      "Epoch [44/50], Step [529/735], Loss: 0.1356\n",
      "Epoch [44/50], Step [530/735], Loss: 0.4936\n",
      "Epoch [44/50], Step [531/735], Loss: 0.2908\n",
      "Epoch [44/50], Step [532/735], Loss: 0.5112\n",
      "Epoch [44/50], Step [533/735], Loss: 0.1276\n",
      "Epoch [44/50], Step [534/735], Loss: 0.2908\n",
      "Epoch [44/50], Step [535/735], Loss: 0.1740\n",
      "Epoch [44/50], Step [536/735], Loss: 0.0844\n",
      "Epoch [44/50], Step [537/735], Loss: 0.1856\n",
      "Epoch [44/50], Step [538/735], Loss: 0.1743\n",
      "Epoch [44/50], Step [539/735], Loss: 0.6577\n",
      "Epoch [44/50], Step [540/735], Loss: 0.3632\n",
      "Epoch [44/50], Step [541/735], Loss: 0.2365\n",
      "Epoch [44/50], Step [542/735], Loss: 0.8806\n",
      "Epoch [44/50], Step [543/735], Loss: 0.3428\n",
      "Epoch [44/50], Step [544/735], Loss: 0.2132\n",
      "Epoch [44/50], Step [545/735], Loss: 0.1945\n",
      "Epoch [44/50], Step [546/735], Loss: 0.1317\n",
      "Epoch [44/50], Step [547/735], Loss: 0.1399\n",
      "Epoch [44/50], Step [548/735], Loss: 0.3317\n",
      "Epoch [44/50], Step [549/735], Loss: 0.3995\n",
      "Epoch [44/50], Step [550/735], Loss: 0.2743\n",
      "Epoch [44/50], Step [551/735], Loss: 0.5807\n",
      "Epoch [44/50], Step [552/735], Loss: 3.3248\n",
      "Epoch [44/50], Step [553/735], Loss: 0.2245\n",
      "Epoch [44/50], Step [554/735], Loss: 0.1680\n",
      "Epoch [44/50], Step [555/735], Loss: 0.2644\n",
      "Epoch [44/50], Step [556/735], Loss: 0.4270\n",
      "Epoch [44/50], Step [557/735], Loss: 0.2821\n",
      "Epoch [44/50], Step [558/735], Loss: 0.2481\n",
      "Epoch [44/50], Step [559/735], Loss: 0.1752\n",
      "Epoch [44/50], Step [560/735], Loss: 0.1195\n",
      "Epoch [44/50], Step [561/735], Loss: 0.2445\n",
      "Epoch [44/50], Step [562/735], Loss: 0.0892\n",
      "Epoch [44/50], Step [563/735], Loss: 0.2073\n",
      "Epoch [44/50], Step [564/735], Loss: 0.3591\n",
      "Epoch [44/50], Step [565/735], Loss: 0.2092\n",
      "Epoch [44/50], Step [566/735], Loss: 0.1238\n",
      "Epoch [44/50], Step [567/735], Loss: 0.1650\n",
      "Epoch [44/50], Step [568/735], Loss: 0.3138\n",
      "Epoch [44/50], Step [569/735], Loss: 0.0979\n",
      "Epoch [44/50], Step [570/735], Loss: 0.2384\n",
      "Epoch [44/50], Step [571/735], Loss: 0.1215\n",
      "Epoch [44/50], Step [572/735], Loss: 0.1209\n",
      "Epoch [44/50], Step [573/735], Loss: 0.1398\n",
      "Epoch [44/50], Step [574/735], Loss: 0.1445\n",
      "Epoch [44/50], Step [575/735], Loss: 0.2720\n",
      "Epoch [44/50], Step [576/735], Loss: 0.3306\n",
      "Epoch [44/50], Step [577/735], Loss: 0.2306\n",
      "Epoch [44/50], Step [578/735], Loss: 0.6294\n",
      "Epoch [44/50], Step [579/735], Loss: 0.0367\n",
      "Epoch [44/50], Step [580/735], Loss: 0.3809\n",
      "Epoch [44/50], Step [581/735], Loss: 0.4753\n",
      "Epoch [44/50], Step [582/735], Loss: 0.1578\n",
      "Epoch [44/50], Step [583/735], Loss: 0.0963\n",
      "Epoch [44/50], Step [584/735], Loss: 0.3833\n",
      "Epoch [44/50], Step [585/735], Loss: 0.2055\n",
      "Epoch [44/50], Step [586/735], Loss: 0.1252\n",
      "Epoch [44/50], Step [587/735], Loss: 0.1768\n",
      "Epoch [44/50], Step [588/735], Loss: 0.1167\n",
      "Epoch [44/50], Step [589/735], Loss: 0.1246\n",
      "Epoch [44/50], Step [590/735], Loss: 0.1610\n",
      "Epoch [44/50], Step [591/735], Loss: 0.1313\n",
      "Epoch [44/50], Step [592/735], Loss: 0.2531\n",
      "Epoch [44/50], Step [593/735], Loss: 0.3927\n",
      "Epoch [44/50], Step [594/735], Loss: 0.1761\n",
      "Epoch [44/50], Step [595/735], Loss: 0.4319\n",
      "Epoch [44/50], Step [596/735], Loss: 0.6965\n",
      "Epoch [44/50], Step [597/735], Loss: 0.2703\n",
      "Epoch [44/50], Step [598/735], Loss: 0.3308\n",
      "Epoch [44/50], Step [599/735], Loss: 0.1084\n",
      "Epoch [44/50], Step [600/735], Loss: 0.0916\n",
      "Epoch [44/50], Step [601/735], Loss: 0.2477\n",
      "Epoch [44/50], Step [602/735], Loss: 0.1289\n",
      "Epoch [44/50], Step [603/735], Loss: 0.2314\n",
      "Epoch [44/50], Step [604/735], Loss: 0.2026\n",
      "Epoch [44/50], Step [605/735], Loss: 1.0369\n",
      "Epoch [44/50], Step [606/735], Loss: 0.4705\n",
      "Epoch [44/50], Step [607/735], Loss: 0.0950\n",
      "Epoch [44/50], Step [608/735], Loss: 0.2593\n",
      "Epoch [44/50], Step [609/735], Loss: 0.7006\n",
      "Epoch [44/50], Step [610/735], Loss: 0.4382\n",
      "Epoch [44/50], Step [611/735], Loss: 0.6599\n",
      "Epoch [44/50], Step [612/735], Loss: 0.2895\n",
      "Epoch [44/50], Step [613/735], Loss: 0.2705\n",
      "Epoch [44/50], Step [614/735], Loss: 0.3415\n",
      "Epoch [44/50], Step [615/735], Loss: 0.2367\n",
      "Epoch [44/50], Step [616/735], Loss: 0.2206\n",
      "Epoch [44/50], Step [617/735], Loss: 0.3585\n",
      "Epoch [44/50], Step [618/735], Loss: 0.3564\n",
      "Epoch [44/50], Step [619/735], Loss: 0.3039\n",
      "Epoch [44/50], Step [620/735], Loss: 0.1955\n",
      "Epoch [44/50], Step [621/735], Loss: 0.2025\n",
      "Epoch [44/50], Step [622/735], Loss: 0.1138\n",
      "Epoch [44/50], Step [623/735], Loss: 0.2376\n",
      "Epoch [44/50], Step [624/735], Loss: 0.1111\n",
      "Epoch [44/50], Step [625/735], Loss: 0.0967\n",
      "Epoch [44/50], Step [626/735], Loss: 0.0807\n",
      "Epoch [44/50], Step [627/735], Loss: 0.5359\n",
      "Epoch [44/50], Step [628/735], Loss: 0.3142\n",
      "Epoch [44/50], Step [629/735], Loss: 0.2680\n",
      "Epoch [44/50], Step [630/735], Loss: 0.1948\n",
      "Epoch [44/50], Step [631/735], Loss: 0.4443\n",
      "Epoch [44/50], Step [632/735], Loss: 0.8203\n",
      "Epoch [44/50], Step [633/735], Loss: 0.1215\n",
      "Epoch [44/50], Step [634/735], Loss: 0.2984\n",
      "Epoch [44/50], Step [635/735], Loss: 0.1645\n",
      "Epoch [44/50], Step [636/735], Loss: 0.2997\n",
      "Epoch [44/50], Step [637/735], Loss: 0.2422\n",
      "Epoch [44/50], Step [638/735], Loss: 0.1042\n",
      "Epoch [44/50], Step [639/735], Loss: 0.3697\n",
      "Epoch [44/50], Step [640/735], Loss: 0.4308\n",
      "Epoch [44/50], Step [641/735], Loss: 0.2490\n",
      "Epoch [44/50], Step [642/735], Loss: 0.2925\n",
      "Epoch [44/50], Step [643/735], Loss: 0.0954\n",
      "Epoch [44/50], Step [644/735], Loss: 1.1059\n",
      "Epoch [44/50], Step [645/735], Loss: 0.1470\n",
      "Epoch [44/50], Step [646/735], Loss: 0.2785\n",
      "Epoch [44/50], Step [647/735], Loss: 0.2286\n",
      "Epoch [44/50], Step [648/735], Loss: 0.2567\n",
      "Epoch [44/50], Step [649/735], Loss: 0.2160\n",
      "Epoch [44/50], Step [650/735], Loss: 0.1240\n",
      "Epoch [44/50], Step [651/735], Loss: 0.6588\n",
      "Epoch [44/50], Step [652/735], Loss: 0.0725\n",
      "Epoch [44/50], Step [653/735], Loss: 0.1227\n",
      "Epoch [44/50], Step [654/735], Loss: 0.0628\n",
      "Epoch [44/50], Step [655/735], Loss: 0.2038\n",
      "Epoch [44/50], Step [656/735], Loss: 0.0423\n",
      "Epoch [44/50], Step [657/735], Loss: 0.1443\n",
      "Epoch [44/50], Step [658/735], Loss: 0.3092\n",
      "Epoch [44/50], Step [659/735], Loss: 0.0458\n",
      "Epoch [44/50], Step [660/735], Loss: 0.2515\n",
      "Epoch [44/50], Step [661/735], Loss: 0.2406\n",
      "Epoch [44/50], Step [662/735], Loss: 0.8866\n",
      "Epoch [44/50], Step [663/735], Loss: 0.2040\n",
      "Epoch [44/50], Step [664/735], Loss: 0.6243\n",
      "Epoch [44/50], Step [665/735], Loss: 0.4415\n",
      "Epoch [44/50], Step [666/735], Loss: 0.2030\n",
      "Epoch [44/50], Step [667/735], Loss: 2.3242\n",
      "Epoch [44/50], Step [668/735], Loss: 0.2403\n",
      "Epoch [44/50], Step [669/735], Loss: 0.4829\n",
      "Epoch [44/50], Step [670/735], Loss: 0.3804\n",
      "Epoch [44/50], Step [671/735], Loss: 0.0888\n",
      "Epoch [44/50], Step [672/735], Loss: 0.0809\n",
      "Epoch [44/50], Step [673/735], Loss: 0.1402\n",
      "Epoch [44/50], Step [674/735], Loss: 0.1533\n",
      "Epoch [44/50], Step [675/735], Loss: 0.5266\n",
      "Epoch [44/50], Step [676/735], Loss: 0.1358\n",
      "Epoch [44/50], Step [677/735], Loss: 0.1930\n",
      "Epoch [44/50], Step [678/735], Loss: 0.2435\n",
      "Epoch [44/50], Step [679/735], Loss: 0.3268\n",
      "Epoch [44/50], Step [680/735], Loss: 0.4960\n",
      "Epoch [44/50], Step [681/735], Loss: 0.2429\n",
      "Epoch [44/50], Step [682/735], Loss: 0.1728\n",
      "Epoch [44/50], Step [683/735], Loss: 0.3481\n",
      "Epoch [44/50], Step [684/735], Loss: 0.1647\n",
      "Epoch [44/50], Step [685/735], Loss: 0.1002\n",
      "Epoch [44/50], Step [686/735], Loss: 0.2447\n",
      "Epoch [44/50], Step [687/735], Loss: 0.2286\n",
      "Epoch [44/50], Step [688/735], Loss: 0.1028\n",
      "Epoch [44/50], Step [689/735], Loss: 0.2486\n",
      "Epoch [44/50], Step [690/735], Loss: 0.1056\n",
      "Epoch [44/50], Step [691/735], Loss: 0.3570\n",
      "Epoch [44/50], Step [692/735], Loss: 0.2203\n",
      "Epoch [44/50], Step [693/735], Loss: 0.2925\n",
      "Epoch [44/50], Step [694/735], Loss: 0.0962\n",
      "Epoch [44/50], Step [695/735], Loss: 0.8907\n",
      "Epoch [44/50], Step [696/735], Loss: 0.2884\n",
      "Epoch [44/50], Step [697/735], Loss: 0.1797\n",
      "Epoch [44/50], Step [698/735], Loss: 0.1052\n",
      "Epoch [44/50], Step [699/735], Loss: 0.2707\n",
      "Epoch [44/50], Step [700/735], Loss: 0.3083\n",
      "Epoch [44/50], Step [701/735], Loss: 0.3716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Step [702/735], Loss: 0.1756\n",
      "Epoch [44/50], Step [703/735], Loss: 0.3510\n",
      "Epoch [44/50], Step [704/735], Loss: 0.1447\n",
      "Epoch [44/50], Step [705/735], Loss: 0.0762\n",
      "Epoch [44/50], Step [706/735], Loss: 0.4189\n",
      "Epoch [44/50], Step [707/735], Loss: 0.2237\n",
      "Epoch [44/50], Step [708/735], Loss: 0.0607\n",
      "Epoch [44/50], Step [709/735], Loss: 0.3034\n",
      "Epoch [44/50], Step [710/735], Loss: 0.1411\n",
      "Epoch [44/50], Step [711/735], Loss: 0.4108\n",
      "Epoch [44/50], Step [712/735], Loss: 0.8495\n",
      "Epoch [44/50], Step [713/735], Loss: 0.2836\n",
      "Epoch [44/50], Step [714/735], Loss: 0.0849\n",
      "Epoch [44/50], Step [715/735], Loss: 0.0830\n",
      "Epoch [44/50], Step [716/735], Loss: 0.1236\n",
      "Epoch [44/50], Step [717/735], Loss: 0.1981\n",
      "Epoch [44/50], Step [718/735], Loss: 0.2707\n",
      "Epoch [44/50], Step [719/735], Loss: 0.2754\n",
      "Epoch [44/50], Step [720/735], Loss: 0.2232\n",
      "Epoch [44/50], Step [721/735], Loss: 0.3290\n",
      "Epoch [44/50], Step [722/735], Loss: 0.4789\n",
      "Epoch [44/50], Step [723/735], Loss: 0.1093\n",
      "Epoch [44/50], Step [724/735], Loss: 0.1461\n",
      "Epoch [44/50], Step [725/735], Loss: 0.1904\n",
      "Epoch [44/50], Step [726/735], Loss: 0.5674\n",
      "Epoch [44/50], Step [727/735], Loss: 0.2639\n",
      "Epoch [44/50], Step [728/735], Loss: 0.3422\n",
      "Epoch [44/50], Step [729/735], Loss: 0.2514\n",
      "Epoch [44/50], Step [730/735], Loss: 0.3290\n",
      "Epoch [44/50], Step [731/735], Loss: 0.3064\n",
      "Epoch [44/50], Step [732/735], Loss: 0.1873\n",
      "Epoch [44/50], Step [733/735], Loss: 0.6469\n",
      "Epoch [44/50], Step [734/735], Loss: 0.2414\n",
      "Epoch [44/50], Step [735/735], Loss: 0.2185\n",
      "Epoch [45/50], Step [1/735], Loss: 0.6621\n",
      "Epoch [45/50], Step [2/735], Loss: 0.1692\n",
      "Epoch [45/50], Step [3/735], Loss: 0.1247\n",
      "Epoch [45/50], Step [4/735], Loss: 0.2971\n",
      "Epoch [45/50], Step [5/735], Loss: 0.1456\n",
      "Epoch [45/50], Step [6/735], Loss: 0.8048\n",
      "Epoch [45/50], Step [7/735], Loss: 0.2423\n",
      "Epoch [45/50], Step [8/735], Loss: 0.3378\n",
      "Epoch [45/50], Step [9/735], Loss: 0.5150\n",
      "Epoch [45/50], Step [10/735], Loss: 2.5890\n",
      "Epoch [45/50], Step [11/735], Loss: 0.3062\n",
      "Epoch [45/50], Step [12/735], Loss: 0.4631\n",
      "Epoch [45/50], Step [13/735], Loss: 0.2882\n",
      "Epoch [45/50], Step [14/735], Loss: 0.3215\n",
      "Epoch [45/50], Step [15/735], Loss: 0.2199\n",
      "Epoch [45/50], Step [16/735], Loss: 0.3767\n",
      "Epoch [45/50], Step [17/735], Loss: 0.0920\n",
      "Epoch [45/50], Step [18/735], Loss: 0.4241\n",
      "Epoch [45/50], Step [19/735], Loss: 0.1179\n",
      "Epoch [45/50], Step [20/735], Loss: 0.2785\n",
      "Epoch [45/50], Step [21/735], Loss: 0.1541\n",
      "Epoch [45/50], Step [22/735], Loss: 0.3495\n",
      "Epoch [45/50], Step [23/735], Loss: 0.3188\n",
      "Epoch [45/50], Step [24/735], Loss: 0.0782\n",
      "Epoch [45/50], Step [25/735], Loss: 0.1815\n",
      "Epoch [45/50], Step [26/735], Loss: 0.1011\n",
      "Epoch [45/50], Step [27/735], Loss: 0.1548\n",
      "Epoch [45/50], Step [28/735], Loss: 0.1240\n",
      "Epoch [45/50], Step [29/735], Loss: 0.0797\n",
      "Epoch [45/50], Step [30/735], Loss: 1.0707\n",
      "Epoch [45/50], Step [31/735], Loss: 0.0936\n",
      "Epoch [45/50], Step [32/735], Loss: 0.1880\n",
      "Epoch [45/50], Step [33/735], Loss: 0.3319\n",
      "Epoch [45/50], Step [34/735], Loss: 0.2659\n",
      "Epoch [45/50], Step [35/735], Loss: 0.1594\n",
      "Epoch [45/50], Step [36/735], Loss: 0.1489\n",
      "Epoch [45/50], Step [37/735], Loss: 0.2023\n",
      "Epoch [45/50], Step [38/735], Loss: 0.2052\n",
      "Epoch [45/50], Step [39/735], Loss: 0.1757\n",
      "Epoch [45/50], Step [40/735], Loss: 0.0961\n",
      "Epoch [45/50], Step [41/735], Loss: 0.2218\n",
      "Epoch [45/50], Step [42/735], Loss: 0.2225\n",
      "Epoch [45/50], Step [43/735], Loss: 0.2236\n",
      "Epoch [45/50], Step [44/735], Loss: 0.1405\n",
      "Epoch [45/50], Step [45/735], Loss: 0.3469\n",
      "Epoch [45/50], Step [46/735], Loss: 0.2994\n",
      "Epoch [45/50], Step [47/735], Loss: 0.5004\n",
      "Epoch [45/50], Step [48/735], Loss: 0.5293\n",
      "Epoch [45/50], Step [49/735], Loss: 0.4330\n",
      "Epoch [45/50], Step [50/735], Loss: 0.1627\n",
      "Epoch [45/50], Step [51/735], Loss: 0.1072\n",
      "Epoch [45/50], Step [52/735], Loss: 0.6575\n",
      "Epoch [45/50], Step [53/735], Loss: 0.2414\n",
      "Epoch [45/50], Step [54/735], Loss: 0.2097\n",
      "Epoch [45/50], Step [55/735], Loss: 0.8643\n",
      "Epoch [45/50], Step [56/735], Loss: 0.0535\n",
      "Epoch [45/50], Step [57/735], Loss: 0.5284\n",
      "Epoch [45/50], Step [58/735], Loss: 0.1512\n",
      "Epoch [45/50], Step [59/735], Loss: 0.3064\n",
      "Epoch [45/50], Step [60/735], Loss: 0.4146\n",
      "Epoch [45/50], Step [61/735], Loss: 0.6179\n",
      "Epoch [45/50], Step [62/735], Loss: 0.0872\n",
      "Epoch [45/50], Step [63/735], Loss: 0.3062\n",
      "Epoch [45/50], Step [64/735], Loss: 0.1662\n",
      "Epoch [45/50], Step [65/735], Loss: 0.2482\n",
      "Epoch [45/50], Step [66/735], Loss: 0.3272\n",
      "Epoch [45/50], Step [67/735], Loss: 0.1338\n",
      "Epoch [45/50], Step [68/735], Loss: 0.3339\n",
      "Epoch [45/50], Step [69/735], Loss: 0.0895\n",
      "Epoch [45/50], Step [70/735], Loss: 0.2881\n",
      "Epoch [45/50], Step [71/735], Loss: 0.1259\n",
      "Epoch [45/50], Step [72/735], Loss: 0.2562\n",
      "Epoch [45/50], Step [73/735], Loss: 0.3820\n",
      "Epoch [45/50], Step [74/735], Loss: 0.5948\n",
      "Epoch [45/50], Step [75/735], Loss: 0.1079\n",
      "Epoch [45/50], Step [76/735], Loss: 0.0457\n",
      "Epoch [45/50], Step [77/735], Loss: 0.0981\n",
      "Epoch [45/50], Step [78/735], Loss: 0.1694\n",
      "Epoch [45/50], Step [79/735], Loss: 0.1473\n",
      "Epoch [45/50], Step [80/735], Loss: 0.4787\n",
      "Epoch [45/50], Step [81/735], Loss: 0.0533\n",
      "Epoch [45/50], Step [82/735], Loss: 0.3536\n",
      "Epoch [45/50], Step [83/735], Loss: 0.7615\n",
      "Epoch [45/50], Step [84/735], Loss: 0.2227\n",
      "Epoch [45/50], Step [85/735], Loss: 0.1247\n",
      "Epoch [45/50], Step [86/735], Loss: 0.4991\n",
      "Epoch [45/50], Step [87/735], Loss: 0.1446\n",
      "Epoch [45/50], Step [88/735], Loss: 0.1596\n",
      "Epoch [45/50], Step [89/735], Loss: 0.2616\n",
      "Epoch [45/50], Step [90/735], Loss: 0.0890\n",
      "Epoch [45/50], Step [91/735], Loss: 0.0997\n",
      "Epoch [45/50], Step [92/735], Loss: 0.6103\n",
      "Epoch [45/50], Step [93/735], Loss: 0.0884\n",
      "Epoch [45/50], Step [94/735], Loss: 0.1840\n",
      "Epoch [45/50], Step [95/735], Loss: 0.2851\n",
      "Epoch [45/50], Step [96/735], Loss: 0.2630\n",
      "Epoch [45/50], Step [97/735], Loss: 0.5868\n",
      "Epoch [45/50], Step [98/735], Loss: 0.2445\n",
      "Epoch [45/50], Step [99/735], Loss: 0.1877\n",
      "Epoch [45/50], Step [100/735], Loss: 0.3532\n",
      "Epoch [45/50], Step [101/735], Loss: 0.3142\n",
      "Epoch [45/50], Step [102/735], Loss: 0.0938\n",
      "Epoch [45/50], Step [103/735], Loss: 0.1808\n",
      "Epoch [45/50], Step [104/735], Loss: 0.1319\n",
      "Epoch [45/50], Step [105/735], Loss: 0.3168\n",
      "Epoch [45/50], Step [106/735], Loss: 0.1594\n",
      "Epoch [45/50], Step [107/735], Loss: 0.8170\n",
      "Epoch [45/50], Step [108/735], Loss: 0.1928\n",
      "Epoch [45/50], Step [109/735], Loss: 0.2920\n",
      "Epoch [45/50], Step [110/735], Loss: 0.0760\n",
      "Epoch [45/50], Step [111/735], Loss: 0.4320\n",
      "Epoch [45/50], Step [112/735], Loss: 0.1897\n",
      "Epoch [45/50], Step [113/735], Loss: 0.2955\n",
      "Epoch [45/50], Step [114/735], Loss: 0.1904\n",
      "Epoch [45/50], Step [115/735], Loss: 0.1072\n",
      "Epoch [45/50], Step [116/735], Loss: 0.1580\n",
      "Epoch [45/50], Step [117/735], Loss: 0.2333\n",
      "Epoch [45/50], Step [118/735], Loss: 0.3645\n",
      "Epoch [45/50], Step [119/735], Loss: 0.4290\n",
      "Epoch [45/50], Step [120/735], Loss: 0.1587\n",
      "Epoch [45/50], Step [121/735], Loss: 0.1702\n",
      "Epoch [45/50], Step [122/735], Loss: 0.0762\n",
      "Epoch [45/50], Step [123/735], Loss: 0.1635\n",
      "Epoch [45/50], Step [124/735], Loss: 0.2270\n",
      "Epoch [45/50], Step [125/735], Loss: 0.4402\n",
      "Epoch [45/50], Step [126/735], Loss: 0.3682\n",
      "Epoch [45/50], Step [127/735], Loss: 0.1149\n",
      "Epoch [45/50], Step [128/735], Loss: 0.3220\n",
      "Epoch [45/50], Step [129/735], Loss: 0.4625\n",
      "Epoch [45/50], Step [130/735], Loss: 0.9700\n",
      "Epoch [45/50], Step [131/735], Loss: 0.1053\n",
      "Epoch [45/50], Step [132/735], Loss: 0.1313\n",
      "Epoch [45/50], Step [133/735], Loss: 0.2160\n",
      "Epoch [45/50], Step [134/735], Loss: 0.2354\n",
      "Epoch [45/50], Step [135/735], Loss: 0.3022\n",
      "Epoch [45/50], Step [136/735], Loss: 0.9087\n",
      "Epoch [45/50], Step [137/735], Loss: 0.2319\n",
      "Epoch [45/50], Step [138/735], Loss: 0.2698\n",
      "Epoch [45/50], Step [139/735], Loss: 0.2570\n",
      "Epoch [45/50], Step [140/735], Loss: 0.3902\n",
      "Epoch [45/50], Step [141/735], Loss: 0.6618\n",
      "Epoch [45/50], Step [142/735], Loss: 0.0679\n",
      "Epoch [45/50], Step [143/735], Loss: 0.1679\n",
      "Epoch [45/50], Step [144/735], Loss: 0.2966\n",
      "Epoch [45/50], Step [145/735], Loss: 0.2043\n",
      "Epoch [45/50], Step [146/735], Loss: 0.4159\n",
      "Epoch [45/50], Step [147/735], Loss: 0.1695\n",
      "Epoch [45/50], Step [148/735], Loss: 0.2639\n",
      "Epoch [45/50], Step [149/735], Loss: 0.2514\n",
      "Epoch [45/50], Step [150/735], Loss: 0.9553\n",
      "Epoch [45/50], Step [151/735], Loss: 0.3345\n",
      "Epoch [45/50], Step [152/735], Loss: 0.1105\n",
      "Epoch [45/50], Step [153/735], Loss: 0.1906\n",
      "Epoch [45/50], Step [154/735], Loss: 0.6403\n",
      "Epoch [45/50], Step [155/735], Loss: 0.3261\n",
      "Epoch [45/50], Step [156/735], Loss: 0.2875\n",
      "Epoch [45/50], Step [157/735], Loss: 0.4122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Step [158/735], Loss: 0.2924\n",
      "Epoch [45/50], Step [159/735], Loss: 0.1742\n",
      "Epoch [45/50], Step [160/735], Loss: 0.1624\n",
      "Epoch [45/50], Step [161/735], Loss: 0.6438\n",
      "Epoch [45/50], Step [162/735], Loss: 0.2138\n",
      "Epoch [45/50], Step [163/735], Loss: 0.1653\n",
      "Epoch [45/50], Step [164/735], Loss: 0.5144\n",
      "Epoch [45/50], Step [165/735], Loss: 0.1010\n",
      "Epoch [45/50], Step [166/735], Loss: 0.0943\n",
      "Epoch [45/50], Step [167/735], Loss: 0.2843\n",
      "Epoch [45/50], Step [168/735], Loss: 0.2368\n",
      "Epoch [45/50], Step [169/735], Loss: 0.3403\n",
      "Epoch [45/50], Step [170/735], Loss: 0.2375\n",
      "Epoch [45/50], Step [171/735], Loss: 0.1575\n",
      "Epoch [45/50], Step [172/735], Loss: 0.1149\n",
      "Epoch [45/50], Step [173/735], Loss: 0.1081\n",
      "Epoch [45/50], Step [174/735], Loss: 0.1456\n",
      "Epoch [45/50], Step [175/735], Loss: 0.4736\n",
      "Epoch [45/50], Step [176/735], Loss: 0.2241\n",
      "Epoch [45/50], Step [177/735], Loss: 0.1718\n",
      "Epoch [45/50], Step [178/735], Loss: 0.4398\n",
      "Epoch [45/50], Step [179/735], Loss: 0.1086\n",
      "Epoch [45/50], Step [180/735], Loss: 0.0965\n",
      "Epoch [45/50], Step [181/735], Loss: 0.2814\n",
      "Epoch [45/50], Step [182/735], Loss: 0.5834\n",
      "Epoch [45/50], Step [183/735], Loss: 0.3272\n",
      "Epoch [45/50], Step [184/735], Loss: 0.3264\n",
      "Epoch [45/50], Step [185/735], Loss: 0.1358\n",
      "Epoch [45/50], Step [186/735], Loss: 0.4217\n",
      "Epoch [45/50], Step [187/735], Loss: 0.2919\n",
      "Epoch [45/50], Step [188/735], Loss: 0.1230\n",
      "Epoch [45/50], Step [189/735], Loss: 0.6829\n",
      "Epoch [45/50], Step [190/735], Loss: 0.4559\n",
      "Epoch [45/50], Step [191/735], Loss: 0.3313\n",
      "Epoch [45/50], Step [192/735], Loss: 0.1559\n",
      "Epoch [45/50], Step [193/735], Loss: 0.4065\n",
      "Epoch [45/50], Step [194/735], Loss: 0.1854\n",
      "Epoch [45/50], Step [195/735], Loss: 0.2080\n",
      "Epoch [45/50], Step [196/735], Loss: 0.4615\n",
      "Epoch [45/50], Step [197/735], Loss: 1.0394\n",
      "Epoch [45/50], Step [198/735], Loss: 0.3925\n",
      "Epoch [45/50], Step [199/735], Loss: 0.2280\n",
      "Epoch [45/50], Step [200/735], Loss: 0.4254\n",
      "Epoch [45/50], Step [201/735], Loss: 0.1895\n",
      "Epoch [45/50], Step [202/735], Loss: 0.4560\n",
      "Epoch [45/50], Step [203/735], Loss: 0.2221\n",
      "Epoch [45/50], Step [204/735], Loss: 0.2165\n",
      "Epoch [45/50], Step [205/735], Loss: 0.0795\n",
      "Epoch [45/50], Step [206/735], Loss: 0.1044\n",
      "Epoch [45/50], Step [207/735], Loss: 0.2882\n",
      "Epoch [45/50], Step [208/735], Loss: 0.2087\n",
      "Epoch [45/50], Step [209/735], Loss: 0.3941\n",
      "Epoch [45/50], Step [210/735], Loss: 0.1306\n",
      "Epoch [45/50], Step [211/735], Loss: 0.2864\n",
      "Epoch [45/50], Step [212/735], Loss: 0.6070\n",
      "Epoch [45/50], Step [213/735], Loss: 0.1835\n",
      "Epoch [45/50], Step [214/735], Loss: 0.2941\n",
      "Epoch [45/50], Step [215/735], Loss: 0.0820\n",
      "Epoch [45/50], Step [216/735], Loss: 0.0674\n",
      "Epoch [45/50], Step [217/735], Loss: 0.3740\n",
      "Epoch [45/50], Step [218/735], Loss: 0.2474\n",
      "Epoch [45/50], Step [219/735], Loss: 0.0798\n",
      "Epoch [45/50], Step [220/735], Loss: 0.2155\n",
      "Epoch [45/50], Step [221/735], Loss: 0.2348\n",
      "Epoch [45/50], Step [222/735], Loss: 0.1569\n",
      "Epoch [45/50], Step [223/735], Loss: 0.1068\n",
      "Epoch [45/50], Step [224/735], Loss: 0.1341\n",
      "Epoch [45/50], Step [225/735], Loss: 0.2783\n",
      "Epoch [45/50], Step [226/735], Loss: 0.1938\n",
      "Epoch [45/50], Step [227/735], Loss: 0.0834\n",
      "Epoch [45/50], Step [228/735], Loss: 0.3712\n",
      "Epoch [45/50], Step [229/735], Loss: 0.1689\n",
      "Epoch [45/50], Step [230/735], Loss: 0.1160\n",
      "Epoch [45/50], Step [231/735], Loss: 0.3721\n",
      "Epoch [45/50], Step [232/735], Loss: 0.3320\n",
      "Epoch [45/50], Step [233/735], Loss: 1.3233\n",
      "Epoch [45/50], Step [234/735], Loss: 0.2032\n",
      "Epoch [45/50], Step [235/735], Loss: 0.3717\n",
      "Epoch [45/50], Step [236/735], Loss: 0.1847\n",
      "Epoch [45/50], Step [237/735], Loss: 0.4148\n",
      "Epoch [45/50], Step [238/735], Loss: 0.1433\n",
      "Epoch [45/50], Step [239/735], Loss: 0.1228\n",
      "Epoch [45/50], Step [240/735], Loss: 0.1539\n",
      "Epoch [45/50], Step [241/735], Loss: 0.1225\n",
      "Epoch [45/50], Step [242/735], Loss: 0.1947\n",
      "Epoch [45/50], Step [243/735], Loss: 0.4803\n",
      "Epoch [45/50], Step [244/735], Loss: 0.1368\n",
      "Epoch [45/50], Step [245/735], Loss: 0.1471\n",
      "Epoch [45/50], Step [246/735], Loss: 0.1684\n",
      "Epoch [45/50], Step [247/735], Loss: 0.4510\n",
      "Epoch [45/50], Step [248/735], Loss: 0.1214\n",
      "Epoch [45/50], Step [249/735], Loss: 0.4059\n",
      "Epoch [45/50], Step [250/735], Loss: 0.1063\n",
      "Epoch [45/50], Step [251/735], Loss: 0.0368\n",
      "Epoch [45/50], Step [252/735], Loss: 0.3470\n",
      "Epoch [45/50], Step [253/735], Loss: 0.3287\n",
      "Epoch [45/50], Step [254/735], Loss: 0.2866\n",
      "Epoch [45/50], Step [255/735], Loss: 0.3994\n",
      "Epoch [45/50], Step [256/735], Loss: 0.1753\n",
      "Epoch [45/50], Step [257/735], Loss: 0.2032\n",
      "Epoch [45/50], Step [258/735], Loss: 0.3460\n",
      "Epoch [45/50], Step [259/735], Loss: 0.2128\n",
      "Epoch [45/50], Step [260/735], Loss: 0.1974\n",
      "Epoch [45/50], Step [261/735], Loss: 0.0758\n",
      "Epoch [45/50], Step [262/735], Loss: 0.6494\n",
      "Epoch [45/50], Step [263/735], Loss: 0.2077\n",
      "Epoch [45/50], Step [264/735], Loss: 0.1035\n",
      "Epoch [45/50], Step [265/735], Loss: 0.2408\n",
      "Epoch [45/50], Step [266/735], Loss: 0.4094\n",
      "Epoch [45/50], Step [267/735], Loss: 0.0875\n",
      "Epoch [45/50], Step [268/735], Loss: 0.0348\n",
      "Epoch [45/50], Step [269/735], Loss: 0.4232\n",
      "Epoch [45/50], Step [270/735], Loss: 0.0413\n",
      "Epoch [45/50], Step [271/735], Loss: 0.3213\n",
      "Epoch [45/50], Step [272/735], Loss: 0.3061\n",
      "Epoch [45/50], Step [273/735], Loss: 0.1151\n",
      "Epoch [45/50], Step [274/735], Loss: 0.1851\n",
      "Epoch [45/50], Step [275/735], Loss: 0.2056\n",
      "Epoch [45/50], Step [276/735], Loss: 1.0221\n",
      "Epoch [45/50], Step [277/735], Loss: 0.4634\n",
      "Epoch [45/50], Step [278/735], Loss: 0.2067\n",
      "Epoch [45/50], Step [279/735], Loss: 0.2670\n",
      "Epoch [45/50], Step [280/735], Loss: 0.6591\n",
      "Epoch [45/50], Step [281/735], Loss: 0.1576\n",
      "Epoch [45/50], Step [282/735], Loss: 0.0636\n",
      "Epoch [45/50], Step [283/735], Loss: 0.6982\n",
      "Epoch [45/50], Step [284/735], Loss: 0.1513\n",
      "Epoch [45/50], Step [285/735], Loss: 0.2123\n",
      "Epoch [45/50], Step [286/735], Loss: 0.1945\n",
      "Epoch [45/50], Step [287/735], Loss: 0.1501\n",
      "Epoch [45/50], Step [288/735], Loss: 0.2510\n",
      "Epoch [45/50], Step [289/735], Loss: 0.6334\n",
      "Epoch [45/50], Step [290/735], Loss: 0.2380\n",
      "Epoch [45/50], Step [291/735], Loss: 0.1315\n",
      "Epoch [45/50], Step [292/735], Loss: 0.3524\n",
      "Epoch [45/50], Step [293/735], Loss: 0.0685\n",
      "Epoch [45/50], Step [294/735], Loss: 0.1107\n",
      "Epoch [45/50], Step [295/735], Loss: 0.2383\n",
      "Epoch [45/50], Step [296/735], Loss: 0.1616\n",
      "Epoch [45/50], Step [297/735], Loss: 0.2419\n",
      "Epoch [45/50], Step [298/735], Loss: 0.1653\n",
      "Epoch [45/50], Step [299/735], Loss: 0.5474\n",
      "Epoch [45/50], Step [300/735], Loss: 0.0947\n",
      "Epoch [45/50], Step [301/735], Loss: 0.1218\n",
      "Epoch [45/50], Step [302/735], Loss: 0.2709\n",
      "Epoch [45/50], Step [303/735], Loss: 0.2389\n",
      "Epoch [45/50], Step [304/735], Loss: 0.1751\n",
      "Epoch [45/50], Step [305/735], Loss: 0.0945\n",
      "Epoch [45/50], Step [306/735], Loss: 1.0146\n",
      "Epoch [45/50], Step [307/735], Loss: 0.3471\n",
      "Epoch [45/50], Step [308/735], Loss: 0.1222\n",
      "Epoch [45/50], Step [309/735], Loss: 0.4249\n",
      "Epoch [45/50], Step [310/735], Loss: 3.2429\n",
      "Epoch [45/50], Step [311/735], Loss: 0.2693\n",
      "Epoch [45/50], Step [312/735], Loss: 0.1023\n",
      "Epoch [45/50], Step [313/735], Loss: 0.1905\n",
      "Epoch [45/50], Step [314/735], Loss: 0.2952\n",
      "Epoch [45/50], Step [315/735], Loss: 0.3691\n",
      "Epoch [45/50], Step [316/735], Loss: 0.1406\n",
      "Epoch [45/50], Step [317/735], Loss: 0.1908\n",
      "Epoch [45/50], Step [318/735], Loss: 0.1879\n",
      "Epoch [45/50], Step [319/735], Loss: 0.2134\n",
      "Epoch [45/50], Step [320/735], Loss: 0.0937\n",
      "Epoch [45/50], Step [321/735], Loss: 0.1215\n",
      "Epoch [45/50], Step [322/735], Loss: 0.1955\n",
      "Epoch [45/50], Step [323/735], Loss: 0.3988\n",
      "Epoch [45/50], Step [324/735], Loss: 0.1997\n",
      "Epoch [45/50], Step [325/735], Loss: 0.2256\n",
      "Epoch [45/50], Step [326/735], Loss: 0.3298\n",
      "Epoch [45/50], Step [327/735], Loss: 1.0062\n",
      "Epoch [45/50], Step [328/735], Loss: 0.4591\n",
      "Epoch [45/50], Step [329/735], Loss: 0.5499\n",
      "Epoch [45/50], Step [330/735], Loss: 0.5468\n",
      "Epoch [45/50], Step [331/735], Loss: 0.6361\n",
      "Epoch [45/50], Step [332/735], Loss: 2.2754\n",
      "Epoch [45/50], Step [333/735], Loss: 0.1530\n",
      "Epoch [45/50], Step [334/735], Loss: 0.2837\n",
      "Epoch [45/50], Step [335/735], Loss: 0.2038\n",
      "Epoch [45/50], Step [336/735], Loss: 0.3394\n",
      "Epoch [45/50], Step [337/735], Loss: 0.1508\n",
      "Epoch [45/50], Step [338/735], Loss: 0.2574\n",
      "Epoch [45/50], Step [339/735], Loss: 0.1427\n",
      "Epoch [45/50], Step [340/735], Loss: 0.1580\n",
      "Epoch [45/50], Step [341/735], Loss: 0.3050\n",
      "Epoch [45/50], Step [342/735], Loss: 0.1557\n",
      "Epoch [45/50], Step [343/735], Loss: 0.1884\n",
      "Epoch [45/50], Step [344/735], Loss: 0.5174\n",
      "Epoch [45/50], Step [345/735], Loss: 0.4807\n",
      "Epoch [45/50], Step [346/735], Loss: 0.1961\n",
      "Epoch [45/50], Step [347/735], Loss: 0.1724\n",
      "Epoch [45/50], Step [348/735], Loss: 0.1119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Step [349/735], Loss: 0.1615\n",
      "Epoch [45/50], Step [350/735], Loss: 0.1234\n",
      "Epoch [45/50], Step [351/735], Loss: 0.1058\n",
      "Epoch [45/50], Step [352/735], Loss: 0.1068\n",
      "Epoch [45/50], Step [353/735], Loss: 0.1948\n",
      "Epoch [45/50], Step [354/735], Loss: 0.1569\n",
      "Epoch [45/50], Step [355/735], Loss: 0.1421\n",
      "Epoch [45/50], Step [356/735], Loss: 0.2698\n",
      "Epoch [45/50], Step [357/735], Loss: 0.3065\n",
      "Epoch [45/50], Step [358/735], Loss: 0.2210\n",
      "Epoch [45/50], Step [359/735], Loss: 0.3766\n",
      "Epoch [45/50], Step [360/735], Loss: 0.2359\n",
      "Epoch [45/50], Step [361/735], Loss: 0.2964\n",
      "Epoch [45/50], Step [362/735], Loss: 0.9932\n",
      "Epoch [45/50], Step [363/735], Loss: 0.2323\n",
      "Epoch [45/50], Step [364/735], Loss: 0.2491\n",
      "Epoch [45/50], Step [365/735], Loss: 0.2075\n",
      "Epoch [45/50], Step [366/735], Loss: 0.0429\n",
      "Epoch [45/50], Step [367/735], Loss: 0.2937\n",
      "Epoch [45/50], Step [368/735], Loss: 0.3564\n",
      "Epoch [45/50], Step [369/735], Loss: 0.1501\n",
      "Epoch [45/50], Step [370/735], Loss: 0.2205\n",
      "Epoch [45/50], Step [371/735], Loss: 0.2752\n",
      "Epoch [45/50], Step [372/735], Loss: 0.1062\n",
      "Epoch [45/50], Step [373/735], Loss: 0.4158\n",
      "Epoch [45/50], Step [374/735], Loss: 0.1804\n",
      "Epoch [45/50], Step [375/735], Loss: 0.2259\n",
      "Epoch [45/50], Step [376/735], Loss: 0.3074\n",
      "Epoch [45/50], Step [377/735], Loss: 0.0767\n",
      "Epoch [45/50], Step [378/735], Loss: 0.1042\n",
      "Epoch [45/50], Step [379/735], Loss: 0.5006\n",
      "Epoch [45/50], Step [380/735], Loss: 0.5951\n",
      "Epoch [45/50], Step [381/735], Loss: 0.1864\n",
      "Epoch [45/50], Step [382/735], Loss: 0.1963\n",
      "Epoch [45/50], Step [383/735], Loss: 0.2394\n",
      "Epoch [45/50], Step [384/735], Loss: 0.2021\n",
      "Epoch [45/50], Step [385/735], Loss: 0.1417\n",
      "Epoch [45/50], Step [386/735], Loss: 0.3987\n",
      "Epoch [45/50], Step [387/735], Loss: 0.3885\n",
      "Epoch [45/50], Step [388/735], Loss: 0.4952\n",
      "Epoch [45/50], Step [389/735], Loss: 0.0795\n",
      "Epoch [45/50], Step [390/735], Loss: 0.2065\n",
      "Epoch [45/50], Step [391/735], Loss: 0.2480\n",
      "Epoch [45/50], Step [392/735], Loss: 0.2150\n",
      "Epoch [45/50], Step [393/735], Loss: 0.1289\n",
      "Epoch [45/50], Step [394/735], Loss: 0.1124\n",
      "Epoch [45/50], Step [395/735], Loss: 0.1249\n",
      "Epoch [45/50], Step [396/735], Loss: 0.6590\n",
      "Epoch [45/50], Step [397/735], Loss: 0.2808\n",
      "Epoch [45/50], Step [398/735], Loss: 0.1605\n",
      "Epoch [45/50], Step [399/735], Loss: 0.6540\n",
      "Epoch [45/50], Step [400/735], Loss: 0.2018\n",
      "Epoch [45/50], Step [401/735], Loss: 0.5092\n",
      "Epoch [45/50], Step [402/735], Loss: 0.8050\n",
      "Epoch [45/50], Step [403/735], Loss: 0.3968\n",
      "Epoch [45/50], Step [404/735], Loss: 0.0624\n",
      "Epoch [45/50], Step [405/735], Loss: 0.2712\n",
      "Epoch [45/50], Step [406/735], Loss: 0.1331\n",
      "Epoch [45/50], Step [407/735], Loss: 0.1585\n",
      "Epoch [45/50], Step [408/735], Loss: 1.0688\n",
      "Epoch [45/50], Step [409/735], Loss: 0.3229\n",
      "Epoch [45/50], Step [410/735], Loss: 0.8560\n",
      "Epoch [45/50], Step [411/735], Loss: 0.2469\n",
      "Epoch [45/50], Step [412/735], Loss: 0.2269\n",
      "Epoch [45/50], Step [413/735], Loss: 0.2110\n",
      "Epoch [45/50], Step [414/735], Loss: 0.3971\n",
      "Epoch [45/50], Step [415/735], Loss: 0.1894\n",
      "Epoch [45/50], Step [416/735], Loss: 0.1503\n",
      "Epoch [45/50], Step [417/735], Loss: 0.3618\n",
      "Epoch [45/50], Step [418/735], Loss: 0.2824\n",
      "Epoch [45/50], Step [419/735], Loss: 0.6719\n",
      "Epoch [45/50], Step [420/735], Loss: 0.2303\n",
      "Epoch [45/50], Step [421/735], Loss: 0.2793\n",
      "Epoch [45/50], Step [422/735], Loss: 0.1761\n",
      "Epoch [45/50], Step [423/735], Loss: 0.4522\n",
      "Epoch [45/50], Step [424/735], Loss: 0.2889\n",
      "Epoch [45/50], Step [425/735], Loss: 0.2405\n",
      "Epoch [45/50], Step [426/735], Loss: 0.1763\n",
      "Epoch [45/50], Step [427/735], Loss: 0.4885\n",
      "Epoch [45/50], Step [428/735], Loss: 0.1577\n",
      "Epoch [45/50], Step [429/735], Loss: 0.2163\n",
      "Epoch [45/50], Step [430/735], Loss: 0.4695\n",
      "Epoch [45/50], Step [431/735], Loss: 0.2556\n",
      "Epoch [45/50], Step [432/735], Loss: 0.3873\n",
      "Epoch [45/50], Step [433/735], Loss: 0.3413\n",
      "Epoch [45/50], Step [434/735], Loss: 0.1102\n",
      "Epoch [45/50], Step [435/735], Loss: 0.1729\n",
      "Epoch [45/50], Step [436/735], Loss: 0.1216\n",
      "Epoch [45/50], Step [437/735], Loss: 0.2484\n",
      "Epoch [45/50], Step [438/735], Loss: 0.0926\n",
      "Epoch [45/50], Step [439/735], Loss: 0.1185\n",
      "Epoch [45/50], Step [440/735], Loss: 0.2713\n",
      "Epoch [45/50], Step [441/735], Loss: 0.1316\n",
      "Epoch [45/50], Step [442/735], Loss: 0.1317\n",
      "Epoch [45/50], Step [443/735], Loss: 0.3282\n",
      "Epoch [45/50], Step [444/735], Loss: 0.1345\n",
      "Epoch [45/50], Step [445/735], Loss: 0.0744\n",
      "Epoch [45/50], Step [446/735], Loss: 0.3646\n",
      "Epoch [45/50], Step [447/735], Loss: 0.2190\n",
      "Epoch [45/50], Step [448/735], Loss: 0.1572\n",
      "Epoch [45/50], Step [449/735], Loss: 0.1248\n",
      "Epoch [45/50], Step [450/735], Loss: 0.0713\n",
      "Epoch [45/50], Step [451/735], Loss: 0.2549\n",
      "Epoch [45/50], Step [452/735], Loss: 0.1574\n",
      "Epoch [45/50], Step [453/735], Loss: 0.1830\n",
      "Epoch [45/50], Step [454/735], Loss: 0.0785\n",
      "Epoch [45/50], Step [455/735], Loss: 0.3483\n",
      "Epoch [45/50], Step [456/735], Loss: 0.0840\n",
      "Epoch [45/50], Step [457/735], Loss: 0.1367\n",
      "Epoch [45/50], Step [458/735], Loss: 0.1792\n",
      "Epoch [45/50], Step [459/735], Loss: 0.2778\n",
      "Epoch [45/50], Step [460/735], Loss: 0.2902\n",
      "Epoch [45/50], Step [461/735], Loss: 0.0847\n",
      "Epoch [45/50], Step [462/735], Loss: 1.3884\n",
      "Epoch [45/50], Step [463/735], Loss: 0.2010\n",
      "Epoch [45/50], Step [464/735], Loss: 0.2849\n",
      "Epoch [45/50], Step [465/735], Loss: 0.0997\n",
      "Epoch [45/50], Step [466/735], Loss: 0.1375\n",
      "Epoch [45/50], Step [467/735], Loss: 0.1034\n",
      "Epoch [45/50], Step [468/735], Loss: 0.0743\n",
      "Epoch [45/50], Step [469/735], Loss: 0.3967\n",
      "Epoch [45/50], Step [470/735], Loss: 0.3885\n",
      "Epoch [45/50], Step [471/735], Loss: 0.2539\n",
      "Epoch [45/50], Step [472/735], Loss: 0.2315\n",
      "Epoch [45/50], Step [473/735], Loss: 0.1714\n",
      "Epoch [45/50], Step [474/735], Loss: 0.2200\n",
      "Epoch [45/50], Step [475/735], Loss: 0.2542\n",
      "Epoch [45/50], Step [476/735], Loss: 0.1436\n",
      "Epoch [45/50], Step [477/735], Loss: 0.1103\n",
      "Epoch [45/50], Step [478/735], Loss: 0.2057\n",
      "Epoch [45/50], Step [479/735], Loss: 0.1953\n",
      "Epoch [45/50], Step [480/735], Loss: 0.2837\n",
      "Epoch [45/50], Step [481/735], Loss: 0.1996\n",
      "Epoch [45/50], Step [482/735], Loss: 0.0824\n",
      "Epoch [45/50], Step [483/735], Loss: 0.1625\n",
      "Epoch [45/50], Step [484/735], Loss: 0.1261\n",
      "Epoch [45/50], Step [485/735], Loss: 0.2076\n",
      "Epoch [45/50], Step [486/735], Loss: 0.3114\n",
      "Epoch [45/50], Step [487/735], Loss: 0.0538\n",
      "Epoch [45/50], Step [488/735], Loss: 0.1191\n",
      "Epoch [45/50], Step [489/735], Loss: 0.1427\n",
      "Epoch [45/50], Step [490/735], Loss: 0.3147\n",
      "Epoch [45/50], Step [491/735], Loss: 0.2446\n",
      "Epoch [45/50], Step [492/735], Loss: 0.1628\n",
      "Epoch [45/50], Step [493/735], Loss: 0.0999\n",
      "Epoch [45/50], Step [494/735], Loss: 0.2927\n",
      "Epoch [45/50], Step [495/735], Loss: 0.1390\n",
      "Epoch [45/50], Step [496/735], Loss: 0.0911\n",
      "Epoch [45/50], Step [497/735], Loss: 0.7666\n",
      "Epoch [45/50], Step [498/735], Loss: 0.4074\n",
      "Epoch [45/50], Step [499/735], Loss: 0.1265\n",
      "Epoch [45/50], Step [500/735], Loss: 0.0981\n",
      "Epoch [45/50], Step [501/735], Loss: 0.2205\n",
      "Epoch [45/50], Step [502/735], Loss: 0.4870\n",
      "Epoch [45/50], Step [503/735], Loss: 0.2076\n",
      "Epoch [45/50], Step [504/735], Loss: 0.2084\n",
      "Epoch [45/50], Step [505/735], Loss: 0.0739\n",
      "Epoch [45/50], Step [506/735], Loss: 0.1188\n",
      "Epoch [45/50], Step [507/735], Loss: 0.1319\n",
      "Epoch [45/50], Step [508/735], Loss: 0.4149\n",
      "Epoch [45/50], Step [509/735], Loss: 0.1857\n",
      "Epoch [45/50], Step [510/735], Loss: 0.2083\n",
      "Epoch [45/50], Step [511/735], Loss: 0.0824\n",
      "Epoch [45/50], Step [512/735], Loss: 0.1545\n",
      "Epoch [45/50], Step [513/735], Loss: 0.1683\n",
      "Epoch [45/50], Step [514/735], Loss: 0.2859\n",
      "Epoch [45/50], Step [515/735], Loss: 0.2834\n",
      "Epoch [45/50], Step [516/735], Loss: 0.1089\n",
      "Epoch [45/50], Step [517/735], Loss: 0.1631\n",
      "Epoch [45/50], Step [518/735], Loss: 0.1048\n",
      "Epoch [45/50], Step [519/735], Loss: 0.2952\n",
      "Epoch [45/50], Step [520/735], Loss: 0.2768\n",
      "Epoch [45/50], Step [521/735], Loss: 0.0801\n",
      "Epoch [45/50], Step [522/735], Loss: 0.2816\n",
      "Epoch [45/50], Step [523/735], Loss: 0.2812\n",
      "Epoch [45/50], Step [524/735], Loss: 0.2771\n",
      "Epoch [45/50], Step [525/735], Loss: 0.1297\n",
      "Epoch [45/50], Step [526/735], Loss: 0.1491\n",
      "Epoch [45/50], Step [527/735], Loss: 0.1869\n",
      "Epoch [45/50], Step [528/735], Loss: 0.2272\n",
      "Epoch [45/50], Step [529/735], Loss: 0.0816\n",
      "Epoch [45/50], Step [530/735], Loss: 0.0903\n",
      "Epoch [45/50], Step [531/735], Loss: 0.2315\n",
      "Epoch [45/50], Step [532/735], Loss: 0.2013\n",
      "Epoch [45/50], Step [533/735], Loss: 0.2553\n",
      "Epoch [45/50], Step [534/735], Loss: 0.3828\n",
      "Epoch [45/50], Step [535/735], Loss: 0.4590\n",
      "Epoch [45/50], Step [536/735], Loss: 0.1656\n",
      "Epoch [45/50], Step [537/735], Loss: 0.1081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Step [538/735], Loss: 0.1707\n",
      "Epoch [45/50], Step [539/735], Loss: 0.4180\n",
      "Epoch [45/50], Step [540/735], Loss: 0.2833\n",
      "Epoch [45/50], Step [541/735], Loss: 0.1566\n",
      "Epoch [45/50], Step [542/735], Loss: 0.0970\n",
      "Epoch [45/50], Step [543/735], Loss: 0.2856\n",
      "Epoch [45/50], Step [544/735], Loss: 0.5424\n",
      "Epoch [45/50], Step [545/735], Loss: 0.0772\n",
      "Epoch [45/50], Step [546/735], Loss: 0.1733\n",
      "Epoch [45/50], Step [547/735], Loss: 0.2782\n",
      "Epoch [45/50], Step [548/735], Loss: 0.3146\n",
      "Epoch [45/50], Step [549/735], Loss: 0.0661\n",
      "Epoch [45/50], Step [550/735], Loss: 0.1280\n",
      "Epoch [45/50], Step [551/735], Loss: 0.1593\n",
      "Epoch [45/50], Step [552/735], Loss: 0.2308\n",
      "Epoch [45/50], Step [553/735], Loss: 0.3051\n",
      "Epoch [45/50], Step [554/735], Loss: 0.1156\n",
      "Epoch [45/50], Step [555/735], Loss: 0.3719\n",
      "Epoch [45/50], Step [556/735], Loss: 0.1671\n",
      "Epoch [45/50], Step [557/735], Loss: 0.5669\n",
      "Epoch [45/50], Step [558/735], Loss: 0.1541\n",
      "Epoch [45/50], Step [559/735], Loss: 1.0693\n",
      "Epoch [45/50], Step [560/735], Loss: 0.4579\n",
      "Epoch [45/50], Step [561/735], Loss: 0.1479\n",
      "Epoch [45/50], Step [562/735], Loss: 0.3086\n",
      "Epoch [45/50], Step [563/735], Loss: 0.1038\n",
      "Epoch [45/50], Step [564/735], Loss: 0.1207\n",
      "Epoch [45/50], Step [565/735], Loss: 0.2705\n",
      "Epoch [45/50], Step [566/735], Loss: 0.1377\n",
      "Epoch [45/50], Step [567/735], Loss: 0.1966\n",
      "Epoch [45/50], Step [568/735], Loss: 0.2771\n",
      "Epoch [45/50], Step [569/735], Loss: 0.1688\n",
      "Epoch [45/50], Step [570/735], Loss: 0.0664\n",
      "Epoch [45/50], Step [571/735], Loss: 0.4131\n",
      "Epoch [45/50], Step [572/735], Loss: 0.4790\n",
      "Epoch [45/50], Step [573/735], Loss: 0.0844\n",
      "Epoch [45/50], Step [574/735], Loss: 0.2246\n",
      "Epoch [45/50], Step [575/735], Loss: 0.1941\n",
      "Epoch [45/50], Step [576/735], Loss: 0.1669\n",
      "Epoch [45/50], Step [577/735], Loss: 0.3889\n",
      "Epoch [45/50], Step [578/735], Loss: 0.2600\n",
      "Epoch [45/50], Step [579/735], Loss: 0.3745\n",
      "Epoch [45/50], Step [580/735], Loss: 0.1060\n",
      "Epoch [45/50], Step [581/735], Loss: 0.1645\n",
      "Epoch [45/50], Step [582/735], Loss: 0.2081\n",
      "Epoch [45/50], Step [583/735], Loss: 0.1236\n",
      "Epoch [45/50], Step [584/735], Loss: 0.1887\n",
      "Epoch [45/50], Step [585/735], Loss: 0.1274\n",
      "Epoch [45/50], Step [586/735], Loss: 0.3383\n",
      "Epoch [45/50], Step [587/735], Loss: 0.2740\n",
      "Epoch [45/50], Step [588/735], Loss: 0.4204\n",
      "Epoch [45/50], Step [589/735], Loss: 0.1111\n",
      "Epoch [45/50], Step [590/735], Loss: 2.7839\n",
      "Epoch [45/50], Step [591/735], Loss: 0.6055\n",
      "Epoch [45/50], Step [592/735], Loss: 0.3894\n",
      "Epoch [45/50], Step [593/735], Loss: 0.1819\n",
      "Epoch [45/50], Step [594/735], Loss: 0.0692\n",
      "Epoch [45/50], Step [595/735], Loss: 0.3073\n",
      "Epoch [45/50], Step [596/735], Loss: 0.3525\n",
      "Epoch [45/50], Step [597/735], Loss: 0.1042\n",
      "Epoch [45/50], Step [598/735], Loss: 0.1295\n",
      "Epoch [45/50], Step [599/735], Loss: 0.0961\n",
      "Epoch [45/50], Step [600/735], Loss: 0.1140\n",
      "Epoch [45/50], Step [601/735], Loss: 0.6089\n",
      "Epoch [45/50], Step [602/735], Loss: 0.4103\n",
      "Epoch [45/50], Step [603/735], Loss: 0.1727\n",
      "Epoch [45/50], Step [604/735], Loss: 0.1372\n",
      "Epoch [45/50], Step [605/735], Loss: 0.3844\n",
      "Epoch [45/50], Step [606/735], Loss: 0.4271\n",
      "Epoch [45/50], Step [607/735], Loss: 0.4261\n",
      "Epoch [45/50], Step [608/735], Loss: 0.2453\n",
      "Epoch [45/50], Step [609/735], Loss: 0.3080\n",
      "Epoch [45/50], Step [610/735], Loss: 0.3557\n",
      "Epoch [45/50], Step [611/735], Loss: 0.2037\n",
      "Epoch [45/50], Step [612/735], Loss: 0.1539\n",
      "Epoch [45/50], Step [613/735], Loss: 0.6245\n",
      "Epoch [45/50], Step [614/735], Loss: 0.4208\n",
      "Epoch [45/50], Step [615/735], Loss: 0.2477\n",
      "Epoch [45/50], Step [616/735], Loss: 0.5086\n",
      "Epoch [45/50], Step [617/735], Loss: 0.0646\n",
      "Epoch [45/50], Step [618/735], Loss: 0.2162\n",
      "Epoch [45/50], Step [619/735], Loss: 0.4111\n",
      "Epoch [45/50], Step [620/735], Loss: 0.2354\n",
      "Epoch [45/50], Step [621/735], Loss: 0.4321\n",
      "Epoch [45/50], Step [622/735], Loss: 0.3351\n",
      "Epoch [45/50], Step [623/735], Loss: 0.1456\n",
      "Epoch [45/50], Step [624/735], Loss: 0.7406\n",
      "Epoch [45/50], Step [625/735], Loss: 0.2168\n",
      "Epoch [45/50], Step [626/735], Loss: 0.1209\n",
      "Epoch [45/50], Step [627/735], Loss: 0.1562\n",
      "Epoch [45/50], Step [628/735], Loss: 0.2390\n",
      "Epoch [45/50], Step [629/735], Loss: 0.3366\n",
      "Epoch [45/50], Step [630/735], Loss: 0.3007\n",
      "Epoch [45/50], Step [631/735], Loss: 0.2308\n",
      "Epoch [45/50], Step [632/735], Loss: 0.5853\n",
      "Epoch [45/50], Step [633/735], Loss: 0.1109\n",
      "Epoch [45/50], Step [634/735], Loss: 0.3994\n",
      "Epoch [45/50], Step [635/735], Loss: 0.1698\n",
      "Epoch [45/50], Step [636/735], Loss: 0.3336\n",
      "Epoch [45/50], Step [637/735], Loss: 0.2821\n",
      "Epoch [45/50], Step [638/735], Loss: 0.1654\n",
      "Epoch [45/50], Step [639/735], Loss: 0.2027\n",
      "Epoch [45/50], Step [640/735], Loss: 0.1418\n",
      "Epoch [45/50], Step [641/735], Loss: 0.2120\n",
      "Epoch [45/50], Step [642/735], Loss: 0.3692\n",
      "Epoch [45/50], Step [643/735], Loss: 0.1841\n",
      "Epoch [45/50], Step [644/735], Loss: 0.3176\n",
      "Epoch [45/50], Step [645/735], Loss: 0.2922\n",
      "Epoch [45/50], Step [646/735], Loss: 0.3101\n",
      "Epoch [45/50], Step [647/735], Loss: 0.2870\n",
      "Epoch [45/50], Step [648/735], Loss: 0.1487\n",
      "Epoch [45/50], Step [649/735], Loss: 0.1656\n",
      "Epoch [45/50], Step [650/735], Loss: 0.4950\n",
      "Epoch [45/50], Step [651/735], Loss: 0.7151\n",
      "Epoch [45/50], Step [652/735], Loss: 0.0813\n",
      "Epoch [45/50], Step [653/735], Loss: 0.4325\n",
      "Epoch [45/50], Step [654/735], Loss: 0.2316\n",
      "Epoch [45/50], Step [655/735], Loss: 0.1310\n",
      "Epoch [45/50], Step [656/735], Loss: 0.5682\n",
      "Epoch [45/50], Step [657/735], Loss: 0.1605\n",
      "Epoch [45/50], Step [658/735], Loss: 0.2521\n",
      "Epoch [45/50], Step [659/735], Loss: 0.2922\n",
      "Epoch [45/50], Step [660/735], Loss: 0.2279\n",
      "Epoch [45/50], Step [661/735], Loss: 0.1399\n",
      "Epoch [45/50], Step [662/735], Loss: 2.8527\n",
      "Epoch [45/50], Step [663/735], Loss: 0.2398\n",
      "Epoch [45/50], Step [664/735], Loss: 0.1267\n",
      "Epoch [45/50], Step [665/735], Loss: 0.1925\n",
      "Epoch [45/50], Step [666/735], Loss: 0.2768\n",
      "Epoch [45/50], Step [667/735], Loss: 0.2088\n",
      "Epoch [45/50], Step [668/735], Loss: 0.2781\n",
      "Epoch [45/50], Step [669/735], Loss: 0.1124\n",
      "Epoch [45/50], Step [670/735], Loss: 0.3986\n",
      "Epoch [45/50], Step [671/735], Loss: 0.1851\n",
      "Epoch [45/50], Step [672/735], Loss: 0.2285\n",
      "Epoch [45/50], Step [673/735], Loss: 0.1445\n",
      "Epoch [45/50], Step [674/735], Loss: 0.2382\n",
      "Epoch [45/50], Step [675/735], Loss: 0.4624\n",
      "Epoch [45/50], Step [676/735], Loss: 0.3374\n",
      "Epoch [45/50], Step [677/735], Loss: 0.0940\n",
      "Epoch [45/50], Step [678/735], Loss: 0.1432\n",
      "Epoch [45/50], Step [679/735], Loss: 0.3573\n",
      "Epoch [45/50], Step [680/735], Loss: 0.3152\n",
      "Epoch [45/50], Step [681/735], Loss: 0.2003\n",
      "Epoch [45/50], Step [682/735], Loss: 0.5083\n",
      "Epoch [45/50], Step [683/735], Loss: 0.1822\n",
      "Epoch [45/50], Step [684/735], Loss: 0.2854\n",
      "Epoch [45/50], Step [685/735], Loss: 0.5448\n",
      "Epoch [45/50], Step [686/735], Loss: 0.2053\n",
      "Epoch [45/50], Step [687/735], Loss: 0.1035\n",
      "Epoch [45/50], Step [688/735], Loss: 0.0795\n",
      "Epoch [45/50], Step [689/735], Loss: 0.4664\n",
      "Epoch [45/50], Step [690/735], Loss: 0.0884\n",
      "Epoch [45/50], Step [691/735], Loss: 0.3232\n",
      "Epoch [45/50], Step [692/735], Loss: 0.2211\n",
      "Epoch [45/50], Step [693/735], Loss: 0.0461\n",
      "Epoch [45/50], Step [694/735], Loss: 0.2134\n",
      "Epoch [45/50], Step [695/735], Loss: 0.4082\n",
      "Epoch [45/50], Step [696/735], Loss: 1.0099\n",
      "Epoch [45/50], Step [697/735], Loss: 0.2205\n",
      "Epoch [45/50], Step [698/735], Loss: 0.3595\n",
      "Epoch [45/50], Step [699/735], Loss: 0.1870\n",
      "Epoch [45/50], Step [700/735], Loss: 0.1872\n",
      "Epoch [45/50], Step [701/735], Loss: 0.2740\n",
      "Epoch [45/50], Step [702/735], Loss: 0.1874\n",
      "Epoch [45/50], Step [703/735], Loss: 0.1072\n",
      "Epoch [45/50], Step [704/735], Loss: 0.2582\n",
      "Epoch [45/50], Step [705/735], Loss: 0.2927\n",
      "Epoch [45/50], Step [706/735], Loss: 0.1298\n",
      "Epoch [45/50], Step [707/735], Loss: 0.1069\n",
      "Epoch [45/50], Step [708/735], Loss: 0.4138\n",
      "Epoch [45/50], Step [709/735], Loss: 0.3402\n",
      "Epoch [45/50], Step [710/735], Loss: 0.0602\n",
      "Epoch [45/50], Step [711/735], Loss: 0.1649\n",
      "Epoch [45/50], Step [712/735], Loss: 0.1309\n",
      "Epoch [45/50], Step [713/735], Loss: 0.4422\n",
      "Epoch [45/50], Step [714/735], Loss: 0.1662\n",
      "Epoch [45/50], Step [715/735], Loss: 0.3126\n",
      "Epoch [45/50], Step [716/735], Loss: 0.1258\n",
      "Epoch [45/50], Step [717/735], Loss: 0.1929\n",
      "Epoch [45/50], Step [718/735], Loss: 0.7237\n",
      "Epoch [45/50], Step [719/735], Loss: 0.3780\n",
      "Epoch [45/50], Step [720/735], Loss: 0.2953\n",
      "Epoch [45/50], Step [721/735], Loss: 0.1598\n",
      "Epoch [45/50], Step [722/735], Loss: 0.1783\n",
      "Epoch [45/50], Step [723/735], Loss: 0.3885\n",
      "Epoch [45/50], Step [724/735], Loss: 0.2413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Step [725/735], Loss: 0.3725\n",
      "Epoch [45/50], Step [726/735], Loss: 0.3184\n",
      "Epoch [45/50], Step [727/735], Loss: 0.3036\n",
      "Epoch [45/50], Step [728/735], Loss: 0.6619\n",
      "Epoch [45/50], Step [729/735], Loss: 0.3055\n",
      "Epoch [45/50], Step [730/735], Loss: 0.2417\n",
      "Epoch [45/50], Step [731/735], Loss: 0.1062\n",
      "Epoch [45/50], Step [732/735], Loss: 0.4114\n",
      "Epoch [45/50], Step [733/735], Loss: 0.2740\n",
      "Epoch [45/50], Step [734/735], Loss: 0.2787\n",
      "Epoch [45/50], Step [735/735], Loss: 0.2524\n",
      "Epoch [46/50], Step [1/735], Loss: 0.2405\n",
      "Epoch [46/50], Step [2/735], Loss: 0.0625\n",
      "Epoch [46/50], Step [3/735], Loss: 0.3083\n",
      "Epoch [46/50], Step [4/735], Loss: 0.6113\n",
      "Epoch [46/50], Step [5/735], Loss: 0.1504\n",
      "Epoch [46/50], Step [6/735], Loss: 0.2758\n",
      "Epoch [46/50], Step [7/735], Loss: 0.0819\n",
      "Epoch [46/50], Step [8/735], Loss: 1.2882\n",
      "Epoch [46/50], Step [9/735], Loss: 0.0829\n",
      "Epoch [46/50], Step [10/735], Loss: 0.1058\n",
      "Epoch [46/50], Step [11/735], Loss: 0.0861\n",
      "Epoch [46/50], Step [12/735], Loss: 0.2760\n",
      "Epoch [46/50], Step [13/735], Loss: 0.2325\n",
      "Epoch [46/50], Step [14/735], Loss: 0.1391\n",
      "Epoch [46/50], Step [15/735], Loss: 0.1872\n",
      "Epoch [46/50], Step [16/735], Loss: 0.7170\n",
      "Epoch [46/50], Step [17/735], Loss: 0.2216\n",
      "Epoch [46/50], Step [18/735], Loss: 0.3746\n",
      "Epoch [46/50], Step [19/735], Loss: 0.3154\n",
      "Epoch [46/50], Step [20/735], Loss: 0.2128\n",
      "Epoch [46/50], Step [21/735], Loss: 0.3208\n",
      "Epoch [46/50], Step [22/735], Loss: 0.1225\n",
      "Epoch [46/50], Step [23/735], Loss: 0.1066\n",
      "Epoch [46/50], Step [24/735], Loss: 0.1865\n",
      "Epoch [46/50], Step [25/735], Loss: 0.1687\n",
      "Epoch [46/50], Step [26/735], Loss: 0.3625\n",
      "Epoch [46/50], Step [27/735], Loss: 0.1328\n",
      "Epoch [46/50], Step [28/735], Loss: 0.7755\n",
      "Epoch [46/50], Step [29/735], Loss: 0.2552\n",
      "Epoch [46/50], Step [30/735], Loss: 0.1786\n",
      "Epoch [46/50], Step [31/735], Loss: 0.3714\n",
      "Epoch [46/50], Step [32/735], Loss: 0.7778\n",
      "Epoch [46/50], Step [33/735], Loss: 0.2426\n",
      "Epoch [46/50], Step [34/735], Loss: 0.2495\n",
      "Epoch [46/50], Step [35/735], Loss: 0.1677\n",
      "Epoch [46/50], Step [36/735], Loss: 0.2548\n",
      "Epoch [46/50], Step [37/735], Loss: 0.0763\n",
      "Epoch [46/50], Step [38/735], Loss: 0.9855\n",
      "Epoch [46/50], Step [39/735], Loss: 0.0718\n",
      "Epoch [46/50], Step [40/735], Loss: 0.2575\n",
      "Epoch [46/50], Step [41/735], Loss: 0.1699\n",
      "Epoch [46/50], Step [42/735], Loss: 0.7337\n",
      "Epoch [46/50], Step [43/735], Loss: 0.1175\n",
      "Epoch [46/50], Step [44/735], Loss: 0.1350\n",
      "Epoch [46/50], Step [45/735], Loss: 0.4198\n",
      "Epoch [46/50], Step [46/735], Loss: 0.2208\n",
      "Epoch [46/50], Step [47/735], Loss: 0.1554\n",
      "Epoch [46/50], Step [48/735], Loss: 0.2829\n",
      "Epoch [46/50], Step [49/735], Loss: 0.1115\n",
      "Epoch [46/50], Step [50/735], Loss: 0.0936\n",
      "Epoch [46/50], Step [51/735], Loss: 0.1210\n",
      "Epoch [46/50], Step [52/735], Loss: 0.4410\n",
      "Epoch [46/50], Step [53/735], Loss: 0.3754\n",
      "Epoch [46/50], Step [54/735], Loss: 0.2128\n",
      "Epoch [46/50], Step [55/735], Loss: 0.1875\n",
      "Epoch [46/50], Step [56/735], Loss: 0.4990\n",
      "Epoch [46/50], Step [57/735], Loss: 0.1391\n",
      "Epoch [46/50], Step [58/735], Loss: 0.1903\n",
      "Epoch [46/50], Step [59/735], Loss: 0.1271\n",
      "Epoch [46/50], Step [60/735], Loss: 0.0523\n",
      "Epoch [46/50], Step [61/735], Loss: 0.1842\n",
      "Epoch [46/50], Step [62/735], Loss: 0.4645\n",
      "Epoch [46/50], Step [63/735], Loss: 0.2910\n",
      "Epoch [46/50], Step [64/735], Loss: 0.1925\n",
      "Epoch [46/50], Step [65/735], Loss: 0.3093\n",
      "Epoch [46/50], Step [66/735], Loss: 0.2463\n",
      "Epoch [46/50], Step [67/735], Loss: 0.1867\n",
      "Epoch [46/50], Step [68/735], Loss: 0.3398\n",
      "Epoch [46/50], Step [69/735], Loss: 0.4086\n",
      "Epoch [46/50], Step [70/735], Loss: 0.5987\n",
      "Epoch [46/50], Step [71/735], Loss: 0.5807\n",
      "Epoch [46/50], Step [72/735], Loss: 0.1458\n",
      "Epoch [46/50], Step [73/735], Loss: 0.1022\n",
      "Epoch [46/50], Step [74/735], Loss: 0.1290\n",
      "Epoch [46/50], Step [75/735], Loss: 0.2258\n",
      "Epoch [46/50], Step [76/735], Loss: 0.0980\n",
      "Epoch [46/50], Step [77/735], Loss: 0.2550\n",
      "Epoch [46/50], Step [78/735], Loss: 0.2553\n",
      "Epoch [46/50], Step [79/735], Loss: 0.1356\n",
      "Epoch [46/50], Step [80/735], Loss: 0.1832\n",
      "Epoch [46/50], Step [81/735], Loss: 0.1881\n",
      "Epoch [46/50], Step [82/735], Loss: 0.3628\n",
      "Epoch [46/50], Step [83/735], Loss: 0.5056\n",
      "Epoch [46/50], Step [84/735], Loss: 0.1355\n",
      "Epoch [46/50], Step [85/735], Loss: 0.1320\n",
      "Epoch [46/50], Step [86/735], Loss: 0.5302\n",
      "Epoch [46/50], Step [87/735], Loss: 0.1957\n",
      "Epoch [46/50], Step [88/735], Loss: 0.0952\n",
      "Epoch [46/50], Step [89/735], Loss: 0.3435\n",
      "Epoch [46/50], Step [90/735], Loss: 0.4314\n",
      "Epoch [46/50], Step [91/735], Loss: 0.1862\n",
      "Epoch [46/50], Step [92/735], Loss: 1.0266\n",
      "Epoch [46/50], Step [93/735], Loss: 1.0225\n",
      "Epoch [46/50], Step [94/735], Loss: 0.1945\n",
      "Epoch [46/50], Step [95/735], Loss: 0.4326\n",
      "Epoch [46/50], Step [96/735], Loss: 0.0747\n",
      "Epoch [46/50], Step [97/735], Loss: 0.1282\n",
      "Epoch [46/50], Step [98/735], Loss: 0.4249\n",
      "Epoch [46/50], Step [99/735], Loss: 0.1763\n",
      "Epoch [46/50], Step [100/735], Loss: 0.1149\n",
      "Epoch [46/50], Step [101/735], Loss: 0.3511\n",
      "Epoch [46/50], Step [102/735], Loss: 0.0758\n",
      "Epoch [46/50], Step [103/735], Loss: 0.3043\n",
      "Epoch [46/50], Step [104/735], Loss: 0.0990\n",
      "Epoch [46/50], Step [105/735], Loss: 0.2357\n",
      "Epoch [46/50], Step [106/735], Loss: 0.1141\n",
      "Epoch [46/50], Step [107/735], Loss: 0.1852\n",
      "Epoch [46/50], Step [108/735], Loss: 0.2516\n",
      "Epoch [46/50], Step [109/735], Loss: 0.2046\n",
      "Epoch [46/50], Step [110/735], Loss: 0.1735\n",
      "Epoch [46/50], Step [111/735], Loss: 0.3819\n",
      "Epoch [46/50], Step [112/735], Loss: 0.2493\n",
      "Epoch [46/50], Step [113/735], Loss: 0.2126\n",
      "Epoch [46/50], Step [114/735], Loss: 0.0911\n",
      "Epoch [46/50], Step [115/735], Loss: 0.4429\n",
      "Epoch [46/50], Step [116/735], Loss: 0.3855\n",
      "Epoch [46/50], Step [117/735], Loss: 0.3052\n",
      "Epoch [46/50], Step [118/735], Loss: 0.0944\n",
      "Epoch [46/50], Step [119/735], Loss: 0.3218\n",
      "Epoch [46/50], Step [120/735], Loss: 0.1290\n",
      "Epoch [46/50], Step [121/735], Loss: 0.2726\n",
      "Epoch [46/50], Step [122/735], Loss: 0.4983\n",
      "Epoch [46/50], Step [123/735], Loss: 0.2601\n",
      "Epoch [46/50], Step [124/735], Loss: 0.1077\n",
      "Epoch [46/50], Step [125/735], Loss: 0.1064\n",
      "Epoch [46/50], Step [126/735], Loss: 0.2212\n",
      "Epoch [46/50], Step [127/735], Loss: 0.2076\n",
      "Epoch [46/50], Step [128/735], Loss: 0.0577\n",
      "Epoch [46/50], Step [129/735], Loss: 0.0521\n",
      "Epoch [46/50], Step [130/735], Loss: 0.1890\n",
      "Epoch [46/50], Step [131/735], Loss: 0.2253\n",
      "Epoch [46/50], Step [132/735], Loss: 0.1287\n",
      "Epoch [46/50], Step [133/735], Loss: 1.0572\n",
      "Epoch [46/50], Step [134/735], Loss: 0.2463\n",
      "Epoch [46/50], Step [135/735], Loss: 0.1105\n",
      "Epoch [46/50], Step [136/735], Loss: 0.2131\n",
      "Epoch [46/50], Step [137/735], Loss: 0.1678\n",
      "Epoch [46/50], Step [138/735], Loss: 0.2728\n",
      "Epoch [46/50], Step [139/735], Loss: 0.2807\n",
      "Epoch [46/50], Step [140/735], Loss: 0.3313\n",
      "Epoch [46/50], Step [141/735], Loss: 0.4440\n",
      "Epoch [46/50], Step [142/735], Loss: 0.1898\n",
      "Epoch [46/50], Step [143/735], Loss: 0.3511\n",
      "Epoch [46/50], Step [144/735], Loss: 0.0640\n",
      "Epoch [46/50], Step [145/735], Loss: 0.1625\n",
      "Epoch [46/50], Step [146/735], Loss: 0.0978\n",
      "Epoch [46/50], Step [147/735], Loss: 0.1952\n",
      "Epoch [46/50], Step [148/735], Loss: 0.0934\n",
      "Epoch [46/50], Step [149/735], Loss: 0.2075\n",
      "Epoch [46/50], Step [150/735], Loss: 0.0972\n",
      "Epoch [46/50], Step [151/735], Loss: 0.5423\n",
      "Epoch [46/50], Step [152/735], Loss: 0.2288\n",
      "Epoch [46/50], Step [153/735], Loss: 0.0868\n",
      "Epoch [46/50], Step [154/735], Loss: 0.1789\n",
      "Epoch [46/50], Step [155/735], Loss: 0.3095\n",
      "Epoch [46/50], Step [156/735], Loss: 0.2143\n",
      "Epoch [46/50], Step [157/735], Loss: 0.2246\n",
      "Epoch [46/50], Step [158/735], Loss: 0.2650\n",
      "Epoch [46/50], Step [159/735], Loss: 0.1423\n",
      "Epoch [46/50], Step [160/735], Loss: 0.1768\n",
      "Epoch [46/50], Step [161/735], Loss: 0.1163\n",
      "Epoch [46/50], Step [162/735], Loss: 0.4136\n",
      "Epoch [46/50], Step [163/735], Loss: 0.8262\n",
      "Epoch [46/50], Step [164/735], Loss: 0.5487\n",
      "Epoch [46/50], Step [165/735], Loss: 0.1621\n",
      "Epoch [46/50], Step [166/735], Loss: 0.1410\n",
      "Epoch [46/50], Step [167/735], Loss: 0.1222\n",
      "Epoch [46/50], Step [168/735], Loss: 0.2069\n",
      "Epoch [46/50], Step [169/735], Loss: 0.1316\n",
      "Epoch [46/50], Step [170/735], Loss: 0.1878\n",
      "Epoch [46/50], Step [171/735], Loss: 0.1347\n",
      "Epoch [46/50], Step [172/735], Loss: 0.3174\n",
      "Epoch [46/50], Step [173/735], Loss: 0.1332\n",
      "Epoch [46/50], Step [174/735], Loss: 0.3361\n",
      "Epoch [46/50], Step [175/735], Loss: 0.1820\n",
      "Epoch [46/50], Step [176/735], Loss: 0.1897\n",
      "Epoch [46/50], Step [177/735], Loss: 0.2006\n",
      "Epoch [46/50], Step [178/735], Loss: 0.1234\n",
      "Epoch [46/50], Step [179/735], Loss: 0.1169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Step [180/735], Loss: 0.2445\n",
      "Epoch [46/50], Step [181/735], Loss: 0.1968\n",
      "Epoch [46/50], Step [182/735], Loss: 0.1415\n",
      "Epoch [46/50], Step [183/735], Loss: 0.4198\n",
      "Epoch [46/50], Step [184/735], Loss: 0.1465\n",
      "Epoch [46/50], Step [185/735], Loss: 0.1836\n",
      "Epoch [46/50], Step [186/735], Loss: 0.2448\n",
      "Epoch [46/50], Step [187/735], Loss: 0.1730\n",
      "Epoch [46/50], Step [188/735], Loss: 0.1841\n",
      "Epoch [46/50], Step [189/735], Loss: 0.1906\n",
      "Epoch [46/50], Step [190/735], Loss: 0.2692\n",
      "Epoch [46/50], Step [191/735], Loss: 0.7313\n",
      "Epoch [46/50], Step [192/735], Loss: 2.9725\n",
      "Epoch [46/50], Step [193/735], Loss: 0.0792\n",
      "Epoch [46/50], Step [194/735], Loss: 0.0816\n",
      "Epoch [46/50], Step [195/735], Loss: 0.1793\n",
      "Epoch [46/50], Step [196/735], Loss: 0.4267\n",
      "Epoch [46/50], Step [197/735], Loss: 0.1821\n",
      "Epoch [46/50], Step [198/735], Loss: 0.8493\n",
      "Epoch [46/50], Step [199/735], Loss: 0.1252\n",
      "Epoch [46/50], Step [200/735], Loss: 0.5731\n",
      "Epoch [46/50], Step [201/735], Loss: 0.1135\n",
      "Epoch [46/50], Step [202/735], Loss: 1.3528\n",
      "Epoch [46/50], Step [203/735], Loss: 0.1182\n",
      "Epoch [46/50], Step [204/735], Loss: 0.1405\n",
      "Epoch [46/50], Step [205/735], Loss: 0.1407\n",
      "Epoch [46/50], Step [206/735], Loss: 0.3622\n",
      "Epoch [46/50], Step [207/735], Loss: 0.1070\n",
      "Epoch [46/50], Step [208/735], Loss: 0.2315\n",
      "Epoch [46/50], Step [209/735], Loss: 0.3618\n",
      "Epoch [46/50], Step [210/735], Loss: 0.4052\n",
      "Epoch [46/50], Step [211/735], Loss: 0.1567\n",
      "Epoch [46/50], Step [212/735], Loss: 0.2729\n",
      "Epoch [46/50], Step [213/735], Loss: 0.4176\n",
      "Epoch [46/50], Step [214/735], Loss: 0.1565\n",
      "Epoch [46/50], Step [215/735], Loss: 0.2672\n",
      "Epoch [46/50], Step [216/735], Loss: 0.2046\n",
      "Epoch [46/50], Step [217/735], Loss: 0.2699\n",
      "Epoch [46/50], Step [218/735], Loss: 0.1551\n",
      "Epoch [46/50], Step [219/735], Loss: 0.3372\n",
      "Epoch [46/50], Step [220/735], Loss: 0.2508\n",
      "Epoch [46/50], Step [221/735], Loss: 0.2356\n",
      "Epoch [46/50], Step [222/735], Loss: 0.1257\n",
      "Epoch [46/50], Step [223/735], Loss: 0.2438\n",
      "Epoch [46/50], Step [224/735], Loss: 0.6745\n",
      "Epoch [46/50], Step [225/735], Loss: 0.2390\n",
      "Epoch [46/50], Step [226/735], Loss: 0.4822\n",
      "Epoch [46/50], Step [227/735], Loss: 0.2246\n",
      "Epoch [46/50], Step [228/735], Loss: 0.2080\n",
      "Epoch [46/50], Step [229/735], Loss: 0.1451\n",
      "Epoch [46/50], Step [230/735], Loss: 0.4301\n",
      "Epoch [46/50], Step [231/735], Loss: 0.3615\n",
      "Epoch [46/50], Step [232/735], Loss: 0.2358\n",
      "Epoch [46/50], Step [233/735], Loss: 0.0730\n",
      "Epoch [46/50], Step [234/735], Loss: 0.2222\n",
      "Epoch [46/50], Step [235/735], Loss: 0.1444\n",
      "Epoch [46/50], Step [236/735], Loss: 0.1785\n",
      "Epoch [46/50], Step [237/735], Loss: 0.5978\n",
      "Epoch [46/50], Step [238/735], Loss: 0.1493\n",
      "Epoch [46/50], Step [239/735], Loss: 0.2323\n",
      "Epoch [46/50], Step [240/735], Loss: 0.1507\n",
      "Epoch [46/50], Step [241/735], Loss: 0.2334\n",
      "Epoch [46/50], Step [242/735], Loss: 0.1705\n",
      "Epoch [46/50], Step [243/735], Loss: 0.6753\n",
      "Epoch [46/50], Step [244/735], Loss: 0.1241\n",
      "Epoch [46/50], Step [245/735], Loss: 0.3170\n",
      "Epoch [46/50], Step [246/735], Loss: 0.0948\n",
      "Epoch [46/50], Step [247/735], Loss: 0.1796\n",
      "Epoch [46/50], Step [248/735], Loss: 0.1648\n",
      "Epoch [46/50], Step [249/735], Loss: 0.4314\n",
      "Epoch [46/50], Step [250/735], Loss: 0.2765\n",
      "Epoch [46/50], Step [251/735], Loss: 0.3090\n",
      "Epoch [46/50], Step [252/735], Loss: 0.1751\n",
      "Epoch [46/50], Step [253/735], Loss: 0.4442\n",
      "Epoch [46/50], Step [254/735], Loss: 0.3063\n",
      "Epoch [46/50], Step [255/735], Loss: 0.1878\n",
      "Epoch [46/50], Step [256/735], Loss: 0.3099\n",
      "Epoch [46/50], Step [257/735], Loss: 0.1653\n",
      "Epoch [46/50], Step [258/735], Loss: 0.1844\n",
      "Epoch [46/50], Step [259/735], Loss: 0.0511\n",
      "Epoch [46/50], Step [260/735], Loss: 0.1921\n",
      "Epoch [46/50], Step [261/735], Loss: 0.2395\n",
      "Epoch [46/50], Step [262/735], Loss: 0.4494\n",
      "Epoch [46/50], Step [263/735], Loss: 0.1246\n",
      "Epoch [46/50], Step [264/735], Loss: 0.0571\n",
      "Epoch [46/50], Step [265/735], Loss: 0.1142\n",
      "Epoch [46/50], Step [266/735], Loss: 0.3514\n",
      "Epoch [46/50], Step [267/735], Loss: 0.2959\n",
      "Epoch [46/50], Step [268/735], Loss: 0.1999\n",
      "Epoch [46/50], Step [269/735], Loss: 0.1317\n",
      "Epoch [46/50], Step [270/735], Loss: 0.2838\n",
      "Epoch [46/50], Step [271/735], Loss: 0.1500\n",
      "Epoch [46/50], Step [272/735], Loss: 0.2710\n",
      "Epoch [46/50], Step [273/735], Loss: 0.4609\n",
      "Epoch [46/50], Step [274/735], Loss: 0.2840\n",
      "Epoch [46/50], Step [275/735], Loss: 0.1342\n",
      "Epoch [46/50], Step [276/735], Loss: 0.1012\n",
      "Epoch [46/50], Step [277/735], Loss: 0.0994\n",
      "Epoch [46/50], Step [278/735], Loss: 0.1209\n",
      "Epoch [46/50], Step [279/735], Loss: 0.2821\n",
      "Epoch [46/50], Step [280/735], Loss: 0.3894\n",
      "Epoch [46/50], Step [281/735], Loss: 0.1893\n",
      "Epoch [46/50], Step [282/735], Loss: 0.0625\n",
      "Epoch [46/50], Step [283/735], Loss: 0.2655\n",
      "Epoch [46/50], Step [284/735], Loss: 0.4437\n",
      "Epoch [46/50], Step [285/735], Loss: 0.0676\n",
      "Epoch [46/50], Step [286/735], Loss: 0.2007\n",
      "Epoch [46/50], Step [287/735], Loss: 0.3060\n",
      "Epoch [46/50], Step [288/735], Loss: 0.5020\n",
      "Epoch [46/50], Step [289/735], Loss: 0.2415\n",
      "Epoch [46/50], Step [290/735], Loss: 0.5901\n",
      "Epoch [46/50], Step [291/735], Loss: 0.0606\n",
      "Epoch [46/50], Step [292/735], Loss: 0.1596\n",
      "Epoch [46/50], Step [293/735], Loss: 0.2077\n",
      "Epoch [46/50], Step [294/735], Loss: 0.1608\n",
      "Epoch [46/50], Step [295/735], Loss: 0.3114\n",
      "Epoch [46/50], Step [296/735], Loss: 0.4333\n",
      "Epoch [46/50], Step [297/735], Loss: 0.2167\n",
      "Epoch [46/50], Step [298/735], Loss: 0.0435\n",
      "Epoch [46/50], Step [299/735], Loss: 0.1229\n",
      "Epoch [46/50], Step [300/735], Loss: 0.2132\n",
      "Epoch [46/50], Step [301/735], Loss: 0.1028\n",
      "Epoch [46/50], Step [302/735], Loss: 0.1913\n",
      "Epoch [46/50], Step [303/735], Loss: 0.2027\n",
      "Epoch [46/50], Step [304/735], Loss: 1.4460\n",
      "Epoch [46/50], Step [305/735], Loss: 0.4477\n",
      "Epoch [46/50], Step [306/735], Loss: 0.1977\n",
      "Epoch [46/50], Step [307/735], Loss: 0.2456\n",
      "Epoch [46/50], Step [308/735], Loss: 0.3668\n",
      "Epoch [46/50], Step [309/735], Loss: 0.0899\n",
      "Epoch [46/50], Step [310/735], Loss: 0.4967\n",
      "Epoch [46/50], Step [311/735], Loss: 0.3439\n",
      "Epoch [46/50], Step [312/735], Loss: 0.5889\n",
      "Epoch [46/50], Step [313/735], Loss: 0.2716\n",
      "Epoch [46/50], Step [314/735], Loss: 0.3481\n",
      "Epoch [46/50], Step [315/735], Loss: 0.3677\n",
      "Epoch [46/50], Step [316/735], Loss: 0.0445\n",
      "Epoch [46/50], Step [317/735], Loss: 0.2673\n",
      "Epoch [46/50], Step [318/735], Loss: 0.0959\n",
      "Epoch [46/50], Step [319/735], Loss: 0.5001\n",
      "Epoch [46/50], Step [320/735], Loss: 0.2129\n",
      "Epoch [46/50], Step [321/735], Loss: 0.2322\n",
      "Epoch [46/50], Step [322/735], Loss: 0.2581\n",
      "Epoch [46/50], Step [323/735], Loss: 0.0427\n",
      "Epoch [46/50], Step [324/735], Loss: 0.2445\n",
      "Epoch [46/50], Step [325/735], Loss: 0.4528\n",
      "Epoch [46/50], Step [326/735], Loss: 0.1307\n",
      "Epoch [46/50], Step [327/735], Loss: 0.0873\n",
      "Epoch [46/50], Step [328/735], Loss: 0.1544\n",
      "Epoch [46/50], Step [329/735], Loss: 0.6311\n",
      "Epoch [46/50], Step [330/735], Loss: 0.1606\n",
      "Epoch [46/50], Step [331/735], Loss: 0.0946\n",
      "Epoch [46/50], Step [332/735], Loss: 0.1323\n",
      "Epoch [46/50], Step [333/735], Loss: 0.1753\n",
      "Epoch [46/50], Step [334/735], Loss: 0.2536\n",
      "Epoch [46/50], Step [335/735], Loss: 0.2704\n",
      "Epoch [46/50], Step [336/735], Loss: 0.2389\n",
      "Epoch [46/50], Step [337/735], Loss: 0.1447\n",
      "Epoch [46/50], Step [338/735], Loss: 0.0324\n",
      "Epoch [46/50], Step [339/735], Loss: 0.0496\n",
      "Epoch [46/50], Step [340/735], Loss: 0.3484\n",
      "Epoch [46/50], Step [341/735], Loss: 0.1527\n",
      "Epoch [46/50], Step [342/735], Loss: 0.0871\n",
      "Epoch [46/50], Step [343/735], Loss: 0.8452\n",
      "Epoch [46/50], Step [344/735], Loss: 0.1641\n",
      "Epoch [46/50], Step [345/735], Loss: 0.1394\n",
      "Epoch [46/50], Step [346/735], Loss: 0.1127\n",
      "Epoch [46/50], Step [347/735], Loss: 0.1910\n",
      "Epoch [46/50], Step [348/735], Loss: 3.3654\n",
      "Epoch [46/50], Step [349/735], Loss: 0.5463\n",
      "Epoch [46/50], Step [350/735], Loss: 0.2063\n",
      "Epoch [46/50], Step [351/735], Loss: 0.6794\n",
      "Epoch [46/50], Step [352/735], Loss: 0.3181\n",
      "Epoch [46/50], Step [353/735], Loss: 0.2446\n",
      "Epoch [46/50], Step [354/735], Loss: 0.0744\n",
      "Epoch [46/50], Step [355/735], Loss: 0.1668\n",
      "Epoch [46/50], Step [356/735], Loss: 0.2029\n",
      "Epoch [46/50], Step [357/735], Loss: 0.3806\n",
      "Epoch [46/50], Step [358/735], Loss: 0.5179\n",
      "Epoch [46/50], Step [359/735], Loss: 0.3657\n",
      "Epoch [46/50], Step [360/735], Loss: 0.5074\n",
      "Epoch [46/50], Step [361/735], Loss: 0.2425\n",
      "Epoch [46/50], Step [362/735], Loss: 0.1667\n",
      "Epoch [46/50], Step [363/735], Loss: 0.2086\n",
      "Epoch [46/50], Step [364/735], Loss: 0.5692\n",
      "Epoch [46/50], Step [365/735], Loss: 0.1456\n",
      "Epoch [46/50], Step [366/735], Loss: 0.1089\n",
      "Epoch [46/50], Step [367/735], Loss: 0.1426\n",
      "Epoch [46/50], Step [368/735], Loss: 0.1880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Step [369/735], Loss: 0.3739\n",
      "Epoch [46/50], Step [370/735], Loss: 0.5114\n",
      "Epoch [46/50], Step [371/735], Loss: 0.2319\n",
      "Epoch [46/50], Step [372/735], Loss: 0.2306\n",
      "Epoch [46/50], Step [373/735], Loss: 0.3149\n",
      "Epoch [46/50], Step [374/735], Loss: 0.1382\n",
      "Epoch [46/50], Step [375/735], Loss: 0.4017\n",
      "Epoch [46/50], Step [376/735], Loss: 0.2119\n",
      "Epoch [46/50], Step [377/735], Loss: 0.2620\n",
      "Epoch [46/50], Step [378/735], Loss: 0.1475\n",
      "Epoch [46/50], Step [379/735], Loss: 0.1928\n",
      "Epoch [46/50], Step [380/735], Loss: 0.1708\n",
      "Epoch [46/50], Step [381/735], Loss: 0.7776\n",
      "Epoch [46/50], Step [382/735], Loss: 0.5130\n",
      "Epoch [46/50], Step [383/735], Loss: 0.3855\n",
      "Epoch [46/50], Step [384/735], Loss: 0.5417\n",
      "Epoch [46/50], Step [385/735], Loss: 0.1353\n",
      "Epoch [46/50], Step [386/735], Loss: 0.1980\n",
      "Epoch [46/50], Step [387/735], Loss: 0.2502\n",
      "Epoch [46/50], Step [388/735], Loss: 0.4477\n",
      "Epoch [46/50], Step [389/735], Loss: 0.1077\n",
      "Epoch [46/50], Step [390/735], Loss: 0.2754\n",
      "Epoch [46/50], Step [391/735], Loss: 0.1460\n",
      "Epoch [46/50], Step [392/735], Loss: 0.3993\n",
      "Epoch [46/50], Step [393/735], Loss: 0.5221\n",
      "Epoch [46/50], Step [394/735], Loss: 0.2973\n",
      "Epoch [46/50], Step [395/735], Loss: 0.2631\n",
      "Epoch [46/50], Step [396/735], Loss: 0.1765\n",
      "Epoch [46/50], Step [397/735], Loss: 0.1378\n",
      "Epoch [46/50], Step [398/735], Loss: 0.2286\n",
      "Epoch [46/50], Step [399/735], Loss: 0.6076\n",
      "Epoch [46/50], Step [400/735], Loss: 0.3375\n",
      "Epoch [46/50], Step [401/735], Loss: 0.2322\n",
      "Epoch [46/50], Step [402/735], Loss: 0.2877\n",
      "Epoch [46/50], Step [403/735], Loss: 0.2576\n",
      "Epoch [46/50], Step [404/735], Loss: 0.1636\n",
      "Epoch [46/50], Step [405/735], Loss: 0.1972\n",
      "Epoch [46/50], Step [406/735], Loss: 0.2743\n",
      "Epoch [46/50], Step [407/735], Loss: 0.2044\n",
      "Epoch [46/50], Step [408/735], Loss: 0.6570\n",
      "Epoch [46/50], Step [409/735], Loss: 0.1269\n",
      "Epoch [46/50], Step [410/735], Loss: 0.2109\n",
      "Epoch [46/50], Step [411/735], Loss: 0.4697\n",
      "Epoch [46/50], Step [412/735], Loss: 0.1037\n",
      "Epoch [46/50], Step [413/735], Loss: 0.2551\n",
      "Epoch [46/50], Step [414/735], Loss: 0.1474\n",
      "Epoch [46/50], Step [415/735], Loss: 0.2580\n",
      "Epoch [46/50], Step [416/735], Loss: 0.1197\n",
      "Epoch [46/50], Step [417/735], Loss: 0.1889\n",
      "Epoch [46/50], Step [418/735], Loss: 0.1207\n",
      "Epoch [46/50], Step [419/735], Loss: 0.1765\n",
      "Epoch [46/50], Step [420/735], Loss: 0.1942\n",
      "Epoch [46/50], Step [421/735], Loss: 0.2245\n",
      "Epoch [46/50], Step [422/735], Loss: 0.6251\n",
      "Epoch [46/50], Step [423/735], Loss: 0.3930\n",
      "Epoch [46/50], Step [424/735], Loss: 0.7696\n",
      "Epoch [46/50], Step [425/735], Loss: 0.0776\n",
      "Epoch [46/50], Step [426/735], Loss: 0.2269\n",
      "Epoch [46/50], Step [427/735], Loss: 0.3682\n",
      "Epoch [46/50], Step [428/735], Loss: 0.2085\n",
      "Epoch [46/50], Step [429/735], Loss: 0.0804\n",
      "Epoch [46/50], Step [430/735], Loss: 0.4240\n",
      "Epoch [46/50], Step [431/735], Loss: 0.1837\n",
      "Epoch [46/50], Step [432/735], Loss: 0.2682\n",
      "Epoch [46/50], Step [433/735], Loss: 0.2839\n",
      "Epoch [46/50], Step [434/735], Loss: 0.3621\n",
      "Epoch [46/50], Step [435/735], Loss: 0.1287\n",
      "Epoch [46/50], Step [436/735], Loss: 0.0755\n",
      "Epoch [46/50], Step [437/735], Loss: 0.1923\n",
      "Epoch [46/50], Step [438/735], Loss: 0.1232\n",
      "Epoch [46/50], Step [439/735], Loss: 0.1850\n",
      "Epoch [46/50], Step [440/735], Loss: 0.0966\n",
      "Epoch [46/50], Step [441/735], Loss: 0.1200\n",
      "Epoch [46/50], Step [442/735], Loss: 0.2675\n",
      "Epoch [46/50], Step [443/735], Loss: 0.3836\n",
      "Epoch [46/50], Step [444/735], Loss: 0.2300\n",
      "Epoch [46/50], Step [445/735], Loss: 0.3551\n",
      "Epoch [46/50], Step [446/735], Loss: 0.2128\n",
      "Epoch [46/50], Step [447/735], Loss: 0.5730\n",
      "Epoch [46/50], Step [448/735], Loss: 0.0962\n",
      "Epoch [46/50], Step [449/735], Loss: 0.2039\n",
      "Epoch [46/50], Step [450/735], Loss: 0.1310\n",
      "Epoch [46/50], Step [451/735], Loss: 0.2111\n",
      "Epoch [46/50], Step [452/735], Loss: 0.1128\n",
      "Epoch [46/50], Step [453/735], Loss: 0.2222\n",
      "Epoch [46/50], Step [454/735], Loss: 0.2856\n",
      "Epoch [46/50], Step [455/735], Loss: 0.3622\n",
      "Epoch [46/50], Step [456/735], Loss: 0.1005\n",
      "Epoch [46/50], Step [457/735], Loss: 0.3450\n",
      "Epoch [46/50], Step [458/735], Loss: 0.2469\n",
      "Epoch [46/50], Step [459/735], Loss: 0.3133\n",
      "Epoch [46/50], Step [460/735], Loss: 0.2121\n",
      "Epoch [46/50], Step [461/735], Loss: 0.1616\n",
      "Epoch [46/50], Step [462/735], Loss: 0.2390\n",
      "Epoch [46/50], Step [463/735], Loss: 0.0438\n",
      "Epoch [46/50], Step [464/735], Loss: 0.1209\n",
      "Epoch [46/50], Step [465/735], Loss: 0.1347\n",
      "Epoch [46/50], Step [466/735], Loss: 0.2348\n",
      "Epoch [46/50], Step [467/735], Loss: 0.0750\n",
      "Epoch [46/50], Step [468/735], Loss: 0.0785\n",
      "Epoch [46/50], Step [469/735], Loss: 2.9534\n",
      "Epoch [46/50], Step [470/735], Loss: 0.6066\n",
      "Epoch [46/50], Step [471/735], Loss: 0.3084\n",
      "Epoch [46/50], Step [472/735], Loss: 0.1726\n",
      "Epoch [46/50], Step [473/735], Loss: 0.0750\n",
      "Epoch [46/50], Step [474/735], Loss: 0.1616\n",
      "Epoch [46/50], Step [475/735], Loss: 0.1465\n",
      "Epoch [46/50], Step [476/735], Loss: 0.2066\n",
      "Epoch [46/50], Step [477/735], Loss: 0.2514\n",
      "Epoch [46/50], Step [478/735], Loss: 0.1752\n",
      "Epoch [46/50], Step [479/735], Loss: 0.1108\n",
      "Epoch [46/50], Step [480/735], Loss: 0.0896\n",
      "Epoch [46/50], Step [481/735], Loss: 0.0676\n",
      "Epoch [46/50], Step [482/735], Loss: 0.3840\n",
      "Epoch [46/50], Step [483/735], Loss: 0.1917\n",
      "Epoch [46/50], Step [484/735], Loss: 0.1832\n",
      "Epoch [46/50], Step [485/735], Loss: 0.5623\n",
      "Epoch [46/50], Step [486/735], Loss: 0.0901\n",
      "Epoch [46/50], Step [487/735], Loss: 0.2220\n",
      "Epoch [46/50], Step [488/735], Loss: 0.0655\n",
      "Epoch [46/50], Step [489/735], Loss: 0.2032\n",
      "Epoch [46/50], Step [490/735], Loss: 0.1907\n",
      "Epoch [46/50], Step [491/735], Loss: 0.1058\n",
      "Epoch [46/50], Step [492/735], Loss: 0.2047\n",
      "Epoch [46/50], Step [493/735], Loss: 0.3045\n",
      "Epoch [46/50], Step [494/735], Loss: 0.1465\n",
      "Epoch [46/50], Step [495/735], Loss: 0.1339\n",
      "Epoch [46/50], Step [496/735], Loss: 0.1037\n",
      "Epoch [46/50], Step [497/735], Loss: 0.3711\n",
      "Epoch [46/50], Step [498/735], Loss: 0.1693\n",
      "Epoch [46/50], Step [499/735], Loss: 0.2724\n",
      "Epoch [46/50], Step [500/735], Loss: 0.2727\n",
      "Epoch [46/50], Step [501/735], Loss: 0.1994\n",
      "Epoch [46/50], Step [502/735], Loss: 0.1931\n",
      "Epoch [46/50], Step [503/735], Loss: 0.2085\n",
      "Epoch [46/50], Step [504/735], Loss: 0.1907\n",
      "Epoch [46/50], Step [505/735], Loss: 0.3259\n",
      "Epoch [46/50], Step [506/735], Loss: 0.1262\n",
      "Epoch [46/50], Step [507/735], Loss: 0.0707\n",
      "Epoch [46/50], Step [508/735], Loss: 0.1658\n",
      "Epoch [46/50], Step [509/735], Loss: 0.0832\n",
      "Epoch [46/50], Step [510/735], Loss: 0.5024\n",
      "Epoch [46/50], Step [511/735], Loss: 0.1507\n",
      "Epoch [46/50], Step [512/735], Loss: 0.3157\n",
      "Epoch [46/50], Step [513/735], Loss: 0.4054\n",
      "Epoch [46/50], Step [514/735], Loss: 0.1922\n",
      "Epoch [46/50], Step [515/735], Loss: 0.1150\n",
      "Epoch [46/50], Step [516/735], Loss: 0.3653\n",
      "Epoch [46/50], Step [517/735], Loss: 0.0690\n",
      "Epoch [46/50], Step [518/735], Loss: 0.1275\n",
      "Epoch [46/50], Step [519/735], Loss: 0.2417\n",
      "Epoch [46/50], Step [520/735], Loss: 0.1886\n",
      "Epoch [46/50], Step [521/735], Loss: 0.4103\n",
      "Epoch [46/50], Step [522/735], Loss: 0.2181\n",
      "Epoch [46/50], Step [523/735], Loss: 0.1926\n",
      "Epoch [46/50], Step [524/735], Loss: 0.3007\n",
      "Epoch [46/50], Step [525/735], Loss: 0.1165\n",
      "Epoch [46/50], Step [526/735], Loss: 0.4623\n",
      "Epoch [46/50], Step [527/735], Loss: 0.5704\n",
      "Epoch [46/50], Step [528/735], Loss: 0.1702\n",
      "Epoch [46/50], Step [529/735], Loss: 0.1332\n",
      "Epoch [46/50], Step [530/735], Loss: 0.3024\n",
      "Epoch [46/50], Step [531/735], Loss: 0.2794\n",
      "Epoch [46/50], Step [532/735], Loss: 0.1016\n",
      "Epoch [46/50], Step [533/735], Loss: 0.1599\n",
      "Epoch [46/50], Step [534/735], Loss: 0.2366\n",
      "Epoch [46/50], Step [535/735], Loss: 0.2245\n",
      "Epoch [46/50], Step [536/735], Loss: 0.2957\n",
      "Epoch [46/50], Step [537/735], Loss: 0.1381\n",
      "Epoch [46/50], Step [538/735], Loss: 0.2020\n",
      "Epoch [46/50], Step [539/735], Loss: 0.2825\n",
      "Epoch [46/50], Step [540/735], Loss: 0.1975\n",
      "Epoch [46/50], Step [541/735], Loss: 0.0945\n",
      "Epoch [46/50], Step [542/735], Loss: 0.3159\n",
      "Epoch [46/50], Step [543/735], Loss: 0.4926\n",
      "Epoch [46/50], Step [544/735], Loss: 0.4407\n",
      "Epoch [46/50], Step [545/735], Loss: 0.2361\n",
      "Epoch [46/50], Step [546/735], Loss: 0.3556\n",
      "Epoch [46/50], Step [547/735], Loss: 0.2315\n",
      "Epoch [46/50], Step [548/735], Loss: 0.1192\n",
      "Epoch [46/50], Step [549/735], Loss: 0.1297\n",
      "Epoch [46/50], Step [550/735], Loss: 0.1458\n",
      "Epoch [46/50], Step [551/735], Loss: 0.2828\n",
      "Epoch [46/50], Step [552/735], Loss: 0.2294\n",
      "Epoch [46/50], Step [553/735], Loss: 0.4118\n",
      "Epoch [46/50], Step [554/735], Loss: 0.1835\n",
      "Epoch [46/50], Step [555/735], Loss: 0.1386\n",
      "Epoch [46/50], Step [556/735], Loss: 0.2029\n",
      "Epoch [46/50], Step [557/735], Loss: 0.1693\n",
      "Epoch [46/50], Step [558/735], Loss: 0.1465\n",
      "Epoch [46/50], Step [559/735], Loss: 0.3438\n",
      "Epoch [46/50], Step [560/735], Loss: 0.2941\n",
      "Epoch [46/50], Step [561/735], Loss: 0.1569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Step [562/735], Loss: 0.4740\n",
      "Epoch [46/50], Step [563/735], Loss: 0.6976\n",
      "Epoch [46/50], Step [564/735], Loss: 0.1444\n",
      "Epoch [46/50], Step [565/735], Loss: 0.2706\n",
      "Epoch [46/50], Step [566/735], Loss: 0.5926\n",
      "Epoch [46/50], Step [567/735], Loss: 0.1141\n",
      "Epoch [46/50], Step [568/735], Loss: 0.2480\n",
      "Epoch [46/50], Step [569/735], Loss: 0.1096\n",
      "Epoch [46/50], Step [570/735], Loss: 0.2871\n",
      "Epoch [46/50], Step [571/735], Loss: 0.2245\n",
      "Epoch [46/50], Step [572/735], Loss: 0.0898\n",
      "Epoch [46/50], Step [573/735], Loss: 0.3615\n",
      "Epoch [46/50], Step [574/735], Loss: 0.3337\n",
      "Epoch [46/50], Step [575/735], Loss: 0.3769\n",
      "Epoch [46/50], Step [576/735], Loss: 0.2628\n",
      "Epoch [46/50], Step [577/735], Loss: 0.6112\n",
      "Epoch [46/50], Step [578/735], Loss: 0.1342\n",
      "Epoch [46/50], Step [579/735], Loss: 0.3966\n",
      "Epoch [46/50], Step [580/735], Loss: 3.4895\n",
      "Epoch [46/50], Step [581/735], Loss: 0.5615\n",
      "Epoch [46/50], Step [582/735], Loss: 0.2124\n",
      "Epoch [46/50], Step [583/735], Loss: 0.1427\n",
      "Epoch [46/50], Step [584/735], Loss: 0.5251\n",
      "Epoch [46/50], Step [585/735], Loss: 0.2039\n",
      "Epoch [46/50], Step [586/735], Loss: 0.2740\n",
      "Epoch [46/50], Step [587/735], Loss: 0.3500\n",
      "Epoch [46/50], Step [588/735], Loss: 0.4884\n",
      "Epoch [46/50], Step [589/735], Loss: 0.0960\n",
      "Epoch [46/50], Step [590/735], Loss: 0.2923\n",
      "Epoch [46/50], Step [591/735], Loss: 0.3950\n",
      "Epoch [46/50], Step [592/735], Loss: 0.1189\n",
      "Epoch [46/50], Step [593/735], Loss: 0.3708\n",
      "Epoch [46/50], Step [594/735], Loss: 0.1411\n",
      "Epoch [46/50], Step [595/735], Loss: 0.1780\n",
      "Epoch [46/50], Step [596/735], Loss: 0.2799\n",
      "Epoch [46/50], Step [597/735], Loss: 0.3346\n",
      "Epoch [46/50], Step [598/735], Loss: 0.1008\n",
      "Epoch [46/50], Step [599/735], Loss: 0.0782\n",
      "Epoch [46/50], Step [600/735], Loss: 0.3600\n",
      "Epoch [46/50], Step [601/735], Loss: 0.1255\n",
      "Epoch [46/50], Step [602/735], Loss: 0.1888\n",
      "Epoch [46/50], Step [603/735], Loss: 0.2404\n",
      "Epoch [46/50], Step [604/735], Loss: 0.3258\n",
      "Epoch [46/50], Step [605/735], Loss: 0.1716\n",
      "Epoch [46/50], Step [606/735], Loss: 0.1136\n",
      "Epoch [46/50], Step [607/735], Loss: 0.1941\n",
      "Epoch [46/50], Step [608/735], Loss: 0.5366\n",
      "Epoch [46/50], Step [609/735], Loss: 0.2364\n",
      "Epoch [46/50], Step [610/735], Loss: 0.5641\n",
      "Epoch [46/50], Step [611/735], Loss: 0.0437\n",
      "Epoch [46/50], Step [612/735], Loss: 0.1250\n",
      "Epoch [46/50], Step [613/735], Loss: 0.1631\n",
      "Epoch [46/50], Step [614/735], Loss: 0.2207\n",
      "Epoch [46/50], Step [615/735], Loss: 0.2222\n",
      "Epoch [46/50], Step [616/735], Loss: 0.2981\n",
      "Epoch [46/50], Step [617/735], Loss: 0.1148\n",
      "Epoch [46/50], Step [618/735], Loss: 0.3261\n",
      "Epoch [46/50], Step [619/735], Loss: 0.1539\n",
      "Epoch [46/50], Step [620/735], Loss: 0.1527\n",
      "Epoch [46/50], Step [621/735], Loss: 0.2104\n",
      "Epoch [46/50], Step [622/735], Loss: 0.1935\n",
      "Epoch [46/50], Step [623/735], Loss: 0.4729\n",
      "Epoch [46/50], Step [624/735], Loss: 0.0869\n",
      "Epoch [46/50], Step [625/735], Loss: 0.1203\n",
      "Epoch [46/50], Step [626/735], Loss: 1.3027\n",
      "Epoch [46/50], Step [627/735], Loss: 0.4705\n",
      "Epoch [46/50], Step [628/735], Loss: 0.3598\n",
      "Epoch [46/50], Step [629/735], Loss: 0.1121\n",
      "Epoch [46/50], Step [630/735], Loss: 0.3083\n",
      "Epoch [46/50], Step [631/735], Loss: 0.1583\n",
      "Epoch [46/50], Step [632/735], Loss: 0.6324\n",
      "Epoch [46/50], Step [633/735], Loss: 0.2828\n",
      "Epoch [46/50], Step [634/735], Loss: 0.0729\n",
      "Epoch [46/50], Step [635/735], Loss: 0.0642\n",
      "Epoch [46/50], Step [636/735], Loss: 0.2263\n",
      "Epoch [46/50], Step [637/735], Loss: 0.3273\n",
      "Epoch [46/50], Step [638/735], Loss: 0.1080\n",
      "Epoch [46/50], Step [639/735], Loss: 0.1536\n",
      "Epoch [46/50], Step [640/735], Loss: 0.4161\n",
      "Epoch [46/50], Step [641/735], Loss: 0.1827\n",
      "Epoch [46/50], Step [642/735], Loss: 0.3434\n",
      "Epoch [46/50], Step [643/735], Loss: 0.3212\n",
      "Epoch [46/50], Step [644/735], Loss: 0.0888\n",
      "Epoch [46/50], Step [645/735], Loss: 0.1704\n",
      "Epoch [46/50], Step [646/735], Loss: 0.4769\n",
      "Epoch [46/50], Step [647/735], Loss: 0.1378\n",
      "Epoch [46/50], Step [648/735], Loss: 0.4261\n",
      "Epoch [46/50], Step [649/735], Loss: 0.0643\n",
      "Epoch [46/50], Step [650/735], Loss: 0.3600\n",
      "Epoch [46/50], Step [651/735], Loss: 0.6450\n",
      "Epoch [46/50], Step [652/735], Loss: 0.1819\n",
      "Epoch [46/50], Step [653/735], Loss: 0.1644\n",
      "Epoch [46/50], Step [654/735], Loss: 0.3000\n",
      "Epoch [46/50], Step [655/735], Loss: 0.2469\n",
      "Epoch [46/50], Step [656/735], Loss: 2.5417\n",
      "Epoch [46/50], Step [657/735], Loss: 0.1030\n",
      "Epoch [46/50], Step [658/735], Loss: 0.4251\n",
      "Epoch [46/50], Step [659/735], Loss: 0.0844\n",
      "Epoch [46/50], Step [660/735], Loss: 0.1664\n",
      "Epoch [46/50], Step [661/735], Loss: 0.4573\n",
      "Epoch [46/50], Step [662/735], Loss: 0.2473\n",
      "Epoch [46/50], Step [663/735], Loss: 0.2196\n",
      "Epoch [46/50], Step [664/735], Loss: 0.6962\n",
      "Epoch [46/50], Step [665/735], Loss: 0.1876\n",
      "Epoch [46/50], Step [666/735], Loss: 0.1675\n",
      "Epoch [46/50], Step [667/735], Loss: 0.3417\n",
      "Epoch [46/50], Step [668/735], Loss: 0.2644\n",
      "Epoch [46/50], Step [669/735], Loss: 0.3470\n",
      "Epoch [46/50], Step [670/735], Loss: 0.1278\n",
      "Epoch [46/50], Step [671/735], Loss: 0.3195\n",
      "Epoch [46/50], Step [672/735], Loss: 0.1977\n",
      "Epoch [46/50], Step [673/735], Loss: 0.6141\n",
      "Epoch [46/50], Step [674/735], Loss: 0.3014\n",
      "Epoch [46/50], Step [675/735], Loss: 0.0903\n",
      "Epoch [46/50], Step [676/735], Loss: 0.0934\n",
      "Epoch [46/50], Step [677/735], Loss: 1.3444\n",
      "Epoch [46/50], Step [678/735], Loss: 0.3260\n",
      "Epoch [46/50], Step [679/735], Loss: 0.1480\n",
      "Epoch [46/50], Step [680/735], Loss: 0.0791\n",
      "Epoch [46/50], Step [681/735], Loss: 0.1575\n",
      "Epoch [46/50], Step [682/735], Loss: 0.1993\n",
      "Epoch [46/50], Step [683/735], Loss: 0.5340\n",
      "Epoch [46/50], Step [684/735], Loss: 0.2416\n",
      "Epoch [46/50], Step [685/735], Loss: 0.2682\n",
      "Epoch [46/50], Step [686/735], Loss: 0.5289\n",
      "Epoch [46/50], Step [687/735], Loss: 0.1189\n",
      "Epoch [46/50], Step [688/735], Loss: 0.2390\n",
      "Epoch [46/50], Step [689/735], Loss: 0.1398\n",
      "Epoch [46/50], Step [690/735], Loss: 0.4979\n",
      "Epoch [46/50], Step [691/735], Loss: 0.1876\n",
      "Epoch [46/50], Step [692/735], Loss: 0.7393\n",
      "Epoch [46/50], Step [693/735], Loss: 0.3940\n",
      "Epoch [46/50], Step [694/735], Loss: 0.3899\n",
      "Epoch [46/50], Step [695/735], Loss: 0.1560\n",
      "Epoch [46/50], Step [696/735], Loss: 0.2395\n",
      "Epoch [46/50], Step [697/735], Loss: 0.1550\n",
      "Epoch [46/50], Step [698/735], Loss: 0.2353\n",
      "Epoch [46/50], Step [699/735], Loss: 0.1961\n",
      "Epoch [46/50], Step [700/735], Loss: 0.3752\n",
      "Epoch [46/50], Step [701/735], Loss: 0.2293\n",
      "Epoch [46/50], Step [702/735], Loss: 0.3330\n",
      "Epoch [46/50], Step [703/735], Loss: 0.1537\n",
      "Epoch [46/50], Step [704/735], Loss: 0.2564\n",
      "Epoch [46/50], Step [705/735], Loss: 0.3414\n",
      "Epoch [46/50], Step [706/735], Loss: 0.1393\n",
      "Epoch [46/50], Step [707/735], Loss: 0.0977\n",
      "Epoch [46/50], Step [708/735], Loss: 0.2592\n",
      "Epoch [46/50], Step [709/735], Loss: 0.3011\n",
      "Epoch [46/50], Step [710/735], Loss: 0.1484\n",
      "Epoch [46/50], Step [711/735], Loss: 0.3253\n",
      "Epoch [46/50], Step [712/735], Loss: 0.1235\n",
      "Epoch [46/50], Step [713/735], Loss: 0.2292\n",
      "Epoch [46/50], Step [714/735], Loss: 0.0722\n",
      "Epoch [46/50], Step [715/735], Loss: 0.0751\n",
      "Epoch [46/50], Step [716/735], Loss: 0.0991\n",
      "Epoch [46/50], Step [717/735], Loss: 0.1809\n",
      "Epoch [46/50], Step [718/735], Loss: 0.3371\n",
      "Epoch [46/50], Step [719/735], Loss: 0.2031\n",
      "Epoch [46/50], Step [720/735], Loss: 0.3718\n",
      "Epoch [46/50], Step [721/735], Loss: 0.2760\n",
      "Epoch [46/50], Step [722/735], Loss: 0.1253\n",
      "Epoch [46/50], Step [723/735], Loss: 0.1249\n",
      "Epoch [46/50], Step [724/735], Loss: 0.2426\n",
      "Epoch [46/50], Step [725/735], Loss: 1.0508\n",
      "Epoch [46/50], Step [726/735], Loss: 0.1133\n",
      "Epoch [46/50], Step [727/735], Loss: 0.1296\n",
      "Epoch [46/50], Step [728/735], Loss: 0.8075\n",
      "Epoch [46/50], Step [729/735], Loss: 0.1840\n",
      "Epoch [46/50], Step [730/735], Loss: 0.1126\n",
      "Epoch [46/50], Step [731/735], Loss: 0.2146\n",
      "Epoch [46/50], Step [732/735], Loss: 0.3879\n",
      "Epoch [46/50], Step [733/735], Loss: 0.2845\n",
      "Epoch [46/50], Step [734/735], Loss: 0.0934\n",
      "Epoch [46/50], Step [735/735], Loss: 0.1155\n",
      "Epoch [47/50], Step [1/735], Loss: 0.1375\n",
      "Epoch [47/50], Step [2/735], Loss: 0.0773\n",
      "Epoch [47/50], Step [3/735], Loss: 0.3699\n",
      "Epoch [47/50], Step [4/735], Loss: 0.2900\n",
      "Epoch [47/50], Step [5/735], Loss: 0.1896\n",
      "Epoch [47/50], Step [6/735], Loss: 0.3258\n",
      "Epoch [47/50], Step [7/735], Loss: 0.1781\n",
      "Epoch [47/50], Step [8/735], Loss: 0.6773\n",
      "Epoch [47/50], Step [9/735], Loss: 0.3477\n",
      "Epoch [47/50], Step [10/735], Loss: 0.2456\n",
      "Epoch [47/50], Step [11/735], Loss: 0.2178\n",
      "Epoch [47/50], Step [12/735], Loss: 0.3402\n",
      "Epoch [47/50], Step [13/735], Loss: 0.1819\n",
      "Epoch [47/50], Step [14/735], Loss: 0.2473\n",
      "Epoch [47/50], Step [15/735], Loss: 0.2040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Step [16/735], Loss: 0.3509\n",
      "Epoch [47/50], Step [17/735], Loss: 0.1920\n",
      "Epoch [47/50], Step [18/735], Loss: 0.3395\n",
      "Epoch [47/50], Step [19/735], Loss: 0.1488\n",
      "Epoch [47/50], Step [20/735], Loss: 0.3955\n",
      "Epoch [47/50], Step [21/735], Loss: 0.2302\n",
      "Epoch [47/50], Step [22/735], Loss: 0.2102\n",
      "Epoch [47/50], Step [23/735], Loss: 0.1870\n",
      "Epoch [47/50], Step [24/735], Loss: 0.2776\n",
      "Epoch [47/50], Step [25/735], Loss: 0.3454\n",
      "Epoch [47/50], Step [26/735], Loss: 0.1076\n",
      "Epoch [47/50], Step [27/735], Loss: 0.1270\n",
      "Epoch [47/50], Step [28/735], Loss: 0.3100\n",
      "Epoch [47/50], Step [29/735], Loss: 0.0651\n",
      "Epoch [47/50], Step [30/735], Loss: 0.2119\n",
      "Epoch [47/50], Step [31/735], Loss: 0.1508\n",
      "Epoch [47/50], Step [32/735], Loss: 2.4597\n",
      "Epoch [47/50], Step [33/735], Loss: 0.0558\n",
      "Epoch [47/50], Step [34/735], Loss: 0.1110\n",
      "Epoch [47/50], Step [35/735], Loss: 0.5513\n",
      "Epoch [47/50], Step [36/735], Loss: 0.1975\n",
      "Epoch [47/50], Step [37/735], Loss: 0.2559\n",
      "Epoch [47/50], Step [38/735], Loss: 0.3159\n",
      "Epoch [47/50], Step [39/735], Loss: 0.2166\n",
      "Epoch [47/50], Step [40/735], Loss: 0.2651\n",
      "Epoch [47/50], Step [41/735], Loss: 0.2417\n",
      "Epoch [47/50], Step [42/735], Loss: 0.1619\n",
      "Epoch [47/50], Step [43/735], Loss: 0.2624\n",
      "Epoch [47/50], Step [44/735], Loss: 0.2091\n",
      "Epoch [47/50], Step [45/735], Loss: 0.4143\n",
      "Epoch [47/50], Step [46/735], Loss: 0.4749\n",
      "Epoch [47/50], Step [47/735], Loss: 0.1748\n",
      "Epoch [47/50], Step [48/735], Loss: 0.2444\n",
      "Epoch [47/50], Step [49/735], Loss: 0.2953\n",
      "Epoch [47/50], Step [50/735], Loss: 0.1964\n",
      "Epoch [47/50], Step [51/735], Loss: 0.2429\n",
      "Epoch [47/50], Step [52/735], Loss: 0.2584\n",
      "Epoch [47/50], Step [53/735], Loss: 0.2788\n",
      "Epoch [47/50], Step [54/735], Loss: 0.1340\n",
      "Epoch [47/50], Step [55/735], Loss: 0.2350\n",
      "Epoch [47/50], Step [56/735], Loss: 0.2551\n",
      "Epoch [47/50], Step [57/735], Loss: 0.5130\n",
      "Epoch [47/50], Step [58/735], Loss: 0.3339\n",
      "Epoch [47/50], Step [59/735], Loss: 1.1382\n",
      "Epoch [47/50], Step [60/735], Loss: 0.4156\n",
      "Epoch [47/50], Step [61/735], Loss: 0.2049\n",
      "Epoch [47/50], Step [62/735], Loss: 0.5761\n",
      "Epoch [47/50], Step [63/735], Loss: 0.0987\n",
      "Epoch [47/50], Step [64/735], Loss: 0.2727\n",
      "Epoch [47/50], Step [65/735], Loss: 0.3300\n",
      "Epoch [47/50], Step [66/735], Loss: 0.1255\n",
      "Epoch [47/50], Step [67/735], Loss: 0.2621\n",
      "Epoch [47/50], Step [68/735], Loss: 0.2169\n",
      "Epoch [47/50], Step [69/735], Loss: 0.0895\n",
      "Epoch [47/50], Step [70/735], Loss: 0.2251\n",
      "Epoch [47/50], Step [71/735], Loss: 0.1952\n",
      "Epoch [47/50], Step [72/735], Loss: 0.1806\n",
      "Epoch [47/50], Step [73/735], Loss: 0.1104\n",
      "Epoch [47/50], Step [74/735], Loss: 0.3615\n",
      "Epoch [47/50], Step [75/735], Loss: 0.1263\n",
      "Epoch [47/50], Step [76/735], Loss: 0.2930\n",
      "Epoch [47/50], Step [77/735], Loss: 0.1697\n",
      "Epoch [47/50], Step [78/735], Loss: 0.2162\n",
      "Epoch [47/50], Step [79/735], Loss: 0.1769\n",
      "Epoch [47/50], Step [80/735], Loss: 0.1144\n",
      "Epoch [47/50], Step [81/735], Loss: 0.0680\n",
      "Epoch [47/50], Step [82/735], Loss: 0.0715\n",
      "Epoch [47/50], Step [83/735], Loss: 0.6854\n",
      "Epoch [47/50], Step [84/735], Loss: 0.2479\n",
      "Epoch [47/50], Step [85/735], Loss: 0.2728\n",
      "Epoch [47/50], Step [86/735], Loss: 0.2308\n",
      "Epoch [47/50], Step [87/735], Loss: 0.2038\n",
      "Epoch [47/50], Step [88/735], Loss: 0.1015\n",
      "Epoch [47/50], Step [89/735], Loss: 0.3944\n",
      "Epoch [47/50], Step [90/735], Loss: 0.1259\n",
      "Epoch [47/50], Step [91/735], Loss: 0.2603\n",
      "Epoch [47/50], Step [92/735], Loss: 0.1031\n",
      "Epoch [47/50], Step [93/735], Loss: 0.3483\n",
      "Epoch [47/50], Step [94/735], Loss: 0.2935\n",
      "Epoch [47/50], Step [95/735], Loss: 0.2027\n",
      "Epoch [47/50], Step [96/735], Loss: 0.3207\n",
      "Epoch [47/50], Step [97/735], Loss: 0.2069\n",
      "Epoch [47/50], Step [98/735], Loss: 0.2833\n",
      "Epoch [47/50], Step [99/735], Loss: 0.4542\n",
      "Epoch [47/50], Step [100/735], Loss: 0.1505\n",
      "Epoch [47/50], Step [101/735], Loss: 0.1208\n",
      "Epoch [47/50], Step [102/735], Loss: 0.1030\n",
      "Epoch [47/50], Step [103/735], Loss: 0.5923\n",
      "Epoch [47/50], Step [104/735], Loss: 0.1065\n",
      "Epoch [47/50], Step [105/735], Loss: 0.2597\n",
      "Epoch [47/50], Step [106/735], Loss: 0.3560\n",
      "Epoch [47/50], Step [107/735], Loss: 0.5532\n",
      "Epoch [47/50], Step [108/735], Loss: 0.4371\n",
      "Epoch [47/50], Step [109/735], Loss: 0.1213\n",
      "Epoch [47/50], Step [110/735], Loss: 0.1781\n",
      "Epoch [47/50], Step [111/735], Loss: 0.1696\n",
      "Epoch [47/50], Step [112/735], Loss: 0.0774\n",
      "Epoch [47/50], Step [113/735], Loss: 0.1318\n",
      "Epoch [47/50], Step [114/735], Loss: 0.0532\n",
      "Epoch [47/50], Step [115/735], Loss: 0.1082\n",
      "Epoch [47/50], Step [116/735], Loss: 0.1813\n",
      "Epoch [47/50], Step [117/735], Loss: 0.2320\n",
      "Epoch [47/50], Step [118/735], Loss: 0.3191\n",
      "Epoch [47/50], Step [119/735], Loss: 0.3870\n",
      "Epoch [47/50], Step [120/735], Loss: 0.1808\n",
      "Epoch [47/50], Step [121/735], Loss: 0.2198\n",
      "Epoch [47/50], Step [122/735], Loss: 0.2432\n",
      "Epoch [47/50], Step [123/735], Loss: 0.2058\n",
      "Epoch [47/50], Step [124/735], Loss: 0.0668\n",
      "Epoch [47/50], Step [125/735], Loss: 0.1217\n",
      "Epoch [47/50], Step [126/735], Loss: 0.1790\n",
      "Epoch [47/50], Step [127/735], Loss: 0.2428\n",
      "Epoch [47/50], Step [128/735], Loss: 0.2328\n",
      "Epoch [47/50], Step [129/735], Loss: 0.1957\n",
      "Epoch [47/50], Step [130/735], Loss: 0.2825\n",
      "Epoch [47/50], Step [131/735], Loss: 0.0492\n",
      "Epoch [47/50], Step [132/735], Loss: 0.1088\n",
      "Epoch [47/50], Step [133/735], Loss: 0.0944\n",
      "Epoch [47/50], Step [134/735], Loss: 0.2439\n",
      "Epoch [47/50], Step [135/735], Loss: 0.3697\n",
      "Epoch [47/50], Step [136/735], Loss: 0.1665\n",
      "Epoch [47/50], Step [137/735], Loss: 0.5830\n",
      "Epoch [47/50], Step [138/735], Loss: 0.2286\n",
      "Epoch [47/50], Step [139/735], Loss: 0.1575\n",
      "Epoch [47/50], Step [140/735], Loss: 0.8794\n",
      "Epoch [47/50], Step [141/735], Loss: 0.2293\n",
      "Epoch [47/50], Step [142/735], Loss: 0.0816\n",
      "Epoch [47/50], Step [143/735], Loss: 0.1954\n",
      "Epoch [47/50], Step [144/735], Loss: 0.4607\n",
      "Epoch [47/50], Step [145/735], Loss: 0.0903\n",
      "Epoch [47/50], Step [146/735], Loss: 0.1807\n",
      "Epoch [47/50], Step [147/735], Loss: 0.1760\n",
      "Epoch [47/50], Step [148/735], Loss: 0.1062\n",
      "Epoch [47/50], Step [149/735], Loss: 0.6551\n",
      "Epoch [47/50], Step [150/735], Loss: 0.1601\n",
      "Epoch [47/50], Step [151/735], Loss: 0.2418\n",
      "Epoch [47/50], Step [152/735], Loss: 0.2509\n",
      "Epoch [47/50], Step [153/735], Loss: 0.4479\n",
      "Epoch [47/50], Step [154/735], Loss: 0.1890\n",
      "Epoch [47/50], Step [155/735], Loss: 0.2057\n",
      "Epoch [47/50], Step [156/735], Loss: 0.1987\n",
      "Epoch [47/50], Step [157/735], Loss: 0.2951\n",
      "Epoch [47/50], Step [158/735], Loss: 0.2783\n",
      "Epoch [47/50], Step [159/735], Loss: 0.0607\n",
      "Epoch [47/50], Step [160/735], Loss: 0.2505\n",
      "Epoch [47/50], Step [161/735], Loss: 0.1580\n",
      "Epoch [47/50], Step [162/735], Loss: 0.2073\n",
      "Epoch [47/50], Step [163/735], Loss: 0.6662\n",
      "Epoch [47/50], Step [164/735], Loss: 0.1112\n",
      "Epoch [47/50], Step [165/735], Loss: 0.0651\n",
      "Epoch [47/50], Step [166/735], Loss: 0.1748\n",
      "Epoch [47/50], Step [167/735], Loss: 0.1049\n",
      "Epoch [47/50], Step [168/735], Loss: 0.1404\n",
      "Epoch [47/50], Step [169/735], Loss: 0.4188\n",
      "Epoch [47/50], Step [170/735], Loss: 0.1628\n",
      "Epoch [47/50], Step [171/735], Loss: 0.1590\n",
      "Epoch [47/50], Step [172/735], Loss: 0.2573\n",
      "Epoch [47/50], Step [173/735], Loss: 0.1342\n",
      "Epoch [47/50], Step [174/735], Loss: 0.4235\n",
      "Epoch [47/50], Step [175/735], Loss: 0.0838\n",
      "Epoch [47/50], Step [176/735], Loss: 0.1125\n",
      "Epoch [47/50], Step [177/735], Loss: 0.4672\n",
      "Epoch [47/50], Step [178/735], Loss: 0.2597\n",
      "Epoch [47/50], Step [179/735], Loss: 0.1221\n",
      "Epoch [47/50], Step [180/735], Loss: 0.1861\n",
      "Epoch [47/50], Step [181/735], Loss: 0.2332\n",
      "Epoch [47/50], Step [182/735], Loss: 0.1084\n",
      "Epoch [47/50], Step [183/735], Loss: 3.3751\n",
      "Epoch [47/50], Step [184/735], Loss: 0.5100\n",
      "Epoch [47/50], Step [185/735], Loss: 0.4009\n",
      "Epoch [47/50], Step [186/735], Loss: 0.3699\n",
      "Epoch [47/50], Step [187/735], Loss: 0.2385\n",
      "Epoch [47/50], Step [188/735], Loss: 0.4947\n",
      "Epoch [47/50], Step [189/735], Loss: 0.1700\n",
      "Epoch [47/50], Step [190/735], Loss: 0.3344\n",
      "Epoch [47/50], Step [191/735], Loss: 0.1771\n",
      "Epoch [47/50], Step [192/735], Loss: 0.3578\n",
      "Epoch [47/50], Step [193/735], Loss: 0.3286\n",
      "Epoch [47/50], Step [194/735], Loss: 0.3964\n",
      "Epoch [47/50], Step [195/735], Loss: 0.3348\n",
      "Epoch [47/50], Step [196/735], Loss: 0.4226\n",
      "Epoch [47/50], Step [197/735], Loss: 0.1988\n",
      "Epoch [47/50], Step [198/735], Loss: 0.0975\n",
      "Epoch [47/50], Step [199/735], Loss: 0.3005\n",
      "Epoch [47/50], Step [200/735], Loss: 0.5557\n",
      "Epoch [47/50], Step [201/735], Loss: 0.1979\n",
      "Epoch [47/50], Step [202/735], Loss: 0.5701\n",
      "Epoch [47/50], Step [203/735], Loss: 0.1890\n",
      "Epoch [47/50], Step [204/735], Loss: 0.6830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Step [205/735], Loss: 0.2360\n",
      "Epoch [47/50], Step [206/735], Loss: 0.3738\n",
      "Epoch [47/50], Step [207/735], Loss: 0.4335\n",
      "Epoch [47/50], Step [208/735], Loss: 0.2573\n",
      "Epoch [47/50], Step [209/735], Loss: 0.2656\n",
      "Epoch [47/50], Step [210/735], Loss: 0.1610\n",
      "Epoch [47/50], Step [211/735], Loss: 0.2050\n",
      "Epoch [47/50], Step [212/735], Loss: 0.3806\n",
      "Epoch [47/50], Step [213/735], Loss: 0.3074\n",
      "Epoch [47/50], Step [214/735], Loss: 0.2312\n",
      "Epoch [47/50], Step [215/735], Loss: 0.1560\n",
      "Epoch [47/50], Step [216/735], Loss: 0.1835\n",
      "Epoch [47/50], Step [217/735], Loss: 0.1807\n",
      "Epoch [47/50], Step [218/735], Loss: 0.1676\n",
      "Epoch [47/50], Step [219/735], Loss: 0.2230\n",
      "Epoch [47/50], Step [220/735], Loss: 0.1878\n",
      "Epoch [47/50], Step [221/735], Loss: 0.1795\n",
      "Epoch [47/50], Step [222/735], Loss: 0.3510\n",
      "Epoch [47/50], Step [223/735], Loss: 0.3053\n",
      "Epoch [47/50], Step [224/735], Loss: 0.3471\n",
      "Epoch [47/50], Step [225/735], Loss: 0.2477\n",
      "Epoch [47/50], Step [226/735], Loss: 0.8097\n",
      "Epoch [47/50], Step [227/735], Loss: 0.5792\n",
      "Epoch [47/50], Step [228/735], Loss: 0.5768\n",
      "Epoch [47/50], Step [229/735], Loss: 0.4914\n",
      "Epoch [47/50], Step [230/735], Loss: 0.1939\n",
      "Epoch [47/50], Step [231/735], Loss: 0.2233\n",
      "Epoch [47/50], Step [232/735], Loss: 0.4922\n",
      "Epoch [47/50], Step [233/735], Loss: 0.3404\n",
      "Epoch [47/50], Step [234/735], Loss: 0.0445\n",
      "Epoch [47/50], Step [235/735], Loss: 0.2641\n",
      "Epoch [47/50], Step [236/735], Loss: 0.7368\n",
      "Epoch [47/50], Step [237/735], Loss: 0.1570\n",
      "Epoch [47/50], Step [238/735], Loss: 0.1042\n",
      "Epoch [47/50], Step [239/735], Loss: 0.2089\n",
      "Epoch [47/50], Step [240/735], Loss: 0.3624\n",
      "Epoch [47/50], Step [241/735], Loss: 0.2353\n",
      "Epoch [47/50], Step [242/735], Loss: 0.2347\n",
      "Epoch [47/50], Step [243/735], Loss: 0.0993\n",
      "Epoch [47/50], Step [244/735], Loss: 0.2373\n",
      "Epoch [47/50], Step [245/735], Loss: 0.1177\n",
      "Epoch [47/50], Step [246/735], Loss: 0.1389\n",
      "Epoch [47/50], Step [247/735], Loss: 0.1207\n",
      "Epoch [47/50], Step [248/735], Loss: 0.0807\n",
      "Epoch [47/50], Step [249/735], Loss: 0.0717\n",
      "Epoch [47/50], Step [250/735], Loss: 0.1413\n",
      "Epoch [47/50], Step [251/735], Loss: 0.1956\n",
      "Epoch [47/50], Step [252/735], Loss: 0.2112\n",
      "Epoch [47/50], Step [253/735], Loss: 0.4127\n",
      "Epoch [47/50], Step [254/735], Loss: 0.0889\n",
      "Epoch [47/50], Step [255/735], Loss: 0.2710\n",
      "Epoch [47/50], Step [256/735], Loss: 0.1198\n",
      "Epoch [47/50], Step [257/735], Loss: 0.5125\n",
      "Epoch [47/50], Step [258/735], Loss: 0.2279\n",
      "Epoch [47/50], Step [259/735], Loss: 0.1738\n",
      "Epoch [47/50], Step [260/735], Loss: 0.1838\n",
      "Epoch [47/50], Step [261/735], Loss: 0.3239\n",
      "Epoch [47/50], Step [262/735], Loss: 0.1085\n",
      "Epoch [47/50], Step [263/735], Loss: 0.4517\n",
      "Epoch [47/50], Step [264/735], Loss: 0.0863\n",
      "Epoch [47/50], Step [265/735], Loss: 0.0860\n",
      "Epoch [47/50], Step [266/735], Loss: 0.4642\n",
      "Epoch [47/50], Step [267/735], Loss: 0.2276\n",
      "Epoch [47/50], Step [268/735], Loss: 0.6286\n",
      "Epoch [47/50], Step [269/735], Loss: 0.2423\n",
      "Epoch [47/50], Step [270/735], Loss: 0.1631\n",
      "Epoch [47/50], Step [271/735], Loss: 0.4149\n",
      "Epoch [47/50], Step [272/735], Loss: 0.3031\n",
      "Epoch [47/50], Step [273/735], Loss: 0.2846\n",
      "Epoch [47/50], Step [274/735], Loss: 0.2611\n",
      "Epoch [47/50], Step [275/735], Loss: 0.2785\n",
      "Epoch [47/50], Step [276/735], Loss: 0.0809\n",
      "Epoch [47/50], Step [277/735], Loss: 0.4372\n",
      "Epoch [47/50], Step [278/735], Loss: 0.3651\n",
      "Epoch [47/50], Step [279/735], Loss: 0.1209\n",
      "Epoch [47/50], Step [280/735], Loss: 0.2459\n",
      "Epoch [47/50], Step [281/735], Loss: 0.2121\n",
      "Epoch [47/50], Step [282/735], Loss: 0.2843\n",
      "Epoch [47/50], Step [283/735], Loss: 0.1549\n",
      "Epoch [47/50], Step [284/735], Loss: 1.3229\n",
      "Epoch [47/50], Step [285/735], Loss: 0.2707\n",
      "Epoch [47/50], Step [286/735], Loss: 0.2443\n",
      "Epoch [47/50], Step [287/735], Loss: 0.1010\n",
      "Epoch [47/50], Step [288/735], Loss: 0.3407\n",
      "Epoch [47/50], Step [289/735], Loss: 0.1306\n",
      "Epoch [47/50], Step [290/735], Loss: 0.2912\n",
      "Epoch [47/50], Step [291/735], Loss: 0.1481\n",
      "Epoch [47/50], Step [292/735], Loss: 0.0968\n",
      "Epoch [47/50], Step [293/735], Loss: 0.2520\n",
      "Epoch [47/50], Step [294/735], Loss: 0.1435\n",
      "Epoch [47/50], Step [295/735], Loss: 0.2878\n",
      "Epoch [47/50], Step [296/735], Loss: 0.2179\n",
      "Epoch [47/50], Step [297/735], Loss: 0.2739\n",
      "Epoch [47/50], Step [298/735], Loss: 0.3619\n",
      "Epoch [47/50], Step [299/735], Loss: 0.1365\n",
      "Epoch [47/50], Step [300/735], Loss: 0.2168\n",
      "Epoch [47/50], Step [301/735], Loss: 0.2658\n",
      "Epoch [47/50], Step [302/735], Loss: 0.1259\n",
      "Epoch [47/50], Step [303/735], Loss: 0.1745\n",
      "Epoch [47/50], Step [304/735], Loss: 0.1466\n",
      "Epoch [47/50], Step [305/735], Loss: 0.2792\n",
      "Epoch [47/50], Step [306/735], Loss: 0.2089\n",
      "Epoch [47/50], Step [307/735], Loss: 0.0681\n",
      "Epoch [47/50], Step [308/735], Loss: 0.1007\n",
      "Epoch [47/50], Step [309/735], Loss: 0.2035\n",
      "Epoch [47/50], Step [310/735], Loss: 0.1904\n",
      "Epoch [47/50], Step [311/735], Loss: 0.4391\n",
      "Epoch [47/50], Step [312/735], Loss: 0.1039\n",
      "Epoch [47/50], Step [313/735], Loss: 0.0811\n",
      "Epoch [47/50], Step [314/735], Loss: 0.3973\n",
      "Epoch [47/50], Step [315/735], Loss: 0.2436\n",
      "Epoch [47/50], Step [316/735], Loss: 0.2707\n",
      "Epoch [47/50], Step [317/735], Loss: 0.0989\n",
      "Epoch [47/50], Step [318/735], Loss: 0.2538\n",
      "Epoch [47/50], Step [319/735], Loss: 0.1692\n",
      "Epoch [47/50], Step [320/735], Loss: 0.2976\n",
      "Epoch [47/50], Step [321/735], Loss: 0.1466\n",
      "Epoch [47/50], Step [322/735], Loss: 0.2615\n",
      "Epoch [47/50], Step [323/735], Loss: 0.1314\n",
      "Epoch [47/50], Step [324/735], Loss: 0.3679\n",
      "Epoch [47/50], Step [325/735], Loss: 0.6335\n",
      "Epoch [47/50], Step [326/735], Loss: 0.1959\n",
      "Epoch [47/50], Step [327/735], Loss: 0.1151\n",
      "Epoch [47/50], Step [328/735], Loss: 0.1808\n",
      "Epoch [47/50], Step [329/735], Loss: 0.3475\n",
      "Epoch [47/50], Step [330/735], Loss: 0.1063\n",
      "Epoch [47/50], Step [331/735], Loss: 0.1796\n",
      "Epoch [47/50], Step [332/735], Loss: 0.8647\n",
      "Epoch [47/50], Step [333/735], Loss: 0.2509\n",
      "Epoch [47/50], Step [334/735], Loss: 0.4597\n",
      "Epoch [47/50], Step [335/735], Loss: 1.5546\n",
      "Epoch [47/50], Step [336/735], Loss: 0.1115\n",
      "Epoch [47/50], Step [337/735], Loss: 0.2732\n",
      "Epoch [47/50], Step [338/735], Loss: 0.3829\n",
      "Epoch [47/50], Step [339/735], Loss: 0.3448\n",
      "Epoch [47/50], Step [340/735], Loss: 0.5023\n",
      "Epoch [47/50], Step [341/735], Loss: 0.1092\n",
      "Epoch [47/50], Step [342/735], Loss: 0.1452\n",
      "Epoch [47/50], Step [343/735], Loss: 0.0869\n",
      "Epoch [47/50], Step [344/735], Loss: 0.3563\n",
      "Epoch [47/50], Step [345/735], Loss: 0.1840\n",
      "Epoch [47/50], Step [346/735], Loss: 0.2299\n",
      "Epoch [47/50], Step [347/735], Loss: 0.1297\n",
      "Epoch [47/50], Step [348/735], Loss: 0.4852\n",
      "Epoch [47/50], Step [349/735], Loss: 0.1337\n",
      "Epoch [47/50], Step [350/735], Loss: 0.3316\n",
      "Epoch [47/50], Step [351/735], Loss: 0.2226\n",
      "Epoch [47/50], Step [352/735], Loss: 0.1416\n",
      "Epoch [47/50], Step [353/735], Loss: 0.1909\n",
      "Epoch [47/50], Step [354/735], Loss: 0.4952\n",
      "Epoch [47/50], Step [355/735], Loss: 0.2554\n",
      "Epoch [47/50], Step [356/735], Loss: 0.3113\n",
      "Epoch [47/50], Step [357/735], Loss: 0.1562\n",
      "Epoch [47/50], Step [358/735], Loss: 0.0601\n",
      "Epoch [47/50], Step [359/735], Loss: 0.2340\n",
      "Epoch [47/50], Step [360/735], Loss: 0.5341\n",
      "Epoch [47/50], Step [361/735], Loss: 0.3830\n",
      "Epoch [47/50], Step [362/735], Loss: 0.2790\n",
      "Epoch [47/50], Step [363/735], Loss: 0.2483\n",
      "Epoch [47/50], Step [364/735], Loss: 0.1961\n",
      "Epoch [47/50], Step [365/735], Loss: 0.1704\n",
      "Epoch [47/50], Step [366/735], Loss: 0.7170\n",
      "Epoch [47/50], Step [367/735], Loss: 0.2067\n",
      "Epoch [47/50], Step [368/735], Loss: 0.0990\n",
      "Epoch [47/50], Step [369/735], Loss: 0.2020\n",
      "Epoch [47/50], Step [370/735], Loss: 0.2490\n",
      "Epoch [47/50], Step [371/735], Loss: 0.1675\n",
      "Epoch [47/50], Step [372/735], Loss: 0.1442\n",
      "Epoch [47/50], Step [373/735], Loss: 0.3207\n",
      "Epoch [47/50], Step [374/735], Loss: 0.0951\n",
      "Epoch [47/50], Step [375/735], Loss: 0.1045\n",
      "Epoch [47/50], Step [376/735], Loss: 0.4076\n",
      "Epoch [47/50], Step [377/735], Loss: 0.2548\n",
      "Epoch [47/50], Step [378/735], Loss: 0.1109\n",
      "Epoch [47/50], Step [379/735], Loss: 1.0963\n",
      "Epoch [47/50], Step [380/735], Loss: 0.3321\n",
      "Epoch [47/50], Step [381/735], Loss: 2.9874\n",
      "Epoch [47/50], Step [382/735], Loss: 0.5324\n",
      "Epoch [47/50], Step [383/735], Loss: 0.2235\n",
      "Epoch [47/50], Step [384/735], Loss: 0.3039\n",
      "Epoch [47/50], Step [385/735], Loss: 0.4383\n",
      "Epoch [47/50], Step [386/735], Loss: 0.2645\n",
      "Epoch [47/50], Step [387/735], Loss: 0.2142\n",
      "Epoch [47/50], Step [388/735], Loss: 0.0935\n",
      "Epoch [47/50], Step [389/735], Loss: 0.1531\n",
      "Epoch [47/50], Step [390/735], Loss: 0.1405\n",
      "Epoch [47/50], Step [391/735], Loss: 0.0920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Step [392/735], Loss: 0.2621\n",
      "Epoch [47/50], Step [393/735], Loss: 2.8588\n",
      "Epoch [47/50], Step [394/735], Loss: 0.4203\n",
      "Epoch [47/50], Step [395/735], Loss: 0.2881\n",
      "Epoch [47/50], Step [396/735], Loss: 0.1514\n",
      "Epoch [47/50], Step [397/735], Loss: 0.1531\n",
      "Epoch [47/50], Step [398/735], Loss: 0.1502\n",
      "Epoch [47/50], Step [399/735], Loss: 0.3945\n",
      "Epoch [47/50], Step [400/735], Loss: 0.2496\n",
      "Epoch [47/50], Step [401/735], Loss: 0.3697\n",
      "Epoch [47/50], Step [402/735], Loss: 0.1040\n",
      "Epoch [47/50], Step [403/735], Loss: 0.4734\n",
      "Epoch [47/50], Step [404/735], Loss: 0.2261\n",
      "Epoch [47/50], Step [405/735], Loss: 0.4857\n",
      "Epoch [47/50], Step [406/735], Loss: 0.7128\n",
      "Epoch [47/50], Step [407/735], Loss: 0.2054\n",
      "Epoch [47/50], Step [408/735], Loss: 0.1009\n",
      "Epoch [47/50], Step [409/735], Loss: 0.2057\n",
      "Epoch [47/50], Step [410/735], Loss: 0.1560\n",
      "Epoch [47/50], Step [411/735], Loss: 0.2530\n",
      "Epoch [47/50], Step [412/735], Loss: 2.3530\n",
      "Epoch [47/50], Step [413/735], Loss: 0.1817\n",
      "Epoch [47/50], Step [414/735], Loss: 0.3670\n",
      "Epoch [47/50], Step [415/735], Loss: 0.1261\n",
      "Epoch [47/50], Step [416/735], Loss: 0.1572\n",
      "Epoch [47/50], Step [417/735], Loss: 0.3368\n",
      "Epoch [47/50], Step [418/735], Loss: 0.0488\n",
      "Epoch [47/50], Step [419/735], Loss: 0.1148\n",
      "Epoch [47/50], Step [420/735], Loss: 0.4652\n",
      "Epoch [47/50], Step [421/735], Loss: 0.1800\n",
      "Epoch [47/50], Step [422/735], Loss: 0.1371\n",
      "Epoch [47/50], Step [423/735], Loss: 0.2494\n",
      "Epoch [47/50], Step [424/735], Loss: 0.4957\n",
      "Epoch [47/50], Step [425/735], Loss: 0.1254\n",
      "Epoch [47/50], Step [426/735], Loss: 0.1004\n",
      "Epoch [47/50], Step [427/735], Loss: 0.2318\n",
      "Epoch [47/50], Step [428/735], Loss: 0.3000\n",
      "Epoch [47/50], Step [429/735], Loss: 0.8173\n",
      "Epoch [47/50], Step [430/735], Loss: 0.3393\n",
      "Epoch [47/50], Step [431/735], Loss: 0.1183\n",
      "Epoch [47/50], Step [432/735], Loss: 0.1825\n",
      "Epoch [47/50], Step [433/735], Loss: 0.3215\n",
      "Epoch [47/50], Step [434/735], Loss: 0.3404\n",
      "Epoch [47/50], Step [435/735], Loss: 0.1855\n",
      "Epoch [47/50], Step [436/735], Loss: 0.2013\n",
      "Epoch [47/50], Step [437/735], Loss: 0.1840\n",
      "Epoch [47/50], Step [438/735], Loss: 0.5777\n",
      "Epoch [47/50], Step [439/735], Loss: 0.2815\n",
      "Epoch [47/50], Step [440/735], Loss: 0.3176\n",
      "Epoch [47/50], Step [441/735], Loss: 0.6003\n",
      "Epoch [47/50], Step [442/735], Loss: 0.1789\n",
      "Epoch [47/50], Step [443/735], Loss: 0.1652\n",
      "Epoch [47/50], Step [444/735], Loss: 0.1997\n",
      "Epoch [47/50], Step [445/735], Loss: 0.2605\n",
      "Epoch [47/50], Step [446/735], Loss: 0.1168\n",
      "Epoch [47/50], Step [447/735], Loss: 0.3562\n",
      "Epoch [47/50], Step [448/735], Loss: 0.1117\n",
      "Epoch [47/50], Step [449/735], Loss: 0.0775\n",
      "Epoch [47/50], Step [450/735], Loss: 0.7026\n",
      "Epoch [47/50], Step [451/735], Loss: 0.2356\n",
      "Epoch [47/50], Step [452/735], Loss: 0.6618\n",
      "Epoch [47/50], Step [453/735], Loss: 0.1277\n",
      "Epoch [47/50], Step [454/735], Loss: 0.5125\n",
      "Epoch [47/50], Step [455/735], Loss: 0.1713\n",
      "Epoch [47/50], Step [456/735], Loss: 0.2523\n",
      "Epoch [47/50], Step [457/735], Loss: 0.4210\n",
      "Epoch [47/50], Step [458/735], Loss: 0.2606\n",
      "Epoch [47/50], Step [459/735], Loss: 0.3235\n",
      "Epoch [47/50], Step [460/735], Loss: 0.3714\n",
      "Epoch [47/50], Step [461/735], Loss: 0.4079\n",
      "Epoch [47/50], Step [462/735], Loss: 0.2268\n",
      "Epoch [47/50], Step [463/735], Loss: 0.0940\n",
      "Epoch [47/50], Step [464/735], Loss: 0.2308\n",
      "Epoch [47/50], Step [465/735], Loss: 0.2289\n",
      "Epoch [47/50], Step [466/735], Loss: 0.4725\n",
      "Epoch [47/50], Step [467/735], Loss: 0.1014\n",
      "Epoch [47/50], Step [468/735], Loss: 0.1441\n",
      "Epoch [47/50], Step [469/735], Loss: 0.2957\n",
      "Epoch [47/50], Step [470/735], Loss: 0.3104\n",
      "Epoch [47/50], Step [471/735], Loss: 0.1846\n",
      "Epoch [47/50], Step [472/735], Loss: 0.2999\n",
      "Epoch [47/50], Step [473/735], Loss: 0.1080\n",
      "Epoch [47/50], Step [474/735], Loss: 0.5288\n",
      "Epoch [47/50], Step [475/735], Loss: 0.6584\n",
      "Epoch [47/50], Step [476/735], Loss: 0.2384\n",
      "Epoch [47/50], Step [477/735], Loss: 0.3673\n",
      "Epoch [47/50], Step [478/735], Loss: 0.3816\n",
      "Epoch [47/50], Step [479/735], Loss: 0.1535\n",
      "Epoch [47/50], Step [480/735], Loss: 0.8218\n",
      "Epoch [47/50], Step [481/735], Loss: 0.1593\n",
      "Epoch [47/50], Step [482/735], Loss: 0.1379\n",
      "Epoch [47/50], Step [483/735], Loss: 0.2873\n",
      "Epoch [47/50], Step [484/735], Loss: 0.3298\n",
      "Epoch [47/50], Step [485/735], Loss: 0.1324\n",
      "Epoch [47/50], Step [486/735], Loss: 0.2811\n",
      "Epoch [47/50], Step [487/735], Loss: 0.1953\n",
      "Epoch [47/50], Step [488/735], Loss: 0.1058\n",
      "Epoch [47/50], Step [489/735], Loss: 0.7259\n",
      "Epoch [47/50], Step [490/735], Loss: 0.2171\n",
      "Epoch [47/50], Step [491/735], Loss: 0.3408\n",
      "Epoch [47/50], Step [492/735], Loss: 0.7999\n",
      "Epoch [47/50], Step [493/735], Loss: 0.1709\n",
      "Epoch [47/50], Step [494/735], Loss: 0.0992\n",
      "Epoch [47/50], Step [495/735], Loss: 0.1655\n",
      "Epoch [47/50], Step [496/735], Loss: 0.4388\n",
      "Epoch [47/50], Step [497/735], Loss: 0.1630\n",
      "Epoch [47/50], Step [498/735], Loss: 0.3517\n",
      "Epoch [47/50], Step [499/735], Loss: 0.2182\n",
      "Epoch [47/50], Step [500/735], Loss: 0.4615\n",
      "Epoch [47/50], Step [501/735], Loss: 0.2599\n",
      "Epoch [47/50], Step [502/735], Loss: 1.8090\n",
      "Epoch [47/50], Step [503/735], Loss: 0.1829\n",
      "Epoch [47/50], Step [504/735], Loss: 0.1667\n",
      "Epoch [47/50], Step [505/735], Loss: 0.0877\n",
      "Epoch [47/50], Step [506/735], Loss: 0.2714\n",
      "Epoch [47/50], Step [507/735], Loss: 0.3144\n",
      "Epoch [47/50], Step [508/735], Loss: 0.1978\n",
      "Epoch [47/50], Step [509/735], Loss: 0.1183\n",
      "Epoch [47/50], Step [510/735], Loss: 0.0645\n",
      "Epoch [47/50], Step [511/735], Loss: 0.4338\n",
      "Epoch [47/50], Step [512/735], Loss: 0.1090\n",
      "Epoch [47/50], Step [513/735], Loss: 0.1392\n",
      "Epoch [47/50], Step [514/735], Loss: 0.2912\n",
      "Epoch [47/50], Step [515/735], Loss: 0.2017\n",
      "Epoch [47/50], Step [516/735], Loss: 0.1912\n",
      "Epoch [47/50], Step [517/735], Loss: 0.2856\n",
      "Epoch [47/50], Step [518/735], Loss: 0.1275\n",
      "Epoch [47/50], Step [519/735], Loss: 0.0766\n",
      "Epoch [47/50], Step [520/735], Loss: 0.3431\n",
      "Epoch [47/50], Step [521/735], Loss: 0.0660\n",
      "Epoch [47/50], Step [522/735], Loss: 0.2185\n",
      "Epoch [47/50], Step [523/735], Loss: 0.5954\n",
      "Epoch [47/50], Step [524/735], Loss: 0.0801\n",
      "Epoch [47/50], Step [525/735], Loss: 0.1250\n",
      "Epoch [47/50], Step [526/735], Loss: 0.0542\n",
      "Epoch [47/50], Step [527/735], Loss: 0.1019\n",
      "Epoch [47/50], Step [528/735], Loss: 0.2366\n",
      "Epoch [47/50], Step [529/735], Loss: 0.1714\n",
      "Epoch [47/50], Step [530/735], Loss: 0.1600\n",
      "Epoch [47/50], Step [531/735], Loss: 0.2489\n",
      "Epoch [47/50], Step [532/735], Loss: 0.2135\n",
      "Epoch [47/50], Step [533/735], Loss: 0.3470\n",
      "Epoch [47/50], Step [534/735], Loss: 0.1278\n",
      "Epoch [47/50], Step [535/735], Loss: 0.0956\n",
      "Epoch [47/50], Step [536/735], Loss: 0.1782\n",
      "Epoch [47/50], Step [537/735], Loss: 0.1683\n",
      "Epoch [47/50], Step [538/735], Loss: 0.2233\n",
      "Epoch [47/50], Step [539/735], Loss: 0.3418\n",
      "Epoch [47/50], Step [540/735], Loss: 0.1099\n",
      "Epoch [47/50], Step [541/735], Loss: 0.1258\n",
      "Epoch [47/50], Step [542/735], Loss: 0.2416\n",
      "Epoch [47/50], Step [543/735], Loss: 0.2668\n",
      "Epoch [47/50], Step [544/735], Loss: 0.0702\n",
      "Epoch [47/50], Step [545/735], Loss: 0.1152\n",
      "Epoch [47/50], Step [546/735], Loss: 0.4730\n",
      "Epoch [47/50], Step [547/735], Loss: 0.3193\n",
      "Epoch [47/50], Step [548/735], Loss: 0.1857\n",
      "Epoch [47/50], Step [549/735], Loss: 0.0479\n",
      "Epoch [47/50], Step [550/735], Loss: 0.1070\n",
      "Epoch [47/50], Step [551/735], Loss: 0.1475\n",
      "Epoch [47/50], Step [552/735], Loss: 0.3462\n",
      "Epoch [47/50], Step [553/735], Loss: 0.9333\n",
      "Epoch [47/50], Step [554/735], Loss: 0.1854\n",
      "Epoch [47/50], Step [555/735], Loss: 0.1666\n",
      "Epoch [47/50], Step [556/735], Loss: 0.1353\n",
      "Epoch [47/50], Step [557/735], Loss: 0.0864\n",
      "Epoch [47/50], Step [558/735], Loss: 0.1731\n",
      "Epoch [47/50], Step [559/735], Loss: 0.0859\n",
      "Epoch [47/50], Step [560/735], Loss: 0.0948\n",
      "Epoch [47/50], Step [561/735], Loss: 0.1729\n",
      "Epoch [47/50], Step [562/735], Loss: 0.2193\n",
      "Epoch [47/50], Step [563/735], Loss: 0.2246\n",
      "Epoch [47/50], Step [564/735], Loss: 0.2863\n",
      "Epoch [47/50], Step [565/735], Loss: 0.3114\n",
      "Epoch [47/50], Step [566/735], Loss: 0.4576\n",
      "Epoch [47/50], Step [567/735], Loss: 0.1226\n",
      "Epoch [47/50], Step [568/735], Loss: 0.2559\n",
      "Epoch [47/50], Step [569/735], Loss: 0.1156\n",
      "Epoch [47/50], Step [570/735], Loss: 0.0858\n",
      "Epoch [47/50], Step [571/735], Loss: 0.1331\n",
      "Epoch [47/50], Step [572/735], Loss: 0.1053\n",
      "Epoch [47/50], Step [573/735], Loss: 0.1093\n",
      "Epoch [47/50], Step [574/735], Loss: 0.1767\n",
      "Epoch [47/50], Step [575/735], Loss: 0.3685\n",
      "Epoch [47/50], Step [576/735], Loss: 0.2117\n",
      "Epoch [47/50], Step [577/735], Loss: 0.1322\n",
      "Epoch [47/50], Step [578/735], Loss: 0.2645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Step [579/735], Loss: 0.7351\n",
      "Epoch [47/50], Step [580/735], Loss: 0.1627\n",
      "Epoch [47/50], Step [581/735], Loss: 0.1865\n",
      "Epoch [47/50], Step [582/735], Loss: 0.2822\n",
      "Epoch [47/50], Step [583/735], Loss: 0.4471\n",
      "Epoch [47/50], Step [584/735], Loss: 0.1298\n",
      "Epoch [47/50], Step [585/735], Loss: 0.3077\n",
      "Epoch [47/50], Step [586/735], Loss: 0.1178\n",
      "Epoch [47/50], Step [587/735], Loss: 0.1885\n",
      "Epoch [47/50], Step [588/735], Loss: 0.1374\n",
      "Epoch [47/50], Step [589/735], Loss: 0.3295\n",
      "Epoch [47/50], Step [590/735], Loss: 0.2306\n",
      "Epoch [47/50], Step [591/735], Loss: 0.2270\n",
      "Epoch [47/50], Step [592/735], Loss: 0.3459\n",
      "Epoch [47/50], Step [593/735], Loss: 0.4605\n",
      "Epoch [47/50], Step [594/735], Loss: 0.3378\n",
      "Epoch [47/50], Step [595/735], Loss: 0.1109\n",
      "Epoch [47/50], Step [596/735], Loss: 0.2242\n",
      "Epoch [47/50], Step [597/735], Loss: 0.0798\n",
      "Epoch [47/50], Step [598/735], Loss: 0.2955\n",
      "Epoch [47/50], Step [599/735], Loss: 0.2834\n",
      "Epoch [47/50], Step [600/735], Loss: 0.2601\n",
      "Epoch [47/50], Step [601/735], Loss: 0.1818\n",
      "Epoch [47/50], Step [602/735], Loss: 0.0686\n",
      "Epoch [47/50], Step [603/735], Loss: 0.1259\n",
      "Epoch [47/50], Step [604/735], Loss: 0.3778\n",
      "Epoch [47/50], Step [605/735], Loss: 0.1820\n",
      "Epoch [47/50], Step [606/735], Loss: 0.1294\n",
      "Epoch [47/50], Step [607/735], Loss: 0.4198\n",
      "Epoch [47/50], Step [608/735], Loss: 0.4413\n",
      "Epoch [47/50], Step [609/735], Loss: 0.3696\n",
      "Epoch [47/50], Step [610/735], Loss: 0.1917\n",
      "Epoch [47/50], Step [611/735], Loss: 0.1381\n",
      "Epoch [47/50], Step [612/735], Loss: 0.1323\n",
      "Epoch [47/50], Step [613/735], Loss: 0.1390\n",
      "Epoch [47/50], Step [614/735], Loss: 0.3877\n",
      "Epoch [47/50], Step [615/735], Loss: 0.1503\n",
      "Epoch [47/50], Step [616/735], Loss: 0.1668\n",
      "Epoch [47/50], Step [617/735], Loss: 0.0911\n",
      "Epoch [47/50], Step [618/735], Loss: 0.0838\n",
      "Epoch [47/50], Step [619/735], Loss: 0.1988\n",
      "Epoch [47/50], Step [620/735], Loss: 0.1212\n",
      "Epoch [47/50], Step [621/735], Loss: 0.3312\n",
      "Epoch [47/50], Step [622/735], Loss: 0.3224\n",
      "Epoch [47/50], Step [623/735], Loss: 0.1338\n",
      "Epoch [47/50], Step [624/735], Loss: 0.0866\n",
      "Epoch [47/50], Step [625/735], Loss: 0.1799\n",
      "Epoch [47/50], Step [626/735], Loss: 0.4894\n",
      "Epoch [47/50], Step [627/735], Loss: 0.4057\n",
      "Epoch [47/50], Step [628/735], Loss: 0.2968\n",
      "Epoch [47/50], Step [629/735], Loss: 0.1631\n",
      "Epoch [47/50], Step [630/735], Loss: 0.3540\n",
      "Epoch [47/50], Step [631/735], Loss: 0.2920\n",
      "Epoch [47/50], Step [632/735], Loss: 0.3477\n",
      "Epoch [47/50], Step [633/735], Loss: 0.1192\n",
      "Epoch [47/50], Step [634/735], Loss: 0.1088\n",
      "Epoch [47/50], Step [635/735], Loss: 0.2888\n",
      "Epoch [47/50], Step [636/735], Loss: 0.6884\n",
      "Epoch [47/50], Step [637/735], Loss: 0.2203\n",
      "Epoch [47/50], Step [638/735], Loss: 0.1479\n",
      "Epoch [47/50], Step [639/735], Loss: 0.1746\n",
      "Epoch [47/50], Step [640/735], Loss: 0.1134\n",
      "Epoch [47/50], Step [641/735], Loss: 0.1864\n",
      "Epoch [47/50], Step [642/735], Loss: 0.2164\n",
      "Epoch [47/50], Step [643/735], Loss: 0.4708\n",
      "Epoch [47/50], Step [644/735], Loss: 0.1480\n",
      "Epoch [47/50], Step [645/735], Loss: 0.2536\n",
      "Epoch [47/50], Step [646/735], Loss: 0.1453\n",
      "Epoch [47/50], Step [647/735], Loss: 0.3013\n",
      "Epoch [47/50], Step [648/735], Loss: 0.1079\n",
      "Epoch [47/50], Step [649/735], Loss: 0.1087\n",
      "Epoch [47/50], Step [650/735], Loss: 0.1202\n",
      "Epoch [47/50], Step [651/735], Loss: 0.2515\n",
      "Epoch [47/50], Step [652/735], Loss: 0.0484\n",
      "Epoch [47/50], Step [653/735], Loss: 0.1768\n",
      "Epoch [47/50], Step [654/735], Loss: 0.3305\n",
      "Epoch [47/50], Step [655/735], Loss: 0.1747\n",
      "Epoch [47/50], Step [656/735], Loss: 0.0868\n",
      "Epoch [47/50], Step [657/735], Loss: 0.2757\n",
      "Epoch [47/50], Step [658/735], Loss: 0.1385\n",
      "Epoch [47/50], Step [659/735], Loss: 0.2472\n",
      "Epoch [47/50], Step [660/735], Loss: 0.0771\n",
      "Epoch [47/50], Step [661/735], Loss: 1.2486\n",
      "Epoch [47/50], Step [662/735], Loss: 0.0631\n",
      "Epoch [47/50], Step [663/735], Loss: 0.2264\n",
      "Epoch [47/50], Step [664/735], Loss: 0.5088\n",
      "Epoch [47/50], Step [665/735], Loss: 0.1136\n",
      "Epoch [47/50], Step [666/735], Loss: 0.0819\n",
      "Epoch [47/50], Step [667/735], Loss: 0.0902\n",
      "Epoch [47/50], Step [668/735], Loss: 0.3051\n",
      "Epoch [47/50], Step [669/735], Loss: 0.0315\n",
      "Epoch [47/50], Step [670/735], Loss: 0.1540\n",
      "Epoch [47/50], Step [671/735], Loss: 0.1089\n",
      "Epoch [47/50], Step [672/735], Loss: 0.2708\n",
      "Epoch [47/50], Step [673/735], Loss: 0.2056\n",
      "Epoch [47/50], Step [674/735], Loss: 1.2343\n",
      "Epoch [47/50], Step [675/735], Loss: 0.3219\n",
      "Epoch [47/50], Step [676/735], Loss: 0.2353\n",
      "Epoch [47/50], Step [677/735], Loss: 0.0996\n",
      "Epoch [47/50], Step [678/735], Loss: 0.1372\n",
      "Epoch [47/50], Step [679/735], Loss: 0.1854\n",
      "Epoch [47/50], Step [680/735], Loss: 0.1683\n",
      "Epoch [47/50], Step [681/735], Loss: 0.1290\n",
      "Epoch [47/50], Step [682/735], Loss: 0.1609\n",
      "Epoch [47/50], Step [683/735], Loss: 0.1720\n",
      "Epoch [47/50], Step [684/735], Loss: 0.6588\n",
      "Epoch [47/50], Step [685/735], Loss: 0.2441\n",
      "Epoch [47/50], Step [686/735], Loss: 0.3365\n",
      "Epoch [47/50], Step [687/735], Loss: 0.2184\n",
      "Epoch [47/50], Step [688/735], Loss: 0.1630\n",
      "Epoch [47/50], Step [689/735], Loss: 0.6975\n",
      "Epoch [47/50], Step [690/735], Loss: 0.1575\n",
      "Epoch [47/50], Step [691/735], Loss: 0.1039\n",
      "Epoch [47/50], Step [692/735], Loss: 0.2347\n",
      "Epoch [47/50], Step [693/735], Loss: 0.2804\n",
      "Epoch [47/50], Step [694/735], Loss: 0.2593\n",
      "Epoch [47/50], Step [695/735], Loss: 0.1882\n",
      "Epoch [47/50], Step [696/735], Loss: 0.3651\n",
      "Epoch [47/50], Step [697/735], Loss: 0.1807\n",
      "Epoch [47/50], Step [698/735], Loss: 0.2502\n",
      "Epoch [47/50], Step [699/735], Loss: 0.2497\n",
      "Epoch [47/50], Step [700/735], Loss: 0.0962\n",
      "Epoch [47/50], Step [701/735], Loss: 0.1309\n",
      "Epoch [47/50], Step [702/735], Loss: 0.1920\n",
      "Epoch [47/50], Step [703/735], Loss: 0.3766\n",
      "Epoch [47/50], Step [704/735], Loss: 0.4659\n",
      "Epoch [47/50], Step [705/735], Loss: 0.0859\n",
      "Epoch [47/50], Step [706/735], Loss: 0.1851\n",
      "Epoch [47/50], Step [707/735], Loss: 0.1483\n",
      "Epoch [47/50], Step [708/735], Loss: 0.2265\n",
      "Epoch [47/50], Step [709/735], Loss: 0.2592\n",
      "Epoch [47/50], Step [710/735], Loss: 0.2175\n",
      "Epoch [47/50], Step [711/735], Loss: 0.1578\n",
      "Epoch [47/50], Step [712/735], Loss: 0.1356\n",
      "Epoch [47/50], Step [713/735], Loss: 0.1448\n",
      "Epoch [47/50], Step [714/735], Loss: 0.2237\n",
      "Epoch [47/50], Step [715/735], Loss: 0.1542\n",
      "Epoch [47/50], Step [716/735], Loss: 0.2915\n",
      "Epoch [47/50], Step [717/735], Loss: 0.6290\n",
      "Epoch [47/50], Step [718/735], Loss: 0.1857\n",
      "Epoch [47/50], Step [719/735], Loss: 0.1072\n",
      "Epoch [47/50], Step [720/735], Loss: 0.2119\n",
      "Epoch [47/50], Step [721/735], Loss: 0.1367\n",
      "Epoch [47/50], Step [722/735], Loss: 0.0837\n",
      "Epoch [47/50], Step [723/735], Loss: 0.3846\n",
      "Epoch [47/50], Step [724/735], Loss: 0.6340\n",
      "Epoch [47/50], Step [725/735], Loss: 0.6782\n",
      "Epoch [47/50], Step [726/735], Loss: 0.1018\n",
      "Epoch [47/50], Step [727/735], Loss: 0.6746\n",
      "Epoch [47/50], Step [728/735], Loss: 0.2509\n",
      "Epoch [47/50], Step [729/735], Loss: 0.5722\n",
      "Epoch [47/50], Step [730/735], Loss: 1.1019\n",
      "Epoch [47/50], Step [731/735], Loss: 0.3344\n",
      "Epoch [47/50], Step [732/735], Loss: 0.3104\n",
      "Epoch [47/50], Step [733/735], Loss: 0.2352\n",
      "Epoch [47/50], Step [734/735], Loss: 0.2613\n",
      "Epoch [47/50], Step [735/735], Loss: 0.1105\n",
      "Epoch [48/50], Step [1/735], Loss: 0.2517\n",
      "Epoch [48/50], Step [2/735], Loss: 0.1428\n",
      "Epoch [48/50], Step [3/735], Loss: 0.2778\n",
      "Epoch [48/50], Step [4/735], Loss: 0.7080\n",
      "Epoch [48/50], Step [5/735], Loss: 0.0653\n",
      "Epoch [48/50], Step [6/735], Loss: 0.0760\n",
      "Epoch [48/50], Step [7/735], Loss: 0.2459\n",
      "Epoch [48/50], Step [8/735], Loss: 0.2018\n",
      "Epoch [48/50], Step [9/735], Loss: 0.2155\n",
      "Epoch [48/50], Step [10/735], Loss: 0.4144\n",
      "Epoch [48/50], Step [11/735], Loss: 0.4202\n",
      "Epoch [48/50], Step [12/735], Loss: 0.1764\n",
      "Epoch [48/50], Step [13/735], Loss: 0.1729\n",
      "Epoch [48/50], Step [14/735], Loss: 0.8664\n",
      "Epoch [48/50], Step [15/735], Loss: 0.2607\n",
      "Epoch [48/50], Step [16/735], Loss: 0.6885\n",
      "Epoch [48/50], Step [17/735], Loss: 0.1522\n",
      "Epoch [48/50], Step [18/735], Loss: 0.1325\n",
      "Epoch [48/50], Step [19/735], Loss: 0.4216\n",
      "Epoch [48/50], Step [20/735], Loss: 0.1879\n",
      "Epoch [48/50], Step [21/735], Loss: 0.1930\n",
      "Epoch [48/50], Step [22/735], Loss: 0.2150\n",
      "Epoch [48/50], Step [23/735], Loss: 0.1478\n",
      "Epoch [48/50], Step [24/735], Loss: 0.1684\n",
      "Epoch [48/50], Step [25/735], Loss: 0.2820\n",
      "Epoch [48/50], Step [26/735], Loss: 0.3243\n",
      "Epoch [48/50], Step [27/735], Loss: 0.2489\n",
      "Epoch [48/50], Step [28/735], Loss: 0.1472\n",
      "Epoch [48/50], Step [29/735], Loss: 0.0788\n",
      "Epoch [48/50], Step [30/735], Loss: 0.3721\n",
      "Epoch [48/50], Step [31/735], Loss: 0.4395\n",
      "Epoch [48/50], Step [32/735], Loss: 0.4194\n",
      "Epoch [48/50], Step [33/735], Loss: 0.2935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Step [34/735], Loss: 3.0310\n",
      "Epoch [48/50], Step [35/735], Loss: 0.1958\n",
      "Epoch [48/50], Step [36/735], Loss: 0.2073\n",
      "Epoch [48/50], Step [37/735], Loss: 0.3893\n",
      "Epoch [48/50], Step [38/735], Loss: 0.8080\n",
      "Epoch [48/50], Step [39/735], Loss: 0.7551\n",
      "Epoch [48/50], Step [40/735], Loss: 0.2494\n",
      "Epoch [48/50], Step [41/735], Loss: 0.2963\n",
      "Epoch [48/50], Step [42/735], Loss: 0.4618\n",
      "Epoch [48/50], Step [43/735], Loss: 0.0852\n",
      "Epoch [48/50], Step [44/735], Loss: 0.4408\n",
      "Epoch [48/50], Step [45/735], Loss: 0.2048\n",
      "Epoch [48/50], Step [46/735], Loss: 0.4455\n",
      "Epoch [48/50], Step [47/735], Loss: 0.2800\n",
      "Epoch [48/50], Step [48/735], Loss: 0.2561\n",
      "Epoch [48/50], Step [49/735], Loss: 0.2162\n",
      "Epoch [48/50], Step [50/735], Loss: 0.2224\n",
      "Epoch [48/50], Step [51/735], Loss: 0.2437\n",
      "Epoch [48/50], Step [52/735], Loss: 0.1020\n",
      "Epoch [48/50], Step [53/735], Loss: 0.2037\n",
      "Epoch [48/50], Step [54/735], Loss: 0.1939\n",
      "Epoch [48/50], Step [55/735], Loss: 0.1089\n",
      "Epoch [48/50], Step [56/735], Loss: 0.4680\n",
      "Epoch [48/50], Step [57/735], Loss: 0.1070\n",
      "Epoch [48/50], Step [58/735], Loss: 0.1474\n",
      "Epoch [48/50], Step [59/735], Loss: 0.1601\n",
      "Epoch [48/50], Step [60/735], Loss: 0.0444\n",
      "Epoch [48/50], Step [61/735], Loss: 0.1310\n",
      "Epoch [48/50], Step [62/735], Loss: 0.1585\n",
      "Epoch [48/50], Step [63/735], Loss: 0.0951\n",
      "Epoch [48/50], Step [64/735], Loss: 0.1076\n",
      "Epoch [48/50], Step [65/735], Loss: 0.1430\n",
      "Epoch [48/50], Step [66/735], Loss: 0.3827\n",
      "Epoch [48/50], Step [67/735], Loss: 0.1857\n",
      "Epoch [48/50], Step [68/735], Loss: 0.1278\n",
      "Epoch [48/50], Step [69/735], Loss: 0.1352\n",
      "Epoch [48/50], Step [70/735], Loss: 0.0987\n",
      "Epoch [48/50], Step [71/735], Loss: 0.0820\n",
      "Epoch [48/50], Step [72/735], Loss: 0.1982\n",
      "Epoch [48/50], Step [73/735], Loss: 0.2695\n",
      "Epoch [48/50], Step [74/735], Loss: 0.1342\n",
      "Epoch [48/50], Step [75/735], Loss: 0.3366\n",
      "Epoch [48/50], Step [76/735], Loss: 0.2786\n",
      "Epoch [48/50], Step [77/735], Loss: 0.1992\n",
      "Epoch [48/50], Step [78/735], Loss: 0.3288\n",
      "Epoch [48/50], Step [79/735], Loss: 0.1961\n",
      "Epoch [48/50], Step [80/735], Loss: 0.1091\n",
      "Epoch [48/50], Step [81/735], Loss: 0.1815\n",
      "Epoch [48/50], Step [82/735], Loss: 0.3114\n",
      "Epoch [48/50], Step [83/735], Loss: 0.3080\n",
      "Epoch [48/50], Step [84/735], Loss: 0.1110\n",
      "Epoch [48/50], Step [85/735], Loss: 0.1042\n",
      "Epoch [48/50], Step [86/735], Loss: 0.2021\n",
      "Epoch [48/50], Step [87/735], Loss: 0.4064\n",
      "Epoch [48/50], Step [88/735], Loss: 0.1610\n",
      "Epoch [48/50], Step [89/735], Loss: 0.9356\n",
      "Epoch [48/50], Step [90/735], Loss: 0.5666\n",
      "Epoch [48/50], Step [91/735], Loss: 0.3022\n",
      "Epoch [48/50], Step [92/735], Loss: 0.2150\n",
      "Epoch [48/50], Step [93/735], Loss: 0.1272\n",
      "Epoch [48/50], Step [94/735], Loss: 0.1782\n",
      "Epoch [48/50], Step [95/735], Loss: 0.1471\n",
      "Epoch [48/50], Step [96/735], Loss: 0.1184\n",
      "Epoch [48/50], Step [97/735], Loss: 0.1390\n",
      "Epoch [48/50], Step [98/735], Loss: 0.3909\n",
      "Epoch [48/50], Step [99/735], Loss: 0.4540\n",
      "Epoch [48/50], Step [100/735], Loss: 0.2619\n",
      "Epoch [48/50], Step [101/735], Loss: 0.1950\n",
      "Epoch [48/50], Step [102/735], Loss: 0.2260\n",
      "Epoch [48/50], Step [103/735], Loss: 0.3262\n",
      "Epoch [48/50], Step [104/735], Loss: 0.8825\n",
      "Epoch [48/50], Step [105/735], Loss: 0.2559\n",
      "Epoch [48/50], Step [106/735], Loss: 0.0600\n",
      "Epoch [48/50], Step [107/735], Loss: 0.3105\n",
      "Epoch [48/50], Step [108/735], Loss: 0.4648\n",
      "Epoch [48/50], Step [109/735], Loss: 0.1548\n",
      "Epoch [48/50], Step [110/735], Loss: 0.3213\n",
      "Epoch [48/50], Step [111/735], Loss: 0.0691\n",
      "Epoch [48/50], Step [112/735], Loss: 0.0833\n",
      "Epoch [48/50], Step [113/735], Loss: 0.1690\n",
      "Epoch [48/50], Step [114/735], Loss: 0.1733\n",
      "Epoch [48/50], Step [115/735], Loss: 0.2559\n",
      "Epoch [48/50], Step [116/735], Loss: 0.1335\n",
      "Epoch [48/50], Step [117/735], Loss: 0.0633\n",
      "Epoch [48/50], Step [118/735], Loss: 0.2382\n",
      "Epoch [48/50], Step [119/735], Loss: 0.2111\n",
      "Epoch [48/50], Step [120/735], Loss: 0.0567\n",
      "Epoch [48/50], Step [121/735], Loss: 0.1224\n",
      "Epoch [48/50], Step [122/735], Loss: 0.4117\n",
      "Epoch [48/50], Step [123/735], Loss: 0.2003\n",
      "Epoch [48/50], Step [124/735], Loss: 0.2623\n",
      "Epoch [48/50], Step [125/735], Loss: 0.1402\n",
      "Epoch [48/50], Step [126/735], Loss: 0.1223\n",
      "Epoch [48/50], Step [127/735], Loss: 0.2057\n",
      "Epoch [48/50], Step [128/735], Loss: 0.3709\n",
      "Epoch [48/50], Step [129/735], Loss: 0.3057\n",
      "Epoch [48/50], Step [130/735], Loss: 0.1217\n",
      "Epoch [48/50], Step [131/735], Loss: 0.1152\n",
      "Epoch [48/50], Step [132/735], Loss: 0.1215\n",
      "Epoch [48/50], Step [133/735], Loss: 0.3854\n",
      "Epoch [48/50], Step [134/735], Loss: 0.1473\n",
      "Epoch [48/50], Step [135/735], Loss: 0.1882\n",
      "Epoch [48/50], Step [136/735], Loss: 0.1786\n",
      "Epoch [48/50], Step [137/735], Loss: 0.1727\n",
      "Epoch [48/50], Step [138/735], Loss: 0.3065\n",
      "Epoch [48/50], Step [139/735], Loss: 0.1687\n",
      "Epoch [48/50], Step [140/735], Loss: 0.2882\n",
      "Epoch [48/50], Step [141/735], Loss: 0.1396\n",
      "Epoch [48/50], Step [142/735], Loss: 0.3074\n",
      "Epoch [48/50], Step [143/735], Loss: 0.1395\n",
      "Epoch [48/50], Step [144/735], Loss: 0.1771\n",
      "Epoch [48/50], Step [145/735], Loss: 0.2632\n",
      "Epoch [48/50], Step [146/735], Loss: 0.2451\n",
      "Epoch [48/50], Step [147/735], Loss: 0.5056\n",
      "Epoch [48/50], Step [148/735], Loss: 0.3340\n",
      "Epoch [48/50], Step [149/735], Loss: 0.1650\n",
      "Epoch [48/50], Step [150/735], Loss: 0.1349\n",
      "Epoch [48/50], Step [151/735], Loss: 0.6394\n",
      "Epoch [48/50], Step [152/735], Loss: 0.4119\n",
      "Epoch [48/50], Step [153/735], Loss: 0.1555\n",
      "Epoch [48/50], Step [154/735], Loss: 0.3061\n",
      "Epoch [48/50], Step [155/735], Loss: 0.4355\n",
      "Epoch [48/50], Step [156/735], Loss: 0.0435\n",
      "Epoch [48/50], Step [157/735], Loss: 0.2964\n",
      "Epoch [48/50], Step [158/735], Loss: 0.1423\n",
      "Epoch [48/50], Step [159/735], Loss: 0.1401\n",
      "Epoch [48/50], Step [160/735], Loss: 0.1168\n",
      "Epoch [48/50], Step [161/735], Loss: 0.1050\n",
      "Epoch [48/50], Step [162/735], Loss: 0.3197\n",
      "Epoch [48/50], Step [163/735], Loss: 0.1078\n",
      "Epoch [48/50], Step [164/735], Loss: 0.0781\n",
      "Epoch [48/50], Step [165/735], Loss: 0.1632\n",
      "Epoch [48/50], Step [166/735], Loss: 0.0555\n",
      "Epoch [48/50], Step [167/735], Loss: 0.0543\n",
      "Epoch [48/50], Step [168/735], Loss: 0.0479\n",
      "Epoch [48/50], Step [169/735], Loss: 0.0977\n",
      "Epoch [48/50], Step [170/735], Loss: 0.1766\n",
      "Epoch [48/50], Step [171/735], Loss: 0.2514\n",
      "Epoch [48/50], Step [172/735], Loss: 0.4358\n",
      "Epoch [48/50], Step [173/735], Loss: 0.0497\n",
      "Epoch [48/50], Step [174/735], Loss: 0.2321\n",
      "Epoch [48/50], Step [175/735], Loss: 0.2024\n",
      "Epoch [48/50], Step [176/735], Loss: 0.1148\n",
      "Epoch [48/50], Step [177/735], Loss: 0.1995\n",
      "Epoch [48/50], Step [178/735], Loss: 0.1376\n",
      "Epoch [48/50], Step [179/735], Loss: 0.5589\n",
      "Epoch [48/50], Step [180/735], Loss: 0.2714\n",
      "Epoch [48/50], Step [181/735], Loss: 0.0991\n",
      "Epoch [48/50], Step [182/735], Loss: 0.1520\n",
      "Epoch [48/50], Step [183/735], Loss: 2.4653\n",
      "Epoch [48/50], Step [184/735], Loss: 0.1329\n",
      "Epoch [48/50], Step [185/735], Loss: 0.1884\n",
      "Epoch [48/50], Step [186/735], Loss: 0.2972\n",
      "Epoch [48/50], Step [187/735], Loss: 0.2629\n",
      "Epoch [48/50], Step [188/735], Loss: 0.2005\n",
      "Epoch [48/50], Step [189/735], Loss: 0.5806\n",
      "Epoch [48/50], Step [190/735], Loss: 0.3375\n",
      "Epoch [48/50], Step [191/735], Loss: 0.4156\n",
      "Epoch [48/50], Step [192/735], Loss: 0.6977\n",
      "Epoch [48/50], Step [193/735], Loss: 0.0888\n",
      "Epoch [48/50], Step [194/735], Loss: 0.2609\n",
      "Epoch [48/50], Step [195/735], Loss: 0.2305\n",
      "Epoch [48/50], Step [196/735], Loss: 0.0626\n",
      "Epoch [48/50], Step [197/735], Loss: 0.5004\n",
      "Epoch [48/50], Step [198/735], Loss: 0.3405\n",
      "Epoch [48/50], Step [199/735], Loss: 0.1269\n",
      "Epoch [48/50], Step [200/735], Loss: 0.4128\n",
      "Epoch [48/50], Step [201/735], Loss: 0.2372\n",
      "Epoch [48/50], Step [202/735], Loss: 0.3404\n",
      "Epoch [48/50], Step [203/735], Loss: 0.1243\n",
      "Epoch [48/50], Step [204/735], Loss: 0.2020\n",
      "Epoch [48/50], Step [205/735], Loss: 0.3303\n",
      "Epoch [48/50], Step [206/735], Loss: 0.1709\n",
      "Epoch [48/50], Step [207/735], Loss: 0.9952\n",
      "Epoch [48/50], Step [208/735], Loss: 0.3731\n",
      "Epoch [48/50], Step [209/735], Loss: 0.4489\n",
      "Epoch [48/50], Step [210/735], Loss: 0.2564\n",
      "Epoch [48/50], Step [211/735], Loss: 0.5589\n",
      "Epoch [48/50], Step [212/735], Loss: 0.2173\n",
      "Epoch [48/50], Step [213/735], Loss: 0.0797\n",
      "Epoch [48/50], Step [214/735], Loss: 0.1507\n",
      "Epoch [48/50], Step [215/735], Loss: 0.8498\n",
      "Epoch [48/50], Step [216/735], Loss: 0.1077\n",
      "Epoch [48/50], Step [217/735], Loss: 0.2233\n",
      "Epoch [48/50], Step [218/735], Loss: 0.2401\n",
      "Epoch [48/50], Step [219/735], Loss: 0.1861\n",
      "Epoch [48/50], Step [220/735], Loss: 0.1628\n",
      "Epoch [48/50], Step [221/735], Loss: 0.5567\n",
      "Epoch [48/50], Step [222/735], Loss: 0.2980\n",
      "Epoch [48/50], Step [223/735], Loss: 0.4293\n",
      "Epoch [48/50], Step [224/735], Loss: 0.4124\n",
      "Epoch [48/50], Step [225/735], Loss: 0.1750\n",
      "Epoch [48/50], Step [226/735], Loss: 0.1627\n",
      "Epoch [48/50], Step [227/735], Loss: 0.5296\n",
      "Epoch [48/50], Step [228/735], Loss: 0.3291\n",
      "Epoch [48/50], Step [229/735], Loss: 0.4311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Step [230/735], Loss: 0.4771\n",
      "Epoch [48/50], Step [231/735], Loss: 0.2306\n",
      "Epoch [48/50], Step [232/735], Loss: 0.1433\n",
      "Epoch [48/50], Step [233/735], Loss: 0.1444\n",
      "Epoch [48/50], Step [234/735], Loss: 0.2701\n",
      "Epoch [48/50], Step [235/735], Loss: 0.2456\n",
      "Epoch [48/50], Step [236/735], Loss: 0.5017\n",
      "Epoch [48/50], Step [237/735], Loss: 0.0725\n",
      "Epoch [48/50], Step [238/735], Loss: 0.2347\n",
      "Epoch [48/50], Step [239/735], Loss: 0.3117\n",
      "Epoch [48/50], Step [240/735], Loss: 0.2648\n",
      "Epoch [48/50], Step [241/735], Loss: 0.2898\n",
      "Epoch [48/50], Step [242/735], Loss: 0.2725\n",
      "Epoch [48/50], Step [243/735], Loss: 0.2245\n",
      "Epoch [48/50], Step [244/735], Loss: 0.3017\n",
      "Epoch [48/50], Step [245/735], Loss: 0.6976\n",
      "Epoch [48/50], Step [246/735], Loss: 0.2550\n",
      "Epoch [48/50], Step [247/735], Loss: 0.3712\n",
      "Epoch [48/50], Step [248/735], Loss: 0.2759\n",
      "Epoch [48/50], Step [249/735], Loss: 0.4257\n",
      "Epoch [48/50], Step [250/735], Loss: 0.3160\n",
      "Epoch [48/50], Step [251/735], Loss: 0.3517\n",
      "Epoch [48/50], Step [252/735], Loss: 0.1612\n",
      "Epoch [48/50], Step [253/735], Loss: 0.4765\n",
      "Epoch [48/50], Step [254/735], Loss: 0.6251\n",
      "Epoch [48/50], Step [255/735], Loss: 0.4297\n",
      "Epoch [48/50], Step [256/735], Loss: 0.4436\n",
      "Epoch [48/50], Step [257/735], Loss: 0.3045\n",
      "Epoch [48/50], Step [258/735], Loss: 0.1348\n",
      "Epoch [48/50], Step [259/735], Loss: 0.1329\n",
      "Epoch [48/50], Step [260/735], Loss: 0.1869\n",
      "Epoch [48/50], Step [261/735], Loss: 0.2327\n",
      "Epoch [48/50], Step [262/735], Loss: 0.1658\n",
      "Epoch [48/50], Step [263/735], Loss: 1.3167\n",
      "Epoch [48/50], Step [264/735], Loss: 0.0875\n",
      "Epoch [48/50], Step [265/735], Loss: 0.2123\n",
      "Epoch [48/50], Step [266/735], Loss: 0.4240\n",
      "Epoch [48/50], Step [267/735], Loss: 0.2168\n",
      "Epoch [48/50], Step [268/735], Loss: 0.2071\n",
      "Epoch [48/50], Step [269/735], Loss: 0.1964\n",
      "Epoch [48/50], Step [270/735], Loss: 1.1666\n",
      "Epoch [48/50], Step [271/735], Loss: 0.2207\n",
      "Epoch [48/50], Step [272/735], Loss: 0.0896\n",
      "Epoch [48/50], Step [273/735], Loss: 0.3831\n",
      "Epoch [48/50], Step [274/735], Loss: 0.3831\n",
      "Epoch [48/50], Step [275/735], Loss: 0.1832\n",
      "Epoch [48/50], Step [276/735], Loss: 0.3393\n",
      "Epoch [48/50], Step [277/735], Loss: 0.2265\n",
      "Epoch [48/50], Step [278/735], Loss: 0.0817\n",
      "Epoch [48/50], Step [279/735], Loss: 0.0433\n",
      "Epoch [48/50], Step [280/735], Loss: 0.0959\n",
      "Epoch [48/50], Step [281/735], Loss: 0.8196\n",
      "Epoch [48/50], Step [282/735], Loss: 0.0904\n",
      "Epoch [48/50], Step [283/735], Loss: 0.1435\n",
      "Epoch [48/50], Step [284/735], Loss: 0.0937\n",
      "Epoch [48/50], Step [285/735], Loss: 0.1613\n",
      "Epoch [48/50], Step [286/735], Loss: 0.2017\n",
      "Epoch [48/50], Step [287/735], Loss: 0.0736\n",
      "Epoch [48/50], Step [288/735], Loss: 0.2480\n",
      "Epoch [48/50], Step [289/735], Loss: 0.0961\n",
      "Epoch [48/50], Step [290/735], Loss: 0.1501\n",
      "Epoch [48/50], Step [291/735], Loss: 0.1068\n",
      "Epoch [48/50], Step [292/735], Loss: 0.3833\n",
      "Epoch [48/50], Step [293/735], Loss: 0.2041\n",
      "Epoch [48/50], Step [294/735], Loss: 0.2105\n",
      "Epoch [48/50], Step [295/735], Loss: 0.1217\n",
      "Epoch [48/50], Step [296/735], Loss: 0.1142\n",
      "Epoch [48/50], Step [297/735], Loss: 0.2476\n",
      "Epoch [48/50], Step [298/735], Loss: 0.3037\n",
      "Epoch [48/50], Step [299/735], Loss: 0.2443\n",
      "Epoch [48/50], Step [300/735], Loss: 0.3380\n",
      "Epoch [48/50], Step [301/735], Loss: 0.1306\n",
      "Epoch [48/50], Step [302/735], Loss: 0.8456\n",
      "Epoch [48/50], Step [303/735], Loss: 0.4435\n",
      "Epoch [48/50], Step [304/735], Loss: 0.2047\n",
      "Epoch [48/50], Step [305/735], Loss: 0.1116\n",
      "Epoch [48/50], Step [306/735], Loss: 0.4873\n",
      "Epoch [48/50], Step [307/735], Loss: 0.3276\n",
      "Epoch [48/50], Step [308/735], Loss: 0.3503\n",
      "Epoch [48/50], Step [309/735], Loss: 0.2382\n",
      "Epoch [48/50], Step [310/735], Loss: 0.0762\n",
      "Epoch [48/50], Step [311/735], Loss: 1.0041\n",
      "Epoch [48/50], Step [312/735], Loss: 0.1642\n",
      "Epoch [48/50], Step [313/735], Loss: 0.2568\n",
      "Epoch [48/50], Step [314/735], Loss: 0.0994\n",
      "Epoch [48/50], Step [315/735], Loss: 0.0760\n",
      "Epoch [48/50], Step [316/735], Loss: 0.1817\n",
      "Epoch [48/50], Step [317/735], Loss: 0.5321\n",
      "Epoch [48/50], Step [318/735], Loss: 0.3284\n",
      "Epoch [48/50], Step [319/735], Loss: 0.2618\n",
      "Epoch [48/50], Step [320/735], Loss: 0.4214\n",
      "Epoch [48/50], Step [321/735], Loss: 0.3913\n",
      "Epoch [48/50], Step [322/735], Loss: 0.5262\n",
      "Epoch [48/50], Step [323/735], Loss: 0.1363\n",
      "Epoch [48/50], Step [324/735], Loss: 0.2719\n",
      "Epoch [48/50], Step [325/735], Loss: 0.1592\n",
      "Epoch [48/50], Step [326/735], Loss: 0.2322\n",
      "Epoch [48/50], Step [327/735], Loss: 0.1935\n",
      "Epoch [48/50], Step [328/735], Loss: 0.6485\n",
      "Epoch [48/50], Step [329/735], Loss: 0.8693\n",
      "Epoch [48/50], Step [330/735], Loss: 0.2419\n",
      "Epoch [48/50], Step [331/735], Loss: 0.1586\n",
      "Epoch [48/50], Step [332/735], Loss: 0.3180\n",
      "Epoch [48/50], Step [333/735], Loss: 0.7729\n",
      "Epoch [48/50], Step [334/735], Loss: 0.4135\n",
      "Epoch [48/50], Step [335/735], Loss: 0.1075\n",
      "Epoch [48/50], Step [336/735], Loss: 0.2501\n",
      "Epoch [48/50], Step [337/735], Loss: 0.6344\n",
      "Epoch [48/50], Step [338/735], Loss: 0.2272\n",
      "Epoch [48/50], Step [339/735], Loss: 0.2851\n",
      "Epoch [48/50], Step [340/735], Loss: 0.3170\n",
      "Epoch [48/50], Step [341/735], Loss: 0.1635\n",
      "Epoch [48/50], Step [342/735], Loss: 0.1902\n",
      "Epoch [48/50], Step [343/735], Loss: 0.3639\n",
      "Epoch [48/50], Step [344/735], Loss: 0.3766\n",
      "Epoch [48/50], Step [345/735], Loss: 0.2255\n",
      "Epoch [48/50], Step [346/735], Loss: 0.2291\n",
      "Epoch [48/50], Step [347/735], Loss: 0.0848\n",
      "Epoch [48/50], Step [348/735], Loss: 0.0845\n",
      "Epoch [48/50], Step [349/735], Loss: 0.1590\n",
      "Epoch [48/50], Step [350/735], Loss: 0.4903\n",
      "Epoch [48/50], Step [351/735], Loss: 0.2804\n",
      "Epoch [48/50], Step [352/735], Loss: 0.1681\n",
      "Epoch [48/50], Step [353/735], Loss: 0.1473\n",
      "Epoch [48/50], Step [354/735], Loss: 0.3271\n",
      "Epoch [48/50], Step [355/735], Loss: 0.1176\n",
      "Epoch [48/50], Step [356/735], Loss: 0.1370\n",
      "Epoch [48/50], Step [357/735], Loss: 0.1819\n",
      "Epoch [48/50], Step [358/735], Loss: 0.1695\n",
      "Epoch [48/50], Step [359/735], Loss: 0.3420\n",
      "Epoch [48/50], Step [360/735], Loss: 0.0972\n",
      "Epoch [48/50], Step [361/735], Loss: 0.4690\n",
      "Epoch [48/50], Step [362/735], Loss: 0.1488\n",
      "Epoch [48/50], Step [363/735], Loss: 0.2748\n",
      "Epoch [48/50], Step [364/735], Loss: 0.1528\n",
      "Epoch [48/50], Step [365/735], Loss: 0.1637\n",
      "Epoch [48/50], Step [366/735], Loss: 0.4111\n",
      "Epoch [48/50], Step [367/735], Loss: 0.1110\n",
      "Epoch [48/50], Step [368/735], Loss: 0.1046\n",
      "Epoch [48/50], Step [369/735], Loss: 0.4837\n",
      "Epoch [48/50], Step [370/735], Loss: 0.3653\n",
      "Epoch [48/50], Step [371/735], Loss: 0.0934\n",
      "Epoch [48/50], Step [372/735], Loss: 0.5392\n",
      "Epoch [48/50], Step [373/735], Loss: 0.3744\n",
      "Epoch [48/50], Step [374/735], Loss: 0.2846\n",
      "Epoch [48/50], Step [375/735], Loss: 0.2581\n",
      "Epoch [48/50], Step [376/735], Loss: 0.3299\n",
      "Epoch [48/50], Step [377/735], Loss: 0.0726\n",
      "Epoch [48/50], Step [378/735], Loss: 0.7207\n",
      "Epoch [48/50], Step [379/735], Loss: 0.2747\n",
      "Epoch [48/50], Step [380/735], Loss: 0.7722\n",
      "Epoch [48/50], Step [381/735], Loss: 0.4087\n",
      "Epoch [48/50], Step [382/735], Loss: 0.0989\n",
      "Epoch [48/50], Step [383/735], Loss: 0.1577\n",
      "Epoch [48/50], Step [384/735], Loss: 0.2319\n",
      "Epoch [48/50], Step [385/735], Loss: 0.1173\n",
      "Epoch [48/50], Step [386/735], Loss: 0.1536\n",
      "Epoch [48/50], Step [387/735], Loss: 0.2206\n",
      "Epoch [48/50], Step [388/735], Loss: 0.5854\n",
      "Epoch [48/50], Step [389/735], Loss: 0.3114\n",
      "Epoch [48/50], Step [390/735], Loss: 0.2358\n",
      "Epoch [48/50], Step [391/735], Loss: 0.1080\n",
      "Epoch [48/50], Step [392/735], Loss: 0.2241\n",
      "Epoch [48/50], Step [393/735], Loss: 0.3881\n",
      "Epoch [48/50], Step [394/735], Loss: 0.2583\n",
      "Epoch [48/50], Step [395/735], Loss: 0.1907\n",
      "Epoch [48/50], Step [396/735], Loss: 0.2341\n",
      "Epoch [48/50], Step [397/735], Loss: 0.3671\n",
      "Epoch [48/50], Step [398/735], Loss: 0.2422\n",
      "Epoch [48/50], Step [399/735], Loss: 0.1567\n",
      "Epoch [48/50], Step [400/735], Loss: 0.3759\n",
      "Epoch [48/50], Step [401/735], Loss: 0.3091\n",
      "Epoch [48/50], Step [402/735], Loss: 0.3244\n",
      "Epoch [48/50], Step [403/735], Loss: 0.1324\n",
      "Epoch [48/50], Step [404/735], Loss: 0.7168\n",
      "Epoch [48/50], Step [405/735], Loss: 0.2784\n",
      "Epoch [48/50], Step [406/735], Loss: 0.1177\n",
      "Epoch [48/50], Step [407/735], Loss: 0.4216\n",
      "Epoch [48/50], Step [408/735], Loss: 0.0808\n",
      "Epoch [48/50], Step [409/735], Loss: 0.2153\n",
      "Epoch [48/50], Step [410/735], Loss: 0.2226\n",
      "Epoch [48/50], Step [411/735], Loss: 0.5834\n",
      "Epoch [48/50], Step [412/735], Loss: 0.3404\n",
      "Epoch [48/50], Step [413/735], Loss: 0.2173\n",
      "Epoch [48/50], Step [414/735], Loss: 0.2904\n",
      "Epoch [48/50], Step [415/735], Loss: 1.4472\n",
      "Epoch [48/50], Step [416/735], Loss: 0.1718\n",
      "Epoch [48/50], Step [417/735], Loss: 0.4568\n",
      "Epoch [48/50], Step [418/735], Loss: 0.1607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Step [419/735], Loss: 0.1158\n",
      "Epoch [48/50], Step [420/735], Loss: 0.5748\n",
      "Epoch [48/50], Step [421/735], Loss: 0.4234\n",
      "Epoch [48/50], Step [422/735], Loss: 0.1537\n",
      "Epoch [48/50], Step [423/735], Loss: 0.3206\n",
      "Epoch [48/50], Step [424/735], Loss: 0.2398\n",
      "Epoch [48/50], Step [425/735], Loss: 0.1336\n",
      "Epoch [48/50], Step [426/735], Loss: 0.1411\n",
      "Epoch [48/50], Step [427/735], Loss: 0.2465\n",
      "Epoch [48/50], Step [428/735], Loss: 0.3911\n",
      "Epoch [48/50], Step [429/735], Loss: 0.1484\n",
      "Epoch [48/50], Step [430/735], Loss: 0.4016\n",
      "Epoch [48/50], Step [431/735], Loss: 0.2394\n",
      "Epoch [48/50], Step [432/735], Loss: 0.1909\n",
      "Epoch [48/50], Step [433/735], Loss: 0.2168\n",
      "Epoch [48/50], Step [434/735], Loss: 0.4743\n",
      "Epoch [48/50], Step [435/735], Loss: 0.3133\n",
      "Epoch [48/50], Step [436/735], Loss: 0.3287\n",
      "Epoch [48/50], Step [437/735], Loss: 0.1812\n",
      "Epoch [48/50], Step [438/735], Loss: 0.2918\n",
      "Epoch [48/50], Step [439/735], Loss: 0.2672\n",
      "Epoch [48/50], Step [440/735], Loss: 0.3619\n",
      "Epoch [48/50], Step [441/735], Loss: 0.2542\n",
      "Epoch [48/50], Step [442/735], Loss: 0.1064\n",
      "Epoch [48/50], Step [443/735], Loss: 0.2254\n",
      "Epoch [48/50], Step [444/735], Loss: 1.1996\n",
      "Epoch [48/50], Step [445/735], Loss: 0.3273\n",
      "Epoch [48/50], Step [446/735], Loss: 0.5147\n",
      "Epoch [48/50], Step [447/735], Loss: 0.2402\n",
      "Epoch [48/50], Step [448/735], Loss: 0.0874\n",
      "Epoch [48/50], Step [449/735], Loss: 0.3464\n",
      "Epoch [48/50], Step [450/735], Loss: 0.0586\n",
      "Epoch [48/50], Step [451/735], Loss: 0.1817\n",
      "Epoch [48/50], Step [452/735], Loss: 0.0903\n",
      "Epoch [48/50], Step [453/735], Loss: 0.1104\n",
      "Epoch [48/50], Step [454/735], Loss: 0.4882\n",
      "Epoch [48/50], Step [455/735], Loss: 0.4493\n",
      "Epoch [48/50], Step [456/735], Loss: 0.4652\n",
      "Epoch [48/50], Step [457/735], Loss: 0.1620\n",
      "Epoch [48/50], Step [458/735], Loss: 0.4872\n",
      "Epoch [48/50], Step [459/735], Loss: 0.2488\n",
      "Epoch [48/50], Step [460/735], Loss: 0.2571\n",
      "Epoch [48/50], Step [461/735], Loss: 0.1064\n",
      "Epoch [48/50], Step [462/735], Loss: 0.3530\n",
      "Epoch [48/50], Step [463/735], Loss: 0.2548\n",
      "Epoch [48/50], Step [464/735], Loss: 0.0745\n",
      "Epoch [48/50], Step [465/735], Loss: 0.9808\n",
      "Epoch [48/50], Step [466/735], Loss: 0.1772\n",
      "Epoch [48/50], Step [467/735], Loss: 0.3932\n",
      "Epoch [48/50], Step [468/735], Loss: 0.1633\n",
      "Epoch [48/50], Step [469/735], Loss: 0.1110\n",
      "Epoch [48/50], Step [470/735], Loss: 0.1505\n",
      "Epoch [48/50], Step [471/735], Loss: 0.1727\n",
      "Epoch [48/50], Step [472/735], Loss: 0.5505\n",
      "Epoch [48/50], Step [473/735], Loss: 0.0900\n",
      "Epoch [48/50], Step [474/735], Loss: 0.2613\n",
      "Epoch [48/50], Step [475/735], Loss: 0.2913\n",
      "Epoch [48/50], Step [476/735], Loss: 0.2040\n",
      "Epoch [48/50], Step [477/735], Loss: 0.1465\n",
      "Epoch [48/50], Step [478/735], Loss: 0.1074\n",
      "Epoch [48/50], Step [479/735], Loss: 0.2532\n",
      "Epoch [48/50], Step [480/735], Loss: 0.0963\n",
      "Epoch [48/50], Step [481/735], Loss: 0.4205\n",
      "Epoch [48/50], Step [482/735], Loss: 0.1452\n",
      "Epoch [48/50], Step [483/735], Loss: 0.1947\n",
      "Epoch [48/50], Step [484/735], Loss: 0.3014\n",
      "Epoch [48/50], Step [485/735], Loss: 0.2295\n",
      "Epoch [48/50], Step [486/735], Loss: 0.1407\n",
      "Epoch [48/50], Step [487/735], Loss: 0.7660\n",
      "Epoch [48/50], Step [488/735], Loss: 0.5683\n",
      "Epoch [48/50], Step [489/735], Loss: 0.3272\n",
      "Epoch [48/50], Step [490/735], Loss: 0.1841\n",
      "Epoch [48/50], Step [491/735], Loss: 0.3516\n",
      "Epoch [48/50], Step [492/735], Loss: 0.4095\n",
      "Epoch [48/50], Step [493/735], Loss: 0.2763\n",
      "Epoch [48/50], Step [494/735], Loss: 0.3846\n",
      "Epoch [48/50], Step [495/735], Loss: 0.1913\n",
      "Epoch [48/50], Step [496/735], Loss: 0.2314\n",
      "Epoch [48/50], Step [497/735], Loss: 0.2282\n",
      "Epoch [48/50], Step [498/735], Loss: 0.1479\n",
      "Epoch [48/50], Step [499/735], Loss: 0.1394\n",
      "Epoch [48/50], Step [500/735], Loss: 0.1134\n",
      "Epoch [48/50], Step [501/735], Loss: 0.1738\n",
      "Epoch [48/50], Step [502/735], Loss: 0.3448\n",
      "Epoch [48/50], Step [503/735], Loss: 0.1262\n",
      "Epoch [48/50], Step [504/735], Loss: 0.3315\n",
      "Epoch [48/50], Step [505/735], Loss: 0.2918\n",
      "Epoch [48/50], Step [506/735], Loss: 0.3858\n",
      "Epoch [48/50], Step [507/735], Loss: 0.1749\n",
      "Epoch [48/50], Step [508/735], Loss: 0.2807\n",
      "Epoch [48/50], Step [509/735], Loss: 0.7434\n",
      "Epoch [48/50], Step [510/735], Loss: 0.1219\n",
      "Epoch [48/50], Step [511/735], Loss: 0.4776\n",
      "Epoch [48/50], Step [512/735], Loss: 0.1439\n",
      "Epoch [48/50], Step [513/735], Loss: 0.2224\n",
      "Epoch [48/50], Step [514/735], Loss: 0.1340\n",
      "Epoch [48/50], Step [515/735], Loss: 0.1808\n",
      "Epoch [48/50], Step [516/735], Loss: 0.0641\n",
      "Epoch [48/50], Step [517/735], Loss: 0.4634\n",
      "Epoch [48/50], Step [518/735], Loss: 0.2014\n",
      "Epoch [48/50], Step [519/735], Loss: 0.2688\n",
      "Epoch [48/50], Step [520/735], Loss: 0.1777\n",
      "Epoch [48/50], Step [521/735], Loss: 0.4442\n",
      "Epoch [48/50], Step [522/735], Loss: 0.1879\n",
      "Epoch [48/50], Step [523/735], Loss: 0.1687\n",
      "Epoch [48/50], Step [524/735], Loss: 0.1363\n",
      "Epoch [48/50], Step [525/735], Loss: 0.2388\n",
      "Epoch [48/50], Step [526/735], Loss: 0.1159\n",
      "Epoch [48/50], Step [527/735], Loss: 0.2764\n",
      "Epoch [48/50], Step [528/735], Loss: 0.1625\n",
      "Epoch [48/50], Step [529/735], Loss: 0.2615\n",
      "Epoch [48/50], Step [530/735], Loss: 0.1717\n",
      "Epoch [48/50], Step [531/735], Loss: 0.1351\n",
      "Epoch [48/50], Step [532/735], Loss: 0.3169\n",
      "Epoch [48/50], Step [533/735], Loss: 0.2477\n",
      "Epoch [48/50], Step [534/735], Loss: 0.2863\n",
      "Epoch [48/50], Step [535/735], Loss: 0.2247\n",
      "Epoch [48/50], Step [536/735], Loss: 0.2317\n",
      "Epoch [48/50], Step [537/735], Loss: 0.1491\n",
      "Epoch [48/50], Step [538/735], Loss: 0.2006\n",
      "Epoch [48/50], Step [539/735], Loss: 0.1610\n",
      "Epoch [48/50], Step [540/735], Loss: 0.3586\n",
      "Epoch [48/50], Step [541/735], Loss: 0.1894\n",
      "Epoch [48/50], Step [542/735], Loss: 0.9073\n",
      "Epoch [48/50], Step [543/735], Loss: 0.1996\n",
      "Epoch [48/50], Step [544/735], Loss: 0.1896\n",
      "Epoch [48/50], Step [545/735], Loss: 0.2092\n",
      "Epoch [48/50], Step [546/735], Loss: 0.3418\n",
      "Epoch [48/50], Step [547/735], Loss: 3.2542\n",
      "Epoch [48/50], Step [548/735], Loss: 0.1009\n",
      "Epoch [48/50], Step [549/735], Loss: 0.0645\n",
      "Epoch [48/50], Step [550/735], Loss: 0.1373\n",
      "Epoch [48/50], Step [551/735], Loss: 0.1268\n",
      "Epoch [48/50], Step [552/735], Loss: 0.2862\n",
      "Epoch [48/50], Step [553/735], Loss: 0.1205\n",
      "Epoch [48/50], Step [554/735], Loss: 1.0587\n",
      "Epoch [48/50], Step [555/735], Loss: 0.1553\n",
      "Epoch [48/50], Step [556/735], Loss: 0.0890\n",
      "Epoch [48/50], Step [557/735], Loss: 0.3712\n",
      "Epoch [48/50], Step [558/735], Loss: 0.2385\n",
      "Epoch [48/50], Step [559/735], Loss: 0.1775\n",
      "Epoch [48/50], Step [560/735], Loss: 0.0726\n",
      "Epoch [48/50], Step [561/735], Loss: 0.1086\n",
      "Epoch [48/50], Step [562/735], Loss: 0.2574\n",
      "Epoch [48/50], Step [563/735], Loss: 0.3175\n",
      "Epoch [48/50], Step [564/735], Loss: 0.0910\n",
      "Epoch [48/50], Step [565/735], Loss: 0.3818\n",
      "Epoch [48/50], Step [566/735], Loss: 2.3783\n",
      "Epoch [48/50], Step [567/735], Loss: 0.3023\n",
      "Epoch [48/50], Step [568/735], Loss: 0.0965\n",
      "Epoch [48/50], Step [569/735], Loss: 0.4394\n",
      "Epoch [48/50], Step [570/735], Loss: 0.1534\n",
      "Epoch [48/50], Step [571/735], Loss: 0.3434\n",
      "Epoch [48/50], Step [572/735], Loss: 0.1823\n",
      "Epoch [48/50], Step [573/735], Loss: 0.1506\n",
      "Epoch [48/50], Step [574/735], Loss: 0.0693\n",
      "Epoch [48/50], Step [575/735], Loss: 0.2388\n",
      "Epoch [48/50], Step [576/735], Loss: 0.2786\n",
      "Epoch [48/50], Step [577/735], Loss: 0.3894\n",
      "Epoch [48/50], Step [578/735], Loss: 0.0572\n",
      "Epoch [48/50], Step [579/735], Loss: 0.2961\n",
      "Epoch [48/50], Step [580/735], Loss: 0.0738\n",
      "Epoch [48/50], Step [581/735], Loss: 0.2221\n",
      "Epoch [48/50], Step [582/735], Loss: 0.1474\n",
      "Epoch [48/50], Step [583/735], Loss: 0.1062\n",
      "Epoch [48/50], Step [584/735], Loss: 0.2793\n",
      "Epoch [48/50], Step [585/735], Loss: 0.4915\n",
      "Epoch [48/50], Step [586/735], Loss: 0.1908\n",
      "Epoch [48/50], Step [587/735], Loss: 0.1872\n",
      "Epoch [48/50], Step [588/735], Loss: 0.2098\n",
      "Epoch [48/50], Step [589/735], Loss: 0.1670\n",
      "Epoch [48/50], Step [590/735], Loss: 0.3957\n",
      "Epoch [48/50], Step [591/735], Loss: 0.2014\n",
      "Epoch [48/50], Step [592/735], Loss: 0.1232\n",
      "Epoch [48/50], Step [593/735], Loss: 0.2950\n",
      "Epoch [48/50], Step [594/735], Loss: 0.4886\n",
      "Epoch [48/50], Step [595/735], Loss: 0.1233\n",
      "Epoch [48/50], Step [596/735], Loss: 0.1474\n",
      "Epoch [48/50], Step [597/735], Loss: 0.2925\n",
      "Epoch [48/50], Step [598/735], Loss: 0.1661\n",
      "Epoch [48/50], Step [599/735], Loss: 0.3158\n",
      "Epoch [48/50], Step [600/735], Loss: 0.4077\n",
      "Epoch [48/50], Step [601/735], Loss: 0.7781\n",
      "Epoch [48/50], Step [602/735], Loss: 0.0878\n",
      "Epoch [48/50], Step [603/735], Loss: 0.4348\n",
      "Epoch [48/50], Step [604/735], Loss: 0.4805\n",
      "Epoch [48/50], Step [605/735], Loss: 0.2411\n",
      "Epoch [48/50], Step [606/735], Loss: 0.3970\n",
      "Epoch [48/50], Step [607/735], Loss: 0.1661\n",
      "Epoch [48/50], Step [608/735], Loss: 0.3581\n",
      "Epoch [48/50], Step [609/735], Loss: 0.0555\n",
      "Epoch [48/50], Step [610/735], Loss: 0.1842\n",
      "Epoch [48/50], Step [611/735], Loss: 0.1120\n",
      "Epoch [48/50], Step [612/735], Loss: 0.1549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Step [613/735], Loss: 0.2658\n",
      "Epoch [48/50], Step [614/735], Loss: 0.3183\n",
      "Epoch [48/50], Step [615/735], Loss: 0.2895\n",
      "Epoch [48/50], Step [616/735], Loss: 0.2306\n",
      "Epoch [48/50], Step [617/735], Loss: 0.2060\n",
      "Epoch [48/50], Step [618/735], Loss: 0.2753\n",
      "Epoch [48/50], Step [619/735], Loss: 0.3768\n",
      "Epoch [48/50], Step [620/735], Loss: 0.1572\n",
      "Epoch [48/50], Step [621/735], Loss: 0.1709\n",
      "Epoch [48/50], Step [622/735], Loss: 0.5154\n",
      "Epoch [48/50], Step [623/735], Loss: 0.2230\n",
      "Epoch [48/50], Step [624/735], Loss: 0.9018\n",
      "Epoch [48/50], Step [625/735], Loss: 0.0869\n",
      "Epoch [48/50], Step [626/735], Loss: 0.2449\n",
      "Epoch [48/50], Step [627/735], Loss: 0.1803\n",
      "Epoch [48/50], Step [628/735], Loss: 2.5095\n",
      "Epoch [48/50], Step [629/735], Loss: 0.2524\n",
      "Epoch [48/50], Step [630/735], Loss: 0.4585\n",
      "Epoch [48/50], Step [631/735], Loss: 0.0906\n",
      "Epoch [48/50], Step [632/735], Loss: 0.0828\n",
      "Epoch [48/50], Step [633/735], Loss: 0.1705\n",
      "Epoch [48/50], Step [634/735], Loss: 0.4079\n",
      "Epoch [48/50], Step [635/735], Loss: 0.3662\n",
      "Epoch [48/50], Step [636/735], Loss: 0.1654\n",
      "Epoch [48/50], Step [637/735], Loss: 0.2327\n",
      "Epoch [48/50], Step [638/735], Loss: 0.2766\n",
      "Epoch [48/50], Step [639/735], Loss: 0.3458\n",
      "Epoch [48/50], Step [640/735], Loss: 0.4718\n",
      "Epoch [48/50], Step [641/735], Loss: 0.3022\n",
      "Epoch [48/50], Step [642/735], Loss: 0.1523\n",
      "Epoch [48/50], Step [643/735], Loss: 0.1175\n",
      "Epoch [48/50], Step [644/735], Loss: 0.1776\n",
      "Epoch [48/50], Step [645/735], Loss: 0.1495\n",
      "Epoch [48/50], Step [646/735], Loss: 0.1684\n",
      "Epoch [48/50], Step [647/735], Loss: 0.1446\n",
      "Epoch [48/50], Step [648/735], Loss: 0.1300\n",
      "Epoch [48/50], Step [649/735], Loss: 0.2652\n",
      "Epoch [48/50], Step [650/735], Loss: 0.3828\n",
      "Epoch [48/50], Step [651/735], Loss: 0.8647\n",
      "Epoch [48/50], Step [652/735], Loss: 1.0217\n",
      "Epoch [48/50], Step [653/735], Loss: 0.2486\n",
      "Epoch [48/50], Step [654/735], Loss: 0.2414\n",
      "Epoch [48/50], Step [655/735], Loss: 0.0516\n",
      "Epoch [48/50], Step [656/735], Loss: 0.0661\n",
      "Epoch [48/50], Step [657/735], Loss: 0.3279\n",
      "Epoch [48/50], Step [658/735], Loss: 0.1353\n",
      "Epoch [48/50], Step [659/735], Loss: 0.3315\n",
      "Epoch [48/50], Step [660/735], Loss: 0.4351\n",
      "Epoch [48/50], Step [661/735], Loss: 0.6997\n",
      "Epoch [48/50], Step [662/735], Loss: 0.3835\n",
      "Epoch [48/50], Step [663/735], Loss: 0.1266\n",
      "Epoch [48/50], Step [664/735], Loss: 0.2703\n",
      "Epoch [48/50], Step [665/735], Loss: 0.4433\n",
      "Epoch [48/50], Step [666/735], Loss: 0.2204\n",
      "Epoch [48/50], Step [667/735], Loss: 0.3932\n",
      "Epoch [48/50], Step [668/735], Loss: 0.4874\n",
      "Epoch [48/50], Step [669/735], Loss: 0.3989\n",
      "Epoch [48/50], Step [670/735], Loss: 0.2134\n",
      "Epoch [48/50], Step [671/735], Loss: 0.1290\n",
      "Epoch [48/50], Step [672/735], Loss: 0.2699\n",
      "Epoch [48/50], Step [673/735], Loss: 0.2486\n",
      "Epoch [48/50], Step [674/735], Loss: 0.7441\n",
      "Epoch [48/50], Step [675/735], Loss: 0.2072\n",
      "Epoch [48/50], Step [676/735], Loss: 0.3560\n",
      "Epoch [48/50], Step [677/735], Loss: 0.2821\n",
      "Epoch [48/50], Step [678/735], Loss: 0.3037\n",
      "Epoch [48/50], Step [679/735], Loss: 0.1147\n",
      "Epoch [48/50], Step [680/735], Loss: 0.5026\n",
      "Epoch [48/50], Step [681/735], Loss: 0.1285\n",
      "Epoch [48/50], Step [682/735], Loss: 0.2330\n",
      "Epoch [48/50], Step [683/735], Loss: 0.3565\n",
      "Epoch [48/50], Step [684/735], Loss: 0.2035\n",
      "Epoch [48/50], Step [685/735], Loss: 0.2790\n",
      "Epoch [48/50], Step [686/735], Loss: 0.3282\n",
      "Epoch [48/50], Step [687/735], Loss: 0.3256\n",
      "Epoch [48/50], Step [688/735], Loss: 0.2285\n",
      "Epoch [48/50], Step [689/735], Loss: 0.3808\n",
      "Epoch [48/50], Step [690/735], Loss: 0.4603\n",
      "Epoch [48/50], Step [691/735], Loss: 0.2391\n",
      "Epoch [48/50], Step [692/735], Loss: 0.1332\n",
      "Epoch [48/50], Step [693/735], Loss: 0.1913\n",
      "Epoch [48/50], Step [694/735], Loss: 0.2868\n",
      "Epoch [48/50], Step [695/735], Loss: 0.2589\n",
      "Epoch [48/50], Step [696/735], Loss: 0.1742\n",
      "Epoch [48/50], Step [697/735], Loss: 0.8848\n",
      "Epoch [48/50], Step [698/735], Loss: 0.4332\n",
      "Epoch [48/50], Step [699/735], Loss: 0.1710\n",
      "Epoch [48/50], Step [700/735], Loss: 0.4993\n",
      "Epoch [48/50], Step [701/735], Loss: 0.1902\n",
      "Epoch [48/50], Step [702/735], Loss: 0.3639\n",
      "Epoch [48/50], Step [703/735], Loss: 0.3174\n",
      "Epoch [48/50], Step [704/735], Loss: 0.2497\n",
      "Epoch [48/50], Step [705/735], Loss: 0.1698\n",
      "Epoch [48/50], Step [706/735], Loss: 0.3680\n",
      "Epoch [48/50], Step [707/735], Loss: 0.2685\n",
      "Epoch [48/50], Step [708/735], Loss: 0.1956\n",
      "Epoch [48/50], Step [709/735], Loss: 0.1733\n",
      "Epoch [48/50], Step [710/735], Loss: 0.2366\n",
      "Epoch [48/50], Step [711/735], Loss: 0.2703\n",
      "Epoch [48/50], Step [712/735], Loss: 0.1853\n",
      "Epoch [48/50], Step [713/735], Loss: 0.1393\n",
      "Epoch [48/50], Step [714/735], Loss: 0.4998\n",
      "Epoch [48/50], Step [715/735], Loss: 0.0823\n",
      "Epoch [48/50], Step [716/735], Loss: 0.1465\n",
      "Epoch [48/50], Step [717/735], Loss: 0.1728\n",
      "Epoch [48/50], Step [718/735], Loss: 0.1884\n",
      "Epoch [48/50], Step [719/735], Loss: 0.1432\n",
      "Epoch [48/50], Step [720/735], Loss: 0.3539\n",
      "Epoch [48/50], Step [721/735], Loss: 0.9866\n",
      "Epoch [48/50], Step [722/735], Loss: 0.2669\n",
      "Epoch [48/50], Step [723/735], Loss: 0.5417\n",
      "Epoch [48/50], Step [724/735], Loss: 0.0958\n",
      "Epoch [48/50], Step [725/735], Loss: 0.1101\n",
      "Epoch [48/50], Step [726/735], Loss: 0.1605\n",
      "Epoch [48/50], Step [727/735], Loss: 0.1470\n",
      "Epoch [48/50], Step [728/735], Loss: 0.2961\n",
      "Epoch [48/50], Step [729/735], Loss: 0.1971\n",
      "Epoch [48/50], Step [730/735], Loss: 0.0730\n",
      "Epoch [48/50], Step [731/735], Loss: 0.3272\n",
      "Epoch [48/50], Step [732/735], Loss: 0.3581\n",
      "Epoch [48/50], Step [733/735], Loss: 0.2070\n",
      "Epoch [48/50], Step [734/735], Loss: 0.1890\n",
      "Epoch [48/50], Step [735/735], Loss: 0.0438\n",
      "Epoch [49/50], Step [1/735], Loss: 0.1198\n",
      "Epoch [49/50], Step [2/735], Loss: 0.1158\n",
      "Epoch [49/50], Step [3/735], Loss: 0.4921\n",
      "Epoch [49/50], Step [4/735], Loss: 0.3498\n",
      "Epoch [49/50], Step [5/735], Loss: 0.1594\n",
      "Epoch [49/50], Step [6/735], Loss: 0.5840\n",
      "Epoch [49/50], Step [7/735], Loss: 0.4621\n",
      "Epoch [49/50], Step [8/735], Loss: 0.5928\n",
      "Epoch [49/50], Step [9/735], Loss: 0.5522\n",
      "Epoch [49/50], Step [10/735], Loss: 0.1776\n",
      "Epoch [49/50], Step [11/735], Loss: 0.1390\n",
      "Epoch [49/50], Step [12/735], Loss: 0.0832\n",
      "Epoch [49/50], Step [13/735], Loss: 0.2030\n",
      "Epoch [49/50], Step [14/735], Loss: 0.1283\n",
      "Epoch [49/50], Step [15/735], Loss: 0.2943\n",
      "Epoch [49/50], Step [16/735], Loss: 0.2545\n",
      "Epoch [49/50], Step [17/735], Loss: 0.1130\n",
      "Epoch [49/50], Step [18/735], Loss: 0.5584\n",
      "Epoch [49/50], Step [19/735], Loss: 0.0983\n",
      "Epoch [49/50], Step [20/735], Loss: 0.1739\n",
      "Epoch [49/50], Step [21/735], Loss: 0.1386\n",
      "Epoch [49/50], Step [22/735], Loss: 0.1502\n",
      "Epoch [49/50], Step [23/735], Loss: 0.1298\n",
      "Epoch [49/50], Step [24/735], Loss: 0.4988\n",
      "Epoch [49/50], Step [25/735], Loss: 0.7438\n",
      "Epoch [49/50], Step [26/735], Loss: 0.1919\n",
      "Epoch [49/50], Step [27/735], Loss: 0.1631\n",
      "Epoch [49/50], Step [28/735], Loss: 0.3359\n",
      "Epoch [49/50], Step [29/735], Loss: 0.4049\n",
      "Epoch [49/50], Step [30/735], Loss: 0.5119\n",
      "Epoch [49/50], Step [31/735], Loss: 0.5816\n",
      "Epoch [49/50], Step [32/735], Loss: 0.0981\n",
      "Epoch [49/50], Step [33/735], Loss: 0.1455\n",
      "Epoch [49/50], Step [34/735], Loss: 0.3754\n",
      "Epoch [49/50], Step [35/735], Loss: 0.1810\n",
      "Epoch [49/50], Step [36/735], Loss: 0.3366\n",
      "Epoch [49/50], Step [37/735], Loss: 0.6529\n",
      "Epoch [49/50], Step [38/735], Loss: 0.1121\n",
      "Epoch [49/50], Step [39/735], Loss: 0.3351\n",
      "Epoch [49/50], Step [40/735], Loss: 0.3627\n",
      "Epoch [49/50], Step [41/735], Loss: 0.1200\n",
      "Epoch [49/50], Step [42/735], Loss: 0.1993\n",
      "Epoch [49/50], Step [43/735], Loss: 0.0964\n",
      "Epoch [49/50], Step [44/735], Loss: 0.4218\n",
      "Epoch [49/50], Step [45/735], Loss: 0.4066\n",
      "Epoch [49/50], Step [46/735], Loss: 0.1182\n",
      "Epoch [49/50], Step [47/735], Loss: 0.5466\n",
      "Epoch [49/50], Step [48/735], Loss: 0.3047\n",
      "Epoch [49/50], Step [49/735], Loss: 0.1592\n",
      "Epoch [49/50], Step [50/735], Loss: 0.2843\n",
      "Epoch [49/50], Step [51/735], Loss: 0.2894\n",
      "Epoch [49/50], Step [52/735], Loss: 0.0748\n",
      "Epoch [49/50], Step [53/735], Loss: 0.3284\n",
      "Epoch [49/50], Step [54/735], Loss: 0.1209\n",
      "Epoch [49/50], Step [55/735], Loss: 0.1321\n",
      "Epoch [49/50], Step [56/735], Loss: 0.4087\n",
      "Epoch [49/50], Step [57/735], Loss: 0.0949\n",
      "Epoch [49/50], Step [58/735], Loss: 0.2080\n",
      "Epoch [49/50], Step [59/735], Loss: 0.2278\n",
      "Epoch [49/50], Step [60/735], Loss: 0.1950\n",
      "Epoch [49/50], Step [61/735], Loss: 0.1615\n",
      "Epoch [49/50], Step [62/735], Loss: 0.2000\n",
      "Epoch [49/50], Step [63/735], Loss: 0.2189\n",
      "Epoch [49/50], Step [64/735], Loss: 0.1324\n",
      "Epoch [49/50], Step [65/735], Loss: 0.2141\n",
      "Epoch [49/50], Step [66/735], Loss: 2.7000\n",
      "Epoch [49/50], Step [67/735], Loss: 0.1302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Step [68/735], Loss: 0.1564\n",
      "Epoch [49/50], Step [69/735], Loss: 0.1432\n",
      "Epoch [49/50], Step [70/735], Loss: 0.4418\n",
      "Epoch [49/50], Step [71/735], Loss: 0.2259\n",
      "Epoch [49/50], Step [72/735], Loss: 0.8879\n",
      "Epoch [49/50], Step [73/735], Loss: 0.4580\n",
      "Epoch [49/50], Step [74/735], Loss: 0.0664\n",
      "Epoch [49/50], Step [75/735], Loss: 0.2728\n",
      "Epoch [49/50], Step [76/735], Loss: 0.0866\n",
      "Epoch [49/50], Step [77/735], Loss: 0.2487\n",
      "Epoch [49/50], Step [78/735], Loss: 0.5351\n",
      "Epoch [49/50], Step [79/735], Loss: 0.2297\n",
      "Epoch [49/50], Step [80/735], Loss: 0.2045\n",
      "Epoch [49/50], Step [81/735], Loss: 0.2119\n",
      "Epoch [49/50], Step [82/735], Loss: 0.1054\n",
      "Epoch [49/50], Step [83/735], Loss: 0.1446\n",
      "Epoch [49/50], Step [84/735], Loss: 0.2189\n",
      "Epoch [49/50], Step [85/735], Loss: 0.1509\n",
      "Epoch [49/50], Step [86/735], Loss: 0.3950\n",
      "Epoch [49/50], Step [87/735], Loss: 0.1361\n",
      "Epoch [49/50], Step [88/735], Loss: 0.1221\n",
      "Epoch [49/50], Step [89/735], Loss: 0.2451\n",
      "Epoch [49/50], Step [90/735], Loss: 0.1393\n",
      "Epoch [49/50], Step [91/735], Loss: 0.1182\n",
      "Epoch [49/50], Step [92/735], Loss: 0.2278\n",
      "Epoch [49/50], Step [93/735], Loss: 0.3074\n",
      "Epoch [49/50], Step [94/735], Loss: 0.1144\n",
      "Epoch [49/50], Step [95/735], Loss: 0.0973\n",
      "Epoch [49/50], Step [96/735], Loss: 0.5020\n",
      "Epoch [49/50], Step [97/735], Loss: 0.1281\n",
      "Epoch [49/50], Step [98/735], Loss: 0.0743\n",
      "Epoch [49/50], Step [99/735], Loss: 0.6058\n",
      "Epoch [49/50], Step [100/735], Loss: 0.1137\n",
      "Epoch [49/50], Step [101/735], Loss: 0.3785\n",
      "Epoch [49/50], Step [102/735], Loss: 0.1177\n",
      "Epoch [49/50], Step [103/735], Loss: 0.2328\n",
      "Epoch [49/50], Step [104/735], Loss: 0.0786\n",
      "Epoch [49/50], Step [105/735], Loss: 0.0728\n",
      "Epoch [49/50], Step [106/735], Loss: 0.2086\n",
      "Epoch [49/50], Step [107/735], Loss: 0.1158\n",
      "Epoch [49/50], Step [108/735], Loss: 0.3193\n",
      "Epoch [49/50], Step [109/735], Loss: 0.0682\n",
      "Epoch [49/50], Step [110/735], Loss: 0.0747\n",
      "Epoch [49/50], Step [111/735], Loss: 0.1535\n",
      "Epoch [49/50], Step [112/735], Loss: 0.4685\n",
      "Epoch [49/50], Step [113/735], Loss: 0.1933\n",
      "Epoch [49/50], Step [114/735], Loss: 0.1692\n",
      "Epoch [49/50], Step [115/735], Loss: 0.3840\n",
      "Epoch [49/50], Step [116/735], Loss: 0.2836\n",
      "Epoch [49/50], Step [117/735], Loss: 0.1898\n",
      "Epoch [49/50], Step [118/735], Loss: 0.4520\n",
      "Epoch [49/50], Step [119/735], Loss: 0.1103\n",
      "Epoch [49/50], Step [120/735], Loss: 0.1918\n",
      "Epoch [49/50], Step [121/735], Loss: 0.2952\n",
      "Epoch [49/50], Step [122/735], Loss: 0.2411\n",
      "Epoch [49/50], Step [123/735], Loss: 0.2476\n",
      "Epoch [49/50], Step [124/735], Loss: 0.1617\n",
      "Epoch [49/50], Step [125/735], Loss: 0.0808\n",
      "Epoch [49/50], Step [126/735], Loss: 0.2792\n",
      "Epoch [49/50], Step [127/735], Loss: 2.3654\n",
      "Epoch [49/50], Step [128/735], Loss: 0.2455\n",
      "Epoch [49/50], Step [129/735], Loss: 0.2862\n",
      "Epoch [49/50], Step [130/735], Loss: 0.1955\n",
      "Epoch [49/50], Step [131/735], Loss: 0.3462\n",
      "Epoch [49/50], Step [132/735], Loss: 0.2237\n",
      "Epoch [49/50], Step [133/735], Loss: 0.2178\n",
      "Epoch [49/50], Step [134/735], Loss: 0.1582\n",
      "Epoch [49/50], Step [135/735], Loss: 0.7200\n",
      "Epoch [49/50], Step [136/735], Loss: 0.3452\n",
      "Epoch [49/50], Step [137/735], Loss: 0.3467\n",
      "Epoch [49/50], Step [138/735], Loss: 0.0917\n",
      "Epoch [49/50], Step [139/735], Loss: 0.2897\n",
      "Epoch [49/50], Step [140/735], Loss: 0.4979\n",
      "Epoch [49/50], Step [141/735], Loss: 0.1114\n",
      "Epoch [49/50], Step [142/735], Loss: 0.7259\n",
      "Epoch [49/50], Step [143/735], Loss: 0.6867\n",
      "Epoch [49/50], Step [144/735], Loss: 0.1020\n",
      "Epoch [49/50], Step [145/735], Loss: 0.3145\n",
      "Epoch [49/50], Step [146/735], Loss: 0.2607\n",
      "Epoch [49/50], Step [147/735], Loss: 0.3039\n",
      "Epoch [49/50], Step [148/735], Loss: 0.6707\n",
      "Epoch [49/50], Step [149/735], Loss: 0.0798\n",
      "Epoch [49/50], Step [150/735], Loss: 0.0880\n",
      "Epoch [49/50], Step [151/735], Loss: 0.3375\n",
      "Epoch [49/50], Step [152/735], Loss: 0.2327\n",
      "Epoch [49/50], Step [153/735], Loss: 0.1055\n",
      "Epoch [49/50], Step [154/735], Loss: 0.0458\n",
      "Epoch [49/50], Step [155/735], Loss: 0.2689\n",
      "Epoch [49/50], Step [156/735], Loss: 0.1710\n",
      "Epoch [49/50], Step [157/735], Loss: 0.1700\n",
      "Epoch [49/50], Step [158/735], Loss: 0.1741\n",
      "Epoch [49/50], Step [159/735], Loss: 1.3252\n",
      "Epoch [49/50], Step [160/735], Loss: 0.2604\n",
      "Epoch [49/50], Step [161/735], Loss: 0.1620\n",
      "Epoch [49/50], Step [162/735], Loss: 0.3090\n",
      "Epoch [49/50], Step [163/735], Loss: 0.2511\n",
      "Epoch [49/50], Step [164/735], Loss: 0.6358\n",
      "Epoch [49/50], Step [165/735], Loss: 0.2729\n",
      "Epoch [49/50], Step [166/735], Loss: 0.2394\n",
      "Epoch [49/50], Step [167/735], Loss: 0.2900\n",
      "Epoch [49/50], Step [168/735], Loss: 0.3155\n",
      "Epoch [49/50], Step [169/735], Loss: 0.1521\n",
      "Epoch [49/50], Step [170/735], Loss: 0.1887\n",
      "Epoch [49/50], Step [171/735], Loss: 0.3226\n",
      "Epoch [49/50], Step [172/735], Loss: 0.2340\n",
      "Epoch [49/50], Step [173/735], Loss: 0.2696\n",
      "Epoch [49/50], Step [174/735], Loss: 0.2010\n",
      "Epoch [49/50], Step [175/735], Loss: 0.4484\n",
      "Epoch [49/50], Step [176/735], Loss: 0.6228\n",
      "Epoch [49/50], Step [177/735], Loss: 0.4487\n",
      "Epoch [49/50], Step [178/735], Loss: 0.3065\n",
      "Epoch [49/50], Step [179/735], Loss: 0.0788\n",
      "Epoch [49/50], Step [180/735], Loss: 0.0800\n",
      "Epoch [49/50], Step [181/735], Loss: 0.1917\n",
      "Epoch [49/50], Step [182/735], Loss: 0.1508\n",
      "Epoch [49/50], Step [183/735], Loss: 0.2351\n",
      "Epoch [49/50], Step [184/735], Loss: 0.1602\n",
      "Epoch [49/50], Step [185/735], Loss: 0.4169\n",
      "Epoch [49/50], Step [186/735], Loss: 0.2126\n",
      "Epoch [49/50], Step [187/735], Loss: 0.3504\n",
      "Epoch [49/50], Step [188/735], Loss: 0.1858\n",
      "Epoch [49/50], Step [189/735], Loss: 0.3372\n",
      "Epoch [49/50], Step [190/735], Loss: 0.1615\n",
      "Epoch [49/50], Step [191/735], Loss: 0.3885\n",
      "Epoch [49/50], Step [192/735], Loss: 0.2713\n",
      "Epoch [49/50], Step [193/735], Loss: 0.4173\n",
      "Epoch [49/50], Step [194/735], Loss: 0.3103\n",
      "Epoch [49/50], Step [195/735], Loss: 0.1147\n",
      "Epoch [49/50], Step [196/735], Loss: 0.2737\n",
      "Epoch [49/50], Step [197/735], Loss: 0.2879\n",
      "Epoch [49/50], Step [198/735], Loss: 0.1363\n",
      "Epoch [49/50], Step [199/735], Loss: 0.4229\n",
      "Epoch [49/50], Step [200/735], Loss: 0.2190\n",
      "Epoch [49/50], Step [201/735], Loss: 0.2085\n",
      "Epoch [49/50], Step [202/735], Loss: 0.2004\n",
      "Epoch [49/50], Step [203/735], Loss: 0.2493\n",
      "Epoch [49/50], Step [204/735], Loss: 0.1950\n",
      "Epoch [49/50], Step [205/735], Loss: 0.3585\n",
      "Epoch [49/50], Step [206/735], Loss: 0.2968\n",
      "Epoch [49/50], Step [207/735], Loss: 0.8118\n",
      "Epoch [49/50], Step [208/735], Loss: 0.3421\n",
      "Epoch [49/50], Step [209/735], Loss: 0.1277\n",
      "Epoch [49/50], Step [210/735], Loss: 0.2299\n",
      "Epoch [49/50], Step [211/735], Loss: 0.2905\n",
      "Epoch [49/50], Step [212/735], Loss: 0.2869\n",
      "Epoch [49/50], Step [213/735], Loss: 0.2694\n",
      "Epoch [49/50], Step [214/735], Loss: 0.3862\n",
      "Epoch [49/50], Step [215/735], Loss: 0.5736\n",
      "Epoch [49/50], Step [216/735], Loss: 0.2207\n",
      "Epoch [49/50], Step [217/735], Loss: 0.2229\n",
      "Epoch [49/50], Step [218/735], Loss: 0.2064\n",
      "Epoch [49/50], Step [219/735], Loss: 0.1157\n",
      "Epoch [49/50], Step [220/735], Loss: 0.2250\n",
      "Epoch [49/50], Step [221/735], Loss: 0.3431\n",
      "Epoch [49/50], Step [222/735], Loss: 0.0697\n",
      "Epoch [49/50], Step [223/735], Loss: 0.2721\n",
      "Epoch [49/50], Step [224/735], Loss: 0.5052\n",
      "Epoch [49/50], Step [225/735], Loss: 0.0735\n",
      "Epoch [49/50], Step [226/735], Loss: 0.1302\n",
      "Epoch [49/50], Step [227/735], Loss: 0.2150\n",
      "Epoch [49/50], Step [228/735], Loss: 0.1594\n",
      "Epoch [49/50], Step [229/735], Loss: 0.2579\n",
      "Epoch [49/50], Step [230/735], Loss: 0.1311\n",
      "Epoch [49/50], Step [231/735], Loss: 0.1142\n",
      "Epoch [49/50], Step [232/735], Loss: 0.0872\n",
      "Epoch [49/50], Step [233/735], Loss: 0.3790\n",
      "Epoch [49/50], Step [234/735], Loss: 0.1840\n",
      "Epoch [49/50], Step [235/735], Loss: 0.5266\n",
      "Epoch [49/50], Step [236/735], Loss: 0.0708\n",
      "Epoch [49/50], Step [237/735], Loss: 0.2089\n",
      "Epoch [49/50], Step [238/735], Loss: 0.0660\n",
      "Epoch [49/50], Step [239/735], Loss: 0.2237\n",
      "Epoch [49/50], Step [240/735], Loss: 0.0824\n",
      "Epoch [49/50], Step [241/735], Loss: 0.1239\n",
      "Epoch [49/50], Step [242/735], Loss: 0.2936\n",
      "Epoch [49/50], Step [243/735], Loss: 0.3198\n",
      "Epoch [49/50], Step [244/735], Loss: 0.3261\n",
      "Epoch [49/50], Step [245/735], Loss: 0.1508\n",
      "Epoch [49/50], Step [246/735], Loss: 0.3257\n",
      "Epoch [49/50], Step [247/735], Loss: 0.0981\n",
      "Epoch [49/50], Step [248/735], Loss: 0.3204\n",
      "Epoch [49/50], Step [249/735], Loss: 0.2195\n",
      "Epoch [49/50], Step [250/735], Loss: 0.2563\n",
      "Epoch [49/50], Step [251/735], Loss: 0.4874\n",
      "Epoch [49/50], Step [252/735], Loss: 0.1467\n",
      "Epoch [49/50], Step [253/735], Loss: 0.1951\n",
      "Epoch [49/50], Step [254/735], Loss: 0.1191\n",
      "Epoch [49/50], Step [255/735], Loss: 0.1928\n",
      "Epoch [49/50], Step [256/735], Loss: 0.2237\n",
      "Epoch [49/50], Step [257/735], Loss: 0.1359\n",
      "Epoch [49/50], Step [258/735], Loss: 0.2181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Step [259/735], Loss: 0.3485\n",
      "Epoch [49/50], Step [260/735], Loss: 0.1742\n",
      "Epoch [49/50], Step [261/735], Loss: 0.1412\n",
      "Epoch [49/50], Step [262/735], Loss: 0.3579\n",
      "Epoch [49/50], Step [263/735], Loss: 0.2654\n",
      "Epoch [49/50], Step [264/735], Loss: 0.5224\n",
      "Epoch [49/50], Step [265/735], Loss: 0.1476\n",
      "Epoch [49/50], Step [266/735], Loss: 0.3399\n",
      "Epoch [49/50], Step [267/735], Loss: 0.2475\n",
      "Epoch [49/50], Step [268/735], Loss: 0.1059\n",
      "Epoch [49/50], Step [269/735], Loss: 0.3321\n",
      "Epoch [49/50], Step [270/735], Loss: 0.3460\n",
      "Epoch [49/50], Step [271/735], Loss: 0.1845\n",
      "Epoch [49/50], Step [272/735], Loss: 0.0979\n",
      "Epoch [49/50], Step [273/735], Loss: 0.2533\n",
      "Epoch [49/50], Step [274/735], Loss: 0.7724\n",
      "Epoch [49/50], Step [275/735], Loss: 0.1412\n",
      "Epoch [49/50], Step [276/735], Loss: 0.5088\n",
      "Epoch [49/50], Step [277/735], Loss: 0.3858\n",
      "Epoch [49/50], Step [278/735], Loss: 0.1042\n",
      "Epoch [49/50], Step [279/735], Loss: 0.1407\n",
      "Epoch [49/50], Step [280/735], Loss: 0.1906\n",
      "Epoch [49/50], Step [281/735], Loss: 0.2415\n",
      "Epoch [49/50], Step [282/735], Loss: 0.1636\n",
      "Epoch [49/50], Step [283/735], Loss: 0.1130\n",
      "Epoch [49/50], Step [284/735], Loss: 0.1434\n",
      "Epoch [49/50], Step [285/735], Loss: 0.3663\n",
      "Epoch [49/50], Step [286/735], Loss: 0.1402\n",
      "Epoch [49/50], Step [287/735], Loss: 0.2455\n",
      "Epoch [49/50], Step [288/735], Loss: 0.1881\n",
      "Epoch [49/50], Step [289/735], Loss: 0.1697\n",
      "Epoch [49/50], Step [290/735], Loss: 0.0631\n",
      "Epoch [49/50], Step [291/735], Loss: 0.8885\n",
      "Epoch [49/50], Step [292/735], Loss: 0.0881\n",
      "Epoch [49/50], Step [293/735], Loss: 1.0120\n",
      "Epoch [49/50], Step [294/735], Loss: 0.2451\n",
      "Epoch [49/50], Step [295/735], Loss: 0.6036\n",
      "Epoch [49/50], Step [296/735], Loss: 0.3416\n",
      "Epoch [49/50], Step [297/735], Loss: 0.2208\n",
      "Epoch [49/50], Step [298/735], Loss: 0.1714\n",
      "Epoch [49/50], Step [299/735], Loss: 0.1787\n",
      "Epoch [49/50], Step [300/735], Loss: 0.2820\n",
      "Epoch [49/50], Step [301/735], Loss: 0.1138\n",
      "Epoch [49/50], Step [302/735], Loss: 0.3506\n",
      "Epoch [49/50], Step [303/735], Loss: 0.2402\n",
      "Epoch [49/50], Step [304/735], Loss: 0.0728\n",
      "Epoch [49/50], Step [305/735], Loss: 0.3145\n",
      "Epoch [49/50], Step [306/735], Loss: 0.1560\n",
      "Epoch [49/50], Step [307/735], Loss: 0.3403\n",
      "Epoch [49/50], Step [308/735], Loss: 0.1319\n",
      "Epoch [49/50], Step [309/735], Loss: 0.4315\n",
      "Epoch [49/50], Step [310/735], Loss: 0.0870\n",
      "Epoch [49/50], Step [311/735], Loss: 0.5496\n",
      "Epoch [49/50], Step [312/735], Loss: 0.3436\n",
      "Epoch [49/50], Step [313/735], Loss: 0.2600\n",
      "Epoch [49/50], Step [314/735], Loss: 0.1005\n",
      "Epoch [49/50], Step [315/735], Loss: 0.0646\n",
      "Epoch [49/50], Step [316/735], Loss: 0.0603\n",
      "Epoch [49/50], Step [317/735], Loss: 0.2698\n",
      "Epoch [49/50], Step [318/735], Loss: 0.2013\n",
      "Epoch [49/50], Step [319/735], Loss: 0.2154\n",
      "Epoch [49/50], Step [320/735], Loss: 0.1194\n",
      "Epoch [49/50], Step [321/735], Loss: 0.2859\n",
      "Epoch [49/50], Step [322/735], Loss: 0.0726\n",
      "Epoch [49/50], Step [323/735], Loss: 0.1494\n",
      "Epoch [49/50], Step [324/735], Loss: 0.3325\n",
      "Epoch [49/50], Step [325/735], Loss: 0.3365\n",
      "Epoch [49/50], Step [326/735], Loss: 0.2080\n",
      "Epoch [49/50], Step [327/735], Loss: 0.1286\n",
      "Epoch [49/50], Step [328/735], Loss: 1.0518\n",
      "Epoch [49/50], Step [329/735], Loss: 0.2517\n",
      "Epoch [49/50], Step [330/735], Loss: 0.0939\n",
      "Epoch [49/50], Step [331/735], Loss: 0.2346\n",
      "Epoch [49/50], Step [332/735], Loss: 0.0650\n",
      "Epoch [49/50], Step [333/735], Loss: 0.2368\n",
      "Epoch [49/50], Step [334/735], Loss: 0.2710\n",
      "Epoch [49/50], Step [335/735], Loss: 0.0799\n",
      "Epoch [49/50], Step [336/735], Loss: 0.1286\n",
      "Epoch [49/50], Step [337/735], Loss: 0.3937\n",
      "Epoch [49/50], Step [338/735], Loss: 0.1163\n",
      "Epoch [49/50], Step [339/735], Loss: 0.1396\n",
      "Epoch [49/50], Step [340/735], Loss: 0.2679\n",
      "Epoch [49/50], Step [341/735], Loss: 0.3986\n",
      "Epoch [49/50], Step [342/735], Loss: 0.0873\n",
      "Epoch [49/50], Step [343/735], Loss: 0.1878\n",
      "Epoch [49/50], Step [344/735], Loss: 0.1914\n",
      "Epoch [49/50], Step [345/735], Loss: 0.1552\n",
      "Epoch [49/50], Step [346/735], Loss: 0.1208\n",
      "Epoch [49/50], Step [347/735], Loss: 0.2888\n",
      "Epoch [49/50], Step [348/735], Loss: 0.1335\n",
      "Epoch [49/50], Step [349/735], Loss: 0.3730\n",
      "Epoch [49/50], Step [350/735], Loss: 0.0740\n",
      "Epoch [49/50], Step [351/735], Loss: 0.3607\n",
      "Epoch [49/50], Step [352/735], Loss: 0.8645\n",
      "Epoch [49/50], Step [353/735], Loss: 0.3534\n",
      "Epoch [49/50], Step [354/735], Loss: 0.0913\n",
      "Epoch [49/50], Step [355/735], Loss: 0.2027\n",
      "Epoch [49/50], Step [356/735], Loss: 0.0902\n",
      "Epoch [49/50], Step [357/735], Loss: 0.1506\n",
      "Epoch [49/50], Step [358/735], Loss: 0.0570\n",
      "Epoch [49/50], Step [359/735], Loss: 0.1766\n",
      "Epoch [49/50], Step [360/735], Loss: 0.0952\n",
      "Epoch [49/50], Step [361/735], Loss: 0.1839\n",
      "Epoch [49/50], Step [362/735], Loss: 0.4543\n",
      "Epoch [49/50], Step [363/735], Loss: 0.1802\n",
      "Epoch [49/50], Step [364/735], Loss: 0.1154\n",
      "Epoch [49/50], Step [365/735], Loss: 0.5514\n",
      "Epoch [49/50], Step [366/735], Loss: 0.2595\n",
      "Epoch [49/50], Step [367/735], Loss: 0.1120\n",
      "Epoch [49/50], Step [368/735], Loss: 0.0847\n",
      "Epoch [49/50], Step [369/735], Loss: 0.2259\n",
      "Epoch [49/50], Step [370/735], Loss: 0.1994\n",
      "Epoch [49/50], Step [371/735], Loss: 0.1801\n",
      "Epoch [49/50], Step [372/735], Loss: 0.7541\n",
      "Epoch [49/50], Step [373/735], Loss: 0.1924\n",
      "Epoch [49/50], Step [374/735], Loss: 0.1767\n",
      "Epoch [49/50], Step [375/735], Loss: 0.2101\n",
      "Epoch [49/50], Step [376/735], Loss: 0.6592\n",
      "Epoch [49/50], Step [377/735], Loss: 0.1893\n",
      "Epoch [49/50], Step [378/735], Loss: 0.5177\n",
      "Epoch [49/50], Step [379/735], Loss: 0.0800\n",
      "Epoch [49/50], Step [380/735], Loss: 0.2186\n",
      "Epoch [49/50], Step [381/735], Loss: 0.2094\n",
      "Epoch [49/50], Step [382/735], Loss: 0.7856\n",
      "Epoch [49/50], Step [383/735], Loss: 0.1709\n",
      "Epoch [49/50], Step [384/735], Loss: 0.1722\n",
      "Epoch [49/50], Step [385/735], Loss: 0.1460\n",
      "Epoch [49/50], Step [386/735], Loss: 0.2992\n",
      "Epoch [49/50], Step [387/735], Loss: 0.8349\n",
      "Epoch [49/50], Step [388/735], Loss: 0.2464\n",
      "Epoch [49/50], Step [389/735], Loss: 0.4047\n",
      "Epoch [49/50], Step [390/735], Loss: 0.2704\n",
      "Epoch [49/50], Step [391/735], Loss: 0.2098\n",
      "Epoch [49/50], Step [392/735], Loss: 0.3393\n",
      "Epoch [49/50], Step [393/735], Loss: 0.6019\n",
      "Epoch [49/50], Step [394/735], Loss: 0.1994\n",
      "Epoch [49/50], Step [395/735], Loss: 0.1582\n",
      "Epoch [49/50], Step [396/735], Loss: 0.3041\n",
      "Epoch [49/50], Step [397/735], Loss: 0.2199\n",
      "Epoch [49/50], Step [398/735], Loss: 0.6745\n",
      "Epoch [49/50], Step [399/735], Loss: 0.2542\n",
      "Epoch [49/50], Step [400/735], Loss: 0.2856\n",
      "Epoch [49/50], Step [401/735], Loss: 0.2606\n",
      "Epoch [49/50], Step [402/735], Loss: 0.4528\n",
      "Epoch [49/50], Step [403/735], Loss: 0.2414\n",
      "Epoch [49/50], Step [404/735], Loss: 0.3365\n",
      "Epoch [49/50], Step [405/735], Loss: 0.2837\n",
      "Epoch [49/50], Step [406/735], Loss: 0.2258\n",
      "Epoch [49/50], Step [407/735], Loss: 0.0816\n",
      "Epoch [49/50], Step [408/735], Loss: 0.1430\n",
      "Epoch [49/50], Step [409/735], Loss: 0.0953\n",
      "Epoch [49/50], Step [410/735], Loss: 0.1637\n",
      "Epoch [49/50], Step [411/735], Loss: 0.0959\n",
      "Epoch [49/50], Step [412/735], Loss: 0.4576\n",
      "Epoch [49/50], Step [413/735], Loss: 0.1895\n",
      "Epoch [49/50], Step [414/735], Loss: 0.1380\n",
      "Epoch [49/50], Step [415/735], Loss: 0.2311\n",
      "Epoch [49/50], Step [416/735], Loss: 0.2974\n",
      "Epoch [49/50], Step [417/735], Loss: 0.1387\n",
      "Epoch [49/50], Step [418/735], Loss: 0.4289\n",
      "Epoch [49/50], Step [419/735], Loss: 0.6516\n",
      "Epoch [49/50], Step [420/735], Loss: 0.2199\n",
      "Epoch [49/50], Step [421/735], Loss: 0.3249\n",
      "Epoch [49/50], Step [422/735], Loss: 0.1112\n",
      "Epoch [49/50], Step [423/735], Loss: 0.1479\n",
      "Epoch [49/50], Step [424/735], Loss: 0.1877\n",
      "Epoch [49/50], Step [425/735], Loss: 0.2006\n",
      "Epoch [49/50], Step [426/735], Loss: 0.1133\n",
      "Epoch [49/50], Step [427/735], Loss: 0.5247\n",
      "Epoch [49/50], Step [428/735], Loss: 0.0922\n",
      "Epoch [49/50], Step [429/735], Loss: 0.1072\n",
      "Epoch [49/50], Step [430/735], Loss: 0.1426\n",
      "Epoch [49/50], Step [431/735], Loss: 0.2289\n",
      "Epoch [49/50], Step [432/735], Loss: 0.2316\n",
      "Epoch [49/50], Step [433/735], Loss: 0.1407\n",
      "Epoch [49/50], Step [434/735], Loss: 0.2240\n",
      "Epoch [49/50], Step [435/735], Loss: 0.2959\n",
      "Epoch [49/50], Step [436/735], Loss: 0.2046\n",
      "Epoch [49/50], Step [437/735], Loss: 0.7104\n",
      "Epoch [49/50], Step [438/735], Loss: 0.2060\n",
      "Epoch [49/50], Step [439/735], Loss: 0.1213\n",
      "Epoch [49/50], Step [440/735], Loss: 0.1650\n",
      "Epoch [49/50], Step [441/735], Loss: 0.2038\n",
      "Epoch [49/50], Step [442/735], Loss: 0.1216\n",
      "Epoch [49/50], Step [443/735], Loss: 0.6287\n",
      "Epoch [49/50], Step [444/735], Loss: 0.2032\n",
      "Epoch [49/50], Step [445/735], Loss: 0.4060\n",
      "Epoch [49/50], Step [446/735], Loss: 0.2325\n",
      "Epoch [49/50], Step [447/735], Loss: 0.7360\n",
      "Epoch [49/50], Step [448/735], Loss: 0.1457\n",
      "Epoch [49/50], Step [449/735], Loss: 0.2362\n",
      "Epoch [49/50], Step [450/735], Loss: 0.1057\n",
      "Epoch [49/50], Step [451/735], Loss: 0.2014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Step [452/735], Loss: 0.8648\n",
      "Epoch [49/50], Step [453/735], Loss: 0.1180\n",
      "Epoch [49/50], Step [454/735], Loss: 0.5042\n",
      "Epoch [49/50], Step [455/735], Loss: 0.5259\n",
      "Epoch [49/50], Step [456/735], Loss: 0.0788\n",
      "Epoch [49/50], Step [457/735], Loss: 0.1275\n",
      "Epoch [49/50], Step [458/735], Loss: 0.0841\n",
      "Epoch [49/50], Step [459/735], Loss: 0.1813\n",
      "Epoch [49/50], Step [460/735], Loss: 0.0524\n",
      "Epoch [49/50], Step [461/735], Loss: 0.5090\n",
      "Epoch [49/50], Step [462/735], Loss: 0.1820\n",
      "Epoch [49/50], Step [463/735], Loss: 0.1998\n",
      "Epoch [49/50], Step [464/735], Loss: 0.1719\n",
      "Epoch [49/50], Step [465/735], Loss: 0.1233\n",
      "Epoch [49/50], Step [466/735], Loss: 0.2957\n",
      "Epoch [49/50], Step [467/735], Loss: 0.2156\n",
      "Epoch [49/50], Step [468/735], Loss: 0.1779\n",
      "Epoch [49/50], Step [469/735], Loss: 0.2711\n",
      "Epoch [49/50], Step [470/735], Loss: 0.3298\n",
      "Epoch [49/50], Step [471/735], Loss: 0.2179\n",
      "Epoch [49/50], Step [472/735], Loss: 0.3327\n",
      "Epoch [49/50], Step [473/735], Loss: 0.1045\n",
      "Epoch [49/50], Step [474/735], Loss: 0.0403\n",
      "Epoch [49/50], Step [475/735], Loss: 0.0812\n",
      "Epoch [49/50], Step [476/735], Loss: 0.0940\n",
      "Epoch [49/50], Step [477/735], Loss: 0.4458\n",
      "Epoch [49/50], Step [478/735], Loss: 0.2162\n",
      "Epoch [49/50], Step [479/735], Loss: 0.4901\n",
      "Epoch [49/50], Step [480/735], Loss: 0.3749\n",
      "Epoch [49/50], Step [481/735], Loss: 0.1708\n",
      "Epoch [49/50], Step [482/735], Loss: 0.1824\n",
      "Epoch [49/50], Step [483/735], Loss: 0.2763\n",
      "Epoch [49/50], Step [484/735], Loss: 0.3396\n",
      "Epoch [49/50], Step [485/735], Loss: 0.4133\n",
      "Epoch [49/50], Step [486/735], Loss: 0.1113\n",
      "Epoch [49/50], Step [487/735], Loss: 0.3690\n",
      "Epoch [49/50], Step [488/735], Loss: 0.3204\n",
      "Epoch [49/50], Step [489/735], Loss: 0.5277\n",
      "Epoch [49/50], Step [490/735], Loss: 0.1339\n",
      "Epoch [49/50], Step [491/735], Loss: 0.2346\n",
      "Epoch [49/50], Step [492/735], Loss: 0.4841\n",
      "Epoch [49/50], Step [493/735], Loss: 0.2819\n",
      "Epoch [49/50], Step [494/735], Loss: 0.2865\n",
      "Epoch [49/50], Step [495/735], Loss: 0.2713\n",
      "Epoch [49/50], Step [496/735], Loss: 0.2185\n",
      "Epoch [49/50], Step [497/735], Loss: 0.1746\n",
      "Epoch [49/50], Step [498/735], Loss: 0.0538\n",
      "Epoch [49/50], Step [499/735], Loss: 0.2032\n",
      "Epoch [49/50], Step [500/735], Loss: 0.1790\n",
      "Epoch [49/50], Step [501/735], Loss: 0.1979\n",
      "Epoch [49/50], Step [502/735], Loss: 0.2364\n",
      "Epoch [49/50], Step [503/735], Loss: 0.7517\n",
      "Epoch [49/50], Step [504/735], Loss: 0.7551\n",
      "Epoch [49/50], Step [505/735], Loss: 0.2752\n",
      "Epoch [49/50], Step [506/735], Loss: 0.0632\n",
      "Epoch [49/50], Step [507/735], Loss: 0.0958\n",
      "Epoch [49/50], Step [508/735], Loss: 0.6120\n",
      "Epoch [49/50], Step [509/735], Loss: 0.1190\n",
      "Epoch [49/50], Step [510/735], Loss: 0.2226\n",
      "Epoch [49/50], Step [511/735], Loss: 0.0647\n",
      "Epoch [49/50], Step [512/735], Loss: 0.0575\n",
      "Epoch [49/50], Step [513/735], Loss: 0.6221\n",
      "Epoch [49/50], Step [514/735], Loss: 0.1457\n",
      "Epoch [49/50], Step [515/735], Loss: 0.0820\n",
      "Epoch [49/50], Step [516/735], Loss: 0.0667\n",
      "Epoch [49/50], Step [517/735], Loss: 0.2812\n",
      "Epoch [49/50], Step [518/735], Loss: 0.0668\n",
      "Epoch [49/50], Step [519/735], Loss: 0.1574\n",
      "Epoch [49/50], Step [520/735], Loss: 0.2533\n",
      "Epoch [49/50], Step [521/735], Loss: 0.2871\n",
      "Epoch [49/50], Step [522/735], Loss: 0.0952\n",
      "Epoch [49/50], Step [523/735], Loss: 0.2692\n",
      "Epoch [49/50], Step [524/735], Loss: 0.2359\n",
      "Epoch [49/50], Step [525/735], Loss: 0.0684\n",
      "Epoch [49/50], Step [526/735], Loss: 0.1119\n",
      "Epoch [49/50], Step [527/735], Loss: 0.1241\n",
      "Epoch [49/50], Step [528/735], Loss: 0.1398\n",
      "Epoch [49/50], Step [529/735], Loss: 2.9596\n",
      "Epoch [49/50], Step [530/735], Loss: 0.0960\n",
      "Epoch [49/50], Step [531/735], Loss: 0.1855\n",
      "Epoch [49/50], Step [532/735], Loss: 0.1031\n",
      "Epoch [49/50], Step [533/735], Loss: 0.3418\n",
      "Epoch [49/50], Step [534/735], Loss: 0.3854\n",
      "Epoch [49/50], Step [535/735], Loss: 0.3573\n",
      "Epoch [49/50], Step [536/735], Loss: 0.0644\n",
      "Epoch [49/50], Step [537/735], Loss: 0.0996\n",
      "Epoch [49/50], Step [538/735], Loss: 0.0646\n",
      "Epoch [49/50], Step [539/735], Loss: 0.2849\n",
      "Epoch [49/50], Step [540/735], Loss: 0.4388\n",
      "Epoch [49/50], Step [541/735], Loss: 0.3630\n",
      "Epoch [49/50], Step [542/735], Loss: 0.3516\n",
      "Epoch [49/50], Step [543/735], Loss: 0.3064\n",
      "Epoch [49/50], Step [544/735], Loss: 0.0831\n",
      "Epoch [49/50], Step [545/735], Loss: 0.3338\n",
      "Epoch [49/50], Step [546/735], Loss: 0.2871\n",
      "Epoch [49/50], Step [547/735], Loss: 0.4037\n",
      "Epoch [49/50], Step [548/735], Loss: 0.2702\n",
      "Epoch [49/50], Step [549/735], Loss: 1.3614\n",
      "Epoch [49/50], Step [550/735], Loss: 0.3287\n",
      "Epoch [49/50], Step [551/735], Loss: 0.1971\n",
      "Epoch [49/50], Step [552/735], Loss: 0.2551\n",
      "Epoch [49/50], Step [553/735], Loss: 0.1683\n",
      "Epoch [49/50], Step [554/735], Loss: 0.1584\n",
      "Epoch [49/50], Step [555/735], Loss: 0.1569\n",
      "Epoch [49/50], Step [556/735], Loss: 0.4530\n",
      "Epoch [49/50], Step [557/735], Loss: 0.1667\n",
      "Epoch [49/50], Step [558/735], Loss: 0.2078\n",
      "Epoch [49/50], Step [559/735], Loss: 0.3343\n",
      "Epoch [49/50], Step [560/735], Loss: 0.3332\n",
      "Epoch [49/50], Step [561/735], Loss: 0.1620\n",
      "Epoch [49/50], Step [562/735], Loss: 0.3781\n",
      "Epoch [49/50], Step [563/735], Loss: 0.5381\n",
      "Epoch [49/50], Step [564/735], Loss: 0.1124\n",
      "Epoch [49/50], Step [565/735], Loss: 0.1921\n",
      "Epoch [49/50], Step [566/735], Loss: 0.9593\n",
      "Epoch [49/50], Step [567/735], Loss: 0.2360\n",
      "Epoch [49/50], Step [568/735], Loss: 0.1828\n",
      "Epoch [49/50], Step [569/735], Loss: 0.1721\n",
      "Epoch [49/50], Step [570/735], Loss: 2.2156\n",
      "Epoch [49/50], Step [571/735], Loss: 0.3563\n",
      "Epoch [49/50], Step [572/735], Loss: 0.0697\n",
      "Epoch [49/50], Step [573/735], Loss: 0.1592\n",
      "Epoch [49/50], Step [574/735], Loss: 2.0793\n",
      "Epoch [49/50], Step [575/735], Loss: 0.2394\n",
      "Epoch [49/50], Step [576/735], Loss: 0.1227\n",
      "Epoch [49/50], Step [577/735], Loss: 0.1052\n",
      "Epoch [49/50], Step [578/735], Loss: 0.2653\n",
      "Epoch [49/50], Step [579/735], Loss: 0.1654\n",
      "Epoch [49/50], Step [580/735], Loss: 0.2032\n",
      "Epoch [49/50], Step [581/735], Loss: 0.3191\n",
      "Epoch [49/50], Step [582/735], Loss: 0.8178\n",
      "Epoch [49/50], Step [583/735], Loss: 0.3162\n",
      "Epoch [49/50], Step [584/735], Loss: 0.4946\n",
      "Epoch [49/50], Step [585/735], Loss: 0.0541\n",
      "Epoch [49/50], Step [586/735], Loss: 0.3372\n",
      "Epoch [49/50], Step [587/735], Loss: 0.4000\n",
      "Epoch [49/50], Step [588/735], Loss: 0.1050\n",
      "Epoch [49/50], Step [589/735], Loss: 0.0645\n",
      "Epoch [49/50], Step [590/735], Loss: 0.1053\n",
      "Epoch [49/50], Step [591/735], Loss: 0.6637\n",
      "Epoch [49/50], Step [592/735], Loss: 0.1846\n",
      "Epoch [49/50], Step [593/735], Loss: 0.3527\n",
      "Epoch [49/50], Step [594/735], Loss: 0.2183\n",
      "Epoch [49/50], Step [595/735], Loss: 0.1580\n",
      "Epoch [49/50], Step [596/735], Loss: 0.2939\n",
      "Epoch [49/50], Step [597/735], Loss: 0.3400\n",
      "Epoch [49/50], Step [598/735], Loss: 0.1282\n",
      "Epoch [49/50], Step [599/735], Loss: 0.5387\n",
      "Epoch [49/50], Step [600/735], Loss: 0.1634\n",
      "Epoch [49/50], Step [601/735], Loss: 0.5327\n",
      "Epoch [49/50], Step [602/735], Loss: 0.2945\n",
      "Epoch [49/50], Step [603/735], Loss: 0.3013\n",
      "Epoch [49/50], Step [604/735], Loss: 0.4556\n",
      "Epoch [49/50], Step [605/735], Loss: 0.3584\n",
      "Epoch [49/50], Step [606/735], Loss: 0.2017\n",
      "Epoch [49/50], Step [607/735], Loss: 0.4942\n",
      "Epoch [49/50], Step [608/735], Loss: 0.2211\n",
      "Epoch [49/50], Step [609/735], Loss: 0.6413\n",
      "Epoch [49/50], Step [610/735], Loss: 0.5471\n",
      "Epoch [49/50], Step [611/735], Loss: 0.1254\n",
      "Epoch [49/50], Step [612/735], Loss: 0.1880\n",
      "Epoch [49/50], Step [613/735], Loss: 0.1412\n",
      "Epoch [49/50], Step [614/735], Loss: 0.2708\n",
      "Epoch [49/50], Step [615/735], Loss: 0.3912\n",
      "Epoch [49/50], Step [616/735], Loss: 0.3728\n",
      "Epoch [49/50], Step [617/735], Loss: 0.3472\n",
      "Epoch [49/50], Step [618/735], Loss: 0.3272\n",
      "Epoch [49/50], Step [619/735], Loss: 0.4429\n",
      "Epoch [49/50], Step [620/735], Loss: 0.2025\n",
      "Epoch [49/50], Step [621/735], Loss: 0.4578\n",
      "Epoch [49/50], Step [622/735], Loss: 0.0732\n",
      "Epoch [49/50], Step [623/735], Loss: 0.2179\n",
      "Epoch [49/50], Step [624/735], Loss: 0.1933\n",
      "Epoch [49/50], Step [625/735], Loss: 0.1432\n",
      "Epoch [49/50], Step [626/735], Loss: 0.3944\n",
      "Epoch [49/50], Step [627/735], Loss: 0.8080\n",
      "Epoch [49/50], Step [628/735], Loss: 0.1438\n",
      "Epoch [49/50], Step [629/735], Loss: 0.2633\n",
      "Epoch [49/50], Step [630/735], Loss: 0.3219\n",
      "Epoch [49/50], Step [631/735], Loss: 0.1175\n",
      "Epoch [49/50], Step [632/735], Loss: 0.0746\n",
      "Epoch [49/50], Step [633/735], Loss: 0.0690\n",
      "Epoch [49/50], Step [634/735], Loss: 0.6693\n",
      "Epoch [49/50], Step [635/735], Loss: 0.1161\n",
      "Epoch [49/50], Step [636/735], Loss: 1.0820\n",
      "Epoch [49/50], Step [637/735], Loss: 0.4864\n",
      "Epoch [49/50], Step [638/735], Loss: 0.8583\n",
      "Epoch [49/50], Step [639/735], Loss: 0.4177\n",
      "Epoch [49/50], Step [640/735], Loss: 0.1040\n",
      "Epoch [49/50], Step [641/735], Loss: 0.1501\n",
      "Epoch [49/50], Step [642/735], Loss: 0.1020\n",
      "Epoch [49/50], Step [643/735], Loss: 0.1921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Step [644/735], Loss: 0.7134\n",
      "Epoch [49/50], Step [645/735], Loss: 0.0623\n",
      "Epoch [49/50], Step [646/735], Loss: 0.3762\n",
      "Epoch [49/50], Step [647/735], Loss: 0.1039\n",
      "Epoch [49/50], Step [648/735], Loss: 0.4537\n",
      "Epoch [49/50], Step [649/735], Loss: 0.1899\n",
      "Epoch [49/50], Step [650/735], Loss: 0.1386\n",
      "Epoch [49/50], Step [651/735], Loss: 0.5169\n",
      "Epoch [49/50], Step [652/735], Loss: 0.0667\n",
      "Epoch [49/50], Step [653/735], Loss: 0.2021\n",
      "Epoch [49/50], Step [654/735], Loss: 0.1333\n",
      "Epoch [49/50], Step [655/735], Loss: 0.4782\n",
      "Epoch [49/50], Step [656/735], Loss: 0.1633\n",
      "Epoch [49/50], Step [657/735], Loss: 0.3776\n",
      "Epoch [49/50], Step [658/735], Loss: 0.0958\n",
      "Epoch [49/50], Step [659/735], Loss: 0.2817\n",
      "Epoch [49/50], Step [660/735], Loss: 0.2346\n",
      "Epoch [49/50], Step [661/735], Loss: 0.0763\n",
      "Epoch [49/50], Step [662/735], Loss: 0.0799\n",
      "Epoch [49/50], Step [663/735], Loss: 0.2625\n",
      "Epoch [49/50], Step [664/735], Loss: 0.2472\n",
      "Epoch [49/50], Step [665/735], Loss: 0.0816\n",
      "Epoch [49/50], Step [666/735], Loss: 0.1148\n",
      "Epoch [49/50], Step [667/735], Loss: 0.2798\n",
      "Epoch [49/50], Step [668/735], Loss: 0.5186\n",
      "Epoch [49/50], Step [669/735], Loss: 0.0996\n",
      "Epoch [49/50], Step [670/735], Loss: 0.4410\n",
      "Epoch [49/50], Step [671/735], Loss: 0.3214\n",
      "Epoch [49/50], Step [672/735], Loss: 0.2077\n",
      "Epoch [49/50], Step [673/735], Loss: 0.2939\n",
      "Epoch [49/50], Step [674/735], Loss: 0.3960\n",
      "Epoch [49/50], Step [675/735], Loss: 0.1842\n",
      "Epoch [49/50], Step [676/735], Loss: 0.1896\n",
      "Epoch [49/50], Step [677/735], Loss: 0.2536\n",
      "Epoch [49/50], Step [678/735], Loss: 0.5460\n",
      "Epoch [49/50], Step [679/735], Loss: 0.2015\n",
      "Epoch [49/50], Step [680/735], Loss: 0.2219\n",
      "Epoch [49/50], Step [681/735], Loss: 0.2183\n",
      "Epoch [49/50], Step [682/735], Loss: 0.1337\n",
      "Epoch [49/50], Step [683/735], Loss: 0.1200\n",
      "Epoch [49/50], Step [684/735], Loss: 1.0158\n",
      "Epoch [49/50], Step [685/735], Loss: 0.1195\n",
      "Epoch [49/50], Step [686/735], Loss: 0.3478\n",
      "Epoch [49/50], Step [687/735], Loss: 0.6480\n",
      "Epoch [49/50], Step [688/735], Loss: 0.3179\n",
      "Epoch [49/50], Step [689/735], Loss: 0.8770\n",
      "Epoch [49/50], Step [690/735], Loss: 0.2006\n",
      "Epoch [49/50], Step [691/735], Loss: 0.3496\n",
      "Epoch [49/50], Step [692/735], Loss: 0.3262\n",
      "Epoch [49/50], Step [693/735], Loss: 0.0662\n",
      "Epoch [49/50], Step [694/735], Loss: 0.3608\n",
      "Epoch [49/50], Step [695/735], Loss: 0.4961\n",
      "Epoch [49/50], Step [696/735], Loss: 0.0717\n",
      "Epoch [49/50], Step [697/735], Loss: 0.1659\n",
      "Epoch [49/50], Step [698/735], Loss: 0.1294\n",
      "Epoch [49/50], Step [699/735], Loss: 1.2277\n",
      "Epoch [49/50], Step [700/735], Loss: 0.2512\n",
      "Epoch [49/50], Step [701/735], Loss: 0.2540\n",
      "Epoch [49/50], Step [702/735], Loss: 0.1552\n",
      "Epoch [49/50], Step [703/735], Loss: 0.3358\n",
      "Epoch [49/50], Step [704/735], Loss: 0.2264\n",
      "Epoch [49/50], Step [705/735], Loss: 0.1555\n",
      "Epoch [49/50], Step [706/735], Loss: 0.3248\n",
      "Epoch [49/50], Step [707/735], Loss: 0.2240\n",
      "Epoch [49/50], Step [708/735], Loss: 0.2680\n",
      "Epoch [49/50], Step [709/735], Loss: 0.2269\n",
      "Epoch [49/50], Step [710/735], Loss: 0.2949\n",
      "Epoch [49/50], Step [711/735], Loss: 0.1642\n",
      "Epoch [49/50], Step [712/735], Loss: 0.1040\n",
      "Epoch [49/50], Step [713/735], Loss: 0.5835\n",
      "Epoch [49/50], Step [714/735], Loss: 0.3651\n",
      "Epoch [49/50], Step [715/735], Loss: 0.1714\n",
      "Epoch [49/50], Step [716/735], Loss: 0.4835\n",
      "Epoch [49/50], Step [717/735], Loss: 0.1774\n",
      "Epoch [49/50], Step [718/735], Loss: 0.1016\n",
      "Epoch [49/50], Step [719/735], Loss: 0.2471\n",
      "Epoch [49/50], Step [720/735], Loss: 0.2769\n",
      "Epoch [49/50], Step [721/735], Loss: 0.1340\n",
      "Epoch [49/50], Step [722/735], Loss: 0.1450\n",
      "Epoch [49/50], Step [723/735], Loss: 0.1528\n",
      "Epoch [49/50], Step [724/735], Loss: 0.1456\n",
      "Epoch [49/50], Step [725/735], Loss: 0.6019\n",
      "Epoch [49/50], Step [726/735], Loss: 0.8368\n",
      "Epoch [49/50], Step [727/735], Loss: 0.2286\n",
      "Epoch [49/50], Step [728/735], Loss: 0.1813\n",
      "Epoch [49/50], Step [729/735], Loss: 0.1458\n",
      "Epoch [49/50], Step [730/735], Loss: 0.1496\n",
      "Epoch [49/50], Step [731/735], Loss: 0.0870\n",
      "Epoch [49/50], Step [732/735], Loss: 0.1072\n",
      "Epoch [49/50], Step [733/735], Loss: 0.0847\n",
      "Epoch [49/50], Step [734/735], Loss: 0.3540\n",
      "Epoch [49/50], Step [735/735], Loss: 0.1321\n",
      "Epoch [50/50], Step [1/735], Loss: 0.1500\n",
      "Epoch [50/50], Step [2/735], Loss: 0.3862\n",
      "Epoch [50/50], Step [3/735], Loss: 0.4432\n",
      "Epoch [50/50], Step [4/735], Loss: 0.1656\n",
      "Epoch [50/50], Step [5/735], Loss: 0.3303\n",
      "Epoch [50/50], Step [6/735], Loss: 0.1175\n",
      "Epoch [50/50], Step [7/735], Loss: 0.0964\n",
      "Epoch [50/50], Step [8/735], Loss: 0.2308\n",
      "Epoch [50/50], Step [9/735], Loss: 0.2610\n",
      "Epoch [50/50], Step [10/735], Loss: 0.2403\n",
      "Epoch [50/50], Step [11/735], Loss: 0.1428\n",
      "Epoch [50/50], Step [12/735], Loss: 0.2355\n",
      "Epoch [50/50], Step [13/735], Loss: 0.0989\n",
      "Epoch [50/50], Step [14/735], Loss: 0.1467\n",
      "Epoch [50/50], Step [15/735], Loss: 0.0935\n",
      "Epoch [50/50], Step [16/735], Loss: 0.1763\n",
      "Epoch [50/50], Step [17/735], Loss: 0.3261\n",
      "Epoch [50/50], Step [18/735], Loss: 0.5694\n",
      "Epoch [50/50], Step [19/735], Loss: 0.1291\n",
      "Epoch [50/50], Step [20/735], Loss: 0.1613\n",
      "Epoch [50/50], Step [21/735], Loss: 0.3885\n",
      "Epoch [50/50], Step [22/735], Loss: 0.2009\n",
      "Epoch [50/50], Step [23/735], Loss: 0.1859\n",
      "Epoch [50/50], Step [24/735], Loss: 0.1347\n",
      "Epoch [50/50], Step [25/735], Loss: 0.1830\n",
      "Epoch [50/50], Step [26/735], Loss: 0.2731\n",
      "Epoch [50/50], Step [27/735], Loss: 0.7090\n",
      "Epoch [50/50], Step [28/735], Loss: 0.0902\n",
      "Epoch [50/50], Step [29/735], Loss: 2.7347\n",
      "Epoch [50/50], Step [30/735], Loss: 0.1713\n",
      "Epoch [50/50], Step [31/735], Loss: 0.2225\n",
      "Epoch [50/50], Step [32/735], Loss: 0.2592\n",
      "Epoch [50/50], Step [33/735], Loss: 0.2512\n",
      "Epoch [50/50], Step [34/735], Loss: 0.4229\n",
      "Epoch [50/50], Step [35/735], Loss: 0.6524\n",
      "Epoch [50/50], Step [36/735], Loss: 0.4663\n",
      "Epoch [50/50], Step [37/735], Loss: 0.4882\n",
      "Epoch [50/50], Step [38/735], Loss: 0.1634\n",
      "Epoch [50/50], Step [39/735], Loss: 0.2194\n",
      "Epoch [50/50], Step [40/735], Loss: 0.5620\n",
      "Epoch [50/50], Step [41/735], Loss: 0.0826\n",
      "Epoch [50/50], Step [42/735], Loss: 0.2539\n",
      "Epoch [50/50], Step [43/735], Loss: 0.2214\n",
      "Epoch [50/50], Step [44/735], Loss: 0.2101\n",
      "Epoch [50/50], Step [45/735], Loss: 0.1151\n",
      "Epoch [50/50], Step [46/735], Loss: 0.4542\n",
      "Epoch [50/50], Step [47/735], Loss: 0.1898\n",
      "Epoch [50/50], Step [48/735], Loss: 0.0979\n",
      "Epoch [50/50], Step [49/735], Loss: 0.3652\n",
      "Epoch [50/50], Step [50/735], Loss: 0.1212\n",
      "Epoch [50/50], Step [51/735], Loss: 0.1196\n",
      "Epoch [50/50], Step [52/735], Loss: 0.2079\n",
      "Epoch [50/50], Step [53/735], Loss: 0.1471\n",
      "Epoch [50/50], Step [54/735], Loss: 0.2768\n",
      "Epoch [50/50], Step [55/735], Loss: 0.1649\n",
      "Epoch [50/50], Step [56/735], Loss: 0.0784\n",
      "Epoch [50/50], Step [57/735], Loss: 0.2557\n",
      "Epoch [50/50], Step [58/735], Loss: 0.3183\n",
      "Epoch [50/50], Step [59/735], Loss: 0.1082\n",
      "Epoch [50/50], Step [60/735], Loss: 0.8021\n",
      "Epoch [50/50], Step [61/735], Loss: 0.2368\n",
      "Epoch [50/50], Step [62/735], Loss: 0.8221\n",
      "Epoch [50/50], Step [63/735], Loss: 0.1981\n",
      "Epoch [50/50], Step [64/735], Loss: 0.4465\n",
      "Epoch [50/50], Step [65/735], Loss: 0.2917\n",
      "Epoch [50/50], Step [66/735], Loss: 0.1024\n",
      "Epoch [50/50], Step [67/735], Loss: 0.2878\n",
      "Epoch [50/50], Step [68/735], Loss: 0.4486\n",
      "Epoch [50/50], Step [69/735], Loss: 0.1707\n",
      "Epoch [50/50], Step [70/735], Loss: 0.1445\n",
      "Epoch [50/50], Step [71/735], Loss: 0.2238\n",
      "Epoch [50/50], Step [72/735], Loss: 0.4179\n",
      "Epoch [50/50], Step [73/735], Loss: 0.0817\n",
      "Epoch [50/50], Step [74/735], Loss: 0.1455\n",
      "Epoch [50/50], Step [75/735], Loss: 0.1268\n",
      "Epoch [50/50], Step [76/735], Loss: 0.3081\n",
      "Epoch [50/50], Step [77/735], Loss: 0.1394\n",
      "Epoch [50/50], Step [78/735], Loss: 0.4868\n",
      "Epoch [50/50], Step [79/735], Loss: 0.4605\n",
      "Epoch [50/50], Step [80/735], Loss: 0.2515\n",
      "Epoch [50/50], Step [81/735], Loss: 0.1907\n",
      "Epoch [50/50], Step [82/735], Loss: 0.3745\n",
      "Epoch [50/50], Step [83/735], Loss: 0.1017\n",
      "Epoch [50/50], Step [84/735], Loss: 0.3163\n",
      "Epoch [50/50], Step [85/735], Loss: 0.1988\n",
      "Epoch [50/50], Step [86/735], Loss: 0.4739\n",
      "Epoch [50/50], Step [87/735], Loss: 0.1823\n",
      "Epoch [50/50], Step [88/735], Loss: 0.3869\n",
      "Epoch [50/50], Step [89/735], Loss: 0.0943\n",
      "Epoch [50/50], Step [90/735], Loss: 0.1937\n",
      "Epoch [50/50], Step [91/735], Loss: 0.1405\n",
      "Epoch [50/50], Step [92/735], Loss: 0.2566\n",
      "Epoch [50/50], Step [93/735], Loss: 0.2740\n",
      "Epoch [50/50], Step [94/735], Loss: 0.1957\n",
      "Epoch [50/50], Step [95/735], Loss: 0.1311\n",
      "Epoch [50/50], Step [96/735], Loss: 0.5943\n",
      "Epoch [50/50], Step [97/735], Loss: 0.2915\n",
      "Epoch [50/50], Step [98/735], Loss: 0.0860\n",
      "Epoch [50/50], Step [99/735], Loss: 0.1311\n",
      "Epoch [50/50], Step [100/735], Loss: 0.2813\n",
      "Epoch [50/50], Step [101/735], Loss: 0.3144\n",
      "Epoch [50/50], Step [102/735], Loss: 0.1242\n",
      "Epoch [50/50], Step [103/735], Loss: 0.1083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Step [104/735], Loss: 0.3424\n",
      "Epoch [50/50], Step [105/735], Loss: 0.1884\n",
      "Epoch [50/50], Step [106/735], Loss: 0.2845\n",
      "Epoch [50/50], Step [107/735], Loss: 0.1827\n",
      "Epoch [50/50], Step [108/735], Loss: 0.0508\n",
      "Epoch [50/50], Step [109/735], Loss: 0.1128\n",
      "Epoch [50/50], Step [110/735], Loss: 0.1742\n",
      "Epoch [50/50], Step [111/735], Loss: 0.5098\n",
      "Epoch [50/50], Step [112/735], Loss: 0.2680\n",
      "Epoch [50/50], Step [113/735], Loss: 0.3004\n",
      "Epoch [50/50], Step [114/735], Loss: 0.2932\n",
      "Epoch [50/50], Step [115/735], Loss: 0.1697\n",
      "Epoch [50/50], Step [116/735], Loss: 0.2421\n",
      "Epoch [50/50], Step [117/735], Loss: 0.1538\n",
      "Epoch [50/50], Step [118/735], Loss: 0.1622\n",
      "Epoch [50/50], Step [119/735], Loss: 0.0396\n",
      "Epoch [50/50], Step [120/735], Loss: 0.3004\n",
      "Epoch [50/50], Step [121/735], Loss: 0.1484\n",
      "Epoch [50/50], Step [122/735], Loss: 0.2397\n",
      "Epoch [50/50], Step [123/735], Loss: 0.2414\n",
      "Epoch [50/50], Step [124/735], Loss: 2.8810\n",
      "Epoch [50/50], Step [125/735], Loss: 0.2611\n",
      "Epoch [50/50], Step [126/735], Loss: 0.2926\n",
      "Epoch [50/50], Step [127/735], Loss: 0.4272\n",
      "Epoch [50/50], Step [128/735], Loss: 0.3169\n",
      "Epoch [50/50], Step [129/735], Loss: 0.1098\n",
      "Epoch [50/50], Step [130/735], Loss: 0.5590\n",
      "Epoch [50/50], Step [131/735], Loss: 0.1693\n",
      "Epoch [50/50], Step [132/735], Loss: 0.2220\n",
      "Epoch [50/50], Step [133/735], Loss: 0.1802\n",
      "Epoch [50/50], Step [134/735], Loss: 0.4620\n",
      "Epoch [50/50], Step [135/735], Loss: 0.2754\n",
      "Epoch [50/50], Step [136/735], Loss: 0.1203\n",
      "Epoch [50/50], Step [137/735], Loss: 0.2870\n",
      "Epoch [50/50], Step [138/735], Loss: 0.0539\n",
      "Epoch [50/50], Step [139/735], Loss: 0.5263\n",
      "Epoch [50/50], Step [140/735], Loss: 0.1023\n",
      "Epoch [50/50], Step [141/735], Loss: 0.1593\n",
      "Epoch [50/50], Step [142/735], Loss: 0.5432\n",
      "Epoch [50/50], Step [143/735], Loss: 0.2330\n",
      "Epoch [50/50], Step [144/735], Loss: 0.0944\n",
      "Epoch [50/50], Step [145/735], Loss: 0.2481\n",
      "Epoch [50/50], Step [146/735], Loss: 0.2342\n",
      "Epoch [50/50], Step [147/735], Loss: 0.8594\n",
      "Epoch [50/50], Step [148/735], Loss: 0.4530\n",
      "Epoch [50/50], Step [149/735], Loss: 0.3975\n",
      "Epoch [50/50], Step [150/735], Loss: 0.1776\n",
      "Epoch [50/50], Step [151/735], Loss: 0.3444\n",
      "Epoch [50/50], Step [152/735], Loss: 0.6154\n",
      "Epoch [50/50], Step [153/735], Loss: 0.1232\n",
      "Epoch [50/50], Step [154/735], Loss: 0.2394\n",
      "Epoch [50/50], Step [155/735], Loss: 0.3353\n",
      "Epoch [50/50], Step [156/735], Loss: 0.9747\n",
      "Epoch [50/50], Step [157/735], Loss: 0.3182\n",
      "Epoch [50/50], Step [158/735], Loss: 0.2037\n",
      "Epoch [50/50], Step [159/735], Loss: 0.3423\n",
      "Epoch [50/50], Step [160/735], Loss: 0.6303\n",
      "Epoch [50/50], Step [161/735], Loss: 0.2429\n",
      "Epoch [50/50], Step [162/735], Loss: 0.2762\n",
      "Epoch [50/50], Step [163/735], Loss: 0.1098\n",
      "Epoch [50/50], Step [164/735], Loss: 0.1896\n",
      "Epoch [50/50], Step [165/735], Loss: 0.1335\n",
      "Epoch [50/50], Step [166/735], Loss: 0.1511\n",
      "Epoch [50/50], Step [167/735], Loss: 0.2180\n",
      "Epoch [50/50], Step [168/735], Loss: 0.4147\n",
      "Epoch [50/50], Step [169/735], Loss: 0.5678\n",
      "Epoch [50/50], Step [170/735], Loss: 0.0631\n",
      "Epoch [50/50], Step [171/735], Loss: 0.1975\n",
      "Epoch [50/50], Step [172/735], Loss: 0.3775\n",
      "Epoch [50/50], Step [173/735], Loss: 0.3041\n",
      "Epoch [50/50], Step [174/735], Loss: 0.1758\n",
      "Epoch [50/50], Step [175/735], Loss: 0.1083\n",
      "Epoch [50/50], Step [176/735], Loss: 0.2356\n",
      "Epoch [50/50], Step [177/735], Loss: 0.1480\n",
      "Epoch [50/50], Step [178/735], Loss: 0.1859\n",
      "Epoch [50/50], Step [179/735], Loss: 0.2711\n",
      "Epoch [50/50], Step [180/735], Loss: 0.2367\n",
      "Epoch [50/50], Step [181/735], Loss: 0.2170\n",
      "Epoch [50/50], Step [182/735], Loss: 0.1872\n",
      "Epoch [50/50], Step [183/735], Loss: 0.2033\n",
      "Epoch [50/50], Step [184/735], Loss: 0.2071\n",
      "Epoch [50/50], Step [185/735], Loss: 2.2183\n",
      "Epoch [50/50], Step [186/735], Loss: 0.1222\n",
      "Epoch [50/50], Step [187/735], Loss: 0.2140\n",
      "Epoch [50/50], Step [188/735], Loss: 0.1755\n",
      "Epoch [50/50], Step [189/735], Loss: 0.2267\n",
      "Epoch [50/50], Step [190/735], Loss: 0.1009\n",
      "Epoch [50/50], Step [191/735], Loss: 1.6980\n",
      "Epoch [50/50], Step [192/735], Loss: 0.2234\n",
      "Epoch [50/50], Step [193/735], Loss: 0.2961\n",
      "Epoch [50/50], Step [194/735], Loss: 0.2131\n",
      "Epoch [50/50], Step [195/735], Loss: 0.2054\n",
      "Epoch [50/50], Step [196/735], Loss: 0.0841\n",
      "Epoch [50/50], Step [197/735], Loss: 0.1005\n",
      "Epoch [50/50], Step [198/735], Loss: 0.0994\n",
      "Epoch [50/50], Step [199/735], Loss: 0.3526\n",
      "Epoch [50/50], Step [200/735], Loss: 0.1898\n",
      "Epoch [50/50], Step [201/735], Loss: 0.0920\n",
      "Epoch [50/50], Step [202/735], Loss: 0.2838\n",
      "Epoch [50/50], Step [203/735], Loss: 0.2771\n",
      "Epoch [50/50], Step [204/735], Loss: 0.1749\n",
      "Epoch [50/50], Step [205/735], Loss: 0.3264\n",
      "Epoch [50/50], Step [206/735], Loss: 0.3368\n",
      "Epoch [50/50], Step [207/735], Loss: 0.3041\n",
      "Epoch [50/50], Step [208/735], Loss: 0.0448\n",
      "Epoch [50/50], Step [209/735], Loss: 0.1010\n",
      "Epoch [50/50], Step [210/735], Loss: 0.3410\n",
      "Epoch [50/50], Step [211/735], Loss: 0.1426\n",
      "Epoch [50/50], Step [212/735], Loss: 0.1231\n",
      "Epoch [50/50], Step [213/735], Loss: 0.2225\n",
      "Epoch [50/50], Step [214/735], Loss: 0.7837\n",
      "Epoch [50/50], Step [215/735], Loss: 0.1894\n",
      "Epoch [50/50], Step [216/735], Loss: 0.1427\n",
      "Epoch [50/50], Step [217/735], Loss: 0.4698\n",
      "Epoch [50/50], Step [218/735], Loss: 0.6518\n",
      "Epoch [50/50], Step [219/735], Loss: 0.1133\n",
      "Epoch [50/50], Step [220/735], Loss: 0.3319\n",
      "Epoch [50/50], Step [221/735], Loss: 0.1322\n",
      "Epoch [50/50], Step [222/735], Loss: 0.2088\n",
      "Epoch [50/50], Step [223/735], Loss: 0.1956\n",
      "Epoch [50/50], Step [224/735], Loss: 0.0839\n",
      "Epoch [50/50], Step [225/735], Loss: 0.0773\n",
      "Epoch [50/50], Step [226/735], Loss: 0.2137\n",
      "Epoch [50/50], Step [227/735], Loss: 0.3004\n",
      "Epoch [50/50], Step [228/735], Loss: 0.1488\n",
      "Epoch [50/50], Step [229/735], Loss: 0.1418\n",
      "Epoch [50/50], Step [230/735], Loss: 0.1792\n",
      "Epoch [50/50], Step [231/735], Loss: 0.1373\n",
      "Epoch [50/50], Step [232/735], Loss: 0.1815\n",
      "Epoch [50/50], Step [233/735], Loss: 0.1425\n",
      "Epoch [50/50], Step [234/735], Loss: 0.1790\n",
      "Epoch [50/50], Step [235/735], Loss: 0.6222\n",
      "Epoch [50/50], Step [236/735], Loss: 0.3023\n",
      "Epoch [50/50], Step [237/735], Loss: 0.2291\n",
      "Epoch [50/50], Step [238/735], Loss: 0.3929\n",
      "Epoch [50/50], Step [239/735], Loss: 0.2390\n",
      "Epoch [50/50], Step [240/735], Loss: 0.1620\n",
      "Epoch [50/50], Step [241/735], Loss: 0.0524\n",
      "Epoch [50/50], Step [242/735], Loss: 0.1513\n",
      "Epoch [50/50], Step [243/735], Loss: 0.2552\n",
      "Epoch [50/50], Step [244/735], Loss: 0.0891\n",
      "Epoch [50/50], Step [245/735], Loss: 0.2247\n",
      "Epoch [50/50], Step [246/735], Loss: 0.6591\n",
      "Epoch [50/50], Step [247/735], Loss: 0.0898\n",
      "Epoch [50/50], Step [248/735], Loss: 0.3526\n",
      "Epoch [50/50], Step [249/735], Loss: 0.6402\n",
      "Epoch [50/50], Step [250/735], Loss: 0.1539\n",
      "Epoch [50/50], Step [251/735], Loss: 0.2486\n",
      "Epoch [50/50], Step [252/735], Loss: 0.1880\n",
      "Epoch [50/50], Step [253/735], Loss: 0.2132\n",
      "Epoch [50/50], Step [254/735], Loss: 0.1252\n",
      "Epoch [50/50], Step [255/735], Loss: 0.1344\n",
      "Epoch [50/50], Step [256/735], Loss: 0.1849\n",
      "Epoch [50/50], Step [257/735], Loss: 0.2802\n",
      "Epoch [50/50], Step [258/735], Loss: 0.2502\n",
      "Epoch [50/50], Step [259/735], Loss: 0.3188\n",
      "Epoch [50/50], Step [260/735], Loss: 0.4751\n",
      "Epoch [50/50], Step [261/735], Loss: 0.1369\n",
      "Epoch [50/50], Step [262/735], Loss: 0.2118\n",
      "Epoch [50/50], Step [263/735], Loss: 0.4270\n",
      "Epoch [50/50], Step [264/735], Loss: 0.1225\n",
      "Epoch [50/50], Step [265/735], Loss: 0.4351\n",
      "Epoch [50/50], Step [266/735], Loss: 0.0858\n",
      "Epoch [50/50], Step [267/735], Loss: 0.2547\n",
      "Epoch [50/50], Step [268/735], Loss: 0.3255\n",
      "Epoch [50/50], Step [269/735], Loss: 0.3808\n",
      "Epoch [50/50], Step [270/735], Loss: 0.1780\n",
      "Epoch [50/50], Step [271/735], Loss: 0.5238\n",
      "Epoch [50/50], Step [272/735], Loss: 0.0640\n",
      "Epoch [50/50], Step [273/735], Loss: 0.2029\n",
      "Epoch [50/50], Step [274/735], Loss: 0.0882\n",
      "Epoch [50/50], Step [275/735], Loss: 0.2834\n",
      "Epoch [50/50], Step [276/735], Loss: 0.0710\n",
      "Epoch [50/50], Step [277/735], Loss: 0.1307\n",
      "Epoch [50/50], Step [278/735], Loss: 0.4828\n",
      "Epoch [50/50], Step [279/735], Loss: 0.2057\n",
      "Epoch [50/50], Step [280/735], Loss: 0.5135\n",
      "Epoch [50/50], Step [281/735], Loss: 0.1518\n",
      "Epoch [50/50], Step [282/735], Loss: 0.1610\n",
      "Epoch [50/50], Step [283/735], Loss: 0.1704\n",
      "Epoch [50/50], Step [284/735], Loss: 0.1686\n",
      "Epoch [50/50], Step [285/735], Loss: 0.2972\n",
      "Epoch [50/50], Step [286/735], Loss: 0.4025\n",
      "Epoch [50/50], Step [287/735], Loss: 0.3336\n",
      "Epoch [50/50], Step [288/735], Loss: 0.0783\n",
      "Epoch [50/50], Step [289/735], Loss: 0.3597\n",
      "Epoch [50/50], Step [290/735], Loss: 0.1066\n",
      "Epoch [50/50], Step [291/735], Loss: 0.1279\n",
      "Epoch [50/50], Step [292/735], Loss: 0.1571\n",
      "Epoch [50/50], Step [293/735], Loss: 0.3277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Step [294/735], Loss: 0.2672\n",
      "Epoch [50/50], Step [295/735], Loss: 0.3967\n",
      "Epoch [50/50], Step [296/735], Loss: 0.1459\n",
      "Epoch [50/50], Step [297/735], Loss: 0.1872\n",
      "Epoch [50/50], Step [298/735], Loss: 0.3096\n",
      "Epoch [50/50], Step [299/735], Loss: 0.4939\n",
      "Epoch [50/50], Step [300/735], Loss: 0.1496\n",
      "Epoch [50/50], Step [301/735], Loss: 0.1081\n",
      "Epoch [50/50], Step [302/735], Loss: 0.3936\n",
      "Epoch [50/50], Step [303/735], Loss: 0.4594\n",
      "Epoch [50/50], Step [304/735], Loss: 0.5040\n",
      "Epoch [50/50], Step [305/735], Loss: 0.1253\n",
      "Epoch [50/50], Step [306/735], Loss: 0.0976\n",
      "Epoch [50/50], Step [307/735], Loss: 0.3189\n",
      "Epoch [50/50], Step [308/735], Loss: 0.4534\n",
      "Epoch [50/50], Step [309/735], Loss: 0.4399\n",
      "Epoch [50/50], Step [310/735], Loss: 0.0411\n",
      "Epoch [50/50], Step [311/735], Loss: 0.4893\n",
      "Epoch [50/50], Step [312/735], Loss: 0.2971\n",
      "Epoch [50/50], Step [313/735], Loss: 0.2470\n",
      "Epoch [50/50], Step [314/735], Loss: 0.4940\n",
      "Epoch [50/50], Step [315/735], Loss: 0.1259\n",
      "Epoch [50/50], Step [316/735], Loss: 0.3717\n",
      "Epoch [50/50], Step [317/735], Loss: 0.3175\n",
      "Epoch [50/50], Step [318/735], Loss: 0.4364\n",
      "Epoch [50/50], Step [319/735], Loss: 0.2203\n",
      "Epoch [50/50], Step [320/735], Loss: 0.7055\n",
      "Epoch [50/50], Step [321/735], Loss: 0.5131\n",
      "Epoch [50/50], Step [322/735], Loss: 0.2014\n",
      "Epoch [50/50], Step [323/735], Loss: 0.1202\n",
      "Epoch [50/50], Step [324/735], Loss: 0.2362\n",
      "Epoch [50/50], Step [325/735], Loss: 0.0614\n",
      "Epoch [50/50], Step [326/735], Loss: 0.1484\n",
      "Epoch [50/50], Step [327/735], Loss: 0.1789\n",
      "Epoch [50/50], Step [328/735], Loss: 0.2116\n",
      "Epoch [50/50], Step [329/735], Loss: 0.3223\n",
      "Epoch [50/50], Step [330/735], Loss: 0.2279\n",
      "Epoch [50/50], Step [331/735], Loss: 0.0939\n",
      "Epoch [50/50], Step [332/735], Loss: 0.1212\n",
      "Epoch [50/50], Step [333/735], Loss: 0.0728\n",
      "Epoch [50/50], Step [334/735], Loss: 0.3339\n",
      "Epoch [50/50], Step [335/735], Loss: 0.1891\n",
      "Epoch [50/50], Step [336/735], Loss: 0.3715\n",
      "Epoch [50/50], Step [337/735], Loss: 0.6813\n",
      "Epoch [50/50], Step [338/735], Loss: 0.1949\n",
      "Epoch [50/50], Step [339/735], Loss: 0.1416\n",
      "Epoch [50/50], Step [340/735], Loss: 0.1037\n",
      "Epoch [50/50], Step [341/735], Loss: 0.0552\n",
      "Epoch [50/50], Step [342/735], Loss: 0.2512\n",
      "Epoch [50/50], Step [343/735], Loss: 0.3535\n",
      "Epoch [50/50], Step [344/735], Loss: 0.1860\n",
      "Epoch [50/50], Step [345/735], Loss: 0.2348\n",
      "Epoch [50/50], Step [346/735], Loss: 0.4011\n",
      "Epoch [50/50], Step [347/735], Loss: 0.2623\n",
      "Epoch [50/50], Step [348/735], Loss: 1.1675\n",
      "Epoch [50/50], Step [349/735], Loss: 0.1033\n",
      "Epoch [50/50], Step [350/735], Loss: 0.2212\n",
      "Epoch [50/50], Step [351/735], Loss: 0.2824\n",
      "Epoch [50/50], Step [352/735], Loss: 0.1561\n",
      "Epoch [50/50], Step [353/735], Loss: 0.1970\n",
      "Epoch [50/50], Step [354/735], Loss: 0.4545\n",
      "Epoch [50/50], Step [355/735], Loss: 0.4197\n",
      "Epoch [50/50], Step [356/735], Loss: 0.0828\n",
      "Epoch [50/50], Step [357/735], Loss: 0.1800\n",
      "Epoch [50/50], Step [358/735], Loss: 0.1016\n",
      "Epoch [50/50], Step [359/735], Loss: 0.0691\n",
      "Epoch [50/50], Step [360/735], Loss: 0.2943\n",
      "Epoch [50/50], Step [361/735], Loss: 0.1312\n",
      "Epoch [50/50], Step [362/735], Loss: 0.1510\n",
      "Epoch [50/50], Step [363/735], Loss: 0.1578\n",
      "Epoch [50/50], Step [364/735], Loss: 0.2120\n",
      "Epoch [50/50], Step [365/735], Loss: 0.3215\n",
      "Epoch [50/50], Step [366/735], Loss: 0.2299\n",
      "Epoch [50/50], Step [367/735], Loss: 0.2953\n",
      "Epoch [50/50], Step [368/735], Loss: 0.0839\n",
      "Epoch [50/50], Step [369/735], Loss: 0.4855\n",
      "Epoch [50/50], Step [370/735], Loss: 0.1472\n",
      "Epoch [50/50], Step [371/735], Loss: 0.1565\n",
      "Epoch [50/50], Step [372/735], Loss: 0.0904\n",
      "Epoch [50/50], Step [373/735], Loss: 0.1111\n",
      "Epoch [50/50], Step [374/735], Loss: 0.0962\n",
      "Epoch [50/50], Step [375/735], Loss: 0.2136\n",
      "Epoch [50/50], Step [376/735], Loss: 0.4114\n",
      "Epoch [50/50], Step [377/735], Loss: 0.4998\n",
      "Epoch [50/50], Step [378/735], Loss: 0.4581\n",
      "Epoch [50/50], Step [379/735], Loss: 0.8645\n",
      "Epoch [50/50], Step [380/735], Loss: 0.2348\n",
      "Epoch [50/50], Step [381/735], Loss: 0.1715\n",
      "Epoch [50/50], Step [382/735], Loss: 0.2866\n",
      "Epoch [50/50], Step [383/735], Loss: 0.6297\n",
      "Epoch [50/50], Step [384/735], Loss: 0.2776\n",
      "Epoch [50/50], Step [385/735], Loss: 0.1849\n",
      "Epoch [50/50], Step [386/735], Loss: 0.0995\n",
      "Epoch [50/50], Step [387/735], Loss: 0.4355\n",
      "Epoch [50/50], Step [388/735], Loss: 0.4138\n",
      "Epoch [50/50], Step [389/735], Loss: 0.2198\n",
      "Epoch [50/50], Step [390/735], Loss: 0.5335\n",
      "Epoch [50/50], Step [391/735], Loss: 0.3515\n",
      "Epoch [50/50], Step [392/735], Loss: 0.1086\n",
      "Epoch [50/50], Step [393/735], Loss: 0.3282\n",
      "Epoch [50/50], Step [394/735], Loss: 0.2123\n",
      "Epoch [50/50], Step [395/735], Loss: 0.2791\n",
      "Epoch [50/50], Step [396/735], Loss: 0.2355\n",
      "Epoch [50/50], Step [397/735], Loss: 0.3836\n",
      "Epoch [50/50], Step [398/735], Loss: 0.3533\n",
      "Epoch [50/50], Step [399/735], Loss: 0.3055\n",
      "Epoch [50/50], Step [400/735], Loss: 0.2051\n",
      "Epoch [50/50], Step [401/735], Loss: 0.4232\n",
      "Epoch [50/50], Step [402/735], Loss: 0.0699\n",
      "Epoch [50/50], Step [403/735], Loss: 0.2658\n",
      "Epoch [50/50], Step [404/735], Loss: 0.8363\n",
      "Epoch [50/50], Step [405/735], Loss: 0.3849\n",
      "Epoch [50/50], Step [406/735], Loss: 0.1785\n",
      "Epoch [50/50], Step [407/735], Loss: 0.3731\n",
      "Epoch [50/50], Step [408/735], Loss: 0.1321\n",
      "Epoch [50/50], Step [409/735], Loss: 0.5683\n",
      "Epoch [50/50], Step [410/735], Loss: 0.3123\n",
      "Epoch [50/50], Step [411/735], Loss: 0.1781\n",
      "Epoch [50/50], Step [412/735], Loss: 0.1577\n",
      "Epoch [50/50], Step [413/735], Loss: 0.1867\n",
      "Epoch [50/50], Step [414/735], Loss: 0.2557\n",
      "Epoch [50/50], Step [415/735], Loss: 0.1332\n",
      "Epoch [50/50], Step [416/735], Loss: 0.1708\n",
      "Epoch [50/50], Step [417/735], Loss: 0.5125\n",
      "Epoch [50/50], Step [418/735], Loss: 0.1611\n",
      "Epoch [50/50], Step [419/735], Loss: 0.4161\n",
      "Epoch [50/50], Step [420/735], Loss: 0.0794\n",
      "Epoch [50/50], Step [421/735], Loss: 0.1973\n",
      "Epoch [50/50], Step [422/735], Loss: 0.0654\n",
      "Epoch [50/50], Step [423/735], Loss: 0.1759\n",
      "Epoch [50/50], Step [424/735], Loss: 0.0983\n",
      "Epoch [50/50], Step [425/735], Loss: 0.1788\n",
      "Epoch [50/50], Step [426/735], Loss: 0.1509\n",
      "Epoch [50/50], Step [427/735], Loss: 0.1393\n",
      "Epoch [50/50], Step [428/735], Loss: 0.3161\n",
      "Epoch [50/50], Step [429/735], Loss: 0.6205\n",
      "Epoch [50/50], Step [430/735], Loss: 0.0574\n",
      "Epoch [50/50], Step [431/735], Loss: 0.2062\n",
      "Epoch [50/50], Step [432/735], Loss: 0.1406\n",
      "Epoch [50/50], Step [433/735], Loss: 1.1000\n",
      "Epoch [50/50], Step [434/735], Loss: 0.1245\n",
      "Epoch [50/50], Step [435/735], Loss: 0.2217\n",
      "Epoch [50/50], Step [436/735], Loss: 0.2679\n",
      "Epoch [50/50], Step [437/735], Loss: 0.2395\n",
      "Epoch [50/50], Step [438/735], Loss: 0.0617\n",
      "Epoch [50/50], Step [439/735], Loss: 0.1541\n",
      "Epoch [50/50], Step [440/735], Loss: 0.1666\n",
      "Epoch [50/50], Step [441/735], Loss: 0.2140\n",
      "Epoch [50/50], Step [442/735], Loss: 0.9843\n",
      "Epoch [50/50], Step [443/735], Loss: 0.4357\n",
      "Epoch [50/50], Step [444/735], Loss: 0.2613\n",
      "Epoch [50/50], Step [445/735], Loss: 0.2286\n",
      "Epoch [50/50], Step [446/735], Loss: 0.1605\n",
      "Epoch [50/50], Step [447/735], Loss: 0.2802\n",
      "Epoch [50/50], Step [448/735], Loss: 0.1966\n",
      "Epoch [50/50], Step [449/735], Loss: 0.2195\n",
      "Epoch [50/50], Step [450/735], Loss: 0.2660\n",
      "Epoch [50/50], Step [451/735], Loss: 0.2507\n",
      "Epoch [50/50], Step [452/735], Loss: 0.0570\n",
      "Epoch [50/50], Step [453/735], Loss: 0.2251\n",
      "Epoch [50/50], Step [454/735], Loss: 0.1823\n",
      "Epoch [50/50], Step [455/735], Loss: 0.2907\n",
      "Epoch [50/50], Step [456/735], Loss: 0.1265\n",
      "Epoch [50/50], Step [457/735], Loss: 0.3263\n",
      "Epoch [50/50], Step [458/735], Loss: 0.1633\n",
      "Epoch [50/50], Step [459/735], Loss: 0.1902\n",
      "Epoch [50/50], Step [460/735], Loss: 0.1262\n",
      "Epoch [50/50], Step [461/735], Loss: 0.1977\n",
      "Epoch [50/50], Step [462/735], Loss: 0.1823\n",
      "Epoch [50/50], Step [463/735], Loss: 0.1892\n",
      "Epoch [50/50], Step [464/735], Loss: 0.1724\n",
      "Epoch [50/50], Step [465/735], Loss: 0.1620\n",
      "Epoch [50/50], Step [466/735], Loss: 0.7436\n",
      "Epoch [50/50], Step [467/735], Loss: 0.1266\n",
      "Epoch [50/50], Step [468/735], Loss: 0.1478\n",
      "Epoch [50/50], Step [469/735], Loss: 0.3271\n",
      "Epoch [50/50], Step [470/735], Loss: 0.0408\n",
      "Epoch [50/50], Step [471/735], Loss: 0.2385\n",
      "Epoch [50/50], Step [472/735], Loss: 0.7018\n",
      "Epoch [50/50], Step [473/735], Loss: 0.1674\n",
      "Epoch [50/50], Step [474/735], Loss: 0.1061\n",
      "Epoch [50/50], Step [475/735], Loss: 0.1503\n",
      "Epoch [50/50], Step [476/735], Loss: 0.2879\n",
      "Epoch [50/50], Step [477/735], Loss: 0.3891\n",
      "Epoch [50/50], Step [478/735], Loss: 0.2688\n",
      "Epoch [50/50], Step [479/735], Loss: 0.0944\n",
      "Epoch [50/50], Step [480/735], Loss: 0.3769\n",
      "Epoch [50/50], Step [481/735], Loss: 0.3266\n",
      "Epoch [50/50], Step [482/735], Loss: 0.0668\n",
      "Epoch [50/50], Step [483/735], Loss: 0.5101\n",
      "Epoch [50/50], Step [484/735], Loss: 0.0646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Step [485/735], Loss: 0.1086\n",
      "Epoch [50/50], Step [486/735], Loss: 0.0760\n",
      "Epoch [50/50], Step [487/735], Loss: 0.0975\n",
      "Epoch [50/50], Step [488/735], Loss: 0.1625\n",
      "Epoch [50/50], Step [489/735], Loss: 0.3460\n",
      "Epoch [50/50], Step [490/735], Loss: 0.4889\n",
      "Epoch [50/50], Step [491/735], Loss: 0.9011\n",
      "Epoch [50/50], Step [492/735], Loss: 0.1043\n",
      "Epoch [50/50], Step [493/735], Loss: 0.1994\n",
      "Epoch [50/50], Step [494/735], Loss: 0.1893\n",
      "Epoch [50/50], Step [495/735], Loss: 0.5106\n",
      "Epoch [50/50], Step [496/735], Loss: 0.2563\n",
      "Epoch [50/50], Step [497/735], Loss: 0.1674\n",
      "Epoch [50/50], Step [498/735], Loss: 0.2189\n",
      "Epoch [50/50], Step [499/735], Loss: 0.1614\n",
      "Epoch [50/50], Step [500/735], Loss: 0.1305\n",
      "Epoch [50/50], Step [501/735], Loss: 0.2989\n",
      "Epoch [50/50], Step [502/735], Loss: 0.1994\n",
      "Epoch [50/50], Step [503/735], Loss: 0.2173\n",
      "Epoch [50/50], Step [504/735], Loss: 0.1397\n",
      "Epoch [50/50], Step [505/735], Loss: 0.2056\n",
      "Epoch [50/50], Step [506/735], Loss: 0.3450\n",
      "Epoch [50/50], Step [507/735], Loss: 0.3743\n",
      "Epoch [50/50], Step [508/735], Loss: 0.5812\n",
      "Epoch [50/50], Step [509/735], Loss: 0.1239\n",
      "Epoch [50/50], Step [510/735], Loss: 0.0991\n",
      "Epoch [50/50], Step [511/735], Loss: 0.1508\n",
      "Epoch [50/50], Step [512/735], Loss: 0.2476\n",
      "Epoch [50/50], Step [513/735], Loss: 0.1564\n",
      "Epoch [50/50], Step [514/735], Loss: 0.2718\n",
      "Epoch [50/50], Step [515/735], Loss: 0.0554\n",
      "Epoch [50/50], Step [516/735], Loss: 0.3129\n",
      "Epoch [50/50], Step [517/735], Loss: 2.4786\n",
      "Epoch [50/50], Step [518/735], Loss: 0.2005\n",
      "Epoch [50/50], Step [519/735], Loss: 0.5731\n",
      "Epoch [50/50], Step [520/735], Loss: 0.2185\n",
      "Epoch [50/50], Step [521/735], Loss: 0.1255\n",
      "Epoch [50/50], Step [522/735], Loss: 0.7953\n",
      "Epoch [50/50], Step [523/735], Loss: 0.1851\n",
      "Epoch [50/50], Step [524/735], Loss: 0.1371\n",
      "Epoch [50/50], Step [525/735], Loss: 0.4427\n",
      "Epoch [50/50], Step [526/735], Loss: 1.4551\n",
      "Epoch [50/50], Step [527/735], Loss: 0.7840\n",
      "Epoch [50/50], Step [528/735], Loss: 0.0921\n",
      "Epoch [50/50], Step [529/735], Loss: 0.4358\n",
      "Epoch [50/50], Step [530/735], Loss: 0.2603\n",
      "Epoch [50/50], Step [531/735], Loss: 0.6738\n",
      "Epoch [50/50], Step [532/735], Loss: 0.2537\n",
      "Epoch [50/50], Step [533/735], Loss: 0.1827\n",
      "Epoch [50/50], Step [534/735], Loss: 0.2343\n",
      "Epoch [50/50], Step [535/735], Loss: 0.1142\n",
      "Epoch [50/50], Step [536/735], Loss: 0.4974\n",
      "Epoch [50/50], Step [537/735], Loss: 0.3836\n",
      "Epoch [50/50], Step [538/735], Loss: 1.3987\n",
      "Epoch [50/50], Step [539/735], Loss: 0.3513\n",
      "Epoch [50/50], Step [540/735], Loss: 0.2397\n",
      "Epoch [50/50], Step [541/735], Loss: 0.3820\n",
      "Epoch [50/50], Step [542/735], Loss: 0.1959\n",
      "Epoch [50/50], Step [543/735], Loss: 0.3148\n",
      "Epoch [50/50], Step [544/735], Loss: 0.3098\n",
      "Epoch [50/50], Step [545/735], Loss: 0.2409\n",
      "Epoch [50/50], Step [546/735], Loss: 0.4479\n",
      "Epoch [50/50], Step [547/735], Loss: 0.3842\n",
      "Epoch [50/50], Step [548/735], Loss: 0.4347\n",
      "Epoch [50/50], Step [549/735], Loss: 0.1782\n",
      "Epoch [50/50], Step [550/735], Loss: 0.1440\n",
      "Epoch [50/50], Step [551/735], Loss: 0.2059\n",
      "Epoch [50/50], Step [552/735], Loss: 0.4983\n",
      "Epoch [50/50], Step [553/735], Loss: 0.5237\n",
      "Epoch [50/50], Step [554/735], Loss: 0.2418\n",
      "Epoch [50/50], Step [555/735], Loss: 0.1292\n",
      "Epoch [50/50], Step [556/735], Loss: 0.2748\n",
      "Epoch [50/50], Step [557/735], Loss: 0.3018\n",
      "Epoch [50/50], Step [558/735], Loss: 0.4864\n",
      "Epoch [50/50], Step [559/735], Loss: 0.2191\n",
      "Epoch [50/50], Step [560/735], Loss: 0.2045\n",
      "Epoch [50/50], Step [561/735], Loss: 0.9594\n",
      "Epoch [50/50], Step [562/735], Loss: 0.4224\n",
      "Epoch [50/50], Step [563/735], Loss: 0.1785\n",
      "Epoch [50/50], Step [564/735], Loss: 0.1823\n",
      "Epoch [50/50], Step [565/735], Loss: 1.0304\n",
      "Epoch [50/50], Step [566/735], Loss: 0.5105\n",
      "Epoch [50/50], Step [567/735], Loss: 0.2623\n",
      "Epoch [50/50], Step [568/735], Loss: 0.3051\n",
      "Epoch [50/50], Step [569/735], Loss: 0.2163\n",
      "Epoch [50/50], Step [570/735], Loss: 0.1287\n",
      "Epoch [50/50], Step [571/735], Loss: 0.4029\n",
      "Epoch [50/50], Step [572/735], Loss: 0.3307\n",
      "Epoch [50/50], Step [573/735], Loss: 0.5600\n",
      "Epoch [50/50], Step [574/735], Loss: 0.0685\n",
      "Epoch [50/50], Step [575/735], Loss: 0.1071\n",
      "Epoch [50/50], Step [576/735], Loss: 0.2521\n",
      "Epoch [50/50], Step [577/735], Loss: 0.1280\n",
      "Epoch [50/50], Step [578/735], Loss: 0.1182\n",
      "Epoch [50/50], Step [579/735], Loss: 0.1834\n",
      "Epoch [50/50], Step [580/735], Loss: 0.2365\n",
      "Epoch [50/50], Step [581/735], Loss: 0.2229\n",
      "Epoch [50/50], Step [582/735], Loss: 0.4397\n",
      "Epoch [50/50], Step [583/735], Loss: 0.2592\n",
      "Epoch [50/50], Step [584/735], Loss: 0.2358\n",
      "Epoch [50/50], Step [585/735], Loss: 0.2630\n",
      "Epoch [50/50], Step [586/735], Loss: 0.2007\n",
      "Epoch [50/50], Step [587/735], Loss: 0.1891\n",
      "Epoch [50/50], Step [588/735], Loss: 0.2490\n",
      "Epoch [50/50], Step [589/735], Loss: 0.2787\n",
      "Epoch [50/50], Step [590/735], Loss: 0.2587\n",
      "Epoch [50/50], Step [591/735], Loss: 0.1415\n",
      "Epoch [50/50], Step [592/735], Loss: 0.3473\n",
      "Epoch [50/50], Step [593/735], Loss: 0.3966\n",
      "Epoch [50/50], Step [594/735], Loss: 0.1789\n",
      "Epoch [50/50], Step [595/735], Loss: 0.1271\n",
      "Epoch [50/50], Step [596/735], Loss: 0.1170\n",
      "Epoch [50/50], Step [597/735], Loss: 0.0492\n",
      "Epoch [50/50], Step [598/735], Loss: 0.1185\n",
      "Epoch [50/50], Step [599/735], Loss: 0.3585\n",
      "Epoch [50/50], Step [600/735], Loss: 0.1652\n",
      "Epoch [50/50], Step [601/735], Loss: 0.1383\n",
      "Epoch [50/50], Step [602/735], Loss: 0.3538\n",
      "Epoch [50/50], Step [603/735], Loss: 0.1771\n",
      "Epoch [50/50], Step [604/735], Loss: 0.0989\n",
      "Epoch [50/50], Step [605/735], Loss: 0.1455\n",
      "Epoch [50/50], Step [606/735], Loss: 0.1831\n",
      "Epoch [50/50], Step [607/735], Loss: 0.2412\n",
      "Epoch [50/50], Step [608/735], Loss: 0.3555\n",
      "Epoch [50/50], Step [609/735], Loss: 0.1310\n",
      "Epoch [50/50], Step [610/735], Loss: 0.1923\n",
      "Epoch [50/50], Step [611/735], Loss: 0.1414\n",
      "Epoch [50/50], Step [612/735], Loss: 0.3395\n",
      "Epoch [50/50], Step [613/735], Loss: 0.0919\n",
      "Epoch [50/50], Step [614/735], Loss: 0.1451\n",
      "Epoch [50/50], Step [615/735], Loss: 0.1053\n",
      "Epoch [50/50], Step [616/735], Loss: 0.2162\n",
      "Epoch [50/50], Step [617/735], Loss: 0.1142\n",
      "Epoch [50/50], Step [618/735], Loss: 0.4193\n",
      "Epoch [50/50], Step [619/735], Loss: 0.2571\n",
      "Epoch [50/50], Step [620/735], Loss: 0.2125\n",
      "Epoch [50/50], Step [621/735], Loss: 0.1088\n",
      "Epoch [50/50], Step [622/735], Loss: 0.2261\n",
      "Epoch [50/50], Step [623/735], Loss: 0.3242\n",
      "Epoch [50/50], Step [624/735], Loss: 0.1053\n",
      "Epoch [50/50], Step [625/735], Loss: 0.1899\n",
      "Epoch [50/50], Step [626/735], Loss: 0.1145\n",
      "Epoch [50/50], Step [627/735], Loss: 0.0850\n",
      "Epoch [50/50], Step [628/735], Loss: 0.0769\n",
      "Epoch [50/50], Step [629/735], Loss: 0.1012\n",
      "Epoch [50/50], Step [630/735], Loss: 0.1536\n",
      "Epoch [50/50], Step [631/735], Loss: 0.4453\n",
      "Epoch [50/50], Step [632/735], Loss: 0.2010\n",
      "Epoch [50/50], Step [633/735], Loss: 0.2017\n",
      "Epoch [50/50], Step [634/735], Loss: 0.3203\n",
      "Epoch [50/50], Step [635/735], Loss: 0.3262\n",
      "Epoch [50/50], Step [636/735], Loss: 0.2016\n",
      "Epoch [50/50], Step [637/735], Loss: 0.1080\n",
      "Epoch [50/50], Step [638/735], Loss: 0.3000\n",
      "Epoch [50/50], Step [639/735], Loss: 0.2572\n",
      "Epoch [50/50], Step [640/735], Loss: 0.2529\n",
      "Epoch [50/50], Step [641/735], Loss: 0.7292\n",
      "Epoch [50/50], Step [642/735], Loss: 0.2672\n",
      "Epoch [50/50], Step [643/735], Loss: 0.2311\n",
      "Epoch [50/50], Step [644/735], Loss: 0.3733\n",
      "Epoch [50/50], Step [645/735], Loss: 0.1979\n",
      "Epoch [50/50], Step [646/735], Loss: 0.0585\n",
      "Epoch [50/50], Step [647/735], Loss: 0.2319\n",
      "Epoch [50/50], Step [648/735], Loss: 0.1559\n",
      "Epoch [50/50], Step [649/735], Loss: 0.1127\n",
      "Epoch [50/50], Step [650/735], Loss: 0.1036\n",
      "Epoch [50/50], Step [651/735], Loss: 0.1402\n",
      "Epoch [50/50], Step [652/735], Loss: 0.1105\n",
      "Epoch [50/50], Step [653/735], Loss: 0.1629\n",
      "Epoch [50/50], Step [654/735], Loss: 0.1361\n",
      "Epoch [50/50], Step [655/735], Loss: 0.8698\n",
      "Epoch [50/50], Step [656/735], Loss: 0.2379\n",
      "Epoch [50/50], Step [657/735], Loss: 0.2681\n",
      "Epoch [50/50], Step [658/735], Loss: 0.3344\n",
      "Epoch [50/50], Step [659/735], Loss: 0.2537\n",
      "Epoch [50/50], Step [660/735], Loss: 0.1312\n",
      "Epoch [50/50], Step [661/735], Loss: 0.1673\n",
      "Epoch [50/50], Step [662/735], Loss: 0.4165\n",
      "Epoch [50/50], Step [663/735], Loss: 0.1551\n",
      "Epoch [50/50], Step [664/735], Loss: 0.1522\n",
      "Epoch [50/50], Step [665/735], Loss: 0.4373\n",
      "Epoch [50/50], Step [666/735], Loss: 0.0887\n",
      "Epoch [50/50], Step [667/735], Loss: 0.2400\n",
      "Epoch [50/50], Step [668/735], Loss: 0.0577\n",
      "Epoch [50/50], Step [669/735], Loss: 0.2587\n",
      "Epoch [50/50], Step [670/735], Loss: 0.3075\n",
      "Epoch [50/50], Step [671/735], Loss: 0.1382\n",
      "Epoch [50/50], Step [672/735], Loss: 0.3516\n",
      "Epoch [50/50], Step [673/735], Loss: 0.1389\n",
      "Epoch [50/50], Step [674/735], Loss: 0.2442\n",
      "Epoch [50/50], Step [675/735], Loss: 0.0852\n",
      "Epoch [50/50], Step [676/735], Loss: 0.8190\n",
      "Epoch [50/50], Step [677/735], Loss: 0.1165\n",
      "Epoch [50/50], Step [678/735], Loss: 0.1396\n",
      "Epoch [50/50], Step [679/735], Loss: 0.1698\n",
      "Epoch [50/50], Step [680/735], Loss: 0.1146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Step [681/735], Loss: 0.1989\n",
      "Epoch [50/50], Step [682/735], Loss: 0.3095\n",
      "Epoch [50/50], Step [683/735], Loss: 0.1360\n",
      "Epoch [50/50], Step [684/735], Loss: 0.1854\n",
      "Epoch [50/50], Step [685/735], Loss: 0.2575\n",
      "Epoch [50/50], Step [686/735], Loss: 0.4467\n",
      "Epoch [50/50], Step [687/735], Loss: 0.1848\n",
      "Epoch [50/50], Step [688/735], Loss: 0.2885\n",
      "Epoch [50/50], Step [689/735], Loss: 0.3631\n",
      "Epoch [50/50], Step [690/735], Loss: 0.1302\n",
      "Epoch [50/50], Step [691/735], Loss: 0.3010\n",
      "Epoch [50/50], Step [692/735], Loss: 0.1191\n",
      "Epoch [50/50], Step [693/735], Loss: 0.3443\n",
      "Epoch [50/50], Step [694/735], Loss: 0.3674\n",
      "Epoch [50/50], Step [695/735], Loss: 0.5698\n",
      "Epoch [50/50], Step [696/735], Loss: 0.0878\n",
      "Epoch [50/50], Step [697/735], Loss: 0.2126\n",
      "Epoch [50/50], Step [698/735], Loss: 0.1633\n",
      "Epoch [50/50], Step [699/735], Loss: 0.2720\n",
      "Epoch [50/50], Step [700/735], Loss: 0.2780\n",
      "Epoch [50/50], Step [701/735], Loss: 0.1401\n",
      "Epoch [50/50], Step [702/735], Loss: 0.4404\n",
      "Epoch [50/50], Step [703/735], Loss: 0.1171\n",
      "Epoch [50/50], Step [704/735], Loss: 0.0851\n",
      "Epoch [50/50], Step [705/735], Loss: 0.2023\n",
      "Epoch [50/50], Step [706/735], Loss: 1.7607\n",
      "Epoch [50/50], Step [707/735], Loss: 0.2646\n",
      "Epoch [50/50], Step [708/735], Loss: 0.1940\n",
      "Epoch [50/50], Step [709/735], Loss: 0.0777\n",
      "Epoch [50/50], Step [710/735], Loss: 0.0883\n",
      "Epoch [50/50], Step [711/735], Loss: 0.3406\n",
      "Epoch [50/50], Step [712/735], Loss: 0.1647\n",
      "Epoch [50/50], Step [713/735], Loss: 0.1468\n",
      "Epoch [50/50], Step [714/735], Loss: 0.0890\n",
      "Epoch [50/50], Step [715/735], Loss: 0.2057\n",
      "Epoch [50/50], Step [716/735], Loss: 0.1682\n",
      "Epoch [50/50], Step [717/735], Loss: 0.0856\n",
      "Epoch [50/50], Step [718/735], Loss: 0.2937\n",
      "Epoch [50/50], Step [719/735], Loss: 0.0898\n",
      "Epoch [50/50], Step [720/735], Loss: 0.2583\n",
      "Epoch [50/50], Step [721/735], Loss: 0.5715\n",
      "Epoch [50/50], Step [722/735], Loss: 0.4905\n",
      "Epoch [50/50], Step [723/735], Loss: 0.6600\n",
      "Epoch [50/50], Step [724/735], Loss: 0.2785\n",
      "Epoch [50/50], Step [725/735], Loss: 0.5291\n",
      "Epoch [50/50], Step [726/735], Loss: 0.3674\n",
      "Epoch [50/50], Step [727/735], Loss: 0.0646\n",
      "Epoch [50/50], Step [728/735], Loss: 0.2716\n",
      "Epoch [50/50], Step [729/735], Loss: 0.2181\n",
      "Epoch [50/50], Step [730/735], Loss: 0.3214\n",
      "Epoch [50/50], Step [731/735], Loss: 0.2548\n",
      "Epoch [50/50], Step [732/735], Loss: 0.0979\n",
      "Epoch [50/50], Step [733/735], Loss: 0.1066\n",
      "Epoch [50/50], Step [734/735], Loss: 0.1550\n",
      "Epoch [50/50], Step [735/735], Loss: 0.1322\n"
     ]
    }
   ],
   "source": [
    "# Set device (CPU or GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Model parameters\n",
    "input_dim = N\n",
    "hidden_dim = 128\n",
    "output_dim = N\n",
    "num_layers = 1\n",
    "num_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Initialize the model, loss function and optimizer\n",
    "model = LSTMModel(input_dim, hidden_dim, output_dim, num_layers).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "epoch_loss = []\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "        #if (i+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf052e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.figure(1, figsize = [20,10])\n",
    "plt.semilogy(epoch_loss)\n",
    "plt.ylabel('Loss(log scale)')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6c66ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriniva3\\AppData\\Local\\Temp\\ipykernel_25872\\1681708791.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_inputs = torch.tensor(inp_test_data, dtype=torch.float32).to(device)\n",
      "C:\\Users\\sriniva3\\AppData\\Local\\Temp\\ipykernel_25872\\1681708791.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_targets = torch.tensor(out_test_data, dtype=torch.float32).to(device)\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    test_inputs = torch.tensor(inp_test_data, dtype=torch.float32).to(device)\n",
    "    test_targets = torch.tensor(out_test_data, dtype=torch.float32).to(device)\n",
    "    test_outputs = model(test_inputs)\n",
    "    test_loss = criterion(test_outputs, test_targets)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce79837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, 'LSTM.pth')\n",
    "#torch.save(model.state_dict(), 'LSTM_state_dict.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "199e3c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## CDF plots ###########\n",
    "pred = test_outputs.detach().numpy()\n",
    "tgt = test_targets.detach().numpy()\n",
    "error = tgt - pred\n",
    "#pred = pred.flatten()\n",
    "#tgt = tgt.flatten()\n",
    "sortd_pred, a_pred = return_cdf(pred[:,0])\n",
    "sortd_tgt, a_tgt = return_cdf(tgt[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "044e0a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(sortd_pred, a_pred)\n",
    "#plt.plot(sortd_tgt, a_tgt, alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bf13b9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pred[:,0], alpha = 1, label = 'predicted')\n",
    "plt.plot(tgt[:,0], label = 'target')\n",
    "plt.legend()\n",
    "plt.ylabel('SINR(dB)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cdc4fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sortd_error, a_error = return_cdf(error.flatten())\n",
    "plt.plot(sortd_error, a_error)\n",
    "plt.title('CDF of error between predicted and ground truth SINR')\n",
    "plt.xlabel('SINRS(dB)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b089c9eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249d895c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8dd6cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
