{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa94cabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "#import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import random\n",
    "import pdb\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pickle\n",
    "import scipy.io\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import pandas as pd\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "from tqdm import tqdm\n",
    "import matplotlib.animation as animation\n",
    "import glob\n",
    "from natsort import natsorted\n",
    "from PIL import Image\n",
    "\n",
    "def create_gif(pth, time_ind):\n",
    "    #files = glob.glob(r\"./imgs/*.png\")\n",
    "    files = glob.glob(os.path.join(pth,'*.png'))\n",
    "    files = natsorted(files)\n",
    "    image_array = []\n",
    "    \n",
    "    def update(i):\n",
    "        im.set_array(image_array[i])\n",
    "        return im, \n",
    "    \n",
    "    for my_file in files:\n",
    "\n",
    "        image = Image.open(my_file)\n",
    "        image_array.append(image)\n",
    "    \n",
    "    # Create the figure and axes objects\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Set the initial image\n",
    "    im = ax.imshow(image_array[0], animated=True)\n",
    "    \n",
    "    animation_fig = animation.FuncAnimation(fig, update, frames=len(image_array), interval=100, blit=True,repeat_delay=10,)\n",
    "\n",
    "    # Show the animation\n",
    "    #plt.show()\n",
    "\n",
    "    #animation_fig.save(\"./imgs/animated_{}.gif\".format(time_ind))\n",
    "    animation_fig.save(os.path.join(pth,'animated_{}.gif').format(time_ind))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e43846d",
   "metadata": {},
   "source": [
    "### Adding gamma_0 value for SINR computation ####\n",
    "\n",
    "$\\gamma = \\frac{|h|_s^2P_t}{|h|_i^2P_t + N_0B}$\n",
    "\n",
    "Assuming power transmitted power is same from all BSs then we have \n",
    "\n",
    "$\\gamma = \\frac{|h|_s^2}{|h|_i^2 + \\frac{1}{\\gamma_0}}$\n",
    "\n",
    "\n",
    "where $\\gamma_0 = P_t/N_0B$, you can assume P_t = 10 dBm, and the below calculations for $N_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dc46e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise_spectral_density_dBm -173.97722915699805\n",
      "thermal_noise_power(dBm) -103.97722915699808\n",
      "1/gamma_0 4.001999999999999e-12\n"
     ]
    }
   ],
   "source": [
    "## transmit power ###\n",
    "Pt_dBm = 10  # Transmit power in dBm\n",
    "\n",
    "#### Noise power ####\n",
    "k = 1.38e-23  # Boltzmann's constant\n",
    "T = 290       # Temperature in Kelvin\n",
    "B = 10e6       # Bandwidth in Hz\n",
    "\n",
    "# Calculate noise spectral density in Watts/Hz\n",
    "Noise_spectral_density = k * T\n",
    "\n",
    "# Convert noise spectral density to dBm/Hz\n",
    "# Convert to Watts first then to dBm (1 mW = 0.001 W)\n",
    "Noise_spectral_density_W = Noise_spectral_density * 1000  # Convert to mW\n",
    "Noise_spectral_density_dBm = 10 * np.log10(Noise_spectral_density_W)\n",
    "print('Noise_spectral_density_dBm', Noise_spectral_density_dBm)\n",
    "\n",
    "# Calculate total noise power in Watts then convert to dBm\n",
    "N_thermal = Noise_spectral_density * B  # Total noise power in Watts\n",
    "N_thermal_dBm = 10 * np.log10(N_thermal * 1000)  # Convert noise power to dBm\n",
    "print('thermal_noise_power(dBm)', N_thermal_dBm)\n",
    "\n",
    "##### gamma_0 in dB ############\n",
    "gamma_0_dB = Pt_dBm - N_thermal_dBm  # Calculate SNR in dB\n",
    "#print('gamma_0 (dB)', gamma_0_dB)\n",
    "\n",
    "##### gamma_0 ######\n",
    "gamma_0 = np.power(10, gamma_0_dB/10)\n",
    "print('1/gamma_0', 1/gamma_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b76f51e",
   "metadata": {},
   "source": [
    "### \n",
    "CDF of SINR computed for F($\\gamma$), for different channel realizations,\n",
    "below is when the the device is at a mean distance of 1m from the serving BS with a standard deviation of 0.1 m, and mean distance from the interfering BS at 4 meters with std of 0.1m "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a7ae1d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def return_cdf(a):\n",
    "    sorted_a = np.sort(a)\n",
    "    cdf = np.arange(1, len(sorted_a) + 1) / len(sorted_a)\n",
    "    return sorted_a, cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "471a7686",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Creating distances intra and inter ########\n",
    "M = 5 # number of sub-networks \n",
    "Ts = 10000 # number of time slots\n",
    "J = 5 # number of devices\n",
    "f_c = 1.3 #GHz\n",
    "N = 30\n",
    "TxRxds = np.zeros((Ts, M, M*J))\n",
    "d_intra = np.abs(np.random.normal(0.5,0.1,M*J))\n",
    "d_intra = np.reshape(d_intra, (M,J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3a24ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 9999/9999 [00:00<00:00, 16323.58it/s]\n"
     ]
    }
   ],
   "source": [
    "def generate_random_point(grid_size):\n",
    "    return np.random.uniform(0, grid_size, 2)\n",
    "\n",
    "def generate_random_velocity():\n",
    "    angle = np.random.uniform(0, 2 * np.pi)\n",
    "    velocity = 11.11  # 40 km/h in m/s\n",
    "    return np.array([velocity * np.cos(angle), velocity * np.sin(angle)])\n",
    "\n",
    "def is_within_grid(point, grid_size):\n",
    "    return all(0 <= coord <= grid_size for coord in point)\n",
    "\n",
    "def handle_boundary_collisions(point, grid_size):\n",
    "    angle = np.random.uniform(0, 2 * np.pi)\n",
    "    velocity = 11.11\n",
    "    if point[0] <= 0 or point[0] >= grid_size:\n",
    "        angle = np.pi - angle if point[0] <= 0 else -angle\n",
    "    if point[1] <= 0 or point[1] >= grid_size:\n",
    "        angle = -np.pi / 2 - angle if point[1] <= 0 else np.pi / 2 - angle\n",
    "    return np.array([velocity * np.cos(angle), velocity * np.sin(angle)])\n",
    "\n",
    "def handle_ap_collisions(points, velocities, min_distance):\n",
    "    for i in range(len(points)):\n",
    "        for j in range(i + 1, len(points)):\n",
    "            if np.linalg.norm(points[i] - points[j]) < min_distance:\n",
    "                # Adjust direction randomly for both APs\n",
    "                velocities[i] = generate_random_velocity()\n",
    "                velocities[j] = generate_random_velocity()\n",
    "    return velocities\n",
    "\n",
    "def update_positions(points, velocities, tau, grid_size, min_distance):\n",
    "    new_points = points + velocities * tau\n",
    "    for i, point in enumerate(new_points):\n",
    "        if not is_within_grid(point, grid_size):\n",
    "            velocities[i] = handle_boundary_collisions(point, grid_size)\n",
    "        new_points[i] = points[i] + velocities[i] * tau  # Recalculate with new velocity\n",
    "    velocities = handle_ap_collisions(new_points, velocities, min_distance)\n",
    "    return new_points, velocities\n",
    "\n",
    "# Initialize parameters\n",
    "grid_size = 20\n",
    "num_points = M\n",
    "min_distance = 2\n",
    "tau = 0.01  # time interval in seconds\n",
    "\n",
    "# Initialize points and velocities\n",
    "points = np.array([generate_random_point(grid_size) for _ in range(num_points)])\n",
    "velocities = np.array([generate_random_velocity() for _ in range(num_points)])\n",
    "init_cents = points\n",
    "# Simulation loop for 20 time steps\n",
    "pth = r'C:\\Users\\sriniva3\\OneDrive - Aalto University\\Simulations\\RL framework URLLC\\RL framework_V2.0_DDPG\\imgs'\n",
    "#Ts = 1000\n",
    "sub_net_cents = np.zeros((Ts+1, num_points, 2))\n",
    "sub_net_cents[0] = init_cents\n",
    "for step in tqdm(range(Ts-1)):\n",
    "    points, velocities = update_positions(points, velocities, tau, grid_size, min_distance)\n",
    "    sub_net_cents[step+1] = points\n",
    "    '''\n",
    "    # Plotting for visualization\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.scatter(points[:, 0], points[:, 1], c='red', label=f'Time Step {step+1}')\n",
    "    plt.xlim(0, grid_size)\n",
    "    plt.ylim(0, grid_size)\n",
    "    plt.grid(True)\n",
    "    plt.title(f'Access Points at Step {step+1}')\n",
    "    plt.xlabel('Meters')\n",
    "    plt.ylabel('Meters')\n",
    "    #plt.legend()\n",
    "    plt.savefig(os.path.join(pth, '{}.png'.format(step)))\n",
    "    plt.close()\n",
    "    #plt.show()\n",
    "    ''';\n",
    "#create_gif(pth, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f571f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_relative_locs = {}\n",
    "for i in range(M):\n",
    "    d_angle = np.random.uniform(0,2*np.pi,J) \n",
    "    d_r = np.random.uniform(0, 1, J)\n",
    "    d_relative_locs[i] = np.vstack([d_r*np.cos(d_angle), d_r*np.sin(d_angle)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cc676f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_euclid_dist(device_x_coord, device_y_coord, AP_x_coord, AP_y_coord):\n",
    "    device_coords = np.array([device_x_coord, device_y_coord])\n",
    "    AP_coords = np.array([AP_x_coord, AP_y_coord])\n",
    "    return np.linalg.norm(device_coords - AP_coords)\n",
    "\n",
    "x_coords_ts, y_coords_ts = {}, {}\n",
    "for ts in range(Ts):\n",
    "    coords = sub_net_cents[ts]\n",
    "    point_xs, point_ys = [], []\n",
    "    for k in d_relative_locs.keys():\n",
    "        point_x = d_relative_locs[k][0] + coords[k][0]\n",
    "        point_y = d_relative_locs[k][1] + coords[k][1]\n",
    "        #print(point_x, point_y)\n",
    "        point_xs.append(point_x)\n",
    "        point_ys.append(point_y)\n",
    "    #break    \n",
    "    x_coords_ts[ts] = point_xs\n",
    "    y_coords_ts[ts] = point_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e05a3ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TxRxds = np.zeros((Ts, M, M*J))\n",
    "for ts in range(Ts):\n",
    "    device_x_coords, device_y_coords = np.array(x_coords_ts[ts]), np.array(y_coords_ts[ts])\n",
    "    device_x_coords, device_y_coords = device_x_coords.flatten(), device_y_coords.flatten()\n",
    "    AP_x_coords, AP_y_coords = sub_net_cents[ts][:,0], sub_net_cents[ts][:,1]\n",
    "    \n",
    "    #for dx in device_x_coords \n",
    "    dists = np.zeros((M,M*J))\n",
    "    for i in range(AP_x_coords.shape[0]):\n",
    "        dist = []\n",
    "        for j in range(len(device_x_coords.flatten())):\n",
    "            #dist = []\n",
    "            #print(i,j)\n",
    "            dist.append(return_euclid_dist(device_x_coords[j], device_y_coords[j], AP_x_coords[i], AP_y_coords[i]))\n",
    "            #print(dist)\n",
    "        dists[i] = np.array(dist)\n",
    "    TxRxds[ts] = dists\n",
    "    #break\n",
    "\n",
    "#dist = return_euclid_dist(x_coords_ts[0], y_coords_ts[0], AP_x_coord, AP_y_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfd07bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([287663., 108412., 154942., 169716., 167512., 155249., 113500.,\n",
       "         63954.,  25569.,   3483.]),\n",
       " array([ 0.03170619,  2.68713165,  5.34255711,  7.99798257, 10.65340803,\n",
       "        13.30883349, 15.96425895, 18.61968441, 21.27510987, 23.93053534,\n",
       "        26.5859608 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(TxRxds.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa0ed303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5, 25)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TxRxds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16618737",
   "metadata": {},
   "source": [
    "### Using Jakes model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4647ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def return_jakes_coeffcients(fd_max, TimeVaris, n_links = 5, plot = True):\n",
    "    ff_gains, TimeSequences = [], []\n",
    "    rays = 100\n",
    "    for i in tqdm(range(n_links)):    \n",
    "        #TimeVaris = np.arange(0,50,0.0005)\n",
    "        #TimeVaris = np.arange(0,.2,0.005)\n",
    "        frequs = np.sort(np.array([np.round(fd_max*np.cos(2*np.pi*np.random.uniform(0,1))) for _ in range(rays)]))\n",
    "        phases = np.array([np.exp(1j*2*np.pi*np.random.uniform(0,1)) for _ in range(rays)])\n",
    "\n",
    "        TimeSequence = []\n",
    "        for t in TimeVaris:\n",
    "            tab = np.exp(1j*2*np.pi*frequs*t)\n",
    "            tabrot = tab*phases\n",
    "            fun = np.sum(tabrot)\n",
    "            TimeSequence.append(fun)\n",
    "        TimeSequence = np.array(TimeSequence)\n",
    "\n",
    "        #TimeSequence = TimeSequence/np.linalg.norm(TimeSequence)*np.sqrt(len(TimeSequence))\n",
    "        PowerSequence1 =  np.abs(TimeSequence)**2;\n",
    "        #plt.plot(TimeVaris[0:200], 10*np.log10(PowerSequence1)[0:200])\n",
    "        ff_gains.append(PowerSequence1)\n",
    "        TimeSequences.append(TimeSequence)\n",
    "    ff_gains = np.array(ff_gains)/rays\n",
    "    TimeSequences = np.array(TimeSequences)\n",
    "    if plot:\n",
    "        plt.plot(TimeVaris[0:200], 10*np.log10(ff_gains[0])[0:200])\n",
    "        plt.show()\n",
    "    return ff_gains, TimeSequences\n",
    "\n",
    "v = 40 #kmph \n",
    "v_ms = v*5/18\n",
    "c = 3*1e8\n",
    "tau = .01\n",
    "fd_max = v_ms*f_c*1e9/c\n",
    "TimeVaris = np.arange(0,5,0.0005)\n",
    "\n",
    "ff_gains, TimeSequences = return_jakes_coeffcients(fd_max, TimeVaris, n_links = M*(M-1)*J*N, plot = False)\n",
    "#plt.plot(TimeVaris[0:Ts], 10*np.log10(ff_gains.flatten()[0:Ts]))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc5f6e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save( 'ff_gains_3000.npy',ff_gains)\n",
    "#ff_gains = np.load('ff_gains_3000.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f53e824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############ fast fading coeffecients ########\n",
    "\n",
    "FastFadingChannels = np.random.normal(0,1/np.sqrt(2), M*J*N) + 1j*np.random.normal(0,1/np.sqrt(2), M*J*N)\n",
    "FastFadingChannels = np.reshape(FastFadingChannels,(M,J,N))\n",
    "FadingGains = np.abs(FastFadingChannels)**2\n",
    "#all_SINRsdB, all_MeansPerSubNW, all_DiffsFromMean = np.zeros((Ts, M*J)), np.zeros((Ts, M)), np.zeros((Ts, M*J))\n",
    "all_SINRsdB = np.zeros((Ts, M,J,N))\n",
    "alltime_WantedSigPerDev, alltime_InterfPowsPerDev = [], []\n",
    "for ts in range(Ts):\n",
    "    \n",
    "\n",
    "    #FadingGains.shape\n",
    "\n",
    "    all_fast_fading_gains = np.zeros((M,M*J,N))\n",
    "    for m in range(M):\n",
    "        jakes_coeffs = ff_gains[:,ts]\n",
    "        jakes_coeffs = np.reshape(jakes_coeffs,(M,(M-1)*J,N))\n",
    "        all_fast_fading_gains[m] = np.concatenate([FadingGains[m], jakes_coeffs[m]])\n",
    "    all_fast_fading_gains = np.array(all_fast_fading_gains)\n",
    "    \n",
    "    PL_los = 31.84 +21.5*np.log10(TxRxds[ts]) + 19*np.log10(f_c)\n",
    "    PL = 33+25.5*np.log10(TxRxds[ts])+20*np.log10(f_c)\n",
    "    PL_nlos = np.max((PL_los, PL), axis = 0)\n",
    "    PathGains = np.power(10, -PL_nlos/10)\n",
    "    PathGains = np.repeat(PathGains[:, :, np.newaxis], N, axis=2)\n",
    "\n",
    "    ##### Compute total path gains ########\n",
    "    #pdb.set_trace()\n",
    "    PathGainsTot = PathGains*all_fast_fading_gains\n",
    "\n",
    "    #### Compute WantedSigPerDev ######\n",
    "    WantedSigPerDev = np.zeros((M,J,N))\n",
    "    for m in range(M):\n",
    "        WantedSigPerDev[m] = PathGainsTot[m,m*J:(m+1)*J]\n",
    "    alltime_WantedSigPerDev.append(WantedSigPerDev)\n",
    "    InterfPowsPerDev = np.zeros((M,J,N))\n",
    "    for m in range(M):\n",
    "        Interferers = [i for i in range(M) if i!=m]\n",
    "        Devs = np.arange(m*J,(m+1)*J)\n",
    "        #print(Interferers, Devs)\n",
    "        InterfPowGains = PathGainsTot[np.ix_(Interferers, Devs)]\n",
    "        InterfPowsPerDev[m,] = np.sum(InterfPowGains, axis = 0)\n",
    "    alltime_InterfPowsPerDev.append(InterfPowsPerDev)\n",
    "    SINRs = WantedSigPerDev/(InterfPowsPerDev + 1/gamma_0);\n",
    "    SINRsdB = 10*np.log10(SINRs)\n",
    "    all_SINRsdB[ts,:] = SINRsdB\n",
    "alltime_WantedSigPerDev = np.array(alltime_WantedSigPerDev)\n",
    "alltime_InterfPowsPerDev = np.array(alltime_InterfPowsPerDev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a13dd931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 30)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WantedSigPerDev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a65cdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.60083144457913\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a1, cdf1 = return_cdf(all_SINRsdB.flatten())\n",
    "plt.figure(figsize= [5,3])\n",
    "#plt.ylim(np.min(cdf2))\n",
    "plt.semilogy(a1, cdf1, label = r'$F(\\gamma)$')\n",
    "plt.grid()\n",
    "plt.xlabel('SINR(dB)')\n",
    "plt.ylabel('CDF(log scale)')\n",
    "plt.legend()\n",
    "print(np.mean(all_SINRsdB.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a82219d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 25, 30)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PathGainsTot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b0a0fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5, 30)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InterfPowGains.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "751dbc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.648262221259358\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alltime_SINRsdB_combined = []\n",
    "all_SINRslin = np.power(10, all_SINRsdB/10)\n",
    "for ts in range(all_SINRsdB.shape[0]):\n",
    "    vals = all_SINRslin[ts,:,:,:]\n",
    "    SINRS_combined = np.min(vals, axis = 2)\n",
    "    SINRsdB_combined = 10*np.log10(SINRS_combined)\n",
    "    alltime_SINRsdB_combined.append(SINRsdB_combined)\n",
    "alltime_SINRsdB_combined = np.array(alltime_SINRsdB_combined)\n",
    "\n",
    "a1, cdf1 = return_cdf(alltime_SINRsdB_combined.flatten())\n",
    "plt.figure(figsize= [5,3])\n",
    "#plt.ylim(np.min(cdf2))\n",
    "plt.semilogy(a1, cdf1, label = r'$F(\\gamma)$')\n",
    "plt.grid()\n",
    "plt.xlabel('SINR(dB)')\n",
    "plt.ylabel('CDF(log scale)')\n",
    "plt.legend()\n",
    "print(np.mean(alltime_SINRsdB_combined.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92cc0e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5, 5, 30)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_SINRsdB.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c839a4bf",
   "metadata": {},
   "source": [
    "### The below model needs to be integrated with DRL framework trained paralelly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d4e4a",
   "metadata": {},
   "source": [
    "##### prediction of SINR at t given 10 previous time slots #########\n",
    "####### 10000 x 5x 5 x 30, 10000 is time slots, first 5 denotes the sub networks, 2nd 5 denotes the devices of a sub network, \n",
    "####### 30 denotes the channel resources. \n",
    "\n",
    "\n",
    "#### preparing data for a sub-network ########\n",
    "######## each sub-network will have one LSTM layer getting trained in parallel with the main DRL agent ########\n",
    "######### i.e., the LSTM layer is trained for a given example with a loss function and predicted SINR is given as the \n",
    "######### input to the DRL framework which is subsequently trained. This happens in an online fashion at every time-slot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa366cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## data for a sub-network \n",
    "lag = 10\n",
    "inp_data, out_data = [], []\n",
    "for i in range(M):\n",
    "    sinr_sub_nw = all_SINRsdB[:,0,:,:]\n",
    "    data_per_device = sinr_sub_nw[:,0,:]\n",
    "    for t in range(0, len(data_per_device)-lag):\n",
    "        inp_data.append(data_per_device[t:t+lag])\n",
    "        out_data.append(data_per_device[t+lag])\n",
    "\n",
    "    \n",
    "inp_data = np.array(inp_data)\n",
    "out_data = np.array(out_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cea5d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        \n",
    "        # Define the output layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        \n",
    "        # Initialize cell state with zeros\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93b6760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_no =47000\n",
    "inp_train_data = inp_data[0:samp_no]\n",
    "out_train_data = out_data[0:samp_no]\n",
    "inp_test_data = inp_data[samp_no:]\n",
    "out_test_data = out_data[samp_no:]\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "inp_train_data = torch.tensor(inp_train_data, dtype=torch.float32)\n",
    "out_train_data = torch.tensor(out_train_data, dtype=torch.float32)\n",
    "inp_test_data = torch.tensor(inp_test_data, dtype=torch.float32)\n",
    "out_test_data = torch.tensor(out_test_data, dtype=torch.float32)\n",
    "\n",
    "\n",
    "inp_test_data \n",
    "# Create a dataset and dataloader\n",
    "train_dataset = TensorDataset(inp_train_data, out_train_data)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "569dbfe4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [1/735], Loss: 314.3802\n",
      "Epoch [1/50], Step [2/735], Loss: 301.0830\n",
      "Epoch [1/50], Step [3/735], Loss: 311.3024\n",
      "Epoch [1/50], Step [4/735], Loss: 302.3984\n",
      "Epoch [1/50], Step [5/735], Loss: 284.6375\n",
      "Epoch [1/50], Step [6/735], Loss: 258.8868\n",
      "Epoch [1/50], Step [7/735], Loss: 259.7709\n",
      "Epoch [1/50], Step [8/735], Loss: 233.0034\n",
      "Epoch [1/50], Step [9/735], Loss: 244.7453\n",
      "Epoch [1/50], Step [10/735], Loss: 264.0462\n",
      "Epoch [1/50], Step [11/735], Loss: 277.3830\n",
      "Epoch [1/50], Step [12/735], Loss: 269.6984\n",
      "Epoch [1/50], Step [13/735], Loss: 265.8924\n",
      "Epoch [1/50], Step [14/735], Loss: 241.4547\n",
      "Epoch [1/50], Step [15/735], Loss: 227.8146\n",
      "Epoch [1/50], Step [16/735], Loss: 236.6425\n",
      "Epoch [1/50], Step [17/735], Loss: 231.2774\n",
      "Epoch [1/50], Step [18/735], Loss: 227.5019\n",
      "Epoch [1/50], Step [19/735], Loss: 230.1498\n",
      "Epoch [1/50], Step [20/735], Loss: 263.5909\n",
      "Epoch [1/50], Step [21/735], Loss: 251.4523\n",
      "Epoch [1/50], Step [22/735], Loss: 221.5935\n",
      "Epoch [1/50], Step [23/735], Loss: 229.2370\n",
      "Epoch [1/50], Step [24/735], Loss: 210.3117\n",
      "Epoch [1/50], Step [25/735], Loss: 253.1392\n",
      "Epoch [1/50], Step [26/735], Loss: 231.8662\n",
      "Epoch [1/50], Step [27/735], Loss: 219.7478\n",
      "Epoch [1/50], Step [28/735], Loss: 210.2768\n",
      "Epoch [1/50], Step [29/735], Loss: 182.5179\n",
      "Epoch [1/50], Step [30/735], Loss: 183.9091\n",
      "Epoch [1/50], Step [31/735], Loss: 200.3027\n",
      "Epoch [1/50], Step [32/735], Loss: 191.1900\n",
      "Epoch [1/50], Step [33/735], Loss: 182.7053\n",
      "Epoch [1/50], Step [34/735], Loss: 184.1088\n",
      "Epoch [1/50], Step [35/735], Loss: 193.0891\n",
      "Epoch [1/50], Step [36/735], Loss: 202.3807\n",
      "Epoch [1/50], Step [37/735], Loss: 203.6472\n",
      "Epoch [1/50], Step [38/735], Loss: 203.5908\n",
      "Epoch [1/50], Step [39/735], Loss: 179.7107\n",
      "Epoch [1/50], Step [40/735], Loss: 188.5491\n",
      "Epoch [1/50], Step [41/735], Loss: 197.8058\n",
      "Epoch [1/50], Step [42/735], Loss: 180.5429\n",
      "Epoch [1/50], Step [43/735], Loss: 165.9506\n",
      "Epoch [1/50], Step [44/735], Loss: 165.4484\n",
      "Epoch [1/50], Step [45/735], Loss: 154.5495\n",
      "Epoch [1/50], Step [46/735], Loss: 158.2042\n",
      "Epoch [1/50], Step [47/735], Loss: 179.5981\n",
      "Epoch [1/50], Step [48/735], Loss: 171.3279\n",
      "Epoch [1/50], Step [49/735], Loss: 167.7204\n",
      "Epoch [1/50], Step [50/735], Loss: 160.5439\n",
      "Epoch [1/50], Step [51/735], Loss: 134.9713\n",
      "Epoch [1/50], Step [52/735], Loss: 159.0833\n",
      "Epoch [1/50], Step [53/735], Loss: 150.7380\n",
      "Epoch [1/50], Step [54/735], Loss: 131.6416\n",
      "Epoch [1/50], Step [55/735], Loss: 133.2579\n",
      "Epoch [1/50], Step [56/735], Loss: 137.2790\n",
      "Epoch [1/50], Step [57/735], Loss: 132.8784\n",
      "Epoch [1/50], Step [58/735], Loss: 137.2383\n",
      "Epoch [1/50], Step [59/735], Loss: 143.8534\n",
      "Epoch [1/50], Step [60/735], Loss: 125.8008\n",
      "Epoch [1/50], Step [61/735], Loss: 139.5631\n",
      "Epoch [1/50], Step [62/735], Loss: 118.7594\n",
      "Epoch [1/50], Step [63/735], Loss: 128.0175\n",
      "Epoch [1/50], Step [64/735], Loss: 122.2211\n",
      "Epoch [1/50], Step [65/735], Loss: 139.0296\n",
      "Epoch [1/50], Step [66/735], Loss: 113.5555\n",
      "Epoch [1/50], Step [67/735], Loss: 114.5556\n",
      "Epoch [1/50], Step [68/735], Loss: 126.1051\n",
      "Epoch [1/50], Step [69/735], Loss: 117.4710\n",
      "Epoch [1/50], Step [70/735], Loss: 105.2822\n",
      "Epoch [1/50], Step [71/735], Loss: 114.6476\n",
      "Epoch [1/50], Step [72/735], Loss: 115.0658\n",
      "Epoch [1/50], Step [73/735], Loss: 106.7519\n",
      "Epoch [1/50], Step [74/735], Loss: 113.3859\n",
      "Epoch [1/50], Step [75/735], Loss: 109.2215\n",
      "Epoch [1/50], Step [76/735], Loss: 109.5934\n",
      "Epoch [1/50], Step [77/735], Loss: 92.0956\n",
      "Epoch [1/50], Step [78/735], Loss: 101.2438\n",
      "Epoch [1/50], Step [79/735], Loss: 102.3457\n",
      "Epoch [1/50], Step [80/735], Loss: 107.7547\n",
      "Epoch [1/50], Step [81/735], Loss: 90.0779\n",
      "Epoch [1/50], Step [82/735], Loss: 78.4197\n",
      "Epoch [1/50], Step [83/735], Loss: 89.7708\n",
      "Epoch [1/50], Step [84/735], Loss: 92.6855\n",
      "Epoch [1/50], Step [85/735], Loss: 85.0671\n",
      "Epoch [1/50], Step [86/735], Loss: 81.2158\n",
      "Epoch [1/50], Step [87/735], Loss: 79.4122\n",
      "Epoch [1/50], Step [88/735], Loss: 81.8766\n",
      "Epoch [1/50], Step [89/735], Loss: 81.7236\n",
      "Epoch [1/50], Step [90/735], Loss: 85.2953\n",
      "Epoch [1/50], Step [91/735], Loss: 72.2425\n",
      "Epoch [1/50], Step [92/735], Loss: 75.7004\n",
      "Epoch [1/50], Step [93/735], Loss: 78.1022\n",
      "Epoch [1/50], Step [94/735], Loss: 73.6077\n",
      "Epoch [1/50], Step [95/735], Loss: 73.2267\n",
      "Epoch [1/50], Step [96/735], Loss: 73.0280\n",
      "Epoch [1/50], Step [97/735], Loss: 71.7260\n",
      "Epoch [1/50], Step [98/735], Loss: 72.6286\n",
      "Epoch [1/50], Step [99/735], Loss: 66.1773\n",
      "Epoch [1/50], Step [100/735], Loss: 49.0076\n",
      "Epoch [1/50], Step [101/735], Loss: 53.9107\n",
      "Epoch [1/50], Step [102/735], Loss: 58.9532\n",
      "Epoch [1/50], Step [103/735], Loss: 62.4154\n",
      "Epoch [1/50], Step [104/735], Loss: 53.2579\n",
      "Epoch [1/50], Step [105/735], Loss: 54.5232\n",
      "Epoch [1/50], Step [106/735], Loss: 56.2526\n",
      "Epoch [1/50], Step [107/735], Loss: 60.2851\n",
      "Epoch [1/50], Step [108/735], Loss: 58.2569\n",
      "Epoch [1/50], Step [109/735], Loss: 62.0546\n",
      "Epoch [1/50], Step [110/735], Loss: 55.0483\n",
      "Epoch [1/50], Step [111/735], Loss: 54.6487\n",
      "Epoch [1/50], Step [112/735], Loss: 46.9219\n",
      "Epoch [1/50], Step [113/735], Loss: 61.4701\n",
      "Epoch [1/50], Step [114/735], Loss: 52.5586\n",
      "Epoch [1/50], Step [115/735], Loss: 52.8791\n",
      "Epoch [1/50], Step [116/735], Loss: 44.9596\n",
      "Epoch [1/50], Step [117/735], Loss: 44.2556\n",
      "Epoch [1/50], Step [118/735], Loss: 47.0792\n",
      "Epoch [1/50], Step [119/735], Loss: 41.3859\n",
      "Epoch [1/50], Step [120/735], Loss: 45.3670\n",
      "Epoch [1/50], Step [121/735], Loss: 42.0882\n",
      "Epoch [1/50], Step [122/735], Loss: 41.9255\n",
      "Epoch [1/50], Step [123/735], Loss: 36.5546\n",
      "Epoch [1/50], Step [124/735], Loss: 42.0994\n",
      "Epoch [1/50], Step [125/735], Loss: 43.0640\n",
      "Epoch [1/50], Step [126/735], Loss: 40.2557\n",
      "Epoch [1/50], Step [127/735], Loss: 33.3621\n",
      "Epoch [1/50], Step [128/735], Loss: 40.5541\n",
      "Epoch [1/50], Step [129/735], Loss: 38.5937\n",
      "Epoch [1/50], Step [130/735], Loss: 39.4907\n",
      "Epoch [1/50], Step [131/735], Loss: 43.2472\n",
      "Epoch [1/50], Step [132/735], Loss: 39.6816\n",
      "Epoch [1/50], Step [133/735], Loss: 34.1748\n",
      "Epoch [1/50], Step [134/735], Loss: 37.4122\n",
      "Epoch [1/50], Step [135/735], Loss: 38.2150\n",
      "Epoch [1/50], Step [136/735], Loss: 39.0173\n",
      "Epoch [1/50], Step [137/735], Loss: 28.8895\n",
      "Epoch [1/50], Step [138/735], Loss: 29.1421\n",
      "Epoch [1/50], Step [139/735], Loss: 33.5953\n",
      "Epoch [1/50], Step [140/735], Loss: 39.1002\n",
      "Epoch [1/50], Step [141/735], Loss: 29.3111\n",
      "Epoch [1/50], Step [142/735], Loss: 31.3280\n",
      "Epoch [1/50], Step [143/735], Loss: 24.1118\n",
      "Epoch [1/50], Step [144/735], Loss: 32.5242\n",
      "Epoch [1/50], Step [145/735], Loss: 26.3288\n",
      "Epoch [1/50], Step [146/735], Loss: 24.1857\n",
      "Epoch [1/50], Step [147/735], Loss: 27.4914\n",
      "Epoch [1/50], Step [148/735], Loss: 24.8960\n",
      "Epoch [1/50], Step [149/735], Loss: 26.1405\n",
      "Epoch [1/50], Step [150/735], Loss: 26.9743\n",
      "Epoch [1/50], Step [151/735], Loss: 21.9716\n",
      "Epoch [1/50], Step [152/735], Loss: 27.4463\n",
      "Epoch [1/50], Step [153/735], Loss: 24.7332\n",
      "Epoch [1/50], Step [154/735], Loss: 27.8216\n",
      "Epoch [1/50], Step [155/735], Loss: 18.1026\n",
      "Epoch [1/50], Step [156/735], Loss: 19.0646\n",
      "Epoch [1/50], Step [157/735], Loss: 28.6522\n",
      "Epoch [1/50], Step [158/735], Loss: 23.5951\n",
      "Epoch [1/50], Step [159/735], Loss: 26.1312\n",
      "Epoch [1/50], Step [160/735], Loss: 24.5188\n",
      "Epoch [1/50], Step [161/735], Loss: 25.1427\n",
      "Epoch [1/50], Step [162/735], Loss: 19.3834\n",
      "Epoch [1/50], Step [163/735], Loss: 16.3374\n",
      "Epoch [1/50], Step [164/735], Loss: 24.6815\n",
      "Epoch [1/50], Step [165/735], Loss: 21.5305\n",
      "Epoch [1/50], Step [166/735], Loss: 22.2449\n",
      "Epoch [1/50], Step [167/735], Loss: 18.5391\n",
      "Epoch [1/50], Step [168/735], Loss: 18.0629\n",
      "Epoch [1/50], Step [169/735], Loss: 22.4183\n",
      "Epoch [1/50], Step [170/735], Loss: 17.2952\n",
      "Epoch [1/50], Step [171/735], Loss: 19.9357\n",
      "Epoch [1/50], Step [172/735], Loss: 18.8887\n",
      "Epoch [1/50], Step [173/735], Loss: 20.3970\n",
      "Epoch [1/50], Step [174/735], Loss: 16.8159\n",
      "Epoch [1/50], Step [175/735], Loss: 23.1324\n",
      "Epoch [1/50], Step [176/735], Loss: 22.0012\n",
      "Epoch [1/50], Step [177/735], Loss: 21.3891\n",
      "Epoch [1/50], Step [178/735], Loss: 19.8593\n",
      "Epoch [1/50], Step [179/735], Loss: 19.1802\n",
      "Epoch [1/50], Step [180/735], Loss: 12.9574\n",
      "Epoch [1/50], Step [181/735], Loss: 19.2553\n",
      "Epoch [1/50], Step [182/735], Loss: 17.2880\n",
      "Epoch [1/50], Step [183/735], Loss: 18.0908\n",
      "Epoch [1/50], Step [184/735], Loss: 20.4752\n",
      "Epoch [1/50], Step [185/735], Loss: 15.2146\n",
      "Epoch [1/50], Step [186/735], Loss: 17.4403\n",
      "Epoch [1/50], Step [187/735], Loss: 13.7544\n",
      "Epoch [1/50], Step [188/735], Loss: 14.1735\n",
      "Epoch [1/50], Step [189/735], Loss: 17.0935\n",
      "Epoch [1/50], Step [190/735], Loss: 14.4051\n",
      "Epoch [1/50], Step [191/735], Loss: 22.3698\n",
      "Epoch [1/50], Step [192/735], Loss: 14.0504\n",
      "Epoch [1/50], Step [193/735], Loss: 15.1383\n",
      "Epoch [1/50], Step [194/735], Loss: 13.5933\n",
      "Epoch [1/50], Step [195/735], Loss: 13.9964\n",
      "Epoch [1/50], Step [196/735], Loss: 15.5843\n",
      "Epoch [1/50], Step [197/735], Loss: 15.5139\n",
      "Epoch [1/50], Step [198/735], Loss: 16.0870\n",
      "Epoch [1/50], Step [199/735], Loss: 14.3535\n",
      "Epoch [1/50], Step [200/735], Loss: 12.4396\n",
      "Epoch [1/50], Step [201/735], Loss: 13.7128\n",
      "Epoch [1/50], Step [202/735], Loss: 13.8752\n",
      "Epoch [1/50], Step [203/735], Loss: 13.9664\n",
      "Epoch [1/50], Step [204/735], Loss: 12.3660\n",
      "Epoch [1/50], Step [205/735], Loss: 14.0642\n",
      "Epoch [1/50], Step [206/735], Loss: 14.1071\n",
      "Epoch [1/50], Step [207/735], Loss: 12.5740\n",
      "Epoch [1/50], Step [208/735], Loss: 12.8229\n",
      "Epoch [1/50], Step [209/735], Loss: 14.4049\n",
      "Epoch [1/50], Step [210/735], Loss: 13.4058\n",
      "Epoch [1/50], Step [211/735], Loss: 10.9340\n",
      "Epoch [1/50], Step [212/735], Loss: 13.3443\n",
      "Epoch [1/50], Step [213/735], Loss: 14.7960\n",
      "Epoch [1/50], Step [214/735], Loss: 13.4917\n",
      "Epoch [1/50], Step [215/735], Loss: 12.0287\n",
      "Epoch [1/50], Step [216/735], Loss: 11.3796\n",
      "Epoch [1/50], Step [217/735], Loss: 16.7623\n",
      "Epoch [1/50], Step [218/735], Loss: 12.4576\n",
      "Epoch [1/50], Step [219/735], Loss: 13.8228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [220/735], Loss: 14.7805\n",
      "Epoch [1/50], Step [221/735], Loss: 11.6100\n",
      "Epoch [1/50], Step [222/735], Loss: 10.8251\n",
      "Epoch [1/50], Step [223/735], Loss: 12.1240\n",
      "Epoch [1/50], Step [224/735], Loss: 11.5738\n",
      "Epoch [1/50], Step [225/735], Loss: 10.1568\n",
      "Epoch [1/50], Step [226/735], Loss: 10.5603\n",
      "Epoch [1/50], Step [227/735], Loss: 8.1919\n",
      "Epoch [1/50], Step [228/735], Loss: 9.8002\n",
      "Epoch [1/50], Step [229/735], Loss: 13.1723\n",
      "Epoch [1/50], Step [230/735], Loss: 9.4726\n",
      "Epoch [1/50], Step [231/735], Loss: 13.4858\n",
      "Epoch [1/50], Step [232/735], Loss: 10.6088\n",
      "Epoch [1/50], Step [233/735], Loss: 12.8690\n",
      "Epoch [1/50], Step [234/735], Loss: 11.3914\n",
      "Epoch [1/50], Step [235/735], Loss: 11.3807\n",
      "Epoch [1/50], Step [236/735], Loss: 9.4263\n",
      "Epoch [1/50], Step [237/735], Loss: 9.1534\n",
      "Epoch [1/50], Step [238/735], Loss: 9.0184\n",
      "Epoch [1/50], Step [239/735], Loss: 10.9869\n",
      "Epoch [1/50], Step [240/735], Loss: 9.0527\n",
      "Epoch [1/50], Step [241/735], Loss: 13.3038\n",
      "Epoch [1/50], Step [242/735], Loss: 8.0220\n",
      "Epoch [1/50], Step [243/735], Loss: 9.2612\n",
      "Epoch [1/50], Step [244/735], Loss: 7.9616\n",
      "Epoch [1/50], Step [245/735], Loss: 11.6008\n",
      "Epoch [1/50], Step [246/735], Loss: 7.9720\n",
      "Epoch [1/50], Step [247/735], Loss: 9.4721\n",
      "Epoch [1/50], Step [248/735], Loss: 10.2669\n",
      "Epoch [1/50], Step [249/735], Loss: 11.0764\n",
      "Epoch [1/50], Step [250/735], Loss: 10.8645\n",
      "Epoch [1/50], Step [251/735], Loss: 9.2164\n",
      "Epoch [1/50], Step [252/735], Loss: 8.1458\n",
      "Epoch [1/50], Step [253/735], Loss: 9.8972\n",
      "Epoch [1/50], Step [254/735], Loss: 9.3747\n",
      "Epoch [1/50], Step [255/735], Loss: 9.0262\n",
      "Epoch [1/50], Step [256/735], Loss: 8.4649\n",
      "Epoch [1/50], Step [257/735], Loss: 8.0537\n",
      "Epoch [1/50], Step [258/735], Loss: 9.4785\n",
      "Epoch [1/50], Step [259/735], Loss: 9.3146\n",
      "Epoch [1/50], Step [260/735], Loss: 9.5373\n",
      "Epoch [1/50], Step [261/735], Loss: 7.9644\n",
      "Epoch [1/50], Step [262/735], Loss: 8.7322\n",
      "Epoch [1/50], Step [263/735], Loss: 9.1360\n",
      "Epoch [1/50], Step [264/735], Loss: 7.0177\n",
      "Epoch [1/50], Step [265/735], Loss: 7.4204\n",
      "Epoch [1/50], Step [266/735], Loss: 6.5702\n",
      "Epoch [1/50], Step [267/735], Loss: 7.9737\n",
      "Epoch [1/50], Step [268/735], Loss: 7.1337\n",
      "Epoch [1/50], Step [269/735], Loss: 6.9101\n",
      "Epoch [1/50], Step [270/735], Loss: 7.3881\n",
      "Epoch [1/50], Step [271/735], Loss: 7.5273\n",
      "Epoch [1/50], Step [272/735], Loss: 9.5494\n",
      "Epoch [1/50], Step [273/735], Loss: 7.5487\n",
      "Epoch [1/50], Step [274/735], Loss: 6.3706\n",
      "Epoch [1/50], Step [275/735], Loss: 7.6483\n",
      "Epoch [1/50], Step [276/735], Loss: 7.1963\n",
      "Epoch [1/50], Step [277/735], Loss: 6.5744\n",
      "Epoch [1/50], Step [278/735], Loss: 6.6688\n",
      "Epoch [1/50], Step [279/735], Loss: 6.9587\n",
      "Epoch [1/50], Step [280/735], Loss: 7.6074\n",
      "Epoch [1/50], Step [281/735], Loss: 7.3553\n",
      "Epoch [1/50], Step [282/735], Loss: 7.6720\n",
      "Epoch [1/50], Step [283/735], Loss: 6.0688\n",
      "Epoch [1/50], Step [284/735], Loss: 6.7070\n",
      "Epoch [1/50], Step [285/735], Loss: 9.1218\n",
      "Epoch [1/50], Step [286/735], Loss: 7.3658\n",
      "Epoch [1/50], Step [287/735], Loss: 6.5891\n",
      "Epoch [1/50], Step [288/735], Loss: 6.2329\n",
      "Epoch [1/50], Step [289/735], Loss: 6.6708\n",
      "Epoch [1/50], Step [290/735], Loss: 6.4665\n",
      "Epoch [1/50], Step [291/735], Loss: 8.7510\n",
      "Epoch [1/50], Step [292/735], Loss: 9.2817\n",
      "Epoch [1/50], Step [293/735], Loss: 7.1012\n",
      "Epoch [1/50], Step [294/735], Loss: 8.2755\n",
      "Epoch [1/50], Step [295/735], Loss: 5.8082\n",
      "Epoch [1/50], Step [296/735], Loss: 6.2926\n",
      "Epoch [1/50], Step [297/735], Loss: 6.0705\n",
      "Epoch [1/50], Step [298/735], Loss: 7.9283\n",
      "Epoch [1/50], Step [299/735], Loss: 7.1678\n",
      "Epoch [1/50], Step [300/735], Loss: 5.4458\n",
      "Epoch [1/50], Step [301/735], Loss: 4.4476\n",
      "Epoch [1/50], Step [302/735], Loss: 5.8110\n",
      "Epoch [1/50], Step [303/735], Loss: 6.2285\n",
      "Epoch [1/50], Step [304/735], Loss: 6.6790\n",
      "Epoch [1/50], Step [305/735], Loss: 6.0765\n",
      "Epoch [1/50], Step [306/735], Loss: 9.1210\n",
      "Epoch [1/50], Step [307/735], Loss: 7.1257\n",
      "Epoch [1/50], Step [308/735], Loss: 6.2135\n",
      "Epoch [1/50], Step [309/735], Loss: 7.3275\n",
      "Epoch [1/50], Step [310/735], Loss: 5.7884\n",
      "Epoch [1/50], Step [311/735], Loss: 7.0093\n",
      "Epoch [1/50], Step [312/735], Loss: 7.5833\n",
      "Epoch [1/50], Step [313/735], Loss: 6.8719\n",
      "Epoch [1/50], Step [314/735], Loss: 6.0109\n",
      "Epoch [1/50], Step [315/735], Loss: 5.2988\n",
      "Epoch [1/50], Step [316/735], Loss: 6.0452\n",
      "Epoch [1/50], Step [317/735], Loss: 5.9274\n",
      "Epoch [1/50], Step [318/735], Loss: 7.4525\n",
      "Epoch [1/50], Step [319/735], Loss: 6.9199\n",
      "Epoch [1/50], Step [320/735], Loss: 7.6152\n",
      "Epoch [1/50], Step [321/735], Loss: 7.1728\n",
      "Epoch [1/50], Step [322/735], Loss: 5.6762\n",
      "Epoch [1/50], Step [323/735], Loss: 5.3468\n",
      "Epoch [1/50], Step [324/735], Loss: 5.9621\n",
      "Epoch [1/50], Step [325/735], Loss: 5.7950\n",
      "Epoch [1/50], Step [326/735], Loss: 6.4042\n",
      "Epoch [1/50], Step [327/735], Loss: 7.0030\n",
      "Epoch [1/50], Step [328/735], Loss: 6.4199\n",
      "Epoch [1/50], Step [329/735], Loss: 5.6494\n",
      "Epoch [1/50], Step [330/735], Loss: 6.4045\n",
      "Epoch [1/50], Step [331/735], Loss: 5.8156\n",
      "Epoch [1/50], Step [332/735], Loss: 6.1205\n",
      "Epoch [1/50], Step [333/735], Loss: 5.0286\n",
      "Epoch [1/50], Step [334/735], Loss: 5.1843\n",
      "Epoch [1/50], Step [335/735], Loss: 5.6252\n",
      "Epoch [1/50], Step [336/735], Loss: 5.4831\n",
      "Epoch [1/50], Step [337/735], Loss: 4.7868\n",
      "Epoch [1/50], Step [338/735], Loss: 6.5078\n",
      "Epoch [1/50], Step [339/735], Loss: 5.4922\n",
      "Epoch [1/50], Step [340/735], Loss: 5.7861\n",
      "Epoch [1/50], Step [341/735], Loss: 4.7027\n",
      "Epoch [1/50], Step [342/735], Loss: 6.3953\n",
      "Epoch [1/50], Step [343/735], Loss: 5.1078\n",
      "Epoch [1/50], Step [344/735], Loss: 5.7989\n",
      "Epoch [1/50], Step [345/735], Loss: 5.2713\n",
      "Epoch [1/50], Step [346/735], Loss: 5.8936\n",
      "Epoch [1/50], Step [347/735], Loss: 5.8112\n",
      "Epoch [1/50], Step [348/735], Loss: 4.5683\n",
      "Epoch [1/50], Step [349/735], Loss: 5.5034\n",
      "Epoch [1/50], Step [350/735], Loss: 5.3128\n",
      "Epoch [1/50], Step [351/735], Loss: 5.7910\n",
      "Epoch [1/50], Step [352/735], Loss: 6.2816\n",
      "Epoch [1/50], Step [353/735], Loss: 4.7587\n",
      "Epoch [1/50], Step [354/735], Loss: 5.9790\n",
      "Epoch [1/50], Step [355/735], Loss: 4.8591\n",
      "Epoch [1/50], Step [356/735], Loss: 4.6829\n",
      "Epoch [1/50], Step [357/735], Loss: 5.5458\n",
      "Epoch [1/50], Step [358/735], Loss: 6.2624\n",
      "Epoch [1/50], Step [359/735], Loss: 4.1128\n",
      "Epoch [1/50], Step [360/735], Loss: 4.6909\n",
      "Epoch [1/50], Step [361/735], Loss: 6.3542\n",
      "Epoch [1/50], Step [362/735], Loss: 5.2676\n",
      "Epoch [1/50], Step [363/735], Loss: 4.7682\n",
      "Epoch [1/50], Step [364/735], Loss: 5.4179\n",
      "Epoch [1/50], Step [365/735], Loss: 5.4036\n",
      "Epoch [1/50], Step [366/735], Loss: 5.3844\n",
      "Epoch [1/50], Step [367/735], Loss: 4.2703\n",
      "Epoch [1/50], Step [368/735], Loss: 4.2136\n",
      "Epoch [1/50], Step [369/735], Loss: 4.2783\n",
      "Epoch [1/50], Step [370/735], Loss: 4.1677\n",
      "Epoch [1/50], Step [371/735], Loss: 5.0889\n",
      "Epoch [1/50], Step [372/735], Loss: 4.9275\n",
      "Epoch [1/50], Step [373/735], Loss: 4.8307\n",
      "Epoch [1/50], Step [374/735], Loss: 4.0835\n",
      "Epoch [1/50], Step [375/735], Loss: 5.5049\n",
      "Epoch [1/50], Step [376/735], Loss: 4.5384\n",
      "Epoch [1/50], Step [377/735], Loss: 4.6000\n",
      "Epoch [1/50], Step [378/735], Loss: 4.8255\n",
      "Epoch [1/50], Step [379/735], Loss: 4.8054\n",
      "Epoch [1/50], Step [380/735], Loss: 4.0730\n",
      "Epoch [1/50], Step [381/735], Loss: 5.2096\n",
      "Epoch [1/50], Step [382/735], Loss: 4.6426\n",
      "Epoch [1/50], Step [383/735], Loss: 3.6473\n",
      "Epoch [1/50], Step [384/735], Loss: 4.1731\n",
      "Epoch [1/50], Step [385/735], Loss: 4.3048\n",
      "Epoch [1/50], Step [386/735], Loss: 4.2112\n",
      "Epoch [1/50], Step [387/735], Loss: 3.3823\n",
      "Epoch [1/50], Step [388/735], Loss: 4.5915\n",
      "Epoch [1/50], Step [389/735], Loss: 4.9606\n",
      "Epoch [1/50], Step [390/735], Loss: 3.5540\n",
      "Epoch [1/50], Step [391/735], Loss: 3.8310\n",
      "Epoch [1/50], Step [392/735], Loss: 4.7404\n",
      "Epoch [1/50], Step [393/735], Loss: 4.3867\n",
      "Epoch [1/50], Step [394/735], Loss: 3.6974\n",
      "Epoch [1/50], Step [395/735], Loss: 4.2776\n",
      "Epoch [1/50], Step [396/735], Loss: 4.5193\n",
      "Epoch [1/50], Step [397/735], Loss: 4.6485\n",
      "Epoch [1/50], Step [398/735], Loss: 5.4249\n",
      "Epoch [1/50], Step [399/735], Loss: 4.0351\n",
      "Epoch [1/50], Step [400/735], Loss: 4.0450\n",
      "Epoch [1/50], Step [401/735], Loss: 4.3745\n",
      "Epoch [1/50], Step [402/735], Loss: 3.9557\n",
      "Epoch [1/50], Step [403/735], Loss: 4.7157\n",
      "Epoch [1/50], Step [404/735], Loss: 3.8507\n",
      "Epoch [1/50], Step [405/735], Loss: 4.2624\n",
      "Epoch [1/50], Step [406/735], Loss: 5.5580\n",
      "Epoch [1/50], Step [407/735], Loss: 5.1544\n",
      "Epoch [1/50], Step [408/735], Loss: 4.1353\n",
      "Epoch [1/50], Step [409/735], Loss: 3.5342\n",
      "Epoch [1/50], Step [410/735], Loss: 3.6203\n",
      "Epoch [1/50], Step [411/735], Loss: 4.7947\n",
      "Epoch [1/50], Step [412/735], Loss: 4.3606\n",
      "Epoch [1/50], Step [413/735], Loss: 3.6607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [414/735], Loss: 3.8912\n",
      "Epoch [1/50], Step [415/735], Loss: 4.2364\n",
      "Epoch [1/50], Step [416/735], Loss: 4.1322\n",
      "Epoch [1/50], Step [417/735], Loss: 4.5323\n",
      "Epoch [1/50], Step [418/735], Loss: 3.5740\n",
      "Epoch [1/50], Step [419/735], Loss: 4.4887\n",
      "Epoch [1/50], Step [420/735], Loss: 3.8216\n",
      "Epoch [1/50], Step [421/735], Loss: 3.3723\n",
      "Epoch [1/50], Step [422/735], Loss: 3.6983\n",
      "Epoch [1/50], Step [423/735], Loss: 4.3280\n",
      "Epoch [1/50], Step [424/735], Loss: 4.3186\n",
      "Epoch [1/50], Step [425/735], Loss: 4.0180\n",
      "Epoch [1/50], Step [426/735], Loss: 3.7056\n",
      "Epoch [1/50], Step [427/735], Loss: 4.0623\n",
      "Epoch [1/50], Step [428/735], Loss: 3.7246\n",
      "Epoch [1/50], Step [429/735], Loss: 3.7787\n",
      "Epoch [1/50], Step [430/735], Loss: 4.0945\n",
      "Epoch [1/50], Step [431/735], Loss: 3.0689\n",
      "Epoch [1/50], Step [432/735], Loss: 3.9496\n",
      "Epoch [1/50], Step [433/735], Loss: 4.3624\n",
      "Epoch [1/50], Step [434/735], Loss: 4.6270\n",
      "Epoch [1/50], Step [435/735], Loss: 4.2225\n",
      "Epoch [1/50], Step [436/735], Loss: 3.4333\n",
      "Epoch [1/50], Step [437/735], Loss: 3.6336\n",
      "Epoch [1/50], Step [438/735], Loss: 2.9021\n",
      "Epoch [1/50], Step [439/735], Loss: 3.0856\n",
      "Epoch [1/50], Step [440/735], Loss: 4.3580\n",
      "Epoch [1/50], Step [441/735], Loss: 3.5851\n",
      "Epoch [1/50], Step [442/735], Loss: 2.7746\n",
      "Epoch [1/50], Step [443/735], Loss: 3.1847\n",
      "Epoch [1/50], Step [444/735], Loss: 4.2537\n",
      "Epoch [1/50], Step [445/735], Loss: 4.1840\n",
      "Epoch [1/50], Step [446/735], Loss: 3.7893\n",
      "Epoch [1/50], Step [447/735], Loss: 3.5773\n",
      "Epoch [1/50], Step [448/735], Loss: 3.7447\n",
      "Epoch [1/50], Step [449/735], Loss: 4.1908\n",
      "Epoch [1/50], Step [450/735], Loss: 3.2823\n",
      "Epoch [1/50], Step [451/735], Loss: 3.4390\n",
      "Epoch [1/50], Step [452/735], Loss: 4.8322\n",
      "Epoch [1/50], Step [453/735], Loss: 3.1922\n",
      "Epoch [1/50], Step [454/735], Loss: 3.5292\n",
      "Epoch [1/50], Step [455/735], Loss: 3.2208\n",
      "Epoch [1/50], Step [456/735], Loss: 3.5789\n",
      "Epoch [1/50], Step [457/735], Loss: 2.9748\n",
      "Epoch [1/50], Step [458/735], Loss: 3.8464\n",
      "Epoch [1/50], Step [459/735], Loss: 3.3272\n",
      "Epoch [1/50], Step [460/735], Loss: 3.4327\n",
      "Epoch [1/50], Step [461/735], Loss: 3.3168\n",
      "Epoch [1/50], Step [462/735], Loss: 2.9668\n",
      "Epoch [1/50], Step [463/735], Loss: 3.4527\n",
      "Epoch [1/50], Step [464/735], Loss: 2.9687\n",
      "Epoch [1/50], Step [465/735], Loss: 3.2280\n",
      "Epoch [1/50], Step [466/735], Loss: 4.4990\n",
      "Epoch [1/50], Step [467/735], Loss: 3.4937\n",
      "Epoch [1/50], Step [468/735], Loss: 4.0739\n",
      "Epoch [1/50], Step [469/735], Loss: 4.3348\n",
      "Epoch [1/50], Step [470/735], Loss: 5.0966\n",
      "Epoch [1/50], Step [471/735], Loss: 3.6588\n",
      "Epoch [1/50], Step [472/735], Loss: 3.8641\n",
      "Epoch [1/50], Step [473/735], Loss: 6.2841\n",
      "Epoch [1/50], Step [474/735], Loss: 2.7661\n",
      "Epoch [1/50], Step [475/735], Loss: 3.3354\n",
      "Epoch [1/50], Step [476/735], Loss: 4.3039\n",
      "Epoch [1/50], Step [477/735], Loss: 3.5856\n",
      "Epoch [1/50], Step [478/735], Loss: 3.5310\n",
      "Epoch [1/50], Step [479/735], Loss: 4.5208\n",
      "Epoch [1/50], Step [480/735], Loss: 3.6738\n",
      "Epoch [1/50], Step [481/735], Loss: 2.8348\n",
      "Epoch [1/50], Step [482/735], Loss: 3.2359\n",
      "Epoch [1/50], Step [483/735], Loss: 2.9023\n",
      "Epoch [1/50], Step [484/735], Loss: 3.3618\n",
      "Epoch [1/50], Step [485/735], Loss: 2.9302\n",
      "Epoch [1/50], Step [486/735], Loss: 4.5636\n",
      "Epoch [1/50], Step [487/735], Loss: 3.1964\n",
      "Epoch [1/50], Step [488/735], Loss: 3.7462\n",
      "Epoch [1/50], Step [489/735], Loss: 3.0728\n",
      "Epoch [1/50], Step [490/735], Loss: 2.2735\n",
      "Epoch [1/50], Step [491/735], Loss: 2.3814\n",
      "Epoch [1/50], Step [492/735], Loss: 2.9401\n",
      "Epoch [1/50], Step [493/735], Loss: 3.2108\n",
      "Epoch [1/50], Step [494/735], Loss: 2.4415\n",
      "Epoch [1/50], Step [495/735], Loss: 5.3531\n",
      "Epoch [1/50], Step [496/735], Loss: 4.1326\n",
      "Epoch [1/50], Step [497/735], Loss: 2.5654\n",
      "Epoch [1/50], Step [498/735], Loss: 3.6050\n",
      "Epoch [1/50], Step [499/735], Loss: 2.8462\n",
      "Epoch [1/50], Step [500/735], Loss: 3.0748\n",
      "Epoch [1/50], Step [501/735], Loss: 2.3565\n",
      "Epoch [1/50], Step [502/735], Loss: 3.3199\n",
      "Epoch [1/50], Step [503/735], Loss: 2.7530\n",
      "Epoch [1/50], Step [504/735], Loss: 3.3869\n",
      "Epoch [1/50], Step [505/735], Loss: 2.8398\n",
      "Epoch [1/50], Step [506/735], Loss: 2.8658\n",
      "Epoch [1/50], Step [507/735], Loss: 2.3182\n",
      "Epoch [1/50], Step [508/735], Loss: 3.2273\n",
      "Epoch [1/50], Step [509/735], Loss: 2.2227\n",
      "Epoch [1/50], Step [510/735], Loss: 3.0443\n",
      "Epoch [1/50], Step [511/735], Loss: 2.6103\n",
      "Epoch [1/50], Step [512/735], Loss: 3.1310\n",
      "Epoch [1/50], Step [513/735], Loss: 3.3303\n",
      "Epoch [1/50], Step [514/735], Loss: 2.7708\n",
      "Epoch [1/50], Step [515/735], Loss: 2.7004\n",
      "Epoch [1/50], Step [516/735], Loss: 2.9403\n",
      "Epoch [1/50], Step [517/735], Loss: 2.3358\n",
      "Epoch [1/50], Step [518/735], Loss: 2.7310\n",
      "Epoch [1/50], Step [519/735], Loss: 2.6196\n",
      "Epoch [1/50], Step [520/735], Loss: 1.9869\n",
      "Epoch [1/50], Step [521/735], Loss: 2.8062\n",
      "Epoch [1/50], Step [522/735], Loss: 4.1444\n",
      "Epoch [1/50], Step [523/735], Loss: 2.8154\n",
      "Epoch [1/50], Step [524/735], Loss: 2.4310\n",
      "Epoch [1/50], Step [525/735], Loss: 1.9954\n",
      "Epoch [1/50], Step [526/735], Loss: 3.2894\n",
      "Epoch [1/50], Step [527/735], Loss: 3.2949\n",
      "Epoch [1/50], Step [528/735], Loss: 2.8795\n",
      "Epoch [1/50], Step [529/735], Loss: 2.0947\n",
      "Epoch [1/50], Step [530/735], Loss: 2.4329\n",
      "Epoch [1/50], Step [531/735], Loss: 2.7717\n",
      "Epoch [1/50], Step [532/735], Loss: 2.3508\n",
      "Epoch [1/50], Step [533/735], Loss: 1.9062\n",
      "Epoch [1/50], Step [534/735], Loss: 3.6588\n",
      "Epoch [1/50], Step [535/735], Loss: 2.7112\n",
      "Epoch [1/50], Step [536/735], Loss: 2.6839\n",
      "Epoch [1/50], Step [537/735], Loss: 3.2130\n",
      "Epoch [1/50], Step [538/735], Loss: 2.6623\n",
      "Epoch [1/50], Step [539/735], Loss: 2.8916\n",
      "Epoch [1/50], Step [540/735], Loss: 2.2744\n",
      "Epoch [1/50], Step [541/735], Loss: 2.8701\n",
      "Epoch [1/50], Step [542/735], Loss: 2.1114\n",
      "Epoch [1/50], Step [543/735], Loss: 2.8776\n",
      "Epoch [1/50], Step [544/735], Loss: 2.5989\n",
      "Epoch [1/50], Step [545/735], Loss: 2.4643\n",
      "Epoch [1/50], Step [546/735], Loss: 3.1448\n",
      "Epoch [1/50], Step [547/735], Loss: 2.5979\n",
      "Epoch [1/50], Step [548/735], Loss: 2.7491\n",
      "Epoch [1/50], Step [549/735], Loss: 2.6781\n",
      "Epoch [1/50], Step [550/735], Loss: 3.1747\n",
      "Epoch [1/50], Step [551/735], Loss: 2.3864\n",
      "Epoch [1/50], Step [552/735], Loss: 3.0188\n",
      "Epoch [1/50], Step [553/735], Loss: 2.1457\n",
      "Epoch [1/50], Step [554/735], Loss: 2.1963\n",
      "Epoch [1/50], Step [555/735], Loss: 3.8180\n",
      "Epoch [1/50], Step [556/735], Loss: 2.4262\n",
      "Epoch [1/50], Step [557/735], Loss: 2.9007\n",
      "Epoch [1/50], Step [558/735], Loss: 2.6689\n",
      "Epoch [1/50], Step [559/735], Loss: 2.3079\n",
      "Epoch [1/50], Step [560/735], Loss: 2.2193\n",
      "Epoch [1/50], Step [561/735], Loss: 3.4075\n",
      "Epoch [1/50], Step [562/735], Loss: 2.8891\n",
      "Epoch [1/50], Step [563/735], Loss: 2.1620\n",
      "Epoch [1/50], Step [564/735], Loss: 2.4659\n",
      "Epoch [1/50], Step [565/735], Loss: 2.4647\n",
      "Epoch [1/50], Step [566/735], Loss: 2.1354\n",
      "Epoch [1/50], Step [567/735], Loss: 2.0834\n",
      "Epoch [1/50], Step [568/735], Loss: 3.3417\n",
      "Epoch [1/50], Step [569/735], Loss: 2.2141\n",
      "Epoch [1/50], Step [570/735], Loss: 2.8637\n",
      "Epoch [1/50], Step [571/735], Loss: 2.0408\n",
      "Epoch [1/50], Step [572/735], Loss: 2.6792\n",
      "Epoch [1/50], Step [573/735], Loss: 2.4597\n",
      "Epoch [1/50], Step [574/735], Loss: 2.3736\n",
      "Epoch [1/50], Step [575/735], Loss: 2.0904\n",
      "Epoch [1/50], Step [576/735], Loss: 2.2810\n",
      "Epoch [1/50], Step [577/735], Loss: 1.8955\n",
      "Epoch [1/50], Step [578/735], Loss: 2.4059\n",
      "Epoch [1/50], Step [579/735], Loss: 1.9865\n",
      "Epoch [1/50], Step [580/735], Loss: 3.0787\n",
      "Epoch [1/50], Step [581/735], Loss: 2.2396\n",
      "Epoch [1/50], Step [582/735], Loss: 2.0748\n",
      "Epoch [1/50], Step [583/735], Loss: 1.9657\n",
      "Epoch [1/50], Step [584/735], Loss: 1.8929\n",
      "Epoch [1/50], Step [585/735], Loss: 2.4810\n",
      "Epoch [1/50], Step [586/735], Loss: 2.5531\n",
      "Epoch [1/50], Step [587/735], Loss: 2.0242\n",
      "Epoch [1/50], Step [588/735], Loss: 1.8380\n",
      "Epoch [1/50], Step [589/735], Loss: 1.9054\n",
      "Epoch [1/50], Step [590/735], Loss: 2.2686\n",
      "Epoch [1/50], Step [591/735], Loss: 2.2760\n",
      "Epoch [1/50], Step [592/735], Loss: 2.1218\n",
      "Epoch [1/50], Step [593/735], Loss: 2.2963\n",
      "Epoch [1/50], Step [594/735], Loss: 1.7360\n",
      "Epoch [1/50], Step [595/735], Loss: 1.9166\n",
      "Epoch [1/50], Step [596/735], Loss: 2.1666\n",
      "Epoch [1/50], Step [597/735], Loss: 2.0967\n",
      "Epoch [1/50], Step [598/735], Loss: 2.8383\n",
      "Epoch [1/50], Step [599/735], Loss: 2.2411\n",
      "Epoch [1/50], Step [600/735], Loss: 1.9409\n",
      "Epoch [1/50], Step [601/735], Loss: 2.1860\n",
      "Epoch [1/50], Step [602/735], Loss: 1.2745\n",
      "Epoch [1/50], Step [603/735], Loss: 2.2721\n",
      "Epoch [1/50], Step [604/735], Loss: 1.7982\n",
      "Epoch [1/50], Step [605/735], Loss: 2.3094\n",
      "Epoch [1/50], Step [606/735], Loss: 2.2841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [607/735], Loss: 3.6593\n",
      "Epoch [1/50], Step [608/735], Loss: 1.8499\n",
      "Epoch [1/50], Step [609/735], Loss: 2.3610\n",
      "Epoch [1/50], Step [610/735], Loss: 2.3843\n",
      "Epoch [1/50], Step [611/735], Loss: 3.2887\n",
      "Epoch [1/50], Step [612/735], Loss: 1.6630\n",
      "Epoch [1/50], Step [613/735], Loss: 2.2382\n",
      "Epoch [1/50], Step [614/735], Loss: 2.1656\n",
      "Epoch [1/50], Step [615/735], Loss: 2.2205\n",
      "Epoch [1/50], Step [616/735], Loss: 3.0829\n",
      "Epoch [1/50], Step [617/735], Loss: 2.1326\n",
      "Epoch [1/50], Step [618/735], Loss: 3.2285\n",
      "Epoch [1/50], Step [619/735], Loss: 2.7480\n",
      "Epoch [1/50], Step [620/735], Loss: 2.8892\n",
      "Epoch [1/50], Step [621/735], Loss: 2.0205\n",
      "Epoch [1/50], Step [622/735], Loss: 1.8334\n",
      "Epoch [1/50], Step [623/735], Loss: 2.2599\n",
      "Epoch [1/50], Step [624/735], Loss: 2.2249\n",
      "Epoch [1/50], Step [625/735], Loss: 1.9028\n",
      "Epoch [1/50], Step [626/735], Loss: 2.3702\n",
      "Epoch [1/50], Step [627/735], Loss: 1.7458\n",
      "Epoch [1/50], Step [628/735], Loss: 2.2500\n",
      "Epoch [1/50], Step [629/735], Loss: 3.0816\n",
      "Epoch [1/50], Step [630/735], Loss: 1.6571\n",
      "Epoch [1/50], Step [631/735], Loss: 2.9906\n",
      "Epoch [1/50], Step [632/735], Loss: 2.0806\n",
      "Epoch [1/50], Step [633/735], Loss: 1.8760\n",
      "Epoch [1/50], Step [634/735], Loss: 2.0956\n",
      "Epoch [1/50], Step [635/735], Loss: 2.0041\n",
      "Epoch [1/50], Step [636/735], Loss: 1.9918\n",
      "Epoch [1/50], Step [637/735], Loss: 1.8631\n",
      "Epoch [1/50], Step [638/735], Loss: 2.2810\n",
      "Epoch [1/50], Step [639/735], Loss: 2.8029\n",
      "Epoch [1/50], Step [640/735], Loss: 1.9048\n",
      "Epoch [1/50], Step [641/735], Loss: 1.9066\n",
      "Epoch [1/50], Step [642/735], Loss: 2.3279\n",
      "Epoch [1/50], Step [643/735], Loss: 2.1022\n",
      "Epoch [1/50], Step [644/735], Loss: 1.4229\n",
      "Epoch [1/50], Step [645/735], Loss: 1.5438\n",
      "Epoch [1/50], Step [646/735], Loss: 2.2361\n",
      "Epoch [1/50], Step [647/735], Loss: 1.7509\n",
      "Epoch [1/50], Step [648/735], Loss: 2.2352\n",
      "Epoch [1/50], Step [649/735], Loss: 2.2289\n",
      "Epoch [1/50], Step [650/735], Loss: 1.6927\n",
      "Epoch [1/50], Step [651/735], Loss: 1.8209\n",
      "Epoch [1/50], Step [652/735], Loss: 1.5774\n",
      "Epoch [1/50], Step [653/735], Loss: 1.8594\n",
      "Epoch [1/50], Step [654/735], Loss: 2.0130\n",
      "Epoch [1/50], Step [655/735], Loss: 2.1969\n",
      "Epoch [1/50], Step [656/735], Loss: 2.2953\n",
      "Epoch [1/50], Step [657/735], Loss: 1.5130\n",
      "Epoch [1/50], Step [658/735], Loss: 1.5917\n",
      "Epoch [1/50], Step [659/735], Loss: 2.3943\n",
      "Epoch [1/50], Step [660/735], Loss: 1.4230\n",
      "Epoch [1/50], Step [661/735], Loss: 1.4728\n",
      "Epoch [1/50], Step [662/735], Loss: 2.5566\n",
      "Epoch [1/50], Step [663/735], Loss: 2.8586\n",
      "Epoch [1/50], Step [664/735], Loss: 2.4329\n",
      "Epoch [1/50], Step [665/735], Loss: 1.6498\n",
      "Epoch [1/50], Step [666/735], Loss: 1.8430\n",
      "Epoch [1/50], Step [667/735], Loss: 2.2527\n",
      "Epoch [1/50], Step [668/735], Loss: 2.4433\n",
      "Epoch [1/50], Step [669/735], Loss: 2.8520\n",
      "Epoch [1/50], Step [670/735], Loss: 1.9475\n",
      "Epoch [1/50], Step [671/735], Loss: 1.3904\n",
      "Epoch [1/50], Step [672/735], Loss: 1.6040\n",
      "Epoch [1/50], Step [673/735], Loss: 1.5058\n",
      "Epoch [1/50], Step [674/735], Loss: 1.5950\n",
      "Epoch [1/50], Step [675/735], Loss: 1.7567\n",
      "Epoch [1/50], Step [676/735], Loss: 2.0455\n",
      "Epoch [1/50], Step [677/735], Loss: 2.6323\n",
      "Epoch [1/50], Step [678/735], Loss: 2.1301\n",
      "Epoch [1/50], Step [679/735], Loss: 1.7971\n",
      "Epoch [1/50], Step [680/735], Loss: 3.0236\n",
      "Epoch [1/50], Step [681/735], Loss: 2.2185\n",
      "Epoch [1/50], Step [682/735], Loss: 1.3979\n",
      "Epoch [1/50], Step [683/735], Loss: 1.8794\n",
      "Epoch [1/50], Step [684/735], Loss: 1.8538\n",
      "Epoch [1/50], Step [685/735], Loss: 1.4633\n",
      "Epoch [1/50], Step [686/735], Loss: 1.9210\n",
      "Epoch [1/50], Step [687/735], Loss: 1.1551\n",
      "Epoch [1/50], Step [688/735], Loss: 1.5025\n",
      "Epoch [1/50], Step [689/735], Loss: 1.3060\n",
      "Epoch [1/50], Step [690/735], Loss: 1.4528\n",
      "Epoch [1/50], Step [691/735], Loss: 3.2543\n",
      "Epoch [1/50], Step [692/735], Loss: 1.4792\n",
      "Epoch [1/50], Step [693/735], Loss: 2.1668\n",
      "Epoch [1/50], Step [694/735], Loss: 1.5115\n",
      "Epoch [1/50], Step [695/735], Loss: 1.3384\n",
      "Epoch [1/50], Step [696/735], Loss: 1.8357\n",
      "Epoch [1/50], Step [697/735], Loss: 1.4836\n",
      "Epoch [1/50], Step [698/735], Loss: 2.3768\n",
      "Epoch [1/50], Step [699/735], Loss: 1.4901\n",
      "Epoch [1/50], Step [700/735], Loss: 1.7475\n",
      "Epoch [1/50], Step [701/735], Loss: 1.1205\n",
      "Epoch [1/50], Step [702/735], Loss: 1.9218\n",
      "Epoch [1/50], Step [703/735], Loss: 1.7127\n",
      "Epoch [1/50], Step [704/735], Loss: 2.2350\n",
      "Epoch [1/50], Step [705/735], Loss: 1.8150\n",
      "Epoch [1/50], Step [706/735], Loss: 1.5061\n",
      "Epoch [1/50], Step [707/735], Loss: 1.4093\n",
      "Epoch [1/50], Step [708/735], Loss: 2.3168\n",
      "Epoch [1/50], Step [709/735], Loss: 1.3238\n",
      "Epoch [1/50], Step [710/735], Loss: 1.3609\n",
      "Epoch [1/50], Step [711/735], Loss: 1.5480\n",
      "Epoch [1/50], Step [712/735], Loss: 1.6179\n",
      "Epoch [1/50], Step [713/735], Loss: 1.2469\n",
      "Epoch [1/50], Step [714/735], Loss: 2.1135\n",
      "Epoch [1/50], Step [715/735], Loss: 2.0920\n",
      "Epoch [1/50], Step [716/735], Loss: 1.2133\n",
      "Epoch [1/50], Step [717/735], Loss: 1.5718\n",
      "Epoch [1/50], Step [718/735], Loss: 1.3543\n",
      "Epoch [1/50], Step [719/735], Loss: 1.3187\n",
      "Epoch [1/50], Step [720/735], Loss: 1.7160\n",
      "Epoch [1/50], Step [721/735], Loss: 1.3838\n",
      "Epoch [1/50], Step [722/735], Loss: 1.2674\n",
      "Epoch [1/50], Step [723/735], Loss: 1.7369\n",
      "Epoch [1/50], Step [724/735], Loss: 1.5711\n",
      "Epoch [1/50], Step [725/735], Loss: 1.3338\n",
      "Epoch [1/50], Step [726/735], Loss: 2.2957\n",
      "Epoch [1/50], Step [727/735], Loss: 1.6008\n",
      "Epoch [1/50], Step [728/735], Loss: 1.1437\n",
      "Epoch [1/50], Step [729/735], Loss: 1.0601\n",
      "Epoch [1/50], Step [730/735], Loss: 1.3772\n",
      "Epoch [1/50], Step [731/735], Loss: 1.1489\n",
      "Epoch [1/50], Step [732/735], Loss: 1.4438\n",
      "Epoch [1/50], Step [733/735], Loss: 2.9004\n",
      "Epoch [1/50], Step [734/735], Loss: 1.9489\n",
      "Epoch [1/50], Step [735/735], Loss: 0.7910\n",
      "Epoch [2/50], Step [1/735], Loss: 1.5114\n",
      "Epoch [2/50], Step [2/735], Loss: 1.2079\n",
      "Epoch [2/50], Step [3/735], Loss: 1.7838\n",
      "Epoch [2/50], Step [4/735], Loss: 1.1140\n",
      "Epoch [2/50], Step [5/735], Loss: 1.0201\n",
      "Epoch [2/50], Step [6/735], Loss: 2.1055\n",
      "Epoch [2/50], Step [7/735], Loss: 1.4591\n",
      "Epoch [2/50], Step [8/735], Loss: 1.2605\n",
      "Epoch [2/50], Step [9/735], Loss: 1.1040\n",
      "Epoch [2/50], Step [10/735], Loss: 1.4563\n",
      "Epoch [2/50], Step [11/735], Loss: 1.4321\n",
      "Epoch [2/50], Step [12/735], Loss: 1.4744\n",
      "Epoch [2/50], Step [13/735], Loss: 1.2799\n",
      "Epoch [2/50], Step [14/735], Loss: 1.4680\n",
      "Epoch [2/50], Step [15/735], Loss: 1.7220\n",
      "Epoch [2/50], Step [16/735], Loss: 1.3713\n",
      "Epoch [2/50], Step [17/735], Loss: 1.1345\n",
      "Epoch [2/50], Step [18/735], Loss: 2.0633\n",
      "Epoch [2/50], Step [19/735], Loss: 1.3535\n",
      "Epoch [2/50], Step [20/735], Loss: 1.7958\n",
      "Epoch [2/50], Step [21/735], Loss: 1.0366\n",
      "Epoch [2/50], Step [22/735], Loss: 1.4694\n",
      "Epoch [2/50], Step [23/735], Loss: 1.3400\n",
      "Epoch [2/50], Step [24/735], Loss: 1.6644\n",
      "Epoch [2/50], Step [25/735], Loss: 1.6943\n",
      "Epoch [2/50], Step [26/735], Loss: 1.7684\n",
      "Epoch [2/50], Step [27/735], Loss: 1.7132\n",
      "Epoch [2/50], Step [28/735], Loss: 1.2661\n",
      "Epoch [2/50], Step [29/735], Loss: 1.4765\n",
      "Epoch [2/50], Step [30/735], Loss: 1.4729\n",
      "Epoch [2/50], Step [31/735], Loss: 1.1817\n",
      "Epoch [2/50], Step [32/735], Loss: 1.0820\n",
      "Epoch [2/50], Step [33/735], Loss: 1.2190\n",
      "Epoch [2/50], Step [34/735], Loss: 1.8652\n",
      "Epoch [2/50], Step [35/735], Loss: 1.3495\n",
      "Epoch [2/50], Step [36/735], Loss: 0.9789\n",
      "Epoch [2/50], Step [37/735], Loss: 1.0026\n",
      "Epoch [2/50], Step [38/735], Loss: 1.4237\n",
      "Epoch [2/50], Step [39/735], Loss: 0.9960\n",
      "Epoch [2/50], Step [40/735], Loss: 1.5482\n",
      "Epoch [2/50], Step [41/735], Loss: 2.3618\n",
      "Epoch [2/50], Step [42/735], Loss: 1.1501\n",
      "Epoch [2/50], Step [43/735], Loss: 1.2934\n",
      "Epoch [2/50], Step [44/735], Loss: 0.8840\n",
      "Epoch [2/50], Step [45/735], Loss: 2.4988\n",
      "Epoch [2/50], Step [46/735], Loss: 1.0185\n",
      "Epoch [2/50], Step [47/735], Loss: 1.1618\n",
      "Epoch [2/50], Step [48/735], Loss: 1.3192\n",
      "Epoch [2/50], Step [49/735], Loss: 1.2522\n",
      "Epoch [2/50], Step [50/735], Loss: 1.2104\n",
      "Epoch [2/50], Step [51/735], Loss: 1.3126\n",
      "Epoch [2/50], Step [52/735], Loss: 1.5835\n",
      "Epoch [2/50], Step [53/735], Loss: 1.6905\n",
      "Epoch [2/50], Step [54/735], Loss: 1.1913\n",
      "Epoch [2/50], Step [55/735], Loss: 2.1576\n",
      "Epoch [2/50], Step [56/735], Loss: 1.2785\n",
      "Epoch [2/50], Step [57/735], Loss: 1.1643\n",
      "Epoch [2/50], Step [58/735], Loss: 0.9507\n",
      "Epoch [2/50], Step [59/735], Loss: 1.5612\n",
      "Epoch [2/50], Step [60/735], Loss: 2.2829\n",
      "Epoch [2/50], Step [61/735], Loss: 1.2240\n",
      "Epoch [2/50], Step [62/735], Loss: 1.2569\n",
      "Epoch [2/50], Step [63/735], Loss: 1.3776\n",
      "Epoch [2/50], Step [64/735], Loss: 1.1870\n",
      "Epoch [2/50], Step [65/735], Loss: 0.8019\n",
      "Epoch [2/50], Step [66/735], Loss: 1.0013\n",
      "Epoch [2/50], Step [67/735], Loss: 1.1970\n",
      "Epoch [2/50], Step [68/735], Loss: 1.0762\n",
      "Epoch [2/50], Step [69/735], Loss: 2.2704\n",
      "Epoch [2/50], Step [70/735], Loss: 1.1443\n",
      "Epoch [2/50], Step [71/735], Loss: 1.7609\n",
      "Epoch [2/50], Step [72/735], Loss: 1.1806\n",
      "Epoch [2/50], Step [73/735], Loss: 1.2069\n",
      "Epoch [2/50], Step [74/735], Loss: 0.9814\n",
      "Epoch [2/50], Step [75/735], Loss: 1.0638\n",
      "Epoch [2/50], Step [76/735], Loss: 1.3621\n",
      "Epoch [2/50], Step [77/735], Loss: 1.0150\n",
      "Epoch [2/50], Step [78/735], Loss: 1.3860\n",
      "Epoch [2/50], Step [79/735], Loss: 1.1162\n",
      "Epoch [2/50], Step [80/735], Loss: 1.2796\n",
      "Epoch [2/50], Step [81/735], Loss: 0.8612\n",
      "Epoch [2/50], Step [82/735], Loss: 1.2709\n",
      "Epoch [2/50], Step [83/735], Loss: 0.9976\n",
      "Epoch [2/50], Step [84/735], Loss: 1.5181\n",
      "Epoch [2/50], Step [85/735], Loss: 0.9784\n",
      "Epoch [2/50], Step [86/735], Loss: 0.9292\n",
      "Epoch [2/50], Step [87/735], Loss: 2.0443\n",
      "Epoch [2/50], Step [88/735], Loss: 0.7263\n",
      "Epoch [2/50], Step [89/735], Loss: 2.2357\n",
      "Epoch [2/50], Step [90/735], Loss: 0.9334\n",
      "Epoch [2/50], Step [91/735], Loss: 1.0232\n",
      "Epoch [2/50], Step [92/735], Loss: 1.2423\n",
      "Epoch [2/50], Step [93/735], Loss: 0.8917\n",
      "Epoch [2/50], Step [94/735], Loss: 0.9281\n",
      "Epoch [2/50], Step [95/735], Loss: 0.8735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Step [96/735], Loss: 1.5431\n",
      "Epoch [2/50], Step [97/735], Loss: 0.9145\n",
      "Epoch [2/50], Step [98/735], Loss: 1.9586\n",
      "Epoch [2/50], Step [99/735], Loss: 1.0091\n",
      "Epoch [2/50], Step [100/735], Loss: 1.1033\n",
      "Epoch [2/50], Step [101/735], Loss: 1.1735\n",
      "Epoch [2/50], Step [102/735], Loss: 1.0898\n",
      "Epoch [2/50], Step [103/735], Loss: 0.9377\n",
      "Epoch [2/50], Step [104/735], Loss: 1.1563\n",
      "Epoch [2/50], Step [105/735], Loss: 1.3237\n",
      "Epoch [2/50], Step [106/735], Loss: 1.9050\n",
      "Epoch [2/50], Step [107/735], Loss: 1.0633\n",
      "Epoch [2/50], Step [108/735], Loss: 1.0640\n",
      "Epoch [2/50], Step [109/735], Loss: 0.9730\n",
      "Epoch [2/50], Step [110/735], Loss: 1.4043\n",
      "Epoch [2/50], Step [111/735], Loss: 0.6014\n",
      "Epoch [2/50], Step [112/735], Loss: 1.3294\n",
      "Epoch [2/50], Step [113/735], Loss: 1.2710\n",
      "Epoch [2/50], Step [114/735], Loss: 1.2135\n",
      "Epoch [2/50], Step [115/735], Loss: 2.2943\n",
      "Epoch [2/50], Step [116/735], Loss: 1.3040\n",
      "Epoch [2/50], Step [117/735], Loss: 0.8072\n",
      "Epoch [2/50], Step [118/735], Loss: 1.2997\n",
      "Epoch [2/50], Step [119/735], Loss: 0.6567\n",
      "Epoch [2/50], Step [120/735], Loss: 1.2340\n",
      "Epoch [2/50], Step [121/735], Loss: 1.0714\n",
      "Epoch [2/50], Step [122/735], Loss: 0.4737\n",
      "Epoch [2/50], Step [123/735], Loss: 1.4292\n",
      "Epoch [2/50], Step [124/735], Loss: 1.8336\n",
      "Epoch [2/50], Step [125/735], Loss: 0.7543\n",
      "Epoch [2/50], Step [126/735], Loss: 1.2283\n",
      "Epoch [2/50], Step [127/735], Loss: 1.0739\n",
      "Epoch [2/50], Step [128/735], Loss: 0.9124\n",
      "Epoch [2/50], Step [129/735], Loss: 1.3887\n",
      "Epoch [2/50], Step [130/735], Loss: 1.0883\n",
      "Epoch [2/50], Step [131/735], Loss: 1.0177\n",
      "Epoch [2/50], Step [132/735], Loss: 1.5031\n",
      "Epoch [2/50], Step [133/735], Loss: 0.8778\n",
      "Epoch [2/50], Step [134/735], Loss: 0.6613\n",
      "Epoch [2/50], Step [135/735], Loss: 1.1981\n",
      "Epoch [2/50], Step [136/735], Loss: 0.5743\n",
      "Epoch [2/50], Step [137/735], Loss: 1.0833\n",
      "Epoch [2/50], Step [138/735], Loss: 0.8341\n",
      "Epoch [2/50], Step [139/735], Loss: 1.3351\n",
      "Epoch [2/50], Step [140/735], Loss: 0.8329\n",
      "Epoch [2/50], Step [141/735], Loss: 0.8244\n",
      "Epoch [2/50], Step [142/735], Loss: 0.8527\n",
      "Epoch [2/50], Step [143/735], Loss: 1.7754\n",
      "Epoch [2/50], Step [144/735], Loss: 0.7066\n",
      "Epoch [2/50], Step [145/735], Loss: 1.5064\n",
      "Epoch [2/50], Step [146/735], Loss: 1.1522\n",
      "Epoch [2/50], Step [147/735], Loss: 0.6679\n",
      "Epoch [2/50], Step [148/735], Loss: 0.8891\n",
      "Epoch [2/50], Step [149/735], Loss: 0.8513\n",
      "Epoch [2/50], Step [150/735], Loss: 0.6262\n",
      "Epoch [2/50], Step [151/735], Loss: 1.0294\n",
      "Epoch [2/50], Step [152/735], Loss: 1.6092\n",
      "Epoch [2/50], Step [153/735], Loss: 1.0887\n",
      "Epoch [2/50], Step [154/735], Loss: 0.8106\n",
      "Epoch [2/50], Step [155/735], Loss: 0.6812\n",
      "Epoch [2/50], Step [156/735], Loss: 0.9933\n",
      "Epoch [2/50], Step [157/735], Loss: 0.8573\n",
      "Epoch [2/50], Step [158/735], Loss: 0.8061\n",
      "Epoch [2/50], Step [159/735], Loss: 0.9705\n",
      "Epoch [2/50], Step [160/735], Loss: 2.9095\n",
      "Epoch [2/50], Step [161/735], Loss: 0.6205\n",
      "Epoch [2/50], Step [162/735], Loss: 1.4210\n",
      "Epoch [2/50], Step [163/735], Loss: 0.7420\n",
      "Epoch [2/50], Step [164/735], Loss: 0.8082\n",
      "Epoch [2/50], Step [165/735], Loss: 0.9642\n",
      "Epoch [2/50], Step [166/735], Loss: 1.2060\n",
      "Epoch [2/50], Step [167/735], Loss: 0.7529\n",
      "Epoch [2/50], Step [168/735], Loss: 1.6477\n",
      "Epoch [2/50], Step [169/735], Loss: 0.7645\n",
      "Epoch [2/50], Step [170/735], Loss: 0.7457\n",
      "Epoch [2/50], Step [171/735], Loss: 1.2998\n",
      "Epoch [2/50], Step [172/735], Loss: 1.2388\n",
      "Epoch [2/50], Step [173/735], Loss: 0.9017\n",
      "Epoch [2/50], Step [174/735], Loss: 0.9739\n",
      "Epoch [2/50], Step [175/735], Loss: 0.7214\n",
      "Epoch [2/50], Step [176/735], Loss: 0.8322\n",
      "Epoch [2/50], Step [177/735], Loss: 1.5052\n",
      "Epoch [2/50], Step [178/735], Loss: 0.7581\n",
      "Epoch [2/50], Step [179/735], Loss: 0.7004\n",
      "Epoch [2/50], Step [180/735], Loss: 1.2421\n",
      "Epoch [2/50], Step [181/735], Loss: 1.1671\n",
      "Epoch [2/50], Step [182/735], Loss: 1.0203\n",
      "Epoch [2/50], Step [183/735], Loss: 0.7238\n",
      "Epoch [2/50], Step [184/735], Loss: 0.6255\n",
      "Epoch [2/50], Step [185/735], Loss: 0.7404\n",
      "Epoch [2/50], Step [186/735], Loss: 0.7332\n",
      "Epoch [2/50], Step [187/735], Loss: 0.9012\n",
      "Epoch [2/50], Step [188/735], Loss: 1.2400\n",
      "Epoch [2/50], Step [189/735], Loss: 0.9425\n",
      "Epoch [2/50], Step [190/735], Loss: 0.6941\n",
      "Epoch [2/50], Step [191/735], Loss: 0.8412\n",
      "Epoch [2/50], Step [192/735], Loss: 0.7817\n",
      "Epoch [2/50], Step [193/735], Loss: 0.5836\n",
      "Epoch [2/50], Step [194/735], Loss: 0.7956\n",
      "Epoch [2/50], Step [195/735], Loss: 0.6787\n",
      "Epoch [2/50], Step [196/735], Loss: 1.5383\n",
      "Epoch [2/50], Step [197/735], Loss: 0.9852\n",
      "Epoch [2/50], Step [198/735], Loss: 2.4499\n",
      "Epoch [2/50], Step [199/735], Loss: 0.6554\n",
      "Epoch [2/50], Step [200/735], Loss: 1.0995\n",
      "Epoch [2/50], Step [201/735], Loss: 1.3278\n",
      "Epoch [2/50], Step [202/735], Loss: 0.7212\n",
      "Epoch [2/50], Step [203/735], Loss: 0.7136\n",
      "Epoch [2/50], Step [204/735], Loss: 0.7930\n",
      "Epoch [2/50], Step [205/735], Loss: 1.3314\n",
      "Epoch [2/50], Step [206/735], Loss: 0.7013\n",
      "Epoch [2/50], Step [207/735], Loss: 0.8116\n",
      "Epoch [2/50], Step [208/735], Loss: 0.7935\n",
      "Epoch [2/50], Step [209/735], Loss: 0.6502\n",
      "Epoch [2/50], Step [210/735], Loss: 0.7897\n",
      "Epoch [2/50], Step [211/735], Loss: 0.7489\n",
      "Epoch [2/50], Step [212/735], Loss: 0.7609\n",
      "Epoch [2/50], Step [213/735], Loss: 0.9086\n",
      "Epoch [2/50], Step [214/735], Loss: 0.8936\n",
      "Epoch [2/50], Step [215/735], Loss: 1.2477\n",
      "Epoch [2/50], Step [216/735], Loss: 0.5905\n",
      "Epoch [2/50], Step [217/735], Loss: 1.3379\n",
      "Epoch [2/50], Step [218/735], Loss: 0.8654\n",
      "Epoch [2/50], Step [219/735], Loss: 1.0987\n",
      "Epoch [2/50], Step [220/735], Loss: 0.8572\n",
      "Epoch [2/50], Step [221/735], Loss: 1.0128\n",
      "Epoch [2/50], Step [222/735], Loss: 0.6437\n",
      "Epoch [2/50], Step [223/735], Loss: 0.9204\n",
      "Epoch [2/50], Step [224/735], Loss: 1.0021\n",
      "Epoch [2/50], Step [225/735], Loss: 0.7951\n",
      "Epoch [2/50], Step [226/735], Loss: 1.0575\n",
      "Epoch [2/50], Step [227/735], Loss: 0.5724\n",
      "Epoch [2/50], Step [228/735], Loss: 2.0662\n",
      "Epoch [2/50], Step [229/735], Loss: 0.8964\n",
      "Epoch [2/50], Step [230/735], Loss: 0.7760\n",
      "Epoch [2/50], Step [231/735], Loss: 1.5953\n",
      "Epoch [2/50], Step [232/735], Loss: 0.7362\n",
      "Epoch [2/50], Step [233/735], Loss: 1.3710\n",
      "Epoch [2/50], Step [234/735], Loss: 0.6775\n",
      "Epoch [2/50], Step [235/735], Loss: 0.6872\n",
      "Epoch [2/50], Step [236/735], Loss: 0.8430\n",
      "Epoch [2/50], Step [237/735], Loss: 1.0704\n",
      "Epoch [2/50], Step [238/735], Loss: 0.5117\n",
      "Epoch [2/50], Step [239/735], Loss: 1.5573\n",
      "Epoch [2/50], Step [240/735], Loss: 0.6664\n",
      "Epoch [2/50], Step [241/735], Loss: 1.3944\n",
      "Epoch [2/50], Step [242/735], Loss: 0.5429\n",
      "Epoch [2/50], Step [243/735], Loss: 0.8133\n",
      "Epoch [2/50], Step [244/735], Loss: 0.9578\n",
      "Epoch [2/50], Step [245/735], Loss: 1.0129\n",
      "Epoch [2/50], Step [246/735], Loss: 0.6892\n",
      "Epoch [2/50], Step [247/735], Loss: 0.4855\n",
      "Epoch [2/50], Step [248/735], Loss: 0.4666\n",
      "Epoch [2/50], Step [249/735], Loss: 0.6774\n",
      "Epoch [2/50], Step [250/735], Loss: 0.5380\n",
      "Epoch [2/50], Step [251/735], Loss: 0.8144\n",
      "Epoch [2/50], Step [252/735], Loss: 0.8395\n",
      "Epoch [2/50], Step [253/735], Loss: 0.5108\n",
      "Epoch [2/50], Step [254/735], Loss: 0.4767\n",
      "Epoch [2/50], Step [255/735], Loss: 0.3892\n",
      "Epoch [2/50], Step [256/735], Loss: 0.7679\n",
      "Epoch [2/50], Step [257/735], Loss: 1.4448\n",
      "Epoch [2/50], Step [258/735], Loss: 1.1574\n",
      "Epoch [2/50], Step [259/735], Loss: 0.6305\n",
      "Epoch [2/50], Step [260/735], Loss: 0.6536\n",
      "Epoch [2/50], Step [261/735], Loss: 0.4632\n",
      "Epoch [2/50], Step [262/735], Loss: 0.6698\n",
      "Epoch [2/50], Step [263/735], Loss: 0.4873\n",
      "Epoch [2/50], Step [264/735], Loss: 0.6419\n",
      "Epoch [2/50], Step [265/735], Loss: 1.4117\n",
      "Epoch [2/50], Step [266/735], Loss: 0.7458\n",
      "Epoch [2/50], Step [267/735], Loss: 0.6941\n",
      "Epoch [2/50], Step [268/735], Loss: 0.7705\n",
      "Epoch [2/50], Step [269/735], Loss: 1.1997\n",
      "Epoch [2/50], Step [270/735], Loss: 0.6304\n",
      "Epoch [2/50], Step [271/735], Loss: 0.9871\n",
      "Epoch [2/50], Step [272/735], Loss: 1.0167\n",
      "Epoch [2/50], Step [273/735], Loss: 0.5860\n",
      "Epoch [2/50], Step [274/735], Loss: 0.3439\n",
      "Epoch [2/50], Step [275/735], Loss: 0.4908\n",
      "Epoch [2/50], Step [276/735], Loss: 0.6314\n",
      "Epoch [2/50], Step [277/735], Loss: 1.0543\n",
      "Epoch [2/50], Step [278/735], Loss: 1.0946\n",
      "Epoch [2/50], Step [279/735], Loss: 0.7829\n",
      "Epoch [2/50], Step [280/735], Loss: 0.7230\n",
      "Epoch [2/50], Step [281/735], Loss: 0.7551\n",
      "Epoch [2/50], Step [282/735], Loss: 0.6853\n",
      "Epoch [2/50], Step [283/735], Loss: 0.9156\n",
      "Epoch [2/50], Step [284/735], Loss: 0.7745\n",
      "Epoch [2/50], Step [285/735], Loss: 0.7384\n",
      "Epoch [2/50], Step [286/735], Loss: 0.7842\n",
      "Epoch [2/50], Step [287/735], Loss: 0.7463\n",
      "Epoch [2/50], Step [288/735], Loss: 0.7017\n",
      "Epoch [2/50], Step [289/735], Loss: 0.4830\n",
      "Epoch [2/50], Step [290/735], Loss: 0.7737\n",
      "Epoch [2/50], Step [291/735], Loss: 1.0035\n",
      "Epoch [2/50], Step [292/735], Loss: 0.5971\n",
      "Epoch [2/50], Step [293/735], Loss: 1.0525\n",
      "Epoch [2/50], Step [294/735], Loss: 1.0521\n",
      "Epoch [2/50], Step [295/735], Loss: 1.6163\n",
      "Epoch [2/50], Step [296/735], Loss: 0.6780\n",
      "Epoch [2/50], Step [297/735], Loss: 0.5045\n",
      "Epoch [2/50], Step [298/735], Loss: 0.3854\n",
      "Epoch [2/50], Step [299/735], Loss: 0.3881\n",
      "Epoch [2/50], Step [300/735], Loss: 0.5327\n",
      "Epoch [2/50], Step [301/735], Loss: 0.6181\n",
      "Epoch [2/50], Step [302/735], Loss: 0.7881\n",
      "Epoch [2/50], Step [303/735], Loss: 0.8850\n",
      "Epoch [2/50], Step [304/735], Loss: 1.0169\n",
      "Epoch [2/50], Step [305/735], Loss: 0.8405\n",
      "Epoch [2/50], Step [306/735], Loss: 0.5660\n",
      "Epoch [2/50], Step [307/735], Loss: 1.5906\n",
      "Epoch [2/50], Step [308/735], Loss: 0.5576\n",
      "Epoch [2/50], Step [309/735], Loss: 0.4392\n",
      "Epoch [2/50], Step [310/735], Loss: 0.9479\n",
      "Epoch [2/50], Step [311/735], Loss: 0.4818\n",
      "Epoch [2/50], Step [312/735], Loss: 0.5628\n",
      "Epoch [2/50], Step [313/735], Loss: 0.4473\n",
      "Epoch [2/50], Step [314/735], Loss: 0.5090\n",
      "Epoch [2/50], Step [315/735], Loss: 1.0832\n",
      "Epoch [2/50], Step [316/735], Loss: 1.7994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Step [317/735], Loss: 1.1269\n",
      "Epoch [2/50], Step [318/735], Loss: 0.5391\n",
      "Epoch [2/50], Step [319/735], Loss: 0.4180\n",
      "Epoch [2/50], Step [320/735], Loss: 0.8490\n",
      "Epoch [2/50], Step [321/735], Loss: 0.8656\n",
      "Epoch [2/50], Step [322/735], Loss: 0.6410\n",
      "Epoch [2/50], Step [323/735], Loss: 1.1914\n",
      "Epoch [2/50], Step [324/735], Loss: 0.8017\n",
      "Epoch [2/50], Step [325/735], Loss: 0.8700\n",
      "Epoch [2/50], Step [326/735], Loss: 0.8667\n",
      "Epoch [2/50], Step [327/735], Loss: 1.8438\n",
      "Epoch [2/50], Step [328/735], Loss: 1.0029\n",
      "Epoch [2/50], Step [329/735], Loss: 0.7374\n",
      "Epoch [2/50], Step [330/735], Loss: 0.7781\n",
      "Epoch [2/50], Step [331/735], Loss: 0.8531\n",
      "Epoch [2/50], Step [332/735], Loss: 1.2315\n",
      "Epoch [2/50], Step [333/735], Loss: 0.5996\n",
      "Epoch [2/50], Step [334/735], Loss: 1.2117\n",
      "Epoch [2/50], Step [335/735], Loss: 0.6390\n",
      "Epoch [2/50], Step [336/735], Loss: 0.7355\n",
      "Epoch [2/50], Step [337/735], Loss: 0.5380\n",
      "Epoch [2/50], Step [338/735], Loss: 0.4277\n",
      "Epoch [2/50], Step [339/735], Loss: 0.5662\n",
      "Epoch [2/50], Step [340/735], Loss: 0.5820\n",
      "Epoch [2/50], Step [341/735], Loss: 0.8267\n",
      "Epoch [2/50], Step [342/735], Loss: 0.4053\n",
      "Epoch [2/50], Step [343/735], Loss: 0.4789\n",
      "Epoch [2/50], Step [344/735], Loss: 0.6811\n",
      "Epoch [2/50], Step [345/735], Loss: 0.5375\n",
      "Epoch [2/50], Step [346/735], Loss: 0.4683\n",
      "Epoch [2/50], Step [347/735], Loss: 0.4885\n",
      "Epoch [2/50], Step [348/735], Loss: 0.4931\n",
      "Epoch [2/50], Step [349/735], Loss: 0.8330\n",
      "Epoch [2/50], Step [350/735], Loss: 0.6659\n",
      "Epoch [2/50], Step [351/735], Loss: 1.5538\n",
      "Epoch [2/50], Step [352/735], Loss: 0.5559\n",
      "Epoch [2/50], Step [353/735], Loss: 0.4378\n",
      "Epoch [2/50], Step [354/735], Loss: 0.6533\n",
      "Epoch [2/50], Step [355/735], Loss: 0.8401\n",
      "Epoch [2/50], Step [356/735], Loss: 1.7675\n",
      "Epoch [2/50], Step [357/735], Loss: 0.7399\n",
      "Epoch [2/50], Step [358/735], Loss: 0.4981\n",
      "Epoch [2/50], Step [359/735], Loss: 0.6349\n",
      "Epoch [2/50], Step [360/735], Loss: 0.4397\n",
      "Epoch [2/50], Step [361/735], Loss: 1.0250\n",
      "Epoch [2/50], Step [362/735], Loss: 0.5413\n",
      "Epoch [2/50], Step [363/735], Loss: 1.5267\n",
      "Epoch [2/50], Step [364/735], Loss: 1.4755\n",
      "Epoch [2/50], Step [365/735], Loss: 0.7397\n",
      "Epoch [2/50], Step [366/735], Loss: 0.4995\n",
      "Epoch [2/50], Step [367/735], Loss: 0.5183\n",
      "Epoch [2/50], Step [368/735], Loss: 0.5350\n",
      "Epoch [2/50], Step [369/735], Loss: 0.6053\n",
      "Epoch [2/50], Step [370/735], Loss: 0.5688\n",
      "Epoch [2/50], Step [371/735], Loss: 0.7055\n",
      "Epoch [2/50], Step [372/735], Loss: 0.7476\n",
      "Epoch [2/50], Step [373/735], Loss: 0.3545\n",
      "Epoch [2/50], Step [374/735], Loss: 0.4877\n",
      "Epoch [2/50], Step [375/735], Loss: 0.5094\n",
      "Epoch [2/50], Step [376/735], Loss: 0.5002\n",
      "Epoch [2/50], Step [377/735], Loss: 0.4093\n",
      "Epoch [2/50], Step [378/735], Loss: 0.4140\n",
      "Epoch [2/50], Step [379/735], Loss: 0.4710\n",
      "Epoch [2/50], Step [380/735], Loss: 0.4332\n",
      "Epoch [2/50], Step [381/735], Loss: 0.5807\n",
      "Epoch [2/50], Step [382/735], Loss: 0.5016\n",
      "Epoch [2/50], Step [383/735], Loss: 0.4657\n",
      "Epoch [2/50], Step [384/735], Loss: 0.6402\n",
      "Epoch [2/50], Step [385/735], Loss: 0.5934\n",
      "Epoch [2/50], Step [386/735], Loss: 0.4798\n",
      "Epoch [2/50], Step [387/735], Loss: 0.9703\n",
      "Epoch [2/50], Step [388/735], Loss: 0.3834\n",
      "Epoch [2/50], Step [389/735], Loss: 0.6420\n",
      "Epoch [2/50], Step [390/735], Loss: 0.5822\n",
      "Epoch [2/50], Step [391/735], Loss: 0.7205\n",
      "Epoch [2/50], Step [392/735], Loss: 1.5492\n",
      "Epoch [2/50], Step [393/735], Loss: 0.5600\n",
      "Epoch [2/50], Step [394/735], Loss: 0.5310\n",
      "Epoch [2/50], Step [395/735], Loss: 1.4211\n",
      "Epoch [2/50], Step [396/735], Loss: 0.5085\n",
      "Epoch [2/50], Step [397/735], Loss: 0.4074\n",
      "Epoch [2/50], Step [398/735], Loss: 0.5224\n",
      "Epoch [2/50], Step [399/735], Loss: 0.5470\n",
      "Epoch [2/50], Step [400/735], Loss: 0.6134\n",
      "Epoch [2/50], Step [401/735], Loss: 0.9667\n",
      "Epoch [2/50], Step [402/735], Loss: 0.4614\n",
      "Epoch [2/50], Step [403/735], Loss: 0.3638\n",
      "Epoch [2/50], Step [404/735], Loss: 0.4600\n",
      "Epoch [2/50], Step [405/735], Loss: 0.4430\n",
      "Epoch [2/50], Step [406/735], Loss: 1.0261\n",
      "Epoch [2/50], Step [407/735], Loss: 0.7683\n",
      "Epoch [2/50], Step [408/735], Loss: 0.4754\n",
      "Epoch [2/50], Step [409/735], Loss: 0.3960\n",
      "Epoch [2/50], Step [410/735], Loss: 0.7361\n",
      "Epoch [2/50], Step [411/735], Loss: 0.7380\n",
      "Epoch [2/50], Step [412/735], Loss: 0.6606\n",
      "Epoch [2/50], Step [413/735], Loss: 0.4448\n",
      "Epoch [2/50], Step [414/735], Loss: 1.7965\n",
      "Epoch [2/50], Step [415/735], Loss: 0.5331\n",
      "Epoch [2/50], Step [416/735], Loss: 0.5697\n",
      "Epoch [2/50], Step [417/735], Loss: 0.4138\n",
      "Epoch [2/50], Step [418/735], Loss: 0.4952\n",
      "Epoch [2/50], Step [419/735], Loss: 0.8279\n",
      "Epoch [2/50], Step [420/735], Loss: 0.5445\n",
      "Epoch [2/50], Step [421/735], Loss: 1.2068\n",
      "Epoch [2/50], Step [422/735], Loss: 0.3322\n",
      "Epoch [2/50], Step [423/735], Loss: 0.6839\n",
      "Epoch [2/50], Step [424/735], Loss: 0.4151\n",
      "Epoch [2/50], Step [425/735], Loss: 1.7399\n",
      "Epoch [2/50], Step [426/735], Loss: 0.4042\n",
      "Epoch [2/50], Step [427/735], Loss: 0.5869\n",
      "Epoch [2/50], Step [428/735], Loss: 0.3547\n",
      "Epoch [2/50], Step [429/735], Loss: 0.7152\n",
      "Epoch [2/50], Step [430/735], Loss: 0.7964\n",
      "Epoch [2/50], Step [431/735], Loss: 0.3897\n",
      "Epoch [2/50], Step [432/735], Loss: 0.7555\n",
      "Epoch [2/50], Step [433/735], Loss: 0.4310\n",
      "Epoch [2/50], Step [434/735], Loss: 0.3534\n",
      "Epoch [2/50], Step [435/735], Loss: 0.3690\n",
      "Epoch [2/50], Step [436/735], Loss: 0.4659\n",
      "Epoch [2/50], Step [437/735], Loss: 0.7002\n",
      "Epoch [2/50], Step [438/735], Loss: 1.2509\n",
      "Epoch [2/50], Step [439/735], Loss: 0.4846\n",
      "Epoch [2/50], Step [440/735], Loss: 0.8623\n",
      "Epoch [2/50], Step [441/735], Loss: 0.5614\n",
      "Epoch [2/50], Step [442/735], Loss: 0.2754\n",
      "Epoch [2/50], Step [443/735], Loss: 0.5806\n",
      "Epoch [2/50], Step [444/735], Loss: 0.7302\n",
      "Epoch [2/50], Step [445/735], Loss: 0.5734\n",
      "Epoch [2/50], Step [446/735], Loss: 0.8792\n",
      "Epoch [2/50], Step [447/735], Loss: 0.3765\n",
      "Epoch [2/50], Step [448/735], Loss: 0.4490\n",
      "Epoch [2/50], Step [449/735], Loss: 0.2862\n",
      "Epoch [2/50], Step [450/735], Loss: 0.4075\n",
      "Epoch [2/50], Step [451/735], Loss: 0.4268\n",
      "Epoch [2/50], Step [452/735], Loss: 0.5943\n",
      "Epoch [2/50], Step [453/735], Loss: 0.3632\n",
      "Epoch [2/50], Step [454/735], Loss: 0.3341\n",
      "Epoch [2/50], Step [455/735], Loss: 0.3243\n",
      "Epoch [2/50], Step [456/735], Loss: 0.4349\n",
      "Epoch [2/50], Step [457/735], Loss: 0.4207\n",
      "Epoch [2/50], Step [458/735], Loss: 0.7198\n",
      "Epoch [2/50], Step [459/735], Loss: 0.5210\n",
      "Epoch [2/50], Step [460/735], Loss: 0.3626\n",
      "Epoch [2/50], Step [461/735], Loss: 0.4006\n",
      "Epoch [2/50], Step [462/735], Loss: 0.8969\n",
      "Epoch [2/50], Step [463/735], Loss: 0.5184\n",
      "Epoch [2/50], Step [464/735], Loss: 0.3235\n",
      "Epoch [2/50], Step [465/735], Loss: 0.5802\n",
      "Epoch [2/50], Step [466/735], Loss: 0.9513\n",
      "Epoch [2/50], Step [467/735], Loss: 0.4131\n",
      "Epoch [2/50], Step [468/735], Loss: 0.4326\n",
      "Epoch [2/50], Step [469/735], Loss: 0.3838\n",
      "Epoch [2/50], Step [470/735], Loss: 0.8852\n",
      "Epoch [2/50], Step [471/735], Loss: 0.5325\n",
      "Epoch [2/50], Step [472/735], Loss: 0.4605\n",
      "Epoch [2/50], Step [473/735], Loss: 0.4429\n",
      "Epoch [2/50], Step [474/735], Loss: 0.3697\n",
      "Epoch [2/50], Step [475/735], Loss: 0.9535\n",
      "Epoch [2/50], Step [476/735], Loss: 0.4224\n",
      "Epoch [2/50], Step [477/735], Loss: 0.3184\n",
      "Epoch [2/50], Step [478/735], Loss: 0.3803\n",
      "Epoch [2/50], Step [479/735], Loss: 0.3831\n",
      "Epoch [2/50], Step [480/735], Loss: 0.5157\n",
      "Epoch [2/50], Step [481/735], Loss: 0.5774\n",
      "Epoch [2/50], Step [482/735], Loss: 0.2538\n",
      "Epoch [2/50], Step [483/735], Loss: 0.3330\n",
      "Epoch [2/50], Step [484/735], Loss: 0.8381\n",
      "Epoch [2/50], Step [485/735], Loss: 1.7634\n",
      "Epoch [2/50], Step [486/735], Loss: 0.3876\n",
      "Epoch [2/50], Step [487/735], Loss: 0.5277\n",
      "Epoch [2/50], Step [488/735], Loss: 1.3873\n",
      "Epoch [2/50], Step [489/735], Loss: 0.8513\n",
      "Epoch [2/50], Step [490/735], Loss: 0.4458\n",
      "Epoch [2/50], Step [491/735], Loss: 0.3380\n",
      "Epoch [2/50], Step [492/735], Loss: 0.3996\n",
      "Epoch [2/50], Step [493/735], Loss: 0.4590\n",
      "Epoch [2/50], Step [494/735], Loss: 0.3164\n",
      "Epoch [2/50], Step [495/735], Loss: 0.6666\n",
      "Epoch [2/50], Step [496/735], Loss: 0.2724\n",
      "Epoch [2/50], Step [497/735], Loss: 0.3368\n",
      "Epoch [2/50], Step [498/735], Loss: 0.4956\n",
      "Epoch [2/50], Step [499/735], Loss: 0.8509\n",
      "Epoch [2/50], Step [500/735], Loss: 0.2789\n",
      "Epoch [2/50], Step [501/735], Loss: 0.3546\n",
      "Epoch [2/50], Step [502/735], Loss: 0.8599\n",
      "Epoch [2/50], Step [503/735], Loss: 0.2472\n",
      "Epoch [2/50], Step [504/735], Loss: 0.7401\n",
      "Epoch [2/50], Step [505/735], Loss: 0.9350\n",
      "Epoch [2/50], Step [506/735], Loss: 1.1589\n",
      "Epoch [2/50], Step [507/735], Loss: 0.4111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Step [508/735], Loss: 0.6907\n",
      "Epoch [2/50], Step [509/735], Loss: 0.4763\n",
      "Epoch [2/50], Step [510/735], Loss: 0.3359\n",
      "Epoch [2/50], Step [511/735], Loss: 0.5521\n",
      "Epoch [2/50], Step [512/735], Loss: 0.8811\n",
      "Epoch [2/50], Step [513/735], Loss: 0.4361\n",
      "Epoch [2/50], Step [514/735], Loss: 0.4037\n",
      "Epoch [2/50], Step [515/735], Loss: 0.4024\n",
      "Epoch [2/50], Step [516/735], Loss: 0.5949\n",
      "Epoch [2/50], Step [517/735], Loss: 0.2969\n",
      "Epoch [2/50], Step [518/735], Loss: 0.8583\n",
      "Epoch [2/50], Step [519/735], Loss: 0.8995\n",
      "Epoch [2/50], Step [520/735], Loss: 0.4267\n",
      "Epoch [2/50], Step [521/735], Loss: 0.3972\n",
      "Epoch [2/50], Step [522/735], Loss: 0.4684\n",
      "Epoch [2/50], Step [523/735], Loss: 0.2852\n",
      "Epoch [2/50], Step [524/735], Loss: 0.3285\n",
      "Epoch [2/50], Step [525/735], Loss: 0.6798\n",
      "Epoch [2/50], Step [526/735], Loss: 0.3214\n",
      "Epoch [2/50], Step [527/735], Loss: 0.3390\n",
      "Epoch [2/50], Step [528/735], Loss: 0.3485\n",
      "Epoch [2/50], Step [529/735], Loss: 0.4360\n",
      "Epoch [2/50], Step [530/735], Loss: 0.4677\n",
      "Epoch [2/50], Step [531/735], Loss: 0.3437\n",
      "Epoch [2/50], Step [532/735], Loss: 0.4153\n",
      "Epoch [2/50], Step [533/735], Loss: 0.6733\n",
      "Epoch [2/50], Step [534/735], Loss: 0.3560\n",
      "Epoch [2/50], Step [535/735], Loss: 0.8724\n",
      "Epoch [2/50], Step [536/735], Loss: 0.5197\n",
      "Epoch [2/50], Step [537/735], Loss: 0.2994\n",
      "Epoch [2/50], Step [538/735], Loss: 0.4754\n",
      "Epoch [2/50], Step [539/735], Loss: 0.3999\n",
      "Epoch [2/50], Step [540/735], Loss: 0.3649\n",
      "Epoch [2/50], Step [541/735], Loss: 0.3077\n",
      "Epoch [2/50], Step [542/735], Loss: 0.3147\n",
      "Epoch [2/50], Step [543/735], Loss: 0.3943\n",
      "Epoch [2/50], Step [544/735], Loss: 0.3999\n",
      "Epoch [2/50], Step [545/735], Loss: 0.4187\n",
      "Epoch [2/50], Step [546/735], Loss: 0.7050\n",
      "Epoch [2/50], Step [547/735], Loss: 0.5660\n",
      "Epoch [2/50], Step [548/735], Loss: 0.4525\n",
      "Epoch [2/50], Step [549/735], Loss: 1.0458\n",
      "Epoch [2/50], Step [550/735], Loss: 0.2038\n",
      "Epoch [2/50], Step [551/735], Loss: 0.4858\n",
      "Epoch [2/50], Step [552/735], Loss: 0.5678\n",
      "Epoch [2/50], Step [553/735], Loss: 1.0157\n",
      "Epoch [2/50], Step [554/735], Loss: 0.6058\n",
      "Epoch [2/50], Step [555/735], Loss: 0.6236\n",
      "Epoch [2/50], Step [556/735], Loss: 0.4273\n",
      "Epoch [2/50], Step [557/735], Loss: 0.3754\n",
      "Epoch [2/50], Step [558/735], Loss: 0.3339\n",
      "Epoch [2/50], Step [559/735], Loss: 0.6694\n",
      "Epoch [2/50], Step [560/735], Loss: 0.4201\n",
      "Epoch [2/50], Step [561/735], Loss: 0.3211\n",
      "Epoch [2/50], Step [562/735], Loss: 0.3120\n",
      "Epoch [2/50], Step [563/735], Loss: 0.3280\n",
      "Epoch [2/50], Step [564/735], Loss: 0.3558\n",
      "Epoch [2/50], Step [565/735], Loss: 0.2856\n",
      "Epoch [2/50], Step [566/735], Loss: 0.7345\n",
      "Epoch [2/50], Step [567/735], Loss: 0.3359\n",
      "Epoch [2/50], Step [568/735], Loss: 0.2682\n",
      "Epoch [2/50], Step [569/735], Loss: 0.4814\n",
      "Epoch [2/50], Step [570/735], Loss: 0.3839\n",
      "Epoch [2/50], Step [571/735], Loss: 0.6763\n",
      "Epoch [2/50], Step [572/735], Loss: 0.5936\n",
      "Epoch [2/50], Step [573/735], Loss: 0.3369\n",
      "Epoch [2/50], Step [574/735], Loss: 0.2101\n",
      "Epoch [2/50], Step [575/735], Loss: 0.3192\n",
      "Epoch [2/50], Step [576/735], Loss: 0.3311\n",
      "Epoch [2/50], Step [577/735], Loss: 0.4905\n",
      "Epoch [2/50], Step [578/735], Loss: 0.5181\n",
      "Epoch [2/50], Step [579/735], Loss: 0.3988\n",
      "Epoch [2/50], Step [580/735], Loss: 0.4002\n",
      "Epoch [2/50], Step [581/735], Loss: 0.8158\n",
      "Epoch [2/50], Step [582/735], Loss: 0.4271\n",
      "Epoch [2/50], Step [583/735], Loss: 0.4986\n",
      "Epoch [2/50], Step [584/735], Loss: 0.4328\n",
      "Epoch [2/50], Step [585/735], Loss: 0.3086\n",
      "Epoch [2/50], Step [586/735], Loss: 0.2398\n",
      "Epoch [2/50], Step [587/735], Loss: 0.4128\n",
      "Epoch [2/50], Step [588/735], Loss: 0.6059\n",
      "Epoch [2/50], Step [589/735], Loss: 0.3216\n",
      "Epoch [2/50], Step [590/735], Loss: 0.3013\n",
      "Epoch [2/50], Step [591/735], Loss: 0.4776\n",
      "Epoch [2/50], Step [592/735], Loss: 0.3571\n",
      "Epoch [2/50], Step [593/735], Loss: 0.3441\n",
      "Epoch [2/50], Step [594/735], Loss: 0.2987\n",
      "Epoch [2/50], Step [595/735], Loss: 0.2450\n",
      "Epoch [2/50], Step [596/735], Loss: 0.5389\n",
      "Epoch [2/50], Step [597/735], Loss: 0.3958\n",
      "Epoch [2/50], Step [598/735], Loss: 0.4711\n",
      "Epoch [2/50], Step [599/735], Loss: 0.5592\n",
      "Epoch [2/50], Step [600/735], Loss: 0.2771\n",
      "Epoch [2/50], Step [601/735], Loss: 0.2702\n",
      "Epoch [2/50], Step [602/735], Loss: 0.4159\n",
      "Epoch [2/50], Step [603/735], Loss: 0.3580\n",
      "Epoch [2/50], Step [604/735], Loss: 0.6697\n",
      "Epoch [2/50], Step [605/735], Loss: 0.5576\n",
      "Epoch [2/50], Step [606/735], Loss: 0.2360\n",
      "Epoch [2/50], Step [607/735], Loss: 0.3265\n",
      "Epoch [2/50], Step [608/735], Loss: 0.3375\n",
      "Epoch [2/50], Step [609/735], Loss: 0.2745\n",
      "Epoch [2/50], Step [610/735], Loss: 0.2720\n",
      "Epoch [2/50], Step [611/735], Loss: 0.9249\n",
      "Epoch [2/50], Step [612/735], Loss: 0.6877\n",
      "Epoch [2/50], Step [613/735], Loss: 0.5186\n",
      "Epoch [2/50], Step [614/735], Loss: 0.2342\n",
      "Epoch [2/50], Step [615/735], Loss: 0.3184\n",
      "Epoch [2/50], Step [616/735], Loss: 0.6343\n",
      "Epoch [2/50], Step [617/735], Loss: 0.2237\n",
      "Epoch [2/50], Step [618/735], Loss: 0.4701\n",
      "Epoch [2/50], Step [619/735], Loss: 0.4941\n",
      "Epoch [2/50], Step [620/735], Loss: 0.2925\n",
      "Epoch [2/50], Step [621/735], Loss: 0.5430\n",
      "Epoch [2/50], Step [622/735], Loss: 0.2853\n",
      "Epoch [2/50], Step [623/735], Loss: 0.2488\n",
      "Epoch [2/50], Step [624/735], Loss: 1.6648\n",
      "Epoch [2/50], Step [625/735], Loss: 0.2296\n",
      "Epoch [2/50], Step [626/735], Loss: 0.5146\n",
      "Epoch [2/50], Step [627/735], Loss: 0.3693\n",
      "Epoch [2/50], Step [628/735], Loss: 0.4095\n",
      "Epoch [2/50], Step [629/735], Loss: 0.3873\n",
      "Epoch [2/50], Step [630/735], Loss: 0.2758\n",
      "Epoch [2/50], Step [631/735], Loss: 0.1869\n",
      "Epoch [2/50], Step [632/735], Loss: 0.3410\n",
      "Epoch [2/50], Step [633/735], Loss: 2.1652\n",
      "Epoch [2/50], Step [634/735], Loss: 0.4394\n",
      "Epoch [2/50], Step [635/735], Loss: 0.4586\n",
      "Epoch [2/50], Step [636/735], Loss: 0.7465\n",
      "Epoch [2/50], Step [637/735], Loss: 0.7476\n",
      "Epoch [2/50], Step [638/735], Loss: 0.3706\n",
      "Epoch [2/50], Step [639/735], Loss: 0.3391\n",
      "Epoch [2/50], Step [640/735], Loss: 0.4090\n",
      "Epoch [2/50], Step [641/735], Loss: 0.4497\n",
      "Epoch [2/50], Step [642/735], Loss: 0.2826\n",
      "Epoch [2/50], Step [643/735], Loss: 0.2978\n",
      "Epoch [2/50], Step [644/735], Loss: 0.3469\n",
      "Epoch [2/50], Step [645/735], Loss: 0.3329\n",
      "Epoch [2/50], Step [646/735], Loss: 0.2799\n",
      "Epoch [2/50], Step [647/735], Loss: 0.6127\n",
      "Epoch [2/50], Step [648/735], Loss: 0.4918\n",
      "Epoch [2/50], Step [649/735], Loss: 0.3564\n",
      "Epoch [2/50], Step [650/735], Loss: 0.6110\n",
      "Epoch [2/50], Step [651/735], Loss: 1.0897\n",
      "Epoch [2/50], Step [652/735], Loss: 0.7158\n",
      "Epoch [2/50], Step [653/735], Loss: 0.3134\n",
      "Epoch [2/50], Step [654/735], Loss: 0.3993\n",
      "Epoch [2/50], Step [655/735], Loss: 0.2766\n",
      "Epoch [2/50], Step [656/735], Loss: 0.4482\n",
      "Epoch [2/50], Step [657/735], Loss: 0.3321\n",
      "Epoch [2/50], Step [658/735], Loss: 0.9805\n",
      "Epoch [2/50], Step [659/735], Loss: 0.6263\n",
      "Epoch [2/50], Step [660/735], Loss: 0.2183\n",
      "Epoch [2/50], Step [661/735], Loss: 0.4576\n",
      "Epoch [2/50], Step [662/735], Loss: 0.9776\n",
      "Epoch [2/50], Step [663/735], Loss: 0.3186\n",
      "Epoch [2/50], Step [664/735], Loss: 0.4613\n",
      "Epoch [2/50], Step [665/735], Loss: 0.7383\n",
      "Epoch [2/50], Step [666/735], Loss: 0.4321\n",
      "Epoch [2/50], Step [667/735], Loss: 1.1259\n",
      "Epoch [2/50], Step [668/735], Loss: 0.5447\n",
      "Epoch [2/50], Step [669/735], Loss: 0.7168\n",
      "Epoch [2/50], Step [670/735], Loss: 0.3891\n",
      "Epoch [2/50], Step [671/735], Loss: 0.3292\n",
      "Epoch [2/50], Step [672/735], Loss: 0.2127\n",
      "Epoch [2/50], Step [673/735], Loss: 0.5411\n",
      "Epoch [2/50], Step [674/735], Loss: 0.3346\n",
      "Epoch [2/50], Step [675/735], Loss: 0.2467\n",
      "Epoch [2/50], Step [676/735], Loss: 0.2683\n",
      "Epoch [2/50], Step [677/735], Loss: 0.2697\n",
      "Epoch [2/50], Step [678/735], Loss: 0.6622\n",
      "Epoch [2/50], Step [679/735], Loss: 0.3809\n",
      "Epoch [2/50], Step [680/735], Loss: 0.5263\n",
      "Epoch [2/50], Step [681/735], Loss: 0.3002\n",
      "Epoch [2/50], Step [682/735], Loss: 0.5986\n",
      "Epoch [2/50], Step [683/735], Loss: 0.2038\n",
      "Epoch [2/50], Step [684/735], Loss: 0.4288\n",
      "Epoch [2/50], Step [685/735], Loss: 0.6713\n",
      "Epoch [2/50], Step [686/735], Loss: 0.2443\n",
      "Epoch [2/50], Step [687/735], Loss: 0.2211\n",
      "Epoch [2/50], Step [688/735], Loss: 0.2395\n",
      "Epoch [2/50], Step [689/735], Loss: 0.2219\n",
      "Epoch [2/50], Step [690/735], Loss: 0.9966\n",
      "Epoch [2/50], Step [691/735], Loss: 0.6708\n",
      "Epoch [2/50], Step [692/735], Loss: 0.2758\n",
      "Epoch [2/50], Step [693/735], Loss: 0.4890\n",
      "Epoch [2/50], Step [694/735], Loss: 1.0391\n",
      "Epoch [2/50], Step [695/735], Loss: 0.2271\n",
      "Epoch [2/50], Step [696/735], Loss: 0.2199\n",
      "Epoch [2/50], Step [697/735], Loss: 0.6814\n",
      "Epoch [2/50], Step [698/735], Loss: 0.6387\n",
      "Epoch [2/50], Step [699/735], Loss: 0.2671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Step [700/735], Loss: 0.5215\n",
      "Epoch [2/50], Step [701/735], Loss: 0.4561\n",
      "Epoch [2/50], Step [702/735], Loss: 0.4697\n",
      "Epoch [2/50], Step [703/735], Loss: 0.2252\n",
      "Epoch [2/50], Step [704/735], Loss: 0.2908\n",
      "Epoch [2/50], Step [705/735], Loss: 0.8074\n",
      "Epoch [2/50], Step [706/735], Loss: 0.3795\n",
      "Epoch [2/50], Step [707/735], Loss: 0.4490\n",
      "Epoch [2/50], Step [708/735], Loss: 0.3022\n",
      "Epoch [2/50], Step [709/735], Loss: 0.3471\n",
      "Epoch [2/50], Step [710/735], Loss: 0.3792\n",
      "Epoch [2/50], Step [711/735], Loss: 0.2939\n",
      "Epoch [2/50], Step [712/735], Loss: 0.2242\n",
      "Epoch [2/50], Step [713/735], Loss: 0.2386\n",
      "Epoch [2/50], Step [714/735], Loss: 0.2754\n",
      "Epoch [2/50], Step [715/735], Loss: 0.2437\n",
      "Epoch [2/50], Step [716/735], Loss: 0.4955\n",
      "Epoch [2/50], Step [717/735], Loss: 0.7411\n",
      "Epoch [2/50], Step [718/735], Loss: 0.1932\n",
      "Epoch [2/50], Step [719/735], Loss: 0.4042\n",
      "Epoch [2/50], Step [720/735], Loss: 0.4494\n",
      "Epoch [2/50], Step [721/735], Loss: 0.5025\n",
      "Epoch [2/50], Step [722/735], Loss: 0.1796\n",
      "Epoch [2/50], Step [723/735], Loss: 0.7379\n",
      "Epoch [2/50], Step [724/735], Loss: 0.5358\n",
      "Epoch [2/50], Step [725/735], Loss: 0.2222\n",
      "Epoch [2/50], Step [726/735], Loss: 0.2869\n",
      "Epoch [2/50], Step [727/735], Loss: 0.2444\n",
      "Epoch [2/50], Step [728/735], Loss: 0.5593\n",
      "Epoch [2/50], Step [729/735], Loss: 0.3333\n",
      "Epoch [2/50], Step [730/735], Loss: 0.3046\n",
      "Epoch [2/50], Step [731/735], Loss: 0.2011\n",
      "Epoch [2/50], Step [732/735], Loss: 0.3220\n",
      "Epoch [2/50], Step [733/735], Loss: 0.2743\n",
      "Epoch [2/50], Step [734/735], Loss: 0.3160\n",
      "Epoch [2/50], Step [735/735], Loss: 0.1172\n",
      "Epoch [3/50], Step [1/735], Loss: 0.2599\n",
      "Epoch [3/50], Step [2/735], Loss: 0.2022\n",
      "Epoch [3/50], Step [3/735], Loss: 0.4105\n",
      "Epoch [3/50], Step [4/735], Loss: 0.6933\n",
      "Epoch [3/50], Step [5/735], Loss: 0.2492\n",
      "Epoch [3/50], Step [6/735], Loss: 0.9516\n",
      "Epoch [3/50], Step [7/735], Loss: 0.2383\n",
      "Epoch [3/50], Step [8/735], Loss: 0.3242\n",
      "Epoch [3/50], Step [9/735], Loss: 0.8677\n",
      "Epoch [3/50], Step [10/735], Loss: 0.8799\n",
      "Epoch [3/50], Step [11/735], Loss: 0.1998\n",
      "Epoch [3/50], Step [12/735], Loss: 0.2093\n",
      "Epoch [3/50], Step [13/735], Loss: 0.9247\n",
      "Epoch [3/50], Step [14/735], Loss: 0.2094\n",
      "Epoch [3/50], Step [15/735], Loss: 0.2731\n",
      "Epoch [3/50], Step [16/735], Loss: 0.3210\n",
      "Epoch [3/50], Step [17/735], Loss: 0.2304\n",
      "Epoch [3/50], Step [18/735], Loss: 0.2493\n",
      "Epoch [3/50], Step [19/735], Loss: 0.1610\n",
      "Epoch [3/50], Step [20/735], Loss: 0.2702\n",
      "Epoch [3/50], Step [21/735], Loss: 0.3605\n",
      "Epoch [3/50], Step [22/735], Loss: 0.2904\n",
      "Epoch [3/50], Step [23/735], Loss: 0.5931\n",
      "Epoch [3/50], Step [24/735], Loss: 0.3716\n",
      "Epoch [3/50], Step [25/735], Loss: 0.3313\n",
      "Epoch [3/50], Step [26/735], Loss: 0.5526\n",
      "Epoch [3/50], Step [27/735], Loss: 0.1526\n",
      "Epoch [3/50], Step [28/735], Loss: 0.4738\n",
      "Epoch [3/50], Step [29/735], Loss: 0.2522\n",
      "Epoch [3/50], Step [30/735], Loss: 0.2318\n",
      "Epoch [3/50], Step [31/735], Loss: 0.3667\n",
      "Epoch [3/50], Step [32/735], Loss: 0.2105\n",
      "Epoch [3/50], Step [33/735], Loss: 0.2140\n",
      "Epoch [3/50], Step [34/735], Loss: 0.3523\n",
      "Epoch [3/50], Step [35/735], Loss: 0.2239\n",
      "Epoch [3/50], Step [36/735], Loss: 0.2926\n",
      "Epoch [3/50], Step [37/735], Loss: 1.0475\n",
      "Epoch [3/50], Step [38/735], Loss: 1.0043\n",
      "Epoch [3/50], Step [39/735], Loss: 0.3161\n",
      "Epoch [3/50], Step [40/735], Loss: 0.1643\n",
      "Epoch [3/50], Step [41/735], Loss: 0.4082\n",
      "Epoch [3/50], Step [42/735], Loss: 0.2192\n",
      "Epoch [3/50], Step [43/735], Loss: 0.2719\n",
      "Epoch [3/50], Step [44/735], Loss: 0.2365\n",
      "Epoch [3/50], Step [45/735], Loss: 0.2576\n",
      "Epoch [3/50], Step [46/735], Loss: 0.3112\n",
      "Epoch [3/50], Step [47/735], Loss: 1.2184\n",
      "Epoch [3/50], Step [48/735], Loss: 0.7577\n",
      "Epoch [3/50], Step [49/735], Loss: 0.2269\n",
      "Epoch [3/50], Step [50/735], Loss: 0.5471\n",
      "Epoch [3/50], Step [51/735], Loss: 0.8552\n",
      "Epoch [3/50], Step [52/735], Loss: 0.2243\n",
      "Epoch [3/50], Step [53/735], Loss: 0.2676\n",
      "Epoch [3/50], Step [54/735], Loss: 0.2108\n",
      "Epoch [3/50], Step [55/735], Loss: 0.2259\n",
      "Epoch [3/50], Step [56/735], Loss: 0.5258\n",
      "Epoch [3/50], Step [57/735], Loss: 0.3122\n",
      "Epoch [3/50], Step [58/735], Loss: 0.2041\n",
      "Epoch [3/50], Step [59/735], Loss: 0.1947\n",
      "Epoch [3/50], Step [60/735], Loss: 0.3565\n",
      "Epoch [3/50], Step [61/735], Loss: 0.2704\n",
      "Epoch [3/50], Step [62/735], Loss: 0.3334\n",
      "Epoch [3/50], Step [63/735], Loss: 0.5366\n",
      "Epoch [3/50], Step [64/735], Loss: 0.4285\n",
      "Epoch [3/50], Step [65/735], Loss: 0.3815\n",
      "Epoch [3/50], Step [66/735], Loss: 0.2265\n",
      "Epoch [3/50], Step [67/735], Loss: 0.2156\n",
      "Epoch [3/50], Step [68/735], Loss: 0.4436\n",
      "Epoch [3/50], Step [69/735], Loss: 0.2288\n",
      "Epoch [3/50], Step [70/735], Loss: 0.1423\n",
      "Epoch [3/50], Step [71/735], Loss: 0.2725\n",
      "Epoch [3/50], Step [72/735], Loss: 0.3257\n",
      "Epoch [3/50], Step [73/735], Loss: 0.4337\n",
      "Epoch [3/50], Step [74/735], Loss: 0.1969\n",
      "Epoch [3/50], Step [75/735], Loss: 0.1736\n",
      "Epoch [3/50], Step [76/735], Loss: 0.4334\n",
      "Epoch [3/50], Step [77/735], Loss: 0.3692\n",
      "Epoch [3/50], Step [78/735], Loss: 0.1670\n",
      "Epoch [3/50], Step [79/735], Loss: 0.4207\n",
      "Epoch [3/50], Step [80/735], Loss: 0.5752\n",
      "Epoch [3/50], Step [81/735], Loss: 0.4412\n",
      "Epoch [3/50], Step [82/735], Loss: 0.3410\n",
      "Epoch [3/50], Step [83/735], Loss: 0.6814\n",
      "Epoch [3/50], Step [84/735], Loss: 0.2895\n",
      "Epoch [3/50], Step [85/735], Loss: 0.2262\n",
      "Epoch [3/50], Step [86/735], Loss: 0.2577\n",
      "Epoch [3/50], Step [87/735], Loss: 0.6749\n",
      "Epoch [3/50], Step [88/735], Loss: 0.2284\n",
      "Epoch [3/50], Step [89/735], Loss: 0.2064\n",
      "Epoch [3/50], Step [90/735], Loss: 0.3551\n",
      "Epoch [3/50], Step [91/735], Loss: 0.1658\n",
      "Epoch [3/50], Step [92/735], Loss: 0.4481\n",
      "Epoch [3/50], Step [93/735], Loss: 0.2397\n",
      "Epoch [3/50], Step [94/735], Loss: 0.1411\n",
      "Epoch [3/50], Step [95/735], Loss: 0.2954\n",
      "Epoch [3/50], Step [96/735], Loss: 0.1468\n",
      "Epoch [3/50], Step [97/735], Loss: 0.4808\n",
      "Epoch [3/50], Step [98/735], Loss: 0.3831\n",
      "Epoch [3/50], Step [99/735], Loss: 0.5404\n",
      "Epoch [3/50], Step [100/735], Loss: 0.2114\n",
      "Epoch [3/50], Step [101/735], Loss: 0.3864\n",
      "Epoch [3/50], Step [102/735], Loss: 0.3364\n",
      "Epoch [3/50], Step [103/735], Loss: 0.1325\n",
      "Epoch [3/50], Step [104/735], Loss: 0.1891\n",
      "Epoch [3/50], Step [105/735], Loss: 0.2572\n",
      "Epoch [3/50], Step [106/735], Loss: 0.2353\n",
      "Epoch [3/50], Step [107/735], Loss: 0.2454\n",
      "Epoch [3/50], Step [108/735], Loss: 0.1319\n",
      "Epoch [3/50], Step [109/735], Loss: 0.6138\n",
      "Epoch [3/50], Step [110/735], Loss: 0.2708\n",
      "Epoch [3/50], Step [111/735], Loss: 0.9596\n",
      "Epoch [3/50], Step [112/735], Loss: 0.2167\n",
      "Epoch [3/50], Step [113/735], Loss: 0.2399\n",
      "Epoch [3/50], Step [114/735], Loss: 0.2964\n",
      "Epoch [3/50], Step [115/735], Loss: 0.3155\n",
      "Epoch [3/50], Step [116/735], Loss: 0.2168\n",
      "Epoch [3/50], Step [117/735], Loss: 0.3806\n",
      "Epoch [3/50], Step [118/735], Loss: 0.2264\n",
      "Epoch [3/50], Step [119/735], Loss: 0.2559\n",
      "Epoch [3/50], Step [120/735], Loss: 0.3556\n",
      "Epoch [3/50], Step [121/735], Loss: 0.2480\n",
      "Epoch [3/50], Step [122/735], Loss: 0.4734\n",
      "Epoch [3/50], Step [123/735], Loss: 0.1328\n",
      "Epoch [3/50], Step [124/735], Loss: 0.6941\n",
      "Epoch [3/50], Step [125/735], Loss: 0.3675\n",
      "Epoch [3/50], Step [126/735], Loss: 0.2276\n",
      "Epoch [3/50], Step [127/735], Loss: 0.2344\n",
      "Epoch [3/50], Step [128/735], Loss: 0.1538\n",
      "Epoch [3/50], Step [129/735], Loss: 0.1186\n",
      "Epoch [3/50], Step [130/735], Loss: 0.1794\n",
      "Epoch [3/50], Step [131/735], Loss: 0.2696\n",
      "Epoch [3/50], Step [132/735], Loss: 0.2248\n",
      "Epoch [3/50], Step [133/735], Loss: 0.3937\n",
      "Epoch [3/50], Step [134/735], Loss: 0.2841\n",
      "Epoch [3/50], Step [135/735], Loss: 0.2386\n",
      "Epoch [3/50], Step [136/735], Loss: 0.2369\n",
      "Epoch [3/50], Step [137/735], Loss: 0.2828\n",
      "Epoch [3/50], Step [138/735], Loss: 0.1518\n",
      "Epoch [3/50], Step [139/735], Loss: 0.1715\n",
      "Epoch [3/50], Step [140/735], Loss: 0.2715\n",
      "Epoch [3/50], Step [141/735], Loss: 0.2066\n",
      "Epoch [3/50], Step [142/735], Loss: 0.3495\n",
      "Epoch [3/50], Step [143/735], Loss: 0.4356\n",
      "Epoch [3/50], Step [144/735], Loss: 0.2659\n",
      "Epoch [3/50], Step [145/735], Loss: 0.1865\n",
      "Epoch [3/50], Step [146/735], Loss: 0.1714\n",
      "Epoch [3/50], Step [147/735], Loss: 0.1811\n",
      "Epoch [3/50], Step [148/735], Loss: 0.4111\n",
      "Epoch [3/50], Step [149/735], Loss: 0.2945\n",
      "Epoch [3/50], Step [150/735], Loss: 0.2664\n",
      "Epoch [3/50], Step [151/735], Loss: 1.0988\n",
      "Epoch [3/50], Step [152/735], Loss: 0.3042\n",
      "Epoch [3/50], Step [153/735], Loss: 0.4038\n",
      "Epoch [3/50], Step [154/735], Loss: 0.4561\n",
      "Epoch [3/50], Step [155/735], Loss: 0.2689\n",
      "Epoch [3/50], Step [156/735], Loss: 0.5097\n",
      "Epoch [3/50], Step [157/735], Loss: 0.7186\n",
      "Epoch [3/50], Step [158/735], Loss: 0.1760\n",
      "Epoch [3/50], Step [159/735], Loss: 0.1656\n",
      "Epoch [3/50], Step [160/735], Loss: 0.6087\n",
      "Epoch [3/50], Step [161/735], Loss: 0.4080\n",
      "Epoch [3/50], Step [162/735], Loss: 0.1719\n",
      "Epoch [3/50], Step [163/735], Loss: 0.1868\n",
      "Epoch [3/50], Step [164/735], Loss: 1.4170\n",
      "Epoch [3/50], Step [165/735], Loss: 0.2575\n",
      "Epoch [3/50], Step [166/735], Loss: 0.4572\n",
      "Epoch [3/50], Step [167/735], Loss: 0.2682\n",
      "Epoch [3/50], Step [168/735], Loss: 0.2497\n",
      "Epoch [3/50], Step [169/735], Loss: 0.1826\n",
      "Epoch [3/50], Step [170/735], Loss: 0.3951\n",
      "Epoch [3/50], Step [171/735], Loss: 0.2169\n",
      "Epoch [3/50], Step [172/735], Loss: 0.2272\n",
      "Epoch [3/50], Step [173/735], Loss: 0.7267\n",
      "Epoch [3/50], Step [174/735], Loss: 0.2085\n",
      "Epoch [3/50], Step [175/735], Loss: 0.2033\n",
      "Epoch [3/50], Step [176/735], Loss: 0.3432\n",
      "Epoch [3/50], Step [177/735], Loss: 0.2077\n",
      "Epoch [3/50], Step [178/735], Loss: 0.2853\n",
      "Epoch [3/50], Step [179/735], Loss: 0.5646\n",
      "Epoch [3/50], Step [180/735], Loss: 0.3820\n",
      "Epoch [3/50], Step [181/735], Loss: 0.2627\n",
      "Epoch [3/50], Step [182/735], Loss: 0.3857\n",
      "Epoch [3/50], Step [183/735], Loss: 0.6717\n",
      "Epoch [3/50], Step [184/735], Loss: 0.6604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Step [185/735], Loss: 0.2483\n",
      "Epoch [3/50], Step [186/735], Loss: 0.2542\n",
      "Epoch [3/50], Step [187/735], Loss: 1.1296\n",
      "Epoch [3/50], Step [188/735], Loss: 0.2292\n",
      "Epoch [3/50], Step [189/735], Loss: 0.2308\n",
      "Epoch [3/50], Step [190/735], Loss: 0.3746\n",
      "Epoch [3/50], Step [191/735], Loss: 0.1798\n",
      "Epoch [3/50], Step [192/735], Loss: 0.2591\n",
      "Epoch [3/50], Step [193/735], Loss: 0.2489\n",
      "Epoch [3/50], Step [194/735], Loss: 0.2098\n",
      "Epoch [3/50], Step [195/735], Loss: 0.1810\n",
      "Epoch [3/50], Step [196/735], Loss: 0.2668\n",
      "Epoch [3/50], Step [197/735], Loss: 0.4173\n",
      "Epoch [3/50], Step [198/735], Loss: 0.5547\n",
      "Epoch [3/50], Step [199/735], Loss: 0.3313\n",
      "Epoch [3/50], Step [200/735], Loss: 0.2463\n",
      "Epoch [3/50], Step [201/735], Loss: 0.2853\n",
      "Epoch [3/50], Step [202/735], Loss: 0.2337\n",
      "Epoch [3/50], Step [203/735], Loss: 0.3030\n",
      "Epoch [3/50], Step [204/735], Loss: 0.1538\n",
      "Epoch [3/50], Step [205/735], Loss: 0.1889\n",
      "Epoch [3/50], Step [206/735], Loss: 0.3351\n",
      "Epoch [3/50], Step [207/735], Loss: 0.4998\n",
      "Epoch [3/50], Step [208/735], Loss: 0.4417\n",
      "Epoch [3/50], Step [209/735], Loss: 0.3544\n",
      "Epoch [3/50], Step [210/735], Loss: 0.1427\n",
      "Epoch [3/50], Step [211/735], Loss: 0.2434\n",
      "Epoch [3/50], Step [212/735], Loss: 0.3685\n",
      "Epoch [3/50], Step [213/735], Loss: 0.2251\n",
      "Epoch [3/50], Step [214/735], Loss: 0.1711\n",
      "Epoch [3/50], Step [215/735], Loss: 0.4186\n",
      "Epoch [3/50], Step [216/735], Loss: 0.2117\n",
      "Epoch [3/50], Step [217/735], Loss: 0.2159\n",
      "Epoch [3/50], Step [218/735], Loss: 0.3424\n",
      "Epoch [3/50], Step [219/735], Loss: 0.3059\n",
      "Epoch [3/50], Step [220/735], Loss: 0.3321\n",
      "Epoch [3/50], Step [221/735], Loss: 0.2098\n",
      "Epoch [3/50], Step [222/735], Loss: 1.5250\n",
      "Epoch [3/50], Step [223/735], Loss: 0.1814\n",
      "Epoch [3/50], Step [224/735], Loss: 0.2360\n",
      "Epoch [3/50], Step [225/735], Loss: 0.3304\n",
      "Epoch [3/50], Step [226/735], Loss: 0.1312\n",
      "Epoch [3/50], Step [227/735], Loss: 0.2271\n",
      "Epoch [3/50], Step [228/735], Loss: 0.1594\n",
      "Epoch [3/50], Step [229/735], Loss: 0.4561\n",
      "Epoch [3/50], Step [230/735], Loss: 0.2168\n",
      "Epoch [3/50], Step [231/735], Loss: 0.2559\n",
      "Epoch [3/50], Step [232/735], Loss: 0.5460\n",
      "Epoch [3/50], Step [233/735], Loss: 0.2343\n",
      "Epoch [3/50], Step [234/735], Loss: 1.2756\n",
      "Epoch [3/50], Step [235/735], Loss: 0.0949\n",
      "Epoch [3/50], Step [236/735], Loss: 0.1550\n",
      "Epoch [3/50], Step [237/735], Loss: 0.2023\n",
      "Epoch [3/50], Step [238/735], Loss: 0.4097\n",
      "Epoch [3/50], Step [239/735], Loss: 0.8041\n",
      "Epoch [3/50], Step [240/735], Loss: 0.3149\n",
      "Epoch [3/50], Step [241/735], Loss: 0.2827\n",
      "Epoch [3/50], Step [242/735], Loss: 0.2181\n",
      "Epoch [3/50], Step [243/735], Loss: 0.3118\n",
      "Epoch [3/50], Step [244/735], Loss: 0.5326\n",
      "Epoch [3/50], Step [245/735], Loss: 0.1863\n",
      "Epoch [3/50], Step [246/735], Loss: 0.4643\n",
      "Epoch [3/50], Step [247/735], Loss: 0.7059\n",
      "Epoch [3/50], Step [248/735], Loss: 0.3980\n",
      "Epoch [3/50], Step [249/735], Loss: 0.1967\n",
      "Epoch [3/50], Step [250/735], Loss: 0.3711\n",
      "Epoch [3/50], Step [251/735], Loss: 0.5221\n",
      "Epoch [3/50], Step [252/735], Loss: 0.2218\n",
      "Epoch [3/50], Step [253/735], Loss: 0.2978\n",
      "Epoch [3/50], Step [254/735], Loss: 0.1909\n",
      "Epoch [3/50], Step [255/735], Loss: 0.1759\n",
      "Epoch [3/50], Step [256/735], Loss: 0.1264\n",
      "Epoch [3/50], Step [257/735], Loss: 0.1291\n",
      "Epoch [3/50], Step [258/735], Loss: 0.1847\n",
      "Epoch [3/50], Step [259/735], Loss: 0.2556\n",
      "Epoch [3/50], Step [260/735], Loss: 0.2466\n",
      "Epoch [3/50], Step [261/735], Loss: 0.1656\n",
      "Epoch [3/50], Step [262/735], Loss: 0.2389\n",
      "Epoch [3/50], Step [263/735], Loss: 0.2687\n",
      "Epoch [3/50], Step [264/735], Loss: 0.1546\n",
      "Epoch [3/50], Step [265/735], Loss: 0.5375\n",
      "Epoch [3/50], Step [266/735], Loss: 0.4067\n",
      "Epoch [3/50], Step [267/735], Loss: 0.1757\n",
      "Epoch [3/50], Step [268/735], Loss: 0.4676\n",
      "Epoch [3/50], Step [269/735], Loss: 0.2252\n",
      "Epoch [3/50], Step [270/735], Loss: 0.1851\n",
      "Epoch [3/50], Step [271/735], Loss: 0.2804\n",
      "Epoch [3/50], Step [272/735], Loss: 0.2299\n",
      "Epoch [3/50], Step [273/735], Loss: 0.2477\n",
      "Epoch [3/50], Step [274/735], Loss: 0.2315\n",
      "Epoch [3/50], Step [275/735], Loss: 0.8217\n",
      "Epoch [3/50], Step [276/735], Loss: 0.3436\n",
      "Epoch [3/50], Step [277/735], Loss: 0.2120\n",
      "Epoch [3/50], Step [278/735], Loss: 0.1911\n",
      "Epoch [3/50], Step [279/735], Loss: 0.2574\n",
      "Epoch [3/50], Step [280/735], Loss: 0.1326\n",
      "Epoch [3/50], Step [281/735], Loss: 0.4521\n",
      "Epoch [3/50], Step [282/735], Loss: 0.1645\n",
      "Epoch [3/50], Step [283/735], Loss: 0.8180\n",
      "Epoch [3/50], Step [284/735], Loss: 0.2828\n",
      "Epoch [3/50], Step [285/735], Loss: 0.4775\n",
      "Epoch [3/50], Step [286/735], Loss: 0.1890\n",
      "Epoch [3/50], Step [287/735], Loss: 0.2804\n",
      "Epoch [3/50], Step [288/735], Loss: 0.2562\n",
      "Epoch [3/50], Step [289/735], Loss: 0.4879\n",
      "Epoch [3/50], Step [290/735], Loss: 0.3491\n",
      "Epoch [3/50], Step [291/735], Loss: 0.1833\n",
      "Epoch [3/50], Step [292/735], Loss: 0.1991\n",
      "Epoch [3/50], Step [293/735], Loss: 0.4790\n",
      "Epoch [3/50], Step [294/735], Loss: 0.2638\n",
      "Epoch [3/50], Step [295/735], Loss: 0.2129\n",
      "Epoch [3/50], Step [296/735], Loss: 0.1478\n",
      "Epoch [3/50], Step [297/735], Loss: 0.2051\n",
      "Epoch [3/50], Step [298/735], Loss: 0.5339\n",
      "Epoch [3/50], Step [299/735], Loss: 0.3059\n",
      "Epoch [3/50], Step [300/735], Loss: 0.3729\n",
      "Epoch [3/50], Step [301/735], Loss: 0.5109\n",
      "Epoch [3/50], Step [302/735], Loss: 0.4440\n",
      "Epoch [3/50], Step [303/735], Loss: 0.4723\n",
      "Epoch [3/50], Step [304/735], Loss: 0.2149\n",
      "Epoch [3/50], Step [305/735], Loss: 0.3263\n",
      "Epoch [3/50], Step [306/735], Loss: 0.1957\n",
      "Epoch [3/50], Step [307/735], Loss: 0.1511\n",
      "Epoch [3/50], Step [308/735], Loss: 0.2370\n",
      "Epoch [3/50], Step [309/735], Loss: 0.1919\n",
      "Epoch [3/50], Step [310/735], Loss: 0.3070\n",
      "Epoch [3/50], Step [311/735], Loss: 0.2294\n",
      "Epoch [3/50], Step [312/735], Loss: 0.1472\n",
      "Epoch [3/50], Step [313/735], Loss: 0.2063\n",
      "Epoch [3/50], Step [314/735], Loss: 0.3435\n",
      "Epoch [3/50], Step [315/735], Loss: 0.1106\n",
      "Epoch [3/50], Step [316/735], Loss: 0.2180\n",
      "Epoch [3/50], Step [317/735], Loss: 0.3439\n",
      "Epoch [3/50], Step [318/735], Loss: 0.2102\n",
      "Epoch [3/50], Step [319/735], Loss: 0.1785\n",
      "Epoch [3/50], Step [320/735], Loss: 0.1735\n",
      "Epoch [3/50], Step [321/735], Loss: 0.2412\n",
      "Epoch [3/50], Step [322/735], Loss: 0.1731\n",
      "Epoch [3/50], Step [323/735], Loss: 0.9000\n",
      "Epoch [3/50], Step [324/735], Loss: 0.1765\n",
      "Epoch [3/50], Step [325/735], Loss: 0.2208\n",
      "Epoch [3/50], Step [326/735], Loss: 0.2620\n",
      "Epoch [3/50], Step [327/735], Loss: 0.1681\n",
      "Epoch [3/50], Step [328/735], Loss: 0.9224\n",
      "Epoch [3/50], Step [329/735], Loss: 0.1320\n",
      "Epoch [3/50], Step [330/735], Loss: 0.1658\n",
      "Epoch [3/50], Step [331/735], Loss: 0.2383\n",
      "Epoch [3/50], Step [332/735], Loss: 0.6768\n",
      "Epoch [3/50], Step [333/735], Loss: 0.3581\n",
      "Epoch [3/50], Step [334/735], Loss: 0.6066\n",
      "Epoch [3/50], Step [335/735], Loss: 0.2261\n",
      "Epoch [3/50], Step [336/735], Loss: 0.3013\n",
      "Epoch [3/50], Step [337/735], Loss: 0.2194\n",
      "Epoch [3/50], Step [338/735], Loss: 0.3197\n",
      "Epoch [3/50], Step [339/735], Loss: 0.2557\n",
      "Epoch [3/50], Step [340/735], Loss: 0.1615\n",
      "Epoch [3/50], Step [341/735], Loss: 0.9072\n",
      "Epoch [3/50], Step [342/735], Loss: 0.5114\n",
      "Epoch [3/50], Step [343/735], Loss: 0.1299\n",
      "Epoch [3/50], Step [344/735], Loss: 0.3775\n",
      "Epoch [3/50], Step [345/735], Loss: 0.1638\n",
      "Epoch [3/50], Step [346/735], Loss: 0.1210\n",
      "Epoch [3/50], Step [347/735], Loss: 0.2063\n",
      "Epoch [3/50], Step [348/735], Loss: 0.3232\n",
      "Epoch [3/50], Step [349/735], Loss: 0.1488\n",
      "Epoch [3/50], Step [350/735], Loss: 0.1948\n",
      "Epoch [3/50], Step [351/735], Loss: 0.1666\n",
      "Epoch [3/50], Step [352/735], Loss: 0.2569\n",
      "Epoch [3/50], Step [353/735], Loss: 0.4685\n",
      "Epoch [3/50], Step [354/735], Loss: 0.1586\n",
      "Epoch [3/50], Step [355/735], Loss: 0.2505\n",
      "Epoch [3/50], Step [356/735], Loss: 0.2772\n",
      "Epoch [3/50], Step [357/735], Loss: 0.2791\n",
      "Epoch [3/50], Step [358/735], Loss: 0.1811\n",
      "Epoch [3/50], Step [359/735], Loss: 0.1222\n",
      "Epoch [3/50], Step [360/735], Loss: 0.5683\n",
      "Epoch [3/50], Step [361/735], Loss: 0.1947\n",
      "Epoch [3/50], Step [362/735], Loss: 0.2872\n",
      "Epoch [3/50], Step [363/735], Loss: 0.2168\n",
      "Epoch [3/50], Step [364/735], Loss: 0.4767\n",
      "Epoch [3/50], Step [365/735], Loss: 0.1283\n",
      "Epoch [3/50], Step [366/735], Loss: 0.6656\n",
      "Epoch [3/50], Step [367/735], Loss: 0.3894\n",
      "Epoch [3/50], Step [368/735], Loss: 0.1729\n",
      "Epoch [3/50], Step [369/735], Loss: 0.5570\n",
      "Epoch [3/50], Step [370/735], Loss: 0.2862\n",
      "Epoch [3/50], Step [371/735], Loss: 0.7248\n",
      "Epoch [3/50], Step [372/735], Loss: 0.2483\n",
      "Epoch [3/50], Step [373/735], Loss: 0.1643\n",
      "Epoch [3/50], Step [374/735], Loss: 0.1700\n",
      "Epoch [3/50], Step [375/735], Loss: 1.1014\n",
      "Epoch [3/50], Step [376/735], Loss: 1.2202\n",
      "Epoch [3/50], Step [377/735], Loss: 0.2231\n",
      "Epoch [3/50], Step [378/735], Loss: 0.1238\n",
      "Epoch [3/50], Step [379/735], Loss: 0.4782\n",
      "Epoch [3/50], Step [380/735], Loss: 0.2404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Step [381/735], Loss: 0.4210\n",
      "Epoch [3/50], Step [382/735], Loss: 0.3573\n",
      "Epoch [3/50], Step [383/735], Loss: 0.2132\n",
      "Epoch [3/50], Step [384/735], Loss: 0.3192\n",
      "Epoch [3/50], Step [385/735], Loss: 0.6857\n",
      "Epoch [3/50], Step [386/735], Loss: 0.2229\n",
      "Epoch [3/50], Step [387/735], Loss: 0.1641\n",
      "Epoch [3/50], Step [388/735], Loss: 0.3524\n",
      "Epoch [3/50], Step [389/735], Loss: 0.1215\n",
      "Epoch [3/50], Step [390/735], Loss: 0.2487\n",
      "Epoch [3/50], Step [391/735], Loss: 0.2294\n",
      "Epoch [3/50], Step [392/735], Loss: 0.4763\n",
      "Epoch [3/50], Step [393/735], Loss: 0.2930\n",
      "Epoch [3/50], Step [394/735], Loss: 0.1449\n",
      "Epoch [3/50], Step [395/735], Loss: 0.2334\n",
      "Epoch [3/50], Step [396/735], Loss: 1.2995\n",
      "Epoch [3/50], Step [397/735], Loss: 0.3628\n",
      "Epoch [3/50], Step [398/735], Loss: 0.4448\n",
      "Epoch [3/50], Step [399/735], Loss: 0.1666\n",
      "Epoch [3/50], Step [400/735], Loss: 0.1553\n",
      "Epoch [3/50], Step [401/735], Loss: 0.2749\n",
      "Epoch [3/50], Step [402/735], Loss: 0.3368\n",
      "Epoch [3/50], Step [403/735], Loss: 0.2356\n",
      "Epoch [3/50], Step [404/735], Loss: 0.5075\n",
      "Epoch [3/50], Step [405/735], Loss: 0.1839\n",
      "Epoch [3/50], Step [406/735], Loss: 0.3759\n",
      "Epoch [3/50], Step [407/735], Loss: 0.2073\n",
      "Epoch [3/50], Step [408/735], Loss: 0.4262\n",
      "Epoch [3/50], Step [409/735], Loss: 0.2320\n",
      "Epoch [3/50], Step [410/735], Loss: 0.1691\n",
      "Epoch [3/50], Step [411/735], Loss: 0.5509\n",
      "Epoch [3/50], Step [412/735], Loss: 0.4898\n",
      "Epoch [3/50], Step [413/735], Loss: 0.1372\n",
      "Epoch [3/50], Step [414/735], Loss: 0.1979\n",
      "Epoch [3/50], Step [415/735], Loss: 0.1675\n",
      "Epoch [3/50], Step [416/735], Loss: 0.1499\n",
      "Epoch [3/50], Step [417/735], Loss: 0.4817\n",
      "Epoch [3/50], Step [418/735], Loss: 0.2004\n",
      "Epoch [3/50], Step [419/735], Loss: 1.0156\n",
      "Epoch [3/50], Step [420/735], Loss: 0.1310\n",
      "Epoch [3/50], Step [421/735], Loss: 0.1622\n",
      "Epoch [3/50], Step [422/735], Loss: 0.4140\n",
      "Epoch [3/50], Step [423/735], Loss: 0.2118\n",
      "Epoch [3/50], Step [424/735], Loss: 0.2574\n",
      "Epoch [3/50], Step [425/735], Loss: 0.2262\n",
      "Epoch [3/50], Step [426/735], Loss: 0.2924\n",
      "Epoch [3/50], Step [427/735], Loss: 0.2280\n",
      "Epoch [3/50], Step [428/735], Loss: 0.5955\n",
      "Epoch [3/50], Step [429/735], Loss: 0.2014\n",
      "Epoch [3/50], Step [430/735], Loss: 1.1897\n",
      "Epoch [3/50], Step [431/735], Loss: 0.5675\n",
      "Epoch [3/50], Step [432/735], Loss: 0.8723\n",
      "Epoch [3/50], Step [433/735], Loss: 0.1269\n",
      "Epoch [3/50], Step [434/735], Loss: 0.2090\n",
      "Epoch [3/50], Step [435/735], Loss: 0.2338\n",
      "Epoch [3/50], Step [436/735], Loss: 0.2093\n",
      "Epoch [3/50], Step [437/735], Loss: 0.4248\n",
      "Epoch [3/50], Step [438/735], Loss: 0.1418\n",
      "Epoch [3/50], Step [439/735], Loss: 0.1287\n",
      "Epoch [3/50], Step [440/735], Loss: 0.1411\n",
      "Epoch [3/50], Step [441/735], Loss: 0.1300\n",
      "Epoch [3/50], Step [442/735], Loss: 0.1963\n",
      "Epoch [3/50], Step [443/735], Loss: 0.5773\n",
      "Epoch [3/50], Step [444/735], Loss: 0.2460\n",
      "Epoch [3/50], Step [445/735], Loss: 0.3804\n",
      "Epoch [3/50], Step [446/735], Loss: 0.6645\n",
      "Epoch [3/50], Step [447/735], Loss: 0.5575\n",
      "Epoch [3/50], Step [448/735], Loss: 0.1329\n",
      "Epoch [3/50], Step [449/735], Loss: 0.1703\n",
      "Epoch [3/50], Step [450/735], Loss: 0.3937\n",
      "Epoch [3/50], Step [451/735], Loss: 0.2056\n",
      "Epoch [3/50], Step [452/735], Loss: 1.0176\n",
      "Epoch [3/50], Step [453/735], Loss: 0.1363\n",
      "Epoch [3/50], Step [454/735], Loss: 0.2198\n",
      "Epoch [3/50], Step [455/735], Loss: 0.1513\n",
      "Epoch [3/50], Step [456/735], Loss: 0.6585\n",
      "Epoch [3/50], Step [457/735], Loss: 0.2611\n",
      "Epoch [3/50], Step [458/735], Loss: 0.3015\n",
      "Epoch [3/50], Step [459/735], Loss: 0.1951\n",
      "Epoch [3/50], Step [460/735], Loss: 0.0882\n",
      "Epoch [3/50], Step [461/735], Loss: 0.1809\n",
      "Epoch [3/50], Step [462/735], Loss: 0.1944\n",
      "Epoch [3/50], Step [463/735], Loss: 0.2236\n",
      "Epoch [3/50], Step [464/735], Loss: 0.3145\n",
      "Epoch [3/50], Step [465/735], Loss: 0.2298\n",
      "Epoch [3/50], Step [466/735], Loss: 0.2343\n",
      "Epoch [3/50], Step [467/735], Loss: 0.1863\n",
      "Epoch [3/50], Step [468/735], Loss: 0.1709\n",
      "Epoch [3/50], Step [469/735], Loss: 0.1726\n",
      "Epoch [3/50], Step [470/735], Loss: 0.1166\n",
      "Epoch [3/50], Step [471/735], Loss: 0.2092\n",
      "Epoch [3/50], Step [472/735], Loss: 0.2122\n",
      "Epoch [3/50], Step [473/735], Loss: 0.1122\n",
      "Epoch [3/50], Step [474/735], Loss: 0.2411\n",
      "Epoch [3/50], Step [475/735], Loss: 0.1813\n",
      "Epoch [3/50], Step [476/735], Loss: 0.4736\n",
      "Epoch [3/50], Step [477/735], Loss: 0.6338\n",
      "Epoch [3/50], Step [478/735], Loss: 0.1630\n",
      "Epoch [3/50], Step [479/735], Loss: 0.3285\n",
      "Epoch [3/50], Step [480/735], Loss: 0.1926\n",
      "Epoch [3/50], Step [481/735], Loss: 0.2298\n",
      "Epoch [3/50], Step [482/735], Loss: 0.0959\n",
      "Epoch [3/50], Step [483/735], Loss: 0.1470\n",
      "Epoch [3/50], Step [484/735], Loss: 1.2570\n",
      "Epoch [3/50], Step [485/735], Loss: 0.2952\n",
      "Epoch [3/50], Step [486/735], Loss: 0.2036\n",
      "Epoch [3/50], Step [487/735], Loss: 0.1245\n",
      "Epoch [3/50], Step [488/735], Loss: 0.2838\n",
      "Epoch [3/50], Step [489/735], Loss: 0.2698\n",
      "Epoch [3/50], Step [490/735], Loss: 0.2453\n",
      "Epoch [3/50], Step [491/735], Loss: 0.1836\n",
      "Epoch [3/50], Step [492/735], Loss: 0.2040\n",
      "Epoch [3/50], Step [493/735], Loss: 0.1648\n",
      "Epoch [3/50], Step [494/735], Loss: 0.2073\n",
      "Epoch [3/50], Step [495/735], Loss: 0.2213\n",
      "Epoch [3/50], Step [496/735], Loss: 0.5609\n",
      "Epoch [3/50], Step [497/735], Loss: 0.2150\n",
      "Epoch [3/50], Step [498/735], Loss: 0.1413\n",
      "Epoch [3/50], Step [499/735], Loss: 0.3847\n",
      "Epoch [3/50], Step [500/735], Loss: 0.1622\n",
      "Epoch [3/50], Step [501/735], Loss: 0.0918\n",
      "Epoch [3/50], Step [502/735], Loss: 0.4053\n",
      "Epoch [3/50], Step [503/735], Loss: 0.7157\n",
      "Epoch [3/50], Step [504/735], Loss: 0.4588\n",
      "Epoch [3/50], Step [505/735], Loss: 0.4212\n",
      "Epoch [3/50], Step [506/735], Loss: 0.2716\n",
      "Epoch [3/50], Step [507/735], Loss: 0.2551\n",
      "Epoch [3/50], Step [508/735], Loss: 0.4633\n",
      "Epoch [3/50], Step [509/735], Loss: 0.3189\n",
      "Epoch [3/50], Step [510/735], Loss: 0.1190\n",
      "Epoch [3/50], Step [511/735], Loss: 0.2576\n",
      "Epoch [3/50], Step [512/735], Loss: 0.1869\n",
      "Epoch [3/50], Step [513/735], Loss: 0.1856\n",
      "Epoch [3/50], Step [514/735], Loss: 0.1644\n",
      "Epoch [3/50], Step [515/735], Loss: 0.1390\n",
      "Epoch [3/50], Step [516/735], Loss: 0.2786\n",
      "Epoch [3/50], Step [517/735], Loss: 0.2271\n",
      "Epoch [3/50], Step [518/735], Loss: 0.2308\n",
      "Epoch [3/50], Step [519/735], Loss: 0.1773\n",
      "Epoch [3/50], Step [520/735], Loss: 0.1410\n",
      "Epoch [3/50], Step [521/735], Loss: 0.1751\n",
      "Epoch [3/50], Step [522/735], Loss: 0.2220\n",
      "Epoch [3/50], Step [523/735], Loss: 0.1387\n",
      "Epoch [3/50], Step [524/735], Loss: 0.1341\n",
      "Epoch [3/50], Step [525/735], Loss: 0.1748\n",
      "Epoch [3/50], Step [526/735], Loss: 0.3073\n",
      "Epoch [3/50], Step [527/735], Loss: 0.2795\n",
      "Epoch [3/50], Step [528/735], Loss: 0.6958\n",
      "Epoch [3/50], Step [529/735], Loss: 0.1343\n",
      "Epoch [3/50], Step [530/735], Loss: 0.1675\n",
      "Epoch [3/50], Step [531/735], Loss: 0.3788\n",
      "Epoch [3/50], Step [532/735], Loss: 0.1407\n",
      "Epoch [3/50], Step [533/735], Loss: 0.1915\n",
      "Epoch [3/50], Step [534/735], Loss: 0.1733\n",
      "Epoch [3/50], Step [535/735], Loss: 0.0966\n",
      "Epoch [3/50], Step [536/735], Loss: 0.4332\n",
      "Epoch [3/50], Step [537/735], Loss: 0.1249\n",
      "Epoch [3/50], Step [538/735], Loss: 0.1313\n",
      "Epoch [3/50], Step [539/735], Loss: 0.2337\n",
      "Epoch [3/50], Step [540/735], Loss: 0.4547\n",
      "Epoch [3/50], Step [541/735], Loss: 0.2122\n",
      "Epoch [3/50], Step [542/735], Loss: 0.1556\n",
      "Epoch [3/50], Step [543/735], Loss: 0.4454\n",
      "Epoch [3/50], Step [544/735], Loss: 0.3343\n",
      "Epoch [3/50], Step [545/735], Loss: 0.1721\n",
      "Epoch [3/50], Step [546/735], Loss: 0.9764\n",
      "Epoch [3/50], Step [547/735], Loss: 0.3654\n",
      "Epoch [3/50], Step [548/735], Loss: 0.1375\n",
      "Epoch [3/50], Step [549/735], Loss: 0.1438\n",
      "Epoch [3/50], Step [550/735], Loss: 0.1143\n",
      "Epoch [3/50], Step [551/735], Loss: 0.2480\n",
      "Epoch [3/50], Step [552/735], Loss: 0.1450\n",
      "Epoch [3/50], Step [553/735], Loss: 0.9339\n",
      "Epoch [3/50], Step [554/735], Loss: 0.1752\n",
      "Epoch [3/50], Step [555/735], Loss: 0.1681\n",
      "Epoch [3/50], Step [556/735], Loss: 0.1205\n",
      "Epoch [3/50], Step [557/735], Loss: 0.5281\n",
      "Epoch [3/50], Step [558/735], Loss: 0.2662\n",
      "Epoch [3/50], Step [559/735], Loss: 0.5513\n",
      "Epoch [3/50], Step [560/735], Loss: 0.1710\n",
      "Epoch [3/50], Step [561/735], Loss: 0.4766\n",
      "Epoch [3/50], Step [562/735], Loss: 0.1810\n",
      "Epoch [3/50], Step [563/735], Loss: 0.4745\n",
      "Epoch [3/50], Step [564/735], Loss: 0.8159\n",
      "Epoch [3/50], Step [565/735], Loss: 0.1164\n",
      "Epoch [3/50], Step [566/735], Loss: 0.2430\n",
      "Epoch [3/50], Step [567/735], Loss: 0.2605\n",
      "Epoch [3/50], Step [568/735], Loss: 0.1367\n",
      "Epoch [3/50], Step [569/735], Loss: 0.1665\n",
      "Epoch [3/50], Step [570/735], Loss: 0.3621\n",
      "Epoch [3/50], Step [571/735], Loss: 0.1280\n",
      "Epoch [3/50], Step [572/735], Loss: 0.2887\n",
      "Epoch [3/50], Step [573/735], Loss: 0.8326\n",
      "Epoch [3/50], Step [574/735], Loss: 0.1206\n",
      "Epoch [3/50], Step [575/735], Loss: 1.1367\n",
      "Epoch [3/50], Step [576/735], Loss: 0.2369\n",
      "Epoch [3/50], Step [577/735], Loss: 0.3055\n",
      "Epoch [3/50], Step [578/735], Loss: 0.2701\n",
      "Epoch [3/50], Step [579/735], Loss: 0.0789\n",
      "Epoch [3/50], Step [580/735], Loss: 0.2186\n",
      "Epoch [3/50], Step [581/735], Loss: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Step [582/735], Loss: 0.2974\n",
      "Epoch [3/50], Step [583/735], Loss: 0.1828\n",
      "Epoch [3/50], Step [584/735], Loss: 0.8503\n",
      "Epoch [3/50], Step [585/735], Loss: 0.2732\n",
      "Epoch [3/50], Step [586/735], Loss: 0.3366\n",
      "Epoch [3/50], Step [587/735], Loss: 0.1667\n",
      "Epoch [3/50], Step [588/735], Loss: 0.1513\n",
      "Epoch [3/50], Step [589/735], Loss: 0.2346\n",
      "Epoch [3/50], Step [590/735], Loss: 0.3615\n",
      "Epoch [3/50], Step [591/735], Loss: 0.2227\n",
      "Epoch [3/50], Step [592/735], Loss: 0.1559\n",
      "Epoch [3/50], Step [593/735], Loss: 0.1382\n",
      "Epoch [3/50], Step [594/735], Loss: 0.4606\n",
      "Epoch [3/50], Step [595/735], Loss: 0.1646\n",
      "Epoch [3/50], Step [596/735], Loss: 0.2581\n",
      "Epoch [3/50], Step [597/735], Loss: 0.1194\n",
      "Epoch [3/50], Step [598/735], Loss: 0.2213\n",
      "Epoch [3/50], Step [599/735], Loss: 0.1196\n",
      "Epoch [3/50], Step [600/735], Loss: 0.1266\n",
      "Epoch [3/50], Step [601/735], Loss: 0.2178\n",
      "Epoch [3/50], Step [602/735], Loss: 0.2023\n",
      "Epoch [3/50], Step [603/735], Loss: 0.5069\n",
      "Epoch [3/50], Step [604/735], Loss: 0.4119\n",
      "Epoch [3/50], Step [605/735], Loss: 0.2275\n",
      "Epoch [3/50], Step [606/735], Loss: 0.1081\n",
      "Epoch [3/50], Step [607/735], Loss: 0.1914\n",
      "Epoch [3/50], Step [608/735], Loss: 0.5229\n",
      "Epoch [3/50], Step [609/735], Loss: 0.1775\n",
      "Epoch [3/50], Step [610/735], Loss: 0.1905\n",
      "Epoch [3/50], Step [611/735], Loss: 0.4375\n",
      "Epoch [3/50], Step [612/735], Loss: 0.1918\n",
      "Epoch [3/50], Step [613/735], Loss: 0.7074\n",
      "Epoch [3/50], Step [614/735], Loss: 0.2230\n",
      "Epoch [3/50], Step [615/735], Loss: 0.4199\n",
      "Epoch [3/50], Step [616/735], Loss: 0.1115\n",
      "Epoch [3/50], Step [617/735], Loss: 0.1471\n",
      "Epoch [3/50], Step [618/735], Loss: 0.3300\n",
      "Epoch [3/50], Step [619/735], Loss: 0.2363\n",
      "Epoch [3/50], Step [620/735], Loss: 0.6258\n",
      "Epoch [3/50], Step [621/735], Loss: 0.3331\n",
      "Epoch [3/50], Step [622/735], Loss: 0.1532\n",
      "Epoch [3/50], Step [623/735], Loss: 0.1326\n",
      "Epoch [3/50], Step [624/735], Loss: 0.1005\n",
      "Epoch [3/50], Step [625/735], Loss: 0.1679\n",
      "Epoch [3/50], Step [626/735], Loss: 0.2194\n",
      "Epoch [3/50], Step [627/735], Loss: 0.0809\n",
      "Epoch [3/50], Step [628/735], Loss: 0.1245\n",
      "Epoch [3/50], Step [629/735], Loss: 0.4135\n",
      "Epoch [3/50], Step [630/735], Loss: 0.6702\n",
      "Epoch [3/50], Step [631/735], Loss: 0.1284\n",
      "Epoch [3/50], Step [632/735], Loss: 0.1642\n",
      "Epoch [3/50], Step [633/735], Loss: 0.2449\n",
      "Epoch [3/50], Step [634/735], Loss: 0.0852\n",
      "Epoch [3/50], Step [635/735], Loss: 0.1810\n",
      "Epoch [3/50], Step [636/735], Loss: 0.4350\n",
      "Epoch [3/50], Step [637/735], Loss: 0.1753\n",
      "Epoch [3/50], Step [638/735], Loss: 0.2503\n",
      "Epoch [3/50], Step [639/735], Loss: 0.1796\n",
      "Epoch [3/50], Step [640/735], Loss: 0.3116\n",
      "Epoch [3/50], Step [641/735], Loss: 0.1764\n",
      "Epoch [3/50], Step [642/735], Loss: 0.2918\n",
      "Epoch [3/50], Step [643/735], Loss: 0.2249\n",
      "Epoch [3/50], Step [644/735], Loss: 0.1554\n",
      "Epoch [3/50], Step [645/735], Loss: 0.2013\n",
      "Epoch [3/50], Step [646/735], Loss: 0.1813\n",
      "Epoch [3/50], Step [647/735], Loss: 0.2864\n",
      "Epoch [3/50], Step [648/735], Loss: 0.1454\n",
      "Epoch [3/50], Step [649/735], Loss: 0.1289\n",
      "Epoch [3/50], Step [650/735], Loss: 0.3009\n",
      "Epoch [3/50], Step [651/735], Loss: 0.1841\n",
      "Epoch [3/50], Step [652/735], Loss: 0.3917\n",
      "Epoch [3/50], Step [653/735], Loss: 0.2383\n",
      "Epoch [3/50], Step [654/735], Loss: 0.3615\n",
      "Epoch [3/50], Step [655/735], Loss: 0.2594\n",
      "Epoch [3/50], Step [656/735], Loss: 0.1844\n",
      "Epoch [3/50], Step [657/735], Loss: 0.1926\n",
      "Epoch [3/50], Step [658/735], Loss: 0.2409\n",
      "Epoch [3/50], Step [659/735], Loss: 0.1142\n",
      "Epoch [3/50], Step [660/735], Loss: 0.1531\n",
      "Epoch [3/50], Step [661/735], Loss: 0.1672\n",
      "Epoch [3/50], Step [662/735], Loss: 0.2495\n",
      "Epoch [3/50], Step [663/735], Loss: 0.1508\n",
      "Epoch [3/50], Step [664/735], Loss: 0.1950\n",
      "Epoch [3/50], Step [665/735], Loss: 0.4152\n",
      "Epoch [3/50], Step [666/735], Loss: 0.1467\n",
      "Epoch [3/50], Step [667/735], Loss: 0.2196\n",
      "Epoch [3/50], Step [668/735], Loss: 0.2414\n",
      "Epoch [3/50], Step [669/735], Loss: 0.0786\n",
      "Epoch [3/50], Step [670/735], Loss: 0.7299\n",
      "Epoch [3/50], Step [671/735], Loss: 0.4372\n",
      "Epoch [3/50], Step [672/735], Loss: 0.1247\n",
      "Epoch [3/50], Step [673/735], Loss: 0.1160\n",
      "Epoch [3/50], Step [674/735], Loss: 0.1158\n",
      "Epoch [3/50], Step [675/735], Loss: 0.1479\n",
      "Epoch [3/50], Step [676/735], Loss: 0.7657\n",
      "Epoch [3/50], Step [677/735], Loss: 0.2938\n",
      "Epoch [3/50], Step [678/735], Loss: 0.1219\n",
      "Epoch [3/50], Step [679/735], Loss: 0.4886\n",
      "Epoch [3/50], Step [680/735], Loss: 0.2987\n",
      "Epoch [3/50], Step [681/735], Loss: 0.9562\n",
      "Epoch [3/50], Step [682/735], Loss: 0.1309\n",
      "Epoch [3/50], Step [683/735], Loss: 0.1183\n",
      "Epoch [3/50], Step [684/735], Loss: 0.1245\n",
      "Epoch [3/50], Step [685/735], Loss: 0.3821\n",
      "Epoch [3/50], Step [686/735], Loss: 0.4093\n",
      "Epoch [3/50], Step [687/735], Loss: 0.1087\n",
      "Epoch [3/50], Step [688/735], Loss: 0.6930\n",
      "Epoch [3/50], Step [689/735], Loss: 0.1603\n",
      "Epoch [3/50], Step [690/735], Loss: 0.1430\n",
      "Epoch [3/50], Step [691/735], Loss: 0.1502\n",
      "Epoch [3/50], Step [692/735], Loss: 0.1776\n",
      "Epoch [3/50], Step [693/735], Loss: 0.1625\n",
      "Epoch [3/50], Step [694/735], Loss: 0.1589\n",
      "Epoch [3/50], Step [695/735], Loss: 0.1253\n",
      "Epoch [3/50], Step [696/735], Loss: 0.1098\n",
      "Epoch [3/50], Step [697/735], Loss: 0.1444\n",
      "Epoch [3/50], Step [698/735], Loss: 0.0758\n",
      "Epoch [3/50], Step [699/735], Loss: 0.1433\n",
      "Epoch [3/50], Step [700/735], Loss: 0.1224\n",
      "Epoch [3/50], Step [701/735], Loss: 0.1806\n",
      "Epoch [3/50], Step [702/735], Loss: 0.1638\n",
      "Epoch [3/50], Step [703/735], Loss: 0.0789\n",
      "Epoch [3/50], Step [704/735], Loss: 0.1863\n",
      "Epoch [3/50], Step [705/735], Loss: 0.1862\n",
      "Epoch [3/50], Step [706/735], Loss: 0.1265\n",
      "Epoch [3/50], Step [707/735], Loss: 0.1522\n",
      "Epoch [3/50], Step [708/735], Loss: 0.1318\n",
      "Epoch [3/50], Step [709/735], Loss: 0.1540\n",
      "Epoch [3/50], Step [710/735], Loss: 0.1402\n",
      "Epoch [3/50], Step [711/735], Loss: 0.2122\n",
      "Epoch [3/50], Step [712/735], Loss: 0.5600\n",
      "Epoch [3/50], Step [713/735], Loss: 0.1831\n",
      "Epoch [3/50], Step [714/735], Loss: 0.1464\n",
      "Epoch [3/50], Step [715/735], Loss: 0.1803\n",
      "Epoch [3/50], Step [716/735], Loss: 0.1176\n",
      "Epoch [3/50], Step [717/735], Loss: 0.1761\n",
      "Epoch [3/50], Step [718/735], Loss: 0.2545\n",
      "Epoch [3/50], Step [719/735], Loss: 0.2769\n",
      "Epoch [3/50], Step [720/735], Loss: 0.1482\n",
      "Epoch [3/50], Step [721/735], Loss: 0.2638\n",
      "Epoch [3/50], Step [722/735], Loss: 0.6052\n",
      "Epoch [3/50], Step [723/735], Loss: 0.2864\n",
      "Epoch [3/50], Step [724/735], Loss: 0.3756\n",
      "Epoch [3/50], Step [725/735], Loss: 0.1017\n",
      "Epoch [3/50], Step [726/735], Loss: 0.1359\n",
      "Epoch [3/50], Step [727/735], Loss: 0.0673\n",
      "Epoch [3/50], Step [728/735], Loss: 0.2190\n",
      "Epoch [3/50], Step [729/735], Loss: 0.2440\n",
      "Epoch [3/50], Step [730/735], Loss: 0.1184\n",
      "Epoch [3/50], Step [731/735], Loss: 0.0811\n",
      "Epoch [3/50], Step [732/735], Loss: 0.1281\n",
      "Epoch [3/50], Step [733/735], Loss: 0.3778\n",
      "Epoch [3/50], Step [734/735], Loss: 0.1647\n",
      "Epoch [3/50], Step [735/735], Loss: 0.0903\n",
      "Epoch [4/50], Step [1/735], Loss: 0.1362\n",
      "Epoch [4/50], Step [2/735], Loss: 0.5426\n",
      "Epoch [4/50], Step [3/735], Loss: 1.0086\n",
      "Epoch [4/50], Step [4/735], Loss: 0.3604\n",
      "Epoch [4/50], Step [5/735], Loss: 0.2708\n",
      "Epoch [4/50], Step [6/735], Loss: 0.3925\n",
      "Epoch [4/50], Step [7/735], Loss: 0.1276\n",
      "Epoch [4/50], Step [8/735], Loss: 0.3558\n",
      "Epoch [4/50], Step [9/735], Loss: 0.1379\n",
      "Epoch [4/50], Step [10/735], Loss: 0.1488\n",
      "Epoch [4/50], Step [11/735], Loss: 0.4213\n",
      "Epoch [4/50], Step [12/735], Loss: 0.1223\n",
      "Epoch [4/50], Step [13/735], Loss: 0.1046\n",
      "Epoch [4/50], Step [14/735], Loss: 0.2471\n",
      "Epoch [4/50], Step [15/735], Loss: 0.1057\n",
      "Epoch [4/50], Step [16/735], Loss: 0.2198\n",
      "Epoch [4/50], Step [17/735], Loss: 0.1038\n",
      "Epoch [4/50], Step [18/735], Loss: 0.1455\n",
      "Epoch [4/50], Step [19/735], Loss: 0.2227\n",
      "Epoch [4/50], Step [20/735], Loss: 0.3081\n",
      "Epoch [4/50], Step [21/735], Loss: 0.7183\n",
      "Epoch [4/50], Step [22/735], Loss: 0.1555\n",
      "Epoch [4/50], Step [23/735], Loss: 0.3482\n",
      "Epoch [4/50], Step [24/735], Loss: 0.1362\n",
      "Epoch [4/50], Step [25/735], Loss: 0.1324\n",
      "Epoch [4/50], Step [26/735], Loss: 0.2099\n",
      "Epoch [4/50], Step [27/735], Loss: 0.2898\n",
      "Epoch [4/50], Step [28/735], Loss: 0.0738\n",
      "Epoch [4/50], Step [29/735], Loss: 0.1151\n",
      "Epoch [4/50], Step [30/735], Loss: 0.2717\n",
      "Epoch [4/50], Step [31/735], Loss: 0.1481\n",
      "Epoch [4/50], Step [32/735], Loss: 0.2185\n",
      "Epoch [4/50], Step [33/735], Loss: 0.3499\n",
      "Epoch [4/50], Step [34/735], Loss: 0.4645\n",
      "Epoch [4/50], Step [35/735], Loss: 0.3388\n",
      "Epoch [4/50], Step [36/735], Loss: 0.1427\n",
      "Epoch [4/50], Step [37/735], Loss: 0.1544\n",
      "Epoch [4/50], Step [38/735], Loss: 0.1158\n",
      "Epoch [4/50], Step [39/735], Loss: 0.1559\n",
      "Epoch [4/50], Step [40/735], Loss: 0.7587\n",
      "Epoch [4/50], Step [41/735], Loss: 0.1999\n",
      "Epoch [4/50], Step [42/735], Loss: 0.1211\n",
      "Epoch [4/50], Step [43/735], Loss: 0.1040\n",
      "Epoch [4/50], Step [44/735], Loss: 0.1180\n",
      "Epoch [4/50], Step [45/735], Loss: 0.0758\n",
      "Epoch [4/50], Step [46/735], Loss: 0.1143\n",
      "Epoch [4/50], Step [47/735], Loss: 0.2041\n",
      "Epoch [4/50], Step [48/735], Loss: 0.1280\n",
      "Epoch [4/50], Step [49/735], Loss: 0.1514\n",
      "Epoch [4/50], Step [50/735], Loss: 0.1357\n",
      "Epoch [4/50], Step [51/735], Loss: 0.1664\n",
      "Epoch [4/50], Step [52/735], Loss: 0.2174\n",
      "Epoch [4/50], Step [53/735], Loss: 0.2174\n",
      "Epoch [4/50], Step [54/735], Loss: 0.6139\n",
      "Epoch [4/50], Step [55/735], Loss: 0.2118\n",
      "Epoch [4/50], Step [56/735], Loss: 0.2677\n",
      "Epoch [4/50], Step [57/735], Loss: 0.1682\n",
      "Epoch [4/50], Step [58/735], Loss: 0.1008\n",
      "Epoch [4/50], Step [59/735], Loss: 0.3131\n",
      "Epoch [4/50], Step [60/735], Loss: 0.2012\n",
      "Epoch [4/50], Step [61/735], Loss: 0.2318\n",
      "Epoch [4/50], Step [62/735], Loss: 0.1180\n",
      "Epoch [4/50], Step [63/735], Loss: 0.3001\n",
      "Epoch [4/50], Step [64/735], Loss: 0.2674\n",
      "Epoch [4/50], Step [65/735], Loss: 0.1795\n",
      "Epoch [4/50], Step [66/735], Loss: 0.1949\n",
      "Epoch [4/50], Step [67/735], Loss: 0.1300\n",
      "Epoch [4/50], Step [68/735], Loss: 0.2045\n",
      "Epoch [4/50], Step [69/735], Loss: 0.1086\n",
      "Epoch [4/50], Step [70/735], Loss: 0.1490\n",
      "Epoch [4/50], Step [71/735], Loss: 0.1946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Step [72/735], Loss: 0.1305\n",
      "Epoch [4/50], Step [73/735], Loss: 0.3207\n",
      "Epoch [4/50], Step [74/735], Loss: 0.2177\n",
      "Epoch [4/50], Step [75/735], Loss: 0.1766\n",
      "Epoch [4/50], Step [76/735], Loss: 0.1796\n",
      "Epoch [4/50], Step [77/735], Loss: 0.2738\n",
      "Epoch [4/50], Step [78/735], Loss: 0.1607\n",
      "Epoch [4/50], Step [79/735], Loss: 0.3823\n",
      "Epoch [4/50], Step [80/735], Loss: 0.1044\n",
      "Epoch [4/50], Step [81/735], Loss: 0.2247\n",
      "Epoch [4/50], Step [82/735], Loss: 0.1004\n",
      "Epoch [4/50], Step [83/735], Loss: 0.1259\n",
      "Epoch [4/50], Step [84/735], Loss: 0.3315\n",
      "Epoch [4/50], Step [85/735], Loss: 0.1917\n",
      "Epoch [4/50], Step [86/735], Loss: 0.1145\n",
      "Epoch [4/50], Step [87/735], Loss: 0.3819\n",
      "Epoch [4/50], Step [88/735], Loss: 0.1186\n",
      "Epoch [4/50], Step [89/735], Loss: 0.1552\n",
      "Epoch [4/50], Step [90/735], Loss: 0.1107\n",
      "Epoch [4/50], Step [91/735], Loss: 0.1407\n",
      "Epoch [4/50], Step [92/735], Loss: 0.4963\n",
      "Epoch [4/50], Step [93/735], Loss: 0.4825\n",
      "Epoch [4/50], Step [94/735], Loss: 0.1187\n",
      "Epoch [4/50], Step [95/735], Loss: 0.2075\n",
      "Epoch [4/50], Step [96/735], Loss: 0.2875\n",
      "Epoch [4/50], Step [97/735], Loss: 0.1697\n",
      "Epoch [4/50], Step [98/735], Loss: 0.1354\n",
      "Epoch [4/50], Step [99/735], Loss: 0.1129\n",
      "Epoch [4/50], Step [100/735], Loss: 0.1666\n",
      "Epoch [4/50], Step [101/735], Loss: 0.4342\n",
      "Epoch [4/50], Step [102/735], Loss: 0.3105\n",
      "Epoch [4/50], Step [103/735], Loss: 0.1383\n",
      "Epoch [4/50], Step [104/735], Loss: 0.1305\n",
      "Epoch [4/50], Step [105/735], Loss: 0.1624\n",
      "Epoch [4/50], Step [106/735], Loss: 0.1170\n",
      "Epoch [4/50], Step [107/735], Loss: 0.2594\n",
      "Epoch [4/50], Step [108/735], Loss: 0.2972\n",
      "Epoch [4/50], Step [109/735], Loss: 0.1579\n",
      "Epoch [4/50], Step [110/735], Loss: 0.1487\n",
      "Epoch [4/50], Step [111/735], Loss: 0.1882\n",
      "Epoch [4/50], Step [112/735], Loss: 0.0999\n",
      "Epoch [4/50], Step [113/735], Loss: 0.4156\n",
      "Epoch [4/50], Step [114/735], Loss: 0.1584\n",
      "Epoch [4/50], Step [115/735], Loss: 0.2189\n",
      "Epoch [4/50], Step [116/735], Loss: 0.1549\n",
      "Epoch [4/50], Step [117/735], Loss: 0.1016\n",
      "Epoch [4/50], Step [118/735], Loss: 0.1275\n",
      "Epoch [4/50], Step [119/735], Loss: 0.0960\n",
      "Epoch [4/50], Step [120/735], Loss: 0.1642\n",
      "Epoch [4/50], Step [121/735], Loss: 0.0828\n",
      "Epoch [4/50], Step [122/735], Loss: 0.1855\n",
      "Epoch [4/50], Step [123/735], Loss: 0.0946\n",
      "Epoch [4/50], Step [124/735], Loss: 0.1428\n",
      "Epoch [4/50], Step [125/735], Loss: 0.2349\n",
      "Epoch [4/50], Step [126/735], Loss: 0.2687\n",
      "Epoch [4/50], Step [127/735], Loss: 1.5065\n",
      "Epoch [4/50], Step [128/735], Loss: 0.9795\n",
      "Epoch [4/50], Step [129/735], Loss: 0.1348\n",
      "Epoch [4/50], Step [130/735], Loss: 0.3352\n",
      "Epoch [4/50], Step [131/735], Loss: 0.1444\n",
      "Epoch [4/50], Step [132/735], Loss: 0.4472\n",
      "Epoch [4/50], Step [133/735], Loss: 0.1590\n",
      "Epoch [4/50], Step [134/735], Loss: 0.0953\n",
      "Epoch [4/50], Step [135/735], Loss: 0.1409\n",
      "Epoch [4/50], Step [136/735], Loss: 0.2380\n",
      "Epoch [4/50], Step [137/735], Loss: 0.3186\n",
      "Epoch [4/50], Step [138/735], Loss: 0.2263\n",
      "Epoch [4/50], Step [139/735], Loss: 0.1027\n",
      "Epoch [4/50], Step [140/735], Loss: 0.2790\n",
      "Epoch [4/50], Step [141/735], Loss: 0.1098\n",
      "Epoch [4/50], Step [142/735], Loss: 0.0950\n",
      "Epoch [4/50], Step [143/735], Loss: 0.2741\n",
      "Epoch [4/50], Step [144/735], Loss: 0.1248\n",
      "Epoch [4/50], Step [145/735], Loss: 0.3130\n",
      "Epoch [4/50], Step [146/735], Loss: 0.1728\n",
      "Epoch [4/50], Step [147/735], Loss: 0.2036\n",
      "Epoch [4/50], Step [148/735], Loss: 0.1449\n",
      "Epoch [4/50], Step [149/735], Loss: 0.2548\n",
      "Epoch [4/50], Step [150/735], Loss: 0.0899\n",
      "Epoch [4/50], Step [151/735], Loss: 0.1879\n",
      "Epoch [4/50], Step [152/735], Loss: 0.1571\n",
      "Epoch [4/50], Step [153/735], Loss: 0.2683\n",
      "Epoch [4/50], Step [154/735], Loss: 0.1194\n",
      "Epoch [4/50], Step [155/735], Loss: 0.2006\n",
      "Epoch [4/50], Step [156/735], Loss: 0.1685\n",
      "Epoch [4/50], Step [157/735], Loss: 0.1214\n",
      "Epoch [4/50], Step [158/735], Loss: 0.1341\n",
      "Epoch [4/50], Step [159/735], Loss: 0.2368\n",
      "Epoch [4/50], Step [160/735], Loss: 0.1412\n",
      "Epoch [4/50], Step [161/735], Loss: 0.3518\n",
      "Epoch [4/50], Step [162/735], Loss: 0.2301\n",
      "Epoch [4/50], Step [163/735], Loss: 0.4743\n",
      "Epoch [4/50], Step [164/735], Loss: 0.2022\n",
      "Epoch [4/50], Step [165/735], Loss: 0.1824\n",
      "Epoch [4/50], Step [166/735], Loss: 0.1245\n",
      "Epoch [4/50], Step [167/735], Loss: 0.1761\n",
      "Epoch [4/50], Step [168/735], Loss: 0.0857\n",
      "Epoch [4/50], Step [169/735], Loss: 0.2407\n",
      "Epoch [4/50], Step [170/735], Loss: 0.0787\n",
      "Epoch [4/50], Step [171/735], Loss: 0.1697\n",
      "Epoch [4/50], Step [172/735], Loss: 0.3539\n",
      "Epoch [4/50], Step [173/735], Loss: 0.2833\n",
      "Epoch [4/50], Step [174/735], Loss: 0.1879\n",
      "Epoch [4/50], Step [175/735], Loss: 0.9114\n",
      "Epoch [4/50], Step [176/735], Loss: 0.0941\n",
      "Epoch [4/50], Step [177/735], Loss: 0.0834\n",
      "Epoch [4/50], Step [178/735], Loss: 0.1351\n",
      "Epoch [4/50], Step [179/735], Loss: 0.1106\n",
      "Epoch [4/50], Step [180/735], Loss: 0.3218\n",
      "Epoch [4/50], Step [181/735], Loss: 0.1815\n",
      "Epoch [4/50], Step [182/735], Loss: 0.3456\n",
      "Epoch [4/50], Step [183/735], Loss: 0.2087\n",
      "Epoch [4/50], Step [184/735], Loss: 0.2124\n",
      "Epoch [4/50], Step [185/735], Loss: 0.2500\n",
      "Epoch [4/50], Step [186/735], Loss: 0.1504\n",
      "Epoch [4/50], Step [187/735], Loss: 0.1635\n",
      "Epoch [4/50], Step [188/735], Loss: 0.0731\n",
      "Epoch [4/50], Step [189/735], Loss: 0.1329\n",
      "Epoch [4/50], Step [190/735], Loss: 0.1221\n",
      "Epoch [4/50], Step [191/735], Loss: 0.1431\n",
      "Epoch [4/50], Step [192/735], Loss: 0.1425\n",
      "Epoch [4/50], Step [193/735], Loss: 0.1505\n",
      "Epoch [4/50], Step [194/735], Loss: 0.1250\n",
      "Epoch [4/50], Step [195/735], Loss: 0.1261\n",
      "Epoch [4/50], Step [196/735], Loss: 0.5737\n",
      "Epoch [4/50], Step [197/735], Loss: 0.3116\n",
      "Epoch [4/50], Step [198/735], Loss: 0.2718\n",
      "Epoch [4/50], Step [199/735], Loss: 0.1641\n",
      "Epoch [4/50], Step [200/735], Loss: 0.0772\n",
      "Epoch [4/50], Step [201/735], Loss: 0.4025\n",
      "Epoch [4/50], Step [202/735], Loss: 0.1282\n",
      "Epoch [4/50], Step [203/735], Loss: 0.0764\n",
      "Epoch [4/50], Step [204/735], Loss: 0.1717\n",
      "Epoch [4/50], Step [205/735], Loss: 0.1862\n",
      "Epoch [4/50], Step [206/735], Loss: 0.1319\n",
      "Epoch [4/50], Step [207/735], Loss: 0.2618\n",
      "Epoch [4/50], Step [208/735], Loss: 0.3580\n",
      "Epoch [4/50], Step [209/735], Loss: 0.2229\n",
      "Epoch [4/50], Step [210/735], Loss: 0.2830\n",
      "Epoch [4/50], Step [211/735], Loss: 0.2134\n",
      "Epoch [4/50], Step [212/735], Loss: 0.2489\n",
      "Epoch [4/50], Step [213/735], Loss: 0.1321\n",
      "Epoch [4/50], Step [214/735], Loss: 0.1599\n",
      "Epoch [4/50], Step [215/735], Loss: 0.0809\n",
      "Epoch [4/50], Step [216/735], Loss: 0.0768\n",
      "Epoch [4/50], Step [217/735], Loss: 0.1055\n",
      "Epoch [4/50], Step [218/735], Loss: 0.1177\n",
      "Epoch [4/50], Step [219/735], Loss: 0.0818\n",
      "Epoch [4/50], Step [220/735], Loss: 0.0929\n",
      "Epoch [4/50], Step [221/735], Loss: 0.1225\n",
      "Epoch [4/50], Step [222/735], Loss: 0.3879\n",
      "Epoch [4/50], Step [223/735], Loss: 0.0888\n",
      "Epoch [4/50], Step [224/735], Loss: 0.0774\n",
      "Epoch [4/50], Step [225/735], Loss: 0.0558\n",
      "Epoch [4/50], Step [226/735], Loss: 0.7699\n",
      "Epoch [4/50], Step [227/735], Loss: 0.0870\n",
      "Epoch [4/50], Step [228/735], Loss: 0.1308\n",
      "Epoch [4/50], Step [229/735], Loss: 0.0795\n",
      "Epoch [4/50], Step [230/735], Loss: 0.3044\n",
      "Epoch [4/50], Step [231/735], Loss: 0.1471\n",
      "Epoch [4/50], Step [232/735], Loss: 0.1706\n",
      "Epoch [4/50], Step [233/735], Loss: 0.1004\n",
      "Epoch [4/50], Step [234/735], Loss: 0.1909\n",
      "Epoch [4/50], Step [235/735], Loss: 0.1224\n",
      "Epoch [4/50], Step [236/735], Loss: 0.0864\n",
      "Epoch [4/50], Step [237/735], Loss: 0.4639\n",
      "Epoch [4/50], Step [238/735], Loss: 0.1036\n",
      "Epoch [4/50], Step [239/735], Loss: 0.2692\n",
      "Epoch [4/50], Step [240/735], Loss: 0.3734\n",
      "Epoch [4/50], Step [241/735], Loss: 0.0754\n",
      "Epoch [4/50], Step [242/735], Loss: 0.5151\n",
      "Epoch [4/50], Step [243/735], Loss: 0.2096\n",
      "Epoch [4/50], Step [244/735], Loss: 0.4047\n",
      "Epoch [4/50], Step [245/735], Loss: 0.1696\n",
      "Epoch [4/50], Step [246/735], Loss: 0.1590\n",
      "Epoch [4/50], Step [247/735], Loss: 0.2724\n",
      "Epoch [4/50], Step [248/735], Loss: 0.1272\n",
      "Epoch [4/50], Step [249/735], Loss: 0.1424\n",
      "Epoch [4/50], Step [250/735], Loss: 0.0966\n",
      "Epoch [4/50], Step [251/735], Loss: 0.1201\n",
      "Epoch [4/50], Step [252/735], Loss: 0.0898\n",
      "Epoch [4/50], Step [253/735], Loss: 0.1351\n",
      "Epoch [4/50], Step [254/735], Loss: 0.0717\n",
      "Epoch [4/50], Step [255/735], Loss: 0.3570\n",
      "Epoch [4/50], Step [256/735], Loss: 0.2147\n",
      "Epoch [4/50], Step [257/735], Loss: 0.0585\n",
      "Epoch [4/50], Step [258/735], Loss: 0.3090\n",
      "Epoch [4/50], Step [259/735], Loss: 0.1858\n",
      "Epoch [4/50], Step [260/735], Loss: 0.1861\n",
      "Epoch [4/50], Step [261/735], Loss: 0.2108\n",
      "Epoch [4/50], Step [262/735], Loss: 0.1893\n",
      "Epoch [4/50], Step [263/735], Loss: 0.2132\n",
      "Epoch [4/50], Step [264/735], Loss: 0.0778\n",
      "Epoch [4/50], Step [265/735], Loss: 0.2772\n",
      "Epoch [4/50], Step [266/735], Loss: 0.2985\n",
      "Epoch [4/50], Step [267/735], Loss: 0.1133\n",
      "Epoch [4/50], Step [268/735], Loss: 0.1522\n",
      "Epoch [4/50], Step [269/735], Loss: 0.1674\n",
      "Epoch [4/50], Step [270/735], Loss: 0.1127\n",
      "Epoch [4/50], Step [271/735], Loss: 0.4207\n",
      "Epoch [4/50], Step [272/735], Loss: 0.2514\n",
      "Epoch [4/50], Step [273/735], Loss: 0.1900\n",
      "Epoch [4/50], Step [274/735], Loss: 0.8481\n",
      "Epoch [4/50], Step [275/735], Loss: 0.0867\n",
      "Epoch [4/50], Step [276/735], Loss: 0.1038\n",
      "Epoch [4/50], Step [277/735], Loss: 0.1259\n",
      "Epoch [4/50], Step [278/735], Loss: 0.1604\n",
      "Epoch [4/50], Step [279/735], Loss: 0.1197\n",
      "Epoch [4/50], Step [280/735], Loss: 0.0992\n",
      "Epoch [4/50], Step [281/735], Loss: 0.2058\n",
      "Epoch [4/50], Step [282/735], Loss: 0.1330\n",
      "Epoch [4/50], Step [283/735], Loss: 0.2080\n",
      "Epoch [4/50], Step [284/735], Loss: 0.2213\n",
      "Epoch [4/50], Step [285/735], Loss: 0.4314\n",
      "Epoch [4/50], Step [286/735], Loss: 0.1312\n",
      "Epoch [4/50], Step [287/735], Loss: 0.1453\n",
      "Epoch [4/50], Step [288/735], Loss: 0.6118\n",
      "Epoch [4/50], Step [289/735], Loss: 0.3043\n",
      "Epoch [4/50], Step [290/735], Loss: 0.1330\n",
      "Epoch [4/50], Step [291/735], Loss: 0.0753\n",
      "Epoch [4/50], Step [292/735], Loss: 0.1003\n",
      "Epoch [4/50], Step [293/735], Loss: 0.1271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Step [294/735], Loss: 0.1021\n",
      "Epoch [4/50], Step [295/735], Loss: 0.1115\n",
      "Epoch [4/50], Step [296/735], Loss: 0.9449\n",
      "Epoch [4/50], Step [297/735], Loss: 0.0671\n",
      "Epoch [4/50], Step [298/735], Loss: 0.2407\n",
      "Epoch [4/50], Step [299/735], Loss: 0.2747\n",
      "Epoch [4/50], Step [300/735], Loss: 0.2431\n",
      "Epoch [4/50], Step [301/735], Loss: 0.1888\n",
      "Epoch [4/50], Step [302/735], Loss: 0.1593\n",
      "Epoch [4/50], Step [303/735], Loss: 0.0530\n",
      "Epoch [4/50], Step [304/735], Loss: 0.1857\n",
      "Epoch [4/50], Step [305/735], Loss: 0.1118\n",
      "Epoch [4/50], Step [306/735], Loss: 0.2078\n",
      "Epoch [4/50], Step [307/735], Loss: 0.0988\n",
      "Epoch [4/50], Step [308/735], Loss: 0.1673\n",
      "Epoch [4/50], Step [309/735], Loss: 0.0634\n",
      "Epoch [4/50], Step [310/735], Loss: 0.1462\n",
      "Epoch [4/50], Step [311/735], Loss: 0.1995\n",
      "Epoch [4/50], Step [312/735], Loss: 0.3649\n",
      "Epoch [4/50], Step [313/735], Loss: 0.1138\n",
      "Epoch [4/50], Step [314/735], Loss: 0.5676\n",
      "Epoch [4/50], Step [315/735], Loss: 0.3631\n",
      "Epoch [4/50], Step [316/735], Loss: 0.2346\n",
      "Epoch [4/50], Step [317/735], Loss: 0.1258\n",
      "Epoch [4/50], Step [318/735], Loss: 0.0738\n",
      "Epoch [4/50], Step [319/735], Loss: 0.1205\n",
      "Epoch [4/50], Step [320/735], Loss: 0.2425\n",
      "Epoch [4/50], Step [321/735], Loss: 0.1544\n",
      "Epoch [4/50], Step [322/735], Loss: 0.1860\n",
      "Epoch [4/50], Step [323/735], Loss: 0.1849\n",
      "Epoch [4/50], Step [324/735], Loss: 0.1520\n",
      "Epoch [4/50], Step [325/735], Loss: 0.1296\n",
      "Epoch [4/50], Step [326/735], Loss: 1.1294\n",
      "Epoch [4/50], Step [327/735], Loss: 0.0886\n",
      "Epoch [4/50], Step [328/735], Loss: 0.0708\n",
      "Epoch [4/50], Step [329/735], Loss: 0.1928\n",
      "Epoch [4/50], Step [330/735], Loss: 0.0735\n",
      "Epoch [4/50], Step [331/735], Loss: 0.3411\n",
      "Epoch [4/50], Step [332/735], Loss: 0.1363\n",
      "Epoch [4/50], Step [333/735], Loss: 0.3175\n",
      "Epoch [4/50], Step [334/735], Loss: 0.1717\n",
      "Epoch [4/50], Step [335/735], Loss: 0.1953\n",
      "Epoch [4/50], Step [336/735], Loss: 0.2027\n",
      "Epoch [4/50], Step [337/735], Loss: 0.1047\n",
      "Epoch [4/50], Step [338/735], Loss: 0.2121\n",
      "Epoch [4/50], Step [339/735], Loss: 0.0760\n",
      "Epoch [4/50], Step [340/735], Loss: 0.1846\n",
      "Epoch [4/50], Step [341/735], Loss: 0.1492\n",
      "Epoch [4/50], Step [342/735], Loss: 0.4267\n",
      "Epoch [4/50], Step [343/735], Loss: 1.0688\n",
      "Epoch [4/50], Step [344/735], Loss: 0.1987\n",
      "Epoch [4/50], Step [345/735], Loss: 0.2266\n",
      "Epoch [4/50], Step [346/735], Loss: 0.2184\n",
      "Epoch [4/50], Step [347/735], Loss: 0.1658\n",
      "Epoch [4/50], Step [348/735], Loss: 0.2570\n",
      "Epoch [4/50], Step [349/735], Loss: 0.1824\n",
      "Epoch [4/50], Step [350/735], Loss: 0.1054\n",
      "Epoch [4/50], Step [351/735], Loss: 0.2136\n",
      "Epoch [4/50], Step [352/735], Loss: 0.2234\n",
      "Epoch [4/50], Step [353/735], Loss: 0.2650\n",
      "Epoch [4/50], Step [354/735], Loss: 0.8342\n",
      "Epoch [4/50], Step [355/735], Loss: 0.1290\n",
      "Epoch [4/50], Step [356/735], Loss: 0.1064\n",
      "Epoch [4/50], Step [357/735], Loss: 0.2617\n",
      "Epoch [4/50], Step [358/735], Loss: 0.1091\n",
      "Epoch [4/50], Step [359/735], Loss: 0.3647\n",
      "Epoch [4/50], Step [360/735], Loss: 0.0998\n",
      "Epoch [4/50], Step [361/735], Loss: 0.2569\n",
      "Epoch [4/50], Step [362/735], Loss: 0.0808\n",
      "Epoch [4/50], Step [363/735], Loss: 0.2856\n",
      "Epoch [4/50], Step [364/735], Loss: 0.3947\n",
      "Epoch [4/50], Step [365/735], Loss: 0.1241\n",
      "Epoch [4/50], Step [366/735], Loss: 0.1455\n",
      "Epoch [4/50], Step [367/735], Loss: 0.1933\n",
      "Epoch [4/50], Step [368/735], Loss: 0.3263\n",
      "Epoch [4/50], Step [369/735], Loss: 0.1683\n",
      "Epoch [4/50], Step [370/735], Loss: 0.8176\n",
      "Epoch [4/50], Step [371/735], Loss: 0.1784\n",
      "Epoch [4/50], Step [372/735], Loss: 0.2578\n",
      "Epoch [4/50], Step [373/735], Loss: 0.2225\n",
      "Epoch [4/50], Step [374/735], Loss: 0.3489\n",
      "Epoch [4/50], Step [375/735], Loss: 0.1991\n",
      "Epoch [4/50], Step [376/735], Loss: 0.1722\n",
      "Epoch [4/50], Step [377/735], Loss: 0.2759\n",
      "Epoch [4/50], Step [378/735], Loss: 0.1181\n",
      "Epoch [4/50], Step [379/735], Loss: 0.1093\n",
      "Epoch [4/50], Step [380/735], Loss: 0.0869\n",
      "Epoch [4/50], Step [381/735], Loss: 0.1723\n",
      "Epoch [4/50], Step [382/735], Loss: 0.2697\n",
      "Epoch [4/50], Step [383/735], Loss: 0.1498\n",
      "Epoch [4/50], Step [384/735], Loss: 0.3417\n",
      "Epoch [4/50], Step [385/735], Loss: 0.0845\n",
      "Epoch [4/50], Step [386/735], Loss: 0.2101\n",
      "Epoch [4/50], Step [387/735], Loss: 0.2787\n",
      "Epoch [4/50], Step [388/735], Loss: 0.1606\n",
      "Epoch [4/50], Step [389/735], Loss: 0.0826\n",
      "Epoch [4/50], Step [390/735], Loss: 0.1337\n",
      "Epoch [4/50], Step [391/735], Loss: 0.0922\n",
      "Epoch [4/50], Step [392/735], Loss: 0.0972\n",
      "Epoch [4/50], Step [393/735], Loss: 0.1776\n",
      "Epoch [4/50], Step [394/735], Loss: 0.1166\n",
      "Epoch [4/50], Step [395/735], Loss: 0.3817\n",
      "Epoch [4/50], Step [396/735], Loss: 0.1938\n",
      "Epoch [4/50], Step [397/735], Loss: 0.0805\n",
      "Epoch [4/50], Step [398/735], Loss: 0.1258\n",
      "Epoch [4/50], Step [399/735], Loss: 0.2457\n",
      "Epoch [4/50], Step [400/735], Loss: 0.1092\n",
      "Epoch [4/50], Step [401/735], Loss: 0.0817\n",
      "Epoch [4/50], Step [402/735], Loss: 0.0927\n",
      "Epoch [4/50], Step [403/735], Loss: 0.1646\n",
      "Epoch [4/50], Step [404/735], Loss: 0.1754\n",
      "Epoch [4/50], Step [405/735], Loss: 0.1097\n",
      "Epoch [4/50], Step [406/735], Loss: 0.1829\n",
      "Epoch [4/50], Step [407/735], Loss: 0.4782\n",
      "Epoch [4/50], Step [408/735], Loss: 0.1005\n",
      "Epoch [4/50], Step [409/735], Loss: 0.1288\n",
      "Epoch [4/50], Step [410/735], Loss: 0.3056\n",
      "Epoch [4/50], Step [411/735], Loss: 0.0606\n",
      "Epoch [4/50], Step [412/735], Loss: 0.0944\n",
      "Epoch [4/50], Step [413/735], Loss: 0.0641\n",
      "Epoch [4/50], Step [414/735], Loss: 0.1563\n",
      "Epoch [4/50], Step [415/735], Loss: 0.1361\n",
      "Epoch [4/50], Step [416/735], Loss: 0.1183\n",
      "Epoch [4/50], Step [417/735], Loss: 0.1915\n",
      "Epoch [4/50], Step [418/735], Loss: 0.1049\n",
      "Epoch [4/50], Step [419/735], Loss: 0.1330\n",
      "Epoch [4/50], Step [420/735], Loss: 0.0950\n",
      "Epoch [4/50], Step [421/735], Loss: 0.5785\n",
      "Epoch [4/50], Step [422/735], Loss: 0.4217\n",
      "Epoch [4/50], Step [423/735], Loss: 0.1827\n",
      "Epoch [4/50], Step [424/735], Loss: 0.0696\n",
      "Epoch [4/50], Step [425/735], Loss: 0.0607\n",
      "Epoch [4/50], Step [426/735], Loss: 0.0927\n",
      "Epoch [4/50], Step [427/735], Loss: 0.0945\n",
      "Epoch [4/50], Step [428/735], Loss: 0.1127\n",
      "Epoch [4/50], Step [429/735], Loss: 0.1889\n",
      "Epoch [4/50], Step [430/735], Loss: 0.3057\n",
      "Epoch [4/50], Step [431/735], Loss: 0.0635\n",
      "Epoch [4/50], Step [432/735], Loss: 0.6674\n",
      "Epoch [4/50], Step [433/735], Loss: 0.2247\n",
      "Epoch [4/50], Step [434/735], Loss: 0.1205\n",
      "Epoch [4/50], Step [435/735], Loss: 0.2387\n",
      "Epoch [4/50], Step [436/735], Loss: 0.0834\n",
      "Epoch [4/50], Step [437/735], Loss: 0.1058\n",
      "Epoch [4/50], Step [438/735], Loss: 0.2213\n",
      "Epoch [4/50], Step [439/735], Loss: 0.2507\n",
      "Epoch [4/50], Step [440/735], Loss: 0.0918\n",
      "Epoch [4/50], Step [441/735], Loss: 0.2362\n",
      "Epoch [4/50], Step [442/735], Loss: 0.1380\n",
      "Epoch [4/50], Step [443/735], Loss: 0.0740\n",
      "Epoch [4/50], Step [444/735], Loss: 0.1681\n",
      "Epoch [4/50], Step [445/735], Loss: 0.2887\n",
      "Epoch [4/50], Step [446/735], Loss: 0.2977\n",
      "Epoch [4/50], Step [447/735], Loss: 0.1086\n",
      "Epoch [4/50], Step [448/735], Loss: 0.1429\n",
      "Epoch [4/50], Step [449/735], Loss: 0.1112\n",
      "Epoch [4/50], Step [450/735], Loss: 0.1111\n",
      "Epoch [4/50], Step [451/735], Loss: 0.1973\n",
      "Epoch [4/50], Step [452/735], Loss: 0.1222\n",
      "Epoch [4/50], Step [453/735], Loss: 0.2511\n",
      "Epoch [4/50], Step [454/735], Loss: 0.3269\n",
      "Epoch [4/50], Step [455/735], Loss: 0.0720\n",
      "Epoch [4/50], Step [456/735], Loss: 0.2378\n",
      "Epoch [4/50], Step [457/735], Loss: 0.2110\n",
      "Epoch [4/50], Step [458/735], Loss: 0.0684\n",
      "Epoch [4/50], Step [459/735], Loss: 0.1448\n",
      "Epoch [4/50], Step [460/735], Loss: 0.0887\n",
      "Epoch [4/50], Step [461/735], Loss: 0.2094\n",
      "Epoch [4/50], Step [462/735], Loss: 0.2005\n",
      "Epoch [4/50], Step [463/735], Loss: 0.1625\n",
      "Epoch [4/50], Step [464/735], Loss: 0.2887\n",
      "Epoch [4/50], Step [465/735], Loss: 0.2394\n",
      "Epoch [4/50], Step [466/735], Loss: 0.2010\n",
      "Epoch [4/50], Step [467/735], Loss: 0.1942\n",
      "Epoch [4/50], Step [468/735], Loss: 0.1917\n",
      "Epoch [4/50], Step [469/735], Loss: 0.0822\n",
      "Epoch [4/50], Step [470/735], Loss: 0.2448\n",
      "Epoch [4/50], Step [471/735], Loss: 0.0835\n",
      "Epoch [4/50], Step [472/735], Loss: 0.1315\n",
      "Epoch [4/50], Step [473/735], Loss: 0.3120\n",
      "Epoch [4/50], Step [474/735], Loss: 0.1072\n",
      "Epoch [4/50], Step [475/735], Loss: 0.1041\n",
      "Epoch [4/50], Step [476/735], Loss: 0.1189\n",
      "Epoch [4/50], Step [477/735], Loss: 0.1154\n",
      "Epoch [4/50], Step [478/735], Loss: 0.0833\n",
      "Epoch [4/50], Step [479/735], Loss: 0.2357\n",
      "Epoch [4/50], Step [480/735], Loss: 0.1056\n",
      "Epoch [4/50], Step [481/735], Loss: 0.1461\n",
      "Epoch [4/50], Step [482/735], Loss: 0.1611\n",
      "Epoch [4/50], Step [483/735], Loss: 0.0957\n",
      "Epoch [4/50], Step [484/735], Loss: 0.1868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Step [485/735], Loss: 0.1106\n",
      "Epoch [4/50], Step [486/735], Loss: 0.1373\n",
      "Epoch [4/50], Step [487/735], Loss: 0.1076\n",
      "Epoch [4/50], Step [488/735], Loss: 0.0551\n",
      "Epoch [4/50], Step [489/735], Loss: 0.2057\n",
      "Epoch [4/50], Step [490/735], Loss: 0.2178\n",
      "Epoch [4/50], Step [491/735], Loss: 0.1473\n",
      "Epoch [4/50], Step [492/735], Loss: 0.1400\n",
      "Epoch [4/50], Step [493/735], Loss: 0.1794\n",
      "Epoch [4/50], Step [494/735], Loss: 0.3047\n",
      "Epoch [4/50], Step [495/735], Loss: 0.1896\n",
      "Epoch [4/50], Step [496/735], Loss: 0.0967\n",
      "Epoch [4/50], Step [497/735], Loss: 0.2460\n",
      "Epoch [4/50], Step [498/735], Loss: 0.0878\n",
      "Epoch [4/50], Step [499/735], Loss: 0.2648\n",
      "Epoch [4/50], Step [500/735], Loss: 0.1419\n",
      "Epoch [4/50], Step [501/735], Loss: 0.1776\n",
      "Epoch [4/50], Step [502/735], Loss: 1.4573\n",
      "Epoch [4/50], Step [503/735], Loss: 0.1126\n",
      "Epoch [4/50], Step [504/735], Loss: 0.2190\n",
      "Epoch [4/50], Step [505/735], Loss: 0.2781\n",
      "Epoch [4/50], Step [506/735], Loss: 0.1459\n",
      "Epoch [4/50], Step [507/735], Loss: 0.2346\n",
      "Epoch [4/50], Step [508/735], Loss: 0.2976\n",
      "Epoch [4/50], Step [509/735], Loss: 0.0883\n",
      "Epoch [4/50], Step [510/735], Loss: 0.0916\n",
      "Epoch [4/50], Step [511/735], Loss: 0.1426\n",
      "Epoch [4/50], Step [512/735], Loss: 0.4083\n",
      "Epoch [4/50], Step [513/735], Loss: 0.1149\n",
      "Epoch [4/50], Step [514/735], Loss: 0.3438\n",
      "Epoch [4/50], Step [515/735], Loss: 0.3370\n",
      "Epoch [4/50], Step [516/735], Loss: 0.3367\n",
      "Epoch [4/50], Step [517/735], Loss: 0.1471\n",
      "Epoch [4/50], Step [518/735], Loss: 0.5692\n",
      "Epoch [4/50], Step [519/735], Loss: 0.0938\n",
      "Epoch [4/50], Step [520/735], Loss: 0.0925\n",
      "Epoch [4/50], Step [521/735], Loss: 0.2687\n",
      "Epoch [4/50], Step [522/735], Loss: 0.3100\n",
      "Epoch [4/50], Step [523/735], Loss: 0.0942\n",
      "Epoch [4/50], Step [524/735], Loss: 0.1071\n",
      "Epoch [4/50], Step [525/735], Loss: 0.2133\n",
      "Epoch [4/50], Step [526/735], Loss: 0.2736\n",
      "Epoch [4/50], Step [527/735], Loss: 0.3981\n",
      "Epoch [4/50], Step [528/735], Loss: 0.1525\n",
      "Epoch [4/50], Step [529/735], Loss: 0.2082\n",
      "Epoch [4/50], Step [530/735], Loss: 0.3197\n",
      "Epoch [4/50], Step [531/735], Loss: 0.0625\n",
      "Epoch [4/50], Step [532/735], Loss: 0.1502\n",
      "Epoch [4/50], Step [533/735], Loss: 0.0532\n",
      "Epoch [4/50], Step [534/735], Loss: 0.0670\n",
      "Epoch [4/50], Step [535/735], Loss: 0.0965\n",
      "Epoch [4/50], Step [536/735], Loss: 0.3082\n",
      "Epoch [4/50], Step [537/735], Loss: 0.1051\n",
      "Epoch [4/50], Step [538/735], Loss: 0.2583\n",
      "Epoch [4/50], Step [539/735], Loss: 0.1492\n",
      "Epoch [4/50], Step [540/735], Loss: 0.2470\n",
      "Epoch [4/50], Step [541/735], Loss: 0.1755\n",
      "Epoch [4/50], Step [542/735], Loss: 0.2406\n",
      "Epoch [4/50], Step [543/735], Loss: 0.2296\n",
      "Epoch [4/50], Step [544/735], Loss: 0.1499\n",
      "Epoch [4/50], Step [545/735], Loss: 0.1484\n",
      "Epoch [4/50], Step [546/735], Loss: 0.3452\n",
      "Epoch [4/50], Step [547/735], Loss: 0.1228\n",
      "Epoch [4/50], Step [548/735], Loss: 0.0854\n",
      "Epoch [4/50], Step [549/735], Loss: 0.0995\n",
      "Epoch [4/50], Step [550/735], Loss: 0.2130\n",
      "Epoch [4/50], Step [551/735], Loss: 0.3633\n",
      "Epoch [4/50], Step [552/735], Loss: 0.1096\n",
      "Epoch [4/50], Step [553/735], Loss: 0.1002\n",
      "Epoch [4/50], Step [554/735], Loss: 0.1228\n",
      "Epoch [4/50], Step [555/735], Loss: 0.5833\n",
      "Epoch [4/50], Step [556/735], Loss: 0.0904\n",
      "Epoch [4/50], Step [557/735], Loss: 0.3662\n",
      "Epoch [4/50], Step [558/735], Loss: 0.1555\n",
      "Epoch [4/50], Step [559/735], Loss: 0.1085\n",
      "Epoch [4/50], Step [560/735], Loss: 0.0636\n",
      "Epoch [4/50], Step [561/735], Loss: 0.2166\n",
      "Epoch [4/50], Step [562/735], Loss: 0.4249\n",
      "Epoch [4/50], Step [563/735], Loss: 0.1079\n",
      "Epoch [4/50], Step [564/735], Loss: 0.0989\n",
      "Epoch [4/50], Step [565/735], Loss: 0.2684\n",
      "Epoch [4/50], Step [566/735], Loss: 0.1055\n",
      "Epoch [4/50], Step [567/735], Loss: 0.1500\n",
      "Epoch [4/50], Step [568/735], Loss: 0.1965\n",
      "Epoch [4/50], Step [569/735], Loss: 0.2666\n",
      "Epoch [4/50], Step [570/735], Loss: 0.1413\n",
      "Epoch [4/50], Step [571/735], Loss: 0.0703\n",
      "Epoch [4/50], Step [572/735], Loss: 0.1479\n",
      "Epoch [4/50], Step [573/735], Loss: 0.8153\n",
      "Epoch [4/50], Step [574/735], Loss: 0.1616\n",
      "Epoch [4/50], Step [575/735], Loss: 0.0681\n",
      "Epoch [4/50], Step [576/735], Loss: 0.1259\n",
      "Epoch [4/50], Step [577/735], Loss: 0.2994\n",
      "Epoch [4/50], Step [578/735], Loss: 0.0770\n",
      "Epoch [4/50], Step [579/735], Loss: 0.2357\n",
      "Epoch [4/50], Step [580/735], Loss: 0.3176\n",
      "Epoch [4/50], Step [581/735], Loss: 0.1375\n",
      "Epoch [4/50], Step [582/735], Loss: 0.1101\n",
      "Epoch [4/50], Step [583/735], Loss: 0.2596\n",
      "Epoch [4/50], Step [584/735], Loss: 0.0659\n",
      "Epoch [4/50], Step [585/735], Loss: 0.0822\n",
      "Epoch [4/50], Step [586/735], Loss: 0.1504\n",
      "Epoch [4/50], Step [587/735], Loss: 0.0806\n",
      "Epoch [4/50], Step [588/735], Loss: 0.1376\n",
      "Epoch [4/50], Step [589/735], Loss: 0.1472\n",
      "Epoch [4/50], Step [590/735], Loss: 0.1583\n",
      "Epoch [4/50], Step [591/735], Loss: 0.8222\n",
      "Epoch [4/50], Step [592/735], Loss: 0.1941\n",
      "Epoch [4/50], Step [593/735], Loss: 0.3669\n",
      "Epoch [4/50], Step [594/735], Loss: 0.1409\n",
      "Epoch [4/50], Step [595/735], Loss: 0.0841\n",
      "Epoch [4/50], Step [596/735], Loss: 0.0872\n",
      "Epoch [4/50], Step [597/735], Loss: 0.0926\n",
      "Epoch [4/50], Step [598/735], Loss: 0.1296\n",
      "Epoch [4/50], Step [599/735], Loss: 0.1102\n",
      "Epoch [4/50], Step [600/735], Loss: 0.1474\n",
      "Epoch [4/50], Step [601/735], Loss: 0.3824\n",
      "Epoch [4/50], Step [602/735], Loss: 0.0642\n",
      "Epoch [4/50], Step [603/735], Loss: 0.9928\n",
      "Epoch [4/50], Step [604/735], Loss: 0.0928\n",
      "Epoch [4/50], Step [605/735], Loss: 0.1368\n",
      "Epoch [4/50], Step [606/735], Loss: 0.1107\n",
      "Epoch [4/50], Step [607/735], Loss: 0.1005\n",
      "Epoch [4/50], Step [608/735], Loss: 0.1243\n",
      "Epoch [4/50], Step [609/735], Loss: 0.1472\n",
      "Epoch [4/50], Step [610/735], Loss: 0.2176\n",
      "Epoch [4/50], Step [611/735], Loss: 0.1201\n",
      "Epoch [4/50], Step [612/735], Loss: 0.6642\n",
      "Epoch [4/50], Step [613/735], Loss: 0.0630\n",
      "Epoch [4/50], Step [614/735], Loss: 0.1746\n",
      "Epoch [4/50], Step [615/735], Loss: 0.1516\n",
      "Epoch [4/50], Step [616/735], Loss: 0.3113\n",
      "Epoch [4/50], Step [617/735], Loss: 0.1505\n",
      "Epoch [4/50], Step [618/735], Loss: 0.1168\n",
      "Epoch [4/50], Step [619/735], Loss: 0.0900\n",
      "Epoch [4/50], Step [620/735], Loss: 0.1835\n",
      "Epoch [4/50], Step [621/735], Loss: 0.0575\n",
      "Epoch [4/50], Step [622/735], Loss: 0.7969\n",
      "Epoch [4/50], Step [623/735], Loss: 0.1433\n",
      "Epoch [4/50], Step [624/735], Loss: 0.5210\n",
      "Epoch [4/50], Step [625/735], Loss: 0.0811\n",
      "Epoch [4/50], Step [626/735], Loss: 0.0606\n",
      "Epoch [4/50], Step [627/735], Loss: 0.0781\n",
      "Epoch [4/50], Step [628/735], Loss: 0.1244\n",
      "Epoch [4/50], Step [629/735], Loss: 0.1939\n",
      "Epoch [4/50], Step [630/735], Loss: 0.1564\n",
      "Epoch [4/50], Step [631/735], Loss: 0.0750\n",
      "Epoch [4/50], Step [632/735], Loss: 0.1783\n",
      "Epoch [4/50], Step [633/735], Loss: 0.2209\n",
      "Epoch [4/50], Step [634/735], Loss: 0.3307\n",
      "Epoch [4/50], Step [635/735], Loss: 0.1145\n",
      "Epoch [4/50], Step [636/735], Loss: 0.0764\n",
      "Epoch [4/50], Step [637/735], Loss: 0.1022\n",
      "Epoch [4/50], Step [638/735], Loss: 0.0863\n",
      "Epoch [4/50], Step [639/735], Loss: 0.5012\n",
      "Epoch [4/50], Step [640/735], Loss: 0.1028\n",
      "Epoch [4/50], Step [641/735], Loss: 0.8438\n",
      "Epoch [4/50], Step [642/735], Loss: 0.1736\n",
      "Epoch [4/50], Step [643/735], Loss: 0.2044\n",
      "Epoch [4/50], Step [644/735], Loss: 0.1814\n",
      "Epoch [4/50], Step [645/735], Loss: 0.2348\n",
      "Epoch [4/50], Step [646/735], Loss: 0.1408\n",
      "Epoch [4/50], Step [647/735], Loss: 0.2014\n",
      "Epoch [4/50], Step [648/735], Loss: 0.1481\n",
      "Epoch [4/50], Step [649/735], Loss: 0.1558\n",
      "Epoch [4/50], Step [650/735], Loss: 0.2502\n",
      "Epoch [4/50], Step [651/735], Loss: 0.1151\n",
      "Epoch [4/50], Step [652/735], Loss: 0.1816\n",
      "Epoch [4/50], Step [653/735], Loss: 0.0814\n",
      "Epoch [4/50], Step [654/735], Loss: 0.3725\n",
      "Epoch [4/50], Step [655/735], Loss: 0.0911\n",
      "Epoch [4/50], Step [656/735], Loss: 0.0698\n",
      "Epoch [4/50], Step [657/735], Loss: 0.2250\n",
      "Epoch [4/50], Step [658/735], Loss: 0.3071\n",
      "Epoch [4/50], Step [659/735], Loss: 0.0687\n",
      "Epoch [4/50], Step [660/735], Loss: 0.1354\n",
      "Epoch [4/50], Step [661/735], Loss: 0.3110\n",
      "Epoch [4/50], Step [662/735], Loss: 0.0650\n",
      "Epoch [4/50], Step [663/735], Loss: 0.8315\n",
      "Epoch [4/50], Step [664/735], Loss: 0.3213\n",
      "Epoch [4/50], Step [665/735], Loss: 0.0655\n",
      "Epoch [4/50], Step [666/735], Loss: 0.2373\n",
      "Epoch [4/50], Step [667/735], Loss: 0.2478\n",
      "Epoch [4/50], Step [668/735], Loss: 0.5261\n",
      "Epoch [4/50], Step [669/735], Loss: 0.1028\n",
      "Epoch [4/50], Step [670/735], Loss: 0.1524\n",
      "Epoch [4/50], Step [671/735], Loss: 0.1606\n",
      "Epoch [4/50], Step [672/735], Loss: 0.1122\n",
      "Epoch [4/50], Step [673/735], Loss: 0.1123\n",
      "Epoch [4/50], Step [674/735], Loss: 0.3015\n",
      "Epoch [4/50], Step [675/735], Loss: 0.3920\n",
      "Epoch [4/50], Step [676/735], Loss: 0.6808\n",
      "Epoch [4/50], Step [677/735], Loss: 0.2277\n",
      "Epoch [4/50], Step [678/735], Loss: 0.0921\n",
      "Epoch [4/50], Step [679/735], Loss: 0.1554\n",
      "Epoch [4/50], Step [680/735], Loss: 0.0689\n",
      "Epoch [4/50], Step [681/735], Loss: 0.1037\n",
      "Epoch [4/50], Step [682/735], Loss: 0.1894\n",
      "Epoch [4/50], Step [683/735], Loss: 0.1611\n",
      "Epoch [4/50], Step [684/735], Loss: 0.0754\n",
      "Epoch [4/50], Step [685/735], Loss: 0.3497\n",
      "Epoch [4/50], Step [686/735], Loss: 0.1559\n",
      "Epoch [4/50], Step [687/735], Loss: 0.1806\n",
      "Epoch [4/50], Step [688/735], Loss: 0.2126\n",
      "Epoch [4/50], Step [689/735], Loss: 0.1518\n",
      "Epoch [4/50], Step [690/735], Loss: 0.1986\n",
      "Epoch [4/50], Step [691/735], Loss: 0.1851\n",
      "Epoch [4/50], Step [692/735], Loss: 0.0619\n",
      "Epoch [4/50], Step [693/735], Loss: 0.4567\n",
      "Epoch [4/50], Step [694/735], Loss: 0.0733\n",
      "Epoch [4/50], Step [695/735], Loss: 0.0918\n",
      "Epoch [4/50], Step [696/735], Loss: 0.0620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Step [697/735], Loss: 0.2079\n",
      "Epoch [4/50], Step [698/735], Loss: 0.2970\n",
      "Epoch [4/50], Step [699/735], Loss: 0.1535\n",
      "Epoch [4/50], Step [700/735], Loss: 0.1133\n",
      "Epoch [4/50], Step [701/735], Loss: 0.2346\n",
      "Epoch [4/50], Step [702/735], Loss: 0.1366\n",
      "Epoch [4/50], Step [703/735], Loss: 0.1209\n",
      "Epoch [4/50], Step [704/735], Loss: 0.1841\n",
      "Epoch [4/50], Step [705/735], Loss: 0.0613\n",
      "Epoch [4/50], Step [706/735], Loss: 0.0833\n",
      "Epoch [4/50], Step [707/735], Loss: 0.0897\n",
      "Epoch [4/50], Step [708/735], Loss: 0.0881\n",
      "Epoch [4/50], Step [709/735], Loss: 0.1245\n",
      "Epoch [4/50], Step [710/735], Loss: 0.4321\n",
      "Epoch [4/50], Step [711/735], Loss: 0.1689\n",
      "Epoch [4/50], Step [712/735], Loss: 0.1796\n",
      "Epoch [4/50], Step [713/735], Loss: 0.1407\n",
      "Epoch [4/50], Step [714/735], Loss: 0.0932\n",
      "Epoch [4/50], Step [715/735], Loss: 0.2708\n",
      "Epoch [4/50], Step [716/735], Loss: 0.1674\n",
      "Epoch [4/50], Step [717/735], Loss: 0.0586\n",
      "Epoch [4/50], Step [718/735], Loss: 0.0946\n",
      "Epoch [4/50], Step [719/735], Loss: 1.0027\n",
      "Epoch [4/50], Step [720/735], Loss: 0.0373\n",
      "Epoch [4/50], Step [721/735], Loss: 0.3977\n",
      "Epoch [4/50], Step [722/735], Loss: 0.2885\n",
      "Epoch [4/50], Step [723/735], Loss: 0.0681\n",
      "Epoch [4/50], Step [724/735], Loss: 0.0913\n",
      "Epoch [4/50], Step [725/735], Loss: 0.1122\n",
      "Epoch [4/50], Step [726/735], Loss: 0.3952\n",
      "Epoch [4/50], Step [727/735], Loss: 0.1128\n",
      "Epoch [4/50], Step [728/735], Loss: 0.2052\n",
      "Epoch [4/50], Step [729/735], Loss: 0.1870\n",
      "Epoch [4/50], Step [730/735], Loss: 0.0707\n",
      "Epoch [4/50], Step [731/735], Loss: 0.1973\n",
      "Epoch [4/50], Step [732/735], Loss: 0.2317\n",
      "Epoch [4/50], Step [733/735], Loss: 0.1348\n",
      "Epoch [4/50], Step [734/735], Loss: 0.0923\n",
      "Epoch [4/50], Step [735/735], Loss: 0.2282\n",
      "Epoch [5/50], Step [1/735], Loss: 0.1489\n",
      "Epoch [5/50], Step [2/735], Loss: 0.1657\n",
      "Epoch [5/50], Step [3/735], Loss: 0.0837\n",
      "Epoch [5/50], Step [4/735], Loss: 0.0999\n",
      "Epoch [5/50], Step [5/735], Loss: 0.0939\n",
      "Epoch [5/50], Step [6/735], Loss: 0.1365\n",
      "Epoch [5/50], Step [7/735], Loss: 0.1154\n",
      "Epoch [5/50], Step [8/735], Loss: 0.1154\n",
      "Epoch [5/50], Step [9/735], Loss: 0.1493\n",
      "Epoch [5/50], Step [10/735], Loss: 0.1417\n",
      "Epoch [5/50], Step [11/735], Loss: 0.1057\n",
      "Epoch [5/50], Step [12/735], Loss: 0.1566\n",
      "Epoch [5/50], Step [13/735], Loss: 0.0835\n",
      "Epoch [5/50], Step [14/735], Loss: 0.2068\n",
      "Epoch [5/50], Step [15/735], Loss: 0.0926\n",
      "Epoch [5/50], Step [16/735], Loss: 0.0971\n",
      "Epoch [5/50], Step [17/735], Loss: 0.0966\n",
      "Epoch [5/50], Step [18/735], Loss: 0.2451\n",
      "Epoch [5/50], Step [19/735], Loss: 0.0744\n",
      "Epoch [5/50], Step [20/735], Loss: 0.1881\n",
      "Epoch [5/50], Step [21/735], Loss: 0.1461\n",
      "Epoch [5/50], Step [22/735], Loss: 0.0918\n",
      "Epoch [5/50], Step [23/735], Loss: 0.1451\n",
      "Epoch [5/50], Step [24/735], Loss: 0.2031\n",
      "Epoch [5/50], Step [25/735], Loss: 0.0678\n",
      "Epoch [5/50], Step [26/735], Loss: 0.5833\n",
      "Epoch [5/50], Step [27/735], Loss: 0.4348\n",
      "Epoch [5/50], Step [28/735], Loss: 0.1122\n",
      "Epoch [5/50], Step [29/735], Loss: 0.2181\n",
      "Epoch [5/50], Step [30/735], Loss: 0.1508\n",
      "Epoch [5/50], Step [31/735], Loss: 0.0975\n",
      "Epoch [5/50], Step [32/735], Loss: 0.0583\n",
      "Epoch [5/50], Step [33/735], Loss: 0.1098\n",
      "Epoch [5/50], Step [34/735], Loss: 0.1107\n",
      "Epoch [5/50], Step [35/735], Loss: 0.4045\n",
      "Epoch [5/50], Step [36/735], Loss: 0.4781\n",
      "Epoch [5/50], Step [37/735], Loss: 0.3767\n",
      "Epoch [5/50], Step [38/735], Loss: 0.2754\n",
      "Epoch [5/50], Step [39/735], Loss: 0.0890\n",
      "Epoch [5/50], Step [40/735], Loss: 0.3240\n",
      "Epoch [5/50], Step [41/735], Loss: 0.1608\n",
      "Epoch [5/50], Step [42/735], Loss: 0.1321\n",
      "Epoch [5/50], Step [43/735], Loss: 0.1021\n",
      "Epoch [5/50], Step [44/735], Loss: 0.0658\n",
      "Epoch [5/50], Step [45/735], Loss: 0.0890\n",
      "Epoch [5/50], Step [46/735], Loss: 0.1461\n",
      "Epoch [5/50], Step [47/735], Loss: 0.1418\n",
      "Epoch [5/50], Step [48/735], Loss: 0.1414\n",
      "Epoch [5/50], Step [49/735], Loss: 0.0692\n",
      "Epoch [5/50], Step [50/735], Loss: 0.0680\n",
      "Epoch [5/50], Step [51/735], Loss: 0.0882\n",
      "Epoch [5/50], Step [52/735], Loss: 0.0700\n",
      "Epoch [5/50], Step [53/735], Loss: 0.0826\n",
      "Epoch [5/50], Step [54/735], Loss: 0.1285\n",
      "Epoch [5/50], Step [55/735], Loss: 0.0689\n",
      "Epoch [5/50], Step [56/735], Loss: 0.0420\n",
      "Epoch [5/50], Step [57/735], Loss: 0.2967\n",
      "Epoch [5/50], Step [58/735], Loss: 0.1115\n",
      "Epoch [5/50], Step [59/735], Loss: 0.0409\n",
      "Epoch [5/50], Step [60/735], Loss: 0.0694\n",
      "Epoch [5/50], Step [61/735], Loss: 0.0789\n",
      "Epoch [5/50], Step [62/735], Loss: 0.3164\n",
      "Epoch [5/50], Step [63/735], Loss: 0.5607\n",
      "Epoch [5/50], Step [64/735], Loss: 0.0772\n",
      "Epoch [5/50], Step [65/735], Loss: 0.0707\n",
      "Epoch [5/50], Step [66/735], Loss: 0.1287\n",
      "Epoch [5/50], Step [67/735], Loss: 0.2400\n",
      "Epoch [5/50], Step [68/735], Loss: 0.0722\n",
      "Epoch [5/50], Step [69/735], Loss: 0.0536\n",
      "Epoch [5/50], Step [70/735], Loss: 0.0522\n",
      "Epoch [5/50], Step [71/735], Loss: 0.6721\n",
      "Epoch [5/50], Step [72/735], Loss: 0.0365\n",
      "Epoch [5/50], Step [73/735], Loss: 0.0554\n",
      "Epoch [5/50], Step [74/735], Loss: 0.0673\n",
      "Epoch [5/50], Step [75/735], Loss: 0.1396\n",
      "Epoch [5/50], Step [76/735], Loss: 0.1337\n",
      "Epoch [5/50], Step [77/735], Loss: 0.2607\n",
      "Epoch [5/50], Step [78/735], Loss: 0.1861\n",
      "Epoch [5/50], Step [79/735], Loss: 0.0633\n",
      "Epoch [5/50], Step [80/735], Loss: 0.1425\n",
      "Epoch [5/50], Step [81/735], Loss: 0.0678\n",
      "Epoch [5/50], Step [82/735], Loss: 0.1724\n",
      "Epoch [5/50], Step [83/735], Loss: 0.1163\n",
      "Epoch [5/50], Step [84/735], Loss: 0.0494\n",
      "Epoch [5/50], Step [85/735], Loss: 0.0536\n",
      "Epoch [5/50], Step [86/735], Loss: 0.1204\n",
      "Epoch [5/50], Step [87/735], Loss: 0.1001\n",
      "Epoch [5/50], Step [88/735], Loss: 0.0906\n",
      "Epoch [5/50], Step [89/735], Loss: 0.0674\n",
      "Epoch [5/50], Step [90/735], Loss: 0.0594\n",
      "Epoch [5/50], Step [91/735], Loss: 0.1917\n",
      "Epoch [5/50], Step [92/735], Loss: 0.0523\n",
      "Epoch [5/50], Step [93/735], Loss: 0.0542\n",
      "Epoch [5/50], Step [94/735], Loss: 0.0679\n",
      "Epoch [5/50], Step [95/735], Loss: 0.0952\n",
      "Epoch [5/50], Step [96/735], Loss: 0.1855\n",
      "Epoch [5/50], Step [97/735], Loss: 0.1772\n",
      "Epoch [5/50], Step [98/735], Loss: 0.1541\n",
      "Epoch [5/50], Step [99/735], Loss: 0.2460\n",
      "Epoch [5/50], Step [100/735], Loss: 0.0956\n",
      "Epoch [5/50], Step [101/735], Loss: 0.0834\n",
      "Epoch [5/50], Step [102/735], Loss: 0.1013\n",
      "Epoch [5/50], Step [103/735], Loss: 0.1075\n",
      "Epoch [5/50], Step [104/735], Loss: 0.5205\n",
      "Epoch [5/50], Step [105/735], Loss: 0.1555\n",
      "Epoch [5/50], Step [106/735], Loss: 0.1396\n",
      "Epoch [5/50], Step [107/735], Loss: 0.0875\n",
      "Epoch [5/50], Step [108/735], Loss: 0.0554\n",
      "Epoch [5/50], Step [109/735], Loss: 0.0566\n",
      "Epoch [5/50], Step [110/735], Loss: 0.1040\n",
      "Epoch [5/50], Step [111/735], Loss: 0.1414\n",
      "Epoch [5/50], Step [112/735], Loss: 0.1331\n",
      "Epoch [5/50], Step [113/735], Loss: 0.1747\n",
      "Epoch [5/50], Step [114/735], Loss: 0.0532\n",
      "Epoch [5/50], Step [115/735], Loss: 0.1310\n",
      "Epoch [5/50], Step [116/735], Loss: 0.3079\n",
      "Epoch [5/50], Step [117/735], Loss: 0.0518\n",
      "Epoch [5/50], Step [118/735], Loss: 0.1419\n",
      "Epoch [5/50], Step [119/735], Loss: 0.2747\n",
      "Epoch [5/50], Step [120/735], Loss: 0.0900\n",
      "Epoch [5/50], Step [121/735], Loss: 0.6567\n",
      "Epoch [5/50], Step [122/735], Loss: 0.0986\n",
      "Epoch [5/50], Step [123/735], Loss: 0.0778\n",
      "Epoch [5/50], Step [124/735], Loss: 0.1257\n",
      "Epoch [5/50], Step [125/735], Loss: 0.1664\n",
      "Epoch [5/50], Step [126/735], Loss: 0.0586\n",
      "Epoch [5/50], Step [127/735], Loss: 0.0625\n",
      "Epoch [5/50], Step [128/735], Loss: 0.6334\n",
      "Epoch [5/50], Step [129/735], Loss: 0.2042\n",
      "Epoch [5/50], Step [130/735], Loss: 0.2953\n",
      "Epoch [5/50], Step [131/735], Loss: 0.6253\n",
      "Epoch [5/50], Step [132/735], Loss: 0.1616\n",
      "Epoch [5/50], Step [133/735], Loss: 0.5363\n",
      "Epoch [5/50], Step [134/735], Loss: 0.1274\n",
      "Epoch [5/50], Step [135/735], Loss: 0.0466\n",
      "Epoch [5/50], Step [136/735], Loss: 0.1246\n",
      "Epoch [5/50], Step [137/735], Loss: 0.1865\n",
      "Epoch [5/50], Step [138/735], Loss: 0.1536\n",
      "Epoch [5/50], Step [139/735], Loss: 0.1106\n",
      "Epoch [5/50], Step [140/735], Loss: 0.1490\n",
      "Epoch [5/50], Step [141/735], Loss: 0.3583\n",
      "Epoch [5/50], Step [142/735], Loss: 0.2935\n",
      "Epoch [5/50], Step [143/735], Loss: 0.0889\n",
      "Epoch [5/50], Step [144/735], Loss: 0.0545\n",
      "Epoch [5/50], Step [145/735], Loss: 0.1119\n",
      "Epoch [5/50], Step [146/735], Loss: 0.0942\n",
      "Epoch [5/50], Step [147/735], Loss: 0.0791\n",
      "Epoch [5/50], Step [148/735], Loss: 0.2870\n",
      "Epoch [5/50], Step [149/735], Loss: 0.0552\n",
      "Epoch [5/50], Step [150/735], Loss: 0.1588\n",
      "Epoch [5/50], Step [151/735], Loss: 0.0763\n",
      "Epoch [5/50], Step [152/735], Loss: 0.1851\n",
      "Epoch [5/50], Step [153/735], Loss: 0.1957\n",
      "Epoch [5/50], Step [154/735], Loss: 0.2014\n",
      "Epoch [5/50], Step [155/735], Loss: 0.3673\n",
      "Epoch [5/50], Step [156/735], Loss: 0.1798\n",
      "Epoch [5/50], Step [157/735], Loss: 0.1348\n",
      "Epoch [5/50], Step [158/735], Loss: 0.0653\n",
      "Epoch [5/50], Step [159/735], Loss: 0.5122\n",
      "Epoch [5/50], Step [160/735], Loss: 0.2296\n",
      "Epoch [5/50], Step [161/735], Loss: 0.2789\n",
      "Epoch [5/50], Step [162/735], Loss: 0.1502\n",
      "Epoch [5/50], Step [163/735], Loss: 0.1396\n",
      "Epoch [5/50], Step [164/735], Loss: 0.1957\n",
      "Epoch [5/50], Step [165/735], Loss: 0.2814\n",
      "Epoch [5/50], Step [166/735], Loss: 0.1771\n",
      "Epoch [5/50], Step [167/735], Loss: 0.1167\n",
      "Epoch [5/50], Step [168/735], Loss: 0.2490\n",
      "Epoch [5/50], Step [169/735], Loss: 0.1376\n",
      "Epoch [5/50], Step [170/735], Loss: 0.0929\n",
      "Epoch [5/50], Step [171/735], Loss: 0.1145\n",
      "Epoch [5/50], Step [172/735], Loss: 0.1763\n",
      "Epoch [5/50], Step [173/735], Loss: 0.1819\n",
      "Epoch [5/50], Step [174/735], Loss: 0.1837\n",
      "Epoch [5/50], Step [175/735], Loss: 0.1206\n",
      "Epoch [5/50], Step [176/735], Loss: 0.1403\n",
      "Epoch [5/50], Step [177/735], Loss: 0.0878\n",
      "Epoch [5/50], Step [178/735], Loss: 0.0845\n",
      "Epoch [5/50], Step [179/735], Loss: 0.0918\n",
      "Epoch [5/50], Step [180/735], Loss: 0.3578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Step [181/735], Loss: 0.1682\n",
      "Epoch [5/50], Step [182/735], Loss: 0.0962\n",
      "Epoch [5/50], Step [183/735], Loss: 0.0679\n",
      "Epoch [5/50], Step [184/735], Loss: 0.0907\n",
      "Epoch [5/50], Step [185/735], Loss: 0.0891\n",
      "Epoch [5/50], Step [186/735], Loss: 0.1370\n",
      "Epoch [5/50], Step [187/735], Loss: 0.0793\n",
      "Epoch [5/50], Step [188/735], Loss: 0.1084\n",
      "Epoch [5/50], Step [189/735], Loss: 0.5385\n",
      "Epoch [5/50], Step [190/735], Loss: 0.1234\n",
      "Epoch [5/50], Step [191/735], Loss: 0.2595\n",
      "Epoch [5/50], Step [192/735], Loss: 0.1667\n",
      "Epoch [5/50], Step [193/735], Loss: 0.0783\n",
      "Epoch [5/50], Step [194/735], Loss: 0.1344\n",
      "Epoch [5/50], Step [195/735], Loss: 0.0674\n",
      "Epoch [5/50], Step [196/735], Loss: 0.3466\n",
      "Epoch [5/50], Step [197/735], Loss: 0.0817\n",
      "Epoch [5/50], Step [198/735], Loss: 0.0778\n",
      "Epoch [5/50], Step [199/735], Loss: 0.0918\n",
      "Epoch [5/50], Step [200/735], Loss: 0.2478\n",
      "Epoch [5/50], Step [201/735], Loss: 0.0717\n",
      "Epoch [5/50], Step [202/735], Loss: 0.0503\n",
      "Epoch [5/50], Step [203/735], Loss: 0.1783\n",
      "Epoch [5/50], Step [204/735], Loss: 0.1330\n",
      "Epoch [5/50], Step [205/735], Loss: 0.1037\n",
      "Epoch [5/50], Step [206/735], Loss: 0.0794\n",
      "Epoch [5/50], Step [207/735], Loss: 0.7809\n",
      "Epoch [5/50], Step [208/735], Loss: 0.2221\n",
      "Epoch [5/50], Step [209/735], Loss: 0.0928\n",
      "Epoch [5/50], Step [210/735], Loss: 0.1305\n",
      "Epoch [5/50], Step [211/735], Loss: 0.2237\n",
      "Epoch [5/50], Step [212/735], Loss: 0.1189\n",
      "Epoch [5/50], Step [213/735], Loss: 0.1442\n",
      "Epoch [5/50], Step [214/735], Loss: 0.3322\n",
      "Epoch [5/50], Step [215/735], Loss: 0.5114\n",
      "Epoch [5/50], Step [216/735], Loss: 0.1032\n",
      "Epoch [5/50], Step [217/735], Loss: 0.0816\n",
      "Epoch [5/50], Step [218/735], Loss: 0.0873\n",
      "Epoch [5/50], Step [219/735], Loss: 0.2002\n",
      "Epoch [5/50], Step [220/735], Loss: 0.0804\n",
      "Epoch [5/50], Step [221/735], Loss: 0.1554\n",
      "Epoch [5/50], Step [222/735], Loss: 0.1567\n",
      "Epoch [5/50], Step [223/735], Loss: 0.0832\n",
      "Epoch [5/50], Step [224/735], Loss: 0.0683\n",
      "Epoch [5/50], Step [225/735], Loss: 0.1336\n",
      "Epoch [5/50], Step [226/735], Loss: 0.3429\n",
      "Epoch [5/50], Step [227/735], Loss: 1.1534\n",
      "Epoch [5/50], Step [228/735], Loss: 0.0582\n",
      "Epoch [5/50], Step [229/735], Loss: 0.2173\n",
      "Epoch [5/50], Step [230/735], Loss: 0.0835\n",
      "Epoch [5/50], Step [231/735], Loss: 0.6299\n",
      "Epoch [5/50], Step [232/735], Loss: 0.2395\n",
      "Epoch [5/50], Step [233/735], Loss: 0.2739\n",
      "Epoch [5/50], Step [234/735], Loss: 0.1146\n",
      "Epoch [5/50], Step [235/735], Loss: 0.3544\n",
      "Epoch [5/50], Step [236/735], Loss: 0.1959\n",
      "Epoch [5/50], Step [237/735], Loss: 0.2539\n",
      "Epoch [5/50], Step [238/735], Loss: 0.1541\n",
      "Epoch [5/50], Step [239/735], Loss: 0.1880\n",
      "Epoch [5/50], Step [240/735], Loss: 0.1183\n",
      "Epoch [5/50], Step [241/735], Loss: 0.1377\n",
      "Epoch [5/50], Step [242/735], Loss: 0.1370\n",
      "Epoch [5/50], Step [243/735], Loss: 0.2281\n",
      "Epoch [5/50], Step [244/735], Loss: 0.1147\n",
      "Epoch [5/50], Step [245/735], Loss: 0.0716\n",
      "Epoch [5/50], Step [246/735], Loss: 0.0874\n",
      "Epoch [5/50], Step [247/735], Loss: 0.1001\n",
      "Epoch [5/50], Step [248/735], Loss: 0.8478\n",
      "Epoch [5/50], Step [249/735], Loss: 0.0708\n",
      "Epoch [5/50], Step [250/735], Loss: 0.0772\n",
      "Epoch [5/50], Step [251/735], Loss: 0.0432\n",
      "Epoch [5/50], Step [252/735], Loss: 0.0567\n",
      "Epoch [5/50], Step [253/735], Loss: 0.0678\n",
      "Epoch [5/50], Step [254/735], Loss: 0.1406\n",
      "Epoch [5/50], Step [255/735], Loss: 0.0611\n",
      "Epoch [5/50], Step [256/735], Loss: 0.1890\n",
      "Epoch [5/50], Step [257/735], Loss: 0.2073\n",
      "Epoch [5/50], Step [258/735], Loss: 0.2987\n",
      "Epoch [5/50], Step [259/735], Loss: 0.0812\n",
      "Epoch [5/50], Step [260/735], Loss: 0.0573\n",
      "Epoch [5/50], Step [261/735], Loss: 0.2678\n",
      "Epoch [5/50], Step [262/735], Loss: 0.0713\n",
      "Epoch [5/50], Step [263/735], Loss: 0.2134\n",
      "Epoch [5/50], Step [264/735], Loss: 0.1081\n",
      "Epoch [5/50], Step [265/735], Loss: 0.0614\n",
      "Epoch [5/50], Step [266/735], Loss: 0.1516\n",
      "Epoch [5/50], Step [267/735], Loss: 0.2577\n",
      "Epoch [5/50], Step [268/735], Loss: 0.0993\n",
      "Epoch [5/50], Step [269/735], Loss: 0.1103\n",
      "Epoch [5/50], Step [270/735], Loss: 0.0801\n",
      "Epoch [5/50], Step [271/735], Loss: 0.1059\n",
      "Epoch [5/50], Step [272/735], Loss: 0.1666\n",
      "Epoch [5/50], Step [273/735], Loss: 0.0854\n",
      "Epoch [5/50], Step [274/735], Loss: 0.2961\n",
      "Epoch [5/50], Step [275/735], Loss: 0.1605\n",
      "Epoch [5/50], Step [276/735], Loss: 0.1310\n",
      "Epoch [5/50], Step [277/735], Loss: 0.2702\n",
      "Epoch [5/50], Step [278/735], Loss: 0.0379\n",
      "Epoch [5/50], Step [279/735], Loss: 0.1224\n",
      "Epoch [5/50], Step [280/735], Loss: 0.0655\n",
      "Epoch [5/50], Step [281/735], Loss: 0.1066\n",
      "Epoch [5/50], Step [282/735], Loss: 0.0716\n",
      "Epoch [5/50], Step [283/735], Loss: 0.1325\n",
      "Epoch [5/50], Step [284/735], Loss: 0.2727\n",
      "Epoch [5/50], Step [285/735], Loss: 0.0600\n",
      "Epoch [5/50], Step [286/735], Loss: 0.2037\n",
      "Epoch [5/50], Step [287/735], Loss: 0.1317\n",
      "Epoch [5/50], Step [288/735], Loss: 0.0858\n",
      "Epoch [5/50], Step [289/735], Loss: 0.3314\n",
      "Epoch [5/50], Step [290/735], Loss: 0.0823\n",
      "Epoch [5/50], Step [291/735], Loss: 0.0923\n",
      "Epoch [5/50], Step [292/735], Loss: 0.2047\n",
      "Epoch [5/50], Step [293/735], Loss: 0.1167\n",
      "Epoch [5/50], Step [294/735], Loss: 0.1631\n",
      "Epoch [5/50], Step [295/735], Loss: 0.2293\n",
      "Epoch [5/50], Step [296/735], Loss: 0.1500\n",
      "Epoch [5/50], Step [297/735], Loss: 0.0707\n",
      "Epoch [5/50], Step [298/735], Loss: 0.0855\n",
      "Epoch [5/50], Step [299/735], Loss: 0.2679\n",
      "Epoch [5/50], Step [300/735], Loss: 0.1203\n",
      "Epoch [5/50], Step [301/735], Loss: 0.1286\n",
      "Epoch [5/50], Step [302/735], Loss: 0.2316\n",
      "Epoch [5/50], Step [303/735], Loss: 0.3753\n",
      "Epoch [5/50], Step [304/735], Loss: 0.1356\n",
      "Epoch [5/50], Step [305/735], Loss: 0.2160\n",
      "Epoch [5/50], Step [306/735], Loss: 0.1811\n",
      "Epoch [5/50], Step [307/735], Loss: 0.1648\n",
      "Epoch [5/50], Step [308/735], Loss: 0.1486\n",
      "Epoch [5/50], Step [309/735], Loss: 0.1984\n",
      "Epoch [5/50], Step [310/735], Loss: 0.3208\n",
      "Epoch [5/50], Step [311/735], Loss: 0.0636\n",
      "Epoch [5/50], Step [312/735], Loss: 0.3264\n",
      "Epoch [5/50], Step [313/735], Loss: 0.1388\n",
      "Epoch [5/50], Step [314/735], Loss: 0.6800\n",
      "Epoch [5/50], Step [315/735], Loss: 0.1163\n",
      "Epoch [5/50], Step [316/735], Loss: 0.1263\n",
      "Epoch [5/50], Step [317/735], Loss: 0.2037\n",
      "Epoch [5/50], Step [318/735], Loss: 0.2217\n",
      "Epoch [5/50], Step [319/735], Loss: 0.2524\n",
      "Epoch [5/50], Step [320/735], Loss: 0.1377\n",
      "Epoch [5/50], Step [321/735], Loss: 0.1064\n",
      "Epoch [5/50], Step [322/735], Loss: 0.3130\n",
      "Epoch [5/50], Step [323/735], Loss: 0.0931\n",
      "Epoch [5/50], Step [324/735], Loss: 0.0947\n",
      "Epoch [5/50], Step [325/735], Loss: 0.1569\n",
      "Epoch [5/50], Step [326/735], Loss: 0.3257\n",
      "Epoch [5/50], Step [327/735], Loss: 0.6900\n",
      "Epoch [5/50], Step [328/735], Loss: 0.0869\n",
      "Epoch [5/50], Step [329/735], Loss: 0.4174\n",
      "Epoch [5/50], Step [330/735], Loss: 0.3663\n",
      "Epoch [5/50], Step [331/735], Loss: 0.1216\n",
      "Epoch [5/50], Step [332/735], Loss: 0.6589\n",
      "Epoch [5/50], Step [333/735], Loss: 0.1987\n",
      "Epoch [5/50], Step [334/735], Loss: 0.2061\n",
      "Epoch [5/50], Step [335/735], Loss: 0.1083\n",
      "Epoch [5/50], Step [336/735], Loss: 0.1405\n",
      "Epoch [5/50], Step [337/735], Loss: 0.1545\n",
      "Epoch [5/50], Step [338/735], Loss: 0.0556\n",
      "Epoch [5/50], Step [339/735], Loss: 0.0708\n",
      "Epoch [5/50], Step [340/735], Loss: 0.1773\n",
      "Epoch [5/50], Step [341/735], Loss: 0.1400\n",
      "Epoch [5/50], Step [342/735], Loss: 0.0517\n",
      "Epoch [5/50], Step [343/735], Loss: 0.0963\n",
      "Epoch [5/50], Step [344/735], Loss: 0.2234\n",
      "Epoch [5/50], Step [345/735], Loss: 0.4306\n",
      "Epoch [5/50], Step [346/735], Loss: 0.1615\n",
      "Epoch [5/50], Step [347/735], Loss: 0.0995\n",
      "Epoch [5/50], Step [348/735], Loss: 0.0987\n",
      "Epoch [5/50], Step [349/735], Loss: 0.3088\n",
      "Epoch [5/50], Step [350/735], Loss: 0.0901\n",
      "Epoch [5/50], Step [351/735], Loss: 0.1469\n",
      "Epoch [5/50], Step [352/735], Loss: 0.0544\n",
      "Epoch [5/50], Step [353/735], Loss: 0.2432\n",
      "Epoch [5/50], Step [354/735], Loss: 0.0955\n",
      "Epoch [5/50], Step [355/735], Loss: 0.3830\n",
      "Epoch [5/50], Step [356/735], Loss: 0.1636\n",
      "Epoch [5/50], Step [357/735], Loss: 0.1221\n",
      "Epoch [5/50], Step [358/735], Loss: 0.1016\n",
      "Epoch [5/50], Step [359/735], Loss: 0.2756\n",
      "Epoch [5/50], Step [360/735], Loss: 0.0908\n",
      "Epoch [5/50], Step [361/735], Loss: 0.0792\n",
      "Epoch [5/50], Step [362/735], Loss: 0.0735\n",
      "Epoch [5/50], Step [363/735], Loss: 0.3647\n",
      "Epoch [5/50], Step [364/735], Loss: 0.1823\n",
      "Epoch [5/50], Step [365/735], Loss: 0.0639\n",
      "Epoch [5/50], Step [366/735], Loss: 0.4026\n",
      "Epoch [5/50], Step [367/735], Loss: 0.1366\n",
      "Epoch [5/50], Step [368/735], Loss: 0.1759\n",
      "Epoch [5/50], Step [369/735], Loss: 0.0995\n",
      "Epoch [5/50], Step [370/735], Loss: 0.0619\n",
      "Epoch [5/50], Step [371/735], Loss: 0.1995\n",
      "Epoch [5/50], Step [372/735], Loss: 0.4285\n",
      "Epoch [5/50], Step [373/735], Loss: 0.6823\n",
      "Epoch [5/50], Step [374/735], Loss: 0.1994\n",
      "Epoch [5/50], Step [375/735], Loss: 0.9069\n",
      "Epoch [5/50], Step [376/735], Loss: 0.0567\n",
      "Epoch [5/50], Step [377/735], Loss: 0.3082\n",
      "Epoch [5/50], Step [378/735], Loss: 0.1121\n",
      "Epoch [5/50], Step [379/735], Loss: 0.1496\n",
      "Epoch [5/50], Step [380/735], Loss: 0.0834\n",
      "Epoch [5/50], Step [381/735], Loss: 0.1531\n",
      "Epoch [5/50], Step [382/735], Loss: 0.0840\n",
      "Epoch [5/50], Step [383/735], Loss: 0.1018\n",
      "Epoch [5/50], Step [384/735], Loss: 0.0766\n",
      "Epoch [5/50], Step [385/735], Loss: 0.1030\n",
      "Epoch [5/50], Step [386/735], Loss: 0.2341\n",
      "Epoch [5/50], Step [387/735], Loss: 0.0630\n",
      "Epoch [5/50], Step [388/735], Loss: 0.0860\n",
      "Epoch [5/50], Step [389/735], Loss: 0.3823\n",
      "Epoch [5/50], Step [390/735], Loss: 0.0399\n",
      "Epoch [5/50], Step [391/735], Loss: 0.0465\n",
      "Epoch [5/50], Step [392/735], Loss: 0.1084\n",
      "Epoch [5/50], Step [393/735], Loss: 0.4378\n",
      "Epoch [5/50], Step [394/735], Loss: 0.0575\n",
      "Epoch [5/50], Step [395/735], Loss: 0.1146\n",
      "Epoch [5/50], Step [396/735], Loss: 0.0965\n",
      "Epoch [5/50], Step [397/735], Loss: 0.1096\n",
      "Epoch [5/50], Step [398/735], Loss: 0.3492\n",
      "Epoch [5/50], Step [399/735], Loss: 0.5460\n",
      "Epoch [5/50], Step [400/735], Loss: 0.1057\n",
      "Epoch [5/50], Step [401/735], Loss: 0.0725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Step [402/735], Loss: 0.2346\n",
      "Epoch [5/50], Step [403/735], Loss: 0.0873\n",
      "Epoch [5/50], Step [404/735], Loss: 0.1681\n",
      "Epoch [5/50], Step [405/735], Loss: 0.6439\n",
      "Epoch [5/50], Step [406/735], Loss: 0.1348\n",
      "Epoch [5/50], Step [407/735], Loss: 0.0633\n",
      "Epoch [5/50], Step [408/735], Loss: 0.1189\n",
      "Epoch [5/50], Step [409/735], Loss: 0.2007\n",
      "Epoch [5/50], Step [410/735], Loss: 0.4284\n",
      "Epoch [5/50], Step [411/735], Loss: 0.0875\n",
      "Epoch [5/50], Step [412/735], Loss: 0.1488\n",
      "Epoch [5/50], Step [413/735], Loss: 0.1250\n",
      "Epoch [5/50], Step [414/735], Loss: 0.1662\n",
      "Epoch [5/50], Step [415/735], Loss: 0.3728\n",
      "Epoch [5/50], Step [416/735], Loss: 0.2189\n",
      "Epoch [5/50], Step [417/735], Loss: 0.0902\n",
      "Epoch [5/50], Step [418/735], Loss: 0.1612\n",
      "Epoch [5/50], Step [419/735], Loss: 0.1493\n",
      "Epoch [5/50], Step [420/735], Loss: 0.0753\n",
      "Epoch [5/50], Step [421/735], Loss: 0.1884\n",
      "Epoch [5/50], Step [422/735], Loss: 0.0961\n",
      "Epoch [5/50], Step [423/735], Loss: 0.1151\n",
      "Epoch [5/50], Step [424/735], Loss: 0.1403\n",
      "Epoch [5/50], Step [425/735], Loss: 0.0840\n",
      "Epoch [5/50], Step [426/735], Loss: 0.2454\n",
      "Epoch [5/50], Step [427/735], Loss: 0.1150\n",
      "Epoch [5/50], Step [428/735], Loss: 0.1253\n",
      "Epoch [5/50], Step [429/735], Loss: 0.7468\n",
      "Epoch [5/50], Step [430/735], Loss: 0.1648\n",
      "Epoch [5/50], Step [431/735], Loss: 0.1787\n",
      "Epoch [5/50], Step [432/735], Loss: 0.1344\n",
      "Epoch [5/50], Step [433/735], Loss: 0.1431\n",
      "Epoch [5/50], Step [434/735], Loss: 0.1180\n",
      "Epoch [5/50], Step [435/735], Loss: 0.0347\n",
      "Epoch [5/50], Step [436/735], Loss: 0.1490\n",
      "Epoch [5/50], Step [437/735], Loss: 0.0846\n",
      "Epoch [5/50], Step [438/735], Loss: 0.0862\n",
      "Epoch [5/50], Step [439/735], Loss: 0.0970\n",
      "Epoch [5/50], Step [440/735], Loss: 0.0933\n",
      "Epoch [5/50], Step [441/735], Loss: 0.3604\n",
      "Epoch [5/50], Step [442/735], Loss: 0.0759\n",
      "Epoch [5/50], Step [443/735], Loss: 0.2904\n",
      "Epoch [5/50], Step [444/735], Loss: 0.2867\n",
      "Epoch [5/50], Step [445/735], Loss: 0.0959\n",
      "Epoch [5/50], Step [446/735], Loss: 0.0640\n",
      "Epoch [5/50], Step [447/735], Loss: 0.0977\n",
      "Epoch [5/50], Step [448/735], Loss: 0.0904\n",
      "Epoch [5/50], Step [449/735], Loss: 0.0816\n",
      "Epoch [5/50], Step [450/735], Loss: 0.0650\n",
      "Epoch [5/50], Step [451/735], Loss: 0.1851\n",
      "Epoch [5/50], Step [452/735], Loss: 0.1249\n",
      "Epoch [5/50], Step [453/735], Loss: 0.3460\n",
      "Epoch [5/50], Step [454/735], Loss: 0.3190\n",
      "Epoch [5/50], Step [455/735], Loss: 0.1952\n",
      "Epoch [5/50], Step [456/735], Loss: 0.0464\n",
      "Epoch [5/50], Step [457/735], Loss: 0.1812\n",
      "Epoch [5/50], Step [458/735], Loss: 0.1560\n",
      "Epoch [5/50], Step [459/735], Loss: 0.1228\n",
      "Epoch [5/50], Step [460/735], Loss: 0.3368\n",
      "Epoch [5/50], Step [461/735], Loss: 0.2098\n",
      "Epoch [5/50], Step [462/735], Loss: 0.1337\n",
      "Epoch [5/50], Step [463/735], Loss: 0.1852\n",
      "Epoch [5/50], Step [464/735], Loss: 0.0865\n",
      "Epoch [5/50], Step [465/735], Loss: 0.0704\n",
      "Epoch [5/50], Step [466/735], Loss: 0.1181\n",
      "Epoch [5/50], Step [467/735], Loss: 0.0774\n",
      "Epoch [5/50], Step [468/735], Loss: 0.0862\n",
      "Epoch [5/50], Step [469/735], Loss: 0.1489\n",
      "Epoch [5/50], Step [470/735], Loss: 0.1526\n",
      "Epoch [5/50], Step [471/735], Loss: 0.1355\n",
      "Epoch [5/50], Step [472/735], Loss: 0.2512\n",
      "Epoch [5/50], Step [473/735], Loss: 0.1239\n",
      "Epoch [5/50], Step [474/735], Loss: 0.2038\n",
      "Epoch [5/50], Step [475/735], Loss: 0.0588\n",
      "Epoch [5/50], Step [476/735], Loss: 0.1616\n",
      "Epoch [5/50], Step [477/735], Loss: 0.4002\n",
      "Epoch [5/50], Step [478/735], Loss: 0.1214\n",
      "Epoch [5/50], Step [479/735], Loss: 0.1172\n",
      "Epoch [5/50], Step [480/735], Loss: 0.0905\n",
      "Epoch [5/50], Step [481/735], Loss: 0.3604\n",
      "Epoch [5/50], Step [482/735], Loss: 0.1612\n",
      "Epoch [5/50], Step [483/735], Loss: 0.2355\n",
      "Epoch [5/50], Step [484/735], Loss: 0.3281\n",
      "Epoch [5/50], Step [485/735], Loss: 0.1307\n",
      "Epoch [5/50], Step [486/735], Loss: 0.0672\n",
      "Epoch [5/50], Step [487/735], Loss: 0.1200\n",
      "Epoch [5/50], Step [488/735], Loss: 0.1420\n",
      "Epoch [5/50], Step [489/735], Loss: 0.0354\n",
      "Epoch [5/50], Step [490/735], Loss: 0.0805\n",
      "Epoch [5/50], Step [491/735], Loss: 0.2026\n",
      "Epoch [5/50], Step [492/735], Loss: 0.0457\n",
      "Epoch [5/50], Step [493/735], Loss: 0.1302\n",
      "Epoch [5/50], Step [494/735], Loss: 0.1039\n",
      "Epoch [5/50], Step [495/735], Loss: 0.0859\n",
      "Epoch [5/50], Step [496/735], Loss: 0.2370\n",
      "Epoch [5/50], Step [497/735], Loss: 0.1062\n",
      "Epoch [5/50], Step [498/735], Loss: 0.1032\n",
      "Epoch [5/50], Step [499/735], Loss: 0.1759\n",
      "Epoch [5/50], Step [500/735], Loss: 0.1181\n",
      "Epoch [5/50], Step [501/735], Loss: 0.0566\n",
      "Epoch [5/50], Step [502/735], Loss: 0.1512\n",
      "Epoch [5/50], Step [503/735], Loss: 0.2070\n",
      "Epoch [5/50], Step [504/735], Loss: 0.1221\n",
      "Epoch [5/50], Step [505/735], Loss: 0.0976\n",
      "Epoch [5/50], Step [506/735], Loss: 0.0684\n",
      "Epoch [5/50], Step [507/735], Loss: 0.0617\n",
      "Epoch [5/50], Step [508/735], Loss: 0.0876\n",
      "Epoch [5/50], Step [509/735], Loss: 0.1585\n",
      "Epoch [5/50], Step [510/735], Loss: 0.0549\n",
      "Epoch [5/50], Step [511/735], Loss: 0.2083\n",
      "Epoch [5/50], Step [512/735], Loss: 0.2571\n",
      "Epoch [5/50], Step [513/735], Loss: 0.0855\n",
      "Epoch [5/50], Step [514/735], Loss: 0.1219\n",
      "Epoch [5/50], Step [515/735], Loss: 0.5545\n",
      "Epoch [5/50], Step [516/735], Loss: 0.0584\n",
      "Epoch [5/50], Step [517/735], Loss: 0.0958\n",
      "Epoch [5/50], Step [518/735], Loss: 0.3020\n",
      "Epoch [5/50], Step [519/735], Loss: 0.1904\n",
      "Epoch [5/50], Step [520/735], Loss: 0.3029\n",
      "Epoch [5/50], Step [521/735], Loss: 0.1124\n",
      "Epoch [5/50], Step [522/735], Loss: 0.0828\n",
      "Epoch [5/50], Step [523/735], Loss: 0.2255\n",
      "Epoch [5/50], Step [524/735], Loss: 0.3878\n",
      "Epoch [5/50], Step [525/735], Loss: 0.0887\n",
      "Epoch [5/50], Step [526/735], Loss: 0.1030\n",
      "Epoch [5/50], Step [527/735], Loss: 0.1179\n",
      "Epoch [5/50], Step [528/735], Loss: 0.1518\n",
      "Epoch [5/50], Step [529/735], Loss: 0.2201\n",
      "Epoch [5/50], Step [530/735], Loss: 0.1157\n",
      "Epoch [5/50], Step [531/735], Loss: 0.1264\n",
      "Epoch [5/50], Step [532/735], Loss: 0.1735\n",
      "Epoch [5/50], Step [533/735], Loss: 0.0726\n",
      "Epoch [5/50], Step [534/735], Loss: 0.1076\n",
      "Epoch [5/50], Step [535/735], Loss: 0.0641\n",
      "Epoch [5/50], Step [536/735], Loss: 0.2887\n",
      "Epoch [5/50], Step [537/735], Loss: 0.1285\n",
      "Epoch [5/50], Step [538/735], Loss: 0.0585\n",
      "Epoch [5/50], Step [539/735], Loss: 0.1473\n",
      "Epoch [5/50], Step [540/735], Loss: 0.1674\n",
      "Epoch [5/50], Step [541/735], Loss: 0.0754\n",
      "Epoch [5/50], Step [542/735], Loss: 0.3266\n",
      "Epoch [5/50], Step [543/735], Loss: 0.1006\n",
      "Epoch [5/50], Step [544/735], Loss: 0.0539\n",
      "Epoch [5/50], Step [545/735], Loss: 0.2084\n",
      "Epoch [5/50], Step [546/735], Loss: 0.3971\n",
      "Epoch [5/50], Step [547/735], Loss: 0.2466\n",
      "Epoch [5/50], Step [548/735], Loss: 0.2071\n",
      "Epoch [5/50], Step [549/735], Loss: 0.2711\n",
      "Epoch [5/50], Step [550/735], Loss: 0.0823\n",
      "Epoch [5/50], Step [551/735], Loss: 0.1687\n",
      "Epoch [5/50], Step [552/735], Loss: 0.0918\n",
      "Epoch [5/50], Step [553/735], Loss: 0.0798\n",
      "Epoch [5/50], Step [554/735], Loss: 0.0915\n",
      "Epoch [5/50], Step [555/735], Loss: 0.0610\n",
      "Epoch [5/50], Step [556/735], Loss: 0.4148\n",
      "Epoch [5/50], Step [557/735], Loss: 0.0983\n",
      "Epoch [5/50], Step [558/735], Loss: 0.0684\n",
      "Epoch [5/50], Step [559/735], Loss: 0.1237\n",
      "Epoch [5/50], Step [560/735], Loss: 0.0746\n",
      "Epoch [5/50], Step [561/735], Loss: 0.0870\n",
      "Epoch [5/50], Step [562/735], Loss: 0.6039\n",
      "Epoch [5/50], Step [563/735], Loss: 0.1026\n",
      "Epoch [5/50], Step [564/735], Loss: 0.1441\n",
      "Epoch [5/50], Step [565/735], Loss: 0.0919\n",
      "Epoch [5/50], Step [566/735], Loss: 0.1394\n",
      "Epoch [5/50], Step [567/735], Loss: 0.3745\n",
      "Epoch [5/50], Step [568/735], Loss: 0.2127\n",
      "Epoch [5/50], Step [569/735], Loss: 0.0851\n",
      "Epoch [5/50], Step [570/735], Loss: 0.0772\n",
      "Epoch [5/50], Step [571/735], Loss: 0.0832\n",
      "Epoch [5/50], Step [572/735], Loss: 0.1017\n",
      "Epoch [5/50], Step [573/735], Loss: 0.2103\n",
      "Epoch [5/50], Step [574/735], Loss: 0.1757\n",
      "Epoch [5/50], Step [575/735], Loss: 0.0702\n",
      "Epoch [5/50], Step [576/735], Loss: 0.3842\n",
      "Epoch [5/50], Step [577/735], Loss: 0.0904\n",
      "Epoch [5/50], Step [578/735], Loss: 0.0725\n",
      "Epoch [5/50], Step [579/735], Loss: 0.2996\n",
      "Epoch [5/50], Step [580/735], Loss: 0.1893\n",
      "Epoch [5/50], Step [581/735], Loss: 0.0968\n",
      "Epoch [5/50], Step [582/735], Loss: 0.1154\n",
      "Epoch [5/50], Step [583/735], Loss: 0.1534\n",
      "Epoch [5/50], Step [584/735], Loss: 0.0922\n",
      "Epoch [5/50], Step [585/735], Loss: 0.0545\n",
      "Epoch [5/50], Step [586/735], Loss: 0.0943\n",
      "Epoch [5/50], Step [587/735], Loss: 0.2303\n",
      "Epoch [5/50], Step [588/735], Loss: 0.0888\n",
      "Epoch [5/50], Step [589/735], Loss: 0.1925\n",
      "Epoch [5/50], Step [590/735], Loss: 0.0484\n",
      "Epoch [5/50], Step [591/735], Loss: 0.0635\n",
      "Epoch [5/50], Step [592/735], Loss: 0.2831\n",
      "Epoch [5/50], Step [593/735], Loss: 0.0597\n",
      "Epoch [5/50], Step [594/735], Loss: 0.0810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Step [595/735], Loss: 0.2463\n",
      "Epoch [5/50], Step [596/735], Loss: 0.1186\n",
      "Epoch [5/50], Step [597/735], Loss: 0.0533\n",
      "Epoch [5/50], Step [598/735], Loss: 0.3631\n",
      "Epoch [5/50], Step [599/735], Loss: 0.1726\n",
      "Epoch [5/50], Step [600/735], Loss: 0.1378\n",
      "Epoch [5/50], Step [601/735], Loss: 0.1640\n",
      "Epoch [5/50], Step [602/735], Loss: 0.5779\n",
      "Epoch [5/50], Step [603/735], Loss: 0.0748\n",
      "Epoch [5/50], Step [604/735], Loss: 0.2846\n",
      "Epoch [5/50], Step [605/735], Loss: 0.1539\n",
      "Epoch [5/50], Step [606/735], Loss: 0.1429\n",
      "Epoch [5/50], Step [607/735], Loss: 0.0591\n",
      "Epoch [5/50], Step [608/735], Loss: 0.0812\n",
      "Epoch [5/50], Step [609/735], Loss: 0.0326\n",
      "Epoch [5/50], Step [610/735], Loss: 0.0926\n",
      "Epoch [5/50], Step [611/735], Loss: 0.0997\n",
      "Epoch [5/50], Step [612/735], Loss: 0.0681\n",
      "Epoch [5/50], Step [613/735], Loss: 0.0803\n",
      "Epoch [5/50], Step [614/735], Loss: 0.7213\n",
      "Epoch [5/50], Step [615/735], Loss: 0.2265\n",
      "Epoch [5/50], Step [616/735], Loss: 0.1771\n",
      "Epoch [5/50], Step [617/735], Loss: 0.1044\n",
      "Epoch [5/50], Step [618/735], Loss: 0.7194\n",
      "Epoch [5/50], Step [619/735], Loss: 0.1655\n",
      "Epoch [5/50], Step [620/735], Loss: 0.0576\n",
      "Epoch [5/50], Step [621/735], Loss: 0.2532\n",
      "Epoch [5/50], Step [622/735], Loss: 0.0435\n",
      "Epoch [5/50], Step [623/735], Loss: 0.1064\n",
      "Epoch [5/50], Step [624/735], Loss: 0.2830\n",
      "Epoch [5/50], Step [625/735], Loss: 0.2220\n",
      "Epoch [5/50], Step [626/735], Loss: 0.4166\n",
      "Epoch [5/50], Step [627/735], Loss: 0.2696\n",
      "Epoch [5/50], Step [628/735], Loss: 0.2824\n",
      "Epoch [5/50], Step [629/735], Loss: 0.0791\n",
      "Epoch [5/50], Step [630/735], Loss: 0.0859\n",
      "Epoch [5/50], Step [631/735], Loss: 0.1588\n",
      "Epoch [5/50], Step [632/735], Loss: 0.1528\n",
      "Epoch [5/50], Step [633/735], Loss: 0.0964\n",
      "Epoch [5/50], Step [634/735], Loss: 0.5005\n",
      "Epoch [5/50], Step [635/735], Loss: 0.0957\n",
      "Epoch [5/50], Step [636/735], Loss: 0.0611\n",
      "Epoch [5/50], Step [637/735], Loss: 0.1588\n",
      "Epoch [5/50], Step [638/735], Loss: 0.0634\n",
      "Epoch [5/50], Step [639/735], Loss: 0.1915\n",
      "Epoch [5/50], Step [640/735], Loss: 0.2436\n",
      "Epoch [5/50], Step [641/735], Loss: 0.0821\n",
      "Epoch [5/50], Step [642/735], Loss: 0.1060\n",
      "Epoch [5/50], Step [643/735], Loss: 0.0531\n",
      "Epoch [5/50], Step [644/735], Loss: 0.1108\n",
      "Epoch [5/50], Step [645/735], Loss: 0.0814\n",
      "Epoch [5/50], Step [646/735], Loss: 0.0909\n",
      "Epoch [5/50], Step [647/735], Loss: 0.2573\n",
      "Epoch [5/50], Step [648/735], Loss: 0.0532\n",
      "Epoch [5/50], Step [649/735], Loss: 0.1764\n",
      "Epoch [5/50], Step [650/735], Loss: 0.1353\n",
      "Epoch [5/50], Step [651/735], Loss: 0.0964\n",
      "Epoch [5/50], Step [652/735], Loss: 0.0779\n",
      "Epoch [5/50], Step [653/735], Loss: 0.0445\n",
      "Epoch [5/50], Step [654/735], Loss: 0.0640\n",
      "Epoch [5/50], Step [655/735], Loss: 0.1085\n",
      "Epoch [5/50], Step [656/735], Loss: 0.1614\n",
      "Epoch [5/50], Step [657/735], Loss: 0.1398\n",
      "Epoch [5/50], Step [658/735], Loss: 0.1866\n",
      "Epoch [5/50], Step [659/735], Loss: 0.3673\n",
      "Epoch [5/50], Step [660/735], Loss: 0.1060\n",
      "Epoch [5/50], Step [661/735], Loss: 0.1874\n",
      "Epoch [5/50], Step [662/735], Loss: 0.1446\n",
      "Epoch [5/50], Step [663/735], Loss: 0.0911\n",
      "Epoch [5/50], Step [664/735], Loss: 0.0443\n",
      "Epoch [5/50], Step [665/735], Loss: 0.0597\n",
      "Epoch [5/50], Step [666/735], Loss: 0.0425\n",
      "Epoch [5/50], Step [667/735], Loss: 0.1366\n",
      "Epoch [5/50], Step [668/735], Loss: 0.2045\n",
      "Epoch [5/50], Step [669/735], Loss: 0.1658\n",
      "Epoch [5/50], Step [670/735], Loss: 0.1721\n",
      "Epoch [5/50], Step [671/735], Loss: 0.0690\n",
      "Epoch [5/50], Step [672/735], Loss: 0.2563\n",
      "Epoch [5/50], Step [673/735], Loss: 0.0553\n",
      "Epoch [5/50], Step [674/735], Loss: 0.0492\n",
      "Epoch [5/50], Step [675/735], Loss: 0.2070\n",
      "Epoch [5/50], Step [676/735], Loss: 0.1592\n",
      "Epoch [5/50], Step [677/735], Loss: 0.0998\n",
      "Epoch [5/50], Step [678/735], Loss: 0.0662\n",
      "Epoch [5/50], Step [679/735], Loss: 0.1195\n",
      "Epoch [5/50], Step [680/735], Loss: 0.1685\n",
      "Epoch [5/50], Step [681/735], Loss: 0.0699\n",
      "Epoch [5/50], Step [682/735], Loss: 0.1081\n",
      "Epoch [5/50], Step [683/735], Loss: 0.0657\n",
      "Epoch [5/50], Step [684/735], Loss: 0.3119\n",
      "Epoch [5/50], Step [685/735], Loss: 0.0640\n",
      "Epoch [5/50], Step [686/735], Loss: 0.0746\n",
      "Epoch [5/50], Step [687/735], Loss: 0.2653\n",
      "Epoch [5/50], Step [688/735], Loss: 0.1435\n",
      "Epoch [5/50], Step [689/735], Loss: 0.1993\n",
      "Epoch [5/50], Step [690/735], Loss: 0.0558\n",
      "Epoch [5/50], Step [691/735], Loss: 0.0397\n",
      "Epoch [5/50], Step [692/735], Loss: 0.0649\n",
      "Epoch [5/50], Step [693/735], Loss: 0.0803\n",
      "Epoch [5/50], Step [694/735], Loss: 0.4241\n",
      "Epoch [5/50], Step [695/735], Loss: 0.1868\n",
      "Epoch [5/50], Step [696/735], Loss: 0.2082\n",
      "Epoch [5/50], Step [697/735], Loss: 0.0656\n",
      "Epoch [5/50], Step [698/735], Loss: 0.0753\n",
      "Epoch [5/50], Step [699/735], Loss: 0.1426\n",
      "Epoch [5/50], Step [700/735], Loss: 0.2046\n",
      "Epoch [5/50], Step [701/735], Loss: 0.2250\n",
      "Epoch [5/50], Step [702/735], Loss: 0.0419\n",
      "Epoch [5/50], Step [703/735], Loss: 0.2372\n",
      "Epoch [5/50], Step [704/735], Loss: 0.1600\n",
      "Epoch [5/50], Step [705/735], Loss: 0.0845\n",
      "Epoch [5/50], Step [706/735], Loss: 0.0743\n",
      "Epoch [5/50], Step [707/735], Loss: 0.1868\n",
      "Epoch [5/50], Step [708/735], Loss: 0.1151\n",
      "Epoch [5/50], Step [709/735], Loss: 0.9317\n",
      "Epoch [5/50], Step [710/735], Loss: 0.1014\n",
      "Epoch [5/50], Step [711/735], Loss: 0.1889\n",
      "Epoch [5/50], Step [712/735], Loss: 0.1489\n",
      "Epoch [5/50], Step [713/735], Loss: 0.0757\n",
      "Epoch [5/50], Step [714/735], Loss: 0.0587\n",
      "Epoch [5/50], Step [715/735], Loss: 0.0501\n",
      "Epoch [5/50], Step [716/735], Loss: 0.3935\n",
      "Epoch [5/50], Step [717/735], Loss: 0.0995\n",
      "Epoch [5/50], Step [718/735], Loss: 0.1276\n",
      "Epoch [5/50], Step [719/735], Loss: 0.3850\n",
      "Epoch [5/50], Step [720/735], Loss: 0.0591\n",
      "Epoch [5/50], Step [721/735], Loss: 0.0546\n",
      "Epoch [5/50], Step [722/735], Loss: 0.1945\n",
      "Epoch [5/50], Step [723/735], Loss: 0.0713\n",
      "Epoch [5/50], Step [724/735], Loss: 0.0748\n",
      "Epoch [5/50], Step [725/735], Loss: 0.1326\n",
      "Epoch [5/50], Step [726/735], Loss: 0.0868\n",
      "Epoch [5/50], Step [727/735], Loss: 0.0417\n",
      "Epoch [5/50], Step [728/735], Loss: 0.0381\n",
      "Epoch [5/50], Step [729/735], Loss: 0.0553\n",
      "Epoch [5/50], Step [730/735], Loss: 0.0773\n",
      "Epoch [5/50], Step [731/735], Loss: 0.1173\n",
      "Epoch [5/50], Step [732/735], Loss: 0.0688\n",
      "Epoch [5/50], Step [733/735], Loss: 0.0821\n",
      "Epoch [5/50], Step [734/735], Loss: 0.0809\n",
      "Epoch [5/50], Step [735/735], Loss: 0.1353\n",
      "Epoch [6/50], Step [1/735], Loss: 0.0995\n",
      "Epoch [6/50], Step [2/735], Loss: 0.1051\n",
      "Epoch [6/50], Step [3/735], Loss: 0.3598\n",
      "Epoch [6/50], Step [4/735], Loss: 0.2793\n",
      "Epoch [6/50], Step [5/735], Loss: 0.1974\n",
      "Epoch [6/50], Step [6/735], Loss: 0.0481\n",
      "Epoch [6/50], Step [7/735], Loss: 0.0727\n",
      "Epoch [6/50], Step [8/735], Loss: 0.1151\n",
      "Epoch [6/50], Step [9/735], Loss: 0.1400\n",
      "Epoch [6/50], Step [10/735], Loss: 0.0648\n",
      "Epoch [6/50], Step [11/735], Loss: 0.0886\n",
      "Epoch [6/50], Step [12/735], Loss: 0.1103\n",
      "Epoch [6/50], Step [13/735], Loss: 0.1415\n",
      "Epoch [6/50], Step [14/735], Loss: 0.0441\n",
      "Epoch [6/50], Step [15/735], Loss: 0.1202\n",
      "Epoch [6/50], Step [16/735], Loss: 0.0486\n",
      "Epoch [6/50], Step [17/735], Loss: 0.4073\n",
      "Epoch [6/50], Step [18/735], Loss: 0.0494\n",
      "Epoch [6/50], Step [19/735], Loss: 0.1608\n",
      "Epoch [6/50], Step [20/735], Loss: 0.1504\n",
      "Epoch [6/50], Step [21/735], Loss: 0.1008\n",
      "Epoch [6/50], Step [22/735], Loss: 0.0784\n",
      "Epoch [6/50], Step [23/735], Loss: 0.1137\n",
      "Epoch [6/50], Step [24/735], Loss: 0.0762\n",
      "Epoch [6/50], Step [25/735], Loss: 0.0416\n",
      "Epoch [6/50], Step [26/735], Loss: 0.0719\n",
      "Epoch [6/50], Step [27/735], Loss: 0.3289\n",
      "Epoch [6/50], Step [28/735], Loss: 0.0556\n",
      "Epoch [6/50], Step [29/735], Loss: 0.0989\n",
      "Epoch [6/50], Step [30/735], Loss: 0.1018\n",
      "Epoch [6/50], Step [31/735], Loss: 0.0380\n",
      "Epoch [6/50], Step [32/735], Loss: 0.0980\n",
      "Epoch [6/50], Step [33/735], Loss: 0.1699\n",
      "Epoch [6/50], Step [34/735], Loss: 0.2939\n",
      "Epoch [6/50], Step [35/735], Loss: 0.0400\n",
      "Epoch [6/50], Step [36/735], Loss: 0.1679\n",
      "Epoch [6/50], Step [37/735], Loss: 0.0340\n",
      "Epoch [6/50], Step [38/735], Loss: 0.1029\n",
      "Epoch [6/50], Step [39/735], Loss: 0.3383\n",
      "Epoch [6/50], Step [40/735], Loss: 0.1714\n",
      "Epoch [6/50], Step [41/735], Loss: 0.0775\n",
      "Epoch [6/50], Step [42/735], Loss: 0.0542\n",
      "Epoch [6/50], Step [43/735], Loss: 0.0705\n",
      "Epoch [6/50], Step [44/735], Loss: 0.0407\n",
      "Epoch [6/50], Step [45/735], Loss: 0.2231\n",
      "Epoch [6/50], Step [46/735], Loss: 0.0375\n",
      "Epoch [6/50], Step [47/735], Loss: 0.1668\n",
      "Epoch [6/50], Step [48/735], Loss: 0.0708\n",
      "Epoch [6/50], Step [49/735], Loss: 0.0406\n",
      "Epoch [6/50], Step [50/735], Loss: 0.2256\n",
      "Epoch [6/50], Step [51/735], Loss: 0.0676\n",
      "Epoch [6/50], Step [52/735], Loss: 0.3902\n",
      "Epoch [6/50], Step [53/735], Loss: 0.0522\n",
      "Epoch [6/50], Step [54/735], Loss: 0.0451\n",
      "Epoch [6/50], Step [55/735], Loss: 0.0785\n",
      "Epoch [6/50], Step [56/735], Loss: 0.0899\n",
      "Epoch [6/50], Step [57/735], Loss: 0.0925\n",
      "Epoch [6/50], Step [58/735], Loss: 0.0902\n",
      "Epoch [6/50], Step [59/735], Loss: 0.2671\n",
      "Epoch [6/50], Step [60/735], Loss: 0.0624\n",
      "Epoch [6/50], Step [61/735], Loss: 0.1683\n",
      "Epoch [6/50], Step [62/735], Loss: 0.2854\n",
      "Epoch [6/50], Step [63/735], Loss: 0.0711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Step [64/735], Loss: 0.2141\n",
      "Epoch [6/50], Step [65/735], Loss: 0.0904\n",
      "Epoch [6/50], Step [66/735], Loss: 0.0951\n",
      "Epoch [6/50], Step [67/735], Loss: 0.2674\n",
      "Epoch [6/50], Step [68/735], Loss: 0.1067\n",
      "Epoch [6/50], Step [69/735], Loss: 0.0522\n",
      "Epoch [6/50], Step [70/735], Loss: 0.2250\n",
      "Epoch [6/50], Step [71/735], Loss: 0.0604\n",
      "Epoch [6/50], Step [72/735], Loss: 0.1009\n",
      "Epoch [6/50], Step [73/735], Loss: 0.1975\n",
      "Epoch [6/50], Step [74/735], Loss: 0.1001\n",
      "Epoch [6/50], Step [75/735], Loss: 0.0597\n",
      "Epoch [6/50], Step [76/735], Loss: 0.1255\n",
      "Epoch [6/50], Step [77/735], Loss: 0.4282\n",
      "Epoch [6/50], Step [78/735], Loss: 0.1063\n",
      "Epoch [6/50], Step [79/735], Loss: 0.4177\n",
      "Epoch [6/50], Step [80/735], Loss: 0.1885\n",
      "Epoch [6/50], Step [81/735], Loss: 0.3142\n",
      "Epoch [6/50], Step [82/735], Loss: 0.0572\n",
      "Epoch [6/50], Step [83/735], Loss: 0.1034\n",
      "Epoch [6/50], Step [84/735], Loss: 0.0918\n",
      "Epoch [6/50], Step [85/735], Loss: 0.1762\n",
      "Epoch [6/50], Step [86/735], Loss: 0.1178\n",
      "Epoch [6/50], Step [87/735], Loss: 0.1478\n",
      "Epoch [6/50], Step [88/735], Loss: 0.0632\n",
      "Epoch [6/50], Step [89/735], Loss: 0.2141\n",
      "Epoch [6/50], Step [90/735], Loss: 0.0678\n",
      "Epoch [6/50], Step [91/735], Loss: 0.1326\n",
      "Epoch [6/50], Step [92/735], Loss: 0.1402\n",
      "Epoch [6/50], Step [93/735], Loss: 0.1059\n",
      "Epoch [6/50], Step [94/735], Loss: 0.1064\n",
      "Epoch [6/50], Step [95/735], Loss: 0.2210\n",
      "Epoch [6/50], Step [96/735], Loss: 0.1015\n",
      "Epoch [6/50], Step [97/735], Loss: 0.2041\n",
      "Epoch [6/50], Step [98/735], Loss: 0.1202\n",
      "Epoch [6/50], Step [99/735], Loss: 0.0316\n",
      "Epoch [6/50], Step [100/735], Loss: 0.1306\n",
      "Epoch [6/50], Step [101/735], Loss: 0.2026\n",
      "Epoch [6/50], Step [102/735], Loss: 0.1718\n",
      "Epoch [6/50], Step [103/735], Loss: 0.1243\n",
      "Epoch [6/50], Step [104/735], Loss: 0.2112\n",
      "Epoch [6/50], Step [105/735], Loss: 0.0607\n",
      "Epoch [6/50], Step [106/735], Loss: 0.2031\n",
      "Epoch [6/50], Step [107/735], Loss: 0.8355\n",
      "Epoch [6/50], Step [108/735], Loss: 0.1420\n",
      "Epoch [6/50], Step [109/735], Loss: 0.0722\n",
      "Epoch [6/50], Step [110/735], Loss: 0.2209\n",
      "Epoch [6/50], Step [111/735], Loss: 0.1830\n",
      "Epoch [6/50], Step [112/735], Loss: 0.1189\n",
      "Epoch [6/50], Step [113/735], Loss: 0.1481\n",
      "Epoch [6/50], Step [114/735], Loss: 0.0791\n",
      "Epoch [6/50], Step [115/735], Loss: 0.0656\n",
      "Epoch [6/50], Step [116/735], Loss: 0.0754\n",
      "Epoch [6/50], Step [117/735], Loss: 0.1305\n",
      "Epoch [6/50], Step [118/735], Loss: 0.2646\n",
      "Epoch [6/50], Step [119/735], Loss: 0.0881\n",
      "Epoch [6/50], Step [120/735], Loss: 0.1088\n",
      "Epoch [6/50], Step [121/735], Loss: 0.2169\n",
      "Epoch [6/50], Step [122/735], Loss: 0.1909\n",
      "Epoch [6/50], Step [123/735], Loss: 0.2679\n",
      "Epoch [6/50], Step [124/735], Loss: 0.0906\n",
      "Epoch [6/50], Step [125/735], Loss: 0.1182\n",
      "Epoch [6/50], Step [126/735], Loss: 0.1044\n",
      "Epoch [6/50], Step [127/735], Loss: 0.1113\n",
      "Epoch [6/50], Step [128/735], Loss: 0.1556\n",
      "Epoch [6/50], Step [129/735], Loss: 0.1845\n",
      "Epoch [6/50], Step [130/735], Loss: 0.1336\n",
      "Epoch [6/50], Step [131/735], Loss: 0.0786\n",
      "Epoch [6/50], Step [132/735], Loss: 0.2227\n",
      "Epoch [6/50], Step [133/735], Loss: 0.0433\n",
      "Epoch [6/50], Step [134/735], Loss: 0.0798\n",
      "Epoch [6/50], Step [135/735], Loss: 0.0861\n",
      "Epoch [6/50], Step [136/735], Loss: 0.0459\n",
      "Epoch [6/50], Step [137/735], Loss: 0.0804\n",
      "Epoch [6/50], Step [138/735], Loss: 0.0721\n",
      "Epoch [6/50], Step [139/735], Loss: 0.0923\n",
      "Epoch [6/50], Step [140/735], Loss: 0.1165\n",
      "Epoch [6/50], Step [141/735], Loss: 0.1288\n",
      "Epoch [6/50], Step [142/735], Loss: 0.1160\n",
      "Epoch [6/50], Step [143/735], Loss: 0.0761\n",
      "Epoch [6/50], Step [144/735], Loss: 0.0780\n",
      "Epoch [6/50], Step [145/735], Loss: 0.0845\n",
      "Epoch [6/50], Step [146/735], Loss: 0.0523\n",
      "Epoch [6/50], Step [147/735], Loss: 0.1441\n",
      "Epoch [6/50], Step [148/735], Loss: 0.0416\n",
      "Epoch [6/50], Step [149/735], Loss: 0.1071\n",
      "Epoch [6/50], Step [150/735], Loss: 0.2976\n",
      "Epoch [6/50], Step [151/735], Loss: 0.1152\n",
      "Epoch [6/50], Step [152/735], Loss: 0.0565\n",
      "Epoch [6/50], Step [153/735], Loss: 0.0773\n",
      "Epoch [6/50], Step [154/735], Loss: 0.1289\n",
      "Epoch [6/50], Step [155/735], Loss: 0.3942\n",
      "Epoch [6/50], Step [156/735], Loss: 0.1204\n",
      "Epoch [6/50], Step [157/735], Loss: 0.1733\n",
      "Epoch [6/50], Step [158/735], Loss: 0.1246\n",
      "Epoch [6/50], Step [159/735], Loss: 0.0371\n",
      "Epoch [6/50], Step [160/735], Loss: 0.0535\n",
      "Epoch [6/50], Step [161/735], Loss: 0.0765\n",
      "Epoch [6/50], Step [162/735], Loss: 0.1175\n",
      "Epoch [6/50], Step [163/735], Loss: 0.0966\n",
      "Epoch [6/50], Step [164/735], Loss: 0.0539\n",
      "Epoch [6/50], Step [165/735], Loss: 0.1303\n",
      "Epoch [6/50], Step [166/735], Loss: 0.2049\n",
      "Epoch [6/50], Step [167/735], Loss: 0.1141\n",
      "Epoch [6/50], Step [168/735], Loss: 0.2370\n",
      "Epoch [6/50], Step [169/735], Loss: 0.1034\n",
      "Epoch [6/50], Step [170/735], Loss: 0.0718\n",
      "Epoch [6/50], Step [171/735], Loss: 0.0527\n",
      "Epoch [6/50], Step [172/735], Loss: 0.1554\n",
      "Epoch [6/50], Step [173/735], Loss: 0.1466\n",
      "Epoch [6/50], Step [174/735], Loss: 0.1298\n",
      "Epoch [6/50], Step [175/735], Loss: 0.1684\n",
      "Epoch [6/50], Step [176/735], Loss: 0.1436\n",
      "Epoch [6/50], Step [177/735], Loss: 0.0937\n",
      "Epoch [6/50], Step [178/735], Loss: 0.0808\n",
      "Epoch [6/50], Step [179/735], Loss: 0.1184\n",
      "Epoch [6/50], Step [180/735], Loss: 0.1448\n",
      "Epoch [6/50], Step [181/735], Loss: 0.0829\n",
      "Epoch [6/50], Step [182/735], Loss: 0.1579\n",
      "Epoch [6/50], Step [183/735], Loss: 0.1046\n",
      "Epoch [6/50], Step [184/735], Loss: 0.1334\n",
      "Epoch [6/50], Step [185/735], Loss: 0.1355\n",
      "Epoch [6/50], Step [186/735], Loss: 0.1391\n",
      "Epoch [6/50], Step [187/735], Loss: 0.0601\n",
      "Epoch [6/50], Step [188/735], Loss: 0.2483\n",
      "Epoch [6/50], Step [189/735], Loss: 0.0357\n",
      "Epoch [6/50], Step [190/735], Loss: 0.0998\n",
      "Epoch [6/50], Step [191/735], Loss: 0.0883\n",
      "Epoch [6/50], Step [192/735], Loss: 0.3890\n",
      "Epoch [6/50], Step [193/735], Loss: 0.0519\n",
      "Epoch [6/50], Step [194/735], Loss: 0.0390\n",
      "Epoch [6/50], Step [195/735], Loss: 0.1002\n",
      "Epoch [6/50], Step [196/735], Loss: 0.0897\n",
      "Epoch [6/50], Step [197/735], Loss: 0.1678\n",
      "Epoch [6/50], Step [198/735], Loss: 0.1609\n",
      "Epoch [6/50], Step [199/735], Loss: 0.1015\n",
      "Epoch [6/50], Step [200/735], Loss: 0.0709\n",
      "Epoch [6/50], Step [201/735], Loss: 0.1657\n",
      "Epoch [6/50], Step [202/735], Loss: 0.1804\n",
      "Epoch [6/50], Step [203/735], Loss: 0.1756\n",
      "Epoch [6/50], Step [204/735], Loss: 0.0293\n",
      "Epoch [6/50], Step [205/735], Loss: 0.0437\n",
      "Epoch [6/50], Step [206/735], Loss: 0.0548\n",
      "Epoch [6/50], Step [207/735], Loss: 0.0949\n",
      "Epoch [6/50], Step [208/735], Loss: 0.0600\n",
      "Epoch [6/50], Step [209/735], Loss: 0.6155\n",
      "Epoch [6/50], Step [210/735], Loss: 0.1247\n",
      "Epoch [6/50], Step [211/735], Loss: 0.0831\n",
      "Epoch [6/50], Step [212/735], Loss: 0.1851\n",
      "Epoch [6/50], Step [213/735], Loss: 0.0682\n",
      "Epoch [6/50], Step [214/735], Loss: 0.1327\n",
      "Epoch [6/50], Step [215/735], Loss: 0.0892\n",
      "Epoch [6/50], Step [216/735], Loss: 0.3976\n",
      "Epoch [6/50], Step [217/735], Loss: 0.5138\n",
      "Epoch [6/50], Step [218/735], Loss: 0.1076\n",
      "Epoch [6/50], Step [219/735], Loss: 0.2204\n",
      "Epoch [6/50], Step [220/735], Loss: 0.1253\n",
      "Epoch [6/50], Step [221/735], Loss: 0.1749\n",
      "Epoch [6/50], Step [222/735], Loss: 0.0720\n",
      "Epoch [6/50], Step [223/735], Loss: 0.5443\n",
      "Epoch [6/50], Step [224/735], Loss: 0.2522\n",
      "Epoch [6/50], Step [225/735], Loss: 0.0617\n",
      "Epoch [6/50], Step [226/735], Loss: 0.0547\n",
      "Epoch [6/50], Step [227/735], Loss: 0.1256\n",
      "Epoch [6/50], Step [228/735], Loss: 0.0846\n",
      "Epoch [6/50], Step [229/735], Loss: 0.1669\n",
      "Epoch [6/50], Step [230/735], Loss: 0.0951\n",
      "Epoch [6/50], Step [231/735], Loss: 0.3084\n",
      "Epoch [6/50], Step [232/735], Loss: 0.2116\n",
      "Epoch [6/50], Step [233/735], Loss: 0.6633\n",
      "Epoch [6/50], Step [234/735], Loss: 0.0544\n",
      "Epoch [6/50], Step [235/735], Loss: 0.2045\n",
      "Epoch [6/50], Step [236/735], Loss: 0.0665\n",
      "Epoch [6/50], Step [237/735], Loss: 0.0951\n",
      "Epoch [6/50], Step [238/735], Loss: 0.1092\n",
      "Epoch [6/50], Step [239/735], Loss: 0.2429\n",
      "Epoch [6/50], Step [240/735], Loss: 0.0729\n",
      "Epoch [6/50], Step [241/735], Loss: 0.1739\n",
      "Epoch [6/50], Step [242/735], Loss: 0.1147\n",
      "Epoch [6/50], Step [243/735], Loss: 0.1595\n",
      "Epoch [6/50], Step [244/735], Loss: 0.0622\n",
      "Epoch [6/50], Step [245/735], Loss: 0.1475\n",
      "Epoch [6/50], Step [246/735], Loss: 0.1388\n",
      "Epoch [6/50], Step [247/735], Loss: 0.5797\n",
      "Epoch [6/50], Step [248/735], Loss: 0.2760\n",
      "Epoch [6/50], Step [249/735], Loss: 0.1179\n",
      "Epoch [6/50], Step [250/735], Loss: 0.1510\n",
      "Epoch [6/50], Step [251/735], Loss: 0.0745\n",
      "Epoch [6/50], Step [252/735], Loss: 0.0805\n",
      "Epoch [6/50], Step [253/735], Loss: 0.0740\n",
      "Epoch [6/50], Step [254/735], Loss: 0.4546\n",
      "Epoch [6/50], Step [255/735], Loss: 0.0778\n",
      "Epoch [6/50], Step [256/735], Loss: 0.1341\n",
      "Epoch [6/50], Step [257/735], Loss: 0.1965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Step [258/735], Loss: 0.1078\n",
      "Epoch [6/50], Step [259/735], Loss: 0.1345\n",
      "Epoch [6/50], Step [260/735], Loss: 0.1174\n",
      "Epoch [6/50], Step [261/735], Loss: 0.1107\n",
      "Epoch [6/50], Step [262/735], Loss: 0.2912\n",
      "Epoch [6/50], Step [263/735], Loss: 0.1957\n",
      "Epoch [6/50], Step [264/735], Loss: 0.1100\n",
      "Epoch [6/50], Step [265/735], Loss: 0.0868\n",
      "Epoch [6/50], Step [266/735], Loss: 0.1696\n",
      "Epoch [6/50], Step [267/735], Loss: 0.1175\n",
      "Epoch [6/50], Step [268/735], Loss: 0.0480\n",
      "Epoch [6/50], Step [269/735], Loss: 0.0535\n",
      "Epoch [6/50], Step [270/735], Loss: 0.0507\n",
      "Epoch [6/50], Step [271/735], Loss: 0.1212\n",
      "Epoch [6/50], Step [272/735], Loss: 0.1046\n",
      "Epoch [6/50], Step [273/735], Loss: 0.1444\n",
      "Epoch [6/50], Step [274/735], Loss: 0.1551\n",
      "Epoch [6/50], Step [275/735], Loss: 0.0998\n",
      "Epoch [6/50], Step [276/735], Loss: 0.0634\n",
      "Epoch [6/50], Step [277/735], Loss: 0.0609\n",
      "Epoch [6/50], Step [278/735], Loss: 0.0305\n",
      "Epoch [6/50], Step [279/735], Loss: 0.0559\n",
      "Epoch [6/50], Step [280/735], Loss: 0.1629\n",
      "Epoch [6/50], Step [281/735], Loss: 0.7043\n",
      "Epoch [6/50], Step [282/735], Loss: 0.0576\n",
      "Epoch [6/50], Step [283/735], Loss: 0.2281\n",
      "Epoch [6/50], Step [284/735], Loss: 0.1253\n",
      "Epoch [6/50], Step [285/735], Loss: 0.1291\n",
      "Epoch [6/50], Step [286/735], Loss: 0.0716\n",
      "Epoch [6/50], Step [287/735], Loss: 0.0852\n",
      "Epoch [6/50], Step [288/735], Loss: 0.1061\n",
      "Epoch [6/50], Step [289/735], Loss: 0.1696\n",
      "Epoch [6/50], Step [290/735], Loss: 0.3783\n",
      "Epoch [6/50], Step [291/735], Loss: 0.1635\n",
      "Epoch [6/50], Step [292/735], Loss: 0.1367\n",
      "Epoch [6/50], Step [293/735], Loss: 0.3930\n",
      "Epoch [6/50], Step [294/735], Loss: 0.2141\n",
      "Epoch [6/50], Step [295/735], Loss: 0.2273\n",
      "Epoch [6/50], Step [296/735], Loss: 0.2426\n",
      "Epoch [6/50], Step [297/735], Loss: 0.0420\n",
      "Epoch [6/50], Step [298/735], Loss: 0.0702\n",
      "Epoch [6/50], Step [299/735], Loss: 0.0959\n",
      "Epoch [6/50], Step [300/735], Loss: 0.0623\n",
      "Epoch [6/50], Step [301/735], Loss: 0.1639\n",
      "Epoch [6/50], Step [302/735], Loss: 0.1048\n",
      "Epoch [6/50], Step [303/735], Loss: 0.1163\n",
      "Epoch [6/50], Step [304/735], Loss: 0.0812\n",
      "Epoch [6/50], Step [305/735], Loss: 0.2710\n",
      "Epoch [6/50], Step [306/735], Loss: 0.0480\n",
      "Epoch [6/50], Step [307/735], Loss: 0.0751\n",
      "Epoch [6/50], Step [308/735], Loss: 0.0986\n",
      "Epoch [6/50], Step [309/735], Loss: 0.0907\n",
      "Epoch [6/50], Step [310/735], Loss: 0.0474\n",
      "Epoch [6/50], Step [311/735], Loss: 0.1032\n",
      "Epoch [6/50], Step [312/735], Loss: 0.1633\n",
      "Epoch [6/50], Step [313/735], Loss: 0.1163\n",
      "Epoch [6/50], Step [314/735], Loss: 0.4979\n",
      "Epoch [6/50], Step [315/735], Loss: 0.0662\n",
      "Epoch [6/50], Step [316/735], Loss: 0.0787\n",
      "Epoch [6/50], Step [317/735], Loss: 0.1817\n",
      "Epoch [6/50], Step [318/735], Loss: 0.0852\n",
      "Epoch [6/50], Step [319/735], Loss: 0.0496\n",
      "Epoch [6/50], Step [320/735], Loss: 0.0479\n",
      "Epoch [6/50], Step [321/735], Loss: 0.0910\n",
      "Epoch [6/50], Step [322/735], Loss: 0.1199\n",
      "Epoch [6/50], Step [323/735], Loss: 0.5253\n",
      "Epoch [6/50], Step [324/735], Loss: 0.0852\n",
      "Epoch [6/50], Step [325/735], Loss: 0.0744\n",
      "Epoch [6/50], Step [326/735], Loss: 0.1946\n",
      "Epoch [6/50], Step [327/735], Loss: 0.0558\n",
      "Epoch [6/50], Step [328/735], Loss: 0.1903\n",
      "Epoch [6/50], Step [329/735], Loss: 0.1932\n",
      "Epoch [6/50], Step [330/735], Loss: 0.0808\n",
      "Epoch [6/50], Step [331/735], Loss: 0.1245\n",
      "Epoch [6/50], Step [332/735], Loss: 0.0651\n",
      "Epoch [6/50], Step [333/735], Loss: 0.3120\n",
      "Epoch [6/50], Step [334/735], Loss: 0.0803\n",
      "Epoch [6/50], Step [335/735], Loss: 0.1114\n",
      "Epoch [6/50], Step [336/735], Loss: 0.2125\n",
      "Epoch [6/50], Step [337/735], Loss: 0.1643\n",
      "Epoch [6/50], Step [338/735], Loss: 0.1682\n",
      "Epoch [6/50], Step [339/735], Loss: 0.0687\n",
      "Epoch [6/50], Step [340/735], Loss: 0.0993\n",
      "Epoch [6/50], Step [341/735], Loss: 0.0457\n",
      "Epoch [6/50], Step [342/735], Loss: 0.1461\n",
      "Epoch [6/50], Step [343/735], Loss: 0.1159\n",
      "Epoch [6/50], Step [344/735], Loss: 0.1517\n",
      "Epoch [6/50], Step [345/735], Loss: 0.2553\n",
      "Epoch [6/50], Step [346/735], Loss: 0.0519\n",
      "Epoch [6/50], Step [347/735], Loss: 0.0708\n",
      "Epoch [6/50], Step [348/735], Loss: 0.1344\n",
      "Epoch [6/50], Step [349/735], Loss: 0.3030\n",
      "Epoch [6/50], Step [350/735], Loss: 0.1817\n",
      "Epoch [6/50], Step [351/735], Loss: 0.0733\n",
      "Epoch [6/50], Step [352/735], Loss: 0.0741\n",
      "Epoch [6/50], Step [353/735], Loss: 0.0891\n",
      "Epoch [6/50], Step [354/735], Loss: 0.0669\n",
      "Epoch [6/50], Step [355/735], Loss: 0.0662\n",
      "Epoch [6/50], Step [356/735], Loss: 0.0928\n",
      "Epoch [6/50], Step [357/735], Loss: 0.0652\n",
      "Epoch [6/50], Step [358/735], Loss: 0.1592\n",
      "Epoch [6/50], Step [359/735], Loss: 0.4355\n",
      "Epoch [6/50], Step [360/735], Loss: 0.0597\n",
      "Epoch [6/50], Step [361/735], Loss: 0.3168\n",
      "Epoch [6/50], Step [362/735], Loss: 0.1214\n",
      "Epoch [6/50], Step [363/735], Loss: 0.1631\n",
      "Epoch [6/50], Step [364/735], Loss: 0.4085\n",
      "Epoch [6/50], Step [365/735], Loss: 0.1719\n",
      "Epoch [6/50], Step [366/735], Loss: 0.0568\n",
      "Epoch [6/50], Step [367/735], Loss: 0.1615\n",
      "Epoch [6/50], Step [368/735], Loss: 0.1708\n",
      "Epoch [6/50], Step [369/735], Loss: 0.1915\n",
      "Epoch [6/50], Step [370/735], Loss: 0.2908\n",
      "Epoch [6/50], Step [371/735], Loss: 0.1429\n",
      "Epoch [6/50], Step [372/735], Loss: 0.1795\n",
      "Epoch [6/50], Step [373/735], Loss: 0.1701\n",
      "Epoch [6/50], Step [374/735], Loss: 0.1980\n",
      "Epoch [6/50], Step [375/735], Loss: 0.0445\n",
      "Epoch [6/50], Step [376/735], Loss: 0.0823\n",
      "Epoch [6/50], Step [377/735], Loss: 0.0529\n",
      "Epoch [6/50], Step [378/735], Loss: 0.2928\n",
      "Epoch [6/50], Step [379/735], Loss: 0.1887\n",
      "Epoch [6/50], Step [380/735], Loss: 0.0801\n",
      "Epoch [6/50], Step [381/735], Loss: 0.2433\n",
      "Epoch [6/50], Step [382/735], Loss: 0.1754\n",
      "Epoch [6/50], Step [383/735], Loss: 0.0452\n",
      "Epoch [6/50], Step [384/735], Loss: 0.1299\n",
      "Epoch [6/50], Step [385/735], Loss: 0.0501\n",
      "Epoch [6/50], Step [386/735], Loss: 0.2359\n",
      "Epoch [6/50], Step [387/735], Loss: 0.1022\n",
      "Epoch [6/50], Step [388/735], Loss: 0.0349\n",
      "Epoch [6/50], Step [389/735], Loss: 0.0563\n",
      "Epoch [6/50], Step [390/735], Loss: 0.0692\n",
      "Epoch [6/50], Step [391/735], Loss: 0.0714\n",
      "Epoch [6/50], Step [392/735], Loss: 0.2768\n",
      "Epoch [6/50], Step [393/735], Loss: 0.0508\n",
      "Epoch [6/50], Step [394/735], Loss: 0.1961\n",
      "Epoch [6/50], Step [395/735], Loss: 0.1334\n",
      "Epoch [6/50], Step [396/735], Loss: 0.0417\n",
      "Epoch [6/50], Step [397/735], Loss: 0.1033\n",
      "Epoch [6/50], Step [398/735], Loss: 0.0724\n",
      "Epoch [6/50], Step [399/735], Loss: 0.2417\n",
      "Epoch [6/50], Step [400/735], Loss: 0.0978\n",
      "Epoch [6/50], Step [401/735], Loss: 0.1461\n",
      "Epoch [6/50], Step [402/735], Loss: 0.1180\n",
      "Epoch [6/50], Step [403/735], Loss: 0.0794\n",
      "Epoch [6/50], Step [404/735], Loss: 0.0682\n",
      "Epoch [6/50], Step [405/735], Loss: 0.0817\n",
      "Epoch [6/50], Step [406/735], Loss: 0.0496\n",
      "Epoch [6/50], Step [407/735], Loss: 0.2249\n",
      "Epoch [6/50], Step [408/735], Loss: 0.1931\n",
      "Epoch [6/50], Step [409/735], Loss: 0.6791\n",
      "Epoch [6/50], Step [410/735], Loss: 0.1967\n",
      "Epoch [6/50], Step [411/735], Loss: 0.3546\n",
      "Epoch [6/50], Step [412/735], Loss: 0.0454\n",
      "Epoch [6/50], Step [413/735], Loss: 0.0822\n",
      "Epoch [6/50], Step [414/735], Loss: 0.0472\n",
      "Epoch [6/50], Step [415/735], Loss: 0.5391\n",
      "Epoch [6/50], Step [416/735], Loss: 0.0461\n",
      "Epoch [6/50], Step [417/735], Loss: 0.0500\n",
      "Epoch [6/50], Step [418/735], Loss: 0.0578\n",
      "Epoch [6/50], Step [419/735], Loss: 0.2633\n",
      "Epoch [6/50], Step [420/735], Loss: 0.3379\n",
      "Epoch [6/50], Step [421/735], Loss: 0.5404\n",
      "Epoch [6/50], Step [422/735], Loss: 0.3111\n",
      "Epoch [6/50], Step [423/735], Loss: 0.1443\n",
      "Epoch [6/50], Step [424/735], Loss: 0.0739\n",
      "Epoch [6/50], Step [425/735], Loss: 0.0570\n",
      "Epoch [6/50], Step [426/735], Loss: 0.0513\n",
      "Epoch [6/50], Step [427/735], Loss: 0.0574\n",
      "Epoch [6/50], Step [428/735], Loss: 0.0474\n",
      "Epoch [6/50], Step [429/735], Loss: 0.0976\n",
      "Epoch [6/50], Step [430/735], Loss: 0.1019\n",
      "Epoch [6/50], Step [431/735], Loss: 0.1564\n",
      "Epoch [6/50], Step [432/735], Loss: 0.1168\n",
      "Epoch [6/50], Step [433/735], Loss: 0.5554\n",
      "Epoch [6/50], Step [434/735], Loss: 0.0940\n",
      "Epoch [6/50], Step [435/735], Loss: 0.1092\n",
      "Epoch [6/50], Step [436/735], Loss: 0.0504\n",
      "Epoch [6/50], Step [437/735], Loss: 0.1597\n",
      "Epoch [6/50], Step [438/735], Loss: 0.1339\n",
      "Epoch [6/50], Step [439/735], Loss: 0.1152\n",
      "Epoch [6/50], Step [440/735], Loss: 0.0374\n",
      "Epoch [6/50], Step [441/735], Loss: 0.0534\n",
      "Epoch [6/50], Step [442/735], Loss: 0.0596\n",
      "Epoch [6/50], Step [443/735], Loss: 0.0929\n",
      "Epoch [6/50], Step [444/735], Loss: 0.0489\n",
      "Epoch [6/50], Step [445/735], Loss: 0.2863\n",
      "Epoch [6/50], Step [446/735], Loss: 0.1372\n",
      "Epoch [6/50], Step [447/735], Loss: 0.1459\n",
      "Epoch [6/50], Step [448/735], Loss: 0.0685\n",
      "Epoch [6/50], Step [449/735], Loss: 0.0653\n",
      "Epoch [6/50], Step [450/735], Loss: 0.3436\n",
      "Epoch [6/50], Step [451/735], Loss: 0.2097\n",
      "Epoch [6/50], Step [452/735], Loss: 0.0957\n",
      "Epoch [6/50], Step [453/735], Loss: 0.2196\n",
      "Epoch [6/50], Step [454/735], Loss: 0.1720\n",
      "Epoch [6/50], Step [455/735], Loss: 0.1454\n",
      "Epoch [6/50], Step [456/735], Loss: 0.0607\n",
      "Epoch [6/50], Step [457/735], Loss: 0.2579\n",
      "Epoch [6/50], Step [458/735], Loss: 0.0554\n",
      "Epoch [6/50], Step [459/735], Loss: 0.1400\n",
      "Epoch [6/50], Step [460/735], Loss: 0.0797\n",
      "Epoch [6/50], Step [461/735], Loss: 0.1365\n",
      "Epoch [6/50], Step [462/735], Loss: 0.0711\n",
      "Epoch [6/50], Step [463/735], Loss: 0.1722\n",
      "Epoch [6/50], Step [464/735], Loss: 0.0863\n",
      "Epoch [6/50], Step [465/735], Loss: 0.0718\n",
      "Epoch [6/50], Step [466/735], Loss: 0.0677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Step [467/735], Loss: 0.4382\n",
      "Epoch [6/50], Step [468/735], Loss: 0.1445\n",
      "Epoch [6/50], Step [469/735], Loss: 0.2226\n",
      "Epoch [6/50], Step [470/735], Loss: 0.0879\n",
      "Epoch [6/50], Step [471/735], Loss: 0.0585\n",
      "Epoch [6/50], Step [472/735], Loss: 0.0320\n",
      "Epoch [6/50], Step [473/735], Loss: 0.0633\n",
      "Epoch [6/50], Step [474/735], Loss: 0.0446\n",
      "Epoch [6/50], Step [475/735], Loss: 0.0695\n",
      "Epoch [6/50], Step [476/735], Loss: 0.0472\n",
      "Epoch [6/50], Step [477/735], Loss: 0.0444\n",
      "Epoch [6/50], Step [478/735], Loss: 0.2310\n",
      "Epoch [6/50], Step [479/735], Loss: 0.1585\n",
      "Epoch [6/50], Step [480/735], Loss: 0.1554\n",
      "Epoch [6/50], Step [481/735], Loss: 0.0376\n",
      "Epoch [6/50], Step [482/735], Loss: 0.5912\n",
      "Epoch [6/50], Step [483/735], Loss: 0.1061\n",
      "Epoch [6/50], Step [484/735], Loss: 0.2199\n",
      "Epoch [6/50], Step [485/735], Loss: 0.0893\n",
      "Epoch [6/50], Step [486/735], Loss: 0.0619\n",
      "Epoch [6/50], Step [487/735], Loss: 0.1182\n",
      "Epoch [6/50], Step [488/735], Loss: 0.0637\n",
      "Epoch [6/50], Step [489/735], Loss: 0.0976\n",
      "Epoch [6/50], Step [490/735], Loss: 0.0628\n",
      "Epoch [6/50], Step [491/735], Loss: 0.0748\n",
      "Epoch [6/50], Step [492/735], Loss: 0.0607\n",
      "Epoch [6/50], Step [493/735], Loss: 0.2078\n",
      "Epoch [6/50], Step [494/735], Loss: 0.0643\n",
      "Epoch [6/50], Step [495/735], Loss: 0.1865\n",
      "Epoch [6/50], Step [496/735], Loss: 0.1624\n",
      "Epoch [6/50], Step [497/735], Loss: 0.0783\n",
      "Epoch [6/50], Step [498/735], Loss: 0.0928\n",
      "Epoch [6/50], Step [499/735], Loss: 0.1491\n",
      "Epoch [6/50], Step [500/735], Loss: 0.1399\n",
      "Epoch [6/50], Step [501/735], Loss: 0.1285\n",
      "Epoch [6/50], Step [502/735], Loss: 0.4343\n",
      "Epoch [6/50], Step [503/735], Loss: 0.1168\n",
      "Epoch [6/50], Step [504/735], Loss: 0.1068\n",
      "Epoch [6/50], Step [505/735], Loss: 0.1190\n",
      "Epoch [6/50], Step [506/735], Loss: 0.0588\n",
      "Epoch [6/50], Step [507/735], Loss: 0.2630\n",
      "Epoch [6/50], Step [508/735], Loss: 0.0637\n",
      "Epoch [6/50], Step [509/735], Loss: 0.1911\n",
      "Epoch [6/50], Step [510/735], Loss: 0.1679\n",
      "Epoch [6/50], Step [511/735], Loss: 0.1352\n",
      "Epoch [6/50], Step [512/735], Loss: 0.0711\n",
      "Epoch [6/50], Step [513/735], Loss: 0.1314\n",
      "Epoch [6/50], Step [514/735], Loss: 0.1382\n",
      "Epoch [6/50], Step [515/735], Loss: 0.0923\n",
      "Epoch [6/50], Step [516/735], Loss: 0.0811\n",
      "Epoch [6/50], Step [517/735], Loss: 0.0541\n",
      "Epoch [6/50], Step [518/735], Loss: 0.1215\n",
      "Epoch [6/50], Step [519/735], Loss: 0.0622\n",
      "Epoch [6/50], Step [520/735], Loss: 0.2285\n",
      "Epoch [6/50], Step [521/735], Loss: 0.1537\n",
      "Epoch [6/50], Step [522/735], Loss: 0.6246\n",
      "Epoch [6/50], Step [523/735], Loss: 0.0678\n",
      "Epoch [6/50], Step [524/735], Loss: 0.1609\n",
      "Epoch [6/50], Step [525/735], Loss: 0.2179\n",
      "Epoch [6/50], Step [526/735], Loss: 0.1004\n",
      "Epoch [6/50], Step [527/735], Loss: 0.2354\n",
      "Epoch [6/50], Step [528/735], Loss: 0.1764\n",
      "Epoch [6/50], Step [529/735], Loss: 0.0827\n",
      "Epoch [6/50], Step [530/735], Loss: 0.3390\n",
      "Epoch [6/50], Step [531/735], Loss: 0.0720\n",
      "Epoch [6/50], Step [532/735], Loss: 0.0894\n",
      "Epoch [6/50], Step [533/735], Loss: 0.1197\n",
      "Epoch [6/50], Step [534/735], Loss: 0.1206\n",
      "Epoch [6/50], Step [535/735], Loss: 0.6167\n",
      "Epoch [6/50], Step [536/735], Loss: 0.0922\n",
      "Epoch [6/50], Step [537/735], Loss: 0.1335\n",
      "Epoch [6/50], Step [538/735], Loss: 0.5755\n",
      "Epoch [6/50], Step [539/735], Loss: 0.0804\n",
      "Epoch [6/50], Step [540/735], Loss: 0.1773\n",
      "Epoch [6/50], Step [541/735], Loss: 0.1824\n",
      "Epoch [6/50], Step [542/735], Loss: 0.0472\n",
      "Epoch [6/50], Step [543/735], Loss: 0.1913\n",
      "Epoch [6/50], Step [544/735], Loss: 0.0956\n",
      "Epoch [6/50], Step [545/735], Loss: 0.0925\n",
      "Epoch [6/50], Step [546/735], Loss: 0.0880\n",
      "Epoch [6/50], Step [547/735], Loss: 0.0473\n",
      "Epoch [6/50], Step [548/735], Loss: 0.1190\n",
      "Epoch [6/50], Step [549/735], Loss: 0.1036\n",
      "Epoch [6/50], Step [550/735], Loss: 0.0904\n",
      "Epoch [6/50], Step [551/735], Loss: 0.0432\n",
      "Epoch [6/50], Step [552/735], Loss: 0.0803\n",
      "Epoch [6/50], Step [553/735], Loss: 0.1070\n",
      "Epoch [6/50], Step [554/735], Loss: 0.6180\n",
      "Epoch [6/50], Step [555/735], Loss: 0.0558\n",
      "Epoch [6/50], Step [556/735], Loss: 0.1079\n",
      "Epoch [6/50], Step [557/735], Loss: 0.0374\n",
      "Epoch [6/50], Step [558/735], Loss: 0.0817\n",
      "Epoch [6/50], Step [559/735], Loss: 0.0585\n",
      "Epoch [6/50], Step [560/735], Loss: 0.1688\n",
      "Epoch [6/50], Step [561/735], Loss: 0.0723\n",
      "Epoch [6/50], Step [562/735], Loss: 0.1218\n",
      "Epoch [6/50], Step [563/735], Loss: 0.4497\n",
      "Epoch [6/50], Step [564/735], Loss: 0.1088\n",
      "Epoch [6/50], Step [565/735], Loss: 0.1669\n",
      "Epoch [6/50], Step [566/735], Loss: 0.0719\n",
      "Epoch [6/50], Step [567/735], Loss: 0.0732\n",
      "Epoch [6/50], Step [568/735], Loss: 0.0340\n",
      "Epoch [6/50], Step [569/735], Loss: 0.1174\n",
      "Epoch [6/50], Step [570/735], Loss: 0.1814\n",
      "Epoch [6/50], Step [571/735], Loss: 0.0305\n",
      "Epoch [6/50], Step [572/735], Loss: 0.0687\n",
      "Epoch [6/50], Step [573/735], Loss: 0.1962\n",
      "Epoch [6/50], Step [574/735], Loss: 0.0528\n",
      "Epoch [6/50], Step [575/735], Loss: 0.0234\n",
      "Epoch [6/50], Step [576/735], Loss: 0.2463\n",
      "Epoch [6/50], Step [577/735], Loss: 0.0592\n",
      "Epoch [6/50], Step [578/735], Loss: 0.2243\n",
      "Epoch [6/50], Step [579/735], Loss: 0.0608\n",
      "Epoch [6/50], Step [580/735], Loss: 0.0579\n",
      "Epoch [6/50], Step [581/735], Loss: 0.1260\n",
      "Epoch [6/50], Step [582/735], Loss: 0.0394\n",
      "Epoch [6/50], Step [583/735], Loss: 0.0545\n",
      "Epoch [6/50], Step [584/735], Loss: 0.0657\n",
      "Epoch [6/50], Step [585/735], Loss: 0.1079\n",
      "Epoch [6/50], Step [586/735], Loss: 0.0738\n",
      "Epoch [6/50], Step [587/735], Loss: 0.0889\n",
      "Epoch [6/50], Step [588/735], Loss: 0.3144\n",
      "Epoch [6/50], Step [589/735], Loss: 0.0681\n",
      "Epoch [6/50], Step [590/735], Loss: 0.1086\n",
      "Epoch [6/50], Step [591/735], Loss: 0.2265\n",
      "Epoch [6/50], Step [592/735], Loss: 0.4970\n",
      "Epoch [6/50], Step [593/735], Loss: 0.1199\n",
      "Epoch [6/50], Step [594/735], Loss: 0.2297\n",
      "Epoch [6/50], Step [595/735], Loss: 0.1616\n",
      "Epoch [6/50], Step [596/735], Loss: 0.0780\n",
      "Epoch [6/50], Step [597/735], Loss: 0.0622\n",
      "Epoch [6/50], Step [598/735], Loss: 0.0766\n",
      "Epoch [6/50], Step [599/735], Loss: 0.1299\n",
      "Epoch [6/50], Step [600/735], Loss: 0.0898\n",
      "Epoch [6/50], Step [601/735], Loss: 0.1031\n",
      "Epoch [6/50], Step [602/735], Loss: 0.0882\n",
      "Epoch [6/50], Step [603/735], Loss: 0.1449\n",
      "Epoch [6/50], Step [604/735], Loss: 0.0499\n",
      "Epoch [6/50], Step [605/735], Loss: 0.1299\n",
      "Epoch [6/50], Step [606/735], Loss: 0.0479\n",
      "Epoch [6/50], Step [607/735], Loss: 0.0942\n",
      "Epoch [6/50], Step [608/735], Loss: 0.1746\n",
      "Epoch [6/50], Step [609/735], Loss: 0.1771\n",
      "Epoch [6/50], Step [610/735], Loss: 0.0337\n",
      "Epoch [6/50], Step [611/735], Loss: 0.2436\n",
      "Epoch [6/50], Step [612/735], Loss: 0.0518\n",
      "Epoch [6/50], Step [613/735], Loss: 0.2691\n",
      "Epoch [6/50], Step [614/735], Loss: 0.1584\n",
      "Epoch [6/50], Step [615/735], Loss: 0.8450\n",
      "Epoch [6/50], Step [616/735], Loss: 0.0460\n",
      "Epoch [6/50], Step [617/735], Loss: 0.2317\n",
      "Epoch [6/50], Step [618/735], Loss: 0.0914\n",
      "Epoch [6/50], Step [619/735], Loss: 0.1101\n",
      "Epoch [6/50], Step [620/735], Loss: 0.1664\n",
      "Epoch [6/50], Step [621/735], Loss: 0.6224\n",
      "Epoch [6/50], Step [622/735], Loss: 0.1148\n",
      "Epoch [6/50], Step [623/735], Loss: 0.5345\n",
      "Epoch [6/50], Step [624/735], Loss: 0.0496\n",
      "Epoch [6/50], Step [625/735], Loss: 0.2949\n",
      "Epoch [6/50], Step [626/735], Loss: 0.2412\n",
      "Epoch [6/50], Step [627/735], Loss: 0.1873\n",
      "Epoch [6/50], Step [628/735], Loss: 0.1777\n",
      "Epoch [6/50], Step [629/735], Loss: 0.0528\n",
      "Epoch [6/50], Step [630/735], Loss: 0.0402\n",
      "Epoch [6/50], Step [631/735], Loss: 0.1035\n",
      "Epoch [6/50], Step [632/735], Loss: 0.1104\n",
      "Epoch [6/50], Step [633/735], Loss: 0.1450\n",
      "Epoch [6/50], Step [634/735], Loss: 0.1945\n",
      "Epoch [6/50], Step [635/735], Loss: 0.1769\n",
      "Epoch [6/50], Step [636/735], Loss: 0.0648\n",
      "Epoch [6/50], Step [637/735], Loss: 0.0402\n",
      "Epoch [6/50], Step [638/735], Loss: 0.0937\n",
      "Epoch [6/50], Step [639/735], Loss: 0.0840\n",
      "Epoch [6/50], Step [640/735], Loss: 0.0669\n",
      "Epoch [6/50], Step [641/735], Loss: 0.8682\n",
      "Epoch [6/50], Step [642/735], Loss: 0.1321\n",
      "Epoch [6/50], Step [643/735], Loss: 0.2349\n",
      "Epoch [6/50], Step [644/735], Loss: 0.1548\n",
      "Epoch [6/50], Step [645/735], Loss: 0.1609\n",
      "Epoch [6/50], Step [646/735], Loss: 0.0565\n",
      "Epoch [6/50], Step [647/735], Loss: 0.2370\n",
      "Epoch [6/50], Step [648/735], Loss: 0.3091\n",
      "Epoch [6/50], Step [649/735], Loss: 0.1364\n",
      "Epoch [6/50], Step [650/735], Loss: 0.3751\n",
      "Epoch [6/50], Step [651/735], Loss: 0.0640\n",
      "Epoch [6/50], Step [652/735], Loss: 0.0805\n",
      "Epoch [6/50], Step [653/735], Loss: 0.0691\n",
      "Epoch [6/50], Step [654/735], Loss: 0.0789\n",
      "Epoch [6/50], Step [655/735], Loss: 0.2014\n",
      "Epoch [6/50], Step [656/735], Loss: 0.1203\n",
      "Epoch [6/50], Step [657/735], Loss: 0.2555\n",
      "Epoch [6/50], Step [658/735], Loss: 0.0429\n",
      "Epoch [6/50], Step [659/735], Loss: 0.1418\n",
      "Epoch [6/50], Step [660/735], Loss: 0.1347\n",
      "Epoch [6/50], Step [661/735], Loss: 0.0394\n",
      "Epoch [6/50], Step [662/735], Loss: 0.1221\n",
      "Epoch [6/50], Step [663/735], Loss: 0.2170\n",
      "Epoch [6/50], Step [664/735], Loss: 0.0693\n",
      "Epoch [6/50], Step [665/735], Loss: 0.1224\n",
      "Epoch [6/50], Step [666/735], Loss: 0.0917\n",
      "Epoch [6/50], Step [667/735], Loss: 0.1934\n",
      "Epoch [6/50], Step [668/735], Loss: 0.0737\n",
      "Epoch [6/50], Step [669/735], Loss: 0.2363\n",
      "Epoch [6/50], Step [670/735], Loss: 0.1263\n",
      "Epoch [6/50], Step [671/735], Loss: 0.0500\n",
      "Epoch [6/50], Step [672/735], Loss: 0.1034\n",
      "Epoch [6/50], Step [673/735], Loss: 0.1398\n",
      "Epoch [6/50], Step [674/735], Loss: 0.0371\n",
      "Epoch [6/50], Step [675/735], Loss: 0.0643\n",
      "Epoch [6/50], Step [676/735], Loss: 0.1513\n",
      "Epoch [6/50], Step [677/735], Loss: 0.0655\n",
      "Epoch [6/50], Step [678/735], Loss: 0.1764\n",
      "Epoch [6/50], Step [679/735], Loss: 0.1520\n",
      "Epoch [6/50], Step [680/735], Loss: 0.2245\n",
      "Epoch [6/50], Step [681/735], Loss: 0.2104\n",
      "Epoch [6/50], Step [682/735], Loss: 0.0423\n",
      "Epoch [6/50], Step [683/735], Loss: 0.0992\n",
      "Epoch [6/50], Step [684/735], Loss: 0.4363\n",
      "Epoch [6/50], Step [685/735], Loss: 0.0361\n",
      "Epoch [6/50], Step [686/735], Loss: 0.0758\n",
      "Epoch [6/50], Step [687/735], Loss: 0.0703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Step [688/735], Loss: 0.1451\n",
      "Epoch [6/50], Step [689/735], Loss: 0.1165\n",
      "Epoch [6/50], Step [690/735], Loss: 0.1446\n",
      "Epoch [6/50], Step [691/735], Loss: 0.2992\n",
      "Epoch [6/50], Step [692/735], Loss: 0.3269\n",
      "Epoch [6/50], Step [693/735], Loss: 0.1297\n",
      "Epoch [6/50], Step [694/735], Loss: 0.0799\n",
      "Epoch [6/50], Step [695/735], Loss: 0.2006\n",
      "Epoch [6/50], Step [696/735], Loss: 0.0763\n",
      "Epoch [6/50], Step [697/735], Loss: 0.2942\n",
      "Epoch [6/50], Step [698/735], Loss: 0.1264\n",
      "Epoch [6/50], Step [699/735], Loss: 0.9152\n",
      "Epoch [6/50], Step [700/735], Loss: 0.0976\n",
      "Epoch [6/50], Step [701/735], Loss: 0.1053\n",
      "Epoch [6/50], Step [702/735], Loss: 0.0564\n",
      "Epoch [6/50], Step [703/735], Loss: 0.6615\n",
      "Epoch [6/50], Step [704/735], Loss: 0.0703\n",
      "Epoch [6/50], Step [705/735], Loss: 0.0928\n",
      "Epoch [6/50], Step [706/735], Loss: 0.5778\n",
      "Epoch [6/50], Step [707/735], Loss: 0.0466\n",
      "Epoch [6/50], Step [708/735], Loss: 0.0654\n",
      "Epoch [6/50], Step [709/735], Loss: 0.0885\n",
      "Epoch [6/50], Step [710/735], Loss: 0.2838\n",
      "Epoch [6/50], Step [711/735], Loss: 0.0983\n",
      "Epoch [6/50], Step [712/735], Loss: 0.1474\n",
      "Epoch [6/50], Step [713/735], Loss: 0.1368\n",
      "Epoch [6/50], Step [714/735], Loss: 0.3889\n",
      "Epoch [6/50], Step [715/735], Loss: 0.0536\n",
      "Epoch [6/50], Step [716/735], Loss: 0.0777\n",
      "Epoch [6/50], Step [717/735], Loss: 0.4046\n",
      "Epoch [6/50], Step [718/735], Loss: 0.1461\n",
      "Epoch [6/50], Step [719/735], Loss: 0.1670\n",
      "Epoch [6/50], Step [720/735], Loss: 0.2072\n",
      "Epoch [6/50], Step [721/735], Loss: 0.0520\n",
      "Epoch [6/50], Step [722/735], Loss: 0.0862\n",
      "Epoch [6/50], Step [723/735], Loss: 0.0760\n",
      "Epoch [6/50], Step [724/735], Loss: 0.6280\n",
      "Epoch [6/50], Step [725/735], Loss: 0.1280\n",
      "Epoch [6/50], Step [726/735], Loss: 0.1990\n",
      "Epoch [6/50], Step [727/735], Loss: 0.1370\n",
      "Epoch [6/50], Step [728/735], Loss: 0.1471\n",
      "Epoch [6/50], Step [729/735], Loss: 0.0752\n",
      "Epoch [6/50], Step [730/735], Loss: 0.1861\n",
      "Epoch [6/50], Step [731/735], Loss: 0.0917\n",
      "Epoch [6/50], Step [732/735], Loss: 0.1812\n",
      "Epoch [6/50], Step [733/735], Loss: 0.1040\n",
      "Epoch [6/50], Step [734/735], Loss: 0.0659\n",
      "Epoch [6/50], Step [735/735], Loss: 0.1089\n",
      "Epoch [7/50], Step [1/735], Loss: 0.2499\n",
      "Epoch [7/50], Step [2/735], Loss: 0.2557\n",
      "Epoch [7/50], Step [3/735], Loss: 0.3187\n",
      "Epoch [7/50], Step [4/735], Loss: 0.2962\n",
      "Epoch [7/50], Step [5/735], Loss: 0.1589\n",
      "Epoch [7/50], Step [6/735], Loss: 0.0726\n",
      "Epoch [7/50], Step [7/735], Loss: 0.1515\n",
      "Epoch [7/50], Step [8/735], Loss: 0.1439\n",
      "Epoch [7/50], Step [9/735], Loss: 0.0719\n",
      "Epoch [7/50], Step [10/735], Loss: 0.0854\n",
      "Epoch [7/50], Step [11/735], Loss: 0.0425\n",
      "Epoch [7/50], Step [12/735], Loss: 0.0852\n",
      "Epoch [7/50], Step [13/735], Loss: 0.0850\n",
      "Epoch [7/50], Step [14/735], Loss: 0.4018\n",
      "Epoch [7/50], Step [15/735], Loss: 0.1350\n",
      "Epoch [7/50], Step [16/735], Loss: 0.0887\n",
      "Epoch [7/50], Step [17/735], Loss: 0.0546\n",
      "Epoch [7/50], Step [18/735], Loss: 0.1136\n",
      "Epoch [7/50], Step [19/735], Loss: 0.0451\n",
      "Epoch [7/50], Step [20/735], Loss: 0.0889\n",
      "Epoch [7/50], Step [21/735], Loss: 0.1154\n",
      "Epoch [7/50], Step [22/735], Loss: 0.0951\n",
      "Epoch [7/50], Step [23/735], Loss: 0.1996\n",
      "Epoch [7/50], Step [24/735], Loss: 0.0810\n",
      "Epoch [7/50], Step [25/735], Loss: 0.1734\n",
      "Epoch [7/50], Step [26/735], Loss: 0.1380\n",
      "Epoch [7/50], Step [27/735], Loss: 0.2722\n",
      "Epoch [7/50], Step [28/735], Loss: 0.0971\n",
      "Epoch [7/50], Step [29/735], Loss: 0.0789\n",
      "Epoch [7/50], Step [30/735], Loss: 0.1212\n",
      "Epoch [7/50], Step [31/735], Loss: 0.0780\n",
      "Epoch [7/50], Step [32/735], Loss: 0.0608\n",
      "Epoch [7/50], Step [33/735], Loss: 0.0897\n",
      "Epoch [7/50], Step [34/735], Loss: 0.0833\n",
      "Epoch [7/50], Step [35/735], Loss: 0.0586\n",
      "Epoch [7/50], Step [36/735], Loss: 0.1430\n",
      "Epoch [7/50], Step [37/735], Loss: 0.2122\n",
      "Epoch [7/50], Step [38/735], Loss: 0.0461\n",
      "Epoch [7/50], Step [39/735], Loss: 0.0738\n",
      "Epoch [7/50], Step [40/735], Loss: 0.1168\n",
      "Epoch [7/50], Step [41/735], Loss: 0.2231\n",
      "Epoch [7/50], Step [42/735], Loss: 0.1668\n",
      "Epoch [7/50], Step [43/735], Loss: 0.0788\n",
      "Epoch [7/50], Step [44/735], Loss: 0.0825\n",
      "Epoch [7/50], Step [45/735], Loss: 0.0864\n",
      "Epoch [7/50], Step [46/735], Loss: 0.3747\n",
      "Epoch [7/50], Step [47/735], Loss: 0.0974\n",
      "Epoch [7/50], Step [48/735], Loss: 0.2081\n",
      "Epoch [7/50], Step [49/735], Loss: 0.1074\n",
      "Epoch [7/50], Step [50/735], Loss: 0.7178\n",
      "Epoch [7/50], Step [51/735], Loss: 0.1205\n",
      "Epoch [7/50], Step [52/735], Loss: 0.0492\n",
      "Epoch [7/50], Step [53/735], Loss: 0.1092\n",
      "Epoch [7/50], Step [54/735], Loss: 0.0659\n",
      "Epoch [7/50], Step [55/735], Loss: 0.0658\n",
      "Epoch [7/50], Step [56/735], Loss: 0.1467\n",
      "Epoch [7/50], Step [57/735], Loss: 0.1211\n",
      "Epoch [7/50], Step [58/735], Loss: 0.1104\n",
      "Epoch [7/50], Step [59/735], Loss: 0.2384\n",
      "Epoch [7/50], Step [60/735], Loss: 0.0573\n",
      "Epoch [7/50], Step [61/735], Loss: 0.0800\n",
      "Epoch [7/50], Step [62/735], Loss: 0.1455\n",
      "Epoch [7/50], Step [63/735], Loss: 0.0833\n",
      "Epoch [7/50], Step [64/735], Loss: 0.0676\n",
      "Epoch [7/50], Step [65/735], Loss: 0.0459\n",
      "Epoch [7/50], Step [66/735], Loss: 0.1013\n",
      "Epoch [7/50], Step [67/735], Loss: 0.1412\n",
      "Epoch [7/50], Step [68/735], Loss: 0.0343\n",
      "Epoch [7/50], Step [69/735], Loss: 0.0735\n",
      "Epoch [7/50], Step [70/735], Loss: 0.0760\n",
      "Epoch [7/50], Step [71/735], Loss: 0.1511\n",
      "Epoch [7/50], Step [72/735], Loss: 0.1560\n",
      "Epoch [7/50], Step [73/735], Loss: 0.0585\n",
      "Epoch [7/50], Step [74/735], Loss: 0.3340\n",
      "Epoch [7/50], Step [75/735], Loss: 0.4578\n",
      "Epoch [7/50], Step [76/735], Loss: 0.1399\n",
      "Epoch [7/50], Step [77/735], Loss: 0.0715\n",
      "Epoch [7/50], Step [78/735], Loss: 0.0804\n",
      "Epoch [7/50], Step [79/735], Loss: 0.0897\n",
      "Epoch [7/50], Step [80/735], Loss: 0.1215\n",
      "Epoch [7/50], Step [81/735], Loss: 0.0564\n",
      "Epoch [7/50], Step [82/735], Loss: 0.0503\n",
      "Epoch [7/50], Step [83/735], Loss: 0.2747\n",
      "Epoch [7/50], Step [84/735], Loss: 0.0367\n",
      "Epoch [7/50], Step [85/735], Loss: 0.0572\n",
      "Epoch [7/50], Step [86/735], Loss: 0.0958\n",
      "Epoch [7/50], Step [87/735], Loss: 0.0340\n",
      "Epoch [7/50], Step [88/735], Loss: 0.0587\n",
      "Epoch [7/50], Step [89/735], Loss: 0.2544\n",
      "Epoch [7/50], Step [90/735], Loss: 0.0766\n",
      "Epoch [7/50], Step [91/735], Loss: 0.0869\n",
      "Epoch [7/50], Step [92/735], Loss: 0.1225\n",
      "Epoch [7/50], Step [93/735], Loss: 0.1568\n",
      "Epoch [7/50], Step [94/735], Loss: 0.0482\n",
      "Epoch [7/50], Step [95/735], Loss: 0.0282\n",
      "Epoch [7/50], Step [96/735], Loss: 0.0366\n",
      "Epoch [7/50], Step [97/735], Loss: 0.1708\n",
      "Epoch [7/50], Step [98/735], Loss: 0.1295\n",
      "Epoch [7/50], Step [99/735], Loss: 0.1120\n",
      "Epoch [7/50], Step [100/735], Loss: 0.0916\n",
      "Epoch [7/50], Step [101/735], Loss: 0.0351\n",
      "Epoch [7/50], Step [102/735], Loss: 0.1020\n",
      "Epoch [7/50], Step [103/735], Loss: 0.3635\n",
      "Epoch [7/50], Step [104/735], Loss: 0.1438\n",
      "Epoch [7/50], Step [105/735], Loss: 0.5316\n",
      "Epoch [7/50], Step [106/735], Loss: 0.2980\n",
      "Epoch [7/50], Step [107/735], Loss: 0.1298\n",
      "Epoch [7/50], Step [108/735], Loss: 0.0735\n",
      "Epoch [7/50], Step [109/735], Loss: 0.0554\n",
      "Epoch [7/50], Step [110/735], Loss: 0.2252\n",
      "Epoch [7/50], Step [111/735], Loss: 0.2737\n",
      "Epoch [7/50], Step [112/735], Loss: 0.0848\n",
      "Epoch [7/50], Step [113/735], Loss: 0.1078\n",
      "Epoch [7/50], Step [114/735], Loss: 0.1454\n",
      "Epoch [7/50], Step [115/735], Loss: 0.0722\n",
      "Epoch [7/50], Step [116/735], Loss: 0.0385\n",
      "Epoch [7/50], Step [117/735], Loss: 0.4356\n",
      "Epoch [7/50], Step [118/735], Loss: 0.8615\n",
      "Epoch [7/50], Step [119/735], Loss: 0.0567\n",
      "Epoch [7/50], Step [120/735], Loss: 0.3344\n",
      "Epoch [7/50], Step [121/735], Loss: 0.1184\n",
      "Epoch [7/50], Step [122/735], Loss: 0.0560\n",
      "Epoch [7/50], Step [123/735], Loss: 0.1118\n",
      "Epoch [7/50], Step [124/735], Loss: 0.0526\n",
      "Epoch [7/50], Step [125/735], Loss: 0.1384\n",
      "Epoch [7/50], Step [126/735], Loss: 0.7631\n",
      "Epoch [7/50], Step [127/735], Loss: 0.0755\n",
      "Epoch [7/50], Step [128/735], Loss: 0.3417\n",
      "Epoch [7/50], Step [129/735], Loss: 0.1700\n",
      "Epoch [7/50], Step [130/735], Loss: 0.0432\n",
      "Epoch [7/50], Step [131/735], Loss: 0.0545\n",
      "Epoch [7/50], Step [132/735], Loss: 0.2307\n",
      "Epoch [7/50], Step [133/735], Loss: 0.1566\n",
      "Epoch [7/50], Step [134/735], Loss: 0.2757\n",
      "Epoch [7/50], Step [135/735], Loss: 0.1092\n",
      "Epoch [7/50], Step [136/735], Loss: 0.1673\n",
      "Epoch [7/50], Step [137/735], Loss: 0.1133\n",
      "Epoch [7/50], Step [138/735], Loss: 0.0739\n",
      "Epoch [7/50], Step [139/735], Loss: 0.0560\n",
      "Epoch [7/50], Step [140/735], Loss: 0.1496\n",
      "Epoch [7/50], Step [141/735], Loss: 0.0330\n",
      "Epoch [7/50], Step [142/735], Loss: 0.0970\n",
      "Epoch [7/50], Step [143/735], Loss: 0.1698\n",
      "Epoch [7/50], Step [144/735], Loss: 0.2057\n",
      "Epoch [7/50], Step [145/735], Loss: 0.2343\n",
      "Epoch [7/50], Step [146/735], Loss: 0.0521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Step [147/735], Loss: 0.2006\n",
      "Epoch [7/50], Step [148/735], Loss: 0.1573\n",
      "Epoch [7/50], Step [149/735], Loss: 0.0480\n",
      "Epoch [7/50], Step [150/735], Loss: 0.0619\n",
      "Epoch [7/50], Step [151/735], Loss: 0.0690\n",
      "Epoch [7/50], Step [152/735], Loss: 0.0449\n",
      "Epoch [7/50], Step [153/735], Loss: 0.0540\n",
      "Epoch [7/50], Step [154/735], Loss: 0.2551\n",
      "Epoch [7/50], Step [155/735], Loss: 0.0436\n",
      "Epoch [7/50], Step [156/735], Loss: 0.3278\n",
      "Epoch [7/50], Step [157/735], Loss: 0.3065\n",
      "Epoch [7/50], Step [158/735], Loss: 0.1270\n",
      "Epoch [7/50], Step [159/735], Loss: 0.1030\n",
      "Epoch [7/50], Step [160/735], Loss: 0.0783\n",
      "Epoch [7/50], Step [161/735], Loss: 0.1172\n",
      "Epoch [7/50], Step [162/735], Loss: 0.1600\n",
      "Epoch [7/50], Step [163/735], Loss: 0.5009\n",
      "Epoch [7/50], Step [164/735], Loss: 0.0533\n",
      "Epoch [7/50], Step [165/735], Loss: 0.0705\n",
      "Epoch [7/50], Step [166/735], Loss: 0.0639\n",
      "Epoch [7/50], Step [167/735], Loss: 0.0754\n",
      "Epoch [7/50], Step [168/735], Loss: 0.1519\n",
      "Epoch [7/50], Step [169/735], Loss: 0.1597\n",
      "Epoch [7/50], Step [170/735], Loss: 0.1550\n",
      "Epoch [7/50], Step [171/735], Loss: 0.1225\n",
      "Epoch [7/50], Step [172/735], Loss: 0.1553\n",
      "Epoch [7/50], Step [173/735], Loss: 0.2304\n",
      "Epoch [7/50], Step [174/735], Loss: 0.0543\n",
      "Epoch [7/50], Step [175/735], Loss: 0.0671\n",
      "Epoch [7/50], Step [176/735], Loss: 0.1726\n",
      "Epoch [7/50], Step [177/735], Loss: 0.2008\n",
      "Epoch [7/50], Step [178/735], Loss: 0.1368\n",
      "Epoch [7/50], Step [179/735], Loss: 0.0397\n",
      "Epoch [7/50], Step [180/735], Loss: 0.1572\n",
      "Epoch [7/50], Step [181/735], Loss: 0.0674\n",
      "Epoch [7/50], Step [182/735], Loss: 0.0689\n",
      "Epoch [7/50], Step [183/735], Loss: 0.5453\n",
      "Epoch [7/50], Step [184/735], Loss: 0.2647\n",
      "Epoch [7/50], Step [185/735], Loss: 0.1850\n",
      "Epoch [7/50], Step [186/735], Loss: 0.1007\n",
      "Epoch [7/50], Step [187/735], Loss: 0.7258\n",
      "Epoch [7/50], Step [188/735], Loss: 0.3092\n",
      "Epoch [7/50], Step [189/735], Loss: 0.0436\n",
      "Epoch [7/50], Step [190/735], Loss: 0.1404\n",
      "Epoch [7/50], Step [191/735], Loss: 0.1234\n",
      "Epoch [7/50], Step [192/735], Loss: 0.0450\n",
      "Epoch [7/50], Step [193/735], Loss: 0.0536\n",
      "Epoch [7/50], Step [194/735], Loss: 0.2350\n",
      "Epoch [7/50], Step [195/735], Loss: 0.4252\n",
      "Epoch [7/50], Step [196/735], Loss: 0.1019\n",
      "Epoch [7/50], Step [197/735], Loss: 0.1241\n",
      "Epoch [7/50], Step [198/735], Loss: 0.1169\n",
      "Epoch [7/50], Step [199/735], Loss: 0.0796\n",
      "Epoch [7/50], Step [200/735], Loss: 0.1709\n",
      "Epoch [7/50], Step [201/735], Loss: 0.2836\n",
      "Epoch [7/50], Step [202/735], Loss: 0.1554\n",
      "Epoch [7/50], Step [203/735], Loss: 0.0602\n",
      "Epoch [7/50], Step [204/735], Loss: 0.1166\n",
      "Epoch [7/50], Step [205/735], Loss: 0.0777\n",
      "Epoch [7/50], Step [206/735], Loss: 0.5847\n",
      "Epoch [7/50], Step [207/735], Loss: 0.2838\n",
      "Epoch [7/50], Step [208/735], Loss: 0.2645\n",
      "Epoch [7/50], Step [209/735], Loss: 0.1504\n",
      "Epoch [7/50], Step [210/735], Loss: 0.1406\n",
      "Epoch [7/50], Step [211/735], Loss: 0.1754\n",
      "Epoch [7/50], Step [212/735], Loss: 0.1317\n",
      "Epoch [7/50], Step [213/735], Loss: 0.0989\n",
      "Epoch [7/50], Step [214/735], Loss: 0.2383\n",
      "Epoch [7/50], Step [215/735], Loss: 0.2019\n",
      "Epoch [7/50], Step [216/735], Loss: 0.1437\n",
      "Epoch [7/50], Step [217/735], Loss: 0.0561\n",
      "Epoch [7/50], Step [218/735], Loss: 0.0664\n",
      "Epoch [7/50], Step [219/735], Loss: 0.0845\n",
      "Epoch [7/50], Step [220/735], Loss: 0.0703\n",
      "Epoch [7/50], Step [221/735], Loss: 0.4856\n",
      "Epoch [7/50], Step [222/735], Loss: 0.3342\n",
      "Epoch [7/50], Step [223/735], Loss: 0.3011\n",
      "Epoch [7/50], Step [224/735], Loss: 0.3238\n",
      "Epoch [7/50], Step [225/735], Loss: 0.1466\n",
      "Epoch [7/50], Step [226/735], Loss: 0.1652\n",
      "Epoch [7/50], Step [227/735], Loss: 0.0862\n",
      "Epoch [7/50], Step [228/735], Loss: 0.0848\n",
      "Epoch [7/50], Step [229/735], Loss: 0.0798\n",
      "Epoch [7/50], Step [230/735], Loss: 0.0776\n",
      "Epoch [7/50], Step [231/735], Loss: 0.0672\n",
      "Epoch [7/50], Step [232/735], Loss: 0.2639\n",
      "Epoch [7/50], Step [233/735], Loss: 0.0669\n",
      "Epoch [7/50], Step [234/735], Loss: 0.0864\n",
      "Epoch [7/50], Step [235/735], Loss: 0.0859\n",
      "Epoch [7/50], Step [236/735], Loss: 0.0881\n",
      "Epoch [7/50], Step [237/735], Loss: 0.0413\n",
      "Epoch [7/50], Step [238/735], Loss: 0.1628\n",
      "Epoch [7/50], Step [239/735], Loss: 0.0821\n",
      "Epoch [7/50], Step [240/735], Loss: 0.0680\n",
      "Epoch [7/50], Step [241/735], Loss: 0.0917\n",
      "Epoch [7/50], Step [242/735], Loss: 0.2079\n",
      "Epoch [7/50], Step [243/735], Loss: 0.1639\n",
      "Epoch [7/50], Step [244/735], Loss: 0.2363\n",
      "Epoch [7/50], Step [245/735], Loss: 0.1034\n",
      "Epoch [7/50], Step [246/735], Loss: 0.1382\n",
      "Epoch [7/50], Step [247/735], Loss: 0.7113\n",
      "Epoch [7/50], Step [248/735], Loss: 0.1968\n",
      "Epoch [7/50], Step [249/735], Loss: 0.0977\n",
      "Epoch [7/50], Step [250/735], Loss: 0.0590\n",
      "Epoch [7/50], Step [251/735], Loss: 0.2034\n",
      "Epoch [7/50], Step [252/735], Loss: 0.1578\n",
      "Epoch [7/50], Step [253/735], Loss: 0.1394\n",
      "Epoch [7/50], Step [254/735], Loss: 0.0781\n",
      "Epoch [7/50], Step [255/735], Loss: 0.0856\n",
      "Epoch [7/50], Step [256/735], Loss: 0.1103\n",
      "Epoch [7/50], Step [257/735], Loss: 0.1206\n",
      "Epoch [7/50], Step [258/735], Loss: 0.0628\n",
      "Epoch [7/50], Step [259/735], Loss: 0.0873\n",
      "Epoch [7/50], Step [260/735], Loss: 0.1082\n",
      "Epoch [7/50], Step [261/735], Loss: 0.0871\n",
      "Epoch [7/50], Step [262/735], Loss: 0.2478\n",
      "Epoch [7/50], Step [263/735], Loss: 0.0906\n",
      "Epoch [7/50], Step [264/735], Loss: 0.1120\n",
      "Epoch [7/50], Step [265/735], Loss: 0.0614\n",
      "Epoch [7/50], Step [266/735], Loss: 0.2943\n",
      "Epoch [7/50], Step [267/735], Loss: 0.0844\n",
      "Epoch [7/50], Step [268/735], Loss: 0.0665\n",
      "Epoch [7/50], Step [269/735], Loss: 0.0894\n",
      "Epoch [7/50], Step [270/735], Loss: 0.0782\n",
      "Epoch [7/50], Step [271/735], Loss: 0.0615\n",
      "Epoch [7/50], Step [272/735], Loss: 0.0538\n",
      "Epoch [7/50], Step [273/735], Loss: 0.2784\n",
      "Epoch [7/50], Step [274/735], Loss: 0.0762\n",
      "Epoch [7/50], Step [275/735], Loss: 0.0945\n",
      "Epoch [7/50], Step [276/735], Loss: 0.0843\n",
      "Epoch [7/50], Step [277/735], Loss: 0.0767\n",
      "Epoch [7/50], Step [278/735], Loss: 0.0911\n",
      "Epoch [7/50], Step [279/735], Loss: 0.0603\n",
      "Epoch [7/50], Step [280/735], Loss: 0.1981\n",
      "Epoch [7/50], Step [281/735], Loss: 0.1067\n",
      "Epoch [7/50], Step [282/735], Loss: 0.1478\n",
      "Epoch [7/50], Step [283/735], Loss: 0.1718\n",
      "Epoch [7/50], Step [284/735], Loss: 0.0714\n",
      "Epoch [7/50], Step [285/735], Loss: 0.2337\n",
      "Epoch [7/50], Step [286/735], Loss: 0.0444\n",
      "Epoch [7/50], Step [287/735], Loss: 0.0693\n",
      "Epoch [7/50], Step [288/735], Loss: 0.2656\n",
      "Epoch [7/50], Step [289/735], Loss: 0.0946\n",
      "Epoch [7/50], Step [290/735], Loss: 0.2154\n",
      "Epoch [7/50], Step [291/735], Loss: 0.1707\n",
      "Epoch [7/50], Step [292/735], Loss: 0.2442\n",
      "Epoch [7/50], Step [293/735], Loss: 0.2219\n",
      "Epoch [7/50], Step [294/735], Loss: 0.0855\n",
      "Epoch [7/50], Step [295/735], Loss: 0.0622\n",
      "Epoch [7/50], Step [296/735], Loss: 0.2158\n",
      "Epoch [7/50], Step [297/735], Loss: 0.1527\n",
      "Epoch [7/50], Step [298/735], Loss: 0.1297\n",
      "Epoch [7/50], Step [299/735], Loss: 0.1989\n",
      "Epoch [7/50], Step [300/735], Loss: 0.1173\n",
      "Epoch [7/50], Step [301/735], Loss: 0.2547\n",
      "Epoch [7/50], Step [302/735], Loss: 0.0758\n",
      "Epoch [7/50], Step [303/735], Loss: 0.1107\n",
      "Epoch [7/50], Step [304/735], Loss: 0.2190\n",
      "Epoch [7/50], Step [305/735], Loss: 0.1361\n",
      "Epoch [7/50], Step [306/735], Loss: 0.0946\n",
      "Epoch [7/50], Step [307/735], Loss: 0.7559\n",
      "Epoch [7/50], Step [308/735], Loss: 0.0993\n",
      "Epoch [7/50], Step [309/735], Loss: 0.1029\n",
      "Epoch [7/50], Step [310/735], Loss: 0.0384\n",
      "Epoch [7/50], Step [311/735], Loss: 0.2715\n",
      "Epoch [7/50], Step [312/735], Loss: 0.0624\n",
      "Epoch [7/50], Step [313/735], Loss: 0.1251\n",
      "Epoch [7/50], Step [314/735], Loss: 0.1766\n",
      "Epoch [7/50], Step [315/735], Loss: 0.2378\n",
      "Epoch [7/50], Step [316/735], Loss: 0.1026\n",
      "Epoch [7/50], Step [317/735], Loss: 0.1249\n",
      "Epoch [7/50], Step [318/735], Loss: 0.0763\n",
      "Epoch [7/50], Step [319/735], Loss: 0.0870\n",
      "Epoch [7/50], Step [320/735], Loss: 0.0794\n",
      "Epoch [7/50], Step [321/735], Loss: 0.1357\n",
      "Epoch [7/50], Step [322/735], Loss: 0.0887\n",
      "Epoch [7/50], Step [323/735], Loss: 0.0903\n",
      "Epoch [7/50], Step [324/735], Loss: 0.2293\n",
      "Epoch [7/50], Step [325/735], Loss: 0.1272\n",
      "Epoch [7/50], Step [326/735], Loss: 0.0535\n",
      "Epoch [7/50], Step [327/735], Loss: 0.0638\n",
      "Epoch [7/50], Step [328/735], Loss: 0.0559\n",
      "Epoch [7/50], Step [329/735], Loss: 0.3458\n",
      "Epoch [7/50], Step [330/735], Loss: 0.1668\n",
      "Epoch [7/50], Step [331/735], Loss: 0.0848\n",
      "Epoch [7/50], Step [332/735], Loss: 0.1612\n",
      "Epoch [7/50], Step [333/735], Loss: 0.0571\n",
      "Epoch [7/50], Step [334/735], Loss: 0.0566\n",
      "Epoch [7/50], Step [335/735], Loss: 0.0951\n",
      "Epoch [7/50], Step [336/735], Loss: 0.1045\n",
      "Epoch [7/50], Step [337/735], Loss: 0.0268\n",
      "Epoch [7/50], Step [338/735], Loss: 0.1217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Step [339/735], Loss: 0.1842\n",
      "Epoch [7/50], Step [340/735], Loss: 0.1015\n",
      "Epoch [7/50], Step [341/735], Loss: 0.0422\n",
      "Epoch [7/50], Step [342/735], Loss: 0.0967\n",
      "Epoch [7/50], Step [343/735], Loss: 0.1871\n",
      "Epoch [7/50], Step [344/735], Loss: 0.0755\n",
      "Epoch [7/50], Step [345/735], Loss: 0.0557\n",
      "Epoch [7/50], Step [346/735], Loss: 0.1335\n",
      "Epoch [7/50], Step [347/735], Loss: 0.1237\n",
      "Epoch [7/50], Step [348/735], Loss: 0.0287\n",
      "Epoch [7/50], Step [349/735], Loss: 0.0266\n",
      "Epoch [7/50], Step [350/735], Loss: 0.0279\n",
      "Epoch [7/50], Step [351/735], Loss: 0.1048\n",
      "Epoch [7/50], Step [352/735], Loss: 0.0474\n",
      "Epoch [7/50], Step [353/735], Loss: 0.0367\n",
      "Epoch [7/50], Step [354/735], Loss: 0.0460\n",
      "Epoch [7/50], Step [355/735], Loss: 0.0533\n",
      "Epoch [7/50], Step [356/735], Loss: 0.0436\n",
      "Epoch [7/50], Step [357/735], Loss: 0.1864\n",
      "Epoch [7/50], Step [358/735], Loss: 0.3771\n",
      "Epoch [7/50], Step [359/735], Loss: 0.0840\n",
      "Epoch [7/50], Step [360/735], Loss: 0.0436\n",
      "Epoch [7/50], Step [361/735], Loss: 0.0710\n",
      "Epoch [7/50], Step [362/735], Loss: 0.4365\n",
      "Epoch [7/50], Step [363/735], Loss: 0.1259\n",
      "Epoch [7/50], Step [364/735], Loss: 0.0495\n",
      "Epoch [7/50], Step [365/735], Loss: 0.0684\n",
      "Epoch [7/50], Step [366/735], Loss: 0.1130\n",
      "Epoch [7/50], Step [367/735], Loss: 0.0518\n",
      "Epoch [7/50], Step [368/735], Loss: 0.1561\n",
      "Epoch [7/50], Step [369/735], Loss: 0.1797\n",
      "Epoch [7/50], Step [370/735], Loss: 0.0780\n",
      "Epoch [7/50], Step [371/735], Loss: 0.1786\n",
      "Epoch [7/50], Step [372/735], Loss: 0.0859\n",
      "Epoch [7/50], Step [373/735], Loss: 0.1276\n",
      "Epoch [7/50], Step [374/735], Loss: 0.0566\n",
      "Epoch [7/50], Step [375/735], Loss: 0.1587\n",
      "Epoch [7/50], Step [376/735], Loss: 0.4374\n",
      "Epoch [7/50], Step [377/735], Loss: 0.0909\n",
      "Epoch [7/50], Step [378/735], Loss: 0.1764\n",
      "Epoch [7/50], Step [379/735], Loss: 0.0564\n",
      "Epoch [7/50], Step [380/735], Loss: 0.0616\n",
      "Epoch [7/50], Step [381/735], Loss: 0.0347\n",
      "Epoch [7/50], Step [382/735], Loss: 0.0431\n",
      "Epoch [7/50], Step [383/735], Loss: 0.1168\n",
      "Epoch [7/50], Step [384/735], Loss: 0.1433\n",
      "Epoch [7/50], Step [385/735], Loss: 0.0902\n",
      "Epoch [7/50], Step [386/735], Loss: 0.2652\n",
      "Epoch [7/50], Step [387/735], Loss: 0.2339\n",
      "Epoch [7/50], Step [388/735], Loss: 0.1389\n",
      "Epoch [7/50], Step [389/735], Loss: 0.0608\n",
      "Epoch [7/50], Step [390/735], Loss: 0.0485\n",
      "Epoch [7/50], Step [391/735], Loss: 0.0824\n",
      "Epoch [7/50], Step [392/735], Loss: 0.0559\n",
      "Epoch [7/50], Step [393/735], Loss: 0.1693\n",
      "Epoch [7/50], Step [394/735], Loss: 0.1876\n",
      "Epoch [7/50], Step [395/735], Loss: 0.1983\n",
      "Epoch [7/50], Step [396/735], Loss: 0.1320\n",
      "Epoch [7/50], Step [397/735], Loss: 0.2624\n",
      "Epoch [7/50], Step [398/735], Loss: 0.0999\n",
      "Epoch [7/50], Step [399/735], Loss: 0.0575\n",
      "Epoch [7/50], Step [400/735], Loss: 0.0484\n",
      "Epoch [7/50], Step [401/735], Loss: 0.0460\n",
      "Epoch [7/50], Step [402/735], Loss: 0.1331\n",
      "Epoch [7/50], Step [403/735], Loss: 0.3847\n",
      "Epoch [7/50], Step [404/735], Loss: 0.0698\n",
      "Epoch [7/50], Step [405/735], Loss: 0.0561\n",
      "Epoch [7/50], Step [406/735], Loss: 0.1654\n",
      "Epoch [7/50], Step [407/735], Loss: 0.2172\n",
      "Epoch [7/50], Step [408/735], Loss: 0.0383\n",
      "Epoch [7/50], Step [409/735], Loss: 0.0776\n",
      "Epoch [7/50], Step [410/735], Loss: 0.1389\n",
      "Epoch [7/50], Step [411/735], Loss: 0.2754\n",
      "Epoch [7/50], Step [412/735], Loss: 0.1334\n",
      "Epoch [7/50], Step [413/735], Loss: 0.0946\n",
      "Epoch [7/50], Step [414/735], Loss: 0.0661\n",
      "Epoch [7/50], Step [415/735], Loss: 0.1980\n",
      "Epoch [7/50], Step [416/735], Loss: 0.0551\n",
      "Epoch [7/50], Step [417/735], Loss: 0.0378\n",
      "Epoch [7/50], Step [418/735], Loss: 0.4493\n",
      "Epoch [7/50], Step [419/735], Loss: 0.1097\n",
      "Epoch [7/50], Step [420/735], Loss: 0.2141\n",
      "Epoch [7/50], Step [421/735], Loss: 0.0444\n",
      "Epoch [7/50], Step [422/735], Loss: 0.1130\n",
      "Epoch [7/50], Step [423/735], Loss: 0.2268\n",
      "Epoch [7/50], Step [424/735], Loss: 0.1056\n",
      "Epoch [7/50], Step [425/735], Loss: 0.0535\n",
      "Epoch [7/50], Step [426/735], Loss: 0.0825\n",
      "Epoch [7/50], Step [427/735], Loss: 0.1654\n",
      "Epoch [7/50], Step [428/735], Loss: 0.0475\n",
      "Epoch [7/50], Step [429/735], Loss: 0.2386\n",
      "Epoch [7/50], Step [430/735], Loss: 0.0658\n",
      "Epoch [7/50], Step [431/735], Loss: 0.0705\n",
      "Epoch [7/50], Step [432/735], Loss: 0.0859\n",
      "Epoch [7/50], Step [433/735], Loss: 0.1501\n",
      "Epoch [7/50], Step [434/735], Loss: 0.1212\n",
      "Epoch [7/50], Step [435/735], Loss: 0.0466\n",
      "Epoch [7/50], Step [436/735], Loss: 0.1026\n",
      "Epoch [7/50], Step [437/735], Loss: 0.0587\n",
      "Epoch [7/50], Step [438/735], Loss: 0.0701\n",
      "Epoch [7/50], Step [439/735], Loss: 0.1828\n",
      "Epoch [7/50], Step [440/735], Loss: 0.0754\n",
      "Epoch [7/50], Step [441/735], Loss: 0.0927\n",
      "Epoch [7/50], Step [442/735], Loss: 0.2335\n",
      "Epoch [7/50], Step [443/735], Loss: 0.0630\n",
      "Epoch [7/50], Step [444/735], Loss: 0.0771\n",
      "Epoch [7/50], Step [445/735], Loss: 0.1242\n",
      "Epoch [7/50], Step [446/735], Loss: 0.2021\n",
      "Epoch [7/50], Step [447/735], Loss: 0.2464\n",
      "Epoch [7/50], Step [448/735], Loss: 0.1869\n",
      "Epoch [7/50], Step [449/735], Loss: 0.0346\n",
      "Epoch [7/50], Step [450/735], Loss: 0.0476\n",
      "Epoch [7/50], Step [451/735], Loss: 0.0892\n",
      "Epoch [7/50], Step [452/735], Loss: 0.0566\n",
      "Epoch [7/50], Step [453/735], Loss: 0.0779\n",
      "Epoch [7/50], Step [454/735], Loss: 0.0613\n",
      "Epoch [7/50], Step [455/735], Loss: 0.1201\n",
      "Epoch [7/50], Step [456/735], Loss: 0.0724\n",
      "Epoch [7/50], Step [457/735], Loss: 0.1777\n",
      "Epoch [7/50], Step [458/735], Loss: 0.0819\n",
      "Epoch [7/50], Step [459/735], Loss: 0.0468\n",
      "Epoch [7/50], Step [460/735], Loss: 0.0813\n",
      "Epoch [7/50], Step [461/735], Loss: 0.3793\n",
      "Epoch [7/50], Step [462/735], Loss: 0.1411\n",
      "Epoch [7/50], Step [463/735], Loss: 0.1445\n",
      "Epoch [7/50], Step [464/735], Loss: 0.0747\n",
      "Epoch [7/50], Step [465/735], Loss: 0.0420\n",
      "Epoch [7/50], Step [466/735], Loss: 0.3270\n",
      "Epoch [7/50], Step [467/735], Loss: 0.2237\n",
      "Epoch [7/50], Step [468/735], Loss: 0.6082\n",
      "Epoch [7/50], Step [469/735], Loss: 0.0825\n",
      "Epoch [7/50], Step [470/735], Loss: 0.1113\n",
      "Epoch [7/50], Step [471/735], Loss: 0.1036\n",
      "Epoch [7/50], Step [472/735], Loss: 0.0325\n",
      "Epoch [7/50], Step [473/735], Loss: 0.1582\n",
      "Epoch [7/50], Step [474/735], Loss: 0.2150\n",
      "Epoch [7/50], Step [475/735], Loss: 0.1217\n",
      "Epoch [7/50], Step [476/735], Loss: 0.1513\n",
      "Epoch [7/50], Step [477/735], Loss: 0.0913\n",
      "Epoch [7/50], Step [478/735], Loss: 0.0709\n",
      "Epoch [7/50], Step [479/735], Loss: 0.0520\n",
      "Epoch [7/50], Step [480/735], Loss: 0.0588\n",
      "Epoch [7/50], Step [481/735], Loss: 0.0491\n",
      "Epoch [7/50], Step [482/735], Loss: 0.1734\n",
      "Epoch [7/50], Step [483/735], Loss: 0.1700\n",
      "Epoch [7/50], Step [484/735], Loss: 0.2418\n",
      "Epoch [7/50], Step [485/735], Loss: 0.0517\n",
      "Epoch [7/50], Step [486/735], Loss: 0.0845\n",
      "Epoch [7/50], Step [487/735], Loss: 0.1211\n",
      "Epoch [7/50], Step [488/735], Loss: 0.1860\n",
      "Epoch [7/50], Step [489/735], Loss: 0.1126\n",
      "Epoch [7/50], Step [490/735], Loss: 0.0858\n",
      "Epoch [7/50], Step [491/735], Loss: 0.1148\n",
      "Epoch [7/50], Step [492/735], Loss: 0.0512\n",
      "Epoch [7/50], Step [493/735], Loss: 0.1423\n",
      "Epoch [7/50], Step [494/735], Loss: 0.5674\n",
      "Epoch [7/50], Step [495/735], Loss: 0.2869\n",
      "Epoch [7/50], Step [496/735], Loss: 0.0540\n",
      "Epoch [7/50], Step [497/735], Loss: 0.0566\n",
      "Epoch [7/50], Step [498/735], Loss: 0.1553\n",
      "Epoch [7/50], Step [499/735], Loss: 0.2508\n",
      "Epoch [7/50], Step [500/735], Loss: 0.0518\n",
      "Epoch [7/50], Step [501/735], Loss: 0.0905\n",
      "Epoch [7/50], Step [502/735], Loss: 0.1331\n",
      "Epoch [7/50], Step [503/735], Loss: 0.1357\n",
      "Epoch [7/50], Step [504/735], Loss: 0.1491\n",
      "Epoch [7/50], Step [505/735], Loss: 0.0883\n",
      "Epoch [7/50], Step [506/735], Loss: 0.1731\n",
      "Epoch [7/50], Step [507/735], Loss: 0.1435\n",
      "Epoch [7/50], Step [508/735], Loss: 0.2060\n",
      "Epoch [7/50], Step [509/735], Loss: 0.1384\n",
      "Epoch [7/50], Step [510/735], Loss: 0.0919\n",
      "Epoch [7/50], Step [511/735], Loss: 0.5161\n",
      "Epoch [7/50], Step [512/735], Loss: 0.1153\n",
      "Epoch [7/50], Step [513/735], Loss: 0.1429\n",
      "Epoch [7/50], Step [514/735], Loss: 0.1386\n",
      "Epoch [7/50], Step [515/735], Loss: 0.1368\n",
      "Epoch [7/50], Step [516/735], Loss: 0.0914\n",
      "Epoch [7/50], Step [517/735], Loss: 0.0800\n",
      "Epoch [7/50], Step [518/735], Loss: 0.0416\n",
      "Epoch [7/50], Step [519/735], Loss: 0.0958\n",
      "Epoch [7/50], Step [520/735], Loss: 0.1017\n",
      "Epoch [7/50], Step [521/735], Loss: 0.1795\n",
      "Epoch [7/50], Step [522/735], Loss: 0.2000\n",
      "Epoch [7/50], Step [523/735], Loss: 0.0846\n",
      "Epoch [7/50], Step [524/735], Loss: 0.1926\n",
      "Epoch [7/50], Step [525/735], Loss: 0.0587\n",
      "Epoch [7/50], Step [526/735], Loss: 0.1031\n",
      "Epoch [7/50], Step [527/735], Loss: 0.3983\n",
      "Epoch [7/50], Step [528/735], Loss: 0.1163\n",
      "Epoch [7/50], Step [529/735], Loss: 0.1463\n",
      "Epoch [7/50], Step [530/735], Loss: 0.1047\n",
      "Epoch [7/50], Step [531/735], Loss: 0.0600\n",
      "Epoch [7/50], Step [532/735], Loss: 0.0594\n",
      "Epoch [7/50], Step [533/735], Loss: 0.1392\n",
      "Epoch [7/50], Step [534/735], Loss: 0.1784\n",
      "Epoch [7/50], Step [535/735], Loss: 0.0306\n",
      "Epoch [7/50], Step [536/735], Loss: 0.0475\n",
      "Epoch [7/50], Step [537/735], Loss: 0.1411\n",
      "Epoch [7/50], Step [538/735], Loss: 0.0573\n",
      "Epoch [7/50], Step [539/735], Loss: 0.0707\n",
      "Epoch [7/50], Step [540/735], Loss: 0.1902\n",
      "Epoch [7/50], Step [541/735], Loss: 0.1493\n",
      "Epoch [7/50], Step [542/735], Loss: 0.1559\n",
      "Epoch [7/50], Step [543/735], Loss: 0.0464\n",
      "Epoch [7/50], Step [544/735], Loss: 0.1050\n",
      "Epoch [7/50], Step [545/735], Loss: 0.0552\n",
      "Epoch [7/50], Step [546/735], Loss: 0.0403\n",
      "Epoch [7/50], Step [547/735], Loss: 0.2608\n",
      "Epoch [7/50], Step [548/735], Loss: 0.4189\n",
      "Epoch [7/50], Step [549/735], Loss: 0.5362\n",
      "Epoch [7/50], Step [550/735], Loss: 0.0946\n",
      "Epoch [7/50], Step [551/735], Loss: 0.2833\n",
      "Epoch [7/50], Step [552/735], Loss: 0.1508\n",
      "Epoch [7/50], Step [553/735], Loss: 0.0276\n",
      "Epoch [7/50], Step [554/735], Loss: 0.0697\n",
      "Epoch [7/50], Step [555/735], Loss: 0.0745\n",
      "Epoch [7/50], Step [556/735], Loss: 0.0489\n",
      "Epoch [7/50], Step [557/735], Loss: 0.1108\n",
      "Epoch [7/50], Step [558/735], Loss: 0.1161\n",
      "Epoch [7/50], Step [559/735], Loss: 0.0900\n",
      "Epoch [7/50], Step [560/735], Loss: 0.0414\n",
      "Epoch [7/50], Step [561/735], Loss: 0.0496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Step [562/735], Loss: 0.0663\n",
      "Epoch [7/50], Step [563/735], Loss: 0.0906\n",
      "Epoch [7/50], Step [564/735], Loss: 0.2263\n",
      "Epoch [7/50], Step [565/735], Loss: 0.0792\n",
      "Epoch [7/50], Step [566/735], Loss: 0.1310\n",
      "Epoch [7/50], Step [567/735], Loss: 0.0594\n",
      "Epoch [7/50], Step [568/735], Loss: 0.0861\n",
      "Epoch [7/50], Step [569/735], Loss: 0.4839\n",
      "Epoch [7/50], Step [570/735], Loss: 0.1169\n",
      "Epoch [7/50], Step [571/735], Loss: 0.4264\n",
      "Epoch [7/50], Step [572/735], Loss: 0.0455\n",
      "Epoch [7/50], Step [573/735], Loss: 0.4144\n",
      "Epoch [7/50], Step [574/735], Loss: 0.0729\n",
      "Epoch [7/50], Step [575/735], Loss: 0.1843\n",
      "Epoch [7/50], Step [576/735], Loss: 0.1523\n",
      "Epoch [7/50], Step [577/735], Loss: 0.1349\n",
      "Epoch [7/50], Step [578/735], Loss: 0.0988\n",
      "Epoch [7/50], Step [579/735], Loss: 0.0563\n",
      "Epoch [7/50], Step [580/735], Loss: 0.0949\n",
      "Epoch [7/50], Step [581/735], Loss: 0.0503\n",
      "Epoch [7/50], Step [582/735], Loss: 0.1795\n",
      "Epoch [7/50], Step [583/735], Loss: 0.1675\n",
      "Epoch [7/50], Step [584/735], Loss: 0.0707\n",
      "Epoch [7/50], Step [585/735], Loss: 0.0491\n",
      "Epoch [7/50], Step [586/735], Loss: 0.1233\n",
      "Epoch [7/50], Step [587/735], Loss: 0.0595\n",
      "Epoch [7/50], Step [588/735], Loss: 0.2296\n",
      "Epoch [7/50], Step [589/735], Loss: 0.0598\n",
      "Epoch [7/50], Step [590/735], Loss: 0.1127\n",
      "Epoch [7/50], Step [591/735], Loss: 0.1899\n",
      "Epoch [7/50], Step [592/735], Loss: 0.2398\n",
      "Epoch [7/50], Step [593/735], Loss: 0.0239\n",
      "Epoch [7/50], Step [594/735], Loss: 0.1686\n",
      "Epoch [7/50], Step [595/735], Loss: 0.0788\n",
      "Epoch [7/50], Step [596/735], Loss: 0.0717\n",
      "Epoch [7/50], Step [597/735], Loss: 0.0575\n",
      "Epoch [7/50], Step [598/735], Loss: 0.0615\n",
      "Epoch [7/50], Step [599/735], Loss: 0.2024\n",
      "Epoch [7/50], Step [600/735], Loss: 0.0706\n",
      "Epoch [7/50], Step [601/735], Loss: 0.0811\n",
      "Epoch [7/50], Step [602/735], Loss: 0.0500\n",
      "Epoch [7/50], Step [603/735], Loss: 0.1283\n",
      "Epoch [7/50], Step [604/735], Loss: 0.0732\n",
      "Epoch [7/50], Step [605/735], Loss: 0.9347\n",
      "Epoch [7/50], Step [606/735], Loss: 0.1566\n",
      "Epoch [7/50], Step [607/735], Loss: 0.1569\n",
      "Epoch [7/50], Step [608/735], Loss: 0.4079\n",
      "Epoch [7/50], Step [609/735], Loss: 0.4503\n",
      "Epoch [7/50], Step [610/735], Loss: 0.1382\n",
      "Epoch [7/50], Step [611/735], Loss: 0.0341\n",
      "Epoch [7/50], Step [612/735], Loss: 0.0542\n",
      "Epoch [7/50], Step [613/735], Loss: 0.1343\n",
      "Epoch [7/50], Step [614/735], Loss: 0.0822\n",
      "Epoch [7/50], Step [615/735], Loss: 0.0736\n",
      "Epoch [7/50], Step [616/735], Loss: 0.2410\n",
      "Epoch [7/50], Step [617/735], Loss: 0.1014\n",
      "Epoch [7/50], Step [618/735], Loss: 0.0838\n",
      "Epoch [7/50], Step [619/735], Loss: 0.1588\n",
      "Epoch [7/50], Step [620/735], Loss: 0.1305\n",
      "Epoch [7/50], Step [621/735], Loss: 0.0499\n",
      "Epoch [7/50], Step [622/735], Loss: 0.1864\n",
      "Epoch [7/50], Step [623/735], Loss: 0.0478\n",
      "Epoch [7/50], Step [624/735], Loss: 0.3406\n",
      "Epoch [7/50], Step [625/735], Loss: 0.1134\n",
      "Epoch [7/50], Step [626/735], Loss: 0.2268\n",
      "Epoch [7/50], Step [627/735], Loss: 0.0731\n",
      "Epoch [7/50], Step [628/735], Loss: 0.2603\n",
      "Epoch [7/50], Step [629/735], Loss: 0.1585\n",
      "Epoch [7/50], Step [630/735], Loss: 0.0934\n",
      "Epoch [7/50], Step [631/735], Loss: 0.0779\n",
      "Epoch [7/50], Step [632/735], Loss: 0.1127\n",
      "Epoch [7/50], Step [633/735], Loss: 0.2175\n",
      "Epoch [7/50], Step [634/735], Loss: 0.0923\n",
      "Epoch [7/50], Step [635/735], Loss: 0.0551\n",
      "Epoch [7/50], Step [636/735], Loss: 0.0569\n",
      "Epoch [7/50], Step [637/735], Loss: 0.0601\n",
      "Epoch [7/50], Step [638/735], Loss: 0.0265\n",
      "Epoch [7/50], Step [639/735], Loss: 0.1290\n",
      "Epoch [7/50], Step [640/735], Loss: 0.0427\n",
      "Epoch [7/50], Step [641/735], Loss: 0.0815\n",
      "Epoch [7/50], Step [642/735], Loss: 0.0998\n",
      "Epoch [7/50], Step [643/735], Loss: 0.0682\n",
      "Epoch [7/50], Step [644/735], Loss: 0.0988\n",
      "Epoch [7/50], Step [645/735], Loss: 0.0423\n",
      "Epoch [7/50], Step [646/735], Loss: 0.2011\n",
      "Epoch [7/50], Step [647/735], Loss: 0.0862\n",
      "Epoch [7/50], Step [648/735], Loss: 0.0540\n",
      "Epoch [7/50], Step [649/735], Loss: 0.1770\n",
      "Epoch [7/50], Step [650/735], Loss: 0.0712\n",
      "Epoch [7/50], Step [651/735], Loss: 0.3002\n",
      "Epoch [7/50], Step [652/735], Loss: 0.1150\n",
      "Epoch [7/50], Step [653/735], Loss: 0.0575\n",
      "Epoch [7/50], Step [654/735], Loss: 0.0937\n",
      "Epoch [7/50], Step [655/735], Loss: 0.1721\n",
      "Epoch [7/50], Step [656/735], Loss: 0.0477\n",
      "Epoch [7/50], Step [657/735], Loss: 0.2201\n",
      "Epoch [7/50], Step [658/735], Loss: 0.1177\n",
      "Epoch [7/50], Step [659/735], Loss: 0.3132\n",
      "Epoch [7/50], Step [660/735], Loss: 0.0267\n",
      "Epoch [7/50], Step [661/735], Loss: 0.1011\n",
      "Epoch [7/50], Step [662/735], Loss: 0.2948\n",
      "Epoch [7/50], Step [663/735], Loss: 0.1181\n",
      "Epoch [7/50], Step [664/735], Loss: 0.0416\n",
      "Epoch [7/50], Step [665/735], Loss: 0.1019\n",
      "Epoch [7/50], Step [666/735], Loss: 0.0864\n",
      "Epoch [7/50], Step [667/735], Loss: 0.0834\n",
      "Epoch [7/50], Step [668/735], Loss: 0.1367\n",
      "Epoch [7/50], Step [669/735], Loss: 0.1633\n",
      "Epoch [7/50], Step [670/735], Loss: 0.0783\n",
      "Epoch [7/50], Step [671/735], Loss: 0.0718\n",
      "Epoch [7/50], Step [672/735], Loss: 0.0528\n",
      "Epoch [7/50], Step [673/735], Loss: 0.0906\n",
      "Epoch [7/50], Step [674/735], Loss: 0.6255\n",
      "Epoch [7/50], Step [675/735], Loss: 0.1996\n",
      "Epoch [7/50], Step [676/735], Loss: 0.2249\n",
      "Epoch [7/50], Step [677/735], Loss: 0.0876\n",
      "Epoch [7/50], Step [678/735], Loss: 0.0880\n",
      "Epoch [7/50], Step [679/735], Loss: 0.1313\n",
      "Epoch [7/50], Step [680/735], Loss: 0.0762\n",
      "Epoch [7/50], Step [681/735], Loss: 0.1333\n",
      "Epoch [7/50], Step [682/735], Loss: 0.0461\n",
      "Epoch [7/50], Step [683/735], Loss: 0.1234\n",
      "Epoch [7/50], Step [684/735], Loss: 0.2518\n",
      "Epoch [7/50], Step [685/735], Loss: 0.1202\n",
      "Epoch [7/50], Step [686/735], Loss: 0.0694\n",
      "Epoch [7/50], Step [687/735], Loss: 0.0355\n",
      "Epoch [7/50], Step [688/735], Loss: 0.1027\n",
      "Epoch [7/50], Step [689/735], Loss: 0.1301\n",
      "Epoch [7/50], Step [690/735], Loss: 0.3461\n",
      "Epoch [7/50], Step [691/735], Loss: 0.1948\n",
      "Epoch [7/50], Step [692/735], Loss: 0.2388\n",
      "Epoch [7/50], Step [693/735], Loss: 0.1216\n",
      "Epoch [7/50], Step [694/735], Loss: 0.0633\n",
      "Epoch [7/50], Step [695/735], Loss: 0.0448\n",
      "Epoch [7/50], Step [696/735], Loss: 0.0532\n",
      "Epoch [7/50], Step [697/735], Loss: 0.0442\n",
      "Epoch [7/50], Step [698/735], Loss: 0.0459\n",
      "Epoch [7/50], Step [699/735], Loss: 0.0457\n",
      "Epoch [7/50], Step [700/735], Loss: 0.0669\n",
      "Epoch [7/50], Step [701/735], Loss: 0.1148\n",
      "Epoch [7/50], Step [702/735], Loss: 0.0960\n",
      "Epoch [7/50], Step [703/735], Loss: 0.0356\n",
      "Epoch [7/50], Step [704/735], Loss: 0.0752\n",
      "Epoch [7/50], Step [705/735], Loss: 0.0899\n",
      "Epoch [7/50], Step [706/735], Loss: 0.1078\n",
      "Epoch [7/50], Step [707/735], Loss: 0.2500\n",
      "Epoch [7/50], Step [708/735], Loss: 0.0899\n",
      "Epoch [7/50], Step [709/735], Loss: 0.1851\n",
      "Epoch [7/50], Step [710/735], Loss: 0.0549\n",
      "Epoch [7/50], Step [711/735], Loss: 0.0786\n",
      "Epoch [7/50], Step [712/735], Loss: 0.0495\n",
      "Epoch [7/50], Step [713/735], Loss: 0.1666\n",
      "Epoch [7/50], Step [714/735], Loss: 0.0638\n",
      "Epoch [7/50], Step [715/735], Loss: 0.1542\n",
      "Epoch [7/50], Step [716/735], Loss: 0.1449\n",
      "Epoch [7/50], Step [717/735], Loss: 0.0690\n",
      "Epoch [7/50], Step [718/735], Loss: 0.0435\n",
      "Epoch [7/50], Step [719/735], Loss: 0.0816\n",
      "Epoch [7/50], Step [720/735], Loss: 0.2623\n",
      "Epoch [7/50], Step [721/735], Loss: 0.1179\n",
      "Epoch [7/50], Step [722/735], Loss: 0.3459\n",
      "Epoch [7/50], Step [723/735], Loss: 0.0341\n",
      "Epoch [7/50], Step [724/735], Loss: 0.0731\n",
      "Epoch [7/50], Step [725/735], Loss: 0.0550\n",
      "Epoch [7/50], Step [726/735], Loss: 0.0826\n",
      "Epoch [7/50], Step [727/735], Loss: 0.0649\n",
      "Epoch [7/50], Step [728/735], Loss: 0.0816\n",
      "Epoch [7/50], Step [729/735], Loss: 0.1088\n",
      "Epoch [7/50], Step [730/735], Loss: 0.0710\n",
      "Epoch [7/50], Step [731/735], Loss: 0.2066\n",
      "Epoch [7/50], Step [732/735], Loss: 0.0743\n",
      "Epoch [7/50], Step [733/735], Loss: 0.1911\n",
      "Epoch [7/50], Step [734/735], Loss: 0.0828\n",
      "Epoch [7/50], Step [735/735], Loss: 0.1784\n",
      "Epoch [8/50], Step [1/735], Loss: 0.0344\n",
      "Epoch [8/50], Step [2/735], Loss: 0.1742\n",
      "Epoch [8/50], Step [3/735], Loss: 0.0823\n",
      "Epoch [8/50], Step [4/735], Loss: 0.1507\n",
      "Epoch [8/50], Step [5/735], Loss: 0.1840\n",
      "Epoch [8/50], Step [6/735], Loss: 0.0505\n",
      "Epoch [8/50], Step [7/735], Loss: 0.1379\n",
      "Epoch [8/50], Step [8/735], Loss: 0.1312\n",
      "Epoch [8/50], Step [9/735], Loss: 0.0817\n",
      "Epoch [8/50], Step [10/735], Loss: 0.0433\n",
      "Epoch [8/50], Step [11/735], Loss: 0.1347\n",
      "Epoch [8/50], Step [12/735], Loss: 0.1144\n",
      "Epoch [8/50], Step [13/735], Loss: 0.0344\n",
      "Epoch [8/50], Step [14/735], Loss: 0.0724\n",
      "Epoch [8/50], Step [15/735], Loss: 0.0403\n",
      "Epoch [8/50], Step [16/735], Loss: 0.1727\n",
      "Epoch [8/50], Step [17/735], Loss: 0.2820\n",
      "Epoch [8/50], Step [18/735], Loss: 0.0260\n",
      "Epoch [8/50], Step [19/735], Loss: 0.1806\n",
      "Epoch [8/50], Step [20/735], Loss: 0.1018\n",
      "Epoch [8/50], Step [21/735], Loss: 0.0284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Step [22/735], Loss: 0.1381\n",
      "Epoch [8/50], Step [23/735], Loss: 0.0983\n",
      "Epoch [8/50], Step [24/735], Loss: 0.3531\n",
      "Epoch [8/50], Step [25/735], Loss: 0.0320\n",
      "Epoch [8/50], Step [26/735], Loss: 0.1325\n",
      "Epoch [8/50], Step [27/735], Loss: 0.3615\n",
      "Epoch [8/50], Step [28/735], Loss: 0.0904\n",
      "Epoch [8/50], Step [29/735], Loss: 0.0539\n",
      "Epoch [8/50], Step [30/735], Loss: 0.0512\n",
      "Epoch [8/50], Step [31/735], Loss: 0.0690\n",
      "Epoch [8/50], Step [32/735], Loss: 0.1401\n",
      "Epoch [8/50], Step [33/735], Loss: 0.2422\n",
      "Epoch [8/50], Step [34/735], Loss: 0.2864\n",
      "Epoch [8/50], Step [35/735], Loss: 0.1076\n",
      "Epoch [8/50], Step [36/735], Loss: 0.0990\n",
      "Epoch [8/50], Step [37/735], Loss: 0.1139\n",
      "Epoch [8/50], Step [38/735], Loss: 0.1293\n",
      "Epoch [8/50], Step [39/735], Loss: 0.1890\n",
      "Epoch [8/50], Step [40/735], Loss: 0.0479\n",
      "Epoch [8/50], Step [41/735], Loss: 0.1541\n",
      "Epoch [8/50], Step [42/735], Loss: 0.0784\n",
      "Epoch [8/50], Step [43/735], Loss: 0.1714\n",
      "Epoch [8/50], Step [44/735], Loss: 0.0381\n",
      "Epoch [8/50], Step [45/735], Loss: 0.2526\n",
      "Epoch [8/50], Step [46/735], Loss: 0.1440\n",
      "Epoch [8/50], Step [47/735], Loss: 0.0779\n",
      "Epoch [8/50], Step [48/735], Loss: 0.0491\n",
      "Epoch [8/50], Step [49/735], Loss: 0.1762\n",
      "Epoch [8/50], Step [50/735], Loss: 0.1507\n",
      "Epoch [8/50], Step [51/735], Loss: 0.0514\n",
      "Epoch [8/50], Step [52/735], Loss: 0.1122\n",
      "Epoch [8/50], Step [53/735], Loss: 0.0898\n",
      "Epoch [8/50], Step [54/735], Loss: 0.1574\n",
      "Epoch [8/50], Step [55/735], Loss: 0.1565\n",
      "Epoch [8/50], Step [56/735], Loss: 0.1904\n",
      "Epoch [8/50], Step [57/735], Loss: 0.0774\n",
      "Epoch [8/50], Step [58/735], Loss: 0.3981\n",
      "Epoch [8/50], Step [59/735], Loss: 0.0316\n",
      "Epoch [8/50], Step [60/735], Loss: 0.0925\n",
      "Epoch [8/50], Step [61/735], Loss: 0.0832\n",
      "Epoch [8/50], Step [62/735], Loss: 0.0778\n",
      "Epoch [8/50], Step [63/735], Loss: 0.1915\n",
      "Epoch [8/50], Step [64/735], Loss: 0.1577\n",
      "Epoch [8/50], Step [65/735], Loss: 0.0743\n",
      "Epoch [8/50], Step [66/735], Loss: 0.0296\n",
      "Epoch [8/50], Step [67/735], Loss: 0.0410\n",
      "Epoch [8/50], Step [68/735], Loss: 0.0763\n",
      "Epoch [8/50], Step [69/735], Loss: 0.0319\n",
      "Epoch [8/50], Step [70/735], Loss: 0.0932\n",
      "Epoch [8/50], Step [71/735], Loss: 0.4652\n",
      "Epoch [8/50], Step [72/735], Loss: 0.0537\n",
      "Epoch [8/50], Step [73/735], Loss: 0.0704\n",
      "Epoch [8/50], Step [74/735], Loss: 0.2003\n",
      "Epoch [8/50], Step [75/735], Loss: 0.1096\n",
      "Epoch [8/50], Step [76/735], Loss: 0.0962\n",
      "Epoch [8/50], Step [77/735], Loss: 0.0350\n",
      "Epoch [8/50], Step [78/735], Loss: 0.0454\n",
      "Epoch [8/50], Step [79/735], Loss: 0.0676\n",
      "Epoch [8/50], Step [80/735], Loss: 0.1996\n",
      "Epoch [8/50], Step [81/735], Loss: 0.1764\n",
      "Epoch [8/50], Step [82/735], Loss: 0.0598\n",
      "Epoch [8/50], Step [83/735], Loss: 0.4235\n",
      "Epoch [8/50], Step [84/735], Loss: 0.3232\n",
      "Epoch [8/50], Step [85/735], Loss: 0.1813\n",
      "Epoch [8/50], Step [86/735], Loss: 0.1437\n",
      "Epoch [8/50], Step [87/735], Loss: 0.1443\n",
      "Epoch [8/50], Step [88/735], Loss: 0.1515\n",
      "Epoch [8/50], Step [89/735], Loss: 0.0432\n",
      "Epoch [8/50], Step [90/735], Loss: 0.1023\n",
      "Epoch [8/50], Step [91/735], Loss: 0.1350\n",
      "Epoch [8/50], Step [92/735], Loss: 0.1012\n",
      "Epoch [8/50], Step [93/735], Loss: 0.1206\n",
      "Epoch [8/50], Step [94/735], Loss: 0.0843\n",
      "Epoch [8/50], Step [95/735], Loss: 0.0787\n",
      "Epoch [8/50], Step [96/735], Loss: 0.1291\n",
      "Epoch [8/50], Step [97/735], Loss: 0.3061\n",
      "Epoch [8/50], Step [98/735], Loss: 0.1129\n",
      "Epoch [8/50], Step [99/735], Loss: 0.0565\n",
      "Epoch [8/50], Step [100/735], Loss: 0.0349\n",
      "Epoch [8/50], Step [101/735], Loss: 0.0408\n",
      "Epoch [8/50], Step [102/735], Loss: 0.0424\n",
      "Epoch [8/50], Step [103/735], Loss: 0.1475\n",
      "Epoch [8/50], Step [104/735], Loss: 0.0904\n",
      "Epoch [8/50], Step [105/735], Loss: 0.1007\n",
      "Epoch [8/50], Step [106/735], Loss: 0.0439\n",
      "Epoch [8/50], Step [107/735], Loss: 0.0435\n",
      "Epoch [8/50], Step [108/735], Loss: 0.0975\n",
      "Epoch [8/50], Step [109/735], Loss: 0.2690\n",
      "Epoch [8/50], Step [110/735], Loss: 0.0336\n",
      "Epoch [8/50], Step [111/735], Loss: 0.3450\n",
      "Epoch [8/50], Step [112/735], Loss: 0.0705\n",
      "Epoch [8/50], Step [113/735], Loss: 0.3350\n",
      "Epoch [8/50], Step [114/735], Loss: 0.0508\n",
      "Epoch [8/50], Step [115/735], Loss: 0.0663\n",
      "Epoch [8/50], Step [116/735], Loss: 0.0613\n",
      "Epoch [8/50], Step [117/735], Loss: 0.1014\n",
      "Epoch [8/50], Step [118/735], Loss: 0.0719\n",
      "Epoch [8/50], Step [119/735], Loss: 0.1108\n",
      "Epoch [8/50], Step [120/735], Loss: 0.1036\n",
      "Epoch [8/50], Step [121/735], Loss: 0.0593\n",
      "Epoch [8/50], Step [122/735], Loss: 0.2321\n",
      "Epoch [8/50], Step [123/735], Loss: 0.4319\n",
      "Epoch [8/50], Step [124/735], Loss: 0.1516\n",
      "Epoch [8/50], Step [125/735], Loss: 0.0676\n",
      "Epoch [8/50], Step [126/735], Loss: 0.1850\n",
      "Epoch [8/50], Step [127/735], Loss: 0.1343\n",
      "Epoch [8/50], Step [128/735], Loss: 0.1156\n",
      "Epoch [8/50], Step [129/735], Loss: 0.3312\n",
      "Epoch [8/50], Step [130/735], Loss: 0.1380\n",
      "Epoch [8/50], Step [131/735], Loss: 0.0887\n",
      "Epoch [8/50], Step [132/735], Loss: 0.2115\n",
      "Epoch [8/50], Step [133/735], Loss: 0.0712\n",
      "Epoch [8/50], Step [134/735], Loss: 0.0722\n",
      "Epoch [8/50], Step [135/735], Loss: 0.0480\n",
      "Epoch [8/50], Step [136/735], Loss: 0.0960\n",
      "Epoch [8/50], Step [137/735], Loss: 0.0296\n",
      "Epoch [8/50], Step [138/735], Loss: 0.0735\n",
      "Epoch [8/50], Step [139/735], Loss: 0.1008\n",
      "Epoch [8/50], Step [140/735], Loss: 0.0304\n",
      "Epoch [8/50], Step [141/735], Loss: 0.0648\n",
      "Epoch [8/50], Step [142/735], Loss: 0.0674\n",
      "Epoch [8/50], Step [143/735], Loss: 0.0366\n",
      "Epoch [8/50], Step [144/735], Loss: 0.0976\n",
      "Epoch [8/50], Step [145/735], Loss: 0.0273\n",
      "Epoch [8/50], Step [146/735], Loss: 0.1447\n",
      "Epoch [8/50], Step [147/735], Loss: 0.1702\n",
      "Epoch [8/50], Step [148/735], Loss: 0.0746\n",
      "Epoch [8/50], Step [149/735], Loss: 0.1856\n",
      "Epoch [8/50], Step [150/735], Loss: 0.0390\n",
      "Epoch [8/50], Step [151/735], Loss: 0.1435\n",
      "Epoch [8/50], Step [152/735], Loss: 0.4225\n",
      "Epoch [8/50], Step [153/735], Loss: 0.8795\n",
      "Epoch [8/50], Step [154/735], Loss: 0.0739\n",
      "Epoch [8/50], Step [155/735], Loss: 0.0682\n",
      "Epoch [8/50], Step [156/735], Loss: 0.0611\n",
      "Epoch [8/50], Step [157/735], Loss: 0.0765\n",
      "Epoch [8/50], Step [158/735], Loss: 0.0554\n",
      "Epoch [8/50], Step [159/735], Loss: 0.6299\n",
      "Epoch [8/50], Step [160/735], Loss: 0.1096\n",
      "Epoch [8/50], Step [161/735], Loss: 0.1545\n",
      "Epoch [8/50], Step [162/735], Loss: 0.2550\n",
      "Epoch [8/50], Step [163/735], Loss: 0.0397\n",
      "Epoch [8/50], Step [164/735], Loss: 0.0603\n",
      "Epoch [8/50], Step [165/735], Loss: 0.0368\n",
      "Epoch [8/50], Step [166/735], Loss: 0.2609\n",
      "Epoch [8/50], Step [167/735], Loss: 0.1074\n",
      "Epoch [8/50], Step [168/735], Loss: 0.0408\n",
      "Epoch [8/50], Step [169/735], Loss: 0.0798\n",
      "Epoch [8/50], Step [170/735], Loss: 0.1628\n",
      "Epoch [8/50], Step [171/735], Loss: 0.0716\n",
      "Epoch [8/50], Step [172/735], Loss: 0.1314\n",
      "Epoch [8/50], Step [173/735], Loss: 0.1461\n",
      "Epoch [8/50], Step [174/735], Loss: 0.1489\n",
      "Epoch [8/50], Step [175/735], Loss: 0.0425\n",
      "Epoch [8/50], Step [176/735], Loss: 0.0561\n",
      "Epoch [8/50], Step [177/735], Loss: 0.0381\n",
      "Epoch [8/50], Step [178/735], Loss: 0.1036\n",
      "Epoch [8/50], Step [179/735], Loss: 0.0419\n",
      "Epoch [8/50], Step [180/735], Loss: 0.1250\n",
      "Epoch [8/50], Step [181/735], Loss: 0.2337\n",
      "Epoch [8/50], Step [182/735], Loss: 0.0534\n",
      "Epoch [8/50], Step [183/735], Loss: 0.0382\n",
      "Epoch [8/50], Step [184/735], Loss: 0.0358\n",
      "Epoch [8/50], Step [185/735], Loss: 0.1579\n",
      "Epoch [8/50], Step [186/735], Loss: 0.0324\n",
      "Epoch [8/50], Step [187/735], Loss: 0.1129\n",
      "Epoch [8/50], Step [188/735], Loss: 0.3394\n",
      "Epoch [8/50], Step [189/735], Loss: 0.0391\n",
      "Epoch [8/50], Step [190/735], Loss: 0.0659\n",
      "Epoch [8/50], Step [191/735], Loss: 0.1123\n",
      "Epoch [8/50], Step [192/735], Loss: 0.1245\n",
      "Epoch [8/50], Step [193/735], Loss: 0.2341\n",
      "Epoch [8/50], Step [194/735], Loss: 0.0255\n",
      "Epoch [8/50], Step [195/735], Loss: 0.1841\n",
      "Epoch [8/50], Step [196/735], Loss: 0.3961\n",
      "Epoch [8/50], Step [197/735], Loss: 0.0903\n",
      "Epoch [8/50], Step [198/735], Loss: 0.2327\n",
      "Epoch [8/50], Step [199/735], Loss: 0.1141\n",
      "Epoch [8/50], Step [200/735], Loss: 0.0828\n",
      "Epoch [8/50], Step [201/735], Loss: 0.0277\n",
      "Epoch [8/50], Step [202/735], Loss: 0.1367\n",
      "Epoch [8/50], Step [203/735], Loss: 0.2118\n",
      "Epoch [8/50], Step [204/735], Loss: 0.1285\n",
      "Epoch [8/50], Step [205/735], Loss: 0.1988\n",
      "Epoch [8/50], Step [206/735], Loss: 0.1296\n",
      "Epoch [8/50], Step [207/735], Loss: 0.1938\n",
      "Epoch [8/50], Step [208/735], Loss: 0.0362\n",
      "Epoch [8/50], Step [209/735], Loss: 0.0550\n",
      "Epoch [8/50], Step [210/735], Loss: 0.2612\n",
      "Epoch [8/50], Step [211/735], Loss: 0.0567\n",
      "Epoch [8/50], Step [212/735], Loss: 0.0925\n",
      "Epoch [8/50], Step [213/735], Loss: 0.0955\n",
      "Epoch [8/50], Step [214/735], Loss: 0.1026\n",
      "Epoch [8/50], Step [215/735], Loss: 0.0552\n",
      "Epoch [8/50], Step [216/735], Loss: 0.0302\n",
      "Epoch [8/50], Step [217/735], Loss: 0.0450\n",
      "Epoch [8/50], Step [218/735], Loss: 0.1140\n",
      "Epoch [8/50], Step [219/735], Loss: 0.2012\n",
      "Epoch [8/50], Step [220/735], Loss: 0.0879\n",
      "Epoch [8/50], Step [221/735], Loss: 0.1422\n",
      "Epoch [8/50], Step [222/735], Loss: 0.3152\n",
      "Epoch [8/50], Step [223/735], Loss: 0.0509\n",
      "Epoch [8/50], Step [224/735], Loss: 0.1199\n",
      "Epoch [8/50], Step [225/735], Loss: 0.3376\n",
      "Epoch [8/50], Step [226/735], Loss: 0.2637\n",
      "Epoch [8/50], Step [227/735], Loss: 0.1086\n",
      "Epoch [8/50], Step [228/735], Loss: 0.1051\n",
      "Epoch [8/50], Step [229/735], Loss: 0.1803\n",
      "Epoch [8/50], Step [230/735], Loss: 0.5061\n",
      "Epoch [8/50], Step [231/735], Loss: 0.0794\n",
      "Epoch [8/50], Step [232/735], Loss: 0.1841\n",
      "Epoch [8/50], Step [233/735], Loss: 0.3085\n",
      "Epoch [8/50], Step [234/735], Loss: 0.1142\n",
      "Epoch [8/50], Step [235/735], Loss: 0.2670\n",
      "Epoch [8/50], Step [236/735], Loss: 0.0402\n",
      "Epoch [8/50], Step [237/735], Loss: 0.3887\n",
      "Epoch [8/50], Step [238/735], Loss: 0.1228\n",
      "Epoch [8/50], Step [239/735], Loss: 0.0553\n",
      "Epoch [8/50], Step [240/735], Loss: 0.2932\n",
      "Epoch [8/50], Step [241/735], Loss: 0.1186\n",
      "Epoch [8/50], Step [242/735], Loss: 0.5377\n",
      "Epoch [8/50], Step [243/735], Loss: 0.1211\n",
      "Epoch [8/50], Step [244/735], Loss: 0.3551\n",
      "Epoch [8/50], Step [245/735], Loss: 0.4959\n",
      "Epoch [8/50], Step [246/735], Loss: 0.0906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Step [247/735], Loss: 0.0778\n",
      "Epoch [8/50], Step [248/735], Loss: 0.3025\n",
      "Epoch [8/50], Step [249/735], Loss: 0.3343\n",
      "Epoch [8/50], Step [250/735], Loss: 0.0634\n",
      "Epoch [8/50], Step [251/735], Loss: 0.0534\n",
      "Epoch [8/50], Step [252/735], Loss: 0.0490\n",
      "Epoch [8/50], Step [253/735], Loss: 0.0625\n",
      "Epoch [8/50], Step [254/735], Loss: 0.1354\n",
      "Epoch [8/50], Step [255/735], Loss: 0.0819\n",
      "Epoch [8/50], Step [256/735], Loss: 0.1864\n",
      "Epoch [8/50], Step [257/735], Loss: 0.0970\n",
      "Epoch [8/50], Step [258/735], Loss: 0.1486\n",
      "Epoch [8/50], Step [259/735], Loss: 0.0764\n",
      "Epoch [8/50], Step [260/735], Loss: 0.3434\n",
      "Epoch [8/50], Step [261/735], Loss: 0.1362\n",
      "Epoch [8/50], Step [262/735], Loss: 0.1058\n",
      "Epoch [8/50], Step [263/735], Loss: 0.0393\n",
      "Epoch [8/50], Step [264/735], Loss: 0.0412\n",
      "Epoch [8/50], Step [265/735], Loss: 0.1745\n",
      "Epoch [8/50], Step [266/735], Loss: 0.0595\n",
      "Epoch [8/50], Step [267/735], Loss: 0.0334\n",
      "Epoch [8/50], Step [268/735], Loss: 0.0834\n",
      "Epoch [8/50], Step [269/735], Loss: 0.1607\n",
      "Epoch [8/50], Step [270/735], Loss: 0.0628\n",
      "Epoch [8/50], Step [271/735], Loss: 0.0318\n",
      "Epoch [8/50], Step [272/735], Loss: 0.0977\n",
      "Epoch [8/50], Step [273/735], Loss: 0.1458\n",
      "Epoch [8/50], Step [274/735], Loss: 0.0686\n",
      "Epoch [8/50], Step [275/735], Loss: 0.0475\n",
      "Epoch [8/50], Step [276/735], Loss: 0.0608\n",
      "Epoch [8/50], Step [277/735], Loss: 0.0239\n",
      "Epoch [8/50], Step [278/735], Loss: 0.0717\n",
      "Epoch [8/50], Step [279/735], Loss: 0.0678\n",
      "Epoch [8/50], Step [280/735], Loss: 0.0984\n",
      "Epoch [8/50], Step [281/735], Loss: 0.2968\n",
      "Epoch [8/50], Step [282/735], Loss: 0.0595\n",
      "Epoch [8/50], Step [283/735], Loss: 0.0450\n",
      "Epoch [8/50], Step [284/735], Loss: 0.0395\n",
      "Epoch [8/50], Step [285/735], Loss: 0.0742\n",
      "Epoch [8/50], Step [286/735], Loss: 0.0532\n",
      "Epoch [8/50], Step [287/735], Loss: 0.0359\n",
      "Epoch [8/50], Step [288/735], Loss: 0.0467\n",
      "Epoch [8/50], Step [289/735], Loss: 0.1495\n",
      "Epoch [8/50], Step [290/735], Loss: 0.0757\n",
      "Epoch [8/50], Step [291/735], Loss: 0.1485\n",
      "Epoch [8/50], Step [292/735], Loss: 0.0398\n",
      "Epoch [8/50], Step [293/735], Loss: 0.0437\n",
      "Epoch [8/50], Step [294/735], Loss: 0.1049\n",
      "Epoch [8/50], Step [295/735], Loss: 0.1591\n",
      "Epoch [8/50], Step [296/735], Loss: 0.1675\n",
      "Epoch [8/50], Step [297/735], Loss: 0.0527\n",
      "Epoch [8/50], Step [298/735], Loss: 0.0956\n",
      "Epoch [8/50], Step [299/735], Loss: 0.1353\n",
      "Epoch [8/50], Step [300/735], Loss: 0.0805\n",
      "Epoch [8/50], Step [301/735], Loss: 0.0863\n",
      "Epoch [8/50], Step [302/735], Loss: 0.0812\n",
      "Epoch [8/50], Step [303/735], Loss: 0.0517\n",
      "Epoch [8/50], Step [304/735], Loss: 0.2315\n",
      "Epoch [8/50], Step [305/735], Loss: 0.0786\n",
      "Epoch [8/50], Step [306/735], Loss: 0.0285\n",
      "Epoch [8/50], Step [307/735], Loss: 0.1217\n",
      "Epoch [8/50], Step [308/735], Loss: 0.0659\n",
      "Epoch [8/50], Step [309/735], Loss: 0.1389\n",
      "Epoch [8/50], Step [310/735], Loss: 0.0630\n",
      "Epoch [8/50], Step [311/735], Loss: 0.0559\n",
      "Epoch [8/50], Step [312/735], Loss: 0.0636\n",
      "Epoch [8/50], Step [313/735], Loss: 0.0620\n",
      "Epoch [8/50], Step [314/735], Loss: 0.0703\n",
      "Epoch [8/50], Step [315/735], Loss: 0.0964\n",
      "Epoch [8/50], Step [316/735], Loss: 0.0608\n",
      "Epoch [8/50], Step [317/735], Loss: 0.0691\n",
      "Epoch [8/50], Step [318/735], Loss: 0.0746\n",
      "Epoch [8/50], Step [319/735], Loss: 0.0503\n",
      "Epoch [8/50], Step [320/735], Loss: 0.4648\n",
      "Epoch [8/50], Step [321/735], Loss: 0.0947\n",
      "Epoch [8/50], Step [322/735], Loss: 0.0834\n",
      "Epoch [8/50], Step [323/735], Loss: 0.1168\n",
      "Epoch [8/50], Step [324/735], Loss: 0.1418\n",
      "Epoch [8/50], Step [325/735], Loss: 0.0598\n",
      "Epoch [8/50], Step [326/735], Loss: 0.1342\n",
      "Epoch [8/50], Step [327/735], Loss: 0.1077\n",
      "Epoch [8/50], Step [328/735], Loss: 0.0641\n",
      "Epoch [8/50], Step [329/735], Loss: 0.0531\n",
      "Epoch [8/50], Step [330/735], Loss: 0.0583\n",
      "Epoch [8/50], Step [331/735], Loss: 0.0409\n",
      "Epoch [8/50], Step [332/735], Loss: 0.0798\n",
      "Epoch [8/50], Step [333/735], Loss: 0.0605\n",
      "Epoch [8/50], Step [334/735], Loss: 0.1323\n",
      "Epoch [8/50], Step [335/735], Loss: 0.0493\n",
      "Epoch [8/50], Step [336/735], Loss: 0.0634\n",
      "Epoch [8/50], Step [337/735], Loss: 0.0705\n",
      "Epoch [8/50], Step [338/735], Loss: 0.1143\n",
      "Epoch [8/50], Step [339/735], Loss: 0.0800\n",
      "Epoch [8/50], Step [340/735], Loss: 0.1359\n",
      "Epoch [8/50], Step [341/735], Loss: 0.0322\n",
      "Epoch [8/50], Step [342/735], Loss: 0.1031\n",
      "Epoch [8/50], Step [343/735], Loss: 0.1280\n",
      "Epoch [8/50], Step [344/735], Loss: 0.1813\n",
      "Epoch [8/50], Step [345/735], Loss: 0.1161\n",
      "Epoch [8/50], Step [346/735], Loss: 0.2183\n",
      "Epoch [8/50], Step [347/735], Loss: 0.0538\n",
      "Epoch [8/50], Step [348/735], Loss: 0.0900\n",
      "Epoch [8/50], Step [349/735], Loss: 0.0623\n",
      "Epoch [8/50], Step [350/735], Loss: 0.0557\n",
      "Epoch [8/50], Step [351/735], Loss: 0.0881\n",
      "Epoch [8/50], Step [352/735], Loss: 0.0386\n",
      "Epoch [8/50], Step [353/735], Loss: 0.1004\n",
      "Epoch [8/50], Step [354/735], Loss: 0.1387\n",
      "Epoch [8/50], Step [355/735], Loss: 0.0556\n",
      "Epoch [8/50], Step [356/735], Loss: 0.0873\n",
      "Epoch [8/50], Step [357/735], Loss: 0.0996\n",
      "Epoch [8/50], Step [358/735], Loss: 0.0627\n",
      "Epoch [8/50], Step [359/735], Loss: 0.0460\n",
      "Epoch [8/50], Step [360/735], Loss: 0.0479\n",
      "Epoch [8/50], Step [361/735], Loss: 0.0449\n",
      "Epoch [8/50], Step [362/735], Loss: 0.0477\n",
      "Epoch [8/50], Step [363/735], Loss: 0.1812\n",
      "Epoch [8/50], Step [364/735], Loss: 0.1126\n",
      "Epoch [8/50], Step [365/735], Loss: 0.1006\n",
      "Epoch [8/50], Step [366/735], Loss: 0.1264\n",
      "Epoch [8/50], Step [367/735], Loss: 0.4726\n",
      "Epoch [8/50], Step [368/735], Loss: 0.0770\n",
      "Epoch [8/50], Step [369/735], Loss: 0.0477\n",
      "Epoch [8/50], Step [370/735], Loss: 0.0866\n",
      "Epoch [8/50], Step [371/735], Loss: 0.0466\n",
      "Epoch [8/50], Step [372/735], Loss: 0.0547\n",
      "Epoch [8/50], Step [373/735], Loss: 0.3990\n",
      "Epoch [8/50], Step [374/735], Loss: 0.0276\n",
      "Epoch [8/50], Step [375/735], Loss: 0.0342\n",
      "Epoch [8/50], Step [376/735], Loss: 0.1189\n",
      "Epoch [8/50], Step [377/735], Loss: 0.0269\n",
      "Epoch [8/50], Step [378/735], Loss: 0.0302\n",
      "Epoch [8/50], Step [379/735], Loss: 0.0541\n",
      "Epoch [8/50], Step [380/735], Loss: 0.1464\n",
      "Epoch [8/50], Step [381/735], Loss: 0.1599\n",
      "Epoch [8/50], Step [382/735], Loss: 0.0468\n",
      "Epoch [8/50], Step [383/735], Loss: 0.1397\n",
      "Epoch [8/50], Step [384/735], Loss: 0.0864\n",
      "Epoch [8/50], Step [385/735], Loss: 0.1458\n",
      "Epoch [8/50], Step [386/735], Loss: 0.2281\n",
      "Epoch [8/50], Step [387/735], Loss: 0.0250\n",
      "Epoch [8/50], Step [388/735], Loss: 0.1542\n",
      "Epoch [8/50], Step [389/735], Loss: 0.0570\n",
      "Epoch [8/50], Step [390/735], Loss: 0.2375\n",
      "Epoch [8/50], Step [391/735], Loss: 0.0781\n",
      "Epoch [8/50], Step [392/735], Loss: 0.0741\n",
      "Epoch [8/50], Step [393/735], Loss: 0.1070\n",
      "Epoch [8/50], Step [394/735], Loss: 0.2875\n",
      "Epoch [8/50], Step [395/735], Loss: 0.1770\n",
      "Epoch [8/50], Step [396/735], Loss: 0.0317\n",
      "Epoch [8/50], Step [397/735], Loss: 0.0426\n",
      "Epoch [8/50], Step [398/735], Loss: 0.0674\n",
      "Epoch [8/50], Step [399/735], Loss: 0.1566\n",
      "Epoch [8/50], Step [400/735], Loss: 0.1038\n",
      "Epoch [8/50], Step [401/735], Loss: 0.0898\n",
      "Epoch [8/50], Step [402/735], Loss: 0.1273\n",
      "Epoch [8/50], Step [403/735], Loss: 0.0380\n",
      "Epoch [8/50], Step [404/735], Loss: 0.0798\n",
      "Epoch [8/50], Step [405/735], Loss: 0.3695\n",
      "Epoch [8/50], Step [406/735], Loss: 0.0789\n",
      "Epoch [8/50], Step [407/735], Loss: 0.0351\n",
      "Epoch [8/50], Step [408/735], Loss: 0.0509\n",
      "Epoch [8/50], Step [409/735], Loss: 0.0305\n",
      "Epoch [8/50], Step [410/735], Loss: 0.0770\n",
      "Epoch [8/50], Step [411/735], Loss: 0.0819\n",
      "Epoch [8/50], Step [412/735], Loss: 0.0760\n",
      "Epoch [8/50], Step [413/735], Loss: 0.0864\n",
      "Epoch [8/50], Step [414/735], Loss: 0.0829\n",
      "Epoch [8/50], Step [415/735], Loss: 0.0338\n",
      "Epoch [8/50], Step [416/735], Loss: 0.0847\n",
      "Epoch [8/50], Step [417/735], Loss: 0.0282\n",
      "Epoch [8/50], Step [418/735], Loss: 0.1114\n",
      "Epoch [8/50], Step [419/735], Loss: 0.0539\n",
      "Epoch [8/50], Step [420/735], Loss: 0.0720\n",
      "Epoch [8/50], Step [421/735], Loss: 0.0879\n",
      "Epoch [8/50], Step [422/735], Loss: 0.2428\n",
      "Epoch [8/50], Step [423/735], Loss: 0.2716\n",
      "Epoch [8/50], Step [424/735], Loss: 0.0406\n",
      "Epoch [8/50], Step [425/735], Loss: 0.2171\n",
      "Epoch [8/50], Step [426/735], Loss: 0.0554\n",
      "Epoch [8/50], Step [427/735], Loss: 0.0216\n",
      "Epoch [8/50], Step [428/735], Loss: 0.0425\n",
      "Epoch [8/50], Step [429/735], Loss: 0.0483\n",
      "Epoch [8/50], Step [430/735], Loss: 0.3093\n",
      "Epoch [8/50], Step [431/735], Loss: 0.2058\n",
      "Epoch [8/50], Step [432/735], Loss: 0.0452\n",
      "Epoch [8/50], Step [433/735], Loss: 0.2272\n",
      "Epoch [8/50], Step [434/735], Loss: 0.1238\n",
      "Epoch [8/50], Step [435/735], Loss: 0.0462\n",
      "Epoch [8/50], Step [436/735], Loss: 0.0370\n",
      "Epoch [8/50], Step [437/735], Loss: 0.1011\n",
      "Epoch [8/50], Step [438/735], Loss: 0.0508\n",
      "Epoch [8/50], Step [439/735], Loss: 0.0785\n",
      "Epoch [8/50], Step [440/735], Loss: 0.0458\n",
      "Epoch [8/50], Step [441/735], Loss: 0.0771\n",
      "Epoch [8/50], Step [442/735], Loss: 0.2677\n",
      "Epoch [8/50], Step [443/735], Loss: 0.0523\n",
      "Epoch [8/50], Step [444/735], Loss: 0.2435\n",
      "Epoch [8/50], Step [445/735], Loss: 0.2753\n",
      "Epoch [8/50], Step [446/735], Loss: 0.0418\n",
      "Epoch [8/50], Step [447/735], Loss: 0.0512\n",
      "Epoch [8/50], Step [448/735], Loss: 0.0719\n",
      "Epoch [8/50], Step [449/735], Loss: 0.1929\n",
      "Epoch [8/50], Step [450/735], Loss: 0.0703\n",
      "Epoch [8/50], Step [451/735], Loss: 0.0489\n",
      "Epoch [8/50], Step [452/735], Loss: 0.1899\n",
      "Epoch [8/50], Step [453/735], Loss: 0.1197\n",
      "Epoch [8/50], Step [454/735], Loss: 0.1436\n",
      "Epoch [8/50], Step [455/735], Loss: 0.0836\n",
      "Epoch [8/50], Step [456/735], Loss: 0.0438\n",
      "Epoch [8/50], Step [457/735], Loss: 0.2210\n",
      "Epoch [8/50], Step [458/735], Loss: 0.8021\n",
      "Epoch [8/50], Step [459/735], Loss: 0.0991\n",
      "Epoch [8/50], Step [460/735], Loss: 0.1681\n",
      "Epoch [8/50], Step [461/735], Loss: 0.0742\n",
      "Epoch [8/50], Step [462/735], Loss: 0.2623\n",
      "Epoch [8/50], Step [463/735], Loss: 0.1066\n",
      "Epoch [8/50], Step [464/735], Loss: 0.1605\n",
      "Epoch [8/50], Step [465/735], Loss: 0.1569\n",
      "Epoch [8/50], Step [466/735], Loss: 0.1306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Step [467/735], Loss: 0.5648\n",
      "Epoch [8/50], Step [468/735], Loss: 0.1714\n",
      "Epoch [8/50], Step [469/735], Loss: 0.0372\n",
      "Epoch [8/50], Step [470/735], Loss: 0.0933\n",
      "Epoch [8/50], Step [471/735], Loss: 0.1471\n",
      "Epoch [8/50], Step [472/735], Loss: 0.0995\n",
      "Epoch [8/50], Step [473/735], Loss: 0.1025\n",
      "Epoch [8/50], Step [474/735], Loss: 0.0714\n",
      "Epoch [8/50], Step [475/735], Loss: 0.0684\n",
      "Epoch [8/50], Step [476/735], Loss: 0.0796\n",
      "Epoch [8/50], Step [477/735], Loss: 0.0884\n",
      "Epoch [8/50], Step [478/735], Loss: 0.1197\n",
      "Epoch [8/50], Step [479/735], Loss: 0.0453\n",
      "Epoch [8/50], Step [480/735], Loss: 0.1262\n",
      "Epoch [8/50], Step [481/735], Loss: 0.0634\n",
      "Epoch [8/50], Step [482/735], Loss: 0.0629\n",
      "Epoch [8/50], Step [483/735], Loss: 0.2685\n",
      "Epoch [8/50], Step [484/735], Loss: 0.1497\n",
      "Epoch [8/50], Step [485/735], Loss: 0.0719\n",
      "Epoch [8/50], Step [486/735], Loss: 0.0845\n",
      "Epoch [8/50], Step [487/735], Loss: 0.0215\n",
      "Epoch [8/50], Step [488/735], Loss: 0.1502\n",
      "Epoch [8/50], Step [489/735], Loss: 0.0500\n",
      "Epoch [8/50], Step [490/735], Loss: 0.1413\n",
      "Epoch [8/50], Step [491/735], Loss: 0.0897\n",
      "Epoch [8/50], Step [492/735], Loss: 0.0420\n",
      "Epoch [8/50], Step [493/735], Loss: 0.7123\n",
      "Epoch [8/50], Step [494/735], Loss: 0.0713\n",
      "Epoch [8/50], Step [495/735], Loss: 0.0352\n",
      "Epoch [8/50], Step [496/735], Loss: 0.0556\n",
      "Epoch [8/50], Step [497/735], Loss: 0.0794\n",
      "Epoch [8/50], Step [498/735], Loss: 0.0807\n",
      "Epoch [8/50], Step [499/735], Loss: 0.0360\n",
      "Epoch [8/50], Step [500/735], Loss: 0.2572\n",
      "Epoch [8/50], Step [501/735], Loss: 0.1634\n",
      "Epoch [8/50], Step [502/735], Loss: 0.2030\n",
      "Epoch [8/50], Step [503/735], Loss: 0.1452\n",
      "Epoch [8/50], Step [504/735], Loss: 0.0473\n",
      "Epoch [8/50], Step [505/735], Loss: 0.0671\n",
      "Epoch [8/50], Step [506/735], Loss: 0.1368\n",
      "Epoch [8/50], Step [507/735], Loss: 0.1587\n",
      "Epoch [8/50], Step [508/735], Loss: 0.0345\n",
      "Epoch [8/50], Step [509/735], Loss: 0.1849\n",
      "Epoch [8/50], Step [510/735], Loss: 0.0360\n",
      "Epoch [8/50], Step [511/735], Loss: 0.4096\n",
      "Epoch [8/50], Step [512/735], Loss: 0.1510\n",
      "Epoch [8/50], Step [513/735], Loss: 0.2341\n",
      "Epoch [8/50], Step [514/735], Loss: 0.2268\n",
      "Epoch [8/50], Step [515/735], Loss: 0.0716\n",
      "Epoch [8/50], Step [516/735], Loss: 0.0611\n",
      "Epoch [8/50], Step [517/735], Loss: 0.0638\n",
      "Epoch [8/50], Step [518/735], Loss: 0.1381\n",
      "Epoch [8/50], Step [519/735], Loss: 0.2809\n",
      "Epoch [8/50], Step [520/735], Loss: 0.0966\n",
      "Epoch [8/50], Step [521/735], Loss: 0.1399\n",
      "Epoch [8/50], Step [522/735], Loss: 0.0785\n",
      "Epoch [8/50], Step [523/735], Loss: 0.0668\n",
      "Epoch [8/50], Step [524/735], Loss: 0.1951\n",
      "Epoch [8/50], Step [525/735], Loss: 0.1317\n",
      "Epoch [8/50], Step [526/735], Loss: 0.0606\n",
      "Epoch [8/50], Step [527/735], Loss: 0.0363\n",
      "Epoch [8/50], Step [528/735], Loss: 0.1425\n",
      "Epoch [8/50], Step [529/735], Loss: 0.1588\n",
      "Epoch [8/50], Step [530/735], Loss: 0.0594\n",
      "Epoch [8/50], Step [531/735], Loss: 0.4660\n",
      "Epoch [8/50], Step [532/735], Loss: 0.1055\n",
      "Epoch [8/50], Step [533/735], Loss: 0.1691\n",
      "Epoch [8/50], Step [534/735], Loss: 0.0492\n",
      "Epoch [8/50], Step [535/735], Loss: 0.0566\n",
      "Epoch [8/50], Step [536/735], Loss: 0.1698\n",
      "Epoch [8/50], Step [537/735], Loss: 0.2243\n",
      "Epoch [8/50], Step [538/735], Loss: 0.2451\n",
      "Epoch [8/50], Step [539/735], Loss: 0.1254\n",
      "Epoch [8/50], Step [540/735], Loss: 0.0339\n",
      "Epoch [8/50], Step [541/735], Loss: 0.0256\n",
      "Epoch [8/50], Step [542/735], Loss: 0.0923\n",
      "Epoch [8/50], Step [543/735], Loss: 0.0805\n",
      "Epoch [8/50], Step [544/735], Loss: 0.0723\n",
      "Epoch [8/50], Step [545/735], Loss: 0.1172\n",
      "Epoch [8/50], Step [546/735], Loss: 0.0511\n",
      "Epoch [8/50], Step [547/735], Loss: 0.0900\n",
      "Epoch [8/50], Step [548/735], Loss: 0.0415\n",
      "Epoch [8/50], Step [549/735], Loss: 0.0845\n",
      "Epoch [8/50], Step [550/735], Loss: 0.1732\n",
      "Epoch [8/50], Step [551/735], Loss: 0.0384\n",
      "Epoch [8/50], Step [552/735], Loss: 0.0715\n",
      "Epoch [8/50], Step [553/735], Loss: 0.2089\n",
      "Epoch [8/50], Step [554/735], Loss: 0.0282\n",
      "Epoch [8/50], Step [555/735], Loss: 0.0523\n",
      "Epoch [8/50], Step [556/735], Loss: 0.1970\n",
      "Epoch [8/50], Step [557/735], Loss: 0.1342\n",
      "Epoch [8/50], Step [558/735], Loss: 0.1308\n",
      "Epoch [8/50], Step [559/735], Loss: 0.4513\n",
      "Epoch [8/50], Step [560/735], Loss: 0.0821\n",
      "Epoch [8/50], Step [561/735], Loss: 0.0487\n",
      "Epoch [8/50], Step [562/735], Loss: 0.2132\n",
      "Epoch [8/50], Step [563/735], Loss: 0.1123\n",
      "Epoch [8/50], Step [564/735], Loss: 0.1984\n",
      "Epoch [8/50], Step [565/735], Loss: 0.0499\n",
      "Epoch [8/50], Step [566/735], Loss: 0.1799\n",
      "Epoch [8/50], Step [567/735], Loss: 0.0688\n",
      "Epoch [8/50], Step [568/735], Loss: 0.1561\n",
      "Epoch [8/50], Step [569/735], Loss: 0.0426\n",
      "Epoch [8/50], Step [570/735], Loss: 0.1055\n",
      "Epoch [8/50], Step [571/735], Loss: 0.1433\n",
      "Epoch [8/50], Step [572/735], Loss: 0.0470\n",
      "Epoch [8/50], Step [573/735], Loss: 0.1272\n",
      "Epoch [8/50], Step [574/735], Loss: 0.1745\n",
      "Epoch [8/50], Step [575/735], Loss: 0.0852\n",
      "Epoch [8/50], Step [576/735], Loss: 0.0595\n",
      "Epoch [8/50], Step [577/735], Loss: 0.1949\n",
      "Epoch [8/50], Step [578/735], Loss: 0.0542\n",
      "Epoch [8/50], Step [579/735], Loss: 0.0438\n",
      "Epoch [8/50], Step [580/735], Loss: 0.0793\n",
      "Epoch [8/50], Step [581/735], Loss: 0.6202\n",
      "Epoch [8/50], Step [582/735], Loss: 0.0579\n",
      "Epoch [8/50], Step [583/735], Loss: 0.5795\n",
      "Epoch [8/50], Step [584/735], Loss: 0.0380\n",
      "Epoch [8/50], Step [585/735], Loss: 0.1222\n",
      "Epoch [8/50], Step [586/735], Loss: 0.0878\n",
      "Epoch [8/50], Step [587/735], Loss: 0.0710\n",
      "Epoch [8/50], Step [588/735], Loss: 0.0768\n",
      "Epoch [8/50], Step [589/735], Loss: 0.1482\n",
      "Epoch [8/50], Step [590/735], Loss: 0.0361\n",
      "Epoch [8/50], Step [591/735], Loss: 0.3391\n",
      "Epoch [8/50], Step [592/735], Loss: 0.1105\n",
      "Epoch [8/50], Step [593/735], Loss: 0.1340\n",
      "Epoch [8/50], Step [594/735], Loss: 0.2308\n",
      "Epoch [8/50], Step [595/735], Loss: 0.1176\n",
      "Epoch [8/50], Step [596/735], Loss: 0.1329\n",
      "Epoch [8/50], Step [597/735], Loss: 0.1001\n",
      "Epoch [8/50], Step [598/735], Loss: 0.1969\n",
      "Epoch [8/50], Step [599/735], Loss: 0.2319\n",
      "Epoch [8/50], Step [600/735], Loss: 0.2023\n",
      "Epoch [8/50], Step [601/735], Loss: 0.0868\n",
      "Epoch [8/50], Step [602/735], Loss: 0.1645\n",
      "Epoch [8/50], Step [603/735], Loss: 0.0359\n",
      "Epoch [8/50], Step [604/735], Loss: 0.0903\n",
      "Epoch [8/50], Step [605/735], Loss: 0.1333\n",
      "Epoch [8/50], Step [606/735], Loss: 0.0748\n",
      "Epoch [8/50], Step [607/735], Loss: 0.0613\n",
      "Epoch [8/50], Step [608/735], Loss: 0.0823\n",
      "Epoch [8/50], Step [609/735], Loss: 0.0727\n",
      "Epoch [8/50], Step [610/735], Loss: 0.0693\n",
      "Epoch [8/50], Step [611/735], Loss: 0.2223\n",
      "Epoch [8/50], Step [612/735], Loss: 0.0418\n",
      "Epoch [8/50], Step [613/735], Loss: 0.0727\n",
      "Epoch [8/50], Step [614/735], Loss: 0.2214\n",
      "Epoch [8/50], Step [615/735], Loss: 0.4225\n",
      "Epoch [8/50], Step [616/735], Loss: 0.0346\n",
      "Epoch [8/50], Step [617/735], Loss: 0.0855\n",
      "Epoch [8/50], Step [618/735], Loss: 0.1134\n",
      "Epoch [8/50], Step [619/735], Loss: 0.0352\n",
      "Epoch [8/50], Step [620/735], Loss: 0.4090\n",
      "Epoch [8/50], Step [621/735], Loss: 0.0333\n",
      "Epoch [8/50], Step [622/735], Loss: 0.1371\n",
      "Epoch [8/50], Step [623/735], Loss: 0.0480\n",
      "Epoch [8/50], Step [624/735], Loss: 0.1516\n",
      "Epoch [8/50], Step [625/735], Loss: 0.0757\n",
      "Epoch [8/50], Step [626/735], Loss: 0.0501\n",
      "Epoch [8/50], Step [627/735], Loss: 0.0745\n",
      "Epoch [8/50], Step [628/735], Loss: 0.1141\n",
      "Epoch [8/50], Step [629/735], Loss: 0.1334\n",
      "Epoch [8/50], Step [630/735], Loss: 0.0600\n",
      "Epoch [8/50], Step [631/735], Loss: 0.0916\n",
      "Epoch [8/50], Step [632/735], Loss: 0.4596\n",
      "Epoch [8/50], Step [633/735], Loss: 0.1019\n",
      "Epoch [8/50], Step [634/735], Loss: 0.0232\n",
      "Epoch [8/50], Step [635/735], Loss: 0.1225\n",
      "Epoch [8/50], Step [636/735], Loss: 0.0800\n",
      "Epoch [8/50], Step [637/735], Loss: 0.0523\n",
      "Epoch [8/50], Step [638/735], Loss: 0.1852\n",
      "Epoch [8/50], Step [639/735], Loss: 0.1513\n",
      "Epoch [8/50], Step [640/735], Loss: 0.0719\n",
      "Epoch [8/50], Step [641/735], Loss: 0.2128\n",
      "Epoch [8/50], Step [642/735], Loss: 0.1489\n",
      "Epoch [8/50], Step [643/735], Loss: 0.1380\n",
      "Epoch [8/50], Step [644/735], Loss: 0.1698\n",
      "Epoch [8/50], Step [645/735], Loss: 0.0653\n",
      "Epoch [8/50], Step [646/735], Loss: 0.1115\n",
      "Epoch [8/50], Step [647/735], Loss: 0.0618\n",
      "Epoch [8/50], Step [648/735], Loss: 0.0867\n",
      "Epoch [8/50], Step [649/735], Loss: 0.0531\n",
      "Epoch [8/50], Step [650/735], Loss: 0.0759\n",
      "Epoch [8/50], Step [651/735], Loss: 0.2126\n",
      "Epoch [8/50], Step [652/735], Loss: 0.1484\n",
      "Epoch [8/50], Step [653/735], Loss: 0.1229\n",
      "Epoch [8/50], Step [654/735], Loss: 0.2221\n",
      "Epoch [8/50], Step [655/735], Loss: 0.2398\n",
      "Epoch [8/50], Step [656/735], Loss: 0.0556\n",
      "Epoch [8/50], Step [657/735], Loss: 0.0277\n",
      "Epoch [8/50], Step [658/735], Loss: 0.1425\n",
      "Epoch [8/50], Step [659/735], Loss: 0.0645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Step [660/735], Loss: 0.1422\n",
      "Epoch [8/50], Step [661/735], Loss: 0.0574\n",
      "Epoch [8/50], Step [662/735], Loss: 0.1099\n",
      "Epoch [8/50], Step [663/735], Loss: 0.0985\n",
      "Epoch [8/50], Step [664/735], Loss: 0.1163\n",
      "Epoch [8/50], Step [665/735], Loss: 0.1398\n",
      "Epoch [8/50], Step [666/735], Loss: 0.1077\n",
      "Epoch [8/50], Step [667/735], Loss: 0.2171\n",
      "Epoch [8/50], Step [668/735], Loss: 0.0421\n",
      "Epoch [8/50], Step [669/735], Loss: 0.0857\n",
      "Epoch [8/50], Step [670/735], Loss: 0.2628\n",
      "Epoch [8/50], Step [671/735], Loss: 0.1754\n",
      "Epoch [8/50], Step [672/735], Loss: 0.0668\n",
      "Epoch [8/50], Step [673/735], Loss: 0.1609\n",
      "Epoch [8/50], Step [674/735], Loss: 0.0548\n",
      "Epoch [8/50], Step [675/735], Loss: 0.1101\n",
      "Epoch [8/50], Step [676/735], Loss: 0.1276\n",
      "Epoch [8/50], Step [677/735], Loss: 0.2010\n",
      "Epoch [8/50], Step [678/735], Loss: 0.1191\n",
      "Epoch [8/50], Step [679/735], Loss: 0.0656\n",
      "Epoch [8/50], Step [680/735], Loss: 0.0846\n",
      "Epoch [8/50], Step [681/735], Loss: 0.0750\n",
      "Epoch [8/50], Step [682/735], Loss: 0.0261\n",
      "Epoch [8/50], Step [683/735], Loss: 0.0555\n",
      "Epoch [8/50], Step [684/735], Loss: 0.0675\n",
      "Epoch [8/50], Step [685/735], Loss: 0.1812\n",
      "Epoch [8/50], Step [686/735], Loss: 0.0382\n",
      "Epoch [8/50], Step [687/735], Loss: 0.0847\n",
      "Epoch [8/50], Step [688/735], Loss: 0.0394\n",
      "Epoch [8/50], Step [689/735], Loss: 0.2109\n",
      "Epoch [8/50], Step [690/735], Loss: 0.0822\n",
      "Epoch [8/50], Step [691/735], Loss: 0.1664\n",
      "Epoch [8/50], Step [692/735], Loss: 0.0676\n",
      "Epoch [8/50], Step [693/735], Loss: 0.0722\n",
      "Epoch [8/50], Step [694/735], Loss: 0.0306\n",
      "Epoch [8/50], Step [695/735], Loss: 0.0710\n",
      "Epoch [8/50], Step [696/735], Loss: 0.1092\n",
      "Epoch [8/50], Step [697/735], Loss: 0.1146\n",
      "Epoch [8/50], Step [698/735], Loss: 0.1473\n",
      "Epoch [8/50], Step [699/735], Loss: 0.1367\n",
      "Epoch [8/50], Step [700/735], Loss: 0.1872\n",
      "Epoch [8/50], Step [701/735], Loss: 0.0985\n",
      "Epoch [8/50], Step [702/735], Loss: 0.0669\n",
      "Epoch [8/50], Step [703/735], Loss: 0.1955\n",
      "Epoch [8/50], Step [704/735], Loss: 0.0467\n",
      "Epoch [8/50], Step [705/735], Loss: 0.1637\n",
      "Epoch [8/50], Step [706/735], Loss: 0.0696\n",
      "Epoch [8/50], Step [707/735], Loss: 0.0645\n",
      "Epoch [8/50], Step [708/735], Loss: 0.1862\n",
      "Epoch [8/50], Step [709/735], Loss: 0.0764\n",
      "Epoch [8/50], Step [710/735], Loss: 0.1985\n",
      "Epoch [8/50], Step [711/735], Loss: 0.3018\n",
      "Epoch [8/50], Step [712/735], Loss: 0.0390\n",
      "Epoch [8/50], Step [713/735], Loss: 0.0569\n",
      "Epoch [8/50], Step [714/735], Loss: 0.1303\n",
      "Epoch [8/50], Step [715/735], Loss: 0.0427\n",
      "Epoch [8/50], Step [716/735], Loss: 0.1253\n",
      "Epoch [8/50], Step [717/735], Loss: 0.1142\n",
      "Epoch [8/50], Step [718/735], Loss: 0.0687\n",
      "Epoch [8/50], Step [719/735], Loss: 0.1139\n",
      "Epoch [8/50], Step [720/735], Loss: 0.0768\n",
      "Epoch [8/50], Step [721/735], Loss: 0.0712\n",
      "Epoch [8/50], Step [722/735], Loss: 0.1587\n",
      "Epoch [8/50], Step [723/735], Loss: 0.2930\n",
      "Epoch [8/50], Step [724/735], Loss: 0.0985\n",
      "Epoch [8/50], Step [725/735], Loss: 0.0252\n",
      "Epoch [8/50], Step [726/735], Loss: 0.4174\n",
      "Epoch [8/50], Step [727/735], Loss: 0.0713\n",
      "Epoch [8/50], Step [728/735], Loss: 0.0724\n",
      "Epoch [8/50], Step [729/735], Loss: 0.0754\n",
      "Epoch [8/50], Step [730/735], Loss: 0.0393\n",
      "Epoch [8/50], Step [731/735], Loss: 0.0462\n",
      "Epoch [8/50], Step [732/735], Loss: 0.1031\n",
      "Epoch [8/50], Step [733/735], Loss: 0.1353\n",
      "Epoch [8/50], Step [734/735], Loss: 0.0871\n",
      "Epoch [8/50], Step [735/735], Loss: 0.0545\n",
      "Epoch [9/50], Step [1/735], Loss: 0.0536\n",
      "Epoch [9/50], Step [2/735], Loss: 0.1613\n",
      "Epoch [9/50], Step [3/735], Loss: 0.0336\n",
      "Epoch [9/50], Step [4/735], Loss: 0.0334\n",
      "Epoch [9/50], Step [5/735], Loss: 0.1765\n",
      "Epoch [9/50], Step [6/735], Loss: 0.1569\n",
      "Epoch [9/50], Step [7/735], Loss: 0.1693\n",
      "Epoch [9/50], Step [8/735], Loss: 0.1980\n",
      "Epoch [9/50], Step [9/735], Loss: 0.1001\n",
      "Epoch [9/50], Step [10/735], Loss: 0.0732\n",
      "Epoch [9/50], Step [11/735], Loss: 0.0248\n",
      "Epoch [9/50], Step [12/735], Loss: 0.0880\n",
      "Epoch [9/50], Step [13/735], Loss: 0.1211\n",
      "Epoch [9/50], Step [14/735], Loss: 0.0310\n",
      "Epoch [9/50], Step [15/735], Loss: 0.4040\n",
      "Epoch [9/50], Step [16/735], Loss: 0.1121\n",
      "Epoch [9/50], Step [17/735], Loss: 0.0782\n",
      "Epoch [9/50], Step [18/735], Loss: 0.1118\n",
      "Epoch [9/50], Step [19/735], Loss: 0.5539\n",
      "Epoch [9/50], Step [20/735], Loss: 0.1201\n",
      "Epoch [9/50], Step [21/735], Loss: 0.0633\n",
      "Epoch [9/50], Step [22/735], Loss: 0.0649\n",
      "Epoch [9/50], Step [23/735], Loss: 0.1124\n",
      "Epoch [9/50], Step [24/735], Loss: 0.1733\n",
      "Epoch [9/50], Step [25/735], Loss: 0.0389\n",
      "Epoch [9/50], Step [26/735], Loss: 0.0423\n",
      "Epoch [9/50], Step [27/735], Loss: 0.1263\n",
      "Epoch [9/50], Step [28/735], Loss: 0.2647\n",
      "Epoch [9/50], Step [29/735], Loss: 0.1641\n",
      "Epoch [9/50], Step [30/735], Loss: 0.0501\n",
      "Epoch [9/50], Step [31/735], Loss: 0.3527\n",
      "Epoch [9/50], Step [32/735], Loss: 0.1514\n",
      "Epoch [9/50], Step [33/735], Loss: 0.2617\n",
      "Epoch [9/50], Step [34/735], Loss: 0.1203\n",
      "Epoch [9/50], Step [35/735], Loss: 0.2877\n",
      "Epoch [9/50], Step [36/735], Loss: 0.2119\n",
      "Epoch [9/50], Step [37/735], Loss: 0.0850\n",
      "Epoch [9/50], Step [38/735], Loss: 0.0803\n",
      "Epoch [9/50], Step [39/735], Loss: 0.0922\n",
      "Epoch [9/50], Step [40/735], Loss: 0.3500\n",
      "Epoch [9/50], Step [41/735], Loss: 0.3101\n",
      "Epoch [9/50], Step [42/735], Loss: 0.0771\n",
      "Epoch [9/50], Step [43/735], Loss: 0.1541\n",
      "Epoch [9/50], Step [44/735], Loss: 0.1223\n",
      "Epoch [9/50], Step [45/735], Loss: 0.2110\n",
      "Epoch [9/50], Step [46/735], Loss: 0.1423\n",
      "Epoch [9/50], Step [47/735], Loss: 0.0611\n",
      "Epoch [9/50], Step [48/735], Loss: 0.0511\n",
      "Epoch [9/50], Step [49/735], Loss: 0.0700\n",
      "Epoch [9/50], Step [50/735], Loss: 0.0770\n",
      "Epoch [9/50], Step [51/735], Loss: 0.2311\n",
      "Epoch [9/50], Step [52/735], Loss: 0.0843\n",
      "Epoch [9/50], Step [53/735], Loss: 0.4666\n",
      "Epoch [9/50], Step [54/735], Loss: 0.0606\n",
      "Epoch [9/50], Step [55/735], Loss: 0.1062\n",
      "Epoch [9/50], Step [56/735], Loss: 0.1372\n",
      "Epoch [9/50], Step [57/735], Loss: 0.1219\n",
      "Epoch [9/50], Step [58/735], Loss: 0.0956\n",
      "Epoch [9/50], Step [59/735], Loss: 0.0452\n",
      "Epoch [9/50], Step [60/735], Loss: 0.0363\n",
      "Epoch [9/50], Step [61/735], Loss: 0.0530\n",
      "Epoch [9/50], Step [62/735], Loss: 0.0452\n",
      "Epoch [9/50], Step [63/735], Loss: 0.3863\n",
      "Epoch [9/50], Step [64/735], Loss: 0.1580\n",
      "Epoch [9/50], Step [65/735], Loss: 0.0843\n",
      "Epoch [9/50], Step [66/735], Loss: 0.1019\n",
      "Epoch [9/50], Step [67/735], Loss: 0.1140\n",
      "Epoch [9/50], Step [68/735], Loss: 0.0350\n",
      "Epoch [9/50], Step [69/735], Loss: 0.0725\n",
      "Epoch [9/50], Step [70/735], Loss: 0.0790\n",
      "Epoch [9/50], Step [71/735], Loss: 0.0724\n",
      "Epoch [9/50], Step [72/735], Loss: 0.0965\n",
      "Epoch [9/50], Step [73/735], Loss: 0.0300\n",
      "Epoch [9/50], Step [74/735], Loss: 0.0246\n",
      "Epoch [9/50], Step [75/735], Loss: 0.0501\n",
      "Epoch [9/50], Step [76/735], Loss: 0.0510\n",
      "Epoch [9/50], Step [77/735], Loss: 0.1270\n",
      "Epoch [9/50], Step [78/735], Loss: 0.1385\n",
      "Epoch [9/50], Step [79/735], Loss: 0.0323\n",
      "Epoch [9/50], Step [80/735], Loss: 0.0477\n",
      "Epoch [9/50], Step [81/735], Loss: 0.0356\n",
      "Epoch [9/50], Step [82/735], Loss: 0.0324\n",
      "Epoch [9/50], Step [83/735], Loss: 0.0873\n",
      "Epoch [9/50], Step [84/735], Loss: 0.0385\n",
      "Epoch [9/50], Step [85/735], Loss: 0.0401\n",
      "Epoch [9/50], Step [86/735], Loss: 0.2214\n",
      "Epoch [9/50], Step [87/735], Loss: 0.0461\n",
      "Epoch [9/50], Step [88/735], Loss: 0.0613\n",
      "Epoch [9/50], Step [89/735], Loss: 0.0250\n",
      "Epoch [9/50], Step [90/735], Loss: 0.0584\n",
      "Epoch [9/50], Step [91/735], Loss: 0.1484\n",
      "Epoch [9/50], Step [92/735], Loss: 0.0357\n",
      "Epoch [9/50], Step [93/735], Loss: 0.3043\n",
      "Epoch [9/50], Step [94/735], Loss: 0.0964\n",
      "Epoch [9/50], Step [95/735], Loss: 0.2921\n",
      "Epoch [9/50], Step [96/735], Loss: 0.0407\n",
      "Epoch [9/50], Step [97/735], Loss: 0.0386\n",
      "Epoch [9/50], Step [98/735], Loss: 0.0645\n",
      "Epoch [9/50], Step [99/735], Loss: 0.0576\n",
      "Epoch [9/50], Step [100/735], Loss: 0.1537\n",
      "Epoch [9/50], Step [101/735], Loss: 0.0367\n",
      "Epoch [9/50], Step [102/735], Loss: 0.0835\n",
      "Epoch [9/50], Step [103/735], Loss: 0.2198\n",
      "Epoch [9/50], Step [104/735], Loss: 0.0408\n",
      "Epoch [9/50], Step [105/735], Loss: 0.0395\n",
      "Epoch [9/50], Step [106/735], Loss: 0.1316\n",
      "Epoch [9/50], Step [107/735], Loss: 0.1990\n",
      "Epoch [9/50], Step [108/735], Loss: 0.1876\n",
      "Epoch [9/50], Step [109/735], Loss: 0.0439\n",
      "Epoch [9/50], Step [110/735], Loss: 0.1565\n",
      "Epoch [9/50], Step [111/735], Loss: 0.0332\n",
      "Epoch [9/50], Step [112/735], Loss: 0.0766\n",
      "Epoch [9/50], Step [113/735], Loss: 0.1029\n",
      "Epoch [9/50], Step [114/735], Loss: 0.1689\n",
      "Epoch [9/50], Step [115/735], Loss: 0.0314\n",
      "Epoch [9/50], Step [116/735], Loss: 0.0536\n",
      "Epoch [9/50], Step [117/735], Loss: 0.0736\n",
      "Epoch [9/50], Step [118/735], Loss: 0.0954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Step [119/735], Loss: 0.0499\n",
      "Epoch [9/50], Step [120/735], Loss: 0.1180\n",
      "Epoch [9/50], Step [121/735], Loss: 0.1538\n",
      "Epoch [9/50], Step [122/735], Loss: 0.0660\n",
      "Epoch [9/50], Step [123/735], Loss: 0.0397\n",
      "Epoch [9/50], Step [124/735], Loss: 0.1786\n",
      "Epoch [9/50], Step [125/735], Loss: 0.3986\n",
      "Epoch [9/50], Step [126/735], Loss: 0.0928\n",
      "Epoch [9/50], Step [127/735], Loss: 0.0488\n",
      "Epoch [9/50], Step [128/735], Loss: 0.0687\n",
      "Epoch [9/50], Step [129/735], Loss: 0.0573\n",
      "Epoch [9/50], Step [130/735], Loss: 0.1491\n",
      "Epoch [9/50], Step [131/735], Loss: 0.0493\n",
      "Epoch [9/50], Step [132/735], Loss: 0.1670\n",
      "Epoch [9/50], Step [133/735], Loss: 0.3184\n",
      "Epoch [9/50], Step [134/735], Loss: 0.5973\n",
      "Epoch [9/50], Step [135/735], Loss: 0.1058\n",
      "Epoch [9/50], Step [136/735], Loss: 0.1801\n",
      "Epoch [9/50], Step [137/735], Loss: 0.0723\n",
      "Epoch [9/50], Step [138/735], Loss: 0.1746\n",
      "Epoch [9/50], Step [139/735], Loss: 0.0685\n",
      "Epoch [9/50], Step [140/735], Loss: 0.1155\n",
      "Epoch [9/50], Step [141/735], Loss: 0.1438\n",
      "Epoch [9/50], Step [142/735], Loss: 0.0554\n",
      "Epoch [9/50], Step [143/735], Loss: 0.0198\n",
      "Epoch [9/50], Step [144/735], Loss: 0.0993\n",
      "Epoch [9/50], Step [145/735], Loss: 0.0776\n",
      "Epoch [9/50], Step [146/735], Loss: 0.0761\n",
      "Epoch [9/50], Step [147/735], Loss: 0.1403\n",
      "Epoch [9/50], Step [148/735], Loss: 0.0442\n",
      "Epoch [9/50], Step [149/735], Loss: 0.2200\n",
      "Epoch [9/50], Step [150/735], Loss: 0.0397\n",
      "Epoch [9/50], Step [151/735], Loss: 0.0813\n",
      "Epoch [9/50], Step [152/735], Loss: 0.0553\n",
      "Epoch [9/50], Step [153/735], Loss: 0.1837\n",
      "Epoch [9/50], Step [154/735], Loss: 0.0506\n",
      "Epoch [9/50], Step [155/735], Loss: 0.1265\n",
      "Epoch [9/50], Step [156/735], Loss: 0.0711\n",
      "Epoch [9/50], Step [157/735], Loss: 0.0583\n",
      "Epoch [9/50], Step [158/735], Loss: 0.1893\n",
      "Epoch [9/50], Step [159/735], Loss: 0.0975\n",
      "Epoch [9/50], Step [160/735], Loss: 0.0670\n",
      "Epoch [9/50], Step [161/735], Loss: 0.0296\n",
      "Epoch [9/50], Step [162/735], Loss: 0.1594\n",
      "Epoch [9/50], Step [163/735], Loss: 0.0198\n",
      "Epoch [9/50], Step [164/735], Loss: 0.0836\n",
      "Epoch [9/50], Step [165/735], Loss: 0.1906\n",
      "Epoch [9/50], Step [166/735], Loss: 0.0728\n",
      "Epoch [9/50], Step [167/735], Loss: 0.0868\n",
      "Epoch [9/50], Step [168/735], Loss: 0.0605\n",
      "Epoch [9/50], Step [169/735], Loss: 0.0626\n",
      "Epoch [9/50], Step [170/735], Loss: 0.0795\n",
      "Epoch [9/50], Step [171/735], Loss: 0.3521\n",
      "Epoch [9/50], Step [172/735], Loss: 0.1624\n",
      "Epoch [9/50], Step [173/735], Loss: 0.1317\n",
      "Epoch [9/50], Step [174/735], Loss: 0.3742\n",
      "Epoch [9/50], Step [175/735], Loss: 0.0643\n",
      "Epoch [9/50], Step [176/735], Loss: 0.0575\n",
      "Epoch [9/50], Step [177/735], Loss: 0.0409\n",
      "Epoch [9/50], Step [178/735], Loss: 0.0714\n",
      "Epoch [9/50], Step [179/735], Loss: 0.2240\n",
      "Epoch [9/50], Step [180/735], Loss: 0.1263\n",
      "Epoch [9/50], Step [181/735], Loss: 0.1879\n",
      "Epoch [9/50], Step [182/735], Loss: 0.0468\n",
      "Epoch [9/50], Step [183/735], Loss: 0.0396\n",
      "Epoch [9/50], Step [184/735], Loss: 0.1153\n",
      "Epoch [9/50], Step [185/735], Loss: 0.0431\n",
      "Epoch [9/50], Step [186/735], Loss: 0.1149\n",
      "Epoch [9/50], Step [187/735], Loss: 0.0866\n",
      "Epoch [9/50], Step [188/735], Loss: 0.1386\n",
      "Epoch [9/50], Step [189/735], Loss: 0.0322\n",
      "Epoch [9/50], Step [190/735], Loss: 0.1106\n",
      "Epoch [9/50], Step [191/735], Loss: 0.0456\n",
      "Epoch [9/50], Step [192/735], Loss: 0.0536\n",
      "Epoch [9/50], Step [193/735], Loss: 0.1209\n",
      "Epoch [9/50], Step [194/735], Loss: 0.0684\n",
      "Epoch [9/50], Step [195/735], Loss: 0.1917\n",
      "Epoch [9/50], Step [196/735], Loss: 0.1558\n",
      "Epoch [9/50], Step [197/735], Loss: 0.0453\n",
      "Epoch [9/50], Step [198/735], Loss: 0.0506\n",
      "Epoch [9/50], Step [199/735], Loss: 0.0534\n",
      "Epoch [9/50], Step [200/735], Loss: 0.0825\n",
      "Epoch [9/50], Step [201/735], Loss: 0.2133\n",
      "Epoch [9/50], Step [202/735], Loss: 0.1649\n",
      "Epoch [9/50], Step [203/735], Loss: 0.1638\n",
      "Epoch [9/50], Step [204/735], Loss: 0.0952\n",
      "Epoch [9/50], Step [205/735], Loss: 0.1666\n",
      "Epoch [9/50], Step [206/735], Loss: 0.1452\n",
      "Epoch [9/50], Step [207/735], Loss: 0.0988\n",
      "Epoch [9/50], Step [208/735], Loss: 0.0916\n",
      "Epoch [9/50], Step [209/735], Loss: 0.1424\n",
      "Epoch [9/50], Step [210/735], Loss: 0.0510\n",
      "Epoch [9/50], Step [211/735], Loss: 0.2650\n",
      "Epoch [9/50], Step [212/735], Loss: 0.0655\n",
      "Epoch [9/50], Step [213/735], Loss: 0.0467\n",
      "Epoch [9/50], Step [214/735], Loss: 0.0568\n",
      "Epoch [9/50], Step [215/735], Loss: 0.0905\n",
      "Epoch [9/50], Step [216/735], Loss: 0.0753\n",
      "Epoch [9/50], Step [217/735], Loss: 0.1595\n",
      "Epoch [9/50], Step [218/735], Loss: 0.0388\n",
      "Epoch [9/50], Step [219/735], Loss: 0.0510\n",
      "Epoch [9/50], Step [220/735], Loss: 0.1800\n",
      "Epoch [9/50], Step [221/735], Loss: 0.0622\n",
      "Epoch [9/50], Step [222/735], Loss: 0.0838\n",
      "Epoch [9/50], Step [223/735], Loss: 0.2289\n",
      "Epoch [9/50], Step [224/735], Loss: 0.0290\n",
      "Epoch [9/50], Step [225/735], Loss: 0.1397\n",
      "Epoch [9/50], Step [226/735], Loss: 0.0736\n",
      "Epoch [9/50], Step [227/735], Loss: 0.1682\n",
      "Epoch [9/50], Step [228/735], Loss: 0.0461\n",
      "Epoch [9/50], Step [229/735], Loss: 0.0485\n",
      "Epoch [9/50], Step [230/735], Loss: 0.0912\n",
      "Epoch [9/50], Step [231/735], Loss: 0.4014\n",
      "Epoch [9/50], Step [232/735], Loss: 0.0709\n",
      "Epoch [9/50], Step [233/735], Loss: 0.0970\n",
      "Epoch [9/50], Step [234/735], Loss: 0.0518\n",
      "Epoch [9/50], Step [235/735], Loss: 0.0340\n",
      "Epoch [9/50], Step [236/735], Loss: 0.2944\n",
      "Epoch [9/50], Step [237/735], Loss: 0.0564\n",
      "Epoch [9/50], Step [238/735], Loss: 0.2746\n",
      "Epoch [9/50], Step [239/735], Loss: 0.0527\n",
      "Epoch [9/50], Step [240/735], Loss: 0.1856\n",
      "Epoch [9/50], Step [241/735], Loss: 0.0507\n",
      "Epoch [9/50], Step [242/735], Loss: 0.1142\n",
      "Epoch [9/50], Step [243/735], Loss: 0.1848\n",
      "Epoch [9/50], Step [244/735], Loss: 0.1264\n",
      "Epoch [9/50], Step [245/735], Loss: 0.0637\n",
      "Epoch [9/50], Step [246/735], Loss: 0.0555\n",
      "Epoch [9/50], Step [247/735], Loss: 0.0586\n",
      "Epoch [9/50], Step [248/735], Loss: 0.2377\n",
      "Epoch [9/50], Step [249/735], Loss: 0.0369\n",
      "Epoch [9/50], Step [250/735], Loss: 0.0503\n",
      "Epoch [9/50], Step [251/735], Loss: 0.0889\n",
      "Epoch [9/50], Step [252/735], Loss: 0.3961\n",
      "Epoch [9/50], Step [253/735], Loss: 0.0587\n",
      "Epoch [9/50], Step [254/735], Loss: 0.2365\n",
      "Epoch [9/50], Step [255/735], Loss: 0.1628\n",
      "Epoch [9/50], Step [256/735], Loss: 0.2249\n",
      "Epoch [9/50], Step [257/735], Loss: 0.1120\n",
      "Epoch [9/50], Step [258/735], Loss: 0.1315\n",
      "Epoch [9/50], Step [259/735], Loss: 0.0760\n",
      "Epoch [9/50], Step [260/735], Loss: 0.1986\n",
      "Epoch [9/50], Step [261/735], Loss: 0.0683\n",
      "Epoch [9/50], Step [262/735], Loss: 0.0559\n",
      "Epoch [9/50], Step [263/735], Loss: 0.0488\n",
      "Epoch [9/50], Step [264/735], Loss: 0.1172\n",
      "Epoch [9/50], Step [265/735], Loss: 0.0390\n",
      "Epoch [9/50], Step [266/735], Loss: 0.4018\n",
      "Epoch [9/50], Step [267/735], Loss: 0.1447\n",
      "Epoch [9/50], Step [268/735], Loss: 0.0855\n",
      "Epoch [9/50], Step [269/735], Loss: 0.3448\n",
      "Epoch [9/50], Step [270/735], Loss: 0.1194\n",
      "Epoch [9/50], Step [271/735], Loss: 0.0531\n",
      "Epoch [9/50], Step [272/735], Loss: 0.0521\n",
      "Epoch [9/50], Step [273/735], Loss: 0.0351\n",
      "Epoch [9/50], Step [274/735], Loss: 0.0644\n",
      "Epoch [9/50], Step [275/735], Loss: 0.0953\n",
      "Epoch [9/50], Step [276/735], Loss: 0.1340\n",
      "Epoch [9/50], Step [277/735], Loss: 0.1586\n",
      "Epoch [9/50], Step [278/735], Loss: 0.0855\n",
      "Epoch [9/50], Step [279/735], Loss: 0.1494\n",
      "Epoch [9/50], Step [280/735], Loss: 0.2311\n",
      "Epoch [9/50], Step [281/735], Loss: 0.2646\n",
      "Epoch [9/50], Step [282/735], Loss: 0.1774\n",
      "Epoch [9/50], Step [283/735], Loss: 0.1595\n",
      "Epoch [9/50], Step [284/735], Loss: 0.0522\n",
      "Epoch [9/50], Step [285/735], Loss: 0.0845\n",
      "Epoch [9/50], Step [286/735], Loss: 0.1773\n",
      "Epoch [9/50], Step [287/735], Loss: 0.0924\n",
      "Epoch [9/50], Step [288/735], Loss: 0.0526\n",
      "Epoch [9/50], Step [289/735], Loss: 0.1863\n",
      "Epoch [9/50], Step [290/735], Loss: 0.0417\n",
      "Epoch [9/50], Step [291/735], Loss: 0.2300\n",
      "Epoch [9/50], Step [292/735], Loss: 0.0289\n",
      "Epoch [9/50], Step [293/735], Loss: 0.1348\n",
      "Epoch [9/50], Step [294/735], Loss: 0.0690\n",
      "Epoch [9/50], Step [295/735], Loss: 0.1471\n",
      "Epoch [9/50], Step [296/735], Loss: 0.0413\n",
      "Epoch [9/50], Step [297/735], Loss: 0.1281\n",
      "Epoch [9/50], Step [298/735], Loss: 0.0616\n",
      "Epoch [9/50], Step [299/735], Loss: 0.0546\n",
      "Epoch [9/50], Step [300/735], Loss: 0.0464\n",
      "Epoch [9/50], Step [301/735], Loss: 0.0262\n",
      "Epoch [9/50], Step [302/735], Loss: 0.1032\n",
      "Epoch [9/50], Step [303/735], Loss: 0.1671\n",
      "Epoch [9/50], Step [304/735], Loss: 0.0693\n",
      "Epoch [9/50], Step [305/735], Loss: 0.1528\n",
      "Epoch [9/50], Step [306/735], Loss: 0.1126\n",
      "Epoch [9/50], Step [307/735], Loss: 0.0330\n",
      "Epoch [9/50], Step [308/735], Loss: 0.0448\n",
      "Epoch [9/50], Step [309/735], Loss: 0.1553\n",
      "Epoch [9/50], Step [310/735], Loss: 0.0510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Step [311/735], Loss: 0.2201\n",
      "Epoch [9/50], Step [312/735], Loss: 0.1028\n",
      "Epoch [9/50], Step [313/735], Loss: 0.0691\n",
      "Epoch [9/50], Step [314/735], Loss: 0.0802\n",
      "Epoch [9/50], Step [315/735], Loss: 0.0416\n",
      "Epoch [9/50], Step [316/735], Loss: 0.0757\n",
      "Epoch [9/50], Step [317/735], Loss: 0.7368\n",
      "Epoch [9/50], Step [318/735], Loss: 0.0407\n",
      "Epoch [9/50], Step [319/735], Loss: 0.0540\n",
      "Epoch [9/50], Step [320/735], Loss: 0.1225\n",
      "Epoch [9/50], Step [321/735], Loss: 0.0504\n",
      "Epoch [9/50], Step [322/735], Loss: 0.0579\n",
      "Epoch [9/50], Step [323/735], Loss: 0.0553\n",
      "Epoch [9/50], Step [324/735], Loss: 0.1226\n",
      "Epoch [9/50], Step [325/735], Loss: 0.1810\n",
      "Epoch [9/50], Step [326/735], Loss: 0.1920\n",
      "Epoch [9/50], Step [327/735], Loss: 0.0840\n",
      "Epoch [9/50], Step [328/735], Loss: 0.0573\n",
      "Epoch [9/50], Step [329/735], Loss: 0.1910\n",
      "Epoch [9/50], Step [330/735], Loss: 0.1645\n",
      "Epoch [9/50], Step [331/735], Loss: 0.1251\n",
      "Epoch [9/50], Step [332/735], Loss: 0.0550\n",
      "Epoch [9/50], Step [333/735], Loss: 0.1217\n",
      "Epoch [9/50], Step [334/735], Loss: 0.0606\n",
      "Epoch [9/50], Step [335/735], Loss: 0.0791\n",
      "Epoch [9/50], Step [336/735], Loss: 0.1677\n",
      "Epoch [9/50], Step [337/735], Loss: 0.0707\n",
      "Epoch [9/50], Step [338/735], Loss: 0.1649\n",
      "Epoch [9/50], Step [339/735], Loss: 0.0458\n",
      "Epoch [9/50], Step [340/735], Loss: 0.0696\n",
      "Epoch [9/50], Step [341/735], Loss: 0.0359\n",
      "Epoch [9/50], Step [342/735], Loss: 0.0500\n",
      "Epoch [9/50], Step [343/735], Loss: 0.0875\n",
      "Epoch [9/50], Step [344/735], Loss: 0.0823\n",
      "Epoch [9/50], Step [345/735], Loss: 0.0788\n",
      "Epoch [9/50], Step [346/735], Loss: 0.1390\n",
      "Epoch [9/50], Step [347/735], Loss: 0.1314\n",
      "Epoch [9/50], Step [348/735], Loss: 0.1123\n",
      "Epoch [9/50], Step [349/735], Loss: 0.1409\n",
      "Epoch [9/50], Step [350/735], Loss: 0.1221\n",
      "Epoch [9/50], Step [351/735], Loss: 0.1226\n",
      "Epoch [9/50], Step [352/735], Loss: 0.0520\n",
      "Epoch [9/50], Step [353/735], Loss: 0.0834\n",
      "Epoch [9/50], Step [354/735], Loss: 0.1064\n",
      "Epoch [9/50], Step [355/735], Loss: 0.0769\n",
      "Epoch [9/50], Step [356/735], Loss: 0.0693\n",
      "Epoch [9/50], Step [357/735], Loss: 0.1223\n",
      "Epoch [9/50], Step [358/735], Loss: 0.0488\n",
      "Epoch [9/50], Step [359/735], Loss: 0.1100\n",
      "Epoch [9/50], Step [360/735], Loss: 0.0282\n",
      "Epoch [9/50], Step [361/735], Loss: 0.0726\n",
      "Epoch [9/50], Step [362/735], Loss: 0.0850\n",
      "Epoch [9/50], Step [363/735], Loss: 0.0631\n",
      "Epoch [9/50], Step [364/735], Loss: 0.0594\n",
      "Epoch [9/50], Step [365/735], Loss: 0.1253\n",
      "Epoch [9/50], Step [366/735], Loss: 0.1708\n",
      "Epoch [9/50], Step [367/735], Loss: 0.0877\n",
      "Epoch [9/50], Step [368/735], Loss: 0.0229\n",
      "Epoch [9/50], Step [369/735], Loss: 0.1019\n",
      "Epoch [9/50], Step [370/735], Loss: 0.0382\n",
      "Epoch [9/50], Step [371/735], Loss: 0.0241\n",
      "Epoch [9/50], Step [372/735], Loss: 0.0424\n",
      "Epoch [9/50], Step [373/735], Loss: 0.0465\n",
      "Epoch [9/50], Step [374/735], Loss: 0.0215\n",
      "Epoch [9/50], Step [375/735], Loss: 0.0596\n",
      "Epoch [9/50], Step [376/735], Loss: 0.0870\n",
      "Epoch [9/50], Step [377/735], Loss: 0.2009\n",
      "Epoch [9/50], Step [378/735], Loss: 0.0980\n",
      "Epoch [9/50], Step [379/735], Loss: 0.0415\n",
      "Epoch [9/50], Step [380/735], Loss: 0.0603\n",
      "Epoch [9/50], Step [381/735], Loss: 0.0546\n",
      "Epoch [9/50], Step [382/735], Loss: 0.0728\n",
      "Epoch [9/50], Step [383/735], Loss: 0.0944\n",
      "Epoch [9/50], Step [384/735], Loss: 0.5595\n",
      "Epoch [9/50], Step [385/735], Loss: 0.0679\n",
      "Epoch [9/50], Step [386/735], Loss: 0.0628\n",
      "Epoch [9/50], Step [387/735], Loss: 0.0814\n",
      "Epoch [9/50], Step [388/735], Loss: 0.0352\n",
      "Epoch [9/50], Step [389/735], Loss: 0.1642\n",
      "Epoch [9/50], Step [390/735], Loss: 0.1982\n",
      "Epoch [9/50], Step [391/735], Loss: 0.0814\n",
      "Epoch [9/50], Step [392/735], Loss: 0.0601\n",
      "Epoch [9/50], Step [393/735], Loss: 0.0651\n",
      "Epoch [9/50], Step [394/735], Loss: 0.0839\n",
      "Epoch [9/50], Step [395/735], Loss: 0.3522\n",
      "Epoch [9/50], Step [396/735], Loss: 0.1056\n",
      "Epoch [9/50], Step [397/735], Loss: 0.0284\n",
      "Epoch [9/50], Step [398/735], Loss: 0.0839\n",
      "Epoch [9/50], Step [399/735], Loss: 0.0608\n",
      "Epoch [9/50], Step [400/735], Loss: 0.2425\n",
      "Epoch [9/50], Step [401/735], Loss: 0.1876\n",
      "Epoch [9/50], Step [402/735], Loss: 0.1045\n",
      "Epoch [9/50], Step [403/735], Loss: 0.2227\n",
      "Epoch [9/50], Step [404/735], Loss: 0.3469\n",
      "Epoch [9/50], Step [405/735], Loss: 0.2059\n",
      "Epoch [9/50], Step [406/735], Loss: 0.1019\n",
      "Epoch [9/50], Step [407/735], Loss: 0.0793\n",
      "Epoch [9/50], Step [408/735], Loss: 0.0351\n",
      "Epoch [9/50], Step [409/735], Loss: 0.0514\n",
      "Epoch [9/50], Step [410/735], Loss: 0.1172\n",
      "Epoch [9/50], Step [411/735], Loss: 0.1212\n",
      "Epoch [9/50], Step [412/735], Loss: 0.1863\n",
      "Epoch [9/50], Step [413/735], Loss: 0.2471\n",
      "Epoch [9/50], Step [414/735], Loss: 0.2077\n",
      "Epoch [9/50], Step [415/735], Loss: 0.0587\n",
      "Epoch [9/50], Step [416/735], Loss: 0.3428\n",
      "Epoch [9/50], Step [417/735], Loss: 0.1156\n",
      "Epoch [9/50], Step [418/735], Loss: 0.2114\n",
      "Epoch [9/50], Step [419/735], Loss: 0.1011\n",
      "Epoch [9/50], Step [420/735], Loss: 0.1272\n",
      "Epoch [9/50], Step [421/735], Loss: 0.1230\n",
      "Epoch [9/50], Step [422/735], Loss: 0.1024\n",
      "Epoch [9/50], Step [423/735], Loss: 0.0290\n",
      "Epoch [9/50], Step [424/735], Loss: 0.2190\n",
      "Epoch [9/50], Step [425/735], Loss: 0.1032\n",
      "Epoch [9/50], Step [426/735], Loss: 0.0374\n",
      "Epoch [9/50], Step [427/735], Loss: 0.2532\n",
      "Epoch [9/50], Step [428/735], Loss: 0.0633\n",
      "Epoch [9/50], Step [429/735], Loss: 0.0962\n",
      "Epoch [9/50], Step [430/735], Loss: 0.2130\n",
      "Epoch [9/50], Step [431/735], Loss: 0.3711\n",
      "Epoch [9/50], Step [432/735], Loss: 0.2222\n",
      "Epoch [9/50], Step [433/735], Loss: 0.0699\n",
      "Epoch [9/50], Step [434/735], Loss: 0.0510\n",
      "Epoch [9/50], Step [435/735], Loss: 0.0833\n",
      "Epoch [9/50], Step [436/735], Loss: 0.0590\n",
      "Epoch [9/50], Step [437/735], Loss: 0.0313\n",
      "Epoch [9/50], Step [438/735], Loss: 0.0906\n",
      "Epoch [9/50], Step [439/735], Loss: 0.3949\n",
      "Epoch [9/50], Step [440/735], Loss: 0.2121\n",
      "Epoch [9/50], Step [441/735], Loss: 0.0772\n",
      "Epoch [9/50], Step [442/735], Loss: 0.0721\n",
      "Epoch [9/50], Step [443/735], Loss: 0.1610\n",
      "Epoch [9/50], Step [444/735], Loss: 0.3028\n",
      "Epoch [9/50], Step [445/735], Loss: 0.0549\n",
      "Epoch [9/50], Step [446/735], Loss: 0.1277\n",
      "Epoch [9/50], Step [447/735], Loss: 0.0214\n",
      "Epoch [9/50], Step [448/735], Loss: 0.1388\n",
      "Epoch [9/50], Step [449/735], Loss: 0.1560\n",
      "Epoch [9/50], Step [450/735], Loss: 0.0296\n",
      "Epoch [9/50], Step [451/735], Loss: 0.0683\n",
      "Epoch [9/50], Step [452/735], Loss: 0.3567\n",
      "Epoch [9/50], Step [453/735], Loss: 0.1418\n",
      "Epoch [9/50], Step [454/735], Loss: 0.0711\n",
      "Epoch [9/50], Step [455/735], Loss: 0.3279\n",
      "Epoch [9/50], Step [456/735], Loss: 0.0875\n",
      "Epoch [9/50], Step [457/735], Loss: 0.1309\n",
      "Epoch [9/50], Step [458/735], Loss: 0.1125\n",
      "Epoch [9/50], Step [459/735], Loss: 0.0810\n",
      "Epoch [9/50], Step [460/735], Loss: 0.1820\n",
      "Epoch [9/50], Step [461/735], Loss: 0.0494\n",
      "Epoch [9/50], Step [462/735], Loss: 0.0860\n",
      "Epoch [9/50], Step [463/735], Loss: 0.0838\n",
      "Epoch [9/50], Step [464/735], Loss: 0.0296\n",
      "Epoch [9/50], Step [465/735], Loss: 0.1457\n",
      "Epoch [9/50], Step [466/735], Loss: 0.0539\n",
      "Epoch [9/50], Step [467/735], Loss: 0.0347\n",
      "Epoch [9/50], Step [468/735], Loss: 0.1782\n",
      "Epoch [9/50], Step [469/735], Loss: 0.2834\n",
      "Epoch [9/50], Step [470/735], Loss: 0.0553\n",
      "Epoch [9/50], Step [471/735], Loss: 0.0519\n",
      "Epoch [9/50], Step [472/735], Loss: 0.1137\n",
      "Epoch [9/50], Step [473/735], Loss: 0.0357\n",
      "Epoch [9/50], Step [474/735], Loss: 0.0627\n",
      "Epoch [9/50], Step [475/735], Loss: 0.1172\n",
      "Epoch [9/50], Step [476/735], Loss: 0.0978\n",
      "Epoch [9/50], Step [477/735], Loss: 0.1169\n",
      "Epoch [9/50], Step [478/735], Loss: 0.0581\n",
      "Epoch [9/50], Step [479/735], Loss: 0.0935\n",
      "Epoch [9/50], Step [480/735], Loss: 0.3925\n",
      "Epoch [9/50], Step [481/735], Loss: 0.0763\n",
      "Epoch [9/50], Step [482/735], Loss: 0.0466\n",
      "Epoch [9/50], Step [483/735], Loss: 0.1593\n",
      "Epoch [9/50], Step [484/735], Loss: 0.0820\n",
      "Epoch [9/50], Step [485/735], Loss: 0.0271\n",
      "Epoch [9/50], Step [486/735], Loss: 0.1000\n",
      "Epoch [9/50], Step [487/735], Loss: 0.1264\n",
      "Epoch [9/50], Step [488/735], Loss: 0.0553\n",
      "Epoch [9/50], Step [489/735], Loss: 0.0402\n",
      "Epoch [9/50], Step [490/735], Loss: 0.0353\n",
      "Epoch [9/50], Step [491/735], Loss: 0.0382\n",
      "Epoch [9/50], Step [492/735], Loss: 0.1576\n",
      "Epoch [9/50], Step [493/735], Loss: 0.1045\n",
      "Epoch [9/50], Step [494/735], Loss: 0.0624\n",
      "Epoch [9/50], Step [495/735], Loss: 0.1180\n",
      "Epoch [9/50], Step [496/735], Loss: 0.0793\n",
      "Epoch [9/50], Step [497/735], Loss: 0.0520\n",
      "Epoch [9/50], Step [498/735], Loss: 0.0527\n",
      "Epoch [9/50], Step [499/735], Loss: 0.2699\n",
      "Epoch [9/50], Step [500/735], Loss: 0.0983\n",
      "Epoch [9/50], Step [501/735], Loss: 0.0881\n",
      "Epoch [9/50], Step [502/735], Loss: 0.0536\n",
      "Epoch [9/50], Step [503/735], Loss: 0.1167\n",
      "Epoch [9/50], Step [504/735], Loss: 0.0754\n",
      "Epoch [9/50], Step [505/735], Loss: 0.0813\n",
      "Epoch [9/50], Step [506/735], Loss: 0.0453\n",
      "Epoch [9/50], Step [507/735], Loss: 0.1545\n",
      "Epoch [9/50], Step [508/735], Loss: 0.1263\n",
      "Epoch [9/50], Step [509/735], Loss: 0.1934\n",
      "Epoch [9/50], Step [510/735], Loss: 0.3231\n",
      "Epoch [9/50], Step [511/735], Loss: 0.0342\n",
      "Epoch [9/50], Step [512/735], Loss: 0.0395\n",
      "Epoch [9/50], Step [513/735], Loss: 0.4628\n",
      "Epoch [9/50], Step [514/735], Loss: 0.0684\n",
      "Epoch [9/50], Step [515/735], Loss: 0.0247\n",
      "Epoch [9/50], Step [516/735], Loss: 0.0511\n",
      "Epoch [9/50], Step [517/735], Loss: 0.0960\n",
      "Epoch [9/50], Step [518/735], Loss: 0.2563\n",
      "Epoch [9/50], Step [519/735], Loss: 0.0514\n",
      "Epoch [9/50], Step [520/735], Loss: 0.0275\n",
      "Epoch [9/50], Step [521/735], Loss: 0.1299\n",
      "Epoch [9/50], Step [522/735], Loss: 0.1422\n",
      "Epoch [9/50], Step [523/735], Loss: 0.0393\n",
      "Epoch [9/50], Step [524/735], Loss: 0.0896\n",
      "Epoch [9/50], Step [525/735], Loss: 0.0545\n",
      "Epoch [9/50], Step [526/735], Loss: 0.2290\n",
      "Epoch [9/50], Step [527/735], Loss: 0.5008\n",
      "Epoch [9/50], Step [528/735], Loss: 0.0359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Step [529/735], Loss: 0.0694\n",
      "Epoch [9/50], Step [530/735], Loss: 0.0553\n",
      "Epoch [9/50], Step [531/735], Loss: 0.0279\n",
      "Epoch [9/50], Step [532/735], Loss: 0.1295\n",
      "Epoch [9/50], Step [533/735], Loss: 0.1785\n",
      "Epoch [9/50], Step [534/735], Loss: 0.0221\n",
      "Epoch [9/50], Step [535/735], Loss: 0.0512\n",
      "Epoch [9/50], Step [536/735], Loss: 0.1029\n",
      "Epoch [9/50], Step [537/735], Loss: 0.2805\n",
      "Epoch [9/50], Step [538/735], Loss: 0.0606\n",
      "Epoch [9/50], Step [539/735], Loss: 0.1370\n",
      "Epoch [9/50], Step [540/735], Loss: 0.0596\n",
      "Epoch [9/50], Step [541/735], Loss: 0.0891\n",
      "Epoch [9/50], Step [542/735], Loss: 0.1751\n",
      "Epoch [9/50], Step [543/735], Loss: 0.0627\n",
      "Epoch [9/50], Step [544/735], Loss: 0.1788\n",
      "Epoch [9/50], Step [545/735], Loss: 0.0591\n",
      "Epoch [9/50], Step [546/735], Loss: 0.2536\n",
      "Epoch [9/50], Step [547/735], Loss: 0.0404\n",
      "Epoch [9/50], Step [548/735], Loss: 0.0531\n",
      "Epoch [9/50], Step [549/735], Loss: 0.0406\n",
      "Epoch [9/50], Step [550/735], Loss: 0.2140\n",
      "Epoch [9/50], Step [551/735], Loss: 0.0955\n",
      "Epoch [9/50], Step [552/735], Loss: 0.0778\n",
      "Epoch [9/50], Step [553/735], Loss: 0.0740\n",
      "Epoch [9/50], Step [554/735], Loss: 0.0225\n",
      "Epoch [9/50], Step [555/735], Loss: 0.0355\n",
      "Epoch [9/50], Step [556/735], Loss: 0.0457\n",
      "Epoch [9/50], Step [557/735], Loss: 0.1236\n",
      "Epoch [9/50], Step [558/735], Loss: 0.0293\n",
      "Epoch [9/50], Step [559/735], Loss: 0.1057\n",
      "Epoch [9/50], Step [560/735], Loss: 0.1909\n",
      "Epoch [9/50], Step [561/735], Loss: 0.0458\n",
      "Epoch [9/50], Step [562/735], Loss: 0.1438\n",
      "Epoch [9/50], Step [563/735], Loss: 0.2411\n",
      "Epoch [9/50], Step [564/735], Loss: 0.0483\n",
      "Epoch [9/50], Step [565/735], Loss: 0.0967\n",
      "Epoch [9/50], Step [566/735], Loss: 0.0397\n",
      "Epoch [9/50], Step [567/735], Loss: 0.0490\n",
      "Epoch [9/50], Step [568/735], Loss: 0.0802\n",
      "Epoch [9/50], Step [569/735], Loss: 0.0804\n",
      "Epoch [9/50], Step [570/735], Loss: 0.1136\n",
      "Epoch [9/50], Step [571/735], Loss: 0.1634\n",
      "Epoch [9/50], Step [572/735], Loss: 0.0862\n",
      "Epoch [9/50], Step [573/735], Loss: 0.0661\n",
      "Epoch [9/50], Step [574/735], Loss: 0.1977\n",
      "Epoch [9/50], Step [575/735], Loss: 0.0914\n",
      "Epoch [9/50], Step [576/735], Loss: 0.3123\n",
      "Epoch [9/50], Step [577/735], Loss: 0.0915\n",
      "Epoch [9/50], Step [578/735], Loss: 0.0478\n",
      "Epoch [9/50], Step [579/735], Loss: 0.0599\n",
      "Epoch [9/50], Step [580/735], Loss: 0.0645\n",
      "Epoch [9/50], Step [581/735], Loss: 0.0533\n",
      "Epoch [9/50], Step [582/735], Loss: 0.1531\n",
      "Epoch [9/50], Step [583/735], Loss: 0.0328\n",
      "Epoch [9/50], Step [584/735], Loss: 0.0227\n",
      "Epoch [9/50], Step [585/735], Loss: 0.0277\n",
      "Epoch [9/50], Step [586/735], Loss: 0.0489\n",
      "Epoch [9/50], Step [587/735], Loss: 0.0450\n",
      "Epoch [9/50], Step [588/735], Loss: 0.1388\n",
      "Epoch [9/50], Step [589/735], Loss: 0.0939\n",
      "Epoch [9/50], Step [590/735], Loss: 0.0384\n",
      "Epoch [9/50], Step [591/735], Loss: 0.1485\n",
      "Epoch [9/50], Step [592/735], Loss: 0.0617\n",
      "Epoch [9/50], Step [593/735], Loss: 0.1174\n",
      "Epoch [9/50], Step [594/735], Loss: 0.0746\n",
      "Epoch [9/50], Step [595/735], Loss: 0.0363\n",
      "Epoch [9/50], Step [596/735], Loss: 0.2950\n",
      "Epoch [9/50], Step [597/735], Loss: 0.0534\n",
      "Epoch [9/50], Step [598/735], Loss: 0.2044\n",
      "Epoch [9/50], Step [599/735], Loss: 0.0833\n",
      "Epoch [9/50], Step [600/735], Loss: 0.0812\n",
      "Epoch [9/50], Step [601/735], Loss: 0.0701\n",
      "Epoch [9/50], Step [602/735], Loss: 0.1196\n",
      "Epoch [9/50], Step [603/735], Loss: 0.0798\n",
      "Epoch [9/50], Step [604/735], Loss: 0.0592\n",
      "Epoch [9/50], Step [605/735], Loss: 0.1126\n",
      "Epoch [9/50], Step [606/735], Loss: 0.2009\n",
      "Epoch [9/50], Step [607/735], Loss: 0.0911\n",
      "Epoch [9/50], Step [608/735], Loss: 0.1289\n",
      "Epoch [9/50], Step [609/735], Loss: 0.0308\n",
      "Epoch [9/50], Step [610/735], Loss: 0.0378\n",
      "Epoch [9/50], Step [611/735], Loss: 0.0405\n",
      "Epoch [9/50], Step [612/735], Loss: 0.0459\n",
      "Epoch [9/50], Step [613/735], Loss: 0.0310\n",
      "Epoch [9/50], Step [614/735], Loss: 0.0279\n",
      "Epoch [9/50], Step [615/735], Loss: 0.0569\n",
      "Epoch [9/50], Step [616/735], Loss: 0.0794\n",
      "Epoch [9/50], Step [617/735], Loss: 0.1880\n",
      "Epoch [9/50], Step [618/735], Loss: 0.0328\n",
      "Epoch [9/50], Step [619/735], Loss: 0.0925\n",
      "Epoch [9/50], Step [620/735], Loss: 0.1160\n",
      "Epoch [9/50], Step [621/735], Loss: 0.3430\n",
      "Epoch [9/50], Step [622/735], Loss: 0.0520\n",
      "Epoch [9/50], Step [623/735], Loss: 0.1766\n",
      "Epoch [9/50], Step [624/735], Loss: 0.0425\n",
      "Epoch [9/50], Step [625/735], Loss: 0.0920\n",
      "Epoch [9/50], Step [626/735], Loss: 0.2568\n",
      "Epoch [9/50], Step [627/735], Loss: 0.1114\n",
      "Epoch [9/50], Step [628/735], Loss: 0.0407\n",
      "Epoch [9/50], Step [629/735], Loss: 0.0938\n",
      "Epoch [9/50], Step [630/735], Loss: 0.1821\n",
      "Epoch [9/50], Step [631/735], Loss: 0.0546\n",
      "Epoch [9/50], Step [632/735], Loss: 0.0474\n",
      "Epoch [9/50], Step [633/735], Loss: 0.0589\n",
      "Epoch [9/50], Step [634/735], Loss: 0.1514\n",
      "Epoch [9/50], Step [635/735], Loss: 0.1364\n",
      "Epoch [9/50], Step [636/735], Loss: 0.0461\n",
      "Epoch [9/50], Step [637/735], Loss: 0.0486\n",
      "Epoch [9/50], Step [638/735], Loss: 0.0849\n",
      "Epoch [9/50], Step [639/735], Loss: 0.2372\n",
      "Epoch [9/50], Step [640/735], Loss: 0.4599\n",
      "Epoch [9/50], Step [641/735], Loss: 0.0685\n",
      "Epoch [9/50], Step [642/735], Loss: 0.6847\n",
      "Epoch [9/50], Step [643/735], Loss: 0.0634\n",
      "Epoch [9/50], Step [644/735], Loss: 0.0335\n",
      "Epoch [9/50], Step [645/735], Loss: 0.1636\n",
      "Epoch [9/50], Step [646/735], Loss: 0.1101\n",
      "Epoch [9/50], Step [647/735], Loss: 0.2747\n",
      "Epoch [9/50], Step [648/735], Loss: 0.0969\n",
      "Epoch [9/50], Step [649/735], Loss: 0.1249\n",
      "Epoch [9/50], Step [650/735], Loss: 0.0479\n",
      "Epoch [9/50], Step [651/735], Loss: 0.0530\n",
      "Epoch [9/50], Step [652/735], Loss: 0.1484\n",
      "Epoch [9/50], Step [653/735], Loss: 0.3032\n",
      "Epoch [9/50], Step [654/735], Loss: 0.1054\n",
      "Epoch [9/50], Step [655/735], Loss: 0.0225\n",
      "Epoch [9/50], Step [656/735], Loss: 0.0979\n",
      "Epoch [9/50], Step [657/735], Loss: 0.0569\n",
      "Epoch [9/50], Step [658/735], Loss: 0.0617\n",
      "Epoch [9/50], Step [659/735], Loss: 0.0468\n",
      "Epoch [9/50], Step [660/735], Loss: 0.1025\n",
      "Epoch [9/50], Step [661/735], Loss: 0.0631\n",
      "Epoch [9/50], Step [662/735], Loss: 0.0390\n",
      "Epoch [9/50], Step [663/735], Loss: 0.1167\n",
      "Epoch [9/50], Step [664/735], Loss: 0.0920\n",
      "Epoch [9/50], Step [665/735], Loss: 0.0362\n",
      "Epoch [9/50], Step [666/735], Loss: 0.0952\n",
      "Epoch [9/50], Step [667/735], Loss: 0.2685\n",
      "Epoch [9/50], Step [668/735], Loss: 0.0425\n",
      "Epoch [9/50], Step [669/735], Loss: 0.0771\n",
      "Epoch [9/50], Step [670/735], Loss: 0.0518\n",
      "Epoch [9/50], Step [671/735], Loss: 0.0681\n",
      "Epoch [9/50], Step [672/735], Loss: 0.0339\n",
      "Epoch [9/50], Step [673/735], Loss: 0.3579\n",
      "Epoch [9/50], Step [674/735], Loss: 0.0660\n",
      "Epoch [9/50], Step [675/735], Loss: 0.0629\n",
      "Epoch [9/50], Step [676/735], Loss: 0.1326\n",
      "Epoch [9/50], Step [677/735], Loss: 0.2080\n",
      "Epoch [9/50], Step [678/735], Loss: 0.0582\n",
      "Epoch [9/50], Step [679/735], Loss: 0.0696\n",
      "Epoch [9/50], Step [680/735], Loss: 0.1335\n",
      "Epoch [9/50], Step [681/735], Loss: 0.1955\n",
      "Epoch [9/50], Step [682/735], Loss: 0.0499\n",
      "Epoch [9/50], Step [683/735], Loss: 0.2408\n",
      "Epoch [9/50], Step [684/735], Loss: 0.1873\n",
      "Epoch [9/50], Step [685/735], Loss: 0.0941\n",
      "Epoch [9/50], Step [686/735], Loss: 0.2739\n",
      "Epoch [9/50], Step [687/735], Loss: 0.1296\n",
      "Epoch [9/50], Step [688/735], Loss: 0.4765\n",
      "Epoch [9/50], Step [689/735], Loss: 0.0393\n",
      "Epoch [9/50], Step [690/735], Loss: 0.1060\n",
      "Epoch [9/50], Step [691/735], Loss: 0.1220\n",
      "Epoch [9/50], Step [692/735], Loss: 0.1365\n",
      "Epoch [9/50], Step [693/735], Loss: 0.0730\n",
      "Epoch [9/50], Step [694/735], Loss: 0.1003\n",
      "Epoch [9/50], Step [695/735], Loss: 0.1372\n",
      "Epoch [9/50], Step [696/735], Loss: 0.0835\n",
      "Epoch [9/50], Step [697/735], Loss: 0.0917\n",
      "Epoch [9/50], Step [698/735], Loss: 0.2867\n",
      "Epoch [9/50], Step [699/735], Loss: 0.1224\n",
      "Epoch [9/50], Step [700/735], Loss: 0.0270\n",
      "Epoch [9/50], Step [701/735], Loss: 0.0772\n",
      "Epoch [9/50], Step [702/735], Loss: 0.0469\n",
      "Epoch [9/50], Step [703/735], Loss: 0.0365\n",
      "Epoch [9/50], Step [704/735], Loss: 0.2091\n",
      "Epoch [9/50], Step [705/735], Loss: 0.1500\n",
      "Epoch [9/50], Step [706/735], Loss: 0.0380\n",
      "Epoch [9/50], Step [707/735], Loss: 0.2408\n",
      "Epoch [9/50], Step [708/735], Loss: 0.1626\n",
      "Epoch [9/50], Step [709/735], Loss: 0.0663\n",
      "Epoch [9/50], Step [710/735], Loss: 0.0629\n",
      "Epoch [9/50], Step [711/735], Loss: 0.0650\n",
      "Epoch [9/50], Step [712/735], Loss: 0.0486\n",
      "Epoch [9/50], Step [713/735], Loss: 0.1373\n",
      "Epoch [9/50], Step [714/735], Loss: 0.0808\n",
      "Epoch [9/50], Step [715/735], Loss: 0.2096\n",
      "Epoch [9/50], Step [716/735], Loss: 0.2535\n",
      "Epoch [9/50], Step [717/735], Loss: 0.0923\n",
      "Epoch [9/50], Step [718/735], Loss: 0.0511\n",
      "Epoch [9/50], Step [719/735], Loss: 0.0567\n",
      "Epoch [9/50], Step [720/735], Loss: 0.3689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Step [721/735], Loss: 0.2313\n",
      "Epoch [9/50], Step [722/735], Loss: 0.0444\n",
      "Epoch [9/50], Step [723/735], Loss: 0.0803\n",
      "Epoch [9/50], Step [724/735], Loss: 0.1315\n",
      "Epoch [9/50], Step [725/735], Loss: 0.0428\n",
      "Epoch [9/50], Step [726/735], Loss: 0.0810\n",
      "Epoch [9/50], Step [727/735], Loss: 0.0837\n",
      "Epoch [9/50], Step [728/735], Loss: 0.1515\n",
      "Epoch [9/50], Step [729/735], Loss: 0.2226\n",
      "Epoch [9/50], Step [730/735], Loss: 0.2471\n",
      "Epoch [9/50], Step [731/735], Loss: 0.0487\n",
      "Epoch [9/50], Step [732/735], Loss: 0.0479\n",
      "Epoch [9/50], Step [733/735], Loss: 0.3078\n",
      "Epoch [9/50], Step [734/735], Loss: 0.0646\n",
      "Epoch [9/50], Step [735/735], Loss: 0.0812\n",
      "Epoch [10/50], Step [1/735], Loss: 0.1492\n",
      "Epoch [10/50], Step [2/735], Loss: 0.0434\n",
      "Epoch [10/50], Step [3/735], Loss: 0.1009\n",
      "Epoch [10/50], Step [4/735], Loss: 0.0695\n",
      "Epoch [10/50], Step [5/735], Loss: 0.1008\n",
      "Epoch [10/50], Step [6/735], Loss: 0.1284\n",
      "Epoch [10/50], Step [7/735], Loss: 0.0546\n",
      "Epoch [10/50], Step [8/735], Loss: 0.0731\n",
      "Epoch [10/50], Step [9/735], Loss: 0.0526\n",
      "Epoch [10/50], Step [10/735], Loss: 0.4312\n",
      "Epoch [10/50], Step [11/735], Loss: 0.0588\n",
      "Epoch [10/50], Step [12/735], Loss: 0.1140\n",
      "Epoch [10/50], Step [13/735], Loss: 0.1351\n",
      "Epoch [10/50], Step [14/735], Loss: 0.1473\n",
      "Epoch [10/50], Step [15/735], Loss: 0.0409\n",
      "Epoch [10/50], Step [16/735], Loss: 0.2214\n",
      "Epoch [10/50], Step [17/735], Loss: 0.2415\n",
      "Epoch [10/50], Step [18/735], Loss: 0.1214\n",
      "Epoch [10/50], Step [19/735], Loss: 0.1576\n",
      "Epoch [10/50], Step [20/735], Loss: 0.0631\n",
      "Epoch [10/50], Step [21/735], Loss: 0.0539\n",
      "Epoch [10/50], Step [22/735], Loss: 0.1411\n",
      "Epoch [10/50], Step [23/735], Loss: 0.0714\n",
      "Epoch [10/50], Step [24/735], Loss: 0.0581\n",
      "Epoch [10/50], Step [25/735], Loss: 0.1466\n",
      "Epoch [10/50], Step [26/735], Loss: 0.0430\n",
      "Epoch [10/50], Step [27/735], Loss: 0.0898\n",
      "Epoch [10/50], Step [28/735], Loss: 0.0413\n",
      "Epoch [10/50], Step [29/735], Loss: 0.0546\n",
      "Epoch [10/50], Step [30/735], Loss: 0.1218\n",
      "Epoch [10/50], Step [31/735], Loss: 0.1205\n",
      "Epoch [10/50], Step [32/735], Loss: 0.2027\n",
      "Epoch [10/50], Step [33/735], Loss: 0.0505\n",
      "Epoch [10/50], Step [34/735], Loss: 0.0463\n",
      "Epoch [10/50], Step [35/735], Loss: 0.2364\n",
      "Epoch [10/50], Step [36/735], Loss: 0.1023\n",
      "Epoch [10/50], Step [37/735], Loss: 0.3160\n",
      "Epoch [10/50], Step [38/735], Loss: 0.0767\n",
      "Epoch [10/50], Step [39/735], Loss: 0.1741\n",
      "Epoch [10/50], Step [40/735], Loss: 0.0796\n",
      "Epoch [10/50], Step [41/735], Loss: 0.0361\n",
      "Epoch [10/50], Step [42/735], Loss: 0.1856\n",
      "Epoch [10/50], Step [43/735], Loss: 0.0404\n",
      "Epoch [10/50], Step [44/735], Loss: 0.0404\n",
      "Epoch [10/50], Step [45/735], Loss: 0.0921\n",
      "Epoch [10/50], Step [46/735], Loss: 0.1072\n",
      "Epoch [10/50], Step [47/735], Loss: 0.1095\n",
      "Epoch [10/50], Step [48/735], Loss: 0.0614\n",
      "Epoch [10/50], Step [49/735], Loss: 0.0318\n",
      "Epoch [10/50], Step [50/735], Loss: 0.0242\n",
      "Epoch [10/50], Step [51/735], Loss: 0.2470\n",
      "Epoch [10/50], Step [52/735], Loss: 0.0872\n",
      "Epoch [10/50], Step [53/735], Loss: 0.2903\n",
      "Epoch [10/50], Step [54/735], Loss: 0.0584\n",
      "Epoch [10/50], Step [55/735], Loss: 0.0962\n",
      "Epoch [10/50], Step [56/735], Loss: 0.0967\n",
      "Epoch [10/50], Step [57/735], Loss: 0.0565\n",
      "Epoch [10/50], Step [58/735], Loss: 0.4232\n",
      "Epoch [10/50], Step [59/735], Loss: 0.0661\n",
      "Epoch [10/50], Step [60/735], Loss: 0.2711\n",
      "Epoch [10/50], Step [61/735], Loss: 0.0264\n",
      "Epoch [10/50], Step [62/735], Loss: 0.2307\n",
      "Epoch [10/50], Step [63/735], Loss: 0.1393\n",
      "Epoch [10/50], Step [64/735], Loss: 0.0539\n",
      "Epoch [10/50], Step [65/735], Loss: 0.0569\n",
      "Epoch [10/50], Step [66/735], Loss: 0.0542\n",
      "Epoch [10/50], Step [67/735], Loss: 0.0367\n",
      "Epoch [10/50], Step [68/735], Loss: 0.0990\n",
      "Epoch [10/50], Step [69/735], Loss: 0.1975\n",
      "Epoch [10/50], Step [70/735], Loss: 0.0751\n",
      "Epoch [10/50], Step [71/735], Loss: 0.1582\n",
      "Epoch [10/50], Step [72/735], Loss: 0.4320\n",
      "Epoch [10/50], Step [73/735], Loss: 0.1151\n",
      "Epoch [10/50], Step [74/735], Loss: 0.0519\n",
      "Epoch [10/50], Step [75/735], Loss: 0.0501\n",
      "Epoch [10/50], Step [76/735], Loss: 0.0295\n",
      "Epoch [10/50], Step [77/735], Loss: 0.0812\n",
      "Epoch [10/50], Step [78/735], Loss: 0.0818\n",
      "Epoch [10/50], Step [79/735], Loss: 0.2006\n",
      "Epoch [10/50], Step [80/735], Loss: 0.0750\n",
      "Epoch [10/50], Step [81/735], Loss: 0.0482\n",
      "Epoch [10/50], Step [82/735], Loss: 0.2405\n",
      "Epoch [10/50], Step [83/735], Loss: 0.3153\n",
      "Epoch [10/50], Step [84/735], Loss: 0.0952\n",
      "Epoch [10/50], Step [85/735], Loss: 0.1114\n",
      "Epoch [10/50], Step [86/735], Loss: 0.0591\n",
      "Epoch [10/50], Step [87/735], Loss: 0.0787\n",
      "Epoch [10/50], Step [88/735], Loss: 0.0628\n",
      "Epoch [10/50], Step [89/735], Loss: 0.0410\n",
      "Epoch [10/50], Step [90/735], Loss: 0.3802\n",
      "Epoch [10/50], Step [91/735], Loss: 0.1094\n",
      "Epoch [10/50], Step [92/735], Loss: 0.1109\n",
      "Epoch [10/50], Step [93/735], Loss: 0.0777\n",
      "Epoch [10/50], Step [94/735], Loss: 0.4366\n",
      "Epoch [10/50], Step [95/735], Loss: 0.0794\n",
      "Epoch [10/50], Step [96/735], Loss: 0.0605\n",
      "Epoch [10/50], Step [97/735], Loss: 0.0942\n",
      "Epoch [10/50], Step [98/735], Loss: 0.1318\n",
      "Epoch [10/50], Step [99/735], Loss: 0.0607\n",
      "Epoch [10/50], Step [100/735], Loss: 0.1815\n",
      "Epoch [10/50], Step [101/735], Loss: 0.1788\n",
      "Epoch [10/50], Step [102/735], Loss: 0.0390\n",
      "Epoch [10/50], Step [103/735], Loss: 0.1989\n",
      "Epoch [10/50], Step [104/735], Loss: 0.0759\n",
      "Epoch [10/50], Step [105/735], Loss: 0.0955\n",
      "Epoch [10/50], Step [106/735], Loss: 0.0910\n",
      "Epoch [10/50], Step [107/735], Loss: 0.0861\n",
      "Epoch [10/50], Step [108/735], Loss: 0.2325\n",
      "Epoch [10/50], Step [109/735], Loss: 0.6382\n",
      "Epoch [10/50], Step [110/735], Loss: 0.0560\n",
      "Epoch [10/50], Step [111/735], Loss: 0.0312\n",
      "Epoch [10/50], Step [112/735], Loss: 0.0529\n",
      "Epoch [10/50], Step [113/735], Loss: 0.1287\n",
      "Epoch [10/50], Step [114/735], Loss: 0.0204\n",
      "Epoch [10/50], Step [115/735], Loss: 0.0704\n",
      "Epoch [10/50], Step [116/735], Loss: 0.0285\n",
      "Epoch [10/50], Step [117/735], Loss: 0.0823\n",
      "Epoch [10/50], Step [118/735], Loss: 0.2237\n",
      "Epoch [10/50], Step [119/735], Loss: 0.0364\n",
      "Epoch [10/50], Step [120/735], Loss: 0.0430\n",
      "Epoch [10/50], Step [121/735], Loss: 0.4186\n",
      "Epoch [10/50], Step [122/735], Loss: 0.1073\n",
      "Epoch [10/50], Step [123/735], Loss: 0.0550\n",
      "Epoch [10/50], Step [124/735], Loss: 0.1069\n",
      "Epoch [10/50], Step [125/735], Loss: 0.0926\n",
      "Epoch [10/50], Step [126/735], Loss: 0.0930\n",
      "Epoch [10/50], Step [127/735], Loss: 0.0509\n",
      "Epoch [10/50], Step [128/735], Loss: 0.0672\n",
      "Epoch [10/50], Step [129/735], Loss: 0.0434\n",
      "Epoch [10/50], Step [130/735], Loss: 0.1232\n",
      "Epoch [10/50], Step [131/735], Loss: 0.2655\n",
      "Epoch [10/50], Step [132/735], Loss: 0.0813\n",
      "Epoch [10/50], Step [133/735], Loss: 0.0310\n",
      "Epoch [10/50], Step [134/735], Loss: 0.1358\n",
      "Epoch [10/50], Step [135/735], Loss: 0.0463\n",
      "Epoch [10/50], Step [136/735], Loss: 0.0521\n",
      "Epoch [10/50], Step [137/735], Loss: 0.1515\n",
      "Epoch [10/50], Step [138/735], Loss: 0.0781\n",
      "Epoch [10/50], Step [139/735], Loss: 0.0704\n",
      "Epoch [10/50], Step [140/735], Loss: 0.0315\n",
      "Epoch [10/50], Step [141/735], Loss: 0.0485\n",
      "Epoch [10/50], Step [142/735], Loss: 0.0297\n",
      "Epoch [10/50], Step [143/735], Loss: 0.0420\n",
      "Epoch [10/50], Step [144/735], Loss: 0.0752\n",
      "Epoch [10/50], Step [145/735], Loss: 0.0789\n",
      "Epoch [10/50], Step [146/735], Loss: 0.0926\n",
      "Epoch [10/50], Step [147/735], Loss: 0.0636\n",
      "Epoch [10/50], Step [148/735], Loss: 0.3242\n",
      "Epoch [10/50], Step [149/735], Loss: 0.1295\n",
      "Epoch [10/50], Step [150/735], Loss: 0.0840\n",
      "Epoch [10/50], Step [151/735], Loss: 0.0708\n",
      "Epoch [10/50], Step [152/735], Loss: 0.1213\n",
      "Epoch [10/50], Step [153/735], Loss: 0.0992\n",
      "Epoch [10/50], Step [154/735], Loss: 0.0302\n",
      "Epoch [10/50], Step [155/735], Loss: 0.0743\n",
      "Epoch [10/50], Step [156/735], Loss: 0.1254\n",
      "Epoch [10/50], Step [157/735], Loss: 0.1887\n",
      "Epoch [10/50], Step [158/735], Loss: 0.0912\n",
      "Epoch [10/50], Step [159/735], Loss: 0.0808\n",
      "Epoch [10/50], Step [160/735], Loss: 0.1162\n",
      "Epoch [10/50], Step [161/735], Loss: 0.0567\n",
      "Epoch [10/50], Step [162/735], Loss: 0.1483\n",
      "Epoch [10/50], Step [163/735], Loss: 0.0706\n",
      "Epoch [10/50], Step [164/735], Loss: 0.0769\n",
      "Epoch [10/50], Step [165/735], Loss: 0.0522\n",
      "Epoch [10/50], Step [166/735], Loss: 0.2008\n",
      "Epoch [10/50], Step [167/735], Loss: 0.1607\n",
      "Epoch [10/50], Step [168/735], Loss: 0.0736\n",
      "Epoch [10/50], Step [169/735], Loss: 0.0660\n",
      "Epoch [10/50], Step [170/735], Loss: 0.0547\n",
      "Epoch [10/50], Step [171/735], Loss: 0.0456\n",
      "Epoch [10/50], Step [172/735], Loss: 0.0851\n",
      "Epoch [10/50], Step [173/735], Loss: 0.1158\n",
      "Epoch [10/50], Step [174/735], Loss: 0.1549\n",
      "Epoch [10/50], Step [175/735], Loss: 0.0816\n",
      "Epoch [10/50], Step [176/735], Loss: 0.0763\n",
      "Epoch [10/50], Step [177/735], Loss: 0.2412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Step [178/735], Loss: 0.0509\n",
      "Epoch [10/50], Step [179/735], Loss: 0.0705\n",
      "Epoch [10/50], Step [180/735], Loss: 0.1418\n",
      "Epoch [10/50], Step [181/735], Loss: 0.0861\n",
      "Epoch [10/50], Step [182/735], Loss: 0.0896\n",
      "Epoch [10/50], Step [183/735], Loss: 0.0302\n",
      "Epoch [10/50], Step [184/735], Loss: 0.0658\n",
      "Epoch [10/50], Step [185/735], Loss: 0.1045\n",
      "Epoch [10/50], Step [186/735], Loss: 0.0402\n",
      "Epoch [10/50], Step [187/735], Loss: 0.0339\n",
      "Epoch [10/50], Step [188/735], Loss: 0.0376\n",
      "Epoch [10/50], Step [189/735], Loss: 0.0606\n",
      "Epoch [10/50], Step [190/735], Loss: 0.0534\n",
      "Epoch [10/50], Step [191/735], Loss: 0.0936\n",
      "Epoch [10/50], Step [192/735], Loss: 0.0613\n",
      "Epoch [10/50], Step [193/735], Loss: 0.0955\n",
      "Epoch [10/50], Step [194/735], Loss: 0.1109\n",
      "Epoch [10/50], Step [195/735], Loss: 0.1497\n",
      "Epoch [10/50], Step [196/735], Loss: 0.0492\n",
      "Epoch [10/50], Step [197/735], Loss: 0.0341\n",
      "Epoch [10/50], Step [198/735], Loss: 0.0625\n",
      "Epoch [10/50], Step [199/735], Loss: 0.0644\n",
      "Epoch [10/50], Step [200/735], Loss: 0.0840\n",
      "Epoch [10/50], Step [201/735], Loss: 0.2444\n",
      "Epoch [10/50], Step [202/735], Loss: 0.0926\n",
      "Epoch [10/50], Step [203/735], Loss: 0.0783\n",
      "Epoch [10/50], Step [204/735], Loss: 0.3088\n",
      "Epoch [10/50], Step [205/735], Loss: 0.0964\n",
      "Epoch [10/50], Step [206/735], Loss: 0.1910\n",
      "Epoch [10/50], Step [207/735], Loss: 0.0260\n",
      "Epoch [10/50], Step [208/735], Loss: 0.0607\n",
      "Epoch [10/50], Step [209/735], Loss: 0.0267\n",
      "Epoch [10/50], Step [210/735], Loss: 0.1283\n",
      "Epoch [10/50], Step [211/735], Loss: 0.0804\n",
      "Epoch [10/50], Step [212/735], Loss: 0.0270\n",
      "Epoch [10/50], Step [213/735], Loss: 0.2555\n",
      "Epoch [10/50], Step [214/735], Loss: 0.0332\n",
      "Epoch [10/50], Step [215/735], Loss: 0.2030\n",
      "Epoch [10/50], Step [216/735], Loss: 0.0272\n",
      "Epoch [10/50], Step [217/735], Loss: 0.0706\n",
      "Epoch [10/50], Step [218/735], Loss: 0.0273\n",
      "Epoch [10/50], Step [219/735], Loss: 0.2850\n",
      "Epoch [10/50], Step [220/735], Loss: 0.1556\n",
      "Epoch [10/50], Step [221/735], Loss: 0.0378\n",
      "Epoch [10/50], Step [222/735], Loss: 0.0745\n",
      "Epoch [10/50], Step [223/735], Loss: 0.1993\n",
      "Epoch [10/50], Step [224/735], Loss: 0.0741\n",
      "Epoch [10/50], Step [225/735], Loss: 0.0397\n",
      "Epoch [10/50], Step [226/735], Loss: 0.1841\n",
      "Epoch [10/50], Step [227/735], Loss: 0.2327\n",
      "Epoch [10/50], Step [228/735], Loss: 0.0415\n",
      "Epoch [10/50], Step [229/735], Loss: 0.0458\n",
      "Epoch [10/50], Step [230/735], Loss: 0.0868\n",
      "Epoch [10/50], Step [231/735], Loss: 0.2185\n",
      "Epoch [10/50], Step [232/735], Loss: 0.3218\n",
      "Epoch [10/50], Step [233/735], Loss: 0.0389\n",
      "Epoch [10/50], Step [234/735], Loss: 0.3169\n",
      "Epoch [10/50], Step [235/735], Loss: 0.3109\n",
      "Epoch [10/50], Step [236/735], Loss: 0.0795\n",
      "Epoch [10/50], Step [237/735], Loss: 0.3004\n",
      "Epoch [10/50], Step [238/735], Loss: 0.1073\n",
      "Epoch [10/50], Step [239/735], Loss: 0.0538\n",
      "Epoch [10/50], Step [240/735], Loss: 0.0553\n",
      "Epoch [10/50], Step [241/735], Loss: 0.2399\n",
      "Epoch [10/50], Step [242/735], Loss: 0.0521\n",
      "Epoch [10/50], Step [243/735], Loss: 0.1672\n",
      "Epoch [10/50], Step [244/735], Loss: 0.0807\n",
      "Epoch [10/50], Step [245/735], Loss: 0.3417\n",
      "Epoch [10/50], Step [246/735], Loss: 0.1013\n",
      "Epoch [10/50], Step [247/735], Loss: 0.1575\n",
      "Epoch [10/50], Step [248/735], Loss: 0.0255\n",
      "Epoch [10/50], Step [249/735], Loss: 0.0535\n",
      "Epoch [10/50], Step [250/735], Loss: 0.0552\n",
      "Epoch [10/50], Step [251/735], Loss: 0.0919\n",
      "Epoch [10/50], Step [252/735], Loss: 0.0357\n",
      "Epoch [10/50], Step [253/735], Loss: 0.0357\n",
      "Epoch [10/50], Step [254/735], Loss: 0.0901\n",
      "Epoch [10/50], Step [255/735], Loss: 0.2339\n",
      "Epoch [10/50], Step [256/735], Loss: 0.2123\n",
      "Epoch [10/50], Step [257/735], Loss: 0.1031\n",
      "Epoch [10/50], Step [258/735], Loss: 0.0363\n",
      "Epoch [10/50], Step [259/735], Loss: 0.1176\n",
      "Epoch [10/50], Step [260/735], Loss: 0.0710\n",
      "Epoch [10/50], Step [261/735], Loss: 0.0281\n",
      "Epoch [10/50], Step [262/735], Loss: 0.1599\n",
      "Epoch [10/50], Step [263/735], Loss: 0.2219\n",
      "Epoch [10/50], Step [264/735], Loss: 0.0762\n",
      "Epoch [10/50], Step [265/735], Loss: 0.0403\n",
      "Epoch [10/50], Step [266/735], Loss: 0.0595\n",
      "Epoch [10/50], Step [267/735], Loss: 0.0927\n",
      "Epoch [10/50], Step [268/735], Loss: 0.0635\n",
      "Epoch [10/50], Step [269/735], Loss: 0.1239\n",
      "Epoch [10/50], Step [270/735], Loss: 0.0541\n",
      "Epoch [10/50], Step [271/735], Loss: 0.3561\n",
      "Epoch [10/50], Step [272/735], Loss: 0.0570\n",
      "Epoch [10/50], Step [273/735], Loss: 0.1056\n",
      "Epoch [10/50], Step [274/735], Loss: 0.0718\n",
      "Epoch [10/50], Step [275/735], Loss: 0.1302\n",
      "Epoch [10/50], Step [276/735], Loss: 0.0577\n",
      "Epoch [10/50], Step [277/735], Loss: 0.1450\n",
      "Epoch [10/50], Step [278/735], Loss: 0.2294\n",
      "Epoch [10/50], Step [279/735], Loss: 0.0227\n",
      "Epoch [10/50], Step [280/735], Loss: 0.0428\n",
      "Epoch [10/50], Step [281/735], Loss: 0.1787\n",
      "Epoch [10/50], Step [282/735], Loss: 0.1178\n",
      "Epoch [10/50], Step [283/735], Loss: 0.2288\n",
      "Epoch [10/50], Step [284/735], Loss: 0.0759\n",
      "Epoch [10/50], Step [285/735], Loss: 0.0362\n",
      "Epoch [10/50], Step [286/735], Loss: 0.1371\n",
      "Epoch [10/50], Step [287/735], Loss: 0.0377\n",
      "Epoch [10/50], Step [288/735], Loss: 0.0451\n",
      "Epoch [10/50], Step [289/735], Loss: 0.0740\n",
      "Epoch [10/50], Step [290/735], Loss: 0.0427\n",
      "Epoch [10/50], Step [291/735], Loss: 0.0923\n",
      "Epoch [10/50], Step [292/735], Loss: 0.0321\n",
      "Epoch [10/50], Step [293/735], Loss: 0.0662\n",
      "Epoch [10/50], Step [294/735], Loss: 0.0444\n",
      "Epoch [10/50], Step [295/735], Loss: 0.0310\n",
      "Epoch [10/50], Step [296/735], Loss: 0.0909\n",
      "Epoch [10/50], Step [297/735], Loss: 0.0991\n",
      "Epoch [10/50], Step [298/735], Loss: 0.0635\n",
      "Epoch [10/50], Step [299/735], Loss: 0.1422\n",
      "Epoch [10/50], Step [300/735], Loss: 0.0730\n",
      "Epoch [10/50], Step [301/735], Loss: 0.0484\n",
      "Epoch [10/50], Step [302/735], Loss: 0.0833\n",
      "Epoch [10/50], Step [303/735], Loss: 0.0673\n",
      "Epoch [10/50], Step [304/735], Loss: 0.1519\n",
      "Epoch [10/50], Step [305/735], Loss: 0.2550\n",
      "Epoch [10/50], Step [306/735], Loss: 0.0748\n",
      "Epoch [10/50], Step [307/735], Loss: 0.1336\n",
      "Epoch [10/50], Step [308/735], Loss: 0.0671\n",
      "Epoch [10/50], Step [309/735], Loss: 0.0230\n",
      "Epoch [10/50], Step [310/735], Loss: 0.1491\n",
      "Epoch [10/50], Step [311/735], Loss: 0.1454\n",
      "Epoch [10/50], Step [312/735], Loss: 0.0544\n",
      "Epoch [10/50], Step [313/735], Loss: 0.0302\n",
      "Epoch [10/50], Step [314/735], Loss: 0.0910\n",
      "Epoch [10/50], Step [315/735], Loss: 0.3655\n",
      "Epoch [10/50], Step [316/735], Loss: 0.0719\n",
      "Epoch [10/50], Step [317/735], Loss: 0.1676\n",
      "Epoch [10/50], Step [318/735], Loss: 0.3574\n",
      "Epoch [10/50], Step [319/735], Loss: 0.0419\n",
      "Epoch [10/50], Step [320/735], Loss: 0.1656\n",
      "Epoch [10/50], Step [321/735], Loss: 0.3253\n",
      "Epoch [10/50], Step [322/735], Loss: 0.1010\n",
      "Epoch [10/50], Step [323/735], Loss: 0.0363\n",
      "Epoch [10/50], Step [324/735], Loss: 0.0391\n",
      "Epoch [10/50], Step [325/735], Loss: 0.0959\n",
      "Epoch [10/50], Step [326/735], Loss: 0.0746\n",
      "Epoch [10/50], Step [327/735], Loss: 0.0325\n",
      "Epoch [10/50], Step [328/735], Loss: 0.0397\n",
      "Epoch [10/50], Step [329/735], Loss: 0.0821\n",
      "Epoch [10/50], Step [330/735], Loss: 0.0520\n",
      "Epoch [10/50], Step [331/735], Loss: 0.0831\n",
      "Epoch [10/50], Step [332/735], Loss: 0.1325\n",
      "Epoch [10/50], Step [333/735], Loss: 0.1827\n",
      "Epoch [10/50], Step [334/735], Loss: 0.2722\n",
      "Epoch [10/50], Step [335/735], Loss: 0.1967\n",
      "Epoch [10/50], Step [336/735], Loss: 0.0351\n",
      "Epoch [10/50], Step [337/735], Loss: 0.0559\n",
      "Epoch [10/50], Step [338/735], Loss: 0.0495\n",
      "Epoch [10/50], Step [339/735], Loss: 0.0936\n",
      "Epoch [10/50], Step [340/735], Loss: 0.2966\n",
      "Epoch [10/50], Step [341/735], Loss: 0.0575\n",
      "Epoch [10/50], Step [342/735], Loss: 0.0562\n",
      "Epoch [10/50], Step [343/735], Loss: 0.1458\n",
      "Epoch [10/50], Step [344/735], Loss: 0.1558\n",
      "Epoch [10/50], Step [345/735], Loss: 0.0484\n",
      "Epoch [10/50], Step [346/735], Loss: 0.0614\n",
      "Epoch [10/50], Step [347/735], Loss: 0.0491\n",
      "Epoch [10/50], Step [348/735], Loss: 0.1563\n",
      "Epoch [10/50], Step [349/735], Loss: 0.0799\n",
      "Epoch [10/50], Step [350/735], Loss: 0.2190\n",
      "Epoch [10/50], Step [351/735], Loss: 0.2509\n",
      "Epoch [10/50], Step [352/735], Loss: 0.0724\n",
      "Epoch [10/50], Step [353/735], Loss: 0.0978\n",
      "Epoch [10/50], Step [354/735], Loss: 0.0973\n",
      "Epoch [10/50], Step [355/735], Loss: 0.1079\n",
      "Epoch [10/50], Step [356/735], Loss: 0.2706\n",
      "Epoch [10/50], Step [357/735], Loss: 0.2560\n",
      "Epoch [10/50], Step [358/735], Loss: 0.1467\n",
      "Epoch [10/50], Step [359/735], Loss: 0.1088\n",
      "Epoch [10/50], Step [360/735], Loss: 0.0250\n",
      "Epoch [10/50], Step [361/735], Loss: 0.2703\n",
      "Epoch [10/50], Step [362/735], Loss: 0.1068\n",
      "Epoch [10/50], Step [363/735], Loss: 0.1034\n",
      "Epoch [10/50], Step [364/735], Loss: 0.2659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Step [365/735], Loss: 0.0451\n",
      "Epoch [10/50], Step [366/735], Loss: 0.0187\n",
      "Epoch [10/50], Step [367/735], Loss: 0.1902\n",
      "Epoch [10/50], Step [368/735], Loss: 0.0206\n",
      "Epoch [10/50], Step [369/735], Loss: 0.1902\n",
      "Epoch [10/50], Step [370/735], Loss: 0.2183\n",
      "Epoch [10/50], Step [371/735], Loss: 0.1210\n",
      "Epoch [10/50], Step [372/735], Loss: 0.0327\n",
      "Epoch [10/50], Step [373/735], Loss: 0.0902\n",
      "Epoch [10/50], Step [374/735], Loss: 0.0360\n",
      "Epoch [10/50], Step [375/735], Loss: 0.0456\n",
      "Epoch [10/50], Step [376/735], Loss: 0.0713\n",
      "Epoch [10/50], Step [377/735], Loss: 0.0416\n",
      "Epoch [10/50], Step [378/735], Loss: 0.0495\n",
      "Epoch [10/50], Step [379/735], Loss: 0.1086\n",
      "Epoch [10/50], Step [380/735], Loss: 0.0491\n",
      "Epoch [10/50], Step [381/735], Loss: 0.2459\n",
      "Epoch [10/50], Step [382/735], Loss: 0.0575\n",
      "Epoch [10/50], Step [383/735], Loss: 0.0411\n",
      "Epoch [10/50], Step [384/735], Loss: 0.0715\n",
      "Epoch [10/50], Step [385/735], Loss: 0.1432\n",
      "Epoch [10/50], Step [386/735], Loss: 0.0611\n",
      "Epoch [10/50], Step [387/735], Loss: 0.0631\n",
      "Epoch [10/50], Step [388/735], Loss: 0.1723\n",
      "Epoch [10/50], Step [389/735], Loss: 0.0300\n",
      "Epoch [10/50], Step [390/735], Loss: 0.0436\n",
      "Epoch [10/50], Step [391/735], Loss: 0.1695\n",
      "Epoch [10/50], Step [392/735], Loss: 0.2618\n",
      "Epoch [10/50], Step [393/735], Loss: 0.0398\n",
      "Epoch [10/50], Step [394/735], Loss: 0.0900\n",
      "Epoch [10/50], Step [395/735], Loss: 0.0834\n",
      "Epoch [10/50], Step [396/735], Loss: 0.1593\n",
      "Epoch [10/50], Step [397/735], Loss: 0.0441\n",
      "Epoch [10/50], Step [398/735], Loss: 0.0384\n",
      "Epoch [10/50], Step [399/735], Loss: 0.0539\n",
      "Epoch [10/50], Step [400/735], Loss: 0.3643\n",
      "Epoch [10/50], Step [401/735], Loss: 0.1045\n",
      "Epoch [10/50], Step [402/735], Loss: 0.1213\n",
      "Epoch [10/50], Step [403/735], Loss: 0.1183\n",
      "Epoch [10/50], Step [404/735], Loss: 0.1405\n",
      "Epoch [10/50], Step [405/735], Loss: 0.0495\n",
      "Epoch [10/50], Step [406/735], Loss: 0.0738\n",
      "Epoch [10/50], Step [407/735], Loss: 0.0835\n",
      "Epoch [10/50], Step [408/735], Loss: 0.2252\n",
      "Epoch [10/50], Step [409/735], Loss: 0.1226\n",
      "Epoch [10/50], Step [410/735], Loss: 0.1137\n",
      "Epoch [10/50], Step [411/735], Loss: 0.1259\n",
      "Epoch [10/50], Step [412/735], Loss: 0.0418\n",
      "Epoch [10/50], Step [413/735], Loss: 0.1845\n",
      "Epoch [10/50], Step [414/735], Loss: 0.1863\n",
      "Epoch [10/50], Step [415/735], Loss: 0.1101\n",
      "Epoch [10/50], Step [416/735], Loss: 0.0428\n",
      "Epoch [10/50], Step [417/735], Loss: 0.1185\n",
      "Epoch [10/50], Step [418/735], Loss: 0.3027\n",
      "Epoch [10/50], Step [419/735], Loss: 0.0945\n",
      "Epoch [10/50], Step [420/735], Loss: 0.0861\n",
      "Epoch [10/50], Step [421/735], Loss: 0.0788\n",
      "Epoch [10/50], Step [422/735], Loss: 0.0521\n",
      "Epoch [10/50], Step [423/735], Loss: 0.0960\n",
      "Epoch [10/50], Step [424/735], Loss: 0.0628\n",
      "Epoch [10/50], Step [425/735], Loss: 0.1386\n",
      "Epoch [10/50], Step [426/735], Loss: 0.2075\n",
      "Epoch [10/50], Step [427/735], Loss: 0.0708\n",
      "Epoch [10/50], Step [428/735], Loss: 0.1383\n",
      "Epoch [10/50], Step [429/735], Loss: 0.0684\n",
      "Epoch [10/50], Step [430/735], Loss: 0.0526\n",
      "Epoch [10/50], Step [431/735], Loss: 0.0585\n",
      "Epoch [10/50], Step [432/735], Loss: 0.1093\n",
      "Epoch [10/50], Step [433/735], Loss: 0.0618\n",
      "Epoch [10/50], Step [434/735], Loss: 0.3393\n",
      "Epoch [10/50], Step [435/735], Loss: 0.1474\n",
      "Epoch [10/50], Step [436/735], Loss: 0.0524\n",
      "Epoch [10/50], Step [437/735], Loss: 0.1455\n",
      "Epoch [10/50], Step [438/735], Loss: 0.0517\n",
      "Epoch [10/50], Step [439/735], Loss: 0.1800\n",
      "Epoch [10/50], Step [440/735], Loss: 0.8577\n",
      "Epoch [10/50], Step [441/735], Loss: 0.5853\n",
      "Epoch [10/50], Step [442/735], Loss: 0.2318\n",
      "Epoch [10/50], Step [443/735], Loss: 0.1001\n",
      "Epoch [10/50], Step [444/735], Loss: 0.1229\n",
      "Epoch [10/50], Step [445/735], Loss: 0.0737\n",
      "Epoch [10/50], Step [446/735], Loss: 0.0279\n",
      "Epoch [10/50], Step [447/735], Loss: 0.1065\n",
      "Epoch [10/50], Step [448/735], Loss: 0.1860\n",
      "Epoch [10/50], Step [449/735], Loss: 0.0587\n",
      "Epoch [10/50], Step [450/735], Loss: 0.0413\n",
      "Epoch [10/50], Step [451/735], Loss: 0.3322\n",
      "Epoch [10/50], Step [452/735], Loss: 0.1108\n",
      "Epoch [10/50], Step [453/735], Loss: 0.0972\n",
      "Epoch [10/50], Step [454/735], Loss: 0.1330\n",
      "Epoch [10/50], Step [455/735], Loss: 0.0771\n",
      "Epoch [10/50], Step [456/735], Loss: 0.0553\n",
      "Epoch [10/50], Step [457/735], Loss: 0.0511\n",
      "Epoch [10/50], Step [458/735], Loss: 0.0957\n",
      "Epoch [10/50], Step [459/735], Loss: 0.1088\n",
      "Epoch [10/50], Step [460/735], Loss: 0.0559\n",
      "Epoch [10/50], Step [461/735], Loss: 0.1426\n",
      "Epoch [10/50], Step [462/735], Loss: 0.0987\n",
      "Epoch [10/50], Step [463/735], Loss: 0.0359\n",
      "Epoch [10/50], Step [464/735], Loss: 0.1888\n",
      "Epoch [10/50], Step [465/735], Loss: 0.0885\n",
      "Epoch [10/50], Step [466/735], Loss: 0.1101\n",
      "Epoch [10/50], Step [467/735], Loss: 0.0918\n",
      "Epoch [10/50], Step [468/735], Loss: 0.1593\n",
      "Epoch [10/50], Step [469/735], Loss: 0.0400\n",
      "Epoch [10/50], Step [470/735], Loss: 0.1808\n",
      "Epoch [10/50], Step [471/735], Loss: 0.1061\n",
      "Epoch [10/50], Step [472/735], Loss: 0.1343\n",
      "Epoch [10/50], Step [473/735], Loss: 0.1211\n",
      "Epoch [10/50], Step [474/735], Loss: 0.0811\n",
      "Epoch [10/50], Step [475/735], Loss: 0.1914\n",
      "Epoch [10/50], Step [476/735], Loss: 0.0554\n",
      "Epoch [10/50], Step [477/735], Loss: 0.0457\n",
      "Epoch [10/50], Step [478/735], Loss: 0.0765\n",
      "Epoch [10/50], Step [479/735], Loss: 0.1009\n",
      "Epoch [10/50], Step [480/735], Loss: 0.0459\n",
      "Epoch [10/50], Step [481/735], Loss: 0.0318\n",
      "Epoch [10/50], Step [482/735], Loss: 0.1535\n",
      "Epoch [10/50], Step [483/735], Loss: 0.0297\n",
      "Epoch [10/50], Step [484/735], Loss: 0.2501\n",
      "Epoch [10/50], Step [485/735], Loss: 0.0808\n",
      "Epoch [10/50], Step [486/735], Loss: 0.1363\n",
      "Epoch [10/50], Step [487/735], Loss: 0.0417\n",
      "Epoch [10/50], Step [488/735], Loss: 0.1796\n",
      "Epoch [10/50], Step [489/735], Loss: 0.0822\n",
      "Epoch [10/50], Step [490/735], Loss: 0.1506\n",
      "Epoch [10/50], Step [491/735], Loss: 0.0518\n",
      "Epoch [10/50], Step [492/735], Loss: 0.7444\n",
      "Epoch [10/50], Step [493/735], Loss: 0.2047\n",
      "Epoch [10/50], Step [494/735], Loss: 0.0618\n",
      "Epoch [10/50], Step [495/735], Loss: 0.0456\n",
      "Epoch [10/50], Step [496/735], Loss: 0.0546\n",
      "Epoch [10/50], Step [497/735], Loss: 0.0163\n",
      "Epoch [10/50], Step [498/735], Loss: 0.1072\n",
      "Epoch [10/50], Step [499/735], Loss: 0.2421\n",
      "Epoch [10/50], Step [500/735], Loss: 0.2916\n",
      "Epoch [10/50], Step [501/735], Loss: 0.1310\n",
      "Epoch [10/50], Step [502/735], Loss: 0.1556\n",
      "Epoch [10/50], Step [503/735], Loss: 0.0319\n",
      "Epoch [10/50], Step [504/735], Loss: 0.0977\n",
      "Epoch [10/50], Step [505/735], Loss: 0.1713\n",
      "Epoch [10/50], Step [506/735], Loss: 0.0876\n",
      "Epoch [10/50], Step [507/735], Loss: 0.0288\n",
      "Epoch [10/50], Step [508/735], Loss: 0.0362\n",
      "Epoch [10/50], Step [509/735], Loss: 0.2684\n",
      "Epoch [10/50], Step [510/735], Loss: 0.0694\n",
      "Epoch [10/50], Step [511/735], Loss: 0.3072\n",
      "Epoch [10/50], Step [512/735], Loss: 0.1638\n",
      "Epoch [10/50], Step [513/735], Loss: 0.0883\n",
      "Epoch [10/50], Step [514/735], Loss: 0.2151\n",
      "Epoch [10/50], Step [515/735], Loss: 0.0298\n",
      "Epoch [10/50], Step [516/735], Loss: 0.0379\n",
      "Epoch [10/50], Step [517/735], Loss: 0.0582\n",
      "Epoch [10/50], Step [518/735], Loss: 0.0552\n",
      "Epoch [10/50], Step [519/735], Loss: 0.1447\n",
      "Epoch [10/50], Step [520/735], Loss: 0.0868\n",
      "Epoch [10/50], Step [521/735], Loss: 0.1785\n",
      "Epoch [10/50], Step [522/735], Loss: 0.1083\n",
      "Epoch [10/50], Step [523/735], Loss: 0.0805\n",
      "Epoch [10/50], Step [524/735], Loss: 0.1438\n",
      "Epoch [10/50], Step [525/735], Loss: 0.1050\n",
      "Epoch [10/50], Step [526/735], Loss: 0.1205\n",
      "Epoch [10/50], Step [527/735], Loss: 0.1046\n",
      "Epoch [10/50], Step [528/735], Loss: 0.0804\n",
      "Epoch [10/50], Step [529/735], Loss: 0.1779\n",
      "Epoch [10/50], Step [530/735], Loss: 0.0713\n",
      "Epoch [10/50], Step [531/735], Loss: 0.1552\n",
      "Epoch [10/50], Step [532/735], Loss: 0.1280\n",
      "Epoch [10/50], Step [533/735], Loss: 0.0483\n",
      "Epoch [10/50], Step [534/735], Loss: 0.0602\n",
      "Epoch [10/50], Step [535/735], Loss: 0.1261\n",
      "Epoch [10/50], Step [536/735], Loss: 0.0915\n",
      "Epoch [10/50], Step [537/735], Loss: 0.2056\n",
      "Epoch [10/50], Step [538/735], Loss: 0.3019\n",
      "Epoch [10/50], Step [539/735], Loss: 0.0302\n",
      "Epoch [10/50], Step [540/735], Loss: 0.0697\n",
      "Epoch [10/50], Step [541/735], Loss: 0.0541\n",
      "Epoch [10/50], Step [542/735], Loss: 0.1268\n",
      "Epoch [10/50], Step [543/735], Loss: 0.3098\n",
      "Epoch [10/50], Step [544/735], Loss: 0.3021\n",
      "Epoch [10/50], Step [545/735], Loss: 0.1108\n",
      "Epoch [10/50], Step [546/735], Loss: 0.0896\n",
      "Epoch [10/50], Step [547/735], Loss: 0.0329\n",
      "Epoch [10/50], Step [548/735], Loss: 0.1443\n",
      "Epoch [10/50], Step [549/735], Loss: 0.0833\n",
      "Epoch [10/50], Step [550/735], Loss: 0.0318\n",
      "Epoch [10/50], Step [551/735], Loss: 0.3580\n",
      "Epoch [10/50], Step [552/735], Loss: 0.0296\n",
      "Epoch [10/50], Step [553/735], Loss: 0.1669\n",
      "Epoch [10/50], Step [554/735], Loss: 0.0524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Step [555/735], Loss: 0.0384\n",
      "Epoch [10/50], Step [556/735], Loss: 0.0951\n",
      "Epoch [10/50], Step [557/735], Loss: 0.3588\n",
      "Epoch [10/50], Step [558/735], Loss: 0.0458\n",
      "Epoch [10/50], Step [559/735], Loss: 0.1229\n",
      "Epoch [10/50], Step [560/735], Loss: 0.0458\n",
      "Epoch [10/50], Step [561/735], Loss: 0.0472\n",
      "Epoch [10/50], Step [562/735], Loss: 0.0643\n",
      "Epoch [10/50], Step [563/735], Loss: 0.1002\n",
      "Epoch [10/50], Step [564/735], Loss: 0.5805\n",
      "Epoch [10/50], Step [565/735], Loss: 0.1097\n",
      "Epoch [10/50], Step [566/735], Loss: 0.0886\n",
      "Epoch [10/50], Step [567/735], Loss: 0.2006\n",
      "Epoch [10/50], Step [568/735], Loss: 0.1697\n",
      "Epoch [10/50], Step [569/735], Loss: 0.1028\n",
      "Epoch [10/50], Step [570/735], Loss: 0.0744\n",
      "Epoch [10/50], Step [571/735], Loss: 0.0292\n",
      "Epoch [10/50], Step [572/735], Loss: 0.1591\n",
      "Epoch [10/50], Step [573/735], Loss: 0.1380\n",
      "Epoch [10/50], Step [574/735], Loss: 0.0536\n",
      "Epoch [10/50], Step [575/735], Loss: 0.3009\n",
      "Epoch [10/50], Step [576/735], Loss: 0.0779\n",
      "Epoch [10/50], Step [577/735], Loss: 0.0993\n",
      "Epoch [10/50], Step [578/735], Loss: 0.0438\n",
      "Epoch [10/50], Step [579/735], Loss: 0.0595\n",
      "Epoch [10/50], Step [580/735], Loss: 0.1775\n",
      "Epoch [10/50], Step [581/735], Loss: 0.0317\n",
      "Epoch [10/50], Step [582/735], Loss: 0.0538\n",
      "Epoch [10/50], Step [583/735], Loss: 0.4364\n",
      "Epoch [10/50], Step [584/735], Loss: 0.1676\n",
      "Epoch [10/50], Step [585/735], Loss: 0.0249\n",
      "Epoch [10/50], Step [586/735], Loss: 0.0353\n",
      "Epoch [10/50], Step [587/735], Loss: 0.0766\n",
      "Epoch [10/50], Step [588/735], Loss: 0.4799\n",
      "Epoch [10/50], Step [589/735], Loss: 0.1353\n",
      "Epoch [10/50], Step [590/735], Loss: 0.3924\n",
      "Epoch [10/50], Step [591/735], Loss: 0.1956\n",
      "Epoch [10/50], Step [592/735], Loss: 0.1298\n",
      "Epoch [10/50], Step [593/735], Loss: 0.0697\n",
      "Epoch [10/50], Step [594/735], Loss: 0.0938\n",
      "Epoch [10/50], Step [595/735], Loss: 0.0243\n",
      "Epoch [10/50], Step [596/735], Loss: 0.0460\n",
      "Epoch [10/50], Step [597/735], Loss: 0.1761\n",
      "Epoch [10/50], Step [598/735], Loss: 0.0750\n",
      "Epoch [10/50], Step [599/735], Loss: 0.2508\n",
      "Epoch [10/50], Step [600/735], Loss: 0.0566\n",
      "Epoch [10/50], Step [601/735], Loss: 0.2653\n",
      "Epoch [10/50], Step [602/735], Loss: 0.1456\n",
      "Epoch [10/50], Step [603/735], Loss: 0.0743\n",
      "Epoch [10/50], Step [604/735], Loss: 0.2022\n",
      "Epoch [10/50], Step [605/735], Loss: 0.1173\n",
      "Epoch [10/50], Step [606/735], Loss: 0.0972\n",
      "Epoch [10/50], Step [607/735], Loss: 0.1636\n",
      "Epoch [10/50], Step [608/735], Loss: 0.0707\n",
      "Epoch [10/50], Step [609/735], Loss: 0.1110\n",
      "Epoch [10/50], Step [610/735], Loss: 0.1782\n",
      "Epoch [10/50], Step [611/735], Loss: 0.0566\n",
      "Epoch [10/50], Step [612/735], Loss: 0.0463\n",
      "Epoch [10/50], Step [613/735], Loss: 0.0697\n",
      "Epoch [10/50], Step [614/735], Loss: 0.0566\n",
      "Epoch [10/50], Step [615/735], Loss: 0.0882\n",
      "Epoch [10/50], Step [616/735], Loss: 0.0658\n",
      "Epoch [10/50], Step [617/735], Loss: 0.0571\n",
      "Epoch [10/50], Step [618/735], Loss: 0.0273\n",
      "Epoch [10/50], Step [619/735], Loss: 0.0358\n",
      "Epoch [10/50], Step [620/735], Loss: 0.1042\n",
      "Epoch [10/50], Step [621/735], Loss: 0.2715\n",
      "Epoch [10/50], Step [622/735], Loss: 0.1451\n",
      "Epoch [10/50], Step [623/735], Loss: 0.0335\n",
      "Epoch [10/50], Step [624/735], Loss: 0.0840\n",
      "Epoch [10/50], Step [625/735], Loss: 0.0532\n",
      "Epoch [10/50], Step [626/735], Loss: 0.0309\n",
      "Epoch [10/50], Step [627/735], Loss: 0.1252\n",
      "Epoch [10/50], Step [628/735], Loss: 0.0743\n",
      "Epoch [10/50], Step [629/735], Loss: 0.1579\n",
      "Epoch [10/50], Step [630/735], Loss: 0.0711\n",
      "Epoch [10/50], Step [631/735], Loss: 0.0452\n",
      "Epoch [10/50], Step [632/735], Loss: 0.1900\n",
      "Epoch [10/50], Step [633/735], Loss: 0.2592\n",
      "Epoch [10/50], Step [634/735], Loss: 0.0656\n",
      "Epoch [10/50], Step [635/735], Loss: 0.0301\n",
      "Epoch [10/50], Step [636/735], Loss: 0.0623\n",
      "Epoch [10/50], Step [637/735], Loss: 0.1148\n",
      "Epoch [10/50], Step [638/735], Loss: 0.0625\n",
      "Epoch [10/50], Step [639/735], Loss: 0.0327\n",
      "Epoch [10/50], Step [640/735], Loss: 0.0734\n",
      "Epoch [10/50], Step [641/735], Loss: 0.0437\n",
      "Epoch [10/50], Step [642/735], Loss: 0.0460\n",
      "Epoch [10/50], Step [643/735], Loss: 0.0445\n",
      "Epoch [10/50], Step [644/735], Loss: 0.0613\n",
      "Epoch [10/50], Step [645/735], Loss: 0.6379\n",
      "Epoch [10/50], Step [646/735], Loss: 0.1132\n",
      "Epoch [10/50], Step [647/735], Loss: 0.1051\n",
      "Epoch [10/50], Step [648/735], Loss: 0.1818\n",
      "Epoch [10/50], Step [649/735], Loss: 0.1270\n",
      "Epoch [10/50], Step [650/735], Loss: 0.0545\n",
      "Epoch [10/50], Step [651/735], Loss: 0.1396\n",
      "Epoch [10/50], Step [652/735], Loss: 0.1271\n",
      "Epoch [10/50], Step [653/735], Loss: 0.1650\n",
      "Epoch [10/50], Step [654/735], Loss: 0.0967\n",
      "Epoch [10/50], Step [655/735], Loss: 0.0378\n",
      "Epoch [10/50], Step [656/735], Loss: 0.0529\n",
      "Epoch [10/50], Step [657/735], Loss: 0.1585\n",
      "Epoch [10/50], Step [658/735], Loss: 0.0999\n",
      "Epoch [10/50], Step [659/735], Loss: 0.0713\n",
      "Epoch [10/50], Step [660/735], Loss: 0.0581\n",
      "Epoch [10/50], Step [661/735], Loss: 0.1080\n",
      "Epoch [10/50], Step [662/735], Loss: 0.0247\n",
      "Epoch [10/50], Step [663/735], Loss: 0.1976\n",
      "Epoch [10/50], Step [664/735], Loss: 0.1526\n",
      "Epoch [10/50], Step [665/735], Loss: 0.0691\n",
      "Epoch [10/50], Step [666/735], Loss: 0.1088\n",
      "Epoch [10/50], Step [667/735], Loss: 0.1436\n",
      "Epoch [10/50], Step [668/735], Loss: 0.0668\n",
      "Epoch [10/50], Step [669/735], Loss: 0.2301\n",
      "Epoch [10/50], Step [670/735], Loss: 0.1133\n",
      "Epoch [10/50], Step [671/735], Loss: 0.0576\n",
      "Epoch [10/50], Step [672/735], Loss: 0.1553\n",
      "Epoch [10/50], Step [673/735], Loss: 0.0852\n",
      "Epoch [10/50], Step [674/735], Loss: 0.0977\n",
      "Epoch [10/50], Step [675/735], Loss: 0.0877\n",
      "Epoch [10/50], Step [676/735], Loss: 0.0462\n",
      "Epoch [10/50], Step [677/735], Loss: 0.1129\n",
      "Epoch [10/50], Step [678/735], Loss: 0.1585\n",
      "Epoch [10/50], Step [679/735], Loss: 0.2434\n",
      "Epoch [10/50], Step [680/735], Loss: 0.1272\n",
      "Epoch [10/50], Step [681/735], Loss: 0.1914\n",
      "Epoch [10/50], Step [682/735], Loss: 0.1149\n",
      "Epoch [10/50], Step [683/735], Loss: 0.0458\n",
      "Epoch [10/50], Step [684/735], Loss: 0.0551\n",
      "Epoch [10/50], Step [685/735], Loss: 0.1447\n",
      "Epoch [10/50], Step [686/735], Loss: 0.0308\n",
      "Epoch [10/50], Step [687/735], Loss: 0.1000\n",
      "Epoch [10/50], Step [688/735], Loss: 0.0372\n",
      "Epoch [10/50], Step [689/735], Loss: 0.0202\n",
      "Epoch [10/50], Step [690/735], Loss: 0.0453\n",
      "Epoch [10/50], Step [691/735], Loss: 0.0402\n",
      "Epoch [10/50], Step [692/735], Loss: 0.0775\n",
      "Epoch [10/50], Step [693/735], Loss: 0.2167\n",
      "Epoch [10/50], Step [694/735], Loss: 0.0585\n",
      "Epoch [10/50], Step [695/735], Loss: 0.0304\n",
      "Epoch [10/50], Step [696/735], Loss: 0.0471\n",
      "Epoch [10/50], Step [697/735], Loss: 0.0300\n",
      "Epoch [10/50], Step [698/735], Loss: 0.0529\n",
      "Epoch [10/50], Step [699/735], Loss: 0.1033\n",
      "Epoch [10/50], Step [700/735], Loss: 0.1733\n",
      "Epoch [10/50], Step [701/735], Loss: 0.0525\n",
      "Epoch [10/50], Step [702/735], Loss: 0.0376\n",
      "Epoch [10/50], Step [703/735], Loss: 0.0648\n",
      "Epoch [10/50], Step [704/735], Loss: 0.0543\n",
      "Epoch [10/50], Step [705/735], Loss: 0.1131\n",
      "Epoch [10/50], Step [706/735], Loss: 0.1238\n",
      "Epoch [10/50], Step [707/735], Loss: 0.0868\n",
      "Epoch [10/50], Step [708/735], Loss: 0.0923\n",
      "Epoch [10/50], Step [709/735], Loss: 0.3904\n",
      "Epoch [10/50], Step [710/735], Loss: 0.0492\n",
      "Epoch [10/50], Step [711/735], Loss: 0.0318\n",
      "Epoch [10/50], Step [712/735], Loss: 0.2586\n",
      "Epoch [10/50], Step [713/735], Loss: 0.0276\n",
      "Epoch [10/50], Step [714/735], Loss: 0.0759\n",
      "Epoch [10/50], Step [715/735], Loss: 0.1162\n",
      "Epoch [10/50], Step [716/735], Loss: 0.0542\n",
      "Epoch [10/50], Step [717/735], Loss: 0.1039\n",
      "Epoch [10/50], Step [718/735], Loss: 0.0782\n",
      "Epoch [10/50], Step [719/735], Loss: 0.0570\n",
      "Epoch [10/50], Step [720/735], Loss: 0.0345\n",
      "Epoch [10/50], Step [721/735], Loss: 0.0478\n",
      "Epoch [10/50], Step [722/735], Loss: 0.1084\n",
      "Epoch [10/50], Step [723/735], Loss: 0.1074\n",
      "Epoch [10/50], Step [724/735], Loss: 0.1441\n",
      "Epoch [10/50], Step [725/735], Loss: 0.0505\n",
      "Epoch [10/50], Step [726/735], Loss: 0.0329\n",
      "Epoch [10/50], Step [727/735], Loss: 0.0422\n",
      "Epoch [10/50], Step [728/735], Loss: 0.0625\n",
      "Epoch [10/50], Step [729/735], Loss: 0.0998\n",
      "Epoch [10/50], Step [730/735], Loss: 0.2156\n",
      "Epoch [10/50], Step [731/735], Loss: 0.2224\n",
      "Epoch [10/50], Step [732/735], Loss: 0.1248\n",
      "Epoch [10/50], Step [733/735], Loss: 0.0891\n",
      "Epoch [10/50], Step [734/735], Loss: 0.0550\n",
      "Epoch [10/50], Step [735/735], Loss: 0.0489\n",
      "Epoch [11/50], Step [1/735], Loss: 0.2946\n",
      "Epoch [11/50], Step [2/735], Loss: 0.1581\n",
      "Epoch [11/50], Step [3/735], Loss: 0.1997\n",
      "Epoch [11/50], Step [4/735], Loss: 0.1018\n",
      "Epoch [11/50], Step [5/735], Loss: 0.0507\n",
      "Epoch [11/50], Step [6/735], Loss: 0.0670\n",
      "Epoch [11/50], Step [7/735], Loss: 0.1165\n",
      "Epoch [11/50], Step [8/735], Loss: 0.0212\n",
      "Epoch [11/50], Step [9/735], Loss: 0.0588\n",
      "Epoch [11/50], Step [10/735], Loss: 0.0734\n",
      "Epoch [11/50], Step [11/735], Loss: 0.1080\n",
      "Epoch [11/50], Step [12/735], Loss: 0.0380\n",
      "Epoch [11/50], Step [13/735], Loss: 0.0423\n",
      "Epoch [11/50], Step [14/735], Loss: 0.0617\n",
      "Epoch [11/50], Step [15/735], Loss: 0.0231\n",
      "Epoch [11/50], Step [16/735], Loss: 0.5822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Step [17/735], Loss: 0.2837\n",
      "Epoch [11/50], Step [18/735], Loss: 0.0449\n",
      "Epoch [11/50], Step [19/735], Loss: 0.1088\n",
      "Epoch [11/50], Step [20/735], Loss: 0.2137\n",
      "Epoch [11/50], Step [21/735], Loss: 0.0802\n",
      "Epoch [11/50], Step [22/735], Loss: 0.0342\n",
      "Epoch [11/50], Step [23/735], Loss: 0.0486\n",
      "Epoch [11/50], Step [24/735], Loss: 0.0411\n",
      "Epoch [11/50], Step [25/735], Loss: 0.0658\n",
      "Epoch [11/50], Step [26/735], Loss: 0.0860\n",
      "Epoch [11/50], Step [27/735], Loss: 0.1471\n",
      "Epoch [11/50], Step [28/735], Loss: 0.1469\n",
      "Epoch [11/50], Step [29/735], Loss: 0.1513\n",
      "Epoch [11/50], Step [30/735], Loss: 0.1667\n",
      "Epoch [11/50], Step [31/735], Loss: 0.0461\n",
      "Epoch [11/50], Step [32/735], Loss: 0.0537\n",
      "Epoch [11/50], Step [33/735], Loss: 0.1901\n",
      "Epoch [11/50], Step [34/735], Loss: 0.1072\n",
      "Epoch [11/50], Step [35/735], Loss: 0.1981\n",
      "Epoch [11/50], Step [36/735], Loss: 0.1037\n",
      "Epoch [11/50], Step [37/735], Loss: 0.1465\n",
      "Epoch [11/50], Step [38/735], Loss: 0.1443\n",
      "Epoch [11/50], Step [39/735], Loss: 0.0616\n",
      "Epoch [11/50], Step [40/735], Loss: 0.1128\n",
      "Epoch [11/50], Step [41/735], Loss: 0.0551\n",
      "Epoch [11/50], Step [42/735], Loss: 0.0983\n",
      "Epoch [11/50], Step [43/735], Loss: 0.0335\n",
      "Epoch [11/50], Step [44/735], Loss: 0.0671\n",
      "Epoch [11/50], Step [45/735], Loss: 0.0302\n",
      "Epoch [11/50], Step [46/735], Loss: 0.2133\n",
      "Epoch [11/50], Step [47/735], Loss: 0.0196\n",
      "Epoch [11/50], Step [48/735], Loss: 0.1375\n",
      "Epoch [11/50], Step [49/735], Loss: 0.1593\n",
      "Epoch [11/50], Step [50/735], Loss: 0.0602\n",
      "Epoch [11/50], Step [51/735], Loss: 0.0642\n",
      "Epoch [11/50], Step [52/735], Loss: 0.0243\n",
      "Epoch [11/50], Step [53/735], Loss: 0.0479\n",
      "Epoch [11/50], Step [54/735], Loss: 0.0869\n",
      "Epoch [11/50], Step [55/735], Loss: 0.1441\n",
      "Epoch [11/50], Step [56/735], Loss: 0.0823\n",
      "Epoch [11/50], Step [57/735], Loss: 0.1300\n",
      "Epoch [11/50], Step [58/735], Loss: 0.1440\n",
      "Epoch [11/50], Step [59/735], Loss: 0.1630\n",
      "Epoch [11/50], Step [60/735], Loss: 0.0427\n",
      "Epoch [11/50], Step [61/735], Loss: 0.0332\n",
      "Epoch [11/50], Step [62/735], Loss: 0.0532\n",
      "Epoch [11/50], Step [63/735], Loss: 0.0355\n",
      "Epoch [11/50], Step [64/735], Loss: 0.0557\n",
      "Epoch [11/50], Step [65/735], Loss: 0.0556\n",
      "Epoch [11/50], Step [66/735], Loss: 0.0372\n",
      "Epoch [11/50], Step [67/735], Loss: 0.0256\n",
      "Epoch [11/50], Step [68/735], Loss: 0.0195\n",
      "Epoch [11/50], Step [69/735], Loss: 0.1436\n",
      "Epoch [11/50], Step [70/735], Loss: 0.0714\n",
      "Epoch [11/50], Step [71/735], Loss: 0.3800\n",
      "Epoch [11/50], Step [72/735], Loss: 0.1133\n",
      "Epoch [11/50], Step [73/735], Loss: 0.0408\n",
      "Epoch [11/50], Step [74/735], Loss: 0.0872\n",
      "Epoch [11/50], Step [75/735], Loss: 0.0711\n",
      "Epoch [11/50], Step [76/735], Loss: 0.1579\n",
      "Epoch [11/50], Step [77/735], Loss: 0.0756\n",
      "Epoch [11/50], Step [78/735], Loss: 0.2267\n",
      "Epoch [11/50], Step [79/735], Loss: 0.0546\n",
      "Epoch [11/50], Step [80/735], Loss: 0.0464\n",
      "Epoch [11/50], Step [81/735], Loss: 0.0680\n",
      "Epoch [11/50], Step [82/735], Loss: 0.2304\n",
      "Epoch [11/50], Step [83/735], Loss: 0.1190\n",
      "Epoch [11/50], Step [84/735], Loss: 0.0651\n",
      "Epoch [11/50], Step [85/735], Loss: 0.0323\n",
      "Epoch [11/50], Step [86/735], Loss: 0.1792\n",
      "Epoch [11/50], Step [87/735], Loss: 0.1119\n",
      "Epoch [11/50], Step [88/735], Loss: 0.0446\n",
      "Epoch [11/50], Step [89/735], Loss: 0.0334\n",
      "Epoch [11/50], Step [90/735], Loss: 0.0450\n",
      "Epoch [11/50], Step [91/735], Loss: 0.0772\n",
      "Epoch [11/50], Step [92/735], Loss: 0.1083\n",
      "Epoch [11/50], Step [93/735], Loss: 0.1251\n",
      "Epoch [11/50], Step [94/735], Loss: 0.0631\n",
      "Epoch [11/50], Step [95/735], Loss: 0.0384\n",
      "Epoch [11/50], Step [96/735], Loss: 0.0856\n",
      "Epoch [11/50], Step [97/735], Loss: 0.0153\n",
      "Epoch [11/50], Step [98/735], Loss: 0.1096\n",
      "Epoch [11/50], Step [99/735], Loss: 0.0330\n",
      "Epoch [11/50], Step [100/735], Loss: 0.0850\n",
      "Epoch [11/50], Step [101/735], Loss: 0.0965\n",
      "Epoch [11/50], Step [102/735], Loss: 0.0300\n",
      "Epoch [11/50], Step [103/735], Loss: 0.0856\n",
      "Epoch [11/50], Step [104/735], Loss: 0.1617\n",
      "Epoch [11/50], Step [105/735], Loss: 0.0836\n",
      "Epoch [11/50], Step [106/735], Loss: 0.0922\n",
      "Epoch [11/50], Step [107/735], Loss: 0.0726\n",
      "Epoch [11/50], Step [108/735], Loss: 0.0454\n",
      "Epoch [11/50], Step [109/735], Loss: 0.0622\n",
      "Epoch [11/50], Step [110/735], Loss: 0.1172\n",
      "Epoch [11/50], Step [111/735], Loss: 0.0903\n",
      "Epoch [11/50], Step [112/735], Loss: 0.1149\n",
      "Epoch [11/50], Step [113/735], Loss: 0.0583\n",
      "Epoch [11/50], Step [114/735], Loss: 0.1496\n",
      "Epoch [11/50], Step [115/735], Loss: 0.0354\n",
      "Epoch [11/50], Step [116/735], Loss: 0.1850\n",
      "Epoch [11/50], Step [117/735], Loss: 0.2003\n",
      "Epoch [11/50], Step [118/735], Loss: 0.0247\n",
      "Epoch [11/50], Step [119/735], Loss: 0.2141\n",
      "Epoch [11/50], Step [120/735], Loss: 0.0435\n",
      "Epoch [11/50], Step [121/735], Loss: 0.0351\n",
      "Epoch [11/50], Step [122/735], Loss: 0.2308\n",
      "Epoch [11/50], Step [123/735], Loss: 0.0572\n",
      "Epoch [11/50], Step [124/735], Loss: 0.0261\n",
      "Epoch [11/50], Step [125/735], Loss: 0.0747\n",
      "Epoch [11/50], Step [126/735], Loss: 0.0701\n",
      "Epoch [11/50], Step [127/735], Loss: 0.0768\n",
      "Epoch [11/50], Step [128/735], Loss: 0.0501\n",
      "Epoch [11/50], Step [129/735], Loss: 0.0284\n",
      "Epoch [11/50], Step [130/735], Loss: 0.0446\n",
      "Epoch [11/50], Step [131/735], Loss: 0.1021\n",
      "Epoch [11/50], Step [132/735], Loss: 0.1909\n",
      "Epoch [11/50], Step [133/735], Loss: 0.0621\n",
      "Epoch [11/50], Step [134/735], Loss: 0.0515\n",
      "Epoch [11/50], Step [135/735], Loss: 0.0966\n",
      "Epoch [11/50], Step [136/735], Loss: 0.0872\n",
      "Epoch [11/50], Step [137/735], Loss: 0.0722\n",
      "Epoch [11/50], Step [138/735], Loss: 0.2637\n",
      "Epoch [11/50], Step [139/735], Loss: 0.0314\n",
      "Epoch [11/50], Step [140/735], Loss: 0.4005\n",
      "Epoch [11/50], Step [141/735], Loss: 0.1722\n",
      "Epoch [11/50], Step [142/735], Loss: 0.0305\n",
      "Epoch [11/50], Step [143/735], Loss: 0.1193\n",
      "Epoch [11/50], Step [144/735], Loss: 0.0957\n",
      "Epoch [11/50], Step [145/735], Loss: 0.1012\n",
      "Epoch [11/50], Step [146/735], Loss: 0.0939\n",
      "Epoch [11/50], Step [147/735], Loss: 0.1256\n",
      "Epoch [11/50], Step [148/735], Loss: 0.2436\n",
      "Epoch [11/50], Step [149/735], Loss: 0.1457\n",
      "Epoch [11/50], Step [150/735], Loss: 0.1178\n",
      "Epoch [11/50], Step [151/735], Loss: 0.0395\n",
      "Epoch [11/50], Step [152/735], Loss: 0.0632\n",
      "Epoch [11/50], Step [153/735], Loss: 0.0704\n",
      "Epoch [11/50], Step [154/735], Loss: 0.3387\n",
      "Epoch [11/50], Step [155/735], Loss: 0.0829\n",
      "Epoch [11/50], Step [156/735], Loss: 0.2028\n",
      "Epoch [11/50], Step [157/735], Loss: 0.2925\n",
      "Epoch [11/50], Step [158/735], Loss: 0.1144\n",
      "Epoch [11/50], Step [159/735], Loss: 0.0546\n",
      "Epoch [11/50], Step [160/735], Loss: 0.1720\n",
      "Epoch [11/50], Step [161/735], Loss: 0.1506\n",
      "Epoch [11/50], Step [162/735], Loss: 0.1281\n",
      "Epoch [11/50], Step [163/735], Loss: 0.0867\n",
      "Epoch [11/50], Step [164/735], Loss: 0.2253\n",
      "Epoch [11/50], Step [165/735], Loss: 0.1162\n",
      "Epoch [11/50], Step [166/735], Loss: 0.0633\n",
      "Epoch [11/50], Step [167/735], Loss: 0.0531\n",
      "Epoch [11/50], Step [168/735], Loss: 0.0385\n",
      "Epoch [11/50], Step [169/735], Loss: 0.0437\n",
      "Epoch [11/50], Step [170/735], Loss: 0.0903\n",
      "Epoch [11/50], Step [171/735], Loss: 0.0948\n",
      "Epoch [11/50], Step [172/735], Loss: 0.1149\n",
      "Epoch [11/50], Step [173/735], Loss: 0.0820\n",
      "Epoch [11/50], Step [174/735], Loss: 0.0728\n",
      "Epoch [11/50], Step [175/735], Loss: 0.0529\n",
      "Epoch [11/50], Step [176/735], Loss: 0.0476\n",
      "Epoch [11/50], Step [177/735], Loss: 0.0482\n",
      "Epoch [11/50], Step [178/735], Loss: 0.0710\n",
      "Epoch [11/50], Step [179/735], Loss: 0.1244\n",
      "Epoch [11/50], Step [180/735], Loss: 0.0195\n",
      "Epoch [11/50], Step [181/735], Loss: 0.0614\n",
      "Epoch [11/50], Step [182/735], Loss: 0.0625\n",
      "Epoch [11/50], Step [183/735], Loss: 0.0747\n",
      "Epoch [11/50], Step [184/735], Loss: 0.1760\n",
      "Epoch [11/50], Step [185/735], Loss: 0.0603\n",
      "Epoch [11/50], Step [186/735], Loss: 0.0537\n",
      "Epoch [11/50], Step [187/735], Loss: 0.0940\n",
      "Epoch [11/50], Step [188/735], Loss: 0.0594\n",
      "Epoch [11/50], Step [189/735], Loss: 0.1150\n",
      "Epoch [11/50], Step [190/735], Loss: 0.1664\n",
      "Epoch [11/50], Step [191/735], Loss: 0.1131\n",
      "Epoch [11/50], Step [192/735], Loss: 0.0442\n",
      "Epoch [11/50], Step [193/735], Loss: 0.1135\n",
      "Epoch [11/50], Step [194/735], Loss: 0.0997\n",
      "Epoch [11/50], Step [195/735], Loss: 0.0869\n",
      "Epoch [11/50], Step [196/735], Loss: 0.1200\n",
      "Epoch [11/50], Step [197/735], Loss: 0.3264\n",
      "Epoch [11/50], Step [198/735], Loss: 0.0308\n",
      "Epoch [11/50], Step [199/735], Loss: 0.1299\n",
      "Epoch [11/50], Step [200/735], Loss: 0.0251\n",
      "Epoch [11/50], Step [201/735], Loss: 0.0440\n",
      "Epoch [11/50], Step [202/735], Loss: 0.0282\n",
      "Epoch [11/50], Step [203/735], Loss: 0.0493\n",
      "Epoch [11/50], Step [204/735], Loss: 0.2111\n",
      "Epoch [11/50], Step [205/735], Loss: 0.0720\n",
      "Epoch [11/50], Step [206/735], Loss: 0.0526\n",
      "Epoch [11/50], Step [207/735], Loss: 0.1372\n",
      "Epoch [11/50], Step [208/735], Loss: 0.1893\n",
      "Epoch [11/50], Step [209/735], Loss: 0.1417\n",
      "Epoch [11/50], Step [210/735], Loss: 0.5244\n",
      "Epoch [11/50], Step [211/735], Loss: 0.1064\n",
      "Epoch [11/50], Step [212/735], Loss: 0.0986\n",
      "Epoch [11/50], Step [213/735], Loss: 0.1219\n",
      "Epoch [11/50], Step [214/735], Loss: 0.1165\n",
      "Epoch [11/50], Step [215/735], Loss: 0.0972\n",
      "Epoch [11/50], Step [216/735], Loss: 0.0737\n",
      "Epoch [11/50], Step [217/735], Loss: 0.0928\n",
      "Epoch [11/50], Step [218/735], Loss: 0.1124\n",
      "Epoch [11/50], Step [219/735], Loss: 0.0598\n",
      "Epoch [11/50], Step [220/735], Loss: 0.1004\n",
      "Epoch [11/50], Step [221/735], Loss: 0.1001\n",
      "Epoch [11/50], Step [222/735], Loss: 0.3455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Step [223/735], Loss: 0.0352\n",
      "Epoch [11/50], Step [224/735], Loss: 0.3036\n",
      "Epoch [11/50], Step [225/735], Loss: 0.1722\n",
      "Epoch [11/50], Step [226/735], Loss: 0.1168\n",
      "Epoch [11/50], Step [227/735], Loss: 0.0526\n",
      "Epoch [11/50], Step [228/735], Loss: 0.0778\n",
      "Epoch [11/50], Step [229/735], Loss: 0.0234\n",
      "Epoch [11/50], Step [230/735], Loss: 0.0520\n",
      "Epoch [11/50], Step [231/735], Loss: 0.0371\n",
      "Epoch [11/50], Step [232/735], Loss: 0.1331\n",
      "Epoch [11/50], Step [233/735], Loss: 0.1461\n",
      "Epoch [11/50], Step [234/735], Loss: 0.0292\n",
      "Epoch [11/50], Step [235/735], Loss: 0.0606\n",
      "Epoch [11/50], Step [236/735], Loss: 0.0425\n",
      "Epoch [11/50], Step [237/735], Loss: 0.2644\n",
      "Epoch [11/50], Step [238/735], Loss: 0.0725\n",
      "Epoch [11/50], Step [239/735], Loss: 0.0662\n",
      "Epoch [11/50], Step [240/735], Loss: 0.1141\n",
      "Epoch [11/50], Step [241/735], Loss: 0.0811\n",
      "Epoch [11/50], Step [242/735], Loss: 0.1231\n",
      "Epoch [11/50], Step [243/735], Loss: 0.0497\n",
      "Epoch [11/50], Step [244/735], Loss: 0.0480\n",
      "Epoch [11/50], Step [245/735], Loss: 0.0865\n",
      "Epoch [11/50], Step [246/735], Loss: 0.0270\n",
      "Epoch [11/50], Step [247/735], Loss: 0.0747\n",
      "Epoch [11/50], Step [248/735], Loss: 0.0733\n",
      "Epoch [11/50], Step [249/735], Loss: 0.2822\n",
      "Epoch [11/50], Step [250/735], Loss: 0.0177\n",
      "Epoch [11/50], Step [251/735], Loss: 0.5507\n",
      "Epoch [11/50], Step [252/735], Loss: 0.0797\n",
      "Epoch [11/50], Step [253/735], Loss: 0.1168\n",
      "Epoch [11/50], Step [254/735], Loss: 0.1070\n",
      "Epoch [11/50], Step [255/735], Loss: 0.1204\n",
      "Epoch [11/50], Step [256/735], Loss: 0.0515\n",
      "Epoch [11/50], Step [257/735], Loss: 0.0532\n",
      "Epoch [11/50], Step [258/735], Loss: 0.0368\n",
      "Epoch [11/50], Step [259/735], Loss: 0.0746\n",
      "Epoch [11/50], Step [260/735], Loss: 0.0468\n",
      "Epoch [11/50], Step [261/735], Loss: 0.0607\n",
      "Epoch [11/50], Step [262/735], Loss: 0.0605\n",
      "Epoch [11/50], Step [263/735], Loss: 0.3382\n",
      "Epoch [11/50], Step [264/735], Loss: 0.1967\n",
      "Epoch [11/50], Step [265/735], Loss: 0.0284\n",
      "Epoch [11/50], Step [266/735], Loss: 0.0483\n",
      "Epoch [11/50], Step [267/735], Loss: 0.0463\n",
      "Epoch [11/50], Step [268/735], Loss: 0.1809\n",
      "Epoch [11/50], Step [269/735], Loss: 0.0412\n",
      "Epoch [11/50], Step [270/735], Loss: 0.0451\n",
      "Epoch [11/50], Step [271/735], Loss: 0.0215\n",
      "Epoch [11/50], Step [272/735], Loss: 0.0777\n",
      "Epoch [11/50], Step [273/735], Loss: 0.0326\n",
      "Epoch [11/50], Step [274/735], Loss: 0.0452\n",
      "Epoch [11/50], Step [275/735], Loss: 0.2560\n",
      "Epoch [11/50], Step [276/735], Loss: 0.3060\n",
      "Epoch [11/50], Step [277/735], Loss: 0.0316\n",
      "Epoch [11/50], Step [278/735], Loss: 0.0306\n",
      "Epoch [11/50], Step [279/735], Loss: 0.0784\n",
      "Epoch [11/50], Step [280/735], Loss: 0.0335\n",
      "Epoch [11/50], Step [281/735], Loss: 0.0480\n",
      "Epoch [11/50], Step [282/735], Loss: 0.1156\n",
      "Epoch [11/50], Step [283/735], Loss: 0.1708\n",
      "Epoch [11/50], Step [284/735], Loss: 0.1698\n",
      "Epoch [11/50], Step [285/735], Loss: 0.0804\n",
      "Epoch [11/50], Step [286/735], Loss: 0.1655\n",
      "Epoch [11/50], Step [287/735], Loss: 0.0355\n",
      "Epoch [11/50], Step [288/735], Loss: 0.3351\n",
      "Epoch [11/50], Step [289/735], Loss: 0.1183\n",
      "Epoch [11/50], Step [290/735], Loss: 0.0510\n",
      "Epoch [11/50], Step [291/735], Loss: 0.0550\n",
      "Epoch [11/50], Step [292/735], Loss: 0.1933\n",
      "Epoch [11/50], Step [293/735], Loss: 0.0668\n",
      "Epoch [11/50], Step [294/735], Loss: 0.1206\n",
      "Epoch [11/50], Step [295/735], Loss: 0.1174\n",
      "Epoch [11/50], Step [296/735], Loss: 0.0729\n",
      "Epoch [11/50], Step [297/735], Loss: 0.0424\n",
      "Epoch [11/50], Step [298/735], Loss: 0.0378\n",
      "Epoch [11/50], Step [299/735], Loss: 0.1206\n",
      "Epoch [11/50], Step [300/735], Loss: 0.2597\n",
      "Epoch [11/50], Step [301/735], Loss: 0.1406\n",
      "Epoch [11/50], Step [302/735], Loss: 0.1074\n",
      "Epoch [11/50], Step [303/735], Loss: 0.1549\n",
      "Epoch [11/50], Step [304/735], Loss: 0.0681\n",
      "Epoch [11/50], Step [305/735], Loss: 0.0368\n",
      "Epoch [11/50], Step [306/735], Loss: 0.0467\n",
      "Epoch [11/50], Step [307/735], Loss: 0.0420\n",
      "Epoch [11/50], Step [308/735], Loss: 0.1276\n",
      "Epoch [11/50], Step [309/735], Loss: 0.2185\n",
      "Epoch [11/50], Step [310/735], Loss: 0.0876\n",
      "Epoch [11/50], Step [311/735], Loss: 0.2674\n",
      "Epoch [11/50], Step [312/735], Loss: 0.0437\n",
      "Epoch [11/50], Step [313/735], Loss: 0.0609\n",
      "Epoch [11/50], Step [314/735], Loss: 0.3575\n",
      "Epoch [11/50], Step [315/735], Loss: 0.2991\n",
      "Epoch [11/50], Step [316/735], Loss: 0.0692\n",
      "Epoch [11/50], Step [317/735], Loss: 0.0233\n",
      "Epoch [11/50], Step [318/735], Loss: 0.0817\n",
      "Epoch [11/50], Step [319/735], Loss: 0.0765\n",
      "Epoch [11/50], Step [320/735], Loss: 0.0573\n",
      "Epoch [11/50], Step [321/735], Loss: 0.2168\n",
      "Epoch [11/50], Step [322/735], Loss: 0.1718\n",
      "Epoch [11/50], Step [323/735], Loss: 0.1273\n",
      "Epoch [11/50], Step [324/735], Loss: 0.0371\n",
      "Epoch [11/50], Step [325/735], Loss: 0.1008\n",
      "Epoch [11/50], Step [326/735], Loss: 0.0476\n",
      "Epoch [11/50], Step [327/735], Loss: 0.2602\n",
      "Epoch [11/50], Step [328/735], Loss: 0.0419\n",
      "Epoch [11/50], Step [329/735], Loss: 0.0345\n",
      "Epoch [11/50], Step [330/735], Loss: 0.0710\n",
      "Epoch [11/50], Step [331/735], Loss: 0.0877\n",
      "Epoch [11/50], Step [332/735], Loss: 0.1347\n",
      "Epoch [11/50], Step [333/735], Loss: 0.1107\n",
      "Epoch [11/50], Step [334/735], Loss: 0.0587\n",
      "Epoch [11/50], Step [335/735], Loss: 0.0643\n",
      "Epoch [11/50], Step [336/735], Loss: 0.3184\n",
      "Epoch [11/50], Step [337/735], Loss: 0.0752\n",
      "Epoch [11/50], Step [338/735], Loss: 0.4026\n",
      "Epoch [11/50], Step [339/735], Loss: 0.0310\n",
      "Epoch [11/50], Step [340/735], Loss: 0.1019\n",
      "Epoch [11/50], Step [341/735], Loss: 0.0419\n",
      "Epoch [11/50], Step [342/735], Loss: 0.0698\n",
      "Epoch [11/50], Step [343/735], Loss: 0.0668\n",
      "Epoch [11/50], Step [344/735], Loss: 0.1005\n",
      "Epoch [11/50], Step [345/735], Loss: 0.0452\n",
      "Epoch [11/50], Step [346/735], Loss: 0.0465\n",
      "Epoch [11/50], Step [347/735], Loss: 0.1345\n",
      "Epoch [11/50], Step [348/735], Loss: 0.0694\n",
      "Epoch [11/50], Step [349/735], Loss: 0.0565\n",
      "Epoch [11/50], Step [350/735], Loss: 0.0627\n",
      "Epoch [11/50], Step [351/735], Loss: 0.0789\n",
      "Epoch [11/50], Step [352/735], Loss: 0.1916\n",
      "Epoch [11/50], Step [353/735], Loss: 0.1186\n",
      "Epoch [11/50], Step [354/735], Loss: 0.1081\n",
      "Epoch [11/50], Step [355/735], Loss: 0.0366\n",
      "Epoch [11/50], Step [356/735], Loss: 0.1544\n",
      "Epoch [11/50], Step [357/735], Loss: 0.1866\n",
      "Epoch [11/50], Step [358/735], Loss: 0.1544\n",
      "Epoch [11/50], Step [359/735], Loss: 0.0965\n",
      "Epoch [11/50], Step [360/735], Loss: 0.1553\n",
      "Epoch [11/50], Step [361/735], Loss: 0.1723\n",
      "Epoch [11/50], Step [362/735], Loss: 0.1142\n",
      "Epoch [11/50], Step [363/735], Loss: 0.3096\n",
      "Epoch [11/50], Step [364/735], Loss: 0.1257\n",
      "Epoch [11/50], Step [365/735], Loss: 0.0682\n",
      "Epoch [11/50], Step [366/735], Loss: 0.0418\n",
      "Epoch [11/50], Step [367/735], Loss: 0.1328\n",
      "Epoch [11/50], Step [368/735], Loss: 0.0882\n",
      "Epoch [11/50], Step [369/735], Loss: 0.0424\n",
      "Epoch [11/50], Step [370/735], Loss: 0.0453\n",
      "Epoch [11/50], Step [371/735], Loss: 0.0889\n",
      "Epoch [11/50], Step [372/735], Loss: 0.1327\n",
      "Epoch [11/50], Step [373/735], Loss: 0.0327\n",
      "Epoch [11/50], Step [374/735], Loss: 0.0219\n",
      "Epoch [11/50], Step [375/735], Loss: 0.0832\n",
      "Epoch [11/50], Step [376/735], Loss: 0.2510\n",
      "Epoch [11/50], Step [377/735], Loss: 0.1716\n",
      "Epoch [11/50], Step [378/735], Loss: 0.0228\n",
      "Epoch [11/50], Step [379/735], Loss: 0.1126\n",
      "Epoch [11/50], Step [380/735], Loss: 0.0676\n",
      "Epoch [11/50], Step [381/735], Loss: 0.0877\n",
      "Epoch [11/50], Step [382/735], Loss: 0.1137\n",
      "Epoch [11/50], Step [383/735], Loss: 0.0799\n",
      "Epoch [11/50], Step [384/735], Loss: 0.0652\n",
      "Epoch [11/50], Step [385/735], Loss: 0.0375\n",
      "Epoch [11/50], Step [386/735], Loss: 0.0507\n",
      "Epoch [11/50], Step [387/735], Loss: 0.0442\n",
      "Epoch [11/50], Step [388/735], Loss: 0.1598\n",
      "Epoch [11/50], Step [389/735], Loss: 0.2151\n",
      "Epoch [11/50], Step [390/735], Loss: 0.1011\n",
      "Epoch [11/50], Step [391/735], Loss: 0.0466\n",
      "Epoch [11/50], Step [392/735], Loss: 0.1766\n",
      "Epoch [11/50], Step [393/735], Loss: 0.0700\n",
      "Epoch [11/50], Step [394/735], Loss: 0.0634\n",
      "Epoch [11/50], Step [395/735], Loss: 0.1647\n",
      "Epoch [11/50], Step [396/735], Loss: 0.0358\n",
      "Epoch [11/50], Step [397/735], Loss: 0.1320\n",
      "Epoch [11/50], Step [398/735], Loss: 0.0334\n",
      "Epoch [11/50], Step [399/735], Loss: 0.0526\n",
      "Epoch [11/50], Step [400/735], Loss: 0.1537\n",
      "Epoch [11/50], Step [401/735], Loss: 0.1455\n",
      "Epoch [11/50], Step [402/735], Loss: 0.0876\n",
      "Epoch [11/50], Step [403/735], Loss: 0.0662\n",
      "Epoch [11/50], Step [404/735], Loss: 0.0623\n",
      "Epoch [11/50], Step [405/735], Loss: 0.0898\n",
      "Epoch [11/50], Step [406/735], Loss: 0.0300\n",
      "Epoch [11/50], Step [407/735], Loss: 0.0846\n",
      "Epoch [11/50], Step [408/735], Loss: 0.0897\n",
      "Epoch [11/50], Step [409/735], Loss: 0.0192\n",
      "Epoch [11/50], Step [410/735], Loss: 0.2010\n",
      "Epoch [11/50], Step [411/735], Loss: 0.0217\n",
      "Epoch [11/50], Step [412/735], Loss: 0.0341\n",
      "Epoch [11/50], Step [413/735], Loss: 0.3314\n",
      "Epoch [11/50], Step [414/735], Loss: 0.3650\n",
      "Epoch [11/50], Step [415/735], Loss: 0.2614\n",
      "Epoch [11/50], Step [416/735], Loss: 0.0170\n",
      "Epoch [11/50], Step [417/735], Loss: 0.0435\n",
      "Epoch [11/50], Step [418/735], Loss: 0.0523\n",
      "Epoch [11/50], Step [419/735], Loss: 0.1626\n",
      "Epoch [11/50], Step [420/735], Loss: 0.0383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Step [421/735], Loss: 0.0511\n",
      "Epoch [11/50], Step [422/735], Loss: 0.1482\n",
      "Epoch [11/50], Step [423/735], Loss: 0.3778\n",
      "Epoch [11/50], Step [424/735], Loss: 0.4742\n",
      "Epoch [11/50], Step [425/735], Loss: 0.0830\n",
      "Epoch [11/50], Step [426/735], Loss: 0.1896\n",
      "Epoch [11/50], Step [427/735], Loss: 0.1337\n",
      "Epoch [11/50], Step [428/735], Loss: 0.1128\n",
      "Epoch [11/50], Step [429/735], Loss: 0.0900\n",
      "Epoch [11/50], Step [430/735], Loss: 0.0365\n",
      "Epoch [11/50], Step [431/735], Loss: 0.1014\n",
      "Epoch [11/50], Step [432/735], Loss: 0.0497\n",
      "Epoch [11/50], Step [433/735], Loss: 0.2229\n",
      "Epoch [11/50], Step [434/735], Loss: 0.2224\n",
      "Epoch [11/50], Step [435/735], Loss: 0.0836\n",
      "Epoch [11/50], Step [436/735], Loss: 0.0700\n",
      "Epoch [11/50], Step [437/735], Loss: 0.0853\n",
      "Epoch [11/50], Step [438/735], Loss: 0.0519\n",
      "Epoch [11/50], Step [439/735], Loss: 0.1371\n",
      "Epoch [11/50], Step [440/735], Loss: 0.1420\n",
      "Epoch [11/50], Step [441/735], Loss: 0.1392\n",
      "Epoch [11/50], Step [442/735], Loss: 0.1194\n",
      "Epoch [11/50], Step [443/735], Loss: 0.1341\n",
      "Epoch [11/50], Step [444/735], Loss: 0.1718\n",
      "Epoch [11/50], Step [445/735], Loss: 0.0268\n",
      "Epoch [11/50], Step [446/735], Loss: 0.0692\n",
      "Epoch [11/50], Step [447/735], Loss: 0.0267\n",
      "Epoch [11/50], Step [448/735], Loss: 0.0796\n",
      "Epoch [11/50], Step [449/735], Loss: 0.0691\n",
      "Epoch [11/50], Step [450/735], Loss: 0.1348\n",
      "Epoch [11/50], Step [451/735], Loss: 0.0626\n",
      "Epoch [11/50], Step [452/735], Loss: 0.2221\n",
      "Epoch [11/50], Step [453/735], Loss: 0.0229\n",
      "Epoch [11/50], Step [454/735], Loss: 0.0893\n",
      "Epoch [11/50], Step [455/735], Loss: 0.1065\n",
      "Epoch [11/50], Step [456/735], Loss: 0.1159\n",
      "Epoch [11/50], Step [457/735], Loss: 0.0594\n",
      "Epoch [11/50], Step [458/735], Loss: 0.0390\n",
      "Epoch [11/50], Step [459/735], Loss: 0.0634\n",
      "Epoch [11/50], Step [460/735], Loss: 0.0690\n",
      "Epoch [11/50], Step [461/735], Loss: 0.1294\n",
      "Epoch [11/50], Step [462/735], Loss: 0.0223\n",
      "Epoch [11/50], Step [463/735], Loss: 0.1881\n",
      "Epoch [11/50], Step [464/735], Loss: 0.0281\n",
      "Epoch [11/50], Step [465/735], Loss: 0.1444\n",
      "Epoch [11/50], Step [466/735], Loss: 0.0608\n",
      "Epoch [11/50], Step [467/735], Loss: 0.0853\n",
      "Epoch [11/50], Step [468/735], Loss: 0.0959\n",
      "Epoch [11/50], Step [469/735], Loss: 0.0288\n",
      "Epoch [11/50], Step [470/735], Loss: 0.0444\n",
      "Epoch [11/50], Step [471/735], Loss: 0.1476\n",
      "Epoch [11/50], Step [472/735], Loss: 0.1427\n",
      "Epoch [11/50], Step [473/735], Loss: 0.2445\n",
      "Epoch [11/50], Step [474/735], Loss: 0.0357\n",
      "Epoch [11/50], Step [475/735], Loss: 0.0756\n",
      "Epoch [11/50], Step [476/735], Loss: 0.2368\n",
      "Epoch [11/50], Step [477/735], Loss: 0.0573\n",
      "Epoch [11/50], Step [478/735], Loss: 0.1986\n",
      "Epoch [11/50], Step [479/735], Loss: 0.1017\n",
      "Epoch [11/50], Step [480/735], Loss: 0.0549\n",
      "Epoch [11/50], Step [481/735], Loss: 0.2644\n",
      "Epoch [11/50], Step [482/735], Loss: 0.1287\n",
      "Epoch [11/50], Step [483/735], Loss: 0.1038\n",
      "Epoch [11/50], Step [484/735], Loss: 0.0640\n",
      "Epoch [11/50], Step [485/735], Loss: 0.0280\n",
      "Epoch [11/50], Step [486/735], Loss: 0.0831\n",
      "Epoch [11/50], Step [487/735], Loss: 0.0416\n",
      "Epoch [11/50], Step [488/735], Loss: 0.0475\n",
      "Epoch [11/50], Step [489/735], Loss: 0.2129\n",
      "Epoch [11/50], Step [490/735], Loss: 0.0670\n",
      "Epoch [11/50], Step [491/735], Loss: 0.1471\n",
      "Epoch [11/50], Step [492/735], Loss: 0.1184\n",
      "Epoch [11/50], Step [493/735], Loss: 0.1066\n",
      "Epoch [11/50], Step [494/735], Loss: 0.0237\n",
      "Epoch [11/50], Step [495/735], Loss: 0.0716\n",
      "Epoch [11/50], Step [496/735], Loss: 0.1108\n",
      "Epoch [11/50], Step [497/735], Loss: 0.2413\n",
      "Epoch [11/50], Step [498/735], Loss: 0.0372\n",
      "Epoch [11/50], Step [499/735], Loss: 0.1217\n",
      "Epoch [11/50], Step [500/735], Loss: 0.0870\n",
      "Epoch [11/50], Step [501/735], Loss: 0.1312\n",
      "Epoch [11/50], Step [502/735], Loss: 0.0706\n",
      "Epoch [11/50], Step [503/735], Loss: 0.1017\n",
      "Epoch [11/50], Step [504/735], Loss: 0.0560\n",
      "Epoch [11/50], Step [505/735], Loss: 0.1488\n",
      "Epoch [11/50], Step [506/735], Loss: 0.0874\n",
      "Epoch [11/50], Step [507/735], Loss: 0.0398\n",
      "Epoch [11/50], Step [508/735], Loss: 0.0444\n",
      "Epoch [11/50], Step [509/735], Loss: 0.1045\n",
      "Epoch [11/50], Step [510/735], Loss: 0.0263\n",
      "Epoch [11/50], Step [511/735], Loss: 0.5088\n",
      "Epoch [11/50], Step [512/735], Loss: 0.0317\n",
      "Epoch [11/50], Step [513/735], Loss: 0.1002\n",
      "Epoch [11/50], Step [514/735], Loss: 0.1289\n",
      "Epoch [11/50], Step [515/735], Loss: 0.1592\n",
      "Epoch [11/50], Step [516/735], Loss: 0.0792\n",
      "Epoch [11/50], Step [517/735], Loss: 0.1367\n",
      "Epoch [11/50], Step [518/735], Loss: 0.0537\n",
      "Epoch [11/50], Step [519/735], Loss: 0.0745\n",
      "Epoch [11/50], Step [520/735], Loss: 0.0847\n",
      "Epoch [11/50], Step [521/735], Loss: 0.1075\n",
      "Epoch [11/50], Step [522/735], Loss: 0.0638\n",
      "Epoch [11/50], Step [523/735], Loss: 0.0417\n",
      "Epoch [11/50], Step [524/735], Loss: 0.1619\n",
      "Epoch [11/50], Step [525/735], Loss: 0.1513\n",
      "Epoch [11/50], Step [526/735], Loss: 0.1776\n",
      "Epoch [11/50], Step [527/735], Loss: 0.1322\n",
      "Epoch [11/50], Step [528/735], Loss: 0.0864\n",
      "Epoch [11/50], Step [529/735], Loss: 0.1289\n",
      "Epoch [11/50], Step [530/735], Loss: 0.2314\n",
      "Epoch [11/50], Step [531/735], Loss: 0.0420\n",
      "Epoch [11/50], Step [532/735], Loss: 0.3246\n",
      "Epoch [11/50], Step [533/735], Loss: 0.0615\n",
      "Epoch [11/50], Step [534/735], Loss: 0.0228\n",
      "Epoch [11/50], Step [535/735], Loss: 0.0784\n",
      "Epoch [11/50], Step [536/735], Loss: 0.0672\n",
      "Epoch [11/50], Step [537/735], Loss: 0.2714\n",
      "Epoch [11/50], Step [538/735], Loss: 0.0351\n",
      "Epoch [11/50], Step [539/735], Loss: 0.0361\n",
      "Epoch [11/50], Step [540/735], Loss: 0.0161\n",
      "Epoch [11/50], Step [541/735], Loss: 0.1126\n",
      "Epoch [11/50], Step [542/735], Loss: 0.0580\n",
      "Epoch [11/50], Step [543/735], Loss: 0.0287\n",
      "Epoch [11/50], Step [544/735], Loss: 0.0529\n",
      "Epoch [11/50], Step [545/735], Loss: 0.0363\n",
      "Epoch [11/50], Step [546/735], Loss: 0.0824\n",
      "Epoch [11/50], Step [547/735], Loss: 0.0795\n",
      "Epoch [11/50], Step [548/735], Loss: 0.2035\n",
      "Epoch [11/50], Step [549/735], Loss: 0.1496\n",
      "Epoch [11/50], Step [550/735], Loss: 0.0917\n",
      "Epoch [11/50], Step [551/735], Loss: 0.0495\n",
      "Epoch [11/50], Step [552/735], Loss: 0.3101\n",
      "Epoch [11/50], Step [553/735], Loss: 0.0409\n",
      "Epoch [11/50], Step [554/735], Loss: 0.0472\n",
      "Epoch [11/50], Step [555/735], Loss: 0.1713\n",
      "Epoch [11/50], Step [556/735], Loss: 0.0301\n",
      "Epoch [11/50], Step [557/735], Loss: 0.0552\n",
      "Epoch [11/50], Step [558/735], Loss: 0.0329\n",
      "Epoch [11/50], Step [559/735], Loss: 0.2650\n",
      "Epoch [11/50], Step [560/735], Loss: 0.0794\n",
      "Epoch [11/50], Step [561/735], Loss: 0.1106\n",
      "Epoch [11/50], Step [562/735], Loss: 0.0581\n",
      "Epoch [11/50], Step [563/735], Loss: 0.0275\n",
      "Epoch [11/50], Step [564/735], Loss: 0.2123\n",
      "Epoch [11/50], Step [565/735], Loss: 0.0715\n",
      "Epoch [11/50], Step [566/735], Loss: 0.1119\n",
      "Epoch [11/50], Step [567/735], Loss: 0.0366\n",
      "Epoch [11/50], Step [568/735], Loss: 0.0407\n",
      "Epoch [11/50], Step [569/735], Loss: 0.0858\n",
      "Epoch [11/50], Step [570/735], Loss: 0.0373\n",
      "Epoch [11/50], Step [571/735], Loss: 0.0682\n",
      "Epoch [11/50], Step [572/735], Loss: 0.0604\n",
      "Epoch [11/50], Step [573/735], Loss: 0.0278\n",
      "Epoch [11/50], Step [574/735], Loss: 0.0753\n",
      "Epoch [11/50], Step [575/735], Loss: 0.1752\n",
      "Epoch [11/50], Step [576/735], Loss: 0.0468\n",
      "Epoch [11/50], Step [577/735], Loss: 0.1880\n",
      "Epoch [11/50], Step [578/735], Loss: 0.1004\n",
      "Epoch [11/50], Step [579/735], Loss: 0.0530\n",
      "Epoch [11/50], Step [580/735], Loss: 0.0404\n",
      "Epoch [11/50], Step [581/735], Loss: 0.0400\n",
      "Epoch [11/50], Step [582/735], Loss: 0.3300\n",
      "Epoch [11/50], Step [583/735], Loss: 0.0546\n",
      "Epoch [11/50], Step [584/735], Loss: 0.1289\n",
      "Epoch [11/50], Step [585/735], Loss: 0.1081\n",
      "Epoch [11/50], Step [586/735], Loss: 0.0791\n",
      "Epoch [11/50], Step [587/735], Loss: 0.0817\n",
      "Epoch [11/50], Step [588/735], Loss: 0.1275\n",
      "Epoch [11/50], Step [589/735], Loss: 0.1195\n",
      "Epoch [11/50], Step [590/735], Loss: 0.1267\n",
      "Epoch [11/50], Step [591/735], Loss: 0.0351\n",
      "Epoch [11/50], Step [592/735], Loss: 0.0856\n",
      "Epoch [11/50], Step [593/735], Loss: 0.1307\n",
      "Epoch [11/50], Step [594/735], Loss: 0.5066\n",
      "Epoch [11/50], Step [595/735], Loss: 0.3298\n",
      "Epoch [11/50], Step [596/735], Loss: 0.0560\n",
      "Epoch [11/50], Step [597/735], Loss: 0.0827\n",
      "Epoch [11/50], Step [598/735], Loss: 0.0957\n",
      "Epoch [11/50], Step [599/735], Loss: 0.2324\n",
      "Epoch [11/50], Step [600/735], Loss: 0.0557\n",
      "Epoch [11/50], Step [601/735], Loss: 0.2675\n",
      "Epoch [11/50], Step [602/735], Loss: 0.0993\n",
      "Epoch [11/50], Step [603/735], Loss: 0.0334\n",
      "Epoch [11/50], Step [604/735], Loss: 0.0676\n",
      "Epoch [11/50], Step [605/735], Loss: 0.1104\n",
      "Epoch [11/50], Step [606/735], Loss: 0.2220\n",
      "Epoch [11/50], Step [607/735], Loss: 0.0584\n",
      "Epoch [11/50], Step [608/735], Loss: 0.0870\n",
      "Epoch [11/50], Step [609/735], Loss: 0.0570\n",
      "Epoch [11/50], Step [610/735], Loss: 0.1000\n",
      "Epoch [11/50], Step [611/735], Loss: 0.1077\n",
      "Epoch [11/50], Step [612/735], Loss: 0.0801\n",
      "Epoch [11/50], Step [613/735], Loss: 0.1670\n",
      "Epoch [11/50], Step [614/735], Loss: 0.0560\n",
      "Epoch [11/50], Step [615/735], Loss: 0.0900\n",
      "Epoch [11/50], Step [616/735], Loss: 0.0815\n",
      "Epoch [11/50], Step [617/735], Loss: 0.1252\n",
      "Epoch [11/50], Step [618/735], Loss: 0.0398\n",
      "Epoch [11/50], Step [619/735], Loss: 0.1797\n",
      "Epoch [11/50], Step [620/735], Loss: 0.0347\n",
      "Epoch [11/50], Step [621/735], Loss: 0.0823\n",
      "Epoch [11/50], Step [622/735], Loss: 0.1105\n",
      "Epoch [11/50], Step [623/735], Loss: 0.0928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Step [624/735], Loss: 0.0480\n",
      "Epoch [11/50], Step [625/735], Loss: 0.0312\n",
      "Epoch [11/50], Step [626/735], Loss: 0.1090\n",
      "Epoch [11/50], Step [627/735], Loss: 0.4813\n",
      "Epoch [11/50], Step [628/735], Loss: 0.0538\n",
      "Epoch [11/50], Step [629/735], Loss: 0.0347\n",
      "Epoch [11/50], Step [630/735], Loss: 0.4443\n",
      "Epoch [11/50], Step [631/735], Loss: 0.4105\n",
      "Epoch [11/50], Step [632/735], Loss: 0.2664\n",
      "Epoch [11/50], Step [633/735], Loss: 0.0595\n",
      "Epoch [11/50], Step [634/735], Loss: 0.1701\n",
      "Epoch [11/50], Step [635/735], Loss: 0.2150\n",
      "Epoch [11/50], Step [636/735], Loss: 0.6550\n",
      "Epoch [11/50], Step [637/735], Loss: 0.2005\n",
      "Epoch [11/50], Step [638/735], Loss: 0.3082\n",
      "Epoch [11/50], Step [639/735], Loss: 0.0457\n",
      "Epoch [11/50], Step [640/735], Loss: 0.1081\n",
      "Epoch [11/50], Step [641/735], Loss: 0.1398\n",
      "Epoch [11/50], Step [642/735], Loss: 0.0777\n",
      "Epoch [11/50], Step [643/735], Loss: 0.1518\n",
      "Epoch [11/50], Step [644/735], Loss: 0.1271\n",
      "Epoch [11/50], Step [645/735], Loss: 0.1456\n",
      "Epoch [11/50], Step [646/735], Loss: 0.1062\n",
      "Epoch [11/50], Step [647/735], Loss: 0.0467\n",
      "Epoch [11/50], Step [648/735], Loss: 0.1792\n",
      "Epoch [11/50], Step [649/735], Loss: 0.2402\n",
      "Epoch [11/50], Step [650/735], Loss: 0.0911\n",
      "Epoch [11/50], Step [651/735], Loss: 0.4921\n",
      "Epoch [11/50], Step [652/735], Loss: 0.0546\n",
      "Epoch [11/50], Step [653/735], Loss: 0.0781\n",
      "Epoch [11/50], Step [654/735], Loss: 0.2654\n",
      "Epoch [11/50], Step [655/735], Loss: 0.0742\n",
      "Epoch [11/50], Step [656/735], Loss: 0.1303\n",
      "Epoch [11/50], Step [657/735], Loss: 0.0847\n",
      "Epoch [11/50], Step [658/735], Loss: 0.0519\n",
      "Epoch [11/50], Step [659/735], Loss: 0.1095\n",
      "Epoch [11/50], Step [660/735], Loss: 0.0927\n",
      "Epoch [11/50], Step [661/735], Loss: 0.0838\n",
      "Epoch [11/50], Step [662/735], Loss: 0.0347\n",
      "Epoch [11/50], Step [663/735], Loss: 0.3748\n",
      "Epoch [11/50], Step [664/735], Loss: 0.0736\n",
      "Epoch [11/50], Step [665/735], Loss: 0.0475\n",
      "Epoch [11/50], Step [666/735], Loss: 0.1600\n",
      "Epoch [11/50], Step [667/735], Loss: 0.0661\n",
      "Epoch [11/50], Step [668/735], Loss: 0.0963\n",
      "Epoch [11/50], Step [669/735], Loss: 0.0624\n",
      "Epoch [11/50], Step [670/735], Loss: 0.0395\n",
      "Epoch [11/50], Step [671/735], Loss: 0.0671\n",
      "Epoch [11/50], Step [672/735], Loss: 0.0701\n",
      "Epoch [11/50], Step [673/735], Loss: 0.0883\n",
      "Epoch [11/50], Step [674/735], Loss: 0.0604\n",
      "Epoch [11/50], Step [675/735], Loss: 0.3045\n",
      "Epoch [11/50], Step [676/735], Loss: 0.0828\n",
      "Epoch [11/50], Step [677/735], Loss: 0.0393\n",
      "Epoch [11/50], Step [678/735], Loss: 0.1076\n",
      "Epoch [11/50], Step [679/735], Loss: 0.1193\n",
      "Epoch [11/50], Step [680/735], Loss: 0.0758\n",
      "Epoch [11/50], Step [681/735], Loss: 0.0630\n",
      "Epoch [11/50], Step [682/735], Loss: 0.0444\n",
      "Epoch [11/50], Step [683/735], Loss: 0.2162\n",
      "Epoch [11/50], Step [684/735], Loss: 0.1549\n",
      "Epoch [11/50], Step [685/735], Loss: 0.1942\n",
      "Epoch [11/50], Step [686/735], Loss: 0.0778\n",
      "Epoch [11/50], Step [687/735], Loss: 0.2299\n",
      "Epoch [11/50], Step [688/735], Loss: 0.1260\n",
      "Epoch [11/50], Step [689/735], Loss: 0.0529\n",
      "Epoch [11/50], Step [690/735], Loss: 0.0481\n",
      "Epoch [11/50], Step [691/735], Loss: 0.1291\n",
      "Epoch [11/50], Step [692/735], Loss: 0.0581\n",
      "Epoch [11/50], Step [693/735], Loss: 0.0861\n",
      "Epoch [11/50], Step [694/735], Loss: 0.2113\n",
      "Epoch [11/50], Step [695/735], Loss: 0.1507\n",
      "Epoch [11/50], Step [696/735], Loss: 0.0660\n",
      "Epoch [11/50], Step [697/735], Loss: 0.3569\n",
      "Epoch [11/50], Step [698/735], Loss: 0.0734\n",
      "Epoch [11/50], Step [699/735], Loss: 0.1137\n",
      "Epoch [11/50], Step [700/735], Loss: 0.5533\n",
      "Epoch [11/50], Step [701/735], Loss: 0.0808\n",
      "Epoch [11/50], Step [702/735], Loss: 0.1254\n",
      "Epoch [11/50], Step [703/735], Loss: 0.2018\n",
      "Epoch [11/50], Step [704/735], Loss: 0.0451\n",
      "Epoch [11/50], Step [705/735], Loss: 0.1000\n",
      "Epoch [11/50], Step [706/735], Loss: 0.0458\n",
      "Epoch [11/50], Step [707/735], Loss: 0.1841\n",
      "Epoch [11/50], Step [708/735], Loss: 0.0902\n",
      "Epoch [11/50], Step [709/735], Loss: 0.0820\n",
      "Epoch [11/50], Step [710/735], Loss: 0.5125\n",
      "Epoch [11/50], Step [711/735], Loss: 0.2397\n",
      "Epoch [11/50], Step [712/735], Loss: 0.0384\n",
      "Epoch [11/50], Step [713/735], Loss: 0.0969\n",
      "Epoch [11/50], Step [714/735], Loss: 0.2193\n",
      "Epoch [11/50], Step [715/735], Loss: 0.0603\n",
      "Epoch [11/50], Step [716/735], Loss: 0.0444\n",
      "Epoch [11/50], Step [717/735], Loss: 0.0420\n",
      "Epoch [11/50], Step [718/735], Loss: 0.0453\n",
      "Epoch [11/50], Step [719/735], Loss: 0.1748\n",
      "Epoch [11/50], Step [720/735], Loss: 0.0399\n",
      "Epoch [11/50], Step [721/735], Loss: 0.0342\n",
      "Epoch [11/50], Step [722/735], Loss: 0.0692\n",
      "Epoch [11/50], Step [723/735], Loss: 0.0583\n",
      "Epoch [11/50], Step [724/735], Loss: 0.0840\n",
      "Epoch [11/50], Step [725/735], Loss: 0.0354\n",
      "Epoch [11/50], Step [726/735], Loss: 0.1629\n",
      "Epoch [11/50], Step [727/735], Loss: 0.0247\n",
      "Epoch [11/50], Step [728/735], Loss: 0.0719\n",
      "Epoch [11/50], Step [729/735], Loss: 0.1250\n",
      "Epoch [11/50], Step [730/735], Loss: 0.0611\n",
      "Epoch [11/50], Step [731/735], Loss: 0.0989\n",
      "Epoch [11/50], Step [732/735], Loss: 0.0593\n",
      "Epoch [11/50], Step [733/735], Loss: 0.0591\n",
      "Epoch [11/50], Step [734/735], Loss: 0.1710\n",
      "Epoch [11/50], Step [735/735], Loss: 0.0212\n",
      "Epoch [12/50], Step [1/735], Loss: 0.1504\n",
      "Epoch [12/50], Step [2/735], Loss: 0.0509\n",
      "Epoch [12/50], Step [3/735], Loss: 0.0931\n",
      "Epoch [12/50], Step [4/735], Loss: 0.1255\n",
      "Epoch [12/50], Step [5/735], Loss: 0.1071\n",
      "Epoch [12/50], Step [6/735], Loss: 0.0522\n",
      "Epoch [12/50], Step [7/735], Loss: 0.1165\n",
      "Epoch [12/50], Step [8/735], Loss: 0.1142\n",
      "Epoch [12/50], Step [9/735], Loss: 0.0494\n",
      "Epoch [12/50], Step [10/735], Loss: 0.0842\n",
      "Epoch [12/50], Step [11/735], Loss: 0.0419\n",
      "Epoch [12/50], Step [12/735], Loss: 0.0427\n",
      "Epoch [12/50], Step [13/735], Loss: 0.0192\n",
      "Epoch [12/50], Step [14/735], Loss: 0.1993\n",
      "Epoch [12/50], Step [15/735], Loss: 0.0367\n",
      "Epoch [12/50], Step [16/735], Loss: 0.0544\n",
      "Epoch [12/50], Step [17/735], Loss: 0.0732\n",
      "Epoch [12/50], Step [18/735], Loss: 0.0842\n",
      "Epoch [12/50], Step [19/735], Loss: 0.0498\n",
      "Epoch [12/50], Step [20/735], Loss: 0.1143\n",
      "Epoch [12/50], Step [21/735], Loss: 0.2104\n",
      "Epoch [12/50], Step [22/735], Loss: 0.0438\n",
      "Epoch [12/50], Step [23/735], Loss: 0.0828\n",
      "Epoch [12/50], Step [24/735], Loss: 0.0589\n",
      "Epoch [12/50], Step [25/735], Loss: 0.1020\n",
      "Epoch [12/50], Step [26/735], Loss: 0.0904\n",
      "Epoch [12/50], Step [27/735], Loss: 0.0772\n",
      "Epoch [12/50], Step [28/735], Loss: 0.1322\n",
      "Epoch [12/50], Step [29/735], Loss: 0.1189\n",
      "Epoch [12/50], Step [30/735], Loss: 0.1549\n",
      "Epoch [12/50], Step [31/735], Loss: 0.2014\n",
      "Epoch [12/50], Step [32/735], Loss: 0.0840\n",
      "Epoch [12/50], Step [33/735], Loss: 0.0580\n",
      "Epoch [12/50], Step [34/735], Loss: 0.1220\n",
      "Epoch [12/50], Step [35/735], Loss: 0.1546\n",
      "Epoch [12/50], Step [36/735], Loss: 0.0781\n",
      "Epoch [12/50], Step [37/735], Loss: 0.1397\n",
      "Epoch [12/50], Step [38/735], Loss: 0.0559\n",
      "Epoch [12/50], Step [39/735], Loss: 0.1023\n",
      "Epoch [12/50], Step [40/735], Loss: 0.1033\n",
      "Epoch [12/50], Step [41/735], Loss: 0.1402\n",
      "Epoch [12/50], Step [42/735], Loss: 0.0393\n",
      "Epoch [12/50], Step [43/735], Loss: 0.3733\n",
      "Epoch [12/50], Step [44/735], Loss: 0.1272\n",
      "Epoch [12/50], Step [45/735], Loss: 0.1311\n",
      "Epoch [12/50], Step [46/735], Loss: 0.0272\n",
      "Epoch [12/50], Step [47/735], Loss: 0.0705\n",
      "Epoch [12/50], Step [48/735], Loss: 0.0738\n",
      "Epoch [12/50], Step [49/735], Loss: 0.1419\n",
      "Epoch [12/50], Step [50/735], Loss: 0.0494\n",
      "Epoch [12/50], Step [51/735], Loss: 0.0979\n",
      "Epoch [12/50], Step [52/735], Loss: 0.0483\n",
      "Epoch [12/50], Step [53/735], Loss: 0.1869\n",
      "Epoch [12/50], Step [54/735], Loss: 0.0795\n",
      "Epoch [12/50], Step [55/735], Loss: 0.0663\n",
      "Epoch [12/50], Step [56/735], Loss: 0.0895\n",
      "Epoch [12/50], Step [57/735], Loss: 0.0720\n",
      "Epoch [12/50], Step [58/735], Loss: 0.0416\n",
      "Epoch [12/50], Step [59/735], Loss: 0.1043\n",
      "Epoch [12/50], Step [60/735], Loss: 0.0682\n",
      "Epoch [12/50], Step [61/735], Loss: 0.0502\n",
      "Epoch [12/50], Step [62/735], Loss: 0.0947\n",
      "Epoch [12/50], Step [63/735], Loss: 0.2295\n",
      "Epoch [12/50], Step [64/735], Loss: 0.0454\n",
      "Epoch [12/50], Step [65/735], Loss: 0.1444\n",
      "Epoch [12/50], Step [66/735], Loss: 0.0783\n",
      "Epoch [12/50], Step [67/735], Loss: 0.0806\n",
      "Epoch [12/50], Step [68/735], Loss: 0.0400\n",
      "Epoch [12/50], Step [69/735], Loss: 0.3496\n",
      "Epoch [12/50], Step [70/735], Loss: 0.1841\n",
      "Epoch [12/50], Step [71/735], Loss: 0.1630\n",
      "Epoch [12/50], Step [72/735], Loss: 0.0439\n",
      "Epoch [12/50], Step [73/735], Loss: 0.0344\n",
      "Epoch [12/50], Step [74/735], Loss: 0.0782\n",
      "Epoch [12/50], Step [75/735], Loss: 0.0432\n",
      "Epoch [12/50], Step [76/735], Loss: 0.2316\n",
      "Epoch [12/50], Step [77/735], Loss: 0.0954\n",
      "Epoch [12/50], Step [78/735], Loss: 0.0185\n",
      "Epoch [12/50], Step [79/735], Loss: 0.1288\n",
      "Epoch [12/50], Step [80/735], Loss: 0.0807\n",
      "Epoch [12/50], Step [81/735], Loss: 0.0230\n",
      "Epoch [12/50], Step [82/735], Loss: 0.0267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Step [83/735], Loss: 0.0620\n",
      "Epoch [12/50], Step [84/735], Loss: 0.0763\n",
      "Epoch [12/50], Step [85/735], Loss: 0.4316\n",
      "Epoch [12/50], Step [86/735], Loss: 0.0461\n",
      "Epoch [12/50], Step [87/735], Loss: 0.1571\n",
      "Epoch [12/50], Step [88/735], Loss: 0.1031\n",
      "Epoch [12/50], Step [89/735], Loss: 0.0324\n",
      "Epoch [12/50], Step [90/735], Loss: 0.1226\n",
      "Epoch [12/50], Step [91/735], Loss: 0.6701\n",
      "Epoch [12/50], Step [92/735], Loss: 0.0784\n",
      "Epoch [12/50], Step [93/735], Loss: 0.2593\n",
      "Epoch [12/50], Step [94/735], Loss: 0.1060\n",
      "Epoch [12/50], Step [95/735], Loss: 0.1091\n",
      "Epoch [12/50], Step [96/735], Loss: 0.1176\n",
      "Epoch [12/50], Step [97/735], Loss: 0.0879\n",
      "Epoch [12/50], Step [98/735], Loss: 0.0448\n",
      "Epoch [12/50], Step [99/735], Loss: 0.1814\n",
      "Epoch [12/50], Step [100/735], Loss: 0.0619\n",
      "Epoch [12/50], Step [101/735], Loss: 0.1500\n",
      "Epoch [12/50], Step [102/735], Loss: 0.0645\n",
      "Epoch [12/50], Step [103/735], Loss: 0.0680\n",
      "Epoch [12/50], Step [104/735], Loss: 0.1628\n",
      "Epoch [12/50], Step [105/735], Loss: 0.0854\n",
      "Epoch [12/50], Step [106/735], Loss: 0.0618\n",
      "Epoch [12/50], Step [107/735], Loss: 0.0578\n",
      "Epoch [12/50], Step [108/735], Loss: 0.1560\n",
      "Epoch [12/50], Step [109/735], Loss: 0.1509\n",
      "Epoch [12/50], Step [110/735], Loss: 0.0216\n",
      "Epoch [12/50], Step [111/735], Loss: 0.1578\n",
      "Epoch [12/50], Step [112/735], Loss: 0.0482\n",
      "Epoch [12/50], Step [113/735], Loss: 0.0526\n",
      "Epoch [12/50], Step [114/735], Loss: 0.0526\n",
      "Epoch [12/50], Step [115/735], Loss: 0.1249\n",
      "Epoch [12/50], Step [116/735], Loss: 0.0621\n",
      "Epoch [12/50], Step [117/735], Loss: 0.0551\n",
      "Epoch [12/50], Step [118/735], Loss: 0.0275\n",
      "Epoch [12/50], Step [119/735], Loss: 0.0742\n",
      "Epoch [12/50], Step [120/735], Loss: 0.0348\n",
      "Epoch [12/50], Step [121/735], Loss: 0.0850\n",
      "Epoch [12/50], Step [122/735], Loss: 0.1650\n",
      "Epoch [12/50], Step [123/735], Loss: 0.3303\n",
      "Epoch [12/50], Step [124/735], Loss: 0.0776\n",
      "Epoch [12/50], Step [125/735], Loss: 0.0778\n",
      "Epoch [12/50], Step [126/735], Loss: 0.0343\n",
      "Epoch [12/50], Step [127/735], Loss: 0.0538\n",
      "Epoch [12/50], Step [128/735], Loss: 0.0525\n",
      "Epoch [12/50], Step [129/735], Loss: 0.0692\n",
      "Epoch [12/50], Step [130/735], Loss: 0.1596\n",
      "Epoch [12/50], Step [131/735], Loss: 0.2076\n",
      "Epoch [12/50], Step [132/735], Loss: 0.0691\n",
      "Epoch [12/50], Step [133/735], Loss: 0.1074\n",
      "Epoch [12/50], Step [134/735], Loss: 0.0238\n",
      "Epoch [12/50], Step [135/735], Loss: 0.0405\n",
      "Epoch [12/50], Step [136/735], Loss: 0.0337\n",
      "Epoch [12/50], Step [137/735], Loss: 0.0509\n",
      "Epoch [12/50], Step [138/735], Loss: 0.1501\n",
      "Epoch [12/50], Step [139/735], Loss: 0.0734\n",
      "Epoch [12/50], Step [140/735], Loss: 0.0283\n",
      "Epoch [12/50], Step [141/735], Loss: 0.0166\n",
      "Epoch [12/50], Step [142/735], Loss: 0.0388\n",
      "Epoch [12/50], Step [143/735], Loss: 0.2034\n",
      "Epoch [12/50], Step [144/735], Loss: 0.0875\n",
      "Epoch [12/50], Step [145/735], Loss: 0.0577\n",
      "Epoch [12/50], Step [146/735], Loss: 0.0307\n",
      "Epoch [12/50], Step [147/735], Loss: 0.1064\n",
      "Epoch [12/50], Step [148/735], Loss: 0.0477\n",
      "Epoch [12/50], Step [149/735], Loss: 0.1301\n",
      "Epoch [12/50], Step [150/735], Loss: 0.0868\n",
      "Epoch [12/50], Step [151/735], Loss: 0.0454\n",
      "Epoch [12/50], Step [152/735], Loss: 0.0253\n",
      "Epoch [12/50], Step [153/735], Loss: 0.1006\n",
      "Epoch [12/50], Step [154/735], Loss: 0.0392\n",
      "Epoch [12/50], Step [155/735], Loss: 0.0498\n",
      "Epoch [12/50], Step [156/735], Loss: 0.2387\n",
      "Epoch [12/50], Step [157/735], Loss: 0.0653\n",
      "Epoch [12/50], Step [158/735], Loss: 0.0765\n",
      "Epoch [12/50], Step [159/735], Loss: 0.0572\n",
      "Epoch [12/50], Step [160/735], Loss: 0.3316\n",
      "Epoch [12/50], Step [161/735], Loss: 0.0402\n",
      "Epoch [12/50], Step [162/735], Loss: 0.1174\n",
      "Epoch [12/50], Step [163/735], Loss: 0.2603\n",
      "Epoch [12/50], Step [164/735], Loss: 0.0475\n",
      "Epoch [12/50], Step [165/735], Loss: 0.1847\n",
      "Epoch [12/50], Step [166/735], Loss: 0.0510\n",
      "Epoch [12/50], Step [167/735], Loss: 0.0526\n",
      "Epoch [12/50], Step [168/735], Loss: 0.0396\n",
      "Epoch [12/50], Step [169/735], Loss: 0.1700\n",
      "Epoch [12/50], Step [170/735], Loss: 0.0593\n",
      "Epoch [12/50], Step [171/735], Loss: 0.0350\n",
      "Epoch [12/50], Step [172/735], Loss: 0.0653\n",
      "Epoch [12/50], Step [173/735], Loss: 0.2085\n",
      "Epoch [12/50], Step [174/735], Loss: 0.0722\n",
      "Epoch [12/50], Step [175/735], Loss: 0.3244\n",
      "Epoch [12/50], Step [176/735], Loss: 0.0499\n",
      "Epoch [12/50], Step [177/735], Loss: 0.1071\n",
      "Epoch [12/50], Step [178/735], Loss: 0.0312\n",
      "Epoch [12/50], Step [179/735], Loss: 0.6344\n",
      "Epoch [12/50], Step [180/735], Loss: 0.0750\n",
      "Epoch [12/50], Step [181/735], Loss: 0.1352\n",
      "Epoch [12/50], Step [182/735], Loss: 0.1105\n",
      "Epoch [12/50], Step [183/735], Loss: 0.0871\n",
      "Epoch [12/50], Step [184/735], Loss: 0.1673\n",
      "Epoch [12/50], Step [185/735], Loss: 0.0522\n",
      "Epoch [12/50], Step [186/735], Loss: 0.0245\n",
      "Epoch [12/50], Step [187/735], Loss: 0.0653\n",
      "Epoch [12/50], Step [188/735], Loss: 0.0812\n",
      "Epoch [12/50], Step [189/735], Loss: 0.0285\n",
      "Epoch [12/50], Step [190/735], Loss: 0.0363\n",
      "Epoch [12/50], Step [191/735], Loss: 0.2245\n",
      "Epoch [12/50], Step [192/735], Loss: 0.0669\n",
      "Epoch [12/50], Step [193/735], Loss: 0.0464\n",
      "Epoch [12/50], Step [194/735], Loss: 0.0199\n",
      "Epoch [12/50], Step [195/735], Loss: 0.0241\n",
      "Epoch [12/50], Step [196/735], Loss: 0.1128\n",
      "Epoch [12/50], Step [197/735], Loss: 0.1812\n",
      "Epoch [12/50], Step [198/735], Loss: 0.0253\n",
      "Epoch [12/50], Step [199/735], Loss: 0.3251\n",
      "Epoch [12/50], Step [200/735], Loss: 0.0769\n",
      "Epoch [12/50], Step [201/735], Loss: 0.0344\n",
      "Epoch [12/50], Step [202/735], Loss: 0.0994\n",
      "Epoch [12/50], Step [203/735], Loss: 0.0995\n",
      "Epoch [12/50], Step [204/735], Loss: 0.1555\n",
      "Epoch [12/50], Step [205/735], Loss: 0.0994\n",
      "Epoch [12/50], Step [206/735], Loss: 0.0282\n",
      "Epoch [12/50], Step [207/735], Loss: 0.0324\n",
      "Epoch [12/50], Step [208/735], Loss: 0.0932\n",
      "Epoch [12/50], Step [209/735], Loss: 0.1535\n",
      "Epoch [12/50], Step [210/735], Loss: 0.0840\n",
      "Epoch [12/50], Step [211/735], Loss: 0.0801\n",
      "Epoch [12/50], Step [212/735], Loss: 0.0919\n",
      "Epoch [12/50], Step [213/735], Loss: 0.1575\n",
      "Epoch [12/50], Step [214/735], Loss: 0.1118\n",
      "Epoch [12/50], Step [215/735], Loss: 0.0955\n",
      "Epoch [12/50], Step [216/735], Loss: 0.0288\n",
      "Epoch [12/50], Step [217/735], Loss: 0.3807\n",
      "Epoch [12/50], Step [218/735], Loss: 0.1031\n",
      "Epoch [12/50], Step [219/735], Loss: 0.0949\n",
      "Epoch [12/50], Step [220/735], Loss: 0.0942\n",
      "Epoch [12/50], Step [221/735], Loss: 0.0440\n",
      "Epoch [12/50], Step [222/735], Loss: 0.1171\n",
      "Epoch [12/50], Step [223/735], Loss: 0.0978\n",
      "Epoch [12/50], Step [224/735], Loss: 0.1038\n",
      "Epoch [12/50], Step [225/735], Loss: 0.1002\n",
      "Epoch [12/50], Step [226/735], Loss: 0.2774\n",
      "Epoch [12/50], Step [227/735], Loss: 0.0950\n",
      "Epoch [12/50], Step [228/735], Loss: 0.0558\n",
      "Epoch [12/50], Step [229/735], Loss: 0.0253\n",
      "Epoch [12/50], Step [230/735], Loss: 0.1660\n",
      "Epoch [12/50], Step [231/735], Loss: 0.0236\n",
      "Epoch [12/50], Step [232/735], Loss: 0.0875\n",
      "Epoch [12/50], Step [233/735], Loss: 0.0581\n",
      "Epoch [12/50], Step [234/735], Loss: 0.1020\n",
      "Epoch [12/50], Step [235/735], Loss: 0.1567\n",
      "Epoch [12/50], Step [236/735], Loss: 0.1259\n",
      "Epoch [12/50], Step [237/735], Loss: 0.0637\n",
      "Epoch [12/50], Step [238/735], Loss: 0.1177\n",
      "Epoch [12/50], Step [239/735], Loss: 0.0427\n",
      "Epoch [12/50], Step [240/735], Loss: 0.0255\n",
      "Epoch [12/50], Step [241/735], Loss: 0.2276\n",
      "Epoch [12/50], Step [242/735], Loss: 0.0521\n",
      "Epoch [12/50], Step [243/735], Loss: 0.1015\n",
      "Epoch [12/50], Step [244/735], Loss: 0.0539\n",
      "Epoch [12/50], Step [245/735], Loss: 0.1954\n",
      "Epoch [12/50], Step [246/735], Loss: 0.0325\n",
      "Epoch [12/50], Step [247/735], Loss: 0.0600\n",
      "Epoch [12/50], Step [248/735], Loss: 0.1076\n",
      "Epoch [12/50], Step [249/735], Loss: 0.0447\n",
      "Epoch [12/50], Step [250/735], Loss: 0.0354\n",
      "Epoch [12/50], Step [251/735], Loss: 0.0349\n",
      "Epoch [12/50], Step [252/735], Loss: 0.0521\n",
      "Epoch [12/50], Step [253/735], Loss: 0.0545\n",
      "Epoch [12/50], Step [254/735], Loss: 0.1355\n",
      "Epoch [12/50], Step [255/735], Loss: 0.0236\n",
      "Epoch [12/50], Step [256/735], Loss: 0.0497\n",
      "Epoch [12/50], Step [257/735], Loss: 0.0496\n",
      "Epoch [12/50], Step [258/735], Loss: 0.1514\n",
      "Epoch [12/50], Step [259/735], Loss: 0.1218\n",
      "Epoch [12/50], Step [260/735], Loss: 0.0475\n",
      "Epoch [12/50], Step [261/735], Loss: 0.1714\n",
      "Epoch [12/50], Step [262/735], Loss: 0.0870\n",
      "Epoch [12/50], Step [263/735], Loss: 0.1532\n",
      "Epoch [12/50], Step [264/735], Loss: 0.0908\n",
      "Epoch [12/50], Step [265/735], Loss: 0.0419\n",
      "Epoch [12/50], Step [266/735], Loss: 0.0151\n",
      "Epoch [12/50], Step [267/735], Loss: 0.1256\n",
      "Epoch [12/50], Step [268/735], Loss: 0.0465\n",
      "Epoch [12/50], Step [269/735], Loss: 0.0671\n",
      "Epoch [12/50], Step [270/735], Loss: 0.0348\n",
      "Epoch [12/50], Step [271/735], Loss: 0.1477\n",
      "Epoch [12/50], Step [272/735], Loss: 0.0365\n",
      "Epoch [12/50], Step [273/735], Loss: 0.0702\n",
      "Epoch [12/50], Step [274/735], Loss: 0.0654\n",
      "Epoch [12/50], Step [275/735], Loss: 0.1225\n",
      "Epoch [12/50], Step [276/735], Loss: 0.1730\n",
      "Epoch [12/50], Step [277/735], Loss: 0.0567\n",
      "Epoch [12/50], Step [278/735], Loss: 0.1008\n",
      "Epoch [12/50], Step [279/735], Loss: 0.1246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Step [280/735], Loss: 0.0769\n",
      "Epoch [12/50], Step [281/735], Loss: 0.0666\n",
      "Epoch [12/50], Step [282/735], Loss: 0.0337\n",
      "Epoch [12/50], Step [283/735], Loss: 0.1348\n",
      "Epoch [12/50], Step [284/735], Loss: 0.0747\n",
      "Epoch [12/50], Step [285/735], Loss: 0.1921\n",
      "Epoch [12/50], Step [286/735], Loss: 0.0695\n",
      "Epoch [12/50], Step [287/735], Loss: 0.0625\n",
      "Epoch [12/50], Step [288/735], Loss: 0.0990\n",
      "Epoch [12/50], Step [289/735], Loss: 0.0340\n",
      "Epoch [12/50], Step [290/735], Loss: 0.1252\n",
      "Epoch [12/50], Step [291/735], Loss: 0.0583\n",
      "Epoch [12/50], Step [292/735], Loss: 0.0336\n",
      "Epoch [12/50], Step [293/735], Loss: 0.0192\n",
      "Epoch [12/50], Step [294/735], Loss: 0.1312\n",
      "Epoch [12/50], Step [295/735], Loss: 0.1901\n",
      "Epoch [12/50], Step [296/735], Loss: 0.0348\n",
      "Epoch [12/50], Step [297/735], Loss: 0.2691\n",
      "Epoch [12/50], Step [298/735], Loss: 0.0705\n",
      "Epoch [12/50], Step [299/735], Loss: 0.2543\n",
      "Epoch [12/50], Step [300/735], Loss: 0.1204\n",
      "Epoch [12/50], Step [301/735], Loss: 0.0737\n",
      "Epoch [12/50], Step [302/735], Loss: 0.1511\n",
      "Epoch [12/50], Step [303/735], Loss: 0.0507\n",
      "Epoch [12/50], Step [304/735], Loss: 0.0443\n",
      "Epoch [12/50], Step [305/735], Loss: 0.0820\n",
      "Epoch [12/50], Step [306/735], Loss: 0.0229\n",
      "Epoch [12/50], Step [307/735], Loss: 0.0773\n",
      "Epoch [12/50], Step [308/735], Loss: 0.0865\n",
      "Epoch [12/50], Step [309/735], Loss: 0.0630\n",
      "Epoch [12/50], Step [310/735], Loss: 0.1058\n",
      "Epoch [12/50], Step [311/735], Loss: 0.0521\n",
      "Epoch [12/50], Step [312/735], Loss: 0.2145\n",
      "Epoch [12/50], Step [313/735], Loss: 0.0962\n",
      "Epoch [12/50], Step [314/735], Loss: 0.6708\n",
      "Epoch [12/50], Step [315/735], Loss: 0.3082\n",
      "Epoch [12/50], Step [316/735], Loss: 0.0751\n",
      "Epoch [12/50], Step [317/735], Loss: 0.0852\n",
      "Epoch [12/50], Step [318/735], Loss: 0.0578\n",
      "Epoch [12/50], Step [319/735], Loss: 0.0331\n",
      "Epoch [12/50], Step [320/735], Loss: 0.0432\n",
      "Epoch [12/50], Step [321/735], Loss: 0.0976\n",
      "Epoch [12/50], Step [322/735], Loss: 0.0419\n",
      "Epoch [12/50], Step [323/735], Loss: 0.4466\n",
      "Epoch [12/50], Step [324/735], Loss: 0.3145\n",
      "Epoch [12/50], Step [325/735], Loss: 0.0458\n",
      "Epoch [12/50], Step [326/735], Loss: 0.1533\n",
      "Epoch [12/50], Step [327/735], Loss: 0.0949\n",
      "Epoch [12/50], Step [328/735], Loss: 0.0846\n",
      "Epoch [12/50], Step [329/735], Loss: 0.0902\n",
      "Epoch [12/50], Step [330/735], Loss: 0.0711\n",
      "Epoch [12/50], Step [331/735], Loss: 0.1035\n",
      "Epoch [12/50], Step [332/735], Loss: 0.0505\n",
      "Epoch [12/50], Step [333/735], Loss: 0.0938\n",
      "Epoch [12/50], Step [334/735], Loss: 0.0800\n",
      "Epoch [12/50], Step [335/735], Loss: 0.0697\n",
      "Epoch [12/50], Step [336/735], Loss: 0.1063\n",
      "Epoch [12/50], Step [337/735], Loss: 0.0564\n",
      "Epoch [12/50], Step [338/735], Loss: 0.0727\n",
      "Epoch [12/50], Step [339/735], Loss: 0.0549\n",
      "Epoch [12/50], Step [340/735], Loss: 0.5869\n",
      "Epoch [12/50], Step [341/735], Loss: 0.3561\n",
      "Epoch [12/50], Step [342/735], Loss: 0.1903\n",
      "Epoch [12/50], Step [343/735], Loss: 0.0904\n",
      "Epoch [12/50], Step [344/735], Loss: 0.1075\n",
      "Epoch [12/50], Step [345/735], Loss: 0.2844\n",
      "Epoch [12/50], Step [346/735], Loss: 0.1390\n",
      "Epoch [12/50], Step [347/735], Loss: 0.0294\n",
      "Epoch [12/50], Step [348/735], Loss: 0.1449\n",
      "Epoch [12/50], Step [349/735], Loss: 0.2038\n",
      "Epoch [12/50], Step [350/735], Loss: 0.1057\n",
      "Epoch [12/50], Step [351/735], Loss: 0.1471\n",
      "Epoch [12/50], Step [352/735], Loss: 0.0823\n",
      "Epoch [12/50], Step [353/735], Loss: 0.0392\n",
      "Epoch [12/50], Step [354/735], Loss: 0.1325\n",
      "Epoch [12/50], Step [355/735], Loss: 0.0338\n",
      "Epoch [12/50], Step [356/735], Loss: 0.0737\n",
      "Epoch [12/50], Step [357/735], Loss: 0.0543\n",
      "Epoch [12/50], Step [358/735], Loss: 0.1216\n",
      "Epoch [12/50], Step [359/735], Loss: 0.0625\n",
      "Epoch [12/50], Step [360/735], Loss: 0.0746\n",
      "Epoch [12/50], Step [361/735], Loss: 0.0464\n",
      "Epoch [12/50], Step [362/735], Loss: 0.0407\n",
      "Epoch [12/50], Step [363/735], Loss: 0.0345\n",
      "Epoch [12/50], Step [364/735], Loss: 0.0392\n",
      "Epoch [12/50], Step [365/735], Loss: 0.1399\n",
      "Epoch [12/50], Step [366/735], Loss: 0.0703\n",
      "Epoch [12/50], Step [367/735], Loss: 0.0614\n",
      "Epoch [12/50], Step [368/735], Loss: 0.2307\n",
      "Epoch [12/50], Step [369/735], Loss: 0.0686\n",
      "Epoch [12/50], Step [370/735], Loss: 0.4560\n",
      "Epoch [12/50], Step [371/735], Loss: 0.0778\n",
      "Epoch [12/50], Step [372/735], Loss: 0.1488\n",
      "Epoch [12/50], Step [373/735], Loss: 0.1147\n",
      "Epoch [12/50], Step [374/735], Loss: 0.1168\n",
      "Epoch [12/50], Step [375/735], Loss: 0.1207\n",
      "Epoch [12/50], Step [376/735], Loss: 0.2125\n",
      "Epoch [12/50], Step [377/735], Loss: 0.1066\n",
      "Epoch [12/50], Step [378/735], Loss: 0.2449\n",
      "Epoch [12/50], Step [379/735], Loss: 0.1681\n",
      "Epoch [12/50], Step [380/735], Loss: 0.0371\n",
      "Epoch [12/50], Step [381/735], Loss: 0.0686\n",
      "Epoch [12/50], Step [382/735], Loss: 0.0644\n",
      "Epoch [12/50], Step [383/735], Loss: 0.3992\n",
      "Epoch [12/50], Step [384/735], Loss: 0.1052\n",
      "Epoch [12/50], Step [385/735], Loss: 0.0204\n",
      "Epoch [12/50], Step [386/735], Loss: 0.1446\n",
      "Epoch [12/50], Step [387/735], Loss: 0.0546\n",
      "Epoch [12/50], Step [388/735], Loss: 0.0916\n",
      "Epoch [12/50], Step [389/735], Loss: 0.0900\n",
      "Epoch [12/50], Step [390/735], Loss: 0.0710\n",
      "Epoch [12/50], Step [391/735], Loss: 0.0738\n",
      "Epoch [12/50], Step [392/735], Loss: 0.0759\n",
      "Epoch [12/50], Step [393/735], Loss: 0.1143\n",
      "Epoch [12/50], Step [394/735], Loss: 0.0699\n",
      "Epoch [12/50], Step [395/735], Loss: 0.0605\n",
      "Epoch [12/50], Step [396/735], Loss: 0.0757\n",
      "Epoch [12/50], Step [397/735], Loss: 0.1005\n",
      "Epoch [12/50], Step [398/735], Loss: 0.1096\n",
      "Epoch [12/50], Step [399/735], Loss: 0.0282\n",
      "Epoch [12/50], Step [400/735], Loss: 0.1589\n",
      "Epoch [12/50], Step [401/735], Loss: 0.1331\n",
      "Epoch [12/50], Step [402/735], Loss: 0.0970\n",
      "Epoch [12/50], Step [403/735], Loss: 0.4231\n",
      "Epoch [12/50], Step [404/735], Loss: 0.1443\n",
      "Epoch [12/50], Step [405/735], Loss: 0.1716\n",
      "Epoch [12/50], Step [406/735], Loss: 0.0859\n",
      "Epoch [12/50], Step [407/735], Loss: 0.0483\n",
      "Epoch [12/50], Step [408/735], Loss: 0.2041\n",
      "Epoch [12/50], Step [409/735], Loss: 0.1392\n",
      "Epoch [12/50], Step [410/735], Loss: 0.1178\n",
      "Epoch [12/50], Step [411/735], Loss: 0.0409\n",
      "Epoch [12/50], Step [412/735], Loss: 0.5478\n",
      "Epoch [12/50], Step [413/735], Loss: 0.0435\n",
      "Epoch [12/50], Step [414/735], Loss: 0.1262\n",
      "Epoch [12/50], Step [415/735], Loss: 0.0769\n",
      "Epoch [12/50], Step [416/735], Loss: 0.0697\n",
      "Epoch [12/50], Step [417/735], Loss: 0.1154\n",
      "Epoch [12/50], Step [418/735], Loss: 0.0803\n",
      "Epoch [12/50], Step [419/735], Loss: 0.1836\n",
      "Epoch [12/50], Step [420/735], Loss: 0.3786\n",
      "Epoch [12/50], Step [421/735], Loss: 0.0421\n",
      "Epoch [12/50], Step [422/735], Loss: 0.0507\n",
      "Epoch [12/50], Step [423/735], Loss: 0.1133\n",
      "Epoch [12/50], Step [424/735], Loss: 0.2510\n",
      "Epoch [12/50], Step [425/735], Loss: 0.0362\n",
      "Epoch [12/50], Step [426/735], Loss: 0.1042\n",
      "Epoch [12/50], Step [427/735], Loss: 0.0992\n",
      "Epoch [12/50], Step [428/735], Loss: 0.0360\n",
      "Epoch [12/50], Step [429/735], Loss: 0.1045\n",
      "Epoch [12/50], Step [430/735], Loss: 0.1678\n",
      "Epoch [12/50], Step [431/735], Loss: 0.1314\n",
      "Epoch [12/50], Step [432/735], Loss: 0.0950\n",
      "Epoch [12/50], Step [433/735], Loss: 0.0335\n",
      "Epoch [12/50], Step [434/735], Loss: 0.0490\n",
      "Epoch [12/50], Step [435/735], Loss: 0.0756\n",
      "Epoch [12/50], Step [436/735], Loss: 0.0385\n",
      "Epoch [12/50], Step [437/735], Loss: 0.1837\n",
      "Epoch [12/50], Step [438/735], Loss: 0.1789\n",
      "Epoch [12/50], Step [439/735], Loss: 0.2085\n",
      "Epoch [12/50], Step [440/735], Loss: 0.0928\n",
      "Epoch [12/50], Step [441/735], Loss: 0.1672\n",
      "Epoch [12/50], Step [442/735], Loss: 0.1613\n",
      "Epoch [12/50], Step [443/735], Loss: 0.1672\n",
      "Epoch [12/50], Step [444/735], Loss: 0.0647\n",
      "Epoch [12/50], Step [445/735], Loss: 0.0586\n",
      "Epoch [12/50], Step [446/735], Loss: 0.0377\n",
      "Epoch [12/50], Step [447/735], Loss: 0.2745\n",
      "Epoch [12/50], Step [448/735], Loss: 0.3195\n",
      "Epoch [12/50], Step [449/735], Loss: 0.1897\n",
      "Epoch [12/50], Step [450/735], Loss: 0.0440\n",
      "Epoch [12/50], Step [451/735], Loss: 0.1680\n",
      "Epoch [12/50], Step [452/735], Loss: 0.5000\n",
      "Epoch [12/50], Step [453/735], Loss: 0.0955\n",
      "Epoch [12/50], Step [454/735], Loss: 0.0912\n",
      "Epoch [12/50], Step [455/735], Loss: 0.0841\n",
      "Epoch [12/50], Step [456/735], Loss: 0.0648\n",
      "Epoch [12/50], Step [457/735], Loss: 0.1137\n",
      "Epoch [12/50], Step [458/735], Loss: 0.1069\n",
      "Epoch [12/50], Step [459/735], Loss: 0.0640\n",
      "Epoch [12/50], Step [460/735], Loss: 0.1219\n",
      "Epoch [12/50], Step [461/735], Loss: 0.0877\n",
      "Epoch [12/50], Step [462/735], Loss: 0.0503\n",
      "Epoch [12/50], Step [463/735], Loss: 0.1641\n",
      "Epoch [12/50], Step [464/735], Loss: 0.0627\n",
      "Epoch [12/50], Step [465/735], Loss: 0.1398\n",
      "Epoch [12/50], Step [466/735], Loss: 0.1224\n",
      "Epoch [12/50], Step [467/735], Loss: 0.0462\n",
      "Epoch [12/50], Step [468/735], Loss: 0.1806\n",
      "Epoch [12/50], Step [469/735], Loss: 0.2701\n",
      "Epoch [12/50], Step [470/735], Loss: 0.1513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Step [471/735], Loss: 0.0936\n",
      "Epoch [12/50], Step [472/735], Loss: 0.1873\n",
      "Epoch [12/50], Step [473/735], Loss: 0.0820\n",
      "Epoch [12/50], Step [474/735], Loss: 0.0544\n",
      "Epoch [12/50], Step [475/735], Loss: 0.0476\n",
      "Epoch [12/50], Step [476/735], Loss: 0.0799\n",
      "Epoch [12/50], Step [477/735], Loss: 0.0811\n",
      "Epoch [12/50], Step [478/735], Loss: 0.1971\n",
      "Epoch [12/50], Step [479/735], Loss: 0.0935\n",
      "Epoch [12/50], Step [480/735], Loss: 0.1986\n",
      "Epoch [12/50], Step [481/735], Loss: 0.1356\n",
      "Epoch [12/50], Step [482/735], Loss: 0.0827\n",
      "Epoch [12/50], Step [483/735], Loss: 0.0782\n",
      "Epoch [12/50], Step [484/735], Loss: 0.1442\n",
      "Epoch [12/50], Step [485/735], Loss: 0.1016\n",
      "Epoch [12/50], Step [486/735], Loss: 0.2192\n",
      "Epoch [12/50], Step [487/735], Loss: 0.0601\n",
      "Epoch [12/50], Step [488/735], Loss: 0.0898\n",
      "Epoch [12/50], Step [489/735], Loss: 0.0839\n",
      "Epoch [12/50], Step [490/735], Loss: 0.0720\n",
      "Epoch [12/50], Step [491/735], Loss: 0.1004\n",
      "Epoch [12/50], Step [492/735], Loss: 0.0870\n",
      "Epoch [12/50], Step [493/735], Loss: 0.0450\n",
      "Epoch [12/50], Step [494/735], Loss: 0.1613\n",
      "Epoch [12/50], Step [495/735], Loss: 0.0742\n",
      "Epoch [12/50], Step [496/735], Loss: 0.0919\n",
      "Epoch [12/50], Step [497/735], Loss: 0.1200\n",
      "Epoch [12/50], Step [498/735], Loss: 0.0421\n",
      "Epoch [12/50], Step [499/735], Loss: 0.4746\n",
      "Epoch [12/50], Step [500/735], Loss: 0.1517\n",
      "Epoch [12/50], Step [501/735], Loss: 0.0653\n",
      "Epoch [12/50], Step [502/735], Loss: 0.0817\n",
      "Epoch [12/50], Step [503/735], Loss: 0.0988\n",
      "Epoch [12/50], Step [504/735], Loss: 0.0605\n",
      "Epoch [12/50], Step [505/735], Loss: 0.0509\n",
      "Epoch [12/50], Step [506/735], Loss: 0.1021\n",
      "Epoch [12/50], Step [507/735], Loss: 0.3471\n",
      "Epoch [12/50], Step [508/735], Loss: 0.1948\n",
      "Epoch [12/50], Step [509/735], Loss: 0.1086\n",
      "Epoch [12/50], Step [510/735], Loss: 0.0702\n",
      "Epoch [12/50], Step [511/735], Loss: 0.0947\n",
      "Epoch [12/50], Step [512/735], Loss: 0.0544\n",
      "Epoch [12/50], Step [513/735], Loss: 0.0405\n",
      "Epoch [12/50], Step [514/735], Loss: 0.0907\n",
      "Epoch [12/50], Step [515/735], Loss: 0.0286\n",
      "Epoch [12/50], Step [516/735], Loss: 0.2029\n",
      "Epoch [12/50], Step [517/735], Loss: 0.1404\n",
      "Epoch [12/50], Step [518/735], Loss: 0.0764\n",
      "Epoch [12/50], Step [519/735], Loss: 0.0294\n",
      "Epoch [12/50], Step [520/735], Loss: 0.0411\n",
      "Epoch [12/50], Step [521/735], Loss: 0.0380\n",
      "Epoch [12/50], Step [522/735], Loss: 0.1469\n",
      "Epoch [12/50], Step [523/735], Loss: 0.1033\n",
      "Epoch [12/50], Step [524/735], Loss: 0.0579\n",
      "Epoch [12/50], Step [525/735], Loss: 0.0465\n",
      "Epoch [12/50], Step [526/735], Loss: 0.0766\n",
      "Epoch [12/50], Step [527/735], Loss: 0.0368\n",
      "Epoch [12/50], Step [528/735], Loss: 0.0845\n",
      "Epoch [12/50], Step [529/735], Loss: 0.1676\n",
      "Epoch [12/50], Step [530/735], Loss: 0.0255\n",
      "Epoch [12/50], Step [531/735], Loss: 0.0249\n",
      "Epoch [12/50], Step [532/735], Loss: 0.0385\n",
      "Epoch [12/50], Step [533/735], Loss: 0.0452\n",
      "Epoch [12/50], Step [534/735], Loss: 0.3855\n",
      "Epoch [12/50], Step [535/735], Loss: 0.0472\n",
      "Epoch [12/50], Step [536/735], Loss: 0.0648\n",
      "Epoch [12/50], Step [537/735], Loss: 0.0872\n",
      "Epoch [12/50], Step [538/735], Loss: 0.3027\n",
      "Epoch [12/50], Step [539/735], Loss: 0.1011\n",
      "Epoch [12/50], Step [540/735], Loss: 0.1145\n",
      "Epoch [12/50], Step [541/735], Loss: 0.0440\n",
      "Epoch [12/50], Step [542/735], Loss: 0.1385\n",
      "Epoch [12/50], Step [543/735], Loss: 0.2650\n",
      "Epoch [12/50], Step [544/735], Loss: 0.0601\n",
      "Epoch [12/50], Step [545/735], Loss: 0.1362\n",
      "Epoch [12/50], Step [546/735], Loss: 0.0461\n",
      "Epoch [12/50], Step [547/735], Loss: 0.1175\n",
      "Epoch [12/50], Step [548/735], Loss: 0.0308\n",
      "Epoch [12/50], Step [549/735], Loss: 0.0287\n",
      "Epoch [12/50], Step [550/735], Loss: 0.0318\n",
      "Epoch [12/50], Step [551/735], Loss: 0.1117\n",
      "Epoch [12/50], Step [552/735], Loss: 0.1686\n",
      "Epoch [12/50], Step [553/735], Loss: 0.0449\n",
      "Epoch [12/50], Step [554/735], Loss: 0.0957\n",
      "Epoch [12/50], Step [555/735], Loss: 0.0864\n",
      "Epoch [12/50], Step [556/735], Loss: 0.0574\n",
      "Epoch [12/50], Step [557/735], Loss: 0.1050\n",
      "Epoch [12/50], Step [558/735], Loss: 0.0387\n",
      "Epoch [12/50], Step [559/735], Loss: 0.0609\n",
      "Epoch [12/50], Step [560/735], Loss: 0.1342\n",
      "Epoch [12/50], Step [561/735], Loss: 0.0666\n",
      "Epoch [12/50], Step [562/735], Loss: 0.0262\n",
      "Epoch [12/50], Step [563/735], Loss: 0.1354\n",
      "Epoch [12/50], Step [564/735], Loss: 0.1780\n",
      "Epoch [12/50], Step [565/735], Loss: 0.0396\n",
      "Epoch [12/50], Step [566/735], Loss: 0.1007\n",
      "Epoch [12/50], Step [567/735], Loss: 0.0862\n",
      "Epoch [12/50], Step [568/735], Loss: 0.0668\n",
      "Epoch [12/50], Step [569/735], Loss: 0.0999\n",
      "Epoch [12/50], Step [570/735], Loss: 0.0634\n",
      "Epoch [12/50], Step [571/735], Loss: 0.0523\n",
      "Epoch [12/50], Step [572/735], Loss: 0.0669\n",
      "Epoch [12/50], Step [573/735], Loss: 0.0821\n",
      "Epoch [12/50], Step [574/735], Loss: 0.2458\n",
      "Epoch [12/50], Step [575/735], Loss: 0.1633\n",
      "Epoch [12/50], Step [576/735], Loss: 0.3298\n",
      "Epoch [12/50], Step [577/735], Loss: 0.0461\n",
      "Epoch [12/50], Step [578/735], Loss: 0.0343\n",
      "Epoch [12/50], Step [579/735], Loss: 0.0285\n",
      "Epoch [12/50], Step [580/735], Loss: 0.0531\n",
      "Epoch [12/50], Step [581/735], Loss: 0.0265\n",
      "Epoch [12/50], Step [582/735], Loss: 0.0673\n",
      "Epoch [12/50], Step [583/735], Loss: 0.1483\n",
      "Epoch [12/50], Step [584/735], Loss: 0.0509\n",
      "Epoch [12/50], Step [585/735], Loss: 0.0294\n",
      "Epoch [12/50], Step [586/735], Loss: 0.1748\n",
      "Epoch [12/50], Step [587/735], Loss: 0.0603\n",
      "Epoch [12/50], Step [588/735], Loss: 0.1286\n",
      "Epoch [12/50], Step [589/735], Loss: 0.0464\n",
      "Epoch [12/50], Step [590/735], Loss: 0.4985\n",
      "Epoch [12/50], Step [591/735], Loss: 0.2273\n",
      "Epoch [12/50], Step [592/735], Loss: 0.4100\n",
      "Epoch [12/50], Step [593/735], Loss: 0.0842\n",
      "Epoch [12/50], Step [594/735], Loss: 0.0819\n",
      "Epoch [12/50], Step [595/735], Loss: 0.2560\n",
      "Epoch [12/50], Step [596/735], Loss: 0.1510\n",
      "Epoch [12/50], Step [597/735], Loss: 0.1385\n",
      "Epoch [12/50], Step [598/735], Loss: 0.2048\n",
      "Epoch [12/50], Step [599/735], Loss: 0.1255\n",
      "Epoch [12/50], Step [600/735], Loss: 0.0642\n",
      "Epoch [12/50], Step [601/735], Loss: 0.0454\n",
      "Epoch [12/50], Step [602/735], Loss: 0.0819\n",
      "Epoch [12/50], Step [603/735], Loss: 0.0256\n",
      "Epoch [12/50], Step [604/735], Loss: 0.0618\n",
      "Epoch [12/50], Step [605/735], Loss: 0.0660\n",
      "Epoch [12/50], Step [606/735], Loss: 0.0458\n",
      "Epoch [12/50], Step [607/735], Loss: 0.1572\n",
      "Epoch [12/50], Step [608/735], Loss: 0.0488\n",
      "Epoch [12/50], Step [609/735], Loss: 0.1215\n",
      "Epoch [12/50], Step [610/735], Loss: 0.0504\n",
      "Epoch [12/50], Step [611/735], Loss: 0.1320\n",
      "Epoch [12/50], Step [612/735], Loss: 0.0209\n",
      "Epoch [12/50], Step [613/735], Loss: 0.2655\n",
      "Epoch [12/50], Step [614/735], Loss: 0.1283\n",
      "Epoch [12/50], Step [615/735], Loss: 0.0673\n",
      "Epoch [12/50], Step [616/735], Loss: 0.0890\n",
      "Epoch [12/50], Step [617/735], Loss: 0.0839\n",
      "Epoch [12/50], Step [618/735], Loss: 0.0338\n",
      "Epoch [12/50], Step [619/735], Loss: 0.0418\n",
      "Epoch [12/50], Step [620/735], Loss: 0.0503\n",
      "Epoch [12/50], Step [621/735], Loss: 0.1276\n",
      "Epoch [12/50], Step [622/735], Loss: 0.0306\n",
      "Epoch [12/50], Step [623/735], Loss: 0.0322\n",
      "Epoch [12/50], Step [624/735], Loss: 0.0427\n",
      "Epoch [12/50], Step [625/735], Loss: 0.0310\n",
      "Epoch [12/50], Step [626/735], Loss: 0.0957\n",
      "Epoch [12/50], Step [627/735], Loss: 0.0859\n",
      "Epoch [12/50], Step [628/735], Loss: 0.1340\n",
      "Epoch [12/50], Step [629/735], Loss: 0.0416\n",
      "Epoch [12/50], Step [630/735], Loss: 0.0410\n",
      "Epoch [12/50], Step [631/735], Loss: 0.0320\n",
      "Epoch [12/50], Step [632/735], Loss: 0.0228\n",
      "Epoch [12/50], Step [633/735], Loss: 0.1018\n",
      "Epoch [12/50], Step [634/735], Loss: 0.0518\n",
      "Epoch [12/50], Step [635/735], Loss: 0.0643\n",
      "Epoch [12/50], Step [636/735], Loss: 0.0558\n",
      "Epoch [12/50], Step [637/735], Loss: 0.0681\n",
      "Epoch [12/50], Step [638/735], Loss: 0.0514\n",
      "Epoch [12/50], Step [639/735], Loss: 0.0743\n",
      "Epoch [12/50], Step [640/735], Loss: 0.0599\n",
      "Epoch [12/50], Step [641/735], Loss: 0.0553\n",
      "Epoch [12/50], Step [642/735], Loss: 0.2934\n",
      "Epoch [12/50], Step [643/735], Loss: 0.0505\n",
      "Epoch [12/50], Step [644/735], Loss: 0.1465\n",
      "Epoch [12/50], Step [645/735], Loss: 0.0652\n",
      "Epoch [12/50], Step [646/735], Loss: 0.0362\n",
      "Epoch [12/50], Step [647/735], Loss: 0.1060\n",
      "Epoch [12/50], Step [648/735], Loss: 0.0506\n",
      "Epoch [12/50], Step [649/735], Loss: 0.0344\n",
      "Epoch [12/50], Step [650/735], Loss: 0.0792\n",
      "Epoch [12/50], Step [651/735], Loss: 0.0496\n",
      "Epoch [12/50], Step [652/735], Loss: 0.0643\n",
      "Epoch [12/50], Step [653/735], Loss: 0.1375\n",
      "Epoch [12/50], Step [654/735], Loss: 0.0633\n",
      "Epoch [12/50], Step [655/735], Loss: 0.0682\n",
      "Epoch [12/50], Step [656/735], Loss: 0.0499\n",
      "Epoch [12/50], Step [657/735], Loss: 0.0625\n",
      "Epoch [12/50], Step [658/735], Loss: 0.0647\n",
      "Epoch [12/50], Step [659/735], Loss: 0.4808\n",
      "Epoch [12/50], Step [660/735], Loss: 0.0582\n",
      "Epoch [12/50], Step [661/735], Loss: 0.0328\n",
      "Epoch [12/50], Step [662/735], Loss: 0.2401\n",
      "Epoch [12/50], Step [663/735], Loss: 0.1559\n",
      "Epoch [12/50], Step [664/735], Loss: 0.0418\n",
      "Epoch [12/50], Step [665/735], Loss: 0.0612\n",
      "Epoch [12/50], Step [666/735], Loss: 0.2377\n",
      "Epoch [12/50], Step [667/735], Loss: 0.1584\n",
      "Epoch [12/50], Step [668/735], Loss: 0.0407\n",
      "Epoch [12/50], Step [669/735], Loss: 0.1030\n",
      "Epoch [12/50], Step [670/735], Loss: 0.0983\n",
      "Epoch [12/50], Step [671/735], Loss: 0.1019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Step [672/735], Loss: 0.1112\n",
      "Epoch [12/50], Step [673/735], Loss: 0.0930\n",
      "Epoch [12/50], Step [674/735], Loss: 0.0395\n",
      "Epoch [12/50], Step [675/735], Loss: 0.0448\n",
      "Epoch [12/50], Step [676/735], Loss: 0.2895\n",
      "Epoch [12/50], Step [677/735], Loss: 0.0693\n",
      "Epoch [12/50], Step [678/735], Loss: 0.1505\n",
      "Epoch [12/50], Step [679/735], Loss: 0.5227\n",
      "Epoch [12/50], Step [680/735], Loss: 0.0852\n",
      "Epoch [12/50], Step [681/735], Loss: 0.1168\n",
      "Epoch [12/50], Step [682/735], Loss: 0.0599\n",
      "Epoch [12/50], Step [683/735], Loss: 0.0589\n",
      "Epoch [12/50], Step [684/735], Loss: 0.1550\n",
      "Epoch [12/50], Step [685/735], Loss: 0.2206\n",
      "Epoch [12/50], Step [686/735], Loss: 0.1466\n",
      "Epoch [12/50], Step [687/735], Loss: 0.1114\n",
      "Epoch [12/50], Step [688/735], Loss: 0.0781\n",
      "Epoch [12/50], Step [689/735], Loss: 0.0733\n",
      "Epoch [12/50], Step [690/735], Loss: 0.0430\n",
      "Epoch [12/50], Step [691/735], Loss: 0.2194\n",
      "Epoch [12/50], Step [692/735], Loss: 0.0610\n",
      "Epoch [12/50], Step [693/735], Loss: 0.0530\n",
      "Epoch [12/50], Step [694/735], Loss: 0.0506\n",
      "Epoch [12/50], Step [695/735], Loss: 0.2844\n",
      "Epoch [12/50], Step [696/735], Loss: 0.0787\n",
      "Epoch [12/50], Step [697/735], Loss: 0.1690\n",
      "Epoch [12/50], Step [698/735], Loss: 0.0696\n",
      "Epoch [12/50], Step [699/735], Loss: 0.0537\n",
      "Epoch [12/50], Step [700/735], Loss: 0.0993\n",
      "Epoch [12/50], Step [701/735], Loss: 0.1272\n",
      "Epoch [12/50], Step [702/735], Loss: 0.3782\n",
      "Epoch [12/50], Step [703/735], Loss: 0.1832\n",
      "Epoch [12/50], Step [704/735], Loss: 0.0541\n",
      "Epoch [12/50], Step [705/735], Loss: 0.1218\n",
      "Epoch [12/50], Step [706/735], Loss: 0.0664\n",
      "Epoch [12/50], Step [707/735], Loss: 0.0503\n",
      "Epoch [12/50], Step [708/735], Loss: 0.0636\n",
      "Epoch [12/50], Step [709/735], Loss: 0.0867\n",
      "Epoch [12/50], Step [710/735], Loss: 0.1242\n",
      "Epoch [12/50], Step [711/735], Loss: 0.0492\n",
      "Epoch [12/50], Step [712/735], Loss: 0.0362\n",
      "Epoch [12/50], Step [713/735], Loss: 0.0690\n",
      "Epoch [12/50], Step [714/735], Loss: 0.0704\n",
      "Epoch [12/50], Step [715/735], Loss: 0.0256\n",
      "Epoch [12/50], Step [716/735], Loss: 0.0968\n",
      "Epoch [12/50], Step [717/735], Loss: 0.1213\n",
      "Epoch [12/50], Step [718/735], Loss: 0.1035\n",
      "Epoch [12/50], Step [719/735], Loss: 0.1670\n",
      "Epoch [12/50], Step [720/735], Loss: 0.0236\n",
      "Epoch [12/50], Step [721/735], Loss: 0.0933\n",
      "Epoch [12/50], Step [722/735], Loss: 0.1712\n",
      "Epoch [12/50], Step [723/735], Loss: 0.0496\n",
      "Epoch [12/50], Step [724/735], Loss: 0.0866\n",
      "Epoch [12/50], Step [725/735], Loss: 0.0944\n",
      "Epoch [12/50], Step [726/735], Loss: 0.0568\n",
      "Epoch [12/50], Step [727/735], Loss: 0.2504\n",
      "Epoch [12/50], Step [728/735], Loss: 0.0781\n",
      "Epoch [12/50], Step [729/735], Loss: 0.2837\n",
      "Epoch [12/50], Step [730/735], Loss: 0.1939\n",
      "Epoch [12/50], Step [731/735], Loss: 0.0585\n",
      "Epoch [12/50], Step [732/735], Loss: 0.0444\n",
      "Epoch [12/50], Step [733/735], Loss: 0.0863\n",
      "Epoch [12/50], Step [734/735], Loss: 0.1906\n",
      "Epoch [12/50], Step [735/735], Loss: 0.1033\n",
      "Epoch [13/50], Step [1/735], Loss: 0.0514\n",
      "Epoch [13/50], Step [2/735], Loss: 0.2164\n",
      "Epoch [13/50], Step [3/735], Loss: 0.1220\n",
      "Epoch [13/50], Step [4/735], Loss: 0.1258\n",
      "Epoch [13/50], Step [5/735], Loss: 0.2109\n",
      "Epoch [13/50], Step [6/735], Loss: 0.0572\n",
      "Epoch [13/50], Step [7/735], Loss: 0.3203\n",
      "Epoch [13/50], Step [8/735], Loss: 0.2990\n",
      "Epoch [13/50], Step [9/735], Loss: 0.0611\n",
      "Epoch [13/50], Step [10/735], Loss: 0.2155\n",
      "Epoch [13/50], Step [11/735], Loss: 0.0735\n",
      "Epoch [13/50], Step [12/735], Loss: 0.0527\n",
      "Epoch [13/50], Step [13/735], Loss: 0.0410\n",
      "Epoch [13/50], Step [14/735], Loss: 0.0470\n",
      "Epoch [13/50], Step [15/735], Loss: 0.0822\n",
      "Epoch [13/50], Step [16/735], Loss: 0.0917\n",
      "Epoch [13/50], Step [17/735], Loss: 0.0387\n",
      "Epoch [13/50], Step [18/735], Loss: 0.1344\n",
      "Epoch [13/50], Step [19/735], Loss: 0.0511\n",
      "Epoch [13/50], Step [20/735], Loss: 0.0441\n",
      "Epoch [13/50], Step [21/735], Loss: 0.0868\n",
      "Epoch [13/50], Step [22/735], Loss: 0.0213\n",
      "Epoch [13/50], Step [23/735], Loss: 0.0418\n",
      "Epoch [13/50], Step [24/735], Loss: 0.0904\n",
      "Epoch [13/50], Step [25/735], Loss: 0.0621\n",
      "Epoch [13/50], Step [26/735], Loss: 0.0277\n",
      "Epoch [13/50], Step [27/735], Loss: 0.1915\n",
      "Epoch [13/50], Step [28/735], Loss: 0.1494\n",
      "Epoch [13/50], Step [29/735], Loss: 0.0647\n",
      "Epoch [13/50], Step [30/735], Loss: 0.0547\n",
      "Epoch [13/50], Step [31/735], Loss: 0.1548\n",
      "Epoch [13/50], Step [32/735], Loss: 0.2784\n",
      "Epoch [13/50], Step [33/735], Loss: 0.0819\n",
      "Epoch [13/50], Step [34/735], Loss: 0.0432\n",
      "Epoch [13/50], Step [35/735], Loss: 0.1823\n",
      "Epoch [13/50], Step [36/735], Loss: 0.0925\n",
      "Epoch [13/50], Step [37/735], Loss: 0.0710\n",
      "Epoch [13/50], Step [38/735], Loss: 0.0536\n",
      "Epoch [13/50], Step [39/735], Loss: 0.0808\n",
      "Epoch [13/50], Step [40/735], Loss: 0.0427\n",
      "Epoch [13/50], Step [41/735], Loss: 0.0269\n",
      "Epoch [13/50], Step [42/735], Loss: 0.0741\n",
      "Epoch [13/50], Step [43/735], Loss: 0.0317\n",
      "Epoch [13/50], Step [44/735], Loss: 0.0801\n",
      "Epoch [13/50], Step [45/735], Loss: 0.0812\n",
      "Epoch [13/50], Step [46/735], Loss: 0.0839\n",
      "Epoch [13/50], Step [47/735], Loss: 0.0336\n",
      "Epoch [13/50], Step [48/735], Loss: 0.1702\n",
      "Epoch [13/50], Step [49/735], Loss: 0.0993\n",
      "Epoch [13/50], Step [50/735], Loss: 0.0652\n",
      "Epoch [13/50], Step [51/735], Loss: 0.0594\n",
      "Epoch [13/50], Step [52/735], Loss: 0.0686\n",
      "Epoch [13/50], Step [53/735], Loss: 0.0996\n",
      "Epoch [13/50], Step [54/735], Loss: 0.0213\n",
      "Epoch [13/50], Step [55/735], Loss: 0.0678\n",
      "Epoch [13/50], Step [56/735], Loss: 0.1142\n",
      "Epoch [13/50], Step [57/735], Loss: 0.0564\n",
      "Epoch [13/50], Step [58/735], Loss: 0.1412\n",
      "Epoch [13/50], Step [59/735], Loss: 0.0440\n",
      "Epoch [13/50], Step [60/735], Loss: 0.6826\n",
      "Epoch [13/50], Step [61/735], Loss: 0.0518\n",
      "Epoch [13/50], Step [62/735], Loss: 0.0867\n",
      "Epoch [13/50], Step [63/735], Loss: 0.0395\n",
      "Epoch [13/50], Step [64/735], Loss: 0.0898\n",
      "Epoch [13/50], Step [65/735], Loss: 0.0757\n",
      "Epoch [13/50], Step [66/735], Loss: 0.0759\n",
      "Epoch [13/50], Step [67/735], Loss: 0.0991\n",
      "Epoch [13/50], Step [68/735], Loss: 0.1748\n",
      "Epoch [13/50], Step [69/735], Loss: 0.1579\n",
      "Epoch [13/50], Step [70/735], Loss: 0.0791\n",
      "Epoch [13/50], Step [71/735], Loss: 0.1679\n",
      "Epoch [13/50], Step [72/735], Loss: 0.1285\n",
      "Epoch [13/50], Step [73/735], Loss: 0.0482\n",
      "Epoch [13/50], Step [74/735], Loss: 0.0552\n",
      "Epoch [13/50], Step [75/735], Loss: 0.0282\n",
      "Epoch [13/50], Step [76/735], Loss: 0.0981\n",
      "Epoch [13/50], Step [77/735], Loss: 0.0355\n",
      "Epoch [13/50], Step [78/735], Loss: 0.0732\n",
      "Epoch [13/50], Step [79/735], Loss: 0.0619\n",
      "Epoch [13/50], Step [80/735], Loss: 0.0706\n",
      "Epoch [13/50], Step [81/735], Loss: 0.0680\n",
      "Epoch [13/50], Step [82/735], Loss: 0.0745\n",
      "Epoch [13/50], Step [83/735], Loss: 0.1292\n",
      "Epoch [13/50], Step [84/735], Loss: 0.3715\n",
      "Epoch [13/50], Step [85/735], Loss: 0.0467\n",
      "Epoch [13/50], Step [86/735], Loss: 0.1086\n",
      "Epoch [13/50], Step [87/735], Loss: 0.1127\n",
      "Epoch [13/50], Step [88/735], Loss: 0.0402\n",
      "Epoch [13/50], Step [89/735], Loss: 0.0916\n",
      "Epoch [13/50], Step [90/735], Loss: 0.0617\n",
      "Epoch [13/50], Step [91/735], Loss: 0.1023\n",
      "Epoch [13/50], Step [92/735], Loss: 0.0553\n",
      "Epoch [13/50], Step [93/735], Loss: 0.1045\n",
      "Epoch [13/50], Step [94/735], Loss: 0.0291\n",
      "Epoch [13/50], Step [95/735], Loss: 0.0340\n",
      "Epoch [13/50], Step [96/735], Loss: 0.0509\n",
      "Epoch [13/50], Step [97/735], Loss: 0.0506\n",
      "Epoch [13/50], Step [98/735], Loss: 0.0896\n",
      "Epoch [13/50], Step [99/735], Loss: 0.1060\n",
      "Epoch [13/50], Step [100/735], Loss: 0.0205\n",
      "Epoch [13/50], Step [101/735], Loss: 0.0887\n",
      "Epoch [13/50], Step [102/735], Loss: 0.3174\n",
      "Epoch [13/50], Step [103/735], Loss: 0.0233\n",
      "Epoch [13/50], Step [104/735], Loss: 0.0979\n",
      "Epoch [13/50], Step [105/735], Loss: 0.0462\n",
      "Epoch [13/50], Step [106/735], Loss: 0.0866\n",
      "Epoch [13/50], Step [107/735], Loss: 0.0268\n",
      "Epoch [13/50], Step [108/735], Loss: 0.0851\n",
      "Epoch [13/50], Step [109/735], Loss: 0.0513\n",
      "Epoch [13/50], Step [110/735], Loss: 0.1177\n",
      "Epoch [13/50], Step [111/735], Loss: 0.0294\n",
      "Epoch [13/50], Step [112/735], Loss: 0.0503\n",
      "Epoch [13/50], Step [113/735], Loss: 0.0516\n",
      "Epoch [13/50], Step [114/735], Loss: 0.0960\n",
      "Epoch [13/50], Step [115/735], Loss: 0.0222\n",
      "Epoch [13/50], Step [116/735], Loss: 0.1195\n",
      "Epoch [13/50], Step [117/735], Loss: 0.0603\n",
      "Epoch [13/50], Step [118/735], Loss: 0.1800\n",
      "Epoch [13/50], Step [119/735], Loss: 0.0877\n",
      "Epoch [13/50], Step [120/735], Loss: 0.0860\n",
      "Epoch [13/50], Step [121/735], Loss: 0.1003\n",
      "Epoch [13/50], Step [122/735], Loss: 0.0838\n",
      "Epoch [13/50], Step [123/735], Loss: 0.1391\n",
      "Epoch [13/50], Step [124/735], Loss: 0.0566\n",
      "Epoch [13/50], Step [125/735], Loss: 0.1195\n",
      "Epoch [13/50], Step [126/735], Loss: 0.1828\n",
      "Epoch [13/50], Step [127/735], Loss: 0.6575\n",
      "Epoch [13/50], Step [128/735], Loss: 0.1252\n",
      "Epoch [13/50], Step [129/735], Loss: 0.0568\n",
      "Epoch [13/50], Step [130/735], Loss: 0.0322\n",
      "Epoch [13/50], Step [131/735], Loss: 0.1037\n",
      "Epoch [13/50], Step [132/735], Loss: 0.0518\n",
      "Epoch [13/50], Step [133/735], Loss: 0.0814\n",
      "Epoch [13/50], Step [134/735], Loss: 0.0462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Step [135/735], Loss: 0.1129\n",
      "Epoch [13/50], Step [136/735], Loss: 0.0764\n",
      "Epoch [13/50], Step [137/735], Loss: 0.0649\n",
      "Epoch [13/50], Step [138/735], Loss: 0.0350\n",
      "Epoch [13/50], Step [139/735], Loss: 0.0677\n",
      "Epoch [13/50], Step [140/735], Loss: 0.0641\n",
      "Epoch [13/50], Step [141/735], Loss: 0.4586\n",
      "Epoch [13/50], Step [142/735], Loss: 0.1973\n",
      "Epoch [13/50], Step [143/735], Loss: 0.0866\n",
      "Epoch [13/50], Step [144/735], Loss: 0.1370\n",
      "Epoch [13/50], Step [145/735], Loss: 0.3102\n",
      "Epoch [13/50], Step [146/735], Loss: 0.0195\n",
      "Epoch [13/50], Step [147/735], Loss: 0.0328\n",
      "Epoch [13/50], Step [148/735], Loss: 0.2573\n",
      "Epoch [13/50], Step [149/735], Loss: 0.1451\n",
      "Epoch [13/50], Step [150/735], Loss: 0.0855\n",
      "Epoch [13/50], Step [151/735], Loss: 0.0817\n",
      "Epoch [13/50], Step [152/735], Loss: 0.1566\n",
      "Epoch [13/50], Step [153/735], Loss: 0.0443\n",
      "Epoch [13/50], Step [154/735], Loss: 0.0628\n",
      "Epoch [13/50], Step [155/735], Loss: 0.0430\n",
      "Epoch [13/50], Step [156/735], Loss: 0.0475\n",
      "Epoch [13/50], Step [157/735], Loss: 0.0133\n",
      "Epoch [13/50], Step [158/735], Loss: 0.2683\n",
      "Epoch [13/50], Step [159/735], Loss: 0.3143\n",
      "Epoch [13/50], Step [160/735], Loss: 0.1961\n",
      "Epoch [13/50], Step [161/735], Loss: 0.0796\n",
      "Epoch [13/50], Step [162/735], Loss: 0.0719\n",
      "Epoch [13/50], Step [163/735], Loss: 0.1945\n",
      "Epoch [13/50], Step [164/735], Loss: 0.0644\n",
      "Epoch [13/50], Step [165/735], Loss: 0.0667\n",
      "Epoch [13/50], Step [166/735], Loss: 0.0197\n",
      "Epoch [13/50], Step [167/735], Loss: 0.2628\n",
      "Epoch [13/50], Step [168/735], Loss: 0.0560\n",
      "Epoch [13/50], Step [169/735], Loss: 0.0729\n",
      "Epoch [13/50], Step [170/735], Loss: 0.0506\n",
      "Epoch [13/50], Step [171/735], Loss: 0.1995\n",
      "Epoch [13/50], Step [172/735], Loss: 0.0193\n",
      "Epoch [13/50], Step [173/735], Loss: 0.0563\n",
      "Epoch [13/50], Step [174/735], Loss: 0.0852\n",
      "Epoch [13/50], Step [175/735], Loss: 0.1864\n",
      "Epoch [13/50], Step [176/735], Loss: 0.0814\n",
      "Epoch [13/50], Step [177/735], Loss: 0.0387\n",
      "Epoch [13/50], Step [178/735], Loss: 0.0635\n",
      "Epoch [13/50], Step [179/735], Loss: 0.1043\n",
      "Epoch [13/50], Step [180/735], Loss: 0.0483\n",
      "Epoch [13/50], Step [181/735], Loss: 0.2678\n",
      "Epoch [13/50], Step [182/735], Loss: 0.0478\n",
      "Epoch [13/50], Step [183/735], Loss: 0.0752\n",
      "Epoch [13/50], Step [184/735], Loss: 0.0428\n",
      "Epoch [13/50], Step [185/735], Loss: 0.1690\n",
      "Epoch [13/50], Step [186/735], Loss: 0.0702\n",
      "Epoch [13/50], Step [187/735], Loss: 0.0292\n",
      "Epoch [13/50], Step [188/735], Loss: 0.0831\n",
      "Epoch [13/50], Step [189/735], Loss: 0.1062\n",
      "Epoch [13/50], Step [190/735], Loss: 0.0501\n",
      "Epoch [13/50], Step [191/735], Loss: 0.1048\n",
      "Epoch [13/50], Step [192/735], Loss: 0.0388\n",
      "Epoch [13/50], Step [193/735], Loss: 0.0632\n",
      "Epoch [13/50], Step [194/735], Loss: 0.0910\n",
      "Epoch [13/50], Step [195/735], Loss: 0.1323\n",
      "Epoch [13/50], Step [196/735], Loss: 0.0696\n",
      "Epoch [13/50], Step [197/735], Loss: 0.0789\n",
      "Epoch [13/50], Step [198/735], Loss: 0.0300\n",
      "Epoch [13/50], Step [199/735], Loss: 0.0510\n",
      "Epoch [13/50], Step [200/735], Loss: 0.1736\n",
      "Epoch [13/50], Step [201/735], Loss: 0.1646\n",
      "Epoch [13/50], Step [202/735], Loss: 0.1069\n",
      "Epoch [13/50], Step [203/735], Loss: 0.0289\n",
      "Epoch [13/50], Step [204/735], Loss: 0.0563\n",
      "Epoch [13/50], Step [205/735], Loss: 0.4248\n",
      "Epoch [13/50], Step [206/735], Loss: 0.0462\n",
      "Epoch [13/50], Step [207/735], Loss: 0.1669\n",
      "Epoch [13/50], Step [208/735], Loss: 0.0809\n",
      "Epoch [13/50], Step [209/735], Loss: 0.0277\n",
      "Epoch [13/50], Step [210/735], Loss: 0.0924\n",
      "Epoch [13/50], Step [211/735], Loss: 0.0593\n",
      "Epoch [13/50], Step [212/735], Loss: 0.0251\n",
      "Epoch [13/50], Step [213/735], Loss: 0.0593\n",
      "Epoch [13/50], Step [214/735], Loss: 0.0462\n",
      "Epoch [13/50], Step [215/735], Loss: 0.1638\n",
      "Epoch [13/50], Step [216/735], Loss: 0.1299\n",
      "Epoch [13/50], Step [217/735], Loss: 0.1095\n",
      "Epoch [13/50], Step [218/735], Loss: 0.0660\n",
      "Epoch [13/50], Step [219/735], Loss: 0.1689\n",
      "Epoch [13/50], Step [220/735], Loss: 0.2404\n",
      "Epoch [13/50], Step [221/735], Loss: 0.1142\n",
      "Epoch [13/50], Step [222/735], Loss: 0.0460\n",
      "Epoch [13/50], Step [223/735], Loss: 0.2063\n",
      "Epoch [13/50], Step [224/735], Loss: 0.0231\n",
      "Epoch [13/50], Step [225/735], Loss: 0.2625\n",
      "Epoch [13/50], Step [226/735], Loss: 0.1181\n",
      "Epoch [13/50], Step [227/735], Loss: 0.0708\n",
      "Epoch [13/50], Step [228/735], Loss: 0.1153\n",
      "Epoch [13/50], Step [229/735], Loss: 0.0903\n",
      "Epoch [13/50], Step [230/735], Loss: 0.0643\n",
      "Epoch [13/50], Step [231/735], Loss: 0.2995\n",
      "Epoch [13/50], Step [232/735], Loss: 0.0900\n",
      "Epoch [13/50], Step [233/735], Loss: 0.0575\n",
      "Epoch [13/50], Step [234/735], Loss: 0.0435\n",
      "Epoch [13/50], Step [235/735], Loss: 0.0338\n",
      "Epoch [13/50], Step [236/735], Loss: 0.1438\n",
      "Epoch [13/50], Step [237/735], Loss: 0.0681\n",
      "Epoch [13/50], Step [238/735], Loss: 0.4013\n",
      "Epoch [13/50], Step [239/735], Loss: 0.1141\n",
      "Epoch [13/50], Step [240/735], Loss: 0.0790\n",
      "Epoch [13/50], Step [241/735], Loss: 0.0830\n",
      "Epoch [13/50], Step [242/735], Loss: 0.0477\n",
      "Epoch [13/50], Step [243/735], Loss: 0.0769\n",
      "Epoch [13/50], Step [244/735], Loss: 0.0608\n",
      "Epoch [13/50], Step [245/735], Loss: 0.0640\n",
      "Epoch [13/50], Step [246/735], Loss: 0.1417\n",
      "Epoch [13/50], Step [247/735], Loss: 0.0576\n",
      "Epoch [13/50], Step [248/735], Loss: 0.1949\n",
      "Epoch [13/50], Step [249/735], Loss: 0.0183\n",
      "Epoch [13/50], Step [250/735], Loss: 0.1387\n",
      "Epoch [13/50], Step [251/735], Loss: 0.0993\n",
      "Epoch [13/50], Step [252/735], Loss: 0.0666\n",
      "Epoch [13/50], Step [253/735], Loss: 0.1966\n",
      "Epoch [13/50], Step [254/735], Loss: 0.0901\n",
      "Epoch [13/50], Step [255/735], Loss: 0.0530\n",
      "Epoch [13/50], Step [256/735], Loss: 0.0420\n",
      "Epoch [13/50], Step [257/735], Loss: 0.0225\n",
      "Epoch [13/50], Step [258/735], Loss: 0.0248\n",
      "Epoch [13/50], Step [259/735], Loss: 0.0479\n",
      "Epoch [13/50], Step [260/735], Loss: 0.1382\n",
      "Epoch [13/50], Step [261/735], Loss: 0.1691\n",
      "Epoch [13/50], Step [262/735], Loss: 0.0197\n",
      "Epoch [13/50], Step [263/735], Loss: 0.0295\n",
      "Epoch [13/50], Step [264/735], Loss: 0.0567\n",
      "Epoch [13/50], Step [265/735], Loss: 0.1183\n",
      "Epoch [13/50], Step [266/735], Loss: 0.0365\n",
      "Epoch [13/50], Step [267/735], Loss: 0.0181\n",
      "Epoch [13/50], Step [268/735], Loss: 0.0339\n",
      "Epoch [13/50], Step [269/735], Loss: 0.0444\n",
      "Epoch [13/50], Step [270/735], Loss: 0.1294\n",
      "Epoch [13/50], Step [271/735], Loss: 0.0564\n",
      "Epoch [13/50], Step [272/735], Loss: 0.0703\n",
      "Epoch [13/50], Step [273/735], Loss: 0.0424\n",
      "Epoch [13/50], Step [274/735], Loss: 0.6635\n",
      "Epoch [13/50], Step [275/735], Loss: 0.0613\n",
      "Epoch [13/50], Step [276/735], Loss: 0.0855\n",
      "Epoch [13/50], Step [277/735], Loss: 0.0924\n",
      "Epoch [13/50], Step [278/735], Loss: 0.0278\n",
      "Epoch [13/50], Step [279/735], Loss: 0.0364\n",
      "Epoch [13/50], Step [280/735], Loss: 0.0694\n",
      "Epoch [13/50], Step [281/735], Loss: 0.1869\n",
      "Epoch [13/50], Step [282/735], Loss: 0.0637\n",
      "Epoch [13/50], Step [283/735], Loss: 0.0586\n",
      "Epoch [13/50], Step [284/735], Loss: 0.2195\n",
      "Epoch [13/50], Step [285/735], Loss: 0.0483\n",
      "Epoch [13/50], Step [286/735], Loss: 0.1181\n",
      "Epoch [13/50], Step [287/735], Loss: 0.0562\n",
      "Epoch [13/50], Step [288/735], Loss: 0.1170\n",
      "Epoch [13/50], Step [289/735], Loss: 0.1870\n",
      "Epoch [13/50], Step [290/735], Loss: 0.4214\n",
      "Epoch [13/50], Step [291/735], Loss: 0.1706\n",
      "Epoch [13/50], Step [292/735], Loss: 0.1978\n",
      "Epoch [13/50], Step [293/735], Loss: 0.1557\n",
      "Epoch [13/50], Step [294/735], Loss: 0.0870\n",
      "Epoch [13/50], Step [295/735], Loss: 0.2427\n",
      "Epoch [13/50], Step [296/735], Loss: 0.0388\n",
      "Epoch [13/50], Step [297/735], Loss: 0.1175\n",
      "Epoch [13/50], Step [298/735], Loss: 0.0939\n",
      "Epoch [13/50], Step [299/735], Loss: 0.0595\n",
      "Epoch [13/50], Step [300/735], Loss: 0.2068\n",
      "Epoch [13/50], Step [301/735], Loss: 0.1202\n",
      "Epoch [13/50], Step [302/735], Loss: 0.0489\n",
      "Epoch [13/50], Step [303/735], Loss: 0.0661\n",
      "Epoch [13/50], Step [304/735], Loss: 0.0676\n",
      "Epoch [13/50], Step [305/735], Loss: 0.1623\n",
      "Epoch [13/50], Step [306/735], Loss: 0.0664\n",
      "Epoch [13/50], Step [307/735], Loss: 0.0299\n",
      "Epoch [13/50], Step [308/735], Loss: 0.0829\n",
      "Epoch [13/50], Step [309/735], Loss: 0.1118\n",
      "Epoch [13/50], Step [310/735], Loss: 0.0771\n",
      "Epoch [13/50], Step [311/735], Loss: 0.1850\n",
      "Epoch [13/50], Step [312/735], Loss: 0.0535\n",
      "Epoch [13/50], Step [313/735], Loss: 0.1499\n",
      "Epoch [13/50], Step [314/735], Loss: 0.0515\n",
      "Epoch [13/50], Step [315/735], Loss: 0.0534\n",
      "Epoch [13/50], Step [316/735], Loss: 0.0536\n",
      "Epoch [13/50], Step [317/735], Loss: 0.3329\n",
      "Epoch [13/50], Step [318/735], Loss: 0.0446\n",
      "Epoch [13/50], Step [319/735], Loss: 0.1148\n",
      "Epoch [13/50], Step [320/735], Loss: 0.0567\n",
      "Epoch [13/50], Step [321/735], Loss: 0.0339\n",
      "Epoch [13/50], Step [322/735], Loss: 0.5157\n",
      "Epoch [13/50], Step [323/735], Loss: 0.0760\n",
      "Epoch [13/50], Step [324/735], Loss: 0.0598\n",
      "Epoch [13/50], Step [325/735], Loss: 0.0199\n",
      "Epoch [13/50], Step [326/735], Loss: 0.0588\n",
      "Epoch [13/50], Step [327/735], Loss: 0.0199\n",
      "Epoch [13/50], Step [328/735], Loss: 0.1048\n",
      "Epoch [13/50], Step [329/735], Loss: 0.0682\n",
      "Epoch [13/50], Step [330/735], Loss: 0.0293\n",
      "Epoch [13/50], Step [331/735], Loss: 0.4552\n",
      "Epoch [13/50], Step [332/735], Loss: 0.1318\n",
      "Epoch [13/50], Step [333/735], Loss: 0.0469\n",
      "Epoch [13/50], Step [334/735], Loss: 0.1504\n",
      "Epoch [13/50], Step [335/735], Loss: 0.0990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Step [336/735], Loss: 0.0418\n",
      "Epoch [13/50], Step [337/735], Loss: 0.5253\n",
      "Epoch [13/50], Step [338/735], Loss: 0.3012\n",
      "Epoch [13/50], Step [339/735], Loss: 0.2549\n",
      "Epoch [13/50], Step [340/735], Loss: 0.1239\n",
      "Epoch [13/50], Step [341/735], Loss: 0.0640\n",
      "Epoch [13/50], Step [342/735], Loss: 0.0733\n",
      "Epoch [13/50], Step [343/735], Loss: 0.1257\n",
      "Epoch [13/50], Step [344/735], Loss: 0.0885\n",
      "Epoch [13/50], Step [345/735], Loss: 0.0943\n",
      "Epoch [13/50], Step [346/735], Loss: 0.0757\n",
      "Epoch [13/50], Step [347/735], Loss: 0.1076\n",
      "Epoch [13/50], Step [348/735], Loss: 0.0942\n",
      "Epoch [13/50], Step [349/735], Loss: 0.0568\n",
      "Epoch [13/50], Step [350/735], Loss: 0.1387\n",
      "Epoch [13/50], Step [351/735], Loss: 0.3300\n",
      "Epoch [13/50], Step [352/735], Loss: 0.2634\n",
      "Epoch [13/50], Step [353/735], Loss: 0.0889\n",
      "Epoch [13/50], Step [354/735], Loss: 0.0799\n",
      "Epoch [13/50], Step [355/735], Loss: 0.0742\n",
      "Epoch [13/50], Step [356/735], Loss: 0.0286\n",
      "Epoch [13/50], Step [357/735], Loss: 0.0858\n",
      "Epoch [13/50], Step [358/735], Loss: 0.0938\n",
      "Epoch [13/50], Step [359/735], Loss: 0.1130\n",
      "Epoch [13/50], Step [360/735], Loss: 0.0876\n",
      "Epoch [13/50], Step [361/735], Loss: 0.0728\n",
      "Epoch [13/50], Step [362/735], Loss: 0.0910\n",
      "Epoch [13/50], Step [363/735], Loss: 0.0811\n",
      "Epoch [13/50], Step [364/735], Loss: 0.2254\n",
      "Epoch [13/50], Step [365/735], Loss: 0.1253\n",
      "Epoch [13/50], Step [366/735], Loss: 0.0983\n",
      "Epoch [13/50], Step [367/735], Loss: 0.0244\n",
      "Epoch [13/50], Step [368/735], Loss: 0.0810\n",
      "Epoch [13/50], Step [369/735], Loss: 0.1061\n",
      "Epoch [13/50], Step [370/735], Loss: 0.0615\n",
      "Epoch [13/50], Step [371/735], Loss: 0.0584\n",
      "Epoch [13/50], Step [372/735], Loss: 0.1215\n",
      "Epoch [13/50], Step [373/735], Loss: 0.0878\n",
      "Epoch [13/50], Step [374/735], Loss: 0.0344\n",
      "Epoch [13/50], Step [375/735], Loss: 0.2986\n",
      "Epoch [13/50], Step [376/735], Loss: 0.0437\n",
      "Epoch [13/50], Step [377/735], Loss: 0.1493\n",
      "Epoch [13/50], Step [378/735], Loss: 0.0617\n",
      "Epoch [13/50], Step [379/735], Loss: 0.0252\n",
      "Epoch [13/50], Step [380/735], Loss: 0.0898\n",
      "Epoch [13/50], Step [381/735], Loss: 0.3099\n",
      "Epoch [13/50], Step [382/735], Loss: 0.0565\n",
      "Epoch [13/50], Step [383/735], Loss: 0.1145\n",
      "Epoch [13/50], Step [384/735], Loss: 0.0302\n",
      "Epoch [13/50], Step [385/735], Loss: 0.0781\n",
      "Epoch [13/50], Step [386/735], Loss: 0.1337\n",
      "Epoch [13/50], Step [387/735], Loss: 0.0761\n",
      "Epoch [13/50], Step [388/735], Loss: 0.2601\n",
      "Epoch [13/50], Step [389/735], Loss: 0.0614\n",
      "Epoch [13/50], Step [390/735], Loss: 0.0579\n",
      "Epoch [13/50], Step [391/735], Loss: 0.1883\n",
      "Epoch [13/50], Step [392/735], Loss: 0.0562\n",
      "Epoch [13/50], Step [393/735], Loss: 0.3923\n",
      "Epoch [13/50], Step [394/735], Loss: 0.0435\n",
      "Epoch [13/50], Step [395/735], Loss: 0.1122\n",
      "Epoch [13/50], Step [396/735], Loss: 0.0651\n",
      "Epoch [13/50], Step [397/735], Loss: 0.2358\n",
      "Epoch [13/50], Step [398/735], Loss: 0.0936\n",
      "Epoch [13/50], Step [399/735], Loss: 0.0954\n",
      "Epoch [13/50], Step [400/735], Loss: 0.0642\n",
      "Epoch [13/50], Step [401/735], Loss: 0.0491\n",
      "Epoch [13/50], Step [402/735], Loss: 0.0560\n",
      "Epoch [13/50], Step [403/735], Loss: 0.0582\n",
      "Epoch [13/50], Step [404/735], Loss: 0.1249\n",
      "Epoch [13/50], Step [405/735], Loss: 0.0897\n",
      "Epoch [13/50], Step [406/735], Loss: 0.1852\n",
      "Epoch [13/50], Step [407/735], Loss: 0.0760\n",
      "Epoch [13/50], Step [408/735], Loss: 0.0186\n",
      "Epoch [13/50], Step [409/735], Loss: 0.3033\n",
      "Epoch [13/50], Step [410/735], Loss: 0.0375\n",
      "Epoch [13/50], Step [411/735], Loss: 0.0527\n",
      "Epoch [13/50], Step [412/735], Loss: 0.1128\n",
      "Epoch [13/50], Step [413/735], Loss: 0.0391\n",
      "Epoch [13/50], Step [414/735], Loss: 0.0665\n",
      "Epoch [13/50], Step [415/735], Loss: 0.3243\n",
      "Epoch [13/50], Step [416/735], Loss: 0.1592\n",
      "Epoch [13/50], Step [417/735], Loss: 0.1408\n",
      "Epoch [13/50], Step [418/735], Loss: 0.0384\n",
      "Epoch [13/50], Step [419/735], Loss: 0.0370\n",
      "Epoch [13/50], Step [420/735], Loss: 0.0437\n",
      "Epoch [13/50], Step [421/735], Loss: 0.0872\n",
      "Epoch [13/50], Step [422/735], Loss: 0.0576\n",
      "Epoch [13/50], Step [423/735], Loss: 0.0876\n",
      "Epoch [13/50], Step [424/735], Loss: 0.0324\n",
      "Epoch [13/50], Step [425/735], Loss: 0.0805\n",
      "Epoch [13/50], Step [426/735], Loss: 0.1353\n",
      "Epoch [13/50], Step [427/735], Loss: 0.1120\n",
      "Epoch [13/50], Step [428/735], Loss: 0.0688\n",
      "Epoch [13/50], Step [429/735], Loss: 0.2674\n",
      "Epoch [13/50], Step [430/735], Loss: 0.0827\n",
      "Epoch [13/50], Step [431/735], Loss: 0.2057\n",
      "Epoch [13/50], Step [432/735], Loss: 0.1626\n",
      "Epoch [13/50], Step [433/735], Loss: 0.1281\n",
      "Epoch [13/50], Step [434/735], Loss: 0.0824\n",
      "Epoch [13/50], Step [435/735], Loss: 0.0301\n",
      "Epoch [13/50], Step [436/735], Loss: 0.0663\n",
      "Epoch [13/50], Step [437/735], Loss: 0.0583\n",
      "Epoch [13/50], Step [438/735], Loss: 0.1117\n",
      "Epoch [13/50], Step [439/735], Loss: 0.0166\n",
      "Epoch [13/50], Step [440/735], Loss: 0.0466\n",
      "Epoch [13/50], Step [441/735], Loss: 0.1143\n",
      "Epoch [13/50], Step [442/735], Loss: 0.0389\n",
      "Epoch [13/50], Step [443/735], Loss: 0.1380\n",
      "Epoch [13/50], Step [444/735], Loss: 0.1192\n",
      "Epoch [13/50], Step [445/735], Loss: 0.1035\n",
      "Epoch [13/50], Step [446/735], Loss: 0.1168\n",
      "Epoch [13/50], Step [447/735], Loss: 0.2382\n",
      "Epoch [13/50], Step [448/735], Loss: 0.0437\n",
      "Epoch [13/50], Step [449/735], Loss: 0.0479\n",
      "Epoch [13/50], Step [450/735], Loss: 0.0846\n",
      "Epoch [13/50], Step [451/735], Loss: 0.0883\n",
      "Epoch [13/50], Step [452/735], Loss: 0.1691\n",
      "Epoch [13/50], Step [453/735], Loss: 0.0529\n",
      "Epoch [13/50], Step [454/735], Loss: 0.0865\n",
      "Epoch [13/50], Step [455/735], Loss: 0.1309\n",
      "Epoch [13/50], Step [456/735], Loss: 0.0419\n",
      "Epoch [13/50], Step [457/735], Loss: 0.0802\n",
      "Epoch [13/50], Step [458/735], Loss: 0.0268\n",
      "Epoch [13/50], Step [459/735], Loss: 0.0863\n",
      "Epoch [13/50], Step [460/735], Loss: 0.0528\n",
      "Epoch [13/50], Step [461/735], Loss: 0.1983\n",
      "Epoch [13/50], Step [462/735], Loss: 0.4849\n",
      "Epoch [13/50], Step [463/735], Loss: 0.0805\n",
      "Epoch [13/50], Step [464/735], Loss: 0.0696\n",
      "Epoch [13/50], Step [465/735], Loss: 0.1048\n",
      "Epoch [13/50], Step [466/735], Loss: 0.0473\n",
      "Epoch [13/50], Step [467/735], Loss: 0.0183\n",
      "Epoch [13/50], Step [468/735], Loss: 0.0270\n",
      "Epoch [13/50], Step [469/735], Loss: 0.0409\n",
      "Epoch [13/50], Step [470/735], Loss: 0.1355\n",
      "Epoch [13/50], Step [471/735], Loss: 0.1961\n",
      "Epoch [13/50], Step [472/735], Loss: 0.0350\n",
      "Epoch [13/50], Step [473/735], Loss: 0.0908\n",
      "Epoch [13/50], Step [474/735], Loss: 0.0650\n",
      "Epoch [13/50], Step [475/735], Loss: 0.0417\n",
      "Epoch [13/50], Step [476/735], Loss: 0.0438\n",
      "Epoch [13/50], Step [477/735], Loss: 0.0624\n",
      "Epoch [13/50], Step [478/735], Loss: 0.0406\n",
      "Epoch [13/50], Step [479/735], Loss: 0.0455\n",
      "Epoch [13/50], Step [480/735], Loss: 0.1082\n",
      "Epoch [13/50], Step [481/735], Loss: 0.0471\n",
      "Epoch [13/50], Step [482/735], Loss: 0.4155\n",
      "Epoch [13/50], Step [483/735], Loss: 0.0383\n",
      "Epoch [13/50], Step [484/735], Loss: 0.6135\n",
      "Epoch [13/50], Step [485/735], Loss: 0.0662\n",
      "Epoch [13/50], Step [486/735], Loss: 0.1746\n",
      "Epoch [13/50], Step [487/735], Loss: 0.1422\n",
      "Epoch [13/50], Step [488/735], Loss: 0.1134\n",
      "Epoch [13/50], Step [489/735], Loss: 0.0630\n",
      "Epoch [13/50], Step [490/735], Loss: 0.1947\n",
      "Epoch [13/50], Step [491/735], Loss: 0.0445\n",
      "Epoch [13/50], Step [492/735], Loss: 0.0597\n",
      "Epoch [13/50], Step [493/735], Loss: 0.1636\n",
      "Epoch [13/50], Step [494/735], Loss: 0.0716\n",
      "Epoch [13/50], Step [495/735], Loss: 0.1304\n",
      "Epoch [13/50], Step [496/735], Loss: 0.2907\n",
      "Epoch [13/50], Step [497/735], Loss: 0.0587\n",
      "Epoch [13/50], Step [498/735], Loss: 0.1816\n",
      "Epoch [13/50], Step [499/735], Loss: 0.0932\n",
      "Epoch [13/50], Step [500/735], Loss: 0.0566\n",
      "Epoch [13/50], Step [501/735], Loss: 0.0638\n",
      "Epoch [13/50], Step [502/735], Loss: 0.0317\n",
      "Epoch [13/50], Step [503/735], Loss: 0.0724\n",
      "Epoch [13/50], Step [504/735], Loss: 0.0899\n",
      "Epoch [13/50], Step [505/735], Loss: 0.0437\n",
      "Epoch [13/50], Step [506/735], Loss: 0.0782\n",
      "Epoch [13/50], Step [507/735], Loss: 0.1099\n",
      "Epoch [13/50], Step [508/735], Loss: 0.1034\n",
      "Epoch [13/50], Step [509/735], Loss: 0.0533\n",
      "Epoch [13/50], Step [510/735], Loss: 0.0485\n",
      "Epoch [13/50], Step [511/735], Loss: 0.0998\n",
      "Epoch [13/50], Step [512/735], Loss: 0.0895\n",
      "Epoch [13/50], Step [513/735], Loss: 0.2378\n",
      "Epoch [13/50], Step [514/735], Loss: 0.0935\n",
      "Epoch [13/50], Step [515/735], Loss: 0.0334\n",
      "Epoch [13/50], Step [516/735], Loss: 0.0406\n",
      "Epoch [13/50], Step [517/735], Loss: 0.1598\n",
      "Epoch [13/50], Step [518/735], Loss: 0.0403\n",
      "Epoch [13/50], Step [519/735], Loss: 0.2242\n",
      "Epoch [13/50], Step [520/735], Loss: 0.0178\n",
      "Epoch [13/50], Step [521/735], Loss: 0.0318\n",
      "Epoch [13/50], Step [522/735], Loss: 0.3637\n",
      "Epoch [13/50], Step [523/735], Loss: 0.0815\n",
      "Epoch [13/50], Step [524/735], Loss: 0.0586\n",
      "Epoch [13/50], Step [525/735], Loss: 0.1134\n",
      "Epoch [13/50], Step [526/735], Loss: 0.3683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Step [527/735], Loss: 0.0494\n",
      "Epoch [13/50], Step [528/735], Loss: 0.0468\n",
      "Epoch [13/50], Step [529/735], Loss: 0.0437\n",
      "Epoch [13/50], Step [530/735], Loss: 0.1650\n",
      "Epoch [13/50], Step [531/735], Loss: 0.0416\n",
      "Epoch [13/50], Step [532/735], Loss: 0.0337\n",
      "Epoch [13/50], Step [533/735], Loss: 0.0480\n",
      "Epoch [13/50], Step [534/735], Loss: 0.0579\n",
      "Epoch [13/50], Step [535/735], Loss: 0.0353\n",
      "Epoch [13/50], Step [536/735], Loss: 0.1263\n",
      "Epoch [13/50], Step [537/735], Loss: 0.0788\n",
      "Epoch [13/50], Step [538/735], Loss: 0.0406\n",
      "Epoch [13/50], Step [539/735], Loss: 0.0432\n",
      "Epoch [13/50], Step [540/735], Loss: 0.4838\n",
      "Epoch [13/50], Step [541/735], Loss: 0.2968\n",
      "Epoch [13/50], Step [542/735], Loss: 0.0527\n",
      "Epoch [13/50], Step [543/735], Loss: 0.1064\n",
      "Epoch [13/50], Step [544/735], Loss: 0.1451\n",
      "Epoch [13/50], Step [545/735], Loss: 0.2225\n",
      "Epoch [13/50], Step [546/735], Loss: 0.1631\n",
      "Epoch [13/50], Step [547/735], Loss: 0.0435\n",
      "Epoch [13/50], Step [548/735], Loss: 0.0685\n",
      "Epoch [13/50], Step [549/735], Loss: 0.0832\n",
      "Epoch [13/50], Step [550/735], Loss: 0.1103\n",
      "Epoch [13/50], Step [551/735], Loss: 0.0707\n",
      "Epoch [13/50], Step [552/735], Loss: 0.0650\n",
      "Epoch [13/50], Step [553/735], Loss: 0.0693\n",
      "Epoch [13/50], Step [554/735], Loss: 0.1532\n",
      "Epoch [13/50], Step [555/735], Loss: 0.0604\n",
      "Epoch [13/50], Step [556/735], Loss: 0.0535\n",
      "Epoch [13/50], Step [557/735], Loss: 0.0400\n",
      "Epoch [13/50], Step [558/735], Loss: 0.1009\n",
      "Epoch [13/50], Step [559/735], Loss: 0.2274\n",
      "Epoch [13/50], Step [560/735], Loss: 0.1353\n",
      "Epoch [13/50], Step [561/735], Loss: 0.0501\n",
      "Epoch [13/50], Step [562/735], Loss: 0.2040\n",
      "Epoch [13/50], Step [563/735], Loss: 0.0592\n",
      "Epoch [13/50], Step [564/735], Loss: 0.0366\n",
      "Epoch [13/50], Step [565/735], Loss: 0.1108\n",
      "Epoch [13/50], Step [566/735], Loss: 0.1488\n",
      "Epoch [13/50], Step [567/735], Loss: 0.0664\n",
      "Epoch [13/50], Step [568/735], Loss: 0.0742\n",
      "Epoch [13/50], Step [569/735], Loss: 0.0398\n",
      "Epoch [13/50], Step [570/735], Loss: 0.0543\n",
      "Epoch [13/50], Step [571/735], Loss: 0.1205\n",
      "Epoch [13/50], Step [572/735], Loss: 0.0622\n",
      "Epoch [13/50], Step [573/735], Loss: 0.0905\n",
      "Epoch [13/50], Step [574/735], Loss: 0.0945\n",
      "Epoch [13/50], Step [575/735], Loss: 0.1093\n",
      "Epoch [13/50], Step [576/735], Loss: 0.0616\n",
      "Epoch [13/50], Step [577/735], Loss: 0.0725\n",
      "Epoch [13/50], Step [578/735], Loss: 0.0198\n",
      "Epoch [13/50], Step [579/735], Loss: 0.0667\n",
      "Epoch [13/50], Step [580/735], Loss: 0.3989\n",
      "Epoch [13/50], Step [581/735], Loss: 0.0662\n",
      "Epoch [13/50], Step [582/735], Loss: 0.0737\n",
      "Epoch [13/50], Step [583/735], Loss: 0.0438\n",
      "Epoch [13/50], Step [584/735], Loss: 0.0681\n",
      "Epoch [13/50], Step [585/735], Loss: 0.0882\n",
      "Epoch [13/50], Step [586/735], Loss: 0.2060\n",
      "Epoch [13/50], Step [587/735], Loss: 0.0991\n",
      "Epoch [13/50], Step [588/735], Loss: 0.0341\n",
      "Epoch [13/50], Step [589/735], Loss: 0.0412\n",
      "Epoch [13/50], Step [590/735], Loss: 0.1542\n",
      "Epoch [13/50], Step [591/735], Loss: 0.1416\n",
      "Epoch [13/50], Step [592/735], Loss: 0.0403\n",
      "Epoch [13/50], Step [593/735], Loss: 0.1029\n",
      "Epoch [13/50], Step [594/735], Loss: 0.3453\n",
      "Epoch [13/50], Step [595/735], Loss: 0.0773\n",
      "Epoch [13/50], Step [596/735], Loss: 0.0279\n",
      "Epoch [13/50], Step [597/735], Loss: 0.0892\n",
      "Epoch [13/50], Step [598/735], Loss: 0.0708\n",
      "Epoch [13/50], Step [599/735], Loss: 0.1380\n",
      "Epoch [13/50], Step [600/735], Loss: 0.0672\n",
      "Epoch [13/50], Step [601/735], Loss: 0.0929\n",
      "Epoch [13/50], Step [602/735], Loss: 0.0527\n",
      "Epoch [13/50], Step [603/735], Loss: 0.0572\n",
      "Epoch [13/50], Step [604/735], Loss: 0.0455\n",
      "Epoch [13/50], Step [605/735], Loss: 0.0937\n",
      "Epoch [13/50], Step [606/735], Loss: 0.0489\n",
      "Epoch [13/50], Step [607/735], Loss: 0.0574\n",
      "Epoch [13/50], Step [608/735], Loss: 0.0377\n",
      "Epoch [13/50], Step [609/735], Loss: 0.0437\n",
      "Epoch [13/50], Step [610/735], Loss: 0.0177\n",
      "Epoch [13/50], Step [611/735], Loss: 0.0578\n",
      "Epoch [13/50], Step [612/735], Loss: 0.2942\n",
      "Epoch [13/50], Step [613/735], Loss: 0.1036\n",
      "Epoch [13/50], Step [614/735], Loss: 0.2354\n",
      "Epoch [13/50], Step [615/735], Loss: 0.1591\n",
      "Epoch [13/50], Step [616/735], Loss: 0.0327\n",
      "Epoch [13/50], Step [617/735], Loss: 0.1831\n",
      "Epoch [13/50], Step [618/735], Loss: 0.0311\n",
      "Epoch [13/50], Step [619/735], Loss: 0.1796\n",
      "Epoch [13/50], Step [620/735], Loss: 0.0820\n",
      "Epoch [13/50], Step [621/735], Loss: 0.4319\n",
      "Epoch [13/50], Step [622/735], Loss: 0.0706\n",
      "Epoch [13/50], Step [623/735], Loss: 0.1482\n",
      "Epoch [13/50], Step [624/735], Loss: 0.1413\n",
      "Epoch [13/50], Step [625/735], Loss: 0.0985\n",
      "Epoch [13/50], Step [626/735], Loss: 0.0503\n",
      "Epoch [13/50], Step [627/735], Loss: 0.0406\n",
      "Epoch [13/50], Step [628/735], Loss: 0.1365\n",
      "Epoch [13/50], Step [629/735], Loss: 0.5416\n",
      "Epoch [13/50], Step [630/735], Loss: 0.1103\n",
      "Epoch [13/50], Step [631/735], Loss: 0.1678\n",
      "Epoch [13/50], Step [632/735], Loss: 0.0473\n",
      "Epoch [13/50], Step [633/735], Loss: 0.0324\n",
      "Epoch [13/50], Step [634/735], Loss: 0.0294\n",
      "Epoch [13/50], Step [635/735], Loss: 0.0985\n",
      "Epoch [13/50], Step [636/735], Loss: 0.1807\n",
      "Epoch [13/50], Step [637/735], Loss: 0.0607\n",
      "Epoch [13/50], Step [638/735], Loss: 0.1082\n",
      "Epoch [13/50], Step [639/735], Loss: 0.0987\n",
      "Epoch [13/50], Step [640/735], Loss: 0.0426\n",
      "Epoch [13/50], Step [641/735], Loss: 0.0642\n",
      "Epoch [13/50], Step [642/735], Loss: 0.5152\n",
      "Epoch [13/50], Step [643/735], Loss: 0.0863\n",
      "Epoch [13/50], Step [644/735], Loss: 0.0726\n",
      "Epoch [13/50], Step [645/735], Loss: 0.1780\n",
      "Epoch [13/50], Step [646/735], Loss: 0.1060\n",
      "Epoch [13/50], Step [647/735], Loss: 0.0856\n",
      "Epoch [13/50], Step [648/735], Loss: 0.0575\n",
      "Epoch [13/50], Step [649/735], Loss: 0.0944\n",
      "Epoch [13/50], Step [650/735], Loss: 0.0530\n",
      "Epoch [13/50], Step [651/735], Loss: 0.0455\n",
      "Epoch [13/50], Step [652/735], Loss: 0.0399\n",
      "Epoch [13/50], Step [653/735], Loss: 0.2190\n",
      "Epoch [13/50], Step [654/735], Loss: 0.1012\n",
      "Epoch [13/50], Step [655/735], Loss: 0.1645\n",
      "Epoch [13/50], Step [656/735], Loss: 0.1965\n",
      "Epoch [13/50], Step [657/735], Loss: 0.0957\n",
      "Epoch [13/50], Step [658/735], Loss: 0.1088\n",
      "Epoch [13/50], Step [659/735], Loss: 0.0592\n",
      "Epoch [13/50], Step [660/735], Loss: 0.0710\n",
      "Epoch [13/50], Step [661/735], Loss: 0.0369\n",
      "Epoch [13/50], Step [662/735], Loss: 0.1732\n",
      "Epoch [13/50], Step [663/735], Loss: 0.0389\n",
      "Epoch [13/50], Step [664/735], Loss: 0.0197\n",
      "Epoch [13/50], Step [665/735], Loss: 0.0587\n",
      "Epoch [13/50], Step [666/735], Loss: 0.1410\n",
      "Epoch [13/50], Step [667/735], Loss: 0.0679\n",
      "Epoch [13/50], Step [668/735], Loss: 0.0449\n",
      "Epoch [13/50], Step [669/735], Loss: 0.0429\n",
      "Epoch [13/50], Step [670/735], Loss: 0.0293\n",
      "Epoch [13/50], Step [671/735], Loss: 0.0855\n",
      "Epoch [13/50], Step [672/735], Loss: 0.0720\n",
      "Epoch [13/50], Step [673/735], Loss: 0.0525\n",
      "Epoch [13/50], Step [674/735], Loss: 0.1975\n",
      "Epoch [13/50], Step [675/735], Loss: 0.0437\n",
      "Epoch [13/50], Step [676/735], Loss: 0.0572\n",
      "Epoch [13/50], Step [677/735], Loss: 0.1072\n",
      "Epoch [13/50], Step [678/735], Loss: 0.0416\n",
      "Epoch [13/50], Step [679/735], Loss: 0.0761\n",
      "Epoch [13/50], Step [680/735], Loss: 0.0424\n",
      "Epoch [13/50], Step [681/735], Loss: 0.2859\n",
      "Epoch [13/50], Step [682/735], Loss: 0.0679\n",
      "Epoch [13/50], Step [683/735], Loss: 0.1216\n",
      "Epoch [13/50], Step [684/735], Loss: 0.0353\n",
      "Epoch [13/50], Step [685/735], Loss: 0.1065\n",
      "Epoch [13/50], Step [686/735], Loss: 0.4150\n",
      "Epoch [13/50], Step [687/735], Loss: 0.0400\n",
      "Epoch [13/50], Step [688/735], Loss: 0.1345\n",
      "Epoch [13/50], Step [689/735], Loss: 0.0595\n",
      "Epoch [13/50], Step [690/735], Loss: 0.0228\n",
      "Epoch [13/50], Step [691/735], Loss: 0.1001\n",
      "Epoch [13/50], Step [692/735], Loss: 0.1063\n",
      "Epoch [13/50], Step [693/735], Loss: 0.0808\n",
      "Epoch [13/50], Step [694/735], Loss: 0.2937\n",
      "Epoch [13/50], Step [695/735], Loss: 0.0560\n",
      "Epoch [13/50], Step [696/735], Loss: 0.1155\n",
      "Epoch [13/50], Step [697/735], Loss: 0.1573\n",
      "Epoch [13/50], Step [698/735], Loss: 0.2162\n",
      "Epoch [13/50], Step [699/735], Loss: 0.5374\n",
      "Epoch [13/50], Step [700/735], Loss: 0.0409\n",
      "Epoch [13/50], Step [701/735], Loss: 0.0353\n",
      "Epoch [13/50], Step [702/735], Loss: 0.0832\n",
      "Epoch [13/50], Step [703/735], Loss: 0.1505\n",
      "Epoch [13/50], Step [704/735], Loss: 0.1170\n",
      "Epoch [13/50], Step [705/735], Loss: 0.0653\n",
      "Epoch [13/50], Step [706/735], Loss: 0.0727\n",
      "Epoch [13/50], Step [707/735], Loss: 0.0696\n",
      "Epoch [13/50], Step [708/735], Loss: 0.0785\n",
      "Epoch [13/50], Step [709/735], Loss: 0.0560\n",
      "Epoch [13/50], Step [710/735], Loss: 0.0265\n",
      "Epoch [13/50], Step [711/735], Loss: 0.0700\n",
      "Epoch [13/50], Step [712/735], Loss: 0.2270\n",
      "Epoch [13/50], Step [713/735], Loss: 0.0545\n",
      "Epoch [13/50], Step [714/735], Loss: 0.1276\n",
      "Epoch [13/50], Step [715/735], Loss: 0.1698\n",
      "Epoch [13/50], Step [716/735], Loss: 0.0863\n",
      "Epoch [13/50], Step [717/735], Loss: 0.0762\n",
      "Epoch [13/50], Step [718/735], Loss: 0.0684\n",
      "Epoch [13/50], Step [719/735], Loss: 0.0430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Step [720/735], Loss: 0.1853\n",
      "Epoch [13/50], Step [721/735], Loss: 0.2182\n",
      "Epoch [13/50], Step [722/735], Loss: 0.0495\n",
      "Epoch [13/50], Step [723/735], Loss: 0.3172\n",
      "Epoch [13/50], Step [724/735], Loss: 0.0907\n",
      "Epoch [13/50], Step [725/735], Loss: 0.0881\n",
      "Epoch [13/50], Step [726/735], Loss: 0.1378\n",
      "Epoch [13/50], Step [727/735], Loss: 0.0834\n",
      "Epoch [13/50], Step [728/735], Loss: 0.1921\n",
      "Epoch [13/50], Step [729/735], Loss: 0.1726\n",
      "Epoch [13/50], Step [730/735], Loss: 0.0358\n",
      "Epoch [13/50], Step [731/735], Loss: 0.0580\n",
      "Epoch [13/50], Step [732/735], Loss: 0.0714\n",
      "Epoch [13/50], Step [733/735], Loss: 0.0719\n",
      "Epoch [13/50], Step [734/735], Loss: 0.1463\n",
      "Epoch [13/50], Step [735/735], Loss: 0.1175\n",
      "Epoch [14/50], Step [1/735], Loss: 0.0748\n",
      "Epoch [14/50], Step [2/735], Loss: 0.0851\n",
      "Epoch [14/50], Step [3/735], Loss: 0.0952\n",
      "Epoch [14/50], Step [4/735], Loss: 0.0455\n",
      "Epoch [14/50], Step [5/735], Loss: 0.0462\n",
      "Epoch [14/50], Step [6/735], Loss: 0.1146\n",
      "Epoch [14/50], Step [7/735], Loss: 0.0419\n",
      "Epoch [14/50], Step [8/735], Loss: 0.0316\n",
      "Epoch [14/50], Step [9/735], Loss: 0.0624\n",
      "Epoch [14/50], Step [10/735], Loss: 0.2372\n",
      "Epoch [14/50], Step [11/735], Loss: 0.0619\n",
      "Epoch [14/50], Step [12/735], Loss: 0.1585\n",
      "Epoch [14/50], Step [13/735], Loss: 0.0567\n",
      "Epoch [14/50], Step [14/735], Loss: 0.0363\n",
      "Epoch [14/50], Step [15/735], Loss: 0.0780\n",
      "Epoch [14/50], Step [16/735], Loss: 0.3710\n",
      "Epoch [14/50], Step [17/735], Loss: 0.0842\n",
      "Epoch [14/50], Step [18/735], Loss: 0.0545\n",
      "Epoch [14/50], Step [19/735], Loss: 0.0707\n",
      "Epoch [14/50], Step [20/735], Loss: 0.0369\n",
      "Epoch [14/50], Step [21/735], Loss: 0.0746\n",
      "Epoch [14/50], Step [22/735], Loss: 0.0570\n",
      "Epoch [14/50], Step [23/735], Loss: 0.1231\n",
      "Epoch [14/50], Step [24/735], Loss: 0.2223\n",
      "Epoch [14/50], Step [25/735], Loss: 0.2661\n",
      "Epoch [14/50], Step [26/735], Loss: 0.0402\n",
      "Epoch [14/50], Step [27/735], Loss: 0.1075\n",
      "Epoch [14/50], Step [28/735], Loss: 0.1032\n",
      "Epoch [14/50], Step [29/735], Loss: 0.0440\n",
      "Epoch [14/50], Step [30/735], Loss: 0.0851\n",
      "Epoch [14/50], Step [31/735], Loss: 0.0733\n",
      "Epoch [14/50], Step [32/735], Loss: 0.0383\n",
      "Epoch [14/50], Step [33/735], Loss: 0.0780\n",
      "Epoch [14/50], Step [34/735], Loss: 0.0939\n",
      "Epoch [14/50], Step [35/735], Loss: 0.4869\n",
      "Epoch [14/50], Step [36/735], Loss: 0.0802\n",
      "Epoch [14/50], Step [37/735], Loss: 0.0534\n",
      "Epoch [14/50], Step [38/735], Loss: 0.0510\n",
      "Epoch [14/50], Step [39/735], Loss: 0.1626\n",
      "Epoch [14/50], Step [40/735], Loss: 0.1241\n",
      "Epoch [14/50], Step [41/735], Loss: 0.0643\n",
      "Epoch [14/50], Step [42/735], Loss: 0.1692\n",
      "Epoch [14/50], Step [43/735], Loss: 0.1888\n",
      "Epoch [14/50], Step [44/735], Loss: 0.0957\n",
      "Epoch [14/50], Step [45/735], Loss: 0.0211\n",
      "Epoch [14/50], Step [46/735], Loss: 0.2084\n",
      "Epoch [14/50], Step [47/735], Loss: 0.0782\n",
      "Epoch [14/50], Step [48/735], Loss: 0.0602\n",
      "Epoch [14/50], Step [49/735], Loss: 0.0921\n",
      "Epoch [14/50], Step [50/735], Loss: 0.0556\n",
      "Epoch [14/50], Step [51/735], Loss: 0.1706\n",
      "Epoch [14/50], Step [52/735], Loss: 0.0711\n",
      "Epoch [14/50], Step [53/735], Loss: 0.3059\n",
      "Epoch [14/50], Step [54/735], Loss: 0.0829\n",
      "Epoch [14/50], Step [55/735], Loss: 0.1499\n",
      "Epoch [14/50], Step [56/735], Loss: 0.0325\n",
      "Epoch [14/50], Step [57/735], Loss: 0.1459\n",
      "Epoch [14/50], Step [58/735], Loss: 0.0437\n",
      "Epoch [14/50], Step [59/735], Loss: 0.0642\n",
      "Epoch [14/50], Step [60/735], Loss: 0.0478\n",
      "Epoch [14/50], Step [61/735], Loss: 0.0406\n",
      "Epoch [14/50], Step [62/735], Loss: 0.0550\n",
      "Epoch [14/50], Step [63/735], Loss: 0.0895\n",
      "Epoch [14/50], Step [64/735], Loss: 0.0343\n",
      "Epoch [14/50], Step [65/735], Loss: 0.1245\n",
      "Epoch [14/50], Step [66/735], Loss: 0.0752\n",
      "Epoch [14/50], Step [67/735], Loss: 0.0203\n",
      "Epoch [14/50], Step [68/735], Loss: 0.0858\n",
      "Epoch [14/50], Step [69/735], Loss: 0.0422\n",
      "Epoch [14/50], Step [70/735], Loss: 0.0507\n",
      "Epoch [14/50], Step [71/735], Loss: 0.0510\n",
      "Epoch [14/50], Step [72/735], Loss: 0.1022\n",
      "Epoch [14/50], Step [73/735], Loss: 0.0466\n",
      "Epoch [14/50], Step [74/735], Loss: 0.0552\n",
      "Epoch [14/50], Step [75/735], Loss: 0.0673\n",
      "Epoch [14/50], Step [76/735], Loss: 0.0988\n",
      "Epoch [14/50], Step [77/735], Loss: 0.0431\n",
      "Epoch [14/50], Step [78/735], Loss: 0.1483\n",
      "Epoch [14/50], Step [79/735], Loss: 0.0508\n",
      "Epoch [14/50], Step [80/735], Loss: 0.1436\n",
      "Epoch [14/50], Step [81/735], Loss: 0.0372\n",
      "Epoch [14/50], Step [82/735], Loss: 0.0607\n",
      "Epoch [14/50], Step [83/735], Loss: 0.1314\n",
      "Epoch [14/50], Step [84/735], Loss: 0.0585\n",
      "Epoch [14/50], Step [85/735], Loss: 0.1326\n",
      "Epoch [14/50], Step [86/735], Loss: 0.0359\n",
      "Epoch [14/50], Step [87/735], Loss: 0.0421\n",
      "Epoch [14/50], Step [88/735], Loss: 0.1723\n",
      "Epoch [14/50], Step [89/735], Loss: 0.0999\n",
      "Epoch [14/50], Step [90/735], Loss: 0.0784\n",
      "Epoch [14/50], Step [91/735], Loss: 0.0426\n",
      "Epoch [14/50], Step [92/735], Loss: 0.0649\n",
      "Epoch [14/50], Step [93/735], Loss: 0.0265\n",
      "Epoch [14/50], Step [94/735], Loss: 0.0541\n",
      "Epoch [14/50], Step [95/735], Loss: 0.4388\n",
      "Epoch [14/50], Step [96/735], Loss: 0.0747\n",
      "Epoch [14/50], Step [97/735], Loss: 0.0739\n",
      "Epoch [14/50], Step [98/735], Loss: 0.2919\n",
      "Epoch [14/50], Step [99/735], Loss: 0.0747\n",
      "Epoch [14/50], Step [100/735], Loss: 0.0519\n",
      "Epoch [14/50], Step [101/735], Loss: 0.0344\n",
      "Epoch [14/50], Step [102/735], Loss: 0.0413\n",
      "Epoch [14/50], Step [103/735], Loss: 0.0735\n",
      "Epoch [14/50], Step [104/735], Loss: 0.1902\n",
      "Epoch [14/50], Step [105/735], Loss: 0.0512\n",
      "Epoch [14/50], Step [106/735], Loss: 0.0381\n",
      "Epoch [14/50], Step [107/735], Loss: 0.0427\n",
      "Epoch [14/50], Step [108/735], Loss: 0.0794\n",
      "Epoch [14/50], Step [109/735], Loss: 0.0945\n",
      "Epoch [14/50], Step [110/735], Loss: 0.0381\n",
      "Epoch [14/50], Step [111/735], Loss: 0.0700\n",
      "Epoch [14/50], Step [112/735], Loss: 0.1103\n",
      "Epoch [14/50], Step [113/735], Loss: 0.1656\n",
      "Epoch [14/50], Step [114/735], Loss: 0.1625\n",
      "Epoch [14/50], Step [115/735], Loss: 0.0891\n",
      "Epoch [14/50], Step [116/735], Loss: 0.2325\n",
      "Epoch [14/50], Step [117/735], Loss: 0.7160\n",
      "Epoch [14/50], Step [118/735], Loss: 0.1731\n",
      "Epoch [14/50], Step [119/735], Loss: 0.0478\n",
      "Epoch [14/50], Step [120/735], Loss: 0.5723\n",
      "Epoch [14/50], Step [121/735], Loss: 0.2100\n",
      "Epoch [14/50], Step [122/735], Loss: 0.1008\n",
      "Epoch [14/50], Step [123/735], Loss: 0.0826\n",
      "Epoch [14/50], Step [124/735], Loss: 0.0645\n",
      "Epoch [14/50], Step [125/735], Loss: 0.0255\n",
      "Epoch [14/50], Step [126/735], Loss: 0.0356\n",
      "Epoch [14/50], Step [127/735], Loss: 0.0809\n",
      "Epoch [14/50], Step [128/735], Loss: 0.0629\n",
      "Epoch [14/50], Step [129/735], Loss: 0.0423\n",
      "Epoch [14/50], Step [130/735], Loss: 0.0671\n",
      "Epoch [14/50], Step [131/735], Loss: 0.1074\n",
      "Epoch [14/50], Step [132/735], Loss: 0.1700\n",
      "Epoch [14/50], Step [133/735], Loss: 0.0598\n",
      "Epoch [14/50], Step [134/735], Loss: 0.0346\n",
      "Epoch [14/50], Step [135/735], Loss: 0.0378\n",
      "Epoch [14/50], Step [136/735], Loss: 0.1977\n",
      "Epoch [14/50], Step [137/735], Loss: 0.0823\n",
      "Epoch [14/50], Step [138/735], Loss: 0.0507\n",
      "Epoch [14/50], Step [139/735], Loss: 0.0968\n",
      "Epoch [14/50], Step [140/735], Loss: 0.0904\n",
      "Epoch [14/50], Step [141/735], Loss: 0.1206\n",
      "Epoch [14/50], Step [142/735], Loss: 0.1083\n",
      "Epoch [14/50], Step [143/735], Loss: 0.1625\n",
      "Epoch [14/50], Step [144/735], Loss: 0.2549\n",
      "Epoch [14/50], Step [145/735], Loss: 0.0630\n",
      "Epoch [14/50], Step [146/735], Loss: 0.0656\n",
      "Epoch [14/50], Step [147/735], Loss: 0.2284\n",
      "Epoch [14/50], Step [148/735], Loss: 0.1031\n",
      "Epoch [14/50], Step [149/735], Loss: 0.1803\n",
      "Epoch [14/50], Step [150/735], Loss: 0.0293\n",
      "Epoch [14/50], Step [151/735], Loss: 0.0916\n",
      "Epoch [14/50], Step [152/735], Loss: 0.0873\n",
      "Epoch [14/50], Step [153/735], Loss: 0.0885\n",
      "Epoch [14/50], Step [154/735], Loss: 0.3665\n",
      "Epoch [14/50], Step [155/735], Loss: 0.0918\n",
      "Epoch [14/50], Step [156/735], Loss: 0.0446\n",
      "Epoch [14/50], Step [157/735], Loss: 0.0530\n",
      "Epoch [14/50], Step [158/735], Loss: 0.0301\n",
      "Epoch [14/50], Step [159/735], Loss: 0.0841\n",
      "Epoch [14/50], Step [160/735], Loss: 0.0503\n",
      "Epoch [14/50], Step [161/735], Loss: 0.0719\n",
      "Epoch [14/50], Step [162/735], Loss: 0.0709\n",
      "Epoch [14/50], Step [163/735], Loss: 0.0911\n",
      "Epoch [14/50], Step [164/735], Loss: 0.3154\n",
      "Epoch [14/50], Step [165/735], Loss: 0.0526\n",
      "Epoch [14/50], Step [166/735], Loss: 0.0911\n",
      "Epoch [14/50], Step [167/735], Loss: 0.1684\n",
      "Epoch [14/50], Step [168/735], Loss: 0.0514\n",
      "Epoch [14/50], Step [169/735], Loss: 0.0659\n",
      "Epoch [14/50], Step [170/735], Loss: 0.1923\n",
      "Epoch [14/50], Step [171/735], Loss: 0.1768\n",
      "Epoch [14/50], Step [172/735], Loss: 0.1155\n",
      "Epoch [14/50], Step [173/735], Loss: 0.0612\n",
      "Epoch [14/50], Step [174/735], Loss: 0.1042\n",
      "Epoch [14/50], Step [175/735], Loss: 0.0522\n",
      "Epoch [14/50], Step [176/735], Loss: 0.0500\n",
      "Epoch [14/50], Step [177/735], Loss: 0.0303\n",
      "Epoch [14/50], Step [178/735], Loss: 0.4819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Step [179/735], Loss: 0.0764\n",
      "Epoch [14/50], Step [180/735], Loss: 0.0929\n",
      "Epoch [14/50], Step [181/735], Loss: 0.0624\n",
      "Epoch [14/50], Step [182/735], Loss: 0.3293\n",
      "Epoch [14/50], Step [183/735], Loss: 0.0322\n",
      "Epoch [14/50], Step [184/735], Loss: 0.0884\n",
      "Epoch [14/50], Step [185/735], Loss: 0.1469\n",
      "Epoch [14/50], Step [186/735], Loss: 0.0987\n",
      "Epoch [14/50], Step [187/735], Loss: 0.0881\n",
      "Epoch [14/50], Step [188/735], Loss: 0.0773\n",
      "Epoch [14/50], Step [189/735], Loss: 0.1664\n",
      "Epoch [14/50], Step [190/735], Loss: 0.0354\n",
      "Epoch [14/50], Step [191/735], Loss: 0.0747\n",
      "Epoch [14/50], Step [192/735], Loss: 0.1286\n",
      "Epoch [14/50], Step [193/735], Loss: 0.0700\n",
      "Epoch [14/50], Step [194/735], Loss: 0.2478\n",
      "Epoch [14/50], Step [195/735], Loss: 0.0681\n",
      "Epoch [14/50], Step [196/735], Loss: 0.1270\n",
      "Epoch [14/50], Step [197/735], Loss: 0.1269\n",
      "Epoch [14/50], Step [198/735], Loss: 0.0708\n",
      "Epoch [14/50], Step [199/735], Loss: 0.0334\n",
      "Epoch [14/50], Step [200/735], Loss: 0.0989\n",
      "Epoch [14/50], Step [201/735], Loss: 0.3320\n",
      "Epoch [14/50], Step [202/735], Loss: 0.0341\n",
      "Epoch [14/50], Step [203/735], Loss: 0.3383\n",
      "Epoch [14/50], Step [204/735], Loss: 0.0811\n",
      "Epoch [14/50], Step [205/735], Loss: 0.1023\n",
      "Epoch [14/50], Step [206/735], Loss: 0.1305\n",
      "Epoch [14/50], Step [207/735], Loss: 0.5118\n",
      "Epoch [14/50], Step [208/735], Loss: 0.0349\n",
      "Epoch [14/50], Step [209/735], Loss: 0.0693\n",
      "Epoch [14/50], Step [210/735], Loss: 0.3344\n",
      "Epoch [14/50], Step [211/735], Loss: 0.0397\n",
      "Epoch [14/50], Step [212/735], Loss: 0.2695\n",
      "Epoch [14/50], Step [213/735], Loss: 0.0411\n",
      "Epoch [14/50], Step [214/735], Loss: 0.0855\n",
      "Epoch [14/50], Step [215/735], Loss: 0.1255\n",
      "Epoch [14/50], Step [216/735], Loss: 0.1504\n",
      "Epoch [14/50], Step [217/735], Loss: 0.0357\n",
      "Epoch [14/50], Step [218/735], Loss: 0.1428\n",
      "Epoch [14/50], Step [219/735], Loss: 0.0321\n",
      "Epoch [14/50], Step [220/735], Loss: 0.1400\n",
      "Epoch [14/50], Step [221/735], Loss: 0.0236\n",
      "Epoch [14/50], Step [222/735], Loss: 0.1795\n",
      "Epoch [14/50], Step [223/735], Loss: 0.0410\n",
      "Epoch [14/50], Step [224/735], Loss: 0.0522\n",
      "Epoch [14/50], Step [225/735], Loss: 0.0628\n",
      "Epoch [14/50], Step [226/735], Loss: 0.0977\n",
      "Epoch [14/50], Step [227/735], Loss: 0.0294\n",
      "Epoch [14/50], Step [228/735], Loss: 0.0770\n",
      "Epoch [14/50], Step [229/735], Loss: 0.1446\n",
      "Epoch [14/50], Step [230/735], Loss: 0.1179\n",
      "Epoch [14/50], Step [231/735], Loss: 0.0274\n",
      "Epoch [14/50], Step [232/735], Loss: 0.0715\n",
      "Epoch [14/50], Step [233/735], Loss: 0.0885\n",
      "Epoch [14/50], Step [234/735], Loss: 0.0373\n",
      "Epoch [14/50], Step [235/735], Loss: 0.1677\n",
      "Epoch [14/50], Step [236/735], Loss: 0.1608\n",
      "Epoch [14/50], Step [237/735], Loss: 0.0430\n",
      "Epoch [14/50], Step [238/735], Loss: 0.1004\n",
      "Epoch [14/50], Step [239/735], Loss: 0.1958\n",
      "Epoch [14/50], Step [240/735], Loss: 0.0798\n",
      "Epoch [14/50], Step [241/735], Loss: 0.1216\n",
      "Epoch [14/50], Step [242/735], Loss: 0.1285\n",
      "Epoch [14/50], Step [243/735], Loss: 0.0341\n",
      "Epoch [14/50], Step [244/735], Loss: 0.0374\n",
      "Epoch [14/50], Step [245/735], Loss: 0.0571\n",
      "Epoch [14/50], Step [246/735], Loss: 0.1941\n",
      "Epoch [14/50], Step [247/735], Loss: 0.0724\n",
      "Epoch [14/50], Step [248/735], Loss: 0.2514\n",
      "Epoch [14/50], Step [249/735], Loss: 0.1106\n",
      "Epoch [14/50], Step [250/735], Loss: 0.0495\n",
      "Epoch [14/50], Step [251/735], Loss: 0.1675\n",
      "Epoch [14/50], Step [252/735], Loss: 0.5551\n",
      "Epoch [14/50], Step [253/735], Loss: 0.0353\n",
      "Epoch [14/50], Step [254/735], Loss: 0.0712\n",
      "Epoch [14/50], Step [255/735], Loss: 0.0891\n",
      "Epoch [14/50], Step [256/735], Loss: 0.0363\n",
      "Epoch [14/50], Step [257/735], Loss: 0.0988\n",
      "Epoch [14/50], Step [258/735], Loss: 0.0856\n",
      "Epoch [14/50], Step [259/735], Loss: 0.1250\n",
      "Epoch [14/50], Step [260/735], Loss: 0.0902\n",
      "Epoch [14/50], Step [261/735], Loss: 0.0571\n",
      "Epoch [14/50], Step [262/735], Loss: 0.1175\n",
      "Epoch [14/50], Step [263/735], Loss: 0.0450\n",
      "Epoch [14/50], Step [264/735], Loss: 0.0868\n",
      "Epoch [14/50], Step [265/735], Loss: 0.2270\n",
      "Epoch [14/50], Step [266/735], Loss: 0.1166\n",
      "Epoch [14/50], Step [267/735], Loss: 0.1426\n",
      "Epoch [14/50], Step [268/735], Loss: 0.0810\n",
      "Epoch [14/50], Step [269/735], Loss: 0.2329\n",
      "Epoch [14/50], Step [270/735], Loss: 0.0364\n",
      "Epoch [14/50], Step [271/735], Loss: 0.0269\n",
      "Epoch [14/50], Step [272/735], Loss: 0.0515\n",
      "Epoch [14/50], Step [273/735], Loss: 0.1957\n",
      "Epoch [14/50], Step [274/735], Loss: 0.0208\n",
      "Epoch [14/50], Step [275/735], Loss: 0.0919\n",
      "Epoch [14/50], Step [276/735], Loss: 0.0721\n",
      "Epoch [14/50], Step [277/735], Loss: 0.1387\n",
      "Epoch [14/50], Step [278/735], Loss: 0.0731\n",
      "Epoch [14/50], Step [279/735], Loss: 0.0291\n",
      "Epoch [14/50], Step [280/735], Loss: 0.0380\n",
      "Epoch [14/50], Step [281/735], Loss: 0.0758\n",
      "Epoch [14/50], Step [282/735], Loss: 0.0581\n",
      "Epoch [14/50], Step [283/735], Loss: 0.1704\n",
      "Epoch [14/50], Step [284/735], Loss: 0.0338\n",
      "Epoch [14/50], Step [285/735], Loss: 0.0947\n",
      "Epoch [14/50], Step [286/735], Loss: 0.0742\n",
      "Epoch [14/50], Step [287/735], Loss: 0.0900\n",
      "Epoch [14/50], Step [288/735], Loss: 0.0685\n",
      "Epoch [14/50], Step [289/735], Loss: 0.0743\n",
      "Epoch [14/50], Step [290/735], Loss: 0.0614\n",
      "Epoch [14/50], Step [291/735], Loss: 0.0568\n",
      "Epoch [14/50], Step [292/735], Loss: 0.1286\n",
      "Epoch [14/50], Step [293/735], Loss: 0.0238\n",
      "Epoch [14/50], Step [294/735], Loss: 0.3023\n",
      "Epoch [14/50], Step [295/735], Loss: 0.1042\n",
      "Epoch [14/50], Step [296/735], Loss: 0.1104\n",
      "Epoch [14/50], Step [297/735], Loss: 0.0523\n",
      "Epoch [14/50], Step [298/735], Loss: 0.0393\n",
      "Epoch [14/50], Step [299/735], Loss: 0.0626\n",
      "Epoch [14/50], Step [300/735], Loss: 0.0381\n",
      "Epoch [14/50], Step [301/735], Loss: 0.1717\n",
      "Epoch [14/50], Step [302/735], Loss: 0.0395\n",
      "Epoch [14/50], Step [303/735], Loss: 0.0811\n",
      "Epoch [14/50], Step [304/735], Loss: 0.0280\n",
      "Epoch [14/50], Step [305/735], Loss: 0.0217\n",
      "Epoch [14/50], Step [306/735], Loss: 0.1312\n",
      "Epoch [14/50], Step [307/735], Loss: 0.0446\n",
      "Epoch [14/50], Step [308/735], Loss: 0.0717\n",
      "Epoch [14/50], Step [309/735], Loss: 0.1545\n",
      "Epoch [14/50], Step [310/735], Loss: 0.1625\n",
      "Epoch [14/50], Step [311/735], Loss: 0.1084\n",
      "Epoch [14/50], Step [312/735], Loss: 0.0630\n",
      "Epoch [14/50], Step [313/735], Loss: 0.1773\n",
      "Epoch [14/50], Step [314/735], Loss: 0.0382\n",
      "Epoch [14/50], Step [315/735], Loss: 0.0313\n",
      "Epoch [14/50], Step [316/735], Loss: 0.0662\n",
      "Epoch [14/50], Step [317/735], Loss: 0.0468\n",
      "Epoch [14/50], Step [318/735], Loss: 0.0450\n",
      "Epoch [14/50], Step [319/735], Loss: 0.0786\n",
      "Epoch [14/50], Step [320/735], Loss: 0.0333\n",
      "Epoch [14/50], Step [321/735], Loss: 0.0629\n",
      "Epoch [14/50], Step [322/735], Loss: 0.1223\n",
      "Epoch [14/50], Step [323/735], Loss: 0.0284\n",
      "Epoch [14/50], Step [324/735], Loss: 0.0376\n",
      "Epoch [14/50], Step [325/735], Loss: 0.0664\n",
      "Epoch [14/50], Step [326/735], Loss: 0.0303\n",
      "Epoch [14/50], Step [327/735], Loss: 0.0628\n",
      "Epoch [14/50], Step [328/735], Loss: 0.0368\n",
      "Epoch [14/50], Step [329/735], Loss: 0.0225\n",
      "Epoch [14/50], Step [330/735], Loss: 0.1200\n",
      "Epoch [14/50], Step [331/735], Loss: 0.0761\n",
      "Epoch [14/50], Step [332/735], Loss: 0.0599\n",
      "Epoch [14/50], Step [333/735], Loss: 0.0765\n",
      "Epoch [14/50], Step [334/735], Loss: 0.0443\n",
      "Epoch [14/50], Step [335/735], Loss: 0.1115\n",
      "Epoch [14/50], Step [336/735], Loss: 0.0929\n",
      "Epoch [14/50], Step [337/735], Loss: 0.1048\n",
      "Epoch [14/50], Step [338/735], Loss: 0.1548\n",
      "Epoch [14/50], Step [339/735], Loss: 0.1051\n",
      "Epoch [14/50], Step [340/735], Loss: 0.0493\n",
      "Epoch [14/50], Step [341/735], Loss: 0.1286\n",
      "Epoch [14/50], Step [342/735], Loss: 0.0561\n",
      "Epoch [14/50], Step [343/735], Loss: 0.2135\n",
      "Epoch [14/50], Step [344/735], Loss: 0.0818\n",
      "Epoch [14/50], Step [345/735], Loss: 0.1810\n",
      "Epoch [14/50], Step [346/735], Loss: 0.0565\n",
      "Epoch [14/50], Step [347/735], Loss: 0.2128\n",
      "Epoch [14/50], Step [348/735], Loss: 0.0407\n",
      "Epoch [14/50], Step [349/735], Loss: 0.1202\n",
      "Epoch [14/50], Step [350/735], Loss: 0.0760\n",
      "Epoch [14/50], Step [351/735], Loss: 0.0657\n",
      "Epoch [14/50], Step [352/735], Loss: 0.0719\n",
      "Epoch [14/50], Step [353/735], Loss: 0.0751\n",
      "Epoch [14/50], Step [354/735], Loss: 0.1378\n",
      "Epoch [14/50], Step [355/735], Loss: 0.0880\n",
      "Epoch [14/50], Step [356/735], Loss: 0.0378\n",
      "Epoch [14/50], Step [357/735], Loss: 0.1057\n",
      "Epoch [14/50], Step [358/735], Loss: 0.0363\n",
      "Epoch [14/50], Step [359/735], Loss: 0.0426\n",
      "Epoch [14/50], Step [360/735], Loss: 0.0878\n",
      "Epoch [14/50], Step [361/735], Loss: 0.0905\n",
      "Epoch [14/50], Step [362/735], Loss: 0.2064\n",
      "Epoch [14/50], Step [363/735], Loss: 0.0312\n",
      "Epoch [14/50], Step [364/735], Loss: 0.0497\n",
      "Epoch [14/50], Step [365/735], Loss: 0.0763\n",
      "Epoch [14/50], Step [366/735], Loss: 0.0664\n",
      "Epoch [14/50], Step [367/735], Loss: 0.0242\n",
      "Epoch [14/50], Step [368/735], Loss: 0.0920\n",
      "Epoch [14/50], Step [369/735], Loss: 0.1402\n",
      "Epoch [14/50], Step [370/735], Loss: 0.0866\n",
      "Epoch [14/50], Step [371/735], Loss: 0.0953\n",
      "Epoch [14/50], Step [372/735], Loss: 0.0321\n",
      "Epoch [14/50], Step [373/735], Loss: 0.1426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Step [374/735], Loss: 0.1745\n",
      "Epoch [14/50], Step [375/735], Loss: 0.1685\n",
      "Epoch [14/50], Step [376/735], Loss: 0.0931\n",
      "Epoch [14/50], Step [377/735], Loss: 0.1044\n",
      "Epoch [14/50], Step [378/735], Loss: 0.0551\n",
      "Epoch [14/50], Step [379/735], Loss: 0.2167\n",
      "Epoch [14/50], Step [380/735], Loss: 0.0715\n",
      "Epoch [14/50], Step [381/735], Loss: 0.0668\n",
      "Epoch [14/50], Step [382/735], Loss: 0.1159\n",
      "Epoch [14/50], Step [383/735], Loss: 0.0937\n",
      "Epoch [14/50], Step [384/735], Loss: 0.0630\n",
      "Epoch [14/50], Step [385/735], Loss: 0.0838\n",
      "Epoch [14/50], Step [386/735], Loss: 0.0366\n",
      "Epoch [14/50], Step [387/735], Loss: 0.0171\n",
      "Epoch [14/50], Step [388/735], Loss: 0.0568\n",
      "Epoch [14/50], Step [389/735], Loss: 0.0321\n",
      "Epoch [14/50], Step [390/735], Loss: 0.3351\n",
      "Epoch [14/50], Step [391/735], Loss: 0.0830\n",
      "Epoch [14/50], Step [392/735], Loss: 0.0467\n",
      "Epoch [14/50], Step [393/735], Loss: 0.0404\n",
      "Epoch [14/50], Step [394/735], Loss: 0.0529\n",
      "Epoch [14/50], Step [395/735], Loss: 0.1604\n",
      "Epoch [14/50], Step [396/735], Loss: 0.0250\n",
      "Epoch [14/50], Step [397/735], Loss: 0.0623\n",
      "Epoch [14/50], Step [398/735], Loss: 0.0610\n",
      "Epoch [14/50], Step [399/735], Loss: 0.0672\n",
      "Epoch [14/50], Step [400/735], Loss: 0.0986\n",
      "Epoch [14/50], Step [401/735], Loss: 0.1144\n",
      "Epoch [14/50], Step [402/735], Loss: 0.2215\n",
      "Epoch [14/50], Step [403/735], Loss: 0.1062\n",
      "Epoch [14/50], Step [404/735], Loss: 0.0558\n",
      "Epoch [14/50], Step [405/735], Loss: 0.0801\n",
      "Epoch [14/50], Step [406/735], Loss: 0.0397\n",
      "Epoch [14/50], Step [407/735], Loss: 0.0522\n",
      "Epoch [14/50], Step [408/735], Loss: 0.0869\n",
      "Epoch [14/50], Step [409/735], Loss: 0.0191\n",
      "Epoch [14/50], Step [410/735], Loss: 0.0343\n",
      "Epoch [14/50], Step [411/735], Loss: 0.0723\n",
      "Epoch [14/50], Step [412/735], Loss: 0.0489\n",
      "Epoch [14/50], Step [413/735], Loss: 0.0457\n",
      "Epoch [14/50], Step [414/735], Loss: 0.0686\n",
      "Epoch [14/50], Step [415/735], Loss: 0.0694\n",
      "Epoch [14/50], Step [416/735], Loss: 0.2948\n",
      "Epoch [14/50], Step [417/735], Loss: 0.0381\n",
      "Epoch [14/50], Step [418/735], Loss: 0.2231\n",
      "Epoch [14/50], Step [419/735], Loss: 0.0460\n",
      "Epoch [14/50], Step [420/735], Loss: 0.0362\n",
      "Epoch [14/50], Step [421/735], Loss: 0.1668\n",
      "Epoch [14/50], Step [422/735], Loss: 0.2161\n",
      "Epoch [14/50], Step [423/735], Loss: 0.0884\n",
      "Epoch [14/50], Step [424/735], Loss: 0.0383\n",
      "Epoch [14/50], Step [425/735], Loss: 0.0601\n",
      "Epoch [14/50], Step [426/735], Loss: 0.0599\n",
      "Epoch [14/50], Step [427/735], Loss: 0.0694\n",
      "Epoch [14/50], Step [428/735], Loss: 0.0551\n",
      "Epoch [14/50], Step [429/735], Loss: 0.0860\n",
      "Epoch [14/50], Step [430/735], Loss: 0.2090\n",
      "Epoch [14/50], Step [431/735], Loss: 0.0221\n",
      "Epoch [14/50], Step [432/735], Loss: 0.0560\n",
      "Epoch [14/50], Step [433/735], Loss: 0.0823\n",
      "Epoch [14/50], Step [434/735], Loss: 0.0894\n",
      "Epoch [14/50], Step [435/735], Loss: 0.0472\n",
      "Epoch [14/50], Step [436/735], Loss: 0.0466\n",
      "Epoch [14/50], Step [437/735], Loss: 0.0479\n",
      "Epoch [14/50], Step [438/735], Loss: 0.0608\n",
      "Epoch [14/50], Step [439/735], Loss: 0.0263\n",
      "Epoch [14/50], Step [440/735], Loss: 0.0430\n",
      "Epoch [14/50], Step [441/735], Loss: 0.1646\n",
      "Epoch [14/50], Step [442/735], Loss: 0.0260\n",
      "Epoch [14/50], Step [443/735], Loss: 0.1630\n",
      "Epoch [14/50], Step [444/735], Loss: 0.3259\n",
      "Epoch [14/50], Step [445/735], Loss: 0.0501\n",
      "Epoch [14/50], Step [446/735], Loss: 0.1297\n",
      "Epoch [14/50], Step [447/735], Loss: 0.2269\n",
      "Epoch [14/50], Step [448/735], Loss: 0.1020\n",
      "Epoch [14/50], Step [449/735], Loss: 0.0190\n",
      "Epoch [14/50], Step [450/735], Loss: 0.0713\n",
      "Epoch [14/50], Step [451/735], Loss: 0.0674\n",
      "Epoch [14/50], Step [452/735], Loss: 0.0628\n",
      "Epoch [14/50], Step [453/735], Loss: 0.1443\n",
      "Epoch [14/50], Step [454/735], Loss: 0.0405\n",
      "Epoch [14/50], Step [455/735], Loss: 0.0546\n",
      "Epoch [14/50], Step [456/735], Loss: 0.0993\n",
      "Epoch [14/50], Step [457/735], Loss: 0.0248\n",
      "Epoch [14/50], Step [458/735], Loss: 0.3569\n",
      "Epoch [14/50], Step [459/735], Loss: 0.0807\n",
      "Epoch [14/50], Step [460/735], Loss: 0.0375\n",
      "Epoch [14/50], Step [461/735], Loss: 0.0529\n",
      "Epoch [14/50], Step [462/735], Loss: 0.0455\n",
      "Epoch [14/50], Step [463/735], Loss: 0.1512\n",
      "Epoch [14/50], Step [464/735], Loss: 0.1628\n",
      "Epoch [14/50], Step [465/735], Loss: 0.1135\n",
      "Epoch [14/50], Step [466/735], Loss: 0.1033\n",
      "Epoch [14/50], Step [467/735], Loss: 0.1816\n",
      "Epoch [14/50], Step [468/735], Loss: 0.5511\n",
      "Epoch [14/50], Step [469/735], Loss: 0.0447\n",
      "Epoch [14/50], Step [470/735], Loss: 0.0669\n",
      "Epoch [14/50], Step [471/735], Loss: 0.0504\n",
      "Epoch [14/50], Step [472/735], Loss: 0.2766\n",
      "Epoch [14/50], Step [473/735], Loss: 0.0493\n",
      "Epoch [14/50], Step [474/735], Loss: 0.0485\n",
      "Epoch [14/50], Step [475/735], Loss: 0.0952\n",
      "Epoch [14/50], Step [476/735], Loss: 0.0677\n",
      "Epoch [14/50], Step [477/735], Loss: 0.0312\n",
      "Epoch [14/50], Step [478/735], Loss: 0.1041\n",
      "Epoch [14/50], Step [479/735], Loss: 0.0351\n",
      "Epoch [14/50], Step [480/735], Loss: 0.1620\n",
      "Epoch [14/50], Step [481/735], Loss: 0.0284\n",
      "Epoch [14/50], Step [482/735], Loss: 0.1000\n",
      "Epoch [14/50], Step [483/735], Loss: 0.0748\n",
      "Epoch [14/50], Step [484/735], Loss: 0.0479\n",
      "Epoch [14/50], Step [485/735], Loss: 0.0386\n",
      "Epoch [14/50], Step [486/735], Loss: 0.2410\n",
      "Epoch [14/50], Step [487/735], Loss: 0.0961\n",
      "Epoch [14/50], Step [488/735], Loss: 0.0734\n",
      "Epoch [14/50], Step [489/735], Loss: 0.1579\n",
      "Epoch [14/50], Step [490/735], Loss: 0.1023\n",
      "Epoch [14/50], Step [491/735], Loss: 0.0758\n",
      "Epoch [14/50], Step [492/735], Loss: 0.1082\n",
      "Epoch [14/50], Step [493/735], Loss: 0.0347\n",
      "Epoch [14/50], Step [494/735], Loss: 0.0925\n",
      "Epoch [14/50], Step [495/735], Loss: 0.3032\n",
      "Epoch [14/50], Step [496/735], Loss: 0.0339\n",
      "Epoch [14/50], Step [497/735], Loss: 0.0876\n",
      "Epoch [14/50], Step [498/735], Loss: 0.4016\n",
      "Epoch [14/50], Step [499/735], Loss: 0.0416\n",
      "Epoch [14/50], Step [500/735], Loss: 0.0950\n",
      "Epoch [14/50], Step [501/735], Loss: 0.0681\n",
      "Epoch [14/50], Step [502/735], Loss: 0.1845\n",
      "Epoch [14/50], Step [503/735], Loss: 0.0575\n",
      "Epoch [14/50], Step [504/735], Loss: 0.0915\n",
      "Epoch [14/50], Step [505/735], Loss: 0.0637\n",
      "Epoch [14/50], Step [506/735], Loss: 0.0365\n",
      "Epoch [14/50], Step [507/735], Loss: 0.0468\n",
      "Epoch [14/50], Step [508/735], Loss: 0.0487\n",
      "Epoch [14/50], Step [509/735], Loss: 0.2408\n",
      "Epoch [14/50], Step [510/735], Loss: 0.0146\n",
      "Epoch [14/50], Step [511/735], Loss: 0.0800\n",
      "Epoch [14/50], Step [512/735], Loss: 0.2086\n",
      "Epoch [14/50], Step [513/735], Loss: 0.0306\n",
      "Epoch [14/50], Step [514/735], Loss: 0.0481\n",
      "Epoch [14/50], Step [515/735], Loss: 0.2285\n",
      "Epoch [14/50], Step [516/735], Loss: 0.1009\n",
      "Epoch [14/50], Step [517/735], Loss: 0.1824\n",
      "Epoch [14/50], Step [518/735], Loss: 0.1171\n",
      "Epoch [14/50], Step [519/735], Loss: 0.0944\n",
      "Epoch [14/50], Step [520/735], Loss: 0.0589\n",
      "Epoch [14/50], Step [521/735], Loss: 0.0855\n",
      "Epoch [14/50], Step [522/735], Loss: 0.1048\n",
      "Epoch [14/50], Step [523/735], Loss: 0.1541\n",
      "Epoch [14/50], Step [524/735], Loss: 0.0338\n",
      "Epoch [14/50], Step [525/735], Loss: 0.1121\n",
      "Epoch [14/50], Step [526/735], Loss: 0.1156\n",
      "Epoch [14/50], Step [527/735], Loss: 0.0518\n",
      "Epoch [14/50], Step [528/735], Loss: 0.1203\n",
      "Epoch [14/50], Step [529/735], Loss: 0.0312\n",
      "Epoch [14/50], Step [530/735], Loss: 0.2074\n",
      "Epoch [14/50], Step [531/735], Loss: 0.0685\n",
      "Epoch [14/50], Step [532/735], Loss: 0.0415\n",
      "Epoch [14/50], Step [533/735], Loss: 0.0278\n",
      "Epoch [14/50], Step [534/735], Loss: 0.0322\n",
      "Epoch [14/50], Step [535/735], Loss: 0.6116\n",
      "Epoch [14/50], Step [536/735], Loss: 0.0419\n",
      "Epoch [14/50], Step [537/735], Loss: 0.0903\n",
      "Epoch [14/50], Step [538/735], Loss: 0.1538\n",
      "Epoch [14/50], Step [539/735], Loss: 0.2774\n",
      "Epoch [14/50], Step [540/735], Loss: 0.0306\n",
      "Epoch [14/50], Step [541/735], Loss: 0.0435\n",
      "Epoch [14/50], Step [542/735], Loss: 0.1815\n",
      "Epoch [14/50], Step [543/735], Loss: 0.0592\n",
      "Epoch [14/50], Step [544/735], Loss: 0.1363\n",
      "Epoch [14/50], Step [545/735], Loss: 0.1201\n",
      "Epoch [14/50], Step [546/735], Loss: 0.0457\n",
      "Epoch [14/50], Step [547/735], Loss: 0.3918\n",
      "Epoch [14/50], Step [548/735], Loss: 0.0171\n",
      "Epoch [14/50], Step [549/735], Loss: 0.0636\n",
      "Epoch [14/50], Step [550/735], Loss: 0.0961\n",
      "Epoch [14/50], Step [551/735], Loss: 0.1007\n",
      "Epoch [14/50], Step [552/735], Loss: 0.1983\n",
      "Epoch [14/50], Step [553/735], Loss: 0.0623\n",
      "Epoch [14/50], Step [554/735], Loss: 0.0727\n",
      "Epoch [14/50], Step [555/735], Loss: 0.0294\n",
      "Epoch [14/50], Step [556/735], Loss: 0.1295\n",
      "Epoch [14/50], Step [557/735], Loss: 0.0657\n",
      "Epoch [14/50], Step [558/735], Loss: 0.2479\n",
      "Epoch [14/50], Step [559/735], Loss: 0.0773\n",
      "Epoch [14/50], Step [560/735], Loss: 0.0735\n",
      "Epoch [14/50], Step [561/735], Loss: 0.1661\n",
      "Epoch [14/50], Step [562/735], Loss: 0.1232\n",
      "Epoch [14/50], Step [563/735], Loss: 0.0340\n",
      "Epoch [14/50], Step [564/735], Loss: 0.0943\n",
      "Epoch [14/50], Step [565/735], Loss: 0.0472\n",
      "Epoch [14/50], Step [566/735], Loss: 0.2048\n",
      "Epoch [14/50], Step [567/735], Loss: 0.0987\n",
      "Epoch [14/50], Step [568/735], Loss: 0.1011\n",
      "Epoch [14/50], Step [569/735], Loss: 0.2510\n",
      "Epoch [14/50], Step [570/735], Loss: 0.0380\n",
      "Epoch [14/50], Step [571/735], Loss: 0.1694\n",
      "Epoch [14/50], Step [572/735], Loss: 0.1008\n",
      "Epoch [14/50], Step [573/735], Loss: 0.1254\n",
      "Epoch [14/50], Step [574/735], Loss: 0.0386\n",
      "Epoch [14/50], Step [575/735], Loss: 0.1780\n",
      "Epoch [14/50], Step [576/735], Loss: 0.2162\n",
      "Epoch [14/50], Step [577/735], Loss: 0.0667\n",
      "Epoch [14/50], Step [578/735], Loss: 0.1184\n",
      "Epoch [14/50], Step [579/735], Loss: 0.1011\n",
      "Epoch [14/50], Step [580/735], Loss: 0.0648\n",
      "Epoch [14/50], Step [581/735], Loss: 0.0521\n",
      "Epoch [14/50], Step [582/735], Loss: 0.0215\n",
      "Epoch [14/50], Step [583/735], Loss: 0.0728\n",
      "Epoch [14/50], Step [584/735], Loss: 0.0254\n",
      "Epoch [14/50], Step [585/735], Loss: 0.1721\n",
      "Epoch [14/50], Step [586/735], Loss: 0.0522\n",
      "Epoch [14/50], Step [587/735], Loss: 0.0268\n",
      "Epoch [14/50], Step [588/735], Loss: 0.1022\n",
      "Epoch [14/50], Step [589/735], Loss: 0.0434\n",
      "Epoch [14/50], Step [590/735], Loss: 0.0925\n",
      "Epoch [14/50], Step [591/735], Loss: 0.1598\n",
      "Epoch [14/50], Step [592/735], Loss: 0.0585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Step [593/735], Loss: 0.0807\n",
      "Epoch [14/50], Step [594/735], Loss: 0.1012\n",
      "Epoch [14/50], Step [595/735], Loss: 0.0695\n",
      "Epoch [14/50], Step [596/735], Loss: 0.0415\n",
      "Epoch [14/50], Step [597/735], Loss: 0.1462\n",
      "Epoch [14/50], Step [598/735], Loss: 0.0468\n",
      "Epoch [14/50], Step [599/735], Loss: 0.1330\n",
      "Epoch [14/50], Step [600/735], Loss: 0.0585\n",
      "Epoch [14/50], Step [601/735], Loss: 0.0992\n",
      "Epoch [14/50], Step [602/735], Loss: 0.2040\n",
      "Epoch [14/50], Step [603/735], Loss: 0.1370\n",
      "Epoch [14/50], Step [604/735], Loss: 0.2830\n",
      "Epoch [14/50], Step [605/735], Loss: 0.0556\n",
      "Epoch [14/50], Step [606/735], Loss: 0.0421\n",
      "Epoch [14/50], Step [607/735], Loss: 0.0797\n",
      "Epoch [14/50], Step [608/735], Loss: 0.0962\n",
      "Epoch [14/50], Step [609/735], Loss: 0.2632\n",
      "Epoch [14/50], Step [610/735], Loss: 0.0246\n",
      "Epoch [14/50], Step [611/735], Loss: 0.0451\n",
      "Epoch [14/50], Step [612/735], Loss: 0.1698\n",
      "Epoch [14/50], Step [613/735], Loss: 0.2399\n",
      "Epoch [14/50], Step [614/735], Loss: 0.1054\n",
      "Epoch [14/50], Step [615/735], Loss: 0.0194\n",
      "Epoch [14/50], Step [616/735], Loss: 0.0835\n",
      "Epoch [14/50], Step [617/735], Loss: 0.0424\n",
      "Epoch [14/50], Step [618/735], Loss: 0.1027\n",
      "Epoch [14/50], Step [619/735], Loss: 0.0692\n",
      "Epoch [14/50], Step [620/735], Loss: 0.0246\n",
      "Epoch [14/50], Step [621/735], Loss: 0.0751\n",
      "Epoch [14/50], Step [622/735], Loss: 0.1511\n",
      "Epoch [14/50], Step [623/735], Loss: 0.0312\n",
      "Epoch [14/50], Step [624/735], Loss: 0.1046\n",
      "Epoch [14/50], Step [625/735], Loss: 0.0958\n",
      "Epoch [14/50], Step [626/735], Loss: 0.0340\n",
      "Epoch [14/50], Step [627/735], Loss: 0.1204\n",
      "Epoch [14/50], Step [628/735], Loss: 0.2880\n",
      "Epoch [14/50], Step [629/735], Loss: 0.1122\n",
      "Epoch [14/50], Step [630/735], Loss: 0.1135\n",
      "Epoch [14/50], Step [631/735], Loss: 0.0383\n",
      "Epoch [14/50], Step [632/735], Loss: 0.0267\n",
      "Epoch [14/50], Step [633/735], Loss: 0.0805\n",
      "Epoch [14/50], Step [634/735], Loss: 0.0988\n",
      "Epoch [14/50], Step [635/735], Loss: 0.0773\n",
      "Epoch [14/50], Step [636/735], Loss: 0.1111\n",
      "Epoch [14/50], Step [637/735], Loss: 0.0485\n",
      "Epoch [14/50], Step [638/735], Loss: 0.0291\n",
      "Epoch [14/50], Step [639/735], Loss: 0.0634\n",
      "Epoch [14/50], Step [640/735], Loss: 0.0580\n",
      "Epoch [14/50], Step [641/735], Loss: 0.0454\n",
      "Epoch [14/50], Step [642/735], Loss: 0.0898\n",
      "Epoch [14/50], Step [643/735], Loss: 0.2428\n",
      "Epoch [14/50], Step [644/735], Loss: 0.0584\n",
      "Epoch [14/50], Step [645/735], Loss: 0.0901\n",
      "Epoch [14/50], Step [646/735], Loss: 0.3377\n",
      "Epoch [14/50], Step [647/735], Loss: 0.0585\n",
      "Epoch [14/50], Step [648/735], Loss: 0.0814\n",
      "Epoch [14/50], Step [649/735], Loss: 0.0812\n",
      "Epoch [14/50], Step [650/735], Loss: 0.0358\n",
      "Epoch [14/50], Step [651/735], Loss: 0.1766\n",
      "Epoch [14/50], Step [652/735], Loss: 0.0183\n",
      "Epoch [14/50], Step [653/735], Loss: 0.0850\n",
      "Epoch [14/50], Step [654/735], Loss: 0.1314\n",
      "Epoch [14/50], Step [655/735], Loss: 0.0481\n",
      "Epoch [14/50], Step [656/735], Loss: 0.1262\n",
      "Epoch [14/50], Step [657/735], Loss: 0.0566\n",
      "Epoch [14/50], Step [658/735], Loss: 0.1070\n",
      "Epoch [14/50], Step [659/735], Loss: 0.0862\n",
      "Epoch [14/50], Step [660/735], Loss: 0.1046\n",
      "Epoch [14/50], Step [661/735], Loss: 0.3087\n",
      "Epoch [14/50], Step [662/735], Loss: 0.0814\n",
      "Epoch [14/50], Step [663/735], Loss: 0.0249\n",
      "Epoch [14/50], Step [664/735], Loss: 0.0485\n",
      "Epoch [14/50], Step [665/735], Loss: 0.0613\n",
      "Epoch [14/50], Step [666/735], Loss: 0.1729\n",
      "Epoch [14/50], Step [667/735], Loss: 0.0479\n",
      "Epoch [14/50], Step [668/735], Loss: 0.1270\n",
      "Epoch [14/50], Step [669/735], Loss: 0.0238\n",
      "Epoch [14/50], Step [670/735], Loss: 0.0602\n",
      "Epoch [14/50], Step [671/735], Loss: 0.0688\n",
      "Epoch [14/50], Step [672/735], Loss: 0.0429\n",
      "Epoch [14/50], Step [673/735], Loss: 0.1547\n",
      "Epoch [14/50], Step [674/735], Loss: 0.0536\n",
      "Epoch [14/50], Step [675/735], Loss: 0.0538\n",
      "Epoch [14/50], Step [676/735], Loss: 0.2746\n",
      "Epoch [14/50], Step [677/735], Loss: 0.0308\n",
      "Epoch [14/50], Step [678/735], Loss: 0.0423\n",
      "Epoch [14/50], Step [679/735], Loss: 0.0692\n",
      "Epoch [14/50], Step [680/735], Loss: 0.0342\n",
      "Epoch [14/50], Step [681/735], Loss: 0.0523\n",
      "Epoch [14/50], Step [682/735], Loss: 0.0631\n",
      "Epoch [14/50], Step [683/735], Loss: 0.0361\n",
      "Epoch [14/50], Step [684/735], Loss: 0.0561\n",
      "Epoch [14/50], Step [685/735], Loss: 0.2148\n",
      "Epoch [14/50], Step [686/735], Loss: 0.0277\n",
      "Epoch [14/50], Step [687/735], Loss: 0.3187\n",
      "Epoch [14/50], Step [688/735], Loss: 0.0537\n",
      "Epoch [14/50], Step [689/735], Loss: 0.0942\n",
      "Epoch [14/50], Step [690/735], Loss: 0.1661\n",
      "Epoch [14/50], Step [691/735], Loss: 0.1018\n",
      "Epoch [14/50], Step [692/735], Loss: 0.0427\n",
      "Epoch [14/50], Step [693/735], Loss: 0.0448\n",
      "Epoch [14/50], Step [694/735], Loss: 0.0490\n",
      "Epoch [14/50], Step [695/735], Loss: 0.1957\n",
      "Epoch [14/50], Step [696/735], Loss: 0.1224\n",
      "Epoch [14/50], Step [697/735], Loss: 0.0970\n",
      "Epoch [14/50], Step [698/735], Loss: 0.0287\n",
      "Epoch [14/50], Step [699/735], Loss: 0.1295\n",
      "Epoch [14/50], Step [700/735], Loss: 0.0382\n",
      "Epoch [14/50], Step [701/735], Loss: 0.1121\n",
      "Epoch [14/50], Step [702/735], Loss: 0.1841\n",
      "Epoch [14/50], Step [703/735], Loss: 0.3429\n",
      "Epoch [14/50], Step [704/735], Loss: 0.0797\n",
      "Epoch [14/50], Step [705/735], Loss: 0.0772\n",
      "Epoch [14/50], Step [706/735], Loss: 0.0742\n",
      "Epoch [14/50], Step [707/735], Loss: 0.0893\n",
      "Epoch [14/50], Step [708/735], Loss: 0.1380\n",
      "Epoch [14/50], Step [709/735], Loss: 0.0581\n",
      "Epoch [14/50], Step [710/735], Loss: 0.4837\n",
      "Epoch [14/50], Step [711/735], Loss: 0.1197\n",
      "Epoch [14/50], Step [712/735], Loss: 0.0867\n",
      "Epoch [14/50], Step [713/735], Loss: 0.4675\n",
      "Epoch [14/50], Step [714/735], Loss: 0.0726\n",
      "Epoch [14/50], Step [715/735], Loss: 0.0685\n",
      "Epoch [14/50], Step [716/735], Loss: 0.0868\n",
      "Epoch [14/50], Step [717/735], Loss: 0.0416\n",
      "Epoch [14/50], Step [718/735], Loss: 0.2690\n",
      "Epoch [14/50], Step [719/735], Loss: 0.0450\n",
      "Epoch [14/50], Step [720/735], Loss: 0.1402\n",
      "Epoch [14/50], Step [721/735], Loss: 0.0535\n",
      "Epoch [14/50], Step [722/735], Loss: 0.0395\n",
      "Epoch [14/50], Step [723/735], Loss: 0.2569\n",
      "Epoch [14/50], Step [724/735], Loss: 0.0830\n",
      "Epoch [14/50], Step [725/735], Loss: 0.3626\n",
      "Epoch [14/50], Step [726/735], Loss: 0.0791\n",
      "Epoch [14/50], Step [727/735], Loss: 0.0373\n",
      "Epoch [14/50], Step [728/735], Loss: 0.1309\n",
      "Epoch [14/50], Step [729/735], Loss: 0.0643\n",
      "Epoch [14/50], Step [730/735], Loss: 0.2271\n",
      "Epoch [14/50], Step [731/735], Loss: 0.1093\n",
      "Epoch [14/50], Step [732/735], Loss: 0.1779\n",
      "Epoch [14/50], Step [733/735], Loss: 0.1938\n",
      "Epoch [14/50], Step [734/735], Loss: 0.1516\n",
      "Epoch [14/50], Step [735/735], Loss: 0.0322\n",
      "Epoch [15/50], Step [1/735], Loss: 0.1253\n",
      "Epoch [15/50], Step [2/735], Loss: 0.1684\n",
      "Epoch [15/50], Step [3/735], Loss: 0.2090\n",
      "Epoch [15/50], Step [4/735], Loss: 0.1366\n",
      "Epoch [15/50], Step [5/735], Loss: 0.1629\n",
      "Epoch [15/50], Step [6/735], Loss: 0.0987\n",
      "Epoch [15/50], Step [7/735], Loss: 0.0241\n",
      "Epoch [15/50], Step [8/735], Loss: 0.0409\n",
      "Epoch [15/50], Step [9/735], Loss: 0.0581\n",
      "Epoch [15/50], Step [10/735], Loss: 0.1029\n",
      "Epoch [15/50], Step [11/735], Loss: 0.1415\n",
      "Epoch [15/50], Step [12/735], Loss: 0.0504\n",
      "Epoch [15/50], Step [13/735], Loss: 0.0149\n",
      "Epoch [15/50], Step [14/735], Loss: 0.1061\n",
      "Epoch [15/50], Step [15/735], Loss: 0.0245\n",
      "Epoch [15/50], Step [16/735], Loss: 0.0471\n",
      "Epoch [15/50], Step [17/735], Loss: 0.0697\n",
      "Epoch [15/50], Step [18/735], Loss: 0.1532\n",
      "Epoch [15/50], Step [19/735], Loss: 0.1180\n",
      "Epoch [15/50], Step [20/735], Loss: 0.0796\n",
      "Epoch [15/50], Step [21/735], Loss: 0.1372\n",
      "Epoch [15/50], Step [22/735], Loss: 0.0302\n",
      "Epoch [15/50], Step [23/735], Loss: 0.0509\n",
      "Epoch [15/50], Step [24/735], Loss: 0.0400\n",
      "Epoch [15/50], Step [25/735], Loss: 0.1460\n",
      "Epoch [15/50], Step [26/735], Loss: 0.0763\n",
      "Epoch [15/50], Step [27/735], Loss: 0.1793\n",
      "Epoch [15/50], Step [28/735], Loss: 0.0163\n",
      "Epoch [15/50], Step [29/735], Loss: 0.0932\n",
      "Epoch [15/50], Step [30/735], Loss: 0.0156\n",
      "Epoch [15/50], Step [31/735], Loss: 0.0436\n",
      "Epoch [15/50], Step [32/735], Loss: 0.0423\n",
      "Epoch [15/50], Step [33/735], Loss: 0.2038\n",
      "Epoch [15/50], Step [34/735], Loss: 0.1300\n",
      "Epoch [15/50], Step [35/735], Loss: 0.1339\n",
      "Epoch [15/50], Step [36/735], Loss: 0.0417\n",
      "Epoch [15/50], Step [37/735], Loss: 0.0832\n",
      "Epoch [15/50], Step [38/735], Loss: 0.0412\n",
      "Epoch [15/50], Step [39/735], Loss: 0.0400\n",
      "Epoch [15/50], Step [40/735], Loss: 0.1490\n",
      "Epoch [15/50], Step [41/735], Loss: 0.0539\n",
      "Epoch [15/50], Step [42/735], Loss: 0.0209\n",
      "Epoch [15/50], Step [43/735], Loss: 0.4534\n",
      "Epoch [15/50], Step [44/735], Loss: 0.0437\n",
      "Epoch [15/50], Step [45/735], Loss: 0.1366\n",
      "Epoch [15/50], Step [46/735], Loss: 0.0969\n",
      "Epoch [15/50], Step [47/735], Loss: 0.0468\n",
      "Epoch [15/50], Step [48/735], Loss: 0.0809\n",
      "Epoch [15/50], Step [49/735], Loss: 0.4225\n",
      "Epoch [15/50], Step [50/735], Loss: 0.2613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Step [51/735], Loss: 0.2145\n",
      "Epoch [15/50], Step [52/735], Loss: 0.0896\n",
      "Epoch [15/50], Step [53/735], Loss: 0.0738\n",
      "Epoch [15/50], Step [54/735], Loss: 0.0901\n",
      "Epoch [15/50], Step [55/735], Loss: 0.0672\n",
      "Epoch [15/50], Step [56/735], Loss: 0.0708\n",
      "Epoch [15/50], Step [57/735], Loss: 0.0313\n",
      "Epoch [15/50], Step [58/735], Loss: 0.1102\n",
      "Epoch [15/50], Step [59/735], Loss: 0.1147\n",
      "Epoch [15/50], Step [60/735], Loss: 0.2165\n",
      "Epoch [15/50], Step [61/735], Loss: 0.0973\n",
      "Epoch [15/50], Step [62/735], Loss: 0.0382\n",
      "Epoch [15/50], Step [63/735], Loss: 0.0236\n",
      "Epoch [15/50], Step [64/735], Loss: 0.0609\n",
      "Epoch [15/50], Step [65/735], Loss: 0.0958\n",
      "Epoch [15/50], Step [66/735], Loss: 0.0392\n",
      "Epoch [15/50], Step [67/735], Loss: 0.1502\n",
      "Epoch [15/50], Step [68/735], Loss: 0.3541\n",
      "Epoch [15/50], Step [69/735], Loss: 0.0324\n",
      "Epoch [15/50], Step [70/735], Loss: 0.0609\n",
      "Epoch [15/50], Step [71/735], Loss: 0.0659\n",
      "Epoch [15/50], Step [72/735], Loss: 0.0906\n",
      "Epoch [15/50], Step [73/735], Loss: 0.2536\n",
      "Epoch [15/50], Step [74/735], Loss: 0.0813\n",
      "Epoch [15/50], Step [75/735], Loss: 0.0514\n",
      "Epoch [15/50], Step [76/735], Loss: 0.1157\n",
      "Epoch [15/50], Step [77/735], Loss: 0.1646\n",
      "Epoch [15/50], Step [78/735], Loss: 0.0462\n",
      "Epoch [15/50], Step [79/735], Loss: 0.0527\n",
      "Epoch [15/50], Step [80/735], Loss: 0.0520\n",
      "Epoch [15/50], Step [81/735], Loss: 0.1454\n",
      "Epoch [15/50], Step [82/735], Loss: 0.0251\n",
      "Epoch [15/50], Step [83/735], Loss: 0.2328\n",
      "Epoch [15/50], Step [84/735], Loss: 0.0496\n",
      "Epoch [15/50], Step [85/735], Loss: 0.0406\n",
      "Epoch [15/50], Step [86/735], Loss: 0.1417\n",
      "Epoch [15/50], Step [87/735], Loss: 0.0972\n",
      "Epoch [15/50], Step [88/735], Loss: 0.4531\n",
      "Epoch [15/50], Step [89/735], Loss: 0.0747\n",
      "Epoch [15/50], Step [90/735], Loss: 0.0616\n",
      "Epoch [15/50], Step [91/735], Loss: 0.0820\n",
      "Epoch [15/50], Step [92/735], Loss: 0.0818\n",
      "Epoch [15/50], Step [93/735], Loss: 0.3711\n",
      "Epoch [15/50], Step [94/735], Loss: 0.1280\n",
      "Epoch [15/50], Step [95/735], Loss: 0.2737\n",
      "Epoch [15/50], Step [96/735], Loss: 0.0387\n",
      "Epoch [15/50], Step [97/735], Loss: 0.0235\n",
      "Epoch [15/50], Step [98/735], Loss: 0.1567\n",
      "Epoch [15/50], Step [99/735], Loss: 0.0437\n",
      "Epoch [15/50], Step [100/735], Loss: 0.1249\n",
      "Epoch [15/50], Step [101/735], Loss: 0.0527\n",
      "Epoch [15/50], Step [102/735], Loss: 0.2361\n",
      "Epoch [15/50], Step [103/735], Loss: 0.0906\n",
      "Epoch [15/50], Step [104/735], Loss: 0.0473\n",
      "Epoch [15/50], Step [105/735], Loss: 0.4354\n",
      "Epoch [15/50], Step [106/735], Loss: 0.0620\n",
      "Epoch [15/50], Step [107/735], Loss: 0.0728\n",
      "Epoch [15/50], Step [108/735], Loss: 0.0463\n",
      "Epoch [15/50], Step [109/735], Loss: 0.2988\n",
      "Epoch [15/50], Step [110/735], Loss: 0.0695\n",
      "Epoch [15/50], Step [111/735], Loss: 0.1665\n",
      "Epoch [15/50], Step [112/735], Loss: 0.0884\n",
      "Epoch [15/50], Step [113/735], Loss: 0.0474\n",
      "Epoch [15/50], Step [114/735], Loss: 0.1034\n",
      "Epoch [15/50], Step [115/735], Loss: 0.1002\n",
      "Epoch [15/50], Step [116/735], Loss: 0.0342\n",
      "Epoch [15/50], Step [117/735], Loss: 0.1910\n",
      "Epoch [15/50], Step [118/735], Loss: 0.0837\n",
      "Epoch [15/50], Step [119/735], Loss: 0.0760\n",
      "Epoch [15/50], Step [120/735], Loss: 0.0847\n",
      "Epoch [15/50], Step [121/735], Loss: 0.1239\n",
      "Epoch [15/50], Step [122/735], Loss: 0.0650\n",
      "Epoch [15/50], Step [123/735], Loss: 0.1662\n",
      "Epoch [15/50], Step [124/735], Loss: 0.0461\n",
      "Epoch [15/50], Step [125/735], Loss: 0.0882\n",
      "Epoch [15/50], Step [126/735], Loss: 0.0835\n",
      "Epoch [15/50], Step [127/735], Loss: 0.0557\n",
      "Epoch [15/50], Step [128/735], Loss: 0.0819\n",
      "Epoch [15/50], Step [129/735], Loss: 0.2381\n",
      "Epoch [15/50], Step [130/735], Loss: 0.0715\n",
      "Epoch [15/50], Step [131/735], Loss: 0.0642\n",
      "Epoch [15/50], Step [132/735], Loss: 0.1322\n",
      "Epoch [15/50], Step [133/735], Loss: 0.1398\n",
      "Epoch [15/50], Step [134/735], Loss: 0.0557\n",
      "Epoch [15/50], Step [135/735], Loss: 0.3192\n",
      "Epoch [15/50], Step [136/735], Loss: 0.1419\n",
      "Epoch [15/50], Step [137/735], Loss: 0.0628\n",
      "Epoch [15/50], Step [138/735], Loss: 0.1984\n",
      "Epoch [15/50], Step [139/735], Loss: 0.0395\n",
      "Epoch [15/50], Step [140/735], Loss: 0.0789\n",
      "Epoch [15/50], Step [141/735], Loss: 0.1290\n",
      "Epoch [15/50], Step [142/735], Loss: 0.0463\n",
      "Epoch [15/50], Step [143/735], Loss: 0.0622\n",
      "Epoch [15/50], Step [144/735], Loss: 0.0876\n",
      "Epoch [15/50], Step [145/735], Loss: 0.0488\n",
      "Epoch [15/50], Step [146/735], Loss: 0.0441\n",
      "Epoch [15/50], Step [147/735], Loss: 0.0685\n",
      "Epoch [15/50], Step [148/735], Loss: 0.0588\n",
      "Epoch [15/50], Step [149/735], Loss: 0.0722\n",
      "Epoch [15/50], Step [150/735], Loss: 0.1247\n",
      "Epoch [15/50], Step [151/735], Loss: 0.0870\n",
      "Epoch [15/50], Step [152/735], Loss: 0.0366\n",
      "Epoch [15/50], Step [153/735], Loss: 0.0571\n",
      "Epoch [15/50], Step [154/735], Loss: 0.1415\n",
      "Epoch [15/50], Step [155/735], Loss: 0.0637\n",
      "Epoch [15/50], Step [156/735], Loss: 0.0490\n",
      "Epoch [15/50], Step [157/735], Loss: 0.2177\n",
      "Epoch [15/50], Step [158/735], Loss: 0.0567\n",
      "Epoch [15/50], Step [159/735], Loss: 0.0531\n",
      "Epoch [15/50], Step [160/735], Loss: 0.0380\n",
      "Epoch [15/50], Step [161/735], Loss: 0.0453\n",
      "Epoch [15/50], Step [162/735], Loss: 0.0738\n",
      "Epoch [15/50], Step [163/735], Loss: 0.0308\n",
      "Epoch [15/50], Step [164/735], Loss: 0.0794\n",
      "Epoch [15/50], Step [165/735], Loss: 0.0665\n",
      "Epoch [15/50], Step [166/735], Loss: 0.0959\n",
      "Epoch [15/50], Step [167/735], Loss: 0.1033\n",
      "Epoch [15/50], Step [168/735], Loss: 0.0483\n",
      "Epoch [15/50], Step [169/735], Loss: 0.0771\n",
      "Epoch [15/50], Step [170/735], Loss: 0.0388\n",
      "Epoch [15/50], Step [171/735], Loss: 0.0182\n",
      "Epoch [15/50], Step [172/735], Loss: 0.0531\n",
      "Epoch [15/50], Step [173/735], Loss: 0.2830\n",
      "Epoch [15/50], Step [174/735], Loss: 0.1248\n",
      "Epoch [15/50], Step [175/735], Loss: 0.0385\n",
      "Epoch [15/50], Step [176/735], Loss: 0.0724\n",
      "Epoch [15/50], Step [177/735], Loss: 0.0413\n",
      "Epoch [15/50], Step [178/735], Loss: 0.1320\n",
      "Epoch [15/50], Step [179/735], Loss: 0.1575\n",
      "Epoch [15/50], Step [180/735], Loss: 0.0649\n",
      "Epoch [15/50], Step [181/735], Loss: 0.1475\n",
      "Epoch [15/50], Step [182/735], Loss: 0.0367\n",
      "Epoch [15/50], Step [183/735], Loss: 0.1044\n",
      "Epoch [15/50], Step [184/735], Loss: 0.4889\n",
      "Epoch [15/50], Step [185/735], Loss: 0.1168\n",
      "Epoch [15/50], Step [186/735], Loss: 0.2041\n",
      "Epoch [15/50], Step [187/735], Loss: 0.0472\n",
      "Epoch [15/50], Step [188/735], Loss: 0.0574\n",
      "Epoch [15/50], Step [189/735], Loss: 0.0657\n",
      "Epoch [15/50], Step [190/735], Loss: 0.0776\n",
      "Epoch [15/50], Step [191/735], Loss: 0.0525\n",
      "Epoch [15/50], Step [192/735], Loss: 0.1650\n",
      "Epoch [15/50], Step [193/735], Loss: 0.0851\n",
      "Epoch [15/50], Step [194/735], Loss: 0.0878\n",
      "Epoch [15/50], Step [195/735], Loss: 0.0424\n",
      "Epoch [15/50], Step [196/735], Loss: 0.0323\n",
      "Epoch [15/50], Step [197/735], Loss: 0.0696\n",
      "Epoch [15/50], Step [198/735], Loss: 0.0578\n",
      "Epoch [15/50], Step [199/735], Loss: 0.0994\n",
      "Epoch [15/50], Step [200/735], Loss: 0.0262\n",
      "Epoch [15/50], Step [201/735], Loss: 0.0239\n",
      "Epoch [15/50], Step [202/735], Loss: 0.0365\n",
      "Epoch [15/50], Step [203/735], Loss: 0.2223\n",
      "Epoch [15/50], Step [204/735], Loss: 0.0522\n",
      "Epoch [15/50], Step [205/735], Loss: 0.0314\n",
      "Epoch [15/50], Step [206/735], Loss: 0.0801\n",
      "Epoch [15/50], Step [207/735], Loss: 0.0543\n",
      "Epoch [15/50], Step [208/735], Loss: 0.1367\n",
      "Epoch [15/50], Step [209/735], Loss: 0.0256\n",
      "Epoch [15/50], Step [210/735], Loss: 0.1075\n",
      "Epoch [15/50], Step [211/735], Loss: 0.1823\n",
      "Epoch [15/50], Step [212/735], Loss: 0.1320\n",
      "Epoch [15/50], Step [213/735], Loss: 0.2083\n",
      "Epoch [15/50], Step [214/735], Loss: 0.0752\n",
      "Epoch [15/50], Step [215/735], Loss: 0.0728\n",
      "Epoch [15/50], Step [216/735], Loss: 0.1769\n",
      "Epoch [15/50], Step [217/735], Loss: 0.0621\n",
      "Epoch [15/50], Step [218/735], Loss: 0.1926\n",
      "Epoch [15/50], Step [219/735], Loss: 0.0870\n",
      "Epoch [15/50], Step [220/735], Loss: 0.2183\n",
      "Epoch [15/50], Step [221/735], Loss: 0.0639\n",
      "Epoch [15/50], Step [222/735], Loss: 0.0683\n",
      "Epoch [15/50], Step [223/735], Loss: 0.1733\n",
      "Epoch [15/50], Step [224/735], Loss: 0.0898\n",
      "Epoch [15/50], Step [225/735], Loss: 0.0702\n",
      "Epoch [15/50], Step [226/735], Loss: 0.3007\n",
      "Epoch [15/50], Step [227/735], Loss: 0.1986\n",
      "Epoch [15/50], Step [228/735], Loss: 0.3066\n",
      "Epoch [15/50], Step [229/735], Loss: 0.0975\n",
      "Epoch [15/50], Step [230/735], Loss: 0.0400\n",
      "Epoch [15/50], Step [231/735], Loss: 0.0888\n",
      "Epoch [15/50], Step [232/735], Loss: 0.2945\n",
      "Epoch [15/50], Step [233/735], Loss: 0.2142\n",
      "Epoch [15/50], Step [234/735], Loss: 0.4486\n",
      "Epoch [15/50], Step [235/735], Loss: 0.0678\n",
      "Epoch [15/50], Step [236/735], Loss: 0.0791\n",
      "Epoch [15/50], Step [237/735], Loss: 0.1949\n",
      "Epoch [15/50], Step [238/735], Loss: 0.0320\n",
      "Epoch [15/50], Step [239/735], Loss: 0.0437\n",
      "Epoch [15/50], Step [240/735], Loss: 0.1073\n",
      "Epoch [15/50], Step [241/735], Loss: 0.0421\n",
      "Epoch [15/50], Step [242/735], Loss: 0.0604\n",
      "Epoch [15/50], Step [243/735], Loss: 0.0342\n",
      "Epoch [15/50], Step [244/735], Loss: 0.0770\n",
      "Epoch [15/50], Step [245/735], Loss: 0.0539\n",
      "Epoch [15/50], Step [246/735], Loss: 0.0846\n",
      "Epoch [15/50], Step [247/735], Loss: 0.1193\n",
      "Epoch [15/50], Step [248/735], Loss: 0.1686\n",
      "Epoch [15/50], Step [249/735], Loss: 0.0787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Step [250/735], Loss: 0.2307\n",
      "Epoch [15/50], Step [251/735], Loss: 0.1030\n",
      "Epoch [15/50], Step [252/735], Loss: 0.0421\n",
      "Epoch [15/50], Step [253/735], Loss: 0.0718\n",
      "Epoch [15/50], Step [254/735], Loss: 0.0282\n",
      "Epoch [15/50], Step [255/735], Loss: 0.0764\n",
      "Epoch [15/50], Step [256/735], Loss: 0.2901\n",
      "Epoch [15/50], Step [257/735], Loss: 0.0340\n",
      "Epoch [15/50], Step [258/735], Loss: 0.1524\n",
      "Epoch [15/50], Step [259/735], Loss: 0.0818\n",
      "Epoch [15/50], Step [260/735], Loss: 0.0509\n",
      "Epoch [15/50], Step [261/735], Loss: 0.0553\n",
      "Epoch [15/50], Step [262/735], Loss: 0.0277\n",
      "Epoch [15/50], Step [263/735], Loss: 0.0545\n",
      "Epoch [15/50], Step [264/735], Loss: 0.0974\n",
      "Epoch [15/50], Step [265/735], Loss: 0.0263\n",
      "Epoch [15/50], Step [266/735], Loss: 0.0595\n",
      "Epoch [15/50], Step [267/735], Loss: 0.2401\n",
      "Epoch [15/50], Step [268/735], Loss: 0.0915\n",
      "Epoch [15/50], Step [269/735], Loss: 0.0302\n",
      "Epoch [15/50], Step [270/735], Loss: 0.0680\n",
      "Epoch [15/50], Step [271/735], Loss: 0.0392\n",
      "Epoch [15/50], Step [272/735], Loss: 0.1540\n",
      "Epoch [15/50], Step [273/735], Loss: 0.1040\n",
      "Epoch [15/50], Step [274/735], Loss: 0.0323\n",
      "Epoch [15/50], Step [275/735], Loss: 0.1055\n",
      "Epoch [15/50], Step [276/735], Loss: 0.0605\n",
      "Epoch [15/50], Step [277/735], Loss: 0.0636\n",
      "Epoch [15/50], Step [278/735], Loss: 0.0860\n",
      "Epoch [15/50], Step [279/735], Loss: 0.0959\n",
      "Epoch [15/50], Step [280/735], Loss: 0.0980\n",
      "Epoch [15/50], Step [281/735], Loss: 0.2054\n",
      "Epoch [15/50], Step [282/735], Loss: 0.0963\n",
      "Epoch [15/50], Step [283/735], Loss: 0.1094\n",
      "Epoch [15/50], Step [284/735], Loss: 0.1435\n",
      "Epoch [15/50], Step [285/735], Loss: 0.1023\n",
      "Epoch [15/50], Step [286/735], Loss: 0.2233\n",
      "Epoch [15/50], Step [287/735], Loss: 0.0390\n",
      "Epoch [15/50], Step [288/735], Loss: 0.3025\n",
      "Epoch [15/50], Step [289/735], Loss: 0.1085\n",
      "Epoch [15/50], Step [290/735], Loss: 0.0509\n",
      "Epoch [15/50], Step [291/735], Loss: 0.4248\n",
      "Epoch [15/50], Step [292/735], Loss: 0.0614\n",
      "Epoch [15/50], Step [293/735], Loss: 0.0387\n",
      "Epoch [15/50], Step [294/735], Loss: 0.2038\n",
      "Epoch [15/50], Step [295/735], Loss: 0.2124\n",
      "Epoch [15/50], Step [296/735], Loss: 0.0584\n",
      "Epoch [15/50], Step [297/735], Loss: 0.0507\n",
      "Epoch [15/50], Step [298/735], Loss: 0.0685\n",
      "Epoch [15/50], Step [299/735], Loss: 0.2765\n",
      "Epoch [15/50], Step [300/735], Loss: 0.0925\n",
      "Epoch [15/50], Step [301/735], Loss: 0.0863\n",
      "Epoch [15/50], Step [302/735], Loss: 0.0589\n",
      "Epoch [15/50], Step [303/735], Loss: 0.1180\n",
      "Epoch [15/50], Step [304/735], Loss: 0.0287\n",
      "Epoch [15/50], Step [305/735], Loss: 0.1141\n",
      "Epoch [15/50], Step [306/735], Loss: 0.2322\n",
      "Epoch [15/50], Step [307/735], Loss: 0.1070\n",
      "Epoch [15/50], Step [308/735], Loss: 0.0576\n",
      "Epoch [15/50], Step [309/735], Loss: 0.0363\n",
      "Epoch [15/50], Step [310/735], Loss: 0.0392\n",
      "Epoch [15/50], Step [311/735], Loss: 0.0760\n",
      "Epoch [15/50], Step [312/735], Loss: 0.0450\n",
      "Epoch [15/50], Step [313/735], Loss: 0.0299\n",
      "Epoch [15/50], Step [314/735], Loss: 0.0412\n",
      "Epoch [15/50], Step [315/735], Loss: 0.0368\n",
      "Epoch [15/50], Step [316/735], Loss: 0.2506\n",
      "Epoch [15/50], Step [317/735], Loss: 0.2242\n",
      "Epoch [15/50], Step [318/735], Loss: 0.0599\n",
      "Epoch [15/50], Step [319/735], Loss: 0.0761\n",
      "Epoch [15/50], Step [320/735], Loss: 0.1664\n",
      "Epoch [15/50], Step [321/735], Loss: 0.0994\n",
      "Epoch [15/50], Step [322/735], Loss: 0.1413\n",
      "Epoch [15/50], Step [323/735], Loss: 0.0847\n",
      "Epoch [15/50], Step [324/735], Loss: 0.0714\n",
      "Epoch [15/50], Step [325/735], Loss: 0.0869\n",
      "Epoch [15/50], Step [326/735], Loss: 0.1106\n",
      "Epoch [15/50], Step [327/735], Loss: 0.1179\n",
      "Epoch [15/50], Step [328/735], Loss: 0.0722\n",
      "Epoch [15/50], Step [329/735], Loss: 0.4638\n",
      "Epoch [15/50], Step [330/735], Loss: 0.0770\n",
      "Epoch [15/50], Step [331/735], Loss: 0.0633\n",
      "Epoch [15/50], Step [332/735], Loss: 0.0765\n",
      "Epoch [15/50], Step [333/735], Loss: 0.0890\n",
      "Epoch [15/50], Step [334/735], Loss: 0.1544\n",
      "Epoch [15/50], Step [335/735], Loss: 0.0810\n",
      "Epoch [15/50], Step [336/735], Loss: 0.1866\n",
      "Epoch [15/50], Step [337/735], Loss: 0.0705\n",
      "Epoch [15/50], Step [338/735], Loss: 0.0256\n",
      "Epoch [15/50], Step [339/735], Loss: 0.1088\n",
      "Epoch [15/50], Step [340/735], Loss: 0.0550\n",
      "Epoch [15/50], Step [341/735], Loss: 0.0585\n",
      "Epoch [15/50], Step [342/735], Loss: 0.0590\n",
      "Epoch [15/50], Step [343/735], Loss: 0.0456\n",
      "Epoch [15/50], Step [344/735], Loss: 0.1328\n",
      "Epoch [15/50], Step [345/735], Loss: 0.0865\n",
      "Epoch [15/50], Step [346/735], Loss: 0.1368\n",
      "Epoch [15/50], Step [347/735], Loss: 0.0840\n",
      "Epoch [15/50], Step [348/735], Loss: 0.0422\n",
      "Epoch [15/50], Step [349/735], Loss: 0.0536\n",
      "Epoch [15/50], Step [350/735], Loss: 0.0608\n",
      "Epoch [15/50], Step [351/735], Loss: 0.2051\n",
      "Epoch [15/50], Step [352/735], Loss: 0.1092\n",
      "Epoch [15/50], Step [353/735], Loss: 0.0314\n",
      "Epoch [15/50], Step [354/735], Loss: 0.0955\n",
      "Epoch [15/50], Step [355/735], Loss: 0.1123\n",
      "Epoch [15/50], Step [356/735], Loss: 0.0630\n",
      "Epoch [15/50], Step [357/735], Loss: 0.0343\n",
      "Epoch [15/50], Step [358/735], Loss: 0.1589\n",
      "Epoch [15/50], Step [359/735], Loss: 0.0519\n",
      "Epoch [15/50], Step [360/735], Loss: 0.0361\n",
      "Epoch [15/50], Step [361/735], Loss: 0.0198\n",
      "Epoch [15/50], Step [362/735], Loss: 0.0420\n",
      "Epoch [15/50], Step [363/735], Loss: 0.0552\n",
      "Epoch [15/50], Step [364/735], Loss: 0.0393\n",
      "Epoch [15/50], Step [365/735], Loss: 0.0301\n",
      "Epoch [15/50], Step [366/735], Loss: 0.0346\n",
      "Epoch [15/50], Step [367/735], Loss: 0.0489\n",
      "Epoch [15/50], Step [368/735], Loss: 0.0274\n",
      "Epoch [15/50], Step [369/735], Loss: 0.1110\n",
      "Epoch [15/50], Step [370/735], Loss: 0.0496\n",
      "Epoch [15/50], Step [371/735], Loss: 0.0592\n",
      "Epoch [15/50], Step [372/735], Loss: 0.1251\n",
      "Epoch [15/50], Step [373/735], Loss: 0.1386\n",
      "Epoch [15/50], Step [374/735], Loss: 0.0380\n",
      "Epoch [15/50], Step [375/735], Loss: 0.0266\n",
      "Epoch [15/50], Step [376/735], Loss: 0.2241\n",
      "Epoch [15/50], Step [377/735], Loss: 0.0230\n",
      "Epoch [15/50], Step [378/735], Loss: 0.0416\n",
      "Epoch [15/50], Step [379/735], Loss: 0.0683\n",
      "Epoch [15/50], Step [380/735], Loss: 0.0775\n",
      "Epoch [15/50], Step [381/735], Loss: 0.1220\n",
      "Epoch [15/50], Step [382/735], Loss: 0.1201\n",
      "Epoch [15/50], Step [383/735], Loss: 0.1257\n",
      "Epoch [15/50], Step [384/735], Loss: 0.0276\n",
      "Epoch [15/50], Step [385/735], Loss: 0.1591\n",
      "Epoch [15/50], Step [386/735], Loss: 0.0280\n",
      "Epoch [15/50], Step [387/735], Loss: 0.1119\n",
      "Epoch [15/50], Step [388/735], Loss: 0.0742\n",
      "Epoch [15/50], Step [389/735], Loss: 0.0257\n",
      "Epoch [15/50], Step [390/735], Loss: 0.0754\n",
      "Epoch [15/50], Step [391/735], Loss: 0.3943\n",
      "Epoch [15/50], Step [392/735], Loss: 0.0635\n",
      "Epoch [15/50], Step [393/735], Loss: 0.0525\n",
      "Epoch [15/50], Step [394/735], Loss: 0.0722\n",
      "Epoch [15/50], Step [395/735], Loss: 0.0784\n",
      "Epoch [15/50], Step [396/735], Loss: 0.0536\n",
      "Epoch [15/50], Step [397/735], Loss: 0.0464\n",
      "Epoch [15/50], Step [398/735], Loss: 0.1504\n",
      "Epoch [15/50], Step [399/735], Loss: 0.0574\n",
      "Epoch [15/50], Step [400/735], Loss: 0.0926\n",
      "Epoch [15/50], Step [401/735], Loss: 0.0485\n",
      "Epoch [15/50], Step [402/735], Loss: 0.0595\n",
      "Epoch [15/50], Step [403/735], Loss: 0.2099\n",
      "Epoch [15/50], Step [404/735], Loss: 0.0630\n",
      "Epoch [15/50], Step [405/735], Loss: 0.0271\n",
      "Epoch [15/50], Step [406/735], Loss: 0.0560\n",
      "Epoch [15/50], Step [407/735], Loss: 0.0402\n",
      "Epoch [15/50], Step [408/735], Loss: 0.1691\n",
      "Epoch [15/50], Step [409/735], Loss: 0.1255\n",
      "Epoch [15/50], Step [410/735], Loss: 0.0816\n",
      "Epoch [15/50], Step [411/735], Loss: 0.0235\n",
      "Epoch [15/50], Step [412/735], Loss: 0.0429\n",
      "Epoch [15/50], Step [413/735], Loss: 0.1513\n",
      "Epoch [15/50], Step [414/735], Loss: 0.0526\n",
      "Epoch [15/50], Step [415/735], Loss: 0.0973\n",
      "Epoch [15/50], Step [416/735], Loss: 0.1407\n",
      "Epoch [15/50], Step [417/735], Loss: 0.0517\n",
      "Epoch [15/50], Step [418/735], Loss: 0.1884\n",
      "Epoch [15/50], Step [419/735], Loss: 0.0404\n",
      "Epoch [15/50], Step [420/735], Loss: 0.0517\n",
      "Epoch [15/50], Step [421/735], Loss: 0.0553\n",
      "Epoch [15/50], Step [422/735], Loss: 0.1181\n",
      "Epoch [15/50], Step [423/735], Loss: 0.0599\n",
      "Epoch [15/50], Step [424/735], Loss: 0.0619\n",
      "Epoch [15/50], Step [425/735], Loss: 0.0435\n",
      "Epoch [15/50], Step [426/735], Loss: 0.1285\n",
      "Epoch [15/50], Step [427/735], Loss: 0.0253\n",
      "Epoch [15/50], Step [428/735], Loss: 0.0348\n",
      "Epoch [15/50], Step [429/735], Loss: 0.0708\n",
      "Epoch [15/50], Step [430/735], Loss: 0.1645\n",
      "Epoch [15/50], Step [431/735], Loss: 0.2144\n",
      "Epoch [15/50], Step [432/735], Loss: 0.0405\n",
      "Epoch [15/50], Step [433/735], Loss: 0.0901\n",
      "Epoch [15/50], Step [434/735], Loss: 0.1398\n",
      "Epoch [15/50], Step [435/735], Loss: 0.0450\n",
      "Epoch [15/50], Step [436/735], Loss: 0.2075\n",
      "Epoch [15/50], Step [437/735], Loss: 0.0303\n",
      "Epoch [15/50], Step [438/735], Loss: 0.1304\n",
      "Epoch [15/50], Step [439/735], Loss: 0.0679\n",
      "Epoch [15/50], Step [440/735], Loss: 0.0398\n",
      "Epoch [15/50], Step [441/735], Loss: 0.0208\n",
      "Epoch [15/50], Step [442/735], Loss: 0.0878\n",
      "Epoch [15/50], Step [443/735], Loss: 0.1099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Step [444/735], Loss: 0.0252\n",
      "Epoch [15/50], Step [445/735], Loss: 0.1277\n",
      "Epoch [15/50], Step [446/735], Loss: 0.1095\n",
      "Epoch [15/50], Step [447/735], Loss: 0.0386\n",
      "Epoch [15/50], Step [448/735], Loss: 0.1771\n",
      "Epoch [15/50], Step [449/735], Loss: 0.1019\n",
      "Epoch [15/50], Step [450/735], Loss: 0.0912\n",
      "Epoch [15/50], Step [451/735], Loss: 0.1323\n",
      "Epoch [15/50], Step [452/735], Loss: 0.1218\n",
      "Epoch [15/50], Step [453/735], Loss: 0.1147\n",
      "Epoch [15/50], Step [454/735], Loss: 0.0542\n",
      "Epoch [15/50], Step [455/735], Loss: 0.1245\n",
      "Epoch [15/50], Step [456/735], Loss: 0.1879\n",
      "Epoch [15/50], Step [457/735], Loss: 0.0645\n",
      "Epoch [15/50], Step [458/735], Loss: 0.0580\n",
      "Epoch [15/50], Step [459/735], Loss: 0.0607\n",
      "Epoch [15/50], Step [460/735], Loss: 0.1927\n",
      "Epoch [15/50], Step [461/735], Loss: 0.1404\n",
      "Epoch [15/50], Step [462/735], Loss: 0.1717\n",
      "Epoch [15/50], Step [463/735], Loss: 0.0392\n",
      "Epoch [15/50], Step [464/735], Loss: 0.7012\n",
      "Epoch [15/50], Step [465/735], Loss: 0.0779\n",
      "Epoch [15/50], Step [466/735], Loss: 0.6121\n",
      "Epoch [15/50], Step [467/735], Loss: 0.0847\n",
      "Epoch [15/50], Step [468/735], Loss: 0.1174\n",
      "Epoch [15/50], Step [469/735], Loss: 0.0923\n",
      "Epoch [15/50], Step [470/735], Loss: 0.1107\n",
      "Epoch [15/50], Step [471/735], Loss: 0.0340\n",
      "Epoch [15/50], Step [472/735], Loss: 0.1499\n",
      "Epoch [15/50], Step [473/735], Loss: 0.1343\n",
      "Epoch [15/50], Step [474/735], Loss: 0.0590\n",
      "Epoch [15/50], Step [475/735], Loss: 0.1287\n",
      "Epoch [15/50], Step [476/735], Loss: 0.1953\n",
      "Epoch [15/50], Step [477/735], Loss: 0.0781\n",
      "Epoch [15/50], Step [478/735], Loss: 0.0625\n",
      "Epoch [15/50], Step [479/735], Loss: 0.0323\n",
      "Epoch [15/50], Step [480/735], Loss: 0.0443\n",
      "Epoch [15/50], Step [481/735], Loss: 0.0593\n",
      "Epoch [15/50], Step [482/735], Loss: 0.1386\n",
      "Epoch [15/50], Step [483/735], Loss: 0.0626\n",
      "Epoch [15/50], Step [484/735], Loss: 0.1689\n",
      "Epoch [15/50], Step [485/735], Loss: 0.3072\n",
      "Epoch [15/50], Step [486/735], Loss: 0.1319\n",
      "Epoch [15/50], Step [487/735], Loss: 0.0607\n",
      "Epoch [15/50], Step [488/735], Loss: 0.1262\n",
      "Epoch [15/50], Step [489/735], Loss: 0.1095\n",
      "Epoch [15/50], Step [490/735], Loss: 0.1690\n",
      "Epoch [15/50], Step [491/735], Loss: 0.0736\n",
      "Epoch [15/50], Step [492/735], Loss: 0.2253\n",
      "Epoch [15/50], Step [493/735], Loss: 0.1551\n",
      "Epoch [15/50], Step [494/735], Loss: 0.0417\n",
      "Epoch [15/50], Step [495/735], Loss: 0.2607\n",
      "Epoch [15/50], Step [496/735], Loss: 0.0424\n",
      "Epoch [15/50], Step [497/735], Loss: 0.0774\n",
      "Epoch [15/50], Step [498/735], Loss: 0.1187\n",
      "Epoch [15/50], Step [499/735], Loss: 0.2110\n",
      "Epoch [15/50], Step [500/735], Loss: 0.2162\n",
      "Epoch [15/50], Step [501/735], Loss: 0.0837\n",
      "Epoch [15/50], Step [502/735], Loss: 0.0558\n",
      "Epoch [15/50], Step [503/735], Loss: 0.0808\n",
      "Epoch [15/50], Step [504/735], Loss: 0.0636\n",
      "Epoch [15/50], Step [505/735], Loss: 0.1844\n",
      "Epoch [15/50], Step [506/735], Loss: 0.1408\n",
      "Epoch [15/50], Step [507/735], Loss: 0.1056\n",
      "Epoch [15/50], Step [508/735], Loss: 0.0715\n",
      "Epoch [15/50], Step [509/735], Loss: 0.1388\n",
      "Epoch [15/50], Step [510/735], Loss: 0.1480\n",
      "Epoch [15/50], Step [511/735], Loss: 0.0822\n",
      "Epoch [15/50], Step [512/735], Loss: 0.5288\n",
      "Epoch [15/50], Step [513/735], Loss: 0.1466\n",
      "Epoch [15/50], Step [514/735], Loss: 0.0524\n",
      "Epoch [15/50], Step [515/735], Loss: 0.0959\n",
      "Epoch [15/50], Step [516/735], Loss: 0.0529\n",
      "Epoch [15/50], Step [517/735], Loss: 0.0860\n",
      "Epoch [15/50], Step [518/735], Loss: 0.1435\n",
      "Epoch [15/50], Step [519/735], Loss: 0.1461\n",
      "Epoch [15/50], Step [520/735], Loss: 0.0461\n",
      "Epoch [15/50], Step [521/735], Loss: 0.1935\n",
      "Epoch [15/50], Step [522/735], Loss: 0.0786\n",
      "Epoch [15/50], Step [523/735], Loss: 0.0622\n",
      "Epoch [15/50], Step [524/735], Loss: 0.0203\n",
      "Epoch [15/50], Step [525/735], Loss: 0.4856\n",
      "Epoch [15/50], Step [526/735], Loss: 0.0461\n",
      "Epoch [15/50], Step [527/735], Loss: 0.0740\n",
      "Epoch [15/50], Step [528/735], Loss: 0.0390\n",
      "Epoch [15/50], Step [529/735], Loss: 0.2186\n",
      "Epoch [15/50], Step [530/735], Loss: 0.0721\n",
      "Epoch [15/50], Step [531/735], Loss: 0.0759\n",
      "Epoch [15/50], Step [532/735], Loss: 0.0666\n",
      "Epoch [15/50], Step [533/735], Loss: 0.1111\n",
      "Epoch [15/50], Step [534/735], Loss: 0.1150\n",
      "Epoch [15/50], Step [535/735], Loss: 0.0739\n",
      "Epoch [15/50], Step [536/735], Loss: 0.0331\n",
      "Epoch [15/50], Step [537/735], Loss: 0.0587\n",
      "Epoch [15/50], Step [538/735], Loss: 0.0784\n",
      "Epoch [15/50], Step [539/735], Loss: 0.1082\n",
      "Epoch [15/50], Step [540/735], Loss: 0.0296\n",
      "Epoch [15/50], Step [541/735], Loss: 0.1003\n",
      "Epoch [15/50], Step [542/735], Loss: 0.1202\n",
      "Epoch [15/50], Step [543/735], Loss: 0.0573\n",
      "Epoch [15/50], Step [544/735], Loss: 0.0373\n",
      "Epoch [15/50], Step [545/735], Loss: 0.0431\n",
      "Epoch [15/50], Step [546/735], Loss: 0.0463\n",
      "Epoch [15/50], Step [547/735], Loss: 0.0521\n",
      "Epoch [15/50], Step [548/735], Loss: 0.2047\n",
      "Epoch [15/50], Step [549/735], Loss: 0.0264\n",
      "Epoch [15/50], Step [550/735], Loss: 0.0409\n",
      "Epoch [15/50], Step [551/735], Loss: 0.1898\n",
      "Epoch [15/50], Step [552/735], Loss: 0.0674\n",
      "Epoch [15/50], Step [553/735], Loss: 0.0470\n",
      "Epoch [15/50], Step [554/735], Loss: 0.0864\n",
      "Epoch [15/50], Step [555/735], Loss: 0.1745\n",
      "Epoch [15/50], Step [556/735], Loss: 0.1054\n",
      "Epoch [15/50], Step [557/735], Loss: 0.0683\n",
      "Epoch [15/50], Step [558/735], Loss: 0.0592\n",
      "Epoch [15/50], Step [559/735], Loss: 0.0312\n",
      "Epoch [15/50], Step [560/735], Loss: 0.0536\n",
      "Epoch [15/50], Step [561/735], Loss: 0.0495\n",
      "Epoch [15/50], Step [562/735], Loss: 0.0212\n",
      "Epoch [15/50], Step [563/735], Loss: 0.0827\n",
      "Epoch [15/50], Step [564/735], Loss: 0.1180\n",
      "Epoch [15/50], Step [565/735], Loss: 0.1816\n",
      "Epoch [15/50], Step [566/735], Loss: 0.0404\n",
      "Epoch [15/50], Step [567/735], Loss: 0.0839\n",
      "Epoch [15/50], Step [568/735], Loss: 0.0514\n",
      "Epoch [15/50], Step [569/735], Loss: 0.1450\n",
      "Epoch [15/50], Step [570/735], Loss: 0.1182\n",
      "Epoch [15/50], Step [571/735], Loss: 0.0609\n",
      "Epoch [15/50], Step [572/735], Loss: 0.0782\n",
      "Epoch [15/50], Step [573/735], Loss: 0.0909\n",
      "Epoch [15/50], Step [574/735], Loss: 0.0445\n",
      "Epoch [15/50], Step [575/735], Loss: 0.1020\n",
      "Epoch [15/50], Step [576/735], Loss: 0.1167\n",
      "Epoch [15/50], Step [577/735], Loss: 0.1021\n",
      "Epoch [15/50], Step [578/735], Loss: 0.1741\n",
      "Epoch [15/50], Step [579/735], Loss: 0.2434\n",
      "Epoch [15/50], Step [580/735], Loss: 0.0405\n",
      "Epoch [15/50], Step [581/735], Loss: 0.0469\n",
      "Epoch [15/50], Step [582/735], Loss: 0.3518\n",
      "Epoch [15/50], Step [583/735], Loss: 0.1062\n",
      "Epoch [15/50], Step [584/735], Loss: 0.0324\n",
      "Epoch [15/50], Step [585/735], Loss: 0.1899\n",
      "Epoch [15/50], Step [586/735], Loss: 0.0509\n",
      "Epoch [15/50], Step [587/735], Loss: 0.0664\n",
      "Epoch [15/50], Step [588/735], Loss: 0.1422\n",
      "Epoch [15/50], Step [589/735], Loss: 0.1671\n",
      "Epoch [15/50], Step [590/735], Loss: 0.0689\n",
      "Epoch [15/50], Step [591/735], Loss: 0.0504\n",
      "Epoch [15/50], Step [592/735], Loss: 0.0441\n",
      "Epoch [15/50], Step [593/735], Loss: 0.1310\n",
      "Epoch [15/50], Step [594/735], Loss: 0.1002\n",
      "Epoch [15/50], Step [595/735], Loss: 0.0810\n",
      "Epoch [15/50], Step [596/735], Loss: 0.0517\n",
      "Epoch [15/50], Step [597/735], Loss: 0.0373\n",
      "Epoch [15/50], Step [598/735], Loss: 0.0702\n",
      "Epoch [15/50], Step [599/735], Loss: 0.1411\n",
      "Epoch [15/50], Step [600/735], Loss: 0.0302\n",
      "Epoch [15/50], Step [601/735], Loss: 0.4803\n",
      "Epoch [15/50], Step [602/735], Loss: 0.2705\n",
      "Epoch [15/50], Step [603/735], Loss: 0.0322\n",
      "Epoch [15/50], Step [604/735], Loss: 0.0568\n",
      "Epoch [15/50], Step [605/735], Loss: 0.0399\n",
      "Epoch [15/50], Step [606/735], Loss: 0.0399\n",
      "Epoch [15/50], Step [607/735], Loss: 0.0362\n",
      "Epoch [15/50], Step [608/735], Loss: 0.0613\n",
      "Epoch [15/50], Step [609/735], Loss: 0.0852\n",
      "Epoch [15/50], Step [610/735], Loss: 0.0607\n",
      "Epoch [15/50], Step [611/735], Loss: 0.1100\n",
      "Epoch [15/50], Step [612/735], Loss: 0.0823\n",
      "Epoch [15/50], Step [613/735], Loss: 0.0566\n",
      "Epoch [15/50], Step [614/735], Loss: 0.1114\n",
      "Epoch [15/50], Step [615/735], Loss: 0.0748\n",
      "Epoch [15/50], Step [616/735], Loss: 0.0422\n",
      "Epoch [15/50], Step [617/735], Loss: 0.0533\n",
      "Epoch [15/50], Step [618/735], Loss: 0.0422\n",
      "Epoch [15/50], Step [619/735], Loss: 0.0409\n",
      "Epoch [15/50], Step [620/735], Loss: 0.1508\n",
      "Epoch [15/50], Step [621/735], Loss: 0.0442\n",
      "Epoch [15/50], Step [622/735], Loss: 0.0613\n",
      "Epoch [15/50], Step [623/735], Loss: 0.1164\n",
      "Epoch [15/50], Step [624/735], Loss: 0.2204\n",
      "Epoch [15/50], Step [625/735], Loss: 0.0457\n",
      "Epoch [15/50], Step [626/735], Loss: 0.0557\n",
      "Epoch [15/50], Step [627/735], Loss: 0.0346\n",
      "Epoch [15/50], Step [628/735], Loss: 0.0827\n",
      "Epoch [15/50], Step [629/735], Loss: 0.1010\n",
      "Epoch [15/50], Step [630/735], Loss: 0.0358\n",
      "Epoch [15/50], Step [631/735], Loss: 0.2321\n",
      "Epoch [15/50], Step [632/735], Loss: 0.0508\n",
      "Epoch [15/50], Step [633/735], Loss: 0.0564\n",
      "Epoch [15/50], Step [634/735], Loss: 0.0472\n",
      "Epoch [15/50], Step [635/735], Loss: 0.1360\n",
      "Epoch [15/50], Step [636/735], Loss: 0.0523\n",
      "Epoch [15/50], Step [637/735], Loss: 0.0810\n",
      "Epoch [15/50], Step [638/735], Loss: 0.0406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Step [639/735], Loss: 0.4415\n",
      "Epoch [15/50], Step [640/735], Loss: 0.0563\n",
      "Epoch [15/50], Step [641/735], Loss: 0.0423\n",
      "Epoch [15/50], Step [642/735], Loss: 0.1308\n",
      "Epoch [15/50], Step [643/735], Loss: 0.0773\n",
      "Epoch [15/50], Step [644/735], Loss: 0.3188\n",
      "Epoch [15/50], Step [645/735], Loss: 0.0889\n",
      "Epoch [15/50], Step [646/735], Loss: 0.5343\n",
      "Epoch [15/50], Step [647/735], Loss: 0.2841\n",
      "Epoch [15/50], Step [648/735], Loss: 0.0743\n",
      "Epoch [15/50], Step [649/735], Loss: 0.0388\n",
      "Epoch [15/50], Step [650/735], Loss: 0.0928\n",
      "Epoch [15/50], Step [651/735], Loss: 0.0514\n",
      "Epoch [15/50], Step [652/735], Loss: 0.1028\n",
      "Epoch [15/50], Step [653/735], Loss: 0.1442\n",
      "Epoch [15/50], Step [654/735], Loss: 0.0681\n",
      "Epoch [15/50], Step [655/735], Loss: 0.0618\n",
      "Epoch [15/50], Step [656/735], Loss: 0.1277\n",
      "Epoch [15/50], Step [657/735], Loss: 0.0729\n",
      "Epoch [15/50], Step [658/735], Loss: 0.2333\n",
      "Epoch [15/50], Step [659/735], Loss: 0.1305\n",
      "Epoch [15/50], Step [660/735], Loss: 0.1355\n",
      "Epoch [15/50], Step [661/735], Loss: 0.0972\n",
      "Epoch [15/50], Step [662/735], Loss: 0.0925\n",
      "Epoch [15/50], Step [663/735], Loss: 0.0760\n",
      "Epoch [15/50], Step [664/735], Loss: 0.0621\n",
      "Epoch [15/50], Step [665/735], Loss: 0.2587\n",
      "Epoch [15/50], Step [666/735], Loss: 0.1234\n",
      "Epoch [15/50], Step [667/735], Loss: 0.1531\n",
      "Epoch [15/50], Step [668/735], Loss: 0.0714\n",
      "Epoch [15/50], Step [669/735], Loss: 0.0312\n",
      "Epoch [15/50], Step [670/735], Loss: 0.0393\n",
      "Epoch [15/50], Step [671/735], Loss: 0.0987\n",
      "Epoch [15/50], Step [672/735], Loss: 0.1136\n",
      "Epoch [15/50], Step [673/735], Loss: 0.0918\n",
      "Epoch [15/50], Step [674/735], Loss: 0.0527\n",
      "Epoch [15/50], Step [675/735], Loss: 0.1886\n",
      "Epoch [15/50], Step [676/735], Loss: 0.0523\n",
      "Epoch [15/50], Step [677/735], Loss: 0.0536\n",
      "Epoch [15/50], Step [678/735], Loss: 0.0957\n",
      "Epoch [15/50], Step [679/735], Loss: 0.0618\n",
      "Epoch [15/50], Step [680/735], Loss: 0.0425\n",
      "Epoch [15/50], Step [681/735], Loss: 0.0932\n",
      "Epoch [15/50], Step [682/735], Loss: 0.0460\n",
      "Epoch [15/50], Step [683/735], Loss: 0.0567\n",
      "Epoch [15/50], Step [684/735], Loss: 0.2345\n",
      "Epoch [15/50], Step [685/735], Loss: 0.1025\n",
      "Epoch [15/50], Step [686/735], Loss: 0.1113\n",
      "Epoch [15/50], Step [687/735], Loss: 0.1050\n",
      "Epoch [15/50], Step [688/735], Loss: 0.1747\n",
      "Epoch [15/50], Step [689/735], Loss: 0.0454\n",
      "Epoch [15/50], Step [690/735], Loss: 0.0763\n",
      "Epoch [15/50], Step [691/735], Loss: 0.0426\n",
      "Epoch [15/50], Step [692/735], Loss: 0.1045\n",
      "Epoch [15/50], Step [693/735], Loss: 0.1429\n",
      "Epoch [15/50], Step [694/735], Loss: 0.0533\n",
      "Epoch [15/50], Step [695/735], Loss: 0.0812\n",
      "Epoch [15/50], Step [696/735], Loss: 0.1366\n",
      "Epoch [15/50], Step [697/735], Loss: 0.1233\n",
      "Epoch [15/50], Step [698/735], Loss: 0.1722\n",
      "Epoch [15/50], Step [699/735], Loss: 0.1070\n",
      "Epoch [15/50], Step [700/735], Loss: 0.0610\n",
      "Epoch [15/50], Step [701/735], Loss: 0.1402\n",
      "Epoch [15/50], Step [702/735], Loss: 0.0360\n",
      "Epoch [15/50], Step [703/735], Loss: 0.0984\n",
      "Epoch [15/50], Step [704/735], Loss: 0.0815\n",
      "Epoch [15/50], Step [705/735], Loss: 0.0455\n",
      "Epoch [15/50], Step [706/735], Loss: 0.0573\n",
      "Epoch [15/50], Step [707/735], Loss: 0.0316\n",
      "Epoch [15/50], Step [708/735], Loss: 0.0663\n",
      "Epoch [15/50], Step [709/735], Loss: 0.1341\n",
      "Epoch [15/50], Step [710/735], Loss: 0.0800\n",
      "Epoch [15/50], Step [711/735], Loss: 0.1001\n",
      "Epoch [15/50], Step [712/735], Loss: 0.0237\n",
      "Epoch [15/50], Step [713/735], Loss: 0.0496\n",
      "Epoch [15/50], Step [714/735], Loss: 0.1636\n",
      "Epoch [15/50], Step [715/735], Loss: 0.0619\n",
      "Epoch [15/50], Step [716/735], Loss: 0.0691\n",
      "Epoch [15/50], Step [717/735], Loss: 0.0913\n",
      "Epoch [15/50], Step [718/735], Loss: 0.1236\n",
      "Epoch [15/50], Step [719/735], Loss: 0.1316\n",
      "Epoch [15/50], Step [720/735], Loss: 0.1151\n",
      "Epoch [15/50], Step [721/735], Loss: 0.0475\n",
      "Epoch [15/50], Step [722/735], Loss: 0.0805\n",
      "Epoch [15/50], Step [723/735], Loss: 0.0520\n",
      "Epoch [15/50], Step [724/735], Loss: 0.0818\n",
      "Epoch [15/50], Step [725/735], Loss: 0.0375\n",
      "Epoch [15/50], Step [726/735], Loss: 0.0709\n",
      "Epoch [15/50], Step [727/735], Loss: 0.0542\n",
      "Epoch [15/50], Step [728/735], Loss: 0.0169\n",
      "Epoch [15/50], Step [729/735], Loss: 0.0413\n",
      "Epoch [15/50], Step [730/735], Loss: 0.0681\n",
      "Epoch [15/50], Step [731/735], Loss: 0.0365\n",
      "Epoch [15/50], Step [732/735], Loss: 0.1342\n",
      "Epoch [15/50], Step [733/735], Loss: 0.1083\n",
      "Epoch [15/50], Step [734/735], Loss: 0.0957\n",
      "Epoch [15/50], Step [735/735], Loss: 0.0875\n",
      "Epoch [16/50], Step [1/735], Loss: 0.0490\n",
      "Epoch [16/50], Step [2/735], Loss: 0.0719\n",
      "Epoch [16/50], Step [3/735], Loss: 0.0426\n",
      "Epoch [16/50], Step [4/735], Loss: 0.0499\n",
      "Epoch [16/50], Step [5/735], Loss: 0.1094\n",
      "Epoch [16/50], Step [6/735], Loss: 0.0438\n",
      "Epoch [16/50], Step [7/735], Loss: 0.0526\n",
      "Epoch [16/50], Step [8/735], Loss: 0.0774\n",
      "Epoch [16/50], Step [9/735], Loss: 0.0925\n",
      "Epoch [16/50], Step [10/735], Loss: 0.0355\n",
      "Epoch [16/50], Step [11/735], Loss: 0.0675\n",
      "Epoch [16/50], Step [12/735], Loss: 0.1134\n",
      "Epoch [16/50], Step [13/735], Loss: 0.0424\n",
      "Epoch [16/50], Step [14/735], Loss: 0.3155\n",
      "Epoch [16/50], Step [15/735], Loss: 0.1473\n",
      "Epoch [16/50], Step [16/735], Loss: 0.0842\n",
      "Epoch [16/50], Step [17/735], Loss: 0.0816\n",
      "Epoch [16/50], Step [18/735], Loss: 0.0552\n",
      "Epoch [16/50], Step [19/735], Loss: 0.2203\n",
      "Epoch [16/50], Step [20/735], Loss: 0.1025\n",
      "Epoch [16/50], Step [21/735], Loss: 0.0434\n",
      "Epoch [16/50], Step [22/735], Loss: 0.1004\n",
      "Epoch [16/50], Step [23/735], Loss: 0.0516\n",
      "Epoch [16/50], Step [24/735], Loss: 0.1007\n",
      "Epoch [16/50], Step [25/735], Loss: 0.3143\n",
      "Epoch [16/50], Step [26/735], Loss: 0.0585\n",
      "Epoch [16/50], Step [27/735], Loss: 0.1146\n",
      "Epoch [16/50], Step [28/735], Loss: 0.1466\n",
      "Epoch [16/50], Step [29/735], Loss: 0.0670\n",
      "Epoch [16/50], Step [30/735], Loss: 0.0242\n",
      "Epoch [16/50], Step [31/735], Loss: 0.0435\n",
      "Epoch [16/50], Step [32/735], Loss: 0.0276\n",
      "Epoch [16/50], Step [33/735], Loss: 0.0382\n",
      "Epoch [16/50], Step [34/735], Loss: 0.1217\n",
      "Epoch [16/50], Step [35/735], Loss: 0.0757\n",
      "Epoch [16/50], Step [36/735], Loss: 0.1195\n",
      "Epoch [16/50], Step [37/735], Loss: 0.0538\n",
      "Epoch [16/50], Step [38/735], Loss: 0.0422\n",
      "Epoch [16/50], Step [39/735], Loss: 0.1003\n",
      "Epoch [16/50], Step [40/735], Loss: 0.0822\n",
      "Epoch [16/50], Step [41/735], Loss: 0.1471\n",
      "Epoch [16/50], Step [42/735], Loss: 0.0600\n",
      "Epoch [16/50], Step [43/735], Loss: 0.0631\n",
      "Epoch [16/50], Step [44/735], Loss: 0.2371\n",
      "Epoch [16/50], Step [45/735], Loss: 0.1072\n",
      "Epoch [16/50], Step [46/735], Loss: 0.1047\n",
      "Epoch [16/50], Step [47/735], Loss: 0.0603\n",
      "Epoch [16/50], Step [48/735], Loss: 0.6074\n",
      "Epoch [16/50], Step [49/735], Loss: 0.2143\n",
      "Epoch [16/50], Step [50/735], Loss: 0.0747\n",
      "Epoch [16/50], Step [51/735], Loss: 0.0599\n",
      "Epoch [16/50], Step [52/735], Loss: 0.0499\n",
      "Epoch [16/50], Step [53/735], Loss: 0.0899\n",
      "Epoch [16/50], Step [54/735], Loss: 0.1028\n",
      "Epoch [16/50], Step [55/735], Loss: 0.1426\n",
      "Epoch [16/50], Step [56/735], Loss: 0.0619\n",
      "Epoch [16/50], Step [57/735], Loss: 0.0937\n",
      "Epoch [16/50], Step [58/735], Loss: 0.0930\n",
      "Epoch [16/50], Step [59/735], Loss: 0.1101\n",
      "Epoch [16/50], Step [60/735], Loss: 0.1328\n",
      "Epoch [16/50], Step [61/735], Loss: 0.0553\n",
      "Epoch [16/50], Step [62/735], Loss: 0.2233\n",
      "Epoch [16/50], Step [63/735], Loss: 0.1309\n",
      "Epoch [16/50], Step [64/735], Loss: 0.0508\n",
      "Epoch [16/50], Step [65/735], Loss: 0.0772\n",
      "Epoch [16/50], Step [66/735], Loss: 0.0574\n",
      "Epoch [16/50], Step [67/735], Loss: 0.0938\n",
      "Epoch [16/50], Step [68/735], Loss: 0.1233\n",
      "Epoch [16/50], Step [69/735], Loss: 0.0867\n",
      "Epoch [16/50], Step [70/735], Loss: 0.0731\n",
      "Epoch [16/50], Step [71/735], Loss: 0.0525\n",
      "Epoch [16/50], Step [72/735], Loss: 0.1173\n",
      "Epoch [16/50], Step [73/735], Loss: 0.2408\n",
      "Epoch [16/50], Step [74/735], Loss: 0.0482\n",
      "Epoch [16/50], Step [75/735], Loss: 0.0345\n",
      "Epoch [16/50], Step [76/735], Loss: 0.0210\n",
      "Epoch [16/50], Step [77/735], Loss: 0.2374\n",
      "Epoch [16/50], Step [78/735], Loss: 0.0427\n",
      "Epoch [16/50], Step [79/735], Loss: 0.0682\n",
      "Epoch [16/50], Step [80/735], Loss: 0.0807\n",
      "Epoch [16/50], Step [81/735], Loss: 0.1070\n",
      "Epoch [16/50], Step [82/735], Loss: 0.0584\n",
      "Epoch [16/50], Step [83/735], Loss: 0.0464\n",
      "Epoch [16/50], Step [84/735], Loss: 0.1222\n",
      "Epoch [16/50], Step [85/735], Loss: 0.0617\n",
      "Epoch [16/50], Step [86/735], Loss: 0.0801\n",
      "Epoch [16/50], Step [87/735], Loss: 0.0210\n",
      "Epoch [16/50], Step [88/735], Loss: 0.2430\n",
      "Epoch [16/50], Step [89/735], Loss: 0.1496\n",
      "Epoch [16/50], Step [90/735], Loss: 0.0478\n",
      "Epoch [16/50], Step [91/735], Loss: 0.1071\n",
      "Epoch [16/50], Step [92/735], Loss: 0.0577\n",
      "Epoch [16/50], Step [93/735], Loss: 0.0345\n",
      "Epoch [16/50], Step [94/735], Loss: 0.0312\n",
      "Epoch [16/50], Step [95/735], Loss: 0.1204\n",
      "Epoch [16/50], Step [96/735], Loss: 0.0657\n",
      "Epoch [16/50], Step [97/735], Loss: 0.0333\n",
      "Epoch [16/50], Step [98/735], Loss: 0.1754\n",
      "Epoch [16/50], Step [99/735], Loss: 0.0505\n",
      "Epoch [16/50], Step [100/735], Loss: 0.0738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Step [101/735], Loss: 0.0719\n",
      "Epoch [16/50], Step [102/735], Loss: 0.0495\n",
      "Epoch [16/50], Step [103/735], Loss: 0.0733\n",
      "Epoch [16/50], Step [104/735], Loss: 0.1621\n",
      "Epoch [16/50], Step [105/735], Loss: 0.0298\n",
      "Epoch [16/50], Step [106/735], Loss: 0.0522\n",
      "Epoch [16/50], Step [107/735], Loss: 0.1177\n",
      "Epoch [16/50], Step [108/735], Loss: 0.0612\n",
      "Epoch [16/50], Step [109/735], Loss: 0.0748\n",
      "Epoch [16/50], Step [110/735], Loss: 0.0917\n",
      "Epoch [16/50], Step [111/735], Loss: 0.0582\n",
      "Epoch [16/50], Step [112/735], Loss: 0.0658\n",
      "Epoch [16/50], Step [113/735], Loss: 0.0533\n",
      "Epoch [16/50], Step [114/735], Loss: 0.0668\n",
      "Epoch [16/50], Step [115/735], Loss: 0.0918\n",
      "Epoch [16/50], Step [116/735], Loss: 0.2173\n",
      "Epoch [16/50], Step [117/735], Loss: 0.0512\n",
      "Epoch [16/50], Step [118/735], Loss: 0.1183\n",
      "Epoch [16/50], Step [119/735], Loss: 0.0695\n",
      "Epoch [16/50], Step [120/735], Loss: 0.0902\n",
      "Epoch [16/50], Step [121/735], Loss: 0.1018\n",
      "Epoch [16/50], Step [122/735], Loss: 0.2024\n",
      "Epoch [16/50], Step [123/735], Loss: 0.0674\n",
      "Epoch [16/50], Step [124/735], Loss: 0.0855\n",
      "Epoch [16/50], Step [125/735], Loss: 0.0295\n",
      "Epoch [16/50], Step [126/735], Loss: 0.0295\n",
      "Epoch [16/50], Step [127/735], Loss: 0.0273\n",
      "Epoch [16/50], Step [128/735], Loss: 0.0451\n",
      "Epoch [16/50], Step [129/735], Loss: 0.1886\n",
      "Epoch [16/50], Step [130/735], Loss: 0.0440\n",
      "Epoch [16/50], Step [131/735], Loss: 0.1438\n",
      "Epoch [16/50], Step [132/735], Loss: 0.2629\n",
      "Epoch [16/50], Step [133/735], Loss: 0.0967\n",
      "Epoch [16/50], Step [134/735], Loss: 0.0730\n",
      "Epoch [16/50], Step [135/735], Loss: 0.0716\n",
      "Epoch [16/50], Step [136/735], Loss: 0.0735\n",
      "Epoch [16/50], Step [137/735], Loss: 0.0545\n",
      "Epoch [16/50], Step [138/735], Loss: 0.0663\n",
      "Epoch [16/50], Step [139/735], Loss: 0.0377\n",
      "Epoch [16/50], Step [140/735], Loss: 0.1497\n",
      "Epoch [16/50], Step [141/735], Loss: 0.0939\n",
      "Epoch [16/50], Step [142/735], Loss: 0.2552\n",
      "Epoch [16/50], Step [143/735], Loss: 0.0690\n",
      "Epoch [16/50], Step [144/735], Loss: 0.5670\n",
      "Epoch [16/50], Step [145/735], Loss: 0.0891\n",
      "Epoch [16/50], Step [146/735], Loss: 0.0467\n",
      "Epoch [16/50], Step [147/735], Loss: 0.0528\n",
      "Epoch [16/50], Step [148/735], Loss: 0.0427\n",
      "Epoch [16/50], Step [149/735], Loss: 0.1782\n",
      "Epoch [16/50], Step [150/735], Loss: 0.0462\n",
      "Epoch [16/50], Step [151/735], Loss: 0.0254\n",
      "Epoch [16/50], Step [152/735], Loss: 0.1910\n",
      "Epoch [16/50], Step [153/735], Loss: 0.0590\n",
      "Epoch [16/50], Step [154/735], Loss: 0.0823\n",
      "Epoch [16/50], Step [155/735], Loss: 0.0474\n",
      "Epoch [16/50], Step [156/735], Loss: 0.0669\n",
      "Epoch [16/50], Step [157/735], Loss: 0.0822\n",
      "Epoch [16/50], Step [158/735], Loss: 0.0562\n",
      "Epoch [16/50], Step [159/735], Loss: 0.0383\n",
      "Epoch [16/50], Step [160/735], Loss: 0.0274\n",
      "Epoch [16/50], Step [161/735], Loss: 0.0159\n",
      "Epoch [16/50], Step [162/735], Loss: 0.0645\n",
      "Epoch [16/50], Step [163/735], Loss: 0.0450\n",
      "Epoch [16/50], Step [164/735], Loss: 0.2014\n",
      "Epoch [16/50], Step [165/735], Loss: 0.0398\n",
      "Epoch [16/50], Step [166/735], Loss: 0.1268\n",
      "Epoch [16/50], Step [167/735], Loss: 0.2859\n",
      "Epoch [16/50], Step [168/735], Loss: 0.0268\n",
      "Epoch [16/50], Step [169/735], Loss: 0.0810\n",
      "Epoch [16/50], Step [170/735], Loss: 0.1194\n",
      "Epoch [16/50], Step [171/735], Loss: 0.3712\n",
      "Epoch [16/50], Step [172/735], Loss: 0.1376\n",
      "Epoch [16/50], Step [173/735], Loss: 0.0450\n",
      "Epoch [16/50], Step [174/735], Loss: 0.0526\n",
      "Epoch [16/50], Step [175/735], Loss: 0.1048\n",
      "Epoch [16/50], Step [176/735], Loss: 0.0401\n",
      "Epoch [16/50], Step [177/735], Loss: 0.0486\n",
      "Epoch [16/50], Step [178/735], Loss: 0.0598\n",
      "Epoch [16/50], Step [179/735], Loss: 0.0678\n",
      "Epoch [16/50], Step [180/735], Loss: 0.1053\n",
      "Epoch [16/50], Step [181/735], Loss: 0.0584\n",
      "Epoch [16/50], Step [182/735], Loss: 0.0256\n",
      "Epoch [16/50], Step [183/735], Loss: 0.0224\n",
      "Epoch [16/50], Step [184/735], Loss: 0.0405\n",
      "Epoch [16/50], Step [185/735], Loss: 0.0559\n",
      "Epoch [16/50], Step [186/735], Loss: 0.0286\n",
      "Epoch [16/50], Step [187/735], Loss: 0.4386\n",
      "Epoch [16/50], Step [188/735], Loss: 0.1778\n",
      "Epoch [16/50], Step [189/735], Loss: 0.0682\n",
      "Epoch [16/50], Step [190/735], Loss: 0.0925\n",
      "Epoch [16/50], Step [191/735], Loss: 0.0461\n",
      "Epoch [16/50], Step [192/735], Loss: 0.1092\n",
      "Epoch [16/50], Step [193/735], Loss: 0.0556\n",
      "Epoch [16/50], Step [194/735], Loss: 0.0675\n",
      "Epoch [16/50], Step [195/735], Loss: 0.1251\n",
      "Epoch [16/50], Step [196/735], Loss: 0.0602\n",
      "Epoch [16/50], Step [197/735], Loss: 0.0334\n",
      "Epoch [16/50], Step [198/735], Loss: 0.0978\n",
      "Epoch [16/50], Step [199/735], Loss: 0.0425\n",
      "Epoch [16/50], Step [200/735], Loss: 0.5658\n",
      "Epoch [16/50], Step [201/735], Loss: 0.0747\n",
      "Epoch [16/50], Step [202/735], Loss: 0.1240\n",
      "Epoch [16/50], Step [203/735], Loss: 0.0957\n",
      "Epoch [16/50], Step [204/735], Loss: 0.0797\n",
      "Epoch [16/50], Step [205/735], Loss: 0.0397\n",
      "Epoch [16/50], Step [206/735], Loss: 0.2388\n",
      "Epoch [16/50], Step [207/735], Loss: 0.0911\n",
      "Epoch [16/50], Step [208/735], Loss: 0.0270\n",
      "Epoch [16/50], Step [209/735], Loss: 0.0659\n",
      "Epoch [16/50], Step [210/735], Loss: 0.1566\n",
      "Epoch [16/50], Step [211/735], Loss: 0.2135\n",
      "Epoch [16/50], Step [212/735], Loss: 0.0483\n",
      "Epoch [16/50], Step [213/735], Loss: 0.2376\n",
      "Epoch [16/50], Step [214/735], Loss: 0.0547\n",
      "Epoch [16/50], Step [215/735], Loss: 0.1299\n",
      "Epoch [16/50], Step [216/735], Loss: 0.0458\n",
      "Epoch [16/50], Step [217/735], Loss: 0.0901\n",
      "Epoch [16/50], Step [218/735], Loss: 0.1529\n",
      "Epoch [16/50], Step [219/735], Loss: 0.0353\n",
      "Epoch [16/50], Step [220/735], Loss: 0.0886\n",
      "Epoch [16/50], Step [221/735], Loss: 0.0232\n",
      "Epoch [16/50], Step [222/735], Loss: 0.0433\n",
      "Epoch [16/50], Step [223/735], Loss: 0.0656\n",
      "Epoch [16/50], Step [224/735], Loss: 0.1050\n",
      "Epoch [16/50], Step [225/735], Loss: 0.1192\n",
      "Epoch [16/50], Step [226/735], Loss: 0.0695\n",
      "Epoch [16/50], Step [227/735], Loss: 0.0421\n",
      "Epoch [16/50], Step [228/735], Loss: 0.0175\n",
      "Epoch [16/50], Step [229/735], Loss: 0.0825\n",
      "Epoch [16/50], Step [230/735], Loss: 0.0595\n",
      "Epoch [16/50], Step [231/735], Loss: 0.0474\n",
      "Epoch [16/50], Step [232/735], Loss: 0.0826\n",
      "Epoch [16/50], Step [233/735], Loss: 0.0677\n",
      "Epoch [16/50], Step [234/735], Loss: 0.1232\n",
      "Epoch [16/50], Step [235/735], Loss: 0.0546\n",
      "Epoch [16/50], Step [236/735], Loss: 0.0891\n",
      "Epoch [16/50], Step [237/735], Loss: 0.0328\n",
      "Epoch [16/50], Step [238/735], Loss: 0.0345\n",
      "Epoch [16/50], Step [239/735], Loss: 0.0364\n",
      "Epoch [16/50], Step [240/735], Loss: 0.0777\n",
      "Epoch [16/50], Step [241/735], Loss: 0.0917\n",
      "Epoch [16/50], Step [242/735], Loss: 0.0629\n",
      "Epoch [16/50], Step [243/735], Loss: 0.0580\n",
      "Epoch [16/50], Step [244/735], Loss: 0.0871\n",
      "Epoch [16/50], Step [245/735], Loss: 0.1668\n",
      "Epoch [16/50], Step [246/735], Loss: 0.2053\n",
      "Epoch [16/50], Step [247/735], Loss: 0.3617\n",
      "Epoch [16/50], Step [248/735], Loss: 0.1635\n",
      "Epoch [16/50], Step [249/735], Loss: 0.0343\n",
      "Epoch [16/50], Step [250/735], Loss: 0.0942\n",
      "Epoch [16/50], Step [251/735], Loss: 0.0907\n",
      "Epoch [16/50], Step [252/735], Loss: 0.0700\n",
      "Epoch [16/50], Step [253/735], Loss: 0.0538\n",
      "Epoch [16/50], Step [254/735], Loss: 0.0804\n",
      "Epoch [16/50], Step [255/735], Loss: 0.0347\n",
      "Epoch [16/50], Step [256/735], Loss: 0.1087\n",
      "Epoch [16/50], Step [257/735], Loss: 0.1300\n",
      "Epoch [16/50], Step [258/735], Loss: 0.0368\n",
      "Epoch [16/50], Step [259/735], Loss: 0.2029\n",
      "Epoch [16/50], Step [260/735], Loss: 0.0657\n",
      "Epoch [16/50], Step [261/735], Loss: 0.1072\n",
      "Epoch [16/50], Step [262/735], Loss: 0.2078\n",
      "Epoch [16/50], Step [263/735], Loss: 0.0379\n",
      "Epoch [16/50], Step [264/735], Loss: 0.0555\n",
      "Epoch [16/50], Step [265/735], Loss: 0.1681\n",
      "Epoch [16/50], Step [266/735], Loss: 0.0806\n",
      "Epoch [16/50], Step [267/735], Loss: 0.0614\n",
      "Epoch [16/50], Step [268/735], Loss: 0.0216\n",
      "Epoch [16/50], Step [269/735], Loss: 0.0700\n",
      "Epoch [16/50], Step [270/735], Loss: 0.0469\n",
      "Epoch [16/50], Step [271/735], Loss: 0.0970\n",
      "Epoch [16/50], Step [272/735], Loss: 0.1166\n",
      "Epoch [16/50], Step [273/735], Loss: 0.0170\n",
      "Epoch [16/50], Step [274/735], Loss: 0.0885\n",
      "Epoch [16/50], Step [275/735], Loss: 0.0467\n",
      "Epoch [16/50], Step [276/735], Loss: 0.1512\n",
      "Epoch [16/50], Step [277/735], Loss: 0.0941\n",
      "Epoch [16/50], Step [278/735], Loss: 0.0943\n",
      "Epoch [16/50], Step [279/735], Loss: 0.0190\n",
      "Epoch [16/50], Step [280/735], Loss: 0.2944\n",
      "Epoch [16/50], Step [281/735], Loss: 0.0817\n",
      "Epoch [16/50], Step [282/735], Loss: 0.0571\n",
      "Epoch [16/50], Step [283/735], Loss: 0.0705\n",
      "Epoch [16/50], Step [284/735], Loss: 0.3772\n",
      "Epoch [16/50], Step [285/735], Loss: 0.0232\n",
      "Epoch [16/50], Step [286/735], Loss: 0.0501\n",
      "Epoch [16/50], Step [287/735], Loss: 0.0292\n",
      "Epoch [16/50], Step [288/735], Loss: 0.0979\n",
      "Epoch [16/50], Step [289/735], Loss: 0.0715\n",
      "Epoch [16/50], Step [290/735], Loss: 0.1006\n",
      "Epoch [16/50], Step [291/735], Loss: 0.0285\n",
      "Epoch [16/50], Step [292/735], Loss: 0.0527\n",
      "Epoch [16/50], Step [293/735], Loss: 0.4574\n",
      "Epoch [16/50], Step [294/735], Loss: 0.2456\n",
      "Epoch [16/50], Step [295/735], Loss: 0.0848\n",
      "Epoch [16/50], Step [296/735], Loss: 0.0666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Step [297/735], Loss: 0.0412\n",
      "Epoch [16/50], Step [298/735], Loss: 0.0644\n",
      "Epoch [16/50], Step [299/735], Loss: 0.2837\n",
      "Epoch [16/50], Step [300/735], Loss: 0.0514\n",
      "Epoch [16/50], Step [301/735], Loss: 0.0621\n",
      "Epoch [16/50], Step [302/735], Loss: 0.0611\n",
      "Epoch [16/50], Step [303/735], Loss: 0.0368\n",
      "Epoch [16/50], Step [304/735], Loss: 0.1133\n",
      "Epoch [16/50], Step [305/735], Loss: 0.0468\n",
      "Epoch [16/50], Step [306/735], Loss: 0.1129\n",
      "Epoch [16/50], Step [307/735], Loss: 0.0737\n",
      "Epoch [16/50], Step [308/735], Loss: 0.1125\n",
      "Epoch [16/50], Step [309/735], Loss: 0.1018\n",
      "Epoch [16/50], Step [310/735], Loss: 0.1064\n",
      "Epoch [16/50], Step [311/735], Loss: 0.0586\n",
      "Epoch [16/50], Step [312/735], Loss: 0.1643\n",
      "Epoch [16/50], Step [313/735], Loss: 0.2512\n",
      "Epoch [16/50], Step [314/735], Loss: 0.1387\n",
      "Epoch [16/50], Step [315/735], Loss: 0.0641\n",
      "Epoch [16/50], Step [316/735], Loss: 0.1154\n",
      "Epoch [16/50], Step [317/735], Loss: 0.0443\n",
      "Epoch [16/50], Step [318/735], Loss: 0.1223\n",
      "Epoch [16/50], Step [319/735], Loss: 0.0894\n",
      "Epoch [16/50], Step [320/735], Loss: 0.0835\n",
      "Epoch [16/50], Step [321/735], Loss: 0.0777\n",
      "Epoch [16/50], Step [322/735], Loss: 0.0538\n",
      "Epoch [16/50], Step [323/735], Loss: 0.0959\n",
      "Epoch [16/50], Step [324/735], Loss: 0.0733\n",
      "Epoch [16/50], Step [325/735], Loss: 0.0780\n",
      "Epoch [16/50], Step [326/735], Loss: 0.2120\n",
      "Epoch [16/50], Step [327/735], Loss: 0.0883\n",
      "Epoch [16/50], Step [328/735], Loss: 0.3722\n",
      "Epoch [16/50], Step [329/735], Loss: 0.0558\n",
      "Epoch [16/50], Step [330/735], Loss: 0.0414\n",
      "Epoch [16/50], Step [331/735], Loss: 0.4732\n",
      "Epoch [16/50], Step [332/735], Loss: 0.1729\n",
      "Epoch [16/50], Step [333/735], Loss: 0.1386\n",
      "Epoch [16/50], Step [334/735], Loss: 0.0919\n",
      "Epoch [16/50], Step [335/735], Loss: 0.1326\n",
      "Epoch [16/50], Step [336/735], Loss: 0.0746\n",
      "Epoch [16/50], Step [337/735], Loss: 0.2121\n",
      "Epoch [16/50], Step [338/735], Loss: 0.0729\n",
      "Epoch [16/50], Step [339/735], Loss: 0.1407\n",
      "Epoch [16/50], Step [340/735], Loss: 0.0623\n",
      "Epoch [16/50], Step [341/735], Loss: 0.1932\n",
      "Epoch [16/50], Step [342/735], Loss: 0.0517\n",
      "Epoch [16/50], Step [343/735], Loss: 0.0642\n",
      "Epoch [16/50], Step [344/735], Loss: 0.3782\n",
      "Epoch [16/50], Step [345/735], Loss: 0.0447\n",
      "Epoch [16/50], Step [346/735], Loss: 0.4406\n",
      "Epoch [16/50], Step [347/735], Loss: 0.2384\n",
      "Epoch [16/50], Step [348/735], Loss: 0.0341\n",
      "Epoch [16/50], Step [349/735], Loss: 0.0222\n",
      "Epoch [16/50], Step [350/735], Loss: 0.0917\n",
      "Epoch [16/50], Step [351/735], Loss: 0.0763\n",
      "Epoch [16/50], Step [352/735], Loss: 0.0874\n",
      "Epoch [16/50], Step [353/735], Loss: 0.0799\n",
      "Epoch [16/50], Step [354/735], Loss: 0.2087\n",
      "Epoch [16/50], Step [355/735], Loss: 0.1219\n",
      "Epoch [16/50], Step [356/735], Loss: 0.0375\n",
      "Epoch [16/50], Step [357/735], Loss: 0.0306\n",
      "Epoch [16/50], Step [358/735], Loss: 0.2063\n",
      "Epoch [16/50], Step [359/735], Loss: 0.1278\n",
      "Epoch [16/50], Step [360/735], Loss: 0.1779\n",
      "Epoch [16/50], Step [361/735], Loss: 0.2115\n",
      "Epoch [16/50], Step [362/735], Loss: 0.0580\n",
      "Epoch [16/50], Step [363/735], Loss: 0.0311\n",
      "Epoch [16/50], Step [364/735], Loss: 0.0388\n",
      "Epoch [16/50], Step [365/735], Loss: 0.1241\n",
      "Epoch [16/50], Step [366/735], Loss: 0.0845\n",
      "Epoch [16/50], Step [367/735], Loss: 0.0284\n",
      "Epoch [16/50], Step [368/735], Loss: 0.0592\n",
      "Epoch [16/50], Step [369/735], Loss: 0.0948\n",
      "Epoch [16/50], Step [370/735], Loss: 0.0479\n",
      "Epoch [16/50], Step [371/735], Loss: 0.0688\n",
      "Epoch [16/50], Step [372/735], Loss: 0.0420\n",
      "Epoch [16/50], Step [373/735], Loss: 0.1243\n",
      "Epoch [16/50], Step [374/735], Loss: 0.0635\n",
      "Epoch [16/50], Step [375/735], Loss: 0.0813\n",
      "Epoch [16/50], Step [376/735], Loss: 0.2289\n",
      "Epoch [16/50], Step [377/735], Loss: 0.0739\n",
      "Epoch [16/50], Step [378/735], Loss: 0.0930\n",
      "Epoch [16/50], Step [379/735], Loss: 0.0374\n",
      "Epoch [16/50], Step [380/735], Loss: 0.1380\n",
      "Epoch [16/50], Step [381/735], Loss: 0.0684\n",
      "Epoch [16/50], Step [382/735], Loss: 0.0233\n",
      "Epoch [16/50], Step [383/735], Loss: 0.1362\n",
      "Epoch [16/50], Step [384/735], Loss: 0.2343\n",
      "Epoch [16/50], Step [385/735], Loss: 0.0678\n",
      "Epoch [16/50], Step [386/735], Loss: 0.0572\n",
      "Epoch [16/50], Step [387/735], Loss: 0.1355\n",
      "Epoch [16/50], Step [388/735], Loss: 0.0635\n",
      "Epoch [16/50], Step [389/735], Loss: 0.0801\n",
      "Epoch [16/50], Step [390/735], Loss: 0.1802\n",
      "Epoch [16/50], Step [391/735], Loss: 0.1004\n",
      "Epoch [16/50], Step [392/735], Loss: 0.0341\n",
      "Epoch [16/50], Step [393/735], Loss: 0.0789\n",
      "Epoch [16/50], Step [394/735], Loss: 0.0543\n",
      "Epoch [16/50], Step [395/735], Loss: 0.0268\n",
      "Epoch [16/50], Step [396/735], Loss: 0.0964\n",
      "Epoch [16/50], Step [397/735], Loss: 0.1062\n",
      "Epoch [16/50], Step [398/735], Loss: 0.0596\n",
      "Epoch [16/50], Step [399/735], Loss: 0.0598\n",
      "Epoch [16/50], Step [400/735], Loss: 0.0304\n",
      "Epoch [16/50], Step [401/735], Loss: 0.0261\n",
      "Epoch [16/50], Step [402/735], Loss: 0.0492\n",
      "Epoch [16/50], Step [403/735], Loss: 0.0445\n",
      "Epoch [16/50], Step [404/735], Loss: 0.1075\n",
      "Epoch [16/50], Step [405/735], Loss: 0.1189\n",
      "Epoch [16/50], Step [406/735], Loss: 0.0518\n",
      "Epoch [16/50], Step [407/735], Loss: 0.1790\n",
      "Epoch [16/50], Step [408/735], Loss: 0.1724\n",
      "Epoch [16/50], Step [409/735], Loss: 0.1242\n",
      "Epoch [16/50], Step [410/735], Loss: 0.1140\n",
      "Epoch [16/50], Step [411/735], Loss: 0.0320\n",
      "Epoch [16/50], Step [412/735], Loss: 0.1471\n",
      "Epoch [16/50], Step [413/735], Loss: 0.0922\n",
      "Epoch [16/50], Step [414/735], Loss: 0.0381\n",
      "Epoch [16/50], Step [415/735], Loss: 0.0855\n",
      "Epoch [16/50], Step [416/735], Loss: 0.0381\n",
      "Epoch [16/50], Step [417/735], Loss: 0.0384\n",
      "Epoch [16/50], Step [418/735], Loss: 0.1332\n",
      "Epoch [16/50], Step [419/735], Loss: 0.0675\n",
      "Epoch [16/50], Step [420/735], Loss: 0.0857\n",
      "Epoch [16/50], Step [421/735], Loss: 0.0280\n",
      "Epoch [16/50], Step [422/735], Loss: 0.0464\n",
      "Epoch [16/50], Step [423/735], Loss: 0.1012\n",
      "Epoch [16/50], Step [424/735], Loss: 0.0566\n",
      "Epoch [16/50], Step [425/735], Loss: 0.1080\n",
      "Epoch [16/50], Step [426/735], Loss: 0.0639\n",
      "Epoch [16/50], Step [427/735], Loss: 0.0628\n",
      "Epoch [16/50], Step [428/735], Loss: 0.0600\n",
      "Epoch [16/50], Step [429/735], Loss: 0.0302\n",
      "Epoch [16/50], Step [430/735], Loss: 0.0332\n",
      "Epoch [16/50], Step [431/735], Loss: 0.0571\n",
      "Epoch [16/50], Step [432/735], Loss: 0.1479\n",
      "Epoch [16/50], Step [433/735], Loss: 0.5112\n",
      "Epoch [16/50], Step [434/735], Loss: 0.1312\n",
      "Epoch [16/50], Step [435/735], Loss: 0.0372\n",
      "Epoch [16/50], Step [436/735], Loss: 0.0669\n",
      "Epoch [16/50], Step [437/735], Loss: 0.1083\n",
      "Epoch [16/50], Step [438/735], Loss: 0.0537\n",
      "Epoch [16/50], Step [439/735], Loss: 0.1375\n",
      "Epoch [16/50], Step [440/735], Loss: 0.0468\n",
      "Epoch [16/50], Step [441/735], Loss: 0.0994\n",
      "Epoch [16/50], Step [442/735], Loss: 0.1076\n",
      "Epoch [16/50], Step [443/735], Loss: 0.1596\n",
      "Epoch [16/50], Step [444/735], Loss: 0.0490\n",
      "Epoch [16/50], Step [445/735], Loss: 0.0499\n",
      "Epoch [16/50], Step [446/735], Loss: 0.0543\n",
      "Epoch [16/50], Step [447/735], Loss: 0.1261\n",
      "Epoch [16/50], Step [448/735], Loss: 0.1043\n",
      "Epoch [16/50], Step [449/735], Loss: 0.0545\n",
      "Epoch [16/50], Step [450/735], Loss: 0.0312\n",
      "Epoch [16/50], Step [451/735], Loss: 0.0533\n",
      "Epoch [16/50], Step [452/735], Loss: 0.1373\n",
      "Epoch [16/50], Step [453/735], Loss: 0.0528\n",
      "Epoch [16/50], Step [454/735], Loss: 0.1799\n",
      "Epoch [16/50], Step [455/735], Loss: 0.0541\n",
      "Epoch [16/50], Step [456/735], Loss: 0.0576\n",
      "Epoch [16/50], Step [457/735], Loss: 0.1784\n",
      "Epoch [16/50], Step [458/735], Loss: 0.0700\n",
      "Epoch [16/50], Step [459/735], Loss: 0.1133\n",
      "Epoch [16/50], Step [460/735], Loss: 0.0390\n",
      "Epoch [16/50], Step [461/735], Loss: 0.1958\n",
      "Epoch [16/50], Step [462/735], Loss: 0.0390\n",
      "Epoch [16/50], Step [463/735], Loss: 0.0746\n",
      "Epoch [16/50], Step [464/735], Loss: 0.1362\n",
      "Epoch [16/50], Step [465/735], Loss: 0.4533\n",
      "Epoch [16/50], Step [466/735], Loss: 0.0493\n",
      "Epoch [16/50], Step [467/735], Loss: 0.0187\n",
      "Epoch [16/50], Step [468/735], Loss: 0.0912\n",
      "Epoch [16/50], Step [469/735], Loss: 0.0380\n",
      "Epoch [16/50], Step [470/735], Loss: 0.0271\n",
      "Epoch [16/50], Step [471/735], Loss: 0.0271\n",
      "Epoch [16/50], Step [472/735], Loss: 0.1554\n",
      "Epoch [16/50], Step [473/735], Loss: 0.0355\n",
      "Epoch [16/50], Step [474/735], Loss: 0.0823\n",
      "Epoch [16/50], Step [475/735], Loss: 0.0581\n",
      "Epoch [16/50], Step [476/735], Loss: 0.1955\n",
      "Epoch [16/50], Step [477/735], Loss: 0.0643\n",
      "Epoch [16/50], Step [478/735], Loss: 0.0958\n",
      "Epoch [16/50], Step [479/735], Loss: 0.0858\n",
      "Epoch [16/50], Step [480/735], Loss: 0.0332\n",
      "Epoch [16/50], Step [481/735], Loss: 0.0332\n",
      "Epoch [16/50], Step [482/735], Loss: 0.0175\n",
      "Epoch [16/50], Step [483/735], Loss: 0.1293\n",
      "Epoch [16/50], Step [484/735], Loss: 0.0256\n",
      "Epoch [16/50], Step [485/735], Loss: 0.0355\n",
      "Epoch [16/50], Step [486/735], Loss: 0.2651\n",
      "Epoch [16/50], Step [487/735], Loss: 0.0847\n",
      "Epoch [16/50], Step [488/735], Loss: 0.0235\n",
      "Epoch [16/50], Step [489/735], Loss: 0.2555\n",
      "Epoch [16/50], Step [490/735], Loss: 0.0917\n",
      "Epoch [16/50], Step [491/735], Loss: 0.0893\n",
      "Epoch [16/50], Step [492/735], Loss: 0.0319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Step [493/735], Loss: 0.1643\n",
      "Epoch [16/50], Step [494/735], Loss: 0.1460\n",
      "Epoch [16/50], Step [495/735], Loss: 0.0722\n",
      "Epoch [16/50], Step [496/735], Loss: 0.1189\n",
      "Epoch [16/50], Step [497/735], Loss: 0.0301\n",
      "Epoch [16/50], Step [498/735], Loss: 0.0224\n",
      "Epoch [16/50], Step [499/735], Loss: 0.0822\n",
      "Epoch [16/50], Step [500/735], Loss: 0.1664\n",
      "Epoch [16/50], Step [501/735], Loss: 0.2330\n",
      "Epoch [16/50], Step [502/735], Loss: 0.1487\n",
      "Epoch [16/50], Step [503/735], Loss: 0.0536\n",
      "Epoch [16/50], Step [504/735], Loss: 0.0866\n",
      "Epoch [16/50], Step [505/735], Loss: 0.0998\n",
      "Epoch [16/50], Step [506/735], Loss: 0.1354\n",
      "Epoch [16/50], Step [507/735], Loss: 0.0762\n",
      "Epoch [16/50], Step [508/735], Loss: 0.2346\n",
      "Epoch [16/50], Step [509/735], Loss: 0.0396\n",
      "Epoch [16/50], Step [510/735], Loss: 0.0167\n",
      "Epoch [16/50], Step [511/735], Loss: 0.1781\n",
      "Epoch [16/50], Step [512/735], Loss: 0.0547\n",
      "Epoch [16/50], Step [513/735], Loss: 0.0930\n",
      "Epoch [16/50], Step [514/735], Loss: 0.1773\n",
      "Epoch [16/50], Step [515/735], Loss: 0.4380\n",
      "Epoch [16/50], Step [516/735], Loss: 0.3116\n",
      "Epoch [16/50], Step [517/735], Loss: 0.0829\n",
      "Epoch [16/50], Step [518/735], Loss: 0.0592\n",
      "Epoch [16/50], Step [519/735], Loss: 0.0349\n",
      "Epoch [16/50], Step [520/735], Loss: 0.1673\n",
      "Epoch [16/50], Step [521/735], Loss: 0.1274\n",
      "Epoch [16/50], Step [522/735], Loss: 0.1651\n",
      "Epoch [16/50], Step [523/735], Loss: 0.0687\n",
      "Epoch [16/50], Step [524/735], Loss: 0.0266\n",
      "Epoch [16/50], Step [525/735], Loss: 0.0627\n",
      "Epoch [16/50], Step [526/735], Loss: 0.0964\n",
      "Epoch [16/50], Step [527/735], Loss: 0.0314\n",
      "Epoch [16/50], Step [528/735], Loss: 0.1016\n",
      "Epoch [16/50], Step [529/735], Loss: 0.1401\n",
      "Epoch [16/50], Step [530/735], Loss: 0.2992\n",
      "Epoch [16/50], Step [531/735], Loss: 0.1570\n",
      "Epoch [16/50], Step [532/735], Loss: 0.1681\n",
      "Epoch [16/50], Step [533/735], Loss: 0.0669\n",
      "Epoch [16/50], Step [534/735], Loss: 0.1687\n",
      "Epoch [16/50], Step [535/735], Loss: 0.0594\n",
      "Epoch [16/50], Step [536/735], Loss: 0.1239\n",
      "Epoch [16/50], Step [537/735], Loss: 0.0950\n",
      "Epoch [16/50], Step [538/735], Loss: 0.0395\n",
      "Epoch [16/50], Step [539/735], Loss: 0.1168\n",
      "Epoch [16/50], Step [540/735], Loss: 0.1058\n",
      "Epoch [16/50], Step [541/735], Loss: 0.1972\n",
      "Epoch [16/50], Step [542/735], Loss: 0.0715\n",
      "Epoch [16/50], Step [543/735], Loss: 0.0305\n",
      "Epoch [16/50], Step [544/735], Loss: 0.0894\n",
      "Epoch [16/50], Step [545/735], Loss: 0.0855\n",
      "Epoch [16/50], Step [546/735], Loss: 0.2746\n",
      "Epoch [16/50], Step [547/735], Loss: 0.0370\n",
      "Epoch [16/50], Step [548/735], Loss: 0.0597\n",
      "Epoch [16/50], Step [549/735], Loss: 0.0743\n",
      "Epoch [16/50], Step [550/735], Loss: 0.2305\n",
      "Epoch [16/50], Step [551/735], Loss: 0.1261\n",
      "Epoch [16/50], Step [552/735], Loss: 0.1013\n",
      "Epoch [16/50], Step [553/735], Loss: 0.2029\n",
      "Epoch [16/50], Step [554/735], Loss: 0.0975\n",
      "Epoch [16/50], Step [555/735], Loss: 0.0799\n",
      "Epoch [16/50], Step [556/735], Loss: 0.1091\n",
      "Epoch [16/50], Step [557/735], Loss: 0.4246\n",
      "Epoch [16/50], Step [558/735], Loss: 0.1525\n",
      "Epoch [16/50], Step [559/735], Loss: 0.0834\n",
      "Epoch [16/50], Step [560/735], Loss: 0.0525\n",
      "Epoch [16/50], Step [561/735], Loss: 0.1133\n",
      "Epoch [16/50], Step [562/735], Loss: 0.0850\n",
      "Epoch [16/50], Step [563/735], Loss: 0.0705\n",
      "Epoch [16/50], Step [564/735], Loss: 0.1071\n",
      "Epoch [16/50], Step [565/735], Loss: 0.0609\n",
      "Epoch [16/50], Step [566/735], Loss: 0.6178\n",
      "Epoch [16/50], Step [567/735], Loss: 0.0937\n",
      "Epoch [16/50], Step [568/735], Loss: 0.0982\n",
      "Epoch [16/50], Step [569/735], Loss: 0.0497\n",
      "Epoch [16/50], Step [570/735], Loss: 0.0765\n",
      "Epoch [16/50], Step [571/735], Loss: 0.0775\n",
      "Epoch [16/50], Step [572/735], Loss: 0.1015\n",
      "Epoch [16/50], Step [573/735], Loss: 0.1208\n",
      "Epoch [16/50], Step [574/735], Loss: 0.0679\n",
      "Epoch [16/50], Step [575/735], Loss: 0.0336\n",
      "Epoch [16/50], Step [576/735], Loss: 0.0287\n",
      "Epoch [16/50], Step [577/735], Loss: 0.2605\n",
      "Epoch [16/50], Step [578/735], Loss: 0.5279\n",
      "Epoch [16/50], Step [579/735], Loss: 0.2149\n",
      "Epoch [16/50], Step [580/735], Loss: 0.0932\n",
      "Epoch [16/50], Step [581/735], Loss: 0.1192\n",
      "Epoch [16/50], Step [582/735], Loss: 0.1104\n",
      "Epoch [16/50], Step [583/735], Loss: 0.1446\n",
      "Epoch [16/50], Step [584/735], Loss: 0.1835\n",
      "Epoch [16/50], Step [585/735], Loss: 0.0848\n",
      "Epoch [16/50], Step [586/735], Loss: 0.4570\n",
      "Epoch [16/50], Step [587/735], Loss: 0.0427\n",
      "Epoch [16/50], Step [588/735], Loss: 0.0630\n",
      "Epoch [16/50], Step [589/735], Loss: 0.0425\n",
      "Epoch [16/50], Step [590/735], Loss: 0.0891\n",
      "Epoch [16/50], Step [591/735], Loss: 0.0778\n",
      "Epoch [16/50], Step [592/735], Loss: 0.1226\n",
      "Epoch [16/50], Step [593/735], Loss: 0.0366\n",
      "Epoch [16/50], Step [594/735], Loss: 0.1225\n",
      "Epoch [16/50], Step [595/735], Loss: 0.1449\n",
      "Epoch [16/50], Step [596/735], Loss: 0.1286\n",
      "Epoch [16/50], Step [597/735], Loss: 0.0647\n",
      "Epoch [16/50], Step [598/735], Loss: 0.0775\n",
      "Epoch [16/50], Step [599/735], Loss: 0.0362\n",
      "Epoch [16/50], Step [600/735], Loss: 0.0516\n",
      "Epoch [16/50], Step [601/735], Loss: 0.1671\n",
      "Epoch [16/50], Step [602/735], Loss: 0.1214\n",
      "Epoch [16/50], Step [603/735], Loss: 0.1046\n",
      "Epoch [16/50], Step [604/735], Loss: 0.0303\n",
      "Epoch [16/50], Step [605/735], Loss: 0.0472\n",
      "Epoch [16/50], Step [606/735], Loss: 0.0457\n",
      "Epoch [16/50], Step [607/735], Loss: 0.0577\n",
      "Epoch [16/50], Step [608/735], Loss: 0.0335\n",
      "Epoch [16/50], Step [609/735], Loss: 0.0286\n",
      "Epoch [16/50], Step [610/735], Loss: 0.0720\n",
      "Epoch [16/50], Step [611/735], Loss: 0.0328\n",
      "Epoch [16/50], Step [612/735], Loss: 0.0401\n",
      "Epoch [16/50], Step [613/735], Loss: 0.2448\n",
      "Epoch [16/50], Step [614/735], Loss: 0.0586\n",
      "Epoch [16/50], Step [615/735], Loss: 0.1889\n",
      "Epoch [16/50], Step [616/735], Loss: 0.0595\n",
      "Epoch [16/50], Step [617/735], Loss: 0.0202\n",
      "Epoch [16/50], Step [618/735], Loss: 0.0436\n",
      "Epoch [16/50], Step [619/735], Loss: 0.0573\n",
      "Epoch [16/50], Step [620/735], Loss: 0.3519\n",
      "Epoch [16/50], Step [621/735], Loss: 0.0579\n",
      "Epoch [16/50], Step [622/735], Loss: 0.0491\n",
      "Epoch [16/50], Step [623/735], Loss: 0.0987\n",
      "Epoch [16/50], Step [624/735], Loss: 0.2160\n",
      "Epoch [16/50], Step [625/735], Loss: 0.0487\n",
      "Epoch [16/50], Step [626/735], Loss: 0.0376\n",
      "Epoch [16/50], Step [627/735], Loss: 0.1801\n",
      "Epoch [16/50], Step [628/735], Loss: 0.0553\n",
      "Epoch [16/50], Step [629/735], Loss: 0.1915\n",
      "Epoch [16/50], Step [630/735], Loss: 0.0986\n",
      "Epoch [16/50], Step [631/735], Loss: 0.0698\n",
      "Epoch [16/50], Step [632/735], Loss: 0.0758\n",
      "Epoch [16/50], Step [633/735], Loss: 0.0847\n",
      "Epoch [16/50], Step [634/735], Loss: 0.1155\n",
      "Epoch [16/50], Step [635/735], Loss: 0.0585\n",
      "Epoch [16/50], Step [636/735], Loss: 0.0676\n",
      "Epoch [16/50], Step [637/735], Loss: 0.0328\n",
      "Epoch [16/50], Step [638/735], Loss: 0.0645\n",
      "Epoch [16/50], Step [639/735], Loss: 0.0954\n",
      "Epoch [16/50], Step [640/735], Loss: 0.0665\n",
      "Epoch [16/50], Step [641/735], Loss: 0.1088\n",
      "Epoch [16/50], Step [642/735], Loss: 0.0926\n",
      "Epoch [16/50], Step [643/735], Loss: 0.1945\n",
      "Epoch [16/50], Step [644/735], Loss: 0.0634\n",
      "Epoch [16/50], Step [645/735], Loss: 0.1032\n",
      "Epoch [16/50], Step [646/735], Loss: 0.0435\n",
      "Epoch [16/50], Step [647/735], Loss: 0.0439\n",
      "Epoch [16/50], Step [648/735], Loss: 0.0510\n",
      "Epoch [16/50], Step [649/735], Loss: 0.0645\n",
      "Epoch [16/50], Step [650/735], Loss: 0.1033\n",
      "Epoch [16/50], Step [651/735], Loss: 0.1766\n",
      "Epoch [16/50], Step [652/735], Loss: 0.1087\n",
      "Epoch [16/50], Step [653/735], Loss: 0.3776\n",
      "Epoch [16/50], Step [654/735], Loss: 0.1833\n",
      "Epoch [16/50], Step [655/735], Loss: 0.0274\n",
      "Epoch [16/50], Step [656/735], Loss: 0.0668\n",
      "Epoch [16/50], Step [657/735], Loss: 0.1803\n",
      "Epoch [16/50], Step [658/735], Loss: 0.1459\n",
      "Epoch [16/50], Step [659/735], Loss: 0.1829\n",
      "Epoch [16/50], Step [660/735], Loss: 0.0325\n",
      "Epoch [16/50], Step [661/735], Loss: 0.0569\n",
      "Epoch [16/50], Step [662/735], Loss: 0.0251\n",
      "Epoch [16/50], Step [663/735], Loss: 0.2237\n",
      "Epoch [16/50], Step [664/735], Loss: 0.0197\n",
      "Epoch [16/50], Step [665/735], Loss: 0.3131\n",
      "Epoch [16/50], Step [666/735], Loss: 0.0503\n",
      "Epoch [16/50], Step [667/735], Loss: 0.0633\n",
      "Epoch [16/50], Step [668/735], Loss: 0.0732\n",
      "Epoch [16/50], Step [669/735], Loss: 0.0873\n",
      "Epoch [16/50], Step [670/735], Loss: 0.0459\n",
      "Epoch [16/50], Step [671/735], Loss: 0.1098\n",
      "Epoch [16/50], Step [672/735], Loss: 0.1144\n",
      "Epoch [16/50], Step [673/735], Loss: 0.1388\n",
      "Epoch [16/50], Step [674/735], Loss: 0.0763\n",
      "Epoch [16/50], Step [675/735], Loss: 0.2466\n",
      "Epoch [16/50], Step [676/735], Loss: 0.0836\n",
      "Epoch [16/50], Step [677/735], Loss: 0.0473\n",
      "Epoch [16/50], Step [678/735], Loss: 0.0192\n",
      "Epoch [16/50], Step [679/735], Loss: 0.0532\n",
      "Epoch [16/50], Step [680/735], Loss: 0.0223\n",
      "Epoch [16/50], Step [681/735], Loss: 0.0788\n",
      "Epoch [16/50], Step [682/735], Loss: 0.0645\n",
      "Epoch [16/50], Step [683/735], Loss: 0.0832\n",
      "Epoch [16/50], Step [684/735], Loss: 0.0566\n",
      "Epoch [16/50], Step [685/735], Loss: 0.0800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Step [686/735], Loss: 0.0269\n",
      "Epoch [16/50], Step [687/735], Loss: 0.0367\n",
      "Epoch [16/50], Step [688/735], Loss: 0.0255\n",
      "Epoch [16/50], Step [689/735], Loss: 0.0990\n",
      "Epoch [16/50], Step [690/735], Loss: 0.2045\n",
      "Epoch [16/50], Step [691/735], Loss: 0.2318\n",
      "Epoch [16/50], Step [692/735], Loss: 0.4374\n",
      "Epoch [16/50], Step [693/735], Loss: 0.1101\n",
      "Epoch [16/50], Step [694/735], Loss: 0.0293\n",
      "Epoch [16/50], Step [695/735], Loss: 0.0865\n",
      "Epoch [16/50], Step [696/735], Loss: 0.0643\n",
      "Epoch [16/50], Step [697/735], Loss: 0.1253\n",
      "Epoch [16/50], Step [698/735], Loss: 0.1926\n",
      "Epoch [16/50], Step [699/735], Loss: 0.0409\n",
      "Epoch [16/50], Step [700/735], Loss: 0.0910\n",
      "Epoch [16/50], Step [701/735], Loss: 0.0895\n",
      "Epoch [16/50], Step [702/735], Loss: 0.1351\n",
      "Epoch [16/50], Step [703/735], Loss: 0.3233\n",
      "Epoch [16/50], Step [704/735], Loss: 0.1030\n",
      "Epoch [16/50], Step [705/735], Loss: 0.1994\n",
      "Epoch [16/50], Step [706/735], Loss: 0.2334\n",
      "Epoch [16/50], Step [707/735], Loss: 0.0559\n",
      "Epoch [16/50], Step [708/735], Loss: 0.2562\n",
      "Epoch [16/50], Step [709/735], Loss: 0.1279\n",
      "Epoch [16/50], Step [710/735], Loss: 0.1306\n",
      "Epoch [16/50], Step [711/735], Loss: 0.1003\n",
      "Epoch [16/50], Step [712/735], Loss: 0.0567\n",
      "Epoch [16/50], Step [713/735], Loss: 0.0692\n",
      "Epoch [16/50], Step [714/735], Loss: 0.0524\n",
      "Epoch [16/50], Step [715/735], Loss: 0.2172\n",
      "Epoch [16/50], Step [716/735], Loss: 0.1077\n",
      "Epoch [16/50], Step [717/735], Loss: 0.1616\n",
      "Epoch [16/50], Step [718/735], Loss: 0.2680\n",
      "Epoch [16/50], Step [719/735], Loss: 0.1565\n",
      "Epoch [16/50], Step [720/735], Loss: 0.1465\n",
      "Epoch [16/50], Step [721/735], Loss: 0.0863\n",
      "Epoch [16/50], Step [722/735], Loss: 0.0324\n",
      "Epoch [16/50], Step [723/735], Loss: 0.0694\n",
      "Epoch [16/50], Step [724/735], Loss: 0.1199\n",
      "Epoch [16/50], Step [725/735], Loss: 0.3325\n",
      "Epoch [16/50], Step [726/735], Loss: 0.0330\n",
      "Epoch [16/50], Step [727/735], Loss: 0.1574\n",
      "Epoch [16/50], Step [728/735], Loss: 0.2370\n",
      "Epoch [16/50], Step [729/735], Loss: 0.1303\n",
      "Epoch [16/50], Step [730/735], Loss: 0.1850\n",
      "Epoch [16/50], Step [731/735], Loss: 0.0879\n",
      "Epoch [16/50], Step [732/735], Loss: 0.0376\n",
      "Epoch [16/50], Step [733/735], Loss: 0.1617\n",
      "Epoch [16/50], Step [734/735], Loss: 0.0385\n",
      "Epoch [16/50], Step [735/735], Loss: 0.2426\n",
      "Epoch [17/50], Step [1/735], Loss: 0.1259\n",
      "Epoch [17/50], Step [2/735], Loss: 0.0516\n",
      "Epoch [17/50], Step [3/735], Loss: 0.0444\n",
      "Epoch [17/50], Step [4/735], Loss: 0.0982\n",
      "Epoch [17/50], Step [5/735], Loss: 0.0933\n",
      "Epoch [17/50], Step [6/735], Loss: 0.1217\n",
      "Epoch [17/50], Step [7/735], Loss: 0.0309\n",
      "Epoch [17/50], Step [8/735], Loss: 0.0710\n",
      "Epoch [17/50], Step [9/735], Loss: 0.1020\n",
      "Epoch [17/50], Step [10/735], Loss: 0.1339\n",
      "Epoch [17/50], Step [11/735], Loss: 0.0634\n",
      "Epoch [17/50], Step [12/735], Loss: 0.0865\n",
      "Epoch [17/50], Step [13/735], Loss: 0.0405\n",
      "Epoch [17/50], Step [14/735], Loss: 0.1318\n",
      "Epoch [17/50], Step [15/735], Loss: 0.0479\n",
      "Epoch [17/50], Step [16/735], Loss: 0.0613\n",
      "Epoch [17/50], Step [17/735], Loss: 0.0642\n",
      "Epoch [17/50], Step [18/735], Loss: 0.0133\n",
      "Epoch [17/50], Step [19/735], Loss: 0.0761\n",
      "Epoch [17/50], Step [20/735], Loss: 0.0443\n",
      "Epoch [17/50], Step [21/735], Loss: 0.1021\n",
      "Epoch [17/50], Step [22/735], Loss: 0.1320\n",
      "Epoch [17/50], Step [23/735], Loss: 0.0555\n",
      "Epoch [17/50], Step [24/735], Loss: 0.0654\n",
      "Epoch [17/50], Step [25/735], Loss: 0.0756\n",
      "Epoch [17/50], Step [26/735], Loss: 0.0511\n",
      "Epoch [17/50], Step [27/735], Loss: 0.0211\n",
      "Epoch [17/50], Step [28/735], Loss: 0.0920\n",
      "Epoch [17/50], Step [29/735], Loss: 0.2388\n",
      "Epoch [17/50], Step [30/735], Loss: 0.2244\n",
      "Epoch [17/50], Step [31/735], Loss: 0.1777\n",
      "Epoch [17/50], Step [32/735], Loss: 0.0252\n",
      "Epoch [17/50], Step [33/735], Loss: 0.0641\n",
      "Epoch [17/50], Step [34/735], Loss: 0.0399\n",
      "Epoch [17/50], Step [35/735], Loss: 0.0509\n",
      "Epoch [17/50], Step [36/735], Loss: 0.0575\n",
      "Epoch [17/50], Step [37/735], Loss: 0.0152\n",
      "Epoch [17/50], Step [38/735], Loss: 0.0700\n",
      "Epoch [17/50], Step [39/735], Loss: 0.1710\n",
      "Epoch [17/50], Step [40/735], Loss: 0.1022\n",
      "Epoch [17/50], Step [41/735], Loss: 0.0294\n",
      "Epoch [17/50], Step [42/735], Loss: 0.0372\n",
      "Epoch [17/50], Step [43/735], Loss: 0.3705\n",
      "Epoch [17/50], Step [44/735], Loss: 0.0332\n",
      "Epoch [17/50], Step [45/735], Loss: 0.0649\n",
      "Epoch [17/50], Step [46/735], Loss: 0.0522\n",
      "Epoch [17/50], Step [47/735], Loss: 0.0663\n",
      "Epoch [17/50], Step [48/735], Loss: 0.0425\n",
      "Epoch [17/50], Step [49/735], Loss: 0.0502\n",
      "Epoch [17/50], Step [50/735], Loss: 0.0569\n",
      "Epoch [17/50], Step [51/735], Loss: 0.1215\n",
      "Epoch [17/50], Step [52/735], Loss: 0.0454\n",
      "Epoch [17/50], Step [53/735], Loss: 0.1186\n",
      "Epoch [17/50], Step [54/735], Loss: 0.0672\n",
      "Epoch [17/50], Step [55/735], Loss: 0.0799\n",
      "Epoch [17/50], Step [56/735], Loss: 0.0923\n",
      "Epoch [17/50], Step [57/735], Loss: 0.0801\n",
      "Epoch [17/50], Step [58/735], Loss: 0.0686\n",
      "Epoch [17/50], Step [59/735], Loss: 0.0959\n",
      "Epoch [17/50], Step [60/735], Loss: 0.0323\n",
      "Epoch [17/50], Step [61/735], Loss: 0.0443\n",
      "Epoch [17/50], Step [62/735], Loss: 0.0360\n",
      "Epoch [17/50], Step [63/735], Loss: 0.0796\n",
      "Epoch [17/50], Step [64/735], Loss: 0.4433\n",
      "Epoch [17/50], Step [65/735], Loss: 0.1784\n",
      "Epoch [17/50], Step [66/735], Loss: 0.0669\n",
      "Epoch [17/50], Step [67/735], Loss: 0.0560\n",
      "Epoch [17/50], Step [68/735], Loss: 0.1004\n",
      "Epoch [17/50], Step [69/735], Loss: 0.1230\n",
      "Epoch [17/50], Step [70/735], Loss: 0.0720\n",
      "Epoch [17/50], Step [71/735], Loss: 0.0951\n",
      "Epoch [17/50], Step [72/735], Loss: 0.0776\n",
      "Epoch [17/50], Step [73/735], Loss: 0.0542\n",
      "Epoch [17/50], Step [74/735], Loss: 0.0432\n",
      "Epoch [17/50], Step [75/735], Loss: 0.1311\n",
      "Epoch [17/50], Step [76/735], Loss: 0.4804\n",
      "Epoch [17/50], Step [77/735], Loss: 0.2425\n",
      "Epoch [17/50], Step [78/735], Loss: 0.1444\n",
      "Epoch [17/50], Step [79/735], Loss: 0.0668\n",
      "Epoch [17/50], Step [80/735], Loss: 0.1167\n",
      "Epoch [17/50], Step [81/735], Loss: 0.1203\n",
      "Epoch [17/50], Step [82/735], Loss: 0.0543\n",
      "Epoch [17/50], Step [83/735], Loss: 0.0768\n",
      "Epoch [17/50], Step [84/735], Loss: 0.0771\n",
      "Epoch [17/50], Step [85/735], Loss: 0.0687\n",
      "Epoch [17/50], Step [86/735], Loss: 0.0440\n",
      "Epoch [17/50], Step [87/735], Loss: 0.0935\n",
      "Epoch [17/50], Step [88/735], Loss: 0.1652\n",
      "Epoch [17/50], Step [89/735], Loss: 0.0363\n",
      "Epoch [17/50], Step [90/735], Loss: 0.1883\n",
      "Epoch [17/50], Step [91/735], Loss: 0.0627\n",
      "Epoch [17/50], Step [92/735], Loss: 0.0855\n",
      "Epoch [17/50], Step [93/735], Loss: 0.3771\n",
      "Epoch [17/50], Step [94/735], Loss: 0.1315\n",
      "Epoch [17/50], Step [95/735], Loss: 0.0815\n",
      "Epoch [17/50], Step [96/735], Loss: 0.2531\n",
      "Epoch [17/50], Step [97/735], Loss: 0.2112\n",
      "Epoch [17/50], Step [98/735], Loss: 0.0385\n",
      "Epoch [17/50], Step [99/735], Loss: 0.1689\n",
      "Epoch [17/50], Step [100/735], Loss: 0.0673\n",
      "Epoch [17/50], Step [101/735], Loss: 0.0977\n",
      "Epoch [17/50], Step [102/735], Loss: 0.0494\n",
      "Epoch [17/50], Step [103/735], Loss: 0.0359\n",
      "Epoch [17/50], Step [104/735], Loss: 0.0435\n",
      "Epoch [17/50], Step [105/735], Loss: 0.0658\n",
      "Epoch [17/50], Step [106/735], Loss: 0.1603\n",
      "Epoch [17/50], Step [107/735], Loss: 0.0273\n",
      "Epoch [17/50], Step [108/735], Loss: 0.0425\n",
      "Epoch [17/50], Step [109/735], Loss: 0.0356\n",
      "Epoch [17/50], Step [110/735], Loss: 0.0299\n",
      "Epoch [17/50], Step [111/735], Loss: 0.0578\n",
      "Epoch [17/50], Step [112/735], Loss: 0.0240\n",
      "Epoch [17/50], Step [113/735], Loss: 0.0382\n",
      "Epoch [17/50], Step [114/735], Loss: 0.0321\n",
      "Epoch [17/50], Step [115/735], Loss: 0.1117\n",
      "Epoch [17/50], Step [116/735], Loss: 0.0959\n",
      "Epoch [17/50], Step [117/735], Loss: 0.0461\n",
      "Epoch [17/50], Step [118/735], Loss: 0.0474\n",
      "Epoch [17/50], Step [119/735], Loss: 0.0380\n",
      "Epoch [17/50], Step [120/735], Loss: 0.0998\n",
      "Epoch [17/50], Step [121/735], Loss: 0.1728\n",
      "Epoch [17/50], Step [122/735], Loss: 0.0545\n",
      "Epoch [17/50], Step [123/735], Loss: 0.0666\n",
      "Epoch [17/50], Step [124/735], Loss: 0.1034\n",
      "Epoch [17/50], Step [125/735], Loss: 0.0714\n",
      "Epoch [17/50], Step [126/735], Loss: 0.0403\n",
      "Epoch [17/50], Step [127/735], Loss: 0.3897\n",
      "Epoch [17/50], Step [128/735], Loss: 0.4432\n",
      "Epoch [17/50], Step [129/735], Loss: 0.0939\n",
      "Epoch [17/50], Step [130/735], Loss: 0.1100\n",
      "Epoch [17/50], Step [131/735], Loss: 0.1031\n",
      "Epoch [17/50], Step [132/735], Loss: 0.1067\n",
      "Epoch [17/50], Step [133/735], Loss: 0.0454\n",
      "Epoch [17/50], Step [134/735], Loss: 0.0526\n",
      "Epoch [17/50], Step [135/735], Loss: 0.1440\n",
      "Epoch [17/50], Step [136/735], Loss: 0.0561\n",
      "Epoch [17/50], Step [137/735], Loss: 0.0383\n",
      "Epoch [17/50], Step [138/735], Loss: 0.0580\n",
      "Epoch [17/50], Step [139/735], Loss: 0.0669\n",
      "Epoch [17/50], Step [140/735], Loss: 0.2404\n",
      "Epoch [17/50], Step [141/735], Loss: 0.0848\n",
      "Epoch [17/50], Step [142/735], Loss: 0.0471\n",
      "Epoch [17/50], Step [143/735], Loss: 0.0737\n",
      "Epoch [17/50], Step [144/735], Loss: 0.4005\n",
      "Epoch [17/50], Step [145/735], Loss: 0.3891\n",
      "Epoch [17/50], Step [146/735], Loss: 0.0269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Step [147/735], Loss: 0.0484\n",
      "Epoch [17/50], Step [148/735], Loss: 0.0587\n",
      "Epoch [17/50], Step [149/735], Loss: 0.0622\n",
      "Epoch [17/50], Step [150/735], Loss: 0.1478\n",
      "Epoch [17/50], Step [151/735], Loss: 0.1910\n",
      "Epoch [17/50], Step [152/735], Loss: 0.0434\n",
      "Epoch [17/50], Step [153/735], Loss: 0.1435\n",
      "Epoch [17/50], Step [154/735], Loss: 0.0941\n",
      "Epoch [17/50], Step [155/735], Loss: 0.1965\n",
      "Epoch [17/50], Step [156/735], Loss: 0.1107\n",
      "Epoch [17/50], Step [157/735], Loss: 0.0564\n",
      "Epoch [17/50], Step [158/735], Loss: 0.0623\n",
      "Epoch [17/50], Step [159/735], Loss: 0.0394\n",
      "Epoch [17/50], Step [160/735], Loss: 0.0539\n",
      "Epoch [17/50], Step [161/735], Loss: 0.0365\n",
      "Epoch [17/50], Step [162/735], Loss: 0.1851\n",
      "Epoch [17/50], Step [163/735], Loss: 0.0300\n",
      "Epoch [17/50], Step [164/735], Loss: 0.0467\n",
      "Epoch [17/50], Step [165/735], Loss: 0.0350\n",
      "Epoch [17/50], Step [166/735], Loss: 0.0336\n",
      "Epoch [17/50], Step [167/735], Loss: 0.5717\n",
      "Epoch [17/50], Step [168/735], Loss: 0.1161\n",
      "Epoch [17/50], Step [169/735], Loss: 0.1224\n",
      "Epoch [17/50], Step [170/735], Loss: 0.1541\n",
      "Epoch [17/50], Step [171/735], Loss: 0.1235\n",
      "Epoch [17/50], Step [172/735], Loss: 0.0546\n",
      "Epoch [17/50], Step [173/735], Loss: 0.0953\n",
      "Epoch [17/50], Step [174/735], Loss: 0.1640\n",
      "Epoch [17/50], Step [175/735], Loss: 0.1037\n",
      "Epoch [17/50], Step [176/735], Loss: 0.0740\n",
      "Epoch [17/50], Step [177/735], Loss: 0.0335\n",
      "Epoch [17/50], Step [178/735], Loss: 0.0562\n",
      "Epoch [17/50], Step [179/735], Loss: 0.0740\n",
      "Epoch [17/50], Step [180/735], Loss: 0.0536\n",
      "Epoch [17/50], Step [181/735], Loss: 0.0693\n",
      "Epoch [17/50], Step [182/735], Loss: 0.3758\n",
      "Epoch [17/50], Step [183/735], Loss: 0.0512\n",
      "Epoch [17/50], Step [184/735], Loss: 0.0750\n",
      "Epoch [17/50], Step [185/735], Loss: 0.0416\n",
      "Epoch [17/50], Step [186/735], Loss: 0.0524\n",
      "Epoch [17/50], Step [187/735], Loss: 0.0408\n",
      "Epoch [17/50], Step [188/735], Loss: 0.0900\n",
      "Epoch [17/50], Step [189/735], Loss: 0.1099\n",
      "Epoch [17/50], Step [190/735], Loss: 0.1785\n",
      "Epoch [17/50], Step [191/735], Loss: 0.0951\n",
      "Epoch [17/50], Step [192/735], Loss: 0.1386\n",
      "Epoch [17/50], Step [193/735], Loss: 0.0338\n",
      "Epoch [17/50], Step [194/735], Loss: 0.1888\n",
      "Epoch [17/50], Step [195/735], Loss: 0.1106\n",
      "Epoch [17/50], Step [196/735], Loss: 0.0740\n",
      "Epoch [17/50], Step [197/735], Loss: 0.1510\n",
      "Epoch [17/50], Step [198/735], Loss: 0.0627\n",
      "Epoch [17/50], Step [199/735], Loss: 0.1880\n",
      "Epoch [17/50], Step [200/735], Loss: 0.0420\n",
      "Epoch [17/50], Step [201/735], Loss: 0.0487\n",
      "Epoch [17/50], Step [202/735], Loss: 0.0547\n",
      "Epoch [17/50], Step [203/735], Loss: 0.1596\n",
      "Epoch [17/50], Step [204/735], Loss: 0.1014\n",
      "Epoch [17/50], Step [205/735], Loss: 0.0471\n",
      "Epoch [17/50], Step [206/735], Loss: 0.0323\n",
      "Epoch [17/50], Step [207/735], Loss: 0.1161\n",
      "Epoch [17/50], Step [208/735], Loss: 0.0604\n",
      "Epoch [17/50], Step [209/735], Loss: 0.0796\n",
      "Epoch [17/50], Step [210/735], Loss: 0.3114\n",
      "Epoch [17/50], Step [211/735], Loss: 0.1355\n",
      "Epoch [17/50], Step [212/735], Loss: 0.2782\n",
      "Epoch [17/50], Step [213/735], Loss: 0.0424\n",
      "Epoch [17/50], Step [214/735], Loss: 0.0913\n",
      "Epoch [17/50], Step [215/735], Loss: 0.0943\n",
      "Epoch [17/50], Step [216/735], Loss: 0.0669\n",
      "Epoch [17/50], Step [217/735], Loss: 0.0767\n",
      "Epoch [17/50], Step [218/735], Loss: 0.0422\n",
      "Epoch [17/50], Step [219/735], Loss: 0.0356\n",
      "Epoch [17/50], Step [220/735], Loss: 0.0579\n",
      "Epoch [17/50], Step [221/735], Loss: 0.1322\n",
      "Epoch [17/50], Step [222/735], Loss: 0.1119\n",
      "Epoch [17/50], Step [223/735], Loss: 0.1025\n",
      "Epoch [17/50], Step [224/735], Loss: 0.0215\n",
      "Epoch [17/50], Step [225/735], Loss: 0.0617\n",
      "Epoch [17/50], Step [226/735], Loss: 0.2584\n",
      "Epoch [17/50], Step [227/735], Loss: 0.0333\n",
      "Epoch [17/50], Step [228/735], Loss: 0.0951\n",
      "Epoch [17/50], Step [229/735], Loss: 0.1065\n",
      "Epoch [17/50], Step [230/735], Loss: 0.0294\n",
      "Epoch [17/50], Step [231/735], Loss: 0.0486\n",
      "Epoch [17/50], Step [232/735], Loss: 0.0995\n",
      "Epoch [17/50], Step [233/735], Loss: 0.1137\n",
      "Epoch [17/50], Step [234/735], Loss: 0.1719\n",
      "Epoch [17/50], Step [235/735], Loss: 0.0624\n",
      "Epoch [17/50], Step [236/735], Loss: 0.0754\n",
      "Epoch [17/50], Step [237/735], Loss: 0.3339\n",
      "Epoch [17/50], Step [238/735], Loss: 0.0346\n",
      "Epoch [17/50], Step [239/735], Loss: 0.0983\n",
      "Epoch [17/50], Step [240/735], Loss: 0.0380\n",
      "Epoch [17/50], Step [241/735], Loss: 0.0639\n",
      "Epoch [17/50], Step [242/735], Loss: 0.0280\n",
      "Epoch [17/50], Step [243/735], Loss: 0.0566\n",
      "Epoch [17/50], Step [244/735], Loss: 0.3450\n",
      "Epoch [17/50], Step [245/735], Loss: 0.0842\n",
      "Epoch [17/50], Step [246/735], Loss: 0.1024\n",
      "Epoch [17/50], Step [247/735], Loss: 0.1032\n",
      "Epoch [17/50], Step [248/735], Loss: 0.0318\n",
      "Epoch [17/50], Step [249/735], Loss: 0.0222\n",
      "Epoch [17/50], Step [250/735], Loss: 0.0804\n",
      "Epoch [17/50], Step [251/735], Loss: 0.0347\n",
      "Epoch [17/50], Step [252/735], Loss: 0.1463\n",
      "Epoch [17/50], Step [253/735], Loss: 0.1244\n",
      "Epoch [17/50], Step [254/735], Loss: 0.0612\n",
      "Epoch [17/50], Step [255/735], Loss: 0.1992\n",
      "Epoch [17/50], Step [256/735], Loss: 0.0477\n",
      "Epoch [17/50], Step [257/735], Loss: 0.0417\n",
      "Epoch [17/50], Step [258/735], Loss: 0.0517\n",
      "Epoch [17/50], Step [259/735], Loss: 0.0177\n",
      "Epoch [17/50], Step [260/735], Loss: 0.1523\n",
      "Epoch [17/50], Step [261/735], Loss: 0.0127\n",
      "Epoch [17/50], Step [262/735], Loss: 0.0274\n",
      "Epoch [17/50], Step [263/735], Loss: 0.0177\n",
      "Epoch [17/50], Step [264/735], Loss: 0.0186\n",
      "Epoch [17/50], Step [265/735], Loss: 0.0501\n",
      "Epoch [17/50], Step [266/735], Loss: 0.1406\n",
      "Epoch [17/50], Step [267/735], Loss: 0.2134\n",
      "Epoch [17/50], Step [268/735], Loss: 0.1878\n",
      "Epoch [17/50], Step [269/735], Loss: 0.0762\n",
      "Epoch [17/50], Step [270/735], Loss: 0.1139\n",
      "Epoch [17/50], Step [271/735], Loss: 0.0717\n",
      "Epoch [17/50], Step [272/735], Loss: 0.1457\n",
      "Epoch [17/50], Step [273/735], Loss: 0.0359\n",
      "Epoch [17/50], Step [274/735], Loss: 0.0583\n",
      "Epoch [17/50], Step [275/735], Loss: 0.1083\n",
      "Epoch [17/50], Step [276/735], Loss: 0.0452\n",
      "Epoch [17/50], Step [277/735], Loss: 0.0540\n",
      "Epoch [17/50], Step [278/735], Loss: 0.0364\n",
      "Epoch [17/50], Step [279/735], Loss: 0.1902\n",
      "Epoch [17/50], Step [280/735], Loss: 0.0710\n",
      "Epoch [17/50], Step [281/735], Loss: 0.0619\n",
      "Epoch [17/50], Step [282/735], Loss: 0.1068\n",
      "Epoch [17/50], Step [283/735], Loss: 0.0843\n",
      "Epoch [17/50], Step [284/735], Loss: 0.0752\n",
      "Epoch [17/50], Step [285/735], Loss: 0.0753\n",
      "Epoch [17/50], Step [286/735], Loss: 0.0508\n",
      "Epoch [17/50], Step [287/735], Loss: 0.2431\n",
      "Epoch [17/50], Step [288/735], Loss: 0.1856\n",
      "Epoch [17/50], Step [289/735], Loss: 0.0670\n",
      "Epoch [17/50], Step [290/735], Loss: 0.0389\n",
      "Epoch [17/50], Step [291/735], Loss: 0.0854\n",
      "Epoch [17/50], Step [292/735], Loss: 0.0589\n",
      "Epoch [17/50], Step [293/735], Loss: 0.0431\n",
      "Epoch [17/50], Step [294/735], Loss: 0.0774\n",
      "Epoch [17/50], Step [295/735], Loss: 0.0390\n",
      "Epoch [17/50], Step [296/735], Loss: 0.1106\n",
      "Epoch [17/50], Step [297/735], Loss: 0.2345\n",
      "Epoch [17/50], Step [298/735], Loss: 0.0859\n",
      "Epoch [17/50], Step [299/735], Loss: 0.0276\n",
      "Epoch [17/50], Step [300/735], Loss: 0.0955\n",
      "Epoch [17/50], Step [301/735], Loss: 0.0336\n",
      "Epoch [17/50], Step [302/735], Loss: 0.0552\n",
      "Epoch [17/50], Step [303/735], Loss: 0.0524\n",
      "Epoch [17/50], Step [304/735], Loss: 0.1846\n",
      "Epoch [17/50], Step [305/735], Loss: 0.0453\n",
      "Epoch [17/50], Step [306/735], Loss: 0.0385\n",
      "Epoch [17/50], Step [307/735], Loss: 0.1761\n",
      "Epoch [17/50], Step [308/735], Loss: 0.1538\n",
      "Epoch [17/50], Step [309/735], Loss: 0.0638\n",
      "Epoch [17/50], Step [310/735], Loss: 0.0593\n",
      "Epoch [17/50], Step [311/735], Loss: 0.0165\n",
      "Epoch [17/50], Step [312/735], Loss: 0.0922\n",
      "Epoch [17/50], Step [313/735], Loss: 0.0591\n",
      "Epoch [17/50], Step [314/735], Loss: 0.0389\n",
      "Epoch [17/50], Step [315/735], Loss: 0.1096\n",
      "Epoch [17/50], Step [316/735], Loss: 0.2281\n",
      "Epoch [17/50], Step [317/735], Loss: 0.1368\n",
      "Epoch [17/50], Step [318/735], Loss: 0.0679\n",
      "Epoch [17/50], Step [319/735], Loss: 0.0201\n",
      "Epoch [17/50], Step [320/735], Loss: 0.1236\n",
      "Epoch [17/50], Step [321/735], Loss: 0.0927\n",
      "Epoch [17/50], Step [322/735], Loss: 0.0801\n",
      "Epoch [17/50], Step [323/735], Loss: 0.0607\n",
      "Epoch [17/50], Step [324/735], Loss: 0.0816\n",
      "Epoch [17/50], Step [325/735], Loss: 0.0329\n",
      "Epoch [17/50], Step [326/735], Loss: 0.2047\n",
      "Epoch [17/50], Step [327/735], Loss: 0.6347\n",
      "Epoch [17/50], Step [328/735], Loss: 0.0933\n",
      "Epoch [17/50], Step [329/735], Loss: 0.0553\n",
      "Epoch [17/50], Step [330/735], Loss: 0.1136\n",
      "Epoch [17/50], Step [331/735], Loss: 0.2058\n",
      "Epoch [17/50], Step [332/735], Loss: 0.0517\n",
      "Epoch [17/50], Step [333/735], Loss: 0.0382\n",
      "Epoch [17/50], Step [334/735], Loss: 0.1462\n",
      "Epoch [17/50], Step [335/735], Loss: 0.3345\n",
      "Epoch [17/50], Step [336/735], Loss: 0.0646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Step [337/735], Loss: 0.1577\n",
      "Epoch [17/50], Step [338/735], Loss: 0.0950\n",
      "Epoch [17/50], Step [339/735], Loss: 0.0366\n",
      "Epoch [17/50], Step [340/735], Loss: 0.0518\n",
      "Epoch [17/50], Step [341/735], Loss: 0.0619\n",
      "Epoch [17/50], Step [342/735], Loss: 0.0464\n",
      "Epoch [17/50], Step [343/735], Loss: 0.0691\n",
      "Epoch [17/50], Step [344/735], Loss: 0.0684\n",
      "Epoch [17/50], Step [345/735], Loss: 0.0564\n",
      "Epoch [17/50], Step [346/735], Loss: 0.0477\n",
      "Epoch [17/50], Step [347/735], Loss: 0.0316\n",
      "Epoch [17/50], Step [348/735], Loss: 0.0235\n",
      "Epoch [17/50], Step [349/735], Loss: 0.0259\n",
      "Epoch [17/50], Step [350/735], Loss: 0.0436\n",
      "Epoch [17/50], Step [351/735], Loss: 0.0558\n",
      "Epoch [17/50], Step [352/735], Loss: 0.0722\n",
      "Epoch [17/50], Step [353/735], Loss: 0.0775\n",
      "Epoch [17/50], Step [354/735], Loss: 0.0467\n",
      "Epoch [17/50], Step [355/735], Loss: 0.0603\n",
      "Epoch [17/50], Step [356/735], Loss: 0.0900\n",
      "Epoch [17/50], Step [357/735], Loss: 0.1180\n",
      "Epoch [17/50], Step [358/735], Loss: 0.0347\n",
      "Epoch [17/50], Step [359/735], Loss: 0.1621\n",
      "Epoch [17/50], Step [360/735], Loss: 0.1990\n",
      "Epoch [17/50], Step [361/735], Loss: 0.0539\n",
      "Epoch [17/50], Step [362/735], Loss: 0.0427\n",
      "Epoch [17/50], Step [363/735], Loss: 0.0569\n",
      "Epoch [17/50], Step [364/735], Loss: 0.0313\n",
      "Epoch [17/50], Step [365/735], Loss: 0.1382\n",
      "Epoch [17/50], Step [366/735], Loss: 0.0302\n",
      "Epoch [17/50], Step [367/735], Loss: 0.0650\n",
      "Epoch [17/50], Step [368/735], Loss: 0.0189\n",
      "Epoch [17/50], Step [369/735], Loss: 0.0210\n",
      "Epoch [17/50], Step [370/735], Loss: 0.0485\n",
      "Epoch [17/50], Step [371/735], Loss: 0.0599\n",
      "Epoch [17/50], Step [372/735], Loss: 0.0803\n",
      "Epoch [17/50], Step [373/735], Loss: 0.0711\n",
      "Epoch [17/50], Step [374/735], Loss: 0.0211\n",
      "Epoch [17/50], Step [375/735], Loss: 0.1164\n",
      "Epoch [17/50], Step [376/735], Loss: 0.0719\n",
      "Epoch [17/50], Step [377/735], Loss: 0.0317\n",
      "Epoch [17/50], Step [378/735], Loss: 0.0329\n",
      "Epoch [17/50], Step [379/735], Loss: 0.0638\n",
      "Epoch [17/50], Step [380/735], Loss: 0.0618\n",
      "Epoch [17/50], Step [381/735], Loss: 0.2080\n",
      "Epoch [17/50], Step [382/735], Loss: 0.0431\n",
      "Epoch [17/50], Step [383/735], Loss: 0.1982\n",
      "Epoch [17/50], Step [384/735], Loss: 0.0895\n",
      "Epoch [17/50], Step [385/735], Loss: 0.0311\n",
      "Epoch [17/50], Step [386/735], Loss: 0.0200\n",
      "Epoch [17/50], Step [387/735], Loss: 0.0466\n",
      "Epoch [17/50], Step [388/735], Loss: 0.1127\n",
      "Epoch [17/50], Step [389/735], Loss: 0.0222\n",
      "Epoch [17/50], Step [390/735], Loss: 0.1169\n",
      "Epoch [17/50], Step [391/735], Loss: 0.2777\n",
      "Epoch [17/50], Step [392/735], Loss: 0.0408\n",
      "Epoch [17/50], Step [393/735], Loss: 0.0472\n",
      "Epoch [17/50], Step [394/735], Loss: 0.0750\n",
      "Epoch [17/50], Step [395/735], Loss: 0.0577\n",
      "Epoch [17/50], Step [396/735], Loss: 0.1109\n",
      "Epoch [17/50], Step [397/735], Loss: 0.2941\n",
      "Epoch [17/50], Step [398/735], Loss: 0.0827\n",
      "Epoch [17/50], Step [399/735], Loss: 0.0677\n",
      "Epoch [17/50], Step [400/735], Loss: 0.1030\n",
      "Epoch [17/50], Step [401/735], Loss: 0.0912\n",
      "Epoch [17/50], Step [402/735], Loss: 0.0685\n",
      "Epoch [17/50], Step [403/735], Loss: 0.0644\n",
      "Epoch [17/50], Step [404/735], Loss: 0.1400\n",
      "Epoch [17/50], Step [405/735], Loss: 0.0803\n",
      "Epoch [17/50], Step [406/735], Loss: 0.0585\n",
      "Epoch [17/50], Step [407/735], Loss: 0.0709\n",
      "Epoch [17/50], Step [408/735], Loss: 0.0765\n",
      "Epoch [17/50], Step [409/735], Loss: 0.0460\n",
      "Epoch [17/50], Step [410/735], Loss: 0.0316\n",
      "Epoch [17/50], Step [411/735], Loss: 0.0256\n",
      "Epoch [17/50], Step [412/735], Loss: 0.0250\n",
      "Epoch [17/50], Step [413/735], Loss: 0.0397\n",
      "Epoch [17/50], Step [414/735], Loss: 0.0175\n",
      "Epoch [17/50], Step [415/735], Loss: 0.1244\n",
      "Epoch [17/50], Step [416/735], Loss: 0.1450\n",
      "Epoch [17/50], Step [417/735], Loss: 0.7014\n",
      "Epoch [17/50], Step [418/735], Loss: 0.0672\n",
      "Epoch [17/50], Step [419/735], Loss: 0.0784\n",
      "Epoch [17/50], Step [420/735], Loss: 0.0993\n",
      "Epoch [17/50], Step [421/735], Loss: 0.0810\n",
      "Epoch [17/50], Step [422/735], Loss: 0.2047\n",
      "Epoch [17/50], Step [423/735], Loss: 0.2535\n",
      "Epoch [17/50], Step [424/735], Loss: 0.1150\n",
      "Epoch [17/50], Step [425/735], Loss: 0.1083\n",
      "Epoch [17/50], Step [426/735], Loss: 0.0854\n",
      "Epoch [17/50], Step [427/735], Loss: 0.0841\n",
      "Epoch [17/50], Step [428/735], Loss: 0.1551\n",
      "Epoch [17/50], Step [429/735], Loss: 0.0348\n",
      "Epoch [17/50], Step [430/735], Loss: 0.0861\n",
      "Epoch [17/50], Step [431/735], Loss: 0.0496\n",
      "Epoch [17/50], Step [432/735], Loss: 0.1084\n",
      "Epoch [17/50], Step [433/735], Loss: 0.0664\n",
      "Epoch [17/50], Step [434/735], Loss: 0.1965\n",
      "Epoch [17/50], Step [435/735], Loss: 0.1560\n",
      "Epoch [17/50], Step [436/735], Loss: 0.0604\n",
      "Epoch [17/50], Step [437/735], Loss: 0.0499\n",
      "Epoch [17/50], Step [438/735], Loss: 0.0387\n",
      "Epoch [17/50], Step [439/735], Loss: 0.4077\n",
      "Epoch [17/50], Step [440/735], Loss: 0.0649\n",
      "Epoch [17/50], Step [441/735], Loss: 0.0441\n",
      "Epoch [17/50], Step [442/735], Loss: 0.0561\n",
      "Epoch [17/50], Step [443/735], Loss: 0.1096\n",
      "Epoch [17/50], Step [444/735], Loss: 0.0523\n",
      "Epoch [17/50], Step [445/735], Loss: 0.0958\n",
      "Epoch [17/50], Step [446/735], Loss: 0.1504\n",
      "Epoch [17/50], Step [447/735], Loss: 0.0376\n",
      "Epoch [17/50], Step [448/735], Loss: 0.0659\n",
      "Epoch [17/50], Step [449/735], Loss: 0.1593\n",
      "Epoch [17/50], Step [450/735], Loss: 0.0494\n",
      "Epoch [17/50], Step [451/735], Loss: 0.1032\n",
      "Epoch [17/50], Step [452/735], Loss: 0.2131\n",
      "Epoch [17/50], Step [453/735], Loss: 0.1708\n",
      "Epoch [17/50], Step [454/735], Loss: 0.1346\n",
      "Epoch [17/50], Step [455/735], Loss: 0.0166\n",
      "Epoch [17/50], Step [456/735], Loss: 0.0728\n",
      "Epoch [17/50], Step [457/735], Loss: 0.0527\n",
      "Epoch [17/50], Step [458/735], Loss: 0.0476\n",
      "Epoch [17/50], Step [459/735], Loss: 0.1829\n",
      "Epoch [17/50], Step [460/735], Loss: 0.3995\n",
      "Epoch [17/50], Step [461/735], Loss: 0.0359\n",
      "Epoch [17/50], Step [462/735], Loss: 0.0663\n",
      "Epoch [17/50], Step [463/735], Loss: 0.0404\n",
      "Epoch [17/50], Step [464/735], Loss: 0.0179\n",
      "Epoch [17/50], Step [465/735], Loss: 0.0292\n",
      "Epoch [17/50], Step [466/735], Loss: 0.1609\n",
      "Epoch [17/50], Step [467/735], Loss: 0.0791\n",
      "Epoch [17/50], Step [468/735], Loss: 0.0501\n",
      "Epoch [17/50], Step [469/735], Loss: 0.0672\n",
      "Epoch [17/50], Step [470/735], Loss: 0.0354\n",
      "Epoch [17/50], Step [471/735], Loss: 0.1117\n",
      "Epoch [17/50], Step [472/735], Loss: 0.0150\n",
      "Epoch [17/50], Step [473/735], Loss: 0.0367\n",
      "Epoch [17/50], Step [474/735], Loss: 0.6154\n",
      "Epoch [17/50], Step [475/735], Loss: 0.0571\n",
      "Epoch [17/50], Step [476/735], Loss: 0.0689\n",
      "Epoch [17/50], Step [477/735], Loss: 0.0484\n",
      "Epoch [17/50], Step [478/735], Loss: 0.4793\n",
      "Epoch [17/50], Step [479/735], Loss: 0.0742\n",
      "Epoch [17/50], Step [480/735], Loss: 0.0307\n",
      "Epoch [17/50], Step [481/735], Loss: 0.0288\n",
      "Epoch [17/50], Step [482/735], Loss: 0.1276\n",
      "Epoch [17/50], Step [483/735], Loss: 0.0380\n",
      "Epoch [17/50], Step [484/735], Loss: 0.0913\n",
      "Epoch [17/50], Step [485/735], Loss: 0.0981\n",
      "Epoch [17/50], Step [486/735], Loss: 0.0339\n",
      "Epoch [17/50], Step [487/735], Loss: 0.1235\n",
      "Epoch [17/50], Step [488/735], Loss: 0.0981\n",
      "Epoch [17/50], Step [489/735], Loss: 0.1097\n",
      "Epoch [17/50], Step [490/735], Loss: 0.1109\n",
      "Epoch [17/50], Step [491/735], Loss: 0.0564\n",
      "Epoch [17/50], Step [492/735], Loss: 0.1010\n",
      "Epoch [17/50], Step [493/735], Loss: 0.0936\n",
      "Epoch [17/50], Step [494/735], Loss: 0.3023\n",
      "Epoch [17/50], Step [495/735], Loss: 0.0920\n",
      "Epoch [17/50], Step [496/735], Loss: 0.0750\n",
      "Epoch [17/50], Step [497/735], Loss: 0.0491\n",
      "Epoch [17/50], Step [498/735], Loss: 0.0553\n",
      "Epoch [17/50], Step [499/735], Loss: 0.0541\n",
      "Epoch [17/50], Step [500/735], Loss: 0.1178\n",
      "Epoch [17/50], Step [501/735], Loss: 0.0640\n",
      "Epoch [17/50], Step [502/735], Loss: 0.0178\n",
      "Epoch [17/50], Step [503/735], Loss: 0.1170\n",
      "Epoch [17/50], Step [504/735], Loss: 0.0924\n",
      "Epoch [17/50], Step [505/735], Loss: 0.0906\n",
      "Epoch [17/50], Step [506/735], Loss: 0.1293\n",
      "Epoch [17/50], Step [507/735], Loss: 0.0449\n",
      "Epoch [17/50], Step [508/735], Loss: 0.0983\n",
      "Epoch [17/50], Step [509/735], Loss: 0.0261\n",
      "Epoch [17/50], Step [510/735], Loss: 0.0311\n",
      "Epoch [17/50], Step [511/735], Loss: 0.0504\n",
      "Epoch [17/50], Step [512/735], Loss: 0.0670\n",
      "Epoch [17/50], Step [513/735], Loss: 0.0830\n",
      "Epoch [17/50], Step [514/735], Loss: 0.1385\n",
      "Epoch [17/50], Step [515/735], Loss: 0.1407\n",
      "Epoch [17/50], Step [516/735], Loss: 0.0439\n",
      "Epoch [17/50], Step [517/735], Loss: 0.3248\n",
      "Epoch [17/50], Step [518/735], Loss: 0.1018\n",
      "Epoch [17/50], Step [519/735], Loss: 0.0308\n",
      "Epoch [17/50], Step [520/735], Loss: 0.0578\n",
      "Epoch [17/50], Step [521/735], Loss: 0.3021\n",
      "Epoch [17/50], Step [522/735], Loss: 0.4164\n",
      "Epoch [17/50], Step [523/735], Loss: 0.0421\n",
      "Epoch [17/50], Step [524/735], Loss: 0.0718\n",
      "Epoch [17/50], Step [525/735], Loss: 0.1118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Step [526/735], Loss: 0.1103\n",
      "Epoch [17/50], Step [527/735], Loss: 0.0972\n",
      "Epoch [17/50], Step [528/735], Loss: 0.0692\n",
      "Epoch [17/50], Step [529/735], Loss: 0.1280\n",
      "Epoch [17/50], Step [530/735], Loss: 0.0648\n",
      "Epoch [17/50], Step [531/735], Loss: 0.0604\n",
      "Epoch [17/50], Step [532/735], Loss: 0.0891\n",
      "Epoch [17/50], Step [533/735], Loss: 0.1531\n",
      "Epoch [17/50], Step [534/735], Loss: 0.0612\n",
      "Epoch [17/50], Step [535/735], Loss: 0.1686\n",
      "Epoch [17/50], Step [536/735], Loss: 0.1014\n",
      "Epoch [17/50], Step [537/735], Loss: 0.1566\n",
      "Epoch [17/50], Step [538/735], Loss: 0.0290\n",
      "Epoch [17/50], Step [539/735], Loss: 0.0414\n",
      "Epoch [17/50], Step [540/735], Loss: 0.1405\n",
      "Epoch [17/50], Step [541/735], Loss: 0.0327\n",
      "Epoch [17/50], Step [542/735], Loss: 0.0683\n",
      "Epoch [17/50], Step [543/735], Loss: 0.1663\n",
      "Epoch [17/50], Step [544/735], Loss: 0.3004\n",
      "Epoch [17/50], Step [545/735], Loss: 0.0290\n",
      "Epoch [17/50], Step [546/735], Loss: 0.0331\n",
      "Epoch [17/50], Step [547/735], Loss: 0.0333\n",
      "Epoch [17/50], Step [548/735], Loss: 0.1411\n",
      "Epoch [17/50], Step [549/735], Loss: 0.0497\n",
      "Epoch [17/50], Step [550/735], Loss: 0.0456\n",
      "Epoch [17/50], Step [551/735], Loss: 0.0554\n",
      "Epoch [17/50], Step [552/735], Loss: 0.0752\n",
      "Epoch [17/50], Step [553/735], Loss: 0.1420\n",
      "Epoch [17/50], Step [554/735], Loss: 0.6027\n",
      "Epoch [17/50], Step [555/735], Loss: 0.0365\n",
      "Epoch [17/50], Step [556/735], Loss: 0.0473\n",
      "Epoch [17/50], Step [557/735], Loss: 0.2756\n",
      "Epoch [17/50], Step [558/735], Loss: 0.1308\n",
      "Epoch [17/50], Step [559/735], Loss: 0.0175\n",
      "Epoch [17/50], Step [560/735], Loss: 0.1323\n",
      "Epoch [17/50], Step [561/735], Loss: 0.1929\n",
      "Epoch [17/50], Step [562/735], Loss: 0.0531\n",
      "Epoch [17/50], Step [563/735], Loss: 0.0356\n",
      "Epoch [17/50], Step [564/735], Loss: 0.1280\n",
      "Epoch [17/50], Step [565/735], Loss: 0.0965\n",
      "Epoch [17/50], Step [566/735], Loss: 0.1154\n",
      "Epoch [17/50], Step [567/735], Loss: 0.0485\n",
      "Epoch [17/50], Step [568/735], Loss: 0.0645\n",
      "Epoch [17/50], Step [569/735], Loss: 0.1283\n",
      "Epoch [17/50], Step [570/735], Loss: 0.0943\n",
      "Epoch [17/50], Step [571/735], Loss: 0.0271\n",
      "Epoch [17/50], Step [572/735], Loss: 0.0790\n",
      "Epoch [17/50], Step [573/735], Loss: 0.0332\n",
      "Epoch [17/50], Step [574/735], Loss: 0.0859\n",
      "Epoch [17/50], Step [575/735], Loss: 0.0320\n",
      "Epoch [17/50], Step [576/735], Loss: 0.1635\n",
      "Epoch [17/50], Step [577/735], Loss: 0.0967\n",
      "Epoch [17/50], Step [578/735], Loss: 0.0875\n",
      "Epoch [17/50], Step [579/735], Loss: 0.0321\n",
      "Epoch [17/50], Step [580/735], Loss: 0.0624\n",
      "Epoch [17/50], Step [581/735], Loss: 0.0230\n",
      "Epoch [17/50], Step [582/735], Loss: 0.0442\n",
      "Epoch [17/50], Step [583/735], Loss: 0.1637\n",
      "Epoch [17/50], Step [584/735], Loss: 0.1671\n",
      "Epoch [17/50], Step [585/735], Loss: 0.0660\n",
      "Epoch [17/50], Step [586/735], Loss: 0.0360\n",
      "Epoch [17/50], Step [587/735], Loss: 0.0714\n",
      "Epoch [17/50], Step [588/735], Loss: 0.0911\n",
      "Epoch [17/50], Step [589/735], Loss: 0.1058\n",
      "Epoch [17/50], Step [590/735], Loss: 0.1273\n",
      "Epoch [17/50], Step [591/735], Loss: 0.1323\n",
      "Epoch [17/50], Step [592/735], Loss: 0.0274\n",
      "Epoch [17/50], Step [593/735], Loss: 0.0670\n",
      "Epoch [17/50], Step [594/735], Loss: 0.0581\n",
      "Epoch [17/50], Step [595/735], Loss: 0.1056\n",
      "Epoch [17/50], Step [596/735], Loss: 0.2752\n",
      "Epoch [17/50], Step [597/735], Loss: 0.0398\n",
      "Epoch [17/50], Step [598/735], Loss: 0.2115\n",
      "Epoch [17/50], Step [599/735], Loss: 0.0368\n",
      "Epoch [17/50], Step [600/735], Loss: 0.1529\n",
      "Epoch [17/50], Step [601/735], Loss: 0.0604\n",
      "Epoch [17/50], Step [602/735], Loss: 0.0750\n",
      "Epoch [17/50], Step [603/735], Loss: 0.0848\n",
      "Epoch [17/50], Step [604/735], Loss: 0.5680\n",
      "Epoch [17/50], Step [605/735], Loss: 0.0597\n",
      "Epoch [17/50], Step [606/735], Loss: 0.0591\n",
      "Epoch [17/50], Step [607/735], Loss: 0.0635\n",
      "Epoch [17/50], Step [608/735], Loss: 0.1629\n",
      "Epoch [17/50], Step [609/735], Loss: 0.2935\n",
      "Epoch [17/50], Step [610/735], Loss: 0.1302\n",
      "Epoch [17/50], Step [611/735], Loss: 0.0633\n",
      "Epoch [17/50], Step [612/735], Loss: 0.0453\n",
      "Epoch [17/50], Step [613/735], Loss: 0.0675\n",
      "Epoch [17/50], Step [614/735], Loss: 0.0644\n",
      "Epoch [17/50], Step [615/735], Loss: 0.0506\n",
      "Epoch [17/50], Step [616/735], Loss: 0.2489\n",
      "Epoch [17/50], Step [617/735], Loss: 0.0839\n",
      "Epoch [17/50], Step [618/735], Loss: 0.1790\n",
      "Epoch [17/50], Step [619/735], Loss: 0.3691\n",
      "Epoch [17/50], Step [620/735], Loss: 0.1397\n",
      "Epoch [17/50], Step [621/735], Loss: 0.0661\n",
      "Epoch [17/50], Step [622/735], Loss: 0.0287\n",
      "Epoch [17/50], Step [623/735], Loss: 0.0242\n",
      "Epoch [17/50], Step [624/735], Loss: 0.0791\n",
      "Epoch [17/50], Step [625/735], Loss: 0.0596\n",
      "Epoch [17/50], Step [626/735], Loss: 0.2554\n",
      "Epoch [17/50], Step [627/735], Loss: 0.1838\n",
      "Epoch [17/50], Step [628/735], Loss: 0.0849\n",
      "Epoch [17/50], Step [629/735], Loss: 0.0216\n",
      "Epoch [17/50], Step [630/735], Loss: 0.0414\n",
      "Epoch [17/50], Step [631/735], Loss: 0.0806\n",
      "Epoch [17/50], Step [632/735], Loss: 0.0760\n",
      "Epoch [17/50], Step [633/735], Loss: 0.0616\n",
      "Epoch [17/50], Step [634/735], Loss: 0.0623\n",
      "Epoch [17/50], Step [635/735], Loss: 0.0344\n",
      "Epoch [17/50], Step [636/735], Loss: 0.0208\n",
      "Epoch [17/50], Step [637/735], Loss: 0.0456\n",
      "Epoch [17/50], Step [638/735], Loss: 0.0318\n",
      "Epoch [17/50], Step [639/735], Loss: 0.0488\n",
      "Epoch [17/50], Step [640/735], Loss: 0.2062\n",
      "Epoch [17/50], Step [641/735], Loss: 0.0645\n",
      "Epoch [17/50], Step [642/735], Loss: 0.2960\n",
      "Epoch [17/50], Step [643/735], Loss: 0.0540\n",
      "Epoch [17/50], Step [644/735], Loss: 0.0557\n",
      "Epoch [17/50], Step [645/735], Loss: 0.1016\n",
      "Epoch [17/50], Step [646/735], Loss: 0.0270\n",
      "Epoch [17/50], Step [647/735], Loss: 0.1114\n",
      "Epoch [17/50], Step [648/735], Loss: 0.0796\n",
      "Epoch [17/50], Step [649/735], Loss: 0.1230\n",
      "Epoch [17/50], Step [650/735], Loss: 0.0494\n",
      "Epoch [17/50], Step [651/735], Loss: 0.0453\n",
      "Epoch [17/50], Step [652/735], Loss: 0.1951\n",
      "Epoch [17/50], Step [653/735], Loss: 0.0266\n",
      "Epoch [17/50], Step [654/735], Loss: 0.0484\n",
      "Epoch [17/50], Step [655/735], Loss: 0.0278\n",
      "Epoch [17/50], Step [656/735], Loss: 0.2099\n",
      "Epoch [17/50], Step [657/735], Loss: 0.0308\n",
      "Epoch [17/50], Step [658/735], Loss: 0.1620\n",
      "Epoch [17/50], Step [659/735], Loss: 0.0175\n",
      "Epoch [17/50], Step [660/735], Loss: 0.1417\n",
      "Epoch [17/50], Step [661/735], Loss: 0.0254\n",
      "Epoch [17/50], Step [662/735], Loss: 0.4522\n",
      "Epoch [17/50], Step [663/735], Loss: 0.0765\n",
      "Epoch [17/50], Step [664/735], Loss: 0.2634\n",
      "Epoch [17/50], Step [665/735], Loss: 0.0298\n",
      "Epoch [17/50], Step [666/735], Loss: 0.0795\n",
      "Epoch [17/50], Step [667/735], Loss: 0.0915\n",
      "Epoch [17/50], Step [668/735], Loss: 0.1777\n",
      "Epoch [17/50], Step [669/735], Loss: 0.0690\n",
      "Epoch [17/50], Step [670/735], Loss: 0.0937\n",
      "Epoch [17/50], Step [671/735], Loss: 0.1147\n",
      "Epoch [17/50], Step [672/735], Loss: 0.1589\n",
      "Epoch [17/50], Step [673/735], Loss: 0.0417\n",
      "Epoch [17/50], Step [674/735], Loss: 0.0562\n",
      "Epoch [17/50], Step [675/735], Loss: 0.0396\n",
      "Epoch [17/50], Step [676/735], Loss: 0.0895\n",
      "Epoch [17/50], Step [677/735], Loss: 0.2315\n",
      "Epoch [17/50], Step [678/735], Loss: 0.0919\n",
      "Epoch [17/50], Step [679/735], Loss: 0.0728\n",
      "Epoch [17/50], Step [680/735], Loss: 0.2629\n",
      "Epoch [17/50], Step [681/735], Loss: 0.0667\n",
      "Epoch [17/50], Step [682/735], Loss: 0.0924\n",
      "Epoch [17/50], Step [683/735], Loss: 0.0440\n",
      "Epoch [17/50], Step [684/735], Loss: 0.0462\n",
      "Epoch [17/50], Step [685/735], Loss: 0.2203\n",
      "Epoch [17/50], Step [686/735], Loss: 0.0823\n",
      "Epoch [17/50], Step [687/735], Loss: 0.0523\n",
      "Epoch [17/50], Step [688/735], Loss: 0.1746\n",
      "Epoch [17/50], Step [689/735], Loss: 0.0216\n",
      "Epoch [17/50], Step [690/735], Loss: 0.1821\n",
      "Epoch [17/50], Step [691/735], Loss: 0.0893\n",
      "Epoch [17/50], Step [692/735], Loss: 0.3477\n",
      "Epoch [17/50], Step [693/735], Loss: 0.0599\n",
      "Epoch [17/50], Step [694/735], Loss: 0.1805\n",
      "Epoch [17/50], Step [695/735], Loss: 0.0626\n",
      "Epoch [17/50], Step [696/735], Loss: 0.0664\n",
      "Epoch [17/50], Step [697/735], Loss: 0.2263\n",
      "Epoch [17/50], Step [698/735], Loss: 0.2121\n",
      "Epoch [17/50], Step [699/735], Loss: 0.0691\n",
      "Epoch [17/50], Step [700/735], Loss: 0.0486\n",
      "Epoch [17/50], Step [701/735], Loss: 0.0842\n",
      "Epoch [17/50], Step [702/735], Loss: 0.0902\n",
      "Epoch [17/50], Step [703/735], Loss: 0.2951\n",
      "Epoch [17/50], Step [704/735], Loss: 0.0356\n",
      "Epoch [17/50], Step [705/735], Loss: 0.0254\n",
      "Epoch [17/50], Step [706/735], Loss: 0.0637\n",
      "Epoch [17/50], Step [707/735], Loss: 0.1263\n",
      "Epoch [17/50], Step [708/735], Loss: 0.0288\n",
      "Epoch [17/50], Step [709/735], Loss: 0.2361\n",
      "Epoch [17/50], Step [710/735], Loss: 0.2836\n",
      "Epoch [17/50], Step [711/735], Loss: 0.0460\n",
      "Epoch [17/50], Step [712/735], Loss: 0.0542\n",
      "Epoch [17/50], Step [713/735], Loss: 0.0240\n",
      "Epoch [17/50], Step [714/735], Loss: 0.0276\n",
      "Epoch [17/50], Step [715/735], Loss: 0.1038\n",
      "Epoch [17/50], Step [716/735], Loss: 0.0353\n",
      "Epoch [17/50], Step [717/735], Loss: 0.0343\n",
      "Epoch [17/50], Step [718/735], Loss: 0.0875\n",
      "Epoch [17/50], Step [719/735], Loss: 0.1468\n",
      "Epoch [17/50], Step [720/735], Loss: 0.0465\n",
      "Epoch [17/50], Step [721/735], Loss: 0.1055\n",
      "Epoch [17/50], Step [722/735], Loss: 0.0417\n",
      "Epoch [17/50], Step [723/735], Loss: 0.0414\n",
      "Epoch [17/50], Step [724/735], Loss: 0.0425\n",
      "Epoch [17/50], Step [725/735], Loss: 0.0417\n",
      "Epoch [17/50], Step [726/735], Loss: 0.0439\n",
      "Epoch [17/50], Step [727/735], Loss: 0.0698\n",
      "Epoch [17/50], Step [728/735], Loss: 0.0877\n",
      "Epoch [17/50], Step [729/735], Loss: 0.0211\n",
      "Epoch [17/50], Step [730/735], Loss: 0.0540\n",
      "Epoch [17/50], Step [731/735], Loss: 0.0131\n",
      "Epoch [17/50], Step [732/735], Loss: 0.1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Step [733/735], Loss: 0.1122\n",
      "Epoch [17/50], Step [734/735], Loss: 0.0330\n",
      "Epoch [17/50], Step [735/735], Loss: 0.1164\n",
      "Epoch [18/50], Step [1/735], Loss: 0.0397\n",
      "Epoch [18/50], Step [2/735], Loss: 0.1683\n",
      "Epoch [18/50], Step [3/735], Loss: 0.0382\n",
      "Epoch [18/50], Step [4/735], Loss: 0.0246\n",
      "Epoch [18/50], Step [5/735], Loss: 0.0820\n",
      "Epoch [18/50], Step [6/735], Loss: 0.0514\n",
      "Epoch [18/50], Step [7/735], Loss: 0.0500\n",
      "Epoch [18/50], Step [8/735], Loss: 0.0339\n",
      "Epoch [18/50], Step [9/735], Loss: 0.1974\n",
      "Epoch [18/50], Step [10/735], Loss: 0.2666\n",
      "Epoch [18/50], Step [11/735], Loss: 0.0222\n",
      "Epoch [18/50], Step [12/735], Loss: 0.0437\n",
      "Epoch [18/50], Step [13/735], Loss: 0.0731\n",
      "Epoch [18/50], Step [14/735], Loss: 0.0710\n",
      "Epoch [18/50], Step [15/735], Loss: 0.0838\n",
      "Epoch [18/50], Step [16/735], Loss: 0.4533\n",
      "Epoch [18/50], Step [17/735], Loss: 0.1787\n",
      "Epoch [18/50], Step [18/735], Loss: 0.0885\n",
      "Epoch [18/50], Step [19/735], Loss: 0.0960\n",
      "Epoch [18/50], Step [20/735], Loss: 0.0934\n",
      "Epoch [18/50], Step [21/735], Loss: 0.0258\n",
      "Epoch [18/50], Step [22/735], Loss: 0.1335\n",
      "Epoch [18/50], Step [23/735], Loss: 0.0396\n",
      "Epoch [18/50], Step [24/735], Loss: 0.1885\n",
      "Epoch [18/50], Step [25/735], Loss: 0.0436\n",
      "Epoch [18/50], Step [26/735], Loss: 0.1330\n",
      "Epoch [18/50], Step [27/735], Loss: 0.0633\n",
      "Epoch [18/50], Step [28/735], Loss: 0.1123\n",
      "Epoch [18/50], Step [29/735], Loss: 0.1015\n",
      "Epoch [18/50], Step [30/735], Loss: 0.3741\n",
      "Epoch [18/50], Step [31/735], Loss: 0.0816\n",
      "Epoch [18/50], Step [32/735], Loss: 0.0959\n",
      "Epoch [18/50], Step [33/735], Loss: 0.0380\n",
      "Epoch [18/50], Step [34/735], Loss: 0.0349\n",
      "Epoch [18/50], Step [35/735], Loss: 0.0422\n",
      "Epoch [18/50], Step [36/735], Loss: 0.0586\n",
      "Epoch [18/50], Step [37/735], Loss: 0.0281\n",
      "Epoch [18/50], Step [38/735], Loss: 0.2290\n",
      "Epoch [18/50], Step [39/735], Loss: 0.3342\n",
      "Epoch [18/50], Step [40/735], Loss: 0.0248\n",
      "Epoch [18/50], Step [41/735], Loss: 0.0268\n",
      "Epoch [18/50], Step [42/735], Loss: 0.0407\n",
      "Epoch [18/50], Step [43/735], Loss: 0.0693\n",
      "Epoch [18/50], Step [44/735], Loss: 0.0292\n",
      "Epoch [18/50], Step [45/735], Loss: 0.1837\n",
      "Epoch [18/50], Step [46/735], Loss: 0.0719\n",
      "Epoch [18/50], Step [47/735], Loss: 0.0749\n",
      "Epoch [18/50], Step [48/735], Loss: 0.0826\n",
      "Epoch [18/50], Step [49/735], Loss: 0.1627\n",
      "Epoch [18/50], Step [50/735], Loss: 0.0499\n",
      "Epoch [18/50], Step [51/735], Loss: 0.0760\n",
      "Epoch [18/50], Step [52/735], Loss: 0.0638\n",
      "Epoch [18/50], Step [53/735], Loss: 0.0542\n",
      "Epoch [18/50], Step [54/735], Loss: 0.0259\n",
      "Epoch [18/50], Step [55/735], Loss: 0.1140\n",
      "Epoch [18/50], Step [56/735], Loss: 0.0682\n",
      "Epoch [18/50], Step [57/735], Loss: 0.1951\n",
      "Epoch [18/50], Step [58/735], Loss: 0.0828\n",
      "Epoch [18/50], Step [59/735], Loss: 0.0532\n",
      "Epoch [18/50], Step [60/735], Loss: 0.0803\n",
      "Epoch [18/50], Step [61/735], Loss: 0.1119\n",
      "Epoch [18/50], Step [62/735], Loss: 0.0837\n",
      "Epoch [18/50], Step [63/735], Loss: 0.0730\n",
      "Epoch [18/50], Step [64/735], Loss: 0.0393\n",
      "Epoch [18/50], Step [65/735], Loss: 0.0365\n",
      "Epoch [18/50], Step [66/735], Loss: 0.3317\n",
      "Epoch [18/50], Step [67/735], Loss: 0.0906\n",
      "Epoch [18/50], Step [68/735], Loss: 0.2958\n",
      "Epoch [18/50], Step [69/735], Loss: 0.0260\n",
      "Epoch [18/50], Step [70/735], Loss: 0.1617\n",
      "Epoch [18/50], Step [71/735], Loss: 0.0796\n",
      "Epoch [18/50], Step [72/735], Loss: 0.0456\n",
      "Epoch [18/50], Step [73/735], Loss: 0.0473\n",
      "Epoch [18/50], Step [74/735], Loss: 0.0538\n",
      "Epoch [18/50], Step [75/735], Loss: 0.0790\n",
      "Epoch [18/50], Step [76/735], Loss: 0.0599\n",
      "Epoch [18/50], Step [77/735], Loss: 0.0234\n",
      "Epoch [18/50], Step [78/735], Loss: 0.0516\n",
      "Epoch [18/50], Step [79/735], Loss: 0.1513\n",
      "Epoch [18/50], Step [80/735], Loss: 0.0479\n",
      "Epoch [18/50], Step [81/735], Loss: 0.1110\n",
      "Epoch [18/50], Step [82/735], Loss: 0.0182\n",
      "Epoch [18/50], Step [83/735], Loss: 0.0595\n",
      "Epoch [18/50], Step [84/735], Loss: 0.0484\n",
      "Epoch [18/50], Step [85/735], Loss: 0.0361\n",
      "Epoch [18/50], Step [86/735], Loss: 0.0220\n",
      "Epoch [18/50], Step [87/735], Loss: 0.0509\n",
      "Epoch [18/50], Step [88/735], Loss: 0.0726\n",
      "Epoch [18/50], Step [89/735], Loss: 0.1497\n",
      "Epoch [18/50], Step [90/735], Loss: 0.0424\n",
      "Epoch [18/50], Step [91/735], Loss: 0.0452\n",
      "Epoch [18/50], Step [92/735], Loss: 0.0872\n",
      "Epoch [18/50], Step [93/735], Loss: 0.0660\n",
      "Epoch [18/50], Step [94/735], Loss: 0.0668\n",
      "Epoch [18/50], Step [95/735], Loss: 0.0843\n",
      "Epoch [18/50], Step [96/735], Loss: 0.0379\n",
      "Epoch [18/50], Step [97/735], Loss: 0.1130\n",
      "Epoch [18/50], Step [98/735], Loss: 0.1145\n",
      "Epoch [18/50], Step [99/735], Loss: 0.0267\n",
      "Epoch [18/50], Step [100/735], Loss: 0.1964\n",
      "Epoch [18/50], Step [101/735], Loss: 0.0380\n",
      "Epoch [18/50], Step [102/735], Loss: 0.5343\n",
      "Epoch [18/50], Step [103/735], Loss: 0.0846\n",
      "Epoch [18/50], Step [104/735], Loss: 0.2422\n",
      "Epoch [18/50], Step [105/735], Loss: 0.0399\n",
      "Epoch [18/50], Step [106/735], Loss: 0.0554\n",
      "Epoch [18/50], Step [107/735], Loss: 0.0539\n",
      "Epoch [18/50], Step [108/735], Loss: 0.0414\n",
      "Epoch [18/50], Step [109/735], Loss: 0.0189\n",
      "Epoch [18/50], Step [110/735], Loss: 0.0489\n",
      "Epoch [18/50], Step [111/735], Loss: 0.1443\n",
      "Epoch [18/50], Step [112/735], Loss: 0.0582\n",
      "Epoch [18/50], Step [113/735], Loss: 0.1177\n",
      "Epoch [18/50], Step [114/735], Loss: 0.1369\n",
      "Epoch [18/50], Step [115/735], Loss: 0.0710\n",
      "Epoch [18/50], Step [116/735], Loss: 0.0341\n",
      "Epoch [18/50], Step [117/735], Loss: 0.0386\n",
      "Epoch [18/50], Step [118/735], Loss: 0.0559\n",
      "Epoch [18/50], Step [119/735], Loss: 0.0552\n",
      "Epoch [18/50], Step [120/735], Loss: 0.0580\n",
      "Epoch [18/50], Step [121/735], Loss: 0.0599\n",
      "Epoch [18/50], Step [122/735], Loss: 0.0589\n",
      "Epoch [18/50], Step [123/735], Loss: 0.0649\n",
      "Epoch [18/50], Step [124/735], Loss: 0.1078\n",
      "Epoch [18/50], Step [125/735], Loss: 0.0788\n",
      "Epoch [18/50], Step [126/735], Loss: 0.0306\n",
      "Epoch [18/50], Step [127/735], Loss: 0.0675\n",
      "Epoch [18/50], Step [128/735], Loss: 0.0495\n",
      "Epoch [18/50], Step [129/735], Loss: 0.0339\n",
      "Epoch [18/50], Step [130/735], Loss: 0.0519\n",
      "Epoch [18/50], Step [131/735], Loss: 0.1151\n",
      "Epoch [18/50], Step [132/735], Loss: 0.0818\n",
      "Epoch [18/50], Step [133/735], Loss: 0.1476\n",
      "Epoch [18/50], Step [134/735], Loss: 0.1314\n",
      "Epoch [18/50], Step [135/735], Loss: 0.1332\n",
      "Epoch [18/50], Step [136/735], Loss: 0.0265\n",
      "Epoch [18/50], Step [137/735], Loss: 0.0562\n",
      "Epoch [18/50], Step [138/735], Loss: 0.0263\n",
      "Epoch [18/50], Step [139/735], Loss: 0.0340\n",
      "Epoch [18/50], Step [140/735], Loss: 0.0493\n",
      "Epoch [18/50], Step [141/735], Loss: 0.0952\n",
      "Epoch [18/50], Step [142/735], Loss: 0.1730\n",
      "Epoch [18/50], Step [143/735], Loss: 0.2802\n",
      "Epoch [18/50], Step [144/735], Loss: 0.0208\n",
      "Epoch [18/50], Step [145/735], Loss: 0.2987\n",
      "Epoch [18/50], Step [146/735], Loss: 0.0810\n",
      "Epoch [18/50], Step [147/735], Loss: 0.0877\n",
      "Epoch [18/50], Step [148/735], Loss: 0.0801\n",
      "Epoch [18/50], Step [149/735], Loss: 0.0536\n",
      "Epoch [18/50], Step [150/735], Loss: 0.0703\n",
      "Epoch [18/50], Step [151/735], Loss: 0.0304\n",
      "Epoch [18/50], Step [152/735], Loss: 0.0368\n",
      "Epoch [18/50], Step [153/735], Loss: 0.0339\n",
      "Epoch [18/50], Step [154/735], Loss: 0.0448\n",
      "Epoch [18/50], Step [155/735], Loss: 0.0813\n",
      "Epoch [18/50], Step [156/735], Loss: 0.0300\n",
      "Epoch [18/50], Step [157/735], Loss: 0.1006\n",
      "Epoch [18/50], Step [158/735], Loss: 0.0273\n",
      "Epoch [18/50], Step [159/735], Loss: 0.0581\n",
      "Epoch [18/50], Step [160/735], Loss: 0.0315\n",
      "Epoch [18/50], Step [161/735], Loss: 0.0374\n",
      "Epoch [18/50], Step [162/735], Loss: 0.0546\n",
      "Epoch [18/50], Step [163/735], Loss: 0.0465\n",
      "Epoch [18/50], Step [164/735], Loss: 0.0523\n",
      "Epoch [18/50], Step [165/735], Loss: 0.0937\n",
      "Epoch [18/50], Step [166/735], Loss: 0.0647\n",
      "Epoch [18/50], Step [167/735], Loss: 0.1199\n",
      "Epoch [18/50], Step [168/735], Loss: 0.1230\n",
      "Epoch [18/50], Step [169/735], Loss: 0.1689\n",
      "Epoch [18/50], Step [170/735], Loss: 0.4020\n",
      "Epoch [18/50], Step [171/735], Loss: 0.0723\n",
      "Epoch [18/50], Step [172/735], Loss: 0.0585\n",
      "Epoch [18/50], Step [173/735], Loss: 0.2468\n",
      "Epoch [18/50], Step [174/735], Loss: 0.3597\n",
      "Epoch [18/50], Step [175/735], Loss: 0.0118\n",
      "Epoch [18/50], Step [176/735], Loss: 0.0544\n",
      "Epoch [18/50], Step [177/735], Loss: 0.0371\n",
      "Epoch [18/50], Step [178/735], Loss: 0.2542\n",
      "Epoch [18/50], Step [179/735], Loss: 0.1235\n",
      "Epoch [18/50], Step [180/735], Loss: 0.0244\n",
      "Epoch [18/50], Step [181/735], Loss: 0.1093\n",
      "Epoch [18/50], Step [182/735], Loss: 0.1287\n",
      "Epoch [18/50], Step [183/735], Loss: 0.0349\n",
      "Epoch [18/50], Step [184/735], Loss: 0.0306\n",
      "Epoch [18/50], Step [185/735], Loss: 0.0684\n",
      "Epoch [18/50], Step [186/735], Loss: 0.1234\n",
      "Epoch [18/50], Step [187/735], Loss: 0.3446\n",
      "Epoch [18/50], Step [188/735], Loss: 0.1581\n",
      "Epoch [18/50], Step [189/735], Loss: 0.0449\n",
      "Epoch [18/50], Step [190/735], Loss: 0.0364\n",
      "Epoch [18/50], Step [191/735], Loss: 0.0924\n",
      "Epoch [18/50], Step [192/735], Loss: 0.0583\n",
      "Epoch [18/50], Step [193/735], Loss: 0.0416\n",
      "Epoch [18/50], Step [194/735], Loss: 0.0489\n",
      "Epoch [18/50], Step [195/735], Loss: 0.1052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Step [196/735], Loss: 0.0492\n",
      "Epoch [18/50], Step [197/735], Loss: 0.0270\n",
      "Epoch [18/50], Step [198/735], Loss: 0.0628\n",
      "Epoch [18/50], Step [199/735], Loss: 0.0494\n",
      "Epoch [18/50], Step [200/735], Loss: 0.1645\n",
      "Epoch [18/50], Step [201/735], Loss: 0.0791\n",
      "Epoch [18/50], Step [202/735], Loss: 0.1277\n",
      "Epoch [18/50], Step [203/735], Loss: 0.1672\n",
      "Epoch [18/50], Step [204/735], Loss: 0.2047\n",
      "Epoch [18/50], Step [205/735], Loss: 0.2009\n",
      "Epoch [18/50], Step [206/735], Loss: 0.0481\n",
      "Epoch [18/50], Step [207/735], Loss: 0.0659\n",
      "Epoch [18/50], Step [208/735], Loss: 0.0384\n",
      "Epoch [18/50], Step [209/735], Loss: 0.1472\n",
      "Epoch [18/50], Step [210/735], Loss: 0.0822\n",
      "Epoch [18/50], Step [211/735], Loss: 0.1533\n",
      "Epoch [18/50], Step [212/735], Loss: 0.0455\n",
      "Epoch [18/50], Step [213/735], Loss: 0.0579\n",
      "Epoch [18/50], Step [214/735], Loss: 0.0832\n",
      "Epoch [18/50], Step [215/735], Loss: 0.0707\n",
      "Epoch [18/50], Step [216/735], Loss: 0.1285\n",
      "Epoch [18/50], Step [217/735], Loss: 0.0413\n",
      "Epoch [18/50], Step [218/735], Loss: 0.0353\n",
      "Epoch [18/50], Step [219/735], Loss: 0.0940\n",
      "Epoch [18/50], Step [220/735], Loss: 0.2004\n",
      "Epoch [18/50], Step [221/735], Loss: 0.0835\n",
      "Epoch [18/50], Step [222/735], Loss: 0.0338\n",
      "Epoch [18/50], Step [223/735], Loss: 0.0994\n",
      "Epoch [18/50], Step [224/735], Loss: 0.0574\n",
      "Epoch [18/50], Step [225/735], Loss: 0.0609\n",
      "Epoch [18/50], Step [226/735], Loss: 0.3250\n",
      "Epoch [18/50], Step [227/735], Loss: 0.1009\n",
      "Epoch [18/50], Step [228/735], Loss: 0.0813\n",
      "Epoch [18/50], Step [229/735], Loss: 0.2017\n",
      "Epoch [18/50], Step [230/735], Loss: 0.0515\n",
      "Epoch [18/50], Step [231/735], Loss: 0.1018\n",
      "Epoch [18/50], Step [232/735], Loss: 0.1007\n",
      "Epoch [18/50], Step [233/735], Loss: 0.0365\n",
      "Epoch [18/50], Step [234/735], Loss: 0.0565\n",
      "Epoch [18/50], Step [235/735], Loss: 0.0548\n",
      "Epoch [18/50], Step [236/735], Loss: 0.0306\n",
      "Epoch [18/50], Step [237/735], Loss: 0.0845\n",
      "Epoch [18/50], Step [238/735], Loss: 0.0352\n",
      "Epoch [18/50], Step [239/735], Loss: 0.0547\n",
      "Epoch [18/50], Step [240/735], Loss: 0.0576\n",
      "Epoch [18/50], Step [241/735], Loss: 0.1230\n",
      "Epoch [18/50], Step [242/735], Loss: 0.0616\n",
      "Epoch [18/50], Step [243/735], Loss: 0.0277\n",
      "Epoch [18/50], Step [244/735], Loss: 0.1148\n",
      "Epoch [18/50], Step [245/735], Loss: 0.1831\n",
      "Epoch [18/50], Step [246/735], Loss: 0.1077\n",
      "Epoch [18/50], Step [247/735], Loss: 0.0381\n",
      "Epoch [18/50], Step [248/735], Loss: 0.0517\n",
      "Epoch [18/50], Step [249/735], Loss: 0.1949\n",
      "Epoch [18/50], Step [250/735], Loss: 0.0175\n",
      "Epoch [18/50], Step [251/735], Loss: 0.0774\n",
      "Epoch [18/50], Step [252/735], Loss: 0.0937\n",
      "Epoch [18/50], Step [253/735], Loss: 0.0511\n",
      "Epoch [18/50], Step [254/735], Loss: 0.3385\n",
      "Epoch [18/50], Step [255/735], Loss: 0.0355\n",
      "Epoch [18/50], Step [256/735], Loss: 0.0419\n",
      "Epoch [18/50], Step [257/735], Loss: 0.0975\n",
      "Epoch [18/50], Step [258/735], Loss: 0.0259\n",
      "Epoch [18/50], Step [259/735], Loss: 0.1307\n",
      "Epoch [18/50], Step [260/735], Loss: 0.0864\n",
      "Epoch [18/50], Step [261/735], Loss: 0.0224\n",
      "Epoch [18/50], Step [262/735], Loss: 0.0803\n",
      "Epoch [18/50], Step [263/735], Loss: 0.0769\n",
      "Epoch [18/50], Step [264/735], Loss: 0.0580\n",
      "Epoch [18/50], Step [265/735], Loss: 0.0214\n",
      "Epoch [18/50], Step [266/735], Loss: 0.1040\n",
      "Epoch [18/50], Step [267/735], Loss: 0.0216\n",
      "Epoch [18/50], Step [268/735], Loss: 0.0547\n",
      "Epoch [18/50], Step [269/735], Loss: 0.0291\n",
      "Epoch [18/50], Step [270/735], Loss: 0.0954\n",
      "Epoch [18/50], Step [271/735], Loss: 0.0597\n",
      "Epoch [18/50], Step [272/735], Loss: 0.0329\n",
      "Epoch [18/50], Step [273/735], Loss: 0.4098\n",
      "Epoch [18/50], Step [274/735], Loss: 0.0311\n",
      "Epoch [18/50], Step [275/735], Loss: 0.1075\n",
      "Epoch [18/50], Step [276/735], Loss: 0.1381\n",
      "Epoch [18/50], Step [277/735], Loss: 0.1229\n",
      "Epoch [18/50], Step [278/735], Loss: 0.0709\n",
      "Epoch [18/50], Step [279/735], Loss: 0.1662\n",
      "Epoch [18/50], Step [280/735], Loss: 0.0668\n",
      "Epoch [18/50], Step [281/735], Loss: 0.0796\n",
      "Epoch [18/50], Step [282/735], Loss: 0.2225\n",
      "Epoch [18/50], Step [283/735], Loss: 0.1534\n",
      "Epoch [18/50], Step [284/735], Loss: 0.0636\n",
      "Epoch [18/50], Step [285/735], Loss: 0.0192\n",
      "Epoch [18/50], Step [286/735], Loss: 0.0527\n",
      "Epoch [18/50], Step [287/735], Loss: 0.0602\n",
      "Epoch [18/50], Step [288/735], Loss: 0.0895\n",
      "Epoch [18/50], Step [289/735], Loss: 0.0769\n",
      "Epoch [18/50], Step [290/735], Loss: 0.2962\n",
      "Epoch [18/50], Step [291/735], Loss: 0.0457\n",
      "Epoch [18/50], Step [292/735], Loss: 0.0838\n",
      "Epoch [18/50], Step [293/735], Loss: 0.1399\n",
      "Epoch [18/50], Step [294/735], Loss: 0.0401\n",
      "Epoch [18/50], Step [295/735], Loss: 0.0421\n",
      "Epoch [18/50], Step [296/735], Loss: 0.1239\n",
      "Epoch [18/50], Step [297/735], Loss: 0.1409\n",
      "Epoch [18/50], Step [298/735], Loss: 0.0548\n",
      "Epoch [18/50], Step [299/735], Loss: 0.0475\n",
      "Epoch [18/50], Step [300/735], Loss: 0.1975\n",
      "Epoch [18/50], Step [301/735], Loss: 0.1767\n",
      "Epoch [18/50], Step [302/735], Loss: 0.0958\n",
      "Epoch [18/50], Step [303/735], Loss: 0.0614\n",
      "Epoch [18/50], Step [304/735], Loss: 0.1415\n",
      "Epoch [18/50], Step [305/735], Loss: 0.1030\n",
      "Epoch [18/50], Step [306/735], Loss: 0.1519\n",
      "Epoch [18/50], Step [307/735], Loss: 0.0902\n",
      "Epoch [18/50], Step [308/735], Loss: 0.0506\n",
      "Epoch [18/50], Step [309/735], Loss: 0.0466\n",
      "Epoch [18/50], Step [310/735], Loss: 0.0383\n",
      "Epoch [18/50], Step [311/735], Loss: 0.0265\n",
      "Epoch [18/50], Step [312/735], Loss: 0.1063\n",
      "Epoch [18/50], Step [313/735], Loss: 0.0244\n",
      "Epoch [18/50], Step [314/735], Loss: 0.1043\n",
      "Epoch [18/50], Step [315/735], Loss: 0.3877\n",
      "Epoch [18/50], Step [316/735], Loss: 0.0363\n",
      "Epoch [18/50], Step [317/735], Loss: 0.0380\n",
      "Epoch [18/50], Step [318/735], Loss: 0.1432\n",
      "Epoch [18/50], Step [319/735], Loss: 0.1331\n",
      "Epoch [18/50], Step [320/735], Loss: 0.1110\n",
      "Epoch [18/50], Step [321/735], Loss: 0.1230\n",
      "Epoch [18/50], Step [322/735], Loss: 0.2381\n",
      "Epoch [18/50], Step [323/735], Loss: 0.0899\n",
      "Epoch [18/50], Step [324/735], Loss: 0.1341\n",
      "Epoch [18/50], Step [325/735], Loss: 0.4084\n",
      "Epoch [18/50], Step [326/735], Loss: 0.0554\n",
      "Epoch [18/50], Step [327/735], Loss: 0.0854\n",
      "Epoch [18/50], Step [328/735], Loss: 0.0597\n",
      "Epoch [18/50], Step [329/735], Loss: 0.1288\n",
      "Epoch [18/50], Step [330/735], Loss: 0.2257\n",
      "Epoch [18/50], Step [331/735], Loss: 0.1219\n",
      "Epoch [18/50], Step [332/735], Loss: 0.0406\n",
      "Epoch [18/50], Step [333/735], Loss: 0.0428\n",
      "Epoch [18/50], Step [334/735], Loss: 0.0703\n",
      "Epoch [18/50], Step [335/735], Loss: 0.0457\n",
      "Epoch [18/50], Step [336/735], Loss: 0.0342\n",
      "Epoch [18/50], Step [337/735], Loss: 0.0905\n",
      "Epoch [18/50], Step [338/735], Loss: 0.1045\n",
      "Epoch [18/50], Step [339/735], Loss: 0.0901\n",
      "Epoch [18/50], Step [340/735], Loss: 0.0518\n",
      "Epoch [18/50], Step [341/735], Loss: 0.0636\n",
      "Epoch [18/50], Step [342/735], Loss: 0.1347\n",
      "Epoch [18/50], Step [343/735], Loss: 0.0473\n",
      "Epoch [18/50], Step [344/735], Loss: 0.0382\n",
      "Epoch [18/50], Step [345/735], Loss: 0.0431\n",
      "Epoch [18/50], Step [346/735], Loss: 0.0719\n",
      "Epoch [18/50], Step [347/735], Loss: 0.0663\n",
      "Epoch [18/50], Step [348/735], Loss: 0.0450\n",
      "Epoch [18/50], Step [349/735], Loss: 0.0295\n",
      "Epoch [18/50], Step [350/735], Loss: 0.1549\n",
      "Epoch [18/50], Step [351/735], Loss: 0.1478\n",
      "Epoch [18/50], Step [352/735], Loss: 0.0187\n",
      "Epoch [18/50], Step [353/735], Loss: 0.2222\n",
      "Epoch [18/50], Step [354/735], Loss: 0.1024\n",
      "Epoch [18/50], Step [355/735], Loss: 0.0259\n",
      "Epoch [18/50], Step [356/735], Loss: 0.0802\n",
      "Epoch [18/50], Step [357/735], Loss: 0.9477\n",
      "Epoch [18/50], Step [358/735], Loss: 0.2135\n",
      "Epoch [18/50], Step [359/735], Loss: 0.1707\n",
      "Epoch [18/50], Step [360/735], Loss: 0.0368\n",
      "Epoch [18/50], Step [361/735], Loss: 0.1245\n",
      "Epoch [18/50], Step [362/735], Loss: 0.0520\n",
      "Epoch [18/50], Step [363/735], Loss: 0.2523\n",
      "Epoch [18/50], Step [364/735], Loss: 0.0528\n",
      "Epoch [18/50], Step [365/735], Loss: 0.1745\n",
      "Epoch [18/50], Step [366/735], Loss: 0.2533\n",
      "Epoch [18/50], Step [367/735], Loss: 0.0653\n",
      "Epoch [18/50], Step [368/735], Loss: 0.1895\n",
      "Epoch [18/50], Step [369/735], Loss: 0.0963\n",
      "Epoch [18/50], Step [370/735], Loss: 0.1585\n",
      "Epoch [18/50], Step [371/735], Loss: 0.3735\n",
      "Epoch [18/50], Step [372/735], Loss: 0.3195\n",
      "Epoch [18/50], Step [373/735], Loss: 0.0559\n",
      "Epoch [18/50], Step [374/735], Loss: 0.0753\n",
      "Epoch [18/50], Step [375/735], Loss: 0.0222\n",
      "Epoch [18/50], Step [376/735], Loss: 0.0205\n",
      "Epoch [18/50], Step [377/735], Loss: 0.0641\n",
      "Epoch [18/50], Step [378/735], Loss: 0.0973\n",
      "Epoch [18/50], Step [379/735], Loss: 0.0669\n",
      "Epoch [18/50], Step [380/735], Loss: 0.1786\n",
      "Epoch [18/50], Step [381/735], Loss: 0.1501\n",
      "Epoch [18/50], Step [382/735], Loss: 0.4171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Step [383/735], Loss: 0.0398\n",
      "Epoch [18/50], Step [384/735], Loss: 0.0301\n",
      "Epoch [18/50], Step [385/735], Loss: 0.2683\n",
      "Epoch [18/50], Step [386/735], Loss: 0.0490\n",
      "Epoch [18/50], Step [387/735], Loss: 0.0314\n",
      "Epoch [18/50], Step [388/735], Loss: 0.2288\n",
      "Epoch [18/50], Step [389/735], Loss: 0.0975\n",
      "Epoch [18/50], Step [390/735], Loss: 0.2086\n",
      "Epoch [18/50], Step [391/735], Loss: 0.0643\n",
      "Epoch [18/50], Step [392/735], Loss: 0.0436\n",
      "Epoch [18/50], Step [393/735], Loss: 0.0463\n",
      "Epoch [18/50], Step [394/735], Loss: 0.0262\n",
      "Epoch [18/50], Step [395/735], Loss: 0.0953\n",
      "Epoch [18/50], Step [396/735], Loss: 0.0521\n",
      "Epoch [18/50], Step [397/735], Loss: 0.0373\n",
      "Epoch [18/50], Step [398/735], Loss: 0.1315\n",
      "Epoch [18/50], Step [399/735], Loss: 0.0227\n",
      "Epoch [18/50], Step [400/735], Loss: 0.0692\n",
      "Epoch [18/50], Step [401/735], Loss: 0.0449\n",
      "Epoch [18/50], Step [402/735], Loss: 0.0502\n",
      "Epoch [18/50], Step [403/735], Loss: 0.0702\n",
      "Epoch [18/50], Step [404/735], Loss: 0.0467\n",
      "Epoch [18/50], Step [405/735], Loss: 0.1486\n",
      "Epoch [18/50], Step [406/735], Loss: 0.0338\n",
      "Epoch [18/50], Step [407/735], Loss: 0.0436\n",
      "Epoch [18/50], Step [408/735], Loss: 0.1474\n",
      "Epoch [18/50], Step [409/735], Loss: 0.0702\n",
      "Epoch [18/50], Step [410/735], Loss: 0.0627\n",
      "Epoch [18/50], Step [411/735], Loss: 0.0985\n",
      "Epoch [18/50], Step [412/735], Loss: 0.0434\n",
      "Epoch [18/50], Step [413/735], Loss: 0.0968\n",
      "Epoch [18/50], Step [414/735], Loss: 0.1084\n",
      "Epoch [18/50], Step [415/735], Loss: 0.1007\n",
      "Epoch [18/50], Step [416/735], Loss: 0.1425\n",
      "Epoch [18/50], Step [417/735], Loss: 0.1897\n",
      "Epoch [18/50], Step [418/735], Loss: 0.1243\n",
      "Epoch [18/50], Step [419/735], Loss: 0.0843\n",
      "Epoch [18/50], Step [420/735], Loss: 0.1628\n",
      "Epoch [18/50], Step [421/735], Loss: 0.0724\n",
      "Epoch [18/50], Step [422/735], Loss: 0.0621\n",
      "Epoch [18/50], Step [423/735], Loss: 0.0609\n",
      "Epoch [18/50], Step [424/735], Loss: 0.0261\n",
      "Epoch [18/50], Step [425/735], Loss: 0.0459\n",
      "Epoch [18/50], Step [426/735], Loss: 0.0469\n",
      "Epoch [18/50], Step [427/735], Loss: 0.0635\n",
      "Epoch [18/50], Step [428/735], Loss: 0.0433\n",
      "Epoch [18/50], Step [429/735], Loss: 0.0699\n",
      "Epoch [18/50], Step [430/735], Loss: 0.0517\n",
      "Epoch [18/50], Step [431/735], Loss: 0.0321\n",
      "Epoch [18/50], Step [432/735], Loss: 0.0562\n",
      "Epoch [18/50], Step [433/735], Loss: 0.0729\n",
      "Epoch [18/50], Step [434/735], Loss: 0.0821\n",
      "Epoch [18/50], Step [435/735], Loss: 0.1660\n",
      "Epoch [18/50], Step [436/735], Loss: 0.0763\n",
      "Epoch [18/50], Step [437/735], Loss: 0.1343\n",
      "Epoch [18/50], Step [438/735], Loss: 0.0757\n",
      "Epoch [18/50], Step [439/735], Loss: 0.0774\n",
      "Epoch [18/50], Step [440/735], Loss: 0.0476\n",
      "Epoch [18/50], Step [441/735], Loss: 0.0671\n",
      "Epoch [18/50], Step [442/735], Loss: 0.1200\n",
      "Epoch [18/50], Step [443/735], Loss: 0.1469\n",
      "Epoch [18/50], Step [444/735], Loss: 0.0465\n",
      "Epoch [18/50], Step [445/735], Loss: 0.1644\n",
      "Epoch [18/50], Step [446/735], Loss: 0.0508\n",
      "Epoch [18/50], Step [447/735], Loss: 0.3785\n",
      "Epoch [18/50], Step [448/735], Loss: 0.0970\n",
      "Epoch [18/50], Step [449/735], Loss: 0.1461\n",
      "Epoch [18/50], Step [450/735], Loss: 0.3301\n",
      "Epoch [18/50], Step [451/735], Loss: 0.1578\n",
      "Epoch [18/50], Step [452/735], Loss: 0.0552\n",
      "Epoch [18/50], Step [453/735], Loss: 0.0501\n",
      "Epoch [18/50], Step [454/735], Loss: 0.1913\n",
      "Epoch [18/50], Step [455/735], Loss: 0.0498\n",
      "Epoch [18/50], Step [456/735], Loss: 0.0647\n",
      "Epoch [18/50], Step [457/735], Loss: 0.0905\n",
      "Epoch [18/50], Step [458/735], Loss: 0.0713\n",
      "Epoch [18/50], Step [459/735], Loss: 0.1179\n",
      "Epoch [18/50], Step [460/735], Loss: 0.2676\n",
      "Epoch [18/50], Step [461/735], Loss: 0.1684\n",
      "Epoch [18/50], Step [462/735], Loss: 0.0283\n",
      "Epoch [18/50], Step [463/735], Loss: 0.0250\n",
      "Epoch [18/50], Step [464/735], Loss: 0.0434\n",
      "Epoch [18/50], Step [465/735], Loss: 0.0875\n",
      "Epoch [18/50], Step [466/735], Loss: 0.0308\n",
      "Epoch [18/50], Step [467/735], Loss: 0.0896\n",
      "Epoch [18/50], Step [468/735], Loss: 0.0628\n",
      "Epoch [18/50], Step [469/735], Loss: 0.0609\n",
      "Epoch [18/50], Step [470/735], Loss: 0.0522\n",
      "Epoch [18/50], Step [471/735], Loss: 0.0304\n",
      "Epoch [18/50], Step [472/735], Loss: 0.2243\n",
      "Epoch [18/50], Step [473/735], Loss: 0.2115\n",
      "Epoch [18/50], Step [474/735], Loss: 0.0839\n",
      "Epoch [18/50], Step [475/735], Loss: 0.0463\n",
      "Epoch [18/50], Step [476/735], Loss: 0.0691\n",
      "Epoch [18/50], Step [477/735], Loss: 0.0412\n",
      "Epoch [18/50], Step [478/735], Loss: 0.0979\n",
      "Epoch [18/50], Step [479/735], Loss: 0.2063\n",
      "Epoch [18/50], Step [480/735], Loss: 0.0955\n",
      "Epoch [18/50], Step [481/735], Loss: 0.0844\n",
      "Epoch [18/50], Step [482/735], Loss: 0.0565\n",
      "Epoch [18/50], Step [483/735], Loss: 0.0579\n",
      "Epoch [18/50], Step [484/735], Loss: 0.0557\n",
      "Epoch [18/50], Step [485/735], Loss: 0.0473\n",
      "Epoch [18/50], Step [486/735], Loss: 0.0981\n",
      "Epoch [18/50], Step [487/735], Loss: 0.0745\n",
      "Epoch [18/50], Step [488/735], Loss: 0.0981\n",
      "Epoch [18/50], Step [489/735], Loss: 0.0886\n",
      "Epoch [18/50], Step [490/735], Loss: 0.0276\n",
      "Epoch [18/50], Step [491/735], Loss: 0.0433\n",
      "Epoch [18/50], Step [492/735], Loss: 0.0461\n",
      "Epoch [18/50], Step [493/735], Loss: 0.0956\n",
      "Epoch [18/50], Step [494/735], Loss: 0.0397\n",
      "Epoch [18/50], Step [495/735], Loss: 0.0671\n",
      "Epoch [18/50], Step [496/735], Loss: 0.1623\n",
      "Epoch [18/50], Step [497/735], Loss: 0.1772\n",
      "Epoch [18/50], Step [498/735], Loss: 0.3655\n",
      "Epoch [18/50], Step [499/735], Loss: 0.0779\n",
      "Epoch [18/50], Step [500/735], Loss: 0.4751\n",
      "Epoch [18/50], Step [501/735], Loss: 0.0692\n",
      "Epoch [18/50], Step [502/735], Loss: 0.0475\n",
      "Epoch [18/50], Step [503/735], Loss: 0.0502\n",
      "Epoch [18/50], Step [504/735], Loss: 0.0332\n",
      "Epoch [18/50], Step [505/735], Loss: 0.0980\n",
      "Epoch [18/50], Step [506/735], Loss: 0.0598\n",
      "Epoch [18/50], Step [507/735], Loss: 0.0547\n",
      "Epoch [18/50], Step [508/735], Loss: 0.0518\n",
      "Epoch [18/50], Step [509/735], Loss: 0.0430\n",
      "Epoch [18/50], Step [510/735], Loss: 0.0462\n",
      "Epoch [18/50], Step [511/735], Loss: 0.0305\n",
      "Epoch [18/50], Step [512/735], Loss: 0.0229\n",
      "Epoch [18/50], Step [513/735], Loss: 0.1328\n",
      "Epoch [18/50], Step [514/735], Loss: 0.0333\n",
      "Epoch [18/50], Step [515/735], Loss: 0.1127\n",
      "Epoch [18/50], Step [516/735], Loss: 0.0443\n",
      "Epoch [18/50], Step [517/735], Loss: 0.0528\n",
      "Epoch [18/50], Step [518/735], Loss: 0.1930\n",
      "Epoch [18/50], Step [519/735], Loss: 0.0423\n",
      "Epoch [18/50], Step [520/735], Loss: 0.0840\n",
      "Epoch [18/50], Step [521/735], Loss: 0.0932\n",
      "Epoch [18/50], Step [522/735], Loss: 0.1095\n",
      "Epoch [18/50], Step [523/735], Loss: 0.1429\n",
      "Epoch [18/50], Step [524/735], Loss: 0.0267\n",
      "Epoch [18/50], Step [525/735], Loss: 0.0312\n",
      "Epoch [18/50], Step [526/735], Loss: 0.2652\n",
      "Epoch [18/50], Step [527/735], Loss: 0.0636\n",
      "Epoch [18/50], Step [528/735], Loss: 0.2818\n",
      "Epoch [18/50], Step [529/735], Loss: 0.1839\n",
      "Epoch [18/50], Step [530/735], Loss: 0.0595\n",
      "Epoch [18/50], Step [531/735], Loss: 0.0256\n",
      "Epoch [18/50], Step [532/735], Loss: 0.0200\n",
      "Epoch [18/50], Step [533/735], Loss: 0.2376\n",
      "Epoch [18/50], Step [534/735], Loss: 0.0470\n",
      "Epoch [18/50], Step [535/735], Loss: 0.0274\n",
      "Epoch [18/50], Step [536/735], Loss: 0.0667\n",
      "Epoch [18/50], Step [537/735], Loss: 0.0243\n",
      "Epoch [18/50], Step [538/735], Loss: 0.1125\n",
      "Epoch [18/50], Step [539/735], Loss: 0.1178\n",
      "Epoch [18/50], Step [540/735], Loss: 0.0360\n",
      "Epoch [18/50], Step [541/735], Loss: 0.0221\n",
      "Epoch [18/50], Step [542/735], Loss: 0.1276\n",
      "Epoch [18/50], Step [543/735], Loss: 0.0950\n",
      "Epoch [18/50], Step [544/735], Loss: 0.0787\n",
      "Epoch [18/50], Step [545/735], Loss: 0.1216\n",
      "Epoch [18/50], Step [546/735], Loss: 0.0522\n",
      "Epoch [18/50], Step [547/735], Loss: 0.0477\n",
      "Epoch [18/50], Step [548/735], Loss: 0.1013\n",
      "Epoch [18/50], Step [549/735], Loss: 0.1249\n",
      "Epoch [18/50], Step [550/735], Loss: 0.1047\n",
      "Epoch [18/50], Step [551/735], Loss: 0.0306\n",
      "Epoch [18/50], Step [552/735], Loss: 0.3539\n",
      "Epoch [18/50], Step [553/735], Loss: 0.2366\n",
      "Epoch [18/50], Step [554/735], Loss: 0.0220\n",
      "Epoch [18/50], Step [555/735], Loss: 0.0658\n",
      "Epoch [18/50], Step [556/735], Loss: 0.1063\n",
      "Epoch [18/50], Step [557/735], Loss: 0.0557\n",
      "Epoch [18/50], Step [558/735], Loss: 0.2070\n",
      "Epoch [18/50], Step [559/735], Loss: 0.1320\n",
      "Epoch [18/50], Step [560/735], Loss: 0.0304\n",
      "Epoch [18/50], Step [561/735], Loss: 0.1115\n",
      "Epoch [18/50], Step [562/735], Loss: 0.0754\n",
      "Epoch [18/50], Step [563/735], Loss: 0.0645\n",
      "Epoch [18/50], Step [564/735], Loss: 0.0780\n",
      "Epoch [18/50], Step [565/735], Loss: 0.0638\n",
      "Epoch [18/50], Step [566/735], Loss: 0.1139\n",
      "Epoch [18/50], Step [567/735], Loss: 0.1520\n",
      "Epoch [18/50], Step [568/735], Loss: 0.0407\n",
      "Epoch [18/50], Step [569/735], Loss: 0.0427\n",
      "Epoch [18/50], Step [570/735], Loss: 0.0664\n",
      "Epoch [18/50], Step [571/735], Loss: 0.2325\n",
      "Epoch [18/50], Step [572/735], Loss: 0.1649\n",
      "Epoch [18/50], Step [573/735], Loss: 0.1360\n",
      "Epoch [18/50], Step [574/735], Loss: 0.0543\n",
      "Epoch [18/50], Step [575/735], Loss: 0.0803\n",
      "Epoch [18/50], Step [576/735], Loss: 0.0407\n",
      "Epoch [18/50], Step [577/735], Loss: 0.2001\n",
      "Epoch [18/50], Step [578/735], Loss: 0.1161\n",
      "Epoch [18/50], Step [579/735], Loss: 0.1028\n",
      "Epoch [18/50], Step [580/735], Loss: 0.1485\n",
      "Epoch [18/50], Step [581/735], Loss: 0.0897\n",
      "Epoch [18/50], Step [582/735], Loss: 0.4059\n",
      "Epoch [18/50], Step [583/735], Loss: 0.1269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Step [584/735], Loss: 0.0601\n",
      "Epoch [18/50], Step [585/735], Loss: 0.0274\n",
      "Epoch [18/50], Step [586/735], Loss: 0.1379\n",
      "Epoch [18/50], Step [587/735], Loss: 0.0462\n",
      "Epoch [18/50], Step [588/735], Loss: 0.4602\n",
      "Epoch [18/50], Step [589/735], Loss: 0.1399\n",
      "Epoch [18/50], Step [590/735], Loss: 0.0800\n",
      "Epoch [18/50], Step [591/735], Loss: 0.0515\n",
      "Epoch [18/50], Step [592/735], Loss: 0.2105\n",
      "Epoch [18/50], Step [593/735], Loss: 0.2718\n",
      "Epoch [18/50], Step [594/735], Loss: 0.1273\n",
      "Epoch [18/50], Step [595/735], Loss: 0.0555\n",
      "Epoch [18/50], Step [596/735], Loss: 0.1428\n",
      "Epoch [18/50], Step [597/735], Loss: 0.0859\n",
      "Epoch [18/50], Step [598/735], Loss: 0.0249\n",
      "Epoch [18/50], Step [599/735], Loss: 0.0378\n",
      "Epoch [18/50], Step [600/735], Loss: 0.0611\n",
      "Epoch [18/50], Step [601/735], Loss: 0.0860\n",
      "Epoch [18/50], Step [602/735], Loss: 0.0385\n",
      "Epoch [18/50], Step [603/735], Loss: 0.0505\n",
      "Epoch [18/50], Step [604/735], Loss: 0.0325\n",
      "Epoch [18/50], Step [605/735], Loss: 0.0380\n",
      "Epoch [18/50], Step [606/735], Loss: 0.0987\n",
      "Epoch [18/50], Step [607/735], Loss: 0.0802\n",
      "Epoch [18/50], Step [608/735], Loss: 0.0832\n",
      "Epoch [18/50], Step [609/735], Loss: 0.0318\n",
      "Epoch [18/50], Step [610/735], Loss: 0.0183\n",
      "Epoch [18/50], Step [611/735], Loss: 0.0931\n",
      "Epoch [18/50], Step [612/735], Loss: 0.3754\n",
      "Epoch [18/50], Step [613/735], Loss: 0.1419\n",
      "Epoch [18/50], Step [614/735], Loss: 0.0895\n",
      "Epoch [18/50], Step [615/735], Loss: 0.0452\n",
      "Epoch [18/50], Step [616/735], Loss: 0.0616\n",
      "Epoch [18/50], Step [617/735], Loss: 0.1640\n",
      "Epoch [18/50], Step [618/735], Loss: 0.0310\n",
      "Epoch [18/50], Step [619/735], Loss: 0.0245\n",
      "Epoch [18/50], Step [620/735], Loss: 0.0697\n",
      "Epoch [18/50], Step [621/735], Loss: 0.3336\n",
      "Epoch [18/50], Step [622/735], Loss: 0.1006\n",
      "Epoch [18/50], Step [623/735], Loss: 0.0401\n",
      "Epoch [18/50], Step [624/735], Loss: 0.0241\n",
      "Epoch [18/50], Step [625/735], Loss: 0.1108\n",
      "Epoch [18/50], Step [626/735], Loss: 0.0425\n",
      "Epoch [18/50], Step [627/735], Loss: 0.0341\n",
      "Epoch [18/50], Step [628/735], Loss: 0.0336\n",
      "Epoch [18/50], Step [629/735], Loss: 0.1449\n",
      "Epoch [18/50], Step [630/735], Loss: 0.1400\n",
      "Epoch [18/50], Step [631/735], Loss: 0.1039\n",
      "Epoch [18/50], Step [632/735], Loss: 0.0943\n",
      "Epoch [18/50], Step [633/735], Loss: 0.0526\n",
      "Epoch [18/50], Step [634/735], Loss: 0.0467\n",
      "Epoch [18/50], Step [635/735], Loss: 0.0730\n",
      "Epoch [18/50], Step [636/735], Loss: 0.0808\n",
      "Epoch [18/50], Step [637/735], Loss: 0.0459\n",
      "Epoch [18/50], Step [638/735], Loss: 0.1572\n",
      "Epoch [18/50], Step [639/735], Loss: 0.0270\n",
      "Epoch [18/50], Step [640/735], Loss: 0.1323\n",
      "Epoch [18/50], Step [641/735], Loss: 0.2510\n",
      "Epoch [18/50], Step [642/735], Loss: 0.0738\n",
      "Epoch [18/50], Step [643/735], Loss: 0.1453\n",
      "Epoch [18/50], Step [644/735], Loss: 0.0260\n",
      "Epoch [18/50], Step [645/735], Loss: 0.5803\n",
      "Epoch [18/50], Step [646/735], Loss: 0.0462\n",
      "Epoch [18/50], Step [647/735], Loss: 0.0347\n",
      "Epoch [18/50], Step [648/735], Loss: 0.0770\n",
      "Epoch [18/50], Step [649/735], Loss: 0.0738\n",
      "Epoch [18/50], Step [650/735], Loss: 0.0855\n",
      "Epoch [18/50], Step [651/735], Loss: 0.1108\n",
      "Epoch [18/50], Step [652/735], Loss: 0.0719\n",
      "Epoch [18/50], Step [653/735], Loss: 0.0608\n",
      "Epoch [18/50], Step [654/735], Loss: 0.0929\n",
      "Epoch [18/50], Step [655/735], Loss: 0.0532\n",
      "Epoch [18/50], Step [656/735], Loss: 0.0436\n",
      "Epoch [18/50], Step [657/735], Loss: 0.0186\n",
      "Epoch [18/50], Step [658/735], Loss: 0.1179\n",
      "Epoch [18/50], Step [659/735], Loss: 0.1156\n",
      "Epoch [18/50], Step [660/735], Loss: 0.0437\n",
      "Epoch [18/50], Step [661/735], Loss: 0.0653\n",
      "Epoch [18/50], Step [662/735], Loss: 0.0535\n",
      "Epoch [18/50], Step [663/735], Loss: 0.1207\n",
      "Epoch [18/50], Step [664/735], Loss: 0.0283\n",
      "Epoch [18/50], Step [665/735], Loss: 0.0646\n",
      "Epoch [18/50], Step [666/735], Loss: 0.0791\n",
      "Epoch [18/50], Step [667/735], Loss: 0.0312\n",
      "Epoch [18/50], Step [668/735], Loss: 0.2303\n",
      "Epoch [18/50], Step [669/735], Loss: 0.0339\n",
      "Epoch [18/50], Step [670/735], Loss: 0.0589\n",
      "Epoch [18/50], Step [671/735], Loss: 0.0233\n",
      "Epoch [18/50], Step [672/735], Loss: 0.0857\n",
      "Epoch [18/50], Step [673/735], Loss: 0.0955\n",
      "Epoch [18/50], Step [674/735], Loss: 0.0461\n",
      "Epoch [18/50], Step [675/735], Loss: 0.0301\n",
      "Epoch [18/50], Step [676/735], Loss: 0.0630\n",
      "Epoch [18/50], Step [677/735], Loss: 0.1067\n",
      "Epoch [18/50], Step [678/735], Loss: 0.0574\n",
      "Epoch [18/50], Step [679/735], Loss: 0.0366\n",
      "Epoch [18/50], Step [680/735], Loss: 0.0132\n",
      "Epoch [18/50], Step [681/735], Loss: 0.0506\n",
      "Epoch [18/50], Step [682/735], Loss: 0.1044\n",
      "Epoch [18/50], Step [683/735], Loss: 0.0859\n",
      "Epoch [18/50], Step [684/735], Loss: 0.0328\n",
      "Epoch [18/50], Step [685/735], Loss: 0.1103\n",
      "Epoch [18/50], Step [686/735], Loss: 0.0387\n",
      "Epoch [18/50], Step [687/735], Loss: 0.0562\n",
      "Epoch [18/50], Step [688/735], Loss: 0.1980\n",
      "Epoch [18/50], Step [689/735], Loss: 0.1438\n",
      "Epoch [18/50], Step [690/735], Loss: 0.0384\n",
      "Epoch [18/50], Step [691/735], Loss: 0.0326\n",
      "Epoch [18/50], Step [692/735], Loss: 0.0698\n",
      "Epoch [18/50], Step [693/735], Loss: 0.1680\n",
      "Epoch [18/50], Step [694/735], Loss: 0.1423\n",
      "Epoch [18/50], Step [695/735], Loss: 0.0655\n",
      "Epoch [18/50], Step [696/735], Loss: 0.0767\n",
      "Epoch [18/50], Step [697/735], Loss: 0.0660\n",
      "Epoch [18/50], Step [698/735], Loss: 0.0958\n",
      "Epoch [18/50], Step [699/735], Loss: 0.0920\n",
      "Epoch [18/50], Step [700/735], Loss: 0.0417\n",
      "Epoch [18/50], Step [701/735], Loss: 0.2693\n",
      "Epoch [18/50], Step [702/735], Loss: 0.0719\n",
      "Epoch [18/50], Step [703/735], Loss: 0.0487\n",
      "Epoch [18/50], Step [704/735], Loss: 0.0269\n",
      "Epoch [18/50], Step [705/735], Loss: 0.5300\n",
      "Epoch [18/50], Step [706/735], Loss: 0.1709\n",
      "Epoch [18/50], Step [707/735], Loss: 0.0657\n",
      "Epoch [18/50], Step [708/735], Loss: 0.0440\n",
      "Epoch [18/50], Step [709/735], Loss: 0.2044\n",
      "Epoch [18/50], Step [710/735], Loss: 0.0303\n",
      "Epoch [18/50], Step [711/735], Loss: 0.1749\n",
      "Epoch [18/50], Step [712/735], Loss: 0.0694\n",
      "Epoch [18/50], Step [713/735], Loss: 0.0585\n",
      "Epoch [18/50], Step [714/735], Loss: 0.0801\n",
      "Epoch [18/50], Step [715/735], Loss: 0.0733\n",
      "Epoch [18/50], Step [716/735], Loss: 0.1483\n",
      "Epoch [18/50], Step [717/735], Loss: 0.4141\n",
      "Epoch [18/50], Step [718/735], Loss: 0.1774\n",
      "Epoch [18/50], Step [719/735], Loss: 0.0832\n",
      "Epoch [18/50], Step [720/735], Loss: 0.0375\n",
      "Epoch [18/50], Step [721/735], Loss: 0.0449\n",
      "Epoch [18/50], Step [722/735], Loss: 0.1608\n",
      "Epoch [18/50], Step [723/735], Loss: 0.0415\n",
      "Epoch [18/50], Step [724/735], Loss: 0.1865\n",
      "Epoch [18/50], Step [725/735], Loss: 0.3299\n",
      "Epoch [18/50], Step [726/735], Loss: 0.0707\n",
      "Epoch [18/50], Step [727/735], Loss: 0.0497\n",
      "Epoch [18/50], Step [728/735], Loss: 0.1259\n",
      "Epoch [18/50], Step [729/735], Loss: 0.1357\n",
      "Epoch [18/50], Step [730/735], Loss: 0.0720\n",
      "Epoch [18/50], Step [731/735], Loss: 0.0882\n",
      "Epoch [18/50], Step [732/735], Loss: 0.0968\n",
      "Epoch [18/50], Step [733/735], Loss: 0.1426\n",
      "Epoch [18/50], Step [734/735], Loss: 0.0515\n",
      "Epoch [18/50], Step [735/735], Loss: 0.0466\n",
      "Epoch [19/50], Step [1/735], Loss: 0.0737\n",
      "Epoch [19/50], Step [2/735], Loss: 0.0607\n",
      "Epoch [19/50], Step [3/735], Loss: 0.0754\n",
      "Epoch [19/50], Step [4/735], Loss: 0.0809\n",
      "Epoch [19/50], Step [5/735], Loss: 0.1505\n",
      "Epoch [19/50], Step [6/735], Loss: 0.0877\n",
      "Epoch [19/50], Step [7/735], Loss: 0.0718\n",
      "Epoch [19/50], Step [8/735], Loss: 0.1018\n",
      "Epoch [19/50], Step [9/735], Loss: 0.0606\n",
      "Epoch [19/50], Step [10/735], Loss: 0.0755\n",
      "Epoch [19/50], Step [11/735], Loss: 0.0709\n",
      "Epoch [19/50], Step [12/735], Loss: 0.0307\n",
      "Epoch [19/50], Step [13/735], Loss: 0.0567\n",
      "Epoch [19/50], Step [14/735], Loss: 0.1250\n",
      "Epoch [19/50], Step [15/735], Loss: 0.0644\n",
      "Epoch [19/50], Step [16/735], Loss: 0.1004\n",
      "Epoch [19/50], Step [17/735], Loss: 0.1067\n",
      "Epoch [19/50], Step [18/735], Loss: 0.0467\n",
      "Epoch [19/50], Step [19/735], Loss: 0.1956\n",
      "Epoch [19/50], Step [20/735], Loss: 0.0308\n",
      "Epoch [19/50], Step [21/735], Loss: 0.0548\n",
      "Epoch [19/50], Step [22/735], Loss: 0.2842\n",
      "Epoch [19/50], Step [23/735], Loss: 0.1810\n",
      "Epoch [19/50], Step [24/735], Loss: 0.0340\n",
      "Epoch [19/50], Step [25/735], Loss: 0.0418\n",
      "Epoch [19/50], Step [26/735], Loss: 0.0605\n",
      "Epoch [19/50], Step [27/735], Loss: 0.2854\n",
      "Epoch [19/50], Step [28/735], Loss: 0.0577\n",
      "Epoch [19/50], Step [29/735], Loss: 0.0445\n",
      "Epoch [19/50], Step [30/735], Loss: 0.0993\n",
      "Epoch [19/50], Step [31/735], Loss: 0.0525\n",
      "Epoch [19/50], Step [32/735], Loss: 0.0452\n",
      "Epoch [19/50], Step [33/735], Loss: 0.0585\n",
      "Epoch [19/50], Step [34/735], Loss: 0.0619\n",
      "Epoch [19/50], Step [35/735], Loss: 0.0646\n",
      "Epoch [19/50], Step [36/735], Loss: 0.0396\n",
      "Epoch [19/50], Step [37/735], Loss: 0.0796\n",
      "Epoch [19/50], Step [38/735], Loss: 0.4690\n",
      "Epoch [19/50], Step [39/735], Loss: 0.0684\n",
      "Epoch [19/50], Step [40/735], Loss: 0.0974\n",
      "Epoch [19/50], Step [41/735], Loss: 0.0396\n",
      "Epoch [19/50], Step [42/735], Loss: 0.0713\n",
      "Epoch [19/50], Step [43/735], Loss: 0.0838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Step [44/735], Loss: 0.0809\n",
      "Epoch [19/50], Step [45/735], Loss: 0.0494\n",
      "Epoch [19/50], Step [46/735], Loss: 0.1997\n",
      "Epoch [19/50], Step [47/735], Loss: 0.1191\n",
      "Epoch [19/50], Step [48/735], Loss: 0.0349\n",
      "Epoch [19/50], Step [49/735], Loss: 0.0436\n",
      "Epoch [19/50], Step [50/735], Loss: 0.1179\n",
      "Epoch [19/50], Step [51/735], Loss: 0.0578\n",
      "Epoch [19/50], Step [52/735], Loss: 0.3065\n",
      "Epoch [19/50], Step [53/735], Loss: 0.0319\n",
      "Epoch [19/50], Step [54/735], Loss: 0.0221\n",
      "Epoch [19/50], Step [55/735], Loss: 0.0718\n",
      "Epoch [19/50], Step [56/735], Loss: 0.1405\n",
      "Epoch [19/50], Step [57/735], Loss: 0.0405\n",
      "Epoch [19/50], Step [58/735], Loss: 0.1073\n",
      "Epoch [19/50], Step [59/735], Loss: 0.1816\n",
      "Epoch [19/50], Step [60/735], Loss: 0.1056\n",
      "Epoch [19/50], Step [61/735], Loss: 0.1120\n",
      "Epoch [19/50], Step [62/735], Loss: 0.0713\n",
      "Epoch [19/50], Step [63/735], Loss: 0.0904\n",
      "Epoch [19/50], Step [64/735], Loss: 0.1245\n",
      "Epoch [19/50], Step [65/735], Loss: 0.0572\n",
      "Epoch [19/50], Step [66/735], Loss: 0.0714\n",
      "Epoch [19/50], Step [67/735], Loss: 0.0755\n",
      "Epoch [19/50], Step [68/735], Loss: 0.0577\n",
      "Epoch [19/50], Step [69/735], Loss: 0.0414\n",
      "Epoch [19/50], Step [70/735], Loss: 0.0539\n",
      "Epoch [19/50], Step [71/735], Loss: 0.2325\n",
      "Epoch [19/50], Step [72/735], Loss: 0.1079\n",
      "Epoch [19/50], Step [73/735], Loss: 0.0410\n",
      "Epoch [19/50], Step [74/735], Loss: 0.1140\n",
      "Epoch [19/50], Step [75/735], Loss: 0.1110\n",
      "Epoch [19/50], Step [76/735], Loss: 0.0222\n",
      "Epoch [19/50], Step [77/735], Loss: 0.2914\n",
      "Epoch [19/50], Step [78/735], Loss: 0.0399\n",
      "Epoch [19/50], Step [79/735], Loss: 0.0700\n",
      "Epoch [19/50], Step [80/735], Loss: 0.0959\n",
      "Epoch [19/50], Step [81/735], Loss: 0.0723\n",
      "Epoch [19/50], Step [82/735], Loss: 0.1581\n",
      "Epoch [19/50], Step [83/735], Loss: 0.0727\n",
      "Epoch [19/50], Step [84/735], Loss: 0.0718\n",
      "Epoch [19/50], Step [85/735], Loss: 0.0470\n",
      "Epoch [19/50], Step [86/735], Loss: 0.1518\n",
      "Epoch [19/50], Step [87/735], Loss: 0.0300\n",
      "Epoch [19/50], Step [88/735], Loss: 0.0460\n",
      "Epoch [19/50], Step [89/735], Loss: 0.0279\n",
      "Epoch [19/50], Step [90/735], Loss: 0.0253\n",
      "Epoch [19/50], Step [91/735], Loss: 0.0811\n",
      "Epoch [19/50], Step [92/735], Loss: 0.0300\n",
      "Epoch [19/50], Step [93/735], Loss: 0.0475\n",
      "Epoch [19/50], Step [94/735], Loss: 0.0400\n",
      "Epoch [19/50], Step [95/735], Loss: 0.1288\n",
      "Epoch [19/50], Step [96/735], Loss: 0.1051\n",
      "Epoch [19/50], Step [97/735], Loss: 0.0271\n",
      "Epoch [19/50], Step [98/735], Loss: 0.1004\n",
      "Epoch [19/50], Step [99/735], Loss: 0.0325\n",
      "Epoch [19/50], Step [100/735], Loss: 0.0390\n",
      "Epoch [19/50], Step [101/735], Loss: 0.0234\n",
      "Epoch [19/50], Step [102/735], Loss: 0.0930\n",
      "Epoch [19/50], Step [103/735], Loss: 0.1021\n",
      "Epoch [19/50], Step [104/735], Loss: 0.1879\n",
      "Epoch [19/50], Step [105/735], Loss: 0.1426\n",
      "Epoch [19/50], Step [106/735], Loss: 0.0323\n",
      "Epoch [19/50], Step [107/735], Loss: 0.0373\n",
      "Epoch [19/50], Step [108/735], Loss: 0.0923\n",
      "Epoch [19/50], Step [109/735], Loss: 0.0584\n",
      "Epoch [19/50], Step [110/735], Loss: 0.0232\n",
      "Epoch [19/50], Step [111/735], Loss: 0.0491\n",
      "Epoch [19/50], Step [112/735], Loss: 0.0326\n",
      "Epoch [19/50], Step [113/735], Loss: 0.0333\n",
      "Epoch [19/50], Step [114/735], Loss: 0.0600\n",
      "Epoch [19/50], Step [115/735], Loss: 0.0933\n",
      "Epoch [19/50], Step [116/735], Loss: 0.0211\n",
      "Epoch [19/50], Step [117/735], Loss: 0.0257\n",
      "Epoch [19/50], Step [118/735], Loss: 0.0636\n",
      "Epoch [19/50], Step [119/735], Loss: 0.0484\n",
      "Epoch [19/50], Step [120/735], Loss: 0.0588\n",
      "Epoch [19/50], Step [121/735], Loss: 0.0696\n",
      "Epoch [19/50], Step [122/735], Loss: 0.0286\n",
      "Epoch [19/50], Step [123/735], Loss: 0.1104\n",
      "Epoch [19/50], Step [124/735], Loss: 0.0589\n",
      "Epoch [19/50], Step [125/735], Loss: 0.1825\n",
      "Epoch [19/50], Step [126/735], Loss: 0.2217\n",
      "Epoch [19/50], Step [127/735], Loss: 0.1129\n",
      "Epoch [19/50], Step [128/735], Loss: 0.0510\n",
      "Epoch [19/50], Step [129/735], Loss: 0.0314\n",
      "Epoch [19/50], Step [130/735], Loss: 0.0195\n",
      "Epoch [19/50], Step [131/735], Loss: 0.1801\n",
      "Epoch [19/50], Step [132/735], Loss: 0.3899\n",
      "Epoch [19/50], Step [133/735], Loss: 0.1964\n",
      "Epoch [19/50], Step [134/735], Loss: 0.0547\n",
      "Epoch [19/50], Step [135/735], Loss: 0.0996\n",
      "Epoch [19/50], Step [136/735], Loss: 0.0388\n",
      "Epoch [19/50], Step [137/735], Loss: 0.0585\n",
      "Epoch [19/50], Step [138/735], Loss: 0.0402\n",
      "Epoch [19/50], Step [139/735], Loss: 0.0429\n",
      "Epoch [19/50], Step [140/735], Loss: 0.0558\n",
      "Epoch [19/50], Step [141/735], Loss: 0.0440\n",
      "Epoch [19/50], Step [142/735], Loss: 0.2152\n",
      "Epoch [19/50], Step [143/735], Loss: 0.0730\n",
      "Epoch [19/50], Step [144/735], Loss: 0.0458\n",
      "Epoch [19/50], Step [145/735], Loss: 0.0742\n",
      "Epoch [19/50], Step [146/735], Loss: 0.1142\n",
      "Epoch [19/50], Step [147/735], Loss: 0.0935\n",
      "Epoch [19/50], Step [148/735], Loss: 0.5563\n",
      "Epoch [19/50], Step [149/735], Loss: 0.0602\n",
      "Epoch [19/50], Step [150/735], Loss: 0.0986\n",
      "Epoch [19/50], Step [151/735], Loss: 0.0384\n",
      "Epoch [19/50], Step [152/735], Loss: 0.1005\n",
      "Epoch [19/50], Step [153/735], Loss: 0.0276\n",
      "Epoch [19/50], Step [154/735], Loss: 0.1429\n",
      "Epoch [19/50], Step [155/735], Loss: 0.1181\n",
      "Epoch [19/50], Step [156/735], Loss: 0.0752\n",
      "Epoch [19/50], Step [157/735], Loss: 0.4675\n",
      "Epoch [19/50], Step [158/735], Loss: 0.0806\n",
      "Epoch [19/50], Step [159/735], Loss: 0.1891\n",
      "Epoch [19/50], Step [160/735], Loss: 0.0737\n",
      "Epoch [19/50], Step [161/735], Loss: 0.0484\n",
      "Epoch [19/50], Step [162/735], Loss: 0.0984\n",
      "Epoch [19/50], Step [163/735], Loss: 0.1932\n",
      "Epoch [19/50], Step [164/735], Loss: 0.0557\n",
      "Epoch [19/50], Step [165/735], Loss: 0.0455\n",
      "Epoch [19/50], Step [166/735], Loss: 0.0657\n",
      "Epoch [19/50], Step [167/735], Loss: 0.1548\n",
      "Epoch [19/50], Step [168/735], Loss: 0.1900\n",
      "Epoch [19/50], Step [169/735], Loss: 0.2196\n",
      "Epoch [19/50], Step [170/735], Loss: 0.0408\n",
      "Epoch [19/50], Step [171/735], Loss: 0.0968\n",
      "Epoch [19/50], Step [172/735], Loss: 0.1192\n",
      "Epoch [19/50], Step [173/735], Loss: 0.1151\n",
      "Epoch [19/50], Step [174/735], Loss: 0.1155\n",
      "Epoch [19/50], Step [175/735], Loss: 0.3343\n",
      "Epoch [19/50], Step [176/735], Loss: 0.0557\n",
      "Epoch [19/50], Step [177/735], Loss: 0.1076\n",
      "Epoch [19/50], Step [178/735], Loss: 0.0581\n",
      "Epoch [19/50], Step [179/735], Loss: 0.1340\n",
      "Epoch [19/50], Step [180/735], Loss: 0.0378\n",
      "Epoch [19/50], Step [181/735], Loss: 0.0224\n",
      "Epoch [19/50], Step [182/735], Loss: 0.0321\n",
      "Epoch [19/50], Step [183/735], Loss: 0.0617\n",
      "Epoch [19/50], Step [184/735], Loss: 0.0365\n",
      "Epoch [19/50], Step [185/735], Loss: 0.2093\n",
      "Epoch [19/50], Step [186/735], Loss: 0.1356\n",
      "Epoch [19/50], Step [187/735], Loss: 0.0273\n",
      "Epoch [19/50], Step [188/735], Loss: 0.0488\n",
      "Epoch [19/50], Step [189/735], Loss: 0.1626\n",
      "Epoch [19/50], Step [190/735], Loss: 0.3375\n",
      "Epoch [19/50], Step [191/735], Loss: 0.1703\n",
      "Epoch [19/50], Step [192/735], Loss: 0.1568\n",
      "Epoch [19/50], Step [193/735], Loss: 0.2222\n",
      "Epoch [19/50], Step [194/735], Loss: 0.1399\n",
      "Epoch [19/50], Step [195/735], Loss: 0.0569\n",
      "Epoch [19/50], Step [196/735], Loss: 0.0903\n",
      "Epoch [19/50], Step [197/735], Loss: 0.5268\n",
      "Epoch [19/50], Step [198/735], Loss: 0.0933\n",
      "Epoch [19/50], Step [199/735], Loss: 0.0309\n",
      "Epoch [19/50], Step [200/735], Loss: 0.0898\n",
      "Epoch [19/50], Step [201/735], Loss: 0.0284\n",
      "Epoch [19/50], Step [202/735], Loss: 0.0690\n",
      "Epoch [19/50], Step [203/735], Loss: 0.0488\n",
      "Epoch [19/50], Step [204/735], Loss: 0.2160\n",
      "Epoch [19/50], Step [205/735], Loss: 0.0426\n",
      "Epoch [19/50], Step [206/735], Loss: 0.0300\n",
      "Epoch [19/50], Step [207/735], Loss: 0.0408\n",
      "Epoch [19/50], Step [208/735], Loss: 0.1108\n",
      "Epoch [19/50], Step [209/735], Loss: 0.2483\n",
      "Epoch [19/50], Step [210/735], Loss: 0.1561\n",
      "Epoch [19/50], Step [211/735], Loss: 0.0912\n",
      "Epoch [19/50], Step [212/735], Loss: 0.0979\n",
      "Epoch [19/50], Step [213/735], Loss: 0.1221\n",
      "Epoch [19/50], Step [214/735], Loss: 0.1206\n",
      "Epoch [19/50], Step [215/735], Loss: 0.0977\n",
      "Epoch [19/50], Step [216/735], Loss: 0.1622\n",
      "Epoch [19/50], Step [217/735], Loss: 0.0218\n",
      "Epoch [19/50], Step [218/735], Loss: 0.1090\n",
      "Epoch [19/50], Step [219/735], Loss: 0.0729\n",
      "Epoch [19/50], Step [220/735], Loss: 0.0560\n",
      "Epoch [19/50], Step [221/735], Loss: 0.0804\n",
      "Epoch [19/50], Step [222/735], Loss: 0.0512\n",
      "Epoch [19/50], Step [223/735], Loss: 0.1843\n",
      "Epoch [19/50], Step [224/735], Loss: 0.0549\n",
      "Epoch [19/50], Step [225/735], Loss: 0.1797\n",
      "Epoch [19/50], Step [226/735], Loss: 0.0662\n",
      "Epoch [19/50], Step [227/735], Loss: 0.0883\n",
      "Epoch [19/50], Step [228/735], Loss: 0.0540\n",
      "Epoch [19/50], Step [229/735], Loss: 0.0487\n",
      "Epoch [19/50], Step [230/735], Loss: 0.1435\n",
      "Epoch [19/50], Step [231/735], Loss: 0.0482\n",
      "Epoch [19/50], Step [232/735], Loss: 0.0620\n",
      "Epoch [19/50], Step [233/735], Loss: 0.1450\n",
      "Epoch [19/50], Step [234/735], Loss: 0.1433\n",
      "Epoch [19/50], Step [235/735], Loss: 0.0610\n",
      "Epoch [19/50], Step [236/735], Loss: 0.0448\n",
      "Epoch [19/50], Step [237/735], Loss: 0.0699\n",
      "Epoch [19/50], Step [238/735], Loss: 0.0816\n",
      "Epoch [19/50], Step [239/735], Loss: 0.0692\n",
      "Epoch [19/50], Step [240/735], Loss: 0.1126\n",
      "Epoch [19/50], Step [241/735], Loss: 0.0267\n",
      "Epoch [19/50], Step [242/735], Loss: 0.0711\n",
      "Epoch [19/50], Step [243/735], Loss: 0.0575\n",
      "Epoch [19/50], Step [244/735], Loss: 0.0553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Step [245/735], Loss: 0.1685\n",
      "Epoch [19/50], Step [246/735], Loss: 0.0635\n",
      "Epoch [19/50], Step [247/735], Loss: 0.0453\n",
      "Epoch [19/50], Step [248/735], Loss: 0.0629\n",
      "Epoch [19/50], Step [249/735], Loss: 0.0368\n",
      "Epoch [19/50], Step [250/735], Loss: 0.0283\n",
      "Epoch [19/50], Step [251/735], Loss: 0.1268\n",
      "Epoch [19/50], Step [252/735], Loss: 0.0588\n",
      "Epoch [19/50], Step [253/735], Loss: 0.0457\n",
      "Epoch [19/50], Step [254/735], Loss: 0.0768\n",
      "Epoch [19/50], Step [255/735], Loss: 0.1108\n",
      "Epoch [19/50], Step [256/735], Loss: 0.7155\n",
      "Epoch [19/50], Step [257/735], Loss: 0.1405\n",
      "Epoch [19/50], Step [258/735], Loss: 0.0783\n",
      "Epoch [19/50], Step [259/735], Loss: 0.1044\n",
      "Epoch [19/50], Step [260/735], Loss: 0.1079\n",
      "Epoch [19/50], Step [261/735], Loss: 0.0560\n",
      "Epoch [19/50], Step [262/735], Loss: 0.1068\n",
      "Epoch [19/50], Step [263/735], Loss: 0.0467\n",
      "Epoch [19/50], Step [264/735], Loss: 0.1374\n",
      "Epoch [19/50], Step [265/735], Loss: 0.1342\n",
      "Epoch [19/50], Step [266/735], Loss: 0.0673\n",
      "Epoch [19/50], Step [267/735], Loss: 0.0473\n",
      "Epoch [19/50], Step [268/735], Loss: 0.0292\n",
      "Epoch [19/50], Step [269/735], Loss: 0.1707\n",
      "Epoch [19/50], Step [270/735], Loss: 0.0830\n",
      "Epoch [19/50], Step [271/735], Loss: 0.0527\n",
      "Epoch [19/50], Step [272/735], Loss: 0.0445\n",
      "Epoch [19/50], Step [273/735], Loss: 0.0176\n",
      "Epoch [19/50], Step [274/735], Loss: 0.0427\n",
      "Epoch [19/50], Step [275/735], Loss: 0.0681\n",
      "Epoch [19/50], Step [276/735], Loss: 0.0948\n",
      "Epoch [19/50], Step [277/735], Loss: 0.0838\n",
      "Epoch [19/50], Step [278/735], Loss: 0.0920\n",
      "Epoch [19/50], Step [279/735], Loss: 0.0739\n",
      "Epoch [19/50], Step [280/735], Loss: 0.2643\n",
      "Epoch [19/50], Step [281/735], Loss: 0.0408\n",
      "Epoch [19/50], Step [282/735], Loss: 0.1095\n",
      "Epoch [19/50], Step [283/735], Loss: 0.1012\n",
      "Epoch [19/50], Step [284/735], Loss: 0.4009\n",
      "Epoch [19/50], Step [285/735], Loss: 0.0911\n",
      "Epoch [19/50], Step [286/735], Loss: 0.1122\n",
      "Epoch [19/50], Step [287/735], Loss: 0.0430\n",
      "Epoch [19/50], Step [288/735], Loss: 0.0581\n",
      "Epoch [19/50], Step [289/735], Loss: 0.0327\n",
      "Epoch [19/50], Step [290/735], Loss: 0.0741\n",
      "Epoch [19/50], Step [291/735], Loss: 0.1352\n",
      "Epoch [19/50], Step [292/735], Loss: 0.3007\n",
      "Epoch [19/50], Step [293/735], Loss: 0.0293\n",
      "Epoch [19/50], Step [294/735], Loss: 0.0643\n",
      "Epoch [19/50], Step [295/735], Loss: 0.3438\n",
      "Epoch [19/50], Step [296/735], Loss: 0.4011\n",
      "Epoch [19/50], Step [297/735], Loss: 0.0535\n",
      "Epoch [19/50], Step [298/735], Loss: 0.1009\n",
      "Epoch [19/50], Step [299/735], Loss: 0.0882\n",
      "Epoch [19/50], Step [300/735], Loss: 0.1192\n",
      "Epoch [19/50], Step [301/735], Loss: 0.4855\n",
      "Epoch [19/50], Step [302/735], Loss: 0.0451\n",
      "Epoch [19/50], Step [303/735], Loss: 0.0816\n",
      "Epoch [19/50], Step [304/735], Loss: 0.1502\n",
      "Epoch [19/50], Step [305/735], Loss: 0.0615\n",
      "Epoch [19/50], Step [306/735], Loss: 0.0742\n",
      "Epoch [19/50], Step [307/735], Loss: 0.0817\n",
      "Epoch [19/50], Step [308/735], Loss: 0.0764\n",
      "Epoch [19/50], Step [309/735], Loss: 0.1215\n",
      "Epoch [19/50], Step [310/735], Loss: 0.1689\n",
      "Epoch [19/50], Step [311/735], Loss: 0.1500\n",
      "Epoch [19/50], Step [312/735], Loss: 0.0898\n",
      "Epoch [19/50], Step [313/735], Loss: 0.1802\n",
      "Epoch [19/50], Step [314/735], Loss: 0.1699\n",
      "Epoch [19/50], Step [315/735], Loss: 0.0790\n",
      "Epoch [19/50], Step [316/735], Loss: 0.0357\n",
      "Epoch [19/50], Step [317/735], Loss: 0.1000\n",
      "Epoch [19/50], Step [318/735], Loss: 0.0266\n",
      "Epoch [19/50], Step [319/735], Loss: 0.0356\n",
      "Epoch [19/50], Step [320/735], Loss: 0.1064\n",
      "Epoch [19/50], Step [321/735], Loss: 0.0542\n",
      "Epoch [19/50], Step [322/735], Loss: 0.2090\n",
      "Epoch [19/50], Step [323/735], Loss: 0.0550\n",
      "Epoch [19/50], Step [324/735], Loss: 0.1148\n",
      "Epoch [19/50], Step [325/735], Loss: 0.0306\n",
      "Epoch [19/50], Step [326/735], Loss: 0.1000\n",
      "Epoch [19/50], Step [327/735], Loss: 0.1121\n",
      "Epoch [19/50], Step [328/735], Loss: 0.1167\n",
      "Epoch [19/50], Step [329/735], Loss: 0.0322\n",
      "Epoch [19/50], Step [330/735], Loss: 0.0371\n",
      "Epoch [19/50], Step [331/735], Loss: 0.3256\n",
      "Epoch [19/50], Step [332/735], Loss: 0.2212\n",
      "Epoch [19/50], Step [333/735], Loss: 0.0145\n",
      "Epoch [19/50], Step [334/735], Loss: 0.2809\n",
      "Epoch [19/50], Step [335/735], Loss: 0.0853\n",
      "Epoch [19/50], Step [336/735], Loss: 0.0506\n",
      "Epoch [19/50], Step [337/735], Loss: 0.0278\n",
      "Epoch [19/50], Step [338/735], Loss: 0.1065\n",
      "Epoch [19/50], Step [339/735], Loss: 0.0995\n",
      "Epoch [19/50], Step [340/735], Loss: 0.0818\n",
      "Epoch [19/50], Step [341/735], Loss: 0.0601\n",
      "Epoch [19/50], Step [342/735], Loss: 0.0717\n",
      "Epoch [19/50], Step [343/735], Loss: 0.0738\n",
      "Epoch [19/50], Step [344/735], Loss: 0.0393\n",
      "Epoch [19/50], Step [345/735], Loss: 0.1987\n",
      "Epoch [19/50], Step [346/735], Loss: 0.2691\n",
      "Epoch [19/50], Step [347/735], Loss: 0.1340\n",
      "Epoch [19/50], Step [348/735], Loss: 0.1033\n",
      "Epoch [19/50], Step [349/735], Loss: 0.1163\n",
      "Epoch [19/50], Step [350/735], Loss: 0.0515\n",
      "Epoch [19/50], Step [351/735], Loss: 0.1282\n",
      "Epoch [19/50], Step [352/735], Loss: 0.1050\n",
      "Epoch [19/50], Step [353/735], Loss: 0.2049\n",
      "Epoch [19/50], Step [354/735], Loss: 0.0235\n",
      "Epoch [19/50], Step [355/735], Loss: 0.0736\n",
      "Epoch [19/50], Step [356/735], Loss: 0.0623\n",
      "Epoch [19/50], Step [357/735], Loss: 0.1193\n",
      "Epoch [19/50], Step [358/735], Loss: 0.0198\n",
      "Epoch [19/50], Step [359/735], Loss: 0.0768\n",
      "Epoch [19/50], Step [360/735], Loss: 0.3077\n",
      "Epoch [19/50], Step [361/735], Loss: 0.1134\n",
      "Epoch [19/50], Step [362/735], Loss: 0.1332\n",
      "Epoch [19/50], Step [363/735], Loss: 0.2225\n",
      "Epoch [19/50], Step [364/735], Loss: 0.3266\n",
      "Epoch [19/50], Step [365/735], Loss: 0.0328\n",
      "Epoch [19/50], Step [366/735], Loss: 0.0521\n",
      "Epoch [19/50], Step [367/735], Loss: 0.0265\n",
      "Epoch [19/50], Step [368/735], Loss: 0.1878\n",
      "Epoch [19/50], Step [369/735], Loss: 0.6307\n",
      "Epoch [19/50], Step [370/735], Loss: 0.1023\n",
      "Epoch [19/50], Step [371/735], Loss: 0.5016\n",
      "Epoch [19/50], Step [372/735], Loss: 0.0448\n",
      "Epoch [19/50], Step [373/735], Loss: 0.1049\n",
      "Epoch [19/50], Step [374/735], Loss: 0.0888\n",
      "Epoch [19/50], Step [375/735], Loss: 0.0358\n",
      "Epoch [19/50], Step [376/735], Loss: 0.1174\n",
      "Epoch [19/50], Step [377/735], Loss: 0.2087\n",
      "Epoch [19/50], Step [378/735], Loss: 0.0456\n",
      "Epoch [19/50], Step [379/735], Loss: 0.0340\n",
      "Epoch [19/50], Step [380/735], Loss: 0.1232\n",
      "Epoch [19/50], Step [381/735], Loss: 0.0605\n",
      "Epoch [19/50], Step [382/735], Loss: 0.1151\n",
      "Epoch [19/50], Step [383/735], Loss: 0.0595\n",
      "Epoch [19/50], Step [384/735], Loss: 0.0988\n",
      "Epoch [19/50], Step [385/735], Loss: 0.0804\n",
      "Epoch [19/50], Step [386/735], Loss: 0.0319\n",
      "Epoch [19/50], Step [387/735], Loss: 0.0558\n",
      "Epoch [19/50], Step [388/735], Loss: 0.0547\n",
      "Epoch [19/50], Step [389/735], Loss: 0.1430\n",
      "Epoch [19/50], Step [390/735], Loss: 0.0927\n",
      "Epoch [19/50], Step [391/735], Loss: 0.0852\n",
      "Epoch [19/50], Step [392/735], Loss: 0.0791\n",
      "Epoch [19/50], Step [393/735], Loss: 0.2704\n",
      "Epoch [19/50], Step [394/735], Loss: 0.0541\n",
      "Epoch [19/50], Step [395/735], Loss: 0.1075\n",
      "Epoch [19/50], Step [396/735], Loss: 0.0283\n",
      "Epoch [19/50], Step [397/735], Loss: 0.0957\n",
      "Epoch [19/50], Step [398/735], Loss: 0.0927\n",
      "Epoch [19/50], Step [399/735], Loss: 0.0887\n",
      "Epoch [19/50], Step [400/735], Loss: 0.0453\n",
      "Epoch [19/50], Step [401/735], Loss: 0.0848\n",
      "Epoch [19/50], Step [402/735], Loss: 0.0779\n",
      "Epoch [19/50], Step [403/735], Loss: 0.1559\n",
      "Epoch [19/50], Step [404/735], Loss: 0.1154\n",
      "Epoch [19/50], Step [405/735], Loss: 0.0534\n",
      "Epoch [19/50], Step [406/735], Loss: 0.0291\n",
      "Epoch [19/50], Step [407/735], Loss: 0.0310\n",
      "Epoch [19/50], Step [408/735], Loss: 0.0948\n",
      "Epoch [19/50], Step [409/735], Loss: 0.0207\n",
      "Epoch [19/50], Step [410/735], Loss: 0.0622\n",
      "Epoch [19/50], Step [411/735], Loss: 0.1107\n",
      "Epoch [19/50], Step [412/735], Loss: 0.2081\n",
      "Epoch [19/50], Step [413/735], Loss: 0.0771\n",
      "Epoch [19/50], Step [414/735], Loss: 0.0347\n",
      "Epoch [19/50], Step [415/735], Loss: 0.1124\n",
      "Epoch [19/50], Step [416/735], Loss: 0.1236\n",
      "Epoch [19/50], Step [417/735], Loss: 0.0659\n",
      "Epoch [19/50], Step [418/735], Loss: 0.4853\n",
      "Epoch [19/50], Step [419/735], Loss: 0.0793\n",
      "Epoch [19/50], Step [420/735], Loss: 0.0688\n",
      "Epoch [19/50], Step [421/735], Loss: 0.0774\n",
      "Epoch [19/50], Step [422/735], Loss: 0.1117\n",
      "Epoch [19/50], Step [423/735], Loss: 0.0624\n",
      "Epoch [19/50], Step [424/735], Loss: 0.0486\n",
      "Epoch [19/50], Step [425/735], Loss: 0.0185\n",
      "Epoch [19/50], Step [426/735], Loss: 0.0838\n",
      "Epoch [19/50], Step [427/735], Loss: 0.1048\n",
      "Epoch [19/50], Step [428/735], Loss: 0.0413\n",
      "Epoch [19/50], Step [429/735], Loss: 0.2206\n",
      "Epoch [19/50], Step [430/735], Loss: 0.0342\n",
      "Epoch [19/50], Step [431/735], Loss: 0.1052\n",
      "Epoch [19/50], Step [432/735], Loss: 0.0475\n",
      "Epoch [19/50], Step [433/735], Loss: 0.0338\n",
      "Epoch [19/50], Step [434/735], Loss: 0.0680\n",
      "Epoch [19/50], Step [435/735], Loss: 0.0577\n",
      "Epoch [19/50], Step [436/735], Loss: 0.0857\n",
      "Epoch [19/50], Step [437/735], Loss: 0.0653\n",
      "Epoch [19/50], Step [438/735], Loss: 0.0351\n",
      "Epoch [19/50], Step [439/735], Loss: 0.0249\n",
      "Epoch [19/50], Step [440/735], Loss: 0.1164\n",
      "Epoch [19/50], Step [441/735], Loss: 0.2016\n",
      "Epoch [19/50], Step [442/735], Loss: 0.0475\n",
      "Epoch [19/50], Step [443/735], Loss: 0.0768\n",
      "Epoch [19/50], Step [444/735], Loss: 0.0727\n",
      "Epoch [19/50], Step [445/735], Loss: 0.0503\n",
      "Epoch [19/50], Step [446/735], Loss: 0.1038\n",
      "Epoch [19/50], Step [447/735], Loss: 0.0677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Step [448/735], Loss: 0.0525\n",
      "Epoch [19/50], Step [449/735], Loss: 0.0333\n",
      "Epoch [19/50], Step [450/735], Loss: 0.0891\n",
      "Epoch [19/50], Step [451/735], Loss: 0.0952\n",
      "Epoch [19/50], Step [452/735], Loss: 0.0346\n",
      "Epoch [19/50], Step [453/735], Loss: 0.0652\n",
      "Epoch [19/50], Step [454/735], Loss: 0.0490\n",
      "Epoch [19/50], Step [455/735], Loss: 0.0513\n",
      "Epoch [19/50], Step [456/735], Loss: 0.0675\n",
      "Epoch [19/50], Step [457/735], Loss: 0.0670\n",
      "Epoch [19/50], Step [458/735], Loss: 0.1611\n",
      "Epoch [19/50], Step [459/735], Loss: 0.0714\n",
      "Epoch [19/50], Step [460/735], Loss: 0.2245\n",
      "Epoch [19/50], Step [461/735], Loss: 0.0338\n",
      "Epoch [19/50], Step [462/735], Loss: 0.0344\n",
      "Epoch [19/50], Step [463/735], Loss: 0.4795\n",
      "Epoch [19/50], Step [464/735], Loss: 0.0458\n",
      "Epoch [19/50], Step [465/735], Loss: 0.0778\n",
      "Epoch [19/50], Step [466/735], Loss: 0.0596\n",
      "Epoch [19/50], Step [467/735], Loss: 0.1540\n",
      "Epoch [19/50], Step [468/735], Loss: 0.0699\n",
      "Epoch [19/50], Step [469/735], Loss: 0.0875\n",
      "Epoch [19/50], Step [470/735], Loss: 0.0931\n",
      "Epoch [19/50], Step [471/735], Loss: 0.0311\n",
      "Epoch [19/50], Step [472/735], Loss: 0.0385\n",
      "Epoch [19/50], Step [473/735], Loss: 0.0540\n",
      "Epoch [19/50], Step [474/735], Loss: 0.0697\n",
      "Epoch [19/50], Step [475/735], Loss: 0.0303\n",
      "Epoch [19/50], Step [476/735], Loss: 0.3262\n",
      "Epoch [19/50], Step [477/735], Loss: 0.0498\n",
      "Epoch [19/50], Step [478/735], Loss: 0.0461\n",
      "Epoch [19/50], Step [479/735], Loss: 0.2305\n",
      "Epoch [19/50], Step [480/735], Loss: 0.0951\n",
      "Epoch [19/50], Step [481/735], Loss: 0.0151\n",
      "Epoch [19/50], Step [482/735], Loss: 0.0422\n",
      "Epoch [19/50], Step [483/735], Loss: 0.0881\n",
      "Epoch [19/50], Step [484/735], Loss: 0.0190\n",
      "Epoch [19/50], Step [485/735], Loss: 0.1058\n",
      "Epoch [19/50], Step [486/735], Loss: 0.0191\n",
      "Epoch [19/50], Step [487/735], Loss: 0.0599\n",
      "Epoch [19/50], Step [488/735], Loss: 0.0262\n",
      "Epoch [19/50], Step [489/735], Loss: 0.0448\n",
      "Epoch [19/50], Step [490/735], Loss: 0.1297\n",
      "Epoch [19/50], Step [491/735], Loss: 0.4733\n",
      "Epoch [19/50], Step [492/735], Loss: 0.0796\n",
      "Epoch [19/50], Step [493/735], Loss: 0.0396\n",
      "Epoch [19/50], Step [494/735], Loss: 0.1310\n",
      "Epoch [19/50], Step [495/735], Loss: 0.1240\n",
      "Epoch [19/50], Step [496/735], Loss: 0.0876\n",
      "Epoch [19/50], Step [497/735], Loss: 0.0346\n",
      "Epoch [19/50], Step [498/735], Loss: 0.0567\n",
      "Epoch [19/50], Step [499/735], Loss: 0.0803\n",
      "Epoch [19/50], Step [500/735], Loss: 0.0509\n",
      "Epoch [19/50], Step [501/735], Loss: 0.2865\n",
      "Epoch [19/50], Step [502/735], Loss: 0.0919\n",
      "Epoch [19/50], Step [503/735], Loss: 0.0286\n",
      "Epoch [19/50], Step [504/735], Loss: 0.0267\n",
      "Epoch [19/50], Step [505/735], Loss: 0.0198\n",
      "Epoch [19/50], Step [506/735], Loss: 0.0752\n",
      "Epoch [19/50], Step [507/735], Loss: 0.0416\n",
      "Epoch [19/50], Step [508/735], Loss: 0.1285\n",
      "Epoch [19/50], Step [509/735], Loss: 0.0875\n",
      "Epoch [19/50], Step [510/735], Loss: 0.0519\n",
      "Epoch [19/50], Step [511/735], Loss: 0.0259\n",
      "Epoch [19/50], Step [512/735], Loss: 0.0527\n",
      "Epoch [19/50], Step [513/735], Loss: 0.0404\n",
      "Epoch [19/50], Step [514/735], Loss: 0.0325\n",
      "Epoch [19/50], Step [515/735], Loss: 0.0226\n",
      "Epoch [19/50], Step [516/735], Loss: 0.1466\n",
      "Epoch [19/50], Step [517/735], Loss: 0.0339\n",
      "Epoch [19/50], Step [518/735], Loss: 0.0307\n",
      "Epoch [19/50], Step [519/735], Loss: 0.0722\n",
      "Epoch [19/50], Step [520/735], Loss: 0.0380\n",
      "Epoch [19/50], Step [521/735], Loss: 0.1975\n",
      "Epoch [19/50], Step [522/735], Loss: 0.0618\n",
      "Epoch [19/50], Step [523/735], Loss: 0.0245\n",
      "Epoch [19/50], Step [524/735], Loss: 0.0241\n",
      "Epoch [19/50], Step [525/735], Loss: 0.0602\n",
      "Epoch [19/50], Step [526/735], Loss: 0.1348\n",
      "Epoch [19/50], Step [527/735], Loss: 0.0258\n",
      "Epoch [19/50], Step [528/735], Loss: 0.1453\n",
      "Epoch [19/50], Step [529/735], Loss: 0.0307\n",
      "Epoch [19/50], Step [530/735], Loss: 0.2879\n",
      "Epoch [19/50], Step [531/735], Loss: 0.0370\n",
      "Epoch [19/50], Step [532/735], Loss: 0.0508\n",
      "Epoch [19/50], Step [533/735], Loss: 0.3769\n",
      "Epoch [19/50], Step [534/735], Loss: 0.0616\n",
      "Epoch [19/50], Step [535/735], Loss: 0.0812\n",
      "Epoch [19/50], Step [536/735], Loss: 0.1281\n",
      "Epoch [19/50], Step [537/735], Loss: 0.0580\n",
      "Epoch [19/50], Step [538/735], Loss: 0.0824\n",
      "Epoch [19/50], Step [539/735], Loss: 0.0246\n",
      "Epoch [19/50], Step [540/735], Loss: 0.0403\n",
      "Epoch [19/50], Step [541/735], Loss: 0.1421\n",
      "Epoch [19/50], Step [542/735], Loss: 0.1156\n",
      "Epoch [19/50], Step [543/735], Loss: 0.1148\n",
      "Epoch [19/50], Step [544/735], Loss: 0.1960\n",
      "Epoch [19/50], Step [545/735], Loss: 0.0223\n",
      "Epoch [19/50], Step [546/735], Loss: 0.1279\n",
      "Epoch [19/50], Step [547/735], Loss: 0.0748\n",
      "Epoch [19/50], Step [548/735], Loss: 0.1002\n",
      "Epoch [19/50], Step [549/735], Loss: 0.0335\n",
      "Epoch [19/50], Step [550/735], Loss: 0.0853\n",
      "Epoch [19/50], Step [551/735], Loss: 0.1593\n",
      "Epoch [19/50], Step [552/735], Loss: 0.0412\n",
      "Epoch [19/50], Step [553/735], Loss: 0.0257\n",
      "Epoch [19/50], Step [554/735], Loss: 0.0259\n",
      "Epoch [19/50], Step [555/735], Loss: 0.0739\n",
      "Epoch [19/50], Step [556/735], Loss: 0.0568\n",
      "Epoch [19/50], Step [557/735], Loss: 0.0674\n",
      "Epoch [19/50], Step [558/735], Loss: 0.1448\n",
      "Epoch [19/50], Step [559/735], Loss: 0.0251\n",
      "Epoch [19/50], Step [560/735], Loss: 0.0482\n",
      "Epoch [19/50], Step [561/735], Loss: 0.1958\n",
      "Epoch [19/50], Step [562/735], Loss: 0.0449\n",
      "Epoch [19/50], Step [563/735], Loss: 0.0578\n",
      "Epoch [19/50], Step [564/735], Loss: 0.1308\n",
      "Epoch [19/50], Step [565/735], Loss: 0.1711\n",
      "Epoch [19/50], Step [566/735], Loss: 0.2846\n",
      "Epoch [19/50], Step [567/735], Loss: 0.0480\n",
      "Epoch [19/50], Step [568/735], Loss: 0.0285\n",
      "Epoch [19/50], Step [569/735], Loss: 0.0712\n",
      "Epoch [19/50], Step [570/735], Loss: 0.0497\n",
      "Epoch [19/50], Step [571/735], Loss: 0.0301\n",
      "Epoch [19/50], Step [572/735], Loss: 0.0500\n",
      "Epoch [19/50], Step [573/735], Loss: 0.0374\n",
      "Epoch [19/50], Step [574/735], Loss: 0.0675\n",
      "Epoch [19/50], Step [575/735], Loss: 0.1658\n",
      "Epoch [19/50], Step [576/735], Loss: 0.0274\n",
      "Epoch [19/50], Step [577/735], Loss: 0.0579\n",
      "Epoch [19/50], Step [578/735], Loss: 0.1549\n",
      "Epoch [19/50], Step [579/735], Loss: 0.0639\n",
      "Epoch [19/50], Step [580/735], Loss: 0.1972\n",
      "Epoch [19/50], Step [581/735], Loss: 0.0909\n",
      "Epoch [19/50], Step [582/735], Loss: 0.0484\n",
      "Epoch [19/50], Step [583/735], Loss: 0.0198\n",
      "Epoch [19/50], Step [584/735], Loss: 0.0540\n",
      "Epoch [19/50], Step [585/735], Loss: 0.0496\n",
      "Epoch [19/50], Step [586/735], Loss: 0.1946\n",
      "Epoch [19/50], Step [587/735], Loss: 0.0898\n",
      "Epoch [19/50], Step [588/735], Loss: 0.0509\n",
      "Epoch [19/50], Step [589/735], Loss: 0.2109\n",
      "Epoch [19/50], Step [590/735], Loss: 0.1201\n",
      "Epoch [19/50], Step [591/735], Loss: 0.0527\n",
      "Epoch [19/50], Step [592/735], Loss: 0.0905\n",
      "Epoch [19/50], Step [593/735], Loss: 0.3042\n",
      "Epoch [19/50], Step [594/735], Loss: 0.0396\n",
      "Epoch [19/50], Step [595/735], Loss: 0.2186\n",
      "Epoch [19/50], Step [596/735], Loss: 0.0671\n",
      "Epoch [19/50], Step [597/735], Loss: 0.0417\n",
      "Epoch [19/50], Step [598/735], Loss: 0.0704\n",
      "Epoch [19/50], Step [599/735], Loss: 0.1375\n",
      "Epoch [19/50], Step [600/735], Loss: 0.0748\n",
      "Epoch [19/50], Step [601/735], Loss: 0.0444\n",
      "Epoch [19/50], Step [602/735], Loss: 0.1309\n",
      "Epoch [19/50], Step [603/735], Loss: 0.0423\n",
      "Epoch [19/50], Step [604/735], Loss: 0.0247\n",
      "Epoch [19/50], Step [605/735], Loss: 0.0515\n",
      "Epoch [19/50], Step [606/735], Loss: 0.0457\n",
      "Epoch [19/50], Step [607/735], Loss: 0.0981\n",
      "Epoch [19/50], Step [608/735], Loss: 0.0393\n",
      "Epoch [19/50], Step [609/735], Loss: 0.1632\n",
      "Epoch [19/50], Step [610/735], Loss: 0.0646\n",
      "Epoch [19/50], Step [611/735], Loss: 0.1052\n",
      "Epoch [19/50], Step [612/735], Loss: 0.0494\n",
      "Epoch [19/50], Step [613/735], Loss: 0.0468\n",
      "Epoch [19/50], Step [614/735], Loss: 0.1397\n",
      "Epoch [19/50], Step [615/735], Loss: 0.0734\n",
      "Epoch [19/50], Step [616/735], Loss: 0.0801\n",
      "Epoch [19/50], Step [617/735], Loss: 0.0246\n",
      "Epoch [19/50], Step [618/735], Loss: 0.0689\n",
      "Epoch [19/50], Step [619/735], Loss: 0.0598\n",
      "Epoch [19/50], Step [620/735], Loss: 0.1704\n",
      "Epoch [19/50], Step [621/735], Loss: 0.1364\n",
      "Epoch [19/50], Step [622/735], Loss: 0.0184\n",
      "Epoch [19/50], Step [623/735], Loss: 0.0386\n",
      "Epoch [19/50], Step [624/735], Loss: 0.1524\n",
      "Epoch [19/50], Step [625/735], Loss: 0.0183\n",
      "Epoch [19/50], Step [626/735], Loss: 0.1176\n",
      "Epoch [19/50], Step [627/735], Loss: 0.0243\n",
      "Epoch [19/50], Step [628/735], Loss: 0.0760\n",
      "Epoch [19/50], Step [629/735], Loss: 0.2037\n",
      "Epoch [19/50], Step [630/735], Loss: 0.0144\n",
      "Epoch [19/50], Step [631/735], Loss: 0.1983\n",
      "Epoch [19/50], Step [632/735], Loss: 0.0653\n",
      "Epoch [19/50], Step [633/735], Loss: 0.0715\n",
      "Epoch [19/50], Step [634/735], Loss: 0.0590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Step [635/735], Loss: 0.0192\n",
      "Epoch [19/50], Step [636/735], Loss: 0.0256\n",
      "Epoch [19/50], Step [637/735], Loss: 0.0337\n",
      "Epoch [19/50], Step [638/735], Loss: 0.0364\n",
      "Epoch [19/50], Step [639/735], Loss: 0.1145\n",
      "Epoch [19/50], Step [640/735], Loss: 0.0447\n",
      "Epoch [19/50], Step [641/735], Loss: 0.1482\n",
      "Epoch [19/50], Step [642/735], Loss: 0.0965\n",
      "Epoch [19/50], Step [643/735], Loss: 0.0242\n",
      "Epoch [19/50], Step [644/735], Loss: 0.0664\n",
      "Epoch [19/50], Step [645/735], Loss: 0.0477\n",
      "Epoch [19/50], Step [646/735], Loss: 0.0921\n",
      "Epoch [19/50], Step [647/735], Loss: 0.0263\n",
      "Epoch [19/50], Step [648/735], Loss: 0.0584\n",
      "Epoch [19/50], Step [649/735], Loss: 0.0602\n",
      "Epoch [19/50], Step [650/735], Loss: 0.0262\n",
      "Epoch [19/50], Step [651/735], Loss: 0.1173\n",
      "Epoch [19/50], Step [652/735], Loss: 0.0677\n",
      "Epoch [19/50], Step [653/735], Loss: 0.1069\n",
      "Epoch [19/50], Step [654/735], Loss: 0.0774\n",
      "Epoch [19/50], Step [655/735], Loss: 0.2037\n",
      "Epoch [19/50], Step [656/735], Loss: 0.1006\n",
      "Epoch [19/50], Step [657/735], Loss: 0.0776\n",
      "Epoch [19/50], Step [658/735], Loss: 0.0573\n",
      "Epoch [19/50], Step [659/735], Loss: 0.0930\n",
      "Epoch [19/50], Step [660/735], Loss: 0.0653\n",
      "Epoch [19/50], Step [661/735], Loss: 0.0553\n",
      "Epoch [19/50], Step [662/735], Loss: 0.0584\n",
      "Epoch [19/50], Step [663/735], Loss: 0.0194\n",
      "Epoch [19/50], Step [664/735], Loss: 0.1170\n",
      "Epoch [19/50], Step [665/735], Loss: 0.2037\n",
      "Epoch [19/50], Step [666/735], Loss: 0.0414\n",
      "Epoch [19/50], Step [667/735], Loss: 0.0919\n",
      "Epoch [19/50], Step [668/735], Loss: 0.0468\n",
      "Epoch [19/50], Step [669/735], Loss: 0.0201\n",
      "Epoch [19/50], Step [670/735], Loss: 0.0909\n",
      "Epoch [19/50], Step [671/735], Loss: 0.0550\n",
      "Epoch [19/50], Step [672/735], Loss: 0.0194\n",
      "Epoch [19/50], Step [673/735], Loss: 0.0501\n",
      "Epoch [19/50], Step [674/735], Loss: 0.0734\n",
      "Epoch [19/50], Step [675/735], Loss: 0.0372\n",
      "Epoch [19/50], Step [676/735], Loss: 0.2983\n",
      "Epoch [19/50], Step [677/735], Loss: 0.0334\n",
      "Epoch [19/50], Step [678/735], Loss: 0.0973\n",
      "Epoch [19/50], Step [679/735], Loss: 0.0447\n",
      "Epoch [19/50], Step [680/735], Loss: 0.6118\n",
      "Epoch [19/50], Step [681/735], Loss: 0.0463\n",
      "Epoch [19/50], Step [682/735], Loss: 0.1216\n",
      "Epoch [19/50], Step [683/735], Loss: 0.0317\n",
      "Epoch [19/50], Step [684/735], Loss: 0.0338\n",
      "Epoch [19/50], Step [685/735], Loss: 0.1422\n",
      "Epoch [19/50], Step [686/735], Loss: 0.0324\n",
      "Epoch [19/50], Step [687/735], Loss: 0.0360\n",
      "Epoch [19/50], Step [688/735], Loss: 0.1350\n",
      "Epoch [19/50], Step [689/735], Loss: 0.0653\n",
      "Epoch [19/50], Step [690/735], Loss: 0.0612\n",
      "Epoch [19/50], Step [691/735], Loss: 0.0382\n",
      "Epoch [19/50], Step [692/735], Loss: 0.0461\n",
      "Epoch [19/50], Step [693/735], Loss: 0.0674\n",
      "Epoch [19/50], Step [694/735], Loss: 0.0283\n",
      "Epoch [19/50], Step [695/735], Loss: 0.0212\n",
      "Epoch [19/50], Step [696/735], Loss: 0.0376\n",
      "Epoch [19/50], Step [697/735], Loss: 0.0791\n",
      "Epoch [19/50], Step [698/735], Loss: 0.1214\n",
      "Epoch [19/50], Step [699/735], Loss: 0.0626\n",
      "Epoch [19/50], Step [700/735], Loss: 0.0921\n",
      "Epoch [19/50], Step [701/735], Loss: 0.2093\n",
      "Epoch [19/50], Step [702/735], Loss: 0.0387\n",
      "Epoch [19/50], Step [703/735], Loss: 0.0873\n",
      "Epoch [19/50], Step [704/735], Loss: 0.1530\n",
      "Epoch [19/50], Step [705/735], Loss: 0.0973\n",
      "Epoch [19/50], Step [706/735], Loss: 0.0731\n",
      "Epoch [19/50], Step [707/735], Loss: 0.0330\n",
      "Epoch [19/50], Step [708/735], Loss: 0.0588\n",
      "Epoch [19/50], Step [709/735], Loss: 0.1679\n",
      "Epoch [19/50], Step [710/735], Loss: 0.1124\n",
      "Epoch [19/50], Step [711/735], Loss: 0.0397\n",
      "Epoch [19/50], Step [712/735], Loss: 0.1199\n",
      "Epoch [19/50], Step [713/735], Loss: 0.0343\n",
      "Epoch [19/50], Step [714/735], Loss: 0.0646\n",
      "Epoch [19/50], Step [715/735], Loss: 0.0612\n",
      "Epoch [19/50], Step [716/735], Loss: 0.0218\n",
      "Epoch [19/50], Step [717/735], Loss: 0.0407\n",
      "Epoch [19/50], Step [718/735], Loss: 0.0273\n",
      "Epoch [19/50], Step [719/735], Loss: 0.0420\n",
      "Epoch [19/50], Step [720/735], Loss: 0.0555\n",
      "Epoch [19/50], Step [721/735], Loss: 0.1175\n",
      "Epoch [19/50], Step [722/735], Loss: 0.0279\n",
      "Epoch [19/50], Step [723/735], Loss: 0.1738\n",
      "Epoch [19/50], Step [724/735], Loss: 0.2517\n",
      "Epoch [19/50], Step [725/735], Loss: 0.0191\n",
      "Epoch [19/50], Step [726/735], Loss: 0.0978\n",
      "Epoch [19/50], Step [727/735], Loss: 0.1418\n",
      "Epoch [19/50], Step [728/735], Loss: 0.0361\n",
      "Epoch [19/50], Step [729/735], Loss: 0.0994\n",
      "Epoch [19/50], Step [730/735], Loss: 0.0693\n",
      "Epoch [19/50], Step [731/735], Loss: 0.2164\n",
      "Epoch [19/50], Step [732/735], Loss: 0.0925\n",
      "Epoch [19/50], Step [733/735], Loss: 0.0800\n",
      "Epoch [19/50], Step [734/735], Loss: 0.0418\n",
      "Epoch [19/50], Step [735/735], Loss: 0.0298\n",
      "Epoch [20/50], Step [1/735], Loss: 0.1370\n",
      "Epoch [20/50], Step [2/735], Loss: 0.0442\n",
      "Epoch [20/50], Step [3/735], Loss: 0.0528\n",
      "Epoch [20/50], Step [4/735], Loss: 0.4308\n",
      "Epoch [20/50], Step [5/735], Loss: 0.2232\n",
      "Epoch [20/50], Step [6/735], Loss: 0.0568\n",
      "Epoch [20/50], Step [7/735], Loss: 0.0687\n",
      "Epoch [20/50], Step [8/735], Loss: 0.3924\n",
      "Epoch [20/50], Step [9/735], Loss: 0.1658\n",
      "Epoch [20/50], Step [10/735], Loss: 0.0586\n",
      "Epoch [20/50], Step [11/735], Loss: 0.1359\n",
      "Epoch [20/50], Step [12/735], Loss: 0.1414\n",
      "Epoch [20/50], Step [13/735], Loss: 0.0823\n",
      "Epoch [20/50], Step [14/735], Loss: 0.0967\n",
      "Epoch [20/50], Step [15/735], Loss: 0.0947\n",
      "Epoch [20/50], Step [16/735], Loss: 0.1202\n",
      "Epoch [20/50], Step [17/735], Loss: 0.1773\n",
      "Epoch [20/50], Step [18/735], Loss: 0.0656\n",
      "Epoch [20/50], Step [19/735], Loss: 0.0884\n",
      "Epoch [20/50], Step [20/735], Loss: 0.1858\n",
      "Epoch [20/50], Step [21/735], Loss: 0.1274\n",
      "Epoch [20/50], Step [22/735], Loss: 0.1093\n",
      "Epoch [20/50], Step [23/735], Loss: 0.1411\n",
      "Epoch [20/50], Step [24/735], Loss: 0.0721\n",
      "Epoch [20/50], Step [25/735], Loss: 0.0742\n",
      "Epoch [20/50], Step [26/735], Loss: 0.0915\n",
      "Epoch [20/50], Step [27/735], Loss: 0.0935\n",
      "Epoch [20/50], Step [28/735], Loss: 0.0272\n",
      "Epoch [20/50], Step [29/735], Loss: 0.1664\n",
      "Epoch [20/50], Step [30/735], Loss: 0.0870\n",
      "Epoch [20/50], Step [31/735], Loss: 0.0567\n",
      "Epoch [20/50], Step [32/735], Loss: 0.0537\n",
      "Epoch [20/50], Step [33/735], Loss: 0.1345\n",
      "Epoch [20/50], Step [34/735], Loss: 0.0431\n",
      "Epoch [20/50], Step [35/735], Loss: 0.1608\n",
      "Epoch [20/50], Step [36/735], Loss: 0.1539\n",
      "Epoch [20/50], Step [37/735], Loss: 0.0319\n",
      "Epoch [20/50], Step [38/735], Loss: 0.1946\n",
      "Epoch [20/50], Step [39/735], Loss: 0.0772\n",
      "Epoch [20/50], Step [40/735], Loss: 0.5284\n",
      "Epoch [20/50], Step [41/735], Loss: 0.2499\n",
      "Epoch [20/50], Step [42/735], Loss: 0.0475\n",
      "Epoch [20/50], Step [43/735], Loss: 0.0773\n",
      "Epoch [20/50], Step [44/735], Loss: 0.0394\n",
      "Epoch [20/50], Step [45/735], Loss: 0.0364\n",
      "Epoch [20/50], Step [46/735], Loss: 0.0565\n",
      "Epoch [20/50], Step [47/735], Loss: 0.0468\n",
      "Epoch [20/50], Step [48/735], Loss: 0.3397\n",
      "Epoch [20/50], Step [49/735], Loss: 0.1324\n",
      "Epoch [20/50], Step [50/735], Loss: 0.0343\n",
      "Epoch [20/50], Step [51/735], Loss: 0.0953\n",
      "Epoch [20/50], Step [52/735], Loss: 0.0585\n",
      "Epoch [20/50], Step [53/735], Loss: 0.0611\n",
      "Epoch [20/50], Step [54/735], Loss: 0.0389\n",
      "Epoch [20/50], Step [55/735], Loss: 0.0301\n",
      "Epoch [20/50], Step [56/735], Loss: 0.2208\n",
      "Epoch [20/50], Step [57/735], Loss: 0.1820\n",
      "Epoch [20/50], Step [58/735], Loss: 0.0508\n",
      "Epoch [20/50], Step [59/735], Loss: 0.0783\n",
      "Epoch [20/50], Step [60/735], Loss: 0.2435\n",
      "Epoch [20/50], Step [61/735], Loss: 0.0397\n",
      "Epoch [20/50], Step [62/735], Loss: 0.2235\n",
      "Epoch [20/50], Step [63/735], Loss: 0.0838\n",
      "Epoch [20/50], Step [64/735], Loss: 0.0784\n",
      "Epoch [20/50], Step [65/735], Loss: 0.1241\n",
      "Epoch [20/50], Step [66/735], Loss: 0.1935\n",
      "Epoch [20/50], Step [67/735], Loss: 0.0984\n",
      "Epoch [20/50], Step [68/735], Loss: 0.0577\n",
      "Epoch [20/50], Step [69/735], Loss: 0.3027\n",
      "Epoch [20/50], Step [70/735], Loss: 0.0438\n",
      "Epoch [20/50], Step [71/735], Loss: 0.1336\n",
      "Epoch [20/50], Step [72/735], Loss: 0.0644\n",
      "Epoch [20/50], Step [73/735], Loss: 0.0465\n",
      "Epoch [20/50], Step [74/735], Loss: 0.0813\n",
      "Epoch [20/50], Step [75/735], Loss: 0.0699\n",
      "Epoch [20/50], Step [76/735], Loss: 0.1116\n",
      "Epoch [20/50], Step [77/735], Loss: 0.1350\n",
      "Epoch [20/50], Step [78/735], Loss: 0.0716\n",
      "Epoch [20/50], Step [79/735], Loss: 0.6824\n",
      "Epoch [20/50], Step [80/735], Loss: 0.0327\n",
      "Epoch [20/50], Step [81/735], Loss: 0.0496\n",
      "Epoch [20/50], Step [82/735], Loss: 0.1756\n",
      "Epoch [20/50], Step [83/735], Loss: 0.0819\n",
      "Epoch [20/50], Step [84/735], Loss: 0.0603\n",
      "Epoch [20/50], Step [85/735], Loss: 0.0608\n",
      "Epoch [20/50], Step [86/735], Loss: 0.0432\n",
      "Epoch [20/50], Step [87/735], Loss: 0.1223\n",
      "Epoch [20/50], Step [88/735], Loss: 0.0415\n",
      "Epoch [20/50], Step [89/735], Loss: 0.0584\n",
      "Epoch [20/50], Step [90/735], Loss: 0.1385\n",
      "Epoch [20/50], Step [91/735], Loss: 0.0295\n",
      "Epoch [20/50], Step [92/735], Loss: 0.0532\n",
      "Epoch [20/50], Step [93/735], Loss: 0.0479\n",
      "Epoch [20/50], Step [94/735], Loss: 0.0457\n",
      "Epoch [20/50], Step [95/735], Loss: 0.0875\n",
      "Epoch [20/50], Step [96/735], Loss: 0.2011\n",
      "Epoch [20/50], Step [97/735], Loss: 0.1398\n",
      "Epoch [20/50], Step [98/735], Loss: 0.1114\n",
      "Epoch [20/50], Step [99/735], Loss: 0.1454\n",
      "Epoch [20/50], Step [100/735], Loss: 0.0774\n",
      "Epoch [20/50], Step [101/735], Loss: 0.0679\n",
      "Epoch [20/50], Step [102/735], Loss: 0.0409\n",
      "Epoch [20/50], Step [103/735], Loss: 0.1936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Step [104/735], Loss: 0.1121\n",
      "Epoch [20/50], Step [105/735], Loss: 0.3431\n",
      "Epoch [20/50], Step [106/735], Loss: 0.0837\n",
      "Epoch [20/50], Step [107/735], Loss: 0.1324\n",
      "Epoch [20/50], Step [108/735], Loss: 0.0847\n",
      "Epoch [20/50], Step [109/735], Loss: 0.1768\n",
      "Epoch [20/50], Step [110/735], Loss: 0.0680\n",
      "Epoch [20/50], Step [111/735], Loss: 0.0527\n",
      "Epoch [20/50], Step [112/735], Loss: 0.0344\n",
      "Epoch [20/50], Step [113/735], Loss: 0.0419\n",
      "Epoch [20/50], Step [114/735], Loss: 0.0266\n",
      "Epoch [20/50], Step [115/735], Loss: 0.0383\n",
      "Epoch [20/50], Step [116/735], Loss: 0.0357\n",
      "Epoch [20/50], Step [117/735], Loss: 0.1795\n",
      "Epoch [20/50], Step [118/735], Loss: 0.0620\n",
      "Epoch [20/50], Step [119/735], Loss: 0.0576\n",
      "Epoch [20/50], Step [120/735], Loss: 0.0506\n",
      "Epoch [20/50], Step [121/735], Loss: 0.0391\n",
      "Epoch [20/50], Step [122/735], Loss: 0.0473\n",
      "Epoch [20/50], Step [123/735], Loss: 0.0372\n",
      "Epoch [20/50], Step [124/735], Loss: 0.0902\n",
      "Epoch [20/50], Step [125/735], Loss: 0.1632\n",
      "Epoch [20/50], Step [126/735], Loss: 0.0216\n",
      "Epoch [20/50], Step [127/735], Loss: 0.1463\n",
      "Epoch [20/50], Step [128/735], Loss: 0.3949\n",
      "Epoch [20/50], Step [129/735], Loss: 0.1043\n",
      "Epoch [20/50], Step [130/735], Loss: 0.0577\n",
      "Epoch [20/50], Step [131/735], Loss: 0.0929\n",
      "Epoch [20/50], Step [132/735], Loss: 0.2547\n",
      "Epoch [20/50], Step [133/735], Loss: 0.0958\n",
      "Epoch [20/50], Step [134/735], Loss: 0.0465\n",
      "Epoch [20/50], Step [135/735], Loss: 0.1311\n",
      "Epoch [20/50], Step [136/735], Loss: 0.0486\n",
      "Epoch [20/50], Step [137/735], Loss: 0.0388\n",
      "Epoch [20/50], Step [138/735], Loss: 0.1202\n",
      "Epoch [20/50], Step [139/735], Loss: 0.0764\n",
      "Epoch [20/50], Step [140/735], Loss: 0.1756\n",
      "Epoch [20/50], Step [141/735], Loss: 0.0770\n",
      "Epoch [20/50], Step [142/735], Loss: 0.0190\n",
      "Epoch [20/50], Step [143/735], Loss: 0.0803\n",
      "Epoch [20/50], Step [144/735], Loss: 0.0513\n",
      "Epoch [20/50], Step [145/735], Loss: 0.0530\n",
      "Epoch [20/50], Step [146/735], Loss: 0.0198\n",
      "Epoch [20/50], Step [147/735], Loss: 0.0513\n",
      "Epoch [20/50], Step [148/735], Loss: 0.0576\n",
      "Epoch [20/50], Step [149/735], Loss: 0.1336\n",
      "Epoch [20/50], Step [150/735], Loss: 0.0451\n",
      "Epoch [20/50], Step [151/735], Loss: 0.0231\n",
      "Epoch [20/50], Step [152/735], Loss: 0.0454\n",
      "Epoch [20/50], Step [153/735], Loss: 0.1213\n",
      "Epoch [20/50], Step [154/735], Loss: 0.0658\n",
      "Epoch [20/50], Step [155/735], Loss: 0.0907\n",
      "Epoch [20/50], Step [156/735], Loss: 0.0592\n",
      "Epoch [20/50], Step [157/735], Loss: 0.0728\n",
      "Epoch [20/50], Step [158/735], Loss: 0.1139\n",
      "Epoch [20/50], Step [159/735], Loss: 0.5228\n",
      "Epoch [20/50], Step [160/735], Loss: 0.0327\n",
      "Epoch [20/50], Step [161/735], Loss: 0.0342\n",
      "Epoch [20/50], Step [162/735], Loss: 0.0230\n",
      "Epoch [20/50], Step [163/735], Loss: 0.0318\n",
      "Epoch [20/50], Step [164/735], Loss: 0.1234\n",
      "Epoch [20/50], Step [165/735], Loss: 0.0943\n",
      "Epoch [20/50], Step [166/735], Loss: 0.0433\n",
      "Epoch [20/50], Step [167/735], Loss: 0.0344\n",
      "Epoch [20/50], Step [168/735], Loss: 0.1423\n",
      "Epoch [20/50], Step [169/735], Loss: 0.0865\n",
      "Epoch [20/50], Step [170/735], Loss: 0.0449\n",
      "Epoch [20/50], Step [171/735], Loss: 0.1117\n",
      "Epoch [20/50], Step [172/735], Loss: 0.0833\n",
      "Epoch [20/50], Step [173/735], Loss: 0.0899\n",
      "Epoch [20/50], Step [174/735], Loss: 0.0705\n",
      "Epoch [20/50], Step [175/735], Loss: 0.1896\n",
      "Epoch [20/50], Step [176/735], Loss: 0.0533\n",
      "Epoch [20/50], Step [177/735], Loss: 0.0541\n",
      "Epoch [20/50], Step [178/735], Loss: 0.5716\n",
      "Epoch [20/50], Step [179/735], Loss: 0.0378\n",
      "Epoch [20/50], Step [180/735], Loss: 0.0937\n",
      "Epoch [20/50], Step [181/735], Loss: 0.0991\n",
      "Epoch [20/50], Step [182/735], Loss: 0.0539\n",
      "Epoch [20/50], Step [183/735], Loss: 0.1165\n",
      "Epoch [20/50], Step [184/735], Loss: 0.0521\n",
      "Epoch [20/50], Step [185/735], Loss: 0.0285\n",
      "Epoch [20/50], Step [186/735], Loss: 0.0706\n",
      "Epoch [20/50], Step [187/735], Loss: 0.0689\n",
      "Epoch [20/50], Step [188/735], Loss: 0.0662\n",
      "Epoch [20/50], Step [189/735], Loss: 0.0500\n",
      "Epoch [20/50], Step [190/735], Loss: 0.0703\n",
      "Epoch [20/50], Step [191/735], Loss: 0.2740\n",
      "Epoch [20/50], Step [192/735], Loss: 0.2049\n",
      "Epoch [20/50], Step [193/735], Loss: 0.0812\n",
      "Epoch [20/50], Step [194/735], Loss: 0.3296\n",
      "Epoch [20/50], Step [195/735], Loss: 0.1277\n",
      "Epoch [20/50], Step [196/735], Loss: 0.0790\n",
      "Epoch [20/50], Step [197/735], Loss: 0.1017\n",
      "Epoch [20/50], Step [198/735], Loss: 0.0253\n",
      "Epoch [20/50], Step [199/735], Loss: 0.0252\n",
      "Epoch [20/50], Step [200/735], Loss: 0.0691\n",
      "Epoch [20/50], Step [201/735], Loss: 0.1036\n",
      "Epoch [20/50], Step [202/735], Loss: 0.2121\n",
      "Epoch [20/50], Step [203/735], Loss: 0.1040\n",
      "Epoch [20/50], Step [204/735], Loss: 0.1082\n",
      "Epoch [20/50], Step [205/735], Loss: 0.1100\n",
      "Epoch [20/50], Step [206/735], Loss: 0.0780\n",
      "Epoch [20/50], Step [207/735], Loss: 0.1213\n",
      "Epoch [20/50], Step [208/735], Loss: 0.0928\n",
      "Epoch [20/50], Step [209/735], Loss: 0.0387\n",
      "Epoch [20/50], Step [210/735], Loss: 0.0857\n",
      "Epoch [20/50], Step [211/735], Loss: 0.0772\n",
      "Epoch [20/50], Step [212/735], Loss: 0.3559\n",
      "Epoch [20/50], Step [213/735], Loss: 0.0743\n",
      "Epoch [20/50], Step [214/735], Loss: 0.0655\n",
      "Epoch [20/50], Step [215/735], Loss: 0.0407\n",
      "Epoch [20/50], Step [216/735], Loss: 0.2469\n",
      "Epoch [20/50], Step [217/735], Loss: 0.1008\n",
      "Epoch [20/50], Step [218/735], Loss: 0.1942\n",
      "Epoch [20/50], Step [219/735], Loss: 0.1362\n",
      "Epoch [20/50], Step [220/735], Loss: 0.0781\n",
      "Epoch [20/50], Step [221/735], Loss: 0.0442\n",
      "Epoch [20/50], Step [222/735], Loss: 0.0354\n",
      "Epoch [20/50], Step [223/735], Loss: 0.0643\n",
      "Epoch [20/50], Step [224/735], Loss: 0.1599\n",
      "Epoch [20/50], Step [225/735], Loss: 0.1168\n",
      "Epoch [20/50], Step [226/735], Loss: 0.0255\n",
      "Epoch [20/50], Step [227/735], Loss: 0.0507\n",
      "Epoch [20/50], Step [228/735], Loss: 0.0907\n",
      "Epoch [20/50], Step [229/735], Loss: 0.0553\n",
      "Epoch [20/50], Step [230/735], Loss: 0.0969\n",
      "Epoch [20/50], Step [231/735], Loss: 0.2859\n",
      "Epoch [20/50], Step [232/735], Loss: 0.0336\n",
      "Epoch [20/50], Step [233/735], Loss: 0.1566\n",
      "Epoch [20/50], Step [234/735], Loss: 0.0248\n",
      "Epoch [20/50], Step [235/735], Loss: 0.0463\n",
      "Epoch [20/50], Step [236/735], Loss: 0.0269\n",
      "Epoch [20/50], Step [237/735], Loss: 0.0885\n",
      "Epoch [20/50], Step [238/735], Loss: 0.0518\n",
      "Epoch [20/50], Step [239/735], Loss: 0.0505\n",
      "Epoch [20/50], Step [240/735], Loss: 0.0937\n",
      "Epoch [20/50], Step [241/735], Loss: 0.1300\n",
      "Epoch [20/50], Step [242/735], Loss: 0.1579\n",
      "Epoch [20/50], Step [243/735], Loss: 0.0617\n",
      "Epoch [20/50], Step [244/735], Loss: 0.0536\n",
      "Epoch [20/50], Step [245/735], Loss: 0.0763\n",
      "Epoch [20/50], Step [246/735], Loss: 0.0332\n",
      "Epoch [20/50], Step [247/735], Loss: 0.0353\n",
      "Epoch [20/50], Step [248/735], Loss: 0.0854\n",
      "Epoch [20/50], Step [249/735], Loss: 0.0779\n",
      "Epoch [20/50], Step [250/735], Loss: 0.1658\n",
      "Epoch [20/50], Step [251/735], Loss: 0.0623\n",
      "Epoch [20/50], Step [252/735], Loss: 0.0779\n",
      "Epoch [20/50], Step [253/735], Loss: 0.0762\n",
      "Epoch [20/50], Step [254/735], Loss: 0.0488\n",
      "Epoch [20/50], Step [255/735], Loss: 0.0297\n",
      "Epoch [20/50], Step [256/735], Loss: 0.0844\n",
      "Epoch [20/50], Step [257/735], Loss: 0.0346\n",
      "Epoch [20/50], Step [258/735], Loss: 0.0813\n",
      "Epoch [20/50], Step [259/735], Loss: 0.0675\n",
      "Epoch [20/50], Step [260/735], Loss: 0.6145\n",
      "Epoch [20/50], Step [261/735], Loss: 0.0445\n",
      "Epoch [20/50], Step [262/735], Loss: 0.0437\n",
      "Epoch [20/50], Step [263/735], Loss: 0.1792\n",
      "Epoch [20/50], Step [264/735], Loss: 0.0329\n",
      "Epoch [20/50], Step [265/735], Loss: 0.0519\n",
      "Epoch [20/50], Step [266/735], Loss: 0.0547\n",
      "Epoch [20/50], Step [267/735], Loss: 0.1115\n",
      "Epoch [20/50], Step [268/735], Loss: 0.2081\n",
      "Epoch [20/50], Step [269/735], Loss: 0.0599\n",
      "Epoch [20/50], Step [270/735], Loss: 0.0271\n",
      "Epoch [20/50], Step [271/735], Loss: 0.0397\n",
      "Epoch [20/50], Step [272/735], Loss: 0.0803\n",
      "Epoch [20/50], Step [273/735], Loss: 0.0591\n",
      "Epoch [20/50], Step [274/735], Loss: 0.0375\n",
      "Epoch [20/50], Step [275/735], Loss: 0.0281\n",
      "Epoch [20/50], Step [276/735], Loss: 0.1760\n",
      "Epoch [20/50], Step [277/735], Loss: 0.0795\n",
      "Epoch [20/50], Step [278/735], Loss: 0.1383\n",
      "Epoch [20/50], Step [279/735], Loss: 0.0384\n",
      "Epoch [20/50], Step [280/735], Loss: 0.0512\n",
      "Epoch [20/50], Step [281/735], Loss: 0.0984\n",
      "Epoch [20/50], Step [282/735], Loss: 0.0944\n",
      "Epoch [20/50], Step [283/735], Loss: 0.0642\n",
      "Epoch [20/50], Step [284/735], Loss: 0.0878\n",
      "Epoch [20/50], Step [285/735], Loss: 0.1392\n",
      "Epoch [20/50], Step [286/735], Loss: 0.0494\n",
      "Epoch [20/50], Step [287/735], Loss: 0.0787\n",
      "Epoch [20/50], Step [288/735], Loss: 0.0503\n",
      "Epoch [20/50], Step [289/735], Loss: 0.0455\n",
      "Epoch [20/50], Step [290/735], Loss: 0.0695\n",
      "Epoch [20/50], Step [291/735], Loss: 0.0567\n",
      "Epoch [20/50], Step [292/735], Loss: 0.0723\n",
      "Epoch [20/50], Step [293/735], Loss: 0.0516\n",
      "Epoch [20/50], Step [294/735], Loss: 0.2003\n",
      "Epoch [20/50], Step [295/735], Loss: 0.0450\n",
      "Epoch [20/50], Step [296/735], Loss: 0.0243\n",
      "Epoch [20/50], Step [297/735], Loss: 0.1894\n",
      "Epoch [20/50], Step [298/735], Loss: 0.1243\n",
      "Epoch [20/50], Step [299/735], Loss: 0.0742\n",
      "Epoch [20/50], Step [300/735], Loss: 0.3094\n",
      "Epoch [20/50], Step [301/735], Loss: 0.0625\n",
      "Epoch [20/50], Step [302/735], Loss: 0.0836\n",
      "Epoch [20/50], Step [303/735], Loss: 0.1730\n",
      "Epoch [20/50], Step [304/735], Loss: 0.0931\n",
      "Epoch [20/50], Step [305/735], Loss: 0.1887\n",
      "Epoch [20/50], Step [306/735], Loss: 0.0274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Step [307/735], Loss: 0.0372\n",
      "Epoch [20/50], Step [308/735], Loss: 0.0645\n",
      "Epoch [20/50], Step [309/735], Loss: 0.0815\n",
      "Epoch [20/50], Step [310/735], Loss: 0.2346\n",
      "Epoch [20/50], Step [311/735], Loss: 0.0374\n",
      "Epoch [20/50], Step [312/735], Loss: 0.1267\n",
      "Epoch [20/50], Step [313/735], Loss: 0.1147\n",
      "Epoch [20/50], Step [314/735], Loss: 0.0749\n",
      "Epoch [20/50], Step [315/735], Loss: 0.0498\n",
      "Epoch [20/50], Step [316/735], Loss: 0.0222\n",
      "Epoch [20/50], Step [317/735], Loss: 0.0335\n",
      "Epoch [20/50], Step [318/735], Loss: 0.0420\n",
      "Epoch [20/50], Step [319/735], Loss: 0.1055\n",
      "Epoch [20/50], Step [320/735], Loss: 0.0476\n",
      "Epoch [20/50], Step [321/735], Loss: 0.0251\n",
      "Epoch [20/50], Step [322/735], Loss: 0.0389\n",
      "Epoch [20/50], Step [323/735], Loss: 0.0364\n",
      "Epoch [20/50], Step [324/735], Loss: 0.0667\n",
      "Epoch [20/50], Step [325/735], Loss: 0.0545\n",
      "Epoch [20/50], Step [326/735], Loss: 0.1014\n",
      "Epoch [20/50], Step [327/735], Loss: 0.0766\n",
      "Epoch [20/50], Step [328/735], Loss: 0.0406\n",
      "Epoch [20/50], Step [329/735], Loss: 0.0924\n",
      "Epoch [20/50], Step [330/735], Loss: 0.1280\n",
      "Epoch [20/50], Step [331/735], Loss: 0.0415\n",
      "Epoch [20/50], Step [332/735], Loss: 0.0287\n",
      "Epoch [20/50], Step [333/735], Loss: 0.0428\n",
      "Epoch [20/50], Step [334/735], Loss: 0.0288\n",
      "Epoch [20/50], Step [335/735], Loss: 0.0869\n",
      "Epoch [20/50], Step [336/735], Loss: 0.0282\n",
      "Epoch [20/50], Step [337/735], Loss: 0.0551\n",
      "Epoch [20/50], Step [338/735], Loss: 0.0267\n",
      "Epoch [20/50], Step [339/735], Loss: 0.0797\n",
      "Epoch [20/50], Step [340/735], Loss: 0.0973\n",
      "Epoch [20/50], Step [341/735], Loss: 0.0972\n",
      "Epoch [20/50], Step [342/735], Loss: 0.4004\n",
      "Epoch [20/50], Step [343/735], Loss: 0.1253\n",
      "Epoch [20/50], Step [344/735], Loss: 0.0739\n",
      "Epoch [20/50], Step [345/735], Loss: 0.0412\n",
      "Epoch [20/50], Step [346/735], Loss: 0.0604\n",
      "Epoch [20/50], Step [347/735], Loss: 0.1191\n",
      "Epoch [20/50], Step [348/735], Loss: 0.0285\n",
      "Epoch [20/50], Step [349/735], Loss: 0.0510\n",
      "Epoch [20/50], Step [350/735], Loss: 0.0381\n",
      "Epoch [20/50], Step [351/735], Loss: 0.1494\n",
      "Epoch [20/50], Step [352/735], Loss: 0.0345\n",
      "Epoch [20/50], Step [353/735], Loss: 0.0425\n",
      "Epoch [20/50], Step [354/735], Loss: 0.1774\n",
      "Epoch [20/50], Step [355/735], Loss: 0.0644\n",
      "Epoch [20/50], Step [356/735], Loss: 0.1975\n",
      "Epoch [20/50], Step [357/735], Loss: 0.1422\n",
      "Epoch [20/50], Step [358/735], Loss: 0.1197\n",
      "Epoch [20/50], Step [359/735], Loss: 0.0569\n",
      "Epoch [20/50], Step [360/735], Loss: 0.1366\n",
      "Epoch [20/50], Step [361/735], Loss: 0.0768\n",
      "Epoch [20/50], Step [362/735], Loss: 0.0360\n",
      "Epoch [20/50], Step [363/735], Loss: 0.1101\n",
      "Epoch [20/50], Step [364/735], Loss: 0.1537\n",
      "Epoch [20/50], Step [365/735], Loss: 0.2467\n",
      "Epoch [20/50], Step [366/735], Loss: 0.1493\n",
      "Epoch [20/50], Step [367/735], Loss: 0.0433\n",
      "Epoch [20/50], Step [368/735], Loss: 0.0728\n",
      "Epoch [20/50], Step [369/735], Loss: 0.0815\n",
      "Epoch [20/50], Step [370/735], Loss: 0.0465\n",
      "Epoch [20/50], Step [371/735], Loss: 0.0755\n",
      "Epoch [20/50], Step [372/735], Loss: 0.1936\n",
      "Epoch [20/50], Step [373/735], Loss: 0.1112\n",
      "Epoch [20/50], Step [374/735], Loss: 0.1520\n",
      "Epoch [20/50], Step [375/735], Loss: 0.0934\n",
      "Epoch [20/50], Step [376/735], Loss: 0.0366\n",
      "Epoch [20/50], Step [377/735], Loss: 0.0278\n",
      "Epoch [20/50], Step [378/735], Loss: 0.0868\n",
      "Epoch [20/50], Step [379/735], Loss: 0.0923\n",
      "Epoch [20/50], Step [380/735], Loss: 0.0950\n",
      "Epoch [20/50], Step [381/735], Loss: 0.0480\n",
      "Epoch [20/50], Step [382/735], Loss: 0.0452\n",
      "Epoch [20/50], Step [383/735], Loss: 0.0185\n",
      "Epoch [20/50], Step [384/735], Loss: 0.1058\n",
      "Epoch [20/50], Step [385/735], Loss: 0.1043\n",
      "Epoch [20/50], Step [386/735], Loss: 0.0780\n",
      "Epoch [20/50], Step [387/735], Loss: 0.0509\n",
      "Epoch [20/50], Step [388/735], Loss: 0.4823\n",
      "Epoch [20/50], Step [389/735], Loss: 0.0683\n",
      "Epoch [20/50], Step [390/735], Loss: 0.0470\n",
      "Epoch [20/50], Step [391/735], Loss: 0.0954\n",
      "Epoch [20/50], Step [392/735], Loss: 0.1119\n",
      "Epoch [20/50], Step [393/735], Loss: 0.0945\n",
      "Epoch [20/50], Step [394/735], Loss: 0.0385\n",
      "Epoch [20/50], Step [395/735], Loss: 0.1237\n",
      "Epoch [20/50], Step [396/735], Loss: 0.0285\n",
      "Epoch [20/50], Step [397/735], Loss: 0.0735\n",
      "Epoch [20/50], Step [398/735], Loss: 0.0172\n",
      "Epoch [20/50], Step [399/735], Loss: 0.2746\n",
      "Epoch [20/50], Step [400/735], Loss: 0.0445\n",
      "Epoch [20/50], Step [401/735], Loss: 0.0177\n",
      "Epoch [20/50], Step [402/735], Loss: 0.0513\n",
      "Epoch [20/50], Step [403/735], Loss: 0.0642\n",
      "Epoch [20/50], Step [404/735], Loss: 0.2087\n",
      "Epoch [20/50], Step [405/735], Loss: 0.0761\n",
      "Epoch [20/50], Step [406/735], Loss: 0.0409\n",
      "Epoch [20/50], Step [407/735], Loss: 0.0256\n",
      "Epoch [20/50], Step [408/735], Loss: 0.1979\n",
      "Epoch [20/50], Step [409/735], Loss: 0.0543\n",
      "Epoch [20/50], Step [410/735], Loss: 0.0323\n",
      "Epoch [20/50], Step [411/735], Loss: 0.0808\n",
      "Epoch [20/50], Step [412/735], Loss: 0.1380\n",
      "Epoch [20/50], Step [413/735], Loss: 0.1076\n",
      "Epoch [20/50], Step [414/735], Loss: 0.1816\n",
      "Epoch [20/50], Step [415/735], Loss: 0.2383\n",
      "Epoch [20/50], Step [416/735], Loss: 0.0227\n",
      "Epoch [20/50], Step [417/735], Loss: 0.0809\n",
      "Epoch [20/50], Step [418/735], Loss: 0.0576\n",
      "Epoch [20/50], Step [419/735], Loss: 0.0586\n",
      "Epoch [20/50], Step [420/735], Loss: 0.0389\n",
      "Epoch [20/50], Step [421/735], Loss: 0.0793\n",
      "Epoch [20/50], Step [422/735], Loss: 0.0864\n",
      "Epoch [20/50], Step [423/735], Loss: 0.1120\n",
      "Epoch [20/50], Step [424/735], Loss: 0.0376\n",
      "Epoch [20/50], Step [425/735], Loss: 0.0940\n",
      "Epoch [20/50], Step [426/735], Loss: 0.0423\n",
      "Epoch [20/50], Step [427/735], Loss: 0.0692\n",
      "Epoch [20/50], Step [428/735], Loss: 0.0439\n",
      "Epoch [20/50], Step [429/735], Loss: 0.0592\n",
      "Epoch [20/50], Step [430/735], Loss: 0.0313\n",
      "Epoch [20/50], Step [431/735], Loss: 0.3840\n",
      "Epoch [20/50], Step [432/735], Loss: 0.1136\n",
      "Epoch [20/50], Step [433/735], Loss: 0.0678\n",
      "Epoch [20/50], Step [434/735], Loss: 0.0675\n",
      "Epoch [20/50], Step [435/735], Loss: 0.1072\n",
      "Epoch [20/50], Step [436/735], Loss: 0.1367\n",
      "Epoch [20/50], Step [437/735], Loss: 0.1053\n",
      "Epoch [20/50], Step [438/735], Loss: 0.0214\n",
      "Epoch [20/50], Step [439/735], Loss: 0.1354\n",
      "Epoch [20/50], Step [440/735], Loss: 0.0308\n",
      "Epoch [20/50], Step [441/735], Loss: 0.1579\n",
      "Epoch [20/50], Step [442/735], Loss: 0.1133\n",
      "Epoch [20/50], Step [443/735], Loss: 0.1606\n",
      "Epoch [20/50], Step [444/735], Loss: 0.0734\n",
      "Epoch [20/50], Step [445/735], Loss: 0.0578\n",
      "Epoch [20/50], Step [446/735], Loss: 0.0609\n",
      "Epoch [20/50], Step [447/735], Loss: 0.2085\n",
      "Epoch [20/50], Step [448/735], Loss: 0.0394\n",
      "Epoch [20/50], Step [449/735], Loss: 0.0466\n",
      "Epoch [20/50], Step [450/735], Loss: 0.0637\n",
      "Epoch [20/50], Step [451/735], Loss: 0.0430\n",
      "Epoch [20/50], Step [452/735], Loss: 0.0372\n",
      "Epoch [20/50], Step [453/735], Loss: 0.0367\n",
      "Epoch [20/50], Step [454/735], Loss: 0.6955\n",
      "Epoch [20/50], Step [455/735], Loss: 0.1173\n",
      "Epoch [20/50], Step [456/735], Loss: 0.1779\n",
      "Epoch [20/50], Step [457/735], Loss: 0.4579\n",
      "Epoch [20/50], Step [458/735], Loss: 0.1030\n",
      "Epoch [20/50], Step [459/735], Loss: 0.1149\n",
      "Epoch [20/50], Step [460/735], Loss: 0.0798\n",
      "Epoch [20/50], Step [461/735], Loss: 0.0654\n",
      "Epoch [20/50], Step [462/735], Loss: 0.0831\n",
      "Epoch [20/50], Step [463/735], Loss: 0.1312\n",
      "Epoch [20/50], Step [464/735], Loss: 0.2697\n",
      "Epoch [20/50], Step [465/735], Loss: 0.0792\n",
      "Epoch [20/50], Step [466/735], Loss: 0.0392\n",
      "Epoch [20/50], Step [467/735], Loss: 0.1129\n",
      "Epoch [20/50], Step [468/735], Loss: 0.1342\n",
      "Epoch [20/50], Step [469/735], Loss: 0.0416\n",
      "Epoch [20/50], Step [470/735], Loss: 0.0672\n",
      "Epoch [20/50], Step [471/735], Loss: 0.1829\n",
      "Epoch [20/50], Step [472/735], Loss: 0.1662\n",
      "Epoch [20/50], Step [473/735], Loss: 0.0977\n",
      "Epoch [20/50], Step [474/735], Loss: 0.1109\n",
      "Epoch [20/50], Step [475/735], Loss: 0.0755\n",
      "Epoch [20/50], Step [476/735], Loss: 0.0441\n",
      "Epoch [20/50], Step [477/735], Loss: 0.1387\n",
      "Epoch [20/50], Step [478/735], Loss: 0.0763\n",
      "Epoch [20/50], Step [479/735], Loss: 0.0887\n",
      "Epoch [20/50], Step [480/735], Loss: 0.2608\n",
      "Epoch [20/50], Step [481/735], Loss: 0.0966\n",
      "Epoch [20/50], Step [482/735], Loss: 0.0860\n",
      "Epoch [20/50], Step [483/735], Loss: 0.0737\n",
      "Epoch [20/50], Step [484/735], Loss: 0.1463\n",
      "Epoch [20/50], Step [485/735], Loss: 0.0563\n",
      "Epoch [20/50], Step [486/735], Loss: 0.0512\n",
      "Epoch [20/50], Step [487/735], Loss: 0.0468\n",
      "Epoch [20/50], Step [488/735], Loss: 0.0366\n",
      "Epoch [20/50], Step [489/735], Loss: 0.0971\n",
      "Epoch [20/50], Step [490/735], Loss: 0.0339\n",
      "Epoch [20/50], Step [491/735], Loss: 0.0713\n",
      "Epoch [20/50], Step [492/735], Loss: 0.0567\n",
      "Epoch [20/50], Step [493/735], Loss: 0.0727\n",
      "Epoch [20/50], Step [494/735], Loss: 0.1173\n",
      "Epoch [20/50], Step [495/735], Loss: 0.0613\n",
      "Epoch [20/50], Step [496/735], Loss: 0.0832\n",
      "Epoch [20/50], Step [497/735], Loss: 0.0464\n",
      "Epoch [20/50], Step [498/735], Loss: 0.0647\n",
      "Epoch [20/50], Step [499/735], Loss: 0.0971\n",
      "Epoch [20/50], Step [500/735], Loss: 0.1303\n",
      "Epoch [20/50], Step [501/735], Loss: 0.0757\n",
      "Epoch [20/50], Step [502/735], Loss: 0.1388\n",
      "Epoch [20/50], Step [503/735], Loss: 0.0683\n",
      "Epoch [20/50], Step [504/735], Loss: 0.0221\n",
      "Epoch [20/50], Step [505/735], Loss: 0.0480\n",
      "Epoch [20/50], Step [506/735], Loss: 0.2710\n",
      "Epoch [20/50], Step [507/735], Loss: 0.0994\n",
      "Epoch [20/50], Step [508/735], Loss: 0.1513\n",
      "Epoch [20/50], Step [509/735], Loss: 0.1466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Step [510/735], Loss: 0.0563\n",
      "Epoch [20/50], Step [511/735], Loss: 0.1344\n",
      "Epoch [20/50], Step [512/735], Loss: 0.0655\n",
      "Epoch [20/50], Step [513/735], Loss: 0.0355\n",
      "Epoch [20/50], Step [514/735], Loss: 0.0663\n",
      "Epoch [20/50], Step [515/735], Loss: 0.0718\n",
      "Epoch [20/50], Step [516/735], Loss: 0.0873\n",
      "Epoch [20/50], Step [517/735], Loss: 0.0668\n",
      "Epoch [20/50], Step [518/735], Loss: 0.1883\n",
      "Epoch [20/50], Step [519/735], Loss: 0.1671\n",
      "Epoch [20/50], Step [520/735], Loss: 0.0590\n",
      "Epoch [20/50], Step [521/735], Loss: 0.0199\n",
      "Epoch [20/50], Step [522/735], Loss: 0.0369\n",
      "Epoch [20/50], Step [523/735], Loss: 0.0181\n",
      "Epoch [20/50], Step [524/735], Loss: 0.0709\n",
      "Epoch [20/50], Step [525/735], Loss: 0.1260\n",
      "Epoch [20/50], Step [526/735], Loss: 0.0285\n",
      "Epoch [20/50], Step [527/735], Loss: 0.0478\n",
      "Epoch [20/50], Step [528/735], Loss: 0.0324\n",
      "Epoch [20/50], Step [529/735], Loss: 0.0234\n",
      "Epoch [20/50], Step [530/735], Loss: 0.1150\n",
      "Epoch [20/50], Step [531/735], Loss: 0.0727\n",
      "Epoch [20/50], Step [532/735], Loss: 0.1011\n",
      "Epoch [20/50], Step [533/735], Loss: 0.0455\n",
      "Epoch [20/50], Step [534/735], Loss: 0.0737\n",
      "Epoch [20/50], Step [535/735], Loss: 0.0586\n",
      "Epoch [20/50], Step [536/735], Loss: 0.0585\n",
      "Epoch [20/50], Step [537/735], Loss: 0.0525\n",
      "Epoch [20/50], Step [538/735], Loss: 0.0677\n",
      "Epoch [20/50], Step [539/735], Loss: 0.0459\n",
      "Epoch [20/50], Step [540/735], Loss: 0.0341\n",
      "Epoch [20/50], Step [541/735], Loss: 0.0340\n",
      "Epoch [20/50], Step [542/735], Loss: 0.1164\n",
      "Epoch [20/50], Step [543/735], Loss: 0.0454\n",
      "Epoch [20/50], Step [544/735], Loss: 0.0224\n",
      "Epoch [20/50], Step [545/735], Loss: 0.0360\n",
      "Epoch [20/50], Step [546/735], Loss: 0.1607\n",
      "Epoch [20/50], Step [547/735], Loss: 0.2406\n",
      "Epoch [20/50], Step [548/735], Loss: 0.0448\n",
      "Epoch [20/50], Step [549/735], Loss: 0.0341\n",
      "Epoch [20/50], Step [550/735], Loss: 0.0601\n",
      "Epoch [20/50], Step [551/735], Loss: 0.1575\n",
      "Epoch [20/50], Step [552/735], Loss: 0.0484\n",
      "Epoch [20/50], Step [553/735], Loss: 0.0945\n",
      "Epoch [20/50], Step [554/735], Loss: 0.0674\n",
      "Epoch [20/50], Step [555/735], Loss: 0.0284\n",
      "Epoch [20/50], Step [556/735], Loss: 0.0350\n",
      "Epoch [20/50], Step [557/735], Loss: 0.0455\n",
      "Epoch [20/50], Step [558/735], Loss: 0.0447\n",
      "Epoch [20/50], Step [559/735], Loss: 0.0850\n",
      "Epoch [20/50], Step [560/735], Loss: 0.0198\n",
      "Epoch [20/50], Step [561/735], Loss: 0.0590\n",
      "Epoch [20/50], Step [562/735], Loss: 0.0579\n",
      "Epoch [20/50], Step [563/735], Loss: 0.0204\n",
      "Epoch [20/50], Step [564/735], Loss: 0.1717\n",
      "Epoch [20/50], Step [565/735], Loss: 0.0270\n",
      "Epoch [20/50], Step [566/735], Loss: 0.0936\n",
      "Epoch [20/50], Step [567/735], Loss: 0.0911\n",
      "Epoch [20/50], Step [568/735], Loss: 0.0653\n",
      "Epoch [20/50], Step [569/735], Loss: 0.0884\n",
      "Epoch [20/50], Step [570/735], Loss: 0.0168\n",
      "Epoch [20/50], Step [571/735], Loss: 0.0327\n",
      "Epoch [20/50], Step [572/735], Loss: 0.1777\n",
      "Epoch [20/50], Step [573/735], Loss: 0.0907\n",
      "Epoch [20/50], Step [574/735], Loss: 0.0664\n",
      "Epoch [20/50], Step [575/735], Loss: 0.0932\n",
      "Epoch [20/50], Step [576/735], Loss: 0.0386\n",
      "Epoch [20/50], Step [577/735], Loss: 0.0760\n",
      "Epoch [20/50], Step [578/735], Loss: 0.0481\n",
      "Epoch [20/50], Step [579/735], Loss: 0.3221\n",
      "Epoch [20/50], Step [580/735], Loss: 0.1048\n",
      "Epoch [20/50], Step [581/735], Loss: 0.1184\n",
      "Epoch [20/50], Step [582/735], Loss: 0.1259\n",
      "Epoch [20/50], Step [583/735], Loss: 0.0283\n",
      "Epoch [20/50], Step [584/735], Loss: 0.0323\n",
      "Epoch [20/50], Step [585/735], Loss: 0.1703\n",
      "Epoch [20/50], Step [586/735], Loss: 0.2766\n",
      "Epoch [20/50], Step [587/735], Loss: 0.5872\n",
      "Epoch [20/50], Step [588/735], Loss: 0.2485\n",
      "Epoch [20/50], Step [589/735], Loss: 0.0475\n",
      "Epoch [20/50], Step [590/735], Loss: 0.1793\n",
      "Epoch [20/50], Step [591/735], Loss: 0.0930\n",
      "Epoch [20/50], Step [592/735], Loss: 0.0574\n",
      "Epoch [20/50], Step [593/735], Loss: 0.0758\n",
      "Epoch [20/50], Step [594/735], Loss: 0.0807\n",
      "Epoch [20/50], Step [595/735], Loss: 0.1120\n",
      "Epoch [20/50], Step [596/735], Loss: 0.0245\n",
      "Epoch [20/50], Step [597/735], Loss: 0.0923\n",
      "Epoch [20/50], Step [598/735], Loss: 0.0832\n",
      "Epoch [20/50], Step [599/735], Loss: 0.0359\n",
      "Epoch [20/50], Step [600/735], Loss: 0.0287\n",
      "Epoch [20/50], Step [601/735], Loss: 0.0610\n",
      "Epoch [20/50], Step [602/735], Loss: 0.0485\n",
      "Epoch [20/50], Step [603/735], Loss: 0.0853\n",
      "Epoch [20/50], Step [604/735], Loss: 0.0658\n",
      "Epoch [20/50], Step [605/735], Loss: 0.2986\n",
      "Epoch [20/50], Step [606/735], Loss: 0.0422\n",
      "Epoch [20/50], Step [607/735], Loss: 0.0257\n",
      "Epoch [20/50], Step [608/735], Loss: 0.2008\n",
      "Epoch [20/50], Step [609/735], Loss: 0.0810\n",
      "Epoch [20/50], Step [610/735], Loss: 0.0898\n",
      "Epoch [20/50], Step [611/735], Loss: 0.1339\n",
      "Epoch [20/50], Step [612/735], Loss: 0.1057\n",
      "Epoch [20/50], Step [613/735], Loss: 0.0337\n",
      "Epoch [20/50], Step [614/735], Loss: 0.0338\n",
      "Epoch [20/50], Step [615/735], Loss: 0.0486\n",
      "Epoch [20/50], Step [616/735], Loss: 0.0538\n",
      "Epoch [20/50], Step [617/735], Loss: 0.0892\n",
      "Epoch [20/50], Step [618/735], Loss: 0.0425\n",
      "Epoch [20/50], Step [619/735], Loss: 0.0608\n",
      "Epoch [20/50], Step [620/735], Loss: 0.1598\n",
      "Epoch [20/50], Step [621/735], Loss: 0.0521\n",
      "Epoch [20/50], Step [622/735], Loss: 0.1543\n",
      "Epoch [20/50], Step [623/735], Loss: 0.2525\n",
      "Epoch [20/50], Step [624/735], Loss: 0.0422\n",
      "Epoch [20/50], Step [625/735], Loss: 0.0495\n",
      "Epoch [20/50], Step [626/735], Loss: 0.0435\n",
      "Epoch [20/50], Step [627/735], Loss: 0.2623\n",
      "Epoch [20/50], Step [628/735], Loss: 0.0232\n",
      "Epoch [20/50], Step [629/735], Loss: 0.1360\n",
      "Epoch [20/50], Step [630/735], Loss: 0.1168\n",
      "Epoch [20/50], Step [631/735], Loss: 0.1772\n",
      "Epoch [20/50], Step [632/735], Loss: 0.0970\n",
      "Epoch [20/50], Step [633/735], Loss: 0.0480\n",
      "Epoch [20/50], Step [634/735], Loss: 0.3212\n",
      "Epoch [20/50], Step [635/735], Loss: 0.1212\n",
      "Epoch [20/50], Step [636/735], Loss: 0.0319\n",
      "Epoch [20/50], Step [637/735], Loss: 0.2043\n",
      "Epoch [20/50], Step [638/735], Loss: 0.0437\n",
      "Epoch [20/50], Step [639/735], Loss: 0.0555\n",
      "Epoch [20/50], Step [640/735], Loss: 0.0154\n",
      "Epoch [20/50], Step [641/735], Loss: 0.0336\n",
      "Epoch [20/50], Step [642/735], Loss: 0.0770\n",
      "Epoch [20/50], Step [643/735], Loss: 0.0403\n",
      "Epoch [20/50], Step [644/735], Loss: 0.0991\n",
      "Epoch [20/50], Step [645/735], Loss: 0.0821\n",
      "Epoch [20/50], Step [646/735], Loss: 0.0315\n",
      "Epoch [20/50], Step [647/735], Loss: 0.0194\n",
      "Epoch [20/50], Step [648/735], Loss: 0.0752\n",
      "Epoch [20/50], Step [649/735], Loss: 0.0688\n",
      "Epoch [20/50], Step [650/735], Loss: 0.0646\n",
      "Epoch [20/50], Step [651/735], Loss: 0.1049\n",
      "Epoch [20/50], Step [652/735], Loss: 0.0357\n",
      "Epoch [20/50], Step [653/735], Loss: 0.1603\n",
      "Epoch [20/50], Step [654/735], Loss: 0.0540\n",
      "Epoch [20/50], Step [655/735], Loss: 0.1052\n",
      "Epoch [20/50], Step [656/735], Loss: 0.0435\n",
      "Epoch [20/50], Step [657/735], Loss: 0.2194\n",
      "Epoch [20/50], Step [658/735], Loss: 0.0740\n",
      "Epoch [20/50], Step [659/735], Loss: 0.0833\n",
      "Epoch [20/50], Step [660/735], Loss: 0.0314\n",
      "Epoch [20/50], Step [661/735], Loss: 0.0266\n",
      "Epoch [20/50], Step [662/735], Loss: 0.1503\n",
      "Epoch [20/50], Step [663/735], Loss: 0.0305\n",
      "Epoch [20/50], Step [664/735], Loss: 0.0668\n",
      "Epoch [20/50], Step [665/735], Loss: 0.0284\n",
      "Epoch [20/50], Step [666/735], Loss: 0.0402\n",
      "Epoch [20/50], Step [667/735], Loss: 0.1229\n",
      "Epoch [20/50], Step [668/735], Loss: 0.0514\n",
      "Epoch [20/50], Step [669/735], Loss: 0.0935\n",
      "Epoch [20/50], Step [670/735], Loss: 0.1777\n",
      "Epoch [20/50], Step [671/735], Loss: 0.0460\n",
      "Epoch [20/50], Step [672/735], Loss: 0.0490\n",
      "Epoch [20/50], Step [673/735], Loss: 0.1852\n",
      "Epoch [20/50], Step [674/735], Loss: 0.1654\n",
      "Epoch [20/50], Step [675/735], Loss: 0.0391\n",
      "Epoch [20/50], Step [676/735], Loss: 0.2504\n",
      "Epoch [20/50], Step [677/735], Loss: 0.2955\n",
      "Epoch [20/50], Step [678/735], Loss: 0.0634\n",
      "Epoch [20/50], Step [679/735], Loss: 0.1411\n",
      "Epoch [20/50], Step [680/735], Loss: 0.0831\n",
      "Epoch [20/50], Step [681/735], Loss: 0.1650\n",
      "Epoch [20/50], Step [682/735], Loss: 0.0416\n",
      "Epoch [20/50], Step [683/735], Loss: 0.2922\n",
      "Epoch [20/50], Step [684/735], Loss: 0.0602\n",
      "Epoch [20/50], Step [685/735], Loss: 0.1006\n",
      "Epoch [20/50], Step [686/735], Loss: 0.0679\n",
      "Epoch [20/50], Step [687/735], Loss: 0.1542\n",
      "Epoch [20/50], Step [688/735], Loss: 0.1700\n",
      "Epoch [20/50], Step [689/735], Loss: 0.0262\n",
      "Epoch [20/50], Step [690/735], Loss: 0.0424\n",
      "Epoch [20/50], Step [691/735], Loss: 0.0233\n",
      "Epoch [20/50], Step [692/735], Loss: 0.1205\n",
      "Epoch [20/50], Step [693/735], Loss: 0.0580\n",
      "Epoch [20/50], Step [694/735], Loss: 0.0951\n",
      "Epoch [20/50], Step [695/735], Loss: 0.0393\n",
      "Epoch [20/50], Step [696/735], Loss: 0.0213\n",
      "Epoch [20/50], Step [697/735], Loss: 0.1077\n",
      "Epoch [20/50], Step [698/735], Loss: 0.0725\n",
      "Epoch [20/50], Step [699/735], Loss: 0.1184\n",
      "Epoch [20/50], Step [700/735], Loss: 0.0930\n",
      "Epoch [20/50], Step [701/735], Loss: 0.0658\n",
      "Epoch [20/50], Step [702/735], Loss: 0.0442\n",
      "Epoch [20/50], Step [703/735], Loss: 0.0353\n",
      "Epoch [20/50], Step [704/735], Loss: 0.1331\n",
      "Epoch [20/50], Step [705/735], Loss: 0.0475\n",
      "Epoch [20/50], Step [706/735], Loss: 0.0669\n",
      "Epoch [20/50], Step [707/735], Loss: 0.1515\n",
      "Epoch [20/50], Step [708/735], Loss: 0.3014\n",
      "Epoch [20/50], Step [709/735], Loss: 0.1170\n",
      "Epoch [20/50], Step [710/735], Loss: 0.0273\n",
      "Epoch [20/50], Step [711/735], Loss: 0.0378\n",
      "Epoch [20/50], Step [712/735], Loss: 0.1711\n",
      "Epoch [20/50], Step [713/735], Loss: 0.2026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Step [714/735], Loss: 0.1269\n",
      "Epoch [20/50], Step [715/735], Loss: 0.1583\n",
      "Epoch [20/50], Step [716/735], Loss: 0.0323\n",
      "Epoch [20/50], Step [717/735], Loss: 0.0282\n",
      "Epoch [20/50], Step [718/735], Loss: 0.0723\n",
      "Epoch [20/50], Step [719/735], Loss: 0.1640\n",
      "Epoch [20/50], Step [720/735], Loss: 0.0539\n",
      "Epoch [20/50], Step [721/735], Loss: 0.1833\n",
      "Epoch [20/50], Step [722/735], Loss: 0.0391\n",
      "Epoch [20/50], Step [723/735], Loss: 0.0663\n",
      "Epoch [20/50], Step [724/735], Loss: 0.0242\n",
      "Epoch [20/50], Step [725/735], Loss: 0.1518\n",
      "Epoch [20/50], Step [726/735], Loss: 0.0565\n",
      "Epoch [20/50], Step [727/735], Loss: 0.0619\n",
      "Epoch [20/50], Step [728/735], Loss: 0.0746\n",
      "Epoch [20/50], Step [729/735], Loss: 0.1331\n",
      "Epoch [20/50], Step [730/735], Loss: 0.0499\n",
      "Epoch [20/50], Step [731/735], Loss: 0.0313\n",
      "Epoch [20/50], Step [732/735], Loss: 0.2287\n",
      "Epoch [20/50], Step [733/735], Loss: 0.1964\n",
      "Epoch [20/50], Step [734/735], Loss: 0.0997\n",
      "Epoch [20/50], Step [735/735], Loss: 0.1442\n",
      "Epoch [21/50], Step [1/735], Loss: 0.0437\n",
      "Epoch [21/50], Step [2/735], Loss: 0.0535\n",
      "Epoch [21/50], Step [3/735], Loss: 0.1459\n",
      "Epoch [21/50], Step [4/735], Loss: 0.0247\n",
      "Epoch [21/50], Step [5/735], Loss: 0.0230\n",
      "Epoch [21/50], Step [6/735], Loss: 0.0266\n",
      "Epoch [21/50], Step [7/735], Loss: 0.0701\n",
      "Epoch [21/50], Step [8/735], Loss: 0.0673\n",
      "Epoch [21/50], Step [9/735], Loss: 0.0924\n",
      "Epoch [21/50], Step [10/735], Loss: 0.0902\n",
      "Epoch [21/50], Step [11/735], Loss: 0.0551\n",
      "Epoch [21/50], Step [12/735], Loss: 0.0893\n",
      "Epoch [21/50], Step [13/735], Loss: 0.0884\n",
      "Epoch [21/50], Step [14/735], Loss: 0.1490\n",
      "Epoch [21/50], Step [15/735], Loss: 0.0454\n",
      "Epoch [21/50], Step [16/735], Loss: 0.0478\n",
      "Epoch [21/50], Step [17/735], Loss: 0.0305\n",
      "Epoch [21/50], Step [18/735], Loss: 0.1582\n",
      "Epoch [21/50], Step [19/735], Loss: 0.0123\n",
      "Epoch [21/50], Step [20/735], Loss: 0.0411\n",
      "Epoch [21/50], Step [21/735], Loss: 0.0503\n",
      "Epoch [21/50], Step [22/735], Loss: 0.0827\n",
      "Epoch [21/50], Step [23/735], Loss: 0.1212\n",
      "Epoch [21/50], Step [24/735], Loss: 0.2100\n",
      "Epoch [21/50], Step [25/735], Loss: 0.0602\n",
      "Epoch [21/50], Step [26/735], Loss: 0.0630\n",
      "Epoch [21/50], Step [27/735], Loss: 0.0451\n",
      "Epoch [21/50], Step [28/735], Loss: 0.0433\n",
      "Epoch [21/50], Step [29/735], Loss: 0.0737\n",
      "Epoch [21/50], Step [30/735], Loss: 0.1189\n",
      "Epoch [21/50], Step [31/735], Loss: 0.1345\n",
      "Epoch [21/50], Step [32/735], Loss: 0.0256\n",
      "Epoch [21/50], Step [33/735], Loss: 0.1535\n",
      "Epoch [21/50], Step [34/735], Loss: 0.0820\n",
      "Epoch [21/50], Step [35/735], Loss: 0.0945\n",
      "Epoch [21/50], Step [36/735], Loss: 0.0281\n",
      "Epoch [21/50], Step [37/735], Loss: 0.1252\n",
      "Epoch [21/50], Step [38/735], Loss: 0.0266\n",
      "Epoch [21/50], Step [39/735], Loss: 0.0581\n",
      "Epoch [21/50], Step [40/735], Loss: 0.0403\n",
      "Epoch [21/50], Step [41/735], Loss: 0.0748\n",
      "Epoch [21/50], Step [42/735], Loss: 0.2285\n",
      "Epoch [21/50], Step [43/735], Loss: 0.0623\n",
      "Epoch [21/50], Step [44/735], Loss: 0.1090\n",
      "Epoch [21/50], Step [45/735], Loss: 0.1059\n",
      "Epoch [21/50], Step [46/735], Loss: 0.0392\n",
      "Epoch [21/50], Step [47/735], Loss: 0.2460\n",
      "Epoch [21/50], Step [48/735], Loss: 0.1229\n",
      "Epoch [21/50], Step [49/735], Loss: 0.0435\n",
      "Epoch [21/50], Step [50/735], Loss: 0.1351\n",
      "Epoch [21/50], Step [51/735], Loss: 0.0373\n",
      "Epoch [21/50], Step [52/735], Loss: 0.1019\n",
      "Epoch [21/50], Step [53/735], Loss: 0.1115\n",
      "Epoch [21/50], Step [54/735], Loss: 0.0593\n",
      "Epoch [21/50], Step [55/735], Loss: 0.0900\n",
      "Epoch [21/50], Step [56/735], Loss: 0.1518\n",
      "Epoch [21/50], Step [57/735], Loss: 0.0669\n",
      "Epoch [21/50], Step [58/735], Loss: 0.0947\n",
      "Epoch [21/50], Step [59/735], Loss: 0.1028\n",
      "Epoch [21/50], Step [60/735], Loss: 0.0973\n",
      "Epoch [21/50], Step [61/735], Loss: 0.0817\n",
      "Epoch [21/50], Step [62/735], Loss: 0.1428\n",
      "Epoch [21/50], Step [63/735], Loss: 0.1525\n",
      "Epoch [21/50], Step [64/735], Loss: 0.0460\n",
      "Epoch [21/50], Step [65/735], Loss: 0.0585\n",
      "Epoch [21/50], Step [66/735], Loss: 0.0225\n",
      "Epoch [21/50], Step [67/735], Loss: 0.0233\n",
      "Epoch [21/50], Step [68/735], Loss: 0.0521\n",
      "Epoch [21/50], Step [69/735], Loss: 0.0374\n",
      "Epoch [21/50], Step [70/735], Loss: 0.0256\n",
      "Epoch [21/50], Step [71/735], Loss: 0.1705\n",
      "Epoch [21/50], Step [72/735], Loss: 0.1158\n",
      "Epoch [21/50], Step [73/735], Loss: 0.0606\n",
      "Epoch [21/50], Step [74/735], Loss: 0.0426\n",
      "Epoch [21/50], Step [75/735], Loss: 0.0434\n",
      "Epoch [21/50], Step [76/735], Loss: 0.0890\n",
      "Epoch [21/50], Step [77/735], Loss: 0.1318\n",
      "Epoch [21/50], Step [78/735], Loss: 0.1435\n",
      "Epoch [21/50], Step [79/735], Loss: 0.1059\n",
      "Epoch [21/50], Step [80/735], Loss: 0.0297\n",
      "Epoch [21/50], Step [81/735], Loss: 0.2255\n",
      "Epoch [21/50], Step [82/735], Loss: 0.0311\n",
      "Epoch [21/50], Step [83/735], Loss: 0.0704\n",
      "Epoch [21/50], Step [84/735], Loss: 0.0252\n",
      "Epoch [21/50], Step [85/735], Loss: 0.0529\n",
      "Epoch [21/50], Step [86/735], Loss: 0.0311\n",
      "Epoch [21/50], Step [87/735], Loss: 0.0472\n",
      "Epoch [21/50], Step [88/735], Loss: 0.0516\n",
      "Epoch [21/50], Step [89/735], Loss: 0.1778\n",
      "Epoch [21/50], Step [90/735], Loss: 0.0549\n",
      "Epoch [21/50], Step [91/735], Loss: 0.0304\n",
      "Epoch [21/50], Step [92/735], Loss: 0.0868\n",
      "Epoch [21/50], Step [93/735], Loss: 0.0659\n",
      "Epoch [21/50], Step [94/735], Loss: 0.0664\n",
      "Epoch [21/50], Step [95/735], Loss: 0.0353\n",
      "Epoch [21/50], Step [96/735], Loss: 0.1267\n",
      "Epoch [21/50], Step [97/735], Loss: 0.0409\n",
      "Epoch [21/50], Step [98/735], Loss: 0.0801\n",
      "Epoch [21/50], Step [99/735], Loss: 0.1734\n",
      "Epoch [21/50], Step [100/735], Loss: 0.0237\n",
      "Epoch [21/50], Step [101/735], Loss: 0.1618\n",
      "Epoch [21/50], Step [102/735], Loss: 0.0533\n",
      "Epoch [21/50], Step [103/735], Loss: 0.0792\n",
      "Epoch [21/50], Step [104/735], Loss: 0.0633\n",
      "Epoch [21/50], Step [105/735], Loss: 0.2925\n",
      "Epoch [21/50], Step [106/735], Loss: 0.0671\n",
      "Epoch [21/50], Step [107/735], Loss: 0.0943\n",
      "Epoch [21/50], Step [108/735], Loss: 0.0616\n",
      "Epoch [21/50], Step [109/735], Loss: 0.0815\n",
      "Epoch [21/50], Step [110/735], Loss: 0.0968\n",
      "Epoch [21/50], Step [111/735], Loss: 0.0547\n",
      "Epoch [21/50], Step [112/735], Loss: 0.0711\n",
      "Epoch [21/50], Step [113/735], Loss: 0.0210\n",
      "Epoch [21/50], Step [114/735], Loss: 0.0553\n",
      "Epoch [21/50], Step [115/735], Loss: 0.0927\n",
      "Epoch [21/50], Step [116/735], Loss: 0.0692\n",
      "Epoch [21/50], Step [117/735], Loss: 0.0576\n",
      "Epoch [21/50], Step [118/735], Loss: 0.0337\n",
      "Epoch [21/50], Step [119/735], Loss: 0.0876\n",
      "Epoch [21/50], Step [120/735], Loss: 0.1436\n",
      "Epoch [21/50], Step [121/735], Loss: 0.0908\n",
      "Epoch [21/50], Step [122/735], Loss: 0.0610\n",
      "Epoch [21/50], Step [123/735], Loss: 0.3520\n",
      "Epoch [21/50], Step [124/735], Loss: 0.0438\n",
      "Epoch [21/50], Step [125/735], Loss: 0.0350\n",
      "Epoch [21/50], Step [126/735], Loss: 0.0966\n",
      "Epoch [21/50], Step [127/735], Loss: 0.1348\n",
      "Epoch [21/50], Step [128/735], Loss: 0.0407\n",
      "Epoch [21/50], Step [129/735], Loss: 0.0460\n",
      "Epoch [21/50], Step [130/735], Loss: 0.0524\n",
      "Epoch [21/50], Step [131/735], Loss: 0.0766\n",
      "Epoch [21/50], Step [132/735], Loss: 0.0807\n",
      "Epoch [21/50], Step [133/735], Loss: 0.1397\n",
      "Epoch [21/50], Step [134/735], Loss: 0.1731\n",
      "Epoch [21/50], Step [135/735], Loss: 0.0688\n",
      "Epoch [21/50], Step [136/735], Loss: 0.0726\n",
      "Epoch [21/50], Step [137/735], Loss: 0.1441\n",
      "Epoch [21/50], Step [138/735], Loss: 0.0897\n",
      "Epoch [21/50], Step [139/735], Loss: 0.0268\n",
      "Epoch [21/50], Step [140/735], Loss: 0.0952\n",
      "Epoch [21/50], Step [141/735], Loss: 0.0550\n",
      "Epoch [21/50], Step [142/735], Loss: 0.1522\n",
      "Epoch [21/50], Step [143/735], Loss: 0.0481\n",
      "Epoch [21/50], Step [144/735], Loss: 0.0230\n",
      "Epoch [21/50], Step [145/735], Loss: 0.0292\n",
      "Epoch [21/50], Step [146/735], Loss: 0.0229\n",
      "Epoch [21/50], Step [147/735], Loss: 0.0791\n",
      "Epoch [21/50], Step [148/735], Loss: 0.1352\n",
      "Epoch [21/50], Step [149/735], Loss: 0.0332\n",
      "Epoch [21/50], Step [150/735], Loss: 0.1332\n",
      "Epoch [21/50], Step [151/735], Loss: 0.1827\n",
      "Epoch [21/50], Step [152/735], Loss: 0.0165\n",
      "Epoch [21/50], Step [153/735], Loss: 0.0605\n",
      "Epoch [21/50], Step [154/735], Loss: 0.0371\n",
      "Epoch [21/50], Step [155/735], Loss: 0.1151\n",
      "Epoch [21/50], Step [156/735], Loss: 0.0612\n",
      "Epoch [21/50], Step [157/735], Loss: 0.0443\n",
      "Epoch [21/50], Step [158/735], Loss: 0.0269\n",
      "Epoch [21/50], Step [159/735], Loss: 0.0978\n",
      "Epoch [21/50], Step [160/735], Loss: 0.2603\n",
      "Epoch [21/50], Step [161/735], Loss: 0.1093\n",
      "Epoch [21/50], Step [162/735], Loss: 0.2526\n",
      "Epoch [21/50], Step [163/735], Loss: 0.0711\n",
      "Epoch [21/50], Step [164/735], Loss: 0.1320\n",
      "Epoch [21/50], Step [165/735], Loss: 0.6660\n",
      "Epoch [21/50], Step [166/735], Loss: 0.0487\n",
      "Epoch [21/50], Step [167/735], Loss: 0.0459\n",
      "Epoch [21/50], Step [168/735], Loss: 0.0229\n",
      "Epoch [21/50], Step [169/735], Loss: 0.3327\n",
      "Epoch [21/50], Step [170/735], Loss: 0.0403\n",
      "Epoch [21/50], Step [171/735], Loss: 0.2461\n",
      "Epoch [21/50], Step [172/735], Loss: 0.0441\n",
      "Epoch [21/50], Step [173/735], Loss: 0.0382\n",
      "Epoch [21/50], Step [174/735], Loss: 0.0385\n",
      "Epoch [21/50], Step [175/735], Loss: 0.1640\n",
      "Epoch [21/50], Step [176/735], Loss: 0.0354\n",
      "Epoch [21/50], Step [177/735], Loss: 0.0833\n",
      "Epoch [21/50], Step [178/735], Loss: 0.0896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Step [179/735], Loss: 0.0554\n",
      "Epoch [21/50], Step [180/735], Loss: 0.1260\n",
      "Epoch [21/50], Step [181/735], Loss: 0.1130\n",
      "Epoch [21/50], Step [182/735], Loss: 0.2491\n",
      "Epoch [21/50], Step [183/735], Loss: 0.1403\n",
      "Epoch [21/50], Step [184/735], Loss: 0.0797\n",
      "Epoch [21/50], Step [185/735], Loss: 0.0305\n",
      "Epoch [21/50], Step [186/735], Loss: 0.0411\n",
      "Epoch [21/50], Step [187/735], Loss: 0.0607\n",
      "Epoch [21/50], Step [188/735], Loss: 0.0407\n",
      "Epoch [21/50], Step [189/735], Loss: 0.1073\n",
      "Epoch [21/50], Step [190/735], Loss: 0.0929\n",
      "Epoch [21/50], Step [191/735], Loss: 0.0841\n",
      "Epoch [21/50], Step [192/735], Loss: 0.0482\n",
      "Epoch [21/50], Step [193/735], Loss: 0.1580\n",
      "Epoch [21/50], Step [194/735], Loss: 0.0720\n",
      "Epoch [21/50], Step [195/735], Loss: 0.1040\n",
      "Epoch [21/50], Step [196/735], Loss: 0.4927\n",
      "Epoch [21/50], Step [197/735], Loss: 0.1142\n",
      "Epoch [21/50], Step [198/735], Loss: 0.1077\n",
      "Epoch [21/50], Step [199/735], Loss: 0.1230\n",
      "Epoch [21/50], Step [200/735], Loss: 0.1790\n",
      "Epoch [21/50], Step [201/735], Loss: 0.0858\n",
      "Epoch [21/50], Step [202/735], Loss: 0.0595\n",
      "Epoch [21/50], Step [203/735], Loss: 0.0333\n",
      "Epoch [21/50], Step [204/735], Loss: 0.1556\n",
      "Epoch [21/50], Step [205/735], Loss: 0.0853\n",
      "Epoch [21/50], Step [206/735], Loss: 0.1435\n",
      "Epoch [21/50], Step [207/735], Loss: 0.0627\n",
      "Epoch [21/50], Step [208/735], Loss: 0.1204\n",
      "Epoch [21/50], Step [209/735], Loss: 0.1391\n",
      "Epoch [21/50], Step [210/735], Loss: 0.0541\n",
      "Epoch [21/50], Step [211/735], Loss: 0.1561\n",
      "Epoch [21/50], Step [212/735], Loss: 0.0473\n",
      "Epoch [21/50], Step [213/735], Loss: 0.1566\n",
      "Epoch [21/50], Step [214/735], Loss: 0.0955\n",
      "Epoch [21/50], Step [215/735], Loss: 0.0547\n",
      "Epoch [21/50], Step [216/735], Loss: 0.0600\n",
      "Epoch [21/50], Step [217/735], Loss: 0.0366\n",
      "Epoch [21/50], Step [218/735], Loss: 0.0632\n",
      "Epoch [21/50], Step [219/735], Loss: 0.0827\n",
      "Epoch [21/50], Step [220/735], Loss: 0.0825\n",
      "Epoch [21/50], Step [221/735], Loss: 0.0286\n",
      "Epoch [21/50], Step [222/735], Loss: 0.0711\n",
      "Epoch [21/50], Step [223/735], Loss: 0.0361\n",
      "Epoch [21/50], Step [224/735], Loss: 0.1999\n",
      "Epoch [21/50], Step [225/735], Loss: 0.1296\n",
      "Epoch [21/50], Step [226/735], Loss: 0.0738\n",
      "Epoch [21/50], Step [227/735], Loss: 0.0541\n",
      "Epoch [21/50], Step [228/735], Loss: 0.0669\n",
      "Epoch [21/50], Step [229/735], Loss: 0.1438\n",
      "Epoch [21/50], Step [230/735], Loss: 0.3835\n",
      "Epoch [21/50], Step [231/735], Loss: 0.0829\n",
      "Epoch [21/50], Step [232/735], Loss: 0.0707\n",
      "Epoch [21/50], Step [233/735], Loss: 0.1349\n",
      "Epoch [21/50], Step [234/735], Loss: 0.1570\n",
      "Epoch [21/50], Step [235/735], Loss: 0.4009\n",
      "Epoch [21/50], Step [236/735], Loss: 0.0574\n",
      "Epoch [21/50], Step [237/735], Loss: 0.2467\n",
      "Epoch [21/50], Step [238/735], Loss: 0.1455\n",
      "Epoch [21/50], Step [239/735], Loss: 0.0795\n",
      "Epoch [21/50], Step [240/735], Loss: 0.0349\n",
      "Epoch [21/50], Step [241/735], Loss: 0.1191\n",
      "Epoch [21/50], Step [242/735], Loss: 0.0279\n",
      "Epoch [21/50], Step [243/735], Loss: 0.0314\n",
      "Epoch [21/50], Step [244/735], Loss: 0.0354\n",
      "Epoch [21/50], Step [245/735], Loss: 0.0488\n",
      "Epoch [21/50], Step [246/735], Loss: 0.1034\n",
      "Epoch [21/50], Step [247/735], Loss: 0.1223\n",
      "Epoch [21/50], Step [248/735], Loss: 0.1922\n",
      "Epoch [21/50], Step [249/735], Loss: 0.1215\n",
      "Epoch [21/50], Step [250/735], Loss: 0.1104\n",
      "Epoch [21/50], Step [251/735], Loss: 0.1249\n",
      "Epoch [21/50], Step [252/735], Loss: 0.2079\n",
      "Epoch [21/50], Step [253/735], Loss: 0.0804\n",
      "Epoch [21/50], Step [254/735], Loss: 0.0751\n",
      "Epoch [21/50], Step [255/735], Loss: 0.0273\n",
      "Epoch [21/50], Step [256/735], Loss: 0.0892\n",
      "Epoch [21/50], Step [257/735], Loss: 0.1387\n",
      "Epoch [21/50], Step [258/735], Loss: 0.0317\n",
      "Epoch [21/50], Step [259/735], Loss: 0.0695\n",
      "Epoch [21/50], Step [260/735], Loss: 0.1600\n",
      "Epoch [21/50], Step [261/735], Loss: 0.0340\n",
      "Epoch [21/50], Step [262/735], Loss: 0.0586\n",
      "Epoch [21/50], Step [263/735], Loss: 0.2418\n",
      "Epoch [21/50], Step [264/735], Loss: 0.0341\n",
      "Epoch [21/50], Step [265/735], Loss: 0.2517\n",
      "Epoch [21/50], Step [266/735], Loss: 0.0585\n",
      "Epoch [21/50], Step [267/735], Loss: 0.0464\n",
      "Epoch [21/50], Step [268/735], Loss: 0.0855\n",
      "Epoch [21/50], Step [269/735], Loss: 0.0308\n",
      "Epoch [21/50], Step [270/735], Loss: 0.0200\n",
      "Epoch [21/50], Step [271/735], Loss: 0.1038\n",
      "Epoch [21/50], Step [272/735], Loss: 0.3297\n",
      "Epoch [21/50], Step [273/735], Loss: 0.4855\n",
      "Epoch [21/50], Step [274/735], Loss: 0.0344\n",
      "Epoch [21/50], Step [275/735], Loss: 0.0349\n",
      "Epoch [21/50], Step [276/735], Loss: 0.0517\n",
      "Epoch [21/50], Step [277/735], Loss: 0.0569\n",
      "Epoch [21/50], Step [278/735], Loss: 0.1597\n",
      "Epoch [21/50], Step [279/735], Loss: 0.0357\n",
      "Epoch [21/50], Step [280/735], Loss: 0.2568\n",
      "Epoch [21/50], Step [281/735], Loss: 0.1527\n",
      "Epoch [21/50], Step [282/735], Loss: 0.0540\n",
      "Epoch [21/50], Step [283/735], Loss: 0.0488\n",
      "Epoch [21/50], Step [284/735], Loss: 0.0943\n",
      "Epoch [21/50], Step [285/735], Loss: 0.0563\n",
      "Epoch [21/50], Step [286/735], Loss: 0.0914\n",
      "Epoch [21/50], Step [287/735], Loss: 0.0503\n",
      "Epoch [21/50], Step [288/735], Loss: 0.1767\n",
      "Epoch [21/50], Step [289/735], Loss: 0.0922\n",
      "Epoch [21/50], Step [290/735], Loss: 0.0766\n",
      "Epoch [21/50], Step [291/735], Loss: 0.1892\n",
      "Epoch [21/50], Step [292/735], Loss: 0.0339\n",
      "Epoch [21/50], Step [293/735], Loss: 0.0919\n",
      "Epoch [21/50], Step [294/735], Loss: 0.0501\n",
      "Epoch [21/50], Step [295/735], Loss: 0.0929\n",
      "Epoch [21/50], Step [296/735], Loss: 0.1991\n",
      "Epoch [21/50], Step [297/735], Loss: 0.1706\n",
      "Epoch [21/50], Step [298/735], Loss: 0.0542\n",
      "Epoch [21/50], Step [299/735], Loss: 0.0839\n",
      "Epoch [21/50], Step [300/735], Loss: 0.0269\n",
      "Epoch [21/50], Step [301/735], Loss: 0.0387\n",
      "Epoch [21/50], Step [302/735], Loss: 0.0990\n",
      "Epoch [21/50], Step [303/735], Loss: 0.0436\n",
      "Epoch [21/50], Step [304/735], Loss: 0.0478\n",
      "Epoch [21/50], Step [305/735], Loss: 0.1024\n",
      "Epoch [21/50], Step [306/735], Loss: 0.0971\n",
      "Epoch [21/50], Step [307/735], Loss: 0.0340\n",
      "Epoch [21/50], Step [308/735], Loss: 0.0192\n",
      "Epoch [21/50], Step [309/735], Loss: 0.0544\n",
      "Epoch [21/50], Step [310/735], Loss: 0.0572\n",
      "Epoch [21/50], Step [311/735], Loss: 0.0524\n",
      "Epoch [21/50], Step [312/735], Loss: 0.0557\n",
      "Epoch [21/50], Step [313/735], Loss: 0.1431\n",
      "Epoch [21/50], Step [314/735], Loss: 0.1339\n",
      "Epoch [21/50], Step [315/735], Loss: 0.0732\n",
      "Epoch [21/50], Step [316/735], Loss: 0.1068\n",
      "Epoch [21/50], Step [317/735], Loss: 0.0724\n",
      "Epoch [21/50], Step [318/735], Loss: 0.0884\n",
      "Epoch [21/50], Step [319/735], Loss: 0.0466\n",
      "Epoch [21/50], Step [320/735], Loss: 0.1569\n",
      "Epoch [21/50], Step [321/735], Loss: 0.0483\n",
      "Epoch [21/50], Step [322/735], Loss: 0.0526\n",
      "Epoch [21/50], Step [323/735], Loss: 0.0658\n",
      "Epoch [21/50], Step [324/735], Loss: 0.0881\n",
      "Epoch [21/50], Step [325/735], Loss: 0.0586\n",
      "Epoch [21/50], Step [326/735], Loss: 0.0553\n",
      "Epoch [21/50], Step [327/735], Loss: 0.0843\n",
      "Epoch [21/50], Step [328/735], Loss: 0.0490\n",
      "Epoch [21/50], Step [329/735], Loss: 0.0438\n",
      "Epoch [21/50], Step [330/735], Loss: 0.2453\n",
      "Epoch [21/50], Step [331/735], Loss: 0.0230\n",
      "Epoch [21/50], Step [332/735], Loss: 0.0273\n",
      "Epoch [21/50], Step [333/735], Loss: 0.1573\n",
      "Epoch [21/50], Step [334/735], Loss: 0.0267\n",
      "Epoch [21/50], Step [335/735], Loss: 0.2238\n",
      "Epoch [21/50], Step [336/735], Loss: 0.0743\n",
      "Epoch [21/50], Step [337/735], Loss: 0.0462\n",
      "Epoch [21/50], Step [338/735], Loss: 0.4394\n",
      "Epoch [21/50], Step [339/735], Loss: 0.0751\n",
      "Epoch [21/50], Step [340/735], Loss: 0.0423\n",
      "Epoch [21/50], Step [341/735], Loss: 0.4491\n",
      "Epoch [21/50], Step [342/735], Loss: 0.2997\n",
      "Epoch [21/50], Step [343/735], Loss: 0.0558\n",
      "Epoch [21/50], Step [344/735], Loss: 0.1448\n",
      "Epoch [21/50], Step [345/735], Loss: 0.0346\n",
      "Epoch [21/50], Step [346/735], Loss: 0.1037\n",
      "Epoch [21/50], Step [347/735], Loss: 0.1240\n",
      "Epoch [21/50], Step [348/735], Loss: 0.0384\n",
      "Epoch [21/50], Step [349/735], Loss: 0.1624\n",
      "Epoch [21/50], Step [350/735], Loss: 0.0358\n",
      "Epoch [21/50], Step [351/735], Loss: 0.1529\n",
      "Epoch [21/50], Step [352/735], Loss: 0.0540\n",
      "Epoch [21/50], Step [353/735], Loss: 0.1169\n",
      "Epoch [21/50], Step [354/735], Loss: 0.0854\n",
      "Epoch [21/50], Step [355/735], Loss: 0.0353\n",
      "Epoch [21/50], Step [356/735], Loss: 0.2453\n",
      "Epoch [21/50], Step [357/735], Loss: 0.0286\n",
      "Epoch [21/50], Step [358/735], Loss: 0.0389\n",
      "Epoch [21/50], Step [359/735], Loss: 0.1531\n",
      "Epoch [21/50], Step [360/735], Loss: 0.0438\n",
      "Epoch [21/50], Step [361/735], Loss: 0.0440\n",
      "Epoch [21/50], Step [362/735], Loss: 0.0498\n",
      "Epoch [21/50], Step [363/735], Loss: 0.1763\n",
      "Epoch [21/50], Step [364/735], Loss: 0.0886\n",
      "Epoch [21/50], Step [365/735], Loss: 0.0690\n",
      "Epoch [21/50], Step [366/735], Loss: 0.0708\n",
      "Epoch [21/50], Step [367/735], Loss: 0.0316\n",
      "Epoch [21/50], Step [368/735], Loss: 0.0621\n",
      "Epoch [21/50], Step [369/735], Loss: 0.0698\n",
      "Epoch [21/50], Step [370/735], Loss: 0.2019\n",
      "Epoch [21/50], Step [371/735], Loss: 0.1269\n",
      "Epoch [21/50], Step [372/735], Loss: 0.0589\n",
      "Epoch [21/50], Step [373/735], Loss: 0.0338\n",
      "Epoch [21/50], Step [374/735], Loss: 0.0270\n",
      "Epoch [21/50], Step [375/735], Loss: 0.0260\n",
      "Epoch [21/50], Step [376/735], Loss: 0.0688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Step [377/735], Loss: 0.0331\n",
      "Epoch [21/50], Step [378/735], Loss: 0.0437\n",
      "Epoch [21/50], Step [379/735], Loss: 0.0354\n",
      "Epoch [21/50], Step [380/735], Loss: 0.0403\n",
      "Epoch [21/50], Step [381/735], Loss: 0.0676\n",
      "Epoch [21/50], Step [382/735], Loss: 0.0478\n",
      "Epoch [21/50], Step [383/735], Loss: 0.1156\n",
      "Epoch [21/50], Step [384/735], Loss: 0.1053\n",
      "Epoch [21/50], Step [385/735], Loss: 0.0350\n",
      "Epoch [21/50], Step [386/735], Loss: 0.1608\n",
      "Epoch [21/50], Step [387/735], Loss: 0.0348\n",
      "Epoch [21/50], Step [388/735], Loss: 0.0788\n",
      "Epoch [21/50], Step [389/735], Loss: 0.1008\n",
      "Epoch [21/50], Step [390/735], Loss: 0.0262\n",
      "Epoch [21/50], Step [391/735], Loss: 0.2597\n",
      "Epoch [21/50], Step [392/735], Loss: 0.1186\n",
      "Epoch [21/50], Step [393/735], Loss: 0.0657\n",
      "Epoch [21/50], Step [394/735], Loss: 0.0909\n",
      "Epoch [21/50], Step [395/735], Loss: 0.0379\n",
      "Epoch [21/50], Step [396/735], Loss: 0.0802\n",
      "Epoch [21/50], Step [397/735], Loss: 0.0843\n",
      "Epoch [21/50], Step [398/735], Loss: 0.0463\n",
      "Epoch [21/50], Step [399/735], Loss: 0.0633\n",
      "Epoch [21/50], Step [400/735], Loss: 0.1986\n",
      "Epoch [21/50], Step [401/735], Loss: 0.0993\n",
      "Epoch [21/50], Step [402/735], Loss: 0.0885\n",
      "Epoch [21/50], Step [403/735], Loss: 0.0217\n",
      "Epoch [21/50], Step [404/735], Loss: 0.0520\n",
      "Epoch [21/50], Step [405/735], Loss: 0.0427\n",
      "Epoch [21/50], Step [406/735], Loss: 0.0974\n",
      "Epoch [21/50], Step [407/735], Loss: 0.0396\n",
      "Epoch [21/50], Step [408/735], Loss: 0.0327\n",
      "Epoch [21/50], Step [409/735], Loss: 0.0492\n",
      "Epoch [21/50], Step [410/735], Loss: 0.1314\n",
      "Epoch [21/50], Step [411/735], Loss: 0.0220\n",
      "Epoch [21/50], Step [412/735], Loss: 0.0198\n",
      "Epoch [21/50], Step [413/735], Loss: 0.0666\n",
      "Epoch [21/50], Step [414/735], Loss: 0.1363\n",
      "Epoch [21/50], Step [415/735], Loss: 0.0145\n",
      "Epoch [21/50], Step [416/735], Loss: 0.0697\n",
      "Epoch [21/50], Step [417/735], Loss: 0.1222\n",
      "Epoch [21/50], Step [418/735], Loss: 0.0756\n",
      "Epoch [21/50], Step [419/735], Loss: 0.0310\n",
      "Epoch [21/50], Step [420/735], Loss: 0.0510\n",
      "Epoch [21/50], Step [421/735], Loss: 0.0248\n",
      "Epoch [21/50], Step [422/735], Loss: 0.1499\n",
      "Epoch [21/50], Step [423/735], Loss: 0.5291\n",
      "Epoch [21/50], Step [424/735], Loss: 0.1694\n",
      "Epoch [21/50], Step [425/735], Loss: 0.0582\n",
      "Epoch [21/50], Step [426/735], Loss: 0.0794\n",
      "Epoch [21/50], Step [427/735], Loss: 0.0771\n",
      "Epoch [21/50], Step [428/735], Loss: 0.0467\n",
      "Epoch [21/50], Step [429/735], Loss: 0.0779\n",
      "Epoch [21/50], Step [430/735], Loss: 0.0324\n",
      "Epoch [21/50], Step [431/735], Loss: 0.1165\n",
      "Epoch [21/50], Step [432/735], Loss: 0.0439\n",
      "Epoch [21/50], Step [433/735], Loss: 0.0652\n",
      "Epoch [21/50], Step [434/735], Loss: 0.1130\n",
      "Epoch [21/50], Step [435/735], Loss: 0.0566\n",
      "Epoch [21/50], Step [436/735], Loss: 0.1308\n",
      "Epoch [21/50], Step [437/735], Loss: 0.0936\n",
      "Epoch [21/50], Step [438/735], Loss: 0.0282\n",
      "Epoch [21/50], Step [439/735], Loss: 0.1376\n",
      "Epoch [21/50], Step [440/735], Loss: 0.0391\n",
      "Epoch [21/50], Step [441/735], Loss: 0.0660\n",
      "Epoch [21/50], Step [442/735], Loss: 0.1099\n",
      "Epoch [21/50], Step [443/735], Loss: 0.1856\n",
      "Epoch [21/50], Step [444/735], Loss: 0.0348\n",
      "Epoch [21/50], Step [445/735], Loss: 0.0843\n",
      "Epoch [21/50], Step [446/735], Loss: 0.0461\n",
      "Epoch [21/50], Step [447/735], Loss: 0.0207\n",
      "Epoch [21/50], Step [448/735], Loss: 0.0211\n",
      "Epoch [21/50], Step [449/735], Loss: 0.0818\n",
      "Epoch [21/50], Step [450/735], Loss: 0.2218\n",
      "Epoch [21/50], Step [451/735], Loss: 0.0723\n",
      "Epoch [21/50], Step [452/735], Loss: 0.3031\n",
      "Epoch [21/50], Step [453/735], Loss: 0.1086\n",
      "Epoch [21/50], Step [454/735], Loss: 0.1238\n",
      "Epoch [21/50], Step [455/735], Loss: 0.0526\n",
      "Epoch [21/50], Step [456/735], Loss: 0.2528\n",
      "Epoch [21/50], Step [457/735], Loss: 0.0572\n",
      "Epoch [21/50], Step [458/735], Loss: 0.0611\n",
      "Epoch [21/50], Step [459/735], Loss: 0.0283\n",
      "Epoch [21/50], Step [460/735], Loss: 0.1367\n",
      "Epoch [21/50], Step [461/735], Loss: 0.1047\n",
      "Epoch [21/50], Step [462/735], Loss: 0.0515\n",
      "Epoch [21/50], Step [463/735], Loss: 0.0155\n",
      "Epoch [21/50], Step [464/735], Loss: 0.0371\n",
      "Epoch [21/50], Step [465/735], Loss: 0.0713\n",
      "Epoch [21/50], Step [466/735], Loss: 0.0599\n",
      "Epoch [21/50], Step [467/735], Loss: 0.0574\n",
      "Epoch [21/50], Step [468/735], Loss: 0.0654\n",
      "Epoch [21/50], Step [469/735], Loss: 0.0301\n",
      "Epoch [21/50], Step [470/735], Loss: 0.2541\n",
      "Epoch [21/50], Step [471/735], Loss: 0.0267\n",
      "Epoch [21/50], Step [472/735], Loss: 0.0124\n",
      "Epoch [21/50], Step [473/735], Loss: 0.0649\n",
      "Epoch [21/50], Step [474/735], Loss: 0.0358\n",
      "Epoch [21/50], Step [475/735], Loss: 0.2427\n",
      "Epoch [21/50], Step [476/735], Loss: 0.0807\n",
      "Epoch [21/50], Step [477/735], Loss: 0.0295\n",
      "Epoch [21/50], Step [478/735], Loss: 0.1462\n",
      "Epoch [21/50], Step [479/735], Loss: 0.0546\n",
      "Epoch [21/50], Step [480/735], Loss: 0.0391\n",
      "Epoch [21/50], Step [481/735], Loss: 0.0478\n",
      "Epoch [21/50], Step [482/735], Loss: 0.0425\n",
      "Epoch [21/50], Step [483/735], Loss: 0.0590\n",
      "Epoch [21/50], Step [484/735], Loss: 0.0627\n",
      "Epoch [21/50], Step [485/735], Loss: 0.0642\n",
      "Epoch [21/50], Step [486/735], Loss: 0.0288\n",
      "Epoch [21/50], Step [487/735], Loss: 0.1156\n",
      "Epoch [21/50], Step [488/735], Loss: 0.1016\n",
      "Epoch [21/50], Step [489/735], Loss: 0.0981\n",
      "Epoch [21/50], Step [490/735], Loss: 0.0842\n",
      "Epoch [21/50], Step [491/735], Loss: 0.0458\n",
      "Epoch [21/50], Step [492/735], Loss: 0.1502\n",
      "Epoch [21/50], Step [493/735], Loss: 0.0673\n",
      "Epoch [21/50], Step [494/735], Loss: 0.1061\n",
      "Epoch [21/50], Step [495/735], Loss: 0.0630\n",
      "Epoch [21/50], Step [496/735], Loss: 0.0423\n",
      "Epoch [21/50], Step [497/735], Loss: 0.0840\n",
      "Epoch [21/50], Step [498/735], Loss: 0.0504\n",
      "Epoch [21/50], Step [499/735], Loss: 0.2255\n",
      "Epoch [21/50], Step [500/735], Loss: 0.1029\n",
      "Epoch [21/50], Step [501/735], Loss: 0.0303\n",
      "Epoch [21/50], Step [502/735], Loss: 0.2485\n",
      "Epoch [21/50], Step [503/735], Loss: 0.0319\n",
      "Epoch [21/50], Step [504/735], Loss: 0.1377\n",
      "Epoch [21/50], Step [505/735], Loss: 0.0307\n",
      "Epoch [21/50], Step [506/735], Loss: 0.0667\n",
      "Epoch [21/50], Step [507/735], Loss: 0.2079\n",
      "Epoch [21/50], Step [508/735], Loss: 0.0599\n",
      "Epoch [21/50], Step [509/735], Loss: 0.0555\n",
      "Epoch [21/50], Step [510/735], Loss: 0.1255\n",
      "Epoch [21/50], Step [511/735], Loss: 0.2323\n",
      "Epoch [21/50], Step [512/735], Loss: 0.0875\n",
      "Epoch [21/50], Step [513/735], Loss: 0.1261\n",
      "Epoch [21/50], Step [514/735], Loss: 0.0566\n",
      "Epoch [21/50], Step [515/735], Loss: 0.1100\n",
      "Epoch [21/50], Step [516/735], Loss: 0.0832\n",
      "Epoch [21/50], Step [517/735], Loss: 0.0768\n",
      "Epoch [21/50], Step [518/735], Loss: 0.0657\n",
      "Epoch [21/50], Step [519/735], Loss: 0.1721\n",
      "Epoch [21/50], Step [520/735], Loss: 0.0935\n",
      "Epoch [21/50], Step [521/735], Loss: 0.1169\n",
      "Epoch [21/50], Step [522/735], Loss: 0.0527\n",
      "Epoch [21/50], Step [523/735], Loss: 0.0248\n",
      "Epoch [21/50], Step [524/735], Loss: 0.0956\n",
      "Epoch [21/50], Step [525/735], Loss: 0.0280\n",
      "Epoch [21/50], Step [526/735], Loss: 0.1038\n",
      "Epoch [21/50], Step [527/735], Loss: 0.0935\n",
      "Epoch [21/50], Step [528/735], Loss: 0.0600\n",
      "Epoch [21/50], Step [529/735], Loss: 0.1166\n",
      "Epoch [21/50], Step [530/735], Loss: 0.1013\n",
      "Epoch [21/50], Step [531/735], Loss: 0.3450\n",
      "Epoch [21/50], Step [532/735], Loss: 0.0276\n",
      "Epoch [21/50], Step [533/735], Loss: 0.0544\n",
      "Epoch [21/50], Step [534/735], Loss: 0.1367\n",
      "Epoch [21/50], Step [535/735], Loss: 0.0514\n",
      "Epoch [21/50], Step [536/735], Loss: 0.0250\n",
      "Epoch [21/50], Step [537/735], Loss: 0.0797\n",
      "Epoch [21/50], Step [538/735], Loss: 0.0473\n",
      "Epoch [21/50], Step [539/735], Loss: 0.0879\n",
      "Epoch [21/50], Step [540/735], Loss: 0.0325\n",
      "Epoch [21/50], Step [541/735], Loss: 0.0307\n",
      "Epoch [21/50], Step [542/735], Loss: 0.0517\n",
      "Epoch [21/50], Step [543/735], Loss: 0.0384\n",
      "Epoch [21/50], Step [544/735], Loss: 0.1235\n",
      "Epoch [21/50], Step [545/735], Loss: 0.1633\n",
      "Epoch [21/50], Step [546/735], Loss: 0.0390\n",
      "Epoch [21/50], Step [547/735], Loss: 0.0237\n",
      "Epoch [21/50], Step [548/735], Loss: 0.0315\n",
      "Epoch [21/50], Step [549/735], Loss: 0.0256\n",
      "Epoch [21/50], Step [550/735], Loss: 0.1638\n",
      "Epoch [21/50], Step [551/735], Loss: 0.0216\n",
      "Epoch [21/50], Step [552/735], Loss: 0.1273\n",
      "Epoch [21/50], Step [553/735], Loss: 0.0859\n",
      "Epoch [21/50], Step [554/735], Loss: 0.0763\n",
      "Epoch [21/50], Step [555/735], Loss: 0.0578\n",
      "Epoch [21/50], Step [556/735], Loss: 0.0324\n",
      "Epoch [21/50], Step [557/735], Loss: 0.1019\n",
      "Epoch [21/50], Step [558/735], Loss: 0.0184\n",
      "Epoch [21/50], Step [559/735], Loss: 0.0216\n",
      "Epoch [21/50], Step [560/735], Loss: 0.0840\n",
      "Epoch [21/50], Step [561/735], Loss: 0.0773\n",
      "Epoch [21/50], Step [562/735], Loss: 0.1145\n",
      "Epoch [21/50], Step [563/735], Loss: 0.0796\n",
      "Epoch [21/50], Step [564/735], Loss: 0.0603\n",
      "Epoch [21/50], Step [565/735], Loss: 0.4087\n",
      "Epoch [21/50], Step [566/735], Loss: 0.0719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Step [567/735], Loss: 0.0193\n",
      "Epoch [21/50], Step [568/735], Loss: 0.1141\n",
      "Epoch [21/50], Step [569/735], Loss: 0.0515\n",
      "Epoch [21/50], Step [570/735], Loss: 0.0828\n",
      "Epoch [21/50], Step [571/735], Loss: 0.0261\n",
      "Epoch [21/50], Step [572/735], Loss: 0.0925\n",
      "Epoch [21/50], Step [573/735], Loss: 0.1166\n",
      "Epoch [21/50], Step [574/735], Loss: 0.0580\n",
      "Epoch [21/50], Step [575/735], Loss: 0.1284\n",
      "Epoch [21/50], Step [576/735], Loss: 0.1579\n",
      "Epoch [21/50], Step [577/735], Loss: 0.0685\n",
      "Epoch [21/50], Step [578/735], Loss: 0.3207\n",
      "Epoch [21/50], Step [579/735], Loss: 0.1009\n",
      "Epoch [21/50], Step [580/735], Loss: 0.0747\n",
      "Epoch [21/50], Step [581/735], Loss: 0.0516\n",
      "Epoch [21/50], Step [582/735], Loss: 0.0434\n",
      "Epoch [21/50], Step [583/735], Loss: 0.1163\n",
      "Epoch [21/50], Step [584/735], Loss: 0.0224\n",
      "Epoch [21/50], Step [585/735], Loss: 0.0500\n",
      "Epoch [21/50], Step [586/735], Loss: 0.0483\n",
      "Epoch [21/50], Step [587/735], Loss: 0.5845\n",
      "Epoch [21/50], Step [588/735], Loss: 0.0503\n",
      "Epoch [21/50], Step [589/735], Loss: 0.0468\n",
      "Epoch [21/50], Step [590/735], Loss: 0.0922\n",
      "Epoch [21/50], Step [591/735], Loss: 0.0452\n",
      "Epoch [21/50], Step [592/735], Loss: 0.0734\n",
      "Epoch [21/50], Step [593/735], Loss: 0.1204\n",
      "Epoch [21/50], Step [594/735], Loss: 0.1104\n",
      "Epoch [21/50], Step [595/735], Loss: 0.0862\n",
      "Epoch [21/50], Step [596/735], Loss: 0.1120\n",
      "Epoch [21/50], Step [597/735], Loss: 0.0358\n",
      "Epoch [21/50], Step [598/735], Loss: 0.0541\n",
      "Epoch [21/50], Step [599/735], Loss: 0.0251\n",
      "Epoch [21/50], Step [600/735], Loss: 0.0483\n",
      "Epoch [21/50], Step [601/735], Loss: 0.0569\n",
      "Epoch [21/50], Step [602/735], Loss: 0.0407\n",
      "Epoch [21/50], Step [603/735], Loss: 0.0442\n",
      "Epoch [21/50], Step [604/735], Loss: 0.0901\n",
      "Epoch [21/50], Step [605/735], Loss: 0.0393\n",
      "Epoch [21/50], Step [606/735], Loss: 0.0349\n",
      "Epoch [21/50], Step [607/735], Loss: 0.0672\n",
      "Epoch [21/50], Step [608/735], Loss: 0.0425\n",
      "Epoch [21/50], Step [609/735], Loss: 0.2417\n",
      "Epoch [21/50], Step [610/735], Loss: 0.0521\n",
      "Epoch [21/50], Step [611/735], Loss: 0.0318\n",
      "Epoch [21/50], Step [612/735], Loss: 0.1874\n",
      "Epoch [21/50], Step [613/735], Loss: 0.3456\n",
      "Epoch [21/50], Step [614/735], Loss: 0.0700\n",
      "Epoch [21/50], Step [615/735], Loss: 0.2352\n",
      "Epoch [21/50], Step [616/735], Loss: 0.1636\n",
      "Epoch [21/50], Step [617/735], Loss: 0.0390\n",
      "Epoch [21/50], Step [618/735], Loss: 0.1566\n",
      "Epoch [21/50], Step [619/735], Loss: 0.0222\n",
      "Epoch [21/50], Step [620/735], Loss: 0.1016\n",
      "Epoch [21/50], Step [621/735], Loss: 0.2061\n",
      "Epoch [21/50], Step [622/735], Loss: 0.1946\n",
      "Epoch [21/50], Step [623/735], Loss: 0.0925\n",
      "Epoch [21/50], Step [624/735], Loss: 0.3264\n",
      "Epoch [21/50], Step [625/735], Loss: 0.0633\n",
      "Epoch [21/50], Step [626/735], Loss: 0.0627\n",
      "Epoch [21/50], Step [627/735], Loss: 0.3141\n",
      "Epoch [21/50], Step [628/735], Loss: 0.0860\n",
      "Epoch [21/50], Step [629/735], Loss: 0.0769\n",
      "Epoch [21/50], Step [630/735], Loss: 0.0705\n",
      "Epoch [21/50], Step [631/735], Loss: 0.0759\n",
      "Epoch [21/50], Step [632/735], Loss: 0.0713\n",
      "Epoch [21/50], Step [633/735], Loss: 0.0545\n",
      "Epoch [21/50], Step [634/735], Loss: 0.0564\n",
      "Epoch [21/50], Step [635/735], Loss: 0.1005\n",
      "Epoch [21/50], Step [636/735], Loss: 0.1948\n",
      "Epoch [21/50], Step [637/735], Loss: 0.1725\n",
      "Epoch [21/50], Step [638/735], Loss: 0.0680\n",
      "Epoch [21/50], Step [639/735], Loss: 0.0631\n",
      "Epoch [21/50], Step [640/735], Loss: 0.1456\n",
      "Epoch [21/50], Step [641/735], Loss: 0.0576\n",
      "Epoch [21/50], Step [642/735], Loss: 0.0940\n",
      "Epoch [21/50], Step [643/735], Loss: 0.0968\n",
      "Epoch [21/50], Step [644/735], Loss: 0.1209\n",
      "Epoch [21/50], Step [645/735], Loss: 0.0554\n",
      "Epoch [21/50], Step [646/735], Loss: 0.0462\n",
      "Epoch [21/50], Step [647/735], Loss: 0.3476\n",
      "Epoch [21/50], Step [648/735], Loss: 0.0468\n",
      "Epoch [21/50], Step [649/735], Loss: 0.0614\n",
      "Epoch [21/50], Step [650/735], Loss: 0.1120\n",
      "Epoch [21/50], Step [651/735], Loss: 0.0857\n",
      "Epoch [21/50], Step [652/735], Loss: 0.1861\n",
      "Epoch [21/50], Step [653/735], Loss: 0.0930\n",
      "Epoch [21/50], Step [654/735], Loss: 0.0608\n",
      "Epoch [21/50], Step [655/735], Loss: 0.0964\n",
      "Epoch [21/50], Step [656/735], Loss: 0.1092\n",
      "Epoch [21/50], Step [657/735], Loss: 0.0721\n",
      "Epoch [21/50], Step [658/735], Loss: 0.0370\n",
      "Epoch [21/50], Step [659/735], Loss: 0.1507\n",
      "Epoch [21/50], Step [660/735], Loss: 0.0870\n",
      "Epoch [21/50], Step [661/735], Loss: 0.0599\n",
      "Epoch [21/50], Step [662/735], Loss: 0.0537\n",
      "Epoch [21/50], Step [663/735], Loss: 0.0540\n",
      "Epoch [21/50], Step [664/735], Loss: 0.3470\n",
      "Epoch [21/50], Step [665/735], Loss: 0.0240\n",
      "Epoch [21/50], Step [666/735], Loss: 0.0235\n",
      "Epoch [21/50], Step [667/735], Loss: 0.0464\n",
      "Epoch [21/50], Step [668/735], Loss: 0.0346\n",
      "Epoch [21/50], Step [669/735], Loss: 0.0875\n",
      "Epoch [21/50], Step [670/735], Loss: 0.0791\n",
      "Epoch [21/50], Step [671/735], Loss: 0.3101\n",
      "Epoch [21/50], Step [672/735], Loss: 0.0622\n",
      "Epoch [21/50], Step [673/735], Loss: 0.1404\n",
      "Epoch [21/50], Step [674/735], Loss: 0.0469\n",
      "Epoch [21/50], Step [675/735], Loss: 0.0559\n",
      "Epoch [21/50], Step [676/735], Loss: 0.1625\n",
      "Epoch [21/50], Step [677/735], Loss: 0.0317\n",
      "Epoch [21/50], Step [678/735], Loss: 0.0447\n",
      "Epoch [21/50], Step [679/735], Loss: 0.1246\n",
      "Epoch [21/50], Step [680/735], Loss: 0.0540\n",
      "Epoch [21/50], Step [681/735], Loss: 0.1418\n",
      "Epoch [21/50], Step [682/735], Loss: 0.3429\n",
      "Epoch [21/50], Step [683/735], Loss: 0.1371\n",
      "Epoch [21/50], Step [684/735], Loss: 0.0379\n",
      "Epoch [21/50], Step [685/735], Loss: 0.0371\n",
      "Epoch [21/50], Step [686/735], Loss: 0.0614\n",
      "Epoch [21/50], Step [687/735], Loss: 0.0395\n",
      "Epoch [21/50], Step [688/735], Loss: 0.0683\n",
      "Epoch [21/50], Step [689/735], Loss: 0.1305\n",
      "Epoch [21/50], Step [690/735], Loss: 0.0259\n",
      "Epoch [21/50], Step [691/735], Loss: 0.1593\n",
      "Epoch [21/50], Step [692/735], Loss: 0.0230\n",
      "Epoch [21/50], Step [693/735], Loss: 0.0505\n",
      "Epoch [21/50], Step [694/735], Loss: 0.1154\n",
      "Epoch [21/50], Step [695/735], Loss: 0.0819\n",
      "Epoch [21/50], Step [696/735], Loss: 0.0411\n",
      "Epoch [21/50], Step [697/735], Loss: 0.0915\n",
      "Epoch [21/50], Step [698/735], Loss: 0.0810\n",
      "Epoch [21/50], Step [699/735], Loss: 0.0905\n",
      "Epoch [21/50], Step [700/735], Loss: 0.0557\n",
      "Epoch [21/50], Step [701/735], Loss: 0.0448\n",
      "Epoch [21/50], Step [702/735], Loss: 0.1439\n",
      "Epoch [21/50], Step [703/735], Loss: 0.0695\n",
      "Epoch [21/50], Step [704/735], Loss: 0.0893\n",
      "Epoch [21/50], Step [705/735], Loss: 0.1255\n",
      "Epoch [21/50], Step [706/735], Loss: 0.0858\n",
      "Epoch [21/50], Step [707/735], Loss: 0.1379\n",
      "Epoch [21/50], Step [708/735], Loss: 0.0424\n",
      "Epoch [21/50], Step [709/735], Loss: 0.0850\n",
      "Epoch [21/50], Step [710/735], Loss: 0.1596\n",
      "Epoch [21/50], Step [711/735], Loss: 0.0522\n",
      "Epoch [21/50], Step [712/735], Loss: 0.0392\n",
      "Epoch [21/50], Step [713/735], Loss: 0.0957\n",
      "Epoch [21/50], Step [714/735], Loss: 0.1548\n",
      "Epoch [21/50], Step [715/735], Loss: 0.0504\n",
      "Epoch [21/50], Step [716/735], Loss: 0.0473\n",
      "Epoch [21/50], Step [717/735], Loss: 0.0358\n",
      "Epoch [21/50], Step [718/735], Loss: 0.0470\n",
      "Epoch [21/50], Step [719/735], Loss: 0.0631\n",
      "Epoch [21/50], Step [720/735], Loss: 0.0877\n",
      "Epoch [21/50], Step [721/735], Loss: 0.2718\n",
      "Epoch [21/50], Step [722/735], Loss: 0.1152\n",
      "Epoch [21/50], Step [723/735], Loss: 0.2419\n",
      "Epoch [21/50], Step [724/735], Loss: 0.0621\n",
      "Epoch [21/50], Step [725/735], Loss: 0.0954\n",
      "Epoch [21/50], Step [726/735], Loss: 0.0318\n",
      "Epoch [21/50], Step [727/735], Loss: 0.0747\n",
      "Epoch [21/50], Step [728/735], Loss: 0.0951\n",
      "Epoch [21/50], Step [729/735], Loss: 0.0633\n",
      "Epoch [21/50], Step [730/735], Loss: 0.1830\n",
      "Epoch [21/50], Step [731/735], Loss: 0.0753\n",
      "Epoch [21/50], Step [732/735], Loss: 0.2084\n",
      "Epoch [21/50], Step [733/735], Loss: 0.0627\n",
      "Epoch [21/50], Step [734/735], Loss: 0.1264\n",
      "Epoch [21/50], Step [735/735], Loss: 0.1455\n",
      "Epoch [22/50], Step [1/735], Loss: 0.0353\n",
      "Epoch [22/50], Step [2/735], Loss: 0.0955\n",
      "Epoch [22/50], Step [3/735], Loss: 0.0335\n",
      "Epoch [22/50], Step [4/735], Loss: 0.0257\n",
      "Epoch [22/50], Step [5/735], Loss: 0.0458\n",
      "Epoch [22/50], Step [6/735], Loss: 0.0508\n",
      "Epoch [22/50], Step [7/735], Loss: 0.4187\n",
      "Epoch [22/50], Step [8/735], Loss: 0.4775\n",
      "Epoch [22/50], Step [9/735], Loss: 0.0462\n",
      "Epoch [22/50], Step [10/735], Loss: 0.0311\n",
      "Epoch [22/50], Step [11/735], Loss: 0.0445\n",
      "Epoch [22/50], Step [12/735], Loss: 0.0411\n",
      "Epoch [22/50], Step [13/735], Loss: 0.0692\n",
      "Epoch [22/50], Step [14/735], Loss: 0.1476\n",
      "Epoch [22/50], Step [15/735], Loss: 0.0388\n",
      "Epoch [22/50], Step [16/735], Loss: 0.0421\n",
      "Epoch [22/50], Step [17/735], Loss: 0.2465\n",
      "Epoch [22/50], Step [18/735], Loss: 0.0207\n",
      "Epoch [22/50], Step [19/735], Loss: 0.0650\n",
      "Epoch [22/50], Step [20/735], Loss: 0.1932\n",
      "Epoch [22/50], Step [21/735], Loss: 0.0550\n",
      "Epoch [22/50], Step [22/735], Loss: 0.1838\n",
      "Epoch [22/50], Step [23/735], Loss: 0.0662\n",
      "Epoch [22/50], Step [24/735], Loss: 0.0838\n",
      "Epoch [22/50], Step [25/735], Loss: 0.0662\n",
      "Epoch [22/50], Step [26/735], Loss: 0.0861\n",
      "Epoch [22/50], Step [27/735], Loss: 0.0750\n",
      "Epoch [22/50], Step [28/735], Loss: 0.0704\n",
      "Epoch [22/50], Step [29/735], Loss: 0.1036\n",
      "Epoch [22/50], Step [30/735], Loss: 0.2728\n",
      "Epoch [22/50], Step [31/735], Loss: 0.0786\n",
      "Epoch [22/50], Step [32/735], Loss: 0.0357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Step [33/735], Loss: 0.1793\n",
      "Epoch [22/50], Step [34/735], Loss: 0.0647\n",
      "Epoch [22/50], Step [35/735], Loss: 0.1281\n",
      "Epoch [22/50], Step [36/735], Loss: 0.0340\n",
      "Epoch [22/50], Step [37/735], Loss: 0.0926\n",
      "Epoch [22/50], Step [38/735], Loss: 0.0718\n",
      "Epoch [22/50], Step [39/735], Loss: 0.1153\n",
      "Epoch [22/50], Step [40/735], Loss: 0.2482\n",
      "Epoch [22/50], Step [41/735], Loss: 0.0416\n",
      "Epoch [22/50], Step [42/735], Loss: 0.0393\n",
      "Epoch [22/50], Step [43/735], Loss: 0.1233\n",
      "Epoch [22/50], Step [44/735], Loss: 0.1417\n",
      "Epoch [22/50], Step [45/735], Loss: 0.0607\n",
      "Epoch [22/50], Step [46/735], Loss: 0.0230\n",
      "Epoch [22/50], Step [47/735], Loss: 0.0374\n",
      "Epoch [22/50], Step [48/735], Loss: 0.0729\n",
      "Epoch [22/50], Step [49/735], Loss: 0.1590\n",
      "Epoch [22/50], Step [50/735], Loss: 0.0391\n",
      "Epoch [22/50], Step [51/735], Loss: 0.1318\n",
      "Epoch [22/50], Step [52/735], Loss: 0.0305\n",
      "Epoch [22/50], Step [53/735], Loss: 0.0305\n",
      "Epoch [22/50], Step [54/735], Loss: 0.0423\n",
      "Epoch [22/50], Step [55/735], Loss: 0.0300\n",
      "Epoch [22/50], Step [56/735], Loss: 0.1285\n",
      "Epoch [22/50], Step [57/735], Loss: 0.0844\n",
      "Epoch [22/50], Step [58/735], Loss: 0.0374\n",
      "Epoch [22/50], Step [59/735], Loss: 0.1078\n",
      "Epoch [22/50], Step [60/735], Loss: 0.0893\n",
      "Epoch [22/50], Step [61/735], Loss: 0.0536\n",
      "Epoch [22/50], Step [62/735], Loss: 0.0510\n",
      "Epoch [22/50], Step [63/735], Loss: 0.1488\n",
      "Epoch [22/50], Step [64/735], Loss: 0.0752\n",
      "Epoch [22/50], Step [65/735], Loss: 0.0576\n",
      "Epoch [22/50], Step [66/735], Loss: 0.1497\n",
      "Epoch [22/50], Step [67/735], Loss: 0.0721\n",
      "Epoch [22/50], Step [68/735], Loss: 0.1426\n",
      "Epoch [22/50], Step [69/735], Loss: 0.0380\n",
      "Epoch [22/50], Step [70/735], Loss: 0.0642\n",
      "Epoch [22/50], Step [71/735], Loss: 0.1053\n",
      "Epoch [22/50], Step [72/735], Loss: 0.0458\n",
      "Epoch [22/50], Step [73/735], Loss: 0.0551\n",
      "Epoch [22/50], Step [74/735], Loss: 0.1454\n",
      "Epoch [22/50], Step [75/735], Loss: 0.0278\n",
      "Epoch [22/50], Step [76/735], Loss: 0.0879\n",
      "Epoch [22/50], Step [77/735], Loss: 0.1085\n",
      "Epoch [22/50], Step [78/735], Loss: 0.1287\n",
      "Epoch [22/50], Step [79/735], Loss: 0.0573\n",
      "Epoch [22/50], Step [80/735], Loss: 0.0619\n",
      "Epoch [22/50], Step [81/735], Loss: 0.0514\n",
      "Epoch [22/50], Step [82/735], Loss: 0.6836\n",
      "Epoch [22/50], Step [83/735], Loss: 0.0591\n",
      "Epoch [22/50], Step [84/735], Loss: 0.1041\n",
      "Epoch [22/50], Step [85/735], Loss: 0.0508\n",
      "Epoch [22/50], Step [86/735], Loss: 0.3555\n",
      "Epoch [22/50], Step [87/735], Loss: 0.2271\n",
      "Epoch [22/50], Step [88/735], Loss: 0.0223\n",
      "Epoch [22/50], Step [89/735], Loss: 0.0428\n",
      "Epoch [22/50], Step [90/735], Loss: 0.1774\n",
      "Epoch [22/50], Step [91/735], Loss: 0.0468\n",
      "Epoch [22/50], Step [92/735], Loss: 0.0542\n",
      "Epoch [22/50], Step [93/735], Loss: 0.0920\n",
      "Epoch [22/50], Step [94/735], Loss: 0.0571\n",
      "Epoch [22/50], Step [95/735], Loss: 0.0891\n",
      "Epoch [22/50], Step [96/735], Loss: 0.0745\n",
      "Epoch [22/50], Step [97/735], Loss: 0.0378\n",
      "Epoch [22/50], Step [98/735], Loss: 0.0288\n",
      "Epoch [22/50], Step [99/735], Loss: 0.0648\n",
      "Epoch [22/50], Step [100/735], Loss: 0.0927\n",
      "Epoch [22/50], Step [101/735], Loss: 0.0560\n",
      "Epoch [22/50], Step [102/735], Loss: 0.0728\n",
      "Epoch [22/50], Step [103/735], Loss: 0.0507\n",
      "Epoch [22/50], Step [104/735], Loss: 0.0763\n",
      "Epoch [22/50], Step [105/735], Loss: 0.0376\n",
      "Epoch [22/50], Step [106/735], Loss: 0.0617\n",
      "Epoch [22/50], Step [107/735], Loss: 0.1197\n",
      "Epoch [22/50], Step [108/735], Loss: 0.0320\n",
      "Epoch [22/50], Step [109/735], Loss: 0.1952\n",
      "Epoch [22/50], Step [110/735], Loss: 0.2139\n",
      "Epoch [22/50], Step [111/735], Loss: 0.3086\n",
      "Epoch [22/50], Step [112/735], Loss: 0.0303\n",
      "Epoch [22/50], Step [113/735], Loss: 0.0687\n",
      "Epoch [22/50], Step [114/735], Loss: 0.0807\n",
      "Epoch [22/50], Step [115/735], Loss: 0.1211\n",
      "Epoch [22/50], Step [116/735], Loss: 0.0253\n",
      "Epoch [22/50], Step [117/735], Loss: 0.0515\n",
      "Epoch [22/50], Step [118/735], Loss: 0.0490\n",
      "Epoch [22/50], Step [119/735], Loss: 0.0236\n",
      "Epoch [22/50], Step [120/735], Loss: 0.0214\n",
      "Epoch [22/50], Step [121/735], Loss: 0.0466\n",
      "Epoch [22/50], Step [122/735], Loss: 0.0360\n",
      "Epoch [22/50], Step [123/735], Loss: 0.1002\n",
      "Epoch [22/50], Step [124/735], Loss: 0.0379\n",
      "Epoch [22/50], Step [125/735], Loss: 0.0334\n",
      "Epoch [22/50], Step [126/735], Loss: 0.0278\n",
      "Epoch [22/50], Step [127/735], Loss: 0.0469\n",
      "Epoch [22/50], Step [128/735], Loss: 0.0837\n",
      "Epoch [22/50], Step [129/735], Loss: 0.0623\n",
      "Epoch [22/50], Step [130/735], Loss: 0.0334\n",
      "Epoch [22/50], Step [131/735], Loss: 0.1483\n",
      "Epoch [22/50], Step [132/735], Loss: 0.0432\n",
      "Epoch [22/50], Step [133/735], Loss: 0.1177\n",
      "Epoch [22/50], Step [134/735], Loss: 0.0712\n",
      "Epoch [22/50], Step [135/735], Loss: 0.0337\n",
      "Epoch [22/50], Step [136/735], Loss: 0.0711\n",
      "Epoch [22/50], Step [137/735], Loss: 0.0458\n",
      "Epoch [22/50], Step [138/735], Loss: 0.1037\n",
      "Epoch [22/50], Step [139/735], Loss: 0.3632\n",
      "Epoch [22/50], Step [140/735], Loss: 0.0773\n",
      "Epoch [22/50], Step [141/735], Loss: 0.0322\n",
      "Epoch [22/50], Step [142/735], Loss: 0.0635\n",
      "Epoch [22/50], Step [143/735], Loss: 0.1735\n",
      "Epoch [22/50], Step [144/735], Loss: 0.0246\n",
      "Epoch [22/50], Step [145/735], Loss: 0.0563\n",
      "Epoch [22/50], Step [146/735], Loss: 0.0220\n",
      "Epoch [22/50], Step [147/735], Loss: 0.0683\n",
      "Epoch [22/50], Step [148/735], Loss: 0.2022\n",
      "Epoch [22/50], Step [149/735], Loss: 0.0362\n",
      "Epoch [22/50], Step [150/735], Loss: 0.0922\n",
      "Epoch [22/50], Step [151/735], Loss: 0.0712\n",
      "Epoch [22/50], Step [152/735], Loss: 0.1868\n",
      "Epoch [22/50], Step [153/735], Loss: 0.0825\n",
      "Epoch [22/50], Step [154/735], Loss: 0.1941\n",
      "Epoch [22/50], Step [155/735], Loss: 0.0276\n",
      "Epoch [22/50], Step [156/735], Loss: 0.0968\n",
      "Epoch [22/50], Step [157/735], Loss: 0.1066\n",
      "Epoch [22/50], Step [158/735], Loss: 0.0572\n",
      "Epoch [22/50], Step [159/735], Loss: 0.1088\n",
      "Epoch [22/50], Step [160/735], Loss: 0.0360\n",
      "Epoch [22/50], Step [161/735], Loss: 0.0643\n",
      "Epoch [22/50], Step [162/735], Loss: 0.0253\n",
      "Epoch [22/50], Step [163/735], Loss: 0.0391\n",
      "Epoch [22/50], Step [164/735], Loss: 0.0932\n",
      "Epoch [22/50], Step [165/735], Loss: 0.0376\n",
      "Epoch [22/50], Step [166/735], Loss: 0.0884\n",
      "Epoch [22/50], Step [167/735], Loss: 0.0939\n",
      "Epoch [22/50], Step [168/735], Loss: 0.0709\n",
      "Epoch [22/50], Step [169/735], Loss: 0.0269\n",
      "Epoch [22/50], Step [170/735], Loss: 0.0551\n",
      "Epoch [22/50], Step [171/735], Loss: 0.2302\n",
      "Epoch [22/50], Step [172/735], Loss: 0.0384\n",
      "Epoch [22/50], Step [173/735], Loss: 0.0299\n",
      "Epoch [22/50], Step [174/735], Loss: 0.0326\n",
      "Epoch [22/50], Step [175/735], Loss: 0.0639\n",
      "Epoch [22/50], Step [176/735], Loss: 0.1278\n",
      "Epoch [22/50], Step [177/735], Loss: 0.1273\n",
      "Epoch [22/50], Step [178/735], Loss: 0.0290\n",
      "Epoch [22/50], Step [179/735], Loss: 0.0670\n",
      "Epoch [22/50], Step [180/735], Loss: 0.1110\n",
      "Epoch [22/50], Step [181/735], Loss: 0.3035\n",
      "Epoch [22/50], Step [182/735], Loss: 0.0412\n",
      "Epoch [22/50], Step [183/735], Loss: 0.0643\n",
      "Epoch [22/50], Step [184/735], Loss: 0.0710\n",
      "Epoch [22/50], Step [185/735], Loss: 0.0396\n",
      "Epoch [22/50], Step [186/735], Loss: 0.1703\n",
      "Epoch [22/50], Step [187/735], Loss: 0.0468\n",
      "Epoch [22/50], Step [188/735], Loss: 0.0726\n",
      "Epoch [22/50], Step [189/735], Loss: 0.0749\n",
      "Epoch [22/50], Step [190/735], Loss: 0.0302\n",
      "Epoch [22/50], Step [191/735], Loss: 0.0714\n",
      "Epoch [22/50], Step [192/735], Loss: 0.1623\n",
      "Epoch [22/50], Step [193/735], Loss: 0.0755\n",
      "Epoch [22/50], Step [194/735], Loss: 0.0741\n",
      "Epoch [22/50], Step [195/735], Loss: 0.0578\n",
      "Epoch [22/50], Step [196/735], Loss: 0.0539\n",
      "Epoch [22/50], Step [197/735], Loss: 0.0425\n",
      "Epoch [22/50], Step [198/735], Loss: 0.0482\n",
      "Epoch [22/50], Step [199/735], Loss: 0.0354\n",
      "Epoch [22/50], Step [200/735], Loss: 0.0148\n",
      "Epoch [22/50], Step [201/735], Loss: 0.1018\n",
      "Epoch [22/50], Step [202/735], Loss: 0.0322\n",
      "Epoch [22/50], Step [203/735], Loss: 0.1004\n",
      "Epoch [22/50], Step [204/735], Loss: 0.2586\n",
      "Epoch [22/50], Step [205/735], Loss: 0.3838\n",
      "Epoch [22/50], Step [206/735], Loss: 0.0267\n",
      "Epoch [22/50], Step [207/735], Loss: 0.0715\n",
      "Epoch [22/50], Step [208/735], Loss: 0.0998\n",
      "Epoch [22/50], Step [209/735], Loss: 0.1087\n",
      "Epoch [22/50], Step [210/735], Loss: 0.1249\n",
      "Epoch [22/50], Step [211/735], Loss: 0.0201\n",
      "Epoch [22/50], Step [212/735], Loss: 0.0568\n",
      "Epoch [22/50], Step [213/735], Loss: 0.0510\n",
      "Epoch [22/50], Step [214/735], Loss: 0.0769\n",
      "Epoch [22/50], Step [215/735], Loss: 0.0432\n",
      "Epoch [22/50], Step [216/735], Loss: 0.0187\n",
      "Epoch [22/50], Step [217/735], Loss: 0.1811\n",
      "Epoch [22/50], Step [218/735], Loss: 0.0162\n",
      "Epoch [22/50], Step [219/735], Loss: 0.0470\n",
      "Epoch [22/50], Step [220/735], Loss: 0.1494\n",
      "Epoch [22/50], Step [221/735], Loss: 0.0501\n",
      "Epoch [22/50], Step [222/735], Loss: 0.0359\n",
      "Epoch [22/50], Step [223/735], Loss: 0.1014\n",
      "Epoch [22/50], Step [224/735], Loss: 0.1891\n",
      "Epoch [22/50], Step [225/735], Loss: 0.0263\n",
      "Epoch [22/50], Step [226/735], Loss: 0.0154\n",
      "Epoch [22/50], Step [227/735], Loss: 0.0509\n",
      "Epoch [22/50], Step [228/735], Loss: 0.0185\n",
      "Epoch [22/50], Step [229/735], Loss: 0.0863\n",
      "Epoch [22/50], Step [230/735], Loss: 0.0718\n",
      "Epoch [22/50], Step [231/735], Loss: 0.1523\n",
      "Epoch [22/50], Step [232/735], Loss: 0.1051\n",
      "Epoch [22/50], Step [233/735], Loss: 0.0852\n",
      "Epoch [22/50], Step [234/735], Loss: 0.0220\n",
      "Epoch [22/50], Step [235/735], Loss: 0.0316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Step [236/735], Loss: 0.1771\n",
      "Epoch [22/50], Step [237/735], Loss: 0.0519\n",
      "Epoch [22/50], Step [238/735], Loss: 0.1808\n",
      "Epoch [22/50], Step [239/735], Loss: 0.0450\n",
      "Epoch [22/50], Step [240/735], Loss: 0.0800\n",
      "Epoch [22/50], Step [241/735], Loss: 0.0902\n",
      "Epoch [22/50], Step [242/735], Loss: 0.0186\n",
      "Epoch [22/50], Step [243/735], Loss: 0.0412\n",
      "Epoch [22/50], Step [244/735], Loss: 0.0422\n",
      "Epoch [22/50], Step [245/735], Loss: 0.1679\n",
      "Epoch [22/50], Step [246/735], Loss: 0.1360\n",
      "Epoch [22/50], Step [247/735], Loss: 0.0503\n",
      "Epoch [22/50], Step [248/735], Loss: 0.1401\n",
      "Epoch [22/50], Step [249/735], Loss: 0.3302\n",
      "Epoch [22/50], Step [250/735], Loss: 0.0279\n",
      "Epoch [22/50], Step [251/735], Loss: 0.0765\n",
      "Epoch [22/50], Step [252/735], Loss: 0.1262\n",
      "Epoch [22/50], Step [253/735], Loss: 0.1294\n",
      "Epoch [22/50], Step [254/735], Loss: 0.1046\n",
      "Epoch [22/50], Step [255/735], Loss: 0.0816\n",
      "Epoch [22/50], Step [256/735], Loss: 0.0959\n",
      "Epoch [22/50], Step [257/735], Loss: 0.0813\n",
      "Epoch [22/50], Step [258/735], Loss: 0.0588\n",
      "Epoch [22/50], Step [259/735], Loss: 0.0860\n",
      "Epoch [22/50], Step [260/735], Loss: 0.0206\n",
      "Epoch [22/50], Step [261/735], Loss: 0.0614\n",
      "Epoch [22/50], Step [262/735], Loss: 0.1552\n",
      "Epoch [22/50], Step [263/735], Loss: 0.0695\n",
      "Epoch [22/50], Step [264/735], Loss: 0.0323\n",
      "Epoch [22/50], Step [265/735], Loss: 0.0204\n",
      "Epoch [22/50], Step [266/735], Loss: 0.0766\n",
      "Epoch [22/50], Step [267/735], Loss: 0.1051\n",
      "Epoch [22/50], Step [268/735], Loss: 0.0651\n",
      "Epoch [22/50], Step [269/735], Loss: 0.2548\n",
      "Epoch [22/50], Step [270/735], Loss: 0.0987\n",
      "Epoch [22/50], Step [271/735], Loss: 0.0691\n",
      "Epoch [22/50], Step [272/735], Loss: 0.0521\n",
      "Epoch [22/50], Step [273/735], Loss: 0.1557\n",
      "Epoch [22/50], Step [274/735], Loss: 0.0351\n",
      "Epoch [22/50], Step [275/735], Loss: 0.0271\n",
      "Epoch [22/50], Step [276/735], Loss: 0.0300\n",
      "Epoch [22/50], Step [277/735], Loss: 0.0543\n",
      "Epoch [22/50], Step [278/735], Loss: 0.1086\n",
      "Epoch [22/50], Step [279/735], Loss: 0.1114\n",
      "Epoch [22/50], Step [280/735], Loss: 0.0222\n",
      "Epoch [22/50], Step [281/735], Loss: 0.0441\n",
      "Epoch [22/50], Step [282/735], Loss: 0.0239\n",
      "Epoch [22/50], Step [283/735], Loss: 0.0842\n",
      "Epoch [22/50], Step [284/735], Loss: 0.1067\n",
      "Epoch [22/50], Step [285/735], Loss: 0.0342\n",
      "Epoch [22/50], Step [286/735], Loss: 0.1573\n",
      "Epoch [22/50], Step [287/735], Loss: 0.0740\n",
      "Epoch [22/50], Step [288/735], Loss: 0.0833\n",
      "Epoch [22/50], Step [289/735], Loss: 0.1104\n",
      "Epoch [22/50], Step [290/735], Loss: 0.0387\n",
      "Epoch [22/50], Step [291/735], Loss: 0.0454\n",
      "Epoch [22/50], Step [292/735], Loss: 0.0246\n",
      "Epoch [22/50], Step [293/735], Loss: 0.3721\n",
      "Epoch [22/50], Step [294/735], Loss: 0.0666\n",
      "Epoch [22/50], Step [295/735], Loss: 0.1321\n",
      "Epoch [22/50], Step [296/735], Loss: 0.0722\n",
      "Epoch [22/50], Step [297/735], Loss: 0.0199\n",
      "Epoch [22/50], Step [298/735], Loss: 0.1173\n",
      "Epoch [22/50], Step [299/735], Loss: 0.0557\n",
      "Epoch [22/50], Step [300/735], Loss: 0.0877\n",
      "Epoch [22/50], Step [301/735], Loss: 0.0425\n",
      "Epoch [22/50], Step [302/735], Loss: 0.0233\n",
      "Epoch [22/50], Step [303/735], Loss: 0.1022\n",
      "Epoch [22/50], Step [304/735], Loss: 0.0115\n",
      "Epoch [22/50], Step [305/735], Loss: 0.0231\n",
      "Epoch [22/50], Step [306/735], Loss: 0.1815\n",
      "Epoch [22/50], Step [307/735], Loss: 0.1333\n",
      "Epoch [22/50], Step [308/735], Loss: 0.0471\n",
      "Epoch [22/50], Step [309/735], Loss: 0.2219\n",
      "Epoch [22/50], Step [310/735], Loss: 0.1157\n",
      "Epoch [22/50], Step [311/735], Loss: 0.1036\n",
      "Epoch [22/50], Step [312/735], Loss: 0.1926\n",
      "Epoch [22/50], Step [313/735], Loss: 0.1888\n",
      "Epoch [22/50], Step [314/735], Loss: 0.0754\n",
      "Epoch [22/50], Step [315/735], Loss: 0.0627\n",
      "Epoch [22/50], Step [316/735], Loss: 0.3987\n",
      "Epoch [22/50], Step [317/735], Loss: 0.1488\n",
      "Epoch [22/50], Step [318/735], Loss: 0.0786\n",
      "Epoch [22/50], Step [319/735], Loss: 0.0476\n",
      "Epoch [22/50], Step [320/735], Loss: 0.2546\n",
      "Epoch [22/50], Step [321/735], Loss: 0.0666\n",
      "Epoch [22/50], Step [322/735], Loss: 0.0882\n",
      "Epoch [22/50], Step [323/735], Loss: 0.0488\n",
      "Epoch [22/50], Step [324/735], Loss: 0.0706\n",
      "Epoch [22/50], Step [325/735], Loss: 0.0834\n",
      "Epoch [22/50], Step [326/735], Loss: 0.1331\n",
      "Epoch [22/50], Step [327/735], Loss: 0.0401\n",
      "Epoch [22/50], Step [328/735], Loss: 0.0916\n",
      "Epoch [22/50], Step [329/735], Loss: 0.0911\n",
      "Epoch [22/50], Step [330/735], Loss: 0.1498\n",
      "Epoch [22/50], Step [331/735], Loss: 0.0486\n",
      "Epoch [22/50], Step [332/735], Loss: 0.1032\n",
      "Epoch [22/50], Step [333/735], Loss: 0.1221\n",
      "Epoch [22/50], Step [334/735], Loss: 0.1260\n",
      "Epoch [22/50], Step [335/735], Loss: 0.0851\n",
      "Epoch [22/50], Step [336/735], Loss: 0.0865\n",
      "Epoch [22/50], Step [337/735], Loss: 0.0978\n",
      "Epoch [22/50], Step [338/735], Loss: 0.1016\n",
      "Epoch [22/50], Step [339/735], Loss: 0.0749\n",
      "Epoch [22/50], Step [340/735], Loss: 0.1052\n",
      "Epoch [22/50], Step [341/735], Loss: 0.0458\n",
      "Epoch [22/50], Step [342/735], Loss: 0.0733\n",
      "Epoch [22/50], Step [343/735], Loss: 0.0537\n",
      "Epoch [22/50], Step [344/735], Loss: 0.0886\n",
      "Epoch [22/50], Step [345/735], Loss: 0.0352\n",
      "Epoch [22/50], Step [346/735], Loss: 0.0164\n",
      "Epoch [22/50], Step [347/735], Loss: 0.1130\n",
      "Epoch [22/50], Step [348/735], Loss: 0.0490\n",
      "Epoch [22/50], Step [349/735], Loss: 0.0536\n",
      "Epoch [22/50], Step [350/735], Loss: 0.1034\n",
      "Epoch [22/50], Step [351/735], Loss: 0.0852\n",
      "Epoch [22/50], Step [352/735], Loss: 0.0401\n",
      "Epoch [22/50], Step [353/735], Loss: 0.0916\n",
      "Epoch [22/50], Step [354/735], Loss: 0.1515\n",
      "Epoch [22/50], Step [355/735], Loss: 0.1816\n",
      "Epoch [22/50], Step [356/735], Loss: 0.0402\n",
      "Epoch [22/50], Step [357/735], Loss: 0.0576\n",
      "Epoch [22/50], Step [358/735], Loss: 0.0418\n",
      "Epoch [22/50], Step [359/735], Loss: 0.0477\n",
      "Epoch [22/50], Step [360/735], Loss: 0.0640\n",
      "Epoch [22/50], Step [361/735], Loss: 0.0271\n",
      "Epoch [22/50], Step [362/735], Loss: 0.0150\n",
      "Epoch [22/50], Step [363/735], Loss: 0.0931\n",
      "Epoch [22/50], Step [364/735], Loss: 0.1407\n",
      "Epoch [22/50], Step [365/735], Loss: 0.0673\n",
      "Epoch [22/50], Step [366/735], Loss: 0.0337\n",
      "Epoch [22/50], Step [367/735], Loss: 0.0225\n",
      "Epoch [22/50], Step [368/735], Loss: 0.0454\n",
      "Epoch [22/50], Step [369/735], Loss: 0.1124\n",
      "Epoch [22/50], Step [370/735], Loss: 0.0408\n",
      "Epoch [22/50], Step [371/735], Loss: 0.1202\n",
      "Epoch [22/50], Step [372/735], Loss: 0.1336\n",
      "Epoch [22/50], Step [373/735], Loss: 0.0319\n",
      "Epoch [22/50], Step [374/735], Loss: 0.1336\n",
      "Epoch [22/50], Step [375/735], Loss: 0.0169\n",
      "Epoch [22/50], Step [376/735], Loss: 0.0992\n",
      "Epoch [22/50], Step [377/735], Loss: 0.1077\n",
      "Epoch [22/50], Step [378/735], Loss: 0.0673\n",
      "Epoch [22/50], Step [379/735], Loss: 0.0569\n",
      "Epoch [22/50], Step [380/735], Loss: 0.0386\n",
      "Epoch [22/50], Step [381/735], Loss: 0.1480\n",
      "Epoch [22/50], Step [382/735], Loss: 0.1004\n",
      "Epoch [22/50], Step [383/735], Loss: 0.0552\n",
      "Epoch [22/50], Step [384/735], Loss: 0.0670\n",
      "Epoch [22/50], Step [385/735], Loss: 0.0603\n",
      "Epoch [22/50], Step [386/735], Loss: 0.1304\n",
      "Epoch [22/50], Step [387/735], Loss: 0.1710\n",
      "Epoch [22/50], Step [388/735], Loss: 0.0312\n",
      "Epoch [22/50], Step [389/735], Loss: 0.0647\n",
      "Epoch [22/50], Step [390/735], Loss: 0.0511\n",
      "Epoch [22/50], Step [391/735], Loss: 0.0559\n",
      "Epoch [22/50], Step [392/735], Loss: 0.0427\n",
      "Epoch [22/50], Step [393/735], Loss: 0.0523\n",
      "Epoch [22/50], Step [394/735], Loss: 0.0147\n",
      "Epoch [22/50], Step [395/735], Loss: 0.0892\n",
      "Epoch [22/50], Step [396/735], Loss: 0.0545\n",
      "Epoch [22/50], Step [397/735], Loss: 0.3498\n",
      "Epoch [22/50], Step [398/735], Loss: 0.0574\n",
      "Epoch [22/50], Step [399/735], Loss: 0.1130\n",
      "Epoch [22/50], Step [400/735], Loss: 0.1074\n",
      "Epoch [22/50], Step [401/735], Loss: 0.0546\n",
      "Epoch [22/50], Step [402/735], Loss: 0.1432\n",
      "Epoch [22/50], Step [403/735], Loss: 0.1286\n",
      "Epoch [22/50], Step [404/735], Loss: 0.0133\n",
      "Epoch [22/50], Step [405/735], Loss: 0.0565\n",
      "Epoch [22/50], Step [406/735], Loss: 0.0875\n",
      "Epoch [22/50], Step [407/735], Loss: 0.0777\n",
      "Epoch [22/50], Step [408/735], Loss: 0.0816\n",
      "Epoch [22/50], Step [409/735], Loss: 0.0609\n",
      "Epoch [22/50], Step [410/735], Loss: 0.1350\n",
      "Epoch [22/50], Step [411/735], Loss: 0.0545\n",
      "Epoch [22/50], Step [412/735], Loss: 0.0350\n",
      "Epoch [22/50], Step [413/735], Loss: 0.0216\n",
      "Epoch [22/50], Step [414/735], Loss: 0.0424\n",
      "Epoch [22/50], Step [415/735], Loss: 0.0876\n",
      "Epoch [22/50], Step [416/735], Loss: 0.0476\n",
      "Epoch [22/50], Step [417/735], Loss: 0.1102\n",
      "Epoch [22/50], Step [418/735], Loss: 0.0484\n",
      "Epoch [22/50], Step [419/735], Loss: 0.1650\n",
      "Epoch [22/50], Step [420/735], Loss: 0.0395\n",
      "Epoch [22/50], Step [421/735], Loss: 0.1394\n",
      "Epoch [22/50], Step [422/735], Loss: 0.2505\n",
      "Epoch [22/50], Step [423/735], Loss: 0.0337\n",
      "Epoch [22/50], Step [424/735], Loss: 0.1185\n",
      "Epoch [22/50], Step [425/735], Loss: 0.0414\n",
      "Epoch [22/50], Step [426/735], Loss: 0.1707\n",
      "Epoch [22/50], Step [427/735], Loss: 0.0473\n",
      "Epoch [22/50], Step [428/735], Loss: 0.1003\n",
      "Epoch [22/50], Step [429/735], Loss: 0.0642\n",
      "Epoch [22/50], Step [430/735], Loss: 0.0517\n",
      "Epoch [22/50], Step [431/735], Loss: 0.0440\n",
      "Epoch [22/50], Step [432/735], Loss: 0.0395\n",
      "Epoch [22/50], Step [433/735], Loss: 0.0958\n",
      "Epoch [22/50], Step [434/735], Loss: 0.1497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Step [435/735], Loss: 0.0516\n",
      "Epoch [22/50], Step [436/735], Loss: 0.0391\n",
      "Epoch [22/50], Step [437/735], Loss: 0.0729\n",
      "Epoch [22/50], Step [438/735], Loss: 0.0498\n",
      "Epoch [22/50], Step [439/735], Loss: 0.0605\n",
      "Epoch [22/50], Step [440/735], Loss: 0.0151\n",
      "Epoch [22/50], Step [441/735], Loss: 0.1386\n",
      "Epoch [22/50], Step [442/735], Loss: 0.0314\n",
      "Epoch [22/50], Step [443/735], Loss: 0.1087\n",
      "Epoch [22/50], Step [444/735], Loss: 0.0374\n",
      "Epoch [22/50], Step [445/735], Loss: 0.1283\n",
      "Epoch [22/50], Step [446/735], Loss: 0.0978\n",
      "Epoch [22/50], Step [447/735], Loss: 0.0561\n",
      "Epoch [22/50], Step [448/735], Loss: 0.1349\n",
      "Epoch [22/50], Step [449/735], Loss: 0.1176\n",
      "Epoch [22/50], Step [450/735], Loss: 0.2009\n",
      "Epoch [22/50], Step [451/735], Loss: 0.1399\n",
      "Epoch [22/50], Step [452/735], Loss: 0.0516\n",
      "Epoch [22/50], Step [453/735], Loss: 0.0828\n",
      "Epoch [22/50], Step [454/735], Loss: 0.0883\n",
      "Epoch [22/50], Step [455/735], Loss: 0.1486\n",
      "Epoch [22/50], Step [456/735], Loss: 0.0370\n",
      "Epoch [22/50], Step [457/735], Loss: 0.0577\n",
      "Epoch [22/50], Step [458/735], Loss: 0.1524\n",
      "Epoch [22/50], Step [459/735], Loss: 0.1954\n",
      "Epoch [22/50], Step [460/735], Loss: 0.0254\n",
      "Epoch [22/50], Step [461/735], Loss: 0.0516\n",
      "Epoch [22/50], Step [462/735], Loss: 0.0400\n",
      "Epoch [22/50], Step [463/735], Loss: 0.0577\n",
      "Epoch [22/50], Step [464/735], Loss: 0.0470\n",
      "Epoch [22/50], Step [465/735], Loss: 0.0362\n",
      "Epoch [22/50], Step [466/735], Loss: 0.0700\n",
      "Epoch [22/50], Step [467/735], Loss: 0.0863\n",
      "Epoch [22/50], Step [468/735], Loss: 0.0234\n",
      "Epoch [22/50], Step [469/735], Loss: 0.0970\n",
      "Epoch [22/50], Step [470/735], Loss: 0.0342\n",
      "Epoch [22/50], Step [471/735], Loss: 0.0621\n",
      "Epoch [22/50], Step [472/735], Loss: 0.1736\n",
      "Epoch [22/50], Step [473/735], Loss: 0.0396\n",
      "Epoch [22/50], Step [474/735], Loss: 0.1294\n",
      "Epoch [22/50], Step [475/735], Loss: 0.0391\n",
      "Epoch [22/50], Step [476/735], Loss: 0.0149\n",
      "Epoch [22/50], Step [477/735], Loss: 0.1024\n",
      "Epoch [22/50], Step [478/735], Loss: 0.1066\n",
      "Epoch [22/50], Step [479/735], Loss: 0.1222\n",
      "Epoch [22/50], Step [480/735], Loss: 0.1182\n",
      "Epoch [22/50], Step [481/735], Loss: 0.3693\n",
      "Epoch [22/50], Step [482/735], Loss: 0.0649\n",
      "Epoch [22/50], Step [483/735], Loss: 0.1238\n",
      "Epoch [22/50], Step [484/735], Loss: 0.0916\n",
      "Epoch [22/50], Step [485/735], Loss: 0.0225\n",
      "Epoch [22/50], Step [486/735], Loss: 0.0252\n",
      "Epoch [22/50], Step [487/735], Loss: 0.1072\n",
      "Epoch [22/50], Step [488/735], Loss: 0.2441\n",
      "Epoch [22/50], Step [489/735], Loss: 0.0874\n",
      "Epoch [22/50], Step [490/735], Loss: 0.1435\n",
      "Epoch [22/50], Step [491/735], Loss: 0.0278\n",
      "Epoch [22/50], Step [492/735], Loss: 0.1245\n",
      "Epoch [22/50], Step [493/735], Loss: 0.3835\n",
      "Epoch [22/50], Step [494/735], Loss: 0.0918\n",
      "Epoch [22/50], Step [495/735], Loss: 0.0545\n",
      "Epoch [22/50], Step [496/735], Loss: 0.0247\n",
      "Epoch [22/50], Step [497/735], Loss: 0.0391\n",
      "Epoch [22/50], Step [498/735], Loss: 0.2441\n",
      "Epoch [22/50], Step [499/735], Loss: 0.0457\n",
      "Epoch [22/50], Step [500/735], Loss: 0.0547\n",
      "Epoch [22/50], Step [501/735], Loss: 0.0294\n",
      "Epoch [22/50], Step [502/735], Loss: 0.0277\n",
      "Epoch [22/50], Step [503/735], Loss: 0.0577\n",
      "Epoch [22/50], Step [504/735], Loss: 0.0981\n",
      "Epoch [22/50], Step [505/735], Loss: 0.0237\n",
      "Epoch [22/50], Step [506/735], Loss: 0.0345\n",
      "Epoch [22/50], Step [507/735], Loss: 0.0422\n",
      "Epoch [22/50], Step [508/735], Loss: 0.1167\n",
      "Epoch [22/50], Step [509/735], Loss: 0.0579\n",
      "Epoch [22/50], Step [510/735], Loss: 0.0511\n",
      "Epoch [22/50], Step [511/735], Loss: 0.0294\n",
      "Epoch [22/50], Step [512/735], Loss: 0.0759\n",
      "Epoch [22/50], Step [513/735], Loss: 0.5830\n",
      "Epoch [22/50], Step [514/735], Loss: 0.0625\n",
      "Epoch [22/50], Step [515/735], Loss: 0.0528\n",
      "Epoch [22/50], Step [516/735], Loss: 0.1603\n",
      "Epoch [22/50], Step [517/735], Loss: 0.0416\n",
      "Epoch [22/50], Step [518/735], Loss: 0.2256\n",
      "Epoch [22/50], Step [519/735], Loss: 0.0640\n",
      "Epoch [22/50], Step [520/735], Loss: 0.0218\n",
      "Epoch [22/50], Step [521/735], Loss: 0.1298\n",
      "Epoch [22/50], Step [522/735], Loss: 0.0680\n",
      "Epoch [22/50], Step [523/735], Loss: 0.1454\n",
      "Epoch [22/50], Step [524/735], Loss: 0.0442\n",
      "Epoch [22/50], Step [525/735], Loss: 0.0907\n",
      "Epoch [22/50], Step [526/735], Loss: 0.0587\n",
      "Epoch [22/50], Step [527/735], Loss: 0.0414\n",
      "Epoch [22/50], Step [528/735], Loss: 0.0600\n",
      "Epoch [22/50], Step [529/735], Loss: 0.0451\n",
      "Epoch [22/50], Step [530/735], Loss: 0.0416\n",
      "Epoch [22/50], Step [531/735], Loss: 0.1844\n",
      "Epoch [22/50], Step [532/735], Loss: 0.0513\n",
      "Epoch [22/50], Step [533/735], Loss: 0.0600\n",
      "Epoch [22/50], Step [534/735], Loss: 0.0338\n",
      "Epoch [22/50], Step [535/735], Loss: 0.0278\n",
      "Epoch [22/50], Step [536/735], Loss: 0.0692\n",
      "Epoch [22/50], Step [537/735], Loss: 0.0335\n",
      "Epoch [22/50], Step [538/735], Loss: 0.0501\n",
      "Epoch [22/50], Step [539/735], Loss: 0.1735\n",
      "Epoch [22/50], Step [540/735], Loss: 0.0257\n",
      "Epoch [22/50], Step [541/735], Loss: 0.1514\n",
      "Epoch [22/50], Step [542/735], Loss: 0.0514\n",
      "Epoch [22/50], Step [543/735], Loss: 0.0433\n",
      "Epoch [22/50], Step [544/735], Loss: 0.2431\n",
      "Epoch [22/50], Step [545/735], Loss: 0.6062\n",
      "Epoch [22/50], Step [546/735], Loss: 0.0701\n",
      "Epoch [22/50], Step [547/735], Loss: 0.0163\n",
      "Epoch [22/50], Step [548/735], Loss: 0.1037\n",
      "Epoch [22/50], Step [549/735], Loss: 0.0695\n",
      "Epoch [22/50], Step [550/735], Loss: 0.1199\n",
      "Epoch [22/50], Step [551/735], Loss: 0.0702\n",
      "Epoch [22/50], Step [552/735], Loss: 0.0647\n",
      "Epoch [22/50], Step [553/735], Loss: 0.0544\n",
      "Epoch [22/50], Step [554/735], Loss: 0.1373\n",
      "Epoch [22/50], Step [555/735], Loss: 0.2621\n",
      "Epoch [22/50], Step [556/735], Loss: 0.1077\n",
      "Epoch [22/50], Step [557/735], Loss: 0.0685\n",
      "Epoch [22/50], Step [558/735], Loss: 0.0555\n",
      "Epoch [22/50], Step [559/735], Loss: 0.2074\n",
      "Epoch [22/50], Step [560/735], Loss: 0.0378\n",
      "Epoch [22/50], Step [561/735], Loss: 0.3463\n",
      "Epoch [22/50], Step [562/735], Loss: 0.0213\n",
      "Epoch [22/50], Step [563/735], Loss: 0.0274\n",
      "Epoch [22/50], Step [564/735], Loss: 0.0784\n",
      "Epoch [22/50], Step [565/735], Loss: 0.0368\n",
      "Epoch [22/50], Step [566/735], Loss: 0.0299\n",
      "Epoch [22/50], Step [567/735], Loss: 0.0182\n",
      "Epoch [22/50], Step [568/735], Loss: 0.0428\n",
      "Epoch [22/50], Step [569/735], Loss: 0.0289\n",
      "Epoch [22/50], Step [570/735], Loss: 0.0880\n",
      "Epoch [22/50], Step [571/735], Loss: 0.0719\n",
      "Epoch [22/50], Step [572/735], Loss: 0.1195\n",
      "Epoch [22/50], Step [573/735], Loss: 0.0623\n",
      "Epoch [22/50], Step [574/735], Loss: 0.0159\n",
      "Epoch [22/50], Step [575/735], Loss: 0.0806\n",
      "Epoch [22/50], Step [576/735], Loss: 0.1611\n",
      "Epoch [22/50], Step [577/735], Loss: 0.0475\n",
      "Epoch [22/50], Step [578/735], Loss: 0.0230\n",
      "Epoch [22/50], Step [579/735], Loss: 0.0296\n",
      "Epoch [22/50], Step [580/735], Loss: 0.0504\n",
      "Epoch [22/50], Step [581/735], Loss: 0.1353\n",
      "Epoch [22/50], Step [582/735], Loss: 0.1618\n",
      "Epoch [22/50], Step [583/735], Loss: 0.0287\n",
      "Epoch [22/50], Step [584/735], Loss: 0.0448\n",
      "Epoch [22/50], Step [585/735], Loss: 0.0758\n",
      "Epoch [22/50], Step [586/735], Loss: 0.0672\n",
      "Epoch [22/50], Step [587/735], Loss: 0.0460\n",
      "Epoch [22/50], Step [588/735], Loss: 0.1228\n",
      "Epoch [22/50], Step [589/735], Loss: 0.0989\n",
      "Epoch [22/50], Step [590/735], Loss: 0.0748\n",
      "Epoch [22/50], Step [591/735], Loss: 0.0227\n",
      "Epoch [22/50], Step [592/735], Loss: 0.1110\n",
      "Epoch [22/50], Step [593/735], Loss: 0.0305\n",
      "Epoch [22/50], Step [594/735], Loss: 0.0237\n",
      "Epoch [22/50], Step [595/735], Loss: 0.0724\n",
      "Epoch [22/50], Step [596/735], Loss: 0.0746\n",
      "Epoch [22/50], Step [597/735], Loss: 0.0349\n",
      "Epoch [22/50], Step [598/735], Loss: 0.0243\n",
      "Epoch [22/50], Step [599/735], Loss: 0.0395\n",
      "Epoch [22/50], Step [600/735], Loss: 0.0620\n",
      "Epoch [22/50], Step [601/735], Loss: 0.1090\n",
      "Epoch [22/50], Step [602/735], Loss: 0.0859\n",
      "Epoch [22/50], Step [603/735], Loss: 0.0689\n",
      "Epoch [22/50], Step [604/735], Loss: 0.0486\n",
      "Epoch [22/50], Step [605/735], Loss: 0.0617\n",
      "Epoch [22/50], Step [606/735], Loss: 0.1457\n",
      "Epoch [22/50], Step [607/735], Loss: 0.0285\n",
      "Epoch [22/50], Step [608/735], Loss: 0.0689\n",
      "Epoch [22/50], Step [609/735], Loss: 0.1492\n",
      "Epoch [22/50], Step [610/735], Loss: 0.0872\n",
      "Epoch [22/50], Step [611/735], Loss: 0.1431\n",
      "Epoch [22/50], Step [612/735], Loss: 0.1386\n",
      "Epoch [22/50], Step [613/735], Loss: 0.0314\n",
      "Epoch [22/50], Step [614/735], Loss: 0.1011\n",
      "Epoch [22/50], Step [615/735], Loss: 0.0589\n",
      "Epoch [22/50], Step [616/735], Loss: 0.0658\n",
      "Epoch [22/50], Step [617/735], Loss: 0.0383\n",
      "Epoch [22/50], Step [618/735], Loss: 0.1939\n",
      "Epoch [22/50], Step [619/735], Loss: 0.0759\n",
      "Epoch [22/50], Step [620/735], Loss: 0.0425\n",
      "Epoch [22/50], Step [621/735], Loss: 0.0762\n",
      "Epoch [22/50], Step [622/735], Loss: 0.0344\n",
      "Epoch [22/50], Step [623/735], Loss: 0.0287\n",
      "Epoch [22/50], Step [624/735], Loss: 0.1386\n",
      "Epoch [22/50], Step [625/735], Loss: 0.1130\n",
      "Epoch [22/50], Step [626/735], Loss: 0.0520\n",
      "Epoch [22/50], Step [627/735], Loss: 0.0258\n",
      "Epoch [22/50], Step [628/735], Loss: 0.0268\n",
      "Epoch [22/50], Step [629/735], Loss: 0.0381\n",
      "Epoch [22/50], Step [630/735], Loss: 0.0676\n",
      "Epoch [22/50], Step [631/735], Loss: 0.0276\n",
      "Epoch [22/50], Step [632/735], Loss: 0.0570\n",
      "Epoch [22/50], Step [633/735], Loss: 0.4810\n",
      "Epoch [22/50], Step [634/735], Loss: 0.1459\n",
      "Epoch [22/50], Step [635/735], Loss: 0.0983\n",
      "Epoch [22/50], Step [636/735], Loss: 0.1589\n",
      "Epoch [22/50], Step [637/735], Loss: 0.0835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Step [638/735], Loss: 0.1531\n",
      "Epoch [22/50], Step [639/735], Loss: 0.1870\n",
      "Epoch [22/50], Step [640/735], Loss: 0.0544\n",
      "Epoch [22/50], Step [641/735], Loss: 0.0604\n",
      "Epoch [22/50], Step [642/735], Loss: 0.1224\n",
      "Epoch [22/50], Step [643/735], Loss: 0.0992\n",
      "Epoch [22/50], Step [644/735], Loss: 0.5586\n",
      "Epoch [22/50], Step [645/735], Loss: 0.1090\n",
      "Epoch [22/50], Step [646/735], Loss: 0.0386\n",
      "Epoch [22/50], Step [647/735], Loss: 0.1696\n",
      "Epoch [22/50], Step [648/735], Loss: 0.0549\n",
      "Epoch [22/50], Step [649/735], Loss: 0.0787\n",
      "Epoch [22/50], Step [650/735], Loss: 0.0638\n",
      "Epoch [22/50], Step [651/735], Loss: 0.1541\n",
      "Epoch [22/50], Step [652/735], Loss: 0.0962\n",
      "Epoch [22/50], Step [653/735], Loss: 0.2250\n",
      "Epoch [22/50], Step [654/735], Loss: 0.0331\n",
      "Epoch [22/50], Step [655/735], Loss: 0.0486\n",
      "Epoch [22/50], Step [656/735], Loss: 0.1379\n",
      "Epoch [22/50], Step [657/735], Loss: 0.0435\n",
      "Epoch [22/50], Step [658/735], Loss: 0.1569\n",
      "Epoch [22/50], Step [659/735], Loss: 0.0607\n",
      "Epoch [22/50], Step [660/735], Loss: 0.0323\n",
      "Epoch [22/50], Step [661/735], Loss: 0.1251\n",
      "Epoch [22/50], Step [662/735], Loss: 0.3330\n",
      "Epoch [22/50], Step [663/735], Loss: 0.1031\n",
      "Epoch [22/50], Step [664/735], Loss: 0.0893\n",
      "Epoch [22/50], Step [665/735], Loss: 0.0444\n",
      "Epoch [22/50], Step [666/735], Loss: 0.0445\n",
      "Epoch [22/50], Step [667/735], Loss: 0.0657\n",
      "Epoch [22/50], Step [668/735], Loss: 0.1204\n",
      "Epoch [22/50], Step [669/735], Loss: 0.0341\n",
      "Epoch [22/50], Step [670/735], Loss: 0.0476\n",
      "Epoch [22/50], Step [671/735], Loss: 0.0802\n",
      "Epoch [22/50], Step [672/735], Loss: 0.0345\n",
      "Epoch [22/50], Step [673/735], Loss: 0.2084\n",
      "Epoch [22/50], Step [674/735], Loss: 0.0950\n",
      "Epoch [22/50], Step [675/735], Loss: 0.0787\n",
      "Epoch [22/50], Step [676/735], Loss: 0.0386\n",
      "Epoch [22/50], Step [677/735], Loss: 0.0232\n",
      "Epoch [22/50], Step [678/735], Loss: 0.0613\n",
      "Epoch [22/50], Step [679/735], Loss: 0.1045\n",
      "Epoch [22/50], Step [680/735], Loss: 0.0792\n",
      "Epoch [22/50], Step [681/735], Loss: 0.0942\n",
      "Epoch [22/50], Step [682/735], Loss: 0.0301\n",
      "Epoch [22/50], Step [683/735], Loss: 0.0396\n",
      "Epoch [22/50], Step [684/735], Loss: 0.1488\n",
      "Epoch [22/50], Step [685/735], Loss: 0.0832\n",
      "Epoch [22/50], Step [686/735], Loss: 0.0147\n",
      "Epoch [22/50], Step [687/735], Loss: 0.0518\n",
      "Epoch [22/50], Step [688/735], Loss: 0.0608\n",
      "Epoch [22/50], Step [689/735], Loss: 0.3855\n",
      "Epoch [22/50], Step [690/735], Loss: 0.0578\n",
      "Epoch [22/50], Step [691/735], Loss: 0.0371\n",
      "Epoch [22/50], Step [692/735], Loss: 0.1693\n",
      "Epoch [22/50], Step [693/735], Loss: 0.0425\n",
      "Epoch [22/50], Step [694/735], Loss: 0.0525\n",
      "Epoch [22/50], Step [695/735], Loss: 0.0621\n",
      "Epoch [22/50], Step [696/735], Loss: 0.0417\n",
      "Epoch [22/50], Step [697/735], Loss: 0.0997\n",
      "Epoch [22/50], Step [698/735], Loss: 0.0413\n",
      "Epoch [22/50], Step [699/735], Loss: 0.0474\n",
      "Epoch [22/50], Step [700/735], Loss: 0.1038\n",
      "Epoch [22/50], Step [701/735], Loss: 0.0552\n",
      "Epoch [22/50], Step [702/735], Loss: 0.0347\n",
      "Epoch [22/50], Step [703/735], Loss: 0.1037\n",
      "Epoch [22/50], Step [704/735], Loss: 0.5885\n",
      "Epoch [22/50], Step [705/735], Loss: 0.0793\n",
      "Epoch [22/50], Step [706/735], Loss: 0.0394\n",
      "Epoch [22/50], Step [707/735], Loss: 0.1509\n",
      "Epoch [22/50], Step [708/735], Loss: 0.0691\n",
      "Epoch [22/50], Step [709/735], Loss: 0.2046\n",
      "Epoch [22/50], Step [710/735], Loss: 0.0535\n",
      "Epoch [22/50], Step [711/735], Loss: 0.0379\n",
      "Epoch [22/50], Step [712/735], Loss: 0.0356\n",
      "Epoch [22/50], Step [713/735], Loss: 0.0862\n",
      "Epoch [22/50], Step [714/735], Loss: 0.1073\n",
      "Epoch [22/50], Step [715/735], Loss: 0.0582\n",
      "Epoch [22/50], Step [716/735], Loss: 0.0492\n",
      "Epoch [22/50], Step [717/735], Loss: 0.1795\n",
      "Epoch [22/50], Step [718/735], Loss: 0.2408\n",
      "Epoch [22/50], Step [719/735], Loss: 0.0720\n",
      "Epoch [22/50], Step [720/735], Loss: 0.1217\n",
      "Epoch [22/50], Step [721/735], Loss: 0.0744\n",
      "Epoch [22/50], Step [722/735], Loss: 0.0519\n",
      "Epoch [22/50], Step [723/735], Loss: 0.0289\n",
      "Epoch [22/50], Step [724/735], Loss: 0.1180\n",
      "Epoch [22/50], Step [725/735], Loss: 0.0474\n",
      "Epoch [22/50], Step [726/735], Loss: 0.0305\n",
      "Epoch [22/50], Step [727/735], Loss: 0.1603\n",
      "Epoch [22/50], Step [728/735], Loss: 0.1230\n",
      "Epoch [22/50], Step [729/735], Loss: 0.1052\n",
      "Epoch [22/50], Step [730/735], Loss: 0.0304\n",
      "Epoch [22/50], Step [731/735], Loss: 0.2175\n",
      "Epoch [22/50], Step [732/735], Loss: 0.0634\n",
      "Epoch [22/50], Step [733/735], Loss: 0.0191\n",
      "Epoch [22/50], Step [734/735], Loss: 0.0620\n",
      "Epoch [22/50], Step [735/735], Loss: 0.0407\n",
      "Epoch [23/50], Step [1/735], Loss: 0.0932\n",
      "Epoch [23/50], Step [2/735], Loss: 0.2105\n",
      "Epoch [23/50], Step [3/735], Loss: 0.0499\n",
      "Epoch [23/50], Step [4/735], Loss: 0.2358\n",
      "Epoch [23/50], Step [5/735], Loss: 0.0370\n",
      "Epoch [23/50], Step [6/735], Loss: 0.0192\n",
      "Epoch [23/50], Step [7/735], Loss: 0.0866\n",
      "Epoch [23/50], Step [8/735], Loss: 0.0441\n",
      "Epoch [23/50], Step [9/735], Loss: 0.0487\n",
      "Epoch [23/50], Step [10/735], Loss: 0.1308\n",
      "Epoch [23/50], Step [11/735], Loss: 0.0511\n",
      "Epoch [23/50], Step [12/735], Loss: 0.3970\n",
      "Epoch [23/50], Step [13/735], Loss: 0.1288\n",
      "Epoch [23/50], Step [14/735], Loss: 0.0437\n",
      "Epoch [23/50], Step [15/735], Loss: 0.0260\n",
      "Epoch [23/50], Step [16/735], Loss: 0.2457\n",
      "Epoch [23/50], Step [17/735], Loss: 0.0548\n",
      "Epoch [23/50], Step [18/735], Loss: 0.1926\n",
      "Epoch [23/50], Step [19/735], Loss: 0.0906\n",
      "Epoch [23/50], Step [20/735], Loss: 0.0336\n",
      "Epoch [23/50], Step [21/735], Loss: 0.0355\n",
      "Epoch [23/50], Step [22/735], Loss: 0.0649\n",
      "Epoch [23/50], Step [23/735], Loss: 0.0586\n",
      "Epoch [23/50], Step [24/735], Loss: 0.0655\n",
      "Epoch [23/50], Step [25/735], Loss: 0.0291\n",
      "Epoch [23/50], Step [26/735], Loss: 0.0268\n",
      "Epoch [23/50], Step [27/735], Loss: 0.0670\n",
      "Epoch [23/50], Step [28/735], Loss: 0.0856\n",
      "Epoch [23/50], Step [29/735], Loss: 0.0426\n",
      "Epoch [23/50], Step [30/735], Loss: 0.0683\n",
      "Epoch [23/50], Step [31/735], Loss: 0.0485\n",
      "Epoch [23/50], Step [32/735], Loss: 0.0698\n",
      "Epoch [23/50], Step [33/735], Loss: 0.0471\n",
      "Epoch [23/50], Step [34/735], Loss: 0.1199\n",
      "Epoch [23/50], Step [35/735], Loss: 0.0575\n",
      "Epoch [23/50], Step [36/735], Loss: 0.0314\n",
      "Epoch [23/50], Step [37/735], Loss: 0.0662\n",
      "Epoch [23/50], Step [38/735], Loss: 0.0817\n",
      "Epoch [23/50], Step [39/735], Loss: 0.1014\n",
      "Epoch [23/50], Step [40/735], Loss: 0.0558\n",
      "Epoch [23/50], Step [41/735], Loss: 0.0396\n",
      "Epoch [23/50], Step [42/735], Loss: 0.1361\n",
      "Epoch [23/50], Step [43/735], Loss: 0.0423\n",
      "Epoch [23/50], Step [44/735], Loss: 0.0452\n",
      "Epoch [23/50], Step [45/735], Loss: 0.0494\n",
      "Epoch [23/50], Step [46/735], Loss: 0.0959\n",
      "Epoch [23/50], Step [47/735], Loss: 0.0319\n",
      "Epoch [23/50], Step [48/735], Loss: 0.1808\n",
      "Epoch [23/50], Step [49/735], Loss: 0.1894\n",
      "Epoch [23/50], Step [50/735], Loss: 0.0937\n",
      "Epoch [23/50], Step [51/735], Loss: 0.0915\n",
      "Epoch [23/50], Step [52/735], Loss: 0.0592\n",
      "Epoch [23/50], Step [53/735], Loss: 0.2839\n",
      "Epoch [23/50], Step [54/735], Loss: 0.0527\n",
      "Epoch [23/50], Step [55/735], Loss: 0.0997\n",
      "Epoch [23/50], Step [56/735], Loss: 0.0294\n",
      "Epoch [23/50], Step [57/735], Loss: 0.4532\n",
      "Epoch [23/50], Step [58/735], Loss: 0.1142\n",
      "Epoch [23/50], Step [59/735], Loss: 0.2798\n",
      "Epoch [23/50], Step [60/735], Loss: 0.0535\n",
      "Epoch [23/50], Step [61/735], Loss: 0.1091\n",
      "Epoch [23/50], Step [62/735], Loss: 0.2051\n",
      "Epoch [23/50], Step [63/735], Loss: 0.1424\n",
      "Epoch [23/50], Step [64/735], Loss: 0.0159\n",
      "Epoch [23/50], Step [65/735], Loss: 0.0960\n",
      "Epoch [23/50], Step [66/735], Loss: 0.0814\n",
      "Epoch [23/50], Step [67/735], Loss: 0.2346\n",
      "Epoch [23/50], Step [68/735], Loss: 0.0219\n",
      "Epoch [23/50], Step [69/735], Loss: 0.0733\n",
      "Epoch [23/50], Step [70/735], Loss: 0.2224\n",
      "Epoch [23/50], Step [71/735], Loss: 0.1041\n",
      "Epoch [23/50], Step [72/735], Loss: 0.0590\n",
      "Epoch [23/50], Step [73/735], Loss: 0.1124\n",
      "Epoch [23/50], Step [74/735], Loss: 0.0446\n",
      "Epoch [23/50], Step [75/735], Loss: 0.0870\n",
      "Epoch [23/50], Step [76/735], Loss: 0.0713\n",
      "Epoch [23/50], Step [77/735], Loss: 0.1681\n",
      "Epoch [23/50], Step [78/735], Loss: 0.0335\n",
      "Epoch [23/50], Step [79/735], Loss: 0.1908\n",
      "Epoch [23/50], Step [80/735], Loss: 0.0841\n",
      "Epoch [23/50], Step [81/735], Loss: 0.1038\n",
      "Epoch [23/50], Step [82/735], Loss: 0.0471\n",
      "Epoch [23/50], Step [83/735], Loss: 0.1131\n",
      "Epoch [23/50], Step [84/735], Loss: 0.0470\n",
      "Epoch [23/50], Step [85/735], Loss: 0.0127\n",
      "Epoch [23/50], Step [86/735], Loss: 0.0659\n",
      "Epoch [23/50], Step [87/735], Loss: 0.0437\n",
      "Epoch [23/50], Step [88/735], Loss: 0.1854\n",
      "Epoch [23/50], Step [89/735], Loss: 0.0638\n",
      "Epoch [23/50], Step [90/735], Loss: 0.0647\n",
      "Epoch [23/50], Step [91/735], Loss: 0.0385\n",
      "Epoch [23/50], Step [92/735], Loss: 0.0508\n",
      "Epoch [23/50], Step [93/735], Loss: 0.0336\n",
      "Epoch [23/50], Step [94/735], Loss: 0.1021\n",
      "Epoch [23/50], Step [95/735], Loss: 0.0704\n",
      "Epoch [23/50], Step [96/735], Loss: 0.0610\n",
      "Epoch [23/50], Step [97/735], Loss: 0.0548\n",
      "Epoch [23/50], Step [98/735], Loss: 0.0342\n",
      "Epoch [23/50], Step [99/735], Loss: 0.1112\n",
      "Epoch [23/50], Step [100/735], Loss: 0.0238\n",
      "Epoch [23/50], Step [101/735], Loss: 0.0442\n",
      "Epoch [23/50], Step [102/735], Loss: 0.0650\n",
      "Epoch [23/50], Step [103/735], Loss: 0.0602\n",
      "Epoch [23/50], Step [104/735], Loss: 0.0476\n",
      "Epoch [23/50], Step [105/735], Loss: 0.2426\n",
      "Epoch [23/50], Step [106/735], Loss: 0.1978\n",
      "Epoch [23/50], Step [107/735], Loss: 0.0599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Step [108/735], Loss: 0.0479\n",
      "Epoch [23/50], Step [109/735], Loss: 0.1421\n",
      "Epoch [23/50], Step [110/735], Loss: 0.0482\n",
      "Epoch [23/50], Step [111/735], Loss: 0.0784\n",
      "Epoch [23/50], Step [112/735], Loss: 0.0451\n",
      "Epoch [23/50], Step [113/735], Loss: 0.0631\n",
      "Epoch [23/50], Step [114/735], Loss: 0.0450\n",
      "Epoch [23/50], Step [115/735], Loss: 0.0316\n",
      "Epoch [23/50], Step [116/735], Loss: 0.1955\n",
      "Epoch [23/50], Step [117/735], Loss: 0.1064\n",
      "Epoch [23/50], Step [118/735], Loss: 0.0694\n",
      "Epoch [23/50], Step [119/735], Loss: 0.2650\n",
      "Epoch [23/50], Step [120/735], Loss: 0.0255\n",
      "Epoch [23/50], Step [121/735], Loss: 0.0312\n",
      "Epoch [23/50], Step [122/735], Loss: 0.1319\n",
      "Epoch [23/50], Step [123/735], Loss: 0.0228\n",
      "Epoch [23/50], Step [124/735], Loss: 0.0839\n",
      "Epoch [23/50], Step [125/735], Loss: 0.0405\n",
      "Epoch [23/50], Step [126/735], Loss: 0.0372\n",
      "Epoch [23/50], Step [127/735], Loss: 0.0529\n",
      "Epoch [23/50], Step [128/735], Loss: 0.0592\n",
      "Epoch [23/50], Step [129/735], Loss: 0.0320\n",
      "Epoch [23/50], Step [130/735], Loss: 0.0800\n",
      "Epoch [23/50], Step [131/735], Loss: 0.0301\n",
      "Epoch [23/50], Step [132/735], Loss: 0.0401\n",
      "Epoch [23/50], Step [133/735], Loss: 0.1943\n",
      "Epoch [23/50], Step [134/735], Loss: 0.0459\n",
      "Epoch [23/50], Step [135/735], Loss: 0.0629\n",
      "Epoch [23/50], Step [136/735], Loss: 0.0791\n",
      "Epoch [23/50], Step [137/735], Loss: 0.0314\n",
      "Epoch [23/50], Step [138/735], Loss: 0.0259\n",
      "Epoch [23/50], Step [139/735], Loss: 0.0667\n",
      "Epoch [23/50], Step [140/735], Loss: 0.1901\n",
      "Epoch [23/50], Step [141/735], Loss: 0.1414\n",
      "Epoch [23/50], Step [142/735], Loss: 0.0518\n",
      "Epoch [23/50], Step [143/735], Loss: 0.0604\n",
      "Epoch [23/50], Step [144/735], Loss: 0.0333\n",
      "Epoch [23/50], Step [145/735], Loss: 0.0208\n",
      "Epoch [23/50], Step [146/735], Loss: 0.1011\n",
      "Epoch [23/50], Step [147/735], Loss: 0.0371\n",
      "Epoch [23/50], Step [148/735], Loss: 0.0335\n",
      "Epoch [23/50], Step [149/735], Loss: 0.2117\n",
      "Epoch [23/50], Step [150/735], Loss: 0.0943\n",
      "Epoch [23/50], Step [151/735], Loss: 0.1518\n",
      "Epoch [23/50], Step [152/735], Loss: 0.1133\n",
      "Epoch [23/50], Step [153/735], Loss: 0.1345\n",
      "Epoch [23/50], Step [154/735], Loss: 0.0702\n",
      "Epoch [23/50], Step [155/735], Loss: 0.0811\n",
      "Epoch [23/50], Step [156/735], Loss: 0.0349\n",
      "Epoch [23/50], Step [157/735], Loss: 0.3856\n",
      "Epoch [23/50], Step [158/735], Loss: 0.0499\n",
      "Epoch [23/50], Step [159/735], Loss: 0.0417\n",
      "Epoch [23/50], Step [160/735], Loss: 0.1134\n",
      "Epoch [23/50], Step [161/735], Loss: 0.0131\n",
      "Epoch [23/50], Step [162/735], Loss: 0.4179\n",
      "Epoch [23/50], Step [163/735], Loss: 0.0265\n",
      "Epoch [23/50], Step [164/735], Loss: 0.0815\n",
      "Epoch [23/50], Step [165/735], Loss: 0.0275\n",
      "Epoch [23/50], Step [166/735], Loss: 0.0380\n",
      "Epoch [23/50], Step [167/735], Loss: 0.2395\n",
      "Epoch [23/50], Step [168/735], Loss: 0.0172\n",
      "Epoch [23/50], Step [169/735], Loss: 0.0768\n",
      "Epoch [23/50], Step [170/735], Loss: 0.1069\n",
      "Epoch [23/50], Step [171/735], Loss: 0.0584\n",
      "Epoch [23/50], Step [172/735], Loss: 0.1108\n",
      "Epoch [23/50], Step [173/735], Loss: 0.0822\n",
      "Epoch [23/50], Step [174/735], Loss: 0.0535\n",
      "Epoch [23/50], Step [175/735], Loss: 0.3619\n",
      "Epoch [23/50], Step [176/735], Loss: 0.1086\n",
      "Epoch [23/50], Step [177/735], Loss: 0.0651\n",
      "Epoch [23/50], Step [178/735], Loss: 0.0533\n",
      "Epoch [23/50], Step [179/735], Loss: 0.1373\n",
      "Epoch [23/50], Step [180/735], Loss: 0.1639\n",
      "Epoch [23/50], Step [181/735], Loss: 0.0542\n",
      "Epoch [23/50], Step [182/735], Loss: 0.0289\n",
      "Epoch [23/50], Step [183/735], Loss: 0.1861\n",
      "Epoch [23/50], Step [184/735], Loss: 0.0751\n",
      "Epoch [23/50], Step [185/735], Loss: 0.1082\n",
      "Epoch [23/50], Step [186/735], Loss: 0.1311\n",
      "Epoch [23/50], Step [187/735], Loss: 0.3153\n",
      "Epoch [23/50], Step [188/735], Loss: 0.0752\n",
      "Epoch [23/50], Step [189/735], Loss: 0.0550\n",
      "Epoch [23/50], Step [190/735], Loss: 0.0355\n",
      "Epoch [23/50], Step [191/735], Loss: 0.1307\n",
      "Epoch [23/50], Step [192/735], Loss: 0.0301\n",
      "Epoch [23/50], Step [193/735], Loss: 0.3959\n",
      "Epoch [23/50], Step [194/735], Loss: 0.1871\n",
      "Epoch [23/50], Step [195/735], Loss: 0.0254\n",
      "Epoch [23/50], Step [196/735], Loss: 0.0347\n",
      "Epoch [23/50], Step [197/735], Loss: 0.2275\n",
      "Epoch [23/50], Step [198/735], Loss: 0.1433\n",
      "Epoch [23/50], Step [199/735], Loss: 0.0650\n",
      "Epoch [23/50], Step [200/735], Loss: 0.0390\n",
      "Epoch [23/50], Step [201/735], Loss: 0.0266\n",
      "Epoch [23/50], Step [202/735], Loss: 0.1231\n",
      "Epoch [23/50], Step [203/735], Loss: 0.0606\n",
      "Epoch [23/50], Step [204/735], Loss: 0.0319\n",
      "Epoch [23/50], Step [205/735], Loss: 0.0565\n",
      "Epoch [23/50], Step [206/735], Loss: 0.0636\n",
      "Epoch [23/50], Step [207/735], Loss: 0.1655\n",
      "Epoch [23/50], Step [208/735], Loss: 0.0187\n",
      "Epoch [23/50], Step [209/735], Loss: 0.0473\n",
      "Epoch [23/50], Step [210/735], Loss: 0.0844\n",
      "Epoch [23/50], Step [211/735], Loss: 0.0461\n",
      "Epoch [23/50], Step [212/735], Loss: 0.0563\n",
      "Epoch [23/50], Step [213/735], Loss: 0.0824\n",
      "Epoch [23/50], Step [214/735], Loss: 0.0491\n",
      "Epoch [23/50], Step [215/735], Loss: 0.0294\n",
      "Epoch [23/50], Step [216/735], Loss: 0.0733\n",
      "Epoch [23/50], Step [217/735], Loss: 0.0270\n",
      "Epoch [23/50], Step [218/735], Loss: 0.0227\n",
      "Epoch [23/50], Step [219/735], Loss: 0.0423\n",
      "Epoch [23/50], Step [220/735], Loss: 0.1578\n",
      "Epoch [23/50], Step [221/735], Loss: 0.1138\n",
      "Epoch [23/50], Step [222/735], Loss: 0.0357\n",
      "Epoch [23/50], Step [223/735], Loss: 0.0470\n",
      "Epoch [23/50], Step [224/735], Loss: 0.1139\n",
      "Epoch [23/50], Step [225/735], Loss: 0.0317\n",
      "Epoch [23/50], Step [226/735], Loss: 0.0537\n",
      "Epoch [23/50], Step [227/735], Loss: 0.0211\n",
      "Epoch [23/50], Step [228/735], Loss: 0.0364\n",
      "Epoch [23/50], Step [229/735], Loss: 0.2452\n",
      "Epoch [23/50], Step [230/735], Loss: 0.0754\n",
      "Epoch [23/50], Step [231/735], Loss: 0.0582\n",
      "Epoch [23/50], Step [232/735], Loss: 0.0467\n",
      "Epoch [23/50], Step [233/735], Loss: 0.1865\n",
      "Epoch [23/50], Step [234/735], Loss: 0.1582\n",
      "Epoch [23/50], Step [235/735], Loss: 0.0696\n",
      "Epoch [23/50], Step [236/735], Loss: 0.1689\n",
      "Epoch [23/50], Step [237/735], Loss: 0.0522\n",
      "Epoch [23/50], Step [238/735], Loss: 0.0357\n",
      "Epoch [23/50], Step [239/735], Loss: 0.0475\n",
      "Epoch [23/50], Step [240/735], Loss: 0.0373\n",
      "Epoch [23/50], Step [241/735], Loss: 0.0999\n",
      "Epoch [23/50], Step [242/735], Loss: 0.1223\n",
      "Epoch [23/50], Step [243/735], Loss: 0.0235\n",
      "Epoch [23/50], Step [244/735], Loss: 0.0372\n",
      "Epoch [23/50], Step [245/735], Loss: 0.0451\n",
      "Epoch [23/50], Step [246/735], Loss: 0.0412\n",
      "Epoch [23/50], Step [247/735], Loss: 0.0323\n",
      "Epoch [23/50], Step [248/735], Loss: 0.0175\n",
      "Epoch [23/50], Step [249/735], Loss: 0.0382\n",
      "Epoch [23/50], Step [250/735], Loss: 0.0133\n",
      "Epoch [23/50], Step [251/735], Loss: 0.2623\n",
      "Epoch [23/50], Step [252/735], Loss: 0.0316\n",
      "Epoch [23/50], Step [253/735], Loss: 0.0204\n",
      "Epoch [23/50], Step [254/735], Loss: 0.0498\n",
      "Epoch [23/50], Step [255/735], Loss: 0.0941\n",
      "Epoch [23/50], Step [256/735], Loss: 0.1906\n",
      "Epoch [23/50], Step [257/735], Loss: 0.0393\n",
      "Epoch [23/50], Step [258/735], Loss: 0.1082\n",
      "Epoch [23/50], Step [259/735], Loss: 0.0947\n",
      "Epoch [23/50], Step [260/735], Loss: 0.0467\n",
      "Epoch [23/50], Step [261/735], Loss: 0.0297\n",
      "Epoch [23/50], Step [262/735], Loss: 0.0554\n",
      "Epoch [23/50], Step [263/735], Loss: 0.0265\n",
      "Epoch [23/50], Step [264/735], Loss: 0.1195\n",
      "Epoch [23/50], Step [265/735], Loss: 0.2972\n",
      "Epoch [23/50], Step [266/735], Loss: 0.1661\n",
      "Epoch [23/50], Step [267/735], Loss: 0.0469\n",
      "Epoch [23/50], Step [268/735], Loss: 0.0540\n",
      "Epoch [23/50], Step [269/735], Loss: 0.0466\n",
      "Epoch [23/50], Step [270/735], Loss: 0.0706\n",
      "Epoch [23/50], Step [271/735], Loss: 0.0924\n",
      "Epoch [23/50], Step [272/735], Loss: 0.0426\n",
      "Epoch [23/50], Step [273/735], Loss: 0.0341\n",
      "Epoch [23/50], Step [274/735], Loss: 0.0415\n",
      "Epoch [23/50], Step [275/735], Loss: 0.0597\n",
      "Epoch [23/50], Step [276/735], Loss: 0.0941\n",
      "Epoch [23/50], Step [277/735], Loss: 0.0344\n",
      "Epoch [23/50], Step [278/735], Loss: 0.0327\n",
      "Epoch [23/50], Step [279/735], Loss: 0.0395\n",
      "Epoch [23/50], Step [280/735], Loss: 0.1247\n",
      "Epoch [23/50], Step [281/735], Loss: 0.0668\n",
      "Epoch [23/50], Step [282/735], Loss: 0.0227\n",
      "Epoch [23/50], Step [283/735], Loss: 0.5976\n",
      "Epoch [23/50], Step [284/735], Loss: 0.0980\n",
      "Epoch [23/50], Step [285/735], Loss: 0.0352\n",
      "Epoch [23/50], Step [286/735], Loss: 0.0867\n",
      "Epoch [23/50], Step [287/735], Loss: 0.1496\n",
      "Epoch [23/50], Step [288/735], Loss: 0.0394\n",
      "Epoch [23/50], Step [289/735], Loss: 0.0348\n",
      "Epoch [23/50], Step [290/735], Loss: 0.1023\n",
      "Epoch [23/50], Step [291/735], Loss: 0.1422\n",
      "Epoch [23/50], Step [292/735], Loss: 0.0947\n",
      "Epoch [23/50], Step [293/735], Loss: 0.0357\n",
      "Epoch [23/50], Step [294/735], Loss: 0.0431\n",
      "Epoch [23/50], Step [295/735], Loss: 0.2238\n",
      "Epoch [23/50], Step [296/735], Loss: 0.0250\n",
      "Epoch [23/50], Step [297/735], Loss: 0.0460\n",
      "Epoch [23/50], Step [298/735], Loss: 0.0573\n",
      "Epoch [23/50], Step [299/735], Loss: 0.5801\n",
      "Epoch [23/50], Step [300/735], Loss: 0.1284\n",
      "Epoch [23/50], Step [301/735], Loss: 0.0700\n",
      "Epoch [23/50], Step [302/735], Loss: 0.1103\n",
      "Epoch [23/50], Step [303/735], Loss: 0.2566\n",
      "Epoch [23/50], Step [304/735], Loss: 0.1344\n",
      "Epoch [23/50], Step [305/735], Loss: 0.0466\n",
      "Epoch [23/50], Step [306/735], Loss: 0.0561\n",
      "Epoch [23/50], Step [307/735], Loss: 0.0166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Step [308/735], Loss: 0.1571\n",
      "Epoch [23/50], Step [309/735], Loss: 0.0382\n",
      "Epoch [23/50], Step [310/735], Loss: 0.0747\n",
      "Epoch [23/50], Step [311/735], Loss: 0.0924\n",
      "Epoch [23/50], Step [312/735], Loss: 0.1202\n",
      "Epoch [23/50], Step [313/735], Loss: 0.0433\n",
      "Epoch [23/50], Step [314/735], Loss: 0.1013\n",
      "Epoch [23/50], Step [315/735], Loss: 0.0913\n",
      "Epoch [23/50], Step [316/735], Loss: 0.0400\n",
      "Epoch [23/50], Step [317/735], Loss: 0.1635\n",
      "Epoch [23/50], Step [318/735], Loss: 0.0365\n",
      "Epoch [23/50], Step [319/735], Loss: 0.0225\n",
      "Epoch [23/50], Step [320/735], Loss: 0.0658\n",
      "Epoch [23/50], Step [321/735], Loss: 0.0825\n",
      "Epoch [23/50], Step [322/735], Loss: 0.1097\n",
      "Epoch [23/50], Step [323/735], Loss: 0.0507\n",
      "Epoch [23/50], Step [324/735], Loss: 0.0992\n",
      "Epoch [23/50], Step [325/735], Loss: 0.0648\n",
      "Epoch [23/50], Step [326/735], Loss: 0.0634\n",
      "Epoch [23/50], Step [327/735], Loss: 0.0248\n",
      "Epoch [23/50], Step [328/735], Loss: 0.0486\n",
      "Epoch [23/50], Step [329/735], Loss: 0.0275\n",
      "Epoch [23/50], Step [330/735], Loss: 0.1257\n",
      "Epoch [23/50], Step [331/735], Loss: 0.0661\n",
      "Epoch [23/50], Step [332/735], Loss: 0.0639\n",
      "Epoch [23/50], Step [333/735], Loss: 0.0640\n",
      "Epoch [23/50], Step [334/735], Loss: 0.1218\n",
      "Epoch [23/50], Step [335/735], Loss: 0.1766\n",
      "Epoch [23/50], Step [336/735], Loss: 0.1555\n",
      "Epoch [23/50], Step [337/735], Loss: 0.0392\n",
      "Epoch [23/50], Step [338/735], Loss: 0.1298\n",
      "Epoch [23/50], Step [339/735], Loss: 0.0760\n",
      "Epoch [23/50], Step [340/735], Loss: 0.0302\n",
      "Epoch [23/50], Step [341/735], Loss: 0.0663\n",
      "Epoch [23/50], Step [342/735], Loss: 0.0362\n",
      "Epoch [23/50], Step [343/735], Loss: 0.1021\n",
      "Epoch [23/50], Step [344/735], Loss: 0.0763\n",
      "Epoch [23/50], Step [345/735], Loss: 0.0256\n",
      "Epoch [23/50], Step [346/735], Loss: 0.0436\n",
      "Epoch [23/50], Step [347/735], Loss: 0.0806\n",
      "Epoch [23/50], Step [348/735], Loss: 0.0732\n",
      "Epoch [23/50], Step [349/735], Loss: 0.0350\n",
      "Epoch [23/50], Step [350/735], Loss: 0.2226\n",
      "Epoch [23/50], Step [351/735], Loss: 0.0625\n",
      "Epoch [23/50], Step [352/735], Loss: 0.0213\n",
      "Epoch [23/50], Step [353/735], Loss: 0.0345\n",
      "Epoch [23/50], Step [354/735], Loss: 0.0504\n",
      "Epoch [23/50], Step [355/735], Loss: 0.1624\n",
      "Epoch [23/50], Step [356/735], Loss: 0.1647\n",
      "Epoch [23/50], Step [357/735], Loss: 0.0590\n",
      "Epoch [23/50], Step [358/735], Loss: 0.0282\n",
      "Epoch [23/50], Step [359/735], Loss: 0.0257\n",
      "Epoch [23/50], Step [360/735], Loss: 0.0369\n",
      "Epoch [23/50], Step [361/735], Loss: 0.0498\n",
      "Epoch [23/50], Step [362/735], Loss: 0.2683\n",
      "Epoch [23/50], Step [363/735], Loss: 0.0585\n",
      "Epoch [23/50], Step [364/735], Loss: 0.1148\n",
      "Epoch [23/50], Step [365/735], Loss: 0.0471\n",
      "Epoch [23/50], Step [366/735], Loss: 0.0564\n",
      "Epoch [23/50], Step [367/735], Loss: 0.0493\n",
      "Epoch [23/50], Step [368/735], Loss: 0.0196\n",
      "Epoch [23/50], Step [369/735], Loss: 0.0544\n",
      "Epoch [23/50], Step [370/735], Loss: 0.1017\n",
      "Epoch [23/50], Step [371/735], Loss: 0.0352\n",
      "Epoch [23/50], Step [372/735], Loss: 0.0372\n",
      "Epoch [23/50], Step [373/735], Loss: 0.1388\n",
      "Epoch [23/50], Step [374/735], Loss: 0.0532\n",
      "Epoch [23/50], Step [375/735], Loss: 0.0284\n",
      "Epoch [23/50], Step [376/735], Loss: 0.0723\n",
      "Epoch [23/50], Step [377/735], Loss: 0.0422\n",
      "Epoch [23/50], Step [378/735], Loss: 0.1928\n",
      "Epoch [23/50], Step [379/735], Loss: 0.1198\n",
      "Epoch [23/50], Step [380/735], Loss: 0.0365\n",
      "Epoch [23/50], Step [381/735], Loss: 0.0880\n",
      "Epoch [23/50], Step [382/735], Loss: 0.1453\n",
      "Epoch [23/50], Step [383/735], Loss: 0.0552\n",
      "Epoch [23/50], Step [384/735], Loss: 0.0794\n",
      "Epoch [23/50], Step [385/735], Loss: 0.0707\n",
      "Epoch [23/50], Step [386/735], Loss: 0.0869\n",
      "Epoch [23/50], Step [387/735], Loss: 0.0509\n",
      "Epoch [23/50], Step [388/735], Loss: 0.1466\n",
      "Epoch [23/50], Step [389/735], Loss: 0.1651\n",
      "Epoch [23/50], Step [390/735], Loss: 0.0703\n",
      "Epoch [23/50], Step [391/735], Loss: 0.1656\n",
      "Epoch [23/50], Step [392/735], Loss: 0.1376\n",
      "Epoch [23/50], Step [393/735], Loss: 0.0453\n",
      "Epoch [23/50], Step [394/735], Loss: 0.0954\n",
      "Epoch [23/50], Step [395/735], Loss: 0.0581\n",
      "Epoch [23/50], Step [396/735], Loss: 0.0326\n",
      "Epoch [23/50], Step [397/735], Loss: 0.0400\n",
      "Epoch [23/50], Step [398/735], Loss: 0.0554\n",
      "Epoch [23/50], Step [399/735], Loss: 0.1197\n",
      "Epoch [23/50], Step [400/735], Loss: 0.0496\n",
      "Epoch [23/50], Step [401/735], Loss: 0.0533\n",
      "Epoch [23/50], Step [402/735], Loss: 0.1333\n",
      "Epoch [23/50], Step [403/735], Loss: 0.0500\n",
      "Epoch [23/50], Step [404/735], Loss: 0.6229\n",
      "Epoch [23/50], Step [405/735], Loss: 0.0542\n",
      "Epoch [23/50], Step [406/735], Loss: 0.0460\n",
      "Epoch [23/50], Step [407/735], Loss: 0.1980\n",
      "Epoch [23/50], Step [408/735], Loss: 0.1894\n",
      "Epoch [23/50], Step [409/735], Loss: 0.0780\n",
      "Epoch [23/50], Step [410/735], Loss: 0.1368\n",
      "Epoch [23/50], Step [411/735], Loss: 0.0542\n",
      "Epoch [23/50], Step [412/735], Loss: 0.0885\n",
      "Epoch [23/50], Step [413/735], Loss: 0.0470\n",
      "Epoch [23/50], Step [414/735], Loss: 0.0633\n",
      "Epoch [23/50], Step [415/735], Loss: 0.0406\n",
      "Epoch [23/50], Step [416/735], Loss: 0.0418\n",
      "Epoch [23/50], Step [417/735], Loss: 0.0396\n",
      "Epoch [23/50], Step [418/735], Loss: 0.0347\n",
      "Epoch [23/50], Step [419/735], Loss: 0.0806\n",
      "Epoch [23/50], Step [420/735], Loss: 0.1348\n",
      "Epoch [23/50], Step [421/735], Loss: 0.0890\n",
      "Epoch [23/50], Step [422/735], Loss: 0.0945\n",
      "Epoch [23/50], Step [423/735], Loss: 0.0439\n",
      "Epoch [23/50], Step [424/735], Loss: 0.0301\n",
      "Epoch [23/50], Step [425/735], Loss: 0.0883\n",
      "Epoch [23/50], Step [426/735], Loss: 0.0307\n",
      "Epoch [23/50], Step [427/735], Loss: 0.0495\n",
      "Epoch [23/50], Step [428/735], Loss: 0.0548\n",
      "Epoch [23/50], Step [429/735], Loss: 0.0277\n",
      "Epoch [23/50], Step [430/735], Loss: 0.1380\n",
      "Epoch [23/50], Step [431/735], Loss: 0.0457\n",
      "Epoch [23/50], Step [432/735], Loss: 0.0446\n",
      "Epoch [23/50], Step [433/735], Loss: 0.0822\n",
      "Epoch [23/50], Step [434/735], Loss: 0.1647\n",
      "Epoch [23/50], Step [435/735], Loss: 0.0374\n",
      "Epoch [23/50], Step [436/735], Loss: 0.0337\n",
      "Epoch [23/50], Step [437/735], Loss: 0.0391\n",
      "Epoch [23/50], Step [438/735], Loss: 0.0553\n",
      "Epoch [23/50], Step [439/735], Loss: 0.0538\n",
      "Epoch [23/50], Step [440/735], Loss: 0.0379\n",
      "Epoch [23/50], Step [441/735], Loss: 0.0417\n",
      "Epoch [23/50], Step [442/735], Loss: 0.0823\n",
      "Epoch [23/50], Step [443/735], Loss: 0.2320\n",
      "Epoch [23/50], Step [444/735], Loss: 0.0754\n",
      "Epoch [23/50], Step [445/735], Loss: 0.0637\n",
      "Epoch [23/50], Step [446/735], Loss: 0.1221\n",
      "Epoch [23/50], Step [447/735], Loss: 0.0341\n",
      "Epoch [23/50], Step [448/735], Loss: 0.1646\n",
      "Epoch [23/50], Step [449/735], Loss: 0.0447\n",
      "Epoch [23/50], Step [450/735], Loss: 0.0898\n",
      "Epoch [23/50], Step [451/735], Loss: 0.0478\n",
      "Epoch [23/50], Step [452/735], Loss: 0.0733\n",
      "Epoch [23/50], Step [453/735], Loss: 0.0556\n",
      "Epoch [23/50], Step [454/735], Loss: 0.0952\n",
      "Epoch [23/50], Step [455/735], Loss: 0.0511\n",
      "Epoch [23/50], Step [456/735], Loss: 0.0474\n",
      "Epoch [23/50], Step [457/735], Loss: 0.0355\n",
      "Epoch [23/50], Step [458/735], Loss: 0.0643\n",
      "Epoch [23/50], Step [459/735], Loss: 0.1571\n",
      "Epoch [23/50], Step [460/735], Loss: 0.1155\n",
      "Epoch [23/50], Step [461/735], Loss: 0.1160\n",
      "Epoch [23/50], Step [462/735], Loss: 0.0160\n",
      "Epoch [23/50], Step [463/735], Loss: 0.0201\n",
      "Epoch [23/50], Step [464/735], Loss: 0.1577\n",
      "Epoch [23/50], Step [465/735], Loss: 0.0234\n",
      "Epoch [23/50], Step [466/735], Loss: 0.0548\n",
      "Epoch [23/50], Step [467/735], Loss: 0.0481\n",
      "Epoch [23/50], Step [468/735], Loss: 0.5993\n",
      "Epoch [23/50], Step [469/735], Loss: 0.2225\n",
      "Epoch [23/50], Step [470/735], Loss: 0.1157\n",
      "Epoch [23/50], Step [471/735], Loss: 0.0367\n",
      "Epoch [23/50], Step [472/735], Loss: 0.0371\n",
      "Epoch [23/50], Step [473/735], Loss: 0.0554\n",
      "Epoch [23/50], Step [474/735], Loss: 0.0337\n",
      "Epoch [23/50], Step [475/735], Loss: 0.0821\n",
      "Epoch [23/50], Step [476/735], Loss: 0.0375\n",
      "Epoch [23/50], Step [477/735], Loss: 0.0400\n",
      "Epoch [23/50], Step [478/735], Loss: 0.2539\n",
      "Epoch [23/50], Step [479/735], Loss: 0.1875\n",
      "Epoch [23/50], Step [480/735], Loss: 0.0689\n",
      "Epoch [23/50], Step [481/735], Loss: 0.0488\n",
      "Epoch [23/50], Step [482/735], Loss: 0.0540\n",
      "Epoch [23/50], Step [483/735], Loss: 0.0777\n",
      "Epoch [23/50], Step [484/735], Loss: 0.0642\n",
      "Epoch [23/50], Step [485/735], Loss: 0.0693\n",
      "Epoch [23/50], Step [486/735], Loss: 0.1455\n",
      "Epoch [23/50], Step [487/735], Loss: 0.0514\n",
      "Epoch [23/50], Step [488/735], Loss: 0.0298\n",
      "Epoch [23/50], Step [489/735], Loss: 0.0283\n",
      "Epoch [23/50], Step [490/735], Loss: 0.0465\n",
      "Epoch [23/50], Step [491/735], Loss: 0.0565\n",
      "Epoch [23/50], Step [492/735], Loss: 0.0500\n",
      "Epoch [23/50], Step [493/735], Loss: 0.0751\n",
      "Epoch [23/50], Step [494/735], Loss: 0.0541\n",
      "Epoch [23/50], Step [495/735], Loss: 0.0708\n",
      "Epoch [23/50], Step [496/735], Loss: 0.1555\n",
      "Epoch [23/50], Step [497/735], Loss: 0.0882\n",
      "Epoch [23/50], Step [498/735], Loss: 0.0503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Step [499/735], Loss: 0.0654\n",
      "Epoch [23/50], Step [500/735], Loss: 0.0266\n",
      "Epoch [23/50], Step [501/735], Loss: 0.0528\n",
      "Epoch [23/50], Step [502/735], Loss: 0.0563\n",
      "Epoch [23/50], Step [503/735], Loss: 0.0218\n",
      "Epoch [23/50], Step [504/735], Loss: 0.0446\n",
      "Epoch [23/50], Step [505/735], Loss: 0.0299\n",
      "Epoch [23/50], Step [506/735], Loss: 0.3781\n",
      "Epoch [23/50], Step [507/735], Loss: 0.3041\n",
      "Epoch [23/50], Step [508/735], Loss: 0.0441\n",
      "Epoch [23/50], Step [509/735], Loss: 0.0720\n",
      "Epoch [23/50], Step [510/735], Loss: 0.0431\n",
      "Epoch [23/50], Step [511/735], Loss: 0.0481\n",
      "Epoch [23/50], Step [512/735], Loss: 0.0501\n",
      "Epoch [23/50], Step [513/735], Loss: 0.0494\n",
      "Epoch [23/50], Step [514/735], Loss: 0.0210\n",
      "Epoch [23/50], Step [515/735], Loss: 0.0695\n",
      "Epoch [23/50], Step [516/735], Loss: 0.0710\n",
      "Epoch [23/50], Step [517/735], Loss: 0.0295\n",
      "Epoch [23/50], Step [518/735], Loss: 0.0715\n",
      "Epoch [23/50], Step [519/735], Loss: 0.0441\n",
      "Epoch [23/50], Step [520/735], Loss: 0.0356\n",
      "Epoch [23/50], Step [521/735], Loss: 0.0219\n",
      "Epoch [23/50], Step [522/735], Loss: 0.0618\n",
      "Epoch [23/50], Step [523/735], Loss: 0.0426\n",
      "Epoch [23/50], Step [524/735], Loss: 0.0319\n",
      "Epoch [23/50], Step [525/735], Loss: 0.0390\n",
      "Epoch [23/50], Step [526/735], Loss: 0.1088\n",
      "Epoch [23/50], Step [527/735], Loss: 0.0645\n",
      "Epoch [23/50], Step [528/735], Loss: 0.0463\n",
      "Epoch [23/50], Step [529/735], Loss: 0.0722\n",
      "Epoch [23/50], Step [530/735], Loss: 0.1733\n",
      "Epoch [23/50], Step [531/735], Loss: 0.0942\n",
      "Epoch [23/50], Step [532/735], Loss: 0.2329\n",
      "Epoch [23/50], Step [533/735], Loss: 0.0348\n",
      "Epoch [23/50], Step [534/735], Loss: 0.0593\n",
      "Epoch [23/50], Step [535/735], Loss: 0.1156\n",
      "Epoch [23/50], Step [536/735], Loss: 0.0772\n",
      "Epoch [23/50], Step [537/735], Loss: 0.0570\n",
      "Epoch [23/50], Step [538/735], Loss: 0.0450\n",
      "Epoch [23/50], Step [539/735], Loss: 0.0237\n",
      "Epoch [23/50], Step [540/735], Loss: 0.0731\n",
      "Epoch [23/50], Step [541/735], Loss: 0.0448\n",
      "Epoch [23/50], Step [542/735], Loss: 0.1077\n",
      "Epoch [23/50], Step [543/735], Loss: 0.0647\n",
      "Epoch [23/50], Step [544/735], Loss: 0.0963\n",
      "Epoch [23/50], Step [545/735], Loss: 0.0578\n",
      "Epoch [23/50], Step [546/735], Loss: 0.0514\n",
      "Epoch [23/50], Step [547/735], Loss: 0.0834\n",
      "Epoch [23/50], Step [548/735], Loss: 0.0389\n",
      "Epoch [23/50], Step [549/735], Loss: 0.1515\n",
      "Epoch [23/50], Step [550/735], Loss: 0.1847\n",
      "Epoch [23/50], Step [551/735], Loss: 0.0722\n",
      "Epoch [23/50], Step [552/735], Loss: 0.0619\n",
      "Epoch [23/50], Step [553/735], Loss: 0.0765\n",
      "Epoch [23/50], Step [554/735], Loss: 0.0633\n",
      "Epoch [23/50], Step [555/735], Loss: 0.0910\n",
      "Epoch [23/50], Step [556/735], Loss: 0.0530\n",
      "Epoch [23/50], Step [557/735], Loss: 0.0528\n",
      "Epoch [23/50], Step [558/735], Loss: 0.0375\n",
      "Epoch [23/50], Step [559/735], Loss: 0.0635\n",
      "Epoch [23/50], Step [560/735], Loss: 0.0309\n",
      "Epoch [23/50], Step [561/735], Loss: 0.0811\n",
      "Epoch [23/50], Step [562/735], Loss: 0.0814\n",
      "Epoch [23/50], Step [563/735], Loss: 0.2180\n",
      "Epoch [23/50], Step [564/735], Loss: 0.0562\n",
      "Epoch [23/50], Step [565/735], Loss: 0.0419\n",
      "Epoch [23/50], Step [566/735], Loss: 0.1782\n",
      "Epoch [23/50], Step [567/735], Loss: 0.0678\n",
      "Epoch [23/50], Step [568/735], Loss: 0.1720\n",
      "Epoch [23/50], Step [569/735], Loss: 0.0853\n",
      "Epoch [23/50], Step [570/735], Loss: 0.0678\n",
      "Epoch [23/50], Step [571/735], Loss: 0.0292\n",
      "Epoch [23/50], Step [572/735], Loss: 0.1892\n",
      "Epoch [23/50], Step [573/735], Loss: 0.2043\n",
      "Epoch [23/50], Step [574/735], Loss: 0.0412\n",
      "Epoch [23/50], Step [575/735], Loss: 0.0668\n",
      "Epoch [23/50], Step [576/735], Loss: 0.0656\n",
      "Epoch [23/50], Step [577/735], Loss: 0.0448\n",
      "Epoch [23/50], Step [578/735], Loss: 0.0701\n",
      "Epoch [23/50], Step [579/735], Loss: 0.0464\n",
      "Epoch [23/50], Step [580/735], Loss: 0.1138\n",
      "Epoch [23/50], Step [581/735], Loss: 0.0821\n",
      "Epoch [23/50], Step [582/735], Loss: 0.1369\n",
      "Epoch [23/50], Step [583/735], Loss: 0.0560\n",
      "Epoch [23/50], Step [584/735], Loss: 0.0912\n",
      "Epoch [23/50], Step [585/735], Loss: 0.1272\n",
      "Epoch [23/50], Step [586/735], Loss: 0.0360\n",
      "Epoch [23/50], Step [587/735], Loss: 0.0804\n",
      "Epoch [23/50], Step [588/735], Loss: 0.0927\n",
      "Epoch [23/50], Step [589/735], Loss: 0.0500\n",
      "Epoch [23/50], Step [590/735], Loss: 0.0500\n",
      "Epoch [23/50], Step [591/735], Loss: 0.0747\n",
      "Epoch [23/50], Step [592/735], Loss: 0.0983\n",
      "Epoch [23/50], Step [593/735], Loss: 0.0758\n",
      "Epoch [23/50], Step [594/735], Loss: 0.0289\n",
      "Epoch [23/50], Step [595/735], Loss: 0.0765\n",
      "Epoch [23/50], Step [596/735], Loss: 0.1383\n",
      "Epoch [23/50], Step [597/735], Loss: 0.0547\n",
      "Epoch [23/50], Step [598/735], Loss: 0.0384\n",
      "Epoch [23/50], Step [599/735], Loss: 0.1659\n",
      "Epoch [23/50], Step [600/735], Loss: 0.0411\n",
      "Epoch [23/50], Step [601/735], Loss: 0.0835\n",
      "Epoch [23/50], Step [602/735], Loss: 0.1693\n",
      "Epoch [23/50], Step [603/735], Loss: 0.0293\n",
      "Epoch [23/50], Step [604/735], Loss: 0.0629\n",
      "Epoch [23/50], Step [605/735], Loss: 0.0720\n",
      "Epoch [23/50], Step [606/735], Loss: 0.0466\n",
      "Epoch [23/50], Step [607/735], Loss: 0.0433\n",
      "Epoch [23/50], Step [608/735], Loss: 0.1426\n",
      "Epoch [23/50], Step [609/735], Loss: 0.0669\n",
      "Epoch [23/50], Step [610/735], Loss: 0.0734\n",
      "Epoch [23/50], Step [611/735], Loss: 0.0767\n",
      "Epoch [23/50], Step [612/735], Loss: 0.5469\n",
      "Epoch [23/50], Step [613/735], Loss: 0.0908\n",
      "Epoch [23/50], Step [614/735], Loss: 0.2686\n",
      "Epoch [23/50], Step [615/735], Loss: 0.0929\n",
      "Epoch [23/50], Step [616/735], Loss: 0.0551\n",
      "Epoch [23/50], Step [617/735], Loss: 0.1909\n",
      "Epoch [23/50], Step [618/735], Loss: 0.0345\n",
      "Epoch [23/50], Step [619/735], Loss: 0.0413\n",
      "Epoch [23/50], Step [620/735], Loss: 0.4807\n",
      "Epoch [23/50], Step [621/735], Loss: 0.1814\n",
      "Epoch [23/50], Step [622/735], Loss: 0.0931\n",
      "Epoch [23/50], Step [623/735], Loss: 0.0952\n",
      "Epoch [23/50], Step [624/735], Loss: 0.0641\n",
      "Epoch [23/50], Step [625/735], Loss: 0.2001\n",
      "Epoch [23/50], Step [626/735], Loss: 0.0383\n",
      "Epoch [23/50], Step [627/735], Loss: 0.0417\n",
      "Epoch [23/50], Step [628/735], Loss: 0.1736\n",
      "Epoch [23/50], Step [629/735], Loss: 0.0341\n",
      "Epoch [23/50], Step [630/735], Loss: 0.0740\n",
      "Epoch [23/50], Step [631/735], Loss: 0.0485\n",
      "Epoch [23/50], Step [632/735], Loss: 0.0890\n",
      "Epoch [23/50], Step [633/735], Loss: 0.1083\n",
      "Epoch [23/50], Step [634/735], Loss: 0.0309\n",
      "Epoch [23/50], Step [635/735], Loss: 0.0337\n",
      "Epoch [23/50], Step [636/735], Loss: 0.0260\n",
      "Epoch [23/50], Step [637/735], Loss: 0.0755\n",
      "Epoch [23/50], Step [638/735], Loss: 0.0431\n",
      "Epoch [23/50], Step [639/735], Loss: 0.1039\n",
      "Epoch [23/50], Step [640/735], Loss: 0.0536\n",
      "Epoch [23/50], Step [641/735], Loss: 0.0834\n",
      "Epoch [23/50], Step [642/735], Loss: 0.0868\n",
      "Epoch [23/50], Step [643/735], Loss: 0.0575\n",
      "Epoch [23/50], Step [644/735], Loss: 0.1096\n",
      "Epoch [23/50], Step [645/735], Loss: 0.0822\n",
      "Epoch [23/50], Step [646/735], Loss: 0.0446\n",
      "Epoch [23/50], Step [647/735], Loss: 0.1689\n",
      "Epoch [23/50], Step [648/735], Loss: 0.0532\n",
      "Epoch [23/50], Step [649/735], Loss: 0.0542\n",
      "Epoch [23/50], Step [650/735], Loss: 0.0493\n",
      "Epoch [23/50], Step [651/735], Loss: 0.0427\n",
      "Epoch [23/50], Step [652/735], Loss: 0.0872\n",
      "Epoch [23/50], Step [653/735], Loss: 0.5997\n",
      "Epoch [23/50], Step [654/735], Loss: 0.0336\n",
      "Epoch [23/50], Step [655/735], Loss: 0.1279\n",
      "Epoch [23/50], Step [656/735], Loss: 0.0641\n",
      "Epoch [23/50], Step [657/735], Loss: 0.0768\n",
      "Epoch [23/50], Step [658/735], Loss: 0.0480\n",
      "Epoch [23/50], Step [659/735], Loss: 0.0833\n",
      "Epoch [23/50], Step [660/735], Loss: 0.0509\n",
      "Epoch [23/50], Step [661/735], Loss: 0.0815\n",
      "Epoch [23/50], Step [662/735], Loss: 0.1091\n",
      "Epoch [23/50], Step [663/735], Loss: 0.0563\n",
      "Epoch [23/50], Step [664/735], Loss: 0.0423\n",
      "Epoch [23/50], Step [665/735], Loss: 0.0321\n",
      "Epoch [23/50], Step [666/735], Loss: 0.0732\n",
      "Epoch [23/50], Step [667/735], Loss: 0.1138\n",
      "Epoch [23/50], Step [668/735], Loss: 0.0377\n",
      "Epoch [23/50], Step [669/735], Loss: 0.0505\n",
      "Epoch [23/50], Step [670/735], Loss: 0.0975\n",
      "Epoch [23/50], Step [671/735], Loss: 0.0402\n",
      "Epoch [23/50], Step [672/735], Loss: 0.1220\n",
      "Epoch [23/50], Step [673/735], Loss: 0.0268\n",
      "Epoch [23/50], Step [674/735], Loss: 0.0645\n",
      "Epoch [23/50], Step [675/735], Loss: 0.0201\n",
      "Epoch [23/50], Step [676/735], Loss: 0.0789\n",
      "Epoch [23/50], Step [677/735], Loss: 0.1140\n",
      "Epoch [23/50], Step [678/735], Loss: 0.0910\n",
      "Epoch [23/50], Step [679/735], Loss: 0.1335\n",
      "Epoch [23/50], Step [680/735], Loss: 0.0458\n",
      "Epoch [23/50], Step [681/735], Loss: 0.0777\n",
      "Epoch [23/50], Step [682/735], Loss: 0.0330\n",
      "Epoch [23/50], Step [683/735], Loss: 0.0961\n",
      "Epoch [23/50], Step [684/735], Loss: 0.1275\n",
      "Epoch [23/50], Step [685/735], Loss: 0.0987\n",
      "Epoch [23/50], Step [686/735], Loss: 0.0728\n",
      "Epoch [23/50], Step [687/735], Loss: 0.0650\n",
      "Epoch [23/50], Step [688/735], Loss: 0.1536\n",
      "Epoch [23/50], Step [689/735], Loss: 0.0882\n",
      "Epoch [23/50], Step [690/735], Loss: 0.1032\n",
      "Epoch [23/50], Step [691/735], Loss: 0.0470\n",
      "Epoch [23/50], Step [692/735], Loss: 0.0812\n",
      "Epoch [23/50], Step [693/735], Loss: 0.0431\n",
      "Epoch [23/50], Step [694/735], Loss: 0.0330\n",
      "Epoch [23/50], Step [695/735], Loss: 0.0497\n",
      "Epoch [23/50], Step [696/735], Loss: 0.0976\n",
      "Epoch [23/50], Step [697/735], Loss: 0.0788\n",
      "Epoch [23/50], Step [698/735], Loss: 0.2330\n",
      "Epoch [23/50], Step [699/735], Loss: 0.0783\n",
      "Epoch [23/50], Step [700/735], Loss: 0.0489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Step [701/735], Loss: 0.0544\n",
      "Epoch [23/50], Step [702/735], Loss: 0.1918\n",
      "Epoch [23/50], Step [703/735], Loss: 0.0411\n",
      "Epoch [23/50], Step [704/735], Loss: 0.2489\n",
      "Epoch [23/50], Step [705/735], Loss: 0.1927\n",
      "Epoch [23/50], Step [706/735], Loss: 0.0751\n",
      "Epoch [23/50], Step [707/735], Loss: 0.0400\n",
      "Epoch [23/50], Step [708/735], Loss: 0.0428\n",
      "Epoch [23/50], Step [709/735], Loss: 0.1682\n",
      "Epoch [23/50], Step [710/735], Loss: 0.1182\n",
      "Epoch [23/50], Step [711/735], Loss: 0.0932\n",
      "Epoch [23/50], Step [712/735], Loss: 0.1339\n",
      "Epoch [23/50], Step [713/735], Loss: 0.0369\n",
      "Epoch [23/50], Step [714/735], Loss: 0.0787\n",
      "Epoch [23/50], Step [715/735], Loss: 0.1898\n",
      "Epoch [23/50], Step [716/735], Loss: 0.1528\n",
      "Epoch [23/50], Step [717/735], Loss: 0.0626\n",
      "Epoch [23/50], Step [718/735], Loss: 0.0525\n",
      "Epoch [23/50], Step [719/735], Loss: 0.1297\n",
      "Epoch [23/50], Step [720/735], Loss: 0.0727\n",
      "Epoch [23/50], Step [721/735], Loss: 0.1773\n",
      "Epoch [23/50], Step [722/735], Loss: 0.0468\n",
      "Epoch [23/50], Step [723/735], Loss: 0.0489\n",
      "Epoch [23/50], Step [724/735], Loss: 0.0551\n",
      "Epoch [23/50], Step [725/735], Loss: 0.0399\n",
      "Epoch [23/50], Step [726/735], Loss: 0.0486\n",
      "Epoch [23/50], Step [727/735], Loss: 0.0738\n",
      "Epoch [23/50], Step [728/735], Loss: 0.1632\n",
      "Epoch [23/50], Step [729/735], Loss: 0.0595\n",
      "Epoch [23/50], Step [730/735], Loss: 0.0421\n",
      "Epoch [23/50], Step [731/735], Loss: 0.0486\n",
      "Epoch [23/50], Step [732/735], Loss: 0.0316\n",
      "Epoch [23/50], Step [733/735], Loss: 0.1178\n",
      "Epoch [23/50], Step [734/735], Loss: 0.1463\n",
      "Epoch [23/50], Step [735/735], Loss: 0.0400\n",
      "Epoch [24/50], Step [1/735], Loss: 0.1213\n",
      "Epoch [24/50], Step [2/735], Loss: 0.0508\n",
      "Epoch [24/50], Step [3/735], Loss: 0.0574\n",
      "Epoch [24/50], Step [4/735], Loss: 0.1855\n",
      "Epoch [24/50], Step [5/735], Loss: 0.0461\n",
      "Epoch [24/50], Step [6/735], Loss: 0.0928\n",
      "Epoch [24/50], Step [7/735], Loss: 0.0952\n",
      "Epoch [24/50], Step [8/735], Loss: 0.0787\n",
      "Epoch [24/50], Step [9/735], Loss: 0.1934\n",
      "Epoch [24/50], Step [10/735], Loss: 0.0373\n",
      "Epoch [24/50], Step [11/735], Loss: 0.0261\n",
      "Epoch [24/50], Step [12/735], Loss: 0.0387\n",
      "Epoch [24/50], Step [13/735], Loss: 0.0429\n",
      "Epoch [24/50], Step [14/735], Loss: 0.0567\n",
      "Epoch [24/50], Step [15/735], Loss: 0.0890\n",
      "Epoch [24/50], Step [16/735], Loss: 0.0298\n",
      "Epoch [24/50], Step [17/735], Loss: 0.0961\n",
      "Epoch [24/50], Step [18/735], Loss: 0.0381\n",
      "Epoch [24/50], Step [19/735], Loss: 0.2600\n",
      "Epoch [24/50], Step [20/735], Loss: 0.0613\n",
      "Epoch [24/50], Step [21/735], Loss: 0.2720\n",
      "Epoch [24/50], Step [22/735], Loss: 0.0384\n",
      "Epoch [24/50], Step [23/735], Loss: 0.0616\n",
      "Epoch [24/50], Step [24/735], Loss: 0.0430\n",
      "Epoch [24/50], Step [25/735], Loss: 0.0488\n",
      "Epoch [24/50], Step [26/735], Loss: 0.0966\n",
      "Epoch [24/50], Step [27/735], Loss: 0.0973\n",
      "Epoch [24/50], Step [28/735], Loss: 0.3073\n",
      "Epoch [24/50], Step [29/735], Loss: 0.0432\n",
      "Epoch [24/50], Step [30/735], Loss: 0.0603\n",
      "Epoch [24/50], Step [31/735], Loss: 0.1086\n",
      "Epoch [24/50], Step [32/735], Loss: 0.0723\n",
      "Epoch [24/50], Step [33/735], Loss: 0.0791\n",
      "Epoch [24/50], Step [34/735], Loss: 0.0844\n",
      "Epoch [24/50], Step [35/735], Loss: 0.3384\n",
      "Epoch [24/50], Step [36/735], Loss: 0.0787\n",
      "Epoch [24/50], Step [37/735], Loss: 0.0844\n",
      "Epoch [24/50], Step [38/735], Loss: 0.0540\n",
      "Epoch [24/50], Step [39/735], Loss: 0.1326\n",
      "Epoch [24/50], Step [40/735], Loss: 0.0693\n",
      "Epoch [24/50], Step [41/735], Loss: 0.1228\n",
      "Epoch [24/50], Step [42/735], Loss: 0.0976\n",
      "Epoch [24/50], Step [43/735], Loss: 0.0315\n",
      "Epoch [24/50], Step [44/735], Loss: 0.0311\n",
      "Epoch [24/50], Step [45/735], Loss: 0.4941\n",
      "Epoch [24/50], Step [46/735], Loss: 0.1501\n",
      "Epoch [24/50], Step [47/735], Loss: 0.0697\n",
      "Epoch [24/50], Step [48/735], Loss: 0.0296\n",
      "Epoch [24/50], Step [49/735], Loss: 0.1036\n",
      "Epoch [24/50], Step [50/735], Loss: 0.1707\n",
      "Epoch [24/50], Step [51/735], Loss: 0.0539\n",
      "Epoch [24/50], Step [52/735], Loss: 0.0680\n",
      "Epoch [24/50], Step [53/735], Loss: 0.0957\n",
      "Epoch [24/50], Step [54/735], Loss: 0.0258\n",
      "Epoch [24/50], Step [55/735], Loss: 0.0279\n",
      "Epoch [24/50], Step [56/735], Loss: 0.0523\n",
      "Epoch [24/50], Step [57/735], Loss: 0.1132\n",
      "Epoch [24/50], Step [58/735], Loss: 0.0707\n",
      "Epoch [24/50], Step [59/735], Loss: 0.0606\n",
      "Epoch [24/50], Step [60/735], Loss: 0.0722\n",
      "Epoch [24/50], Step [61/735], Loss: 0.1935\n",
      "Epoch [24/50], Step [62/735], Loss: 0.0346\n",
      "Epoch [24/50], Step [63/735], Loss: 0.1038\n",
      "Epoch [24/50], Step [64/735], Loss: 0.1127\n",
      "Epoch [24/50], Step [65/735], Loss: 0.0576\n",
      "Epoch [24/50], Step [66/735], Loss: 0.0851\n",
      "Epoch [24/50], Step [67/735], Loss: 0.0283\n",
      "Epoch [24/50], Step [68/735], Loss: 0.0265\n",
      "Epoch [24/50], Step [69/735], Loss: 0.0583\n",
      "Epoch [24/50], Step [70/735], Loss: 0.1640\n",
      "Epoch [24/50], Step [71/735], Loss: 0.0577\n",
      "Epoch [24/50], Step [72/735], Loss: 0.0665\n",
      "Epoch [24/50], Step [73/735], Loss: 0.0425\n",
      "Epoch [24/50], Step [74/735], Loss: 0.1501\n",
      "Epoch [24/50], Step [75/735], Loss: 0.0401\n",
      "Epoch [24/50], Step [76/735], Loss: 0.1220\n",
      "Epoch [24/50], Step [77/735], Loss: 0.0164\n",
      "Epoch [24/50], Step [78/735], Loss: 0.0195\n",
      "Epoch [24/50], Step [79/735], Loss: 0.0356\n",
      "Epoch [24/50], Step [80/735], Loss: 0.1968\n",
      "Epoch [24/50], Step [81/735], Loss: 0.1858\n",
      "Epoch [24/50], Step [82/735], Loss: 0.0975\n",
      "Epoch [24/50], Step [83/735], Loss: 0.0773\n",
      "Epoch [24/50], Step [84/735], Loss: 0.0644\n",
      "Epoch [24/50], Step [85/735], Loss: 0.0288\n",
      "Epoch [24/50], Step [86/735], Loss: 0.0438\n",
      "Epoch [24/50], Step [87/735], Loss: 0.0320\n",
      "Epoch [24/50], Step [88/735], Loss: 0.0746\n",
      "Epoch [24/50], Step [89/735], Loss: 0.0246\n",
      "Epoch [24/50], Step [90/735], Loss: 0.0293\n",
      "Epoch [24/50], Step [91/735], Loss: 0.0218\n",
      "Epoch [24/50], Step [92/735], Loss: 0.0592\n",
      "Epoch [24/50], Step [93/735], Loss: 0.0230\n",
      "Epoch [24/50], Step [94/735], Loss: 0.0898\n",
      "Epoch [24/50], Step [95/735], Loss: 0.1311\n",
      "Epoch [24/50], Step [96/735], Loss: 0.0593\n",
      "Epoch [24/50], Step [97/735], Loss: 0.0512\n",
      "Epoch [24/50], Step [98/735], Loss: 0.1607\n",
      "Epoch [24/50], Step [99/735], Loss: 0.0450\n",
      "Epoch [24/50], Step [100/735], Loss: 0.0687\n",
      "Epoch [24/50], Step [101/735], Loss: 0.0234\n",
      "Epoch [24/50], Step [102/735], Loss: 0.0560\n",
      "Epoch [24/50], Step [103/735], Loss: 0.0387\n",
      "Epoch [24/50], Step [104/735], Loss: 0.0697\n",
      "Epoch [24/50], Step [105/735], Loss: 0.0344\n",
      "Epoch [24/50], Step [106/735], Loss: 0.0999\n",
      "Epoch [24/50], Step [107/735], Loss: 0.0358\n",
      "Epoch [24/50], Step [108/735], Loss: 0.0337\n",
      "Epoch [24/50], Step [109/735], Loss: 0.0424\n",
      "Epoch [24/50], Step [110/735], Loss: 0.0485\n",
      "Epoch [24/50], Step [111/735], Loss: 0.0519\n",
      "Epoch [24/50], Step [112/735], Loss: 0.0340\n",
      "Epoch [24/50], Step [113/735], Loss: 0.0251\n",
      "Epoch [24/50], Step [114/735], Loss: 0.0379\n",
      "Epoch [24/50], Step [115/735], Loss: 0.0795\n",
      "Epoch [24/50], Step [116/735], Loss: 0.0577\n",
      "Epoch [24/50], Step [117/735], Loss: 0.0378\n",
      "Epoch [24/50], Step [118/735], Loss: 0.0805\n",
      "Epoch [24/50], Step [119/735], Loss: 0.0582\n",
      "Epoch [24/50], Step [120/735], Loss: 0.0274\n",
      "Epoch [24/50], Step [121/735], Loss: 0.0320\n",
      "Epoch [24/50], Step [122/735], Loss: 0.0365\n",
      "Epoch [24/50], Step [123/735], Loss: 0.1697\n",
      "Epoch [24/50], Step [124/735], Loss: 0.0162\n",
      "Epoch [24/50], Step [125/735], Loss: 0.0724\n",
      "Epoch [24/50], Step [126/735], Loss: 0.0548\n",
      "Epoch [24/50], Step [127/735], Loss: 0.1866\n",
      "Epoch [24/50], Step [128/735], Loss: 0.1996\n",
      "Epoch [24/50], Step [129/735], Loss: 0.1058\n",
      "Epoch [24/50], Step [130/735], Loss: 0.0702\n",
      "Epoch [24/50], Step [131/735], Loss: 0.0239\n",
      "Epoch [24/50], Step [132/735], Loss: 0.0634\n",
      "Epoch [24/50], Step [133/735], Loss: 0.0521\n",
      "Epoch [24/50], Step [134/735], Loss: 0.1318\n",
      "Epoch [24/50], Step [135/735], Loss: 0.2063\n",
      "Epoch [24/50], Step [136/735], Loss: 0.0764\n",
      "Epoch [24/50], Step [137/735], Loss: 0.1159\n",
      "Epoch [24/50], Step [138/735], Loss: 0.0877\n",
      "Epoch [24/50], Step [139/735], Loss: 0.1300\n",
      "Epoch [24/50], Step [140/735], Loss: 0.0394\n",
      "Epoch [24/50], Step [141/735], Loss: 0.0951\n",
      "Epoch [24/50], Step [142/735], Loss: 0.2607\n",
      "Epoch [24/50], Step [143/735], Loss: 0.2767\n",
      "Epoch [24/50], Step [144/735], Loss: 0.4244\n",
      "Epoch [24/50], Step [145/735], Loss: 0.0547\n",
      "Epoch [24/50], Step [146/735], Loss: 0.2033\n",
      "Epoch [24/50], Step [147/735], Loss: 0.1068\n",
      "Epoch [24/50], Step [148/735], Loss: 0.0987\n",
      "Epoch [24/50], Step [149/735], Loss: 0.0527\n",
      "Epoch [24/50], Step [150/735], Loss: 0.1244\n",
      "Epoch [24/50], Step [151/735], Loss: 0.3863\n",
      "Epoch [24/50], Step [152/735], Loss: 0.0501\n",
      "Epoch [24/50], Step [153/735], Loss: 0.1619\n",
      "Epoch [24/50], Step [154/735], Loss: 0.0563\n",
      "Epoch [24/50], Step [155/735], Loss: 0.1118\n",
      "Epoch [24/50], Step [156/735], Loss: 0.0463\n",
      "Epoch [24/50], Step [157/735], Loss: 0.0442\n",
      "Epoch [24/50], Step [158/735], Loss: 0.0648\n",
      "Epoch [24/50], Step [159/735], Loss: 0.1875\n",
      "Epoch [24/50], Step [160/735], Loss: 0.0527\n",
      "Epoch [24/50], Step [161/735], Loss: 0.1703\n",
      "Epoch [24/50], Step [162/735], Loss: 0.0506\n",
      "Epoch [24/50], Step [163/735], Loss: 0.1969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Step [164/735], Loss: 0.0640\n",
      "Epoch [24/50], Step [165/735], Loss: 0.1087\n",
      "Epoch [24/50], Step [166/735], Loss: 0.0782\n",
      "Epoch [24/50], Step [167/735], Loss: 0.0560\n",
      "Epoch [24/50], Step [168/735], Loss: 0.0678\n",
      "Epoch [24/50], Step [169/735], Loss: 0.0406\n",
      "Epoch [24/50], Step [170/735], Loss: 0.0536\n",
      "Epoch [24/50], Step [171/735], Loss: 0.0633\n",
      "Epoch [24/50], Step [172/735], Loss: 0.0894\n",
      "Epoch [24/50], Step [173/735], Loss: 0.2063\n",
      "Epoch [24/50], Step [174/735], Loss: 0.0734\n",
      "Epoch [24/50], Step [175/735], Loss: 0.0684\n",
      "Epoch [24/50], Step [176/735], Loss: 0.1473\n",
      "Epoch [24/50], Step [177/735], Loss: 0.0706\n",
      "Epoch [24/50], Step [178/735], Loss: 0.0475\n",
      "Epoch [24/50], Step [179/735], Loss: 0.1116\n",
      "Epoch [24/50], Step [180/735], Loss: 0.0656\n",
      "Epoch [24/50], Step [181/735], Loss: 0.0623\n",
      "Epoch [24/50], Step [182/735], Loss: 0.5004\n",
      "Epoch [24/50], Step [183/735], Loss: 0.0844\n",
      "Epoch [24/50], Step [184/735], Loss: 0.0270\n",
      "Epoch [24/50], Step [185/735], Loss: 0.1189\n",
      "Epoch [24/50], Step [186/735], Loss: 0.0520\n",
      "Epoch [24/50], Step [187/735], Loss: 0.0482\n",
      "Epoch [24/50], Step [188/735], Loss: 0.0364\n",
      "Epoch [24/50], Step [189/735], Loss: 0.0900\n",
      "Epoch [24/50], Step [190/735], Loss: 0.1684\n",
      "Epoch [24/50], Step [191/735], Loss: 0.0236\n",
      "Epoch [24/50], Step [192/735], Loss: 0.0406\n",
      "Epoch [24/50], Step [193/735], Loss: 0.0894\n",
      "Epoch [24/50], Step [194/735], Loss: 0.0283\n",
      "Epoch [24/50], Step [195/735], Loss: 0.0995\n",
      "Epoch [24/50], Step [196/735], Loss: 0.1557\n",
      "Epoch [24/50], Step [197/735], Loss: 0.0383\n",
      "Epoch [24/50], Step [198/735], Loss: 0.0375\n",
      "Epoch [24/50], Step [199/735], Loss: 0.0218\n",
      "Epoch [24/50], Step [200/735], Loss: 0.0432\n",
      "Epoch [24/50], Step [201/735], Loss: 0.0411\n",
      "Epoch [24/50], Step [202/735], Loss: 0.0625\n",
      "Epoch [24/50], Step [203/735], Loss: 0.0557\n",
      "Epoch [24/50], Step [204/735], Loss: 0.1299\n",
      "Epoch [24/50], Step [205/735], Loss: 0.0215\n",
      "Epoch [24/50], Step [206/735], Loss: 0.0938\n",
      "Epoch [24/50], Step [207/735], Loss: 0.0422\n",
      "Epoch [24/50], Step [208/735], Loss: 0.0546\n",
      "Epoch [24/50], Step [209/735], Loss: 0.0754\n",
      "Epoch [24/50], Step [210/735], Loss: 0.0652\n",
      "Epoch [24/50], Step [211/735], Loss: 0.0518\n",
      "Epoch [24/50], Step [212/735], Loss: 0.1003\n",
      "Epoch [24/50], Step [213/735], Loss: 0.0682\n",
      "Epoch [24/50], Step [214/735], Loss: 0.0457\n",
      "Epoch [24/50], Step [215/735], Loss: 0.1386\n",
      "Epoch [24/50], Step [216/735], Loss: 0.0690\n",
      "Epoch [24/50], Step [217/735], Loss: 0.0739\n",
      "Epoch [24/50], Step [218/735], Loss: 0.0855\n",
      "Epoch [24/50], Step [219/735], Loss: 0.1467\n",
      "Epoch [24/50], Step [220/735], Loss: 0.0351\n",
      "Epoch [24/50], Step [221/735], Loss: 0.0441\n",
      "Epoch [24/50], Step [222/735], Loss: 0.1049\n",
      "Epoch [24/50], Step [223/735], Loss: 0.0569\n",
      "Epoch [24/50], Step [224/735], Loss: 0.0207\n",
      "Epoch [24/50], Step [225/735], Loss: 0.2133\n",
      "Epoch [24/50], Step [226/735], Loss: 0.0507\n",
      "Epoch [24/50], Step [227/735], Loss: 0.0518\n",
      "Epoch [24/50], Step [228/735], Loss: 0.0890\n",
      "Epoch [24/50], Step [229/735], Loss: 0.0893\n",
      "Epoch [24/50], Step [230/735], Loss: 0.1263\n",
      "Epoch [24/50], Step [231/735], Loss: 0.0419\n",
      "Epoch [24/50], Step [232/735], Loss: 0.0701\n",
      "Epoch [24/50], Step [233/735], Loss: 0.0800\n",
      "Epoch [24/50], Step [234/735], Loss: 0.0658\n",
      "Epoch [24/50], Step [235/735], Loss: 0.1051\n",
      "Epoch [24/50], Step [236/735], Loss: 0.0494\n",
      "Epoch [24/50], Step [237/735], Loss: 0.1806\n",
      "Epoch [24/50], Step [238/735], Loss: 0.0587\n",
      "Epoch [24/50], Step [239/735], Loss: 0.0921\n",
      "Epoch [24/50], Step [240/735], Loss: 0.0576\n",
      "Epoch [24/50], Step [241/735], Loss: 0.1037\n",
      "Epoch [24/50], Step [242/735], Loss: 0.1991\n",
      "Epoch [24/50], Step [243/735], Loss: 0.1085\n",
      "Epoch [24/50], Step [244/735], Loss: 0.0532\n",
      "Epoch [24/50], Step [245/735], Loss: 0.2172\n",
      "Epoch [24/50], Step [246/735], Loss: 0.0322\n",
      "Epoch [24/50], Step [247/735], Loss: 0.0599\n",
      "Epoch [24/50], Step [248/735], Loss: 0.0322\n",
      "Epoch [24/50], Step [249/735], Loss: 0.0928\n",
      "Epoch [24/50], Step [250/735], Loss: 0.1303\n",
      "Epoch [24/50], Step [251/735], Loss: 0.0694\n",
      "Epoch [24/50], Step [252/735], Loss: 0.0324\n",
      "Epoch [24/50], Step [253/735], Loss: 0.0469\n",
      "Epoch [24/50], Step [254/735], Loss: 0.0711\n",
      "Epoch [24/50], Step [255/735], Loss: 0.0666\n",
      "Epoch [24/50], Step [256/735], Loss: 0.0813\n",
      "Epoch [24/50], Step [257/735], Loss: 0.0224\n",
      "Epoch [24/50], Step [258/735], Loss: 0.0492\n",
      "Epoch [24/50], Step [259/735], Loss: 0.0197\n",
      "Epoch [24/50], Step [260/735], Loss: 0.0405\n",
      "Epoch [24/50], Step [261/735], Loss: 0.0646\n",
      "Epoch [24/50], Step [262/735], Loss: 0.0180\n",
      "Epoch [24/50], Step [263/735], Loss: 0.0345\n",
      "Epoch [24/50], Step [264/735], Loss: 0.0833\n",
      "Epoch [24/50], Step [265/735], Loss: 0.0700\n",
      "Epoch [24/50], Step [266/735], Loss: 0.1471\n",
      "Epoch [24/50], Step [267/735], Loss: 0.0251\n",
      "Epoch [24/50], Step [268/735], Loss: 0.0581\n",
      "Epoch [24/50], Step [269/735], Loss: 0.0379\n",
      "Epoch [24/50], Step [270/735], Loss: 0.0207\n",
      "Epoch [24/50], Step [271/735], Loss: 0.0553\n",
      "Epoch [24/50], Step [272/735], Loss: 0.0778\n",
      "Epoch [24/50], Step [273/735], Loss: 0.0179\n",
      "Epoch [24/50], Step [274/735], Loss: 0.0495\n",
      "Epoch [24/50], Step [275/735], Loss: 0.1010\n",
      "Epoch [24/50], Step [276/735], Loss: 0.0823\n",
      "Epoch [24/50], Step [277/735], Loss: 0.0496\n",
      "Epoch [24/50], Step [278/735], Loss: 0.0605\n",
      "Epoch [24/50], Step [279/735], Loss: 0.0319\n",
      "Epoch [24/50], Step [280/735], Loss: 0.0669\n",
      "Epoch [24/50], Step [281/735], Loss: 0.0296\n",
      "Epoch [24/50], Step [282/735], Loss: 0.0438\n",
      "Epoch [24/50], Step [283/735], Loss: 0.0137\n",
      "Epoch [24/50], Step [284/735], Loss: 0.0569\n",
      "Epoch [24/50], Step [285/735], Loss: 0.0238\n",
      "Epoch [24/50], Step [286/735], Loss: 0.0272\n",
      "Epoch [24/50], Step [287/735], Loss: 0.0277\n",
      "Epoch [24/50], Step [288/735], Loss: 0.0404\n",
      "Epoch [24/50], Step [289/735], Loss: 0.0289\n",
      "Epoch [24/50], Step [290/735], Loss: 0.0365\n",
      "Epoch [24/50], Step [291/735], Loss: 0.0461\n",
      "Epoch [24/50], Step [292/735], Loss: 0.0514\n",
      "Epoch [24/50], Step [293/735], Loss: 0.0241\n",
      "Epoch [24/50], Step [294/735], Loss: 0.0318\n",
      "Epoch [24/50], Step [295/735], Loss: 0.0431\n",
      "Epoch [24/50], Step [296/735], Loss: 0.0199\n",
      "Epoch [24/50], Step [297/735], Loss: 0.0121\n",
      "Epoch [24/50], Step [298/735], Loss: 0.2513\n",
      "Epoch [24/50], Step [299/735], Loss: 0.0430\n",
      "Epoch [24/50], Step [300/735], Loss: 0.0140\n",
      "Epoch [24/50], Step [301/735], Loss: 0.0201\n",
      "Epoch [24/50], Step [302/735], Loss: 0.1255\n",
      "Epoch [24/50], Step [303/735], Loss: 0.0568\n",
      "Epoch [24/50], Step [304/735], Loss: 0.0667\n",
      "Epoch [24/50], Step [305/735], Loss: 0.1042\n",
      "Epoch [24/50], Step [306/735], Loss: 0.0461\n",
      "Epoch [24/50], Step [307/735], Loss: 0.0309\n",
      "Epoch [24/50], Step [308/735], Loss: 0.1423\n",
      "Epoch [24/50], Step [309/735], Loss: 0.0304\n",
      "Epoch [24/50], Step [310/735], Loss: 0.1242\n",
      "Epoch [24/50], Step [311/735], Loss: 0.0520\n",
      "Epoch [24/50], Step [312/735], Loss: 0.0209\n",
      "Epoch [24/50], Step [313/735], Loss: 0.0196\n",
      "Epoch [24/50], Step [314/735], Loss: 0.0858\n",
      "Epoch [24/50], Step [315/735], Loss: 0.0325\n",
      "Epoch [24/50], Step [316/735], Loss: 0.1075\n",
      "Epoch [24/50], Step [317/735], Loss: 0.0506\n",
      "Epoch [24/50], Step [318/735], Loss: 0.1002\n",
      "Epoch [24/50], Step [319/735], Loss: 0.0961\n",
      "Epoch [24/50], Step [320/735], Loss: 0.1088\n",
      "Epoch [24/50], Step [321/735], Loss: 0.1018\n",
      "Epoch [24/50], Step [322/735], Loss: 0.0223\n",
      "Epoch [24/50], Step [323/735], Loss: 0.2133\n",
      "Epoch [24/50], Step [324/735], Loss: 0.0813\n",
      "Epoch [24/50], Step [325/735], Loss: 0.0238\n",
      "Epoch [24/50], Step [326/735], Loss: 0.0589\n",
      "Epoch [24/50], Step [327/735], Loss: 0.0355\n",
      "Epoch [24/50], Step [328/735], Loss: 0.2089\n",
      "Epoch [24/50], Step [329/735], Loss: 0.0612\n",
      "Epoch [24/50], Step [330/735], Loss: 0.1521\n",
      "Epoch [24/50], Step [331/735], Loss: 0.0387\n",
      "Epoch [24/50], Step [332/735], Loss: 0.2698\n",
      "Epoch [24/50], Step [333/735], Loss: 0.0534\n",
      "Epoch [24/50], Step [334/735], Loss: 0.0856\n",
      "Epoch [24/50], Step [335/735], Loss: 0.0690\n",
      "Epoch [24/50], Step [336/735], Loss: 0.0879\n",
      "Epoch [24/50], Step [337/735], Loss: 0.0231\n",
      "Epoch [24/50], Step [338/735], Loss: 0.1937\n",
      "Epoch [24/50], Step [339/735], Loss: 0.0896\n",
      "Epoch [24/50], Step [340/735], Loss: 0.0189\n",
      "Epoch [24/50], Step [341/735], Loss: 0.0356\n",
      "Epoch [24/50], Step [342/735], Loss: 0.1891\n",
      "Epoch [24/50], Step [343/735], Loss: 0.1135\n",
      "Epoch [24/50], Step [344/735], Loss: 0.0515\n",
      "Epoch [24/50], Step [345/735], Loss: 0.1416\n",
      "Epoch [24/50], Step [346/735], Loss: 0.0499\n",
      "Epoch [24/50], Step [347/735], Loss: 0.0809\n",
      "Epoch [24/50], Step [348/735], Loss: 0.1203\n",
      "Epoch [24/50], Step [349/735], Loss: 0.0456\n",
      "Epoch [24/50], Step [350/735], Loss: 0.0671\n",
      "Epoch [24/50], Step [351/735], Loss: 0.1235\n",
      "Epoch [24/50], Step [352/735], Loss: 0.0995\n",
      "Epoch [24/50], Step [353/735], Loss: 0.0471\n",
      "Epoch [24/50], Step [354/735], Loss: 0.0734\n",
      "Epoch [24/50], Step [355/735], Loss: 0.0836\n",
      "Epoch [24/50], Step [356/735], Loss: 0.1724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Step [357/735], Loss: 0.0532\n",
      "Epoch [24/50], Step [358/735], Loss: 0.0590\n",
      "Epoch [24/50], Step [359/735], Loss: 0.0497\n",
      "Epoch [24/50], Step [360/735], Loss: 0.0539\n",
      "Epoch [24/50], Step [361/735], Loss: 0.0526\n",
      "Epoch [24/50], Step [362/735], Loss: 0.0837\n",
      "Epoch [24/50], Step [363/735], Loss: 0.0612\n",
      "Epoch [24/50], Step [364/735], Loss: 0.0294\n",
      "Epoch [24/50], Step [365/735], Loss: 0.0958\n",
      "Epoch [24/50], Step [366/735], Loss: 0.0226\n",
      "Epoch [24/50], Step [367/735], Loss: 0.0734\n",
      "Epoch [24/50], Step [368/735], Loss: 0.0698\n",
      "Epoch [24/50], Step [369/735], Loss: 0.1306\n",
      "Epoch [24/50], Step [370/735], Loss: 0.0313\n",
      "Epoch [24/50], Step [371/735], Loss: 0.0540\n",
      "Epoch [24/50], Step [372/735], Loss: 0.0478\n",
      "Epoch [24/50], Step [373/735], Loss: 0.1780\n",
      "Epoch [24/50], Step [374/735], Loss: 0.0629\n",
      "Epoch [24/50], Step [375/735], Loss: 0.3002\n",
      "Epoch [24/50], Step [376/735], Loss: 0.1115\n",
      "Epoch [24/50], Step [377/735], Loss: 0.0352\n",
      "Epoch [24/50], Step [378/735], Loss: 0.4028\n",
      "Epoch [24/50], Step [379/735], Loss: 0.0315\n",
      "Epoch [24/50], Step [380/735], Loss: 0.0244\n",
      "Epoch [24/50], Step [381/735], Loss: 0.0846\n",
      "Epoch [24/50], Step [382/735], Loss: 0.0300\n",
      "Epoch [24/50], Step [383/735], Loss: 0.0255\n",
      "Epoch [24/50], Step [384/735], Loss: 0.1376\n",
      "Epoch [24/50], Step [385/735], Loss: 0.0188\n",
      "Epoch [24/50], Step [386/735], Loss: 0.1021\n",
      "Epoch [24/50], Step [387/735], Loss: 0.1168\n",
      "Epoch [24/50], Step [388/735], Loss: 0.0682\n",
      "Epoch [24/50], Step [389/735], Loss: 0.0329\n",
      "Epoch [24/50], Step [390/735], Loss: 0.0470\n",
      "Epoch [24/50], Step [391/735], Loss: 0.1409\n",
      "Epoch [24/50], Step [392/735], Loss: 0.1449\n",
      "Epoch [24/50], Step [393/735], Loss: 0.0734\n",
      "Epoch [24/50], Step [394/735], Loss: 0.0574\n",
      "Epoch [24/50], Step [395/735], Loss: 0.1446\n",
      "Epoch [24/50], Step [396/735], Loss: 0.0670\n",
      "Epoch [24/50], Step [397/735], Loss: 0.0565\n",
      "Epoch [24/50], Step [398/735], Loss: 0.1656\n",
      "Epoch [24/50], Step [399/735], Loss: 0.1015\n",
      "Epoch [24/50], Step [400/735], Loss: 0.0719\n",
      "Epoch [24/50], Step [401/735], Loss: 0.0498\n",
      "Epoch [24/50], Step [402/735], Loss: 0.2224\n",
      "Epoch [24/50], Step [403/735], Loss: 0.1009\n",
      "Epoch [24/50], Step [404/735], Loss: 0.0943\n",
      "Epoch [24/50], Step [405/735], Loss: 0.0453\n",
      "Epoch [24/50], Step [406/735], Loss: 0.0785\n",
      "Epoch [24/50], Step [407/735], Loss: 0.1740\n",
      "Epoch [24/50], Step [408/735], Loss: 0.0260\n",
      "Epoch [24/50], Step [409/735], Loss: 0.0462\n",
      "Epoch [24/50], Step [410/735], Loss: 0.0984\n",
      "Epoch [24/50], Step [411/735], Loss: 0.1098\n",
      "Epoch [24/50], Step [412/735], Loss: 0.0167\n",
      "Epoch [24/50], Step [413/735], Loss: 0.1856\n",
      "Epoch [24/50], Step [414/735], Loss: 0.0994\n",
      "Epoch [24/50], Step [415/735], Loss: 0.0194\n",
      "Epoch [24/50], Step [416/735], Loss: 0.0332\n",
      "Epoch [24/50], Step [417/735], Loss: 0.0733\n",
      "Epoch [24/50], Step [418/735], Loss: 0.0399\n",
      "Epoch [24/50], Step [419/735], Loss: 0.1124\n",
      "Epoch [24/50], Step [420/735], Loss: 0.0488\n",
      "Epoch [24/50], Step [421/735], Loss: 0.0969\n",
      "Epoch [24/50], Step [422/735], Loss: 0.0875\n",
      "Epoch [24/50], Step [423/735], Loss: 0.1459\n",
      "Epoch [24/50], Step [424/735], Loss: 0.5738\n",
      "Epoch [24/50], Step [425/735], Loss: 0.0465\n",
      "Epoch [24/50], Step [426/735], Loss: 0.0572\n",
      "Epoch [24/50], Step [427/735], Loss: 0.3843\n",
      "Epoch [24/50], Step [428/735], Loss: 0.0837\n",
      "Epoch [24/50], Step [429/735], Loss: 0.1207\n",
      "Epoch [24/50], Step [430/735], Loss: 0.0380\n",
      "Epoch [24/50], Step [431/735], Loss: 0.0932\n",
      "Epoch [24/50], Step [432/735], Loss: 0.0695\n",
      "Epoch [24/50], Step [433/735], Loss: 0.1241\n",
      "Epoch [24/50], Step [434/735], Loss: 0.0684\n",
      "Epoch [24/50], Step [435/735], Loss: 0.1213\n",
      "Epoch [24/50], Step [436/735], Loss: 0.0447\n",
      "Epoch [24/50], Step [437/735], Loss: 0.0558\n",
      "Epoch [24/50], Step [438/735], Loss: 0.0734\n",
      "Epoch [24/50], Step [439/735], Loss: 0.3332\n",
      "Epoch [24/50], Step [440/735], Loss: 0.1077\n",
      "Epoch [24/50], Step [441/735], Loss: 0.2491\n",
      "Epoch [24/50], Step [442/735], Loss: 0.0263\n",
      "Epoch [24/50], Step [443/735], Loss: 0.0303\n",
      "Epoch [24/50], Step [444/735], Loss: 0.0685\n",
      "Epoch [24/50], Step [445/735], Loss: 0.0437\n",
      "Epoch [24/50], Step [446/735], Loss: 0.0420\n",
      "Epoch [24/50], Step [447/735], Loss: 0.0219\n",
      "Epoch [24/50], Step [448/735], Loss: 0.1541\n",
      "Epoch [24/50], Step [449/735], Loss: 0.0368\n",
      "Epoch [24/50], Step [450/735], Loss: 0.0881\n",
      "Epoch [24/50], Step [451/735], Loss: 0.0864\n",
      "Epoch [24/50], Step [452/735], Loss: 0.1086\n",
      "Epoch [24/50], Step [453/735], Loss: 0.0634\n",
      "Epoch [24/50], Step [454/735], Loss: 0.1228\n",
      "Epoch [24/50], Step [455/735], Loss: 0.0744\n",
      "Epoch [24/50], Step [456/735], Loss: 0.0514\n",
      "Epoch [24/50], Step [457/735], Loss: 0.0301\n",
      "Epoch [24/50], Step [458/735], Loss: 0.0617\n",
      "Epoch [24/50], Step [459/735], Loss: 0.0873\n",
      "Epoch [24/50], Step [460/735], Loss: 0.0206\n",
      "Epoch [24/50], Step [461/735], Loss: 0.0702\n",
      "Epoch [24/50], Step [462/735], Loss: 0.0962\n",
      "Epoch [24/50], Step [463/735], Loss: 0.0729\n",
      "Epoch [24/50], Step [464/735], Loss: 0.0171\n",
      "Epoch [24/50], Step [465/735], Loss: 0.0209\n",
      "Epoch [24/50], Step [466/735], Loss: 0.0477\n",
      "Epoch [24/50], Step [467/735], Loss: 0.2034\n",
      "Epoch [24/50], Step [468/735], Loss: 0.0440\n",
      "Epoch [24/50], Step [469/735], Loss: 0.2086\n",
      "Epoch [24/50], Step [470/735], Loss: 0.0501\n",
      "Epoch [24/50], Step [471/735], Loss: 0.0501\n",
      "Epoch [24/50], Step [472/735], Loss: 0.0805\n",
      "Epoch [24/50], Step [473/735], Loss: 0.0798\n",
      "Epoch [24/50], Step [474/735], Loss: 0.0526\n",
      "Epoch [24/50], Step [475/735], Loss: 0.0635\n",
      "Epoch [24/50], Step [476/735], Loss: 0.0703\n",
      "Epoch [24/50], Step [477/735], Loss: 0.0784\n",
      "Epoch [24/50], Step [478/735], Loss: 0.2087\n",
      "Epoch [24/50], Step [479/735], Loss: 0.1034\n",
      "Epoch [24/50], Step [480/735], Loss: 0.0436\n",
      "Epoch [24/50], Step [481/735], Loss: 0.1686\n",
      "Epoch [24/50], Step [482/735], Loss: 0.0511\n",
      "Epoch [24/50], Step [483/735], Loss: 0.0352\n",
      "Epoch [24/50], Step [484/735], Loss: 0.0621\n",
      "Epoch [24/50], Step [485/735], Loss: 0.0230\n",
      "Epoch [24/50], Step [486/735], Loss: 0.0225\n",
      "Epoch [24/50], Step [487/735], Loss: 0.0926\n",
      "Epoch [24/50], Step [488/735], Loss: 0.0892\n",
      "Epoch [24/50], Step [489/735], Loss: 0.0437\n",
      "Epoch [24/50], Step [490/735], Loss: 0.1380\n",
      "Epoch [24/50], Step [491/735], Loss: 0.0224\n",
      "Epoch [24/50], Step [492/735], Loss: 0.0857\n",
      "Epoch [24/50], Step [493/735], Loss: 0.1266\n",
      "Epoch [24/50], Step [494/735], Loss: 0.2656\n",
      "Epoch [24/50], Step [495/735], Loss: 0.0226\n",
      "Epoch [24/50], Step [496/735], Loss: 0.0657\n",
      "Epoch [24/50], Step [497/735], Loss: 0.3946\n",
      "Epoch [24/50], Step [498/735], Loss: 0.0788\n",
      "Epoch [24/50], Step [499/735], Loss: 0.0196\n",
      "Epoch [24/50], Step [500/735], Loss: 0.0364\n",
      "Epoch [24/50], Step [501/735], Loss: 0.0531\n",
      "Epoch [24/50], Step [502/735], Loss: 0.2061\n",
      "Epoch [24/50], Step [503/735], Loss: 0.0404\n",
      "Epoch [24/50], Step [504/735], Loss: 0.0487\n",
      "Epoch [24/50], Step [505/735], Loss: 0.1040\n",
      "Epoch [24/50], Step [506/735], Loss: 0.0784\n",
      "Epoch [24/50], Step [507/735], Loss: 0.1812\n",
      "Epoch [24/50], Step [508/735], Loss: 0.0666\n",
      "Epoch [24/50], Step [509/735], Loss: 0.0841\n",
      "Epoch [24/50], Step [510/735], Loss: 0.0895\n",
      "Epoch [24/50], Step [511/735], Loss: 0.0739\n",
      "Epoch [24/50], Step [512/735], Loss: 0.0391\n",
      "Epoch [24/50], Step [513/735], Loss: 0.4666\n",
      "Epoch [24/50], Step [514/735], Loss: 0.0334\n",
      "Epoch [24/50], Step [515/735], Loss: 0.1474\n",
      "Epoch [24/50], Step [516/735], Loss: 0.1303\n",
      "Epoch [24/50], Step [517/735], Loss: 0.0504\n",
      "Epoch [24/50], Step [518/735], Loss: 0.0944\n",
      "Epoch [24/50], Step [519/735], Loss: 0.0535\n",
      "Epoch [24/50], Step [520/735], Loss: 0.0677\n",
      "Epoch [24/50], Step [521/735], Loss: 0.0982\n",
      "Epoch [24/50], Step [522/735], Loss: 0.0597\n",
      "Epoch [24/50], Step [523/735], Loss: 0.0379\n",
      "Epoch [24/50], Step [524/735], Loss: 0.0637\n",
      "Epoch [24/50], Step [525/735], Loss: 0.0789\n",
      "Epoch [24/50], Step [526/735], Loss: 0.0932\n",
      "Epoch [24/50], Step [527/735], Loss: 0.4569\n",
      "Epoch [24/50], Step [528/735], Loss: 0.1374\n",
      "Epoch [24/50], Step [529/735], Loss: 0.1326\n",
      "Epoch [24/50], Step [530/735], Loss: 0.0953\n",
      "Epoch [24/50], Step [531/735], Loss: 0.0797\n",
      "Epoch [24/50], Step [532/735], Loss: 0.0662\n",
      "Epoch [24/50], Step [533/735], Loss: 0.0878\n",
      "Epoch [24/50], Step [534/735], Loss: 0.0436\n",
      "Epoch [24/50], Step [535/735], Loss: 0.1185\n",
      "Epoch [24/50], Step [536/735], Loss: 0.0478\n",
      "Epoch [24/50], Step [537/735], Loss: 0.1045\n",
      "Epoch [24/50], Step [538/735], Loss: 0.1022\n",
      "Epoch [24/50], Step [539/735], Loss: 0.0415\n",
      "Epoch [24/50], Step [540/735], Loss: 0.4321\n",
      "Epoch [24/50], Step [541/735], Loss: 0.0185\n",
      "Epoch [24/50], Step [542/735], Loss: 0.0342\n",
      "Epoch [24/50], Step [543/735], Loss: 0.0315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Step [544/735], Loss: 0.0714\n",
      "Epoch [24/50], Step [545/735], Loss: 0.0299\n",
      "Epoch [24/50], Step [546/735], Loss: 0.0777\n",
      "Epoch [24/50], Step [547/735], Loss: 0.1116\n",
      "Epoch [24/50], Step [548/735], Loss: 0.0792\n",
      "Epoch [24/50], Step [549/735], Loss: 0.1396\n",
      "Epoch [24/50], Step [550/735], Loss: 0.0655\n",
      "Epoch [24/50], Step [551/735], Loss: 0.0744\n",
      "Epoch [24/50], Step [552/735], Loss: 0.0219\n",
      "Epoch [24/50], Step [553/735], Loss: 0.2120\n",
      "Epoch [24/50], Step [554/735], Loss: 0.1329\n",
      "Epoch [24/50], Step [555/735], Loss: 0.1129\n",
      "Epoch [24/50], Step [556/735], Loss: 0.0604\n",
      "Epoch [24/50], Step [557/735], Loss: 0.0410\n",
      "Epoch [24/50], Step [558/735], Loss: 0.2848\n",
      "Epoch [24/50], Step [559/735], Loss: 0.1510\n",
      "Epoch [24/50], Step [560/735], Loss: 0.1709\n",
      "Epoch [24/50], Step [561/735], Loss: 0.1151\n",
      "Epoch [24/50], Step [562/735], Loss: 0.0747\n",
      "Epoch [24/50], Step [563/735], Loss: 0.1975\n",
      "Epoch [24/50], Step [564/735], Loss: 0.0922\n",
      "Epoch [24/50], Step [565/735], Loss: 0.0177\n",
      "Epoch [24/50], Step [566/735], Loss: 0.1207\n",
      "Epoch [24/50], Step [567/735], Loss: 0.0569\n",
      "Epoch [24/50], Step [568/735], Loss: 0.1007\n",
      "Epoch [24/50], Step [569/735], Loss: 0.0412\n",
      "Epoch [24/50], Step [570/735], Loss: 0.0562\n",
      "Epoch [24/50], Step [571/735], Loss: 0.1165\n",
      "Epoch [24/50], Step [572/735], Loss: 0.1082\n",
      "Epoch [24/50], Step [573/735], Loss: 0.0458\n",
      "Epoch [24/50], Step [574/735], Loss: 0.0418\n",
      "Epoch [24/50], Step [575/735], Loss: 0.0352\n",
      "Epoch [24/50], Step [576/735], Loss: 0.0685\n",
      "Epoch [24/50], Step [577/735], Loss: 0.1774\n",
      "Epoch [24/50], Step [578/735], Loss: 0.2078\n",
      "Epoch [24/50], Step [579/735], Loss: 0.0412\n",
      "Epoch [24/50], Step [580/735], Loss: 0.1186\n",
      "Epoch [24/50], Step [581/735], Loss: 0.0444\n",
      "Epoch [24/50], Step [582/735], Loss: 0.3994\n",
      "Epoch [24/50], Step [583/735], Loss: 0.0644\n",
      "Epoch [24/50], Step [584/735], Loss: 0.0507\n",
      "Epoch [24/50], Step [585/735], Loss: 0.0664\n",
      "Epoch [24/50], Step [586/735], Loss: 0.0494\n",
      "Epoch [24/50], Step [587/735], Loss: 0.0741\n",
      "Epoch [24/50], Step [588/735], Loss: 0.1226\n",
      "Epoch [24/50], Step [589/735], Loss: 0.0364\n",
      "Epoch [24/50], Step [590/735], Loss: 0.1041\n",
      "Epoch [24/50], Step [591/735], Loss: 0.0576\n",
      "Epoch [24/50], Step [592/735], Loss: 0.0600\n",
      "Epoch [24/50], Step [593/735], Loss: 0.1062\n",
      "Epoch [24/50], Step [594/735], Loss: 0.2981\n",
      "Epoch [24/50], Step [595/735], Loss: 0.1729\n",
      "Epoch [24/50], Step [596/735], Loss: 0.1324\n",
      "Epoch [24/50], Step [597/735], Loss: 0.1444\n",
      "Epoch [24/50], Step [598/735], Loss: 0.1666\n",
      "Epoch [24/50], Step [599/735], Loss: 0.0301\n",
      "Epoch [24/50], Step [600/735], Loss: 0.0921\n",
      "Epoch [24/50], Step [601/735], Loss: 0.0354\n",
      "Epoch [24/50], Step [602/735], Loss: 0.0339\n",
      "Epoch [24/50], Step [603/735], Loss: 0.0245\n",
      "Epoch [24/50], Step [604/735], Loss: 0.0685\n",
      "Epoch [24/50], Step [605/735], Loss: 0.0613\n",
      "Epoch [24/50], Step [606/735], Loss: 0.0887\n",
      "Epoch [24/50], Step [607/735], Loss: 0.0543\n",
      "Epoch [24/50], Step [608/735], Loss: 0.0914\n",
      "Epoch [24/50], Step [609/735], Loss: 0.0592\n",
      "Epoch [24/50], Step [610/735], Loss: 0.0418\n",
      "Epoch [24/50], Step [611/735], Loss: 0.0568\n",
      "Epoch [24/50], Step [612/735], Loss: 0.0306\n",
      "Epoch [24/50], Step [613/735], Loss: 0.0338\n",
      "Epoch [24/50], Step [614/735], Loss: 0.0613\n",
      "Epoch [24/50], Step [615/735], Loss: 0.0324\n",
      "Epoch [24/50], Step [616/735], Loss: 0.0240\n",
      "Epoch [24/50], Step [617/735], Loss: 0.0529\n",
      "Epoch [24/50], Step [618/735], Loss: 0.0730\n",
      "Epoch [24/50], Step [619/735], Loss: 0.0465\n",
      "Epoch [24/50], Step [620/735], Loss: 0.0656\n",
      "Epoch [24/50], Step [621/735], Loss: 0.0445\n",
      "Epoch [24/50], Step [622/735], Loss: 0.0811\n",
      "Epoch [24/50], Step [623/735], Loss: 0.1043\n",
      "Epoch [24/50], Step [624/735], Loss: 0.1538\n",
      "Epoch [24/50], Step [625/735], Loss: 0.0357\n",
      "Epoch [24/50], Step [626/735], Loss: 0.0179\n",
      "Epoch [24/50], Step [627/735], Loss: 0.1889\n",
      "Epoch [24/50], Step [628/735], Loss: 0.1051\n",
      "Epoch [24/50], Step [629/735], Loss: 0.1790\n",
      "Epoch [24/50], Step [630/735], Loss: 0.0332\n",
      "Epoch [24/50], Step [631/735], Loss: 0.0482\n",
      "Epoch [24/50], Step [632/735], Loss: 0.0312\n",
      "Epoch [24/50], Step [633/735], Loss: 0.1042\n",
      "Epoch [24/50], Step [634/735], Loss: 0.2163\n",
      "Epoch [24/50], Step [635/735], Loss: 0.0424\n",
      "Epoch [24/50], Step [636/735], Loss: 0.0800\n",
      "Epoch [24/50], Step [637/735], Loss: 0.0561\n",
      "Epoch [24/50], Step [638/735], Loss: 0.0329\n",
      "Epoch [24/50], Step [639/735], Loss: 0.0969\n",
      "Epoch [24/50], Step [640/735], Loss: 0.0558\n",
      "Epoch [24/50], Step [641/735], Loss: 0.0542\n",
      "Epoch [24/50], Step [642/735], Loss: 0.0883\n",
      "Epoch [24/50], Step [643/735], Loss: 0.0532\n",
      "Epoch [24/50], Step [644/735], Loss: 0.0775\n",
      "Epoch [24/50], Step [645/735], Loss: 0.0452\n",
      "Epoch [24/50], Step [646/735], Loss: 0.0213\n",
      "Epoch [24/50], Step [647/735], Loss: 0.1078\n",
      "Epoch [24/50], Step [648/735], Loss: 0.0301\n",
      "Epoch [24/50], Step [649/735], Loss: 0.3312\n",
      "Epoch [24/50], Step [650/735], Loss: 0.0674\n",
      "Epoch [24/50], Step [651/735], Loss: 0.0591\n",
      "Epoch [24/50], Step [652/735], Loss: 0.0239\n",
      "Epoch [24/50], Step [653/735], Loss: 0.0533\n",
      "Epoch [24/50], Step [654/735], Loss: 0.0717\n",
      "Epoch [24/50], Step [655/735], Loss: 0.2149\n",
      "Epoch [24/50], Step [656/735], Loss: 0.0507\n",
      "Epoch [24/50], Step [657/735], Loss: 0.0763\n",
      "Epoch [24/50], Step [658/735], Loss: 0.0746\n",
      "Epoch [24/50], Step [659/735], Loss: 0.0296\n",
      "Epoch [24/50], Step [660/735], Loss: 0.0594\n",
      "Epoch [24/50], Step [661/735], Loss: 0.0792\n",
      "Epoch [24/50], Step [662/735], Loss: 0.0607\n",
      "Epoch [24/50], Step [663/735], Loss: 0.0824\n",
      "Epoch [24/50], Step [664/735], Loss: 0.1089\n",
      "Epoch [24/50], Step [665/735], Loss: 0.0638\n",
      "Epoch [24/50], Step [666/735], Loss: 0.0232\n",
      "Epoch [24/50], Step [667/735], Loss: 0.0803\n",
      "Epoch [24/50], Step [668/735], Loss: 0.0383\n",
      "Epoch [24/50], Step [669/735], Loss: 0.0673\n",
      "Epoch [24/50], Step [670/735], Loss: 0.0480\n",
      "Epoch [24/50], Step [671/735], Loss: 0.0163\n",
      "Epoch [24/50], Step [672/735], Loss: 0.0422\n",
      "Epoch [24/50], Step [673/735], Loss: 0.1834\n",
      "Epoch [24/50], Step [674/735], Loss: 0.0898\n",
      "Epoch [24/50], Step [675/735], Loss: 0.0326\n",
      "Epoch [24/50], Step [676/735], Loss: 0.0345\n",
      "Epoch [24/50], Step [677/735], Loss: 0.1901\n",
      "Epoch [24/50], Step [678/735], Loss: 0.0217\n",
      "Epoch [24/50], Step [679/735], Loss: 0.0549\n",
      "Epoch [24/50], Step [680/735], Loss: 0.0370\n",
      "Epoch [24/50], Step [681/735], Loss: 0.0828\n",
      "Epoch [24/50], Step [682/735], Loss: 0.0205\n",
      "Epoch [24/50], Step [683/735], Loss: 0.0302\n",
      "Epoch [24/50], Step [684/735], Loss: 0.0317\n",
      "Epoch [24/50], Step [685/735], Loss: 0.0325\n",
      "Epoch [24/50], Step [686/735], Loss: 0.0252\n",
      "Epoch [24/50], Step [687/735], Loss: 0.0265\n",
      "Epoch [24/50], Step [688/735], Loss: 0.0472\n",
      "Epoch [24/50], Step [689/735], Loss: 0.0554\n",
      "Epoch [24/50], Step [690/735], Loss: 0.1688\n",
      "Epoch [24/50], Step [691/735], Loss: 0.0582\n",
      "Epoch [24/50], Step [692/735], Loss: 0.0592\n",
      "Epoch [24/50], Step [693/735], Loss: 0.0170\n",
      "Epoch [24/50], Step [694/735], Loss: 0.0163\n",
      "Epoch [24/50], Step [695/735], Loss: 0.0552\n",
      "Epoch [24/50], Step [696/735], Loss: 0.0316\n",
      "Epoch [24/50], Step [697/735], Loss: 0.0267\n",
      "Epoch [24/50], Step [698/735], Loss: 0.0474\n",
      "Epoch [24/50], Step [699/735], Loss: 0.0243\n",
      "Epoch [24/50], Step [700/735], Loss: 0.1496\n",
      "Epoch [24/50], Step [701/735], Loss: 0.0408\n",
      "Epoch [24/50], Step [702/735], Loss: 0.0300\n",
      "Epoch [24/50], Step [703/735], Loss: 0.0617\n",
      "Epoch [24/50], Step [704/735], Loss: 0.0270\n",
      "Epoch [24/50], Step [705/735], Loss: 0.2441\n",
      "Epoch [24/50], Step [706/735], Loss: 0.1233\n",
      "Epoch [24/50], Step [707/735], Loss: 0.0196\n",
      "Epoch [24/50], Step [708/735], Loss: 0.0182\n",
      "Epoch [24/50], Step [709/735], Loss: 0.0438\n",
      "Epoch [24/50], Step [710/735], Loss: 0.0698\n",
      "Epoch [24/50], Step [711/735], Loss: 0.0205\n",
      "Epoch [24/50], Step [712/735], Loss: 0.0823\n",
      "Epoch [24/50], Step [713/735], Loss: 0.1687\n",
      "Epoch [24/50], Step [714/735], Loss: 0.0405\n",
      "Epoch [24/50], Step [715/735], Loss: 0.0349\n",
      "Epoch [24/50], Step [716/735], Loss: 0.1170\n",
      "Epoch [24/50], Step [717/735], Loss: 0.0578\n",
      "Epoch [24/50], Step [718/735], Loss: 0.0878\n",
      "Epoch [24/50], Step [719/735], Loss: 0.0288\n",
      "Epoch [24/50], Step [720/735], Loss: 0.0669\n",
      "Epoch [24/50], Step [721/735], Loss: 0.0301\n",
      "Epoch [24/50], Step [722/735], Loss: 0.0721\n",
      "Epoch [24/50], Step [723/735], Loss: 0.0507\n",
      "Epoch [24/50], Step [724/735], Loss: 0.0309\n",
      "Epoch [24/50], Step [725/735], Loss: 0.0435\n",
      "Epoch [24/50], Step [726/735], Loss: 0.0721\n",
      "Epoch [24/50], Step [727/735], Loss: 0.0844\n",
      "Epoch [24/50], Step [728/735], Loss: 0.0574\n",
      "Epoch [24/50], Step [729/735], Loss: 0.0448\n",
      "Epoch [24/50], Step [730/735], Loss: 0.0943\n",
      "Epoch [24/50], Step [731/735], Loss: 0.0461\n",
      "Epoch [24/50], Step [732/735], Loss: 0.0331\n",
      "Epoch [24/50], Step [733/735], Loss: 0.3377\n",
      "Epoch [24/50], Step [734/735], Loss: 0.1174\n",
      "Epoch [24/50], Step [735/735], Loss: 0.0363\n",
      "Epoch [25/50], Step [1/735], Loss: 0.1219\n",
      "Epoch [25/50], Step [2/735], Loss: 0.1201\n",
      "Epoch [25/50], Step [3/735], Loss: 0.1605\n",
      "Epoch [25/50], Step [4/735], Loss: 0.0334\n",
      "Epoch [25/50], Step [5/735], Loss: 0.0670\n",
      "Epoch [25/50], Step [6/735], Loss: 0.0321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Step [7/735], Loss: 0.0847\n",
      "Epoch [25/50], Step [8/735], Loss: 0.0840\n",
      "Epoch [25/50], Step [9/735], Loss: 0.0877\n",
      "Epoch [25/50], Step [10/735], Loss: 0.1769\n",
      "Epoch [25/50], Step [11/735], Loss: 0.0418\n",
      "Epoch [25/50], Step [12/735], Loss: 0.1118\n",
      "Epoch [25/50], Step [13/735], Loss: 0.5631\n",
      "Epoch [25/50], Step [14/735], Loss: 0.0664\n",
      "Epoch [25/50], Step [15/735], Loss: 0.1680\n",
      "Epoch [25/50], Step [16/735], Loss: 0.0285\n",
      "Epoch [25/50], Step [17/735], Loss: 0.0665\n",
      "Epoch [25/50], Step [18/735], Loss: 0.1702\n",
      "Epoch [25/50], Step [19/735], Loss: 0.0604\n",
      "Epoch [25/50], Step [20/735], Loss: 0.0835\n",
      "Epoch [25/50], Step [21/735], Loss: 0.1011\n",
      "Epoch [25/50], Step [22/735], Loss: 0.0505\n",
      "Epoch [25/50], Step [23/735], Loss: 0.0913\n",
      "Epoch [25/50], Step [24/735], Loss: 0.1696\n",
      "Epoch [25/50], Step [25/735], Loss: 0.0658\n",
      "Epoch [25/50], Step [26/735], Loss: 0.0202\n",
      "Epoch [25/50], Step [27/735], Loss: 0.0521\n",
      "Epoch [25/50], Step [28/735], Loss: 0.0156\n",
      "Epoch [25/50], Step [29/735], Loss: 0.0972\n",
      "Epoch [25/50], Step [30/735], Loss: 0.0398\n",
      "Epoch [25/50], Step [31/735], Loss: 0.0816\n",
      "Epoch [25/50], Step [32/735], Loss: 0.0834\n",
      "Epoch [25/50], Step [33/735], Loss: 0.0378\n",
      "Epoch [25/50], Step [34/735], Loss: 0.0303\n",
      "Epoch [25/50], Step [35/735], Loss: 0.1825\n",
      "Epoch [25/50], Step [36/735], Loss: 0.0611\n",
      "Epoch [25/50], Step [37/735], Loss: 0.2066\n",
      "Epoch [25/50], Step [38/735], Loss: 0.0732\n",
      "Epoch [25/50], Step [39/735], Loss: 0.0383\n",
      "Epoch [25/50], Step [40/735], Loss: 0.0416\n",
      "Epoch [25/50], Step [41/735], Loss: 0.1189\n",
      "Epoch [25/50], Step [42/735], Loss: 0.1744\n",
      "Epoch [25/50], Step [43/735], Loss: 0.0487\n",
      "Epoch [25/50], Step [44/735], Loss: 0.0845\n",
      "Epoch [25/50], Step [45/735], Loss: 0.2227\n",
      "Epoch [25/50], Step [46/735], Loss: 0.0527\n",
      "Epoch [25/50], Step [47/735], Loss: 0.1329\n",
      "Epoch [25/50], Step [48/735], Loss: 0.0326\n",
      "Epoch [25/50], Step [49/735], Loss: 0.0792\n",
      "Epoch [25/50], Step [50/735], Loss: 0.0940\n",
      "Epoch [25/50], Step [51/735], Loss: 0.0884\n",
      "Epoch [25/50], Step [52/735], Loss: 0.0313\n",
      "Epoch [25/50], Step [53/735], Loss: 0.0635\n",
      "Epoch [25/50], Step [54/735], Loss: 0.0885\n",
      "Epoch [25/50], Step [55/735], Loss: 0.0361\n",
      "Epoch [25/50], Step [56/735], Loss: 0.0457\n",
      "Epoch [25/50], Step [57/735], Loss: 0.0629\n",
      "Epoch [25/50], Step [58/735], Loss: 0.0407\n",
      "Epoch [25/50], Step [59/735], Loss: 0.0962\n",
      "Epoch [25/50], Step [60/735], Loss: 0.0589\n",
      "Epoch [25/50], Step [61/735], Loss: 0.0634\n",
      "Epoch [25/50], Step [62/735], Loss: 0.0314\n",
      "Epoch [25/50], Step [63/735], Loss: 0.0975\n",
      "Epoch [25/50], Step [64/735], Loss: 0.0379\n",
      "Epoch [25/50], Step [65/735], Loss: 0.0439\n",
      "Epoch [25/50], Step [66/735], Loss: 0.0916\n",
      "Epoch [25/50], Step [67/735], Loss: 0.0460\n",
      "Epoch [25/50], Step [68/735], Loss: 0.0365\n",
      "Epoch [25/50], Step [69/735], Loss: 0.0891\n",
      "Epoch [25/50], Step [70/735], Loss: 0.1024\n",
      "Epoch [25/50], Step [71/735], Loss: 0.2088\n",
      "Epoch [25/50], Step [72/735], Loss: 0.3060\n",
      "Epoch [25/50], Step [73/735], Loss: 0.0581\n",
      "Epoch [25/50], Step [74/735], Loss: 0.0320\n",
      "Epoch [25/50], Step [75/735], Loss: 0.0284\n",
      "Epoch [25/50], Step [76/735], Loss: 0.0625\n",
      "Epoch [25/50], Step [77/735], Loss: 0.0432\n",
      "Epoch [25/50], Step [78/735], Loss: 0.0555\n",
      "Epoch [25/50], Step [79/735], Loss: 0.0655\n",
      "Epoch [25/50], Step [80/735], Loss: 0.0290\n",
      "Epoch [25/50], Step [81/735], Loss: 0.0372\n",
      "Epoch [25/50], Step [82/735], Loss: 0.0848\n",
      "Epoch [25/50], Step [83/735], Loss: 0.0599\n",
      "Epoch [25/50], Step [84/735], Loss: 0.2483\n",
      "Epoch [25/50], Step [85/735], Loss: 0.0198\n",
      "Epoch [25/50], Step [86/735], Loss: 0.0855\n",
      "Epoch [25/50], Step [87/735], Loss: 0.0825\n",
      "Epoch [25/50], Step [88/735], Loss: 0.1890\n",
      "Epoch [25/50], Step [89/735], Loss: 0.0691\n",
      "Epoch [25/50], Step [90/735], Loss: 0.3859\n",
      "Epoch [25/50], Step [91/735], Loss: 0.0626\n",
      "Epoch [25/50], Step [92/735], Loss: 0.0372\n",
      "Epoch [25/50], Step [93/735], Loss: 0.0617\n",
      "Epoch [25/50], Step [94/735], Loss: 0.0234\n",
      "Epoch [25/50], Step [95/735], Loss: 0.1923\n",
      "Epoch [25/50], Step [96/735], Loss: 0.0513\n",
      "Epoch [25/50], Step [97/735], Loss: 0.0397\n",
      "Epoch [25/50], Step [98/735], Loss: 0.0115\n",
      "Epoch [25/50], Step [99/735], Loss: 0.1401\n",
      "Epoch [25/50], Step [100/735], Loss: 0.0537\n",
      "Epoch [25/50], Step [101/735], Loss: 0.0566\n",
      "Epoch [25/50], Step [102/735], Loss: 0.0590\n",
      "Epoch [25/50], Step [103/735], Loss: 0.0733\n",
      "Epoch [25/50], Step [104/735], Loss: 0.0898\n",
      "Epoch [25/50], Step [105/735], Loss: 0.0950\n",
      "Epoch [25/50], Step [106/735], Loss: 0.0750\n",
      "Epoch [25/50], Step [107/735], Loss: 0.1520\n",
      "Epoch [25/50], Step [108/735], Loss: 0.0357\n",
      "Epoch [25/50], Step [109/735], Loss: 0.0391\n",
      "Epoch [25/50], Step [110/735], Loss: 0.2759\n",
      "Epoch [25/50], Step [111/735], Loss: 0.0470\n",
      "Epoch [25/50], Step [112/735], Loss: 0.1199\n",
      "Epoch [25/50], Step [113/735], Loss: 0.0390\n",
      "Epoch [25/50], Step [114/735], Loss: 0.0471\n",
      "Epoch [25/50], Step [115/735], Loss: 0.1557\n",
      "Epoch [25/50], Step [116/735], Loss: 0.0360\n",
      "Epoch [25/50], Step [117/735], Loss: 0.1893\n",
      "Epoch [25/50], Step [118/735], Loss: 0.0551\n",
      "Epoch [25/50], Step [119/735], Loss: 0.0993\n",
      "Epoch [25/50], Step [120/735], Loss: 0.1234\n",
      "Epoch [25/50], Step [121/735], Loss: 0.2022\n",
      "Epoch [25/50], Step [122/735], Loss: 0.0579\n",
      "Epoch [25/50], Step [123/735], Loss: 0.1352\n",
      "Epoch [25/50], Step [124/735], Loss: 0.0266\n",
      "Epoch [25/50], Step [125/735], Loss: 0.0367\n",
      "Epoch [25/50], Step [126/735], Loss: 0.1361\n",
      "Epoch [25/50], Step [127/735], Loss: 0.1583\n",
      "Epoch [25/50], Step [128/735], Loss: 0.0283\n",
      "Epoch [25/50], Step [129/735], Loss: 0.1030\n",
      "Epoch [25/50], Step [130/735], Loss: 0.0403\n",
      "Epoch [25/50], Step [131/735], Loss: 0.0962\n",
      "Epoch [25/50], Step [132/735], Loss: 0.0392\n",
      "Epoch [25/50], Step [133/735], Loss: 0.0340\n",
      "Epoch [25/50], Step [134/735], Loss: 0.0594\n",
      "Epoch [25/50], Step [135/735], Loss: 0.0529\n",
      "Epoch [25/50], Step [136/735], Loss: 0.0565\n",
      "Epoch [25/50], Step [137/735], Loss: 0.0818\n",
      "Epoch [25/50], Step [138/735], Loss: 0.0985\n",
      "Epoch [25/50], Step [139/735], Loss: 0.0599\n",
      "Epoch [25/50], Step [140/735], Loss: 0.0302\n",
      "Epoch [25/50], Step [141/735], Loss: 0.0530\n",
      "Epoch [25/50], Step [142/735], Loss: 0.6439\n",
      "Epoch [25/50], Step [143/735], Loss: 0.0301\n",
      "Epoch [25/50], Step [144/735], Loss: 0.2087\n",
      "Epoch [25/50], Step [145/735], Loss: 0.0601\n",
      "Epoch [25/50], Step [146/735], Loss: 0.0243\n",
      "Epoch [25/50], Step [147/735], Loss: 0.0382\n",
      "Epoch [25/50], Step [148/735], Loss: 0.0252\n",
      "Epoch [25/50], Step [149/735], Loss: 0.0377\n",
      "Epoch [25/50], Step [150/735], Loss: 0.0620\n",
      "Epoch [25/50], Step [151/735], Loss: 0.1202\n",
      "Epoch [25/50], Step [152/735], Loss: 0.2186\n",
      "Epoch [25/50], Step [153/735], Loss: 0.0278\n",
      "Epoch [25/50], Step [154/735], Loss: 0.0787\n",
      "Epoch [25/50], Step [155/735], Loss: 0.0408\n",
      "Epoch [25/50], Step [156/735], Loss: 0.0359\n",
      "Epoch [25/50], Step [157/735], Loss: 0.1057\n",
      "Epoch [25/50], Step [158/735], Loss: 0.0383\n",
      "Epoch [25/50], Step [159/735], Loss: 0.0366\n",
      "Epoch [25/50], Step [160/735], Loss: 0.0527\n",
      "Epoch [25/50], Step [161/735], Loss: 0.1073\n",
      "Epoch [25/50], Step [162/735], Loss: 0.1012\n",
      "Epoch [25/50], Step [163/735], Loss: 0.0465\n",
      "Epoch [25/50], Step [164/735], Loss: 0.0922\n",
      "Epoch [25/50], Step [165/735], Loss: 0.0468\n",
      "Epoch [25/50], Step [166/735], Loss: 0.1111\n",
      "Epoch [25/50], Step [167/735], Loss: 0.0341\n",
      "Epoch [25/50], Step [168/735], Loss: 0.0392\n",
      "Epoch [25/50], Step [169/735], Loss: 0.0260\n",
      "Epoch [25/50], Step [170/735], Loss: 0.0405\n",
      "Epoch [25/50], Step [171/735], Loss: 0.3168\n",
      "Epoch [25/50], Step [172/735], Loss: 0.0154\n",
      "Epoch [25/50], Step [173/735], Loss: 0.1305\n",
      "Epoch [25/50], Step [174/735], Loss: 0.1200\n",
      "Epoch [25/50], Step [175/735], Loss: 0.1137\n",
      "Epoch [25/50], Step [176/735], Loss: 0.0751\n",
      "Epoch [25/50], Step [177/735], Loss: 0.0545\n",
      "Epoch [25/50], Step [178/735], Loss: 0.0340\n",
      "Epoch [25/50], Step [179/735], Loss: 0.0704\n",
      "Epoch [25/50], Step [180/735], Loss: 0.0530\n",
      "Epoch [25/50], Step [181/735], Loss: 0.0482\n",
      "Epoch [25/50], Step [182/735], Loss: 0.0547\n",
      "Epoch [25/50], Step [183/735], Loss: 0.1272\n",
      "Epoch [25/50], Step [184/735], Loss: 0.0971\n",
      "Epoch [25/50], Step [185/735], Loss: 0.0637\n",
      "Epoch [25/50], Step [186/735], Loss: 0.0705\n",
      "Epoch [25/50], Step [187/735], Loss: 0.0605\n",
      "Epoch [25/50], Step [188/735], Loss: 0.2275\n",
      "Epoch [25/50], Step [189/735], Loss: 0.0325\n",
      "Epoch [25/50], Step [190/735], Loss: 0.0386\n",
      "Epoch [25/50], Step [191/735], Loss: 0.0514\n",
      "Epoch [25/50], Step [192/735], Loss: 0.1086\n",
      "Epoch [25/50], Step [193/735], Loss: 0.0213\n",
      "Epoch [25/50], Step [194/735], Loss: 0.0384\n",
      "Epoch [25/50], Step [195/735], Loss: 0.0643\n",
      "Epoch [25/50], Step [196/735], Loss: 0.1056\n",
      "Epoch [25/50], Step [197/735], Loss: 0.0616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Step [198/735], Loss: 0.0618\n",
      "Epoch [25/50], Step [199/735], Loss: 0.1202\n",
      "Epoch [25/50], Step [200/735], Loss: 0.0503\n",
      "Epoch [25/50], Step [201/735], Loss: 0.0998\n",
      "Epoch [25/50], Step [202/735], Loss: 0.1268\n",
      "Epoch [25/50], Step [203/735], Loss: 0.0558\n",
      "Epoch [25/50], Step [204/735], Loss: 0.0304\n",
      "Epoch [25/50], Step [205/735], Loss: 0.0801\n",
      "Epoch [25/50], Step [206/735], Loss: 0.0890\n",
      "Epoch [25/50], Step [207/735], Loss: 0.0253\n",
      "Epoch [25/50], Step [208/735], Loss: 0.0266\n",
      "Epoch [25/50], Step [209/735], Loss: 0.0669\n",
      "Epoch [25/50], Step [210/735], Loss: 0.0629\n",
      "Epoch [25/50], Step [211/735], Loss: 0.0498\n",
      "Epoch [25/50], Step [212/735], Loss: 0.0759\n",
      "Epoch [25/50], Step [213/735], Loss: 0.0404\n",
      "Epoch [25/50], Step [214/735], Loss: 0.0467\n",
      "Epoch [25/50], Step [215/735], Loss: 0.0622\n",
      "Epoch [25/50], Step [216/735], Loss: 0.0358\n",
      "Epoch [25/50], Step [217/735], Loss: 0.0615\n",
      "Epoch [25/50], Step [218/735], Loss: 0.1603\n",
      "Epoch [25/50], Step [219/735], Loss: 0.0540\n",
      "Epoch [25/50], Step [220/735], Loss: 0.0478\n",
      "Epoch [25/50], Step [221/735], Loss: 0.0342\n",
      "Epoch [25/50], Step [222/735], Loss: 0.1983\n",
      "Epoch [25/50], Step [223/735], Loss: 0.1491\n",
      "Epoch [25/50], Step [224/735], Loss: 0.0530\n",
      "Epoch [25/50], Step [225/735], Loss: 0.0348\n",
      "Epoch [25/50], Step [226/735], Loss: 0.0452\n",
      "Epoch [25/50], Step [227/735], Loss: 0.3084\n",
      "Epoch [25/50], Step [228/735], Loss: 0.1519\n",
      "Epoch [25/50], Step [229/735], Loss: 0.0615\n",
      "Epoch [25/50], Step [230/735], Loss: 0.0436\n",
      "Epoch [25/50], Step [231/735], Loss: 0.0681\n",
      "Epoch [25/50], Step [232/735], Loss: 0.0456\n",
      "Epoch [25/50], Step [233/735], Loss: 0.3186\n",
      "Epoch [25/50], Step [234/735], Loss: 0.0401\n",
      "Epoch [25/50], Step [235/735], Loss: 0.0641\n",
      "Epoch [25/50], Step [236/735], Loss: 0.0340\n",
      "Epoch [25/50], Step [237/735], Loss: 0.0540\n",
      "Epoch [25/50], Step [238/735], Loss: 0.0609\n",
      "Epoch [25/50], Step [239/735], Loss: 0.0282\n",
      "Epoch [25/50], Step [240/735], Loss: 0.0203\n",
      "Epoch [25/50], Step [241/735], Loss: 0.0623\n",
      "Epoch [25/50], Step [242/735], Loss: 0.0404\n",
      "Epoch [25/50], Step [243/735], Loss: 0.2508\n",
      "Epoch [25/50], Step [244/735], Loss: 0.2128\n",
      "Epoch [25/50], Step [245/735], Loss: 0.0379\n",
      "Epoch [25/50], Step [246/735], Loss: 0.0560\n",
      "Epoch [25/50], Step [247/735], Loss: 0.1170\n",
      "Epoch [25/50], Step [248/735], Loss: 0.0325\n",
      "Epoch [25/50], Step [249/735], Loss: 0.0421\n",
      "Epoch [25/50], Step [250/735], Loss: 0.0633\n",
      "Epoch [25/50], Step [251/735], Loss: 0.0738\n",
      "Epoch [25/50], Step [252/735], Loss: 0.0498\n",
      "Epoch [25/50], Step [253/735], Loss: 0.1314\n",
      "Epoch [25/50], Step [254/735], Loss: 0.0639\n",
      "Epoch [25/50], Step [255/735], Loss: 0.0645\n",
      "Epoch [25/50], Step [256/735], Loss: 0.0388\n",
      "Epoch [25/50], Step [257/735], Loss: 0.0292\n",
      "Epoch [25/50], Step [258/735], Loss: 0.0362\n",
      "Epoch [25/50], Step [259/735], Loss: 0.0494\n",
      "Epoch [25/50], Step [260/735], Loss: 0.1415\n",
      "Epoch [25/50], Step [261/735], Loss: 0.0365\n",
      "Epoch [25/50], Step [262/735], Loss: 0.0827\n",
      "Epoch [25/50], Step [263/735], Loss: 0.0431\n",
      "Epoch [25/50], Step [264/735], Loss: 0.0408\n",
      "Epoch [25/50], Step [265/735], Loss: 0.0611\n",
      "Epoch [25/50], Step [266/735], Loss: 0.0312\n",
      "Epoch [25/50], Step [267/735], Loss: 0.0523\n",
      "Epoch [25/50], Step [268/735], Loss: 0.1045\n",
      "Epoch [25/50], Step [269/735], Loss: 0.2894\n",
      "Epoch [25/50], Step [270/735], Loss: 0.0666\n",
      "Epoch [25/50], Step [271/735], Loss: 0.0797\n",
      "Epoch [25/50], Step [272/735], Loss: 0.0708\n",
      "Epoch [25/50], Step [273/735], Loss: 0.0247\n",
      "Epoch [25/50], Step [274/735], Loss: 0.0490\n",
      "Epoch [25/50], Step [275/735], Loss: 0.2456\n",
      "Epoch [25/50], Step [276/735], Loss: 0.0840\n",
      "Epoch [25/50], Step [277/735], Loss: 0.0739\n",
      "Epoch [25/50], Step [278/735], Loss: 0.0478\n",
      "Epoch [25/50], Step [279/735], Loss: 0.0401\n",
      "Epoch [25/50], Step [280/735], Loss: 0.0269\n",
      "Epoch [25/50], Step [281/735], Loss: 0.0765\n",
      "Epoch [25/50], Step [282/735], Loss: 0.0379\n",
      "Epoch [25/50], Step [283/735], Loss: 0.0271\n",
      "Epoch [25/50], Step [284/735], Loss: 0.0247\n",
      "Epoch [25/50], Step [285/735], Loss: 0.0423\n",
      "Epoch [25/50], Step [286/735], Loss: 0.1326\n",
      "Epoch [25/50], Step [287/735], Loss: 0.0590\n",
      "Epoch [25/50], Step [288/735], Loss: 0.0418\n",
      "Epoch [25/50], Step [289/735], Loss: 0.0285\n",
      "Epoch [25/50], Step [290/735], Loss: 0.1251\n",
      "Epoch [25/50], Step [291/735], Loss: 0.0352\n",
      "Epoch [25/50], Step [292/735], Loss: 0.0654\n",
      "Epoch [25/50], Step [293/735], Loss: 0.0687\n",
      "Epoch [25/50], Step [294/735], Loss: 0.0336\n",
      "Epoch [25/50], Step [295/735], Loss: 0.0346\n",
      "Epoch [25/50], Step [296/735], Loss: 0.0313\n",
      "Epoch [25/50], Step [297/735], Loss: 0.0585\n",
      "Epoch [25/50], Step [298/735], Loss: 0.0619\n",
      "Epoch [25/50], Step [299/735], Loss: 0.0166\n",
      "Epoch [25/50], Step [300/735], Loss: 0.1228\n",
      "Epoch [25/50], Step [301/735], Loss: 0.0612\n",
      "Epoch [25/50], Step [302/735], Loss: 0.0705\n",
      "Epoch [25/50], Step [303/735], Loss: 0.0269\n",
      "Epoch [25/50], Step [304/735], Loss: 0.0262\n",
      "Epoch [25/50], Step [305/735], Loss: 0.0472\n",
      "Epoch [25/50], Step [306/735], Loss: 0.0435\n",
      "Epoch [25/50], Step [307/735], Loss: 0.2956\n",
      "Epoch [25/50], Step [308/735], Loss: 0.2477\n",
      "Epoch [25/50], Step [309/735], Loss: 0.0469\n",
      "Epoch [25/50], Step [310/735], Loss: 0.0659\n",
      "Epoch [25/50], Step [311/735], Loss: 0.2613\n",
      "Epoch [25/50], Step [312/735], Loss: 0.0420\n",
      "Epoch [25/50], Step [313/735], Loss: 0.0525\n",
      "Epoch [25/50], Step [314/735], Loss: 0.1028\n",
      "Epoch [25/50], Step [315/735], Loss: 0.1980\n",
      "Epoch [25/50], Step [316/735], Loss: 0.0364\n",
      "Epoch [25/50], Step [317/735], Loss: 0.0635\n",
      "Epoch [25/50], Step [318/735], Loss: 0.1077\n",
      "Epoch [25/50], Step [319/735], Loss: 0.0314\n",
      "Epoch [25/50], Step [320/735], Loss: 0.0508\n",
      "Epoch [25/50], Step [321/735], Loss: 0.0466\n",
      "Epoch [25/50], Step [322/735], Loss: 0.2170\n",
      "Epoch [25/50], Step [323/735], Loss: 0.0543\n",
      "Epoch [25/50], Step [324/735], Loss: 0.1031\n",
      "Epoch [25/50], Step [325/735], Loss: 0.0458\n",
      "Epoch [25/50], Step [326/735], Loss: 0.0532\n",
      "Epoch [25/50], Step [327/735], Loss: 0.0318\n",
      "Epoch [25/50], Step [328/735], Loss: 0.0672\n",
      "Epoch [25/50], Step [329/735], Loss: 0.1321\n",
      "Epoch [25/50], Step [330/735], Loss: 0.0433\n",
      "Epoch [25/50], Step [331/735], Loss: 0.0228\n",
      "Epoch [25/50], Step [332/735], Loss: 0.0427\n",
      "Epoch [25/50], Step [333/735], Loss: 0.2233\n",
      "Epoch [25/50], Step [334/735], Loss: 0.0655\n",
      "Epoch [25/50], Step [335/735], Loss: 0.2080\n",
      "Epoch [25/50], Step [336/735], Loss: 0.1586\n",
      "Epoch [25/50], Step [337/735], Loss: 0.1044\n",
      "Epoch [25/50], Step [338/735], Loss: 0.0329\n",
      "Epoch [25/50], Step [339/735], Loss: 0.0433\n",
      "Epoch [25/50], Step [340/735], Loss: 0.0483\n",
      "Epoch [25/50], Step [341/735], Loss: 0.0731\n",
      "Epoch [25/50], Step [342/735], Loss: 0.1164\n",
      "Epoch [25/50], Step [343/735], Loss: 0.0629\n",
      "Epoch [25/50], Step [344/735], Loss: 0.0351\n",
      "Epoch [25/50], Step [345/735], Loss: 0.1079\n",
      "Epoch [25/50], Step [346/735], Loss: 0.0316\n",
      "Epoch [25/50], Step [347/735], Loss: 0.0447\n",
      "Epoch [25/50], Step [348/735], Loss: 0.0654\n",
      "Epoch [25/50], Step [349/735], Loss: 0.0602\n",
      "Epoch [25/50], Step [350/735], Loss: 0.0193\n",
      "Epoch [25/50], Step [351/735], Loss: 0.0274\n",
      "Epoch [25/50], Step [352/735], Loss: 0.0320\n",
      "Epoch [25/50], Step [353/735], Loss: 0.0335\n",
      "Epoch [25/50], Step [354/735], Loss: 0.0764\n",
      "Epoch [25/50], Step [355/735], Loss: 0.0511\n",
      "Epoch [25/50], Step [356/735], Loss: 0.1422\n",
      "Epoch [25/50], Step [357/735], Loss: 0.0231\n",
      "Epoch [25/50], Step [358/735], Loss: 0.0767\n",
      "Epoch [25/50], Step [359/735], Loss: 0.0360\n",
      "Epoch [25/50], Step [360/735], Loss: 0.0260\n",
      "Epoch [25/50], Step [361/735], Loss: 0.0518\n",
      "Epoch [25/50], Step [362/735], Loss: 0.0247\n",
      "Epoch [25/50], Step [363/735], Loss: 0.0279\n",
      "Epoch [25/50], Step [364/735], Loss: 0.1168\n",
      "Epoch [25/50], Step [365/735], Loss: 0.0609\n",
      "Epoch [25/50], Step [366/735], Loss: 0.0462\n",
      "Epoch [25/50], Step [367/735], Loss: 0.0487\n",
      "Epoch [25/50], Step [368/735], Loss: 0.0682\n",
      "Epoch [25/50], Step [369/735], Loss: 0.3021\n",
      "Epoch [25/50], Step [370/735], Loss: 0.0283\n",
      "Epoch [25/50], Step [371/735], Loss: 0.0171\n",
      "Epoch [25/50], Step [372/735], Loss: 0.0408\n",
      "Epoch [25/50], Step [373/735], Loss: 0.0574\n",
      "Epoch [25/50], Step [374/735], Loss: 0.0916\n",
      "Epoch [25/50], Step [375/735], Loss: 0.0403\n",
      "Epoch [25/50], Step [376/735], Loss: 0.0423\n",
      "Epoch [25/50], Step [377/735], Loss: 0.0481\n",
      "Epoch [25/50], Step [378/735], Loss: 0.1043\n",
      "Epoch [25/50], Step [379/735], Loss: 0.0424\n",
      "Epoch [25/50], Step [380/735], Loss: 0.0852\n",
      "Epoch [25/50], Step [381/735], Loss: 0.0162\n",
      "Epoch [25/50], Step [382/735], Loss: 0.0590\n",
      "Epoch [25/50], Step [383/735], Loss: 0.0963\n",
      "Epoch [25/50], Step [384/735], Loss: 0.2122\n",
      "Epoch [25/50], Step [385/735], Loss: 0.1035\n",
      "Epoch [25/50], Step [386/735], Loss: 0.0335\n",
      "Epoch [25/50], Step [387/735], Loss: 0.0150\n",
      "Epoch [25/50], Step [388/735], Loss: 0.0729\n",
      "Epoch [25/50], Step [389/735], Loss: 0.0301\n",
      "Epoch [25/50], Step [390/735], Loss: 0.1288\n",
      "Epoch [25/50], Step [391/735], Loss: 0.0709\n",
      "Epoch [25/50], Step [392/735], Loss: 0.1839\n",
      "Epoch [25/50], Step [393/735], Loss: 0.0170\n",
      "Epoch [25/50], Step [394/735], Loss: 0.1275\n",
      "Epoch [25/50], Step [395/735], Loss: 0.0657\n",
      "Epoch [25/50], Step [396/735], Loss: 0.0732\n",
      "Epoch [25/50], Step [397/735], Loss: 0.0161\n",
      "Epoch [25/50], Step [398/735], Loss: 0.0372\n",
      "Epoch [25/50], Step [399/735], Loss: 0.0562\n",
      "Epoch [25/50], Step [400/735], Loss: 0.0361\n",
      "Epoch [25/50], Step [401/735], Loss: 0.0740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Step [402/735], Loss: 0.0538\n",
      "Epoch [25/50], Step [403/735], Loss: 0.0271\n",
      "Epoch [25/50], Step [404/735], Loss: 0.1409\n",
      "Epoch [25/50], Step [405/735], Loss: 0.0463\n",
      "Epoch [25/50], Step [406/735], Loss: 0.1635\n",
      "Epoch [25/50], Step [407/735], Loss: 0.0974\n",
      "Epoch [25/50], Step [408/735], Loss: 0.1124\n",
      "Epoch [25/50], Step [409/735], Loss: 0.1504\n",
      "Epoch [25/50], Step [410/735], Loss: 0.0408\n",
      "Epoch [25/50], Step [411/735], Loss: 0.0209\n",
      "Epoch [25/50], Step [412/735], Loss: 0.0349\n",
      "Epoch [25/50], Step [413/735], Loss: 0.1404\n",
      "Epoch [25/50], Step [414/735], Loss: 0.0439\n",
      "Epoch [25/50], Step [415/735], Loss: 0.0542\n",
      "Epoch [25/50], Step [416/735], Loss: 0.1760\n",
      "Epoch [25/50], Step [417/735], Loss: 0.1170\n",
      "Epoch [25/50], Step [418/735], Loss: 0.1247\n",
      "Epoch [25/50], Step [419/735], Loss: 0.0754\n",
      "Epoch [25/50], Step [420/735], Loss: 0.0448\n",
      "Epoch [25/50], Step [421/735], Loss: 0.0656\n",
      "Epoch [25/50], Step [422/735], Loss: 0.0813\n",
      "Epoch [25/50], Step [423/735], Loss: 0.0305\n",
      "Epoch [25/50], Step [424/735], Loss: 0.0529\n",
      "Epoch [25/50], Step [425/735], Loss: 0.0968\n",
      "Epoch [25/50], Step [426/735], Loss: 0.0263\n",
      "Epoch [25/50], Step [427/735], Loss: 0.0433\n",
      "Epoch [25/50], Step [428/735], Loss: 0.0585\n",
      "Epoch [25/50], Step [429/735], Loss: 0.0307\n",
      "Epoch [25/50], Step [430/735], Loss: 0.0193\n",
      "Epoch [25/50], Step [431/735], Loss: 0.0533\n",
      "Epoch [25/50], Step [432/735], Loss: 0.0584\n",
      "Epoch [25/50], Step [433/735], Loss: 0.0676\n",
      "Epoch [25/50], Step [434/735], Loss: 0.2591\n",
      "Epoch [25/50], Step [435/735], Loss: 0.0820\n",
      "Epoch [25/50], Step [436/735], Loss: 0.1204\n",
      "Epoch [25/50], Step [437/735], Loss: 0.0250\n",
      "Epoch [25/50], Step [438/735], Loss: 0.0274\n",
      "Epoch [25/50], Step [439/735], Loss: 0.0290\n",
      "Epoch [25/50], Step [440/735], Loss: 0.0441\n",
      "Epoch [25/50], Step [441/735], Loss: 0.5224\n",
      "Epoch [25/50], Step [442/735], Loss: 0.0401\n",
      "Epoch [25/50], Step [443/735], Loss: 0.0749\n",
      "Epoch [25/50], Step [444/735], Loss: 0.0280\n",
      "Epoch [25/50], Step [445/735], Loss: 0.1082\n",
      "Epoch [25/50], Step [446/735], Loss: 0.0363\n",
      "Epoch [25/50], Step [447/735], Loss: 0.1483\n",
      "Epoch [25/50], Step [448/735], Loss: 0.5220\n",
      "Epoch [25/50], Step [449/735], Loss: 0.0757\n",
      "Epoch [25/50], Step [450/735], Loss: 0.0531\n",
      "Epoch [25/50], Step [451/735], Loss: 0.1110\n",
      "Epoch [25/50], Step [452/735], Loss: 0.0422\n",
      "Epoch [25/50], Step [453/735], Loss: 0.0898\n",
      "Epoch [25/50], Step [454/735], Loss: 0.0672\n",
      "Epoch [25/50], Step [455/735], Loss: 0.0306\n",
      "Epoch [25/50], Step [456/735], Loss: 0.0359\n",
      "Epoch [25/50], Step [457/735], Loss: 0.0458\n",
      "Epoch [25/50], Step [458/735], Loss: 0.0295\n",
      "Epoch [25/50], Step [459/735], Loss: 0.0775\n",
      "Epoch [25/50], Step [460/735], Loss: 0.1608\n",
      "Epoch [25/50], Step [461/735], Loss: 0.2114\n",
      "Epoch [25/50], Step [462/735], Loss: 0.1731\n",
      "Epoch [25/50], Step [463/735], Loss: 0.1057\n",
      "Epoch [25/50], Step [464/735], Loss: 0.0418\n",
      "Epoch [25/50], Step [465/735], Loss: 0.0317\n",
      "Epoch [25/50], Step [466/735], Loss: 0.0899\n",
      "Epoch [25/50], Step [467/735], Loss: 0.1800\n",
      "Epoch [25/50], Step [468/735], Loss: 0.0711\n",
      "Epoch [25/50], Step [469/735], Loss: 0.0372\n",
      "Epoch [25/50], Step [470/735], Loss: 0.0981\n",
      "Epoch [25/50], Step [471/735], Loss: 0.0343\n",
      "Epoch [25/50], Step [472/735], Loss: 0.1311\n",
      "Epoch [25/50], Step [473/735], Loss: 0.0163\n",
      "Epoch [25/50], Step [474/735], Loss: 0.0209\n",
      "Epoch [25/50], Step [475/735], Loss: 0.0657\n",
      "Epoch [25/50], Step [476/735], Loss: 0.0241\n",
      "Epoch [25/50], Step [477/735], Loss: 0.0374\n",
      "Epoch [25/50], Step [478/735], Loss: 0.0286\n",
      "Epoch [25/50], Step [479/735], Loss: 0.0444\n",
      "Epoch [25/50], Step [480/735], Loss: 0.0799\n",
      "Epoch [25/50], Step [481/735], Loss: 0.0471\n",
      "Epoch [25/50], Step [482/735], Loss: 0.0253\n",
      "Epoch [25/50], Step [483/735], Loss: 0.2622\n",
      "Epoch [25/50], Step [484/735], Loss: 0.0391\n",
      "Epoch [25/50], Step [485/735], Loss: 0.0633\n",
      "Epoch [25/50], Step [486/735], Loss: 0.1362\n",
      "Epoch [25/50], Step [487/735], Loss: 0.0807\n",
      "Epoch [25/50], Step [488/735], Loss: 0.0256\n",
      "Epoch [25/50], Step [489/735], Loss: 0.0895\n",
      "Epoch [25/50], Step [490/735], Loss: 0.0444\n",
      "Epoch [25/50], Step [491/735], Loss: 0.0345\n",
      "Epoch [25/50], Step [492/735], Loss: 0.0915\n",
      "Epoch [25/50], Step [493/735], Loss: 0.1325\n",
      "Epoch [25/50], Step [494/735], Loss: 0.4288\n",
      "Epoch [25/50], Step [495/735], Loss: 0.0339\n",
      "Epoch [25/50], Step [496/735], Loss: 0.0558\n",
      "Epoch [25/50], Step [497/735], Loss: 0.0657\n",
      "Epoch [25/50], Step [498/735], Loss: 0.0676\n",
      "Epoch [25/50], Step [499/735], Loss: 0.0322\n",
      "Epoch [25/50], Step [500/735], Loss: 0.0529\n",
      "Epoch [25/50], Step [501/735], Loss: 0.0629\n",
      "Epoch [25/50], Step [502/735], Loss: 0.0707\n",
      "Epoch [25/50], Step [503/735], Loss: 0.3822\n",
      "Epoch [25/50], Step [504/735], Loss: 0.1448\n",
      "Epoch [25/50], Step [505/735], Loss: 0.0583\n",
      "Epoch [25/50], Step [506/735], Loss: 0.0335\n",
      "Epoch [25/50], Step [507/735], Loss: 0.0449\n",
      "Epoch [25/50], Step [508/735], Loss: 0.1186\n",
      "Epoch [25/50], Step [509/735], Loss: 0.0281\n",
      "Epoch [25/50], Step [510/735], Loss: 0.0226\n",
      "Epoch [25/50], Step [511/735], Loss: 0.1409\n",
      "Epoch [25/50], Step [512/735], Loss: 0.0546\n",
      "Epoch [25/50], Step [513/735], Loss: 0.0269\n",
      "Epoch [25/50], Step [514/735], Loss: 0.0896\n",
      "Epoch [25/50], Step [515/735], Loss: 0.0724\n",
      "Epoch [25/50], Step [516/735], Loss: 0.0192\n",
      "Epoch [25/50], Step [517/735], Loss: 0.0447\n",
      "Epoch [25/50], Step [518/735], Loss: 0.1249\n",
      "Epoch [25/50], Step [519/735], Loss: 0.0570\n",
      "Epoch [25/50], Step [520/735], Loss: 0.0479\n",
      "Epoch [25/50], Step [521/735], Loss: 0.1445\n",
      "Epoch [25/50], Step [522/735], Loss: 0.0740\n",
      "Epoch [25/50], Step [523/735], Loss: 0.0260\n",
      "Epoch [25/50], Step [524/735], Loss: 0.0731\n",
      "Epoch [25/50], Step [525/735], Loss: 0.0445\n",
      "Epoch [25/50], Step [526/735], Loss: 0.0355\n",
      "Epoch [25/50], Step [527/735], Loss: 0.0697\n",
      "Epoch [25/50], Step [528/735], Loss: 0.0201\n",
      "Epoch [25/50], Step [529/735], Loss: 0.0433\n",
      "Epoch [25/50], Step [530/735], Loss: 0.0418\n",
      "Epoch [25/50], Step [531/735], Loss: 0.0584\n",
      "Epoch [25/50], Step [532/735], Loss: 0.0323\n",
      "Epoch [25/50], Step [533/735], Loss: 0.0441\n",
      "Epoch [25/50], Step [534/735], Loss: 0.0598\n",
      "Epoch [25/50], Step [535/735], Loss: 0.0590\n",
      "Epoch [25/50], Step [536/735], Loss: 0.1019\n",
      "Epoch [25/50], Step [537/735], Loss: 0.0385\n",
      "Epoch [25/50], Step [538/735], Loss: 0.1177\n",
      "Epoch [25/50], Step [539/735], Loss: 0.0406\n",
      "Epoch [25/50], Step [540/735], Loss: 0.0542\n",
      "Epoch [25/50], Step [541/735], Loss: 0.0212\n",
      "Epoch [25/50], Step [542/735], Loss: 0.0901\n",
      "Epoch [25/50], Step [543/735], Loss: 0.0384\n",
      "Epoch [25/50], Step [544/735], Loss: 0.0447\n",
      "Epoch [25/50], Step [545/735], Loss: 0.0380\n",
      "Epoch [25/50], Step [546/735], Loss: 0.0580\n",
      "Epoch [25/50], Step [547/735], Loss: 0.0293\n",
      "Epoch [25/50], Step [548/735], Loss: 0.0387\n",
      "Epoch [25/50], Step [549/735], Loss: 0.2203\n",
      "Epoch [25/50], Step [550/735], Loss: 0.0232\n",
      "Epoch [25/50], Step [551/735], Loss: 0.0823\n",
      "Epoch [25/50], Step [552/735], Loss: 0.1343\n",
      "Epoch [25/50], Step [553/735], Loss: 0.0417\n",
      "Epoch [25/50], Step [554/735], Loss: 0.1009\n",
      "Epoch [25/50], Step [555/735], Loss: 0.0543\n",
      "Epoch [25/50], Step [556/735], Loss: 0.1188\n",
      "Epoch [25/50], Step [557/735], Loss: 0.1121\n",
      "Epoch [25/50], Step [558/735], Loss: 0.0531\n",
      "Epoch [25/50], Step [559/735], Loss: 0.0343\n",
      "Epoch [25/50], Step [560/735], Loss: 0.1436\n",
      "Epoch [25/50], Step [561/735], Loss: 0.0604\n",
      "Epoch [25/50], Step [562/735], Loss: 0.1403\n",
      "Epoch [25/50], Step [563/735], Loss: 0.0279\n",
      "Epoch [25/50], Step [564/735], Loss: 0.0971\n",
      "Epoch [25/50], Step [565/735], Loss: 0.0250\n",
      "Epoch [25/50], Step [566/735], Loss: 0.0231\n",
      "Epoch [25/50], Step [567/735], Loss: 0.0466\n",
      "Epoch [25/50], Step [568/735], Loss: 0.0647\n",
      "Epoch [25/50], Step [569/735], Loss: 0.0446\n",
      "Epoch [25/50], Step [570/735], Loss: 0.0992\n",
      "Epoch [25/50], Step [571/735], Loss: 0.0535\n",
      "Epoch [25/50], Step [572/735], Loss: 0.0663\n",
      "Epoch [25/50], Step [573/735], Loss: 0.0706\n",
      "Epoch [25/50], Step [574/735], Loss: 0.0278\n",
      "Epoch [25/50], Step [575/735], Loss: 0.0773\n",
      "Epoch [25/50], Step [576/735], Loss: 0.1373\n",
      "Epoch [25/50], Step [577/735], Loss: 0.0771\n",
      "Epoch [25/50], Step [578/735], Loss: 0.0687\n",
      "Epoch [25/50], Step [579/735], Loss: 0.1308\n",
      "Epoch [25/50], Step [580/735], Loss: 0.0519\n",
      "Epoch [25/50], Step [581/735], Loss: 0.1359\n",
      "Epoch [25/50], Step [582/735], Loss: 0.3295\n",
      "Epoch [25/50], Step [583/735], Loss: 0.1632\n",
      "Epoch [25/50], Step [584/735], Loss: 0.0834\n",
      "Epoch [25/50], Step [585/735], Loss: 0.1963\n",
      "Epoch [25/50], Step [586/735], Loss: 0.0961\n",
      "Epoch [25/50], Step [587/735], Loss: 0.1943\n",
      "Epoch [25/50], Step [588/735], Loss: 0.0340\n",
      "Epoch [25/50], Step [589/735], Loss: 0.1304\n",
      "Epoch [25/50], Step [590/735], Loss: 0.1013\n",
      "Epoch [25/50], Step [591/735], Loss: 0.1670\n",
      "Epoch [25/50], Step [592/735], Loss: 0.1215\n",
      "Epoch [25/50], Step [593/735], Loss: 0.1812\n",
      "Epoch [25/50], Step [594/735], Loss: 0.0712\n",
      "Epoch [25/50], Step [595/735], Loss: 0.1159\n",
      "Epoch [25/50], Step [596/735], Loss: 0.0366\n",
      "Epoch [25/50], Step [597/735], Loss: 0.5271\n",
      "Epoch [25/50], Step [598/735], Loss: 0.1158\n",
      "Epoch [25/50], Step [599/735], Loss: 0.2102\n",
      "Epoch [25/50], Step [600/735], Loss: 0.0727\n",
      "Epoch [25/50], Step [601/735], Loss: 0.0669\n",
      "Epoch [25/50], Step [602/735], Loss: 0.1744\n",
      "Epoch [25/50], Step [603/735], Loss: 0.0627\n",
      "Epoch [25/50], Step [604/735], Loss: 0.1670\n",
      "Epoch [25/50], Step [605/735], Loss: 0.0440\n",
      "Epoch [25/50], Step [606/735], Loss: 0.0903\n",
      "Epoch [25/50], Step [607/735], Loss: 0.0733\n",
      "Epoch [25/50], Step [608/735], Loss: 0.0366\n",
      "Epoch [25/50], Step [609/735], Loss: 0.1968\n",
      "Epoch [25/50], Step [610/735], Loss: 0.0679\n",
      "Epoch [25/50], Step [611/735], Loss: 0.1273\n",
      "Epoch [25/50], Step [612/735], Loss: 0.0576\n",
      "Epoch [25/50], Step [613/735], Loss: 0.0726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Step [614/735], Loss: 0.0632\n",
      "Epoch [25/50], Step [615/735], Loss: 0.0503\n",
      "Epoch [25/50], Step [616/735], Loss: 0.0268\n",
      "Epoch [25/50], Step [617/735], Loss: 0.0571\n",
      "Epoch [25/50], Step [618/735], Loss: 0.0538\n",
      "Epoch [25/50], Step [619/735], Loss: 0.0140\n",
      "Epoch [25/50], Step [620/735], Loss: 0.0523\n",
      "Epoch [25/50], Step [621/735], Loss: 0.0341\n",
      "Epoch [25/50], Step [622/735], Loss: 0.4753\n",
      "Epoch [25/50], Step [623/735], Loss: 0.0483\n",
      "Epoch [25/50], Step [624/735], Loss: 0.0259\n",
      "Epoch [25/50], Step [625/735], Loss: 0.0669\n",
      "Epoch [25/50], Step [626/735], Loss: 0.0503\n",
      "Epoch [25/50], Step [627/735], Loss: 0.1555\n",
      "Epoch [25/50], Step [628/735], Loss: 0.0970\n",
      "Epoch [25/50], Step [629/735], Loss: 0.1324\n",
      "Epoch [25/50], Step [630/735], Loss: 0.0431\n",
      "Epoch [25/50], Step [631/735], Loss: 0.0684\n",
      "Epoch [25/50], Step [632/735], Loss: 0.0847\n",
      "Epoch [25/50], Step [633/735], Loss: 0.1336\n",
      "Epoch [25/50], Step [634/735], Loss: 0.1377\n",
      "Epoch [25/50], Step [635/735], Loss: 0.1906\n",
      "Epoch [25/50], Step [636/735], Loss: 0.0509\n",
      "Epoch [25/50], Step [637/735], Loss: 0.0274\n",
      "Epoch [25/50], Step [638/735], Loss: 0.1013\n",
      "Epoch [25/50], Step [639/735], Loss: 0.0645\n",
      "Epoch [25/50], Step [640/735], Loss: 0.0650\n",
      "Epoch [25/50], Step [641/735], Loss: 0.0294\n",
      "Epoch [25/50], Step [642/735], Loss: 0.0527\n",
      "Epoch [25/50], Step [643/735], Loss: 0.0225\n",
      "Epoch [25/50], Step [644/735], Loss: 0.3657\n",
      "Epoch [25/50], Step [645/735], Loss: 0.0633\n",
      "Epoch [25/50], Step [646/735], Loss: 0.0403\n",
      "Epoch [25/50], Step [647/735], Loss: 0.0353\n",
      "Epoch [25/50], Step [648/735], Loss: 0.0378\n",
      "Epoch [25/50], Step [649/735], Loss: 0.0992\n",
      "Epoch [25/50], Step [650/735], Loss: 0.2257\n",
      "Epoch [25/50], Step [651/735], Loss: 0.0870\n",
      "Epoch [25/50], Step [652/735], Loss: 0.1114\n",
      "Epoch [25/50], Step [653/735], Loss: 0.0517\n",
      "Epoch [25/50], Step [654/735], Loss: 0.0334\n",
      "Epoch [25/50], Step [655/735], Loss: 0.0638\n",
      "Epoch [25/50], Step [656/735], Loss: 0.0572\n",
      "Epoch [25/50], Step [657/735], Loss: 0.0829\n",
      "Epoch [25/50], Step [658/735], Loss: 0.0182\n",
      "Epoch [25/50], Step [659/735], Loss: 0.2448\n",
      "Epoch [25/50], Step [660/735], Loss: 0.1120\n",
      "Epoch [25/50], Step [661/735], Loss: 0.0578\n",
      "Epoch [25/50], Step [662/735], Loss: 0.0624\n",
      "Epoch [25/50], Step [663/735], Loss: 0.0421\n",
      "Epoch [25/50], Step [664/735], Loss: 0.2351\n",
      "Epoch [25/50], Step [665/735], Loss: 0.0986\n",
      "Epoch [25/50], Step [666/735], Loss: 0.1135\n",
      "Epoch [25/50], Step [667/735], Loss: 0.3875\n",
      "Epoch [25/50], Step [668/735], Loss: 0.1036\n",
      "Epoch [25/50], Step [669/735], Loss: 0.0367\n",
      "Epoch [25/50], Step [670/735], Loss: 0.0602\n",
      "Epoch [25/50], Step [671/735], Loss: 0.0835\n",
      "Epoch [25/50], Step [672/735], Loss: 0.0231\n",
      "Epoch [25/50], Step [673/735], Loss: 0.0871\n",
      "Epoch [25/50], Step [674/735], Loss: 0.1192\n",
      "Epoch [25/50], Step [675/735], Loss: 0.0556\n",
      "Epoch [25/50], Step [676/735], Loss: 0.0469\n",
      "Epoch [25/50], Step [677/735], Loss: 0.0336\n",
      "Epoch [25/50], Step [678/735], Loss: 0.0283\n",
      "Epoch [25/50], Step [679/735], Loss: 0.0964\n",
      "Epoch [25/50], Step [680/735], Loss: 0.0675\n",
      "Epoch [25/50], Step [681/735], Loss: 0.0642\n",
      "Epoch [25/50], Step [682/735], Loss: 0.0180\n",
      "Epoch [25/50], Step [683/735], Loss: 0.0332\n",
      "Epoch [25/50], Step [684/735], Loss: 0.0727\n",
      "Epoch [25/50], Step [685/735], Loss: 0.0684\n",
      "Epoch [25/50], Step [686/735], Loss: 0.0318\n",
      "Epoch [25/50], Step [687/735], Loss: 0.0278\n",
      "Epoch [25/50], Step [688/735], Loss: 0.0758\n",
      "Epoch [25/50], Step [689/735], Loss: 0.0268\n",
      "Epoch [25/50], Step [690/735], Loss: 0.1441\n",
      "Epoch [25/50], Step [691/735], Loss: 0.0560\n",
      "Epoch [25/50], Step [692/735], Loss: 0.0312\n",
      "Epoch [25/50], Step [693/735], Loss: 0.0534\n",
      "Epoch [25/50], Step [694/735], Loss: 0.0702\n",
      "Epoch [25/50], Step [695/735], Loss: 0.0451\n",
      "Epoch [25/50], Step [696/735], Loss: 0.0443\n",
      "Epoch [25/50], Step [697/735], Loss: 0.0797\n",
      "Epoch [25/50], Step [698/735], Loss: 0.0753\n",
      "Epoch [25/50], Step [699/735], Loss: 0.0319\n",
      "Epoch [25/50], Step [700/735], Loss: 0.0300\n",
      "Epoch [25/50], Step [701/735], Loss: 0.0868\n",
      "Epoch [25/50], Step [702/735], Loss: 0.0459\n",
      "Epoch [25/50], Step [703/735], Loss: 0.1065\n",
      "Epoch [25/50], Step [704/735], Loss: 0.0258\n",
      "Epoch [25/50], Step [705/735], Loss: 0.2279\n",
      "Epoch [25/50], Step [706/735], Loss: 0.0497\n",
      "Epoch [25/50], Step [707/735], Loss: 0.0316\n",
      "Epoch [25/50], Step [708/735], Loss: 0.0289\n",
      "Epoch [25/50], Step [709/735], Loss: 0.0282\n",
      "Epoch [25/50], Step [710/735], Loss: 0.0305\n",
      "Epoch [25/50], Step [711/735], Loss: 0.0287\n",
      "Epoch [25/50], Step [712/735], Loss: 0.0628\n",
      "Epoch [25/50], Step [713/735], Loss: 0.3029\n",
      "Epoch [25/50], Step [714/735], Loss: 0.1078\n",
      "Epoch [25/50], Step [715/735], Loss: 0.0529\n",
      "Epoch [25/50], Step [716/735], Loss: 0.0764\n",
      "Epoch [25/50], Step [717/735], Loss: 0.0373\n",
      "Epoch [25/50], Step [718/735], Loss: 0.0525\n",
      "Epoch [25/50], Step [719/735], Loss: 0.0779\n",
      "Epoch [25/50], Step [720/735], Loss: 0.0561\n",
      "Epoch [25/50], Step [721/735], Loss: 0.1434\n",
      "Epoch [25/50], Step [722/735], Loss: 0.2094\n",
      "Epoch [25/50], Step [723/735], Loss: 0.0445\n",
      "Epoch [25/50], Step [724/735], Loss: 0.1475\n",
      "Epoch [25/50], Step [725/735], Loss: 0.0502\n",
      "Epoch [25/50], Step [726/735], Loss: 0.0640\n",
      "Epoch [25/50], Step [727/735], Loss: 0.0477\n",
      "Epoch [25/50], Step [728/735], Loss: 0.0398\n",
      "Epoch [25/50], Step [729/735], Loss: 0.0416\n",
      "Epoch [25/50], Step [730/735], Loss: 0.0435\n",
      "Epoch [25/50], Step [731/735], Loss: 0.0367\n",
      "Epoch [25/50], Step [732/735], Loss: 0.0885\n",
      "Epoch [25/50], Step [733/735], Loss: 0.0221\n",
      "Epoch [25/50], Step [734/735], Loss: 0.0420\n",
      "Epoch [25/50], Step [735/735], Loss: 0.0201\n",
      "Epoch [26/50], Step [1/735], Loss: 0.0578\n",
      "Epoch [26/50], Step [2/735], Loss: 0.0250\n",
      "Epoch [26/50], Step [3/735], Loss: 0.0655\n",
      "Epoch [26/50], Step [4/735], Loss: 0.0443\n",
      "Epoch [26/50], Step [5/735], Loss: 0.0648\n",
      "Epoch [26/50], Step [6/735], Loss: 0.0723\n",
      "Epoch [26/50], Step [7/735], Loss: 0.0745\n",
      "Epoch [26/50], Step [8/735], Loss: 0.0405\n",
      "Epoch [26/50], Step [9/735], Loss: 0.0182\n",
      "Epoch [26/50], Step [10/735], Loss: 0.1989\n",
      "Epoch [26/50], Step [11/735], Loss: 0.0356\n",
      "Epoch [26/50], Step [12/735], Loss: 0.0288\n",
      "Epoch [26/50], Step [13/735], Loss: 0.0356\n",
      "Epoch [26/50], Step [14/735], Loss: 0.1060\n",
      "Epoch [26/50], Step [15/735], Loss: 0.0928\n",
      "Epoch [26/50], Step [16/735], Loss: 0.0578\n",
      "Epoch [26/50], Step [17/735], Loss: 0.1126\n",
      "Epoch [26/50], Step [18/735], Loss: 0.0731\n",
      "Epoch [26/50], Step [19/735], Loss: 0.0310\n",
      "Epoch [26/50], Step [20/735], Loss: 0.0711\n",
      "Epoch [26/50], Step [21/735], Loss: 0.1567\n",
      "Epoch [26/50], Step [22/735], Loss: 0.0212\n",
      "Epoch [26/50], Step [23/735], Loss: 0.0633\n",
      "Epoch [26/50], Step [24/735], Loss: 0.0425\n",
      "Epoch [26/50], Step [25/735], Loss: 0.1742\n",
      "Epoch [26/50], Step [26/735], Loss: 0.1406\n",
      "Epoch [26/50], Step [27/735], Loss: 0.0813\n",
      "Epoch [26/50], Step [28/735], Loss: 0.0454\n",
      "Epoch [26/50], Step [29/735], Loss: 0.1334\n",
      "Epoch [26/50], Step [30/735], Loss: 0.0331\n",
      "Epoch [26/50], Step [31/735], Loss: 0.0177\n",
      "Epoch [26/50], Step [32/735], Loss: 0.0610\n",
      "Epoch [26/50], Step [33/735], Loss: 0.3025\n",
      "Epoch [26/50], Step [34/735], Loss: 0.0323\n",
      "Epoch [26/50], Step [35/735], Loss: 0.0378\n",
      "Epoch [26/50], Step [36/735], Loss: 0.0478\n",
      "Epoch [26/50], Step [37/735], Loss: 0.0352\n",
      "Epoch [26/50], Step [38/735], Loss: 0.1137\n",
      "Epoch [26/50], Step [39/735], Loss: 0.0466\n",
      "Epoch [26/50], Step [40/735], Loss: 0.0557\n",
      "Epoch [26/50], Step [41/735], Loss: 0.2104\n",
      "Epoch [26/50], Step [42/735], Loss: 0.0609\n",
      "Epoch [26/50], Step [43/735], Loss: 0.0352\n",
      "Epoch [26/50], Step [44/735], Loss: 0.0665\n",
      "Epoch [26/50], Step [45/735], Loss: 0.0438\n",
      "Epoch [26/50], Step [46/735], Loss: 0.0381\n",
      "Epoch [26/50], Step [47/735], Loss: 0.0286\n",
      "Epoch [26/50], Step [48/735], Loss: 0.0368\n",
      "Epoch [26/50], Step [49/735], Loss: 0.1008\n",
      "Epoch [26/50], Step [50/735], Loss: 0.1185\n",
      "Epoch [26/50], Step [51/735], Loss: 0.0701\n",
      "Epoch [26/50], Step [52/735], Loss: 0.0579\n",
      "Epoch [26/50], Step [53/735], Loss: 0.0803\n",
      "Epoch [26/50], Step [54/735], Loss: 0.0497\n",
      "Epoch [26/50], Step [55/735], Loss: 0.0772\n",
      "Epoch [26/50], Step [56/735], Loss: 0.1191\n",
      "Epoch [26/50], Step [57/735], Loss: 0.0413\n",
      "Epoch [26/50], Step [58/735], Loss: 0.0203\n",
      "Epoch [26/50], Step [59/735], Loss: 0.0657\n",
      "Epoch [26/50], Step [60/735], Loss: 0.1046\n",
      "Epoch [26/50], Step [61/735], Loss: 0.0900\n",
      "Epoch [26/50], Step [62/735], Loss: 0.0517\n",
      "Epoch [26/50], Step [63/735], Loss: 0.0266\n",
      "Epoch [26/50], Step [64/735], Loss: 0.0305\n",
      "Epoch [26/50], Step [65/735], Loss: 0.0431\n",
      "Epoch [26/50], Step [66/735], Loss: 0.0243\n",
      "Epoch [26/50], Step [67/735], Loss: 0.0481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Step [68/735], Loss: 0.1126\n",
      "Epoch [26/50], Step [69/735], Loss: 0.0432\n",
      "Epoch [26/50], Step [70/735], Loss: 0.1116\n",
      "Epoch [26/50], Step [71/735], Loss: 0.0570\n",
      "Epoch [26/50], Step [72/735], Loss: 0.0238\n",
      "Epoch [26/50], Step [73/735], Loss: 0.0803\n",
      "Epoch [26/50], Step [74/735], Loss: 0.0498\n",
      "Epoch [26/50], Step [75/735], Loss: 0.0485\n",
      "Epoch [26/50], Step [76/735], Loss: 0.1758\n",
      "Epoch [26/50], Step [77/735], Loss: 0.0572\n",
      "Epoch [26/50], Step [78/735], Loss: 0.0243\n",
      "Epoch [26/50], Step [79/735], Loss: 0.0785\n",
      "Epoch [26/50], Step [80/735], Loss: 0.0681\n",
      "Epoch [26/50], Step [81/735], Loss: 0.0288\n",
      "Epoch [26/50], Step [82/735], Loss: 0.1133\n",
      "Epoch [26/50], Step [83/735], Loss: 0.0717\n",
      "Epoch [26/50], Step [84/735], Loss: 0.0666\n",
      "Epoch [26/50], Step [85/735], Loss: 0.1206\n",
      "Epoch [26/50], Step [86/735], Loss: 0.0272\n",
      "Epoch [26/50], Step [87/735], Loss: 0.0144\n",
      "Epoch [26/50], Step [88/735], Loss: 0.0383\n",
      "Epoch [26/50], Step [89/735], Loss: 0.1064\n",
      "Epoch [26/50], Step [90/735], Loss: 0.0443\n",
      "Epoch [26/50], Step [91/735], Loss: 0.0499\n",
      "Epoch [26/50], Step [92/735], Loss: 0.0676\n",
      "Epoch [26/50], Step [93/735], Loss: 0.1278\n",
      "Epoch [26/50], Step [94/735], Loss: 0.0301\n",
      "Epoch [26/50], Step [95/735], Loss: 0.3561\n",
      "Epoch [26/50], Step [96/735], Loss: 0.0429\n",
      "Epoch [26/50], Step [97/735], Loss: 0.0573\n",
      "Epoch [26/50], Step [98/735], Loss: 0.0938\n",
      "Epoch [26/50], Step [99/735], Loss: 0.1439\n",
      "Epoch [26/50], Step [100/735], Loss: 0.0664\n",
      "Epoch [26/50], Step [101/735], Loss: 0.0526\n",
      "Epoch [26/50], Step [102/735], Loss: 0.0881\n",
      "Epoch [26/50], Step [103/735], Loss: 0.1000\n",
      "Epoch [26/50], Step [104/735], Loss: 0.0842\n",
      "Epoch [26/50], Step [105/735], Loss: 0.1608\n",
      "Epoch [26/50], Step [106/735], Loss: 0.0438\n",
      "Epoch [26/50], Step [107/735], Loss: 0.1351\n",
      "Epoch [26/50], Step [108/735], Loss: 0.0257\n",
      "Epoch [26/50], Step [109/735], Loss: 0.0652\n",
      "Epoch [26/50], Step [110/735], Loss: 0.0442\n",
      "Epoch [26/50], Step [111/735], Loss: 0.0538\n",
      "Epoch [26/50], Step [112/735], Loss: 0.0319\n",
      "Epoch [26/50], Step [113/735], Loss: 0.0331\n",
      "Epoch [26/50], Step [114/735], Loss: 0.0899\n",
      "Epoch [26/50], Step [115/735], Loss: 0.0464\n",
      "Epoch [26/50], Step [116/735], Loss: 0.1226\n",
      "Epoch [26/50], Step [117/735], Loss: 0.1688\n",
      "Epoch [26/50], Step [118/735], Loss: 0.0453\n",
      "Epoch [26/50], Step [119/735], Loss: 0.0852\n",
      "Epoch [26/50], Step [120/735], Loss: 0.2993\n",
      "Epoch [26/50], Step [121/735], Loss: 0.0671\n",
      "Epoch [26/50], Step [122/735], Loss: 0.0640\n",
      "Epoch [26/50], Step [123/735], Loss: 0.1114\n",
      "Epoch [26/50], Step [124/735], Loss: 0.0637\n",
      "Epoch [26/50], Step [125/735], Loss: 0.0374\n",
      "Epoch [26/50], Step [126/735], Loss: 0.1092\n",
      "Epoch [26/50], Step [127/735], Loss: 0.1518\n",
      "Epoch [26/50], Step [128/735], Loss: 0.0730\n",
      "Epoch [26/50], Step [129/735], Loss: 0.0391\n",
      "Epoch [26/50], Step [130/735], Loss: 0.0332\n",
      "Epoch [26/50], Step [131/735], Loss: 0.2001\n",
      "Epoch [26/50], Step [132/735], Loss: 0.0221\n",
      "Epoch [26/50], Step [133/735], Loss: 0.0254\n",
      "Epoch [26/50], Step [134/735], Loss: 0.0924\n",
      "Epoch [26/50], Step [135/735], Loss: 0.0581\n",
      "Epoch [26/50], Step [136/735], Loss: 0.0232\n",
      "Epoch [26/50], Step [137/735], Loss: 0.0206\n",
      "Epoch [26/50], Step [138/735], Loss: 0.0443\n",
      "Epoch [26/50], Step [139/735], Loss: 0.1037\n",
      "Epoch [26/50], Step [140/735], Loss: 0.0598\n",
      "Epoch [26/50], Step [141/735], Loss: 0.0226\n",
      "Epoch [26/50], Step [142/735], Loss: 0.0278\n",
      "Epoch [26/50], Step [143/735], Loss: 0.1121\n",
      "Epoch [26/50], Step [144/735], Loss: 0.0217\n",
      "Epoch [26/50], Step [145/735], Loss: 0.0252\n",
      "Epoch [26/50], Step [146/735], Loss: 0.0399\n",
      "Epoch [26/50], Step [147/735], Loss: 0.0575\n",
      "Epoch [26/50], Step [148/735], Loss: 0.0722\n",
      "Epoch [26/50], Step [149/735], Loss: 0.0612\n",
      "Epoch [26/50], Step [150/735], Loss: 0.2726\n",
      "Epoch [26/50], Step [151/735], Loss: 0.0582\n",
      "Epoch [26/50], Step [152/735], Loss: 0.0946\n",
      "Epoch [26/50], Step [153/735], Loss: 0.0750\n",
      "Epoch [26/50], Step [154/735], Loss: 0.1127\n",
      "Epoch [26/50], Step [155/735], Loss: 0.1989\n",
      "Epoch [26/50], Step [156/735], Loss: 0.0191\n",
      "Epoch [26/50], Step [157/735], Loss: 0.0374\n",
      "Epoch [26/50], Step [158/735], Loss: 0.0293\n",
      "Epoch [26/50], Step [159/735], Loss: 0.0511\n",
      "Epoch [26/50], Step [160/735], Loss: 0.0594\n",
      "Epoch [26/50], Step [161/735], Loss: 0.0812\n",
      "Epoch [26/50], Step [162/735], Loss: 0.0174\n",
      "Epoch [26/50], Step [163/735], Loss: 0.2588\n",
      "Epoch [26/50], Step [164/735], Loss: 0.1333\n",
      "Epoch [26/50], Step [165/735], Loss: 0.1150\n",
      "Epoch [26/50], Step [166/735], Loss: 0.0171\n",
      "Epoch [26/50], Step [167/735], Loss: 0.0439\n",
      "Epoch [26/50], Step [168/735], Loss: 0.0912\n",
      "Epoch [26/50], Step [169/735], Loss: 0.0492\n",
      "Epoch [26/50], Step [170/735], Loss: 0.0683\n",
      "Epoch [26/50], Step [171/735], Loss: 0.0325\n",
      "Epoch [26/50], Step [172/735], Loss: 0.0704\n",
      "Epoch [26/50], Step [173/735], Loss: 0.0643\n",
      "Epoch [26/50], Step [174/735], Loss: 0.3023\n",
      "Epoch [26/50], Step [175/735], Loss: 0.0365\n",
      "Epoch [26/50], Step [176/735], Loss: 0.0861\n",
      "Epoch [26/50], Step [177/735], Loss: 0.0385\n",
      "Epoch [26/50], Step [178/735], Loss: 0.0804\n",
      "Epoch [26/50], Step [179/735], Loss: 0.0786\n",
      "Epoch [26/50], Step [180/735], Loss: 0.1220\n",
      "Epoch [26/50], Step [181/735], Loss: 0.1284\n",
      "Epoch [26/50], Step [182/735], Loss: 0.0714\n",
      "Epoch [26/50], Step [183/735], Loss: 0.0353\n",
      "Epoch [26/50], Step [184/735], Loss: 0.1642\n",
      "Epoch [26/50], Step [185/735], Loss: 0.1412\n",
      "Epoch [26/50], Step [186/735], Loss: 0.0244\n",
      "Epoch [26/50], Step [187/735], Loss: 0.0344\n",
      "Epoch [26/50], Step [188/735], Loss: 0.1654\n",
      "Epoch [26/50], Step [189/735], Loss: 0.0429\n",
      "Epoch [26/50], Step [190/735], Loss: 0.0311\n",
      "Epoch [26/50], Step [191/735], Loss: 0.1090\n",
      "Epoch [26/50], Step [192/735], Loss: 0.0487\n",
      "Epoch [26/50], Step [193/735], Loss: 0.0371\n",
      "Epoch [26/50], Step [194/735], Loss: 0.0855\n",
      "Epoch [26/50], Step [195/735], Loss: 0.2160\n",
      "Epoch [26/50], Step [196/735], Loss: 0.0719\n",
      "Epoch [26/50], Step [197/735], Loss: 0.0905\n",
      "Epoch [26/50], Step [198/735], Loss: 0.0202\n",
      "Epoch [26/50], Step [199/735], Loss: 0.0422\n",
      "Epoch [26/50], Step [200/735], Loss: 0.0636\n",
      "Epoch [26/50], Step [201/735], Loss: 0.0690\n",
      "Epoch [26/50], Step [202/735], Loss: 0.0919\n",
      "Epoch [26/50], Step [203/735], Loss: 0.0232\n",
      "Epoch [26/50], Step [204/735], Loss: 0.0417\n",
      "Epoch [26/50], Step [205/735], Loss: 0.4169\n",
      "Epoch [26/50], Step [206/735], Loss: 0.0475\n",
      "Epoch [26/50], Step [207/735], Loss: 0.0601\n",
      "Epoch [26/50], Step [208/735], Loss: 0.0657\n",
      "Epoch [26/50], Step [209/735], Loss: 0.1578\n",
      "Epoch [26/50], Step [210/735], Loss: 0.1261\n",
      "Epoch [26/50], Step [211/735], Loss: 0.0288\n",
      "Epoch [26/50], Step [212/735], Loss: 0.0581\n",
      "Epoch [26/50], Step [213/735], Loss: 0.0298\n",
      "Epoch [26/50], Step [214/735], Loss: 0.0482\n",
      "Epoch [26/50], Step [215/735], Loss: 0.0601\n",
      "Epoch [26/50], Step [216/735], Loss: 0.0778\n",
      "Epoch [26/50], Step [217/735], Loss: 0.0730\n",
      "Epoch [26/50], Step [218/735], Loss: 0.0460\n",
      "Epoch [26/50], Step [219/735], Loss: 0.0225\n",
      "Epoch [26/50], Step [220/735], Loss: 0.0765\n",
      "Epoch [26/50], Step [221/735], Loss: 0.0402\n",
      "Epoch [26/50], Step [222/735], Loss: 0.0180\n",
      "Epoch [26/50], Step [223/735], Loss: 0.0748\n",
      "Epoch [26/50], Step [224/735], Loss: 0.0255\n",
      "Epoch [26/50], Step [225/735], Loss: 0.4011\n",
      "Epoch [26/50], Step [226/735], Loss: 0.0411\n",
      "Epoch [26/50], Step [227/735], Loss: 0.0269\n",
      "Epoch [26/50], Step [228/735], Loss: 0.0448\n",
      "Epoch [26/50], Step [229/735], Loss: 0.0173\n",
      "Epoch [26/50], Step [230/735], Loss: 0.0447\n",
      "Epoch [26/50], Step [231/735], Loss: 0.1378\n",
      "Epoch [26/50], Step [232/735], Loss: 0.0217\n",
      "Epoch [26/50], Step [233/735], Loss: 0.0829\n",
      "Epoch [26/50], Step [234/735], Loss: 0.0346\n",
      "Epoch [26/50], Step [235/735], Loss: 0.0713\n",
      "Epoch [26/50], Step [236/735], Loss: 0.1844\n",
      "Epoch [26/50], Step [237/735], Loss: 0.0906\n",
      "Epoch [26/50], Step [238/735], Loss: 0.0786\n",
      "Epoch [26/50], Step [239/735], Loss: 0.0277\n",
      "Epoch [26/50], Step [240/735], Loss: 0.0495\n",
      "Epoch [26/50], Step [241/735], Loss: 0.0255\n",
      "Epoch [26/50], Step [242/735], Loss: 0.0587\n",
      "Epoch [26/50], Step [243/735], Loss: 0.1090\n",
      "Epoch [26/50], Step [244/735], Loss: 0.1246\n",
      "Epoch [26/50], Step [245/735], Loss: 0.0525\n",
      "Epoch [26/50], Step [246/735], Loss: 0.0498\n",
      "Epoch [26/50], Step [247/735], Loss: 0.0275\n",
      "Epoch [26/50], Step [248/735], Loss: 0.0412\n",
      "Epoch [26/50], Step [249/735], Loss: 0.0655\n",
      "Epoch [26/50], Step [250/735], Loss: 0.0754\n",
      "Epoch [26/50], Step [251/735], Loss: 0.1632\n",
      "Epoch [26/50], Step [252/735], Loss: 0.3073\n",
      "Epoch [26/50], Step [253/735], Loss: 0.1022\n",
      "Epoch [26/50], Step [254/735], Loss: 0.0382\n",
      "Epoch [26/50], Step [255/735], Loss: 0.0254\n",
      "Epoch [26/50], Step [256/735], Loss: 0.0662\n",
      "Epoch [26/50], Step [257/735], Loss: 0.0788\n",
      "Epoch [26/50], Step [258/735], Loss: 0.0744\n",
      "Epoch [26/50], Step [259/735], Loss: 0.0524\n",
      "Epoch [26/50], Step [260/735], Loss: 0.0331\n",
      "Epoch [26/50], Step [261/735], Loss: 0.0974\n",
      "Epoch [26/50], Step [262/735], Loss: 0.0969\n",
      "Epoch [26/50], Step [263/735], Loss: 0.0728\n",
      "Epoch [26/50], Step [264/735], Loss: 0.0474\n",
      "Epoch [26/50], Step [265/735], Loss: 0.0480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Step [266/735], Loss: 0.1702\n",
      "Epoch [26/50], Step [267/735], Loss: 0.1180\n",
      "Epoch [26/50], Step [268/735], Loss: 0.1137\n",
      "Epoch [26/50], Step [269/735], Loss: 0.1393\n",
      "Epoch [26/50], Step [270/735], Loss: 0.0220\n",
      "Epoch [26/50], Step [271/735], Loss: 0.0311\n",
      "Epoch [26/50], Step [272/735], Loss: 0.0321\n",
      "Epoch [26/50], Step [273/735], Loss: 0.0682\n",
      "Epoch [26/50], Step [274/735], Loss: 0.2741\n",
      "Epoch [26/50], Step [275/735], Loss: 0.0673\n",
      "Epoch [26/50], Step [276/735], Loss: 0.0296\n",
      "Epoch [26/50], Step [277/735], Loss: 0.1150\n",
      "Epoch [26/50], Step [278/735], Loss: 0.0712\n",
      "Epoch [26/50], Step [279/735], Loss: 0.0309\n",
      "Epoch [26/50], Step [280/735], Loss: 0.0363\n",
      "Epoch [26/50], Step [281/735], Loss: 0.0246\n",
      "Epoch [26/50], Step [282/735], Loss: 0.0380\n",
      "Epoch [26/50], Step [283/735], Loss: 0.0361\n",
      "Epoch [26/50], Step [284/735], Loss: 0.1674\n",
      "Epoch [26/50], Step [285/735], Loss: 0.0711\n",
      "Epoch [26/50], Step [286/735], Loss: 0.0247\n",
      "Epoch [26/50], Step [287/735], Loss: 0.0496\n",
      "Epoch [26/50], Step [288/735], Loss: 0.0577\n",
      "Epoch [26/50], Step [289/735], Loss: 0.0652\n",
      "Epoch [26/50], Step [290/735], Loss: 0.0462\n",
      "Epoch [26/50], Step [291/735], Loss: 0.0397\n",
      "Epoch [26/50], Step [292/735], Loss: 0.0285\n",
      "Epoch [26/50], Step [293/735], Loss: 0.0587\n",
      "Epoch [26/50], Step [294/735], Loss: 0.0767\n",
      "Epoch [26/50], Step [295/735], Loss: 0.0315\n",
      "Epoch [26/50], Step [296/735], Loss: 0.0519\n",
      "Epoch [26/50], Step [297/735], Loss: 0.0473\n",
      "Epoch [26/50], Step [298/735], Loss: 0.0411\n",
      "Epoch [26/50], Step [299/735], Loss: 0.0811\n",
      "Epoch [26/50], Step [300/735], Loss: 0.0657\n",
      "Epoch [26/50], Step [301/735], Loss: 0.0594\n",
      "Epoch [26/50], Step [302/735], Loss: 0.0331\n",
      "Epoch [26/50], Step [303/735], Loss: 0.0387\n",
      "Epoch [26/50], Step [304/735], Loss: 0.0758\n",
      "Epoch [26/50], Step [305/735], Loss: 0.0517\n",
      "Epoch [26/50], Step [306/735], Loss: 0.1136\n",
      "Epoch [26/50], Step [307/735], Loss: 0.0269\n",
      "Epoch [26/50], Step [308/735], Loss: 0.0292\n",
      "Epoch [26/50], Step [309/735], Loss: 0.0859\n",
      "Epoch [26/50], Step [310/735], Loss: 0.0575\n",
      "Epoch [26/50], Step [311/735], Loss: 0.0563\n",
      "Epoch [26/50], Step [312/735], Loss: 0.0833\n",
      "Epoch [26/50], Step [313/735], Loss: 0.1225\n",
      "Epoch [26/50], Step [314/735], Loss: 0.0469\n",
      "Epoch [26/50], Step [315/735], Loss: 0.0428\n",
      "Epoch [26/50], Step [316/735], Loss: 0.0386\n",
      "Epoch [26/50], Step [317/735], Loss: 0.0368\n",
      "Epoch [26/50], Step [318/735], Loss: 0.0343\n",
      "Epoch [26/50], Step [319/735], Loss: 0.0841\n",
      "Epoch [26/50], Step [320/735], Loss: 0.0195\n",
      "Epoch [26/50], Step [321/735], Loss: 0.0372\n",
      "Epoch [26/50], Step [322/735], Loss: 0.1817\n",
      "Epoch [26/50], Step [323/735], Loss: 0.0742\n",
      "Epoch [26/50], Step [324/735], Loss: 0.0404\n",
      "Epoch [26/50], Step [325/735], Loss: 0.1464\n",
      "Epoch [26/50], Step [326/735], Loss: 0.0374\n",
      "Epoch [26/50], Step [327/735], Loss: 0.0624\n",
      "Epoch [26/50], Step [328/735], Loss: 0.0258\n",
      "Epoch [26/50], Step [329/735], Loss: 0.0762\n",
      "Epoch [26/50], Step [330/735], Loss: 0.0297\n",
      "Epoch [26/50], Step [331/735], Loss: 0.0374\n",
      "Epoch [26/50], Step [332/735], Loss: 0.0964\n",
      "Epoch [26/50], Step [333/735], Loss: 0.1263\n",
      "Epoch [26/50], Step [334/735], Loss: 0.0402\n",
      "Epoch [26/50], Step [335/735], Loss: 0.0563\n",
      "Epoch [26/50], Step [336/735], Loss: 0.0422\n",
      "Epoch [26/50], Step [337/735], Loss: 0.1519\n",
      "Epoch [26/50], Step [338/735], Loss: 0.0464\n",
      "Epoch [26/50], Step [339/735], Loss: 0.0321\n",
      "Epoch [26/50], Step [340/735], Loss: 0.0554\n",
      "Epoch [26/50], Step [341/735], Loss: 0.1207\n",
      "Epoch [26/50], Step [342/735], Loss: 0.0558\n",
      "Epoch [26/50], Step [343/735], Loss: 0.0702\n",
      "Epoch [26/50], Step [344/735], Loss: 0.0710\n",
      "Epoch [26/50], Step [345/735], Loss: 0.0640\n",
      "Epoch [26/50], Step [346/735], Loss: 0.0461\n",
      "Epoch [26/50], Step [347/735], Loss: 0.1525\n",
      "Epoch [26/50], Step [348/735], Loss: 0.1473\n",
      "Epoch [26/50], Step [349/735], Loss: 0.0326\n",
      "Epoch [26/50], Step [350/735], Loss: 0.0312\n",
      "Epoch [26/50], Step [351/735], Loss: 0.1218\n",
      "Epoch [26/50], Step [352/735], Loss: 0.0618\n",
      "Epoch [26/50], Step [353/735], Loss: 0.0232\n",
      "Epoch [26/50], Step [354/735], Loss: 0.0680\n",
      "Epoch [26/50], Step [355/735], Loss: 0.1177\n",
      "Epoch [26/50], Step [356/735], Loss: 0.0234\n",
      "Epoch [26/50], Step [357/735], Loss: 0.0364\n",
      "Epoch [26/50], Step [358/735], Loss: 0.1241\n",
      "Epoch [26/50], Step [359/735], Loss: 0.0592\n",
      "Epoch [26/50], Step [360/735], Loss: 0.0807\n",
      "Epoch [26/50], Step [361/735], Loss: 0.0257\n",
      "Epoch [26/50], Step [362/735], Loss: 0.0880\n",
      "Epoch [26/50], Step [363/735], Loss: 0.0238\n",
      "Epoch [26/50], Step [364/735], Loss: 0.1006\n",
      "Epoch [26/50], Step [365/735], Loss: 0.0280\n",
      "Epoch [26/50], Step [366/735], Loss: 0.0477\n",
      "Epoch [26/50], Step [367/735], Loss: 0.0417\n",
      "Epoch [26/50], Step [368/735], Loss: 0.0610\n",
      "Epoch [26/50], Step [369/735], Loss: 0.0373\n",
      "Epoch [26/50], Step [370/735], Loss: 0.1322\n",
      "Epoch [26/50], Step [371/735], Loss: 0.0557\n",
      "Epoch [26/50], Step [372/735], Loss: 0.0711\n",
      "Epoch [26/50], Step [373/735], Loss: 0.0490\n",
      "Epoch [26/50], Step [374/735], Loss: 0.1168\n",
      "Epoch [26/50], Step [375/735], Loss: 0.0890\n",
      "Epoch [26/50], Step [376/735], Loss: 0.0474\n",
      "Epoch [26/50], Step [377/735], Loss: 0.0785\n",
      "Epoch [26/50], Step [378/735], Loss: 0.1999\n",
      "Epoch [26/50], Step [379/735], Loss: 0.0793\n",
      "Epoch [26/50], Step [380/735], Loss: 0.0705\n",
      "Epoch [26/50], Step [381/735], Loss: 0.0546\n",
      "Epoch [26/50], Step [382/735], Loss: 0.1240\n",
      "Epoch [26/50], Step [383/735], Loss: 0.0266\n",
      "Epoch [26/50], Step [384/735], Loss: 0.0826\n",
      "Epoch [26/50], Step [385/735], Loss: 0.0279\n",
      "Epoch [26/50], Step [386/735], Loss: 0.0646\n",
      "Epoch [26/50], Step [387/735], Loss: 0.1350\n",
      "Epoch [26/50], Step [388/735], Loss: 0.0906\n",
      "Epoch [26/50], Step [389/735], Loss: 0.0169\n",
      "Epoch [26/50], Step [390/735], Loss: 0.1389\n",
      "Epoch [26/50], Step [391/735], Loss: 0.0512\n",
      "Epoch [26/50], Step [392/735], Loss: 0.0372\n",
      "Epoch [26/50], Step [393/735], Loss: 0.0452\n",
      "Epoch [26/50], Step [394/735], Loss: 0.0284\n",
      "Epoch [26/50], Step [395/735], Loss: 0.0450\n",
      "Epoch [26/50], Step [396/735], Loss: 0.0355\n",
      "Epoch [26/50], Step [397/735], Loss: 0.0277\n",
      "Epoch [26/50], Step [398/735], Loss: 0.0664\n",
      "Epoch [26/50], Step [399/735], Loss: 0.0368\n",
      "Epoch [26/50], Step [400/735], Loss: 0.0722\n",
      "Epoch [26/50], Step [401/735], Loss: 0.0197\n",
      "Epoch [26/50], Step [402/735], Loss: 0.1437\n",
      "Epoch [26/50], Step [403/735], Loss: 0.0458\n",
      "Epoch [26/50], Step [404/735], Loss: 0.0509\n",
      "Epoch [26/50], Step [405/735], Loss: 0.0552\n",
      "Epoch [26/50], Step [406/735], Loss: 0.0821\n",
      "Epoch [26/50], Step [407/735], Loss: 0.0552\n",
      "Epoch [26/50], Step [408/735], Loss: 0.0410\n",
      "Epoch [26/50], Step [409/735], Loss: 0.0698\n",
      "Epoch [26/50], Step [410/735], Loss: 0.1136\n",
      "Epoch [26/50], Step [411/735], Loss: 0.0995\n",
      "Epoch [26/50], Step [412/735], Loss: 0.0454\n",
      "Epoch [26/50], Step [413/735], Loss: 0.0503\n",
      "Epoch [26/50], Step [414/735], Loss: 0.0640\n",
      "Epoch [26/50], Step [415/735], Loss: 0.1869\n",
      "Epoch [26/50], Step [416/735], Loss: 0.0414\n",
      "Epoch [26/50], Step [417/735], Loss: 0.0269\n",
      "Epoch [26/50], Step [418/735], Loss: 0.0481\n",
      "Epoch [26/50], Step [419/735], Loss: 0.0518\n",
      "Epoch [26/50], Step [420/735], Loss: 0.0678\n",
      "Epoch [26/50], Step [421/735], Loss: 0.0701\n",
      "Epoch [26/50], Step [422/735], Loss: 0.0441\n",
      "Epoch [26/50], Step [423/735], Loss: 0.0530\n",
      "Epoch [26/50], Step [424/735], Loss: 0.0962\n",
      "Epoch [26/50], Step [425/735], Loss: 0.0585\n",
      "Epoch [26/50], Step [426/735], Loss: 0.0186\n",
      "Epoch [26/50], Step [427/735], Loss: 0.0428\n",
      "Epoch [26/50], Step [428/735], Loss: 0.0246\n",
      "Epoch [26/50], Step [429/735], Loss: 0.0362\n",
      "Epoch [26/50], Step [430/735], Loss: 0.0349\n",
      "Epoch [26/50], Step [431/735], Loss: 0.1001\n",
      "Epoch [26/50], Step [432/735], Loss: 0.0344\n",
      "Epoch [26/50], Step [433/735], Loss: 0.1601\n",
      "Epoch [26/50], Step [434/735], Loss: 0.3991\n",
      "Epoch [26/50], Step [435/735], Loss: 0.0510\n",
      "Epoch [26/50], Step [436/735], Loss: 0.0531\n",
      "Epoch [26/50], Step [437/735], Loss: 0.0375\n",
      "Epoch [26/50], Step [438/735], Loss: 0.0674\n",
      "Epoch [26/50], Step [439/735], Loss: 0.2469\n",
      "Epoch [26/50], Step [440/735], Loss: 0.0904\n",
      "Epoch [26/50], Step [441/735], Loss: 0.1489\n",
      "Epoch [26/50], Step [442/735], Loss: 0.0270\n",
      "Epoch [26/50], Step [443/735], Loss: 0.0795\n",
      "Epoch [26/50], Step [444/735], Loss: 0.1015\n",
      "Epoch [26/50], Step [445/735], Loss: 0.0425\n",
      "Epoch [26/50], Step [446/735], Loss: 0.0858\n",
      "Epoch [26/50], Step [447/735], Loss: 0.0286\n",
      "Epoch [26/50], Step [448/735], Loss: 0.0218\n",
      "Epoch [26/50], Step [449/735], Loss: 0.1762\n",
      "Epoch [26/50], Step [450/735], Loss: 0.0253\n",
      "Epoch [26/50], Step [451/735], Loss: 0.1068\n",
      "Epoch [26/50], Step [452/735], Loss: 0.0237\n",
      "Epoch [26/50], Step [453/735], Loss: 0.0553\n",
      "Epoch [26/50], Step [454/735], Loss: 0.0417\n",
      "Epoch [26/50], Step [455/735], Loss: 0.0328\n",
      "Epoch [26/50], Step [456/735], Loss: 0.1374\n",
      "Epoch [26/50], Step [457/735], Loss: 0.0281\n",
      "Epoch [26/50], Step [458/735], Loss: 0.3600\n",
      "Epoch [26/50], Step [459/735], Loss: 0.0444\n",
      "Epoch [26/50], Step [460/735], Loss: 0.0842\n",
      "Epoch [26/50], Step [461/735], Loss: 0.0268\n",
      "Epoch [26/50], Step [462/735], Loss: 0.0537\n",
      "Epoch [26/50], Step [463/735], Loss: 0.0540\n",
      "Epoch [26/50], Step [464/735], Loss: 0.0395\n",
      "Epoch [26/50], Step [465/735], Loss: 0.0303\n",
      "Epoch [26/50], Step [466/735], Loss: 0.1080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Step [467/735], Loss: 0.0405\n",
      "Epoch [26/50], Step [468/735], Loss: 0.0322\n",
      "Epoch [26/50], Step [469/735], Loss: 0.0629\n",
      "Epoch [26/50], Step [470/735], Loss: 0.1133\n",
      "Epoch [26/50], Step [471/735], Loss: 0.0234\n",
      "Epoch [26/50], Step [472/735], Loss: 0.2881\n",
      "Epoch [26/50], Step [473/735], Loss: 0.0819\n",
      "Epoch [26/50], Step [474/735], Loss: 0.0939\n",
      "Epoch [26/50], Step [475/735], Loss: 0.0944\n",
      "Epoch [26/50], Step [476/735], Loss: 0.1458\n",
      "Epoch [26/50], Step [477/735], Loss: 0.1045\n",
      "Epoch [26/50], Step [478/735], Loss: 0.0338\n",
      "Epoch [26/50], Step [479/735], Loss: 0.0625\n",
      "Epoch [26/50], Step [480/735], Loss: 0.4185\n",
      "Epoch [26/50], Step [481/735], Loss: 0.1250\n",
      "Epoch [26/50], Step [482/735], Loss: 0.0227\n",
      "Epoch [26/50], Step [483/735], Loss: 0.1195\n",
      "Epoch [26/50], Step [484/735], Loss: 0.1029\n",
      "Epoch [26/50], Step [485/735], Loss: 0.0397\n",
      "Epoch [26/50], Step [486/735], Loss: 0.0391\n",
      "Epoch [26/50], Step [487/735], Loss: 0.0269\n",
      "Epoch [26/50], Step [488/735], Loss: 0.1741\n",
      "Epoch [26/50], Step [489/735], Loss: 0.0565\n",
      "Epoch [26/50], Step [490/735], Loss: 0.0822\n",
      "Epoch [26/50], Step [491/735], Loss: 0.0593\n",
      "Epoch [26/50], Step [492/735], Loss: 0.0277\n",
      "Epoch [26/50], Step [493/735], Loss: 0.2036\n",
      "Epoch [26/50], Step [494/735], Loss: 0.0370\n",
      "Epoch [26/50], Step [495/735], Loss: 0.0841\n",
      "Epoch [26/50], Step [496/735], Loss: 0.0672\n",
      "Epoch [26/50], Step [497/735], Loss: 0.0209\n",
      "Epoch [26/50], Step [498/735], Loss: 0.0285\n",
      "Epoch [26/50], Step [499/735], Loss: 0.0361\n",
      "Epoch [26/50], Step [500/735], Loss: 0.0453\n",
      "Epoch [26/50], Step [501/735], Loss: 0.0259\n",
      "Epoch [26/50], Step [502/735], Loss: 0.0972\n",
      "Epoch [26/50], Step [503/735], Loss: 0.0951\n",
      "Epoch [26/50], Step [504/735], Loss: 0.0297\n",
      "Epoch [26/50], Step [505/735], Loss: 0.2493\n",
      "Epoch [26/50], Step [506/735], Loss: 0.1546\n",
      "Epoch [26/50], Step [507/735], Loss: 0.1552\n",
      "Epoch [26/50], Step [508/735], Loss: 0.0717\n",
      "Epoch [26/50], Step [509/735], Loss: 0.1425\n",
      "Epoch [26/50], Step [510/735], Loss: 0.0547\n",
      "Epoch [26/50], Step [511/735], Loss: 0.0885\n",
      "Epoch [26/50], Step [512/735], Loss: 0.0491\n",
      "Epoch [26/50], Step [513/735], Loss: 0.0458\n",
      "Epoch [26/50], Step [514/735], Loss: 0.1177\n",
      "Epoch [26/50], Step [515/735], Loss: 0.0487\n",
      "Epoch [26/50], Step [516/735], Loss: 0.0765\n",
      "Epoch [26/50], Step [517/735], Loss: 0.1160\n",
      "Epoch [26/50], Step [518/735], Loss: 0.0979\n",
      "Epoch [26/50], Step [519/735], Loss: 0.0679\n",
      "Epoch [26/50], Step [520/735], Loss: 0.0762\n",
      "Epoch [26/50], Step [521/735], Loss: 0.0239\n",
      "Epoch [26/50], Step [522/735], Loss: 0.0270\n",
      "Epoch [26/50], Step [523/735], Loss: 0.1245\n",
      "Epoch [26/50], Step [524/735], Loss: 0.1026\n",
      "Epoch [26/50], Step [525/735], Loss: 0.0381\n",
      "Epoch [26/50], Step [526/735], Loss: 0.0675\n",
      "Epoch [26/50], Step [527/735], Loss: 0.0484\n",
      "Epoch [26/50], Step [528/735], Loss: 0.4389\n",
      "Epoch [26/50], Step [529/735], Loss: 0.1133\n",
      "Epoch [26/50], Step [530/735], Loss: 0.1486\n",
      "Epoch [26/50], Step [531/735], Loss: 0.1304\n",
      "Epoch [26/50], Step [532/735], Loss: 0.0893\n",
      "Epoch [26/50], Step [533/735], Loss: 0.0546\n",
      "Epoch [26/50], Step [534/735], Loss: 0.0717\n",
      "Epoch [26/50], Step [535/735], Loss: 0.0523\n",
      "Epoch [26/50], Step [536/735], Loss: 0.0349\n",
      "Epoch [26/50], Step [537/735], Loss: 0.0485\n",
      "Epoch [26/50], Step [538/735], Loss: 0.0479\n",
      "Epoch [26/50], Step [539/735], Loss: 0.0800\n",
      "Epoch [26/50], Step [540/735], Loss: 0.0889\n",
      "Epoch [26/50], Step [541/735], Loss: 0.0375\n",
      "Epoch [26/50], Step [542/735], Loss: 0.0880\n",
      "Epoch [26/50], Step [543/735], Loss: 0.0618\n",
      "Epoch [26/50], Step [544/735], Loss: 0.0635\n",
      "Epoch [26/50], Step [545/735], Loss: 0.0281\n",
      "Epoch [26/50], Step [546/735], Loss: 0.0443\n",
      "Epoch [26/50], Step [547/735], Loss: 0.1326\n",
      "Epoch [26/50], Step [548/735], Loss: 0.0708\n",
      "Epoch [26/50], Step [549/735], Loss: 0.0264\n",
      "Epoch [26/50], Step [550/735], Loss: 0.1538\n",
      "Epoch [26/50], Step [551/735], Loss: 0.0612\n",
      "Epoch [26/50], Step [552/735], Loss: 0.1424\n",
      "Epoch [26/50], Step [553/735], Loss: 0.0457\n",
      "Epoch [26/50], Step [554/735], Loss: 0.1349\n",
      "Epoch [26/50], Step [555/735], Loss: 0.0723\n",
      "Epoch [26/50], Step [556/735], Loss: 0.2786\n",
      "Epoch [26/50], Step [557/735], Loss: 0.0416\n",
      "Epoch [26/50], Step [558/735], Loss: 0.0406\n",
      "Epoch [26/50], Step [559/735], Loss: 0.0447\n",
      "Epoch [26/50], Step [560/735], Loss: 0.1842\n",
      "Epoch [26/50], Step [561/735], Loss: 0.1383\n",
      "Epoch [26/50], Step [562/735], Loss: 0.1399\n",
      "Epoch [26/50], Step [563/735], Loss: 0.1464\n",
      "Epoch [26/50], Step [564/735], Loss: 0.0541\n",
      "Epoch [26/50], Step [565/735], Loss: 0.0339\n",
      "Epoch [26/50], Step [566/735], Loss: 0.2314\n",
      "Epoch [26/50], Step [567/735], Loss: 0.1036\n",
      "Epoch [26/50], Step [568/735], Loss: 0.0921\n",
      "Epoch [26/50], Step [569/735], Loss: 0.1006\n",
      "Epoch [26/50], Step [570/735], Loss: 0.0405\n",
      "Epoch [26/50], Step [571/735], Loss: 0.0422\n",
      "Epoch [26/50], Step [572/735], Loss: 0.0915\n",
      "Epoch [26/50], Step [573/735], Loss: 0.2520\n",
      "Epoch [26/50], Step [574/735], Loss: 0.6290\n",
      "Epoch [26/50], Step [575/735], Loss: 0.0280\n",
      "Epoch [26/50], Step [576/735], Loss: 0.0890\n",
      "Epoch [26/50], Step [577/735], Loss: 0.1110\n",
      "Epoch [26/50], Step [578/735], Loss: 0.1043\n",
      "Epoch [26/50], Step [579/735], Loss: 0.0721\n",
      "Epoch [26/50], Step [580/735], Loss: 0.0423\n",
      "Epoch [26/50], Step [581/735], Loss: 0.0576\n",
      "Epoch [26/50], Step [582/735], Loss: 0.0918\n",
      "Epoch [26/50], Step [583/735], Loss: 0.0255\n",
      "Epoch [26/50], Step [584/735], Loss: 0.1102\n",
      "Epoch [26/50], Step [585/735], Loss: 0.1948\n",
      "Epoch [26/50], Step [586/735], Loss: 0.0325\n",
      "Epoch [26/50], Step [587/735], Loss: 0.0634\n",
      "Epoch [26/50], Step [588/735], Loss: 0.0478\n",
      "Epoch [26/50], Step [589/735], Loss: 0.1130\n",
      "Epoch [26/50], Step [590/735], Loss: 0.1082\n",
      "Epoch [26/50], Step [591/735], Loss: 0.1576\n",
      "Epoch [26/50], Step [592/735], Loss: 0.0515\n",
      "Epoch [26/50], Step [593/735], Loss: 0.1491\n",
      "Epoch [26/50], Step [594/735], Loss: 0.0290\n",
      "Epoch [26/50], Step [595/735], Loss: 0.0634\n",
      "Epoch [26/50], Step [596/735], Loss: 0.0376\n",
      "Epoch [26/50], Step [597/735], Loss: 0.0693\n",
      "Epoch [26/50], Step [598/735], Loss: 0.3698\n",
      "Epoch [26/50], Step [599/735], Loss: 0.2305\n",
      "Epoch [26/50], Step [600/735], Loss: 0.0516\n",
      "Epoch [26/50], Step [601/735], Loss: 0.0421\n",
      "Epoch [26/50], Step [602/735], Loss: 0.0459\n",
      "Epoch [26/50], Step [603/735], Loss: 0.0327\n",
      "Epoch [26/50], Step [604/735], Loss: 0.0653\n",
      "Epoch [26/50], Step [605/735], Loss: 0.0569\n",
      "Epoch [26/50], Step [606/735], Loss: 0.0516\n",
      "Epoch [26/50], Step [607/735], Loss: 0.0648\n",
      "Epoch [26/50], Step [608/735], Loss: 0.1115\n",
      "Epoch [26/50], Step [609/735], Loss: 0.2512\n",
      "Epoch [26/50], Step [610/735], Loss: 0.0958\n",
      "Epoch [26/50], Step [611/735], Loss: 0.1148\n",
      "Epoch [26/50], Step [612/735], Loss: 0.0441\n",
      "Epoch [26/50], Step [613/735], Loss: 0.1341\n",
      "Epoch [26/50], Step [614/735], Loss: 0.0944\n",
      "Epoch [26/50], Step [615/735], Loss: 0.0692\n",
      "Epoch [26/50], Step [616/735], Loss: 0.0474\n",
      "Epoch [26/50], Step [617/735], Loss: 0.0407\n",
      "Epoch [26/50], Step [618/735], Loss: 0.0980\n",
      "Epoch [26/50], Step [619/735], Loss: 0.0808\n",
      "Epoch [26/50], Step [620/735], Loss: 0.0437\n",
      "Epoch [26/50], Step [621/735], Loss: 0.0494\n",
      "Epoch [26/50], Step [622/735], Loss: 0.0345\n",
      "Epoch [26/50], Step [623/735], Loss: 0.0365\n",
      "Epoch [26/50], Step [624/735], Loss: 0.0287\n",
      "Epoch [26/50], Step [625/735], Loss: 0.0863\n",
      "Epoch [26/50], Step [626/735], Loss: 0.0280\n",
      "Epoch [26/50], Step [627/735], Loss: 0.0391\n",
      "Epoch [26/50], Step [628/735], Loss: 0.0179\n",
      "Epoch [26/50], Step [629/735], Loss: 0.0558\n",
      "Epoch [26/50], Step [630/735], Loss: 0.0462\n",
      "Epoch [26/50], Step [631/735], Loss: 0.0603\n",
      "Epoch [26/50], Step [632/735], Loss: 0.0331\n",
      "Epoch [26/50], Step [633/735], Loss: 0.0439\n",
      "Epoch [26/50], Step [634/735], Loss: 0.1597\n",
      "Epoch [26/50], Step [635/735], Loss: 0.0585\n",
      "Epoch [26/50], Step [636/735], Loss: 0.0345\n",
      "Epoch [26/50], Step [637/735], Loss: 0.1601\n",
      "Epoch [26/50], Step [638/735], Loss: 0.0709\n",
      "Epoch [26/50], Step [639/735], Loss: 0.0579\n",
      "Epoch [26/50], Step [640/735], Loss: 0.0173\n",
      "Epoch [26/50], Step [641/735], Loss: 0.0820\n",
      "Epoch [26/50], Step [642/735], Loss: 0.0538\n",
      "Epoch [26/50], Step [643/735], Loss: 0.0216\n",
      "Epoch [26/50], Step [644/735], Loss: 0.1756\n",
      "Epoch [26/50], Step [645/735], Loss: 0.1509\n",
      "Epoch [26/50], Step [646/735], Loss: 0.0931\n",
      "Epoch [26/50], Step [647/735], Loss: 0.0481\n",
      "Epoch [26/50], Step [648/735], Loss: 0.1713\n",
      "Epoch [26/50], Step [649/735], Loss: 0.0370\n",
      "Epoch [26/50], Step [650/735], Loss: 0.0462\n",
      "Epoch [26/50], Step [651/735], Loss: 0.0694\n",
      "Epoch [26/50], Step [652/735], Loss: 0.0477\n",
      "Epoch [26/50], Step [653/735], Loss: 0.0741\n",
      "Epoch [26/50], Step [654/735], Loss: 0.0512\n",
      "Epoch [26/50], Step [655/735], Loss: 0.3811\n",
      "Epoch [26/50], Step [656/735], Loss: 0.1266\n",
      "Epoch [26/50], Step [657/735], Loss: 0.0393\n",
      "Epoch [26/50], Step [658/735], Loss: 0.0572\n",
      "Epoch [26/50], Step [659/735], Loss: 0.3296\n",
      "Epoch [26/50], Step [660/735], Loss: 0.0303\n",
      "Epoch [26/50], Step [661/735], Loss: 0.0183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Step [662/735], Loss: 0.0451\n",
      "Epoch [26/50], Step [663/735], Loss: 0.0852\n",
      "Epoch [26/50], Step [664/735], Loss: 0.0872\n",
      "Epoch [26/50], Step [665/735], Loss: 0.0623\n",
      "Epoch [26/50], Step [666/735], Loss: 0.0302\n",
      "Epoch [26/50], Step [667/735], Loss: 0.0434\n",
      "Epoch [26/50], Step [668/735], Loss: 0.0293\n",
      "Epoch [26/50], Step [669/735], Loss: 0.0256\n",
      "Epoch [26/50], Step [670/735], Loss: 0.0880\n",
      "Epoch [26/50], Step [671/735], Loss: 0.4318\n",
      "Epoch [26/50], Step [672/735], Loss: 0.0337\n",
      "Epoch [26/50], Step [673/735], Loss: 0.0579\n",
      "Epoch [26/50], Step [674/735], Loss: 0.0343\n",
      "Epoch [26/50], Step [675/735], Loss: 0.0255\n",
      "Epoch [26/50], Step [676/735], Loss: 0.0691\n",
      "Epoch [26/50], Step [677/735], Loss: 0.0191\n",
      "Epoch [26/50], Step [678/735], Loss: 0.0400\n",
      "Epoch [26/50], Step [679/735], Loss: 0.0622\n",
      "Epoch [26/50], Step [680/735], Loss: 0.0538\n",
      "Epoch [26/50], Step [681/735], Loss: 0.0693\n",
      "Epoch [26/50], Step [682/735], Loss: 0.0588\n",
      "Epoch [26/50], Step [683/735], Loss: 0.0400\n",
      "Epoch [26/50], Step [684/735], Loss: 0.1744\n",
      "Epoch [26/50], Step [685/735], Loss: 0.0383\n",
      "Epoch [26/50], Step [686/735], Loss: 0.0830\n",
      "Epoch [26/50], Step [687/735], Loss: 0.0663\n",
      "Epoch [26/50], Step [688/735], Loss: 0.0918\n",
      "Epoch [26/50], Step [689/735], Loss: 0.0481\n",
      "Epoch [26/50], Step [690/735], Loss: 0.0211\n",
      "Epoch [26/50], Step [691/735], Loss: 0.0857\n",
      "Epoch [26/50], Step [692/735], Loss: 0.0226\n",
      "Epoch [26/50], Step [693/735], Loss: 0.0408\n",
      "Epoch [26/50], Step [694/735], Loss: 0.0331\n",
      "Epoch [26/50], Step [695/735], Loss: 0.0723\n",
      "Epoch [26/50], Step [696/735], Loss: 0.0357\n",
      "Epoch [26/50], Step [697/735], Loss: 0.1238\n",
      "Epoch [26/50], Step [698/735], Loss: 0.0250\n",
      "Epoch [26/50], Step [699/735], Loss: 0.0448\n",
      "Epoch [26/50], Step [700/735], Loss: 0.0511\n",
      "Epoch [26/50], Step [701/735], Loss: 0.0626\n",
      "Epoch [26/50], Step [702/735], Loss: 0.0669\n",
      "Epoch [26/50], Step [703/735], Loss: 0.0459\n",
      "Epoch [26/50], Step [704/735], Loss: 0.0328\n",
      "Epoch [26/50], Step [705/735], Loss: 0.1771\n",
      "Epoch [26/50], Step [706/735], Loss: 0.1155\n",
      "Epoch [26/50], Step [707/735], Loss: 0.0787\n",
      "Epoch [26/50], Step [708/735], Loss: 0.0194\n",
      "Epoch [26/50], Step [709/735], Loss: 0.0542\n",
      "Epoch [26/50], Step [710/735], Loss: 0.0372\n",
      "Epoch [26/50], Step [711/735], Loss: 0.0671\n",
      "Epoch [26/50], Step [712/735], Loss: 0.0113\n",
      "Epoch [26/50], Step [713/735], Loss: 0.0302\n",
      "Epoch [26/50], Step [714/735], Loss: 0.0439\n",
      "Epoch [26/50], Step [715/735], Loss: 0.0720\n",
      "Epoch [26/50], Step [716/735], Loss: 0.0388\n",
      "Epoch [26/50], Step [717/735], Loss: 0.1290\n",
      "Epoch [26/50], Step [718/735], Loss: 0.0806\n",
      "Epoch [26/50], Step [719/735], Loss: 0.0977\n",
      "Epoch [26/50], Step [720/735], Loss: 0.0393\n",
      "Epoch [26/50], Step [721/735], Loss: 0.0209\n",
      "Epoch [26/50], Step [722/735], Loss: 0.0833\n",
      "Epoch [26/50], Step [723/735], Loss: 0.3654\n",
      "Epoch [26/50], Step [724/735], Loss: 0.0688\n",
      "Epoch [26/50], Step [725/735], Loss: 0.0658\n",
      "Epoch [26/50], Step [726/735], Loss: 0.0743\n",
      "Epoch [26/50], Step [727/735], Loss: 0.1147\n",
      "Epoch [26/50], Step [728/735], Loss: 0.1067\n",
      "Epoch [26/50], Step [729/735], Loss: 0.0317\n",
      "Epoch [26/50], Step [730/735], Loss: 0.0863\n",
      "Epoch [26/50], Step [731/735], Loss: 0.0166\n",
      "Epoch [26/50], Step [732/735], Loss: 0.1907\n",
      "Epoch [26/50], Step [733/735], Loss: 0.0954\n",
      "Epoch [26/50], Step [734/735], Loss: 0.0605\n",
      "Epoch [26/50], Step [735/735], Loss: 0.0146\n",
      "Epoch [27/50], Step [1/735], Loss: 0.0758\n",
      "Epoch [27/50], Step [2/735], Loss: 0.0345\n",
      "Epoch [27/50], Step [3/735], Loss: 0.0842\n",
      "Epoch [27/50], Step [4/735], Loss: 0.1406\n",
      "Epoch [27/50], Step [5/735], Loss: 0.2398\n",
      "Epoch [27/50], Step [6/735], Loss: 0.1008\n",
      "Epoch [27/50], Step [7/735], Loss: 0.0395\n",
      "Epoch [27/50], Step [8/735], Loss: 0.0818\n",
      "Epoch [27/50], Step [9/735], Loss: 0.0634\n",
      "Epoch [27/50], Step [10/735], Loss: 0.0446\n",
      "Epoch [27/50], Step [11/735], Loss: 0.0924\n",
      "Epoch [27/50], Step [12/735], Loss: 0.0545\n",
      "Epoch [27/50], Step [13/735], Loss: 0.1359\n",
      "Epoch [27/50], Step [14/735], Loss: 0.0590\n",
      "Epoch [27/50], Step [15/735], Loss: 0.1022\n",
      "Epoch [27/50], Step [16/735], Loss: 0.1936\n",
      "Epoch [27/50], Step [17/735], Loss: 0.0579\n",
      "Epoch [27/50], Step [18/735], Loss: 0.0170\n",
      "Epoch [27/50], Step [19/735], Loss: 0.0344\n",
      "Epoch [27/50], Step [20/735], Loss: 0.0454\n",
      "Epoch [27/50], Step [21/735], Loss: 0.0395\n",
      "Epoch [27/50], Step [22/735], Loss: 0.0236\n",
      "Epoch [27/50], Step [23/735], Loss: 0.0978\n",
      "Epoch [27/50], Step [24/735], Loss: 0.1022\n",
      "Epoch [27/50], Step [25/735], Loss: 0.1406\n",
      "Epoch [27/50], Step [26/735], Loss: 0.0689\n",
      "Epoch [27/50], Step [27/735], Loss: 0.2511\n",
      "Epoch [27/50], Step [28/735], Loss: 0.0600\n",
      "Epoch [27/50], Step [29/735], Loss: 0.4227\n",
      "Epoch [27/50], Step [30/735], Loss: 0.0468\n",
      "Epoch [27/50], Step [31/735], Loss: 0.0319\n",
      "Epoch [27/50], Step [32/735], Loss: 0.0668\n",
      "Epoch [27/50], Step [33/735], Loss: 0.0772\n",
      "Epoch [27/50], Step [34/735], Loss: 0.0559\n",
      "Epoch [27/50], Step [35/735], Loss: 0.0302\n",
      "Epoch [27/50], Step [36/735], Loss: 0.0912\n",
      "Epoch [27/50], Step [37/735], Loss: 0.0711\n",
      "Epoch [27/50], Step [38/735], Loss: 0.0382\n",
      "Epoch [27/50], Step [39/735], Loss: 0.0997\n",
      "Epoch [27/50], Step [40/735], Loss: 0.0699\n",
      "Epoch [27/50], Step [41/735], Loss: 0.0402\n",
      "Epoch [27/50], Step [42/735], Loss: 0.0283\n",
      "Epoch [27/50], Step [43/735], Loss: 0.0997\n",
      "Epoch [27/50], Step [44/735], Loss: 0.0985\n",
      "Epoch [27/50], Step [45/735], Loss: 0.0222\n",
      "Epoch [27/50], Step [46/735], Loss: 0.0692\n",
      "Epoch [27/50], Step [47/735], Loss: 0.0511\n",
      "Epoch [27/50], Step [48/735], Loss: 0.2468\n",
      "Epoch [27/50], Step [49/735], Loss: 0.1537\n",
      "Epoch [27/50], Step [50/735], Loss: 0.0994\n",
      "Epoch [27/50], Step [51/735], Loss: 0.1633\n",
      "Epoch [27/50], Step [52/735], Loss: 0.1151\n",
      "Epoch [27/50], Step [53/735], Loss: 0.0711\n",
      "Epoch [27/50], Step [54/735], Loss: 0.0239\n",
      "Epoch [27/50], Step [55/735], Loss: 0.0709\n",
      "Epoch [27/50], Step [56/735], Loss: 0.0431\n",
      "Epoch [27/50], Step [57/735], Loss: 0.0673\n",
      "Epoch [27/50], Step [58/735], Loss: 0.0492\n",
      "Epoch [27/50], Step [59/735], Loss: 0.0632\n",
      "Epoch [27/50], Step [60/735], Loss: 0.0579\n",
      "Epoch [27/50], Step [61/735], Loss: 0.1792\n",
      "Epoch [27/50], Step [62/735], Loss: 0.0336\n",
      "Epoch [27/50], Step [63/735], Loss: 0.0242\n",
      "Epoch [27/50], Step [64/735], Loss: 0.1001\n",
      "Epoch [27/50], Step [65/735], Loss: 0.0711\n",
      "Epoch [27/50], Step [66/735], Loss: 0.0489\n",
      "Epoch [27/50], Step [67/735], Loss: 0.1386\n",
      "Epoch [27/50], Step [68/735], Loss: 0.0405\n",
      "Epoch [27/50], Step [69/735], Loss: 0.0288\n",
      "Epoch [27/50], Step [70/735], Loss: 0.1247\n",
      "Epoch [27/50], Step [71/735], Loss: 0.0161\n",
      "Epoch [27/50], Step [72/735], Loss: 0.2097\n",
      "Epoch [27/50], Step [73/735], Loss: 0.0446\n",
      "Epoch [27/50], Step [74/735], Loss: 0.0399\n",
      "Epoch [27/50], Step [75/735], Loss: 0.0450\n",
      "Epoch [27/50], Step [76/735], Loss: 0.0804\n",
      "Epoch [27/50], Step [77/735], Loss: 0.0723\n",
      "Epoch [27/50], Step [78/735], Loss: 0.0527\n",
      "Epoch [27/50], Step [79/735], Loss: 0.0607\n",
      "Epoch [27/50], Step [80/735], Loss: 0.1023\n",
      "Epoch [27/50], Step [81/735], Loss: 0.0549\n",
      "Epoch [27/50], Step [82/735], Loss: 0.0327\n",
      "Epoch [27/50], Step [83/735], Loss: 0.0232\n",
      "Epoch [27/50], Step [84/735], Loss: 0.0661\n",
      "Epoch [27/50], Step [85/735], Loss: 0.0546\n",
      "Epoch [27/50], Step [86/735], Loss: 0.0373\n",
      "Epoch [27/50], Step [87/735], Loss: 0.0432\n",
      "Epoch [27/50], Step [88/735], Loss: 0.5570\n",
      "Epoch [27/50], Step [89/735], Loss: 0.0345\n",
      "Epoch [27/50], Step [90/735], Loss: 0.1844\n",
      "Epoch [27/50], Step [91/735], Loss: 0.0454\n",
      "Epoch [27/50], Step [92/735], Loss: 0.0906\n",
      "Epoch [27/50], Step [93/735], Loss: 0.0395\n",
      "Epoch [27/50], Step [94/735], Loss: 0.0973\n",
      "Epoch [27/50], Step [95/735], Loss: 0.0276\n",
      "Epoch [27/50], Step [96/735], Loss: 0.1708\n",
      "Epoch [27/50], Step [97/735], Loss: 0.0350\n",
      "Epoch [27/50], Step [98/735], Loss: 0.0316\n",
      "Epoch [27/50], Step [99/735], Loss: 0.0706\n",
      "Epoch [27/50], Step [100/735], Loss: 0.0699\n",
      "Epoch [27/50], Step [101/735], Loss: 0.0340\n",
      "Epoch [27/50], Step [102/735], Loss: 0.0518\n",
      "Epoch [27/50], Step [103/735], Loss: 0.0176\n",
      "Epoch [27/50], Step [104/735], Loss: 0.0255\n",
      "Epoch [27/50], Step [105/735], Loss: 0.0243\n",
      "Epoch [27/50], Step [106/735], Loss: 0.0929\n",
      "Epoch [27/50], Step [107/735], Loss: 0.1064\n",
      "Epoch [27/50], Step [108/735], Loss: 0.0843\n",
      "Epoch [27/50], Step [109/735], Loss: 0.0836\n",
      "Epoch [27/50], Step [110/735], Loss: 0.2212\n",
      "Epoch [27/50], Step [111/735], Loss: 0.0316\n",
      "Epoch [27/50], Step [112/735], Loss: 0.0427\n",
      "Epoch [27/50], Step [113/735], Loss: 0.0234\n",
      "Epoch [27/50], Step [114/735], Loss: 0.1174\n",
      "Epoch [27/50], Step [115/735], Loss: 0.0654\n",
      "Epoch [27/50], Step [116/735], Loss: 0.4309\n",
      "Epoch [27/50], Step [117/735], Loss: 0.0334\n",
      "Epoch [27/50], Step [118/735], Loss: 0.0495\n",
      "Epoch [27/50], Step [119/735], Loss: 0.0369\n",
      "Epoch [27/50], Step [120/735], Loss: 0.0467\n",
      "Epoch [27/50], Step [121/735], Loss: 0.0393\n",
      "Epoch [27/50], Step [122/735], Loss: 0.0888\n",
      "Epoch [27/50], Step [123/735], Loss: 0.0544\n",
      "Epoch [27/50], Step [124/735], Loss: 0.0673\n",
      "Epoch [27/50], Step [125/735], Loss: 0.1136\n",
      "Epoch [27/50], Step [126/735], Loss: 0.0551\n",
      "Epoch [27/50], Step [127/735], Loss: 0.0925\n",
      "Epoch [27/50], Step [128/735], Loss: 0.0557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Step [129/735], Loss: 0.3074\n",
      "Epoch [27/50], Step [130/735], Loss: 0.0289\n",
      "Epoch [27/50], Step [131/735], Loss: 0.0299\n",
      "Epoch [27/50], Step [132/735], Loss: 0.0420\n",
      "Epoch [27/50], Step [133/735], Loss: 0.1056\n",
      "Epoch [27/50], Step [134/735], Loss: 0.1484\n",
      "Epoch [27/50], Step [135/735], Loss: 0.0700\n",
      "Epoch [27/50], Step [136/735], Loss: 0.0476\n",
      "Epoch [27/50], Step [137/735], Loss: 0.0470\n",
      "Epoch [27/50], Step [138/735], Loss: 0.0524\n",
      "Epoch [27/50], Step [139/735], Loss: 0.2937\n",
      "Epoch [27/50], Step [140/735], Loss: 0.1073\n",
      "Epoch [27/50], Step [141/735], Loss: 0.0443\n",
      "Epoch [27/50], Step [142/735], Loss: 0.0296\n",
      "Epoch [27/50], Step [143/735], Loss: 0.0427\n",
      "Epoch [27/50], Step [144/735], Loss: 0.1283\n",
      "Epoch [27/50], Step [145/735], Loss: 0.0786\n",
      "Epoch [27/50], Step [146/735], Loss: 0.0379\n",
      "Epoch [27/50], Step [147/735], Loss: 0.0936\n",
      "Epoch [27/50], Step [148/735], Loss: 0.0547\n",
      "Epoch [27/50], Step [149/735], Loss: 0.0547\n",
      "Epoch [27/50], Step [150/735], Loss: 0.2647\n",
      "Epoch [27/50], Step [151/735], Loss: 0.0323\n",
      "Epoch [27/50], Step [152/735], Loss: 0.0570\n",
      "Epoch [27/50], Step [153/735], Loss: 0.0388\n",
      "Epoch [27/50], Step [154/735], Loss: 0.0250\n",
      "Epoch [27/50], Step [155/735], Loss: 0.0579\n",
      "Epoch [27/50], Step [156/735], Loss: 0.0194\n",
      "Epoch [27/50], Step [157/735], Loss: 0.2200\n",
      "Epoch [27/50], Step [158/735], Loss: 0.0828\n",
      "Epoch [27/50], Step [159/735], Loss: 0.1239\n",
      "Epoch [27/50], Step [160/735], Loss: 0.4442\n",
      "Epoch [27/50], Step [161/735], Loss: 0.0708\n",
      "Epoch [27/50], Step [162/735], Loss: 0.0863\n",
      "Epoch [27/50], Step [163/735], Loss: 0.0472\n",
      "Epoch [27/50], Step [164/735], Loss: 0.0715\n",
      "Epoch [27/50], Step [165/735], Loss: 0.1518\n",
      "Epoch [27/50], Step [166/735], Loss: 0.0576\n",
      "Epoch [27/50], Step [167/735], Loss: 0.0236\n",
      "Epoch [27/50], Step [168/735], Loss: 0.0863\n",
      "Epoch [27/50], Step [169/735], Loss: 0.0637\n",
      "Epoch [27/50], Step [170/735], Loss: 0.1281\n",
      "Epoch [27/50], Step [171/735], Loss: 0.0378\n",
      "Epoch [27/50], Step [172/735], Loss: 0.0463\n",
      "Epoch [27/50], Step [173/735], Loss: 0.0684\n",
      "Epoch [27/50], Step [174/735], Loss: 0.0601\n",
      "Epoch [27/50], Step [175/735], Loss: 0.0272\n",
      "Epoch [27/50], Step [176/735], Loss: 0.0794\n",
      "Epoch [27/50], Step [177/735], Loss: 0.0409\n",
      "Epoch [27/50], Step [178/735], Loss: 0.0460\n",
      "Epoch [27/50], Step [179/735], Loss: 0.0309\n",
      "Epoch [27/50], Step [180/735], Loss: 0.0257\n",
      "Epoch [27/50], Step [181/735], Loss: 0.0411\n",
      "Epoch [27/50], Step [182/735], Loss: 0.0441\n",
      "Epoch [27/50], Step [183/735], Loss: 0.2006\n",
      "Epoch [27/50], Step [184/735], Loss: 0.0425\n",
      "Epoch [27/50], Step [185/735], Loss: 0.0545\n",
      "Epoch [27/50], Step [186/735], Loss: 0.0859\n",
      "Epoch [27/50], Step [187/735], Loss: 0.0364\n",
      "Epoch [27/50], Step [188/735], Loss: 0.1292\n",
      "Epoch [27/50], Step [189/735], Loss: 0.0284\n",
      "Epoch [27/50], Step [190/735], Loss: 0.0621\n",
      "Epoch [27/50], Step [191/735], Loss: 0.0540\n",
      "Epoch [27/50], Step [192/735], Loss: 0.0593\n",
      "Epoch [27/50], Step [193/735], Loss: 0.0590\n",
      "Epoch [27/50], Step [194/735], Loss: 0.0281\n",
      "Epoch [27/50], Step [195/735], Loss: 0.0572\n",
      "Epoch [27/50], Step [196/735], Loss: 0.2408\n",
      "Epoch [27/50], Step [197/735], Loss: 0.0327\n",
      "Epoch [27/50], Step [198/735], Loss: 0.0428\n",
      "Epoch [27/50], Step [199/735], Loss: 0.1138\n",
      "Epoch [27/50], Step [200/735], Loss: 0.1811\n",
      "Epoch [27/50], Step [201/735], Loss: 0.0281\n",
      "Epoch [27/50], Step [202/735], Loss: 0.0477\n",
      "Epoch [27/50], Step [203/735], Loss: 0.0869\n",
      "Epoch [27/50], Step [204/735], Loss: 0.1017\n",
      "Epoch [27/50], Step [205/735], Loss: 0.0830\n",
      "Epoch [27/50], Step [206/735], Loss: 0.1806\n",
      "Epoch [27/50], Step [207/735], Loss: 0.0549\n",
      "Epoch [27/50], Step [208/735], Loss: 0.0813\n",
      "Epoch [27/50], Step [209/735], Loss: 0.0459\n",
      "Epoch [27/50], Step [210/735], Loss: 0.0227\n",
      "Epoch [27/50], Step [211/735], Loss: 0.1028\n",
      "Epoch [27/50], Step [212/735], Loss: 0.1818\n",
      "Epoch [27/50], Step [213/735], Loss: 0.0305\n",
      "Epoch [27/50], Step [214/735], Loss: 0.2332\n",
      "Epoch [27/50], Step [215/735], Loss: 0.0570\n",
      "Epoch [27/50], Step [216/735], Loss: 0.0721\n",
      "Epoch [27/50], Step [217/735], Loss: 0.1124\n",
      "Epoch [27/50], Step [218/735], Loss: 0.0766\n",
      "Epoch [27/50], Step [219/735], Loss: 0.1192\n",
      "Epoch [27/50], Step [220/735], Loss: 0.0955\n",
      "Epoch [27/50], Step [221/735], Loss: 0.0696\n",
      "Epoch [27/50], Step [222/735], Loss: 0.0501\n",
      "Epoch [27/50], Step [223/735], Loss: 0.0698\n",
      "Epoch [27/50], Step [224/735], Loss: 0.0282\n",
      "Epoch [27/50], Step [225/735], Loss: 0.0512\n",
      "Epoch [27/50], Step [226/735], Loss: 0.0951\n",
      "Epoch [27/50], Step [227/735], Loss: 0.0413\n",
      "Epoch [27/50], Step [228/735], Loss: 0.0681\n",
      "Epoch [27/50], Step [229/735], Loss: 0.0516\n",
      "Epoch [27/50], Step [230/735], Loss: 0.0585\n",
      "Epoch [27/50], Step [231/735], Loss: 0.0843\n",
      "Epoch [27/50], Step [232/735], Loss: 0.1057\n",
      "Epoch [27/50], Step [233/735], Loss: 0.0368\n",
      "Epoch [27/50], Step [234/735], Loss: 0.0423\n",
      "Epoch [27/50], Step [235/735], Loss: 0.0387\n",
      "Epoch [27/50], Step [236/735], Loss: 0.0424\n",
      "Epoch [27/50], Step [237/735], Loss: 0.0261\n",
      "Epoch [27/50], Step [238/735], Loss: 0.0222\n",
      "Epoch [27/50], Step [239/735], Loss: 0.0677\n",
      "Epoch [27/50], Step [240/735], Loss: 0.1523\n",
      "Epoch [27/50], Step [241/735], Loss: 0.0751\n",
      "Epoch [27/50], Step [242/735], Loss: 0.0454\n",
      "Epoch [27/50], Step [243/735], Loss: 0.0903\n",
      "Epoch [27/50], Step [244/735], Loss: 0.0726\n",
      "Epoch [27/50], Step [245/735], Loss: 0.0394\n",
      "Epoch [27/50], Step [246/735], Loss: 0.1069\n",
      "Epoch [27/50], Step [247/735], Loss: 0.0933\n",
      "Epoch [27/50], Step [248/735], Loss: 0.1172\n",
      "Epoch [27/50], Step [249/735], Loss: 0.0175\n",
      "Epoch [27/50], Step [250/735], Loss: 0.0315\n",
      "Epoch [27/50], Step [251/735], Loss: 0.1076\n",
      "Epoch [27/50], Step [252/735], Loss: 0.2068\n",
      "Epoch [27/50], Step [253/735], Loss: 0.0292\n",
      "Epoch [27/50], Step [254/735], Loss: 0.0351\n",
      "Epoch [27/50], Step [255/735], Loss: 0.0405\n",
      "Epoch [27/50], Step [256/735], Loss: 0.0888\n",
      "Epoch [27/50], Step [257/735], Loss: 0.0500\n",
      "Epoch [27/50], Step [258/735], Loss: 0.0190\n",
      "Epoch [27/50], Step [259/735], Loss: 0.0356\n",
      "Epoch [27/50], Step [260/735], Loss: 0.0474\n",
      "Epoch [27/50], Step [261/735], Loss: 0.0323\n",
      "Epoch [27/50], Step [262/735], Loss: 0.2131\n",
      "Epoch [27/50], Step [263/735], Loss: 0.0462\n",
      "Epoch [27/50], Step [264/735], Loss: 0.0340\n",
      "Epoch [27/50], Step [265/735], Loss: 0.1031\n",
      "Epoch [27/50], Step [266/735], Loss: 0.0605\n",
      "Epoch [27/50], Step [267/735], Loss: 0.0413\n",
      "Epoch [27/50], Step [268/735], Loss: 0.0228\n",
      "Epoch [27/50], Step [269/735], Loss: 0.0513\n",
      "Epoch [27/50], Step [270/735], Loss: 0.0223\n",
      "Epoch [27/50], Step [271/735], Loss: 0.1307\n",
      "Epoch [27/50], Step [272/735], Loss: 0.1097\n",
      "Epoch [27/50], Step [273/735], Loss: 0.0338\n",
      "Epoch [27/50], Step [274/735], Loss: 0.0289\n",
      "Epoch [27/50], Step [275/735], Loss: 0.0605\n",
      "Epoch [27/50], Step [276/735], Loss: 0.0510\n",
      "Epoch [27/50], Step [277/735], Loss: 0.0228\n",
      "Epoch [27/50], Step [278/735], Loss: 0.0481\n",
      "Epoch [27/50], Step [279/735], Loss: 0.0621\n",
      "Epoch [27/50], Step [280/735], Loss: 0.1010\n",
      "Epoch [27/50], Step [281/735], Loss: 0.1695\n",
      "Epoch [27/50], Step [282/735], Loss: 0.0230\n",
      "Epoch [27/50], Step [283/735], Loss: 0.0584\n",
      "Epoch [27/50], Step [284/735], Loss: 0.0756\n",
      "Epoch [27/50], Step [285/735], Loss: 0.2606\n",
      "Epoch [27/50], Step [286/735], Loss: 0.0384\n",
      "Epoch [27/50], Step [287/735], Loss: 0.0852\n",
      "Epoch [27/50], Step [288/735], Loss: 0.3748\n",
      "Epoch [27/50], Step [289/735], Loss: 0.0859\n",
      "Epoch [27/50], Step [290/735], Loss: 0.0705\n",
      "Epoch [27/50], Step [291/735], Loss: 0.1591\n",
      "Epoch [27/50], Step [292/735], Loss: 0.0755\n",
      "Epoch [27/50], Step [293/735], Loss: 0.0540\n",
      "Epoch [27/50], Step [294/735], Loss: 0.0416\n",
      "Epoch [27/50], Step [295/735], Loss: 0.0494\n",
      "Epoch [27/50], Step [296/735], Loss: 0.0635\n",
      "Epoch [27/50], Step [297/735], Loss: 0.0251\n",
      "Epoch [27/50], Step [298/735], Loss: 0.0325\n",
      "Epoch [27/50], Step [299/735], Loss: 0.0800\n",
      "Epoch [27/50], Step [300/735], Loss: 0.0584\n",
      "Epoch [27/50], Step [301/735], Loss: 0.0241\n",
      "Epoch [27/50], Step [302/735], Loss: 0.2328\n",
      "Epoch [27/50], Step [303/735], Loss: 0.1030\n",
      "Epoch [27/50], Step [304/735], Loss: 0.0665\n",
      "Epoch [27/50], Step [305/735], Loss: 0.0268\n",
      "Epoch [27/50], Step [306/735], Loss: 0.0360\n",
      "Epoch [27/50], Step [307/735], Loss: 0.0609\n",
      "Epoch [27/50], Step [308/735], Loss: 0.0648\n",
      "Epoch [27/50], Step [309/735], Loss: 0.0435\n",
      "Epoch [27/50], Step [310/735], Loss: 0.1114\n",
      "Epoch [27/50], Step [311/735], Loss: 0.0322\n",
      "Epoch [27/50], Step [312/735], Loss: 0.1669\n",
      "Epoch [27/50], Step [313/735], Loss: 0.0900\n",
      "Epoch [27/50], Step [314/735], Loss: 0.0468\n",
      "Epoch [27/50], Step [315/735], Loss: 0.0435\n",
      "Epoch [27/50], Step [316/735], Loss: 0.0658\n",
      "Epoch [27/50], Step [317/735], Loss: 0.0435\n",
      "Epoch [27/50], Step [318/735], Loss: 0.2772\n",
      "Epoch [27/50], Step [319/735], Loss: 0.0387\n",
      "Epoch [27/50], Step [320/735], Loss: 0.0435\n",
      "Epoch [27/50], Step [321/735], Loss: 0.1355\n",
      "Epoch [27/50], Step [322/735], Loss: 0.0556\n",
      "Epoch [27/50], Step [323/735], Loss: 0.1094\n",
      "Epoch [27/50], Step [324/735], Loss: 0.0197\n",
      "Epoch [27/50], Step [325/735], Loss: 0.0420\n",
      "Epoch [27/50], Step [326/735], Loss: 0.0252\n",
      "Epoch [27/50], Step [327/735], Loss: 0.0794\n",
      "Epoch [27/50], Step [328/735], Loss: 0.0339\n",
      "Epoch [27/50], Step [329/735], Loss: 0.0645\n",
      "Epoch [27/50], Step [330/735], Loss: 0.0253\n",
      "Epoch [27/50], Step [331/735], Loss: 0.1317\n",
      "Epoch [27/50], Step [332/735], Loss: 0.0629\n",
      "Epoch [27/50], Step [333/735], Loss: 0.0313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Step [334/735], Loss: 0.0332\n",
      "Epoch [27/50], Step [335/735], Loss: 0.0635\n",
      "Epoch [27/50], Step [336/735], Loss: 0.0261\n",
      "Epoch [27/50], Step [337/735], Loss: 0.0194\n",
      "Epoch [27/50], Step [338/735], Loss: 0.0409\n",
      "Epoch [27/50], Step [339/735], Loss: 0.0210\n",
      "Epoch [27/50], Step [340/735], Loss: 0.0607\n",
      "Epoch [27/50], Step [341/735], Loss: 0.0327\n",
      "Epoch [27/50], Step [342/735], Loss: 0.0895\n",
      "Epoch [27/50], Step [343/735], Loss: 0.1169\n",
      "Epoch [27/50], Step [344/735], Loss: 0.1890\n",
      "Epoch [27/50], Step [345/735], Loss: 0.0346\n",
      "Epoch [27/50], Step [346/735], Loss: 0.0173\n",
      "Epoch [27/50], Step [347/735], Loss: 0.0998\n",
      "Epoch [27/50], Step [348/735], Loss: 0.0485\n",
      "Epoch [27/50], Step [349/735], Loss: 0.0271\n",
      "Epoch [27/50], Step [350/735], Loss: 0.0347\n",
      "Epoch [27/50], Step [351/735], Loss: 0.1102\n",
      "Epoch [27/50], Step [352/735], Loss: 0.0468\n",
      "Epoch [27/50], Step [353/735], Loss: 0.3670\n",
      "Epoch [27/50], Step [354/735], Loss: 0.0394\n",
      "Epoch [27/50], Step [355/735], Loss: 0.0588\n",
      "Epoch [27/50], Step [356/735], Loss: 0.0793\n",
      "Epoch [27/50], Step [357/735], Loss: 0.1312\n",
      "Epoch [27/50], Step [358/735], Loss: 0.0574\n",
      "Epoch [27/50], Step [359/735], Loss: 0.0482\n",
      "Epoch [27/50], Step [360/735], Loss: 0.0261\n",
      "Epoch [27/50], Step [361/735], Loss: 0.2879\n",
      "Epoch [27/50], Step [362/735], Loss: 0.1627\n",
      "Epoch [27/50], Step [363/735], Loss: 0.0256\n",
      "Epoch [27/50], Step [364/735], Loss: 0.0501\n",
      "Epoch [27/50], Step [365/735], Loss: 0.0562\n",
      "Epoch [27/50], Step [366/735], Loss: 0.0268\n",
      "Epoch [27/50], Step [367/735], Loss: 0.0285\n",
      "Epoch [27/50], Step [368/735], Loss: 0.0423\n",
      "Epoch [27/50], Step [369/735], Loss: 0.0898\n",
      "Epoch [27/50], Step [370/735], Loss: 0.1442\n",
      "Epoch [27/50], Step [371/735], Loss: 0.0491\n",
      "Epoch [27/50], Step [372/735], Loss: 0.0253\n",
      "Epoch [27/50], Step [373/735], Loss: 0.0926\n",
      "Epoch [27/50], Step [374/735], Loss: 0.0308\n",
      "Epoch [27/50], Step [375/735], Loss: 0.0921\n",
      "Epoch [27/50], Step [376/735], Loss: 0.0346\n",
      "Epoch [27/50], Step [377/735], Loss: 0.0715\n",
      "Epoch [27/50], Step [378/735], Loss: 0.3123\n",
      "Epoch [27/50], Step [379/735], Loss: 0.1120\n",
      "Epoch [27/50], Step [380/735], Loss: 0.1072\n",
      "Epoch [27/50], Step [381/735], Loss: 0.0707\n",
      "Epoch [27/50], Step [382/735], Loss: 0.1593\n",
      "Epoch [27/50], Step [383/735], Loss: 0.0670\n",
      "Epoch [27/50], Step [384/735], Loss: 0.0419\n",
      "Epoch [27/50], Step [385/735], Loss: 0.0577\n",
      "Epoch [27/50], Step [386/735], Loss: 0.2234\n",
      "Epoch [27/50], Step [387/735], Loss: 0.0720\n",
      "Epoch [27/50], Step [388/735], Loss: 0.0277\n",
      "Epoch [27/50], Step [389/735], Loss: 0.0549\n",
      "Epoch [27/50], Step [390/735], Loss: 0.0375\n",
      "Epoch [27/50], Step [391/735], Loss: 0.0200\n",
      "Epoch [27/50], Step [392/735], Loss: 0.0214\n",
      "Epoch [27/50], Step [393/735], Loss: 0.0794\n",
      "Epoch [27/50], Step [394/735], Loss: 0.0837\n",
      "Epoch [27/50], Step [395/735], Loss: 0.0844\n",
      "Epoch [27/50], Step [396/735], Loss: 0.0417\n",
      "Epoch [27/50], Step [397/735], Loss: 0.0572\n",
      "Epoch [27/50], Step [398/735], Loss: 0.0252\n",
      "Epoch [27/50], Step [399/735], Loss: 0.0606\n",
      "Epoch [27/50], Step [400/735], Loss: 0.0130\n",
      "Epoch [27/50], Step [401/735], Loss: 0.1368\n",
      "Epoch [27/50], Step [402/735], Loss: 0.0265\n",
      "Epoch [27/50], Step [403/735], Loss: 0.0607\n",
      "Epoch [27/50], Step [404/735], Loss: 0.0619\n",
      "Epoch [27/50], Step [405/735], Loss: 0.0349\n",
      "Epoch [27/50], Step [406/735], Loss: 0.0622\n",
      "Epoch [27/50], Step [407/735], Loss: 0.0538\n",
      "Epoch [27/50], Step [408/735], Loss: 0.0229\n",
      "Epoch [27/50], Step [409/735], Loss: 0.0270\n",
      "Epoch [27/50], Step [410/735], Loss: 0.0859\n",
      "Epoch [27/50], Step [411/735], Loss: 0.0685\n",
      "Epoch [27/50], Step [412/735], Loss: 0.0647\n",
      "Epoch [27/50], Step [413/735], Loss: 0.0375\n",
      "Epoch [27/50], Step [414/735], Loss: 0.1066\n",
      "Epoch [27/50], Step [415/735], Loss: 0.1010\n",
      "Epoch [27/50], Step [416/735], Loss: 0.0448\n",
      "Epoch [27/50], Step [417/735], Loss: 0.1936\n",
      "Epoch [27/50], Step [418/735], Loss: 0.0224\n",
      "Epoch [27/50], Step [419/735], Loss: 0.0224\n",
      "Epoch [27/50], Step [420/735], Loss: 0.0373\n",
      "Epoch [27/50], Step [421/735], Loss: 0.0243\n",
      "Epoch [27/50], Step [422/735], Loss: 0.0363\n",
      "Epoch [27/50], Step [423/735], Loss: 0.0553\n",
      "Epoch [27/50], Step [424/735], Loss: 0.0228\n",
      "Epoch [27/50], Step [425/735], Loss: 0.0096\n",
      "Epoch [27/50], Step [426/735], Loss: 0.0791\n",
      "Epoch [27/50], Step [427/735], Loss: 0.3080\n",
      "Epoch [27/50], Step [428/735], Loss: 0.0925\n",
      "Epoch [27/50], Step [429/735], Loss: 0.0629\n",
      "Epoch [27/50], Step [430/735], Loss: 0.0440\n",
      "Epoch [27/50], Step [431/735], Loss: 0.0309\n",
      "Epoch [27/50], Step [432/735], Loss: 0.0409\n",
      "Epoch [27/50], Step [433/735], Loss: 0.0430\n",
      "Epoch [27/50], Step [434/735], Loss: 0.0789\n",
      "Epoch [27/50], Step [435/735], Loss: 0.0705\n",
      "Epoch [27/50], Step [436/735], Loss: 0.1395\n",
      "Epoch [27/50], Step [437/735], Loss: 0.0601\n",
      "Epoch [27/50], Step [438/735], Loss: 0.0224\n",
      "Epoch [27/50], Step [439/735], Loss: 0.0218\n",
      "Epoch [27/50], Step [440/735], Loss: 0.1011\n",
      "Epoch [27/50], Step [441/735], Loss: 0.0324\n",
      "Epoch [27/50], Step [442/735], Loss: 0.1711\n",
      "Epoch [27/50], Step [443/735], Loss: 0.0282\n",
      "Epoch [27/50], Step [444/735], Loss: 0.0823\n",
      "Epoch [27/50], Step [445/735], Loss: 0.1697\n",
      "Epoch [27/50], Step [446/735], Loss: 0.0789\n",
      "Epoch [27/50], Step [447/735], Loss: 0.0546\n",
      "Epoch [27/50], Step [448/735], Loss: 0.0310\n",
      "Epoch [27/50], Step [449/735], Loss: 0.0735\n",
      "Epoch [27/50], Step [450/735], Loss: 0.1299\n",
      "Epoch [27/50], Step [451/735], Loss: 0.0620\n",
      "Epoch [27/50], Step [452/735], Loss: 0.2020\n",
      "Epoch [27/50], Step [453/735], Loss: 0.0346\n",
      "Epoch [27/50], Step [454/735], Loss: 0.0245\n",
      "Epoch [27/50], Step [455/735], Loss: 0.0296\n",
      "Epoch [27/50], Step [456/735], Loss: 0.1033\n",
      "Epoch [27/50], Step [457/735], Loss: 0.1100\n",
      "Epoch [27/50], Step [458/735], Loss: 0.0581\n",
      "Epoch [27/50], Step [459/735], Loss: 0.0376\n",
      "Epoch [27/50], Step [460/735], Loss: 0.0641\n",
      "Epoch [27/50], Step [461/735], Loss: 0.1149\n",
      "Epoch [27/50], Step [462/735], Loss: 0.0172\n",
      "Epoch [27/50], Step [463/735], Loss: 0.5718\n",
      "Epoch [27/50], Step [464/735], Loss: 0.0174\n",
      "Epoch [27/50], Step [465/735], Loss: 0.0973\n",
      "Epoch [27/50], Step [466/735], Loss: 0.0979\n",
      "Epoch [27/50], Step [467/735], Loss: 0.0333\n",
      "Epoch [27/50], Step [468/735], Loss: 0.0892\n",
      "Epoch [27/50], Step [469/735], Loss: 0.0959\n",
      "Epoch [27/50], Step [470/735], Loss: 0.0647\n",
      "Epoch [27/50], Step [471/735], Loss: 0.0629\n",
      "Epoch [27/50], Step [472/735], Loss: 0.0421\n",
      "Epoch [27/50], Step [473/735], Loss: 0.0754\n",
      "Epoch [27/50], Step [474/735], Loss: 0.1283\n",
      "Epoch [27/50], Step [475/735], Loss: 0.0244\n",
      "Epoch [27/50], Step [476/735], Loss: 0.0428\n",
      "Epoch [27/50], Step [477/735], Loss: 0.0749\n",
      "Epoch [27/50], Step [478/735], Loss: 0.0293\n",
      "Epoch [27/50], Step [479/735], Loss: 0.0566\n",
      "Epoch [27/50], Step [480/735], Loss: 0.0245\n",
      "Epoch [27/50], Step [481/735], Loss: 0.1003\n",
      "Epoch [27/50], Step [482/735], Loss: 0.0294\n",
      "Epoch [27/50], Step [483/735], Loss: 0.0271\n",
      "Epoch [27/50], Step [484/735], Loss: 0.0307\n",
      "Epoch [27/50], Step [485/735], Loss: 0.1048\n",
      "Epoch [27/50], Step [486/735], Loss: 0.1007\n",
      "Epoch [27/50], Step [487/735], Loss: 0.0929\n",
      "Epoch [27/50], Step [488/735], Loss: 0.0772\n",
      "Epoch [27/50], Step [489/735], Loss: 0.1613\n",
      "Epoch [27/50], Step [490/735], Loss: 0.0273\n",
      "Epoch [27/50], Step [491/735], Loss: 0.0231\n",
      "Epoch [27/50], Step [492/735], Loss: 0.0380\n",
      "Epoch [27/50], Step [493/735], Loss: 0.1102\n",
      "Epoch [27/50], Step [494/735], Loss: 0.1049\n",
      "Epoch [27/50], Step [495/735], Loss: 0.1913\n",
      "Epoch [27/50], Step [496/735], Loss: 0.1135\n",
      "Epoch [27/50], Step [497/735], Loss: 0.0493\n",
      "Epoch [27/50], Step [498/735], Loss: 0.0828\n",
      "Epoch [27/50], Step [499/735], Loss: 0.4638\n",
      "Epoch [27/50], Step [500/735], Loss: 0.0725\n",
      "Epoch [27/50], Step [501/735], Loss: 0.0224\n",
      "Epoch [27/50], Step [502/735], Loss: 0.0902\n",
      "Epoch [27/50], Step [503/735], Loss: 0.1298\n",
      "Epoch [27/50], Step [504/735], Loss: 0.1005\n",
      "Epoch [27/50], Step [505/735], Loss: 0.0339\n",
      "Epoch [27/50], Step [506/735], Loss: 0.2311\n",
      "Epoch [27/50], Step [507/735], Loss: 0.0514\n",
      "Epoch [27/50], Step [508/735], Loss: 0.0527\n",
      "Epoch [27/50], Step [509/735], Loss: 0.1228\n",
      "Epoch [27/50], Step [510/735], Loss: 0.0153\n",
      "Epoch [27/50], Step [511/735], Loss: 0.0646\n",
      "Epoch [27/50], Step [512/735], Loss: 0.2456\n",
      "Epoch [27/50], Step [513/735], Loss: 0.0582\n",
      "Epoch [27/50], Step [514/735], Loss: 0.0550\n",
      "Epoch [27/50], Step [515/735], Loss: 0.0499\n",
      "Epoch [27/50], Step [516/735], Loss: 0.0889\n",
      "Epoch [27/50], Step [517/735], Loss: 0.0716\n",
      "Epoch [27/50], Step [518/735], Loss: 0.0649\n",
      "Epoch [27/50], Step [519/735], Loss: 0.0421\n",
      "Epoch [27/50], Step [520/735], Loss: 0.0902\n",
      "Epoch [27/50], Step [521/735], Loss: 0.1109\n",
      "Epoch [27/50], Step [522/735], Loss: 0.0328\n",
      "Epoch [27/50], Step [523/735], Loss: 0.0806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Step [524/735], Loss: 0.0397\n",
      "Epoch [27/50], Step [525/735], Loss: 0.0474\n",
      "Epoch [27/50], Step [526/735], Loss: 0.0779\n",
      "Epoch [27/50], Step [527/735], Loss: 0.0535\n",
      "Epoch [27/50], Step [528/735], Loss: 0.0605\n",
      "Epoch [27/50], Step [529/735], Loss: 0.0200\n",
      "Epoch [27/50], Step [530/735], Loss: 0.0307\n",
      "Epoch [27/50], Step [531/735], Loss: 0.1265\n",
      "Epoch [27/50], Step [532/735], Loss: 0.0605\n",
      "Epoch [27/50], Step [533/735], Loss: 0.0183\n",
      "Epoch [27/50], Step [534/735], Loss: 0.0174\n",
      "Epoch [27/50], Step [535/735], Loss: 0.0853\n",
      "Epoch [27/50], Step [536/735], Loss: 0.0605\n",
      "Epoch [27/50], Step [537/735], Loss: 0.1076\n",
      "Epoch [27/50], Step [538/735], Loss: 0.0949\n",
      "Epoch [27/50], Step [539/735], Loss: 0.0214\n",
      "Epoch [27/50], Step [540/735], Loss: 0.0767\n",
      "Epoch [27/50], Step [541/735], Loss: 0.0474\n",
      "Epoch [27/50], Step [542/735], Loss: 0.0499\n",
      "Epoch [27/50], Step [543/735], Loss: 0.0282\n",
      "Epoch [27/50], Step [544/735], Loss: 0.0443\n",
      "Epoch [27/50], Step [545/735], Loss: 0.0401\n",
      "Epoch [27/50], Step [546/735], Loss: 0.0347\n",
      "Epoch [27/50], Step [547/735], Loss: 0.0875\n",
      "Epoch [27/50], Step [548/735], Loss: 0.1266\n",
      "Epoch [27/50], Step [549/735], Loss: 0.1166\n",
      "Epoch [27/50], Step [550/735], Loss: 0.0392\n",
      "Epoch [27/50], Step [551/735], Loss: 0.0336\n",
      "Epoch [27/50], Step [552/735], Loss: 0.0893\n",
      "Epoch [27/50], Step [553/735], Loss: 0.1173\n",
      "Epoch [27/50], Step [554/735], Loss: 0.0392\n",
      "Epoch [27/50], Step [555/735], Loss: 0.0931\n",
      "Epoch [27/50], Step [556/735], Loss: 0.1302\n",
      "Epoch [27/50], Step [557/735], Loss: 0.0634\n",
      "Epoch [27/50], Step [558/735], Loss: 0.2127\n",
      "Epoch [27/50], Step [559/735], Loss: 0.0327\n",
      "Epoch [27/50], Step [560/735], Loss: 0.0782\n",
      "Epoch [27/50], Step [561/735], Loss: 0.0574\n",
      "Epoch [27/50], Step [562/735], Loss: 0.4463\n",
      "Epoch [27/50], Step [563/735], Loss: 0.0347\n",
      "Epoch [27/50], Step [564/735], Loss: 0.1509\n",
      "Epoch [27/50], Step [565/735], Loss: 0.1027\n",
      "Epoch [27/50], Step [566/735], Loss: 0.0596\n",
      "Epoch [27/50], Step [567/735], Loss: 0.0419\n",
      "Epoch [27/50], Step [568/735], Loss: 0.0781\n",
      "Epoch [27/50], Step [569/735], Loss: 0.0708\n",
      "Epoch [27/50], Step [570/735], Loss: 0.0641\n",
      "Epoch [27/50], Step [571/735], Loss: 0.2048\n",
      "Epoch [27/50], Step [572/735], Loss: 0.1063\n",
      "Epoch [27/50], Step [573/735], Loss: 0.0438\n",
      "Epoch [27/50], Step [574/735], Loss: 0.1308\n",
      "Epoch [27/50], Step [575/735], Loss: 0.0452\n",
      "Epoch [27/50], Step [576/735], Loss: 0.0609\n",
      "Epoch [27/50], Step [577/735], Loss: 0.0877\n",
      "Epoch [27/50], Step [578/735], Loss: 0.1136\n",
      "Epoch [27/50], Step [579/735], Loss: 0.1562\n",
      "Epoch [27/50], Step [580/735], Loss: 0.0429\n",
      "Epoch [27/50], Step [581/735], Loss: 0.1009\n",
      "Epoch [27/50], Step [582/735], Loss: 0.0309\n",
      "Epoch [27/50], Step [583/735], Loss: 0.0880\n",
      "Epoch [27/50], Step [584/735], Loss: 0.0848\n",
      "Epoch [27/50], Step [585/735], Loss: 0.0454\n",
      "Epoch [27/50], Step [586/735], Loss: 0.1011\n",
      "Epoch [27/50], Step [587/735], Loss: 0.0305\n",
      "Epoch [27/50], Step [588/735], Loss: 0.0306\n",
      "Epoch [27/50], Step [589/735], Loss: 0.0460\n",
      "Epoch [27/50], Step [590/735], Loss: 0.0368\n",
      "Epoch [27/50], Step [591/735], Loss: 0.1334\n",
      "Epoch [27/50], Step [592/735], Loss: 0.0895\n",
      "Epoch [27/50], Step [593/735], Loss: 0.0675\n",
      "Epoch [27/50], Step [594/735], Loss: 0.0777\n",
      "Epoch [27/50], Step [595/735], Loss: 0.0763\n",
      "Epoch [27/50], Step [596/735], Loss: 0.0687\n",
      "Epoch [27/50], Step [597/735], Loss: 0.0585\n",
      "Epoch [27/50], Step [598/735], Loss: 0.2022\n",
      "Epoch [27/50], Step [599/735], Loss: 0.0856\n",
      "Epoch [27/50], Step [600/735], Loss: 0.0191\n",
      "Epoch [27/50], Step [601/735], Loss: 0.0911\n",
      "Epoch [27/50], Step [602/735], Loss: 0.0389\n",
      "Epoch [27/50], Step [603/735], Loss: 0.0793\n",
      "Epoch [27/50], Step [604/735], Loss: 0.0850\n",
      "Epoch [27/50], Step [605/735], Loss: 0.1700\n",
      "Epoch [27/50], Step [606/735], Loss: 0.1425\n",
      "Epoch [27/50], Step [607/735], Loss: 0.0563\n",
      "Epoch [27/50], Step [608/735], Loss: 0.0490\n",
      "Epoch [27/50], Step [609/735], Loss: 0.0432\n",
      "Epoch [27/50], Step [610/735], Loss: 0.0724\n",
      "Epoch [27/50], Step [611/735], Loss: 0.0984\n",
      "Epoch [27/50], Step [612/735], Loss: 0.0716\n",
      "Epoch [27/50], Step [613/735], Loss: 0.0860\n",
      "Epoch [27/50], Step [614/735], Loss: 0.1457\n",
      "Epoch [27/50], Step [615/735], Loss: 0.1064\n",
      "Epoch [27/50], Step [616/735], Loss: 0.0563\n",
      "Epoch [27/50], Step [617/735], Loss: 0.0696\n",
      "Epoch [27/50], Step [618/735], Loss: 0.0511\n",
      "Epoch [27/50], Step [619/735], Loss: 0.0896\n",
      "Epoch [27/50], Step [620/735], Loss: 0.0521\n",
      "Epoch [27/50], Step [621/735], Loss: 0.0453\n",
      "Epoch [27/50], Step [622/735], Loss: 0.0497\n",
      "Epoch [27/50], Step [623/735], Loss: 0.0232\n",
      "Epoch [27/50], Step [624/735], Loss: 0.1261\n",
      "Epoch [27/50], Step [625/735], Loss: 0.0299\n",
      "Epoch [27/50], Step [626/735], Loss: 0.0594\n",
      "Epoch [27/50], Step [627/735], Loss: 0.1872\n",
      "Epoch [27/50], Step [628/735], Loss: 0.0587\n",
      "Epoch [27/50], Step [629/735], Loss: 0.0885\n",
      "Epoch [27/50], Step [630/735], Loss: 0.2349\n",
      "Epoch [27/50], Step [631/735], Loss: 0.0731\n",
      "Epoch [27/50], Step [632/735], Loss: 0.0331\n",
      "Epoch [27/50], Step [633/735], Loss: 0.0350\n",
      "Epoch [27/50], Step [634/735], Loss: 0.0162\n",
      "Epoch [27/50], Step [635/735], Loss: 0.0860\n",
      "Epoch [27/50], Step [636/735], Loss: 0.0393\n",
      "Epoch [27/50], Step [637/735], Loss: 0.0326\n",
      "Epoch [27/50], Step [638/735], Loss: 0.0284\n",
      "Epoch [27/50], Step [639/735], Loss: 0.1136\n",
      "Epoch [27/50], Step [640/735], Loss: 0.0309\n",
      "Epoch [27/50], Step [641/735], Loss: 0.0666\n",
      "Epoch [27/50], Step [642/735], Loss: 0.0927\n",
      "Epoch [27/50], Step [643/735], Loss: 0.1055\n",
      "Epoch [27/50], Step [644/735], Loss: 0.0960\n",
      "Epoch [27/50], Step [645/735], Loss: 0.0376\n",
      "Epoch [27/50], Step [646/735], Loss: 0.3160\n",
      "Epoch [27/50], Step [647/735], Loss: 0.0285\n",
      "Epoch [27/50], Step [648/735], Loss: 0.0396\n",
      "Epoch [27/50], Step [649/735], Loss: 0.0350\n",
      "Epoch [27/50], Step [650/735], Loss: 0.0487\n",
      "Epoch [27/50], Step [651/735], Loss: 0.0830\n",
      "Epoch [27/50], Step [652/735], Loss: 0.0611\n",
      "Epoch [27/50], Step [653/735], Loss: 0.0846\n",
      "Epoch [27/50], Step [654/735], Loss: 0.0595\n",
      "Epoch [27/50], Step [655/735], Loss: 0.2085\n",
      "Epoch [27/50], Step [656/735], Loss: 0.0471\n",
      "Epoch [27/50], Step [657/735], Loss: 0.1142\n",
      "Epoch [27/50], Step [658/735], Loss: 0.0214\n",
      "Epoch [27/50], Step [659/735], Loss: 0.2114\n",
      "Epoch [27/50], Step [660/735], Loss: 0.0530\n",
      "Epoch [27/50], Step [661/735], Loss: 0.2660\n",
      "Epoch [27/50], Step [662/735], Loss: 0.0198\n",
      "Epoch [27/50], Step [663/735], Loss: 0.0350\n",
      "Epoch [27/50], Step [664/735], Loss: 0.0688\n",
      "Epoch [27/50], Step [665/735], Loss: 0.0717\n",
      "Epoch [27/50], Step [666/735], Loss: 0.0650\n",
      "Epoch [27/50], Step [667/735], Loss: 0.0412\n",
      "Epoch [27/50], Step [668/735], Loss: 0.2841\n",
      "Epoch [27/50], Step [669/735], Loss: 0.0972\n",
      "Epoch [27/50], Step [670/735], Loss: 0.0347\n",
      "Epoch [27/50], Step [671/735], Loss: 0.0593\n",
      "Epoch [27/50], Step [672/735], Loss: 0.1606\n",
      "Epoch [27/50], Step [673/735], Loss: 0.0211\n",
      "Epoch [27/50], Step [674/735], Loss: 0.1794\n",
      "Epoch [27/50], Step [675/735], Loss: 0.0347\n",
      "Epoch [27/50], Step [676/735], Loss: 0.0567\n",
      "Epoch [27/50], Step [677/735], Loss: 0.0532\n",
      "Epoch [27/50], Step [678/735], Loss: 0.0503\n",
      "Epoch [27/50], Step [679/735], Loss: 0.0750\n",
      "Epoch [27/50], Step [680/735], Loss: 0.0421\n",
      "Epoch [27/50], Step [681/735], Loss: 0.2678\n",
      "Epoch [27/50], Step [682/735], Loss: 0.0497\n",
      "Epoch [27/50], Step [683/735], Loss: 0.0643\n",
      "Epoch [27/50], Step [684/735], Loss: 0.0886\n",
      "Epoch [27/50], Step [685/735], Loss: 0.0650\n",
      "Epoch [27/50], Step [686/735], Loss: 0.0705\n",
      "Epoch [27/50], Step [687/735], Loss: 0.3887\n",
      "Epoch [27/50], Step [688/735], Loss: 0.0952\n",
      "Epoch [27/50], Step [689/735], Loss: 0.0732\n",
      "Epoch [27/50], Step [690/735], Loss: 0.0286\n",
      "Epoch [27/50], Step [691/735], Loss: 0.0730\n",
      "Epoch [27/50], Step [692/735], Loss: 0.0804\n",
      "Epoch [27/50], Step [693/735], Loss: 0.1352\n",
      "Epoch [27/50], Step [694/735], Loss: 0.0474\n",
      "Epoch [27/50], Step [695/735], Loss: 0.0422\n",
      "Epoch [27/50], Step [696/735], Loss: 0.1936\n",
      "Epoch [27/50], Step [697/735], Loss: 0.0393\n",
      "Epoch [27/50], Step [698/735], Loss: 0.0261\n",
      "Epoch [27/50], Step [699/735], Loss: 0.0416\n",
      "Epoch [27/50], Step [700/735], Loss: 0.0417\n",
      "Epoch [27/50], Step [701/735], Loss: 0.0213\n",
      "Epoch [27/50], Step [702/735], Loss: 0.0616\n",
      "Epoch [27/50], Step [703/735], Loss: 0.0678\n",
      "Epoch [27/50], Step [704/735], Loss: 0.0569\n",
      "Epoch [27/50], Step [705/735], Loss: 0.0254\n",
      "Epoch [27/50], Step [706/735], Loss: 0.0768\n",
      "Epoch [27/50], Step [707/735], Loss: 0.0595\n",
      "Epoch [27/50], Step [708/735], Loss: 0.0391\n",
      "Epoch [27/50], Step [709/735], Loss: 0.0514\n",
      "Epoch [27/50], Step [710/735], Loss: 0.0514\n",
      "Epoch [27/50], Step [711/735], Loss: 0.0487\n",
      "Epoch [27/50], Step [712/735], Loss: 0.0231\n",
      "Epoch [27/50], Step [713/735], Loss: 0.0512\n",
      "Epoch [27/50], Step [714/735], Loss: 0.0319\n",
      "Epoch [27/50], Step [715/735], Loss: 0.0293\n",
      "Epoch [27/50], Step [716/735], Loss: 0.1414\n",
      "Epoch [27/50], Step [717/735], Loss: 0.0675\n",
      "Epoch [27/50], Step [718/735], Loss: 0.2190\n",
      "Epoch [27/50], Step [719/735], Loss: 0.1036\n",
      "Epoch [27/50], Step [720/735], Loss: 0.1013\n",
      "Epoch [27/50], Step [721/735], Loss: 0.0677\n",
      "Epoch [27/50], Step [722/735], Loss: 0.1006\n",
      "Epoch [27/50], Step [723/735], Loss: 0.2168\n",
      "Epoch [27/50], Step [724/735], Loss: 0.0130\n",
      "Epoch [27/50], Step [725/735], Loss: 0.1309\n",
      "Epoch [27/50], Step [726/735], Loss: 0.0818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Step [727/735], Loss: 0.0424\n",
      "Epoch [27/50], Step [728/735], Loss: 0.0594\n",
      "Epoch [27/50], Step [729/735], Loss: 0.1542\n",
      "Epoch [27/50], Step [730/735], Loss: 0.0708\n",
      "Epoch [27/50], Step [731/735], Loss: 0.0496\n",
      "Epoch [27/50], Step [732/735], Loss: 0.1037\n",
      "Epoch [27/50], Step [733/735], Loss: 0.0865\n",
      "Epoch [27/50], Step [734/735], Loss: 0.0502\n",
      "Epoch [27/50], Step [735/735], Loss: 0.1046\n",
      "Epoch [28/50], Step [1/735], Loss: 0.1275\n",
      "Epoch [28/50], Step [2/735], Loss: 0.1713\n",
      "Epoch [28/50], Step [3/735], Loss: 0.0929\n",
      "Epoch [28/50], Step [4/735], Loss: 0.0684\n",
      "Epoch [28/50], Step [5/735], Loss: 0.0915\n",
      "Epoch [28/50], Step [6/735], Loss: 0.0651\n",
      "Epoch [28/50], Step [7/735], Loss: 0.0670\n",
      "Epoch [28/50], Step [8/735], Loss: 0.0513\n",
      "Epoch [28/50], Step [9/735], Loss: 0.0407\n",
      "Epoch [28/50], Step [10/735], Loss: 0.0270\n",
      "Epoch [28/50], Step [11/735], Loss: 0.0441\n",
      "Epoch [28/50], Step [12/735], Loss: 0.0389\n",
      "Epoch [28/50], Step [13/735], Loss: 0.0327\n",
      "Epoch [28/50], Step [14/735], Loss: 0.0462\n",
      "Epoch [28/50], Step [15/735], Loss: 0.0473\n",
      "Epoch [28/50], Step [16/735], Loss: 0.0444\n",
      "Epoch [28/50], Step [17/735], Loss: 0.0317\n",
      "Epoch [28/50], Step [18/735], Loss: 0.0470\n",
      "Epoch [28/50], Step [19/735], Loss: 0.0776\n",
      "Epoch [28/50], Step [20/735], Loss: 0.0840\n",
      "Epoch [28/50], Step [21/735], Loss: 0.0562\n",
      "Epoch [28/50], Step [22/735], Loss: 0.0506\n",
      "Epoch [28/50], Step [23/735], Loss: 0.0388\n",
      "Epoch [28/50], Step [24/735], Loss: 0.0356\n",
      "Epoch [28/50], Step [25/735], Loss: 0.0406\n",
      "Epoch [28/50], Step [26/735], Loss: 0.0407\n",
      "Epoch [28/50], Step [27/735], Loss: 0.1286\n",
      "Epoch [28/50], Step [28/735], Loss: 0.0523\n",
      "Epoch [28/50], Step [29/735], Loss: 0.0397\n",
      "Epoch [28/50], Step [30/735], Loss: 0.2211\n",
      "Epoch [28/50], Step [31/735], Loss: 0.0499\n",
      "Epoch [28/50], Step [32/735], Loss: 0.1438\n",
      "Epoch [28/50], Step [33/735], Loss: 0.0424\n",
      "Epoch [28/50], Step [34/735], Loss: 0.0344\n",
      "Epoch [28/50], Step [35/735], Loss: 0.1833\n",
      "Epoch [28/50], Step [36/735], Loss: 0.0510\n",
      "Epoch [28/50], Step [37/735], Loss: 0.1699\n",
      "Epoch [28/50], Step [38/735], Loss: 0.0365\n",
      "Epoch [28/50], Step [39/735], Loss: 0.0438\n",
      "Epoch [28/50], Step [40/735], Loss: 0.0537\n",
      "Epoch [28/50], Step [41/735], Loss: 0.1534\n",
      "Epoch [28/50], Step [42/735], Loss: 0.0449\n",
      "Epoch [28/50], Step [43/735], Loss: 0.0385\n",
      "Epoch [28/50], Step [44/735], Loss: 0.0270\n",
      "Epoch [28/50], Step [45/735], Loss: 0.0507\n",
      "Epoch [28/50], Step [46/735], Loss: 0.0404\n",
      "Epoch [28/50], Step [47/735], Loss: 0.1839\n",
      "Epoch [28/50], Step [48/735], Loss: 0.0587\n",
      "Epoch [28/50], Step [49/735], Loss: 0.0335\n",
      "Epoch [28/50], Step [50/735], Loss: 0.0599\n",
      "Epoch [28/50], Step [51/735], Loss: 0.0680\n",
      "Epoch [28/50], Step [52/735], Loss: 0.0176\n",
      "Epoch [28/50], Step [53/735], Loss: 0.0351\n",
      "Epoch [28/50], Step [54/735], Loss: 0.0414\n",
      "Epoch [28/50], Step [55/735], Loss: 0.0176\n",
      "Epoch [28/50], Step [56/735], Loss: 0.0700\n",
      "Epoch [28/50], Step [57/735], Loss: 0.0786\n",
      "Epoch [28/50], Step [58/735], Loss: 0.0149\n",
      "Epoch [28/50], Step [59/735], Loss: 0.0136\n",
      "Epoch [28/50], Step [60/735], Loss: 0.1349\n",
      "Epoch [28/50], Step [61/735], Loss: 0.0830\n",
      "Epoch [28/50], Step [62/735], Loss: 0.0795\n",
      "Epoch [28/50], Step [63/735], Loss: 0.0499\n",
      "Epoch [28/50], Step [64/735], Loss: 0.0655\n",
      "Epoch [28/50], Step [65/735], Loss: 0.1156\n",
      "Epoch [28/50], Step [66/735], Loss: 0.0346\n",
      "Epoch [28/50], Step [67/735], Loss: 0.1667\n",
      "Epoch [28/50], Step [68/735], Loss: 0.1054\n",
      "Epoch [28/50], Step [69/735], Loss: 0.0603\n",
      "Epoch [28/50], Step [70/735], Loss: 0.0512\n",
      "Epoch [28/50], Step [71/735], Loss: 0.0319\n",
      "Epoch [28/50], Step [72/735], Loss: 0.0797\n",
      "Epoch [28/50], Step [73/735], Loss: 0.0295\n",
      "Epoch [28/50], Step [74/735], Loss: 0.0470\n",
      "Epoch [28/50], Step [75/735], Loss: 0.0501\n",
      "Epoch [28/50], Step [76/735], Loss: 0.0158\n",
      "Epoch [28/50], Step [77/735], Loss: 0.0269\n",
      "Epoch [28/50], Step [78/735], Loss: 0.0375\n",
      "Epoch [28/50], Step [79/735], Loss: 0.0559\n",
      "Epoch [28/50], Step [80/735], Loss: 0.0606\n",
      "Epoch [28/50], Step [81/735], Loss: 0.2573\n",
      "Epoch [28/50], Step [82/735], Loss: 0.0399\n",
      "Epoch [28/50], Step [83/735], Loss: 0.0437\n",
      "Epoch [28/50], Step [84/735], Loss: 0.1617\n",
      "Epoch [28/50], Step [85/735], Loss: 0.0608\n",
      "Epoch [28/50], Step [86/735], Loss: 0.0270\n",
      "Epoch [28/50], Step [87/735], Loss: 0.1404\n",
      "Epoch [28/50], Step [88/735], Loss: 0.1217\n",
      "Epoch [28/50], Step [89/735], Loss: 0.0550\n",
      "Epoch [28/50], Step [90/735], Loss: 0.0248\n",
      "Epoch [28/50], Step [91/735], Loss: 0.0634\n",
      "Epoch [28/50], Step [92/735], Loss: 0.0600\n",
      "Epoch [28/50], Step [93/735], Loss: 0.0677\n",
      "Epoch [28/50], Step [94/735], Loss: 0.0435\n",
      "Epoch [28/50], Step [95/735], Loss: 0.1777\n",
      "Epoch [28/50], Step [96/735], Loss: 0.1241\n",
      "Epoch [28/50], Step [97/735], Loss: 0.0381\n",
      "Epoch [28/50], Step [98/735], Loss: 0.0885\n",
      "Epoch [28/50], Step [99/735], Loss: 0.0344\n",
      "Epoch [28/50], Step [100/735], Loss: 0.0571\n",
      "Epoch [28/50], Step [101/735], Loss: 0.0459\n",
      "Epoch [28/50], Step [102/735], Loss: 0.0744\n",
      "Epoch [28/50], Step [103/735], Loss: 0.0437\n",
      "Epoch [28/50], Step [104/735], Loss: 0.0392\n",
      "Epoch [28/50], Step [105/735], Loss: 0.0344\n",
      "Epoch [28/50], Step [106/735], Loss: 0.0361\n",
      "Epoch [28/50], Step [107/735], Loss: 0.0572\n",
      "Epoch [28/50], Step [108/735], Loss: 0.1361\n",
      "Epoch [28/50], Step [109/735], Loss: 0.0294\n",
      "Epoch [28/50], Step [110/735], Loss: 0.0496\n",
      "Epoch [28/50], Step [111/735], Loss: 0.1408\n",
      "Epoch [28/50], Step [112/735], Loss: 0.1106\n",
      "Epoch [28/50], Step [113/735], Loss: 0.0676\n",
      "Epoch [28/50], Step [114/735], Loss: 0.0823\n",
      "Epoch [28/50], Step [115/735], Loss: 0.0615\n",
      "Epoch [28/50], Step [116/735], Loss: 0.0258\n",
      "Epoch [28/50], Step [117/735], Loss: 0.0383\n",
      "Epoch [28/50], Step [118/735], Loss: 0.0457\n",
      "Epoch [28/50], Step [119/735], Loss: 0.0497\n",
      "Epoch [28/50], Step [120/735], Loss: 0.0160\n",
      "Epoch [28/50], Step [121/735], Loss: 0.1585\n",
      "Epoch [28/50], Step [122/735], Loss: 0.0183\n",
      "Epoch [28/50], Step [123/735], Loss: 0.0252\n",
      "Epoch [28/50], Step [124/735], Loss: 0.0759\n",
      "Epoch [28/50], Step [125/735], Loss: 0.0286\n",
      "Epoch [28/50], Step [126/735], Loss: 0.0414\n",
      "Epoch [28/50], Step [127/735], Loss: 0.0264\n",
      "Epoch [28/50], Step [128/735], Loss: 0.0184\n",
      "Epoch [28/50], Step [129/735], Loss: 0.1557\n",
      "Epoch [28/50], Step [130/735], Loss: 0.1310\n",
      "Epoch [28/50], Step [131/735], Loss: 0.1060\n",
      "Epoch [28/50], Step [132/735], Loss: 0.0460\n",
      "Epoch [28/50], Step [133/735], Loss: 0.0448\n",
      "Epoch [28/50], Step [134/735], Loss: 0.0153\n",
      "Epoch [28/50], Step [135/735], Loss: 0.0564\n",
      "Epoch [28/50], Step [136/735], Loss: 0.0358\n",
      "Epoch [28/50], Step [137/735], Loss: 0.0846\n",
      "Epoch [28/50], Step [138/735], Loss: 0.0335\n",
      "Epoch [28/50], Step [139/735], Loss: 0.0177\n",
      "Epoch [28/50], Step [140/735], Loss: 0.0431\n",
      "Epoch [28/50], Step [141/735], Loss: 0.1648\n",
      "Epoch [28/50], Step [142/735], Loss: 0.0123\n",
      "Epoch [28/50], Step [143/735], Loss: 0.0468\n",
      "Epoch [28/50], Step [144/735], Loss: 0.0683\n",
      "Epoch [28/50], Step [145/735], Loss: 0.0577\n",
      "Epoch [28/50], Step [146/735], Loss: 0.0252\n",
      "Epoch [28/50], Step [147/735], Loss: 0.0670\n",
      "Epoch [28/50], Step [148/735], Loss: 0.0459\n",
      "Epoch [28/50], Step [149/735], Loss: 0.0605\n",
      "Epoch [28/50], Step [150/735], Loss: 0.0739\n",
      "Epoch [28/50], Step [151/735], Loss: 0.1394\n",
      "Epoch [28/50], Step [152/735], Loss: 0.0318\n",
      "Epoch [28/50], Step [153/735], Loss: 0.0576\n",
      "Epoch [28/50], Step [154/735], Loss: 0.0497\n",
      "Epoch [28/50], Step [155/735], Loss: 0.1065\n",
      "Epoch [28/50], Step [156/735], Loss: 0.2366\n",
      "Epoch [28/50], Step [157/735], Loss: 0.0666\n",
      "Epoch [28/50], Step [158/735], Loss: 0.0367\n",
      "Epoch [28/50], Step [159/735], Loss: 0.2202\n",
      "Epoch [28/50], Step [160/735], Loss: 0.0679\n",
      "Epoch [28/50], Step [161/735], Loss: 0.0934\n",
      "Epoch [28/50], Step [162/735], Loss: 0.0654\n",
      "Epoch [28/50], Step [163/735], Loss: 0.0446\n",
      "Epoch [28/50], Step [164/735], Loss: 0.0494\n",
      "Epoch [28/50], Step [165/735], Loss: 0.0650\n",
      "Epoch [28/50], Step [166/735], Loss: 0.1285\n",
      "Epoch [28/50], Step [167/735], Loss: 0.0620\n",
      "Epoch [28/50], Step [168/735], Loss: 0.0985\n",
      "Epoch [28/50], Step [169/735], Loss: 0.0257\n",
      "Epoch [28/50], Step [170/735], Loss: 0.0446\n",
      "Epoch [28/50], Step [171/735], Loss: 0.0261\n",
      "Epoch [28/50], Step [172/735], Loss: 0.1387\n",
      "Epoch [28/50], Step [173/735], Loss: 0.1417\n",
      "Epoch [28/50], Step [174/735], Loss: 0.0403\n",
      "Epoch [28/50], Step [175/735], Loss: 0.0565\n",
      "Epoch [28/50], Step [176/735], Loss: 0.0712\n",
      "Epoch [28/50], Step [177/735], Loss: 0.0580\n",
      "Epoch [28/50], Step [178/735], Loss: 0.1461\n",
      "Epoch [28/50], Step [179/735], Loss: 0.0952\n",
      "Epoch [28/50], Step [180/735], Loss: 0.2099\n",
      "Epoch [28/50], Step [181/735], Loss: 0.3710\n",
      "Epoch [28/50], Step [182/735], Loss: 0.0917\n",
      "Epoch [28/50], Step [183/735], Loss: 0.3595\n",
      "Epoch [28/50], Step [184/735], Loss: 0.1520\n",
      "Epoch [28/50], Step [185/735], Loss: 0.0639\n",
      "Epoch [28/50], Step [186/735], Loss: 0.0448\n",
      "Epoch [28/50], Step [187/735], Loss: 0.0999\n",
      "Epoch [28/50], Step [188/735], Loss: 0.0563\n",
      "Epoch [28/50], Step [189/735], Loss: 0.1321\n",
      "Epoch [28/50], Step [190/735], Loss: 0.0786\n",
      "Epoch [28/50], Step [191/735], Loss: 0.0694\n",
      "Epoch [28/50], Step [192/735], Loss: 0.0529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Step [193/735], Loss: 0.0456\n",
      "Epoch [28/50], Step [194/735], Loss: 0.0655\n",
      "Epoch [28/50], Step [195/735], Loss: 0.0684\n",
      "Epoch [28/50], Step [196/735], Loss: 0.0602\n",
      "Epoch [28/50], Step [197/735], Loss: 0.1726\n",
      "Epoch [28/50], Step [198/735], Loss: 0.1531\n",
      "Epoch [28/50], Step [199/735], Loss: 0.0830\n",
      "Epoch [28/50], Step [200/735], Loss: 0.0476\n",
      "Epoch [28/50], Step [201/735], Loss: 0.0139\n",
      "Epoch [28/50], Step [202/735], Loss: 0.1254\n",
      "Epoch [28/50], Step [203/735], Loss: 0.0229\n",
      "Epoch [28/50], Step [204/735], Loss: 0.0271\n",
      "Epoch [28/50], Step [205/735], Loss: 0.0857\n",
      "Epoch [28/50], Step [206/735], Loss: 0.0300\n",
      "Epoch [28/50], Step [207/735], Loss: 0.0719\n",
      "Epoch [28/50], Step [208/735], Loss: 0.0827\n",
      "Epoch [28/50], Step [209/735], Loss: 0.0809\n",
      "Epoch [28/50], Step [210/735], Loss: 0.0184\n",
      "Epoch [28/50], Step [211/735], Loss: 0.0729\n",
      "Epoch [28/50], Step [212/735], Loss: 0.0604\n",
      "Epoch [28/50], Step [213/735], Loss: 0.0233\n",
      "Epoch [28/50], Step [214/735], Loss: 0.0476\n",
      "Epoch [28/50], Step [215/735], Loss: 0.0194\n",
      "Epoch [28/50], Step [216/735], Loss: 0.1840\n",
      "Epoch [28/50], Step [217/735], Loss: 0.0599\n",
      "Epoch [28/50], Step [218/735], Loss: 0.0507\n",
      "Epoch [28/50], Step [219/735], Loss: 0.0649\n",
      "Epoch [28/50], Step [220/735], Loss: 0.0299\n",
      "Epoch [28/50], Step [221/735], Loss: 0.0870\n",
      "Epoch [28/50], Step [222/735], Loss: 0.0300\n",
      "Epoch [28/50], Step [223/735], Loss: 0.0491\n",
      "Epoch [28/50], Step [224/735], Loss: 0.0590\n",
      "Epoch [28/50], Step [225/735], Loss: 0.0906\n",
      "Epoch [28/50], Step [226/735], Loss: 0.1292\n",
      "Epoch [28/50], Step [227/735], Loss: 0.5871\n",
      "Epoch [28/50], Step [228/735], Loss: 0.0536\n",
      "Epoch [28/50], Step [229/735], Loss: 0.1391\n",
      "Epoch [28/50], Step [230/735], Loss: 0.0677\n",
      "Epoch [28/50], Step [231/735], Loss: 0.0412\n",
      "Epoch [28/50], Step [232/735], Loss: 0.0904\n",
      "Epoch [28/50], Step [233/735], Loss: 0.0174\n",
      "Epoch [28/50], Step [234/735], Loss: 0.0818\n",
      "Epoch [28/50], Step [235/735], Loss: 0.1279\n",
      "Epoch [28/50], Step [236/735], Loss: 0.0525\n",
      "Epoch [28/50], Step [237/735], Loss: 0.1063\n",
      "Epoch [28/50], Step [238/735], Loss: 0.0341\n",
      "Epoch [28/50], Step [239/735], Loss: 0.0771\n",
      "Epoch [28/50], Step [240/735], Loss: 0.0947\n",
      "Epoch [28/50], Step [241/735], Loss: 0.1017\n",
      "Epoch [28/50], Step [242/735], Loss: 0.0833\n",
      "Epoch [28/50], Step [243/735], Loss: 0.0849\n",
      "Epoch [28/50], Step [244/735], Loss: 0.0506\n",
      "Epoch [28/50], Step [245/735], Loss: 0.0367\n",
      "Epoch [28/50], Step [246/735], Loss: 0.0530\n",
      "Epoch [28/50], Step [247/735], Loss: 0.1095\n",
      "Epoch [28/50], Step [248/735], Loss: 0.1060\n",
      "Epoch [28/50], Step [249/735], Loss: 0.1456\n",
      "Epoch [28/50], Step [250/735], Loss: 0.0463\n",
      "Epoch [28/50], Step [251/735], Loss: 0.0598\n",
      "Epoch [28/50], Step [252/735], Loss: 0.0573\n",
      "Epoch [28/50], Step [253/735], Loss: 0.0476\n",
      "Epoch [28/50], Step [254/735], Loss: 0.0850\n",
      "Epoch [28/50], Step [255/735], Loss: 0.0235\n",
      "Epoch [28/50], Step [256/735], Loss: 0.1035\n",
      "Epoch [28/50], Step [257/735], Loss: 0.0832\n",
      "Epoch [28/50], Step [258/735], Loss: 0.0370\n",
      "Epoch [28/50], Step [259/735], Loss: 0.0670\n",
      "Epoch [28/50], Step [260/735], Loss: 0.1236\n",
      "Epoch [28/50], Step [261/735], Loss: 0.0221\n",
      "Epoch [28/50], Step [262/735], Loss: 0.0658\n",
      "Epoch [28/50], Step [263/735], Loss: 0.0255\n",
      "Epoch [28/50], Step [264/735], Loss: 0.0580\n",
      "Epoch [28/50], Step [265/735], Loss: 0.0394\n",
      "Epoch [28/50], Step [266/735], Loss: 0.2800\n",
      "Epoch [28/50], Step [267/735], Loss: 0.0197\n",
      "Epoch [28/50], Step [268/735], Loss: 0.1320\n",
      "Epoch [28/50], Step [269/735], Loss: 0.0485\n",
      "Epoch [28/50], Step [270/735], Loss: 0.0904\n",
      "Epoch [28/50], Step [271/735], Loss: 0.0335\n",
      "Epoch [28/50], Step [272/735], Loss: 0.0836\n",
      "Epoch [28/50], Step [273/735], Loss: 0.0316\n",
      "Epoch [28/50], Step [274/735], Loss: 0.0620\n",
      "Epoch [28/50], Step [275/735], Loss: 0.1742\n",
      "Epoch [28/50], Step [276/735], Loss: 0.0355\n",
      "Epoch [28/50], Step [277/735], Loss: 0.0500\n",
      "Epoch [28/50], Step [278/735], Loss: 0.0606\n",
      "Epoch [28/50], Step [279/735], Loss: 0.0202\n",
      "Epoch [28/50], Step [280/735], Loss: 0.0337\n",
      "Epoch [28/50], Step [281/735], Loss: 0.0234\n",
      "Epoch [28/50], Step [282/735], Loss: 0.0206\n",
      "Epoch [28/50], Step [283/735], Loss: 0.0801\n",
      "Epoch [28/50], Step [284/735], Loss: 0.0997\n",
      "Epoch [28/50], Step [285/735], Loss: 0.0591\n",
      "Epoch [28/50], Step [286/735], Loss: 0.1581\n",
      "Epoch [28/50], Step [287/735], Loss: 0.0237\n",
      "Epoch [28/50], Step [288/735], Loss: 0.1124\n",
      "Epoch [28/50], Step [289/735], Loss: 0.0458\n",
      "Epoch [28/50], Step [290/735], Loss: 0.0502\n",
      "Epoch [28/50], Step [291/735], Loss: 0.0935\n",
      "Epoch [28/50], Step [292/735], Loss: 0.0329\n",
      "Epoch [28/50], Step [293/735], Loss: 0.1141\n",
      "Epoch [28/50], Step [294/735], Loss: 0.0807\n",
      "Epoch [28/50], Step [295/735], Loss: 0.1720\n",
      "Epoch [28/50], Step [296/735], Loss: 0.0307\n",
      "Epoch [28/50], Step [297/735], Loss: 0.0470\n",
      "Epoch [28/50], Step [298/735], Loss: 0.1095\n",
      "Epoch [28/50], Step [299/735], Loss: 0.0369\n",
      "Epoch [28/50], Step [300/735], Loss: 0.0826\n",
      "Epoch [28/50], Step [301/735], Loss: 0.1214\n",
      "Epoch [28/50], Step [302/735], Loss: 0.0400\n",
      "Epoch [28/50], Step [303/735], Loss: 0.0323\n",
      "Epoch [28/50], Step [304/735], Loss: 0.0402\n",
      "Epoch [28/50], Step [305/735], Loss: 0.0614\n",
      "Epoch [28/50], Step [306/735], Loss: 0.1227\n",
      "Epoch [28/50], Step [307/735], Loss: 0.0362\n",
      "Epoch [28/50], Step [308/735], Loss: 0.0588\n",
      "Epoch [28/50], Step [309/735], Loss: 0.0895\n",
      "Epoch [28/50], Step [310/735], Loss: 0.0260\n",
      "Epoch [28/50], Step [311/735], Loss: 0.0265\n",
      "Epoch [28/50], Step [312/735], Loss: 0.0663\n",
      "Epoch [28/50], Step [313/735], Loss: 0.0526\n",
      "Epoch [28/50], Step [314/735], Loss: 0.0262\n",
      "Epoch [28/50], Step [315/735], Loss: 0.1697\n",
      "Epoch [28/50], Step [316/735], Loss: 0.0318\n",
      "Epoch [28/50], Step [317/735], Loss: 0.0714\n",
      "Epoch [28/50], Step [318/735], Loss: 0.0927\n",
      "Epoch [28/50], Step [319/735], Loss: 0.0768\n",
      "Epoch [28/50], Step [320/735], Loss: 0.0834\n",
      "Epoch [28/50], Step [321/735], Loss: 0.2153\n",
      "Epoch [28/50], Step [322/735], Loss: 0.1460\n",
      "Epoch [28/50], Step [323/735], Loss: 0.5336\n",
      "Epoch [28/50], Step [324/735], Loss: 0.0573\n",
      "Epoch [28/50], Step [325/735], Loss: 0.2311\n",
      "Epoch [28/50], Step [326/735], Loss: 0.2835\n",
      "Epoch [28/50], Step [327/735], Loss: 0.0259\n",
      "Epoch [28/50], Step [328/735], Loss: 0.0494\n",
      "Epoch [28/50], Step [329/735], Loss: 0.0480\n",
      "Epoch [28/50], Step [330/735], Loss: 0.1148\n",
      "Epoch [28/50], Step [331/735], Loss: 0.1482\n",
      "Epoch [28/50], Step [332/735], Loss: 0.2270\n",
      "Epoch [28/50], Step [333/735], Loss: 0.0898\n",
      "Epoch [28/50], Step [334/735], Loss: 0.0754\n",
      "Epoch [28/50], Step [335/735], Loss: 0.0517\n",
      "Epoch [28/50], Step [336/735], Loss: 0.0333\n",
      "Epoch [28/50], Step [337/735], Loss: 0.0526\n",
      "Epoch [28/50], Step [338/735], Loss: 0.0466\n",
      "Epoch [28/50], Step [339/735], Loss: 0.0515\n",
      "Epoch [28/50], Step [340/735], Loss: 0.0206\n",
      "Epoch [28/50], Step [341/735], Loss: 0.0351\n",
      "Epoch [28/50], Step [342/735], Loss: 0.1315\n",
      "Epoch [28/50], Step [343/735], Loss: 0.0711\n",
      "Epoch [28/50], Step [344/735], Loss: 0.0326\n",
      "Epoch [28/50], Step [345/735], Loss: 0.0250\n",
      "Epoch [28/50], Step [346/735], Loss: 0.0408\n",
      "Epoch [28/50], Step [347/735], Loss: 0.0628\n",
      "Epoch [28/50], Step [348/735], Loss: 0.0948\n",
      "Epoch [28/50], Step [349/735], Loss: 0.0292\n",
      "Epoch [28/50], Step [350/735], Loss: 0.0737\n",
      "Epoch [28/50], Step [351/735], Loss: 0.0802\n",
      "Epoch [28/50], Step [352/735], Loss: 0.0275\n",
      "Epoch [28/50], Step [353/735], Loss: 0.1109\n",
      "Epoch [28/50], Step [354/735], Loss: 0.0332\n",
      "Epoch [28/50], Step [355/735], Loss: 0.0829\n",
      "Epoch [28/50], Step [356/735], Loss: 0.0435\n",
      "Epoch [28/50], Step [357/735], Loss: 0.0470\n",
      "Epoch [28/50], Step [358/735], Loss: 0.0885\n",
      "Epoch [28/50], Step [359/735], Loss: 0.0458\n",
      "Epoch [28/50], Step [360/735], Loss: 0.0904\n",
      "Epoch [28/50], Step [361/735], Loss: 0.0416\n",
      "Epoch [28/50], Step [362/735], Loss: 0.0590\n",
      "Epoch [28/50], Step [363/735], Loss: 0.1825\n",
      "Epoch [28/50], Step [364/735], Loss: 0.0230\n",
      "Epoch [28/50], Step [365/735], Loss: 0.4656\n",
      "Epoch [28/50], Step [366/735], Loss: 0.0836\n",
      "Epoch [28/50], Step [367/735], Loss: 0.0638\n",
      "Epoch [28/50], Step [368/735], Loss: 0.0292\n",
      "Epoch [28/50], Step [369/735], Loss: 0.0267\n",
      "Epoch [28/50], Step [370/735], Loss: 0.0600\n",
      "Epoch [28/50], Step [371/735], Loss: 0.0252\n",
      "Epoch [28/50], Step [372/735], Loss: 0.0373\n",
      "Epoch [28/50], Step [373/735], Loss: 0.3412\n",
      "Epoch [28/50], Step [374/735], Loss: 0.0384\n",
      "Epoch [28/50], Step [375/735], Loss: 0.1017\n",
      "Epoch [28/50], Step [376/735], Loss: 0.0392\n",
      "Epoch [28/50], Step [377/735], Loss: 0.0846\n",
      "Epoch [28/50], Step [378/735], Loss: 0.0721\n",
      "Epoch [28/50], Step [379/735], Loss: 0.0194\n",
      "Epoch [28/50], Step [380/735], Loss: 0.0959\n",
      "Epoch [28/50], Step [381/735], Loss: 0.0523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Step [382/735], Loss: 0.0277\n",
      "Epoch [28/50], Step [383/735], Loss: 0.4196\n",
      "Epoch [28/50], Step [384/735], Loss: 0.0656\n",
      "Epoch [28/50], Step [385/735], Loss: 0.0970\n",
      "Epoch [28/50], Step [386/735], Loss: 0.0277\n",
      "Epoch [28/50], Step [387/735], Loss: 0.0187\n",
      "Epoch [28/50], Step [388/735], Loss: 0.0428\n",
      "Epoch [28/50], Step [389/735], Loss: 0.1166\n",
      "Epoch [28/50], Step [390/735], Loss: 0.4054\n",
      "Epoch [28/50], Step [391/735], Loss: 0.0225\n",
      "Epoch [28/50], Step [392/735], Loss: 0.0639\n",
      "Epoch [28/50], Step [393/735], Loss: 0.0194\n",
      "Epoch [28/50], Step [394/735], Loss: 0.0802\n",
      "Epoch [28/50], Step [395/735], Loss: 0.0346\n",
      "Epoch [28/50], Step [396/735], Loss: 0.0152\n",
      "Epoch [28/50], Step [397/735], Loss: 0.0533\n",
      "Epoch [28/50], Step [398/735], Loss: 0.0177\n",
      "Epoch [28/50], Step [399/735], Loss: 0.1058\n",
      "Epoch [28/50], Step [400/735], Loss: 0.0456\n",
      "Epoch [28/50], Step [401/735], Loss: 0.0442\n",
      "Epoch [28/50], Step [402/735], Loss: 0.0670\n",
      "Epoch [28/50], Step [403/735], Loss: 0.0895\n",
      "Epoch [28/50], Step [404/735], Loss: 0.0325\n",
      "Epoch [28/50], Step [405/735], Loss: 0.0470\n",
      "Epoch [28/50], Step [406/735], Loss: 0.0430\n",
      "Epoch [28/50], Step [407/735], Loss: 0.0582\n",
      "Epoch [28/50], Step [408/735], Loss: 0.1073\n",
      "Epoch [28/50], Step [409/735], Loss: 0.0390\n",
      "Epoch [28/50], Step [410/735], Loss: 0.0300\n",
      "Epoch [28/50], Step [411/735], Loss: 0.0670\n",
      "Epoch [28/50], Step [412/735], Loss: 0.0703\n",
      "Epoch [28/50], Step [413/735], Loss: 0.1263\n",
      "Epoch [28/50], Step [414/735], Loss: 0.0097\n",
      "Epoch [28/50], Step [415/735], Loss: 0.0374\n",
      "Epoch [28/50], Step [416/735], Loss: 0.0316\n",
      "Epoch [28/50], Step [417/735], Loss: 0.0355\n",
      "Epoch [28/50], Step [418/735], Loss: 0.0264\n",
      "Epoch [28/50], Step [419/735], Loss: 0.0830\n",
      "Epoch [28/50], Step [420/735], Loss: 0.0341\n",
      "Epoch [28/50], Step [421/735], Loss: 0.1277\n",
      "Epoch [28/50], Step [422/735], Loss: 0.1312\n",
      "Epoch [28/50], Step [423/735], Loss: 0.0546\n",
      "Epoch [28/50], Step [424/735], Loss: 0.0255\n",
      "Epoch [28/50], Step [425/735], Loss: 0.0700\n",
      "Epoch [28/50], Step [426/735], Loss: 0.0362\n",
      "Epoch [28/50], Step [427/735], Loss: 0.0749\n",
      "Epoch [28/50], Step [428/735], Loss: 0.0277\n",
      "Epoch [28/50], Step [429/735], Loss: 0.0979\n",
      "Epoch [28/50], Step [430/735], Loss: 0.0268\n",
      "Epoch [28/50], Step [431/735], Loss: 0.0310\n",
      "Epoch [28/50], Step [432/735], Loss: 0.0382\n",
      "Epoch [28/50], Step [433/735], Loss: 0.0332\n",
      "Epoch [28/50], Step [434/735], Loss: 0.0612\n",
      "Epoch [28/50], Step [435/735], Loss: 0.0755\n",
      "Epoch [28/50], Step [436/735], Loss: 0.1017\n",
      "Epoch [28/50], Step [437/735], Loss: 0.0619\n",
      "Epoch [28/50], Step [438/735], Loss: 0.0250\n",
      "Epoch [28/50], Step [439/735], Loss: 0.0362\n",
      "Epoch [28/50], Step [440/735], Loss: 0.0525\n",
      "Epoch [28/50], Step [441/735], Loss: 0.0511\n",
      "Epoch [28/50], Step [442/735], Loss: 0.0388\n",
      "Epoch [28/50], Step [443/735], Loss: 0.0827\n",
      "Epoch [28/50], Step [444/735], Loss: 0.0234\n",
      "Epoch [28/50], Step [445/735], Loss: 0.0949\n",
      "Epoch [28/50], Step [446/735], Loss: 0.0497\n",
      "Epoch [28/50], Step [447/735], Loss: 0.0588\n",
      "Epoch [28/50], Step [448/735], Loss: 0.0242\n",
      "Epoch [28/50], Step [449/735], Loss: 0.0892\n",
      "Epoch [28/50], Step [450/735], Loss: 0.0252\n",
      "Epoch [28/50], Step [451/735], Loss: 0.2546\n",
      "Epoch [28/50], Step [452/735], Loss: 0.0281\n",
      "Epoch [28/50], Step [453/735], Loss: 0.1102\n",
      "Epoch [28/50], Step [454/735], Loss: 0.0899\n",
      "Epoch [28/50], Step [455/735], Loss: 0.0884\n",
      "Epoch [28/50], Step [456/735], Loss: 0.4341\n",
      "Epoch [28/50], Step [457/735], Loss: 0.0324\n",
      "Epoch [28/50], Step [458/735], Loss: 0.1105\n",
      "Epoch [28/50], Step [459/735], Loss: 0.5342\n",
      "Epoch [28/50], Step [460/735], Loss: 0.0427\n",
      "Epoch [28/50], Step [461/735], Loss: 0.0557\n",
      "Epoch [28/50], Step [462/735], Loss: 0.0311\n",
      "Epoch [28/50], Step [463/735], Loss: 0.1864\n",
      "Epoch [28/50], Step [464/735], Loss: 0.2560\n",
      "Epoch [28/50], Step [465/735], Loss: 0.0579\n",
      "Epoch [28/50], Step [466/735], Loss: 0.2092\n",
      "Epoch [28/50], Step [467/735], Loss: 0.0852\n",
      "Epoch [28/50], Step [468/735], Loss: 0.1767\n",
      "Epoch [28/50], Step [469/735], Loss: 0.0310\n",
      "Epoch [28/50], Step [470/735], Loss: 0.0533\n",
      "Epoch [28/50], Step [471/735], Loss: 0.0299\n",
      "Epoch [28/50], Step [472/735], Loss: 0.0458\n",
      "Epoch [28/50], Step [473/735], Loss: 0.0432\n",
      "Epoch [28/50], Step [474/735], Loss: 0.0292\n",
      "Epoch [28/50], Step [475/735], Loss: 0.1757\n",
      "Epoch [28/50], Step [476/735], Loss: 0.1304\n",
      "Epoch [28/50], Step [477/735], Loss: 0.0759\n",
      "Epoch [28/50], Step [478/735], Loss: 0.1280\n",
      "Epoch [28/50], Step [479/735], Loss: 0.0493\n",
      "Epoch [28/50], Step [480/735], Loss: 0.0545\n",
      "Epoch [28/50], Step [481/735], Loss: 0.0388\n",
      "Epoch [28/50], Step [482/735], Loss: 0.0442\n",
      "Epoch [28/50], Step [483/735], Loss: 0.0150\n",
      "Epoch [28/50], Step [484/735], Loss: 0.0571\n",
      "Epoch [28/50], Step [485/735], Loss: 0.0243\n",
      "Epoch [28/50], Step [486/735], Loss: 0.0396\n",
      "Epoch [28/50], Step [487/735], Loss: 0.0660\n",
      "Epoch [28/50], Step [488/735], Loss: 0.0523\n",
      "Epoch [28/50], Step [489/735], Loss: 0.0593\n",
      "Epoch [28/50], Step [490/735], Loss: 0.0209\n",
      "Epoch [28/50], Step [491/735], Loss: 0.3530\n",
      "Epoch [28/50], Step [492/735], Loss: 0.0414\n",
      "Epoch [28/50], Step [493/735], Loss: 0.0504\n",
      "Epoch [28/50], Step [494/735], Loss: 0.0348\n",
      "Epoch [28/50], Step [495/735], Loss: 0.0527\n",
      "Epoch [28/50], Step [496/735], Loss: 0.0163\n",
      "Epoch [28/50], Step [497/735], Loss: 0.0485\n",
      "Epoch [28/50], Step [498/735], Loss: 0.0510\n",
      "Epoch [28/50], Step [499/735], Loss: 0.0520\n",
      "Epoch [28/50], Step [500/735], Loss: 0.0283\n",
      "Epoch [28/50], Step [501/735], Loss: 0.0665\n",
      "Epoch [28/50], Step [502/735], Loss: 0.0268\n",
      "Epoch [28/50], Step [503/735], Loss: 0.0349\n",
      "Epoch [28/50], Step [504/735], Loss: 0.0641\n",
      "Epoch [28/50], Step [505/735], Loss: 0.0372\n",
      "Epoch [28/50], Step [506/735], Loss: 0.0342\n",
      "Epoch [28/50], Step [507/735], Loss: 0.0318\n",
      "Epoch [28/50], Step [508/735], Loss: 0.0378\n",
      "Epoch [28/50], Step [509/735], Loss: 0.0410\n",
      "Epoch [28/50], Step [510/735], Loss: 0.0287\n",
      "Epoch [28/50], Step [511/735], Loss: 0.0145\n",
      "Epoch [28/50], Step [512/735], Loss: 0.0808\n",
      "Epoch [28/50], Step [513/735], Loss: 0.0326\n",
      "Epoch [28/50], Step [514/735], Loss: 0.0778\n",
      "Epoch [28/50], Step [515/735], Loss: 0.1024\n",
      "Epoch [28/50], Step [516/735], Loss: 0.0248\n",
      "Epoch [28/50], Step [517/735], Loss: 0.1006\n",
      "Epoch [28/50], Step [518/735], Loss: 0.0339\n",
      "Epoch [28/50], Step [519/735], Loss: 0.3638\n",
      "Epoch [28/50], Step [520/735], Loss: 0.0446\n",
      "Epoch [28/50], Step [521/735], Loss: 0.0321\n",
      "Epoch [28/50], Step [522/735], Loss: 0.0561\n",
      "Epoch [28/50], Step [523/735], Loss: 0.0256\n",
      "Epoch [28/50], Step [524/735], Loss: 0.0606\n",
      "Epoch [28/50], Step [525/735], Loss: 0.0263\n",
      "Epoch [28/50], Step [526/735], Loss: 0.1629\n",
      "Epoch [28/50], Step [527/735], Loss: 0.0314\n",
      "Epoch [28/50], Step [528/735], Loss: 0.0255\n",
      "Epoch [28/50], Step [529/735], Loss: 0.0510\n",
      "Epoch [28/50], Step [530/735], Loss: 0.0244\n",
      "Epoch [28/50], Step [531/735], Loss: 0.0655\n",
      "Epoch [28/50], Step [532/735], Loss: 0.0461\n",
      "Epoch [28/50], Step [533/735], Loss: 0.2216\n",
      "Epoch [28/50], Step [534/735], Loss: 0.0674\n",
      "Epoch [28/50], Step [535/735], Loss: 0.0321\n",
      "Epoch [28/50], Step [536/735], Loss: 0.0897\n",
      "Epoch [28/50], Step [537/735], Loss: 0.0418\n",
      "Epoch [28/50], Step [538/735], Loss: 0.1237\n",
      "Epoch [28/50], Step [539/735], Loss: 0.0720\n",
      "Epoch [28/50], Step [540/735], Loss: 0.0395\n",
      "Epoch [28/50], Step [541/735], Loss: 0.0473\n",
      "Epoch [28/50], Step [542/735], Loss: 0.0417\n",
      "Epoch [28/50], Step [543/735], Loss: 0.0292\n",
      "Epoch [28/50], Step [544/735], Loss: 0.1430\n",
      "Epoch [28/50], Step [545/735], Loss: 0.1232\n",
      "Epoch [28/50], Step [546/735], Loss: 0.1577\n",
      "Epoch [28/50], Step [547/735], Loss: 0.0528\n",
      "Epoch [28/50], Step [548/735], Loss: 0.0346\n",
      "Epoch [28/50], Step [549/735], Loss: 0.0502\n",
      "Epoch [28/50], Step [550/735], Loss: 0.0445\n",
      "Epoch [28/50], Step [551/735], Loss: 0.0885\n",
      "Epoch [28/50], Step [552/735], Loss: 0.0618\n",
      "Epoch [28/50], Step [553/735], Loss: 0.1624\n",
      "Epoch [28/50], Step [554/735], Loss: 0.0579\n",
      "Epoch [28/50], Step [555/735], Loss: 0.0217\n",
      "Epoch [28/50], Step [556/735], Loss: 0.0314\n",
      "Epoch [28/50], Step [557/735], Loss: 0.5009\n",
      "Epoch [28/50], Step [558/735], Loss: 0.0263\n",
      "Epoch [28/50], Step [559/735], Loss: 0.1249\n",
      "Epoch [28/50], Step [560/735], Loss: 0.0478\n",
      "Epoch [28/50], Step [561/735], Loss: 0.0978\n",
      "Epoch [28/50], Step [562/735], Loss: 0.0222\n",
      "Epoch [28/50], Step [563/735], Loss: 0.0377\n",
      "Epoch [28/50], Step [564/735], Loss: 0.0707\n",
      "Epoch [28/50], Step [565/735], Loss: 0.0805\n",
      "Epoch [28/50], Step [566/735], Loss: 0.0631\n",
      "Epoch [28/50], Step [567/735], Loss: 0.0860\n",
      "Epoch [28/50], Step [568/735], Loss: 0.0687\n",
      "Epoch [28/50], Step [569/735], Loss: 0.0581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Step [570/735], Loss: 0.0930\n",
      "Epoch [28/50], Step [571/735], Loss: 0.0315\n",
      "Epoch [28/50], Step [572/735], Loss: 0.0695\n",
      "Epoch [28/50], Step [573/735], Loss: 0.0863\n",
      "Epoch [28/50], Step [574/735], Loss: 0.0702\n",
      "Epoch [28/50], Step [575/735], Loss: 0.0381\n",
      "Epoch [28/50], Step [576/735], Loss: 0.0264\n",
      "Epoch [28/50], Step [577/735], Loss: 0.0466\n",
      "Epoch [28/50], Step [578/735], Loss: 0.0295\n",
      "Epoch [28/50], Step [579/735], Loss: 0.0470\n",
      "Epoch [28/50], Step [580/735], Loss: 0.1894\n",
      "Epoch [28/50], Step [581/735], Loss: 0.2178\n",
      "Epoch [28/50], Step [582/735], Loss: 0.0504\n",
      "Epoch [28/50], Step [583/735], Loss: 0.0180\n",
      "Epoch [28/50], Step [584/735], Loss: 0.0959\n",
      "Epoch [28/50], Step [585/735], Loss: 0.1864\n",
      "Epoch [28/50], Step [586/735], Loss: 0.0239\n",
      "Epoch [28/50], Step [587/735], Loss: 0.0140\n",
      "Epoch [28/50], Step [588/735], Loss: 0.1010\n",
      "Epoch [28/50], Step [589/735], Loss: 0.0775\n",
      "Epoch [28/50], Step [590/735], Loss: 0.0987\n",
      "Epoch [28/50], Step [591/735], Loss: 0.0332\n",
      "Epoch [28/50], Step [592/735], Loss: 0.1985\n",
      "Epoch [28/50], Step [593/735], Loss: 0.0644\n",
      "Epoch [28/50], Step [594/735], Loss: 0.1632\n",
      "Epoch [28/50], Step [595/735], Loss: 0.0275\n",
      "Epoch [28/50], Step [596/735], Loss: 0.0394\n",
      "Epoch [28/50], Step [597/735], Loss: 0.0374\n",
      "Epoch [28/50], Step [598/735], Loss: 0.0339\n",
      "Epoch [28/50], Step [599/735], Loss: 0.0561\n",
      "Epoch [28/50], Step [600/735], Loss: 0.0358\n",
      "Epoch [28/50], Step [601/735], Loss: 0.0310\n",
      "Epoch [28/50], Step [602/735], Loss: 0.0330\n",
      "Epoch [28/50], Step [603/735], Loss: 0.1667\n",
      "Epoch [28/50], Step [604/735], Loss: 0.2270\n",
      "Epoch [28/50], Step [605/735], Loss: 0.0462\n",
      "Epoch [28/50], Step [606/735], Loss: 0.3189\n",
      "Epoch [28/50], Step [607/735], Loss: 0.1064\n",
      "Epoch [28/50], Step [608/735], Loss: 0.0849\n",
      "Epoch [28/50], Step [609/735], Loss: 0.1155\n",
      "Epoch [28/50], Step [610/735], Loss: 0.1907\n",
      "Epoch [28/50], Step [611/735], Loss: 0.1030\n",
      "Epoch [28/50], Step [612/735], Loss: 0.0653\n",
      "Epoch [28/50], Step [613/735], Loss: 0.1625\n",
      "Epoch [28/50], Step [614/735], Loss: 0.1494\n",
      "Epoch [28/50], Step [615/735], Loss: 0.4189\n",
      "Epoch [28/50], Step [616/735], Loss: 0.0479\n",
      "Epoch [28/50], Step [617/735], Loss: 0.1186\n",
      "Epoch [28/50], Step [618/735], Loss: 0.0545\n",
      "Epoch [28/50], Step [619/735], Loss: 0.0882\n",
      "Epoch [28/50], Step [620/735], Loss: 0.0875\n",
      "Epoch [28/50], Step [621/735], Loss: 0.0764\n",
      "Epoch [28/50], Step [622/735], Loss: 0.0535\n",
      "Epoch [28/50], Step [623/735], Loss: 0.1242\n",
      "Epoch [28/50], Step [624/735], Loss: 0.0278\n",
      "Epoch [28/50], Step [625/735], Loss: 0.1273\n",
      "Epoch [28/50], Step [626/735], Loss: 0.0703\n",
      "Epoch [28/50], Step [627/735], Loss: 0.0841\n",
      "Epoch [28/50], Step [628/735], Loss: 0.0366\n",
      "Epoch [28/50], Step [629/735], Loss: 0.0579\n",
      "Epoch [28/50], Step [630/735], Loss: 0.1452\n",
      "Epoch [28/50], Step [631/735], Loss: 0.0495\n",
      "Epoch [28/50], Step [632/735], Loss: 0.0790\n",
      "Epoch [28/50], Step [633/735], Loss: 0.0686\n",
      "Epoch [28/50], Step [634/735], Loss: 0.0452\n",
      "Epoch [28/50], Step [635/735], Loss: 0.0392\n",
      "Epoch [28/50], Step [636/735], Loss: 0.0349\n",
      "Epoch [28/50], Step [637/735], Loss: 0.0841\n",
      "Epoch [28/50], Step [638/735], Loss: 0.0488\n",
      "Epoch [28/50], Step [639/735], Loss: 0.0492\n",
      "Epoch [28/50], Step [640/735], Loss: 0.0985\n",
      "Epoch [28/50], Step [641/735], Loss: 0.0206\n",
      "Epoch [28/50], Step [642/735], Loss: 0.0828\n",
      "Epoch [28/50], Step [643/735], Loss: 0.1395\n",
      "Epoch [28/50], Step [644/735], Loss: 0.0517\n",
      "Epoch [28/50], Step [645/735], Loss: 0.0553\n",
      "Epoch [28/50], Step [646/735], Loss: 0.0919\n",
      "Epoch [28/50], Step [647/735], Loss: 0.1807\n",
      "Epoch [28/50], Step [648/735], Loss: 0.0438\n",
      "Epoch [28/50], Step [649/735], Loss: 0.0641\n",
      "Epoch [28/50], Step [650/735], Loss: 0.0482\n",
      "Epoch [28/50], Step [651/735], Loss: 0.0327\n",
      "Epoch [28/50], Step [652/735], Loss: 0.0524\n",
      "Epoch [28/50], Step [653/735], Loss: 0.0521\n",
      "Epoch [28/50], Step [654/735], Loss: 0.2560\n",
      "Epoch [28/50], Step [655/735], Loss: 0.0553\n",
      "Epoch [28/50], Step [656/735], Loss: 0.1127\n",
      "Epoch [28/50], Step [657/735], Loss: 0.1697\n",
      "Epoch [28/50], Step [658/735], Loss: 0.3096\n",
      "Epoch [28/50], Step [659/735], Loss: 0.0364\n",
      "Epoch [28/50], Step [660/735], Loss: 0.1040\n",
      "Epoch [28/50], Step [661/735], Loss: 0.1088\n",
      "Epoch [28/50], Step [662/735], Loss: 0.2301\n",
      "Epoch [28/50], Step [663/735], Loss: 0.0458\n",
      "Epoch [28/50], Step [664/735], Loss: 0.1029\n",
      "Epoch [28/50], Step [665/735], Loss: 0.0783\n",
      "Epoch [28/50], Step [666/735], Loss: 0.0353\n",
      "Epoch [28/50], Step [667/735], Loss: 0.0584\n",
      "Epoch [28/50], Step [668/735], Loss: 0.0554\n",
      "Epoch [28/50], Step [669/735], Loss: 0.0487\n",
      "Epoch [28/50], Step [670/735], Loss: 0.0965\n",
      "Epoch [28/50], Step [671/735], Loss: 0.2807\n",
      "Epoch [28/50], Step [672/735], Loss: 0.1324\n",
      "Epoch [28/50], Step [673/735], Loss: 0.0964\n",
      "Epoch [28/50], Step [674/735], Loss: 0.0188\n",
      "Epoch [28/50], Step [675/735], Loss: 0.0518\n",
      "Epoch [28/50], Step [676/735], Loss: 0.0363\n",
      "Epoch [28/50], Step [677/735], Loss: 0.1321\n",
      "Epoch [28/50], Step [678/735], Loss: 0.0341\n",
      "Epoch [28/50], Step [679/735], Loss: 0.0416\n",
      "Epoch [28/50], Step [680/735], Loss: 0.1118\n",
      "Epoch [28/50], Step [681/735], Loss: 0.1236\n",
      "Epoch [28/50], Step [682/735], Loss: 0.0929\n",
      "Epoch [28/50], Step [683/735], Loss: 0.0658\n",
      "Epoch [28/50], Step [684/735], Loss: 0.3083\n",
      "Epoch [28/50], Step [685/735], Loss: 0.1131\n",
      "Epoch [28/50], Step [686/735], Loss: 0.0436\n",
      "Epoch [28/50], Step [687/735], Loss: 0.0562\n",
      "Epoch [28/50], Step [688/735], Loss: 0.0379\n",
      "Epoch [28/50], Step [689/735], Loss: 0.0501\n",
      "Epoch [28/50], Step [690/735], Loss: 0.0570\n",
      "Epoch [28/50], Step [691/735], Loss: 0.0331\n",
      "Epoch [28/50], Step [692/735], Loss: 0.0454\n",
      "Epoch [28/50], Step [693/735], Loss: 0.1429\n",
      "Epoch [28/50], Step [694/735], Loss: 0.2881\n",
      "Epoch [28/50], Step [695/735], Loss: 0.1408\n",
      "Epoch [28/50], Step [696/735], Loss: 0.1181\n",
      "Epoch [28/50], Step [697/735], Loss: 0.0232\n",
      "Epoch [28/50], Step [698/735], Loss: 0.0233\n",
      "Epoch [28/50], Step [699/735], Loss: 0.0868\n",
      "Epoch [28/50], Step [700/735], Loss: 0.0374\n",
      "Epoch [28/50], Step [701/735], Loss: 0.0597\n",
      "Epoch [28/50], Step [702/735], Loss: 0.1275\n",
      "Epoch [28/50], Step [703/735], Loss: 0.0599\n",
      "Epoch [28/50], Step [704/735], Loss: 0.0294\n",
      "Epoch [28/50], Step [705/735], Loss: 0.0736\n",
      "Epoch [28/50], Step [706/735], Loss: 0.0182\n",
      "Epoch [28/50], Step [707/735], Loss: 0.0416\n",
      "Epoch [28/50], Step [708/735], Loss: 0.1276\n",
      "Epoch [28/50], Step [709/735], Loss: 0.0704\n",
      "Epoch [28/50], Step [710/735], Loss: 0.0194\n",
      "Epoch [28/50], Step [711/735], Loss: 0.0488\n",
      "Epoch [28/50], Step [712/735], Loss: 0.0569\n",
      "Epoch [28/50], Step [713/735], Loss: 0.0190\n",
      "Epoch [28/50], Step [714/735], Loss: 0.0655\n",
      "Epoch [28/50], Step [715/735], Loss: 0.1412\n",
      "Epoch [28/50], Step [716/735], Loss: 0.2232\n",
      "Epoch [28/50], Step [717/735], Loss: 0.0562\n",
      "Epoch [28/50], Step [718/735], Loss: 0.0958\n",
      "Epoch [28/50], Step [719/735], Loss: 0.0699\n",
      "Epoch [28/50], Step [720/735], Loss: 0.0940\n",
      "Epoch [28/50], Step [721/735], Loss: 0.0584\n",
      "Epoch [28/50], Step [722/735], Loss: 0.0292\n",
      "Epoch [28/50], Step [723/735], Loss: 0.0468\n",
      "Epoch [28/50], Step [724/735], Loss: 0.0482\n",
      "Epoch [28/50], Step [725/735], Loss: 0.0867\n",
      "Epoch [28/50], Step [726/735], Loss: 0.1484\n",
      "Epoch [28/50], Step [727/735], Loss: 0.0417\n",
      "Epoch [28/50], Step [728/735], Loss: 0.0459\n",
      "Epoch [28/50], Step [729/735], Loss: 0.1284\n",
      "Epoch [28/50], Step [730/735], Loss: 0.2281\n",
      "Epoch [28/50], Step [731/735], Loss: 0.0453\n",
      "Epoch [28/50], Step [732/735], Loss: 0.0584\n",
      "Epoch [28/50], Step [733/735], Loss: 0.0279\n",
      "Epoch [28/50], Step [734/735], Loss: 0.0386\n",
      "Epoch [28/50], Step [735/735], Loss: 0.0303\n",
      "Epoch [29/50], Step [1/735], Loss: 0.0469\n",
      "Epoch [29/50], Step [2/735], Loss: 0.0403\n",
      "Epoch [29/50], Step [3/735], Loss: 0.0957\n",
      "Epoch [29/50], Step [4/735], Loss: 0.0460\n",
      "Epoch [29/50], Step [5/735], Loss: 0.0948\n",
      "Epoch [29/50], Step [6/735], Loss: 0.0442\n",
      "Epoch [29/50], Step [7/735], Loss: 0.3963\n",
      "Epoch [29/50], Step [8/735], Loss: 0.0735\n",
      "Epoch [29/50], Step [9/735], Loss: 0.1071\n",
      "Epoch [29/50], Step [10/735], Loss: 0.1058\n",
      "Epoch [29/50], Step [11/735], Loss: 0.0241\n",
      "Epoch [29/50], Step [12/735], Loss: 0.0699\n",
      "Epoch [29/50], Step [13/735], Loss: 0.0749\n",
      "Epoch [29/50], Step [14/735], Loss: 0.0773\n",
      "Epoch [29/50], Step [15/735], Loss: 0.0388\n",
      "Epoch [29/50], Step [16/735], Loss: 0.0651\n",
      "Epoch [29/50], Step [17/735], Loss: 0.0829\n",
      "Epoch [29/50], Step [18/735], Loss: 0.0802\n",
      "Epoch [29/50], Step [19/735], Loss: 0.0592\n",
      "Epoch [29/50], Step [20/735], Loss: 0.0764\n",
      "Epoch [29/50], Step [21/735], Loss: 0.0215\n",
      "Epoch [29/50], Step [22/735], Loss: 0.0480\n",
      "Epoch [29/50], Step [23/735], Loss: 0.0599\n",
      "Epoch [29/50], Step [24/735], Loss: 0.0690\n",
      "Epoch [29/50], Step [25/735], Loss: 0.0415\n",
      "Epoch [29/50], Step [26/735], Loss: 0.0435\n",
      "Epoch [29/50], Step [27/735], Loss: 0.1718\n",
      "Epoch [29/50], Step [28/735], Loss: 0.0255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Step [29/735], Loss: 0.0252\n",
      "Epoch [29/50], Step [30/735], Loss: 0.0665\n",
      "Epoch [29/50], Step [31/735], Loss: 0.0498\n",
      "Epoch [29/50], Step [32/735], Loss: 0.0479\n",
      "Epoch [29/50], Step [33/735], Loss: 0.5695\n",
      "Epoch [29/50], Step [34/735], Loss: 0.0269\n",
      "Epoch [29/50], Step [35/735], Loss: 0.0709\n",
      "Epoch [29/50], Step [36/735], Loss: 0.0826\n",
      "Epoch [29/50], Step [37/735], Loss: 0.1543\n",
      "Epoch [29/50], Step [38/735], Loss: 0.0300\n",
      "Epoch [29/50], Step [39/735], Loss: 0.0534\n",
      "Epoch [29/50], Step [40/735], Loss: 0.0417\n",
      "Epoch [29/50], Step [41/735], Loss: 0.0367\n",
      "Epoch [29/50], Step [42/735], Loss: 0.0250\n",
      "Epoch [29/50], Step [43/735], Loss: 0.0301\n",
      "Epoch [29/50], Step [44/735], Loss: 0.1847\n",
      "Epoch [29/50], Step [45/735], Loss: 0.0332\n",
      "Epoch [29/50], Step [46/735], Loss: 0.1191\n",
      "Epoch [29/50], Step [47/735], Loss: 0.0523\n",
      "Epoch [29/50], Step [48/735], Loss: 0.0707\n",
      "Epoch [29/50], Step [49/735], Loss: 0.1766\n",
      "Epoch [29/50], Step [50/735], Loss: 0.1268\n",
      "Epoch [29/50], Step [51/735], Loss: 0.2139\n",
      "Epoch [29/50], Step [52/735], Loss: 0.0298\n",
      "Epoch [29/50], Step [53/735], Loss: 0.0410\n",
      "Epoch [29/50], Step [54/735], Loss: 0.0924\n",
      "Epoch [29/50], Step [55/735], Loss: 0.0468\n",
      "Epoch [29/50], Step [56/735], Loss: 0.1303\n",
      "Epoch [29/50], Step [57/735], Loss: 0.0388\n",
      "Epoch [29/50], Step [58/735], Loss: 0.0235\n",
      "Epoch [29/50], Step [59/735], Loss: 0.1836\n",
      "Epoch [29/50], Step [60/735], Loss: 0.0604\n",
      "Epoch [29/50], Step [61/735], Loss: 0.0431\n",
      "Epoch [29/50], Step [62/735], Loss: 0.0910\n",
      "Epoch [29/50], Step [63/735], Loss: 0.0803\n",
      "Epoch [29/50], Step [64/735], Loss: 0.1058\n",
      "Epoch [29/50], Step [65/735], Loss: 0.0598\n",
      "Epoch [29/50], Step [66/735], Loss: 0.0673\n",
      "Epoch [29/50], Step [67/735], Loss: 0.0680\n",
      "Epoch [29/50], Step [68/735], Loss: 0.1462\n",
      "Epoch [29/50], Step [69/735], Loss: 0.0630\n",
      "Epoch [29/50], Step [70/735], Loss: 0.0566\n",
      "Epoch [29/50], Step [71/735], Loss: 0.2638\n",
      "Epoch [29/50], Step [72/735], Loss: 0.1043\n",
      "Epoch [29/50], Step [73/735], Loss: 0.0509\n",
      "Epoch [29/50], Step [74/735], Loss: 0.1178\n",
      "Epoch [29/50], Step [75/735], Loss: 0.0813\n",
      "Epoch [29/50], Step [76/735], Loss: 0.0523\n",
      "Epoch [29/50], Step [77/735], Loss: 0.0419\n",
      "Epoch [29/50], Step [78/735], Loss: 0.0598\n",
      "Epoch [29/50], Step [79/735], Loss: 0.1255\n",
      "Epoch [29/50], Step [80/735], Loss: 0.1312\n",
      "Epoch [29/50], Step [81/735], Loss: 0.0291\n",
      "Epoch [29/50], Step [82/735], Loss: 0.0416\n",
      "Epoch [29/50], Step [83/735], Loss: 0.0474\n",
      "Epoch [29/50], Step [84/735], Loss: 0.1771\n",
      "Epoch [29/50], Step [85/735], Loss: 0.0666\n",
      "Epoch [29/50], Step [86/735], Loss: 0.0791\n",
      "Epoch [29/50], Step [87/735], Loss: 0.0578\n",
      "Epoch [29/50], Step [88/735], Loss: 0.0608\n",
      "Epoch [29/50], Step [89/735], Loss: 0.0206\n",
      "Epoch [29/50], Step [90/735], Loss: 0.0356\n",
      "Epoch [29/50], Step [91/735], Loss: 0.0284\n",
      "Epoch [29/50], Step [92/735], Loss: 0.0865\n",
      "Epoch [29/50], Step [93/735], Loss: 0.0521\n",
      "Epoch [29/50], Step [94/735], Loss: 0.0345\n",
      "Epoch [29/50], Step [95/735], Loss: 0.0723\n",
      "Epoch [29/50], Step [96/735], Loss: 0.2017\n",
      "Epoch [29/50], Step [97/735], Loss: 0.2218\n",
      "Epoch [29/50], Step [98/735], Loss: 0.0531\n",
      "Epoch [29/50], Step [99/735], Loss: 0.0823\n",
      "Epoch [29/50], Step [100/735], Loss: 0.0393\n",
      "Epoch [29/50], Step [101/735], Loss: 0.0591\n",
      "Epoch [29/50], Step [102/735], Loss: 0.4125\n",
      "Epoch [29/50], Step [103/735], Loss: 0.1104\n",
      "Epoch [29/50], Step [104/735], Loss: 0.0495\n",
      "Epoch [29/50], Step [105/735], Loss: 0.0886\n",
      "Epoch [29/50], Step [106/735], Loss: 0.0605\n",
      "Epoch [29/50], Step [107/735], Loss: 0.1383\n",
      "Epoch [29/50], Step [108/735], Loss: 0.0585\n",
      "Epoch [29/50], Step [109/735], Loss: 0.0413\n",
      "Epoch [29/50], Step [110/735], Loss: 0.0363\n",
      "Epoch [29/50], Step [111/735], Loss: 0.0701\n",
      "Epoch [29/50], Step [112/735], Loss: 0.1845\n",
      "Epoch [29/50], Step [113/735], Loss: 0.0548\n",
      "Epoch [29/50], Step [114/735], Loss: 0.0507\n",
      "Epoch [29/50], Step [115/735], Loss: 0.0527\n",
      "Epoch [29/50], Step [116/735], Loss: 0.0740\n",
      "Epoch [29/50], Step [117/735], Loss: 0.0463\n",
      "Epoch [29/50], Step [118/735], Loss: 0.0407\n",
      "Epoch [29/50], Step [119/735], Loss: 0.1593\n",
      "Epoch [29/50], Step [120/735], Loss: 0.0715\n",
      "Epoch [29/50], Step [121/735], Loss: 0.1009\n",
      "Epoch [29/50], Step [122/735], Loss: 0.0534\n",
      "Epoch [29/50], Step [123/735], Loss: 0.0319\n",
      "Epoch [29/50], Step [124/735], Loss: 0.0463\n",
      "Epoch [29/50], Step [125/735], Loss: 0.0433\n",
      "Epoch [29/50], Step [126/735], Loss: 0.0646\n",
      "Epoch [29/50], Step [127/735], Loss: 0.0717\n",
      "Epoch [29/50], Step [128/735], Loss: 0.0300\n",
      "Epoch [29/50], Step [129/735], Loss: 0.0435\n",
      "Epoch [29/50], Step [130/735], Loss: 0.1067\n",
      "Epoch [29/50], Step [131/735], Loss: 0.0289\n",
      "Epoch [29/50], Step [132/735], Loss: 0.0161\n",
      "Epoch [29/50], Step [133/735], Loss: 0.0861\n",
      "Epoch [29/50], Step [134/735], Loss: 0.0721\n",
      "Epoch [29/50], Step [135/735], Loss: 0.0338\n",
      "Epoch [29/50], Step [136/735], Loss: 0.0201\n",
      "Epoch [29/50], Step [137/735], Loss: 0.1541\n",
      "Epoch [29/50], Step [138/735], Loss: 0.0362\n",
      "Epoch [29/50], Step [139/735], Loss: 0.0197\n",
      "Epoch [29/50], Step [140/735], Loss: 0.0647\n",
      "Epoch [29/50], Step [141/735], Loss: 0.0226\n",
      "Epoch [29/50], Step [142/735], Loss: 0.0242\n",
      "Epoch [29/50], Step [143/735], Loss: 0.0205\n",
      "Epoch [29/50], Step [144/735], Loss: 0.0337\n",
      "Epoch [29/50], Step [145/735], Loss: 0.1682\n",
      "Epoch [29/50], Step [146/735], Loss: 0.0415\n",
      "Epoch [29/50], Step [147/735], Loss: 0.1616\n",
      "Epoch [29/50], Step [148/735], Loss: 0.0328\n",
      "Epoch [29/50], Step [149/735], Loss: 0.0478\n",
      "Epoch [29/50], Step [150/735], Loss: 0.0663\n",
      "Epoch [29/50], Step [151/735], Loss: 0.0337\n",
      "Epoch [29/50], Step [152/735], Loss: 0.0146\n",
      "Epoch [29/50], Step [153/735], Loss: 0.1045\n",
      "Epoch [29/50], Step [154/735], Loss: 0.1223\n",
      "Epoch [29/50], Step [155/735], Loss: 0.0575\n",
      "Epoch [29/50], Step [156/735], Loss: 0.0704\n",
      "Epoch [29/50], Step [157/735], Loss: 0.0961\n",
      "Epoch [29/50], Step [158/735], Loss: 0.0365\n",
      "Epoch [29/50], Step [159/735], Loss: 0.0183\n",
      "Epoch [29/50], Step [160/735], Loss: 0.0257\n",
      "Epoch [29/50], Step [161/735], Loss: 0.0247\n",
      "Epoch [29/50], Step [162/735], Loss: 0.0444\n",
      "Epoch [29/50], Step [163/735], Loss: 0.0174\n",
      "Epoch [29/50], Step [164/735], Loss: 0.0208\n",
      "Epoch [29/50], Step [165/735], Loss: 0.0429\n",
      "Epoch [29/50], Step [166/735], Loss: 0.0842\n",
      "Epoch [29/50], Step [167/735], Loss: 0.0356\n",
      "Epoch [29/50], Step [168/735], Loss: 0.0398\n",
      "Epoch [29/50], Step [169/735], Loss: 0.0541\n",
      "Epoch [29/50], Step [170/735], Loss: 0.1128\n",
      "Epoch [29/50], Step [171/735], Loss: 0.0744\n",
      "Epoch [29/50], Step [172/735], Loss: 0.0888\n",
      "Epoch [29/50], Step [173/735], Loss: 0.0923\n",
      "Epoch [29/50], Step [174/735], Loss: 0.0651\n",
      "Epoch [29/50], Step [175/735], Loss: 0.0693\n",
      "Epoch [29/50], Step [176/735], Loss: 0.0192\n",
      "Epoch [29/50], Step [177/735], Loss: 0.1987\n",
      "Epoch [29/50], Step [178/735], Loss: 0.4175\n",
      "Epoch [29/50], Step [179/735], Loss: 0.0434\n",
      "Epoch [29/50], Step [180/735], Loss: 0.0660\n",
      "Epoch [29/50], Step [181/735], Loss: 0.0887\n",
      "Epoch [29/50], Step [182/735], Loss: 0.0477\n",
      "Epoch [29/50], Step [183/735], Loss: 0.0602\n",
      "Epoch [29/50], Step [184/735], Loss: 0.0527\n",
      "Epoch [29/50], Step [185/735], Loss: 0.1260\n",
      "Epoch [29/50], Step [186/735], Loss: 0.1915\n",
      "Epoch [29/50], Step [187/735], Loss: 0.0818\n",
      "Epoch [29/50], Step [188/735], Loss: 0.0958\n",
      "Epoch [29/50], Step [189/735], Loss: 0.0579\n",
      "Epoch [29/50], Step [190/735], Loss: 0.0839\n",
      "Epoch [29/50], Step [191/735], Loss: 0.4978\n",
      "Epoch [29/50], Step [192/735], Loss: 0.0523\n",
      "Epoch [29/50], Step [193/735], Loss: 0.0251\n",
      "Epoch [29/50], Step [194/735], Loss: 0.1833\n",
      "Epoch [29/50], Step [195/735], Loss: 0.0541\n",
      "Epoch [29/50], Step [196/735], Loss: 0.0606\n",
      "Epoch [29/50], Step [197/735], Loss: 0.0278\n",
      "Epoch [29/50], Step [198/735], Loss: 0.0750\n",
      "Epoch [29/50], Step [199/735], Loss: 0.0600\n",
      "Epoch [29/50], Step [200/735], Loss: 0.1108\n",
      "Epoch [29/50], Step [201/735], Loss: 0.0751\n",
      "Epoch [29/50], Step [202/735], Loss: 0.0526\n",
      "Epoch [29/50], Step [203/735], Loss: 0.0470\n",
      "Epoch [29/50], Step [204/735], Loss: 0.0231\n",
      "Epoch [29/50], Step [205/735], Loss: 0.0986\n",
      "Epoch [29/50], Step [206/735], Loss: 0.1926\n",
      "Epoch [29/50], Step [207/735], Loss: 0.0287\n",
      "Epoch [29/50], Step [208/735], Loss: 0.0378\n",
      "Epoch [29/50], Step [209/735], Loss: 0.0298\n",
      "Epoch [29/50], Step [210/735], Loss: 0.1290\n",
      "Epoch [29/50], Step [211/735], Loss: 0.1073\n",
      "Epoch [29/50], Step [212/735], Loss: 0.0880\n",
      "Epoch [29/50], Step [213/735], Loss: 0.1405\n",
      "Epoch [29/50], Step [214/735], Loss: 0.0263\n",
      "Epoch [29/50], Step [215/735], Loss: 0.0642\n",
      "Epoch [29/50], Step [216/735], Loss: 0.0295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Step [217/735], Loss: 0.0411\n",
      "Epoch [29/50], Step [218/735], Loss: 0.0782\n",
      "Epoch [29/50], Step [219/735], Loss: 0.0375\n",
      "Epoch [29/50], Step [220/735], Loss: 0.0608\n",
      "Epoch [29/50], Step [221/735], Loss: 0.1308\n",
      "Epoch [29/50], Step [222/735], Loss: 0.2898\n",
      "Epoch [29/50], Step [223/735], Loss: 0.0358\n",
      "Epoch [29/50], Step [224/735], Loss: 0.0640\n",
      "Epoch [29/50], Step [225/735], Loss: 0.0551\n",
      "Epoch [29/50], Step [226/735], Loss: 0.0495\n",
      "Epoch [29/50], Step [227/735], Loss: 0.0670\n",
      "Epoch [29/50], Step [228/735], Loss: 0.1565\n",
      "Epoch [29/50], Step [229/735], Loss: 0.0301\n",
      "Epoch [29/50], Step [230/735], Loss: 0.0332\n",
      "Epoch [29/50], Step [231/735], Loss: 0.0410\n",
      "Epoch [29/50], Step [232/735], Loss: 0.0688\n",
      "Epoch [29/50], Step [233/735], Loss: 0.0268\n",
      "Epoch [29/50], Step [234/735], Loss: 0.0163\n",
      "Epoch [29/50], Step [235/735], Loss: 0.0272\n",
      "Epoch [29/50], Step [236/735], Loss: 0.0368\n",
      "Epoch [29/50], Step [237/735], Loss: 0.0727\n",
      "Epoch [29/50], Step [238/735], Loss: 0.0202\n",
      "Epoch [29/50], Step [239/735], Loss: 0.1032\n",
      "Epoch [29/50], Step [240/735], Loss: 0.0457\n",
      "Epoch [29/50], Step [241/735], Loss: 0.2272\n",
      "Epoch [29/50], Step [242/735], Loss: 0.0607\n",
      "Epoch [29/50], Step [243/735], Loss: 0.0427\n",
      "Epoch [29/50], Step [244/735], Loss: 0.0355\n",
      "Epoch [29/50], Step [245/735], Loss: 0.0525\n",
      "Epoch [29/50], Step [246/735], Loss: 0.0430\n",
      "Epoch [29/50], Step [247/735], Loss: 0.0607\n",
      "Epoch [29/50], Step [248/735], Loss: 0.0342\n",
      "Epoch [29/50], Step [249/735], Loss: 0.0710\n",
      "Epoch [29/50], Step [250/735], Loss: 0.1489\n",
      "Epoch [29/50], Step [251/735], Loss: 0.0517\n",
      "Epoch [29/50], Step [252/735], Loss: 0.1037\n",
      "Epoch [29/50], Step [253/735], Loss: 0.0489\n",
      "Epoch [29/50], Step [254/735], Loss: 0.0596\n",
      "Epoch [29/50], Step [255/735], Loss: 0.1115\n",
      "Epoch [29/50], Step [256/735], Loss: 0.0949\n",
      "Epoch [29/50], Step [257/735], Loss: 0.0426\n",
      "Epoch [29/50], Step [258/735], Loss: 0.0743\n",
      "Epoch [29/50], Step [259/735], Loss: 0.0260\n",
      "Epoch [29/50], Step [260/735], Loss: 0.1534\n",
      "Epoch [29/50], Step [261/735], Loss: 0.0599\n",
      "Epoch [29/50], Step [262/735], Loss: 0.0439\n",
      "Epoch [29/50], Step [263/735], Loss: 0.0600\n",
      "Epoch [29/50], Step [264/735], Loss: 0.0281\n",
      "Epoch [29/50], Step [265/735], Loss: 0.0535\n",
      "Epoch [29/50], Step [266/735], Loss: 0.0642\n",
      "Epoch [29/50], Step [267/735], Loss: 0.0654\n",
      "Epoch [29/50], Step [268/735], Loss: 0.0295\n",
      "Epoch [29/50], Step [269/735], Loss: 0.0767\n",
      "Epoch [29/50], Step [270/735], Loss: 0.0418\n",
      "Epoch [29/50], Step [271/735], Loss: 0.0503\n",
      "Epoch [29/50], Step [272/735], Loss: 0.1195\n",
      "Epoch [29/50], Step [273/735], Loss: 0.0494\n",
      "Epoch [29/50], Step [274/735], Loss: 0.0762\n",
      "Epoch [29/50], Step [275/735], Loss: 0.1008\n",
      "Epoch [29/50], Step [276/735], Loss: 0.0401\n",
      "Epoch [29/50], Step [277/735], Loss: 0.0294\n",
      "Epoch [29/50], Step [278/735], Loss: 0.0524\n",
      "Epoch [29/50], Step [279/735], Loss: 0.0182\n",
      "Epoch [29/50], Step [280/735], Loss: 0.0223\n",
      "Epoch [29/50], Step [281/735], Loss: 0.0530\n",
      "Epoch [29/50], Step [282/735], Loss: 0.1673\n",
      "Epoch [29/50], Step [283/735], Loss: 0.0878\n",
      "Epoch [29/50], Step [284/735], Loss: 0.0268\n",
      "Epoch [29/50], Step [285/735], Loss: 0.0554\n",
      "Epoch [29/50], Step [286/735], Loss: 0.0253\n",
      "Epoch [29/50], Step [287/735], Loss: 0.0417\n",
      "Epoch [29/50], Step [288/735], Loss: 0.0923\n",
      "Epoch [29/50], Step [289/735], Loss: 0.0468\n",
      "Epoch [29/50], Step [290/735], Loss: 0.0605\n",
      "Epoch [29/50], Step [291/735], Loss: 0.0474\n",
      "Epoch [29/50], Step [292/735], Loss: 0.0502\n",
      "Epoch [29/50], Step [293/735], Loss: 0.0734\n",
      "Epoch [29/50], Step [294/735], Loss: 0.0327\n",
      "Epoch [29/50], Step [295/735], Loss: 0.0188\n",
      "Epoch [29/50], Step [296/735], Loss: 0.0469\n",
      "Epoch [29/50], Step [297/735], Loss: 0.0436\n",
      "Epoch [29/50], Step [298/735], Loss: 0.0301\n",
      "Epoch [29/50], Step [299/735], Loss: 0.0259\n",
      "Epoch [29/50], Step [300/735], Loss: 0.2812\n",
      "Epoch [29/50], Step [301/735], Loss: 0.0835\n",
      "Epoch [29/50], Step [302/735], Loss: 0.0422\n",
      "Epoch [29/50], Step [303/735], Loss: 0.0688\n",
      "Epoch [29/50], Step [304/735], Loss: 0.1642\n",
      "Epoch [29/50], Step [305/735], Loss: 0.0731\n",
      "Epoch [29/50], Step [306/735], Loss: 0.0505\n",
      "Epoch [29/50], Step [307/735], Loss: 0.0716\n",
      "Epoch [29/50], Step [308/735], Loss: 0.0414\n",
      "Epoch [29/50], Step [309/735], Loss: 0.1201\n",
      "Epoch [29/50], Step [310/735], Loss: 0.0621\n",
      "Epoch [29/50], Step [311/735], Loss: 0.1026\n",
      "Epoch [29/50], Step [312/735], Loss: 0.0573\n",
      "Epoch [29/50], Step [313/735], Loss: 0.1161\n",
      "Epoch [29/50], Step [314/735], Loss: 0.0928\n",
      "Epoch [29/50], Step [315/735], Loss: 0.0625\n",
      "Epoch [29/50], Step [316/735], Loss: 0.0857\n",
      "Epoch [29/50], Step [317/735], Loss: 0.1255\n",
      "Epoch [29/50], Step [318/735], Loss: 0.0712\n",
      "Epoch [29/50], Step [319/735], Loss: 0.0928\n",
      "Epoch [29/50], Step [320/735], Loss: 0.0551\n",
      "Epoch [29/50], Step [321/735], Loss: 0.0623\n",
      "Epoch [29/50], Step [322/735], Loss: 0.0902\n",
      "Epoch [29/50], Step [323/735], Loss: 0.0499\n",
      "Epoch [29/50], Step [324/735], Loss: 0.0609\n",
      "Epoch [29/50], Step [325/735], Loss: 0.0826\n",
      "Epoch [29/50], Step [326/735], Loss: 0.0395\n",
      "Epoch [29/50], Step [327/735], Loss: 0.1014\n",
      "Epoch [29/50], Step [328/735], Loss: 0.0659\n",
      "Epoch [29/50], Step [329/735], Loss: 0.0765\n",
      "Epoch [29/50], Step [330/735], Loss: 0.1673\n",
      "Epoch [29/50], Step [331/735], Loss: 0.0456\n",
      "Epoch [29/50], Step [332/735], Loss: 0.0383\n",
      "Epoch [29/50], Step [333/735], Loss: 0.0967\n",
      "Epoch [29/50], Step [334/735], Loss: 0.0423\n",
      "Epoch [29/50], Step [335/735], Loss: 0.0937\n",
      "Epoch [29/50], Step [336/735], Loss: 0.0196\n",
      "Epoch [29/50], Step [337/735], Loss: 0.0827\n",
      "Epoch [29/50], Step [338/735], Loss: 0.0766\n",
      "Epoch [29/50], Step [339/735], Loss: 0.0585\n",
      "Epoch [29/50], Step [340/735], Loss: 0.0230\n",
      "Epoch [29/50], Step [341/735], Loss: 0.2993\n",
      "Epoch [29/50], Step [342/735], Loss: 0.0174\n",
      "Epoch [29/50], Step [343/735], Loss: 0.3902\n",
      "Epoch [29/50], Step [344/735], Loss: 0.0420\n",
      "Epoch [29/50], Step [345/735], Loss: 0.3586\n",
      "Epoch [29/50], Step [346/735], Loss: 0.0641\n",
      "Epoch [29/50], Step [347/735], Loss: 0.2458\n",
      "Epoch [29/50], Step [348/735], Loss: 0.1081\n",
      "Epoch [29/50], Step [349/735], Loss: 0.0426\n",
      "Epoch [29/50], Step [350/735], Loss: 0.1142\n",
      "Epoch [29/50], Step [351/735], Loss: 0.0875\n",
      "Epoch [29/50], Step [352/735], Loss: 0.0628\n",
      "Epoch [29/50], Step [353/735], Loss: 0.0427\n",
      "Epoch [29/50], Step [354/735], Loss: 0.0546\n",
      "Epoch [29/50], Step [355/735], Loss: 0.0278\n",
      "Epoch [29/50], Step [356/735], Loss: 0.0719\n",
      "Epoch [29/50], Step [357/735], Loss: 0.0742\n",
      "Epoch [29/50], Step [358/735], Loss: 0.0314\n",
      "Epoch [29/50], Step [359/735], Loss: 0.0372\n",
      "Epoch [29/50], Step [360/735], Loss: 0.0518\n",
      "Epoch [29/50], Step [361/735], Loss: 0.1380\n",
      "Epoch [29/50], Step [362/735], Loss: 0.1470\n",
      "Epoch [29/50], Step [363/735], Loss: 0.0355\n",
      "Epoch [29/50], Step [364/735], Loss: 0.0413\n",
      "Epoch [29/50], Step [365/735], Loss: 0.0271\n",
      "Epoch [29/50], Step [366/735], Loss: 0.1370\n",
      "Epoch [29/50], Step [367/735], Loss: 0.0406\n",
      "Epoch [29/50], Step [368/735], Loss: 0.0665\n",
      "Epoch [29/50], Step [369/735], Loss: 0.0973\n",
      "Epoch [29/50], Step [370/735], Loss: 0.0926\n",
      "Epoch [29/50], Step [371/735], Loss: 0.0292\n",
      "Epoch [29/50], Step [372/735], Loss: 0.0438\n",
      "Epoch [29/50], Step [373/735], Loss: 0.0714\n",
      "Epoch [29/50], Step [374/735], Loss: 0.2747\n",
      "Epoch [29/50], Step [375/735], Loss: 0.1643\n",
      "Epoch [29/50], Step [376/735], Loss: 0.1070\n",
      "Epoch [29/50], Step [377/735], Loss: 0.0846\n",
      "Epoch [29/50], Step [378/735], Loss: 0.0330\n",
      "Epoch [29/50], Step [379/735], Loss: 0.0575\n",
      "Epoch [29/50], Step [380/735], Loss: 0.2793\n",
      "Epoch [29/50], Step [381/735], Loss: 0.0633\n",
      "Epoch [29/50], Step [382/735], Loss: 0.0567\n",
      "Epoch [29/50], Step [383/735], Loss: 0.0395\n",
      "Epoch [29/50], Step [384/735], Loss: 0.0646\n",
      "Epoch [29/50], Step [385/735], Loss: 0.0358\n",
      "Epoch [29/50], Step [386/735], Loss: 0.1252\n",
      "Epoch [29/50], Step [387/735], Loss: 0.0492\n",
      "Epoch [29/50], Step [388/735], Loss: 0.1342\n",
      "Epoch [29/50], Step [389/735], Loss: 0.0337\n",
      "Epoch [29/50], Step [390/735], Loss: 0.1188\n",
      "Epoch [29/50], Step [391/735], Loss: 0.0554\n",
      "Epoch [29/50], Step [392/735], Loss: 0.0727\n",
      "Epoch [29/50], Step [393/735], Loss: 0.0366\n",
      "Epoch [29/50], Step [394/735], Loss: 0.0984\n",
      "Epoch [29/50], Step [395/735], Loss: 0.0412\n",
      "Epoch [29/50], Step [396/735], Loss: 0.0680\n",
      "Epoch [29/50], Step [397/735], Loss: 0.0619\n",
      "Epoch [29/50], Step [398/735], Loss: 0.0323\n",
      "Epoch [29/50], Step [399/735], Loss: 0.0716\n",
      "Epoch [29/50], Step [400/735], Loss: 0.0243\n",
      "Epoch [29/50], Step [401/735], Loss: 0.1648\n",
      "Epoch [29/50], Step [402/735], Loss: 0.0862\n",
      "Epoch [29/50], Step [403/735], Loss: 0.1421\n",
      "Epoch [29/50], Step [404/735], Loss: 0.1234\n",
      "Epoch [29/50], Step [405/735], Loss: 0.0944\n",
      "Epoch [29/50], Step [406/735], Loss: 0.0671\n",
      "Epoch [29/50], Step [407/735], Loss: 0.0639\n",
      "Epoch [29/50], Step [408/735], Loss: 0.0819\n",
      "Epoch [29/50], Step [409/735], Loss: 0.0971\n",
      "Epoch [29/50], Step [410/735], Loss: 0.0725\n",
      "Epoch [29/50], Step [411/735], Loss: 0.0650\n",
      "Epoch [29/50], Step [412/735], Loss: 0.0899\n",
      "Epoch [29/50], Step [413/735], Loss: 0.1388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Step [414/735], Loss: 0.1497\n",
      "Epoch [29/50], Step [415/735], Loss: 0.0379\n",
      "Epoch [29/50], Step [416/735], Loss: 0.0968\n",
      "Epoch [29/50], Step [417/735], Loss: 0.1821\n",
      "Epoch [29/50], Step [418/735], Loss: 0.0463\n",
      "Epoch [29/50], Step [419/735], Loss: 0.0537\n",
      "Epoch [29/50], Step [420/735], Loss: 0.0422\n",
      "Epoch [29/50], Step [421/735], Loss: 0.1994\n",
      "Epoch [29/50], Step [422/735], Loss: 0.1429\n",
      "Epoch [29/50], Step [423/735], Loss: 0.0797\n",
      "Epoch [29/50], Step [424/735], Loss: 0.0230\n",
      "Epoch [29/50], Step [425/735], Loss: 0.0340\n",
      "Epoch [29/50], Step [426/735], Loss: 0.0424\n",
      "Epoch [29/50], Step [427/735], Loss: 0.0460\n",
      "Epoch [29/50], Step [428/735], Loss: 0.0574\n",
      "Epoch [29/50], Step [429/735], Loss: 0.0868\n",
      "Epoch [29/50], Step [430/735], Loss: 0.1530\n",
      "Epoch [29/50], Step [431/735], Loss: 0.0337\n",
      "Epoch [29/50], Step [432/735], Loss: 0.0934\n",
      "Epoch [29/50], Step [433/735], Loss: 0.0667\n",
      "Epoch [29/50], Step [434/735], Loss: 0.0247\n",
      "Epoch [29/50], Step [435/735], Loss: 0.0537\n",
      "Epoch [29/50], Step [436/735], Loss: 0.0266\n",
      "Epoch [29/50], Step [437/735], Loss: 0.0425\n",
      "Epoch [29/50], Step [438/735], Loss: 0.0908\n",
      "Epoch [29/50], Step [439/735], Loss: 0.1124\n",
      "Epoch [29/50], Step [440/735], Loss: 0.0406\n",
      "Epoch [29/50], Step [441/735], Loss: 0.0549\n",
      "Epoch [29/50], Step [442/735], Loss: 0.0281\n",
      "Epoch [29/50], Step [443/735], Loss: 0.0619\n",
      "Epoch [29/50], Step [444/735], Loss: 0.0343\n",
      "Epoch [29/50], Step [445/735], Loss: 0.0225\n",
      "Epoch [29/50], Step [446/735], Loss: 0.0177\n",
      "Epoch [29/50], Step [447/735], Loss: 0.0273\n",
      "Epoch [29/50], Step [448/735], Loss: 0.1577\n",
      "Epoch [29/50], Step [449/735], Loss: 0.0297\n",
      "Epoch [29/50], Step [450/735], Loss: 0.0472\n",
      "Epoch [29/50], Step [451/735], Loss: 0.0923\n",
      "Epoch [29/50], Step [452/735], Loss: 0.1522\n",
      "Epoch [29/50], Step [453/735], Loss: 0.4404\n",
      "Epoch [29/50], Step [454/735], Loss: 0.0479\n",
      "Epoch [29/50], Step [455/735], Loss: 0.0281\n",
      "Epoch [29/50], Step [456/735], Loss: 0.0264\n",
      "Epoch [29/50], Step [457/735], Loss: 0.0487\n",
      "Epoch [29/50], Step [458/735], Loss: 0.0412\n",
      "Epoch [29/50], Step [459/735], Loss: 0.1781\n",
      "Epoch [29/50], Step [460/735], Loss: 0.1611\n",
      "Epoch [29/50], Step [461/735], Loss: 0.0577\n",
      "Epoch [29/50], Step [462/735], Loss: 0.0230\n",
      "Epoch [29/50], Step [463/735], Loss: 0.0216\n",
      "Epoch [29/50], Step [464/735], Loss: 0.1455\n",
      "Epoch [29/50], Step [465/735], Loss: 0.0400\n",
      "Epoch [29/50], Step [466/735], Loss: 0.0600\n",
      "Epoch [29/50], Step [467/735], Loss: 0.0482\n",
      "Epoch [29/50], Step [468/735], Loss: 0.0314\n",
      "Epoch [29/50], Step [469/735], Loss: 0.1294\n",
      "Epoch [29/50], Step [470/735], Loss: 0.0506\n",
      "Epoch [29/50], Step [471/735], Loss: 0.0565\n",
      "Epoch [29/50], Step [472/735], Loss: 0.0291\n",
      "Epoch [29/50], Step [473/735], Loss: 0.0501\n",
      "Epoch [29/50], Step [474/735], Loss: 0.0339\n",
      "Epoch [29/50], Step [475/735], Loss: 0.0492\n",
      "Epoch [29/50], Step [476/735], Loss: 0.0236\n",
      "Epoch [29/50], Step [477/735], Loss: 0.0720\n",
      "Epoch [29/50], Step [478/735], Loss: 0.0323\n",
      "Epoch [29/50], Step [479/735], Loss: 0.1592\n",
      "Epoch [29/50], Step [480/735], Loss: 0.0306\n",
      "Epoch [29/50], Step [481/735], Loss: 0.0750\n",
      "Epoch [29/50], Step [482/735], Loss: 0.2976\n",
      "Epoch [29/50], Step [483/735], Loss: 0.0182\n",
      "Epoch [29/50], Step [484/735], Loss: 0.0281\n",
      "Epoch [29/50], Step [485/735], Loss: 0.0809\n",
      "Epoch [29/50], Step [486/735], Loss: 0.3544\n",
      "Epoch [29/50], Step [487/735], Loss: 0.0984\n",
      "Epoch [29/50], Step [488/735], Loss: 0.0310\n",
      "Epoch [29/50], Step [489/735], Loss: 0.0434\n",
      "Epoch [29/50], Step [490/735], Loss: 0.0482\n",
      "Epoch [29/50], Step [491/735], Loss: 0.1172\n",
      "Epoch [29/50], Step [492/735], Loss: 0.0260\n",
      "Epoch [29/50], Step [493/735], Loss: 0.0946\n",
      "Epoch [29/50], Step [494/735], Loss: 0.0356\n",
      "Epoch [29/50], Step [495/735], Loss: 0.0436\n",
      "Epoch [29/50], Step [496/735], Loss: 0.0381\n",
      "Epoch [29/50], Step [497/735], Loss: 0.0235\n",
      "Epoch [29/50], Step [498/735], Loss: 0.0388\n",
      "Epoch [29/50], Step [499/735], Loss: 0.0268\n",
      "Epoch [29/50], Step [500/735], Loss: 0.1026\n",
      "Epoch [29/50], Step [501/735], Loss: 0.0246\n",
      "Epoch [29/50], Step [502/735], Loss: 0.0186\n",
      "Epoch [29/50], Step [503/735], Loss: 0.0188\n",
      "Epoch [29/50], Step [504/735], Loss: 0.0550\n",
      "Epoch [29/50], Step [505/735], Loss: 0.3535\n",
      "Epoch [29/50], Step [506/735], Loss: 0.0213\n",
      "Epoch [29/50], Step [507/735], Loss: 0.0725\n",
      "Epoch [29/50], Step [508/735], Loss: 0.0630\n",
      "Epoch [29/50], Step [509/735], Loss: 0.0207\n",
      "Epoch [29/50], Step [510/735], Loss: 0.0443\n",
      "Epoch [29/50], Step [511/735], Loss: 0.0435\n",
      "Epoch [29/50], Step [512/735], Loss: 0.1401\n",
      "Epoch [29/50], Step [513/735], Loss: 0.0511\n",
      "Epoch [29/50], Step [514/735], Loss: 0.0285\n",
      "Epoch [29/50], Step [515/735], Loss: 0.0391\n",
      "Epoch [29/50], Step [516/735], Loss: 0.0212\n",
      "Epoch [29/50], Step [517/735], Loss: 0.0364\n",
      "Epoch [29/50], Step [518/735], Loss: 0.0756\n",
      "Epoch [29/50], Step [519/735], Loss: 0.0586\n",
      "Epoch [29/50], Step [520/735], Loss: 0.0246\n",
      "Epoch [29/50], Step [521/735], Loss: 0.0789\n",
      "Epoch [29/50], Step [522/735], Loss: 0.1128\n",
      "Epoch [29/50], Step [523/735], Loss: 0.0493\n",
      "Epoch [29/50], Step [524/735], Loss: 0.0662\n",
      "Epoch [29/50], Step [525/735], Loss: 0.0287\n",
      "Epoch [29/50], Step [526/735], Loss: 0.0705\n",
      "Epoch [29/50], Step [527/735], Loss: 0.0603\n",
      "Epoch [29/50], Step [528/735], Loss: 0.1471\n",
      "Epoch [29/50], Step [529/735], Loss: 0.0724\n",
      "Epoch [29/50], Step [530/735], Loss: 0.0299\n",
      "Epoch [29/50], Step [531/735], Loss: 0.0198\n",
      "Epoch [29/50], Step [532/735], Loss: 0.0280\n",
      "Epoch [29/50], Step [533/735], Loss: 0.0581\n",
      "Epoch [29/50], Step [534/735], Loss: 0.2932\n",
      "Epoch [29/50], Step [535/735], Loss: 0.0515\n",
      "Epoch [29/50], Step [536/735], Loss: 0.0717\n",
      "Epoch [29/50], Step [537/735], Loss: 0.0385\n",
      "Epoch [29/50], Step [538/735], Loss: 0.0407\n",
      "Epoch [29/50], Step [539/735], Loss: 0.0510\n",
      "Epoch [29/50], Step [540/735], Loss: 0.1105\n",
      "Epoch [29/50], Step [541/735], Loss: 0.0439\n",
      "Epoch [29/50], Step [542/735], Loss: 0.0283\n",
      "Epoch [29/50], Step [543/735], Loss: 0.0372\n",
      "Epoch [29/50], Step [544/735], Loss: 0.0265\n",
      "Epoch [29/50], Step [545/735], Loss: 0.0297\n",
      "Epoch [29/50], Step [546/735], Loss: 0.1182\n",
      "Epoch [29/50], Step [547/735], Loss: 0.0220\n",
      "Epoch [29/50], Step [548/735], Loss: 0.0842\n",
      "Epoch [29/50], Step [549/735], Loss: 0.0345\n",
      "Epoch [29/50], Step [550/735], Loss: 0.0339\n",
      "Epoch [29/50], Step [551/735], Loss: 0.0236\n",
      "Epoch [29/50], Step [552/735], Loss: 0.1662\n",
      "Epoch [29/50], Step [553/735], Loss: 0.0330\n",
      "Epoch [29/50], Step [554/735], Loss: 0.0316\n",
      "Epoch [29/50], Step [555/735], Loss: 0.0239\n",
      "Epoch [29/50], Step [556/735], Loss: 0.0623\n",
      "Epoch [29/50], Step [557/735], Loss: 0.0989\n",
      "Epoch [29/50], Step [558/735], Loss: 0.0646\n",
      "Epoch [29/50], Step [559/735], Loss: 0.0395\n",
      "Epoch [29/50], Step [560/735], Loss: 0.0331\n",
      "Epoch [29/50], Step [561/735], Loss: 0.0315\n",
      "Epoch [29/50], Step [562/735], Loss: 0.0278\n",
      "Epoch [29/50], Step [563/735], Loss: 0.0706\n",
      "Epoch [29/50], Step [564/735], Loss: 0.0324\n",
      "Epoch [29/50], Step [565/735], Loss: 0.0748\n",
      "Epoch [29/50], Step [566/735], Loss: 0.0408\n",
      "Epoch [29/50], Step [567/735], Loss: 0.0796\n",
      "Epoch [29/50], Step [568/735], Loss: 0.0818\n",
      "Epoch [29/50], Step [569/735], Loss: 0.0450\n",
      "Epoch [29/50], Step [570/735], Loss: 0.0706\n",
      "Epoch [29/50], Step [571/735], Loss: 0.0251\n",
      "Epoch [29/50], Step [572/735], Loss: 0.0700\n",
      "Epoch [29/50], Step [573/735], Loss: 0.0586\n",
      "Epoch [29/50], Step [574/735], Loss: 0.3224\n",
      "Epoch [29/50], Step [575/735], Loss: 0.0626\n",
      "Epoch [29/50], Step [576/735], Loss: 0.0151\n",
      "Epoch [29/50], Step [577/735], Loss: 0.0397\n",
      "Epoch [29/50], Step [578/735], Loss: 0.0402\n",
      "Epoch [29/50], Step [579/735], Loss: 0.2346\n",
      "Epoch [29/50], Step [580/735], Loss: 0.0917\n",
      "Epoch [29/50], Step [581/735], Loss: 0.0322\n",
      "Epoch [29/50], Step [582/735], Loss: 0.0156\n",
      "Epoch [29/50], Step [583/735], Loss: 0.0228\n",
      "Epoch [29/50], Step [584/735], Loss: 0.0282\n",
      "Epoch [29/50], Step [585/735], Loss: 0.0163\n",
      "Epoch [29/50], Step [586/735], Loss: 0.0696\n",
      "Epoch [29/50], Step [587/735], Loss: 0.0239\n",
      "Epoch [29/50], Step [588/735], Loss: 0.0336\n",
      "Epoch [29/50], Step [589/735], Loss: 0.0342\n",
      "Epoch [29/50], Step [590/735], Loss: 0.1672\n",
      "Epoch [29/50], Step [591/735], Loss: 0.1198\n",
      "Epoch [29/50], Step [592/735], Loss: 0.0780\n",
      "Epoch [29/50], Step [593/735], Loss: 0.1331\n",
      "Epoch [29/50], Step [594/735], Loss: 0.0958\n",
      "Epoch [29/50], Step [595/735], Loss: 0.0351\n",
      "Epoch [29/50], Step [596/735], Loss: 0.0288\n",
      "Epoch [29/50], Step [597/735], Loss: 0.0580\n",
      "Epoch [29/50], Step [598/735], Loss: 0.0287\n",
      "Epoch [29/50], Step [599/735], Loss: 0.0214\n",
      "Epoch [29/50], Step [600/735], Loss: 0.0594\n",
      "Epoch [29/50], Step [601/735], Loss: 0.0760\n",
      "Epoch [29/50], Step [602/735], Loss: 0.0652\n",
      "Epoch [29/50], Step [603/735], Loss: 0.0176\n",
      "Epoch [29/50], Step [604/735], Loss: 0.0933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Step [605/735], Loss: 0.0382\n",
      "Epoch [29/50], Step [606/735], Loss: 0.0604\n",
      "Epoch [29/50], Step [607/735], Loss: 0.0265\n",
      "Epoch [29/50], Step [608/735], Loss: 0.0294\n",
      "Epoch [29/50], Step [609/735], Loss: 0.0393\n",
      "Epoch [29/50], Step [610/735], Loss: 0.1854\n",
      "Epoch [29/50], Step [611/735], Loss: 0.0273\n",
      "Epoch [29/50], Step [612/735], Loss: 0.0392\n",
      "Epoch [29/50], Step [613/735], Loss: 0.1027\n",
      "Epoch [29/50], Step [614/735], Loss: 0.0781\n",
      "Epoch [29/50], Step [615/735], Loss: 0.0590\n",
      "Epoch [29/50], Step [616/735], Loss: 0.1364\n",
      "Epoch [29/50], Step [617/735], Loss: 0.0441\n",
      "Epoch [29/50], Step [618/735], Loss: 0.0527\n",
      "Epoch [29/50], Step [619/735], Loss: 0.0284\n",
      "Epoch [29/50], Step [620/735], Loss: 0.0583\n",
      "Epoch [29/50], Step [621/735], Loss: 0.1186\n",
      "Epoch [29/50], Step [622/735], Loss: 0.1219\n",
      "Epoch [29/50], Step [623/735], Loss: 0.0437\n",
      "Epoch [29/50], Step [624/735], Loss: 0.0502\n",
      "Epoch [29/50], Step [625/735], Loss: 0.0393\n",
      "Epoch [29/50], Step [626/735], Loss: 0.0901\n",
      "Epoch [29/50], Step [627/735], Loss: 0.1832\n",
      "Epoch [29/50], Step [628/735], Loss: 0.0552\n",
      "Epoch [29/50], Step [629/735], Loss: 0.0438\n",
      "Epoch [29/50], Step [630/735], Loss: 0.0952\n",
      "Epoch [29/50], Step [631/735], Loss: 0.0495\n",
      "Epoch [29/50], Step [632/735], Loss: 0.1717\n",
      "Epoch [29/50], Step [633/735], Loss: 0.0623\n",
      "Epoch [29/50], Step [634/735], Loss: 0.1084\n",
      "Epoch [29/50], Step [635/735], Loss: 0.0933\n",
      "Epoch [29/50], Step [636/735], Loss: 0.0579\n",
      "Epoch [29/50], Step [637/735], Loss: 0.3621\n",
      "Epoch [29/50], Step [638/735], Loss: 0.0790\n",
      "Epoch [29/50], Step [639/735], Loss: 0.0632\n",
      "Epoch [29/50], Step [640/735], Loss: 0.0300\n",
      "Epoch [29/50], Step [641/735], Loss: 0.0790\n",
      "Epoch [29/50], Step [642/735], Loss: 0.2272\n",
      "Epoch [29/50], Step [643/735], Loss: 0.0269\n",
      "Epoch [29/50], Step [644/735], Loss: 0.0514\n",
      "Epoch [29/50], Step [645/735], Loss: 0.0579\n",
      "Epoch [29/50], Step [646/735], Loss: 0.0340\n",
      "Epoch [29/50], Step [647/735], Loss: 0.1326\n",
      "Epoch [29/50], Step [648/735], Loss: 0.0513\n",
      "Epoch [29/50], Step [649/735], Loss: 0.0898\n",
      "Epoch [29/50], Step [650/735], Loss: 0.0646\n",
      "Epoch [29/50], Step [651/735], Loss: 0.1524\n",
      "Epoch [29/50], Step [652/735], Loss: 0.0598\n",
      "Epoch [29/50], Step [653/735], Loss: 0.0989\n",
      "Epoch [29/50], Step [654/735], Loss: 0.3131\n",
      "Epoch [29/50], Step [655/735], Loss: 0.0408\n",
      "Epoch [29/50], Step [656/735], Loss: 0.0288\n",
      "Epoch [29/50], Step [657/735], Loss: 0.0474\n",
      "Epoch [29/50], Step [658/735], Loss: 0.0485\n",
      "Epoch [29/50], Step [659/735], Loss: 0.0519\n",
      "Epoch [29/50], Step [660/735], Loss: 0.0924\n",
      "Epoch [29/50], Step [661/735], Loss: 0.0351\n",
      "Epoch [29/50], Step [662/735], Loss: 0.0439\n",
      "Epoch [29/50], Step [663/735], Loss: 0.1135\n",
      "Epoch [29/50], Step [664/735], Loss: 0.0927\n",
      "Epoch [29/50], Step [665/735], Loss: 0.0582\n",
      "Epoch [29/50], Step [666/735], Loss: 0.0297\n",
      "Epoch [29/50], Step [667/735], Loss: 0.0403\n",
      "Epoch [29/50], Step [668/735], Loss: 0.0427\n",
      "Epoch [29/50], Step [669/735], Loss: 0.0447\n",
      "Epoch [29/50], Step [670/735], Loss: 0.1041\n",
      "Epoch [29/50], Step [671/735], Loss: 0.0579\n",
      "Epoch [29/50], Step [672/735], Loss: 0.0495\n",
      "Epoch [29/50], Step [673/735], Loss: 0.0288\n",
      "Epoch [29/50], Step [674/735], Loss: 0.0625\n",
      "Epoch [29/50], Step [675/735], Loss: 0.0911\n",
      "Epoch [29/50], Step [676/735], Loss: 0.0436\n",
      "Epoch [29/50], Step [677/735], Loss: 0.1274\n",
      "Epoch [29/50], Step [678/735], Loss: 0.0549\n",
      "Epoch [29/50], Step [679/735], Loss: 0.0337\n",
      "Epoch [29/50], Step [680/735], Loss: 0.0508\n",
      "Epoch [29/50], Step [681/735], Loss: 0.0637\n",
      "Epoch [29/50], Step [682/735], Loss: 0.0442\n",
      "Epoch [29/50], Step [683/735], Loss: 0.0434\n",
      "Epoch [29/50], Step [684/735], Loss: 0.0909\n",
      "Epoch [29/50], Step [685/735], Loss: 0.0969\n",
      "Epoch [29/50], Step [686/735], Loss: 0.0257\n",
      "Epoch [29/50], Step [687/735], Loss: 0.1134\n",
      "Epoch [29/50], Step [688/735], Loss: 0.0870\n",
      "Epoch [29/50], Step [689/735], Loss: 0.1105\n",
      "Epoch [29/50], Step [690/735], Loss: 0.0324\n",
      "Epoch [29/50], Step [691/735], Loss: 0.0697\n",
      "Epoch [29/50], Step [692/735], Loss: 0.0355\n",
      "Epoch [29/50], Step [693/735], Loss: 0.0556\n",
      "Epoch [29/50], Step [694/735], Loss: 0.0396\n",
      "Epoch [29/50], Step [695/735], Loss: 0.1059\n",
      "Epoch [29/50], Step [696/735], Loss: 0.2761\n",
      "Epoch [29/50], Step [697/735], Loss: 0.1661\n",
      "Epoch [29/50], Step [698/735], Loss: 0.0393\n",
      "Epoch [29/50], Step [699/735], Loss: 0.0551\n",
      "Epoch [29/50], Step [700/735], Loss: 0.0642\n",
      "Epoch [29/50], Step [701/735], Loss: 0.0452\n",
      "Epoch [29/50], Step [702/735], Loss: 0.0633\n",
      "Epoch [29/50], Step [703/735], Loss: 0.0145\n",
      "Epoch [29/50], Step [704/735], Loss: 0.0473\n",
      "Epoch [29/50], Step [705/735], Loss: 0.0218\n",
      "Epoch [29/50], Step [706/735], Loss: 0.0338\n",
      "Epoch [29/50], Step [707/735], Loss: 0.0416\n",
      "Epoch [29/50], Step [708/735], Loss: 0.0258\n",
      "Epoch [29/50], Step [709/735], Loss: 0.1998\n",
      "Epoch [29/50], Step [710/735], Loss: 0.0218\n",
      "Epoch [29/50], Step [711/735], Loss: 0.1169\n",
      "Epoch [29/50], Step [712/735], Loss: 0.0987\n",
      "Epoch [29/50], Step [713/735], Loss: 0.1468\n",
      "Epoch [29/50], Step [714/735], Loss: 0.0372\n",
      "Epoch [29/50], Step [715/735], Loss: 0.1324\n",
      "Epoch [29/50], Step [716/735], Loss: 0.0552\n",
      "Epoch [29/50], Step [717/735], Loss: 0.0276\n",
      "Epoch [29/50], Step [718/735], Loss: 0.0243\n",
      "Epoch [29/50], Step [719/735], Loss: 0.0335\n",
      "Epoch [29/50], Step [720/735], Loss: 0.0142\n",
      "Epoch [29/50], Step [721/735], Loss: 0.0227\n",
      "Epoch [29/50], Step [722/735], Loss: 0.0339\n",
      "Epoch [29/50], Step [723/735], Loss: 0.0672\n",
      "Epoch [29/50], Step [724/735], Loss: 0.0225\n",
      "Epoch [29/50], Step [725/735], Loss: 0.0722\n",
      "Epoch [29/50], Step [726/735], Loss: 0.1335\n",
      "Epoch [29/50], Step [727/735], Loss: 0.0145\n",
      "Epoch [29/50], Step [728/735], Loss: 0.0460\n",
      "Epoch [29/50], Step [729/735], Loss: 0.0224\n",
      "Epoch [29/50], Step [730/735], Loss: 0.0813\n",
      "Epoch [29/50], Step [731/735], Loss: 0.2405\n",
      "Epoch [29/50], Step [732/735], Loss: 0.0224\n",
      "Epoch [29/50], Step [733/735], Loss: 0.0328\n",
      "Epoch [29/50], Step [734/735], Loss: 0.0934\n",
      "Epoch [29/50], Step [735/735], Loss: 0.4318\n",
      "Epoch [30/50], Step [1/735], Loss: 0.0399\n",
      "Epoch [30/50], Step [2/735], Loss: 0.0583\n",
      "Epoch [30/50], Step [3/735], Loss: 0.0610\n",
      "Epoch [30/50], Step [4/735], Loss: 0.0405\n",
      "Epoch [30/50], Step [5/735], Loss: 0.1604\n",
      "Epoch [30/50], Step [6/735], Loss: 0.1539\n",
      "Epoch [30/50], Step [7/735], Loss: 0.0637\n",
      "Epoch [30/50], Step [8/735], Loss: 0.0649\n",
      "Epoch [30/50], Step [9/735], Loss: 0.0703\n",
      "Epoch [30/50], Step [10/735], Loss: 0.0360\n",
      "Epoch [30/50], Step [11/735], Loss: 0.0792\n",
      "Epoch [30/50], Step [12/735], Loss: 0.1474\n",
      "Epoch [30/50], Step [13/735], Loss: 0.0860\n",
      "Epoch [30/50], Step [14/735], Loss: 0.0389\n",
      "Epoch [30/50], Step [15/735], Loss: 0.0987\n",
      "Epoch [30/50], Step [16/735], Loss: 0.0413\n",
      "Epoch [30/50], Step [17/735], Loss: 0.2546\n",
      "Epoch [30/50], Step [18/735], Loss: 0.0519\n",
      "Epoch [30/50], Step [19/735], Loss: 0.0967\n",
      "Epoch [30/50], Step [20/735], Loss: 0.0278\n",
      "Epoch [30/50], Step [21/735], Loss: 0.0930\n",
      "Epoch [30/50], Step [22/735], Loss: 0.1620\n",
      "Epoch [30/50], Step [23/735], Loss: 0.0462\n",
      "Epoch [30/50], Step [24/735], Loss: 0.0436\n",
      "Epoch [30/50], Step [25/735], Loss: 0.2325\n",
      "Epoch [30/50], Step [26/735], Loss: 0.1116\n",
      "Epoch [30/50], Step [27/735], Loss: 0.0418\n",
      "Epoch [30/50], Step [28/735], Loss: 0.0802\n",
      "Epoch [30/50], Step [29/735], Loss: 0.0282\n",
      "Epoch [30/50], Step [30/735], Loss: 0.0473\n",
      "Epoch [30/50], Step [31/735], Loss: 0.0493\n",
      "Epoch [30/50], Step [32/735], Loss: 0.1483\n",
      "Epoch [30/50], Step [33/735], Loss: 0.0511\n",
      "Epoch [30/50], Step [34/735], Loss: 0.0660\n",
      "Epoch [30/50], Step [35/735], Loss: 0.0383\n",
      "Epoch [30/50], Step [36/735], Loss: 0.1291\n",
      "Epoch [30/50], Step [37/735], Loss: 0.0363\n",
      "Epoch [30/50], Step [38/735], Loss: 0.1125\n",
      "Epoch [30/50], Step [39/735], Loss: 0.0529\n",
      "Epoch [30/50], Step [40/735], Loss: 0.0589\n",
      "Epoch [30/50], Step [41/735], Loss: 0.0625\n",
      "Epoch [30/50], Step [42/735], Loss: 0.1019\n",
      "Epoch [30/50], Step [43/735], Loss: 0.0544\n",
      "Epoch [30/50], Step [44/735], Loss: 0.0446\n",
      "Epoch [30/50], Step [45/735], Loss: 0.1328\n",
      "Epoch [30/50], Step [46/735], Loss: 0.1134\n",
      "Epoch [30/50], Step [47/735], Loss: 0.0145\n",
      "Epoch [30/50], Step [48/735], Loss: 0.0882\n",
      "Epoch [30/50], Step [49/735], Loss: 0.0767\n",
      "Epoch [30/50], Step [50/735], Loss: 0.0580\n",
      "Epoch [30/50], Step [51/735], Loss: 0.0874\n",
      "Epoch [30/50], Step [52/735], Loss: 0.0565\n",
      "Epoch [30/50], Step [53/735], Loss: 0.0551\n",
      "Epoch [30/50], Step [54/735], Loss: 0.0576\n",
      "Epoch [30/50], Step [55/735], Loss: 0.0333\n",
      "Epoch [30/50], Step [56/735], Loss: 0.0330\n",
      "Epoch [30/50], Step [57/735], Loss: 0.0278\n",
      "Epoch [30/50], Step [58/735], Loss: 0.0376\n",
      "Epoch [30/50], Step [59/735], Loss: 0.0250\n",
      "Epoch [30/50], Step [60/735], Loss: 0.0442\n",
      "Epoch [30/50], Step [61/735], Loss: 0.0409\n",
      "Epoch [30/50], Step [62/735], Loss: 0.0322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Step [63/735], Loss: 0.0932\n",
      "Epoch [30/50], Step [64/735], Loss: 0.0436\n",
      "Epoch [30/50], Step [65/735], Loss: 0.0958\n",
      "Epoch [30/50], Step [66/735], Loss: 0.0223\n",
      "Epoch [30/50], Step [67/735], Loss: 0.0234\n",
      "Epoch [30/50], Step [68/735], Loss: 0.0285\n",
      "Epoch [30/50], Step [69/735], Loss: 0.0915\n",
      "Epoch [30/50], Step [70/735], Loss: 0.0387\n",
      "Epoch [30/50], Step [71/735], Loss: 0.0353\n",
      "Epoch [30/50], Step [72/735], Loss: 0.0906\n",
      "Epoch [30/50], Step [73/735], Loss: 0.1199\n",
      "Epoch [30/50], Step [74/735], Loss: 0.0956\n",
      "Epoch [30/50], Step [75/735], Loss: 0.0712\n",
      "Epoch [30/50], Step [76/735], Loss: 0.0455\n",
      "Epoch [30/50], Step [77/735], Loss: 0.0786\n",
      "Epoch [30/50], Step [78/735], Loss: 0.1057\n",
      "Epoch [30/50], Step [79/735], Loss: 0.0571\n",
      "Epoch [30/50], Step [80/735], Loss: 0.0401\n",
      "Epoch [30/50], Step [81/735], Loss: 0.1016\n",
      "Epoch [30/50], Step [82/735], Loss: 0.0365\n",
      "Epoch [30/50], Step [83/735], Loss: 0.0969\n",
      "Epoch [30/50], Step [84/735], Loss: 0.0954\n",
      "Epoch [30/50], Step [85/735], Loss: 0.0428\n",
      "Epoch [30/50], Step [86/735], Loss: 0.0388\n",
      "Epoch [30/50], Step [87/735], Loss: 0.0765\n",
      "Epoch [30/50], Step [88/735], Loss: 0.1033\n",
      "Epoch [30/50], Step [89/735], Loss: 0.0557\n",
      "Epoch [30/50], Step [90/735], Loss: 0.0303\n",
      "Epoch [30/50], Step [91/735], Loss: 0.0167\n",
      "Epoch [30/50], Step [92/735], Loss: 0.0505\n",
      "Epoch [30/50], Step [93/735], Loss: 0.0888\n",
      "Epoch [30/50], Step [94/735], Loss: 0.1281\n",
      "Epoch [30/50], Step [95/735], Loss: 0.0187\n",
      "Epoch [30/50], Step [96/735], Loss: 0.0798\n",
      "Epoch [30/50], Step [97/735], Loss: 0.0943\n",
      "Epoch [30/50], Step [98/735], Loss: 0.2102\n",
      "Epoch [30/50], Step [99/735], Loss: 0.0301\n",
      "Epoch [30/50], Step [100/735], Loss: 0.0262\n",
      "Epoch [30/50], Step [101/735], Loss: 0.0770\n",
      "Epoch [30/50], Step [102/735], Loss: 0.0842\n",
      "Epoch [30/50], Step [103/735], Loss: 0.0446\n",
      "Epoch [30/50], Step [104/735], Loss: 0.0327\n",
      "Epoch [30/50], Step [105/735], Loss: 0.0348\n",
      "Epoch [30/50], Step [106/735], Loss: 0.0476\n",
      "Epoch [30/50], Step [107/735], Loss: 0.0447\n",
      "Epoch [30/50], Step [108/735], Loss: 0.0357\n",
      "Epoch [30/50], Step [109/735], Loss: 0.1666\n",
      "Epoch [30/50], Step [110/735], Loss: 0.1905\n",
      "Epoch [30/50], Step [111/735], Loss: 0.0595\n",
      "Epoch [30/50], Step [112/735], Loss: 0.0656\n",
      "Epoch [30/50], Step [113/735], Loss: 0.1169\n",
      "Epoch [30/50], Step [114/735], Loss: 0.0328\n",
      "Epoch [30/50], Step [115/735], Loss: 0.0585\n",
      "Epoch [30/50], Step [116/735], Loss: 0.0474\n",
      "Epoch [30/50], Step [117/735], Loss: 0.3277\n",
      "Epoch [30/50], Step [118/735], Loss: 0.0584\n",
      "Epoch [30/50], Step [119/735], Loss: 0.0469\n",
      "Epoch [30/50], Step [120/735], Loss: 0.1577\n",
      "Epoch [30/50], Step [121/735], Loss: 0.0539\n",
      "Epoch [30/50], Step [122/735], Loss: 0.0543\n",
      "Epoch [30/50], Step [123/735], Loss: 0.0496\n",
      "Epoch [30/50], Step [124/735], Loss: 0.3487\n",
      "Epoch [30/50], Step [125/735], Loss: 0.0393\n",
      "Epoch [30/50], Step [126/735], Loss: 0.1125\n",
      "Epoch [30/50], Step [127/735], Loss: 0.0687\n",
      "Epoch [30/50], Step [128/735], Loss: 0.0198\n",
      "Epoch [30/50], Step [129/735], Loss: 0.0531\n",
      "Epoch [30/50], Step [130/735], Loss: 0.1206\n",
      "Epoch [30/50], Step [131/735], Loss: 0.1846\n",
      "Epoch [30/50], Step [132/735], Loss: 0.0347\n",
      "Epoch [30/50], Step [133/735], Loss: 0.0467\n",
      "Epoch [30/50], Step [134/735], Loss: 0.1014\n",
      "Epoch [30/50], Step [135/735], Loss: 0.0392\n",
      "Epoch [30/50], Step [136/735], Loss: 0.0175\n",
      "Epoch [30/50], Step [137/735], Loss: 0.0661\n",
      "Epoch [30/50], Step [138/735], Loss: 0.0167\n",
      "Epoch [30/50], Step [139/735], Loss: 0.0554\n",
      "Epoch [30/50], Step [140/735], Loss: 0.0320\n",
      "Epoch [30/50], Step [141/735], Loss: 0.0372\n",
      "Epoch [30/50], Step [142/735], Loss: 0.0382\n",
      "Epoch [30/50], Step [143/735], Loss: 0.0499\n",
      "Epoch [30/50], Step [144/735], Loss: 0.1235\n",
      "Epoch [30/50], Step [145/735], Loss: 0.0600\n",
      "Epoch [30/50], Step [146/735], Loss: 0.0511\n",
      "Epoch [30/50], Step [147/735], Loss: 0.0749\n",
      "Epoch [30/50], Step [148/735], Loss: 0.0608\n",
      "Epoch [30/50], Step [149/735], Loss: 0.0443\n",
      "Epoch [30/50], Step [150/735], Loss: 0.3541\n",
      "Epoch [30/50], Step [151/735], Loss: 0.0380\n",
      "Epoch [30/50], Step [152/735], Loss: 0.0756\n",
      "Epoch [30/50], Step [153/735], Loss: 0.0215\n",
      "Epoch [30/50], Step [154/735], Loss: 0.0409\n",
      "Epoch [30/50], Step [155/735], Loss: 0.0535\n",
      "Epoch [30/50], Step [156/735], Loss: 0.0340\n",
      "Epoch [30/50], Step [157/735], Loss: 0.0609\n",
      "Epoch [30/50], Step [158/735], Loss: 0.0857\n",
      "Epoch [30/50], Step [159/735], Loss: 0.0511\n",
      "Epoch [30/50], Step [160/735], Loss: 0.0377\n",
      "Epoch [30/50], Step [161/735], Loss: 0.1981\n",
      "Epoch [30/50], Step [162/735], Loss: 0.0235\n",
      "Epoch [30/50], Step [163/735], Loss: 0.0764\n",
      "Epoch [30/50], Step [164/735], Loss: 0.0210\n",
      "Epoch [30/50], Step [165/735], Loss: 0.0592\n",
      "Epoch [30/50], Step [166/735], Loss: 0.0477\n",
      "Epoch [30/50], Step [167/735], Loss: 0.0296\n",
      "Epoch [30/50], Step [168/735], Loss: 0.0352\n",
      "Epoch [30/50], Step [169/735], Loss: 0.0401\n",
      "Epoch [30/50], Step [170/735], Loss: 0.0412\n",
      "Epoch [30/50], Step [171/735], Loss: 0.0282\n",
      "Epoch [30/50], Step [172/735], Loss: 0.0236\n",
      "Epoch [30/50], Step [173/735], Loss: 0.0215\n",
      "Epoch [30/50], Step [174/735], Loss: 0.0803\n",
      "Epoch [30/50], Step [175/735], Loss: 0.0634\n",
      "Epoch [30/50], Step [176/735], Loss: 0.0949\n",
      "Epoch [30/50], Step [177/735], Loss: 0.0392\n",
      "Epoch [30/50], Step [178/735], Loss: 0.0924\n",
      "Epoch [30/50], Step [179/735], Loss: 0.0637\n",
      "Epoch [30/50], Step [180/735], Loss: 0.0247\n",
      "Epoch [30/50], Step [181/735], Loss: 0.0511\n",
      "Epoch [30/50], Step [182/735], Loss: 0.0334\n",
      "Epoch [30/50], Step [183/735], Loss: 0.0515\n",
      "Epoch [30/50], Step [184/735], Loss: 0.0684\n",
      "Epoch [30/50], Step [185/735], Loss: 0.0298\n",
      "Epoch [30/50], Step [186/735], Loss: 0.3107\n",
      "Epoch [30/50], Step [187/735], Loss: 0.0431\n",
      "Epoch [30/50], Step [188/735], Loss: 0.1552\n",
      "Epoch [30/50], Step [189/735], Loss: 0.0721\n",
      "Epoch [30/50], Step [190/735], Loss: 0.0276\n",
      "Epoch [30/50], Step [191/735], Loss: 0.0944\n",
      "Epoch [30/50], Step [192/735], Loss: 0.0298\n",
      "Epoch [30/50], Step [193/735], Loss: 0.4062\n",
      "Epoch [30/50], Step [194/735], Loss: 0.0825\n",
      "Epoch [30/50], Step [195/735], Loss: 0.0234\n",
      "Epoch [30/50], Step [196/735], Loss: 0.0296\n",
      "Epoch [30/50], Step [197/735], Loss: 0.0224\n",
      "Epoch [30/50], Step [198/735], Loss: 0.0779\n",
      "Epoch [30/50], Step [199/735], Loss: 0.0267\n",
      "Epoch [30/50], Step [200/735], Loss: 0.0285\n",
      "Epoch [30/50], Step [201/735], Loss: 0.0479\n",
      "Epoch [30/50], Step [202/735], Loss: 0.3919\n",
      "Epoch [30/50], Step [203/735], Loss: 0.0751\n",
      "Epoch [30/50], Step [204/735], Loss: 0.0759\n",
      "Epoch [30/50], Step [205/735], Loss: 0.1656\n",
      "Epoch [30/50], Step [206/735], Loss: 0.0148\n",
      "Epoch [30/50], Step [207/735], Loss: 0.0211\n",
      "Epoch [30/50], Step [208/735], Loss: 0.0948\n",
      "Epoch [30/50], Step [209/735], Loss: 0.0563\n",
      "Epoch [30/50], Step [210/735], Loss: 0.0889\n",
      "Epoch [30/50], Step [211/735], Loss: 0.0786\n",
      "Epoch [30/50], Step [212/735], Loss: 0.0509\n",
      "Epoch [30/50], Step [213/735], Loss: 0.0751\n",
      "Epoch [30/50], Step [214/735], Loss: 0.0234\n",
      "Epoch [30/50], Step [215/735], Loss: 0.0157\n",
      "Epoch [30/50], Step [216/735], Loss: 0.2774\n",
      "Epoch [30/50], Step [217/735], Loss: 0.0387\n",
      "Epoch [30/50], Step [218/735], Loss: 0.0868\n",
      "Epoch [30/50], Step [219/735], Loss: 0.0563\n",
      "Epoch [30/50], Step [220/735], Loss: 0.1017\n",
      "Epoch [30/50], Step [221/735], Loss: 0.0263\n",
      "Epoch [30/50], Step [222/735], Loss: 0.0527\n",
      "Epoch [30/50], Step [223/735], Loss: 0.0587\n",
      "Epoch [30/50], Step [224/735], Loss: 0.0566\n",
      "Epoch [30/50], Step [225/735], Loss: 0.0539\n",
      "Epoch [30/50], Step [226/735], Loss: 0.0646\n",
      "Epoch [30/50], Step [227/735], Loss: 0.1883\n",
      "Epoch [30/50], Step [228/735], Loss: 0.0410\n",
      "Epoch [30/50], Step [229/735], Loss: 0.0369\n",
      "Epoch [30/50], Step [230/735], Loss: 0.0500\n",
      "Epoch [30/50], Step [231/735], Loss: 0.2571\n",
      "Epoch [30/50], Step [232/735], Loss: 0.0850\n",
      "Epoch [30/50], Step [233/735], Loss: 0.1588\n",
      "Epoch [30/50], Step [234/735], Loss: 0.0596\n",
      "Epoch [30/50], Step [235/735], Loss: 0.0473\n",
      "Epoch [30/50], Step [236/735], Loss: 0.1900\n",
      "Epoch [30/50], Step [237/735], Loss: 0.0292\n",
      "Epoch [30/50], Step [238/735], Loss: 0.0460\n",
      "Epoch [30/50], Step [239/735], Loss: 0.2126\n",
      "Epoch [30/50], Step [240/735], Loss: 0.0397\n",
      "Epoch [30/50], Step [241/735], Loss: 0.1547\n",
      "Epoch [30/50], Step [242/735], Loss: 0.1424\n",
      "Epoch [30/50], Step [243/735], Loss: 0.0662\n",
      "Epoch [30/50], Step [244/735], Loss: 0.0462\n",
      "Epoch [30/50], Step [245/735], Loss: 0.0777\n",
      "Epoch [30/50], Step [246/735], Loss: 0.0411\n",
      "Epoch [30/50], Step [247/735], Loss: 0.0154\n",
      "Epoch [30/50], Step [248/735], Loss: 0.1553\n",
      "Epoch [30/50], Step [249/735], Loss: 0.0674\n",
      "Epoch [30/50], Step [250/735], Loss: 0.0673\n",
      "Epoch [30/50], Step [251/735], Loss: 0.0556\n",
      "Epoch [30/50], Step [252/735], Loss: 0.0512\n",
      "Epoch [30/50], Step [253/735], Loss: 0.0454\n",
      "Epoch [30/50], Step [254/735], Loss: 0.0455\n",
      "Epoch [30/50], Step [255/735], Loss: 0.0404\n",
      "Epoch [30/50], Step [256/735], Loss: 0.1263\n",
      "Epoch [30/50], Step [257/735], Loss: 0.0697\n",
      "Epoch [30/50], Step [258/735], Loss: 0.0857\n",
      "Epoch [30/50], Step [259/735], Loss: 0.0582\n",
      "Epoch [30/50], Step [260/735], Loss: 0.0771\n",
      "Epoch [30/50], Step [261/735], Loss: 0.0373\n",
      "Epoch [30/50], Step [262/735], Loss: 0.0438\n",
      "Epoch [30/50], Step [263/735], Loss: 0.0982\n",
      "Epoch [30/50], Step [264/735], Loss: 0.0527\n",
      "Epoch [30/50], Step [265/735], Loss: 0.1539\n",
      "Epoch [30/50], Step [266/735], Loss: 0.0737\n",
      "Epoch [30/50], Step [267/735], Loss: 0.0869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Step [268/735], Loss: 0.0746\n",
      "Epoch [30/50], Step [269/735], Loss: 0.0432\n",
      "Epoch [30/50], Step [270/735], Loss: 0.0452\n",
      "Epoch [30/50], Step [271/735], Loss: 0.0486\n",
      "Epoch [30/50], Step [272/735], Loss: 0.0513\n",
      "Epoch [30/50], Step [273/735], Loss: 0.0872\n",
      "Epoch [30/50], Step [274/735], Loss: 0.0473\n",
      "Epoch [30/50], Step [275/735], Loss: 0.0581\n",
      "Epoch [30/50], Step [276/735], Loss: 0.1249\n",
      "Epoch [30/50], Step [277/735], Loss: 0.0454\n",
      "Epoch [30/50], Step [278/735], Loss: 0.0338\n",
      "Epoch [30/50], Step [279/735], Loss: 0.0591\n",
      "Epoch [30/50], Step [280/735], Loss: 0.0238\n",
      "Epoch [30/50], Step [281/735], Loss: 0.0827\n",
      "Epoch [30/50], Step [282/735], Loss: 0.0811\n",
      "Epoch [30/50], Step [283/735], Loss: 0.0815\n",
      "Epoch [30/50], Step [284/735], Loss: 0.0817\n",
      "Epoch [30/50], Step [285/735], Loss: 0.0424\n",
      "Epoch [30/50], Step [286/735], Loss: 0.0615\n",
      "Epoch [30/50], Step [287/735], Loss: 0.0861\n",
      "Epoch [30/50], Step [288/735], Loss: 0.0533\n",
      "Epoch [30/50], Step [289/735], Loss: 0.0463\n",
      "Epoch [30/50], Step [290/735], Loss: 0.0869\n",
      "Epoch [30/50], Step [291/735], Loss: 0.1576\n",
      "Epoch [30/50], Step [292/735], Loss: 0.1371\n",
      "Epoch [30/50], Step [293/735], Loss: 0.0190\n",
      "Epoch [30/50], Step [294/735], Loss: 0.0416\n",
      "Epoch [30/50], Step [295/735], Loss: 0.0407\n",
      "Epoch [30/50], Step [296/735], Loss: 0.0511\n",
      "Epoch [30/50], Step [297/735], Loss: 0.0770\n",
      "Epoch [30/50], Step [298/735], Loss: 0.0370\n",
      "Epoch [30/50], Step [299/735], Loss: 0.0430\n",
      "Epoch [30/50], Step [300/735], Loss: 0.0894\n",
      "Epoch [30/50], Step [301/735], Loss: 0.0645\n",
      "Epoch [30/50], Step [302/735], Loss: 0.0481\n",
      "Epoch [30/50], Step [303/735], Loss: 0.0829\n",
      "Epoch [30/50], Step [304/735], Loss: 0.0796\n",
      "Epoch [30/50], Step [305/735], Loss: 0.1637\n",
      "Epoch [30/50], Step [306/735], Loss: 0.0823\n",
      "Epoch [30/50], Step [307/735], Loss: 0.0494\n",
      "Epoch [30/50], Step [308/735], Loss: 0.0838\n",
      "Epoch [30/50], Step [309/735], Loss: 0.0378\n",
      "Epoch [30/50], Step [310/735], Loss: 0.0232\n",
      "Epoch [30/50], Step [311/735], Loss: 0.0420\n",
      "Epoch [30/50], Step [312/735], Loss: 0.0498\n",
      "Epoch [30/50], Step [313/735], Loss: 0.0375\n",
      "Epoch [30/50], Step [314/735], Loss: 0.0487\n",
      "Epoch [30/50], Step [315/735], Loss: 0.0670\n",
      "Epoch [30/50], Step [316/735], Loss: 0.1057\n",
      "Epoch [30/50], Step [317/735], Loss: 0.0350\n",
      "Epoch [30/50], Step [318/735], Loss: 0.0308\n",
      "Epoch [30/50], Step [319/735], Loss: 0.0754\n",
      "Epoch [30/50], Step [320/735], Loss: 0.0606\n",
      "Epoch [30/50], Step [321/735], Loss: 0.0782\n",
      "Epoch [30/50], Step [322/735], Loss: 0.1533\n",
      "Epoch [30/50], Step [323/735], Loss: 0.0282\n",
      "Epoch [30/50], Step [324/735], Loss: 0.0767\n",
      "Epoch [30/50], Step [325/735], Loss: 0.0357\n",
      "Epoch [30/50], Step [326/735], Loss: 0.0577\n",
      "Epoch [30/50], Step [327/735], Loss: 0.1552\n",
      "Epoch [30/50], Step [328/735], Loss: 0.1051\n",
      "Epoch [30/50], Step [329/735], Loss: 0.0196\n",
      "Epoch [30/50], Step [330/735], Loss: 0.0343\n",
      "Epoch [30/50], Step [331/735], Loss: 0.0521\n",
      "Epoch [30/50], Step [332/735], Loss: 0.1145\n",
      "Epoch [30/50], Step [333/735], Loss: 0.0769\n",
      "Epoch [30/50], Step [334/735], Loss: 0.0509\n",
      "Epoch [30/50], Step [335/735], Loss: 0.0355\n",
      "Epoch [30/50], Step [336/735], Loss: 0.0619\n",
      "Epoch [30/50], Step [337/735], Loss: 0.0451\n",
      "Epoch [30/50], Step [338/735], Loss: 0.0419\n",
      "Epoch [30/50], Step [339/735], Loss: 0.0479\n",
      "Epoch [30/50], Step [340/735], Loss: 0.0616\n",
      "Epoch [30/50], Step [341/735], Loss: 0.0654\n",
      "Epoch [30/50], Step [342/735], Loss: 0.0491\n",
      "Epoch [30/50], Step [343/735], Loss: 0.0680\n",
      "Epoch [30/50], Step [344/735], Loss: 0.0198\n",
      "Epoch [30/50], Step [345/735], Loss: 0.0402\n",
      "Epoch [30/50], Step [346/735], Loss: 0.0242\n",
      "Epoch [30/50], Step [347/735], Loss: 0.0277\n",
      "Epoch [30/50], Step [348/735], Loss: 0.1775\n",
      "Epoch [30/50], Step [349/735], Loss: 0.0375\n",
      "Epoch [30/50], Step [350/735], Loss: 0.0173\n",
      "Epoch [30/50], Step [351/735], Loss: 0.0422\n",
      "Epoch [30/50], Step [352/735], Loss: 0.0267\n",
      "Epoch [30/50], Step [353/735], Loss: 0.0646\n",
      "Epoch [30/50], Step [354/735], Loss: 0.0722\n",
      "Epoch [30/50], Step [355/735], Loss: 0.0345\n",
      "Epoch [30/50], Step [356/735], Loss: 0.0257\n",
      "Epoch [30/50], Step [357/735], Loss: 0.0420\n",
      "Epoch [30/50], Step [358/735], Loss: 0.0403\n",
      "Epoch [30/50], Step [359/735], Loss: 0.0376\n",
      "Epoch [30/50], Step [360/735], Loss: 0.0286\n",
      "Epoch [30/50], Step [361/735], Loss: 0.0592\n",
      "Epoch [30/50], Step [362/735], Loss: 0.1095\n",
      "Epoch [30/50], Step [363/735], Loss: 0.0896\n",
      "Epoch [30/50], Step [364/735], Loss: 0.0153\n",
      "Epoch [30/50], Step [365/735], Loss: 0.1388\n",
      "Epoch [30/50], Step [366/735], Loss: 0.0544\n",
      "Epoch [30/50], Step [367/735], Loss: 0.0584\n",
      "Epoch [30/50], Step [368/735], Loss: 0.0389\n",
      "Epoch [30/50], Step [369/735], Loss: 0.0290\n",
      "Epoch [30/50], Step [370/735], Loss: 0.0809\n",
      "Epoch [30/50], Step [371/735], Loss: 0.0938\n",
      "Epoch [30/50], Step [372/735], Loss: 0.0299\n",
      "Epoch [30/50], Step [373/735], Loss: 0.0718\n",
      "Epoch [30/50], Step [374/735], Loss: 0.0371\n",
      "Epoch [30/50], Step [375/735], Loss: 0.0650\n",
      "Epoch [30/50], Step [376/735], Loss: 0.0537\n",
      "Epoch [30/50], Step [377/735], Loss: 0.0277\n",
      "Epoch [30/50], Step [378/735], Loss: 0.1722\n",
      "Epoch [30/50], Step [379/735], Loss: 0.0639\n",
      "Epoch [30/50], Step [380/735], Loss: 0.0247\n",
      "Epoch [30/50], Step [381/735], Loss: 0.3486\n",
      "Epoch [30/50], Step [382/735], Loss: 0.0603\n",
      "Epoch [30/50], Step [383/735], Loss: 0.0611\n",
      "Epoch [30/50], Step [384/735], Loss: 0.0723\n",
      "Epoch [30/50], Step [385/735], Loss: 0.0788\n",
      "Epoch [30/50], Step [386/735], Loss: 0.0441\n",
      "Epoch [30/50], Step [387/735], Loss: 0.0380\n",
      "Epoch [30/50], Step [388/735], Loss: 0.1877\n",
      "Epoch [30/50], Step [389/735], Loss: 0.0715\n",
      "Epoch [30/50], Step [390/735], Loss: 0.0187\n",
      "Epoch [30/50], Step [391/735], Loss: 0.1299\n",
      "Epoch [30/50], Step [392/735], Loss: 0.0222\n",
      "Epoch [30/50], Step [393/735], Loss: 0.0208\n",
      "Epoch [30/50], Step [394/735], Loss: 0.5192\n",
      "Epoch [30/50], Step [395/735], Loss: 0.0409\n",
      "Epoch [30/50], Step [396/735], Loss: 0.2966\n",
      "Epoch [30/50], Step [397/735], Loss: 0.0224\n",
      "Epoch [30/50], Step [398/735], Loss: 0.0648\n",
      "Epoch [30/50], Step [399/735], Loss: 0.0647\n",
      "Epoch [30/50], Step [400/735], Loss: 0.0546\n",
      "Epoch [30/50], Step [401/735], Loss: 0.0506\n",
      "Epoch [30/50], Step [402/735], Loss: 0.0283\n",
      "Epoch [30/50], Step [403/735], Loss: 0.0710\n",
      "Epoch [30/50], Step [404/735], Loss: 0.0680\n",
      "Epoch [30/50], Step [405/735], Loss: 0.0254\n",
      "Epoch [30/50], Step [406/735], Loss: 0.0390\n",
      "Epoch [30/50], Step [407/735], Loss: 0.1011\n",
      "Epoch [30/50], Step [408/735], Loss: 0.0453\n",
      "Epoch [30/50], Step [409/735], Loss: 0.0543\n",
      "Epoch [30/50], Step [410/735], Loss: 0.0809\n",
      "Epoch [30/50], Step [411/735], Loss: 0.0384\n",
      "Epoch [30/50], Step [412/735], Loss: 0.1571\n",
      "Epoch [30/50], Step [413/735], Loss: 0.0359\n",
      "Epoch [30/50], Step [414/735], Loss: 0.0307\n",
      "Epoch [30/50], Step [415/735], Loss: 0.0597\n",
      "Epoch [30/50], Step [416/735], Loss: 0.0214\n",
      "Epoch [30/50], Step [417/735], Loss: 0.0494\n",
      "Epoch [30/50], Step [418/735], Loss: 0.0245\n",
      "Epoch [30/50], Step [419/735], Loss: 0.0157\n",
      "Epoch [30/50], Step [420/735], Loss: 0.0339\n",
      "Epoch [30/50], Step [421/735], Loss: 0.0388\n",
      "Epoch [30/50], Step [422/735], Loss: 0.0147\n",
      "Epoch [30/50], Step [423/735], Loss: 0.2486\n",
      "Epoch [30/50], Step [424/735], Loss: 0.0938\n",
      "Epoch [30/50], Step [425/735], Loss: 0.0411\n",
      "Epoch [30/50], Step [426/735], Loss: 0.0675\n",
      "Epoch [30/50], Step [427/735], Loss: 0.0694\n",
      "Epoch [30/50], Step [428/735], Loss: 0.2234\n",
      "Epoch [30/50], Step [429/735], Loss: 0.0541\n",
      "Epoch [30/50], Step [430/735], Loss: 0.0515\n",
      "Epoch [30/50], Step [431/735], Loss: 0.0417\n",
      "Epoch [30/50], Step [432/735], Loss: 0.0512\n",
      "Epoch [30/50], Step [433/735], Loss: 0.0733\n",
      "Epoch [30/50], Step [434/735], Loss: 0.1608\n",
      "Epoch [30/50], Step [435/735], Loss: 0.0574\n",
      "Epoch [30/50], Step [436/735], Loss: 0.0201\n",
      "Epoch [30/50], Step [437/735], Loss: 0.0645\n",
      "Epoch [30/50], Step [438/735], Loss: 0.1482\n",
      "Epoch [30/50], Step [439/735], Loss: 0.0709\n",
      "Epoch [30/50], Step [440/735], Loss: 0.0893\n",
      "Epoch [30/50], Step [441/735], Loss: 0.0614\n",
      "Epoch [30/50], Step [442/735], Loss: 0.0653\n",
      "Epoch [30/50], Step [443/735], Loss: 0.0614\n",
      "Epoch [30/50], Step [444/735], Loss: 0.0453\n",
      "Epoch [30/50], Step [445/735], Loss: 0.0835\n",
      "Epoch [30/50], Step [446/735], Loss: 0.1436\n",
      "Epoch [30/50], Step [447/735], Loss: 0.1445\n",
      "Epoch [30/50], Step [448/735], Loss: 0.0297\n",
      "Epoch [30/50], Step [449/735], Loss: 0.0632\n",
      "Epoch [30/50], Step [450/735], Loss: 0.0464\n",
      "Epoch [30/50], Step [451/735], Loss: 0.0352\n",
      "Epoch [30/50], Step [452/735], Loss: 0.0871\n",
      "Epoch [30/50], Step [453/735], Loss: 0.0335\n",
      "Epoch [30/50], Step [454/735], Loss: 0.1179\n",
      "Epoch [30/50], Step [455/735], Loss: 0.0390\n",
      "Epoch [30/50], Step [456/735], Loss: 0.0347\n",
      "Epoch [30/50], Step [457/735], Loss: 0.0421\n",
      "Epoch [30/50], Step [458/735], Loss: 0.0382\n",
      "Epoch [30/50], Step [459/735], Loss: 0.0656\n",
      "Epoch [30/50], Step [460/735], Loss: 0.0911\n",
      "Epoch [30/50], Step [461/735], Loss: 0.1231\n",
      "Epoch [30/50], Step [462/735], Loss: 0.0741\n",
      "Epoch [30/50], Step [463/735], Loss: 0.0726\n",
      "Epoch [30/50], Step [464/735], Loss: 0.3705\n",
      "Epoch [30/50], Step [465/735], Loss: 0.4441\n",
      "Epoch [30/50], Step [466/735], Loss: 0.0484\n",
      "Epoch [30/50], Step [467/735], Loss: 0.0291\n",
      "Epoch [30/50], Step [468/735], Loss: 0.0424\n",
      "Epoch [30/50], Step [469/735], Loss: 0.0410\n",
      "Epoch [30/50], Step [470/735], Loss: 0.0611\n",
      "Epoch [30/50], Step [471/735], Loss: 0.0541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Step [472/735], Loss: 0.1372\n",
      "Epoch [30/50], Step [473/735], Loss: 0.0662\n",
      "Epoch [30/50], Step [474/735], Loss: 0.0547\n",
      "Epoch [30/50], Step [475/735], Loss: 0.0274\n",
      "Epoch [30/50], Step [476/735], Loss: 0.0268\n",
      "Epoch [30/50], Step [477/735], Loss: 0.0978\n",
      "Epoch [30/50], Step [478/735], Loss: 0.0435\n",
      "Epoch [30/50], Step [479/735], Loss: 0.0431\n",
      "Epoch [30/50], Step [480/735], Loss: 0.0259\n",
      "Epoch [30/50], Step [481/735], Loss: 0.0582\n",
      "Epoch [30/50], Step [482/735], Loss: 0.0357\n",
      "Epoch [30/50], Step [483/735], Loss: 0.0332\n",
      "Epoch [30/50], Step [484/735], Loss: 0.0571\n",
      "Epoch [30/50], Step [485/735], Loss: 0.0424\n",
      "Epoch [30/50], Step [486/735], Loss: 0.0402\n",
      "Epoch [30/50], Step [487/735], Loss: 0.3251\n",
      "Epoch [30/50], Step [488/735], Loss: 0.0751\n",
      "Epoch [30/50], Step [489/735], Loss: 0.1652\n",
      "Epoch [30/50], Step [490/735], Loss: 0.0822\n",
      "Epoch [30/50], Step [491/735], Loss: 0.1189\n",
      "Epoch [30/50], Step [492/735], Loss: 0.0278\n",
      "Epoch [30/50], Step [493/735], Loss: 0.0749\n",
      "Epoch [30/50], Step [494/735], Loss: 0.0569\n",
      "Epoch [30/50], Step [495/735], Loss: 0.0649\n",
      "Epoch [30/50], Step [496/735], Loss: 0.1592\n",
      "Epoch [30/50], Step [497/735], Loss: 0.1563\n",
      "Epoch [30/50], Step [498/735], Loss: 0.0762\n",
      "Epoch [30/50], Step [499/735], Loss: 0.0259\n",
      "Epoch [30/50], Step [500/735], Loss: 0.0635\n",
      "Epoch [30/50], Step [501/735], Loss: 0.0264\n",
      "Epoch [30/50], Step [502/735], Loss: 0.0639\n",
      "Epoch [30/50], Step [503/735], Loss: 0.0900\n",
      "Epoch [30/50], Step [504/735], Loss: 0.0745\n",
      "Epoch [30/50], Step [505/735], Loss: 0.0511\n",
      "Epoch [30/50], Step [506/735], Loss: 0.1079\n",
      "Epoch [30/50], Step [507/735], Loss: 0.0482\n",
      "Epoch [30/50], Step [508/735], Loss: 0.0441\n",
      "Epoch [30/50], Step [509/735], Loss: 0.0655\n",
      "Epoch [30/50], Step [510/735], Loss: 0.0442\n",
      "Epoch [30/50], Step [511/735], Loss: 0.0154\n",
      "Epoch [30/50], Step [512/735], Loss: 0.0157\n",
      "Epoch [30/50], Step [513/735], Loss: 0.0301\n",
      "Epoch [30/50], Step [514/735], Loss: 0.0371\n",
      "Epoch [30/50], Step [515/735], Loss: 0.0457\n",
      "Epoch [30/50], Step [516/735], Loss: 0.1298\n",
      "Epoch [30/50], Step [517/735], Loss: 0.0505\n",
      "Epoch [30/50], Step [518/735], Loss: 0.0507\n",
      "Epoch [30/50], Step [519/735], Loss: 0.0324\n",
      "Epoch [30/50], Step [520/735], Loss: 0.0696\n",
      "Epoch [30/50], Step [521/735], Loss: 0.0605\n",
      "Epoch [30/50], Step [522/735], Loss: 0.0611\n",
      "Epoch [30/50], Step [523/735], Loss: 0.0749\n",
      "Epoch [30/50], Step [524/735], Loss: 0.0225\n",
      "Epoch [30/50], Step [525/735], Loss: 0.0160\n",
      "Epoch [30/50], Step [526/735], Loss: 0.1640\n",
      "Epoch [30/50], Step [527/735], Loss: 0.0489\n",
      "Epoch [30/50], Step [528/735], Loss: 0.0239\n",
      "Epoch [30/50], Step [529/735], Loss: 0.0915\n",
      "Epoch [30/50], Step [530/735], Loss: 0.0949\n",
      "Epoch [30/50], Step [531/735], Loss: 0.0509\n",
      "Epoch [30/50], Step [532/735], Loss: 0.0264\n",
      "Epoch [30/50], Step [533/735], Loss: 0.0918\n",
      "Epoch [30/50], Step [534/735], Loss: 0.0411\n",
      "Epoch [30/50], Step [535/735], Loss: 0.0253\n",
      "Epoch [30/50], Step [536/735], Loss: 0.0845\n",
      "Epoch [30/50], Step [537/735], Loss: 0.0769\n",
      "Epoch [30/50], Step [538/735], Loss: 0.0288\n",
      "Epoch [30/50], Step [539/735], Loss: 0.0505\n",
      "Epoch [30/50], Step [540/735], Loss: 0.0527\n",
      "Epoch [30/50], Step [541/735], Loss: 0.1231\n",
      "Epoch [30/50], Step [542/735], Loss: 0.0557\n",
      "Epoch [30/50], Step [543/735], Loss: 0.0922\n",
      "Epoch [30/50], Step [544/735], Loss: 0.1289\n",
      "Epoch [30/50], Step [545/735], Loss: 0.0501\n",
      "Epoch [30/50], Step [546/735], Loss: 0.1117\n",
      "Epoch [30/50], Step [547/735], Loss: 0.0917\n",
      "Epoch [30/50], Step [548/735], Loss: 0.0484\n",
      "Epoch [30/50], Step [549/735], Loss: 0.0287\n",
      "Epoch [30/50], Step [550/735], Loss: 0.2012\n",
      "Epoch [30/50], Step [551/735], Loss: 0.0239\n",
      "Epoch [30/50], Step [552/735], Loss: 0.0288\n",
      "Epoch [30/50], Step [553/735], Loss: 0.0158\n",
      "Epoch [30/50], Step [554/735], Loss: 0.0888\n",
      "Epoch [30/50], Step [555/735], Loss: 0.0300\n",
      "Epoch [30/50], Step [556/735], Loss: 0.0829\n",
      "Epoch [30/50], Step [557/735], Loss: 0.0344\n",
      "Epoch [30/50], Step [558/735], Loss: 0.0497\n",
      "Epoch [30/50], Step [559/735], Loss: 0.0319\n",
      "Epoch [30/50], Step [560/735], Loss: 0.0529\n",
      "Epoch [30/50], Step [561/735], Loss: 0.0305\n",
      "Epoch [30/50], Step [562/735], Loss: 0.1548\n",
      "Epoch [30/50], Step [563/735], Loss: 0.0229\n",
      "Epoch [30/50], Step [564/735], Loss: 0.0272\n",
      "Epoch [30/50], Step [565/735], Loss: 0.0596\n",
      "Epoch [30/50], Step [566/735], Loss: 0.0154\n",
      "Epoch [30/50], Step [567/735], Loss: 0.0625\n",
      "Epoch [30/50], Step [568/735], Loss: 0.0449\n",
      "Epoch [30/50], Step [569/735], Loss: 0.0290\n",
      "Epoch [30/50], Step [570/735], Loss: 0.0845\n",
      "Epoch [30/50], Step [571/735], Loss: 0.0501\n",
      "Epoch [30/50], Step [572/735], Loss: 0.1233\n",
      "Epoch [30/50], Step [573/735], Loss: 0.0547\n",
      "Epoch [30/50], Step [574/735], Loss: 0.0661\n",
      "Epoch [30/50], Step [575/735], Loss: 0.0349\n",
      "Epoch [30/50], Step [576/735], Loss: 0.3441\n",
      "Epoch [30/50], Step [577/735], Loss: 0.0631\n",
      "Epoch [30/50], Step [578/735], Loss: 0.0624\n",
      "Epoch [30/50], Step [579/735], Loss: 0.0411\n",
      "Epoch [30/50], Step [580/735], Loss: 0.0530\n",
      "Epoch [30/50], Step [581/735], Loss: 0.0511\n",
      "Epoch [30/50], Step [582/735], Loss: 0.0411\n",
      "Epoch [30/50], Step [583/735], Loss: 0.0418\n",
      "Epoch [30/50], Step [584/735], Loss: 0.1364\n",
      "Epoch [30/50], Step [585/735], Loss: 0.0796\n",
      "Epoch [30/50], Step [586/735], Loss: 0.0458\n",
      "Epoch [30/50], Step [587/735], Loss: 0.2822\n",
      "Epoch [30/50], Step [588/735], Loss: 0.1838\n",
      "Epoch [30/50], Step [589/735], Loss: 0.1984\n",
      "Epoch [30/50], Step [590/735], Loss: 0.0679\n",
      "Epoch [30/50], Step [591/735], Loss: 0.0366\n",
      "Epoch [30/50], Step [592/735], Loss: 0.0405\n",
      "Epoch [30/50], Step [593/735], Loss: 0.0487\n",
      "Epoch [30/50], Step [594/735], Loss: 0.0448\n",
      "Epoch [30/50], Step [595/735], Loss: 0.0410\n",
      "Epoch [30/50], Step [596/735], Loss: 0.0377\n",
      "Epoch [30/50], Step [597/735], Loss: 0.0407\n",
      "Epoch [30/50], Step [598/735], Loss: 0.0609\n",
      "Epoch [30/50], Step [599/735], Loss: 0.0486\n",
      "Epoch [30/50], Step [600/735], Loss: 0.0329\n",
      "Epoch [30/50], Step [601/735], Loss: 0.0671\n",
      "Epoch [30/50], Step [602/735], Loss: 0.0894\n",
      "Epoch [30/50], Step [603/735], Loss: 0.0535\n",
      "Epoch [30/50], Step [604/735], Loss: 0.0238\n",
      "Epoch [30/50], Step [605/735], Loss: 0.0176\n",
      "Epoch [30/50], Step [606/735], Loss: 0.1253\n",
      "Epoch [30/50], Step [607/735], Loss: 0.0615\n",
      "Epoch [30/50], Step [608/735], Loss: 0.1209\n",
      "Epoch [30/50], Step [609/735], Loss: 0.1212\n",
      "Epoch [30/50], Step [610/735], Loss: 0.0469\n",
      "Epoch [30/50], Step [611/735], Loss: 0.1206\n",
      "Epoch [30/50], Step [612/735], Loss: 0.0836\n",
      "Epoch [30/50], Step [613/735], Loss: 0.0156\n",
      "Epoch [30/50], Step [614/735], Loss: 0.0588\n",
      "Epoch [30/50], Step [615/735], Loss: 0.2141\n",
      "Epoch [30/50], Step [616/735], Loss: 0.0402\n",
      "Epoch [30/50], Step [617/735], Loss: 0.0392\n",
      "Epoch [30/50], Step [618/735], Loss: 0.0774\n",
      "Epoch [30/50], Step [619/735], Loss: 0.1342\n",
      "Epoch [30/50], Step [620/735], Loss: 0.0448\n",
      "Epoch [30/50], Step [621/735], Loss: 0.0402\n",
      "Epoch [30/50], Step [622/735], Loss: 0.0421\n",
      "Epoch [30/50], Step [623/735], Loss: 0.0261\n",
      "Epoch [30/50], Step [624/735], Loss: 0.0275\n",
      "Epoch [30/50], Step [625/735], Loss: 0.0630\n",
      "Epoch [30/50], Step [626/735], Loss: 0.0421\n",
      "Epoch [30/50], Step [627/735], Loss: 0.0993\n",
      "Epoch [30/50], Step [628/735], Loss: 0.0518\n",
      "Epoch [30/50], Step [629/735], Loss: 0.0431\n",
      "Epoch [30/50], Step [630/735], Loss: 0.0729\n",
      "Epoch [30/50], Step [631/735], Loss: 0.0355\n",
      "Epoch [30/50], Step [632/735], Loss: 0.0588\n",
      "Epoch [30/50], Step [633/735], Loss: 0.0546\n",
      "Epoch [30/50], Step [634/735], Loss: 0.0213\n",
      "Epoch [30/50], Step [635/735], Loss: 0.2459\n",
      "Epoch [30/50], Step [636/735], Loss: 0.0290\n",
      "Epoch [30/50], Step [637/735], Loss: 0.0588\n",
      "Epoch [30/50], Step [638/735], Loss: 0.0237\n",
      "Epoch [30/50], Step [639/735], Loss: 0.0687\n",
      "Epoch [30/50], Step [640/735], Loss: 0.0681\n",
      "Epoch [30/50], Step [641/735], Loss: 0.0324\n",
      "Epoch [30/50], Step [642/735], Loss: 0.0436\n",
      "Epoch [30/50], Step [643/735], Loss: 0.0592\n",
      "Epoch [30/50], Step [644/735], Loss: 0.0682\n",
      "Epoch [30/50], Step [645/735], Loss: 0.0344\n",
      "Epoch [30/50], Step [646/735], Loss: 0.0314\n",
      "Epoch [30/50], Step [647/735], Loss: 0.0306\n",
      "Epoch [30/50], Step [648/735], Loss: 0.0382\n",
      "Epoch [30/50], Step [649/735], Loss: 0.0229\n",
      "Epoch [30/50], Step [650/735], Loss: 0.0785\n",
      "Epoch [30/50], Step [651/735], Loss: 0.0287\n",
      "Epoch [30/50], Step [652/735], Loss: 0.0593\n",
      "Epoch [30/50], Step [653/735], Loss: 0.0581\n",
      "Epoch [30/50], Step [654/735], Loss: 0.0879\n",
      "Epoch [30/50], Step [655/735], Loss: 0.0477\n",
      "Epoch [30/50], Step [656/735], Loss: 0.0576\n",
      "Epoch [30/50], Step [657/735], Loss: 0.0417\n",
      "Epoch [30/50], Step [658/735], Loss: 0.0210\n",
      "Epoch [30/50], Step [659/735], Loss: 0.0645\n",
      "Epoch [30/50], Step [660/735], Loss: 0.0294\n",
      "Epoch [30/50], Step [661/735], Loss: 0.3377\n",
      "Epoch [30/50], Step [662/735], Loss: 0.0448\n",
      "Epoch [30/50], Step [663/735], Loss: 0.0514\n",
      "Epoch [30/50], Step [664/735], Loss: 0.0914\n",
      "Epoch [30/50], Step [665/735], Loss: 0.0377\n",
      "Epoch [30/50], Step [666/735], Loss: 0.0857\n",
      "Epoch [30/50], Step [667/735], Loss: 0.1728\n",
      "Epoch [30/50], Step [668/735], Loss: 0.0459\n",
      "Epoch [30/50], Step [669/735], Loss: 0.0367\n",
      "Epoch [30/50], Step [670/735], Loss: 0.0179\n",
      "Epoch [30/50], Step [671/735], Loss: 0.0729\n",
      "Epoch [30/50], Step [672/735], Loss: 0.0701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Step [673/735], Loss: 0.0701\n",
      "Epoch [30/50], Step [674/735], Loss: 0.0580\n",
      "Epoch [30/50], Step [675/735], Loss: 0.1018\n",
      "Epoch [30/50], Step [676/735], Loss: 0.0496\n",
      "Epoch [30/50], Step [677/735], Loss: 0.3736\n",
      "Epoch [30/50], Step [678/735], Loss: 0.1504\n",
      "Epoch [30/50], Step [679/735], Loss: 0.0366\n",
      "Epoch [30/50], Step [680/735], Loss: 0.1208\n",
      "Epoch [30/50], Step [681/735], Loss: 0.0274\n",
      "Epoch [30/50], Step [682/735], Loss: 0.0518\n",
      "Epoch [30/50], Step [683/735], Loss: 0.1182\n",
      "Epoch [30/50], Step [684/735], Loss: 0.0376\n",
      "Epoch [30/50], Step [685/735], Loss: 0.0694\n",
      "Epoch [30/50], Step [686/735], Loss: 0.0280\n",
      "Epoch [30/50], Step [687/735], Loss: 0.0386\n",
      "Epoch [30/50], Step [688/735], Loss: 0.0371\n",
      "Epoch [30/50], Step [689/735], Loss: 0.0532\n",
      "Epoch [30/50], Step [690/735], Loss: 0.0539\n",
      "Epoch [30/50], Step [691/735], Loss: 0.0181\n",
      "Epoch [30/50], Step [692/735], Loss: 0.0264\n",
      "Epoch [30/50], Step [693/735], Loss: 0.0282\n",
      "Epoch [30/50], Step [694/735], Loss: 0.0330\n",
      "Epoch [30/50], Step [695/735], Loss: 0.0555\n",
      "Epoch [30/50], Step [696/735], Loss: 0.0652\n",
      "Epoch [30/50], Step [697/735], Loss: 0.0644\n",
      "Epoch [30/50], Step [698/735], Loss: 0.0167\n",
      "Epoch [30/50], Step [699/735], Loss: 0.0194\n",
      "Epoch [30/50], Step [700/735], Loss: 0.0484\n",
      "Epoch [30/50], Step [701/735], Loss: 0.3608\n",
      "Epoch [30/50], Step [702/735], Loss: 0.2619\n",
      "Epoch [30/50], Step [703/735], Loss: 0.0805\n",
      "Epoch [30/50], Step [704/735], Loss: 0.0600\n",
      "Epoch [30/50], Step [705/735], Loss: 0.0365\n",
      "Epoch [30/50], Step [706/735], Loss: 0.0184\n",
      "Epoch [30/50], Step [707/735], Loss: 0.0319\n",
      "Epoch [30/50], Step [708/735], Loss: 0.0652\n",
      "Epoch [30/50], Step [709/735], Loss: 0.0202\n",
      "Epoch [30/50], Step [710/735], Loss: 0.0922\n",
      "Epoch [30/50], Step [711/735], Loss: 0.0226\n",
      "Epoch [30/50], Step [712/735], Loss: 0.0543\n",
      "Epoch [30/50], Step [713/735], Loss: 0.0799\n",
      "Epoch [30/50], Step [714/735], Loss: 0.0752\n",
      "Epoch [30/50], Step [715/735], Loss: 0.1220\n",
      "Epoch [30/50], Step [716/735], Loss: 0.0159\n",
      "Epoch [30/50], Step [717/735], Loss: 0.1752\n",
      "Epoch [30/50], Step [718/735], Loss: 0.0171\n",
      "Epoch [30/50], Step [719/735], Loss: 0.0372\n",
      "Epoch [30/50], Step [720/735], Loss: 0.0286\n",
      "Epoch [30/50], Step [721/735], Loss: 0.0348\n",
      "Epoch [30/50], Step [722/735], Loss: 0.0626\n",
      "Epoch [30/50], Step [723/735], Loss: 0.1339\n",
      "Epoch [30/50], Step [724/735], Loss: 0.0527\n",
      "Epoch [30/50], Step [725/735], Loss: 0.0577\n",
      "Epoch [30/50], Step [726/735], Loss: 0.1118\n",
      "Epoch [30/50], Step [727/735], Loss: 0.0391\n",
      "Epoch [30/50], Step [728/735], Loss: 0.0617\n",
      "Epoch [30/50], Step [729/735], Loss: 0.0826\n",
      "Epoch [30/50], Step [730/735], Loss: 0.4305\n",
      "Epoch [30/50], Step [731/735], Loss: 0.0365\n",
      "Epoch [30/50], Step [732/735], Loss: 0.1248\n",
      "Epoch [30/50], Step [733/735], Loss: 0.0997\n",
      "Epoch [30/50], Step [734/735], Loss: 0.0626\n",
      "Epoch [30/50], Step [735/735], Loss: 0.0191\n",
      "Epoch [31/50], Step [1/735], Loss: 0.0379\n",
      "Epoch [31/50], Step [2/735], Loss: 0.2921\n",
      "Epoch [31/50], Step [3/735], Loss: 0.0266\n",
      "Epoch [31/50], Step [4/735], Loss: 0.1476\n",
      "Epoch [31/50], Step [5/735], Loss: 0.0906\n",
      "Epoch [31/50], Step [6/735], Loss: 0.0549\n",
      "Epoch [31/50], Step [7/735], Loss: 0.0759\n",
      "Epoch [31/50], Step [8/735], Loss: 0.3410\n",
      "Epoch [31/50], Step [9/735], Loss: 0.0681\n",
      "Epoch [31/50], Step [10/735], Loss: 0.0409\n",
      "Epoch [31/50], Step [11/735], Loss: 0.1146\n",
      "Epoch [31/50], Step [12/735], Loss: 0.0994\n",
      "Epoch [31/50], Step [13/735], Loss: 0.0516\n",
      "Epoch [31/50], Step [14/735], Loss: 0.0676\n",
      "Epoch [31/50], Step [15/735], Loss: 0.1177\n",
      "Epoch [31/50], Step [16/735], Loss: 0.0991\n",
      "Epoch [31/50], Step [17/735], Loss: 0.0730\n",
      "Epoch [31/50], Step [18/735], Loss: 0.2629\n",
      "Epoch [31/50], Step [19/735], Loss: 0.1690\n",
      "Epoch [31/50], Step [20/735], Loss: 0.0399\n",
      "Epoch [31/50], Step [21/735], Loss: 0.0680\n",
      "Epoch [31/50], Step [22/735], Loss: 0.0532\n",
      "Epoch [31/50], Step [23/735], Loss: 0.0578\n",
      "Epoch [31/50], Step [24/735], Loss: 0.0572\n",
      "Epoch [31/50], Step [25/735], Loss: 0.2885\n",
      "Epoch [31/50], Step [26/735], Loss: 0.1080\n",
      "Epoch [31/50], Step [27/735], Loss: 0.0437\n",
      "Epoch [31/50], Step [28/735], Loss: 0.0622\n",
      "Epoch [31/50], Step [29/735], Loss: 0.1628\n",
      "Epoch [31/50], Step [30/735], Loss: 0.0217\n",
      "Epoch [31/50], Step [31/735], Loss: 0.2598\n",
      "Epoch [31/50], Step [32/735], Loss: 0.2889\n",
      "Epoch [31/50], Step [33/735], Loss: 0.0961\n",
      "Epoch [31/50], Step [34/735], Loss: 0.0805\n",
      "Epoch [31/50], Step [35/735], Loss: 0.0401\n",
      "Epoch [31/50], Step [36/735], Loss: 0.0354\n",
      "Epoch [31/50], Step [37/735], Loss: 0.0611\n",
      "Epoch [31/50], Step [38/735], Loss: 0.0719\n",
      "Epoch [31/50], Step [39/735], Loss: 0.1285\n",
      "Epoch [31/50], Step [40/735], Loss: 0.0643\n",
      "Epoch [31/50], Step [41/735], Loss: 0.0841\n",
      "Epoch [31/50], Step [42/735], Loss: 0.0815\n",
      "Epoch [31/50], Step [43/735], Loss: 0.1662\n",
      "Epoch [31/50], Step [44/735], Loss: 0.0280\n",
      "Epoch [31/50], Step [45/735], Loss: 0.0327\n",
      "Epoch [31/50], Step [46/735], Loss: 0.0223\n",
      "Epoch [31/50], Step [47/735], Loss: 0.0959\n",
      "Epoch [31/50], Step [48/735], Loss: 0.0315\n",
      "Epoch [31/50], Step [49/735], Loss: 0.0233\n",
      "Epoch [31/50], Step [50/735], Loss: 0.0853\n",
      "Epoch [31/50], Step [51/735], Loss: 0.1260\n",
      "Epoch [31/50], Step [52/735], Loss: 0.0464\n",
      "Epoch [31/50], Step [53/735], Loss: 0.2434\n",
      "Epoch [31/50], Step [54/735], Loss: 0.0224\n",
      "Epoch [31/50], Step [55/735], Loss: 0.0561\n",
      "Epoch [31/50], Step [56/735], Loss: 0.0205\n",
      "Epoch [31/50], Step [57/735], Loss: 0.0442\n",
      "Epoch [31/50], Step [58/735], Loss: 0.0335\n",
      "Epoch [31/50], Step [59/735], Loss: 0.0364\n",
      "Epoch [31/50], Step [60/735], Loss: 0.1296\n",
      "Epoch [31/50], Step [61/735], Loss: 0.1225\n",
      "Epoch [31/50], Step [62/735], Loss: 0.0574\n",
      "Epoch [31/50], Step [63/735], Loss: 0.0307\n",
      "Epoch [31/50], Step [64/735], Loss: 0.0267\n",
      "Epoch [31/50], Step [65/735], Loss: 0.0559\n",
      "Epoch [31/50], Step [66/735], Loss: 0.1965\n",
      "Epoch [31/50], Step [67/735], Loss: 0.0297\n",
      "Epoch [31/50], Step [68/735], Loss: 0.0298\n",
      "Epoch [31/50], Step [69/735], Loss: 0.0843\n",
      "Epoch [31/50], Step [70/735], Loss: 0.0546\n",
      "Epoch [31/50], Step [71/735], Loss: 0.0871\n",
      "Epoch [31/50], Step [72/735], Loss: 0.0461\n",
      "Epoch [31/50], Step [73/735], Loss: 0.0292\n",
      "Epoch [31/50], Step [74/735], Loss: 0.0499\n",
      "Epoch [31/50], Step [75/735], Loss: 0.0525\n",
      "Epoch [31/50], Step [76/735], Loss: 0.1522\n",
      "Epoch [31/50], Step [77/735], Loss: 0.0257\n",
      "Epoch [31/50], Step [78/735], Loss: 0.0227\n",
      "Epoch [31/50], Step [79/735], Loss: 0.1507\n",
      "Epoch [31/50], Step [80/735], Loss: 0.0578\n",
      "Epoch [31/50], Step [81/735], Loss: 0.0348\n",
      "Epoch [31/50], Step [82/735], Loss: 0.0618\n",
      "Epoch [31/50], Step [83/735], Loss: 0.0417\n",
      "Epoch [31/50], Step [84/735], Loss: 0.0404\n",
      "Epoch [31/50], Step [85/735], Loss: 0.0667\n",
      "Epoch [31/50], Step [86/735], Loss: 0.0664\n",
      "Epoch [31/50], Step [87/735], Loss: 0.0557\n",
      "Epoch [31/50], Step [88/735], Loss: 0.0287\n",
      "Epoch [31/50], Step [89/735], Loss: 0.0289\n",
      "Epoch [31/50], Step [90/735], Loss: 0.0224\n",
      "Epoch [31/50], Step [91/735], Loss: 0.0649\n",
      "Epoch [31/50], Step [92/735], Loss: 0.0435\n",
      "Epoch [31/50], Step [93/735], Loss: 0.0501\n",
      "Epoch [31/50], Step [94/735], Loss: 0.0492\n",
      "Epoch [31/50], Step [95/735], Loss: 0.0339\n",
      "Epoch [31/50], Step [96/735], Loss: 0.0458\n",
      "Epoch [31/50], Step [97/735], Loss: 0.0445\n",
      "Epoch [31/50], Step [98/735], Loss: 0.0672\n",
      "Epoch [31/50], Step [99/735], Loss: 0.0858\n",
      "Epoch [31/50], Step [100/735], Loss: 0.0471\n",
      "Epoch [31/50], Step [101/735], Loss: 0.0395\n",
      "Epoch [31/50], Step [102/735], Loss: 0.0326\n",
      "Epoch [31/50], Step [103/735], Loss: 0.0494\n",
      "Epoch [31/50], Step [104/735], Loss: 0.0331\n",
      "Epoch [31/50], Step [105/735], Loss: 0.0890\n",
      "Epoch [31/50], Step [106/735], Loss: 0.0934\n",
      "Epoch [31/50], Step [107/735], Loss: 0.1579\n",
      "Epoch [31/50], Step [108/735], Loss: 0.2114\n",
      "Epoch [31/50], Step [109/735], Loss: 0.0410\n",
      "Epoch [31/50], Step [110/735], Loss: 0.3846\n",
      "Epoch [31/50], Step [111/735], Loss: 0.0526\n",
      "Epoch [31/50], Step [112/735], Loss: 0.0380\n",
      "Epoch [31/50], Step [113/735], Loss: 0.0271\n",
      "Epoch [31/50], Step [114/735], Loss: 0.0337\n",
      "Epoch [31/50], Step [115/735], Loss: 0.0712\n",
      "Epoch [31/50], Step [116/735], Loss: 0.0580\n",
      "Epoch [31/50], Step [117/735], Loss: 0.0259\n",
      "Epoch [31/50], Step [118/735], Loss: 0.0251\n",
      "Epoch [31/50], Step [119/735], Loss: 0.0344\n",
      "Epoch [31/50], Step [120/735], Loss: 0.0648\n",
      "Epoch [31/50], Step [121/735], Loss: 0.1033\n",
      "Epoch [31/50], Step [122/735], Loss: 0.2432\n",
      "Epoch [31/50], Step [123/735], Loss: 0.0262\n",
      "Epoch [31/50], Step [124/735], Loss: 0.1170\n",
      "Epoch [31/50], Step [125/735], Loss: 0.0947\n",
      "Epoch [31/50], Step [126/735], Loss: 0.1174\n",
      "Epoch [31/50], Step [127/735], Loss: 0.0186\n",
      "Epoch [31/50], Step [128/735], Loss: 0.0566\n",
      "Epoch [31/50], Step [129/735], Loss: 0.0949\n",
      "Epoch [31/50], Step [130/735], Loss: 0.0631\n",
      "Epoch [31/50], Step [131/735], Loss: 0.0154\n",
      "Epoch [31/50], Step [132/735], Loss: 0.1873\n",
      "Epoch [31/50], Step [133/735], Loss: 0.0179\n",
      "Epoch [31/50], Step [134/735], Loss: 0.0269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Step [135/735], Loss: 0.0735\n",
      "Epoch [31/50], Step [136/735], Loss: 0.0449\n",
      "Epoch [31/50], Step [137/735], Loss: 0.0501\n",
      "Epoch [31/50], Step [138/735], Loss: 0.0405\n",
      "Epoch [31/50], Step [139/735], Loss: 0.0286\n",
      "Epoch [31/50], Step [140/735], Loss: 0.0547\n",
      "Epoch [31/50], Step [141/735], Loss: 0.1287\n",
      "Epoch [31/50], Step [142/735], Loss: 0.0347\n",
      "Epoch [31/50], Step [143/735], Loss: 0.0221\n",
      "Epoch [31/50], Step [144/735], Loss: 0.0295\n",
      "Epoch [31/50], Step [145/735], Loss: 0.0787\n",
      "Epoch [31/50], Step [146/735], Loss: 0.0875\n",
      "Epoch [31/50], Step [147/735], Loss: 0.0382\n",
      "Epoch [31/50], Step [148/735], Loss: 0.1530\n",
      "Epoch [31/50], Step [149/735], Loss: 0.1168\n",
      "Epoch [31/50], Step [150/735], Loss: 0.0244\n",
      "Epoch [31/50], Step [151/735], Loss: 0.0437\n",
      "Epoch [31/50], Step [152/735], Loss: 0.0711\n",
      "Epoch [31/50], Step [153/735], Loss: 0.0278\n",
      "Epoch [31/50], Step [154/735], Loss: 0.0263\n",
      "Epoch [31/50], Step [155/735], Loss: 0.0344\n",
      "Epoch [31/50], Step [156/735], Loss: 0.0149\n",
      "Epoch [31/50], Step [157/735], Loss: 0.0288\n",
      "Epoch [31/50], Step [158/735], Loss: 0.0495\n",
      "Epoch [31/50], Step [159/735], Loss: 0.0608\n",
      "Epoch [31/50], Step [160/735], Loss: 0.1181\n",
      "Epoch [31/50], Step [161/735], Loss: 0.1962\n",
      "Epoch [31/50], Step [162/735], Loss: 0.0774\n",
      "Epoch [31/50], Step [163/735], Loss: 0.1916\n",
      "Epoch [31/50], Step [164/735], Loss: 0.0399\n",
      "Epoch [31/50], Step [165/735], Loss: 0.0366\n",
      "Epoch [31/50], Step [166/735], Loss: 0.1381\n",
      "Epoch [31/50], Step [167/735], Loss: 0.1656\n",
      "Epoch [31/50], Step [168/735], Loss: 0.1052\n",
      "Epoch [31/50], Step [169/735], Loss: 0.0346\n",
      "Epoch [31/50], Step [170/735], Loss: 0.0322\n",
      "Epoch [31/50], Step [171/735], Loss: 0.0464\n",
      "Epoch [31/50], Step [172/735], Loss: 0.1509\n",
      "Epoch [31/50], Step [173/735], Loss: 0.0729\n",
      "Epoch [31/50], Step [174/735], Loss: 0.1110\n",
      "Epoch [31/50], Step [175/735], Loss: 0.0766\n",
      "Epoch [31/50], Step [176/735], Loss: 0.0981\n",
      "Epoch [31/50], Step [177/735], Loss: 0.0953\n",
      "Epoch [31/50], Step [178/735], Loss: 0.0989\n",
      "Epoch [31/50], Step [179/735], Loss: 0.0780\n",
      "Epoch [31/50], Step [180/735], Loss: 0.0728\n",
      "Epoch [31/50], Step [181/735], Loss: 0.1911\n",
      "Epoch [31/50], Step [182/735], Loss: 0.0217\n",
      "Epoch [31/50], Step [183/735], Loss: 0.0529\n",
      "Epoch [31/50], Step [184/735], Loss: 0.0938\n",
      "Epoch [31/50], Step [185/735], Loss: 0.0608\n",
      "Epoch [31/50], Step [186/735], Loss: 0.0620\n",
      "Epoch [31/50], Step [187/735], Loss: 0.0399\n",
      "Epoch [31/50], Step [188/735], Loss: 0.0301\n",
      "Epoch [31/50], Step [189/735], Loss: 0.0344\n",
      "Epoch [31/50], Step [190/735], Loss: 0.0399\n",
      "Epoch [31/50], Step [191/735], Loss: 0.1225\n",
      "Epoch [31/50], Step [192/735], Loss: 0.0286\n",
      "Epoch [31/50], Step [193/735], Loss: 0.1261\n",
      "Epoch [31/50], Step [194/735], Loss: 0.2633\n",
      "Epoch [31/50], Step [195/735], Loss: 0.0520\n",
      "Epoch [31/50], Step [196/735], Loss: 0.0991\n",
      "Epoch [31/50], Step [197/735], Loss: 0.1021\n",
      "Epoch [31/50], Step [198/735], Loss: 0.0307\n",
      "Epoch [31/50], Step [199/735], Loss: 0.2374\n",
      "Epoch [31/50], Step [200/735], Loss: 0.1414\n",
      "Epoch [31/50], Step [201/735], Loss: 0.0399\n",
      "Epoch [31/50], Step [202/735], Loss: 0.0457\n",
      "Epoch [31/50], Step [203/735], Loss: 0.0573\n",
      "Epoch [31/50], Step [204/735], Loss: 0.0602\n",
      "Epoch [31/50], Step [205/735], Loss: 0.0585\n",
      "Epoch [31/50], Step [206/735], Loss: 0.1620\n",
      "Epoch [31/50], Step [207/735], Loss: 0.0439\n",
      "Epoch [31/50], Step [208/735], Loss: 0.0542\n",
      "Epoch [31/50], Step [209/735], Loss: 0.0688\n",
      "Epoch [31/50], Step [210/735], Loss: 0.1343\n",
      "Epoch [31/50], Step [211/735], Loss: 0.0670\n",
      "Epoch [31/50], Step [212/735], Loss: 0.0315\n",
      "Epoch [31/50], Step [213/735], Loss: 0.0439\n",
      "Epoch [31/50], Step [214/735], Loss: 0.0526\n",
      "Epoch [31/50], Step [215/735], Loss: 0.1083\n",
      "Epoch [31/50], Step [216/735], Loss: 0.1029\n",
      "Epoch [31/50], Step [217/735], Loss: 0.0287\n",
      "Epoch [31/50], Step [218/735], Loss: 0.1966\n",
      "Epoch [31/50], Step [219/735], Loss: 0.0530\n",
      "Epoch [31/50], Step [220/735], Loss: 0.1145\n",
      "Epoch [31/50], Step [221/735], Loss: 0.3542\n",
      "Epoch [31/50], Step [222/735], Loss: 0.1062\n",
      "Epoch [31/50], Step [223/735], Loss: 0.0487\n",
      "Epoch [31/50], Step [224/735], Loss: 0.4248\n",
      "Epoch [31/50], Step [225/735], Loss: 0.0412\n",
      "Epoch [31/50], Step [226/735], Loss: 0.1077\n",
      "Epoch [31/50], Step [227/735], Loss: 0.0838\n",
      "Epoch [31/50], Step [228/735], Loss: 0.0769\n",
      "Epoch [31/50], Step [229/735], Loss: 0.0643\n",
      "Epoch [31/50], Step [230/735], Loss: 0.0479\n",
      "Epoch [31/50], Step [231/735], Loss: 0.0458\n",
      "Epoch [31/50], Step [232/735], Loss: 0.0647\n",
      "Epoch [31/50], Step [233/735], Loss: 0.0502\n",
      "Epoch [31/50], Step [234/735], Loss: 0.0553\n",
      "Epoch [31/50], Step [235/735], Loss: 0.0647\n",
      "Epoch [31/50], Step [236/735], Loss: 0.0457\n",
      "Epoch [31/50], Step [237/735], Loss: 0.0590\n",
      "Epoch [31/50], Step [238/735], Loss: 0.0526\n",
      "Epoch [31/50], Step [239/735], Loss: 0.0864\n",
      "Epoch [31/50], Step [240/735], Loss: 0.0439\n",
      "Epoch [31/50], Step [241/735], Loss: 0.0245\n",
      "Epoch [31/50], Step [242/735], Loss: 0.0219\n",
      "Epoch [31/50], Step [243/735], Loss: 0.1206\n",
      "Epoch [31/50], Step [244/735], Loss: 0.0478\n",
      "Epoch [31/50], Step [245/735], Loss: 0.0344\n",
      "Epoch [31/50], Step [246/735], Loss: 0.0765\n",
      "Epoch [31/50], Step [247/735], Loss: 0.1056\n",
      "Epoch [31/50], Step [248/735], Loss: 0.0972\n",
      "Epoch [31/50], Step [249/735], Loss: 0.0284\n",
      "Epoch [31/50], Step [250/735], Loss: 0.0395\n",
      "Epoch [31/50], Step [251/735], Loss: 0.0531\n",
      "Epoch [31/50], Step [252/735], Loss: 0.0248\n",
      "Epoch [31/50], Step [253/735], Loss: 0.0556\n",
      "Epoch [31/50], Step [254/735], Loss: 0.1188\n",
      "Epoch [31/50], Step [255/735], Loss: 0.0419\n",
      "Epoch [31/50], Step [256/735], Loss: 0.1048\n",
      "Epoch [31/50], Step [257/735], Loss: 0.0357\n",
      "Epoch [31/50], Step [258/735], Loss: 0.0336\n",
      "Epoch [31/50], Step [259/735], Loss: 0.0236\n",
      "Epoch [31/50], Step [260/735], Loss: 0.1027\n",
      "Epoch [31/50], Step [261/735], Loss: 0.0284\n",
      "Epoch [31/50], Step [262/735], Loss: 0.0414\n",
      "Epoch [31/50], Step [263/735], Loss: 0.0656\n",
      "Epoch [31/50], Step [264/735], Loss: 0.0271\n",
      "Epoch [31/50], Step [265/735], Loss: 0.0552\n",
      "Epoch [31/50], Step [266/735], Loss: 0.0254\n",
      "Epoch [31/50], Step [267/735], Loss: 0.0546\n",
      "Epoch [31/50], Step [268/735], Loss: 0.0656\n",
      "Epoch [31/50], Step [269/735], Loss: 0.0634\n",
      "Epoch [31/50], Step [270/735], Loss: 0.0456\n",
      "Epoch [31/50], Step [271/735], Loss: 0.1543\n",
      "Epoch [31/50], Step [272/735], Loss: 0.1112\n",
      "Epoch [31/50], Step [273/735], Loss: 0.1308\n",
      "Epoch [31/50], Step [274/735], Loss: 0.0511\n",
      "Epoch [31/50], Step [275/735], Loss: 0.0331\n",
      "Epoch [31/50], Step [276/735], Loss: 0.1570\n",
      "Epoch [31/50], Step [277/735], Loss: 0.0395\n",
      "Epoch [31/50], Step [278/735], Loss: 0.0456\n",
      "Epoch [31/50], Step [279/735], Loss: 0.0392\n",
      "Epoch [31/50], Step [280/735], Loss: 0.0923\n",
      "Epoch [31/50], Step [281/735], Loss: 0.1336\n",
      "Epoch [31/50], Step [282/735], Loss: 0.0520\n",
      "Epoch [31/50], Step [283/735], Loss: 0.0190\n",
      "Epoch [31/50], Step [284/735], Loss: 0.0136\n",
      "Epoch [31/50], Step [285/735], Loss: 0.0468\n",
      "Epoch [31/50], Step [286/735], Loss: 0.0219\n",
      "Epoch [31/50], Step [287/735], Loss: 0.2428\n",
      "Epoch [31/50], Step [288/735], Loss: 0.1941\n",
      "Epoch [31/50], Step [289/735], Loss: 0.1700\n",
      "Epoch [31/50], Step [290/735], Loss: 0.0430\n",
      "Epoch [31/50], Step [291/735], Loss: 0.0730\n",
      "Epoch [31/50], Step [292/735], Loss: 0.0488\n",
      "Epoch [31/50], Step [293/735], Loss: 0.0525\n",
      "Epoch [31/50], Step [294/735], Loss: 0.0462\n",
      "Epoch [31/50], Step [295/735], Loss: 0.0394\n",
      "Epoch [31/50], Step [296/735], Loss: 0.1266\n",
      "Epoch [31/50], Step [297/735], Loss: 0.0848\n",
      "Epoch [31/50], Step [298/735], Loss: 0.0528\n",
      "Epoch [31/50], Step [299/735], Loss: 0.1489\n",
      "Epoch [31/50], Step [300/735], Loss: 0.2024\n",
      "Epoch [31/50], Step [301/735], Loss: 0.3282\n",
      "Epoch [31/50], Step [302/735], Loss: 0.0610\n",
      "Epoch [31/50], Step [303/735], Loss: 0.0546\n",
      "Epoch [31/50], Step [304/735], Loss: 0.1081\n",
      "Epoch [31/50], Step [305/735], Loss: 0.0838\n",
      "Epoch [31/50], Step [306/735], Loss: 0.0885\n",
      "Epoch [31/50], Step [307/735], Loss: 0.2179\n",
      "Epoch [31/50], Step [308/735], Loss: 0.0315\n",
      "Epoch [31/50], Step [309/735], Loss: 0.1110\n",
      "Epoch [31/50], Step [310/735], Loss: 0.2578\n",
      "Epoch [31/50], Step [311/735], Loss: 0.1245\n",
      "Epoch [31/50], Step [312/735], Loss: 0.1709\n",
      "Epoch [31/50], Step [313/735], Loss: 0.0426\n",
      "Epoch [31/50], Step [314/735], Loss: 0.0469\n",
      "Epoch [31/50], Step [315/735], Loss: 0.0526\n",
      "Epoch [31/50], Step [316/735], Loss: 0.1050\n",
      "Epoch [31/50], Step [317/735], Loss: 0.0560\n",
      "Epoch [31/50], Step [318/735], Loss: 0.0890\n",
      "Epoch [31/50], Step [319/735], Loss: 0.0760\n",
      "Epoch [31/50], Step [320/735], Loss: 0.0506\n",
      "Epoch [31/50], Step [321/735], Loss: 0.0509\n",
      "Epoch [31/50], Step [322/735], Loss: 0.0204\n",
      "Epoch [31/50], Step [323/735], Loss: 0.0864\n",
      "Epoch [31/50], Step [324/735], Loss: 0.0794\n",
      "Epoch [31/50], Step [325/735], Loss: 0.0451\n",
      "Epoch [31/50], Step [326/735], Loss: 0.0570\n",
      "Epoch [31/50], Step [327/735], Loss: 0.0981\n",
      "Epoch [31/50], Step [328/735], Loss: 0.1206\n",
      "Epoch [31/50], Step [329/735], Loss: 0.0427\n",
      "Epoch [31/50], Step [330/735], Loss: 0.0312\n",
      "Epoch [31/50], Step [331/735], Loss: 0.0564\n",
      "Epoch [31/50], Step [332/735], Loss: 0.0604\n",
      "Epoch [31/50], Step [333/735], Loss: 0.0767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Step [334/735], Loss: 0.1273\n",
      "Epoch [31/50], Step [335/735], Loss: 0.0347\n",
      "Epoch [31/50], Step [336/735], Loss: 0.0647\n",
      "Epoch [31/50], Step [337/735], Loss: 0.0591\n",
      "Epoch [31/50], Step [338/735], Loss: 0.0399\n",
      "Epoch [31/50], Step [339/735], Loss: 0.0694\n",
      "Epoch [31/50], Step [340/735], Loss: 0.0407\n",
      "Epoch [31/50], Step [341/735], Loss: 0.0894\n",
      "Epoch [31/50], Step [342/735], Loss: 0.0294\n",
      "Epoch [31/50], Step [343/735], Loss: 0.0443\n",
      "Epoch [31/50], Step [344/735], Loss: 0.0725\n",
      "Epoch [31/50], Step [345/735], Loss: 0.1022\n",
      "Epoch [31/50], Step [346/735], Loss: 0.1165\n",
      "Epoch [31/50], Step [347/735], Loss: 0.0755\n",
      "Epoch [31/50], Step [348/735], Loss: 0.1480\n",
      "Epoch [31/50], Step [349/735], Loss: 0.0877\n",
      "Epoch [31/50], Step [350/735], Loss: 0.0389\n",
      "Epoch [31/50], Step [351/735], Loss: 0.1285\n",
      "Epoch [31/50], Step [352/735], Loss: 0.0269\n",
      "Epoch [31/50], Step [353/735], Loss: 0.1215\n",
      "Epoch [31/50], Step [354/735], Loss: 0.1152\n",
      "Epoch [31/50], Step [355/735], Loss: 0.0589\n",
      "Epoch [31/50], Step [356/735], Loss: 0.1064\n",
      "Epoch [31/50], Step [357/735], Loss: 0.1338\n",
      "Epoch [31/50], Step [358/735], Loss: 0.0364\n",
      "Epoch [31/50], Step [359/735], Loss: 0.0427\n",
      "Epoch [31/50], Step [360/735], Loss: 0.1155\n",
      "Epoch [31/50], Step [361/735], Loss: 0.0386\n",
      "Epoch [31/50], Step [362/735], Loss: 0.0363\n",
      "Epoch [31/50], Step [363/735], Loss: 0.0465\n",
      "Epoch [31/50], Step [364/735], Loss: 0.0680\n",
      "Epoch [31/50], Step [365/735], Loss: 0.0919\n",
      "Epoch [31/50], Step [366/735], Loss: 0.3117\n",
      "Epoch [31/50], Step [367/735], Loss: 0.1075\n",
      "Epoch [31/50], Step [368/735], Loss: 0.0580\n",
      "Epoch [31/50], Step [369/735], Loss: 0.0505\n",
      "Epoch [31/50], Step [370/735], Loss: 0.0488\n",
      "Epoch [31/50], Step [371/735], Loss: 0.0336\n",
      "Epoch [31/50], Step [372/735], Loss: 0.0969\n",
      "Epoch [31/50], Step [373/735], Loss: 0.0783\n",
      "Epoch [31/50], Step [374/735], Loss: 0.1254\n",
      "Epoch [31/50], Step [375/735], Loss: 0.1093\n",
      "Epoch [31/50], Step [376/735], Loss: 0.0417\n",
      "Epoch [31/50], Step [377/735], Loss: 0.1121\n",
      "Epoch [31/50], Step [378/735], Loss: 0.0482\n",
      "Epoch [31/50], Step [379/735], Loss: 0.0266\n",
      "Epoch [31/50], Step [380/735], Loss: 0.0711\n",
      "Epoch [31/50], Step [381/735], Loss: 0.0537\n",
      "Epoch [31/50], Step [382/735], Loss: 0.0371\n",
      "Epoch [31/50], Step [383/735], Loss: 0.2236\n",
      "Epoch [31/50], Step [384/735], Loss: 0.1008\n",
      "Epoch [31/50], Step [385/735], Loss: 0.0738\n",
      "Epoch [31/50], Step [386/735], Loss: 0.0756\n",
      "Epoch [31/50], Step [387/735], Loss: 0.0392\n",
      "Epoch [31/50], Step [388/735], Loss: 0.0445\n",
      "Epoch [31/50], Step [389/735], Loss: 0.0810\n",
      "Epoch [31/50], Step [390/735], Loss: 0.3045\n",
      "Epoch [31/50], Step [391/735], Loss: 0.0775\n",
      "Epoch [31/50], Step [392/735], Loss: 0.0904\n",
      "Epoch [31/50], Step [393/735], Loss: 0.0992\n",
      "Epoch [31/50], Step [394/735], Loss: 0.0332\n",
      "Epoch [31/50], Step [395/735], Loss: 0.0714\n",
      "Epoch [31/50], Step [396/735], Loss: 0.0720\n",
      "Epoch [31/50], Step [397/735], Loss: 0.0938\n",
      "Epoch [31/50], Step [398/735], Loss: 0.0912\n",
      "Epoch [31/50], Step [399/735], Loss: 0.3415\n",
      "Epoch [31/50], Step [400/735], Loss: 0.0546\n",
      "Epoch [31/50], Step [401/735], Loss: 0.0711\n",
      "Epoch [31/50], Step [402/735], Loss: 0.0390\n",
      "Epoch [31/50], Step [403/735], Loss: 0.0383\n",
      "Epoch [31/50], Step [404/735], Loss: 0.1010\n",
      "Epoch [31/50], Step [405/735], Loss: 0.0752\n",
      "Epoch [31/50], Step [406/735], Loss: 0.0306\n",
      "Epoch [31/50], Step [407/735], Loss: 0.0474\n",
      "Epoch [31/50], Step [408/735], Loss: 0.0438\n",
      "Epoch [31/50], Step [409/735], Loss: 0.0663\n",
      "Epoch [31/50], Step [410/735], Loss: 0.1051\n",
      "Epoch [31/50], Step [411/735], Loss: 0.1355\n",
      "Epoch [31/50], Step [412/735], Loss: 0.0363\n",
      "Epoch [31/50], Step [413/735], Loss: 0.0956\n",
      "Epoch [31/50], Step [414/735], Loss: 0.0341\n",
      "Epoch [31/50], Step [415/735], Loss: 0.0394\n",
      "Epoch [31/50], Step [416/735], Loss: 0.0733\n",
      "Epoch [31/50], Step [417/735], Loss: 0.0916\n",
      "Epoch [31/50], Step [418/735], Loss: 0.0756\n",
      "Epoch [31/50], Step [419/735], Loss: 0.0622\n",
      "Epoch [31/50], Step [420/735], Loss: 0.1132\n",
      "Epoch [31/50], Step [421/735], Loss: 0.0439\n",
      "Epoch [31/50], Step [422/735], Loss: 0.0426\n",
      "Epoch [31/50], Step [423/735], Loss: 0.1083\n",
      "Epoch [31/50], Step [424/735], Loss: 0.0196\n",
      "Epoch [31/50], Step [425/735], Loss: 0.1227\n",
      "Epoch [31/50], Step [426/735], Loss: 0.0592\n",
      "Epoch [31/50], Step [427/735], Loss: 0.1564\n",
      "Epoch [31/50], Step [428/735], Loss: 0.0976\n",
      "Epoch [31/50], Step [429/735], Loss: 0.0871\n",
      "Epoch [31/50], Step [430/735], Loss: 0.1019\n",
      "Epoch [31/50], Step [431/735], Loss: 0.1615\n",
      "Epoch [31/50], Step [432/735], Loss: 0.3079\n",
      "Epoch [31/50], Step [433/735], Loss: 0.0211\n",
      "Epoch [31/50], Step [434/735], Loss: 0.0700\n",
      "Epoch [31/50], Step [435/735], Loss: 0.2238\n",
      "Epoch [31/50], Step [436/735], Loss: 0.0279\n",
      "Epoch [31/50], Step [437/735], Loss: 0.0904\n",
      "Epoch [31/50], Step [438/735], Loss: 0.0230\n",
      "Epoch [31/50], Step [439/735], Loss: 0.0495\n",
      "Epoch [31/50], Step [440/735], Loss: 0.0355\n",
      "Epoch [31/50], Step [441/735], Loss: 0.0346\n",
      "Epoch [31/50], Step [442/735], Loss: 0.2790\n",
      "Epoch [31/50], Step [443/735], Loss: 0.2002\n",
      "Epoch [31/50], Step [444/735], Loss: 0.0652\n",
      "Epoch [31/50], Step [445/735], Loss: 0.0809\n",
      "Epoch [31/50], Step [446/735], Loss: 0.0515\n",
      "Epoch [31/50], Step [447/735], Loss: 0.0946\n",
      "Epoch [31/50], Step [448/735], Loss: 0.0349\n",
      "Epoch [31/50], Step [449/735], Loss: 0.0998\n",
      "Epoch [31/50], Step [450/735], Loss: 0.0698\n",
      "Epoch [31/50], Step [451/735], Loss: 0.0411\n",
      "Epoch [31/50], Step [452/735], Loss: 0.0680\n",
      "Epoch [31/50], Step [453/735], Loss: 0.0450\n",
      "Epoch [31/50], Step [454/735], Loss: 0.0800\n",
      "Epoch [31/50], Step [455/735], Loss: 0.0546\n",
      "Epoch [31/50], Step [456/735], Loss: 0.0407\n",
      "Epoch [31/50], Step [457/735], Loss: 0.3706\n",
      "Epoch [31/50], Step [458/735], Loss: 0.0619\n",
      "Epoch [31/50], Step [459/735], Loss: 0.0151\n",
      "Epoch [31/50], Step [460/735], Loss: 0.2884\n",
      "Epoch [31/50], Step [461/735], Loss: 0.0260\n",
      "Epoch [31/50], Step [462/735], Loss: 0.0964\n",
      "Epoch [31/50], Step [463/735], Loss: 0.0335\n",
      "Epoch [31/50], Step [464/735], Loss: 0.0381\n",
      "Epoch [31/50], Step [465/735], Loss: 0.0805\n",
      "Epoch [31/50], Step [466/735], Loss: 0.0723\n",
      "Epoch [31/50], Step [467/735], Loss: 0.0312\n",
      "Epoch [31/50], Step [468/735], Loss: 0.0914\n",
      "Epoch [31/50], Step [469/735], Loss: 0.0518\n",
      "Epoch [31/50], Step [470/735], Loss: 0.0302\n",
      "Epoch [31/50], Step [471/735], Loss: 0.0440\n",
      "Epoch [31/50], Step [472/735], Loss: 0.0255\n",
      "Epoch [31/50], Step [473/735], Loss: 0.0822\n",
      "Epoch [31/50], Step [474/735], Loss: 0.0363\n",
      "Epoch [31/50], Step [475/735], Loss: 0.0396\n",
      "Epoch [31/50], Step [476/735], Loss: 0.0267\n",
      "Epoch [31/50], Step [477/735], Loss: 0.0185\n",
      "Epoch [31/50], Step [478/735], Loss: 0.1469\n",
      "Epoch [31/50], Step [479/735], Loss: 0.0226\n",
      "Epoch [31/50], Step [480/735], Loss: 0.0559\n",
      "Epoch [31/50], Step [481/735], Loss: 0.1133\n",
      "Epoch [31/50], Step [482/735], Loss: 0.0679\n",
      "Epoch [31/50], Step [483/735], Loss: 0.0316\n",
      "Epoch [31/50], Step [484/735], Loss: 0.1933\n",
      "Epoch [31/50], Step [485/735], Loss: 0.0832\n",
      "Epoch [31/50], Step [486/735], Loss: 0.0468\n",
      "Epoch [31/50], Step [487/735], Loss: 0.1021\n",
      "Epoch [31/50], Step [488/735], Loss: 0.0545\n",
      "Epoch [31/50], Step [489/735], Loss: 0.0731\n",
      "Epoch [31/50], Step [490/735], Loss: 0.0446\n",
      "Epoch [31/50], Step [491/735], Loss: 0.0602\n",
      "Epoch [31/50], Step [492/735], Loss: 0.0458\n",
      "Epoch [31/50], Step [493/735], Loss: 0.0483\n",
      "Epoch [31/50], Step [494/735], Loss: 0.0767\n",
      "Epoch [31/50], Step [495/735], Loss: 0.2937\n",
      "Epoch [31/50], Step [496/735], Loss: 0.0800\n",
      "Epoch [31/50], Step [497/735], Loss: 0.0423\n",
      "Epoch [31/50], Step [498/735], Loss: 0.0610\n",
      "Epoch [31/50], Step [499/735], Loss: 0.0314\n",
      "Epoch [31/50], Step [500/735], Loss: 0.0416\n",
      "Epoch [31/50], Step [501/735], Loss: 0.0371\n",
      "Epoch [31/50], Step [502/735], Loss: 0.1603\n",
      "Epoch [31/50], Step [503/735], Loss: 0.0927\n",
      "Epoch [31/50], Step [504/735], Loss: 0.0451\n",
      "Epoch [31/50], Step [505/735], Loss: 0.1184\n",
      "Epoch [31/50], Step [506/735], Loss: 0.0626\n",
      "Epoch [31/50], Step [507/735], Loss: 0.0357\n",
      "Epoch [31/50], Step [508/735], Loss: 0.0386\n",
      "Epoch [31/50], Step [509/735], Loss: 0.0992\n",
      "Epoch [31/50], Step [510/735], Loss: 0.0298\n",
      "Epoch [31/50], Step [511/735], Loss: 0.0792\n",
      "Epoch [31/50], Step [512/735], Loss: 0.0675\n",
      "Epoch [31/50], Step [513/735], Loss: 0.0392\n",
      "Epoch [31/50], Step [514/735], Loss: 0.1123\n",
      "Epoch [31/50], Step [515/735], Loss: 0.0805\n",
      "Epoch [31/50], Step [516/735], Loss: 0.0478\n",
      "Epoch [31/50], Step [517/735], Loss: 0.0363\n",
      "Epoch [31/50], Step [518/735], Loss: 0.0416\n",
      "Epoch [31/50], Step [519/735], Loss: 0.0967\n",
      "Epoch [31/50], Step [520/735], Loss: 0.1442\n",
      "Epoch [31/50], Step [521/735], Loss: 0.0144\n",
      "Epoch [31/50], Step [522/735], Loss: 0.0363\n",
      "Epoch [31/50], Step [523/735], Loss: 0.1147\n",
      "Epoch [31/50], Step [524/735], Loss: 0.0222\n",
      "Epoch [31/50], Step [525/735], Loss: 0.0250\n",
      "Epoch [31/50], Step [526/735], Loss: 0.1334\n",
      "Epoch [31/50], Step [527/735], Loss: 0.0594\n",
      "Epoch [31/50], Step [528/735], Loss: 0.0758\n",
      "Epoch [31/50], Step [529/735], Loss: 0.1727\n",
      "Epoch [31/50], Step [530/735], Loss: 0.0823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Step [531/735], Loss: 0.0560\n",
      "Epoch [31/50], Step [532/735], Loss: 0.0414\n",
      "Epoch [31/50], Step [533/735], Loss: 0.0172\n",
      "Epoch [31/50], Step [534/735], Loss: 0.2129\n",
      "Epoch [31/50], Step [535/735], Loss: 0.0200\n",
      "Epoch [31/50], Step [536/735], Loss: 0.0585\n",
      "Epoch [31/50], Step [537/735], Loss: 0.0607\n",
      "Epoch [31/50], Step [538/735], Loss: 0.0446\n",
      "Epoch [31/50], Step [539/735], Loss: 0.0285\n",
      "Epoch [31/50], Step [540/735], Loss: 0.0302\n",
      "Epoch [31/50], Step [541/735], Loss: 0.0475\n",
      "Epoch [31/50], Step [542/735], Loss: 0.0679\n",
      "Epoch [31/50], Step [543/735], Loss: 0.0265\n",
      "Epoch [31/50], Step [544/735], Loss: 0.0692\n",
      "Epoch [31/50], Step [545/735], Loss: 0.2499\n",
      "Epoch [31/50], Step [546/735], Loss: 0.0368\n",
      "Epoch [31/50], Step [547/735], Loss: 0.0438\n",
      "Epoch [31/50], Step [548/735], Loss: 0.0457\n",
      "Epoch [31/50], Step [549/735], Loss: 0.1075\n",
      "Epoch [31/50], Step [550/735], Loss: 0.0663\n",
      "Epoch [31/50], Step [551/735], Loss: 0.1063\n",
      "Epoch [31/50], Step [552/735], Loss: 0.1286\n",
      "Epoch [31/50], Step [553/735], Loss: 0.0421\n",
      "Epoch [31/50], Step [554/735], Loss: 0.0370\n",
      "Epoch [31/50], Step [555/735], Loss: 0.0572\n",
      "Epoch [31/50], Step [556/735], Loss: 0.0816\n",
      "Epoch [31/50], Step [557/735], Loss: 0.0231\n",
      "Epoch [31/50], Step [558/735], Loss: 0.1223\n",
      "Epoch [31/50], Step [559/735], Loss: 0.0751\n",
      "Epoch [31/50], Step [560/735], Loss: 0.0882\n",
      "Epoch [31/50], Step [561/735], Loss: 0.0467\n",
      "Epoch [31/50], Step [562/735], Loss: 0.0746\n",
      "Epoch [31/50], Step [563/735], Loss: 0.0788\n",
      "Epoch [31/50], Step [564/735], Loss: 0.0300\n",
      "Epoch [31/50], Step [565/735], Loss: 0.0213\n",
      "Epoch [31/50], Step [566/735], Loss: 0.0247\n",
      "Epoch [31/50], Step [567/735], Loss: 0.1153\n",
      "Epoch [31/50], Step [568/735], Loss: 0.0484\n",
      "Epoch [31/50], Step [569/735], Loss: 0.0633\n",
      "Epoch [31/50], Step [570/735], Loss: 0.3040\n",
      "Epoch [31/50], Step [571/735], Loss: 0.0767\n",
      "Epoch [31/50], Step [572/735], Loss: 0.0197\n",
      "Epoch [31/50], Step [573/735], Loss: 0.2513\n",
      "Epoch [31/50], Step [574/735], Loss: 0.0541\n",
      "Epoch [31/50], Step [575/735], Loss: 0.0868\n",
      "Epoch [31/50], Step [576/735], Loss: 0.0847\n",
      "Epoch [31/50], Step [577/735], Loss: 0.0221\n",
      "Epoch [31/50], Step [578/735], Loss: 0.0647\n",
      "Epoch [31/50], Step [579/735], Loss: 0.0386\n",
      "Epoch [31/50], Step [580/735], Loss: 0.1835\n",
      "Epoch [31/50], Step [581/735], Loss: 0.0499\n",
      "Epoch [31/50], Step [582/735], Loss: 0.2202\n",
      "Epoch [31/50], Step [583/735], Loss: 0.0248\n",
      "Epoch [31/50], Step [584/735], Loss: 0.0845\n",
      "Epoch [31/50], Step [585/735], Loss: 0.1574\n",
      "Epoch [31/50], Step [586/735], Loss: 0.0295\n",
      "Epoch [31/50], Step [587/735], Loss: 0.0442\n",
      "Epoch [31/50], Step [588/735], Loss: 0.0451\n",
      "Epoch [31/50], Step [589/735], Loss: 0.0666\n",
      "Epoch [31/50], Step [590/735], Loss: 0.1230\n",
      "Epoch [31/50], Step [591/735], Loss: 0.0460\n",
      "Epoch [31/50], Step [592/735], Loss: 0.0430\n",
      "Epoch [31/50], Step [593/735], Loss: 0.1128\n",
      "Epoch [31/50], Step [594/735], Loss: 0.1246\n",
      "Epoch [31/50], Step [595/735], Loss: 0.0864\n",
      "Epoch [31/50], Step [596/735], Loss: 0.0352\n",
      "Epoch [31/50], Step [597/735], Loss: 0.0401\n",
      "Epoch [31/50], Step [598/735], Loss: 0.0561\n",
      "Epoch [31/50], Step [599/735], Loss: 0.1040\n",
      "Epoch [31/50], Step [600/735], Loss: 0.0412\n",
      "Epoch [31/50], Step [601/735], Loss: 0.0452\n",
      "Epoch [31/50], Step [602/735], Loss: 0.0493\n",
      "Epoch [31/50], Step [603/735], Loss: 0.0480\n",
      "Epoch [31/50], Step [604/735], Loss: 0.0466\n",
      "Epoch [31/50], Step [605/735], Loss: 0.0114\n",
      "Epoch [31/50], Step [606/735], Loss: 0.0525\n",
      "Epoch [31/50], Step [607/735], Loss: 0.0523\n",
      "Epoch [31/50], Step [608/735], Loss: 0.0381\n",
      "Epoch [31/50], Step [609/735], Loss: 0.0323\n",
      "Epoch [31/50], Step [610/735], Loss: 0.0506\n",
      "Epoch [31/50], Step [611/735], Loss: 0.0412\n",
      "Epoch [31/50], Step [612/735], Loss: 0.1178\n",
      "Epoch [31/50], Step [613/735], Loss: 0.0487\n",
      "Epoch [31/50], Step [614/735], Loss: 0.0690\n",
      "Epoch [31/50], Step [615/735], Loss: 0.0379\n",
      "Epoch [31/50], Step [616/735], Loss: 0.0422\n",
      "Epoch [31/50], Step [617/735], Loss: 0.0380\n",
      "Epoch [31/50], Step [618/735], Loss: 0.0472\n",
      "Epoch [31/50], Step [619/735], Loss: 0.0621\n",
      "Epoch [31/50], Step [620/735], Loss: 0.0816\n",
      "Epoch [31/50], Step [621/735], Loss: 0.0434\n",
      "Epoch [31/50], Step [622/735], Loss: 0.0394\n",
      "Epoch [31/50], Step [623/735], Loss: 0.2199\n",
      "Epoch [31/50], Step [624/735], Loss: 0.0609\n",
      "Epoch [31/50], Step [625/735], Loss: 0.0593\n",
      "Epoch [31/50], Step [626/735], Loss: 0.0551\n",
      "Epoch [31/50], Step [627/735], Loss: 0.0628\n",
      "Epoch [31/50], Step [628/735], Loss: 0.1029\n",
      "Epoch [31/50], Step [629/735], Loss: 0.0433\n",
      "Epoch [31/50], Step [630/735], Loss: 0.0448\n",
      "Epoch [31/50], Step [631/735], Loss: 0.0447\n",
      "Epoch [31/50], Step [632/735], Loss: 0.0751\n",
      "Epoch [31/50], Step [633/735], Loss: 0.0657\n",
      "Epoch [31/50], Step [634/735], Loss: 0.0577\n",
      "Epoch [31/50], Step [635/735], Loss: 0.0583\n",
      "Epoch [31/50], Step [636/735], Loss: 0.0446\n",
      "Epoch [31/50], Step [637/735], Loss: 0.0267\n",
      "Epoch [31/50], Step [638/735], Loss: 0.0250\n",
      "Epoch [31/50], Step [639/735], Loss: 0.0528\n",
      "Epoch [31/50], Step [640/735], Loss: 0.1346\n",
      "Epoch [31/50], Step [641/735], Loss: 0.0732\n",
      "Epoch [31/50], Step [642/735], Loss: 0.0535\n",
      "Epoch [31/50], Step [643/735], Loss: 0.0744\n",
      "Epoch [31/50], Step [644/735], Loss: 0.0488\n",
      "Epoch [31/50], Step [645/735], Loss: 0.0247\n",
      "Epoch [31/50], Step [646/735], Loss: 0.0364\n",
      "Epoch [31/50], Step [647/735], Loss: 0.0402\n",
      "Epoch [31/50], Step [648/735], Loss: 0.0684\n",
      "Epoch [31/50], Step [649/735], Loss: 0.0452\n",
      "Epoch [31/50], Step [650/735], Loss: 0.0552\n",
      "Epoch [31/50], Step [651/735], Loss: 0.0315\n",
      "Epoch [31/50], Step [652/735], Loss: 0.0590\n",
      "Epoch [31/50], Step [653/735], Loss: 0.0524\n",
      "Epoch [31/50], Step [654/735], Loss: 0.0485\n",
      "Epoch [31/50], Step [655/735], Loss: 0.0378\n",
      "Epoch [31/50], Step [656/735], Loss: 0.0515\n",
      "Epoch [31/50], Step [657/735], Loss: 0.0430\n",
      "Epoch [31/50], Step [658/735], Loss: 0.0237\n",
      "Epoch [31/50], Step [659/735], Loss: 0.0541\n",
      "Epoch [31/50], Step [660/735], Loss: 0.0917\n",
      "Epoch [31/50], Step [661/735], Loss: 0.0847\n",
      "Epoch [31/50], Step [662/735], Loss: 0.0517\n",
      "Epoch [31/50], Step [663/735], Loss: 0.0717\n",
      "Epoch [31/50], Step [664/735], Loss: 0.0589\n",
      "Epoch [31/50], Step [665/735], Loss: 0.0188\n",
      "Epoch [31/50], Step [666/735], Loss: 0.0392\n",
      "Epoch [31/50], Step [667/735], Loss: 0.0779\n",
      "Epoch [31/50], Step [668/735], Loss: 0.0181\n",
      "Epoch [31/50], Step [669/735], Loss: 0.0476\n",
      "Epoch [31/50], Step [670/735], Loss: 0.0130\n",
      "Epoch [31/50], Step [671/735], Loss: 0.0378\n",
      "Epoch [31/50], Step [672/735], Loss: 0.0718\n",
      "Epoch [31/50], Step [673/735], Loss: 0.1018\n",
      "Epoch [31/50], Step [674/735], Loss: 0.0453\n",
      "Epoch [31/50], Step [675/735], Loss: 0.0417\n",
      "Epoch [31/50], Step [676/735], Loss: 0.0540\n",
      "Epoch [31/50], Step [677/735], Loss: 0.0386\n",
      "Epoch [31/50], Step [678/735], Loss: 0.0429\n",
      "Epoch [31/50], Step [679/735], Loss: 0.1696\n",
      "Epoch [31/50], Step [680/735], Loss: 0.0306\n",
      "Epoch [31/50], Step [681/735], Loss: 0.0193\n",
      "Epoch [31/50], Step [682/735], Loss: 0.0247\n",
      "Epoch [31/50], Step [683/735], Loss: 0.0353\n",
      "Epoch [31/50], Step [684/735], Loss: 0.0426\n",
      "Epoch [31/50], Step [685/735], Loss: 0.0489\n",
      "Epoch [31/50], Step [686/735], Loss: 0.0579\n",
      "Epoch [31/50], Step [687/735], Loss: 0.0535\n",
      "Epoch [31/50], Step [688/735], Loss: 0.1371\n",
      "Epoch [31/50], Step [689/735], Loss: 0.0404\n",
      "Epoch [31/50], Step [690/735], Loss: 0.1077\n",
      "Epoch [31/50], Step [691/735], Loss: 0.0393\n",
      "Epoch [31/50], Step [692/735], Loss: 0.0307\n",
      "Epoch [31/50], Step [693/735], Loss: 0.0123\n",
      "Epoch [31/50], Step [694/735], Loss: 0.0573\n",
      "Epoch [31/50], Step [695/735], Loss: 0.0531\n",
      "Epoch [31/50], Step [696/735], Loss: 0.0281\n",
      "Epoch [31/50], Step [697/735], Loss: 0.0212\n",
      "Epoch [31/50], Step [698/735], Loss: 0.1442\n",
      "Epoch [31/50], Step [699/735], Loss: 0.0198\n",
      "Epoch [31/50], Step [700/735], Loss: 0.1253\n",
      "Epoch [31/50], Step [701/735], Loss: 0.0206\n",
      "Epoch [31/50], Step [702/735], Loss: 0.0254\n",
      "Epoch [31/50], Step [703/735], Loss: 0.0714\n",
      "Epoch [31/50], Step [704/735], Loss: 0.1832\n",
      "Epoch [31/50], Step [705/735], Loss: 0.0444\n",
      "Epoch [31/50], Step [706/735], Loss: 0.0609\n",
      "Epoch [31/50], Step [707/735], Loss: 0.0737\n",
      "Epoch [31/50], Step [708/735], Loss: 0.0448\n",
      "Epoch [31/50], Step [709/735], Loss: 0.0454\n",
      "Epoch [31/50], Step [710/735], Loss: 0.0504\n",
      "Epoch [31/50], Step [711/735], Loss: 0.0331\n",
      "Epoch [31/50], Step [712/735], Loss: 0.0358\n",
      "Epoch [31/50], Step [713/735], Loss: 0.4293\n",
      "Epoch [31/50], Step [714/735], Loss: 0.0978\n",
      "Epoch [31/50], Step [715/735], Loss: 0.0423\n",
      "Epoch [31/50], Step [716/735], Loss: 0.0353\n",
      "Epoch [31/50], Step [717/735], Loss: 0.0519\n",
      "Epoch [31/50], Step [718/735], Loss: 0.1124\n",
      "Epoch [31/50], Step [719/735], Loss: 0.0558\n",
      "Epoch [31/50], Step [720/735], Loss: 0.0418\n",
      "Epoch [31/50], Step [721/735], Loss: 0.0784\n",
      "Epoch [31/50], Step [722/735], Loss: 0.0431\n",
      "Epoch [31/50], Step [723/735], Loss: 0.0439\n",
      "Epoch [31/50], Step [724/735], Loss: 0.0836\n",
      "Epoch [31/50], Step [725/735], Loss: 0.0634\n",
      "Epoch [31/50], Step [726/735], Loss: 0.0610\n",
      "Epoch [31/50], Step [727/735], Loss: 0.0416\n",
      "Epoch [31/50], Step [728/735], Loss: 0.0573\n",
      "Epoch [31/50], Step [729/735], Loss: 0.0445\n",
      "Epoch [31/50], Step [730/735], Loss: 0.0283\n",
      "Epoch [31/50], Step [731/735], Loss: 0.0437\n",
      "Epoch [31/50], Step [732/735], Loss: 0.0289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Step [733/735], Loss: 0.0479\n",
      "Epoch [31/50], Step [734/735], Loss: 0.0237\n",
      "Epoch [31/50], Step [735/735], Loss: 0.0408\n",
      "Epoch [32/50], Step [1/735], Loss: 0.0292\n",
      "Epoch [32/50], Step [2/735], Loss: 0.0448\n",
      "Epoch [32/50], Step [3/735], Loss: 0.0634\n",
      "Epoch [32/50], Step [4/735], Loss: 0.0693\n",
      "Epoch [32/50], Step [5/735], Loss: 0.0578\n",
      "Epoch [32/50], Step [6/735], Loss: 0.0277\n",
      "Epoch [32/50], Step [7/735], Loss: 0.0197\n",
      "Epoch [32/50], Step [8/735], Loss: 0.0339\n",
      "Epoch [32/50], Step [9/735], Loss: 0.0349\n",
      "Epoch [32/50], Step [10/735], Loss: 0.0481\n",
      "Epoch [32/50], Step [11/735], Loss: 0.0279\n",
      "Epoch [32/50], Step [12/735], Loss: 0.0518\n",
      "Epoch [32/50], Step [13/735], Loss: 0.0940\n",
      "Epoch [32/50], Step [14/735], Loss: 0.0381\n",
      "Epoch [32/50], Step [15/735], Loss: 0.0833\n",
      "Epoch [32/50], Step [16/735], Loss: 0.0974\n",
      "Epoch [32/50], Step [17/735], Loss: 0.0320\n",
      "Epoch [32/50], Step [18/735], Loss: 0.0245\n",
      "Epoch [32/50], Step [19/735], Loss: 0.0223\n",
      "Epoch [32/50], Step [20/735], Loss: 0.0456\n",
      "Epoch [32/50], Step [21/735], Loss: 0.0843\n",
      "Epoch [32/50], Step [22/735], Loss: 0.1018\n",
      "Epoch [32/50], Step [23/735], Loss: 0.0250\n",
      "Epoch [32/50], Step [24/735], Loss: 0.0665\n",
      "Epoch [32/50], Step [25/735], Loss: 0.0478\n",
      "Epoch [32/50], Step [26/735], Loss: 0.0193\n",
      "Epoch [32/50], Step [27/735], Loss: 0.0561\n",
      "Epoch [32/50], Step [28/735], Loss: 0.0631\n",
      "Epoch [32/50], Step [29/735], Loss: 0.0731\n",
      "Epoch [32/50], Step [30/735], Loss: 0.0156\n",
      "Epoch [32/50], Step [31/735], Loss: 0.0493\n",
      "Epoch [32/50], Step [32/735], Loss: 0.0567\n",
      "Epoch [32/50], Step [33/735], Loss: 0.0359\n",
      "Epoch [32/50], Step [34/735], Loss: 0.0632\n",
      "Epoch [32/50], Step [35/735], Loss: 0.0581\n",
      "Epoch [32/50], Step [36/735], Loss: 0.0969\n",
      "Epoch [32/50], Step [37/735], Loss: 0.0394\n",
      "Epoch [32/50], Step [38/735], Loss: 0.0238\n",
      "Epoch [32/50], Step [39/735], Loss: 0.0421\n",
      "Epoch [32/50], Step [40/735], Loss: 0.0730\n",
      "Epoch [32/50], Step [41/735], Loss: 0.0711\n",
      "Epoch [32/50], Step [42/735], Loss: 0.0199\n",
      "Epoch [32/50], Step [43/735], Loss: 0.0699\n",
      "Epoch [32/50], Step [44/735], Loss: 0.0381\n",
      "Epoch [32/50], Step [45/735], Loss: 0.0549\n",
      "Epoch [32/50], Step [46/735], Loss: 0.0896\n",
      "Epoch [32/50], Step [47/735], Loss: 0.0295\n",
      "Epoch [32/50], Step [48/735], Loss: 0.0278\n",
      "Epoch [32/50], Step [49/735], Loss: 0.0854\n",
      "Epoch [32/50], Step [50/735], Loss: 0.0418\n",
      "Epoch [32/50], Step [51/735], Loss: 0.0789\n",
      "Epoch [32/50], Step [52/735], Loss: 0.0705\n",
      "Epoch [32/50], Step [53/735], Loss: 0.0940\n",
      "Epoch [32/50], Step [54/735], Loss: 0.0592\n",
      "Epoch [32/50], Step [55/735], Loss: 0.0759\n",
      "Epoch [32/50], Step [56/735], Loss: 0.0282\n",
      "Epoch [32/50], Step [57/735], Loss: 0.0441\n",
      "Epoch [32/50], Step [58/735], Loss: 0.0261\n",
      "Epoch [32/50], Step [59/735], Loss: 0.0466\n",
      "Epoch [32/50], Step [60/735], Loss: 0.0222\n",
      "Epoch [32/50], Step [61/735], Loss: 0.0343\n",
      "Epoch [32/50], Step [62/735], Loss: 0.0330\n",
      "Epoch [32/50], Step [63/735], Loss: 0.0270\n",
      "Epoch [32/50], Step [64/735], Loss: 0.2079\n",
      "Epoch [32/50], Step [65/735], Loss: 0.0416\n",
      "Epoch [32/50], Step [66/735], Loss: 0.1985\n",
      "Epoch [32/50], Step [67/735], Loss: 0.0354\n",
      "Epoch [32/50], Step [68/735], Loss: 0.0455\n",
      "Epoch [32/50], Step [69/735], Loss: 0.0513\n",
      "Epoch [32/50], Step [70/735], Loss: 0.0325\n",
      "Epoch [32/50], Step [71/735], Loss: 0.0911\n",
      "Epoch [32/50], Step [72/735], Loss: 0.1076\n",
      "Epoch [32/50], Step [73/735], Loss: 0.0143\n",
      "Epoch [32/50], Step [74/735], Loss: 0.2631\n",
      "Epoch [32/50], Step [75/735], Loss: 0.0690\n",
      "Epoch [32/50], Step [76/735], Loss: 0.1193\n",
      "Epoch [32/50], Step [77/735], Loss: 0.2190\n",
      "Epoch [32/50], Step [78/735], Loss: 0.0152\n",
      "Epoch [32/50], Step [79/735], Loss: 0.0479\n",
      "Epoch [32/50], Step [80/735], Loss: 0.0440\n",
      "Epoch [32/50], Step [81/735], Loss: 0.2224\n",
      "Epoch [32/50], Step [82/735], Loss: 0.0275\n",
      "Epoch [32/50], Step [83/735], Loss: 0.0597\n",
      "Epoch [32/50], Step [84/735], Loss: 0.1196\n",
      "Epoch [32/50], Step [85/735], Loss: 0.0409\n",
      "Epoch [32/50], Step [86/735], Loss: 0.0268\n",
      "Epoch [32/50], Step [87/735], Loss: 0.0499\n",
      "Epoch [32/50], Step [88/735], Loss: 0.0701\n",
      "Epoch [32/50], Step [89/735], Loss: 0.0488\n",
      "Epoch [32/50], Step [90/735], Loss: 0.0570\n",
      "Epoch [32/50], Step [91/735], Loss: 0.1027\n",
      "Epoch [32/50], Step [92/735], Loss: 0.0270\n",
      "Epoch [32/50], Step [93/735], Loss: 0.0380\n",
      "Epoch [32/50], Step [94/735], Loss: 0.0270\n",
      "Epoch [32/50], Step [95/735], Loss: 0.0711\n",
      "Epoch [32/50], Step [96/735], Loss: 0.0574\n",
      "Epoch [32/50], Step [97/735], Loss: 0.0326\n",
      "Epoch [32/50], Step [98/735], Loss: 0.0415\n",
      "Epoch [32/50], Step [99/735], Loss: 0.0127\n",
      "Epoch [32/50], Step [100/735], Loss: 0.0500\n",
      "Epoch [32/50], Step [101/735], Loss: 0.0168\n",
      "Epoch [32/50], Step [102/735], Loss: 0.0742\n",
      "Epoch [32/50], Step [103/735], Loss: 0.0588\n",
      "Epoch [32/50], Step [104/735], Loss: 0.0470\n",
      "Epoch [32/50], Step [105/735], Loss: 0.0349\n",
      "Epoch [32/50], Step [106/735], Loss: 0.0326\n",
      "Epoch [32/50], Step [107/735], Loss: 0.0418\n",
      "Epoch [32/50], Step [108/735], Loss: 0.0163\n",
      "Epoch [32/50], Step [109/735], Loss: 0.0268\n",
      "Epoch [32/50], Step [110/735], Loss: 0.0437\n",
      "Epoch [32/50], Step [111/735], Loss: 0.0127\n",
      "Epoch [32/50], Step [112/735], Loss: 0.0325\n",
      "Epoch [32/50], Step [113/735], Loss: 0.0445\n",
      "Epoch [32/50], Step [114/735], Loss: 0.0668\n",
      "Epoch [32/50], Step [115/735], Loss: 0.0479\n",
      "Epoch [32/50], Step [116/735], Loss: 0.0486\n",
      "Epoch [32/50], Step [117/735], Loss: 0.0436\n",
      "Epoch [32/50], Step [118/735], Loss: 0.0257\n",
      "Epoch [32/50], Step [119/735], Loss: 0.1124\n",
      "Epoch [32/50], Step [120/735], Loss: 0.0442\n",
      "Epoch [32/50], Step [121/735], Loss: 0.0341\n",
      "Epoch [32/50], Step [122/735], Loss: 0.0567\n",
      "Epoch [32/50], Step [123/735], Loss: 0.0146\n",
      "Epoch [32/50], Step [124/735], Loss: 0.0639\n",
      "Epoch [32/50], Step [125/735], Loss: 0.0296\n",
      "Epoch [32/50], Step [126/735], Loss: 0.0538\n",
      "Epoch [32/50], Step [127/735], Loss: 0.0274\n",
      "Epoch [32/50], Step [128/735], Loss: 0.0267\n",
      "Epoch [32/50], Step [129/735], Loss: 0.0577\n",
      "Epoch [32/50], Step [130/735], Loss: 0.0283\n",
      "Epoch [32/50], Step [131/735], Loss: 0.0949\n",
      "Epoch [32/50], Step [132/735], Loss: 0.0782\n",
      "Epoch [32/50], Step [133/735], Loss: 0.0700\n",
      "Epoch [32/50], Step [134/735], Loss: 0.0647\n",
      "Epoch [32/50], Step [135/735], Loss: 0.0285\n",
      "Epoch [32/50], Step [136/735], Loss: 0.0837\n",
      "Epoch [32/50], Step [137/735], Loss: 0.1449\n",
      "Epoch [32/50], Step [138/735], Loss: 0.0950\n",
      "Epoch [32/50], Step [139/735], Loss: 0.2123\n",
      "Epoch [32/50], Step [140/735], Loss: 0.0287\n",
      "Epoch [32/50], Step [141/735], Loss: 0.0358\n",
      "Epoch [32/50], Step [142/735], Loss: 0.0751\n",
      "Epoch [32/50], Step [143/735], Loss: 0.0409\n",
      "Epoch [32/50], Step [144/735], Loss: 0.1600\n",
      "Epoch [32/50], Step [145/735], Loss: 0.0266\n",
      "Epoch [32/50], Step [146/735], Loss: 0.0869\n",
      "Epoch [32/50], Step [147/735], Loss: 0.0786\n",
      "Epoch [32/50], Step [148/735], Loss: 0.0381\n",
      "Epoch [32/50], Step [149/735], Loss: 0.0445\n",
      "Epoch [32/50], Step [150/735], Loss: 0.0330\n",
      "Epoch [32/50], Step [151/735], Loss: 0.1035\n",
      "Epoch [32/50], Step [152/735], Loss: 0.0246\n",
      "Epoch [32/50], Step [153/735], Loss: 0.1773\n",
      "Epoch [32/50], Step [154/735], Loss: 0.0680\n",
      "Epoch [32/50], Step [155/735], Loss: 0.0658\n",
      "Epoch [32/50], Step [156/735], Loss: 0.0987\n",
      "Epoch [32/50], Step [157/735], Loss: 0.0255\n",
      "Epoch [32/50], Step [158/735], Loss: 0.0540\n",
      "Epoch [32/50], Step [159/735], Loss: 0.0568\n",
      "Epoch [32/50], Step [160/735], Loss: 0.0217\n",
      "Epoch [32/50], Step [161/735], Loss: 0.0354\n",
      "Epoch [32/50], Step [162/735], Loss: 0.0450\n",
      "Epoch [32/50], Step [163/735], Loss: 0.0306\n",
      "Epoch [32/50], Step [164/735], Loss: 0.0725\n",
      "Epoch [32/50], Step [165/735], Loss: 0.0988\n",
      "Epoch [32/50], Step [166/735], Loss: 0.0606\n",
      "Epoch [32/50], Step [167/735], Loss: 0.1196\n",
      "Epoch [32/50], Step [168/735], Loss: 0.0838\n",
      "Epoch [32/50], Step [169/735], Loss: 0.1190\n",
      "Epoch [32/50], Step [170/735], Loss: 0.0367\n",
      "Epoch [32/50], Step [171/735], Loss: 0.1581\n",
      "Epoch [32/50], Step [172/735], Loss: 0.0807\n",
      "Epoch [32/50], Step [173/735], Loss: 0.0717\n",
      "Epoch [32/50], Step [174/735], Loss: 0.0329\n",
      "Epoch [32/50], Step [175/735], Loss: 0.0447\n",
      "Epoch [32/50], Step [176/735], Loss: 0.0138\n",
      "Epoch [32/50], Step [177/735], Loss: 0.0218\n",
      "Epoch [32/50], Step [178/735], Loss: 0.0718\n",
      "Epoch [32/50], Step [179/735], Loss: 0.0275\n",
      "Epoch [32/50], Step [180/735], Loss: 0.1588\n",
      "Epoch [32/50], Step [181/735], Loss: 0.0364\n",
      "Epoch [32/50], Step [182/735], Loss: 0.0533\n",
      "Epoch [32/50], Step [183/735], Loss: 0.0306\n",
      "Epoch [32/50], Step [184/735], Loss: 0.0600\n",
      "Epoch [32/50], Step [185/735], Loss: 0.0774\n",
      "Epoch [32/50], Step [186/735], Loss: 0.0426\n",
      "Epoch [32/50], Step [187/735], Loss: 0.2126\n",
      "Epoch [32/50], Step [188/735], Loss: 0.0504\n",
      "Epoch [32/50], Step [189/735], Loss: 0.1263\n",
      "Epoch [32/50], Step [190/735], Loss: 0.2112\n",
      "Epoch [32/50], Step [191/735], Loss: 0.0603\n",
      "Epoch [32/50], Step [192/735], Loss: 0.2397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Step [193/735], Loss: 0.1693\n",
      "Epoch [32/50], Step [194/735], Loss: 0.0425\n",
      "Epoch [32/50], Step [195/735], Loss: 0.0807\n",
      "Epoch [32/50], Step [196/735], Loss: 0.0848\n",
      "Epoch [32/50], Step [197/735], Loss: 0.0337\n",
      "Epoch [32/50], Step [198/735], Loss: 0.0891\n",
      "Epoch [32/50], Step [199/735], Loss: 0.0834\n",
      "Epoch [32/50], Step [200/735], Loss: 0.0869\n",
      "Epoch [32/50], Step [201/735], Loss: 0.0895\n",
      "Epoch [32/50], Step [202/735], Loss: 0.0317\n",
      "Epoch [32/50], Step [203/735], Loss: 0.0355\n",
      "Epoch [32/50], Step [204/735], Loss: 0.0345\n",
      "Epoch [32/50], Step [205/735], Loss: 0.0454\n",
      "Epoch [32/50], Step [206/735], Loss: 0.0440\n",
      "Epoch [32/50], Step [207/735], Loss: 0.0299\n",
      "Epoch [32/50], Step [208/735], Loss: 0.0662\n",
      "Epoch [32/50], Step [209/735], Loss: 0.0747\n",
      "Epoch [32/50], Step [210/735], Loss: 0.0879\n",
      "Epoch [32/50], Step [211/735], Loss: 0.2164\n",
      "Epoch [32/50], Step [212/735], Loss: 0.0678\n",
      "Epoch [32/50], Step [213/735], Loss: 0.0371\n",
      "Epoch [32/50], Step [214/735], Loss: 0.0994\n",
      "Epoch [32/50], Step [215/735], Loss: 0.0402\n",
      "Epoch [32/50], Step [216/735], Loss: 0.0819\n",
      "Epoch [32/50], Step [217/735], Loss: 0.2059\n",
      "Epoch [32/50], Step [218/735], Loss: 0.1744\n",
      "Epoch [32/50], Step [219/735], Loss: 0.0659\n",
      "Epoch [32/50], Step [220/735], Loss: 0.0614\n",
      "Epoch [32/50], Step [221/735], Loss: 0.0570\n",
      "Epoch [32/50], Step [222/735], Loss: 0.0254\n",
      "Epoch [32/50], Step [223/735], Loss: 0.0592\n",
      "Epoch [32/50], Step [224/735], Loss: 0.0643\n",
      "Epoch [32/50], Step [225/735], Loss: 0.0480\n",
      "Epoch [32/50], Step [226/735], Loss: 0.5373\n",
      "Epoch [32/50], Step [227/735], Loss: 0.0618\n",
      "Epoch [32/50], Step [228/735], Loss: 0.0201\n",
      "Epoch [32/50], Step [229/735], Loss: 0.0815\n",
      "Epoch [32/50], Step [230/735], Loss: 0.0387\n",
      "Epoch [32/50], Step [231/735], Loss: 0.0509\n",
      "Epoch [32/50], Step [232/735], Loss: 0.0384\n",
      "Epoch [32/50], Step [233/735], Loss: 0.0796\n",
      "Epoch [32/50], Step [234/735], Loss: 0.0168\n",
      "Epoch [32/50], Step [235/735], Loss: 0.0462\n",
      "Epoch [32/50], Step [236/735], Loss: 0.1107\n",
      "Epoch [32/50], Step [237/735], Loss: 0.0267\n",
      "Epoch [32/50], Step [238/735], Loss: 0.0667\n",
      "Epoch [32/50], Step [239/735], Loss: 0.0420\n",
      "Epoch [32/50], Step [240/735], Loss: 0.0251\n",
      "Epoch [32/50], Step [241/735], Loss: 0.0599\n",
      "Epoch [32/50], Step [242/735], Loss: 0.0616\n",
      "Epoch [32/50], Step [243/735], Loss: 0.0647\n",
      "Epoch [32/50], Step [244/735], Loss: 0.0573\n",
      "Epoch [32/50], Step [245/735], Loss: 0.0508\n",
      "Epoch [32/50], Step [246/735], Loss: 0.0735\n",
      "Epoch [32/50], Step [247/735], Loss: 0.0632\n",
      "Epoch [32/50], Step [248/735], Loss: 0.0766\n",
      "Epoch [32/50], Step [249/735], Loss: 0.0676\n",
      "Epoch [32/50], Step [250/735], Loss: 0.0467\n",
      "Epoch [32/50], Step [251/735], Loss: 0.0256\n",
      "Epoch [32/50], Step [252/735], Loss: 0.0282\n",
      "Epoch [32/50], Step [253/735], Loss: 0.0463\n",
      "Epoch [32/50], Step [254/735], Loss: 0.0502\n",
      "Epoch [32/50], Step [255/735], Loss: 0.1160\n",
      "Epoch [32/50], Step [256/735], Loss: 0.0847\n",
      "Epoch [32/50], Step [257/735], Loss: 0.0250\n",
      "Epoch [32/50], Step [258/735], Loss: 0.0342\n",
      "Epoch [32/50], Step [259/735], Loss: 0.0895\n",
      "Epoch [32/50], Step [260/735], Loss: 0.2197\n",
      "Epoch [32/50], Step [261/735], Loss: 0.0253\n",
      "Epoch [32/50], Step [262/735], Loss: 0.0578\n",
      "Epoch [32/50], Step [263/735], Loss: 0.0339\n",
      "Epoch [32/50], Step [264/735], Loss: 0.0272\n",
      "Epoch [32/50], Step [265/735], Loss: 0.0354\n",
      "Epoch [32/50], Step [266/735], Loss: 0.1055\n",
      "Epoch [32/50], Step [267/735], Loss: 0.0530\n",
      "Epoch [32/50], Step [268/735], Loss: 0.0494\n",
      "Epoch [32/50], Step [269/735], Loss: 0.0648\n",
      "Epoch [32/50], Step [270/735], Loss: 0.0358\n",
      "Epoch [32/50], Step [271/735], Loss: 0.0374\n",
      "Epoch [32/50], Step [272/735], Loss: 0.0290\n",
      "Epoch [32/50], Step [273/735], Loss: 0.0214\n",
      "Epoch [32/50], Step [274/735], Loss: 0.0692\n",
      "Epoch [32/50], Step [275/735], Loss: 0.0396\n",
      "Epoch [32/50], Step [276/735], Loss: 0.1517\n",
      "Epoch [32/50], Step [277/735], Loss: 0.1179\n",
      "Epoch [32/50], Step [278/735], Loss: 0.0447\n",
      "Epoch [32/50], Step [279/735], Loss: 0.1302\n",
      "Epoch [32/50], Step [280/735], Loss: 0.0365\n",
      "Epoch [32/50], Step [281/735], Loss: 0.0274\n",
      "Epoch [32/50], Step [282/735], Loss: 0.0165\n",
      "Epoch [32/50], Step [283/735], Loss: 0.1063\n",
      "Epoch [32/50], Step [284/735], Loss: 0.0464\n",
      "Epoch [32/50], Step [285/735], Loss: 0.0405\n",
      "Epoch [32/50], Step [286/735], Loss: 0.1537\n",
      "Epoch [32/50], Step [287/735], Loss: 0.0406\n",
      "Epoch [32/50], Step [288/735], Loss: 0.0296\n",
      "Epoch [32/50], Step [289/735], Loss: 0.0261\n",
      "Epoch [32/50], Step [290/735], Loss: 0.1273\n",
      "Epoch [32/50], Step [291/735], Loss: 0.0612\n",
      "Epoch [32/50], Step [292/735], Loss: 0.0350\n",
      "Epoch [32/50], Step [293/735], Loss: 0.0338\n",
      "Epoch [32/50], Step [294/735], Loss: 0.1417\n",
      "Epoch [32/50], Step [295/735], Loss: 0.1157\n",
      "Epoch [32/50], Step [296/735], Loss: 0.1116\n",
      "Epoch [32/50], Step [297/735], Loss: 0.4302\n",
      "Epoch [32/50], Step [298/735], Loss: 0.0890\n",
      "Epoch [32/50], Step [299/735], Loss: 0.0345\n",
      "Epoch [32/50], Step [300/735], Loss: 0.0311\n",
      "Epoch [32/50], Step [301/735], Loss: 0.1054\n",
      "Epoch [32/50], Step [302/735], Loss: 0.4238\n",
      "Epoch [32/50], Step [303/735], Loss: 0.0925\n",
      "Epoch [32/50], Step [304/735], Loss: 0.0469\n",
      "Epoch [32/50], Step [305/735], Loss: 0.0711\n",
      "Epoch [32/50], Step [306/735], Loss: 0.0804\n",
      "Epoch [32/50], Step [307/735], Loss: 0.0346\n",
      "Epoch [32/50], Step [308/735], Loss: 0.0420\n",
      "Epoch [32/50], Step [309/735], Loss: 0.0115\n",
      "Epoch [32/50], Step [310/735], Loss: 0.0765\n",
      "Epoch [32/50], Step [311/735], Loss: 0.0636\n",
      "Epoch [32/50], Step [312/735], Loss: 0.1172\n",
      "Epoch [32/50], Step [313/735], Loss: 0.0477\n",
      "Epoch [32/50], Step [314/735], Loss: 0.0619\n",
      "Epoch [32/50], Step [315/735], Loss: 0.0579\n",
      "Epoch [32/50], Step [316/735], Loss: 0.1934\n",
      "Epoch [32/50], Step [317/735], Loss: 0.0306\n",
      "Epoch [32/50], Step [318/735], Loss: 0.0683\n",
      "Epoch [32/50], Step [319/735], Loss: 0.0991\n",
      "Epoch [32/50], Step [320/735], Loss: 0.0284\n",
      "Epoch [32/50], Step [321/735], Loss: 0.0555\n",
      "Epoch [32/50], Step [322/735], Loss: 0.0236\n",
      "Epoch [32/50], Step [323/735], Loss: 0.0339\n",
      "Epoch [32/50], Step [324/735], Loss: 0.0785\n",
      "Epoch [32/50], Step [325/735], Loss: 0.0559\n",
      "Epoch [32/50], Step [326/735], Loss: 0.0925\n",
      "Epoch [32/50], Step [327/735], Loss: 0.3667\n",
      "Epoch [32/50], Step [328/735], Loss: 0.0418\n",
      "Epoch [32/50], Step [329/735], Loss: 0.0550\n",
      "Epoch [32/50], Step [330/735], Loss: 0.0576\n",
      "Epoch [32/50], Step [331/735], Loss: 0.1041\n",
      "Epoch [32/50], Step [332/735], Loss: 0.0360\n",
      "Epoch [32/50], Step [333/735], Loss: 0.1157\n",
      "Epoch [32/50], Step [334/735], Loss: 0.1434\n",
      "Epoch [32/50], Step [335/735], Loss: 0.0614\n",
      "Epoch [32/50], Step [336/735], Loss: 0.0380\n",
      "Epoch [32/50], Step [337/735], Loss: 0.0386\n",
      "Epoch [32/50], Step [338/735], Loss: 0.2269\n",
      "Epoch [32/50], Step [339/735], Loss: 0.1489\n",
      "Epoch [32/50], Step [340/735], Loss: 0.1066\n",
      "Epoch [32/50], Step [341/735], Loss: 0.0346\n",
      "Epoch [32/50], Step [342/735], Loss: 0.1710\n",
      "Epoch [32/50], Step [343/735], Loss: 0.0486\n",
      "Epoch [32/50], Step [344/735], Loss: 0.6693\n",
      "Epoch [32/50], Step [345/735], Loss: 0.0389\n",
      "Epoch [32/50], Step [346/735], Loss: 0.1098\n",
      "Epoch [32/50], Step [347/735], Loss: 0.0948\n",
      "Epoch [32/50], Step [348/735], Loss: 0.0484\n",
      "Epoch [32/50], Step [349/735], Loss: 0.0673\n",
      "Epoch [32/50], Step [350/735], Loss: 0.1186\n",
      "Epoch [32/50], Step [351/735], Loss: 0.0572\n",
      "Epoch [32/50], Step [352/735], Loss: 0.0964\n",
      "Epoch [32/50], Step [353/735], Loss: 0.0498\n",
      "Epoch [32/50], Step [354/735], Loss: 0.0474\n",
      "Epoch [32/50], Step [355/735], Loss: 0.0399\n",
      "Epoch [32/50], Step [356/735], Loss: 0.0888\n",
      "Epoch [32/50], Step [357/735], Loss: 0.0329\n",
      "Epoch [32/50], Step [358/735], Loss: 0.0593\n",
      "Epoch [32/50], Step [359/735], Loss: 0.0463\n",
      "Epoch [32/50], Step [360/735], Loss: 0.1960\n",
      "Epoch [32/50], Step [361/735], Loss: 0.0253\n",
      "Epoch [32/50], Step [362/735], Loss: 0.0907\n",
      "Epoch [32/50], Step [363/735], Loss: 0.0791\n",
      "Epoch [32/50], Step [364/735], Loss: 0.0532\n",
      "Epoch [32/50], Step [365/735], Loss: 0.0666\n",
      "Epoch [32/50], Step [366/735], Loss: 0.0561\n",
      "Epoch [32/50], Step [367/735], Loss: 0.0312\n",
      "Epoch [32/50], Step [368/735], Loss: 0.0380\n",
      "Epoch [32/50], Step [369/735], Loss: 0.3807\n",
      "Epoch [32/50], Step [370/735], Loss: 0.1134\n",
      "Epoch [32/50], Step [371/735], Loss: 0.0249\n",
      "Epoch [32/50], Step [372/735], Loss: 0.0375\n",
      "Epoch [32/50], Step [373/735], Loss: 0.0636\n",
      "Epoch [32/50], Step [374/735], Loss: 0.0924\n",
      "Epoch [32/50], Step [375/735], Loss: 0.1038\n",
      "Epoch [32/50], Step [376/735], Loss: 0.0445\n",
      "Epoch [32/50], Step [377/735], Loss: 0.0542\n",
      "Epoch [32/50], Step [378/735], Loss: 0.0335\n",
      "Epoch [32/50], Step [379/735], Loss: 0.0364\n",
      "Epoch [32/50], Step [380/735], Loss: 0.0332\n",
      "Epoch [32/50], Step [381/735], Loss: 0.0575\n",
      "Epoch [32/50], Step [382/735], Loss: 0.0613\n",
      "Epoch [32/50], Step [383/735], Loss: 0.0196\n",
      "Epoch [32/50], Step [384/735], Loss: 0.0291\n",
      "Epoch [32/50], Step [385/735], Loss: 0.0814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Step [386/735], Loss: 0.0744\n",
      "Epoch [32/50], Step [387/735], Loss: 0.0708\n",
      "Epoch [32/50], Step [388/735], Loss: 0.0502\n",
      "Epoch [32/50], Step [389/735], Loss: 0.0778\n",
      "Epoch [32/50], Step [390/735], Loss: 0.0437\n",
      "Epoch [32/50], Step [391/735], Loss: 0.0595\n",
      "Epoch [32/50], Step [392/735], Loss: 0.0314\n",
      "Epoch [32/50], Step [393/735], Loss: 0.0485\n",
      "Epoch [32/50], Step [394/735], Loss: 0.0191\n",
      "Epoch [32/50], Step [395/735], Loss: 0.0689\n",
      "Epoch [32/50], Step [396/735], Loss: 0.0586\n",
      "Epoch [32/50], Step [397/735], Loss: 0.0391\n",
      "Epoch [32/50], Step [398/735], Loss: 0.0356\n",
      "Epoch [32/50], Step [399/735], Loss: 0.2409\n",
      "Epoch [32/50], Step [400/735], Loss: 0.0354\n",
      "Epoch [32/50], Step [401/735], Loss: 0.0788\n",
      "Epoch [32/50], Step [402/735], Loss: 0.0554\n",
      "Epoch [32/50], Step [403/735], Loss: 0.0391\n",
      "Epoch [32/50], Step [404/735], Loss: 0.0474\n",
      "Epoch [32/50], Step [405/735], Loss: 0.0786\n",
      "Epoch [32/50], Step [406/735], Loss: 0.0499\n",
      "Epoch [32/50], Step [407/735], Loss: 0.0516\n",
      "Epoch [32/50], Step [408/735], Loss: 0.1138\n",
      "Epoch [32/50], Step [409/735], Loss: 0.0365\n",
      "Epoch [32/50], Step [410/735], Loss: 0.0175\n",
      "Epoch [32/50], Step [411/735], Loss: 0.0750\n",
      "Epoch [32/50], Step [412/735], Loss: 0.0386\n",
      "Epoch [32/50], Step [413/735], Loss: 0.0629\n",
      "Epoch [32/50], Step [414/735], Loss: 0.0241\n",
      "Epoch [32/50], Step [415/735], Loss: 0.0778\n",
      "Epoch [32/50], Step [416/735], Loss: 0.0502\n",
      "Epoch [32/50], Step [417/735], Loss: 0.0988\n",
      "Epoch [32/50], Step [418/735], Loss: 0.0860\n",
      "Epoch [32/50], Step [419/735], Loss: 0.0350\n",
      "Epoch [32/50], Step [420/735], Loss: 0.0317\n",
      "Epoch [32/50], Step [421/735], Loss: 0.0803\n",
      "Epoch [32/50], Step [422/735], Loss: 0.1070\n",
      "Epoch [32/50], Step [423/735], Loss: 0.0277\n",
      "Epoch [32/50], Step [424/735], Loss: 0.0289\n",
      "Epoch [32/50], Step [425/735], Loss: 0.0661\n",
      "Epoch [32/50], Step [426/735], Loss: 0.0170\n",
      "Epoch [32/50], Step [427/735], Loss: 0.1492\n",
      "Epoch [32/50], Step [428/735], Loss: 0.0633\n",
      "Epoch [32/50], Step [429/735], Loss: 0.0319\n",
      "Epoch [32/50], Step [430/735], Loss: 0.1870\n",
      "Epoch [32/50], Step [431/735], Loss: 0.0883\n",
      "Epoch [32/50], Step [432/735], Loss: 0.0612\n",
      "Epoch [32/50], Step [433/735], Loss: 0.1018\n",
      "Epoch [32/50], Step [434/735], Loss: 0.0830\n",
      "Epoch [32/50], Step [435/735], Loss: 0.0319\n",
      "Epoch [32/50], Step [436/735], Loss: 0.0376\n",
      "Epoch [32/50], Step [437/735], Loss: 0.0436\n",
      "Epoch [32/50], Step [438/735], Loss: 0.0460\n",
      "Epoch [32/50], Step [439/735], Loss: 0.0412\n",
      "Epoch [32/50], Step [440/735], Loss: 0.0994\n",
      "Epoch [32/50], Step [441/735], Loss: 0.0464\n",
      "Epoch [32/50], Step [442/735], Loss: 0.0438\n",
      "Epoch [32/50], Step [443/735], Loss: 0.0824\n",
      "Epoch [32/50], Step [444/735], Loss: 0.0326\n",
      "Epoch [32/50], Step [445/735], Loss: 0.0239\n",
      "Epoch [32/50], Step [446/735], Loss: 0.1402\n",
      "Epoch [32/50], Step [447/735], Loss: 0.0977\n",
      "Epoch [32/50], Step [448/735], Loss: 0.2295\n",
      "Epoch [32/50], Step [449/735], Loss: 0.1546\n",
      "Epoch [32/50], Step [450/735], Loss: 0.0410\n",
      "Epoch [32/50], Step [451/735], Loss: 0.0519\n",
      "Epoch [32/50], Step [452/735], Loss: 0.0608\n",
      "Epoch [32/50], Step [453/735], Loss: 0.1000\n",
      "Epoch [32/50], Step [454/735], Loss: 0.1027\n",
      "Epoch [32/50], Step [455/735], Loss: 0.0267\n",
      "Epoch [32/50], Step [456/735], Loss: 0.0613\n",
      "Epoch [32/50], Step [457/735], Loss: 0.0660\n",
      "Epoch [32/50], Step [458/735], Loss: 0.1836\n",
      "Epoch [32/50], Step [459/735], Loss: 0.0662\n",
      "Epoch [32/50], Step [460/735], Loss: 0.0245\n",
      "Epoch [32/50], Step [461/735], Loss: 0.1421\n",
      "Epoch [32/50], Step [462/735], Loss: 0.0265\n",
      "Epoch [32/50], Step [463/735], Loss: 0.0408\n",
      "Epoch [32/50], Step [464/735], Loss: 0.0252\n",
      "Epoch [32/50], Step [465/735], Loss: 0.0335\n",
      "Epoch [32/50], Step [466/735], Loss: 0.0725\n",
      "Epoch [32/50], Step [467/735], Loss: 0.0475\n",
      "Epoch [32/50], Step [468/735], Loss: 0.0451\n",
      "Epoch [32/50], Step [469/735], Loss: 0.3859\n",
      "Epoch [32/50], Step [470/735], Loss: 0.0472\n",
      "Epoch [32/50], Step [471/735], Loss: 0.0817\n",
      "Epoch [32/50], Step [472/735], Loss: 0.0758\n",
      "Epoch [32/50], Step [473/735], Loss: 0.0336\n",
      "Epoch [32/50], Step [474/735], Loss: 0.1239\n",
      "Epoch [32/50], Step [475/735], Loss: 0.0441\n",
      "Epoch [32/50], Step [476/735], Loss: 0.0528\n",
      "Epoch [32/50], Step [477/735], Loss: 0.1128\n",
      "Epoch [32/50], Step [478/735], Loss: 0.0233\n",
      "Epoch [32/50], Step [479/735], Loss: 0.0545\n",
      "Epoch [32/50], Step [480/735], Loss: 0.0479\n",
      "Epoch [32/50], Step [481/735], Loss: 0.4383\n",
      "Epoch [32/50], Step [482/735], Loss: 0.1033\n",
      "Epoch [32/50], Step [483/735], Loss: 0.1582\n",
      "Epoch [32/50], Step [484/735], Loss: 0.0276\n",
      "Epoch [32/50], Step [485/735], Loss: 0.0602\n",
      "Epoch [32/50], Step [486/735], Loss: 0.0847\n",
      "Epoch [32/50], Step [487/735], Loss: 0.0598\n",
      "Epoch [32/50], Step [488/735], Loss: 0.0346\n",
      "Epoch [32/50], Step [489/735], Loss: 0.0510\n",
      "Epoch [32/50], Step [490/735], Loss: 0.1408\n",
      "Epoch [32/50], Step [491/735], Loss: 0.0344\n",
      "Epoch [32/50], Step [492/735], Loss: 0.0228\n",
      "Epoch [32/50], Step [493/735], Loss: 0.0534\n",
      "Epoch [32/50], Step [494/735], Loss: 0.1013\n",
      "Epoch [32/50], Step [495/735], Loss: 0.0321\n",
      "Epoch [32/50], Step [496/735], Loss: 0.0358\n",
      "Epoch [32/50], Step [497/735], Loss: 0.0166\n",
      "Epoch [32/50], Step [498/735], Loss: 0.0334\n",
      "Epoch [32/50], Step [499/735], Loss: 0.0414\n",
      "Epoch [32/50], Step [500/735], Loss: 0.0247\n",
      "Epoch [32/50], Step [501/735], Loss: 0.1109\n",
      "Epoch [32/50], Step [502/735], Loss: 0.0218\n",
      "Epoch [32/50], Step [503/735], Loss: 0.1364\n",
      "Epoch [32/50], Step [504/735], Loss: 0.0253\n",
      "Epoch [32/50], Step [505/735], Loss: 0.0891\n",
      "Epoch [32/50], Step [506/735], Loss: 0.0399\n",
      "Epoch [32/50], Step [507/735], Loss: 0.0352\n",
      "Epoch [32/50], Step [508/735], Loss: 0.0183\n",
      "Epoch [32/50], Step [509/735], Loss: 0.0726\n",
      "Epoch [32/50], Step [510/735], Loss: 0.0583\n",
      "Epoch [32/50], Step [511/735], Loss: 0.0902\n",
      "Epoch [32/50], Step [512/735], Loss: 0.0385\n",
      "Epoch [32/50], Step [513/735], Loss: 0.0312\n",
      "Epoch [32/50], Step [514/735], Loss: 0.1013\n",
      "Epoch [32/50], Step [515/735], Loss: 0.0292\n",
      "Epoch [32/50], Step [516/735], Loss: 0.0345\n",
      "Epoch [32/50], Step [517/735], Loss: 0.0274\n",
      "Epoch [32/50], Step [518/735], Loss: 0.1004\n",
      "Epoch [32/50], Step [519/735], Loss: 0.0188\n",
      "Epoch [32/50], Step [520/735], Loss: 0.0452\n",
      "Epoch [32/50], Step [521/735], Loss: 0.0500\n",
      "Epoch [32/50], Step [522/735], Loss: 0.0314\n",
      "Epoch [32/50], Step [523/735], Loss: 0.0512\n",
      "Epoch [32/50], Step [524/735], Loss: 0.0582\n",
      "Epoch [32/50], Step [525/735], Loss: 0.0294\n",
      "Epoch [32/50], Step [526/735], Loss: 0.0410\n",
      "Epoch [32/50], Step [527/735], Loss: 0.0140\n",
      "Epoch [32/50], Step [528/735], Loss: 0.0179\n",
      "Epoch [32/50], Step [529/735], Loss: 0.0268\n",
      "Epoch [32/50], Step [530/735], Loss: 0.0749\n",
      "Epoch [32/50], Step [531/735], Loss: 0.2708\n",
      "Epoch [32/50], Step [532/735], Loss: 0.0546\n",
      "Epoch [32/50], Step [533/735], Loss: 0.0374\n",
      "Epoch [32/50], Step [534/735], Loss: 0.0497\n",
      "Epoch [32/50], Step [535/735], Loss: 0.0233\n",
      "Epoch [32/50], Step [536/735], Loss: 0.0451\n",
      "Epoch [32/50], Step [537/735], Loss: 0.1037\n",
      "Epoch [32/50], Step [538/735], Loss: 0.1235\n",
      "Epoch [32/50], Step [539/735], Loss: 0.0932\n",
      "Epoch [32/50], Step [540/735], Loss: 0.0249\n",
      "Epoch [32/50], Step [541/735], Loss: 0.0345\n",
      "Epoch [32/50], Step [542/735], Loss: 0.1486\n",
      "Epoch [32/50], Step [543/735], Loss: 0.1348\n",
      "Epoch [32/50], Step [544/735], Loss: 0.0424\n",
      "Epoch [32/50], Step [545/735], Loss: 0.0316\n",
      "Epoch [32/50], Step [546/735], Loss: 0.0842\n",
      "Epoch [32/50], Step [547/735], Loss: 0.0305\n",
      "Epoch [32/50], Step [548/735], Loss: 0.0239\n",
      "Epoch [32/50], Step [549/735], Loss: 0.0463\n",
      "Epoch [32/50], Step [550/735], Loss: 0.0560\n",
      "Epoch [32/50], Step [551/735], Loss: 0.0630\n",
      "Epoch [32/50], Step [552/735], Loss: 0.1004\n",
      "Epoch [32/50], Step [553/735], Loss: 0.0472\n",
      "Epoch [32/50], Step [554/735], Loss: 0.0635\n",
      "Epoch [32/50], Step [555/735], Loss: 0.0699\n",
      "Epoch [32/50], Step [556/735], Loss: 0.0963\n",
      "Epoch [32/50], Step [557/735], Loss: 0.0893\n",
      "Epoch [32/50], Step [558/735], Loss: 0.0624\n",
      "Epoch [32/50], Step [559/735], Loss: 0.0341\n",
      "Epoch [32/50], Step [560/735], Loss: 0.0351\n",
      "Epoch [32/50], Step [561/735], Loss: 0.0401\n",
      "Epoch [32/50], Step [562/735], Loss: 0.0310\n",
      "Epoch [32/50], Step [563/735], Loss: 0.0211\n",
      "Epoch [32/50], Step [564/735], Loss: 0.0218\n",
      "Epoch [32/50], Step [565/735], Loss: 0.0703\n",
      "Epoch [32/50], Step [566/735], Loss: 0.1767\n",
      "Epoch [32/50], Step [567/735], Loss: 0.0431\n",
      "Epoch [32/50], Step [568/735], Loss: 0.0759\n",
      "Epoch [32/50], Step [569/735], Loss: 0.0248\n",
      "Epoch [32/50], Step [570/735], Loss: 0.0388\n",
      "Epoch [32/50], Step [571/735], Loss: 0.0467\n",
      "Epoch [32/50], Step [572/735], Loss: 0.0377\n",
      "Epoch [32/50], Step [573/735], Loss: 0.0715\n",
      "Epoch [32/50], Step [574/735], Loss: 0.0311\n",
      "Epoch [32/50], Step [575/735], Loss: 0.1338\n",
      "Epoch [32/50], Step [576/735], Loss: 0.0704\n",
      "Epoch [32/50], Step [577/735], Loss: 0.0231\n",
      "Epoch [32/50], Step [578/735], Loss: 0.1120\n",
      "Epoch [32/50], Step [579/735], Loss: 0.0569\n",
      "Epoch [32/50], Step [580/735], Loss: 0.0785\n",
      "Epoch [32/50], Step [581/735], Loss: 0.0414\n",
      "Epoch [32/50], Step [582/735], Loss: 0.0694\n",
      "Epoch [32/50], Step [583/735], Loss: 0.0228\n",
      "Epoch [32/50], Step [584/735], Loss: 0.1047\n",
      "Epoch [32/50], Step [585/735], Loss: 0.0198\n",
      "Epoch [32/50], Step [586/735], Loss: 0.0249\n",
      "Epoch [32/50], Step [587/735], Loss: 0.1987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Step [588/735], Loss: 0.0851\n",
      "Epoch [32/50], Step [589/735], Loss: 0.0629\n",
      "Epoch [32/50], Step [590/735], Loss: 0.1051\n",
      "Epoch [32/50], Step [591/735], Loss: 0.0298\n",
      "Epoch [32/50], Step [592/735], Loss: 0.0145\n",
      "Epoch [32/50], Step [593/735], Loss: 0.0889\n",
      "Epoch [32/50], Step [594/735], Loss: 0.0136\n",
      "Epoch [32/50], Step [595/735], Loss: 0.0850\n",
      "Epoch [32/50], Step [596/735], Loss: 0.4449\n",
      "Epoch [32/50], Step [597/735], Loss: 0.1846\n",
      "Epoch [32/50], Step [598/735], Loss: 0.0573\n",
      "Epoch [32/50], Step [599/735], Loss: 0.0708\n",
      "Epoch [32/50], Step [600/735], Loss: 0.0378\n",
      "Epoch [32/50], Step [601/735], Loss: 0.0489\n",
      "Epoch [32/50], Step [602/735], Loss: 0.0729\n",
      "Epoch [32/50], Step [603/735], Loss: 0.0465\n",
      "Epoch [32/50], Step [604/735], Loss: 0.3862\n",
      "Epoch [32/50], Step [605/735], Loss: 0.0312\n",
      "Epoch [32/50], Step [606/735], Loss: 0.0419\n",
      "Epoch [32/50], Step [607/735], Loss: 0.0878\n",
      "Epoch [32/50], Step [608/735], Loss: 0.0781\n",
      "Epoch [32/50], Step [609/735], Loss: 0.0901\n",
      "Epoch [32/50], Step [610/735], Loss: 0.0182\n",
      "Epoch [32/50], Step [611/735], Loss: 0.0564\n",
      "Epoch [32/50], Step [612/735], Loss: 0.0572\n",
      "Epoch [32/50], Step [613/735], Loss: 0.1629\n",
      "Epoch [32/50], Step [614/735], Loss: 0.0534\n",
      "Epoch [32/50], Step [615/735], Loss: 0.0773\n",
      "Epoch [32/50], Step [616/735], Loss: 0.0698\n",
      "Epoch [32/50], Step [617/735], Loss: 0.0799\n",
      "Epoch [32/50], Step [618/735], Loss: 0.2216\n",
      "Epoch [32/50], Step [619/735], Loss: 0.0451\n",
      "Epoch [32/50], Step [620/735], Loss: 0.0803\n",
      "Epoch [32/50], Step [621/735], Loss: 0.0574\n",
      "Epoch [32/50], Step [622/735], Loss: 0.0534\n",
      "Epoch [32/50], Step [623/735], Loss: 0.0405\n",
      "Epoch [32/50], Step [624/735], Loss: 0.0810\n",
      "Epoch [32/50], Step [625/735], Loss: 0.1542\n",
      "Epoch [32/50], Step [626/735], Loss: 0.0442\n",
      "Epoch [32/50], Step [627/735], Loss: 0.0450\n",
      "Epoch [32/50], Step [628/735], Loss: 0.0291\n",
      "Epoch [32/50], Step [629/735], Loss: 0.0583\n",
      "Epoch [32/50], Step [630/735], Loss: 0.1415\n",
      "Epoch [32/50], Step [631/735], Loss: 0.0361\n",
      "Epoch [32/50], Step [632/735], Loss: 0.0343\n",
      "Epoch [32/50], Step [633/735], Loss: 0.0620\n",
      "Epoch [32/50], Step [634/735], Loss: 0.0708\n",
      "Epoch [32/50], Step [635/735], Loss: 0.0524\n",
      "Epoch [32/50], Step [636/735], Loss: 0.1290\n",
      "Epoch [32/50], Step [637/735], Loss: 0.4151\n",
      "Epoch [32/50], Step [638/735], Loss: 0.0775\n",
      "Epoch [32/50], Step [639/735], Loss: 0.0616\n",
      "Epoch [32/50], Step [640/735], Loss: 0.0321\n",
      "Epoch [32/50], Step [641/735], Loss: 0.1288\n",
      "Epoch [32/50], Step [642/735], Loss: 0.0286\n",
      "Epoch [32/50], Step [643/735], Loss: 0.0164\n",
      "Epoch [32/50], Step [644/735], Loss: 0.0389\n",
      "Epoch [32/50], Step [645/735], Loss: 0.0293\n",
      "Epoch [32/50], Step [646/735], Loss: 0.0733\n",
      "Epoch [32/50], Step [647/735], Loss: 0.0480\n",
      "Epoch [32/50], Step [648/735], Loss: 0.0539\n",
      "Epoch [32/50], Step [649/735], Loss: 0.4096\n",
      "Epoch [32/50], Step [650/735], Loss: 0.0432\n",
      "Epoch [32/50], Step [651/735], Loss: 0.0528\n",
      "Epoch [32/50], Step [652/735], Loss: 0.0299\n",
      "Epoch [32/50], Step [653/735], Loss: 0.0190\n",
      "Epoch [32/50], Step [654/735], Loss: 0.1350\n",
      "Epoch [32/50], Step [655/735], Loss: 0.0164\n",
      "Epoch [32/50], Step [656/735], Loss: 0.0806\n",
      "Epoch [32/50], Step [657/735], Loss: 0.0579\n",
      "Epoch [32/50], Step [658/735], Loss: 0.0327\n",
      "Epoch [32/50], Step [659/735], Loss: 0.0631\n",
      "Epoch [32/50], Step [660/735], Loss: 0.0499\n",
      "Epoch [32/50], Step [661/735], Loss: 0.0511\n",
      "Epoch [32/50], Step [662/735], Loss: 0.0503\n",
      "Epoch [32/50], Step [663/735], Loss: 0.0718\n",
      "Epoch [32/50], Step [664/735], Loss: 0.0615\n",
      "Epoch [32/50], Step [665/735], Loss: 0.0719\n",
      "Epoch [32/50], Step [666/735], Loss: 0.0464\n",
      "Epoch [32/50], Step [667/735], Loss: 0.0297\n",
      "Epoch [32/50], Step [668/735], Loss: 0.0429\n",
      "Epoch [32/50], Step [669/735], Loss: 0.0536\n",
      "Epoch [32/50], Step [670/735], Loss: 0.0324\n",
      "Epoch [32/50], Step [671/735], Loss: 0.0887\n",
      "Epoch [32/50], Step [672/735], Loss: 0.0298\n",
      "Epoch [32/50], Step [673/735], Loss: 0.0181\n",
      "Epoch [32/50], Step [674/735], Loss: 0.0670\n",
      "Epoch [32/50], Step [675/735], Loss: 0.0235\n",
      "Epoch [32/50], Step [676/735], Loss: 0.0755\n",
      "Epoch [32/50], Step [677/735], Loss: 0.0256\n",
      "Epoch [32/50], Step [678/735], Loss: 0.0425\n",
      "Epoch [32/50], Step [679/735], Loss: 0.0544\n",
      "Epoch [32/50], Step [680/735], Loss: 0.0366\n",
      "Epoch [32/50], Step [681/735], Loss: 0.0954\n",
      "Epoch [32/50], Step [682/735], Loss: 0.0274\n",
      "Epoch [32/50], Step [683/735], Loss: 0.0433\n",
      "Epoch [32/50], Step [684/735], Loss: 0.0267\n",
      "Epoch [32/50], Step [685/735], Loss: 0.0433\n",
      "Epoch [32/50], Step [686/735], Loss: 0.0493\n",
      "Epoch [32/50], Step [687/735], Loss: 0.0657\n",
      "Epoch [32/50], Step [688/735], Loss: 0.0331\n",
      "Epoch [32/50], Step [689/735], Loss: 0.0740\n",
      "Epoch [32/50], Step [690/735], Loss: 0.0750\n",
      "Epoch [32/50], Step [691/735], Loss: 0.2469\n",
      "Epoch [32/50], Step [692/735], Loss: 0.0955\n",
      "Epoch [32/50], Step [693/735], Loss: 0.0219\n",
      "Epoch [32/50], Step [694/735], Loss: 0.0849\n",
      "Epoch [32/50], Step [695/735], Loss: 0.0480\n",
      "Epoch [32/50], Step [696/735], Loss: 0.1760\n",
      "Epoch [32/50], Step [697/735], Loss: 0.1019\n",
      "Epoch [32/50], Step [698/735], Loss: 0.1582\n",
      "Epoch [32/50], Step [699/735], Loss: 0.0199\n",
      "Epoch [32/50], Step [700/735], Loss: 0.1154\n",
      "Epoch [32/50], Step [701/735], Loss: 0.3581\n",
      "Epoch [32/50], Step [702/735], Loss: 0.0338\n",
      "Epoch [32/50], Step [703/735], Loss: 0.0514\n",
      "Epoch [32/50], Step [704/735], Loss: 0.0204\n",
      "Epoch [32/50], Step [705/735], Loss: 0.0182\n",
      "Epoch [32/50], Step [706/735], Loss: 0.0436\n",
      "Epoch [32/50], Step [707/735], Loss: 0.0417\n",
      "Epoch [32/50], Step [708/735], Loss: 0.0303\n",
      "Epoch [32/50], Step [709/735], Loss: 0.0240\n",
      "Epoch [32/50], Step [710/735], Loss: 0.0265\n",
      "Epoch [32/50], Step [711/735], Loss: 0.1939\n",
      "Epoch [32/50], Step [712/735], Loss: 0.0918\n",
      "Epoch [32/50], Step [713/735], Loss: 0.0144\n",
      "Epoch [32/50], Step [714/735], Loss: 0.0300\n",
      "Epoch [32/50], Step [715/735], Loss: 0.0441\n",
      "Epoch [32/50], Step [716/735], Loss: 0.0278\n",
      "Epoch [32/50], Step [717/735], Loss: 0.0664\n",
      "Epoch [32/50], Step [718/735], Loss: 0.0190\n",
      "Epoch [32/50], Step [719/735], Loss: 0.0590\n",
      "Epoch [32/50], Step [720/735], Loss: 0.0176\n",
      "Epoch [32/50], Step [721/735], Loss: 0.0432\n",
      "Epoch [32/50], Step [722/735], Loss: 0.0476\n",
      "Epoch [32/50], Step [723/735], Loss: 0.0644\n",
      "Epoch [32/50], Step [724/735], Loss: 0.0428\n",
      "Epoch [32/50], Step [725/735], Loss: 0.2109\n",
      "Epoch [32/50], Step [726/735], Loss: 0.0352\n",
      "Epoch [32/50], Step [727/735], Loss: 0.2759\n",
      "Epoch [32/50], Step [728/735], Loss: 0.0364\n",
      "Epoch [32/50], Step [729/735], Loss: 0.0143\n",
      "Epoch [32/50], Step [730/735], Loss: 0.0561\n",
      "Epoch [32/50], Step [731/735], Loss: 0.0486\n",
      "Epoch [32/50], Step [732/735], Loss: 0.0899\n",
      "Epoch [32/50], Step [733/735], Loss: 0.0623\n",
      "Epoch [32/50], Step [734/735], Loss: 0.0301\n",
      "Epoch [32/50], Step [735/735], Loss: 0.0693\n",
      "Epoch [33/50], Step [1/735], Loss: 0.0524\n",
      "Epoch [33/50], Step [2/735], Loss: 0.0359\n",
      "Epoch [33/50], Step [3/735], Loss: 0.0549\n",
      "Epoch [33/50], Step [4/735], Loss: 0.0265\n",
      "Epoch [33/50], Step [5/735], Loss: 0.0640\n",
      "Epoch [33/50], Step [6/735], Loss: 0.0487\n",
      "Epoch [33/50], Step [7/735], Loss: 0.0317\n",
      "Epoch [33/50], Step [8/735], Loss: 0.0709\n",
      "Epoch [33/50], Step [9/735], Loss: 0.0815\n",
      "Epoch [33/50], Step [10/735], Loss: 0.0775\n",
      "Epoch [33/50], Step [11/735], Loss: 0.0646\n",
      "Epoch [33/50], Step [12/735], Loss: 0.0293\n",
      "Epoch [33/50], Step [13/735], Loss: 0.2993\n",
      "Epoch [33/50], Step [14/735], Loss: 0.0387\n",
      "Epoch [33/50], Step [15/735], Loss: 0.0253\n",
      "Epoch [33/50], Step [16/735], Loss: 0.0357\n",
      "Epoch [33/50], Step [17/735], Loss: 0.0469\n",
      "Epoch [33/50], Step [18/735], Loss: 0.3267\n",
      "Epoch [33/50], Step [19/735], Loss: 0.0343\n",
      "Epoch [33/50], Step [20/735], Loss: 0.0567\n",
      "Epoch [33/50], Step [21/735], Loss: 0.0355\n",
      "Epoch [33/50], Step [22/735], Loss: 0.0337\n",
      "Epoch [33/50], Step [23/735], Loss: 0.0375\n",
      "Epoch [33/50], Step [24/735], Loss: 0.0340\n",
      "Epoch [33/50], Step [25/735], Loss: 0.0569\n",
      "Epoch [33/50], Step [26/735], Loss: 0.0511\n",
      "Epoch [33/50], Step [27/735], Loss: 0.0761\n",
      "Epoch [33/50], Step [28/735], Loss: 0.0778\n",
      "Epoch [33/50], Step [29/735], Loss: 0.0243\n",
      "Epoch [33/50], Step [30/735], Loss: 0.0575\n",
      "Epoch [33/50], Step [31/735], Loss: 0.0234\n",
      "Epoch [33/50], Step [32/735], Loss: 0.0396\n",
      "Epoch [33/50], Step [33/735], Loss: 0.0454\n",
      "Epoch [33/50], Step [34/735], Loss: 0.0351\n",
      "Epoch [33/50], Step [35/735], Loss: 0.0139\n",
      "Epoch [33/50], Step [36/735], Loss: 0.0479\n",
      "Epoch [33/50], Step [37/735], Loss: 0.0684\n",
      "Epoch [33/50], Step [38/735], Loss: 0.0436\n",
      "Epoch [33/50], Step [39/735], Loss: 0.0201\n",
      "Epoch [33/50], Step [40/735], Loss: 0.0237\n",
      "Epoch [33/50], Step [41/735], Loss: 0.1810\n",
      "Epoch [33/50], Step [42/735], Loss: 0.0378\n",
      "Epoch [33/50], Step [43/735], Loss: 0.0236\n",
      "Epoch [33/50], Step [44/735], Loss: 0.1796\n",
      "Epoch [33/50], Step [45/735], Loss: 0.0906\n",
      "Epoch [33/50], Step [46/735], Loss: 0.0310\n",
      "Epoch [33/50], Step [47/735], Loss: 0.0781\n",
      "Epoch [33/50], Step [48/735], Loss: 0.1707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Step [49/735], Loss: 0.1609\n",
      "Epoch [33/50], Step [50/735], Loss: 0.0360\n",
      "Epoch [33/50], Step [51/735], Loss: 0.0425\n",
      "Epoch [33/50], Step [52/735], Loss: 0.0268\n",
      "Epoch [33/50], Step [53/735], Loss: 0.0774\n",
      "Epoch [33/50], Step [54/735], Loss: 0.0237\n",
      "Epoch [33/50], Step [55/735], Loss: 0.0727\n",
      "Epoch [33/50], Step [56/735], Loss: 0.0341\n",
      "Epoch [33/50], Step [57/735], Loss: 0.0741\n",
      "Epoch [33/50], Step [58/735], Loss: 0.0656\n",
      "Epoch [33/50], Step [59/735], Loss: 0.0707\n",
      "Epoch [33/50], Step [60/735], Loss: 0.0486\n",
      "Epoch [33/50], Step [61/735], Loss: 0.1440\n",
      "Epoch [33/50], Step [62/735], Loss: 0.0231\n",
      "Epoch [33/50], Step [63/735], Loss: 0.0947\n",
      "Epoch [33/50], Step [64/735], Loss: 0.2092\n",
      "Epoch [33/50], Step [65/735], Loss: 0.1890\n",
      "Epoch [33/50], Step [66/735], Loss: 0.1041\n",
      "Epoch [33/50], Step [67/735], Loss: 0.0401\n",
      "Epoch [33/50], Step [68/735], Loss: 0.0970\n",
      "Epoch [33/50], Step [69/735], Loss: 0.1594\n",
      "Epoch [33/50], Step [70/735], Loss: 0.0722\n",
      "Epoch [33/50], Step [71/735], Loss: 0.1054\n",
      "Epoch [33/50], Step [72/735], Loss: 0.0447\n",
      "Epoch [33/50], Step [73/735], Loss: 0.1067\n",
      "Epoch [33/50], Step [74/735], Loss: 0.0506\n",
      "Epoch [33/50], Step [75/735], Loss: 0.1052\n",
      "Epoch [33/50], Step [76/735], Loss: 0.0681\n",
      "Epoch [33/50], Step [77/735], Loss: 0.1543\n",
      "Epoch [33/50], Step [78/735], Loss: 0.0383\n",
      "Epoch [33/50], Step [79/735], Loss: 0.2973\n",
      "Epoch [33/50], Step [80/735], Loss: 0.1019\n",
      "Epoch [33/50], Step [81/735], Loss: 0.0261\n",
      "Epoch [33/50], Step [82/735], Loss: 0.0584\n",
      "Epoch [33/50], Step [83/735], Loss: 0.0542\n",
      "Epoch [33/50], Step [84/735], Loss: 0.1706\n",
      "Epoch [33/50], Step [85/735], Loss: 0.0784\n",
      "Epoch [33/50], Step [86/735], Loss: 0.0532\n",
      "Epoch [33/50], Step [87/735], Loss: 0.0353\n",
      "Epoch [33/50], Step [88/735], Loss: 0.0422\n",
      "Epoch [33/50], Step [89/735], Loss: 0.2126\n",
      "Epoch [33/50], Step [90/735], Loss: 0.0718\n",
      "Epoch [33/50], Step [91/735], Loss: 0.0620\n",
      "Epoch [33/50], Step [92/735], Loss: 0.0259\n",
      "Epoch [33/50], Step [93/735], Loss: 0.0493\n",
      "Epoch [33/50], Step [94/735], Loss: 0.0696\n",
      "Epoch [33/50], Step [95/735], Loss: 0.0679\n",
      "Epoch [33/50], Step [96/735], Loss: 0.0379\n",
      "Epoch [33/50], Step [97/735], Loss: 0.0703\n",
      "Epoch [33/50], Step [98/735], Loss: 0.1000\n",
      "Epoch [33/50], Step [99/735], Loss: 0.0465\n",
      "Epoch [33/50], Step [100/735], Loss: 0.0433\n",
      "Epoch [33/50], Step [101/735], Loss: 0.0698\n",
      "Epoch [33/50], Step [102/735], Loss: 0.0646\n",
      "Epoch [33/50], Step [103/735], Loss: 0.0523\n",
      "Epoch [33/50], Step [104/735], Loss: 0.0253\n",
      "Epoch [33/50], Step [105/735], Loss: 0.0287\n",
      "Epoch [33/50], Step [106/735], Loss: 0.0628\n",
      "Epoch [33/50], Step [107/735], Loss: 0.0993\n",
      "Epoch [33/50], Step [108/735], Loss: 0.0660\n",
      "Epoch [33/50], Step [109/735], Loss: 0.0378\n",
      "Epoch [33/50], Step [110/735], Loss: 0.0595\n",
      "Epoch [33/50], Step [111/735], Loss: 0.0414\n",
      "Epoch [33/50], Step [112/735], Loss: 0.0446\n",
      "Epoch [33/50], Step [113/735], Loss: 0.0731\n",
      "Epoch [33/50], Step [114/735], Loss: 0.0884\n",
      "Epoch [33/50], Step [115/735], Loss: 0.0281\n",
      "Epoch [33/50], Step [116/735], Loss: 0.0350\n",
      "Epoch [33/50], Step [117/735], Loss: 0.0387\n",
      "Epoch [33/50], Step [118/735], Loss: 0.0470\n",
      "Epoch [33/50], Step [119/735], Loss: 0.0811\n",
      "Epoch [33/50], Step [120/735], Loss: 0.0482\n",
      "Epoch [33/50], Step [121/735], Loss: 0.1056\n",
      "Epoch [33/50], Step [122/735], Loss: 0.0635\n",
      "Epoch [33/50], Step [123/735], Loss: 0.0919\n",
      "Epoch [33/50], Step [124/735], Loss: 0.0899\n",
      "Epoch [33/50], Step [125/735], Loss: 0.1412\n",
      "Epoch [33/50], Step [126/735], Loss: 0.0782\n",
      "Epoch [33/50], Step [127/735], Loss: 0.0608\n",
      "Epoch [33/50], Step [128/735], Loss: 0.0242\n",
      "Epoch [33/50], Step [129/735], Loss: 0.1254\n",
      "Epoch [33/50], Step [130/735], Loss: 0.0375\n",
      "Epoch [33/50], Step [131/735], Loss: 0.0600\n",
      "Epoch [33/50], Step [132/735], Loss: 0.0177\n",
      "Epoch [33/50], Step [133/735], Loss: 0.0695\n",
      "Epoch [33/50], Step [134/735], Loss: 0.1482\n",
      "Epoch [33/50], Step [135/735], Loss: 0.0495\n",
      "Epoch [33/50], Step [136/735], Loss: 0.0952\n",
      "Epoch [33/50], Step [137/735], Loss: 0.0517\n",
      "Epoch [33/50], Step [138/735], Loss: 0.0397\n",
      "Epoch [33/50], Step [139/735], Loss: 0.0512\n",
      "Epoch [33/50], Step [140/735], Loss: 0.0223\n",
      "Epoch [33/50], Step [141/735], Loss: 0.0535\n",
      "Epoch [33/50], Step [142/735], Loss: 0.0350\n",
      "Epoch [33/50], Step [143/735], Loss: 0.0350\n",
      "Epoch [33/50], Step [144/735], Loss: 0.0935\n",
      "Epoch [33/50], Step [145/735], Loss: 0.0229\n",
      "Epoch [33/50], Step [146/735], Loss: 0.0560\n",
      "Epoch [33/50], Step [147/735], Loss: 0.1485\n",
      "Epoch [33/50], Step [148/735], Loss: 0.0519\n",
      "Epoch [33/50], Step [149/735], Loss: 0.1202\n",
      "Epoch [33/50], Step [150/735], Loss: 0.0396\n",
      "Epoch [33/50], Step [151/735], Loss: 0.0480\n",
      "Epoch [33/50], Step [152/735], Loss: 0.0508\n",
      "Epoch [33/50], Step [153/735], Loss: 0.0557\n",
      "Epoch [33/50], Step [154/735], Loss: 0.0573\n",
      "Epoch [33/50], Step [155/735], Loss: 0.0525\n",
      "Epoch [33/50], Step [156/735], Loss: 0.0752\n",
      "Epoch [33/50], Step [157/735], Loss: 0.0622\n",
      "Epoch [33/50], Step [158/735], Loss: 0.2014\n",
      "Epoch [33/50], Step [159/735], Loss: 0.0652\n",
      "Epoch [33/50], Step [160/735], Loss: 0.0677\n",
      "Epoch [33/50], Step [161/735], Loss: 0.0703\n",
      "Epoch [33/50], Step [162/735], Loss: 0.0629\n",
      "Epoch [33/50], Step [163/735], Loss: 0.0997\n",
      "Epoch [33/50], Step [164/735], Loss: 0.0467\n",
      "Epoch [33/50], Step [165/735], Loss: 0.0179\n",
      "Epoch [33/50], Step [166/735], Loss: 0.1120\n",
      "Epoch [33/50], Step [167/735], Loss: 0.0916\n",
      "Epoch [33/50], Step [168/735], Loss: 0.0612\n",
      "Epoch [33/50], Step [169/735], Loss: 0.0384\n",
      "Epoch [33/50], Step [170/735], Loss: 0.0564\n",
      "Epoch [33/50], Step [171/735], Loss: 0.0276\n",
      "Epoch [33/50], Step [172/735], Loss: 0.0623\n",
      "Epoch [33/50], Step [173/735], Loss: 0.0741\n",
      "Epoch [33/50], Step [174/735], Loss: 0.1364\n",
      "Epoch [33/50], Step [175/735], Loss: 0.0684\n",
      "Epoch [33/50], Step [176/735], Loss: 0.0254\n",
      "Epoch [33/50], Step [177/735], Loss: 0.2881\n",
      "Epoch [33/50], Step [178/735], Loss: 0.1664\n",
      "Epoch [33/50], Step [179/735], Loss: 0.0386\n",
      "Epoch [33/50], Step [180/735], Loss: 0.0197\n",
      "Epoch [33/50], Step [181/735], Loss: 0.0251\n",
      "Epoch [33/50], Step [182/735], Loss: 0.0569\n",
      "Epoch [33/50], Step [183/735], Loss: 0.0232\n",
      "Epoch [33/50], Step [184/735], Loss: 0.0682\n",
      "Epoch [33/50], Step [185/735], Loss: 0.0179\n",
      "Epoch [33/50], Step [186/735], Loss: 0.1399\n",
      "Epoch [33/50], Step [187/735], Loss: 0.0354\n",
      "Epoch [33/50], Step [188/735], Loss: 0.1216\n",
      "Epoch [33/50], Step [189/735], Loss: 0.0780\n",
      "Epoch [33/50], Step [190/735], Loss: 0.0335\n",
      "Epoch [33/50], Step [191/735], Loss: 0.0658\n",
      "Epoch [33/50], Step [192/735], Loss: 0.1054\n",
      "Epoch [33/50], Step [193/735], Loss: 0.0175\n",
      "Epoch [33/50], Step [194/735], Loss: 0.0383\n",
      "Epoch [33/50], Step [195/735], Loss: 0.2077\n",
      "Epoch [33/50], Step [196/735], Loss: 0.0268\n",
      "Epoch [33/50], Step [197/735], Loss: 0.0247\n",
      "Epoch [33/50], Step [198/735], Loss: 0.0573\n",
      "Epoch [33/50], Step [199/735], Loss: 0.0300\n",
      "Epoch [33/50], Step [200/735], Loss: 0.0354\n",
      "Epoch [33/50], Step [201/735], Loss: 0.0370\n",
      "Epoch [33/50], Step [202/735], Loss: 0.0637\n",
      "Epoch [33/50], Step [203/735], Loss: 0.0470\n",
      "Epoch [33/50], Step [204/735], Loss: 0.0794\n",
      "Epoch [33/50], Step [205/735], Loss: 0.0332\n",
      "Epoch [33/50], Step [206/735], Loss: 0.0845\n",
      "Epoch [33/50], Step [207/735], Loss: 0.0628\n",
      "Epoch [33/50], Step [208/735], Loss: 0.0287\n",
      "Epoch [33/50], Step [209/735], Loss: 0.0599\n",
      "Epoch [33/50], Step [210/735], Loss: 0.0882\n",
      "Epoch [33/50], Step [211/735], Loss: 0.0288\n",
      "Epoch [33/50], Step [212/735], Loss: 0.0238\n",
      "Epoch [33/50], Step [213/735], Loss: 0.0739\n",
      "Epoch [33/50], Step [214/735], Loss: 0.0442\n",
      "Epoch [33/50], Step [215/735], Loss: 0.0654\n",
      "Epoch [33/50], Step [216/735], Loss: 0.0550\n",
      "Epoch [33/50], Step [217/735], Loss: 0.0295\n",
      "Epoch [33/50], Step [218/735], Loss: 0.0373\n",
      "Epoch [33/50], Step [219/735], Loss: 0.0361\n",
      "Epoch [33/50], Step [220/735], Loss: 0.0261\n",
      "Epoch [33/50], Step [221/735], Loss: 0.1737\n",
      "Epoch [33/50], Step [222/735], Loss: 0.1237\n",
      "Epoch [33/50], Step [223/735], Loss: 0.0603\n",
      "Epoch [33/50], Step [224/735], Loss: 0.0500\n",
      "Epoch [33/50], Step [225/735], Loss: 0.1353\n",
      "Epoch [33/50], Step [226/735], Loss: 0.0572\n",
      "Epoch [33/50], Step [227/735], Loss: 0.0933\n",
      "Epoch [33/50], Step [228/735], Loss: 0.0611\n",
      "Epoch [33/50], Step [229/735], Loss: 0.0824\n",
      "Epoch [33/50], Step [230/735], Loss: 0.1066\n",
      "Epoch [33/50], Step [231/735], Loss: 0.0442\n",
      "Epoch [33/50], Step [232/735], Loss: 0.0202\n",
      "Epoch [33/50], Step [233/735], Loss: 0.0304\n",
      "Epoch [33/50], Step [234/735], Loss: 0.1520\n",
      "Epoch [33/50], Step [235/735], Loss: 0.0258\n",
      "Epoch [33/50], Step [236/735], Loss: 0.0506\n",
      "Epoch [33/50], Step [237/735], Loss: 0.0668\n",
      "Epoch [33/50], Step [238/735], Loss: 0.0633\n",
      "Epoch [33/50], Step [239/735], Loss: 0.0269\n",
      "Epoch [33/50], Step [240/735], Loss: 0.0671\n",
      "Epoch [33/50], Step [241/735], Loss: 0.0615\n",
      "Epoch [33/50], Step [242/735], Loss: 0.0199\n",
      "Epoch [33/50], Step [243/735], Loss: 0.0721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Step [244/735], Loss: 0.1144\n",
      "Epoch [33/50], Step [245/735], Loss: 0.0468\n",
      "Epoch [33/50], Step [246/735], Loss: 0.2070\n",
      "Epoch [33/50], Step [247/735], Loss: 0.3051\n",
      "Epoch [33/50], Step [248/735], Loss: 0.0417\n",
      "Epoch [33/50], Step [249/735], Loss: 0.0659\n",
      "Epoch [33/50], Step [250/735], Loss: 0.0242\n",
      "Epoch [33/50], Step [251/735], Loss: 0.0353\n",
      "Epoch [33/50], Step [252/735], Loss: 0.0991\n",
      "Epoch [33/50], Step [253/735], Loss: 0.0480\n",
      "Epoch [33/50], Step [254/735], Loss: 0.0287\n",
      "Epoch [33/50], Step [255/735], Loss: 0.0333\n",
      "Epoch [33/50], Step [256/735], Loss: 0.1160\n",
      "Epoch [33/50], Step [257/735], Loss: 0.0915\n",
      "Epoch [33/50], Step [258/735], Loss: 0.0305\n",
      "Epoch [33/50], Step [259/735], Loss: 0.0643\n",
      "Epoch [33/50], Step [260/735], Loss: 0.0370\n",
      "Epoch [33/50], Step [261/735], Loss: 0.0442\n",
      "Epoch [33/50], Step [262/735], Loss: 0.0321\n",
      "Epoch [33/50], Step [263/735], Loss: 0.0307\n",
      "Epoch [33/50], Step [264/735], Loss: 0.0332\n",
      "Epoch [33/50], Step [265/735], Loss: 0.1974\n",
      "Epoch [33/50], Step [266/735], Loss: 0.1607\n",
      "Epoch [33/50], Step [267/735], Loss: 0.0217\n",
      "Epoch [33/50], Step [268/735], Loss: 0.0651\n",
      "Epoch [33/50], Step [269/735], Loss: 0.0207\n",
      "Epoch [33/50], Step [270/735], Loss: 0.1436\n",
      "Epoch [33/50], Step [271/735], Loss: 0.0158\n",
      "Epoch [33/50], Step [272/735], Loss: 0.0190\n",
      "Epoch [33/50], Step [273/735], Loss: 0.1284\n",
      "Epoch [33/50], Step [274/735], Loss: 0.0260\n",
      "Epoch [33/50], Step [275/735], Loss: 0.0372\n",
      "Epoch [33/50], Step [276/735], Loss: 0.0291\n",
      "Epoch [33/50], Step [277/735], Loss: 0.0330\n",
      "Epoch [33/50], Step [278/735], Loss: 0.0386\n",
      "Epoch [33/50], Step [279/735], Loss: 0.0225\n",
      "Epoch [33/50], Step [280/735], Loss: 0.0319\n",
      "Epoch [33/50], Step [281/735], Loss: 0.0134\n",
      "Epoch [33/50], Step [282/735], Loss: 0.0229\n",
      "Epoch [33/50], Step [283/735], Loss: 0.0312\n",
      "Epoch [33/50], Step [284/735], Loss: 0.0934\n",
      "Epoch [33/50], Step [285/735], Loss: 0.0556\n",
      "Epoch [33/50], Step [286/735], Loss: 0.0377\n",
      "Epoch [33/50], Step [287/735], Loss: 0.0187\n",
      "Epoch [33/50], Step [288/735], Loss: 0.0206\n",
      "Epoch [33/50], Step [289/735], Loss: 0.0552\n",
      "Epoch [33/50], Step [290/735], Loss: 0.0326\n",
      "Epoch [33/50], Step [291/735], Loss: 0.0998\n",
      "Epoch [33/50], Step [292/735], Loss: 0.0303\n",
      "Epoch [33/50], Step [293/735], Loss: 0.0512\n",
      "Epoch [33/50], Step [294/735], Loss: 0.0481\n",
      "Epoch [33/50], Step [295/735], Loss: 0.0535\n",
      "Epoch [33/50], Step [296/735], Loss: 0.0931\n",
      "Epoch [33/50], Step [297/735], Loss: 0.0690\n",
      "Epoch [33/50], Step [298/735], Loss: 0.0353\n",
      "Epoch [33/50], Step [299/735], Loss: 0.0555\n",
      "Epoch [33/50], Step [300/735], Loss: 0.1204\n",
      "Epoch [33/50], Step [301/735], Loss: 0.0477\n",
      "Epoch [33/50], Step [302/735], Loss: 0.1192\n",
      "Epoch [33/50], Step [303/735], Loss: 0.0429\n",
      "Epoch [33/50], Step [304/735], Loss: 0.0572\n",
      "Epoch [33/50], Step [305/735], Loss: 0.0381\n",
      "Epoch [33/50], Step [306/735], Loss: 0.0359\n",
      "Epoch [33/50], Step [307/735], Loss: 0.0927\n",
      "Epoch [33/50], Step [308/735], Loss: 0.1005\n",
      "Epoch [33/50], Step [309/735], Loss: 0.0743\n",
      "Epoch [33/50], Step [310/735], Loss: 0.0461\n",
      "Epoch [33/50], Step [311/735], Loss: 0.0401\n",
      "Epoch [33/50], Step [312/735], Loss: 0.0373\n",
      "Epoch [33/50], Step [313/735], Loss: 0.0372\n",
      "Epoch [33/50], Step [314/735], Loss: 0.0328\n",
      "Epoch [33/50], Step [315/735], Loss: 0.0830\n",
      "Epoch [33/50], Step [316/735], Loss: 0.0698\n",
      "Epoch [33/50], Step [317/735], Loss: 0.0331\n",
      "Epoch [33/50], Step [318/735], Loss: 0.4590\n",
      "Epoch [33/50], Step [319/735], Loss: 0.0813\n",
      "Epoch [33/50], Step [320/735], Loss: 0.0315\n",
      "Epoch [33/50], Step [321/735], Loss: 0.0441\n",
      "Epoch [33/50], Step [322/735], Loss: 0.1138\n",
      "Epoch [33/50], Step [323/735], Loss: 0.0371\n",
      "Epoch [33/50], Step [324/735], Loss: 0.0718\n",
      "Epoch [33/50], Step [325/735], Loss: 0.0759\n",
      "Epoch [33/50], Step [326/735], Loss: 0.0759\n",
      "Epoch [33/50], Step [327/735], Loss: 0.1440\n",
      "Epoch [33/50], Step [328/735], Loss: 0.0496\n",
      "Epoch [33/50], Step [329/735], Loss: 0.1313\n",
      "Epoch [33/50], Step [330/735], Loss: 0.0873\n",
      "Epoch [33/50], Step [331/735], Loss: 0.0959\n",
      "Epoch [33/50], Step [332/735], Loss: 0.0489\n",
      "Epoch [33/50], Step [333/735], Loss: 0.2327\n",
      "Epoch [33/50], Step [334/735], Loss: 0.0292\n",
      "Epoch [33/50], Step [335/735], Loss: 0.0407\n",
      "Epoch [33/50], Step [336/735], Loss: 0.0644\n",
      "Epoch [33/50], Step [337/735], Loss: 0.0616\n",
      "Epoch [33/50], Step [338/735], Loss: 0.0806\n",
      "Epoch [33/50], Step [339/735], Loss: 0.1182\n",
      "Epoch [33/50], Step [340/735], Loss: 0.0393\n",
      "Epoch [33/50], Step [341/735], Loss: 0.0711\n",
      "Epoch [33/50], Step [342/735], Loss: 0.0462\n",
      "Epoch [33/50], Step [343/735], Loss: 0.0223\n",
      "Epoch [33/50], Step [344/735], Loss: 0.0409\n",
      "Epoch [33/50], Step [345/735], Loss: 0.0421\n",
      "Epoch [33/50], Step [346/735], Loss: 0.0603\n",
      "Epoch [33/50], Step [347/735], Loss: 0.1004\n",
      "Epoch [33/50], Step [348/735], Loss: 0.0252\n",
      "Epoch [33/50], Step [349/735], Loss: 0.0852\n",
      "Epoch [33/50], Step [350/735], Loss: 0.3046\n",
      "Epoch [33/50], Step [351/735], Loss: 0.0356\n",
      "Epoch [33/50], Step [352/735], Loss: 0.0496\n",
      "Epoch [33/50], Step [353/735], Loss: 0.0619\n",
      "Epoch [33/50], Step [354/735], Loss: 0.0271\n",
      "Epoch [33/50], Step [355/735], Loss: 0.0965\n",
      "Epoch [33/50], Step [356/735], Loss: 0.0421\n",
      "Epoch [33/50], Step [357/735], Loss: 0.1193\n",
      "Epoch [33/50], Step [358/735], Loss: 0.0301\n",
      "Epoch [33/50], Step [359/735], Loss: 0.0590\n",
      "Epoch [33/50], Step [360/735], Loss: 0.0331\n",
      "Epoch [33/50], Step [361/735], Loss: 0.0756\n",
      "Epoch [33/50], Step [362/735], Loss: 0.1031\n",
      "Epoch [33/50], Step [363/735], Loss: 0.0737\n",
      "Epoch [33/50], Step [364/735], Loss: 0.0725\n",
      "Epoch [33/50], Step [365/735], Loss: 0.2017\n",
      "Epoch [33/50], Step [366/735], Loss: 0.0514\n",
      "Epoch [33/50], Step [367/735], Loss: 0.0229\n",
      "Epoch [33/50], Step [368/735], Loss: 0.0585\n",
      "Epoch [33/50], Step [369/735], Loss: 0.0291\n",
      "Epoch [33/50], Step [370/735], Loss: 0.0640\n",
      "Epoch [33/50], Step [371/735], Loss: 0.0583\n",
      "Epoch [33/50], Step [372/735], Loss: 0.0816\n",
      "Epoch [33/50], Step [373/735], Loss: 0.0578\n",
      "Epoch [33/50], Step [374/735], Loss: 0.0336\n",
      "Epoch [33/50], Step [375/735], Loss: 0.0316\n",
      "Epoch [33/50], Step [376/735], Loss: 0.0704\n",
      "Epoch [33/50], Step [377/735], Loss: 0.0312\n",
      "Epoch [33/50], Step [378/735], Loss: 0.0342\n",
      "Epoch [33/50], Step [379/735], Loss: 0.0705\n",
      "Epoch [33/50], Step [380/735], Loss: 0.1031\n",
      "Epoch [33/50], Step [381/735], Loss: 0.0156\n",
      "Epoch [33/50], Step [382/735], Loss: 0.1172\n",
      "Epoch [33/50], Step [383/735], Loss: 0.0339\n",
      "Epoch [33/50], Step [384/735], Loss: 0.0196\n",
      "Epoch [33/50], Step [385/735], Loss: 0.0313\n",
      "Epoch [33/50], Step [386/735], Loss: 0.0193\n",
      "Epoch [33/50], Step [387/735], Loss: 0.0684\n",
      "Epoch [33/50], Step [388/735], Loss: 0.0344\n",
      "Epoch [33/50], Step [389/735], Loss: 0.0366\n",
      "Epoch [33/50], Step [390/735], Loss: 0.0637\n",
      "Epoch [33/50], Step [391/735], Loss: 0.0410\n",
      "Epoch [33/50], Step [392/735], Loss: 0.0238\n",
      "Epoch [33/50], Step [393/735], Loss: 0.0605\n",
      "Epoch [33/50], Step [394/735], Loss: 0.0684\n",
      "Epoch [33/50], Step [395/735], Loss: 0.0243\n",
      "Epoch [33/50], Step [396/735], Loss: 0.0419\n",
      "Epoch [33/50], Step [397/735], Loss: 0.0329\n",
      "Epoch [33/50], Step [398/735], Loss: 0.0765\n",
      "Epoch [33/50], Step [399/735], Loss: 0.0553\n",
      "Epoch [33/50], Step [400/735], Loss: 0.0371\n",
      "Epoch [33/50], Step [401/735], Loss: 0.0224\n",
      "Epoch [33/50], Step [402/735], Loss: 0.0470\n",
      "Epoch [33/50], Step [403/735], Loss: 0.0185\n",
      "Epoch [33/50], Step [404/735], Loss: 0.0837\n",
      "Epoch [33/50], Step [405/735], Loss: 0.0199\n",
      "Epoch [33/50], Step [406/735], Loss: 0.1145\n",
      "Epoch [33/50], Step [407/735], Loss: 0.0968\n",
      "Epoch [33/50], Step [408/735], Loss: 0.2438\n",
      "Epoch [33/50], Step [409/735], Loss: 0.0261\n",
      "Epoch [33/50], Step [410/735], Loss: 0.0510\n",
      "Epoch [33/50], Step [411/735], Loss: 0.0260\n",
      "Epoch [33/50], Step [412/735], Loss: 0.0426\n",
      "Epoch [33/50], Step [413/735], Loss: 0.0418\n",
      "Epoch [33/50], Step [414/735], Loss: 0.0276\n",
      "Epoch [33/50], Step [415/735], Loss: 0.0234\n",
      "Epoch [33/50], Step [416/735], Loss: 0.0827\n",
      "Epoch [33/50], Step [417/735], Loss: 0.1430\n",
      "Epoch [33/50], Step [418/735], Loss: 0.0838\n",
      "Epoch [33/50], Step [419/735], Loss: 0.1862\n",
      "Epoch [33/50], Step [420/735], Loss: 0.0185\n",
      "Epoch [33/50], Step [421/735], Loss: 0.0550\n",
      "Epoch [33/50], Step [422/735], Loss: 0.0513\n",
      "Epoch [33/50], Step [423/735], Loss: 0.0561\n",
      "Epoch [33/50], Step [424/735], Loss: 0.0809\n",
      "Epoch [33/50], Step [425/735], Loss: 0.0239\n",
      "Epoch [33/50], Step [426/735], Loss: 0.0317\n",
      "Epoch [33/50], Step [427/735], Loss: 0.1700\n",
      "Epoch [33/50], Step [428/735], Loss: 0.1449\n",
      "Epoch [33/50], Step [429/735], Loss: 0.0501\n",
      "Epoch [33/50], Step [430/735], Loss: 0.0592\n",
      "Epoch [33/50], Step [431/735], Loss: 0.0562\n",
      "Epoch [33/50], Step [432/735], Loss: 0.0331\n",
      "Epoch [33/50], Step [433/735], Loss: 0.0492\n",
      "Epoch [33/50], Step [434/735], Loss: 0.0281\n",
      "Epoch [33/50], Step [435/735], Loss: 0.0443\n",
      "Epoch [33/50], Step [436/735], Loss: 0.1436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Step [437/735], Loss: 0.0365\n",
      "Epoch [33/50], Step [438/735], Loss: 0.0884\n",
      "Epoch [33/50], Step [439/735], Loss: 0.0701\n",
      "Epoch [33/50], Step [440/735], Loss: 0.0387\n",
      "Epoch [33/50], Step [441/735], Loss: 0.0628\n",
      "Epoch [33/50], Step [442/735], Loss: 0.0576\n",
      "Epoch [33/50], Step [443/735], Loss: 0.0993\n",
      "Epoch [33/50], Step [444/735], Loss: 0.0440\n",
      "Epoch [33/50], Step [445/735], Loss: 0.1023\n",
      "Epoch [33/50], Step [446/735], Loss: 0.0511\n",
      "Epoch [33/50], Step [447/735], Loss: 0.0400\n",
      "Epoch [33/50], Step [448/735], Loss: 0.0528\n",
      "Epoch [33/50], Step [449/735], Loss: 0.0670\n",
      "Epoch [33/50], Step [450/735], Loss: 0.0248\n",
      "Epoch [33/50], Step [451/735], Loss: 0.0399\n",
      "Epoch [33/50], Step [452/735], Loss: 0.1698\n",
      "Epoch [33/50], Step [453/735], Loss: 0.0807\n",
      "Epoch [33/50], Step [454/735], Loss: 0.1129\n",
      "Epoch [33/50], Step [455/735], Loss: 0.1239\n",
      "Epoch [33/50], Step [456/735], Loss: 0.0257\n",
      "Epoch [33/50], Step [457/735], Loss: 0.0496\n",
      "Epoch [33/50], Step [458/735], Loss: 0.1108\n",
      "Epoch [33/50], Step [459/735], Loss: 0.0524\n",
      "Epoch [33/50], Step [460/735], Loss: 0.0301\n",
      "Epoch [33/50], Step [461/735], Loss: 0.0434\n",
      "Epoch [33/50], Step [462/735], Loss: 0.0328\n",
      "Epoch [33/50], Step [463/735], Loss: 0.0210\n",
      "Epoch [33/50], Step [464/735], Loss: 0.0527\n",
      "Epoch [33/50], Step [465/735], Loss: 0.0464\n",
      "Epoch [33/50], Step [466/735], Loss: 0.0617\n",
      "Epoch [33/50], Step [467/735], Loss: 0.0361\n",
      "Epoch [33/50], Step [468/735], Loss: 0.0832\n",
      "Epoch [33/50], Step [469/735], Loss: 0.0477\n",
      "Epoch [33/50], Step [470/735], Loss: 0.0345\n",
      "Epoch [33/50], Step [471/735], Loss: 0.0364\n",
      "Epoch [33/50], Step [472/735], Loss: 0.3792\n",
      "Epoch [33/50], Step [473/735], Loss: 0.0458\n",
      "Epoch [33/50], Step [474/735], Loss: 0.0735\n",
      "Epoch [33/50], Step [475/735], Loss: 0.0586\n",
      "Epoch [33/50], Step [476/735], Loss: 0.1226\n",
      "Epoch [33/50], Step [477/735], Loss: 0.0802\n",
      "Epoch [33/50], Step [478/735], Loss: 0.0401\n",
      "Epoch [33/50], Step [479/735], Loss: 0.0525\n",
      "Epoch [33/50], Step [480/735], Loss: 0.0470\n",
      "Epoch [33/50], Step [481/735], Loss: 0.0188\n",
      "Epoch [33/50], Step [482/735], Loss: 0.0261\n",
      "Epoch [33/50], Step [483/735], Loss: 0.0244\n",
      "Epoch [33/50], Step [484/735], Loss: 0.0187\n",
      "Epoch [33/50], Step [485/735], Loss: 0.0819\n",
      "Epoch [33/50], Step [486/735], Loss: 0.0316\n",
      "Epoch [33/50], Step [487/735], Loss: 0.0900\n",
      "Epoch [33/50], Step [488/735], Loss: 0.0995\n",
      "Epoch [33/50], Step [489/735], Loss: 0.1238\n",
      "Epoch [33/50], Step [490/735], Loss: 0.1359\n",
      "Epoch [33/50], Step [491/735], Loss: 0.0834\n",
      "Epoch [33/50], Step [492/735], Loss: 0.5692\n",
      "Epoch [33/50], Step [493/735], Loss: 0.0258\n",
      "Epoch [33/50], Step [494/735], Loss: 0.0477\n",
      "Epoch [33/50], Step [495/735], Loss: 0.0267\n",
      "Epoch [33/50], Step [496/735], Loss: 0.1440\n",
      "Epoch [33/50], Step [497/735], Loss: 0.0730\n",
      "Epoch [33/50], Step [498/735], Loss: 0.2248\n",
      "Epoch [33/50], Step [499/735], Loss: 0.0507\n",
      "Epoch [33/50], Step [500/735], Loss: 0.1212\n",
      "Epoch [33/50], Step [501/735], Loss: 0.1247\n",
      "Epoch [33/50], Step [502/735], Loss: 0.0986\n",
      "Epoch [33/50], Step [503/735], Loss: 0.0819\n",
      "Epoch [33/50], Step [504/735], Loss: 0.1434\n",
      "Epoch [33/50], Step [505/735], Loss: 0.0391\n",
      "Epoch [33/50], Step [506/735], Loss: 0.0546\n",
      "Epoch [33/50], Step [507/735], Loss: 0.0415\n",
      "Epoch [33/50], Step [508/735], Loss: 0.1068\n",
      "Epoch [33/50], Step [509/735], Loss: 0.1328\n",
      "Epoch [33/50], Step [510/735], Loss: 0.0820\n",
      "Epoch [33/50], Step [511/735], Loss: 0.0649\n",
      "Epoch [33/50], Step [512/735], Loss: 0.0897\n",
      "Epoch [33/50], Step [513/735], Loss: 0.0529\n",
      "Epoch [33/50], Step [514/735], Loss: 0.0650\n",
      "Epoch [33/50], Step [515/735], Loss: 0.1342\n",
      "Epoch [33/50], Step [516/735], Loss: 0.1121\n",
      "Epoch [33/50], Step [517/735], Loss: 0.1198\n",
      "Epoch [33/50], Step [518/735], Loss: 0.0806\n",
      "Epoch [33/50], Step [519/735], Loss: 0.0548\n",
      "Epoch [33/50], Step [520/735], Loss: 0.0264\n",
      "Epoch [33/50], Step [521/735], Loss: 0.0211\n",
      "Epoch [33/50], Step [522/735], Loss: 0.0231\n",
      "Epoch [33/50], Step [523/735], Loss: 0.0771\n",
      "Epoch [33/50], Step [524/735], Loss: 0.0671\n",
      "Epoch [33/50], Step [525/735], Loss: 0.0705\n",
      "Epoch [33/50], Step [526/735], Loss: 0.0624\n",
      "Epoch [33/50], Step [527/735], Loss: 0.0521\n",
      "Epoch [33/50], Step [528/735], Loss: 0.0752\n",
      "Epoch [33/50], Step [529/735], Loss: 0.0434\n",
      "Epoch [33/50], Step [530/735], Loss: 0.0515\n",
      "Epoch [33/50], Step [531/735], Loss: 0.0716\n",
      "Epoch [33/50], Step [532/735], Loss: 0.0233\n",
      "Epoch [33/50], Step [533/735], Loss: 0.0606\n",
      "Epoch [33/50], Step [534/735], Loss: 0.1567\n",
      "Epoch [33/50], Step [535/735], Loss: 0.0388\n",
      "Epoch [33/50], Step [536/735], Loss: 0.0345\n",
      "Epoch [33/50], Step [537/735], Loss: 0.0277\n",
      "Epoch [33/50], Step [538/735], Loss: 0.0690\n",
      "Epoch [33/50], Step [539/735], Loss: 0.0550\n",
      "Epoch [33/50], Step [540/735], Loss: 0.0564\n",
      "Epoch [33/50], Step [541/735], Loss: 0.0275\n",
      "Epoch [33/50], Step [542/735], Loss: 0.0353\n",
      "Epoch [33/50], Step [543/735], Loss: 0.0385\n",
      "Epoch [33/50], Step [544/735], Loss: 0.0842\n",
      "Epoch [33/50], Step [545/735], Loss: 0.0479\n",
      "Epoch [33/50], Step [546/735], Loss: 0.1454\n",
      "Epoch [33/50], Step [547/735], Loss: 0.0330\n",
      "Epoch [33/50], Step [548/735], Loss: 0.0268\n",
      "Epoch [33/50], Step [549/735], Loss: 0.2421\n",
      "Epoch [33/50], Step [550/735], Loss: 0.0405\n",
      "Epoch [33/50], Step [551/735], Loss: 0.0651\n",
      "Epoch [33/50], Step [552/735], Loss: 0.1280\n",
      "Epoch [33/50], Step [553/735], Loss: 0.1257\n",
      "Epoch [33/50], Step [554/735], Loss: 0.0867\n",
      "Epoch [33/50], Step [555/735], Loss: 0.0445\n",
      "Epoch [33/50], Step [556/735], Loss: 0.0352\n",
      "Epoch [33/50], Step [557/735], Loss: 0.0653\n",
      "Epoch [33/50], Step [558/735], Loss: 0.0808\n",
      "Epoch [33/50], Step [559/735], Loss: 0.0816\n",
      "Epoch [33/50], Step [560/735], Loss: 0.0235\n",
      "Epoch [33/50], Step [561/735], Loss: 0.0338\n",
      "Epoch [33/50], Step [562/735], Loss: 0.0520\n",
      "Epoch [33/50], Step [563/735], Loss: 0.0575\n",
      "Epoch [33/50], Step [564/735], Loss: 0.1220\n",
      "Epoch [33/50], Step [565/735], Loss: 0.0517\n",
      "Epoch [33/50], Step [566/735], Loss: 0.0258\n",
      "Epoch [33/50], Step [567/735], Loss: 0.2039\n",
      "Epoch [33/50], Step [568/735], Loss: 0.0666\n",
      "Epoch [33/50], Step [569/735], Loss: 0.1388\n",
      "Epoch [33/50], Step [570/735], Loss: 0.1950\n",
      "Epoch [33/50], Step [571/735], Loss: 0.0164\n",
      "Epoch [33/50], Step [572/735], Loss: 0.1740\n",
      "Epoch [33/50], Step [573/735], Loss: 0.1156\n",
      "Epoch [33/50], Step [574/735], Loss: 0.0563\n",
      "Epoch [33/50], Step [575/735], Loss: 0.0408\n",
      "Epoch [33/50], Step [576/735], Loss: 0.0824\n",
      "Epoch [33/50], Step [577/735], Loss: 0.0626\n",
      "Epoch [33/50], Step [578/735], Loss: 0.0654\n",
      "Epoch [33/50], Step [579/735], Loss: 0.0479\n",
      "Epoch [33/50], Step [580/735], Loss: 0.0444\n",
      "Epoch [33/50], Step [581/735], Loss: 0.0386\n",
      "Epoch [33/50], Step [582/735], Loss: 0.0835\n",
      "Epoch [33/50], Step [583/735], Loss: 0.0600\n",
      "Epoch [33/50], Step [584/735], Loss: 0.0346\n",
      "Epoch [33/50], Step [585/735], Loss: 0.0844\n",
      "Epoch [33/50], Step [586/735], Loss: 0.0770\n",
      "Epoch [33/50], Step [587/735], Loss: 0.0638\n",
      "Epoch [33/50], Step [588/735], Loss: 0.0939\n",
      "Epoch [33/50], Step [589/735], Loss: 0.0612\n",
      "Epoch [33/50], Step [590/735], Loss: 0.0376\n",
      "Epoch [33/50], Step [591/735], Loss: 0.4523\n",
      "Epoch [33/50], Step [592/735], Loss: 0.0824\n",
      "Epoch [33/50], Step [593/735], Loss: 0.0279\n",
      "Epoch [33/50], Step [594/735], Loss: 0.0989\n",
      "Epoch [33/50], Step [595/735], Loss: 0.0400\n",
      "Epoch [33/50], Step [596/735], Loss: 0.0647\n",
      "Epoch [33/50], Step [597/735], Loss: 0.1776\n",
      "Epoch [33/50], Step [598/735], Loss: 0.0661\n",
      "Epoch [33/50], Step [599/735], Loss: 0.0473\n",
      "Epoch [33/50], Step [600/735], Loss: 0.0276\n",
      "Epoch [33/50], Step [601/735], Loss: 0.0451\n",
      "Epoch [33/50], Step [602/735], Loss: 0.0719\n",
      "Epoch [33/50], Step [603/735], Loss: 0.0560\n",
      "Epoch [33/50], Step [604/735], Loss: 0.1087\n",
      "Epoch [33/50], Step [605/735], Loss: 0.0350\n",
      "Epoch [33/50], Step [606/735], Loss: 0.0273\n",
      "Epoch [33/50], Step [607/735], Loss: 0.4567\n",
      "Epoch [33/50], Step [608/735], Loss: 0.0587\n",
      "Epoch [33/50], Step [609/735], Loss: 0.0782\n",
      "Epoch [33/50], Step [610/735], Loss: 0.0523\n",
      "Epoch [33/50], Step [611/735], Loss: 0.1629\n",
      "Epoch [33/50], Step [612/735], Loss: 0.0456\n",
      "Epoch [33/50], Step [613/735], Loss: 0.0323\n",
      "Epoch [33/50], Step [614/735], Loss: 0.0705\n",
      "Epoch [33/50], Step [615/735], Loss: 0.0717\n",
      "Epoch [33/50], Step [616/735], Loss: 0.1093\n",
      "Epoch [33/50], Step [617/735], Loss: 0.0274\n",
      "Epoch [33/50], Step [618/735], Loss: 0.0240\n",
      "Epoch [33/50], Step [619/735], Loss: 0.0758\n",
      "Epoch [33/50], Step [620/735], Loss: 0.1017\n",
      "Epoch [33/50], Step [621/735], Loss: 0.0187\n",
      "Epoch [33/50], Step [622/735], Loss: 0.0285\n",
      "Epoch [33/50], Step [623/735], Loss: 0.0741\n",
      "Epoch [33/50], Step [624/735], Loss: 0.0520\n",
      "Epoch [33/50], Step [625/735], Loss: 0.0749\n",
      "Epoch [33/50], Step [626/735], Loss: 0.0273\n",
      "Epoch [33/50], Step [627/735], Loss: 0.1276\n",
      "Epoch [33/50], Step [628/735], Loss: 0.0324\n",
      "Epoch [33/50], Step [629/735], Loss: 0.0270\n",
      "Epoch [33/50], Step [630/735], Loss: 0.2908\n",
      "Epoch [33/50], Step [631/735], Loss: 0.0775\n",
      "Epoch [33/50], Step [632/735], Loss: 0.0450\n",
      "Epoch [33/50], Step [633/735], Loss: 0.0449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Step [634/735], Loss: 0.1312\n",
      "Epoch [33/50], Step [635/735], Loss: 0.0944\n",
      "Epoch [33/50], Step [636/735], Loss: 0.0732\n",
      "Epoch [33/50], Step [637/735], Loss: 0.1947\n",
      "Epoch [33/50], Step [638/735], Loss: 0.0658\n",
      "Epoch [33/50], Step [639/735], Loss: 0.1455\n",
      "Epoch [33/50], Step [640/735], Loss: 0.0474\n",
      "Epoch [33/50], Step [641/735], Loss: 0.0348\n",
      "Epoch [33/50], Step [642/735], Loss: 0.0540\n",
      "Epoch [33/50], Step [643/735], Loss: 0.0670\n",
      "Epoch [33/50], Step [644/735], Loss: 0.0692\n",
      "Epoch [33/50], Step [645/735], Loss: 0.1270\n",
      "Epoch [33/50], Step [646/735], Loss: 0.0773\n",
      "Epoch [33/50], Step [647/735], Loss: 0.1310\n",
      "Epoch [33/50], Step [648/735], Loss: 0.2648\n",
      "Epoch [33/50], Step [649/735], Loss: 0.0635\n",
      "Epoch [33/50], Step [650/735], Loss: 0.0575\n",
      "Epoch [33/50], Step [651/735], Loss: 0.0461\n",
      "Epoch [33/50], Step [652/735], Loss: 0.0267\n",
      "Epoch [33/50], Step [653/735], Loss: 0.0435\n",
      "Epoch [33/50], Step [654/735], Loss: 0.0437\n",
      "Epoch [33/50], Step [655/735], Loss: 0.0376\n",
      "Epoch [33/50], Step [656/735], Loss: 0.1020\n",
      "Epoch [33/50], Step [657/735], Loss: 0.0867\n",
      "Epoch [33/50], Step [658/735], Loss: 0.0624\n",
      "Epoch [33/50], Step [659/735], Loss: 0.0608\n",
      "Epoch [33/50], Step [660/735], Loss: 0.0222\n",
      "Epoch [33/50], Step [661/735], Loss: 0.0589\n",
      "Epoch [33/50], Step [662/735], Loss: 0.0625\n",
      "Epoch [33/50], Step [663/735], Loss: 0.0465\n",
      "Epoch [33/50], Step [664/735], Loss: 0.0224\n",
      "Epoch [33/50], Step [665/735], Loss: 0.0358\n",
      "Epoch [33/50], Step [666/735], Loss: 0.0185\n",
      "Epoch [33/50], Step [667/735], Loss: 0.0648\n",
      "Epoch [33/50], Step [668/735], Loss: 0.1109\n",
      "Epoch [33/50], Step [669/735], Loss: 0.0329\n",
      "Epoch [33/50], Step [670/735], Loss: 0.0536\n",
      "Epoch [33/50], Step [671/735], Loss: 0.0437\n",
      "Epoch [33/50], Step [672/735], Loss: 0.0796\n",
      "Epoch [33/50], Step [673/735], Loss: 0.0280\n",
      "Epoch [33/50], Step [674/735], Loss: 0.0757\n",
      "Epoch [33/50], Step [675/735], Loss: 0.0962\n",
      "Epoch [33/50], Step [676/735], Loss: 0.0483\n",
      "Epoch [33/50], Step [677/735], Loss: 0.0413\n",
      "Epoch [33/50], Step [678/735], Loss: 0.0454\n",
      "Epoch [33/50], Step [679/735], Loss: 0.0366\n",
      "Epoch [33/50], Step [680/735], Loss: 0.1095\n",
      "Epoch [33/50], Step [681/735], Loss: 0.0360\n",
      "Epoch [33/50], Step [682/735], Loss: 0.0272\n",
      "Epoch [33/50], Step [683/735], Loss: 0.0378\n",
      "Epoch [33/50], Step [684/735], Loss: 0.0252\n",
      "Epoch [33/50], Step [685/735], Loss: 0.0305\n",
      "Epoch [33/50], Step [686/735], Loss: 0.1121\n",
      "Epoch [33/50], Step [687/735], Loss: 0.0435\n",
      "Epoch [33/50], Step [688/735], Loss: 0.0573\n",
      "Epoch [33/50], Step [689/735], Loss: 0.0845\n",
      "Epoch [33/50], Step [690/735], Loss: 0.1344\n",
      "Epoch [33/50], Step [691/735], Loss: 0.0400\n",
      "Epoch [33/50], Step [692/735], Loss: 0.0649\n",
      "Epoch [33/50], Step [693/735], Loss: 0.0229\n",
      "Epoch [33/50], Step [694/735], Loss: 0.0765\n",
      "Epoch [33/50], Step [695/735], Loss: 0.0645\n",
      "Epoch [33/50], Step [696/735], Loss: 0.0427\n",
      "Epoch [33/50], Step [697/735], Loss: 0.0938\n",
      "Epoch [33/50], Step [698/735], Loss: 0.0313\n",
      "Epoch [33/50], Step [699/735], Loss: 0.0588\n",
      "Epoch [33/50], Step [700/735], Loss: 0.0621\n",
      "Epoch [33/50], Step [701/735], Loss: 0.2274\n",
      "Epoch [33/50], Step [702/735], Loss: 0.0498\n",
      "Epoch [33/50], Step [703/735], Loss: 0.0635\n",
      "Epoch [33/50], Step [704/735], Loss: 0.0496\n",
      "Epoch [33/50], Step [705/735], Loss: 0.0212\n",
      "Epoch [33/50], Step [706/735], Loss: 0.1465\n",
      "Epoch [33/50], Step [707/735], Loss: 0.0414\n",
      "Epoch [33/50], Step [708/735], Loss: 0.5955\n",
      "Epoch [33/50], Step [709/735], Loss: 0.0414\n",
      "Epoch [33/50], Step [710/735], Loss: 0.0322\n",
      "Epoch [33/50], Step [711/735], Loss: 0.0889\n",
      "Epoch [33/50], Step [712/735], Loss: 0.1154\n",
      "Epoch [33/50], Step [713/735], Loss: 0.0663\n",
      "Epoch [33/50], Step [714/735], Loss: 0.1003\n",
      "Epoch [33/50], Step [715/735], Loss: 0.0364\n",
      "Epoch [33/50], Step [716/735], Loss: 0.0497\n",
      "Epoch [33/50], Step [717/735], Loss: 0.0755\n",
      "Epoch [33/50], Step [718/735], Loss: 0.0196\n",
      "Epoch [33/50], Step [719/735], Loss: 0.0344\n",
      "Epoch [33/50], Step [720/735], Loss: 0.3323\n",
      "Epoch [33/50], Step [721/735], Loss: 0.0772\n",
      "Epoch [33/50], Step [722/735], Loss: 0.0228\n",
      "Epoch [33/50], Step [723/735], Loss: 0.0425\n",
      "Epoch [33/50], Step [724/735], Loss: 0.0525\n",
      "Epoch [33/50], Step [725/735], Loss: 0.1665\n",
      "Epoch [33/50], Step [726/735], Loss: 0.1080\n",
      "Epoch [33/50], Step [727/735], Loss: 0.0371\n",
      "Epoch [33/50], Step [728/735], Loss: 0.0674\n",
      "Epoch [33/50], Step [729/735], Loss: 0.0470\n",
      "Epoch [33/50], Step [730/735], Loss: 0.0998\n",
      "Epoch [33/50], Step [731/735], Loss: 0.0525\n",
      "Epoch [33/50], Step [732/735], Loss: 0.0987\n",
      "Epoch [33/50], Step [733/735], Loss: 0.0329\n",
      "Epoch [33/50], Step [734/735], Loss: 0.0266\n",
      "Epoch [33/50], Step [735/735], Loss: 0.0798\n",
      "Epoch [34/50], Step [1/735], Loss: 0.0574\n",
      "Epoch [34/50], Step [2/735], Loss: 0.2029\n",
      "Epoch [34/50], Step [3/735], Loss: 0.1004\n",
      "Epoch [34/50], Step [4/735], Loss: 0.0651\n",
      "Epoch [34/50], Step [5/735], Loss: 0.0269\n",
      "Epoch [34/50], Step [6/735], Loss: 0.1038\n",
      "Epoch [34/50], Step [7/735], Loss: 0.0326\n",
      "Epoch [34/50], Step [8/735], Loss: 0.0876\n",
      "Epoch [34/50], Step [9/735], Loss: 0.0357\n",
      "Epoch [34/50], Step [10/735], Loss: 0.1654\n",
      "Epoch [34/50], Step [11/735], Loss: 0.0482\n",
      "Epoch [34/50], Step [12/735], Loss: 0.0214\n",
      "Epoch [34/50], Step [13/735], Loss: 0.1010\n",
      "Epoch [34/50], Step [14/735], Loss: 0.1255\n",
      "Epoch [34/50], Step [15/735], Loss: 0.0751\n",
      "Epoch [34/50], Step [16/735], Loss: 0.0449\n",
      "Epoch [34/50], Step [17/735], Loss: 0.0598\n",
      "Epoch [34/50], Step [18/735], Loss: 0.1991\n",
      "Epoch [34/50], Step [19/735], Loss: 0.0595\n",
      "Epoch [34/50], Step [20/735], Loss: 0.0468\n",
      "Epoch [34/50], Step [21/735], Loss: 0.0489\n",
      "Epoch [34/50], Step [22/735], Loss: 0.0838\n",
      "Epoch [34/50], Step [23/735], Loss: 0.0712\n",
      "Epoch [34/50], Step [24/735], Loss: 0.0961\n",
      "Epoch [34/50], Step [25/735], Loss: 0.0276\n",
      "Epoch [34/50], Step [26/735], Loss: 0.0524\n",
      "Epoch [34/50], Step [27/735], Loss: 0.1085\n",
      "Epoch [34/50], Step [28/735], Loss: 0.0306\n",
      "Epoch [34/50], Step [29/735], Loss: 0.0382\n",
      "Epoch [34/50], Step [30/735], Loss: 0.0519\n",
      "Epoch [34/50], Step [31/735], Loss: 0.0432\n",
      "Epoch [34/50], Step [32/735], Loss: 0.0667\n",
      "Epoch [34/50], Step [33/735], Loss: 0.0807\n",
      "Epoch [34/50], Step [34/735], Loss: 0.1503\n",
      "Epoch [34/50], Step [35/735], Loss: 0.0536\n",
      "Epoch [34/50], Step [36/735], Loss: 0.0628\n",
      "Epoch [34/50], Step [37/735], Loss: 0.1067\n",
      "Epoch [34/50], Step [38/735], Loss: 0.0507\n",
      "Epoch [34/50], Step [39/735], Loss: 0.1090\n",
      "Epoch [34/50], Step [40/735], Loss: 0.0161\n",
      "Epoch [34/50], Step [41/735], Loss: 0.0462\n",
      "Epoch [34/50], Step [42/735], Loss: 0.0325\n",
      "Epoch [34/50], Step [43/735], Loss: 0.0632\n",
      "Epoch [34/50], Step [44/735], Loss: 0.0255\n",
      "Epoch [34/50], Step [45/735], Loss: 0.0572\n",
      "Epoch [34/50], Step [46/735], Loss: 0.1298\n",
      "Epoch [34/50], Step [47/735], Loss: 0.0801\n",
      "Epoch [34/50], Step [48/735], Loss: 0.1229\n",
      "Epoch [34/50], Step [49/735], Loss: 0.1127\n",
      "Epoch [34/50], Step [50/735], Loss: 0.0538\n",
      "Epoch [34/50], Step [51/735], Loss: 0.0554\n",
      "Epoch [34/50], Step [52/735], Loss: 0.0504\n",
      "Epoch [34/50], Step [53/735], Loss: 0.0673\n",
      "Epoch [34/50], Step [54/735], Loss: 0.4777\n",
      "Epoch [34/50], Step [55/735], Loss: 0.0528\n",
      "Epoch [34/50], Step [56/735], Loss: 0.0792\n",
      "Epoch [34/50], Step [57/735], Loss: 0.0558\n",
      "Epoch [34/50], Step [58/735], Loss: 0.0526\n",
      "Epoch [34/50], Step [59/735], Loss: 0.1119\n",
      "Epoch [34/50], Step [60/735], Loss: 0.0457\n",
      "Epoch [34/50], Step [61/735], Loss: 0.0509\n",
      "Epoch [34/50], Step [62/735], Loss: 0.1405\n",
      "Epoch [34/50], Step [63/735], Loss: 0.0700\n",
      "Epoch [34/50], Step [64/735], Loss: 0.0627\n",
      "Epoch [34/50], Step [65/735], Loss: 0.0703\n",
      "Epoch [34/50], Step [66/735], Loss: 0.0867\n",
      "Epoch [34/50], Step [67/735], Loss: 0.0318\n",
      "Epoch [34/50], Step [68/735], Loss: 0.1356\n",
      "Epoch [34/50], Step [69/735], Loss: 0.0490\n",
      "Epoch [34/50], Step [70/735], Loss: 0.0879\n",
      "Epoch [34/50], Step [71/735], Loss: 0.0969\n",
      "Epoch [34/50], Step [72/735], Loss: 0.0498\n",
      "Epoch [34/50], Step [73/735], Loss: 0.1052\n",
      "Epoch [34/50], Step [74/735], Loss: 0.0277\n",
      "Epoch [34/50], Step [75/735], Loss: 0.0695\n",
      "Epoch [34/50], Step [76/735], Loss: 0.0362\n",
      "Epoch [34/50], Step [77/735], Loss: 0.0462\n",
      "Epoch [34/50], Step [78/735], Loss: 0.0638\n",
      "Epoch [34/50], Step [79/735], Loss: 0.0680\n",
      "Epoch [34/50], Step [80/735], Loss: 0.0420\n",
      "Epoch [34/50], Step [81/735], Loss: 0.0869\n",
      "Epoch [34/50], Step [82/735], Loss: 0.0284\n",
      "Epoch [34/50], Step [83/735], Loss: 0.0214\n",
      "Epoch [34/50], Step [84/735], Loss: 0.0459\n",
      "Epoch [34/50], Step [85/735], Loss: 0.0546\n",
      "Epoch [34/50], Step [86/735], Loss: 0.0252\n",
      "Epoch [34/50], Step [87/735], Loss: 0.2010\n",
      "Epoch [34/50], Step [88/735], Loss: 0.0549\n",
      "Epoch [34/50], Step [89/735], Loss: 0.1053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Step [90/735], Loss: 0.0818\n",
      "Epoch [34/50], Step [91/735], Loss: 0.0408\n",
      "Epoch [34/50], Step [92/735], Loss: 0.0275\n",
      "Epoch [34/50], Step [93/735], Loss: 0.1019\n",
      "Epoch [34/50], Step [94/735], Loss: 0.0244\n",
      "Epoch [34/50], Step [95/735], Loss: 0.0461\n",
      "Epoch [34/50], Step [96/735], Loss: 0.0509\n",
      "Epoch [34/50], Step [97/735], Loss: 0.0411\n",
      "Epoch [34/50], Step [98/735], Loss: 0.0355\n",
      "Epoch [34/50], Step [99/735], Loss: 0.0464\n",
      "Epoch [34/50], Step [100/735], Loss: 0.0214\n",
      "Epoch [34/50], Step [101/735], Loss: 0.0471\n",
      "Epoch [34/50], Step [102/735], Loss: 0.0247\n",
      "Epoch [34/50], Step [103/735], Loss: 0.0186\n",
      "Epoch [34/50], Step [104/735], Loss: 0.3751\n",
      "Epoch [34/50], Step [105/735], Loss: 0.0430\n",
      "Epoch [34/50], Step [106/735], Loss: 0.0832\n",
      "Epoch [34/50], Step [107/735], Loss: 0.0998\n",
      "Epoch [34/50], Step [108/735], Loss: 0.0252\n",
      "Epoch [34/50], Step [109/735], Loss: 0.1180\n",
      "Epoch [34/50], Step [110/735], Loss: 0.0468\n",
      "Epoch [34/50], Step [111/735], Loss: 0.0448\n",
      "Epoch [34/50], Step [112/735], Loss: 0.0862\n",
      "Epoch [34/50], Step [113/735], Loss: 0.0383\n",
      "Epoch [34/50], Step [114/735], Loss: 0.0648\n",
      "Epoch [34/50], Step [115/735], Loss: 0.0634\n",
      "Epoch [34/50], Step [116/735], Loss: 0.0461\n",
      "Epoch [34/50], Step [117/735], Loss: 0.0997\n",
      "Epoch [34/50], Step [118/735], Loss: 0.0391\n",
      "Epoch [34/50], Step [119/735], Loss: 0.0454\n",
      "Epoch [34/50], Step [120/735], Loss: 0.0950\n",
      "Epoch [34/50], Step [121/735], Loss: 0.1191\n",
      "Epoch [34/50], Step [122/735], Loss: 0.1012\n",
      "Epoch [34/50], Step [123/735], Loss: 0.1622\n",
      "Epoch [34/50], Step [124/735], Loss: 0.0835\n",
      "Epoch [34/50], Step [125/735], Loss: 0.0632\n",
      "Epoch [34/50], Step [126/735], Loss: 0.2819\n",
      "Epoch [34/50], Step [127/735], Loss: 0.1982\n",
      "Epoch [34/50], Step [128/735], Loss: 0.0403\n",
      "Epoch [34/50], Step [129/735], Loss: 0.0923\n",
      "Epoch [34/50], Step [130/735], Loss: 0.1202\n",
      "Epoch [34/50], Step [131/735], Loss: 0.0828\n",
      "Epoch [34/50], Step [132/735], Loss: 0.0705\n",
      "Epoch [34/50], Step [133/735], Loss: 0.1075\n",
      "Epoch [34/50], Step [134/735], Loss: 0.0395\n",
      "Epoch [34/50], Step [135/735], Loss: 0.3160\n",
      "Epoch [34/50], Step [136/735], Loss: 0.0378\n",
      "Epoch [34/50], Step [137/735], Loss: 0.0605\n",
      "Epoch [34/50], Step [138/735], Loss: 0.1594\n",
      "Epoch [34/50], Step [139/735], Loss: 0.1022\n",
      "Epoch [34/50], Step [140/735], Loss: 0.0295\n",
      "Epoch [34/50], Step [141/735], Loss: 0.0883\n",
      "Epoch [34/50], Step [142/735], Loss: 0.0677\n",
      "Epoch [34/50], Step [143/735], Loss: 0.0279\n",
      "Epoch [34/50], Step [144/735], Loss: 0.0706\n",
      "Epoch [34/50], Step [145/735], Loss: 0.0509\n",
      "Epoch [34/50], Step [146/735], Loss: 0.0982\n",
      "Epoch [34/50], Step [147/735], Loss: 0.1472\n",
      "Epoch [34/50], Step [148/735], Loss: 0.0459\n",
      "Epoch [34/50], Step [149/735], Loss: 0.1153\n",
      "Epoch [34/50], Step [150/735], Loss: 0.1044\n",
      "Epoch [34/50], Step [151/735], Loss: 0.1920\n",
      "Epoch [34/50], Step [152/735], Loss: 0.1031\n",
      "Epoch [34/50], Step [153/735], Loss: 0.1759\n",
      "Epoch [34/50], Step [154/735], Loss: 0.0284\n",
      "Epoch [34/50], Step [155/735], Loss: 0.1422\n",
      "Epoch [34/50], Step [156/735], Loss: 0.0579\n",
      "Epoch [34/50], Step [157/735], Loss: 0.0622\n",
      "Epoch [34/50], Step [158/735], Loss: 0.0346\n",
      "Epoch [34/50], Step [159/735], Loss: 0.1030\n",
      "Epoch [34/50], Step [160/735], Loss: 0.0986\n",
      "Epoch [34/50], Step [161/735], Loss: 0.0637\n",
      "Epoch [34/50], Step [162/735], Loss: 0.0873\n",
      "Epoch [34/50], Step [163/735], Loss: 0.1336\n",
      "Epoch [34/50], Step [164/735], Loss: 0.1244\n",
      "Epoch [34/50], Step [165/735], Loss: 0.0656\n",
      "Epoch [34/50], Step [166/735], Loss: 0.1078\n",
      "Epoch [34/50], Step [167/735], Loss: 0.0548\n",
      "Epoch [34/50], Step [168/735], Loss: 0.0404\n",
      "Epoch [34/50], Step [169/735], Loss: 0.0480\n",
      "Epoch [34/50], Step [170/735], Loss: 0.0713\n",
      "Epoch [34/50], Step [171/735], Loss: 0.0372\n",
      "Epoch [34/50], Step [172/735], Loss: 0.0252\n",
      "Epoch [34/50], Step [173/735], Loss: 0.0381\n",
      "Epoch [34/50], Step [174/735], Loss: 0.0547\n",
      "Epoch [34/50], Step [175/735], Loss: 0.0938\n",
      "Epoch [34/50], Step [176/735], Loss: 0.0418\n",
      "Epoch [34/50], Step [177/735], Loss: 0.0571\n",
      "Epoch [34/50], Step [178/735], Loss: 0.1353\n",
      "Epoch [34/50], Step [179/735], Loss: 0.0633\n",
      "Epoch [34/50], Step [180/735], Loss: 0.1693\n",
      "Epoch [34/50], Step [181/735], Loss: 0.0549\n",
      "Epoch [34/50], Step [182/735], Loss: 0.0463\n",
      "Epoch [34/50], Step [183/735], Loss: 0.0578\n",
      "Epoch [34/50], Step [184/735], Loss: 0.0588\n",
      "Epoch [34/50], Step [185/735], Loss: 0.1145\n",
      "Epoch [34/50], Step [186/735], Loss: 0.1074\n",
      "Epoch [34/50], Step [187/735], Loss: 0.0383\n",
      "Epoch [34/50], Step [188/735], Loss: 0.0342\n",
      "Epoch [34/50], Step [189/735], Loss: 0.0460\n",
      "Epoch [34/50], Step [190/735], Loss: 0.0643\n",
      "Epoch [34/50], Step [191/735], Loss: 0.0822\n",
      "Epoch [34/50], Step [192/735], Loss: 0.0431\n",
      "Epoch [34/50], Step [193/735], Loss: 0.0259\n",
      "Epoch [34/50], Step [194/735], Loss: 0.0254\n",
      "Epoch [34/50], Step [195/735], Loss: 0.0862\n",
      "Epoch [34/50], Step [196/735], Loss: 0.0396\n",
      "Epoch [34/50], Step [197/735], Loss: 0.0366\n",
      "Epoch [34/50], Step [198/735], Loss: 0.0369\n",
      "Epoch [34/50], Step [199/735], Loss: 0.0186\n",
      "Epoch [34/50], Step [200/735], Loss: 0.0861\n",
      "Epoch [34/50], Step [201/735], Loss: 0.1105\n",
      "Epoch [34/50], Step [202/735], Loss: 0.2989\n",
      "Epoch [34/50], Step [203/735], Loss: 0.0843\n",
      "Epoch [34/50], Step [204/735], Loss: 0.2732\n",
      "Epoch [34/50], Step [205/735], Loss: 0.1124\n",
      "Epoch [34/50], Step [206/735], Loss: 0.0341\n",
      "Epoch [34/50], Step [207/735], Loss: 0.0411\n",
      "Epoch [34/50], Step [208/735], Loss: 0.0486\n",
      "Epoch [34/50], Step [209/735], Loss: 0.0538\n",
      "Epoch [34/50], Step [210/735], Loss: 0.0328\n",
      "Epoch [34/50], Step [211/735], Loss: 0.0405\n",
      "Epoch [34/50], Step [212/735], Loss: 0.0280\n",
      "Epoch [34/50], Step [213/735], Loss: 0.1325\n",
      "Epoch [34/50], Step [214/735], Loss: 0.0262\n",
      "Epoch [34/50], Step [215/735], Loss: 0.0790\n",
      "Epoch [34/50], Step [216/735], Loss: 0.0229\n",
      "Epoch [34/50], Step [217/735], Loss: 0.0185\n",
      "Epoch [34/50], Step [218/735], Loss: 0.0538\n",
      "Epoch [34/50], Step [219/735], Loss: 0.0129\n",
      "Epoch [34/50], Step [220/735], Loss: 0.0234\n",
      "Epoch [34/50], Step [221/735], Loss: 0.1221\n",
      "Epoch [34/50], Step [222/735], Loss: 0.0385\n",
      "Epoch [34/50], Step [223/735], Loss: 0.0232\n",
      "Epoch [34/50], Step [224/735], Loss: 0.1436\n",
      "Epoch [34/50], Step [225/735], Loss: 0.0144\n",
      "Epoch [34/50], Step [226/735], Loss: 0.1025\n",
      "Epoch [34/50], Step [227/735], Loss: 0.1287\n",
      "Epoch [34/50], Step [228/735], Loss: 0.1217\n",
      "Epoch [34/50], Step [229/735], Loss: 0.0268\n",
      "Epoch [34/50], Step [230/735], Loss: 0.0813\n",
      "Epoch [34/50], Step [231/735], Loss: 0.0532\n",
      "Epoch [34/50], Step [232/735], Loss: 0.0185\n",
      "Epoch [34/50], Step [233/735], Loss: 0.1471\n",
      "Epoch [34/50], Step [234/735], Loss: 0.0339\n",
      "Epoch [34/50], Step [235/735], Loss: 0.0717\n",
      "Epoch [34/50], Step [236/735], Loss: 0.0389\n",
      "Epoch [34/50], Step [237/735], Loss: 0.0486\n",
      "Epoch [34/50], Step [238/735], Loss: 0.0878\n",
      "Epoch [34/50], Step [239/735], Loss: 0.0707\n",
      "Epoch [34/50], Step [240/735], Loss: 0.0894\n",
      "Epoch [34/50], Step [241/735], Loss: 0.3230\n",
      "Epoch [34/50], Step [242/735], Loss: 0.0493\n",
      "Epoch [34/50], Step [243/735], Loss: 0.0437\n",
      "Epoch [34/50], Step [244/735], Loss: 0.0654\n",
      "Epoch [34/50], Step [245/735], Loss: 0.0622\n",
      "Epoch [34/50], Step [246/735], Loss: 0.1192\n",
      "Epoch [34/50], Step [247/735], Loss: 0.0951\n",
      "Epoch [34/50], Step [248/735], Loss: 0.0516\n",
      "Epoch [34/50], Step [249/735], Loss: 0.0250\n",
      "Epoch [34/50], Step [250/735], Loss: 0.0951\n",
      "Epoch [34/50], Step [251/735], Loss: 0.0836\n",
      "Epoch [34/50], Step [252/735], Loss: 0.1147\n",
      "Epoch [34/50], Step [253/735], Loss: 0.0654\n",
      "Epoch [34/50], Step [254/735], Loss: 0.0520\n",
      "Epoch [34/50], Step [255/735], Loss: 0.0453\n",
      "Epoch [34/50], Step [256/735], Loss: 0.0935\n",
      "Epoch [34/50], Step [257/735], Loss: 0.0453\n",
      "Epoch [34/50], Step [258/735], Loss: 0.1402\n",
      "Epoch [34/50], Step [259/735], Loss: 0.0899\n",
      "Epoch [34/50], Step [260/735], Loss: 0.0548\n",
      "Epoch [34/50], Step [261/735], Loss: 0.0480\n",
      "Epoch [34/50], Step [262/735], Loss: 0.0440\n",
      "Epoch [34/50], Step [263/735], Loss: 0.0816\n",
      "Epoch [34/50], Step [264/735], Loss: 0.1545\n",
      "Epoch [34/50], Step [265/735], Loss: 0.2726\n",
      "Epoch [34/50], Step [266/735], Loss: 0.0875\n",
      "Epoch [34/50], Step [267/735], Loss: 0.0288\n",
      "Epoch [34/50], Step [268/735], Loss: 0.0617\n",
      "Epoch [34/50], Step [269/735], Loss: 0.2883\n",
      "Epoch [34/50], Step [270/735], Loss: 0.0289\n",
      "Epoch [34/50], Step [271/735], Loss: 0.0781\n",
      "Epoch [34/50], Step [272/735], Loss: 0.0454\n",
      "Epoch [34/50], Step [273/735], Loss: 0.0342\n",
      "Epoch [34/50], Step [274/735], Loss: 0.0566\n",
      "Epoch [34/50], Step [275/735], Loss: 0.0452\n",
      "Epoch [34/50], Step [276/735], Loss: 0.0810\n",
      "Epoch [34/50], Step [277/735], Loss: 0.0270\n",
      "Epoch [34/50], Step [278/735], Loss: 0.0742\n",
      "Epoch [34/50], Step [279/735], Loss: 0.2557\n",
      "Epoch [34/50], Step [280/735], Loss: 0.0523\n",
      "Epoch [34/50], Step [281/735], Loss: 0.1405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Step [282/735], Loss: 0.0693\n",
      "Epoch [34/50], Step [283/735], Loss: 0.0335\n",
      "Epoch [34/50], Step [284/735], Loss: 0.0603\n",
      "Epoch [34/50], Step [285/735], Loss: 0.0316\n",
      "Epoch [34/50], Step [286/735], Loss: 0.0772\n",
      "Epoch [34/50], Step [287/735], Loss: 0.0211\n",
      "Epoch [34/50], Step [288/735], Loss: 0.1977\n",
      "Epoch [34/50], Step [289/735], Loss: 0.0629\n",
      "Epoch [34/50], Step [290/735], Loss: 0.0463\n",
      "Epoch [34/50], Step [291/735], Loss: 0.0623\n",
      "Epoch [34/50], Step [292/735], Loss: 0.0483\n",
      "Epoch [34/50], Step [293/735], Loss: 0.0222\n",
      "Epoch [34/50], Step [294/735], Loss: 0.0466\n",
      "Epoch [34/50], Step [295/735], Loss: 0.0249\n",
      "Epoch [34/50], Step [296/735], Loss: 0.3970\n",
      "Epoch [34/50], Step [297/735], Loss: 0.1046\n",
      "Epoch [34/50], Step [298/735], Loss: 0.0494\n",
      "Epoch [34/50], Step [299/735], Loss: 0.0664\n",
      "Epoch [34/50], Step [300/735], Loss: 0.0518\n",
      "Epoch [34/50], Step [301/735], Loss: 0.1103\n",
      "Epoch [34/50], Step [302/735], Loss: 0.0458\n",
      "Epoch [34/50], Step [303/735], Loss: 0.0377\n",
      "Epoch [34/50], Step [304/735], Loss: 0.1765\n",
      "Epoch [34/50], Step [305/735], Loss: 0.0457\n",
      "Epoch [34/50], Step [306/735], Loss: 0.0318\n",
      "Epoch [34/50], Step [307/735], Loss: 0.1486\n",
      "Epoch [34/50], Step [308/735], Loss: 0.0869\n",
      "Epoch [34/50], Step [309/735], Loss: 0.0257\n",
      "Epoch [34/50], Step [310/735], Loss: 0.0680\n",
      "Epoch [34/50], Step [311/735], Loss: 0.0645\n",
      "Epoch [34/50], Step [312/735], Loss: 0.0733\n",
      "Epoch [34/50], Step [313/735], Loss: 0.0648\n",
      "Epoch [34/50], Step [314/735], Loss: 0.0458\n",
      "Epoch [34/50], Step [315/735], Loss: 0.0286\n",
      "Epoch [34/50], Step [316/735], Loss: 0.2670\n",
      "Epoch [34/50], Step [317/735], Loss: 0.0690\n",
      "Epoch [34/50], Step [318/735], Loss: 0.1370\n",
      "Epoch [34/50], Step [319/735], Loss: 0.0466\n",
      "Epoch [34/50], Step [320/735], Loss: 0.1173\n",
      "Epoch [34/50], Step [321/735], Loss: 0.0408\n",
      "Epoch [34/50], Step [322/735], Loss: 0.0799\n",
      "Epoch [34/50], Step [323/735], Loss: 0.0578\n",
      "Epoch [34/50], Step [324/735], Loss: 0.0382\n",
      "Epoch [34/50], Step [325/735], Loss: 0.0533\n",
      "Epoch [34/50], Step [326/735], Loss: 0.0450\n",
      "Epoch [34/50], Step [327/735], Loss: 0.0287\n",
      "Epoch [34/50], Step [328/735], Loss: 0.0339\n",
      "Epoch [34/50], Step [329/735], Loss: 0.0865\n",
      "Epoch [34/50], Step [330/735], Loss: 0.0856\n",
      "Epoch [34/50], Step [331/735], Loss: 0.0256\n",
      "Epoch [34/50], Step [332/735], Loss: 0.1235\n",
      "Epoch [34/50], Step [333/735], Loss: 0.0302\n",
      "Epoch [34/50], Step [334/735], Loss: 0.0523\n",
      "Epoch [34/50], Step [335/735], Loss: 0.0728\n",
      "Epoch [34/50], Step [336/735], Loss: 0.0701\n",
      "Epoch [34/50], Step [337/735], Loss: 0.0451\n",
      "Epoch [34/50], Step [338/735], Loss: 0.1572\n",
      "Epoch [34/50], Step [339/735], Loss: 0.1806\n",
      "Epoch [34/50], Step [340/735], Loss: 0.1557\n",
      "Epoch [34/50], Step [341/735], Loss: 0.0386\n",
      "Epoch [34/50], Step [342/735], Loss: 0.0345\n",
      "Epoch [34/50], Step [343/735], Loss: 0.0257\n",
      "Epoch [34/50], Step [344/735], Loss: 0.1245\n",
      "Epoch [34/50], Step [345/735], Loss: 0.3934\n",
      "Epoch [34/50], Step [346/735], Loss: 0.0618\n",
      "Epoch [34/50], Step [347/735], Loss: 0.0447\n",
      "Epoch [34/50], Step [348/735], Loss: 0.0508\n",
      "Epoch [34/50], Step [349/735], Loss: 0.1463\n",
      "Epoch [34/50], Step [350/735], Loss: 0.1701\n",
      "Epoch [34/50], Step [351/735], Loss: 0.0281\n",
      "Epoch [34/50], Step [352/735], Loss: 0.0941\n",
      "Epoch [34/50], Step [353/735], Loss: 0.0634\n",
      "Epoch [34/50], Step [354/735], Loss: 0.1117\n",
      "Epoch [34/50], Step [355/735], Loss: 0.1214\n",
      "Epoch [34/50], Step [356/735], Loss: 0.0608\n",
      "Epoch [34/50], Step [357/735], Loss: 0.1146\n",
      "Epoch [34/50], Step [358/735], Loss: 0.0774\n",
      "Epoch [34/50], Step [359/735], Loss: 0.0448\n",
      "Epoch [34/50], Step [360/735], Loss: 0.0553\n",
      "Epoch [34/50], Step [361/735], Loss: 0.0685\n",
      "Epoch [34/50], Step [362/735], Loss: 0.0895\n",
      "Epoch [34/50], Step [363/735], Loss: 0.0433\n",
      "Epoch [34/50], Step [364/735], Loss: 0.0423\n",
      "Epoch [34/50], Step [365/735], Loss: 0.0211\n",
      "Epoch [34/50], Step [366/735], Loss: 0.0822\n",
      "Epoch [34/50], Step [367/735], Loss: 0.1197\n",
      "Epoch [34/50], Step [368/735], Loss: 0.0668\n",
      "Epoch [34/50], Step [369/735], Loss: 0.0707\n",
      "Epoch [34/50], Step [370/735], Loss: 0.0408\n",
      "Epoch [34/50], Step [371/735], Loss: 0.0444\n",
      "Epoch [34/50], Step [372/735], Loss: 0.0945\n",
      "Epoch [34/50], Step [373/735], Loss: 0.0573\n",
      "Epoch [34/50], Step [374/735], Loss: 0.2209\n",
      "Epoch [34/50], Step [375/735], Loss: 0.1576\n",
      "Epoch [34/50], Step [376/735], Loss: 0.0419\n",
      "Epoch [34/50], Step [377/735], Loss: 0.0504\n",
      "Epoch [34/50], Step [378/735], Loss: 0.0409\n",
      "Epoch [34/50], Step [379/735], Loss: 0.0338\n",
      "Epoch [34/50], Step [380/735], Loss: 0.0321\n",
      "Epoch [34/50], Step [381/735], Loss: 0.0222\n",
      "Epoch [34/50], Step [382/735], Loss: 0.0178\n",
      "Epoch [34/50], Step [383/735], Loss: 0.0434\n",
      "Epoch [34/50], Step [384/735], Loss: 0.6508\n",
      "Epoch [34/50], Step [385/735], Loss: 0.1590\n",
      "Epoch [34/50], Step [386/735], Loss: 0.0823\n",
      "Epoch [34/50], Step [387/735], Loss: 0.0788\n",
      "Epoch [34/50], Step [388/735], Loss: 0.0403\n",
      "Epoch [34/50], Step [389/735], Loss: 0.0401\n",
      "Epoch [34/50], Step [390/735], Loss: 0.1481\n",
      "Epoch [34/50], Step [391/735], Loss: 0.0626\n",
      "Epoch [34/50], Step [392/735], Loss: 0.0642\n",
      "Epoch [34/50], Step [393/735], Loss: 0.0382\n",
      "Epoch [34/50], Step [394/735], Loss: 0.0481\n",
      "Epoch [34/50], Step [395/735], Loss: 0.0412\n",
      "Epoch [34/50], Step [396/735], Loss: 0.0247\n",
      "Epoch [34/50], Step [397/735], Loss: 0.0298\n",
      "Epoch [34/50], Step [398/735], Loss: 0.0351\n",
      "Epoch [34/50], Step [399/735], Loss: 0.0468\n",
      "Epoch [34/50], Step [400/735], Loss: 0.0914\n",
      "Epoch [34/50], Step [401/735], Loss: 0.0313\n",
      "Epoch [34/50], Step [402/735], Loss: 0.1495\n",
      "Epoch [34/50], Step [403/735], Loss: 0.1097\n",
      "Epoch [34/50], Step [404/735], Loss: 0.0590\n",
      "Epoch [34/50], Step [405/735], Loss: 0.0640\n",
      "Epoch [34/50], Step [406/735], Loss: 0.0653\n",
      "Epoch [34/50], Step [407/735], Loss: 0.0241\n",
      "Epoch [34/50], Step [408/735], Loss: 0.0372\n",
      "Epoch [34/50], Step [409/735], Loss: 0.0442\n",
      "Epoch [34/50], Step [410/735], Loss: 0.0410\n",
      "Epoch [34/50], Step [411/735], Loss: 0.1246\n",
      "Epoch [34/50], Step [412/735], Loss: 0.0190\n",
      "Epoch [34/50], Step [413/735], Loss: 0.0513\n",
      "Epoch [34/50], Step [414/735], Loss: 0.0361\n",
      "Epoch [34/50], Step [415/735], Loss: 0.0654\n",
      "Epoch [34/50], Step [416/735], Loss: 0.0236\n",
      "Epoch [34/50], Step [417/735], Loss: 0.0671\n",
      "Epoch [34/50], Step [418/735], Loss: 0.0638\n",
      "Epoch [34/50], Step [419/735], Loss: 0.0245\n",
      "Epoch [34/50], Step [420/735], Loss: 0.0695\n",
      "Epoch [34/50], Step [421/735], Loss: 0.0509\n",
      "Epoch [34/50], Step [422/735], Loss: 0.0361\n",
      "Epoch [34/50], Step [423/735], Loss: 0.0212\n",
      "Epoch [34/50], Step [424/735], Loss: 0.0240\n",
      "Epoch [34/50], Step [425/735], Loss: 0.0737\n",
      "Epoch [34/50], Step [426/735], Loss: 0.0594\n",
      "Epoch [34/50], Step [427/735], Loss: 0.1026\n",
      "Epoch [34/50], Step [428/735], Loss: 0.0595\n",
      "Epoch [34/50], Step [429/735], Loss: 0.0853\n",
      "Epoch [34/50], Step [430/735], Loss: 0.0181\n",
      "Epoch [34/50], Step [431/735], Loss: 0.0304\n",
      "Epoch [34/50], Step [432/735], Loss: 0.0345\n",
      "Epoch [34/50], Step [433/735], Loss: 0.1228\n",
      "Epoch [34/50], Step [434/735], Loss: 0.0262\n",
      "Epoch [34/50], Step [435/735], Loss: 0.0358\n",
      "Epoch [34/50], Step [436/735], Loss: 0.0926\n",
      "Epoch [34/50], Step [437/735], Loss: 0.0458\n",
      "Epoch [34/50], Step [438/735], Loss: 0.0441\n",
      "Epoch [34/50], Step [439/735], Loss: 0.0394\n",
      "Epoch [34/50], Step [440/735], Loss: 0.0351\n",
      "Epoch [34/50], Step [441/735], Loss: 0.1014\n",
      "Epoch [34/50], Step [442/735], Loss: 0.0265\n",
      "Epoch [34/50], Step [443/735], Loss: 0.0294\n",
      "Epoch [34/50], Step [444/735], Loss: 0.0582\n",
      "Epoch [34/50], Step [445/735], Loss: 0.0408\n",
      "Epoch [34/50], Step [446/735], Loss: 0.0534\n",
      "Epoch [34/50], Step [447/735], Loss: 0.1034\n",
      "Epoch [34/50], Step [448/735], Loss: 0.0689\n",
      "Epoch [34/50], Step [449/735], Loss: 0.0593\n",
      "Epoch [34/50], Step [450/735], Loss: 0.0211\n",
      "Epoch [34/50], Step [451/735], Loss: 0.0505\n",
      "Epoch [34/50], Step [452/735], Loss: 0.0421\n",
      "Epoch [34/50], Step [453/735], Loss: 0.0673\n",
      "Epoch [34/50], Step [454/735], Loss: 0.0290\n",
      "Epoch [34/50], Step [455/735], Loss: 0.1185\n",
      "Epoch [34/50], Step [456/735], Loss: 0.1098\n",
      "Epoch [34/50], Step [457/735], Loss: 0.0347\n",
      "Epoch [34/50], Step [458/735], Loss: 0.0331\n",
      "Epoch [34/50], Step [459/735], Loss: 0.1578\n",
      "Epoch [34/50], Step [460/735], Loss: 0.0413\n",
      "Epoch [34/50], Step [461/735], Loss: 0.0460\n",
      "Epoch [34/50], Step [462/735], Loss: 0.0359\n",
      "Epoch [34/50], Step [463/735], Loss: 0.1020\n",
      "Epoch [34/50], Step [464/735], Loss: 0.0938\n",
      "Epoch [34/50], Step [465/735], Loss: 0.0303\n",
      "Epoch [34/50], Step [466/735], Loss: 0.2018\n",
      "Epoch [34/50], Step [467/735], Loss: 0.0447\n",
      "Epoch [34/50], Step [468/735], Loss: 0.0369\n",
      "Epoch [34/50], Step [469/735], Loss: 0.0181\n",
      "Epoch [34/50], Step [470/735], Loss: 0.0963\n",
      "Epoch [34/50], Step [471/735], Loss: 0.1916\n",
      "Epoch [34/50], Step [472/735], Loss: 0.1150\n",
      "Epoch [34/50], Step [473/735], Loss: 0.0325\n",
      "Epoch [34/50], Step [474/735], Loss: 0.0676\n",
      "Epoch [34/50], Step [475/735], Loss: 0.0542\n",
      "Epoch [34/50], Step [476/735], Loss: 0.2494\n",
      "Epoch [34/50], Step [477/735], Loss: 0.0681\n",
      "Epoch [34/50], Step [478/735], Loss: 0.0673\n",
      "Epoch [34/50], Step [479/735], Loss: 0.0945\n",
      "Epoch [34/50], Step [480/735], Loss: 0.0241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Step [481/735], Loss: 0.1103\n",
      "Epoch [34/50], Step [482/735], Loss: 0.0347\n",
      "Epoch [34/50], Step [483/735], Loss: 0.0715\n",
      "Epoch [34/50], Step [484/735], Loss: 0.0690\n",
      "Epoch [34/50], Step [485/735], Loss: 0.0310\n",
      "Epoch [34/50], Step [486/735], Loss: 0.0412\n",
      "Epoch [34/50], Step [487/735], Loss: 0.0426\n",
      "Epoch [34/50], Step [488/735], Loss: 0.0464\n",
      "Epoch [34/50], Step [489/735], Loss: 0.1077\n",
      "Epoch [34/50], Step [490/735], Loss: 0.0743\n",
      "Epoch [34/50], Step [491/735], Loss: 0.0302\n",
      "Epoch [34/50], Step [492/735], Loss: 0.1025\n",
      "Epoch [34/50], Step [493/735], Loss: 0.1492\n",
      "Epoch [34/50], Step [494/735], Loss: 0.0718\n",
      "Epoch [34/50], Step [495/735], Loss: 0.0579\n",
      "Epoch [34/50], Step [496/735], Loss: 0.3015\n",
      "Epoch [34/50], Step [497/735], Loss: 0.0769\n",
      "Epoch [34/50], Step [498/735], Loss: 0.0620\n",
      "Epoch [34/50], Step [499/735], Loss: 0.0442\n",
      "Epoch [34/50], Step [500/735], Loss: 0.0837\n",
      "Epoch [34/50], Step [501/735], Loss: 0.0644\n",
      "Epoch [34/50], Step [502/735], Loss: 0.1302\n",
      "Epoch [34/50], Step [503/735], Loss: 0.0634\n",
      "Epoch [34/50], Step [504/735], Loss: 0.0790\n",
      "Epoch [34/50], Step [505/735], Loss: 0.0312\n",
      "Epoch [34/50], Step [506/735], Loss: 0.1396\n",
      "Epoch [34/50], Step [507/735], Loss: 0.0689\n",
      "Epoch [34/50], Step [508/735], Loss: 0.1271\n",
      "Epoch [34/50], Step [509/735], Loss: 0.0242\n",
      "Epoch [34/50], Step [510/735], Loss: 0.0409\n",
      "Epoch [34/50], Step [511/735], Loss: 0.0302\n",
      "Epoch [34/50], Step [512/735], Loss: 0.0450\n",
      "Epoch [34/50], Step [513/735], Loss: 0.0322\n",
      "Epoch [34/50], Step [514/735], Loss: 0.0322\n",
      "Epoch [34/50], Step [515/735], Loss: 0.0243\n",
      "Epoch [34/50], Step [516/735], Loss: 0.0343\n",
      "Epoch [34/50], Step [517/735], Loss: 0.0509\n",
      "Epoch [34/50], Step [518/735], Loss: 0.1011\n",
      "Epoch [34/50], Step [519/735], Loss: 0.0328\n",
      "Epoch [34/50], Step [520/735], Loss: 0.0278\n",
      "Epoch [34/50], Step [521/735], Loss: 0.2365\n",
      "Epoch [34/50], Step [522/735], Loss: 0.0212\n",
      "Epoch [34/50], Step [523/735], Loss: 0.0472\n",
      "Epoch [34/50], Step [524/735], Loss: 0.0332\n",
      "Epoch [34/50], Step [525/735], Loss: 0.0475\n",
      "Epoch [34/50], Step [526/735], Loss: 0.0302\n",
      "Epoch [34/50], Step [527/735], Loss: 0.0561\n",
      "Epoch [34/50], Step [528/735], Loss: 0.0488\n",
      "Epoch [34/50], Step [529/735], Loss: 0.0391\n",
      "Epoch [34/50], Step [530/735], Loss: 0.0306\n",
      "Epoch [34/50], Step [531/735], Loss: 0.0612\n",
      "Epoch [34/50], Step [532/735], Loss: 0.0702\n",
      "Epoch [34/50], Step [533/735], Loss: 0.1272\n",
      "Epoch [34/50], Step [534/735], Loss: 0.0405\n",
      "Epoch [34/50], Step [535/735], Loss: 0.0514\n",
      "Epoch [34/50], Step [536/735], Loss: 0.0424\n",
      "Epoch [34/50], Step [537/735], Loss: 0.0328\n",
      "Epoch [34/50], Step [538/735], Loss: 0.0595\n",
      "Epoch [34/50], Step [539/735], Loss: 0.0223\n",
      "Epoch [34/50], Step [540/735], Loss: 0.0234\n",
      "Epoch [34/50], Step [541/735], Loss: 0.0874\n",
      "Epoch [34/50], Step [542/735], Loss: 0.0318\n",
      "Epoch [34/50], Step [543/735], Loss: 0.0606\n",
      "Epoch [34/50], Step [544/735], Loss: 0.0323\n",
      "Epoch [34/50], Step [545/735], Loss: 0.0282\n",
      "Epoch [34/50], Step [546/735], Loss: 0.1142\n",
      "Epoch [34/50], Step [547/735], Loss: 0.1229\n",
      "Epoch [34/50], Step [548/735], Loss: 0.0271\n",
      "Epoch [34/50], Step [549/735], Loss: 0.0434\n",
      "Epoch [34/50], Step [550/735], Loss: 0.0699\n",
      "Epoch [34/50], Step [551/735], Loss: 0.0722\n",
      "Epoch [34/50], Step [552/735], Loss: 0.0272\n",
      "Epoch [34/50], Step [553/735], Loss: 0.0377\n",
      "Epoch [34/50], Step [554/735], Loss: 0.0562\n",
      "Epoch [34/50], Step [555/735], Loss: 0.0452\n",
      "Epoch [34/50], Step [556/735], Loss: 0.0562\n",
      "Epoch [34/50], Step [557/735], Loss: 0.0351\n",
      "Epoch [34/50], Step [558/735], Loss: 0.1879\n",
      "Epoch [34/50], Step [559/735], Loss: 0.1603\n",
      "Epoch [34/50], Step [560/735], Loss: 0.0522\n",
      "Epoch [34/50], Step [561/735], Loss: 0.0300\n",
      "Epoch [34/50], Step [562/735], Loss: 0.0501\n",
      "Epoch [34/50], Step [563/735], Loss: 0.1613\n",
      "Epoch [34/50], Step [564/735], Loss: 0.0785\n",
      "Epoch [34/50], Step [565/735], Loss: 0.0665\n",
      "Epoch [34/50], Step [566/735], Loss: 0.0290\n",
      "Epoch [34/50], Step [567/735], Loss: 0.0630\n",
      "Epoch [34/50], Step [568/735], Loss: 0.0304\n",
      "Epoch [34/50], Step [569/735], Loss: 0.0329\n",
      "Epoch [34/50], Step [570/735], Loss: 0.0628\n",
      "Epoch [34/50], Step [571/735], Loss: 0.0532\n",
      "Epoch [34/50], Step [572/735], Loss: 0.0380\n",
      "Epoch [34/50], Step [573/735], Loss: 0.0357\n",
      "Epoch [34/50], Step [574/735], Loss: 0.0493\n",
      "Epoch [34/50], Step [575/735], Loss: 0.0174\n",
      "Epoch [34/50], Step [576/735], Loss: 0.0226\n",
      "Epoch [34/50], Step [577/735], Loss: 0.0816\n",
      "Epoch [34/50], Step [578/735], Loss: 0.0523\n",
      "Epoch [34/50], Step [579/735], Loss: 0.1180\n",
      "Epoch [34/50], Step [580/735], Loss: 0.0354\n",
      "Epoch [34/50], Step [581/735], Loss: 0.0758\n",
      "Epoch [34/50], Step [582/735], Loss: 0.0790\n",
      "Epoch [34/50], Step [583/735], Loss: 0.1926\n",
      "Epoch [34/50], Step [584/735], Loss: 0.0732\n",
      "Epoch [34/50], Step [585/735], Loss: 0.0351\n",
      "Epoch [34/50], Step [586/735], Loss: 0.2043\n",
      "Epoch [34/50], Step [587/735], Loss: 0.0610\n",
      "Epoch [34/50], Step [588/735], Loss: 0.1060\n",
      "Epoch [34/50], Step [589/735], Loss: 0.0327\n",
      "Epoch [34/50], Step [590/735], Loss: 0.0657\n",
      "Epoch [34/50], Step [591/735], Loss: 0.0997\n",
      "Epoch [34/50], Step [592/735], Loss: 0.1851\n",
      "Epoch [34/50], Step [593/735], Loss: 0.0770\n",
      "Epoch [34/50], Step [594/735], Loss: 0.0812\n",
      "Epoch [34/50], Step [595/735], Loss: 0.0607\n",
      "Epoch [34/50], Step [596/735], Loss: 0.0635\n",
      "Epoch [34/50], Step [597/735], Loss: 0.0947\n",
      "Epoch [34/50], Step [598/735], Loss: 0.0317\n",
      "Epoch [34/50], Step [599/735], Loss: 0.0453\n",
      "Epoch [34/50], Step [600/735], Loss: 0.0327\n",
      "Epoch [34/50], Step [601/735], Loss: 0.0571\n",
      "Epoch [34/50], Step [602/735], Loss: 0.0332\n",
      "Epoch [34/50], Step [603/735], Loss: 0.0498\n",
      "Epoch [34/50], Step [604/735], Loss: 0.0659\n",
      "Epoch [34/50], Step [605/735], Loss: 0.0663\n",
      "Epoch [34/50], Step [606/735], Loss: 0.1082\n",
      "Epoch [34/50], Step [607/735], Loss: 0.0444\n",
      "Epoch [34/50], Step [608/735], Loss: 0.0365\n",
      "Epoch [34/50], Step [609/735], Loss: 0.0417\n",
      "Epoch [34/50], Step [610/735], Loss: 0.0728\n",
      "Epoch [34/50], Step [611/735], Loss: 0.0698\n",
      "Epoch [34/50], Step [612/735], Loss: 0.0466\n",
      "Epoch [34/50], Step [613/735], Loss: 0.0749\n",
      "Epoch [34/50], Step [614/735], Loss: 0.0211\n",
      "Epoch [34/50], Step [615/735], Loss: 0.0522\n",
      "Epoch [34/50], Step [616/735], Loss: 0.0436\n",
      "Epoch [34/50], Step [617/735], Loss: 0.0294\n",
      "Epoch [34/50], Step [618/735], Loss: 0.0252\n",
      "Epoch [34/50], Step [619/735], Loss: 0.0503\n",
      "Epoch [34/50], Step [620/735], Loss: 0.0543\n",
      "Epoch [34/50], Step [621/735], Loss: 0.0631\n",
      "Epoch [34/50], Step [622/735], Loss: 0.0167\n",
      "Epoch [34/50], Step [623/735], Loss: 0.0427\n",
      "Epoch [34/50], Step [624/735], Loss: 0.2128\n",
      "Epoch [34/50], Step [625/735], Loss: 0.0724\n",
      "Epoch [34/50], Step [626/735], Loss: 0.0556\n",
      "Epoch [34/50], Step [627/735], Loss: 0.0649\n",
      "Epoch [34/50], Step [628/735], Loss: 0.0386\n",
      "Epoch [34/50], Step [629/735], Loss: 0.0881\n",
      "Epoch [34/50], Step [630/735], Loss: 0.3510\n",
      "Epoch [34/50], Step [631/735], Loss: 0.1238\n",
      "Epoch [34/50], Step [632/735], Loss: 0.0497\n",
      "Epoch [34/50], Step [633/735], Loss: 0.0386\n",
      "Epoch [34/50], Step [634/735], Loss: 0.0449\n",
      "Epoch [34/50], Step [635/735], Loss: 0.1932\n",
      "Epoch [34/50], Step [636/735], Loss: 0.0948\n",
      "Epoch [34/50], Step [637/735], Loss: 0.0597\n",
      "Epoch [34/50], Step [638/735], Loss: 0.0724\n",
      "Epoch [34/50], Step [639/735], Loss: 0.0296\n",
      "Epoch [34/50], Step [640/735], Loss: 0.0301\n",
      "Epoch [34/50], Step [641/735], Loss: 0.0208\n",
      "Epoch [34/50], Step [642/735], Loss: 0.0654\n",
      "Epoch [34/50], Step [643/735], Loss: 0.0633\n",
      "Epoch [34/50], Step [644/735], Loss: 0.0581\n",
      "Epoch [34/50], Step [645/735], Loss: 0.0306\n",
      "Epoch [34/50], Step [646/735], Loss: 0.0583\n",
      "Epoch [34/50], Step [647/735], Loss: 0.0692\n",
      "Epoch [34/50], Step [648/735], Loss: 0.0289\n",
      "Epoch [34/50], Step [649/735], Loss: 0.0681\n",
      "Epoch [34/50], Step [650/735], Loss: 0.1663\n",
      "Epoch [34/50], Step [651/735], Loss: 0.0704\n",
      "Epoch [34/50], Step [652/735], Loss: 0.0495\n",
      "Epoch [34/50], Step [653/735], Loss: 0.0656\n",
      "Epoch [34/50], Step [654/735], Loss: 0.0569\n",
      "Epoch [34/50], Step [655/735], Loss: 0.0670\n",
      "Epoch [34/50], Step [656/735], Loss: 0.3993\n",
      "Epoch [34/50], Step [657/735], Loss: 0.5485\n",
      "Epoch [34/50], Step [658/735], Loss: 0.0393\n",
      "Epoch [34/50], Step [659/735], Loss: 0.0535\n",
      "Epoch [34/50], Step [660/735], Loss: 0.0762\n",
      "Epoch [34/50], Step [661/735], Loss: 0.0249\n",
      "Epoch [34/50], Step [662/735], Loss: 0.0951\n",
      "Epoch [34/50], Step [663/735], Loss: 0.1224\n",
      "Epoch [34/50], Step [664/735], Loss: 0.1712\n",
      "Epoch [34/50], Step [665/735], Loss: 0.0536\n",
      "Epoch [34/50], Step [666/735], Loss: 0.0561\n",
      "Epoch [34/50], Step [667/735], Loss: 0.0718\n",
      "Epoch [34/50], Step [668/735], Loss: 0.0930\n",
      "Epoch [34/50], Step [669/735], Loss: 0.0363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Step [670/735], Loss: 0.0765\n",
      "Epoch [34/50], Step [671/735], Loss: 0.0796\n",
      "Epoch [34/50], Step [672/735], Loss: 0.4281\n",
      "Epoch [34/50], Step [673/735], Loss: 0.0440\n",
      "Epoch [34/50], Step [674/735], Loss: 0.0879\n",
      "Epoch [34/50], Step [675/735], Loss: 0.1182\n",
      "Epoch [34/50], Step [676/735], Loss: 0.0835\n",
      "Epoch [34/50], Step [677/735], Loss: 0.0478\n",
      "Epoch [34/50], Step [678/735], Loss: 0.0623\n",
      "Epoch [34/50], Step [679/735], Loss: 0.0677\n",
      "Epoch [34/50], Step [680/735], Loss: 0.0257\n",
      "Epoch [34/50], Step [681/735], Loss: 0.0748\n",
      "Epoch [34/50], Step [682/735], Loss: 0.0430\n",
      "Epoch [34/50], Step [683/735], Loss: 0.0371\n",
      "Epoch [34/50], Step [684/735], Loss: 0.0306\n",
      "Epoch [34/50], Step [685/735], Loss: 0.0373\n",
      "Epoch [34/50], Step [686/735], Loss: 0.0501\n",
      "Epoch [34/50], Step [687/735], Loss: 0.0434\n",
      "Epoch [34/50], Step [688/735], Loss: 0.0374\n",
      "Epoch [34/50], Step [689/735], Loss: 0.0438\n",
      "Epoch [34/50], Step [690/735], Loss: 0.0310\n",
      "Epoch [34/50], Step [691/735], Loss: 0.0477\n",
      "Epoch [34/50], Step [692/735], Loss: 0.0547\n",
      "Epoch [34/50], Step [693/735], Loss: 0.0294\n",
      "Epoch [34/50], Step [694/735], Loss: 0.1840\n",
      "Epoch [34/50], Step [695/735], Loss: 0.0567\n",
      "Epoch [34/50], Step [696/735], Loss: 0.0226\n",
      "Epoch [34/50], Step [697/735], Loss: 0.0549\n",
      "Epoch [34/50], Step [698/735], Loss: 0.0668\n",
      "Epoch [34/50], Step [699/735], Loss: 0.0541\n",
      "Epoch [34/50], Step [700/735], Loss: 0.0500\n",
      "Epoch [34/50], Step [701/735], Loss: 0.0702\n",
      "Epoch [34/50], Step [702/735], Loss: 0.1336\n",
      "Epoch [34/50], Step [703/735], Loss: 0.0461\n",
      "Epoch [34/50], Step [704/735], Loss: 0.0386\n",
      "Epoch [34/50], Step [705/735], Loss: 0.0661\n",
      "Epoch [34/50], Step [706/735], Loss: 0.0323\n",
      "Epoch [34/50], Step [707/735], Loss: 0.0420\n",
      "Epoch [34/50], Step [708/735], Loss: 0.0482\n",
      "Epoch [34/50], Step [709/735], Loss: 0.0308\n",
      "Epoch [34/50], Step [710/735], Loss: 0.0405\n",
      "Epoch [34/50], Step [711/735], Loss: 0.0250\n",
      "Epoch [34/50], Step [712/735], Loss: 0.0498\n",
      "Epoch [34/50], Step [713/735], Loss: 0.0615\n",
      "Epoch [34/50], Step [714/735], Loss: 0.0168\n",
      "Epoch [34/50], Step [715/735], Loss: 0.0694\n",
      "Epoch [34/50], Step [716/735], Loss: 0.2443\n",
      "Epoch [34/50], Step [717/735], Loss: 0.1621\n",
      "Epoch [34/50], Step [718/735], Loss: 0.3207\n",
      "Epoch [34/50], Step [719/735], Loss: 0.0275\n",
      "Epoch [34/50], Step [720/735], Loss: 0.1333\n",
      "Epoch [34/50], Step [721/735], Loss: 0.0486\n",
      "Epoch [34/50], Step [722/735], Loss: 0.0231\n",
      "Epoch [34/50], Step [723/735], Loss: 0.0230\n",
      "Epoch [34/50], Step [724/735], Loss: 0.0329\n",
      "Epoch [34/50], Step [725/735], Loss: 0.0292\n",
      "Epoch [34/50], Step [726/735], Loss: 0.0701\n",
      "Epoch [34/50], Step [727/735], Loss: 0.0863\n",
      "Epoch [34/50], Step [728/735], Loss: 0.0606\n",
      "Epoch [34/50], Step [729/735], Loss: 0.0379\n",
      "Epoch [34/50], Step [730/735], Loss: 0.1041\n",
      "Epoch [34/50], Step [731/735], Loss: 0.0510\n",
      "Epoch [34/50], Step [732/735], Loss: 0.0268\n",
      "Epoch [34/50], Step [733/735], Loss: 0.2121\n",
      "Epoch [34/50], Step [734/735], Loss: 0.0313\n",
      "Epoch [34/50], Step [735/735], Loss: 0.0355\n",
      "Epoch [35/50], Step [1/735], Loss: 0.1086\n",
      "Epoch [35/50], Step [2/735], Loss: 0.0932\n",
      "Epoch [35/50], Step [3/735], Loss: 0.0541\n",
      "Epoch [35/50], Step [4/735], Loss: 0.0351\n",
      "Epoch [35/50], Step [5/735], Loss: 0.0719\n",
      "Epoch [35/50], Step [6/735], Loss: 0.0651\n",
      "Epoch [35/50], Step [7/735], Loss: 0.1002\n",
      "Epoch [35/50], Step [8/735], Loss: 0.0467\n",
      "Epoch [35/50], Step [9/735], Loss: 0.0361\n",
      "Epoch [35/50], Step [10/735], Loss: 0.0489\n",
      "Epoch [35/50], Step [11/735], Loss: 0.0654\n",
      "Epoch [35/50], Step [12/735], Loss: 0.0228\n",
      "Epoch [35/50], Step [13/735], Loss: 0.0300\n",
      "Epoch [35/50], Step [14/735], Loss: 0.0413\n",
      "Epoch [35/50], Step [15/735], Loss: 0.0249\n",
      "Epoch [35/50], Step [16/735], Loss: 0.1103\n",
      "Epoch [35/50], Step [17/735], Loss: 0.0326\n",
      "Epoch [35/50], Step [18/735], Loss: 0.0955\n",
      "Epoch [35/50], Step [19/735], Loss: 0.0957\n",
      "Epoch [35/50], Step [20/735], Loss: 0.0550\n",
      "Epoch [35/50], Step [21/735], Loss: 0.0289\n",
      "Epoch [35/50], Step [22/735], Loss: 0.0567\n",
      "Epoch [35/50], Step [23/735], Loss: 0.0222\n",
      "Epoch [35/50], Step [24/735], Loss: 0.2406\n",
      "Epoch [35/50], Step [25/735], Loss: 0.0597\n",
      "Epoch [35/50], Step [26/735], Loss: 0.0331\n",
      "Epoch [35/50], Step [27/735], Loss: 0.0352\n",
      "Epoch [35/50], Step [28/735], Loss: 0.0795\n",
      "Epoch [35/50], Step [29/735], Loss: 0.0335\n",
      "Epoch [35/50], Step [30/735], Loss: 0.1123\n",
      "Epoch [35/50], Step [31/735], Loss: 0.1106\n",
      "Epoch [35/50], Step [32/735], Loss: 0.0507\n",
      "Epoch [35/50], Step [33/735], Loss: 0.1189\n",
      "Epoch [35/50], Step [34/735], Loss: 0.0230\n",
      "Epoch [35/50], Step [35/735], Loss: 0.0797\n",
      "Epoch [35/50], Step [36/735], Loss: 0.0990\n",
      "Epoch [35/50], Step [37/735], Loss: 0.0651\n",
      "Epoch [35/50], Step [38/735], Loss: 0.0683\n",
      "Epoch [35/50], Step [39/735], Loss: 0.0262\n",
      "Epoch [35/50], Step [40/735], Loss: 0.0626\n",
      "Epoch [35/50], Step [41/735], Loss: 0.0603\n",
      "Epoch [35/50], Step [42/735], Loss: 0.0442\n",
      "Epoch [35/50], Step [43/735], Loss: 0.0308\n",
      "Epoch [35/50], Step [44/735], Loss: 0.0358\n",
      "Epoch [35/50], Step [45/735], Loss: 0.0928\n",
      "Epoch [35/50], Step [46/735], Loss: 0.0785\n",
      "Epoch [35/50], Step [47/735], Loss: 0.0286\n",
      "Epoch [35/50], Step [48/735], Loss: 0.0438\n",
      "Epoch [35/50], Step [49/735], Loss: 0.1127\n",
      "Epoch [35/50], Step [50/735], Loss: 0.0262\n",
      "Epoch [35/50], Step [51/735], Loss: 0.0513\n",
      "Epoch [35/50], Step [52/735], Loss: 0.1191\n",
      "Epoch [35/50], Step [53/735], Loss: 0.1638\n",
      "Epoch [35/50], Step [54/735], Loss: 0.0357\n",
      "Epoch [35/50], Step [55/735], Loss: 0.0901\n",
      "Epoch [35/50], Step [56/735], Loss: 0.0235\n",
      "Epoch [35/50], Step [57/735], Loss: 0.0875\n",
      "Epoch [35/50], Step [58/735], Loss: 0.0568\n",
      "Epoch [35/50], Step [59/735], Loss: 0.0727\n",
      "Epoch [35/50], Step [60/735], Loss: 0.0183\n",
      "Epoch [35/50], Step [61/735], Loss: 0.0201\n",
      "Epoch [35/50], Step [62/735], Loss: 0.0356\n",
      "Epoch [35/50], Step [63/735], Loss: 0.0227\n",
      "Epoch [35/50], Step [64/735], Loss: 0.0563\n",
      "Epoch [35/50], Step [65/735], Loss: 0.0398\n",
      "Epoch [35/50], Step [66/735], Loss: 0.0272\n",
      "Epoch [35/50], Step [67/735], Loss: 0.0399\n",
      "Epoch [35/50], Step [68/735], Loss: 0.0229\n",
      "Epoch [35/50], Step [69/735], Loss: 0.1399\n",
      "Epoch [35/50], Step [70/735], Loss: 0.0801\n",
      "Epoch [35/50], Step [71/735], Loss: 0.0215\n",
      "Epoch [35/50], Step [72/735], Loss: 0.2030\n",
      "Epoch [35/50], Step [73/735], Loss: 0.0383\n",
      "Epoch [35/50], Step [74/735], Loss: 0.0213\n",
      "Epoch [35/50], Step [75/735], Loss: 0.0641\n",
      "Epoch [35/50], Step [76/735], Loss: 0.1195\n",
      "Epoch [35/50], Step [77/735], Loss: 0.0544\n",
      "Epoch [35/50], Step [78/735], Loss: 0.0344\n",
      "Epoch [35/50], Step [79/735], Loss: 0.0561\n",
      "Epoch [35/50], Step [80/735], Loss: 0.0445\n",
      "Epoch [35/50], Step [81/735], Loss: 0.0481\n",
      "Epoch [35/50], Step [82/735], Loss: 0.0494\n",
      "Epoch [35/50], Step [83/735], Loss: 0.0317\n",
      "Epoch [35/50], Step [84/735], Loss: 0.0660\n",
      "Epoch [35/50], Step [85/735], Loss: 0.1150\n",
      "Epoch [35/50], Step [86/735], Loss: 0.0220\n",
      "Epoch [35/50], Step [87/735], Loss: 0.0425\n",
      "Epoch [35/50], Step [88/735], Loss: 0.0507\n",
      "Epoch [35/50], Step [89/735], Loss: 0.1202\n",
      "Epoch [35/50], Step [90/735], Loss: 0.0301\n",
      "Epoch [35/50], Step [91/735], Loss: 0.0685\n",
      "Epoch [35/50], Step [92/735], Loss: 0.0404\n",
      "Epoch [35/50], Step [93/735], Loss: 0.0436\n",
      "Epoch [35/50], Step [94/735], Loss: 0.0627\n",
      "Epoch [35/50], Step [95/735], Loss: 0.0281\n",
      "Epoch [35/50], Step [96/735], Loss: 0.0689\n",
      "Epoch [35/50], Step [97/735], Loss: 0.0308\n",
      "Epoch [35/50], Step [98/735], Loss: 0.0390\n",
      "Epoch [35/50], Step [99/735], Loss: 0.0423\n",
      "Epoch [35/50], Step [100/735], Loss: 0.0338\n",
      "Epoch [35/50], Step [101/735], Loss: 0.0560\n",
      "Epoch [35/50], Step [102/735], Loss: 0.0283\n",
      "Epoch [35/50], Step [103/735], Loss: 0.1368\n",
      "Epoch [35/50], Step [104/735], Loss: 0.0180\n",
      "Epoch [35/50], Step [105/735], Loss: 0.0606\n",
      "Epoch [35/50], Step [106/735], Loss: 0.0472\n",
      "Epoch [35/50], Step [107/735], Loss: 0.0576\n",
      "Epoch [35/50], Step [108/735], Loss: 0.0501\n",
      "Epoch [35/50], Step [109/735], Loss: 0.1824\n",
      "Epoch [35/50], Step [110/735], Loss: 0.0719\n",
      "Epoch [35/50], Step [111/735], Loss: 0.0465\n",
      "Epoch [35/50], Step [112/735], Loss: 0.0316\n",
      "Epoch [35/50], Step [113/735], Loss: 0.1110\n",
      "Epoch [35/50], Step [114/735], Loss: 0.1350\n",
      "Epoch [35/50], Step [115/735], Loss: 0.0774\n",
      "Epoch [35/50], Step [116/735], Loss: 0.1006\n",
      "Epoch [35/50], Step [117/735], Loss: 0.0609\n",
      "Epoch [35/50], Step [118/735], Loss: 0.0795\n",
      "Epoch [35/50], Step [119/735], Loss: 0.0385\n",
      "Epoch [35/50], Step [120/735], Loss: 0.0576\n",
      "Epoch [35/50], Step [121/735], Loss: 0.0571\n",
      "Epoch [35/50], Step [122/735], Loss: 0.0774\n",
      "Epoch [35/50], Step [123/735], Loss: 0.0595\n",
      "Epoch [35/50], Step [124/735], Loss: 0.1067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Step [125/735], Loss: 0.0477\n",
      "Epoch [35/50], Step [126/735], Loss: 0.1200\n",
      "Epoch [35/50], Step [127/735], Loss: 0.0602\n",
      "Epoch [35/50], Step [128/735], Loss: 0.0181\n",
      "Epoch [35/50], Step [129/735], Loss: 0.0508\n",
      "Epoch [35/50], Step [130/735], Loss: 0.0601\n",
      "Epoch [35/50], Step [131/735], Loss: 0.0340\n",
      "Epoch [35/50], Step [132/735], Loss: 0.0196\n",
      "Epoch [35/50], Step [133/735], Loss: 0.0502\n",
      "Epoch [35/50], Step [134/735], Loss: 0.0287\n",
      "Epoch [35/50], Step [135/735], Loss: 0.1148\n",
      "Epoch [35/50], Step [136/735], Loss: 0.0437\n",
      "Epoch [35/50], Step [137/735], Loss: 0.0375\n",
      "Epoch [35/50], Step [138/735], Loss: 0.0753\n",
      "Epoch [35/50], Step [139/735], Loss: 0.0979\n",
      "Epoch [35/50], Step [140/735], Loss: 0.1292\n",
      "Epoch [35/50], Step [141/735], Loss: 0.0267\n",
      "Epoch [35/50], Step [142/735], Loss: 0.1196\n",
      "Epoch [35/50], Step [143/735], Loss: 0.0386\n",
      "Epoch [35/50], Step [144/735], Loss: 0.0399\n",
      "Epoch [35/50], Step [145/735], Loss: 0.0258\n",
      "Epoch [35/50], Step [146/735], Loss: 0.0190\n",
      "Epoch [35/50], Step [147/735], Loss: 0.0299\n",
      "Epoch [35/50], Step [148/735], Loss: 0.0340\n",
      "Epoch [35/50], Step [149/735], Loss: 0.1291\n",
      "Epoch [35/50], Step [150/735], Loss: 0.0385\n",
      "Epoch [35/50], Step [151/735], Loss: 0.0627\n",
      "Epoch [35/50], Step [152/735], Loss: 0.1873\n",
      "Epoch [35/50], Step [153/735], Loss: 0.1468\n",
      "Epoch [35/50], Step [154/735], Loss: 0.0161\n",
      "Epoch [35/50], Step [155/735], Loss: 0.0635\n",
      "Epoch [35/50], Step [156/735], Loss: 0.0408\n",
      "Epoch [35/50], Step [157/735], Loss: 0.0796\n",
      "Epoch [35/50], Step [158/735], Loss: 0.0787\n",
      "Epoch [35/50], Step [159/735], Loss: 0.0772\n",
      "Epoch [35/50], Step [160/735], Loss: 0.0355\n",
      "Epoch [35/50], Step [161/735], Loss: 0.0192\n",
      "Epoch [35/50], Step [162/735], Loss: 0.0465\n",
      "Epoch [35/50], Step [163/735], Loss: 0.0657\n",
      "Epoch [35/50], Step [164/735], Loss: 0.0626\n",
      "Epoch [35/50], Step [165/735], Loss: 0.0452\n",
      "Epoch [35/50], Step [166/735], Loss: 0.1526\n",
      "Epoch [35/50], Step [167/735], Loss: 0.0381\n",
      "Epoch [35/50], Step [168/735], Loss: 0.1159\n",
      "Epoch [35/50], Step [169/735], Loss: 0.0508\n",
      "Epoch [35/50], Step [170/735], Loss: 0.1071\n",
      "Epoch [35/50], Step [171/735], Loss: 0.0739\n",
      "Epoch [35/50], Step [172/735], Loss: 0.0655\n",
      "Epoch [35/50], Step [173/735], Loss: 0.1359\n",
      "Epoch [35/50], Step [174/735], Loss: 0.0382\n",
      "Epoch [35/50], Step [175/735], Loss: 0.0532\n",
      "Epoch [35/50], Step [176/735], Loss: 0.0766\n",
      "Epoch [35/50], Step [177/735], Loss: 0.1109\n",
      "Epoch [35/50], Step [178/735], Loss: 0.0512\n",
      "Epoch [35/50], Step [179/735], Loss: 0.2717\n",
      "Epoch [35/50], Step [180/735], Loss: 0.1037\n",
      "Epoch [35/50], Step [181/735], Loss: 0.0276\n",
      "Epoch [35/50], Step [182/735], Loss: 0.0427\n",
      "Epoch [35/50], Step [183/735], Loss: 0.4278\n",
      "Epoch [35/50], Step [184/735], Loss: 0.0587\n",
      "Epoch [35/50], Step [185/735], Loss: 0.0521\n",
      "Epoch [35/50], Step [186/735], Loss: 0.0229\n",
      "Epoch [35/50], Step [187/735], Loss: 0.0438\n",
      "Epoch [35/50], Step [188/735], Loss: 0.0398\n",
      "Epoch [35/50], Step [189/735], Loss: 0.1195\n",
      "Epoch [35/50], Step [190/735], Loss: 0.1333\n",
      "Epoch [35/50], Step [191/735], Loss: 0.0403\n",
      "Epoch [35/50], Step [192/735], Loss: 0.0951\n",
      "Epoch [35/50], Step [193/735], Loss: 0.0519\n",
      "Epoch [35/50], Step [194/735], Loss: 0.1211\n",
      "Epoch [35/50], Step [195/735], Loss: 0.0625\n",
      "Epoch [35/50], Step [196/735], Loss: 0.0716\n",
      "Epoch [35/50], Step [197/735], Loss: 0.0753\n",
      "Epoch [35/50], Step [198/735], Loss: 0.0484\n",
      "Epoch [35/50], Step [199/735], Loss: 0.0442\n",
      "Epoch [35/50], Step [200/735], Loss: 0.2591\n",
      "Epoch [35/50], Step [201/735], Loss: 0.0351\n",
      "Epoch [35/50], Step [202/735], Loss: 0.0743\n",
      "Epoch [35/50], Step [203/735], Loss: 0.0833\n",
      "Epoch [35/50], Step [204/735], Loss: 0.0428\n",
      "Epoch [35/50], Step [205/735], Loss: 0.0558\n",
      "Epoch [35/50], Step [206/735], Loss: 0.2474\n",
      "Epoch [35/50], Step [207/735], Loss: 0.0383\n",
      "Epoch [35/50], Step [208/735], Loss: 0.0741\n",
      "Epoch [35/50], Step [209/735], Loss: 0.0445\n",
      "Epoch [35/50], Step [210/735], Loss: 0.0386\n",
      "Epoch [35/50], Step [211/735], Loss: 0.0332\n",
      "Epoch [35/50], Step [212/735], Loss: 0.1344\n",
      "Epoch [35/50], Step [213/735], Loss: 0.0476\n",
      "Epoch [35/50], Step [214/735], Loss: 0.1238\n",
      "Epoch [35/50], Step [215/735], Loss: 0.2206\n",
      "Epoch [35/50], Step [216/735], Loss: 0.0590\n",
      "Epoch [35/50], Step [217/735], Loss: 0.0862\n",
      "Epoch [35/50], Step [218/735], Loss: 0.0382\n",
      "Epoch [35/50], Step [219/735], Loss: 0.0969\n",
      "Epoch [35/50], Step [220/735], Loss: 0.0378\n",
      "Epoch [35/50], Step [221/735], Loss: 0.0363\n",
      "Epoch [35/50], Step [222/735], Loss: 0.0517\n",
      "Epoch [35/50], Step [223/735], Loss: 0.0440\n",
      "Epoch [35/50], Step [224/735], Loss: 0.0590\n",
      "Epoch [35/50], Step [225/735], Loss: 0.0877\n",
      "Epoch [35/50], Step [226/735], Loss: 0.0363\n",
      "Epoch [35/50], Step [227/735], Loss: 0.0517\n",
      "Epoch [35/50], Step [228/735], Loss: 0.0288\n",
      "Epoch [35/50], Step [229/735], Loss: 0.0478\n",
      "Epoch [35/50], Step [230/735], Loss: 0.0136\n",
      "Epoch [35/50], Step [231/735], Loss: 0.0236\n",
      "Epoch [35/50], Step [232/735], Loss: 0.0395\n",
      "Epoch [35/50], Step [233/735], Loss: 0.0540\n",
      "Epoch [35/50], Step [234/735], Loss: 0.0927\n",
      "Epoch [35/50], Step [235/735], Loss: 0.0705\n",
      "Epoch [35/50], Step [236/735], Loss: 0.0206\n",
      "Epoch [35/50], Step [237/735], Loss: 0.1466\n",
      "Epoch [35/50], Step [238/735], Loss: 0.1727\n",
      "Epoch [35/50], Step [239/735], Loss: 0.0661\n",
      "Epoch [35/50], Step [240/735], Loss: 0.0537\n",
      "Epoch [35/50], Step [241/735], Loss: 0.0530\n",
      "Epoch [35/50], Step [242/735], Loss: 0.0810\n",
      "Epoch [35/50], Step [243/735], Loss: 0.0413\n",
      "Epoch [35/50], Step [244/735], Loss: 0.0892\n",
      "Epoch [35/50], Step [245/735], Loss: 0.1491\n",
      "Epoch [35/50], Step [246/735], Loss: 0.0663\n",
      "Epoch [35/50], Step [247/735], Loss: 0.3981\n",
      "Epoch [35/50], Step [248/735], Loss: 0.0608\n",
      "Epoch [35/50], Step [249/735], Loss: 0.0601\n",
      "Epoch [35/50], Step [250/735], Loss: 0.0711\n",
      "Epoch [35/50], Step [251/735], Loss: 0.0780\n",
      "Epoch [35/50], Step [252/735], Loss: 0.0389\n",
      "Epoch [35/50], Step [253/735], Loss: 0.0783\n",
      "Epoch [35/50], Step [254/735], Loss: 0.1200\n",
      "Epoch [35/50], Step [255/735], Loss: 0.0410\n",
      "Epoch [35/50], Step [256/735], Loss: 0.0733\n",
      "Epoch [35/50], Step [257/735], Loss: 0.2096\n",
      "Epoch [35/50], Step [258/735], Loss: 0.0376\n",
      "Epoch [35/50], Step [259/735], Loss: 0.1978\n",
      "Epoch [35/50], Step [260/735], Loss: 0.0738\n",
      "Epoch [35/50], Step [261/735], Loss: 0.1046\n",
      "Epoch [35/50], Step [262/735], Loss: 0.0440\n",
      "Epoch [35/50], Step [263/735], Loss: 0.0326\n",
      "Epoch [35/50], Step [264/735], Loss: 0.0789\n",
      "Epoch [35/50], Step [265/735], Loss: 0.0159\n",
      "Epoch [35/50], Step [266/735], Loss: 0.0572\n",
      "Epoch [35/50], Step [267/735], Loss: 0.0469\n",
      "Epoch [35/50], Step [268/735], Loss: 0.0206\n",
      "Epoch [35/50], Step [269/735], Loss: 0.1361\n",
      "Epoch [35/50], Step [270/735], Loss: 0.0556\n",
      "Epoch [35/50], Step [271/735], Loss: 0.3422\n",
      "Epoch [35/50], Step [272/735], Loss: 0.0488\n",
      "Epoch [35/50], Step [273/735], Loss: 0.0500\n",
      "Epoch [35/50], Step [274/735], Loss: 0.0789\n",
      "Epoch [35/50], Step [275/735], Loss: 0.0448\n",
      "Epoch [35/50], Step [276/735], Loss: 0.0557\n",
      "Epoch [35/50], Step [277/735], Loss: 0.0693\n",
      "Epoch [35/50], Step [278/735], Loss: 0.0553\n",
      "Epoch [35/50], Step [279/735], Loss: 0.0521\n",
      "Epoch [35/50], Step [280/735], Loss: 0.0597\n",
      "Epoch [35/50], Step [281/735], Loss: 0.0432\n",
      "Epoch [35/50], Step [282/735], Loss: 0.0411\n",
      "Epoch [35/50], Step [283/735], Loss: 0.0189\n",
      "Epoch [35/50], Step [284/735], Loss: 0.0555\n",
      "Epoch [35/50], Step [285/735], Loss: 0.0549\n",
      "Epoch [35/50], Step [286/735], Loss: 0.1033\n",
      "Epoch [35/50], Step [287/735], Loss: 0.0736\n",
      "Epoch [35/50], Step [288/735], Loss: 0.0517\n",
      "Epoch [35/50], Step [289/735], Loss: 0.0705\n",
      "Epoch [35/50], Step [290/735], Loss: 0.0367\n",
      "Epoch [35/50], Step [291/735], Loss: 0.0830\n",
      "Epoch [35/50], Step [292/735], Loss: 0.1339\n",
      "Epoch [35/50], Step [293/735], Loss: 0.0742\n",
      "Epoch [35/50], Step [294/735], Loss: 0.0861\n",
      "Epoch [35/50], Step [295/735], Loss: 0.0397\n",
      "Epoch [35/50], Step [296/735], Loss: 0.0435\n",
      "Epoch [35/50], Step [297/735], Loss: 0.0356\n",
      "Epoch [35/50], Step [298/735], Loss: 0.0551\n",
      "Epoch [35/50], Step [299/735], Loss: 0.1457\n",
      "Epoch [35/50], Step [300/735], Loss: 0.0222\n",
      "Epoch [35/50], Step [301/735], Loss: 0.0867\n",
      "Epoch [35/50], Step [302/735], Loss: 0.1241\n",
      "Epoch [35/50], Step [303/735], Loss: 0.0411\n",
      "Epoch [35/50], Step [304/735], Loss: 0.1686\n",
      "Epoch [35/50], Step [305/735], Loss: 0.0759\n",
      "Epoch [35/50], Step [306/735], Loss: 0.0724\n",
      "Epoch [35/50], Step [307/735], Loss: 0.0973\n",
      "Epoch [35/50], Step [308/735], Loss: 0.0544\n",
      "Epoch [35/50], Step [309/735], Loss: 0.0505\n",
      "Epoch [35/50], Step [310/735], Loss: 0.0621\n",
      "Epoch [35/50], Step [311/735], Loss: 0.0368\n",
      "Epoch [35/50], Step [312/735], Loss: 0.0556\n",
      "Epoch [35/50], Step [313/735], Loss: 0.0453\n",
      "Epoch [35/50], Step [314/735], Loss: 0.0458\n",
      "Epoch [35/50], Step [315/735], Loss: 0.0379\n",
      "Epoch [35/50], Step [316/735], Loss: 0.0227\n",
      "Epoch [35/50], Step [317/735], Loss: 0.0296\n",
      "Epoch [35/50], Step [318/735], Loss: 0.0232\n",
      "Epoch [35/50], Step [319/735], Loss: 0.0325\n",
      "Epoch [35/50], Step [320/735], Loss: 0.0368\n",
      "Epoch [35/50], Step [321/735], Loss: 0.0580\n",
      "Epoch [35/50], Step [322/735], Loss: 0.0697\n",
      "Epoch [35/50], Step [323/735], Loss: 0.0513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Step [324/735], Loss: 0.0305\n",
      "Epoch [35/50], Step [325/735], Loss: 0.0922\n",
      "Epoch [35/50], Step [326/735], Loss: 0.1177\n",
      "Epoch [35/50], Step [327/735], Loss: 0.0732\n",
      "Epoch [35/50], Step [328/735], Loss: 0.0275\n",
      "Epoch [35/50], Step [329/735], Loss: 0.0377\n",
      "Epoch [35/50], Step [330/735], Loss: 0.0847\n",
      "Epoch [35/50], Step [331/735], Loss: 0.0370\n",
      "Epoch [35/50], Step [332/735], Loss: 0.0397\n",
      "Epoch [35/50], Step [333/735], Loss: 0.0752\n",
      "Epoch [35/50], Step [334/735], Loss: 0.0234\n",
      "Epoch [35/50], Step [335/735], Loss: 0.0325\n",
      "Epoch [35/50], Step [336/735], Loss: 0.0624\n",
      "Epoch [35/50], Step [337/735], Loss: 0.0268\n",
      "Epoch [35/50], Step [338/735], Loss: 0.0366\n",
      "Epoch [35/50], Step [339/735], Loss: 0.0185\n",
      "Epoch [35/50], Step [340/735], Loss: 0.0373\n",
      "Epoch [35/50], Step [341/735], Loss: 0.1605\n",
      "Epoch [35/50], Step [342/735], Loss: 0.0491\n",
      "Epoch [35/50], Step [343/735], Loss: 0.0686\n",
      "Epoch [35/50], Step [344/735], Loss: 0.3447\n",
      "Epoch [35/50], Step [345/735], Loss: 0.1040\n",
      "Epoch [35/50], Step [346/735], Loss: 0.0912\n",
      "Epoch [35/50], Step [347/735], Loss: 0.0897\n",
      "Epoch [35/50], Step [348/735], Loss: 0.0163\n",
      "Epoch [35/50], Step [349/735], Loss: 0.0917\n",
      "Epoch [35/50], Step [350/735], Loss: 0.0580\n",
      "Epoch [35/50], Step [351/735], Loss: 0.0334\n",
      "Epoch [35/50], Step [352/735], Loss: 0.0274\n",
      "Epoch [35/50], Step [353/735], Loss: 0.0789\n",
      "Epoch [35/50], Step [354/735], Loss: 0.0431\n",
      "Epoch [35/50], Step [355/735], Loss: 0.0413\n",
      "Epoch [35/50], Step [356/735], Loss: 0.0460\n",
      "Epoch [35/50], Step [357/735], Loss: 0.0503\n",
      "Epoch [35/50], Step [358/735], Loss: 0.0577\n",
      "Epoch [35/50], Step [359/735], Loss: 0.0476\n",
      "Epoch [35/50], Step [360/735], Loss: 0.1396\n",
      "Epoch [35/50], Step [361/735], Loss: 0.0221\n",
      "Epoch [35/50], Step [362/735], Loss: 0.0194\n",
      "Epoch [35/50], Step [363/735], Loss: 0.0507\n",
      "Epoch [35/50], Step [364/735], Loss: 0.0214\n",
      "Epoch [35/50], Step [365/735], Loss: 0.0327\n",
      "Epoch [35/50], Step [366/735], Loss: 0.0529\n",
      "Epoch [35/50], Step [367/735], Loss: 0.0337\n",
      "Epoch [35/50], Step [368/735], Loss: 0.0827\n",
      "Epoch [35/50], Step [369/735], Loss: 0.0685\n",
      "Epoch [35/50], Step [370/735], Loss: 0.1632\n",
      "Epoch [35/50], Step [371/735], Loss: 0.0774\n",
      "Epoch [35/50], Step [372/735], Loss: 0.0478\n",
      "Epoch [35/50], Step [373/735], Loss: 0.0208\n",
      "Epoch [35/50], Step [374/735], Loss: 0.0311\n",
      "Epoch [35/50], Step [375/735], Loss: 0.0621\n",
      "Epoch [35/50], Step [376/735], Loss: 0.0256\n",
      "Epoch [35/50], Step [377/735], Loss: 0.0206\n",
      "Epoch [35/50], Step [378/735], Loss: 0.0914\n",
      "Epoch [35/50], Step [379/735], Loss: 0.0390\n",
      "Epoch [35/50], Step [380/735], Loss: 0.0513\n",
      "Epoch [35/50], Step [381/735], Loss: 0.0326\n",
      "Epoch [35/50], Step [382/735], Loss: 0.0291\n",
      "Epoch [35/50], Step [383/735], Loss: 0.0330\n",
      "Epoch [35/50], Step [384/735], Loss: 0.0450\n",
      "Epoch [35/50], Step [385/735], Loss: 0.1077\n",
      "Epoch [35/50], Step [386/735], Loss: 0.1290\n",
      "Epoch [35/50], Step [387/735], Loss: 0.0203\n",
      "Epoch [35/50], Step [388/735], Loss: 0.0527\n",
      "Epoch [35/50], Step [389/735], Loss: 0.1641\n",
      "Epoch [35/50], Step [390/735], Loss: 0.1603\n",
      "Epoch [35/50], Step [391/735], Loss: 0.0221\n",
      "Epoch [35/50], Step [392/735], Loss: 0.0118\n",
      "Epoch [35/50], Step [393/735], Loss: 0.0181\n",
      "Epoch [35/50], Step [394/735], Loss: 0.0625\n",
      "Epoch [35/50], Step [395/735], Loss: 0.0395\n",
      "Epoch [35/50], Step [396/735], Loss: 0.0182\n",
      "Epoch [35/50], Step [397/735], Loss: 0.0323\n",
      "Epoch [35/50], Step [398/735], Loss: 0.0328\n",
      "Epoch [35/50], Step [399/735], Loss: 0.0404\n",
      "Epoch [35/50], Step [400/735], Loss: 0.0239\n",
      "Epoch [35/50], Step [401/735], Loss: 0.0450\n",
      "Epoch [35/50], Step [402/735], Loss: 0.0474\n",
      "Epoch [35/50], Step [403/735], Loss: 0.1119\n",
      "Epoch [35/50], Step [404/735], Loss: 0.1785\n",
      "Epoch [35/50], Step [405/735], Loss: 0.0235\n",
      "Epoch [35/50], Step [406/735], Loss: 0.1594\n",
      "Epoch [35/50], Step [407/735], Loss: 0.0469\n",
      "Epoch [35/50], Step [408/735], Loss: 0.0706\n",
      "Epoch [35/50], Step [409/735], Loss: 0.0420\n",
      "Epoch [35/50], Step [410/735], Loss: 0.0328\n",
      "Epoch [35/50], Step [411/735], Loss: 0.0413\n",
      "Epoch [35/50], Step [412/735], Loss: 0.0566\n",
      "Epoch [35/50], Step [413/735], Loss: 0.0920\n",
      "Epoch [35/50], Step [414/735], Loss: 0.2354\n",
      "Epoch [35/50], Step [415/735], Loss: 0.0319\n",
      "Epoch [35/50], Step [416/735], Loss: 0.0256\n",
      "Epoch [35/50], Step [417/735], Loss: 0.0439\n",
      "Epoch [35/50], Step [418/735], Loss: 0.0200\n",
      "Epoch [35/50], Step [419/735], Loss: 0.0964\n",
      "Epoch [35/50], Step [420/735], Loss: 0.0359\n",
      "Epoch [35/50], Step [421/735], Loss: 0.1190\n",
      "Epoch [35/50], Step [422/735], Loss: 0.0473\n",
      "Epoch [35/50], Step [423/735], Loss: 0.0839\n",
      "Epoch [35/50], Step [424/735], Loss: 0.0391\n",
      "Epoch [35/50], Step [425/735], Loss: 0.0269\n",
      "Epoch [35/50], Step [426/735], Loss: 0.0566\n",
      "Epoch [35/50], Step [427/735], Loss: 0.0298\n",
      "Epoch [35/50], Step [428/735], Loss: 0.0431\n",
      "Epoch [35/50], Step [429/735], Loss: 0.0370\n",
      "Epoch [35/50], Step [430/735], Loss: 0.0232\n",
      "Epoch [35/50], Step [431/735], Loss: 0.0386\n",
      "Epoch [35/50], Step [432/735], Loss: 0.0759\n",
      "Epoch [35/50], Step [433/735], Loss: 0.0159\n",
      "Epoch [35/50], Step [434/735], Loss: 0.0291\n",
      "Epoch [35/50], Step [435/735], Loss: 0.0934\n",
      "Epoch [35/50], Step [436/735], Loss: 0.0428\n",
      "Epoch [35/50], Step [437/735], Loss: 0.0294\n",
      "Epoch [35/50], Step [438/735], Loss: 0.0327\n",
      "Epoch [35/50], Step [439/735], Loss: 0.0576\n",
      "Epoch [35/50], Step [440/735], Loss: 0.0343\n",
      "Epoch [35/50], Step [441/735], Loss: 0.0454\n",
      "Epoch [35/50], Step [442/735], Loss: 0.0730\n",
      "Epoch [35/50], Step [443/735], Loss: 0.0343\n",
      "Epoch [35/50], Step [444/735], Loss: 0.0486\n",
      "Epoch [35/50], Step [445/735], Loss: 0.0148\n",
      "Epoch [35/50], Step [446/735], Loss: 0.0440\n",
      "Epoch [35/50], Step [447/735], Loss: 0.0549\n",
      "Epoch [35/50], Step [448/735], Loss: 0.0163\n",
      "Epoch [35/50], Step [449/735], Loss: 0.0568\n",
      "Epoch [35/50], Step [450/735], Loss: 0.0603\n",
      "Epoch [35/50], Step [451/735], Loss: 0.0667\n",
      "Epoch [35/50], Step [452/735], Loss: 0.0617\n",
      "Epoch [35/50], Step [453/735], Loss: 0.0491\n",
      "Epoch [35/50], Step [454/735], Loss: 0.0364\n",
      "Epoch [35/50], Step [455/735], Loss: 0.0564\n",
      "Epoch [35/50], Step [456/735], Loss: 0.0698\n",
      "Epoch [35/50], Step [457/735], Loss: 0.0364\n",
      "Epoch [35/50], Step [458/735], Loss: 0.0570\n",
      "Epoch [35/50], Step [459/735], Loss: 0.0306\n",
      "Epoch [35/50], Step [460/735], Loss: 0.0507\n",
      "Epoch [35/50], Step [461/735], Loss: 0.0339\n",
      "Epoch [35/50], Step [462/735], Loss: 0.0802\n",
      "Epoch [35/50], Step [463/735], Loss: 0.0676\n",
      "Epoch [35/50], Step [464/735], Loss: 0.0492\n",
      "Epoch [35/50], Step [465/735], Loss: 0.0336\n",
      "Epoch [35/50], Step [466/735], Loss: 0.0244\n",
      "Epoch [35/50], Step [467/735], Loss: 0.0399\n",
      "Epoch [35/50], Step [468/735], Loss: 0.0380\n",
      "Epoch [35/50], Step [469/735], Loss: 0.1285\n",
      "Epoch [35/50], Step [470/735], Loss: 0.0770\n",
      "Epoch [35/50], Step [471/735], Loss: 0.0341\n",
      "Epoch [35/50], Step [472/735], Loss: 0.0292\n",
      "Epoch [35/50], Step [473/735], Loss: 0.0505\n",
      "Epoch [35/50], Step [474/735], Loss: 0.1663\n",
      "Epoch [35/50], Step [475/735], Loss: 0.0341\n",
      "Epoch [35/50], Step [476/735], Loss: 0.0679\n",
      "Epoch [35/50], Step [477/735], Loss: 0.0728\n",
      "Epoch [35/50], Step [478/735], Loss: 0.0748\n",
      "Epoch [35/50], Step [479/735], Loss: 0.1051\n",
      "Epoch [35/50], Step [480/735], Loss: 0.0947\n",
      "Epoch [35/50], Step [481/735], Loss: 0.0144\n",
      "Epoch [35/50], Step [482/735], Loss: 0.0312\n",
      "Epoch [35/50], Step [483/735], Loss: 0.0389\n",
      "Epoch [35/50], Step [484/735], Loss: 0.1439\n",
      "Epoch [35/50], Step [485/735], Loss: 0.1057\n",
      "Epoch [35/50], Step [486/735], Loss: 0.0597\n",
      "Epoch [35/50], Step [487/735], Loss: 0.0277\n",
      "Epoch [35/50], Step [488/735], Loss: 0.0511\n",
      "Epoch [35/50], Step [489/735], Loss: 0.0611\n",
      "Epoch [35/50], Step [490/735], Loss: 0.0373\n",
      "Epoch [35/50], Step [491/735], Loss: 0.1518\n",
      "Epoch [35/50], Step [492/735], Loss: 0.0436\n",
      "Epoch [35/50], Step [493/735], Loss: 0.0193\n",
      "Epoch [35/50], Step [494/735], Loss: 0.0469\n",
      "Epoch [35/50], Step [495/735], Loss: 0.0447\n",
      "Epoch [35/50], Step [496/735], Loss: 0.0150\n",
      "Epoch [35/50], Step [497/735], Loss: 0.0306\n",
      "Epoch [35/50], Step [498/735], Loss: 0.0833\n",
      "Epoch [35/50], Step [499/735], Loss: 0.1140\n",
      "Epoch [35/50], Step [500/735], Loss: 0.0711\n",
      "Epoch [35/50], Step [501/735], Loss: 0.0437\n",
      "Epoch [35/50], Step [502/735], Loss: 0.1336\n",
      "Epoch [35/50], Step [503/735], Loss: 0.0424\n",
      "Epoch [35/50], Step [504/735], Loss: 0.1470\n",
      "Epoch [35/50], Step [505/735], Loss: 0.0244\n",
      "Epoch [35/50], Step [506/735], Loss: 0.0281\n",
      "Epoch [35/50], Step [507/735], Loss: 0.0549\n",
      "Epoch [35/50], Step [508/735], Loss: 0.0410\n",
      "Epoch [35/50], Step [509/735], Loss: 0.0364\n",
      "Epoch [35/50], Step [510/735], Loss: 0.1035\n",
      "Epoch [35/50], Step [511/735], Loss: 0.0365\n",
      "Epoch [35/50], Step [512/735], Loss: 0.0352\n",
      "Epoch [35/50], Step [513/735], Loss: 0.0414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Step [514/735], Loss: 0.0413\n",
      "Epoch [35/50], Step [515/735], Loss: 0.0514\n",
      "Epoch [35/50], Step [516/735], Loss: 0.0819\n",
      "Epoch [35/50], Step [517/735], Loss: 0.0667\n",
      "Epoch [35/50], Step [518/735], Loss: 0.0279\n",
      "Epoch [35/50], Step [519/735], Loss: 0.0383\n",
      "Epoch [35/50], Step [520/735], Loss: 0.0605\n",
      "Epoch [35/50], Step [521/735], Loss: 0.1138\n",
      "Epoch [35/50], Step [522/735], Loss: 0.0986\n",
      "Epoch [35/50], Step [523/735], Loss: 0.0598\n",
      "Epoch [35/50], Step [524/735], Loss: 0.0526\n",
      "Epoch [35/50], Step [525/735], Loss: 0.0461\n",
      "Epoch [35/50], Step [526/735], Loss: 0.1027\n",
      "Epoch [35/50], Step [527/735], Loss: 0.2159\n",
      "Epoch [35/50], Step [528/735], Loss: 0.0422\n",
      "Epoch [35/50], Step [529/735], Loss: 0.1713\n",
      "Epoch [35/50], Step [530/735], Loss: 0.1022\n",
      "Epoch [35/50], Step [531/735], Loss: 0.0632\n",
      "Epoch [35/50], Step [532/735], Loss: 0.0301\n",
      "Epoch [35/50], Step [533/735], Loss: 0.0333\n",
      "Epoch [35/50], Step [534/735], Loss: 0.0973\n",
      "Epoch [35/50], Step [535/735], Loss: 0.1136\n",
      "Epoch [35/50], Step [536/735], Loss: 0.0730\n",
      "Epoch [35/50], Step [537/735], Loss: 0.0654\n",
      "Epoch [35/50], Step [538/735], Loss: 0.0444\n",
      "Epoch [35/50], Step [539/735], Loss: 0.0593\n",
      "Epoch [35/50], Step [540/735], Loss: 0.1577\n",
      "Epoch [35/50], Step [541/735], Loss: 0.1072\n",
      "Epoch [35/50], Step [542/735], Loss: 0.0459\n",
      "Epoch [35/50], Step [543/735], Loss: 0.0305\n",
      "Epoch [35/50], Step [544/735], Loss: 0.0501\n",
      "Epoch [35/50], Step [545/735], Loss: 0.1129\n",
      "Epoch [35/50], Step [546/735], Loss: 0.1135\n",
      "Epoch [35/50], Step [547/735], Loss: 0.0872\n",
      "Epoch [35/50], Step [548/735], Loss: 0.0342\n",
      "Epoch [35/50], Step [549/735], Loss: 0.0624\n",
      "Epoch [35/50], Step [550/735], Loss: 0.0362\n",
      "Epoch [35/50], Step [551/735], Loss: 0.0158\n",
      "Epoch [35/50], Step [552/735], Loss: 0.0825\n",
      "Epoch [35/50], Step [553/735], Loss: 0.0389\n",
      "Epoch [35/50], Step [554/735], Loss: 0.0569\n",
      "Epoch [35/50], Step [555/735], Loss: 0.0394\n",
      "Epoch [35/50], Step [556/735], Loss: 0.1350\n",
      "Epoch [35/50], Step [557/735], Loss: 0.0681\n",
      "Epoch [35/50], Step [558/735], Loss: 0.1583\n",
      "Epoch [35/50], Step [559/735], Loss: 0.1910\n",
      "Epoch [35/50], Step [560/735], Loss: 0.1847\n",
      "Epoch [35/50], Step [561/735], Loss: 0.0302\n",
      "Epoch [35/50], Step [562/735], Loss: 0.0780\n",
      "Epoch [35/50], Step [563/735], Loss: 0.0736\n",
      "Epoch [35/50], Step [564/735], Loss: 0.1161\n",
      "Epoch [35/50], Step [565/735], Loss: 0.0733\n",
      "Epoch [35/50], Step [566/735], Loss: 0.0171\n",
      "Epoch [35/50], Step [567/735], Loss: 0.0701\n",
      "Epoch [35/50], Step [568/735], Loss: 0.0748\n",
      "Epoch [35/50], Step [569/735], Loss: 0.0194\n",
      "Epoch [35/50], Step [570/735], Loss: 0.0722\n",
      "Epoch [35/50], Step [571/735], Loss: 0.0483\n",
      "Epoch [35/50], Step [572/735], Loss: 0.0514\n",
      "Epoch [35/50], Step [573/735], Loss: 0.0335\n",
      "Epoch [35/50], Step [574/735], Loss: 0.0734\n",
      "Epoch [35/50], Step [575/735], Loss: 0.0792\n",
      "Epoch [35/50], Step [576/735], Loss: 0.0283\n",
      "Epoch [35/50], Step [577/735], Loss: 0.0308\n",
      "Epoch [35/50], Step [578/735], Loss: 0.0550\n",
      "Epoch [35/50], Step [579/735], Loss: 0.1249\n",
      "Epoch [35/50], Step [580/735], Loss: 0.1083\n",
      "Epoch [35/50], Step [581/735], Loss: 0.0619\n",
      "Epoch [35/50], Step [582/735], Loss: 0.0897\n",
      "Epoch [35/50], Step [583/735], Loss: 0.0288\n",
      "Epoch [35/50], Step [584/735], Loss: 0.0611\n",
      "Epoch [35/50], Step [585/735], Loss: 0.1810\n",
      "Epoch [35/50], Step [586/735], Loss: 0.0411\n",
      "Epoch [35/50], Step [587/735], Loss: 0.0277\n",
      "Epoch [35/50], Step [588/735], Loss: 0.0998\n",
      "Epoch [35/50], Step [589/735], Loss: 0.0667\n",
      "Epoch [35/50], Step [590/735], Loss: 0.2890\n",
      "Epoch [35/50], Step [591/735], Loss: 0.0681\n",
      "Epoch [35/50], Step [592/735], Loss: 0.0555\n",
      "Epoch [35/50], Step [593/735], Loss: 0.2703\n",
      "Epoch [35/50], Step [594/735], Loss: 0.0205\n",
      "Epoch [35/50], Step [595/735], Loss: 0.0544\n",
      "Epoch [35/50], Step [596/735], Loss: 0.0850\n",
      "Epoch [35/50], Step [597/735], Loss: 0.0977\n",
      "Epoch [35/50], Step [598/735], Loss: 0.3798\n",
      "Epoch [35/50], Step [599/735], Loss: 0.0342\n",
      "Epoch [35/50], Step [600/735], Loss: 0.1215\n",
      "Epoch [35/50], Step [601/735], Loss: 0.0531\n",
      "Epoch [35/50], Step [602/735], Loss: 0.0889\n",
      "Epoch [35/50], Step [603/735], Loss: 0.0565\n",
      "Epoch [35/50], Step [604/735], Loss: 0.0454\n",
      "Epoch [35/50], Step [605/735], Loss: 0.0436\n",
      "Epoch [35/50], Step [606/735], Loss: 0.0582\n",
      "Epoch [35/50], Step [607/735], Loss: 0.0416\n",
      "Epoch [35/50], Step [608/735], Loss: 0.1444\n",
      "Epoch [35/50], Step [609/735], Loss: 0.0628\n",
      "Epoch [35/50], Step [610/735], Loss: 0.0393\n",
      "Epoch [35/50], Step [611/735], Loss: 0.0309\n",
      "Epoch [35/50], Step [612/735], Loss: 0.1060\n",
      "Epoch [35/50], Step [613/735], Loss: 0.0247\n",
      "Epoch [35/50], Step [614/735], Loss: 0.0329\n",
      "Epoch [35/50], Step [615/735], Loss: 0.1020\n",
      "Epoch [35/50], Step [616/735], Loss: 0.0388\n",
      "Epoch [35/50], Step [617/735], Loss: 0.0469\n",
      "Epoch [35/50], Step [618/735], Loss: 0.0494\n",
      "Epoch [35/50], Step [619/735], Loss: 0.0338\n",
      "Epoch [35/50], Step [620/735], Loss: 0.0246\n",
      "Epoch [35/50], Step [621/735], Loss: 0.0330\n",
      "Epoch [35/50], Step [622/735], Loss: 0.0588\n",
      "Epoch [35/50], Step [623/735], Loss: 0.0473\n",
      "Epoch [35/50], Step [624/735], Loss: 0.0571\n",
      "Epoch [35/50], Step [625/735], Loss: 0.0621\n",
      "Epoch [35/50], Step [626/735], Loss: 0.0599\n",
      "Epoch [35/50], Step [627/735], Loss: 0.0252\n",
      "Epoch [35/50], Step [628/735], Loss: 0.0804\n",
      "Epoch [35/50], Step [629/735], Loss: 0.1913\n",
      "Epoch [35/50], Step [630/735], Loss: 0.0875\n",
      "Epoch [35/50], Step [631/735], Loss: 0.0404\n",
      "Epoch [35/50], Step [632/735], Loss: 0.2595\n",
      "Epoch [35/50], Step [633/735], Loss: 0.0400\n",
      "Epoch [35/50], Step [634/735], Loss: 0.1216\n",
      "Epoch [35/50], Step [635/735], Loss: 0.0468\n",
      "Epoch [35/50], Step [636/735], Loss: 0.1086\n",
      "Epoch [35/50], Step [637/735], Loss: 0.0323\n",
      "Epoch [35/50], Step [638/735], Loss: 0.0497\n",
      "Epoch [35/50], Step [639/735], Loss: 0.0373\n",
      "Epoch [35/50], Step [640/735], Loss: 0.0401\n",
      "Epoch [35/50], Step [641/735], Loss: 0.0275\n",
      "Epoch [35/50], Step [642/735], Loss: 0.0980\n",
      "Epoch [35/50], Step [643/735], Loss: 0.0376\n",
      "Epoch [35/50], Step [644/735], Loss: 0.0286\n",
      "Epoch [35/50], Step [645/735], Loss: 0.0652\n",
      "Epoch [35/50], Step [646/735], Loss: 0.0667\n",
      "Epoch [35/50], Step [647/735], Loss: 0.0804\n",
      "Epoch [35/50], Step [648/735], Loss: 0.0808\n",
      "Epoch [35/50], Step [649/735], Loss: 0.0197\n",
      "Epoch [35/50], Step [650/735], Loss: 0.0643\n",
      "Epoch [35/50], Step [651/735], Loss: 0.0823\n",
      "Epoch [35/50], Step [652/735], Loss: 0.0753\n",
      "Epoch [35/50], Step [653/735], Loss: 0.0597\n",
      "Epoch [35/50], Step [654/735], Loss: 0.0456\n",
      "Epoch [35/50], Step [655/735], Loss: 0.0601\n",
      "Epoch [35/50], Step [656/735], Loss: 0.0284\n",
      "Epoch [35/50], Step [657/735], Loss: 0.0765\n",
      "Epoch [35/50], Step [658/735], Loss: 0.0416\n",
      "Epoch [35/50], Step [659/735], Loss: 0.2420\n",
      "Epoch [35/50], Step [660/735], Loss: 0.0756\n",
      "Epoch [35/50], Step [661/735], Loss: 0.0450\n",
      "Epoch [35/50], Step [662/735], Loss: 0.0313\n",
      "Epoch [35/50], Step [663/735], Loss: 0.0295\n",
      "Epoch [35/50], Step [664/735], Loss: 0.4385\n",
      "Epoch [35/50], Step [665/735], Loss: 0.0695\n",
      "Epoch [35/50], Step [666/735], Loss: 0.0260\n",
      "Epoch [35/50], Step [667/735], Loss: 0.1564\n",
      "Epoch [35/50], Step [668/735], Loss: 0.0369\n",
      "Epoch [35/50], Step [669/735], Loss: 0.0384\n",
      "Epoch [35/50], Step [670/735], Loss: 0.0188\n",
      "Epoch [35/50], Step [671/735], Loss: 0.0185\n",
      "Epoch [35/50], Step [672/735], Loss: 0.0284\n",
      "Epoch [35/50], Step [673/735], Loss: 0.0241\n",
      "Epoch [35/50], Step [674/735], Loss: 0.0411\n",
      "Epoch [35/50], Step [675/735], Loss: 0.0432\n",
      "Epoch [35/50], Step [676/735], Loss: 0.0235\n",
      "Epoch [35/50], Step [677/735], Loss: 0.0451\n",
      "Epoch [35/50], Step [678/735], Loss: 0.0390\n",
      "Epoch [35/50], Step [679/735], Loss: 0.0448\n",
      "Epoch [35/50], Step [680/735], Loss: 0.2138\n",
      "Epoch [35/50], Step [681/735], Loss: 0.0323\n",
      "Epoch [35/50], Step [682/735], Loss: 0.0335\n",
      "Epoch [35/50], Step [683/735], Loss: 0.0551\n",
      "Epoch [35/50], Step [684/735], Loss: 0.0366\n",
      "Epoch [35/50], Step [685/735], Loss: 0.0529\n",
      "Epoch [35/50], Step [686/735], Loss: 0.0653\n",
      "Epoch [35/50], Step [687/735], Loss: 0.0364\n",
      "Epoch [35/50], Step [688/735], Loss: 0.0288\n",
      "Epoch [35/50], Step [689/735], Loss: 0.1102\n",
      "Epoch [35/50], Step [690/735], Loss: 0.0584\n",
      "Epoch [35/50], Step [691/735], Loss: 0.2918\n",
      "Epoch [35/50], Step [692/735], Loss: 0.1819\n",
      "Epoch [35/50], Step [693/735], Loss: 0.0792\n",
      "Epoch [35/50], Step [694/735], Loss: 0.2798\n",
      "Epoch [35/50], Step [695/735], Loss: 0.0310\n",
      "Epoch [35/50], Step [696/735], Loss: 0.0377\n",
      "Epoch [35/50], Step [697/735], Loss: 0.0391\n",
      "Epoch [35/50], Step [698/735], Loss: 0.0399\n",
      "Epoch [35/50], Step [699/735], Loss: 0.1800\n",
      "Epoch [35/50], Step [700/735], Loss: 0.3760\n",
      "Epoch [35/50], Step [701/735], Loss: 0.0326\n",
      "Epoch [35/50], Step [702/735], Loss: 0.1373\n",
      "Epoch [35/50], Step [703/735], Loss: 0.0541\n",
      "Epoch [35/50], Step [704/735], Loss: 0.0260\n",
      "Epoch [35/50], Step [705/735], Loss: 0.0431\n",
      "Epoch [35/50], Step [706/735], Loss: 0.0749\n",
      "Epoch [35/50], Step [707/735], Loss: 0.0679\n",
      "Epoch [35/50], Step [708/735], Loss: 0.0252\n",
      "Epoch [35/50], Step [709/735], Loss: 0.0426\n",
      "Epoch [35/50], Step [710/735], Loss: 0.0475\n",
      "Epoch [35/50], Step [711/735], Loss: 0.0433\n",
      "Epoch [35/50], Step [712/735], Loss: 0.0299\n",
      "Epoch [35/50], Step [713/735], Loss: 0.2811\n",
      "Epoch [35/50], Step [714/735], Loss: 0.0372\n",
      "Epoch [35/50], Step [715/735], Loss: 0.0635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Step [716/735], Loss: 0.0304\n",
      "Epoch [35/50], Step [717/735], Loss: 0.0993\n",
      "Epoch [35/50], Step [718/735], Loss: 0.0595\n",
      "Epoch [35/50], Step [719/735], Loss: 0.0576\n",
      "Epoch [35/50], Step [720/735], Loss: 0.0427\n",
      "Epoch [35/50], Step [721/735], Loss: 0.0267\n",
      "Epoch [35/50], Step [722/735], Loss: 0.0981\n",
      "Epoch [35/50], Step [723/735], Loss: 0.0423\n",
      "Epoch [35/50], Step [724/735], Loss: 0.0851\n",
      "Epoch [35/50], Step [725/735], Loss: 0.0463\n",
      "Epoch [35/50], Step [726/735], Loss: 0.0355\n",
      "Epoch [35/50], Step [727/735], Loss: 0.1364\n",
      "Epoch [35/50], Step [728/735], Loss: 0.0204\n",
      "Epoch [35/50], Step [729/735], Loss: 0.0385\n",
      "Epoch [35/50], Step [730/735], Loss: 0.0812\n",
      "Epoch [35/50], Step [731/735], Loss: 0.0384\n",
      "Epoch [35/50], Step [732/735], Loss: 0.0667\n",
      "Epoch [35/50], Step [733/735], Loss: 0.1324\n",
      "Epoch [35/50], Step [734/735], Loss: 0.0346\n",
      "Epoch [35/50], Step [735/735], Loss: 0.0200\n",
      "Epoch [36/50], Step [1/735], Loss: 0.0410\n",
      "Epoch [36/50], Step [2/735], Loss: 0.0248\n",
      "Epoch [36/50], Step [3/735], Loss: 0.0490\n",
      "Epoch [36/50], Step [4/735], Loss: 0.0717\n",
      "Epoch [36/50], Step [5/735], Loss: 0.0882\n",
      "Epoch [36/50], Step [6/735], Loss: 0.0687\n",
      "Epoch [36/50], Step [7/735], Loss: 0.0226\n",
      "Epoch [36/50], Step [8/735], Loss: 0.0363\n",
      "Epoch [36/50], Step [9/735], Loss: 0.0496\n",
      "Epoch [36/50], Step [10/735], Loss: 0.0339\n",
      "Epoch [36/50], Step [11/735], Loss: 0.0376\n",
      "Epoch [36/50], Step [12/735], Loss: 0.0632\n",
      "Epoch [36/50], Step [13/735], Loss: 0.1274\n",
      "Epoch [36/50], Step [14/735], Loss: 0.0643\n",
      "Epoch [36/50], Step [15/735], Loss: 0.0560\n",
      "Epoch [36/50], Step [16/735], Loss: 0.0503\n",
      "Epoch [36/50], Step [17/735], Loss: 0.0518\n",
      "Epoch [36/50], Step [18/735], Loss: 0.0524\n",
      "Epoch [36/50], Step [19/735], Loss: 0.0707\n",
      "Epoch [36/50], Step [20/735], Loss: 0.0400\n",
      "Epoch [36/50], Step [21/735], Loss: 0.0651\n",
      "Epoch [36/50], Step [22/735], Loss: 0.0470\n",
      "Epoch [36/50], Step [23/735], Loss: 0.0478\n",
      "Epoch [36/50], Step [24/735], Loss: 0.2861\n",
      "Epoch [36/50], Step [25/735], Loss: 0.0456\n",
      "Epoch [36/50], Step [26/735], Loss: 0.0392\n",
      "Epoch [36/50], Step [27/735], Loss: 0.0263\n",
      "Epoch [36/50], Step [28/735], Loss: 0.0317\n",
      "Epoch [36/50], Step [29/735], Loss: 0.0690\n",
      "Epoch [36/50], Step [30/735], Loss: 0.0388\n",
      "Epoch [36/50], Step [31/735], Loss: 0.0591\n",
      "Epoch [36/50], Step [32/735], Loss: 0.0293\n",
      "Epoch [36/50], Step [33/735], Loss: 0.3150\n",
      "Epoch [36/50], Step [34/735], Loss: 0.0510\n",
      "Epoch [36/50], Step [35/735], Loss: 0.0758\n",
      "Epoch [36/50], Step [36/735], Loss: 0.0567\n",
      "Epoch [36/50], Step [37/735], Loss: 0.0334\n",
      "Epoch [36/50], Step [38/735], Loss: 0.0369\n",
      "Epoch [36/50], Step [39/735], Loss: 0.2486\n",
      "Epoch [36/50], Step [40/735], Loss: 0.0730\n",
      "Epoch [36/50], Step [41/735], Loss: 0.0653\n",
      "Epoch [36/50], Step [42/735], Loss: 0.1050\n",
      "Epoch [36/50], Step [43/735], Loss: 0.0568\n",
      "Epoch [36/50], Step [44/735], Loss: 0.0189\n",
      "Epoch [36/50], Step [45/735], Loss: 0.1277\n",
      "Epoch [36/50], Step [46/735], Loss: 0.0414\n",
      "Epoch [36/50], Step [47/735], Loss: 0.0333\n",
      "Epoch [36/50], Step [48/735], Loss: 0.1097\n",
      "Epoch [36/50], Step [49/735], Loss: 0.0281\n",
      "Epoch [36/50], Step [50/735], Loss: 0.1220\n",
      "Epoch [36/50], Step [51/735], Loss: 0.0294\n",
      "Epoch [36/50], Step [52/735], Loss: 0.0916\n",
      "Epoch [36/50], Step [53/735], Loss: 0.0177\n",
      "Epoch [36/50], Step [54/735], Loss: 0.1219\n",
      "Epoch [36/50], Step [55/735], Loss: 0.0312\n",
      "Epoch [36/50], Step [56/735], Loss: 0.0596\n",
      "Epoch [36/50], Step [57/735], Loss: 0.0470\n",
      "Epoch [36/50], Step [58/735], Loss: 0.0453\n",
      "Epoch [36/50], Step [59/735], Loss: 0.0725\n",
      "Epoch [36/50], Step [60/735], Loss: 0.2530\n",
      "Epoch [36/50], Step [61/735], Loss: 0.0503\n",
      "Epoch [36/50], Step [62/735], Loss: 0.0354\n",
      "Epoch [36/50], Step [63/735], Loss: 0.0473\n",
      "Epoch [36/50], Step [64/735], Loss: 0.0739\n",
      "Epoch [36/50], Step [65/735], Loss: 0.0699\n",
      "Epoch [36/50], Step [66/735], Loss: 0.0141\n",
      "Epoch [36/50], Step [67/735], Loss: 0.1655\n",
      "Epoch [36/50], Step [68/735], Loss: 0.0455\n",
      "Epoch [36/50], Step [69/735], Loss: 0.0953\n",
      "Epoch [36/50], Step [70/735], Loss: 0.0446\n",
      "Epoch [36/50], Step [71/735], Loss: 0.2508\n",
      "Epoch [36/50], Step [72/735], Loss: 0.0199\n",
      "Epoch [36/50], Step [73/735], Loss: 0.0651\n",
      "Epoch [36/50], Step [74/735], Loss: 0.0895\n",
      "Epoch [36/50], Step [75/735], Loss: 0.0787\n",
      "Epoch [36/50], Step [76/735], Loss: 0.0658\n",
      "Epoch [36/50], Step [77/735], Loss: 0.1163\n",
      "Epoch [36/50], Step [78/735], Loss: 0.0655\n",
      "Epoch [36/50], Step [79/735], Loss: 0.0651\n",
      "Epoch [36/50], Step [80/735], Loss: 0.0320\n",
      "Epoch [36/50], Step [81/735], Loss: 0.0519\n",
      "Epoch [36/50], Step [82/735], Loss: 0.0577\n",
      "Epoch [36/50], Step [83/735], Loss: 0.1854\n",
      "Epoch [36/50], Step [84/735], Loss: 0.0556\n",
      "Epoch [36/50], Step [85/735], Loss: 0.0578\n",
      "Epoch [36/50], Step [86/735], Loss: 0.2459\n",
      "Epoch [36/50], Step [87/735], Loss: 0.0293\n",
      "Epoch [36/50], Step [88/735], Loss: 0.1104\n",
      "Epoch [36/50], Step [89/735], Loss: 0.0737\n",
      "Epoch [36/50], Step [90/735], Loss: 0.3951\n",
      "Epoch [36/50], Step [91/735], Loss: 0.0327\n",
      "Epoch [36/50], Step [92/735], Loss: 0.0540\n",
      "Epoch [36/50], Step [93/735], Loss: 0.0440\n",
      "Epoch [36/50], Step [94/735], Loss: 0.3250\n",
      "Epoch [36/50], Step [95/735], Loss: 0.0545\n",
      "Epoch [36/50], Step [96/735], Loss: 0.0842\n",
      "Epoch [36/50], Step [97/735], Loss: 0.1075\n",
      "Epoch [36/50], Step [98/735], Loss: 0.0876\n",
      "Epoch [36/50], Step [99/735], Loss: 0.0323\n",
      "Epoch [36/50], Step [100/735], Loss: 0.0399\n",
      "Epoch [36/50], Step [101/735], Loss: 0.0524\n",
      "Epoch [36/50], Step [102/735], Loss: 0.1720\n",
      "Epoch [36/50], Step [103/735], Loss: 0.0309\n",
      "Epoch [36/50], Step [104/735], Loss: 0.0671\n",
      "Epoch [36/50], Step [105/735], Loss: 0.0879\n",
      "Epoch [36/50], Step [106/735], Loss: 0.0463\n",
      "Epoch [36/50], Step [107/735], Loss: 0.1597\n",
      "Epoch [36/50], Step [108/735], Loss: 0.0491\n",
      "Epoch [36/50], Step [109/735], Loss: 0.0936\n",
      "Epoch [36/50], Step [110/735], Loss: 0.0392\n",
      "Epoch [36/50], Step [111/735], Loss: 0.1584\n",
      "Epoch [36/50], Step [112/735], Loss: 0.0736\n",
      "Epoch [36/50], Step [113/735], Loss: 0.1244\n",
      "Epoch [36/50], Step [114/735], Loss: 0.0604\n",
      "Epoch [36/50], Step [115/735], Loss: 0.0546\n",
      "Epoch [36/50], Step [116/735], Loss: 0.0468\n",
      "Epoch [36/50], Step [117/735], Loss: 0.0468\n",
      "Epoch [36/50], Step [118/735], Loss: 0.0823\n",
      "Epoch [36/50], Step [119/735], Loss: 0.1077\n",
      "Epoch [36/50], Step [120/735], Loss: 0.1194\n",
      "Epoch [36/50], Step [121/735], Loss: 0.0569\n",
      "Epoch [36/50], Step [122/735], Loss: 0.3480\n",
      "Epoch [36/50], Step [123/735], Loss: 0.0674\n",
      "Epoch [36/50], Step [124/735], Loss: 0.0768\n",
      "Epoch [36/50], Step [125/735], Loss: 0.1222\n",
      "Epoch [36/50], Step [126/735], Loss: 0.0470\n",
      "Epoch [36/50], Step [127/735], Loss: 0.1067\n",
      "Epoch [36/50], Step [128/735], Loss: 0.0622\n",
      "Epoch [36/50], Step [129/735], Loss: 0.0287\n",
      "Epoch [36/50], Step [130/735], Loss: 0.0614\n",
      "Epoch [36/50], Step [131/735], Loss: 0.0205\n",
      "Epoch [36/50], Step [132/735], Loss: 0.0348\n",
      "Epoch [36/50], Step [133/735], Loss: 0.0913\n",
      "Epoch [36/50], Step [134/735], Loss: 0.0555\n",
      "Epoch [36/50], Step [135/735], Loss: 0.1055\n",
      "Epoch [36/50], Step [136/735], Loss: 0.0787\n",
      "Epoch [36/50], Step [137/735], Loss: 0.0970\n",
      "Epoch [36/50], Step [138/735], Loss: 0.0338\n",
      "Epoch [36/50], Step [139/735], Loss: 0.1156\n",
      "Epoch [36/50], Step [140/735], Loss: 0.1186\n",
      "Epoch [36/50], Step [141/735], Loss: 0.1163\n",
      "Epoch [36/50], Step [142/735], Loss: 0.2356\n",
      "Epoch [36/50], Step [143/735], Loss: 0.0683\n",
      "Epoch [36/50], Step [144/735], Loss: 0.0333\n",
      "Epoch [36/50], Step [145/735], Loss: 0.0690\n",
      "Epoch [36/50], Step [146/735], Loss: 0.0669\n",
      "Epoch [36/50], Step [147/735], Loss: 0.1078\n",
      "Epoch [36/50], Step [148/735], Loss: 0.0229\n",
      "Epoch [36/50], Step [149/735], Loss: 0.0854\n",
      "Epoch [36/50], Step [150/735], Loss: 0.0962\n",
      "Epoch [36/50], Step [151/735], Loss: 0.0618\n",
      "Epoch [36/50], Step [152/735], Loss: 0.1239\n",
      "Epoch [36/50], Step [153/735], Loss: 0.0464\n",
      "Epoch [36/50], Step [154/735], Loss: 0.0628\n",
      "Epoch [36/50], Step [155/735], Loss: 0.2043\n",
      "Epoch [36/50], Step [156/735], Loss: 0.0977\n",
      "Epoch [36/50], Step [157/735], Loss: 0.0789\n",
      "Epoch [36/50], Step [158/735], Loss: 0.0829\n",
      "Epoch [36/50], Step [159/735], Loss: 0.0962\n",
      "Epoch [36/50], Step [160/735], Loss: 0.0234\n",
      "Epoch [36/50], Step [161/735], Loss: 0.1614\n",
      "Epoch [36/50], Step [162/735], Loss: 0.0932\n",
      "Epoch [36/50], Step [163/735], Loss: 0.0202\n",
      "Epoch [36/50], Step [164/735], Loss: 0.0386\n",
      "Epoch [36/50], Step [165/735], Loss: 0.1050\n",
      "Epoch [36/50], Step [166/735], Loss: 0.2823\n",
      "Epoch [36/50], Step [167/735], Loss: 0.1290\n",
      "Epoch [36/50], Step [168/735], Loss: 0.0901\n",
      "Epoch [36/50], Step [169/735], Loss: 0.0747\n",
      "Epoch [36/50], Step [170/735], Loss: 0.0596\n",
      "Epoch [36/50], Step [171/735], Loss: 0.0615\n",
      "Epoch [36/50], Step [172/735], Loss: 0.0213\n",
      "Epoch [36/50], Step [173/735], Loss: 0.1720\n",
      "Epoch [36/50], Step [174/735], Loss: 0.0355\n",
      "Epoch [36/50], Step [175/735], Loss: 0.0804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Step [176/735], Loss: 0.0490\n",
      "Epoch [36/50], Step [177/735], Loss: 0.1049\n",
      "Epoch [36/50], Step [178/735], Loss: 0.0726\n",
      "Epoch [36/50], Step [179/735], Loss: 0.0648\n",
      "Epoch [36/50], Step [180/735], Loss: 0.0701\n",
      "Epoch [36/50], Step [181/735], Loss: 0.0535\n",
      "Epoch [36/50], Step [182/735], Loss: 0.0270\n",
      "Epoch [36/50], Step [183/735], Loss: 0.0682\n",
      "Epoch [36/50], Step [184/735], Loss: 0.1298\n",
      "Epoch [36/50], Step [185/735], Loss: 0.0330\n",
      "Epoch [36/50], Step [186/735], Loss: 0.0355\n",
      "Epoch [36/50], Step [187/735], Loss: 0.0841\n",
      "Epoch [36/50], Step [188/735], Loss: 0.0571\n",
      "Epoch [36/50], Step [189/735], Loss: 0.0457\n",
      "Epoch [36/50], Step [190/735], Loss: 0.0247\n",
      "Epoch [36/50], Step [191/735], Loss: 0.0588\n",
      "Epoch [36/50], Step [192/735], Loss: 0.0517\n",
      "Epoch [36/50], Step [193/735], Loss: 0.0637\n",
      "Epoch [36/50], Step [194/735], Loss: 0.0246\n",
      "Epoch [36/50], Step [195/735], Loss: 0.0450\n",
      "Epoch [36/50], Step [196/735], Loss: 0.0591\n",
      "Epoch [36/50], Step [197/735], Loss: 0.0652\n",
      "Epoch [36/50], Step [198/735], Loss: 0.0791\n",
      "Epoch [36/50], Step [199/735], Loss: 0.0488\n",
      "Epoch [36/50], Step [200/735], Loss: 0.0553\n",
      "Epoch [36/50], Step [201/735], Loss: 0.0714\n",
      "Epoch [36/50], Step [202/735], Loss: 0.0538\n",
      "Epoch [36/50], Step [203/735], Loss: 0.0665\n",
      "Epoch [36/50], Step [204/735], Loss: 0.0690\n",
      "Epoch [36/50], Step [205/735], Loss: 0.0392\n",
      "Epoch [36/50], Step [206/735], Loss: 0.0879\n",
      "Epoch [36/50], Step [207/735], Loss: 0.0747\n",
      "Epoch [36/50], Step [208/735], Loss: 0.0423\n",
      "Epoch [36/50], Step [209/735], Loss: 0.1453\n",
      "Epoch [36/50], Step [210/735], Loss: 0.0253\n",
      "Epoch [36/50], Step [211/735], Loss: 0.0936\n",
      "Epoch [36/50], Step [212/735], Loss: 0.0471\n",
      "Epoch [36/50], Step [213/735], Loss: 0.0799\n",
      "Epoch [36/50], Step [214/735], Loss: 0.0568\n",
      "Epoch [36/50], Step [215/735], Loss: 0.0394\n",
      "Epoch [36/50], Step [216/735], Loss: 0.0269\n",
      "Epoch [36/50], Step [217/735], Loss: 0.0562\n",
      "Epoch [36/50], Step [218/735], Loss: 0.0652\n",
      "Epoch [36/50], Step [219/735], Loss: 0.0873\n",
      "Epoch [36/50], Step [220/735], Loss: 0.0232\n",
      "Epoch [36/50], Step [221/735], Loss: 0.0996\n",
      "Epoch [36/50], Step [222/735], Loss: 0.0665\n",
      "Epoch [36/50], Step [223/735], Loss: 0.0653\n",
      "Epoch [36/50], Step [224/735], Loss: 0.1625\n",
      "Epoch [36/50], Step [225/735], Loss: 0.0762\n",
      "Epoch [36/50], Step [226/735], Loss: 0.0686\n",
      "Epoch [36/50], Step [227/735], Loss: 0.1348\n",
      "Epoch [36/50], Step [228/735], Loss: 0.0303\n",
      "Epoch [36/50], Step [229/735], Loss: 0.1334\n",
      "Epoch [36/50], Step [230/735], Loss: 0.0338\n",
      "Epoch [36/50], Step [231/735], Loss: 0.0619\n",
      "Epoch [36/50], Step [232/735], Loss: 0.1427\n",
      "Epoch [36/50], Step [233/735], Loss: 0.1169\n",
      "Epoch [36/50], Step [234/735], Loss: 0.0592\n",
      "Epoch [36/50], Step [235/735], Loss: 0.0531\n",
      "Epoch [36/50], Step [236/735], Loss: 0.0484\n",
      "Epoch [36/50], Step [237/735], Loss: 0.1811\n",
      "Epoch [36/50], Step [238/735], Loss: 0.0225\n",
      "Epoch [36/50], Step [239/735], Loss: 0.0661\n",
      "Epoch [36/50], Step [240/735], Loss: 0.1018\n",
      "Epoch [36/50], Step [241/735], Loss: 0.0412\n",
      "Epoch [36/50], Step [242/735], Loss: 0.0905\n",
      "Epoch [36/50], Step [243/735], Loss: 0.0331\n",
      "Epoch [36/50], Step [244/735], Loss: 0.0701\n",
      "Epoch [36/50], Step [245/735], Loss: 0.0307\n",
      "Epoch [36/50], Step [246/735], Loss: 0.0705\n",
      "Epoch [36/50], Step [247/735], Loss: 0.0242\n",
      "Epoch [36/50], Step [248/735], Loss: 0.3378\n",
      "Epoch [36/50], Step [249/735], Loss: 0.0281\n",
      "Epoch [36/50], Step [250/735], Loss: 0.0540\n",
      "Epoch [36/50], Step [251/735], Loss: 0.0448\n",
      "Epoch [36/50], Step [252/735], Loss: 0.0320\n",
      "Epoch [36/50], Step [253/735], Loss: 0.0716\n",
      "Epoch [36/50], Step [254/735], Loss: 0.0571\n",
      "Epoch [36/50], Step [255/735], Loss: 0.1921\n",
      "Epoch [36/50], Step [256/735], Loss: 0.1425\n",
      "Epoch [36/50], Step [257/735], Loss: 0.1866\n",
      "Epoch [36/50], Step [258/735], Loss: 0.0638\n",
      "Epoch [36/50], Step [259/735], Loss: 0.0616\n",
      "Epoch [36/50], Step [260/735], Loss: 0.0763\n",
      "Epoch [36/50], Step [261/735], Loss: 0.0348\n",
      "Epoch [36/50], Step [262/735], Loss: 0.0307\n",
      "Epoch [36/50], Step [263/735], Loss: 0.0448\n",
      "Epoch [36/50], Step [264/735], Loss: 0.1292\n",
      "Epoch [36/50], Step [265/735], Loss: 0.0770\n",
      "Epoch [36/50], Step [266/735], Loss: 0.0434\n",
      "Epoch [36/50], Step [267/735], Loss: 0.0746\n",
      "Epoch [36/50], Step [268/735], Loss: 0.0981\n",
      "Epoch [36/50], Step [269/735], Loss: 0.0407\n",
      "Epoch [36/50], Step [270/735], Loss: 0.2211\n",
      "Epoch [36/50], Step [271/735], Loss: 0.0978\n",
      "Epoch [36/50], Step [272/735], Loss: 0.1156\n",
      "Epoch [36/50], Step [273/735], Loss: 0.0655\n",
      "Epoch [36/50], Step [274/735], Loss: 0.0733\n",
      "Epoch [36/50], Step [275/735], Loss: 0.0264\n",
      "Epoch [36/50], Step [276/735], Loss: 0.1411\n",
      "Epoch [36/50], Step [277/735], Loss: 0.1563\n",
      "Epoch [36/50], Step [278/735], Loss: 0.0840\n",
      "Epoch [36/50], Step [279/735], Loss: 0.0606\n",
      "Epoch [36/50], Step [280/735], Loss: 0.0270\n",
      "Epoch [36/50], Step [281/735], Loss: 0.0963\n",
      "Epoch [36/50], Step [282/735], Loss: 0.0585\n",
      "Epoch [36/50], Step [283/735], Loss: 0.1050\n",
      "Epoch [36/50], Step [284/735], Loss: 0.0726\n",
      "Epoch [36/50], Step [285/735], Loss: 0.0493\n",
      "Epoch [36/50], Step [286/735], Loss: 0.0362\n",
      "Epoch [36/50], Step [287/735], Loss: 0.0671\n",
      "Epoch [36/50], Step [288/735], Loss: 0.0561\n",
      "Epoch [36/50], Step [289/735], Loss: 0.1262\n",
      "Epoch [36/50], Step [290/735], Loss: 0.0395\n",
      "Epoch [36/50], Step [291/735], Loss: 0.1300\n",
      "Epoch [36/50], Step [292/735], Loss: 0.2187\n",
      "Epoch [36/50], Step [293/735], Loss: 0.0993\n",
      "Epoch [36/50], Step [294/735], Loss: 0.1055\n",
      "Epoch [36/50], Step [295/735], Loss: 0.0476\n",
      "Epoch [36/50], Step [296/735], Loss: 0.0795\n",
      "Epoch [36/50], Step [297/735], Loss: 0.0393\n",
      "Epoch [36/50], Step [298/735], Loss: 0.0374\n",
      "Epoch [36/50], Step [299/735], Loss: 0.0294\n",
      "Epoch [36/50], Step [300/735], Loss: 0.0828\n",
      "Epoch [36/50], Step [301/735], Loss: 0.1850\n",
      "Epoch [36/50], Step [302/735], Loss: 0.0613\n",
      "Epoch [36/50], Step [303/735], Loss: 0.0307\n",
      "Epoch [36/50], Step [304/735], Loss: 0.0558\n",
      "Epoch [36/50], Step [305/735], Loss: 0.0727\n",
      "Epoch [36/50], Step [306/735], Loss: 0.0604\n",
      "Epoch [36/50], Step [307/735], Loss: 0.0779\n",
      "Epoch [36/50], Step [308/735], Loss: 0.0386\n",
      "Epoch [36/50], Step [309/735], Loss: 0.0785\n",
      "Epoch [36/50], Step [310/735], Loss: 0.1331\n",
      "Epoch [36/50], Step [311/735], Loss: 0.1193\n",
      "Epoch [36/50], Step [312/735], Loss: 0.0306\n",
      "Epoch [36/50], Step [313/735], Loss: 0.0610\n",
      "Epoch [36/50], Step [314/735], Loss: 0.1246\n",
      "Epoch [36/50], Step [315/735], Loss: 0.0169\n",
      "Epoch [36/50], Step [316/735], Loss: 0.0276\n",
      "Epoch [36/50], Step [317/735], Loss: 0.0199\n",
      "Epoch [36/50], Step [318/735], Loss: 0.0598\n",
      "Epoch [36/50], Step [319/735], Loss: 0.3387\n",
      "Epoch [36/50], Step [320/735], Loss: 0.0380\n",
      "Epoch [36/50], Step [321/735], Loss: 0.0847\n",
      "Epoch [36/50], Step [322/735], Loss: 0.1320\n",
      "Epoch [36/50], Step [323/735], Loss: 0.0896\n",
      "Epoch [36/50], Step [324/735], Loss: 0.0882\n",
      "Epoch [36/50], Step [325/735], Loss: 0.0458\n",
      "Epoch [36/50], Step [326/735], Loss: 0.0361\n",
      "Epoch [36/50], Step [327/735], Loss: 0.0453\n",
      "Epoch [36/50], Step [328/735], Loss: 0.0407\n",
      "Epoch [36/50], Step [329/735], Loss: 0.2803\n",
      "Epoch [36/50], Step [330/735], Loss: 0.0746\n",
      "Epoch [36/50], Step [331/735], Loss: 0.1213\n",
      "Epoch [36/50], Step [332/735], Loss: 0.0268\n",
      "Epoch [36/50], Step [333/735], Loss: 0.0698\n",
      "Epoch [36/50], Step [334/735], Loss: 0.0492\n",
      "Epoch [36/50], Step [335/735], Loss: 0.0248\n",
      "Epoch [36/50], Step [336/735], Loss: 0.1168\n",
      "Epoch [36/50], Step [337/735], Loss: 0.0389\n",
      "Epoch [36/50], Step [338/735], Loss: 0.0276\n",
      "Epoch [36/50], Step [339/735], Loss: 0.0964\n",
      "Epoch [36/50], Step [340/735], Loss: 0.0780\n",
      "Epoch [36/50], Step [341/735], Loss: 0.0920\n",
      "Epoch [36/50], Step [342/735], Loss: 0.0532\n",
      "Epoch [36/50], Step [343/735], Loss: 0.0317\n",
      "Epoch [36/50], Step [344/735], Loss: 0.0925\n",
      "Epoch [36/50], Step [345/735], Loss: 0.0516\n",
      "Epoch [36/50], Step [346/735], Loss: 0.0467\n",
      "Epoch [36/50], Step [347/735], Loss: 0.0679\n",
      "Epoch [36/50], Step [348/735], Loss: 0.1254\n",
      "Epoch [36/50], Step [349/735], Loss: 0.0485\n",
      "Epoch [36/50], Step [350/735], Loss: 0.0485\n",
      "Epoch [36/50], Step [351/735], Loss: 0.0376\n",
      "Epoch [36/50], Step [352/735], Loss: 0.0795\n",
      "Epoch [36/50], Step [353/735], Loss: 0.0813\n",
      "Epoch [36/50], Step [354/735], Loss: 0.0610\n",
      "Epoch [36/50], Step [355/735], Loss: 0.0717\n",
      "Epoch [36/50], Step [356/735], Loss: 0.1264\n",
      "Epoch [36/50], Step [357/735], Loss: 0.0732\n",
      "Epoch [36/50], Step [358/735], Loss: 0.0848\n",
      "Epoch [36/50], Step [359/735], Loss: 0.0365\n",
      "Epoch [36/50], Step [360/735], Loss: 0.1340\n",
      "Epoch [36/50], Step [361/735], Loss: 0.0196\n",
      "Epoch [36/50], Step [362/735], Loss: 0.0924\n",
      "Epoch [36/50], Step [363/735], Loss: 0.0561\n",
      "Epoch [36/50], Step [364/735], Loss: 0.0492\n",
      "Epoch [36/50], Step [365/735], Loss: 0.0649\n",
      "Epoch [36/50], Step [366/735], Loss: 0.0221\n",
      "Epoch [36/50], Step [367/735], Loss: 0.0695\n",
      "Epoch [36/50], Step [368/735], Loss: 0.1360\n",
      "Epoch [36/50], Step [369/735], Loss: 0.0332\n",
      "Epoch [36/50], Step [370/735], Loss: 0.2115\n",
      "Epoch [36/50], Step [371/735], Loss: 0.1493\n",
      "Epoch [36/50], Step [372/735], Loss: 0.0541\n",
      "Epoch [36/50], Step [373/735], Loss: 0.0589\n",
      "Epoch [36/50], Step [374/735], Loss: 0.0743\n",
      "Epoch [36/50], Step [375/735], Loss: 0.0744\n",
      "Epoch [36/50], Step [376/735], Loss: 0.0783\n",
      "Epoch [36/50], Step [377/735], Loss: 0.1278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Step [378/735], Loss: 0.0988\n",
      "Epoch [36/50], Step [379/735], Loss: 0.0437\n",
      "Epoch [36/50], Step [380/735], Loss: 0.0577\n",
      "Epoch [36/50], Step [381/735], Loss: 0.0612\n",
      "Epoch [36/50], Step [382/735], Loss: 0.0957\n",
      "Epoch [36/50], Step [383/735], Loss: 0.1296\n",
      "Epoch [36/50], Step [384/735], Loss: 0.0270\n",
      "Epoch [36/50], Step [385/735], Loss: 0.1465\n",
      "Epoch [36/50], Step [386/735], Loss: 0.2075\n",
      "Epoch [36/50], Step [387/735], Loss: 0.0972\n",
      "Epoch [36/50], Step [388/735], Loss: 0.0513\n",
      "Epoch [36/50], Step [389/735], Loss: 0.0655\n",
      "Epoch [36/50], Step [390/735], Loss: 0.0735\n",
      "Epoch [36/50], Step [391/735], Loss: 0.2030\n",
      "Epoch [36/50], Step [392/735], Loss: 0.1259\n",
      "Epoch [36/50], Step [393/735], Loss: 0.0499\n",
      "Epoch [36/50], Step [394/735], Loss: 0.1085\n",
      "Epoch [36/50], Step [395/735], Loss: 0.0461\n",
      "Epoch [36/50], Step [396/735], Loss: 0.0548\n",
      "Epoch [36/50], Step [397/735], Loss: 0.0976\n",
      "Epoch [36/50], Step [398/735], Loss: 0.0566\n",
      "Epoch [36/50], Step [399/735], Loss: 0.0389\n",
      "Epoch [36/50], Step [400/735], Loss: 0.0607\n",
      "Epoch [36/50], Step [401/735], Loss: 0.0440\n",
      "Epoch [36/50], Step [402/735], Loss: 0.0784\n",
      "Epoch [36/50], Step [403/735], Loss: 0.0286\n",
      "Epoch [36/50], Step [404/735], Loss: 0.0606\n",
      "Epoch [36/50], Step [405/735], Loss: 0.4158\n",
      "Epoch [36/50], Step [406/735], Loss: 0.0386\n",
      "Epoch [36/50], Step [407/735], Loss: 0.0773\n",
      "Epoch [36/50], Step [408/735], Loss: 0.0397\n",
      "Epoch [36/50], Step [409/735], Loss: 0.0553\n",
      "Epoch [36/50], Step [410/735], Loss: 0.0543\n",
      "Epoch [36/50], Step [411/735], Loss: 0.0408\n",
      "Epoch [36/50], Step [412/735], Loss: 0.1954\n",
      "Epoch [36/50], Step [413/735], Loss: 0.0765\n",
      "Epoch [36/50], Step [414/735], Loss: 0.0699\n",
      "Epoch [36/50], Step [415/735], Loss: 0.0419\n",
      "Epoch [36/50], Step [416/735], Loss: 0.0231\n",
      "Epoch [36/50], Step [417/735], Loss: 0.0839\n",
      "Epoch [36/50], Step [418/735], Loss: 0.0295\n",
      "Epoch [36/50], Step [419/735], Loss: 0.0656\n",
      "Epoch [36/50], Step [420/735], Loss: 0.0827\n",
      "Epoch [36/50], Step [421/735], Loss: 0.0519\n",
      "Epoch [36/50], Step [422/735], Loss: 0.0479\n",
      "Epoch [36/50], Step [423/735], Loss: 0.0360\n",
      "Epoch [36/50], Step [424/735], Loss: 0.0774\n",
      "Epoch [36/50], Step [425/735], Loss: 0.2410\n",
      "Epoch [36/50], Step [426/735], Loss: 0.0391\n",
      "Epoch [36/50], Step [427/735], Loss: 0.0527\n",
      "Epoch [36/50], Step [428/735], Loss: 0.0411\n",
      "Epoch [36/50], Step [429/735], Loss: 0.0397\n",
      "Epoch [36/50], Step [430/735], Loss: 0.0499\n",
      "Epoch [36/50], Step [431/735], Loss: 0.0447\n",
      "Epoch [36/50], Step [432/735], Loss: 0.0842\n",
      "Epoch [36/50], Step [433/735], Loss: 0.1839\n",
      "Epoch [36/50], Step [434/735], Loss: 0.1032\n",
      "Epoch [36/50], Step [435/735], Loss: 0.0421\n",
      "Epoch [36/50], Step [436/735], Loss: 0.1015\n",
      "Epoch [36/50], Step [437/735], Loss: 0.0594\n",
      "Epoch [36/50], Step [438/735], Loss: 0.0421\n",
      "Epoch [36/50], Step [439/735], Loss: 0.1297\n",
      "Epoch [36/50], Step [440/735], Loss: 0.0976\n",
      "Epoch [36/50], Step [441/735], Loss: 0.0561\n",
      "Epoch [36/50], Step [442/735], Loss: 0.0832\n",
      "Epoch [36/50], Step [443/735], Loss: 0.0323\n",
      "Epoch [36/50], Step [444/735], Loss: 0.0756\n",
      "Epoch [36/50], Step [445/735], Loss: 0.0286\n",
      "Epoch [36/50], Step [446/735], Loss: 0.0439\n",
      "Epoch [36/50], Step [447/735], Loss: 0.2519\n",
      "Epoch [36/50], Step [448/735], Loss: 0.0898\n",
      "Epoch [36/50], Step [449/735], Loss: 0.0251\n",
      "Epoch [36/50], Step [450/735], Loss: 0.0185\n",
      "Epoch [36/50], Step [451/735], Loss: 0.0330\n",
      "Epoch [36/50], Step [452/735], Loss: 0.0657\n",
      "Epoch [36/50], Step [453/735], Loss: 0.1011\n",
      "Epoch [36/50], Step [454/735], Loss: 0.0705\n",
      "Epoch [36/50], Step [455/735], Loss: 0.1143\n",
      "Epoch [36/50], Step [456/735], Loss: 0.0354\n",
      "Epoch [36/50], Step [457/735], Loss: 0.0230\n",
      "Epoch [36/50], Step [458/735], Loss: 0.0368\n",
      "Epoch [36/50], Step [459/735], Loss: 0.0366\n",
      "Epoch [36/50], Step [460/735], Loss: 0.0548\n",
      "Epoch [36/50], Step [461/735], Loss: 0.0870\n",
      "Epoch [36/50], Step [462/735], Loss: 0.1433\n",
      "Epoch [36/50], Step [463/735], Loss: 0.0283\n",
      "Epoch [36/50], Step [464/735], Loss: 0.0344\n",
      "Epoch [36/50], Step [465/735], Loss: 0.0566\n",
      "Epoch [36/50], Step [466/735], Loss: 0.1107\n",
      "Epoch [36/50], Step [467/735], Loss: 0.0409\n",
      "Epoch [36/50], Step [468/735], Loss: 0.0393\n",
      "Epoch [36/50], Step [469/735], Loss: 0.2239\n",
      "Epoch [36/50], Step [470/735], Loss: 0.0367\n",
      "Epoch [36/50], Step [471/735], Loss: 0.1411\n",
      "Epoch [36/50], Step [472/735], Loss: 0.0888\n",
      "Epoch [36/50], Step [473/735], Loss: 0.0618\n",
      "Epoch [36/50], Step [474/735], Loss: 0.0723\n",
      "Epoch [36/50], Step [475/735], Loss: 0.0671\n",
      "Epoch [36/50], Step [476/735], Loss: 0.1044\n",
      "Epoch [36/50], Step [477/735], Loss: 0.0349\n",
      "Epoch [36/50], Step [478/735], Loss: 0.0730\n",
      "Epoch [36/50], Step [479/735], Loss: 0.0472\n",
      "Epoch [36/50], Step [480/735], Loss: 0.0641\n",
      "Epoch [36/50], Step [481/735], Loss: 0.0267\n",
      "Epoch [36/50], Step [482/735], Loss: 0.0309\n",
      "Epoch [36/50], Step [483/735], Loss: 0.0403\n",
      "Epoch [36/50], Step [484/735], Loss: 0.1054\n",
      "Epoch [36/50], Step [485/735], Loss: 0.0560\n",
      "Epoch [36/50], Step [486/735], Loss: 0.0481\n",
      "Epoch [36/50], Step [487/735], Loss: 0.0742\n",
      "Epoch [36/50], Step [488/735], Loss: 0.2887\n",
      "Epoch [36/50], Step [489/735], Loss: 0.0586\n",
      "Epoch [36/50], Step [490/735], Loss: 0.2908\n",
      "Epoch [36/50], Step [491/735], Loss: 0.1243\n",
      "Epoch [36/50], Step [492/735], Loss: 0.0409\n",
      "Epoch [36/50], Step [493/735], Loss: 0.2723\n",
      "Epoch [36/50], Step [494/735], Loss: 0.0549\n",
      "Epoch [36/50], Step [495/735], Loss: 0.1022\n",
      "Epoch [36/50], Step [496/735], Loss: 0.0556\n",
      "Epoch [36/50], Step [497/735], Loss: 0.0160\n",
      "Epoch [36/50], Step [498/735], Loss: 0.0482\n",
      "Epoch [36/50], Step [499/735], Loss: 0.1531\n",
      "Epoch [36/50], Step [500/735], Loss: 0.0227\n",
      "Epoch [36/50], Step [501/735], Loss: 0.0493\n",
      "Epoch [36/50], Step [502/735], Loss: 0.0627\n",
      "Epoch [36/50], Step [503/735], Loss: 0.0690\n",
      "Epoch [36/50], Step [504/735], Loss: 0.0190\n",
      "Epoch [36/50], Step [505/735], Loss: 0.0937\n",
      "Epoch [36/50], Step [506/735], Loss: 0.1103\n",
      "Epoch [36/50], Step [507/735], Loss: 0.1063\n",
      "Epoch [36/50], Step [508/735], Loss: 0.0627\n",
      "Epoch [36/50], Step [509/735], Loss: 0.0289\n",
      "Epoch [36/50], Step [510/735], Loss: 0.0598\n",
      "Epoch [36/50], Step [511/735], Loss: 0.0616\n",
      "Epoch [36/50], Step [512/735], Loss: 0.1037\n",
      "Epoch [36/50], Step [513/735], Loss: 0.0332\n",
      "Epoch [36/50], Step [514/735], Loss: 0.0714\n",
      "Epoch [36/50], Step [515/735], Loss: 0.2054\n",
      "Epoch [36/50], Step [516/735], Loss: 0.0616\n",
      "Epoch [36/50], Step [517/735], Loss: 0.1204\n",
      "Epoch [36/50], Step [518/735], Loss: 0.0490\n",
      "Epoch [36/50], Step [519/735], Loss: 0.0334\n",
      "Epoch [36/50], Step [520/735], Loss: 0.0811\n",
      "Epoch [36/50], Step [521/735], Loss: 0.0312\n",
      "Epoch [36/50], Step [522/735], Loss: 0.0389\n",
      "Epoch [36/50], Step [523/735], Loss: 0.0295\n",
      "Epoch [36/50], Step [524/735], Loss: 0.0516\n",
      "Epoch [36/50], Step [525/735], Loss: 0.0274\n",
      "Epoch [36/50], Step [526/735], Loss: 0.0669\n",
      "Epoch [36/50], Step [527/735], Loss: 0.1070\n",
      "Epoch [36/50], Step [528/735], Loss: 0.0273\n",
      "Epoch [36/50], Step [529/735], Loss: 0.0627\n",
      "Epoch [36/50], Step [530/735], Loss: 0.1562\n",
      "Epoch [36/50], Step [531/735], Loss: 0.0231\n",
      "Epoch [36/50], Step [532/735], Loss: 0.0921\n",
      "Epoch [36/50], Step [533/735], Loss: 0.0657\n",
      "Epoch [36/50], Step [534/735], Loss: 0.0165\n",
      "Epoch [36/50], Step [535/735], Loss: 0.1561\n",
      "Epoch [36/50], Step [536/735], Loss: 0.0262\n",
      "Epoch [36/50], Step [537/735], Loss: 0.0234\n",
      "Epoch [36/50], Step [538/735], Loss: 0.0872\n",
      "Epoch [36/50], Step [539/735], Loss: 0.0781\n",
      "Epoch [36/50], Step [540/735], Loss: 0.0984\n",
      "Epoch [36/50], Step [541/735], Loss: 0.0767\n",
      "Epoch [36/50], Step [542/735], Loss: 0.0297\n",
      "Epoch [36/50], Step [543/735], Loss: 0.0688\n",
      "Epoch [36/50], Step [544/735], Loss: 0.0219\n",
      "Epoch [36/50], Step [545/735], Loss: 0.0751\n",
      "Epoch [36/50], Step [546/735], Loss: 0.1140\n",
      "Epoch [36/50], Step [547/735], Loss: 0.0431\n",
      "Epoch [36/50], Step [548/735], Loss: 0.0491\n",
      "Epoch [36/50], Step [549/735], Loss: 0.1019\n",
      "Epoch [36/50], Step [550/735], Loss: 0.0415\n",
      "Epoch [36/50], Step [551/735], Loss: 0.0265\n",
      "Epoch [36/50], Step [552/735], Loss: 0.0636\n",
      "Epoch [36/50], Step [553/735], Loss: 0.0537\n",
      "Epoch [36/50], Step [554/735], Loss: 0.1043\n",
      "Epoch [36/50], Step [555/735], Loss: 0.0687\n",
      "Epoch [36/50], Step [556/735], Loss: 0.1179\n",
      "Epoch [36/50], Step [557/735], Loss: 0.0353\n",
      "Epoch [36/50], Step [558/735], Loss: 0.0303\n",
      "Epoch [36/50], Step [559/735], Loss: 0.2192\n",
      "Epoch [36/50], Step [560/735], Loss: 0.1246\n",
      "Epoch [36/50], Step [561/735], Loss: 0.0818\n",
      "Epoch [36/50], Step [562/735], Loss: 0.0565\n",
      "Epoch [36/50], Step [563/735], Loss: 0.0923\n",
      "Epoch [36/50], Step [564/735], Loss: 0.0449\n",
      "Epoch [36/50], Step [565/735], Loss: 0.0235\n",
      "Epoch [36/50], Step [566/735], Loss: 0.0330\n",
      "Epoch [36/50], Step [567/735], Loss: 0.0631\n",
      "Epoch [36/50], Step [568/735], Loss: 0.0207\n",
      "Epoch [36/50], Step [569/735], Loss: 0.0668\n",
      "Epoch [36/50], Step [570/735], Loss: 0.0272\n",
      "Epoch [36/50], Step [571/735], Loss: 0.0405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Step [572/735], Loss: 0.0675\n",
      "Epoch [36/50], Step [573/735], Loss: 0.0627\n",
      "Epoch [36/50], Step [574/735], Loss: 0.0530\n",
      "Epoch [36/50], Step [575/735], Loss: 0.0219\n",
      "Epoch [36/50], Step [576/735], Loss: 0.0177\n",
      "Epoch [36/50], Step [577/735], Loss: 0.0907\n",
      "Epoch [36/50], Step [578/735], Loss: 0.0746\n",
      "Epoch [36/50], Step [579/735], Loss: 0.0471\n",
      "Epoch [36/50], Step [580/735], Loss: 0.0248\n",
      "Epoch [36/50], Step [581/735], Loss: 0.0376\n",
      "Epoch [36/50], Step [582/735], Loss: 0.1079\n",
      "Epoch [36/50], Step [583/735], Loss: 0.0448\n",
      "Epoch [36/50], Step [584/735], Loss: 0.0222\n",
      "Epoch [36/50], Step [585/735], Loss: 0.0465\n",
      "Epoch [36/50], Step [586/735], Loss: 0.0366\n",
      "Epoch [36/50], Step [587/735], Loss: 0.0225\n",
      "Epoch [36/50], Step [588/735], Loss: 0.0254\n",
      "Epoch [36/50], Step [589/735], Loss: 0.1113\n",
      "Epoch [36/50], Step [590/735], Loss: 0.0661\n",
      "Epoch [36/50], Step [591/735], Loss: 0.0658\n",
      "Epoch [36/50], Step [592/735], Loss: 0.0619\n",
      "Epoch [36/50], Step [593/735], Loss: 0.2448\n",
      "Epoch [36/50], Step [594/735], Loss: 0.0571\n",
      "Epoch [36/50], Step [595/735], Loss: 0.0821\n",
      "Epoch [36/50], Step [596/735], Loss: 0.0944\n",
      "Epoch [36/50], Step [597/735], Loss: 0.0584\n",
      "Epoch [36/50], Step [598/735], Loss: 0.0267\n",
      "Epoch [36/50], Step [599/735], Loss: 0.0725\n",
      "Epoch [36/50], Step [600/735], Loss: 0.0499\n",
      "Epoch [36/50], Step [601/735], Loss: 0.0300\n",
      "Epoch [36/50], Step [602/735], Loss: 0.0671\n",
      "Epoch [36/50], Step [603/735], Loss: 0.2241\n",
      "Epoch [36/50], Step [604/735], Loss: 0.3558\n",
      "Epoch [36/50], Step [605/735], Loss: 0.0727\n",
      "Epoch [36/50], Step [606/735], Loss: 0.0404\n",
      "Epoch [36/50], Step [607/735], Loss: 0.0808\n",
      "Epoch [36/50], Step [608/735], Loss: 0.0386\n",
      "Epoch [36/50], Step [609/735], Loss: 0.0639\n",
      "Epoch [36/50], Step [610/735], Loss: 0.0533\n",
      "Epoch [36/50], Step [611/735], Loss: 0.1120\n",
      "Epoch [36/50], Step [612/735], Loss: 0.0701\n",
      "Epoch [36/50], Step [613/735], Loss: 0.1737\n",
      "Epoch [36/50], Step [614/735], Loss: 0.0740\n",
      "Epoch [36/50], Step [615/735], Loss: 0.0304\n",
      "Epoch [36/50], Step [616/735], Loss: 0.0347\n",
      "Epoch [36/50], Step [617/735], Loss: 0.1732\n",
      "Epoch [36/50], Step [618/735], Loss: 0.2353\n",
      "Epoch [36/50], Step [619/735], Loss: 0.0470\n",
      "Epoch [36/50], Step [620/735], Loss: 0.1120\n",
      "Epoch [36/50], Step [621/735], Loss: 0.1850\n",
      "Epoch [36/50], Step [622/735], Loss: 0.0982\n",
      "Epoch [36/50], Step [623/735], Loss: 0.1029\n",
      "Epoch [36/50], Step [624/735], Loss: 0.0474\n",
      "Epoch [36/50], Step [625/735], Loss: 0.0634\n",
      "Epoch [36/50], Step [626/735], Loss: 0.0457\n",
      "Epoch [36/50], Step [627/735], Loss: 0.0735\n",
      "Epoch [36/50], Step [628/735], Loss: 0.0787\n",
      "Epoch [36/50], Step [629/735], Loss: 0.0260\n",
      "Epoch [36/50], Step [630/735], Loss: 0.1260\n",
      "Epoch [36/50], Step [631/735], Loss: 0.0263\n",
      "Epoch [36/50], Step [632/735], Loss: 0.0690\n",
      "Epoch [36/50], Step [633/735], Loss: 0.1166\n",
      "Epoch [36/50], Step [634/735], Loss: 0.0442\n",
      "Epoch [36/50], Step [635/735], Loss: 0.0526\n",
      "Epoch [36/50], Step [636/735], Loss: 0.0737\n",
      "Epoch [36/50], Step [637/735], Loss: 0.0497\n",
      "Epoch [36/50], Step [638/735], Loss: 0.0514\n",
      "Epoch [36/50], Step [639/735], Loss: 0.0314\n",
      "Epoch [36/50], Step [640/735], Loss: 0.0842\n",
      "Epoch [36/50], Step [641/735], Loss: 0.0325\n",
      "Epoch [36/50], Step [642/735], Loss: 0.0434\n",
      "Epoch [36/50], Step [643/735], Loss: 0.0744\n",
      "Epoch [36/50], Step [644/735], Loss: 0.0533\n",
      "Epoch [36/50], Step [645/735], Loss: 0.0394\n",
      "Epoch [36/50], Step [646/735], Loss: 0.0634\n",
      "Epoch [36/50], Step [647/735], Loss: 0.0352\n",
      "Epoch [36/50], Step [648/735], Loss: 0.0275\n",
      "Epoch [36/50], Step [649/735], Loss: 0.0734\n",
      "Epoch [36/50], Step [650/735], Loss: 0.0621\n",
      "Epoch [36/50], Step [651/735], Loss: 0.0327\n",
      "Epoch [36/50], Step [652/735], Loss: 0.0252\n",
      "Epoch [36/50], Step [653/735], Loss: 0.1030\n",
      "Epoch [36/50], Step [654/735], Loss: 0.0613\n",
      "Epoch [36/50], Step [655/735], Loss: 0.0279\n",
      "Epoch [36/50], Step [656/735], Loss: 0.0336\n",
      "Epoch [36/50], Step [657/735], Loss: 0.0643\n",
      "Epoch [36/50], Step [658/735], Loss: 0.3099\n",
      "Epoch [36/50], Step [659/735], Loss: 0.0539\n",
      "Epoch [36/50], Step [660/735], Loss: 0.0378\n",
      "Epoch [36/50], Step [661/735], Loss: 0.0342\n",
      "Epoch [36/50], Step [662/735], Loss: 0.0843\n",
      "Epoch [36/50], Step [663/735], Loss: 0.0285\n",
      "Epoch [36/50], Step [664/735], Loss: 0.0352\n",
      "Epoch [36/50], Step [665/735], Loss: 0.0344\n",
      "Epoch [36/50], Step [666/735], Loss: 0.0689\n",
      "Epoch [36/50], Step [667/735], Loss: 0.0514\n",
      "Epoch [36/50], Step [668/735], Loss: 0.0238\n",
      "Epoch [36/50], Step [669/735], Loss: 0.0870\n",
      "Epoch [36/50], Step [670/735], Loss: 0.0128\n",
      "Epoch [36/50], Step [671/735], Loss: 0.0249\n",
      "Epoch [36/50], Step [672/735], Loss: 0.2152\n",
      "Epoch [36/50], Step [673/735], Loss: 0.0606\n",
      "Epoch [36/50], Step [674/735], Loss: 0.1802\n",
      "Epoch [36/50], Step [675/735], Loss: 0.0188\n",
      "Epoch [36/50], Step [676/735], Loss: 0.0427\n",
      "Epoch [36/50], Step [677/735], Loss: 0.1175\n",
      "Epoch [36/50], Step [678/735], Loss: 0.0242\n",
      "Epoch [36/50], Step [679/735], Loss: 0.0317\n",
      "Epoch [36/50], Step [680/735], Loss: 0.0322\n",
      "Epoch [36/50], Step [681/735], Loss: 0.0374\n",
      "Epoch [36/50], Step [682/735], Loss: 0.0415\n",
      "Epoch [36/50], Step [683/735], Loss: 0.0131\n",
      "Epoch [36/50], Step [684/735], Loss: 0.0200\n",
      "Epoch [36/50], Step [685/735], Loss: 0.0821\n",
      "Epoch [36/50], Step [686/735], Loss: 0.0416\n",
      "Epoch [36/50], Step [687/735], Loss: 0.0495\n",
      "Epoch [36/50], Step [688/735], Loss: 0.0396\n",
      "Epoch [36/50], Step [689/735], Loss: 0.0477\n",
      "Epoch [36/50], Step [690/735], Loss: 0.0565\n",
      "Epoch [36/50], Step [691/735], Loss: 0.0659\n",
      "Epoch [36/50], Step [692/735], Loss: 0.0707\n",
      "Epoch [36/50], Step [693/735], Loss: 0.0308\n",
      "Epoch [36/50], Step [694/735], Loss: 0.0923\n",
      "Epoch [36/50], Step [695/735], Loss: 0.0220\n",
      "Epoch [36/50], Step [696/735], Loss: 0.0564\n",
      "Epoch [36/50], Step [697/735], Loss: 0.0406\n",
      "Epoch [36/50], Step [698/735], Loss: 0.1005\n",
      "Epoch [36/50], Step [699/735], Loss: 0.0899\n",
      "Epoch [36/50], Step [700/735], Loss: 0.1131\n",
      "Epoch [36/50], Step [701/735], Loss: 0.0583\n",
      "Epoch [36/50], Step [702/735], Loss: 0.0509\n",
      "Epoch [36/50], Step [703/735], Loss: 0.0189\n",
      "Epoch [36/50], Step [704/735], Loss: 0.1713\n",
      "Epoch [36/50], Step [705/735], Loss: 0.0744\n",
      "Epoch [36/50], Step [706/735], Loss: 0.1448\n",
      "Epoch [36/50], Step [707/735], Loss: 0.1024\n",
      "Epoch [36/50], Step [708/735], Loss: 0.0646\n",
      "Epoch [36/50], Step [709/735], Loss: 0.0972\n",
      "Epoch [36/50], Step [710/735], Loss: 0.0341\n",
      "Epoch [36/50], Step [711/735], Loss: 0.1748\n",
      "Epoch [36/50], Step [712/735], Loss: 0.0865\n",
      "Epoch [36/50], Step [713/735], Loss: 0.0320\n",
      "Epoch [36/50], Step [714/735], Loss: 0.1488\n",
      "Epoch [36/50], Step [715/735], Loss: 0.0707\n",
      "Epoch [36/50], Step [716/735], Loss: 0.0560\n",
      "Epoch [36/50], Step [717/735], Loss: 0.0390\n",
      "Epoch [36/50], Step [718/735], Loss: 0.0902\n",
      "Epoch [36/50], Step [719/735], Loss: 0.0465\n",
      "Epoch [36/50], Step [720/735], Loss: 0.0920\n",
      "Epoch [36/50], Step [721/735], Loss: 0.0969\n",
      "Epoch [36/50], Step [722/735], Loss: 0.0275\n",
      "Epoch [36/50], Step [723/735], Loss: 0.0181\n",
      "Epoch [36/50], Step [724/735], Loss: 0.0238\n",
      "Epoch [36/50], Step [725/735], Loss: 0.0272\n",
      "Epoch [36/50], Step [726/735], Loss: 0.1160\n",
      "Epoch [36/50], Step [727/735], Loss: 0.0536\n",
      "Epoch [36/50], Step [728/735], Loss: 0.0486\n",
      "Epoch [36/50], Step [729/735], Loss: 0.0448\n",
      "Epoch [36/50], Step [730/735], Loss: 0.0404\n",
      "Epoch [36/50], Step [731/735], Loss: 0.0247\n",
      "Epoch [36/50], Step [732/735], Loss: 0.0546\n",
      "Epoch [36/50], Step [733/735], Loss: 0.0386\n",
      "Epoch [36/50], Step [734/735], Loss: 0.0172\n",
      "Epoch [36/50], Step [735/735], Loss: 0.0935\n",
      "Epoch [37/50], Step [1/735], Loss: 0.0446\n",
      "Epoch [37/50], Step [2/735], Loss: 0.0292\n",
      "Epoch [37/50], Step [3/735], Loss: 0.0404\n",
      "Epoch [37/50], Step [4/735], Loss: 0.0198\n",
      "Epoch [37/50], Step [5/735], Loss: 0.0155\n",
      "Epoch [37/50], Step [6/735], Loss: 0.0490\n",
      "Epoch [37/50], Step [7/735], Loss: 0.0574\n",
      "Epoch [37/50], Step [8/735], Loss: 0.1024\n",
      "Epoch [37/50], Step [9/735], Loss: 0.0162\n",
      "Epoch [37/50], Step [10/735], Loss: 0.0177\n",
      "Epoch [37/50], Step [11/735], Loss: 0.0948\n",
      "Epoch [37/50], Step [12/735], Loss: 0.0324\n",
      "Epoch [37/50], Step [13/735], Loss: 0.1096\n",
      "Epoch [37/50], Step [14/735], Loss: 0.0197\n",
      "Epoch [37/50], Step [15/735], Loss: 0.2848\n",
      "Epoch [37/50], Step [16/735], Loss: 0.0461\n",
      "Epoch [37/50], Step [17/735], Loss: 0.0577\n",
      "Epoch [37/50], Step [18/735], Loss: 0.0988\n",
      "Epoch [37/50], Step [19/735], Loss: 0.0221\n",
      "Epoch [37/50], Step [20/735], Loss: 0.0367\n",
      "Epoch [37/50], Step [21/735], Loss: 0.0614\n",
      "Epoch [37/50], Step [22/735], Loss: 0.0625\n",
      "Epoch [37/50], Step [23/735], Loss: 0.1102\n",
      "Epoch [37/50], Step [24/735], Loss: 0.0396\n",
      "Epoch [37/50], Step [25/735], Loss: 0.0651\n",
      "Epoch [37/50], Step [26/735], Loss: 0.2230\n",
      "Epoch [37/50], Step [27/735], Loss: 0.0249\n",
      "Epoch [37/50], Step [28/735], Loss: 0.1624\n",
      "Epoch [37/50], Step [29/735], Loss: 0.0605\n",
      "Epoch [37/50], Step [30/735], Loss: 0.0586\n",
      "Epoch [37/50], Step [31/735], Loss: 0.0287\n",
      "Epoch [37/50], Step [32/735], Loss: 0.0387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Step [33/735], Loss: 0.0298\n",
      "Epoch [37/50], Step [34/735], Loss: 0.0685\n",
      "Epoch [37/50], Step [35/735], Loss: 0.0380\n",
      "Epoch [37/50], Step [36/735], Loss: 0.0263\n",
      "Epoch [37/50], Step [37/735], Loss: 0.0685\n",
      "Epoch [37/50], Step [38/735], Loss: 0.0664\n",
      "Epoch [37/50], Step [39/735], Loss: 0.0637\n",
      "Epoch [37/50], Step [40/735], Loss: 0.0915\n",
      "Epoch [37/50], Step [41/735], Loss: 0.0737\n",
      "Epoch [37/50], Step [42/735], Loss: 0.0412\n",
      "Epoch [37/50], Step [43/735], Loss: 0.1190\n",
      "Epoch [37/50], Step [44/735], Loss: 0.0484\n",
      "Epoch [37/50], Step [45/735], Loss: 0.1769\n",
      "Epoch [37/50], Step [46/735], Loss: 0.0403\n",
      "Epoch [37/50], Step [47/735], Loss: 0.1050\n",
      "Epoch [37/50], Step [48/735], Loss: 0.0584\n",
      "Epoch [37/50], Step [49/735], Loss: 0.0371\n",
      "Epoch [37/50], Step [50/735], Loss: 0.0317\n",
      "Epoch [37/50], Step [51/735], Loss: 0.0391\n",
      "Epoch [37/50], Step [52/735], Loss: 0.0416\n",
      "Epoch [37/50], Step [53/735], Loss: 0.0343\n",
      "Epoch [37/50], Step [54/735], Loss: 0.0344\n",
      "Epoch [37/50], Step [55/735], Loss: 0.0942\n",
      "Epoch [37/50], Step [56/735], Loss: 0.2963\n",
      "Epoch [37/50], Step [57/735], Loss: 0.0431\n",
      "Epoch [37/50], Step [58/735], Loss: 0.0381\n",
      "Epoch [37/50], Step [59/735], Loss: 0.0444\n",
      "Epoch [37/50], Step [60/735], Loss: 0.0214\n",
      "Epoch [37/50], Step [61/735], Loss: 0.1325\n",
      "Epoch [37/50], Step [62/735], Loss: 0.0626\n",
      "Epoch [37/50], Step [63/735], Loss: 0.0523\n",
      "Epoch [37/50], Step [64/735], Loss: 0.0781\n",
      "Epoch [37/50], Step [65/735], Loss: 0.0445\n",
      "Epoch [37/50], Step [66/735], Loss: 0.0510\n",
      "Epoch [37/50], Step [67/735], Loss: 0.0479\n",
      "Epoch [37/50], Step [68/735], Loss: 0.0198\n",
      "Epoch [37/50], Step [69/735], Loss: 0.0267\n",
      "Epoch [37/50], Step [70/735], Loss: 0.0472\n",
      "Epoch [37/50], Step [71/735], Loss: 0.0513\n",
      "Epoch [37/50], Step [72/735], Loss: 0.0420\n",
      "Epoch [37/50], Step [73/735], Loss: 0.0184\n",
      "Epoch [37/50], Step [74/735], Loss: 0.0318\n",
      "Epoch [37/50], Step [75/735], Loss: 0.0588\n",
      "Epoch [37/50], Step [76/735], Loss: 0.0240\n",
      "Epoch [37/50], Step [77/735], Loss: 0.0300\n",
      "Epoch [37/50], Step [78/735], Loss: 0.0245\n",
      "Epoch [37/50], Step [79/735], Loss: 0.0559\n",
      "Epoch [37/50], Step [80/735], Loss: 0.0359\n",
      "Epoch [37/50], Step [81/735], Loss: 0.0286\n",
      "Epoch [37/50], Step [82/735], Loss: 0.0543\n",
      "Epoch [37/50], Step [83/735], Loss: 0.0294\n",
      "Epoch [37/50], Step [84/735], Loss: 0.1305\n",
      "Epoch [37/50], Step [85/735], Loss: 0.0171\n",
      "Epoch [37/50], Step [86/735], Loss: 0.0556\n",
      "Epoch [37/50], Step [87/735], Loss: 0.0577\n",
      "Epoch [37/50], Step [88/735], Loss: 0.0334\n",
      "Epoch [37/50], Step [89/735], Loss: 0.0489\n",
      "Epoch [37/50], Step [90/735], Loss: 0.1166\n",
      "Epoch [37/50], Step [91/735], Loss: 0.0697\n",
      "Epoch [37/50], Step [92/735], Loss: 0.0447\n",
      "Epoch [37/50], Step [93/735], Loss: 0.0385\n",
      "Epoch [37/50], Step [94/735], Loss: 0.0314\n",
      "Epoch [37/50], Step [95/735], Loss: 0.0251\n",
      "Epoch [37/50], Step [96/735], Loss: 0.0573\n",
      "Epoch [37/50], Step [97/735], Loss: 0.0377\n",
      "Epoch [37/50], Step [98/735], Loss: 0.0536\n",
      "Epoch [37/50], Step [99/735], Loss: 0.0749\n",
      "Epoch [37/50], Step [100/735], Loss: 0.0866\n",
      "Epoch [37/50], Step [101/735], Loss: 0.0154\n",
      "Epoch [37/50], Step [102/735], Loss: 0.2591\n",
      "Epoch [37/50], Step [103/735], Loss: 0.0178\n",
      "Epoch [37/50], Step [104/735], Loss: 0.1066\n",
      "Epoch [37/50], Step [105/735], Loss: 0.1609\n",
      "Epoch [37/50], Step [106/735], Loss: 0.0356\n",
      "Epoch [37/50], Step [107/735], Loss: 0.3423\n",
      "Epoch [37/50], Step [108/735], Loss: 0.1120\n",
      "Epoch [37/50], Step [109/735], Loss: 0.0197\n",
      "Epoch [37/50], Step [110/735], Loss: 0.0376\n",
      "Epoch [37/50], Step [111/735], Loss: 0.0498\n",
      "Epoch [37/50], Step [112/735], Loss: 0.1002\n",
      "Epoch [37/50], Step [113/735], Loss: 0.0484\n",
      "Epoch [37/50], Step [114/735], Loss: 0.0688\n",
      "Epoch [37/50], Step [115/735], Loss: 0.0123\n",
      "Epoch [37/50], Step [116/735], Loss: 0.0865\n",
      "Epoch [37/50], Step [117/735], Loss: 0.0216\n",
      "Epoch [37/50], Step [118/735], Loss: 0.0329\n",
      "Epoch [37/50], Step [119/735], Loss: 0.0189\n",
      "Epoch [37/50], Step [120/735], Loss: 0.1144\n",
      "Epoch [37/50], Step [121/735], Loss: 0.0936\n",
      "Epoch [37/50], Step [122/735], Loss: 0.0449\n",
      "Epoch [37/50], Step [123/735], Loss: 0.0601\n",
      "Epoch [37/50], Step [124/735], Loss: 0.0315\n",
      "Epoch [37/50], Step [125/735], Loss: 0.0927\n",
      "Epoch [37/50], Step [126/735], Loss: 0.0832\n",
      "Epoch [37/50], Step [127/735], Loss: 0.1022\n",
      "Epoch [37/50], Step [128/735], Loss: 0.0364\n",
      "Epoch [37/50], Step [129/735], Loss: 0.0644\n",
      "Epoch [37/50], Step [130/735], Loss: 0.0259\n",
      "Epoch [37/50], Step [131/735], Loss: 0.0497\n",
      "Epoch [37/50], Step [132/735], Loss: 0.0224\n",
      "Epoch [37/50], Step [133/735], Loss: 0.0326\n",
      "Epoch [37/50], Step [134/735], Loss: 0.0450\n",
      "Epoch [37/50], Step [135/735], Loss: 0.0341\n",
      "Epoch [37/50], Step [136/735], Loss: 0.0516\n",
      "Epoch [37/50], Step [137/735], Loss: 0.0260\n",
      "Epoch [37/50], Step [138/735], Loss: 0.0680\n",
      "Epoch [37/50], Step [139/735], Loss: 0.0213\n",
      "Epoch [37/50], Step [140/735], Loss: 0.2874\n",
      "Epoch [37/50], Step [141/735], Loss: 0.0354\n",
      "Epoch [37/50], Step [142/735], Loss: 0.0233\n",
      "Epoch [37/50], Step [143/735], Loss: 0.0279\n",
      "Epoch [37/50], Step [144/735], Loss: 0.0500\n",
      "Epoch [37/50], Step [145/735], Loss: 0.0376\n",
      "Epoch [37/50], Step [146/735], Loss: 0.0556\n",
      "Epoch [37/50], Step [147/735], Loss: 0.0499\n",
      "Epoch [37/50], Step [148/735], Loss: 0.0475\n",
      "Epoch [37/50], Step [149/735], Loss: 0.0319\n",
      "Epoch [37/50], Step [150/735], Loss: 0.0287\n",
      "Epoch [37/50], Step [151/735], Loss: 0.0362\n",
      "Epoch [37/50], Step [152/735], Loss: 0.0464\n",
      "Epoch [37/50], Step [153/735], Loss: 0.0154\n",
      "Epoch [37/50], Step [154/735], Loss: 0.1944\n",
      "Epoch [37/50], Step [155/735], Loss: 0.0697\n",
      "Epoch [37/50], Step [156/735], Loss: 0.0424\n",
      "Epoch [37/50], Step [157/735], Loss: 0.0489\n",
      "Epoch [37/50], Step [158/735], Loss: 0.0259\n",
      "Epoch [37/50], Step [159/735], Loss: 0.0437\n",
      "Epoch [37/50], Step [160/735], Loss: 0.0583\n",
      "Epoch [37/50], Step [161/735], Loss: 0.0412\n",
      "Epoch [37/50], Step [162/735], Loss: 0.0446\n",
      "Epoch [37/50], Step [163/735], Loss: 0.0829\n",
      "Epoch [37/50], Step [164/735], Loss: 0.0143\n",
      "Epoch [37/50], Step [165/735], Loss: 0.0334\n",
      "Epoch [37/50], Step [166/735], Loss: 0.0350\n",
      "Epoch [37/50], Step [167/735], Loss: 0.0904\n",
      "Epoch [37/50], Step [168/735], Loss: 0.0654\n",
      "Epoch [37/50], Step [169/735], Loss: 0.0386\n",
      "Epoch [37/50], Step [170/735], Loss: 0.0785\n",
      "Epoch [37/50], Step [171/735], Loss: 0.0351\n",
      "Epoch [37/50], Step [172/735], Loss: 0.0375\n",
      "Epoch [37/50], Step [173/735], Loss: 0.0688\n",
      "Epoch [37/50], Step [174/735], Loss: 0.1752\n",
      "Epoch [37/50], Step [175/735], Loss: 0.1023\n",
      "Epoch [37/50], Step [176/735], Loss: 0.0620\n",
      "Epoch [37/50], Step [177/735], Loss: 0.1589\n",
      "Epoch [37/50], Step [178/735], Loss: 0.0475\n",
      "Epoch [37/50], Step [179/735], Loss: 0.0686\n",
      "Epoch [37/50], Step [180/735], Loss: 0.0677\n",
      "Epoch [37/50], Step [181/735], Loss: 0.0955\n",
      "Epoch [37/50], Step [182/735], Loss: 0.0794\n",
      "Epoch [37/50], Step [183/735], Loss: 0.0429\n",
      "Epoch [37/50], Step [184/735], Loss: 0.0896\n",
      "Epoch [37/50], Step [185/735], Loss: 0.1338\n",
      "Epoch [37/50], Step [186/735], Loss: 0.0831\n",
      "Epoch [37/50], Step [187/735], Loss: 0.0599\n",
      "Epoch [37/50], Step [188/735], Loss: 0.0264\n",
      "Epoch [37/50], Step [189/735], Loss: 0.0274\n",
      "Epoch [37/50], Step [190/735], Loss: 0.0361\n",
      "Epoch [37/50], Step [191/735], Loss: 0.0613\n",
      "Epoch [37/50], Step [192/735], Loss: 0.0820\n",
      "Epoch [37/50], Step [193/735], Loss: 0.1417\n",
      "Epoch [37/50], Step [194/735], Loss: 0.0267\n",
      "Epoch [37/50], Step [195/735], Loss: 0.0651\n",
      "Epoch [37/50], Step [196/735], Loss: 0.0348\n",
      "Epoch [37/50], Step [197/735], Loss: 0.0244\n",
      "Epoch [37/50], Step [198/735], Loss: 0.0494\n",
      "Epoch [37/50], Step [199/735], Loss: 0.0197\n",
      "Epoch [37/50], Step [200/735], Loss: 0.0535\n",
      "Epoch [37/50], Step [201/735], Loss: 0.0661\n",
      "Epoch [37/50], Step [202/735], Loss: 0.0623\n",
      "Epoch [37/50], Step [203/735], Loss: 0.0372\n",
      "Epoch [37/50], Step [204/735], Loss: 0.0516\n",
      "Epoch [37/50], Step [205/735], Loss: 0.0209\n",
      "Epoch [37/50], Step [206/735], Loss: 0.0723\n",
      "Epoch [37/50], Step [207/735], Loss: 0.1172\n",
      "Epoch [37/50], Step [208/735], Loss: 0.0672\n",
      "Epoch [37/50], Step [209/735], Loss: 0.0465\n",
      "Epoch [37/50], Step [210/735], Loss: 0.1725\n",
      "Epoch [37/50], Step [211/735], Loss: 0.1401\n",
      "Epoch [37/50], Step [212/735], Loss: 0.0836\n",
      "Epoch [37/50], Step [213/735], Loss: 0.0204\n",
      "Epoch [37/50], Step [214/735], Loss: 0.0328\n",
      "Epoch [37/50], Step [215/735], Loss: 0.0248\n",
      "Epoch [37/50], Step [216/735], Loss: 0.0428\n",
      "Epoch [37/50], Step [217/735], Loss: 0.1103\n",
      "Epoch [37/50], Step [218/735], Loss: 0.0544\n",
      "Epoch [37/50], Step [219/735], Loss: 0.0622\n",
      "Epoch [37/50], Step [220/735], Loss: 0.4814\n",
      "Epoch [37/50], Step [221/735], Loss: 0.1244\n",
      "Epoch [37/50], Step [222/735], Loss: 0.0306\n",
      "Epoch [37/50], Step [223/735], Loss: 0.0207\n",
      "Epoch [37/50], Step [224/735], Loss: 0.0581\n",
      "Epoch [37/50], Step [225/735], Loss: 0.0542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Step [226/735], Loss: 0.0265\n",
      "Epoch [37/50], Step [227/735], Loss: 0.2012\n",
      "Epoch [37/50], Step [228/735], Loss: 0.0412\n",
      "Epoch [37/50], Step [229/735], Loss: 0.0836\n",
      "Epoch [37/50], Step [230/735], Loss: 0.0136\n",
      "Epoch [37/50], Step [231/735], Loss: 0.0322\n",
      "Epoch [37/50], Step [232/735], Loss: 0.0763\n",
      "Epoch [37/50], Step [233/735], Loss: 0.0784\n",
      "Epoch [37/50], Step [234/735], Loss: 0.0631\n",
      "Epoch [37/50], Step [235/735], Loss: 0.0533\n",
      "Epoch [37/50], Step [236/735], Loss: 0.1032\n",
      "Epoch [37/50], Step [237/735], Loss: 0.0779\n",
      "Epoch [37/50], Step [238/735], Loss: 0.0217\n",
      "Epoch [37/50], Step [239/735], Loss: 0.0471\n",
      "Epoch [37/50], Step [240/735], Loss: 0.0132\n",
      "Epoch [37/50], Step [241/735], Loss: 0.0182\n",
      "Epoch [37/50], Step [242/735], Loss: 0.0676\n",
      "Epoch [37/50], Step [243/735], Loss: 0.0501\n",
      "Epoch [37/50], Step [244/735], Loss: 0.0391\n",
      "Epoch [37/50], Step [245/735], Loss: 0.0666\n",
      "Epoch [37/50], Step [246/735], Loss: 0.0659\n",
      "Epoch [37/50], Step [247/735], Loss: 0.0291\n",
      "Epoch [37/50], Step [248/735], Loss: 0.0323\n",
      "Epoch [37/50], Step [249/735], Loss: 0.0643\n",
      "Epoch [37/50], Step [250/735], Loss: 0.0558\n",
      "Epoch [37/50], Step [251/735], Loss: 0.0272\n",
      "Epoch [37/50], Step [252/735], Loss: 0.0163\n",
      "Epoch [37/50], Step [253/735], Loss: 0.0182\n",
      "Epoch [37/50], Step [254/735], Loss: 0.0477\n",
      "Epoch [37/50], Step [255/735], Loss: 0.0265\n",
      "Epoch [37/50], Step [256/735], Loss: 0.0467\n",
      "Epoch [37/50], Step [257/735], Loss: 0.0344\n",
      "Epoch [37/50], Step [258/735], Loss: 0.0712\n",
      "Epoch [37/50], Step [259/735], Loss: 0.0710\n",
      "Epoch [37/50], Step [260/735], Loss: 0.0763\n",
      "Epoch [37/50], Step [261/735], Loss: 0.0352\n",
      "Epoch [37/50], Step [262/735], Loss: 0.0273\n",
      "Epoch [37/50], Step [263/735], Loss: 0.1178\n",
      "Epoch [37/50], Step [264/735], Loss: 0.0331\n",
      "Epoch [37/50], Step [265/735], Loss: 0.0538\n",
      "Epoch [37/50], Step [266/735], Loss: 0.0669\n",
      "Epoch [37/50], Step [267/735], Loss: 0.0156\n",
      "Epoch [37/50], Step [268/735], Loss: 0.0303\n",
      "Epoch [37/50], Step [269/735], Loss: 0.0573\n",
      "Epoch [37/50], Step [270/735], Loss: 0.0671\n",
      "Epoch [37/50], Step [271/735], Loss: 0.0469\n",
      "Epoch [37/50], Step [272/735], Loss: 0.0215\n",
      "Epoch [37/50], Step [273/735], Loss: 0.0443\n",
      "Epoch [37/50], Step [274/735], Loss: 0.0410\n",
      "Epoch [37/50], Step [275/735], Loss: 0.0460\n",
      "Epoch [37/50], Step [276/735], Loss: 0.1927\n",
      "Epoch [37/50], Step [277/735], Loss: 0.0665\n",
      "Epoch [37/50], Step [278/735], Loss: 0.0557\n",
      "Epoch [37/50], Step [279/735], Loss: 0.1627\n",
      "Epoch [37/50], Step [280/735], Loss: 0.0334\n",
      "Epoch [37/50], Step [281/735], Loss: 0.0388\n",
      "Epoch [37/50], Step [282/735], Loss: 0.0353\n",
      "Epoch [37/50], Step [283/735], Loss: 0.0386\n",
      "Epoch [37/50], Step [284/735], Loss: 0.1126\n",
      "Epoch [37/50], Step [285/735], Loss: 0.1796\n",
      "Epoch [37/50], Step [286/735], Loss: 0.0887\n",
      "Epoch [37/50], Step [287/735], Loss: 0.2815\n",
      "Epoch [37/50], Step [288/735], Loss: 0.0406\n",
      "Epoch [37/50], Step [289/735], Loss: 0.0321\n",
      "Epoch [37/50], Step [290/735], Loss: 0.0382\n",
      "Epoch [37/50], Step [291/735], Loss: 0.0808\n",
      "Epoch [37/50], Step [292/735], Loss: 0.0482\n",
      "Epoch [37/50], Step [293/735], Loss: 0.1190\n",
      "Epoch [37/50], Step [294/735], Loss: 0.0710\n",
      "Epoch [37/50], Step [295/735], Loss: 0.0632\n",
      "Epoch [37/50], Step [296/735], Loss: 0.0382\n",
      "Epoch [37/50], Step [297/735], Loss: 0.2571\n",
      "Epoch [37/50], Step [298/735], Loss: 0.0478\n",
      "Epoch [37/50], Step [299/735], Loss: 0.0289\n",
      "Epoch [37/50], Step [300/735], Loss: 0.0253\n",
      "Epoch [37/50], Step [301/735], Loss: 0.0629\n",
      "Epoch [37/50], Step [302/735], Loss: 0.0715\n",
      "Epoch [37/50], Step [303/735], Loss: 0.0564\n",
      "Epoch [37/50], Step [304/735], Loss: 0.0280\n",
      "Epoch [37/50], Step [305/735], Loss: 0.1490\n",
      "Epoch [37/50], Step [306/735], Loss: 0.0412\n",
      "Epoch [37/50], Step [307/735], Loss: 0.0706\n",
      "Epoch [37/50], Step [308/735], Loss: 0.0718\n",
      "Epoch [37/50], Step [309/735], Loss: 0.0724\n",
      "Epoch [37/50], Step [310/735], Loss: 0.1102\n",
      "Epoch [37/50], Step [311/735], Loss: 0.0882\n",
      "Epoch [37/50], Step [312/735], Loss: 0.0244\n",
      "Epoch [37/50], Step [313/735], Loss: 0.0962\n",
      "Epoch [37/50], Step [314/735], Loss: 0.1513\n",
      "Epoch [37/50], Step [315/735], Loss: 0.0371\n",
      "Epoch [37/50], Step [316/735], Loss: 0.0427\n",
      "Epoch [37/50], Step [317/735], Loss: 0.0335\n",
      "Epoch [37/50], Step [318/735], Loss: 0.0315\n",
      "Epoch [37/50], Step [319/735], Loss: 0.0998\n",
      "Epoch [37/50], Step [320/735], Loss: 0.0216\n",
      "Epoch [37/50], Step [321/735], Loss: 0.0357\n",
      "Epoch [37/50], Step [322/735], Loss: 0.0278\n",
      "Epoch [37/50], Step [323/735], Loss: 0.0962\n",
      "Epoch [37/50], Step [324/735], Loss: 0.0458\n",
      "Epoch [37/50], Step [325/735], Loss: 0.0895\n",
      "Epoch [37/50], Step [326/735], Loss: 0.0466\n",
      "Epoch [37/50], Step [327/735], Loss: 0.0676\n",
      "Epoch [37/50], Step [328/735], Loss: 0.0669\n",
      "Epoch [37/50], Step [329/735], Loss: 0.0526\n",
      "Epoch [37/50], Step [330/735], Loss: 0.0617\n",
      "Epoch [37/50], Step [331/735], Loss: 0.0306\n",
      "Epoch [37/50], Step [332/735], Loss: 0.1509\n",
      "Epoch [37/50], Step [333/735], Loss: 0.0549\n",
      "Epoch [37/50], Step [334/735], Loss: 0.0591\n",
      "Epoch [37/50], Step [335/735], Loss: 0.0643\n",
      "Epoch [37/50], Step [336/735], Loss: 0.0552\n",
      "Epoch [37/50], Step [337/735], Loss: 0.0255\n",
      "Epoch [37/50], Step [338/735], Loss: 0.0232\n",
      "Epoch [37/50], Step [339/735], Loss: 0.0704\n",
      "Epoch [37/50], Step [340/735], Loss: 0.1484\n",
      "Epoch [37/50], Step [341/735], Loss: 0.0492\n",
      "Epoch [37/50], Step [342/735], Loss: 0.0672\n",
      "Epoch [37/50], Step [343/735], Loss: 0.0880\n",
      "Epoch [37/50], Step [344/735], Loss: 0.0603\n",
      "Epoch [37/50], Step [345/735], Loss: 0.0487\n",
      "Epoch [37/50], Step [346/735], Loss: 0.0270\n",
      "Epoch [37/50], Step [347/735], Loss: 0.0421\n",
      "Epoch [37/50], Step [348/735], Loss: 0.0363\n",
      "Epoch [37/50], Step [349/735], Loss: 0.4886\n",
      "Epoch [37/50], Step [350/735], Loss: 0.0625\n",
      "Epoch [37/50], Step [351/735], Loss: 0.0295\n",
      "Epoch [37/50], Step [352/735], Loss: 0.1139\n",
      "Epoch [37/50], Step [353/735], Loss: 0.0568\n",
      "Epoch [37/50], Step [354/735], Loss: 0.0733\n",
      "Epoch [37/50], Step [355/735], Loss: 0.0557\n",
      "Epoch [37/50], Step [356/735], Loss: 0.0786\n",
      "Epoch [37/50], Step [357/735], Loss: 0.0430\n",
      "Epoch [37/50], Step [358/735], Loss: 0.0403\n",
      "Epoch [37/50], Step [359/735], Loss: 0.0674\n",
      "Epoch [37/50], Step [360/735], Loss: 0.0875\n",
      "Epoch [37/50], Step [361/735], Loss: 0.2218\n",
      "Epoch [37/50], Step [362/735], Loss: 0.0746\n",
      "Epoch [37/50], Step [363/735], Loss: 0.0760\n",
      "Epoch [37/50], Step [364/735], Loss: 0.0483\n",
      "Epoch [37/50], Step [365/735], Loss: 0.0568\n",
      "Epoch [37/50], Step [366/735], Loss: 0.0392\n",
      "Epoch [37/50], Step [367/735], Loss: 0.0522\n",
      "Epoch [37/50], Step [368/735], Loss: 0.1987\n",
      "Epoch [37/50], Step [369/735], Loss: 0.1007\n",
      "Epoch [37/50], Step [370/735], Loss: 0.0545\n",
      "Epoch [37/50], Step [371/735], Loss: 0.2002\n",
      "Epoch [37/50], Step [372/735], Loss: 0.0439\n",
      "Epoch [37/50], Step [373/735], Loss: 0.0364\n",
      "Epoch [37/50], Step [374/735], Loss: 0.0279\n",
      "Epoch [37/50], Step [375/735], Loss: 0.0931\n",
      "Epoch [37/50], Step [376/735], Loss: 0.0854\n",
      "Epoch [37/50], Step [377/735], Loss: 0.0786\n",
      "Epoch [37/50], Step [378/735], Loss: 0.0380\n",
      "Epoch [37/50], Step [379/735], Loss: 0.1793\n",
      "Epoch [37/50], Step [380/735], Loss: 0.0696\n",
      "Epoch [37/50], Step [381/735], Loss: 0.0378\n",
      "Epoch [37/50], Step [382/735], Loss: 0.0777\n",
      "Epoch [37/50], Step [383/735], Loss: 0.0363\n",
      "Epoch [37/50], Step [384/735], Loss: 0.0808\n",
      "Epoch [37/50], Step [385/735], Loss: 0.0270\n",
      "Epoch [37/50], Step [386/735], Loss: 0.0630\n",
      "Epoch [37/50], Step [387/735], Loss: 0.0280\n",
      "Epoch [37/50], Step [388/735], Loss: 0.0516\n",
      "Epoch [37/50], Step [389/735], Loss: 0.1814\n",
      "Epoch [37/50], Step [390/735], Loss: 0.1490\n",
      "Epoch [37/50], Step [391/735], Loss: 0.0390\n",
      "Epoch [37/50], Step [392/735], Loss: 0.0505\n",
      "Epoch [37/50], Step [393/735], Loss: 0.1067\n",
      "Epoch [37/50], Step [394/735], Loss: 0.0546\n",
      "Epoch [37/50], Step [395/735], Loss: 0.0436\n",
      "Epoch [37/50], Step [396/735], Loss: 0.0235\n",
      "Epoch [37/50], Step [397/735], Loss: 0.0989\n",
      "Epoch [37/50], Step [398/735], Loss: 0.2262\n",
      "Epoch [37/50], Step [399/735], Loss: 0.3481\n",
      "Epoch [37/50], Step [400/735], Loss: 0.0501\n",
      "Epoch [37/50], Step [401/735], Loss: 0.1200\n",
      "Epoch [37/50], Step [402/735], Loss: 0.0356\n",
      "Epoch [37/50], Step [403/735], Loss: 0.0451\n",
      "Epoch [37/50], Step [404/735], Loss: 0.0334\n",
      "Epoch [37/50], Step [405/735], Loss: 0.0228\n",
      "Epoch [37/50], Step [406/735], Loss: 0.0549\n",
      "Epoch [37/50], Step [407/735], Loss: 0.0457\n",
      "Epoch [37/50], Step [408/735], Loss: 0.0880\n",
      "Epoch [37/50], Step [409/735], Loss: 0.0465\n",
      "Epoch [37/50], Step [410/735], Loss: 0.0418\n",
      "Epoch [37/50], Step [411/735], Loss: 0.0219\n",
      "Epoch [37/50], Step [412/735], Loss: 0.0913\n",
      "Epoch [37/50], Step [413/735], Loss: 0.3294\n",
      "Epoch [37/50], Step [414/735], Loss: 0.0535\n",
      "Epoch [37/50], Step [415/735], Loss: 0.1146\n",
      "Epoch [37/50], Step [416/735], Loss: 0.0664\n",
      "Epoch [37/50], Step [417/735], Loss: 0.0486\n",
      "Epoch [37/50], Step [418/735], Loss: 0.0569\n",
      "Epoch [37/50], Step [419/735], Loss: 0.0617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Step [420/735], Loss: 0.1284\n",
      "Epoch [37/50], Step [421/735], Loss: 0.0932\n",
      "Epoch [37/50], Step [422/735], Loss: 0.4805\n",
      "Epoch [37/50], Step [423/735], Loss: 0.0431\n",
      "Epoch [37/50], Step [424/735], Loss: 0.0575\n",
      "Epoch [37/50], Step [425/735], Loss: 0.0752\n",
      "Epoch [37/50], Step [426/735], Loss: 0.2213\n",
      "Epoch [37/50], Step [427/735], Loss: 0.0630\n",
      "Epoch [37/50], Step [428/735], Loss: 0.0734\n",
      "Epoch [37/50], Step [429/735], Loss: 0.1956\n",
      "Epoch [37/50], Step [430/735], Loss: 0.0258\n",
      "Epoch [37/50], Step [431/735], Loss: 0.0366\n",
      "Epoch [37/50], Step [432/735], Loss: 0.0384\n",
      "Epoch [37/50], Step [433/735], Loss: 0.2289\n",
      "Epoch [37/50], Step [434/735], Loss: 0.1432\n",
      "Epoch [37/50], Step [435/735], Loss: 0.0387\n",
      "Epoch [37/50], Step [436/735], Loss: 0.0516\n",
      "Epoch [37/50], Step [437/735], Loss: 0.0709\n",
      "Epoch [37/50], Step [438/735], Loss: 0.1820\n",
      "Epoch [37/50], Step [439/735], Loss: 0.0669\n",
      "Epoch [37/50], Step [440/735], Loss: 0.1750\n",
      "Epoch [37/50], Step [441/735], Loss: 0.0882\n",
      "Epoch [37/50], Step [442/735], Loss: 0.0699\n",
      "Epoch [37/50], Step [443/735], Loss: 0.0527\n",
      "Epoch [37/50], Step [444/735], Loss: 0.0305\n",
      "Epoch [37/50], Step [445/735], Loss: 0.0687\n",
      "Epoch [37/50], Step [446/735], Loss: 0.0873\n",
      "Epoch [37/50], Step [447/735], Loss: 0.1324\n",
      "Epoch [37/50], Step [448/735], Loss: 0.0494\n",
      "Epoch [37/50], Step [449/735], Loss: 0.0508\n",
      "Epoch [37/50], Step [450/735], Loss: 0.0846\n",
      "Epoch [37/50], Step [451/735], Loss: 0.0777\n",
      "Epoch [37/50], Step [452/735], Loss: 0.0418\n",
      "Epoch [37/50], Step [453/735], Loss: 0.0394\n",
      "Epoch [37/50], Step [454/735], Loss: 0.0360\n",
      "Epoch [37/50], Step [455/735], Loss: 0.0424\n",
      "Epoch [37/50], Step [456/735], Loss: 0.0513\n",
      "Epoch [37/50], Step [457/735], Loss: 0.0767\n",
      "Epoch [37/50], Step [458/735], Loss: 0.0556\n",
      "Epoch [37/50], Step [459/735], Loss: 0.0422\n",
      "Epoch [37/50], Step [460/735], Loss: 0.0244\n",
      "Epoch [37/50], Step [461/735], Loss: 0.0415\n",
      "Epoch [37/50], Step [462/735], Loss: 0.0298\n",
      "Epoch [37/50], Step [463/735], Loss: 0.2226\n",
      "Epoch [37/50], Step [464/735], Loss: 0.0447\n",
      "Epoch [37/50], Step [465/735], Loss: 0.0965\n",
      "Epoch [37/50], Step [466/735], Loss: 0.0676\n",
      "Epoch [37/50], Step [467/735], Loss: 0.0244\n",
      "Epoch [37/50], Step [468/735], Loss: 0.0214\n",
      "Epoch [37/50], Step [469/735], Loss: 0.0358\n",
      "Epoch [37/50], Step [470/735], Loss: 0.0643\n",
      "Epoch [37/50], Step [471/735], Loss: 0.0721\n",
      "Epoch [37/50], Step [472/735], Loss: 0.0460\n",
      "Epoch [37/50], Step [473/735], Loss: 0.0624\n",
      "Epoch [37/50], Step [474/735], Loss: 0.0791\n",
      "Epoch [37/50], Step [475/735], Loss: 0.0544\n",
      "Epoch [37/50], Step [476/735], Loss: 0.0838\n",
      "Epoch [37/50], Step [477/735], Loss: 0.0608\n",
      "Epoch [37/50], Step [478/735], Loss: 0.0420\n",
      "Epoch [37/50], Step [479/735], Loss: 0.2269\n",
      "Epoch [37/50], Step [480/735], Loss: 0.0589\n",
      "Epoch [37/50], Step [481/735], Loss: 0.0538\n",
      "Epoch [37/50], Step [482/735], Loss: 0.0624\n",
      "Epoch [37/50], Step [483/735], Loss: 0.2753\n",
      "Epoch [37/50], Step [484/735], Loss: 0.0356\n",
      "Epoch [37/50], Step [485/735], Loss: 0.0448\n",
      "Epoch [37/50], Step [486/735], Loss: 0.0960\n",
      "Epoch [37/50], Step [487/735], Loss: 0.1393\n",
      "Epoch [37/50], Step [488/735], Loss: 0.0379\n",
      "Epoch [37/50], Step [489/735], Loss: 0.0356\n",
      "Epoch [37/50], Step [490/735], Loss: 0.2176\n",
      "Epoch [37/50], Step [491/735], Loss: 0.0495\n",
      "Epoch [37/50], Step [492/735], Loss: 0.0470\n",
      "Epoch [37/50], Step [493/735], Loss: 0.0539\n",
      "Epoch [37/50], Step [494/735], Loss: 0.0328\n",
      "Epoch [37/50], Step [495/735], Loss: 0.0449\n",
      "Epoch [37/50], Step [496/735], Loss: 0.0306\n",
      "Epoch [37/50], Step [497/735], Loss: 0.0453\n",
      "Epoch [37/50], Step [498/735], Loss: 0.0152\n",
      "Epoch [37/50], Step [499/735], Loss: 0.0654\n",
      "Epoch [37/50], Step [500/735], Loss: 0.0509\n",
      "Epoch [37/50], Step [501/735], Loss: 0.0368\n",
      "Epoch [37/50], Step [502/735], Loss: 0.0560\n",
      "Epoch [37/50], Step [503/735], Loss: 0.0268\n",
      "Epoch [37/50], Step [504/735], Loss: 0.0936\n",
      "Epoch [37/50], Step [505/735], Loss: 0.0278\n",
      "Epoch [37/50], Step [506/735], Loss: 0.0569\n",
      "Epoch [37/50], Step [507/735], Loss: 0.0216\n",
      "Epoch [37/50], Step [508/735], Loss: 0.0371\n",
      "Epoch [37/50], Step [509/735], Loss: 0.0161\n",
      "Epoch [37/50], Step [510/735], Loss: 0.0180\n",
      "Epoch [37/50], Step [511/735], Loss: 0.0813\n",
      "Epoch [37/50], Step [512/735], Loss: 0.2494\n",
      "Epoch [37/50], Step [513/735], Loss: 0.0705\n",
      "Epoch [37/50], Step [514/735], Loss: 0.0254\n",
      "Epoch [37/50], Step [515/735], Loss: 0.0834\n",
      "Epoch [37/50], Step [516/735], Loss: 0.0477\n",
      "Epoch [37/50], Step [517/735], Loss: 0.0844\n",
      "Epoch [37/50], Step [518/735], Loss: 0.1163\n",
      "Epoch [37/50], Step [519/735], Loss: 0.0352\n",
      "Epoch [37/50], Step [520/735], Loss: 0.0636\n",
      "Epoch [37/50], Step [521/735], Loss: 0.0863\n",
      "Epoch [37/50], Step [522/735], Loss: 0.0234\n",
      "Epoch [37/50], Step [523/735], Loss: 0.0875\n",
      "Epoch [37/50], Step [524/735], Loss: 0.0360\n",
      "Epoch [37/50], Step [525/735], Loss: 0.1344\n",
      "Epoch [37/50], Step [526/735], Loss: 0.0629\n",
      "Epoch [37/50], Step [527/735], Loss: 0.0356\n",
      "Epoch [37/50], Step [528/735], Loss: 0.1383\n",
      "Epoch [37/50], Step [529/735], Loss: 0.0155\n",
      "Epoch [37/50], Step [530/735], Loss: 0.1069\n",
      "Epoch [37/50], Step [531/735], Loss: 0.0429\n",
      "Epoch [37/50], Step [532/735], Loss: 0.2301\n",
      "Epoch [37/50], Step [533/735], Loss: 0.1507\n",
      "Epoch [37/50], Step [534/735], Loss: 0.0245\n",
      "Epoch [37/50], Step [535/735], Loss: 0.1174\n",
      "Epoch [37/50], Step [536/735], Loss: 0.0363\n",
      "Epoch [37/50], Step [537/735], Loss: 0.0747\n",
      "Epoch [37/50], Step [538/735], Loss: 0.1603\n",
      "Epoch [37/50], Step [539/735], Loss: 0.0572\n",
      "Epoch [37/50], Step [540/735], Loss: 0.0601\n",
      "Epoch [37/50], Step [541/735], Loss: 0.0310\n",
      "Epoch [37/50], Step [542/735], Loss: 0.0364\n",
      "Epoch [37/50], Step [543/735], Loss: 0.0542\n",
      "Epoch [37/50], Step [544/735], Loss: 0.0430\n",
      "Epoch [37/50], Step [545/735], Loss: 0.0550\n",
      "Epoch [37/50], Step [546/735], Loss: 0.0618\n",
      "Epoch [37/50], Step [547/735], Loss: 0.0810\n",
      "Epoch [37/50], Step [548/735], Loss: 0.0720\n",
      "Epoch [37/50], Step [549/735], Loss: 0.1171\n",
      "Epoch [37/50], Step [550/735], Loss: 0.4799\n",
      "Epoch [37/50], Step [551/735], Loss: 0.1138\n",
      "Epoch [37/50], Step [552/735], Loss: 0.1113\n",
      "Epoch [37/50], Step [553/735], Loss: 0.0322\n",
      "Epoch [37/50], Step [554/735], Loss: 0.0967\n",
      "Epoch [37/50], Step [555/735], Loss: 0.0741\n",
      "Epoch [37/50], Step [556/735], Loss: 0.0780\n",
      "Epoch [37/50], Step [557/735], Loss: 0.0353\n",
      "Epoch [37/50], Step [558/735], Loss: 0.2228\n",
      "Epoch [37/50], Step [559/735], Loss: 0.0615\n",
      "Epoch [37/50], Step [560/735], Loss: 0.0653\n",
      "Epoch [37/50], Step [561/735], Loss: 0.0724\n",
      "Epoch [37/50], Step [562/735], Loss: 0.1533\n",
      "Epoch [37/50], Step [563/735], Loss: 0.0435\n",
      "Epoch [37/50], Step [564/735], Loss: 0.0834\n",
      "Epoch [37/50], Step [565/735], Loss: 0.0361\n",
      "Epoch [37/50], Step [566/735], Loss: 0.0871\n",
      "Epoch [37/50], Step [567/735], Loss: 0.0722\n",
      "Epoch [37/50], Step [568/735], Loss: 0.0278\n",
      "Epoch [37/50], Step [569/735], Loss: 0.0624\n",
      "Epoch [37/50], Step [570/735], Loss: 0.0475\n",
      "Epoch [37/50], Step [571/735], Loss: 0.0431\n",
      "Epoch [37/50], Step [572/735], Loss: 0.1511\n",
      "Epoch [37/50], Step [573/735], Loss: 0.0267\n",
      "Epoch [37/50], Step [574/735], Loss: 0.0263\n",
      "Epoch [37/50], Step [575/735], Loss: 0.0328\n",
      "Epoch [37/50], Step [576/735], Loss: 0.0587\n",
      "Epoch [37/50], Step [577/735], Loss: 0.0758\n",
      "Epoch [37/50], Step [578/735], Loss: 0.0493\n",
      "Epoch [37/50], Step [579/735], Loss: 0.0465\n",
      "Epoch [37/50], Step [580/735], Loss: 0.0763\n",
      "Epoch [37/50], Step [581/735], Loss: 0.0223\n",
      "Epoch [37/50], Step [582/735], Loss: 0.0862\n",
      "Epoch [37/50], Step [583/735], Loss: 0.1534\n",
      "Epoch [37/50], Step [584/735], Loss: 0.0462\n",
      "Epoch [37/50], Step [585/735], Loss: 0.0559\n",
      "Epoch [37/50], Step [586/735], Loss: 0.0194\n",
      "Epoch [37/50], Step [587/735], Loss: 0.0834\n",
      "Epoch [37/50], Step [588/735], Loss: 0.0526\n",
      "Epoch [37/50], Step [589/735], Loss: 0.2653\n",
      "Epoch [37/50], Step [590/735], Loss: 0.0939\n",
      "Epoch [37/50], Step [591/735], Loss: 0.0134\n",
      "Epoch [37/50], Step [592/735], Loss: 0.0414\n",
      "Epoch [37/50], Step [593/735], Loss: 0.0946\n",
      "Epoch [37/50], Step [594/735], Loss: 0.0483\n",
      "Epoch [37/50], Step [595/735], Loss: 0.1645\n",
      "Epoch [37/50], Step [596/735], Loss: 0.0350\n",
      "Epoch [37/50], Step [597/735], Loss: 0.0429\n",
      "Epoch [37/50], Step [598/735], Loss: 0.1883\n",
      "Epoch [37/50], Step [599/735], Loss: 0.0270\n",
      "Epoch [37/50], Step [600/735], Loss: 0.0878\n",
      "Epoch [37/50], Step [601/735], Loss: 0.0373\n",
      "Epoch [37/50], Step [602/735], Loss: 0.0660\n",
      "Epoch [37/50], Step [603/735], Loss: 0.0320\n",
      "Epoch [37/50], Step [604/735], Loss: 0.0605\n",
      "Epoch [37/50], Step [605/735], Loss: 0.0667\n",
      "Epoch [37/50], Step [606/735], Loss: 0.0516\n",
      "Epoch [37/50], Step [607/735], Loss: 0.0178\n",
      "Epoch [37/50], Step [608/735], Loss: 0.1068\n",
      "Epoch [37/50], Step [609/735], Loss: 0.0865\n",
      "Epoch [37/50], Step [610/735], Loss: 0.0402\n",
      "Epoch [37/50], Step [611/735], Loss: 0.0271\n",
      "Epoch [37/50], Step [612/735], Loss: 0.0864\n",
      "Epoch [37/50], Step [613/735], Loss: 0.0478\n",
      "Epoch [37/50], Step [614/735], Loss: 0.1158\n",
      "Epoch [37/50], Step [615/735], Loss: 0.0502\n",
      "Epoch [37/50], Step [616/735], Loss: 0.0493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Step [617/735], Loss: 0.0347\n",
      "Epoch [37/50], Step [618/735], Loss: 0.1036\n",
      "Epoch [37/50], Step [619/735], Loss: 0.0556\n",
      "Epoch [37/50], Step [620/735], Loss: 0.0534\n",
      "Epoch [37/50], Step [621/735], Loss: 0.0640\n",
      "Epoch [37/50], Step [622/735], Loss: 0.0241\n",
      "Epoch [37/50], Step [623/735], Loss: 0.0744\n",
      "Epoch [37/50], Step [624/735], Loss: 0.0428\n",
      "Epoch [37/50], Step [625/735], Loss: 0.1031\n",
      "Epoch [37/50], Step [626/735], Loss: 0.0633\n",
      "Epoch [37/50], Step [627/735], Loss: 0.1331\n",
      "Epoch [37/50], Step [628/735], Loss: 0.0232\n",
      "Epoch [37/50], Step [629/735], Loss: 0.0144\n",
      "Epoch [37/50], Step [630/735], Loss: 0.0487\n",
      "Epoch [37/50], Step [631/735], Loss: 0.0646\n",
      "Epoch [37/50], Step [632/735], Loss: 0.0407\n",
      "Epoch [37/50], Step [633/735], Loss: 0.0428\n",
      "Epoch [37/50], Step [634/735], Loss: 0.0379\n",
      "Epoch [37/50], Step [635/735], Loss: 0.1549\n",
      "Epoch [37/50], Step [636/735], Loss: 0.0859\n",
      "Epoch [37/50], Step [637/735], Loss: 0.0446\n",
      "Epoch [37/50], Step [638/735], Loss: 0.0645\n",
      "Epoch [37/50], Step [639/735], Loss: 0.0795\n",
      "Epoch [37/50], Step [640/735], Loss: 0.0425\n",
      "Epoch [37/50], Step [641/735], Loss: 0.0539\n",
      "Epoch [37/50], Step [642/735], Loss: 0.1327\n",
      "Epoch [37/50], Step [643/735], Loss: 0.1302\n",
      "Epoch [37/50], Step [644/735], Loss: 0.1906\n",
      "Epoch [37/50], Step [645/735], Loss: 0.1130\n",
      "Epoch [37/50], Step [646/735], Loss: 0.0408\n",
      "Epoch [37/50], Step [647/735], Loss: 0.0956\n",
      "Epoch [37/50], Step [648/735], Loss: 0.0413\n",
      "Epoch [37/50], Step [649/735], Loss: 0.0259\n",
      "Epoch [37/50], Step [650/735], Loss: 0.0555\n",
      "Epoch [37/50], Step [651/735], Loss: 0.0690\n",
      "Epoch [37/50], Step [652/735], Loss: 0.0221\n",
      "Epoch [37/50], Step [653/735], Loss: 0.0599\n",
      "Epoch [37/50], Step [654/735], Loss: 0.3231\n",
      "Epoch [37/50], Step [655/735], Loss: 0.0972\n",
      "Epoch [37/50], Step [656/735], Loss: 0.0713\n",
      "Epoch [37/50], Step [657/735], Loss: 0.0633\n",
      "Epoch [37/50], Step [658/735], Loss: 0.0725\n",
      "Epoch [37/50], Step [659/735], Loss: 0.0538\n",
      "Epoch [37/50], Step [660/735], Loss: 0.0518\n",
      "Epoch [37/50], Step [661/735], Loss: 0.0522\n",
      "Epoch [37/50], Step [662/735], Loss: 0.0432\n",
      "Epoch [37/50], Step [663/735], Loss: 0.0895\n",
      "Epoch [37/50], Step [664/735], Loss: 0.0717\n",
      "Epoch [37/50], Step [665/735], Loss: 0.0764\n",
      "Epoch [37/50], Step [666/735], Loss: 0.0527\n",
      "Epoch [37/50], Step [667/735], Loss: 0.0202\n",
      "Epoch [37/50], Step [668/735], Loss: 0.4579\n",
      "Epoch [37/50], Step [669/735], Loss: 0.0663\n",
      "Epoch [37/50], Step [670/735], Loss: 0.0524\n",
      "Epoch [37/50], Step [671/735], Loss: 0.3139\n",
      "Epoch [37/50], Step [672/735], Loss: 0.1023\n",
      "Epoch [37/50], Step [673/735], Loss: 0.1176\n",
      "Epoch [37/50], Step [674/735], Loss: 0.0577\n",
      "Epoch [37/50], Step [675/735], Loss: 0.0451\n",
      "Epoch [37/50], Step [676/735], Loss: 0.4339\n",
      "Epoch [37/50], Step [677/735], Loss: 0.1167\n",
      "Epoch [37/50], Step [678/735], Loss: 0.0688\n",
      "Epoch [37/50], Step [679/735], Loss: 0.0568\n",
      "Epoch [37/50], Step [680/735], Loss: 0.0403\n",
      "Epoch [37/50], Step [681/735], Loss: 0.0937\n",
      "Epoch [37/50], Step [682/735], Loss: 0.0945\n",
      "Epoch [37/50], Step [683/735], Loss: 0.0315\n",
      "Epoch [37/50], Step [684/735], Loss: 0.0879\n",
      "Epoch [37/50], Step [685/735], Loss: 0.0329\n",
      "Epoch [37/50], Step [686/735], Loss: 0.0653\n",
      "Epoch [37/50], Step [687/735], Loss: 0.0307\n",
      "Epoch [37/50], Step [688/735], Loss: 0.1374\n",
      "Epoch [37/50], Step [689/735], Loss: 0.1475\n",
      "Epoch [37/50], Step [690/735], Loss: 0.0407\n",
      "Epoch [37/50], Step [691/735], Loss: 0.0252\n",
      "Epoch [37/50], Step [692/735], Loss: 0.0437\n",
      "Epoch [37/50], Step [693/735], Loss: 0.0836\n",
      "Epoch [37/50], Step [694/735], Loss: 0.0371\n",
      "Epoch [37/50], Step [695/735], Loss: 0.0302\n",
      "Epoch [37/50], Step [696/735], Loss: 0.0438\n",
      "Epoch [37/50], Step [697/735], Loss: 0.0444\n",
      "Epoch [37/50], Step [698/735], Loss: 0.0377\n",
      "Epoch [37/50], Step [699/735], Loss: 0.0740\n",
      "Epoch [37/50], Step [700/735], Loss: 0.0811\n",
      "Epoch [37/50], Step [701/735], Loss: 0.0372\n",
      "Epoch [37/50], Step [702/735], Loss: 0.0535\n",
      "Epoch [37/50], Step [703/735], Loss: 0.0614\n",
      "Epoch [37/50], Step [704/735], Loss: 0.0469\n",
      "Epoch [37/50], Step [705/735], Loss: 0.0817\n",
      "Epoch [37/50], Step [706/735], Loss: 0.0299\n",
      "Epoch [37/50], Step [707/735], Loss: 0.0975\n",
      "Epoch [37/50], Step [708/735], Loss: 0.0699\n",
      "Epoch [37/50], Step [709/735], Loss: 0.0454\n",
      "Epoch [37/50], Step [710/735], Loss: 0.1076\n",
      "Epoch [37/50], Step [711/735], Loss: 0.0799\n",
      "Epoch [37/50], Step [712/735], Loss: 0.1617\n",
      "Epoch [37/50], Step [713/735], Loss: 0.0756\n",
      "Epoch [37/50], Step [714/735], Loss: 0.0588\n",
      "Epoch [37/50], Step [715/735], Loss: 0.0644\n",
      "Epoch [37/50], Step [716/735], Loss: 0.1096\n",
      "Epoch [37/50], Step [717/735], Loss: 0.0794\n",
      "Epoch [37/50], Step [718/735], Loss: 0.0242\n",
      "Epoch [37/50], Step [719/735], Loss: 0.0275\n",
      "Epoch [37/50], Step [720/735], Loss: 0.2105\n",
      "Epoch [37/50], Step [721/735], Loss: 0.1010\n",
      "Epoch [37/50], Step [722/735], Loss: 0.0206\n",
      "Epoch [37/50], Step [723/735], Loss: 0.0863\n",
      "Epoch [37/50], Step [724/735], Loss: 0.0620\n",
      "Epoch [37/50], Step [725/735], Loss: 0.0598\n",
      "Epoch [37/50], Step [726/735], Loss: 0.0384\n",
      "Epoch [37/50], Step [727/735], Loss: 0.2621\n",
      "Epoch [37/50], Step [728/735], Loss: 0.0356\n",
      "Epoch [37/50], Step [729/735], Loss: 0.0943\n",
      "Epoch [37/50], Step [730/735], Loss: 0.0271\n",
      "Epoch [37/50], Step [731/735], Loss: 0.0568\n",
      "Epoch [37/50], Step [732/735], Loss: 0.0275\n",
      "Epoch [37/50], Step [733/735], Loss: 0.0269\n",
      "Epoch [37/50], Step [734/735], Loss: 0.0676\n",
      "Epoch [37/50], Step [735/735], Loss: 0.0398\n",
      "Epoch [38/50], Step [1/735], Loss: 0.0386\n",
      "Epoch [38/50], Step [2/735], Loss: 0.0328\n",
      "Epoch [38/50], Step [3/735], Loss: 0.0253\n",
      "Epoch [38/50], Step [4/735], Loss: 0.1214\n",
      "Epoch [38/50], Step [5/735], Loss: 0.0155\n",
      "Epoch [38/50], Step [6/735], Loss: 0.1622\n",
      "Epoch [38/50], Step [7/735], Loss: 0.0612\n",
      "Epoch [38/50], Step [8/735], Loss: 0.0643\n",
      "Epoch [38/50], Step [9/735], Loss: 0.1934\n",
      "Epoch [38/50], Step [10/735], Loss: 0.0383\n",
      "Epoch [38/50], Step [11/735], Loss: 0.0410\n",
      "Epoch [38/50], Step [12/735], Loss: 0.0539\n",
      "Epoch [38/50], Step [13/735], Loss: 0.2270\n",
      "Epoch [38/50], Step [14/735], Loss: 0.0608\n",
      "Epoch [38/50], Step [15/735], Loss: 0.0889\n",
      "Epoch [38/50], Step [16/735], Loss: 0.0496\n",
      "Epoch [38/50], Step [17/735], Loss: 0.0442\n",
      "Epoch [38/50], Step [18/735], Loss: 0.0395\n",
      "Epoch [38/50], Step [19/735], Loss: 0.3250\n",
      "Epoch [38/50], Step [20/735], Loss: 0.0774\n",
      "Epoch [38/50], Step [21/735], Loss: 0.1651\n",
      "Epoch [38/50], Step [22/735], Loss: 0.0329\n",
      "Epoch [38/50], Step [23/735], Loss: 0.1617\n",
      "Epoch [38/50], Step [24/735], Loss: 0.0640\n",
      "Epoch [38/50], Step [25/735], Loss: 0.0467\n",
      "Epoch [38/50], Step [26/735], Loss: 0.0407\n",
      "Epoch [38/50], Step [27/735], Loss: 0.1142\n",
      "Epoch [38/50], Step [28/735], Loss: 0.0752\n",
      "Epoch [38/50], Step [29/735], Loss: 0.0497\n",
      "Epoch [38/50], Step [30/735], Loss: 0.0300\n",
      "Epoch [38/50], Step [31/735], Loss: 0.0389\n",
      "Epoch [38/50], Step [32/735], Loss: 0.0643\n",
      "Epoch [38/50], Step [33/735], Loss: 0.0546\n",
      "Epoch [38/50], Step [34/735], Loss: 0.0379\n",
      "Epoch [38/50], Step [35/735], Loss: 0.1548\n",
      "Epoch [38/50], Step [36/735], Loss: 0.0384\n",
      "Epoch [38/50], Step [37/735], Loss: 0.0644\n",
      "Epoch [38/50], Step [38/735], Loss: 0.0966\n",
      "Epoch [38/50], Step [39/735], Loss: 0.0474\n",
      "Epoch [38/50], Step [40/735], Loss: 0.0231\n",
      "Epoch [38/50], Step [41/735], Loss: 0.1146\n",
      "Epoch [38/50], Step [42/735], Loss: 0.0271\n",
      "Epoch [38/50], Step [43/735], Loss: 0.0470\n",
      "Epoch [38/50], Step [44/735], Loss: 0.0289\n",
      "Epoch [38/50], Step [45/735], Loss: 0.1363\n",
      "Epoch [38/50], Step [46/735], Loss: 0.0287\n",
      "Epoch [38/50], Step [47/735], Loss: 0.0323\n",
      "Epoch [38/50], Step [48/735], Loss: 0.0369\n",
      "Epoch [38/50], Step [49/735], Loss: 0.0619\n",
      "Epoch [38/50], Step [50/735], Loss: 0.0457\n",
      "Epoch [38/50], Step [51/735], Loss: 0.0312\n",
      "Epoch [38/50], Step [52/735], Loss: 0.0849\n",
      "Epoch [38/50], Step [53/735], Loss: 0.1018\n",
      "Epoch [38/50], Step [54/735], Loss: 0.0751\n",
      "Epoch [38/50], Step [55/735], Loss: 0.0387\n",
      "Epoch [38/50], Step [56/735], Loss: 0.0225\n",
      "Epoch [38/50], Step [57/735], Loss: 0.1279\n",
      "Epoch [38/50], Step [58/735], Loss: 0.0374\n",
      "Epoch [38/50], Step [59/735], Loss: 0.0531\n",
      "Epoch [38/50], Step [60/735], Loss: 0.0645\n",
      "Epoch [38/50], Step [61/735], Loss: 0.0561\n",
      "Epoch [38/50], Step [62/735], Loss: 0.0797\n",
      "Epoch [38/50], Step [63/735], Loss: 0.3563\n",
      "Epoch [38/50], Step [64/735], Loss: 0.0775\n",
      "Epoch [38/50], Step [65/735], Loss: 0.0297\n",
      "Epoch [38/50], Step [66/735], Loss: 0.0711\n",
      "Epoch [38/50], Step [67/735], Loss: 0.0344\n",
      "Epoch [38/50], Step [68/735], Loss: 0.0427\n",
      "Epoch [38/50], Step [69/735], Loss: 0.1057\n",
      "Epoch [38/50], Step [70/735], Loss: 0.0411\n",
      "Epoch [38/50], Step [71/735], Loss: 0.0368\n",
      "Epoch [38/50], Step [72/735], Loss: 0.0687\n",
      "Epoch [38/50], Step [73/735], Loss: 0.0590\n",
      "Epoch [38/50], Step [74/735], Loss: 0.0437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Step [75/735], Loss: 0.3176\n",
      "Epoch [38/50], Step [76/735], Loss: 0.0357\n",
      "Epoch [38/50], Step [77/735], Loss: 0.0461\n",
      "Epoch [38/50], Step [78/735], Loss: 0.0365\n",
      "Epoch [38/50], Step [79/735], Loss: 0.0528\n",
      "Epoch [38/50], Step [80/735], Loss: 0.0986\n",
      "Epoch [38/50], Step [81/735], Loss: 0.0287\n",
      "Epoch [38/50], Step [82/735], Loss: 0.0412\n",
      "Epoch [38/50], Step [83/735], Loss: 0.0713\n",
      "Epoch [38/50], Step [84/735], Loss: 0.0247\n",
      "Epoch [38/50], Step [85/735], Loss: 0.0389\n",
      "Epoch [38/50], Step [86/735], Loss: 0.0674\n",
      "Epoch [38/50], Step [87/735], Loss: 0.1105\n",
      "Epoch [38/50], Step [88/735], Loss: 0.0461\n",
      "Epoch [38/50], Step [89/735], Loss: 0.0495\n",
      "Epoch [38/50], Step [90/735], Loss: 0.0697\n",
      "Epoch [38/50], Step [91/735], Loss: 0.0978\n",
      "Epoch [38/50], Step [92/735], Loss: 0.0739\n",
      "Epoch [38/50], Step [93/735], Loss: 0.0280\n",
      "Epoch [38/50], Step [94/735], Loss: 0.0374\n",
      "Epoch [38/50], Step [95/735], Loss: 0.0263\n",
      "Epoch [38/50], Step [96/735], Loss: 0.0558\n",
      "Epoch [38/50], Step [97/735], Loss: 0.0310\n",
      "Epoch [38/50], Step [98/735], Loss: 0.0311\n",
      "Epoch [38/50], Step [99/735], Loss: 0.0197\n",
      "Epoch [38/50], Step [100/735], Loss: 0.1361\n",
      "Epoch [38/50], Step [101/735], Loss: 0.0645\n",
      "Epoch [38/50], Step [102/735], Loss: 0.0755\n",
      "Epoch [38/50], Step [103/735], Loss: 0.0647\n",
      "Epoch [38/50], Step [104/735], Loss: 0.0130\n",
      "Epoch [38/50], Step [105/735], Loss: 0.0334\n",
      "Epoch [38/50], Step [106/735], Loss: 0.0414\n",
      "Epoch [38/50], Step [107/735], Loss: 0.0378\n",
      "Epoch [38/50], Step [108/735], Loss: 0.0520\n",
      "Epoch [38/50], Step [109/735], Loss: 0.0614\n",
      "Epoch [38/50], Step [110/735], Loss: 0.0526\n",
      "Epoch [38/50], Step [111/735], Loss: 0.1600\n",
      "Epoch [38/50], Step [112/735], Loss: 0.1193\n",
      "Epoch [38/50], Step [113/735], Loss: 0.0560\n",
      "Epoch [38/50], Step [114/735], Loss: 0.1206\n",
      "Epoch [38/50], Step [115/735], Loss: 0.0454\n",
      "Epoch [38/50], Step [116/735], Loss: 0.0701\n",
      "Epoch [38/50], Step [117/735], Loss: 0.0341\n",
      "Epoch [38/50], Step [118/735], Loss: 0.0597\n",
      "Epoch [38/50], Step [119/735], Loss: 0.0549\n",
      "Epoch [38/50], Step [120/735], Loss: 0.0557\n",
      "Epoch [38/50], Step [121/735], Loss: 0.0894\n",
      "Epoch [38/50], Step [122/735], Loss: 0.0406\n",
      "Epoch [38/50], Step [123/735], Loss: 0.0419\n",
      "Epoch [38/50], Step [124/735], Loss: 0.0515\n",
      "Epoch [38/50], Step [125/735], Loss: 0.0919\n",
      "Epoch [38/50], Step [126/735], Loss: 0.0536\n",
      "Epoch [38/50], Step [127/735], Loss: 0.0407\n",
      "Epoch [38/50], Step [128/735], Loss: 0.0594\n",
      "Epoch [38/50], Step [129/735], Loss: 0.0650\n",
      "Epoch [38/50], Step [130/735], Loss: 0.0499\n",
      "Epoch [38/50], Step [131/735], Loss: 0.0178\n",
      "Epoch [38/50], Step [132/735], Loss: 0.0689\n",
      "Epoch [38/50], Step [133/735], Loss: 0.0716\n",
      "Epoch [38/50], Step [134/735], Loss: 0.0400\n",
      "Epoch [38/50], Step [135/735], Loss: 0.0247\n",
      "Epoch [38/50], Step [136/735], Loss: 0.0861\n",
      "Epoch [38/50], Step [137/735], Loss: 0.0384\n",
      "Epoch [38/50], Step [138/735], Loss: 0.0273\n",
      "Epoch [38/50], Step [139/735], Loss: 0.0198\n",
      "Epoch [38/50], Step [140/735], Loss: 0.0534\n",
      "Epoch [38/50], Step [141/735], Loss: 0.0462\n",
      "Epoch [38/50], Step [142/735], Loss: 0.0292\n",
      "Epoch [38/50], Step [143/735], Loss: 0.0176\n",
      "Epoch [38/50], Step [144/735], Loss: 0.0561\n",
      "Epoch [38/50], Step [145/735], Loss: 0.0501\n",
      "Epoch [38/50], Step [146/735], Loss: 0.1124\n",
      "Epoch [38/50], Step [147/735], Loss: 0.1098\n",
      "Epoch [38/50], Step [148/735], Loss: 0.0167\n",
      "Epoch [38/50], Step [149/735], Loss: 0.0724\n",
      "Epoch [38/50], Step [150/735], Loss: 0.0349\n",
      "Epoch [38/50], Step [151/735], Loss: 0.0519\n",
      "Epoch [38/50], Step [152/735], Loss: 0.0121\n",
      "Epoch [38/50], Step [153/735], Loss: 0.0864\n",
      "Epoch [38/50], Step [154/735], Loss: 0.0764\n",
      "Epoch [38/50], Step [155/735], Loss: 0.0165\n",
      "Epoch [38/50], Step [156/735], Loss: 0.0789\n",
      "Epoch [38/50], Step [157/735], Loss: 0.0192\n",
      "Epoch [38/50], Step [158/735], Loss: 0.0483\n",
      "Epoch [38/50], Step [159/735], Loss: 0.1124\n",
      "Epoch [38/50], Step [160/735], Loss: 0.1256\n",
      "Epoch [38/50], Step [161/735], Loss: 0.0180\n",
      "Epoch [38/50], Step [162/735], Loss: 0.0405\n",
      "Epoch [38/50], Step [163/735], Loss: 0.0390\n",
      "Epoch [38/50], Step [164/735], Loss: 0.0382\n",
      "Epoch [38/50], Step [165/735], Loss: 0.0431\n",
      "Epoch [38/50], Step [166/735], Loss: 0.0577\n",
      "Epoch [38/50], Step [167/735], Loss: 0.0452\n",
      "Epoch [38/50], Step [168/735], Loss: 0.1628\n",
      "Epoch [38/50], Step [169/735], Loss: 0.0447\n",
      "Epoch [38/50], Step [170/735], Loss: 0.0818\n",
      "Epoch [38/50], Step [171/735], Loss: 0.0842\n",
      "Epoch [38/50], Step [172/735], Loss: 0.0338\n",
      "Epoch [38/50], Step [173/735], Loss: 0.1158\n",
      "Epoch [38/50], Step [174/735], Loss: 0.0505\n",
      "Epoch [38/50], Step [175/735], Loss: 0.0490\n",
      "Epoch [38/50], Step [176/735], Loss: 0.0478\n",
      "Epoch [38/50], Step [177/735], Loss: 0.0601\n",
      "Epoch [38/50], Step [178/735], Loss: 0.0756\n",
      "Epoch [38/50], Step [179/735], Loss: 0.0672\n",
      "Epoch [38/50], Step [180/735], Loss: 0.0332\n",
      "Epoch [38/50], Step [181/735], Loss: 0.0479\n",
      "Epoch [38/50], Step [182/735], Loss: 0.0429\n",
      "Epoch [38/50], Step [183/735], Loss: 0.0961\n",
      "Epoch [38/50], Step [184/735], Loss: 0.2923\n",
      "Epoch [38/50], Step [185/735], Loss: 0.0982\n",
      "Epoch [38/50], Step [186/735], Loss: 0.1750\n",
      "Epoch [38/50], Step [187/735], Loss: 0.1703\n",
      "Epoch [38/50], Step [188/735], Loss: 0.0442\n",
      "Epoch [38/50], Step [189/735], Loss: 0.0455\n",
      "Epoch [38/50], Step [190/735], Loss: 0.0473\n",
      "Epoch [38/50], Step [191/735], Loss: 0.1039\n",
      "Epoch [38/50], Step [192/735], Loss: 0.0899\n",
      "Epoch [38/50], Step [193/735], Loss: 0.0282\n",
      "Epoch [38/50], Step [194/735], Loss: 0.0820\n",
      "Epoch [38/50], Step [195/735], Loss: 0.0731\n",
      "Epoch [38/50], Step [196/735], Loss: 0.1180\n",
      "Epoch [38/50], Step [197/735], Loss: 0.0901\n",
      "Epoch [38/50], Step [198/735], Loss: 0.0593\n",
      "Epoch [38/50], Step [199/735], Loss: 0.0768\n",
      "Epoch [38/50], Step [200/735], Loss: 0.0407\n",
      "Epoch [38/50], Step [201/735], Loss: 0.0249\n",
      "Epoch [38/50], Step [202/735], Loss: 0.1136\n",
      "Epoch [38/50], Step [203/735], Loss: 0.0710\n",
      "Epoch [38/50], Step [204/735], Loss: 0.0308\n",
      "Epoch [38/50], Step [205/735], Loss: 0.0478\n",
      "Epoch [38/50], Step [206/735], Loss: 0.0861\n",
      "Epoch [38/50], Step [207/735], Loss: 0.0427\n",
      "Epoch [38/50], Step [208/735], Loss: 0.0507\n",
      "Epoch [38/50], Step [209/735], Loss: 0.0528\n",
      "Epoch [38/50], Step [210/735], Loss: 0.0412\n",
      "Epoch [38/50], Step [211/735], Loss: 0.0312\n",
      "Epoch [38/50], Step [212/735], Loss: 0.0333\n",
      "Epoch [38/50], Step [213/735], Loss: 0.0292\n",
      "Epoch [38/50], Step [214/735], Loss: 0.0425\n",
      "Epoch [38/50], Step [215/735], Loss: 0.0273\n",
      "Epoch [38/50], Step [216/735], Loss: 0.0159\n",
      "Epoch [38/50], Step [217/735], Loss: 0.1078\n",
      "Epoch [38/50], Step [218/735], Loss: 0.0429\n",
      "Epoch [38/50], Step [219/735], Loss: 0.0580\n",
      "Epoch [38/50], Step [220/735], Loss: 0.0731\n",
      "Epoch [38/50], Step [221/735], Loss: 0.0582\n",
      "Epoch [38/50], Step [222/735], Loss: 0.0422\n",
      "Epoch [38/50], Step [223/735], Loss: 0.0423\n",
      "Epoch [38/50], Step [224/735], Loss: 0.0489\n",
      "Epoch [38/50], Step [225/735], Loss: 0.0316\n",
      "Epoch [38/50], Step [226/735], Loss: 0.1154\n",
      "Epoch [38/50], Step [227/735], Loss: 0.0313\n",
      "Epoch [38/50], Step [228/735], Loss: 0.0685\n",
      "Epoch [38/50], Step [229/735], Loss: 0.0305\n",
      "Epoch [38/50], Step [230/735], Loss: 0.0303\n",
      "Epoch [38/50], Step [231/735], Loss: 0.0400\n",
      "Epoch [38/50], Step [232/735], Loss: 0.1136\n",
      "Epoch [38/50], Step [233/735], Loss: 0.0384\n",
      "Epoch [38/50], Step [234/735], Loss: 0.2245\n",
      "Epoch [38/50], Step [235/735], Loss: 0.0194\n",
      "Epoch [38/50], Step [236/735], Loss: 0.0491\n",
      "Epoch [38/50], Step [237/735], Loss: 0.0395\n",
      "Epoch [38/50], Step [238/735], Loss: 0.1200\n",
      "Epoch [38/50], Step [239/735], Loss: 0.0721\n",
      "Epoch [38/50], Step [240/735], Loss: 0.0778\n",
      "Epoch [38/50], Step [241/735], Loss: 0.0348\n",
      "Epoch [38/50], Step [242/735], Loss: 0.0288\n",
      "Epoch [38/50], Step [243/735], Loss: 0.0739\n",
      "Epoch [38/50], Step [244/735], Loss: 0.0481\n",
      "Epoch [38/50], Step [245/735], Loss: 0.0735\n",
      "Epoch [38/50], Step [246/735], Loss: 0.1292\n",
      "Epoch [38/50], Step [247/735], Loss: 0.0364\n",
      "Epoch [38/50], Step [248/735], Loss: 0.0725\n",
      "Epoch [38/50], Step [249/735], Loss: 0.0725\n",
      "Epoch [38/50], Step [250/735], Loss: 0.0932\n",
      "Epoch [38/50], Step [251/735], Loss: 0.0744\n",
      "Epoch [38/50], Step [252/735], Loss: 0.1423\n",
      "Epoch [38/50], Step [253/735], Loss: 0.1037\n",
      "Epoch [38/50], Step [254/735], Loss: 0.0351\n",
      "Epoch [38/50], Step [255/735], Loss: 0.1862\n",
      "Epoch [38/50], Step [256/735], Loss: 0.0993\n",
      "Epoch [38/50], Step [257/735], Loss: 0.1307\n",
      "Epoch [38/50], Step [258/735], Loss: 0.0729\n",
      "Epoch [38/50], Step [259/735], Loss: 0.0276\n",
      "Epoch [38/50], Step [260/735], Loss: 0.0661\n",
      "Epoch [38/50], Step [261/735], Loss: 0.1894\n",
      "Epoch [38/50], Step [262/735], Loss: 0.0565\n",
      "Epoch [38/50], Step [263/735], Loss: 0.0754\n",
      "Epoch [38/50], Step [264/735], Loss: 0.0357\n",
      "Epoch [38/50], Step [265/735], Loss: 0.0223\n",
      "Epoch [38/50], Step [266/735], Loss: 0.0492\n",
      "Epoch [38/50], Step [267/735], Loss: 0.0361\n",
      "Epoch [38/50], Step [268/735], Loss: 0.0487\n",
      "Epoch [38/50], Step [269/735], Loss: 0.0332\n",
      "Epoch [38/50], Step [270/735], Loss: 0.0780\n",
      "Epoch [38/50], Step [271/735], Loss: 0.1587\n",
      "Epoch [38/50], Step [272/735], Loss: 0.1029\n",
      "Epoch [38/50], Step [273/735], Loss: 0.3436\n",
      "Epoch [38/50], Step [274/735], Loss: 0.5554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Step [275/735], Loss: 0.1122\n",
      "Epoch [38/50], Step [276/735], Loss: 0.0398\n",
      "Epoch [38/50], Step [277/735], Loss: 0.0578\n",
      "Epoch [38/50], Step [278/735], Loss: 0.0616\n",
      "Epoch [38/50], Step [279/735], Loss: 0.0235\n",
      "Epoch [38/50], Step [280/735], Loss: 0.0353\n",
      "Epoch [38/50], Step [281/735], Loss: 0.0446\n",
      "Epoch [38/50], Step [282/735], Loss: 0.0469\n",
      "Epoch [38/50], Step [283/735], Loss: 0.0469\n",
      "Epoch [38/50], Step [284/735], Loss: 0.0132\n",
      "Epoch [38/50], Step [285/735], Loss: 0.0569\n",
      "Epoch [38/50], Step [286/735], Loss: 0.0524\n",
      "Epoch [38/50], Step [287/735], Loss: 0.0546\n",
      "Epoch [38/50], Step [288/735], Loss: 0.0108\n",
      "Epoch [38/50], Step [289/735], Loss: 0.0347\n",
      "Epoch [38/50], Step [290/735], Loss: 0.0444\n",
      "Epoch [38/50], Step [291/735], Loss: 0.0135\n",
      "Epoch [38/50], Step [292/735], Loss: 0.0251\n",
      "Epoch [38/50], Step [293/735], Loss: 0.0501\n",
      "Epoch [38/50], Step [294/735], Loss: 0.0949\n",
      "Epoch [38/50], Step [295/735], Loss: 0.0319\n",
      "Epoch [38/50], Step [296/735], Loss: 0.2032\n",
      "Epoch [38/50], Step [297/735], Loss: 0.0892\n",
      "Epoch [38/50], Step [298/735], Loss: 0.0224\n",
      "Epoch [38/50], Step [299/735], Loss: 0.2046\n",
      "Epoch [38/50], Step [300/735], Loss: 0.0748\n",
      "Epoch [38/50], Step [301/735], Loss: 0.1228\n",
      "Epoch [38/50], Step [302/735], Loss: 0.0725\n",
      "Epoch [38/50], Step [303/735], Loss: 0.0410\n",
      "Epoch [38/50], Step [304/735], Loss: 0.1020\n",
      "Epoch [38/50], Step [305/735], Loss: 0.1032\n",
      "Epoch [38/50], Step [306/735], Loss: 0.0769\n",
      "Epoch [38/50], Step [307/735], Loss: 0.0315\n",
      "Epoch [38/50], Step [308/735], Loss: 0.0277\n",
      "Epoch [38/50], Step [309/735], Loss: 0.0665\n",
      "Epoch [38/50], Step [310/735], Loss: 0.0521\n",
      "Epoch [38/50], Step [311/735], Loss: 0.0702\n",
      "Epoch [38/50], Step [312/735], Loss: 0.0705\n",
      "Epoch [38/50], Step [313/735], Loss: 0.0650\n",
      "Epoch [38/50], Step [314/735], Loss: 0.0434\n",
      "Epoch [38/50], Step [315/735], Loss: 0.0388\n",
      "Epoch [38/50], Step [316/735], Loss: 0.0649\n",
      "Epoch [38/50], Step [317/735], Loss: 0.0254\n",
      "Epoch [38/50], Step [318/735], Loss: 0.0425\n",
      "Epoch [38/50], Step [319/735], Loss: 0.0246\n",
      "Epoch [38/50], Step [320/735], Loss: 0.0389\n",
      "Epoch [38/50], Step [321/735], Loss: 0.2206\n",
      "Epoch [38/50], Step [322/735], Loss: 0.0344\n",
      "Epoch [38/50], Step [323/735], Loss: 0.0309\n",
      "Epoch [38/50], Step [324/735], Loss: 0.0398\n",
      "Epoch [38/50], Step [325/735], Loss: 0.0291\n",
      "Epoch [38/50], Step [326/735], Loss: 0.0562\n",
      "Epoch [38/50], Step [327/735], Loss: 0.0260\n",
      "Epoch [38/50], Step [328/735], Loss: 0.0530\n",
      "Epoch [38/50], Step [329/735], Loss: 0.0329\n",
      "Epoch [38/50], Step [330/735], Loss: 0.0419\n",
      "Epoch [38/50], Step [331/735], Loss: 0.0815\n",
      "Epoch [38/50], Step [332/735], Loss: 0.0947\n",
      "Epoch [38/50], Step [333/735], Loss: 0.0658\n",
      "Epoch [38/50], Step [334/735], Loss: 0.0308\n",
      "Epoch [38/50], Step [335/735], Loss: 0.0305\n",
      "Epoch [38/50], Step [336/735], Loss: 0.0566\n",
      "Epoch [38/50], Step [337/735], Loss: 0.0380\n",
      "Epoch [38/50], Step [338/735], Loss: 0.0225\n",
      "Epoch [38/50], Step [339/735], Loss: 0.0414\n",
      "Epoch [38/50], Step [340/735], Loss: 0.0693\n",
      "Epoch [38/50], Step [341/735], Loss: 0.1301\n",
      "Epoch [38/50], Step [342/735], Loss: 0.0320\n",
      "Epoch [38/50], Step [343/735], Loss: 0.0672\n",
      "Epoch [38/50], Step [344/735], Loss: 0.3549\n",
      "Epoch [38/50], Step [345/735], Loss: 0.0208\n",
      "Epoch [38/50], Step [346/735], Loss: 0.0483\n",
      "Epoch [38/50], Step [347/735], Loss: 0.0281\n",
      "Epoch [38/50], Step [348/735], Loss: 0.0343\n",
      "Epoch [38/50], Step [349/735], Loss: 0.0234\n",
      "Epoch [38/50], Step [350/735], Loss: 0.0226\n",
      "Epoch [38/50], Step [351/735], Loss: 0.0259\n",
      "Epoch [38/50], Step [352/735], Loss: 0.1705\n",
      "Epoch [38/50], Step [353/735], Loss: 0.0218\n",
      "Epoch [38/50], Step [354/735], Loss: 0.1211\n",
      "Epoch [38/50], Step [355/735], Loss: 0.0351\n",
      "Epoch [38/50], Step [356/735], Loss: 0.0416\n",
      "Epoch [38/50], Step [357/735], Loss: 0.0145\n",
      "Epoch [38/50], Step [358/735], Loss: 0.0258\n",
      "Epoch [38/50], Step [359/735], Loss: 0.0844\n",
      "Epoch [38/50], Step [360/735], Loss: 0.0496\n",
      "Epoch [38/50], Step [361/735], Loss: 0.0378\n",
      "Epoch [38/50], Step [362/735], Loss: 0.0389\n",
      "Epoch [38/50], Step [363/735], Loss: 0.0246\n",
      "Epoch [38/50], Step [364/735], Loss: 0.0541\n",
      "Epoch [38/50], Step [365/735], Loss: 0.1398\n",
      "Epoch [38/50], Step [366/735], Loss: 0.0389\n",
      "Epoch [38/50], Step [367/735], Loss: 0.1387\n",
      "Epoch [38/50], Step [368/735], Loss: 0.1610\n",
      "Epoch [38/50], Step [369/735], Loss: 0.2159\n",
      "Epoch [38/50], Step [370/735], Loss: 0.0246\n",
      "Epoch [38/50], Step [371/735], Loss: 0.0365\n",
      "Epoch [38/50], Step [372/735], Loss: 0.0462\n",
      "Epoch [38/50], Step [373/735], Loss: 0.1430\n",
      "Epoch [38/50], Step [374/735], Loss: 0.0699\n",
      "Epoch [38/50], Step [375/735], Loss: 0.0181\n",
      "Epoch [38/50], Step [376/735], Loss: 0.1667\n",
      "Epoch [38/50], Step [377/735], Loss: 0.0370\n",
      "Epoch [38/50], Step [378/735], Loss: 0.0466\n",
      "Epoch [38/50], Step [379/735], Loss: 0.0298\n",
      "Epoch [38/50], Step [380/735], Loss: 0.0489\n",
      "Epoch [38/50], Step [381/735], Loss: 0.0604\n",
      "Epoch [38/50], Step [382/735], Loss: 0.0296\n",
      "Epoch [38/50], Step [383/735], Loss: 0.0769\n",
      "Epoch [38/50], Step [384/735], Loss: 0.0328\n",
      "Epoch [38/50], Step [385/735], Loss: 0.1093\n",
      "Epoch [38/50], Step [386/735], Loss: 0.2598\n",
      "Epoch [38/50], Step [387/735], Loss: 0.0387\n",
      "Epoch [38/50], Step [388/735], Loss: 0.0366\n",
      "Epoch [38/50], Step [389/735], Loss: 0.0989\n",
      "Epoch [38/50], Step [390/735], Loss: 0.0638\n",
      "Epoch [38/50], Step [391/735], Loss: 0.0563\n",
      "Epoch [38/50], Step [392/735], Loss: 0.0229\n",
      "Epoch [38/50], Step [393/735], Loss: 0.0327\n",
      "Epoch [38/50], Step [394/735], Loss: 0.0230\n",
      "Epoch [38/50], Step [395/735], Loss: 0.1191\n",
      "Epoch [38/50], Step [396/735], Loss: 0.0414\n",
      "Epoch [38/50], Step [397/735], Loss: 0.0220\n",
      "Epoch [38/50], Step [398/735], Loss: 0.0736\n",
      "Epoch [38/50], Step [399/735], Loss: 0.0341\n",
      "Epoch [38/50], Step [400/735], Loss: 0.0461\n",
      "Epoch [38/50], Step [401/735], Loss: 0.1827\n",
      "Epoch [38/50], Step [402/735], Loss: 0.1047\n",
      "Epoch [38/50], Step [403/735], Loss: 0.0442\n",
      "Epoch [38/50], Step [404/735], Loss: 0.0598\n",
      "Epoch [38/50], Step [405/735], Loss: 0.0531\n",
      "Epoch [38/50], Step [406/735], Loss: 0.1254\n",
      "Epoch [38/50], Step [407/735], Loss: 0.0771\n",
      "Epoch [38/50], Step [408/735], Loss: 0.0482\n",
      "Epoch [38/50], Step [409/735], Loss: 0.0618\n",
      "Epoch [38/50], Step [410/735], Loss: 0.0565\n",
      "Epoch [38/50], Step [411/735], Loss: 0.0586\n",
      "Epoch [38/50], Step [412/735], Loss: 0.0305\n",
      "Epoch [38/50], Step [413/735], Loss: 0.0407\n",
      "Epoch [38/50], Step [414/735], Loss: 0.0336\n",
      "Epoch [38/50], Step [415/735], Loss: 0.1119\n",
      "Epoch [38/50], Step [416/735], Loss: 0.0602\n",
      "Epoch [38/50], Step [417/735], Loss: 0.0308\n",
      "Epoch [38/50], Step [418/735], Loss: 0.0817\n",
      "Epoch [38/50], Step [419/735], Loss: 0.0318\n",
      "Epoch [38/50], Step [420/735], Loss: 0.0193\n",
      "Epoch [38/50], Step [421/735], Loss: 0.1089\n",
      "Epoch [38/50], Step [422/735], Loss: 0.0744\n",
      "Epoch [38/50], Step [423/735], Loss: 0.0451\n",
      "Epoch [38/50], Step [424/735], Loss: 0.0993\n",
      "Epoch [38/50], Step [425/735], Loss: 0.0434\n",
      "Epoch [38/50], Step [426/735], Loss: 0.1008\n",
      "Epoch [38/50], Step [427/735], Loss: 0.0695\n",
      "Epoch [38/50], Step [428/735], Loss: 0.0393\n",
      "Epoch [38/50], Step [429/735], Loss: 0.0090\n",
      "Epoch [38/50], Step [430/735], Loss: 0.1013\n",
      "Epoch [38/50], Step [431/735], Loss: 0.0472\n",
      "Epoch [38/50], Step [432/735], Loss: 0.0392\n",
      "Epoch [38/50], Step [433/735], Loss: 0.0592\n",
      "Epoch [38/50], Step [434/735], Loss: 0.1076\n",
      "Epoch [38/50], Step [435/735], Loss: 0.0987\n",
      "Epoch [38/50], Step [436/735], Loss: 0.0494\n",
      "Epoch [38/50], Step [437/735], Loss: 0.0736\n",
      "Epoch [38/50], Step [438/735], Loss: 0.1649\n",
      "Epoch [38/50], Step [439/735], Loss: 0.0592\n",
      "Epoch [38/50], Step [440/735], Loss: 0.0500\n",
      "Epoch [38/50], Step [441/735], Loss: 0.0367\n",
      "Epoch [38/50], Step [442/735], Loss: 0.0748\n",
      "Epoch [38/50], Step [443/735], Loss: 0.1785\n",
      "Epoch [38/50], Step [444/735], Loss: 0.3824\n",
      "Epoch [38/50], Step [445/735], Loss: 0.0308\n",
      "Epoch [38/50], Step [446/735], Loss: 0.0952\n",
      "Epoch [38/50], Step [447/735], Loss: 0.1085\n",
      "Epoch [38/50], Step [448/735], Loss: 0.0590\n",
      "Epoch [38/50], Step [449/735], Loss: 0.1229\n",
      "Epoch [38/50], Step [450/735], Loss: 0.0274\n",
      "Epoch [38/50], Step [451/735], Loss: 0.0934\n",
      "Epoch [38/50], Step [452/735], Loss: 0.1712\n",
      "Epoch [38/50], Step [453/735], Loss: 0.0498\n",
      "Epoch [38/50], Step [454/735], Loss: 0.1446\n",
      "Epoch [38/50], Step [455/735], Loss: 0.0524\n",
      "Epoch [38/50], Step [456/735], Loss: 0.2071\n",
      "Epoch [38/50], Step [457/735], Loss: 0.1046\n",
      "Epoch [38/50], Step [458/735], Loss: 0.0511\n",
      "Epoch [38/50], Step [459/735], Loss: 0.0306\n",
      "Epoch [38/50], Step [460/735], Loss: 0.1402\n",
      "Epoch [38/50], Step [461/735], Loss: 0.0588\n",
      "Epoch [38/50], Step [462/735], Loss: 0.0343\n",
      "Epoch [38/50], Step [463/735], Loss: 0.0355\n",
      "Epoch [38/50], Step [464/735], Loss: 0.0979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Step [465/735], Loss: 0.0829\n",
      "Epoch [38/50], Step [466/735], Loss: 0.0535\n",
      "Epoch [38/50], Step [467/735], Loss: 0.0391\n",
      "Epoch [38/50], Step [468/735], Loss: 0.4702\n",
      "Epoch [38/50], Step [469/735], Loss: 0.0574\n",
      "Epoch [38/50], Step [470/735], Loss: 0.0657\n",
      "Epoch [38/50], Step [471/735], Loss: 0.0339\n",
      "Epoch [38/50], Step [472/735], Loss: 0.0311\n",
      "Epoch [38/50], Step [473/735], Loss: 0.0170\n",
      "Epoch [38/50], Step [474/735], Loss: 0.0240\n",
      "Epoch [38/50], Step [475/735], Loss: 0.0546\n",
      "Epoch [38/50], Step [476/735], Loss: 0.1352\n",
      "Epoch [38/50], Step [477/735], Loss: 0.0400\n",
      "Epoch [38/50], Step [478/735], Loss: 0.0427\n",
      "Epoch [38/50], Step [479/735], Loss: 0.0830\n",
      "Epoch [38/50], Step [480/735], Loss: 0.0482\n",
      "Epoch [38/50], Step [481/735], Loss: 0.0657\n",
      "Epoch [38/50], Step [482/735], Loss: 0.0153\n",
      "Epoch [38/50], Step [483/735], Loss: 0.1319\n",
      "Epoch [38/50], Step [484/735], Loss: 0.0360\n",
      "Epoch [38/50], Step [485/735], Loss: 0.0394\n",
      "Epoch [38/50], Step [486/735], Loss: 0.0249\n",
      "Epoch [38/50], Step [487/735], Loss: 0.0285\n",
      "Epoch [38/50], Step [488/735], Loss: 0.0276\n",
      "Epoch [38/50], Step [489/735], Loss: 0.0561\n",
      "Epoch [38/50], Step [490/735], Loss: 0.0255\n",
      "Epoch [38/50], Step [491/735], Loss: 0.0296\n",
      "Epoch [38/50], Step [492/735], Loss: 0.0404\n",
      "Epoch [38/50], Step [493/735], Loss: 0.1541\n",
      "Epoch [38/50], Step [494/735], Loss: 0.0679\n",
      "Epoch [38/50], Step [495/735], Loss: 0.1300\n",
      "Epoch [38/50], Step [496/735], Loss: 0.0197\n",
      "Epoch [38/50], Step [497/735], Loss: 0.2128\n",
      "Epoch [38/50], Step [498/735], Loss: 0.0606\n",
      "Epoch [38/50], Step [499/735], Loss: 0.0402\n",
      "Epoch [38/50], Step [500/735], Loss: 0.2351\n",
      "Epoch [38/50], Step [501/735], Loss: 0.1874\n",
      "Epoch [38/50], Step [502/735], Loss: 0.0775\n",
      "Epoch [38/50], Step [503/735], Loss: 0.0460\n",
      "Epoch [38/50], Step [504/735], Loss: 0.2777\n",
      "Epoch [38/50], Step [505/735], Loss: 0.0675\n",
      "Epoch [38/50], Step [506/735], Loss: 0.0527\n",
      "Epoch [38/50], Step [507/735], Loss: 0.0296\n",
      "Epoch [38/50], Step [508/735], Loss: 0.1050\n",
      "Epoch [38/50], Step [509/735], Loss: 0.0407\n",
      "Epoch [38/50], Step [510/735], Loss: 0.1509\n",
      "Epoch [38/50], Step [511/735], Loss: 0.0509\n",
      "Epoch [38/50], Step [512/735], Loss: 0.0734\n",
      "Epoch [38/50], Step [513/735], Loss: 0.0852\n",
      "Epoch [38/50], Step [514/735], Loss: 0.0266\n",
      "Epoch [38/50], Step [515/735], Loss: 0.0313\n",
      "Epoch [38/50], Step [516/735], Loss: 0.0618\n",
      "Epoch [38/50], Step [517/735], Loss: 0.1507\n",
      "Epoch [38/50], Step [518/735], Loss: 0.0906\n",
      "Epoch [38/50], Step [519/735], Loss: 0.0948\n",
      "Epoch [38/50], Step [520/735], Loss: 0.0401\n",
      "Epoch [38/50], Step [521/735], Loss: 0.0626\n",
      "Epoch [38/50], Step [522/735], Loss: 0.0507\n",
      "Epoch [38/50], Step [523/735], Loss: 0.0345\n",
      "Epoch [38/50], Step [524/735], Loss: 0.0621\n",
      "Epoch [38/50], Step [525/735], Loss: 0.1139\n",
      "Epoch [38/50], Step [526/735], Loss: 0.0631\n",
      "Epoch [38/50], Step [527/735], Loss: 0.0545\n",
      "Epoch [38/50], Step [528/735], Loss: 0.0932\n",
      "Epoch [38/50], Step [529/735], Loss: 0.4241\n",
      "Epoch [38/50], Step [530/735], Loss: 0.0463\n",
      "Epoch [38/50], Step [531/735], Loss: 0.0474\n",
      "Epoch [38/50], Step [532/735], Loss: 0.0957\n",
      "Epoch [38/50], Step [533/735], Loss: 0.0666\n",
      "Epoch [38/50], Step [534/735], Loss: 0.0353\n",
      "Epoch [38/50], Step [535/735], Loss: 0.0624\n",
      "Epoch [38/50], Step [536/735], Loss: 0.0623\n",
      "Epoch [38/50], Step [537/735], Loss: 0.0422\n",
      "Epoch [38/50], Step [538/735], Loss: 0.0416\n",
      "Epoch [38/50], Step [539/735], Loss: 0.1837\n",
      "Epoch [38/50], Step [540/735], Loss: 0.1052\n",
      "Epoch [38/50], Step [541/735], Loss: 0.0814\n",
      "Epoch [38/50], Step [542/735], Loss: 0.0818\n",
      "Epoch [38/50], Step [543/735], Loss: 0.0576\n",
      "Epoch [38/50], Step [544/735], Loss: 0.1148\n",
      "Epoch [38/50], Step [545/735], Loss: 0.0475\n",
      "Epoch [38/50], Step [546/735], Loss: 0.0887\n",
      "Epoch [38/50], Step [547/735], Loss: 0.0774\n",
      "Epoch [38/50], Step [548/735], Loss: 0.1415\n",
      "Epoch [38/50], Step [549/735], Loss: 0.0491\n",
      "Epoch [38/50], Step [550/735], Loss: 0.0334\n",
      "Epoch [38/50], Step [551/735], Loss: 0.1175\n",
      "Epoch [38/50], Step [552/735], Loss: 0.0710\n",
      "Epoch [38/50], Step [553/735], Loss: 0.0682\n",
      "Epoch [38/50], Step [554/735], Loss: 0.0354\n",
      "Epoch [38/50], Step [555/735], Loss: 0.1443\n",
      "Epoch [38/50], Step [556/735], Loss: 0.0553\n",
      "Epoch [38/50], Step [557/735], Loss: 0.1002\n",
      "Epoch [38/50], Step [558/735], Loss: 0.0188\n",
      "Epoch [38/50], Step [559/735], Loss: 0.0475\n",
      "Epoch [38/50], Step [560/735], Loss: 0.1003\n",
      "Epoch [38/50], Step [561/735], Loss: 0.1484\n",
      "Epoch [38/50], Step [562/735], Loss: 0.0400\n",
      "Epoch [38/50], Step [563/735], Loss: 0.0362\n",
      "Epoch [38/50], Step [564/735], Loss: 0.0237\n",
      "Epoch [38/50], Step [565/735], Loss: 0.0931\n",
      "Epoch [38/50], Step [566/735], Loss: 0.0312\n",
      "Epoch [38/50], Step [567/735], Loss: 0.0590\n",
      "Epoch [38/50], Step [568/735], Loss: 0.0344\n",
      "Epoch [38/50], Step [569/735], Loss: 0.0787\n",
      "Epoch [38/50], Step [570/735], Loss: 0.0790\n",
      "Epoch [38/50], Step [571/735], Loss: 0.0587\n",
      "Epoch [38/50], Step [572/735], Loss: 0.1103\n",
      "Epoch [38/50], Step [573/735], Loss: 0.0837\n",
      "Epoch [38/50], Step [574/735], Loss: 0.0600\n",
      "Epoch [38/50], Step [575/735], Loss: 0.1882\n",
      "Epoch [38/50], Step [576/735], Loss: 0.0652\n",
      "Epoch [38/50], Step [577/735], Loss: 0.0888\n",
      "Epoch [38/50], Step [578/735], Loss: 0.1254\n",
      "Epoch [38/50], Step [579/735], Loss: 0.0507\n",
      "Epoch [38/50], Step [580/735], Loss: 0.0667\n",
      "Epoch [38/50], Step [581/735], Loss: 0.0370\n",
      "Epoch [38/50], Step [582/735], Loss: 0.0362\n",
      "Epoch [38/50], Step [583/735], Loss: 0.0896\n",
      "Epoch [38/50], Step [584/735], Loss: 0.0389\n",
      "Epoch [38/50], Step [585/735], Loss: 0.0463\n",
      "Epoch [38/50], Step [586/735], Loss: 0.1255\n",
      "Epoch [38/50], Step [587/735], Loss: 0.0622\n",
      "Epoch [38/50], Step [588/735], Loss: 0.0381\n",
      "Epoch [38/50], Step [589/735], Loss: 0.0189\n",
      "Epoch [38/50], Step [590/735], Loss: 0.0298\n",
      "Epoch [38/50], Step [591/735], Loss: 0.0451\n",
      "Epoch [38/50], Step [592/735], Loss: 0.0816\n",
      "Epoch [38/50], Step [593/735], Loss: 0.1084\n",
      "Epoch [38/50], Step [594/735], Loss: 0.0271\n",
      "Epoch [38/50], Step [595/735], Loss: 0.1188\n",
      "Epoch [38/50], Step [596/735], Loss: 0.0476\n",
      "Epoch [38/50], Step [597/735], Loss: 0.0476\n",
      "Epoch [38/50], Step [598/735], Loss: 0.0299\n",
      "Epoch [38/50], Step [599/735], Loss: 0.0291\n",
      "Epoch [38/50], Step [600/735], Loss: 0.0611\n",
      "Epoch [38/50], Step [601/735], Loss: 0.0488\n",
      "Epoch [38/50], Step [602/735], Loss: 0.0899\n",
      "Epoch [38/50], Step [603/735], Loss: 0.1360\n",
      "Epoch [38/50], Step [604/735], Loss: 0.0487\n",
      "Epoch [38/50], Step [605/735], Loss: 0.0403\n",
      "Epoch [38/50], Step [606/735], Loss: 0.0429\n",
      "Epoch [38/50], Step [607/735], Loss: 0.0548\n",
      "Epoch [38/50], Step [608/735], Loss: 0.0168\n",
      "Epoch [38/50], Step [609/735], Loss: 0.0363\n",
      "Epoch [38/50], Step [610/735], Loss: 0.0532\n",
      "Epoch [38/50], Step [611/735], Loss: 0.0196\n",
      "Epoch [38/50], Step [612/735], Loss: 0.0679\n",
      "Epoch [38/50], Step [613/735], Loss: 0.0436\n",
      "Epoch [38/50], Step [614/735], Loss: 0.0319\n",
      "Epoch [38/50], Step [615/735], Loss: 0.0312\n",
      "Epoch [38/50], Step [616/735], Loss: 0.0209\n",
      "Epoch [38/50], Step [617/735], Loss: 0.0499\n",
      "Epoch [38/50], Step [618/735], Loss: 0.0687\n",
      "Epoch [38/50], Step [619/735], Loss: 0.1362\n",
      "Epoch [38/50], Step [620/735], Loss: 0.0201\n",
      "Epoch [38/50], Step [621/735], Loss: 0.0608\n",
      "Epoch [38/50], Step [622/735], Loss: 0.0288\n",
      "Epoch [38/50], Step [623/735], Loss: 0.0397\n",
      "Epoch [38/50], Step [624/735], Loss: 0.1072\n",
      "Epoch [38/50], Step [625/735], Loss: 0.0591\n",
      "Epoch [38/50], Step [626/735], Loss: 0.1352\n",
      "Epoch [38/50], Step [627/735], Loss: 0.0510\n",
      "Epoch [38/50], Step [628/735], Loss: 0.0189\n",
      "Epoch [38/50], Step [629/735], Loss: 0.0563\n",
      "Epoch [38/50], Step [630/735], Loss: 0.0319\n",
      "Epoch [38/50], Step [631/735], Loss: 0.0393\n",
      "Epoch [38/50], Step [632/735], Loss: 0.1121\n",
      "Epoch [38/50], Step [633/735], Loss: 0.0205\n",
      "Epoch [38/50], Step [634/735], Loss: 0.0886\n",
      "Epoch [38/50], Step [635/735], Loss: 0.1422\n",
      "Epoch [38/50], Step [636/735], Loss: 0.0199\n",
      "Epoch [38/50], Step [637/735], Loss: 0.0232\n",
      "Epoch [38/50], Step [638/735], Loss: 0.1865\n",
      "Epoch [38/50], Step [639/735], Loss: 0.0259\n",
      "Epoch [38/50], Step [640/735], Loss: 0.0470\n",
      "Epoch [38/50], Step [641/735], Loss: 0.0519\n",
      "Epoch [38/50], Step [642/735], Loss: 0.0621\n",
      "Epoch [38/50], Step [643/735], Loss: 0.0384\n",
      "Epoch [38/50], Step [644/735], Loss: 0.1295\n",
      "Epoch [38/50], Step [645/735], Loss: 0.0643\n",
      "Epoch [38/50], Step [646/735], Loss: 0.0755\n",
      "Epoch [38/50], Step [647/735], Loss: 0.0665\n",
      "Epoch [38/50], Step [648/735], Loss: 0.0758\n",
      "Epoch [38/50], Step [649/735], Loss: 0.0420\n",
      "Epoch [38/50], Step [650/735], Loss: 0.0496\n",
      "Epoch [38/50], Step [651/735], Loss: 0.0292\n",
      "Epoch [38/50], Step [652/735], Loss: 0.0608\n",
      "Epoch [38/50], Step [653/735], Loss: 0.0551\n",
      "Epoch [38/50], Step [654/735], Loss: 0.0733\n",
      "Epoch [38/50], Step [655/735], Loss: 0.0639\n",
      "Epoch [38/50], Step [656/735], Loss: 0.0394\n",
      "Epoch [38/50], Step [657/735], Loss: 0.0546\n",
      "Epoch [38/50], Step [658/735], Loss: 0.0137\n",
      "Epoch [38/50], Step [659/735], Loss: 0.0558\n",
      "Epoch [38/50], Step [660/735], Loss: 0.0226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Step [661/735], Loss: 0.0160\n",
      "Epoch [38/50], Step [662/735], Loss: 0.0966\n",
      "Epoch [38/50], Step [663/735], Loss: 0.0219\n",
      "Epoch [38/50], Step [664/735], Loss: 0.0608\n",
      "Epoch [38/50], Step [665/735], Loss: 0.0378\n",
      "Epoch [38/50], Step [666/735], Loss: 0.0236\n",
      "Epoch [38/50], Step [667/735], Loss: 0.0666\n",
      "Epoch [38/50], Step [668/735], Loss: 0.0156\n",
      "Epoch [38/50], Step [669/735], Loss: 0.0340\n",
      "Epoch [38/50], Step [670/735], Loss: 0.0214\n",
      "Epoch [38/50], Step [671/735], Loss: 0.0252\n",
      "Epoch [38/50], Step [672/735], Loss: 0.0672\n",
      "Epoch [38/50], Step [673/735], Loss: 0.0441\n",
      "Epoch [38/50], Step [674/735], Loss: 0.0696\n",
      "Epoch [38/50], Step [675/735], Loss: 0.0478\n",
      "Epoch [38/50], Step [676/735], Loss: 0.0680\n",
      "Epoch [38/50], Step [677/735], Loss: 0.0287\n",
      "Epoch [38/50], Step [678/735], Loss: 0.1182\n",
      "Epoch [38/50], Step [679/735], Loss: 0.0338\n",
      "Epoch [38/50], Step [680/735], Loss: 0.0742\n",
      "Epoch [38/50], Step [681/735], Loss: 0.0208\n",
      "Epoch [38/50], Step [682/735], Loss: 0.0849\n",
      "Epoch [38/50], Step [683/735], Loss: 0.1632\n",
      "Epoch [38/50], Step [684/735], Loss: 0.0243\n",
      "Epoch [38/50], Step [685/735], Loss: 0.1961\n",
      "Epoch [38/50], Step [686/735], Loss: 0.0367\n",
      "Epoch [38/50], Step [687/735], Loss: 0.0278\n",
      "Epoch [38/50], Step [688/735], Loss: 0.0274\n",
      "Epoch [38/50], Step [689/735], Loss: 0.0412\n",
      "Epoch [38/50], Step [690/735], Loss: 0.0618\n",
      "Epoch [38/50], Step [691/735], Loss: 0.1899\n",
      "Epoch [38/50], Step [692/735], Loss: 0.0495\n",
      "Epoch [38/50], Step [693/735], Loss: 0.1987\n",
      "Epoch [38/50], Step [694/735], Loss: 0.0254\n",
      "Epoch [38/50], Step [695/735], Loss: 0.0332\n",
      "Epoch [38/50], Step [696/735], Loss: 0.0422\n",
      "Epoch [38/50], Step [697/735], Loss: 0.0537\n",
      "Epoch [38/50], Step [698/735], Loss: 0.0508\n",
      "Epoch [38/50], Step [699/735], Loss: 0.6024\n",
      "Epoch [38/50], Step [700/735], Loss: 0.0732\n",
      "Epoch [38/50], Step [701/735], Loss: 0.0504\n",
      "Epoch [38/50], Step [702/735], Loss: 0.0436\n",
      "Epoch [38/50], Step [703/735], Loss: 0.1269\n",
      "Epoch [38/50], Step [704/735], Loss: 0.0233\n",
      "Epoch [38/50], Step [705/735], Loss: 0.0355\n",
      "Epoch [38/50], Step [706/735], Loss: 0.1069\n",
      "Epoch [38/50], Step [707/735], Loss: 0.0324\n",
      "Epoch [38/50], Step [708/735], Loss: 0.4812\n",
      "Epoch [38/50], Step [709/735], Loss: 0.0317\n",
      "Epoch [38/50], Step [710/735], Loss: 0.0547\n",
      "Epoch [38/50], Step [711/735], Loss: 0.0401\n",
      "Epoch [38/50], Step [712/735], Loss: 0.0368\n",
      "Epoch [38/50], Step [713/735], Loss: 0.0256\n",
      "Epoch [38/50], Step [714/735], Loss: 0.0846\n",
      "Epoch [38/50], Step [715/735], Loss: 0.0233\n",
      "Epoch [38/50], Step [716/735], Loss: 0.1108\n",
      "Epoch [38/50], Step [717/735], Loss: 0.0637\n",
      "Epoch [38/50], Step [718/735], Loss: 0.0638\n",
      "Epoch [38/50], Step [719/735], Loss: 0.0719\n",
      "Epoch [38/50], Step [720/735], Loss: 0.0707\n",
      "Epoch [38/50], Step [721/735], Loss: 0.0118\n",
      "Epoch [38/50], Step [722/735], Loss: 0.1274\n",
      "Epoch [38/50], Step [723/735], Loss: 0.2489\n",
      "Epoch [38/50], Step [724/735], Loss: 0.0561\n",
      "Epoch [38/50], Step [725/735], Loss: 0.0917\n",
      "Epoch [38/50], Step [726/735], Loss: 0.0299\n",
      "Epoch [38/50], Step [727/735], Loss: 0.0194\n",
      "Epoch [38/50], Step [728/735], Loss: 0.1516\n",
      "Epoch [38/50], Step [729/735], Loss: 0.0715\n",
      "Epoch [38/50], Step [730/735], Loss: 0.0203\n",
      "Epoch [38/50], Step [731/735], Loss: 0.0820\n",
      "Epoch [38/50], Step [732/735], Loss: 0.0593\n",
      "Epoch [38/50], Step [733/735], Loss: 0.0634\n",
      "Epoch [38/50], Step [734/735], Loss: 0.0593\n",
      "Epoch [38/50], Step [735/735], Loss: 0.0436\n",
      "Epoch [39/50], Step [1/735], Loss: 0.0586\n",
      "Epoch [39/50], Step [2/735], Loss: 0.1313\n",
      "Epoch [39/50], Step [3/735], Loss: 0.0791\n",
      "Epoch [39/50], Step [4/735], Loss: 0.0557\n",
      "Epoch [39/50], Step [5/735], Loss: 0.0465\n",
      "Epoch [39/50], Step [6/735], Loss: 0.0401\n",
      "Epoch [39/50], Step [7/735], Loss: 0.0195\n",
      "Epoch [39/50], Step [8/735], Loss: 0.0229\n",
      "Epoch [39/50], Step [9/735], Loss: 0.0497\n",
      "Epoch [39/50], Step [10/735], Loss: 0.0531\n",
      "Epoch [39/50], Step [11/735], Loss: 0.1168\n",
      "Epoch [39/50], Step [12/735], Loss: 0.0230\n",
      "Epoch [39/50], Step [13/735], Loss: 0.0529\n",
      "Epoch [39/50], Step [14/735], Loss: 0.0220\n",
      "Epoch [39/50], Step [15/735], Loss: 0.0113\n",
      "Epoch [39/50], Step [16/735], Loss: 0.0324\n",
      "Epoch [39/50], Step [17/735], Loss: 0.1075\n",
      "Epoch [39/50], Step [18/735], Loss: 0.0635\n",
      "Epoch [39/50], Step [19/735], Loss: 0.0776\n",
      "Epoch [39/50], Step [20/735], Loss: 0.0941\n",
      "Epoch [39/50], Step [21/735], Loss: 0.0298\n",
      "Epoch [39/50], Step [22/735], Loss: 0.0398\n",
      "Epoch [39/50], Step [23/735], Loss: 0.0612\n",
      "Epoch [39/50], Step [24/735], Loss: 0.0615\n",
      "Epoch [39/50], Step [25/735], Loss: 0.0540\n",
      "Epoch [39/50], Step [26/735], Loss: 0.0299\n",
      "Epoch [39/50], Step [27/735], Loss: 0.0790\n",
      "Epoch [39/50], Step [28/735], Loss: 0.0604\n",
      "Epoch [39/50], Step [29/735], Loss: 0.0976\n",
      "Epoch [39/50], Step [30/735], Loss: 0.2188\n",
      "Epoch [39/50], Step [31/735], Loss: 0.1302\n",
      "Epoch [39/50], Step [32/735], Loss: 0.0512\n",
      "Epoch [39/50], Step [33/735], Loss: 0.0338\n",
      "Epoch [39/50], Step [34/735], Loss: 0.0532\n",
      "Epoch [39/50], Step [35/735], Loss: 0.1334\n",
      "Epoch [39/50], Step [36/735], Loss: 0.0378\n",
      "Epoch [39/50], Step [37/735], Loss: 0.0775\n",
      "Epoch [39/50], Step [38/735], Loss: 0.1323\n",
      "Epoch [39/50], Step [39/735], Loss: 0.0391\n",
      "Epoch [39/50], Step [40/735], Loss: 0.0858\n",
      "Epoch [39/50], Step [41/735], Loss: 0.0598\n",
      "Epoch [39/50], Step [42/735], Loss: 0.0373\n",
      "Epoch [39/50], Step [43/735], Loss: 0.0600\n",
      "Epoch [39/50], Step [44/735], Loss: 0.0547\n",
      "Epoch [39/50], Step [45/735], Loss: 0.2448\n",
      "Epoch [39/50], Step [46/735], Loss: 0.0532\n",
      "Epoch [39/50], Step [47/735], Loss: 0.0546\n",
      "Epoch [39/50], Step [48/735], Loss: 0.0298\n",
      "Epoch [39/50], Step [49/735], Loss: 0.0385\n",
      "Epoch [39/50], Step [50/735], Loss: 0.1098\n",
      "Epoch [39/50], Step [51/735], Loss: 0.0902\n",
      "Epoch [39/50], Step [52/735], Loss: 0.2482\n",
      "Epoch [39/50], Step [53/735], Loss: 0.0560\n",
      "Epoch [39/50], Step [54/735], Loss: 0.1521\n",
      "Epoch [39/50], Step [55/735], Loss: 0.1203\n",
      "Epoch [39/50], Step [56/735], Loss: 0.3023\n",
      "Epoch [39/50], Step [57/735], Loss: 0.0253\n",
      "Epoch [39/50], Step [58/735], Loss: 0.1268\n",
      "Epoch [39/50], Step [59/735], Loss: 0.0491\n",
      "Epoch [39/50], Step [60/735], Loss: 0.1060\n",
      "Epoch [39/50], Step [61/735], Loss: 0.1255\n",
      "Epoch [39/50], Step [62/735], Loss: 0.0659\n",
      "Epoch [39/50], Step [63/735], Loss: 0.0323\n",
      "Epoch [39/50], Step [64/735], Loss: 0.0443\n",
      "Epoch [39/50], Step [65/735], Loss: 0.0380\n",
      "Epoch [39/50], Step [66/735], Loss: 0.0777\n",
      "Epoch [39/50], Step [67/735], Loss: 0.0766\n",
      "Epoch [39/50], Step [68/735], Loss: 0.0291\n",
      "Epoch [39/50], Step [69/735], Loss: 0.0348\n",
      "Epoch [39/50], Step [70/735], Loss: 0.4125\n",
      "Epoch [39/50], Step [71/735], Loss: 0.1083\n",
      "Epoch [39/50], Step [72/735], Loss: 0.0885\n",
      "Epoch [39/50], Step [73/735], Loss: 0.0813\n",
      "Epoch [39/50], Step [74/735], Loss: 0.0303\n",
      "Epoch [39/50], Step [75/735], Loss: 0.0457\n",
      "Epoch [39/50], Step [76/735], Loss: 0.0596\n",
      "Epoch [39/50], Step [77/735], Loss: 0.0478\n",
      "Epoch [39/50], Step [78/735], Loss: 0.0526\n",
      "Epoch [39/50], Step [79/735], Loss: 0.0557\n",
      "Epoch [39/50], Step [80/735], Loss: 0.0282\n",
      "Epoch [39/50], Step [81/735], Loss: 0.0588\n",
      "Epoch [39/50], Step [82/735], Loss: 0.0595\n",
      "Epoch [39/50], Step [83/735], Loss: 0.0397\n",
      "Epoch [39/50], Step [84/735], Loss: 0.0388\n",
      "Epoch [39/50], Step [85/735], Loss: 0.0511\n",
      "Epoch [39/50], Step [86/735], Loss: 0.0502\n",
      "Epoch [39/50], Step [87/735], Loss: 0.0703\n",
      "Epoch [39/50], Step [88/735], Loss: 0.0707\n",
      "Epoch [39/50], Step [89/735], Loss: 0.0149\n",
      "Epoch [39/50], Step [90/735], Loss: 0.2153\n",
      "Epoch [39/50], Step [91/735], Loss: 0.0402\n",
      "Epoch [39/50], Step [92/735], Loss: 0.0268\n",
      "Epoch [39/50], Step [93/735], Loss: 0.0223\n",
      "Epoch [39/50], Step [94/735], Loss: 0.0220\n",
      "Epoch [39/50], Step [95/735], Loss: 0.1995\n",
      "Epoch [39/50], Step [96/735], Loss: 0.0428\n",
      "Epoch [39/50], Step [97/735], Loss: 0.0702\n",
      "Epoch [39/50], Step [98/735], Loss: 0.0488\n",
      "Epoch [39/50], Step [99/735], Loss: 0.1498\n",
      "Epoch [39/50], Step [100/735], Loss: 0.0946\n",
      "Epoch [39/50], Step [101/735], Loss: 0.0519\n",
      "Epoch [39/50], Step [102/735], Loss: 0.0463\n",
      "Epoch [39/50], Step [103/735], Loss: 0.0783\n",
      "Epoch [39/50], Step [104/735], Loss: 0.0548\n",
      "Epoch [39/50], Step [105/735], Loss: 0.1164\n",
      "Epoch [39/50], Step [106/735], Loss: 0.0639\n",
      "Epoch [39/50], Step [107/735], Loss: 0.0564\n",
      "Epoch [39/50], Step [108/735], Loss: 0.0616\n",
      "Epoch [39/50], Step [109/735], Loss: 0.1272\n",
      "Epoch [39/50], Step [110/735], Loss: 0.0754\n",
      "Epoch [39/50], Step [111/735], Loss: 0.0461\n",
      "Epoch [39/50], Step [112/735], Loss: 0.0581\n",
      "Epoch [39/50], Step [113/735], Loss: 0.0352\n",
      "Epoch [39/50], Step [114/735], Loss: 0.1657\n",
      "Epoch [39/50], Step [115/735], Loss: 0.0745\n",
      "Epoch [39/50], Step [116/735], Loss: 0.1063\n",
      "Epoch [39/50], Step [117/735], Loss: 0.0677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Step [118/735], Loss: 0.0411\n",
      "Epoch [39/50], Step [119/735], Loss: 0.0231\n",
      "Epoch [39/50], Step [120/735], Loss: 0.0867\n",
      "Epoch [39/50], Step [121/735], Loss: 0.0322\n",
      "Epoch [39/50], Step [122/735], Loss: 0.0236\n",
      "Epoch [39/50], Step [123/735], Loss: 0.0188\n",
      "Epoch [39/50], Step [124/735], Loss: 0.0584\n",
      "Epoch [39/50], Step [125/735], Loss: 0.1067\n",
      "Epoch [39/50], Step [126/735], Loss: 0.1257\n",
      "Epoch [39/50], Step [127/735], Loss: 0.0630\n",
      "Epoch [39/50], Step [128/735], Loss: 0.1205\n",
      "Epoch [39/50], Step [129/735], Loss: 0.0426\n",
      "Epoch [39/50], Step [130/735], Loss: 0.0692\n",
      "Epoch [39/50], Step [131/735], Loss: 0.0234\n",
      "Epoch [39/50], Step [132/735], Loss: 0.0422\n",
      "Epoch [39/50], Step [133/735], Loss: 0.0235\n",
      "Epoch [39/50], Step [134/735], Loss: 0.3277\n",
      "Epoch [39/50], Step [135/735], Loss: 0.0317\n",
      "Epoch [39/50], Step [136/735], Loss: 0.0225\n",
      "Epoch [39/50], Step [137/735], Loss: 0.0924\n",
      "Epoch [39/50], Step [138/735], Loss: 0.1111\n",
      "Epoch [39/50], Step [139/735], Loss: 0.0278\n",
      "Epoch [39/50], Step [140/735], Loss: 0.1190\n",
      "Epoch [39/50], Step [141/735], Loss: 0.0907\n",
      "Epoch [39/50], Step [142/735], Loss: 0.0436\n",
      "Epoch [39/50], Step [143/735], Loss: 0.0307\n",
      "Epoch [39/50], Step [144/735], Loss: 0.0499\n",
      "Epoch [39/50], Step [145/735], Loss: 0.3460\n",
      "Epoch [39/50], Step [146/735], Loss: 0.0974\n",
      "Epoch [39/50], Step [147/735], Loss: 0.0175\n",
      "Epoch [39/50], Step [148/735], Loss: 0.0741\n",
      "Epoch [39/50], Step [149/735], Loss: 0.0466\n",
      "Epoch [39/50], Step [150/735], Loss: 0.0315\n",
      "Epoch [39/50], Step [151/735], Loss: 0.0312\n",
      "Epoch [39/50], Step [152/735], Loss: 0.0431\n",
      "Epoch [39/50], Step [153/735], Loss: 0.0651\n",
      "Epoch [39/50], Step [154/735], Loss: 0.0345\n",
      "Epoch [39/50], Step [155/735], Loss: 0.2628\n",
      "Epoch [39/50], Step [156/735], Loss: 0.0338\n",
      "Epoch [39/50], Step [157/735], Loss: 0.0749\n",
      "Epoch [39/50], Step [158/735], Loss: 0.1208\n",
      "Epoch [39/50], Step [159/735], Loss: 0.0292\n",
      "Epoch [39/50], Step [160/735], Loss: 0.0812\n",
      "Epoch [39/50], Step [161/735], Loss: 0.0441\n",
      "Epoch [39/50], Step [162/735], Loss: 0.1252\n",
      "Epoch [39/50], Step [163/735], Loss: 0.0512\n",
      "Epoch [39/50], Step [164/735], Loss: 0.1158\n",
      "Epoch [39/50], Step [165/735], Loss: 0.0384\n",
      "Epoch [39/50], Step [166/735], Loss: 0.0803\n",
      "Epoch [39/50], Step [167/735], Loss: 0.0338\n",
      "Epoch [39/50], Step [168/735], Loss: 0.0857\n",
      "Epoch [39/50], Step [169/735], Loss: 0.0374\n",
      "Epoch [39/50], Step [170/735], Loss: 0.0975\n",
      "Epoch [39/50], Step [171/735], Loss: 0.1495\n",
      "Epoch [39/50], Step [172/735], Loss: 0.0169\n",
      "Epoch [39/50], Step [173/735], Loss: 0.0881\n",
      "Epoch [39/50], Step [174/735], Loss: 0.0365\n",
      "Epoch [39/50], Step [175/735], Loss: 0.0487\n",
      "Epoch [39/50], Step [176/735], Loss: 0.0344\n",
      "Epoch [39/50], Step [177/735], Loss: 0.0341\n",
      "Epoch [39/50], Step [178/735], Loss: 0.1154\n",
      "Epoch [39/50], Step [179/735], Loss: 0.0584\n",
      "Epoch [39/50], Step [180/735], Loss: 0.0379\n",
      "Epoch [39/50], Step [181/735], Loss: 0.0870\n",
      "Epoch [39/50], Step [182/735], Loss: 0.0403\n",
      "Epoch [39/50], Step [183/735], Loss: 0.0778\n",
      "Epoch [39/50], Step [184/735], Loss: 0.0335\n",
      "Epoch [39/50], Step [185/735], Loss: 0.0627\n",
      "Epoch [39/50], Step [186/735], Loss: 0.0281\n",
      "Epoch [39/50], Step [187/735], Loss: 0.2062\n",
      "Epoch [39/50], Step [188/735], Loss: 0.0207\n",
      "Epoch [39/50], Step [189/735], Loss: 0.0628\n",
      "Epoch [39/50], Step [190/735], Loss: 0.0516\n",
      "Epoch [39/50], Step [191/735], Loss: 0.0962\n",
      "Epoch [39/50], Step [192/735], Loss: 0.0538\n",
      "Epoch [39/50], Step [193/735], Loss: 0.0692\n",
      "Epoch [39/50], Step [194/735], Loss: 0.0437\n",
      "Epoch [39/50], Step [195/735], Loss: 0.0607\n",
      "Epoch [39/50], Step [196/735], Loss: 0.0701\n",
      "Epoch [39/50], Step [197/735], Loss: 0.0274\n",
      "Epoch [39/50], Step [198/735], Loss: 0.0491\n",
      "Epoch [39/50], Step [199/735], Loss: 0.0412\n",
      "Epoch [39/50], Step [200/735], Loss: 0.0535\n",
      "Epoch [39/50], Step [201/735], Loss: 0.0900\n",
      "Epoch [39/50], Step [202/735], Loss: 0.2357\n",
      "Epoch [39/50], Step [203/735], Loss: 0.0314\n",
      "Epoch [39/50], Step [204/735], Loss: 0.0613\n",
      "Epoch [39/50], Step [205/735], Loss: 0.0583\n",
      "Epoch [39/50], Step [206/735], Loss: 0.0523\n",
      "Epoch [39/50], Step [207/735], Loss: 0.0654\n",
      "Epoch [39/50], Step [208/735], Loss: 0.1127\n",
      "Epoch [39/50], Step [209/735], Loss: 0.0204\n",
      "Epoch [39/50], Step [210/735], Loss: 0.2093\n",
      "Epoch [39/50], Step [211/735], Loss: 0.0778\n",
      "Epoch [39/50], Step [212/735], Loss: 0.0955\n",
      "Epoch [39/50], Step [213/735], Loss: 0.0480\n",
      "Epoch [39/50], Step [214/735], Loss: 0.1034\n",
      "Epoch [39/50], Step [215/735], Loss: 0.1081\n",
      "Epoch [39/50], Step [216/735], Loss: 0.1048\n",
      "Epoch [39/50], Step [217/735], Loss: 0.0321\n",
      "Epoch [39/50], Step [218/735], Loss: 0.0431\n",
      "Epoch [39/50], Step [219/735], Loss: 0.0196\n",
      "Epoch [39/50], Step [220/735], Loss: 0.0336\n",
      "Epoch [39/50], Step [221/735], Loss: 0.0544\n",
      "Epoch [39/50], Step [222/735], Loss: 0.0403\n",
      "Epoch [39/50], Step [223/735], Loss: 0.0534\n",
      "Epoch [39/50], Step [224/735], Loss: 0.0860\n",
      "Epoch [39/50], Step [225/735], Loss: 0.1261\n",
      "Epoch [39/50], Step [226/735], Loss: 0.1938\n",
      "Epoch [39/50], Step [227/735], Loss: 0.0618\n",
      "Epoch [39/50], Step [228/735], Loss: 0.0648\n",
      "Epoch [39/50], Step [229/735], Loss: 0.0728\n",
      "Epoch [39/50], Step [230/735], Loss: 0.1349\n",
      "Epoch [39/50], Step [231/735], Loss: 0.0418\n",
      "Epoch [39/50], Step [232/735], Loss: 0.0583\n",
      "Epoch [39/50], Step [233/735], Loss: 0.0809\n",
      "Epoch [39/50], Step [234/735], Loss: 0.0727\n",
      "Epoch [39/50], Step [235/735], Loss: 0.3027\n",
      "Epoch [39/50], Step [236/735], Loss: 0.0891\n",
      "Epoch [39/50], Step [237/735], Loss: 0.0779\n",
      "Epoch [39/50], Step [238/735], Loss: 0.0727\n",
      "Epoch [39/50], Step [239/735], Loss: 0.0293\n",
      "Epoch [39/50], Step [240/735], Loss: 0.0570\n",
      "Epoch [39/50], Step [241/735], Loss: 0.0317\n",
      "Epoch [39/50], Step [242/735], Loss: 0.0808\n",
      "Epoch [39/50], Step [243/735], Loss: 0.1375\n",
      "Epoch [39/50], Step [244/735], Loss: 0.0493\n",
      "Epoch [39/50], Step [245/735], Loss: 0.0493\n",
      "Epoch [39/50], Step [246/735], Loss: 0.0465\n",
      "Epoch [39/50], Step [247/735], Loss: 0.0258\n",
      "Epoch [39/50], Step [248/735], Loss: 0.1143\n",
      "Epoch [39/50], Step [249/735], Loss: 0.0778\n",
      "Epoch [39/50], Step [250/735], Loss: 0.0151\n",
      "Epoch [39/50], Step [251/735], Loss: 0.0847\n",
      "Epoch [39/50], Step [252/735], Loss: 0.0378\n",
      "Epoch [39/50], Step [253/735], Loss: 0.0285\n",
      "Epoch [39/50], Step [254/735], Loss: 0.0496\n",
      "Epoch [39/50], Step [255/735], Loss: 0.1266\n",
      "Epoch [39/50], Step [256/735], Loss: 0.0216\n",
      "Epoch [39/50], Step [257/735], Loss: 0.1010\n",
      "Epoch [39/50], Step [258/735], Loss: 0.0494\n",
      "Epoch [39/50], Step [259/735], Loss: 0.0311\n",
      "Epoch [39/50], Step [260/735], Loss: 0.0474\n",
      "Epoch [39/50], Step [261/735], Loss: 0.1676\n",
      "Epoch [39/50], Step [262/735], Loss: 0.0633\n",
      "Epoch [39/50], Step [263/735], Loss: 0.0308\n",
      "Epoch [39/50], Step [264/735], Loss: 0.0351\n",
      "Epoch [39/50], Step [265/735], Loss: 0.1263\n",
      "Epoch [39/50], Step [266/735], Loss: 0.2384\n",
      "Epoch [39/50], Step [267/735], Loss: 0.0374\n",
      "Epoch [39/50], Step [268/735], Loss: 0.0462\n",
      "Epoch [39/50], Step [269/735], Loss: 0.0166\n",
      "Epoch [39/50], Step [270/735], Loss: 0.0695\n",
      "Epoch [39/50], Step [271/735], Loss: 0.0739\n",
      "Epoch [39/50], Step [272/735], Loss: 0.0254\n",
      "Epoch [39/50], Step [273/735], Loss: 0.0729\n",
      "Epoch [39/50], Step [274/735], Loss: 0.0993\n",
      "Epoch [39/50], Step [275/735], Loss: 0.0307\n",
      "Epoch [39/50], Step [276/735], Loss: 0.0847\n",
      "Epoch [39/50], Step [277/735], Loss: 0.0980\n",
      "Epoch [39/50], Step [278/735], Loss: 0.0858\n",
      "Epoch [39/50], Step [279/735], Loss: 0.1273\n",
      "Epoch [39/50], Step [280/735], Loss: 0.0540\n",
      "Epoch [39/50], Step [281/735], Loss: 0.0956\n",
      "Epoch [39/50], Step [282/735], Loss: 0.0648\n",
      "Epoch [39/50], Step [283/735], Loss: 0.1477\n",
      "Epoch [39/50], Step [284/735], Loss: 0.0443\n",
      "Epoch [39/50], Step [285/735], Loss: 0.0297\n",
      "Epoch [39/50], Step [286/735], Loss: 0.2197\n",
      "Epoch [39/50], Step [287/735], Loss: 0.0996\n",
      "Epoch [39/50], Step [288/735], Loss: 0.0575\n",
      "Epoch [39/50], Step [289/735], Loss: 0.0440\n",
      "Epoch [39/50], Step [290/735], Loss: 0.0673\n",
      "Epoch [39/50], Step [291/735], Loss: 0.1111\n",
      "Epoch [39/50], Step [292/735], Loss: 0.0613\n",
      "Epoch [39/50], Step [293/735], Loss: 0.1122\n",
      "Epoch [39/50], Step [294/735], Loss: 0.0938\n",
      "Epoch [39/50], Step [295/735], Loss: 0.0417\n",
      "Epoch [39/50], Step [296/735], Loss: 0.0602\n",
      "Epoch [39/50], Step [297/735], Loss: 0.0302\n",
      "Epoch [39/50], Step [298/735], Loss: 0.0526\n",
      "Epoch [39/50], Step [299/735], Loss: 0.2461\n",
      "Epoch [39/50], Step [300/735], Loss: 0.0421\n",
      "Epoch [39/50], Step [301/735], Loss: 0.0345\n",
      "Epoch [39/50], Step [302/735], Loss: 0.0420\n",
      "Epoch [39/50], Step [303/735], Loss: 0.1150\n",
      "Epoch [39/50], Step [304/735], Loss: 0.0292\n",
      "Epoch [39/50], Step [305/735], Loss: 0.1823\n",
      "Epoch [39/50], Step [306/735], Loss: 0.1169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Step [307/735], Loss: 0.0279\n",
      "Epoch [39/50], Step [308/735], Loss: 0.0285\n",
      "Epoch [39/50], Step [309/735], Loss: 0.0613\n",
      "Epoch [39/50], Step [310/735], Loss: 0.0421\n",
      "Epoch [39/50], Step [311/735], Loss: 0.2917\n",
      "Epoch [39/50], Step [312/735], Loss: 0.0273\n",
      "Epoch [39/50], Step [313/735], Loss: 0.0532\n",
      "Epoch [39/50], Step [314/735], Loss: 0.0178\n",
      "Epoch [39/50], Step [315/735], Loss: 0.0835\n",
      "Epoch [39/50], Step [316/735], Loss: 0.1356\n",
      "Epoch [39/50], Step [317/735], Loss: 0.0467\n",
      "Epoch [39/50], Step [318/735], Loss: 0.0748\n",
      "Epoch [39/50], Step [319/735], Loss: 0.0516\n",
      "Epoch [39/50], Step [320/735], Loss: 0.0251\n",
      "Epoch [39/50], Step [321/735], Loss: 0.0399\n",
      "Epoch [39/50], Step [322/735], Loss: 0.1136\n",
      "Epoch [39/50], Step [323/735], Loss: 0.0793\n",
      "Epoch [39/50], Step [324/735], Loss: 0.1103\n",
      "Epoch [39/50], Step [325/735], Loss: 0.1318\n",
      "Epoch [39/50], Step [326/735], Loss: 0.0683\n",
      "Epoch [39/50], Step [327/735], Loss: 0.0757\n",
      "Epoch [39/50], Step [328/735], Loss: 0.0545\n",
      "Epoch [39/50], Step [329/735], Loss: 0.0769\n",
      "Epoch [39/50], Step [330/735], Loss: 0.0367\n",
      "Epoch [39/50], Step [331/735], Loss: 0.0494\n",
      "Epoch [39/50], Step [332/735], Loss: 0.0709\n",
      "Epoch [39/50], Step [333/735], Loss: 0.0812\n",
      "Epoch [39/50], Step [334/735], Loss: 0.0462\n",
      "Epoch [39/50], Step [335/735], Loss: 0.0289\n",
      "Epoch [39/50], Step [336/735], Loss: 0.0343\n",
      "Epoch [39/50], Step [337/735], Loss: 0.0645\n",
      "Epoch [39/50], Step [338/735], Loss: 0.0180\n",
      "Epoch [39/50], Step [339/735], Loss: 0.0456\n",
      "Epoch [39/50], Step [340/735], Loss: 0.0849\n",
      "Epoch [39/50], Step [341/735], Loss: 0.0164\n",
      "Epoch [39/50], Step [342/735], Loss: 0.0551\n",
      "Epoch [39/50], Step [343/735], Loss: 0.0456\n",
      "Epoch [39/50], Step [344/735], Loss: 0.0602\n",
      "Epoch [39/50], Step [345/735], Loss: 0.1645\n",
      "Epoch [39/50], Step [346/735], Loss: 0.0995\n",
      "Epoch [39/50], Step [347/735], Loss: 0.0383\n",
      "Epoch [39/50], Step [348/735], Loss: 0.0343\n",
      "Epoch [39/50], Step [349/735], Loss: 0.0502\n",
      "Epoch [39/50], Step [350/735], Loss: 0.0246\n",
      "Epoch [39/50], Step [351/735], Loss: 0.1387\n",
      "Epoch [39/50], Step [352/735], Loss: 0.1652\n",
      "Epoch [39/50], Step [353/735], Loss: 0.1409\n",
      "Epoch [39/50], Step [354/735], Loss: 0.0198\n",
      "Epoch [39/50], Step [355/735], Loss: 0.0531\n",
      "Epoch [39/50], Step [356/735], Loss: 0.0232\n",
      "Epoch [39/50], Step [357/735], Loss: 0.0384\n",
      "Epoch [39/50], Step [358/735], Loss: 0.0819\n",
      "Epoch [39/50], Step [359/735], Loss: 0.0359\n",
      "Epoch [39/50], Step [360/735], Loss: 0.0213\n",
      "Epoch [39/50], Step [361/735], Loss: 0.0471\n",
      "Epoch [39/50], Step [362/735], Loss: 0.1141\n",
      "Epoch [39/50], Step [363/735], Loss: 0.0528\n",
      "Epoch [39/50], Step [364/735], Loss: 0.0397\n",
      "Epoch [39/50], Step [365/735], Loss: 0.0733\n",
      "Epoch [39/50], Step [366/735], Loss: 0.0443\n",
      "Epoch [39/50], Step [367/735], Loss: 0.0839\n",
      "Epoch [39/50], Step [368/735], Loss: 0.0905\n",
      "Epoch [39/50], Step [369/735], Loss: 0.0325\n",
      "Epoch [39/50], Step [370/735], Loss: 0.0383\n",
      "Epoch [39/50], Step [371/735], Loss: 0.0144\n",
      "Epoch [39/50], Step [372/735], Loss: 0.0323\n",
      "Epoch [39/50], Step [373/735], Loss: 0.0847\n",
      "Epoch [39/50], Step [374/735], Loss: 0.0221\n",
      "Epoch [39/50], Step [375/735], Loss: 0.0461\n",
      "Epoch [39/50], Step [376/735], Loss: 0.0263\n",
      "Epoch [39/50], Step [377/735], Loss: 0.2389\n",
      "Epoch [39/50], Step [378/735], Loss: 0.0439\n",
      "Epoch [39/50], Step [379/735], Loss: 0.1239\n",
      "Epoch [39/50], Step [380/735], Loss: 0.2081\n",
      "Epoch [39/50], Step [381/735], Loss: 0.0276\n",
      "Epoch [39/50], Step [382/735], Loss: 0.0769\n",
      "Epoch [39/50], Step [383/735], Loss: 0.0537\n",
      "Epoch [39/50], Step [384/735], Loss: 0.0331\n",
      "Epoch [39/50], Step [385/735], Loss: 0.0809\n",
      "Epoch [39/50], Step [386/735], Loss: 0.0291\n",
      "Epoch [39/50], Step [387/735], Loss: 0.1436\n",
      "Epoch [39/50], Step [388/735], Loss: 0.0961\n",
      "Epoch [39/50], Step [389/735], Loss: 0.0498\n",
      "Epoch [39/50], Step [390/735], Loss: 0.0835\n",
      "Epoch [39/50], Step [391/735], Loss: 0.0834\n",
      "Epoch [39/50], Step [392/735], Loss: 0.0499\n",
      "Epoch [39/50], Step [393/735], Loss: 0.0422\n",
      "Epoch [39/50], Step [394/735], Loss: 0.0336\n",
      "Epoch [39/50], Step [395/735], Loss: 0.0655\n",
      "Epoch [39/50], Step [396/735], Loss: 0.1019\n",
      "Epoch [39/50], Step [397/735], Loss: 0.0672\n",
      "Epoch [39/50], Step [398/735], Loss: 0.0673\n",
      "Epoch [39/50], Step [399/735], Loss: 0.0507\n",
      "Epoch [39/50], Step [400/735], Loss: 0.0305\n",
      "Epoch [39/50], Step [401/735], Loss: 0.0546\n",
      "Epoch [39/50], Step [402/735], Loss: 0.0594\n",
      "Epoch [39/50], Step [403/735], Loss: 0.0566\n",
      "Epoch [39/50], Step [404/735], Loss: 0.0329\n",
      "Epoch [39/50], Step [405/735], Loss: 0.0796\n",
      "Epoch [39/50], Step [406/735], Loss: 0.1165\n",
      "Epoch [39/50], Step [407/735], Loss: 0.0330\n",
      "Epoch [39/50], Step [408/735], Loss: 0.0338\n",
      "Epoch [39/50], Step [409/735], Loss: 0.0818\n",
      "Epoch [39/50], Step [410/735], Loss: 0.0395\n",
      "Epoch [39/50], Step [411/735], Loss: 0.0195\n",
      "Epoch [39/50], Step [412/735], Loss: 0.0569\n",
      "Epoch [39/50], Step [413/735], Loss: 0.0827\n",
      "Epoch [39/50], Step [414/735], Loss: 0.0413\n",
      "Epoch [39/50], Step [415/735], Loss: 0.0497\n",
      "Epoch [39/50], Step [416/735], Loss: 0.0204\n",
      "Epoch [39/50], Step [417/735], Loss: 0.0597\n",
      "Epoch [39/50], Step [418/735], Loss: 0.0572\n",
      "Epoch [39/50], Step [419/735], Loss: 0.0337\n",
      "Epoch [39/50], Step [420/735], Loss: 0.0284\n",
      "Epoch [39/50], Step [421/735], Loss: 0.0325\n",
      "Epoch [39/50], Step [422/735], Loss: 0.0208\n",
      "Epoch [39/50], Step [423/735], Loss: 0.0283\n",
      "Epoch [39/50], Step [424/735], Loss: 0.0418\n",
      "Epoch [39/50], Step [425/735], Loss: 0.0810\n",
      "Epoch [39/50], Step [426/735], Loss: 0.1163\n",
      "Epoch [39/50], Step [427/735], Loss: 0.0592\n",
      "Epoch [39/50], Step [428/735], Loss: 0.0208\n",
      "Epoch [39/50], Step [429/735], Loss: 0.0480\n",
      "Epoch [39/50], Step [430/735], Loss: 0.0556\n",
      "Epoch [39/50], Step [431/735], Loss: 0.0451\n",
      "Epoch [39/50], Step [432/735], Loss: 0.0410\n",
      "Epoch [39/50], Step [433/735], Loss: 0.1823\n",
      "Epoch [39/50], Step [434/735], Loss: 0.0361\n",
      "Epoch [39/50], Step [435/735], Loss: 0.0610\n",
      "Epoch [39/50], Step [436/735], Loss: 0.0368\n",
      "Epoch [39/50], Step [437/735], Loss: 0.0235\n",
      "Epoch [39/50], Step [438/735], Loss: 0.0888\n",
      "Epoch [39/50], Step [439/735], Loss: 0.1060\n",
      "Epoch [39/50], Step [440/735], Loss: 0.0256\n",
      "Epoch [39/50], Step [441/735], Loss: 0.0511\n",
      "Epoch [39/50], Step [442/735], Loss: 0.0585\n",
      "Epoch [39/50], Step [443/735], Loss: 0.0327\n",
      "Epoch [39/50], Step [444/735], Loss: 0.0507\n",
      "Epoch [39/50], Step [445/735], Loss: 0.0310\n",
      "Epoch [39/50], Step [446/735], Loss: 0.0718\n",
      "Epoch [39/50], Step [447/735], Loss: 0.0211\n",
      "Epoch [39/50], Step [448/735], Loss: 0.0791\n",
      "Epoch [39/50], Step [449/735], Loss: 0.0611\n",
      "Epoch [39/50], Step [450/735], Loss: 0.0471\n",
      "Epoch [39/50], Step [451/735], Loss: 0.0468\n",
      "Epoch [39/50], Step [452/735], Loss: 0.0459\n",
      "Epoch [39/50], Step [453/735], Loss: 0.0453\n",
      "Epoch [39/50], Step [454/735], Loss: 0.1151\n",
      "Epoch [39/50], Step [455/735], Loss: 0.0366\n",
      "Epoch [39/50], Step [456/735], Loss: 0.0271\n",
      "Epoch [39/50], Step [457/735], Loss: 0.0489\n",
      "Epoch [39/50], Step [458/735], Loss: 0.0878\n",
      "Epoch [39/50], Step [459/735], Loss: 0.0838\n",
      "Epoch [39/50], Step [460/735], Loss: 0.0462\n",
      "Epoch [39/50], Step [461/735], Loss: 0.0602\n",
      "Epoch [39/50], Step [462/735], Loss: 0.0234\n",
      "Epoch [39/50], Step [463/735], Loss: 0.3925\n",
      "Epoch [39/50], Step [464/735], Loss: 0.0486\n",
      "Epoch [39/50], Step [465/735], Loss: 0.0520\n",
      "Epoch [39/50], Step [466/735], Loss: 0.0511\n",
      "Epoch [39/50], Step [467/735], Loss: 0.0328\n",
      "Epoch [39/50], Step [468/735], Loss: 0.0778\n",
      "Epoch [39/50], Step [469/735], Loss: 0.0668\n",
      "Epoch [39/50], Step [470/735], Loss: 0.0668\n",
      "Epoch [39/50], Step [471/735], Loss: 0.0505\n",
      "Epoch [39/50], Step [472/735], Loss: 0.2261\n",
      "Epoch [39/50], Step [473/735], Loss: 0.1229\n",
      "Epoch [39/50], Step [474/735], Loss: 0.0184\n",
      "Epoch [39/50], Step [475/735], Loss: 0.0748\n",
      "Epoch [39/50], Step [476/735], Loss: 0.0435\n",
      "Epoch [39/50], Step [477/735], Loss: 0.0999\n",
      "Epoch [39/50], Step [478/735], Loss: 0.0328\n",
      "Epoch [39/50], Step [479/735], Loss: 0.0306\n",
      "Epoch [39/50], Step [480/735], Loss: 0.0320\n",
      "Epoch [39/50], Step [481/735], Loss: 0.0880\n",
      "Epoch [39/50], Step [482/735], Loss: 0.1186\n",
      "Epoch [39/50], Step [483/735], Loss: 0.0341\n",
      "Epoch [39/50], Step [484/735], Loss: 0.1185\n",
      "Epoch [39/50], Step [485/735], Loss: 0.0635\n",
      "Epoch [39/50], Step [486/735], Loss: 0.0482\n",
      "Epoch [39/50], Step [487/735], Loss: 0.0123\n",
      "Epoch [39/50], Step [488/735], Loss: 0.0265\n",
      "Epoch [39/50], Step [489/735], Loss: 0.0400\n",
      "Epoch [39/50], Step [490/735], Loss: 0.0471\n",
      "Epoch [39/50], Step [491/735], Loss: 0.0695\n",
      "Epoch [39/50], Step [492/735], Loss: 0.0351\n",
      "Epoch [39/50], Step [493/735], Loss: 0.0528\n",
      "Epoch [39/50], Step [494/735], Loss: 0.0169\n",
      "Epoch [39/50], Step [495/735], Loss: 0.2224\n",
      "Epoch [39/50], Step [496/735], Loss: 0.0406\n",
      "Epoch [39/50], Step [497/735], Loss: 0.0686\n",
      "Epoch [39/50], Step [498/735], Loss: 0.1986\n",
      "Epoch [39/50], Step [499/735], Loss: 0.0481\n",
      "Epoch [39/50], Step [500/735], Loss: 0.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Step [501/735], Loss: 0.0777\n",
      "Epoch [39/50], Step [502/735], Loss: 0.1385\n",
      "Epoch [39/50], Step [503/735], Loss: 0.0478\n",
      "Epoch [39/50], Step [504/735], Loss: 0.0677\n",
      "Epoch [39/50], Step [505/735], Loss: 0.0351\n",
      "Epoch [39/50], Step [506/735], Loss: 0.1677\n",
      "Epoch [39/50], Step [507/735], Loss: 0.0690\n",
      "Epoch [39/50], Step [508/735], Loss: 0.0160\n",
      "Epoch [39/50], Step [509/735], Loss: 0.0495\n",
      "Epoch [39/50], Step [510/735], Loss: 0.0133\n",
      "Epoch [39/50], Step [511/735], Loss: 0.0278\n",
      "Epoch [39/50], Step [512/735], Loss: 0.0349\n",
      "Epoch [39/50], Step [513/735], Loss: 0.0447\n",
      "Epoch [39/50], Step [514/735], Loss: 0.0473\n",
      "Epoch [39/50], Step [515/735], Loss: 0.0337\n",
      "Epoch [39/50], Step [516/735], Loss: 0.0606\n",
      "Epoch [39/50], Step [517/735], Loss: 0.0596\n",
      "Epoch [39/50], Step [518/735], Loss: 0.0193\n",
      "Epoch [39/50], Step [519/735], Loss: 0.1019\n",
      "Epoch [39/50], Step [520/735], Loss: 0.3492\n",
      "Epoch [39/50], Step [521/735], Loss: 0.1126\n",
      "Epoch [39/50], Step [522/735], Loss: 0.1232\n",
      "Epoch [39/50], Step [523/735], Loss: 0.0353\n",
      "Epoch [39/50], Step [524/735], Loss: 0.0267\n",
      "Epoch [39/50], Step [525/735], Loss: 0.0416\n",
      "Epoch [39/50], Step [526/735], Loss: 0.0291\n",
      "Epoch [39/50], Step [527/735], Loss: 0.0312\n",
      "Epoch [39/50], Step [528/735], Loss: 0.3782\n",
      "Epoch [39/50], Step [529/735], Loss: 0.0401\n",
      "Epoch [39/50], Step [530/735], Loss: 0.0634\n",
      "Epoch [39/50], Step [531/735], Loss: 0.0338\n",
      "Epoch [39/50], Step [532/735], Loss: 0.0511\n",
      "Epoch [39/50], Step [533/735], Loss: 0.0384\n",
      "Epoch [39/50], Step [534/735], Loss: 0.0393\n",
      "Epoch [39/50], Step [535/735], Loss: 0.0350\n",
      "Epoch [39/50], Step [536/735], Loss: 0.0767\n",
      "Epoch [39/50], Step [537/735], Loss: 0.0564\n",
      "Epoch [39/50], Step [538/735], Loss: 0.0388\n",
      "Epoch [39/50], Step [539/735], Loss: 0.0554\n",
      "Epoch [39/50], Step [540/735], Loss: 0.0368\n",
      "Epoch [39/50], Step [541/735], Loss: 0.0300\n",
      "Epoch [39/50], Step [542/735], Loss: 0.0437\n",
      "Epoch [39/50], Step [543/735], Loss: 0.0290\n",
      "Epoch [39/50], Step [544/735], Loss: 0.0510\n",
      "Epoch [39/50], Step [545/735], Loss: 0.0374\n",
      "Epoch [39/50], Step [546/735], Loss: 0.0236\n",
      "Epoch [39/50], Step [547/735], Loss: 0.0625\n",
      "Epoch [39/50], Step [548/735], Loss: 0.0651\n",
      "Epoch [39/50], Step [549/735], Loss: 0.0890\n",
      "Epoch [39/50], Step [550/735], Loss: 0.0170\n",
      "Epoch [39/50], Step [551/735], Loss: 0.0306\n",
      "Epoch [39/50], Step [552/735], Loss: 0.0312\n",
      "Epoch [39/50], Step [553/735], Loss: 0.0330\n",
      "Epoch [39/50], Step [554/735], Loss: 0.0549\n",
      "Epoch [39/50], Step [555/735], Loss: 0.0454\n",
      "Epoch [39/50], Step [556/735], Loss: 0.0354\n",
      "Epoch [39/50], Step [557/735], Loss: 0.1168\n",
      "Epoch [39/50], Step [558/735], Loss: 0.0920\n",
      "Epoch [39/50], Step [559/735], Loss: 0.0732\n",
      "Epoch [39/50], Step [560/735], Loss: 0.0767\n",
      "Epoch [39/50], Step [561/735], Loss: 0.0245\n",
      "Epoch [39/50], Step [562/735], Loss: 0.0539\n",
      "Epoch [39/50], Step [563/735], Loss: 0.0272\n",
      "Epoch [39/50], Step [564/735], Loss: 0.0315\n",
      "Epoch [39/50], Step [565/735], Loss: 0.0386\n",
      "Epoch [39/50], Step [566/735], Loss: 0.1679\n",
      "Epoch [39/50], Step [567/735], Loss: 0.0413\n",
      "Epoch [39/50], Step [568/735], Loss: 0.0497\n",
      "Epoch [39/50], Step [569/735], Loss: 0.0918\n",
      "Epoch [39/50], Step [570/735], Loss: 0.0399\n",
      "Epoch [39/50], Step [571/735], Loss: 0.0486\n",
      "Epoch [39/50], Step [572/735], Loss: 0.0614\n",
      "Epoch [39/50], Step [573/735], Loss: 0.0130\n",
      "Epoch [39/50], Step [574/735], Loss: 0.0901\n",
      "Epoch [39/50], Step [575/735], Loss: 0.1267\n",
      "Epoch [39/50], Step [576/735], Loss: 0.0731\n",
      "Epoch [39/50], Step [577/735], Loss: 0.0331\n",
      "Epoch [39/50], Step [578/735], Loss: 0.0477\n",
      "Epoch [39/50], Step [579/735], Loss: 0.1406\n",
      "Epoch [39/50], Step [580/735], Loss: 0.2383\n",
      "Epoch [39/50], Step [581/735], Loss: 0.0576\n",
      "Epoch [39/50], Step [582/735], Loss: 0.0504\n",
      "Epoch [39/50], Step [583/735], Loss: 0.0703\n",
      "Epoch [39/50], Step [584/735], Loss: 0.0296\n",
      "Epoch [39/50], Step [585/735], Loss: 0.0323\n",
      "Epoch [39/50], Step [586/735], Loss: 0.0309\n",
      "Epoch [39/50], Step [587/735], Loss: 0.0197\n",
      "Epoch [39/50], Step [588/735], Loss: 0.0353\n",
      "Epoch [39/50], Step [589/735], Loss: 0.0160\n",
      "Epoch [39/50], Step [590/735], Loss: 0.0369\n",
      "Epoch [39/50], Step [591/735], Loss: 0.0107\n",
      "Epoch [39/50], Step [592/735], Loss: 0.0718\n",
      "Epoch [39/50], Step [593/735], Loss: 0.0431\n",
      "Epoch [39/50], Step [594/735], Loss: 0.0259\n",
      "Epoch [39/50], Step [595/735], Loss: 0.0406\n",
      "Epoch [39/50], Step [596/735], Loss: 0.2467\n",
      "Epoch [39/50], Step [597/735], Loss: 0.0239\n",
      "Epoch [39/50], Step [598/735], Loss: 0.0377\n",
      "Epoch [39/50], Step [599/735], Loss: 0.0588\n",
      "Epoch [39/50], Step [600/735], Loss: 0.0689\n",
      "Epoch [39/50], Step [601/735], Loss: 0.0398\n",
      "Epoch [39/50], Step [602/735], Loss: 0.0408\n",
      "Epoch [39/50], Step [603/735], Loss: 0.0292\n",
      "Epoch [39/50], Step [604/735], Loss: 0.0810\n",
      "Epoch [39/50], Step [605/735], Loss: 0.1759\n",
      "Epoch [39/50], Step [606/735], Loss: 0.0367\n",
      "Epoch [39/50], Step [607/735], Loss: 0.0356\n",
      "Epoch [39/50], Step [608/735], Loss: 0.0196\n",
      "Epoch [39/50], Step [609/735], Loss: 0.0490\n",
      "Epoch [39/50], Step [610/735], Loss: 0.0905\n",
      "Epoch [39/50], Step [611/735], Loss: 0.1535\n",
      "Epoch [39/50], Step [612/735], Loss: 0.3598\n",
      "Epoch [39/50], Step [613/735], Loss: 0.0763\n",
      "Epoch [39/50], Step [614/735], Loss: 0.0263\n",
      "Epoch [39/50], Step [615/735], Loss: 0.0568\n",
      "Epoch [39/50], Step [616/735], Loss: 0.0222\n",
      "Epoch [39/50], Step [617/735], Loss: 0.0449\n",
      "Epoch [39/50], Step [618/735], Loss: 0.0989\n",
      "Epoch [39/50], Step [619/735], Loss: 0.2425\n",
      "Epoch [39/50], Step [620/735], Loss: 0.0785\n",
      "Epoch [39/50], Step [621/735], Loss: 0.0330\n",
      "Epoch [39/50], Step [622/735], Loss: 0.1454\n",
      "Epoch [39/50], Step [623/735], Loss: 0.1562\n",
      "Epoch [39/50], Step [624/735], Loss: 0.0601\n",
      "Epoch [39/50], Step [625/735], Loss: 0.0387\n",
      "Epoch [39/50], Step [626/735], Loss: 0.0408\n",
      "Epoch [39/50], Step [627/735], Loss: 0.0470\n",
      "Epoch [39/50], Step [628/735], Loss: 0.0477\n",
      "Epoch [39/50], Step [629/735], Loss: 0.1208\n",
      "Epoch [39/50], Step [630/735], Loss: 0.0151\n",
      "Epoch [39/50], Step [631/735], Loss: 0.0637\n",
      "Epoch [39/50], Step [632/735], Loss: 0.1512\n",
      "Epoch [39/50], Step [633/735], Loss: 0.0800\n",
      "Epoch [39/50], Step [634/735], Loss: 0.0721\n",
      "Epoch [39/50], Step [635/735], Loss: 0.0207\n",
      "Epoch [39/50], Step [636/735], Loss: 0.1307\n",
      "Epoch [39/50], Step [637/735], Loss: 0.0537\n",
      "Epoch [39/50], Step [638/735], Loss: 0.0522\n",
      "Epoch [39/50], Step [639/735], Loss: 0.0517\n",
      "Epoch [39/50], Step [640/735], Loss: 0.0668\n",
      "Epoch [39/50], Step [641/735], Loss: 0.1478\n",
      "Epoch [39/50], Step [642/735], Loss: 0.0384\n",
      "Epoch [39/50], Step [643/735], Loss: 0.1083\n",
      "Epoch [39/50], Step [644/735], Loss: 0.0154\n",
      "Epoch [39/50], Step [645/735], Loss: 0.0533\n",
      "Epoch [39/50], Step [646/735], Loss: 0.0432\n",
      "Epoch [39/50], Step [647/735], Loss: 0.0220\n",
      "Epoch [39/50], Step [648/735], Loss: 0.0906\n",
      "Epoch [39/50], Step [649/735], Loss: 0.0477\n",
      "Epoch [39/50], Step [650/735], Loss: 0.0691\n",
      "Epoch [39/50], Step [651/735], Loss: 0.0774\n",
      "Epoch [39/50], Step [652/735], Loss: 0.1238\n",
      "Epoch [39/50], Step [653/735], Loss: 0.0264\n",
      "Epoch [39/50], Step [654/735], Loss: 0.0303\n",
      "Epoch [39/50], Step [655/735], Loss: 0.0344\n",
      "Epoch [39/50], Step [656/735], Loss: 0.0415\n",
      "Epoch [39/50], Step [657/735], Loss: 0.0497\n",
      "Epoch [39/50], Step [658/735], Loss: 0.0456\n",
      "Epoch [39/50], Step [659/735], Loss: 0.0224\n",
      "Epoch [39/50], Step [660/735], Loss: 0.0789\n",
      "Epoch [39/50], Step [661/735], Loss: 0.0306\n",
      "Epoch [39/50], Step [662/735], Loss: 0.1050\n",
      "Epoch [39/50], Step [663/735], Loss: 0.0348\n",
      "Epoch [39/50], Step [664/735], Loss: 0.0322\n",
      "Epoch [39/50], Step [665/735], Loss: 0.0294\n",
      "Epoch [39/50], Step [666/735], Loss: 0.0281\n",
      "Epoch [39/50], Step [667/735], Loss: 0.0344\n",
      "Epoch [39/50], Step [668/735], Loss: 0.0653\n",
      "Epoch [39/50], Step [669/735], Loss: 0.0650\n",
      "Epoch [39/50], Step [670/735], Loss: 0.0499\n",
      "Epoch [39/50], Step [671/735], Loss: 0.0341\n",
      "Epoch [39/50], Step [672/735], Loss: 0.0238\n",
      "Epoch [39/50], Step [673/735], Loss: 0.0196\n",
      "Epoch [39/50], Step [674/735], Loss: 0.0156\n",
      "Epoch [39/50], Step [675/735], Loss: 0.0199\n",
      "Epoch [39/50], Step [676/735], Loss: 0.0370\n",
      "Epoch [39/50], Step [677/735], Loss: 0.0222\n",
      "Epoch [39/50], Step [678/735], Loss: 0.0821\n",
      "Epoch [39/50], Step [679/735], Loss: 0.1838\n",
      "Epoch [39/50], Step [680/735], Loss: 0.0156\n",
      "Epoch [39/50], Step [681/735], Loss: 0.0798\n",
      "Epoch [39/50], Step [682/735], Loss: 0.0370\n",
      "Epoch [39/50], Step [683/735], Loss: 0.0276\n",
      "Epoch [39/50], Step [684/735], Loss: 0.0298\n",
      "Epoch [39/50], Step [685/735], Loss: 0.0240\n",
      "Epoch [39/50], Step [686/735], Loss: 0.0284\n",
      "Epoch [39/50], Step [687/735], Loss: 0.0795\n",
      "Epoch [39/50], Step [688/735], Loss: 0.0343\n",
      "Epoch [39/50], Step [689/735], Loss: 0.0274\n",
      "Epoch [39/50], Step [690/735], Loss: 0.0738\n",
      "Epoch [39/50], Step [691/735], Loss: 0.0563\n",
      "Epoch [39/50], Step [692/735], Loss: 0.0295\n",
      "Epoch [39/50], Step [693/735], Loss: 0.0165\n",
      "Epoch [39/50], Step [694/735], Loss: 0.0858\n",
      "Epoch [39/50], Step [695/735], Loss: 0.0383\n",
      "Epoch [39/50], Step [696/735], Loss: 0.1067\n",
      "Epoch [39/50], Step [697/735], Loss: 0.0783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Step [698/735], Loss: 0.0477\n",
      "Epoch [39/50], Step [699/735], Loss: 0.0737\n",
      "Epoch [39/50], Step [700/735], Loss: 0.0899\n",
      "Epoch [39/50], Step [701/735], Loss: 0.0954\n",
      "Epoch [39/50], Step [702/735], Loss: 0.0549\n",
      "Epoch [39/50], Step [703/735], Loss: 0.1100\n",
      "Epoch [39/50], Step [704/735], Loss: 0.0513\n",
      "Epoch [39/50], Step [705/735], Loss: 0.0422\n",
      "Epoch [39/50], Step [706/735], Loss: 0.0265\n",
      "Epoch [39/50], Step [707/735], Loss: 0.0608\n",
      "Epoch [39/50], Step [708/735], Loss: 0.0818\n",
      "Epoch [39/50], Step [709/735], Loss: 0.0602\n",
      "Epoch [39/50], Step [710/735], Loss: 0.0185\n",
      "Epoch [39/50], Step [711/735], Loss: 0.0322\n",
      "Epoch [39/50], Step [712/735], Loss: 0.0353\n",
      "Epoch [39/50], Step [713/735], Loss: 0.0719\n",
      "Epoch [39/50], Step [714/735], Loss: 0.1026\n",
      "Epoch [39/50], Step [715/735], Loss: 0.0458\n",
      "Epoch [39/50], Step [716/735], Loss: 0.0397\n",
      "Epoch [39/50], Step [717/735], Loss: 0.0420\n",
      "Epoch [39/50], Step [718/735], Loss: 0.0522\n",
      "Epoch [39/50], Step [719/735], Loss: 0.0178\n",
      "Epoch [39/50], Step [720/735], Loss: 0.0517\n",
      "Epoch [39/50], Step [721/735], Loss: 0.0822\n",
      "Epoch [39/50], Step [722/735], Loss: 0.0382\n",
      "Epoch [39/50], Step [723/735], Loss: 0.0521\n",
      "Epoch [39/50], Step [724/735], Loss: 0.0297\n",
      "Epoch [39/50], Step [725/735], Loss: 0.0782\n",
      "Epoch [39/50], Step [726/735], Loss: 0.0152\n",
      "Epoch [39/50], Step [727/735], Loss: 0.0278\n",
      "Epoch [39/50], Step [728/735], Loss: 0.0395\n",
      "Epoch [39/50], Step [729/735], Loss: 0.0627\n",
      "Epoch [39/50], Step [730/735], Loss: 0.1313\n",
      "Epoch [39/50], Step [731/735], Loss: 0.0245\n",
      "Epoch [39/50], Step [732/735], Loss: 0.0313\n",
      "Epoch [39/50], Step [733/735], Loss: 0.0870\n",
      "Epoch [39/50], Step [734/735], Loss: 0.1860\n",
      "Epoch [39/50], Step [735/735], Loss: 0.0076\n",
      "Epoch [40/50], Step [1/735], Loss: 0.0136\n",
      "Epoch [40/50], Step [2/735], Loss: 0.0572\n",
      "Epoch [40/50], Step [3/735], Loss: 0.0318\n",
      "Epoch [40/50], Step [4/735], Loss: 0.0274\n",
      "Epoch [40/50], Step [5/735], Loss: 0.0456\n",
      "Epoch [40/50], Step [6/735], Loss: 0.0276\n",
      "Epoch [40/50], Step [7/735], Loss: 0.0421\n",
      "Epoch [40/50], Step [8/735], Loss: 0.0340\n",
      "Epoch [40/50], Step [9/735], Loss: 0.0241\n",
      "Epoch [40/50], Step [10/735], Loss: 0.0375\n",
      "Epoch [40/50], Step [11/735], Loss: 0.0473\n",
      "Epoch [40/50], Step [12/735], Loss: 0.0272\n",
      "Epoch [40/50], Step [13/735], Loss: 0.0657\n",
      "Epoch [40/50], Step [14/735], Loss: 0.0585\n",
      "Epoch [40/50], Step [15/735], Loss: 0.0183\n",
      "Epoch [40/50], Step [16/735], Loss: 0.0877\n",
      "Epoch [40/50], Step [17/735], Loss: 0.0440\n",
      "Epoch [40/50], Step [18/735], Loss: 0.0490\n",
      "Epoch [40/50], Step [19/735], Loss: 0.0789\n",
      "Epoch [40/50], Step [20/735], Loss: 0.0945\n",
      "Epoch [40/50], Step [21/735], Loss: 0.0980\n",
      "Epoch [40/50], Step [22/735], Loss: 0.0280\n",
      "Epoch [40/50], Step [23/735], Loss: 0.0106\n",
      "Epoch [40/50], Step [24/735], Loss: 0.0321\n",
      "Epoch [40/50], Step [25/735], Loss: 0.0452\n",
      "Epoch [40/50], Step [26/735], Loss: 0.1135\n",
      "Epoch [40/50], Step [27/735], Loss: 0.0164\n",
      "Epoch [40/50], Step [28/735], Loss: 0.0670\n",
      "Epoch [40/50], Step [29/735], Loss: 0.1842\n",
      "Epoch [40/50], Step [30/735], Loss: 0.0530\n",
      "Epoch [40/50], Step [31/735], Loss: 0.0160\n",
      "Epoch [40/50], Step [32/735], Loss: 0.0581\n",
      "Epoch [40/50], Step [33/735], Loss: 0.1067\n",
      "Epoch [40/50], Step [34/735], Loss: 0.0835\n",
      "Epoch [40/50], Step [35/735], Loss: 0.4086\n",
      "Epoch [40/50], Step [36/735], Loss: 0.0865\n",
      "Epoch [40/50], Step [37/735], Loss: 0.0268\n",
      "Epoch [40/50], Step [38/735], Loss: 0.1006\n",
      "Epoch [40/50], Step [39/735], Loss: 0.0196\n",
      "Epoch [40/50], Step [40/735], Loss: 0.0333\n",
      "Epoch [40/50], Step [41/735], Loss: 0.0362\n",
      "Epoch [40/50], Step [42/735], Loss: 0.0618\n",
      "Epoch [40/50], Step [43/735], Loss: 0.0280\n",
      "Epoch [40/50], Step [44/735], Loss: 0.0462\n",
      "Epoch [40/50], Step [45/735], Loss: 0.0216\n",
      "Epoch [40/50], Step [46/735], Loss: 0.0902\n",
      "Epoch [40/50], Step [47/735], Loss: 0.0246\n",
      "Epoch [40/50], Step [48/735], Loss: 0.0337\n",
      "Epoch [40/50], Step [49/735], Loss: 0.0630\n",
      "Epoch [40/50], Step [50/735], Loss: 0.0476\n",
      "Epoch [40/50], Step [51/735], Loss: 0.0858\n",
      "Epoch [40/50], Step [52/735], Loss: 0.3387\n",
      "Epoch [40/50], Step [53/735], Loss: 0.0390\n",
      "Epoch [40/50], Step [54/735], Loss: 0.2196\n",
      "Epoch [40/50], Step [55/735], Loss: 0.0307\n",
      "Epoch [40/50], Step [56/735], Loss: 0.0939\n",
      "Epoch [40/50], Step [57/735], Loss: 0.0820\n",
      "Epoch [40/50], Step [58/735], Loss: 0.0334\n",
      "Epoch [40/50], Step [59/735], Loss: 0.0461\n",
      "Epoch [40/50], Step [60/735], Loss: 0.0606\n",
      "Epoch [40/50], Step [61/735], Loss: 0.1031\n",
      "Epoch [40/50], Step [62/735], Loss: 0.1474\n",
      "Epoch [40/50], Step [63/735], Loss: 0.0434\n",
      "Epoch [40/50], Step [64/735], Loss: 0.0516\n",
      "Epoch [40/50], Step [65/735], Loss: 0.0525\n",
      "Epoch [40/50], Step [66/735], Loss: 0.0329\n",
      "Epoch [40/50], Step [67/735], Loss: 0.0333\n",
      "Epoch [40/50], Step [68/735], Loss: 0.0186\n",
      "Epoch [40/50], Step [69/735], Loss: 0.0502\n",
      "Epoch [40/50], Step [70/735], Loss: 0.0908\n",
      "Epoch [40/50], Step [71/735], Loss: 0.0801\n",
      "Epoch [40/50], Step [72/735], Loss: 0.1575\n",
      "Epoch [40/50], Step [73/735], Loss: 0.0448\n",
      "Epoch [40/50], Step [74/735], Loss: 0.0534\n",
      "Epoch [40/50], Step [75/735], Loss: 0.0766\n",
      "Epoch [40/50], Step [76/735], Loss: 0.0137\n",
      "Epoch [40/50], Step [77/735], Loss: 0.0249\n",
      "Epoch [40/50], Step [78/735], Loss: 0.0416\n",
      "Epoch [40/50], Step [79/735], Loss: 0.0267\n",
      "Epoch [40/50], Step [80/735], Loss: 0.0375\n",
      "Epoch [40/50], Step [81/735], Loss: 0.0345\n",
      "Epoch [40/50], Step [82/735], Loss: 0.0207\n",
      "Epoch [40/50], Step [83/735], Loss: 0.0461\n",
      "Epoch [40/50], Step [84/735], Loss: 0.0722\n",
      "Epoch [40/50], Step [85/735], Loss: 0.2348\n",
      "Epoch [40/50], Step [86/735], Loss: 0.0721\n",
      "Epoch [40/50], Step [87/735], Loss: 0.0175\n",
      "Epoch [40/50], Step [88/735], Loss: 0.0468\n",
      "Epoch [40/50], Step [89/735], Loss: 0.0679\n",
      "Epoch [40/50], Step [90/735], Loss: 0.0463\n",
      "Epoch [40/50], Step [91/735], Loss: 0.0216\n",
      "Epoch [40/50], Step [92/735], Loss: 0.0329\n",
      "Epoch [40/50], Step [93/735], Loss: 0.0283\n",
      "Epoch [40/50], Step [94/735], Loss: 0.0191\n",
      "Epoch [40/50], Step [95/735], Loss: 0.0479\n",
      "Epoch [40/50], Step [96/735], Loss: 0.3935\n",
      "Epoch [40/50], Step [97/735], Loss: 0.0221\n",
      "Epoch [40/50], Step [98/735], Loss: 0.0223\n",
      "Epoch [40/50], Step [99/735], Loss: 0.0377\n",
      "Epoch [40/50], Step [100/735], Loss: 0.0539\n",
      "Epoch [40/50], Step [101/735], Loss: 0.1648\n",
      "Epoch [40/50], Step [102/735], Loss: 0.0181\n",
      "Epoch [40/50], Step [103/735], Loss: 0.0329\n",
      "Epoch [40/50], Step [104/735], Loss: 0.0209\n",
      "Epoch [40/50], Step [105/735], Loss: 0.0167\n",
      "Epoch [40/50], Step [106/735], Loss: 0.0170\n",
      "Epoch [40/50], Step [107/735], Loss: 0.4545\n",
      "Epoch [40/50], Step [108/735], Loss: 0.0483\n",
      "Epoch [40/50], Step [109/735], Loss: 0.0297\n",
      "Epoch [40/50], Step [110/735], Loss: 0.0758\n",
      "Epoch [40/50], Step [111/735], Loss: 0.0216\n",
      "Epoch [40/50], Step [112/735], Loss: 0.0636\n",
      "Epoch [40/50], Step [113/735], Loss: 0.0452\n",
      "Epoch [40/50], Step [114/735], Loss: 0.0604\n",
      "Epoch [40/50], Step [115/735], Loss: 0.2124\n",
      "Epoch [40/50], Step [116/735], Loss: 0.0350\n",
      "Epoch [40/50], Step [117/735], Loss: 0.0594\n",
      "Epoch [40/50], Step [118/735], Loss: 0.1082\n",
      "Epoch [40/50], Step [119/735], Loss: 0.0220\n",
      "Epoch [40/50], Step [120/735], Loss: 0.0523\n",
      "Epoch [40/50], Step [121/735], Loss: 0.0491\n",
      "Epoch [40/50], Step [122/735], Loss: 0.0940\n",
      "Epoch [40/50], Step [123/735], Loss: 0.0806\n",
      "Epoch [40/50], Step [124/735], Loss: 0.1279\n",
      "Epoch [40/50], Step [125/735], Loss: 0.0532\n",
      "Epoch [40/50], Step [126/735], Loss: 0.0378\n",
      "Epoch [40/50], Step [127/735], Loss: 0.0738\n",
      "Epoch [40/50], Step [128/735], Loss: 0.0926\n",
      "Epoch [40/50], Step [129/735], Loss: 0.1636\n",
      "Epoch [40/50], Step [130/735], Loss: 0.1071\n",
      "Epoch [40/50], Step [131/735], Loss: 0.0367\n",
      "Epoch [40/50], Step [132/735], Loss: 0.0409\n",
      "Epoch [40/50], Step [133/735], Loss: 0.0557\n",
      "Epoch [40/50], Step [134/735], Loss: 0.2156\n",
      "Epoch [40/50], Step [135/735], Loss: 0.0359\n",
      "Epoch [40/50], Step [136/735], Loss: 0.0674\n",
      "Epoch [40/50], Step [137/735], Loss: 0.0251\n",
      "Epoch [40/50], Step [138/735], Loss: 0.1312\n",
      "Epoch [40/50], Step [139/735], Loss: 0.0301\n",
      "Epoch [40/50], Step [140/735], Loss: 0.1787\n",
      "Epoch [40/50], Step [141/735], Loss: 0.0659\n",
      "Epoch [40/50], Step [142/735], Loss: 0.0660\n",
      "Epoch [40/50], Step [143/735], Loss: 0.0359\n",
      "Epoch [40/50], Step [144/735], Loss: 0.0318\n",
      "Epoch [40/50], Step [145/735], Loss: 0.0255\n",
      "Epoch [40/50], Step [146/735], Loss: 0.0785\n",
      "Epoch [40/50], Step [147/735], Loss: 0.0522\n",
      "Epoch [40/50], Step [148/735], Loss: 0.0138\n",
      "Epoch [40/50], Step [149/735], Loss: 0.0270\n",
      "Epoch [40/50], Step [150/735], Loss: 0.0377\n",
      "Epoch [40/50], Step [151/735], Loss: 0.1486\n",
      "Epoch [40/50], Step [152/735], Loss: 0.0216\n",
      "Epoch [40/50], Step [153/735], Loss: 0.1207\n",
      "Epoch [40/50], Step [154/735], Loss: 0.0292\n",
      "Epoch [40/50], Step [155/735], Loss: 0.3401\n",
      "Epoch [40/50], Step [156/735], Loss: 0.0459\n",
      "Epoch [40/50], Step [157/735], Loss: 0.0488\n",
      "Epoch [40/50], Step [158/735], Loss: 0.0450\n",
      "Epoch [40/50], Step [159/735], Loss: 0.0484\n",
      "Epoch [40/50], Step [160/735], Loss: 0.0922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Step [161/735], Loss: 0.1247\n",
      "Epoch [40/50], Step [162/735], Loss: 0.0403\n",
      "Epoch [40/50], Step [163/735], Loss: 0.0682\n",
      "Epoch [40/50], Step [164/735], Loss: 0.1023\n",
      "Epoch [40/50], Step [165/735], Loss: 0.0215\n",
      "Epoch [40/50], Step [166/735], Loss: 0.1276\n",
      "Epoch [40/50], Step [167/735], Loss: 0.0434\n",
      "Epoch [40/50], Step [168/735], Loss: 0.0507\n",
      "Epoch [40/50], Step [169/735], Loss: 0.0945\n",
      "Epoch [40/50], Step [170/735], Loss: 0.0593\n",
      "Epoch [40/50], Step [171/735], Loss: 0.0714\n",
      "Epoch [40/50], Step [172/735], Loss: 0.0344\n",
      "Epoch [40/50], Step [173/735], Loss: 0.0168\n",
      "Epoch [40/50], Step [174/735], Loss: 0.0405\n",
      "Epoch [40/50], Step [175/735], Loss: 0.0824\n",
      "Epoch [40/50], Step [176/735], Loss: 0.0519\n",
      "Epoch [40/50], Step [177/735], Loss: 0.0438\n",
      "Epoch [40/50], Step [178/735], Loss: 0.0854\n",
      "Epoch [40/50], Step [179/735], Loss: 0.0360\n",
      "Epoch [40/50], Step [180/735], Loss: 0.0275\n",
      "Epoch [40/50], Step [181/735], Loss: 0.0161\n",
      "Epoch [40/50], Step [182/735], Loss: 0.0301\n",
      "Epoch [40/50], Step [183/735], Loss: 0.0290\n",
      "Epoch [40/50], Step [184/735], Loss: 0.2216\n",
      "Epoch [40/50], Step [185/735], Loss: 0.0238\n",
      "Epoch [40/50], Step [186/735], Loss: 0.0320\n",
      "Epoch [40/50], Step [187/735], Loss: 0.0486\n",
      "Epoch [40/50], Step [188/735], Loss: 0.0225\n",
      "Epoch [40/50], Step [189/735], Loss: 0.0443\n",
      "Epoch [40/50], Step [190/735], Loss: 0.0350\n",
      "Epoch [40/50], Step [191/735], Loss: 0.0373\n",
      "Epoch [40/50], Step [192/735], Loss: 0.0260\n",
      "Epoch [40/50], Step [193/735], Loss: 0.2118\n",
      "Epoch [40/50], Step [194/735], Loss: 0.2061\n",
      "Epoch [40/50], Step [195/735], Loss: 0.0172\n",
      "Epoch [40/50], Step [196/735], Loss: 0.0594\n",
      "Epoch [40/50], Step [197/735], Loss: 0.0492\n",
      "Epoch [40/50], Step [198/735], Loss: 0.0475\n",
      "Epoch [40/50], Step [199/735], Loss: 0.0527\n",
      "Epoch [40/50], Step [200/735], Loss: 0.0547\n",
      "Epoch [40/50], Step [201/735], Loss: 0.0621\n",
      "Epoch [40/50], Step [202/735], Loss: 0.0444\n",
      "Epoch [40/50], Step [203/735], Loss: 0.0729\n",
      "Epoch [40/50], Step [204/735], Loss: 0.0381\n",
      "Epoch [40/50], Step [205/735], Loss: 0.0427\n",
      "Epoch [40/50], Step [206/735], Loss: 0.0288\n",
      "Epoch [40/50], Step [207/735], Loss: 0.0362\n",
      "Epoch [40/50], Step [208/735], Loss: 0.0407\n",
      "Epoch [40/50], Step [209/735], Loss: 0.0725\n",
      "Epoch [40/50], Step [210/735], Loss: 0.0285\n",
      "Epoch [40/50], Step [211/735], Loss: 0.0313\n",
      "Epoch [40/50], Step [212/735], Loss: 0.0190\n",
      "Epoch [40/50], Step [213/735], Loss: 0.0343\n",
      "Epoch [40/50], Step [214/735], Loss: 0.0417\n",
      "Epoch [40/50], Step [215/735], Loss: 0.0589\n",
      "Epoch [40/50], Step [216/735], Loss: 0.0683\n",
      "Epoch [40/50], Step [217/735], Loss: 0.0993\n",
      "Epoch [40/50], Step [218/735], Loss: 0.0505\n",
      "Epoch [40/50], Step [219/735], Loss: 0.0314\n",
      "Epoch [40/50], Step [220/735], Loss: 0.0334\n",
      "Epoch [40/50], Step [221/735], Loss: 0.0511\n",
      "Epoch [40/50], Step [222/735], Loss: 0.0655\n",
      "Epoch [40/50], Step [223/735], Loss: 0.0734\n",
      "Epoch [40/50], Step [224/735], Loss: 0.0366\n",
      "Epoch [40/50], Step [225/735], Loss: 0.0739\n",
      "Epoch [40/50], Step [226/735], Loss: 0.0425\n",
      "Epoch [40/50], Step [227/735], Loss: 0.0320\n",
      "Epoch [40/50], Step [228/735], Loss: 0.1877\n",
      "Epoch [40/50], Step [229/735], Loss: 0.0538\n",
      "Epoch [40/50], Step [230/735], Loss: 0.0509\n",
      "Epoch [40/50], Step [231/735], Loss: 0.0933\n",
      "Epoch [40/50], Step [232/735], Loss: 0.0410\n",
      "Epoch [40/50], Step [233/735], Loss: 0.0829\n",
      "Epoch [40/50], Step [234/735], Loss: 0.0528\n",
      "Epoch [40/50], Step [235/735], Loss: 0.0269\n",
      "Epoch [40/50], Step [236/735], Loss: 0.0684\n",
      "Epoch [40/50], Step [237/735], Loss: 0.0170\n",
      "Epoch [40/50], Step [238/735], Loss: 0.0527\n",
      "Epoch [40/50], Step [239/735], Loss: 0.1449\n",
      "Epoch [40/50], Step [240/735], Loss: 0.0164\n",
      "Epoch [40/50], Step [241/735], Loss: 0.0212\n",
      "Epoch [40/50], Step [242/735], Loss: 0.1770\n",
      "Epoch [40/50], Step [243/735], Loss: 0.0339\n",
      "Epoch [40/50], Step [244/735], Loss: 0.0323\n",
      "Epoch [40/50], Step [245/735], Loss: 0.1059\n",
      "Epoch [40/50], Step [246/735], Loss: 0.0253\n",
      "Epoch [40/50], Step [247/735], Loss: 0.1052\n",
      "Epoch [40/50], Step [248/735], Loss: 0.0931\n",
      "Epoch [40/50], Step [249/735], Loss: 0.0511\n",
      "Epoch [40/50], Step [250/735], Loss: 0.0516\n",
      "Epoch [40/50], Step [251/735], Loss: 0.0436\n",
      "Epoch [40/50], Step [252/735], Loss: 0.1326\n",
      "Epoch [40/50], Step [253/735], Loss: 0.0923\n",
      "Epoch [40/50], Step [254/735], Loss: 0.0147\n",
      "Epoch [40/50], Step [255/735], Loss: 0.0380\n",
      "Epoch [40/50], Step [256/735], Loss: 0.0538\n",
      "Epoch [40/50], Step [257/735], Loss: 0.0802\n",
      "Epoch [40/50], Step [258/735], Loss: 0.0487\n",
      "Epoch [40/50], Step [259/735], Loss: 0.0810\n",
      "Epoch [40/50], Step [260/735], Loss: 0.0427\n",
      "Epoch [40/50], Step [261/735], Loss: 0.0258\n",
      "Epoch [40/50], Step [262/735], Loss: 0.1053\n",
      "Epoch [40/50], Step [263/735], Loss: 0.0918\n",
      "Epoch [40/50], Step [264/735], Loss: 0.0677\n",
      "Epoch [40/50], Step [265/735], Loss: 0.0441\n",
      "Epoch [40/50], Step [266/735], Loss: 0.0348\n",
      "Epoch [40/50], Step [267/735], Loss: 0.1111\n",
      "Epoch [40/50], Step [268/735], Loss: 0.0348\n",
      "Epoch [40/50], Step [269/735], Loss: 0.0398\n",
      "Epoch [40/50], Step [270/735], Loss: 0.0613\n",
      "Epoch [40/50], Step [271/735], Loss: 0.0315\n",
      "Epoch [40/50], Step [272/735], Loss: 0.0471\n",
      "Epoch [40/50], Step [273/735], Loss: 0.1197\n",
      "Epoch [40/50], Step [274/735], Loss: 0.0433\n",
      "Epoch [40/50], Step [275/735], Loss: 0.0811\n",
      "Epoch [40/50], Step [276/735], Loss: 0.0571\n",
      "Epoch [40/50], Step [277/735], Loss: 0.0253\n",
      "Epoch [40/50], Step [278/735], Loss: 0.0205\n",
      "Epoch [40/50], Step [279/735], Loss: 0.0389\n",
      "Epoch [40/50], Step [280/735], Loss: 0.0550\n",
      "Epoch [40/50], Step [281/735], Loss: 0.0489\n",
      "Epoch [40/50], Step [282/735], Loss: 0.0829\n",
      "Epoch [40/50], Step [283/735], Loss: 0.1807\n",
      "Epoch [40/50], Step [284/735], Loss: 0.0888\n",
      "Epoch [40/50], Step [285/735], Loss: 0.0702\n",
      "Epoch [40/50], Step [286/735], Loss: 0.0797\n",
      "Epoch [40/50], Step [287/735], Loss: 0.0937\n",
      "Epoch [40/50], Step [288/735], Loss: 0.0608\n",
      "Epoch [40/50], Step [289/735], Loss: 0.0845\n",
      "Epoch [40/50], Step [290/735], Loss: 0.0924\n",
      "Epoch [40/50], Step [291/735], Loss: 0.0688\n",
      "Epoch [40/50], Step [292/735], Loss: 0.0565\n",
      "Epoch [40/50], Step [293/735], Loss: 0.0404\n",
      "Epoch [40/50], Step [294/735], Loss: 0.0260\n",
      "Epoch [40/50], Step [295/735], Loss: 0.0481\n",
      "Epoch [40/50], Step [296/735], Loss: 0.1394\n",
      "Epoch [40/50], Step [297/735], Loss: 0.1218\n",
      "Epoch [40/50], Step [298/735], Loss: 0.5934\n",
      "Epoch [40/50], Step [299/735], Loss: 0.0301\n",
      "Epoch [40/50], Step [300/735], Loss: 0.0528\n",
      "Epoch [40/50], Step [301/735], Loss: 0.0294\n",
      "Epoch [40/50], Step [302/735], Loss: 0.0685\n",
      "Epoch [40/50], Step [303/735], Loss: 0.0348\n",
      "Epoch [40/50], Step [304/735], Loss: 0.1109\n",
      "Epoch [40/50], Step [305/735], Loss: 0.0402\n",
      "Epoch [40/50], Step [306/735], Loss: 0.1458\n",
      "Epoch [40/50], Step [307/735], Loss: 0.0194\n",
      "Epoch [40/50], Step [308/735], Loss: 0.0346\n",
      "Epoch [40/50], Step [309/735], Loss: 0.0588\n",
      "Epoch [40/50], Step [310/735], Loss: 0.0436\n",
      "Epoch [40/50], Step [311/735], Loss: 0.0144\n",
      "Epoch [40/50], Step [312/735], Loss: 0.0404\n",
      "Epoch [40/50], Step [313/735], Loss: 0.0378\n",
      "Epoch [40/50], Step [314/735], Loss: 0.0504\n",
      "Epoch [40/50], Step [315/735], Loss: 0.0840\n",
      "Epoch [40/50], Step [316/735], Loss: 0.0317\n",
      "Epoch [40/50], Step [317/735], Loss: 0.0424\n",
      "Epoch [40/50], Step [318/735], Loss: 0.0319\n",
      "Epoch [40/50], Step [319/735], Loss: 0.0635\n",
      "Epoch [40/50], Step [320/735], Loss: 0.0334\n",
      "Epoch [40/50], Step [321/735], Loss: 0.1439\n",
      "Epoch [40/50], Step [322/735], Loss: 0.2764\n",
      "Epoch [40/50], Step [323/735], Loss: 0.0353\n",
      "Epoch [40/50], Step [324/735], Loss: 0.0262\n",
      "Epoch [40/50], Step [325/735], Loss: 0.0207\n",
      "Epoch [40/50], Step [326/735], Loss: 0.0207\n",
      "Epoch [40/50], Step [327/735], Loss: 0.0442\n",
      "Epoch [40/50], Step [328/735], Loss: 0.0549\n",
      "Epoch [40/50], Step [329/735], Loss: 0.0377\n",
      "Epoch [40/50], Step [330/735], Loss: 0.0438\n",
      "Epoch [40/50], Step [331/735], Loss: 0.0526\n",
      "Epoch [40/50], Step [332/735], Loss: 0.0538\n",
      "Epoch [40/50], Step [333/735], Loss: 0.0381\n",
      "Epoch [40/50], Step [334/735], Loss: 0.0398\n",
      "Epoch [40/50], Step [335/735], Loss: 0.1081\n",
      "Epoch [40/50], Step [336/735], Loss: 0.0470\n",
      "Epoch [40/50], Step [337/735], Loss: 0.0501\n",
      "Epoch [40/50], Step [338/735], Loss: 0.0464\n",
      "Epoch [40/50], Step [339/735], Loss: 0.0210\n",
      "Epoch [40/50], Step [340/735], Loss: 0.0301\n",
      "Epoch [40/50], Step [341/735], Loss: 0.1268\n",
      "Epoch [40/50], Step [342/735], Loss: 0.0868\n",
      "Epoch [40/50], Step [343/735], Loss: 0.0686\n",
      "Epoch [40/50], Step [344/735], Loss: 0.0888\n",
      "Epoch [40/50], Step [345/735], Loss: 0.0273\n",
      "Epoch [40/50], Step [346/735], Loss: 0.0290\n",
      "Epoch [40/50], Step [347/735], Loss: 0.0583\n",
      "Epoch [40/50], Step [348/735], Loss: 0.0623\n",
      "Epoch [40/50], Step [349/735], Loss: 0.0257\n",
      "Epoch [40/50], Step [350/735], Loss: 0.0733\n",
      "Epoch [40/50], Step [351/735], Loss: 0.0507\n",
      "Epoch [40/50], Step [352/735], Loss: 0.0662\n",
      "Epoch [40/50], Step [353/735], Loss: 0.0177\n",
      "Epoch [40/50], Step [354/735], Loss: 0.0470\n",
      "Epoch [40/50], Step [355/735], Loss: 0.0514\n",
      "Epoch [40/50], Step [356/735], Loss: 0.0135\n",
      "Epoch [40/50], Step [357/735], Loss: 0.0978\n",
      "Epoch [40/50], Step [358/735], Loss: 0.0470\n",
      "Epoch [40/50], Step [359/735], Loss: 0.0283\n",
      "Epoch [40/50], Step [360/735], Loss: 0.0334\n",
      "Epoch [40/50], Step [361/735], Loss: 0.0541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Step [362/735], Loss: 0.1004\n",
      "Epoch [40/50], Step [363/735], Loss: 0.0983\n",
      "Epoch [40/50], Step [364/735], Loss: 0.0844\n",
      "Epoch [40/50], Step [365/735], Loss: 0.0711\n",
      "Epoch [40/50], Step [366/735], Loss: 0.0928\n",
      "Epoch [40/50], Step [367/735], Loss: 0.0477\n",
      "Epoch [40/50], Step [368/735], Loss: 0.0916\n",
      "Epoch [40/50], Step [369/735], Loss: 0.0663\n",
      "Epoch [40/50], Step [370/735], Loss: 0.1089\n",
      "Epoch [40/50], Step [371/735], Loss: 0.0450\n",
      "Epoch [40/50], Step [372/735], Loss: 0.0353\n",
      "Epoch [40/50], Step [373/735], Loss: 0.1024\n",
      "Epoch [40/50], Step [374/735], Loss: 0.0630\n",
      "Epoch [40/50], Step [375/735], Loss: 0.0506\n",
      "Epoch [40/50], Step [376/735], Loss: 0.0263\n",
      "Epoch [40/50], Step [377/735], Loss: 0.1796\n",
      "Epoch [40/50], Step [378/735], Loss: 0.1634\n",
      "Epoch [40/50], Step [379/735], Loss: 0.0558\n",
      "Epoch [40/50], Step [380/735], Loss: 0.0429\n",
      "Epoch [40/50], Step [381/735], Loss: 0.0819\n",
      "Epoch [40/50], Step [382/735], Loss: 0.0380\n",
      "Epoch [40/50], Step [383/735], Loss: 0.0175\n",
      "Epoch [40/50], Step [384/735], Loss: 0.1104\n",
      "Epoch [40/50], Step [385/735], Loss: 0.0184\n",
      "Epoch [40/50], Step [386/735], Loss: 0.0345\n",
      "Epoch [40/50], Step [387/735], Loss: 0.0575\n",
      "Epoch [40/50], Step [388/735], Loss: 0.1048\n",
      "Epoch [40/50], Step [389/735], Loss: 0.3848\n",
      "Epoch [40/50], Step [390/735], Loss: 0.0958\n",
      "Epoch [40/50], Step [391/735], Loss: 0.0520\n",
      "Epoch [40/50], Step [392/735], Loss: 0.0343\n",
      "Epoch [40/50], Step [393/735], Loss: 0.0378\n",
      "Epoch [40/50], Step [394/735], Loss: 0.0350\n",
      "Epoch [40/50], Step [395/735], Loss: 0.0767\n",
      "Epoch [40/50], Step [396/735], Loss: 0.0274\n",
      "Epoch [40/50], Step [397/735], Loss: 0.0938\n",
      "Epoch [40/50], Step [398/735], Loss: 0.0161\n",
      "Epoch [40/50], Step [399/735], Loss: 0.0182\n",
      "Epoch [40/50], Step [400/735], Loss: 0.0392\n",
      "Epoch [40/50], Step [401/735], Loss: 0.0529\n",
      "Epoch [40/50], Step [402/735], Loss: 0.0509\n",
      "Epoch [40/50], Step [403/735], Loss: 0.0728\n",
      "Epoch [40/50], Step [404/735], Loss: 0.0386\n",
      "Epoch [40/50], Step [405/735], Loss: 0.0189\n",
      "Epoch [40/50], Step [406/735], Loss: 0.0250\n",
      "Epoch [40/50], Step [407/735], Loss: 0.0181\n",
      "Epoch [40/50], Step [408/735], Loss: 0.0302\n",
      "Epoch [40/50], Step [409/735], Loss: 0.0227\n",
      "Epoch [40/50], Step [410/735], Loss: 0.0683\n",
      "Epoch [40/50], Step [411/735], Loss: 0.0218\n",
      "Epoch [40/50], Step [412/735], Loss: 0.0203\n",
      "Epoch [40/50], Step [413/735], Loss: 0.0131\n",
      "Epoch [40/50], Step [414/735], Loss: 0.0407\n",
      "Epoch [40/50], Step [415/735], Loss: 0.0388\n",
      "Epoch [40/50], Step [416/735], Loss: 0.1409\n",
      "Epoch [40/50], Step [417/735], Loss: 0.0805\n",
      "Epoch [40/50], Step [418/735], Loss: 0.0187\n",
      "Epoch [40/50], Step [419/735], Loss: 0.2679\n",
      "Epoch [40/50], Step [420/735], Loss: 0.0163\n",
      "Epoch [40/50], Step [421/735], Loss: 0.0241\n",
      "Epoch [40/50], Step [422/735], Loss: 0.1245\n",
      "Epoch [40/50], Step [423/735], Loss: 0.1393\n",
      "Epoch [40/50], Step [424/735], Loss: 0.0306\n",
      "Epoch [40/50], Step [425/735], Loss: 0.0290\n",
      "Epoch [40/50], Step [426/735], Loss: 0.0531\n",
      "Epoch [40/50], Step [427/735], Loss: 0.0811\n",
      "Epoch [40/50], Step [428/735], Loss: 0.1262\n",
      "Epoch [40/50], Step [429/735], Loss: 0.0344\n",
      "Epoch [40/50], Step [430/735], Loss: 0.0611\n",
      "Epoch [40/50], Step [431/735], Loss: 0.0719\n",
      "Epoch [40/50], Step [432/735], Loss: 0.0790\n",
      "Epoch [40/50], Step [433/735], Loss: 0.0283\n",
      "Epoch [40/50], Step [434/735], Loss: 0.0399\n",
      "Epoch [40/50], Step [435/735], Loss: 0.0721\n",
      "Epoch [40/50], Step [436/735], Loss: 0.0267\n",
      "Epoch [40/50], Step [437/735], Loss: 0.0597\n",
      "Epoch [40/50], Step [438/735], Loss: 0.0419\n",
      "Epoch [40/50], Step [439/735], Loss: 0.0621\n",
      "Epoch [40/50], Step [440/735], Loss: 0.0660\n",
      "Epoch [40/50], Step [441/735], Loss: 0.0318\n",
      "Epoch [40/50], Step [442/735], Loss: 0.0743\n",
      "Epoch [40/50], Step [443/735], Loss: 0.0129\n",
      "Epoch [40/50], Step [444/735], Loss: 0.0677\n",
      "Epoch [40/50], Step [445/735], Loss: 0.3899\n",
      "Epoch [40/50], Step [446/735], Loss: 0.0382\n",
      "Epoch [40/50], Step [447/735], Loss: 0.0260\n",
      "Epoch [40/50], Step [448/735], Loss: 0.0818\n",
      "Epoch [40/50], Step [449/735], Loss: 0.0453\n",
      "Epoch [40/50], Step [450/735], Loss: 0.0278\n",
      "Epoch [40/50], Step [451/735], Loss: 0.0514\n",
      "Epoch [40/50], Step [452/735], Loss: 0.1075\n",
      "Epoch [40/50], Step [453/735], Loss: 0.1161\n",
      "Epoch [40/50], Step [454/735], Loss: 0.0400\n",
      "Epoch [40/50], Step [455/735], Loss: 0.0373\n",
      "Epoch [40/50], Step [456/735], Loss: 0.0256\n",
      "Epoch [40/50], Step [457/735], Loss: 0.2192\n",
      "Epoch [40/50], Step [458/735], Loss: 0.0400\n",
      "Epoch [40/50], Step [459/735], Loss: 0.0816\n",
      "Epoch [40/50], Step [460/735], Loss: 0.0586\n",
      "Epoch [40/50], Step [461/735], Loss: 0.0668\n",
      "Epoch [40/50], Step [462/735], Loss: 0.0353\n",
      "Epoch [40/50], Step [463/735], Loss: 0.0249\n",
      "Epoch [40/50], Step [464/735], Loss: 0.0702\n",
      "Epoch [40/50], Step [465/735], Loss: 0.0273\n",
      "Epoch [40/50], Step [466/735], Loss: 0.0246\n",
      "Epoch [40/50], Step [467/735], Loss: 0.0330\n",
      "Epoch [40/50], Step [468/735], Loss: 0.0337\n",
      "Epoch [40/50], Step [469/735], Loss: 0.0870\n",
      "Epoch [40/50], Step [470/735], Loss: 0.1510\n",
      "Epoch [40/50], Step [471/735], Loss: 0.0218\n",
      "Epoch [40/50], Step [472/735], Loss: 0.0348\n",
      "Epoch [40/50], Step [473/735], Loss: 0.1368\n",
      "Epoch [40/50], Step [474/735], Loss: 0.0558\n",
      "Epoch [40/50], Step [475/735], Loss: 0.0475\n",
      "Epoch [40/50], Step [476/735], Loss: 0.0282\n",
      "Epoch [40/50], Step [477/735], Loss: 0.0485\n",
      "Epoch [40/50], Step [478/735], Loss: 0.0536\n",
      "Epoch [40/50], Step [479/735], Loss: 0.0664\n",
      "Epoch [40/50], Step [480/735], Loss: 0.0244\n",
      "Epoch [40/50], Step [481/735], Loss: 0.0347\n",
      "Epoch [40/50], Step [482/735], Loss: 0.0505\n",
      "Epoch [40/50], Step [483/735], Loss: 0.1113\n",
      "Epoch [40/50], Step [484/735], Loss: 0.1004\n",
      "Epoch [40/50], Step [485/735], Loss: 0.0362\n",
      "Epoch [40/50], Step [486/735], Loss: 0.0382\n",
      "Epoch [40/50], Step [487/735], Loss: 0.0552\n",
      "Epoch [40/50], Step [488/735], Loss: 0.0257\n",
      "Epoch [40/50], Step [489/735], Loss: 0.0821\n",
      "Epoch [40/50], Step [490/735], Loss: 0.0214\n",
      "Epoch [40/50], Step [491/735], Loss: 0.0205\n",
      "Epoch [40/50], Step [492/735], Loss: 0.1189\n",
      "Epoch [40/50], Step [493/735], Loss: 0.0690\n",
      "Epoch [40/50], Step [494/735], Loss: 0.0950\n",
      "Epoch [40/50], Step [495/735], Loss: 0.0283\n",
      "Epoch [40/50], Step [496/735], Loss: 0.0216\n",
      "Epoch [40/50], Step [497/735], Loss: 0.0363\n",
      "Epoch [40/50], Step [498/735], Loss: 0.0812\n",
      "Epoch [40/50], Step [499/735], Loss: 0.0262\n",
      "Epoch [40/50], Step [500/735], Loss: 0.0711\n",
      "Epoch [40/50], Step [501/735], Loss: 0.1178\n",
      "Epoch [40/50], Step [502/735], Loss: 0.2147\n",
      "Epoch [40/50], Step [503/735], Loss: 0.0772\n",
      "Epoch [40/50], Step [504/735], Loss: 0.0940\n",
      "Epoch [40/50], Step [505/735], Loss: 0.0307\n",
      "Epoch [40/50], Step [506/735], Loss: 0.1846\n",
      "Epoch [40/50], Step [507/735], Loss: 0.0354\n",
      "Epoch [40/50], Step [508/735], Loss: 0.0713\n",
      "Epoch [40/50], Step [509/735], Loss: 0.0837\n",
      "Epoch [40/50], Step [510/735], Loss: 0.0424\n",
      "Epoch [40/50], Step [511/735], Loss: 0.0285\n",
      "Epoch [40/50], Step [512/735], Loss: 0.0991\n",
      "Epoch [40/50], Step [513/735], Loss: 0.0237\n",
      "Epoch [40/50], Step [514/735], Loss: 0.0293\n",
      "Epoch [40/50], Step [515/735], Loss: 0.0391\n",
      "Epoch [40/50], Step [516/735], Loss: 0.0164\n",
      "Epoch [40/50], Step [517/735], Loss: 0.0274\n",
      "Epoch [40/50], Step [518/735], Loss: 0.0412\n",
      "Epoch [40/50], Step [519/735], Loss: 0.0486\n",
      "Epoch [40/50], Step [520/735], Loss: 0.0271\n",
      "Epoch [40/50], Step [521/735], Loss: 0.0414\n",
      "Epoch [40/50], Step [522/735], Loss: 0.0199\n",
      "Epoch [40/50], Step [523/735], Loss: 0.0228\n",
      "Epoch [40/50], Step [524/735], Loss: 0.0271\n",
      "Epoch [40/50], Step [525/735], Loss: 0.0556\n",
      "Epoch [40/50], Step [526/735], Loss: 0.0309\n",
      "Epoch [40/50], Step [527/735], Loss: 0.0244\n",
      "Epoch [40/50], Step [528/735], Loss: 0.0204\n",
      "Epoch [40/50], Step [529/735], Loss: 0.0673\n",
      "Epoch [40/50], Step [530/735], Loss: 0.3215\n",
      "Epoch [40/50], Step [531/735], Loss: 0.0499\n",
      "Epoch [40/50], Step [532/735], Loss: 0.0882\n",
      "Epoch [40/50], Step [533/735], Loss: 0.0393\n",
      "Epoch [40/50], Step [534/735], Loss: 0.0577\n",
      "Epoch [40/50], Step [535/735], Loss: 0.0327\n",
      "Epoch [40/50], Step [536/735], Loss: 0.0452\n",
      "Epoch [40/50], Step [537/735], Loss: 0.0670\n",
      "Epoch [40/50], Step [538/735], Loss: 0.0628\n",
      "Epoch [40/50], Step [539/735], Loss: 0.0497\n",
      "Epoch [40/50], Step [540/735], Loss: 0.1608\n",
      "Epoch [40/50], Step [541/735], Loss: 0.0773\n",
      "Epoch [40/50], Step [542/735], Loss: 0.0599\n",
      "Epoch [40/50], Step [543/735], Loss: 0.0552\n",
      "Epoch [40/50], Step [544/735], Loss: 0.0430\n",
      "Epoch [40/50], Step [545/735], Loss: 0.0327\n",
      "Epoch [40/50], Step [546/735], Loss: 0.2624\n",
      "Epoch [40/50], Step [547/735], Loss: 0.0274\n",
      "Epoch [40/50], Step [548/735], Loss: 0.0811\n",
      "Epoch [40/50], Step [549/735], Loss: 0.0421\n",
      "Epoch [40/50], Step [550/735], Loss: 0.0170\n",
      "Epoch [40/50], Step [551/735], Loss: 0.0332\n",
      "Epoch [40/50], Step [552/735], Loss: 0.0427\n",
      "Epoch [40/50], Step [553/735], Loss: 0.1289\n",
      "Epoch [40/50], Step [554/735], Loss: 0.1034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Step [555/735], Loss: 0.0418\n",
      "Epoch [40/50], Step [556/735], Loss: 0.0310\n",
      "Epoch [40/50], Step [557/735], Loss: 0.0678\n",
      "Epoch [40/50], Step [558/735], Loss: 0.0643\n",
      "Epoch [40/50], Step [559/735], Loss: 0.0173\n",
      "Epoch [40/50], Step [560/735], Loss: 0.0367\n",
      "Epoch [40/50], Step [561/735], Loss: 0.0641\n",
      "Epoch [40/50], Step [562/735], Loss: 0.1033\n",
      "Epoch [40/50], Step [563/735], Loss: 0.0471\n",
      "Epoch [40/50], Step [564/735], Loss: 0.0785\n",
      "Epoch [40/50], Step [565/735], Loss: 0.0258\n",
      "Epoch [40/50], Step [566/735], Loss: 0.1677\n",
      "Epoch [40/50], Step [567/735], Loss: 0.0740\n",
      "Epoch [40/50], Step [568/735], Loss: 0.0413\n",
      "Epoch [40/50], Step [569/735], Loss: 0.3867\n",
      "Epoch [40/50], Step [570/735], Loss: 0.0283\n",
      "Epoch [40/50], Step [571/735], Loss: 0.3368\n",
      "Epoch [40/50], Step [572/735], Loss: 0.0624\n",
      "Epoch [40/50], Step [573/735], Loss: 0.1824\n",
      "Epoch [40/50], Step [574/735], Loss: 0.0277\n",
      "Epoch [40/50], Step [575/735], Loss: 0.0283\n",
      "Epoch [40/50], Step [576/735], Loss: 0.0357\n",
      "Epoch [40/50], Step [577/735], Loss: 0.0242\n",
      "Epoch [40/50], Step [578/735], Loss: 0.0280\n",
      "Epoch [40/50], Step [579/735], Loss: 0.0862\n",
      "Epoch [40/50], Step [580/735], Loss: 0.0191\n",
      "Epoch [40/50], Step [581/735], Loss: 0.0439\n",
      "Epoch [40/50], Step [582/735], Loss: 0.0661\n",
      "Epoch [40/50], Step [583/735], Loss: 0.0776\n",
      "Epoch [40/50], Step [584/735], Loss: 0.0509\n",
      "Epoch [40/50], Step [585/735], Loss: 0.0429\n",
      "Epoch [40/50], Step [586/735], Loss: 0.1277\n",
      "Epoch [40/50], Step [587/735], Loss: 0.0575\n",
      "Epoch [40/50], Step [588/735], Loss: 0.1009\n",
      "Epoch [40/50], Step [589/735], Loss: 0.0271\n",
      "Epoch [40/50], Step [590/735], Loss: 0.0612\n",
      "Epoch [40/50], Step [591/735], Loss: 0.0485\n",
      "Epoch [40/50], Step [592/735], Loss: 0.1260\n",
      "Epoch [40/50], Step [593/735], Loss: 0.0173\n",
      "Epoch [40/50], Step [594/735], Loss: 0.0489\n",
      "Epoch [40/50], Step [595/735], Loss: 0.1436\n",
      "Epoch [40/50], Step [596/735], Loss: 0.0523\n",
      "Epoch [40/50], Step [597/735], Loss: 0.0403\n",
      "Epoch [40/50], Step [598/735], Loss: 0.2207\n",
      "Epoch [40/50], Step [599/735], Loss: 0.0533\n",
      "Epoch [40/50], Step [600/735], Loss: 0.1400\n",
      "Epoch [40/50], Step [601/735], Loss: 0.1436\n",
      "Epoch [40/50], Step [602/735], Loss: 0.0861\n",
      "Epoch [40/50], Step [603/735], Loss: 0.0562\n",
      "Epoch [40/50], Step [604/735], Loss: 0.0768\n",
      "Epoch [40/50], Step [605/735], Loss: 0.0508\n",
      "Epoch [40/50], Step [606/735], Loss: 0.0329\n",
      "Epoch [40/50], Step [607/735], Loss: 0.0273\n",
      "Epoch [40/50], Step [608/735], Loss: 0.0418\n",
      "Epoch [40/50], Step [609/735], Loss: 0.1021\n",
      "Epoch [40/50], Step [610/735], Loss: 0.0732\n",
      "Epoch [40/50], Step [611/735], Loss: 0.0654\n",
      "Epoch [40/50], Step [612/735], Loss: 0.0369\n",
      "Epoch [40/50], Step [613/735], Loss: 0.2965\n",
      "Epoch [40/50], Step [614/735], Loss: 0.0355\n",
      "Epoch [40/50], Step [615/735], Loss: 0.1689\n",
      "Epoch [40/50], Step [616/735], Loss: 0.0509\n",
      "Epoch [40/50], Step [617/735], Loss: 0.1173\n",
      "Epoch [40/50], Step [618/735], Loss: 0.1273\n",
      "Epoch [40/50], Step [619/735], Loss: 0.1760\n",
      "Epoch [40/50], Step [620/735], Loss: 0.0389\n",
      "Epoch [40/50], Step [621/735], Loss: 0.0596\n",
      "Epoch [40/50], Step [622/735], Loss: 0.0590\n",
      "Epoch [40/50], Step [623/735], Loss: 0.0745\n",
      "Epoch [40/50], Step [624/735], Loss: 0.0377\n",
      "Epoch [40/50], Step [625/735], Loss: 0.0698\n",
      "Epoch [40/50], Step [626/735], Loss: 0.0355\n",
      "Epoch [40/50], Step [627/735], Loss: 0.1078\n",
      "Epoch [40/50], Step [628/735], Loss: 0.1703\n",
      "Epoch [40/50], Step [629/735], Loss: 0.0342\n",
      "Epoch [40/50], Step [630/735], Loss: 0.0768\n",
      "Epoch [40/50], Step [631/735], Loss: 0.0390\n",
      "Epoch [40/50], Step [632/735], Loss: 0.1397\n",
      "Epoch [40/50], Step [633/735], Loss: 0.0454\n",
      "Epoch [40/50], Step [634/735], Loss: 0.0572\n",
      "Epoch [40/50], Step [635/735], Loss: 0.1202\n",
      "Epoch [40/50], Step [636/735], Loss: 0.0854\n",
      "Epoch [40/50], Step [637/735], Loss: 0.1091\n",
      "Epoch [40/50], Step [638/735], Loss: 0.0347\n",
      "Epoch [40/50], Step [639/735], Loss: 0.1662\n",
      "Epoch [40/50], Step [640/735], Loss: 0.0536\n",
      "Epoch [40/50], Step [641/735], Loss: 0.0325\n",
      "Epoch [40/50], Step [642/735], Loss: 0.1019\n",
      "Epoch [40/50], Step [643/735], Loss: 0.0416\n",
      "Epoch [40/50], Step [644/735], Loss: 0.0391\n",
      "Epoch [40/50], Step [645/735], Loss: 0.0164\n",
      "Epoch [40/50], Step [646/735], Loss: 0.0389\n",
      "Epoch [40/50], Step [647/735], Loss: 0.0201\n",
      "Epoch [40/50], Step [648/735], Loss: 0.0640\n",
      "Epoch [40/50], Step [649/735], Loss: 0.0177\n",
      "Epoch [40/50], Step [650/735], Loss: 0.0505\n",
      "Epoch [40/50], Step [651/735], Loss: 0.0714\n",
      "Epoch [40/50], Step [652/735], Loss: 0.0362\n",
      "Epoch [40/50], Step [653/735], Loss: 0.1021\n",
      "Epoch [40/50], Step [654/735], Loss: 0.0404\n",
      "Epoch [40/50], Step [655/735], Loss: 0.0374\n",
      "Epoch [40/50], Step [656/735], Loss: 0.0541\n",
      "Epoch [40/50], Step [657/735], Loss: 0.0306\n",
      "Epoch [40/50], Step [658/735], Loss: 0.0680\n",
      "Epoch [40/50], Step [659/735], Loss: 0.0278\n",
      "Epoch [40/50], Step [660/735], Loss: 0.0960\n",
      "Epoch [40/50], Step [661/735], Loss: 0.0335\n",
      "Epoch [40/50], Step [662/735], Loss: 0.5310\n",
      "Epoch [40/50], Step [663/735], Loss: 0.0438\n",
      "Epoch [40/50], Step [664/735], Loss: 0.0272\n",
      "Epoch [40/50], Step [665/735], Loss: 0.0801\n",
      "Epoch [40/50], Step [666/735], Loss: 0.0763\n",
      "Epoch [40/50], Step [667/735], Loss: 0.0243\n",
      "Epoch [40/50], Step [668/735], Loss: 0.0229\n",
      "Epoch [40/50], Step [669/735], Loss: 0.0636\n",
      "Epoch [40/50], Step [670/735], Loss: 0.0381\n",
      "Epoch [40/50], Step [671/735], Loss: 0.0838\n",
      "Epoch [40/50], Step [672/735], Loss: 0.0147\n",
      "Epoch [40/50], Step [673/735], Loss: 0.0658\n",
      "Epoch [40/50], Step [674/735], Loss: 0.0630\n",
      "Epoch [40/50], Step [675/735], Loss: 0.0210\n",
      "Epoch [40/50], Step [676/735], Loss: 0.0305\n",
      "Epoch [40/50], Step [677/735], Loss: 0.0869\n",
      "Epoch [40/50], Step [678/735], Loss: 0.0501\n",
      "Epoch [40/50], Step [679/735], Loss: 0.0773\n",
      "Epoch [40/50], Step [680/735], Loss: 0.0253\n",
      "Epoch [40/50], Step [681/735], Loss: 0.3737\n",
      "Epoch [40/50], Step [682/735], Loss: 0.0782\n",
      "Epoch [40/50], Step [683/735], Loss: 0.2091\n",
      "Epoch [40/50], Step [684/735], Loss: 0.0383\n",
      "Epoch [40/50], Step [685/735], Loss: 0.0563\n",
      "Epoch [40/50], Step [686/735], Loss: 0.0671\n",
      "Epoch [40/50], Step [687/735], Loss: 0.0410\n",
      "Epoch [40/50], Step [688/735], Loss: 0.0898\n",
      "Epoch [40/50], Step [689/735], Loss: 0.0802\n",
      "Epoch [40/50], Step [690/735], Loss: 0.0251\n",
      "Epoch [40/50], Step [691/735], Loss: 0.0400\n",
      "Epoch [40/50], Step [692/735], Loss: 0.0666\n",
      "Epoch [40/50], Step [693/735], Loss: 0.0620\n",
      "Epoch [40/50], Step [694/735], Loss: 0.0186\n",
      "Epoch [40/50], Step [695/735], Loss: 0.0473\n",
      "Epoch [40/50], Step [696/735], Loss: 0.0349\n",
      "Epoch [40/50], Step [697/735], Loss: 0.1705\n",
      "Epoch [40/50], Step [698/735], Loss: 0.0512\n",
      "Epoch [40/50], Step [699/735], Loss: 0.0732\n",
      "Epoch [40/50], Step [700/735], Loss: 0.4368\n",
      "Epoch [40/50], Step [701/735], Loss: 0.0381\n",
      "Epoch [40/50], Step [702/735], Loss: 0.0312\n",
      "Epoch [40/50], Step [703/735], Loss: 0.0518\n",
      "Epoch [40/50], Step [704/735], Loss: 0.0444\n",
      "Epoch [40/50], Step [705/735], Loss: 0.0528\n",
      "Epoch [40/50], Step [706/735], Loss: 0.0558\n",
      "Epoch [40/50], Step [707/735], Loss: 0.2180\n",
      "Epoch [40/50], Step [708/735], Loss: 0.0585\n",
      "Epoch [40/50], Step [709/735], Loss: 0.0571\n",
      "Epoch [40/50], Step [710/735], Loss: 0.1293\n",
      "Epoch [40/50], Step [711/735], Loss: 0.3220\n",
      "Epoch [40/50], Step [712/735], Loss: 0.0741\n",
      "Epoch [40/50], Step [713/735], Loss: 0.0812\n",
      "Epoch [40/50], Step [714/735], Loss: 0.0783\n",
      "Epoch [40/50], Step [715/735], Loss: 0.0383\n",
      "Epoch [40/50], Step [716/735], Loss: 0.0619\n",
      "Epoch [40/50], Step [717/735], Loss: 0.0914\n",
      "Epoch [40/50], Step [718/735], Loss: 0.1443\n",
      "Epoch [40/50], Step [719/735], Loss: 0.0611\n",
      "Epoch [40/50], Step [720/735], Loss: 0.0734\n",
      "Epoch [40/50], Step [721/735], Loss: 0.0302\n",
      "Epoch [40/50], Step [722/735], Loss: 0.0943\n",
      "Epoch [40/50], Step [723/735], Loss: 0.0248\n",
      "Epoch [40/50], Step [724/735], Loss: 0.2641\n",
      "Epoch [40/50], Step [725/735], Loss: 0.0541\n",
      "Epoch [40/50], Step [726/735], Loss: 0.0174\n",
      "Epoch [40/50], Step [727/735], Loss: 0.1634\n",
      "Epoch [40/50], Step [728/735], Loss: 0.0506\n",
      "Epoch [40/50], Step [729/735], Loss: 0.0533\n",
      "Epoch [40/50], Step [730/735], Loss: 0.1220\n",
      "Epoch [40/50], Step [731/735], Loss: 0.2256\n",
      "Epoch [40/50], Step [732/735], Loss: 0.1440\n",
      "Epoch [40/50], Step [733/735], Loss: 0.2168\n",
      "Epoch [40/50], Step [734/735], Loss: 0.0280\n",
      "Epoch [40/50], Step [735/735], Loss: 0.8753\n",
      "Epoch [41/50], Step [1/735], Loss: 0.0807\n",
      "Epoch [41/50], Step [2/735], Loss: 0.0906\n",
      "Epoch [41/50], Step [3/735], Loss: 0.0402\n",
      "Epoch [41/50], Step [4/735], Loss: 0.2817\n",
      "Epoch [41/50], Step [5/735], Loss: 0.0459\n",
      "Epoch [41/50], Step [6/735], Loss: 0.0879\n",
      "Epoch [41/50], Step [7/735], Loss: 0.0916\n",
      "Epoch [41/50], Step [8/735], Loss: 0.1299\n",
      "Epoch [41/50], Step [9/735], Loss: 0.0486\n",
      "Epoch [41/50], Step [10/735], Loss: 0.0905\n",
      "Epoch [41/50], Step [11/735], Loss: 0.0775\n",
      "Epoch [41/50], Step [12/735], Loss: 0.1081\n",
      "Epoch [41/50], Step [13/735], Loss: 0.1696\n",
      "Epoch [41/50], Step [14/735], Loss: 0.0453\n",
      "Epoch [41/50], Step [15/735], Loss: 0.1084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Step [16/735], Loss: 0.1314\n",
      "Epoch [41/50], Step [17/735], Loss: 0.0451\n",
      "Epoch [41/50], Step [18/735], Loss: 0.0719\n",
      "Epoch [41/50], Step [19/735], Loss: 0.1259\n",
      "Epoch [41/50], Step [20/735], Loss: 0.2340\n",
      "Epoch [41/50], Step [21/735], Loss: 0.0713\n",
      "Epoch [41/50], Step [22/735], Loss: 0.0300\n",
      "Epoch [41/50], Step [23/735], Loss: 0.0887\n",
      "Epoch [41/50], Step [24/735], Loss: 0.0637\n",
      "Epoch [41/50], Step [25/735], Loss: 0.0875\n",
      "Epoch [41/50], Step [26/735], Loss: 0.0656\n",
      "Epoch [41/50], Step [27/735], Loss: 0.0618\n",
      "Epoch [41/50], Step [28/735], Loss: 0.0358\n",
      "Epoch [41/50], Step [29/735], Loss: 0.0227\n",
      "Epoch [41/50], Step [30/735], Loss: 0.0353\n",
      "Epoch [41/50], Step [31/735], Loss: 0.1491\n",
      "Epoch [41/50], Step [32/735], Loss: 0.0741\n",
      "Epoch [41/50], Step [33/735], Loss: 0.0217\n",
      "Epoch [41/50], Step [34/735], Loss: 0.0812\n",
      "Epoch [41/50], Step [35/735], Loss: 0.2886\n",
      "Epoch [41/50], Step [36/735], Loss: 0.0431\n",
      "Epoch [41/50], Step [37/735], Loss: 0.0528\n",
      "Epoch [41/50], Step [38/735], Loss: 0.0299\n",
      "Epoch [41/50], Step [39/735], Loss: 0.0329\n",
      "Epoch [41/50], Step [40/735], Loss: 0.0225\n",
      "Epoch [41/50], Step [41/735], Loss: 0.0338\n",
      "Epoch [41/50], Step [42/735], Loss: 0.0410\n",
      "Epoch [41/50], Step [43/735], Loss: 0.0294\n",
      "Epoch [41/50], Step [44/735], Loss: 0.0215\n",
      "Epoch [41/50], Step [45/735], Loss: 0.0686\n",
      "Epoch [41/50], Step [46/735], Loss: 0.0521\n",
      "Epoch [41/50], Step [47/735], Loss: 0.0355\n",
      "Epoch [41/50], Step [48/735], Loss: 0.0480\n",
      "Epoch [41/50], Step [49/735], Loss: 0.0880\n",
      "Epoch [41/50], Step [50/735], Loss: 0.1055\n",
      "Epoch [41/50], Step [51/735], Loss: 0.1534\n",
      "Epoch [41/50], Step [52/735], Loss: 0.0322\n",
      "Epoch [41/50], Step [53/735], Loss: 0.0275\n",
      "Epoch [41/50], Step [54/735], Loss: 0.0591\n",
      "Epoch [41/50], Step [55/735], Loss: 0.0466\n",
      "Epoch [41/50], Step [56/735], Loss: 0.0746\n",
      "Epoch [41/50], Step [57/735], Loss: 0.0463\n",
      "Epoch [41/50], Step [58/735], Loss: 0.0300\n",
      "Epoch [41/50], Step [59/735], Loss: 0.0818\n",
      "Epoch [41/50], Step [60/735], Loss: 0.0286\n",
      "Epoch [41/50], Step [61/735], Loss: 0.0551\n",
      "Epoch [41/50], Step [62/735], Loss: 0.0504\n",
      "Epoch [41/50], Step [63/735], Loss: 0.0589\n",
      "Epoch [41/50], Step [64/735], Loss: 0.0161\n",
      "Epoch [41/50], Step [65/735], Loss: 0.0323\n",
      "Epoch [41/50], Step [66/735], Loss: 0.0453\n",
      "Epoch [41/50], Step [67/735], Loss: 0.0160\n",
      "Epoch [41/50], Step [68/735], Loss: 0.0382\n",
      "Epoch [41/50], Step [69/735], Loss: 0.0951\n",
      "Epoch [41/50], Step [70/735], Loss: 0.1677\n",
      "Epoch [41/50], Step [71/735], Loss: 0.0248\n",
      "Epoch [41/50], Step [72/735], Loss: 0.0553\n",
      "Epoch [41/50], Step [73/735], Loss: 0.0863\n",
      "Epoch [41/50], Step [74/735], Loss: 0.2961\n",
      "Epoch [41/50], Step [75/735], Loss: 0.0187\n",
      "Epoch [41/50], Step [76/735], Loss: 0.0613\n",
      "Epoch [41/50], Step [77/735], Loss: 0.2522\n",
      "Epoch [41/50], Step [78/735], Loss: 0.0358\n",
      "Epoch [41/50], Step [79/735], Loss: 0.0394\n",
      "Epoch [41/50], Step [80/735], Loss: 0.0605\n",
      "Epoch [41/50], Step [81/735], Loss: 0.0336\n",
      "Epoch [41/50], Step [82/735], Loss: 0.0436\n",
      "Epoch [41/50], Step [83/735], Loss: 0.0465\n",
      "Epoch [41/50], Step [84/735], Loss: 0.0397\n",
      "Epoch [41/50], Step [85/735], Loss: 0.1121\n",
      "Epoch [41/50], Step [86/735], Loss: 0.1369\n",
      "Epoch [41/50], Step [87/735], Loss: 0.0532\n",
      "Epoch [41/50], Step [88/735], Loss: 0.1029\n",
      "Epoch [41/50], Step [89/735], Loss: 0.0469\n",
      "Epoch [41/50], Step [90/735], Loss: 0.0376\n",
      "Epoch [41/50], Step [91/735], Loss: 0.0262\n",
      "Epoch [41/50], Step [92/735], Loss: 0.0506\n",
      "Epoch [41/50], Step [93/735], Loss: 0.0235\n",
      "Epoch [41/50], Step [94/735], Loss: 0.0239\n",
      "Epoch [41/50], Step [95/735], Loss: 0.0416\n",
      "Epoch [41/50], Step [96/735], Loss: 0.0323\n",
      "Epoch [41/50], Step [97/735], Loss: 0.0654\n",
      "Epoch [41/50], Step [98/735], Loss: 0.1083\n",
      "Epoch [41/50], Step [99/735], Loss: 0.0311\n",
      "Epoch [41/50], Step [100/735], Loss: 0.0285\n",
      "Epoch [41/50], Step [101/735], Loss: 0.0705\n",
      "Epoch [41/50], Step [102/735], Loss: 0.0619\n",
      "Epoch [41/50], Step [103/735], Loss: 0.0591\n",
      "Epoch [41/50], Step [104/735], Loss: 0.0414\n",
      "Epoch [41/50], Step [105/735], Loss: 0.0563\n",
      "Epoch [41/50], Step [106/735], Loss: 0.0302\n",
      "Epoch [41/50], Step [107/735], Loss: 0.0436\n",
      "Epoch [41/50], Step [108/735], Loss: 0.0937\n",
      "Epoch [41/50], Step [109/735], Loss: 0.0217\n",
      "Epoch [41/50], Step [110/735], Loss: 0.0753\n",
      "Epoch [41/50], Step [111/735], Loss: 0.0836\n",
      "Epoch [41/50], Step [112/735], Loss: 0.0314\n",
      "Epoch [41/50], Step [113/735], Loss: 0.0433\n",
      "Epoch [41/50], Step [114/735], Loss: 0.0515\n",
      "Epoch [41/50], Step [115/735], Loss: 0.0213\n",
      "Epoch [41/50], Step [116/735], Loss: 0.0358\n",
      "Epoch [41/50], Step [117/735], Loss: 0.0415\n",
      "Epoch [41/50], Step [118/735], Loss: 0.1675\n",
      "Epoch [41/50], Step [119/735], Loss: 0.0330\n",
      "Epoch [41/50], Step [120/735], Loss: 0.0282\n",
      "Epoch [41/50], Step [121/735], Loss: 0.0347\n",
      "Epoch [41/50], Step [122/735], Loss: 0.0380\n",
      "Epoch [41/50], Step [123/735], Loss: 0.1705\n",
      "Epoch [41/50], Step [124/735], Loss: 0.0417\n",
      "Epoch [41/50], Step [125/735], Loss: 0.0506\n",
      "Epoch [41/50], Step [126/735], Loss: 0.0500\n",
      "Epoch [41/50], Step [127/735], Loss: 0.0525\n",
      "Epoch [41/50], Step [128/735], Loss: 0.0241\n",
      "Epoch [41/50], Step [129/735], Loss: 0.0342\n",
      "Epoch [41/50], Step [130/735], Loss: 0.0253\n",
      "Epoch [41/50], Step [131/735], Loss: 0.1291\n",
      "Epoch [41/50], Step [132/735], Loss: 0.2570\n",
      "Epoch [41/50], Step [133/735], Loss: 0.0412\n",
      "Epoch [41/50], Step [134/735], Loss: 0.0272\n",
      "Epoch [41/50], Step [135/735], Loss: 0.0526\n",
      "Epoch [41/50], Step [136/735], Loss: 0.0551\n",
      "Epoch [41/50], Step [137/735], Loss: 0.0575\n",
      "Epoch [41/50], Step [138/735], Loss: 0.0414\n",
      "Epoch [41/50], Step [139/735], Loss: 0.1345\n",
      "Epoch [41/50], Step [140/735], Loss: 0.0346\n",
      "Epoch [41/50], Step [141/735], Loss: 0.0593\n",
      "Epoch [41/50], Step [142/735], Loss: 0.0990\n",
      "Epoch [41/50], Step [143/735], Loss: 0.0619\n",
      "Epoch [41/50], Step [144/735], Loss: 0.0281\n",
      "Epoch [41/50], Step [145/735], Loss: 0.0584\n",
      "Epoch [41/50], Step [146/735], Loss: 0.1204\n",
      "Epoch [41/50], Step [147/735], Loss: 0.0572\n",
      "Epoch [41/50], Step [148/735], Loss: 0.0363\n",
      "Epoch [41/50], Step [149/735], Loss: 0.0381\n",
      "Epoch [41/50], Step [150/735], Loss: 0.0227\n",
      "Epoch [41/50], Step [151/735], Loss: 0.0338\n",
      "Epoch [41/50], Step [152/735], Loss: 0.0908\n",
      "Epoch [41/50], Step [153/735], Loss: 0.0358\n",
      "Epoch [41/50], Step [154/735], Loss: 0.0400\n",
      "Epoch [41/50], Step [155/735], Loss: 0.0497\n",
      "Epoch [41/50], Step [156/735], Loss: 0.0682\n",
      "Epoch [41/50], Step [157/735], Loss: 0.0567\n",
      "Epoch [41/50], Step [158/735], Loss: 0.0289\n",
      "Epoch [41/50], Step [159/735], Loss: 0.0284\n",
      "Epoch [41/50], Step [160/735], Loss: 0.0433\n",
      "Epoch [41/50], Step [161/735], Loss: 0.0369\n",
      "Epoch [41/50], Step [162/735], Loss: 0.0860\n",
      "Epoch [41/50], Step [163/735], Loss: 0.0522\n",
      "Epoch [41/50], Step [164/735], Loss: 0.0774\n",
      "Epoch [41/50], Step [165/735], Loss: 0.1271\n",
      "Epoch [41/50], Step [166/735], Loss: 0.0988\n",
      "Epoch [41/50], Step [167/735], Loss: 0.0563\n",
      "Epoch [41/50], Step [168/735], Loss: 0.0425\n",
      "Epoch [41/50], Step [169/735], Loss: 0.0444\n",
      "Epoch [41/50], Step [170/735], Loss: 0.0452\n",
      "Epoch [41/50], Step [171/735], Loss: 0.1050\n",
      "Epoch [41/50], Step [172/735], Loss: 0.1798\n",
      "Epoch [41/50], Step [173/735], Loss: 0.0484\n",
      "Epoch [41/50], Step [174/735], Loss: 0.0554\n",
      "Epoch [41/50], Step [175/735], Loss: 0.0691\n",
      "Epoch [41/50], Step [176/735], Loss: 0.1456\n",
      "Epoch [41/50], Step [177/735], Loss: 0.0633\n",
      "Epoch [41/50], Step [178/735], Loss: 0.0418\n",
      "Epoch [41/50], Step [179/735], Loss: 0.0433\n",
      "Epoch [41/50], Step [180/735], Loss: 0.0546\n",
      "Epoch [41/50], Step [181/735], Loss: 0.0922\n",
      "Epoch [41/50], Step [182/735], Loss: 0.0637\n",
      "Epoch [41/50], Step [183/735], Loss: 0.0741\n",
      "Epoch [41/50], Step [184/735], Loss: 0.0601\n",
      "Epoch [41/50], Step [185/735], Loss: 0.3653\n",
      "Epoch [41/50], Step [186/735], Loss: 0.0711\n",
      "Epoch [41/50], Step [187/735], Loss: 0.1177\n",
      "Epoch [41/50], Step [188/735], Loss: 0.0472\n",
      "Epoch [41/50], Step [189/735], Loss: 0.0469\n",
      "Epoch [41/50], Step [190/735], Loss: 0.0964\n",
      "Epoch [41/50], Step [191/735], Loss: 0.0286\n",
      "Epoch [41/50], Step [192/735], Loss: 0.0225\n",
      "Epoch [41/50], Step [193/735], Loss: 0.0739\n",
      "Epoch [41/50], Step [194/735], Loss: 0.0339\n",
      "Epoch [41/50], Step [195/735], Loss: 0.0271\n",
      "Epoch [41/50], Step [196/735], Loss: 0.0336\n",
      "Epoch [41/50], Step [197/735], Loss: 0.0852\n",
      "Epoch [41/50], Step [198/735], Loss: 0.0257\n",
      "Epoch [41/50], Step [199/735], Loss: 0.0640\n",
      "Epoch [41/50], Step [200/735], Loss: 0.0392\n",
      "Epoch [41/50], Step [201/735], Loss: 0.0334\n",
      "Epoch [41/50], Step [202/735], Loss: 0.0166\n",
      "Epoch [41/50], Step [203/735], Loss: 0.0225\n",
      "Epoch [41/50], Step [204/735], Loss: 0.0240\n",
      "Epoch [41/50], Step [205/735], Loss: 0.0406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Step [206/735], Loss: 0.1624\n",
      "Epoch [41/50], Step [207/735], Loss: 0.0709\n",
      "Epoch [41/50], Step [208/735], Loss: 0.0779\n",
      "Epoch [41/50], Step [209/735], Loss: 0.3330\n",
      "Epoch [41/50], Step [210/735], Loss: 0.1054\n",
      "Epoch [41/50], Step [211/735], Loss: 0.0864\n",
      "Epoch [41/50], Step [212/735], Loss: 0.0436\n",
      "Epoch [41/50], Step [213/735], Loss: 0.0207\n",
      "Epoch [41/50], Step [214/735], Loss: 0.0980\n",
      "Epoch [41/50], Step [215/735], Loss: 0.0750\n",
      "Epoch [41/50], Step [216/735], Loss: 0.0597\n",
      "Epoch [41/50], Step [217/735], Loss: 0.0515\n",
      "Epoch [41/50], Step [218/735], Loss: 0.0126\n",
      "Epoch [41/50], Step [219/735], Loss: 0.0247\n",
      "Epoch [41/50], Step [220/735], Loss: 0.0361\n",
      "Epoch [41/50], Step [221/735], Loss: 0.0766\n",
      "Epoch [41/50], Step [222/735], Loss: 0.0198\n",
      "Epoch [41/50], Step [223/735], Loss: 0.0260\n",
      "Epoch [41/50], Step [224/735], Loss: 0.1234\n",
      "Epoch [41/50], Step [225/735], Loss: 0.0499\n",
      "Epoch [41/50], Step [226/735], Loss: 0.0213\n",
      "Epoch [41/50], Step [227/735], Loss: 0.0342\n",
      "Epoch [41/50], Step [228/735], Loss: 0.3542\n",
      "Epoch [41/50], Step [229/735], Loss: 0.0828\n",
      "Epoch [41/50], Step [230/735], Loss: 0.0360\n",
      "Epoch [41/50], Step [231/735], Loss: 0.0485\n",
      "Epoch [41/50], Step [232/735], Loss: 0.0775\n",
      "Epoch [41/50], Step [233/735], Loss: 0.0639\n",
      "Epoch [41/50], Step [234/735], Loss: 0.0650\n",
      "Epoch [41/50], Step [235/735], Loss: 0.0463\n",
      "Epoch [41/50], Step [236/735], Loss: 0.0318\n",
      "Epoch [41/50], Step [237/735], Loss: 0.0735\n",
      "Epoch [41/50], Step [238/735], Loss: 0.0498\n",
      "Epoch [41/50], Step [239/735], Loss: 0.0986\n",
      "Epoch [41/50], Step [240/735], Loss: 0.1096\n",
      "Epoch [41/50], Step [241/735], Loss: 0.2961\n",
      "Epoch [41/50], Step [242/735], Loss: 0.0480\n",
      "Epoch [41/50], Step [243/735], Loss: 0.0915\n",
      "Epoch [41/50], Step [244/735], Loss: 0.0899\n",
      "Epoch [41/50], Step [245/735], Loss: 0.3667\n",
      "Epoch [41/50], Step [246/735], Loss: 0.0251\n",
      "Epoch [41/50], Step [247/735], Loss: 0.0374\n",
      "Epoch [41/50], Step [248/735], Loss: 0.0538\n",
      "Epoch [41/50], Step [249/735], Loss: 0.0379\n",
      "Epoch [41/50], Step [250/735], Loss: 0.0547\n",
      "Epoch [41/50], Step [251/735], Loss: 0.0284\n",
      "Epoch [41/50], Step [252/735], Loss: 0.0385\n",
      "Epoch [41/50], Step [253/735], Loss: 0.0690\n",
      "Epoch [41/50], Step [254/735], Loss: 0.0475\n",
      "Epoch [41/50], Step [255/735], Loss: 0.0373\n",
      "Epoch [41/50], Step [256/735], Loss: 0.0343\n",
      "Epoch [41/50], Step [257/735], Loss: 0.0643\n",
      "Epoch [41/50], Step [258/735], Loss: 0.1038\n",
      "Epoch [41/50], Step [259/735], Loss: 0.0330\n",
      "Epoch [41/50], Step [260/735], Loss: 0.0425\n",
      "Epoch [41/50], Step [261/735], Loss: 0.0128\n",
      "Epoch [41/50], Step [262/735], Loss: 0.0307\n",
      "Epoch [41/50], Step [263/735], Loss: 0.0386\n",
      "Epoch [41/50], Step [264/735], Loss: 0.0305\n",
      "Epoch [41/50], Step [265/735], Loss: 0.0447\n",
      "Epoch [41/50], Step [266/735], Loss: 0.0408\n",
      "Epoch [41/50], Step [267/735], Loss: 0.0454\n",
      "Epoch [41/50], Step [268/735], Loss: 0.2258\n",
      "Epoch [41/50], Step [269/735], Loss: 0.0258\n",
      "Epoch [41/50], Step [270/735], Loss: 0.1119\n",
      "Epoch [41/50], Step [271/735], Loss: 0.0479\n",
      "Epoch [41/50], Step [272/735], Loss: 0.0162\n",
      "Epoch [41/50], Step [273/735], Loss: 0.0656\n",
      "Epoch [41/50], Step [274/735], Loss: 0.0467\n",
      "Epoch [41/50], Step [275/735], Loss: 0.1058\n",
      "Epoch [41/50], Step [276/735], Loss: 0.0303\n",
      "Epoch [41/50], Step [277/735], Loss: 0.0533\n",
      "Epoch [41/50], Step [278/735], Loss: 0.0357\n",
      "Epoch [41/50], Step [279/735], Loss: 0.0579\n",
      "Epoch [41/50], Step [280/735], Loss: 0.0494\n",
      "Epoch [41/50], Step [281/735], Loss: 0.0243\n",
      "Epoch [41/50], Step [282/735], Loss: 0.0198\n",
      "Epoch [41/50], Step [283/735], Loss: 0.0280\n",
      "Epoch [41/50], Step [284/735], Loss: 0.0586\n",
      "Epoch [41/50], Step [285/735], Loss: 0.0480\n",
      "Epoch [41/50], Step [286/735], Loss: 0.0422\n",
      "Epoch [41/50], Step [287/735], Loss: 0.0646\n",
      "Epoch [41/50], Step [288/735], Loss: 0.0887\n",
      "Epoch [41/50], Step [289/735], Loss: 0.0189\n",
      "Epoch [41/50], Step [290/735], Loss: 0.1856\n",
      "Epoch [41/50], Step [291/735], Loss: 0.0115\n",
      "Epoch [41/50], Step [292/735], Loss: 0.0514\n",
      "Epoch [41/50], Step [293/735], Loss: 0.1523\n",
      "Epoch [41/50], Step [294/735], Loss: 0.0400\n",
      "Epoch [41/50], Step [295/735], Loss: 0.1138\n",
      "Epoch [41/50], Step [296/735], Loss: 0.0404\n",
      "Epoch [41/50], Step [297/735], Loss: 0.0179\n",
      "Epoch [41/50], Step [298/735], Loss: 0.0565\n",
      "Epoch [41/50], Step [299/735], Loss: 0.0455\n",
      "Epoch [41/50], Step [300/735], Loss: 0.0900\n",
      "Epoch [41/50], Step [301/735], Loss: 0.0648\n",
      "Epoch [41/50], Step [302/735], Loss: 0.0305\n",
      "Epoch [41/50], Step [303/735], Loss: 0.0306\n",
      "Epoch [41/50], Step [304/735], Loss: 0.1701\n",
      "Epoch [41/50], Step [305/735], Loss: 0.1749\n",
      "Epoch [41/50], Step [306/735], Loss: 0.0421\n",
      "Epoch [41/50], Step [307/735], Loss: 0.0834\n",
      "Epoch [41/50], Step [308/735], Loss: 0.0418\n",
      "Epoch [41/50], Step [309/735], Loss: 0.0485\n",
      "Epoch [41/50], Step [310/735], Loss: 0.0322\n",
      "Epoch [41/50], Step [311/735], Loss: 0.0646\n",
      "Epoch [41/50], Step [312/735], Loss: 0.0298\n",
      "Epoch [41/50], Step [313/735], Loss: 0.0437\n",
      "Epoch [41/50], Step [314/735], Loss: 0.0608\n",
      "Epoch [41/50], Step [315/735], Loss: 0.0549\n",
      "Epoch [41/50], Step [316/735], Loss: 0.0173\n",
      "Epoch [41/50], Step [317/735], Loss: 0.0207\n",
      "Epoch [41/50], Step [318/735], Loss: 0.1125\n",
      "Epoch [41/50], Step [319/735], Loss: 0.0522\n",
      "Epoch [41/50], Step [320/735], Loss: 0.0661\n",
      "Epoch [41/50], Step [321/735], Loss: 0.0936\n",
      "Epoch [41/50], Step [322/735], Loss: 0.0277\n",
      "Epoch [41/50], Step [323/735], Loss: 0.0266\n",
      "Epoch [41/50], Step [324/735], Loss: 0.0536\n",
      "Epoch [41/50], Step [325/735], Loss: 0.0542\n",
      "Epoch [41/50], Step [326/735], Loss: 0.0707\n",
      "Epoch [41/50], Step [327/735], Loss: 0.0352\n",
      "Epoch [41/50], Step [328/735], Loss: 0.0366\n",
      "Epoch [41/50], Step [329/735], Loss: 0.0614\n",
      "Epoch [41/50], Step [330/735], Loss: 0.0740\n",
      "Epoch [41/50], Step [331/735], Loss: 0.0487\n",
      "Epoch [41/50], Step [332/735], Loss: 0.0371\n",
      "Epoch [41/50], Step [333/735], Loss: 0.0258\n",
      "Epoch [41/50], Step [334/735], Loss: 0.0381\n",
      "Epoch [41/50], Step [335/735], Loss: 0.0719\n",
      "Epoch [41/50], Step [336/735], Loss: 0.0221\n",
      "Epoch [41/50], Step [337/735], Loss: 0.0366\n",
      "Epoch [41/50], Step [338/735], Loss: 0.0686\n",
      "Epoch [41/50], Step [339/735], Loss: 0.0546\n",
      "Epoch [41/50], Step [340/735], Loss: 0.0695\n",
      "Epoch [41/50], Step [341/735], Loss: 0.0171\n",
      "Epoch [41/50], Step [342/735], Loss: 0.0217\n",
      "Epoch [41/50], Step [343/735], Loss: 0.1040\n",
      "Epoch [41/50], Step [344/735], Loss: 0.0750\n",
      "Epoch [41/50], Step [345/735], Loss: 0.0532\n",
      "Epoch [41/50], Step [346/735], Loss: 0.0173\n",
      "Epoch [41/50], Step [347/735], Loss: 0.0664\n",
      "Epoch [41/50], Step [348/735], Loss: 0.0253\n",
      "Epoch [41/50], Step [349/735], Loss: 0.1477\n",
      "Epoch [41/50], Step [350/735], Loss: 0.0241\n",
      "Epoch [41/50], Step [351/735], Loss: 0.0376\n",
      "Epoch [41/50], Step [352/735], Loss: 0.0833\n",
      "Epoch [41/50], Step [353/735], Loss: 0.1348\n",
      "Epoch [41/50], Step [354/735], Loss: 0.0261\n",
      "Epoch [41/50], Step [355/735], Loss: 0.0822\n",
      "Epoch [41/50], Step [356/735], Loss: 0.0163\n",
      "Epoch [41/50], Step [357/735], Loss: 0.0448\n",
      "Epoch [41/50], Step [358/735], Loss: 0.0364\n",
      "Epoch [41/50], Step [359/735], Loss: 0.0879\n",
      "Epoch [41/50], Step [360/735], Loss: 0.0442\n",
      "Epoch [41/50], Step [361/735], Loss: 0.0588\n",
      "Epoch [41/50], Step [362/735], Loss: 0.0328\n",
      "Epoch [41/50], Step [363/735], Loss: 0.0800\n",
      "Epoch [41/50], Step [364/735], Loss: 0.0712\n",
      "Epoch [41/50], Step [365/735], Loss: 0.0304\n",
      "Epoch [41/50], Step [366/735], Loss: 0.0540\n",
      "Epoch [41/50], Step [367/735], Loss: 0.0353\n",
      "Epoch [41/50], Step [368/735], Loss: 0.0479\n",
      "Epoch [41/50], Step [369/735], Loss: 0.0345\n",
      "Epoch [41/50], Step [370/735], Loss: 0.0747\n",
      "Epoch [41/50], Step [371/735], Loss: 0.0394\n",
      "Epoch [41/50], Step [372/735], Loss: 0.0293\n",
      "Epoch [41/50], Step [373/735], Loss: 0.0202\n",
      "Epoch [41/50], Step [374/735], Loss: 0.0838\n",
      "Epoch [41/50], Step [375/735], Loss: 0.0494\n",
      "Epoch [41/50], Step [376/735], Loss: 0.0598\n",
      "Epoch [41/50], Step [377/735], Loss: 0.0546\n",
      "Epoch [41/50], Step [378/735], Loss: 0.3465\n",
      "Epoch [41/50], Step [379/735], Loss: 0.0570\n",
      "Epoch [41/50], Step [380/735], Loss: 0.0483\n",
      "Epoch [41/50], Step [381/735], Loss: 0.0471\n",
      "Epoch [41/50], Step [382/735], Loss: 0.0299\n",
      "Epoch [41/50], Step [383/735], Loss: 0.1049\n",
      "Epoch [41/50], Step [384/735], Loss: 0.0778\n",
      "Epoch [41/50], Step [385/735], Loss: 0.0378\n",
      "Epoch [41/50], Step [386/735], Loss: 0.0381\n",
      "Epoch [41/50], Step [387/735], Loss: 0.0389\n",
      "Epoch [41/50], Step [388/735], Loss: 0.0582\n",
      "Epoch [41/50], Step [389/735], Loss: 0.0580\n",
      "Epoch [41/50], Step [390/735], Loss: 0.0944\n",
      "Epoch [41/50], Step [391/735], Loss: 0.0384\n",
      "Epoch [41/50], Step [392/735], Loss: 0.0578\n",
      "Epoch [41/50], Step [393/735], Loss: 0.0317\n",
      "Epoch [41/50], Step [394/735], Loss: 0.0300\n",
      "Epoch [41/50], Step [395/735], Loss: 0.0765\n",
      "Epoch [41/50], Step [396/735], Loss: 0.0837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Step [397/735], Loss: 0.2081\n",
      "Epoch [41/50], Step [398/735], Loss: 0.0479\n",
      "Epoch [41/50], Step [399/735], Loss: 0.0418\n",
      "Epoch [41/50], Step [400/735], Loss: 0.0613\n",
      "Epoch [41/50], Step [401/735], Loss: 0.0151\n",
      "Epoch [41/50], Step [402/735], Loss: 0.0643\n",
      "Epoch [41/50], Step [403/735], Loss: 0.0292\n",
      "Epoch [41/50], Step [404/735], Loss: 0.2408\n",
      "Epoch [41/50], Step [405/735], Loss: 0.0548\n",
      "Epoch [41/50], Step [406/735], Loss: 0.0733\n",
      "Epoch [41/50], Step [407/735], Loss: 0.0714\n",
      "Epoch [41/50], Step [408/735], Loss: 0.1132\n",
      "Epoch [41/50], Step [409/735], Loss: 0.0493\n",
      "Epoch [41/50], Step [410/735], Loss: 0.1179\n",
      "Epoch [41/50], Step [411/735], Loss: 0.0322\n",
      "Epoch [41/50], Step [412/735], Loss: 0.0559\n",
      "Epoch [41/50], Step [413/735], Loss: 0.0243\n",
      "Epoch [41/50], Step [414/735], Loss: 0.0882\n",
      "Epoch [41/50], Step [415/735], Loss: 0.0917\n",
      "Epoch [41/50], Step [416/735], Loss: 0.1062\n",
      "Epoch [41/50], Step [417/735], Loss: 0.2162\n",
      "Epoch [41/50], Step [418/735], Loss: 0.0530\n",
      "Epoch [41/50], Step [419/735], Loss: 0.0529\n",
      "Epoch [41/50], Step [420/735], Loss: 0.0831\n",
      "Epoch [41/50], Step [421/735], Loss: 0.0479\n",
      "Epoch [41/50], Step [422/735], Loss: 0.0612\n",
      "Epoch [41/50], Step [423/735], Loss: 0.0411\n",
      "Epoch [41/50], Step [424/735], Loss: 0.0456\n",
      "Epoch [41/50], Step [425/735], Loss: 0.3761\n",
      "Epoch [41/50], Step [426/735], Loss: 0.0566\n",
      "Epoch [41/50], Step [427/735], Loss: 0.0527\n",
      "Epoch [41/50], Step [428/735], Loss: 0.0617\n",
      "Epoch [41/50], Step [429/735], Loss: 0.0430\n",
      "Epoch [41/50], Step [430/735], Loss: 0.0922\n",
      "Epoch [41/50], Step [431/735], Loss: 0.0757\n",
      "Epoch [41/50], Step [432/735], Loss: 0.0893\n",
      "Epoch [41/50], Step [433/735], Loss: 0.0515\n",
      "Epoch [41/50], Step [434/735], Loss: 0.0490\n",
      "Epoch [41/50], Step [435/735], Loss: 0.0228\n",
      "Epoch [41/50], Step [436/735], Loss: 0.0356\n",
      "Epoch [41/50], Step [437/735], Loss: 0.0450\n",
      "Epoch [41/50], Step [438/735], Loss: 0.0323\n",
      "Epoch [41/50], Step [439/735], Loss: 0.0304\n",
      "Epoch [41/50], Step [440/735], Loss: 0.0372\n",
      "Epoch [41/50], Step [441/735], Loss: 0.0277\n",
      "Epoch [41/50], Step [442/735], Loss: 0.0542\n",
      "Epoch [41/50], Step [443/735], Loss: 0.1709\n",
      "Epoch [41/50], Step [444/735], Loss: 0.0312\n",
      "Epoch [41/50], Step [445/735], Loss: 0.0369\n",
      "Epoch [41/50], Step [446/735], Loss: 0.0629\n",
      "Epoch [41/50], Step [447/735], Loss: 0.0283\n",
      "Epoch [41/50], Step [448/735], Loss: 0.0321\n",
      "Epoch [41/50], Step [449/735], Loss: 0.1470\n",
      "Epoch [41/50], Step [450/735], Loss: 0.0237\n",
      "Epoch [41/50], Step [451/735], Loss: 0.0231\n",
      "Epoch [41/50], Step [452/735], Loss: 0.0356\n",
      "Epoch [41/50], Step [453/735], Loss: 0.0608\n",
      "Epoch [41/50], Step [454/735], Loss: 0.0295\n",
      "Epoch [41/50], Step [455/735], Loss: 0.0623\n",
      "Epoch [41/50], Step [456/735], Loss: 0.0572\n",
      "Epoch [41/50], Step [457/735], Loss: 0.0344\n",
      "Epoch [41/50], Step [458/735], Loss: 0.0362\n",
      "Epoch [41/50], Step [459/735], Loss: 0.0605\n",
      "Epoch [41/50], Step [460/735], Loss: 0.0195\n",
      "Epoch [41/50], Step [461/735], Loss: 0.0339\n",
      "Epoch [41/50], Step [462/735], Loss: 0.0366\n",
      "Epoch [41/50], Step [463/735], Loss: 0.0645\n",
      "Epoch [41/50], Step [464/735], Loss: 0.0927\n",
      "Epoch [41/50], Step [465/735], Loss: 0.0558\n",
      "Epoch [41/50], Step [466/735], Loss: 0.0490\n",
      "Epoch [41/50], Step [467/735], Loss: 0.1170\n",
      "Epoch [41/50], Step [468/735], Loss: 0.0329\n",
      "Epoch [41/50], Step [469/735], Loss: 0.0459\n",
      "Epoch [41/50], Step [470/735], Loss: 0.0405\n",
      "Epoch [41/50], Step [471/735], Loss: 0.0511\n",
      "Epoch [41/50], Step [472/735], Loss: 0.0395\n",
      "Epoch [41/50], Step [473/735], Loss: 0.0368\n",
      "Epoch [41/50], Step [474/735], Loss: 0.0689\n",
      "Epoch [41/50], Step [475/735], Loss: 0.0423\n",
      "Epoch [41/50], Step [476/735], Loss: 0.0269\n",
      "Epoch [41/50], Step [477/735], Loss: 0.0362\n",
      "Epoch [41/50], Step [478/735], Loss: 0.0753\n",
      "Epoch [41/50], Step [479/735], Loss: 0.0781\n",
      "Epoch [41/50], Step [480/735], Loss: 0.1183\n",
      "Epoch [41/50], Step [481/735], Loss: 0.0477\n",
      "Epoch [41/50], Step [482/735], Loss: 0.0339\n",
      "Epoch [41/50], Step [483/735], Loss: 0.1059\n",
      "Epoch [41/50], Step [484/735], Loss: 0.0415\n",
      "Epoch [41/50], Step [485/735], Loss: 0.0655\n",
      "Epoch [41/50], Step [486/735], Loss: 0.0385\n",
      "Epoch [41/50], Step [487/735], Loss: 0.1938\n",
      "Epoch [41/50], Step [488/735], Loss: 0.0242\n",
      "Epoch [41/50], Step [489/735], Loss: 0.0602\n",
      "Epoch [41/50], Step [490/735], Loss: 0.0190\n",
      "Epoch [41/50], Step [491/735], Loss: 0.0188\n",
      "Epoch [41/50], Step [492/735], Loss: 0.2219\n",
      "Epoch [41/50], Step [493/735], Loss: 0.0246\n",
      "Epoch [41/50], Step [494/735], Loss: 0.0413\n",
      "Epoch [41/50], Step [495/735], Loss: 0.0790\n",
      "Epoch [41/50], Step [496/735], Loss: 0.0374\n",
      "Epoch [41/50], Step [497/735], Loss: 0.0278\n",
      "Epoch [41/50], Step [498/735], Loss: 0.0549\n",
      "Epoch [41/50], Step [499/735], Loss: 0.0717\n",
      "Epoch [41/50], Step [500/735], Loss: 0.0343\n",
      "Epoch [41/50], Step [501/735], Loss: 0.0311\n",
      "Epoch [41/50], Step [502/735], Loss: 0.0334\n",
      "Epoch [41/50], Step [503/735], Loss: 0.0451\n",
      "Epoch [41/50], Step [504/735], Loss: 0.0620\n",
      "Epoch [41/50], Step [505/735], Loss: 0.0833\n",
      "Epoch [41/50], Step [506/735], Loss: 0.0559\n",
      "Epoch [41/50], Step [507/735], Loss: 0.0805\n",
      "Epoch [41/50], Step [508/735], Loss: 0.0523\n",
      "Epoch [41/50], Step [509/735], Loss: 0.0746\n",
      "Epoch [41/50], Step [510/735], Loss: 0.0401\n",
      "Epoch [41/50], Step [511/735], Loss: 0.0429\n",
      "Epoch [41/50], Step [512/735], Loss: 0.1059\n",
      "Epoch [41/50], Step [513/735], Loss: 0.0818\n",
      "Epoch [41/50], Step [514/735], Loss: 0.0505\n",
      "Epoch [41/50], Step [515/735], Loss: 0.0852\n",
      "Epoch [41/50], Step [516/735], Loss: 0.0567\n",
      "Epoch [41/50], Step [517/735], Loss: 0.3735\n",
      "Epoch [41/50], Step [518/735], Loss: 0.0765\n",
      "Epoch [41/50], Step [519/735], Loss: 0.1460\n",
      "Epoch [41/50], Step [520/735], Loss: 0.0259\n",
      "Epoch [41/50], Step [521/735], Loss: 0.0968\n",
      "Epoch [41/50], Step [522/735], Loss: 0.0180\n",
      "Epoch [41/50], Step [523/735], Loss: 0.0354\n",
      "Epoch [41/50], Step [524/735], Loss: 0.0296\n",
      "Epoch [41/50], Step [525/735], Loss: 0.0224\n",
      "Epoch [41/50], Step [526/735], Loss: 0.0226\n",
      "Epoch [41/50], Step [527/735], Loss: 0.0568\n",
      "Epoch [41/50], Step [528/735], Loss: 0.0228\n",
      "Epoch [41/50], Step [529/735], Loss: 0.0268\n",
      "Epoch [41/50], Step [530/735], Loss: 0.0384\n",
      "Epoch [41/50], Step [531/735], Loss: 0.0567\n",
      "Epoch [41/50], Step [532/735], Loss: 0.1089\n",
      "Epoch [41/50], Step [533/735], Loss: 0.0488\n",
      "Epoch [41/50], Step [534/735], Loss: 0.0307\n",
      "Epoch [41/50], Step [535/735], Loss: 0.0401\n",
      "Epoch [41/50], Step [536/735], Loss: 0.0296\n",
      "Epoch [41/50], Step [537/735], Loss: 0.0369\n",
      "Epoch [41/50], Step [538/735], Loss: 0.0251\n",
      "Epoch [41/50], Step [539/735], Loss: 0.0411\n",
      "Epoch [41/50], Step [540/735], Loss: 0.0369\n",
      "Epoch [41/50], Step [541/735], Loss: 0.0649\n",
      "Epoch [41/50], Step [542/735], Loss: 0.0521\n",
      "Epoch [41/50], Step [543/735], Loss: 0.0597\n",
      "Epoch [41/50], Step [544/735], Loss: 0.0136\n",
      "Epoch [41/50], Step [545/735], Loss: 0.0527\n",
      "Epoch [41/50], Step [546/735], Loss: 0.0346\n",
      "Epoch [41/50], Step [547/735], Loss: 0.0639\n",
      "Epoch [41/50], Step [548/735], Loss: 0.1283\n",
      "Epoch [41/50], Step [549/735], Loss: 0.0915\n",
      "Epoch [41/50], Step [550/735], Loss: 0.0321\n",
      "Epoch [41/50], Step [551/735], Loss: 0.0877\n",
      "Epoch [41/50], Step [552/735], Loss: 0.0450\n",
      "Epoch [41/50], Step [553/735], Loss: 0.0205\n",
      "Epoch [41/50], Step [554/735], Loss: 0.0282\n",
      "Epoch [41/50], Step [555/735], Loss: 0.0455\n",
      "Epoch [41/50], Step [556/735], Loss: 0.0336\n",
      "Epoch [41/50], Step [557/735], Loss: 0.0771\n",
      "Epoch [41/50], Step [558/735], Loss: 0.0587\n",
      "Epoch [41/50], Step [559/735], Loss: 0.0411\n",
      "Epoch [41/50], Step [560/735], Loss: 0.0450\n",
      "Epoch [41/50], Step [561/735], Loss: 0.0306\n",
      "Epoch [41/50], Step [562/735], Loss: 0.1052\n",
      "Epoch [41/50], Step [563/735], Loss: 0.0192\n",
      "Epoch [41/50], Step [564/735], Loss: 0.0691\n",
      "Epoch [41/50], Step [565/735], Loss: 0.0515\n",
      "Epoch [41/50], Step [566/735], Loss: 0.0176\n",
      "Epoch [41/50], Step [567/735], Loss: 0.0387\n",
      "Epoch [41/50], Step [568/735], Loss: 0.0226\n",
      "Epoch [41/50], Step [569/735], Loss: 0.1944\n",
      "Epoch [41/50], Step [570/735], Loss: 0.0383\n",
      "Epoch [41/50], Step [571/735], Loss: 0.0105\n",
      "Epoch [41/50], Step [572/735], Loss: 0.0634\n",
      "Epoch [41/50], Step [573/735], Loss: 0.1279\n",
      "Epoch [41/50], Step [574/735], Loss: 0.0317\n",
      "Epoch [41/50], Step [575/735], Loss: 0.0344\n",
      "Epoch [41/50], Step [576/735], Loss: 0.0259\n",
      "Epoch [41/50], Step [577/735], Loss: 0.0420\n",
      "Epoch [41/50], Step [578/735], Loss: 0.0125\n",
      "Epoch [41/50], Step [579/735], Loss: 0.0447\n",
      "Epoch [41/50], Step [580/735], Loss: 0.0356\n",
      "Epoch [41/50], Step [581/735], Loss: 0.0951\n",
      "Epoch [41/50], Step [582/735], Loss: 0.0134\n",
      "Epoch [41/50], Step [583/735], Loss: 0.0356\n",
      "Epoch [41/50], Step [584/735], Loss: 0.0790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Step [585/735], Loss: 0.0568\n",
      "Epoch [41/50], Step [586/735], Loss: 0.0350\n",
      "Epoch [41/50], Step [587/735], Loss: 0.0360\n",
      "Epoch [41/50], Step [588/735], Loss: 0.0272\n",
      "Epoch [41/50], Step [589/735], Loss: 0.0293\n",
      "Epoch [41/50], Step [590/735], Loss: 0.1793\n",
      "Epoch [41/50], Step [591/735], Loss: 0.0327\n",
      "Epoch [41/50], Step [592/735], Loss: 0.0338\n",
      "Epoch [41/50], Step [593/735], Loss: 0.1305\n",
      "Epoch [41/50], Step [594/735], Loss: 0.0164\n",
      "Epoch [41/50], Step [595/735], Loss: 0.1192\n",
      "Epoch [41/50], Step [596/735], Loss: 0.0399\n",
      "Epoch [41/50], Step [597/735], Loss: 0.0606\n",
      "Epoch [41/50], Step [598/735], Loss: 0.0512\n",
      "Epoch [41/50], Step [599/735], Loss: 0.0392\n",
      "Epoch [41/50], Step [600/735], Loss: 0.0682\n",
      "Epoch [41/50], Step [601/735], Loss: 0.0710\n",
      "Epoch [41/50], Step [602/735], Loss: 0.0401\n",
      "Epoch [41/50], Step [603/735], Loss: 0.1748\n",
      "Epoch [41/50], Step [604/735], Loss: 0.0752\n",
      "Epoch [41/50], Step [605/735], Loss: 0.5425\n",
      "Epoch [41/50], Step [606/735], Loss: 0.0204\n",
      "Epoch [41/50], Step [607/735], Loss: 0.0553\n",
      "Epoch [41/50], Step [608/735], Loss: 0.4705\n",
      "Epoch [41/50], Step [609/735], Loss: 0.0758\n",
      "Epoch [41/50], Step [610/735], Loss: 0.0271\n",
      "Epoch [41/50], Step [611/735], Loss: 0.2615\n",
      "Epoch [41/50], Step [612/735], Loss: 0.0935\n",
      "Epoch [41/50], Step [613/735], Loss: 0.0457\n",
      "Epoch [41/50], Step [614/735], Loss: 0.1232\n",
      "Epoch [41/50], Step [615/735], Loss: 0.0339\n",
      "Epoch [41/50], Step [616/735], Loss: 0.0655\n",
      "Epoch [41/50], Step [617/735], Loss: 0.0257\n",
      "Epoch [41/50], Step [618/735], Loss: 0.0648\n",
      "Epoch [41/50], Step [619/735], Loss: 0.1031\n",
      "Epoch [41/50], Step [620/735], Loss: 0.0761\n",
      "Epoch [41/50], Step [621/735], Loss: 0.0384\n",
      "Epoch [41/50], Step [622/735], Loss: 0.0302\n",
      "Epoch [41/50], Step [623/735], Loss: 0.0768\n",
      "Epoch [41/50], Step [624/735], Loss: 0.1022\n",
      "Epoch [41/50], Step [625/735], Loss: 0.0252\n",
      "Epoch [41/50], Step [626/735], Loss: 0.0955\n",
      "Epoch [41/50], Step [627/735], Loss: 0.0759\n",
      "Epoch [41/50], Step [628/735], Loss: 0.0656\n",
      "Epoch [41/50], Step [629/735], Loss: 0.0235\n",
      "Epoch [41/50], Step [630/735], Loss: 0.0149\n",
      "Epoch [41/50], Step [631/735], Loss: 0.0566\n",
      "Epoch [41/50], Step [632/735], Loss: 0.0453\n",
      "Epoch [41/50], Step [633/735], Loss: 0.0453\n",
      "Epoch [41/50], Step [634/735], Loss: 0.0908\n",
      "Epoch [41/50], Step [635/735], Loss: 0.0371\n",
      "Epoch [41/50], Step [636/735], Loss: 0.0274\n",
      "Epoch [41/50], Step [637/735], Loss: 0.1613\n",
      "Epoch [41/50], Step [638/735], Loss: 0.0554\n",
      "Epoch [41/50], Step [639/735], Loss: 0.0510\n",
      "Epoch [41/50], Step [640/735], Loss: 0.0604\n",
      "Epoch [41/50], Step [641/735], Loss: 0.0350\n",
      "Epoch [41/50], Step [642/735], Loss: 0.0953\n",
      "Epoch [41/50], Step [643/735], Loss: 0.0573\n",
      "Epoch [41/50], Step [644/735], Loss: 0.0337\n",
      "Epoch [41/50], Step [645/735], Loss: 0.0411\n",
      "Epoch [41/50], Step [646/735], Loss: 0.0541\n",
      "Epoch [41/50], Step [647/735], Loss: 0.0203\n",
      "Epoch [41/50], Step [648/735], Loss: 0.0703\n",
      "Epoch [41/50], Step [649/735], Loss: 0.0557\n",
      "Epoch [41/50], Step [650/735], Loss: 0.0337\n",
      "Epoch [41/50], Step [651/735], Loss: 0.1755\n",
      "Epoch [41/50], Step [652/735], Loss: 0.1092\n",
      "Epoch [41/50], Step [653/735], Loss: 0.0518\n",
      "Epoch [41/50], Step [654/735], Loss: 0.0572\n",
      "Epoch [41/50], Step [655/735], Loss: 0.0214\n",
      "Epoch [41/50], Step [656/735], Loss: 0.2453\n",
      "Epoch [41/50], Step [657/735], Loss: 0.0482\n",
      "Epoch [41/50], Step [658/735], Loss: 0.0759\n",
      "Epoch [41/50], Step [659/735], Loss: 0.2801\n",
      "Epoch [41/50], Step [660/735], Loss: 0.0713\n",
      "Epoch [41/50], Step [661/735], Loss: 0.0191\n",
      "Epoch [41/50], Step [662/735], Loss: 0.2027\n",
      "Epoch [41/50], Step [663/735], Loss: 0.0368\n",
      "Epoch [41/50], Step [664/735], Loss: 0.0803\n",
      "Epoch [41/50], Step [665/735], Loss: 0.0550\n",
      "Epoch [41/50], Step [666/735], Loss: 0.0235\n",
      "Epoch [41/50], Step [667/735], Loss: 0.0683\n",
      "Epoch [41/50], Step [668/735], Loss: 0.0908\n",
      "Epoch [41/50], Step [669/735], Loss: 0.0410\n",
      "Epoch [41/50], Step [670/735], Loss: 0.0547\n",
      "Epoch [41/50], Step [671/735], Loss: 0.1158\n",
      "Epoch [41/50], Step [672/735], Loss: 0.0429\n",
      "Epoch [41/50], Step [673/735], Loss: 0.0300\n",
      "Epoch [41/50], Step [674/735], Loss: 0.0461\n",
      "Epoch [41/50], Step [675/735], Loss: 0.0241\n",
      "Epoch [41/50], Step [676/735], Loss: 0.0401\n",
      "Epoch [41/50], Step [677/735], Loss: 0.0488\n",
      "Epoch [41/50], Step [678/735], Loss: 0.1009\n",
      "Epoch [41/50], Step [679/735], Loss: 0.0372\n",
      "Epoch [41/50], Step [680/735], Loss: 0.0394\n",
      "Epoch [41/50], Step [681/735], Loss: 0.0234\n",
      "Epoch [41/50], Step [682/735], Loss: 0.1295\n",
      "Epoch [41/50], Step [683/735], Loss: 0.0519\n",
      "Epoch [41/50], Step [684/735], Loss: 0.0388\n",
      "Epoch [41/50], Step [685/735], Loss: 0.0541\n",
      "Epoch [41/50], Step [686/735], Loss: 0.0616\n",
      "Epoch [41/50], Step [687/735], Loss: 0.0648\n",
      "Epoch [41/50], Step [688/735], Loss: 0.0463\n",
      "Epoch [41/50], Step [689/735], Loss: 0.0332\n",
      "Epoch [41/50], Step [690/735], Loss: 0.0767\n",
      "Epoch [41/50], Step [691/735], Loss: 0.0382\n",
      "Epoch [41/50], Step [692/735], Loss: 0.0241\n",
      "Epoch [41/50], Step [693/735], Loss: 0.0857\n",
      "Epoch [41/50], Step [694/735], Loss: 0.0493\n",
      "Epoch [41/50], Step [695/735], Loss: 0.0635\n",
      "Epoch [41/50], Step [696/735], Loss: 0.0439\n",
      "Epoch [41/50], Step [697/735], Loss: 0.0531\n",
      "Epoch [41/50], Step [698/735], Loss: 0.0887\n",
      "Epoch [41/50], Step [699/735], Loss: 0.3310\n",
      "Epoch [41/50], Step [700/735], Loss: 0.0971\n",
      "Epoch [41/50], Step [701/735], Loss: 0.1271\n",
      "Epoch [41/50], Step [702/735], Loss: 0.0153\n",
      "Epoch [41/50], Step [703/735], Loss: 0.0526\n",
      "Epoch [41/50], Step [704/735], Loss: 0.0688\n",
      "Epoch [41/50], Step [705/735], Loss: 0.0703\n",
      "Epoch [41/50], Step [706/735], Loss: 0.0487\n",
      "Epoch [41/50], Step [707/735], Loss: 0.0250\n",
      "Epoch [41/50], Step [708/735], Loss: 0.0386\n",
      "Epoch [41/50], Step [709/735], Loss: 0.0552\n",
      "Epoch [41/50], Step [710/735], Loss: 0.0552\n",
      "Epoch [41/50], Step [711/735], Loss: 0.0469\n",
      "Epoch [41/50], Step [712/735], Loss: 0.0315\n",
      "Epoch [41/50], Step [713/735], Loss: 0.0789\n",
      "Epoch [41/50], Step [714/735], Loss: 0.0832\n",
      "Epoch [41/50], Step [715/735], Loss: 0.0272\n",
      "Epoch [41/50], Step [716/735], Loss: 0.0302\n",
      "Epoch [41/50], Step [717/735], Loss: 0.0923\n",
      "Epoch [41/50], Step [718/735], Loss: 0.0382\n",
      "Epoch [41/50], Step [719/735], Loss: 0.1093\n",
      "Epoch [41/50], Step [720/735], Loss: 0.0493\n",
      "Epoch [41/50], Step [721/735], Loss: 0.0473\n",
      "Epoch [41/50], Step [722/735], Loss: 0.1127\n",
      "Epoch [41/50], Step [723/735], Loss: 0.0320\n",
      "Epoch [41/50], Step [724/735], Loss: 0.0262\n",
      "Epoch [41/50], Step [725/735], Loss: 0.1330\n",
      "Epoch [41/50], Step [726/735], Loss: 0.0597\n",
      "Epoch [41/50], Step [727/735], Loss: 0.0314\n",
      "Epoch [41/50], Step [728/735], Loss: 0.0471\n",
      "Epoch [41/50], Step [729/735], Loss: 0.0332\n",
      "Epoch [41/50], Step [730/735], Loss: 0.0595\n",
      "Epoch [41/50], Step [731/735], Loss: 0.0473\n",
      "Epoch [41/50], Step [732/735], Loss: 0.0466\n",
      "Epoch [41/50], Step [733/735], Loss: 0.0425\n",
      "Epoch [41/50], Step [734/735], Loss: 0.1191\n",
      "Epoch [41/50], Step [735/735], Loss: 0.1064\n",
      "Epoch [42/50], Step [1/735], Loss: 0.0469\n",
      "Epoch [42/50], Step [2/735], Loss: 0.0728\n",
      "Epoch [42/50], Step [3/735], Loss: 0.0913\n",
      "Epoch [42/50], Step [4/735], Loss: 0.0224\n",
      "Epoch [42/50], Step [5/735], Loss: 0.0331\n",
      "Epoch [42/50], Step [6/735], Loss: 0.0773\n",
      "Epoch [42/50], Step [7/735], Loss: 0.0178\n",
      "Epoch [42/50], Step [8/735], Loss: 0.0581\n",
      "Epoch [42/50], Step [9/735], Loss: 0.0445\n",
      "Epoch [42/50], Step [10/735], Loss: 0.1066\n",
      "Epoch [42/50], Step [11/735], Loss: 0.0331\n",
      "Epoch [42/50], Step [12/735], Loss: 0.0255\n",
      "Epoch [42/50], Step [13/735], Loss: 0.0372\n",
      "Epoch [42/50], Step [14/735], Loss: 0.0689\n",
      "Epoch [42/50], Step [15/735], Loss: 0.0396\n",
      "Epoch [42/50], Step [16/735], Loss: 0.0854\n",
      "Epoch [42/50], Step [17/735], Loss: 0.0482\n",
      "Epoch [42/50], Step [18/735], Loss: 0.1149\n",
      "Epoch [42/50], Step [19/735], Loss: 0.0234\n",
      "Epoch [42/50], Step [20/735], Loss: 0.0459\n",
      "Epoch [42/50], Step [21/735], Loss: 0.0262\n",
      "Epoch [42/50], Step [22/735], Loss: 0.0458\n",
      "Epoch [42/50], Step [23/735], Loss: 0.0545\n",
      "Epoch [42/50], Step [24/735], Loss: 0.0535\n",
      "Epoch [42/50], Step [25/735], Loss: 0.0496\n",
      "Epoch [42/50], Step [26/735], Loss: 0.0750\n",
      "Epoch [42/50], Step [27/735], Loss: 0.0574\n",
      "Epoch [42/50], Step [28/735], Loss: 0.0545\n",
      "Epoch [42/50], Step [29/735], Loss: 0.0399\n",
      "Epoch [42/50], Step [30/735], Loss: 0.0501\n",
      "Epoch [42/50], Step [31/735], Loss: 0.0754\n",
      "Epoch [42/50], Step [32/735], Loss: 0.1032\n",
      "Epoch [42/50], Step [33/735], Loss: 0.1169\n",
      "Epoch [42/50], Step [34/735], Loss: 0.0287\n",
      "Epoch [42/50], Step [35/735], Loss: 0.0233\n",
      "Epoch [42/50], Step [36/735], Loss: 0.0635\n",
      "Epoch [42/50], Step [37/735], Loss: 0.0637\n",
      "Epoch [42/50], Step [38/735], Loss: 0.0397\n",
      "Epoch [42/50], Step [39/735], Loss: 0.2248\n",
      "Epoch [42/50], Step [40/735], Loss: 0.0544\n",
      "Epoch [42/50], Step [41/735], Loss: 0.0762\n",
      "Epoch [42/50], Step [42/735], Loss: 0.0576\n",
      "Epoch [42/50], Step [43/735], Loss: 0.0355\n",
      "Epoch [42/50], Step [44/735], Loss: 0.0935\n",
      "Epoch [42/50], Step [45/735], Loss: 0.1397\n",
      "Epoch [42/50], Step [46/735], Loss: 0.0660\n",
      "Epoch [42/50], Step [47/735], Loss: 0.0471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Step [48/735], Loss: 0.1076\n",
      "Epoch [42/50], Step [49/735], Loss: 0.0351\n",
      "Epoch [42/50], Step [50/735], Loss: 0.0305\n",
      "Epoch [42/50], Step [51/735], Loss: 0.0759\n",
      "Epoch [42/50], Step [52/735], Loss: 0.0421\n",
      "Epoch [42/50], Step [53/735], Loss: 0.0564\n",
      "Epoch [42/50], Step [54/735], Loss: 0.0288\n",
      "Epoch [42/50], Step [55/735], Loss: 0.0643\n",
      "Epoch [42/50], Step [56/735], Loss: 0.0889\n",
      "Epoch [42/50], Step [57/735], Loss: 0.0370\n",
      "Epoch [42/50], Step [58/735], Loss: 0.0361\n",
      "Epoch [42/50], Step [59/735], Loss: 0.0267\n",
      "Epoch [42/50], Step [60/735], Loss: 0.0438\n",
      "Epoch [42/50], Step [61/735], Loss: 0.0291\n",
      "Epoch [42/50], Step [62/735], Loss: 0.0300\n",
      "Epoch [42/50], Step [63/735], Loss: 0.0350\n",
      "Epoch [42/50], Step [64/735], Loss: 0.0733\n",
      "Epoch [42/50], Step [65/735], Loss: 0.0285\n",
      "Epoch [42/50], Step [66/735], Loss: 0.0460\n",
      "Epoch [42/50], Step [67/735], Loss: 0.1238\n",
      "Epoch [42/50], Step [68/735], Loss: 0.0407\n",
      "Epoch [42/50], Step [69/735], Loss: 0.1032\n",
      "Epoch [42/50], Step [70/735], Loss: 0.1692\n",
      "Epoch [42/50], Step [71/735], Loss: 0.0318\n",
      "Epoch [42/50], Step [72/735], Loss: 0.0444\n",
      "Epoch [42/50], Step [73/735], Loss: 0.1055\n",
      "Epoch [42/50], Step [74/735], Loss: 0.0150\n",
      "Epoch [42/50], Step [75/735], Loss: 0.0610\n",
      "Epoch [42/50], Step [76/735], Loss: 0.0354\n",
      "Epoch [42/50], Step [77/735], Loss: 0.0494\n",
      "Epoch [42/50], Step [78/735], Loss: 0.0205\n",
      "Epoch [42/50], Step [79/735], Loss: 0.0384\n",
      "Epoch [42/50], Step [80/735], Loss: 0.0385\n",
      "Epoch [42/50], Step [81/735], Loss: 0.0808\n",
      "Epoch [42/50], Step [82/735], Loss: 0.0489\n",
      "Epoch [42/50], Step [83/735], Loss: 0.0464\n",
      "Epoch [42/50], Step [84/735], Loss: 0.0654\n",
      "Epoch [42/50], Step [85/735], Loss: 0.0586\n",
      "Epoch [42/50], Step [86/735], Loss: 0.0549\n",
      "Epoch [42/50], Step [87/735], Loss: 0.0351\n",
      "Epoch [42/50], Step [88/735], Loss: 0.0466\n",
      "Epoch [42/50], Step [89/735], Loss: 0.0700\n",
      "Epoch [42/50], Step [90/735], Loss: 0.0286\n",
      "Epoch [42/50], Step [91/735], Loss: 0.0167\n",
      "Epoch [42/50], Step [92/735], Loss: 0.1024\n",
      "Epoch [42/50], Step [93/735], Loss: 0.1813\n",
      "Epoch [42/50], Step [94/735], Loss: 0.0612\n",
      "Epoch [42/50], Step [95/735], Loss: 0.0373\n",
      "Epoch [42/50], Step [96/735], Loss: 0.0440\n",
      "Epoch [42/50], Step [97/735], Loss: 0.0257\n",
      "Epoch [42/50], Step [98/735], Loss: 0.0423\n",
      "Epoch [42/50], Step [99/735], Loss: 0.0249\n",
      "Epoch [42/50], Step [100/735], Loss: 0.0552\n",
      "Epoch [42/50], Step [101/735], Loss: 0.0543\n",
      "Epoch [42/50], Step [102/735], Loss: 0.0235\n",
      "Epoch [42/50], Step [103/735], Loss: 0.0551\n",
      "Epoch [42/50], Step [104/735], Loss: 0.0536\n",
      "Epoch [42/50], Step [105/735], Loss: 0.0177\n",
      "Epoch [42/50], Step [106/735], Loss: 0.0403\n",
      "Epoch [42/50], Step [107/735], Loss: 0.0177\n",
      "Epoch [42/50], Step [108/735], Loss: 0.0883\n",
      "Epoch [42/50], Step [109/735], Loss: 0.0609\n",
      "Epoch [42/50], Step [110/735], Loss: 0.0164\n",
      "Epoch [42/50], Step [111/735], Loss: 0.0606\n",
      "Epoch [42/50], Step [112/735], Loss: 0.0315\n",
      "Epoch [42/50], Step [113/735], Loss: 0.3948\n",
      "Epoch [42/50], Step [114/735], Loss: 0.1026\n",
      "Epoch [42/50], Step [115/735], Loss: 0.0964\n",
      "Epoch [42/50], Step [116/735], Loss: 0.0587\n",
      "Epoch [42/50], Step [117/735], Loss: 0.0367\n",
      "Epoch [42/50], Step [118/735], Loss: 0.1366\n",
      "Epoch [42/50], Step [119/735], Loss: 0.0539\n",
      "Epoch [42/50], Step [120/735], Loss: 0.0678\n",
      "Epoch [42/50], Step [121/735], Loss: 0.0333\n",
      "Epoch [42/50], Step [122/735], Loss: 0.0475\n",
      "Epoch [42/50], Step [123/735], Loss: 0.1015\n",
      "Epoch [42/50], Step [124/735], Loss: 0.0344\n",
      "Epoch [42/50], Step [125/735], Loss: 0.0369\n",
      "Epoch [42/50], Step [126/735], Loss: 0.0347\n",
      "Epoch [42/50], Step [127/735], Loss: 0.0485\n",
      "Epoch [42/50], Step [128/735], Loss: 0.1062\n",
      "Epoch [42/50], Step [129/735], Loss: 0.0647\n",
      "Epoch [42/50], Step [130/735], Loss: 0.1840\n",
      "Epoch [42/50], Step [131/735], Loss: 0.0275\n",
      "Epoch [42/50], Step [132/735], Loss: 0.0635\n",
      "Epoch [42/50], Step [133/735], Loss: 0.0268\n",
      "Epoch [42/50], Step [134/735], Loss: 0.0258\n",
      "Epoch [42/50], Step [135/735], Loss: 0.0336\n",
      "Epoch [42/50], Step [136/735], Loss: 0.0318\n",
      "Epoch [42/50], Step [137/735], Loss: 0.0707\n",
      "Epoch [42/50], Step [138/735], Loss: 0.0504\n",
      "Epoch [42/50], Step [139/735], Loss: 0.0564\n",
      "Epoch [42/50], Step [140/735], Loss: 0.0405\n",
      "Epoch [42/50], Step [141/735], Loss: 0.0551\n",
      "Epoch [42/50], Step [142/735], Loss: 0.0542\n",
      "Epoch [42/50], Step [143/735], Loss: 0.0251\n",
      "Epoch [42/50], Step [144/735], Loss: 0.0979\n",
      "Epoch [42/50], Step [145/735], Loss: 0.0266\n",
      "Epoch [42/50], Step [146/735], Loss: 0.0807\n",
      "Epoch [42/50], Step [147/735], Loss: 0.0567\n",
      "Epoch [42/50], Step [148/735], Loss: 0.0137\n",
      "Epoch [42/50], Step [149/735], Loss: 0.0258\n",
      "Epoch [42/50], Step [150/735], Loss: 0.0991\n",
      "Epoch [42/50], Step [151/735], Loss: 0.0279\n",
      "Epoch [42/50], Step [152/735], Loss: 0.0789\n",
      "Epoch [42/50], Step [153/735], Loss: 0.0261\n",
      "Epoch [42/50], Step [154/735], Loss: 0.0667\n",
      "Epoch [42/50], Step [155/735], Loss: 0.0525\n",
      "Epoch [42/50], Step [156/735], Loss: 0.2524\n",
      "Epoch [42/50], Step [157/735], Loss: 0.1373\n",
      "Epoch [42/50], Step [158/735], Loss: 0.0274\n",
      "Epoch [42/50], Step [159/735], Loss: 0.0271\n",
      "Epoch [42/50], Step [160/735], Loss: 0.0827\n",
      "Epoch [42/50], Step [161/735], Loss: 0.0646\n",
      "Epoch [42/50], Step [162/735], Loss: 0.0602\n",
      "Epoch [42/50], Step [163/735], Loss: 0.0345\n",
      "Epoch [42/50], Step [164/735], Loss: 0.0392\n",
      "Epoch [42/50], Step [165/735], Loss: 0.0516\n",
      "Epoch [42/50], Step [166/735], Loss: 0.1017\n",
      "Epoch [42/50], Step [167/735], Loss: 0.0677\n",
      "Epoch [42/50], Step [168/735], Loss: 0.0365\n",
      "Epoch [42/50], Step [169/735], Loss: 0.0659\n",
      "Epoch [42/50], Step [170/735], Loss: 0.0252\n",
      "Epoch [42/50], Step [171/735], Loss: 0.0264\n",
      "Epoch [42/50], Step [172/735], Loss: 0.0709\n",
      "Epoch [42/50], Step [173/735], Loss: 0.0268\n",
      "Epoch [42/50], Step [174/735], Loss: 0.1407\n",
      "Epoch [42/50], Step [175/735], Loss: 0.0369\n",
      "Epoch [42/50], Step [176/735], Loss: 0.0376\n",
      "Epoch [42/50], Step [177/735], Loss: 0.0278\n",
      "Epoch [42/50], Step [178/735], Loss: 0.0629\n",
      "Epoch [42/50], Step [179/735], Loss: 0.0466\n",
      "Epoch [42/50], Step [180/735], Loss: 0.0472\n",
      "Epoch [42/50], Step [181/735], Loss: 0.0476\n",
      "Epoch [42/50], Step [182/735], Loss: 0.0370\n",
      "Epoch [42/50], Step [183/735], Loss: 0.1189\n",
      "Epoch [42/50], Step [184/735], Loss: 0.0739\n",
      "Epoch [42/50], Step [185/735], Loss: 0.0404\n",
      "Epoch [42/50], Step [186/735], Loss: 0.0420\n",
      "Epoch [42/50], Step [187/735], Loss: 0.0454\n",
      "Epoch [42/50], Step [188/735], Loss: 0.0918\n",
      "Epoch [42/50], Step [189/735], Loss: 0.0606\n",
      "Epoch [42/50], Step [190/735], Loss: 0.0163\n",
      "Epoch [42/50], Step [191/735], Loss: 0.0547\n",
      "Epoch [42/50], Step [192/735], Loss: 0.0261\n",
      "Epoch [42/50], Step [193/735], Loss: 0.0682\n",
      "Epoch [42/50], Step [194/735], Loss: 0.0544\n",
      "Epoch [42/50], Step [195/735], Loss: 0.2364\n",
      "Epoch [42/50], Step [196/735], Loss: 0.0158\n",
      "Epoch [42/50], Step [197/735], Loss: 0.0155\n",
      "Epoch [42/50], Step [198/735], Loss: 0.0492\n",
      "Epoch [42/50], Step [199/735], Loss: 0.0270\n",
      "Epoch [42/50], Step [200/735], Loss: 0.0233\n",
      "Epoch [42/50], Step [201/735], Loss: 0.0240\n",
      "Epoch [42/50], Step [202/735], Loss: 0.3673\n",
      "Epoch [42/50], Step [203/735], Loss: 0.0507\n",
      "Epoch [42/50], Step [204/735], Loss: 0.0848\n",
      "Epoch [42/50], Step [205/735], Loss: 0.0262\n",
      "Epoch [42/50], Step [206/735], Loss: 0.0749\n",
      "Epoch [42/50], Step [207/735], Loss: 0.2592\n",
      "Epoch [42/50], Step [208/735], Loss: 0.2662\n",
      "Epoch [42/50], Step [209/735], Loss: 0.0369\n",
      "Epoch [42/50], Step [210/735], Loss: 0.0210\n",
      "Epoch [42/50], Step [211/735], Loss: 0.0353\n",
      "Epoch [42/50], Step [212/735], Loss: 0.0288\n",
      "Epoch [42/50], Step [213/735], Loss: 0.0358\n",
      "Epoch [42/50], Step [214/735], Loss: 0.1237\n",
      "Epoch [42/50], Step [215/735], Loss: 0.0346\n",
      "Epoch [42/50], Step [216/735], Loss: 0.0394\n",
      "Epoch [42/50], Step [217/735], Loss: 0.2109\n",
      "Epoch [42/50], Step [218/735], Loss: 0.0299\n",
      "Epoch [42/50], Step [219/735], Loss: 0.0712\n",
      "Epoch [42/50], Step [220/735], Loss: 0.0344\n",
      "Epoch [42/50], Step [221/735], Loss: 0.0342\n",
      "Epoch [42/50], Step [222/735], Loss: 0.0617\n",
      "Epoch [42/50], Step [223/735], Loss: 0.0418\n",
      "Epoch [42/50], Step [224/735], Loss: 0.0458\n",
      "Epoch [42/50], Step [225/735], Loss: 0.0477\n",
      "Epoch [42/50], Step [226/735], Loss: 0.0671\n",
      "Epoch [42/50], Step [227/735], Loss: 0.0708\n",
      "Epoch [42/50], Step [228/735], Loss: 0.0356\n",
      "Epoch [42/50], Step [229/735], Loss: 0.3686\n",
      "Epoch [42/50], Step [230/735], Loss: 0.0317\n",
      "Epoch [42/50], Step [231/735], Loss: 0.0897\n",
      "Epoch [42/50], Step [232/735], Loss: 0.0828\n",
      "Epoch [42/50], Step [233/735], Loss: 0.0318\n",
      "Epoch [42/50], Step [234/735], Loss: 0.1023\n",
      "Epoch [42/50], Step [235/735], Loss: 0.0473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Step [236/735], Loss: 0.0513\n",
      "Epoch [42/50], Step [237/735], Loss: 0.0705\n",
      "Epoch [42/50], Step [238/735], Loss: 0.0901\n",
      "Epoch [42/50], Step [239/735], Loss: 0.0533\n",
      "Epoch [42/50], Step [240/735], Loss: 0.0500\n",
      "Epoch [42/50], Step [241/735], Loss: 0.0523\n",
      "Epoch [42/50], Step [242/735], Loss: 0.0449\n",
      "Epoch [42/50], Step [243/735], Loss: 0.0537\n",
      "Epoch [42/50], Step [244/735], Loss: 0.0226\n",
      "Epoch [42/50], Step [245/735], Loss: 0.1388\n",
      "Epoch [42/50], Step [246/735], Loss: 0.0407\n",
      "Epoch [42/50], Step [247/735], Loss: 0.1149\n",
      "Epoch [42/50], Step [248/735], Loss: 0.0548\n",
      "Epoch [42/50], Step [249/735], Loss: 0.0384\n",
      "Epoch [42/50], Step [250/735], Loss: 0.0524\n",
      "Epoch [42/50], Step [251/735], Loss: 0.0788\n",
      "Epoch [42/50], Step [252/735], Loss: 0.0734\n",
      "Epoch [42/50], Step [253/735], Loss: 0.1046\n",
      "Epoch [42/50], Step [254/735], Loss: 0.0266\n",
      "Epoch [42/50], Step [255/735], Loss: 0.0427\n",
      "Epoch [42/50], Step [256/735], Loss: 0.0504\n",
      "Epoch [42/50], Step [257/735], Loss: 0.0489\n",
      "Epoch [42/50], Step [258/735], Loss: 0.0365\n",
      "Epoch [42/50], Step [259/735], Loss: 0.0494\n",
      "Epoch [42/50], Step [260/735], Loss: 0.0289\n",
      "Epoch [42/50], Step [261/735], Loss: 0.0110\n",
      "Epoch [42/50], Step [262/735], Loss: 0.0794\n",
      "Epoch [42/50], Step [263/735], Loss: 0.0601\n",
      "Epoch [42/50], Step [264/735], Loss: 0.0412\n",
      "Epoch [42/50], Step [265/735], Loss: 0.0261\n",
      "Epoch [42/50], Step [266/735], Loss: 0.0264\n",
      "Epoch [42/50], Step [267/735], Loss: 0.0505\n",
      "Epoch [42/50], Step [268/735], Loss: 0.2310\n",
      "Epoch [42/50], Step [269/735], Loss: 0.0244\n",
      "Epoch [42/50], Step [270/735], Loss: 0.0743\n",
      "Epoch [42/50], Step [271/735], Loss: 0.0300\n",
      "Epoch [42/50], Step [272/735], Loss: 0.0242\n",
      "Epoch [42/50], Step [273/735], Loss: 0.0241\n",
      "Epoch [42/50], Step [274/735], Loss: 0.0709\n",
      "Epoch [42/50], Step [275/735], Loss: 0.0487\n",
      "Epoch [42/50], Step [276/735], Loss: 0.0338\n",
      "Epoch [42/50], Step [277/735], Loss: 0.0346\n",
      "Epoch [42/50], Step [278/735], Loss: 0.0363\n",
      "Epoch [42/50], Step [279/735], Loss: 0.0500\n",
      "Epoch [42/50], Step [280/735], Loss: 0.0338\n",
      "Epoch [42/50], Step [281/735], Loss: 0.0258\n",
      "Epoch [42/50], Step [282/735], Loss: 0.0516\n",
      "Epoch [42/50], Step [283/735], Loss: 0.0386\n",
      "Epoch [42/50], Step [284/735], Loss: 0.0291\n",
      "Epoch [42/50], Step [285/735], Loss: 0.0198\n",
      "Epoch [42/50], Step [286/735], Loss: 0.1813\n",
      "Epoch [42/50], Step [287/735], Loss: 0.0622\n",
      "Epoch [42/50], Step [288/735], Loss: 0.0846\n",
      "Epoch [42/50], Step [289/735], Loss: 0.0561\n",
      "Epoch [42/50], Step [290/735], Loss: 0.0862\n",
      "Epoch [42/50], Step [291/735], Loss: 0.1317\n",
      "Epoch [42/50], Step [292/735], Loss: 0.0436\n",
      "Epoch [42/50], Step [293/735], Loss: 0.0442\n",
      "Epoch [42/50], Step [294/735], Loss: 0.0569\n",
      "Epoch [42/50], Step [295/735], Loss: 0.0563\n",
      "Epoch [42/50], Step [296/735], Loss: 0.0403\n",
      "Epoch [42/50], Step [297/735], Loss: 0.2001\n",
      "Epoch [42/50], Step [298/735], Loss: 0.0299\n",
      "Epoch [42/50], Step [299/735], Loss: 0.0344\n",
      "Epoch [42/50], Step [300/735], Loss: 0.1173\n",
      "Epoch [42/50], Step [301/735], Loss: 0.1355\n",
      "Epoch [42/50], Step [302/735], Loss: 0.0257\n",
      "Epoch [42/50], Step [303/735], Loss: 0.0229\n",
      "Epoch [42/50], Step [304/735], Loss: 0.0321\n",
      "Epoch [42/50], Step [305/735], Loss: 0.0401\n",
      "Epoch [42/50], Step [306/735], Loss: 0.0187\n",
      "Epoch [42/50], Step [307/735], Loss: 0.0449\n",
      "Epoch [42/50], Step [308/735], Loss: 0.0302\n",
      "Epoch [42/50], Step [309/735], Loss: 0.1050\n",
      "Epoch [42/50], Step [310/735], Loss: 0.0324\n",
      "Epoch [42/50], Step [311/735], Loss: 0.0782\n",
      "Epoch [42/50], Step [312/735], Loss: 0.0746\n",
      "Epoch [42/50], Step [313/735], Loss: 0.0857\n",
      "Epoch [42/50], Step [314/735], Loss: 0.0602\n",
      "Epoch [42/50], Step [315/735], Loss: 0.0397\n",
      "Epoch [42/50], Step [316/735], Loss: 0.0475\n",
      "Epoch [42/50], Step [317/735], Loss: 0.0184\n",
      "Epoch [42/50], Step [318/735], Loss: 0.0323\n",
      "Epoch [42/50], Step [319/735], Loss: 0.0375\n",
      "Epoch [42/50], Step [320/735], Loss: 0.0175\n",
      "Epoch [42/50], Step [321/735], Loss: 0.0219\n",
      "Epoch [42/50], Step [322/735], Loss: 0.0309\n",
      "Epoch [42/50], Step [323/735], Loss: 0.0157\n",
      "Epoch [42/50], Step [324/735], Loss: 0.0553\n",
      "Epoch [42/50], Step [325/735], Loss: 0.1116\n",
      "Epoch [42/50], Step [326/735], Loss: 0.0715\n",
      "Epoch [42/50], Step [327/735], Loss: 0.1682\n",
      "Epoch [42/50], Step [328/735], Loss: 0.0225\n",
      "Epoch [42/50], Step [329/735], Loss: 0.0516\n",
      "Epoch [42/50], Step [330/735], Loss: 0.0507\n",
      "Epoch [42/50], Step [331/735], Loss: 0.0932\n",
      "Epoch [42/50], Step [332/735], Loss: 0.0339\n",
      "Epoch [42/50], Step [333/735], Loss: 0.0537\n",
      "Epoch [42/50], Step [334/735], Loss: 0.0210\n",
      "Epoch [42/50], Step [335/735], Loss: 0.0179\n",
      "Epoch [42/50], Step [336/735], Loss: 0.0207\n",
      "Epoch [42/50], Step [337/735], Loss: 0.0502\n",
      "Epoch [42/50], Step [338/735], Loss: 0.0188\n",
      "Epoch [42/50], Step [339/735], Loss: 0.0233\n",
      "Epoch [42/50], Step [340/735], Loss: 0.0227\n",
      "Epoch [42/50], Step [341/735], Loss: 0.0324\n",
      "Epoch [42/50], Step [342/735], Loss: 0.0994\n",
      "Epoch [42/50], Step [343/735], Loss: 0.1100\n",
      "Epoch [42/50], Step [344/735], Loss: 0.0451\n",
      "Epoch [42/50], Step [345/735], Loss: 0.0636\n",
      "Epoch [42/50], Step [346/735], Loss: 0.0870\n",
      "Epoch [42/50], Step [347/735], Loss: 0.0685\n",
      "Epoch [42/50], Step [348/735], Loss: 0.0499\n",
      "Epoch [42/50], Step [349/735], Loss: 0.0667\n",
      "Epoch [42/50], Step [350/735], Loss: 0.0432\n",
      "Epoch [42/50], Step [351/735], Loss: 0.0426\n",
      "Epoch [42/50], Step [352/735], Loss: 0.0348\n",
      "Epoch [42/50], Step [353/735], Loss: 0.0572\n",
      "Epoch [42/50], Step [354/735], Loss: 0.0965\n",
      "Epoch [42/50], Step [355/735], Loss: 0.0234\n",
      "Epoch [42/50], Step [356/735], Loss: 0.0279\n",
      "Epoch [42/50], Step [357/735], Loss: 0.0398\n",
      "Epoch [42/50], Step [358/735], Loss: 0.0429\n",
      "Epoch [42/50], Step [359/735], Loss: 0.0519\n",
      "Epoch [42/50], Step [360/735], Loss: 0.0771\n",
      "Epoch [42/50], Step [361/735], Loss: 0.0424\n",
      "Epoch [42/50], Step [362/735], Loss: 0.0187\n",
      "Epoch [42/50], Step [363/735], Loss: 0.0256\n",
      "Epoch [42/50], Step [364/735], Loss: 0.0353\n",
      "Epoch [42/50], Step [365/735], Loss: 0.1106\n",
      "Epoch [42/50], Step [366/735], Loss: 0.5789\n",
      "Epoch [42/50], Step [367/735], Loss: 0.0485\n",
      "Epoch [42/50], Step [368/735], Loss: 0.0527\n",
      "Epoch [42/50], Step [369/735], Loss: 0.0459\n",
      "Epoch [42/50], Step [370/735], Loss: 0.0433\n",
      "Epoch [42/50], Step [371/735], Loss: 0.1193\n",
      "Epoch [42/50], Step [372/735], Loss: 0.0493\n",
      "Epoch [42/50], Step [373/735], Loss: 0.0146\n",
      "Epoch [42/50], Step [374/735], Loss: 0.0522\n",
      "Epoch [42/50], Step [375/735], Loss: 0.0672\n",
      "Epoch [42/50], Step [376/735], Loss: 0.0464\n",
      "Epoch [42/50], Step [377/735], Loss: 0.0223\n",
      "Epoch [42/50], Step [378/735], Loss: 0.0584\n",
      "Epoch [42/50], Step [379/735], Loss: 0.0344\n",
      "Epoch [42/50], Step [380/735], Loss: 0.1278\n",
      "Epoch [42/50], Step [381/735], Loss: 0.1192\n",
      "Epoch [42/50], Step [382/735], Loss: 0.0297\n",
      "Epoch [42/50], Step [383/735], Loss: 0.0174\n",
      "Epoch [42/50], Step [384/735], Loss: 0.0137\n",
      "Epoch [42/50], Step [385/735], Loss: 0.0736\n",
      "Epoch [42/50], Step [386/735], Loss: 0.0799\n",
      "Epoch [42/50], Step [387/735], Loss: 0.0296\n",
      "Epoch [42/50], Step [388/735], Loss: 0.0455\n",
      "Epoch [42/50], Step [389/735], Loss: 0.0383\n",
      "Epoch [42/50], Step [390/735], Loss: 0.0357\n",
      "Epoch [42/50], Step [391/735], Loss: 0.0440\n",
      "Epoch [42/50], Step [392/735], Loss: 0.0646\n",
      "Epoch [42/50], Step [393/735], Loss: 0.0231\n",
      "Epoch [42/50], Step [394/735], Loss: 0.0177\n",
      "Epoch [42/50], Step [395/735], Loss: 0.0415\n",
      "Epoch [42/50], Step [396/735], Loss: 0.1041\n",
      "Epoch [42/50], Step [397/735], Loss: 0.0497\n",
      "Epoch [42/50], Step [398/735], Loss: 0.1660\n",
      "Epoch [42/50], Step [399/735], Loss: 0.1499\n",
      "Epoch [42/50], Step [400/735], Loss: 0.1695\n",
      "Epoch [42/50], Step [401/735], Loss: 0.0263\n",
      "Epoch [42/50], Step [402/735], Loss: 0.2963\n",
      "Epoch [42/50], Step [403/735], Loss: 0.0328\n",
      "Epoch [42/50], Step [404/735], Loss: 0.0439\n",
      "Epoch [42/50], Step [405/735], Loss: 0.0204\n",
      "Epoch [42/50], Step [406/735], Loss: 0.0651\n",
      "Epoch [42/50], Step [407/735], Loss: 0.0511\n",
      "Epoch [42/50], Step [408/735], Loss: 0.0684\n",
      "Epoch [42/50], Step [409/735], Loss: 0.1422\n",
      "Epoch [42/50], Step [410/735], Loss: 0.0956\n",
      "Epoch [42/50], Step [411/735], Loss: 0.0291\n",
      "Epoch [42/50], Step [412/735], Loss: 0.0310\n",
      "Epoch [42/50], Step [413/735], Loss: 0.0524\n",
      "Epoch [42/50], Step [414/735], Loss: 0.0407\n",
      "Epoch [42/50], Step [415/735], Loss: 0.0650\n",
      "Epoch [42/50], Step [416/735], Loss: 0.1635\n",
      "Epoch [42/50], Step [417/735], Loss: 0.2038\n",
      "Epoch [42/50], Step [418/735], Loss: 0.1029\n",
      "Epoch [42/50], Step [419/735], Loss: 0.3188\n",
      "Epoch [42/50], Step [420/735], Loss: 0.0374\n",
      "Epoch [42/50], Step [421/735], Loss: 0.0614\n",
      "Epoch [42/50], Step [422/735], Loss: 0.0985\n",
      "Epoch [42/50], Step [423/735], Loss: 0.0540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Step [424/735], Loss: 0.0261\n",
      "Epoch [42/50], Step [425/735], Loss: 0.0706\n",
      "Epoch [42/50], Step [426/735], Loss: 0.0334\n",
      "Epoch [42/50], Step [427/735], Loss: 0.0475\n",
      "Epoch [42/50], Step [428/735], Loss: 0.0224\n",
      "Epoch [42/50], Step [429/735], Loss: 0.0693\n",
      "Epoch [42/50], Step [430/735], Loss: 0.0889\n",
      "Epoch [42/50], Step [431/735], Loss: 0.0387\n",
      "Epoch [42/50], Step [432/735], Loss: 0.1333\n",
      "Epoch [42/50], Step [433/735], Loss: 0.0642\n",
      "Epoch [42/50], Step [434/735], Loss: 0.0301\n",
      "Epoch [42/50], Step [435/735], Loss: 0.0532\n",
      "Epoch [42/50], Step [436/735], Loss: 0.0683\n",
      "Epoch [42/50], Step [437/735], Loss: 0.0562\n",
      "Epoch [42/50], Step [438/735], Loss: 0.1217\n",
      "Epoch [42/50], Step [439/735], Loss: 0.0244\n",
      "Epoch [42/50], Step [440/735], Loss: 0.0704\n",
      "Epoch [42/50], Step [441/735], Loss: 0.0365\n",
      "Epoch [42/50], Step [442/735], Loss: 0.3731\n",
      "Epoch [42/50], Step [443/735], Loss: 0.0784\n",
      "Epoch [42/50], Step [444/735], Loss: 0.0598\n",
      "Epoch [42/50], Step [445/735], Loss: 0.0154\n",
      "Epoch [42/50], Step [446/735], Loss: 0.0673\n",
      "Epoch [42/50], Step [447/735], Loss: 0.0330\n",
      "Epoch [42/50], Step [448/735], Loss: 0.0647\n",
      "Epoch [42/50], Step [449/735], Loss: 0.1181\n",
      "Epoch [42/50], Step [450/735], Loss: 0.0706\n",
      "Epoch [42/50], Step [451/735], Loss: 0.0610\n",
      "Epoch [42/50], Step [452/735], Loss: 0.0809\n",
      "Epoch [42/50], Step [453/735], Loss: 0.0363\n",
      "Epoch [42/50], Step [454/735], Loss: 0.0418\n",
      "Epoch [42/50], Step [455/735], Loss: 0.0394\n",
      "Epoch [42/50], Step [456/735], Loss: 0.0335\n",
      "Epoch [42/50], Step [457/735], Loss: 0.0350\n",
      "Epoch [42/50], Step [458/735], Loss: 0.0715\n",
      "Epoch [42/50], Step [459/735], Loss: 0.0574\n",
      "Epoch [42/50], Step [460/735], Loss: 0.0278\n",
      "Epoch [42/50], Step [461/735], Loss: 0.0580\n",
      "Epoch [42/50], Step [462/735], Loss: 0.0674\n",
      "Epoch [42/50], Step [463/735], Loss: 0.0508\n",
      "Epoch [42/50], Step [464/735], Loss: 0.0405\n",
      "Epoch [42/50], Step [465/735], Loss: 0.0476\n",
      "Epoch [42/50], Step [466/735], Loss: 0.0334\n",
      "Epoch [42/50], Step [467/735], Loss: 0.0118\n",
      "Epoch [42/50], Step [468/735], Loss: 0.0321\n",
      "Epoch [42/50], Step [469/735], Loss: 0.0220\n",
      "Epoch [42/50], Step [470/735], Loss: 0.0258\n",
      "Epoch [42/50], Step [471/735], Loss: 0.0594\n",
      "Epoch [42/50], Step [472/735], Loss: 0.1048\n",
      "Epoch [42/50], Step [473/735], Loss: 0.0460\n",
      "Epoch [42/50], Step [474/735], Loss: 0.0745\n",
      "Epoch [42/50], Step [475/735], Loss: 0.0720\n",
      "Epoch [42/50], Step [476/735], Loss: 0.1145\n",
      "Epoch [42/50], Step [477/735], Loss: 0.0217\n",
      "Epoch [42/50], Step [478/735], Loss: 0.0255\n",
      "Epoch [42/50], Step [479/735], Loss: 0.1125\n",
      "Epoch [42/50], Step [480/735], Loss: 0.0364\n",
      "Epoch [42/50], Step [481/735], Loss: 0.0494\n",
      "Epoch [42/50], Step [482/735], Loss: 0.0215\n",
      "Epoch [42/50], Step [483/735], Loss: 0.1053\n",
      "Epoch [42/50], Step [484/735], Loss: 0.0514\n",
      "Epoch [42/50], Step [485/735], Loss: 0.0351\n",
      "Epoch [42/50], Step [486/735], Loss: 0.0580\n",
      "Epoch [42/50], Step [487/735], Loss: 0.0404\n",
      "Epoch [42/50], Step [488/735], Loss: 0.0664\n",
      "Epoch [42/50], Step [489/735], Loss: 0.0211\n",
      "Epoch [42/50], Step [490/735], Loss: 0.0300\n",
      "Epoch [42/50], Step [491/735], Loss: 0.1623\n",
      "Epoch [42/50], Step [492/735], Loss: 0.0448\n",
      "Epoch [42/50], Step [493/735], Loss: 0.0813\n",
      "Epoch [42/50], Step [494/735], Loss: 0.0294\n",
      "Epoch [42/50], Step [495/735], Loss: 0.0284\n",
      "Epoch [42/50], Step [496/735], Loss: 0.1057\n",
      "Epoch [42/50], Step [497/735], Loss: 0.0530\n",
      "Epoch [42/50], Step [498/735], Loss: 0.0425\n",
      "Epoch [42/50], Step [499/735], Loss: 0.0224\n",
      "Epoch [42/50], Step [500/735], Loss: 0.1817\n",
      "Epoch [42/50], Step [501/735], Loss: 0.0856\n",
      "Epoch [42/50], Step [502/735], Loss: 0.0947\n",
      "Epoch [42/50], Step [503/735], Loss: 0.0280\n",
      "Epoch [42/50], Step [504/735], Loss: 0.0481\n",
      "Epoch [42/50], Step [505/735], Loss: 0.0917\n",
      "Epoch [42/50], Step [506/735], Loss: 0.0417\n",
      "Epoch [42/50], Step [507/735], Loss: 0.0273\n",
      "Epoch [42/50], Step [508/735], Loss: 0.0513\n",
      "Epoch [42/50], Step [509/735], Loss: 0.0378\n",
      "Epoch [42/50], Step [510/735], Loss: 0.0417\n",
      "Epoch [42/50], Step [511/735], Loss: 0.0347\n",
      "Epoch [42/50], Step [512/735], Loss: 0.0315\n",
      "Epoch [42/50], Step [513/735], Loss: 0.2884\n",
      "Epoch [42/50], Step [514/735], Loss: 0.0552\n",
      "Epoch [42/50], Step [515/735], Loss: 0.0181\n",
      "Epoch [42/50], Step [516/735], Loss: 0.0250\n",
      "Epoch [42/50], Step [517/735], Loss: 0.0399\n",
      "Epoch [42/50], Step [518/735], Loss: 0.0425\n",
      "Epoch [42/50], Step [519/735], Loss: 0.0468\n",
      "Epoch [42/50], Step [520/735], Loss: 0.0311\n",
      "Epoch [42/50], Step [521/735], Loss: 0.2548\n",
      "Epoch [42/50], Step [522/735], Loss: 0.0792\n",
      "Epoch [42/50], Step [523/735], Loss: 0.0278\n",
      "Epoch [42/50], Step [524/735], Loss: 0.0174\n",
      "Epoch [42/50], Step [525/735], Loss: 0.0499\n",
      "Epoch [42/50], Step [526/735], Loss: 0.0459\n",
      "Epoch [42/50], Step [527/735], Loss: 0.0235\n",
      "Epoch [42/50], Step [528/735], Loss: 0.0305\n",
      "Epoch [42/50], Step [529/735], Loss: 0.1729\n",
      "Epoch [42/50], Step [530/735], Loss: 0.0316\n",
      "Epoch [42/50], Step [531/735], Loss: 0.0391\n",
      "Epoch [42/50], Step [532/735], Loss: 0.0705\n",
      "Epoch [42/50], Step [533/735], Loss: 0.0236\n",
      "Epoch [42/50], Step [534/735], Loss: 0.0443\n",
      "Epoch [42/50], Step [535/735], Loss: 0.0241\n",
      "Epoch [42/50], Step [536/735], Loss: 0.0625\n",
      "Epoch [42/50], Step [537/735], Loss: 0.0914\n",
      "Epoch [42/50], Step [538/735], Loss: 0.1421\n",
      "Epoch [42/50], Step [539/735], Loss: 0.0836\n",
      "Epoch [42/50], Step [540/735], Loss: 0.0315\n",
      "Epoch [42/50], Step [541/735], Loss: 0.0345\n",
      "Epoch [42/50], Step [542/735], Loss: 0.1054\n",
      "Epoch [42/50], Step [543/735], Loss: 0.0763\n",
      "Epoch [42/50], Step [544/735], Loss: 0.0283\n",
      "Epoch [42/50], Step [545/735], Loss: 0.0679\n",
      "Epoch [42/50], Step [546/735], Loss: 0.0435\n",
      "Epoch [42/50], Step [547/735], Loss: 0.0703\n",
      "Epoch [42/50], Step [548/735], Loss: 0.0471\n",
      "Epoch [42/50], Step [549/735], Loss: 0.0572\n",
      "Epoch [42/50], Step [550/735], Loss: 0.0228\n",
      "Epoch [42/50], Step [551/735], Loss: 0.0286\n",
      "Epoch [42/50], Step [552/735], Loss: 0.0793\n",
      "Epoch [42/50], Step [553/735], Loss: 0.0263\n",
      "Epoch [42/50], Step [554/735], Loss: 0.1509\n",
      "Epoch [42/50], Step [555/735], Loss: 0.0316\n",
      "Epoch [42/50], Step [556/735], Loss: 0.0354\n",
      "Epoch [42/50], Step [557/735], Loss: 0.1112\n",
      "Epoch [42/50], Step [558/735], Loss: 0.1054\n",
      "Epoch [42/50], Step [559/735], Loss: 0.0425\n",
      "Epoch [42/50], Step [560/735], Loss: 0.0117\n",
      "Epoch [42/50], Step [561/735], Loss: 0.0266\n",
      "Epoch [42/50], Step [562/735], Loss: 0.0648\n",
      "Epoch [42/50], Step [563/735], Loss: 0.1043\n",
      "Epoch [42/50], Step [564/735], Loss: 0.0966\n",
      "Epoch [42/50], Step [565/735], Loss: 0.0807\n",
      "Epoch [42/50], Step [566/735], Loss: 0.0769\n",
      "Epoch [42/50], Step [567/735], Loss: 0.0179\n",
      "Epoch [42/50], Step [568/735], Loss: 0.0615\n",
      "Epoch [42/50], Step [569/735], Loss: 0.0716\n",
      "Epoch [42/50], Step [570/735], Loss: 0.0528\n",
      "Epoch [42/50], Step [571/735], Loss: 0.0269\n",
      "Epoch [42/50], Step [572/735], Loss: 0.0504\n",
      "Epoch [42/50], Step [573/735], Loss: 0.0289\n",
      "Epoch [42/50], Step [574/735], Loss: 0.0309\n",
      "Epoch [42/50], Step [575/735], Loss: 0.0500\n",
      "Epoch [42/50], Step [576/735], Loss: 0.2854\n",
      "Epoch [42/50], Step [577/735], Loss: 0.0386\n",
      "Epoch [42/50], Step [578/735], Loss: 0.0917\n",
      "Epoch [42/50], Step [579/735], Loss: 0.0591\n",
      "Epoch [42/50], Step [580/735], Loss: 0.0268\n",
      "Epoch [42/50], Step [581/735], Loss: 0.0657\n",
      "Epoch [42/50], Step [582/735], Loss: 0.0721\n",
      "Epoch [42/50], Step [583/735], Loss: 0.1707\n",
      "Epoch [42/50], Step [584/735], Loss: 0.0787\n",
      "Epoch [42/50], Step [585/735], Loss: 0.0220\n",
      "Epoch [42/50], Step [586/735], Loss: 0.1108\n",
      "Epoch [42/50], Step [587/735], Loss: 0.0231\n",
      "Epoch [42/50], Step [588/735], Loss: 0.0338\n",
      "Epoch [42/50], Step [589/735], Loss: 0.0266\n",
      "Epoch [42/50], Step [590/735], Loss: 0.0827\n",
      "Epoch [42/50], Step [591/735], Loss: 0.1673\n",
      "Epoch [42/50], Step [592/735], Loss: 0.0556\n",
      "Epoch [42/50], Step [593/735], Loss: 0.0291\n",
      "Epoch [42/50], Step [594/735], Loss: 0.0406\n",
      "Epoch [42/50], Step [595/735], Loss: 0.0337\n",
      "Epoch [42/50], Step [596/735], Loss: 0.0851\n",
      "Epoch [42/50], Step [597/735], Loss: 0.0638\n",
      "Epoch [42/50], Step [598/735], Loss: 0.1206\n",
      "Epoch [42/50], Step [599/735], Loss: 0.0266\n",
      "Epoch [42/50], Step [600/735], Loss: 0.0667\n",
      "Epoch [42/50], Step [601/735], Loss: 0.0573\n",
      "Epoch [42/50], Step [602/735], Loss: 0.1089\n",
      "Epoch [42/50], Step [603/735], Loss: 0.3297\n",
      "Epoch [42/50], Step [604/735], Loss: 0.0559\n",
      "Epoch [42/50], Step [605/735], Loss: 0.0640\n",
      "Epoch [42/50], Step [606/735], Loss: 0.0312\n",
      "Epoch [42/50], Step [607/735], Loss: 0.0224\n",
      "Epoch [42/50], Step [608/735], Loss: 0.0343\n",
      "Epoch [42/50], Step [609/735], Loss: 0.0363\n",
      "Epoch [42/50], Step [610/735], Loss: 0.0908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Step [611/735], Loss: 0.0685\n",
      "Epoch [42/50], Step [612/735], Loss: 0.0918\n",
      "Epoch [42/50], Step [613/735], Loss: 0.0431\n",
      "Epoch [42/50], Step [614/735], Loss: 0.0507\n",
      "Epoch [42/50], Step [615/735], Loss: 0.0130\n",
      "Epoch [42/50], Step [616/735], Loss: 0.0514\n",
      "Epoch [42/50], Step [617/735], Loss: 0.0330\n",
      "Epoch [42/50], Step [618/735], Loss: 0.0548\n",
      "Epoch [42/50], Step [619/735], Loss: 0.0414\n",
      "Epoch [42/50], Step [620/735], Loss: 0.0662\n",
      "Epoch [42/50], Step [621/735], Loss: 0.2548\n",
      "Epoch [42/50], Step [622/735], Loss: 0.0527\n",
      "Epoch [42/50], Step [623/735], Loss: 0.0333\n",
      "Epoch [42/50], Step [624/735], Loss: 0.1066\n",
      "Epoch [42/50], Step [625/735], Loss: 0.0364\n",
      "Epoch [42/50], Step [626/735], Loss: 0.0407\n",
      "Epoch [42/50], Step [627/735], Loss: 0.0599\n",
      "Epoch [42/50], Step [628/735], Loss: 0.0659\n",
      "Epoch [42/50], Step [629/735], Loss: 0.0283\n",
      "Epoch [42/50], Step [630/735], Loss: 0.0460\n",
      "Epoch [42/50], Step [631/735], Loss: 0.0559\n",
      "Epoch [42/50], Step [632/735], Loss: 0.0299\n",
      "Epoch [42/50], Step [633/735], Loss: 0.0550\n",
      "Epoch [42/50], Step [634/735], Loss: 0.0777\n",
      "Epoch [42/50], Step [635/735], Loss: 0.0774\n",
      "Epoch [42/50], Step [636/735], Loss: 0.0494\n",
      "Epoch [42/50], Step [637/735], Loss: 0.0182\n",
      "Epoch [42/50], Step [638/735], Loss: 0.1143\n",
      "Epoch [42/50], Step [639/735], Loss: 0.0644\n",
      "Epoch [42/50], Step [640/735], Loss: 0.0577\n",
      "Epoch [42/50], Step [641/735], Loss: 0.0714\n",
      "Epoch [42/50], Step [642/735], Loss: 0.0615\n",
      "Epoch [42/50], Step [643/735], Loss: 0.0713\n",
      "Epoch [42/50], Step [644/735], Loss: 0.0341\n",
      "Epoch [42/50], Step [645/735], Loss: 0.1025\n",
      "Epoch [42/50], Step [646/735], Loss: 0.0641\n",
      "Epoch [42/50], Step [647/735], Loss: 0.2383\n",
      "Epoch [42/50], Step [648/735], Loss: 0.0639\n",
      "Epoch [42/50], Step [649/735], Loss: 0.1091\n",
      "Epoch [42/50], Step [650/735], Loss: 0.0163\n",
      "Epoch [42/50], Step [651/735], Loss: 0.0754\n",
      "Epoch [42/50], Step [652/735], Loss: 0.0791\n",
      "Epoch [42/50], Step [653/735], Loss: 0.2236\n",
      "Epoch [42/50], Step [654/735], Loss: 0.0692\n",
      "Epoch [42/50], Step [655/735], Loss: 0.3667\n",
      "Epoch [42/50], Step [656/735], Loss: 0.0254\n",
      "Epoch [42/50], Step [657/735], Loss: 0.1131\n",
      "Epoch [42/50], Step [658/735], Loss: 0.0391\n",
      "Epoch [42/50], Step [659/735], Loss: 0.0183\n",
      "Epoch [42/50], Step [660/735], Loss: 0.0478\n",
      "Epoch [42/50], Step [661/735], Loss: 0.0836\n",
      "Epoch [42/50], Step [662/735], Loss: 0.0333\n",
      "Epoch [42/50], Step [663/735], Loss: 0.0381\n",
      "Epoch [42/50], Step [664/735], Loss: 0.0574\n",
      "Epoch [42/50], Step [665/735], Loss: 0.0444\n",
      "Epoch [42/50], Step [666/735], Loss: 0.0356\n",
      "Epoch [42/50], Step [667/735], Loss: 0.0300\n",
      "Epoch [42/50], Step [668/735], Loss: 0.0666\n",
      "Epoch [42/50], Step [669/735], Loss: 0.0695\n",
      "Epoch [42/50], Step [670/735], Loss: 0.0438\n",
      "Epoch [42/50], Step [671/735], Loss: 0.0643\n",
      "Epoch [42/50], Step [672/735], Loss: 0.0631\n",
      "Epoch [42/50], Step [673/735], Loss: 0.1020\n",
      "Epoch [42/50], Step [674/735], Loss: 0.0231\n",
      "Epoch [42/50], Step [675/735], Loss: 0.0779\n",
      "Epoch [42/50], Step [676/735], Loss: 0.0374\n",
      "Epoch [42/50], Step [677/735], Loss: 0.0608\n",
      "Epoch [42/50], Step [678/735], Loss: 0.0374\n",
      "Epoch [42/50], Step [679/735], Loss: 0.0580\n",
      "Epoch [42/50], Step [680/735], Loss: 0.1648\n",
      "Epoch [42/50], Step [681/735], Loss: 0.1618\n",
      "Epoch [42/50], Step [682/735], Loss: 0.0343\n",
      "Epoch [42/50], Step [683/735], Loss: 0.0363\n",
      "Epoch [42/50], Step [684/735], Loss: 0.1609\n",
      "Epoch [42/50], Step [685/735], Loss: 0.0170\n",
      "Epoch [42/50], Step [686/735], Loss: 0.2023\n",
      "Epoch [42/50], Step [687/735], Loss: 0.1103\n",
      "Epoch [42/50], Step [688/735], Loss: 0.0807\n",
      "Epoch [42/50], Step [689/735], Loss: 0.0803\n",
      "Epoch [42/50], Step [690/735], Loss: 0.0557\n",
      "Epoch [42/50], Step [691/735], Loss: 0.0358\n",
      "Epoch [42/50], Step [692/735], Loss: 0.0890\n",
      "Epoch [42/50], Step [693/735], Loss: 0.0715\n",
      "Epoch [42/50], Step [694/735], Loss: 0.0376\n",
      "Epoch [42/50], Step [695/735], Loss: 0.0199\n",
      "Epoch [42/50], Step [696/735], Loss: 0.0780\n",
      "Epoch [42/50], Step [697/735], Loss: 0.2852\n",
      "Epoch [42/50], Step [698/735], Loss: 0.0260\n",
      "Epoch [42/50], Step [699/735], Loss: 0.0313\n",
      "Epoch [42/50], Step [700/735], Loss: 0.0414\n",
      "Epoch [42/50], Step [701/735], Loss: 0.0587\n",
      "Epoch [42/50], Step [702/735], Loss: 0.0363\n",
      "Epoch [42/50], Step [703/735], Loss: 0.0761\n",
      "Epoch [42/50], Step [704/735], Loss: 0.0478\n",
      "Epoch [42/50], Step [705/735], Loss: 0.0515\n",
      "Epoch [42/50], Step [706/735], Loss: 0.0904\n",
      "Epoch [42/50], Step [707/735], Loss: 0.1395\n",
      "Epoch [42/50], Step [708/735], Loss: 0.0567\n",
      "Epoch [42/50], Step [709/735], Loss: 0.0540\n",
      "Epoch [42/50], Step [710/735], Loss: 0.0358\n",
      "Epoch [42/50], Step [711/735], Loss: 0.0539\n",
      "Epoch [42/50], Step [712/735], Loss: 0.1620\n",
      "Epoch [42/50], Step [713/735], Loss: 0.0704\n",
      "Epoch [42/50], Step [714/735], Loss: 0.1738\n",
      "Epoch [42/50], Step [715/735], Loss: 0.0232\n",
      "Epoch [42/50], Step [716/735], Loss: 0.3206\n",
      "Epoch [42/50], Step [717/735], Loss: 0.0517\n",
      "Epoch [42/50], Step [718/735], Loss: 0.0791\n",
      "Epoch [42/50], Step [719/735], Loss: 0.0608\n",
      "Epoch [42/50], Step [720/735], Loss: 0.2209\n",
      "Epoch [42/50], Step [721/735], Loss: 0.0545\n",
      "Epoch [42/50], Step [722/735], Loss: 0.1291\n",
      "Epoch [42/50], Step [723/735], Loss: 0.0653\n",
      "Epoch [42/50], Step [724/735], Loss: 0.0431\n",
      "Epoch [42/50], Step [725/735], Loss: 0.1502\n",
      "Epoch [42/50], Step [726/735], Loss: 0.0571\n",
      "Epoch [42/50], Step [727/735], Loss: 0.0315\n",
      "Epoch [42/50], Step [728/735], Loss: 0.0233\n",
      "Epoch [42/50], Step [729/735], Loss: 0.0174\n",
      "Epoch [42/50], Step [730/735], Loss: 0.0252\n",
      "Epoch [42/50], Step [731/735], Loss: 0.2486\n",
      "Epoch [42/50], Step [732/735], Loss: 0.0228\n",
      "Epoch [42/50], Step [733/735], Loss: 0.1259\n",
      "Epoch [42/50], Step [734/735], Loss: 0.2087\n",
      "Epoch [42/50], Step [735/735], Loss: 0.0196\n",
      "Epoch [43/50], Step [1/735], Loss: 0.0406\n",
      "Epoch [43/50], Step [2/735], Loss: 0.0679\n",
      "Epoch [43/50], Step [3/735], Loss: 0.0347\n",
      "Epoch [43/50], Step [4/735], Loss: 0.0557\n",
      "Epoch [43/50], Step [5/735], Loss: 0.0599\n",
      "Epoch [43/50], Step [6/735], Loss: 0.0483\n",
      "Epoch [43/50], Step [7/735], Loss: 0.0937\n",
      "Epoch [43/50], Step [8/735], Loss: 0.0632\n",
      "Epoch [43/50], Step [9/735], Loss: 0.0280\n",
      "Epoch [43/50], Step [10/735], Loss: 0.0413\n",
      "Epoch [43/50], Step [11/735], Loss: 0.0282\n",
      "Epoch [43/50], Step [12/735], Loss: 0.0682\n",
      "Epoch [43/50], Step [13/735], Loss: 0.0197\n",
      "Epoch [43/50], Step [14/735], Loss: 0.0544\n",
      "Epoch [43/50], Step [15/735], Loss: 0.0573\n",
      "Epoch [43/50], Step [16/735], Loss: 0.2028\n",
      "Epoch [43/50], Step [17/735], Loss: 0.0486\n",
      "Epoch [43/50], Step [18/735], Loss: 0.0372\n",
      "Epoch [43/50], Step [19/735], Loss: 0.0368\n",
      "Epoch [43/50], Step [20/735], Loss: 0.0278\n",
      "Epoch [43/50], Step [21/735], Loss: 0.0511\n",
      "Epoch [43/50], Step [22/735], Loss: 0.2749\n",
      "Epoch [43/50], Step [23/735], Loss: 0.0439\n",
      "Epoch [43/50], Step [24/735], Loss: 0.0645\n",
      "Epoch [43/50], Step [25/735], Loss: 0.1520\n",
      "Epoch [43/50], Step [26/735], Loss: 0.0665\n",
      "Epoch [43/50], Step [27/735], Loss: 0.2486\n",
      "Epoch [43/50], Step [28/735], Loss: 0.1446\n",
      "Epoch [43/50], Step [29/735], Loss: 0.0446\n",
      "Epoch [43/50], Step [30/735], Loss: 0.2387\n",
      "Epoch [43/50], Step [31/735], Loss: 0.0938\n",
      "Epoch [43/50], Step [32/735], Loss: 0.0348\n",
      "Epoch [43/50], Step [33/735], Loss: 0.0390\n",
      "Epoch [43/50], Step [34/735], Loss: 0.0706\n",
      "Epoch [43/50], Step [35/735], Loss: 0.1555\n",
      "Epoch [43/50], Step [36/735], Loss: 0.1137\n",
      "Epoch [43/50], Step [37/735], Loss: 0.3897\n",
      "Epoch [43/50], Step [38/735], Loss: 0.0614\n",
      "Epoch [43/50], Step [39/735], Loss: 0.0353\n",
      "Epoch [43/50], Step [40/735], Loss: 0.0763\n",
      "Epoch [43/50], Step [41/735], Loss: 0.0598\n",
      "Epoch [43/50], Step [42/735], Loss: 0.0374\n",
      "Epoch [43/50], Step [43/735], Loss: 0.0280\n",
      "Epoch [43/50], Step [44/735], Loss: 0.0372\n",
      "Epoch [43/50], Step [45/735], Loss: 0.0298\n",
      "Epoch [43/50], Step [46/735], Loss: 0.1022\n",
      "Epoch [43/50], Step [47/735], Loss: 0.0420\n",
      "Epoch [43/50], Step [48/735], Loss: 0.0379\n",
      "Epoch [43/50], Step [49/735], Loss: 0.0265\n",
      "Epoch [43/50], Step [50/735], Loss: 0.0349\n",
      "Epoch [43/50], Step [51/735], Loss: 0.0574\n",
      "Epoch [43/50], Step [52/735], Loss: 0.1825\n",
      "Epoch [43/50], Step [53/735], Loss: 0.0801\n",
      "Epoch [43/50], Step [54/735], Loss: 0.0260\n",
      "Epoch [43/50], Step [55/735], Loss: 0.0739\n",
      "Epoch [43/50], Step [56/735], Loss: 0.0969\n",
      "Epoch [43/50], Step [57/735], Loss: 0.2517\n",
      "Epoch [43/50], Step [58/735], Loss: 0.2568\n",
      "Epoch [43/50], Step [59/735], Loss: 0.0535\n",
      "Epoch [43/50], Step [60/735], Loss: 0.0471\n",
      "Epoch [43/50], Step [61/735], Loss: 0.1507\n",
      "Epoch [43/50], Step [62/735], Loss: 0.0986\n",
      "Epoch [43/50], Step [63/735], Loss: 0.0752\n",
      "Epoch [43/50], Step [64/735], Loss: 0.0357\n",
      "Epoch [43/50], Step [65/735], Loss: 0.0270\n",
      "Epoch [43/50], Step [66/735], Loss: 0.0249\n",
      "Epoch [43/50], Step [67/735], Loss: 0.0518\n",
      "Epoch [43/50], Step [68/735], Loss: 0.0822\n",
      "Epoch [43/50], Step [69/735], Loss: 0.0368\n",
      "Epoch [43/50], Step [70/735], Loss: 0.0380\n",
      "Epoch [43/50], Step [71/735], Loss: 0.0982\n",
      "Epoch [43/50], Step [72/735], Loss: 0.0408\n",
      "Epoch [43/50], Step [73/735], Loss: 0.0621\n",
      "Epoch [43/50], Step [74/735], Loss: 0.0465\n",
      "Epoch [43/50], Step [75/735], Loss: 0.0385\n",
      "Epoch [43/50], Step [76/735], Loss: 0.0868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Step [77/735], Loss: 0.0191\n",
      "Epoch [43/50], Step [78/735], Loss: 0.0802\n",
      "Epoch [43/50], Step [79/735], Loss: 0.0639\n",
      "Epoch [43/50], Step [80/735], Loss: 0.0836\n",
      "Epoch [43/50], Step [81/735], Loss: 0.0756\n",
      "Epoch [43/50], Step [82/735], Loss: 0.0549\n",
      "Epoch [43/50], Step [83/735], Loss: 0.0384\n",
      "Epoch [43/50], Step [84/735], Loss: 0.0333\n",
      "Epoch [43/50], Step [85/735], Loss: 0.0826\n",
      "Epoch [43/50], Step [86/735], Loss: 0.1469\n",
      "Epoch [43/50], Step [87/735], Loss: 0.0811\n",
      "Epoch [43/50], Step [88/735], Loss: 0.0135\n",
      "Epoch [43/50], Step [89/735], Loss: 0.2996\n",
      "Epoch [43/50], Step [90/735], Loss: 0.0694\n",
      "Epoch [43/50], Step [91/735], Loss: 0.0080\n",
      "Epoch [43/50], Step [92/735], Loss: 0.0140\n",
      "Epoch [43/50], Step [93/735], Loss: 0.0638\n",
      "Epoch [43/50], Step [94/735], Loss: 0.0435\n",
      "Epoch [43/50], Step [95/735], Loss: 0.0183\n",
      "Epoch [43/50], Step [96/735], Loss: 0.0393\n",
      "Epoch [43/50], Step [97/735], Loss: 0.1390\n",
      "Epoch [43/50], Step [98/735], Loss: 0.0289\n",
      "Epoch [43/50], Step [99/735], Loss: 0.0628\n",
      "Epoch [43/50], Step [100/735], Loss: 0.0866\n",
      "Epoch [43/50], Step [101/735], Loss: 0.0766\n",
      "Epoch [43/50], Step [102/735], Loss: 0.0320\n",
      "Epoch [43/50], Step [103/735], Loss: 0.0528\n",
      "Epoch [43/50], Step [104/735], Loss: 0.1170\n",
      "Epoch [43/50], Step [105/735], Loss: 0.0430\n",
      "Epoch [43/50], Step [106/735], Loss: 0.0427\n",
      "Epoch [43/50], Step [107/735], Loss: 0.0930\n",
      "Epoch [43/50], Step [108/735], Loss: 0.1138\n",
      "Epoch [43/50], Step [109/735], Loss: 0.0620\n",
      "Epoch [43/50], Step [110/735], Loss: 0.0233\n",
      "Epoch [43/50], Step [111/735], Loss: 0.0645\n",
      "Epoch [43/50], Step [112/735], Loss: 0.0561\n",
      "Epoch [43/50], Step [113/735], Loss: 0.0473\n",
      "Epoch [43/50], Step [114/735], Loss: 0.0276\n",
      "Epoch [43/50], Step [115/735], Loss: 0.0858\n",
      "Epoch [43/50], Step [116/735], Loss: 0.0573\n",
      "Epoch [43/50], Step [117/735], Loss: 0.0212\n",
      "Epoch [43/50], Step [118/735], Loss: 0.0353\n",
      "Epoch [43/50], Step [119/735], Loss: 0.0367\n",
      "Epoch [43/50], Step [120/735], Loss: 0.0290\n",
      "Epoch [43/50], Step [121/735], Loss: 0.0368\n",
      "Epoch [43/50], Step [122/735], Loss: 0.0504\n",
      "Epoch [43/50], Step [123/735], Loss: 0.0348\n",
      "Epoch [43/50], Step [124/735], Loss: 0.0253\n",
      "Epoch [43/50], Step [125/735], Loss: 0.0267\n",
      "Epoch [43/50], Step [126/735], Loss: 0.0521\n",
      "Epoch [43/50], Step [127/735], Loss: 0.0493\n",
      "Epoch [43/50], Step [128/735], Loss: 0.1236\n",
      "Epoch [43/50], Step [129/735], Loss: 0.1008\n",
      "Epoch [43/50], Step [130/735], Loss: 0.0347\n",
      "Epoch [43/50], Step [131/735], Loss: 0.1256\n",
      "Epoch [43/50], Step [132/735], Loss: 0.0144\n",
      "Epoch [43/50], Step [133/735], Loss: 0.0817\n",
      "Epoch [43/50], Step [134/735], Loss: 0.0346\n",
      "Epoch [43/50], Step [135/735], Loss: 0.0722\n",
      "Epoch [43/50], Step [136/735], Loss: 0.0164\n",
      "Epoch [43/50], Step [137/735], Loss: 0.0549\n",
      "Epoch [43/50], Step [138/735], Loss: 0.0204\n",
      "Epoch [43/50], Step [139/735], Loss: 0.0318\n",
      "Epoch [43/50], Step [140/735], Loss: 0.0904\n",
      "Epoch [43/50], Step [141/735], Loss: 0.0521\n",
      "Epoch [43/50], Step [142/735], Loss: 0.1898\n",
      "Epoch [43/50], Step [143/735], Loss: 0.1004\n",
      "Epoch [43/50], Step [144/735], Loss: 0.0797\n",
      "Epoch [43/50], Step [145/735], Loss: 0.0809\n",
      "Epoch [43/50], Step [146/735], Loss: 0.0378\n",
      "Epoch [43/50], Step [147/735], Loss: 0.0633\n",
      "Epoch [43/50], Step [148/735], Loss: 0.1650\n",
      "Epoch [43/50], Step [149/735], Loss: 0.0471\n",
      "Epoch [43/50], Step [150/735], Loss: 0.1013\n",
      "Epoch [43/50], Step [151/735], Loss: 0.0456\n",
      "Epoch [43/50], Step [152/735], Loss: 0.0373\n",
      "Epoch [43/50], Step [153/735], Loss: 0.0584\n",
      "Epoch [43/50], Step [154/735], Loss: 0.0616\n",
      "Epoch [43/50], Step [155/735], Loss: 0.0429\n",
      "Epoch [43/50], Step [156/735], Loss: 0.0466\n",
      "Epoch [43/50], Step [157/735], Loss: 0.0700\n",
      "Epoch [43/50], Step [158/735], Loss: 0.0163\n",
      "Epoch [43/50], Step [159/735], Loss: 0.3879\n",
      "Epoch [43/50], Step [160/735], Loss: 0.4561\n",
      "Epoch [43/50], Step [161/735], Loss: 0.0756\n",
      "Epoch [43/50], Step [162/735], Loss: 0.0506\n",
      "Epoch [43/50], Step [163/735], Loss: 0.0878\n",
      "Epoch [43/50], Step [164/735], Loss: 0.0655\n",
      "Epoch [43/50], Step [165/735], Loss: 0.0407\n",
      "Epoch [43/50], Step [166/735], Loss: 0.0527\n",
      "Epoch [43/50], Step [167/735], Loss: 0.0933\n",
      "Epoch [43/50], Step [168/735], Loss: 0.0679\n",
      "Epoch [43/50], Step [169/735], Loss: 0.0762\n",
      "Epoch [43/50], Step [170/735], Loss: 0.2232\n",
      "Epoch [43/50], Step [171/735], Loss: 0.1079\n",
      "Epoch [43/50], Step [172/735], Loss: 0.0585\n",
      "Epoch [43/50], Step [173/735], Loss: 0.0836\n",
      "Epoch [43/50], Step [174/735], Loss: 0.0519\n",
      "Epoch [43/50], Step [175/735], Loss: 0.0422\n",
      "Epoch [43/50], Step [176/735], Loss: 0.0436\n",
      "Epoch [43/50], Step [177/735], Loss: 0.0695\n",
      "Epoch [43/50], Step [178/735], Loss: 0.0777\n",
      "Epoch [43/50], Step [179/735], Loss: 0.0386\n",
      "Epoch [43/50], Step [180/735], Loss: 0.0565\n",
      "Epoch [43/50], Step [181/735], Loss: 0.0259\n",
      "Epoch [43/50], Step [182/735], Loss: 0.0340\n",
      "Epoch [43/50], Step [183/735], Loss: 0.0527\n",
      "Epoch [43/50], Step [184/735], Loss: 0.0483\n",
      "Epoch [43/50], Step [185/735], Loss: 0.0543\n",
      "Epoch [43/50], Step [186/735], Loss: 0.0248\n",
      "Epoch [43/50], Step [187/735], Loss: 0.0468\n",
      "Epoch [43/50], Step [188/735], Loss: 0.0669\n",
      "Epoch [43/50], Step [189/735], Loss: 0.0347\n",
      "Epoch [43/50], Step [190/735], Loss: 0.0592\n",
      "Epoch [43/50], Step [191/735], Loss: 0.1671\n",
      "Epoch [43/50], Step [192/735], Loss: 0.0435\n",
      "Epoch [43/50], Step [193/735], Loss: 0.0253\n",
      "Epoch [43/50], Step [194/735], Loss: 0.1166\n",
      "Epoch [43/50], Step [195/735], Loss: 0.0308\n",
      "Epoch [43/50], Step [196/735], Loss: 0.0278\n",
      "Epoch [43/50], Step [197/735], Loss: 0.3107\n",
      "Epoch [43/50], Step [198/735], Loss: 0.1686\n",
      "Epoch [43/50], Step [199/735], Loss: 0.0565\n",
      "Epoch [43/50], Step [200/735], Loss: 0.0234\n",
      "Epoch [43/50], Step [201/735], Loss: 0.0397\n",
      "Epoch [43/50], Step [202/735], Loss: 0.0288\n",
      "Epoch [43/50], Step [203/735], Loss: 0.0368\n",
      "Epoch [43/50], Step [204/735], Loss: 0.0406\n",
      "Epoch [43/50], Step [205/735], Loss: 0.0893\n",
      "Epoch [43/50], Step [206/735], Loss: 0.1954\n",
      "Epoch [43/50], Step [207/735], Loss: 0.0300\n",
      "Epoch [43/50], Step [208/735], Loss: 0.0239\n",
      "Epoch [43/50], Step [209/735], Loss: 0.0712\n",
      "Epoch [43/50], Step [210/735], Loss: 0.1038\n",
      "Epoch [43/50], Step [211/735], Loss: 0.1532\n",
      "Epoch [43/50], Step [212/735], Loss: 0.0439\n",
      "Epoch [43/50], Step [213/735], Loss: 0.0883\n",
      "Epoch [43/50], Step [214/735], Loss: 0.0418\n",
      "Epoch [43/50], Step [215/735], Loss: 0.0340\n",
      "Epoch [43/50], Step [216/735], Loss: 0.0891\n",
      "Epoch [43/50], Step [217/735], Loss: 0.0204\n",
      "Epoch [43/50], Step [218/735], Loss: 0.0207\n",
      "Epoch [43/50], Step [219/735], Loss: 0.1289\n",
      "Epoch [43/50], Step [220/735], Loss: 0.0710\n",
      "Epoch [43/50], Step [221/735], Loss: 0.0524\n",
      "Epoch [43/50], Step [222/735], Loss: 0.0225\n",
      "Epoch [43/50], Step [223/735], Loss: 0.0455\n",
      "Epoch [43/50], Step [224/735], Loss: 0.0629\n",
      "Epoch [43/50], Step [225/735], Loss: 0.1993\n",
      "Epoch [43/50], Step [226/735], Loss: 0.0287\n",
      "Epoch [43/50], Step [227/735], Loss: 0.1961\n",
      "Epoch [43/50], Step [228/735], Loss: 0.0284\n",
      "Epoch [43/50], Step [229/735], Loss: 0.0335\n",
      "Epoch [43/50], Step [230/735], Loss: 0.0820\n",
      "Epoch [43/50], Step [231/735], Loss: 0.0260\n",
      "Epoch [43/50], Step [232/735], Loss: 0.0173\n",
      "Epoch [43/50], Step [233/735], Loss: 0.0313\n",
      "Epoch [43/50], Step [234/735], Loss: 0.0418\n",
      "Epoch [43/50], Step [235/735], Loss: 0.0426\n",
      "Epoch [43/50], Step [236/735], Loss: 0.0356\n",
      "Epoch [43/50], Step [237/735], Loss: 0.0405\n",
      "Epoch [43/50], Step [238/735], Loss: 0.0326\n",
      "Epoch [43/50], Step [239/735], Loss: 0.0710\n",
      "Epoch [43/50], Step [240/735], Loss: 0.0348\n",
      "Epoch [43/50], Step [241/735], Loss: 0.3396\n",
      "Epoch [43/50], Step [242/735], Loss: 0.0800\n",
      "Epoch [43/50], Step [243/735], Loss: 0.0290\n",
      "Epoch [43/50], Step [244/735], Loss: 0.0333\n",
      "Epoch [43/50], Step [245/735], Loss: 0.0300\n",
      "Epoch [43/50], Step [246/735], Loss: 0.1225\n",
      "Epoch [43/50], Step [247/735], Loss: 0.0462\n",
      "Epoch [43/50], Step [248/735], Loss: 0.0660\n",
      "Epoch [43/50], Step [249/735], Loss: 0.1226\n",
      "Epoch [43/50], Step [250/735], Loss: 0.0286\n",
      "Epoch [43/50], Step [251/735], Loss: 0.0207\n",
      "Epoch [43/50], Step [252/735], Loss: 0.0749\n",
      "Epoch [43/50], Step [253/735], Loss: 0.1703\n",
      "Epoch [43/50], Step [254/735], Loss: 0.0195\n",
      "Epoch [43/50], Step [255/735], Loss: 0.0869\n",
      "Epoch [43/50], Step [256/735], Loss: 0.0936\n",
      "Epoch [43/50], Step [257/735], Loss: 0.0252\n",
      "Epoch [43/50], Step [258/735], Loss: 0.0784\n",
      "Epoch [43/50], Step [259/735], Loss: 0.0369\n",
      "Epoch [43/50], Step [260/735], Loss: 0.0262\n",
      "Epoch [43/50], Step [261/735], Loss: 0.0539\n",
      "Epoch [43/50], Step [262/735], Loss: 0.0216\n",
      "Epoch [43/50], Step [263/735], Loss: 0.0510\n",
      "Epoch [43/50], Step [264/735], Loss: 0.0375\n",
      "Epoch [43/50], Step [265/735], Loss: 0.0612\n",
      "Epoch [43/50], Step [266/735], Loss: 0.0521\n",
      "Epoch [43/50], Step [267/735], Loss: 0.0237\n",
      "Epoch [43/50], Step [268/735], Loss: 0.0537\n",
      "Epoch [43/50], Step [269/735], Loss: 0.0812\n",
      "Epoch [43/50], Step [270/735], Loss: 0.0158\n",
      "Epoch [43/50], Step [271/735], Loss: 0.0676\n",
      "Epoch [43/50], Step [272/735], Loss: 0.0783\n",
      "Epoch [43/50], Step [273/735], Loss: 0.0620\n",
      "Epoch [43/50], Step [274/735], Loss: 0.0310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Step [275/735], Loss: 0.0453\n",
      "Epoch [43/50], Step [276/735], Loss: 0.0495\n",
      "Epoch [43/50], Step [277/735], Loss: 0.0816\n",
      "Epoch [43/50], Step [278/735], Loss: 0.0371\n",
      "Epoch [43/50], Step [279/735], Loss: 0.0626\n",
      "Epoch [43/50], Step [280/735], Loss: 0.0306\n",
      "Epoch [43/50], Step [281/735], Loss: 0.0270\n",
      "Epoch [43/50], Step [282/735], Loss: 0.0662\n",
      "Epoch [43/50], Step [283/735], Loss: 0.0642\n",
      "Epoch [43/50], Step [284/735], Loss: 0.1160\n",
      "Epoch [43/50], Step [285/735], Loss: 0.0654\n",
      "Epoch [43/50], Step [286/735], Loss: 0.0432\n",
      "Epoch [43/50], Step [287/735], Loss: 0.1060\n",
      "Epoch [43/50], Step [288/735], Loss: 0.0757\n",
      "Epoch [43/50], Step [289/735], Loss: 0.0584\n",
      "Epoch [43/50], Step [290/735], Loss: 0.1043\n",
      "Epoch [43/50], Step [291/735], Loss: 0.1371\n",
      "Epoch [43/50], Step [292/735], Loss: 0.0819\n",
      "Epoch [43/50], Step [293/735], Loss: 0.0737\n",
      "Epoch [43/50], Step [294/735], Loss: 0.1019\n",
      "Epoch [43/50], Step [295/735], Loss: 0.0318\n",
      "Epoch [43/50], Step [296/735], Loss: 0.1034\n",
      "Epoch [43/50], Step [297/735], Loss: 0.0278\n",
      "Epoch [43/50], Step [298/735], Loss: 0.1006\n",
      "Epoch [43/50], Step [299/735], Loss: 0.0405\n",
      "Epoch [43/50], Step [300/735], Loss: 0.1337\n",
      "Epoch [43/50], Step [301/735], Loss: 0.0203\n",
      "Epoch [43/50], Step [302/735], Loss: 0.0549\n",
      "Epoch [43/50], Step [303/735], Loss: 0.0925\n",
      "Epoch [43/50], Step [304/735], Loss: 0.0647\n",
      "Epoch [43/50], Step [305/735], Loss: 0.3623\n",
      "Epoch [43/50], Step [306/735], Loss: 0.0913\n",
      "Epoch [43/50], Step [307/735], Loss: 0.0230\n",
      "Epoch [43/50], Step [308/735], Loss: 0.0735\n",
      "Epoch [43/50], Step [309/735], Loss: 0.0500\n",
      "Epoch [43/50], Step [310/735], Loss: 0.0408\n",
      "Epoch [43/50], Step [311/735], Loss: 0.0551\n",
      "Epoch [43/50], Step [312/735], Loss: 0.0715\n",
      "Epoch [43/50], Step [313/735], Loss: 0.0489\n",
      "Epoch [43/50], Step [314/735], Loss: 0.1457\n",
      "Epoch [43/50], Step [315/735], Loss: 0.0583\n",
      "Epoch [43/50], Step [316/735], Loss: 0.0946\n",
      "Epoch [43/50], Step [317/735], Loss: 0.0931\n",
      "Epoch [43/50], Step [318/735], Loss: 0.1276\n",
      "Epoch [43/50], Step [319/735], Loss: 0.0324\n",
      "Epoch [43/50], Step [320/735], Loss: 0.1001\n",
      "Epoch [43/50], Step [321/735], Loss: 0.0480\n",
      "Epoch [43/50], Step [322/735], Loss: 0.0379\n",
      "Epoch [43/50], Step [323/735], Loss: 0.0332\n",
      "Epoch [43/50], Step [324/735], Loss: 0.0813\n",
      "Epoch [43/50], Step [325/735], Loss: 0.0331\n",
      "Epoch [43/50], Step [326/735], Loss: 0.0659\n",
      "Epoch [43/50], Step [327/735], Loss: 0.1542\n",
      "Epoch [43/50], Step [328/735], Loss: 0.1246\n",
      "Epoch [43/50], Step [329/735], Loss: 0.0552\n",
      "Epoch [43/50], Step [330/735], Loss: 0.0345\n",
      "Epoch [43/50], Step [331/735], Loss: 0.1227\n",
      "Epoch [43/50], Step [332/735], Loss: 0.0614\n",
      "Epoch [43/50], Step [333/735], Loss: 0.0831\n",
      "Epoch [43/50], Step [334/735], Loss: 0.1267\n",
      "Epoch [43/50], Step [335/735], Loss: 0.0458\n",
      "Epoch [43/50], Step [336/735], Loss: 0.0943\n",
      "Epoch [43/50], Step [337/735], Loss: 0.0311\n",
      "Epoch [43/50], Step [338/735], Loss: 0.0855\n",
      "Epoch [43/50], Step [339/735], Loss: 0.0687\n",
      "Epoch [43/50], Step [340/735], Loss: 0.0431\n",
      "Epoch [43/50], Step [341/735], Loss: 0.0484\n",
      "Epoch [43/50], Step [342/735], Loss: 0.0603\n",
      "Epoch [43/50], Step [343/735], Loss: 0.0511\n",
      "Epoch [43/50], Step [344/735], Loss: 0.0330\n",
      "Epoch [43/50], Step [345/735], Loss: 0.0203\n",
      "Epoch [43/50], Step [346/735], Loss: 0.0410\n",
      "Epoch [43/50], Step [347/735], Loss: 0.0285\n",
      "Epoch [43/50], Step [348/735], Loss: 0.0356\n",
      "Epoch [43/50], Step [349/735], Loss: 0.0493\n",
      "Epoch [43/50], Step [350/735], Loss: 0.0702\n",
      "Epoch [43/50], Step [351/735], Loss: 0.0907\n",
      "Epoch [43/50], Step [352/735], Loss: 0.0219\n",
      "Epoch [43/50], Step [353/735], Loss: 0.0806\n",
      "Epoch [43/50], Step [354/735], Loss: 0.0366\n",
      "Epoch [43/50], Step [355/735], Loss: 0.0988\n",
      "Epoch [43/50], Step [356/735], Loss: 0.0925\n",
      "Epoch [43/50], Step [357/735], Loss: 0.0474\n",
      "Epoch [43/50], Step [358/735], Loss: 0.0752\n",
      "Epoch [43/50], Step [359/735], Loss: 0.0431\n",
      "Epoch [43/50], Step [360/735], Loss: 0.0495\n",
      "Epoch [43/50], Step [361/735], Loss: 0.0326\n",
      "Epoch [43/50], Step [362/735], Loss: 0.0424\n",
      "Epoch [43/50], Step [363/735], Loss: 0.0386\n",
      "Epoch [43/50], Step [364/735], Loss: 0.0593\n",
      "Epoch [43/50], Step [365/735], Loss: 0.0225\n",
      "Epoch [43/50], Step [366/735], Loss: 0.0337\n",
      "Epoch [43/50], Step [367/735], Loss: 0.0513\n",
      "Epoch [43/50], Step [368/735], Loss: 0.0945\n",
      "Epoch [43/50], Step [369/735], Loss: 0.0918\n",
      "Epoch [43/50], Step [370/735], Loss: 0.0870\n",
      "Epoch [43/50], Step [371/735], Loss: 0.0785\n",
      "Epoch [43/50], Step [372/735], Loss: 0.0220\n",
      "Epoch [43/50], Step [373/735], Loss: 0.0680\n",
      "Epoch [43/50], Step [374/735], Loss: 0.0622\n",
      "Epoch [43/50], Step [375/735], Loss: 0.0973\n",
      "Epoch [43/50], Step [376/735], Loss: 0.1174\n",
      "Epoch [43/50], Step [377/735], Loss: 0.0391\n",
      "Epoch [43/50], Step [378/735], Loss: 0.0563\n",
      "Epoch [43/50], Step [379/735], Loss: 0.1208\n",
      "Epoch [43/50], Step [380/735], Loss: 0.0453\n",
      "Epoch [43/50], Step [381/735], Loss: 0.0348\n",
      "Epoch [43/50], Step [382/735], Loss: 0.0693\n",
      "Epoch [43/50], Step [383/735], Loss: 0.0254\n",
      "Epoch [43/50], Step [384/735], Loss: 0.0322\n",
      "Epoch [43/50], Step [385/735], Loss: 0.0351\n",
      "Epoch [43/50], Step [386/735], Loss: 0.0429\n",
      "Epoch [43/50], Step [387/735], Loss: 0.0495\n",
      "Epoch [43/50], Step [388/735], Loss: 0.0363\n",
      "Epoch [43/50], Step [389/735], Loss: 0.1844\n",
      "Epoch [43/50], Step [390/735], Loss: 0.0589\n",
      "Epoch [43/50], Step [391/735], Loss: 0.0404\n",
      "Epoch [43/50], Step [392/735], Loss: 0.0260\n",
      "Epoch [43/50], Step [393/735], Loss: 0.0323\n",
      "Epoch [43/50], Step [394/735], Loss: 0.0222\n",
      "Epoch [43/50], Step [395/735], Loss: 0.0183\n",
      "Epoch [43/50], Step [396/735], Loss: 0.1248\n",
      "Epoch [43/50], Step [397/735], Loss: 0.0892\n",
      "Epoch [43/50], Step [398/735], Loss: 0.0736\n",
      "Epoch [43/50], Step [399/735], Loss: 0.0769\n",
      "Epoch [43/50], Step [400/735], Loss: 0.0436\n",
      "Epoch [43/50], Step [401/735], Loss: 0.0698\n",
      "Epoch [43/50], Step [402/735], Loss: 0.0570\n",
      "Epoch [43/50], Step [403/735], Loss: 0.0606\n",
      "Epoch [43/50], Step [404/735], Loss: 0.0368\n",
      "Epoch [43/50], Step [405/735], Loss: 0.1993\n",
      "Epoch [43/50], Step [406/735], Loss: 0.0792\n",
      "Epoch [43/50], Step [407/735], Loss: 0.0228\n",
      "Epoch [43/50], Step [408/735], Loss: 0.0431\n",
      "Epoch [43/50], Step [409/735], Loss: 0.1242\n",
      "Epoch [43/50], Step [410/735], Loss: 0.0900\n",
      "Epoch [43/50], Step [411/735], Loss: 0.0409\n",
      "Epoch [43/50], Step [412/735], Loss: 0.0412\n",
      "Epoch [43/50], Step [413/735], Loss: 0.0772\n",
      "Epoch [43/50], Step [414/735], Loss: 0.0421\n",
      "Epoch [43/50], Step [415/735], Loss: 0.0117\n",
      "Epoch [43/50], Step [416/735], Loss: 0.0936\n",
      "Epoch [43/50], Step [417/735], Loss: 0.0659\n",
      "Epoch [43/50], Step [418/735], Loss: 0.0910\n",
      "Epoch [43/50], Step [419/735], Loss: 0.0335\n",
      "Epoch [43/50], Step [420/735], Loss: 0.0691\n",
      "Epoch [43/50], Step [421/735], Loss: 0.0791\n",
      "Epoch [43/50], Step [422/735], Loss: 0.1579\n",
      "Epoch [43/50], Step [423/735], Loss: 0.0482\n",
      "Epoch [43/50], Step [424/735], Loss: 0.1461\n",
      "Epoch [43/50], Step [425/735], Loss: 0.0897\n",
      "Epoch [43/50], Step [426/735], Loss: 0.0685\n",
      "Epoch [43/50], Step [427/735], Loss: 0.0247\n",
      "Epoch [43/50], Step [428/735], Loss: 0.0577\n",
      "Epoch [43/50], Step [429/735], Loss: 0.0487\n",
      "Epoch [43/50], Step [430/735], Loss: 0.0956\n",
      "Epoch [43/50], Step [431/735], Loss: 0.0404\n",
      "Epoch [43/50], Step [432/735], Loss: 0.1685\n",
      "Epoch [43/50], Step [433/735], Loss: 0.2083\n",
      "Epoch [43/50], Step [434/735], Loss: 0.0376\n",
      "Epoch [43/50], Step [435/735], Loss: 0.2937\n",
      "Epoch [43/50], Step [436/735], Loss: 0.0542\n",
      "Epoch [43/50], Step [437/735], Loss: 0.0932\n",
      "Epoch [43/50], Step [438/735], Loss: 0.0323\n",
      "Epoch [43/50], Step [439/735], Loss: 0.0825\n",
      "Epoch [43/50], Step [440/735], Loss: 0.0342\n",
      "Epoch [43/50], Step [441/735], Loss: 0.0444\n",
      "Epoch [43/50], Step [442/735], Loss: 0.0266\n",
      "Epoch [43/50], Step [443/735], Loss: 0.0916\n",
      "Epoch [43/50], Step [444/735], Loss: 0.0253\n",
      "Epoch [43/50], Step [445/735], Loss: 0.0484\n",
      "Epoch [43/50], Step [446/735], Loss: 0.0312\n",
      "Epoch [43/50], Step [447/735], Loss: 0.1028\n",
      "Epoch [43/50], Step [448/735], Loss: 0.0769\n",
      "Epoch [43/50], Step [449/735], Loss: 0.0488\n",
      "Epoch [43/50], Step [450/735], Loss: 0.0535\n",
      "Epoch [43/50], Step [451/735], Loss: 0.0531\n",
      "Epoch [43/50], Step [452/735], Loss: 0.0425\n",
      "Epoch [43/50], Step [453/735], Loss: 0.0591\n",
      "Epoch [43/50], Step [454/735], Loss: 0.0503\n",
      "Epoch [43/50], Step [455/735], Loss: 0.1765\n",
      "Epoch [43/50], Step [456/735], Loss: 0.1195\n",
      "Epoch [43/50], Step [457/735], Loss: 0.0711\n",
      "Epoch [43/50], Step [458/735], Loss: 0.0777\n",
      "Epoch [43/50], Step [459/735], Loss: 0.0408\n",
      "Epoch [43/50], Step [460/735], Loss: 0.0358\n",
      "Epoch [43/50], Step [461/735], Loss: 0.0994\n",
      "Epoch [43/50], Step [462/735], Loss: 0.0171\n",
      "Epoch [43/50], Step [463/735], Loss: 0.0359\n",
      "Epoch [43/50], Step [464/735], Loss: 0.1811\n",
      "Epoch [43/50], Step [465/735], Loss: 0.0244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Step [466/735], Loss: 0.0915\n",
      "Epoch [43/50], Step [467/735], Loss: 0.0519\n",
      "Epoch [43/50], Step [468/735], Loss: 0.0899\n",
      "Epoch [43/50], Step [469/735], Loss: 0.0629\n",
      "Epoch [43/50], Step [470/735], Loss: 0.0251\n",
      "Epoch [43/50], Step [471/735], Loss: 0.0427\n",
      "Epoch [43/50], Step [472/735], Loss: 0.0396\n",
      "Epoch [43/50], Step [473/735], Loss: 0.0555\n",
      "Epoch [43/50], Step [474/735], Loss: 0.0464\n",
      "Epoch [43/50], Step [475/735], Loss: 0.0172\n",
      "Epoch [43/50], Step [476/735], Loss: 0.0949\n",
      "Epoch [43/50], Step [477/735], Loss: 0.0363\n",
      "Epoch [43/50], Step [478/735], Loss: 0.0257\n",
      "Epoch [43/50], Step [479/735], Loss: 0.1097\n",
      "Epoch [43/50], Step [480/735], Loss: 0.0661\n",
      "Epoch [43/50], Step [481/735], Loss: 0.1206\n",
      "Epoch [43/50], Step [482/735], Loss: 0.0274\n",
      "Epoch [43/50], Step [483/735], Loss: 0.0819\n",
      "Epoch [43/50], Step [484/735], Loss: 0.0429\n",
      "Epoch [43/50], Step [485/735], Loss: 0.0304\n",
      "Epoch [43/50], Step [486/735], Loss: 0.1577\n",
      "Epoch [43/50], Step [487/735], Loss: 0.0617\n",
      "Epoch [43/50], Step [488/735], Loss: 0.0643\n",
      "Epoch [43/50], Step [489/735], Loss: 0.1039\n",
      "Epoch [43/50], Step [490/735], Loss: 0.0504\n",
      "Epoch [43/50], Step [491/735], Loss: 0.0307\n",
      "Epoch [43/50], Step [492/735], Loss: 0.0427\n",
      "Epoch [43/50], Step [493/735], Loss: 0.1371\n",
      "Epoch [43/50], Step [494/735], Loss: 0.0769\n",
      "Epoch [43/50], Step [495/735], Loss: 0.0653\n",
      "Epoch [43/50], Step [496/735], Loss: 0.1555\n",
      "Epoch [43/50], Step [497/735], Loss: 0.0227\n",
      "Epoch [43/50], Step [498/735], Loss: 0.0658\n",
      "Epoch [43/50], Step [499/735], Loss: 0.0566\n",
      "Epoch [43/50], Step [500/735], Loss: 0.0494\n",
      "Epoch [43/50], Step [501/735], Loss: 0.1977\n",
      "Epoch [43/50], Step [502/735], Loss: 0.0484\n",
      "Epoch [43/50], Step [503/735], Loss: 0.0927\n",
      "Epoch [43/50], Step [504/735], Loss: 0.0787\n",
      "Epoch [43/50], Step [505/735], Loss: 0.0276\n",
      "Epoch [43/50], Step [506/735], Loss: 0.0746\n",
      "Epoch [43/50], Step [507/735], Loss: 0.0394\n",
      "Epoch [43/50], Step [508/735], Loss: 0.0664\n",
      "Epoch [43/50], Step [509/735], Loss: 0.0428\n",
      "Epoch [43/50], Step [510/735], Loss: 0.0343\n",
      "Epoch [43/50], Step [511/735], Loss: 0.0512\n",
      "Epoch [43/50], Step [512/735], Loss: 0.0339\n",
      "Epoch [43/50], Step [513/735], Loss: 0.1112\n",
      "Epoch [43/50], Step [514/735], Loss: 0.0795\n",
      "Epoch [43/50], Step [515/735], Loss: 0.0539\n",
      "Epoch [43/50], Step [516/735], Loss: 0.0408\n",
      "Epoch [43/50], Step [517/735], Loss: 0.0306\n",
      "Epoch [43/50], Step [518/735], Loss: 0.0206\n",
      "Epoch [43/50], Step [519/735], Loss: 0.0424\n",
      "Epoch [43/50], Step [520/735], Loss: 0.0950\n",
      "Epoch [43/50], Step [521/735], Loss: 0.0135\n",
      "Epoch [43/50], Step [522/735], Loss: 0.0644\n",
      "Epoch [43/50], Step [523/735], Loss: 0.0723\n",
      "Epoch [43/50], Step [524/735], Loss: 0.3401\n",
      "Epoch [43/50], Step [525/735], Loss: 0.1402\n",
      "Epoch [43/50], Step [526/735], Loss: 0.1034\n",
      "Epoch [43/50], Step [527/735], Loss: 0.0637\n",
      "Epoch [43/50], Step [528/735], Loss: 0.0161\n",
      "Epoch [43/50], Step [529/735], Loss: 0.0534\n",
      "Epoch [43/50], Step [530/735], Loss: 0.0215\n",
      "Epoch [43/50], Step [531/735], Loss: 0.0361\n",
      "Epoch [43/50], Step [532/735], Loss: 0.0429\n",
      "Epoch [43/50], Step [533/735], Loss: 0.1009\n",
      "Epoch [43/50], Step [534/735], Loss: 0.0347\n",
      "Epoch [43/50], Step [535/735], Loss: 0.0661\n",
      "Epoch [43/50], Step [536/735], Loss: 0.0586\n",
      "Epoch [43/50], Step [537/735], Loss: 0.1499\n",
      "Epoch [43/50], Step [538/735], Loss: 0.0285\n",
      "Epoch [43/50], Step [539/735], Loss: 0.0215\n",
      "Epoch [43/50], Step [540/735], Loss: 0.0316\n",
      "Epoch [43/50], Step [541/735], Loss: 0.0337\n",
      "Epoch [43/50], Step [542/735], Loss: 0.0370\n",
      "Epoch [43/50], Step [543/735], Loss: 0.0447\n",
      "Epoch [43/50], Step [544/735], Loss: 0.0394\n",
      "Epoch [43/50], Step [545/735], Loss: 0.0839\n",
      "Epoch [43/50], Step [546/735], Loss: 0.0604\n",
      "Epoch [43/50], Step [547/735], Loss: 0.0535\n",
      "Epoch [43/50], Step [548/735], Loss: 0.0282\n",
      "Epoch [43/50], Step [549/735], Loss: 0.0611\n",
      "Epoch [43/50], Step [550/735], Loss: 0.0246\n",
      "Epoch [43/50], Step [551/735], Loss: 0.0987\n",
      "Epoch [43/50], Step [552/735], Loss: 0.0626\n",
      "Epoch [43/50], Step [553/735], Loss: 0.0528\n",
      "Epoch [43/50], Step [554/735], Loss: 0.0279\n",
      "Epoch [43/50], Step [555/735], Loss: 0.0494\n",
      "Epoch [43/50], Step [556/735], Loss: 0.0312\n",
      "Epoch [43/50], Step [557/735], Loss: 0.0428\n",
      "Epoch [43/50], Step [558/735], Loss: 0.0424\n",
      "Epoch [43/50], Step [559/735], Loss: 0.0458\n",
      "Epoch [43/50], Step [560/735], Loss: 0.0505\n",
      "Epoch [43/50], Step [561/735], Loss: 0.0279\n",
      "Epoch [43/50], Step [562/735], Loss: 0.0445\n",
      "Epoch [43/50], Step [563/735], Loss: 0.1026\n",
      "Epoch [43/50], Step [564/735], Loss: 0.0398\n",
      "Epoch [43/50], Step [565/735], Loss: 0.0126\n",
      "Epoch [43/50], Step [566/735], Loss: 0.0411\n",
      "Epoch [43/50], Step [567/735], Loss: 0.1406\n",
      "Epoch [43/50], Step [568/735], Loss: 0.2079\n",
      "Epoch [43/50], Step [569/735], Loss: 0.0407\n",
      "Epoch [43/50], Step [570/735], Loss: 0.0275\n",
      "Epoch [43/50], Step [571/735], Loss: 0.0594\n",
      "Epoch [43/50], Step [572/735], Loss: 0.0628\n",
      "Epoch [43/50], Step [573/735], Loss: 0.0768\n",
      "Epoch [43/50], Step [574/735], Loss: 0.1208\n",
      "Epoch [43/50], Step [575/735], Loss: 0.0423\n",
      "Epoch [43/50], Step [576/735], Loss: 0.0524\n",
      "Epoch [43/50], Step [577/735], Loss: 0.0335\n",
      "Epoch [43/50], Step [578/735], Loss: 0.0378\n",
      "Epoch [43/50], Step [579/735], Loss: 0.0425\n",
      "Epoch [43/50], Step [580/735], Loss: 0.0411\n",
      "Epoch [43/50], Step [581/735], Loss: 0.0783\n",
      "Epoch [43/50], Step [582/735], Loss: 0.0316\n",
      "Epoch [43/50], Step [583/735], Loss: 0.0635\n",
      "Epoch [43/50], Step [584/735], Loss: 0.0370\n",
      "Epoch [43/50], Step [585/735], Loss: 0.2195\n",
      "Epoch [43/50], Step [586/735], Loss: 0.0236\n",
      "Epoch [43/50], Step [587/735], Loss: 0.1133\n",
      "Epoch [43/50], Step [588/735], Loss: 0.0479\n",
      "Epoch [43/50], Step [589/735], Loss: 0.0872\n",
      "Epoch [43/50], Step [590/735], Loss: 0.0364\n",
      "Epoch [43/50], Step [591/735], Loss: 0.1323\n",
      "Epoch [43/50], Step [592/735], Loss: 0.0735\n",
      "Epoch [43/50], Step [593/735], Loss: 0.0443\n",
      "Epoch [43/50], Step [594/735], Loss: 0.0118\n",
      "Epoch [43/50], Step [595/735], Loss: 0.0614\n",
      "Epoch [43/50], Step [596/735], Loss: 0.4888\n",
      "Epoch [43/50], Step [597/735], Loss: 0.0433\n",
      "Epoch [43/50], Step [598/735], Loss: 0.0405\n",
      "Epoch [43/50], Step [599/735], Loss: 0.0262\n",
      "Epoch [43/50], Step [600/735], Loss: 0.0275\n",
      "Epoch [43/50], Step [601/735], Loss: 0.0338\n",
      "Epoch [43/50], Step [602/735], Loss: 0.1198\n",
      "Epoch [43/50], Step [603/735], Loss: 0.0414\n",
      "Epoch [43/50], Step [604/735], Loss: 0.0247\n",
      "Epoch [43/50], Step [605/735], Loss: 0.0662\n",
      "Epoch [43/50], Step [606/735], Loss: 0.0982\n",
      "Epoch [43/50], Step [607/735], Loss: 0.1451\n",
      "Epoch [43/50], Step [608/735], Loss: 0.0438\n",
      "Epoch [43/50], Step [609/735], Loss: 0.0254\n",
      "Epoch [43/50], Step [610/735], Loss: 0.2073\n",
      "Epoch [43/50], Step [611/735], Loss: 0.3277\n",
      "Epoch [43/50], Step [612/735], Loss: 0.0422\n",
      "Epoch [43/50], Step [613/735], Loss: 0.0366\n",
      "Epoch [43/50], Step [614/735], Loss: 0.0922\n",
      "Epoch [43/50], Step [615/735], Loss: 0.0417\n",
      "Epoch [43/50], Step [616/735], Loss: 0.1776\n",
      "Epoch [43/50], Step [617/735], Loss: 0.0523\n",
      "Epoch [43/50], Step [618/735], Loss: 0.0363\n",
      "Epoch [43/50], Step [619/735], Loss: 0.0805\n",
      "Epoch [43/50], Step [620/735], Loss: 0.0773\n",
      "Epoch [43/50], Step [621/735], Loss: 0.0586\n",
      "Epoch [43/50], Step [622/735], Loss: 0.0273\n",
      "Epoch [43/50], Step [623/735], Loss: 0.0380\n",
      "Epoch [43/50], Step [624/735], Loss: 0.0453\n",
      "Epoch [43/50], Step [625/735], Loss: 0.0294\n",
      "Epoch [43/50], Step [626/735], Loss: 0.0394\n",
      "Epoch [43/50], Step [627/735], Loss: 0.0350\n",
      "Epoch [43/50], Step [628/735], Loss: 0.1653\n",
      "Epoch [43/50], Step [629/735], Loss: 0.0294\n",
      "Epoch [43/50], Step [630/735], Loss: 0.0866\n",
      "Epoch [43/50], Step [631/735], Loss: 0.0720\n",
      "Epoch [43/50], Step [632/735], Loss: 0.3478\n",
      "Epoch [43/50], Step [633/735], Loss: 0.0777\n",
      "Epoch [43/50], Step [634/735], Loss: 0.0881\n",
      "Epoch [43/50], Step [635/735], Loss: 0.0397\n",
      "Epoch [43/50], Step [636/735], Loss: 0.0268\n",
      "Epoch [43/50], Step [637/735], Loss: 0.0572\n",
      "Epoch [43/50], Step [638/735], Loss: 0.0291\n",
      "Epoch [43/50], Step [639/735], Loss: 0.0717\n",
      "Epoch [43/50], Step [640/735], Loss: 0.1109\n",
      "Epoch [43/50], Step [641/735], Loss: 0.0685\n",
      "Epoch [43/50], Step [642/735], Loss: 0.1489\n",
      "Epoch [43/50], Step [643/735], Loss: 0.0475\n",
      "Epoch [43/50], Step [644/735], Loss: 0.1311\n",
      "Epoch [43/50], Step [645/735], Loss: 0.0264\n",
      "Epoch [43/50], Step [646/735], Loss: 0.0181\n",
      "Epoch [43/50], Step [647/735], Loss: 0.0521\n",
      "Epoch [43/50], Step [648/735], Loss: 0.0680\n",
      "Epoch [43/50], Step [649/735], Loss: 0.0985\n",
      "Epoch [43/50], Step [650/735], Loss: 0.0343\n",
      "Epoch [43/50], Step [651/735], Loss: 0.0188\n",
      "Epoch [43/50], Step [652/735], Loss: 0.0807\n",
      "Epoch [43/50], Step [653/735], Loss: 0.0530\n",
      "Epoch [43/50], Step [654/735], Loss: 0.0547\n",
      "Epoch [43/50], Step [655/735], Loss: 0.0811\n",
      "Epoch [43/50], Step [656/735], Loss: 0.0195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Step [657/735], Loss: 0.0653\n",
      "Epoch [43/50], Step [658/735], Loss: 0.0288\n",
      "Epoch [43/50], Step [659/735], Loss: 0.0422\n",
      "Epoch [43/50], Step [660/735], Loss: 0.0392\n",
      "Epoch [43/50], Step [661/735], Loss: 0.1426\n",
      "Epoch [43/50], Step [662/735], Loss: 0.1497\n",
      "Epoch [43/50], Step [663/735], Loss: 0.1628\n",
      "Epoch [43/50], Step [664/735], Loss: 0.0485\n",
      "Epoch [43/50], Step [665/735], Loss: 0.1122\n",
      "Epoch [43/50], Step [666/735], Loss: 0.0195\n",
      "Epoch [43/50], Step [667/735], Loss: 0.1729\n",
      "Epoch [43/50], Step [668/735], Loss: 0.0265\n",
      "Epoch [43/50], Step [669/735], Loss: 0.0496\n",
      "Epoch [43/50], Step [670/735], Loss: 0.0286\n",
      "Epoch [43/50], Step [671/735], Loss: 0.0753\n",
      "Epoch [43/50], Step [672/735], Loss: 0.0302\n",
      "Epoch [43/50], Step [673/735], Loss: 0.0925\n",
      "Epoch [43/50], Step [674/735], Loss: 0.0845\n",
      "Epoch [43/50], Step [675/735], Loss: 0.0836\n",
      "Epoch [43/50], Step [676/735], Loss: 0.0821\n",
      "Epoch [43/50], Step [677/735], Loss: 0.1005\n",
      "Epoch [43/50], Step [678/735], Loss: 0.0392\n",
      "Epoch [43/50], Step [679/735], Loss: 0.1184\n",
      "Epoch [43/50], Step [680/735], Loss: 0.0443\n",
      "Epoch [43/50], Step [681/735], Loss: 0.0626\n",
      "Epoch [43/50], Step [682/735], Loss: 0.0704\n",
      "Epoch [43/50], Step [683/735], Loss: 0.0431\n",
      "Epoch [43/50], Step [684/735], Loss: 0.0881\n",
      "Epoch [43/50], Step [685/735], Loss: 0.0481\n",
      "Epoch [43/50], Step [686/735], Loss: 0.0307\n",
      "Epoch [43/50], Step [687/735], Loss: 0.0616\n",
      "Epoch [43/50], Step [688/735], Loss: 0.0467\n",
      "Epoch [43/50], Step [689/735], Loss: 0.0458\n",
      "Epoch [43/50], Step [690/735], Loss: 0.0684\n",
      "Epoch [43/50], Step [691/735], Loss: 0.0403\n",
      "Epoch [43/50], Step [692/735], Loss: 0.0401\n",
      "Epoch [43/50], Step [693/735], Loss: 0.0312\n",
      "Epoch [43/50], Step [694/735], Loss: 0.0379\n",
      "Epoch [43/50], Step [695/735], Loss: 0.0421\n",
      "Epoch [43/50], Step [696/735], Loss: 0.0357\n",
      "Epoch [43/50], Step [697/735], Loss: 0.0384\n",
      "Epoch [43/50], Step [698/735], Loss: 0.0252\n",
      "Epoch [43/50], Step [699/735], Loss: 0.0397\n",
      "Epoch [43/50], Step [700/735], Loss: 0.0475\n",
      "Epoch [43/50], Step [701/735], Loss: 0.0392\n",
      "Epoch [43/50], Step [702/735], Loss: 0.0289\n",
      "Epoch [43/50], Step [703/735], Loss: 0.0470\n",
      "Epoch [43/50], Step [704/735], Loss: 0.0603\n",
      "Epoch [43/50], Step [705/735], Loss: 0.0183\n",
      "Epoch [43/50], Step [706/735], Loss: 0.1102\n",
      "Epoch [43/50], Step [707/735], Loss: 0.0851\n",
      "Epoch [43/50], Step [708/735], Loss: 0.0307\n",
      "Epoch [43/50], Step [709/735], Loss: 0.0530\n",
      "Epoch [43/50], Step [710/735], Loss: 0.0582\n",
      "Epoch [43/50], Step [711/735], Loss: 0.0266\n",
      "Epoch [43/50], Step [712/735], Loss: 0.0259\n",
      "Epoch [43/50], Step [713/735], Loss: 0.0749\n",
      "Epoch [43/50], Step [714/735], Loss: 0.0606\n",
      "Epoch [43/50], Step [715/735], Loss: 0.0719\n",
      "Epoch [43/50], Step [716/735], Loss: 0.0105\n",
      "Epoch [43/50], Step [717/735], Loss: 0.0284\n",
      "Epoch [43/50], Step [718/735], Loss: 0.0606\n",
      "Epoch [43/50], Step [719/735], Loss: 0.0427\n",
      "Epoch [43/50], Step [720/735], Loss: 0.1494\n",
      "Epoch [43/50], Step [721/735], Loss: 0.0489\n",
      "Epoch [43/50], Step [722/735], Loss: 0.0472\n",
      "Epoch [43/50], Step [723/735], Loss: 0.1513\n",
      "Epoch [43/50], Step [724/735], Loss: 0.0403\n",
      "Epoch [43/50], Step [725/735], Loss: 0.0503\n",
      "Epoch [43/50], Step [726/735], Loss: 0.0674\n",
      "Epoch [43/50], Step [727/735], Loss: 0.0524\n",
      "Epoch [43/50], Step [728/735], Loss: 0.0438\n",
      "Epoch [43/50], Step [729/735], Loss: 0.0166\n",
      "Epoch [43/50], Step [730/735], Loss: 0.0337\n",
      "Epoch [43/50], Step [731/735], Loss: 0.0661\n",
      "Epoch [43/50], Step [732/735], Loss: 0.0421\n",
      "Epoch [43/50], Step [733/735], Loss: 0.0326\n",
      "Epoch [43/50], Step [734/735], Loss: 0.0223\n",
      "Epoch [43/50], Step [735/735], Loss: 0.0518\n",
      "Epoch [44/50], Step [1/735], Loss: 0.0339\n",
      "Epoch [44/50], Step [2/735], Loss: 0.0201\n",
      "Epoch [44/50], Step [3/735], Loss: 0.0696\n",
      "Epoch [44/50], Step [4/735], Loss: 0.0442\n",
      "Epoch [44/50], Step [5/735], Loss: 0.1705\n",
      "Epoch [44/50], Step [6/735], Loss: 0.1441\n",
      "Epoch [44/50], Step [7/735], Loss: 0.0698\n",
      "Epoch [44/50], Step [8/735], Loss: 0.0741\n",
      "Epoch [44/50], Step [9/735], Loss: 0.0366\n",
      "Epoch [44/50], Step [10/735], Loss: 0.0790\n",
      "Epoch [44/50], Step [11/735], Loss: 0.0364\n",
      "Epoch [44/50], Step [12/735], Loss: 0.0233\n",
      "Epoch [44/50], Step [13/735], Loss: 0.1043\n",
      "Epoch [44/50], Step [14/735], Loss: 0.0288\n",
      "Epoch [44/50], Step [15/735], Loss: 0.0525\n",
      "Epoch [44/50], Step [16/735], Loss: 0.0898\n",
      "Epoch [44/50], Step [17/735], Loss: 0.0390\n",
      "Epoch [44/50], Step [18/735], Loss: 0.0295\n",
      "Epoch [44/50], Step [19/735], Loss: 0.0748\n",
      "Epoch [44/50], Step [20/735], Loss: 0.0355\n",
      "Epoch [44/50], Step [21/735], Loss: 0.1013\n",
      "Epoch [44/50], Step [22/735], Loss: 0.0356\n",
      "Epoch [44/50], Step [23/735], Loss: 0.0291\n",
      "Epoch [44/50], Step [24/735], Loss: 0.0513\n",
      "Epoch [44/50], Step [25/735], Loss: 0.1180\n",
      "Epoch [44/50], Step [26/735], Loss: 0.0606\n",
      "Epoch [44/50], Step [27/735], Loss: 0.0244\n",
      "Epoch [44/50], Step [28/735], Loss: 0.0421\n",
      "Epoch [44/50], Step [29/735], Loss: 0.0351\n",
      "Epoch [44/50], Step [30/735], Loss: 0.0422\n",
      "Epoch [44/50], Step [31/735], Loss: 0.0377\n",
      "Epoch [44/50], Step [32/735], Loss: 0.0208\n",
      "Epoch [44/50], Step [33/735], Loss: 0.0284\n",
      "Epoch [44/50], Step [34/735], Loss: 0.0233\n",
      "Epoch [44/50], Step [35/735], Loss: 0.0299\n",
      "Epoch [44/50], Step [36/735], Loss: 0.1659\n",
      "Epoch [44/50], Step [37/735], Loss: 0.1007\n",
      "Epoch [44/50], Step [38/735], Loss: 0.1272\n",
      "Epoch [44/50], Step [39/735], Loss: 0.0227\n",
      "Epoch [44/50], Step [40/735], Loss: 0.2082\n",
      "Epoch [44/50], Step [41/735], Loss: 0.0545\n",
      "Epoch [44/50], Step [42/735], Loss: 0.0547\n",
      "Epoch [44/50], Step [43/735], Loss: 0.0330\n",
      "Epoch [44/50], Step [44/735], Loss: 0.0313\n",
      "Epoch [44/50], Step [45/735], Loss: 0.0800\n",
      "Epoch [44/50], Step [46/735], Loss: 0.0710\n",
      "Epoch [44/50], Step [47/735], Loss: 0.0329\n",
      "Epoch [44/50], Step [48/735], Loss: 0.0428\n",
      "Epoch [44/50], Step [49/735], Loss: 0.0289\n",
      "Epoch [44/50], Step [50/735], Loss: 0.1693\n",
      "Epoch [44/50], Step [51/735], Loss: 0.0210\n",
      "Epoch [44/50], Step [52/735], Loss: 0.0449\n",
      "Epoch [44/50], Step [53/735], Loss: 0.0576\n",
      "Epoch [44/50], Step [54/735], Loss: 0.0229\n",
      "Epoch [44/50], Step [55/735], Loss: 0.0548\n",
      "Epoch [44/50], Step [56/735], Loss: 0.1403\n",
      "Epoch [44/50], Step [57/735], Loss: 0.0302\n",
      "Epoch [44/50], Step [58/735], Loss: 0.0492\n",
      "Epoch [44/50], Step [59/735], Loss: 0.0129\n",
      "Epoch [44/50], Step [60/735], Loss: 0.0408\n",
      "Epoch [44/50], Step [61/735], Loss: 0.0327\n",
      "Epoch [44/50], Step [62/735], Loss: 0.0756\n",
      "Epoch [44/50], Step [63/735], Loss: 0.0591\n",
      "Epoch [44/50], Step [64/735], Loss: 0.1749\n",
      "Epoch [44/50], Step [65/735], Loss: 0.0539\n",
      "Epoch [44/50], Step [66/735], Loss: 0.0880\n",
      "Epoch [44/50], Step [67/735], Loss: 0.0178\n",
      "Epoch [44/50], Step [68/735], Loss: 0.0536\n",
      "Epoch [44/50], Step [69/735], Loss: 0.0444\n",
      "Epoch [44/50], Step [70/735], Loss: 0.0159\n",
      "Epoch [44/50], Step [71/735], Loss: 0.0828\n",
      "Epoch [44/50], Step [72/735], Loss: 0.0925\n",
      "Epoch [44/50], Step [73/735], Loss: 0.4012\n",
      "Epoch [44/50], Step [74/735], Loss: 0.1438\n",
      "Epoch [44/50], Step [75/735], Loss: 0.1264\n",
      "Epoch [44/50], Step [76/735], Loss: 0.0610\n",
      "Epoch [44/50], Step [77/735], Loss: 0.0977\n",
      "Epoch [44/50], Step [78/735], Loss: 0.1120\n",
      "Epoch [44/50], Step [79/735], Loss: 0.0740\n",
      "Epoch [44/50], Step [80/735], Loss: 0.0341\n",
      "Epoch [44/50], Step [81/735], Loss: 0.0206\n",
      "Epoch [44/50], Step [82/735], Loss: 0.0642\n",
      "Epoch [44/50], Step [83/735], Loss: 0.0152\n",
      "Epoch [44/50], Step [84/735], Loss: 0.0279\n",
      "Epoch [44/50], Step [85/735], Loss: 0.0242\n",
      "Epoch [44/50], Step [86/735], Loss: 0.0639\n",
      "Epoch [44/50], Step [87/735], Loss: 0.0211\n",
      "Epoch [44/50], Step [88/735], Loss: 0.0596\n",
      "Epoch [44/50], Step [89/735], Loss: 0.0306\n",
      "Epoch [44/50], Step [90/735], Loss: 0.0476\n",
      "Epoch [44/50], Step [91/735], Loss: 0.0203\n",
      "Epoch [44/50], Step [92/735], Loss: 0.0170\n",
      "Epoch [44/50], Step [93/735], Loss: 0.0552\n",
      "Epoch [44/50], Step [94/735], Loss: 0.0322\n",
      "Epoch [44/50], Step [95/735], Loss: 0.0212\n",
      "Epoch [44/50], Step [96/735], Loss: 0.0110\n",
      "Epoch [44/50], Step [97/735], Loss: 0.0677\n",
      "Epoch [44/50], Step [98/735], Loss: 0.0141\n",
      "Epoch [44/50], Step [99/735], Loss: 0.0256\n",
      "Epoch [44/50], Step [100/735], Loss: 0.0960\n",
      "Epoch [44/50], Step [101/735], Loss: 0.0763\n",
      "Epoch [44/50], Step [102/735], Loss: 0.0339\n",
      "Epoch [44/50], Step [103/735], Loss: 0.0574\n",
      "Epoch [44/50], Step [104/735], Loss: 0.0537\n",
      "Epoch [44/50], Step [105/735], Loss: 0.0124\n",
      "Epoch [44/50], Step [106/735], Loss: 0.1486\n",
      "Epoch [44/50], Step [107/735], Loss: 0.0362\n",
      "Epoch [44/50], Step [108/735], Loss: 0.0184\n",
      "Epoch [44/50], Step [109/735], Loss: 0.0312\n",
      "Epoch [44/50], Step [110/735], Loss: 0.0587\n",
      "Epoch [44/50], Step [111/735], Loss: 0.0372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Step [112/735], Loss: 0.2213\n",
      "Epoch [44/50], Step [113/735], Loss: 0.0344\n",
      "Epoch [44/50], Step [114/735], Loss: 0.0555\n",
      "Epoch [44/50], Step [115/735], Loss: 0.0317\n",
      "Epoch [44/50], Step [116/735], Loss: 0.1206\n",
      "Epoch [44/50], Step [117/735], Loss: 0.0198\n",
      "Epoch [44/50], Step [118/735], Loss: 0.0618\n",
      "Epoch [44/50], Step [119/735], Loss: 0.0443\n",
      "Epoch [44/50], Step [120/735], Loss: 0.0768\n",
      "Epoch [44/50], Step [121/735], Loss: 0.0600\n",
      "Epoch [44/50], Step [122/735], Loss: 0.0577\n",
      "Epoch [44/50], Step [123/735], Loss: 0.0981\n",
      "Epoch [44/50], Step [124/735], Loss: 0.0247\n",
      "Epoch [44/50], Step [125/735], Loss: 0.0615\n",
      "Epoch [44/50], Step [126/735], Loss: 0.0296\n",
      "Epoch [44/50], Step [127/735], Loss: 0.0278\n",
      "Epoch [44/50], Step [128/735], Loss: 0.1152\n",
      "Epoch [44/50], Step [129/735], Loss: 0.0458\n",
      "Epoch [44/50], Step [130/735], Loss: 0.0174\n",
      "Epoch [44/50], Step [131/735], Loss: 0.0697\n",
      "Epoch [44/50], Step [132/735], Loss: 0.0285\n",
      "Epoch [44/50], Step [133/735], Loss: 0.1023\n",
      "Epoch [44/50], Step [134/735], Loss: 0.0343\n",
      "Epoch [44/50], Step [135/735], Loss: 0.0637\n",
      "Epoch [44/50], Step [136/735], Loss: 0.0819\n",
      "Epoch [44/50], Step [137/735], Loss: 0.0407\n",
      "Epoch [44/50], Step [138/735], Loss: 0.0739\n",
      "Epoch [44/50], Step [139/735], Loss: 0.0231\n",
      "Epoch [44/50], Step [140/735], Loss: 0.0449\n",
      "Epoch [44/50], Step [141/735], Loss: 0.0402\n",
      "Epoch [44/50], Step [142/735], Loss: 0.0184\n",
      "Epoch [44/50], Step [143/735], Loss: 0.0291\n",
      "Epoch [44/50], Step [144/735], Loss: 0.0602\n",
      "Epoch [44/50], Step [145/735], Loss: 0.1400\n",
      "Epoch [44/50], Step [146/735], Loss: 0.0288\n",
      "Epoch [44/50], Step [147/735], Loss: 0.0497\n",
      "Epoch [44/50], Step [148/735], Loss: 0.0180\n",
      "Epoch [44/50], Step [149/735], Loss: 0.0434\n",
      "Epoch [44/50], Step [150/735], Loss: 0.1165\n",
      "Epoch [44/50], Step [151/735], Loss: 0.2390\n",
      "Epoch [44/50], Step [152/735], Loss: 0.0494\n",
      "Epoch [44/50], Step [153/735], Loss: 0.0215\n",
      "Epoch [44/50], Step [154/735], Loss: 0.1192\n",
      "Epoch [44/50], Step [155/735], Loss: 0.0967\n",
      "Epoch [44/50], Step [156/735], Loss: 0.0448\n",
      "Epoch [44/50], Step [157/735], Loss: 0.0511\n",
      "Epoch [44/50], Step [158/735], Loss: 0.0184\n",
      "Epoch [44/50], Step [159/735], Loss: 0.0759\n",
      "Epoch [44/50], Step [160/735], Loss: 0.0155\n",
      "Epoch [44/50], Step [161/735], Loss: 0.0157\n",
      "Epoch [44/50], Step [162/735], Loss: 0.0663\n",
      "Epoch [44/50], Step [163/735], Loss: 0.0232\n",
      "Epoch [44/50], Step [164/735], Loss: 0.0901\n",
      "Epoch [44/50], Step [165/735], Loss: 0.1389\n",
      "Epoch [44/50], Step [166/735], Loss: 0.0624\n",
      "Epoch [44/50], Step [167/735], Loss: 0.0428\n",
      "Epoch [44/50], Step [168/735], Loss: 0.0278\n",
      "Epoch [44/50], Step [169/735], Loss: 0.0246\n",
      "Epoch [44/50], Step [170/735], Loss: 0.0297\n",
      "Epoch [44/50], Step [171/735], Loss: 0.0494\n",
      "Epoch [44/50], Step [172/735], Loss: 0.0639\n",
      "Epoch [44/50], Step [173/735], Loss: 0.0813\n",
      "Epoch [44/50], Step [174/735], Loss: 0.0235\n",
      "Epoch [44/50], Step [175/735], Loss: 0.0208\n",
      "Epoch [44/50], Step [176/735], Loss: 0.0298\n",
      "Epoch [44/50], Step [177/735], Loss: 0.0480\n",
      "Epoch [44/50], Step [178/735], Loss: 0.0579\n",
      "Epoch [44/50], Step [179/735], Loss: 0.0307\n",
      "Epoch [44/50], Step [180/735], Loss: 0.1482\n",
      "Epoch [44/50], Step [181/735], Loss: 0.0258\n",
      "Epoch [44/50], Step [182/735], Loss: 0.0178\n",
      "Epoch [44/50], Step [183/735], Loss: 0.1883\n",
      "Epoch [44/50], Step [184/735], Loss: 0.0899\n",
      "Epoch [44/50], Step [185/735], Loss: 0.0373\n",
      "Epoch [44/50], Step [186/735], Loss: 0.0762\n",
      "Epoch [44/50], Step [187/735], Loss: 0.1141\n",
      "Epoch [44/50], Step [188/735], Loss: 0.0667\n",
      "Epoch [44/50], Step [189/735], Loss: 0.0525\n",
      "Epoch [44/50], Step [190/735], Loss: 0.0262\n",
      "Epoch [44/50], Step [191/735], Loss: 0.0274\n",
      "Epoch [44/50], Step [192/735], Loss: 0.0257\n",
      "Epoch [44/50], Step [193/735], Loss: 0.0409\n",
      "Epoch [44/50], Step [194/735], Loss: 0.0376\n",
      "Epoch [44/50], Step [195/735], Loss: 0.0545\n",
      "Epoch [44/50], Step [196/735], Loss: 0.0334\n",
      "Epoch [44/50], Step [197/735], Loss: 0.0202\n",
      "Epoch [44/50], Step [198/735], Loss: 0.0657\n",
      "Epoch [44/50], Step [199/735], Loss: 0.0392\n",
      "Epoch [44/50], Step [200/735], Loss: 0.0732\n",
      "Epoch [44/50], Step [201/735], Loss: 0.0324\n",
      "Epoch [44/50], Step [202/735], Loss: 0.0398\n",
      "Epoch [44/50], Step [203/735], Loss: 0.0234\n",
      "Epoch [44/50], Step [204/735], Loss: 0.0244\n",
      "Epoch [44/50], Step [205/735], Loss: 0.0772\n",
      "Epoch [44/50], Step [206/735], Loss: 0.0684\n",
      "Epoch [44/50], Step [207/735], Loss: 0.1771\n",
      "Epoch [44/50], Step [208/735], Loss: 0.0284\n",
      "Epoch [44/50], Step [209/735], Loss: 0.0352\n",
      "Epoch [44/50], Step [210/735], Loss: 0.0589\n",
      "Epoch [44/50], Step [211/735], Loss: 0.1044\n",
      "Epoch [44/50], Step [212/735], Loss: 0.1129\n",
      "Epoch [44/50], Step [213/735], Loss: 0.0451\n",
      "Epoch [44/50], Step [214/735], Loss: 0.0804\n",
      "Epoch [44/50], Step [215/735], Loss: 0.1589\n",
      "Epoch [44/50], Step [216/735], Loss: 0.0513\n",
      "Epoch [44/50], Step [217/735], Loss: 0.0350\n",
      "Epoch [44/50], Step [218/735], Loss: 0.0728\n",
      "Epoch [44/50], Step [219/735], Loss: 0.1138\n",
      "Epoch [44/50], Step [220/735], Loss: 0.1051\n",
      "Epoch [44/50], Step [221/735], Loss: 0.2089\n",
      "Epoch [44/50], Step [222/735], Loss: 0.1664\n",
      "Epoch [44/50], Step [223/735], Loss: 0.0504\n",
      "Epoch [44/50], Step [224/735], Loss: 0.3219\n",
      "Epoch [44/50], Step [225/735], Loss: 0.0584\n",
      "Epoch [44/50], Step [226/735], Loss: 0.0182\n",
      "Epoch [44/50], Step [227/735], Loss: 0.0449\n",
      "Epoch [44/50], Step [228/735], Loss: 0.0521\n",
      "Epoch [44/50], Step [229/735], Loss: 0.0531\n",
      "Epoch [44/50], Step [230/735], Loss: 0.0175\n",
      "Epoch [44/50], Step [231/735], Loss: 0.0565\n",
      "Epoch [44/50], Step [232/735], Loss: 0.0295\n",
      "Epoch [44/50], Step [233/735], Loss: 0.0812\n",
      "Epoch [44/50], Step [234/735], Loss: 0.2395\n",
      "Epoch [44/50], Step [235/735], Loss: 0.0339\n",
      "Epoch [44/50], Step [236/735], Loss: 0.0315\n",
      "Epoch [44/50], Step [237/735], Loss: 0.0475\n",
      "Epoch [44/50], Step [238/735], Loss: 0.0573\n",
      "Epoch [44/50], Step [239/735], Loss: 0.0562\n",
      "Epoch [44/50], Step [240/735], Loss: 0.1157\n",
      "Epoch [44/50], Step [241/735], Loss: 0.0837\n",
      "Epoch [44/50], Step [242/735], Loss: 0.0102\n",
      "Epoch [44/50], Step [243/735], Loss: 0.0729\n",
      "Epoch [44/50], Step [244/735], Loss: 0.0853\n",
      "Epoch [44/50], Step [245/735], Loss: 0.0606\n",
      "Epoch [44/50], Step [246/735], Loss: 0.1677\n",
      "Epoch [44/50], Step [247/735], Loss: 0.0598\n",
      "Epoch [44/50], Step [248/735], Loss: 0.0519\n",
      "Epoch [44/50], Step [249/735], Loss: 0.0316\n",
      "Epoch [44/50], Step [250/735], Loss: 0.0150\n",
      "Epoch [44/50], Step [251/735], Loss: 0.0171\n",
      "Epoch [44/50], Step [252/735], Loss: 0.1148\n",
      "Epoch [44/50], Step [253/735], Loss: 0.0404\n",
      "Epoch [44/50], Step [254/735], Loss: 0.0539\n",
      "Epoch [44/50], Step [255/735], Loss: 0.1731\n",
      "Epoch [44/50], Step [256/735], Loss: 0.0386\n",
      "Epoch [44/50], Step [257/735], Loss: 0.0849\n",
      "Epoch [44/50], Step [258/735], Loss: 0.0380\n",
      "Epoch [44/50], Step [259/735], Loss: 0.0276\n",
      "Epoch [44/50], Step [260/735], Loss: 0.0680\n",
      "Epoch [44/50], Step [261/735], Loss: 0.0679\n",
      "Epoch [44/50], Step [262/735], Loss: 0.0822\n",
      "Epoch [44/50], Step [263/735], Loss: 0.0405\n",
      "Epoch [44/50], Step [264/735], Loss: 0.0265\n",
      "Epoch [44/50], Step [265/735], Loss: 0.0333\n",
      "Epoch [44/50], Step [266/735], Loss: 0.0249\n",
      "Epoch [44/50], Step [267/735], Loss: 0.0574\n",
      "Epoch [44/50], Step [268/735], Loss: 0.0272\n",
      "Epoch [44/50], Step [269/735], Loss: 0.0253\n",
      "Epoch [44/50], Step [270/735], Loss: 0.0778\n",
      "Epoch [44/50], Step [271/735], Loss: 0.0392\n",
      "Epoch [44/50], Step [272/735], Loss: 0.0573\n",
      "Epoch [44/50], Step [273/735], Loss: 0.0692\n",
      "Epoch [44/50], Step [274/735], Loss: 0.1220\n",
      "Epoch [44/50], Step [275/735], Loss: 0.0360\n",
      "Epoch [44/50], Step [276/735], Loss: 0.0636\n",
      "Epoch [44/50], Step [277/735], Loss: 0.2599\n",
      "Epoch [44/50], Step [278/735], Loss: 0.0357\n",
      "Epoch [44/50], Step [279/735], Loss: 0.0308\n",
      "Epoch [44/50], Step [280/735], Loss: 0.0327\n",
      "Epoch [44/50], Step [281/735], Loss: 0.0509\n",
      "Epoch [44/50], Step [282/735], Loss: 0.0500\n",
      "Epoch [44/50], Step [283/735], Loss: 0.0528\n",
      "Epoch [44/50], Step [284/735], Loss: 0.0250\n",
      "Epoch [44/50], Step [285/735], Loss: 0.0171\n",
      "Epoch [44/50], Step [286/735], Loss: 0.0388\n",
      "Epoch [44/50], Step [287/735], Loss: 0.0503\n",
      "Epoch [44/50], Step [288/735], Loss: 0.0996\n",
      "Epoch [44/50], Step [289/735], Loss: 0.0718\n",
      "Epoch [44/50], Step [290/735], Loss: 0.0694\n",
      "Epoch [44/50], Step [291/735], Loss: 0.0605\n",
      "Epoch [44/50], Step [292/735], Loss: 0.0817\n",
      "Epoch [44/50], Step [293/735], Loss: 0.3870\n",
      "Epoch [44/50], Step [294/735], Loss: 0.0492\n",
      "Epoch [44/50], Step [295/735], Loss: 0.0643\n",
      "Epoch [44/50], Step [296/735], Loss: 0.0712\n",
      "Epoch [44/50], Step [297/735], Loss: 0.1985\n",
      "Epoch [44/50], Step [298/735], Loss: 0.0636\n",
      "Epoch [44/50], Step [299/735], Loss: 0.1453\n",
      "Epoch [44/50], Step [300/735], Loss: 0.0213\n",
      "Epoch [44/50], Step [301/735], Loss: 0.0567\n",
      "Epoch [44/50], Step [302/735], Loss: 0.0381\n",
      "Epoch [44/50], Step [303/735], Loss: 0.0718\n",
      "Epoch [44/50], Step [304/735], Loss: 0.0928\n",
      "Epoch [44/50], Step [305/735], Loss: 0.1005\n",
      "Epoch [44/50], Step [306/735], Loss: 0.1067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Step [307/735], Loss: 0.1426\n",
      "Epoch [44/50], Step [308/735], Loss: 0.0982\n",
      "Epoch [44/50], Step [309/735], Loss: 0.0345\n",
      "Epoch [44/50], Step [310/735], Loss: 0.0518\n",
      "Epoch [44/50], Step [311/735], Loss: 0.0379\n",
      "Epoch [44/50], Step [312/735], Loss: 0.0732\n",
      "Epoch [44/50], Step [313/735], Loss: 0.3261\n",
      "Epoch [44/50], Step [314/735], Loss: 0.0324\n",
      "Epoch [44/50], Step [315/735], Loss: 0.0723\n",
      "Epoch [44/50], Step [316/735], Loss: 0.0617\n",
      "Epoch [44/50], Step [317/735], Loss: 0.0197\n",
      "Epoch [44/50], Step [318/735], Loss: 0.0432\n",
      "Epoch [44/50], Step [319/735], Loss: 0.0200\n",
      "Epoch [44/50], Step [320/735], Loss: 0.0935\n",
      "Epoch [44/50], Step [321/735], Loss: 0.0814\n",
      "Epoch [44/50], Step [322/735], Loss: 0.0877\n",
      "Epoch [44/50], Step [323/735], Loss: 0.0512\n",
      "Epoch [44/50], Step [324/735], Loss: 0.4722\n",
      "Epoch [44/50], Step [325/735], Loss: 0.0581\n",
      "Epoch [44/50], Step [326/735], Loss: 0.0746\n",
      "Epoch [44/50], Step [327/735], Loss: 0.0788\n",
      "Epoch [44/50], Step [328/735], Loss: 0.0341\n",
      "Epoch [44/50], Step [329/735], Loss: 0.0444\n",
      "Epoch [44/50], Step [330/735], Loss: 0.0398\n",
      "Epoch [44/50], Step [331/735], Loss: 0.0384\n",
      "Epoch [44/50], Step [332/735], Loss: 0.0823\n",
      "Epoch [44/50], Step [333/735], Loss: 0.0442\n",
      "Epoch [44/50], Step [334/735], Loss: 0.1526\n",
      "Epoch [44/50], Step [335/735], Loss: 0.0663\n",
      "Epoch [44/50], Step [336/735], Loss: 0.0576\n",
      "Epoch [44/50], Step [337/735], Loss: 0.0413\n",
      "Epoch [44/50], Step [338/735], Loss: 0.0926\n",
      "Epoch [44/50], Step [339/735], Loss: 0.0320\n",
      "Epoch [44/50], Step [340/735], Loss: 0.0765\n",
      "Epoch [44/50], Step [341/735], Loss: 0.0968\n",
      "Epoch [44/50], Step [342/735], Loss: 0.0515\n",
      "Epoch [44/50], Step [343/735], Loss: 0.0482\n",
      "Epoch [44/50], Step [344/735], Loss: 0.0300\n",
      "Epoch [44/50], Step [345/735], Loss: 0.1024\n",
      "Epoch [44/50], Step [346/735], Loss: 0.0313\n",
      "Epoch [44/50], Step [347/735], Loss: 0.1626\n",
      "Epoch [44/50], Step [348/735], Loss: 0.0459\n",
      "Epoch [44/50], Step [349/735], Loss: 0.0239\n",
      "Epoch [44/50], Step [350/735], Loss: 0.0148\n",
      "Epoch [44/50], Step [351/735], Loss: 0.0182\n",
      "Epoch [44/50], Step [352/735], Loss: 0.0613\n",
      "Epoch [44/50], Step [353/735], Loss: 0.0314\n",
      "Epoch [44/50], Step [354/735], Loss: 0.0340\n",
      "Epoch [44/50], Step [355/735], Loss: 0.0358\n",
      "Epoch [44/50], Step [356/735], Loss: 0.0926\n",
      "Epoch [44/50], Step [357/735], Loss: 0.0185\n",
      "Epoch [44/50], Step [358/735], Loss: 0.0109\n",
      "Epoch [44/50], Step [359/735], Loss: 0.0942\n",
      "Epoch [44/50], Step [360/735], Loss: 0.0598\n",
      "Epoch [44/50], Step [361/735], Loss: 0.0598\n",
      "Epoch [44/50], Step [362/735], Loss: 0.0456\n",
      "Epoch [44/50], Step [363/735], Loss: 0.1781\n",
      "Epoch [44/50], Step [364/735], Loss: 0.0933\n",
      "Epoch [44/50], Step [365/735], Loss: 0.0724\n",
      "Epoch [44/50], Step [366/735], Loss: 0.0790\n",
      "Epoch [44/50], Step [367/735], Loss: 0.0314\n",
      "Epoch [44/50], Step [368/735], Loss: 0.0622\n",
      "Epoch [44/50], Step [369/735], Loss: 0.0672\n",
      "Epoch [44/50], Step [370/735], Loss: 0.0635\n",
      "Epoch [44/50], Step [371/735], Loss: 0.0451\n",
      "Epoch [44/50], Step [372/735], Loss: 0.0441\n",
      "Epoch [44/50], Step [373/735], Loss: 0.1003\n",
      "Epoch [44/50], Step [374/735], Loss: 0.0499\n",
      "Epoch [44/50], Step [375/735], Loss: 0.0270\n",
      "Epoch [44/50], Step [376/735], Loss: 0.1048\n",
      "Epoch [44/50], Step [377/735], Loss: 0.0484\n",
      "Epoch [44/50], Step [378/735], Loss: 0.0314\n",
      "Epoch [44/50], Step [379/735], Loss: 0.0680\n",
      "Epoch [44/50], Step [380/735], Loss: 0.0238\n",
      "Epoch [44/50], Step [381/735], Loss: 0.0312\n",
      "Epoch [44/50], Step [382/735], Loss: 0.0346\n",
      "Epoch [44/50], Step [383/735], Loss: 0.0162\n",
      "Epoch [44/50], Step [384/735], Loss: 0.0955\n",
      "Epoch [44/50], Step [385/735], Loss: 0.0448\n",
      "Epoch [44/50], Step [386/735], Loss: 0.0906\n",
      "Epoch [44/50], Step [387/735], Loss: 0.0553\n",
      "Epoch [44/50], Step [388/735], Loss: 0.0385\n",
      "Epoch [44/50], Step [389/735], Loss: 0.0436\n",
      "Epoch [44/50], Step [390/735], Loss: 0.0756\n",
      "Epoch [44/50], Step [391/735], Loss: 0.0505\n",
      "Epoch [44/50], Step [392/735], Loss: 0.1561\n",
      "Epoch [44/50], Step [393/735], Loss: 0.0891\n",
      "Epoch [44/50], Step [394/735], Loss: 0.0434\n",
      "Epoch [44/50], Step [395/735], Loss: 0.0423\n",
      "Epoch [44/50], Step [396/735], Loss: 0.0340\n",
      "Epoch [44/50], Step [397/735], Loss: 0.0220\n",
      "Epoch [44/50], Step [398/735], Loss: 0.0971\n",
      "Epoch [44/50], Step [399/735], Loss: 0.0219\n",
      "Epoch [44/50], Step [400/735], Loss: 0.1521\n",
      "Epoch [44/50], Step [401/735], Loss: 0.0644\n",
      "Epoch [44/50], Step [402/735], Loss: 0.1078\n",
      "Epoch [44/50], Step [403/735], Loss: 0.0678\n",
      "Epoch [44/50], Step [404/735], Loss: 0.0994\n",
      "Epoch [44/50], Step [405/735], Loss: 0.0887\n",
      "Epoch [44/50], Step [406/735], Loss: 0.1403\n",
      "Epoch [44/50], Step [407/735], Loss: 0.0529\n",
      "Epoch [44/50], Step [408/735], Loss: 0.0629\n",
      "Epoch [44/50], Step [409/735], Loss: 0.0343\n",
      "Epoch [44/50], Step [410/735], Loss: 0.0462\n",
      "Epoch [44/50], Step [411/735], Loss: 0.1488\n",
      "Epoch [44/50], Step [412/735], Loss: 0.0904\n",
      "Epoch [44/50], Step [413/735], Loss: 0.0435\n",
      "Epoch [44/50], Step [414/735], Loss: 0.3159\n",
      "Epoch [44/50], Step [415/735], Loss: 0.1937\n",
      "Epoch [44/50], Step [416/735], Loss: 0.1429\n",
      "Epoch [44/50], Step [417/735], Loss: 0.3202\n",
      "Epoch [44/50], Step [418/735], Loss: 0.0179\n",
      "Epoch [44/50], Step [419/735], Loss: 0.0639\n",
      "Epoch [44/50], Step [420/735], Loss: 0.0289\n",
      "Epoch [44/50], Step [421/735], Loss: 0.0338\n",
      "Epoch [44/50], Step [422/735], Loss: 0.0888\n",
      "Epoch [44/50], Step [423/735], Loss: 0.0658\n",
      "Epoch [44/50], Step [424/735], Loss: 0.0327\n",
      "Epoch [44/50], Step [425/735], Loss: 0.0223\n",
      "Epoch [44/50], Step [426/735], Loss: 0.0766\n",
      "Epoch [44/50], Step [427/735], Loss: 0.0414\n",
      "Epoch [44/50], Step [428/735], Loss: 0.1521\n",
      "Epoch [44/50], Step [429/735], Loss: 0.0334\n",
      "Epoch [44/50], Step [430/735], Loss: 0.0367\n",
      "Epoch [44/50], Step [431/735], Loss: 0.4816\n",
      "Epoch [44/50], Step [432/735], Loss: 0.0935\n",
      "Epoch [44/50], Step [433/735], Loss: 0.1645\n",
      "Epoch [44/50], Step [434/735], Loss: 0.0455\n",
      "Epoch [44/50], Step [435/735], Loss: 0.0571\n",
      "Epoch [44/50], Step [436/735], Loss: 0.0945\n",
      "Epoch [44/50], Step [437/735], Loss: 0.0695\n",
      "Epoch [44/50], Step [438/735], Loss: 0.1095\n",
      "Epoch [44/50], Step [439/735], Loss: 0.0715\n",
      "Epoch [44/50], Step [440/735], Loss: 0.0446\n",
      "Epoch [44/50], Step [441/735], Loss: 0.0601\n",
      "Epoch [44/50], Step [442/735], Loss: 0.0626\n",
      "Epoch [44/50], Step [443/735], Loss: 0.0753\n",
      "Epoch [44/50], Step [444/735], Loss: 0.0456\n",
      "Epoch [44/50], Step [445/735], Loss: 0.0934\n",
      "Epoch [44/50], Step [446/735], Loss: 0.1166\n",
      "Epoch [44/50], Step [447/735], Loss: 0.0440\n",
      "Epoch [44/50], Step [448/735], Loss: 0.0449\n",
      "Epoch [44/50], Step [449/735], Loss: 0.1470\n",
      "Epoch [44/50], Step [450/735], Loss: 0.1461\n",
      "Epoch [44/50], Step [451/735], Loss: 0.0516\n",
      "Epoch [44/50], Step [452/735], Loss: 0.1741\n",
      "Epoch [44/50], Step [453/735], Loss: 0.0419\n",
      "Epoch [44/50], Step [454/735], Loss: 0.0273\n",
      "Epoch [44/50], Step [455/735], Loss: 0.0478\n",
      "Epoch [44/50], Step [456/735], Loss: 0.1101\n",
      "Epoch [44/50], Step [457/735], Loss: 0.0446\n",
      "Epoch [44/50], Step [458/735], Loss: 0.0704\n",
      "Epoch [44/50], Step [459/735], Loss: 0.0523\n",
      "Epoch [44/50], Step [460/735], Loss: 0.0554\n",
      "Epoch [44/50], Step [461/735], Loss: 0.0482\n",
      "Epoch [44/50], Step [462/735], Loss: 0.0624\n",
      "Epoch [44/50], Step [463/735], Loss: 0.0148\n",
      "Epoch [44/50], Step [464/735], Loss: 0.0350\n",
      "Epoch [44/50], Step [465/735], Loss: 0.0193\n",
      "Epoch [44/50], Step [466/735], Loss: 0.0780\n",
      "Epoch [44/50], Step [467/735], Loss: 0.0251\n",
      "Epoch [44/50], Step [468/735], Loss: 0.0484\n",
      "Epoch [44/50], Step [469/735], Loss: 0.0903\n",
      "Epoch [44/50], Step [470/735], Loss: 0.0237\n",
      "Epoch [44/50], Step [471/735], Loss: 0.0395\n",
      "Epoch [44/50], Step [472/735], Loss: 0.0382\n",
      "Epoch [44/50], Step [473/735], Loss: 0.0184\n",
      "Epoch [44/50], Step [474/735], Loss: 0.0391\n",
      "Epoch [44/50], Step [475/735], Loss: 0.0603\n",
      "Epoch [44/50], Step [476/735], Loss: 0.1367\n",
      "Epoch [44/50], Step [477/735], Loss: 0.0248\n",
      "Epoch [44/50], Step [478/735], Loss: 0.0610\n",
      "Epoch [44/50], Step [479/735], Loss: 0.0888\n",
      "Epoch [44/50], Step [480/735], Loss: 0.0522\n",
      "Epoch [44/50], Step [481/735], Loss: 0.2962\n",
      "Epoch [44/50], Step [482/735], Loss: 0.0778\n",
      "Epoch [44/50], Step [483/735], Loss: 0.0480\n",
      "Epoch [44/50], Step [484/735], Loss: 0.0980\n",
      "Epoch [44/50], Step [485/735], Loss: 0.0612\n",
      "Epoch [44/50], Step [486/735], Loss: 0.0305\n",
      "Epoch [44/50], Step [487/735], Loss: 0.0456\n",
      "Epoch [44/50], Step [488/735], Loss: 0.0405\n",
      "Epoch [44/50], Step [489/735], Loss: 0.0656\n",
      "Epoch [44/50], Step [490/735], Loss: 0.0562\n",
      "Epoch [44/50], Step [491/735], Loss: 0.0505\n",
      "Epoch [44/50], Step [492/735], Loss: 0.0326\n",
      "Epoch [44/50], Step [493/735], Loss: 0.0241\n",
      "Epoch [44/50], Step [494/735], Loss: 0.2079\n",
      "Epoch [44/50], Step [495/735], Loss: 0.0434\n",
      "Epoch [44/50], Step [496/735], Loss: 0.0712\n",
      "Epoch [44/50], Step [497/735], Loss: 0.0667\n",
      "Epoch [44/50], Step [498/735], Loss: 0.0355\n",
      "Epoch [44/50], Step [499/735], Loss: 0.0262\n",
      "Epoch [44/50], Step [500/735], Loss: 0.0359\n",
      "Epoch [44/50], Step [501/735], Loss: 0.0380\n",
      "Epoch [44/50], Step [502/735], Loss: 0.0335\n",
      "Epoch [44/50], Step [503/735], Loss: 0.0327\n",
      "Epoch [44/50], Step [504/735], Loss: 0.3592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Step [505/735], Loss: 0.0459\n",
      "Epoch [44/50], Step [506/735], Loss: 0.0310\n",
      "Epoch [44/50], Step [507/735], Loss: 0.0277\n",
      "Epoch [44/50], Step [508/735], Loss: 0.0434\n",
      "Epoch [44/50], Step [509/735], Loss: 0.0161\n",
      "Epoch [44/50], Step [510/735], Loss: 0.1096\n",
      "Epoch [44/50], Step [511/735], Loss: 0.0487\n",
      "Epoch [44/50], Step [512/735], Loss: 0.0667\n",
      "Epoch [44/50], Step [513/735], Loss: 0.0539\n",
      "Epoch [44/50], Step [514/735], Loss: 0.1246\n",
      "Epoch [44/50], Step [515/735], Loss: 0.0547\n",
      "Epoch [44/50], Step [516/735], Loss: 0.0673\n",
      "Epoch [44/50], Step [517/735], Loss: 0.0508\n",
      "Epoch [44/50], Step [518/735], Loss: 0.0377\n",
      "Epoch [44/50], Step [519/735], Loss: 0.3222\n",
      "Epoch [44/50], Step [520/735], Loss: 0.0223\n",
      "Epoch [44/50], Step [521/735], Loss: 0.0249\n",
      "Epoch [44/50], Step [522/735], Loss: 0.0817\n",
      "Epoch [44/50], Step [523/735], Loss: 0.0412\n",
      "Epoch [44/50], Step [524/735], Loss: 0.1014\n",
      "Epoch [44/50], Step [525/735], Loss: 0.0124\n",
      "Epoch [44/50], Step [526/735], Loss: 0.0404\n",
      "Epoch [44/50], Step [527/735], Loss: 0.0865\n",
      "Epoch [44/50], Step [528/735], Loss: 0.0318\n",
      "Epoch [44/50], Step [529/735], Loss: 0.0248\n",
      "Epoch [44/50], Step [530/735], Loss: 0.0221\n",
      "Epoch [44/50], Step [531/735], Loss: 0.0602\n",
      "Epoch [44/50], Step [532/735], Loss: 0.0474\n",
      "Epoch [44/50], Step [533/735], Loss: 0.0261\n",
      "Epoch [44/50], Step [534/735], Loss: 0.0677\n",
      "Epoch [44/50], Step [535/735], Loss: 0.0170\n",
      "Epoch [44/50], Step [536/735], Loss: 0.0401\n",
      "Epoch [44/50], Step [537/735], Loss: 0.0765\n",
      "Epoch [44/50], Step [538/735], Loss: 0.0184\n",
      "Epoch [44/50], Step [539/735], Loss: 0.0605\n",
      "Epoch [44/50], Step [540/735], Loss: 0.2339\n",
      "Epoch [44/50], Step [541/735], Loss: 0.0240\n",
      "Epoch [44/50], Step [542/735], Loss: 0.0368\n",
      "Epoch [44/50], Step [543/735], Loss: 0.0329\n",
      "Epoch [44/50], Step [544/735], Loss: 0.0208\n",
      "Epoch [44/50], Step [545/735], Loss: 0.0290\n",
      "Epoch [44/50], Step [546/735], Loss: 0.0418\n",
      "Epoch [44/50], Step [547/735], Loss: 0.0340\n",
      "Epoch [44/50], Step [548/735], Loss: 0.0549\n",
      "Epoch [44/50], Step [549/735], Loss: 0.0612\n",
      "Epoch [44/50], Step [550/735], Loss: 0.0668\n",
      "Epoch [44/50], Step [551/735], Loss: 0.0464\n",
      "Epoch [44/50], Step [552/735], Loss: 0.0699\n",
      "Epoch [44/50], Step [553/735], Loss: 0.0478\n",
      "Epoch [44/50], Step [554/735], Loss: 0.0611\n",
      "Epoch [44/50], Step [555/735], Loss: 0.0273\n",
      "Epoch [44/50], Step [556/735], Loss: 0.0479\n",
      "Epoch [44/50], Step [557/735], Loss: 0.0819\n",
      "Epoch [44/50], Step [558/735], Loss: 0.0229\n",
      "Epoch [44/50], Step [559/735], Loss: 0.2929\n",
      "Epoch [44/50], Step [560/735], Loss: 0.1088\n",
      "Epoch [44/50], Step [561/735], Loss: 0.1838\n",
      "Epoch [44/50], Step [562/735], Loss: 0.1074\n",
      "Epoch [44/50], Step [563/735], Loss: 0.3033\n",
      "Epoch [44/50], Step [564/735], Loss: 0.0532\n",
      "Epoch [44/50], Step [565/735], Loss: 0.0275\n",
      "Epoch [44/50], Step [566/735], Loss: 0.0409\n",
      "Epoch [44/50], Step [567/735], Loss: 0.0751\n",
      "Epoch [44/50], Step [568/735], Loss: 0.0311\n",
      "Epoch [44/50], Step [569/735], Loss: 0.1171\n",
      "Epoch [44/50], Step [570/735], Loss: 0.1742\n",
      "Epoch [44/50], Step [571/735], Loss: 0.0742\n",
      "Epoch [44/50], Step [572/735], Loss: 0.0165\n",
      "Epoch [44/50], Step [573/735], Loss: 0.0633\n",
      "Epoch [44/50], Step [574/735], Loss: 0.0226\n",
      "Epoch [44/50], Step [575/735], Loss: 0.0493\n",
      "Epoch [44/50], Step [576/735], Loss: 0.0465\n",
      "Epoch [44/50], Step [577/735], Loss: 0.0601\n",
      "Epoch [44/50], Step [578/735], Loss: 0.0370\n",
      "Epoch [44/50], Step [579/735], Loss: 0.0913\n",
      "Epoch [44/50], Step [580/735], Loss: 0.0586\n",
      "Epoch [44/50], Step [581/735], Loss: 0.0515\n",
      "Epoch [44/50], Step [582/735], Loss: 0.0723\n",
      "Epoch [44/50], Step [583/735], Loss: 0.0606\n",
      "Epoch [44/50], Step [584/735], Loss: 0.1312\n",
      "Epoch [44/50], Step [585/735], Loss: 0.0360\n",
      "Epoch [44/50], Step [586/735], Loss: 0.0734\n",
      "Epoch [44/50], Step [587/735], Loss: 0.0359\n",
      "Epoch [44/50], Step [588/735], Loss: 0.0634\n",
      "Epoch [44/50], Step [589/735], Loss: 0.0270\n",
      "Epoch [44/50], Step [590/735], Loss: 0.1102\n",
      "Epoch [44/50], Step [591/735], Loss: 0.0751\n",
      "Epoch [44/50], Step [592/735], Loss: 0.0346\n",
      "Epoch [44/50], Step [593/735], Loss: 0.0479\n",
      "Epoch [44/50], Step [594/735], Loss: 0.0735\n",
      "Epoch [44/50], Step [595/735], Loss: 0.0546\n",
      "Epoch [44/50], Step [596/735], Loss: 0.0541\n",
      "Epoch [44/50], Step [597/735], Loss: 0.0341\n",
      "Epoch [44/50], Step [598/735], Loss: 0.0485\n",
      "Epoch [44/50], Step [599/735], Loss: 0.1020\n",
      "Epoch [44/50], Step [600/735], Loss: 0.0303\n",
      "Epoch [44/50], Step [601/735], Loss: 0.0425\n",
      "Epoch [44/50], Step [602/735], Loss: 0.0937\n",
      "Epoch [44/50], Step [603/735], Loss: 0.0482\n",
      "Epoch [44/50], Step [604/735], Loss: 0.0420\n",
      "Epoch [44/50], Step [605/735], Loss: 0.0509\n",
      "Epoch [44/50], Step [606/735], Loss: 0.1127\n",
      "Epoch [44/50], Step [607/735], Loss: 0.0503\n",
      "Epoch [44/50], Step [608/735], Loss: 0.0495\n",
      "Epoch [44/50], Step [609/735], Loss: 0.1328\n",
      "Epoch [44/50], Step [610/735], Loss: 0.0257\n",
      "Epoch [44/50], Step [611/735], Loss: 0.1558\n",
      "Epoch [44/50], Step [612/735], Loss: 0.0259\n",
      "Epoch [44/50], Step [613/735], Loss: 0.0394\n",
      "Epoch [44/50], Step [614/735], Loss: 0.0359\n",
      "Epoch [44/50], Step [615/735], Loss: 0.1296\n",
      "Epoch [44/50], Step [616/735], Loss: 0.1055\n",
      "Epoch [44/50], Step [617/735], Loss: 0.0687\n",
      "Epoch [44/50], Step [618/735], Loss: 0.0674\n",
      "Epoch [44/50], Step [619/735], Loss: 0.0250\n",
      "Epoch [44/50], Step [620/735], Loss: 0.0986\n",
      "Epoch [44/50], Step [621/735], Loss: 0.0481\n",
      "Epoch [44/50], Step [622/735], Loss: 0.0906\n",
      "Epoch [44/50], Step [623/735], Loss: 0.0348\n",
      "Epoch [44/50], Step [624/735], Loss: 0.0494\n",
      "Epoch [44/50], Step [625/735], Loss: 0.0391\n",
      "Epoch [44/50], Step [626/735], Loss: 0.0463\n",
      "Epoch [44/50], Step [627/735], Loss: 0.0426\n",
      "Epoch [44/50], Step [628/735], Loss: 0.0285\n",
      "Epoch [44/50], Step [629/735], Loss: 0.1178\n",
      "Epoch [44/50], Step [630/735], Loss: 0.0220\n",
      "Epoch [44/50], Step [631/735], Loss: 0.0209\n",
      "Epoch [44/50], Step [632/735], Loss: 0.1690\n",
      "Epoch [44/50], Step [633/735], Loss: 0.1119\n",
      "Epoch [44/50], Step [634/735], Loss: 0.0305\n",
      "Epoch [44/50], Step [635/735], Loss: 0.0826\n",
      "Epoch [44/50], Step [636/735], Loss: 0.1602\n",
      "Epoch [44/50], Step [637/735], Loss: 0.0430\n",
      "Epoch [44/50], Step [638/735], Loss: 0.0768\n",
      "Epoch [44/50], Step [639/735], Loss: 0.0483\n",
      "Epoch [44/50], Step [640/735], Loss: 0.0414\n",
      "Epoch [44/50], Step [641/735], Loss: 0.0186\n",
      "Epoch [44/50], Step [642/735], Loss: 0.0436\n",
      "Epoch [44/50], Step [643/735], Loss: 0.0448\n",
      "Epoch [44/50], Step [644/735], Loss: 0.0224\n",
      "Epoch [44/50], Step [645/735], Loss: 0.0852\n",
      "Epoch [44/50], Step [646/735], Loss: 0.0133\n",
      "Epoch [44/50], Step [647/735], Loss: 0.0733\n",
      "Epoch [44/50], Step [648/735], Loss: 0.1412\n",
      "Epoch [44/50], Step [649/735], Loss: 0.0457\n",
      "Epoch [44/50], Step [650/735], Loss: 0.0375\n",
      "Epoch [44/50], Step [651/735], Loss: 0.0491\n",
      "Epoch [44/50], Step [652/735], Loss: 0.1099\n",
      "Epoch [44/50], Step [653/735], Loss: 0.1039\n",
      "Epoch [44/50], Step [654/735], Loss: 0.0165\n",
      "Epoch [44/50], Step [655/735], Loss: 0.0686\n",
      "Epoch [44/50], Step [656/735], Loss: 0.0280\n",
      "Epoch [44/50], Step [657/735], Loss: 0.0431\n",
      "Epoch [44/50], Step [658/735], Loss: 0.2446\n",
      "Epoch [44/50], Step [659/735], Loss: 0.0773\n",
      "Epoch [44/50], Step [660/735], Loss: 0.0347\n",
      "Epoch [44/50], Step [661/735], Loss: 0.0405\n",
      "Epoch [44/50], Step [662/735], Loss: 0.0539\n",
      "Epoch [44/50], Step [663/735], Loss: 0.0228\n",
      "Epoch [44/50], Step [664/735], Loss: 0.0959\n",
      "Epoch [44/50], Step [665/735], Loss: 0.0428\n",
      "Epoch [44/50], Step [666/735], Loss: 0.0758\n",
      "Epoch [44/50], Step [667/735], Loss: 0.0190\n",
      "Epoch [44/50], Step [668/735], Loss: 0.0417\n",
      "Epoch [44/50], Step [669/735], Loss: 0.0496\n",
      "Epoch [44/50], Step [670/735], Loss: 0.0291\n",
      "Epoch [44/50], Step [671/735], Loss: 0.0522\n",
      "Epoch [44/50], Step [672/735], Loss: 0.0531\n",
      "Epoch [44/50], Step [673/735], Loss: 0.0305\n",
      "Epoch [44/50], Step [674/735], Loss: 0.0638\n",
      "Epoch [44/50], Step [675/735], Loss: 0.0437\n",
      "Epoch [44/50], Step [676/735], Loss: 0.0927\n",
      "Epoch [44/50], Step [677/735], Loss: 0.0363\n",
      "Epoch [44/50], Step [678/735], Loss: 0.0844\n",
      "Epoch [44/50], Step [679/735], Loss: 0.0734\n",
      "Epoch [44/50], Step [680/735], Loss: 0.0387\n",
      "Epoch [44/50], Step [681/735], Loss: 0.1699\n",
      "Epoch [44/50], Step [682/735], Loss: 0.0372\n",
      "Epoch [44/50], Step [683/735], Loss: 0.0675\n",
      "Epoch [44/50], Step [684/735], Loss: 0.0464\n",
      "Epoch [44/50], Step [685/735], Loss: 0.0946\n",
      "Epoch [44/50], Step [686/735], Loss: 0.0773\n",
      "Epoch [44/50], Step [687/735], Loss: 0.0943\n",
      "Epoch [44/50], Step [688/735], Loss: 0.0360\n",
      "Epoch [44/50], Step [689/735], Loss: 0.0505\n",
      "Epoch [44/50], Step [690/735], Loss: 0.0509\n",
      "Epoch [44/50], Step [691/735], Loss: 0.0371\n",
      "Epoch [44/50], Step [692/735], Loss: 0.0967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Step [693/735], Loss: 0.0843\n",
      "Epoch [44/50], Step [694/735], Loss: 0.0392\n",
      "Epoch [44/50], Step [695/735], Loss: 0.0343\n",
      "Epoch [44/50], Step [696/735], Loss: 0.0441\n",
      "Epoch [44/50], Step [697/735], Loss: 0.0482\n",
      "Epoch [44/50], Step [698/735], Loss: 0.0528\n",
      "Epoch [44/50], Step [699/735], Loss: 0.0648\n",
      "Epoch [44/50], Step [700/735], Loss: 0.0470\n",
      "Epoch [44/50], Step [701/735], Loss: 0.1383\n",
      "Epoch [44/50], Step [702/735], Loss: 0.0801\n",
      "Epoch [44/50], Step [703/735], Loss: 0.0373\n",
      "Epoch [44/50], Step [704/735], Loss: 0.0589\n",
      "Epoch [44/50], Step [705/735], Loss: 0.0670\n",
      "Epoch [44/50], Step [706/735], Loss: 0.0386\n",
      "Epoch [44/50], Step [707/735], Loss: 0.0507\n",
      "Epoch [44/50], Step [708/735], Loss: 0.0538\n",
      "Epoch [44/50], Step [709/735], Loss: 0.0364\n",
      "Epoch [44/50], Step [710/735], Loss: 0.0405\n",
      "Epoch [44/50], Step [711/735], Loss: 0.0989\n",
      "Epoch [44/50], Step [712/735], Loss: 0.0365\n",
      "Epoch [44/50], Step [713/735], Loss: 0.0535\n",
      "Epoch [44/50], Step [714/735], Loss: 0.0400\n",
      "Epoch [44/50], Step [715/735], Loss: 0.0800\n",
      "Epoch [44/50], Step [716/735], Loss: 0.0298\n",
      "Epoch [44/50], Step [717/735], Loss: 0.1045\n",
      "Epoch [44/50], Step [718/735], Loss: 0.0626\n",
      "Epoch [44/50], Step [719/735], Loss: 0.0436\n",
      "Epoch [44/50], Step [720/735], Loss: 0.0227\n",
      "Epoch [44/50], Step [721/735], Loss: 0.0791\n",
      "Epoch [44/50], Step [722/735], Loss: 0.0869\n",
      "Epoch [44/50], Step [723/735], Loss: 0.0859\n",
      "Epoch [44/50], Step [724/735], Loss: 0.0479\n",
      "Epoch [44/50], Step [725/735], Loss: 0.0902\n",
      "Epoch [44/50], Step [726/735], Loss: 0.0424\n",
      "Epoch [44/50], Step [727/735], Loss: 0.0690\n",
      "Epoch [44/50], Step [728/735], Loss: 0.0276\n",
      "Epoch [44/50], Step [729/735], Loss: 0.0577\n",
      "Epoch [44/50], Step [730/735], Loss: 0.0387\n",
      "Epoch [44/50], Step [731/735], Loss: 0.0447\n",
      "Epoch [44/50], Step [732/735], Loss: 0.0733\n",
      "Epoch [44/50], Step [733/735], Loss: 0.0254\n",
      "Epoch [44/50], Step [734/735], Loss: 0.0219\n",
      "Epoch [44/50], Step [735/735], Loss: 0.0170\n",
      "Epoch [45/50], Step [1/735], Loss: 0.0393\n",
      "Epoch [45/50], Step [2/735], Loss: 0.0904\n",
      "Epoch [45/50], Step [3/735], Loss: 0.0986\n",
      "Epoch [45/50], Step [4/735], Loss: 0.0191\n",
      "Epoch [45/50], Step [5/735], Loss: 0.0531\n",
      "Epoch [45/50], Step [6/735], Loss: 0.0429\n",
      "Epoch [45/50], Step [7/735], Loss: 0.0421\n",
      "Epoch [45/50], Step [8/735], Loss: 0.0481\n",
      "Epoch [45/50], Step [9/735], Loss: 0.0835\n",
      "Epoch [45/50], Step [10/735], Loss: 0.1025\n",
      "Epoch [45/50], Step [11/735], Loss: 0.0893\n",
      "Epoch [45/50], Step [12/735], Loss: 0.1402\n",
      "Epoch [45/50], Step [13/735], Loss: 0.0239\n",
      "Epoch [45/50], Step [14/735], Loss: 0.0909\n",
      "Epoch [45/50], Step [15/735], Loss: 0.0281\n",
      "Epoch [45/50], Step [16/735], Loss: 0.0689\n",
      "Epoch [45/50], Step [17/735], Loss: 0.0240\n",
      "Epoch [45/50], Step [18/735], Loss: 0.0459\n",
      "Epoch [45/50], Step [19/735], Loss: 0.0396\n",
      "Epoch [45/50], Step [20/735], Loss: 0.0400\n",
      "Epoch [45/50], Step [21/735], Loss: 0.0580\n",
      "Epoch [45/50], Step [22/735], Loss: 0.0849\n",
      "Epoch [45/50], Step [23/735], Loss: 0.0398\n",
      "Epoch [45/50], Step [24/735], Loss: 0.0456\n",
      "Epoch [45/50], Step [25/735], Loss: 0.0653\n",
      "Epoch [45/50], Step [26/735], Loss: 0.1157\n",
      "Epoch [45/50], Step [27/735], Loss: 0.1153\n",
      "Epoch [45/50], Step [28/735], Loss: 0.0520\n",
      "Epoch [45/50], Step [29/735], Loss: 0.0152\n",
      "Epoch [45/50], Step [30/735], Loss: 0.0216\n",
      "Epoch [45/50], Step [31/735], Loss: 0.0295\n",
      "Epoch [45/50], Step [32/735], Loss: 0.1242\n",
      "Epoch [45/50], Step [33/735], Loss: 0.1040\n",
      "Epoch [45/50], Step [34/735], Loss: 0.0877\n",
      "Epoch [45/50], Step [35/735], Loss: 0.0632\n",
      "Epoch [45/50], Step [36/735], Loss: 0.0634\n",
      "Epoch [45/50], Step [37/735], Loss: 0.0298\n",
      "Epoch [45/50], Step [38/735], Loss: 0.0215\n",
      "Epoch [45/50], Step [39/735], Loss: 0.0408\n",
      "Epoch [45/50], Step [40/735], Loss: 0.0991\n",
      "Epoch [45/50], Step [41/735], Loss: 0.0319\n",
      "Epoch [45/50], Step [42/735], Loss: 0.0454\n",
      "Epoch [45/50], Step [43/735], Loss: 0.1337\n",
      "Epoch [45/50], Step [44/735], Loss: 0.0467\n",
      "Epoch [45/50], Step [45/735], Loss: 0.0585\n",
      "Epoch [45/50], Step [46/735], Loss: 0.0320\n",
      "Epoch [45/50], Step [47/735], Loss: 0.0620\n",
      "Epoch [45/50], Step [48/735], Loss: 0.0432\n",
      "Epoch [45/50], Step [49/735], Loss: 0.0486\n",
      "Epoch [45/50], Step [50/735], Loss: 0.0366\n",
      "Epoch [45/50], Step [51/735], Loss: 0.0440\n",
      "Epoch [45/50], Step [52/735], Loss: 0.0556\n",
      "Epoch [45/50], Step [53/735], Loss: 0.0764\n",
      "Epoch [45/50], Step [54/735], Loss: 0.0494\n",
      "Epoch [45/50], Step [55/735], Loss: 0.0485\n",
      "Epoch [45/50], Step [56/735], Loss: 0.3420\n",
      "Epoch [45/50], Step [57/735], Loss: 0.0470\n",
      "Epoch [45/50], Step [58/735], Loss: 0.0647\n",
      "Epoch [45/50], Step [59/735], Loss: 0.0461\n",
      "Epoch [45/50], Step [60/735], Loss: 0.0352\n",
      "Epoch [45/50], Step [61/735], Loss: 0.0494\n",
      "Epoch [45/50], Step [62/735], Loss: 0.0538\n",
      "Epoch [45/50], Step [63/735], Loss: 0.0349\n",
      "Epoch [45/50], Step [64/735], Loss: 0.2668\n",
      "Epoch [45/50], Step [65/735], Loss: 0.0689\n",
      "Epoch [45/50], Step [66/735], Loss: 0.0424\n",
      "Epoch [45/50], Step [67/735], Loss: 0.0954\n",
      "Epoch [45/50], Step [68/735], Loss: 0.0711\n",
      "Epoch [45/50], Step [69/735], Loss: 0.1023\n",
      "Epoch [45/50], Step [70/735], Loss: 0.0535\n",
      "Epoch [45/50], Step [71/735], Loss: 0.0506\n",
      "Epoch [45/50], Step [72/735], Loss: 0.0579\n",
      "Epoch [45/50], Step [73/735], Loss: 0.1812\n",
      "Epoch [45/50], Step [74/735], Loss: 0.0998\n",
      "Epoch [45/50], Step [75/735], Loss: 0.0326\n",
      "Epoch [45/50], Step [76/735], Loss: 0.1112\n",
      "Epoch [45/50], Step [77/735], Loss: 0.0575\n",
      "Epoch [45/50], Step [78/735], Loss: 0.0332\n",
      "Epoch [45/50], Step [79/735], Loss: 0.0298\n",
      "Epoch [45/50], Step [80/735], Loss: 0.0683\n",
      "Epoch [45/50], Step [81/735], Loss: 0.0297\n",
      "Epoch [45/50], Step [82/735], Loss: 0.0527\n",
      "Epoch [45/50], Step [83/735], Loss: 0.0827\n",
      "Epoch [45/50], Step [84/735], Loss: 0.0162\n",
      "Epoch [45/50], Step [85/735], Loss: 0.0436\n",
      "Epoch [45/50], Step [86/735], Loss: 0.0241\n",
      "Epoch [45/50], Step [87/735], Loss: 0.0359\n",
      "Epoch [45/50], Step [88/735], Loss: 0.1189\n",
      "Epoch [45/50], Step [89/735], Loss: 0.0616\n",
      "Epoch [45/50], Step [90/735], Loss: 0.0607\n",
      "Epoch [45/50], Step [91/735], Loss: 0.1203\n",
      "Epoch [45/50], Step [92/735], Loss: 0.0927\n",
      "Epoch [45/50], Step [93/735], Loss: 0.0315\n",
      "Epoch [45/50], Step [94/735], Loss: 0.0424\n",
      "Epoch [45/50], Step [95/735], Loss: 0.0530\n",
      "Epoch [45/50], Step [96/735], Loss: 0.0709\n",
      "Epoch [45/50], Step [97/735], Loss: 0.0472\n",
      "Epoch [45/50], Step [98/735], Loss: 0.4030\n",
      "Epoch [45/50], Step [99/735], Loss: 0.0825\n",
      "Epoch [45/50], Step [100/735], Loss: 0.0361\n",
      "Epoch [45/50], Step [101/735], Loss: 0.0394\n",
      "Epoch [45/50], Step [102/735], Loss: 0.0359\n",
      "Epoch [45/50], Step [103/735], Loss: 0.0449\n",
      "Epoch [45/50], Step [104/735], Loss: 0.2638\n",
      "Epoch [45/50], Step [105/735], Loss: 0.0252\n",
      "Epoch [45/50], Step [106/735], Loss: 0.0640\n",
      "Epoch [45/50], Step [107/735], Loss: 0.1688\n",
      "Epoch [45/50], Step [108/735], Loss: 0.1321\n",
      "Epoch [45/50], Step [109/735], Loss: 0.0500\n",
      "Epoch [45/50], Step [110/735], Loss: 0.0538\n",
      "Epoch [45/50], Step [111/735], Loss: 0.0414\n",
      "Epoch [45/50], Step [112/735], Loss: 0.0286\n",
      "Epoch [45/50], Step [113/735], Loss: 0.0405\n",
      "Epoch [45/50], Step [114/735], Loss: 0.0537\n",
      "Epoch [45/50], Step [115/735], Loss: 0.0788\n",
      "Epoch [45/50], Step [116/735], Loss: 0.0549\n",
      "Epoch [45/50], Step [117/735], Loss: 0.0360\n",
      "Epoch [45/50], Step [118/735], Loss: 0.0675\n",
      "Epoch [45/50], Step [119/735], Loss: 0.0527\n",
      "Epoch [45/50], Step [120/735], Loss: 0.0671\n",
      "Epoch [45/50], Step [121/735], Loss: 0.0282\n",
      "Epoch [45/50], Step [122/735], Loss: 0.0376\n",
      "Epoch [45/50], Step [123/735], Loss: 0.2177\n",
      "Epoch [45/50], Step [124/735], Loss: 0.0424\n",
      "Epoch [45/50], Step [125/735], Loss: 0.0796\n",
      "Epoch [45/50], Step [126/735], Loss: 0.0430\n",
      "Epoch [45/50], Step [127/735], Loss: 0.0295\n",
      "Epoch [45/50], Step [128/735], Loss: 0.0534\n",
      "Epoch [45/50], Step [129/735], Loss: 0.0404\n",
      "Epoch [45/50], Step [130/735], Loss: 0.2337\n",
      "Epoch [45/50], Step [131/735], Loss: 0.0426\n",
      "Epoch [45/50], Step [132/735], Loss: 0.0495\n",
      "Epoch [45/50], Step [133/735], Loss: 0.0502\n",
      "Epoch [45/50], Step [134/735], Loss: 0.0188\n",
      "Epoch [45/50], Step [135/735], Loss: 0.0509\n",
      "Epoch [45/50], Step [136/735], Loss: 0.0236\n",
      "Epoch [45/50], Step [137/735], Loss: 0.0568\n",
      "Epoch [45/50], Step [138/735], Loss: 0.0892\n",
      "Epoch [45/50], Step [139/735], Loss: 0.1861\n",
      "Epoch [45/50], Step [140/735], Loss: 0.0673\n",
      "Epoch [45/50], Step [141/735], Loss: 0.0477\n",
      "Epoch [45/50], Step [142/735], Loss: 0.0517\n",
      "Epoch [45/50], Step [143/735], Loss: 0.0888\n",
      "Epoch [45/50], Step [144/735], Loss: 0.1174\n",
      "Epoch [45/50], Step [145/735], Loss: 0.0661\n",
      "Epoch [45/50], Step [146/735], Loss: 0.0696\n",
      "Epoch [45/50], Step [147/735], Loss: 0.0575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Step [148/735], Loss: 0.1048\n",
      "Epoch [45/50], Step [149/735], Loss: 0.0408\n",
      "Epoch [45/50], Step [150/735], Loss: 0.0738\n",
      "Epoch [45/50], Step [151/735], Loss: 0.0465\n",
      "Epoch [45/50], Step [152/735], Loss: 0.0965\n",
      "Epoch [45/50], Step [153/735], Loss: 0.0219\n",
      "Epoch [45/50], Step [154/735], Loss: 0.0524\n",
      "Epoch [45/50], Step [155/735], Loss: 0.0619\n",
      "Epoch [45/50], Step [156/735], Loss: 0.0904\n",
      "Epoch [45/50], Step [157/735], Loss: 0.0496\n",
      "Epoch [45/50], Step [158/735], Loss: 0.1050\n",
      "Epoch [45/50], Step [159/735], Loss: 0.0292\n",
      "Epoch [45/50], Step [160/735], Loss: 0.0177\n",
      "Epoch [45/50], Step [161/735], Loss: 0.0700\n",
      "Epoch [45/50], Step [162/735], Loss: 0.0441\n",
      "Epoch [45/50], Step [163/735], Loss: 0.0436\n",
      "Epoch [45/50], Step [164/735], Loss: 0.0595\n",
      "Epoch [45/50], Step [165/735], Loss: 0.1380\n",
      "Epoch [45/50], Step [166/735], Loss: 0.0290\n",
      "Epoch [45/50], Step [167/735], Loss: 0.0420\n",
      "Epoch [45/50], Step [168/735], Loss: 0.0339\n",
      "Epoch [45/50], Step [169/735], Loss: 0.0225\n",
      "Epoch [45/50], Step [170/735], Loss: 0.0143\n",
      "Epoch [45/50], Step [171/735], Loss: 0.3003\n",
      "Epoch [45/50], Step [172/735], Loss: 0.0709\n",
      "Epoch [45/50], Step [173/735], Loss: 0.0287\n",
      "Epoch [45/50], Step [174/735], Loss: 0.0366\n",
      "Epoch [45/50], Step [175/735], Loss: 0.0244\n",
      "Epoch [45/50], Step [176/735], Loss: 0.0302\n",
      "Epoch [45/50], Step [177/735], Loss: 0.1610\n",
      "Epoch [45/50], Step [178/735], Loss: 0.0336\n",
      "Epoch [45/50], Step [179/735], Loss: 0.1387\n",
      "Epoch [45/50], Step [180/735], Loss: 0.0420\n",
      "Epoch [45/50], Step [181/735], Loss: 0.0587\n",
      "Epoch [45/50], Step [182/735], Loss: 0.0429\n",
      "Epoch [45/50], Step [183/735], Loss: 0.0412\n",
      "Epoch [45/50], Step [184/735], Loss: 0.0305\n",
      "Epoch [45/50], Step [185/735], Loss: 0.0832\n",
      "Epoch [45/50], Step [186/735], Loss: 0.0390\n",
      "Epoch [45/50], Step [187/735], Loss: 0.0735\n",
      "Epoch [45/50], Step [188/735], Loss: 0.1101\n",
      "Epoch [45/50], Step [189/735], Loss: 0.1046\n",
      "Epoch [45/50], Step [190/735], Loss: 0.0514\n",
      "Epoch [45/50], Step [191/735], Loss: 0.1184\n",
      "Epoch [45/50], Step [192/735], Loss: 0.0356\n",
      "Epoch [45/50], Step [193/735], Loss: 0.0834\n",
      "Epoch [45/50], Step [194/735], Loss: 0.0432\n",
      "Epoch [45/50], Step [195/735], Loss: 0.0846\n",
      "Epoch [45/50], Step [196/735], Loss: 0.0396\n",
      "Epoch [45/50], Step [197/735], Loss: 0.0853\n",
      "Epoch [45/50], Step [198/735], Loss: 0.0187\n",
      "Epoch [45/50], Step [199/735], Loss: 0.0543\n",
      "Epoch [45/50], Step [200/735], Loss: 0.0363\n",
      "Epoch [45/50], Step [201/735], Loss: 0.0578\n",
      "Epoch [45/50], Step [202/735], Loss: 0.0325\n",
      "Epoch [45/50], Step [203/735], Loss: 0.0387\n",
      "Epoch [45/50], Step [204/735], Loss: 0.0266\n",
      "Epoch [45/50], Step [205/735], Loss: 0.0386\n",
      "Epoch [45/50], Step [206/735], Loss: 0.0571\n",
      "Epoch [45/50], Step [207/735], Loss: 0.0485\n",
      "Epoch [45/50], Step [208/735], Loss: 0.0625\n",
      "Epoch [45/50], Step [209/735], Loss: 0.0603\n",
      "Epoch [45/50], Step [210/735], Loss: 0.0710\n",
      "Epoch [45/50], Step [211/735], Loss: 0.0958\n",
      "Epoch [45/50], Step [212/735], Loss: 0.0615\n",
      "Epoch [45/50], Step [213/735], Loss: 0.0452\n",
      "Epoch [45/50], Step [214/735], Loss: 0.0252\n",
      "Epoch [45/50], Step [215/735], Loss: 0.0242\n",
      "Epoch [45/50], Step [216/735], Loss: 0.1472\n",
      "Epoch [45/50], Step [217/735], Loss: 0.3165\n",
      "Epoch [45/50], Step [218/735], Loss: 0.0246\n",
      "Epoch [45/50], Step [219/735], Loss: 0.0156\n",
      "Epoch [45/50], Step [220/735], Loss: 0.0720\n",
      "Epoch [45/50], Step [221/735], Loss: 0.0250\n",
      "Epoch [45/50], Step [222/735], Loss: 0.0250\n",
      "Epoch [45/50], Step [223/735], Loss: 0.0448\n",
      "Epoch [45/50], Step [224/735], Loss: 0.0585\n",
      "Epoch [45/50], Step [225/735], Loss: 0.0244\n",
      "Epoch [45/50], Step [226/735], Loss: 0.0174\n",
      "Epoch [45/50], Step [227/735], Loss: 0.0897\n",
      "Epoch [45/50], Step [228/735], Loss: 0.0393\n",
      "Epoch [45/50], Step [229/735], Loss: 0.0971\n",
      "Epoch [45/50], Step [230/735], Loss: 0.1162\n",
      "Epoch [45/50], Step [231/735], Loss: 0.0547\n",
      "Epoch [45/50], Step [232/735], Loss: 0.0585\n",
      "Epoch [45/50], Step [233/735], Loss: 0.0388\n",
      "Epoch [45/50], Step [234/735], Loss: 0.0547\n",
      "Epoch [45/50], Step [235/735], Loss: 0.0312\n",
      "Epoch [45/50], Step [236/735], Loss: 0.2145\n",
      "Epoch [45/50], Step [237/735], Loss: 0.1790\n",
      "Epoch [45/50], Step [238/735], Loss: 0.0554\n",
      "Epoch [45/50], Step [239/735], Loss: 0.0236\n",
      "Epoch [45/50], Step [240/735], Loss: 0.0448\n",
      "Epoch [45/50], Step [241/735], Loss: 0.0322\n",
      "Epoch [45/50], Step [242/735], Loss: 0.0628\n",
      "Epoch [45/50], Step [243/735], Loss: 0.1475\n",
      "Epoch [45/50], Step [244/735], Loss: 0.0246\n",
      "Epoch [45/50], Step [245/735], Loss: 0.0534\n",
      "Epoch [45/50], Step [246/735], Loss: 0.0283\n",
      "Epoch [45/50], Step [247/735], Loss: 0.0429\n",
      "Epoch [45/50], Step [248/735], Loss: 0.0275\n",
      "Epoch [45/50], Step [249/735], Loss: 0.0654\n",
      "Epoch [45/50], Step [250/735], Loss: 0.0424\n",
      "Epoch [45/50], Step [251/735], Loss: 0.0845\n",
      "Epoch [45/50], Step [252/735], Loss: 0.0409\n",
      "Epoch [45/50], Step [253/735], Loss: 0.0324\n",
      "Epoch [45/50], Step [254/735], Loss: 0.0283\n",
      "Epoch [45/50], Step [255/735], Loss: 0.1966\n",
      "Epoch [45/50], Step [256/735], Loss: 0.0296\n",
      "Epoch [45/50], Step [257/735], Loss: 0.0461\n",
      "Epoch [45/50], Step [258/735], Loss: 0.0610\n",
      "Epoch [45/50], Step [259/735], Loss: 0.0380\n",
      "Epoch [45/50], Step [260/735], Loss: 0.0713\n",
      "Epoch [45/50], Step [261/735], Loss: 0.3630\n",
      "Epoch [45/50], Step [262/735], Loss: 0.0998\n",
      "Epoch [45/50], Step [263/735], Loss: 0.0335\n",
      "Epoch [45/50], Step [264/735], Loss: 0.0388\n",
      "Epoch [45/50], Step [265/735], Loss: 0.0299\n",
      "Epoch [45/50], Step [266/735], Loss: 0.1165\n",
      "Epoch [45/50], Step [267/735], Loss: 0.0788\n",
      "Epoch [45/50], Step [268/735], Loss: 0.1091\n",
      "Epoch [45/50], Step [269/735], Loss: 0.0459\n",
      "Epoch [45/50], Step [270/735], Loss: 0.0829\n",
      "Epoch [45/50], Step [271/735], Loss: 0.0403\n",
      "Epoch [45/50], Step [272/735], Loss: 0.0263\n",
      "Epoch [45/50], Step [273/735], Loss: 0.0416\n",
      "Epoch [45/50], Step [274/735], Loss: 0.0676\n",
      "Epoch [45/50], Step [275/735], Loss: 0.0516\n",
      "Epoch [45/50], Step [276/735], Loss: 0.0191\n",
      "Epoch [45/50], Step [277/735], Loss: 0.0878\n",
      "Epoch [45/50], Step [278/735], Loss: 0.0357\n",
      "Epoch [45/50], Step [279/735], Loss: 0.0241\n",
      "Epoch [45/50], Step [280/735], Loss: 0.0920\n",
      "Epoch [45/50], Step [281/735], Loss: 0.0414\n",
      "Epoch [45/50], Step [282/735], Loss: 0.0294\n",
      "Epoch [45/50], Step [283/735], Loss: 0.0495\n",
      "Epoch [45/50], Step [284/735], Loss: 0.0331\n",
      "Epoch [45/50], Step [285/735], Loss: 0.0262\n",
      "Epoch [45/50], Step [286/735], Loss: 0.0369\n",
      "Epoch [45/50], Step [287/735], Loss: 0.0186\n",
      "Epoch [45/50], Step [288/735], Loss: 0.0708\n",
      "Epoch [45/50], Step [289/735], Loss: 0.1365\n",
      "Epoch [45/50], Step [290/735], Loss: 0.0236\n",
      "Epoch [45/50], Step [291/735], Loss: 0.1236\n",
      "Epoch [45/50], Step [292/735], Loss: 0.3590\n",
      "Epoch [45/50], Step [293/735], Loss: 0.0776\n",
      "Epoch [45/50], Step [294/735], Loss: 0.0632\n",
      "Epoch [45/50], Step [295/735], Loss: 0.0399\n",
      "Epoch [45/50], Step [296/735], Loss: 0.0544\n",
      "Epoch [45/50], Step [297/735], Loss: 0.1021\n",
      "Epoch [45/50], Step [298/735], Loss: 0.0377\n",
      "Epoch [45/50], Step [299/735], Loss: 0.0581\n",
      "Epoch [45/50], Step [300/735], Loss: 0.0315\n",
      "Epoch [45/50], Step [301/735], Loss: 0.0534\n",
      "Epoch [45/50], Step [302/735], Loss: 0.0689\n",
      "Epoch [45/50], Step [303/735], Loss: 0.0911\n",
      "Epoch [45/50], Step [304/735], Loss: 0.3796\n",
      "Epoch [45/50], Step [305/735], Loss: 0.0901\n",
      "Epoch [45/50], Step [306/735], Loss: 0.0590\n",
      "Epoch [45/50], Step [307/735], Loss: 0.0401\n",
      "Epoch [45/50], Step [308/735], Loss: 0.0526\n",
      "Epoch [45/50], Step [309/735], Loss: 0.0766\n",
      "Epoch [45/50], Step [310/735], Loss: 0.0919\n",
      "Epoch [45/50], Step [311/735], Loss: 0.0561\n",
      "Epoch [45/50], Step [312/735], Loss: 0.1263\n",
      "Epoch [45/50], Step [313/735], Loss: 0.0409\n",
      "Epoch [45/50], Step [314/735], Loss: 0.0431\n",
      "Epoch [45/50], Step [315/735], Loss: 0.2316\n",
      "Epoch [45/50], Step [316/735], Loss: 0.0579\n",
      "Epoch [45/50], Step [317/735], Loss: 0.0227\n",
      "Epoch [45/50], Step [318/735], Loss: 0.0353\n",
      "Epoch [45/50], Step [319/735], Loss: 0.0208\n",
      "Epoch [45/50], Step [320/735], Loss: 0.0292\n",
      "Epoch [45/50], Step [321/735], Loss: 0.0694\n",
      "Epoch [45/50], Step [322/735], Loss: 0.0576\n",
      "Epoch [45/50], Step [323/735], Loss: 0.0422\n",
      "Epoch [45/50], Step [324/735], Loss: 0.0696\n",
      "Epoch [45/50], Step [325/735], Loss: 0.1236\n",
      "Epoch [45/50], Step [326/735], Loss: 0.0163\n",
      "Epoch [45/50], Step [327/735], Loss: 0.0413\n",
      "Epoch [45/50], Step [328/735], Loss: 0.0656\n",
      "Epoch [45/50], Step [329/735], Loss: 0.1121\n",
      "Epoch [45/50], Step [330/735], Loss: 0.0450\n",
      "Epoch [45/50], Step [331/735], Loss: 0.1237\n",
      "Epoch [45/50], Step [332/735], Loss: 0.0505\n",
      "Epoch [45/50], Step [333/735], Loss: 0.1456\n",
      "Epoch [45/50], Step [334/735], Loss: 0.0231\n",
      "Epoch [45/50], Step [335/735], Loss: 0.0316\n",
      "Epoch [45/50], Step [336/735], Loss: 0.0987\n",
      "Epoch [45/50], Step [337/735], Loss: 0.0928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Step [338/735], Loss: 0.0685\n",
      "Epoch [45/50], Step [339/735], Loss: 0.0593\n",
      "Epoch [45/50], Step [340/735], Loss: 0.0274\n",
      "Epoch [45/50], Step [341/735], Loss: 0.0588\n",
      "Epoch [45/50], Step [342/735], Loss: 0.0334\n",
      "Epoch [45/50], Step [343/735], Loss: 0.0848\n",
      "Epoch [45/50], Step [344/735], Loss: 0.0214\n",
      "Epoch [45/50], Step [345/735], Loss: 0.0417\n",
      "Epoch [45/50], Step [346/735], Loss: 0.0595\n",
      "Epoch [45/50], Step [347/735], Loss: 0.2106\n",
      "Epoch [45/50], Step [348/735], Loss: 0.0739\n",
      "Epoch [45/50], Step [349/735], Loss: 0.0305\n",
      "Epoch [45/50], Step [350/735], Loss: 0.0350\n",
      "Epoch [45/50], Step [351/735], Loss: 0.0391\n",
      "Epoch [45/50], Step [352/735], Loss: 0.0637\n",
      "Epoch [45/50], Step [353/735], Loss: 0.0278\n",
      "Epoch [45/50], Step [354/735], Loss: 0.0766\n",
      "Epoch [45/50], Step [355/735], Loss: 0.0642\n",
      "Epoch [45/50], Step [356/735], Loss: 0.0549\n",
      "Epoch [45/50], Step [357/735], Loss: 0.0565\n",
      "Epoch [45/50], Step [358/735], Loss: 0.0349\n",
      "Epoch [45/50], Step [359/735], Loss: 0.0751\n",
      "Epoch [45/50], Step [360/735], Loss: 0.0579\n",
      "Epoch [45/50], Step [361/735], Loss: 0.0333\n",
      "Epoch [45/50], Step [362/735], Loss: 0.0403\n",
      "Epoch [45/50], Step [363/735], Loss: 0.0392\n",
      "Epoch [45/50], Step [364/735], Loss: 0.0517\n",
      "Epoch [45/50], Step [365/735], Loss: 0.0595\n",
      "Epoch [45/50], Step [366/735], Loss: 0.3793\n",
      "Epoch [45/50], Step [367/735], Loss: 0.0750\n",
      "Epoch [45/50], Step [368/735], Loss: 0.0610\n",
      "Epoch [45/50], Step [369/735], Loss: 0.0396\n",
      "Epoch [45/50], Step [370/735], Loss: 0.0552\n",
      "Epoch [45/50], Step [371/735], Loss: 0.0465\n",
      "Epoch [45/50], Step [372/735], Loss: 0.0523\n",
      "Epoch [45/50], Step [373/735], Loss: 0.0364\n",
      "Epoch [45/50], Step [374/735], Loss: 0.0422\n",
      "Epoch [45/50], Step [375/735], Loss: 0.0762\n",
      "Epoch [45/50], Step [376/735], Loss: 0.0428\n",
      "Epoch [45/50], Step [377/735], Loss: 0.0528\n",
      "Epoch [45/50], Step [378/735], Loss: 0.0166\n",
      "Epoch [45/50], Step [379/735], Loss: 0.0265\n",
      "Epoch [45/50], Step [380/735], Loss: 0.0689\n",
      "Epoch [45/50], Step [381/735], Loss: 0.0233\n",
      "Epoch [45/50], Step [382/735], Loss: 0.0943\n",
      "Epoch [45/50], Step [383/735], Loss: 0.0494\n",
      "Epoch [45/50], Step [384/735], Loss: 0.0567\n",
      "Epoch [45/50], Step [385/735], Loss: 0.0604\n",
      "Epoch [45/50], Step [386/735], Loss: 0.0444\n",
      "Epoch [45/50], Step [387/735], Loss: 0.0386\n",
      "Epoch [45/50], Step [388/735], Loss: 0.0884\n",
      "Epoch [45/50], Step [389/735], Loss: 0.0997\n",
      "Epoch [45/50], Step [390/735], Loss: 0.0157\n",
      "Epoch [45/50], Step [391/735], Loss: 0.0157\n",
      "Epoch [45/50], Step [392/735], Loss: 0.0521\n",
      "Epoch [45/50], Step [393/735], Loss: 0.0698\n",
      "Epoch [45/50], Step [394/735], Loss: 0.0306\n",
      "Epoch [45/50], Step [395/735], Loss: 0.1000\n",
      "Epoch [45/50], Step [396/735], Loss: 0.0425\n",
      "Epoch [45/50], Step [397/735], Loss: 0.3673\n",
      "Epoch [45/50], Step [398/735], Loss: 0.0731\n",
      "Epoch [45/50], Step [399/735], Loss: 0.0361\n",
      "Epoch [45/50], Step [400/735], Loss: 0.1238\n",
      "Epoch [45/50], Step [401/735], Loss: 0.0331\n",
      "Epoch [45/50], Step [402/735], Loss: 0.0221\n",
      "Epoch [45/50], Step [403/735], Loss: 0.0609\n",
      "Epoch [45/50], Step [404/735], Loss: 0.0260\n",
      "Epoch [45/50], Step [405/735], Loss: 0.0651\n",
      "Epoch [45/50], Step [406/735], Loss: 0.0992\n",
      "Epoch [45/50], Step [407/735], Loss: 0.0217\n",
      "Epoch [45/50], Step [408/735], Loss: 0.0890\n",
      "Epoch [45/50], Step [409/735], Loss: 0.0440\n",
      "Epoch [45/50], Step [410/735], Loss: 0.0303\n",
      "Epoch [45/50], Step [411/735], Loss: 0.0306\n",
      "Epoch [45/50], Step [412/735], Loss: 0.0374\n",
      "Epoch [45/50], Step [413/735], Loss: 0.0881\n",
      "Epoch [45/50], Step [414/735], Loss: 0.0543\n",
      "Epoch [45/50], Step [415/735], Loss: 0.1013\n",
      "Epoch [45/50], Step [416/735], Loss: 0.0243\n",
      "Epoch [45/50], Step [417/735], Loss: 0.0512\n",
      "Epoch [45/50], Step [418/735], Loss: 0.0922\n",
      "Epoch [45/50], Step [419/735], Loss: 0.0716\n",
      "Epoch [45/50], Step [420/735], Loss: 0.0573\n",
      "Epoch [45/50], Step [421/735], Loss: 0.0311\n",
      "Epoch [45/50], Step [422/735], Loss: 0.2316\n",
      "Epoch [45/50], Step [423/735], Loss: 0.0322\n",
      "Epoch [45/50], Step [424/735], Loss: 0.0235\n",
      "Epoch [45/50], Step [425/735], Loss: 0.0662\n",
      "Epoch [45/50], Step [426/735], Loss: 0.0334\n",
      "Epoch [45/50], Step [427/735], Loss: 0.0431\n",
      "Epoch [45/50], Step [428/735], Loss: 0.0156\n",
      "Epoch [45/50], Step [429/735], Loss: 0.0516\n",
      "Epoch [45/50], Step [430/735], Loss: 0.0402\n",
      "Epoch [45/50], Step [431/735], Loss: 0.2771\n",
      "Epoch [45/50], Step [432/735], Loss: 0.0757\n",
      "Epoch [45/50], Step [433/735], Loss: 0.0394\n",
      "Epoch [45/50], Step [434/735], Loss: 0.0437\n",
      "Epoch [45/50], Step [435/735], Loss: 0.0405\n",
      "Epoch [45/50], Step [436/735], Loss: 0.0309\n",
      "Epoch [45/50], Step [437/735], Loss: 0.0819\n",
      "Epoch [45/50], Step [438/735], Loss: 0.0453\n",
      "Epoch [45/50], Step [439/735], Loss: 0.1236\n",
      "Epoch [45/50], Step [440/735], Loss: 0.0385\n",
      "Epoch [45/50], Step [441/735], Loss: 0.0310\n",
      "Epoch [45/50], Step [442/735], Loss: 0.0403\n",
      "Epoch [45/50], Step [443/735], Loss: 0.0372\n",
      "Epoch [45/50], Step [444/735], Loss: 0.0611\n",
      "Epoch [45/50], Step [445/735], Loss: 0.0489\n",
      "Epoch [45/50], Step [446/735], Loss: 0.1249\n",
      "Epoch [45/50], Step [447/735], Loss: 0.0325\n",
      "Epoch [45/50], Step [448/735], Loss: 0.0581\n",
      "Epoch [45/50], Step [449/735], Loss: 0.0552\n",
      "Epoch [45/50], Step [450/735], Loss: 0.0717\n",
      "Epoch [45/50], Step [451/735], Loss: 0.0843\n",
      "Epoch [45/50], Step [452/735], Loss: 0.0619\n",
      "Epoch [45/50], Step [453/735], Loss: 0.0400\n",
      "Epoch [45/50], Step [454/735], Loss: 0.0483\n",
      "Epoch [45/50], Step [455/735], Loss: 0.0437\n",
      "Epoch [45/50], Step [456/735], Loss: 0.0343\n",
      "Epoch [45/50], Step [457/735], Loss: 0.0218\n",
      "Epoch [45/50], Step [458/735], Loss: 0.0444\n",
      "Epoch [45/50], Step [459/735], Loss: 0.0537\n",
      "Epoch [45/50], Step [460/735], Loss: 0.0643\n",
      "Epoch [45/50], Step [461/735], Loss: 0.0587\n",
      "Epoch [45/50], Step [462/735], Loss: 0.0605\n",
      "Epoch [45/50], Step [463/735], Loss: 0.0755\n",
      "Epoch [45/50], Step [464/735], Loss: 0.0246\n",
      "Epoch [45/50], Step [465/735], Loss: 0.0374\n",
      "Epoch [45/50], Step [466/735], Loss: 0.1016\n",
      "Epoch [45/50], Step [467/735], Loss: 0.0208\n",
      "Epoch [45/50], Step [468/735], Loss: 0.0436\n",
      "Epoch [45/50], Step [469/735], Loss: 0.0319\n",
      "Epoch [45/50], Step [470/735], Loss: 0.0157\n",
      "Epoch [45/50], Step [471/735], Loss: 0.0330\n",
      "Epoch [45/50], Step [472/735], Loss: 0.0181\n",
      "Epoch [45/50], Step [473/735], Loss: 0.0222\n",
      "Epoch [45/50], Step [474/735], Loss: 0.0704\n",
      "Epoch [45/50], Step [475/735], Loss: 0.0387\n",
      "Epoch [45/50], Step [476/735], Loss: 0.0658\n",
      "Epoch [45/50], Step [477/735], Loss: 0.0762\n",
      "Epoch [45/50], Step [478/735], Loss: 0.0274\n",
      "Epoch [45/50], Step [479/735], Loss: 0.0275\n",
      "Epoch [45/50], Step [480/735], Loss: 0.0803\n",
      "Epoch [45/50], Step [481/735], Loss: 0.0540\n",
      "Epoch [45/50], Step [482/735], Loss: 0.0392\n",
      "Epoch [45/50], Step [483/735], Loss: 0.0177\n",
      "Epoch [45/50], Step [484/735], Loss: 0.0484\n",
      "Epoch [45/50], Step [485/735], Loss: 0.0323\n",
      "Epoch [45/50], Step [486/735], Loss: 0.0206\n",
      "Epoch [45/50], Step [487/735], Loss: 0.0592\n",
      "Epoch [45/50], Step [488/735], Loss: 0.0202\n",
      "Epoch [45/50], Step [489/735], Loss: 0.0296\n",
      "Epoch [45/50], Step [490/735], Loss: 0.0703\n",
      "Epoch [45/50], Step [491/735], Loss: 0.0600\n",
      "Epoch [45/50], Step [492/735], Loss: 0.0466\n",
      "Epoch [45/50], Step [493/735], Loss: 0.0288\n",
      "Epoch [45/50], Step [494/735], Loss: 0.0478\n",
      "Epoch [45/50], Step [495/735], Loss: 0.0398\n",
      "Epoch [45/50], Step [496/735], Loss: 0.0342\n",
      "Epoch [45/50], Step [497/735], Loss: 0.9023\n",
      "Epoch [45/50], Step [498/735], Loss: 0.0713\n",
      "Epoch [45/50], Step [499/735], Loss: 0.0475\n",
      "Epoch [45/50], Step [500/735], Loss: 0.0376\n",
      "Epoch [45/50], Step [501/735], Loss: 0.0474\n",
      "Epoch [45/50], Step [502/735], Loss: 0.0329\n",
      "Epoch [45/50], Step [503/735], Loss: 0.1063\n",
      "Epoch [45/50], Step [504/735], Loss: 0.0652\n",
      "Epoch [45/50], Step [505/735], Loss: 0.0936\n",
      "Epoch [45/50], Step [506/735], Loss: 0.0834\n",
      "Epoch [45/50], Step [507/735], Loss: 0.0510\n",
      "Epoch [45/50], Step [508/735], Loss: 0.0702\n",
      "Epoch [45/50], Step [509/735], Loss: 0.0741\n",
      "Epoch [45/50], Step [510/735], Loss: 0.0641\n",
      "Epoch [45/50], Step [511/735], Loss: 0.0266\n",
      "Epoch [45/50], Step [512/735], Loss: 0.0585\n",
      "Epoch [45/50], Step [513/735], Loss: 0.0822\n",
      "Epoch [45/50], Step [514/735], Loss: 0.0415\n",
      "Epoch [45/50], Step [515/735], Loss: 0.1674\n",
      "Epoch [45/50], Step [516/735], Loss: 0.0552\n",
      "Epoch [45/50], Step [517/735], Loss: 0.0887\n",
      "Epoch [45/50], Step [518/735], Loss: 0.0321\n",
      "Epoch [45/50], Step [519/735], Loss: 0.0504\n",
      "Epoch [45/50], Step [520/735], Loss: 0.0656\n",
      "Epoch [45/50], Step [521/735], Loss: 0.0462\n",
      "Epoch [45/50], Step [522/735], Loss: 0.1012\n",
      "Epoch [45/50], Step [523/735], Loss: 0.0557\n",
      "Epoch [45/50], Step [524/735], Loss: 0.0416\n",
      "Epoch [45/50], Step [525/735], Loss: 0.0291\n",
      "Epoch [45/50], Step [526/735], Loss: 0.0311\n",
      "Epoch [45/50], Step [527/735], Loss: 0.0229\n",
      "Epoch [45/50], Step [528/735], Loss: 0.0626\n",
      "Epoch [45/50], Step [529/735], Loss: 0.0485\n",
      "Epoch [45/50], Step [530/735], Loss: 0.0196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Step [531/735], Loss: 0.0288\n",
      "Epoch [45/50], Step [532/735], Loss: 0.0365\n",
      "Epoch [45/50], Step [533/735], Loss: 0.0868\n",
      "Epoch [45/50], Step [534/735], Loss: 0.0276\n",
      "Epoch [45/50], Step [535/735], Loss: 0.0442\n",
      "Epoch [45/50], Step [536/735], Loss: 0.0484\n",
      "Epoch [45/50], Step [537/735], Loss: 0.0334\n",
      "Epoch [45/50], Step [538/735], Loss: 0.0301\n",
      "Epoch [45/50], Step [539/735], Loss: 0.1139\n",
      "Epoch [45/50], Step [540/735], Loss: 0.0367\n",
      "Epoch [45/50], Step [541/735], Loss: 0.0598\n",
      "Epoch [45/50], Step [542/735], Loss: 0.2297\n",
      "Epoch [45/50], Step [543/735], Loss: 0.0351\n",
      "Epoch [45/50], Step [544/735], Loss: 0.0536\n",
      "Epoch [45/50], Step [545/735], Loss: 0.0252\n",
      "Epoch [45/50], Step [546/735], Loss: 0.1146\n",
      "Epoch [45/50], Step [547/735], Loss: 0.0553\n",
      "Epoch [45/50], Step [548/735], Loss: 0.0839\n",
      "Epoch [45/50], Step [549/735], Loss: 0.0898\n",
      "Epoch [45/50], Step [550/735], Loss: 0.0277\n",
      "Epoch [45/50], Step [551/735], Loss: 0.0685\n",
      "Epoch [45/50], Step [552/735], Loss: 0.0159\n",
      "Epoch [45/50], Step [553/735], Loss: 0.0649\n",
      "Epoch [45/50], Step [554/735], Loss: 0.0444\n",
      "Epoch [45/50], Step [555/735], Loss: 0.1820\n",
      "Epoch [45/50], Step [556/735], Loss: 0.0279\n",
      "Epoch [45/50], Step [557/735], Loss: 0.0291\n",
      "Epoch [45/50], Step [558/735], Loss: 0.0381\n",
      "Epoch [45/50], Step [559/735], Loss: 0.0582\n",
      "Epoch [45/50], Step [560/735], Loss: 0.0647\n",
      "Epoch [45/50], Step [561/735], Loss: 0.0909\n",
      "Epoch [45/50], Step [562/735], Loss: 0.0421\n",
      "Epoch [45/50], Step [563/735], Loss: 0.0821\n",
      "Epoch [45/50], Step [564/735], Loss: 0.0468\n",
      "Epoch [45/50], Step [565/735], Loss: 0.0510\n",
      "Epoch [45/50], Step [566/735], Loss: 0.0361\n",
      "Epoch [45/50], Step [567/735], Loss: 0.0268\n",
      "Epoch [45/50], Step [568/735], Loss: 0.0238\n",
      "Epoch [45/50], Step [569/735], Loss: 0.0161\n",
      "Epoch [45/50], Step [570/735], Loss: 0.3488\n",
      "Epoch [45/50], Step [571/735], Loss: 0.0476\n",
      "Epoch [45/50], Step [572/735], Loss: 0.0344\n",
      "Epoch [45/50], Step [573/735], Loss: 0.0224\n",
      "Epoch [45/50], Step [574/735], Loss: 0.0299\n",
      "Epoch [45/50], Step [575/735], Loss: 0.0320\n",
      "Epoch [45/50], Step [576/735], Loss: 0.0312\n",
      "Epoch [45/50], Step [577/735], Loss: 0.0669\n",
      "Epoch [45/50], Step [578/735], Loss: 0.0301\n",
      "Epoch [45/50], Step [579/735], Loss: 0.0402\n",
      "Epoch [45/50], Step [580/735], Loss: 0.0203\n",
      "Epoch [45/50], Step [581/735], Loss: 0.0393\n",
      "Epoch [45/50], Step [582/735], Loss: 0.2367\n",
      "Epoch [45/50], Step [583/735], Loss: 0.0445\n",
      "Epoch [45/50], Step [584/735], Loss: 0.0747\n",
      "Epoch [45/50], Step [585/735], Loss: 0.0517\n",
      "Epoch [45/50], Step [586/735], Loss: 0.0484\n",
      "Epoch [45/50], Step [587/735], Loss: 0.0304\n",
      "Epoch [45/50], Step [588/735], Loss: 0.1289\n",
      "Epoch [45/50], Step [589/735], Loss: 0.0256\n",
      "Epoch [45/50], Step [590/735], Loss: 0.0392\n",
      "Epoch [45/50], Step [591/735], Loss: 0.1467\n",
      "Epoch [45/50], Step [592/735], Loss: 0.0374\n",
      "Epoch [45/50], Step [593/735], Loss: 0.0185\n",
      "Epoch [45/50], Step [594/735], Loss: 0.0541\n",
      "Epoch [45/50], Step [595/735], Loss: 0.0431\n",
      "Epoch [45/50], Step [596/735], Loss: 0.0517\n",
      "Epoch [45/50], Step [597/735], Loss: 0.0305\n",
      "Epoch [45/50], Step [598/735], Loss: 0.0366\n",
      "Epoch [45/50], Step [599/735], Loss: 0.0648\n",
      "Epoch [45/50], Step [600/735], Loss: 0.2187\n",
      "Epoch [45/50], Step [601/735], Loss: 0.0398\n",
      "Epoch [45/50], Step [602/735], Loss: 0.0392\n",
      "Epoch [45/50], Step [603/735], Loss: 0.0419\n",
      "Epoch [45/50], Step [604/735], Loss: 0.1115\n",
      "Epoch [45/50], Step [605/735], Loss: 0.0503\n",
      "Epoch [45/50], Step [606/735], Loss: 0.0412\n",
      "Epoch [45/50], Step [607/735], Loss: 0.0241\n",
      "Epoch [45/50], Step [608/735], Loss: 0.0324\n",
      "Epoch [45/50], Step [609/735], Loss: 0.0198\n",
      "Epoch [45/50], Step [610/735], Loss: 0.0200\n",
      "Epoch [45/50], Step [611/735], Loss: 0.0365\n",
      "Epoch [45/50], Step [612/735], Loss: 0.0280\n",
      "Epoch [45/50], Step [613/735], Loss: 0.0333\n",
      "Epoch [45/50], Step [614/735], Loss: 0.0210\n",
      "Epoch [45/50], Step [615/735], Loss: 0.0515\n",
      "Epoch [45/50], Step [616/735], Loss: 0.0705\n",
      "Epoch [45/50], Step [617/735], Loss: 0.0678\n",
      "Epoch [45/50], Step [618/735], Loss: 0.0435\n",
      "Epoch [45/50], Step [619/735], Loss: 0.0542\n",
      "Epoch [45/50], Step [620/735], Loss: 0.0203\n",
      "Epoch [45/50], Step [621/735], Loss: 0.0166\n",
      "Epoch [45/50], Step [622/735], Loss: 0.1226\n",
      "Epoch [45/50], Step [623/735], Loss: 0.0322\n",
      "Epoch [45/50], Step [624/735], Loss: 0.1160\n",
      "Epoch [45/50], Step [625/735], Loss: 0.0335\n",
      "Epoch [45/50], Step [626/735], Loss: 0.0134\n",
      "Epoch [45/50], Step [627/735], Loss: 0.0358\n",
      "Epoch [45/50], Step [628/735], Loss: 0.0360\n",
      "Epoch [45/50], Step [629/735], Loss: 0.0206\n",
      "Epoch [45/50], Step [630/735], Loss: 0.0326\n",
      "Epoch [45/50], Step [631/735], Loss: 0.0324\n",
      "Epoch [45/50], Step [632/735], Loss: 0.0464\n",
      "Epoch [45/50], Step [633/735], Loss: 0.0649\n",
      "Epoch [45/50], Step [634/735], Loss: 0.0337\n",
      "Epoch [45/50], Step [635/735], Loss: 0.0346\n",
      "Epoch [45/50], Step [636/735], Loss: 0.0176\n",
      "Epoch [45/50], Step [637/735], Loss: 0.0581\n",
      "Epoch [45/50], Step [638/735], Loss: 0.0435\n",
      "Epoch [45/50], Step [639/735], Loss: 0.0624\n",
      "Epoch [45/50], Step [640/735], Loss: 0.0368\n",
      "Epoch [45/50], Step [641/735], Loss: 0.0210\n",
      "Epoch [45/50], Step [642/735], Loss: 0.0435\n",
      "Epoch [45/50], Step [643/735], Loss: 0.0162\n",
      "Epoch [45/50], Step [644/735], Loss: 0.0682\n",
      "Epoch [45/50], Step [645/735], Loss: 0.0621\n",
      "Epoch [45/50], Step [646/735], Loss: 0.1592\n",
      "Epoch [45/50], Step [647/735], Loss: 0.0442\n",
      "Epoch [45/50], Step [648/735], Loss: 0.3207\n",
      "Epoch [45/50], Step [649/735], Loss: 0.0762\n",
      "Epoch [45/50], Step [650/735], Loss: 0.0457\n",
      "Epoch [45/50], Step [651/735], Loss: 0.0849\n",
      "Epoch [45/50], Step [652/735], Loss: 0.0905\n",
      "Epoch [45/50], Step [653/735], Loss: 0.0581\n",
      "Epoch [45/50], Step [654/735], Loss: 0.0488\n",
      "Epoch [45/50], Step [655/735], Loss: 0.0271\n",
      "Epoch [45/50], Step [656/735], Loss: 0.0595\n",
      "Epoch [45/50], Step [657/735], Loss: 0.0197\n",
      "Epoch [45/50], Step [658/735], Loss: 0.0894\n",
      "Epoch [45/50], Step [659/735], Loss: 0.0545\n",
      "Epoch [45/50], Step [660/735], Loss: 0.0575\n",
      "Epoch [45/50], Step [661/735], Loss: 0.0548\n",
      "Epoch [45/50], Step [662/735], Loss: 0.0808\n",
      "Epoch [45/50], Step [663/735], Loss: 0.0323\n",
      "Epoch [45/50], Step [664/735], Loss: 0.0887\n",
      "Epoch [45/50], Step [665/735], Loss: 0.0254\n",
      "Epoch [45/50], Step [666/735], Loss: 0.0307\n",
      "Epoch [45/50], Step [667/735], Loss: 0.0465\n",
      "Epoch [45/50], Step [668/735], Loss: 0.0629\n",
      "Epoch [45/50], Step [669/735], Loss: 0.0518\n",
      "Epoch [45/50], Step [670/735], Loss: 0.0397\n",
      "Epoch [45/50], Step [671/735], Loss: 0.0189\n",
      "Epoch [45/50], Step [672/735], Loss: 0.0256\n",
      "Epoch [45/50], Step [673/735], Loss: 0.0421\n",
      "Epoch [45/50], Step [674/735], Loss: 0.0882\n",
      "Epoch [45/50], Step [675/735], Loss: 0.0562\n",
      "Epoch [45/50], Step [676/735], Loss: 0.0440\n",
      "Epoch [45/50], Step [677/735], Loss: 0.0881\n",
      "Epoch [45/50], Step [678/735], Loss: 0.1447\n",
      "Epoch [45/50], Step [679/735], Loss: 0.0357\n",
      "Epoch [45/50], Step [680/735], Loss: 0.0916\n",
      "Epoch [45/50], Step [681/735], Loss: 0.0352\n",
      "Epoch [45/50], Step [682/735], Loss: 0.0487\n",
      "Epoch [45/50], Step [683/735], Loss: 0.0357\n",
      "Epoch [45/50], Step [684/735], Loss: 0.0501\n",
      "Epoch [45/50], Step [685/735], Loss: 0.0326\n",
      "Epoch [45/50], Step [686/735], Loss: 0.0456\n",
      "Epoch [45/50], Step [687/735], Loss: 0.1132\n",
      "Epoch [45/50], Step [688/735], Loss: 0.1061\n",
      "Epoch [45/50], Step [689/735], Loss: 0.0555\n",
      "Epoch [45/50], Step [690/735], Loss: 0.1179\n",
      "Epoch [45/50], Step [691/735], Loss: 0.0412\n",
      "Epoch [45/50], Step [692/735], Loss: 0.0725\n",
      "Epoch [45/50], Step [693/735], Loss: 0.0281\n",
      "Epoch [45/50], Step [694/735], Loss: 0.0497\n",
      "Epoch [45/50], Step [695/735], Loss: 0.0867\n",
      "Epoch [45/50], Step [696/735], Loss: 0.0747\n",
      "Epoch [45/50], Step [697/735], Loss: 0.0422\n",
      "Epoch [45/50], Step [698/735], Loss: 0.0472\n",
      "Epoch [45/50], Step [699/735], Loss: 0.0288\n",
      "Epoch [45/50], Step [700/735], Loss: 0.0634\n",
      "Epoch [45/50], Step [701/735], Loss: 0.0259\n",
      "Epoch [45/50], Step [702/735], Loss: 0.2224\n",
      "Epoch [45/50], Step [703/735], Loss: 0.1115\n",
      "Epoch [45/50], Step [704/735], Loss: 0.0834\n",
      "Epoch [45/50], Step [705/735], Loss: 0.0582\n",
      "Epoch [45/50], Step [706/735], Loss: 0.0793\n",
      "Epoch [45/50], Step [707/735], Loss: 0.0391\n",
      "Epoch [45/50], Step [708/735], Loss: 0.0396\n",
      "Epoch [45/50], Step [709/735], Loss: 0.0441\n",
      "Epoch [45/50], Step [710/735], Loss: 0.0544\n",
      "Epoch [45/50], Step [711/735], Loss: 0.0450\n",
      "Epoch [45/50], Step [712/735], Loss: 0.0440\n",
      "Epoch [45/50], Step [713/735], Loss: 0.0496\n",
      "Epoch [45/50], Step [714/735], Loss: 0.0639\n",
      "Epoch [45/50], Step [715/735], Loss: 0.0289\n",
      "Epoch [45/50], Step [716/735], Loss: 0.0266\n",
      "Epoch [45/50], Step [717/735], Loss: 0.0756\n",
      "Epoch [45/50], Step [718/735], Loss: 0.0730\n",
      "Epoch [45/50], Step [719/735], Loss: 0.0359\n",
      "Epoch [45/50], Step [720/735], Loss: 0.0280\n",
      "Epoch [45/50], Step [721/735], Loss: 0.0214\n",
      "Epoch [45/50], Step [722/735], Loss: 0.0292\n",
      "Epoch [45/50], Step [723/735], Loss: 0.0710\n",
      "Epoch [45/50], Step [724/735], Loss: 0.0153\n",
      "Epoch [45/50], Step [725/735], Loss: 0.2237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Step [726/735], Loss: 0.0566\n",
      "Epoch [45/50], Step [727/735], Loss: 0.0645\n",
      "Epoch [45/50], Step [728/735], Loss: 0.1080\n",
      "Epoch [45/50], Step [729/735], Loss: 0.1744\n",
      "Epoch [45/50], Step [730/735], Loss: 0.0308\n",
      "Epoch [45/50], Step [731/735], Loss: 0.0738\n",
      "Epoch [45/50], Step [732/735], Loss: 0.0548\n",
      "Epoch [45/50], Step [733/735], Loss: 0.0559\n",
      "Epoch [45/50], Step [734/735], Loss: 0.0326\n",
      "Epoch [45/50], Step [735/735], Loss: 0.0339\n",
      "Epoch [46/50], Step [1/735], Loss: 0.0574\n",
      "Epoch [46/50], Step [2/735], Loss: 0.0158\n",
      "Epoch [46/50], Step [3/735], Loss: 0.2218\n",
      "Epoch [46/50], Step [4/735], Loss: 0.0691\n",
      "Epoch [46/50], Step [5/735], Loss: 0.0336\n",
      "Epoch [46/50], Step [6/735], Loss: 0.0376\n",
      "Epoch [46/50], Step [7/735], Loss: 0.0389\n",
      "Epoch [46/50], Step [8/735], Loss: 0.0371\n",
      "Epoch [46/50], Step [9/735], Loss: 0.0190\n",
      "Epoch [46/50], Step [10/735], Loss: 0.0308\n",
      "Epoch [46/50], Step [11/735], Loss: 0.0540\n",
      "Epoch [46/50], Step [12/735], Loss: 0.0454\n",
      "Epoch [46/50], Step [13/735], Loss: 0.0477\n",
      "Epoch [46/50], Step [14/735], Loss: 0.0949\n",
      "Epoch [46/50], Step [15/735], Loss: 0.1399\n",
      "Epoch [46/50], Step [16/735], Loss: 0.0641\n",
      "Epoch [46/50], Step [17/735], Loss: 0.0895\n",
      "Epoch [46/50], Step [18/735], Loss: 0.0381\n",
      "Epoch [46/50], Step [19/735], Loss: 0.2287\n",
      "Epoch [46/50], Step [20/735], Loss: 0.0498\n",
      "Epoch [46/50], Step [21/735], Loss: 0.0486\n",
      "Epoch [46/50], Step [22/735], Loss: 0.1752\n",
      "Epoch [46/50], Step [23/735], Loss: 0.0461\n",
      "Epoch [46/50], Step [24/735], Loss: 0.0427\n",
      "Epoch [46/50], Step [25/735], Loss: 0.2352\n",
      "Epoch [46/50], Step [26/735], Loss: 0.0247\n",
      "Epoch [46/50], Step [27/735], Loss: 0.1089\n",
      "Epoch [46/50], Step [28/735], Loss: 0.0591\n",
      "Epoch [46/50], Step [29/735], Loss: 0.0274\n",
      "Epoch [46/50], Step [30/735], Loss: 0.2989\n",
      "Epoch [46/50], Step [31/735], Loss: 0.1395\n",
      "Epoch [46/50], Step [32/735], Loss: 0.0363\n",
      "Epoch [46/50], Step [33/735], Loss: 0.0620\n",
      "Epoch [46/50], Step [34/735], Loss: 0.0166\n",
      "Epoch [46/50], Step [35/735], Loss: 0.0291\n",
      "Epoch [46/50], Step [36/735], Loss: 0.0244\n",
      "Epoch [46/50], Step [37/735], Loss: 0.0470\n",
      "Epoch [46/50], Step [38/735], Loss: 0.2550\n",
      "Epoch [46/50], Step [39/735], Loss: 0.1168\n",
      "Epoch [46/50], Step [40/735], Loss: 0.0724\n",
      "Epoch [46/50], Step [41/735], Loss: 0.0740\n",
      "Epoch [46/50], Step [42/735], Loss: 0.0529\n",
      "Epoch [46/50], Step [43/735], Loss: 0.0620\n",
      "Epoch [46/50], Step [44/735], Loss: 0.0157\n",
      "Epoch [46/50], Step [45/735], Loss: 0.0643\n",
      "Epoch [46/50], Step [46/735], Loss: 0.0508\n",
      "Epoch [46/50], Step [47/735], Loss: 0.0791\n",
      "Epoch [46/50], Step [48/735], Loss: 0.0342\n",
      "Epoch [46/50], Step [49/735], Loss: 0.0310\n",
      "Epoch [46/50], Step [50/735], Loss: 0.0265\n",
      "Epoch [46/50], Step [51/735], Loss: 0.1654\n",
      "Epoch [46/50], Step [52/735], Loss: 0.0369\n",
      "Epoch [46/50], Step [53/735], Loss: 0.1091\n",
      "Epoch [46/50], Step [54/735], Loss: 0.0779\n",
      "Epoch [46/50], Step [55/735], Loss: 0.0448\n",
      "Epoch [46/50], Step [56/735], Loss: 0.1647\n",
      "Epoch [46/50], Step [57/735], Loss: 0.0361\n",
      "Epoch [46/50], Step [58/735], Loss: 0.0271\n",
      "Epoch [46/50], Step [59/735], Loss: 0.0405\n",
      "Epoch [46/50], Step [60/735], Loss: 0.0639\n",
      "Epoch [46/50], Step [61/735], Loss: 0.0319\n",
      "Epoch [46/50], Step [62/735], Loss: 0.0848\n",
      "Epoch [46/50], Step [63/735], Loss: 0.0199\n",
      "Epoch [46/50], Step [64/735], Loss: 0.0209\n",
      "Epoch [46/50], Step [65/735], Loss: 0.1341\n",
      "Epoch [46/50], Step [66/735], Loss: 0.1197\n",
      "Epoch [46/50], Step [67/735], Loss: 0.0149\n",
      "Epoch [46/50], Step [68/735], Loss: 0.0235\n",
      "Epoch [46/50], Step [69/735], Loss: 0.1395\n",
      "Epoch [46/50], Step [70/735], Loss: 0.0759\n",
      "Epoch [46/50], Step [71/735], Loss: 0.0372\n",
      "Epoch [46/50], Step [72/735], Loss: 0.0294\n",
      "Epoch [46/50], Step [73/735], Loss: 0.0313\n",
      "Epoch [46/50], Step [74/735], Loss: 0.1404\n",
      "Epoch [46/50], Step [75/735], Loss: 0.0371\n",
      "Epoch [46/50], Step [76/735], Loss: 0.0757\n",
      "Epoch [46/50], Step [77/735], Loss: 0.0575\n",
      "Epoch [46/50], Step [78/735], Loss: 0.0350\n",
      "Epoch [46/50], Step [79/735], Loss: 0.0623\n",
      "Epoch [46/50], Step [80/735], Loss: 0.0391\n",
      "Epoch [46/50], Step [81/735], Loss: 0.0418\n",
      "Epoch [46/50], Step [82/735], Loss: 0.0277\n",
      "Epoch [46/50], Step [83/735], Loss: 0.0507\n",
      "Epoch [46/50], Step [84/735], Loss: 0.0772\n",
      "Epoch [46/50], Step [85/735], Loss: 0.0253\n",
      "Epoch [46/50], Step [86/735], Loss: 0.0431\n",
      "Epoch [46/50], Step [87/735], Loss: 0.0558\n",
      "Epoch [46/50], Step [88/735], Loss: 0.0507\n",
      "Epoch [46/50], Step [89/735], Loss: 0.0858\n",
      "Epoch [46/50], Step [90/735], Loss: 0.0165\n",
      "Epoch [46/50], Step [91/735], Loss: 0.0504\n",
      "Epoch [46/50], Step [92/735], Loss: 0.0316\n",
      "Epoch [46/50], Step [93/735], Loss: 0.0459\n",
      "Epoch [46/50], Step [94/735], Loss: 0.0361\n",
      "Epoch [46/50], Step [95/735], Loss: 0.0792\n",
      "Epoch [46/50], Step [96/735], Loss: 0.0865\n",
      "Epoch [46/50], Step [97/735], Loss: 0.0481\n",
      "Epoch [46/50], Step [98/735], Loss: 0.0311\n",
      "Epoch [46/50], Step [99/735], Loss: 0.0199\n",
      "Epoch [46/50], Step [100/735], Loss: 0.0790\n",
      "Epoch [46/50], Step [101/735], Loss: 0.0846\n",
      "Epoch [46/50], Step [102/735], Loss: 0.0303\n",
      "Epoch [46/50], Step [103/735], Loss: 0.0463\n",
      "Epoch [46/50], Step [104/735], Loss: 0.0948\n",
      "Epoch [46/50], Step [105/735], Loss: 0.0183\n",
      "Epoch [46/50], Step [106/735], Loss: 0.0496\n",
      "Epoch [46/50], Step [107/735], Loss: 0.0265\n",
      "Epoch [46/50], Step [108/735], Loss: 0.0374\n",
      "Epoch [46/50], Step [109/735], Loss: 0.0417\n",
      "Epoch [46/50], Step [110/735], Loss: 0.0583\n",
      "Epoch [46/50], Step [111/735], Loss: 0.0257\n",
      "Epoch [46/50], Step [112/735], Loss: 0.0260\n",
      "Epoch [46/50], Step [113/735], Loss: 0.0162\n",
      "Epoch [46/50], Step [114/735], Loss: 0.0762\n",
      "Epoch [46/50], Step [115/735], Loss: 0.0552\n",
      "Epoch [46/50], Step [116/735], Loss: 0.0501\n",
      "Epoch [46/50], Step [117/735], Loss: 0.1328\n",
      "Epoch [46/50], Step [118/735], Loss: 0.1390\n",
      "Epoch [46/50], Step [119/735], Loss: 0.4049\n",
      "Epoch [46/50], Step [120/735], Loss: 0.0253\n",
      "Epoch [46/50], Step [121/735], Loss: 0.0389\n",
      "Epoch [46/50], Step [122/735], Loss: 0.0220\n",
      "Epoch [46/50], Step [123/735], Loss: 0.0408\n",
      "Epoch [46/50], Step [124/735], Loss: 0.0519\n",
      "Epoch [46/50], Step [125/735], Loss: 0.0322\n",
      "Epoch [46/50], Step [126/735], Loss: 0.0254\n",
      "Epoch [46/50], Step [127/735], Loss: 0.1881\n",
      "Epoch [46/50], Step [128/735], Loss: 0.1540\n",
      "Epoch [46/50], Step [129/735], Loss: 0.0964\n",
      "Epoch [46/50], Step [130/735], Loss: 0.0237\n",
      "Epoch [46/50], Step [131/735], Loss: 0.0818\n",
      "Epoch [46/50], Step [132/735], Loss: 0.0447\n",
      "Epoch [46/50], Step [133/735], Loss: 0.0852\n",
      "Epoch [46/50], Step [134/735], Loss: 0.0201\n",
      "Epoch [46/50], Step [135/735], Loss: 0.0718\n",
      "Epoch [46/50], Step [136/735], Loss: 0.0300\n",
      "Epoch [46/50], Step [137/735], Loss: 0.0474\n",
      "Epoch [46/50], Step [138/735], Loss: 0.0240\n",
      "Epoch [46/50], Step [139/735], Loss: 0.0792\n",
      "Epoch [46/50], Step [140/735], Loss: 0.0300\n",
      "Epoch [46/50], Step [141/735], Loss: 0.0218\n",
      "Epoch [46/50], Step [142/735], Loss: 0.0341\n",
      "Epoch [46/50], Step [143/735], Loss: 0.0330\n",
      "Epoch [46/50], Step [144/735], Loss: 0.0326\n",
      "Epoch [46/50], Step [145/735], Loss: 0.0869\n",
      "Epoch [46/50], Step [146/735], Loss: 0.0594\n",
      "Epoch [46/50], Step [147/735], Loss: 0.0348\n",
      "Epoch [46/50], Step [148/735], Loss: 0.0137\n",
      "Epoch [46/50], Step [149/735], Loss: 0.0282\n",
      "Epoch [46/50], Step [150/735], Loss: 0.0261\n",
      "Epoch [46/50], Step [151/735], Loss: 0.0277\n",
      "Epoch [46/50], Step [152/735], Loss: 0.0352\n",
      "Epoch [46/50], Step [153/735], Loss: 0.0376\n",
      "Epoch [46/50], Step [154/735], Loss: 0.0172\n",
      "Epoch [46/50], Step [155/735], Loss: 0.0461\n",
      "Epoch [46/50], Step [156/735], Loss: 0.0252\n",
      "Epoch [46/50], Step [157/735], Loss: 0.0518\n",
      "Epoch [46/50], Step [158/735], Loss: 0.0754\n",
      "Epoch [46/50], Step [159/735], Loss: 0.0376\n",
      "Epoch [46/50], Step [160/735], Loss: 0.1050\n",
      "Epoch [46/50], Step [161/735], Loss: 0.0694\n",
      "Epoch [46/50], Step [162/735], Loss: 0.0228\n",
      "Epoch [46/50], Step [163/735], Loss: 0.0449\n",
      "Epoch [46/50], Step [164/735], Loss: 0.0420\n",
      "Epoch [46/50], Step [165/735], Loss: 0.0598\n",
      "Epoch [46/50], Step [166/735], Loss: 0.0484\n",
      "Epoch [46/50], Step [167/735], Loss: 0.0671\n",
      "Epoch [46/50], Step [168/735], Loss: 0.0970\n",
      "Epoch [46/50], Step [169/735], Loss: 0.0489\n",
      "Epoch [46/50], Step [170/735], Loss: 0.0728\n",
      "Epoch [46/50], Step [171/735], Loss: 0.0625\n",
      "Epoch [46/50], Step [172/735], Loss: 0.0276\n",
      "Epoch [46/50], Step [173/735], Loss: 0.0429\n",
      "Epoch [46/50], Step [174/735], Loss: 0.0749\n",
      "Epoch [46/50], Step [175/735], Loss: 0.1073\n",
      "Epoch [46/50], Step [176/735], Loss: 0.0538\n",
      "Epoch [46/50], Step [177/735], Loss: 0.1057\n",
      "Epoch [46/50], Step [178/735], Loss: 0.0655\n",
      "Epoch [46/50], Step [179/735], Loss: 0.0222\n",
      "Epoch [46/50], Step [180/735], Loss: 0.0275\n",
      "Epoch [46/50], Step [181/735], Loss: 0.0455\n",
      "Epoch [46/50], Step [182/735], Loss: 0.0431\n",
      "Epoch [46/50], Step [183/735], Loss: 0.0325\n",
      "Epoch [46/50], Step [184/735], Loss: 0.0661\n",
      "Epoch [46/50], Step [185/735], Loss: 0.0368\n",
      "Epoch [46/50], Step [186/735], Loss: 0.0251\n",
      "Epoch [46/50], Step [187/735], Loss: 0.0450\n",
      "Epoch [46/50], Step [188/735], Loss: 0.0235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Step [189/735], Loss: 0.0685\n",
      "Epoch [46/50], Step [190/735], Loss: 0.1032\n",
      "Epoch [46/50], Step [191/735], Loss: 0.2036\n",
      "Epoch [46/50], Step [192/735], Loss: 0.0324\n",
      "Epoch [46/50], Step [193/735], Loss: 0.0673\n",
      "Epoch [46/50], Step [194/735], Loss: 0.0899\n",
      "Epoch [46/50], Step [195/735], Loss: 0.0362\n",
      "Epoch [46/50], Step [196/735], Loss: 0.0259\n",
      "Epoch [46/50], Step [197/735], Loss: 0.0478\n",
      "Epoch [46/50], Step [198/735], Loss: 0.0411\n",
      "Epoch [46/50], Step [199/735], Loss: 0.0654\n",
      "Epoch [46/50], Step [200/735], Loss: 0.0245\n",
      "Epoch [46/50], Step [201/735], Loss: 0.0285\n",
      "Epoch [46/50], Step [202/735], Loss: 0.0512\n",
      "Epoch [46/50], Step [203/735], Loss: 0.0495\n",
      "Epoch [46/50], Step [204/735], Loss: 0.0249\n",
      "Epoch [46/50], Step [205/735], Loss: 0.2112\n",
      "Epoch [46/50], Step [206/735], Loss: 0.0715\n",
      "Epoch [46/50], Step [207/735], Loss: 0.0495\n",
      "Epoch [46/50], Step [208/735], Loss: 0.0278\n",
      "Epoch [46/50], Step [209/735], Loss: 0.0236\n",
      "Epoch [46/50], Step [210/735], Loss: 0.0224\n",
      "Epoch [46/50], Step [211/735], Loss: 0.0259\n",
      "Epoch [46/50], Step [212/735], Loss: 0.2815\n",
      "Epoch [46/50], Step [213/735], Loss: 0.0675\n",
      "Epoch [46/50], Step [214/735], Loss: 0.0700\n",
      "Epoch [46/50], Step [215/735], Loss: 0.0292\n",
      "Epoch [46/50], Step [216/735], Loss: 0.0168\n",
      "Epoch [46/50], Step [217/735], Loss: 0.0457\n",
      "Epoch [46/50], Step [218/735], Loss: 0.0203\n",
      "Epoch [46/50], Step [219/735], Loss: 0.0636\n",
      "Epoch [46/50], Step [220/735], Loss: 0.1576\n",
      "Epoch [46/50], Step [221/735], Loss: 0.1032\n",
      "Epoch [46/50], Step [222/735], Loss: 0.0256\n",
      "Epoch [46/50], Step [223/735], Loss: 0.0573\n",
      "Epoch [46/50], Step [224/735], Loss: 0.0503\n",
      "Epoch [46/50], Step [225/735], Loss: 0.0765\n",
      "Epoch [46/50], Step [226/735], Loss: 0.1112\n",
      "Epoch [46/50], Step [227/735], Loss: 0.0269\n",
      "Epoch [46/50], Step [228/735], Loss: 0.0605\n",
      "Epoch [46/50], Step [229/735], Loss: 0.0598\n",
      "Epoch [46/50], Step [230/735], Loss: 0.0351\n",
      "Epoch [46/50], Step [231/735], Loss: 0.0426\n",
      "Epoch [46/50], Step [232/735], Loss: 0.0342\n",
      "Epoch [46/50], Step [233/735], Loss: 0.1161\n",
      "Epoch [46/50], Step [234/735], Loss: 0.0996\n",
      "Epoch [46/50], Step [235/735], Loss: 0.0439\n",
      "Epoch [46/50], Step [236/735], Loss: 0.1004\n",
      "Epoch [46/50], Step [237/735], Loss: 0.0216\n",
      "Epoch [46/50], Step [238/735], Loss: 0.1470\n",
      "Epoch [46/50], Step [239/735], Loss: 0.0238\n",
      "Epoch [46/50], Step [240/735], Loss: 0.0337\n",
      "Epoch [46/50], Step [241/735], Loss: 0.0549\n",
      "Epoch [46/50], Step [242/735], Loss: 0.0254\n",
      "Epoch [46/50], Step [243/735], Loss: 0.0759\n",
      "Epoch [46/50], Step [244/735], Loss: 0.0877\n",
      "Epoch [46/50], Step [245/735], Loss: 0.0511\n",
      "Epoch [46/50], Step [246/735], Loss: 0.0409\n",
      "Epoch [46/50], Step [247/735], Loss: 0.0326\n",
      "Epoch [46/50], Step [248/735], Loss: 0.0330\n",
      "Epoch [46/50], Step [249/735], Loss: 0.0246\n",
      "Epoch [46/50], Step [250/735], Loss: 0.1990\n",
      "Epoch [46/50], Step [251/735], Loss: 0.0416\n",
      "Epoch [46/50], Step [252/735], Loss: 0.0487\n",
      "Epoch [46/50], Step [253/735], Loss: 0.0898\n",
      "Epoch [46/50], Step [254/735], Loss: 0.0295\n",
      "Epoch [46/50], Step [255/735], Loss: 0.2048\n",
      "Epoch [46/50], Step [256/735], Loss: 0.0987\n",
      "Epoch [46/50], Step [257/735], Loss: 0.0536\n",
      "Epoch [46/50], Step [258/735], Loss: 0.0995\n",
      "Epoch [46/50], Step [259/735], Loss: 0.0588\n",
      "Epoch [46/50], Step [260/735], Loss: 0.0326\n",
      "Epoch [46/50], Step [261/735], Loss: 0.0471\n",
      "Epoch [46/50], Step [262/735], Loss: 0.0979\n",
      "Epoch [46/50], Step [263/735], Loss: 0.0493\n",
      "Epoch [46/50], Step [264/735], Loss: 0.0829\n",
      "Epoch [46/50], Step [265/735], Loss: 0.0260\n",
      "Epoch [46/50], Step [266/735], Loss: 0.1338\n",
      "Epoch [46/50], Step [267/735], Loss: 0.0417\n",
      "Epoch [46/50], Step [268/735], Loss: 0.0394\n",
      "Epoch [46/50], Step [269/735], Loss: 0.0189\n",
      "Epoch [46/50], Step [270/735], Loss: 0.0894\n",
      "Epoch [46/50], Step [271/735], Loss: 0.0348\n",
      "Epoch [46/50], Step [272/735], Loss: 0.1266\n",
      "Epoch [46/50], Step [273/735], Loss: 0.3936\n",
      "Epoch [46/50], Step [274/735], Loss: 0.0578\n",
      "Epoch [46/50], Step [275/735], Loss: 0.0587\n",
      "Epoch [46/50], Step [276/735], Loss: 0.0408\n",
      "Epoch [46/50], Step [277/735], Loss: 0.0432\n",
      "Epoch [46/50], Step [278/735], Loss: 0.0879\n",
      "Epoch [46/50], Step [279/735], Loss: 0.0299\n",
      "Epoch [46/50], Step [280/735], Loss: 0.2174\n",
      "Epoch [46/50], Step [281/735], Loss: 0.1438\n",
      "Epoch [46/50], Step [282/735], Loss: 0.0296\n",
      "Epoch [46/50], Step [283/735], Loss: 0.0546\n",
      "Epoch [46/50], Step [284/735], Loss: 0.0575\n",
      "Epoch [46/50], Step [285/735], Loss: 0.0171\n",
      "Epoch [46/50], Step [286/735], Loss: 0.0264\n",
      "Epoch [46/50], Step [287/735], Loss: 0.1373\n",
      "Epoch [46/50], Step [288/735], Loss: 0.0665\n",
      "Epoch [46/50], Step [289/735], Loss: 0.0326\n",
      "Epoch [46/50], Step [290/735], Loss: 0.0254\n",
      "Epoch [46/50], Step [291/735], Loss: 0.0207\n",
      "Epoch [46/50], Step [292/735], Loss: 0.0555\n",
      "Epoch [46/50], Step [293/735], Loss: 0.1042\n",
      "Epoch [46/50], Step [294/735], Loss: 0.0191\n",
      "Epoch [46/50], Step [295/735], Loss: 0.0217\n",
      "Epoch [46/50], Step [296/735], Loss: 0.0435\n",
      "Epoch [46/50], Step [297/735], Loss: 0.0599\n",
      "Epoch [46/50], Step [298/735], Loss: 0.0206\n",
      "Epoch [46/50], Step [299/735], Loss: 0.0555\n",
      "Epoch [46/50], Step [300/735], Loss: 0.0277\n",
      "Epoch [46/50], Step [301/735], Loss: 0.0623\n",
      "Epoch [46/50], Step [302/735], Loss: 0.0741\n",
      "Epoch [46/50], Step [303/735], Loss: 0.1994\n",
      "Epoch [46/50], Step [304/735], Loss: 0.0925\n",
      "Epoch [46/50], Step [305/735], Loss: 0.0233\n",
      "Epoch [46/50], Step [306/735], Loss: 0.0598\n",
      "Epoch [46/50], Step [307/735], Loss: 0.0393\n",
      "Epoch [46/50], Step [308/735], Loss: 0.0380\n",
      "Epoch [46/50], Step [309/735], Loss: 0.0487\n",
      "Epoch [46/50], Step [310/735], Loss: 0.0687\n",
      "Epoch [46/50], Step [311/735], Loss: 0.0708\n",
      "Epoch [46/50], Step [312/735], Loss: 0.1415\n",
      "Epoch [46/50], Step [313/735], Loss: 0.0992\n",
      "Epoch [46/50], Step [314/735], Loss: 0.0391\n",
      "Epoch [46/50], Step [315/735], Loss: 0.0560\n",
      "Epoch [46/50], Step [316/735], Loss: 0.0475\n",
      "Epoch [46/50], Step [317/735], Loss: 0.0339\n",
      "Epoch [46/50], Step [318/735], Loss: 0.0279\n",
      "Epoch [46/50], Step [319/735], Loss: 0.0459\n",
      "Epoch [46/50], Step [320/735], Loss: 0.0887\n",
      "Epoch [46/50], Step [321/735], Loss: 0.0278\n",
      "Epoch [46/50], Step [322/735], Loss: 0.0855\n",
      "Epoch [46/50], Step [323/735], Loss: 0.0741\n",
      "Epoch [46/50], Step [324/735], Loss: 0.0719\n",
      "Epoch [46/50], Step [325/735], Loss: 0.0990\n",
      "Epoch [46/50], Step [326/735], Loss: 0.0565\n",
      "Epoch [46/50], Step [327/735], Loss: 0.0441\n",
      "Epoch [46/50], Step [328/735], Loss: 0.0412\n",
      "Epoch [46/50], Step [329/735], Loss: 0.0145\n",
      "Epoch [46/50], Step [330/735], Loss: 0.0292\n",
      "Epoch [46/50], Step [331/735], Loss: 0.0241\n",
      "Epoch [46/50], Step [332/735], Loss: 0.0992\n",
      "Epoch [46/50], Step [333/735], Loss: 0.0275\n",
      "Epoch [46/50], Step [334/735], Loss: 0.0633\n",
      "Epoch [46/50], Step [335/735], Loss: 0.0429\n",
      "Epoch [46/50], Step [336/735], Loss: 0.0333\n",
      "Epoch [46/50], Step [337/735], Loss: 0.0463\n",
      "Epoch [46/50], Step [338/735], Loss: 0.0666\n",
      "Epoch [46/50], Step [339/735], Loss: 0.0384\n",
      "Epoch [46/50], Step [340/735], Loss: 0.0314\n",
      "Epoch [46/50], Step [341/735], Loss: 0.0419\n",
      "Epoch [46/50], Step [342/735], Loss: 0.0415\n",
      "Epoch [46/50], Step [343/735], Loss: 0.0497\n",
      "Epoch [46/50], Step [344/735], Loss: 0.0447\n",
      "Epoch [46/50], Step [345/735], Loss: 0.0261\n",
      "Epoch [46/50], Step [346/735], Loss: 0.0204\n",
      "Epoch [46/50], Step [347/735], Loss: 0.0283\n",
      "Epoch [46/50], Step [348/735], Loss: 0.0421\n",
      "Epoch [46/50], Step [349/735], Loss: 0.1814\n",
      "Epoch [46/50], Step [350/735], Loss: 0.0474\n",
      "Epoch [46/50], Step [351/735], Loss: 0.0671\n",
      "Epoch [46/50], Step [352/735], Loss: 0.0556\n",
      "Epoch [46/50], Step [353/735], Loss: 0.0265\n",
      "Epoch [46/50], Step [354/735], Loss: 0.0664\n",
      "Epoch [46/50], Step [355/735], Loss: 0.0268\n",
      "Epoch [46/50], Step [356/735], Loss: 0.0200\n",
      "Epoch [46/50], Step [357/735], Loss: 0.0809\n",
      "Epoch [46/50], Step [358/735], Loss: 0.0254\n",
      "Epoch [46/50], Step [359/735], Loss: 0.1671\n",
      "Epoch [46/50], Step [360/735], Loss: 0.0727\n",
      "Epoch [46/50], Step [361/735], Loss: 0.3825\n",
      "Epoch [46/50], Step [362/735], Loss: 0.0686\n",
      "Epoch [46/50], Step [363/735], Loss: 0.0491\n",
      "Epoch [46/50], Step [364/735], Loss: 0.0446\n",
      "Epoch [46/50], Step [365/735], Loss: 0.0587\n",
      "Epoch [46/50], Step [366/735], Loss: 0.0268\n",
      "Epoch [46/50], Step [367/735], Loss: 0.0491\n",
      "Epoch [46/50], Step [368/735], Loss: 0.0358\n",
      "Epoch [46/50], Step [369/735], Loss: 0.1128\n",
      "Epoch [46/50], Step [370/735], Loss: 0.0646\n",
      "Epoch [46/50], Step [371/735], Loss: 0.1057\n",
      "Epoch [46/50], Step [372/735], Loss: 0.0403\n",
      "Epoch [46/50], Step [373/735], Loss: 0.1570\n",
      "Epoch [46/50], Step [374/735], Loss: 0.0313\n",
      "Epoch [46/50], Step [375/735], Loss: 0.0991\n",
      "Epoch [46/50], Step [376/735], Loss: 0.0414\n",
      "Epoch [46/50], Step [377/735], Loss: 0.1011\n",
      "Epoch [46/50], Step [378/735], Loss: 0.0477\n",
      "Epoch [46/50], Step [379/735], Loss: 0.0665\n",
      "Epoch [46/50], Step [380/735], Loss: 0.0350\n",
      "Epoch [46/50], Step [381/735], Loss: 0.3512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Step [382/735], Loss: 0.0828\n",
      "Epoch [46/50], Step [383/735], Loss: 0.0485\n",
      "Epoch [46/50], Step [384/735], Loss: 0.0751\n",
      "Epoch [46/50], Step [385/735], Loss: 0.0486\n",
      "Epoch [46/50], Step [386/735], Loss: 0.0733\n",
      "Epoch [46/50], Step [387/735], Loss: 0.1404\n",
      "Epoch [46/50], Step [388/735], Loss: 0.0898\n",
      "Epoch [46/50], Step [389/735], Loss: 0.1091\n",
      "Epoch [46/50], Step [390/735], Loss: 0.0589\n",
      "Epoch [46/50], Step [391/735], Loss: 0.0254\n",
      "Epoch [46/50], Step [392/735], Loss: 0.0718\n",
      "Epoch [46/50], Step [393/735], Loss: 0.0331\n",
      "Epoch [46/50], Step [394/735], Loss: 0.1806\n",
      "Epoch [46/50], Step [395/735], Loss: 0.0547\n",
      "Epoch [46/50], Step [396/735], Loss: 0.0311\n",
      "Epoch [46/50], Step [397/735], Loss: 0.0243\n",
      "Epoch [46/50], Step [398/735], Loss: 0.1010\n",
      "Epoch [46/50], Step [399/735], Loss: 0.1109\n",
      "Epoch [46/50], Step [400/735], Loss: 0.0884\n",
      "Epoch [46/50], Step [401/735], Loss: 0.0327\n",
      "Epoch [46/50], Step [402/735], Loss: 0.0285\n",
      "Epoch [46/50], Step [403/735], Loss: 0.0912\n",
      "Epoch [46/50], Step [404/735], Loss: 0.1086\n",
      "Epoch [46/50], Step [405/735], Loss: 0.0340\n",
      "Epoch [46/50], Step [406/735], Loss: 0.0514\n",
      "Epoch [46/50], Step [407/735], Loss: 0.0226\n",
      "Epoch [46/50], Step [408/735], Loss: 0.0722\n",
      "Epoch [46/50], Step [409/735], Loss: 0.0374\n",
      "Epoch [46/50], Step [410/735], Loss: 0.0381\n",
      "Epoch [46/50], Step [411/735], Loss: 0.0401\n",
      "Epoch [46/50], Step [412/735], Loss: 0.0481\n",
      "Epoch [46/50], Step [413/735], Loss: 0.0238\n",
      "Epoch [46/50], Step [414/735], Loss: 0.0400\n",
      "Epoch [46/50], Step [415/735], Loss: 0.0627\n",
      "Epoch [46/50], Step [416/735], Loss: 0.0585\n",
      "Epoch [46/50], Step [417/735], Loss: 0.0550\n",
      "Epoch [46/50], Step [418/735], Loss: 0.0562\n",
      "Epoch [46/50], Step [419/735], Loss: 0.0733\n",
      "Epoch [46/50], Step [420/735], Loss: 0.1551\n",
      "Epoch [46/50], Step [421/735], Loss: 0.0563\n",
      "Epoch [46/50], Step [422/735], Loss: 0.0289\n",
      "Epoch [46/50], Step [423/735], Loss: 0.0292\n",
      "Epoch [46/50], Step [424/735], Loss: 0.0818\n",
      "Epoch [46/50], Step [425/735], Loss: 0.0682\n",
      "Epoch [46/50], Step [426/735], Loss: 0.0875\n",
      "Epoch [46/50], Step [427/735], Loss: 0.0357\n",
      "Epoch [46/50], Step [428/735], Loss: 0.0731\n",
      "Epoch [46/50], Step [429/735], Loss: 0.0453\n",
      "Epoch [46/50], Step [430/735], Loss: 0.0351\n",
      "Epoch [46/50], Step [431/735], Loss: 0.0551\n",
      "Epoch [46/50], Step [432/735], Loss: 0.0451\n",
      "Epoch [46/50], Step [433/735], Loss: 0.0511\n",
      "Epoch [46/50], Step [434/735], Loss: 0.0670\n",
      "Epoch [46/50], Step [435/735], Loss: 0.3885\n",
      "Epoch [46/50], Step [436/735], Loss: 0.0301\n",
      "Epoch [46/50], Step [437/735], Loss: 0.0264\n",
      "Epoch [46/50], Step [438/735], Loss: 0.0271\n",
      "Epoch [46/50], Step [439/735], Loss: 0.0393\n",
      "Epoch [46/50], Step [440/735], Loss: 0.0276\n",
      "Epoch [46/50], Step [441/735], Loss: 0.0389\n",
      "Epoch [46/50], Step [442/735], Loss: 0.0215\n",
      "Epoch [46/50], Step [443/735], Loss: 0.0439\n",
      "Epoch [46/50], Step [444/735], Loss: 0.0228\n",
      "Epoch [46/50], Step [445/735], Loss: 0.1016\n",
      "Epoch [46/50], Step [446/735], Loss: 0.0237\n",
      "Epoch [46/50], Step [447/735], Loss: 0.0584\n",
      "Epoch [46/50], Step [448/735], Loss: 0.0367\n",
      "Epoch [46/50], Step [449/735], Loss: 0.0175\n",
      "Epoch [46/50], Step [450/735], Loss: 0.0339\n",
      "Epoch [46/50], Step [451/735], Loss: 0.0455\n",
      "Epoch [46/50], Step [452/735], Loss: 0.1067\n",
      "Epoch [46/50], Step [453/735], Loss: 0.0275\n",
      "Epoch [46/50], Step [454/735], Loss: 0.0480\n",
      "Epoch [46/50], Step [455/735], Loss: 0.0340\n",
      "Epoch [46/50], Step [456/735], Loss: 0.1243\n",
      "Epoch [46/50], Step [457/735], Loss: 0.1313\n",
      "Epoch [46/50], Step [458/735], Loss: 0.0518\n",
      "Epoch [46/50], Step [459/735], Loss: 0.0179\n",
      "Epoch [46/50], Step [460/735], Loss: 0.0226\n",
      "Epoch [46/50], Step [461/735], Loss: 0.0924\n",
      "Epoch [46/50], Step [462/735], Loss: 0.0740\n",
      "Epoch [46/50], Step [463/735], Loss: 0.0823\n",
      "Epoch [46/50], Step [464/735], Loss: 0.0484\n",
      "Epoch [46/50], Step [465/735], Loss: 0.0280\n",
      "Epoch [46/50], Step [466/735], Loss: 0.0527\n",
      "Epoch [46/50], Step [467/735], Loss: 0.1010\n",
      "Epoch [46/50], Step [468/735], Loss: 0.0363\n",
      "Epoch [46/50], Step [469/735], Loss: 0.0978\n",
      "Epoch [46/50], Step [470/735], Loss: 0.0593\n",
      "Epoch [46/50], Step [471/735], Loss: 0.0326\n",
      "Epoch [46/50], Step [472/735], Loss: 0.1642\n",
      "Epoch [46/50], Step [473/735], Loss: 0.0962\n",
      "Epoch [46/50], Step [474/735], Loss: 0.0211\n",
      "Epoch [46/50], Step [475/735], Loss: 0.0715\n",
      "Epoch [46/50], Step [476/735], Loss: 0.0133\n",
      "Epoch [46/50], Step [477/735], Loss: 0.0478\n",
      "Epoch [46/50], Step [478/735], Loss: 0.0187\n",
      "Epoch [46/50], Step [479/735], Loss: 0.0435\n",
      "Epoch [46/50], Step [480/735], Loss: 0.1212\n",
      "Epoch [46/50], Step [481/735], Loss: 0.0927\n",
      "Epoch [46/50], Step [482/735], Loss: 0.0540\n",
      "Epoch [46/50], Step [483/735], Loss: 0.0834\n",
      "Epoch [46/50], Step [484/735], Loss: 0.0438\n",
      "Epoch [46/50], Step [485/735], Loss: 0.0599\n",
      "Epoch [46/50], Step [486/735], Loss: 0.0717\n",
      "Epoch [46/50], Step [487/735], Loss: 0.0407\n",
      "Epoch [46/50], Step [488/735], Loss: 0.1499\n",
      "Epoch [46/50], Step [489/735], Loss: 0.1364\n",
      "Epoch [46/50], Step [490/735], Loss: 0.0519\n",
      "Epoch [46/50], Step [491/735], Loss: 0.0698\n",
      "Epoch [46/50], Step [492/735], Loss: 0.1061\n",
      "Epoch [46/50], Step [493/735], Loss: 0.0287\n",
      "Epoch [46/50], Step [494/735], Loss: 0.0443\n",
      "Epoch [46/50], Step [495/735], Loss: 0.0561\n",
      "Epoch [46/50], Step [496/735], Loss: 0.1212\n",
      "Epoch [46/50], Step [497/735], Loss: 0.1410\n",
      "Epoch [46/50], Step [498/735], Loss: 0.0332\n",
      "Epoch [46/50], Step [499/735], Loss: 0.0265\n",
      "Epoch [46/50], Step [500/735], Loss: 0.2501\n",
      "Epoch [46/50], Step [501/735], Loss: 0.0539\n",
      "Epoch [46/50], Step [502/735], Loss: 0.0490\n",
      "Epoch [46/50], Step [503/735], Loss: 0.0497\n",
      "Epoch [46/50], Step [504/735], Loss: 0.0343\n",
      "Epoch [46/50], Step [505/735], Loss: 0.1075\n",
      "Epoch [46/50], Step [506/735], Loss: 0.1128\n",
      "Epoch [46/50], Step [507/735], Loss: 0.0484\n",
      "Epoch [46/50], Step [508/735], Loss: 0.0727\n",
      "Epoch [46/50], Step [509/735], Loss: 0.0601\n",
      "Epoch [46/50], Step [510/735], Loss: 0.0347\n",
      "Epoch [46/50], Step [511/735], Loss: 0.0754\n",
      "Epoch [46/50], Step [512/735], Loss: 0.0328\n",
      "Epoch [46/50], Step [513/735], Loss: 0.0363\n",
      "Epoch [46/50], Step [514/735], Loss: 0.0352\n",
      "Epoch [46/50], Step [515/735], Loss: 0.0466\n",
      "Epoch [46/50], Step [516/735], Loss: 0.0654\n",
      "Epoch [46/50], Step [517/735], Loss: 0.0390\n",
      "Epoch [46/50], Step [518/735], Loss: 0.0369\n",
      "Epoch [46/50], Step [519/735], Loss: 0.0367\n",
      "Epoch [46/50], Step [520/735], Loss: 0.0368\n",
      "Epoch [46/50], Step [521/735], Loss: 0.0933\n",
      "Epoch [46/50], Step [522/735], Loss: 0.0391\n",
      "Epoch [46/50], Step [523/735], Loss: 0.0427\n",
      "Epoch [46/50], Step [524/735], Loss: 0.0525\n",
      "Epoch [46/50], Step [525/735], Loss: 0.0255\n",
      "Epoch [46/50], Step [526/735], Loss: 0.0300\n",
      "Epoch [46/50], Step [527/735], Loss: 0.3984\n",
      "Epoch [46/50], Step [528/735], Loss: 0.0415\n",
      "Epoch [46/50], Step [529/735], Loss: 0.0646\n",
      "Epoch [46/50], Step [530/735], Loss: 0.0355\n",
      "Epoch [46/50], Step [531/735], Loss: 0.0447\n",
      "Epoch [46/50], Step [532/735], Loss: 0.0806\n",
      "Epoch [46/50], Step [533/735], Loss: 0.0909\n",
      "Epoch [46/50], Step [534/735], Loss: 0.0139\n",
      "Epoch [46/50], Step [535/735], Loss: 0.0704\n",
      "Epoch [46/50], Step [536/735], Loss: 0.1467\n",
      "Epoch [46/50], Step [537/735], Loss: 0.1353\n",
      "Epoch [46/50], Step [538/735], Loss: 0.0232\n",
      "Epoch [46/50], Step [539/735], Loss: 0.0821\n",
      "Epoch [46/50], Step [540/735], Loss: 0.0237\n",
      "Epoch [46/50], Step [541/735], Loss: 0.0316\n",
      "Epoch [46/50], Step [542/735], Loss: 0.1313\n",
      "Epoch [46/50], Step [543/735], Loss: 0.0323\n",
      "Epoch [46/50], Step [544/735], Loss: 0.0431\n",
      "Epoch [46/50], Step [545/735], Loss: 0.0185\n",
      "Epoch [46/50], Step [546/735], Loss: 0.0376\n",
      "Epoch [46/50], Step [547/735], Loss: 0.0654\n",
      "Epoch [46/50], Step [548/735], Loss: 0.0560\n",
      "Epoch [46/50], Step [549/735], Loss: 0.0984\n",
      "Epoch [46/50], Step [550/735], Loss: 0.0459\n",
      "Epoch [46/50], Step [551/735], Loss: 0.1166\n",
      "Epoch [46/50], Step [552/735], Loss: 0.0976\n",
      "Epoch [46/50], Step [553/735], Loss: 0.0333\n",
      "Epoch [46/50], Step [554/735], Loss: 0.0348\n",
      "Epoch [46/50], Step [555/735], Loss: 0.0380\n",
      "Epoch [46/50], Step [556/735], Loss: 0.0423\n",
      "Epoch [46/50], Step [557/735], Loss: 0.1009\n",
      "Epoch [46/50], Step [558/735], Loss: 0.1031\n",
      "Epoch [46/50], Step [559/735], Loss: 0.0423\n",
      "Epoch [46/50], Step [560/735], Loss: 0.0858\n",
      "Epoch [46/50], Step [561/735], Loss: 0.0238\n",
      "Epoch [46/50], Step [562/735], Loss: 0.0723\n",
      "Epoch [46/50], Step [563/735], Loss: 0.0925\n",
      "Epoch [46/50], Step [564/735], Loss: 0.0391\n",
      "Epoch [46/50], Step [565/735], Loss: 0.0355\n",
      "Epoch [46/50], Step [566/735], Loss: 0.0321\n",
      "Epoch [46/50], Step [567/735], Loss: 0.0617\n",
      "Epoch [46/50], Step [568/735], Loss: 0.0546\n",
      "Epoch [46/50], Step [569/735], Loss: 0.0311\n",
      "Epoch [46/50], Step [570/735], Loss: 0.0431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Step [571/735], Loss: 0.0297\n",
      "Epoch [46/50], Step [572/735], Loss: 0.0357\n",
      "Epoch [46/50], Step [573/735], Loss: 0.0467\n",
      "Epoch [46/50], Step [574/735], Loss: 0.0269\n",
      "Epoch [46/50], Step [575/735], Loss: 0.0238\n",
      "Epoch [46/50], Step [576/735], Loss: 0.0949\n",
      "Epoch [46/50], Step [577/735], Loss: 0.0509\n",
      "Epoch [46/50], Step [578/735], Loss: 0.0497\n",
      "Epoch [46/50], Step [579/735], Loss: 0.1493\n",
      "Epoch [46/50], Step [580/735], Loss: 0.0383\n",
      "Epoch [46/50], Step [581/735], Loss: 0.2922\n",
      "Epoch [46/50], Step [582/735], Loss: 0.0353\n",
      "Epoch [46/50], Step [583/735], Loss: 0.0944\n",
      "Epoch [46/50], Step [584/735], Loss: 0.0657\n",
      "Epoch [46/50], Step [585/735], Loss: 0.0782\n",
      "Epoch [46/50], Step [586/735], Loss: 0.0258\n",
      "Epoch [46/50], Step [587/735], Loss: 0.0536\n",
      "Epoch [46/50], Step [588/735], Loss: 0.0225\n",
      "Epoch [46/50], Step [589/735], Loss: 0.0383\n",
      "Epoch [46/50], Step [590/735], Loss: 0.0248\n",
      "Epoch [46/50], Step [591/735], Loss: 0.0325\n",
      "Epoch [46/50], Step [592/735], Loss: 0.0871\n",
      "Epoch [46/50], Step [593/735], Loss: 0.0615\n",
      "Epoch [46/50], Step [594/735], Loss: 0.0459\n",
      "Epoch [46/50], Step [595/735], Loss: 0.0446\n",
      "Epoch [46/50], Step [596/735], Loss: 0.1048\n",
      "Epoch [46/50], Step [597/735], Loss: 0.0617\n",
      "Epoch [46/50], Step [598/735], Loss: 0.0221\n",
      "Epoch [46/50], Step [599/735], Loss: 0.0482\n",
      "Epoch [46/50], Step [600/735], Loss: 0.0345\n",
      "Epoch [46/50], Step [601/735], Loss: 0.0478\n",
      "Epoch [46/50], Step [602/735], Loss: 0.0764\n",
      "Epoch [46/50], Step [603/735], Loss: 0.0256\n",
      "Epoch [46/50], Step [604/735], Loss: 0.0598\n",
      "Epoch [46/50], Step [605/735], Loss: 0.0692\n",
      "Epoch [46/50], Step [606/735], Loss: 0.0284\n",
      "Epoch [46/50], Step [607/735], Loss: 0.0625\n",
      "Epoch [46/50], Step [608/735], Loss: 0.0737\n",
      "Epoch [46/50], Step [609/735], Loss: 0.0449\n",
      "Epoch [46/50], Step [610/735], Loss: 0.1177\n",
      "Epoch [46/50], Step [611/735], Loss: 0.0388\n",
      "Epoch [46/50], Step [612/735], Loss: 0.0628\n",
      "Epoch [46/50], Step [613/735], Loss: 0.1260\n",
      "Epoch [46/50], Step [614/735], Loss: 0.0574\n",
      "Epoch [46/50], Step [615/735], Loss: 0.0401\n",
      "Epoch [46/50], Step [616/735], Loss: 0.0644\n",
      "Epoch [46/50], Step [617/735], Loss: 0.0359\n",
      "Epoch [46/50], Step [618/735], Loss: 0.0158\n",
      "Epoch [46/50], Step [619/735], Loss: 0.0622\n",
      "Epoch [46/50], Step [620/735], Loss: 0.0306\n",
      "Epoch [46/50], Step [621/735], Loss: 0.0315\n",
      "Epoch [46/50], Step [622/735], Loss: 0.0569\n",
      "Epoch [46/50], Step [623/735], Loss: 0.0349\n",
      "Epoch [46/50], Step [624/735], Loss: 0.0258\n",
      "Epoch [46/50], Step [625/735], Loss: 0.0253\n",
      "Epoch [46/50], Step [626/735], Loss: 0.0407\n",
      "Epoch [46/50], Step [627/735], Loss: 0.0621\n",
      "Epoch [46/50], Step [628/735], Loss: 0.0722\n",
      "Epoch [46/50], Step [629/735], Loss: 0.0303\n",
      "Epoch [46/50], Step [630/735], Loss: 0.0402\n",
      "Epoch [46/50], Step [631/735], Loss: 0.1081\n",
      "Epoch [46/50], Step [632/735], Loss: 0.0579\n",
      "Epoch [46/50], Step [633/735], Loss: 0.1252\n",
      "Epoch [46/50], Step [634/735], Loss: 0.0407\n",
      "Epoch [46/50], Step [635/735], Loss: 0.3262\n",
      "Epoch [46/50], Step [636/735], Loss: 0.0886\n",
      "Epoch [46/50], Step [637/735], Loss: 0.0760\n",
      "Epoch [46/50], Step [638/735], Loss: 0.1404\n",
      "Epoch [46/50], Step [639/735], Loss: 0.0426\n",
      "Epoch [46/50], Step [640/735], Loss: 0.0715\n",
      "Epoch [46/50], Step [641/735], Loss: 0.0408\n",
      "Epoch [46/50], Step [642/735], Loss: 0.0592\n",
      "Epoch [46/50], Step [643/735], Loss: 0.0433\n",
      "Epoch [46/50], Step [644/735], Loss: 0.0459\n",
      "Epoch [46/50], Step [645/735], Loss: 0.0619\n",
      "Epoch [46/50], Step [646/735], Loss: 0.0350\n",
      "Epoch [46/50], Step [647/735], Loss: 0.1014\n",
      "Epoch [46/50], Step [648/735], Loss: 0.0480\n",
      "Epoch [46/50], Step [649/735], Loss: 0.0347\n",
      "Epoch [46/50], Step [650/735], Loss: 0.0213\n",
      "Epoch [46/50], Step [651/735], Loss: 0.0610\n",
      "Epoch [46/50], Step [652/735], Loss: 0.0973\n",
      "Epoch [46/50], Step [653/735], Loss: 0.0954\n",
      "Epoch [46/50], Step [654/735], Loss: 0.0383\n",
      "Epoch [46/50], Step [655/735], Loss: 0.0756\n",
      "Epoch [46/50], Step [656/735], Loss: 0.0451\n",
      "Epoch [46/50], Step [657/735], Loss: 0.2183\n",
      "Epoch [46/50], Step [658/735], Loss: 0.0370\n",
      "Epoch [46/50], Step [659/735], Loss: 0.0352\n",
      "Epoch [46/50], Step [660/735], Loss: 0.1536\n",
      "Epoch [46/50], Step [661/735], Loss: 0.0453\n",
      "Epoch [46/50], Step [662/735], Loss: 0.0290\n",
      "Epoch [46/50], Step [663/735], Loss: 0.0123\n",
      "Epoch [46/50], Step [664/735], Loss: 0.0416\n",
      "Epoch [46/50], Step [665/735], Loss: 0.0638\n",
      "Epoch [46/50], Step [666/735], Loss: 0.0308\n",
      "Epoch [46/50], Step [667/735], Loss: 0.0229\n",
      "Epoch [46/50], Step [668/735], Loss: 0.0452\n",
      "Epoch [46/50], Step [669/735], Loss: 0.0325\n",
      "Epoch [46/50], Step [670/735], Loss: 0.0138\n",
      "Epoch [46/50], Step [671/735], Loss: 0.0134\n",
      "Epoch [46/50], Step [672/735], Loss: 0.0117\n",
      "Epoch [46/50], Step [673/735], Loss: 0.0483\n",
      "Epoch [46/50], Step [674/735], Loss: 0.0342\n",
      "Epoch [46/50], Step [675/735], Loss: 0.0374\n",
      "Epoch [46/50], Step [676/735], Loss: 0.1683\n",
      "Epoch [46/50], Step [677/735], Loss: 0.1464\n",
      "Epoch [46/50], Step [678/735], Loss: 0.0439\n",
      "Epoch [46/50], Step [679/735], Loss: 0.0294\n",
      "Epoch [46/50], Step [680/735], Loss: 0.0605\n",
      "Epoch [46/50], Step [681/735], Loss: 0.0199\n",
      "Epoch [46/50], Step [682/735], Loss: 0.0664\n",
      "Epoch [46/50], Step [683/735], Loss: 0.0397\n",
      "Epoch [46/50], Step [684/735], Loss: 0.0232\n",
      "Epoch [46/50], Step [685/735], Loss: 0.0201\n",
      "Epoch [46/50], Step [686/735], Loss: 0.0302\n",
      "Epoch [46/50], Step [687/735], Loss: 0.0419\n",
      "Epoch [46/50], Step [688/735], Loss: 0.0390\n",
      "Epoch [46/50], Step [689/735], Loss: 0.0335\n",
      "Epoch [46/50], Step [690/735], Loss: 0.0352\n",
      "Epoch [46/50], Step [691/735], Loss: 0.0330\n",
      "Epoch [46/50], Step [692/735], Loss: 0.0349\n",
      "Epoch [46/50], Step [693/735], Loss: 0.1098\n",
      "Epoch [46/50], Step [694/735], Loss: 0.0309\n",
      "Epoch [46/50], Step [695/735], Loss: 0.0382\n",
      "Epoch [46/50], Step [696/735], Loss: 0.0281\n",
      "Epoch [46/50], Step [697/735], Loss: 0.0679\n",
      "Epoch [46/50], Step [698/735], Loss: 0.0447\n",
      "Epoch [46/50], Step [699/735], Loss: 0.1612\n",
      "Epoch [46/50], Step [700/735], Loss: 0.0784\n",
      "Epoch [46/50], Step [701/735], Loss: 0.0265\n",
      "Epoch [46/50], Step [702/735], Loss: 0.0492\n",
      "Epoch [46/50], Step [703/735], Loss: 0.0139\n",
      "Epoch [46/50], Step [704/735], Loss: 0.0542\n",
      "Epoch [46/50], Step [705/735], Loss: 0.0986\n",
      "Epoch [46/50], Step [706/735], Loss: 0.0589\n",
      "Epoch [46/50], Step [707/735], Loss: 0.0337\n",
      "Epoch [46/50], Step [708/735], Loss: 0.0496\n",
      "Epoch [46/50], Step [709/735], Loss: 0.0462\n",
      "Epoch [46/50], Step [710/735], Loss: 0.0374\n",
      "Epoch [46/50], Step [711/735], Loss: 0.0396\n",
      "Epoch [46/50], Step [712/735], Loss: 0.0567\n",
      "Epoch [46/50], Step [713/735], Loss: 0.1033\n",
      "Epoch [46/50], Step [714/735], Loss: 0.0320\n",
      "Epoch [46/50], Step [715/735], Loss: 0.1240\n",
      "Epoch [46/50], Step [716/735], Loss: 0.0504\n",
      "Epoch [46/50], Step [717/735], Loss: 0.0303\n",
      "Epoch [46/50], Step [718/735], Loss: 0.0358\n",
      "Epoch [46/50], Step [719/735], Loss: 0.0575\n",
      "Epoch [46/50], Step [720/735], Loss: 0.0402\n",
      "Epoch [46/50], Step [721/735], Loss: 0.0329\n",
      "Epoch [46/50], Step [722/735], Loss: 0.0195\n",
      "Epoch [46/50], Step [723/735], Loss: 0.1820\n",
      "Epoch [46/50], Step [724/735], Loss: 0.0291\n",
      "Epoch [46/50], Step [725/735], Loss: 0.0204\n",
      "Epoch [46/50], Step [726/735], Loss: 0.1064\n",
      "Epoch [46/50], Step [727/735], Loss: 0.0907\n",
      "Epoch [46/50], Step [728/735], Loss: 0.0528\n",
      "Epoch [46/50], Step [729/735], Loss: 0.0344\n",
      "Epoch [46/50], Step [730/735], Loss: 0.0252\n",
      "Epoch [46/50], Step [731/735], Loss: 0.1261\n",
      "Epoch [46/50], Step [732/735], Loss: 0.0470\n",
      "Epoch [46/50], Step [733/735], Loss: 0.0483\n",
      "Epoch [46/50], Step [734/735], Loss: 0.0318\n",
      "Epoch [46/50], Step [735/735], Loss: 0.0219\n",
      "Epoch [47/50], Step [1/735], Loss: 0.0503\n",
      "Epoch [47/50], Step [2/735], Loss: 0.2796\n",
      "Epoch [47/50], Step [3/735], Loss: 0.0352\n",
      "Epoch [47/50], Step [4/735], Loss: 0.0330\n",
      "Epoch [47/50], Step [5/735], Loss: 0.0269\n",
      "Epoch [47/50], Step [6/735], Loss: 0.0745\n",
      "Epoch [47/50], Step [7/735], Loss: 0.0341\n",
      "Epoch [47/50], Step [8/735], Loss: 0.0618\n",
      "Epoch [47/50], Step [9/735], Loss: 0.0501\n",
      "Epoch [47/50], Step [10/735], Loss: 0.0518\n",
      "Epoch [47/50], Step [11/735], Loss: 0.0453\n",
      "Epoch [47/50], Step [12/735], Loss: 0.0483\n",
      "Epoch [47/50], Step [13/735], Loss: 0.0222\n",
      "Epoch [47/50], Step [14/735], Loss: 0.0318\n",
      "Epoch [47/50], Step [15/735], Loss: 0.0341\n",
      "Epoch [47/50], Step [16/735], Loss: 0.1063\n",
      "Epoch [47/50], Step [17/735], Loss: 0.0356\n",
      "Epoch [47/50], Step [18/735], Loss: 0.0242\n",
      "Epoch [47/50], Step [19/735], Loss: 0.0379\n",
      "Epoch [47/50], Step [20/735], Loss: 0.1087\n",
      "Epoch [47/50], Step [21/735], Loss: 0.1178\n",
      "Epoch [47/50], Step [22/735], Loss: 0.0267\n",
      "Epoch [47/50], Step [23/735], Loss: 0.0237\n",
      "Epoch [47/50], Step [24/735], Loss: 0.0775\n",
      "Epoch [47/50], Step [25/735], Loss: 0.0457\n",
      "Epoch [47/50], Step [26/735], Loss: 0.0237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Step [27/735], Loss: 0.1271\n",
      "Epoch [47/50], Step [28/735], Loss: 0.0385\n",
      "Epoch [47/50], Step [29/735], Loss: 0.0793\n",
      "Epoch [47/50], Step [30/735], Loss: 0.0611\n",
      "Epoch [47/50], Step [31/735], Loss: 0.0244\n",
      "Epoch [47/50], Step [32/735], Loss: 0.1247\n",
      "Epoch [47/50], Step [33/735], Loss: 0.0473\n",
      "Epoch [47/50], Step [34/735], Loss: 0.0305\n",
      "Epoch [47/50], Step [35/735], Loss: 0.0565\n",
      "Epoch [47/50], Step [36/735], Loss: 0.0357\n",
      "Epoch [47/50], Step [37/735], Loss: 0.0996\n",
      "Epoch [47/50], Step [38/735], Loss: 0.0763\n",
      "Epoch [47/50], Step [39/735], Loss: 0.2176\n",
      "Epoch [47/50], Step [40/735], Loss: 0.0386\n",
      "Epoch [47/50], Step [41/735], Loss: 0.1403\n",
      "Epoch [47/50], Step [42/735], Loss: 0.0819\n",
      "Epoch [47/50], Step [43/735], Loss: 0.1594\n",
      "Epoch [47/50], Step [44/735], Loss: 0.0327\n",
      "Epoch [47/50], Step [45/735], Loss: 0.1378\n",
      "Epoch [47/50], Step [46/735], Loss: 0.0597\n",
      "Epoch [47/50], Step [47/735], Loss: 0.0763\n",
      "Epoch [47/50], Step [48/735], Loss: 0.0554\n",
      "Epoch [47/50], Step [49/735], Loss: 0.0891\n",
      "Epoch [47/50], Step [50/735], Loss: 0.0501\n",
      "Epoch [47/50], Step [51/735], Loss: 0.0595\n",
      "Epoch [47/50], Step [52/735], Loss: 0.1120\n",
      "Epoch [47/50], Step [53/735], Loss: 0.0348\n",
      "Epoch [47/50], Step [54/735], Loss: 0.0366\n",
      "Epoch [47/50], Step [55/735], Loss: 0.0593\n",
      "Epoch [47/50], Step [56/735], Loss: 0.0583\n",
      "Epoch [47/50], Step [57/735], Loss: 0.0265\n",
      "Epoch [47/50], Step [58/735], Loss: 0.0475\n",
      "Epoch [47/50], Step [59/735], Loss: 0.0430\n",
      "Epoch [47/50], Step [60/735], Loss: 0.1444\n",
      "Epoch [47/50], Step [61/735], Loss: 0.0492\n",
      "Epoch [47/50], Step [62/735], Loss: 0.0425\n",
      "Epoch [47/50], Step [63/735], Loss: 0.0802\n",
      "Epoch [47/50], Step [64/735], Loss: 0.0749\n",
      "Epoch [47/50], Step [65/735], Loss: 0.0284\n",
      "Epoch [47/50], Step [66/735], Loss: 0.0261\n",
      "Epoch [47/50], Step [67/735], Loss: 0.0683\n",
      "Epoch [47/50], Step [68/735], Loss: 0.0397\n",
      "Epoch [47/50], Step [69/735], Loss: 0.0199\n",
      "Epoch [47/50], Step [70/735], Loss: 0.0768\n",
      "Epoch [47/50], Step [71/735], Loss: 0.0578\n",
      "Epoch [47/50], Step [72/735], Loss: 0.0586\n",
      "Epoch [47/50], Step [73/735], Loss: 0.0487\n",
      "Epoch [47/50], Step [74/735], Loss: 0.0578\n",
      "Epoch [47/50], Step [75/735], Loss: 0.0253\n",
      "Epoch [47/50], Step [76/735], Loss: 0.0673\n",
      "Epoch [47/50], Step [77/735], Loss: 0.0680\n",
      "Epoch [47/50], Step [78/735], Loss: 0.0577\n",
      "Epoch [47/50], Step [79/735], Loss: 0.0665\n",
      "Epoch [47/50], Step [80/735], Loss: 0.0355\n",
      "Epoch [47/50], Step [81/735], Loss: 0.0285\n",
      "Epoch [47/50], Step [82/735], Loss: 0.0299\n",
      "Epoch [47/50], Step [83/735], Loss: 0.0283\n",
      "Epoch [47/50], Step [84/735], Loss: 0.0256\n",
      "Epoch [47/50], Step [85/735], Loss: 0.0505\n",
      "Epoch [47/50], Step [86/735], Loss: 0.0406\n",
      "Epoch [47/50], Step [87/735], Loss: 0.0430\n",
      "Epoch [47/50], Step [88/735], Loss: 0.0313\n",
      "Epoch [47/50], Step [89/735], Loss: 0.0150\n",
      "Epoch [47/50], Step [90/735], Loss: 0.1977\n",
      "Epoch [47/50], Step [91/735], Loss: 0.2315\n",
      "Epoch [47/50], Step [92/735], Loss: 0.0308\n",
      "Epoch [47/50], Step [93/735], Loss: 0.0383\n",
      "Epoch [47/50], Step [94/735], Loss: 0.0540\n",
      "Epoch [47/50], Step [95/735], Loss: 0.0665\n",
      "Epoch [47/50], Step [96/735], Loss: 0.0428\n",
      "Epoch [47/50], Step [97/735], Loss: 0.0573\n",
      "Epoch [47/50], Step [98/735], Loss: 0.0328\n",
      "Epoch [47/50], Step [99/735], Loss: 0.0360\n",
      "Epoch [47/50], Step [100/735], Loss: 0.0502\n",
      "Epoch [47/50], Step [101/735], Loss: 0.0599\n",
      "Epoch [47/50], Step [102/735], Loss: 0.0273\n",
      "Epoch [47/50], Step [103/735], Loss: 0.0370\n",
      "Epoch [47/50], Step [104/735], Loss: 0.0109\n",
      "Epoch [47/50], Step [105/735], Loss: 0.0723\n",
      "Epoch [47/50], Step [106/735], Loss: 0.0739\n",
      "Epoch [47/50], Step [107/735], Loss: 0.0885\n",
      "Epoch [47/50], Step [108/735], Loss: 0.0654\n",
      "Epoch [47/50], Step [109/735], Loss: 0.0522\n",
      "Epoch [47/50], Step [110/735], Loss: 0.0498\n",
      "Epoch [47/50], Step [111/735], Loss: 0.0625\n",
      "Epoch [47/50], Step [112/735], Loss: 0.0287\n",
      "Epoch [47/50], Step [113/735], Loss: 0.0435\n",
      "Epoch [47/50], Step [114/735], Loss: 0.0471\n",
      "Epoch [47/50], Step [115/735], Loss: 0.0573\n",
      "Epoch [47/50], Step [116/735], Loss: 0.0400\n",
      "Epoch [47/50], Step [117/735], Loss: 0.0571\n",
      "Epoch [47/50], Step [118/735], Loss: 0.0282\n",
      "Epoch [47/50], Step [119/735], Loss: 0.0299\n",
      "Epoch [47/50], Step [120/735], Loss: 0.0499\n",
      "Epoch [47/50], Step [121/735], Loss: 0.0452\n",
      "Epoch [47/50], Step [122/735], Loss: 0.0596\n",
      "Epoch [47/50], Step [123/735], Loss: 0.0278\n",
      "Epoch [47/50], Step [124/735], Loss: 0.0215\n",
      "Epoch [47/50], Step [125/735], Loss: 0.0524\n",
      "Epoch [47/50], Step [126/735], Loss: 0.0261\n",
      "Epoch [47/50], Step [127/735], Loss: 0.0184\n",
      "Epoch [47/50], Step [128/735], Loss: 0.0137\n",
      "Epoch [47/50], Step [129/735], Loss: 0.0844\n",
      "Epoch [47/50], Step [130/735], Loss: 0.0282\n",
      "Epoch [47/50], Step [131/735], Loss: 0.0243\n",
      "Epoch [47/50], Step [132/735], Loss: 0.0331\n",
      "Epoch [47/50], Step [133/735], Loss: 0.0650\n",
      "Epoch [47/50], Step [134/735], Loss: 0.0342\n",
      "Epoch [47/50], Step [135/735], Loss: 0.0381\n",
      "Epoch [47/50], Step [136/735], Loss: 0.1059\n",
      "Epoch [47/50], Step [137/735], Loss: 0.0995\n",
      "Epoch [47/50], Step [138/735], Loss: 0.0755\n",
      "Epoch [47/50], Step [139/735], Loss: 0.0179\n",
      "Epoch [47/50], Step [140/735], Loss: 0.0582\n",
      "Epoch [47/50], Step [141/735], Loss: 0.0437\n",
      "Epoch [47/50], Step [142/735], Loss: 0.0459\n",
      "Epoch [47/50], Step [143/735], Loss: 0.1284\n",
      "Epoch [47/50], Step [144/735], Loss: 0.0712\n",
      "Epoch [47/50], Step [145/735], Loss: 0.1033\n",
      "Epoch [47/50], Step [146/735], Loss: 0.0303\n",
      "Epoch [47/50], Step [147/735], Loss: 0.1015\n",
      "Epoch [47/50], Step [148/735], Loss: 0.0310\n",
      "Epoch [47/50], Step [149/735], Loss: 0.0439\n",
      "Epoch [47/50], Step [150/735], Loss: 0.0848\n",
      "Epoch [47/50], Step [151/735], Loss: 0.0356\n",
      "Epoch [47/50], Step [152/735], Loss: 0.0864\n",
      "Epoch [47/50], Step [153/735], Loss: 0.1582\n",
      "Epoch [47/50], Step [154/735], Loss: 0.0452\n",
      "Epoch [47/50], Step [155/735], Loss: 0.0246\n",
      "Epoch [47/50], Step [156/735], Loss: 0.0268\n",
      "Epoch [47/50], Step [157/735], Loss: 0.0890\n",
      "Epoch [47/50], Step [158/735], Loss: 0.0388\n",
      "Epoch [47/50], Step [159/735], Loss: 0.0749\n",
      "Epoch [47/50], Step [160/735], Loss: 0.0997\n",
      "Epoch [47/50], Step [161/735], Loss: 0.0787\n",
      "Epoch [47/50], Step [162/735], Loss: 0.1512\n",
      "Epoch [47/50], Step [163/735], Loss: 0.0483\n",
      "Epoch [47/50], Step [164/735], Loss: 0.0712\n",
      "Epoch [47/50], Step [165/735], Loss: 0.0746\n",
      "Epoch [47/50], Step [166/735], Loss: 0.0631\n",
      "Epoch [47/50], Step [167/735], Loss: 0.0305\n",
      "Epoch [47/50], Step [168/735], Loss: 0.1164\n",
      "Epoch [47/50], Step [169/735], Loss: 0.0407\n",
      "Epoch [47/50], Step [170/735], Loss: 0.1460\n",
      "Epoch [47/50], Step [171/735], Loss: 0.0414\n",
      "Epoch [47/50], Step [172/735], Loss: 0.0471\n",
      "Epoch [47/50], Step [173/735], Loss: 0.0728\n",
      "Epoch [47/50], Step [174/735], Loss: 0.0353\n",
      "Epoch [47/50], Step [175/735], Loss: 0.0629\n",
      "Epoch [47/50], Step [176/735], Loss: 0.0659\n",
      "Epoch [47/50], Step [177/735], Loss: 0.0233\n",
      "Epoch [47/50], Step [178/735], Loss: 0.0232\n",
      "Epoch [47/50], Step [179/735], Loss: 0.0209\n",
      "Epoch [47/50], Step [180/735], Loss: 0.1428\n",
      "Epoch [47/50], Step [181/735], Loss: 0.0199\n",
      "Epoch [47/50], Step [182/735], Loss: 0.0951\n",
      "Epoch [47/50], Step [183/735], Loss: 0.0314\n",
      "Epoch [47/50], Step [184/735], Loss: 0.0226\n",
      "Epoch [47/50], Step [185/735], Loss: 0.0527\n",
      "Epoch [47/50], Step [186/735], Loss: 0.0458\n",
      "Epoch [47/50], Step [187/735], Loss: 0.0382\n",
      "Epoch [47/50], Step [188/735], Loss: 0.0213\n",
      "Epoch [47/50], Step [189/735], Loss: 0.0826\n",
      "Epoch [47/50], Step [190/735], Loss: 0.1009\n",
      "Epoch [47/50], Step [191/735], Loss: 0.0572\n",
      "Epoch [47/50], Step [192/735], Loss: 0.0693\n",
      "Epoch [47/50], Step [193/735], Loss: 0.1081\n",
      "Epoch [47/50], Step [194/735], Loss: 0.0348\n",
      "Epoch [47/50], Step [195/735], Loss: 0.0620\n",
      "Epoch [47/50], Step [196/735], Loss: 0.0151\n",
      "Epoch [47/50], Step [197/735], Loss: 0.0503\n",
      "Epoch [47/50], Step [198/735], Loss: 0.0334\n",
      "Epoch [47/50], Step [199/735], Loss: 0.0556\n",
      "Epoch [47/50], Step [200/735], Loss: 0.0203\n",
      "Epoch [47/50], Step [201/735], Loss: 0.0484\n",
      "Epoch [47/50], Step [202/735], Loss: 0.0438\n",
      "Epoch [47/50], Step [203/735], Loss: 0.0492\n",
      "Epoch [47/50], Step [204/735], Loss: 0.0609\n",
      "Epoch [47/50], Step [205/735], Loss: 0.0596\n",
      "Epoch [47/50], Step [206/735], Loss: 0.0374\n",
      "Epoch [47/50], Step [207/735], Loss: 0.0238\n",
      "Epoch [47/50], Step [208/735], Loss: 0.0237\n",
      "Epoch [47/50], Step [209/735], Loss: 0.0539\n",
      "Epoch [47/50], Step [210/735], Loss: 0.0194\n",
      "Epoch [47/50], Step [211/735], Loss: 0.0487\n",
      "Epoch [47/50], Step [212/735], Loss: 0.0439\n",
      "Epoch [47/50], Step [213/735], Loss: 0.0374\n",
      "Epoch [47/50], Step [214/735], Loss: 0.0579\n",
      "Epoch [47/50], Step [215/735], Loss: 0.0297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Step [216/735], Loss: 0.0535\n",
      "Epoch [47/50], Step [217/735], Loss: 0.0617\n",
      "Epoch [47/50], Step [218/735], Loss: 0.0270\n",
      "Epoch [47/50], Step [219/735], Loss: 0.0133\n",
      "Epoch [47/50], Step [220/735], Loss: 0.0250\n",
      "Epoch [47/50], Step [221/735], Loss: 0.0284\n",
      "Epoch [47/50], Step [222/735], Loss: 0.0518\n",
      "Epoch [47/50], Step [223/735], Loss: 0.0211\n",
      "Epoch [47/50], Step [224/735], Loss: 0.0437\n",
      "Epoch [47/50], Step [225/735], Loss: 0.0197\n",
      "Epoch [47/50], Step [226/735], Loss: 0.0527\n",
      "Epoch [47/50], Step [227/735], Loss: 0.0614\n",
      "Epoch [47/50], Step [228/735], Loss: 0.0454\n",
      "Epoch [47/50], Step [229/735], Loss: 0.0650\n",
      "Epoch [47/50], Step [230/735], Loss: 0.1042\n",
      "Epoch [47/50], Step [231/735], Loss: 0.2853\n",
      "Epoch [47/50], Step [232/735], Loss: 0.0597\n",
      "Epoch [47/50], Step [233/735], Loss: 0.0542\n",
      "Epoch [47/50], Step [234/735], Loss: 0.0895\n",
      "Epoch [47/50], Step [235/735], Loss: 0.1550\n",
      "Epoch [47/50], Step [236/735], Loss: 0.2800\n",
      "Epoch [47/50], Step [237/735], Loss: 0.0440\n",
      "Epoch [47/50], Step [238/735], Loss: 0.0291\n",
      "Epoch [47/50], Step [239/735], Loss: 0.0437\n",
      "Epoch [47/50], Step [240/735], Loss: 0.0327\n",
      "Epoch [47/50], Step [241/735], Loss: 0.0661\n",
      "Epoch [47/50], Step [242/735], Loss: 0.0235\n",
      "Epoch [47/50], Step [243/735], Loss: 0.0582\n",
      "Epoch [47/50], Step [244/735], Loss: 0.0952\n",
      "Epoch [47/50], Step [245/735], Loss: 0.0241\n",
      "Epoch [47/50], Step [246/735], Loss: 0.0308\n",
      "Epoch [47/50], Step [247/735], Loss: 0.0221\n",
      "Epoch [47/50], Step [248/735], Loss: 0.0243\n",
      "Epoch [47/50], Step [249/735], Loss: 0.0264\n",
      "Epoch [47/50], Step [250/735], Loss: 0.0301\n",
      "Epoch [47/50], Step [251/735], Loss: 0.0890\n",
      "Epoch [47/50], Step [252/735], Loss: 0.0218\n",
      "Epoch [47/50], Step [253/735], Loss: 0.0673\n",
      "Epoch [47/50], Step [254/735], Loss: 0.0622\n",
      "Epoch [47/50], Step [255/735], Loss: 0.0410\n",
      "Epoch [47/50], Step [256/735], Loss: 0.0225\n",
      "Epoch [47/50], Step [257/735], Loss: 0.0438\n",
      "Epoch [47/50], Step [258/735], Loss: 0.1791\n",
      "Epoch [47/50], Step [259/735], Loss: 0.0242\n",
      "Epoch [47/50], Step [260/735], Loss: 0.0352\n",
      "Epoch [47/50], Step [261/735], Loss: 0.0425\n",
      "Epoch [47/50], Step [262/735], Loss: 0.0333\n",
      "Epoch [47/50], Step [263/735], Loss: 0.1294\n",
      "Epoch [47/50], Step [264/735], Loss: 0.0668\n",
      "Epoch [47/50], Step [265/735], Loss: 0.0737\n",
      "Epoch [47/50], Step [266/735], Loss: 0.0347\n",
      "Epoch [47/50], Step [267/735], Loss: 0.0904\n",
      "Epoch [47/50], Step [268/735], Loss: 0.0336\n",
      "Epoch [47/50], Step [269/735], Loss: 0.0429\n",
      "Epoch [47/50], Step [270/735], Loss: 0.0520\n",
      "Epoch [47/50], Step [271/735], Loss: 0.0356\n",
      "Epoch [47/50], Step [272/735], Loss: 0.0787\n",
      "Epoch [47/50], Step [273/735], Loss: 0.0354\n",
      "Epoch [47/50], Step [274/735], Loss: 0.0152\n",
      "Epoch [47/50], Step [275/735], Loss: 0.0174\n",
      "Epoch [47/50], Step [276/735], Loss: 0.0559\n",
      "Epoch [47/50], Step [277/735], Loss: 0.1499\n",
      "Epoch [47/50], Step [278/735], Loss: 0.1608\n",
      "Epoch [47/50], Step [279/735], Loss: 0.0341\n",
      "Epoch [47/50], Step [280/735], Loss: 0.0333\n",
      "Epoch [47/50], Step [281/735], Loss: 0.1273\n",
      "Epoch [47/50], Step [282/735], Loss: 0.0331\n",
      "Epoch [47/50], Step [283/735], Loss: 0.0305\n",
      "Epoch [47/50], Step [284/735], Loss: 0.0408\n",
      "Epoch [47/50], Step [285/735], Loss: 0.1338\n",
      "Epoch [47/50], Step [286/735], Loss: 0.0666\n",
      "Epoch [47/50], Step [287/735], Loss: 0.0843\n",
      "Epoch [47/50], Step [288/735], Loss: 0.0441\n",
      "Epoch [47/50], Step [289/735], Loss: 0.0880\n",
      "Epoch [47/50], Step [290/735], Loss: 0.1236\n",
      "Epoch [47/50], Step [291/735], Loss: 0.0392\n",
      "Epoch [47/50], Step [292/735], Loss: 0.0651\n",
      "Epoch [47/50], Step [293/735], Loss: 0.0593\n",
      "Epoch [47/50], Step [294/735], Loss: 0.0666\n",
      "Epoch [47/50], Step [295/735], Loss: 0.0459\n",
      "Epoch [47/50], Step [296/735], Loss: 0.0379\n",
      "Epoch [47/50], Step [297/735], Loss: 0.1532\n",
      "Epoch [47/50], Step [298/735], Loss: 0.0482\n",
      "Epoch [47/50], Step [299/735], Loss: 0.1827\n",
      "Epoch [47/50], Step [300/735], Loss: 0.0412\n",
      "Epoch [47/50], Step [301/735], Loss: 0.0351\n",
      "Epoch [47/50], Step [302/735], Loss: 0.0559\n",
      "Epoch [47/50], Step [303/735], Loss: 0.0716\n",
      "Epoch [47/50], Step [304/735], Loss: 0.0267\n",
      "Epoch [47/50], Step [305/735], Loss: 0.0434\n",
      "Epoch [47/50], Step [306/735], Loss: 0.0353\n",
      "Epoch [47/50], Step [307/735], Loss: 0.0247\n",
      "Epoch [47/50], Step [308/735], Loss: 0.0361\n",
      "Epoch [47/50], Step [309/735], Loss: 0.0546\n",
      "Epoch [47/50], Step [310/735], Loss: 0.0724\n",
      "Epoch [47/50], Step [311/735], Loss: 0.0213\n",
      "Epoch [47/50], Step [312/735], Loss: 0.1491\n",
      "Epoch [47/50], Step [313/735], Loss: 0.1985\n",
      "Epoch [47/50], Step [314/735], Loss: 0.0479\n",
      "Epoch [47/50], Step [315/735], Loss: 0.0367\n",
      "Epoch [47/50], Step [316/735], Loss: 0.0341\n",
      "Epoch [47/50], Step [317/735], Loss: 0.0338\n",
      "Epoch [47/50], Step [318/735], Loss: 0.0849\n",
      "Epoch [47/50], Step [319/735], Loss: 0.0911\n",
      "Epoch [47/50], Step [320/735], Loss: 0.0509\n",
      "Epoch [47/50], Step [321/735], Loss: 0.0418\n",
      "Epoch [47/50], Step [322/735], Loss: 0.0695\n",
      "Epoch [47/50], Step [323/735], Loss: 0.0507\n",
      "Epoch [47/50], Step [324/735], Loss: 0.0448\n",
      "Epoch [47/50], Step [325/735], Loss: 0.0842\n",
      "Epoch [47/50], Step [326/735], Loss: 0.0484\n",
      "Epoch [47/50], Step [327/735], Loss: 0.0548\n",
      "Epoch [47/50], Step [328/735], Loss: 0.0329\n",
      "Epoch [47/50], Step [329/735], Loss: 0.0333\n",
      "Epoch [47/50], Step [330/735], Loss: 0.0159\n",
      "Epoch [47/50], Step [331/735], Loss: 0.0391\n",
      "Epoch [47/50], Step [332/735], Loss: 0.0322\n",
      "Epoch [47/50], Step [333/735], Loss: 0.0744\n",
      "Epoch [47/50], Step [334/735], Loss: 0.0533\n",
      "Epoch [47/50], Step [335/735], Loss: 0.1072\n",
      "Epoch [47/50], Step [336/735], Loss: 0.0773\n",
      "Epoch [47/50], Step [337/735], Loss: 0.0669\n",
      "Epoch [47/50], Step [338/735], Loss: 0.0271\n",
      "Epoch [47/50], Step [339/735], Loss: 0.0282\n",
      "Epoch [47/50], Step [340/735], Loss: 0.0388\n",
      "Epoch [47/50], Step [341/735], Loss: 0.0290\n",
      "Epoch [47/50], Step [342/735], Loss: 0.1060\n",
      "Epoch [47/50], Step [343/735], Loss: 0.1288\n",
      "Epoch [47/50], Step [344/735], Loss: 0.0352\n",
      "Epoch [47/50], Step [345/735], Loss: 0.0546\n",
      "Epoch [47/50], Step [346/735], Loss: 0.0500\n",
      "Epoch [47/50], Step [347/735], Loss: 0.1047\n",
      "Epoch [47/50], Step [348/735], Loss: 0.0784\n",
      "Epoch [47/50], Step [349/735], Loss: 0.0235\n",
      "Epoch [47/50], Step [350/735], Loss: 0.0526\n",
      "Epoch [47/50], Step [351/735], Loss: 0.0446\n",
      "Epoch [47/50], Step [352/735], Loss: 0.0656\n",
      "Epoch [47/50], Step [353/735], Loss: 0.0473\n",
      "Epoch [47/50], Step [354/735], Loss: 0.0439\n",
      "Epoch [47/50], Step [355/735], Loss: 0.0427\n",
      "Epoch [47/50], Step [356/735], Loss: 0.0484\n",
      "Epoch [47/50], Step [357/735], Loss: 0.0467\n",
      "Epoch [47/50], Step [358/735], Loss: 0.0264\n",
      "Epoch [47/50], Step [359/735], Loss: 0.0441\n",
      "Epoch [47/50], Step [360/735], Loss: 0.0322\n",
      "Epoch [47/50], Step [361/735], Loss: 0.0411\n",
      "Epoch [47/50], Step [362/735], Loss: 0.0395\n",
      "Epoch [47/50], Step [363/735], Loss: 0.0272\n",
      "Epoch [47/50], Step [364/735], Loss: 0.0257\n",
      "Epoch [47/50], Step [365/735], Loss: 0.0241\n",
      "Epoch [47/50], Step [366/735], Loss: 0.0652\n",
      "Epoch [47/50], Step [367/735], Loss: 0.0307\n",
      "Epoch [47/50], Step [368/735], Loss: 0.0431\n",
      "Epoch [47/50], Step [369/735], Loss: 0.0576\n",
      "Epoch [47/50], Step [370/735], Loss: 0.0438\n",
      "Epoch [47/50], Step [371/735], Loss: 0.0578\n",
      "Epoch [47/50], Step [372/735], Loss: 0.0663\n",
      "Epoch [47/50], Step [373/735], Loss: 0.0460\n",
      "Epoch [47/50], Step [374/735], Loss: 0.0384\n",
      "Epoch [47/50], Step [375/735], Loss: 0.0590\n",
      "Epoch [47/50], Step [376/735], Loss: 0.2088\n",
      "Epoch [47/50], Step [377/735], Loss: 0.0292\n",
      "Epoch [47/50], Step [378/735], Loss: 0.0286\n",
      "Epoch [47/50], Step [379/735], Loss: 0.0605\n",
      "Epoch [47/50], Step [380/735], Loss: 0.0741\n",
      "Epoch [47/50], Step [381/735], Loss: 0.0364\n",
      "Epoch [47/50], Step [382/735], Loss: 0.0805\n",
      "Epoch [47/50], Step [383/735], Loss: 0.0569\n",
      "Epoch [47/50], Step [384/735], Loss: 0.1400\n",
      "Epoch [47/50], Step [385/735], Loss: 0.0747\n",
      "Epoch [47/50], Step [386/735], Loss: 0.0750\n",
      "Epoch [47/50], Step [387/735], Loss: 0.0844\n",
      "Epoch [47/50], Step [388/735], Loss: 0.1194\n",
      "Epoch [47/50], Step [389/735], Loss: 0.0467\n",
      "Epoch [47/50], Step [390/735], Loss: 0.0386\n",
      "Epoch [47/50], Step [391/735], Loss: 0.1058\n",
      "Epoch [47/50], Step [392/735], Loss: 0.0236\n",
      "Epoch [47/50], Step [393/735], Loss: 0.0700\n",
      "Epoch [47/50], Step [394/735], Loss: 0.0404\n",
      "Epoch [47/50], Step [395/735], Loss: 0.0598\n",
      "Epoch [47/50], Step [396/735], Loss: 0.0508\n",
      "Epoch [47/50], Step [397/735], Loss: 0.0506\n",
      "Epoch [47/50], Step [398/735], Loss: 0.0559\n",
      "Epoch [47/50], Step [399/735], Loss: 0.4355\n",
      "Epoch [47/50], Step [400/735], Loss: 0.0750\n",
      "Epoch [47/50], Step [401/735], Loss: 0.1026\n",
      "Epoch [47/50], Step [402/735], Loss: 0.0558\n",
      "Epoch [47/50], Step [403/735], Loss: 0.0820\n",
      "Epoch [47/50], Step [404/735], Loss: 0.0671\n",
      "Epoch [47/50], Step [405/735], Loss: 0.0603\n",
      "Epoch [47/50], Step [406/735], Loss: 0.0230\n",
      "Epoch [47/50], Step [407/735], Loss: 0.0868\n",
      "Epoch [47/50], Step [408/735], Loss: 0.0794\n",
      "Epoch [47/50], Step [409/735], Loss: 0.0292\n",
      "Epoch [47/50], Step [410/735], Loss: 0.0275\n",
      "Epoch [47/50], Step [411/735], Loss: 0.0658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Step [412/735], Loss: 0.1139\n",
      "Epoch [47/50], Step [413/735], Loss: 0.0752\n",
      "Epoch [47/50], Step [414/735], Loss: 0.0536\n",
      "Epoch [47/50], Step [415/735], Loss: 0.0447\n",
      "Epoch [47/50], Step [416/735], Loss: 0.0699\n",
      "Epoch [47/50], Step [417/735], Loss: 0.0378\n",
      "Epoch [47/50], Step [418/735], Loss: 0.0413\n",
      "Epoch [47/50], Step [419/735], Loss: 0.0352\n",
      "Epoch [47/50], Step [420/735], Loss: 0.0230\n",
      "Epoch [47/50], Step [421/735], Loss: 0.0549\n",
      "Epoch [47/50], Step [422/735], Loss: 0.0389\n",
      "Epoch [47/50], Step [423/735], Loss: 0.0596\n",
      "Epoch [47/50], Step [424/735], Loss: 0.0473\n",
      "Epoch [47/50], Step [425/735], Loss: 0.0634\n",
      "Epoch [47/50], Step [426/735], Loss: 0.0250\n",
      "Epoch [47/50], Step [427/735], Loss: 0.0123\n",
      "Epoch [47/50], Step [428/735], Loss: 0.0377\n",
      "Epoch [47/50], Step [429/735], Loss: 0.0593\n",
      "Epoch [47/50], Step [430/735], Loss: 0.0629\n",
      "Epoch [47/50], Step [431/735], Loss: 0.0526\n",
      "Epoch [47/50], Step [432/735], Loss: 0.0776\n",
      "Epoch [47/50], Step [433/735], Loss: 0.0263\n",
      "Epoch [47/50], Step [434/735], Loss: 0.0285\n",
      "Epoch [47/50], Step [435/735], Loss: 0.0588\n",
      "Epoch [47/50], Step [436/735], Loss: 0.3279\n",
      "Epoch [47/50], Step [437/735], Loss: 0.0607\n",
      "Epoch [47/50], Step [438/735], Loss: 0.0259\n",
      "Epoch [47/50], Step [439/735], Loss: 0.0452\n",
      "Epoch [47/50], Step [440/735], Loss: 0.0195\n",
      "Epoch [47/50], Step [441/735], Loss: 0.1003\n",
      "Epoch [47/50], Step [442/735], Loss: 0.1037\n",
      "Epoch [47/50], Step [443/735], Loss: 0.0371\n",
      "Epoch [47/50], Step [444/735], Loss: 0.0752\n",
      "Epoch [47/50], Step [445/735], Loss: 0.0277\n",
      "Epoch [47/50], Step [446/735], Loss: 0.0332\n",
      "Epoch [47/50], Step [447/735], Loss: 0.0408\n",
      "Epoch [47/50], Step [448/735], Loss: 0.0412\n",
      "Epoch [47/50], Step [449/735], Loss: 0.0279\n",
      "Epoch [47/50], Step [450/735], Loss: 0.0625\n",
      "Epoch [47/50], Step [451/735], Loss: 0.0568\n",
      "Epoch [47/50], Step [452/735], Loss: 0.0499\n",
      "Epoch [47/50], Step [453/735], Loss: 0.0814\n",
      "Epoch [47/50], Step [454/735], Loss: 0.0206\n",
      "Epoch [47/50], Step [455/735], Loss: 0.0194\n",
      "Epoch [47/50], Step [456/735], Loss: 0.0590\n",
      "Epoch [47/50], Step [457/735], Loss: 0.0179\n",
      "Epoch [47/50], Step [458/735], Loss: 0.0414\n",
      "Epoch [47/50], Step [459/735], Loss: 0.0444\n",
      "Epoch [47/50], Step [460/735], Loss: 0.0944\n",
      "Epoch [47/50], Step [461/735], Loss: 0.0674\n",
      "Epoch [47/50], Step [462/735], Loss: 0.1646\n",
      "Epoch [47/50], Step [463/735], Loss: 0.0200\n",
      "Epoch [47/50], Step [464/735], Loss: 0.0785\n",
      "Epoch [47/50], Step [465/735], Loss: 0.0641\n",
      "Epoch [47/50], Step [466/735], Loss: 0.0752\n",
      "Epoch [47/50], Step [467/735], Loss: 0.0704\n",
      "Epoch [47/50], Step [468/735], Loss: 0.0931\n",
      "Epoch [47/50], Step [469/735], Loss: 0.0530\n",
      "Epoch [47/50], Step [470/735], Loss: 0.0352\n",
      "Epoch [47/50], Step [471/735], Loss: 0.0178\n",
      "Epoch [47/50], Step [472/735], Loss: 0.0184\n",
      "Epoch [47/50], Step [473/735], Loss: 0.0540\n",
      "Epoch [47/50], Step [474/735], Loss: 0.0696\n",
      "Epoch [47/50], Step [475/735], Loss: 0.0198\n",
      "Epoch [47/50], Step [476/735], Loss: 0.0272\n",
      "Epoch [47/50], Step [477/735], Loss: 0.0270\n",
      "Epoch [47/50], Step [478/735], Loss: 0.0333\n",
      "Epoch [47/50], Step [479/735], Loss: 0.0811\n",
      "Epoch [47/50], Step [480/735], Loss: 0.0512\n",
      "Epoch [47/50], Step [481/735], Loss: 0.0287\n",
      "Epoch [47/50], Step [482/735], Loss: 0.0390\n",
      "Epoch [47/50], Step [483/735], Loss: 0.0365\n",
      "Epoch [47/50], Step [484/735], Loss: 0.0598\n",
      "Epoch [47/50], Step [485/735], Loss: 0.0169\n",
      "Epoch [47/50], Step [486/735], Loss: 0.0587\n",
      "Epoch [47/50], Step [487/735], Loss: 0.0386\n",
      "Epoch [47/50], Step [488/735], Loss: 0.0175\n",
      "Epoch [47/50], Step [489/735], Loss: 0.0477\n",
      "Epoch [47/50], Step [490/735], Loss: 0.1249\n",
      "Epoch [47/50], Step [491/735], Loss: 0.0551\n",
      "Epoch [47/50], Step [492/735], Loss: 0.0370\n",
      "Epoch [47/50], Step [493/735], Loss: 0.0920\n",
      "Epoch [47/50], Step [494/735], Loss: 0.0484\n",
      "Epoch [47/50], Step [495/735], Loss: 0.0387\n",
      "Epoch [47/50], Step [496/735], Loss: 0.0532\n",
      "Epoch [47/50], Step [497/735], Loss: 0.0228\n",
      "Epoch [47/50], Step [498/735], Loss: 0.3065\n",
      "Epoch [47/50], Step [499/735], Loss: 0.0252\n",
      "Epoch [47/50], Step [500/735], Loss: 0.0941\n",
      "Epoch [47/50], Step [501/735], Loss: 0.0725\n",
      "Epoch [47/50], Step [502/735], Loss: 0.0455\n",
      "Epoch [47/50], Step [503/735], Loss: 0.0668\n",
      "Epoch [47/50], Step [504/735], Loss: 0.0255\n",
      "Epoch [47/50], Step [505/735], Loss: 0.0714\n",
      "Epoch [47/50], Step [506/735], Loss: 0.0319\n",
      "Epoch [47/50], Step [507/735], Loss: 0.0261\n",
      "Epoch [47/50], Step [508/735], Loss: 0.0395\n",
      "Epoch [47/50], Step [509/735], Loss: 0.0710\n",
      "Epoch [47/50], Step [510/735], Loss: 0.2536\n",
      "Epoch [47/50], Step [511/735], Loss: 0.0823\n",
      "Epoch [47/50], Step [512/735], Loss: 0.0553\n",
      "Epoch [47/50], Step [513/735], Loss: 0.0448\n",
      "Epoch [47/50], Step [514/735], Loss: 0.0323\n",
      "Epoch [47/50], Step [515/735], Loss: 0.0443\n",
      "Epoch [47/50], Step [516/735], Loss: 0.0306\n",
      "Epoch [47/50], Step [517/735], Loss: 0.0472\n",
      "Epoch [47/50], Step [518/735], Loss: 0.1330\n",
      "Epoch [47/50], Step [519/735], Loss: 0.0523\n",
      "Epoch [47/50], Step [520/735], Loss: 0.0870\n",
      "Epoch [47/50], Step [521/735], Loss: 0.0413\n",
      "Epoch [47/50], Step [522/735], Loss: 0.0430\n",
      "Epoch [47/50], Step [523/735], Loss: 0.0431\n",
      "Epoch [47/50], Step [524/735], Loss: 0.0798\n",
      "Epoch [47/50], Step [525/735], Loss: 0.0383\n",
      "Epoch [47/50], Step [526/735], Loss: 0.0381\n",
      "Epoch [47/50], Step [527/735], Loss: 0.0334\n",
      "Epoch [47/50], Step [528/735], Loss: 0.0528\n",
      "Epoch [47/50], Step [529/735], Loss: 0.0408\n",
      "Epoch [47/50], Step [530/735], Loss: 0.0843\n",
      "Epoch [47/50], Step [531/735], Loss: 0.0433\n",
      "Epoch [47/50], Step [532/735], Loss: 0.0693\n",
      "Epoch [47/50], Step [533/735], Loss: 0.0308\n",
      "Epoch [47/50], Step [534/735], Loss: 0.0793\n",
      "Epoch [47/50], Step [535/735], Loss: 0.0311\n",
      "Epoch [47/50], Step [536/735], Loss: 0.0473\n",
      "Epoch [47/50], Step [537/735], Loss: 0.0322\n",
      "Epoch [47/50], Step [538/735], Loss: 0.0405\n",
      "Epoch [47/50], Step [539/735], Loss: 0.1198\n",
      "Epoch [47/50], Step [540/735], Loss: 0.1742\n",
      "Epoch [47/50], Step [541/735], Loss: 0.0425\n",
      "Epoch [47/50], Step [542/735], Loss: 0.0588\n",
      "Epoch [47/50], Step [543/735], Loss: 0.0823\n",
      "Epoch [47/50], Step [544/735], Loss: 0.0416\n",
      "Epoch [47/50], Step [545/735], Loss: 0.0450\n",
      "Epoch [47/50], Step [546/735], Loss: 0.0602\n",
      "Epoch [47/50], Step [547/735], Loss: 0.0367\n",
      "Epoch [47/50], Step [548/735], Loss: 0.0299\n",
      "Epoch [47/50], Step [549/735], Loss: 0.1166\n",
      "Epoch [47/50], Step [550/735], Loss: 0.0506\n",
      "Epoch [47/50], Step [551/735], Loss: 0.0259\n",
      "Epoch [47/50], Step [552/735], Loss: 0.0641\n",
      "Epoch [47/50], Step [553/735], Loss: 0.0681\n",
      "Epoch [47/50], Step [554/735], Loss: 0.0312\n",
      "Epoch [47/50], Step [555/735], Loss: 0.0500\n",
      "Epoch [47/50], Step [556/735], Loss: 0.0920\n",
      "Epoch [47/50], Step [557/735], Loss: 0.0236\n",
      "Epoch [47/50], Step [558/735], Loss: 0.0610\n",
      "Epoch [47/50], Step [559/735], Loss: 0.0422\n",
      "Epoch [47/50], Step [560/735], Loss: 0.0255\n",
      "Epoch [47/50], Step [561/735], Loss: 0.0248\n",
      "Epoch [47/50], Step [562/735], Loss: 0.0269\n",
      "Epoch [47/50], Step [563/735], Loss: 0.0300\n",
      "Epoch [47/50], Step [564/735], Loss: 0.1366\n",
      "Epoch [47/50], Step [565/735], Loss: 0.0774\n",
      "Epoch [47/50], Step [566/735], Loss: 0.0368\n",
      "Epoch [47/50], Step [567/735], Loss: 0.0329\n",
      "Epoch [47/50], Step [568/735], Loss: 0.0863\n",
      "Epoch [47/50], Step [569/735], Loss: 0.0213\n",
      "Epoch [47/50], Step [570/735], Loss: 0.0552\n",
      "Epoch [47/50], Step [571/735], Loss: 0.0844\n",
      "Epoch [47/50], Step [572/735], Loss: 0.0334\n",
      "Epoch [47/50], Step [573/735], Loss: 0.0239\n",
      "Epoch [47/50], Step [574/735], Loss: 0.0720\n",
      "Epoch [47/50], Step [575/735], Loss: 0.0259\n",
      "Epoch [47/50], Step [576/735], Loss: 0.1572\n",
      "Epoch [47/50], Step [577/735], Loss: 0.0320\n",
      "Epoch [47/50], Step [578/735], Loss: 0.0315\n",
      "Epoch [47/50], Step [579/735], Loss: 0.0197\n",
      "Epoch [47/50], Step [580/735], Loss: 0.0277\n",
      "Epoch [47/50], Step [581/735], Loss: 0.0320\n",
      "Epoch [47/50], Step [582/735], Loss: 0.0853\n",
      "Epoch [47/50], Step [583/735], Loss: 0.0599\n",
      "Epoch [47/50], Step [584/735], Loss: 0.0751\n",
      "Epoch [47/50], Step [585/735], Loss: 0.0139\n",
      "Epoch [47/50], Step [586/735], Loss: 0.0483\n",
      "Epoch [47/50], Step [587/735], Loss: 0.0487\n",
      "Epoch [47/50], Step [588/735], Loss: 0.0379\n",
      "Epoch [47/50], Step [589/735], Loss: 0.0512\n",
      "Epoch [47/50], Step [590/735], Loss: 0.1000\n",
      "Epoch [47/50], Step [591/735], Loss: 0.0307\n",
      "Epoch [47/50], Step [592/735], Loss: 0.0427\n",
      "Epoch [47/50], Step [593/735], Loss: 0.0208\n",
      "Epoch [47/50], Step [594/735], Loss: 0.0579\n",
      "Epoch [47/50], Step [595/735], Loss: 0.2854\n",
      "Epoch [47/50], Step [596/735], Loss: 0.0420\n",
      "Epoch [47/50], Step [597/735], Loss: 0.1394\n",
      "Epoch [47/50], Step [598/735], Loss: 0.0176\n",
      "Epoch [47/50], Step [599/735], Loss: 0.0295\n",
      "Epoch [47/50], Step [600/735], Loss: 0.0314\n",
      "Epoch [47/50], Step [601/735], Loss: 0.0307\n",
      "Epoch [47/50], Step [602/735], Loss: 0.0217\n",
      "Epoch [47/50], Step [603/735], Loss: 0.0536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Step [604/735], Loss: 0.0834\n",
      "Epoch [47/50], Step [605/735], Loss: 0.0553\n",
      "Epoch [47/50], Step [606/735], Loss: 0.0280\n",
      "Epoch [47/50], Step [607/735], Loss: 0.0428\n",
      "Epoch [47/50], Step [608/735], Loss: 0.0465\n",
      "Epoch [47/50], Step [609/735], Loss: 0.0531\n",
      "Epoch [47/50], Step [610/735], Loss: 0.2405\n",
      "Epoch [47/50], Step [611/735], Loss: 0.0760\n",
      "Epoch [47/50], Step [612/735], Loss: 0.0125\n",
      "Epoch [47/50], Step [613/735], Loss: 0.0203\n",
      "Epoch [47/50], Step [614/735], Loss: 0.0465\n",
      "Epoch [47/50], Step [615/735], Loss: 0.0878\n",
      "Epoch [47/50], Step [616/735], Loss: 0.0566\n",
      "Epoch [47/50], Step [617/735], Loss: 0.0456\n",
      "Epoch [47/50], Step [618/735], Loss: 0.0305\n",
      "Epoch [47/50], Step [619/735], Loss: 0.0580\n",
      "Epoch [47/50], Step [620/735], Loss: 0.0290\n",
      "Epoch [47/50], Step [621/735], Loss: 0.0777\n",
      "Epoch [47/50], Step [622/735], Loss: 0.0679\n",
      "Epoch [47/50], Step [623/735], Loss: 0.0429\n",
      "Epoch [47/50], Step [624/735], Loss: 0.1045\n",
      "Epoch [47/50], Step [625/735], Loss: 0.0373\n",
      "Epoch [47/50], Step [626/735], Loss: 0.0453\n",
      "Epoch [47/50], Step [627/735], Loss: 0.0565\n",
      "Epoch [47/50], Step [628/735], Loss: 0.0537\n",
      "Epoch [47/50], Step [629/735], Loss: 0.0425\n",
      "Epoch [47/50], Step [630/735], Loss: 0.0732\n",
      "Epoch [47/50], Step [631/735], Loss: 0.0634\n",
      "Epoch [47/50], Step [632/735], Loss: 0.0622\n",
      "Epoch [47/50], Step [633/735], Loss: 0.1285\n",
      "Epoch [47/50], Step [634/735], Loss: 0.1245\n",
      "Epoch [47/50], Step [635/735], Loss: 0.0356\n",
      "Epoch [47/50], Step [636/735], Loss: 0.1504\n",
      "Epoch [47/50], Step [637/735], Loss: 0.0305\n",
      "Epoch [47/50], Step [638/735], Loss: 0.0251\n",
      "Epoch [47/50], Step [639/735], Loss: 0.0471\n",
      "Epoch [47/50], Step [640/735], Loss: 0.1027\n",
      "Epoch [47/50], Step [641/735], Loss: 0.0668\n",
      "Epoch [47/50], Step [642/735], Loss: 0.0596\n",
      "Epoch [47/50], Step [643/735], Loss: 0.0375\n",
      "Epoch [47/50], Step [644/735], Loss: 0.0365\n",
      "Epoch [47/50], Step [645/735], Loss: 0.2267\n",
      "Epoch [47/50], Step [646/735], Loss: 0.0870\n",
      "Epoch [47/50], Step [647/735], Loss: 0.0452\n",
      "Epoch [47/50], Step [648/735], Loss: 0.0647\n",
      "Epoch [47/50], Step [649/735], Loss: 0.0124\n",
      "Epoch [47/50], Step [650/735], Loss: 0.1229\n",
      "Epoch [47/50], Step [651/735], Loss: 0.0273\n",
      "Epoch [47/50], Step [652/735], Loss: 0.0635\n",
      "Epoch [47/50], Step [653/735], Loss: 0.0584\n",
      "Epoch [47/50], Step [654/735], Loss: 0.0305\n",
      "Epoch [47/50], Step [655/735], Loss: 0.0391\n",
      "Epoch [47/50], Step [656/735], Loss: 0.0268\n",
      "Epoch [47/50], Step [657/735], Loss: 0.0587\n",
      "Epoch [47/50], Step [658/735], Loss: 0.1220\n",
      "Epoch [47/50], Step [659/735], Loss: 0.0630\n",
      "Epoch [47/50], Step [660/735], Loss: 0.0465\n",
      "Epoch [47/50], Step [661/735], Loss: 0.0362\n",
      "Epoch [47/50], Step [662/735], Loss: 0.0501\n",
      "Epoch [47/50], Step [663/735], Loss: 0.0412\n",
      "Epoch [47/50], Step [664/735], Loss: 0.0235\n",
      "Epoch [47/50], Step [665/735], Loss: 0.0803\n",
      "Epoch [47/50], Step [666/735], Loss: 0.2943\n",
      "Epoch [47/50], Step [667/735], Loss: 0.0508\n",
      "Epoch [47/50], Step [668/735], Loss: 0.0186\n",
      "Epoch [47/50], Step [669/735], Loss: 0.0556\n",
      "Epoch [47/50], Step [670/735], Loss: 0.0240\n",
      "Epoch [47/50], Step [671/735], Loss: 0.0303\n",
      "Epoch [47/50], Step [672/735], Loss: 0.0377\n",
      "Epoch [47/50], Step [673/735], Loss: 0.0672\n",
      "Epoch [47/50], Step [674/735], Loss: 0.0204\n",
      "Epoch [47/50], Step [675/735], Loss: 0.0311\n",
      "Epoch [47/50], Step [676/735], Loss: 0.0186\n",
      "Epoch [47/50], Step [677/735], Loss: 0.0269\n",
      "Epoch [47/50], Step [678/735], Loss: 0.0810\n",
      "Epoch [47/50], Step [679/735], Loss: 0.0476\n",
      "Epoch [47/50], Step [680/735], Loss: 0.0200\n",
      "Epoch [47/50], Step [681/735], Loss: 0.0677\n",
      "Epoch [47/50], Step [682/735], Loss: 0.1167\n",
      "Epoch [47/50], Step [683/735], Loss: 0.0400\n",
      "Epoch [47/50], Step [684/735], Loss: 0.0325\n",
      "Epoch [47/50], Step [685/735], Loss: 0.0331\n",
      "Epoch [47/50], Step [686/735], Loss: 0.0592\n",
      "Epoch [47/50], Step [687/735], Loss: 0.0364\n",
      "Epoch [47/50], Step [688/735], Loss: 0.0208\n",
      "Epoch [47/50], Step [689/735], Loss: 0.3066\n",
      "Epoch [47/50], Step [690/735], Loss: 0.0360\n",
      "Epoch [47/50], Step [691/735], Loss: 0.1507\n",
      "Epoch [47/50], Step [692/735], Loss: 0.0655\n",
      "Epoch [47/50], Step [693/735], Loss: 0.0426\n",
      "Epoch [47/50], Step [694/735], Loss: 0.0569\n",
      "Epoch [47/50], Step [695/735], Loss: 0.0309\n",
      "Epoch [47/50], Step [696/735], Loss: 0.0388\n",
      "Epoch [47/50], Step [697/735], Loss: 0.0510\n",
      "Epoch [47/50], Step [698/735], Loss: 0.0291\n",
      "Epoch [47/50], Step [699/735], Loss: 0.1232\n",
      "Epoch [47/50], Step [700/735], Loss: 0.0607\n",
      "Epoch [47/50], Step [701/735], Loss: 0.0711\n",
      "Epoch [47/50], Step [702/735], Loss: 0.0760\n",
      "Epoch [47/50], Step [703/735], Loss: 0.1042\n",
      "Epoch [47/50], Step [704/735], Loss: 0.0299\n",
      "Epoch [47/50], Step [705/735], Loss: 0.1694\n",
      "Epoch [47/50], Step [706/735], Loss: 0.0539\n",
      "Epoch [47/50], Step [707/735], Loss: 0.0325\n",
      "Epoch [47/50], Step [708/735], Loss: 0.0228\n",
      "Epoch [47/50], Step [709/735], Loss: 0.0441\n",
      "Epoch [47/50], Step [710/735], Loss: 0.3772\n",
      "Epoch [47/50], Step [711/735], Loss: 0.0303\n",
      "Epoch [47/50], Step [712/735], Loss: 0.0644\n",
      "Epoch [47/50], Step [713/735], Loss: 0.0350\n",
      "Epoch [47/50], Step [714/735], Loss: 0.0568\n",
      "Epoch [47/50], Step [715/735], Loss: 0.0376\n",
      "Epoch [47/50], Step [716/735], Loss: 0.0191\n",
      "Epoch [47/50], Step [717/735], Loss: 0.0252\n",
      "Epoch [47/50], Step [718/735], Loss: 0.0229\n",
      "Epoch [47/50], Step [719/735], Loss: 0.0466\n",
      "Epoch [47/50], Step [720/735], Loss: 0.1047\n",
      "Epoch [47/50], Step [721/735], Loss: 0.0750\n",
      "Epoch [47/50], Step [722/735], Loss: 0.0289\n",
      "Epoch [47/50], Step [723/735], Loss: 0.4303\n",
      "Epoch [47/50], Step [724/735], Loss: 0.0538\n",
      "Epoch [47/50], Step [725/735], Loss: 0.1849\n",
      "Epoch [47/50], Step [726/735], Loss: 0.0343\n",
      "Epoch [47/50], Step [727/735], Loss: 0.0812\n",
      "Epoch [47/50], Step [728/735], Loss: 0.0582\n",
      "Epoch [47/50], Step [729/735], Loss: 0.0540\n",
      "Epoch [47/50], Step [730/735], Loss: 0.0505\n",
      "Epoch [47/50], Step [731/735], Loss: 0.0752\n",
      "Epoch [47/50], Step [732/735], Loss: 0.1430\n",
      "Epoch [47/50], Step [733/735], Loss: 0.0762\n",
      "Epoch [47/50], Step [734/735], Loss: 0.0339\n",
      "Epoch [47/50], Step [735/735], Loss: 0.0499\n",
      "Epoch [48/50], Step [1/735], Loss: 0.1321\n",
      "Epoch [48/50], Step [2/735], Loss: 0.1408\n",
      "Epoch [48/50], Step [3/735], Loss: 0.0237\n",
      "Epoch [48/50], Step [4/735], Loss: 0.1513\n",
      "Epoch [48/50], Step [5/735], Loss: 0.0186\n",
      "Epoch [48/50], Step [6/735], Loss: 0.1348\n",
      "Epoch [48/50], Step [7/735], Loss: 0.0497\n",
      "Epoch [48/50], Step [8/735], Loss: 0.0297\n",
      "Epoch [48/50], Step [9/735], Loss: 0.0467\n",
      "Epoch [48/50], Step [10/735], Loss: 0.0269\n",
      "Epoch [48/50], Step [11/735], Loss: 0.1207\n",
      "Epoch [48/50], Step [12/735], Loss: 0.0239\n",
      "Epoch [48/50], Step [13/735], Loss: 0.0365\n",
      "Epoch [48/50], Step [14/735], Loss: 0.0904\n",
      "Epoch [48/50], Step [15/735], Loss: 0.0851\n",
      "Epoch [48/50], Step [16/735], Loss: 0.0313\n",
      "Epoch [48/50], Step [17/735], Loss: 0.0162\n",
      "Epoch [48/50], Step [18/735], Loss: 0.2223\n",
      "Epoch [48/50], Step [19/735], Loss: 0.0511\n",
      "Epoch [48/50], Step [20/735], Loss: 0.0347\n",
      "Epoch [48/50], Step [21/735], Loss: 0.0425\n",
      "Epoch [48/50], Step [22/735], Loss: 0.0517\n",
      "Epoch [48/50], Step [23/735], Loss: 0.0157\n",
      "Epoch [48/50], Step [24/735], Loss: 0.0555\n",
      "Epoch [48/50], Step [25/735], Loss: 0.0356\n",
      "Epoch [48/50], Step [26/735], Loss: 0.0323\n",
      "Epoch [48/50], Step [27/735], Loss: 0.0579\n",
      "Epoch [48/50], Step [28/735], Loss: 0.0342\n",
      "Epoch [48/50], Step [29/735], Loss: 0.0724\n",
      "Epoch [48/50], Step [30/735], Loss: 0.0647\n",
      "Epoch [48/50], Step [31/735], Loss: 0.0305\n",
      "Epoch [48/50], Step [32/735], Loss: 0.0269\n",
      "Epoch [48/50], Step [33/735], Loss: 0.0369\n",
      "Epoch [48/50], Step [34/735], Loss: 0.0727\n",
      "Epoch [48/50], Step [35/735], Loss: 0.0322\n",
      "Epoch [48/50], Step [36/735], Loss: 0.0526\n",
      "Epoch [48/50], Step [37/735], Loss: 0.0179\n",
      "Epoch [48/50], Step [38/735], Loss: 0.1000\n",
      "Epoch [48/50], Step [39/735], Loss: 0.0370\n",
      "Epoch [48/50], Step [40/735], Loss: 0.0612\n",
      "Epoch [48/50], Step [41/735], Loss: 0.0394\n",
      "Epoch [48/50], Step [42/735], Loss: 0.1428\n",
      "Epoch [48/50], Step [43/735], Loss: 0.0322\n",
      "Epoch [48/50], Step [44/735], Loss: 0.0318\n",
      "Epoch [48/50], Step [45/735], Loss: 0.0239\n",
      "Epoch [48/50], Step [46/735], Loss: 0.0201\n",
      "Epoch [48/50], Step [47/735], Loss: 0.0335\n",
      "Epoch [48/50], Step [48/735], Loss: 0.0250\n",
      "Epoch [48/50], Step [49/735], Loss: 0.0440\n",
      "Epoch [48/50], Step [50/735], Loss: 0.0246\n",
      "Epoch [48/50], Step [51/735], Loss: 0.0795\n",
      "Epoch [48/50], Step [52/735], Loss: 0.0547\n",
      "Epoch [48/50], Step [53/735], Loss: 0.0192\n",
      "Epoch [48/50], Step [54/735], Loss: 0.0172\n",
      "Epoch [48/50], Step [55/735], Loss: 0.0974\n",
      "Epoch [48/50], Step [56/735], Loss: 0.0176\n",
      "Epoch [48/50], Step [57/735], Loss: 0.0270\n",
      "Epoch [48/50], Step [58/735], Loss: 0.0361\n",
      "Epoch [48/50], Step [59/735], Loss: 0.0497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Step [60/735], Loss: 0.0335\n",
      "Epoch [48/50], Step [61/735], Loss: 0.0495\n",
      "Epoch [48/50], Step [62/735], Loss: 0.0296\n",
      "Epoch [48/50], Step [63/735], Loss: 0.0210\n",
      "Epoch [48/50], Step [64/735], Loss: 0.0518\n",
      "Epoch [48/50], Step [65/735], Loss: 0.0401\n",
      "Epoch [48/50], Step [66/735], Loss: 0.1135\n",
      "Epoch [48/50], Step [67/735], Loss: 0.0787\n",
      "Epoch [48/50], Step [68/735], Loss: 0.0281\n",
      "Epoch [48/50], Step [69/735], Loss: 0.0571\n",
      "Epoch [48/50], Step [70/735], Loss: 0.0366\n",
      "Epoch [48/50], Step [71/735], Loss: 0.0495\n",
      "Epoch [48/50], Step [72/735], Loss: 0.0328\n",
      "Epoch [48/50], Step [73/735], Loss: 0.0968\n",
      "Epoch [48/50], Step [74/735], Loss: 0.0580\n",
      "Epoch [48/50], Step [75/735], Loss: 0.0577\n",
      "Epoch [48/50], Step [76/735], Loss: 0.0370\n",
      "Epoch [48/50], Step [77/735], Loss: 0.0380\n",
      "Epoch [48/50], Step [78/735], Loss: 0.0478\n",
      "Epoch [48/50], Step [79/735], Loss: 0.0391\n",
      "Epoch [48/50], Step [80/735], Loss: 0.0311\n",
      "Epoch [48/50], Step [81/735], Loss: 0.0924\n",
      "Epoch [48/50], Step [82/735], Loss: 0.0328\n",
      "Epoch [48/50], Step [83/735], Loss: 0.3398\n",
      "Epoch [48/50], Step [84/735], Loss: 0.1150\n",
      "Epoch [48/50], Step [85/735], Loss: 0.0226\n",
      "Epoch [48/50], Step [86/735], Loss: 0.0322\n",
      "Epoch [48/50], Step [87/735], Loss: 0.0346\n",
      "Epoch [48/50], Step [88/735], Loss: 0.0353\n",
      "Epoch [48/50], Step [89/735], Loss: 0.0816\n",
      "Epoch [48/50], Step [90/735], Loss: 0.0958\n",
      "Epoch [48/50], Step [91/735], Loss: 0.0388\n",
      "Epoch [48/50], Step [92/735], Loss: 0.0302\n",
      "Epoch [48/50], Step [93/735], Loss: 0.0633\n",
      "Epoch [48/50], Step [94/735], Loss: 0.0348\n",
      "Epoch [48/50], Step [95/735], Loss: 0.2249\n",
      "Epoch [48/50], Step [96/735], Loss: 0.0369\n",
      "Epoch [48/50], Step [97/735], Loss: 0.1385\n",
      "Epoch [48/50], Step [98/735], Loss: 0.0431\n",
      "Epoch [48/50], Step [99/735], Loss: 0.0289\n",
      "Epoch [48/50], Step [100/735], Loss: 0.0709\n",
      "Epoch [48/50], Step [101/735], Loss: 0.0447\n",
      "Epoch [48/50], Step [102/735], Loss: 0.0405\n",
      "Epoch [48/50], Step [103/735], Loss: 0.0423\n",
      "Epoch [48/50], Step [104/735], Loss: 0.0666\n",
      "Epoch [48/50], Step [105/735], Loss: 0.1054\n",
      "Epoch [48/50], Step [106/735], Loss: 0.0571\n",
      "Epoch [48/50], Step [107/735], Loss: 0.0343\n",
      "Epoch [48/50], Step [108/735], Loss: 0.0539\n",
      "Epoch [48/50], Step [109/735], Loss: 0.0668\n",
      "Epoch [48/50], Step [110/735], Loss: 0.0433\n",
      "Epoch [48/50], Step [111/735], Loss: 0.0919\n",
      "Epoch [48/50], Step [112/735], Loss: 0.0816\n",
      "Epoch [48/50], Step [113/735], Loss: 0.1520\n",
      "Epoch [48/50], Step [114/735], Loss: 0.0470\n",
      "Epoch [48/50], Step [115/735], Loss: 0.0471\n",
      "Epoch [48/50], Step [116/735], Loss: 0.0529\n",
      "Epoch [48/50], Step [117/735], Loss: 0.0529\n",
      "Epoch [48/50], Step [118/735], Loss: 0.0999\n",
      "Epoch [48/50], Step [119/735], Loss: 0.0804\n",
      "Epoch [48/50], Step [120/735], Loss: 0.0591\n",
      "Epoch [48/50], Step [121/735], Loss: 0.0588\n",
      "Epoch [48/50], Step [122/735], Loss: 0.0440\n",
      "Epoch [48/50], Step [123/735], Loss: 0.0542\n",
      "Epoch [48/50], Step [124/735], Loss: 0.2842\n",
      "Epoch [48/50], Step [125/735], Loss: 0.0599\n",
      "Epoch [48/50], Step [126/735], Loss: 0.0216\n",
      "Epoch [48/50], Step [127/735], Loss: 0.0540\n",
      "Epoch [48/50], Step [128/735], Loss: 0.0425\n",
      "Epoch [48/50], Step [129/735], Loss: 0.0211\n",
      "Epoch [48/50], Step [130/735], Loss: 0.0466\n",
      "Epoch [48/50], Step [131/735], Loss: 0.0416\n",
      "Epoch [48/50], Step [132/735], Loss: 0.0203\n",
      "Epoch [48/50], Step [133/735], Loss: 0.0441\n",
      "Epoch [48/50], Step [134/735], Loss: 0.0297\n",
      "Epoch [48/50], Step [135/735], Loss: 0.1390\n",
      "Epoch [48/50], Step [136/735], Loss: 0.0359\n",
      "Epoch [48/50], Step [137/735], Loss: 0.0220\n",
      "Epoch [48/50], Step [138/735], Loss: 0.0272\n",
      "Epoch [48/50], Step [139/735], Loss: 0.0464\n",
      "Epoch [48/50], Step [140/735], Loss: 0.0448\n",
      "Epoch [48/50], Step [141/735], Loss: 0.0525\n",
      "Epoch [48/50], Step [142/735], Loss: 0.0474\n",
      "Epoch [48/50], Step [143/735], Loss: 0.0413\n",
      "Epoch [48/50], Step [144/735], Loss: 0.1115\n",
      "Epoch [48/50], Step [145/735], Loss: 0.0205\n",
      "Epoch [48/50], Step [146/735], Loss: 0.0626\n",
      "Epoch [48/50], Step [147/735], Loss: 0.0373\n",
      "Epoch [48/50], Step [148/735], Loss: 0.0328\n",
      "Epoch [48/50], Step [149/735], Loss: 0.0216\n",
      "Epoch [48/50], Step [150/735], Loss: 0.0354\n",
      "Epoch [48/50], Step [151/735], Loss: 0.0337\n",
      "Epoch [48/50], Step [152/735], Loss: 0.0830\n",
      "Epoch [48/50], Step [153/735], Loss: 0.0268\n",
      "Epoch [48/50], Step [154/735], Loss: 0.0350\n",
      "Epoch [48/50], Step [155/735], Loss: 0.0608\n",
      "Epoch [48/50], Step [156/735], Loss: 0.1304\n",
      "Epoch [48/50], Step [157/735], Loss: 0.0483\n",
      "Epoch [48/50], Step [158/735], Loss: 0.0878\n",
      "Epoch [48/50], Step [159/735], Loss: 0.0143\n",
      "Epoch [48/50], Step [160/735], Loss: 0.0647\n",
      "Epoch [48/50], Step [161/735], Loss: 0.0693\n",
      "Epoch [48/50], Step [162/735], Loss: 0.0324\n",
      "Epoch [48/50], Step [163/735], Loss: 0.0483\n",
      "Epoch [48/50], Step [164/735], Loss: 0.0792\n",
      "Epoch [48/50], Step [165/735], Loss: 0.0926\n",
      "Epoch [48/50], Step [166/735], Loss: 0.0483\n",
      "Epoch [48/50], Step [167/735], Loss: 0.1594\n",
      "Epoch [48/50], Step [168/735], Loss: 0.1085\n",
      "Epoch [48/50], Step [169/735], Loss: 0.1485\n",
      "Epoch [48/50], Step [170/735], Loss: 0.0838\n",
      "Epoch [48/50], Step [171/735], Loss: 0.0412\n",
      "Epoch [48/50], Step [172/735], Loss: 0.0318\n",
      "Epoch [48/50], Step [173/735], Loss: 0.0404\n",
      "Epoch [48/50], Step [174/735], Loss: 0.0763\n",
      "Epoch [48/50], Step [175/735], Loss: 0.0602\n",
      "Epoch [48/50], Step [176/735], Loss: 0.0494\n",
      "Epoch [48/50], Step [177/735], Loss: 0.0890\n",
      "Epoch [48/50], Step [178/735], Loss: 0.0442\n",
      "Epoch [48/50], Step [179/735], Loss: 0.0669\n",
      "Epoch [48/50], Step [180/735], Loss: 0.0264\n",
      "Epoch [48/50], Step [181/735], Loss: 0.0837\n",
      "Epoch [48/50], Step [182/735], Loss: 0.0601\n",
      "Epoch [48/50], Step [183/735], Loss: 0.0829\n",
      "Epoch [48/50], Step [184/735], Loss: 0.0549\n",
      "Epoch [48/50], Step [185/735], Loss: 0.0639\n",
      "Epoch [48/50], Step [186/735], Loss: 0.0281\n",
      "Epoch [48/50], Step [187/735], Loss: 0.0547\n",
      "Epoch [48/50], Step [188/735], Loss: 0.0700\n",
      "Epoch [48/50], Step [189/735], Loss: 0.0560\n",
      "Epoch [48/50], Step [190/735], Loss: 0.0295\n",
      "Epoch [48/50], Step [191/735], Loss: 0.0590\n",
      "Epoch [48/50], Step [192/735], Loss: 0.4617\n",
      "Epoch [48/50], Step [193/735], Loss: 0.0393\n",
      "Epoch [48/50], Step [194/735], Loss: 0.0341\n",
      "Epoch [48/50], Step [195/735], Loss: 0.0442\n",
      "Epoch [48/50], Step [196/735], Loss: 0.0803\n",
      "Epoch [48/50], Step [197/735], Loss: 0.0653\n",
      "Epoch [48/50], Step [198/735], Loss: 0.0226\n",
      "Epoch [48/50], Step [199/735], Loss: 0.1278\n",
      "Epoch [48/50], Step [200/735], Loss: 0.0308\n",
      "Epoch [48/50], Step [201/735], Loss: 0.0187\n",
      "Epoch [48/50], Step [202/735], Loss: 0.0879\n",
      "Epoch [48/50], Step [203/735], Loss: 0.0529\n",
      "Epoch [48/50], Step [204/735], Loss: 0.0794\n",
      "Epoch [48/50], Step [205/735], Loss: 0.1069\n",
      "Epoch [48/50], Step [206/735], Loss: 0.1336\n",
      "Epoch [48/50], Step [207/735], Loss: 0.0227\n",
      "Epoch [48/50], Step [208/735], Loss: 0.0449\n",
      "Epoch [48/50], Step [209/735], Loss: 0.1237\n",
      "Epoch [48/50], Step [210/735], Loss: 0.0593\n",
      "Epoch [48/50], Step [211/735], Loss: 0.0605\n",
      "Epoch [48/50], Step [212/735], Loss: 0.0111\n",
      "Epoch [48/50], Step [213/735], Loss: 0.0417\n",
      "Epoch [48/50], Step [214/735], Loss: 0.0722\n",
      "Epoch [48/50], Step [215/735], Loss: 0.0668\n",
      "Epoch [48/50], Step [216/735], Loss: 0.0543\n",
      "Epoch [48/50], Step [217/735], Loss: 0.1356\n",
      "Epoch [48/50], Step [218/735], Loss: 0.0643\n",
      "Epoch [48/50], Step [219/735], Loss: 0.0528\n",
      "Epoch [48/50], Step [220/735], Loss: 0.1369\n",
      "Epoch [48/50], Step [221/735], Loss: 0.0324\n",
      "Epoch [48/50], Step [222/735], Loss: 0.0213\n",
      "Epoch [48/50], Step [223/735], Loss: 0.0227\n",
      "Epoch [48/50], Step [224/735], Loss: 0.0660\n",
      "Epoch [48/50], Step [225/735], Loss: 0.0374\n",
      "Epoch [48/50], Step [226/735], Loss: 0.0584\n",
      "Epoch [48/50], Step [227/735], Loss: 0.0543\n",
      "Epoch [48/50], Step [228/735], Loss: 0.0507\n",
      "Epoch [48/50], Step [229/735], Loss: 0.0973\n",
      "Epoch [48/50], Step [230/735], Loss: 0.0262\n",
      "Epoch [48/50], Step [231/735], Loss: 0.0402\n",
      "Epoch [48/50], Step [232/735], Loss: 0.0612\n",
      "Epoch [48/50], Step [233/735], Loss: 0.0646\n",
      "Epoch [48/50], Step [234/735], Loss: 0.0482\n",
      "Epoch [48/50], Step [235/735], Loss: 0.0269\n",
      "Epoch [48/50], Step [236/735], Loss: 0.0596\n",
      "Epoch [48/50], Step [237/735], Loss: 0.0407\n",
      "Epoch [48/50], Step [238/735], Loss: 0.0420\n",
      "Epoch [48/50], Step [239/735], Loss: 0.0337\n",
      "Epoch [48/50], Step [240/735], Loss: 0.0324\n",
      "Epoch [48/50], Step [241/735], Loss: 0.0475\n",
      "Epoch [48/50], Step [242/735], Loss: 0.1064\n",
      "Epoch [48/50], Step [243/735], Loss: 0.0388\n",
      "Epoch [48/50], Step [244/735], Loss: 0.0207\n",
      "Epoch [48/50], Step [245/735], Loss: 0.0409\n",
      "Epoch [48/50], Step [246/735], Loss: 0.0480\n",
      "Epoch [48/50], Step [247/735], Loss: 0.0368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Step [248/735], Loss: 0.0282\n",
      "Epoch [48/50], Step [249/735], Loss: 0.0257\n",
      "Epoch [48/50], Step [250/735], Loss: 0.0515\n",
      "Epoch [48/50], Step [251/735], Loss: 0.0316\n",
      "Epoch [48/50], Step [252/735], Loss: 0.0324\n",
      "Epoch [48/50], Step [253/735], Loss: 0.1748\n",
      "Epoch [48/50], Step [254/735], Loss: 0.0384\n",
      "Epoch [48/50], Step [255/735], Loss: 0.0489\n",
      "Epoch [48/50], Step [256/735], Loss: 0.0426\n",
      "Epoch [48/50], Step [257/735], Loss: 0.0268\n",
      "Epoch [48/50], Step [258/735], Loss: 0.0286\n",
      "Epoch [48/50], Step [259/735], Loss: 0.0299\n",
      "Epoch [48/50], Step [260/735], Loss: 0.0688\n",
      "Epoch [48/50], Step [261/735], Loss: 0.0926\n",
      "Epoch [48/50], Step [262/735], Loss: 0.0515\n",
      "Epoch [48/50], Step [263/735], Loss: 0.1156\n",
      "Epoch [48/50], Step [264/735], Loss: 0.0986\n",
      "Epoch [48/50], Step [265/735], Loss: 0.0322\n",
      "Epoch [48/50], Step [266/735], Loss: 0.0481\n",
      "Epoch [48/50], Step [267/735], Loss: 0.0463\n",
      "Epoch [48/50], Step [268/735], Loss: 0.0493\n",
      "Epoch [48/50], Step [269/735], Loss: 0.0311\n",
      "Epoch [48/50], Step [270/735], Loss: 0.0259\n",
      "Epoch [48/50], Step [271/735], Loss: 0.1085\n",
      "Epoch [48/50], Step [272/735], Loss: 0.1010\n",
      "Epoch [48/50], Step [273/735], Loss: 0.0343\n",
      "Epoch [48/50], Step [274/735], Loss: 0.0826\n",
      "Epoch [48/50], Step [275/735], Loss: 0.0213\n",
      "Epoch [48/50], Step [276/735], Loss: 0.0782\n",
      "Epoch [48/50], Step [277/735], Loss: 0.0916\n",
      "Epoch [48/50], Step [278/735], Loss: 0.0508\n",
      "Epoch [48/50], Step [279/735], Loss: 0.0408\n",
      "Epoch [48/50], Step [280/735], Loss: 0.0294\n",
      "Epoch [48/50], Step [281/735], Loss: 0.1078\n",
      "Epoch [48/50], Step [282/735], Loss: 0.0404\n",
      "Epoch [48/50], Step [283/735], Loss: 0.1238\n",
      "Epoch [48/50], Step [284/735], Loss: 0.0208\n",
      "Epoch [48/50], Step [285/735], Loss: 0.0491\n",
      "Epoch [48/50], Step [286/735], Loss: 0.1958\n",
      "Epoch [48/50], Step [287/735], Loss: 0.0733\n",
      "Epoch [48/50], Step [288/735], Loss: 0.0279\n",
      "Epoch [48/50], Step [289/735], Loss: 0.0802\n",
      "Epoch [48/50], Step [290/735], Loss: 0.0418\n",
      "Epoch [48/50], Step [291/735], Loss: 0.0559\n",
      "Epoch [48/50], Step [292/735], Loss: 0.0560\n",
      "Epoch [48/50], Step [293/735], Loss: 0.0564\n",
      "Epoch [48/50], Step [294/735], Loss: 0.1577\n",
      "Epoch [48/50], Step [295/735], Loss: 0.0779\n",
      "Epoch [48/50], Step [296/735], Loss: 0.0632\n",
      "Epoch [48/50], Step [297/735], Loss: 0.0367\n",
      "Epoch [48/50], Step [298/735], Loss: 0.0211\n",
      "Epoch [48/50], Step [299/735], Loss: 0.0434\n",
      "Epoch [48/50], Step [300/735], Loss: 0.0745\n",
      "Epoch [48/50], Step [301/735], Loss: 0.1912\n",
      "Epoch [48/50], Step [302/735], Loss: 0.0400\n",
      "Epoch [48/50], Step [303/735], Loss: 0.0445\n",
      "Epoch [48/50], Step [304/735], Loss: 0.0286\n",
      "Epoch [48/50], Step [305/735], Loss: 0.0335\n",
      "Epoch [48/50], Step [306/735], Loss: 0.0297\n",
      "Epoch [48/50], Step [307/735], Loss: 0.0173\n",
      "Epoch [48/50], Step [308/735], Loss: 0.1173\n",
      "Epoch [48/50], Step [309/735], Loss: 0.0577\n",
      "Epoch [48/50], Step [310/735], Loss: 0.1201\n",
      "Epoch [48/50], Step [311/735], Loss: 0.0511\n",
      "Epoch [48/50], Step [312/735], Loss: 0.0621\n",
      "Epoch [48/50], Step [313/735], Loss: 0.0184\n",
      "Epoch [48/50], Step [314/735], Loss: 0.2698\n",
      "Epoch [48/50], Step [315/735], Loss: 0.0713\n",
      "Epoch [48/50], Step [316/735], Loss: 0.0867\n",
      "Epoch [48/50], Step [317/735], Loss: 0.0274\n",
      "Epoch [48/50], Step [318/735], Loss: 0.0395\n",
      "Epoch [48/50], Step [319/735], Loss: 0.0237\n",
      "Epoch [48/50], Step [320/735], Loss: 0.0496\n",
      "Epoch [48/50], Step [321/735], Loss: 0.0502\n",
      "Epoch [48/50], Step [322/735], Loss: 0.0222\n",
      "Epoch [48/50], Step [323/735], Loss: 0.0541\n",
      "Epoch [48/50], Step [324/735], Loss: 0.0555\n",
      "Epoch [48/50], Step [325/735], Loss: 0.0313\n",
      "Epoch [48/50], Step [326/735], Loss: 0.0719\n",
      "Epoch [48/50], Step [327/735], Loss: 0.0545\n",
      "Epoch [48/50], Step [328/735], Loss: 0.0662\n",
      "Epoch [48/50], Step [329/735], Loss: 0.0297\n",
      "Epoch [48/50], Step [330/735], Loss: 0.0301\n",
      "Epoch [48/50], Step [331/735], Loss: 0.0364\n",
      "Epoch [48/50], Step [332/735], Loss: 0.0594\n",
      "Epoch [48/50], Step [333/735], Loss: 0.0427\n",
      "Epoch [48/50], Step [334/735], Loss: 0.0243\n",
      "Epoch [48/50], Step [335/735], Loss: 0.0336\n",
      "Epoch [48/50], Step [336/735], Loss: 0.0148\n",
      "Epoch [48/50], Step [337/735], Loss: 0.0166\n",
      "Epoch [48/50], Step [338/735], Loss: 0.0530\n",
      "Epoch [48/50], Step [339/735], Loss: 0.0237\n",
      "Epoch [48/50], Step [340/735], Loss: 0.0172\n",
      "Epoch [48/50], Step [341/735], Loss: 0.0186\n",
      "Epoch [48/50], Step [342/735], Loss: 0.0208\n",
      "Epoch [48/50], Step [343/735], Loss: 0.0485\n",
      "Epoch [48/50], Step [344/735], Loss: 0.0537\n",
      "Epoch [48/50], Step [345/735], Loss: 0.0301\n",
      "Epoch [48/50], Step [346/735], Loss: 0.1861\n",
      "Epoch [48/50], Step [347/735], Loss: 0.0768\n",
      "Epoch [48/50], Step [348/735], Loss: 0.0120\n",
      "Epoch [48/50], Step [349/735], Loss: 0.0732\n",
      "Epoch [48/50], Step [350/735], Loss: 0.0670\n",
      "Epoch [48/50], Step [351/735], Loss: 0.0775\n",
      "Epoch [48/50], Step [352/735], Loss: 0.0671\n",
      "Epoch [48/50], Step [353/735], Loss: 0.1091\n",
      "Epoch [48/50], Step [354/735], Loss: 0.0226\n",
      "Epoch [48/50], Step [355/735], Loss: 0.0203\n",
      "Epoch [48/50], Step [356/735], Loss: 0.1233\n",
      "Epoch [48/50], Step [357/735], Loss: 0.2043\n",
      "Epoch [48/50], Step [358/735], Loss: 0.0389\n",
      "Epoch [48/50], Step [359/735], Loss: 0.0511\n",
      "Epoch [48/50], Step [360/735], Loss: 0.0187\n",
      "Epoch [48/50], Step [361/735], Loss: 0.0383\n",
      "Epoch [48/50], Step [362/735], Loss: 0.0412\n",
      "Epoch [48/50], Step [363/735], Loss: 0.0723\n",
      "Epoch [48/50], Step [364/735], Loss: 0.0995\n",
      "Epoch [48/50], Step [365/735], Loss: 0.0201\n",
      "Epoch [48/50], Step [366/735], Loss: 0.0384\n",
      "Epoch [48/50], Step [367/735], Loss: 0.0754\n",
      "Epoch [48/50], Step [368/735], Loss: 0.0269\n",
      "Epoch [48/50], Step [369/735], Loss: 0.0321\n",
      "Epoch [48/50], Step [370/735], Loss: 0.1482\n",
      "Epoch [48/50], Step [371/735], Loss: 0.1262\n",
      "Epoch [48/50], Step [372/735], Loss: 0.0734\n",
      "Epoch [48/50], Step [373/735], Loss: 0.0340\n",
      "Epoch [48/50], Step [374/735], Loss: 0.0416\n",
      "Epoch [48/50], Step [375/735], Loss: 0.0894\n",
      "Epoch [48/50], Step [376/735], Loss: 0.0258\n",
      "Epoch [48/50], Step [377/735], Loss: 0.0202\n",
      "Epoch [48/50], Step [378/735], Loss: 0.0538\n",
      "Epoch [48/50], Step [379/735], Loss: 0.0299\n",
      "Epoch [48/50], Step [380/735], Loss: 0.2085\n",
      "Epoch [48/50], Step [381/735], Loss: 0.0290\n",
      "Epoch [48/50], Step [382/735], Loss: 0.0195\n",
      "Epoch [48/50], Step [383/735], Loss: 0.0133\n",
      "Epoch [48/50], Step [384/735], Loss: 0.0360\n",
      "Epoch [48/50], Step [385/735], Loss: 0.1363\n",
      "Epoch [48/50], Step [386/735], Loss: 0.1665\n",
      "Epoch [48/50], Step [387/735], Loss: 0.0301\n",
      "Epoch [48/50], Step [388/735], Loss: 0.0634\n",
      "Epoch [48/50], Step [389/735], Loss: 0.0221\n",
      "Epoch [48/50], Step [390/735], Loss: 0.1071\n",
      "Epoch [48/50], Step [391/735], Loss: 0.1131\n",
      "Epoch [48/50], Step [392/735], Loss: 0.0797\n",
      "Epoch [48/50], Step [393/735], Loss: 0.0295\n",
      "Epoch [48/50], Step [394/735], Loss: 0.0380\n",
      "Epoch [48/50], Step [395/735], Loss: 0.3423\n",
      "Epoch [48/50], Step [396/735], Loss: 0.0939\n",
      "Epoch [48/50], Step [397/735], Loss: 0.0457\n",
      "Epoch [48/50], Step [398/735], Loss: 0.0490\n",
      "Epoch [48/50], Step [399/735], Loss: 0.0299\n",
      "Epoch [48/50], Step [400/735], Loss: 0.0890\n",
      "Epoch [48/50], Step [401/735], Loss: 0.0481\n",
      "Epoch [48/50], Step [402/735], Loss: 0.0594\n",
      "Epoch [48/50], Step [403/735], Loss: 0.0947\n",
      "Epoch [48/50], Step [404/735], Loss: 0.0307\n",
      "Epoch [48/50], Step [405/735], Loss: 0.0462\n",
      "Epoch [48/50], Step [406/735], Loss: 0.0619\n",
      "Epoch [48/50], Step [407/735], Loss: 0.0352\n",
      "Epoch [48/50], Step [408/735], Loss: 0.0457\n",
      "Epoch [48/50], Step [409/735], Loss: 0.0272\n",
      "Epoch [48/50], Step [410/735], Loss: 0.0674\n",
      "Epoch [48/50], Step [411/735], Loss: 0.0226\n",
      "Epoch [48/50], Step [412/735], Loss: 0.2744\n",
      "Epoch [48/50], Step [413/735], Loss: 0.0643\n",
      "Epoch [48/50], Step [414/735], Loss: 0.0636\n",
      "Epoch [48/50], Step [415/735], Loss: 0.0598\n",
      "Epoch [48/50], Step [416/735], Loss: 0.0711\n",
      "Epoch [48/50], Step [417/735], Loss: 0.0264\n",
      "Epoch [48/50], Step [418/735], Loss: 0.0461\n",
      "Epoch [48/50], Step [419/735], Loss: 0.0445\n",
      "Epoch [48/50], Step [420/735], Loss: 0.0960\n",
      "Epoch [48/50], Step [421/735], Loss: 0.0302\n",
      "Epoch [48/50], Step [422/735], Loss: 0.0465\n",
      "Epoch [48/50], Step [423/735], Loss: 0.0577\n",
      "Epoch [48/50], Step [424/735], Loss: 0.0176\n",
      "Epoch [48/50], Step [425/735], Loss: 0.0497\n",
      "Epoch [48/50], Step [426/735], Loss: 0.0204\n",
      "Epoch [48/50], Step [427/735], Loss: 0.0790\n",
      "Epoch [48/50], Step [428/735], Loss: 0.2078\n",
      "Epoch [48/50], Step [429/735], Loss: 0.0894\n",
      "Epoch [48/50], Step [430/735], Loss: 0.0231\n",
      "Epoch [48/50], Step [431/735], Loss: 0.0498\n",
      "Epoch [48/50], Step [432/735], Loss: 0.0344\n",
      "Epoch [48/50], Step [433/735], Loss: 0.0347\n",
      "Epoch [48/50], Step [434/735], Loss: 0.1923\n",
      "Epoch [48/50], Step [435/735], Loss: 0.0293\n",
      "Epoch [48/50], Step [436/735], Loss: 0.0437\n",
      "Epoch [48/50], Step [437/735], Loss: 0.1141\n",
      "Epoch [48/50], Step [438/735], Loss: 0.0415\n",
      "Epoch [48/50], Step [439/735], Loss: 0.0607\n",
      "Epoch [48/50], Step [440/735], Loss: 0.1187\n",
      "Epoch [48/50], Step [441/735], Loss: 0.3450\n",
      "Epoch [48/50], Step [442/735], Loss: 0.5236\n",
      "Epoch [48/50], Step [443/735], Loss: 0.0469\n",
      "Epoch [48/50], Step [444/735], Loss: 0.0452\n",
      "Epoch [48/50], Step [445/735], Loss: 0.0649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Step [446/735], Loss: 0.0471\n",
      "Epoch [48/50], Step [447/735], Loss: 0.0672\n",
      "Epoch [48/50], Step [448/735], Loss: 0.1438\n",
      "Epoch [48/50], Step [449/735], Loss: 0.0434\n",
      "Epoch [48/50], Step [450/735], Loss: 0.0275\n",
      "Epoch [48/50], Step [451/735], Loss: 0.0435\n",
      "Epoch [48/50], Step [452/735], Loss: 0.0492\n",
      "Epoch [48/50], Step [453/735], Loss: 0.0738\n",
      "Epoch [48/50], Step [454/735], Loss: 0.0532\n",
      "Epoch [48/50], Step [455/735], Loss: 0.0398\n",
      "Epoch [48/50], Step [456/735], Loss: 0.0734\n",
      "Epoch [48/50], Step [457/735], Loss: 0.1468\n",
      "Epoch [48/50], Step [458/735], Loss: 0.0765\n",
      "Epoch [48/50], Step [459/735], Loss: 0.0262\n",
      "Epoch [48/50], Step [460/735], Loss: 0.0782\n",
      "Epoch [48/50], Step [461/735], Loss: 0.1708\n",
      "Epoch [48/50], Step [462/735], Loss: 0.0442\n",
      "Epoch [48/50], Step [463/735], Loss: 0.0534\n",
      "Epoch [48/50], Step [464/735], Loss: 0.0631\n",
      "Epoch [48/50], Step [465/735], Loss: 0.0309\n",
      "Epoch [48/50], Step [466/735], Loss: 0.0913\n",
      "Epoch [48/50], Step [467/735], Loss: 0.0524\n",
      "Epoch [48/50], Step [468/735], Loss: 0.0386\n",
      "Epoch [48/50], Step [469/735], Loss: 0.0696\n",
      "Epoch [48/50], Step [470/735], Loss: 0.0592\n",
      "Epoch [48/50], Step [471/735], Loss: 0.0417\n",
      "Epoch [48/50], Step [472/735], Loss: 0.0590\n",
      "Epoch [48/50], Step [473/735], Loss: 0.0428\n",
      "Epoch [48/50], Step [474/735], Loss: 0.0417\n",
      "Epoch [48/50], Step [475/735], Loss: 0.0465\n",
      "Epoch [48/50], Step [476/735], Loss: 0.0416\n",
      "Epoch [48/50], Step [477/735], Loss: 0.0254\n",
      "Epoch [48/50], Step [478/735], Loss: 0.0997\n",
      "Epoch [48/50], Step [479/735], Loss: 0.0323\n",
      "Epoch [48/50], Step [480/735], Loss: 0.0525\n",
      "Epoch [48/50], Step [481/735], Loss: 0.0540\n",
      "Epoch [48/50], Step [482/735], Loss: 0.1659\n",
      "Epoch [48/50], Step [483/735], Loss: 0.0248\n",
      "Epoch [48/50], Step [484/735], Loss: 0.0442\n",
      "Epoch [48/50], Step [485/735], Loss: 0.1091\n",
      "Epoch [48/50], Step [486/735], Loss: 0.0365\n",
      "Epoch [48/50], Step [487/735], Loss: 0.0323\n",
      "Epoch [48/50], Step [488/735], Loss: 0.0795\n",
      "Epoch [48/50], Step [489/735], Loss: 0.0773\n",
      "Epoch [48/50], Step [490/735], Loss: 0.0298\n",
      "Epoch [48/50], Step [491/735], Loss: 0.0406\n",
      "Epoch [48/50], Step [492/735], Loss: 0.0194\n",
      "Epoch [48/50], Step [493/735], Loss: 0.0403\n",
      "Epoch [48/50], Step [494/735], Loss: 0.0557\n",
      "Epoch [48/50], Step [495/735], Loss: 0.0241\n",
      "Epoch [48/50], Step [496/735], Loss: 0.0428\n",
      "Epoch [48/50], Step [497/735], Loss: 0.0187\n",
      "Epoch [48/50], Step [498/735], Loss: 0.0340\n",
      "Epoch [48/50], Step [499/735], Loss: 0.0224\n",
      "Epoch [48/50], Step [500/735], Loss: 0.0562\n",
      "Epoch [48/50], Step [501/735], Loss: 0.0429\n",
      "Epoch [48/50], Step [502/735], Loss: 0.0578\n",
      "Epoch [48/50], Step [503/735], Loss: 0.1130\n",
      "Epoch [48/50], Step [504/735], Loss: 0.0245\n",
      "Epoch [48/50], Step [505/735], Loss: 0.2279\n",
      "Epoch [48/50], Step [506/735], Loss: 0.1188\n",
      "Epoch [48/50], Step [507/735], Loss: 0.0464\n",
      "Epoch [48/50], Step [508/735], Loss: 0.0340\n",
      "Epoch [48/50], Step [509/735], Loss: 0.0298\n",
      "Epoch [48/50], Step [510/735], Loss: 0.0435\n",
      "Epoch [48/50], Step [511/735], Loss: 0.0282\n",
      "Epoch [48/50], Step [512/735], Loss: 0.1619\n",
      "Epoch [48/50], Step [513/735], Loss: 0.0271\n",
      "Epoch [48/50], Step [514/735], Loss: 0.0572\n",
      "Epoch [48/50], Step [515/735], Loss: 0.0180\n",
      "Epoch [48/50], Step [516/735], Loss: 0.0472\n",
      "Epoch [48/50], Step [517/735], Loss: 0.0250\n",
      "Epoch [48/50], Step [518/735], Loss: 0.1171\n",
      "Epoch [48/50], Step [519/735], Loss: 0.0740\n",
      "Epoch [48/50], Step [520/735], Loss: 0.0469\n",
      "Epoch [48/50], Step [521/735], Loss: 0.0433\n",
      "Epoch [48/50], Step [522/735], Loss: 0.0631\n",
      "Epoch [48/50], Step [523/735], Loss: 0.0476\n",
      "Epoch [48/50], Step [524/735], Loss: 0.0721\n",
      "Epoch [48/50], Step [525/735], Loss: 0.0937\n",
      "Epoch [48/50], Step [526/735], Loss: 0.0468\n",
      "Epoch [48/50], Step [527/735], Loss: 0.0532\n",
      "Epoch [48/50], Step [528/735], Loss: 0.0304\n",
      "Epoch [48/50], Step [529/735], Loss: 0.0612\n",
      "Epoch [48/50], Step [530/735], Loss: 0.0534\n",
      "Epoch [48/50], Step [531/735], Loss: 0.0697\n",
      "Epoch [48/50], Step [532/735], Loss: 0.0124\n",
      "Epoch [48/50], Step [533/735], Loss: 0.0324\n",
      "Epoch [48/50], Step [534/735], Loss: 0.0325\n",
      "Epoch [48/50], Step [535/735], Loss: 0.0407\n",
      "Epoch [48/50], Step [536/735], Loss: 0.0245\n",
      "Epoch [48/50], Step [537/735], Loss: 0.0832\n",
      "Epoch [48/50], Step [538/735], Loss: 0.1257\n",
      "Epoch [48/50], Step [539/735], Loss: 0.0839\n",
      "Epoch [48/50], Step [540/735], Loss: 0.0581\n",
      "Epoch [48/50], Step [541/735], Loss: 0.0449\n",
      "Epoch [48/50], Step [542/735], Loss: 0.0478\n",
      "Epoch [48/50], Step [543/735], Loss: 0.0378\n",
      "Epoch [48/50], Step [544/735], Loss: 0.1706\n",
      "Epoch [48/50], Step [545/735], Loss: 0.0668\n",
      "Epoch [48/50], Step [546/735], Loss: 0.0658\n",
      "Epoch [48/50], Step [547/735], Loss: 0.0749\n",
      "Epoch [48/50], Step [548/735], Loss: 0.0220\n",
      "Epoch [48/50], Step [549/735], Loss: 0.0220\n",
      "Epoch [48/50], Step [550/735], Loss: 0.0892\n",
      "Epoch [48/50], Step [551/735], Loss: 0.0363\n",
      "Epoch [48/50], Step [552/735], Loss: 0.0238\n",
      "Epoch [48/50], Step [553/735], Loss: 0.0639\n",
      "Epoch [48/50], Step [554/735], Loss: 0.0226\n",
      "Epoch [48/50], Step [555/735], Loss: 0.0568\n",
      "Epoch [48/50], Step [556/735], Loss: 0.0642\n",
      "Epoch [48/50], Step [557/735], Loss: 0.0768\n",
      "Epoch [48/50], Step [558/735], Loss: 0.3342\n",
      "Epoch [48/50], Step [559/735], Loss: 0.0379\n",
      "Epoch [48/50], Step [560/735], Loss: 0.0810\n",
      "Epoch [48/50], Step [561/735], Loss: 0.0724\n",
      "Epoch [48/50], Step [562/735], Loss: 0.0403\n",
      "Epoch [48/50], Step [563/735], Loss: 0.0731\n",
      "Epoch [48/50], Step [564/735], Loss: 0.0506\n",
      "Epoch [48/50], Step [565/735], Loss: 0.1150\n",
      "Epoch [48/50], Step [566/735], Loss: 0.0226\n",
      "Epoch [48/50], Step [567/735], Loss: 0.2539\n",
      "Epoch [48/50], Step [568/735], Loss: 0.0524\n",
      "Epoch [48/50], Step [569/735], Loss: 0.0295\n",
      "Epoch [48/50], Step [570/735], Loss: 0.0564\n",
      "Epoch [48/50], Step [571/735], Loss: 0.0536\n",
      "Epoch [48/50], Step [572/735], Loss: 0.0560\n",
      "Epoch [48/50], Step [573/735], Loss: 0.0989\n",
      "Epoch [48/50], Step [574/735], Loss: 0.0241\n",
      "Epoch [48/50], Step [575/735], Loss: 0.0568\n",
      "Epoch [48/50], Step [576/735], Loss: 0.0618\n",
      "Epoch [48/50], Step [577/735], Loss: 0.0466\n",
      "Epoch [48/50], Step [578/735], Loss: 0.0647\n",
      "Epoch [48/50], Step [579/735], Loss: 0.0282\n",
      "Epoch [48/50], Step [580/735], Loss: 0.0583\n",
      "Epoch [48/50], Step [581/735], Loss: 0.0829\n",
      "Epoch [48/50], Step [582/735], Loss: 0.0384\n",
      "Epoch [48/50], Step [583/735], Loss: 0.0196\n",
      "Epoch [48/50], Step [584/735], Loss: 0.0611\n",
      "Epoch [48/50], Step [585/735], Loss: 0.0289\n",
      "Epoch [48/50], Step [586/735], Loss: 0.0320\n",
      "Epoch [48/50], Step [587/735], Loss: 0.0469\n",
      "Epoch [48/50], Step [588/735], Loss: 0.0720\n",
      "Epoch [48/50], Step [589/735], Loss: 0.0291\n",
      "Epoch [48/50], Step [590/735], Loss: 0.0463\n",
      "Epoch [48/50], Step [591/735], Loss: 0.0501\n",
      "Epoch [48/50], Step [592/735], Loss: 0.0540\n",
      "Epoch [48/50], Step [593/735], Loss: 0.0614\n",
      "Epoch [48/50], Step [594/735], Loss: 0.0266\n",
      "Epoch [48/50], Step [595/735], Loss: 0.0475\n",
      "Epoch [48/50], Step [596/735], Loss: 0.0310\n",
      "Epoch [48/50], Step [597/735], Loss: 0.0142\n",
      "Epoch [48/50], Step [598/735], Loss: 0.0330\n",
      "Epoch [48/50], Step [599/735], Loss: 0.0555\n",
      "Epoch [48/50], Step [600/735], Loss: 0.0177\n",
      "Epoch [48/50], Step [601/735], Loss: 0.0752\n",
      "Epoch [48/50], Step [602/735], Loss: 0.1170\n",
      "Epoch [48/50], Step [603/735], Loss: 0.0639\n",
      "Epoch [48/50], Step [604/735], Loss: 0.0639\n",
      "Epoch [48/50], Step [605/735], Loss: 0.0678\n",
      "Epoch [48/50], Step [606/735], Loss: 0.0342\n",
      "Epoch [48/50], Step [607/735], Loss: 0.0715\n",
      "Epoch [48/50], Step [608/735], Loss: 0.0590\n",
      "Epoch [48/50], Step [609/735], Loss: 0.0361\n",
      "Epoch [48/50], Step [610/735], Loss: 0.0411\n",
      "Epoch [48/50], Step [611/735], Loss: 0.0269\n",
      "Epoch [48/50], Step [612/735], Loss: 0.1460\n",
      "Epoch [48/50], Step [613/735], Loss: 0.1074\n",
      "Epoch [48/50], Step [614/735], Loss: 0.0380\n",
      "Epoch [48/50], Step [615/735], Loss: 0.0423\n",
      "Epoch [48/50], Step [616/735], Loss: 0.0251\n",
      "Epoch [48/50], Step [617/735], Loss: 0.1135\n",
      "Epoch [48/50], Step [618/735], Loss: 0.0175\n",
      "Epoch [48/50], Step [619/735], Loss: 0.0177\n",
      "Epoch [48/50], Step [620/735], Loss: 0.1044\n",
      "Epoch [48/50], Step [621/735], Loss: 0.0299\n",
      "Epoch [48/50], Step [622/735], Loss: 0.0337\n",
      "Epoch [48/50], Step [623/735], Loss: 0.1012\n",
      "Epoch [48/50], Step [624/735], Loss: 0.0206\n",
      "Epoch [48/50], Step [625/735], Loss: 0.0248\n",
      "Epoch [48/50], Step [626/735], Loss: 0.0354\n",
      "Epoch [48/50], Step [627/735], Loss: 0.1605\n",
      "Epoch [48/50], Step [628/735], Loss: 0.0975\n",
      "Epoch [48/50], Step [629/735], Loss: 0.0762\n",
      "Epoch [48/50], Step [630/735], Loss: 0.0422\n",
      "Epoch [48/50], Step [631/735], Loss: 0.0250\n",
      "Epoch [48/50], Step [632/735], Loss: 0.0314\n",
      "Epoch [48/50], Step [633/735], Loss: 0.0313\n",
      "Epoch [48/50], Step [634/735], Loss: 0.0554\n",
      "Epoch [48/50], Step [635/735], Loss: 0.0352\n",
      "Epoch [48/50], Step [636/735], Loss: 0.0183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Step [637/735], Loss: 0.0419\n",
      "Epoch [48/50], Step [638/735], Loss: 0.0826\n",
      "Epoch [48/50], Step [639/735], Loss: 0.0826\n",
      "Epoch [48/50], Step [640/735], Loss: 0.0459\n",
      "Epoch [48/50], Step [641/735], Loss: 0.0276\n",
      "Epoch [48/50], Step [642/735], Loss: 0.0463\n",
      "Epoch [48/50], Step [643/735], Loss: 0.0521\n",
      "Epoch [48/50], Step [644/735], Loss: 0.0816\n",
      "Epoch [48/50], Step [645/735], Loss: 0.0839\n",
      "Epoch [48/50], Step [646/735], Loss: 0.0202\n",
      "Epoch [48/50], Step [647/735], Loss: 0.0340\n",
      "Epoch [48/50], Step [648/735], Loss: 0.0520\n",
      "Epoch [48/50], Step [649/735], Loss: 0.0329\n",
      "Epoch [48/50], Step [650/735], Loss: 0.0391\n",
      "Epoch [48/50], Step [651/735], Loss: 0.0785\n",
      "Epoch [48/50], Step [652/735], Loss: 0.0890\n",
      "Epoch [48/50], Step [653/735], Loss: 0.0274\n",
      "Epoch [48/50], Step [654/735], Loss: 0.0430\n",
      "Epoch [48/50], Step [655/735], Loss: 0.0181\n",
      "Epoch [48/50], Step [656/735], Loss: 0.0960\n",
      "Epoch [48/50], Step [657/735], Loss: 0.0270\n",
      "Epoch [48/50], Step [658/735], Loss: 0.0650\n",
      "Epoch [48/50], Step [659/735], Loss: 0.0396\n",
      "Epoch [48/50], Step [660/735], Loss: 0.0169\n",
      "Epoch [48/50], Step [661/735], Loss: 0.0193\n",
      "Epoch [48/50], Step [662/735], Loss: 0.0759\n",
      "Epoch [48/50], Step [663/735], Loss: 0.0557\n",
      "Epoch [48/50], Step [664/735], Loss: 0.1631\n",
      "Epoch [48/50], Step [665/735], Loss: 0.0237\n",
      "Epoch [48/50], Step [666/735], Loss: 0.0921\n",
      "Epoch [48/50], Step [667/735], Loss: 0.0266\n",
      "Epoch [48/50], Step [668/735], Loss: 0.0715\n",
      "Epoch [48/50], Step [669/735], Loss: 0.0746\n",
      "Epoch [48/50], Step [670/735], Loss: 0.0229\n",
      "Epoch [48/50], Step [671/735], Loss: 0.0349\n",
      "Epoch [48/50], Step [672/735], Loss: 0.0524\n",
      "Epoch [48/50], Step [673/735], Loss: 0.0439\n",
      "Epoch [48/50], Step [674/735], Loss: 0.0344\n",
      "Epoch [48/50], Step [675/735], Loss: 0.0231\n",
      "Epoch [48/50], Step [676/735], Loss: 0.0404\n",
      "Epoch [48/50], Step [677/735], Loss: 0.0391\n",
      "Epoch [48/50], Step [678/735], Loss: 0.0525\n",
      "Epoch [48/50], Step [679/735], Loss: 0.0731\n",
      "Epoch [48/50], Step [680/735], Loss: 0.0175\n",
      "Epoch [48/50], Step [681/735], Loss: 0.0743\n",
      "Epoch [48/50], Step [682/735], Loss: 0.0146\n",
      "Epoch [48/50], Step [683/735], Loss: 0.0401\n",
      "Epoch [48/50], Step [684/735], Loss: 0.0536\n",
      "Epoch [48/50], Step [685/735], Loss: 0.0434\n",
      "Epoch [48/50], Step [686/735], Loss: 0.0228\n",
      "Epoch [48/50], Step [687/735], Loss: 0.0901\n",
      "Epoch [48/50], Step [688/735], Loss: 0.0256\n",
      "Epoch [48/50], Step [689/735], Loss: 0.0429\n",
      "Epoch [48/50], Step [690/735], Loss: 0.0704\n",
      "Epoch [48/50], Step [691/735], Loss: 0.0184\n",
      "Epoch [48/50], Step [692/735], Loss: 0.1570\n",
      "Epoch [48/50], Step [693/735], Loss: 0.1392\n",
      "Epoch [48/50], Step [694/735], Loss: 0.0575\n",
      "Epoch [48/50], Step [695/735], Loss: 0.0256\n",
      "Epoch [48/50], Step [696/735], Loss: 0.0518\n",
      "Epoch [48/50], Step [697/735], Loss: 0.0475\n",
      "Epoch [48/50], Step [698/735], Loss: 0.0163\n",
      "Epoch [48/50], Step [699/735], Loss: 0.0636\n",
      "Epoch [48/50], Step [700/735], Loss: 0.0775\n",
      "Epoch [48/50], Step [701/735], Loss: 0.0547\n",
      "Epoch [48/50], Step [702/735], Loss: 0.0766\n",
      "Epoch [48/50], Step [703/735], Loss: 0.0370\n",
      "Epoch [48/50], Step [704/735], Loss: 0.0402\n",
      "Epoch [48/50], Step [705/735], Loss: 0.0552\n",
      "Epoch [48/50], Step [706/735], Loss: 0.0963\n",
      "Epoch [48/50], Step [707/735], Loss: 0.0395\n",
      "Epoch [48/50], Step [708/735], Loss: 0.0719\n",
      "Epoch [48/50], Step [709/735], Loss: 0.0244\n",
      "Epoch [48/50], Step [710/735], Loss: 0.0693\n",
      "Epoch [48/50], Step [711/735], Loss: 0.0388\n",
      "Epoch [48/50], Step [712/735], Loss: 0.0352\n",
      "Epoch [48/50], Step [713/735], Loss: 0.0455\n",
      "Epoch [48/50], Step [714/735], Loss: 0.0533\n",
      "Epoch [48/50], Step [715/735], Loss: 0.0637\n",
      "Epoch [48/50], Step [716/735], Loss: 0.0439\n",
      "Epoch [48/50], Step [717/735], Loss: 0.0784\n",
      "Epoch [48/50], Step [718/735], Loss: 0.0460\n",
      "Epoch [48/50], Step [719/735], Loss: 0.0573\n",
      "Epoch [48/50], Step [720/735], Loss: 0.1014\n",
      "Epoch [48/50], Step [721/735], Loss: 0.0341\n",
      "Epoch [48/50], Step [722/735], Loss: 0.0744\n",
      "Epoch [48/50], Step [723/735], Loss: 0.0591\n",
      "Epoch [48/50], Step [724/735], Loss: 0.0258\n",
      "Epoch [48/50], Step [725/735], Loss: 0.0399\n",
      "Epoch [48/50], Step [726/735], Loss: 0.0220\n",
      "Epoch [48/50], Step [727/735], Loss: 0.0258\n",
      "Epoch [48/50], Step [728/735], Loss: 0.0545\n",
      "Epoch [48/50], Step [729/735], Loss: 0.0478\n",
      "Epoch [48/50], Step [730/735], Loss: 0.0495\n",
      "Epoch [48/50], Step [731/735], Loss: 0.3577\n",
      "Epoch [48/50], Step [732/735], Loss: 0.1405\n",
      "Epoch [48/50], Step [733/735], Loss: 0.0357\n",
      "Epoch [48/50], Step [734/735], Loss: 0.0745\n",
      "Epoch [48/50], Step [735/735], Loss: 0.0363\n",
      "Epoch [49/50], Step [1/735], Loss: 0.0226\n",
      "Epoch [49/50], Step [2/735], Loss: 0.0395\n",
      "Epoch [49/50], Step [3/735], Loss: 0.0319\n",
      "Epoch [49/50], Step [4/735], Loss: 0.1016\n",
      "Epoch [49/50], Step [5/735], Loss: 0.0457\n",
      "Epoch [49/50], Step [6/735], Loss: 0.1136\n",
      "Epoch [49/50], Step [7/735], Loss: 0.0516\n",
      "Epoch [49/50], Step [8/735], Loss: 0.0390\n",
      "Epoch [49/50], Step [9/735], Loss: 0.1387\n",
      "Epoch [49/50], Step [10/735], Loss: 0.0496\n",
      "Epoch [49/50], Step [11/735], Loss: 0.0902\n",
      "Epoch [49/50], Step [12/735], Loss: 0.0462\n",
      "Epoch [49/50], Step [13/735], Loss: 0.1183\n",
      "Epoch [49/50], Step [14/735], Loss: 0.0391\n",
      "Epoch [49/50], Step [15/735], Loss: 0.2490\n",
      "Epoch [49/50], Step [16/735], Loss: 0.0895\n",
      "Epoch [49/50], Step [17/735], Loss: 0.0587\n",
      "Epoch [49/50], Step [18/735], Loss: 0.0475\n",
      "Epoch [49/50], Step [19/735], Loss: 0.0484\n",
      "Epoch [49/50], Step [20/735], Loss: 0.1543\n",
      "Epoch [49/50], Step [21/735], Loss: 0.0330\n",
      "Epoch [49/50], Step [22/735], Loss: 0.0647\n",
      "Epoch [49/50], Step [23/735], Loss: 0.0580\n",
      "Epoch [49/50], Step [24/735], Loss: 0.0916\n",
      "Epoch [49/50], Step [25/735], Loss: 0.0554\n",
      "Epoch [49/50], Step [26/735], Loss: 0.0456\n",
      "Epoch [49/50], Step [27/735], Loss: 0.0381\n",
      "Epoch [49/50], Step [28/735], Loss: 0.0701\n",
      "Epoch [49/50], Step [29/735], Loss: 0.0435\n",
      "Epoch [49/50], Step [30/735], Loss: 0.0381\n",
      "Epoch [49/50], Step [31/735], Loss: 0.1035\n",
      "Epoch [49/50], Step [32/735], Loss: 0.0194\n",
      "Epoch [49/50], Step [33/735], Loss: 0.0259\n",
      "Epoch [49/50], Step [34/735], Loss: 0.0971\n",
      "Epoch [49/50], Step [35/735], Loss: 0.0299\n",
      "Epoch [49/50], Step [36/735], Loss: 0.0200\n",
      "Epoch [49/50], Step [37/735], Loss: 0.0286\n",
      "Epoch [49/50], Step [38/735], Loss: 0.0274\n",
      "Epoch [49/50], Step [39/735], Loss: 0.0521\n",
      "Epoch [49/50], Step [40/735], Loss: 0.0389\n",
      "Epoch [49/50], Step [41/735], Loss: 0.0201\n",
      "Epoch [49/50], Step [42/735], Loss: 0.0593\n",
      "Epoch [49/50], Step [43/735], Loss: 0.0646\n",
      "Epoch [49/50], Step [44/735], Loss: 0.0650\n",
      "Epoch [49/50], Step [45/735], Loss: 0.0531\n",
      "Epoch [49/50], Step [46/735], Loss: 0.0416\n",
      "Epoch [49/50], Step [47/735], Loss: 0.0577\n",
      "Epoch [49/50], Step [48/735], Loss: 0.0257\n",
      "Epoch [49/50], Step [49/735], Loss: 0.0356\n",
      "Epoch [49/50], Step [50/735], Loss: 0.0346\n",
      "Epoch [49/50], Step [51/735], Loss: 0.0358\n",
      "Epoch [49/50], Step [52/735], Loss: 0.0563\n",
      "Epoch [49/50], Step [53/735], Loss: 0.2037\n",
      "Epoch [49/50], Step [54/735], Loss: 0.0210\n",
      "Epoch [49/50], Step [55/735], Loss: 0.0166\n",
      "Epoch [49/50], Step [56/735], Loss: 0.0406\n",
      "Epoch [49/50], Step [57/735], Loss: 0.0408\n",
      "Epoch [49/50], Step [58/735], Loss: 0.0288\n",
      "Epoch [49/50], Step [59/735], Loss: 0.0530\n",
      "Epoch [49/50], Step [60/735], Loss: 0.0377\n",
      "Epoch [49/50], Step [61/735], Loss: 0.0405\n",
      "Epoch [49/50], Step [62/735], Loss: 0.0493\n",
      "Epoch [49/50], Step [63/735], Loss: 0.0317\n",
      "Epoch [49/50], Step [64/735], Loss: 0.0364\n",
      "Epoch [49/50], Step [65/735], Loss: 0.0381\n",
      "Epoch [49/50], Step [66/735], Loss: 0.1055\n",
      "Epoch [49/50], Step [67/735], Loss: 0.0331\n",
      "Epoch [49/50], Step [68/735], Loss: 0.0324\n",
      "Epoch [49/50], Step [69/735], Loss: 0.0742\n",
      "Epoch [49/50], Step [70/735], Loss: 0.0515\n",
      "Epoch [49/50], Step [71/735], Loss: 0.1486\n",
      "Epoch [49/50], Step [72/735], Loss: 0.0640\n",
      "Epoch [49/50], Step [73/735], Loss: 0.0765\n",
      "Epoch [49/50], Step [74/735], Loss: 0.0567\n",
      "Epoch [49/50], Step [75/735], Loss: 0.0821\n",
      "Epoch [49/50], Step [76/735], Loss: 0.0482\n",
      "Epoch [49/50], Step [77/735], Loss: 0.0317\n",
      "Epoch [49/50], Step [78/735], Loss: 0.0247\n",
      "Epoch [49/50], Step [79/735], Loss: 0.0458\n",
      "Epoch [49/50], Step [80/735], Loss: 0.0427\n",
      "Epoch [49/50], Step [81/735], Loss: 0.0736\n",
      "Epoch [49/50], Step [82/735], Loss: 0.0239\n",
      "Epoch [49/50], Step [83/735], Loss: 0.0375\n",
      "Epoch [49/50], Step [84/735], Loss: 0.0949\n",
      "Epoch [49/50], Step [85/735], Loss: 0.0711\n",
      "Epoch [49/50], Step [86/735], Loss: 0.0298\n",
      "Epoch [49/50], Step [87/735], Loss: 0.0413\n",
      "Epoch [49/50], Step [88/735], Loss: 0.0135\n",
      "Epoch [49/50], Step [89/735], Loss: 0.0611\n",
      "Epoch [49/50], Step [90/735], Loss: 0.0667\n",
      "Epoch [49/50], Step [91/735], Loss: 0.0368\n",
      "Epoch [49/50], Step [92/735], Loss: 0.0380\n",
      "Epoch [49/50], Step [93/735], Loss: 0.0280\n",
      "Epoch [49/50], Step [94/735], Loss: 0.1200\n",
      "Epoch [49/50], Step [95/735], Loss: 0.0488\n",
      "Epoch [49/50], Step [96/735], Loss: 0.0423\n",
      "Epoch [49/50], Step [97/735], Loss: 0.0156\n",
      "Epoch [49/50], Step [98/735], Loss: 0.0254\n",
      "Epoch [49/50], Step [99/735], Loss: 0.0433\n",
      "Epoch [49/50], Step [100/735], Loss: 0.0713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Step [101/735], Loss: 0.1620\n",
      "Epoch [49/50], Step [102/735], Loss: 0.0419\n",
      "Epoch [49/50], Step [103/735], Loss: 0.0304\n",
      "Epoch [49/50], Step [104/735], Loss: 0.0669\n",
      "Epoch [49/50], Step [105/735], Loss: 0.0436\n",
      "Epoch [49/50], Step [106/735], Loss: 0.0422\n",
      "Epoch [49/50], Step [107/735], Loss: 0.0346\n",
      "Epoch [49/50], Step [108/735], Loss: 0.0176\n",
      "Epoch [49/50], Step [109/735], Loss: 0.0361\n",
      "Epoch [49/50], Step [110/735], Loss: 0.0566\n",
      "Epoch [49/50], Step [111/735], Loss: 0.0358\n",
      "Epoch [49/50], Step [112/735], Loss: 0.0216\n",
      "Epoch [49/50], Step [113/735], Loss: 0.0168\n",
      "Epoch [49/50], Step [114/735], Loss: 0.0985\n",
      "Epoch [49/50], Step [115/735], Loss: 0.0136\n",
      "Epoch [49/50], Step [116/735], Loss: 0.0456\n",
      "Epoch [49/50], Step [117/735], Loss: 0.0313\n",
      "Epoch [49/50], Step [118/735], Loss: 0.0265\n",
      "Epoch [49/50], Step [119/735], Loss: 0.0679\n",
      "Epoch [49/50], Step [120/735], Loss: 0.0430\n",
      "Epoch [49/50], Step [121/735], Loss: 0.0467\n",
      "Epoch [49/50], Step [122/735], Loss: 0.0150\n",
      "Epoch [49/50], Step [123/735], Loss: 0.0225\n",
      "Epoch [49/50], Step [124/735], Loss: 0.0126\n",
      "Epoch [49/50], Step [125/735], Loss: 0.0177\n",
      "Epoch [49/50], Step [126/735], Loss: 0.0228\n",
      "Epoch [49/50], Step [127/735], Loss: 0.0180\n",
      "Epoch [49/50], Step [128/735], Loss: 0.0462\n",
      "Epoch [49/50], Step [129/735], Loss: 0.0237\n",
      "Epoch [49/50], Step [130/735], Loss: 0.0291\n",
      "Epoch [49/50], Step [131/735], Loss: 0.0641\n",
      "Epoch [49/50], Step [132/735], Loss: 0.0661\n",
      "Epoch [49/50], Step [133/735], Loss: 0.1052\n",
      "Epoch [49/50], Step [134/735], Loss: 0.0893\n",
      "Epoch [49/50], Step [135/735], Loss: 0.0479\n",
      "Epoch [49/50], Step [136/735], Loss: 0.0369\n",
      "Epoch [49/50], Step [137/735], Loss: 0.0650\n",
      "Epoch [49/50], Step [138/735], Loss: 0.4185\n",
      "Epoch [49/50], Step [139/735], Loss: 0.0768\n",
      "Epoch [49/50], Step [140/735], Loss: 0.0818\n",
      "Epoch [49/50], Step [141/735], Loss: 0.0235\n",
      "Epoch [49/50], Step [142/735], Loss: 0.0360\n",
      "Epoch [49/50], Step [143/735], Loss: 0.0880\n",
      "Epoch [49/50], Step [144/735], Loss: 0.4710\n",
      "Epoch [49/50], Step [145/735], Loss: 0.0290\n",
      "Epoch [49/50], Step [146/735], Loss: 0.0400\n",
      "Epoch [49/50], Step [147/735], Loss: 0.0588\n",
      "Epoch [49/50], Step [148/735], Loss: 0.3955\n",
      "Epoch [49/50], Step [149/735], Loss: 0.1746\n",
      "Epoch [49/50], Step [150/735], Loss: 0.0339\n",
      "Epoch [49/50], Step [151/735], Loss: 0.0923\n",
      "Epoch [49/50], Step [152/735], Loss: 0.0631\n",
      "Epoch [49/50], Step [153/735], Loss: 0.0542\n",
      "Epoch [49/50], Step [154/735], Loss: 0.1267\n",
      "Epoch [49/50], Step [155/735], Loss: 0.0754\n",
      "Epoch [49/50], Step [156/735], Loss: 0.0618\n",
      "Epoch [49/50], Step [157/735], Loss: 0.0649\n",
      "Epoch [49/50], Step [158/735], Loss: 0.1215\n",
      "Epoch [49/50], Step [159/735], Loss: 0.1815\n",
      "Epoch [49/50], Step [160/735], Loss: 0.0618\n",
      "Epoch [49/50], Step [161/735], Loss: 0.0494\n",
      "Epoch [49/50], Step [162/735], Loss: 0.1132\n",
      "Epoch [49/50], Step [163/735], Loss: 0.0648\n",
      "Epoch [49/50], Step [164/735], Loss: 0.0432\n",
      "Epoch [49/50], Step [165/735], Loss: 0.0289\n",
      "Epoch [49/50], Step [166/735], Loss: 0.0313\n",
      "Epoch [49/50], Step [167/735], Loss: 0.1098\n",
      "Epoch [49/50], Step [168/735], Loss: 0.0691\n",
      "Epoch [49/50], Step [169/735], Loss: 0.0376\n",
      "Epoch [49/50], Step [170/735], Loss: 0.0855\n",
      "Epoch [49/50], Step [171/735], Loss: 0.0662\n",
      "Epoch [49/50], Step [172/735], Loss: 0.1065\n",
      "Epoch [49/50], Step [173/735], Loss: 0.0367\n",
      "Epoch [49/50], Step [174/735], Loss: 0.0501\n",
      "Epoch [49/50], Step [175/735], Loss: 0.0331\n",
      "Epoch [49/50], Step [176/735], Loss: 0.0332\n",
      "Epoch [49/50], Step [177/735], Loss: 0.0638\n",
      "Epoch [49/50], Step [178/735], Loss: 0.1091\n",
      "Epoch [49/50], Step [179/735], Loss: 0.0358\n",
      "Epoch [49/50], Step [180/735], Loss: 0.0609\n",
      "Epoch [49/50], Step [181/735], Loss: 0.1771\n",
      "Epoch [49/50], Step [182/735], Loss: 0.0505\n",
      "Epoch [49/50], Step [183/735], Loss: 0.0263\n",
      "Epoch [49/50], Step [184/735], Loss: 0.0448\n",
      "Epoch [49/50], Step [185/735], Loss: 0.0845\n",
      "Epoch [49/50], Step [186/735], Loss: 0.0521\n",
      "Epoch [49/50], Step [187/735], Loss: 0.1118\n",
      "Epoch [49/50], Step [188/735], Loss: 0.2059\n",
      "Epoch [49/50], Step [189/735], Loss: 0.0366\n",
      "Epoch [49/50], Step [190/735], Loss: 0.0842\n",
      "Epoch [49/50], Step [191/735], Loss: 0.0762\n",
      "Epoch [49/50], Step [192/735], Loss: 0.0277\n",
      "Epoch [49/50], Step [193/735], Loss: 0.0489\n",
      "Epoch [49/50], Step [194/735], Loss: 0.0539\n",
      "Epoch [49/50], Step [195/735], Loss: 0.0431\n",
      "Epoch [49/50], Step [196/735], Loss: 0.0338\n",
      "Epoch [49/50], Step [197/735], Loss: 0.0518\n",
      "Epoch [49/50], Step [198/735], Loss: 0.0514\n",
      "Epoch [49/50], Step [199/735], Loss: 0.0613\n",
      "Epoch [49/50], Step [200/735], Loss: 0.0969\n",
      "Epoch [49/50], Step [201/735], Loss: 0.0420\n",
      "Epoch [49/50], Step [202/735], Loss: 0.0587\n",
      "Epoch [49/50], Step [203/735], Loss: 0.0739\n",
      "Epoch [49/50], Step [204/735], Loss: 0.0456\n",
      "Epoch [49/50], Step [205/735], Loss: 0.1841\n",
      "Epoch [49/50], Step [206/735], Loss: 0.1034\n",
      "Epoch [49/50], Step [207/735], Loss: 0.0322\n",
      "Epoch [49/50], Step [208/735], Loss: 0.0814\n",
      "Epoch [49/50], Step [209/735], Loss: 0.0257\n",
      "Epoch [49/50], Step [210/735], Loss: 0.1142\n",
      "Epoch [49/50], Step [211/735], Loss: 0.0827\n",
      "Epoch [49/50], Step [212/735], Loss: 0.0863\n",
      "Epoch [49/50], Step [213/735], Loss: 0.0494\n",
      "Epoch [49/50], Step [214/735], Loss: 0.0202\n",
      "Epoch [49/50], Step [215/735], Loss: 0.0355\n",
      "Epoch [49/50], Step [216/735], Loss: 0.0691\n",
      "Epoch [49/50], Step [217/735], Loss: 0.0519\n",
      "Epoch [49/50], Step [218/735], Loss: 0.0254\n",
      "Epoch [49/50], Step [219/735], Loss: 0.0303\n",
      "Epoch [49/50], Step [220/735], Loss: 0.0642\n",
      "Epoch [49/50], Step [221/735], Loss: 0.0303\n",
      "Epoch [49/50], Step [222/735], Loss: 0.0472\n",
      "Epoch [49/50], Step [223/735], Loss: 0.0381\n",
      "Epoch [49/50], Step [224/735], Loss: 0.0917\n",
      "Epoch [49/50], Step [225/735], Loss: 0.0510\n",
      "Epoch [49/50], Step [226/735], Loss: 0.0334\n",
      "Epoch [49/50], Step [227/735], Loss: 0.0697\n",
      "Epoch [49/50], Step [228/735], Loss: 0.0665\n",
      "Epoch [49/50], Step [229/735], Loss: 0.0961\n",
      "Epoch [49/50], Step [230/735], Loss: 0.0757\n",
      "Epoch [49/50], Step [231/735], Loss: 0.0533\n",
      "Epoch [49/50], Step [232/735], Loss: 0.2307\n",
      "Epoch [49/50], Step [233/735], Loss: 0.0410\n",
      "Epoch [49/50], Step [234/735], Loss: 0.0128\n",
      "Epoch [49/50], Step [235/735], Loss: 0.0503\n",
      "Epoch [49/50], Step [236/735], Loss: 0.0548\n",
      "Epoch [49/50], Step [237/735], Loss: 0.0972\n",
      "Epoch [49/50], Step [238/735], Loss: 0.0845\n",
      "Epoch [49/50], Step [239/735], Loss: 0.0626\n",
      "Epoch [49/50], Step [240/735], Loss: 0.0540\n",
      "Epoch [49/50], Step [241/735], Loss: 0.0293\n",
      "Epoch [49/50], Step [242/735], Loss: 0.0191\n",
      "Epoch [49/50], Step [243/735], Loss: 0.0245\n",
      "Epoch [49/50], Step [244/735], Loss: 0.1067\n",
      "Epoch [49/50], Step [245/735], Loss: 0.0504\n",
      "Epoch [49/50], Step [246/735], Loss: 0.0239\n",
      "Epoch [49/50], Step [247/735], Loss: 0.0411\n",
      "Epoch [49/50], Step [248/735], Loss: 0.0381\n",
      "Epoch [49/50], Step [249/735], Loss: 0.0282\n",
      "Epoch [49/50], Step [250/735], Loss: 0.0374\n",
      "Epoch [49/50], Step [251/735], Loss: 0.0578\n",
      "Epoch [49/50], Step [252/735], Loss: 0.0323\n",
      "Epoch [49/50], Step [253/735], Loss: 0.0385\n",
      "Epoch [49/50], Step [254/735], Loss: 0.0440\n",
      "Epoch [49/50], Step [255/735], Loss: 0.0370\n",
      "Epoch [49/50], Step [256/735], Loss: 0.0511\n",
      "Epoch [49/50], Step [257/735], Loss: 0.0390\n",
      "Epoch [49/50], Step [258/735], Loss: 0.0285\n",
      "Epoch [49/50], Step [259/735], Loss: 0.0296\n",
      "Epoch [49/50], Step [260/735], Loss: 0.3162\n",
      "Epoch [49/50], Step [261/735], Loss: 0.1121\n",
      "Epoch [49/50], Step [262/735], Loss: 0.0791\n",
      "Epoch [49/50], Step [263/735], Loss: 0.0572\n",
      "Epoch [49/50], Step [264/735], Loss: 0.0619\n",
      "Epoch [49/50], Step [265/735], Loss: 0.0228\n",
      "Epoch [49/50], Step [266/735], Loss: 0.0395\n",
      "Epoch [49/50], Step [267/735], Loss: 0.0413\n",
      "Epoch [49/50], Step [268/735], Loss: 0.0334\n",
      "Epoch [49/50], Step [269/735], Loss: 0.0223\n",
      "Epoch [49/50], Step [270/735], Loss: 0.0650\n",
      "Epoch [49/50], Step [271/735], Loss: 0.0499\n",
      "Epoch [49/50], Step [272/735], Loss: 0.1075\n",
      "Epoch [49/50], Step [273/735], Loss: 0.0560\n",
      "Epoch [49/50], Step [274/735], Loss: 0.0627\n",
      "Epoch [49/50], Step [275/735], Loss: 0.0736\n",
      "Epoch [49/50], Step [276/735], Loss: 0.0428\n",
      "Epoch [49/50], Step [277/735], Loss: 0.0456\n",
      "Epoch [49/50], Step [278/735], Loss: 0.0164\n",
      "Epoch [49/50], Step [279/735], Loss: 0.0216\n",
      "Epoch [49/50], Step [280/735], Loss: 0.0346\n",
      "Epoch [49/50], Step [281/735], Loss: 0.0353\n",
      "Epoch [49/50], Step [282/735], Loss: 0.0485\n",
      "Epoch [49/50], Step [283/735], Loss: 0.0417\n",
      "Epoch [49/50], Step [284/735], Loss: 0.0524\n",
      "Epoch [49/50], Step [285/735], Loss: 0.0354\n",
      "Epoch [49/50], Step [286/735], Loss: 0.0985\n",
      "Epoch [49/50], Step [287/735], Loss: 0.0245\n",
      "Epoch [49/50], Step [288/735], Loss: 0.0433\n",
      "Epoch [49/50], Step [289/735], Loss: 0.0467\n",
      "Epoch [49/50], Step [290/735], Loss: 0.0457\n",
      "Epoch [49/50], Step [291/735], Loss: 0.0504\n",
      "Epoch [49/50], Step [292/735], Loss: 0.0269\n",
      "Epoch [49/50], Step [293/735], Loss: 0.0436\n",
      "Epoch [49/50], Step [294/735], Loss: 0.0385\n",
      "Epoch [49/50], Step [295/735], Loss: 0.0549\n",
      "Epoch [49/50], Step [296/735], Loss: 0.0724\n",
      "Epoch [49/50], Step [297/735], Loss: 0.0145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Step [298/735], Loss: 0.0579\n",
      "Epoch [49/50], Step [299/735], Loss: 0.0410\n",
      "Epoch [49/50], Step [300/735], Loss: 0.0735\n",
      "Epoch [49/50], Step [301/735], Loss: 0.0359\n",
      "Epoch [49/50], Step [302/735], Loss: 0.0685\n",
      "Epoch [49/50], Step [303/735], Loss: 0.0554\n",
      "Epoch [49/50], Step [304/735], Loss: 0.0235\n",
      "Epoch [49/50], Step [305/735], Loss: 0.0327\n",
      "Epoch [49/50], Step [306/735], Loss: 0.1214\n",
      "Epoch [49/50], Step [307/735], Loss: 0.0549\n",
      "Epoch [49/50], Step [308/735], Loss: 0.0410\n",
      "Epoch [49/50], Step [309/735], Loss: 0.1464\n",
      "Epoch [49/50], Step [310/735], Loss: 0.0292\n",
      "Epoch [49/50], Step [311/735], Loss: 0.0420\n",
      "Epoch [49/50], Step [312/735], Loss: 0.0338\n",
      "Epoch [49/50], Step [313/735], Loss: 0.0258\n",
      "Epoch [49/50], Step [314/735], Loss: 0.0302\n",
      "Epoch [49/50], Step [315/735], Loss: 0.0265\n",
      "Epoch [49/50], Step [316/735], Loss: 0.0379\n",
      "Epoch [49/50], Step [317/735], Loss: 0.0786\n",
      "Epoch [49/50], Step [318/735], Loss: 0.0279\n",
      "Epoch [49/50], Step [319/735], Loss: 0.2167\n",
      "Epoch [49/50], Step [320/735], Loss: 0.0407\n",
      "Epoch [49/50], Step [321/735], Loss: 0.0593\n",
      "Epoch [49/50], Step [322/735], Loss: 0.0795\n",
      "Epoch [49/50], Step [323/735], Loss: 0.0842\n",
      "Epoch [49/50], Step [324/735], Loss: 0.0222\n",
      "Epoch [49/50], Step [325/735], Loss: 0.0722\n",
      "Epoch [49/50], Step [326/735], Loss: 0.1544\n",
      "Epoch [49/50], Step [327/735], Loss: 0.0312\n",
      "Epoch [49/50], Step [328/735], Loss: 0.0789\n",
      "Epoch [49/50], Step [329/735], Loss: 0.0725\n",
      "Epoch [49/50], Step [330/735], Loss: 0.0802\n",
      "Epoch [49/50], Step [331/735], Loss: 0.0825\n",
      "Epoch [49/50], Step [332/735], Loss: 0.0697\n",
      "Epoch [49/50], Step [333/735], Loss: 0.0640\n",
      "Epoch [49/50], Step [334/735], Loss: 0.1404\n",
      "Epoch [49/50], Step [335/735], Loss: 0.0212\n",
      "Epoch [49/50], Step [336/735], Loss: 0.0234\n",
      "Epoch [49/50], Step [337/735], Loss: 0.0434\n",
      "Epoch [49/50], Step [338/735], Loss: 0.0508\n",
      "Epoch [49/50], Step [339/735], Loss: 0.0357\n",
      "Epoch [49/50], Step [340/735], Loss: 0.2388\n",
      "Epoch [49/50], Step [341/735], Loss: 0.0624\n",
      "Epoch [49/50], Step [342/735], Loss: 0.0541\n",
      "Epoch [49/50], Step [343/735], Loss: 0.0633\n",
      "Epoch [49/50], Step [344/735], Loss: 0.0302\n",
      "Epoch [49/50], Step [345/735], Loss: 0.0532\n",
      "Epoch [49/50], Step [346/735], Loss: 0.0252\n",
      "Epoch [49/50], Step [347/735], Loss: 0.0178\n",
      "Epoch [49/50], Step [348/735], Loss: 0.0248\n",
      "Epoch [49/50], Step [349/735], Loss: 0.0452\n",
      "Epoch [49/50], Step [350/735], Loss: 0.0832\n",
      "Epoch [49/50], Step [351/735], Loss: 0.0223\n",
      "Epoch [49/50], Step [352/735], Loss: 0.1162\n",
      "Epoch [49/50], Step [353/735], Loss: 0.0458\n",
      "Epoch [49/50], Step [354/735], Loss: 0.0688\n",
      "Epoch [49/50], Step [355/735], Loss: 0.0148\n",
      "Epoch [49/50], Step [356/735], Loss: 0.0277\n",
      "Epoch [49/50], Step [357/735], Loss: 0.0410\n",
      "Epoch [49/50], Step [358/735], Loss: 0.1185\n",
      "Epoch [49/50], Step [359/735], Loss: 0.0155\n",
      "Epoch [49/50], Step [360/735], Loss: 0.0251\n",
      "Epoch [49/50], Step [361/735], Loss: 0.0646\n",
      "Epoch [49/50], Step [362/735], Loss: 0.1562\n",
      "Epoch [49/50], Step [363/735], Loss: 0.0736\n",
      "Epoch [49/50], Step [364/735], Loss: 0.0554\n",
      "Epoch [49/50], Step [365/735], Loss: 0.0434\n",
      "Epoch [49/50], Step [366/735], Loss: 0.0421\n",
      "Epoch [49/50], Step [367/735], Loss: 0.0455\n",
      "Epoch [49/50], Step [368/735], Loss: 0.0843\n",
      "Epoch [49/50], Step [369/735], Loss: 0.0825\n",
      "Epoch [49/50], Step [370/735], Loss: 0.0265\n",
      "Epoch [49/50], Step [371/735], Loss: 0.0284\n",
      "Epoch [49/50], Step [372/735], Loss: 0.0181\n",
      "Epoch [49/50], Step [373/735], Loss: 0.0844\n",
      "Epoch [49/50], Step [374/735], Loss: 0.0281\n",
      "Epoch [49/50], Step [375/735], Loss: 0.0226\n",
      "Epoch [49/50], Step [376/735], Loss: 0.0292\n",
      "Epoch [49/50], Step [377/735], Loss: 0.0954\n",
      "Epoch [49/50], Step [378/735], Loss: 0.0761\n",
      "Epoch [49/50], Step [379/735], Loss: 0.0346\n",
      "Epoch [49/50], Step [380/735], Loss: 0.3429\n",
      "Epoch [49/50], Step [381/735], Loss: 0.0192\n",
      "Epoch [49/50], Step [382/735], Loss: 0.0744\n",
      "Epoch [49/50], Step [383/735], Loss: 0.0742\n",
      "Epoch [49/50], Step [384/735], Loss: 0.0385\n",
      "Epoch [49/50], Step [385/735], Loss: 0.0381\n",
      "Epoch [49/50], Step [386/735], Loss: 0.0702\n",
      "Epoch [49/50], Step [387/735], Loss: 0.0236\n",
      "Epoch [49/50], Step [388/735], Loss: 0.0518\n",
      "Epoch [49/50], Step [389/735], Loss: 0.0702\n",
      "Epoch [49/50], Step [390/735], Loss: 0.0516\n",
      "Epoch [49/50], Step [391/735], Loss: 0.0624\n",
      "Epoch [49/50], Step [392/735], Loss: 0.0227\n",
      "Epoch [49/50], Step [393/735], Loss: 0.1035\n",
      "Epoch [49/50], Step [394/735], Loss: 0.0171\n",
      "Epoch [49/50], Step [395/735], Loss: 0.1496\n",
      "Epoch [49/50], Step [396/735], Loss: 0.0185\n",
      "Epoch [49/50], Step [397/735], Loss: 0.0769\n",
      "Epoch [49/50], Step [398/735], Loss: 0.0800\n",
      "Epoch [49/50], Step [399/735], Loss: 0.0355\n",
      "Epoch [49/50], Step [400/735], Loss: 0.0268\n",
      "Epoch [49/50], Step [401/735], Loss: 0.1185\n",
      "Epoch [49/50], Step [402/735], Loss: 0.1465\n",
      "Epoch [49/50], Step [403/735], Loss: 0.0280\n",
      "Epoch [49/50], Step [404/735], Loss: 0.0344\n",
      "Epoch [49/50], Step [405/735], Loss: 0.1065\n",
      "Epoch [49/50], Step [406/735], Loss: 0.0321\n",
      "Epoch [49/50], Step [407/735], Loss: 0.0611\n",
      "Epoch [49/50], Step [408/735], Loss: 0.0636\n",
      "Epoch [49/50], Step [409/735], Loss: 0.0782\n",
      "Epoch [49/50], Step [410/735], Loss: 0.0298\n",
      "Epoch [49/50], Step [411/735], Loss: 0.2390\n",
      "Epoch [49/50], Step [412/735], Loss: 0.0952\n",
      "Epoch [49/50], Step [413/735], Loss: 0.0209\n",
      "Epoch [49/50], Step [414/735], Loss: 0.0540\n",
      "Epoch [49/50], Step [415/735], Loss: 0.0351\n",
      "Epoch [49/50], Step [416/735], Loss: 0.0214\n",
      "Epoch [49/50], Step [417/735], Loss: 0.0354\n",
      "Epoch [49/50], Step [418/735], Loss: 0.0310\n",
      "Epoch [49/50], Step [419/735], Loss: 0.0807\n",
      "Epoch [49/50], Step [420/735], Loss: 0.0426\n",
      "Epoch [49/50], Step [421/735], Loss: 0.1494\n",
      "Epoch [49/50], Step [422/735], Loss: 0.0496\n",
      "Epoch [49/50], Step [423/735], Loss: 0.0367\n",
      "Epoch [49/50], Step [424/735], Loss: 0.0476\n",
      "Epoch [49/50], Step [425/735], Loss: 0.0491\n",
      "Epoch [49/50], Step [426/735], Loss: 0.0695\n",
      "Epoch [49/50], Step [427/735], Loss: 0.0412\n",
      "Epoch [49/50], Step [428/735], Loss: 0.0572\n",
      "Epoch [49/50], Step [429/735], Loss: 0.7246\n",
      "Epoch [49/50], Step [430/735], Loss: 0.0856\n",
      "Epoch [49/50], Step [431/735], Loss: 0.0288\n",
      "Epoch [49/50], Step [432/735], Loss: 0.0873\n",
      "Epoch [49/50], Step [433/735], Loss: 0.0419\n",
      "Epoch [49/50], Step [434/735], Loss: 0.0329\n",
      "Epoch [49/50], Step [435/735], Loss: 0.1554\n",
      "Epoch [49/50], Step [436/735], Loss: 0.0570\n",
      "Epoch [49/50], Step [437/735], Loss: 0.0541\n",
      "Epoch [49/50], Step [438/735], Loss: 0.0294\n",
      "Epoch [49/50], Step [439/735], Loss: 0.0681\n",
      "Epoch [49/50], Step [440/735], Loss: 0.0640\n",
      "Epoch [49/50], Step [441/735], Loss: 0.0364\n",
      "Epoch [49/50], Step [442/735], Loss: 0.0246\n",
      "Epoch [49/50], Step [443/735], Loss: 0.1261\n",
      "Epoch [49/50], Step [444/735], Loss: 0.0306\n",
      "Epoch [49/50], Step [445/735], Loss: 0.1262\n",
      "Epoch [49/50], Step [446/735], Loss: 0.0431\n",
      "Epoch [49/50], Step [447/735], Loss: 0.0382\n",
      "Epoch [49/50], Step [448/735], Loss: 0.0190\n",
      "Epoch [49/50], Step [449/735], Loss: 0.0385\n",
      "Epoch [49/50], Step [450/735], Loss: 0.0417\n",
      "Epoch [49/50], Step [451/735], Loss: 0.1174\n",
      "Epoch [49/50], Step [452/735], Loss: 0.0863\n",
      "Epoch [49/50], Step [453/735], Loss: 0.0208\n",
      "Epoch [49/50], Step [454/735], Loss: 0.0351\n",
      "Epoch [49/50], Step [455/735], Loss: 0.0200\n",
      "Epoch [49/50], Step [456/735], Loss: 0.1113\n",
      "Epoch [49/50], Step [457/735], Loss: 0.0395\n",
      "Epoch [49/50], Step [458/735], Loss: 0.0626\n",
      "Epoch [49/50], Step [459/735], Loss: 0.0415\n",
      "Epoch [49/50], Step [460/735], Loss: 0.1138\n",
      "Epoch [49/50], Step [461/735], Loss: 0.0487\n",
      "Epoch [49/50], Step [462/735], Loss: 0.0447\n",
      "Epoch [49/50], Step [463/735], Loss: 0.0489\n",
      "Epoch [49/50], Step [464/735], Loss: 0.0573\n",
      "Epoch [49/50], Step [465/735], Loss: 0.0319\n",
      "Epoch [49/50], Step [466/735], Loss: 0.0509\n",
      "Epoch [49/50], Step [467/735], Loss: 0.0413\n",
      "Epoch [49/50], Step [468/735], Loss: 0.0350\n",
      "Epoch [49/50], Step [469/735], Loss: 0.0527\n",
      "Epoch [49/50], Step [470/735], Loss: 0.0274\n",
      "Epoch [49/50], Step [471/735], Loss: 0.3565\n",
      "Epoch [49/50], Step [472/735], Loss: 0.0339\n",
      "Epoch [49/50], Step [473/735], Loss: 0.0350\n",
      "Epoch [49/50], Step [474/735], Loss: 0.1118\n",
      "Epoch [49/50], Step [475/735], Loss: 0.0453\n",
      "Epoch [49/50], Step [476/735], Loss: 0.0297\n",
      "Epoch [49/50], Step [477/735], Loss: 0.0644\n",
      "Epoch [49/50], Step [478/735], Loss: 0.0459\n",
      "Epoch [49/50], Step [479/735], Loss: 0.0633\n",
      "Epoch [49/50], Step [480/735], Loss: 0.0318\n",
      "Epoch [49/50], Step [481/735], Loss: 0.0382\n",
      "Epoch [49/50], Step [482/735], Loss: 0.0256\n",
      "Epoch [49/50], Step [483/735], Loss: 0.0422\n",
      "Epoch [49/50], Step [484/735], Loss: 0.0517\n",
      "Epoch [49/50], Step [485/735], Loss: 0.0455\n",
      "Epoch [49/50], Step [486/735], Loss: 0.0485\n",
      "Epoch [49/50], Step [487/735], Loss: 0.0863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Step [488/735], Loss: 0.0677\n",
      "Epoch [49/50], Step [489/735], Loss: 0.0751\n",
      "Epoch [49/50], Step [490/735], Loss: 0.0515\n",
      "Epoch [49/50], Step [491/735], Loss: 0.0557\n",
      "Epoch [49/50], Step [492/735], Loss: 0.0314\n",
      "Epoch [49/50], Step [493/735], Loss: 0.0347\n",
      "Epoch [49/50], Step [494/735], Loss: 0.0619\n",
      "Epoch [49/50], Step [495/735], Loss: 0.0315\n",
      "Epoch [49/50], Step [496/735], Loss: 0.0367\n",
      "Epoch [49/50], Step [497/735], Loss: 0.0382\n",
      "Epoch [49/50], Step [498/735], Loss: 0.0886\n",
      "Epoch [49/50], Step [499/735], Loss: 0.0245\n",
      "Epoch [49/50], Step [500/735], Loss: 0.0301\n",
      "Epoch [49/50], Step [501/735], Loss: 0.0161\n",
      "Epoch [49/50], Step [502/735], Loss: 0.0695\n",
      "Epoch [49/50], Step [503/735], Loss: 0.0429\n",
      "Epoch [49/50], Step [504/735], Loss: 0.0408\n",
      "Epoch [49/50], Step [505/735], Loss: 0.2793\n",
      "Epoch [49/50], Step [506/735], Loss: 0.0473\n",
      "Epoch [49/50], Step [507/735], Loss: 0.0390\n",
      "Epoch [49/50], Step [508/735], Loss: 0.0177\n",
      "Epoch [49/50], Step [509/735], Loss: 0.0594\n",
      "Epoch [49/50], Step [510/735], Loss: 0.0494\n",
      "Epoch [49/50], Step [511/735], Loss: 0.0414\n",
      "Epoch [49/50], Step [512/735], Loss: 0.1822\n",
      "Epoch [49/50], Step [513/735], Loss: 0.0554\n",
      "Epoch [49/50], Step [514/735], Loss: 0.0446\n",
      "Epoch [49/50], Step [515/735], Loss: 0.0217\n",
      "Epoch [49/50], Step [516/735], Loss: 0.0283\n",
      "Epoch [49/50], Step [517/735], Loss: 0.0279\n",
      "Epoch [49/50], Step [518/735], Loss: 0.0539\n",
      "Epoch [49/50], Step [519/735], Loss: 0.0304\n",
      "Epoch [49/50], Step [520/735], Loss: 0.0445\n",
      "Epoch [49/50], Step [521/735], Loss: 0.0951\n",
      "Epoch [49/50], Step [522/735], Loss: 0.0321\n",
      "Epoch [49/50], Step [523/735], Loss: 0.0574\n",
      "Epoch [49/50], Step [524/735], Loss: 0.0853\n",
      "Epoch [49/50], Step [525/735], Loss: 0.0416\n",
      "Epoch [49/50], Step [526/735], Loss: 0.0274\n",
      "Epoch [49/50], Step [527/735], Loss: 0.0574\n",
      "Epoch [49/50], Step [528/735], Loss: 0.0369\n",
      "Epoch [49/50], Step [529/735], Loss: 0.0248\n",
      "Epoch [49/50], Step [530/735], Loss: 0.0256\n",
      "Epoch [49/50], Step [531/735], Loss: 0.0292\n",
      "Epoch [49/50], Step [532/735], Loss: 0.0355\n",
      "Epoch [49/50], Step [533/735], Loss: 0.0845\n",
      "Epoch [49/50], Step [534/735], Loss: 0.0342\n",
      "Epoch [49/50], Step [535/735], Loss: 0.0137\n",
      "Epoch [49/50], Step [536/735], Loss: 0.1246\n",
      "Epoch [49/50], Step [537/735], Loss: 0.0255\n",
      "Epoch [49/50], Step [538/735], Loss: 0.0340\n",
      "Epoch [49/50], Step [539/735], Loss: 0.0224\n",
      "Epoch [49/50], Step [540/735], Loss: 0.0669\n",
      "Epoch [49/50], Step [541/735], Loss: 0.0170\n",
      "Epoch [49/50], Step [542/735], Loss: 0.0142\n",
      "Epoch [49/50], Step [543/735], Loss: 0.0236\n",
      "Epoch [49/50], Step [544/735], Loss: 0.0567\n",
      "Epoch [49/50], Step [545/735], Loss: 0.0325\n",
      "Epoch [49/50], Step [546/735], Loss: 0.0769\n",
      "Epoch [49/50], Step [547/735], Loss: 0.0237\n",
      "Epoch [49/50], Step [548/735], Loss: 0.0505\n",
      "Epoch [49/50], Step [549/735], Loss: 0.0156\n",
      "Epoch [49/50], Step [550/735], Loss: 0.1182\n",
      "Epoch [49/50], Step [551/735], Loss: 0.0789\n",
      "Epoch [49/50], Step [552/735], Loss: 0.0652\n",
      "Epoch [49/50], Step [553/735], Loss: 0.0172\n",
      "Epoch [49/50], Step [554/735], Loss: 0.0369\n",
      "Epoch [49/50], Step [555/735], Loss: 0.0424\n",
      "Epoch [49/50], Step [556/735], Loss: 0.2926\n",
      "Epoch [49/50], Step [557/735], Loss: 0.0636\n",
      "Epoch [49/50], Step [558/735], Loss: 0.0686\n",
      "Epoch [49/50], Step [559/735], Loss: 0.1032\n",
      "Epoch [49/50], Step [560/735], Loss: 0.0531\n",
      "Epoch [49/50], Step [561/735], Loss: 0.1600\n",
      "Epoch [49/50], Step [562/735], Loss: 0.0412\n",
      "Epoch [49/50], Step [563/735], Loss: 0.0488\n",
      "Epoch [49/50], Step [564/735], Loss: 0.0248\n",
      "Epoch [49/50], Step [565/735], Loss: 0.0883\n",
      "Epoch [49/50], Step [566/735], Loss: 0.0614\n",
      "Epoch [49/50], Step [567/735], Loss: 0.0278\n",
      "Epoch [49/50], Step [568/735], Loss: 0.1010\n",
      "Epoch [49/50], Step [569/735], Loss: 0.0655\n",
      "Epoch [49/50], Step [570/735], Loss: 0.0526\n",
      "Epoch [49/50], Step [571/735], Loss: 0.0433\n",
      "Epoch [49/50], Step [572/735], Loss: 0.0414\n",
      "Epoch [49/50], Step [573/735], Loss: 0.0347\n",
      "Epoch [49/50], Step [574/735], Loss: 0.0499\n",
      "Epoch [49/50], Step [575/735], Loss: 0.0238\n",
      "Epoch [49/50], Step [576/735], Loss: 0.0582\n",
      "Epoch [49/50], Step [577/735], Loss: 0.1235\n",
      "Epoch [49/50], Step [578/735], Loss: 0.0189\n",
      "Epoch [49/50], Step [579/735], Loss: 0.0344\n",
      "Epoch [49/50], Step [580/735], Loss: 0.0503\n",
      "Epoch [49/50], Step [581/735], Loss: 0.1385\n",
      "Epoch [49/50], Step [582/735], Loss: 0.0526\n",
      "Epoch [49/50], Step [583/735], Loss: 0.0383\n",
      "Epoch [49/50], Step [584/735], Loss: 0.0326\n",
      "Epoch [49/50], Step [585/735], Loss: 0.0663\n",
      "Epoch [49/50], Step [586/735], Loss: 0.0287\n",
      "Epoch [49/50], Step [587/735], Loss: 0.0298\n",
      "Epoch [49/50], Step [588/735], Loss: 0.0309\n",
      "Epoch [49/50], Step [589/735], Loss: 0.0714\n",
      "Epoch [49/50], Step [590/735], Loss: 0.0487\n",
      "Epoch [49/50], Step [591/735], Loss: 0.0587\n",
      "Epoch [49/50], Step [592/735], Loss: 0.0926\n",
      "Epoch [49/50], Step [593/735], Loss: 0.0408\n",
      "Epoch [49/50], Step [594/735], Loss: 0.0626\n",
      "Epoch [49/50], Step [595/735], Loss: 0.0291\n",
      "Epoch [49/50], Step [596/735], Loss: 0.0216\n",
      "Epoch [49/50], Step [597/735], Loss: 0.0825\n",
      "Epoch [49/50], Step [598/735], Loss: 0.2648\n",
      "Epoch [49/50], Step [599/735], Loss: 0.0422\n",
      "Epoch [49/50], Step [600/735], Loss: 0.0297\n",
      "Epoch [49/50], Step [601/735], Loss: 0.1073\n",
      "Epoch [49/50], Step [602/735], Loss: 0.0770\n",
      "Epoch [49/50], Step [603/735], Loss: 0.0268\n",
      "Epoch [49/50], Step [604/735], Loss: 0.0257\n",
      "Epoch [49/50], Step [605/735], Loss: 0.1485\n",
      "Epoch [49/50], Step [606/735], Loss: 0.0702\n",
      "Epoch [49/50], Step [607/735], Loss: 0.0348\n",
      "Epoch [49/50], Step [608/735], Loss: 0.2288\n",
      "Epoch [49/50], Step [609/735], Loss: 0.1089\n",
      "Epoch [49/50], Step [610/735], Loss: 0.0481\n",
      "Epoch [49/50], Step [611/735], Loss: 0.0508\n",
      "Epoch [49/50], Step [612/735], Loss: 0.2400\n",
      "Epoch [49/50], Step [613/735], Loss: 0.0257\n",
      "Epoch [49/50], Step [614/735], Loss: 0.0269\n",
      "Epoch [49/50], Step [615/735], Loss: 0.1113\n",
      "Epoch [49/50], Step [616/735], Loss: 0.0641\n",
      "Epoch [49/50], Step [617/735], Loss: 0.0757\n",
      "Epoch [49/50], Step [618/735], Loss: 0.0275\n",
      "Epoch [49/50], Step [619/735], Loss: 0.0574\n",
      "Epoch [49/50], Step [620/735], Loss: 0.0213\n",
      "Epoch [49/50], Step [621/735], Loss: 0.0416\n",
      "Epoch [49/50], Step [622/735], Loss: 0.0544\n",
      "Epoch [49/50], Step [623/735], Loss: 0.0249\n",
      "Epoch [49/50], Step [624/735], Loss: 0.3680\n",
      "Epoch [49/50], Step [625/735], Loss: 0.0647\n",
      "Epoch [49/50], Step [626/735], Loss: 0.0605\n",
      "Epoch [49/50], Step [627/735], Loss: 0.0523\n",
      "Epoch [49/50], Step [628/735], Loss: 0.0451\n",
      "Epoch [49/50], Step [629/735], Loss: 0.0876\n",
      "Epoch [49/50], Step [630/735], Loss: 0.0909\n",
      "Epoch [49/50], Step [631/735], Loss: 0.0871\n",
      "Epoch [49/50], Step [632/735], Loss: 0.0660\n",
      "Epoch [49/50], Step [633/735], Loss: 0.1348\n",
      "Epoch [49/50], Step [634/735], Loss: 0.0752\n",
      "Epoch [49/50], Step [635/735], Loss: 0.0694\n",
      "Epoch [49/50], Step [636/735], Loss: 0.0558\n",
      "Epoch [49/50], Step [637/735], Loss: 0.0435\n",
      "Epoch [49/50], Step [638/735], Loss: 0.1340\n",
      "Epoch [49/50], Step [639/735], Loss: 0.0697\n",
      "Epoch [49/50], Step [640/735], Loss: 0.0425\n",
      "Epoch [49/50], Step [641/735], Loss: 0.0327\n",
      "Epoch [49/50], Step [642/735], Loss: 0.0586\n",
      "Epoch [49/50], Step [643/735], Loss: 0.0708\n",
      "Epoch [49/50], Step [644/735], Loss: 0.0431\n",
      "Epoch [49/50], Step [645/735], Loss: 0.0161\n",
      "Epoch [49/50], Step [646/735], Loss: 0.0467\n",
      "Epoch [49/50], Step [647/735], Loss: 0.0533\n",
      "Epoch [49/50], Step [648/735], Loss: 0.0412\n",
      "Epoch [49/50], Step [649/735], Loss: 0.0829\n",
      "Epoch [49/50], Step [650/735], Loss: 0.0907\n",
      "Epoch [49/50], Step [651/735], Loss: 0.0340\n",
      "Epoch [49/50], Step [652/735], Loss: 0.0467\n",
      "Epoch [49/50], Step [653/735], Loss: 0.1333\n",
      "Epoch [49/50], Step [654/735], Loss: 0.0377\n",
      "Epoch [49/50], Step [655/735], Loss: 0.0527\n",
      "Epoch [49/50], Step [656/735], Loss: 0.0424\n",
      "Epoch [49/50], Step [657/735], Loss: 0.0407\n",
      "Epoch [49/50], Step [658/735], Loss: 0.0468\n",
      "Epoch [49/50], Step [659/735], Loss: 0.0287\n",
      "Epoch [49/50], Step [660/735], Loss: 0.0642\n",
      "Epoch [49/50], Step [661/735], Loss: 0.0394\n",
      "Epoch [49/50], Step [662/735], Loss: 0.0293\n",
      "Epoch [49/50], Step [663/735], Loss: 0.0329\n",
      "Epoch [49/50], Step [664/735], Loss: 0.0463\n",
      "Epoch [49/50], Step [665/735], Loss: 0.0304\n",
      "Epoch [49/50], Step [666/735], Loss: 0.0367\n",
      "Epoch [49/50], Step [667/735], Loss: 0.0337\n",
      "Epoch [49/50], Step [668/735], Loss: 0.0884\n",
      "Epoch [49/50], Step [669/735], Loss: 0.0340\n",
      "Epoch [49/50], Step [670/735], Loss: 0.0242\n",
      "Epoch [49/50], Step [671/735], Loss: 0.0409\n",
      "Epoch [49/50], Step [672/735], Loss: 0.0246\n",
      "Epoch [49/50], Step [673/735], Loss: 0.0464\n",
      "Epoch [49/50], Step [674/735], Loss: 0.0336\n",
      "Epoch [49/50], Step [675/735], Loss: 0.0305\n",
      "Epoch [49/50], Step [676/735], Loss: 0.0717\n",
      "Epoch [49/50], Step [677/735], Loss: 0.0485\n",
      "Epoch [49/50], Step [678/735], Loss: 0.0877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Step [679/735], Loss: 0.0709\n",
      "Epoch [49/50], Step [680/735], Loss: 0.0209\n",
      "Epoch [49/50], Step [681/735], Loss: 0.0343\n",
      "Epoch [49/50], Step [682/735], Loss: 0.0848\n",
      "Epoch [49/50], Step [683/735], Loss: 0.0583\n",
      "Epoch [49/50], Step [684/735], Loss: 0.1186\n",
      "Epoch [49/50], Step [685/735], Loss: 0.0636\n",
      "Epoch [49/50], Step [686/735], Loss: 0.1592\n",
      "Epoch [49/50], Step [687/735], Loss: 0.0821\n",
      "Epoch [49/50], Step [688/735], Loss: 0.0218\n",
      "Epoch [49/50], Step [689/735], Loss: 0.1176\n",
      "Epoch [49/50], Step [690/735], Loss: 0.0633\n",
      "Epoch [49/50], Step [691/735], Loss: 0.0252\n",
      "Epoch [49/50], Step [692/735], Loss: 0.0182\n",
      "Epoch [49/50], Step [693/735], Loss: 0.0388\n",
      "Epoch [49/50], Step [694/735], Loss: 0.0453\n",
      "Epoch [49/50], Step [695/735], Loss: 0.0445\n",
      "Epoch [49/50], Step [696/735], Loss: 0.0589\n",
      "Epoch [49/50], Step [697/735], Loss: 0.0335\n",
      "Epoch [49/50], Step [698/735], Loss: 0.0339\n",
      "Epoch [49/50], Step [699/735], Loss: 0.0462\n",
      "Epoch [49/50], Step [700/735], Loss: 0.0338\n",
      "Epoch [49/50], Step [701/735], Loss: 0.0637\n",
      "Epoch [49/50], Step [702/735], Loss: 0.0469\n",
      "Epoch [49/50], Step [703/735], Loss: 0.0181\n",
      "Epoch [49/50], Step [704/735], Loss: 0.0284\n",
      "Epoch [49/50], Step [705/735], Loss: 0.0222\n",
      "Epoch [49/50], Step [706/735], Loss: 0.0190\n",
      "Epoch [49/50], Step [707/735], Loss: 0.0127\n",
      "Epoch [49/50], Step [708/735], Loss: 0.1062\n",
      "Epoch [49/50], Step [709/735], Loss: 0.0551\n",
      "Epoch [49/50], Step [710/735], Loss: 0.0591\n",
      "Epoch [49/50], Step [711/735], Loss: 0.0341\n",
      "Epoch [49/50], Step [712/735], Loss: 0.0301\n",
      "Epoch [49/50], Step [713/735], Loss: 0.0375\n",
      "Epoch [49/50], Step [714/735], Loss: 0.0611\n",
      "Epoch [49/50], Step [715/735], Loss: 0.0312\n",
      "Epoch [49/50], Step [716/735], Loss: 0.0557\n",
      "Epoch [49/50], Step [717/735], Loss: 0.0605\n",
      "Epoch [49/50], Step [718/735], Loss: 0.0757\n",
      "Epoch [49/50], Step [719/735], Loss: 0.0309\n",
      "Epoch [49/50], Step [720/735], Loss: 0.0368\n",
      "Epoch [49/50], Step [721/735], Loss: 0.0360\n",
      "Epoch [49/50], Step [722/735], Loss: 0.1504\n",
      "Epoch [49/50], Step [723/735], Loss: 0.0599\n",
      "Epoch [49/50], Step [724/735], Loss: 0.1025\n",
      "Epoch [49/50], Step [725/735], Loss: 0.0528\n",
      "Epoch [49/50], Step [726/735], Loss: 0.0359\n",
      "Epoch [49/50], Step [727/735], Loss: 0.2930\n",
      "Epoch [49/50], Step [728/735], Loss: 0.0482\n",
      "Epoch [49/50], Step [729/735], Loss: 0.1563\n",
      "Epoch [49/50], Step [730/735], Loss: 0.0760\n",
      "Epoch [49/50], Step [731/735], Loss: 0.0292\n",
      "Epoch [49/50], Step [732/735], Loss: 0.0291\n",
      "Epoch [49/50], Step [733/735], Loss: 0.1748\n",
      "Epoch [49/50], Step [734/735], Loss: 0.0461\n",
      "Epoch [49/50], Step [735/735], Loss: 0.1036\n",
      "Epoch [50/50], Step [1/735], Loss: 0.0569\n",
      "Epoch [50/50], Step [2/735], Loss: 0.0772\n",
      "Epoch [50/50], Step [3/735], Loss: 0.0692\n",
      "Epoch [50/50], Step [4/735], Loss: 0.0314\n",
      "Epoch [50/50], Step [5/735], Loss: 0.0645\n",
      "Epoch [50/50], Step [6/735], Loss: 0.0545\n",
      "Epoch [50/50], Step [7/735], Loss: 0.0565\n",
      "Epoch [50/50], Step [8/735], Loss: 0.0908\n",
      "Epoch [50/50], Step [9/735], Loss: 0.0636\n",
      "Epoch [50/50], Step [10/735], Loss: 0.0596\n",
      "Epoch [50/50], Step [11/735], Loss: 0.1115\n",
      "Epoch [50/50], Step [12/735], Loss: 0.0727\n",
      "Epoch [50/50], Step [13/735], Loss: 0.0583\n",
      "Epoch [50/50], Step [14/735], Loss: 0.0490\n",
      "Epoch [50/50], Step [15/735], Loss: 0.2730\n",
      "Epoch [50/50], Step [16/735], Loss: 0.0683\n",
      "Epoch [50/50], Step [17/735], Loss: 0.0425\n",
      "Epoch [50/50], Step [18/735], Loss: 0.0504\n",
      "Epoch [50/50], Step [19/735], Loss: 0.0751\n",
      "Epoch [50/50], Step [20/735], Loss: 0.1380\n",
      "Epoch [50/50], Step [21/735], Loss: 0.1649\n",
      "Epoch [50/50], Step [22/735], Loss: 0.1154\n",
      "Epoch [50/50], Step [23/735], Loss: 0.0354\n",
      "Epoch [50/50], Step [24/735], Loss: 0.0631\n",
      "Epoch [50/50], Step [25/735], Loss: 0.0598\n",
      "Epoch [50/50], Step [26/735], Loss: 0.0419\n",
      "Epoch [50/50], Step [27/735], Loss: 0.0271\n",
      "Epoch [50/50], Step [28/735], Loss: 0.0819\n",
      "Epoch [50/50], Step [29/735], Loss: 0.0704\n",
      "Epoch [50/50], Step [30/735], Loss: 0.0414\n",
      "Epoch [50/50], Step [31/735], Loss: 0.0635\n",
      "Epoch [50/50], Step [32/735], Loss: 0.0369\n",
      "Epoch [50/50], Step [33/735], Loss: 0.0634\n",
      "Epoch [50/50], Step [34/735], Loss: 0.0647\n",
      "Epoch [50/50], Step [35/735], Loss: 0.0214\n",
      "Epoch [50/50], Step [36/735], Loss: 0.0383\n",
      "Epoch [50/50], Step [37/735], Loss: 0.0534\n",
      "Epoch [50/50], Step [38/735], Loss: 0.0923\n",
      "Epoch [50/50], Step [39/735], Loss: 0.0275\n",
      "Epoch [50/50], Step [40/735], Loss: 0.0495\n",
      "Epoch [50/50], Step [41/735], Loss: 0.0282\n",
      "Epoch [50/50], Step [42/735], Loss: 0.0398\n",
      "Epoch [50/50], Step [43/735], Loss: 0.0471\n",
      "Epoch [50/50], Step [44/735], Loss: 0.0563\n",
      "Epoch [50/50], Step [45/735], Loss: 0.0584\n",
      "Epoch [50/50], Step [46/735], Loss: 0.1572\n",
      "Epoch [50/50], Step [47/735], Loss: 0.0547\n",
      "Epoch [50/50], Step [48/735], Loss: 0.1489\n",
      "Epoch [50/50], Step [49/735], Loss: 0.1240\n",
      "Epoch [50/50], Step [50/735], Loss: 0.0770\n",
      "Epoch [50/50], Step [51/735], Loss: 0.0757\n",
      "Epoch [50/50], Step [52/735], Loss: 0.1035\n",
      "Epoch [50/50], Step [53/735], Loss: 0.0546\n",
      "Epoch [50/50], Step [54/735], Loss: 0.0409\n",
      "Epoch [50/50], Step [55/735], Loss: 0.0813\n",
      "Epoch [50/50], Step [56/735], Loss: 0.0444\n",
      "Epoch [50/50], Step [57/735], Loss: 0.0380\n",
      "Epoch [50/50], Step [58/735], Loss: 0.0426\n",
      "Epoch [50/50], Step [59/735], Loss: 0.1395\n",
      "Epoch [50/50], Step [60/735], Loss: 0.0527\n",
      "Epoch [50/50], Step [61/735], Loss: 0.1443\n",
      "Epoch [50/50], Step [62/735], Loss: 0.0560\n",
      "Epoch [50/50], Step [63/735], Loss: 0.0635\n",
      "Epoch [50/50], Step [64/735], Loss: 0.0964\n",
      "Epoch [50/50], Step [65/735], Loss: 0.1565\n",
      "Epoch [50/50], Step [66/735], Loss: 0.0510\n",
      "Epoch [50/50], Step [67/735], Loss: 0.0299\n",
      "Epoch [50/50], Step [68/735], Loss: 0.0633\n",
      "Epoch [50/50], Step [69/735], Loss: 0.1096\n",
      "Epoch [50/50], Step [70/735], Loss: 0.1140\n",
      "Epoch [50/50], Step [71/735], Loss: 0.0461\n",
      "Epoch [50/50], Step [72/735], Loss: 0.2062\n",
      "Epoch [50/50], Step [73/735], Loss: 0.1002\n",
      "Epoch [50/50], Step [74/735], Loss: 0.0414\n",
      "Epoch [50/50], Step [75/735], Loss: 0.0122\n",
      "Epoch [50/50], Step [76/735], Loss: 0.0509\n",
      "Epoch [50/50], Step [77/735], Loss: 0.0381\n",
      "Epoch [50/50], Step [78/735], Loss: 0.4040\n",
      "Epoch [50/50], Step [79/735], Loss: 0.0786\n",
      "Epoch [50/50], Step [80/735], Loss: 0.0438\n",
      "Epoch [50/50], Step [81/735], Loss: 0.0453\n",
      "Epoch [50/50], Step [82/735], Loss: 0.0562\n",
      "Epoch [50/50], Step [83/735], Loss: 0.0705\n",
      "Epoch [50/50], Step [84/735], Loss: 0.0458\n",
      "Epoch [50/50], Step [85/735], Loss: 0.1680\n",
      "Epoch [50/50], Step [86/735], Loss: 0.0837\n",
      "Epoch [50/50], Step [87/735], Loss: 0.0965\n",
      "Epoch [50/50], Step [88/735], Loss: 0.1265\n",
      "Epoch [50/50], Step [89/735], Loss: 0.0764\n",
      "Epoch [50/50], Step [90/735], Loss: 0.0286\n",
      "Epoch [50/50], Step [91/735], Loss: 0.0551\n",
      "Epoch [50/50], Step [92/735], Loss: 0.0864\n",
      "Epoch [50/50], Step [93/735], Loss: 0.0659\n",
      "Epoch [50/50], Step [94/735], Loss: 0.0578\n",
      "Epoch [50/50], Step [95/735], Loss: 0.0280\n",
      "Epoch [50/50], Step [96/735], Loss: 0.0794\n",
      "Epoch [50/50], Step [97/735], Loss: 0.0204\n",
      "Epoch [50/50], Step [98/735], Loss: 0.0531\n",
      "Epoch [50/50], Step [99/735], Loss: 0.0462\n",
      "Epoch [50/50], Step [100/735], Loss: 0.0317\n",
      "Epoch [50/50], Step [101/735], Loss: 0.1062\n",
      "Epoch [50/50], Step [102/735], Loss: 0.0176\n",
      "Epoch [50/50], Step [103/735], Loss: 0.0396\n",
      "Epoch [50/50], Step [104/735], Loss: 0.0282\n",
      "Epoch [50/50], Step [105/735], Loss: 0.0303\n",
      "Epoch [50/50], Step [106/735], Loss: 0.0770\n",
      "Epoch [50/50], Step [107/735], Loss: 0.0540\n",
      "Epoch [50/50], Step [108/735], Loss: 0.0388\n",
      "Epoch [50/50], Step [109/735], Loss: 0.0509\n",
      "Epoch [50/50], Step [110/735], Loss: 0.0354\n",
      "Epoch [50/50], Step [111/735], Loss: 0.0205\n",
      "Epoch [50/50], Step [112/735], Loss: 0.0362\n",
      "Epoch [50/50], Step [113/735], Loss: 0.0720\n",
      "Epoch [50/50], Step [114/735], Loss: 0.0239\n",
      "Epoch [50/50], Step [115/735], Loss: 0.0391\n",
      "Epoch [50/50], Step [116/735], Loss: 0.1220\n",
      "Epoch [50/50], Step [117/735], Loss: 0.0304\n",
      "Epoch [50/50], Step [118/735], Loss: 0.1217\n",
      "Epoch [50/50], Step [119/735], Loss: 0.0382\n",
      "Epoch [50/50], Step [120/735], Loss: 0.1030\n",
      "Epoch [50/50], Step [121/735], Loss: 0.0562\n",
      "Epoch [50/50], Step [122/735], Loss: 0.0779\n",
      "Epoch [50/50], Step [123/735], Loss: 0.0540\n",
      "Epoch [50/50], Step [124/735], Loss: 0.0280\n",
      "Epoch [50/50], Step [125/735], Loss: 0.1019\n",
      "Epoch [50/50], Step [126/735], Loss: 0.0207\n",
      "Epoch [50/50], Step [127/735], Loss: 0.0946\n",
      "Epoch [50/50], Step [128/735], Loss: 0.0513\n",
      "Epoch [50/50], Step [129/735], Loss: 0.0226\n",
      "Epoch [50/50], Step [130/735], Loss: 0.0611\n",
      "Epoch [50/50], Step [131/735], Loss: 0.0618\n",
      "Epoch [50/50], Step [132/735], Loss: 0.0409\n",
      "Epoch [50/50], Step [133/735], Loss: 0.0270\n",
      "Epoch [50/50], Step [134/735], Loss: 0.0342\n",
      "Epoch [50/50], Step [135/735], Loss: 0.0242\n",
      "Epoch [50/50], Step [136/735], Loss: 0.0611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Step [137/735], Loss: 0.0487\n",
      "Epoch [50/50], Step [138/735], Loss: 0.0445\n",
      "Epoch [50/50], Step [139/735], Loss: 0.0234\n",
      "Epoch [50/50], Step [140/735], Loss: 0.0418\n",
      "Epoch [50/50], Step [141/735], Loss: 0.0956\n",
      "Epoch [50/50], Step [142/735], Loss: 0.0741\n",
      "Epoch [50/50], Step [143/735], Loss: 0.0218\n",
      "Epoch [50/50], Step [144/735], Loss: 0.0340\n",
      "Epoch [50/50], Step [145/735], Loss: 0.0250\n",
      "Epoch [50/50], Step [146/735], Loss: 0.0599\n",
      "Epoch [50/50], Step [147/735], Loss: 0.0525\n",
      "Epoch [50/50], Step [148/735], Loss: 0.0580\n",
      "Epoch [50/50], Step [149/735], Loss: 0.0283\n",
      "Epoch [50/50], Step [150/735], Loss: 0.0401\n",
      "Epoch [50/50], Step [151/735], Loss: 0.0411\n",
      "Epoch [50/50], Step [152/735], Loss: 0.0322\n",
      "Epoch [50/50], Step [153/735], Loss: 0.0595\n",
      "Epoch [50/50], Step [154/735], Loss: 0.0704\n",
      "Epoch [50/50], Step [155/735], Loss: 0.0278\n",
      "Epoch [50/50], Step [156/735], Loss: 0.0893\n",
      "Epoch [50/50], Step [157/735], Loss: 0.0378\n",
      "Epoch [50/50], Step [158/735], Loss: 0.0363\n",
      "Epoch [50/50], Step [159/735], Loss: 0.0403\n",
      "Epoch [50/50], Step [160/735], Loss: 0.0685\n",
      "Epoch [50/50], Step [161/735], Loss: 0.0938\n",
      "Epoch [50/50], Step [162/735], Loss: 0.1087\n",
      "Epoch [50/50], Step [163/735], Loss: 0.0593\n",
      "Epoch [50/50], Step [164/735], Loss: 0.0374\n",
      "Epoch [50/50], Step [165/735], Loss: 0.0593\n",
      "Epoch [50/50], Step [166/735], Loss: 0.0421\n",
      "Epoch [50/50], Step [167/735], Loss: 0.0426\n",
      "Epoch [50/50], Step [168/735], Loss: 0.0245\n",
      "Epoch [50/50], Step [169/735], Loss: 0.0349\n",
      "Epoch [50/50], Step [170/735], Loss: 0.0655\n",
      "Epoch [50/50], Step [171/735], Loss: 0.0237\n",
      "Epoch [50/50], Step [172/735], Loss: 0.0656\n",
      "Epoch [50/50], Step [173/735], Loss: 0.0663\n",
      "Epoch [50/50], Step [174/735], Loss: 0.0498\n",
      "Epoch [50/50], Step [175/735], Loss: 0.0824\n",
      "Epoch [50/50], Step [176/735], Loss: 0.0658\n",
      "Epoch [50/50], Step [177/735], Loss: 0.0694\n",
      "Epoch [50/50], Step [178/735], Loss: 0.0492\n",
      "Epoch [50/50], Step [179/735], Loss: 0.3169\n",
      "Epoch [50/50], Step [180/735], Loss: 0.0164\n",
      "Epoch [50/50], Step [181/735], Loss: 0.0175\n",
      "Epoch [50/50], Step [182/735], Loss: 0.0665\n",
      "Epoch [50/50], Step [183/735], Loss: 0.0401\n",
      "Epoch [50/50], Step [184/735], Loss: 0.0840\n",
      "Epoch [50/50], Step [185/735], Loss: 0.3419\n",
      "Epoch [50/50], Step [186/735], Loss: 0.0627\n",
      "Epoch [50/50], Step [187/735], Loss: 0.0261\n",
      "Epoch [50/50], Step [188/735], Loss: 0.0186\n",
      "Epoch [50/50], Step [189/735], Loss: 0.0598\n",
      "Epoch [50/50], Step [190/735], Loss: 0.0655\n",
      "Epoch [50/50], Step [191/735], Loss: 0.0318\n",
      "Epoch [50/50], Step [192/735], Loss: 0.0615\n",
      "Epoch [50/50], Step [193/735], Loss: 0.0394\n",
      "Epoch [50/50], Step [194/735], Loss: 0.0567\n",
      "Epoch [50/50], Step [195/735], Loss: 0.0481\n",
      "Epoch [50/50], Step [196/735], Loss: 0.1016\n",
      "Epoch [50/50], Step [197/735], Loss: 0.0266\n",
      "Epoch [50/50], Step [198/735], Loss: 0.0374\n",
      "Epoch [50/50], Step [199/735], Loss: 0.0336\n",
      "Epoch [50/50], Step [200/735], Loss: 0.0474\n",
      "Epoch [50/50], Step [201/735], Loss: 0.1682\n",
      "Epoch [50/50], Step [202/735], Loss: 0.0220\n",
      "Epoch [50/50], Step [203/735], Loss: 0.0529\n",
      "Epoch [50/50], Step [204/735], Loss: 0.0922\n",
      "Epoch [50/50], Step [205/735], Loss: 0.0401\n",
      "Epoch [50/50], Step [206/735], Loss: 0.1723\n",
      "Epoch [50/50], Step [207/735], Loss: 0.0677\n",
      "Epoch [50/50], Step [208/735], Loss: 0.0390\n",
      "Epoch [50/50], Step [209/735], Loss: 0.0322\n",
      "Epoch [50/50], Step [210/735], Loss: 0.0224\n",
      "Epoch [50/50], Step [211/735], Loss: 0.0287\n",
      "Epoch [50/50], Step [212/735], Loss: 0.0378\n",
      "Epoch [50/50], Step [213/735], Loss: 0.0180\n",
      "Epoch [50/50], Step [214/735], Loss: 0.0290\n",
      "Epoch [50/50], Step [215/735], Loss: 0.0507\n",
      "Epoch [50/50], Step [216/735], Loss: 0.0399\n",
      "Epoch [50/50], Step [217/735], Loss: 0.0326\n",
      "Epoch [50/50], Step [218/735], Loss: 0.0369\n",
      "Epoch [50/50], Step [219/735], Loss: 0.0084\n",
      "Epoch [50/50], Step [220/735], Loss: 0.1002\n",
      "Epoch [50/50], Step [221/735], Loss: 0.0150\n",
      "Epoch [50/50], Step [222/735], Loss: 0.0769\n",
      "Epoch [50/50], Step [223/735], Loss: 0.0209\n",
      "Epoch [50/50], Step [224/735], Loss: 0.0337\n",
      "Epoch [50/50], Step [225/735], Loss: 0.0289\n",
      "Epoch [50/50], Step [226/735], Loss: 0.0892\n",
      "Epoch [50/50], Step [227/735], Loss: 0.0417\n",
      "Epoch [50/50], Step [228/735], Loss: 0.0286\n",
      "Epoch [50/50], Step [229/735], Loss: 0.0348\n",
      "Epoch [50/50], Step [230/735], Loss: 0.0191\n",
      "Epoch [50/50], Step [231/735], Loss: 0.0687\n",
      "Epoch [50/50], Step [232/735], Loss: 0.0394\n",
      "Epoch [50/50], Step [233/735], Loss: 0.0603\n",
      "Epoch [50/50], Step [234/735], Loss: 0.0659\n",
      "Epoch [50/50], Step [235/735], Loss: 0.0770\n",
      "Epoch [50/50], Step [236/735], Loss: 0.0453\n",
      "Epoch [50/50], Step [237/735], Loss: 0.0154\n",
      "Epoch [50/50], Step [238/735], Loss: 0.0750\n",
      "Epoch [50/50], Step [239/735], Loss: 0.0862\n",
      "Epoch [50/50], Step [240/735], Loss: 0.0502\n",
      "Epoch [50/50], Step [241/735], Loss: 0.3194\n",
      "Epoch [50/50], Step [242/735], Loss: 0.0718\n",
      "Epoch [50/50], Step [243/735], Loss: 0.0826\n",
      "Epoch [50/50], Step [244/735], Loss: 0.2730\n",
      "Epoch [50/50], Step [245/735], Loss: 0.0308\n",
      "Epoch [50/50], Step [246/735], Loss: 0.0393\n",
      "Epoch [50/50], Step [247/735], Loss: 0.0600\n",
      "Epoch [50/50], Step [248/735], Loss: 0.0550\n",
      "Epoch [50/50], Step [249/735], Loss: 0.0842\n",
      "Epoch [50/50], Step [250/735], Loss: 0.0433\n",
      "Epoch [50/50], Step [251/735], Loss: 0.0419\n",
      "Epoch [50/50], Step [252/735], Loss: 0.1958\n",
      "Epoch [50/50], Step [253/735], Loss: 0.0585\n",
      "Epoch [50/50], Step [254/735], Loss: 0.0466\n",
      "Epoch [50/50], Step [255/735], Loss: 0.0366\n",
      "Epoch [50/50], Step [256/735], Loss: 0.0275\n",
      "Epoch [50/50], Step [257/735], Loss: 0.0572\n",
      "Epoch [50/50], Step [258/735], Loss: 0.1211\n",
      "Epoch [50/50], Step [259/735], Loss: 0.0547\n",
      "Epoch [50/50], Step [260/735], Loss: 0.0587\n",
      "Epoch [50/50], Step [261/735], Loss: 0.2424\n",
      "Epoch [50/50], Step [262/735], Loss: 0.0357\n",
      "Epoch [50/50], Step [263/735], Loss: 0.0300\n",
      "Epoch [50/50], Step [264/735], Loss: 0.1130\n",
      "Epoch [50/50], Step [265/735], Loss: 0.0427\n",
      "Epoch [50/50], Step [266/735], Loss: 0.0465\n",
      "Epoch [50/50], Step [267/735], Loss: 0.0195\n",
      "Epoch [50/50], Step [268/735], Loss: 0.0324\n",
      "Epoch [50/50], Step [269/735], Loss: 0.0573\n",
      "Epoch [50/50], Step [270/735], Loss: 0.0552\n",
      "Epoch [50/50], Step [271/735], Loss: 0.0432\n",
      "Epoch [50/50], Step [272/735], Loss: 0.0423\n",
      "Epoch [50/50], Step [273/735], Loss: 0.1055\n",
      "Epoch [50/50], Step [274/735], Loss: 0.0253\n",
      "Epoch [50/50], Step [275/735], Loss: 0.0902\n",
      "Epoch [50/50], Step [276/735], Loss: 0.0133\n",
      "Epoch [50/50], Step [277/735], Loss: 0.0331\n",
      "Epoch [50/50], Step [278/735], Loss: 0.0465\n",
      "Epoch [50/50], Step [279/735], Loss: 0.0700\n",
      "Epoch [50/50], Step [280/735], Loss: 0.0710\n",
      "Epoch [50/50], Step [281/735], Loss: 0.0356\n",
      "Epoch [50/50], Step [282/735], Loss: 0.0273\n",
      "Epoch [50/50], Step [283/735], Loss: 0.0423\n",
      "Epoch [50/50], Step [284/735], Loss: 0.0183\n",
      "Epoch [50/50], Step [285/735], Loss: 0.0351\n",
      "Epoch [50/50], Step [286/735], Loss: 0.1084\n",
      "Epoch [50/50], Step [287/735], Loss: 0.0400\n",
      "Epoch [50/50], Step [288/735], Loss: 0.0406\n",
      "Epoch [50/50], Step [289/735], Loss: 0.0268\n",
      "Epoch [50/50], Step [290/735], Loss: 0.0232\n",
      "Epoch [50/50], Step [291/735], Loss: 0.0500\n",
      "Epoch [50/50], Step [292/735], Loss: 0.1505\n",
      "Epoch [50/50], Step [293/735], Loss: 0.1673\n",
      "Epoch [50/50], Step [294/735], Loss: 0.0749\n",
      "Epoch [50/50], Step [295/735], Loss: 0.0235\n",
      "Epoch [50/50], Step [296/735], Loss: 0.0627\n",
      "Epoch [50/50], Step [297/735], Loss: 0.0388\n",
      "Epoch [50/50], Step [298/735], Loss: 0.0596\n",
      "Epoch [50/50], Step [299/735], Loss: 0.1456\n",
      "Epoch [50/50], Step [300/735], Loss: 0.0407\n",
      "Epoch [50/50], Step [301/735], Loss: 0.0571\n",
      "Epoch [50/50], Step [302/735], Loss: 0.0536\n",
      "Epoch [50/50], Step [303/735], Loss: 0.0291\n",
      "Epoch [50/50], Step [304/735], Loss: 0.0194\n",
      "Epoch [50/50], Step [305/735], Loss: 0.0855\n",
      "Epoch [50/50], Step [306/735], Loss: 0.0491\n",
      "Epoch [50/50], Step [307/735], Loss: 0.0339\n",
      "Epoch [50/50], Step [308/735], Loss: 0.0349\n",
      "Epoch [50/50], Step [309/735], Loss: 0.0378\n",
      "Epoch [50/50], Step [310/735], Loss: 0.0324\n",
      "Epoch [50/50], Step [311/735], Loss: 0.0248\n",
      "Epoch [50/50], Step [312/735], Loss: 0.0704\n",
      "Epoch [50/50], Step [313/735], Loss: 0.0756\n",
      "Epoch [50/50], Step [314/735], Loss: 0.0736\n",
      "Epoch [50/50], Step [315/735], Loss: 0.0369\n",
      "Epoch [50/50], Step [316/735], Loss: 0.0629\n",
      "Epoch [50/50], Step [317/735], Loss: 0.0495\n",
      "Epoch [50/50], Step [318/735], Loss: 0.0878\n",
      "Epoch [50/50], Step [319/735], Loss: 0.1305\n",
      "Epoch [50/50], Step [320/735], Loss: 0.0139\n",
      "Epoch [50/50], Step [321/735], Loss: 0.0425\n",
      "Epoch [50/50], Step [322/735], Loss: 0.0634\n",
      "Epoch [50/50], Step [323/735], Loss: 0.2186\n",
      "Epoch [50/50], Step [324/735], Loss: 0.0282\n",
      "Epoch [50/50], Step [325/735], Loss: 0.0635\n",
      "Epoch [50/50], Step [326/735], Loss: 0.0331\n",
      "Epoch [50/50], Step [327/735], Loss: 0.0321\n",
      "Epoch [50/50], Step [328/735], Loss: 0.0375\n",
      "Epoch [50/50], Step [329/735], Loss: 0.0267\n",
      "Epoch [50/50], Step [330/735], Loss: 0.0501\n",
      "Epoch [50/50], Step [331/735], Loss: 0.4239\n",
      "Epoch [50/50], Step [332/735], Loss: 0.0777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Step [333/735], Loss: 0.0380\n",
      "Epoch [50/50], Step [334/735], Loss: 0.0553\n",
      "Epoch [50/50], Step [335/735], Loss: 0.0507\n",
      "Epoch [50/50], Step [336/735], Loss: 0.0313\n",
      "Epoch [50/50], Step [337/735], Loss: 0.1215\n",
      "Epoch [50/50], Step [338/735], Loss: 0.0910\n",
      "Epoch [50/50], Step [339/735], Loss: 0.0575\n",
      "Epoch [50/50], Step [340/735], Loss: 0.0362\n",
      "Epoch [50/50], Step [341/735], Loss: 0.0556\n",
      "Epoch [50/50], Step [342/735], Loss: 0.0481\n",
      "Epoch [50/50], Step [343/735], Loss: 0.0167\n",
      "Epoch [50/50], Step [344/735], Loss: 0.0277\n",
      "Epoch [50/50], Step [345/735], Loss: 0.0842\n",
      "Epoch [50/50], Step [346/735], Loss: 0.0482\n",
      "Epoch [50/50], Step [347/735], Loss: 0.0341\n",
      "Epoch [50/50], Step [348/735], Loss: 0.0206\n",
      "Epoch [50/50], Step [349/735], Loss: 0.0591\n",
      "Epoch [50/50], Step [350/735], Loss: 0.0887\n",
      "Epoch [50/50], Step [351/735], Loss: 0.0560\n",
      "Epoch [50/50], Step [352/735], Loss: 0.0604\n",
      "Epoch [50/50], Step [353/735], Loss: 0.0186\n",
      "Epoch [50/50], Step [354/735], Loss: 0.0601\n",
      "Epoch [50/50], Step [355/735], Loss: 0.0330\n",
      "Epoch [50/50], Step [356/735], Loss: 0.0343\n",
      "Epoch [50/50], Step [357/735], Loss: 0.0513\n",
      "Epoch [50/50], Step [358/735], Loss: 0.1289\n",
      "Epoch [50/50], Step [359/735], Loss: 0.0314\n",
      "Epoch [50/50], Step [360/735], Loss: 0.0487\n",
      "Epoch [50/50], Step [361/735], Loss: 0.0236\n",
      "Epoch [50/50], Step [362/735], Loss: 0.0621\n",
      "Epoch [50/50], Step [363/735], Loss: 0.0592\n",
      "Epoch [50/50], Step [364/735], Loss: 0.0396\n",
      "Epoch [50/50], Step [365/735], Loss: 0.1041\n",
      "Epoch [50/50], Step [366/735], Loss: 0.0451\n",
      "Epoch [50/50], Step [367/735], Loss: 0.0454\n",
      "Epoch [50/50], Step [368/735], Loss: 0.0239\n",
      "Epoch [50/50], Step [369/735], Loss: 0.0438\n",
      "Epoch [50/50], Step [370/735], Loss: 0.0295\n",
      "Epoch [50/50], Step [371/735], Loss: 0.0512\n",
      "Epoch [50/50], Step [372/735], Loss: 0.0414\n",
      "Epoch [50/50], Step [373/735], Loss: 0.1109\n",
      "Epoch [50/50], Step [374/735], Loss: 0.0274\n",
      "Epoch [50/50], Step [375/735], Loss: 0.0271\n",
      "Epoch [50/50], Step [376/735], Loss: 0.0361\n",
      "Epoch [50/50], Step [377/735], Loss: 0.0424\n",
      "Epoch [50/50], Step [378/735], Loss: 0.0583\n",
      "Epoch [50/50], Step [379/735], Loss: 0.1368\n",
      "Epoch [50/50], Step [380/735], Loss: 0.0341\n",
      "Epoch [50/50], Step [381/735], Loss: 0.0563\n",
      "Epoch [50/50], Step [382/735], Loss: 0.1774\n",
      "Epoch [50/50], Step [383/735], Loss: 0.0292\n",
      "Epoch [50/50], Step [384/735], Loss: 0.0387\n",
      "Epoch [50/50], Step [385/735], Loss: 0.0273\n",
      "Epoch [50/50], Step [386/735], Loss: 0.0306\n",
      "Epoch [50/50], Step [387/735], Loss: 0.0259\n",
      "Epoch [50/50], Step [388/735], Loss: 0.0544\n",
      "Epoch [50/50], Step [389/735], Loss: 0.0239\n",
      "Epoch [50/50], Step [390/735], Loss: 0.0819\n",
      "Epoch [50/50], Step [391/735], Loss: 0.0251\n",
      "Epoch [50/50], Step [392/735], Loss: 0.0262\n",
      "Epoch [50/50], Step [393/735], Loss: 0.0535\n",
      "Epoch [50/50], Step [394/735], Loss: 0.0342\n",
      "Epoch [50/50], Step [395/735], Loss: 0.0732\n",
      "Epoch [50/50], Step [396/735], Loss: 0.0625\n",
      "Epoch [50/50], Step [397/735], Loss: 0.0355\n",
      "Epoch [50/50], Step [398/735], Loss: 0.0579\n",
      "Epoch [50/50], Step [399/735], Loss: 0.0445\n",
      "Epoch [50/50], Step [400/735], Loss: 0.0166\n",
      "Epoch [50/50], Step [401/735], Loss: 0.0887\n",
      "Epoch [50/50], Step [402/735], Loss: 0.0545\n",
      "Epoch [50/50], Step [403/735], Loss: 0.0568\n",
      "Epoch [50/50], Step [404/735], Loss: 0.0150\n",
      "Epoch [50/50], Step [405/735], Loss: 0.0677\n",
      "Epoch [50/50], Step [406/735], Loss: 0.0424\n",
      "Epoch [50/50], Step [407/735], Loss: 0.0235\n",
      "Epoch [50/50], Step [408/735], Loss: 0.0471\n",
      "Epoch [50/50], Step [409/735], Loss: 0.0522\n",
      "Epoch [50/50], Step [410/735], Loss: 0.0543\n",
      "Epoch [50/50], Step [411/735], Loss: 0.0312\n",
      "Epoch [50/50], Step [412/735], Loss: 0.0274\n",
      "Epoch [50/50], Step [413/735], Loss: 0.0304\n",
      "Epoch [50/50], Step [414/735], Loss: 0.0244\n",
      "Epoch [50/50], Step [415/735], Loss: 0.0787\n",
      "Epoch [50/50], Step [416/735], Loss: 0.1105\n",
      "Epoch [50/50], Step [417/735], Loss: 0.0306\n",
      "Epoch [50/50], Step [418/735], Loss: 0.2650\n",
      "Epoch [50/50], Step [419/735], Loss: 0.1432\n",
      "Epoch [50/50], Step [420/735], Loss: 0.0898\n",
      "Epoch [50/50], Step [421/735], Loss: 0.0390\n",
      "Epoch [50/50], Step [422/735], Loss: 0.0145\n",
      "Epoch [50/50], Step [423/735], Loss: 0.0650\n",
      "Epoch [50/50], Step [424/735], Loss: 0.0492\n",
      "Epoch [50/50], Step [425/735], Loss: 0.0173\n",
      "Epoch [50/50], Step [426/735], Loss: 0.0475\n",
      "Epoch [50/50], Step [427/735], Loss: 0.0848\n",
      "Epoch [50/50], Step [428/735], Loss: 0.0956\n",
      "Epoch [50/50], Step [429/735], Loss: 0.0463\n",
      "Epoch [50/50], Step [430/735], Loss: 0.0443\n",
      "Epoch [50/50], Step [431/735], Loss: 0.0485\n",
      "Epoch [50/50], Step [432/735], Loss: 0.0361\n",
      "Epoch [50/50], Step [433/735], Loss: 0.0719\n",
      "Epoch [50/50], Step [434/735], Loss: 0.0650\n",
      "Epoch [50/50], Step [435/735], Loss: 0.0463\n",
      "Epoch [50/50], Step [436/735], Loss: 0.0810\n",
      "Epoch [50/50], Step [437/735], Loss: 0.0537\n",
      "Epoch [50/50], Step [438/735], Loss: 0.0474\n",
      "Epoch [50/50], Step [439/735], Loss: 0.2037\n",
      "Epoch [50/50], Step [440/735], Loss: 0.0499\n",
      "Epoch [50/50], Step [441/735], Loss: 0.0343\n",
      "Epoch [50/50], Step [442/735], Loss: 0.0464\n",
      "Epoch [50/50], Step [443/735], Loss: 0.0129\n",
      "Epoch [50/50], Step [444/735], Loss: 0.2714\n",
      "Epoch [50/50], Step [445/735], Loss: 0.0625\n",
      "Epoch [50/50], Step [446/735], Loss: 0.0653\n",
      "Epoch [50/50], Step [447/735], Loss: 0.0377\n",
      "Epoch [50/50], Step [448/735], Loss: 0.0706\n",
      "Epoch [50/50], Step [449/735], Loss: 0.0350\n",
      "Epoch [50/50], Step [450/735], Loss: 0.0280\n",
      "Epoch [50/50], Step [451/735], Loss: 0.0227\n",
      "Epoch [50/50], Step [452/735], Loss: 0.0242\n",
      "Epoch [50/50], Step [453/735], Loss: 0.0370\n",
      "Epoch [50/50], Step [454/735], Loss: 0.0464\n",
      "Epoch [50/50], Step [455/735], Loss: 0.0357\n",
      "Epoch [50/50], Step [456/735], Loss: 0.0420\n",
      "Epoch [50/50], Step [457/735], Loss: 0.1002\n",
      "Epoch [50/50], Step [458/735], Loss: 0.0570\n",
      "Epoch [50/50], Step [459/735], Loss: 0.0436\n",
      "Epoch [50/50], Step [460/735], Loss: 0.1055\n",
      "Epoch [50/50], Step [461/735], Loss: 0.0477\n",
      "Epoch [50/50], Step [462/735], Loss: 0.0443\n",
      "Epoch [50/50], Step [463/735], Loss: 0.0372\n",
      "Epoch [50/50], Step [464/735], Loss: 0.0357\n",
      "Epoch [50/50], Step [465/735], Loss: 0.0928\n",
      "Epoch [50/50], Step [466/735], Loss: 0.0669\n",
      "Epoch [50/50], Step [467/735], Loss: 0.0470\n",
      "Epoch [50/50], Step [468/735], Loss: 0.0269\n",
      "Epoch [50/50], Step [469/735], Loss: 0.0277\n",
      "Epoch [50/50], Step [470/735], Loss: 0.0520\n",
      "Epoch [50/50], Step [471/735], Loss: 0.0406\n",
      "Epoch [50/50], Step [472/735], Loss: 0.0201\n",
      "Epoch [50/50], Step [473/735], Loss: 0.0280\n",
      "Epoch [50/50], Step [474/735], Loss: 0.0331\n",
      "Epoch [50/50], Step [475/735], Loss: 0.0275\n",
      "Epoch [50/50], Step [476/735], Loss: 0.0404\n",
      "Epoch [50/50], Step [477/735], Loss: 0.1109\n",
      "Epoch [50/50], Step [478/735], Loss: 0.0544\n",
      "Epoch [50/50], Step [479/735], Loss: 0.1059\n",
      "Epoch [50/50], Step [480/735], Loss: 0.0416\n",
      "Epoch [50/50], Step [481/735], Loss: 0.0249\n",
      "Epoch [50/50], Step [482/735], Loss: 0.0234\n",
      "Epoch [50/50], Step [483/735], Loss: 0.0264\n",
      "Epoch [50/50], Step [484/735], Loss: 0.0631\n",
      "Epoch [50/50], Step [485/735], Loss: 0.0093\n",
      "Epoch [50/50], Step [486/735], Loss: 0.0517\n",
      "Epoch [50/50], Step [487/735], Loss: 0.0465\n",
      "Epoch [50/50], Step [488/735], Loss: 0.0398\n",
      "Epoch [50/50], Step [489/735], Loss: 0.0252\n",
      "Epoch [50/50], Step [490/735], Loss: 0.0384\n",
      "Epoch [50/50], Step [491/735], Loss: 0.0490\n",
      "Epoch [50/50], Step [492/735], Loss: 0.0479\n",
      "Epoch [50/50], Step [493/735], Loss: 0.0516\n",
      "Epoch [50/50], Step [494/735], Loss: 0.0420\n",
      "Epoch [50/50], Step [495/735], Loss: 0.0295\n",
      "Epoch [50/50], Step [496/735], Loss: 0.0393\n",
      "Epoch [50/50], Step [497/735], Loss: 0.0353\n",
      "Epoch [50/50], Step [498/735], Loss: 0.0327\n",
      "Epoch [50/50], Step [499/735], Loss: 0.0194\n",
      "Epoch [50/50], Step [500/735], Loss: 0.0467\n",
      "Epoch [50/50], Step [501/735], Loss: 0.0225\n",
      "Epoch [50/50], Step [502/735], Loss: 0.0398\n",
      "Epoch [50/50], Step [503/735], Loss: 0.0145\n",
      "Epoch [50/50], Step [504/735], Loss: 0.0234\n",
      "Epoch [50/50], Step [505/735], Loss: 0.0330\n",
      "Epoch [50/50], Step [506/735], Loss: 0.0547\n",
      "Epoch [50/50], Step [507/735], Loss: 0.0678\n",
      "Epoch [50/50], Step [508/735], Loss: 0.1894\n",
      "Epoch [50/50], Step [509/735], Loss: 0.0722\n",
      "Epoch [50/50], Step [510/735], Loss: 0.0608\n",
      "Epoch [50/50], Step [511/735], Loss: 0.0324\n",
      "Epoch [50/50], Step [512/735], Loss: 0.0828\n",
      "Epoch [50/50], Step [513/735], Loss: 0.0320\n",
      "Epoch [50/50], Step [514/735], Loss: 0.0488\n",
      "Epoch [50/50], Step [515/735], Loss: 0.1495\n",
      "Epoch [50/50], Step [516/735], Loss: 0.0468\n",
      "Epoch [50/50], Step [517/735], Loss: 0.0547\n",
      "Epoch [50/50], Step [518/735], Loss: 0.0390\n",
      "Epoch [50/50], Step [519/735], Loss: 0.0887\n",
      "Epoch [50/50], Step [520/735], Loss: 0.0408\n",
      "Epoch [50/50], Step [521/735], Loss: 0.0530\n",
      "Epoch [50/50], Step [522/735], Loss: 0.7212\n",
      "Epoch [50/50], Step [523/735], Loss: 0.0818\n",
      "Epoch [50/50], Step [524/735], Loss: 0.0614\n",
      "Epoch [50/50], Step [525/735], Loss: 0.0668\n",
      "Epoch [50/50], Step [526/735], Loss: 0.0845\n",
      "Epoch [50/50], Step [527/735], Loss: 0.0388\n",
      "Epoch [50/50], Step [528/735], Loss: 0.1177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Step [529/735], Loss: 0.1009\n",
      "Epoch [50/50], Step [530/735], Loss: 0.0367\n",
      "Epoch [50/50], Step [531/735], Loss: 0.0648\n",
      "Epoch [50/50], Step [532/735], Loss: 0.0626\n",
      "Epoch [50/50], Step [533/735], Loss: 0.0415\n",
      "Epoch [50/50], Step [534/735], Loss: 0.0172\n",
      "Epoch [50/50], Step [535/735], Loss: 0.0357\n",
      "Epoch [50/50], Step [536/735], Loss: 0.0227\n",
      "Epoch [50/50], Step [537/735], Loss: 0.0649\n",
      "Epoch [50/50], Step [538/735], Loss: 0.4479\n",
      "Epoch [50/50], Step [539/735], Loss: 0.3555\n",
      "Epoch [50/50], Step [540/735], Loss: 0.0401\n",
      "Epoch [50/50], Step [541/735], Loss: 0.0472\n",
      "Epoch [50/50], Step [542/735], Loss: 0.0355\n",
      "Epoch [50/50], Step [543/735], Loss: 0.0493\n",
      "Epoch [50/50], Step [544/735], Loss: 0.0638\n",
      "Epoch [50/50], Step [545/735], Loss: 0.0352\n",
      "Epoch [50/50], Step [546/735], Loss: 0.0425\n",
      "Epoch [50/50], Step [547/735], Loss: 0.0735\n",
      "Epoch [50/50], Step [548/735], Loss: 0.0153\n",
      "Epoch [50/50], Step [549/735], Loss: 0.0616\n",
      "Epoch [50/50], Step [550/735], Loss: 0.0513\n",
      "Epoch [50/50], Step [551/735], Loss: 0.0429\n",
      "Epoch [50/50], Step [552/735], Loss: 0.0304\n",
      "Epoch [50/50], Step [553/735], Loss: 0.0681\n",
      "Epoch [50/50], Step [554/735], Loss: 0.0439\n",
      "Epoch [50/50], Step [555/735], Loss: 0.1085\n",
      "Epoch [50/50], Step [556/735], Loss: 0.0258\n",
      "Epoch [50/50], Step [557/735], Loss: 0.2206\n",
      "Epoch [50/50], Step [558/735], Loss: 0.0205\n",
      "Epoch [50/50], Step [559/735], Loss: 0.1205\n",
      "Epoch [50/50], Step [560/735], Loss: 0.0381\n",
      "Epoch [50/50], Step [561/735], Loss: 0.0446\n",
      "Epoch [50/50], Step [562/735], Loss: 0.0216\n",
      "Epoch [50/50], Step [563/735], Loss: 0.0555\n",
      "Epoch [50/50], Step [564/735], Loss: 0.0368\n",
      "Epoch [50/50], Step [565/735], Loss: 0.0451\n",
      "Epoch [50/50], Step [566/735], Loss: 0.0219\n",
      "Epoch [50/50], Step [567/735], Loss: 0.0698\n",
      "Epoch [50/50], Step [568/735], Loss: 0.0181\n",
      "Epoch [50/50], Step [569/735], Loss: 0.0408\n",
      "Epoch [50/50], Step [570/735], Loss: 0.0165\n",
      "Epoch [50/50], Step [571/735], Loss: 0.0741\n",
      "Epoch [50/50], Step [572/735], Loss: 0.0652\n",
      "Epoch [50/50], Step [573/735], Loss: 0.0506\n",
      "Epoch [50/50], Step [574/735], Loss: 0.0537\n",
      "Epoch [50/50], Step [575/735], Loss: 0.0806\n",
      "Epoch [50/50], Step [576/735], Loss: 0.1343\n",
      "Epoch [50/50], Step [577/735], Loss: 0.0794\n",
      "Epoch [50/50], Step [578/735], Loss: 0.0430\n",
      "Epoch [50/50], Step [579/735], Loss: 0.0267\n",
      "Epoch [50/50], Step [580/735], Loss: 0.0221\n",
      "Epoch [50/50], Step [581/735], Loss: 0.0171\n",
      "Epoch [50/50], Step [582/735], Loss: 0.0310\n",
      "Epoch [50/50], Step [583/735], Loss: 0.0279\n",
      "Epoch [50/50], Step [584/735], Loss: 0.0622\n",
      "Epoch [50/50], Step [585/735], Loss: 0.1019\n",
      "Epoch [50/50], Step [586/735], Loss: 0.0858\n",
      "Epoch [50/50], Step [587/735], Loss: 0.0460\n",
      "Epoch [50/50], Step [588/735], Loss: 0.2252\n",
      "Epoch [50/50], Step [589/735], Loss: 0.0806\n",
      "Epoch [50/50], Step [590/735], Loss: 0.4758\n",
      "Epoch [50/50], Step [591/735], Loss: 0.0663\n",
      "Epoch [50/50], Step [592/735], Loss: 0.0321\n",
      "Epoch [50/50], Step [593/735], Loss: 0.0641\n",
      "Epoch [50/50], Step [594/735], Loss: 0.0373\n",
      "Epoch [50/50], Step [595/735], Loss: 0.0370\n",
      "Epoch [50/50], Step [596/735], Loss: 0.0330\n",
      "Epoch [50/50], Step [597/735], Loss: 0.0321\n",
      "Epoch [50/50], Step [598/735], Loss: 0.0599\n",
      "Epoch [50/50], Step [599/735], Loss: 0.0572\n",
      "Epoch [50/50], Step [600/735], Loss: 0.0450\n",
      "Epoch [50/50], Step [601/735], Loss: 0.0395\n",
      "Epoch [50/50], Step [602/735], Loss: 0.0284\n",
      "Epoch [50/50], Step [603/735], Loss: 0.0309\n",
      "Epoch [50/50], Step [604/735], Loss: 0.0603\n",
      "Epoch [50/50], Step [605/735], Loss: 0.0311\n",
      "Epoch [50/50], Step [606/735], Loss: 0.0345\n",
      "Epoch [50/50], Step [607/735], Loss: 0.0230\n",
      "Epoch [50/50], Step [608/735], Loss: 0.0225\n",
      "Epoch [50/50], Step [609/735], Loss: 0.0426\n",
      "Epoch [50/50], Step [610/735], Loss: 0.0325\n",
      "Epoch [50/50], Step [611/735], Loss: 0.0751\n",
      "Epoch [50/50], Step [612/735], Loss: 0.0234\n",
      "Epoch [50/50], Step [613/735], Loss: 0.0346\n",
      "Epoch [50/50], Step [614/735], Loss: 0.0432\n",
      "Epoch [50/50], Step [615/735], Loss: 0.0787\n",
      "Epoch [50/50], Step [616/735], Loss: 0.1078\n",
      "Epoch [50/50], Step [617/735], Loss: 0.0682\n",
      "Epoch [50/50], Step [618/735], Loss: 0.0233\n",
      "Epoch [50/50], Step [619/735], Loss: 0.0342\n",
      "Epoch [50/50], Step [620/735], Loss: 0.0735\n",
      "Epoch [50/50], Step [621/735], Loss: 0.1061\n",
      "Epoch [50/50], Step [622/735], Loss: 0.0158\n",
      "Epoch [50/50], Step [623/735], Loss: 0.0720\n",
      "Epoch [50/50], Step [624/735], Loss: 0.0120\n",
      "Epoch [50/50], Step [625/735], Loss: 0.0156\n",
      "Epoch [50/50], Step [626/735], Loss: 0.1180\n",
      "Epoch [50/50], Step [627/735], Loss: 0.0351\n",
      "Epoch [50/50], Step [628/735], Loss: 0.0626\n",
      "Epoch [50/50], Step [629/735], Loss: 0.0302\n",
      "Epoch [50/50], Step [630/735], Loss: 0.0323\n",
      "Epoch [50/50], Step [631/735], Loss: 0.0191\n",
      "Epoch [50/50], Step [632/735], Loss: 0.1506\n",
      "Epoch [50/50], Step [633/735], Loss: 0.0417\n",
      "Epoch [50/50], Step [634/735], Loss: 0.0687\n",
      "Epoch [50/50], Step [635/735], Loss: 0.0539\n",
      "Epoch [50/50], Step [636/735], Loss: 0.1046\n",
      "Epoch [50/50], Step [637/735], Loss: 0.0213\n",
      "Epoch [50/50], Step [638/735], Loss: 0.0359\n",
      "Epoch [50/50], Step [639/735], Loss: 0.0277\n",
      "Epoch [50/50], Step [640/735], Loss: 0.0265\n",
      "Epoch [50/50], Step [641/735], Loss: 0.0418\n",
      "Epoch [50/50], Step [642/735], Loss: 0.1131\n",
      "Epoch [50/50], Step [643/735], Loss: 0.0255\n",
      "Epoch [50/50], Step [644/735], Loss: 0.2449\n",
      "Epoch [50/50], Step [645/735], Loss: 0.0369\n",
      "Epoch [50/50], Step [646/735], Loss: 0.0434\n",
      "Epoch [50/50], Step [647/735], Loss: 0.0387\n",
      "Epoch [50/50], Step [648/735], Loss: 0.0790\n",
      "Epoch [50/50], Step [649/735], Loss: 0.0678\n",
      "Epoch [50/50], Step [650/735], Loss: 0.0865\n",
      "Epoch [50/50], Step [651/735], Loss: 0.0671\n",
      "Epoch [50/50], Step [652/735], Loss: 0.0206\n",
      "Epoch [50/50], Step [653/735], Loss: 0.0279\n",
      "Epoch [50/50], Step [654/735], Loss: 0.0601\n",
      "Epoch [50/50], Step [655/735], Loss: 0.0451\n",
      "Epoch [50/50], Step [656/735], Loss: 0.0910\n",
      "Epoch [50/50], Step [657/735], Loss: 0.0203\n",
      "Epoch [50/50], Step [658/735], Loss: 0.0609\n",
      "Epoch [50/50], Step [659/735], Loss: 0.0258\n",
      "Epoch [50/50], Step [660/735], Loss: 0.0332\n",
      "Epoch [50/50], Step [661/735], Loss: 0.0173\n",
      "Epoch [50/50], Step [662/735], Loss: 0.1105\n",
      "Epoch [50/50], Step [663/735], Loss: 0.0708\n",
      "Epoch [50/50], Step [664/735], Loss: 0.0481\n",
      "Epoch [50/50], Step [665/735], Loss: 0.0594\n",
      "Epoch [50/50], Step [666/735], Loss: 0.0478\n",
      "Epoch [50/50], Step [667/735], Loss: 0.0489\n",
      "Epoch [50/50], Step [668/735], Loss: 0.0282\n",
      "Epoch [50/50], Step [669/735], Loss: 0.0187\n",
      "Epoch [50/50], Step [670/735], Loss: 0.0307\n",
      "Epoch [50/50], Step [671/735], Loss: 0.0250\n",
      "Epoch [50/50], Step [672/735], Loss: 0.0774\n",
      "Epoch [50/50], Step [673/735], Loss: 0.0417\n",
      "Epoch [50/50], Step [674/735], Loss: 0.0843\n",
      "Epoch [50/50], Step [675/735], Loss: 0.0248\n",
      "Epoch [50/50], Step [676/735], Loss: 0.1038\n",
      "Epoch [50/50], Step [677/735], Loss: 0.0424\n",
      "Epoch [50/50], Step [678/735], Loss: 0.0217\n",
      "Epoch [50/50], Step [679/735], Loss: 0.0547\n",
      "Epoch [50/50], Step [680/735], Loss: 0.0294\n",
      "Epoch [50/50], Step [681/735], Loss: 0.0777\n",
      "Epoch [50/50], Step [682/735], Loss: 0.0459\n",
      "Epoch [50/50], Step [683/735], Loss: 0.0567\n",
      "Epoch [50/50], Step [684/735], Loss: 0.1008\n",
      "Epoch [50/50], Step [685/735], Loss: 0.0235\n",
      "Epoch [50/50], Step [686/735], Loss: 0.0397\n",
      "Epoch [50/50], Step [687/735], Loss: 0.0536\n",
      "Epoch [50/50], Step [688/735], Loss: 0.0395\n",
      "Epoch [50/50], Step [689/735], Loss: 0.0379\n",
      "Epoch [50/50], Step [690/735], Loss: 0.0588\n",
      "Epoch [50/50], Step [691/735], Loss: 0.0270\n",
      "Epoch [50/50], Step [692/735], Loss: 0.0629\n",
      "Epoch [50/50], Step [693/735], Loss: 0.0280\n",
      "Epoch [50/50], Step [694/735], Loss: 0.0938\n",
      "Epoch [50/50], Step [695/735], Loss: 0.0566\n",
      "Epoch [50/50], Step [696/735], Loss: 0.0796\n",
      "Epoch [50/50], Step [697/735], Loss: 0.0544\n",
      "Epoch [50/50], Step [698/735], Loss: 0.0149\n",
      "Epoch [50/50], Step [699/735], Loss: 0.0406\n",
      "Epoch [50/50], Step [700/735], Loss: 0.0410\n",
      "Epoch [50/50], Step [701/735], Loss: 0.0370\n",
      "Epoch [50/50], Step [702/735], Loss: 0.0364\n",
      "Epoch [50/50], Step [703/735], Loss: 0.1554\n",
      "Epoch [50/50], Step [704/735], Loss: 0.1142\n",
      "Epoch [50/50], Step [705/735], Loss: 0.0200\n",
      "Epoch [50/50], Step [706/735], Loss: 0.0755\n",
      "Epoch [50/50], Step [707/735], Loss: 0.0347\n",
      "Epoch [50/50], Step [708/735], Loss: 0.0233\n",
      "Epoch [50/50], Step [709/735], Loss: 0.0134\n",
      "Epoch [50/50], Step [710/735], Loss: 0.0387\n",
      "Epoch [50/50], Step [711/735], Loss: 0.0388\n",
      "Epoch [50/50], Step [712/735], Loss: 0.0171\n",
      "Epoch [50/50], Step [713/735], Loss: 0.0211\n",
      "Epoch [50/50], Step [714/735], Loss: 0.2959\n",
      "Epoch [50/50], Step [715/735], Loss: 0.0178\n",
      "Epoch [50/50], Step [716/735], Loss: 0.1201\n",
      "Epoch [50/50], Step [717/735], Loss: 0.0756\n",
      "Epoch [50/50], Step [718/735], Loss: 0.0212\n",
      "Epoch [50/50], Step [719/735], Loss: 0.0670\n",
      "Epoch [50/50], Step [720/735], Loss: 0.0551\n",
      "Epoch [50/50], Step [721/735], Loss: 0.0356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Step [722/735], Loss: 0.0675\n",
      "Epoch [50/50], Step [723/735], Loss: 0.0273\n",
      "Epoch [50/50], Step [724/735], Loss: 0.0394\n",
      "Epoch [50/50], Step [725/735], Loss: 0.0462\n",
      "Epoch [50/50], Step [726/735], Loss: 0.0536\n",
      "Epoch [50/50], Step [727/735], Loss: 0.0222\n",
      "Epoch [50/50], Step [728/735], Loss: 0.0390\n",
      "Epoch [50/50], Step [729/735], Loss: 0.0296\n",
      "Epoch [50/50], Step [730/735], Loss: 0.0422\n",
      "Epoch [50/50], Step [731/735], Loss: 0.0486\n",
      "Epoch [50/50], Step [732/735], Loss: 0.1545\n",
      "Epoch [50/50], Step [733/735], Loss: 0.0290\n",
      "Epoch [50/50], Step [734/735], Loss: 0.0619\n",
      "Epoch [50/50], Step [735/735], Loss: 0.0116\n"
     ]
    }
   ],
   "source": [
    "# Set device (CPU or GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Model parameters\n",
    "input_dim = N\n",
    "hidden_dim = 128\n",
    "output_dim = N\n",
    "num_layers = 1\n",
    "num_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Initialize the model, loss function and optimizer\n",
    "model = LSTMModel(input_dim, hidden_dim, output_dim, num_layers).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "epoch_loss = []\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "        #if (i+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf052e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.figure(1, figsize = [20,10])\n",
    "plt.semilogy(epoch_loss)\n",
    "plt.ylabel('Loss(log scale)')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6c66ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriniva3\\AppData\\Local\\Temp\\ipykernel_34224\\1681708791.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_inputs = torch.tensor(inp_test_data, dtype=torch.float32).to(device)\n",
      "C:\\Users\\sriniva3\\AppData\\Local\\Temp\\ipykernel_34224\\1681708791.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_targets = torch.tensor(out_test_data, dtype=torch.float32).to(device)\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    test_inputs = torch.tensor(inp_test_data, dtype=torch.float32).to(device)\n",
    "    test_targets = torch.tensor(out_test_data, dtype=torch.float32).to(device)\n",
    "    test_outputs = model(test_inputs)\n",
    "    test_loss = criterion(test_outputs, test_targets)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce79837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, 'LSTM.pth')\n",
    "#torch.save(model.state_dict(), 'LSTM_state_dict.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "199e3c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## CDF plots ###########\n",
    "pred = test_outputs.detach().numpy()\n",
    "tgt = test_targets.detach().numpy()\n",
    "error = tgt - pred\n",
    "#pred = pred.flatten()\n",
    "#tgt = tgt.flatten()\n",
    "sortd_pred, a_pred = return_cdf(pred[:,0])\n",
    "sortd_tgt, a_tgt = return_cdf(tgt[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "044e0a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(sortd_pred, a_pred)\n",
    "#plt.plot(sortd_tgt, a_tgt, alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4bf13b9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkEAAAGdCAYAAAAVEKdkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADIhUlEQVR4nOydd5xcZb3/32dmzvTtJbtJNp0ECCWhVxNAulwVRdF71Vy9ohdQkWu5FhRUwHZVsP4UBVFRUYooHZQaOiQkBNJ7sinbZ6edOef5/fGcM7MzO7M7bXdnds/79corOzOnPHPmlM/zrYoQQmBjY2NjY2NjM8VwTPQAbGxsbGxsbGwmAlsE2djY2NjY2ExJbBFkY2NjY2NjMyWxRZCNjY2NjY3NlMQWQTY2NjY2NjZTElsE2djY2NjY2ExJbBFkY2NjY2NjMyWxRZCNjY2NjY3NlMQ10QOoNAzDYM+ePdTU1KAoykQPx8bGxsbGxiYPhBAMDAwwffp0HI78bDy2CMpgz549dHR0TPQwbGxsbGxsbIpg586dzJw5M69lq0YE3Xjjjdx999289dZb+Hw+TjnlFL7zne+waNGi5DIrVqzgt7/9bdp6J554Is8//3ze+6mpqQHkQaytrS3P4AFN03jkkUc455xzUFW1bNudzNjHrDDs41U49jErDPt4FYZ9vAqnlGPW399PR0dH8jmeD1Ujgp588kmuuOIKjj/+eBKJBF/5ylc455xzWLduHYFAILnceeedx6233pp87Xa7C9qP5QKrra0tuwjy+/3U1tbaF0Oe2MesMOzjVTj2MSsM+3gVhn28Cqccx6yQUJaqEUEPPfRQ2utbb72V1tZWXnnlFd72trcl3/d4PLS1tY338GxsbGxsbGyqjKoRQZn09fUB0NjYmPb+E088QWtrK/X19Sxbtozrr7+e1tbWnNuJxWLEYrHk6/7+fkCqUU3TyjZea1vl3OZkxz5mhWEfr8Kxj1lh2MerMOzjVTilHLNi1lGEEKLgtSYYIQTvfOc76enp4emnn06+/+c//5lgMMjs2bPZunUr11xzDYlEgldeeQWPx5N1W9deey3XXXfdsPfvuOMO/H7/mH0HGxsbGxsbm/IRDof54Ac/SF9fX97hLFUpgq644gruv/9+nnnmmREjwPfu3cvs2bP505/+xMUXX5x1mWyWoI6ODg4ePJjzIOq6TiKRoJBDl0gkWLlyJaeccgouV9Ua4MaVsTpmiqLgdDpxOp2TqgyCpmk8+uijnH322Xb8QZ7Yx6ww7ONVGPbxKpxSjll/fz/Nzc0FiaCqexp/6lOf4r777uOpp54aNQWuvb2d2bNns3HjxpzLeDyerFYiVVWz/gChUIhdu3YVJIBAWq/a2trYu3fvpHrwjiVjfcz8fj/t7e0FB89XOrnOXZvc2MesMOzjVRj28SqcYo5ZMce4akSQEIJPfepT3HPPPTzxxBPMnTt31HW6urrYuXMn7e3tZRmDruvs2rULv99PS0tLQQ9mwzAIhUIEg8G8izhNdcbqmAkhiMfjHDhwgK1bt3LIIYfYv4mNjY3NFKRqRNAVV1zBHXfcwd/+9jdqamro7OwEoK6uDp/PRygU4tprr+U973kP7e3tbNu2jS9/+cs0Nzfz7ne/uyxj0DQNIQQtLS34fL6C1jUMg3g8jtfrtR+4eTKWx8zn86GqKtu3b0/uw8bGxsZmalE1IujnP/85AMuXL097/9Zbb2XFihU4nU7WrFnD7bffTm9vL+3t7Zxxxhn8+c9/LqhwUj7Y7qzJgS1GbWxsbKY2VSOCRovB8fl8PPzww+M0GhsbGxsbG5tqx54K29jY2NjY2ExJbBFkU1bmzJnDj370o+RrRVG49957x30c1157LUuWLBn3/drY2NjYVA+2CLIZU/bu3cv555+f17K2cLGxsbGxGU9sEWQzjHg8XrZttbW15azWbWNTsXSuhed+CnpiokdiY2MzhtgiqASEEITjibz/ReJ6QcuP9K+QYo3Lly/nyiuv5Morr6S+vp6mpia++tWvJrcxZ84cvvWtb7FixQrq6ur4+Mc/DsDKlSt529vehs/no6Ojg09/+tMMDg4mt7t//34uuugifD4fc+fO5Q9/+MOwfWe6w3bt2sWll15KY2MjgUCA4447jhdeeIHbbruN6667jtWrV6MoCoqicNtttwGyT9xll11Ga2srtbW1nHnmmaxevTptP9/+9reZNm0aNTU1fOxjHyMajeZ9fGxs0kjEEL8+Gx7+MsZLv57o0djY2IwhVZMdVolENJ3DvzYxGWnrvnEufnf+P99vf/tbPvaxj/HCCy/w8ssvc9lllzF79uyk4Pne977HNddcw1e/+lUA1qxZw7nnnss3v/lNfv3rX3PgwIGkkLr11lsBWLFiBTt37uSf//wnbrebT3/60+zfvz/nGEKhEMuWLWPGjBncd999tLW18eqrr2IYBu9///tZu3YtDz30EI899hgANTU1xONxLrroIhobG3nggQeoq6vj//2//8dZZ53Fhg0baGxs5M477+TrX/86P/3pTzn99NP53e9+x80338y8efOKPbw2U5lXb0fRwgCEnvoJtSdeBnZZDBubSYktgqYIHR0d/PCHP0RRFBYtWsSaNWv44Q9/mBRBZ555Jp/73OeSy3/4wx/mgx/8IFdddRUAhxxyCDfffDPLli3j5z//OTt27ODBBx/k+eef58QTTwTg17/+NYcddljOMdxxxx0cOHCAl156icbGRgAWLFiQ/DwYDOJyuWhrawNkscTHH3+cNWvWsH///qRb7fvf/z733nsvf/3rX7nsssv40Y9+xEc/+lH+67/+C4BvfetbPPbYY7Y1yKZwhCDyzE+xSqHWhncgdjyHMvuUCR2WjY3N2GCLoBLwqU7WfePcvJY1DIOB/gFqamvKUqTPpzoLWv6kk05KK/J48skn83//93/oug7Acccdl7b8K6+8wqZNm9JcXEIIDMNg69atbNiwAZfLlbbeoYceSn19fc4xrFq1iqVLlyYFUD6sWrWKUChEU1NT2vuRSITNmzcD8Oabb/LJT34y7fOTTz6Zf/3rX3nvx8YGgB3P4+vfSkh4ecJYwjucz9P31P+j/kO2CLKxmYzYIqgEFEXJ2yVlGAYJtxO/21WRlYoDgUDaa8Mw+MQnPsGnP/3pYcvOmjWL9evXA4VVzy601Yg1jvb2dp544olhn40kuGxsiiH+6h9wAw/oJ/I7/Wze4Xye4Jb7QYuAWvj5WxI7XoBgKzSO3ifRxsamOCrvaWwzJjz//PPDXh9yyCE4ndktSscccwxvvPEGCxYsGPbP7XZz2GGHkUgkePnll5PrrF+/nt7e3pxjOOqoo1i1ahXd3d1ZP3e73UnLlMXRRx9NZ2cnLpdr2Diam5sBOOyww7J+PxubghAC460HAXgxeCb/9b53s0/U4xIaYvcr4zuWvavhN+fAzUsg0ju++7axmULYImiKsHPnTq6++mrWr1/PH//4R3784x/zmc98JufyX/ziF3nuuee44oorWLVqFRs3buS+++7jU5/6FACLFi3ivPPO4+Mf/zgvvPACr7zyCv/1X/81orXnAx/4AG1tbbzrXe/i2WefZcuWLdx1110899xzgMxS27p1K6tWreLgwYPEYjGWL1/OySefzLve9S4efvhhtm3bxsqVK/nqV7+aFGCf+cxn+M1vfsNvfvMbNmzYwNe//nXeeOONMh49mynB/nV4YweJCDetR5zBmYdN41WxCICet54Z37H8v7cl/zRW/2l8921jM4WwRdAU4cMf/jCRSIQTTjiBK664gk996lNcdtllOZc/6qijePLJJ9m4cSOnn346S5cu5ZprrqG9vT25zK233kpHRwfLli3j4osvTqax58LtdvPII4/Q2trKBRdcwJFHHsm3v/3tpDXqPe95D+eddx5nnHEGLS0t/PGPf0RRFP7xj3/wtre9jY9+9KMsXLiQSy+9lG3btjFt2jQA3v/+9/O1r32NL37xixx77LFs376d//7v/y7TkbOZKogtTwDwonEoyw6fSY1XZU/t0QDEtz47fgNZ97e0l9orvxu/fdvYTDHsmKApgqqq/OhHP+LnP//5sM+2bduWdZ3jjz+eRx55JOc229ra+Mc//pH23oc+9KG015n1jGbPns1f//rXrNvzeDxpnxmGQX9/PzU1Ndx8883cfPPNOcfy5S9/mS9/+ctp733nO9/JubyNTSaxHa/iBV4Wi7iio16+N+NkWP9LGg68DIk4uNxjPg7jrQeSs9OYcOE5sFa6x9qPHvN929hMNWxLkI2NjQ2Q2CtdqL3BQ/Ca2ZfN84/lgKjFY4Rh5wvjMo6Bra8C8LH4//CoYWZfvja8EKmNjU3p2CLIxsbGRtfw9W0CQGlbnHz7uLlNPGMcCYC24bGxH4cWoWZAln54w5jDnfoy+faqP0MiNvb7t7GZYtgiaArwxBNPpHV2t7GxyaB7C06hMSg8tHYcknx7bnOANZ5jAIhsGIe6U/vX4UDnoKjlsxcvY2D6aewRjajxXlj/wNjv38ZmimGLIBsbmymPcmAdABtEB4dNr0+9rygwV2ZqBbvWQGxgTMdh7JE98dYZszl6VgNfeccR3KXL/SfsAGkbm7JjiyAbG5spj9EpRdBbRgeHttemfXbYosPYYbTgwJAFDMeQgS0vyXEo81jQEuTY2Q28VCer0ju2/Av694zp/m1sphq2CLKxsZnyRHavBWCbazbT67xpn500r4kXheyJF9+6ckzHYeyWQdH9jUficjpQFIVTTjiRF4xDpQh7fnh2p42NTfHYIsjGxsamZysARsOCYa1gOhr9bPNKERTa8uLYjUGLUNu/EQB3x7HJty9eOoNf6xcCoL/6eztA2samjNgiyMbGZmojBN5B6WaqaZuXdRFnh0xV9x1YDRm1r8pG51qcZlD03PmLkm+31noRC85hr2jEGe2GN/8+Nvu3sZmC2CLIxsZmSqPqYVkHCKhvz96sdPZhxxETLnx6P3RvGZNxJMx4o1XGfI7uaEj77NKT5nKnvhwA/eXbxmT/NjZTEVsE2djYTGl88YMAHBS1tDY2Zl3mqNmtrBNzANB2jk0z1YGNsj/ZG85D6WhM78G3fFErTwbOQxcKzu1Pw8FNYzIGG5uphi2CpgDLly/nqquumuhhJKm08dhMbfymCNotmplRn70B8NzmAOudsn7QgbfGIDhaCNQ9siGw1n7csLgkp0PhrJOO5QljiXzjNTtd3samHNgiyCYv4vH4RA/BxmZM8MZSIqi93pt1GadDIdQke3e5Ol8r/yD6dhGMHyAhHDQfekrWRS49voN7hFlBevWdYBjlH4eNzRTDFkGlIATEB/P/p4ULW36kf3kGZ65YsYInn3ySm266CUVRUBSFzZs387GPfYy5c+fi8/lYtGgRN91007D13vWud3HjjTcyffp0Fi5cCMDKlStZsmQJXq+X4447jnvvvRdFUVi1alVy3XXr1nHBBRcQDAaZNm0aH/rQhzh48GDO8eRq4GpjMx44o/Lc7FRaaAqM0CB1xlIAGvrWgZ4o7yB2yayzdWI2h89qy7pIU9CDOORc+oUPNbQHdj5f3jHY2ExB7C7ypaCF4YbpeS3qAOrLue8v7wF3YNTFbrrpJjZs2MARRxzBN77xDQAaGhqYOXMmd955J83NzaxcuZLLLruM9vZ23ve+9yXXffzxx6mtreXRRx9FCMHAwAAXXXQRF1xwAXfccQfbt28f5tbau3cvy5Yt4+Mf/zg/+MEPiEQifPGLX+R973sf//znP7OOp6WlpXzHxcamQNyxLgBC3vZhbqihtMw5nPAqD35iMji6ZWHZxhDa9BxB4FVjIe+dXptzuXccM5eHNp7A+1xPIl6/E2V2dquRjY1NftgiaJJTV1eH2+3G7/fT1paaYV533XXJv+fOncvKlSu5884700RQIBDglltuwe2Ws+Nf/OIXKIrCr371K7xeL4cffji7d+/m4x//eHKdn//85xxzzDHccMMNyfd+85vf0NHRwYYNG1i4cGHW8djYTBSBuBRB8cCMEZdb1F7PetHBUmUT4R2r8JdRBEV3vEoQ6Kk/gqAn9235jENb+ZTzdN7HkyTW3IN6/nfBNYL1ysbGZkRsEVQKql9aZPLAMAz6BwaoranB4SiDF1L1l7T6L37xC2655Ra2b99OJBIhHo+zZMmStGWOPPLIpAACWL9+PUcddRRebypu4oQTTkhb55VXXuFf//oXwWBw2D43b96cdKvZ2FQKtQnpDqOhY8TlFk2r4Y/GLJY6NtG37VX8x75vxOXzRggCfesB8M9aMuKiXtVJw+Kz2P/GT2iN98Lmf8Ki88ozDhubKYgtgkpBUfJySQEyiFHV5fLlEEElcOedd/LZz36W//u//+Pkk0+mpqaG733ve7zwQnpfpEAg/bsJIYa5C0RGbJJhGFx00UV85zvfGbbf9vb2Mn0DG5syocepEbIpqr9p1oiLKorCvsAiiP2T+M5XyzeG3h349BBx4aRl7hGjLv7OY2bx99dP5mOuB9FX/xmnLYJsbIrGDoyeArjdbnRdT75++umnOeWUU7j88stZunQpCxYsYPPmzaNu59BDD+X1118nFkuV7X/55ZfTljnmmGN44403mDNnDgsWLEj7Z4mqzPHY2EwYg9IKpAkn9U3TRl38YO3hADQPvFW2ytGicw0AG8VMDp3RPOryJ81r4inPcvli/QMQC5VlHDY2RfPcT+HaOrjr42NXUX2MsEXQFGDOnDm88MILbNu2jYMHD7JgwQJefvllHn74YTZs2MA111zDSy+9NOp2PvjBD2IYBpdddhlvvvkmDz/8MN///vcBkhaiK664gu7ubj7wgQ/w4osvsmXLFh555BE++tGPJoVP5ngMO9XXZoJQQvsAOEgd0xtGdzEvO+10DKEQ0PsgtL8sY+jfJlPu1zObBa3D3ciZOB0Kc486jS1GG049KoWQjc1E8vCX5f9r7oSdL4y8bIVhi6ApwOc+9zmcTieHH344LS0tnHfeeVx88cW8//3v58QTT6Srq4vLL7981O3U1tby97//nVWrVrFkyRK+8pWv8LWvfQ0gGSc0ffp0nn32WXRd59xzz+WII47gM5/5DHV1dclYqMzx7NixY+y+vI3NSAweAGS16Ok5CiUO5bCOaWwT0mKk71tXliFEd60G4ID/ENyu/G7JJ81v5j5DZoYZr/+5LOOwsSmKjHIRkZW/mqCBFIcdEzQFWLhwIc8991zae7feeiu33npr2ns33nhj8u/bbrst67ZOOeUUVq9enXz9hz/8AVVVmTUrFU9xyCGHcPfddxc0HhubiSDe14kLOCDqOb4ue6HEocyo9/G40sE8OuneupqWBWeUPAZPlxRTeuvo8UAWyxe18DPXMq7ibpTN/5JuvcDorjSbSUrfLrjl7XDke+Gcb43vvvt3pb30vfVXCH8P/Nlb0FQatiXIpiBuv/12nnnmGbZu3cq9996brAHk840+i7axqTRCXXsB6HPWU+NVR13e4VDo8s8HILp7TekDiA1QH90NQHD2krxX86pOFh91DKuNeShChzfuKX0sNlWLePEWGNgLK38MidjoK5SRnj2yj92ASD0DYjtezrV4xWGLIJuC6Ozs5D/+4z847LDD+OxnP8sll1zCL3/5y4kelo1NUcT7OwGIupvyXifWdBgA6sEyuMMOyNT4faKeebNGzk7L5OJjZnKfbrrEVv+x9LHYVC0H96dKtYhd4ytA+kwR9KpxCP/QTwJgx2uPj+sYSsEWQTYF8YUvfIFt27YRjUbZunUrP/zhD/H7S6tZZGMzUYhIPwAJd+4qzZm4ZxwJQOPg5pL7d8X2rAVggzGTw9prClr3uNkNrPQtRxNOHLtfgb2rR1/JZnKy/83kn5GNT43rruMHtwLQ65nOLiGr/x+y/hfjOoZSqBoRdOONN3L88cdTU1NDa2sr73rXu1i/fn3aMkIIrr32WqZPn47P52P58uW88cYbEzRiGxubiicuawTpav4CpG32IhLCgVvEINRZ0u57t0nhskudQ1PQU9C6iqJw2tLF/MvqLL/+wZLGYlOlGAa1AxuTL0PrnxjX3Tv6zMSW+llsajgt+b6+rTriPqtGBD355JNcccUVPP/88zz66KMkEgnOOeccBgcHk8t897vf5Qc/+AE/+clPeOmll2hra+Pss89mYGCgrGPJLBBoU53Yv6ONIy5r7Ah3/iJoQVsje4R0nyUOjl5fayT0fXIGH64vrpL6f546l0eNYwHQVt1ZdTVabMpA3w48RiT5sqHrNUjEx233jr6dACRqO5h7zNuT7ztvOw/e/Pu4jaNYqkYEPfTQQ6xYsYLFixdz9NFHc+utt7Jjxw5eeeUVQD7QfvSjH/GVr3yFiy++mCOOOILf/va3hMNh7rjjjrKMwel0AhCPj98JZjN2hMNhAFR19IBYm8mJUzMLDXryF0Ez6n3sUmTfu66dG0raf7BPru9qX1zU+tPrffTOuYAB4UPt3QxbnihpPDbVhyWk3zQ6OChqUUUM9pSxovlIGAYtYRkTtEGbxrmLp3GvPqSp75//A/asGp+xFEnVpsj39fUB0Ngo0/C2bt1KZ2cn55xzTnIZj8fDsmXLWLlyJZ/4xCeybicWi6VVQO7vlzECmqahaVraskIIvF4v+/fvx+l0FtQDTAhBPB4nEomM2KnaJsVYHTMhBOFwmAMHDlBbW4thGJOiYKN1vmaetza5cSVFUKCg49brmQHxNYT2rqex2OMd6aE2IZu3NsxaXPTvdt7S+dy1/XRWuB5Bf/4XGLNOG32lIrHPscIYj+PVv+11moBNYgZbRDsXOl+kf/1T+NqPHbN9WoiBfdQoEQyhoE4/nNkNXt6rfYR3OVcml9Gf/B7Ge2/Le5ulHLNi1qlKESSE4Oqrr+a0007jiCNkbY3OTumbnzYtvfT9tGnT2L59e85t3XjjjWkd1S0eeeSRrAG/DoeDlpaWpFiyqU4Mw2BgYICNGzeOvnCV8eijj070EKqGt8Xldbz3YB8PPJB/5eVeUS//3/Y6awtYbyj1oU0sA/aKRvZs2cADncVZlQwd/izOZgWP4Nj4MM/eeRM9wUOK2la+2OdYYYzl8Zq38WmagL3OGbgVAwSsW/U8+8JjX0nc1b+NC5EV12dHtvDAA1s4Y46fedt+z0PuL7LQsZvejc/zTBHXSDHHzLLuF0JViqArr7yS119/nWeeeWbYZ9kafI5kRfjSl77E1VdfnXzd399PR0cH55xzDrW12TNGDMNA07SCYkoSiQQrV67klFNOweWqysM+7ozVMVMUBZfLlXRvThY0TePRRx/l7LPPtl18eaKvugyAOYcs5oKzT897vb/17YAt0Oro56gLLihq36EXfwcbYato50PvOi/vatHZeEl/g7teP433OJ/htNhj6O/7TNHbGgn7HCuM8ThevT/+LgB6y+HUe+OwE5pcEY4t8rwshB3P3wuboUtp5F0Xyf2dNBjnnm8/wcXx63jd83GajINccPpSqMmvgXYpx6wY40TVPY0/9alPcd999/HUU08xc+bM5PttbdJH39nZmdatfP/+/cOsQ0PxeDx4PMOzMlRVHfEHyLbOSGiaRiKRIBgM2jePPLGPWXGMdu7amBg6qogC4KlpKOiYeVoXwBaoi+0p+liHOzfSABxwdxDwFXY/yeRjp8/nI69eykWO53DveA7Hq7fCCR+HMXK9j9k59urv4M374N3/r2oqDufDmB0vIagJbQHAM/1wVNEFOyEQ7RyXe4DWJ+sTDahNyf1Nq1f51+eWc8b3n2CNmMvRyhZiG/5F8KSPFLTtYo5ZMd+5agKjhRBceeWV3H333fzzn/9k7ty5aZ/PnTuXtra2NBNaPB7nySef5JRTTsncnI2NzVQnlpo1ev11Ba0abJNVo2v1HogPjrJ0dvQD0hU7WDN3lCVHZ1FbDc66GfxBN7NzHvw8/O5doEVL3va4cWA93HclbHwEvlv6MZkS9O/Ba4RJCAezFxyJp3k2AHXxfeOy+0SvrLg+6GlNe39uc4DVXz+Hp4yjANjyQuVmiVWNCLriiiv4/e9/zx133EFNTQ2dnZ10dnYSicjUQEVRuOqqq7jhhhu45557WLt2LStWrMDv9/PBD35wgkdvY2NTccRk6YyYUAsu+NnaOo0+Ya7TkzvmcCS8fXIGL5rmF7V+Jn+67CT+L3EJmw3TEr7lCbj3v8uy7XHh0a9P9AiqDmO/rJW3XUxjXnsjtS2y6nhADBYtzgtB65MtX/TAcG9LnU/lGV0WFm3ufmXMx1IsVSOCfv7zn9PX18fy5ctpb29P/vvzn1MdlL/whS9w1VVXcfnll3Pcccexe/duHnnkEWpqCqvEamNjMwUwRVAIL0FPYfFhM+p97BRy9mtVzC0Iw6A+Kuur+KcfVvj6Weho9LPijKM4K/5/fDT+ObmbdX8b915SRbH1KdiQUezxxerqRj4R9O+SFcc3M4OOBh/Nzc2EhNkIeKC0Qp754A/Jc1htym65u+SCcwGYrnRDLDTm4ymGqhFBQois/1asWJFcRlEUrr32Wvbu3Us0GuXJJ59MZo/Z2NjYpKFJK3JYeAl6CguPrPOp7Fbk7Hegc1Ph++7fhVvEiQsns+YeWvj6Ofifcxby/uM6+KexlH7hxyF0wnvXj77iRGIY8MhXAbgtkSpxwgOfgzV/naBBVQehTlmss8fbgcvpYFqtl32iAYDwwR1jvv+GiLSCxurnZf38xMXz6RLSCKEdKOI6GQeqRgTZ2JSd3p0Q2j/8fV2TXbm/vwiurZP//nCJ/H/b8IxEm+pEmO6CKG5qvIWJIEVR6PfIZIzowcLdYfF9lhujjTkt5bNUK4rCd957FG9cdx4bxQwADm6p8J5ia/4Ce1cTws/NiYu5OHZt6rO7PjZhw6oGdLNieaJWxgIFPC4OKjKgvP/AzjHddyTURyvdAGwX2TO/ZtT72CqmAzCw+82sy0w0VZcdZmNTFl66Be7/HwDiTYfjfttnAAVW35G96u7GR+T/t10IR74P3vUzcNoZWBVLIgada2WGUWN2U70Wi+AGIrhpKdASBKD52yAOib69Ba/bt/NNWoDtynQWBNwFrz8aAY+LnsB8iGwksqeC+ycaOjxxAwA/0y6im1q6hR2+kC/uASl0atoXJN/rd7eABtGuXWO67+6dbzIDOChqaWlty7qMw6GwV+0AfT3RvZUpgmxLkM3UY+vTSQEE4O5aB/d8Au65LL+2A2vuJPH49anXfbtgd+UG/k0pYiF49GvwrVa45Uy4eQn8+UNZF42EzcBo3PjdhdeMUmrljd8ZKlwExUxLULd39phVkI/UyYKJyoG3xmT7ZeGtf0DPNnpEkFv1c7np0iWAwtLokC7k1RDTNBEIQWNcpqjXTk8Vx4yamVoJM2h5rIiabtYtop13HJW7BlCPX05CEp3rxnQ8xWKLIJupxeo/w2/fkXz5y8SFvGQsRBOph+Au0cxZse8xJ3oH86O/4+LYtVwcu5avav+ZXMa18ofQtxtW/hh+eAT86kzY/M9x/So2GQgBt78Tnr0p/f0374MbOyDSm/Z2LCLdYTHcRQkRd72sU+aNZnGpjoKjS8ZHRGrHLhXcYwZcBwdKa/I6ZiRiiMeuBeB2/WzOPHIu/3b0dP582Un0kLIGiXEI8K1KQvvwEEcXCs3TUxmGCStTa6BwcV7Q7vdIcR2tmYvLmVtKeGfIuFxvT2VW57fdYTZTh/igtPaYnBz9MXuR3cAdGBhZ5gQ6Tl4VssP3q/pCnjSO4jH35/EoCfjh4WnL9qy6j4b5Z47hF7DJiRBw6wWw+2UAdnvm87mBS/lMzb84KbZS1gR67OtwUUogxU0RpCnFuaMCzVIE1WgH5f4LEFKBkMwoE00LRlmyeJrnLYFXoVXbJa0prtIKMpadlTejdG9hv6jnD65388A7F6MoCsfObgAU9opG2pVuYq/fhXfZ1aNubqoR3b8ZL7BHNNPRUp98X6lth33gDhcuzvPet6azdf0qjnZCtC57ULRF7ayj4C1oiu2oyPPQtgTZTB1euS3555mx7ycFEJBVAF15xgJuePeRfPbtC7nzEyfz2jVns1NM4/3xr6UtFxbyotY2PTk247YZnfUPwg7ZtPFe/RRO7fsmzxmLubTvSr6smcG1r9yWZiXSolIExYsUQQ3TZDCqR8Qg2pf/iokYNXH5gAq0jV2Pr/nzDqFf+HFhMLCrwlwRfbswnvw+ADdoH+TKc4+mOSivI5fTwabrz0c3r8nYvsrMKppoenbLXnN7HNOo86fiE90NUpwHYmMngn7zr3XJJqn73DNHXPaIQxfRL/w4MYjtK64/3lhiW4JspgZaBB7+MgA/TryLLWbGwuYbLsDpyH8Gv+3bF/K1v63lqOfa+A/n4/zTWEqnaOAVzydpjWyRLrK6GWPyFWxyoEXhTx9IvvzaELclwB36WcxS9vNJ19/h8W/Aoe+ApvloMdlsMVGkCGpvbqBXBKhXBhH9e1B89fmt2LcLB4Kw8NDSNvIDpBTq/G5ecc7jWGMt+9c/R82cpWO2r4IQAv7+GRx6lBeMQ9nafgH/d+LstEVcTgc/E+/lBuUXhPdvpbB63lOD8D7p5uz1TE9739/cAUBtoqtgC2W+NKxP1efTpp8w4rIzGvysooOlrKd76yraZxxZ9vGUgm0JspkaPHtz8s/fJM4DYNXXzi5IAFl8451HcMX5x/Ez/Z3s883n6+8/jTVCmoSjtjVo/Pn5yck//z3+JfoJcPycBh67elny/e8k3s8rYhEYCXj6/wDQY9ISVKwImlbnoVPIdOSBAtKRhVlhepdoZnZzsKh958v+msUAJHa8PKb7KYg37oZNjxEVKl/XVvDlCw/Peh1uTUhLbXh/EcUopwCiWx6XaHBW2vv1LXISppKAcNeY7NvolwHZa405XLp8ZHGtKAr7vDL2LWwWd6wkbBFkM/nRE8k03Af14+mhlhPmNlLvLz41+RPL5rPt2xfy2tfO4V1LZvCSsQiA7reeLsuQbfJk2zPQLdtP/DjxLp41juTfT5zFXz55Cgtagzz1+TMAEDj4Rvzf5Tqr/wTdWzDislii4SzuPPC4nPQ6C6/JEtonx7tLtDCj3lfUvvMlMe1oAPzdFZImP9CJ8Q+ZmfkL/SLmLj6BE+c1ZV20xy0zjmYqB2VBRZs03P2yGKKoT7eiTWus5YCoBcAYowyx6RwA4B/6SfjdozuUBmpl7Jurq/IyFW0RZDP5WZuqOvuLxEUA/OnjJ5Vt84qiIDqkSdi1+8WybddmdIxVdyT/vjlxMRcvncH1706Z22c1+dnwrfMBWC0W8E99CQgdVv4YEZfuML1ISxBAyExHDhdQkyVkujF63O24XWN7C66ZezwAbZFNkIiP6b5GRQjE367EEe1hrTGHW7iYb70rd0X/n3ziQgyh4FE0+EYDvPLbcRxs5VMblQLH05ree6456GFf0kI5NrWCZhtS9J9+6tvyWj5UK2PfaiswU9EWQTaTnv6HvglASHhZLeSMxFGEG2wk6g45DYDm8ObCgmRtikdP4Fj1BwA+Hr8aDRc3XDw83sDtcvDzfz8GgF/qZnmE1X9GjUpXQbGWIADNJ9OR9d78Z9yJLukOiwTGPnZs/sLF9Ak/KgkGJtgVId64B2XTo8SEylXa5Xz/0uNoCubOFJo7rQGHIlJv/P3TsL8yC+6NO/Ew9bo8f+tnpAfXq04HPU5pXQuNUeuM2oTcd03r7FGWlHinS7dsXXRXsl1NpWCLIJtJT21EzoYeMqS15qGrTi/7PubMmcc2YxoOBOx4oezbt8nCm/cl/1xjzOWf/7MMr5q96OH5R7bzkZNn87xxGDudHaANsqjnCQAMR/Epu6JGumwcofxr2bgsN0bdrFGWLJ2OpgAbHNJS0L3+2THfXy60UDexuy4H4A79TP7t7Wdy3hG5C+wBWeOEjF1jWJR0+3Pw5j+qwvUmeqWQ7hc+prdNH/Z5yN0CQKy7/O6wTevX0qz0A+CsG/k3tFgwbx7dIijvjwcrK0PMFkE2k5tIT/LP2xLn8NFT53JoW23Zd3PY9FpeELJuUPc6u2jieDC47iEAIsLNly49i3ktIwcZX3T0dEDhV9H0Wk7CUXz7E7VWWoLc0fwDUAMR043RMnJ9lXKxrUYGriY2PDYu+8vG+j9/Ba+IoAknP0/8G586M7/6SMtiP6BbpH7XjeteHZsBGjr6798Lf/53+NXyiu8R2LtHlg3YKVqZ3uAf9nncJ920VgBzOVl53y1yH8JJbeO0vNZZ0FrDBiGz1mK7VpV9TKVgiyCbSU33ppeSf78lZnHNOw4bk/3UelX6mmQQarySMnEmK4aBY9OjAHxU+zyHtI7eb0oW4YNnjfQ4lFLcYd56+bDxaj2jLGmiRalNyKaTtW3jI4I4RHZmn979woTFBfXskIHZNyY+yBcvWZ53he7too1jYr/kK9pHAdD3rhmbAQ504tRC8u+9q2WPwJ+fCkNiziqJ/r2y+vIBtR01S7VmPVi4hTJfWvqlW/Xn+jvpaMovu7Eh4GaDU7rtQpsrK27SFkE2k5Znnn2KxrsuAWRBwwSuMevTBOCdI91t9b1vVIVJvao58Ca+eDch4aW/+VgOnz66dU9RFK44Yz4x0i0/pQRGBxtl/7AaPc84sH5pBYoIN21Z3BhjwSFHn8oBUYtPRDC2rxyXfWbS4Y0CEK+dxXuOzb820ufPlVmXbxrSddgQGqVwoq7B1qdkRmgBGL0y0He/qOf2xNkYihP2rYV7L69Iq1B8v8wwDPmyH0tnnTy3vJHyFkwciGosccjg5kNOurCgdQ/WyXi9wNYHZfX+CsEWQTaTErH/LU579KLk6xgqHz117Po0AcxetJSw8OA1wtBVmX1yJgtin7QsrBOzueGSY/Ne79LjZxET6SKoFHdYXbOccQcZlA/gUYh3y4ftHtHErKZA0fsthMOm1/GksQSArc/+deSFxwh/oheAc49fXNB6V5yxgOe/dFayIGArPYhcAkcI+GYz/PYixP2Ftdno378NgG1iGl9L/CfHRX7KI85lgEDc84mKS3Zw9MmYIL02e1yZt1EG3QfjB8q633XrXqdd6SYhHLQfevLoKwwh1LGMiHDjjXXBd+ZC79gEbReKLYJsJiXdf/1M2usfJ97NZW8bW/fDUbOaWSvmABDe8tyY7muq07/9dQA2i5kc2j66K8yio9FPnEwRVHzh/KbmaehCWhejfaPPuns75Qx+n9JMg7948VUIHpeTx3SZHTdz85+gZ1vqw9CBcenSHtBlIK2vrrXgddvqvNz7hX/DEApORRDam2OCsS+V/aa8+tu8RKlFaN82ALqdLbzjqHa6qeWzgx9mu9GK0rcLnvhOweMeS3yDMtnD2ZR9YhdsMatGG71l/X0ff0zG4a0Vc5jT3lLQurPaWrlVl4Vq0WOIgX1lG1cp2CLIZlIS6U51UP514nxu1c+lrc47pvtsCLjZ5JYxR+HVfxvTfU11IrvlA6+/9hA8ruwZYbn4yjuXpL0uxRJU63PTa3Y87z04etfu8AE5++13TxtT12wmb7/4ozxvHCZr7tx0NFxbJ/99fwF8q5X+h741djtPxAkg06KDDYWLIIBavy+ZLl9zS/YaX1pfRvzLrpeyLpcNy0IX87fzkw8ew1OfP4PjFs7imoRswWK8+KuKsVwgBA1xGfAcbMseYN7Y3E5MmOI+VD6x0d6/GoAdYhoNgcLcyCfMbeK7iUs5J/YdTo/9kIf7Oso2rlKwRZDNpGS3Q8ZqvGgs4puJDyHG6VQ/OFMGofo7XwBDH5d9TkU8PesBcLUV5l4BOOfIDBdCCZYgRVHod8jOVv1do4sg3Yw9ifrzSy0uF+85dhZf01aQENmvg9rnv1dwHE2+GGEZCK4LhYamwqwHOclm5Xnof9NeRtc9mPfmFDNWSwtKt9usJj+//shxGHPP5Fl9MQ4jDv+6ofjxlpPBg/hEFEMoNM/MLoLa6nzsFzIRIN5TvoKJxznkdfe0UXj/r8On17J8UQsbRAfTZh3K2Yfnl1k21tgiyGZSYqUs/zpxAQDvLSAYsxRCzUcSEl78xiAcqLwS8ZOCWIiGmJwJN887uuDV6wLeNDEglMIsSZkMuuoBCPeMPuN2mA9bvWZ8m+wqisK1//VePqd9Mucyna+PTQp9yDwufQSoDxRfk+lD8ZTIibz5sPxj/5vwyFdh27OoPelB0+H1/8p72+5BeT456lP3CZfTwY3vOYrvGbI5r1j9Jzg48R3towdkYHInDXS0NGRdpt6vsl8xW7rsL5MI0jUWKnJbO93zR1k4O99779H87N+P4Y6Pn1RU38axwBZBNpMOIQTNyEDGA0LO0r9/SeEPy2I498gO1hgy9qhvk100cSzQ90txeUDUcdiCwuO8FEVJyxBTnKWJoKgqH0SJgdGDUH0R6bJxNYy/K+CU+c08GziLI6O3MCf6B+ZE72BONJUC3va394/JfkM9Mlaqj9qCXZdDedo4Kvm376//DuFuxC+Xw8ofw20XJD/7WFz2JvP1b5XB0nkQjEmh5m1KtxJ2NPo5/LjlPKYvRUHAC78oevzlonuXjInao0yjLkdcmaIo9Llk1ehIV/597Uaia+82PIq0Fi4+5rSittFS4+GCI8e+XUwhVM5IbGzKwOt3fpP7b3g/rUovAAep45HP5tffphws7ahntdlRvn/z8+O236nEgc2vAbCJDuaPUiAxF9rQ4OgSYoIA4h454xaDB0ddtjYuH7b+lvzaDZSbl77ydv77vKX856lz2XrjBdx9+Sl8V0uJn/hgb9n3Ge6T4jDkLK1I6f2fPo07Emek3vjuXJRENG2Z14wFPGO6anxGCExX3IhoUeqMXgBq24YHGv/3svncqkuRpb/2+7QCrBNB2Ow91+sZ2ZoYNvvaxXvLUzDxr/c/AMAOo4VPn7WoLNusBGwRZDN5iIc5at33eYf2sAwABW7+zzNZOC3/7KFScTgU3LOOA8C7f9W47XcqYWWGdQcWFG1SjytDLEElxAQB6D4pghyRUapGR/vxC9m0tX7anJL2WQqXL1/A1y9ajKIoHDOrgZ/p7yQspJvq4LZ1Zd9frF+KoIirrqTtLJ5ex29qLx9xmXfHr+Oadx3DPlEv99m1bfQND6ndNK11eKxWR6Of1qPO5k1jFs5EBF69vdChlxW9eysA0cDILn7DJy1BidDo4jwfmg/KIocviUNzWqCqEVsE2Uwa9DfuTXttCIUlC8a+P1MmykwpghpDGyuqKNhkwdElgzNFy6FFbyPdElSaCBL+ZgDU2MhWB2Fm6QwIH9Oam0raZzlZe925rBHSAhLaU/4GpYkBKQ7j7vqSt/WLFSdznfahrJ9pwgko/MdJs+lUZAB2z+7Ru5YPHpQ1d/aIpqwtKAD+87S5/MZM7068dGvebraxwNMnRZDROLIr2BGQ56USzr+ly0jM88gyB68b41TpfJywRZDNpGHD6+kxOAP4wDH+p3h7xwJ2iWacGLB7DBs+TlFqwjLGwTttYQlbSVmQFEdpMUGOgBQ0nnjviMuFuqRb4oCoo7W2+ADhchP0uNhsSAtI9/byd5o3zIdwwpM9iLcQFrTWcJt+Ls/ph6e9f1X8cs6Lf5vHrl4GQJ8qXUGD+7eOus3+zm0AHHA0E/BkF8RHzaxnz/TziAoVV+9WMIt1TgT1EXn++9oOGXE5Z1CKIHe8PO67oCYtSueetKQs26sUbBFkM2lw921Je12nhCdkHMfMaWCL+VDp3GFXji4rukZzQgYX13cUH5cghtboKTEmSK2VD1z/KP3D+g5It0uvoyFnt/uJIlons31m9uZfWydfHBFpIROm27BU/vBfJ/MB7avclHg3AN/RLuVe4zQ2ixnMa5ZVuMN+meqe6B49KDhiWoL63SOnbH/0zCN4ygzO1t+YoDpgsQHqDXk8mzoOH3FRV40UQR6t9GrXhiHwRWWAu1I7vuUdxhpbBNlMGoKhbRM9BABagh52C3kD2rl1wwSPZnKR6NqKE4Ow8DB9Zglm+TQRVJo7zGNWQQ4aIz9swj3SEjSolkcMlJPEvLMAmBlagzZY3sBfV0xuz7KYlcopC5r5wfuO5qbEezgn9h1+ob+DmQ0+Lj2+A4cZI2aYJQgcA6OLoIRZRyc2Su2mMxa18ox6CgCR1+8p5SsUTWy/TNHvEjV0TB95vL5aeQ8KJEoXQWs2baEdadFT6sa3vMNYY4sgm8mBnqAxXp4siFJRFCWZ/eMNj15AzyZ/unbK9PgdTKOtzlfCllK3PqVEl2mgXloQasXAiI1zE30yJijmbS5pf2PBIYuPo0vIBIKtm8obF+SOy4ewK1i+OKiLj5nJF88/nA2iA4GDZ754Jt9+TyqF3tmQ//XnGpAWOqN25EBjh0MheOQ70ISTYN9GODj+Vt7uHfK32Uk7zcGRKzb76k1xLgZKLtwa6HwZpyLYaMzA11gZlZ7LhS2CbCYHO59HJUFUqHxbuxSA3yTOm7DheMx6I6JSSu1PEvp3SxF0UJ2RnPUXxRBLUKk122rMTvJODERkhOBoMzBaq0ARtHxRS9J6Ge8q7znr13sBcNeWqVq0ycdOm8stHz6OVV87e/g+W+YAUB/rHPZZJt6IFEpqHrWbzjpmISsNWaV8Ilxiob0yKaDL2zFq25Vas0WJAwGR3pL2u3mLFHzbRBtHzqwvaVuVhi2CbCYFfS/9GYCHjOP5hf5vHB39Jd9IZM8iGQ86FXkDCkRHvwnb5E/igHQHDARKrbMzRASVuKX6Gj99QmYVDY5QNVqNyFRxI1Bc/6yxRFEUomYcjRjaYLUMBPQQAN6a8mbEuZwO3n74NOr9wy0i9dNljFOd6AMtMuJ26jQZ6xLIo3bTko4GnnTJ7ukT4RIzDspst0jN6GNtqA0kz8tEqLRu8r2bZazYRlHi5KMCsUWQzaRg35vPAvCgfgIfOXk2fQQZ+qAbbxYfJmeLM5SDE5pOO9lQ+7YBo6cHj8bQX6TUPqZe1UkPshDgYHdu0euJmTEVNZXRMymTXap8sPZtfK58GxWCADJBwVdbenZYvrS1TiMkZMNkrXsEy1a0j4BVu6l9zqjbdToU4vPPBSDYtTa/YoxlJNBrlodoGj0zst6n0m26OEcS5/mwOCDT46cvOGqUJasPWwTZTApadHmRbxdtnLJg4t0NCw9ZiCEUvIpGtG//RA9n0lAblg80T2v2xpF5U0Z3GJBsohrpzf2wCWjygemuq0wRtNsjrSe+8O6ybVNoEVRkq4Vg7fgFhDfXeNiDvA/07N2SczmtRwZO94oA7S353TeOP+JQNhnSasaOcawKr0Vpi0pLkDrr2FEXdzkd9DukOA/3lnYP8odlvGVDe3E9wyoZWwTZVD+xEA2KNLlfv+J8zjl8Gv93ydE8fNX4tcvIpDYY4AD1APTvy30TtimARJymhBQZdTOLL5QIIIbc+spxE7SaqMZy9Q8TglpdZkn5GqaXYY/l58Qlsr/eDOUg/dEsXdqLIDIgv7MhFGrr6suyzXxQFIVulxSbA525awX1mZ/tpZnmYH61m5YtbOFlIc+//g1PlTjSAuhcgwudg6KWaTm6x2cy6KwHINpXvDust6ebOYq87sK1tgiysak4Ige3AdAv/CzomIGiKLzn2Jksahu/dhmZKIrCfocMBA3v3zZh45hMaN3bkunxMzuG93gqjPJaguKqnHEnwjnSkSM9KYtIU2XWWVHqZWBwm9LD1t3liWUb6JPWrxA+fO7xbbUQ8srjHOvannOZgX3ysx5XS96xLvV+NwcapSUmtvnpEkeZP5HtMi5ntTGfeS353duiqrRQxgeKb50R3b8ZhyLoFkGWHbu46O1UKrYIsql6uszS+HuVlorqadOjyplofKSYBJu86d0lay7tpJVptaWkx1N2d5jhlg8lPUeNHatlRq8I0Fg7ceJ8JGbOnJXsIfbPu28pyzbDA1IEDSr+UbOZyo0WNC1ufblrBVnXZshTmDCtP0xWpm7oe3PcWuOEtsiK+Fs9i/K+z2luGYdlDBbfOiO0V153u0QrfndpNbUqEVsE2VQ9oX3SpN2rVlasxaBXpk7bafLlIWS2QOhyTSs5Q0UZEhpdjkez4ZEzbhHNbgmK9krLygFRT9Mo9V0mivZ6P+uEDI729Y3ecysfoqY7LOwIlmV7heAwLVueUO4YJ9EnCyVqwcJE0AlLlrBLNONCJ7b1hdFXKANq5yoAws35ByfrXjMYfbTmviOwY410+a01Ss3IrEyqSgQ99dRTXHTRRUyfPh1FUbj33nvTPl+xYgWKoqT9O+mkkyZmsJVG3274zfnw/C8meiRlxzJ3h32VFWsRqpH+c++BNRM8ksmBVb+m0Fn7aJTDQKF4pQhSYv1ZPx80+4Z1KfUVPZt+QD8RgHlKeQqPxgZ7AYg6A2XZXiF4muRDu2aEWkHukPyeSt3IhRIzWTgtyFtOmaG1580yZtPlItJLfXgbAIF5J+S/nl+WJXCNVL9qFGoHzbYitcW3qalkqkoEDQ4OcvTRR/OTn/wk5zLnnXcee/fuTf574IEHxnGElYu47QLYsRIe+uJED6XsdO+Rgcd6bWWVc1emSf+5dyB3TIJNAZhujViwDGK3zK4Zl1+KIGd8IOvnkV5ZkC/kHL808WJ4w5gDwOGO8pyzmimC4s7xdwHWtsm4sUb9QM6KyYGYdFN6mmcVtG1FUYg2HwFAdOdrJYwyT8wstB1GC4fNzz8eTjE7yaujNPcdiWm6PHcPX7yk6G1UMpU7JcnC+eefz/nnnz/iMh6Ph7a2tnEaUZWw4WGUMhdAqyT80U5wQMxfWZaglV0B3gtMU3plwTa1xDiWKY5nULo1lPrCHljjgSsgxY2qZbcEaf3SHRFz14/XkIriKx84C+7+JjOVg6zf28+i9tqStmeEewFIqOPvDmuZPoeEcOBSdIz+vTjqM6w9hkFDQqaO17TOKXj7NXOOhf1Q21veNiPZiDz/G3zAE2IJ7ymgYrPb7B/m03qL27EQNGvSkqY0zSluGxVOVYmgfHjiiSdobW2lvr6eZcuWcf3119PamrtCaywWIxaLJV/398ubmKZpaFp50kSt7Q39f9wQBuLhrzM0CiE0MIDH6x3fcRRBvsfMauw3d+6C8T++I/DOkw5nYJuPGiVCaO9GPO2Hjen+JuwcGydqonJG6mroKPk7ZtqBSt2e6pNiwaOHsm4rEZLZOZq7vqJ/nwXz5qMJJ6qi8+3b/sIvP/fhtM8LPceMiIyRSqjBcf/eTUEPe2migwN079pAXSA9ZlAM7MNNAkMo1LXMLHh8sw47Hl6E9sRu+nu68AWHC8ZyXJPxru0Etj6MIRRea7uEDzhE3ttTzX5tAb23uDEMHsRHFEMouOoLP0bFUMoxK2adSSWCzj//fC655BJmz57N1q1bueaaazjzzDN55ZVX8Hiy14C48cYbue6664a9/8gjj+D3+8s+xkcffbTs2xyJ9t6XOKHrTULCS1CJAvDQ3+9GDdSP6zhKYaRjJgyDCxTp735zy2427q8c96cQsFs0c6iyk2cfu49oU+56JeVkvM+x8UARCS7UpZDYuLuPWIlu7n5xPB9iC28ZMni21GM2eGAnxwPexEBWF/zM/dK91B1TKt5Fv0DMZLGynQWhl3nggewFBPM9Xr6DMvC4O6xPyPdup4UODvDKUw8R3ZzuqvT2b+FcYD/1vP7iSt5yFrZtISAgGmhVerj/r7fibz0k57KlnF+xPWt4H7JlBU5fQcdxT88AbwOCYpD77r8PoRT2yA+GNnMWsI8GXn/tVfavL2j1kijmmIXD4YLXmVQi6P3vf3/y7yOOOILjjjuO2bNnc//993PxxRdnXedLX/oSV199dfJ1f38/HR0dnHPOOdTWlmYKHoqmaTz66KOcffbZqOr4pXHHbvsVALfp5/J+5xO0KH0cd+QhzDj0+HEbQ7Hkc8xCXXtwr9bRhcI573w/3hxid6J4dfX/gdjJolktzFh2wZjua6LOsXGhdwfOVYKYcHHWeRdyyLTSrs0vDE7nX2s7eMVYyDeg5GO2deNauBNqlDAXXDD8d9656WaIQUP73KyfVxKPv/xjFrOdFqVv2FgLPcdWb70DYlA3bRYnTsD3furN30N0HbMaXCzI2P/u5/4Cm2G/0sy7LipubG+89RNaoy8yr0bjmCzfrxzX5Jv3rYd9sF1M44vvP5OmPIs6AmzZ14/xKwWHIjh/2UkQLKxv3csP3ArALtHMB/7tXHzuApViEZRyzCxPTiFMKhGUSXt7O7Nnz2bjxo05l/F4PFmtRKqqjsmDZKy2m5XQARy7ZU+tA/PfS9+OVbSIPhKDXVX1kBzpmK156y3eBuyngfbg+McdjEbU2wIR6D+whznjdMzH9RwbJ8K9u1CBPaKJWS11qGppty6X6uafxjHmq0TJx6ymQRbG9BOThYec6eNzm4Gp7tqWiv9tXjIWcZ7zJdqV3PeJfI+XmpCV3BVf/YR872hwJkRB6ds5bP+xbhlo3++eVvTYBhoOh70v4j74xojbKOX8cvRJK6KjaR5tDYXd41obaugjQAMhiPWhNhSWPPLmW29wMrBTtHJ8YHxDKIo5ZsUc46rKDiuUrq4udu7cSXt7ZVZoHWuiq+/CicEqYx4Xv/1tDJgl1LW+0prpVRLC7P2zV4xfX6JC0P1y5mUVy7Mpjn6z/9M+RytBT+lzN5ezvNlh/prU+Rc3M6KG4kvI2BgrULWSGfDIc7ZNKb05qNsUQQ5v+azqhSDqZBC9JzS8YGLCvHeEfSU8H9pkzZ6G/reK38YoOEIyFi4RLDz7tdan0mM2UQ0V0UT1mFrpQrRakExGqkoEhUIhVq1axapVqwDYunUrq1atYseOHYRCIT73uc/x3HPPsW3bNp544gkuuugimpubefe73z2xA58gBl7+EwArfcs5amYdEVVmsGgDxT+QE7pRlrGVC19UZi6ICkuPt9DNYExX2G6iWgrhg7JGUL+7MHN+LpzlKBM9hIDPy6BZbTnSP7wwXUCXZnp/XUtZ9zsWfOAsWVutvRwiSJfVlB2+upK3VdT+W2Q6eU1keN0jx4B8z6gpPqu0ZrYUQdPiO2SQ0BjgipqNd2sLP/edDiXVRLWn8HtQ3Czt0NQ2OQslQpWJoJdffpmlS5eydOlSAK6++mqWLl3K1772NZxOJ2vWrOGd73wnCxcu5CMf+QgLFy7kueeeo6amMsvUjyn9e2npeU12Mj/6vSiKQtwrMwXEQHEP5Fd+9lFe/8ZJbOvMow+NELDrFege2+aheq8MvIz5K9TaVyNFkDdafANDG0j0yvT4mK88M1KXo7y3PpfTQQiZSBEJZbTO0KJ4kRmoNY2VP6O2RME0eujsLTzQdCgeXa5vZc+NN7VtstFog34A9ETaZ16zM7qzofiSCzPmHEZCOPARI9q9q/iBjoA3LkWQt6G4cyfslMc+2l94/zA1Ip8Va/oqP5u4WKoqJmj58uWIEdT2ww8/PI6jqWy0DY+iAq+LeZy05EgAhK8JekCEi5jhhbs5dv9doMAdj97NnA9dNuLixut34rjnMgQKLPsiyhlfKuJbjI7bvEidtZUpgqxxBbXiGxjagBIyLX415akBVm5LEEBICTCNnmSrCAsR7kIBEsJBQ31T2fdbbuqndaALBVXRpSWgvvjO4V4RAUD1T4wImjZjNjGh4lE0RN9OlMZUocHauLx3+FuKF0HNdQG2K9OYw172b3uDWU0dJY85kxq9FwB/fXEiSFNrQYd4jr52I9GiyH2fsnTyNU61qCpLkE3+dK+WaZSvqMdyWLu0hDn80h3miOXodD0C8ZduS/5d74zlXtCk85W/A7JHk/Lkt2Hv6oL3mQ++uLywdX9luhk8jbJAW0PiwJiZy6cCbtOd6Korj9vTNQYiKOKQrSES4fSHTcScgfcSpLGAzJ6JYv60enYLGbu0Y+2zJW3LK2RZDs8EiaDpDf7kd+nbO6QfWiJGgyEng/Vt84revqIoHHDLa7xv1xgUTTQMaoSMywkWaUVMuOWxT2SJVRsRIWhFrnPIvAVF7bsasEXQZMQwqNnzDACJeWckuze7g1IEueIFiiA9gfb8L5MvgyI06iruA2vlUITcd/dr9xW2zzwJJMwHTqAyA05nzJqPIRTcaET77LigYgnGpTvR31RYj6dclDswGiBu9seKh9Pr0Qx0y9+9jyD+cUgxLgevCykMunaU8GAXAp9pCfIGJkYEeVxO9juleBgqguIHt+BAMCB8tLaVdk6Fg9K6lNifOwu5WIxwDy5kHGZtY5FWUDMoXUR6C1ot0t+NW5EuxMZplRlzWQ5sETQZObgBvz5AWHhYtHR58m1PUGaweBMF1lLY8gSByN7kS0d0FLOqnqA+IjMvbtPPBWD/5lWF7TNPAqapOFCkqXismd1aTxcyKLRrz9jGR01aDIN6c9Ze11qelhn/eepcmoMePnRS+VpwaE4ZE5SIpl9fg71SBIUctckJSaXT0C5FUE2i+O7jQgvjVKT1M1s15fGi3ycf4NH9qevv4A6ZzbWLaTTXlGadE03SXaj2lv/6DvVIN3C/8FNfU1wJEMVXL/8v0APQs39Xct/BQOWVHykXtgiahHRvlF2N14q5nLAglVHgMdNz/frolpyh9D7/u7TXo7rTerbiIkFYeHgTeTON9o9BYLAQ1BnygdPUVpkzFUVROOiQx32sAicnO0ZoP04MdKHQXOKs3aI56OHFL5/F1y48tCzbA0i4pCXIiKZbgmKmOyzimpgMqWLwNshYNn+8eBEUGUyJQX9g4pJT4kEzTqc31RQ2tFdabbrc00sWpv522V29PrqjpO1kI9QtRVA3dbhdxT2unaYIcsYKm/x275fJCH2O+qoR78Vgi6BJSO8GKYJ2Bxbjd6di332mCArk4c5Koifwbn0EgEf0YwFwjSKC9H1ylrVZtHPs4oUA1OiFV/IcjUh/N6oiu0PXNVVmYDTAoJmdoYVKTzmeivTtl1bFg9QVXCxuJBxljgvSVSmCRDT9+rL6hsUrvHnqUJSgWfxRK/6cDYfkfWJQePB7Jq5ApNJg1QpKTUK0g9JqMxgo3RLYMudwAKYlOhGJeMnbG0qkV4qgAWfxAtpqkZSruW8uBnuk9T+sVmYNtnJhi6BJiHvfawCIGcemvR80M1NqCGMk8ms0F9v1Gl4jTK8I0Nv+Nrl9bWQRNLh7HQBbmMER8+cAUCvKL4L6u2SK64DwEQwEyr79chF3yVmwVkR2hg307Zcz7G5HE6qzcm9Zhts8B+MZIsjspK576sd3QCXgCprdxxOFJ1FYxAalRSyMb0ItCb5WaY2ui+5Ovufu2waA3jCn5O3P6JhPTKiois7BPeXtDxjvkxb0QVd90dvw1sj7vqdAD4AzLPcdMuvLTVYq945iUxx6gmlROctpWXRS2ke1DakMqsEsBd2y0fn64wCschzOnFnSFTFaTFHctATt88zGVy/dcbWiv+zZUYOmv7xXqatoc61mZmcYYVsEFYPlRux3VXh6uSqtVEqGCFKippCYoKrJxeCulfeKGqP4yUtsUH7viDKxNWbqOqSlpsHohoi8BoNhaV30tpSe9eRWXex3yOO1f+emkrc3FD0khUjMXbwQ8dZKS47PKEwEOcLSgmlbgmyqivjBTagkGBQe5i9Ij3fwejyEhA+AUG9+dWsiO1YB0N94FK6AGVitD4ywBknfezgwO1nbwoOGiBd2EY46tl5Z+dpqB1Kp6G7TlB3tndBxVCt6n2mW91RmGQQLxSNFkEMbTHvfabohhKd6RJDXrE5cW4II0iLyPhFz+MoypmKZ1d7GLjNNPrZ3HWhRWhPSilw787Cy7KPXLe9zgwe2lWV7FmJQ3qc1T/FCxGu2dAmKwVGWTGfLNmnV6qZ6YtmKwRZBk4zOTbIezzZlBu31/mGfDyjSZD/Ym58lyNe7HoCaWUehmtllgVFmFJ6QNDsr9TMJ1tQSEzIeIF5ExdKR0Ppl1k1YrS/rdsuN8MqbiCNavGthSjMgRVC8TNWixwqHV7o9XYn0h42qmU1EvdXzMKlrkunYfiXGrn1ZrttID8ZLt4IWzbkNSwTFJ1gENQfdbFVkcHTX5teI73sTJwa9IsDMWcUXghxKxOw/pneXNzjaGZX3ad1XvBXUb1mCiCESo9d4s5ihyvP2oKge8V4MtgiaZPTvfAOALt/crC6isEPeqKMDo4sgoWu0a/Kinr7wWDymb9kq3pUVPYE/Jk24nuY5BDwq3RTfwG8k9AF5c465K9xN4pOmbGeh9ZlsAHBF5PlkBCtbBDnN1hBqhghyJ+T14vBVT2xFQ0MjcSFrGq18dXih07du+RiO+69i9x/+O+c2EmaAeNw5fDI2niiKQndAur2iu9dwwCzXsUmZxbS68rjq9FopspwD5c0AVc2+YUoJddBqalNWpMhA/i75RtELwNLDFxW972rAFkGTjQMyHiden93XHXHJG3U8NLoI6tmzCbeZ6j5r3qH46+SF6CWeewY4sBcnOnHhpK5lJg6HQr8i9xkqooHfSDjMwL2Et7J91k5/PQDuArMzbCTumHwQuGoq2x2m+qTYdxvp/ba8pghy+qvHEoSisEnIGMBnn35s2MdH9j8FwIxtd8NAZ9ZN6GapgMQEiyCAaJN0e/kPrCK6/RUA9vsWlC2W0NUoRZAvPLxRayn4zOw8Z03xjYP9XjcDZhhEuD//bL9a3WzcWl+5mbflwBZBk4yaARkU7ZiW3dcdV60S6qNfDJ07ZC2NfY5WfB6VmrpGdLMCdCyXiOqTM6FO0ciMBtP1ZqZ3RvvKWyvIac6SDH9lW4JUs1J3wUUqbQDwa70AeOoq2xLkNkWOJ0ME+QxpGVKD9eM9pJJYa8wBYJ5jb/oHwkh7OfDa3VnXFzFpCUq4Jl4EOeacBkDr4AYad/8TgL6W48q2fb/Zrb4uXl5rdyDRC4C3rngRpChKMgwinGdCDELQYFqC/A22CLKpIuo1OSsLtme3BCWSmUq9o24rvH8bAP1m0F+N100/5sXUN7II2i1amF4vZx9RM2YnPlBeEaTGewFwVGjLDAt3UIo0b4EpqjYSq4FkoMgu2uOF2y8tQV4jkvZ+wAxI9QQq22KZyVYhH35LlfSMp/6Ma3/L+hx9AePye+uuiS9fcfihh7LVmIYDg4bYbgyhUHfYsrJt36qw3WIcwNCNUZbOEyGS2Xm+EivihxUZtJ/Z3DcXRrRfWvyBQAXXYCsHtgiaRAgtQp0Zr9MyfW7WZQxTBIk8qocaPTIeKOyfDmC6tuTFFO7LHuQcMQMD99LIDFMEaR5pCdFDIwRGa5GCU+g9Zr0iV6CyYy18tVIE5dNzzSYDLYIfKSpqK/xm7AtKS5CPIa5iLYobWZPLU1M/AaMqnhNPPQOAGUr6ddu/L70Wjrd/W9b1FTNLzlAn3hJ0WFstDzvelny90jicpYeXr1p4y4w5APiUOF3dZXL7xwdxIYvBBuuLtwQBRJzyvp1vrbJBM34zLDzU1daXtO9KxxZBVYK+53Wir/4JjNyzjO5OKUAiws30tuzN9oTH7CifR7q6Y0Bmeek1qVYFg8kZRXZLULhbXjyDrgZ8ZrNIw2fOgMPZ1zn4/B3o18+g86YzoIDsBZ+Zqu+prWx3WMAMTPQSL+j72YA2IB8oceGksbGyLX6egOkOQwPdLEZqZgQaQiEQrGyxnsnRi48AoEXpQzdSE5RDBmRF+gNCft/aSPZgYEdSBE28JcjhUNh16Aqe1o9gs9HOHXWX0V5Xvqw11eNPWsl7OneWZZu6WVcsLpzU15XWdiTmKlAEmSVU+gjiVauj6W+x2CKoCnj+77fg/OXpeO/7BGufuz/ncla10oOOJjyqK+syiimCnHmIIL8Z5OdsSImgiNOsfpyjBUTE7JSeFD4AZsyOK5plnUQc9yNfwolOW+9rbPnXb0cdl4WVqu+vreyHY7CuCcOMpdLtgokF0d9l9U6qpSFQWqPLscYXSAU+axFpaU2Yv/cAPoI+94SMq1j8jdLyVquECQ2m7hcB09IVFfL7BBK9iCxWXGfCjI1yV0bzzRVnHs3ljq9xvv5D3nn+eWXffq9T3vNCXeXJEAuZbsd+AiWf+1bVeiPPTvJWMd1BR2X8dmOJLYIqHBEb4LBXrk2+3r91Xc5lBw5IS1C/mlsUOM2qta7E6CKoXpNWHV/LnOR7MTO7LNeMwjBdXu4hmTxOMyZGjfUOWz68ZSW1Rur92Nr7Rh2X3JGRLP4VqK/srKE6v4cB5KxzMIcb0SY7A6YI6lfqyt7rq9z4fb5kWnnEbBkRDfUC0C8CBDzVNaP2BBuJCzmZivSkMsBqXdLK9XLruwFZhC8aG96Gx2VaghT3xLvDABa01rDyS2fyzBfP4NzF2S3lpTCoWo2Sy5MhZomgASVQcrsYKxaUPGuVRa2mv86Ja3w7XtgiqMLpfOGv1JGqy6OGs6ejAiR6pfsq4s0dROf0Z69lko16Q1puals6ku9Z2WUih0XDHZfraN6Ui0o1BZHPzHQYyr7XHgRgsyFnnTP7Xs0rNig+2ItDkcvVNVS2JcjtctCPnFEN5goot8mK1UAy5Kp8V5Lb5SCCrDsTDZsiaEBeDyHFj8dVXSIIRaFbMTM7e1IPdmvyMfvwEwFwKIJYFsuwU5cWI8U98e4wixqvSmvt2LTxiHrlfU7vz32PLoSIJUTKYI0xzKr1Sp4iyMoejrlsEWQzwQyuezjttScyQgpmv0xlTfhziyDVLOjmMUYWQXo0hB8Zv1LbND31vkdeTCLHxeQxM7a0IbV7/HXy5hDQh6+j7JY1O55vuYS4cFLDIIP7R29COGDWHBoUHmoruHmqRdSsmhsJ2QUTCyHeLzMKo1XSgT2qSBdRLGwWCgzJycKgUvnnaDYGHPJ67zmYerAHkG4ub11rsg1PPEvSg8uQIsjpqc7vXih6QN53lVB50uStTK6os/SKzVYYRGZfu1wkBnsB0NTJXS0abBFU8dR0rQHgEcfpAARiudPM3ZaVqHZ6zmU8gXoAvBm1TDIZ6JbbigmVuvrULFyYIsgRy/4w92vywjWGiiAztblWDAyz8jQMyvTbugUnstUxC4A9b70w4tgABszAvQElWPFuEoCYQ7oErKaSNvlhmA0kNW9lW/ssYmaz0HhEPmwst7GVnVNtxM3GnZEhbtwaIe8daqCBHiG/17adu4etmxJBleEOG2uUGuliUyPlyQ6z4i41tXRrjGKGQTi1/ESQMBvNJjz1Je+70rFFUCWjRWnWpBl6cMapAPi13EUOrXYV7saZOZfxmmm8fjGKCLICUpVa1KFmfF89AM5sIigRSxWKG1LAsLZRpneqJDCiQ1LzBw9Sp8uLrXnuUXT75si3924YcWyQ8lkPOqrDXKs55Ww4PklFUDxh8J2H3uK5zeV19ymD8pwWFV4Q0yKeIYL0iPy9Y1UqgtxKAoBpu6TbGl3Dp0gLsTdYT4/p5k1ksQSphlxO9Uxs77DxwmMWFfTHyhP3Z1kRjTI03nX5s/e1y4XDjN8U3vqS913p2CKoggl3rseJQZ/w0zzvaAD8I3Rwr0vIB4a/qSPnMl6zam1ARLJmdFhYsRj9jvRS/1bpf6sfUhpDBE6gLvXQaqirJyxkdsPQ/mHxvbLP2XajlXnTW4nVSEuQ6B7dHWbFWlRL4J5VNTcRHaHvWhVz1xMvMv/Zz3PjLX8o63atjMJKL4hpEXdIEWT1zbKKksarNLaiNionYfO7nwbS3eCemgacftPiGxk+OXMLKYJc3uoUgIXiNyeftYnyTAQsK6JahiKbVhiEO08R5DInuQ5z0juZsUVQBdO17XUAtiodNDRJl1LQyF7kUBg6TWYgc920WTm3GaiR5m2PohGN5u4AHetL1fsZisu8ID3ZWkCYBRhDwktbfWr253Y56DWbqPZ3p0TQwZ2yQ/0uRzstNR6URll11TsweifmhNm2I6ZWRz+mhCofBCJWnAgSQnD5H17hijteLeewykbNpvt4r/MpPuv6a1m3a/VOctVWdrVoC82M/UrEzIeNeU1oanUKgV/Gz029EIKYme02KDwEvN7k9adkSb22RJDbOzXcYXWtUgQ1ip60ukrFYk00y2EJcpvlGzL72uVCNfscOv2Vn5BQKrYIqmAG928HoNczHZ8VXEwEEvFhy/Yc2INb0TGEQtMIIshfkxINof7cNWt0s8VFRE2fhbjN6sy+bC0gzKC7ED5mNaYHQ4Yc8kKO9Jr+8tB+Gl/4rvzTOx1FUfC3yVYfDbHR62xY9XaSqZ8Vjm4VjIsVVzX6YCjOA2s6uf/1vfSGh//+E43VF+04xwbQE2XbrtU7yVNC76TxRHdKS5BuiiBhXhPCXZ2WoPb5Ryb/3vn6kzzzhuxN2E8An+okbgasO7LUAPOYbRfcU8QSVN8qLfA1SoSu3vwblebCY4qghKf0iZ7XFEG+URJiUvuW17MarK5WL8Vgi6AKRuuTLqmEv5VgfXOy4J7IYnru2ScFU7dSh9uTu7CW4lQJIz8Pm7O6rAxaAanpF4HVAsIqVDiUeFiaUAeFl+ZgemG4sMtMtTWzffb/5By8Ufm3USdFW9PMQ+T/xsERK2MDYAbu6VUSuGeYloB8szMy0Q3Bscp6ZnCAAwOVV3XaY4riGiUC+9aUbbsBQz4IfHXV4Q7TXdISZJgiSDH7Z1FBaeKFcMbbL0r+/fprz/PgUysBGBA+HA4lGTjrzKwBZuiycjbg9U0NS5DTV0vYLJHQ21l6wUSr16BRhomeFQZhtaAZDb+5b7ctgmwmEsegdB0ZgRZqfR76zLLskSwF9wYPyFLtPc7RHxZh5E0pOtCbe98RuQ/Dlx6QaokgH9FUawCTUJ8UJiH81HrVtM+sFGdt4CAIQWs0FffjaJAzqNZ2KYZUdAb7Rs6wUKJy7Eq1+KxNS4BTy28mlsnap+/lLs91POv9DJ/642vlHFlZCAy5ue5Z/c/ybNTQqTHTsYN1lV0Q08JwShEk4nLcjmTBwOoUQZq7htsTZwPQENvNO+rlZGunkJY5w7RSqPF097jQUueD2z81LEEAvQ5pKQ+XoWBi0nVVhorbfishhhgiD0ut1efQW+HV+MuBLYIqGNUUIo6aNryqg14zEyOSRSDEumWKasg9+sPCqlkzUrq2lf2VGZAarEvNDERGHMCgKapiTv+wtHXNI9cTg13EBjJEXP1suW2/jy4hZz1de7eP+B3UuByf4q+SmYpH/nb5pqhm0vzid5N/n3zgzhGD2icCr54Sd+GNT5Zlm7EhVcnrGqpDBAmzWaglAqxsHIe3Oty2mRzSWsNuIe8B/ug+prmlFTIx/TgAFPO8diTSY02i4dT54JtCIijkrAcg1l96mrzHMIVkGeosBYY0QQ2HRmmerScImpMPf111ZGWWgi2CKphAXIoFtb4dRVEYUOSNNNo/PPtA75MiKDZCoUSLqENeVJqZuZINVZNuCDWjQ3tdwEu/WSAtkjGOiOle01zDL1ph9hJTIl2EM3rrOBtSMUxW/53+AyObk91m4F7m+CoVh9dMUdXzC0zMxBKHAF9Xf8eGfZXVkV4dki04rffV0d2ZeTDQLd2lg8JDTaA60qyFKsdpdVB3meKgWjOknA6FU46W3dY9se6kqHMFpTByeKzU6/TzOhaVy8WEis+dbhWezMTMysx6qPQMMbdZZ8lRhrYjPq8/2dJlxDAIIDaYCreoqRI3dCnYIqiCqdXlyehvlMUPw2Y6eDzLBeYalPFDRjB3oUSLuFWzJpx7RmAF5Xlr0kWGT3UyYLrlQkNFUP8e4ubMXc+WCWNabFzRHsJdqcJq9+in4m2YkXwdcsuLLtI9vPha2ubMWBE1WB0zFaf5EHTrxbnDWtzpcUBOpXSRUU6GtmGpMQYw9r9Z8jZDfVIEVUtBTADMB5ZiWoJUczbv8lVnYDSAIyhdXz6tB9UU8cJ07znN7+XOEPcxs05SFDfOavntykDcbVm8cxe1zRevkOeOw1O6gFYcDsKKFOjhEcIgAHoOSitWSHipDVbH5KMUbBFUqegJaky/bJ3ZtsIquKdlES9es52Gs350EWRZakQ0twjyJTu0p7ubFEUhpFhuOVMEPfdT+MFhHL7uJvk6iw/bmjm6471Jf/lT+pF8VruCWU0py1HcK2+4Wu/eEb9DSgRVhzvMZbUrKdIS1GqkuxArrQeZFcRpWQkPvlF6XFC4T04CqqmTtWK6wxwJ+QCzfm+3vzrdYQCuWnlNBvWelNgxRZDLtHBmpl7HIqYlSElPkJjs6EmLdxmyw8wSA0qZ2o6EFXlujlaw1bq3hJQgijL5BawtgioUI5I6UesbpbUjYaZZJyLDxUtNXM48vCNUi7bQzcJ9VgZLNoKWCMriE46a1W+jA+aD+OEvA+DAtE54hs963ckmqn3ETYEzqDbxx4+fxKymlLnXCJruvFH67wTMiteZlqpKxeWTZnJPnnU60jB0mkS66Pni7WUKPi4TVhuWpwxZ1DO66emStxkzz69olRTEhFSfLKcuRZA1m/cEqqOeVTa8dfKarDP68FiWTDPQXzUrEXuN9KwjzRRBcXJnqk5KzMrmzmju8iN5kYijIgOYnVnup8UQNUVQLDyyCEqEzaa/VVKNv1RsEVShhM0HQFh4qA2YosUUQXqWqsONpqUg2JK7RpCFYYqgZPpuBroWx2+Wxg9m8QlHzeq3VpO9YetnqYniNwNbg3ofxoAUOK76dk6eny6yXLWy/457hEaxwtAJmtlIPjP1s9LxBKQlwCfyS1EdSrR3Lyo6CeFgh5E6jpWE9b12tcged3X7XxrWJ65QrFpQcVf1WFEcZp8sVyICuobbShMPVO8Dxd9o9sQiQVNCXpdWQLR1XnszzmstJkVxzDG1RJCVSOKJlyiChmSROrzlsQTFzczFbJ6EoeimSAo7qjOjsVBsEVShRMwOwv348bjkz2QVXBMZBfdi4f5kKnFj25xRt22YJnu07FaJ8EDKlBusG25psToLJwZ7wNCHb0AdfvEE6s3ZpOjHacUvBYYXwFPNWafX7Eafjdhg6iLOdNdVKpYlwEekYHHQt1eWE9hPA5Zx+iLnc+UcXmnoiWRhvMbFb5dNd/Vu6Npc0mYNSwRVSUFMAJcpDlxGNFk8FMBXxZag2mCQTiHvA5aos+JUPH4r9Tr9vNbMwOiEMrVEkFpjZtJpvaVtKG4Flrtwq+U5hlb/umyehKFYk+y4Y2rUd7JFUIViBRkPKv6kX9aafWUW3Os208lDwkt9Qx6iwBQpjhx9ZAb7TXOo8OFxD78ArSrNItqbLKo4FEUdHkxXZ7b9cCkGtSH5UHeYXZeH4jMrAwdGsHSETYEYEy4C/uqYrVgVW52InOIzFwNmIHmvs5HpirT4fcT1aHkHWAIinrJMLj1sAavEfAAGS0yVt2pBJcwaU9WAas7a3UY0WR08JlwEA9X7QKn3uekX6eO3in9a9WeciLTaQLpZJ0kze6lNFazK5kGjREutefwieHC7yvOYtsIg9FFEkDXJTjgnf1A02CKoYomH5EUUUVIPeavWiCNDBPXvl722uhxN+QWymRksjhwP41i/FRiXXWAkOwtHexH9wwOYLZfAUGqDNfQIeeOcGZel9911w0VQTYN1E+nPWQvHspIN4quazJNAsDZZ8Vsb5SaUScyssj3oqufX+gUAHBSVYx2xLHNx4aS9qZ4N3qMA6H2zNBGU6mRdPVYUKxXeLaLEzd85jJeg2zWRwyoJn9uZrDJv0SekuPEFU26++JDz2jDdYQnn1LIE+evl/as2R4/HvDHv8YN4cTvL85jOt3+hYYogzVW9wr0QbBFUoVg1fCLOlBCx0mxdiXQRFO6S1aL71fxqOlgWJWcie3xKLGRm5eQQQZgPJWesn4GDO4d97MhiCXI4FPYr6ePztswetlxdk7yJ1BNiMJa9smnUauKYa3wViN+jMmiW1I8OFDZLtGqORNV6/mksBaBHVE6MiVUkcxAfAbcTZfapAAT2rCwpLihZhbhaqoKTsgR5RIzIoHzYDOIl4HFO5LBKxpOR3aaZVgK/W2VQSKETGVKEz7IKJaaYJaiuSU7sgkqEeLTw+D+L7Z1m70ZRPkuQZb1jtCbOpitOt0WQzUSim9WYLT8ugGreiDILk2k9srBg2DvcspINK4NFzZGuHTcDnsM5snIcZmdhV7yfgQPDRZAziyUIoEdNxQDpQqFu2pxhy1juMFXR6enJngYeM8cXrSKftdvlIIpMF45ECqwVFJbHIe5uIGZmeASV4m+w5SZiWoIiihdFUZh59HJiwkV94gB0bSp6u8lO1r7qyAAEUH1mrIyIJSuyR/DiKtNsfqLodqdKb2wwZnDsLPMe4HQk+2VFQylxL8wJlj7FLEE1dU0khPyt+7s7i97OnSvfAqSAVst17rjz61+omB4CI0ts52Skqq7Mp556iosuuojp02XX8XvvvTftcyEE1157LdOnT8fn87F8+XLeeOONiRlsiQgzRT7uSgkRtxmEmFlrRhmQLqlEYPRq0QAOrxW8mf1BqpvxSDFX9vos7kC9HEein2iWooauHCIo6mtP/r2XJma1ZHFzqD4ipul9oDt7hphmZi9EndVTPwYgZgaJxiKjzMQycJg1RwxvI1+/5EQgvVfXRBM1H/ZRsxjb0vkzeFksAmDgjUeK3q7XLNjpqpJaUABuUwT5iBJNisPqEeu56HelsjgXOnYze0hZi4j5u6cVX41bImhqxJVYOJxOBkwLdah3eI/HfLFaZpQzJkgxwylGa91jVTsXtgiqPAYHBzn66KP5yU9+kvXz7373u/zgBz/gJz/5CS+99BJtbW2cffbZDAwU9tCpCMxChgk1JYK8ZhCiV6RbEtSwKRZqRi+UCKB6rOrF2R+kRhYBNhSrs7BXD6H3DY8Jcnmy3/hiDYck/97taMefI05iwCEv1sHe7FVXdWt8zuq6SONJEVSYJUiNSREk/I3MajdjDpQI+7t7yzq+YkmYDz/LMlfnU9kYOBaA0FuPF71dv24VxKweS5DHFEFuRSdmujHjk0AIvLovlQWaGY8WV0xL0JDzWknIlg+Gc2q5wwBCirxvhrM0us4X1ZAlSiLCXbaYoOTkN0dCjIXTtATZIqgCOf/88/nWt77FxRdfPOwzIQQ/+tGP+MpXvsLFF1/MEUccwW9/+1vC4TB33HHHBIy2REyTpT6k+rKViZFZayYQk2XO3Y0zyAcrtsgjotkXsLJy1OzBt94aOSsMGAM4BoebfNUcliCjfWny753+xTnHF3bK76nl6L9jRCyBWF0XadxsXKsVKIKsmiNKoBl/Xcql+Mc/3la2sZWCFpXnqvX9AOKzlwHQsO95yKNrdTYCVifrKmmNAuAZ0ixU65OTE62K3La5qBnSOPlniXemfaaZtYCs8wBAMd1hhmvqiSDLQm0lcBSDw5AlJ2K4y2YJcpixnOpoIsgMtyhXpepKp3pTFjLYunUrnZ2dnHPOOcn3PB4Py5YtY+XKlXziE5/Iul4sFiMWS/Vl6u+XD1hN09A0rWzj0zQNf+xA/ts0I/SFK5Bcx2WelD4RQ4vHwcwEq9PMatH10/PavsMtH1ZeEc26vOWK093BrJ97THdYkEFC4eEiyOHyZF1v+mEn8cSzR3OIYxd7Z78751gjrjrQQA8dAF/NsOUsS5Xmyj6+SkVzeECXdZ0KGbcv0QuAw9eA0+nkNWMBSx2baKQvbTvW3+N9TLRByzLnT+57xqHH0/tmgHpjkMSOFxEzjy9so8LALyKggDsw/BwoF+U+Zg6HC10oOBVBot8UQS5/VZ2n2Tj18Dnwsvy70SPSvk8ieV6HUu+bgdGGM/u9YDITc9VAAqL9B4s/vzQ5QY3jwtATWcuxFYoVq+nWB0ccj2UpEurEnLelXJPFrDNpRFBnp3wYT5uWHhczbdo0tm/fnnO9G2+8keuuu27Y+4888gh+f3lmcC49zJItP+Ntg+t5QnESdY8e4zDTrNVzsC/EAw88AEA8FuESwKEI7vv731BcbjASvEP0gAJrN+9my74HRt221reXQ5AiyNr2UJp65M374EAs6+fhWIwFyNogLXGZnr9HNDJdkWN+ZfUaNm4ZHjBtCPip7/PsGoTPJLJvG6AlIbtOd+3cgHvhPB59NL0mjn+/DATvCes5t1GJtOlyRrdl41ts1/If9zIzG3DTjr2EHniABrUV9E04Bzqzfv/M4zXWuLZvBGBAcyTHM6jBSmMxFzhfZO0Dv2L7zMIaSjoSES5SZGbZiy+vYs2a0huyjkQ5j9lZeAgSJbxP1sMaiFNV52k29N07Odb8+9nobDqGHK92XU7Gtm7ewE7zezabrqADvYNV/90LpSUhH6t7tq3noHmcCj2/ElGrxpRatuMX27eLJYA7MfJvsjgmDQE79hyY0N+umGsyHC68LdGkEUEWmXVyhBAj1s750pe+xNVXX5183d/fT0dHB+eccw61teWpxTIQibP9Bz9kBjGWhB6n8T9uHXWdLRtuhgS0zZzNGRfI2jCxWAzWyc+XnX4KwYZWevdsxrlaEBMq//bu9+FWR/9Juzu3wRbwE+W8c8/DkeFzXrfpFtCgefocTjP3PRRNNwi98SmCShS32d+mc4gIWrb8TNqnZc9Uu/ACgW6IEbNlXt99L+yH5qCbfuDss89GVdXU59v+CDGoa+3g5Czjq1RWr78FwjBjWhPHFDBu8ZqcVR97wskcfcSRrNv7N+iElhqV5UO2o2kajz766LDjNdas/t1TMADumiYuGDKeX2x5EcIvMiOxlcUF/k4DB3bCGplFeNE7/g23OjYp5mNxzPpfkyKoQY1DHDx1LZxTRedpNta+OQfulg2SVyuH8euzz0oer9c3/AoGYXprE8eZ3/PNzb+R95C2GVnvIZOZ1TvvgoPQUuPhhLPPLur8eung07AT4qi8q0zHb/vaRvgbBJRo2nWaycHXvwQ6zFt0BKeeOf6/XSnXpOXJKYRJI4La2uRDt7Ozk/b2VBbS/v37h1mHhuLxePB4hqdxqqpatptio6ry+/n/w9GbPsG07X/H2LcGx8xjRlzHqUtzqNsXTI7D5XKhCSeqoqNrcb507zpcO5/j28A+pYlZ/vwCMINmqwmXYhA3EngyetNYPmO3vzbrMVBV2Ko0EkR2g48KlahaD6bJ1pNjvbyx6hCZlYgzfwuXmb3g8NWN68O+VIRVP0mL5j/uRBxMoVnX0CzX81j1ogZz/D7lO3fzwWH+HoYaTNuvuujt8NpPaOpZLQsfBlvy3mYsLH/7EH7q/GMfV1LOYxY3SyF4NTMmxB2sqvM0G96WuZwd+y5RVD60SKQdL+GS57UYcl47DOmWcKreqv/uhaKYda0csf7kdy/0/PI5ZDPqjpb6sh2/QL287/tEZMRtus1YUU9gYu+vxVyTxYy3qgKjR2Lu3Lm0tbWlmdDi8ThPPvkkp5xyygSOTHLJOy7kH0KO4+DjN426vMsUQeoQgaIoSrLWTGdXD399ZRexg9sA6FXzS48H8PlTWV9WQbf0fUuTolX9Nhu9rlThwz0041NTp5KzxF43iimCXFp2Va+aqdMOX+VUTc4H3cqUKaBtxtDqrjW1MktKeKzjM3Kq63jhsMbhST9fjj36aF435uLAIPHW/QVtM5ysmF59mVVWFmDAjOVS3NUfYOpVnWwUM9kppjE7mFEA0wx+Hto2wwrsVdSpFxjtMEWQM164VSK5DTM7THe4yzEkAAJmlmVQiRLXcicreM30fCuBZrJTVSIoFAqxatUqVq1aBchg6FWrVrFjxw4UReGqq67ihhtu4J577mHt2rWsWLECv9/PBz/4wYkdONAc9PBSjQzabtx2P0RHrhqsGlIEuTIeLFatmbA5U55h9pKK+NvJF4fqJi6kETCWpaOwlTrv9ue+CMLu1Ky+y9mKY4jLsdTCcE6zGKOa4yHv1qXlwemrnnYKAIbLsgTlX+PHEgNRoVIXlDFqimkJ8uiVIoLMQEp3+vlyzKwGnnKeBEDfK3cXtE2rKnikCjOrNPPBVWPIa9Q5CbJsZjf6OW9xGx8+aRaBjMm2ZeHMJoIcrqlVLBHAFbDuXyWIIF0ev0QZRZC/JnW/HMxVtV4IvJheiBHu/5OJqhJBL7/8MkuXLmXpUplqffXVV7N06VK+9rWvAfCFL3yBq666issvv5zjjjuO3bt388gjj1BTUxk/Zkv7XDYZ03EJjfiGx0Zc1qoToWa4qqxZ5mAoxMmON3i781UA9Pp5BY0lbNb2iIWHP0g9hrRUWMUZsxHxp2oShXztODCSr0vt5+VKFmPMXt/JKhapVltnbvNhoeRoV5KNUL90qYTw4zWtbYppAXOPkuo6XlgptY6Mh73ToZBYeCEAdZ3Pjir8h2L1V4tVoQiyOqd7MIWAu/q+QyYOh8IvPnQs11x46LDPhGnhVPRUyQ2n5Q7L0oB5suM2RVCu+1c+aHF5LBNK+dxRLo8fTcjYupzp+4koTvNe7qkyS3uxVJUIWr58OUKIYf9uu+02QLqLrr32Wvbu3Us0GuXJJ5/kiCOOmNhBD2FWEF5wHQdA96qR3QNWDR+3L/3BYlmC1ANr+aP7epY4NgPgbC/se0bNUvfxLJYgr+UTHmEmEG9O1fnpq1+cvHAAXI7STiurIrXPyG7p8JvFIq1U/WpBmL14ChFBYbMvV0TxJQP8A6ZbLLOH3ERhxZA5vMPPlyOXnMBGYwYukcBYk781SDfPy2oriAlmyvgQMicykw1husOG9iJ0mpYg5xR0h3nMOmq+Eiy1W/fJJJNXdxee7ZQTRSFsupfDoRwTknhqYjW05tVkpqpEULWjKBCdKZtLuna/NOKyHqQlKFMEWTdYX196T6ZphxxX0FhiycJ9wy9UqxijdwRLS2DRcvqFn7DwoC48u6yWIG+NDODzi+yWDr+QNwZvsL6k/Yw3ilmfyZmjUnc2EhGrGnMqNsYqXOczKsMS5DYtc84sIujUBc3c6zgTgMHnbsl7m7pZMV1zVZ+AyOycPtlFEKoU9w49VW/NKazA6PK5c6oFn3n/sop9FoMHefxilDcw2Yqxs/raZWLFIIaFB793avx2JYugoYUGbUZn+mEyOLo5tgPMJqnDMAy8pindnRGcrJldmUUsdYGtMeYwe97CgsYRN7eTiKZfqELX8CryAvQEcptDjz38EP7d+xPe6/oxJx57DE5S1bxcJYogv5m9FhSDGJlNyHUNnykQfbXV01MKQDEfFs4hboPRSESsAOGUS8Vnir8AETTdyLbauOI2AynVLIGUXtWJfuSlxISLmu61sGdVXtu0bsaJKhRB+hSzBGFae4ae1y4h718utfoC20vFXyctQTUMEtOKq3LoMTNC42UWQZZ7OR7OLoKsqt9hPPjcY1OWotIoWAQ9/PDDrFixgvnz56OqKn6/n5qaGpYtW8b111/Pnj17xmKck4ZF82ezw5BBxfFdr2ZfKJG6mfgyXFIJU7yosZRP987Z141YCykblphKxNJFUHRItpjVpiMbQY+Luz7/bu790iU0Bz3JjAKQ8QOlEKi1biIR4on0h3xsyMUbqDpLkLwBuQoQQXpU/h5xZ0oEWZayGsIMxoprSVFOvKZlTs0RqH7RyUfyoHECAIOPfzevbSqmCNLV6jPJZ7aKcE1yEeQwhY7LSE2IXWLqxgRZ969aJUJfuDgjgdu0BFkJLOXCEkFaljAISJWmCAsPvjGqzVVp5C2C7r33XhYtWsRHPvIRHA4Hn//857n77rt5+OGH+fWvf82yZct47LHHmDdvHp/85Cc5cKCwCrFThZn1PjY75gCwf8vrWZfRYik3hzfDHaabpnav1gvAU/qRXPX+8wseh2Y+VI0MS1DEaoEgnPi8I8/i3C5Hsq/Nm0HZ3XyPKN064zVTOR2KQNPSBUPYDBSOCDfBPOsiVQoOT+EiSFh9uYbExlhiI6DECEfjZRxhcVju01yWw8XT63hu+goMoRDYfD9sXwlAItTF6z/7MM/ef/vwlczeecJdhSIoo2moOgmyw0bCcvO6jNR5rZoiyOWeejFBDn998u+Bvu6ithF0SQvSGYs7yjGkJJZ7ORHNLoLipgiKKF7UMjVurXTylpk33HAD3//+97nwwgtxZAl8fd/73gfA7t27uemmm7j99tv5n//5n/KNdJKgKAqDwTkQeolI54asy0TCIVRkyXRfhl9WNztS+xNSrNTU1NAULHy2lTC3Y8TT40pig/LiiOClrgCLzuPNH+axTh9P6Et4seDRZKB6iaHiQcOIpwcGRgZ6aEBmS7WUaHEab5ymJUjN1bg2C5ZbKC02xpOyDsqYoQkUCoaRdE96A7kD6T/8zvP4y8+W8X7XE8T+tALPxT8j9JcrOSq+lwP7/gUXfjhteWey9lBlZHYWgsiwBKm+6s8OGwnLzasOsQSppiVD9Uw9EYRTJYwXP1Ei/cV1kq9x6aDB9Ob6sg7Nci8bkeyZa/GofB5YWchTgbxF0Isv5vdomzFjBt/9bn4m76mK1jAfQuDq3pT1cyttPYKb+owOwpapPSDkSZw568wX3cxUIpYhgkx3U1jxUUgCuu7y8lf9jKLGko1BJYBH9CIyCgta9WPCSvU9WCy3iNvI30Ru1V5Je7C63MRx4SZBIjr8ZjYYS/DBm5/k2HktfPPdR5c26NHGl4hgSVGfP3cM2eLpdfz+iP9l6bqNLIzshj+8h3rzsxalH0030maeTrP2kFKFIogMEZQZ1zfZcLqzucMSoIDqri5rbbkIOwL4jWjyflUoVmA5rvIGJ+uqvAeJWPagbS0q77dTSQRNDXtXhaFOWwRA7eC2rJ/HzYytGMNPRKtEfb2ZeVCsCDLM2RtapgiSD9VogZV6y22UCTvkg0PJKCxoBfRVYxE9l+kWcRdgCbIKK4qM39lqzaBFh2/r6eee4W/972P2KzcWOdL8iUVS548vMLLb55qLj+erdTfwD/0kukQNWwzZ6iYhHAxE02Ob3GZ6cbVVBQfAlX7teHyTWwRZdZDcIiWC3FPZEgREzftXLJSjHs8ouIS8HspdbNKw3Mvx7JagREyKoMwyD5OZgkXQxo0bueuuu9i6VXZIvv/++3nb297G8ccfz/XXX48Qmek8NpnUT58v/08cAGN49kDMNEnGlOGzAMsi4DA7bGea3vPFqlmT2cIhYZpJY45CRVB5VVDUaYmg9PFpyfox1SeCrNgQjyggWNISgRlZNlbWSCJLC47ep/4fqqLzX64HQdeKG2yeRMOpbtcB78g3Tr/bxW2fegdrT7mJ/57+Fx455Q5A9rCLZog5d7J1SxVagjJq43j9kzsmyGUKHSsY2khoOM37k3sKxgQBxF3y/qWFe4ta3yHkc0Fxlrl3l1nVXYlntwQl4pYImjq/W0Gh5/fccw/ve9/7cDgcKIrCL3/5Sy677DLOOOMMamtrufbaa3G5XHzxi18cq/FOCmbMnEtCOHApBsbAPhx109M+T8SsaqHDRZCSmXJaZDEyYfYzcmQU7ktErEDcAkVQmU1BcVcQ4uDUM0WaWT+mCkWQ23wYWjWg8sLKFMz4nTXFDQIS8eE1hxIiNbfZ+trjzD3uvMIHmyeRwQHqMV23eZwDfreL/z3frDqsReB5889YBEhZfayq4K4RqpZXKo4h12hcOPFmadA8mXCZ56YVDB2PRbDOVvcoyRWTFU0NQtQs+lmbf19HC4dpCXK6yiuCFLMNk1PLXmPMMMMjMmtdTWYKsgRdf/31fOELXyAajfLzn/+cT37yk3z729/mwQcf5B//+Ac//elPk9WbbXIzsynIfjMiordz27DP46YI0h1ZLoBMEeQq7iZjNXV0ZVwMySJ1BYqMcrvDEi6zU3qGCLJSxhOu6nMxWJYgLxoY+dX3cZiZZI6M310zBbIeGy6CrH5yAF2v/r2oseaLVVckqhQhxodYMS0zvIWVdu8eIc6oUlGGxMFE8ZTcS6/SsSxBVjC0df8C8ExRd5hhWlxEAa1ihqKYlqDRrKuFYhU0deVouWOYk6piwyyqkYKuzvXr1/PRj34URVH4yEc+Qjwe5+1vf3vy83POOYft27eXfZCTDdXpoMshu7D37x9+vKy+MUaWvjGODIuAUmTgoeKxCvelP0RFciZQmAnfWWZ3WMK8iaiZ44ta9WOqz8UwtAy9yDETy8RhWoIyf2fN9Nkb2vCYoJlDRFDrvqcKHmchaEnXbRE3a0UhasY2ZYogqyq4u9r6w5HeKyyaJa5vsmEFPw+1BAEYQsFVZktGtSA8pniPFddE1XKHBXxlFkFmjJ2ao+WOlY1ri6AcDA4OJpuROhwOfD4ffv+QSrY+n11BOk/6VVkwMdq1c9hnCc2yBA13hzkzfOzD3GN5YnW2dmWKDNNXnMwey5NCizWOhpFDBCXrx1RhET3vEBEUi+TXE8hqRZDZhNNylerx4SJohpKq0TVL38GBndlLMZSDRIkptVaAd2JoKQTDIGB2svZVWUFMSGVLAcSzuLQnG1bwsxsNhEhaguK4UErsI1itKF4p3h2x4pqoWhX4XWp5RaTLtKxaTbIzEeazxyjSw1CNFHSGKoqS9rDLfG2TP1Gf9BMnencP+0yPywefkcUdlvkwdBZpCXKYqceqkSEyzNTJZPZYnpTaL2wY5kzKnXGxJgP6PFUoglQXMbMCbDRPEWSlHbs8GSLIFMjZLEGWgNiJzL7a9tw9xQ04DywLTrwYdxgpkTDUrTe0irlvhNYtlYrLk7omi7KQVRmqOTFzKgIjoZnxXRAvYwf0asNhFjR1aoWLIMMQSRHkLHNgtMeMsfNk3vdNkokoU6jxbUGB0UIIFi5cmBQ+oVCIpUuXJosn2plhBeBvhj4wBruGfSQS8sGXzRLkyMgGK1YEqWbtEneGpUUx3TSFVuqt9ZY5gM8rH35ekT4+RxUX0XM5HYRx4yFBPJafO8xpVuF1ZYhfqz+VyCghgKHjUmS80fZpb6dj3+/xbH0cGJtkBd38HlqRKbVWgLc+JMA7PDiQDJEOBKtP7A79rYoVh9WEe0jcTzweSbrztTL3vaomrIB+dyJEoW2OdSFwmQ2pHc7yts3wmO5lXw5LUDIRYwpZggo6wrfeeutYjWPK4axpgb3giAwXQSRGsgRliCBPcVlSLlMEeTJq1jgS8uIo1N30sdPn8tyWg1x4ZHtR48nEmkl5My5WK6DPUY2p06RS2+N5WoJUw2xE6c0UQVIgDxNBeqqNRu0x74EHf8/C8KvEIgN4sjQ4LRVhurG0ArMJLSw3mjFEBEVMERQWHvxldgeMB+qQ30qbAlk2QzPA4rEoibiV3Vp9v125SFpc9EIlEOhDLEFKmWOqhjZfNgwxLKvXyhYuNta0GilIBH3kIx8Zq3FMObx1rQC4Y1mKaZkPMiObJSjj5FSLFEFWx+9MEWSlTjoK7HcU9Lj402UnFzWWbFgzqUxLkGqKNNcYPNDHA8s9omXJ6sqGatYUcmeKIOvhmkiPwTOG1AVauPR09j7YTLtykDdeeIjFyy8pdtg5sQIp9SLrilhZbsYQMWc18Y0qbqqvEAKoQ9xhU6Heilt1owsFpyLQhoggbSqLILP/odfIHoA8EsYQS1C53WH+GrPvIBHC8QTBDAu+krCyUavxyiuOqRm1VgEEGmW8RiBRmAjKdH9lxorki5Wp5MsQQaqZkq5McMyNGqgH5MU6FGtm5arGSsKkHvpWj57RsKrwZjbhtLI3REZMkJGQ505MqHhUF1sbTwMg/MYDxQ96BKy2JnqR5vNEFrdePGpVTK9OAaEO6Ro/FUSQoigpC2csQsKMaZzKliBfrRRBQRFGy68aRhLdELgwK0aX2x1mBkY7FUEoNDxeyalb2ahTRwTlfYQbGhryDoLu7i6uc+5UItAgRVCtyJJCaT7IRJZZgDMjYM3tLS5V3OuXlhSfEkcYOorDCaREkHOC3U2W7zog0t1GVlaDWs0iKCMGZiQ8yHPBndGEU5iWICXDEoQhLUExVDyKgufQc2HlvXQcfBqEgHInMpSYUpvI4tazMs5iVSogPL4hImiKpBprioqPOFo8im5lt06BzLhc+E1LUFCJEE6MsnAGhm4kK247ymwJUobEekZCvdDcmPa5FYPo9NjusGH86Ec/Sv7d1dXFt771Lc4991xOPlm6QJ577jkefvhhrrnmmrIPcjJS0yizw2oIo8ej6anvZlq0cA6/iagZbpHMh2O+eIZk3cSjoaQP2wqUdk1wvyOvdRMhXQT5TPdYNRbRA9PyYWSkhI+AR8RBGS52LRGEnm4JEqY7zGq5suiUdxB99tO0cYDOzatoW7C0xG+QjmLGEBRvCZLn/dAst4RpCarWoOKhv9VUsYYk27jEoxiamdgxRb57NqyYxhoiRAoUQbqeWqHcFaNxOBjEJ91hoeGFHHNlo05m8hZBQ+OB3vOe9/CNb3yDK6+8Mvnepz/9aX7yk5/w2GOP8dnPfra8o5yE1De2JFtn9Hfvo6FtdvIzxXSHiSzusMwsIU+RliC/P4ghFByKIDo4MCR1sjIsLb7kTCpKJJFANQNkfaZ7zBOsviJ6kHL/ZKv0nIlIxJOZXq6MmZkwGytaxRSTmCLIqr8TDNbymucolsZfofPVB8ovgjQrkL64m6ZhibkhliDdTLvXqtQS5B0yMZkq+bKJISJI13IndkwZzDpBfiVGVCtMBemJVFyfw+ks67AAIoqPgIgQG+wd9pk6BUVQUTFBDz/8MOedN7wf0bnnnstjjz1W8qCmAqrLRb8iBcxAz4G0zxTTpSGyZJaoGQ9Dr684EaS6nETMB6UViAqpQGR1gi0t/tqUmdaasQhdw2e6h7xVWEkYUqnt2YocZjLUWuTODFQ3RZCip7vDLAE9NCi1r13GBanbnix8wKNgWYJEkZYgw2XFNg0VQVbV8uoUQWkTlSmigqzzLRGLYCRyF3udMgwp4aFnqeU1EsJIiaayN1AFYg55flrNqIdiiaDMGMTJTFEiqKmpiXvuGV6A7d5776WpqankQU0Vwop0OQ32p8dQOZLusOEXwDB3mLd4xW71e4qFUyLIZxba80ywCHJ7fcTNwoLhARk8PnSc/iq1BFlZXUYeMUFaNCWC1MweTKZ4cGSIIGG2LtCGxGO0LpETlrnhVSTyzErLF6fV1qNIS5DIEuCdTLt3VGlcwpAqyYKpUUw2WcFciyGSlqApLIKcKhFFnr+5OrbnYqglCEd5A6MBYmZLpGwiyGNloxY5ua5GijrC1113HR/72Md44oknkjFBzz//PA899BC33HJLWQc4mYk4g5CA8EC6CFLM2jDkYQkqtm0GgOz13JdsgkkijtvMSvD4Jz4FPaT4aaSfWEiKoGioDy+yM7ffX50XqeX+GVbfJwtW0bmoUHG7Mszilggy4mlvK2Y8wdCg1EVHncTBv9XRTB/rX/sXi066oOjxZ5LsPVdkXRFhfg8lMVQESUtQsXFGlUSBiUFVS8KhgmFaOHWr2OsUdocB/a5mfNpOXPHegtYzhoogpfzuMKs5diIyPDvMbSViFBlmUY0UZQlasWIFK1eupL6+nrvvvpu77rqLuro6nn32WVasWFHmIU5e4man9HiGCHKY7jDL5TEUd2bUfgkiyMq+0SJmv7Ah7QoqwdISNt2FsUHpDouEeuX7+MrfpmOcSKa2Z8byZMGqtxLHNez7KmaWoDMjMBrTlJ4Y8gByOh1sqTkegN61jxQ38BxY+89s55I3VgX0ocejxLT7SsIQ1XmeFooVBK1rUUQyu3UKW4KAqFf2hyxUBFnuMF0oaVbFcpEwm08b0QxLkGHgTWajTh0RVLSt7cQTT+QPf/hDOccy5dDUGohCItyb9r4lgpRs2WGZFoESfMZW9k3C7MweCfURRNaY8fsmPh4j4giADlpYiqCYab4NKz7qJ3BcpWBZPsjLEmTWW8E1rDyFYm7HmWkJMs+dzPRkMW85rH6Mxs5nixl2Tqzec4q7yJumKeKVNBFUWpxRJdArAtQrg2zyHMbbJ3ow44AV/2MkoskSH0aRrVQmCzFfKwxAMFstuBGw3GE6TspvBwLDJcMwRCzdTScS0aTz1ldk1nE1krfMHBwsrPx3octPRXS3GXcTTU9VdFqtD1zDRVA5G9ZaZlHdrMsSNUXGIB48romvo2n5rhOmJShuji+qVO/D0crqIg9LkJVlk63yrmUJslJak+8LOYvMjMeYffyFAMzXNtLftb+wQY+AFUjpLDKQMmXRSn2PUjPOKoF/j3+FT8ev5GnfWRM9lHEhKYLisRFLfEwl4maT7Dq9MBGUtASNgSsMwLAK4WbEKsWHJGt4fdV7jy2UvJ90CxYs4IYbbmDPnj05lxFC8Oijj3L++edz8803l2WAkxnDFEGOWLpZ0imkCFKyuMPKidXvyXKDxQflOCL4yiq2isUSQYYpEhOmRSjiqGJTrSuL5SMHVuVdLYvB1mqf4sphCTIyLIRtM+exzdGBQxFsevH+wsedA3eyuFpxgsWhWgHeqeNh9S+qZhH0hpjDfcYpU8YdZqXDCz2WKvExxUWQ4TNbZ4j8aoJZ6AlTBI2JHQgwCyY6MkRQNJKyTvu8U0cE5e0Oe+KJJ/jqV7/Kddddx5IlSzjuuOOYPn06Xq+Xnp4e1q1bx3PPPYeqqnzpS1/isssuG8txTwqEWUvCEc8QQZY7TB3bm4huiiCr/5PlbopWSH2WhFoDERCm7zoRkf/HndX7cFSS7p/YKEumRFC2onOWeHCJTBFk3kCzuCI6m09mzv6daBv/Cef/Z2EDz4HV1sNVpCXIEnPOIRYtpymCSol3qxQaAlMjONgK+De0uC2CTBweOcn1GoVlZFr9/xJjJIIUM33fqaWLoEg0Qh0y8cTtKn9WWqWS9zddtGgRf/nLX9i1axd/+ctfeOqpp1i5ciWRSITm5maWLl3Kr371Ky644AIcYxDMNRlRzKqiqpYepe8w05wdY9yB2go8tXzDWsRqXFkZIiNhdbKPyXEZZuySVtUiyCxymBnQnAU9kYoJysTqIadmiCBHssbU8AeQ/9C3w/47mdnzAkKIslj7rJRatchsEodqWbSGiCAz48xRbJxRBfDTDx7Db1du45p3HD7RQxkXrMKuIhHFYbnzp7oIMgvOZjaBHg2hyw7yY2UJsqpZq4n0504sKsepKSpT6ZcrWO7NnDmTz372s3ZV6DJgnYyeRLolyCUsS9BYiyDzIWN2jrcsLbEKERmGW85YLEuZJdYSrup9OFqWIKcxuiXIignK1nrBZZ4buSxB2UTQISecR/xJJzPYx7ZNa5lzyJGFDT4TIfBgdbkvrs2KlVU2VAS5kiKoMs7DYrjwqHYuPKp9oocxbiTPt0R8SImPqfQoHY7TFEE+ChVBqcDoscAZkIVofRnPHc2sIaYxNayXFmU32bz00kvl3uSkxWpNoerpF4n1YHOOEhNklFqIzXLNmO4w3awXVClF6oRpTnbG5YxFmBYhXZ0aIsjQ5HmQTQQ53ZYISi/J7xCWCBp+7viCdWz2SMvErpfL0FU+EcVhlkQutoed1ahRHSqCzDgjxxSqWlvtJEWQHktagsY6prHSUc1Jrr9AS5CRrPU1Nh4VV1AWNA7o6SIoFYNoi6BRCYVCRCLpP+yqVau46KKLOOmkk8oysKmA1QRUzfAZO4Q0hzqyZIcNpY/SChoKU0w4EmYncMvdVCGWFst37TJ911blVUOd2OaupZBy/8RHWTLVVDRbDyaX2XBXJVMEmTWmcszCB2e+DQDPjqfyG/BIDAnuLra4Wja3XjLYukjrks0EMMQSlCzgOdVFkFlrLVCoJci05hpjZAly1zQDUCPS3WFWe49s2aiTmYJE0K5duzj11FOpq6ujrq6Oq6++mnA4zIc//GGOP/54PB4PzzzzzFiNddJhVWX25BBBo3UQPuBoLm0AbksEmfu3LC2VIoIs37Uu3XWKWUlY8VTvwzGV1ZWHJcist6Irw73WqtsKjE4XQU7rdY54smlLZQuNheHXiERHH8NICDNmyRAKHk9xrg+rz9ZQEeQxRdBUauJY9QzpZWfVrprqliBPoEgRZLnDxihF3lMrnxt1OURQNsvzZKYgEfS///u/hEIhbrrpJk499VRuuukmTj/9dFwuFxs2bOCvf/1rso2Gzej4AqbPWKQHyToZWQRdol3HM/pift/2vyXt33I3uExLULJdQYW4m1xWYKEuLUAOyyLknfiWHsWStHwUIoKy9GBSTXeYGy3tfadlCcphRZx5+Cn0E6ROGWTdy0/kO+ysxGKpitY+d3HZJFYbGKtcPwzJOLMtQdWDc6gIMmMap7gI8gbqAahRosQL6CQv9LFNkffVtcr/lTixSCpDTI/njkGczBQkgv71r3/xs5/9jCuvvJI//vGPCCG45JJL+M1vfsPcuXPHaoyTFn9QPuT9RIknUl2GnKYlyJXjQXblR/6dvyz+KVf9+7tL2r9iiSArENV0N4kKEUGqvx4Ar2kJciXk/w5PNYsg040l8nCHWZaWbO4wMzDarSQQxtBzx7zZ5ngAKU4XO+qOA6DvjdJaaGhmNkkcFa9a3A07KYJESsylgq1tS1DVYJ6PihHHMU51zioddyDVeiiepU9XLsbaHRasqUcTctvh3gPJ9w3N6vk2tQLaCxJBnZ2dzJ8/H4C2tjZ8Ph/vfOc7x2RgU4GkJUiJEx7imkhagtTss+tlC1u46dKlNAZKO1mt2i5WTJLDzBKjQkSGGrACC+W43JYY8lXG+IrBcvG48xBBSXdTlpnZ0Ea6mpYSEMnMwhHKKyjzzwCgad/KPEacm1jMEkEuVGdxQZyqWZTNg4YQZpD1FOxfVO1Ygsehx3GZliDHGGe3Vjou1UtCyOvCirfMB8sSZIyRO8zpdCAbJEG072DyfcOM8ctWl2wyU/Cdy+lM/TAOhwOvtzIK61Uj6pCHeSScMks6zWDX0WKCSsUSE25TBDkTprupQmJuvEFZcdVPBITArUu3nWoGlFcjTjMGxs3o7jCRLDo3/DzweFIPmHg8FXNgWYJGKq8w54R3AHC4vp7te/blMersxKNmIGUJ2SQe09rjUTTiCR30BC6z97rHtgRVDQ6zl53D0JLZrVNdBDmdDgaRx0UvwhI0VjFBAP2KvPfHBlKWIMsdZluCRkAIwVlnncUxxxzDMcccQyQS4aKLLkq+tv5NFNdeey2KoqT9a2trm7DxjIrLi26muUcHU+mKTiEfAq4xNidbMRfJQFQzNshRITE3vmA9ACo6QgvjMeT43P6J73BfLEMtH6NiNlIUWW5Kbndq8qHFUoJKFaPHYwTaFrDP2Y6q6Gx66aG8xp0NLZ4qrlYs7iHl+WOxKPqQxrJeWwRVDZbgcRrxpDXSOcVFkKIoDGJW5c9oVjoSSUvQWLXNAPqd9QBo/ak+gkK3RNDUsgQVFM349a9/Pe11JbrCFi9ezGOPPZZ8PdRyVXEoClG8BIigDQlQc5nuMFeRwab54rOy08zAbMvSUikBqYFgHbpQcCqCWKgXn1lvw2uKo2pENd1hHhEHIWCEqs0jWYIcLjV5bKxu8wAu8nNFHJx2CtP23IWx6Z/ARwr9GgBo8dKzSdxDMsDi0QhOp4HlBLNFUPUwVARZ1sipLoIAwlj9GYuICRpDS9CgqxF0iPenLMHCjAnKNumazJQkgioRl8tV2dafDCKKl4CIpAXOWSLImeXhV04CNdKiYmWnuU1Li5WVNdEEPC5C+KgjTHSgm6CIgAL+YBVbgsxYHociEIlYsot6NpI9mHLclDRcONGSYgRSKfOWeyIXdYvPgT13Mbf/JaKaXlRgsxazRFDxN03F6cYQCg5FEI+G0UkQQPYv8rin1oy0mkmJIC1pjXSMcG5PFcKK2Zoomr8liHEQQZq3EWKQGCqCkokYtgiqajZu3Mj06dPxeDyceOKJ3HDDDcybNy/n8rFYjNgQd0J/v3RLaZqWFnBaKta2MrcZVXwgeoiGetE0DUPX8SgyQFRHKesYMvH6pMXHrSQYHOhP1ityeAJjut980fUEA/ipI8zA/u3UK6ab0F9bEeMrBseQIobhwQHcgdw3OuumJByurN9XU1x40YiEQ8nz1WUVT3RmX8ei9Ygz0R91sEDZzcrX13D8UYsL/i7xqNluRVFL+j0SioqPOOt37OPWfzzG7W6I40bRE5htlMaMXNelTXZyHS/FfHA6RTxpjVRynLdTiX7dDU7YtqeTaXkeC6tSvIFzzI5fwtcMfSAGDiT3kcoOK+16LpVSrsli1ilIBJ1xxhmjNl1UFIXHH3+84IGUgxNPPJHbb7+dhQsXsm/fPr71rW9xyimn8MYbb9DU1JR1nRtvvJHrrrtu2PuPPPIIfn/5zfGPPvpo2uvDDHnzeGvtKnb36hiJBFbi+1NPPVN0Jd58MAyDi4QDl2Lw0D/u5gJDWlrWvrWJvfv7xmy/hXAo8jdY+8K/6EBaCJ5+6llcztKbf04Emi642LR8fPHXD7FX1POhBUZWr1iwtwuArr5BHnhgeJuL04ULFHjphed4Y+NOAI40H0AbNm9j5+DIrTEOd8zlEGMz6x7/Awd2nVb4d9nxFkcDMUPJOr58WS5UfEqczoe/x+1umbYfReXxErZZKJnXpc3IZB4vfd9mFgMuPYpKHBR4dfUa1m3vmpgBVghe0x324Gtb6FLzO5/1bVs5Fogm9JKuq5EID8rZRaJnZ2ofBzoB6A/Hxmy/hVDMNRkOhwtepyARtGTJkpyf9ff388c//jHNqjLenH/++cm/jzzySE4++WTmz5/Pb3/7W66++uqs63zpS19K+6y/v5+Ojg7OOeccamvL5xbSNI1HH32Us88+G1VNmfm3vPEdiMO8jjaOP/8CYoP9sEZ+dtbZ51BTM7aun77VNTTRx5LD5uNbL3+7U05bxvw5c8Z0v/mgaRobXrsegFn1TjgIAwT4t4sunOCRFY8QgthqaflYdTDBLuHgq+89hSNmDD/XVm+/E2LQ0DKNky+4YNjnPa/J8+ioIxazcMmpaJpG12ufB2DxUUs49LizRhzL1sFnYMNm5sTfYtkFNxT8XV67fyd0yUanF2QZX770veYGBvmAkqpbpCnukraZL7muS5vs5DpeW191wx5wKzpu0yV78qmn0T770IkaakVw38u/BCBIJO/zefV9m6AHXG7fmF0Dzz/UDa9AvSPC0eY+Xtj7GEQgWN/E6eNw7eWilGvS8uQUQkEi6Ic//OGw9xKJBD/96U+5/vrrmTFjBt/85jcLHsRYEQgEOPLII9m4cWPOZTweT1q6sYWqqmNyU8zcrmZ1bNfCqKqK5kiZBDwe35jfmPuVWppEH+vu+hbzTc9MoL61Yh4IVmChY2A3ACElSFOFjK1YenDjI47XrIdjKI6sx9s5pOZPts8TigpCBlJan6tCAwU83sCov+H0Yy+EDb/kaG0VXYMabfUFWj7NitaG013S+aKZ3yNt00pp2yyUsbreJyuZx8tjWqxVtGQVc6+vZsof00M72mEPHNHizOtYRDUdxcwOFg7XmB2/YON0+X+iO7kPJVnp21sRv1sx12Qx4y6pTe0f/vAHFi1axHe+8x2uvfZa3nzzTS699NJSNllWYrEYb775Ju3t7RM9lJwkXPLBI2Jmywo95dMc6zpBACGntDRd5HwegAHhI+ivjC7yAFGHmU01KEVQ2FH9BfTiSBfoY54v8BP15pzLOQyrGWr288DqKaZrQ1LkzZggl3v0zJzg/FOI4KVF6WfdqufyGvtQjDJlkySyrK+VEGxtM/64PDII2iNiOM2YRtVjB0Zb/Rmt8h4j8bvnt3PoNQ/xxq5uAMQYpsjXtcyQ/4tU2INipsjnar48WSlKBD300EMsWbKEyy+/nBUrVrBx40Yuv/xyXK6JjbP+3Oc+x5NPPsnWrVt54YUXeO9730t/fz8f+UhxKcDjgW6JILNvl7CC1ISCcxyOZ1StT3vdK4LUeCsnXj5qZlfURPcCEHFWRg2jUogPecC/w/l8zix5SwQZOW5KVmXXoSLImoW73Hk8gFxudtfJul7R9Y+NsvBwrLYeYoTq1PmQTfBoUyxDpdqxGvoGST3s8xHikx2fJgXNOf13j7rsNfeuBWD7AenSMRxjJ4IaWqQlyEeMWFgKISsbNVfLnclKQSLoxRdf5IwzzuDd7343Z5xxBps3b+aaa64hEKiM2fmuXbv4wAc+wKJFi7j44otxu908//zzzJ49e6KHlhPDFEGKlm4JSuDAOUoQejmIe9M70Q84griKbIEwFsSdUgQ1JmRRr5izMmoYlUI886EvRNblHMmO8NkFQSIpgoY0H01agvKbhRtzlwPQsr/wFhpJS1CJM0fdMfyma1uCqguX1QNOSaXzqXmeg5MZB8boC2VgtU0SythNRuvrGwgLed11798DyL5vQM7my5OVgo7ySSedhM/n47//+7+ZM2cOd9xxR9blPv3pT5dlcIXypz/9aUL2WxIu0/VkVsq1RJCOE7dj7EVQX9PR0HNv8vWgozJqBFnETXeY07yZxNXJYAnypMXAJN1eGYzmDrMaq1piBCHwKHKdfB9A7cdcAKtu4MjEG3R29dLWVJ/XegCUyXyezR1WSu0hm/Enm+vLbRdLZPfMC5mz+x90OtvJt3qd1TZmLOsEKYpCr6MOv9hP/8HdtM85DIc+NRvfFiSCZs2ahaIo3HPPPTmXURRlwkRQVWLdKMzmdSIhZ/KJMfQHDyU0/99gU6pEQFStrEKECWd6fJLhriyRVgyZD/jkDCwDyxKkOLJfplZ5e8stldBiyS5ebk9+cV01HUfQpTTRRBebX32MtrPfm9d6kKowW6r53MhiCcomjGwql8zzLSZUPBVkUZ4wzPN4mPU3Cx7i3KD+mvc4nwZAjKEIAhhwNkBiP4PdMjXemQyMtkVQTrZt2zZGw5i6ONzy5qGYIsgwLHfY+IigfztuLjf84wN8Wf0jAFF347jsN1+Emn5zFYHmHEtWDwmHB4YUAdTj2ctKKEIupOSyBJk3Vt3M0tLicayjlXc8hqKwu/EEmroeRNvwTyhABFmWoFJvmtkaNmZzkdlULu4My2McF/YvKJuMA8mMr5H4D+ejSQEEYy+Cou5GSECsV4ogh2E1vp1abkxbqk8wDvMh7zAfKJYlSB8nEeRVnZx49BHJ1yF/x7jsN18UV7oIUmqqpyVKLrSMB/y9L67PupzDFEHkCJC03GFWZWk9MaSHmJq/JUWZfwYAM7qez3sdSAVSliqCjCyB1bY7rLpQMtq0lNJUdzKhmL0r84kNalbSa9yIHBbgcmHFgxoh2UneaYkg2xKUm5tvzp3OOxTbHZY/liXIEkGGOasfL0sQwGBDqqBZoj53i5EJwZ0eCO2qq34RlGn52Lt1HTC8AGTSHZbDEmQ1VhWWJWhIyXi1gODG9mPOhxe/wHx9C30H91LXnF9JiXKJoGzZZfoUS9OtepwuEmb1eUiVgZjqWK7sfCxBgvQYUKGMrY1C88ouCmrkIJCqSzbVGt+WXCwxEzsmqDCcbjPwV7fcYaYlaIxNoUNpnnsUf3vqFPzEUOa+bdz2mw8JX7r7y9cwfYJGUj50Z/qs+YjGXNlh0hLkcGa/TIVpCcIUIwkzRkcTTtQC4jGa22axxTGbecZ2Nrz4MMdfsCKv9SzzeckiKMv6tjus+tAUFRex5N824DSvQyUPS5BVPNXCxdg2zjN8MvRBjffK/Ymp6Q4rSARt3bp1rMYxZXGZliDVMN1h+vi6wwAOa6/n3xNXIgQ8saCyCku6vOmB2rWtMydoJOUj0/1zede36Qt/ljp/+oMj6Q7LmR1mzrZNEWRZETVcFPoI6mpcyryD29G2Pw+syGudsomgLJagbMHSNpWNhorPEkEFn4GTE8V0ZTvysAS1Kj2ZK4/FkJI4PdLK7kjI2k5O0/LsnGL1nQo6yi+88AIPPvhg2nu33347c+fOpbW1lcsuu2xCe4dVI5Y7zFLhhvlAG08R1BBw87uPnshfP3kyc5oro+aTRcCdfop2tM+YoJGUj8wHvKronPqNe4ctl7QE5YgNsNxhVvsKXSs+qN4560QAGrpW5b9OMpCyxJuma/jM07YEVR/xIdYfu9ilxLLi5mMJeofzhbTXRnYDcdlwma1OnAlZnkW13GFZrsfJTEEi6Otf/zqvv/568vWaNWv42Mc+xtvf/nb+93//l7///e/ceOONZR/kZMbhke4w1RRBE2EJAjjtkGaOm1NZmWEW93reCcD9xsn43ON7XMYCI8tN5u/urwx7z4GVHZbLHZZuCUqYRRMTRbhSpx8h3aDztE0M5tmJ2UqpHQsRlHD8//buPTqq8mAX+LP3nj2Te0jIjUiACAJqQCWoBO/4EVFRW0/9pHooHlvWoX7YWmz7gX6ngNUFPa22tqvaVbRqe9qFbVGXp2JLukREAeUgFhBFFJSLhEsCmUDC3PZ7/pjZe/bckplkZvZk9vNby+XMnj3Dy8uemWfeK1sShhpz6w8Htgfps8P6HBi99Vngr9+MORw9Rijd1MJgS5AjEAxBDj0E2WyRy5RC0L/+9S9cf314Z+rVq1fj8ssvx6pVq7Bo0SL88pe/xJ///Oe0FzKfKaGWIKfQu8OCX3zZHBOU6ypv/TFWOO+H49YnrS5KesQZ9NsoH409LdQ8LSfaPkUf/KzprYj6Qpupzyqpa7wQJ1EGl+TD3n8lt3p0ulqCpDhjEAQnrg455uDDEBSkt+L22R322iJg119jDmc6BDkLgiHIqYVagowtd+zVCpvSJ83JkydRW1tr3N+wYQNmzZpl3L/00ktx8ODB9JXOBtTQImMu6C1B4RWjKahlfD2WPPQobpg6weqipEWi2V7RFGNgdIIvlFBLkBS6ZjS9JWgAIQiShEPFFwIAuve+k2T59Nkkg/vlGHdMURa2jKH0Mi9wGWBLHgDTOkH6EvGd+4E/zQEO9L8cRaZDkKs4uPq+UwtOytG7wxw2mx2WUgiqra01Bkd7vV68//77aGlpMR7v7u4e0Fb2dqbPDnOJqF/zbAnKW4m6t6Lp3WFyotAUCkf6cvf6oon+Ae45dLauGQBQcHRbUuenq/k8XktShodDUAYETGOC/BzTBSA8JsjoDvvLPcAnrwO/u6Hf52Y6BBUUBUNQgTgLIYSx+bKzILnV5vNFSiFo1qxZWLx4MTZu3IglS5agqKgIV111lfH4jh07MHbs2LQXMp/pLUFOfXqkPkV+IL/maUgoQPy9wkTURqpKP2OC4Ah96YTG5gQGOai+fNx0AEDDmQ9jyhKPPo5tsC1B+uQAs0wPCqX0M7cEaWwJAgDIocUS9b0P0Zn8DOuMh6DCUAiCB76AMDZfVuO8H/NZSiHo0UcfhaIouOaaa7Bq1SqsWrUKTmf4wv/d736H1tbWtBcyn6kFwZagAnjh9weM7rBMbp5H1lLl+OMDAlHf/Hp3mJJwTFDw17Y+Nkf49VbEgQXoUZOvREBIqMMJHDm0r9/zHWkaQxAvRAUYgoYcc/Dh7L4gPQRJ0CCEQK83/g+geDI+Jqg4OCaoCB6c7vVAlYKfN8luvpwvUvq0rK6uxsaNG9HV1YWSkhIoSuQX9V/+8heUlJQkeDbFo+rTFCWBM14PEJodpnFMUN7SV9WN5j/dAUd5tXFf6ac7TB8rpO82r68TNNAQVFBcjs+UMRir7cfxj95BfUPfrbqq8AES4Bjkh6YqxSYetgQNPebgo3GKPABAlsPbZhzs7EW9dhbJZptMvwX07jBZEnCf6oA+N9hZYK8QNKApGOXl5TEBCAAqKysjWoaof+bdl71ne/Bl52kA2d02g7LLEedLHwDe2bAu4r4RghJsgSGFxtLoixYONgQBwLGy4D5yvgP/r8/zhBBQjebzwX1oBoaPjzmmMQUNOebgE28/ODvSW3EVoSHg9yT8ARSPluEZkqor3GBxpqvDuD3Y7u2hhvNQLeZwFkITwZ8Gfk8P/r4zOLvO7eWXQL7SXMPiHt9x+FTEfX0cQaJtMySjJSjUeqi3Ig4iBPnrLgIAFHXs6vs8LTyQcrAhyFczGd/x/gfu8PzIOLbPmR8zAe0kMgTxxzAASFJ4dljxnpdSem7GvwEUB7yhzqCz3R2m4/b6t+PoW6tJEjxQUQgvfJ5e44vPx5agvHXo3Dtwclcb3tIm47/UPxrHHcK0V5CmGdeC4kjQHRb6xaavNq5vpDqYEFTW2Ax8DNT3fgKhaZDk+L+TvH4NrlBLkDO04OdA1Za78Kp2BQBghudnOFc6Ap9z0qBek7JPmL48JbYEAQh3hynQUPPGopSem+kxQQDggRNO+OE5HdyywwsHnDZbnoItQTnAF/rS8nnPGpvmcZ2g/CUKKvAN3xI8E7gZP/X9u3FcNc8aC7XuAIkHRuvdZHJoqrqxxtQgZuZMmDwNPqFgGLpx9NCnCc/z+gJwSaGWINfgWoJqSguw5tvTsf7712KfqMc/teaYQeKU+yL2gLNZl0oi+sxOOUEXeF/OyoP7cZEMrxT8N/Od0UOQ/Wb1MQTlAH25eb/3LOqkTgDAhJE1VhaJMkiRw7+0fh34CjYGguNwEoeg+M3T+vo6jqgQNJiWoILCInyhjAIAnNi7NeF5Xl94j0AlDYurNY+uQKNp37pxNZxgMdQI83Vqs/2nEpEGsQnqKUd1/ycNkhfBfzOttwuAPTe+ZQjKAfqF5/OexWw1uFCdYyKXGshX/qj53/qvr6pCUzO0KQQlGhOkhw99pVeEQpAYRAgCgGMlEwEAvoPvJzzHe7Y3fGeQu8ibvfIfV+DeKxrxYGvsYGnKbQGHafNlV6l1BckhUpwJRP1Z6ZuDvwUux/bSazJQokjGRrdngyHIL9kvBHFMUA4ISA5AAAGvB2WiO3hs+PkWl4oypdcXiLjvC70NSxymmSOmEORI1BKkrxMU3RKUYNf5ZHmqJwPu1+E6vjPhOT6vKQSlcfzHxQ3DcHHDsLS9HmWP5jQFHydDEABIKbYzaELCbwK3AAEJs7MwJMIX6g6TPe7gfbYEkRX09B3wnYUjNNhUsdkmdnYyY2INVEXCZY2V+Nv9V8Kvvw0D4eAT0R2W4Nekvl1FuCUoNDB6kKv1ljUGt88Y0fMxkGDlaJ8nuN+QHwqQYPA02YumhrswpQJ2ZwLhxRKTFZwQE2wRzsaoOL0lSPEGQxBbgsgS+o7LAZ8nvJOvzTaxs5PKYif+tbQVBQ4FsiwB1WVAJyBMs8M0vw8yAJ9Q4FDihwz9GtGDswiFqMF2hzWcfykCbRIq0IWznYdQMLwh5hyfNxiCvFD5IUIAAM1VZtyWCsr6ONNG5H5CUNSPDJ/53ZSFFOQPtQSpvlAIsuF2J/wJlwMCoe4LzXsWKvSlyxmC8lmR0xEMQACE3n1lav3xh7bA8EOBosSfsupQo1qCQitHiyQ3aE2kurIC+6WRAICje96Le07Aq7cE2e9Dk+IrKBlm3FYK2B0GhKfIJ7Jj3fMR90uks8ZtkYUU5FdCnyH+4DAM/Qe5nTAE5YBA6MIT3tPGMbttYmdr+j5xoRD0/oGTePwfuwEEQ5BDjh+ClNDq7PrKzUYIGmSTtiRJOFpwLgDg9MEdcc/xh0KQz4bN5xRfWVW9cbsoTuuhHfUXgqo2/TjhY0nsYTxo/tBWJwX+4HdPwIbvZ4agHKCv66KdNYUgF1uCbEP/oNSCrYC3P7UJbbsOAwACkCOm1JvpKzU74YcQApI+OyzBXmOpODMsuGKzdGx33McDoSnydhxDQPFVn3cpnvPfgCf9t2NkfX3/T7CBRIuN6iqk7iyVJD59v7fCQCgE2XDPN3bn5wB9IKvwhN8QzkEuQEdDhzGGxzwjLNQtGmwJSjAmKNRl6pJ8+Oz4aaMlCIOcHQYASt2FQDtQ5v4k7uNGdxhDEIVUlhRg9H//FVwOBdWl/BEHBEOQJqSEiyW6ELmr/B/8/2bcNq+blSmBUHdYkQiGoMFOqhiK2BKUA7RQGtdDkE8ocCZYJZjykDEmKDww2hyCEjQERXSZ/tcvnoakh6g0fJBVNF4CAKjzHQRC23GYaf5gCLLjL0dKbMbEWlwxrsrqYuQMWQq25kbzCX13+chwdFRU4Pn/cSnuvaIRC2eMy3j5tFAIKhZngvdt+H5mCMoBQv/SCo0J8sGRsAuE8lBUdxgQ3jzVDwVSgr18zNtVPOz4IyR9TFAaQtDocyegWxTCgQB62z+OeVxjdxhRv2RJghZnD7BPxMi451dX1+DaCTX40S0XoMiZ+R/CWmiNrxIE1/1iCCJL6DsuK95gGvfCkfCLj/JQqCVIErHdYQGR+C2qmFZqbpI/D7cEpWFM0PDSAnwmBbfPOP5p7MrR+pggO35oEiVLkiRocb5mZWhxzgYm1ldmukgRtKjtTTSb7SAPMATlBH33ZTk0Qt8/yHVeaGiR5MjZYUBkd1hCUVPh9ZagdIQgADheNBYA0HModuVo4Q+GoMFs1kqU7xJ1h0V3gxnHHdl9P0mOqFnIDEFkidAXicMfbAni2is2Y7QEmcYESaGWoBTeonpLkJSmEOStDO4h5jj+Ucxjgi1BRP2SgLjdYUqCliBZze77SXZFhiDBEESWCHVrOAM9ALj2it1IoRB0qCO8RMLF0mcAUptCK4v0DYwGALU+uLv9sNN7Yx7TQi1BdvzQJEqWnKA7TErQEqQk2CcwUxRnUcR9O76fGYJygH7h6SHIz5ULbCUgBd+G33C04fCpXtwib8J/qqsBANWSO6nXcIsiyEZLUHqun+HnTgEAVAWOGbtMG0IhSEvj5qlE+UZK0B2WqCVIyXJ3mOqKDkH2W5qFISgHSKEQVKAFR+gHOCbIVoq6Pzdun+pyY77jtaSfu9w3FwDwoTYGsr59Rpp+zY0ddQ6OiOBAzZ7DuyIfDG3WKtgdRpSQJEmowOmY46ocvyXIWP09S9SCyBCELLdE5QKGoFwQ6g4rRKglyIb7t9iZ0x/+kPR7zuBC6fOkn/ulGA4AcEh+oyUoXYMrhxU58YUcnMp78vPIECQF2B1GlIx4CyUmmh2W7e6w2BDElqC88NRTT6GxsREFBQVobm7Gxo0brS5Sn6RQCCoWoZagNKz4S0NJ+EOyy+2GkmB12Xj02WMqAsaYIDmNwaSzYAwAoPdI5FpBkt4SxBBElLJEIehMbXNWy+EsiFyVWnLYr3s770LQiy++iAceeAAPP/wwtm/fjquuugo33ngjDhw4YHXREpJC6d8lBb/EAmwJshVJhD8QH1nzbsRj62vv6fO5910fnMF1sfwZFJHeMUEA0DssuGqt0hG5fYbMEEQ0YIkGRgf6WhIjA5SojbplhqCh74knnsA3v/lNfOtb38L555+PX/ziF2hoaMDTTz9tddESktXIC8+O+7fYmTkENUrtEY/1t/rzxGHhD1OHCHZRSWlsUleqxwMASk7vjzguaaGtNDgwmihliojfEhTI8qQYR9TAaEm1X3dYXvW7eL1ebNu2DYsXL4443traik2bNsV9jsfjgcfjMe673cHZOD6fDz6fL+5zBkJ/rbivGfVF55fUtP7ZQ1WfdZZHzOsDFSByny6tv2tBCv+OqQ4cDz4HStrqrKh+IrADqPQdga+32xgzoLcEafLQvlbtco2lC+srNT6fL+6qbxK0uI9VlRVkt26jWo2FYv37eTDX2ECek1ch6MSJEwgEAqitrY04Xltbi/b29rjPWbFiBZYvXx5zfN26dSgqKorzjMFpa2uLOaYdOoSLTfd7vAGsXbs27X/2UBWvzvLJxDPhgdH6StG646fcfV4Lmqbgq6HbpQgutrn3s/040pOe6+fLMwJuUYQyqQcbXnkB3UUNAICSnuCU+fbjnTiYB9dqvl9j6cb6St5tcY7J0LB27dqYxz7c+g52ZnHGpffMSYwy3d//xUEczpH380CusZ6enpSfk1chSBe975YQIuFeXEuWLMGiRYuM+263Gw0NDWhtbUVZWVnayuTz+dDW1oaZM2dCVSPz/54NbuB4+L6zqBw33XRT2v7soaqvOssnL6uFmPDeHQDCK0XrpOLh/V4LHR+UYbhpPaGJF1yIyS2taSnbWV8Ae1fWY4r0KS4ZW4WSS4Jl2fbxs0AvUDdyNCYN4WvVLtdYurC+UuPz+YDtsccVaMH3ddRjs266JbyhchZ0dR4HTMP9xk9swgVXWft+Hsw1pvfkpCKvQlBVVRUURYlp9Tl27FhM65DO5XLB5Yod16Cqakbe5PFe1xln6XJ+wIRl6t8iV7hLx6Et0IyZyjao0S1BvaLfv3v0YmwOZ2Ha6ktVVRxRRwGBT3HmyMeouCz4ukpoTSJZLciLf5t8v8bSjfU1ODLiv69VV3bH5BSVRv7QdxYW58y/60CusYGUPa8GRjudTjQ3N8c0o7W1tWH69OkWlap/StTAaMHBprZy46QR8IZmhdRKJyMeCySxhYo/6m2c7k0Yu0sag2U5usc4pocgO06pJUrFeyUzY44lmiKfbU5nITQR7iVRnBwYPeQtWrQIc+fOxdSpU9HS0oLf/va3OHDgABYsWGB10RKKns0j0rQBJg0N5wwrxOHSQqAH+K7jpYjHnFHdY/FE702Urg1Ujdcffh7QBbhOfWYcc4Rmh0kqQxBRX04462OO6bvIH3Kei5HefcGD38z+OCuHQ0EvVBSGJmQ4GIKGvjvvvBMdHR145JFHcOTIETQ1NWHt2rUYPXq01UVLSI4JQfxisZsq0RH3ePRA6XiqcSrifrpbggrqzgf2ARW9XwCaBsgyHGwJIkqKiLP2j94SdEYpBwC83fQormy4LKvl0nngZAjKN/fddx/uu+8+q4uRtJgQxC8W25FF/LCzr2hSv8/VF9k0XivNS+8PHzUB3ncUuHAWcB8GhjXAIbyhP4vXKlFfNCk2BIU3UA22CGkW7hLgMS3O64haPNEO8mpM0FAVs7gdW4IIwJP+r+JM+fiUn5fuEHRuTTm+EHUAgMDx4FQStgQRJSnObC9ZEoAwrxodf/ZyNngQ/rxw2rAliCEoB8R8adlwJ1+K9X/8M/HAv52X8vPkNI8Jqh9WiC8QDEFdhyNDkOJkCCLqi0jwNSu0ACQ9CEnWfRWbt+ooKimxrBxWYQjKAdFdChJbggjBWV9jq1P/UEr3mCBFlnCqILibfE97MASp+hR5G+46TZSSON1hAKBpGiS9WyzBOnbZYO6KLywut6wcVmEIygGyGtnywxk3dhS7oeKa+64a0CspavpbEj1lYwAA2ongDDEV4XWCiCgxIcf/mtU0P/T3vbCwO0w2Tb5I576DQwVDUA6IaQniOAsC4BjgomXpHhMEANLwcwEAhae/ABAOQY4sL+5GNNTEmx0GAELTIOm9YRa2BClJzEDNZwxBOUCJCj2ccWM/UpxdpWUluRkjrwcujbjvSPJ5qZCHjwUADPMcBrQAVBGckeZgSxBRn0SC8T5aINwSZOVXsSNHFm60CkNQDojuDpPZHWY7RYHumGNSkmFmlf9m47ZHOKAo6X9bF9WMgVcowbFA7i/hhD4wmiGIqC8iwV5gwjQmSFjYEuSAv/+T8hhDUA5QHNFjgvjFYjcvVX4r5liyLUE+03JfPjigZOADtX5YMQ6KGgDA0f074ZCCH96cHUbUn3AI8ovwV64wDUi2sjvsLOw3DsiMISgHKA5HxJsjei8xyn/vFl2Dw2J4xDE5yd2kzRuo+qFAkdP/gXpxwzB8Hlor6MjeD4zjKluCiPpmeh+bp6NrWgCS0R1mXQhaO2EFOkUJ/jrqYcvKYKW8XDF6qFFkCT444NCXLmdLkO34NYEjYjjOkYLbZ/iEAjnJX4fRLUGFGQhBDkVGQe044MR2iGMfGcdVG64wS5QK85gg8w+W4MBoY2R0totluHfOnXjzk+vQOqbSsjJYiS1BOUCRpIgvMidn3NhOQNOgmX4NapCRbJYxf7B64chISxAAoDI4Q6zUvRcAoAkJagam4xPlFdM6QRokY9d2IUS4JcjKdYJkCTMm1qKswJ4bdzME5QBFluA1hSBXQZGFpSEr+AMiYjd4P+Skw4zP1MReip6MhaCi2uDq1SO8nwMIBi7VwY8Qoj6ZWoI0UweY0ALIhdlhdseazwFSdEsQQ5Dt+DWBgGlcWLHkgSPJWV4BEQ5BZVJvxgZZVo6aGCwbegEAXqiWDugkGhJkc0uQbCyMqAnkREuQ3TEE5Qi/6de8q5DjLOym84w3ojsMABxJtuj4EyzGlm71o8dHDOD3wp7N50SpEJJ5YLQcfp9rWngTVYYgyzAE5Qjzqp123L/F7v5z1gScLx+IOJZrIUh1unBUrjHu+yTOqyDql5SgJUgLd45ZuW2G3TEE5QinacGqgiL77eRrd7OaRqBKckccS3Zsz5N3Tc1EkeLqdI00bvvYEkTUr9jZYfrA6HAIkizcRd7uWPM5whyCFCU7v+wptyU73ubSsTX9n5Qm3tIG47ZPYggi6o957zBzd5iAAHJgnSC7YwjKEarNly4noFMMrAVQVrIXRuTK0cZtP1uCiPrlN3WHBSfFh0KQFghHn0wta0H9YgjKEQxB5C5s6P+kOBwZ2DU+keKascZtP1uCiPoVvYGq3vajCfPGyQxBVmEIyhEcGEeOggG2BDkceDtwIQDguMjsoPqqUecZtz1sCSLqV6kz3BIUHAOktwRpAKfIW44hKEd8LIKtAJ2l4y0uCVlH9H9KAuMXvY7/0v4nHi17JI3liVVZbwpBPq2PM4kIACQ5/DUrQYSnyJsHRvOr2DKs+RxRPvcPOFBzHcq++oTVRSGLDObNWFNRjv/18KOYMa4ibeWJqyi8yWuV1JXZP4soD5jXCZIhTFPkA6j3Hwo9wJYgq3Chjxwx6rzJwHmvWF0MslBNqRM4NfDny9n4IDU129dKJzP/5xENccL086YGp3AawR0Bive8bDqLIcgqDEFEOSLZxRFzRZnUY3URiHKf6YeDLIW7wxyde43jHBNqHXaHEeUKwTE2RPkuHHjCYwC5B591GIKIcoUwDYye/XPrytGff/9DcGfsW560uiREQ5f5Rw9XjLYMu8OIckVRZfj21HutK0d/LrgVeOhLQOVGv0Sp0vS2B83c8suWIKswBBHlihv/N9B7Cpi2wOqS9I8BiGhAjBWjYW4JYgiyCkMQUa4Y1gDc+7rVpSCibBAcE5QL2BFJRESUQSek8PpawrRYooFjgizDmiciIsooYbqlhyDTRAi2BFmGIYiIiCiDRMTtOCGIA6MtwxBERESUScJ8Mxh4/IGAcYxjgqzDEERERJRBLjX8VStCgaerxxNzjLKPIYiIiCiDSlzmidihKfKmgdGaYAiyCkMQERFRBpkjjt4d9uXJXuNYQIAswhBERESUJXoIkk0DhTRuG2iZvApBY8aMgSRJEf8tXrzY6mIREZGNaVPuCd5ovDocgqRw8vGzO8wyebdi9COPPIL58+cb90tKSiwsDRER2Z12xQNQGq8AzmkGVk4FBHC5/HH4cXaHWSbvQlBpaSnq6uqsLgYREVGQ7AAarwYAKCIQ8zDHBFkn70LQT37yE/z4xz9GQ0MD7rjjDvzgBz+A0+lMeL7H44HHE56q6Ha7AQA+nw8+ny9t5dJfK52vme9YZ6lhfaWOdZYa1ldq4tXXCHE05jyvP8A6DRnMNTaQ50hCiLzJoD//+c8xZcoUVFRU4L333sOSJUtw22234Zlnnkn4nGXLlmH58uUxx//0pz+hqKgok8UlIiKbuW37N2KOLa9+EhePrLCgNPmlp6cHd911F7q6ulBWVpbUc3I+BCUKKWZbt27F1KlTY46vWbMGX/va13DixAkMHz48zjPjtwQ1NDTgxIkTSVdiMnw+H9ra2jBz5kyoqpq2181nrLPUsL5SxzpLDesrNfHqS32sKua8t+7YiZbxI7JdvJw0mGvM7XajqqoqpRCU891hCxcuxJw5c/o8Z8yYMXGPT5s2DQDw6aefJgxBLpcLLpcr5riqqhl5k2fqdfMZ6yw1rK/Usc5Sw/pKTX/1dcX5DVBkzhAzG8g1NpBrMudDUFVVFaqqYpNzMrZv3w4AGDGCCZuIiHLPJtcVmM4AZJmcD0HJ2rx5M7Zs2YLrrrsO5eXl2Lp1K773ve/h1ltvxahRo6wuHhERURwMQFbKmxDkcrnw4osvYvny5fB4PBg9ejTmz5+PH/7wh1YXjYiIKC5GIGvlTQiaMmUKtmzZYnUxiIiIksYd5K2VV9tmEBERDSWdZ7g+kJUYgoiIiMiWGIKIiIgsktML9dkAQxAREZFFBIdGW4ohiIiIiGyJIYiIiMgibAmyFkMQERER2RJDEBERkUU4MNpaDEFEREQWYXeYtRiCiIiIyJYYgoiIiCzCliBrMQQRERFZhGOCrMUQRERERLbEEERERGQZdodZiSGIiIjIInXotLoItsYQREREZJGGcofVRbA1hiAiIiKLnDOs0Ooi2BpDEBERkUUUmWOCrMQQREREZBmGICsxBBEREZEtMQQRERFZRWJLkJUYgoiIiLJl6r1Wl4BMGIKIiIiypXyk1SUgE4YgIiIiy7A7zEoMQURERFnD0JNLGIKIiIiyJmrfeA6MthRDEBEREdkSQxARERHZEkMQERGRVYTo/xzKGIYgIiIiyzAEWYkhiIiIyCpsCbIUQxARERHZEkMQERGRVU4ftboEtsYQREREZJXOz6wuga0xBBEREZEtMQQRERGRLTEEERERkS0NmRD02GOPYfr06SgqKsKwYcPinnPgwAHccsstKC4uRlVVFb7zne/A6/Vmt6BEREQ0JDisLkCyvF4v7rjjDrS0tODZZ5+NeTwQCODmm29GdXU13n77bXR0dGDevHkQQuBXv/qVBSUmIiKiXDZkQtDy5csBAM8//3zcx9etW4fdu3fj4MGDqK+vBwA8/vjjuOeee/DYY4+hrKwsW0UlIiKiIWDIhKD+bN68GU1NTUYAAoAbbrgBHo8H27Ztw3XXXRf3eR6PBx6Px7jvdrsBAD6fDz6fL23l018rna+Z71hnqWF9pY51lhrWV2ri1Zcc0KCYzhGSDD/r0zCYa2wgz8mbENTe3o7a2tqIYxUVFXA6nWhvb0/4vBUrVhitTGbr1q1DUVFR2svZ1taW9tfMd6yz1LC+Usc6Sw3rKzXm+jqvfQ8uMD0mCQ1r167NfqFy3ECusZ6enpSfY2kIWrZsWdwAYrZ161ZMnTo1qdeTJCnmmBAi7nHdkiVLsGjRIuO+2+1GQ0MDWltb09qF5vP50NbWhpkzZ0JV1bS9bj5jnaWG9ZU61llqWF+piVdf8jufAEciz7vpppssKF1uGsw1pvfkpMLSELRw4ULMmTOnz3PGjBmT1GvV1dXh3XffjTh28uRJ+Hy+mBYiM5fLBZfLFXNcVdWMvMkz9br5jHWWGtZX6lhnqWF9pSaivpTYSdmsy1gDucYGUo+WhqCqqipUVVWl5bVaWlrw2GOP4ciRIxgxYgSAYJeWy+VCc3NzWv4MIiIiyh9DZkzQgQMH0NnZiQMHDiAQCOCDDz4AAIwbNw4lJSVobW3FBRdcgLlz5+KnP/0pOjs78f3vfx/z58/nzDAiIiKKMWRC0I9+9CO88MILxv1LLrkEALB+/Xpce+21UBQFr732Gu677z5cccUVKCwsxF133YWf/exnVhWZiIiIctiQCUHPP/98wjWCdKNGjcLf/va37BSIiIiIhrQhs20GERHRkKcWW10CMmEIIiIiypYp3wAar7a6FBTCEERERJQtziJg3v+1uhQUwhBEREREtsQQRERERLbEEERERES2xBBERESUbQ3Tgv8fO8PactjckFkniIiIKG/M+RPw4UtA03+zuiS2xhBERESUbcXDgcvmW10K22N3GBEREdkSQxARERHZEkMQERER2RJDEBEREdkSQxARERHZEkMQERER2RJDEBEREdkSQxARERHZEkMQERER2RJDEBEREdkSQxARERHZEkMQERER2RJDEBEREdkSd5GPIoQAALjd7rS+rs/nQ09PD9xuN1RVTetr5yvWWWpYX6ljnaWG9ZUa1lfqBlNn+ve2/j2eDIagKN3d3QCAhoYGi0tCREREqeru7kZ5eXlS50oilchkA5qm4csvv0RpaSkkSUrb67rdbjQ0NODgwYMoKytL2+vmM9ZZalhfqWOdpYb1lRrWV+oGU2dCCHR3d6O+vh6ynNxoH7YERZFlGSNHjszY65eVlfHNkCLWWWpYX6ljnaWG9ZUa1lfqBlpnybYA6TgwmoiIiGyJIYiIiIhsiSEoS1wuF5YuXQqXy2V1UYYM1llqWF+pY52lhvWVGtZX6rJdZxwYTURERLbEliAiIiKyJYYgIiIisiWGICIiIrIlhiAiIiKyJYagLHnqqafQ2NiIgoICNDc3Y+PGjVYXKeuWLVsGSZIi/qurqzMeF0Jg2bJlqK+vR2FhIa699lp8+OGHEa/h8Xhw//33o6qqCsXFxbj11ltx6NChbP9VMuatt97CLbfcgvr6ekiShFdeeSXi8XTV0cmTJzF37lyUl5ejvLwcc+fOxalTpzL8t0u//urrnnvuibnmpk2bFnGOneprxYoVuPTSS1FaWoqamhp85StfwZ49eyLO4TUWKZk643UW9vTTT2Py5MnGYoctLS14/fXXjcdz7voSlHGrV68WqqqKVatWid27d4vvfve7ori4WHzxxRdWFy2rli5dKi688EJx5MgR479jx44Zj69cuVKUlpaKNWvWiJ07d4o777xTjBgxQrjdbuOcBQsWiHPOOUe0tbWJ999/X1x33XXioosuEn6/34q/UtqtXbtWPPzww2LNmjUCgHj55ZcjHk9XHc2aNUs0NTWJTZs2iU2bNommpiYxe/bsbP0106a/+po3b56YNWtWxDXX0dERcY6d6uuGG24Qzz33nNi1a5f44IMPxM033yxGjRolTp8+bZzDayxSMnXG6yzs1VdfFa+99prYs2eP2LNnj3jooYeEqqpi165dQojcu74YgrLgsssuEwsWLIg4NnHiRLF48WKLSmSNpUuXiosuuijuY5qmibq6OrFy5Urj2NmzZ0V5ebn4zW9+I4QQ4tSpU0JVVbF69WrjnMOHDwtZlsXf//73jJbdCtFf6umqo927dwsAYsuWLcY5mzdvFgDExx9/nOG/VeYkCkG33XZbwufYub6EEOLYsWMCgNiwYYMQgtdYMqLrTAheZ/2pqKgQzzzzTE5eX+wOyzCv14tt27ahtbU14nhrays2bdpkUamss3fvXtTX16OxsRFz5szBvn37AAD79+9He3t7RD25XC5cc801Rj1t27YNPp8v4pz6+no0NTXZoi7TVUebN29GeXk5Lr/8cuOcadOmoby8PC/r8c0330RNTQ3Gjx+P+fPn49ixY8Zjdq+vrq4uAEBlZSUAXmPJiK4zHa+zWIFAAKtXr8aZM2fQ0tKSk9cXQ1CGnThxAoFAALW1tRHHa2tr0d7eblGprHH55Zfj97//Pf7xj39g1apVaG9vx/Tp09HR0WHURV/11N7eDqfTiYqKioTn5LN01VF7eztqampiXr+mpibv6vHGG2/EH//4R7zxxht4/PHHsXXrVsyYMQMejweAvetLCIFFixbhyiuvRFNTEwBeY/2JV2cAr7NoO3fuRElJCVwuFxYsWICXX34ZF1xwQU5eX9xFPkskSYq4L4SIOZbvbrzxRuP2pEmT0NLSgrFjx+KFF14wBhEOpJ7sVpfpqKN45+djPd55553G7aamJkydOhWjR4/Ga6+9httvvz3h8+xQXwsXLsSOHTvw9ttvxzzGayy+RHXG6yzShAkT8MEHH+DUqVNYs2YN5s2bhw0bNhiP59L1xZagDKuqqoKiKDHp9NixYzFp2G6Ki4sxadIk7N2715gl1lc91dXVwev14uTJkwnPyWfpqqO6ujocPXo05vWPHz+e9/U4YsQIjB49Gnv37gVg3/q6//778eqrr2L9+vUYOXKkcZzXWGKJ6iweu19nTqcT48aNw9SpU7FixQpcdNFFePLJJ3Py+mIIyjCn04nm5ma0tbVFHG9ra8P06dMtKlVu8Hg8+OijjzBixAg0Njairq4uop68Xi82bNhg1FNzczNUVY0458iRI9i1a5ct6jJdddTS0oKuri689957xjnvvvsuurq68r4eOzo6cPDgQYwYMQKA/epLCIGFCxfipZdewhtvvIHGxsaIx3mNxeqvzuKx+3UWTQgBj8eTm9dXSsOoaUD0KfLPPvus2L17t3jggQdEcXGx+Pzzz60uWlY9+OCD4s033xT79u0TW7ZsEbNnzxalpaVGPaxcuVKUl5eLl156SezcuVN8/etfjzt1cuTIkeKf//yneP/998WMGTPyaop8d3e32L59u9i+fbsAIJ544gmxfft2YzmFdNXRrFmzxOTJk8XmzZvF5s2bxaRJk4bcVFwh+q6v7u5u8eCDD4pNmzaJ/fv3i/Xr14uWlhZxzjnn2La+vv3tb4vy8nLx5ptvRkzn7unpMc7hNRapvzrjdRZpyZIl4q233hL79+8XO3bsEA899JCQZVmsW7dOCJF71xdDUJb8+te/FqNHjxZOp1NMmTIlYnqlXejrQaiqKurr68Xtt98uPvzwQ+NxTdPE0qVLRV1dnXC5XOLqq68WO3fujHiN3t5esXDhQlFZWSkKCwvF7NmzxYEDB7L9V8mY9evXCwAx/82bN08Ikb466ujoEHfffbcoLS0VpaWl4u677xYnT57M0t8yffqqr56eHtHa2iqqq6uFqqpi1KhRYt68eTF1Yaf6ildXAMRzzz1nnMNrLFJ/dcbrLNK9995rfNdVV1eL66+/3ghAQuTe9SUJIURqbUdEREREQx/HBBEREZEtMQQRERGRLTEEERERkS0xBBEREZEtMQQRERGRLTEEERERkS0xBBEREZEtMQQRERGRLTEEERERkS0xBBEREZEtMQQRERGRLTEEERERkS39f/6uhiyHPW5tAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pred[:,0], alpha = 1, label = 'predicted')\n",
    "plt.plot(tgt[:,0], label = 'target')\n",
    "plt.legend()\n",
    "plt.ylabel('SINR(dB)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1cdc4fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sortd_error, a_error = return_cdf(error.flatten())\n",
    "plt.plot(sortd_error, a_error)\n",
    "plt.title('CDF of error between predicted and ground truth SINR')\n",
    "plt.xlabel('SINRS(dB)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b089c9eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249d895c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8dd6cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
