{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa94cabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "#import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import random\n",
    "import pdb\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pickle\n",
    "import scipy.io\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import pandas as pd\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "from tqdm import tqdm\n",
    "import matplotlib.animation as animation\n",
    "import glob\n",
    "from natsort import natsorted\n",
    "from PIL import Image\n",
    "\n",
    "def create_gif(pth, time_ind):\n",
    "    #files = glob.glob(r\"./imgs/*.png\")\n",
    "    files = glob.glob(os.path.join(pth,'*.png'))\n",
    "    files = natsorted(files)\n",
    "    image_array = []\n",
    "    \n",
    "    def update(i):\n",
    "        im.set_array(image_array[i])\n",
    "        return im, \n",
    "    \n",
    "    for my_file in files:\n",
    "\n",
    "        image = Image.open(my_file)\n",
    "        image_array.append(image)\n",
    "    \n",
    "    # Create the figure and axes objects\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Set the initial image\n",
    "    im = ax.imshow(image_array[0], animated=True)\n",
    "    \n",
    "    animation_fig = animation.FuncAnimation(fig, update, frames=len(image_array), interval=100, blit=True,repeat_delay=10,)\n",
    "\n",
    "    # Show the animation\n",
    "    #plt.show()\n",
    "\n",
    "    #animation_fig.save(\"./imgs/animated_{}.gif\".format(time_ind))\n",
    "    animation_fig.save(os.path.join(pth,'animated_{}.gif').format(time_ind))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e43846d",
   "metadata": {},
   "source": [
    "### Adding gamma_0 value for SINR computation ####\n",
    "\n",
    "$\\gamma = \\frac{|h|_s^2P_t}{|h|_i^2P_t + N_0B}$\n",
    "\n",
    "Assuming power transmitted power is same from all BSs then we have \n",
    "\n",
    "$\\gamma = \\frac{|h|_s^2}{|h|_i^2 + \\frac{1}{\\gamma_0}}$\n",
    "\n",
    "\n",
    "where $\\gamma_0 = P_t/N_0B$, you can assume P_t = 10 dBm, and the below calculations for $N_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dc46e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise_spectral_density_dBm -173.97722915699805\n",
      "thermal_noise_power(dBm) -103.97722915699808\n",
      "1/gamma_0 4.001999999999999e-12\n"
     ]
    }
   ],
   "source": [
    "## transmit power ###\n",
    "Pt_dBm = 10  # Transmit power in dBm\n",
    "\n",
    "#### Noise power ####\n",
    "k = 1.38e-23  # Boltzmann's constant\n",
    "T = 290       # Temperature in Kelvin\n",
    "B = 10e6       # Bandwidth in Hz\n",
    "\n",
    "# Calculate noise spectral density in Watts/Hz\n",
    "Noise_spectral_density = k * T\n",
    "\n",
    "# Convert noise spectral density to dBm/Hz\n",
    "# Convert to Watts first then to dBm (1 mW = 0.001 W)\n",
    "Noise_spectral_density_W = Noise_spectral_density * 1000  # Convert to mW\n",
    "Noise_spectral_density_dBm = 10 * np.log10(Noise_spectral_density_W)\n",
    "print('Noise_spectral_density_dBm', Noise_spectral_density_dBm)\n",
    "\n",
    "# Calculate total noise power in Watts then convert to dBm\n",
    "N_thermal = Noise_spectral_density * B  # Total noise power in Watts\n",
    "N_thermal_dBm = 10 * np.log10(N_thermal * 1000)  # Convert noise power to dBm\n",
    "print('thermal_noise_power(dBm)', N_thermal_dBm)\n",
    "\n",
    "##### gamma_0 in dB ############\n",
    "gamma_0_dB = Pt_dBm - N_thermal_dBm  # Calculate SNR in dB\n",
    "#print('gamma_0 (dB)', gamma_0_dB)\n",
    "\n",
    "##### gamma_0 ######\n",
    "gamma_0 = np.power(10, gamma_0_dB/10)\n",
    "print('1/gamma_0', 1/gamma_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b76f51e",
   "metadata": {},
   "source": [
    "### \n",
    "CDF of SINR computed for F($\\gamma$), for different channel realizations,\n",
    "below is when the the device is at a mean distance of 1m from the serving BS with a standard deviation of 0.1 m, and mean distance from the interfering BS at 4 meters with std of 0.1m "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a7ae1d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def return_cdf(a):\n",
    "    sorted_a = np.sort(a)\n",
    "    cdf = np.arange(1, len(sorted_a) + 1) / len(sorted_a)\n",
    "    return sorted_a, cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "471a7686",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Creating distances intra and inter ########\n",
    "M = 5 # number of sub-networks \n",
    "Ts = 10000 # number of time slots\n",
    "J = 5 # number of devices\n",
    "f_c = 1.3 #GHz\n",
    "N = 30\n",
    "TxRxds = np.zeros((Ts, M, M*J))\n",
    "d_intra = np.abs(np.random.normal(0.5,0.1,M*J))\n",
    "d_intra = np.reshape(d_intra, (M,J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3a24ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 9999/9999 [00:00<00:00, 14849.60it/s]\n"
     ]
    }
   ],
   "source": [
    "def generate_random_point(grid_size):\n",
    "    return np.random.uniform(0, grid_size, 2)\n",
    "\n",
    "def generate_random_velocity():\n",
    "    angle = np.random.uniform(0, 2 * np.pi)\n",
    "    velocity = 11.11  # 40 km/h in m/s\n",
    "    return np.array([velocity * np.cos(angle), velocity * np.sin(angle)])\n",
    "\n",
    "def is_within_grid(point, grid_size):\n",
    "    return all(0 <= coord <= grid_size for coord in point)\n",
    "\n",
    "def handle_boundary_collisions(point, grid_size):\n",
    "    angle = np.random.uniform(0, 2 * np.pi)\n",
    "    velocity = 11.11\n",
    "    if point[0] <= 0 or point[0] >= grid_size:\n",
    "        angle = np.pi - angle if point[0] <= 0 else -angle\n",
    "    if point[1] <= 0 or point[1] >= grid_size:\n",
    "        angle = -np.pi / 2 - angle if point[1] <= 0 else np.pi / 2 - angle\n",
    "    return np.array([velocity * np.cos(angle), velocity * np.sin(angle)])\n",
    "\n",
    "def handle_ap_collisions(points, velocities, min_distance):\n",
    "    for i in range(len(points)):\n",
    "        for j in range(i + 1, len(points)):\n",
    "            if np.linalg.norm(points[i] - points[j]) < min_distance:\n",
    "                # Adjust direction randomly for both APs\n",
    "                velocities[i] = generate_random_velocity()\n",
    "                velocities[j] = generate_random_velocity()\n",
    "    return velocities\n",
    "\n",
    "def update_positions(points, velocities, tau, grid_size, min_distance):\n",
    "    new_points = points + velocities * tau\n",
    "    for i, point in enumerate(new_points):\n",
    "        if not is_within_grid(point, grid_size):\n",
    "            velocities[i] = handle_boundary_collisions(point, grid_size)\n",
    "        new_points[i] = points[i] + velocities[i] * tau  # Recalculate with new velocity\n",
    "    velocities = handle_ap_collisions(new_points, velocities, min_distance)\n",
    "    return new_points, velocities\n",
    "\n",
    "# Initialize parameters\n",
    "grid_size = 20\n",
    "num_points = M\n",
    "min_distance = 2\n",
    "tau = 0.01  # time interval in seconds\n",
    "\n",
    "# Initialize points and velocities\n",
    "points = np.array([generate_random_point(grid_size) for _ in range(num_points)])\n",
    "velocities = np.array([generate_random_velocity() for _ in range(num_points)])\n",
    "init_cents = points\n",
    "# Simulation loop for 20 time steps\n",
    "pth = r'C:\\Users\\sriniva3\\OneDrive - Aalto University\\Simulations\\RL framework URLLC\\RL framework_V2.0_DDPG\\imgs'\n",
    "#Ts = 1000\n",
    "sub_net_cents = np.zeros((Ts+1, num_points, 2))\n",
    "sub_net_cents[0] = init_cents\n",
    "for step in tqdm(range(Ts-1)):\n",
    "    points, velocities = update_positions(points, velocities, tau, grid_size, min_distance)\n",
    "    sub_net_cents[step+1] = points\n",
    "    '''\n",
    "    # Plotting for visualization\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.scatter(points[:, 0], points[:, 1], c='red', label=f'Time Step {step+1}')\n",
    "    plt.xlim(0, grid_size)\n",
    "    plt.ylim(0, grid_size)\n",
    "    plt.grid(True)\n",
    "    plt.title(f'Access Points at Step {step+1}')\n",
    "    plt.xlabel('Meters')\n",
    "    plt.ylabel('Meters')\n",
    "    #plt.legend()\n",
    "    plt.savefig(os.path.join(pth, '{}.png'.format(step)))\n",
    "    plt.close()\n",
    "    #plt.show()\n",
    "    ''';\n",
    "#create_gif(pth, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f571f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_relative_locs = {}\n",
    "for i in range(M):\n",
    "    d_angle = np.random.uniform(0,2*np.pi,J) \n",
    "    d_r = np.random.uniform(0, 1, J)\n",
    "    d_relative_locs[i] = np.vstack([d_r*np.cos(d_angle), d_r*np.sin(d_angle)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cc676f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_euclid_dist(device_x_coord, device_y_coord, AP_x_coord, AP_y_coord):\n",
    "    device_coords = np.array([device_x_coord, device_y_coord])\n",
    "    AP_coords = np.array([AP_x_coord, AP_y_coord])\n",
    "    return np.linalg.norm(device_coords - AP_coords)\n",
    "\n",
    "x_coords_ts, y_coords_ts = {}, {}\n",
    "for ts in range(Ts):\n",
    "    coords = sub_net_cents[ts]\n",
    "    point_xs, point_ys = [], []\n",
    "    for k in d_relative_locs.keys():\n",
    "        point_x = d_relative_locs[k][0] + coords[k][0]\n",
    "        point_y = d_relative_locs[k][1] + coords[k][1]\n",
    "        #print(point_x, point_y)\n",
    "        point_xs.append(point_x)\n",
    "        point_ys.append(point_y)\n",
    "    #break    \n",
    "    x_coords_ts[ts] = point_xs\n",
    "    y_coords_ts[ts] = point_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e05a3ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TxRxds = np.zeros((Ts, M, M*J))\n",
    "for ts in range(Ts):\n",
    "    device_x_coords, device_y_coords = np.array(x_coords_ts[ts]), np.array(y_coords_ts[ts])\n",
    "    device_x_coords, device_y_coords = device_x_coords.flatten(), device_y_coords.flatten()\n",
    "    AP_x_coords, AP_y_coords = sub_net_cents[ts][:,0], sub_net_cents[ts][:,1]\n",
    "    \n",
    "    #for dx in device_x_coords \n",
    "    dists = np.zeros((M,M*J))\n",
    "    for i in range(AP_x_coords.shape[0]):\n",
    "        dist = []\n",
    "        for j in range(len(device_x_coords.flatten())):\n",
    "            #dist = []\n",
    "            #print(i,j)\n",
    "            dist.append(return_euclid_dist(device_x_coords[j], device_y_coords[j], AP_x_coords[i], AP_y_coords[i]))\n",
    "            #print(dist)\n",
    "        dists[i] = np.array(dist)\n",
    "    TxRxds[ts] = dists\n",
    "    #break\n",
    "\n",
    "#dist = return_euclid_dist(x_coords_ts[0], y_coords_ts[0], AP_x_coord, AP_y_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfd07bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([293508., 123284., 151740., 179284., 172980., 145072.,  85414.,\n",
       "         59402.,  31832.,   7484.]),\n",
       " array([5.04843017e-03, 3.14209328e+00, 6.27913814e+00, 9.41618299e+00,\n",
       "        1.25532278e+01, 1.56902727e+01, 1.88273176e+01, 2.19643624e+01,\n",
       "        2.51014073e+01, 2.82384521e+01, 3.13754970e+01]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(TxRxds.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa0ed303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5, 25)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TxRxds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16618737",
   "metadata": {},
   "source": [
    "### Using Jakes model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4647ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [07:31<00:00,  6.65it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def return_jakes_coeffcients(fd_max, TimeVaris, n_links = 5, plot = True):\n",
    "    ff_gains, TimeSequences = [], []\n",
    "    rays = 100\n",
    "    for i in tqdm(range(n_links)):    \n",
    "        #TimeVaris = np.arange(0,50,0.0005)\n",
    "        #TimeVaris = np.arange(0,.2,0.005)\n",
    "        frequs = np.sort(np.array([np.round(fd_max*np.cos(2*np.pi*np.random.uniform(0,1))) for _ in range(rays)]))\n",
    "        phases = np.array([np.exp(1j*2*np.pi*np.random.uniform(0,1)) for _ in range(rays)])\n",
    "\n",
    "        TimeSequence = []\n",
    "        for t in TimeVaris:\n",
    "            tab = np.exp(1j*2*np.pi*frequs*t)\n",
    "            tabrot = tab*phases\n",
    "            fun = np.sum(tabrot)\n",
    "            TimeSequence.append(fun)\n",
    "        TimeSequence = np.array(TimeSequence)\n",
    "\n",
    "        #TimeSequence = TimeSequence/np.linalg.norm(TimeSequence)*np.sqrt(len(TimeSequence))\n",
    "        PowerSequence1 =  np.abs(TimeSequence)**2;\n",
    "        #plt.plot(TimeVaris[0:200], 10*np.log10(PowerSequence1)[0:200])\n",
    "        ff_gains.append(PowerSequence1)\n",
    "        TimeSequences.append(TimeSequence)\n",
    "    ff_gains = np.array(ff_gains)/rays\n",
    "    TimeSequences = np.array(TimeSequences)\n",
    "    if plot:\n",
    "        plt.plot(TimeVaris[0:200], 10*np.log10(ff_gains[0])[0:200])\n",
    "        plt.show()\n",
    "    return ff_gains, TimeSequences\n",
    "\n",
    "v = 40 #kmph \n",
    "v_ms = v*5/18\n",
    "c = 3*1e8\n",
    "tau = .01\n",
    "fd_max = v_ms*f_c*1e9/c\n",
    "TimeVaris = np.arange(0,5,0.0005)\n",
    "\n",
    "ff_gains, TimeSequences = return_jakes_coeffcients(fd_max, TimeVaris, n_links = M*(M-1)*J*N, plot = False)\n",
    "#plt.plot(TimeVaris[0:Ts], 10*np.log10(ff_gains.flatten()[0:Ts]))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc5f6e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save( 'ff_gains_3000.npy',ff_gains)\n",
    "#ff_gains = np.load('ff_gains_3000.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f53e824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############ fast fading coeffecients ########\n",
    "\n",
    "FastFadingChannels = np.random.normal(0,1/np.sqrt(2), M*J*N) + 1j*np.random.normal(0,1/np.sqrt(2), M*J*N)\n",
    "FastFadingChannels = np.reshape(FastFadingChannels,(M,J,N))\n",
    "FadingGains = np.abs(FastFadingChannels)**2\n",
    "#all_SINRsdB, all_MeansPerSubNW, all_DiffsFromMean = np.zeros((Ts, M*J)), np.zeros((Ts, M)), np.zeros((Ts, M*J))\n",
    "all_SINRsdB = np.zeros((Ts, M,J,N))\n",
    "alltime_WantedSigPerDev, alltime_InterfPowsPerDev = [], []\n",
    "for ts in range(Ts):\n",
    "    \n",
    "\n",
    "    #FadingGains.shape\n",
    "\n",
    "    all_fast_fading_gains = np.zeros((M,M*J,N))\n",
    "    for m in range(M):\n",
    "        jakes_coeffs = ff_gains[:,ts]\n",
    "        jakes_coeffs = np.reshape(jakes_coeffs,(M,(M-1)*J,N))\n",
    "        all_fast_fading_gains[m] = np.concatenate([FadingGains[m], jakes_coeffs[m]])\n",
    "    all_fast_fading_gains = np.array(all_fast_fading_gains)\n",
    "    \n",
    "    PL_los = 31.84 +21.5*np.log10(TxRxds[ts]) + 19*np.log10(f_c)\n",
    "    PL = 33+25.5*np.log10(TxRxds[ts])+20*np.log10(f_c)\n",
    "    PL_nlos = np.max((PL_los, PL), axis = 0)\n",
    "    PathGains = np.power(10, -PL_nlos/10)\n",
    "    PathGains = np.repeat(PathGains[:, :, np.newaxis], N, axis=2)\n",
    "\n",
    "    ##### Compute total path gains ########\n",
    "    #pdb.set_trace()\n",
    "    PathGainsTot = PathGains*all_fast_fading_gains\n",
    "\n",
    "    #### Compute WantedSigPerDev ######\n",
    "    WantedSigPerDev = np.zeros((M,J,N))\n",
    "    for m in range(M):\n",
    "        WantedSigPerDev[m] = PathGainsTot[m,m*J:(m+1)*J]\n",
    "    alltime_WantedSigPerDev.append(WantedSigPerDev)\n",
    "    InterfPowsPerDev = np.zeros((M,J,N))\n",
    "    for m in range(M):\n",
    "        Interferers = [i for i in range(M) if i!=m]\n",
    "        Devs = np.arange(m*J,(m+1)*J)\n",
    "        #print(Interferers, Devs)\n",
    "        InterfPowGains = PathGainsTot[np.ix_(Interferers, Devs)]\n",
    "        InterfPowsPerDev[m,] = np.sum(InterfPowGains, axis = 0)\n",
    "    alltime_InterfPowsPerDev.append(InterfPowsPerDev)\n",
    "    SINRs = WantedSigPerDev/(InterfPowsPerDev + 1/gamma_0);\n",
    "    SINRsdB = 10*np.log10(SINRs)\n",
    "    all_SINRsdB[ts,:] = SINRsdB\n",
    "alltime_WantedSigPerDev = np.array(alltime_WantedSigPerDev)\n",
    "alltime_InterfPowsPerDev = np.array(alltime_InterfPowsPerDev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a13dd931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 30)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WantedSigPerDev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a65cdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.342561560833843\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a1, cdf1 = return_cdf(all_SINRsdB.flatten())\n",
    "plt.figure(figsize= [5,3])\n",
    "#plt.ylim(np.min(cdf2))\n",
    "plt.semilogy(a1, cdf1, label = r'$F(\\gamma)$')\n",
    "plt.grid()\n",
    "plt.xlabel('SINR(dB)')\n",
    "plt.ylabel('CDF(log scale)')\n",
    "plt.legend()\n",
    "print(np.mean(all_SINRsdB.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a82219d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 25, 30)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PathGainsTot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b0a0fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5, 30)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InterfPowGains.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "751dbc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.932242208035754\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alltime_SINRsdB_combined = []\n",
    "all_SINRslin = np.power(10, all_SINRsdB/10)\n",
    "for ts in range(all_SINRsdB.shape[0]):\n",
    "    vals = all_SINRslin[ts,:,:,:]\n",
    "    SINRS_combined = np.min(vals, axis = 2)\n",
    "    SINRsdB_combined = 10*np.log10(SINRS_combined)\n",
    "    alltime_SINRsdB_combined.append(SINRsdB_combined)\n",
    "alltime_SINRsdB_combined = np.array(alltime_SINRsdB_combined)\n",
    "\n",
    "a1, cdf1 = return_cdf(alltime_SINRsdB_combined.flatten())\n",
    "plt.figure(figsize= [5,3])\n",
    "#plt.ylim(np.min(cdf2))\n",
    "plt.semilogy(a1, cdf1, label = r'$F(\\gamma)$')\n",
    "plt.grid()\n",
    "plt.xlabel('SINR(dB)')\n",
    "plt.ylabel('CDF(log scale)')\n",
    "plt.legend()\n",
    "print(np.mean(alltime_SINRsdB_combined.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92cc0e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5, 5, 30)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_SINRsdB.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c839a4bf",
   "metadata": {},
   "source": [
    "### The below model needs to be integrated with DRL framework trained paralelly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d4e4a",
   "metadata": {},
   "source": [
    "##### prediction of SINR at t given 10 previous time slots #########\n",
    "####### 10000 x 5x 5 x 30, 10000 is time slots, first 5 denotes the sub networks, 2nd 5 denotes the devices of a sub network, \n",
    "####### 30 denotes the channel resources. \n",
    "\n",
    "\n",
    "#### preparing data for a sub-network ########\n",
    "######## each sub-network will have one LSTM layer getting trained in parallel with the main DRL agent ########\n",
    "######### i.e., the LSTM layer is trained for a given example with a loss function and predicted SINR is given as the \n",
    "######### input to the DRL framework which is subsequently trained. This happens in an online fashion at every time-slot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa366cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## data for a sub-network \n",
    "lag = 10\n",
    "inp_data, out_data = [], []\n",
    "for i in range(M):\n",
    "    sinr_sub_nw = all_SINRsdB[:,0,:,:]\n",
    "    data_per_device = sinr_sub_nw[:,0,:]\n",
    "    for t in range(0, len(data_per_device)-lag):\n",
    "        inp_data.append(data_per_device[t:t+lag])\n",
    "        out_data.append(data_per_device[t+lag])\n",
    "\n",
    "    \n",
    "inp_data = np.array(inp_data)\n",
    "out_data = np.array(out_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cea5d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        \n",
    "        # Define the output layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        \n",
    "        # Initialize cell state with zeros\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93b6760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_no =47000\n",
    "inp_train_data = inp_data[0:samp_no]\n",
    "out_train_data = out_data[0:samp_no]\n",
    "inp_test_data = inp_data[samp_no:]\n",
    "out_test_data = out_data[samp_no:]\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "inp_train_data = torch.tensor(inp_train_data, dtype=torch.float32)\n",
    "out_train_data = torch.tensor(out_train_data, dtype=torch.float32)\n",
    "inp_test_data = torch.tensor(inp_test_data, dtype=torch.float32)\n",
    "out_test_data = torch.tensor(out_test_data, dtype=torch.float32)\n",
    "\n",
    "\n",
    "inp_test_data \n",
    "# Create a dataset and dataloader\n",
    "train_dataset = TensorDataset(inp_train_data, out_train_data)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "569dbfe4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [1/735], Loss: 326.6364\n",
      "Epoch [1/50], Step [2/735], Loss: 378.9938\n",
      "Epoch [1/50], Step [3/735], Loss: 324.7120\n",
      "Epoch [1/50], Step [4/735], Loss: 347.9648\n",
      "Epoch [1/50], Step [5/735], Loss: 364.8281\n",
      "Epoch [1/50], Step [6/735], Loss: 353.8886\n",
      "Epoch [1/50], Step [7/735], Loss: 386.9536\n",
      "Epoch [1/50], Step [8/735], Loss: 287.2282\n",
      "Epoch [1/50], Step [9/735], Loss: 316.9350\n",
      "Epoch [1/50], Step [10/735], Loss: 343.9369\n",
      "Epoch [1/50], Step [11/735], Loss: 336.2985\n",
      "Epoch [1/50], Step [12/735], Loss: 322.2376\n",
      "Epoch [1/50], Step [13/735], Loss: 315.9123\n",
      "Epoch [1/50], Step [14/735], Loss: 303.5144\n",
      "Epoch [1/50], Step [15/735], Loss: 310.5087\n",
      "Epoch [1/50], Step [16/735], Loss: 336.7853\n",
      "Epoch [1/50], Step [17/735], Loss: 339.2222\n",
      "Epoch [1/50], Step [18/735], Loss: 310.3443\n",
      "Epoch [1/50], Step [19/735], Loss: 298.8839\n",
      "Epoch [1/50], Step [20/735], Loss: 331.2439\n",
      "Epoch [1/50], Step [21/735], Loss: 314.6675\n",
      "Epoch [1/50], Step [22/735], Loss: 299.6485\n",
      "Epoch [1/50], Step [23/735], Loss: 299.7293\n",
      "Epoch [1/50], Step [24/735], Loss: 287.1534\n",
      "Epoch [1/50], Step [25/735], Loss: 295.9976\n",
      "Epoch [1/50], Step [26/735], Loss: 283.0475\n",
      "Epoch [1/50], Step [27/735], Loss: 236.9957\n",
      "Epoch [1/50], Step [28/735], Loss: 270.9458\n",
      "Epoch [1/50], Step [29/735], Loss: 266.7135\n",
      "Epoch [1/50], Step [30/735], Loss: 220.2708\n",
      "Epoch [1/50], Step [31/735], Loss: 271.1499\n",
      "Epoch [1/50], Step [32/735], Loss: 241.4145\n",
      "Epoch [1/50], Step [33/735], Loss: 270.1422\n",
      "Epoch [1/50], Step [34/735], Loss: 253.8677\n",
      "Epoch [1/50], Step [35/735], Loss: 244.9500\n",
      "Epoch [1/50], Step [36/735], Loss: 267.1815\n",
      "Epoch [1/50], Step [37/735], Loss: 246.2938\n",
      "Epoch [1/50], Step [38/735], Loss: 268.5728\n",
      "Epoch [1/50], Step [39/735], Loss: 279.0756\n",
      "Epoch [1/50], Step [40/735], Loss: 244.8045\n",
      "Epoch [1/50], Step [41/735], Loss: 236.9736\n",
      "Epoch [1/50], Step [42/735], Loss: 224.4891\n",
      "Epoch [1/50], Step [43/735], Loss: 250.9787\n",
      "Epoch [1/50], Step [44/735], Loss: 223.6750\n",
      "Epoch [1/50], Step [45/735], Loss: 202.4775\n",
      "Epoch [1/50], Step [46/735], Loss: 186.1201\n",
      "Epoch [1/50], Step [47/735], Loss: 180.6951\n",
      "Epoch [1/50], Step [48/735], Loss: 239.1667\n",
      "Epoch [1/50], Step [49/735], Loss: 202.2854\n",
      "Epoch [1/50], Step [50/735], Loss: 204.5144\n",
      "Epoch [1/50], Step [51/735], Loss: 198.2229\n",
      "Epoch [1/50], Step [52/735], Loss: 205.9144\n",
      "Epoch [1/50], Step [53/735], Loss: 191.3283\n",
      "Epoch [1/50], Step [54/735], Loss: 187.1917\n",
      "Epoch [1/50], Step [55/735], Loss: 193.6445\n",
      "Epoch [1/50], Step [56/735], Loss: 163.0753\n",
      "Epoch [1/50], Step [57/735], Loss: 149.8979\n",
      "Epoch [1/50], Step [58/735], Loss: 189.8586\n",
      "Epoch [1/50], Step [59/735], Loss: 198.5928\n",
      "Epoch [1/50], Step [60/735], Loss: 205.8786\n",
      "Epoch [1/50], Step [61/735], Loss: 197.2675\n",
      "Epoch [1/50], Step [62/735], Loss: 174.0497\n",
      "Epoch [1/50], Step [63/735], Loss: 160.9422\n",
      "Epoch [1/50], Step [64/735], Loss: 199.0296\n",
      "Epoch [1/50], Step [65/735], Loss: 193.3460\n",
      "Epoch [1/50], Step [66/735], Loss: 147.1140\n",
      "Epoch [1/50], Step [67/735], Loss: 167.1567\n",
      "Epoch [1/50], Step [68/735], Loss: 165.1729\n",
      "Epoch [1/50], Step [69/735], Loss: 161.4072\n",
      "Epoch [1/50], Step [70/735], Loss: 151.7705\n",
      "Epoch [1/50], Step [71/735], Loss: 169.9588\n",
      "Epoch [1/50], Step [72/735], Loss: 161.7148\n",
      "Epoch [1/50], Step [73/735], Loss: 145.4731\n",
      "Epoch [1/50], Step [74/735], Loss: 131.9143\n",
      "Epoch [1/50], Step [75/735], Loss: 147.8313\n",
      "Epoch [1/50], Step [76/735], Loss: 145.0652\n",
      "Epoch [1/50], Step [77/735], Loss: 139.4869\n",
      "Epoch [1/50], Step [78/735], Loss: 158.2749\n",
      "Epoch [1/50], Step [79/735], Loss: 126.2147\n",
      "Epoch [1/50], Step [80/735], Loss: 129.6867\n",
      "Epoch [1/50], Step [81/735], Loss: 127.5876\n",
      "Epoch [1/50], Step [82/735], Loss: 141.2730\n",
      "Epoch [1/50], Step [83/735], Loss: 121.3889\n",
      "Epoch [1/50], Step [84/735], Loss: 133.9656\n",
      "Epoch [1/50], Step [85/735], Loss: 118.0340\n",
      "Epoch [1/50], Step [86/735], Loss: 116.9189\n",
      "Epoch [1/50], Step [87/735], Loss: 125.7864\n",
      "Epoch [1/50], Step [88/735], Loss: 118.8141\n",
      "Epoch [1/50], Step [89/735], Loss: 117.6855\n",
      "Epoch [1/50], Step [90/735], Loss: 122.0560\n",
      "Epoch [1/50], Step [91/735], Loss: 110.0000\n",
      "Epoch [1/50], Step [92/735], Loss: 111.9289\n",
      "Epoch [1/50], Step [93/735], Loss: 102.7860\n",
      "Epoch [1/50], Step [94/735], Loss: 105.3950\n",
      "Epoch [1/50], Step [95/735], Loss: 113.2205\n",
      "Epoch [1/50], Step [96/735], Loss: 93.7430\n",
      "Epoch [1/50], Step [97/735], Loss: 95.1521\n",
      "Epoch [1/50], Step [98/735], Loss: 105.6138\n",
      "Epoch [1/50], Step [99/735], Loss: 91.4422\n",
      "Epoch [1/50], Step [100/735], Loss: 107.6442\n",
      "Epoch [1/50], Step [101/735], Loss: 95.6418\n",
      "Epoch [1/50], Step [102/735], Loss: 84.6383\n",
      "Epoch [1/50], Step [103/735], Loss: 98.2773\n",
      "Epoch [1/50], Step [104/735], Loss: 81.6060\n",
      "Epoch [1/50], Step [105/735], Loss: 82.2761\n",
      "Epoch [1/50], Step [106/735], Loss: 87.7134\n",
      "Epoch [1/50], Step [107/735], Loss: 89.4467\n",
      "Epoch [1/50], Step [108/735], Loss: 79.6373\n",
      "Epoch [1/50], Step [109/735], Loss: 65.6899\n",
      "Epoch [1/50], Step [110/735], Loss: 82.8354\n",
      "Epoch [1/50], Step [111/735], Loss: 87.9373\n",
      "Epoch [1/50], Step [112/735], Loss: 89.6225\n",
      "Epoch [1/50], Step [113/735], Loss: 77.6218\n",
      "Epoch [1/50], Step [114/735], Loss: 73.7097\n",
      "Epoch [1/50], Step [115/735], Loss: 73.2364\n",
      "Epoch [1/50], Step [116/735], Loss: 67.6298\n",
      "Epoch [1/50], Step [117/735], Loss: 69.5389\n",
      "Epoch [1/50], Step [118/735], Loss: 79.7001\n",
      "Epoch [1/50], Step [119/735], Loss: 78.7760\n",
      "Epoch [1/50], Step [120/735], Loss: 82.6984\n",
      "Epoch [1/50], Step [121/735], Loss: 83.1086\n",
      "Epoch [1/50], Step [122/735], Loss: 68.9077\n",
      "Epoch [1/50], Step [123/735], Loss: 70.3555\n",
      "Epoch [1/50], Step [124/735], Loss: 73.0034\n",
      "Epoch [1/50], Step [125/735], Loss: 66.4694\n",
      "Epoch [1/50], Step [126/735], Loss: 59.9602\n",
      "Epoch [1/50], Step [127/735], Loss: 60.4344\n",
      "Epoch [1/50], Step [128/735], Loss: 61.5060\n",
      "Epoch [1/50], Step [129/735], Loss: 66.4495\n",
      "Epoch [1/50], Step [130/735], Loss: 60.5479\n",
      "Epoch [1/50], Step [131/735], Loss: 61.6694\n",
      "Epoch [1/50], Step [132/735], Loss: 60.9446\n",
      "Epoch [1/50], Step [133/735], Loss: 73.0133\n",
      "Epoch [1/50], Step [134/735], Loss: 55.2356\n",
      "Epoch [1/50], Step [135/735], Loss: 61.8322\n",
      "Epoch [1/50], Step [136/735], Loss: 55.6599\n",
      "Epoch [1/50], Step [137/735], Loss: 56.6092\n",
      "Epoch [1/50], Step [138/735], Loss: 53.7839\n",
      "Epoch [1/50], Step [139/735], Loss: 63.6225\n",
      "Epoch [1/50], Step [140/735], Loss: 55.5684\n",
      "Epoch [1/50], Step [141/735], Loss: 54.7643\n",
      "Epoch [1/50], Step [142/735], Loss: 55.4954\n",
      "Epoch [1/50], Step [143/735], Loss: 60.8542\n",
      "Epoch [1/50], Step [144/735], Loss: 46.0839\n",
      "Epoch [1/50], Step [145/735], Loss: 47.1760\n",
      "Epoch [1/50], Step [146/735], Loss: 48.3771\n",
      "Epoch [1/50], Step [147/735], Loss: 42.3999\n",
      "Epoch [1/50], Step [148/735], Loss: 47.1621\n",
      "Epoch [1/50], Step [149/735], Loss: 50.7829\n",
      "Epoch [1/50], Step [150/735], Loss: 46.3906\n",
      "Epoch [1/50], Step [151/735], Loss: 55.0794\n",
      "Epoch [1/50], Step [152/735], Loss: 44.7399\n",
      "Epoch [1/50], Step [153/735], Loss: 48.7087\n",
      "Epoch [1/50], Step [154/735], Loss: 48.8849\n",
      "Epoch [1/50], Step [155/735], Loss: 40.1467\n",
      "Epoch [1/50], Step [156/735], Loss: 47.3480\n",
      "Epoch [1/50], Step [157/735], Loss: 40.2130\n",
      "Epoch [1/50], Step [158/735], Loss: 42.9891\n",
      "Epoch [1/50], Step [159/735], Loss: 36.0708\n",
      "Epoch [1/50], Step [160/735], Loss: 34.5780\n",
      "Epoch [1/50], Step [161/735], Loss: 41.6482\n",
      "Epoch [1/50], Step [162/735], Loss: 32.7775\n",
      "Epoch [1/50], Step [163/735], Loss: 35.4999\n",
      "Epoch [1/50], Step [164/735], Loss: 35.4631\n",
      "Epoch [1/50], Step [165/735], Loss: 32.1336\n",
      "Epoch [1/50], Step [166/735], Loss: 37.7348\n",
      "Epoch [1/50], Step [167/735], Loss: 32.0171\n",
      "Epoch [1/50], Step [168/735], Loss: 33.4565\n",
      "Epoch [1/50], Step [169/735], Loss: 35.9299\n",
      "Epoch [1/50], Step [170/735], Loss: 30.2776\n",
      "Epoch [1/50], Step [171/735], Loss: 34.8110\n",
      "Epoch [1/50], Step [172/735], Loss: 34.0904\n",
      "Epoch [1/50], Step [173/735], Loss: 39.5168\n",
      "Epoch [1/50], Step [174/735], Loss: 24.5719\n",
      "Epoch [1/50], Step [175/735], Loss: 35.9776\n",
      "Epoch [1/50], Step [176/735], Loss: 30.5598\n",
      "Epoch [1/50], Step [177/735], Loss: 34.6194\n",
      "Epoch [1/50], Step [178/735], Loss: 36.6327\n",
      "Epoch [1/50], Step [179/735], Loss: 32.0587\n",
      "Epoch [1/50], Step [180/735], Loss: 30.1073\n",
      "Epoch [1/50], Step [181/735], Loss: 29.2648\n",
      "Epoch [1/50], Step [182/735], Loss: 31.0309\n",
      "Epoch [1/50], Step [183/735], Loss: 35.3823\n",
      "Epoch [1/50], Step [184/735], Loss: 26.2681\n",
      "Epoch [1/50], Step [185/735], Loss: 23.8449\n",
      "Epoch [1/50], Step [186/735], Loss: 29.0476\n",
      "Epoch [1/50], Step [187/735], Loss: 24.7067\n",
      "Epoch [1/50], Step [188/735], Loss: 22.4743\n",
      "Epoch [1/50], Step [189/735], Loss: 32.8297\n",
      "Epoch [1/50], Step [190/735], Loss: 24.3431\n",
      "Epoch [1/50], Step [191/735], Loss: 30.9494\n",
      "Epoch [1/50], Step [192/735], Loss: 24.9443\n",
      "Epoch [1/50], Step [193/735], Loss: 23.5504\n",
      "Epoch [1/50], Step [194/735], Loss: 25.0082\n",
      "Epoch [1/50], Step [195/735], Loss: 24.1362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [196/735], Loss: 22.7435\n",
      "Epoch [1/50], Step [197/735], Loss: 26.8000\n",
      "Epoch [1/50], Step [198/735], Loss: 23.2911\n",
      "Epoch [1/50], Step [199/735], Loss: 19.7886\n",
      "Epoch [1/50], Step [200/735], Loss: 23.7576\n",
      "Epoch [1/50], Step [201/735], Loss: 23.2205\n",
      "Epoch [1/50], Step [202/735], Loss: 18.8190\n",
      "Epoch [1/50], Step [203/735], Loss: 22.0590\n",
      "Epoch [1/50], Step [204/735], Loss: 21.3020\n",
      "Epoch [1/50], Step [205/735], Loss: 23.6653\n",
      "Epoch [1/50], Step [206/735], Loss: 21.3625\n",
      "Epoch [1/50], Step [207/735], Loss: 20.0246\n",
      "Epoch [1/50], Step [208/735], Loss: 19.9233\n",
      "Epoch [1/50], Step [209/735], Loss: 17.2262\n",
      "Epoch [1/50], Step [210/735], Loss: 19.4523\n",
      "Epoch [1/50], Step [211/735], Loss: 25.4883\n",
      "Epoch [1/50], Step [212/735], Loss: 23.3298\n",
      "Epoch [1/50], Step [213/735], Loss: 20.7251\n",
      "Epoch [1/50], Step [214/735], Loss: 18.4301\n",
      "Epoch [1/50], Step [215/735], Loss: 21.4694\n",
      "Epoch [1/50], Step [216/735], Loss: 20.6047\n",
      "Epoch [1/50], Step [217/735], Loss: 20.1227\n",
      "Epoch [1/50], Step [218/735], Loss: 21.9745\n",
      "Epoch [1/50], Step [219/735], Loss: 22.7514\n",
      "Epoch [1/50], Step [220/735], Loss: 20.0987\n",
      "Epoch [1/50], Step [221/735], Loss: 23.0526\n",
      "Epoch [1/50], Step [222/735], Loss: 23.0517\n",
      "Epoch [1/50], Step [223/735], Loss: 16.0303\n",
      "Epoch [1/50], Step [224/735], Loss: 19.2864\n",
      "Epoch [1/50], Step [225/735], Loss: 18.3367\n",
      "Epoch [1/50], Step [226/735], Loss: 19.0326\n",
      "Epoch [1/50], Step [227/735], Loss: 14.5556\n",
      "Epoch [1/50], Step [228/735], Loss: 18.4539\n",
      "Epoch [1/50], Step [229/735], Loss: 15.7256\n",
      "Epoch [1/50], Step [230/735], Loss: 16.6682\n",
      "Epoch [1/50], Step [231/735], Loss: 18.1219\n",
      "Epoch [1/50], Step [232/735], Loss: 18.2808\n",
      "Epoch [1/50], Step [233/735], Loss: 17.4793\n",
      "Epoch [1/50], Step [234/735], Loss: 17.4131\n",
      "Epoch [1/50], Step [235/735], Loss: 13.4945\n",
      "Epoch [1/50], Step [236/735], Loss: 19.9675\n",
      "Epoch [1/50], Step [237/735], Loss: 13.6382\n",
      "Epoch [1/50], Step [238/735], Loss: 14.3797\n",
      "Epoch [1/50], Step [239/735], Loss: 17.7459\n",
      "Epoch [1/50], Step [240/735], Loss: 18.5684\n",
      "Epoch [1/50], Step [241/735], Loss: 17.4209\n",
      "Epoch [1/50], Step [242/735], Loss: 18.6647\n",
      "Epoch [1/50], Step [243/735], Loss: 13.4291\n",
      "Epoch [1/50], Step [244/735], Loss: 17.1863\n",
      "Epoch [1/50], Step [245/735], Loss: 17.0404\n",
      "Epoch [1/50], Step [246/735], Loss: 13.2180\n",
      "Epoch [1/50], Step [247/735], Loss: 14.2124\n",
      "Epoch [1/50], Step [248/735], Loss: 13.8868\n",
      "Epoch [1/50], Step [249/735], Loss: 12.2396\n",
      "Epoch [1/50], Step [250/735], Loss: 13.5205\n",
      "Epoch [1/50], Step [251/735], Loss: 16.8724\n",
      "Epoch [1/50], Step [252/735], Loss: 12.6215\n",
      "Epoch [1/50], Step [253/735], Loss: 14.6903\n",
      "Epoch [1/50], Step [254/735], Loss: 15.8344\n",
      "Epoch [1/50], Step [255/735], Loss: 13.3523\n",
      "Epoch [1/50], Step [256/735], Loss: 15.4653\n",
      "Epoch [1/50], Step [257/735], Loss: 11.5747\n",
      "Epoch [1/50], Step [258/735], Loss: 14.9817\n",
      "Epoch [1/50], Step [259/735], Loss: 13.9578\n",
      "Epoch [1/50], Step [260/735], Loss: 11.8044\n",
      "Epoch [1/50], Step [261/735], Loss: 11.7640\n",
      "Epoch [1/50], Step [262/735], Loss: 14.0102\n",
      "Epoch [1/50], Step [263/735], Loss: 14.1654\n",
      "Epoch [1/50], Step [264/735], Loss: 13.8882\n",
      "Epoch [1/50], Step [265/735], Loss: 13.6768\n",
      "Epoch [1/50], Step [266/735], Loss: 13.3165\n",
      "Epoch [1/50], Step [267/735], Loss: 13.4544\n",
      "Epoch [1/50], Step [268/735], Loss: 14.3069\n",
      "Epoch [1/50], Step [269/735], Loss: 12.8753\n",
      "Epoch [1/50], Step [270/735], Loss: 13.3906\n",
      "Epoch [1/50], Step [271/735], Loss: 13.2962\n",
      "Epoch [1/50], Step [272/735], Loss: 12.7966\n",
      "Epoch [1/50], Step [273/735], Loss: 9.9297\n",
      "Epoch [1/50], Step [274/735], Loss: 12.5873\n",
      "Epoch [1/50], Step [275/735], Loss: 10.9770\n",
      "Epoch [1/50], Step [276/735], Loss: 12.6528\n",
      "Epoch [1/50], Step [277/735], Loss: 8.5789\n",
      "Epoch [1/50], Step [278/735], Loss: 11.0531\n",
      "Epoch [1/50], Step [279/735], Loss: 14.2009\n",
      "Epoch [1/50], Step [280/735], Loss: 10.9589\n",
      "Epoch [1/50], Step [281/735], Loss: 9.5052\n",
      "Epoch [1/50], Step [282/735], Loss: 11.1261\n",
      "Epoch [1/50], Step [283/735], Loss: 10.8886\n",
      "Epoch [1/50], Step [284/735], Loss: 12.2547\n",
      "Epoch [1/50], Step [285/735], Loss: 9.8917\n",
      "Epoch [1/50], Step [286/735], Loss: 11.4764\n",
      "Epoch [1/50], Step [287/735], Loss: 9.7789\n",
      "Epoch [1/50], Step [288/735], Loss: 10.9901\n",
      "Epoch [1/50], Step [289/735], Loss: 10.8323\n",
      "Epoch [1/50], Step [290/735], Loss: 8.1910\n",
      "Epoch [1/50], Step [291/735], Loss: 10.8502\n",
      "Epoch [1/50], Step [292/735], Loss: 10.3969\n",
      "Epoch [1/50], Step [293/735], Loss: 7.8270\n",
      "Epoch [1/50], Step [294/735], Loss: 11.7868\n",
      "Epoch [1/50], Step [295/735], Loss: 9.4636\n",
      "Epoch [1/50], Step [296/735], Loss: 8.5250\n",
      "Epoch [1/50], Step [297/735], Loss: 11.3329\n",
      "Epoch [1/50], Step [298/735], Loss: 9.6540\n",
      "Epoch [1/50], Step [299/735], Loss: 9.3100\n",
      "Epoch [1/50], Step [300/735], Loss: 9.5534\n",
      "Epoch [1/50], Step [301/735], Loss: 8.3954\n",
      "Epoch [1/50], Step [302/735], Loss: 10.8580\n",
      "Epoch [1/50], Step [303/735], Loss: 8.1001\n",
      "Epoch [1/50], Step [304/735], Loss: 8.2751\n",
      "Epoch [1/50], Step [305/735], Loss: 9.3376\n",
      "Epoch [1/50], Step [306/735], Loss: 11.8089\n",
      "Epoch [1/50], Step [307/735], Loss: 11.1481\n",
      "Epoch [1/50], Step [308/735], Loss: 7.6557\n",
      "Epoch [1/50], Step [309/735], Loss: 10.4553\n",
      "Epoch [1/50], Step [310/735], Loss: 8.1473\n",
      "Epoch [1/50], Step [311/735], Loss: 9.3900\n",
      "Epoch [1/50], Step [312/735], Loss: 10.1613\n",
      "Epoch [1/50], Step [313/735], Loss: 9.5567\n",
      "Epoch [1/50], Step [314/735], Loss: 14.5157\n",
      "Epoch [1/50], Step [315/735], Loss: 9.6337\n",
      "Epoch [1/50], Step [316/735], Loss: 8.4423\n",
      "Epoch [1/50], Step [317/735], Loss: 9.4420\n",
      "Epoch [1/50], Step [318/735], Loss: 9.0099\n",
      "Epoch [1/50], Step [319/735], Loss: 8.7441\n",
      "Epoch [1/50], Step [320/735], Loss: 8.9139\n",
      "Epoch [1/50], Step [321/735], Loss: 8.7913\n",
      "Epoch [1/50], Step [322/735], Loss: 8.7887\n",
      "Epoch [1/50], Step [323/735], Loss: 6.9067\n",
      "Epoch [1/50], Step [324/735], Loss: 9.0568\n",
      "Epoch [1/50], Step [325/735], Loss: 10.0158\n",
      "Epoch [1/50], Step [326/735], Loss: 7.5868\n",
      "Epoch [1/50], Step [327/735], Loss: 7.4323\n",
      "Epoch [1/50], Step [328/735], Loss: 9.3439\n",
      "Epoch [1/50], Step [329/735], Loss: 10.1733\n",
      "Epoch [1/50], Step [330/735], Loss: 7.6077\n",
      "Epoch [1/50], Step [331/735], Loss: 11.4288\n",
      "Epoch [1/50], Step [332/735], Loss: 7.6726\n",
      "Epoch [1/50], Step [333/735], Loss: 8.6610\n",
      "Epoch [1/50], Step [334/735], Loss: 7.2190\n",
      "Epoch [1/50], Step [335/735], Loss: 9.4145\n",
      "Epoch [1/50], Step [336/735], Loss: 6.6963\n",
      "Epoch [1/50], Step [337/735], Loss: 7.1305\n",
      "Epoch [1/50], Step [338/735], Loss: 10.0448\n",
      "Epoch [1/50], Step [339/735], Loss: 7.2893\n",
      "Epoch [1/50], Step [340/735], Loss: 8.4190\n",
      "Epoch [1/50], Step [341/735], Loss: 7.9758\n",
      "Epoch [1/50], Step [342/735], Loss: 7.7566\n",
      "Epoch [1/50], Step [343/735], Loss: 7.9766\n",
      "Epoch [1/50], Step [344/735], Loss: 9.2434\n",
      "Epoch [1/50], Step [345/735], Loss: 7.1495\n",
      "Epoch [1/50], Step [346/735], Loss: 7.2548\n",
      "Epoch [1/50], Step [347/735], Loss: 8.9506\n",
      "Epoch [1/50], Step [348/735], Loss: 9.8973\n",
      "Epoch [1/50], Step [349/735], Loss: 6.6540\n",
      "Epoch [1/50], Step [350/735], Loss: 7.7573\n",
      "Epoch [1/50], Step [351/735], Loss: 7.1273\n",
      "Epoch [1/50], Step [352/735], Loss: 7.9985\n",
      "Epoch [1/50], Step [353/735], Loss: 8.4730\n",
      "Epoch [1/50], Step [354/735], Loss: 7.7584\n",
      "Epoch [1/50], Step [355/735], Loss: 7.0001\n",
      "Epoch [1/50], Step [356/735], Loss: 7.9837\n",
      "Epoch [1/50], Step [357/735], Loss: 8.6748\n",
      "Epoch [1/50], Step [358/735], Loss: 6.3132\n",
      "Epoch [1/50], Step [359/735], Loss: 6.6684\n",
      "Epoch [1/50], Step [360/735], Loss: 8.5075\n",
      "Epoch [1/50], Step [361/735], Loss: 7.0956\n",
      "Epoch [1/50], Step [362/735], Loss: 6.3830\n",
      "Epoch [1/50], Step [363/735], Loss: 6.7402\n",
      "Epoch [1/50], Step [364/735], Loss: 6.3034\n",
      "Epoch [1/50], Step [365/735], Loss: 7.5723\n",
      "Epoch [1/50], Step [366/735], Loss: 6.5278\n",
      "Epoch [1/50], Step [367/735], Loss: 6.5546\n",
      "Epoch [1/50], Step [368/735], Loss: 7.1219\n",
      "Epoch [1/50], Step [369/735], Loss: 8.6783\n",
      "Epoch [1/50], Step [370/735], Loss: 5.8783\n",
      "Epoch [1/50], Step [371/735], Loss: 7.1246\n",
      "Epoch [1/50], Step [372/735], Loss: 6.9417\n",
      "Epoch [1/50], Step [373/735], Loss: 5.8135\n",
      "Epoch [1/50], Step [374/735], Loss: 5.9728\n",
      "Epoch [1/50], Step [375/735], Loss: 6.7407\n",
      "Epoch [1/50], Step [376/735], Loss: 8.6110\n",
      "Epoch [1/50], Step [377/735], Loss: 7.2740\n",
      "Epoch [1/50], Step [378/735], Loss: 7.8255\n",
      "Epoch [1/50], Step [379/735], Loss: 6.5741\n",
      "Epoch [1/50], Step [380/735], Loss: 7.1560\n",
      "Epoch [1/50], Step [381/735], Loss: 7.4673\n",
      "Epoch [1/50], Step [382/735], Loss: 6.7872\n",
      "Epoch [1/50], Step [383/735], Loss: 5.6254\n",
      "Epoch [1/50], Step [384/735], Loss: 6.2889\n",
      "Epoch [1/50], Step [385/735], Loss: 8.0979\n",
      "Epoch [1/50], Step [386/735], Loss: 7.3204\n",
      "Epoch [1/50], Step [387/735], Loss: 6.6423\n",
      "Epoch [1/50], Step [388/735], Loss: 5.9218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [389/735], Loss: 5.6677\n",
      "Epoch [1/50], Step [390/735], Loss: 6.1797\n",
      "Epoch [1/50], Step [391/735], Loss: 9.6281\n",
      "Epoch [1/50], Step [392/735], Loss: 5.4587\n",
      "Epoch [1/50], Step [393/735], Loss: 6.8294\n",
      "Epoch [1/50], Step [394/735], Loss: 5.3233\n",
      "Epoch [1/50], Step [395/735], Loss: 6.6903\n",
      "Epoch [1/50], Step [396/735], Loss: 6.3955\n",
      "Epoch [1/50], Step [397/735], Loss: 5.8919\n",
      "Epoch [1/50], Step [398/735], Loss: 5.6286\n",
      "Epoch [1/50], Step [399/735], Loss: 5.3904\n",
      "Epoch [1/50], Step [400/735], Loss: 5.4795\n",
      "Epoch [1/50], Step [401/735], Loss: 6.2306\n",
      "Epoch [1/50], Step [402/735], Loss: 6.2813\n",
      "Epoch [1/50], Step [403/735], Loss: 6.6159\n",
      "Epoch [1/50], Step [404/735], Loss: 7.1325\n",
      "Epoch [1/50], Step [405/735], Loss: 4.8130\n",
      "Epoch [1/50], Step [406/735], Loss: 6.8278\n",
      "Epoch [1/50], Step [407/735], Loss: 6.1347\n",
      "Epoch [1/50], Step [408/735], Loss: 5.6059\n",
      "Epoch [1/50], Step [409/735], Loss: 5.4468\n",
      "Epoch [1/50], Step [410/735], Loss: 6.0483\n",
      "Epoch [1/50], Step [411/735], Loss: 5.4209\n",
      "Epoch [1/50], Step [412/735], Loss: 6.6289\n",
      "Epoch [1/50], Step [413/735], Loss: 6.0956\n",
      "Epoch [1/50], Step [414/735], Loss: 7.6321\n",
      "Epoch [1/50], Step [415/735], Loss: 5.6057\n",
      "Epoch [1/50], Step [416/735], Loss: 7.6670\n",
      "Epoch [1/50], Step [417/735], Loss: 4.6549\n",
      "Epoch [1/50], Step [418/735], Loss: 5.8339\n",
      "Epoch [1/50], Step [419/735], Loss: 5.4994\n",
      "Epoch [1/50], Step [420/735], Loss: 6.0291\n",
      "Epoch [1/50], Step [421/735], Loss: 6.2519\n",
      "Epoch [1/50], Step [422/735], Loss: 4.9514\n",
      "Epoch [1/50], Step [423/735], Loss: 4.7788\n",
      "Epoch [1/50], Step [424/735], Loss: 5.2650\n",
      "Epoch [1/50], Step [425/735], Loss: 5.0533\n",
      "Epoch [1/50], Step [426/735], Loss: 6.1040\n",
      "Epoch [1/50], Step [427/735], Loss: 5.5864\n",
      "Epoch [1/50], Step [428/735], Loss: 6.0526\n",
      "Epoch [1/50], Step [429/735], Loss: 5.1381\n",
      "Epoch [1/50], Step [430/735], Loss: 6.4853\n",
      "Epoch [1/50], Step [431/735], Loss: 6.1828\n",
      "Epoch [1/50], Step [432/735], Loss: 5.7273\n",
      "Epoch [1/50], Step [433/735], Loss: 4.7849\n",
      "Epoch [1/50], Step [434/735], Loss: 6.3958\n",
      "Epoch [1/50], Step [435/735], Loss: 5.3678\n",
      "Epoch [1/50], Step [436/735], Loss: 6.0080\n",
      "Epoch [1/50], Step [437/735], Loss: 5.2474\n",
      "Epoch [1/50], Step [438/735], Loss: 5.2050\n",
      "Epoch [1/50], Step [439/735], Loss: 6.0368\n",
      "Epoch [1/50], Step [440/735], Loss: 4.8989\n",
      "Epoch [1/50], Step [441/735], Loss: 5.6902\n",
      "Epoch [1/50], Step [442/735], Loss: 4.1366\n",
      "Epoch [1/50], Step [443/735], Loss: 4.1388\n",
      "Epoch [1/50], Step [444/735], Loss: 4.8578\n",
      "Epoch [1/50], Step [445/735], Loss: 5.9749\n",
      "Epoch [1/50], Step [446/735], Loss: 4.2124\n",
      "Epoch [1/50], Step [447/735], Loss: 4.9267\n",
      "Epoch [1/50], Step [448/735], Loss: 5.4518\n",
      "Epoch [1/50], Step [449/735], Loss: 5.0930\n",
      "Epoch [1/50], Step [450/735], Loss: 4.2532\n",
      "Epoch [1/50], Step [451/735], Loss: 4.0330\n",
      "Epoch [1/50], Step [452/735], Loss: 6.0526\n",
      "Epoch [1/50], Step [453/735], Loss: 5.5950\n",
      "Epoch [1/50], Step [454/735], Loss: 4.8653\n",
      "Epoch [1/50], Step [455/735], Loss: 4.5682\n",
      "Epoch [1/50], Step [456/735], Loss: 6.7535\n",
      "Epoch [1/50], Step [457/735], Loss: 3.8453\n",
      "Epoch [1/50], Step [458/735], Loss: 4.9199\n",
      "Epoch [1/50], Step [459/735], Loss: 6.0195\n",
      "Epoch [1/50], Step [460/735], Loss: 5.5459\n",
      "Epoch [1/50], Step [461/735], Loss: 4.1220\n",
      "Epoch [1/50], Step [462/735], Loss: 4.0716\n",
      "Epoch [1/50], Step [463/735], Loss: 4.9410\n",
      "Epoch [1/50], Step [464/735], Loss: 4.2346\n",
      "Epoch [1/50], Step [465/735], Loss: 5.1539\n",
      "Epoch [1/50], Step [466/735], Loss: 4.4641\n",
      "Epoch [1/50], Step [467/735], Loss: 4.8256\n",
      "Epoch [1/50], Step [468/735], Loss: 4.6527\n",
      "Epoch [1/50], Step [469/735], Loss: 5.4582\n",
      "Epoch [1/50], Step [470/735], Loss: 4.3587\n",
      "Epoch [1/50], Step [471/735], Loss: 3.3161\n",
      "Epoch [1/50], Step [472/735], Loss: 3.9411\n",
      "Epoch [1/50], Step [473/735], Loss: 4.0801\n",
      "Epoch [1/50], Step [474/735], Loss: 5.3349\n",
      "Epoch [1/50], Step [475/735], Loss: 5.1640\n",
      "Epoch [1/50], Step [476/735], Loss: 4.2355\n",
      "Epoch [1/50], Step [477/735], Loss: 4.7292\n",
      "Epoch [1/50], Step [478/735], Loss: 3.7315\n",
      "Epoch [1/50], Step [479/735], Loss: 4.9739\n",
      "Epoch [1/50], Step [480/735], Loss: 3.9905\n",
      "Epoch [1/50], Step [481/735], Loss: 5.4429\n",
      "Epoch [1/50], Step [482/735], Loss: 4.5783\n",
      "Epoch [1/50], Step [483/735], Loss: 5.4269\n",
      "Epoch [1/50], Step [484/735], Loss: 4.3430\n",
      "Epoch [1/50], Step [485/735], Loss: 4.4739\n",
      "Epoch [1/50], Step [486/735], Loss: 3.8891\n",
      "Epoch [1/50], Step [487/735], Loss: 3.6229\n",
      "Epoch [1/50], Step [488/735], Loss: 4.2968\n",
      "Epoch [1/50], Step [489/735], Loss: 4.4821\n",
      "Epoch [1/50], Step [490/735], Loss: 4.8814\n",
      "Epoch [1/50], Step [491/735], Loss: 4.6477\n",
      "Epoch [1/50], Step [492/735], Loss: 3.9448\n",
      "Epoch [1/50], Step [493/735], Loss: 3.8936\n",
      "Epoch [1/50], Step [494/735], Loss: 4.2208\n",
      "Epoch [1/50], Step [495/735], Loss: 4.5390\n",
      "Epoch [1/50], Step [496/735], Loss: 5.9143\n",
      "Epoch [1/50], Step [497/735], Loss: 4.1581\n",
      "Epoch [1/50], Step [498/735], Loss: 5.2414\n",
      "Epoch [1/50], Step [499/735], Loss: 5.2576\n",
      "Epoch [1/50], Step [500/735], Loss: 3.7082\n",
      "Epoch [1/50], Step [501/735], Loss: 3.3167\n",
      "Epoch [1/50], Step [502/735], Loss: 3.4660\n",
      "Epoch [1/50], Step [503/735], Loss: 3.8530\n",
      "Epoch [1/50], Step [504/735], Loss: 3.9106\n",
      "Epoch [1/50], Step [505/735], Loss: 3.4982\n",
      "Epoch [1/50], Step [506/735], Loss: 3.6528\n",
      "Epoch [1/50], Step [507/735], Loss: 4.1581\n",
      "Epoch [1/50], Step [508/735], Loss: 5.3893\n",
      "Epoch [1/50], Step [509/735], Loss: 5.3405\n",
      "Epoch [1/50], Step [510/735], Loss: 4.1670\n",
      "Epoch [1/50], Step [511/735], Loss: 4.1124\n",
      "Epoch [1/50], Step [512/735], Loss: 4.6604\n",
      "Epoch [1/50], Step [513/735], Loss: 3.8085\n",
      "Epoch [1/50], Step [514/735], Loss: 3.3240\n",
      "Epoch [1/50], Step [515/735], Loss: 4.3714\n",
      "Epoch [1/50], Step [516/735], Loss: 3.6240\n",
      "Epoch [1/50], Step [517/735], Loss: 4.6450\n",
      "Epoch [1/50], Step [518/735], Loss: 4.6571\n",
      "Epoch [1/50], Step [519/735], Loss: 3.8431\n",
      "Epoch [1/50], Step [520/735], Loss: 3.1026\n",
      "Epoch [1/50], Step [521/735], Loss: 4.3547\n",
      "Epoch [1/50], Step [522/735], Loss: 3.2422\n",
      "Epoch [1/50], Step [523/735], Loss: 4.0115\n",
      "Epoch [1/50], Step [524/735], Loss: 4.0635\n",
      "Epoch [1/50], Step [525/735], Loss: 3.8442\n",
      "Epoch [1/50], Step [526/735], Loss: 3.0166\n",
      "Epoch [1/50], Step [527/735], Loss: 4.0432\n",
      "Epoch [1/50], Step [528/735], Loss: 3.8880\n",
      "Epoch [1/50], Step [529/735], Loss: 3.7899\n",
      "Epoch [1/50], Step [530/735], Loss: 3.4390\n",
      "Epoch [1/50], Step [531/735], Loss: 3.1662\n",
      "Epoch [1/50], Step [532/735], Loss: 4.6067\n",
      "Epoch [1/50], Step [533/735], Loss: 5.8479\n",
      "Epoch [1/50], Step [534/735], Loss: 4.3296\n",
      "Epoch [1/50], Step [535/735], Loss: 4.4151\n",
      "Epoch [1/50], Step [536/735], Loss: 4.4847\n",
      "Epoch [1/50], Step [537/735], Loss: 3.6990\n",
      "Epoch [1/50], Step [538/735], Loss: 4.1826\n",
      "Epoch [1/50], Step [539/735], Loss: 4.3853\n",
      "Epoch [1/50], Step [540/735], Loss: 4.7827\n",
      "Epoch [1/50], Step [541/735], Loss: 4.2812\n",
      "Epoch [1/50], Step [542/735], Loss: 4.2253\n",
      "Epoch [1/50], Step [543/735], Loss: 4.2247\n",
      "Epoch [1/50], Step [544/735], Loss: 4.3624\n",
      "Epoch [1/50], Step [545/735], Loss: 3.7762\n",
      "Epoch [1/50], Step [546/735], Loss: 4.8218\n",
      "Epoch [1/50], Step [547/735], Loss: 2.5521\n",
      "Epoch [1/50], Step [548/735], Loss: 4.0311\n",
      "Epoch [1/50], Step [549/735], Loss: 3.9851\n",
      "Epoch [1/50], Step [550/735], Loss: 3.0983\n",
      "Epoch [1/50], Step [551/735], Loss: 2.9261\n",
      "Epoch [1/50], Step [552/735], Loss: 3.7129\n",
      "Epoch [1/50], Step [553/735], Loss: 3.7983\n",
      "Epoch [1/50], Step [554/735], Loss: 3.4849\n",
      "Epoch [1/50], Step [555/735], Loss: 6.2267\n",
      "Epoch [1/50], Step [556/735], Loss: 4.6767\n",
      "Epoch [1/50], Step [557/735], Loss: 4.2533\n",
      "Epoch [1/50], Step [558/735], Loss: 3.0606\n",
      "Epoch [1/50], Step [559/735], Loss: 3.0840\n",
      "Epoch [1/50], Step [560/735], Loss: 3.2092\n",
      "Epoch [1/50], Step [561/735], Loss: 3.7665\n",
      "Epoch [1/50], Step [562/735], Loss: 4.1975\n",
      "Epoch [1/50], Step [563/735], Loss: 2.8066\n",
      "Epoch [1/50], Step [564/735], Loss: 2.7789\n",
      "Epoch [1/50], Step [565/735], Loss: 4.5532\n",
      "Epoch [1/50], Step [566/735], Loss: 2.9374\n",
      "Epoch [1/50], Step [567/735], Loss: 3.4481\n",
      "Epoch [1/50], Step [568/735], Loss: 2.9180\n",
      "Epoch [1/50], Step [569/735], Loss: 3.8265\n",
      "Epoch [1/50], Step [570/735], Loss: 3.5940\n",
      "Epoch [1/50], Step [571/735], Loss: 2.6010\n",
      "Epoch [1/50], Step [572/735], Loss: 3.1695\n",
      "Epoch [1/50], Step [573/735], Loss: 3.2671\n",
      "Epoch [1/50], Step [574/735], Loss: 3.6988\n",
      "Epoch [1/50], Step [575/735], Loss: 3.2948\n",
      "Epoch [1/50], Step [576/735], Loss: 4.9794\n",
      "Epoch [1/50], Step [577/735], Loss: 4.1941\n",
      "Epoch [1/50], Step [578/735], Loss: 3.8927\n",
      "Epoch [1/50], Step [579/735], Loss: 3.0909\n",
      "Epoch [1/50], Step [580/735], Loss: 4.1701\n",
      "Epoch [1/50], Step [581/735], Loss: 3.1643\n",
      "Epoch [1/50], Step [582/735], Loss: 4.0748\n",
      "Epoch [1/50], Step [583/735], Loss: 3.4651\n",
      "Epoch [1/50], Step [584/735], Loss: 2.7932\n",
      "Epoch [1/50], Step [585/735], Loss: 3.0536\n",
      "Epoch [1/50], Step [586/735], Loss: 3.5132\n",
      "Epoch [1/50], Step [587/735], Loss: 3.9683\n",
      "Epoch [1/50], Step [588/735], Loss: 2.6980\n",
      "Epoch [1/50], Step [589/735], Loss: 2.4897\n",
      "Epoch [1/50], Step [590/735], Loss: 2.6073\n",
      "Epoch [1/50], Step [591/735], Loss: 2.8506\n",
      "Epoch [1/50], Step [592/735], Loss: 2.6545\n",
      "Epoch [1/50], Step [593/735], Loss: 4.4623\n",
      "Epoch [1/50], Step [594/735], Loss: 3.3184\n",
      "Epoch [1/50], Step [595/735], Loss: 2.9013\n",
      "Epoch [1/50], Step [596/735], Loss: 4.1648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [597/735], Loss: 2.8681\n",
      "Epoch [1/50], Step [598/735], Loss: 3.3597\n",
      "Epoch [1/50], Step [599/735], Loss: 2.5442\n",
      "Epoch [1/50], Step [600/735], Loss: 3.6012\n",
      "Epoch [1/50], Step [601/735], Loss: 3.1371\n",
      "Epoch [1/50], Step [602/735], Loss: 3.1299\n",
      "Epoch [1/50], Step [603/735], Loss: 4.7545\n",
      "Epoch [1/50], Step [604/735], Loss: 3.0927\n",
      "Epoch [1/50], Step [605/735], Loss: 3.0123\n",
      "Epoch [1/50], Step [606/735], Loss: 2.9892\n",
      "Epoch [1/50], Step [607/735], Loss: 2.6907\n",
      "Epoch [1/50], Step [608/735], Loss: 2.5076\n",
      "Epoch [1/50], Step [609/735], Loss: 3.2037\n",
      "Epoch [1/50], Step [610/735], Loss: 3.5756\n",
      "Epoch [1/50], Step [611/735], Loss: 3.3664\n",
      "Epoch [1/50], Step [612/735], Loss: 3.7671\n",
      "Epoch [1/50], Step [613/735], Loss: 2.6189\n",
      "Epoch [1/50], Step [614/735], Loss: 2.9715\n",
      "Epoch [1/50], Step [615/735], Loss: 2.8358\n",
      "Epoch [1/50], Step [616/735], Loss: 2.9853\n",
      "Epoch [1/50], Step [617/735], Loss: 3.8161\n",
      "Epoch [1/50], Step [618/735], Loss: 2.5608\n",
      "Epoch [1/50], Step [619/735], Loss: 3.0520\n",
      "Epoch [1/50], Step [620/735], Loss: 3.3850\n",
      "Epoch [1/50], Step [621/735], Loss: 2.9638\n",
      "Epoch [1/50], Step [622/735], Loss: 2.8103\n",
      "Epoch [1/50], Step [623/735], Loss: 3.0500\n",
      "Epoch [1/50], Step [624/735], Loss: 2.8340\n",
      "Epoch [1/50], Step [625/735], Loss: 2.7499\n",
      "Epoch [1/50], Step [626/735], Loss: 2.5655\n",
      "Epoch [1/50], Step [627/735], Loss: 4.5529\n",
      "Epoch [1/50], Step [628/735], Loss: 2.9832\n",
      "Epoch [1/50], Step [629/735], Loss: 3.0738\n",
      "Epoch [1/50], Step [630/735], Loss: 4.1965\n",
      "Epoch [1/50], Step [631/735], Loss: 2.4883\n",
      "Epoch [1/50], Step [632/735], Loss: 2.9919\n",
      "Epoch [1/50], Step [633/735], Loss: 2.7907\n",
      "Epoch [1/50], Step [634/735], Loss: 3.5820\n",
      "Epoch [1/50], Step [635/735], Loss: 2.7217\n",
      "Epoch [1/50], Step [636/735], Loss: 2.4327\n",
      "Epoch [1/50], Step [637/735], Loss: 2.1890\n",
      "Epoch [1/50], Step [638/735], Loss: 2.2556\n",
      "Epoch [1/50], Step [639/735], Loss: 2.5886\n",
      "Epoch [1/50], Step [640/735], Loss: 2.6175\n",
      "Epoch [1/50], Step [641/735], Loss: 2.6439\n",
      "Epoch [1/50], Step [642/735], Loss: 3.3965\n",
      "Epoch [1/50], Step [643/735], Loss: 3.1459\n",
      "Epoch [1/50], Step [644/735], Loss: 4.1828\n",
      "Epoch [1/50], Step [645/735], Loss: 2.6811\n",
      "Epoch [1/50], Step [646/735], Loss: 2.7943\n",
      "Epoch [1/50], Step [647/735], Loss: 2.4429\n",
      "Epoch [1/50], Step [648/735], Loss: 2.8277\n",
      "Epoch [1/50], Step [649/735], Loss: 2.6620\n",
      "Epoch [1/50], Step [650/735], Loss: 2.1148\n",
      "Epoch [1/50], Step [651/735], Loss: 4.3079\n",
      "Epoch [1/50], Step [652/735], Loss: 3.4518\n",
      "Epoch [1/50], Step [653/735], Loss: 2.6078\n",
      "Epoch [1/50], Step [654/735], Loss: 2.3357\n",
      "Epoch [1/50], Step [655/735], Loss: 2.3203\n",
      "Epoch [1/50], Step [656/735], Loss: 2.1788\n",
      "Epoch [1/50], Step [657/735], Loss: 2.4435\n",
      "Epoch [1/50], Step [658/735], Loss: 2.5094\n",
      "Epoch [1/50], Step [659/735], Loss: 3.4434\n",
      "Epoch [1/50], Step [660/735], Loss: 2.3806\n",
      "Epoch [1/50], Step [661/735], Loss: 2.7680\n",
      "Epoch [1/50], Step [662/735], Loss: 2.3280\n",
      "Epoch [1/50], Step [663/735], Loss: 2.6345\n",
      "Epoch [1/50], Step [664/735], Loss: 2.0146\n",
      "Epoch [1/50], Step [665/735], Loss: 2.2661\n",
      "Epoch [1/50], Step [666/735], Loss: 2.4304\n",
      "Epoch [1/50], Step [667/735], Loss: 2.2087\n",
      "Epoch [1/50], Step [668/735], Loss: 2.5383\n",
      "Epoch [1/50], Step [669/735], Loss: 2.4813\n",
      "Epoch [1/50], Step [670/735], Loss: 2.1240\n",
      "Epoch [1/50], Step [671/735], Loss: 2.4639\n",
      "Epoch [1/50], Step [672/735], Loss: 2.7026\n",
      "Epoch [1/50], Step [673/735], Loss: 1.8822\n",
      "Epoch [1/50], Step [674/735], Loss: 2.3332\n",
      "Epoch [1/50], Step [675/735], Loss: 3.0911\n",
      "Epoch [1/50], Step [676/735], Loss: 1.8273\n",
      "Epoch [1/50], Step [677/735], Loss: 2.3298\n",
      "Epoch [1/50], Step [678/735], Loss: 2.6685\n",
      "Epoch [1/50], Step [679/735], Loss: 2.2257\n",
      "Epoch [1/50], Step [680/735], Loss: 1.8710\n",
      "Epoch [1/50], Step [681/735], Loss: 1.4887\n",
      "Epoch [1/50], Step [682/735], Loss: 2.1104\n",
      "Epoch [1/50], Step [683/735], Loss: 7.2405\n",
      "Epoch [1/50], Step [684/735], Loss: 6.5141\n",
      "Epoch [1/50], Step [685/735], Loss: 1.8466\n",
      "Epoch [1/50], Step [686/735], Loss: 2.0622\n",
      "Epoch [1/50], Step [687/735], Loss: 2.4747\n",
      "Epoch [1/50], Step [688/735], Loss: 2.1124\n",
      "Epoch [1/50], Step [689/735], Loss: 2.1353\n",
      "Epoch [1/50], Step [690/735], Loss: 2.4325\n",
      "Epoch [1/50], Step [691/735], Loss: 2.4440\n",
      "Epoch [1/50], Step [692/735], Loss: 2.9405\n",
      "Epoch [1/50], Step [693/735], Loss: 3.5589\n",
      "Epoch [1/50], Step [694/735], Loss: 2.2301\n",
      "Epoch [1/50], Step [695/735], Loss: 2.3435\n",
      "Epoch [1/50], Step [696/735], Loss: 2.4606\n",
      "Epoch [1/50], Step [697/735], Loss: 1.8426\n",
      "Epoch [1/50], Step [698/735], Loss: 2.1414\n",
      "Epoch [1/50], Step [699/735], Loss: 3.3348\n",
      "Epoch [1/50], Step [700/735], Loss: 2.1730\n",
      "Epoch [1/50], Step [701/735], Loss: 2.9859\n",
      "Epoch [1/50], Step [702/735], Loss: 2.1485\n",
      "Epoch [1/50], Step [703/735], Loss: 2.1737\n",
      "Epoch [1/50], Step [704/735], Loss: 1.7165\n",
      "Epoch [1/50], Step [705/735], Loss: 1.6299\n",
      "Epoch [1/50], Step [706/735], Loss: 2.7889\n",
      "Epoch [1/50], Step [707/735], Loss: 3.2615\n",
      "Epoch [1/50], Step [708/735], Loss: 2.1634\n",
      "Epoch [1/50], Step [709/735], Loss: 2.2774\n",
      "Epoch [1/50], Step [710/735], Loss: 2.0777\n",
      "Epoch [1/50], Step [711/735], Loss: 2.6598\n",
      "Epoch [1/50], Step [712/735], Loss: 2.0339\n",
      "Epoch [1/50], Step [713/735], Loss: 2.4511\n",
      "Epoch [1/50], Step [714/735], Loss: 2.4449\n",
      "Epoch [1/50], Step [715/735], Loss: 2.6633\n",
      "Epoch [1/50], Step [716/735], Loss: 2.3293\n",
      "Epoch [1/50], Step [717/735], Loss: 2.8898\n",
      "Epoch [1/50], Step [718/735], Loss: 2.3186\n",
      "Epoch [1/50], Step [719/735], Loss: 2.2655\n",
      "Epoch [1/50], Step [720/735], Loss: 1.8313\n",
      "Epoch [1/50], Step [721/735], Loss: 1.8803\n",
      "Epoch [1/50], Step [722/735], Loss: 2.0470\n",
      "Epoch [1/50], Step [723/735], Loss: 2.0826\n",
      "Epoch [1/50], Step [724/735], Loss: 2.3943\n",
      "Epoch [1/50], Step [725/735], Loss: 2.5605\n",
      "Epoch [1/50], Step [726/735], Loss: 2.3475\n",
      "Epoch [1/50], Step [727/735], Loss: 1.4963\n",
      "Epoch [1/50], Step [728/735], Loss: 2.4443\n",
      "Epoch [1/50], Step [729/735], Loss: 2.0102\n",
      "Epoch [1/50], Step [730/735], Loss: 2.8271\n",
      "Epoch [1/50], Step [731/735], Loss: 2.0079\n",
      "Epoch [1/50], Step [732/735], Loss: 2.7857\n",
      "Epoch [1/50], Step [733/735], Loss: 1.8390\n",
      "Epoch [1/50], Step [734/735], Loss: 2.7420\n",
      "Epoch [1/50], Step [735/735], Loss: 1.6086\n",
      "Epoch [2/50], Step [1/735], Loss: 1.9390\n",
      "Epoch [2/50], Step [2/735], Loss: 3.1284\n",
      "Epoch [2/50], Step [3/735], Loss: 1.6485\n",
      "Epoch [2/50], Step [4/735], Loss: 1.8923\n",
      "Epoch [2/50], Step [5/735], Loss: 2.8122\n",
      "Epoch [2/50], Step [6/735], Loss: 2.5850\n",
      "Epoch [2/50], Step [7/735], Loss: 2.6008\n",
      "Epoch [2/50], Step [8/735], Loss: 2.2386\n",
      "Epoch [2/50], Step [9/735], Loss: 2.0408\n",
      "Epoch [2/50], Step [10/735], Loss: 1.9463\n",
      "Epoch [2/50], Step [11/735], Loss: 2.9000\n",
      "Epoch [2/50], Step [12/735], Loss: 2.5280\n",
      "Epoch [2/50], Step [13/735], Loss: 2.0458\n",
      "Epoch [2/50], Step [14/735], Loss: 2.7604\n",
      "Epoch [2/50], Step [15/735], Loss: 2.7568\n",
      "Epoch [2/50], Step [16/735], Loss: 2.4720\n",
      "Epoch [2/50], Step [17/735], Loss: 1.7058\n",
      "Epoch [2/50], Step [18/735], Loss: 1.7124\n",
      "Epoch [2/50], Step [19/735], Loss: 2.5170\n",
      "Epoch [2/50], Step [20/735], Loss: 2.0583\n",
      "Epoch [2/50], Step [21/735], Loss: 1.7992\n",
      "Epoch [2/50], Step [22/735], Loss: 2.2780\n",
      "Epoch [2/50], Step [23/735], Loss: 1.6922\n",
      "Epoch [2/50], Step [24/735], Loss: 1.7467\n",
      "Epoch [2/50], Step [25/735], Loss: 2.0529\n",
      "Epoch [2/50], Step [26/735], Loss: 1.9590\n",
      "Epoch [2/50], Step [27/735], Loss: 1.7253\n",
      "Epoch [2/50], Step [28/735], Loss: 2.4049\n",
      "Epoch [2/50], Step [29/735], Loss: 2.1287\n",
      "Epoch [2/50], Step [30/735], Loss: 2.7542\n",
      "Epoch [2/50], Step [31/735], Loss: 2.2481\n",
      "Epoch [2/50], Step [32/735], Loss: 2.3778\n",
      "Epoch [2/50], Step [33/735], Loss: 4.2913\n",
      "Epoch [2/50], Step [34/735], Loss: 2.2990\n",
      "Epoch [2/50], Step [35/735], Loss: 2.1808\n",
      "Epoch [2/50], Step [36/735], Loss: 1.8221\n",
      "Epoch [2/50], Step [37/735], Loss: 1.6524\n",
      "Epoch [2/50], Step [38/735], Loss: 1.9151\n",
      "Epoch [2/50], Step [39/735], Loss: 5.1325\n",
      "Epoch [2/50], Step [40/735], Loss: 2.0266\n",
      "Epoch [2/50], Step [41/735], Loss: 1.8130\n",
      "Epoch [2/50], Step [42/735], Loss: 1.8909\n",
      "Epoch [2/50], Step [43/735], Loss: 1.7057\n",
      "Epoch [2/50], Step [44/735], Loss: 2.1865\n",
      "Epoch [2/50], Step [45/735], Loss: 1.9407\n",
      "Epoch [2/50], Step [46/735], Loss: 6.3630\n",
      "Epoch [2/50], Step [47/735], Loss: 2.2699\n",
      "Epoch [2/50], Step [48/735], Loss: 2.5720\n",
      "Epoch [2/50], Step [49/735], Loss: 1.7176\n",
      "Epoch [2/50], Step [50/735], Loss: 2.3023\n",
      "Epoch [2/50], Step [51/735], Loss: 2.1583\n",
      "Epoch [2/50], Step [52/735], Loss: 2.6952\n",
      "Epoch [2/50], Step [53/735], Loss: 1.9420\n",
      "Epoch [2/50], Step [54/735], Loss: 2.0469\n",
      "Epoch [2/50], Step [55/735], Loss: 2.0374\n",
      "Epoch [2/50], Step [56/735], Loss: 3.2384\n",
      "Epoch [2/50], Step [57/735], Loss: 3.0273\n",
      "Epoch [2/50], Step [58/735], Loss: 1.8987\n",
      "Epoch [2/50], Step [59/735], Loss: 1.4407\n",
      "Epoch [2/50], Step [60/735], Loss: 2.1341\n",
      "Epoch [2/50], Step [61/735], Loss: 2.8338\n",
      "Epoch [2/50], Step [62/735], Loss: 1.7334\n",
      "Epoch [2/50], Step [63/735], Loss: 3.7003\n",
      "Epoch [2/50], Step [64/735], Loss: 2.4579\n",
      "Epoch [2/50], Step [65/735], Loss: 1.6678\n",
      "Epoch [2/50], Step [66/735], Loss: 1.7522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Step [67/735], Loss: 1.6710\n",
      "Epoch [2/50], Step [68/735], Loss: 2.7042\n",
      "Epoch [2/50], Step [69/735], Loss: 1.4715\n",
      "Epoch [2/50], Step [70/735], Loss: 2.1907\n",
      "Epoch [2/50], Step [71/735], Loss: 2.0564\n",
      "Epoch [2/50], Step [72/735], Loss: 1.4178\n",
      "Epoch [2/50], Step [73/735], Loss: 2.3568\n",
      "Epoch [2/50], Step [74/735], Loss: 2.3272\n",
      "Epoch [2/50], Step [75/735], Loss: 1.8817\n",
      "Epoch [2/50], Step [76/735], Loss: 1.6251\n",
      "Epoch [2/50], Step [77/735], Loss: 1.7357\n",
      "Epoch [2/50], Step [78/735], Loss: 1.9030\n",
      "Epoch [2/50], Step [79/735], Loss: 1.6118\n",
      "Epoch [2/50], Step [80/735], Loss: 2.9016\n",
      "Epoch [2/50], Step [81/735], Loss: 1.7997\n",
      "Epoch [2/50], Step [82/735], Loss: 1.6625\n",
      "Epoch [2/50], Step [83/735], Loss: 1.8611\n",
      "Epoch [2/50], Step [84/735], Loss: 2.0357\n",
      "Epoch [2/50], Step [85/735], Loss: 1.9711\n",
      "Epoch [2/50], Step [86/735], Loss: 4.0380\n",
      "Epoch [2/50], Step [87/735], Loss: 1.5028\n",
      "Epoch [2/50], Step [88/735], Loss: 1.5191\n",
      "Epoch [2/50], Step [89/735], Loss: 1.4254\n",
      "Epoch [2/50], Step [90/735], Loss: 1.8354\n",
      "Epoch [2/50], Step [91/735], Loss: 2.4637\n",
      "Epoch [2/50], Step [92/735], Loss: 2.3133\n",
      "Epoch [2/50], Step [93/735], Loss: 1.5209\n",
      "Epoch [2/50], Step [94/735], Loss: 2.0068\n",
      "Epoch [2/50], Step [95/735], Loss: 1.4383\n",
      "Epoch [2/50], Step [96/735], Loss: 2.2386\n",
      "Epoch [2/50], Step [97/735], Loss: 1.7361\n",
      "Epoch [2/50], Step [98/735], Loss: 1.4326\n",
      "Epoch [2/50], Step [99/735], Loss: 1.4434\n",
      "Epoch [2/50], Step [100/735], Loss: 1.5013\n",
      "Epoch [2/50], Step [101/735], Loss: 5.5853\n",
      "Epoch [2/50], Step [102/735], Loss: 1.5476\n",
      "Epoch [2/50], Step [103/735], Loss: 3.9444\n",
      "Epoch [2/50], Step [104/735], Loss: 1.1358\n",
      "Epoch [2/50], Step [105/735], Loss: 1.3888\n",
      "Epoch [2/50], Step [106/735], Loss: 2.0478\n",
      "Epoch [2/50], Step [107/735], Loss: 1.7704\n",
      "Epoch [2/50], Step [108/735], Loss: 2.2483\n",
      "Epoch [2/50], Step [109/735], Loss: 1.6198\n",
      "Epoch [2/50], Step [110/735], Loss: 1.7222\n",
      "Epoch [2/50], Step [111/735], Loss: 1.3590\n",
      "Epoch [2/50], Step [112/735], Loss: 1.4308\n",
      "Epoch [2/50], Step [113/735], Loss: 1.0889\n",
      "Epoch [2/50], Step [114/735], Loss: 1.8198\n",
      "Epoch [2/50], Step [115/735], Loss: 1.7413\n",
      "Epoch [2/50], Step [116/735], Loss: 1.5773\n",
      "Epoch [2/50], Step [117/735], Loss: 1.8200\n",
      "Epoch [2/50], Step [118/735], Loss: 1.5065\n",
      "Epoch [2/50], Step [119/735], Loss: 1.3546\n",
      "Epoch [2/50], Step [120/735], Loss: 2.4752\n",
      "Epoch [2/50], Step [121/735], Loss: 1.7280\n",
      "Epoch [2/50], Step [122/735], Loss: 1.9767\n",
      "Epoch [2/50], Step [123/735], Loss: 1.1618\n",
      "Epoch [2/50], Step [124/735], Loss: 1.7964\n",
      "Epoch [2/50], Step [125/735], Loss: 1.4081\n",
      "Epoch [2/50], Step [126/735], Loss: 2.5235\n",
      "Epoch [2/50], Step [127/735], Loss: 1.4888\n",
      "Epoch [2/50], Step [128/735], Loss: 1.6728\n",
      "Epoch [2/50], Step [129/735], Loss: 1.1994\n",
      "Epoch [2/50], Step [130/735], Loss: 1.9742\n",
      "Epoch [2/50], Step [131/735], Loss: 2.1378\n",
      "Epoch [2/50], Step [132/735], Loss: 2.1373\n",
      "Epoch [2/50], Step [133/735], Loss: 1.7130\n",
      "Epoch [2/50], Step [134/735], Loss: 1.2052\n",
      "Epoch [2/50], Step [135/735], Loss: 1.4962\n",
      "Epoch [2/50], Step [136/735], Loss: 3.4889\n",
      "Epoch [2/50], Step [137/735], Loss: 1.8188\n",
      "Epoch [2/50], Step [138/735], Loss: 1.1932\n",
      "Epoch [2/50], Step [139/735], Loss: 1.5904\n",
      "Epoch [2/50], Step [140/735], Loss: 1.1295\n",
      "Epoch [2/50], Step [141/735], Loss: 1.5867\n",
      "Epoch [2/50], Step [142/735], Loss: 1.3534\n",
      "Epoch [2/50], Step [143/735], Loss: 1.6337\n",
      "Epoch [2/50], Step [144/735], Loss: 1.6316\n",
      "Epoch [2/50], Step [145/735], Loss: 1.9000\n",
      "Epoch [2/50], Step [146/735], Loss: 1.8789\n",
      "Epoch [2/50], Step [147/735], Loss: 1.2045\n",
      "Epoch [2/50], Step [148/735], Loss: 1.5609\n",
      "Epoch [2/50], Step [149/735], Loss: 1.1355\n",
      "Epoch [2/50], Step [150/735], Loss: 1.7358\n",
      "Epoch [2/50], Step [151/735], Loss: 1.3377\n",
      "Epoch [2/50], Step [152/735], Loss: 1.9278\n",
      "Epoch [2/50], Step [153/735], Loss: 1.2092\n",
      "Epoch [2/50], Step [154/735], Loss: 1.3629\n",
      "Epoch [2/50], Step [155/735], Loss: 1.3853\n",
      "Epoch [2/50], Step [156/735], Loss: 1.8055\n",
      "Epoch [2/50], Step [157/735], Loss: 3.6836\n",
      "Epoch [2/50], Step [158/735], Loss: 2.0215\n",
      "Epoch [2/50], Step [159/735], Loss: 1.2952\n",
      "Epoch [2/50], Step [160/735], Loss: 2.0235\n",
      "Epoch [2/50], Step [161/735], Loss: 1.7845\n",
      "Epoch [2/50], Step [162/735], Loss: 2.9467\n",
      "Epoch [2/50], Step [163/735], Loss: 1.1861\n",
      "Epoch [2/50], Step [164/735], Loss: 2.0966\n",
      "Epoch [2/50], Step [165/735], Loss: 1.1938\n",
      "Epoch [2/50], Step [166/735], Loss: 2.5626\n",
      "Epoch [2/50], Step [167/735], Loss: 2.6199\n",
      "Epoch [2/50], Step [168/735], Loss: 1.0157\n",
      "Epoch [2/50], Step [169/735], Loss: 1.8780\n",
      "Epoch [2/50], Step [170/735], Loss: 1.8938\n",
      "Epoch [2/50], Step [171/735], Loss: 1.1411\n",
      "Epoch [2/50], Step [172/735], Loss: 1.1895\n",
      "Epoch [2/50], Step [173/735], Loss: 1.5072\n",
      "Epoch [2/50], Step [174/735], Loss: 1.8109\n",
      "Epoch [2/50], Step [175/735], Loss: 4.7074\n",
      "Epoch [2/50], Step [176/735], Loss: 1.8905\n",
      "Epoch [2/50], Step [177/735], Loss: 1.3799\n",
      "Epoch [2/50], Step [178/735], Loss: 1.3889\n",
      "Epoch [2/50], Step [179/735], Loss: 1.3365\n",
      "Epoch [2/50], Step [180/735], Loss: 1.0504\n",
      "Epoch [2/50], Step [181/735], Loss: 1.4343\n",
      "Epoch [2/50], Step [182/735], Loss: 1.5269\n",
      "Epoch [2/50], Step [183/735], Loss: 1.4251\n",
      "Epoch [2/50], Step [184/735], Loss: 1.8530\n",
      "Epoch [2/50], Step [185/735], Loss: 3.0478\n",
      "Epoch [2/50], Step [186/735], Loss: 1.8053\n",
      "Epoch [2/50], Step [187/735], Loss: 1.3668\n",
      "Epoch [2/50], Step [188/735], Loss: 1.7992\n",
      "Epoch [2/50], Step [189/735], Loss: 1.7950\n",
      "Epoch [2/50], Step [190/735], Loss: 1.9915\n",
      "Epoch [2/50], Step [191/735], Loss: 1.0983\n",
      "Epoch [2/50], Step [192/735], Loss: 2.4482\n",
      "Epoch [2/50], Step [193/735], Loss: 1.1721\n",
      "Epoch [2/50], Step [194/735], Loss: 1.6175\n",
      "Epoch [2/50], Step [195/735], Loss: 1.2716\n",
      "Epoch [2/50], Step [196/735], Loss: 2.5831\n",
      "Epoch [2/50], Step [197/735], Loss: 1.1859\n",
      "Epoch [2/50], Step [198/735], Loss: 0.8373\n",
      "Epoch [2/50], Step [199/735], Loss: 1.1643\n",
      "Epoch [2/50], Step [200/735], Loss: 1.1670\n",
      "Epoch [2/50], Step [201/735], Loss: 0.9523\n",
      "Epoch [2/50], Step [202/735], Loss: 1.1705\n",
      "Epoch [2/50], Step [203/735], Loss: 1.4035\n",
      "Epoch [2/50], Step [204/735], Loss: 1.5350\n",
      "Epoch [2/50], Step [205/735], Loss: 1.6152\n",
      "Epoch [2/50], Step [206/735], Loss: 2.6479\n",
      "Epoch [2/50], Step [207/735], Loss: 2.4961\n",
      "Epoch [2/50], Step [208/735], Loss: 2.0969\n",
      "Epoch [2/50], Step [209/735], Loss: 1.4561\n",
      "Epoch [2/50], Step [210/735], Loss: 1.1640\n",
      "Epoch [2/50], Step [211/735], Loss: 1.5102\n",
      "Epoch [2/50], Step [212/735], Loss: 1.5673\n",
      "Epoch [2/50], Step [213/735], Loss: 1.4522\n",
      "Epoch [2/50], Step [214/735], Loss: 1.4451\n",
      "Epoch [2/50], Step [215/735], Loss: 1.5558\n",
      "Epoch [2/50], Step [216/735], Loss: 1.3429\n",
      "Epoch [2/50], Step [217/735], Loss: 1.6257\n",
      "Epoch [2/50], Step [218/735], Loss: 2.1669\n",
      "Epoch [2/50], Step [219/735], Loss: 1.3545\n",
      "Epoch [2/50], Step [220/735], Loss: 1.1105\n",
      "Epoch [2/50], Step [221/735], Loss: 0.9621\n",
      "Epoch [2/50], Step [222/735], Loss: 1.0570\n",
      "Epoch [2/50], Step [223/735], Loss: 1.2254\n",
      "Epoch [2/50], Step [224/735], Loss: 1.5114\n",
      "Epoch [2/50], Step [225/735], Loss: 1.7032\n",
      "Epoch [2/50], Step [226/735], Loss: 1.4639\n",
      "Epoch [2/50], Step [227/735], Loss: 2.9652\n",
      "Epoch [2/50], Step [228/735], Loss: 1.3132\n",
      "Epoch [2/50], Step [229/735], Loss: 1.0298\n",
      "Epoch [2/50], Step [230/735], Loss: 2.1842\n",
      "Epoch [2/50], Step [231/735], Loss: 1.2161\n",
      "Epoch [2/50], Step [232/735], Loss: 1.3969\n",
      "Epoch [2/50], Step [233/735], Loss: 2.0114\n",
      "Epoch [2/50], Step [234/735], Loss: 1.4950\n",
      "Epoch [2/50], Step [235/735], Loss: 0.9633\n",
      "Epoch [2/50], Step [236/735], Loss: 1.2903\n",
      "Epoch [2/50], Step [237/735], Loss: 1.2424\n",
      "Epoch [2/50], Step [238/735], Loss: 1.3502\n",
      "Epoch [2/50], Step [239/735], Loss: 2.3534\n",
      "Epoch [2/50], Step [240/735], Loss: 1.0466\n",
      "Epoch [2/50], Step [241/735], Loss: 1.4892\n",
      "Epoch [2/50], Step [242/735], Loss: 2.4672\n",
      "Epoch [2/50], Step [243/735], Loss: 1.0845\n",
      "Epoch [2/50], Step [244/735], Loss: 3.1859\n",
      "Epoch [2/50], Step [245/735], Loss: 1.2321\n",
      "Epoch [2/50], Step [246/735], Loss: 1.2368\n",
      "Epoch [2/50], Step [247/735], Loss: 1.7362\n",
      "Epoch [2/50], Step [248/735], Loss: 0.9681\n",
      "Epoch [2/50], Step [249/735], Loss: 1.9565\n",
      "Epoch [2/50], Step [250/735], Loss: 1.0331\n",
      "Epoch [2/50], Step [251/735], Loss: 1.0097\n",
      "Epoch [2/50], Step [252/735], Loss: 2.0881\n",
      "Epoch [2/50], Step [253/735], Loss: 1.3337\n",
      "Epoch [2/50], Step [254/735], Loss: 1.1192\n",
      "Epoch [2/50], Step [255/735], Loss: 0.7448\n",
      "Epoch [2/50], Step [256/735], Loss: 1.9342\n",
      "Epoch [2/50], Step [257/735], Loss: 1.4142\n",
      "Epoch [2/50], Step [258/735], Loss: 1.5318\n",
      "Epoch [2/50], Step [259/735], Loss: 1.5837\n",
      "Epoch [2/50], Step [260/735], Loss: 1.2222\n",
      "Epoch [2/50], Step [261/735], Loss: 2.9869\n",
      "Epoch [2/50], Step [262/735], Loss: 0.7452\n",
      "Epoch [2/50], Step [263/735], Loss: 1.3993\n",
      "Epoch [2/50], Step [264/735], Loss: 0.9127\n",
      "Epoch [2/50], Step [265/735], Loss: 1.2697\n",
      "Epoch [2/50], Step [266/735], Loss: 1.5709\n",
      "Epoch [2/50], Step [267/735], Loss: 2.8066\n",
      "Epoch [2/50], Step [268/735], Loss: 0.9605\n",
      "Epoch [2/50], Step [269/735], Loss: 1.6889\n",
      "Epoch [2/50], Step [270/735], Loss: 1.0812\n",
      "Epoch [2/50], Step [271/735], Loss: 1.3749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Step [272/735], Loss: 1.2513\n",
      "Epoch [2/50], Step [273/735], Loss: 1.4109\n",
      "Epoch [2/50], Step [274/735], Loss: 1.6812\n",
      "Epoch [2/50], Step [275/735], Loss: 1.1171\n",
      "Epoch [2/50], Step [276/735], Loss: 1.3816\n",
      "Epoch [2/50], Step [277/735], Loss: 1.4595\n",
      "Epoch [2/50], Step [278/735], Loss: 0.9548\n",
      "Epoch [2/50], Step [279/735], Loss: 1.2454\n",
      "Epoch [2/50], Step [280/735], Loss: 0.9685\n",
      "Epoch [2/50], Step [281/735], Loss: 1.5152\n",
      "Epoch [2/50], Step [282/735], Loss: 1.2339\n",
      "Epoch [2/50], Step [283/735], Loss: 1.0883\n",
      "Epoch [2/50], Step [284/735], Loss: 1.2192\n",
      "Epoch [2/50], Step [285/735], Loss: 1.5897\n",
      "Epoch [2/50], Step [286/735], Loss: 1.9399\n",
      "Epoch [2/50], Step [287/735], Loss: 1.8179\n",
      "Epoch [2/50], Step [288/735], Loss: 1.0827\n",
      "Epoch [2/50], Step [289/735], Loss: 1.0966\n",
      "Epoch [2/50], Step [290/735], Loss: 1.2969\n",
      "Epoch [2/50], Step [291/735], Loss: 1.1034\n",
      "Epoch [2/50], Step [292/735], Loss: 1.3603\n",
      "Epoch [2/50], Step [293/735], Loss: 0.9739\n",
      "Epoch [2/50], Step [294/735], Loss: 0.9006\n",
      "Epoch [2/50], Step [295/735], Loss: 1.1160\n",
      "Epoch [2/50], Step [296/735], Loss: 1.1325\n",
      "Epoch [2/50], Step [297/735], Loss: 1.1982\n",
      "Epoch [2/50], Step [298/735], Loss: 1.0935\n",
      "Epoch [2/50], Step [299/735], Loss: 1.3614\n",
      "Epoch [2/50], Step [300/735], Loss: 1.0627\n",
      "Epoch [2/50], Step [301/735], Loss: 1.0672\n",
      "Epoch [2/50], Step [302/735], Loss: 0.9627\n",
      "Epoch [2/50], Step [303/735], Loss: 1.4592\n",
      "Epoch [2/50], Step [304/735], Loss: 0.7459\n",
      "Epoch [2/50], Step [305/735], Loss: 1.2237\n",
      "Epoch [2/50], Step [306/735], Loss: 1.0793\n",
      "Epoch [2/50], Step [307/735], Loss: 1.4653\n",
      "Epoch [2/50], Step [308/735], Loss: 1.0547\n",
      "Epoch [2/50], Step [309/735], Loss: 0.7798\n",
      "Epoch [2/50], Step [310/735], Loss: 0.9728\n",
      "Epoch [2/50], Step [311/735], Loss: 2.0469\n",
      "Epoch [2/50], Step [312/735], Loss: 0.9177\n",
      "Epoch [2/50], Step [313/735], Loss: 1.4402\n",
      "Epoch [2/50], Step [314/735], Loss: 3.2336\n",
      "Epoch [2/50], Step [315/735], Loss: 0.9185\n",
      "Epoch [2/50], Step [316/735], Loss: 0.7645\n",
      "Epoch [2/50], Step [317/735], Loss: 1.4212\n",
      "Epoch [2/50], Step [318/735], Loss: 0.7655\n",
      "Epoch [2/50], Step [319/735], Loss: 3.5116\n",
      "Epoch [2/50], Step [320/735], Loss: 0.8450\n",
      "Epoch [2/50], Step [321/735], Loss: 0.9218\n",
      "Epoch [2/50], Step [322/735], Loss: 1.7731\n",
      "Epoch [2/50], Step [323/735], Loss: 0.7967\n",
      "Epoch [2/50], Step [324/735], Loss: 1.3980\n",
      "Epoch [2/50], Step [325/735], Loss: 0.8103\n",
      "Epoch [2/50], Step [326/735], Loss: 1.2801\n",
      "Epoch [2/50], Step [327/735], Loss: 0.7413\n",
      "Epoch [2/50], Step [328/735], Loss: 1.5789\n",
      "Epoch [2/50], Step [329/735], Loss: 0.6910\n",
      "Epoch [2/50], Step [330/735], Loss: 1.1974\n",
      "Epoch [2/50], Step [331/735], Loss: 1.3071\n",
      "Epoch [2/50], Step [332/735], Loss: 1.5826\n",
      "Epoch [2/50], Step [333/735], Loss: 1.1970\n",
      "Epoch [2/50], Step [334/735], Loss: 0.8808\n",
      "Epoch [2/50], Step [335/735], Loss: 1.4942\n",
      "Epoch [2/50], Step [336/735], Loss: 1.1945\n",
      "Epoch [2/50], Step [337/735], Loss: 0.9854\n",
      "Epoch [2/50], Step [338/735], Loss: 0.8842\n",
      "Epoch [2/50], Step [339/735], Loss: 0.8007\n",
      "Epoch [2/50], Step [340/735], Loss: 0.8028\n",
      "Epoch [2/50], Step [341/735], Loss: 1.7430\n",
      "Epoch [2/50], Step [342/735], Loss: 0.9648\n",
      "Epoch [2/50], Step [343/735], Loss: 0.9882\n",
      "Epoch [2/50], Step [344/735], Loss: 1.2447\n",
      "Epoch [2/50], Step [345/735], Loss: 1.1440\n",
      "Epoch [2/50], Step [346/735], Loss: 1.0858\n",
      "Epoch [2/50], Step [347/735], Loss: 1.0099\n",
      "Epoch [2/50], Step [348/735], Loss: 0.7307\n",
      "Epoch [2/50], Step [349/735], Loss: 0.7005\n",
      "Epoch [2/50], Step [350/735], Loss: 2.4654\n",
      "Epoch [2/50], Step [351/735], Loss: 1.2386\n",
      "Epoch [2/50], Step [352/735], Loss: 3.7347\n",
      "Epoch [2/50], Step [353/735], Loss: 1.9331\n",
      "Epoch [2/50], Step [354/735], Loss: 1.3739\n",
      "Epoch [2/50], Step [355/735], Loss: 0.9102\n",
      "Epoch [2/50], Step [356/735], Loss: 0.6457\n",
      "Epoch [2/50], Step [357/735], Loss: 1.2112\n",
      "Epoch [2/50], Step [358/735], Loss: 0.7348\n",
      "Epoch [2/50], Step [359/735], Loss: 1.3249\n",
      "Epoch [2/50], Step [360/735], Loss: 0.9077\n",
      "Epoch [2/50], Step [361/735], Loss: 0.6867\n",
      "Epoch [2/50], Step [362/735], Loss: 0.8836\n",
      "Epoch [2/50], Step [363/735], Loss: 1.5997\n",
      "Epoch [2/50], Step [364/735], Loss: 1.0904\n",
      "Epoch [2/50], Step [365/735], Loss: 1.3880\n",
      "Epoch [2/50], Step [366/735], Loss: 1.5921\n",
      "Epoch [2/50], Step [367/735], Loss: 1.4856\n",
      "Epoch [2/50], Step [368/735], Loss: 2.6733\n",
      "Epoch [2/50], Step [369/735], Loss: 0.9691\n",
      "Epoch [2/50], Step [370/735], Loss: 1.0533\n",
      "Epoch [2/50], Step [371/735], Loss: 0.9905\n",
      "Epoch [2/50], Step [372/735], Loss: 0.7117\n",
      "Epoch [2/50], Step [373/735], Loss: 1.3973\n",
      "Epoch [2/50], Step [374/735], Loss: 0.9085\n",
      "Epoch [2/50], Step [375/735], Loss: 0.8018\n",
      "Epoch [2/50], Step [376/735], Loss: 1.3161\n",
      "Epoch [2/50], Step [377/735], Loss: 0.8221\n",
      "Epoch [2/50], Step [378/735], Loss: 2.2305\n",
      "Epoch [2/50], Step [379/735], Loss: 0.8645\n",
      "Epoch [2/50], Step [380/735], Loss: 0.5700\n",
      "Epoch [2/50], Step [381/735], Loss: 1.1207\n",
      "Epoch [2/50], Step [382/735], Loss: 0.9192\n",
      "Epoch [2/50], Step [383/735], Loss: 0.8594\n",
      "Epoch [2/50], Step [384/735], Loss: 0.9630\n",
      "Epoch [2/50], Step [385/735], Loss: 0.6633\n",
      "Epoch [2/50], Step [386/735], Loss: 1.0850\n",
      "Epoch [2/50], Step [387/735], Loss: 0.9268\n",
      "Epoch [2/50], Step [388/735], Loss: 1.0206\n",
      "Epoch [2/50], Step [389/735], Loss: 1.0437\n",
      "Epoch [2/50], Step [390/735], Loss: 1.0499\n",
      "Epoch [2/50], Step [391/735], Loss: 0.9264\n",
      "Epoch [2/50], Step [392/735], Loss: 1.0139\n",
      "Epoch [2/50], Step [393/735], Loss: 1.5910\n",
      "Epoch [2/50], Step [394/735], Loss: 1.0578\n",
      "Epoch [2/50], Step [395/735], Loss: 0.7167\n",
      "Epoch [2/50], Step [396/735], Loss: 0.7957\n",
      "Epoch [2/50], Step [397/735], Loss: 1.9396\n",
      "Epoch [2/50], Step [398/735], Loss: 1.5043\n",
      "Epoch [2/50], Step [399/735], Loss: 0.7590\n",
      "Epoch [2/50], Step [400/735], Loss: 0.8743\n",
      "Epoch [2/50], Step [401/735], Loss: 0.8316\n",
      "Epoch [2/50], Step [402/735], Loss: 0.9800\n",
      "Epoch [2/50], Step [403/735], Loss: 0.6696\n",
      "Epoch [2/50], Step [404/735], Loss: 1.2042\n",
      "Epoch [2/50], Step [405/735], Loss: 0.6550\n",
      "Epoch [2/50], Step [406/735], Loss: 0.6869\n",
      "Epoch [2/50], Step [407/735], Loss: 1.5381\n",
      "Epoch [2/50], Step [408/735], Loss: 1.4418\n",
      "Epoch [2/50], Step [409/735], Loss: 0.8282\n",
      "Epoch [2/50], Step [410/735], Loss: 0.8206\n",
      "Epoch [2/50], Step [411/735], Loss: 0.8627\n",
      "Epoch [2/50], Step [412/735], Loss: 1.0271\n",
      "Epoch [2/50], Step [413/735], Loss: 0.7970\n",
      "Epoch [2/50], Step [414/735], Loss: 1.0306\n",
      "Epoch [2/50], Step [415/735], Loss: 0.7909\n",
      "Epoch [2/50], Step [416/735], Loss: 0.8797\n",
      "Epoch [2/50], Step [417/735], Loss: 1.2806\n",
      "Epoch [2/50], Step [418/735], Loss: 0.9928\n",
      "Epoch [2/50], Step [419/735], Loss: 1.5887\n",
      "Epoch [2/50], Step [420/735], Loss: 1.1913\n",
      "Epoch [2/50], Step [421/735], Loss: 0.9609\n",
      "Epoch [2/50], Step [422/735], Loss: 0.6257\n",
      "Epoch [2/50], Step [423/735], Loss: 0.8120\n",
      "Epoch [2/50], Step [424/735], Loss: 0.7855\n",
      "Epoch [2/50], Step [425/735], Loss: 1.2674\n",
      "Epoch [2/50], Step [426/735], Loss: 1.6910\n",
      "Epoch [2/50], Step [427/735], Loss: 1.4257\n",
      "Epoch [2/50], Step [428/735], Loss: 0.8893\n",
      "Epoch [2/50], Step [429/735], Loss: 1.0520\n",
      "Epoch [2/50], Step [430/735], Loss: 1.1669\n",
      "Epoch [2/50], Step [431/735], Loss: 0.6567\n",
      "Epoch [2/50], Step [432/735], Loss: 0.9261\n",
      "Epoch [2/50], Step [433/735], Loss: 0.7721\n",
      "Epoch [2/50], Step [434/735], Loss: 0.9128\n",
      "Epoch [2/50], Step [435/735], Loss: 1.2312\n",
      "Epoch [2/50], Step [436/735], Loss: 0.8247\n",
      "Epoch [2/50], Step [437/735], Loss: 1.1128\n",
      "Epoch [2/50], Step [438/735], Loss: 0.9609\n",
      "Epoch [2/50], Step [439/735], Loss: 1.1974\n",
      "Epoch [2/50], Step [440/735], Loss: 0.7740\n",
      "Epoch [2/50], Step [441/735], Loss: 0.6630\n",
      "Epoch [2/50], Step [442/735], Loss: 0.8997\n",
      "Epoch [2/50], Step [443/735], Loss: 2.0750\n",
      "Epoch [2/50], Step [444/735], Loss: 0.5734\n",
      "Epoch [2/50], Step [445/735], Loss: 0.8496\n",
      "Epoch [2/50], Step [446/735], Loss: 1.2397\n",
      "Epoch [2/50], Step [447/735], Loss: 0.9603\n",
      "Epoch [2/50], Step [448/735], Loss: 0.9348\n",
      "Epoch [2/50], Step [449/735], Loss: 0.6195\n",
      "Epoch [2/50], Step [450/735], Loss: 2.0761\n",
      "Epoch [2/50], Step [451/735], Loss: 1.1345\n",
      "Epoch [2/50], Step [452/735], Loss: 0.9478\n",
      "Epoch [2/50], Step [453/735], Loss: 0.7755\n",
      "Epoch [2/50], Step [454/735], Loss: 0.6309\n",
      "Epoch [2/50], Step [455/735], Loss: 0.8021\n",
      "Epoch [2/50], Step [456/735], Loss: 0.6561\n",
      "Epoch [2/50], Step [457/735], Loss: 0.9434\n",
      "Epoch [2/50], Step [458/735], Loss: 0.7575\n",
      "Epoch [2/50], Step [459/735], Loss: 4.5212\n",
      "Epoch [2/50], Step [460/735], Loss: 0.6671\n",
      "Epoch [2/50], Step [461/735], Loss: 0.7728\n",
      "Epoch [2/50], Step [462/735], Loss: 0.6020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Step [463/735], Loss: 1.3497\n",
      "Epoch [2/50], Step [464/735], Loss: 0.4606\n",
      "Epoch [2/50], Step [465/735], Loss: 0.8174\n",
      "Epoch [2/50], Step [466/735], Loss: 0.8529\n",
      "Epoch [2/50], Step [467/735], Loss: 0.9753\n",
      "Epoch [2/50], Step [468/735], Loss: 1.3246\n",
      "Epoch [2/50], Step [469/735], Loss: 1.0412\n",
      "Epoch [2/50], Step [470/735], Loss: 0.8890\n",
      "Epoch [2/50], Step [471/735], Loss: 0.7670\n",
      "Epoch [2/50], Step [472/735], Loss: 1.2889\n",
      "Epoch [2/50], Step [473/735], Loss: 1.3341\n",
      "Epoch [2/50], Step [474/735], Loss: 1.1120\n",
      "Epoch [2/50], Step [475/735], Loss: 0.7601\n",
      "Epoch [2/50], Step [476/735], Loss: 0.6115\n",
      "Epoch [2/50], Step [477/735], Loss: 0.9444\n",
      "Epoch [2/50], Step [478/735], Loss: 1.1722\n",
      "Epoch [2/50], Step [479/735], Loss: 0.6747\n",
      "Epoch [2/50], Step [480/735], Loss: 0.8275\n",
      "Epoch [2/50], Step [481/735], Loss: 0.7011\n",
      "Epoch [2/50], Step [482/735], Loss: 1.2206\n",
      "Epoch [2/50], Step [483/735], Loss: 1.2571\n",
      "Epoch [2/50], Step [484/735], Loss: 0.8794\n",
      "Epoch [2/50], Step [485/735], Loss: 0.7241\n",
      "Epoch [2/50], Step [486/735], Loss: 0.9920\n",
      "Epoch [2/50], Step [487/735], Loss: 0.6894\n",
      "Epoch [2/50], Step [488/735], Loss: 0.6212\n",
      "Epoch [2/50], Step [489/735], Loss: 0.7851\n",
      "Epoch [2/50], Step [490/735], Loss: 0.5104\n",
      "Epoch [2/50], Step [491/735], Loss: 0.3978\n",
      "Epoch [2/50], Step [492/735], Loss: 0.4832\n",
      "Epoch [2/50], Step [493/735], Loss: 1.1527\n",
      "Epoch [2/50], Step [494/735], Loss: 1.0714\n",
      "Epoch [2/50], Step [495/735], Loss: 0.7517\n",
      "Epoch [2/50], Step [496/735], Loss: 0.9477\n",
      "Epoch [2/50], Step [497/735], Loss: 0.6416\n",
      "Epoch [2/50], Step [498/735], Loss: 0.7764\n",
      "Epoch [2/50], Step [499/735], Loss: 0.8119\n",
      "Epoch [2/50], Step [500/735], Loss: 0.7942\n",
      "Epoch [2/50], Step [501/735], Loss: 0.6114\n",
      "Epoch [2/50], Step [502/735], Loss: 0.7287\n",
      "Epoch [2/50], Step [503/735], Loss: 0.8989\n",
      "Epoch [2/50], Step [504/735], Loss: 0.8786\n",
      "Epoch [2/50], Step [505/735], Loss: 0.5570\n",
      "Epoch [2/50], Step [506/735], Loss: 1.0789\n",
      "Epoch [2/50], Step [507/735], Loss: 1.2523\n",
      "Epoch [2/50], Step [508/735], Loss: 0.7430\n",
      "Epoch [2/50], Step [509/735], Loss: 0.6954\n",
      "Epoch [2/50], Step [510/735], Loss: 0.7007\n",
      "Epoch [2/50], Step [511/735], Loss: 0.8576\n",
      "Epoch [2/50], Step [512/735], Loss: 1.4546\n",
      "Epoch [2/50], Step [513/735], Loss: 0.6379\n",
      "Epoch [2/50], Step [514/735], Loss: 0.7262\n",
      "Epoch [2/50], Step [515/735], Loss: 0.5501\n",
      "Epoch [2/50], Step [516/735], Loss: 1.0502\n",
      "Epoch [2/50], Step [517/735], Loss: 0.9527\n",
      "Epoch [2/50], Step [518/735], Loss: 0.9375\n",
      "Epoch [2/50], Step [519/735], Loss: 0.6245\n",
      "Epoch [2/50], Step [520/735], Loss: 0.5551\n",
      "Epoch [2/50], Step [521/735], Loss: 0.6788\n",
      "Epoch [2/50], Step [522/735], Loss: 0.6253\n",
      "Epoch [2/50], Step [523/735], Loss: 0.5818\n",
      "Epoch [2/50], Step [524/735], Loss: 0.8972\n",
      "Epoch [2/50], Step [525/735], Loss: 1.1265\n",
      "Epoch [2/50], Step [526/735], Loss: 0.5840\n",
      "Epoch [2/50], Step [527/735], Loss: 1.0968\n",
      "Epoch [2/50], Step [528/735], Loss: 0.7906\n",
      "Epoch [2/50], Step [529/735], Loss: 0.8638\n",
      "Epoch [2/50], Step [530/735], Loss: 0.7153\n",
      "Epoch [2/50], Step [531/735], Loss: 1.1034\n",
      "Epoch [2/50], Step [532/735], Loss: 0.7231\n",
      "Epoch [2/50], Step [533/735], Loss: 0.4545\n",
      "Epoch [2/50], Step [534/735], Loss: 0.8906\n",
      "Epoch [2/50], Step [535/735], Loss: 0.6596\n",
      "Epoch [2/50], Step [536/735], Loss: 0.7993\n",
      "Epoch [2/50], Step [537/735], Loss: 1.0474\n",
      "Epoch [2/50], Step [538/735], Loss: 1.1851\n",
      "Epoch [2/50], Step [539/735], Loss: 0.7336\n",
      "Epoch [2/50], Step [540/735], Loss: 0.5631\n",
      "Epoch [2/50], Step [541/735], Loss: 0.8154\n",
      "Epoch [2/50], Step [542/735], Loss: 1.1496\n",
      "Epoch [2/50], Step [543/735], Loss: 0.3879\n",
      "Epoch [2/50], Step [544/735], Loss: 0.7964\n",
      "Epoch [2/50], Step [545/735], Loss: 0.8934\n",
      "Epoch [2/50], Step [546/735], Loss: 0.4807\n",
      "Epoch [2/50], Step [547/735], Loss: 1.0157\n",
      "Epoch [2/50], Step [548/735], Loss: 0.8644\n",
      "Epoch [2/50], Step [549/735], Loss: 1.0644\n",
      "Epoch [2/50], Step [550/735], Loss: 0.9256\n",
      "Epoch [2/50], Step [551/735], Loss: 0.6201\n",
      "Epoch [2/50], Step [552/735], Loss: 0.6746\n",
      "Epoch [2/50], Step [553/735], Loss: 0.6176\n",
      "Epoch [2/50], Step [554/735], Loss: 1.1520\n",
      "Epoch [2/50], Step [555/735], Loss: 0.6139\n",
      "Epoch [2/50], Step [556/735], Loss: 3.7488\n",
      "Epoch [2/50], Step [557/735], Loss: 0.5621\n",
      "Epoch [2/50], Step [558/735], Loss: 0.8522\n",
      "Epoch [2/50], Step [559/735], Loss: 0.4919\n",
      "Epoch [2/50], Step [560/735], Loss: 0.6284\n",
      "Epoch [2/50], Step [561/735], Loss: 0.6282\n",
      "Epoch [2/50], Step [562/735], Loss: 0.7633\n",
      "Epoch [2/50], Step [563/735], Loss: 0.9936\n",
      "Epoch [2/50], Step [564/735], Loss: 2.1960\n",
      "Epoch [2/50], Step [565/735], Loss: 0.6171\n",
      "Epoch [2/50], Step [566/735], Loss: 1.1142\n",
      "Epoch [2/50], Step [567/735], Loss: 0.4928\n",
      "Epoch [2/50], Step [568/735], Loss: 1.0877\n",
      "Epoch [2/50], Step [569/735], Loss: 0.5885\n",
      "Epoch [2/50], Step [570/735], Loss: 0.9329\n",
      "Epoch [2/50], Step [571/735], Loss: 0.8932\n",
      "Epoch [2/50], Step [572/735], Loss: 0.7720\n",
      "Epoch [2/50], Step [573/735], Loss: 0.7505\n",
      "Epoch [2/50], Step [574/735], Loss: 1.0055\n",
      "Epoch [2/50], Step [575/735], Loss: 0.9752\n",
      "Epoch [2/50], Step [576/735], Loss: 0.5288\n",
      "Epoch [2/50], Step [577/735], Loss: 0.5580\n",
      "Epoch [2/50], Step [578/735], Loss: 0.9009\n",
      "Epoch [2/50], Step [579/735], Loss: 0.5849\n",
      "Epoch [2/50], Step [580/735], Loss: 0.5051\n",
      "Epoch [2/50], Step [581/735], Loss: 1.3609\n",
      "Epoch [2/50], Step [582/735], Loss: 1.1706\n",
      "Epoch [2/50], Step [583/735], Loss: 0.3073\n",
      "Epoch [2/50], Step [584/735], Loss: 0.7489\n",
      "Epoch [2/50], Step [585/735], Loss: 1.0163\n",
      "Epoch [2/50], Step [586/735], Loss: 1.1576\n",
      "Epoch [2/50], Step [587/735], Loss: 1.9224\n",
      "Epoch [2/50], Step [588/735], Loss: 1.6677\n",
      "Epoch [2/50], Step [589/735], Loss: 0.6220\n",
      "Epoch [2/50], Step [590/735], Loss: 0.7970\n",
      "Epoch [2/50], Step [591/735], Loss: 0.5189\n",
      "Epoch [2/50], Step [592/735], Loss: 0.9910\n",
      "Epoch [2/50], Step [593/735], Loss: 0.4513\n",
      "Epoch [2/50], Step [594/735], Loss: 0.5849\n",
      "Epoch [2/50], Step [595/735], Loss: 0.7726\n",
      "Epoch [2/50], Step [596/735], Loss: 0.9220\n",
      "Epoch [2/50], Step [597/735], Loss: 0.9575\n",
      "Epoch [2/50], Step [598/735], Loss: 0.4705\n",
      "Epoch [2/50], Step [599/735], Loss: 0.7840\n",
      "Epoch [2/50], Step [600/735], Loss: 0.7015\n",
      "Epoch [2/50], Step [601/735], Loss: 0.9162\n",
      "Epoch [2/50], Step [602/735], Loss: 0.9296\n",
      "Epoch [2/50], Step [603/735], Loss: 1.0170\n",
      "Epoch [2/50], Step [604/735], Loss: 0.8994\n",
      "Epoch [2/50], Step [605/735], Loss: 0.8191\n",
      "Epoch [2/50], Step [606/735], Loss: 0.7753\n",
      "Epoch [2/50], Step [607/735], Loss: 2.3495\n",
      "Epoch [2/50], Step [608/735], Loss: 1.4694\n",
      "Epoch [2/50], Step [609/735], Loss: 0.5693\n",
      "Epoch [2/50], Step [610/735], Loss: 1.1448\n",
      "Epoch [2/50], Step [611/735], Loss: 0.4849\n",
      "Epoch [2/50], Step [612/735], Loss: 2.5878\n",
      "Epoch [2/50], Step [613/735], Loss: 0.9123\n",
      "Epoch [2/50], Step [614/735], Loss: 0.5890\n",
      "Epoch [2/50], Step [615/735], Loss: 1.2356\n",
      "Epoch [2/50], Step [616/735], Loss: 0.5201\n",
      "Epoch [2/50], Step [617/735], Loss: 1.0210\n",
      "Epoch [2/50], Step [618/735], Loss: 0.9078\n",
      "Epoch [2/50], Step [619/735], Loss: 0.4756\n",
      "Epoch [2/50], Step [620/735], Loss: 0.9514\n",
      "Epoch [2/50], Step [621/735], Loss: 0.4732\n",
      "Epoch [2/50], Step [622/735], Loss: 0.6902\n",
      "Epoch [2/50], Step [623/735], Loss: 0.5678\n",
      "Epoch [2/50], Step [624/735], Loss: 0.8590\n",
      "Epoch [2/50], Step [625/735], Loss: 0.6908\n",
      "Epoch [2/50], Step [626/735], Loss: 0.7306\n",
      "Epoch [2/50], Step [627/735], Loss: 0.5555\n",
      "Epoch [2/50], Step [628/735], Loss: 2.3025\n",
      "Epoch [2/50], Step [629/735], Loss: 0.7215\n",
      "Epoch [2/50], Step [630/735], Loss: 0.6403\n",
      "Epoch [2/50], Step [631/735], Loss: 0.9201\n",
      "Epoch [2/50], Step [632/735], Loss: 0.6798\n",
      "Epoch [2/50], Step [633/735], Loss: 0.7011\n",
      "Epoch [2/50], Step [634/735], Loss: 0.6963\n",
      "Epoch [2/50], Step [635/735], Loss: 1.5524\n",
      "Epoch [2/50], Step [636/735], Loss: 0.7577\n",
      "Epoch [2/50], Step [637/735], Loss: 0.7103\n",
      "Epoch [2/50], Step [638/735], Loss: 0.4766\n",
      "Epoch [2/50], Step [639/735], Loss: 0.5275\n",
      "Epoch [2/50], Step [640/735], Loss: 0.9137\n",
      "Epoch [2/50], Step [641/735], Loss: 0.7131\n",
      "Epoch [2/50], Step [642/735], Loss: 0.8676\n",
      "Epoch [2/50], Step [643/735], Loss: 0.7709\n",
      "Epoch [2/50], Step [644/735], Loss: 0.9713\n",
      "Epoch [2/50], Step [645/735], Loss: 0.4847\n",
      "Epoch [2/50], Step [646/735], Loss: 0.9955\n",
      "Epoch [2/50], Step [647/735], Loss: 1.1074\n",
      "Epoch [2/50], Step [648/735], Loss: 0.4266\n",
      "Epoch [2/50], Step [649/735], Loss: 0.7667\n",
      "Epoch [2/50], Step [650/735], Loss: 1.0960\n",
      "Epoch [2/50], Step [651/735], Loss: 0.2945\n",
      "Epoch [2/50], Step [652/735], Loss: 0.3823\n",
      "Epoch [2/50], Step [653/735], Loss: 0.5169\n",
      "Epoch [2/50], Step [654/735], Loss: 0.8008\n",
      "Epoch [2/50], Step [655/735], Loss: 0.7659\n",
      "Epoch [2/50], Step [656/735], Loss: 0.5579\n",
      "Epoch [2/50], Step [657/735], Loss: 0.5877\n",
      "Epoch [2/50], Step [658/735], Loss: 0.3968\n",
      "Epoch [2/50], Step [659/735], Loss: 0.4529\n",
      "Epoch [2/50], Step [660/735], Loss: 0.7950\n",
      "Epoch [2/50], Step [661/735], Loss: 0.5740\n",
      "Epoch [2/50], Step [662/735], Loss: 0.3860\n",
      "Epoch [2/50], Step [663/735], Loss: 0.6070\n",
      "Epoch [2/50], Step [664/735], Loss: 0.6983\n",
      "Epoch [2/50], Step [665/735], Loss: 0.9102\n",
      "Epoch [2/50], Step [666/735], Loss: 0.8806\n",
      "Epoch [2/50], Step [667/735], Loss: 0.6900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Step [668/735], Loss: 1.0913\n",
      "Epoch [2/50], Step [669/735], Loss: 0.3199\n",
      "Epoch [2/50], Step [670/735], Loss: 0.8385\n",
      "Epoch [2/50], Step [671/735], Loss: 0.9961\n",
      "Epoch [2/50], Step [672/735], Loss: 0.3841\n",
      "Epoch [2/50], Step [673/735], Loss: 0.4928\n",
      "Epoch [2/50], Step [674/735], Loss: 0.5326\n",
      "Epoch [2/50], Step [675/735], Loss: 1.0850\n",
      "Epoch [2/50], Step [676/735], Loss: 0.6614\n",
      "Epoch [2/50], Step [677/735], Loss: 0.5151\n",
      "Epoch [2/50], Step [678/735], Loss: 0.4113\n",
      "Epoch [2/50], Step [679/735], Loss: 0.5149\n",
      "Epoch [2/50], Step [680/735], Loss: 0.5138\n",
      "Epoch [2/50], Step [681/735], Loss: 0.8673\n",
      "Epoch [2/50], Step [682/735], Loss: 0.5566\n",
      "Epoch [2/50], Step [683/735], Loss: 1.3097\n",
      "Epoch [2/50], Step [684/735], Loss: 0.7195\n",
      "Epoch [2/50], Step [685/735], Loss: 0.2999\n",
      "Epoch [2/50], Step [686/735], Loss: 0.6742\n",
      "Epoch [2/50], Step [687/735], Loss: 0.6701\n",
      "Epoch [2/50], Step [688/735], Loss: 0.8575\n",
      "Epoch [2/50], Step [689/735], Loss: 0.3396\n",
      "Epoch [2/50], Step [690/735], Loss: 1.3121\n",
      "Epoch [2/50], Step [691/735], Loss: 0.5886\n",
      "Epoch [2/50], Step [692/735], Loss: 0.4395\n",
      "Epoch [2/50], Step [693/735], Loss: 1.7644\n",
      "Epoch [2/50], Step [694/735], Loss: 3.0111\n",
      "Epoch [2/50], Step [695/735], Loss: 0.7885\n",
      "Epoch [2/50], Step [696/735], Loss: 0.9970\n",
      "Epoch [2/50], Step [697/735], Loss: 0.5339\n",
      "Epoch [2/50], Step [698/735], Loss: 0.4457\n",
      "Epoch [2/50], Step [699/735], Loss: 0.5812\n",
      "Epoch [2/50], Step [700/735], Loss: 0.4152\n",
      "Epoch [2/50], Step [701/735], Loss: 0.7601\n",
      "Epoch [2/50], Step [702/735], Loss: 0.6269\n",
      "Epoch [2/50], Step [703/735], Loss: 0.5696\n",
      "Epoch [2/50], Step [704/735], Loss: 0.3431\n",
      "Epoch [2/50], Step [705/735], Loss: 0.6805\n",
      "Epoch [2/50], Step [706/735], Loss: 0.8305\n",
      "Epoch [2/50], Step [707/735], Loss: 0.4476\n",
      "Epoch [2/50], Step [708/735], Loss: 1.2618\n",
      "Epoch [2/50], Step [709/735], Loss: 0.7636\n",
      "Epoch [2/50], Step [710/735], Loss: 0.8033\n",
      "Epoch [2/50], Step [711/735], Loss: 0.3047\n",
      "Epoch [2/50], Step [712/735], Loss: 0.4897\n",
      "Epoch [2/50], Step [713/735], Loss: 1.3541\n",
      "Epoch [2/50], Step [714/735], Loss: 0.3369\n",
      "Epoch [2/50], Step [715/735], Loss: 0.8078\n",
      "Epoch [2/50], Step [716/735], Loss: 0.3134\n",
      "Epoch [2/50], Step [717/735], Loss: 0.5571\n",
      "Epoch [2/50], Step [718/735], Loss: 0.6050\n",
      "Epoch [2/50], Step [719/735], Loss: 0.7674\n",
      "Epoch [2/50], Step [720/735], Loss: 0.6589\n",
      "Epoch [2/50], Step [721/735], Loss: 0.2783\n",
      "Epoch [2/50], Step [722/735], Loss: 0.4866\n",
      "Epoch [2/50], Step [723/735], Loss: 0.9261\n",
      "Epoch [2/50], Step [724/735], Loss: 0.5990\n",
      "Epoch [2/50], Step [725/735], Loss: 0.5183\n",
      "Epoch [2/50], Step [726/735], Loss: 1.5754\n",
      "Epoch [2/50], Step [727/735], Loss: 0.4101\n",
      "Epoch [2/50], Step [728/735], Loss: 0.4223\n",
      "Epoch [2/50], Step [729/735], Loss: 0.5385\n",
      "Epoch [2/50], Step [730/735], Loss: 0.7275\n",
      "Epoch [2/50], Step [731/735], Loss: 0.5301\n",
      "Epoch [2/50], Step [732/735], Loss: 0.5428\n",
      "Epoch [2/50], Step [733/735], Loss: 0.8091\n",
      "Epoch [2/50], Step [734/735], Loss: 0.6371\n",
      "Epoch [2/50], Step [735/735], Loss: 0.5434\n",
      "Epoch [3/50], Step [1/735], Loss: 0.4381\n",
      "Epoch [3/50], Step [2/735], Loss: 0.8119\n",
      "Epoch [3/50], Step [3/735], Loss: 0.5648\n",
      "Epoch [3/50], Step [4/735], Loss: 0.5984\n",
      "Epoch [3/50], Step [5/735], Loss: 2.3438\n",
      "Epoch [3/50], Step [6/735], Loss: 0.4250\n",
      "Epoch [3/50], Step [7/735], Loss: 0.4537\n",
      "Epoch [3/50], Step [8/735], Loss: 1.0157\n",
      "Epoch [3/50], Step [9/735], Loss: 0.9622\n",
      "Epoch [3/50], Step [10/735], Loss: 0.5929\n",
      "Epoch [3/50], Step [11/735], Loss: 1.1417\n",
      "Epoch [3/50], Step [12/735], Loss: 0.5830\n",
      "Epoch [3/50], Step [13/735], Loss: 0.6515\n",
      "Epoch [3/50], Step [14/735], Loss: 0.6944\n",
      "Epoch [3/50], Step [15/735], Loss: 0.2719\n",
      "Epoch [3/50], Step [16/735], Loss: 0.7873\n",
      "Epoch [3/50], Step [17/735], Loss: 0.5334\n",
      "Epoch [3/50], Step [18/735], Loss: 0.6153\n",
      "Epoch [3/50], Step [19/735], Loss: 0.7761\n",
      "Epoch [3/50], Step [20/735], Loss: 0.7516\n",
      "Epoch [3/50], Step [21/735], Loss: 0.4405\n",
      "Epoch [3/50], Step [22/735], Loss: 1.2985\n",
      "Epoch [3/50], Step [23/735], Loss: 0.5814\n",
      "Epoch [3/50], Step [24/735], Loss: 0.6286\n",
      "Epoch [3/50], Step [25/735], Loss: 0.8932\n",
      "Epoch [3/50], Step [26/735], Loss: 0.5232\n",
      "Epoch [3/50], Step [27/735], Loss: 0.9176\n",
      "Epoch [3/50], Step [28/735], Loss: 0.8924\n",
      "Epoch [3/50], Step [29/735], Loss: 0.3673\n",
      "Epoch [3/50], Step [30/735], Loss: 0.8080\n",
      "Epoch [3/50], Step [31/735], Loss: 0.9865\n",
      "Epoch [3/50], Step [32/735], Loss: 0.6402\n",
      "Epoch [3/50], Step [33/735], Loss: 1.3045\n",
      "Epoch [3/50], Step [34/735], Loss: 0.7042\n",
      "Epoch [3/50], Step [35/735], Loss: 0.4494\n",
      "Epoch [3/50], Step [36/735], Loss: 0.5170\n",
      "Epoch [3/50], Step [37/735], Loss: 0.5691\n",
      "Epoch [3/50], Step [38/735], Loss: 0.3288\n",
      "Epoch [3/50], Step [39/735], Loss: 0.6525\n",
      "Epoch [3/50], Step [40/735], Loss: 0.8541\n",
      "Epoch [3/50], Step [41/735], Loss: 0.5005\n",
      "Epoch [3/50], Step [42/735], Loss: 0.4331\n",
      "Epoch [3/50], Step [43/735], Loss: 0.3401\n",
      "Epoch [3/50], Step [44/735], Loss: 3.0571\n",
      "Epoch [3/50], Step [45/735], Loss: 0.6383\n",
      "Epoch [3/50], Step [46/735], Loss: 1.0637\n",
      "Epoch [3/50], Step [47/735], Loss: 0.3706\n",
      "Epoch [3/50], Step [48/735], Loss: 0.6053\n",
      "Epoch [3/50], Step [49/735], Loss: 2.7988\n",
      "Epoch [3/50], Step [50/735], Loss: 0.5107\n",
      "Epoch [3/50], Step [51/735], Loss: 0.6550\n",
      "Epoch [3/50], Step [52/735], Loss: 0.6218\n",
      "Epoch [3/50], Step [53/735], Loss: 0.8189\n",
      "Epoch [3/50], Step [54/735], Loss: 0.3027\n",
      "Epoch [3/50], Step [55/735], Loss: 0.4618\n",
      "Epoch [3/50], Step [56/735], Loss: 0.6985\n",
      "Epoch [3/50], Step [57/735], Loss: 0.7502\n",
      "Epoch [3/50], Step [58/735], Loss: 0.4656\n",
      "Epoch [3/50], Step [59/735], Loss: 0.9670\n",
      "Epoch [3/50], Step [60/735], Loss: 0.4132\n",
      "Epoch [3/50], Step [61/735], Loss: 1.5786\n",
      "Epoch [3/50], Step [62/735], Loss: 0.2802\n",
      "Epoch [3/50], Step [63/735], Loss: 0.5508\n",
      "Epoch [3/50], Step [64/735], Loss: 0.3325\n",
      "Epoch [3/50], Step [65/735], Loss: 0.8280\n",
      "Epoch [3/50], Step [66/735], Loss: 0.5136\n",
      "Epoch [3/50], Step [67/735], Loss: 0.6816\n",
      "Epoch [3/50], Step [68/735], Loss: 0.6267\n",
      "Epoch [3/50], Step [69/735], Loss: 0.4578\n",
      "Epoch [3/50], Step [70/735], Loss: 0.3006\n",
      "Epoch [3/50], Step [71/735], Loss: 0.4751\n",
      "Epoch [3/50], Step [72/735], Loss: 0.4310\n",
      "Epoch [3/50], Step [73/735], Loss: 0.7140\n",
      "Epoch [3/50], Step [74/735], Loss: 0.5725\n",
      "Epoch [3/50], Step [75/735], Loss: 0.9980\n",
      "Epoch [3/50], Step [76/735], Loss: 0.2734\n",
      "Epoch [3/50], Step [77/735], Loss: 0.6927\n",
      "Epoch [3/50], Step [78/735], Loss: 0.5943\n",
      "Epoch [3/50], Step [79/735], Loss: 0.5518\n",
      "Epoch [3/50], Step [80/735], Loss: 1.4117\n",
      "Epoch [3/50], Step [81/735], Loss: 0.3540\n",
      "Epoch [3/50], Step [82/735], Loss: 0.4475\n",
      "Epoch [3/50], Step [83/735], Loss: 2.2066\n",
      "Epoch [3/50], Step [84/735], Loss: 0.4109\n",
      "Epoch [3/50], Step [85/735], Loss: 0.3838\n",
      "Epoch [3/50], Step [86/735], Loss: 0.5187\n",
      "Epoch [3/50], Step [87/735], Loss: 0.9756\n",
      "Epoch [3/50], Step [88/735], Loss: 0.6287\n",
      "Epoch [3/50], Step [89/735], Loss: 0.5882\n",
      "Epoch [3/50], Step [90/735], Loss: 0.3719\n",
      "Epoch [3/50], Step [91/735], Loss: 0.4771\n",
      "Epoch [3/50], Step [92/735], Loss: 0.4306\n",
      "Epoch [3/50], Step [93/735], Loss: 0.3407\n",
      "Epoch [3/50], Step [94/735], Loss: 1.1462\n",
      "Epoch [3/50], Step [95/735], Loss: 0.5197\n",
      "Epoch [3/50], Step [96/735], Loss: 0.7050\n",
      "Epoch [3/50], Step [97/735], Loss: 0.5708\n",
      "Epoch [3/50], Step [98/735], Loss: 0.2963\n",
      "Epoch [3/50], Step [99/735], Loss: 0.9255\n",
      "Epoch [3/50], Step [100/735], Loss: 0.6177\n",
      "Epoch [3/50], Step [101/735], Loss: 0.4808\n",
      "Epoch [3/50], Step [102/735], Loss: 0.7232\n",
      "Epoch [3/50], Step [103/735], Loss: 0.3682\n",
      "Epoch [3/50], Step [104/735], Loss: 0.8362\n",
      "Epoch [3/50], Step [105/735], Loss: 1.1391\n",
      "Epoch [3/50], Step [106/735], Loss: 0.3919\n",
      "Epoch [3/50], Step [107/735], Loss: 1.9760\n",
      "Epoch [3/50], Step [108/735], Loss: 0.3677\n",
      "Epoch [3/50], Step [109/735], Loss: 0.8105\n",
      "Epoch [3/50], Step [110/735], Loss: 0.7361\n",
      "Epoch [3/50], Step [111/735], Loss: 0.6361\n",
      "Epoch [3/50], Step [112/735], Loss: 0.8036\n",
      "Epoch [3/50], Step [113/735], Loss: 0.8339\n",
      "Epoch [3/50], Step [114/735], Loss: 0.5074\n",
      "Epoch [3/50], Step [115/735], Loss: 0.9818\n",
      "Epoch [3/50], Step [116/735], Loss: 0.4312\n",
      "Epoch [3/50], Step [117/735], Loss: 0.7061\n",
      "Epoch [3/50], Step [118/735], Loss: 0.3422\n",
      "Epoch [3/50], Step [119/735], Loss: 0.4077\n",
      "Epoch [3/50], Step [120/735], Loss: 0.4731\n",
      "Epoch [3/50], Step [121/735], Loss: 0.6098\n",
      "Epoch [3/50], Step [122/735], Loss: 3.8394\n",
      "Epoch [3/50], Step [123/735], Loss: 0.6639\n",
      "Epoch [3/50], Step [124/735], Loss: 0.8314\n",
      "Epoch [3/50], Step [125/735], Loss: 0.3524\n",
      "Epoch [3/50], Step [126/735], Loss: 0.6440\n",
      "Epoch [3/50], Step [127/735], Loss: 0.7137\n",
      "Epoch [3/50], Step [128/735], Loss: 0.9479\n",
      "Epoch [3/50], Step [129/735], Loss: 0.2483\n",
      "Epoch [3/50], Step [130/735], Loss: 0.7756\n",
      "Epoch [3/50], Step [131/735], Loss: 0.4659\n",
      "Epoch [3/50], Step [132/735], Loss: 0.4643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Step [133/735], Loss: 0.3010\n",
      "Epoch [3/50], Step [134/735], Loss: 0.3545\n",
      "Epoch [3/50], Step [135/735], Loss: 0.7505\n",
      "Epoch [3/50], Step [136/735], Loss: 0.4438\n",
      "Epoch [3/50], Step [137/735], Loss: 0.4276\n",
      "Epoch [3/50], Step [138/735], Loss: 0.6117\n",
      "Epoch [3/50], Step [139/735], Loss: 0.3187\n",
      "Epoch [3/50], Step [140/735], Loss: 0.7975\n",
      "Epoch [3/50], Step [141/735], Loss: 0.5097\n",
      "Epoch [3/50], Step [142/735], Loss: 0.6505\n",
      "Epoch [3/50], Step [143/735], Loss: 0.4468\n",
      "Epoch [3/50], Step [144/735], Loss: 0.4675\n",
      "Epoch [3/50], Step [145/735], Loss: 0.7304\n",
      "Epoch [3/50], Step [146/735], Loss: 0.8172\n",
      "Epoch [3/50], Step [147/735], Loss: 0.4248\n",
      "Epoch [3/50], Step [148/735], Loss: 0.2623\n",
      "Epoch [3/50], Step [149/735], Loss: 0.4542\n",
      "Epoch [3/50], Step [150/735], Loss: 0.3639\n",
      "Epoch [3/50], Step [151/735], Loss: 0.7225\n",
      "Epoch [3/50], Step [152/735], Loss: 0.2729\n",
      "Epoch [3/50], Step [153/735], Loss: 0.8326\n",
      "Epoch [3/50], Step [154/735], Loss: 0.6703\n",
      "Epoch [3/50], Step [155/735], Loss: 0.6727\n",
      "Epoch [3/50], Step [156/735], Loss: 0.3967\n",
      "Epoch [3/50], Step [157/735], Loss: 0.2829\n",
      "Epoch [3/50], Step [158/735], Loss: 0.6421\n",
      "Epoch [3/50], Step [159/735], Loss: 0.6726\n",
      "Epoch [3/50], Step [160/735], Loss: 0.8751\n",
      "Epoch [3/50], Step [161/735], Loss: 0.5010\n",
      "Epoch [3/50], Step [162/735], Loss: 0.5085\n",
      "Epoch [3/50], Step [163/735], Loss: 0.3218\n",
      "Epoch [3/50], Step [164/735], Loss: 0.3953\n",
      "Epoch [3/50], Step [165/735], Loss: 0.6667\n",
      "Epoch [3/50], Step [166/735], Loss: 0.4417\n",
      "Epoch [3/50], Step [167/735], Loss: 0.5355\n",
      "Epoch [3/50], Step [168/735], Loss: 0.8624\n",
      "Epoch [3/50], Step [169/735], Loss: 0.7378\n",
      "Epoch [3/50], Step [170/735], Loss: 0.7103\n",
      "Epoch [3/50], Step [171/735], Loss: 0.5680\n",
      "Epoch [3/50], Step [172/735], Loss: 0.5865\n",
      "Epoch [3/50], Step [173/735], Loss: 0.5022\n",
      "Epoch [3/50], Step [174/735], Loss: 1.0580\n",
      "Epoch [3/50], Step [175/735], Loss: 0.4001\n",
      "Epoch [3/50], Step [176/735], Loss: 0.3073\n",
      "Epoch [3/50], Step [177/735], Loss: 0.5689\n",
      "Epoch [3/50], Step [178/735], Loss: 0.6373\n",
      "Epoch [3/50], Step [179/735], Loss: 0.3226\n",
      "Epoch [3/50], Step [180/735], Loss: 0.6019\n",
      "Epoch [3/50], Step [181/735], Loss: 0.5193\n",
      "Epoch [3/50], Step [182/735], Loss: 0.2889\n",
      "Epoch [3/50], Step [183/735], Loss: 0.3803\n",
      "Epoch [3/50], Step [184/735], Loss: 0.6055\n",
      "Epoch [3/50], Step [185/735], Loss: 0.2887\n",
      "Epoch [3/50], Step [186/735], Loss: 0.7026\n",
      "Epoch [3/50], Step [187/735], Loss: 0.4569\n",
      "Epoch [3/50], Step [188/735], Loss: 0.6878\n",
      "Epoch [3/50], Step [189/735], Loss: 0.9159\n",
      "Epoch [3/50], Step [190/735], Loss: 0.5548\n",
      "Epoch [3/50], Step [191/735], Loss: 0.2960\n",
      "Epoch [3/50], Step [192/735], Loss: 0.4138\n",
      "Epoch [3/50], Step [193/735], Loss: 0.8621\n",
      "Epoch [3/50], Step [194/735], Loss: 2.1461\n",
      "Epoch [3/50], Step [195/735], Loss: 0.3646\n",
      "Epoch [3/50], Step [196/735], Loss: 0.6382\n",
      "Epoch [3/50], Step [197/735], Loss: 0.7117\n",
      "Epoch [3/50], Step [198/735], Loss: 0.6768\n",
      "Epoch [3/50], Step [199/735], Loss: 0.3765\n",
      "Epoch [3/50], Step [200/735], Loss: 0.4347\n",
      "Epoch [3/50], Step [201/735], Loss: 0.4404\n",
      "Epoch [3/50], Step [202/735], Loss: 0.2537\n",
      "Epoch [3/50], Step [203/735], Loss: 0.8759\n",
      "Epoch [3/50], Step [204/735], Loss: 0.6028\n",
      "Epoch [3/50], Step [205/735], Loss: 0.4374\n",
      "Epoch [3/50], Step [206/735], Loss: 1.1916\n",
      "Epoch [3/50], Step [207/735], Loss: 0.6614\n",
      "Epoch [3/50], Step [208/735], Loss: 0.4817\n",
      "Epoch [3/50], Step [209/735], Loss: 0.3832\n",
      "Epoch [3/50], Step [210/735], Loss: 0.3378\n",
      "Epoch [3/50], Step [211/735], Loss: 0.3267\n",
      "Epoch [3/50], Step [212/735], Loss: 0.5272\n",
      "Epoch [3/50], Step [213/735], Loss: 0.4506\n",
      "Epoch [3/50], Step [214/735], Loss: 0.4408\n",
      "Epoch [3/50], Step [215/735], Loss: 0.2803\n",
      "Epoch [3/50], Step [216/735], Loss: 0.5610\n",
      "Epoch [3/50], Step [217/735], Loss: 1.1176\n",
      "Epoch [3/50], Step [218/735], Loss: 0.8749\n",
      "Epoch [3/50], Step [219/735], Loss: 0.7196\n",
      "Epoch [3/50], Step [220/735], Loss: 0.5893\n",
      "Epoch [3/50], Step [221/735], Loss: 0.3538\n",
      "Epoch [3/50], Step [222/735], Loss: 0.5495\n",
      "Epoch [3/50], Step [223/735], Loss: 0.8989\n",
      "Epoch [3/50], Step [224/735], Loss: 0.3430\n",
      "Epoch [3/50], Step [225/735], Loss: 0.6103\n",
      "Epoch [3/50], Step [226/735], Loss: 0.4118\n",
      "Epoch [3/50], Step [227/735], Loss: 0.4806\n",
      "Epoch [3/50], Step [228/735], Loss: 0.4722\n",
      "Epoch [3/50], Step [229/735], Loss: 0.7212\n",
      "Epoch [3/50], Step [230/735], Loss: 0.4719\n",
      "Epoch [3/50], Step [231/735], Loss: 0.4129\n",
      "Epoch [3/50], Step [232/735], Loss: 0.3854\n",
      "Epoch [3/50], Step [233/735], Loss: 0.2330\n",
      "Epoch [3/50], Step [234/735], Loss: 0.3188\n",
      "Epoch [3/50], Step [235/735], Loss: 0.6212\n",
      "Epoch [3/50], Step [236/735], Loss: 1.2387\n",
      "Epoch [3/50], Step [237/735], Loss: 0.4804\n",
      "Epoch [3/50], Step [238/735], Loss: 0.3445\n",
      "Epoch [3/50], Step [239/735], Loss: 0.6876\n",
      "Epoch [3/50], Step [240/735], Loss: 0.7144\n",
      "Epoch [3/50], Step [241/735], Loss: 0.6709\n",
      "Epoch [3/50], Step [242/735], Loss: 0.2970\n",
      "Epoch [3/50], Step [243/735], Loss: 0.5770\n",
      "Epoch [3/50], Step [244/735], Loss: 0.6324\n",
      "Epoch [3/50], Step [245/735], Loss: 0.2514\n",
      "Epoch [3/50], Step [246/735], Loss: 0.8010\n",
      "Epoch [3/50], Step [247/735], Loss: 0.7412\n",
      "Epoch [3/50], Step [248/735], Loss: 1.1992\n",
      "Epoch [3/50], Step [249/735], Loss: 0.4056\n",
      "Epoch [3/50], Step [250/735], Loss: 0.3173\n",
      "Epoch [3/50], Step [251/735], Loss: 0.4191\n",
      "Epoch [3/50], Step [252/735], Loss: 0.4419\n",
      "Epoch [3/50], Step [253/735], Loss: 0.2882\n",
      "Epoch [3/50], Step [254/735], Loss: 0.8425\n",
      "Epoch [3/50], Step [255/735], Loss: 0.2723\n",
      "Epoch [3/50], Step [256/735], Loss: 0.2624\n",
      "Epoch [3/50], Step [257/735], Loss: 0.2901\n",
      "Epoch [3/50], Step [258/735], Loss: 0.5414\n",
      "Epoch [3/50], Step [259/735], Loss: 0.2852\n",
      "Epoch [3/50], Step [260/735], Loss: 0.2841\n",
      "Epoch [3/50], Step [261/735], Loss: 0.2154\n",
      "Epoch [3/50], Step [262/735], Loss: 0.3220\n",
      "Epoch [3/50], Step [263/735], Loss: 0.2927\n",
      "Epoch [3/50], Step [264/735], Loss: 0.3154\n",
      "Epoch [3/50], Step [265/735], Loss: 0.4567\n",
      "Epoch [3/50], Step [266/735], Loss: 1.1367\n",
      "Epoch [3/50], Step [267/735], Loss: 0.3260\n",
      "Epoch [3/50], Step [268/735], Loss: 0.3332\n",
      "Epoch [3/50], Step [269/735], Loss: 0.7125\n",
      "Epoch [3/50], Step [270/735], Loss: 0.3598\n",
      "Epoch [3/50], Step [271/735], Loss: 0.6743\n",
      "Epoch [3/50], Step [272/735], Loss: 0.6112\n",
      "Epoch [3/50], Step [273/735], Loss: 0.2218\n",
      "Epoch [3/50], Step [274/735], Loss: 0.5985\n",
      "Epoch [3/50], Step [275/735], Loss: 0.5721\n",
      "Epoch [3/50], Step [276/735], Loss: 0.6025\n",
      "Epoch [3/50], Step [277/735], Loss: 0.2420\n",
      "Epoch [3/50], Step [278/735], Loss: 0.7690\n",
      "Epoch [3/50], Step [279/735], Loss: 0.3731\n",
      "Epoch [3/50], Step [280/735], Loss: 0.3520\n",
      "Epoch [3/50], Step [281/735], Loss: 0.4572\n",
      "Epoch [3/50], Step [282/735], Loss: 0.3118\n",
      "Epoch [3/50], Step [283/735], Loss: 1.0108\n",
      "Epoch [3/50], Step [284/735], Loss: 0.7411\n",
      "Epoch [3/50], Step [285/735], Loss: 1.1435\n",
      "Epoch [3/50], Step [286/735], Loss: 0.6931\n",
      "Epoch [3/50], Step [287/735], Loss: 0.6465\n",
      "Epoch [3/50], Step [288/735], Loss: 0.3005\n",
      "Epoch [3/50], Step [289/735], Loss: 0.4533\n",
      "Epoch [3/50], Step [290/735], Loss: 0.7480\n",
      "Epoch [3/50], Step [291/735], Loss: 0.3388\n",
      "Epoch [3/50], Step [292/735], Loss: 0.2932\n",
      "Epoch [3/50], Step [293/735], Loss: 0.5918\n",
      "Epoch [3/50], Step [294/735], Loss: 0.4713\n",
      "Epoch [3/50], Step [295/735], Loss: 0.2921\n",
      "Epoch [3/50], Step [296/735], Loss: 0.6359\n",
      "Epoch [3/50], Step [297/735], Loss: 0.7205\n",
      "Epoch [3/50], Step [298/735], Loss: 0.4836\n",
      "Epoch [3/50], Step [299/735], Loss: 0.4473\n",
      "Epoch [3/50], Step [300/735], Loss: 0.7153\n",
      "Epoch [3/50], Step [301/735], Loss: 0.2551\n",
      "Epoch [3/50], Step [302/735], Loss: 0.6945\n",
      "Epoch [3/50], Step [303/735], Loss: 0.4796\n",
      "Epoch [3/50], Step [304/735], Loss: 0.3084\n",
      "Epoch [3/50], Step [305/735], Loss: 0.3848\n",
      "Epoch [3/50], Step [306/735], Loss: 0.3627\n",
      "Epoch [3/50], Step [307/735], Loss: 0.3938\n",
      "Epoch [3/50], Step [308/735], Loss: 0.2115\n",
      "Epoch [3/50], Step [309/735], Loss: 0.3111\n",
      "Epoch [3/50], Step [310/735], Loss: 0.5165\n",
      "Epoch [3/50], Step [311/735], Loss: 0.4466\n",
      "Epoch [3/50], Step [312/735], Loss: 0.4376\n",
      "Epoch [3/50], Step [313/735], Loss: 0.2330\n",
      "Epoch [3/50], Step [314/735], Loss: 0.6324\n",
      "Epoch [3/50], Step [315/735], Loss: 0.2869\n",
      "Epoch [3/50], Step [316/735], Loss: 0.3636\n",
      "Epoch [3/50], Step [317/735], Loss: 0.6717\n",
      "Epoch [3/50], Step [318/735], Loss: 0.2829\n",
      "Epoch [3/50], Step [319/735], Loss: 1.0815\n",
      "Epoch [3/50], Step [320/735], Loss: 0.2343\n",
      "Epoch [3/50], Step [321/735], Loss: 0.3391\n",
      "Epoch [3/50], Step [322/735], Loss: 0.8556\n",
      "Epoch [3/50], Step [323/735], Loss: 0.4107\n",
      "Epoch [3/50], Step [324/735], Loss: 0.2471\n",
      "Epoch [3/50], Step [325/735], Loss: 0.2987\n",
      "Epoch [3/50], Step [326/735], Loss: 0.4958\n",
      "Epoch [3/50], Step [327/735], Loss: 0.5306\n",
      "Epoch [3/50], Step [328/735], Loss: 0.3060\n",
      "Epoch [3/50], Step [329/735], Loss: 0.7391\n",
      "Epoch [3/50], Step [330/735], Loss: 0.2868\n",
      "Epoch [3/50], Step [331/735], Loss: 0.6335\n",
      "Epoch [3/50], Step [332/735], Loss: 0.5013\n",
      "Epoch [3/50], Step [333/735], Loss: 2.3119\n",
      "Epoch [3/50], Step [334/735], Loss: 0.3905\n",
      "Epoch [3/50], Step [335/735], Loss: 0.8946\n",
      "Epoch [3/50], Step [336/735], Loss: 0.4776\n",
      "Epoch [3/50], Step [337/735], Loss: 0.8902\n",
      "Epoch [3/50], Step [338/735], Loss: 0.3339\n",
      "Epoch [3/50], Step [339/735], Loss: 0.4079\n",
      "Epoch [3/50], Step [340/735], Loss: 0.3692\n",
      "Epoch [3/50], Step [341/735], Loss: 0.7917\n",
      "Epoch [3/50], Step [342/735], Loss: 0.5174\n",
      "Epoch [3/50], Step [343/735], Loss: 1.1808\n",
      "Epoch [3/50], Step [344/735], Loss: 0.4341\n",
      "Epoch [3/50], Step [345/735], Loss: 0.3942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Step [346/735], Loss: 0.4552\n",
      "Epoch [3/50], Step [347/735], Loss: 0.2578\n",
      "Epoch [3/50], Step [348/735], Loss: 0.1739\n",
      "Epoch [3/50], Step [349/735], Loss: 0.2917\n",
      "Epoch [3/50], Step [350/735], Loss: 0.6285\n",
      "Epoch [3/50], Step [351/735], Loss: 0.8949\n",
      "Epoch [3/50], Step [352/735], Loss: 0.6649\n",
      "Epoch [3/50], Step [353/735], Loss: 0.2580\n",
      "Epoch [3/50], Step [354/735], Loss: 0.2610\n",
      "Epoch [3/50], Step [355/735], Loss: 0.2616\n",
      "Epoch [3/50], Step [356/735], Loss: 0.4134\n",
      "Epoch [3/50], Step [357/735], Loss: 0.4906\n",
      "Epoch [3/50], Step [358/735], Loss: 0.7841\n",
      "Epoch [3/50], Step [359/735], Loss: 0.5047\n",
      "Epoch [3/50], Step [360/735], Loss: 0.3480\n",
      "Epoch [3/50], Step [361/735], Loss: 0.5374\n",
      "Epoch [3/50], Step [362/735], Loss: 0.6942\n",
      "Epoch [3/50], Step [363/735], Loss: 0.7203\n",
      "Epoch [3/50], Step [364/735], Loss: 0.5471\n",
      "Epoch [3/50], Step [365/735], Loss: 0.2844\n",
      "Epoch [3/50], Step [366/735], Loss: 2.2437\n",
      "Epoch [3/50], Step [367/735], Loss: 0.2759\n",
      "Epoch [3/50], Step [368/735], Loss: 0.1840\n",
      "Epoch [3/50], Step [369/735], Loss: 0.2607\n",
      "Epoch [3/50], Step [370/735], Loss: 0.3200\n",
      "Epoch [3/50], Step [371/735], Loss: 0.3251\n",
      "Epoch [3/50], Step [372/735], Loss: 0.4217\n",
      "Epoch [3/50], Step [373/735], Loss: 0.2226\n",
      "Epoch [3/50], Step [374/735], Loss: 0.4375\n",
      "Epoch [3/50], Step [375/735], Loss: 1.0346\n",
      "Epoch [3/50], Step [376/735], Loss: 0.3920\n",
      "Epoch [3/50], Step [377/735], Loss: 0.5807\n",
      "Epoch [3/50], Step [378/735], Loss: 2.1436\n",
      "Epoch [3/50], Step [379/735], Loss: 0.2186\n",
      "Epoch [3/50], Step [380/735], Loss: 0.2915\n",
      "Epoch [3/50], Step [381/735], Loss: 0.2601\n",
      "Epoch [3/50], Step [382/735], Loss: 0.1809\n",
      "Epoch [3/50], Step [383/735], Loss: 0.3571\n",
      "Epoch [3/50], Step [384/735], Loss: 0.5117\n",
      "Epoch [3/50], Step [385/735], Loss: 0.7534\n",
      "Epoch [3/50], Step [386/735], Loss: 2.0835\n",
      "Epoch [3/50], Step [387/735], Loss: 0.4496\n",
      "Epoch [3/50], Step [388/735], Loss: 0.2785\n",
      "Epoch [3/50], Step [389/735], Loss: 0.5800\n",
      "Epoch [3/50], Step [390/735], Loss: 0.2989\n",
      "Epoch [3/50], Step [391/735], Loss: 0.3673\n",
      "Epoch [3/50], Step [392/735], Loss: 0.3659\n",
      "Epoch [3/50], Step [393/735], Loss: 0.4837\n",
      "Epoch [3/50], Step [394/735], Loss: 0.4897\n",
      "Epoch [3/50], Step [395/735], Loss: 0.3844\n",
      "Epoch [3/50], Step [396/735], Loss: 0.3112\n",
      "Epoch [3/50], Step [397/735], Loss: 0.4001\n",
      "Epoch [3/50], Step [398/735], Loss: 0.3495\n",
      "Epoch [3/50], Step [399/735], Loss: 0.3099\n",
      "Epoch [3/50], Step [400/735], Loss: 0.4078\n",
      "Epoch [3/50], Step [401/735], Loss: 0.2144\n",
      "Epoch [3/50], Step [402/735], Loss: 0.2346\n",
      "Epoch [3/50], Step [403/735], Loss: 0.3689\n",
      "Epoch [3/50], Step [404/735], Loss: 0.7564\n",
      "Epoch [3/50], Step [405/735], Loss: 0.6168\n",
      "Epoch [3/50], Step [406/735], Loss: 0.3226\n",
      "Epoch [3/50], Step [407/735], Loss: 0.3066\n",
      "Epoch [3/50], Step [408/735], Loss: 0.1899\n",
      "Epoch [3/50], Step [409/735], Loss: 0.7238\n",
      "Epoch [3/50], Step [410/735], Loss: 0.4123\n",
      "Epoch [3/50], Step [411/735], Loss: 0.4044\n",
      "Epoch [3/50], Step [412/735], Loss: 0.5644\n",
      "Epoch [3/50], Step [413/735], Loss: 0.8467\n",
      "Epoch [3/50], Step [414/735], Loss: 0.7507\n",
      "Epoch [3/50], Step [415/735], Loss: 0.4289\n",
      "Epoch [3/50], Step [416/735], Loss: 0.2866\n",
      "Epoch [3/50], Step [417/735], Loss: 0.4480\n",
      "Epoch [3/50], Step [418/735], Loss: 0.2000\n",
      "Epoch [3/50], Step [419/735], Loss: 0.3610\n",
      "Epoch [3/50], Step [420/735], Loss: 0.5626\n",
      "Epoch [3/50], Step [421/735], Loss: 0.2011\n",
      "Epoch [3/50], Step [422/735], Loss: 0.3073\n",
      "Epoch [3/50], Step [423/735], Loss: 1.7349\n",
      "Epoch [3/50], Step [424/735], Loss: 0.8010\n",
      "Epoch [3/50], Step [425/735], Loss: 0.5946\n",
      "Epoch [3/50], Step [426/735], Loss: 0.2579\n",
      "Epoch [3/50], Step [427/735], Loss: 0.3390\n",
      "Epoch [3/50], Step [428/735], Loss: 0.4535\n",
      "Epoch [3/50], Step [429/735], Loss: 0.2286\n",
      "Epoch [3/50], Step [430/735], Loss: 0.2337\n",
      "Epoch [3/50], Step [431/735], Loss: 0.1489\n",
      "Epoch [3/50], Step [432/735], Loss: 0.3878\n",
      "Epoch [3/50], Step [433/735], Loss: 0.2677\n",
      "Epoch [3/50], Step [434/735], Loss: 0.3718\n",
      "Epoch [3/50], Step [435/735], Loss: 0.5570\n",
      "Epoch [3/50], Step [436/735], Loss: 0.2579\n",
      "Epoch [3/50], Step [437/735], Loss: 0.5735\n",
      "Epoch [3/50], Step [438/735], Loss: 0.4454\n",
      "Epoch [3/50], Step [439/735], Loss: 0.7666\n",
      "Epoch [3/50], Step [440/735], Loss: 0.3500\n",
      "Epoch [3/50], Step [441/735], Loss: 0.8185\n",
      "Epoch [3/50], Step [442/735], Loss: 0.3436\n",
      "Epoch [3/50], Step [443/735], Loss: 0.3289\n",
      "Epoch [3/50], Step [444/735], Loss: 0.4711\n",
      "Epoch [3/50], Step [445/735], Loss: 0.7203\n",
      "Epoch [3/50], Step [446/735], Loss: 0.4250\n",
      "Epoch [3/50], Step [447/735], Loss: 0.2680\n",
      "Epoch [3/50], Step [448/735], Loss: 0.2167\n",
      "Epoch [3/50], Step [449/735], Loss: 0.3068\n",
      "Epoch [3/50], Step [450/735], Loss: 0.2078\n",
      "Epoch [3/50], Step [451/735], Loss: 0.3353\n",
      "Epoch [3/50], Step [452/735], Loss: 0.5866\n",
      "Epoch [3/50], Step [453/735], Loss: 0.3578\n",
      "Epoch [3/50], Step [454/735], Loss: 0.5335\n",
      "Epoch [3/50], Step [455/735], Loss: 0.3960\n",
      "Epoch [3/50], Step [456/735], Loss: 0.2989\n",
      "Epoch [3/50], Step [457/735], Loss: 0.1749\n",
      "Epoch [3/50], Step [458/735], Loss: 0.2795\n",
      "Epoch [3/50], Step [459/735], Loss: 0.3873\n",
      "Epoch [3/50], Step [460/735], Loss: 3.1363\n",
      "Epoch [3/50], Step [461/735], Loss: 0.3875\n",
      "Epoch [3/50], Step [462/735], Loss: 0.3352\n",
      "Epoch [3/50], Step [463/735], Loss: 0.5196\n",
      "Epoch [3/50], Step [464/735], Loss: 0.5043\n",
      "Epoch [3/50], Step [465/735], Loss: 0.5831\n",
      "Epoch [3/50], Step [466/735], Loss: 0.5129\n",
      "Epoch [3/50], Step [467/735], Loss: 0.4782\n",
      "Epoch [3/50], Step [468/735], Loss: 0.3450\n",
      "Epoch [3/50], Step [469/735], Loss: 1.7775\n",
      "Epoch [3/50], Step [470/735], Loss: 0.5713\n",
      "Epoch [3/50], Step [471/735], Loss: 0.7802\n",
      "Epoch [3/50], Step [472/735], Loss: 0.4997\n",
      "Epoch [3/50], Step [473/735], Loss: 0.3491\n",
      "Epoch [3/50], Step [474/735], Loss: 0.2802\n",
      "Epoch [3/50], Step [475/735], Loss: 0.3638\n",
      "Epoch [3/50], Step [476/735], Loss: 0.3352\n",
      "Epoch [3/50], Step [477/735], Loss: 0.6725\n",
      "Epoch [3/50], Step [478/735], Loss: 0.3513\n",
      "Epoch [3/50], Step [479/735], Loss: 0.2644\n",
      "Epoch [3/50], Step [480/735], Loss: 1.0082\n",
      "Epoch [3/50], Step [481/735], Loss: 0.6117\n",
      "Epoch [3/50], Step [482/735], Loss: 0.2233\n",
      "Epoch [3/50], Step [483/735], Loss: 0.5871\n",
      "Epoch [3/50], Step [484/735], Loss: 3.3457\n",
      "Epoch [3/50], Step [485/735], Loss: 0.3719\n",
      "Epoch [3/50], Step [486/735], Loss: 0.4493\n",
      "Epoch [3/50], Step [487/735], Loss: 0.4446\n",
      "Epoch [3/50], Step [488/735], Loss: 0.2869\n",
      "Epoch [3/50], Step [489/735], Loss: 0.3172\n",
      "Epoch [3/50], Step [490/735], Loss: 0.4164\n",
      "Epoch [3/50], Step [491/735], Loss: 0.3895\n",
      "Epoch [3/50], Step [492/735], Loss: 0.5310\n",
      "Epoch [3/50], Step [493/735], Loss: 0.6126\n",
      "Epoch [3/50], Step [494/735], Loss: 0.4345\n",
      "Epoch [3/50], Step [495/735], Loss: 0.3186\n",
      "Epoch [3/50], Step [496/735], Loss: 2.3078\n",
      "Epoch [3/50], Step [497/735], Loss: 0.3604\n",
      "Epoch [3/50], Step [498/735], Loss: 0.2154\n",
      "Epoch [3/50], Step [499/735], Loss: 0.2466\n",
      "Epoch [3/50], Step [500/735], Loss: 0.4619\n",
      "Epoch [3/50], Step [501/735], Loss: 0.5402\n",
      "Epoch [3/50], Step [502/735], Loss: 0.7866\n",
      "Epoch [3/50], Step [503/735], Loss: 0.4827\n",
      "Epoch [3/50], Step [504/735], Loss: 0.6298\n",
      "Epoch [3/50], Step [505/735], Loss: 0.4738\n",
      "Epoch [3/50], Step [506/735], Loss: 0.5451\n",
      "Epoch [3/50], Step [507/735], Loss: 0.5979\n",
      "Epoch [3/50], Step [508/735], Loss: 0.3896\n",
      "Epoch [3/50], Step [509/735], Loss: 0.3579\n",
      "Epoch [3/50], Step [510/735], Loss: 0.2290\n",
      "Epoch [3/50], Step [511/735], Loss: 0.4951\n",
      "Epoch [3/50], Step [512/735], Loss: 0.7351\n",
      "Epoch [3/50], Step [513/735], Loss: 0.4369\n",
      "Epoch [3/50], Step [514/735], Loss: 0.3923\n",
      "Epoch [3/50], Step [515/735], Loss: 0.1941\n",
      "Epoch [3/50], Step [516/735], Loss: 0.2345\n",
      "Epoch [3/50], Step [517/735], Loss: 0.4013\n",
      "Epoch [3/50], Step [518/735], Loss: 0.4763\n",
      "Epoch [3/50], Step [519/735], Loss: 0.3497\n",
      "Epoch [3/50], Step [520/735], Loss: 0.4740\n",
      "Epoch [3/50], Step [521/735], Loss: 0.2054\n",
      "Epoch [3/50], Step [522/735], Loss: 0.4016\n",
      "Epoch [3/50], Step [523/735], Loss: 0.2540\n",
      "Epoch [3/50], Step [524/735], Loss: 1.8834\n",
      "Epoch [3/50], Step [525/735], Loss: 0.2097\n",
      "Epoch [3/50], Step [526/735], Loss: 0.4006\n",
      "Epoch [3/50], Step [527/735], Loss: 0.2853\n",
      "Epoch [3/50], Step [528/735], Loss: 0.2656\n",
      "Epoch [3/50], Step [529/735], Loss: 0.3574\n",
      "Epoch [3/50], Step [530/735], Loss: 0.2461\n",
      "Epoch [3/50], Step [531/735], Loss: 0.1968\n",
      "Epoch [3/50], Step [532/735], Loss: 0.3621\n",
      "Epoch [3/50], Step [533/735], Loss: 0.4190\n",
      "Epoch [3/50], Step [534/735], Loss: 0.2936\n",
      "Epoch [3/50], Step [535/735], Loss: 0.5067\n",
      "Epoch [3/50], Step [536/735], Loss: 0.2733\n",
      "Epoch [3/50], Step [537/735], Loss: 0.7337\n",
      "Epoch [3/50], Step [538/735], Loss: 0.3199\n",
      "Epoch [3/50], Step [539/735], Loss: 0.2984\n",
      "Epoch [3/50], Step [540/735], Loss: 0.5250\n",
      "Epoch [3/50], Step [541/735], Loss: 0.3944\n",
      "Epoch [3/50], Step [542/735], Loss: 0.2204\n",
      "Epoch [3/50], Step [543/735], Loss: 0.2046\n",
      "Epoch [3/50], Step [544/735], Loss: 0.2266\n",
      "Epoch [3/50], Step [545/735], Loss: 0.2221\n",
      "Epoch [3/50], Step [546/735], Loss: 0.3192\n",
      "Epoch [3/50], Step [547/735], Loss: 0.4982\n",
      "Epoch [3/50], Step [548/735], Loss: 0.4519\n",
      "Epoch [3/50], Step [549/735], Loss: 0.3157\n",
      "Epoch [3/50], Step [550/735], Loss: 0.6645\n",
      "Epoch [3/50], Step [551/735], Loss: 0.3032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Step [552/735], Loss: 0.3074\n",
      "Epoch [3/50], Step [553/735], Loss: 0.7310\n",
      "Epoch [3/50], Step [554/735], Loss: 0.2620\n",
      "Epoch [3/50], Step [555/735], Loss: 0.1771\n",
      "Epoch [3/50], Step [556/735], Loss: 0.3260\n",
      "Epoch [3/50], Step [557/735], Loss: 0.2147\n",
      "Epoch [3/50], Step [558/735], Loss: 0.2082\n",
      "Epoch [3/50], Step [559/735], Loss: 0.5903\n",
      "Epoch [3/50], Step [560/735], Loss: 0.1795\n",
      "Epoch [3/50], Step [561/735], Loss: 2.1741\n",
      "Epoch [3/50], Step [562/735], Loss: 0.3935\n",
      "Epoch [3/50], Step [563/735], Loss: 0.5810\n",
      "Epoch [3/50], Step [564/735], Loss: 0.2163\n",
      "Epoch [3/50], Step [565/735], Loss: 0.2616\n",
      "Epoch [3/50], Step [566/735], Loss: 0.2373\n",
      "Epoch [3/50], Step [567/735], Loss: 0.4221\n",
      "Epoch [3/50], Step [568/735], Loss: 1.1611\n",
      "Epoch [3/50], Step [569/735], Loss: 0.2813\n",
      "Epoch [3/50], Step [570/735], Loss: 0.4154\n",
      "Epoch [3/50], Step [571/735], Loss: 0.1984\n",
      "Epoch [3/50], Step [572/735], Loss: 1.1570\n",
      "Epoch [3/50], Step [573/735], Loss: 0.3581\n",
      "Epoch [3/50], Step [574/735], Loss: 0.3376\n",
      "Epoch [3/50], Step [575/735], Loss: 0.2978\n",
      "Epoch [3/50], Step [576/735], Loss: 0.5460\n",
      "Epoch [3/50], Step [577/735], Loss: 0.2481\n",
      "Epoch [3/50], Step [578/735], Loss: 0.2456\n",
      "Epoch [3/50], Step [579/735], Loss: 0.9997\n",
      "Epoch [3/50], Step [580/735], Loss: 0.3660\n",
      "Epoch [3/50], Step [581/735], Loss: 0.5168\n",
      "Epoch [3/50], Step [582/735], Loss: 0.8175\n",
      "Epoch [3/50], Step [583/735], Loss: 0.6678\n",
      "Epoch [3/50], Step [584/735], Loss: 0.4094\n",
      "Epoch [3/50], Step [585/735], Loss: 0.2452\n",
      "Epoch [3/50], Step [586/735], Loss: 0.3563\n",
      "Epoch [3/50], Step [587/735], Loss: 0.3014\n",
      "Epoch [3/50], Step [588/735], Loss: 1.6403\n",
      "Epoch [3/50], Step [589/735], Loss: 0.3260\n",
      "Epoch [3/50], Step [590/735], Loss: 0.3870\n",
      "Epoch [3/50], Step [591/735], Loss: 0.3342\n",
      "Epoch [3/50], Step [592/735], Loss: 0.4992\n",
      "Epoch [3/50], Step [593/735], Loss: 0.2538\n",
      "Epoch [3/50], Step [594/735], Loss: 0.3563\n",
      "Epoch [3/50], Step [595/735], Loss: 0.7415\n",
      "Epoch [3/50], Step [596/735], Loss: 0.5104\n",
      "Epoch [3/50], Step [597/735], Loss: 0.2725\n",
      "Epoch [3/50], Step [598/735], Loss: 0.3496\n",
      "Epoch [3/50], Step [599/735], Loss: 0.4083\n",
      "Epoch [3/50], Step [600/735], Loss: 0.8224\n",
      "Epoch [3/50], Step [601/735], Loss: 0.3483\n",
      "Epoch [3/50], Step [602/735], Loss: 0.3232\n",
      "Epoch [3/50], Step [603/735], Loss: 0.6839\n",
      "Epoch [3/50], Step [604/735], Loss: 0.2682\n",
      "Epoch [3/50], Step [605/735], Loss: 0.5374\n",
      "Epoch [3/50], Step [606/735], Loss: 0.2346\n",
      "Epoch [3/50], Step [607/735], Loss: 0.7826\n",
      "Epoch [3/50], Step [608/735], Loss: 0.7850\n",
      "Epoch [3/50], Step [609/735], Loss: 0.1609\n",
      "Epoch [3/50], Step [610/735], Loss: 0.2784\n",
      "Epoch [3/50], Step [611/735], Loss: 0.3318\n",
      "Epoch [3/50], Step [612/735], Loss: 0.2924\n",
      "Epoch [3/50], Step [613/735], Loss: 0.5285\n",
      "Epoch [3/50], Step [614/735], Loss: 0.2602\n",
      "Epoch [3/50], Step [615/735], Loss: 1.7507\n",
      "Epoch [3/50], Step [616/735], Loss: 0.3731\n",
      "Epoch [3/50], Step [617/735], Loss: 0.2422\n",
      "Epoch [3/50], Step [618/735], Loss: 0.2423\n",
      "Epoch [3/50], Step [619/735], Loss: 0.1732\n",
      "Epoch [3/50], Step [620/735], Loss: 0.6572\n",
      "Epoch [3/50], Step [621/735], Loss: 0.7076\n",
      "Epoch [3/50], Step [622/735], Loss: 1.9717\n",
      "Epoch [3/50], Step [623/735], Loss: 1.1513\n",
      "Epoch [3/50], Step [624/735], Loss: 0.4098\n",
      "Epoch [3/50], Step [625/735], Loss: 0.4911\n",
      "Epoch [3/50], Step [626/735], Loss: 0.3522\n",
      "Epoch [3/50], Step [627/735], Loss: 0.8704\n",
      "Epoch [3/50], Step [628/735], Loss: 0.3897\n",
      "Epoch [3/50], Step [629/735], Loss: 0.3118\n",
      "Epoch [3/50], Step [630/735], Loss: 0.2765\n",
      "Epoch [3/50], Step [631/735], Loss: 0.1909\n",
      "Epoch [3/50], Step [632/735], Loss: 0.2082\n",
      "Epoch [3/50], Step [633/735], Loss: 0.5228\n",
      "Epoch [3/50], Step [634/735], Loss: 0.2946\n",
      "Epoch [3/50], Step [635/735], Loss: 0.3700\n",
      "Epoch [3/50], Step [636/735], Loss: 0.2229\n",
      "Epoch [3/50], Step [637/735], Loss: 0.5147\n",
      "Epoch [3/50], Step [638/735], Loss: 0.3745\n",
      "Epoch [3/50], Step [639/735], Loss: 0.3905\n",
      "Epoch [3/50], Step [640/735], Loss: 0.4462\n",
      "Epoch [3/50], Step [641/735], Loss: 0.2883\n",
      "Epoch [3/50], Step [642/735], Loss: 0.4016\n",
      "Epoch [3/50], Step [643/735], Loss: 0.5457\n",
      "Epoch [3/50], Step [644/735], Loss: 0.3190\n",
      "Epoch [3/50], Step [645/735], Loss: 0.3842\n",
      "Epoch [3/50], Step [646/735], Loss: 0.2996\n",
      "Epoch [3/50], Step [647/735], Loss: 1.4215\n",
      "Epoch [3/50], Step [648/735], Loss: 0.2960\n",
      "Epoch [3/50], Step [649/735], Loss: 0.2417\n",
      "Epoch [3/50], Step [650/735], Loss: 0.3089\n",
      "Epoch [3/50], Step [651/735], Loss: 0.4168\n",
      "Epoch [3/50], Step [652/735], Loss: 0.3731\n",
      "Epoch [3/50], Step [653/735], Loss: 0.5394\n",
      "Epoch [3/50], Step [654/735], Loss: 0.7237\n",
      "Epoch [3/50], Step [655/735], Loss: 0.2699\n",
      "Epoch [3/50], Step [656/735], Loss: 1.9288\n",
      "Epoch [3/50], Step [657/735], Loss: 0.3206\n",
      "Epoch [3/50], Step [658/735], Loss: 0.2764\n",
      "Epoch [3/50], Step [659/735], Loss: 3.4600\n",
      "Epoch [3/50], Step [660/735], Loss: 1.8043\n",
      "Epoch [3/50], Step [661/735], Loss: 0.3505\n",
      "Epoch [3/50], Step [662/735], Loss: 0.3368\n",
      "Epoch [3/50], Step [663/735], Loss: 0.4317\n",
      "Epoch [3/50], Step [664/735], Loss: 0.2963\n",
      "Epoch [3/50], Step [665/735], Loss: 0.3007\n",
      "Epoch [3/50], Step [666/735], Loss: 0.4491\n",
      "Epoch [3/50], Step [667/735], Loss: 0.2068\n",
      "Epoch [3/50], Step [668/735], Loss: 0.4133\n",
      "Epoch [3/50], Step [669/735], Loss: 0.2742\n",
      "Epoch [3/50], Step [670/735], Loss: 0.4517\n",
      "Epoch [3/50], Step [671/735], Loss: 0.1660\n",
      "Epoch [3/50], Step [672/735], Loss: 0.2908\n",
      "Epoch [3/50], Step [673/735], Loss: 0.2987\n",
      "Epoch [3/50], Step [674/735], Loss: 0.2107\n",
      "Epoch [3/50], Step [675/735], Loss: 0.2929\n",
      "Epoch [3/50], Step [676/735], Loss: 0.4173\n",
      "Epoch [3/50], Step [677/735], Loss: 0.3349\n",
      "Epoch [3/50], Step [678/735], Loss: 0.1455\n",
      "Epoch [3/50], Step [679/735], Loss: 0.3803\n",
      "Epoch [3/50], Step [680/735], Loss: 0.2922\n",
      "Epoch [3/50], Step [681/735], Loss: 0.1694\n",
      "Epoch [3/50], Step [682/735], Loss: 0.2903\n",
      "Epoch [3/50], Step [683/735], Loss: 0.1732\n",
      "Epoch [3/50], Step [684/735], Loss: 0.5182\n",
      "Epoch [3/50], Step [685/735], Loss: 0.3344\n",
      "Epoch [3/50], Step [686/735], Loss: 0.1814\n",
      "Epoch [3/50], Step [687/735], Loss: 0.2101\n",
      "Epoch [3/50], Step [688/735], Loss: 0.3268\n",
      "Epoch [3/50], Step [689/735], Loss: 0.5361\n",
      "Epoch [3/50], Step [690/735], Loss: 0.3509\n",
      "Epoch [3/50], Step [691/735], Loss: 1.1315\n",
      "Epoch [3/50], Step [692/735], Loss: 0.3055\n",
      "Epoch [3/50], Step [693/735], Loss: 0.5702\n",
      "Epoch [3/50], Step [694/735], Loss: 0.5078\n",
      "Epoch [3/50], Step [695/735], Loss: 0.2285\n",
      "Epoch [3/50], Step [696/735], Loss: 0.5752\n",
      "Epoch [3/50], Step [697/735], Loss: 0.3427\n",
      "Epoch [3/50], Step [698/735], Loss: 1.6749\n",
      "Epoch [3/50], Step [699/735], Loss: 0.4773\n",
      "Epoch [3/50], Step [700/735], Loss: 0.6887\n",
      "Epoch [3/50], Step [701/735], Loss: 1.0550\n",
      "Epoch [3/50], Step [702/735], Loss: 0.2814\n",
      "Epoch [3/50], Step [703/735], Loss: 0.2929\n",
      "Epoch [3/50], Step [704/735], Loss: 0.2319\n",
      "Epoch [3/50], Step [705/735], Loss: 0.3007\n",
      "Epoch [3/50], Step [706/735], Loss: 0.6702\n",
      "Epoch [3/50], Step [707/735], Loss: 0.2001\n",
      "Epoch [3/50], Step [708/735], Loss: 2.8985\n",
      "Epoch [3/50], Step [709/735], Loss: 0.3885\n",
      "Epoch [3/50], Step [710/735], Loss: 0.3241\n",
      "Epoch [3/50], Step [711/735], Loss: 0.1666\n",
      "Epoch [3/50], Step [712/735], Loss: 0.4083\n",
      "Epoch [3/50], Step [713/735], Loss: 0.6507\n",
      "Epoch [3/50], Step [714/735], Loss: 0.3108\n",
      "Epoch [3/50], Step [715/735], Loss: 0.3777\n",
      "Epoch [3/50], Step [716/735], Loss: 0.7164\n",
      "Epoch [3/50], Step [717/735], Loss: 0.5452\n",
      "Epoch [3/50], Step [718/735], Loss: 0.2913\n",
      "Epoch [3/50], Step [719/735], Loss: 0.4672\n",
      "Epoch [3/50], Step [720/735], Loss: 0.8494\n",
      "Epoch [3/50], Step [721/735], Loss: 0.4244\n",
      "Epoch [3/50], Step [722/735], Loss: 0.3115\n",
      "Epoch [3/50], Step [723/735], Loss: 0.5892\n",
      "Epoch [3/50], Step [724/735], Loss: 0.2831\n",
      "Epoch [3/50], Step [725/735], Loss: 0.2502\n",
      "Epoch [3/50], Step [726/735], Loss: 0.4163\n",
      "Epoch [3/50], Step [727/735], Loss: 0.4336\n",
      "Epoch [3/50], Step [728/735], Loss: 0.2390\n",
      "Epoch [3/50], Step [729/735], Loss: 0.4595\n",
      "Epoch [3/50], Step [730/735], Loss: 0.2904\n",
      "Epoch [3/50], Step [731/735], Loss: 0.2633\n",
      "Epoch [3/50], Step [732/735], Loss: 0.3701\n",
      "Epoch [3/50], Step [733/735], Loss: 0.3075\n",
      "Epoch [3/50], Step [734/735], Loss: 0.5847\n",
      "Epoch [3/50], Step [735/735], Loss: 0.2591\n",
      "Epoch [4/50], Step [1/735], Loss: 0.6615\n",
      "Epoch [4/50], Step [2/735], Loss: 0.8460\n",
      "Epoch [4/50], Step [3/735], Loss: 0.2179\n",
      "Epoch [4/50], Step [4/735], Loss: 0.1268\n",
      "Epoch [4/50], Step [5/735], Loss: 0.1864\n",
      "Epoch [4/50], Step [6/735], Loss: 0.5515\n",
      "Epoch [4/50], Step [7/735], Loss: 0.5526\n",
      "Epoch [4/50], Step [8/735], Loss: 0.2831\n",
      "Epoch [4/50], Step [9/735], Loss: 0.1709\n",
      "Epoch [4/50], Step [10/735], Loss: 0.2822\n",
      "Epoch [4/50], Step [11/735], Loss: 0.2279\n",
      "Epoch [4/50], Step [12/735], Loss: 0.3200\n",
      "Epoch [4/50], Step [13/735], Loss: 0.3259\n",
      "Epoch [4/50], Step [14/735], Loss: 0.1864\n",
      "Epoch [4/50], Step [15/735], Loss: 0.3039\n",
      "Epoch [4/50], Step [16/735], Loss: 0.2477\n",
      "Epoch [4/50], Step [17/735], Loss: 0.8889\n",
      "Epoch [4/50], Step [18/735], Loss: 0.2152\n",
      "Epoch [4/50], Step [19/735], Loss: 0.5127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Step [20/735], Loss: 0.1473\n",
      "Epoch [4/50], Step [21/735], Loss: 0.3260\n",
      "Epoch [4/50], Step [22/735], Loss: 0.6644\n",
      "Epoch [4/50], Step [23/735], Loss: 0.2807\n",
      "Epoch [4/50], Step [24/735], Loss: 0.2236\n",
      "Epoch [4/50], Step [25/735], Loss: 0.4221\n",
      "Epoch [4/50], Step [26/735], Loss: 0.1852\n",
      "Epoch [4/50], Step [27/735], Loss: 0.2222\n",
      "Epoch [4/50], Step [28/735], Loss: 0.2415\n",
      "Epoch [4/50], Step [29/735], Loss: 0.3380\n",
      "Epoch [4/50], Step [30/735], Loss: 0.3101\n",
      "Epoch [4/50], Step [31/735], Loss: 0.7003\n",
      "Epoch [4/50], Step [32/735], Loss: 0.5201\n",
      "Epoch [4/50], Step [33/735], Loss: 0.6454\n",
      "Epoch [4/50], Step [34/735], Loss: 0.7568\n",
      "Epoch [4/50], Step [35/735], Loss: 0.3578\n",
      "Epoch [4/50], Step [36/735], Loss: 0.7046\n",
      "Epoch [4/50], Step [37/735], Loss: 0.2491\n",
      "Epoch [4/50], Step [38/735], Loss: 0.1823\n",
      "Epoch [4/50], Step [39/735], Loss: 0.1913\n",
      "Epoch [4/50], Step [40/735], Loss: 2.4183\n",
      "Epoch [4/50], Step [41/735], Loss: 0.5719\n",
      "Epoch [4/50], Step [42/735], Loss: 0.2753\n",
      "Epoch [4/50], Step [43/735], Loss: 0.6656\n",
      "Epoch [4/50], Step [44/735], Loss: 0.2369\n",
      "Epoch [4/50], Step [45/735], Loss: 0.4962\n",
      "Epoch [4/50], Step [46/735], Loss: 0.1837\n",
      "Epoch [4/50], Step [47/735], Loss: 0.5423\n",
      "Epoch [4/50], Step [48/735], Loss: 0.4314\n",
      "Epoch [4/50], Step [49/735], Loss: 0.2213\n",
      "Epoch [4/50], Step [50/735], Loss: 0.8183\n",
      "Epoch [4/50], Step [51/735], Loss: 0.3479\n",
      "Epoch [4/50], Step [52/735], Loss: 0.3785\n",
      "Epoch [4/50], Step [53/735], Loss: 0.5162\n",
      "Epoch [4/50], Step [54/735], Loss: 0.6714\n",
      "Epoch [4/50], Step [55/735], Loss: 0.2838\n",
      "Epoch [4/50], Step [56/735], Loss: 0.2320\n",
      "Epoch [4/50], Step [57/735], Loss: 0.2223\n",
      "Epoch [4/50], Step [58/735], Loss: 0.3205\n",
      "Epoch [4/50], Step [59/735], Loss: 0.2111\n",
      "Epoch [4/50], Step [60/735], Loss: 0.1267\n",
      "Epoch [4/50], Step [61/735], Loss: 0.2539\n",
      "Epoch [4/50], Step [62/735], Loss: 0.3064\n",
      "Epoch [4/50], Step [63/735], Loss: 0.3069\n",
      "Epoch [4/50], Step [64/735], Loss: 0.1636\n",
      "Epoch [4/50], Step [65/735], Loss: 0.2657\n",
      "Epoch [4/50], Step [66/735], Loss: 0.8050\n",
      "Epoch [4/50], Step [67/735], Loss: 0.2634\n",
      "Epoch [4/50], Step [68/735], Loss: 0.5100\n",
      "Epoch [4/50], Step [69/735], Loss: 0.5081\n",
      "Epoch [4/50], Step [70/735], Loss: 0.2090\n",
      "Epoch [4/50], Step [71/735], Loss: 0.1552\n",
      "Epoch [4/50], Step [72/735], Loss: 0.8163\n",
      "Epoch [4/50], Step [73/735], Loss: 0.3419\n",
      "Epoch [4/50], Step [74/735], Loss: 0.6520\n",
      "Epoch [4/50], Step [75/735], Loss: 0.1909\n",
      "Epoch [4/50], Step [76/735], Loss: 0.2250\n",
      "Epoch [4/50], Step [77/735], Loss: 0.3081\n",
      "Epoch [4/50], Step [78/735], Loss: 0.3631\n",
      "Epoch [4/50], Step [79/735], Loss: 0.1835\n",
      "Epoch [4/50], Step [80/735], Loss: 0.2188\n",
      "Epoch [4/50], Step [81/735], Loss: 0.3614\n",
      "Epoch [4/50], Step [82/735], Loss: 0.2250\n",
      "Epoch [4/50], Step [83/735], Loss: 0.3732\n",
      "Epoch [4/50], Step [84/735], Loss: 0.2091\n",
      "Epoch [4/50], Step [85/735], Loss: 0.6389\n",
      "Epoch [4/50], Step [86/735], Loss: 0.4797\n",
      "Epoch [4/50], Step [87/735], Loss: 0.1510\n",
      "Epoch [4/50], Step [88/735], Loss: 1.7235\n",
      "Epoch [4/50], Step [89/735], Loss: 0.3522\n",
      "Epoch [4/50], Step [90/735], Loss: 0.7795\n",
      "Epoch [4/50], Step [91/735], Loss: 0.1914\n",
      "Epoch [4/50], Step [92/735], Loss: 0.1404\n",
      "Epoch [4/50], Step [93/735], Loss: 0.3180\n",
      "Epoch [4/50], Step [94/735], Loss: 0.1484\n",
      "Epoch [4/50], Step [95/735], Loss: 0.8064\n",
      "Epoch [4/50], Step [96/735], Loss: 0.7581\n",
      "Epoch [4/50], Step [97/735], Loss: 0.4620\n",
      "Epoch [4/50], Step [98/735], Loss: 0.1559\n",
      "Epoch [4/50], Step [99/735], Loss: 0.6058\n",
      "Epoch [4/50], Step [100/735], Loss: 0.2733\n",
      "Epoch [4/50], Step [101/735], Loss: 0.1995\n",
      "Epoch [4/50], Step [102/735], Loss: 0.4502\n",
      "Epoch [4/50], Step [103/735], Loss: 0.3058\n",
      "Epoch [4/50], Step [104/735], Loss: 0.8143\n",
      "Epoch [4/50], Step [105/735], Loss: 0.2749\n",
      "Epoch [4/50], Step [106/735], Loss: 0.1739\n",
      "Epoch [4/50], Step [107/735], Loss: 0.1926\n",
      "Epoch [4/50], Step [108/735], Loss: 0.2871\n",
      "Epoch [4/50], Step [109/735], Loss: 0.2491\n",
      "Epoch [4/50], Step [110/735], Loss: 0.2283\n",
      "Epoch [4/50], Step [111/735], Loss: 0.6500\n",
      "Epoch [4/50], Step [112/735], Loss: 0.1282\n",
      "Epoch [4/50], Step [113/735], Loss: 0.5589\n",
      "Epoch [4/50], Step [114/735], Loss: 0.4686\n",
      "Epoch [4/50], Step [115/735], Loss: 0.6008\n",
      "Epoch [4/50], Step [116/735], Loss: 0.4164\n",
      "Epoch [4/50], Step [117/735], Loss: 1.6747\n",
      "Epoch [4/50], Step [118/735], Loss: 0.4972\n",
      "Epoch [4/50], Step [119/735], Loss: 0.1118\n",
      "Epoch [4/50], Step [120/735], Loss: 0.3937\n",
      "Epoch [4/50], Step [121/735], Loss: 0.3505\n",
      "Epoch [4/50], Step [122/735], Loss: 0.4888\n",
      "Epoch [4/50], Step [123/735], Loss: 0.2741\n",
      "Epoch [4/50], Step [124/735], Loss: 0.4506\n",
      "Epoch [4/50], Step [125/735], Loss: 0.8077\n",
      "Epoch [4/50], Step [126/735], Loss: 0.3518\n",
      "Epoch [4/50], Step [127/735], Loss: 0.4360\n",
      "Epoch [4/50], Step [128/735], Loss: 0.1964\n",
      "Epoch [4/50], Step [129/735], Loss: 0.1687\n",
      "Epoch [4/50], Step [130/735], Loss: 0.9899\n",
      "Epoch [4/50], Step [131/735], Loss: 0.1460\n",
      "Epoch [4/50], Step [132/735], Loss: 0.3761\n",
      "Epoch [4/50], Step [133/735], Loss: 0.3372\n",
      "Epoch [4/50], Step [134/735], Loss: 0.1812\n",
      "Epoch [4/50], Step [135/735], Loss: 0.4017\n",
      "Epoch [4/50], Step [136/735], Loss: 0.1218\n",
      "Epoch [4/50], Step [137/735], Loss: 0.4050\n",
      "Epoch [4/50], Step [138/735], Loss: 0.5218\n",
      "Epoch [4/50], Step [139/735], Loss: 0.5396\n",
      "Epoch [4/50], Step [140/735], Loss: 0.4354\n",
      "Epoch [4/50], Step [141/735], Loss: 0.2019\n",
      "Epoch [4/50], Step [142/735], Loss: 0.3022\n",
      "Epoch [4/50], Step [143/735], Loss: 0.3469\n",
      "Epoch [4/50], Step [144/735], Loss: 0.3225\n",
      "Epoch [4/50], Step [145/735], Loss: 0.3950\n",
      "Epoch [4/50], Step [146/735], Loss: 0.1359\n",
      "Epoch [4/50], Step [147/735], Loss: 0.4188\n",
      "Epoch [4/50], Step [148/735], Loss: 3.2581\n",
      "Epoch [4/50], Step [149/735], Loss: 0.2350\n",
      "Epoch [4/50], Step [150/735], Loss: 0.1899\n",
      "Epoch [4/50], Step [151/735], Loss: 0.2218\n",
      "Epoch [4/50], Step [152/735], Loss: 0.5282\n",
      "Epoch [4/50], Step [153/735], Loss: 0.7928\n",
      "Epoch [4/50], Step [154/735], Loss: 0.1850\n",
      "Epoch [4/50], Step [155/735], Loss: 0.2322\n",
      "Epoch [4/50], Step [156/735], Loss: 0.4378\n",
      "Epoch [4/50], Step [157/735], Loss: 0.2313\n",
      "Epoch [4/50], Step [158/735], Loss: 0.2968\n",
      "Epoch [4/50], Step [159/735], Loss: 0.4494\n",
      "Epoch [4/50], Step [160/735], Loss: 0.1865\n",
      "Epoch [4/50], Step [161/735], Loss: 0.3586\n",
      "Epoch [4/50], Step [162/735], Loss: 0.4802\n",
      "Epoch [4/50], Step [163/735], Loss: 0.5742\n",
      "Epoch [4/50], Step [164/735], Loss: 0.2710\n",
      "Epoch [4/50], Step [165/735], Loss: 0.4332\n",
      "Epoch [4/50], Step [166/735], Loss: 0.4138\n",
      "Epoch [4/50], Step [167/735], Loss: 0.6064\n",
      "Epoch [4/50], Step [168/735], Loss: 0.4306\n",
      "Epoch [4/50], Step [169/735], Loss: 0.2349\n",
      "Epoch [4/50], Step [170/735], Loss: 0.4882\n",
      "Epoch [4/50], Step [171/735], Loss: 0.2418\n",
      "Epoch [4/50], Step [172/735], Loss: 0.4256\n",
      "Epoch [4/50], Step [173/735], Loss: 0.5742\n",
      "Epoch [4/50], Step [174/735], Loss: 0.1663\n",
      "Epoch [4/50], Step [175/735], Loss: 0.3050\n",
      "Epoch [4/50], Step [176/735], Loss: 0.1740\n",
      "Epoch [4/50], Step [177/735], Loss: 0.3006\n",
      "Epoch [4/50], Step [178/735], Loss: 0.3286\n",
      "Epoch [4/50], Step [179/735], Loss: 0.1916\n",
      "Epoch [4/50], Step [180/735], Loss: 0.2399\n",
      "Epoch [4/50], Step [181/735], Loss: 0.2759\n",
      "Epoch [4/50], Step [182/735], Loss: 0.2541\n",
      "Epoch [4/50], Step [183/735], Loss: 0.2846\n",
      "Epoch [4/50], Step [184/735], Loss: 0.1642\n",
      "Epoch [4/50], Step [185/735], Loss: 0.3846\n",
      "Epoch [4/50], Step [186/735], Loss: 0.2376\n",
      "Epoch [4/50], Step [187/735], Loss: 0.2878\n",
      "Epoch [4/50], Step [188/735], Loss: 0.3771\n",
      "Epoch [4/50], Step [189/735], Loss: 0.2414\n",
      "Epoch [4/50], Step [190/735], Loss: 0.2876\n",
      "Epoch [4/50], Step [191/735], Loss: 0.5715\n",
      "Epoch [4/50], Step [192/735], Loss: 0.1611\n",
      "Epoch [4/50], Step [193/735], Loss: 0.5847\n",
      "Epoch [4/50], Step [194/735], Loss: 0.1745\n",
      "Epoch [4/50], Step [195/735], Loss: 0.3579\n",
      "Epoch [4/50], Step [196/735], Loss: 1.0554\n",
      "Epoch [4/50], Step [197/735], Loss: 0.3420\n",
      "Epoch [4/50], Step [198/735], Loss: 0.6530\n",
      "Epoch [4/50], Step [199/735], Loss: 0.5396\n",
      "Epoch [4/50], Step [200/735], Loss: 0.4624\n",
      "Epoch [4/50], Step [201/735], Loss: 0.1535\n",
      "Epoch [4/50], Step [202/735], Loss: 0.3725\n",
      "Epoch [4/50], Step [203/735], Loss: 0.1772\n",
      "Epoch [4/50], Step [204/735], Loss: 0.3280\n",
      "Epoch [4/50], Step [205/735], Loss: 0.4019\n",
      "Epoch [4/50], Step [206/735], Loss: 0.2984\n",
      "Epoch [4/50], Step [207/735], Loss: 0.4248\n",
      "Epoch [4/50], Step [208/735], Loss: 0.2339\n",
      "Epoch [4/50], Step [209/735], Loss: 0.3543\n",
      "Epoch [4/50], Step [210/735], Loss: 1.9634\n",
      "Epoch [4/50], Step [211/735], Loss: 0.4086\n",
      "Epoch [4/50], Step [212/735], Loss: 0.3803\n",
      "Epoch [4/50], Step [213/735], Loss: 0.1843\n",
      "Epoch [4/50], Step [214/735], Loss: 0.2549\n",
      "Epoch [4/50], Step [215/735], Loss: 0.1961\n",
      "Epoch [4/50], Step [216/735], Loss: 0.1802\n",
      "Epoch [4/50], Step [217/735], Loss: 0.1776\n",
      "Epoch [4/50], Step [218/735], Loss: 0.2194\n",
      "Epoch [4/50], Step [219/735], Loss: 0.3977\n",
      "Epoch [4/50], Step [220/735], Loss: 0.4112\n",
      "Epoch [4/50], Step [221/735], Loss: 0.6373\n",
      "Epoch [4/50], Step [222/735], Loss: 0.3527\n",
      "Epoch [4/50], Step [223/735], Loss: 0.3589\n",
      "Epoch [4/50], Step [224/735], Loss: 0.3762\n",
      "Epoch [4/50], Step [225/735], Loss: 0.1444\n",
      "Epoch [4/50], Step [226/735], Loss: 0.3513\n",
      "Epoch [4/50], Step [227/735], Loss: 0.3024\n",
      "Epoch [4/50], Step [228/735], Loss: 0.2533\n",
      "Epoch [4/50], Step [229/735], Loss: 0.2860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Step [230/735], Loss: 0.1842\n",
      "Epoch [4/50], Step [231/735], Loss: 2.7782\n",
      "Epoch [4/50], Step [232/735], Loss: 0.3318\n",
      "Epoch [4/50], Step [233/735], Loss: 0.3360\n",
      "Epoch [4/50], Step [234/735], Loss: 0.1578\n",
      "Epoch [4/50], Step [235/735], Loss: 0.3551\n",
      "Epoch [4/50], Step [236/735], Loss: 0.5110\n",
      "Epoch [4/50], Step [237/735], Loss: 0.1092\n",
      "Epoch [4/50], Step [238/735], Loss: 0.3165\n",
      "Epoch [4/50], Step [239/735], Loss: 0.3735\n",
      "Epoch [4/50], Step [240/735], Loss: 0.2268\n",
      "Epoch [4/50], Step [241/735], Loss: 0.1617\n",
      "Epoch [4/50], Step [242/735], Loss: 0.2103\n",
      "Epoch [4/50], Step [243/735], Loss: 0.2471\n",
      "Epoch [4/50], Step [244/735], Loss: 0.4488\n",
      "Epoch [4/50], Step [245/735], Loss: 0.2150\n",
      "Epoch [4/50], Step [246/735], Loss: 0.2426\n",
      "Epoch [4/50], Step [247/735], Loss: 2.7477\n",
      "Epoch [4/50], Step [248/735], Loss: 0.9222\n",
      "Epoch [4/50], Step [249/735], Loss: 0.1897\n",
      "Epoch [4/50], Step [250/735], Loss: 0.5472\n",
      "Epoch [4/50], Step [251/735], Loss: 0.6592\n",
      "Epoch [4/50], Step [252/735], Loss: 0.2115\n",
      "Epoch [4/50], Step [253/735], Loss: 0.8458\n",
      "Epoch [4/50], Step [254/735], Loss: 0.4190\n",
      "Epoch [4/50], Step [255/735], Loss: 0.2870\n",
      "Epoch [4/50], Step [256/735], Loss: 0.5125\n",
      "Epoch [4/50], Step [257/735], Loss: 0.6796\n",
      "Epoch [4/50], Step [258/735], Loss: 0.3346\n",
      "Epoch [4/50], Step [259/735], Loss: 0.1123\n",
      "Epoch [4/50], Step [260/735], Loss: 0.1768\n",
      "Epoch [4/50], Step [261/735], Loss: 0.1570\n",
      "Epoch [4/50], Step [262/735], Loss: 0.2452\n",
      "Epoch [4/50], Step [263/735], Loss: 0.3431\n",
      "Epoch [4/50], Step [264/735], Loss: 0.1914\n",
      "Epoch [4/50], Step [265/735], Loss: 0.2024\n",
      "Epoch [4/50], Step [266/735], Loss: 0.2114\n",
      "Epoch [4/50], Step [267/735], Loss: 0.3793\n",
      "Epoch [4/50], Step [268/735], Loss: 0.3779\n",
      "Epoch [4/50], Step [269/735], Loss: 0.6631\n",
      "Epoch [4/50], Step [270/735], Loss: 0.1289\n",
      "Epoch [4/50], Step [271/735], Loss: 0.1420\n",
      "Epoch [4/50], Step [272/735], Loss: 0.3012\n",
      "Epoch [4/50], Step [273/735], Loss: 0.4632\n",
      "Epoch [4/50], Step [274/735], Loss: 0.3476\n",
      "Epoch [4/50], Step [275/735], Loss: 0.2690\n",
      "Epoch [4/50], Step [276/735], Loss: 0.7317\n",
      "Epoch [4/50], Step [277/735], Loss: 0.1972\n",
      "Epoch [4/50], Step [278/735], Loss: 0.1499\n",
      "Epoch [4/50], Step [279/735], Loss: 0.1970\n",
      "Epoch [4/50], Step [280/735], Loss: 0.1303\n",
      "Epoch [4/50], Step [281/735], Loss: 0.7292\n",
      "Epoch [4/50], Step [282/735], Loss: 0.3702\n",
      "Epoch [4/50], Step [283/735], Loss: 0.2828\n",
      "Epoch [4/50], Step [284/735], Loss: 0.3312\n",
      "Epoch [4/50], Step [285/735], Loss: 0.2465\n",
      "Epoch [4/50], Step [286/735], Loss: 0.2289\n",
      "Epoch [4/50], Step [287/735], Loss: 0.1750\n",
      "Epoch [4/50], Step [288/735], Loss: 0.2694\n",
      "Epoch [4/50], Step [289/735], Loss: 0.3676\n",
      "Epoch [4/50], Step [290/735], Loss: 0.2355\n",
      "Epoch [4/50], Step [291/735], Loss: 0.2421\n",
      "Epoch [4/50], Step [292/735], Loss: 0.2480\n",
      "Epoch [4/50], Step [293/735], Loss: 0.6096\n",
      "Epoch [4/50], Step [294/735], Loss: 0.2547\n",
      "Epoch [4/50], Step [295/735], Loss: 0.1243\n",
      "Epoch [4/50], Step [296/735], Loss: 1.2923\n",
      "Epoch [4/50], Step [297/735], Loss: 1.0050\n",
      "Epoch [4/50], Step [298/735], Loss: 0.2108\n",
      "Epoch [4/50], Step [299/735], Loss: 1.7199\n",
      "Epoch [4/50], Step [300/735], Loss: 0.4260\n",
      "Epoch [4/50], Step [301/735], Loss: 0.2237\n",
      "Epoch [4/50], Step [302/735], Loss: 0.3411\n",
      "Epoch [4/50], Step [303/735], Loss: 0.2125\n",
      "Epoch [4/50], Step [304/735], Loss: 0.3594\n",
      "Epoch [4/50], Step [305/735], Loss: 0.3810\n",
      "Epoch [4/50], Step [306/735], Loss: 0.2190\n",
      "Epoch [4/50], Step [307/735], Loss: 0.1751\n",
      "Epoch [4/50], Step [308/735], Loss: 0.2036\n",
      "Epoch [4/50], Step [309/735], Loss: 0.2999\n",
      "Epoch [4/50], Step [310/735], Loss: 0.1340\n",
      "Epoch [4/50], Step [311/735], Loss: 0.2003\n",
      "Epoch [4/50], Step [312/735], Loss: 0.1183\n",
      "Epoch [4/50], Step [313/735], Loss: 0.1767\n",
      "Epoch [4/50], Step [314/735], Loss: 0.1947\n",
      "Epoch [4/50], Step [315/735], Loss: 0.2316\n",
      "Epoch [4/50], Step [316/735], Loss: 0.1555\n",
      "Epoch [4/50], Step [317/735], Loss: 0.2762\n",
      "Epoch [4/50], Step [318/735], Loss: 0.2956\n",
      "Epoch [4/50], Step [319/735], Loss: 0.2508\n",
      "Epoch [4/50], Step [320/735], Loss: 0.2858\n",
      "Epoch [4/50], Step [321/735], Loss: 0.3647\n",
      "Epoch [4/50], Step [322/735], Loss: 0.5041\n",
      "Epoch [4/50], Step [323/735], Loss: 0.3213\n",
      "Epoch [4/50], Step [324/735], Loss: 0.6880\n",
      "Epoch [4/50], Step [325/735], Loss: 0.3834\n",
      "Epoch [4/50], Step [326/735], Loss: 0.1929\n",
      "Epoch [4/50], Step [327/735], Loss: 0.3675\n",
      "Epoch [4/50], Step [328/735], Loss: 1.2443\n",
      "Epoch [4/50], Step [329/735], Loss: 0.9114\n",
      "Epoch [4/50], Step [330/735], Loss: 0.8578\n",
      "Epoch [4/50], Step [331/735], Loss: 0.1995\n",
      "Epoch [4/50], Step [332/735], Loss: 0.1981\n",
      "Epoch [4/50], Step [333/735], Loss: 0.5648\n",
      "Epoch [4/50], Step [334/735], Loss: 0.5395\n",
      "Epoch [4/50], Step [335/735], Loss: 1.5453\n",
      "Epoch [4/50], Step [336/735], Loss: 0.2039\n",
      "Epoch [4/50], Step [337/735], Loss: 0.4759\n",
      "Epoch [4/50], Step [338/735], Loss: 0.2018\n",
      "Epoch [4/50], Step [339/735], Loss: 0.3304\n",
      "Epoch [4/50], Step [340/735], Loss: 0.2420\n",
      "Epoch [4/50], Step [341/735], Loss: 0.2037\n",
      "Epoch [4/50], Step [342/735], Loss: 0.6273\n",
      "Epoch [4/50], Step [343/735], Loss: 0.1736\n",
      "Epoch [4/50], Step [344/735], Loss: 0.1421\n",
      "Epoch [4/50], Step [345/735], Loss: 0.7978\n",
      "Epoch [4/50], Step [346/735], Loss: 1.0616\n",
      "Epoch [4/50], Step [347/735], Loss: 0.3448\n",
      "Epoch [4/50], Step [348/735], Loss: 0.1330\n",
      "Epoch [4/50], Step [349/735], Loss: 0.4790\n",
      "Epoch [4/50], Step [350/735], Loss: 0.2324\n",
      "Epoch [4/50], Step [351/735], Loss: 0.4316\n",
      "Epoch [4/50], Step [352/735], Loss: 0.2259\n",
      "Epoch [4/50], Step [353/735], Loss: 0.3247\n",
      "Epoch [4/50], Step [354/735], Loss: 0.1801\n",
      "Epoch [4/50], Step [355/735], Loss: 0.5705\n",
      "Epoch [4/50], Step [356/735], Loss: 0.2403\n",
      "Epoch [4/50], Step [357/735], Loss: 0.4956\n",
      "Epoch [4/50], Step [358/735], Loss: 0.2596\n",
      "Epoch [4/50], Step [359/735], Loss: 0.2956\n",
      "Epoch [4/50], Step [360/735], Loss: 0.2555\n",
      "Epoch [4/50], Step [361/735], Loss: 0.2306\n",
      "Epoch [4/50], Step [362/735], Loss: 0.2522\n",
      "Epoch [4/50], Step [363/735], Loss: 0.4554\n",
      "Epoch [4/50], Step [364/735], Loss: 0.4513\n",
      "Epoch [4/50], Step [365/735], Loss: 0.2195\n",
      "Epoch [4/50], Step [366/735], Loss: 0.4321\n",
      "Epoch [4/50], Step [367/735], Loss: 0.4588\n",
      "Epoch [4/50], Step [368/735], Loss: 0.2532\n",
      "Epoch [4/50], Step [369/735], Loss: 0.1687\n",
      "Epoch [4/50], Step [370/735], Loss: 0.2231\n",
      "Epoch [4/50], Step [371/735], Loss: 0.1498\n",
      "Epoch [4/50], Step [372/735], Loss: 0.5646\n",
      "Epoch [4/50], Step [373/735], Loss: 0.1878\n",
      "Epoch [4/50], Step [374/735], Loss: 0.3788\n",
      "Epoch [4/50], Step [375/735], Loss: 0.4166\n",
      "Epoch [4/50], Step [376/735], Loss: 0.1773\n",
      "Epoch [4/50], Step [377/735], Loss: 0.2996\n",
      "Epoch [4/50], Step [378/735], Loss: 0.2117\n",
      "Epoch [4/50], Step [379/735], Loss: 0.5716\n",
      "Epoch [4/50], Step [380/735], Loss: 0.2578\n",
      "Epoch [4/50], Step [381/735], Loss: 0.3294\n",
      "Epoch [4/50], Step [382/735], Loss: 0.3424\n",
      "Epoch [4/50], Step [383/735], Loss: 0.2593\n",
      "Epoch [4/50], Step [384/735], Loss: 0.4862\n",
      "Epoch [4/50], Step [385/735], Loss: 0.1764\n",
      "Epoch [4/50], Step [386/735], Loss: 0.3297\n",
      "Epoch [4/50], Step [387/735], Loss: 0.1416\n",
      "Epoch [4/50], Step [388/735], Loss: 0.1798\n",
      "Epoch [4/50], Step [389/735], Loss: 0.1973\n",
      "Epoch [4/50], Step [390/735], Loss: 0.3473\n",
      "Epoch [4/50], Step [391/735], Loss: 0.3568\n",
      "Epoch [4/50], Step [392/735], Loss: 0.3151\n",
      "Epoch [4/50], Step [393/735], Loss: 0.2144\n",
      "Epoch [4/50], Step [394/735], Loss: 0.2581\n",
      "Epoch [4/50], Step [395/735], Loss: 0.2343\n",
      "Epoch [4/50], Step [396/735], Loss: 0.2552\n",
      "Epoch [4/50], Step [397/735], Loss: 1.6674\n",
      "Epoch [4/50], Step [398/735], Loss: 0.4559\n",
      "Epoch [4/50], Step [399/735], Loss: 0.1564\n",
      "Epoch [4/50], Step [400/735], Loss: 0.6842\n",
      "Epoch [4/50], Step [401/735], Loss: 0.1972\n",
      "Epoch [4/50], Step [402/735], Loss: 0.1537\n",
      "Epoch [4/50], Step [403/735], Loss: 0.1636\n",
      "Epoch [4/50], Step [404/735], Loss: 0.3833\n",
      "Epoch [4/50], Step [405/735], Loss: 0.2265\n",
      "Epoch [4/50], Step [406/735], Loss: 0.3345\n",
      "Epoch [4/50], Step [407/735], Loss: 0.3229\n",
      "Epoch [4/50], Step [408/735], Loss: 0.2659\n",
      "Epoch [4/50], Step [409/735], Loss: 0.3912\n",
      "Epoch [4/50], Step [410/735], Loss: 0.5313\n",
      "Epoch [4/50], Step [411/735], Loss: 0.1044\n",
      "Epoch [4/50], Step [412/735], Loss: 0.5388\n",
      "Epoch [4/50], Step [413/735], Loss: 0.1793\n",
      "Epoch [4/50], Step [414/735], Loss: 0.3316\n",
      "Epoch [4/50], Step [415/735], Loss: 0.3954\n",
      "Epoch [4/50], Step [416/735], Loss: 0.4170\n",
      "Epoch [4/50], Step [417/735], Loss: 0.1253\n",
      "Epoch [4/50], Step [418/735], Loss: 0.4353\n",
      "Epoch [4/50], Step [419/735], Loss: 0.2151\n",
      "Epoch [4/50], Step [420/735], Loss: 0.5306\n",
      "Epoch [4/50], Step [421/735], Loss: 0.3798\n",
      "Epoch [4/50], Step [422/735], Loss: 0.4467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Step [423/735], Loss: 0.1440\n",
      "Epoch [4/50], Step [424/735], Loss: 1.1987\n",
      "Epoch [4/50], Step [425/735], Loss: 0.6321\n",
      "Epoch [4/50], Step [426/735], Loss: 0.2266\n",
      "Epoch [4/50], Step [427/735], Loss: 0.4973\n",
      "Epoch [4/50], Step [428/735], Loss: 0.3577\n",
      "Epoch [4/50], Step [429/735], Loss: 0.3019\n",
      "Epoch [4/50], Step [430/735], Loss: 0.3070\n",
      "Epoch [4/50], Step [431/735], Loss: 0.1675\n",
      "Epoch [4/50], Step [432/735], Loss: 0.3686\n",
      "Epoch [4/50], Step [433/735], Loss: 0.1721\n",
      "Epoch [4/50], Step [434/735], Loss: 0.5406\n",
      "Epoch [4/50], Step [435/735], Loss: 2.1053\n",
      "Epoch [4/50], Step [436/735], Loss: 0.3851\n",
      "Epoch [4/50], Step [437/735], Loss: 0.3729\n",
      "Epoch [4/50], Step [438/735], Loss: 0.3862\n",
      "Epoch [4/50], Step [439/735], Loss: 0.1286\n",
      "Epoch [4/50], Step [440/735], Loss: 0.3741\n",
      "Epoch [4/50], Step [441/735], Loss: 0.1654\n",
      "Epoch [4/50], Step [442/735], Loss: 0.2019\n",
      "Epoch [4/50], Step [443/735], Loss: 0.4108\n",
      "Epoch [4/50], Step [444/735], Loss: 0.1886\n",
      "Epoch [4/50], Step [445/735], Loss: 0.4447\n",
      "Epoch [4/50], Step [446/735], Loss: 0.2374\n",
      "Epoch [4/50], Step [447/735], Loss: 0.1730\n",
      "Epoch [4/50], Step [448/735], Loss: 0.2840\n",
      "Epoch [4/50], Step [449/735], Loss: 0.6839\n",
      "Epoch [4/50], Step [450/735], Loss: 0.2624\n",
      "Epoch [4/50], Step [451/735], Loss: 0.7313\n",
      "Epoch [4/50], Step [452/735], Loss: 0.3652\n",
      "Epoch [4/50], Step [453/735], Loss: 0.3468\n",
      "Epoch [4/50], Step [454/735], Loss: 0.2863\n",
      "Epoch [4/50], Step [455/735], Loss: 0.3000\n",
      "Epoch [4/50], Step [456/735], Loss: 0.1731\n",
      "Epoch [4/50], Step [457/735], Loss: 0.2790\n",
      "Epoch [4/50], Step [458/735], Loss: 0.9724\n",
      "Epoch [4/50], Step [459/735], Loss: 0.3309\n",
      "Epoch [4/50], Step [460/735], Loss: 0.1885\n",
      "Epoch [4/50], Step [461/735], Loss: 0.7026\n",
      "Epoch [4/50], Step [462/735], Loss: 2.8572\n",
      "Epoch [4/50], Step [463/735], Loss: 0.2644\n",
      "Epoch [4/50], Step [464/735], Loss: 0.1974\n",
      "Epoch [4/50], Step [465/735], Loss: 0.3478\n",
      "Epoch [4/50], Step [466/735], Loss: 0.4549\n",
      "Epoch [4/50], Step [467/735], Loss: 0.1253\n",
      "Epoch [4/50], Step [468/735], Loss: 0.2673\n",
      "Epoch [4/50], Step [469/735], Loss: 0.1268\n",
      "Epoch [4/50], Step [470/735], Loss: 0.5593\n",
      "Epoch [4/50], Step [471/735], Loss: 0.1667\n",
      "Epoch [4/50], Step [472/735], Loss: 0.2609\n",
      "Epoch [4/50], Step [473/735], Loss: 0.4094\n",
      "Epoch [4/50], Step [474/735], Loss: 0.1449\n",
      "Epoch [4/50], Step [475/735], Loss: 0.2257\n",
      "Epoch [4/50], Step [476/735], Loss: 0.1271\n",
      "Epoch [4/50], Step [477/735], Loss: 0.3463\n",
      "Epoch [4/50], Step [478/735], Loss: 0.3629\n",
      "Epoch [4/50], Step [479/735], Loss: 0.3230\n",
      "Epoch [4/50], Step [480/735], Loss: 0.2091\n",
      "Epoch [4/50], Step [481/735], Loss: 0.3199\n",
      "Epoch [4/50], Step [482/735], Loss: 0.2631\n",
      "Epoch [4/50], Step [483/735], Loss: 0.2012\n",
      "Epoch [4/50], Step [484/735], Loss: 0.1140\n",
      "Epoch [4/50], Step [485/735], Loss: 0.9179\n",
      "Epoch [4/50], Step [486/735], Loss: 0.1652\n",
      "Epoch [4/50], Step [487/735], Loss: 0.3333\n",
      "Epoch [4/50], Step [488/735], Loss: 0.3226\n",
      "Epoch [4/50], Step [489/735], Loss: 0.2106\n",
      "Epoch [4/50], Step [490/735], Loss: 0.2467\n",
      "Epoch [4/50], Step [491/735], Loss: 0.2352\n",
      "Epoch [4/50], Step [492/735], Loss: 1.1125\n",
      "Epoch [4/50], Step [493/735], Loss: 0.1440\n",
      "Epoch [4/50], Step [494/735], Loss: 0.2115\n",
      "Epoch [4/50], Step [495/735], Loss: 0.2768\n",
      "Epoch [4/50], Step [496/735], Loss: 0.3897\n",
      "Epoch [4/50], Step [497/735], Loss: 2.2612\n",
      "Epoch [4/50], Step [498/735], Loss: 0.1583\n",
      "Epoch [4/50], Step [499/735], Loss: 0.3202\n",
      "Epoch [4/50], Step [500/735], Loss: 0.1942\n",
      "Epoch [4/50], Step [501/735], Loss: 0.3543\n",
      "Epoch [4/50], Step [502/735], Loss: 0.1778\n",
      "Epoch [4/50], Step [503/735], Loss: 0.1113\n",
      "Epoch [4/50], Step [504/735], Loss: 0.1708\n",
      "Epoch [4/50], Step [505/735], Loss: 0.1557\n",
      "Epoch [4/50], Step [506/735], Loss: 0.2640\n",
      "Epoch [4/50], Step [507/735], Loss: 0.3587\n",
      "Epoch [4/50], Step [508/735], Loss: 0.2846\n",
      "Epoch [4/50], Step [509/735], Loss: 0.2199\n",
      "Epoch [4/50], Step [510/735], Loss: 0.4359\n",
      "Epoch [4/50], Step [511/735], Loss: 0.2237\n",
      "Epoch [4/50], Step [512/735], Loss: 0.4851\n",
      "Epoch [4/50], Step [513/735], Loss: 0.1589\n",
      "Epoch [4/50], Step [514/735], Loss: 0.1582\n",
      "Epoch [4/50], Step [515/735], Loss: 0.2774\n",
      "Epoch [4/50], Step [516/735], Loss: 0.3051\n",
      "Epoch [4/50], Step [517/735], Loss: 0.6288\n",
      "Epoch [4/50], Step [518/735], Loss: 0.3053\n",
      "Epoch [4/50], Step [519/735], Loss: 0.5858\n",
      "Epoch [4/50], Step [520/735], Loss: 0.6759\n",
      "Epoch [4/50], Step [521/735], Loss: 1.1427\n",
      "Epoch [4/50], Step [522/735], Loss: 0.1714\n",
      "Epoch [4/50], Step [523/735], Loss: 0.2055\n",
      "Epoch [4/50], Step [524/735], Loss: 0.2174\n",
      "Epoch [4/50], Step [525/735], Loss: 0.2795\n",
      "Epoch [4/50], Step [526/735], Loss: 0.4070\n",
      "Epoch [4/50], Step [527/735], Loss: 0.5209\n",
      "Epoch [4/50], Step [528/735], Loss: 1.7518\n",
      "Epoch [4/50], Step [529/735], Loss: 0.3153\n",
      "Epoch [4/50], Step [530/735], Loss: 0.2924\n",
      "Epoch [4/50], Step [531/735], Loss: 0.2770\n",
      "Epoch [4/50], Step [532/735], Loss: 0.7235\n",
      "Epoch [4/50], Step [533/735], Loss: 0.3488\n",
      "Epoch [4/50], Step [534/735], Loss: 0.2845\n",
      "Epoch [4/50], Step [535/735], Loss: 0.2902\n",
      "Epoch [4/50], Step [536/735], Loss: 1.9475\n",
      "Epoch [4/50], Step [537/735], Loss: 0.1948\n",
      "Epoch [4/50], Step [538/735], Loss: 0.2043\n",
      "Epoch [4/50], Step [539/735], Loss: 0.2537\n",
      "Epoch [4/50], Step [540/735], Loss: 0.2208\n",
      "Epoch [4/50], Step [541/735], Loss: 0.5310\n",
      "Epoch [4/50], Step [542/735], Loss: 0.2219\n",
      "Epoch [4/50], Step [543/735], Loss: 1.4012\n",
      "Epoch [4/50], Step [544/735], Loss: 0.7731\n",
      "Epoch [4/50], Step [545/735], Loss: 0.3675\n",
      "Epoch [4/50], Step [546/735], Loss: 0.1366\n",
      "Epoch [4/50], Step [547/735], Loss: 0.2035\n",
      "Epoch [4/50], Step [548/735], Loss: 0.4789\n",
      "Epoch [4/50], Step [549/735], Loss: 0.4577\n",
      "Epoch [4/50], Step [550/735], Loss: 0.2966\n",
      "Epoch [4/50], Step [551/735], Loss: 0.5971\n",
      "Epoch [4/50], Step [552/735], Loss: 0.4505\n",
      "Epoch [4/50], Step [553/735], Loss: 0.2095\n",
      "Epoch [4/50], Step [554/735], Loss: 0.2108\n",
      "Epoch [4/50], Step [555/735], Loss: 0.2860\n",
      "Epoch [4/50], Step [556/735], Loss: 0.1222\n",
      "Epoch [4/50], Step [557/735], Loss: 0.4900\n",
      "Epoch [4/50], Step [558/735], Loss: 0.2980\n",
      "Epoch [4/50], Step [559/735], Loss: 0.2492\n",
      "Epoch [4/50], Step [560/735], Loss: 0.1997\n",
      "Epoch [4/50], Step [561/735], Loss: 0.2902\n",
      "Epoch [4/50], Step [562/735], Loss: 0.5230\n",
      "Epoch [4/50], Step [563/735], Loss: 0.3099\n",
      "Epoch [4/50], Step [564/735], Loss: 0.2064\n",
      "Epoch [4/50], Step [565/735], Loss: 0.1704\n",
      "Epoch [4/50], Step [566/735], Loss: 0.5717\n",
      "Epoch [4/50], Step [567/735], Loss: 0.2011\n",
      "Epoch [4/50], Step [568/735], Loss: 0.2492\n",
      "Epoch [4/50], Step [569/735], Loss: 0.1327\n",
      "Epoch [4/50], Step [570/735], Loss: 0.2272\n",
      "Epoch [4/50], Step [571/735], Loss: 0.2592\n",
      "Epoch [4/50], Step [572/735], Loss: 0.1197\n",
      "Epoch [4/50], Step [573/735], Loss: 0.3125\n",
      "Epoch [4/50], Step [574/735], Loss: 0.2455\n",
      "Epoch [4/50], Step [575/735], Loss: 0.2025\n",
      "Epoch [4/50], Step [576/735], Loss: 1.3233\n",
      "Epoch [4/50], Step [577/735], Loss: 0.0903\n",
      "Epoch [4/50], Step [578/735], Loss: 0.1978\n",
      "Epoch [4/50], Step [579/735], Loss: 0.1932\n",
      "Epoch [4/50], Step [580/735], Loss: 0.4073\n",
      "Epoch [4/50], Step [581/735], Loss: 0.3209\n",
      "Epoch [4/50], Step [582/735], Loss: 0.3123\n",
      "Epoch [4/50], Step [583/735], Loss: 0.3316\n",
      "Epoch [4/50], Step [584/735], Loss: 0.1979\n",
      "Epoch [4/50], Step [585/735], Loss: 0.1815\n",
      "Epoch [4/50], Step [586/735], Loss: 0.1473\n",
      "Epoch [4/50], Step [587/735], Loss: 0.1761\n",
      "Epoch [4/50], Step [588/735], Loss: 0.2282\n",
      "Epoch [4/50], Step [589/735], Loss: 0.2800\n",
      "Epoch [4/50], Step [590/735], Loss: 0.2578\n",
      "Epoch [4/50], Step [591/735], Loss: 0.2040\n",
      "Epoch [4/50], Step [592/735], Loss: 1.0425\n",
      "Epoch [4/50], Step [593/735], Loss: 0.8124\n",
      "Epoch [4/50], Step [594/735], Loss: 0.1175\n",
      "Epoch [4/50], Step [595/735], Loss: 0.3264\n",
      "Epoch [4/50], Step [596/735], Loss: 0.2632\n",
      "Epoch [4/50], Step [597/735], Loss: 0.2386\n",
      "Epoch [4/50], Step [598/735], Loss: 0.2060\n",
      "Epoch [4/50], Step [599/735], Loss: 0.2304\n",
      "Epoch [4/50], Step [600/735], Loss: 0.6514\n",
      "Epoch [4/50], Step [601/735], Loss: 0.3124\n",
      "Epoch [4/50], Step [602/735], Loss: 0.1985\n",
      "Epoch [4/50], Step [603/735], Loss: 0.2093\n",
      "Epoch [4/50], Step [604/735], Loss: 0.1035\n",
      "Epoch [4/50], Step [605/735], Loss: 0.3682\n",
      "Epoch [4/50], Step [606/735], Loss: 0.1194\n",
      "Epoch [4/50], Step [607/735], Loss: 0.3314\n",
      "Epoch [4/50], Step [608/735], Loss: 0.2140\n",
      "Epoch [4/50], Step [609/735], Loss: 0.2985\n",
      "Epoch [4/50], Step [610/735], Loss: 0.3160\n",
      "Epoch [4/50], Step [611/735], Loss: 0.2389\n",
      "Epoch [4/50], Step [612/735], Loss: 0.1585\n",
      "Epoch [4/50], Step [613/735], Loss: 0.4374\n",
      "Epoch [4/50], Step [614/735], Loss: 0.2607\n",
      "Epoch [4/50], Step [615/735], Loss: 0.3606\n",
      "Epoch [4/50], Step [616/735], Loss: 0.1313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Step [617/735], Loss: 0.1125\n",
      "Epoch [4/50], Step [618/735], Loss: 0.2087\n",
      "Epoch [4/50], Step [619/735], Loss: 0.1813\n",
      "Epoch [4/50], Step [620/735], Loss: 0.1107\n",
      "Epoch [4/50], Step [621/735], Loss: 0.2571\n",
      "Epoch [4/50], Step [622/735], Loss: 0.3722\n",
      "Epoch [4/50], Step [623/735], Loss: 0.8902\n",
      "Epoch [4/50], Step [624/735], Loss: 0.1631\n",
      "Epoch [4/50], Step [625/735], Loss: 0.0952\n",
      "Epoch [4/50], Step [626/735], Loss: 0.2379\n",
      "Epoch [4/50], Step [627/735], Loss: 0.2594\n",
      "Epoch [4/50], Step [628/735], Loss: 0.1810\n",
      "Epoch [4/50], Step [629/735], Loss: 0.3488\n",
      "Epoch [4/50], Step [630/735], Loss: 0.1367\n",
      "Epoch [4/50], Step [631/735], Loss: 0.2227\n",
      "Epoch [4/50], Step [632/735], Loss: 0.5721\n",
      "Epoch [4/50], Step [633/735], Loss: 0.1671\n",
      "Epoch [4/50], Step [634/735], Loss: 0.5599\n",
      "Epoch [4/50], Step [635/735], Loss: 0.2935\n",
      "Epoch [4/50], Step [636/735], Loss: 0.5774\n",
      "Epoch [4/50], Step [637/735], Loss: 0.3308\n",
      "Epoch [4/50], Step [638/735], Loss: 0.3484\n",
      "Epoch [4/50], Step [639/735], Loss: 0.2441\n",
      "Epoch [4/50], Step [640/735], Loss: 0.4055\n",
      "Epoch [4/50], Step [641/735], Loss: 0.3234\n",
      "Epoch [4/50], Step [642/735], Loss: 0.2793\n",
      "Epoch [4/50], Step [643/735], Loss: 0.3558\n",
      "Epoch [4/50], Step [644/735], Loss: 0.1722\n",
      "Epoch [4/50], Step [645/735], Loss: 0.4026\n",
      "Epoch [4/50], Step [646/735], Loss: 0.3519\n",
      "Epoch [4/50], Step [647/735], Loss: 0.4397\n",
      "Epoch [4/50], Step [648/735], Loss: 0.3149\n",
      "Epoch [4/50], Step [649/735], Loss: 0.3039\n",
      "Epoch [4/50], Step [650/735], Loss: 0.2188\n",
      "Epoch [4/50], Step [651/735], Loss: 0.4277\n",
      "Epoch [4/50], Step [652/735], Loss: 2.3356\n",
      "Epoch [4/50], Step [653/735], Loss: 0.2335\n",
      "Epoch [4/50], Step [654/735], Loss: 0.1932\n",
      "Epoch [4/50], Step [655/735], Loss: 0.2420\n",
      "Epoch [4/50], Step [656/735], Loss: 0.3869\n",
      "Epoch [4/50], Step [657/735], Loss: 0.2447\n",
      "Epoch [4/50], Step [658/735], Loss: 0.2787\n",
      "Epoch [4/50], Step [659/735], Loss: 0.5716\n",
      "Epoch [4/50], Step [660/735], Loss: 0.1360\n",
      "Epoch [4/50], Step [661/735], Loss: 0.2971\n",
      "Epoch [4/50], Step [662/735], Loss: 0.2165\n",
      "Epoch [4/50], Step [663/735], Loss: 0.5091\n",
      "Epoch [4/50], Step [664/735], Loss: 0.4977\n",
      "Epoch [4/50], Step [665/735], Loss: 0.2211\n",
      "Epoch [4/50], Step [666/735], Loss: 0.2752\n",
      "Epoch [4/50], Step [667/735], Loss: 0.1921\n",
      "Epoch [4/50], Step [668/735], Loss: 0.1839\n",
      "Epoch [4/50], Step [669/735], Loss: 0.3224\n",
      "Epoch [4/50], Step [670/735], Loss: 0.3064\n",
      "Epoch [4/50], Step [671/735], Loss: 0.4706\n",
      "Epoch [4/50], Step [672/735], Loss: 3.3722\n",
      "Epoch [4/50], Step [673/735], Loss: 0.1414\n",
      "Epoch [4/50], Step [674/735], Loss: 0.2667\n",
      "Epoch [4/50], Step [675/735], Loss: 0.1924\n",
      "Epoch [4/50], Step [676/735], Loss: 0.2610\n",
      "Epoch [4/50], Step [677/735], Loss: 0.4313\n",
      "Epoch [4/50], Step [678/735], Loss: 0.1964\n",
      "Epoch [4/50], Step [679/735], Loss: 0.3053\n",
      "Epoch [4/50], Step [680/735], Loss: 0.3537\n",
      "Epoch [4/50], Step [681/735], Loss: 0.2141\n",
      "Epoch [4/50], Step [682/735], Loss: 0.1771\n",
      "Epoch [4/50], Step [683/735], Loss: 0.1869\n",
      "Epoch [4/50], Step [684/735], Loss: 0.1524\n",
      "Epoch [4/50], Step [685/735], Loss: 0.1391\n",
      "Epoch [4/50], Step [686/735], Loss: 0.1924\n",
      "Epoch [4/50], Step [687/735], Loss: 0.2111\n",
      "Epoch [4/50], Step [688/735], Loss: 0.1823\n",
      "Epoch [4/50], Step [689/735], Loss: 0.2806\n",
      "Epoch [4/50], Step [690/735], Loss: 1.4776\n",
      "Epoch [4/50], Step [691/735], Loss: 0.2045\n",
      "Epoch [4/50], Step [692/735], Loss: 0.5004\n",
      "Epoch [4/50], Step [693/735], Loss: 0.1731\n",
      "Epoch [4/50], Step [694/735], Loss: 0.2027\n",
      "Epoch [4/50], Step [695/735], Loss: 0.1996\n",
      "Epoch [4/50], Step [696/735], Loss: 0.1132\n",
      "Epoch [4/50], Step [697/735], Loss: 0.1006\n",
      "Epoch [4/50], Step [698/735], Loss: 0.1767\n",
      "Epoch [4/50], Step [699/735], Loss: 0.4646\n",
      "Epoch [4/50], Step [700/735], Loss: 0.3060\n",
      "Epoch [4/50], Step [701/735], Loss: 0.2440\n",
      "Epoch [4/50], Step [702/735], Loss: 0.1065\n",
      "Epoch [4/50], Step [703/735], Loss: 0.1580\n",
      "Epoch [4/50], Step [704/735], Loss: 0.2678\n",
      "Epoch [4/50], Step [705/735], Loss: 0.1648\n",
      "Epoch [4/50], Step [706/735], Loss: 0.4572\n",
      "Epoch [4/50], Step [707/735], Loss: 0.2838\n",
      "Epoch [4/50], Step [708/735], Loss: 0.3168\n",
      "Epoch [4/50], Step [709/735], Loss: 0.5537\n",
      "Epoch [4/50], Step [710/735], Loss: 0.2512\n",
      "Epoch [4/50], Step [711/735], Loss: 0.0887\n",
      "Epoch [4/50], Step [712/735], Loss: 1.3594\n",
      "Epoch [4/50], Step [713/735], Loss: 0.1729\n",
      "Epoch [4/50], Step [714/735], Loss: 0.4463\n",
      "Epoch [4/50], Step [715/735], Loss: 0.0950\n",
      "Epoch [4/50], Step [716/735], Loss: 0.2659\n",
      "Epoch [4/50], Step [717/735], Loss: 0.1599\n",
      "Epoch [4/50], Step [718/735], Loss: 0.3274\n",
      "Epoch [4/50], Step [719/735], Loss: 0.3228\n",
      "Epoch [4/50], Step [720/735], Loss: 0.2130\n",
      "Epoch [4/50], Step [721/735], Loss: 0.4869\n",
      "Epoch [4/50], Step [722/735], Loss: 0.1860\n",
      "Epoch [4/50], Step [723/735], Loss: 0.1654\n",
      "Epoch [4/50], Step [724/735], Loss: 0.2492\n",
      "Epoch [4/50], Step [725/735], Loss: 1.0225\n",
      "Epoch [4/50], Step [726/735], Loss: 0.3946\n",
      "Epoch [4/50], Step [727/735], Loss: 0.1436\n",
      "Epoch [4/50], Step [728/735], Loss: 0.2569\n",
      "Epoch [4/50], Step [729/735], Loss: 0.3784\n",
      "Epoch [4/50], Step [730/735], Loss: 0.4435\n",
      "Epoch [4/50], Step [731/735], Loss: 0.1172\n",
      "Epoch [4/50], Step [732/735], Loss: 0.1322\n",
      "Epoch [4/50], Step [733/735], Loss: 0.1691\n",
      "Epoch [4/50], Step [734/735], Loss: 1.6607\n",
      "Epoch [4/50], Step [735/735], Loss: 0.1693\n",
      "Epoch [5/50], Step [1/735], Loss: 0.1299\n",
      "Epoch [5/50], Step [2/735], Loss: 0.1975\n",
      "Epoch [5/50], Step [3/735], Loss: 0.1154\n",
      "Epoch [5/50], Step [4/735], Loss: 0.1458\n",
      "Epoch [5/50], Step [5/735], Loss: 0.2213\n",
      "Epoch [5/50], Step [6/735], Loss: 0.1956\n",
      "Epoch [5/50], Step [7/735], Loss: 0.2878\n",
      "Epoch [5/50], Step [8/735], Loss: 0.1329\n",
      "Epoch [5/50], Step [9/735], Loss: 0.1491\n",
      "Epoch [5/50], Step [10/735], Loss: 0.3433\n",
      "Epoch [5/50], Step [11/735], Loss: 0.1925\n",
      "Epoch [5/50], Step [12/735], Loss: 0.2858\n",
      "Epoch [5/50], Step [13/735], Loss: 0.2044\n",
      "Epoch [5/50], Step [14/735], Loss: 0.3605\n",
      "Epoch [5/50], Step [15/735], Loss: 0.4141\n",
      "Epoch [5/50], Step [16/735], Loss: 0.2725\n",
      "Epoch [5/50], Step [17/735], Loss: 0.1719\n",
      "Epoch [5/50], Step [18/735], Loss: 0.1184\n",
      "Epoch [5/50], Step [19/735], Loss: 0.1424\n",
      "Epoch [5/50], Step [20/735], Loss: 0.3955\n",
      "Epoch [5/50], Step [21/735], Loss: 0.1887\n",
      "Epoch [5/50], Step [22/735], Loss: 0.3523\n",
      "Epoch [5/50], Step [23/735], Loss: 0.2961\n",
      "Epoch [5/50], Step [24/735], Loss: 0.3473\n",
      "Epoch [5/50], Step [25/735], Loss: 0.2491\n",
      "Epoch [5/50], Step [26/735], Loss: 0.4542\n",
      "Epoch [5/50], Step [27/735], Loss: 0.4668\n",
      "Epoch [5/50], Step [28/735], Loss: 0.0882\n",
      "Epoch [5/50], Step [29/735], Loss: 0.4008\n",
      "Epoch [5/50], Step [30/735], Loss: 1.2364\n",
      "Epoch [5/50], Step [31/735], Loss: 0.2425\n",
      "Epoch [5/50], Step [32/735], Loss: 0.3677\n",
      "Epoch [5/50], Step [33/735], Loss: 0.4689\n",
      "Epoch [5/50], Step [34/735], Loss: 1.0878\n",
      "Epoch [5/50], Step [35/735], Loss: 0.1878\n",
      "Epoch [5/50], Step [36/735], Loss: 0.4209\n",
      "Epoch [5/50], Step [37/735], Loss: 0.1816\n",
      "Epoch [5/50], Step [38/735], Loss: 0.2028\n",
      "Epoch [5/50], Step [39/735], Loss: 0.2410\n",
      "Epoch [5/50], Step [40/735], Loss: 0.3007\n",
      "Epoch [5/50], Step [41/735], Loss: 0.1997\n",
      "Epoch [5/50], Step [42/735], Loss: 0.1678\n",
      "Epoch [5/50], Step [43/735], Loss: 0.1769\n",
      "Epoch [5/50], Step [44/735], Loss: 0.2191\n",
      "Epoch [5/50], Step [45/735], Loss: 0.1771\n",
      "Epoch [5/50], Step [46/735], Loss: 0.1702\n",
      "Epoch [5/50], Step [47/735], Loss: 0.3008\n",
      "Epoch [5/50], Step [48/735], Loss: 1.0768\n",
      "Epoch [5/50], Step [49/735], Loss: 0.3907\n",
      "Epoch [5/50], Step [50/735], Loss: 1.3826\n",
      "Epoch [5/50], Step [51/735], Loss: 0.1018\n",
      "Epoch [5/50], Step [52/735], Loss: 0.2068\n",
      "Epoch [5/50], Step [53/735], Loss: 0.4993\n",
      "Epoch [5/50], Step [54/735], Loss: 0.2212\n",
      "Epoch [5/50], Step [55/735], Loss: 0.1980\n",
      "Epoch [5/50], Step [56/735], Loss: 0.4975\n",
      "Epoch [5/50], Step [57/735], Loss: 0.3293\n",
      "Epoch [5/50], Step [58/735], Loss: 0.2060\n",
      "Epoch [5/50], Step [59/735], Loss: 0.6293\n",
      "Epoch [5/50], Step [60/735], Loss: 0.3106\n",
      "Epoch [5/50], Step [61/735], Loss: 0.2398\n",
      "Epoch [5/50], Step [62/735], Loss: 0.3759\n",
      "Epoch [5/50], Step [63/735], Loss: 0.1877\n",
      "Epoch [5/50], Step [64/735], Loss: 0.1877\n",
      "Epoch [5/50], Step [65/735], Loss: 0.1193\n",
      "Epoch [5/50], Step [66/735], Loss: 0.1162\n",
      "Epoch [5/50], Step [67/735], Loss: 0.2475\n",
      "Epoch [5/50], Step [68/735], Loss: 0.5747\n",
      "Epoch [5/50], Step [69/735], Loss: 0.2878\n",
      "Epoch [5/50], Step [70/735], Loss: 0.2470\n",
      "Epoch [5/50], Step [71/735], Loss: 0.2823\n",
      "Epoch [5/50], Step [72/735], Loss: 0.4185\n",
      "Epoch [5/50], Step [73/735], Loss: 0.2367\n",
      "Epoch [5/50], Step [74/735], Loss: 0.3254\n",
      "Epoch [5/50], Step [75/735], Loss: 0.2133\n",
      "Epoch [5/50], Step [76/735], Loss: 0.1830\n",
      "Epoch [5/50], Step [77/735], Loss: 0.1579\n",
      "Epoch [5/50], Step [78/735], Loss: 0.1711\n",
      "Epoch [5/50], Step [79/735], Loss: 0.2015\n",
      "Epoch [5/50], Step [80/735], Loss: 0.2215\n",
      "Epoch [5/50], Step [81/735], Loss: 0.1946\n",
      "Epoch [5/50], Step [82/735], Loss: 0.3181\n",
      "Epoch [5/50], Step [83/735], Loss: 0.1498\n",
      "Epoch [5/50], Step [84/735], Loss: 0.2401\n",
      "Epoch [5/50], Step [85/735], Loss: 0.2272\n",
      "Epoch [5/50], Step [86/735], Loss: 0.4350\n",
      "Epoch [5/50], Step [87/735], Loss: 0.2903\n",
      "Epoch [5/50], Step [88/735], Loss: 0.3335\n",
      "Epoch [5/50], Step [89/735], Loss: 0.0863\n",
      "Epoch [5/50], Step [90/735], Loss: 0.1168\n",
      "Epoch [5/50], Step [91/735], Loss: 0.1922\n",
      "Epoch [5/50], Step [92/735], Loss: 0.1157\n",
      "Epoch [5/50], Step [93/735], Loss: 0.4750\n",
      "Epoch [5/50], Step [94/735], Loss: 0.2958\n",
      "Epoch [5/50], Step [95/735], Loss: 0.6110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Step [96/735], Loss: 0.1903\n",
      "Epoch [5/50], Step [97/735], Loss: 0.4180\n",
      "Epoch [5/50], Step [98/735], Loss: 0.1551\n",
      "Epoch [5/50], Step [99/735], Loss: 0.4742\n",
      "Epoch [5/50], Step [100/735], Loss: 0.1542\n",
      "Epoch [5/50], Step [101/735], Loss: 0.3962\n",
      "Epoch [5/50], Step [102/735], Loss: 0.3287\n",
      "Epoch [5/50], Step [103/735], Loss: 0.4202\n",
      "Epoch [5/50], Step [104/735], Loss: 3.1716\n",
      "Epoch [5/50], Step [105/735], Loss: 0.3038\n",
      "Epoch [5/50], Step [106/735], Loss: 0.1533\n",
      "Epoch [5/50], Step [107/735], Loss: 0.2090\n",
      "Epoch [5/50], Step [108/735], Loss: 0.1583\n",
      "Epoch [5/50], Step [109/735], Loss: 0.1387\n",
      "Epoch [5/50], Step [110/735], Loss: 0.1431\n",
      "Epoch [5/50], Step [111/735], Loss: 0.1402\n",
      "Epoch [5/50], Step [112/735], Loss: 0.3810\n",
      "Epoch [5/50], Step [113/735], Loss: 1.4023\n",
      "Epoch [5/50], Step [114/735], Loss: 0.3751\n",
      "Epoch [5/50], Step [115/735], Loss: 0.2743\n",
      "Epoch [5/50], Step [116/735], Loss: 0.2470\n",
      "Epoch [5/50], Step [117/735], Loss: 0.2582\n",
      "Epoch [5/50], Step [118/735], Loss: 0.5932\n",
      "Epoch [5/50], Step [119/735], Loss: 0.1252\n",
      "Epoch [5/50], Step [120/735], Loss: 0.2011\n",
      "Epoch [5/50], Step [121/735], Loss: 0.3452\n",
      "Epoch [5/50], Step [122/735], Loss: 0.0866\n",
      "Epoch [5/50], Step [123/735], Loss: 0.3867\n",
      "Epoch [5/50], Step [124/735], Loss: 0.1444\n",
      "Epoch [5/50], Step [125/735], Loss: 0.2106\n",
      "Epoch [5/50], Step [126/735], Loss: 0.0944\n",
      "Epoch [5/50], Step [127/735], Loss: 0.0837\n",
      "Epoch [5/50], Step [128/735], Loss: 0.2346\n",
      "Epoch [5/50], Step [129/735], Loss: 0.4652\n",
      "Epoch [5/50], Step [130/735], Loss: 0.1665\n",
      "Epoch [5/50], Step [131/735], Loss: 0.1169\n",
      "Epoch [5/50], Step [132/735], Loss: 0.2173\n",
      "Epoch [5/50], Step [133/735], Loss: 0.2290\n",
      "Epoch [5/50], Step [134/735], Loss: 0.2577\n",
      "Epoch [5/50], Step [135/735], Loss: 0.2578\n",
      "Epoch [5/50], Step [136/735], Loss: 0.2708\n",
      "Epoch [5/50], Step [137/735], Loss: 0.1469\n",
      "Epoch [5/50], Step [138/735], Loss: 0.0768\n",
      "Epoch [5/50], Step [139/735], Loss: 0.1394\n",
      "Epoch [5/50], Step [140/735], Loss: 0.3438\n",
      "Epoch [5/50], Step [141/735], Loss: 0.3114\n",
      "Epoch [5/50], Step [142/735], Loss: 0.2651\n",
      "Epoch [5/50], Step [143/735], Loss: 0.1192\n",
      "Epoch [5/50], Step [144/735], Loss: 0.3726\n",
      "Epoch [5/50], Step [145/735], Loss: 0.2383\n",
      "Epoch [5/50], Step [146/735], Loss: 0.2008\n",
      "Epoch [5/50], Step [147/735], Loss: 0.2415\n",
      "Epoch [5/50], Step [148/735], Loss: 1.2350\n",
      "Epoch [5/50], Step [149/735], Loss: 0.1443\n",
      "Epoch [5/50], Step [150/735], Loss: 0.2740\n",
      "Epoch [5/50], Step [151/735], Loss: 0.1299\n",
      "Epoch [5/50], Step [152/735], Loss: 0.3239\n",
      "Epoch [5/50], Step [153/735], Loss: 0.2825\n",
      "Epoch [5/50], Step [154/735], Loss: 0.2770\n",
      "Epoch [5/50], Step [155/735], Loss: 0.3350\n",
      "Epoch [5/50], Step [156/735], Loss: 0.2500\n",
      "Epoch [5/50], Step [157/735], Loss: 0.2487\n",
      "Epoch [5/50], Step [158/735], Loss: 0.0895\n",
      "Epoch [5/50], Step [159/735], Loss: 0.1401\n",
      "Epoch [5/50], Step [160/735], Loss: 0.2777\n",
      "Epoch [5/50], Step [161/735], Loss: 0.2585\n",
      "Epoch [5/50], Step [162/735], Loss: 0.1396\n",
      "Epoch [5/50], Step [163/735], Loss: 0.1353\n",
      "Epoch [5/50], Step [164/735], Loss: 0.1990\n",
      "Epoch [5/50], Step [165/735], Loss: 0.4208\n",
      "Epoch [5/50], Step [166/735], Loss: 0.2716\n",
      "Epoch [5/50], Step [167/735], Loss: 0.2165\n",
      "Epoch [5/50], Step [168/735], Loss: 0.5080\n",
      "Epoch [5/50], Step [169/735], Loss: 0.3860\n",
      "Epoch [5/50], Step [170/735], Loss: 0.5423\n",
      "Epoch [5/50], Step [171/735], Loss: 0.1273\n",
      "Epoch [5/50], Step [172/735], Loss: 0.3981\n",
      "Epoch [5/50], Step [173/735], Loss: 1.5214\n",
      "Epoch [5/50], Step [174/735], Loss: 1.0424\n",
      "Epoch [5/50], Step [175/735], Loss: 0.3565\n",
      "Epoch [5/50], Step [176/735], Loss: 0.2062\n",
      "Epoch [5/50], Step [177/735], Loss: 0.3511\n",
      "Epoch [5/50], Step [178/735], Loss: 0.3014\n",
      "Epoch [5/50], Step [179/735], Loss: 0.1110\n",
      "Epoch [5/50], Step [180/735], Loss: 0.4029\n",
      "Epoch [5/50], Step [181/735], Loss: 0.2748\n",
      "Epoch [5/50], Step [182/735], Loss: 0.3977\n",
      "Epoch [5/50], Step [183/735], Loss: 0.1190\n",
      "Epoch [5/50], Step [184/735], Loss: 0.1963\n",
      "Epoch [5/50], Step [185/735], Loss: 0.3327\n",
      "Epoch [5/50], Step [186/735], Loss: 0.1987\n",
      "Epoch [5/50], Step [187/735], Loss: 0.2029\n",
      "Epoch [5/50], Step [188/735], Loss: 0.0777\n",
      "Epoch [5/50], Step [189/735], Loss: 0.5003\n",
      "Epoch [5/50], Step [190/735], Loss: 2.7309\n",
      "Epoch [5/50], Step [191/735], Loss: 0.1873\n",
      "Epoch [5/50], Step [192/735], Loss: 0.2130\n",
      "Epoch [5/50], Step [193/735], Loss: 0.2512\n",
      "Epoch [5/50], Step [194/735], Loss: 0.4238\n",
      "Epoch [5/50], Step [195/735], Loss: 0.3173\n",
      "Epoch [5/50], Step [196/735], Loss: 0.3160\n",
      "Epoch [5/50], Step [197/735], Loss: 0.1198\n",
      "Epoch [5/50], Step [198/735], Loss: 0.2548\n",
      "Epoch [5/50], Step [199/735], Loss: 0.3927\n",
      "Epoch [5/50], Step [200/735], Loss: 0.7505\n",
      "Epoch [5/50], Step [201/735], Loss: 0.3633\n",
      "Epoch [5/50], Step [202/735], Loss: 0.1818\n",
      "Epoch [5/50], Step [203/735], Loss: 0.1506\n",
      "Epoch [5/50], Step [204/735], Loss: 0.1708\n",
      "Epoch [5/50], Step [205/735], Loss: 0.2468\n",
      "Epoch [5/50], Step [206/735], Loss: 0.1536\n",
      "Epoch [5/50], Step [207/735], Loss: 0.3678\n",
      "Epoch [5/50], Step [208/735], Loss: 0.1232\n",
      "Epoch [5/50], Step [209/735], Loss: 0.4104\n",
      "Epoch [5/50], Step [210/735], Loss: 0.2904\n",
      "Epoch [5/50], Step [211/735], Loss: 0.2046\n",
      "Epoch [5/50], Step [212/735], Loss: 0.1095\n",
      "Epoch [5/50], Step [213/735], Loss: 0.2306\n",
      "Epoch [5/50], Step [214/735], Loss: 0.3392\n",
      "Epoch [5/50], Step [215/735], Loss: 0.2001\n",
      "Epoch [5/50], Step [216/735], Loss: 0.1294\n",
      "Epoch [5/50], Step [217/735], Loss: 0.1346\n",
      "Epoch [5/50], Step [218/735], Loss: 0.1650\n",
      "Epoch [5/50], Step [219/735], Loss: 0.2292\n",
      "Epoch [5/50], Step [220/735], Loss: 0.5330\n",
      "Epoch [5/50], Step [221/735], Loss: 0.2912\n",
      "Epoch [5/50], Step [222/735], Loss: 0.1659\n",
      "Epoch [5/50], Step [223/735], Loss: 0.4462\n",
      "Epoch [5/50], Step [224/735], Loss: 0.3194\n",
      "Epoch [5/50], Step [225/735], Loss: 0.1995\n",
      "Epoch [5/50], Step [226/735], Loss: 0.1660\n",
      "Epoch [5/50], Step [227/735], Loss: 0.2140\n",
      "Epoch [5/50], Step [228/735], Loss: 0.1575\n",
      "Epoch [5/50], Step [229/735], Loss: 0.3209\n",
      "Epoch [5/50], Step [230/735], Loss: 0.3670\n",
      "Epoch [5/50], Step [231/735], Loss: 0.3022\n",
      "Epoch [5/50], Step [232/735], Loss: 0.4427\n",
      "Epoch [5/50], Step [233/735], Loss: 0.3141\n",
      "Epoch [5/50], Step [234/735], Loss: 0.1596\n",
      "Epoch [5/50], Step [235/735], Loss: 0.2378\n",
      "Epoch [5/50], Step [236/735], Loss: 0.7515\n",
      "Epoch [5/50], Step [237/735], Loss: 0.4285\n",
      "Epoch [5/50], Step [238/735], Loss: 0.2333\n",
      "Epoch [5/50], Step [239/735], Loss: 0.1409\n",
      "Epoch [5/50], Step [240/735], Loss: 0.3799\n",
      "Epoch [5/50], Step [241/735], Loss: 2.6421\n",
      "Epoch [5/50], Step [242/735], Loss: 2.6491\n",
      "Epoch [5/50], Step [243/735], Loss: 0.4384\n",
      "Epoch [5/50], Step [244/735], Loss: 0.3166\n",
      "Epoch [5/50], Step [245/735], Loss: 0.0913\n",
      "Epoch [5/50], Step [246/735], Loss: 2.0711\n",
      "Epoch [5/50], Step [247/735], Loss: 0.2383\n",
      "Epoch [5/50], Step [248/735], Loss: 0.2404\n",
      "Epoch [5/50], Step [249/735], Loss: 0.2672\n",
      "Epoch [5/50], Step [250/735], Loss: 0.1900\n",
      "Epoch [5/50], Step [251/735], Loss: 0.1235\n",
      "Epoch [5/50], Step [252/735], Loss: 0.1232\n",
      "Epoch [5/50], Step [253/735], Loss: 0.1337\n",
      "Epoch [5/50], Step [254/735], Loss: 0.5992\n",
      "Epoch [5/50], Step [255/735], Loss: 0.2212\n",
      "Epoch [5/50], Step [256/735], Loss: 0.2945\n",
      "Epoch [5/50], Step [257/735], Loss: 0.0829\n",
      "Epoch [5/50], Step [258/735], Loss: 0.3010\n",
      "Epoch [5/50], Step [259/735], Loss: 0.1901\n",
      "Epoch [5/50], Step [260/735], Loss: 0.2761\n",
      "Epoch [5/50], Step [261/735], Loss: 0.1763\n",
      "Epoch [5/50], Step [262/735], Loss: 0.2297\n",
      "Epoch [5/50], Step [263/735], Loss: 0.4022\n",
      "Epoch [5/50], Step [264/735], Loss: 0.3236\n",
      "Epoch [5/50], Step [265/735], Loss: 0.1484\n",
      "Epoch [5/50], Step [266/735], Loss: 0.2423\n",
      "Epoch [5/50], Step [267/735], Loss: 0.1261\n",
      "Epoch [5/50], Step [268/735], Loss: 0.1962\n",
      "Epoch [5/50], Step [269/735], Loss: 0.1764\n",
      "Epoch [5/50], Step [270/735], Loss: 0.1556\n",
      "Epoch [5/50], Step [271/735], Loss: 0.3882\n",
      "Epoch [5/50], Step [272/735], Loss: 0.2610\n",
      "Epoch [5/50], Step [273/735], Loss: 1.3978\n",
      "Epoch [5/50], Step [274/735], Loss: 0.2498\n",
      "Epoch [5/50], Step [275/735], Loss: 0.2531\n",
      "Epoch [5/50], Step [276/735], Loss: 0.1651\n",
      "Epoch [5/50], Step [277/735], Loss: 0.2083\n",
      "Epoch [5/50], Step [278/735], Loss: 0.6017\n",
      "Epoch [5/50], Step [279/735], Loss: 0.4235\n",
      "Epoch [5/50], Step [280/735], Loss: 0.3225\n",
      "Epoch [5/50], Step [281/735], Loss: 1.1052\n",
      "Epoch [5/50], Step [282/735], Loss: 0.3298\n",
      "Epoch [5/50], Step [283/735], Loss: 0.1717\n",
      "Epoch [5/50], Step [284/735], Loss: 0.2786\n",
      "Epoch [5/50], Step [285/735], Loss: 0.2110\n",
      "Epoch [5/50], Step [286/735], Loss: 0.2538\n",
      "Epoch [5/50], Step [287/735], Loss: 0.3477\n",
      "Epoch [5/50], Step [288/735], Loss: 0.2177\n",
      "Epoch [5/50], Step [289/735], Loss: 0.2068\n",
      "Epoch [5/50], Step [290/735], Loss: 0.2734\n",
      "Epoch [5/50], Step [291/735], Loss: 0.2350\n",
      "Epoch [5/50], Step [292/735], Loss: 0.2489\n",
      "Epoch [5/50], Step [293/735], Loss: 0.2525\n",
      "Epoch [5/50], Step [294/735], Loss: 0.4390\n",
      "Epoch [5/50], Step [295/735], Loss: 0.2596\n",
      "Epoch [5/50], Step [296/735], Loss: 0.1821\n",
      "Epoch [5/50], Step [297/735], Loss: 0.2404\n",
      "Epoch [5/50], Step [298/735], Loss: 0.2484\n",
      "Epoch [5/50], Step [299/735], Loss: 0.1550\n",
      "Epoch [5/50], Step [300/735], Loss: 0.1685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Step [301/735], Loss: 0.2128\n",
      "Epoch [5/50], Step [302/735], Loss: 0.1875\n",
      "Epoch [5/50], Step [303/735], Loss: 0.0932\n",
      "Epoch [5/50], Step [304/735], Loss: 0.2375\n",
      "Epoch [5/50], Step [305/735], Loss: 0.2313\n",
      "Epoch [5/50], Step [306/735], Loss: 0.1997\n",
      "Epoch [5/50], Step [307/735], Loss: 0.1066\n",
      "Epoch [5/50], Step [308/735], Loss: 0.1629\n",
      "Epoch [5/50], Step [309/735], Loss: 0.1359\n",
      "Epoch [5/50], Step [310/735], Loss: 0.3023\n",
      "Epoch [5/50], Step [311/735], Loss: 0.5275\n",
      "Epoch [5/50], Step [312/735], Loss: 0.6968\n",
      "Epoch [5/50], Step [313/735], Loss: 0.2869\n",
      "Epoch [5/50], Step [314/735], Loss: 0.2916\n",
      "Epoch [5/50], Step [315/735], Loss: 0.7641\n",
      "Epoch [5/50], Step [316/735], Loss: 0.2201\n",
      "Epoch [5/50], Step [317/735], Loss: 0.8068\n",
      "Epoch [5/50], Step [318/735], Loss: 0.5401\n",
      "Epoch [5/50], Step [319/735], Loss: 0.3584\n",
      "Epoch [5/50], Step [320/735], Loss: 0.1942\n",
      "Epoch [5/50], Step [321/735], Loss: 0.1839\n",
      "Epoch [5/50], Step [322/735], Loss: 0.2711\n",
      "Epoch [5/50], Step [323/735], Loss: 0.1524\n",
      "Epoch [5/50], Step [324/735], Loss: 0.3312\n",
      "Epoch [5/50], Step [325/735], Loss: 0.1475\n",
      "Epoch [5/50], Step [326/735], Loss: 0.3521\n",
      "Epoch [5/50], Step [327/735], Loss: 0.2517\n",
      "Epoch [5/50], Step [328/735], Loss: 0.6124\n",
      "Epoch [5/50], Step [329/735], Loss: 0.6202\n",
      "Epoch [5/50], Step [330/735], Loss: 0.1121\n",
      "Epoch [5/50], Step [331/735], Loss: 0.1394\n",
      "Epoch [5/50], Step [332/735], Loss: 0.5326\n",
      "Epoch [5/50], Step [333/735], Loss: 0.1564\n",
      "Epoch [5/50], Step [334/735], Loss: 0.8765\n",
      "Epoch [5/50], Step [335/735], Loss: 0.2573\n",
      "Epoch [5/50], Step [336/735], Loss: 0.3238\n",
      "Epoch [5/50], Step [337/735], Loss: 0.7790\n",
      "Epoch [5/50], Step [338/735], Loss: 0.2992\n",
      "Epoch [5/50], Step [339/735], Loss: 0.2433\n",
      "Epoch [5/50], Step [340/735], Loss: 0.2679\n",
      "Epoch [5/50], Step [341/735], Loss: 0.2933\n",
      "Epoch [5/50], Step [342/735], Loss: 0.1452\n",
      "Epoch [5/50], Step [343/735], Loss: 0.1329\n",
      "Epoch [5/50], Step [344/735], Loss: 0.3671\n",
      "Epoch [5/50], Step [345/735], Loss: 0.5536\n",
      "Epoch [5/50], Step [346/735], Loss: 0.2074\n",
      "Epoch [5/50], Step [347/735], Loss: 0.1895\n",
      "Epoch [5/50], Step [348/735], Loss: 0.1876\n",
      "Epoch [5/50], Step [349/735], Loss: 0.1214\n",
      "Epoch [5/50], Step [350/735], Loss: 0.1454\n",
      "Epoch [5/50], Step [351/735], Loss: 0.1462\n",
      "Epoch [5/50], Step [352/735], Loss: 0.1586\n",
      "Epoch [5/50], Step [353/735], Loss: 0.1458\n",
      "Epoch [5/50], Step [354/735], Loss: 0.1000\n",
      "Epoch [5/50], Step [355/735], Loss: 0.4858\n",
      "Epoch [5/50], Step [356/735], Loss: 0.2219\n",
      "Epoch [5/50], Step [357/735], Loss: 0.2602\n",
      "Epoch [5/50], Step [358/735], Loss: 0.1233\n",
      "Epoch [5/50], Step [359/735], Loss: 0.1173\n",
      "Epoch [5/50], Step [360/735], Loss: 0.2002\n",
      "Epoch [5/50], Step [361/735], Loss: 0.2049\n",
      "Epoch [5/50], Step [362/735], Loss: 0.1954\n",
      "Epoch [5/50], Step [363/735], Loss: 1.3255\n",
      "Epoch [5/50], Step [364/735], Loss: 0.1116\n",
      "Epoch [5/50], Step [365/735], Loss: 0.1781\n",
      "Epoch [5/50], Step [366/735], Loss: 0.4006\n",
      "Epoch [5/50], Step [367/735], Loss: 0.2035\n",
      "Epoch [5/50], Step [368/735], Loss: 0.1319\n",
      "Epoch [5/50], Step [369/735], Loss: 0.1306\n",
      "Epoch [5/50], Step [370/735], Loss: 0.2499\n",
      "Epoch [5/50], Step [371/735], Loss: 0.6428\n",
      "Epoch [5/50], Step [372/735], Loss: 0.1722\n",
      "Epoch [5/50], Step [373/735], Loss: 0.2393\n",
      "Epoch [5/50], Step [374/735], Loss: 0.1656\n",
      "Epoch [5/50], Step [375/735], Loss: 0.1367\n",
      "Epoch [5/50], Step [376/735], Loss: 0.2585\n",
      "Epoch [5/50], Step [377/735], Loss: 0.1699\n",
      "Epoch [5/50], Step [378/735], Loss: 0.1735\n",
      "Epoch [5/50], Step [379/735], Loss: 0.1534\n",
      "Epoch [5/50], Step [380/735], Loss: 0.1417\n",
      "Epoch [5/50], Step [381/735], Loss: 0.4045\n",
      "Epoch [5/50], Step [382/735], Loss: 0.1012\n",
      "Epoch [5/50], Step [383/735], Loss: 0.3683\n",
      "Epoch [5/50], Step [384/735], Loss: 0.1867\n",
      "Epoch [5/50], Step [385/735], Loss: 0.2852\n",
      "Epoch [5/50], Step [386/735], Loss: 0.3569\n",
      "Epoch [5/50], Step [387/735], Loss: 0.3354\n",
      "Epoch [5/50], Step [388/735], Loss: 0.2224\n",
      "Epoch [5/50], Step [389/735], Loss: 0.3179\n",
      "Epoch [5/50], Step [390/735], Loss: 0.4050\n",
      "Epoch [5/50], Step [391/735], Loss: 2.3644\n",
      "Epoch [5/50], Step [392/735], Loss: 1.2856\n",
      "Epoch [5/50], Step [393/735], Loss: 0.5138\n",
      "Epoch [5/50], Step [394/735], Loss: 0.2982\n",
      "Epoch [5/50], Step [395/735], Loss: 0.3726\n",
      "Epoch [5/50], Step [396/735], Loss: 0.3876\n",
      "Epoch [5/50], Step [397/735], Loss: 0.4262\n",
      "Epoch [5/50], Step [398/735], Loss: 0.8252\n",
      "Epoch [5/50], Step [399/735], Loss: 0.1422\n",
      "Epoch [5/50], Step [400/735], Loss: 0.1323\n",
      "Epoch [5/50], Step [401/735], Loss: 0.1736\n",
      "Epoch [5/50], Step [402/735], Loss: 0.1816\n",
      "Epoch [5/50], Step [403/735], Loss: 0.4412\n",
      "Epoch [5/50], Step [404/735], Loss: 0.0969\n",
      "Epoch [5/50], Step [405/735], Loss: 0.1754\n",
      "Epoch [5/50], Step [406/735], Loss: 0.2105\n",
      "Epoch [5/50], Step [407/735], Loss: 0.4688\n",
      "Epoch [5/50], Step [408/735], Loss: 0.4167\n",
      "Epoch [5/50], Step [409/735], Loss: 0.3964\n",
      "Epoch [5/50], Step [410/735], Loss: 0.3066\n",
      "Epoch [5/50], Step [411/735], Loss: 0.2066\n",
      "Epoch [5/50], Step [412/735], Loss: 1.3931\n",
      "Epoch [5/50], Step [413/735], Loss: 0.3086\n",
      "Epoch [5/50], Step [414/735], Loss: 0.2718\n",
      "Epoch [5/50], Step [415/735], Loss: 0.1003\n",
      "Epoch [5/50], Step [416/735], Loss: 0.2926\n",
      "Epoch [5/50], Step [417/735], Loss: 0.4550\n",
      "Epoch [5/50], Step [418/735], Loss: 0.2708\n",
      "Epoch [5/50], Step [419/735], Loss: 0.3510\n",
      "Epoch [5/50], Step [420/735], Loss: 0.1734\n",
      "Epoch [5/50], Step [421/735], Loss: 0.4142\n",
      "Epoch [5/50], Step [422/735], Loss: 0.1451\n",
      "Epoch [5/50], Step [423/735], Loss: 0.1431\n",
      "Epoch [5/50], Step [424/735], Loss: 0.2583\n",
      "Epoch [5/50], Step [425/735], Loss: 0.2248\n",
      "Epoch [5/50], Step [426/735], Loss: 0.1040\n",
      "Epoch [5/50], Step [427/735], Loss: 0.2285\n",
      "Epoch [5/50], Step [428/735], Loss: 0.7129\n",
      "Epoch [5/50], Step [429/735], Loss: 0.2637\n",
      "Epoch [5/50], Step [430/735], Loss: 0.2499\n",
      "Epoch [5/50], Step [431/735], Loss: 0.4772\n",
      "Epoch [5/50], Step [432/735], Loss: 0.3212\n",
      "Epoch [5/50], Step [433/735], Loss: 0.2421\n",
      "Epoch [5/50], Step [434/735], Loss: 0.2407\n",
      "Epoch [5/50], Step [435/735], Loss: 0.2762\n",
      "Epoch [5/50], Step [436/735], Loss: 0.0957\n",
      "Epoch [5/50], Step [437/735], Loss: 0.1497\n",
      "Epoch [5/50], Step [438/735], Loss: 0.1528\n",
      "Epoch [5/50], Step [439/735], Loss: 0.4031\n",
      "Epoch [5/50], Step [440/735], Loss: 0.0910\n",
      "Epoch [5/50], Step [441/735], Loss: 0.4804\n",
      "Epoch [5/50], Step [442/735], Loss: 0.1058\n",
      "Epoch [5/50], Step [443/735], Loss: 0.3834\n",
      "Epoch [5/50], Step [444/735], Loss: 0.1254\n",
      "Epoch [5/50], Step [445/735], Loss: 0.2147\n",
      "Epoch [5/50], Step [446/735], Loss: 0.1262\n",
      "Epoch [5/50], Step [447/735], Loss: 0.2398\n",
      "Epoch [5/50], Step [448/735], Loss: 0.2052\n",
      "Epoch [5/50], Step [449/735], Loss: 0.3242\n",
      "Epoch [5/50], Step [450/735], Loss: 0.1314\n",
      "Epoch [5/50], Step [451/735], Loss: 0.2168\n",
      "Epoch [5/50], Step [452/735], Loss: 0.1824\n",
      "Epoch [5/50], Step [453/735], Loss: 0.1235\n",
      "Epoch [5/50], Step [454/735], Loss: 0.6946\n",
      "Epoch [5/50], Step [455/735], Loss: 0.3507\n",
      "Epoch [5/50], Step [456/735], Loss: 0.1202\n",
      "Epoch [5/50], Step [457/735], Loss: 0.1794\n",
      "Epoch [5/50], Step [458/735], Loss: 0.1109\n",
      "Epoch [5/50], Step [459/735], Loss: 0.1744\n",
      "Epoch [5/50], Step [460/735], Loss: 0.1867\n",
      "Epoch [5/50], Step [461/735], Loss: 0.0861\n",
      "Epoch [5/50], Step [462/735], Loss: 2.1621\n",
      "Epoch [5/50], Step [463/735], Loss: 0.0806\n",
      "Epoch [5/50], Step [464/735], Loss: 0.1656\n",
      "Epoch [5/50], Step [465/735], Loss: 0.1564\n",
      "Epoch [5/50], Step [466/735], Loss: 0.4145\n",
      "Epoch [5/50], Step [467/735], Loss: 0.3089\n",
      "Epoch [5/50], Step [468/735], Loss: 0.0938\n",
      "Epoch [5/50], Step [469/735], Loss: 0.1892\n",
      "Epoch [5/50], Step [470/735], Loss: 0.9524\n",
      "Epoch [5/50], Step [471/735], Loss: 0.2134\n",
      "Epoch [5/50], Step [472/735], Loss: 0.3858\n",
      "Epoch [5/50], Step [473/735], Loss: 0.2400\n",
      "Epoch [5/50], Step [474/735], Loss: 0.1454\n",
      "Epoch [5/50], Step [475/735], Loss: 0.1880\n",
      "Epoch [5/50], Step [476/735], Loss: 0.1687\n",
      "Epoch [5/50], Step [477/735], Loss: 0.0822\n",
      "Epoch [5/50], Step [478/735], Loss: 0.3555\n",
      "Epoch [5/50], Step [479/735], Loss: 0.1565\n",
      "Epoch [5/50], Step [480/735], Loss: 1.1583\n",
      "Epoch [5/50], Step [481/735], Loss: 0.4071\n",
      "Epoch [5/50], Step [482/735], Loss: 0.6428\n",
      "Epoch [5/50], Step [483/735], Loss: 0.2633\n",
      "Epoch [5/50], Step [484/735], Loss: 0.2771\n",
      "Epoch [5/50], Step [485/735], Loss: 0.3266\n",
      "Epoch [5/50], Step [486/735], Loss: 0.2811\n",
      "Epoch [5/50], Step [487/735], Loss: 0.1898\n",
      "Epoch [5/50], Step [488/735], Loss: 0.0787\n",
      "Epoch [5/50], Step [489/735], Loss: 0.3143\n",
      "Epoch [5/50], Step [490/735], Loss: 0.1443\n",
      "Epoch [5/50], Step [491/735], Loss: 0.4111\n",
      "Epoch [5/50], Step [492/735], Loss: 0.2416\n",
      "Epoch [5/50], Step [493/735], Loss: 1.2880\n",
      "Epoch [5/50], Step [494/735], Loss: 0.3558\n",
      "Epoch [5/50], Step [495/735], Loss: 0.4360\n",
      "Epoch [5/50], Step [496/735], Loss: 0.2697\n",
      "Epoch [5/50], Step [497/735], Loss: 0.2332\n",
      "Epoch [5/50], Step [498/735], Loss: 0.2339\n",
      "Epoch [5/50], Step [499/735], Loss: 0.2359\n",
      "Epoch [5/50], Step [500/735], Loss: 0.3541\n",
      "Epoch [5/50], Step [501/735], Loss: 0.2269\n",
      "Epoch [5/50], Step [502/735], Loss: 0.2725\n",
      "Epoch [5/50], Step [503/735], Loss: 0.1626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Step [504/735], Loss: 0.4318\n",
      "Epoch [5/50], Step [505/735], Loss: 0.1684\n",
      "Epoch [5/50], Step [506/735], Loss: 0.4114\n",
      "Epoch [5/50], Step [507/735], Loss: 0.1234\n",
      "Epoch [5/50], Step [508/735], Loss: 0.3691\n",
      "Epoch [5/50], Step [509/735], Loss: 0.2371\n",
      "Epoch [5/50], Step [510/735], Loss: 0.4595\n",
      "Epoch [5/50], Step [511/735], Loss: 0.3532\n",
      "Epoch [5/50], Step [512/735], Loss: 0.1740\n",
      "Epoch [5/50], Step [513/735], Loss: 0.3790\n",
      "Epoch [5/50], Step [514/735], Loss: 0.3023\n",
      "Epoch [5/50], Step [515/735], Loss: 0.1145\n",
      "Epoch [5/50], Step [516/735], Loss: 0.1741\n",
      "Epoch [5/50], Step [517/735], Loss: 0.2158\n",
      "Epoch [5/50], Step [518/735], Loss: 0.2616\n",
      "Epoch [5/50], Step [519/735], Loss: 0.1302\n",
      "Epoch [5/50], Step [520/735], Loss: 0.0683\n",
      "Epoch [5/50], Step [521/735], Loss: 0.1496\n",
      "Epoch [5/50], Step [522/735], Loss: 0.1446\n",
      "Epoch [5/50], Step [523/735], Loss: 0.1903\n",
      "Epoch [5/50], Step [524/735], Loss: 0.1767\n",
      "Epoch [5/50], Step [525/735], Loss: 0.1663\n",
      "Epoch [5/50], Step [526/735], Loss: 1.3409\n",
      "Epoch [5/50], Step [527/735], Loss: 0.1163\n",
      "Epoch [5/50], Step [528/735], Loss: 0.3411\n",
      "Epoch [5/50], Step [529/735], Loss: 0.1406\n",
      "Epoch [5/50], Step [530/735], Loss: 0.0807\n",
      "Epoch [5/50], Step [531/735], Loss: 0.4294\n",
      "Epoch [5/50], Step [532/735], Loss: 0.1581\n",
      "Epoch [5/50], Step [533/735], Loss: 0.1221\n",
      "Epoch [5/50], Step [534/735], Loss: 0.2132\n",
      "Epoch [5/50], Step [535/735], Loss: 0.0734\n",
      "Epoch [5/50], Step [536/735], Loss: 0.3585\n",
      "Epoch [5/50], Step [537/735], Loss: 0.2895\n",
      "Epoch [5/50], Step [538/735], Loss: 0.1211\n",
      "Epoch [5/50], Step [539/735], Loss: 0.4448\n",
      "Epoch [5/50], Step [540/735], Loss: 0.2248\n",
      "Epoch [5/50], Step [541/735], Loss: 0.1356\n",
      "Epoch [5/50], Step [542/735], Loss: 0.1656\n",
      "Epoch [5/50], Step [543/735], Loss: 0.1179\n",
      "Epoch [5/50], Step [544/735], Loss: 0.0814\n",
      "Epoch [5/50], Step [545/735], Loss: 0.0791\n",
      "Epoch [5/50], Step [546/735], Loss: 0.1913\n",
      "Epoch [5/50], Step [547/735], Loss: 1.5075\n",
      "Epoch [5/50], Step [548/735], Loss: 0.1838\n",
      "Epoch [5/50], Step [549/735], Loss: 0.5900\n",
      "Epoch [5/50], Step [550/735], Loss: 0.1816\n",
      "Epoch [5/50], Step [551/735], Loss: 0.2060\n",
      "Epoch [5/50], Step [552/735], Loss: 0.1213\n",
      "Epoch [5/50], Step [553/735], Loss: 0.1718\n",
      "Epoch [5/50], Step [554/735], Loss: 0.2253\n",
      "Epoch [5/50], Step [555/735], Loss: 0.4884\n",
      "Epoch [5/50], Step [556/735], Loss: 0.6188\n",
      "Epoch [5/50], Step [557/735], Loss: 0.1529\n",
      "Epoch [5/50], Step [558/735], Loss: 0.3795\n",
      "Epoch [5/50], Step [559/735], Loss: 1.3506\n",
      "Epoch [5/50], Step [560/735], Loss: 0.3794\n",
      "Epoch [5/50], Step [561/735], Loss: 0.4001\n",
      "Epoch [5/50], Step [562/735], Loss: 0.2023\n",
      "Epoch [5/50], Step [563/735], Loss: 0.2112\n",
      "Epoch [5/50], Step [564/735], Loss: 0.2865\n",
      "Epoch [5/50], Step [565/735], Loss: 0.6811\n",
      "Epoch [5/50], Step [566/735], Loss: 0.3566\n",
      "Epoch [5/50], Step [567/735], Loss: 0.3212\n",
      "Epoch [5/50], Step [568/735], Loss: 0.1264\n",
      "Epoch [5/50], Step [569/735], Loss: 0.3824\n",
      "Epoch [5/50], Step [570/735], Loss: 0.1770\n",
      "Epoch [5/50], Step [571/735], Loss: 0.1373\n",
      "Epoch [5/50], Step [572/735], Loss: 0.1563\n",
      "Epoch [5/50], Step [573/735], Loss: 0.1821\n",
      "Epoch [5/50], Step [574/735], Loss: 0.2634\n",
      "Epoch [5/50], Step [575/735], Loss: 0.2273\n",
      "Epoch [5/50], Step [576/735], Loss: 0.1974\n",
      "Epoch [5/50], Step [577/735], Loss: 0.2805\n",
      "Epoch [5/50], Step [578/735], Loss: 0.3538\n",
      "Epoch [5/50], Step [579/735], Loss: 0.2784\n",
      "Epoch [5/50], Step [580/735], Loss: 0.1760\n",
      "Epoch [5/50], Step [581/735], Loss: 0.3497\n",
      "Epoch [5/50], Step [582/735], Loss: 0.1093\n",
      "Epoch [5/50], Step [583/735], Loss: 0.6245\n",
      "Epoch [5/50], Step [584/735], Loss: 0.2177\n",
      "Epoch [5/50], Step [585/735], Loss: 0.2643\n",
      "Epoch [5/50], Step [586/735], Loss: 0.3868\n",
      "Epoch [5/50], Step [587/735], Loss: 0.1600\n",
      "Epoch [5/50], Step [588/735], Loss: 0.1452\n",
      "Epoch [5/50], Step [589/735], Loss: 0.2258\n",
      "Epoch [5/50], Step [590/735], Loss: 0.3121\n",
      "Epoch [5/50], Step [591/735], Loss: 0.2706\n",
      "Epoch [5/50], Step [592/735], Loss: 0.1426\n",
      "Epoch [5/50], Step [593/735], Loss: 0.5919\n",
      "Epoch [5/50], Step [594/735], Loss: 0.0889\n",
      "Epoch [5/50], Step [595/735], Loss: 0.3915\n",
      "Epoch [5/50], Step [596/735], Loss: 0.0826\n",
      "Epoch [5/50], Step [597/735], Loss: 0.4088\n",
      "Epoch [5/50], Step [598/735], Loss: 0.2091\n",
      "Epoch [5/50], Step [599/735], Loss: 0.2015\n",
      "Epoch [5/50], Step [600/735], Loss: 0.0785\n",
      "Epoch [5/50], Step [601/735], Loss: 0.1443\n",
      "Epoch [5/50], Step [602/735], Loss: 0.6083\n",
      "Epoch [5/50], Step [603/735], Loss: 0.3646\n",
      "Epoch [5/50], Step [604/735], Loss: 0.1335\n",
      "Epoch [5/50], Step [605/735], Loss: 0.2294\n",
      "Epoch [5/50], Step [606/735], Loss: 1.9505\n",
      "Epoch [5/50], Step [607/735], Loss: 0.0521\n",
      "Epoch [5/50], Step [608/735], Loss: 0.0659\n",
      "Epoch [5/50], Step [609/735], Loss: 0.0904\n",
      "Epoch [5/50], Step [610/735], Loss: 0.0917\n",
      "Epoch [5/50], Step [611/735], Loss: 0.2809\n",
      "Epoch [5/50], Step [612/735], Loss: 0.1313\n",
      "Epoch [5/50], Step [613/735], Loss: 0.5861\n",
      "Epoch [5/50], Step [614/735], Loss: 0.1665\n",
      "Epoch [5/50], Step [615/735], Loss: 0.3276\n",
      "Epoch [5/50], Step [616/735], Loss: 0.2160\n",
      "Epoch [5/50], Step [617/735], Loss: 0.3581\n",
      "Epoch [5/50], Step [618/735], Loss: 0.1465\n",
      "Epoch [5/50], Step [619/735], Loss: 1.2168\n",
      "Epoch [5/50], Step [620/735], Loss: 0.1594\n",
      "Epoch [5/50], Step [621/735], Loss: 0.1561\n",
      "Epoch [5/50], Step [622/735], Loss: 0.2591\n",
      "Epoch [5/50], Step [623/735], Loss: 0.3456\n",
      "Epoch [5/50], Step [624/735], Loss: 0.1050\n",
      "Epoch [5/50], Step [625/735], Loss: 0.0970\n",
      "Epoch [5/50], Step [626/735], Loss: 0.8677\n",
      "Epoch [5/50], Step [627/735], Loss: 0.5743\n",
      "Epoch [5/50], Step [628/735], Loss: 0.1118\n",
      "Epoch [5/50], Step [629/735], Loss: 0.3378\n",
      "Epoch [5/50], Step [630/735], Loss: 0.2751\n",
      "Epoch [5/50], Step [631/735], Loss: 0.1751\n",
      "Epoch [5/50], Step [632/735], Loss: 0.3479\n",
      "Epoch [5/50], Step [633/735], Loss: 0.2428\n",
      "Epoch [5/50], Step [634/735], Loss: 0.2096\n",
      "Epoch [5/50], Step [635/735], Loss: 0.1658\n",
      "Epoch [5/50], Step [636/735], Loss: 0.2231\n",
      "Epoch [5/50], Step [637/735], Loss: 0.0873\n",
      "Epoch [5/50], Step [638/735], Loss: 0.1130\n",
      "Epoch [5/50], Step [639/735], Loss: 0.1303\n",
      "Epoch [5/50], Step [640/735], Loss: 0.1079\n",
      "Epoch [5/50], Step [641/735], Loss: 0.2170\n",
      "Epoch [5/50], Step [642/735], Loss: 0.2844\n",
      "Epoch [5/50], Step [643/735], Loss: 0.1667\n",
      "Epoch [5/50], Step [644/735], Loss: 0.1755\n",
      "Epoch [5/50], Step [645/735], Loss: 0.1512\n",
      "Epoch [5/50], Step [646/735], Loss: 0.5172\n",
      "Epoch [5/50], Step [647/735], Loss: 0.1779\n",
      "Epoch [5/50], Step [648/735], Loss: 0.2712\n",
      "Epoch [5/50], Step [649/735], Loss: 0.1277\n",
      "Epoch [5/50], Step [650/735], Loss: 0.1397\n",
      "Epoch [5/50], Step [651/735], Loss: 0.1112\n",
      "Epoch [5/50], Step [652/735], Loss: 0.0912\n",
      "Epoch [5/50], Step [653/735], Loss: 0.4933\n",
      "Epoch [5/50], Step [654/735], Loss: 0.1497\n",
      "Epoch [5/50], Step [655/735], Loss: 0.2325\n",
      "Epoch [5/50], Step [656/735], Loss: 0.1231\n",
      "Epoch [5/50], Step [657/735], Loss: 0.3877\n",
      "Epoch [5/50], Step [658/735], Loss: 0.3656\n",
      "Epoch [5/50], Step [659/735], Loss: 0.1021\n",
      "Epoch [5/50], Step [660/735], Loss: 0.2976\n",
      "Epoch [5/50], Step [661/735], Loss: 1.4404\n",
      "Epoch [5/50], Step [662/735], Loss: 0.5711\n",
      "Epoch [5/50], Step [663/735], Loss: 0.2914\n",
      "Epoch [5/50], Step [664/735], Loss: 0.1361\n",
      "Epoch [5/50], Step [665/735], Loss: 0.5899\n",
      "Epoch [5/50], Step [666/735], Loss: 0.2142\n",
      "Epoch [5/50], Step [667/735], Loss: 0.1390\n",
      "Epoch [5/50], Step [668/735], Loss: 0.1878\n",
      "Epoch [5/50], Step [669/735], Loss: 0.1601\n",
      "Epoch [5/50], Step [670/735], Loss: 0.2215\n",
      "Epoch [5/50], Step [671/735], Loss: 0.2918\n",
      "Epoch [5/50], Step [672/735], Loss: 0.1289\n",
      "Epoch [5/50], Step [673/735], Loss: 0.3173\n",
      "Epoch [5/50], Step [674/735], Loss: 0.2835\n",
      "Epoch [5/50], Step [675/735], Loss: 0.1961\n",
      "Epoch [5/50], Step [676/735], Loss: 0.3718\n",
      "Epoch [5/50], Step [677/735], Loss: 0.3593\n",
      "Epoch [5/50], Step [678/735], Loss: 0.1820\n",
      "Epoch [5/50], Step [679/735], Loss: 0.1598\n",
      "Epoch [5/50], Step [680/735], Loss: 2.1895\n",
      "Epoch [5/50], Step [681/735], Loss: 0.1327\n",
      "Epoch [5/50], Step [682/735], Loss: 0.2607\n",
      "Epoch [5/50], Step [683/735], Loss: 0.7134\n",
      "Epoch [5/50], Step [684/735], Loss: 0.3419\n",
      "Epoch [5/50], Step [685/735], Loss: 0.3250\n",
      "Epoch [5/50], Step [686/735], Loss: 0.3796\n",
      "Epoch [5/50], Step [687/735], Loss: 0.0711\n",
      "Epoch [5/50], Step [688/735], Loss: 0.0854\n",
      "Epoch [5/50], Step [689/735], Loss: 0.1642\n",
      "Epoch [5/50], Step [690/735], Loss: 0.7036\n",
      "Epoch [5/50], Step [691/735], Loss: 0.1111\n",
      "Epoch [5/50], Step [692/735], Loss: 0.3009\n",
      "Epoch [5/50], Step [693/735], Loss: 0.3511\n",
      "Epoch [5/50], Step [694/735], Loss: 0.1638\n",
      "Epoch [5/50], Step [695/735], Loss: 0.1781\n",
      "Epoch [5/50], Step [696/735], Loss: 0.0973\n",
      "Epoch [5/50], Step [697/735], Loss: 0.3425\n",
      "Epoch [5/50], Step [698/735], Loss: 0.1466\n",
      "Epoch [5/50], Step [699/735], Loss: 0.3452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Step [700/735], Loss: 0.1874\n",
      "Epoch [5/50], Step [701/735], Loss: 0.4827\n",
      "Epoch [5/50], Step [702/735], Loss: 2.9997\n",
      "Epoch [5/50], Step [703/735], Loss: 1.2839\n",
      "Epoch [5/50], Step [704/735], Loss: 0.1229\n",
      "Epoch [5/50], Step [705/735], Loss: 0.1847\n",
      "Epoch [5/50], Step [706/735], Loss: 0.1891\n",
      "Epoch [5/50], Step [707/735], Loss: 0.1505\n",
      "Epoch [5/50], Step [708/735], Loss: 0.2088\n",
      "Epoch [5/50], Step [709/735], Loss: 0.1565\n",
      "Epoch [5/50], Step [710/735], Loss: 0.2750\n",
      "Epoch [5/50], Step [711/735], Loss: 0.4490\n",
      "Epoch [5/50], Step [712/735], Loss: 0.2824\n",
      "Epoch [5/50], Step [713/735], Loss: 0.1224\n",
      "Epoch [5/50], Step [714/735], Loss: 0.1643\n",
      "Epoch [5/50], Step [715/735], Loss: 0.1512\n",
      "Epoch [5/50], Step [716/735], Loss: 0.3382\n",
      "Epoch [5/50], Step [717/735], Loss: 1.0419\n",
      "Epoch [5/50], Step [718/735], Loss: 0.2188\n",
      "Epoch [5/50], Step [719/735], Loss: 0.1165\n",
      "Epoch [5/50], Step [720/735], Loss: 0.1689\n",
      "Epoch [5/50], Step [721/735], Loss: 0.1932\n",
      "Epoch [5/50], Step [722/735], Loss: 0.2408\n",
      "Epoch [5/50], Step [723/735], Loss: 0.2770\n",
      "Epoch [5/50], Step [724/735], Loss: 0.3001\n",
      "Epoch [5/50], Step [725/735], Loss: 0.0941\n",
      "Epoch [5/50], Step [726/735], Loss: 0.4481\n",
      "Epoch [5/50], Step [727/735], Loss: 0.2568\n",
      "Epoch [5/50], Step [728/735], Loss: 0.5303\n",
      "Epoch [5/50], Step [729/735], Loss: 0.1218\n",
      "Epoch [5/50], Step [730/735], Loss: 0.2149\n",
      "Epoch [5/50], Step [731/735], Loss: 0.2692\n",
      "Epoch [5/50], Step [732/735], Loss: 0.0934\n",
      "Epoch [5/50], Step [733/735], Loss: 0.2541\n",
      "Epoch [5/50], Step [734/735], Loss: 0.5345\n",
      "Epoch [5/50], Step [735/735], Loss: 0.1566\n",
      "Epoch [6/50], Step [1/735], Loss: 0.2004\n",
      "Epoch [6/50], Step [2/735], Loss: 0.2819\n",
      "Epoch [6/50], Step [3/735], Loss: 0.0898\n",
      "Epoch [6/50], Step [4/735], Loss: 0.1964\n",
      "Epoch [6/50], Step [5/735], Loss: 0.1824\n",
      "Epoch [6/50], Step [6/735], Loss: 0.1547\n",
      "Epoch [6/50], Step [7/735], Loss: 0.2849\n",
      "Epoch [6/50], Step [8/735], Loss: 0.1635\n",
      "Epoch [6/50], Step [9/735], Loss: 0.4189\n",
      "Epoch [6/50], Step [10/735], Loss: 0.5687\n",
      "Epoch [6/50], Step [11/735], Loss: 0.2818\n",
      "Epoch [6/50], Step [12/735], Loss: 1.1986\n",
      "Epoch [6/50], Step [13/735], Loss: 0.1346\n",
      "Epoch [6/50], Step [14/735], Loss: 0.2150\n",
      "Epoch [6/50], Step [15/735], Loss: 0.1835\n",
      "Epoch [6/50], Step [16/735], Loss: 0.2173\n",
      "Epoch [6/50], Step [17/735], Loss: 0.1284\n",
      "Epoch [6/50], Step [18/735], Loss: 0.1755\n",
      "Epoch [6/50], Step [19/735], Loss: 0.1746\n",
      "Epoch [6/50], Step [20/735], Loss: 0.4557\n",
      "Epoch [6/50], Step [21/735], Loss: 0.2233\n",
      "Epoch [6/50], Step [22/735], Loss: 0.1867\n",
      "Epoch [6/50], Step [23/735], Loss: 0.2387\n",
      "Epoch [6/50], Step [24/735], Loss: 0.2472\n",
      "Epoch [6/50], Step [25/735], Loss: 0.6474\n",
      "Epoch [6/50], Step [26/735], Loss: 0.1855\n",
      "Epoch [6/50], Step [27/735], Loss: 0.2484\n",
      "Epoch [6/50], Step [28/735], Loss: 0.3820\n",
      "Epoch [6/50], Step [29/735], Loss: 0.1670\n",
      "Epoch [6/50], Step [30/735], Loss: 0.1462\n",
      "Epoch [6/50], Step [31/735], Loss: 0.1384\n",
      "Epoch [6/50], Step [32/735], Loss: 0.2028\n",
      "Epoch [6/50], Step [33/735], Loss: 0.1240\n",
      "Epoch [6/50], Step [34/735], Loss: 0.1343\n",
      "Epoch [6/50], Step [35/735], Loss: 0.1359\n",
      "Epoch [6/50], Step [36/735], Loss: 0.8042\n",
      "Epoch [6/50], Step [37/735], Loss: 0.2160\n",
      "Epoch [6/50], Step [38/735], Loss: 0.1934\n",
      "Epoch [6/50], Step [39/735], Loss: 0.1090\n",
      "Epoch [6/50], Step [40/735], Loss: 0.0722\n",
      "Epoch [6/50], Step [41/735], Loss: 0.2362\n",
      "Epoch [6/50], Step [42/735], Loss: 0.1498\n",
      "Epoch [6/50], Step [43/735], Loss: 0.7889\n",
      "Epoch [6/50], Step [44/735], Loss: 2.7766\n",
      "Epoch [6/50], Step [45/735], Loss: 0.1260\n",
      "Epoch [6/50], Step [46/735], Loss: 0.2458\n",
      "Epoch [6/50], Step [47/735], Loss: 0.2734\n",
      "Epoch [6/50], Step [48/735], Loss: 0.0832\n",
      "Epoch [6/50], Step [49/735], Loss: 0.1088\n",
      "Epoch [6/50], Step [50/735], Loss: 0.2294\n",
      "Epoch [6/50], Step [51/735], Loss: 0.0787\n",
      "Epoch [6/50], Step [52/735], Loss: 0.3550\n",
      "Epoch [6/50], Step [53/735], Loss: 0.0724\n",
      "Epoch [6/50], Step [54/735], Loss: 0.3446\n",
      "Epoch [6/50], Step [55/735], Loss: 0.0978\n",
      "Epoch [6/50], Step [56/735], Loss: 0.2468\n",
      "Epoch [6/50], Step [57/735], Loss: 0.1236\n",
      "Epoch [6/50], Step [58/735], Loss: 0.3105\n",
      "Epoch [6/50], Step [59/735], Loss: 0.2415\n",
      "Epoch [6/50], Step [60/735], Loss: 0.1470\n",
      "Epoch [6/50], Step [61/735], Loss: 0.2954\n",
      "Epoch [6/50], Step [62/735], Loss: 0.1452\n",
      "Epoch [6/50], Step [63/735], Loss: 0.0848\n",
      "Epoch [6/50], Step [64/735], Loss: 0.0974\n",
      "Epoch [6/50], Step [65/735], Loss: 0.3262\n",
      "Epoch [6/50], Step [66/735], Loss: 0.1591\n",
      "Epoch [6/50], Step [67/735], Loss: 0.2121\n",
      "Epoch [6/50], Step [68/735], Loss: 0.1913\n",
      "Epoch [6/50], Step [69/735], Loss: 0.4328\n",
      "Epoch [6/50], Step [70/735], Loss: 0.2335\n",
      "Epoch [6/50], Step [71/735], Loss: 0.2029\n",
      "Epoch [6/50], Step [72/735], Loss: 0.3659\n",
      "Epoch [6/50], Step [73/735], Loss: 0.1254\n",
      "Epoch [6/50], Step [74/735], Loss: 0.4616\n",
      "Epoch [6/50], Step [75/735], Loss: 0.1401\n",
      "Epoch [6/50], Step [76/735], Loss: 0.2047\n",
      "Epoch [6/50], Step [77/735], Loss: 0.4098\n",
      "Epoch [6/50], Step [78/735], Loss: 0.2293\n",
      "Epoch [6/50], Step [79/735], Loss: 0.2315\n",
      "Epoch [6/50], Step [80/735], Loss: 0.0754\n",
      "Epoch [6/50], Step [81/735], Loss: 0.2739\n",
      "Epoch [6/50], Step [82/735], Loss: 0.1898\n",
      "Epoch [6/50], Step [83/735], Loss: 0.1962\n",
      "Epoch [6/50], Step [84/735], Loss: 0.3348\n",
      "Epoch [6/50], Step [85/735], Loss: 0.2296\n",
      "Epoch [6/50], Step [86/735], Loss: 0.0689\n",
      "Epoch [6/50], Step [87/735], Loss: 0.8447\n",
      "Epoch [6/50], Step [88/735], Loss: 0.6467\n",
      "Epoch [6/50], Step [89/735], Loss: 0.1885\n",
      "Epoch [6/50], Step [90/735], Loss: 0.1241\n",
      "Epoch [6/50], Step [91/735], Loss: 0.2058\n",
      "Epoch [6/50], Step [92/735], Loss: 0.2097\n",
      "Epoch [6/50], Step [93/735], Loss: 0.1898\n",
      "Epoch [6/50], Step [94/735], Loss: 0.1886\n",
      "Epoch [6/50], Step [95/735], Loss: 0.1606\n",
      "Epoch [6/50], Step [96/735], Loss: 0.3316\n",
      "Epoch [6/50], Step [97/735], Loss: 0.1996\n",
      "Epoch [6/50], Step [98/735], Loss: 0.1937\n",
      "Epoch [6/50], Step [99/735], Loss: 0.1668\n",
      "Epoch [6/50], Step [100/735], Loss: 2.0975\n",
      "Epoch [6/50], Step [101/735], Loss: 0.4282\n",
      "Epoch [6/50], Step [102/735], Loss: 0.1712\n",
      "Epoch [6/50], Step [103/735], Loss: 0.4655\n",
      "Epoch [6/50], Step [104/735], Loss: 0.1550\n",
      "Epoch [6/50], Step [105/735], Loss: 0.3718\n",
      "Epoch [6/50], Step [106/735], Loss: 0.4087\n",
      "Epoch [6/50], Step [107/735], Loss: 0.1307\n",
      "Epoch [6/50], Step [108/735], Loss: 0.2423\n",
      "Epoch [6/50], Step [109/735], Loss: 0.2017\n",
      "Epoch [6/50], Step [110/735], Loss: 0.2099\n",
      "Epoch [6/50], Step [111/735], Loss: 0.1882\n",
      "Epoch [6/50], Step [112/735], Loss: 0.2764\n",
      "Epoch [6/50], Step [113/735], Loss: 0.5354\n",
      "Epoch [6/50], Step [114/735], Loss: 0.4863\n",
      "Epoch [6/50], Step [115/735], Loss: 1.1626\n",
      "Epoch [6/50], Step [116/735], Loss: 0.3087\n",
      "Epoch [6/50], Step [117/735], Loss: 0.0828\n",
      "Epoch [6/50], Step [118/735], Loss: 0.8358\n",
      "Epoch [6/50], Step [119/735], Loss: 0.1124\n",
      "Epoch [6/50], Step [120/735], Loss: 0.1101\n",
      "Epoch [6/50], Step [121/735], Loss: 0.1493\n",
      "Epoch [6/50], Step [122/735], Loss: 0.2630\n",
      "Epoch [6/50], Step [123/735], Loss: 0.1920\n",
      "Epoch [6/50], Step [124/735], Loss: 0.6601\n",
      "Epoch [6/50], Step [125/735], Loss: 0.2361\n",
      "Epoch [6/50], Step [126/735], Loss: 0.3759\n",
      "Epoch [6/50], Step [127/735], Loss: 0.2469\n",
      "Epoch [6/50], Step [128/735], Loss: 0.2687\n",
      "Epoch [6/50], Step [129/735], Loss: 0.3433\n",
      "Epoch [6/50], Step [130/735], Loss: 0.4916\n",
      "Epoch [6/50], Step [131/735], Loss: 0.1604\n",
      "Epoch [6/50], Step [132/735], Loss: 0.2640\n",
      "Epoch [6/50], Step [133/735], Loss: 0.1906\n",
      "Epoch [6/50], Step [134/735], Loss: 0.2262\n",
      "Epoch [6/50], Step [135/735], Loss: 0.4367\n",
      "Epoch [6/50], Step [136/735], Loss: 0.1843\n",
      "Epoch [6/50], Step [137/735], Loss: 0.1581\n",
      "Epoch [6/50], Step [138/735], Loss: 0.3397\n",
      "Epoch [6/50], Step [139/735], Loss: 0.2010\n",
      "Epoch [6/50], Step [140/735], Loss: 0.2495\n",
      "Epoch [6/50], Step [141/735], Loss: 0.2499\n",
      "Epoch [6/50], Step [142/735], Loss: 0.3455\n",
      "Epoch [6/50], Step [143/735], Loss: 0.9594\n",
      "Epoch [6/50], Step [144/735], Loss: 0.2614\n",
      "Epoch [6/50], Step [145/735], Loss: 0.1528\n",
      "Epoch [6/50], Step [146/735], Loss: 0.1888\n",
      "Epoch [6/50], Step [147/735], Loss: 0.1453\n",
      "Epoch [6/50], Step [148/735], Loss: 0.1907\n",
      "Epoch [6/50], Step [149/735], Loss: 0.2352\n",
      "Epoch [6/50], Step [150/735], Loss: 0.1144\n",
      "Epoch [6/50], Step [151/735], Loss: 0.3420\n",
      "Epoch [6/50], Step [152/735], Loss: 0.2094\n",
      "Epoch [6/50], Step [153/735], Loss: 0.2080\n",
      "Epoch [6/50], Step [154/735], Loss: 0.1511\n",
      "Epoch [6/50], Step [155/735], Loss: 0.1716\n",
      "Epoch [6/50], Step [156/735], Loss: 0.1342\n",
      "Epoch [6/50], Step [157/735], Loss: 0.1363\n",
      "Epoch [6/50], Step [158/735], Loss: 0.2719\n",
      "Epoch [6/50], Step [159/735], Loss: 0.1063\n",
      "Epoch [6/50], Step [160/735], Loss: 0.7572\n",
      "Epoch [6/50], Step [161/735], Loss: 0.2138\n",
      "Epoch [6/50], Step [162/735], Loss: 0.1054\n",
      "Epoch [6/50], Step [163/735], Loss: 0.1613\n",
      "Epoch [6/50], Step [164/735], Loss: 0.0769\n",
      "Epoch [6/50], Step [165/735], Loss: 0.2548\n",
      "Epoch [6/50], Step [166/735], Loss: 0.0625\n",
      "Epoch [6/50], Step [167/735], Loss: 0.1413\n",
      "Epoch [6/50], Step [168/735], Loss: 0.1827\n",
      "Epoch [6/50], Step [169/735], Loss: 0.1007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Step [170/735], Loss: 0.3447\n",
      "Epoch [6/50], Step [171/735], Loss: 0.0798\n",
      "Epoch [6/50], Step [172/735], Loss: 0.1650\n",
      "Epoch [6/50], Step [173/735], Loss: 0.2054\n",
      "Epoch [6/50], Step [174/735], Loss: 0.2263\n",
      "Epoch [6/50], Step [175/735], Loss: 0.3168\n",
      "Epoch [6/50], Step [176/735], Loss: 0.1441\n",
      "Epoch [6/50], Step [177/735], Loss: 0.1343\n",
      "Epoch [6/50], Step [178/735], Loss: 0.1813\n",
      "Epoch [6/50], Step [179/735], Loss: 0.3368\n",
      "Epoch [6/50], Step [180/735], Loss: 1.4019\n",
      "Epoch [6/50], Step [181/735], Loss: 0.1387\n",
      "Epoch [6/50], Step [182/735], Loss: 0.2677\n",
      "Epoch [6/50], Step [183/735], Loss: 0.3447\n",
      "Epoch [6/50], Step [184/735], Loss: 1.1097\n",
      "Epoch [6/50], Step [185/735], Loss: 0.1453\n",
      "Epoch [6/50], Step [186/735], Loss: 0.2103\n",
      "Epoch [6/50], Step [187/735], Loss: 0.2643\n",
      "Epoch [6/50], Step [188/735], Loss: 0.4352\n",
      "Epoch [6/50], Step [189/735], Loss: 0.1693\n",
      "Epoch [6/50], Step [190/735], Loss: 0.2276\n",
      "Epoch [6/50], Step [191/735], Loss: 0.1375\n",
      "Epoch [6/50], Step [192/735], Loss: 0.1070\n",
      "Epoch [6/50], Step [193/735], Loss: 0.1314\n",
      "Epoch [6/50], Step [194/735], Loss: 0.0931\n",
      "Epoch [6/50], Step [195/735], Loss: 0.1688\n",
      "Epoch [6/50], Step [196/735], Loss: 0.1221\n",
      "Epoch [6/50], Step [197/735], Loss: 1.4629\n",
      "Epoch [6/50], Step [198/735], Loss: 0.2181\n",
      "Epoch [6/50], Step [199/735], Loss: 1.0390\n",
      "Epoch [6/50], Step [200/735], Loss: 0.1598\n",
      "Epoch [6/50], Step [201/735], Loss: 0.3442\n",
      "Epoch [6/50], Step [202/735], Loss: 0.2129\n",
      "Epoch [6/50], Step [203/735], Loss: 0.2660\n",
      "Epoch [6/50], Step [204/735], Loss: 0.1288\n",
      "Epoch [6/50], Step [205/735], Loss: 0.2104\n",
      "Epoch [6/50], Step [206/735], Loss: 1.0228\n",
      "Epoch [6/50], Step [207/735], Loss: 0.2144\n",
      "Epoch [6/50], Step [208/735], Loss: 0.1716\n",
      "Epoch [6/50], Step [209/735], Loss: 0.1939\n",
      "Epoch [6/50], Step [210/735], Loss: 0.6074\n",
      "Epoch [6/50], Step [211/735], Loss: 0.1208\n",
      "Epoch [6/50], Step [212/735], Loss: 0.1204\n",
      "Epoch [6/50], Step [213/735], Loss: 0.2291\n",
      "Epoch [6/50], Step [214/735], Loss: 0.3092\n",
      "Epoch [6/50], Step [215/735], Loss: 0.1668\n",
      "Epoch [6/50], Step [216/735], Loss: 0.1195\n",
      "Epoch [6/50], Step [217/735], Loss: 0.4259\n",
      "Epoch [6/50], Step [218/735], Loss: 0.1035\n",
      "Epoch [6/50], Step [219/735], Loss: 0.3542\n",
      "Epoch [6/50], Step [220/735], Loss: 0.2335\n",
      "Epoch [6/50], Step [221/735], Loss: 0.2754\n",
      "Epoch [6/50], Step [222/735], Loss: 0.6412\n",
      "Epoch [6/50], Step [223/735], Loss: 0.1791\n",
      "Epoch [6/50], Step [224/735], Loss: 1.8409\n",
      "Epoch [6/50], Step [225/735], Loss: 0.1376\n",
      "Epoch [6/50], Step [226/735], Loss: 0.3426\n",
      "Epoch [6/50], Step [227/735], Loss: 0.1650\n",
      "Epoch [6/50], Step [228/735], Loss: 0.2537\n",
      "Epoch [6/50], Step [229/735], Loss: 0.1801\n",
      "Epoch [6/50], Step [230/735], Loss: 0.1452\n",
      "Epoch [6/50], Step [231/735], Loss: 0.3330\n",
      "Epoch [6/50], Step [232/735], Loss: 0.1714\n",
      "Epoch [6/50], Step [233/735], Loss: 0.1123\n",
      "Epoch [6/50], Step [234/735], Loss: 0.2039\n",
      "Epoch [6/50], Step [235/735], Loss: 0.2567\n",
      "Epoch [6/50], Step [236/735], Loss: 0.2218\n",
      "Epoch [6/50], Step [237/735], Loss: 0.2219\n",
      "Epoch [6/50], Step [238/735], Loss: 0.6524\n",
      "Epoch [6/50], Step [239/735], Loss: 0.4626\n",
      "Epoch [6/50], Step [240/735], Loss: 0.9702\n",
      "Epoch [6/50], Step [241/735], Loss: 0.1309\n",
      "Epoch [6/50], Step [242/735], Loss: 1.2000\n",
      "Epoch [6/50], Step [243/735], Loss: 0.1680\n",
      "Epoch [6/50], Step [244/735], Loss: 0.3095\n",
      "Epoch [6/50], Step [245/735], Loss: 0.3117\n",
      "Epoch [6/50], Step [246/735], Loss: 0.2880\n",
      "Epoch [6/50], Step [247/735], Loss: 0.1890\n",
      "Epoch [6/50], Step [248/735], Loss: 0.1101\n",
      "Epoch [6/50], Step [249/735], Loss: 0.2266\n",
      "Epoch [6/50], Step [250/735], Loss: 0.1495\n",
      "Epoch [6/50], Step [251/735], Loss: 0.3321\n",
      "Epoch [6/50], Step [252/735], Loss: 0.2441\n",
      "Epoch [6/50], Step [253/735], Loss: 0.0939\n",
      "Epoch [6/50], Step [254/735], Loss: 0.3644\n",
      "Epoch [6/50], Step [255/735], Loss: 0.0886\n",
      "Epoch [6/50], Step [256/735], Loss: 0.0810\n",
      "Epoch [6/50], Step [257/735], Loss: 0.0827\n",
      "Epoch [6/50], Step [258/735], Loss: 0.0925\n",
      "Epoch [6/50], Step [259/735], Loss: 0.1609\n",
      "Epoch [6/50], Step [260/735], Loss: 0.0974\n",
      "Epoch [6/50], Step [261/735], Loss: 0.1637\n",
      "Epoch [6/50], Step [262/735], Loss: 0.2344\n",
      "Epoch [6/50], Step [263/735], Loss: 0.0940\n",
      "Epoch [6/50], Step [264/735], Loss: 0.2147\n",
      "Epoch [6/50], Step [265/735], Loss: 0.4987\n",
      "Epoch [6/50], Step [266/735], Loss: 0.1114\n",
      "Epoch [6/50], Step [267/735], Loss: 0.2712\n",
      "Epoch [6/50], Step [268/735], Loss: 0.3068\n",
      "Epoch [6/50], Step [269/735], Loss: 0.1546\n",
      "Epoch [6/50], Step [270/735], Loss: 0.0613\n",
      "Epoch [6/50], Step [271/735], Loss: 0.0937\n",
      "Epoch [6/50], Step [272/735], Loss: 0.4936\n",
      "Epoch [6/50], Step [273/735], Loss: 0.1224\n",
      "Epoch [6/50], Step [274/735], Loss: 0.1368\n",
      "Epoch [6/50], Step [275/735], Loss: 0.3495\n",
      "Epoch [6/50], Step [276/735], Loss: 0.2169\n",
      "Epoch [6/50], Step [277/735], Loss: 0.2059\n",
      "Epoch [6/50], Step [278/735], Loss: 0.1469\n",
      "Epoch [6/50], Step [279/735], Loss: 0.2534\n",
      "Epoch [6/50], Step [280/735], Loss: 0.2732\n",
      "Epoch [6/50], Step [281/735], Loss: 1.0312\n",
      "Epoch [6/50], Step [282/735], Loss: 0.1414\n",
      "Epoch [6/50], Step [283/735], Loss: 0.2456\n",
      "Epoch [6/50], Step [284/735], Loss: 0.3493\n",
      "Epoch [6/50], Step [285/735], Loss: 0.3075\n",
      "Epoch [6/50], Step [286/735], Loss: 0.3572\n",
      "Epoch [6/50], Step [287/735], Loss: 0.1255\n",
      "Epoch [6/50], Step [288/735], Loss: 0.2198\n",
      "Epoch [6/50], Step [289/735], Loss: 0.1578\n",
      "Epoch [6/50], Step [290/735], Loss: 0.1261\n",
      "Epoch [6/50], Step [291/735], Loss: 0.3549\n",
      "Epoch [6/50], Step [292/735], Loss: 0.6766\n",
      "Epoch [6/50], Step [293/735], Loss: 0.5355\n",
      "Epoch [6/50], Step [294/735], Loss: 0.3547\n",
      "Epoch [6/50], Step [295/735], Loss: 0.1026\n",
      "Epoch [6/50], Step [296/735], Loss: 0.0983\n",
      "Epoch [6/50], Step [297/735], Loss: 0.0654\n",
      "Epoch [6/50], Step [298/735], Loss: 0.2037\n",
      "Epoch [6/50], Step [299/735], Loss: 0.3903\n",
      "Epoch [6/50], Step [300/735], Loss: 0.0588\n",
      "Epoch [6/50], Step [301/735], Loss: 0.1289\n",
      "Epoch [6/50], Step [302/735], Loss: 0.2336\n",
      "Epoch [6/50], Step [303/735], Loss: 0.1538\n",
      "Epoch [6/50], Step [304/735], Loss: 0.3619\n",
      "Epoch [6/50], Step [305/735], Loss: 0.2376\n",
      "Epoch [6/50], Step [306/735], Loss: 0.1019\n",
      "Epoch [6/50], Step [307/735], Loss: 0.0601\n",
      "Epoch [6/50], Step [308/735], Loss: 1.1563\n",
      "Epoch [6/50], Step [309/735], Loss: 0.1334\n",
      "Epoch [6/50], Step [310/735], Loss: 0.2592\n",
      "Epoch [6/50], Step [311/735], Loss: 0.2167\n",
      "Epoch [6/50], Step [312/735], Loss: 0.3726\n",
      "Epoch [6/50], Step [313/735], Loss: 0.2110\n",
      "Epoch [6/50], Step [314/735], Loss: 0.1883\n",
      "Epoch [6/50], Step [315/735], Loss: 2.4166\n",
      "Epoch [6/50], Step [316/735], Loss: 0.2168\n",
      "Epoch [6/50], Step [317/735], Loss: 0.1393\n",
      "Epoch [6/50], Step [318/735], Loss: 0.1215\n",
      "Epoch [6/50], Step [319/735], Loss: 1.0561\n",
      "Epoch [6/50], Step [320/735], Loss: 0.1691\n",
      "Epoch [6/50], Step [321/735], Loss: 0.0853\n",
      "Epoch [6/50], Step [322/735], Loss: 0.1135\n",
      "Epoch [6/50], Step [323/735], Loss: 0.1688\n",
      "Epoch [6/50], Step [324/735], Loss: 0.4884\n",
      "Epoch [6/50], Step [325/735], Loss: 0.2510\n",
      "Epoch [6/50], Step [326/735], Loss: 0.1214\n",
      "Epoch [6/50], Step [327/735], Loss: 0.1328\n",
      "Epoch [6/50], Step [328/735], Loss: 0.2762\n",
      "Epoch [6/50], Step [329/735], Loss: 0.3997\n",
      "Epoch [6/50], Step [330/735], Loss: 0.1470\n",
      "Epoch [6/50], Step [331/735], Loss: 0.1569\n",
      "Epoch [6/50], Step [332/735], Loss: 0.1033\n",
      "Epoch [6/50], Step [333/735], Loss: 0.2149\n",
      "Epoch [6/50], Step [334/735], Loss: 0.1335\n",
      "Epoch [6/50], Step [335/735], Loss: 0.2013\n",
      "Epoch [6/50], Step [336/735], Loss: 0.3716\n",
      "Epoch [6/50], Step [337/735], Loss: 0.1449\n",
      "Epoch [6/50], Step [338/735], Loss: 0.3084\n",
      "Epoch [6/50], Step [339/735], Loss: 0.1289\n",
      "Epoch [6/50], Step [340/735], Loss: 0.1703\n",
      "Epoch [6/50], Step [341/735], Loss: 0.1595\n",
      "Epoch [6/50], Step [342/735], Loss: 0.2140\n",
      "Epoch [6/50], Step [343/735], Loss: 0.2957\n",
      "Epoch [6/50], Step [344/735], Loss: 0.1316\n",
      "Epoch [6/50], Step [345/735], Loss: 0.3067\n",
      "Epoch [6/50], Step [346/735], Loss: 0.1767\n",
      "Epoch [6/50], Step [347/735], Loss: 0.1075\n",
      "Epoch [6/50], Step [348/735], Loss: 0.3826\n",
      "Epoch [6/50], Step [349/735], Loss: 0.1354\n",
      "Epoch [6/50], Step [350/735], Loss: 0.3374\n",
      "Epoch [6/50], Step [351/735], Loss: 0.3170\n",
      "Epoch [6/50], Step [352/735], Loss: 0.2025\n",
      "Epoch [6/50], Step [353/735], Loss: 0.0659\n",
      "Epoch [6/50], Step [354/735], Loss: 0.2064\n",
      "Epoch [6/50], Step [355/735], Loss: 0.3895\n",
      "Epoch [6/50], Step [356/735], Loss: 0.1866\n",
      "Epoch [6/50], Step [357/735], Loss: 0.1875\n",
      "Epoch [6/50], Step [358/735], Loss: 0.1108\n",
      "Epoch [6/50], Step [359/735], Loss: 0.0982\n",
      "Epoch [6/50], Step [360/735], Loss: 0.0901\n",
      "Epoch [6/50], Step [361/735], Loss: 0.3820\n",
      "Epoch [6/50], Step [362/735], Loss: 1.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Step [363/735], Loss: 0.3565\n",
      "Epoch [6/50], Step [364/735], Loss: 0.1309\n",
      "Epoch [6/50], Step [365/735], Loss: 0.1435\n",
      "Epoch [6/50], Step [366/735], Loss: 0.2025\n",
      "Epoch [6/50], Step [367/735], Loss: 0.1932\n",
      "Epoch [6/50], Step [368/735], Loss: 0.1112\n",
      "Epoch [6/50], Step [369/735], Loss: 0.1510\n",
      "Epoch [6/50], Step [370/735], Loss: 0.0719\n",
      "Epoch [6/50], Step [371/735], Loss: 0.1285\n",
      "Epoch [6/50], Step [372/735], Loss: 0.1590\n",
      "Epoch [6/50], Step [373/735], Loss: 0.1380\n",
      "Epoch [6/50], Step [374/735], Loss: 0.0710\n",
      "Epoch [6/50], Step [375/735], Loss: 0.1469\n",
      "Epoch [6/50], Step [376/735], Loss: 0.0770\n",
      "Epoch [6/50], Step [377/735], Loss: 0.1032\n",
      "Epoch [6/50], Step [378/735], Loss: 0.1957\n",
      "Epoch [6/50], Step [379/735], Loss: 0.9027\n",
      "Epoch [6/50], Step [380/735], Loss: 0.2400\n",
      "Epoch [6/50], Step [381/735], Loss: 0.1324\n",
      "Epoch [6/50], Step [382/735], Loss: 0.1648\n",
      "Epoch [6/50], Step [383/735], Loss: 0.1196\n",
      "Epoch [6/50], Step [384/735], Loss: 0.1058\n",
      "Epoch [6/50], Step [385/735], Loss: 0.1365\n",
      "Epoch [6/50], Step [386/735], Loss: 0.2086\n",
      "Epoch [6/50], Step [387/735], Loss: 0.5520\n",
      "Epoch [6/50], Step [388/735], Loss: 0.2462\n",
      "Epoch [6/50], Step [389/735], Loss: 0.1696\n",
      "Epoch [6/50], Step [390/735], Loss: 0.2734\n",
      "Epoch [6/50], Step [391/735], Loss: 0.2997\n",
      "Epoch [6/50], Step [392/735], Loss: 1.0265\n",
      "Epoch [6/50], Step [393/735], Loss: 0.1048\n",
      "Epoch [6/50], Step [394/735], Loss: 0.1179\n",
      "Epoch [6/50], Step [395/735], Loss: 0.1293\n",
      "Epoch [6/50], Step [396/735], Loss: 0.2853\n",
      "Epoch [6/50], Step [397/735], Loss: 0.0749\n",
      "Epoch [6/50], Step [398/735], Loss: 0.1813\n",
      "Epoch [6/50], Step [399/735], Loss: 0.3369\n",
      "Epoch [6/50], Step [400/735], Loss: 0.0528\n",
      "Epoch [6/50], Step [401/735], Loss: 0.1078\n",
      "Epoch [6/50], Step [402/735], Loss: 0.1128\n",
      "Epoch [6/50], Step [403/735], Loss: 0.1025\n",
      "Epoch [6/50], Step [404/735], Loss: 0.4217\n",
      "Epoch [6/50], Step [405/735], Loss: 0.2581\n",
      "Epoch [6/50], Step [406/735], Loss: 0.0989\n",
      "Epoch [6/50], Step [407/735], Loss: 0.2257\n",
      "Epoch [6/50], Step [408/735], Loss: 0.1748\n",
      "Epoch [6/50], Step [409/735], Loss: 0.1892\n",
      "Epoch [6/50], Step [410/735], Loss: 0.0777\n",
      "Epoch [6/50], Step [411/735], Loss: 0.2641\n",
      "Epoch [6/50], Step [412/735], Loss: 0.2012\n",
      "Epoch [6/50], Step [413/735], Loss: 0.4352\n",
      "Epoch [6/50], Step [414/735], Loss: 0.0842\n",
      "Epoch [6/50], Step [415/735], Loss: 0.2737\n",
      "Epoch [6/50], Step [416/735], Loss: 0.3348\n",
      "Epoch [6/50], Step [417/735], Loss: 0.1268\n",
      "Epoch [6/50], Step [418/735], Loss: 0.0860\n",
      "Epoch [6/50], Step [419/735], Loss: 1.7191\n",
      "Epoch [6/50], Step [420/735], Loss: 0.1001\n",
      "Epoch [6/50], Step [421/735], Loss: 0.3571\n",
      "Epoch [6/50], Step [422/735], Loss: 0.1409\n",
      "Epoch [6/50], Step [423/735], Loss: 0.2765\n",
      "Epoch [6/50], Step [424/735], Loss: 0.2871\n",
      "Epoch [6/50], Step [425/735], Loss: 0.1459\n",
      "Epoch [6/50], Step [426/735], Loss: 0.2689\n",
      "Epoch [6/50], Step [427/735], Loss: 0.0898\n",
      "Epoch [6/50], Step [428/735], Loss: 0.3081\n",
      "Epoch [6/50], Step [429/735], Loss: 0.1182\n",
      "Epoch [6/50], Step [430/735], Loss: 0.0994\n",
      "Epoch [6/50], Step [431/735], Loss: 0.0943\n",
      "Epoch [6/50], Step [432/735], Loss: 0.1167\n",
      "Epoch [6/50], Step [433/735], Loss: 0.0958\n",
      "Epoch [6/50], Step [434/735], Loss: 0.2083\n",
      "Epoch [6/50], Step [435/735], Loss: 0.2168\n",
      "Epoch [6/50], Step [436/735], Loss: 0.1719\n",
      "Epoch [6/50], Step [437/735], Loss: 0.3988\n",
      "Epoch [6/50], Step [438/735], Loss: 0.2006\n",
      "Epoch [6/50], Step [439/735], Loss: 0.2198\n",
      "Epoch [6/50], Step [440/735], Loss: 0.1461\n",
      "Epoch [6/50], Step [441/735], Loss: 0.3679\n",
      "Epoch [6/50], Step [442/735], Loss: 0.1502\n",
      "Epoch [6/50], Step [443/735], Loss: 0.2819\n",
      "Epoch [6/50], Step [444/735], Loss: 0.2556\n",
      "Epoch [6/50], Step [445/735], Loss: 0.1965\n",
      "Epoch [6/50], Step [446/735], Loss: 0.3113\n",
      "Epoch [6/50], Step [447/735], Loss: 0.1891\n",
      "Epoch [6/50], Step [448/735], Loss: 0.0796\n",
      "Epoch [6/50], Step [449/735], Loss: 0.1318\n",
      "Epoch [6/50], Step [450/735], Loss: 0.4629\n",
      "Epoch [6/50], Step [451/735], Loss: 0.6118\n",
      "Epoch [6/50], Step [452/735], Loss: 0.1413\n",
      "Epoch [6/50], Step [453/735], Loss: 0.2346\n",
      "Epoch [6/50], Step [454/735], Loss: 0.1002\n",
      "Epoch [6/50], Step [455/735], Loss: 0.1735\n",
      "Epoch [6/50], Step [456/735], Loss: 0.1784\n",
      "Epoch [6/50], Step [457/735], Loss: 0.5328\n",
      "Epoch [6/50], Step [458/735], Loss: 0.1618\n",
      "Epoch [6/50], Step [459/735], Loss: 0.1188\n",
      "Epoch [6/50], Step [460/735], Loss: 0.5004\n",
      "Epoch [6/50], Step [461/735], Loss: 0.2844\n",
      "Epoch [6/50], Step [462/735], Loss: 0.1479\n",
      "Epoch [6/50], Step [463/735], Loss: 0.1748\n",
      "Epoch [6/50], Step [464/735], Loss: 0.1385\n",
      "Epoch [6/50], Step [465/735], Loss: 0.2422\n",
      "Epoch [6/50], Step [466/735], Loss: 0.1385\n",
      "Epoch [6/50], Step [467/735], Loss: 0.0829\n",
      "Epoch [6/50], Step [468/735], Loss: 0.4398\n",
      "Epoch [6/50], Step [469/735], Loss: 0.4489\n",
      "Epoch [6/50], Step [470/735], Loss: 0.1503\n",
      "Epoch [6/50], Step [471/735], Loss: 0.1455\n",
      "Epoch [6/50], Step [472/735], Loss: 0.1553\n",
      "Epoch [6/50], Step [473/735], Loss: 0.2085\n",
      "Epoch [6/50], Step [474/735], Loss: 0.2468\n",
      "Epoch [6/50], Step [475/735], Loss: 0.1942\n",
      "Epoch [6/50], Step [476/735], Loss: 0.0927\n",
      "Epoch [6/50], Step [477/735], Loss: 0.1333\n",
      "Epoch [6/50], Step [478/735], Loss: 0.1460\n",
      "Epoch [6/50], Step [479/735], Loss: 0.1599\n",
      "Epoch [6/50], Step [480/735], Loss: 0.1433\n",
      "Epoch [6/50], Step [481/735], Loss: 0.2653\n",
      "Epoch [6/50], Step [482/735], Loss: 0.2969\n",
      "Epoch [6/50], Step [483/735], Loss: 0.0764\n",
      "Epoch [6/50], Step [484/735], Loss: 0.1936\n",
      "Epoch [6/50], Step [485/735], Loss: 0.3372\n",
      "Epoch [6/50], Step [486/735], Loss: 0.1112\n",
      "Epoch [6/50], Step [487/735], Loss: 0.0823\n",
      "Epoch [6/50], Step [488/735], Loss: 0.0597\n",
      "Epoch [6/50], Step [489/735], Loss: 0.1133\n",
      "Epoch [6/50], Step [490/735], Loss: 0.6003\n",
      "Epoch [6/50], Step [491/735], Loss: 0.3516\n",
      "Epoch [6/50], Step [492/735], Loss: 0.3328\n",
      "Epoch [6/50], Step [493/735], Loss: 0.1560\n",
      "Epoch [6/50], Step [494/735], Loss: 0.1431\n",
      "Epoch [6/50], Step [495/735], Loss: 0.3967\n",
      "Epoch [6/50], Step [496/735], Loss: 0.2033\n",
      "Epoch [6/50], Step [497/735], Loss: 0.4183\n",
      "Epoch [6/50], Step [498/735], Loss: 0.6385\n",
      "Epoch [6/50], Step [499/735], Loss: 0.0623\n",
      "Epoch [6/50], Step [500/735], Loss: 0.3541\n",
      "Epoch [6/50], Step [501/735], Loss: 0.4164\n",
      "Epoch [6/50], Step [502/735], Loss: 0.1087\n",
      "Epoch [6/50], Step [503/735], Loss: 0.0857\n",
      "Epoch [6/50], Step [504/735], Loss: 0.2261\n",
      "Epoch [6/50], Step [505/735], Loss: 0.3687\n",
      "Epoch [6/50], Step [506/735], Loss: 0.3661\n",
      "Epoch [6/50], Step [507/735], Loss: 0.2140\n",
      "Epoch [6/50], Step [508/735], Loss: 0.2029\n",
      "Epoch [6/50], Step [509/735], Loss: 1.2903\n",
      "Epoch [6/50], Step [510/735], Loss: 0.5775\n",
      "Epoch [6/50], Step [511/735], Loss: 1.1403\n",
      "Epoch [6/50], Step [512/735], Loss: 0.1180\n",
      "Epoch [6/50], Step [513/735], Loss: 2.4840\n",
      "Epoch [6/50], Step [514/735], Loss: 0.0930\n",
      "Epoch [6/50], Step [515/735], Loss: 0.2201\n",
      "Epoch [6/50], Step [516/735], Loss: 0.4518\n",
      "Epoch [6/50], Step [517/735], Loss: 0.2040\n",
      "Epoch [6/50], Step [518/735], Loss: 0.1692\n",
      "Epoch [6/50], Step [519/735], Loss: 0.2071\n",
      "Epoch [6/50], Step [520/735], Loss: 0.1972\n",
      "Epoch [6/50], Step [521/735], Loss: 0.1914\n",
      "Epoch [6/50], Step [522/735], Loss: 1.6581\n",
      "Epoch [6/50], Step [523/735], Loss: 0.1650\n",
      "Epoch [6/50], Step [524/735], Loss: 0.1912\n",
      "Epoch [6/50], Step [525/735], Loss: 0.2068\n",
      "Epoch [6/50], Step [526/735], Loss: 0.1421\n",
      "Epoch [6/50], Step [527/735], Loss: 0.3264\n",
      "Epoch [6/50], Step [528/735], Loss: 2.5027\n",
      "Epoch [6/50], Step [529/735], Loss: 0.1790\n",
      "Epoch [6/50], Step [530/735], Loss: 0.1593\n",
      "Epoch [6/50], Step [531/735], Loss: 0.1743\n",
      "Epoch [6/50], Step [532/735], Loss: 0.3081\n",
      "Epoch [6/50], Step [533/735], Loss: 0.2512\n",
      "Epoch [6/50], Step [534/735], Loss: 0.9135\n",
      "Epoch [6/50], Step [535/735], Loss: 0.2830\n",
      "Epoch [6/50], Step [536/735], Loss: 0.2384\n",
      "Epoch [6/50], Step [537/735], Loss: 0.1277\n",
      "Epoch [6/50], Step [538/735], Loss: 0.1459\n",
      "Epoch [6/50], Step [539/735], Loss: 0.1725\n",
      "Epoch [6/50], Step [540/735], Loss: 0.0882\n",
      "Epoch [6/50], Step [541/735], Loss: 0.1002\n",
      "Epoch [6/50], Step [542/735], Loss: 0.2232\n",
      "Epoch [6/50], Step [543/735], Loss: 0.2136\n",
      "Epoch [6/50], Step [544/735], Loss: 0.2036\n",
      "Epoch [6/50], Step [545/735], Loss: 0.2346\n",
      "Epoch [6/50], Step [546/735], Loss: 0.1718\n",
      "Epoch [6/50], Step [547/735], Loss: 0.1699\n",
      "Epoch [6/50], Step [548/735], Loss: 0.3612\n",
      "Epoch [6/50], Step [549/735], Loss: 0.3917\n",
      "Epoch [6/50], Step [550/735], Loss: 0.3337\n",
      "Epoch [6/50], Step [551/735], Loss: 0.3312\n",
      "Epoch [6/50], Step [552/735], Loss: 0.2607\n",
      "Epoch [6/50], Step [553/735], Loss: 0.1313\n",
      "Epoch [6/50], Step [554/735], Loss: 0.1800\n",
      "Epoch [6/50], Step [555/735], Loss: 0.1880\n",
      "Epoch [6/50], Step [556/735], Loss: 0.2241\n",
      "Epoch [6/50], Step [557/735], Loss: 0.9236\n",
      "Epoch [6/50], Step [558/735], Loss: 0.4762\n",
      "Epoch [6/50], Step [559/735], Loss: 0.2114\n",
      "Epoch [6/50], Step [560/735], Loss: 0.1663\n",
      "Epoch [6/50], Step [561/735], Loss: 0.0841\n",
      "Epoch [6/50], Step [562/735], Loss: 0.1598\n",
      "Epoch [6/50], Step [563/735], Loss: 0.4393\n",
      "Epoch [6/50], Step [564/735], Loss: 1.1300\n",
      "Epoch [6/50], Step [565/735], Loss: 0.1774\n",
      "Epoch [6/50], Step [566/735], Loss: 0.5000\n",
      "Epoch [6/50], Step [567/735], Loss: 0.2359\n",
      "Epoch [6/50], Step [568/735], Loss: 0.2835\n",
      "Epoch [6/50], Step [569/735], Loss: 0.1988\n",
      "Epoch [6/50], Step [570/735], Loss: 0.1348\n",
      "Epoch [6/50], Step [571/735], Loss: 0.4715\n",
      "Epoch [6/50], Step [572/735], Loss: 0.2501\n",
      "Epoch [6/50], Step [573/735], Loss: 0.7229\n",
      "Epoch [6/50], Step [574/735], Loss: 0.4188\n",
      "Epoch [6/50], Step [575/735], Loss: 0.2214\n",
      "Epoch [6/50], Step [576/735], Loss: 0.1645\n",
      "Epoch [6/50], Step [577/735], Loss: 0.3325\n",
      "Epoch [6/50], Step [578/735], Loss: 2.1766\n",
      "Epoch [6/50], Step [579/735], Loss: 0.1799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Step [580/735], Loss: 0.9140\n",
      "Epoch [6/50], Step [581/735], Loss: 0.1942\n",
      "Epoch [6/50], Step [582/735], Loss: 0.3073\n",
      "Epoch [6/50], Step [583/735], Loss: 0.5936\n",
      "Epoch [6/50], Step [584/735], Loss: 0.4417\n",
      "Epoch [6/50], Step [585/735], Loss: 0.2840\n",
      "Epoch [6/50], Step [586/735], Loss: 0.1218\n",
      "Epoch [6/50], Step [587/735], Loss: 0.1944\n",
      "Epoch [6/50], Step [588/735], Loss: 0.6142\n",
      "Epoch [6/50], Step [589/735], Loss: 0.1844\n",
      "Epoch [6/50], Step [590/735], Loss: 0.2195\n",
      "Epoch [6/50], Step [591/735], Loss: 0.2271\n",
      "Epoch [6/50], Step [592/735], Loss: 0.1071\n",
      "Epoch [6/50], Step [593/735], Loss: 0.2276\n",
      "Epoch [6/50], Step [594/735], Loss: 0.2476\n",
      "Epoch [6/50], Step [595/735], Loss: 0.2736\n",
      "Epoch [6/50], Step [596/735], Loss: 0.2117\n",
      "Epoch [6/50], Step [597/735], Loss: 0.1396\n",
      "Epoch [6/50], Step [598/735], Loss: 0.1833\n",
      "Epoch [6/50], Step [599/735], Loss: 2.3055\n",
      "Epoch [6/50], Step [600/735], Loss: 0.1418\n",
      "Epoch [6/50], Step [601/735], Loss: 0.0874\n",
      "Epoch [6/50], Step [602/735], Loss: 0.7557\n",
      "Epoch [6/50], Step [603/735], Loss: 0.1129\n",
      "Epoch [6/50], Step [604/735], Loss: 0.2612\n",
      "Epoch [6/50], Step [605/735], Loss: 0.2375\n",
      "Epoch [6/50], Step [606/735], Loss: 0.1250\n",
      "Epoch [6/50], Step [607/735], Loss: 0.1659\n",
      "Epoch [6/50], Step [608/735], Loss: 0.1769\n",
      "Epoch [6/50], Step [609/735], Loss: 0.1205\n",
      "Epoch [6/50], Step [610/735], Loss: 0.1089\n",
      "Epoch [6/50], Step [611/735], Loss: 0.2903\n",
      "Epoch [6/50], Step [612/735], Loss: 0.2843\n",
      "Epoch [6/50], Step [613/735], Loss: 0.2706\n",
      "Epoch [6/50], Step [614/735], Loss: 0.4087\n",
      "Epoch [6/50], Step [615/735], Loss: 0.4149\n",
      "Epoch [6/50], Step [616/735], Loss: 0.2283\n",
      "Epoch [6/50], Step [617/735], Loss: 0.1893\n",
      "Epoch [6/50], Step [618/735], Loss: 0.0845\n",
      "Epoch [6/50], Step [619/735], Loss: 0.0959\n",
      "Epoch [6/50], Step [620/735], Loss: 0.2242\n",
      "Epoch [6/50], Step [621/735], Loss: 0.4529\n",
      "Epoch [6/50], Step [622/735], Loss: 0.2721\n",
      "Epoch [6/50], Step [623/735], Loss: 0.2158\n",
      "Epoch [6/50], Step [624/735], Loss: 0.2242\n",
      "Epoch [6/50], Step [625/735], Loss: 0.4884\n",
      "Epoch [6/50], Step [626/735], Loss: 0.1826\n",
      "Epoch [6/50], Step [627/735], Loss: 0.1708\n",
      "Epoch [6/50], Step [628/735], Loss: 0.1716\n",
      "Epoch [6/50], Step [629/735], Loss: 1.8721\n",
      "Epoch [6/50], Step [630/735], Loss: 0.2008\n",
      "Epoch [6/50], Step [631/735], Loss: 0.4881\n",
      "Epoch [6/50], Step [632/735], Loss: 0.0946\n",
      "Epoch [6/50], Step [633/735], Loss: 0.4098\n",
      "Epoch [6/50], Step [634/735], Loss: 0.1639\n",
      "Epoch [6/50], Step [635/735], Loss: 0.3885\n",
      "Epoch [6/50], Step [636/735], Loss: 0.1427\n",
      "Epoch [6/50], Step [637/735], Loss: 0.2532\n",
      "Epoch [6/50], Step [638/735], Loss: 0.1463\n",
      "Epoch [6/50], Step [639/735], Loss: 0.7490\n",
      "Epoch [6/50], Step [640/735], Loss: 0.3538\n",
      "Epoch [6/50], Step [641/735], Loss: 0.2293\n",
      "Epoch [6/50], Step [642/735], Loss: 0.0667\n",
      "Epoch [6/50], Step [643/735], Loss: 0.2414\n",
      "Epoch [6/50], Step [644/735], Loss: 0.1359\n",
      "Epoch [6/50], Step [645/735], Loss: 0.1444\n",
      "Epoch [6/50], Step [646/735], Loss: 0.3335\n",
      "Epoch [6/50], Step [647/735], Loss: 0.0991\n",
      "Epoch [6/50], Step [648/735], Loss: 0.0559\n",
      "Epoch [6/50], Step [649/735], Loss: 0.1158\n",
      "Epoch [6/50], Step [650/735], Loss: 0.0874\n",
      "Epoch [6/50], Step [651/735], Loss: 0.1234\n",
      "Epoch [6/50], Step [652/735], Loss: 0.1155\n",
      "Epoch [6/50], Step [653/735], Loss: 0.1371\n",
      "Epoch [6/50], Step [654/735], Loss: 0.2356\n",
      "Epoch [6/50], Step [655/735], Loss: 0.2722\n",
      "Epoch [6/50], Step [656/735], Loss: 0.2605\n",
      "Epoch [6/50], Step [657/735], Loss: 0.1978\n",
      "Epoch [6/50], Step [658/735], Loss: 0.1486\n",
      "Epoch [6/50], Step [659/735], Loss: 0.2082\n",
      "Epoch [6/50], Step [660/735], Loss: 0.2988\n",
      "Epoch [6/50], Step [661/735], Loss: 0.3168\n",
      "Epoch [6/50], Step [662/735], Loss: 1.5719\n",
      "Epoch [6/50], Step [663/735], Loss: 0.1804\n",
      "Epoch [6/50], Step [664/735], Loss: 0.2160\n",
      "Epoch [6/50], Step [665/735], Loss: 0.1937\n",
      "Epoch [6/50], Step [666/735], Loss: 0.1193\n",
      "Epoch [6/50], Step [667/735], Loss: 0.2244\n",
      "Epoch [6/50], Step [668/735], Loss: 0.1292\n",
      "Epoch [6/50], Step [669/735], Loss: 0.2756\n",
      "Epoch [6/50], Step [670/735], Loss: 0.2158\n",
      "Epoch [6/50], Step [671/735], Loss: 0.2397\n",
      "Epoch [6/50], Step [672/735], Loss: 0.1361\n",
      "Epoch [6/50], Step [673/735], Loss: 0.1646\n",
      "Epoch [6/50], Step [674/735], Loss: 0.2108\n",
      "Epoch [6/50], Step [675/735], Loss: 0.1793\n",
      "Epoch [6/50], Step [676/735], Loss: 0.1872\n",
      "Epoch [6/50], Step [677/735], Loss: 0.2095\n",
      "Epoch [6/50], Step [678/735], Loss: 0.2481\n",
      "Epoch [6/50], Step [679/735], Loss: 0.0996\n",
      "Epoch [6/50], Step [680/735], Loss: 0.3286\n",
      "Epoch [6/50], Step [681/735], Loss: 0.1823\n",
      "Epoch [6/50], Step [682/735], Loss: 0.1391\n",
      "Epoch [6/50], Step [683/735], Loss: 0.1198\n",
      "Epoch [6/50], Step [684/735], Loss: 0.1142\n",
      "Epoch [6/50], Step [685/735], Loss: 0.2207\n",
      "Epoch [6/50], Step [686/735], Loss: 0.1191\n",
      "Epoch [6/50], Step [687/735], Loss: 0.2005\n",
      "Epoch [6/50], Step [688/735], Loss: 0.1054\n",
      "Epoch [6/50], Step [689/735], Loss: 0.0817\n",
      "Epoch [6/50], Step [690/735], Loss: 0.2084\n",
      "Epoch [6/50], Step [691/735], Loss: 0.2331\n",
      "Epoch [6/50], Step [692/735], Loss: 0.1538\n",
      "Epoch [6/50], Step [693/735], Loss: 0.1681\n",
      "Epoch [6/50], Step [694/735], Loss: 0.1078\n",
      "Epoch [6/50], Step [695/735], Loss: 0.2328\n",
      "Epoch [6/50], Step [696/735], Loss: 0.1879\n",
      "Epoch [6/50], Step [697/735], Loss: 0.1280\n",
      "Epoch [6/50], Step [698/735], Loss: 0.8570\n",
      "Epoch [6/50], Step [699/735], Loss: 0.4418\n",
      "Epoch [6/50], Step [700/735], Loss: 0.3797\n",
      "Epoch [6/50], Step [701/735], Loss: 0.1278\n",
      "Epoch [6/50], Step [702/735], Loss: 0.5052\n",
      "Epoch [6/50], Step [703/735], Loss: 0.2028\n",
      "Epoch [6/50], Step [704/735], Loss: 0.1638\n",
      "Epoch [6/50], Step [705/735], Loss: 0.4492\n",
      "Epoch [6/50], Step [706/735], Loss: 0.1185\n",
      "Epoch [6/50], Step [707/735], Loss: 0.2240\n",
      "Epoch [6/50], Step [708/735], Loss: 0.0818\n",
      "Epoch [6/50], Step [709/735], Loss: 0.1392\n",
      "Epoch [6/50], Step [710/735], Loss: 0.1440\n",
      "Epoch [6/50], Step [711/735], Loss: 0.0936\n",
      "Epoch [6/50], Step [712/735], Loss: 0.0645\n",
      "Epoch [6/50], Step [713/735], Loss: 0.1830\n",
      "Epoch [6/50], Step [714/735], Loss: 0.1498\n",
      "Epoch [6/50], Step [715/735], Loss: 0.1303\n",
      "Epoch [6/50], Step [716/735], Loss: 0.0867\n",
      "Epoch [6/50], Step [717/735], Loss: 0.4650\n",
      "Epoch [6/50], Step [718/735], Loss: 0.2382\n",
      "Epoch [6/50], Step [719/735], Loss: 0.1715\n",
      "Epoch [6/50], Step [720/735], Loss: 0.1919\n",
      "Epoch [6/50], Step [721/735], Loss: 0.1610\n",
      "Epoch [6/50], Step [722/735], Loss: 0.2991\n",
      "Epoch [6/50], Step [723/735], Loss: 0.1171\n",
      "Epoch [6/50], Step [724/735], Loss: 0.1671\n",
      "Epoch [6/50], Step [725/735], Loss: 0.1853\n",
      "Epoch [6/50], Step [726/735], Loss: 0.1077\n",
      "Epoch [6/50], Step [727/735], Loss: 0.3941\n",
      "Epoch [6/50], Step [728/735], Loss: 0.2491\n",
      "Epoch [6/50], Step [729/735], Loss: 0.2826\n",
      "Epoch [6/50], Step [730/735], Loss: 0.6019\n",
      "Epoch [6/50], Step [731/735], Loss: 0.2178\n",
      "Epoch [6/50], Step [732/735], Loss: 0.2557\n",
      "Epoch [6/50], Step [733/735], Loss: 0.4245\n",
      "Epoch [6/50], Step [734/735], Loss: 0.2702\n",
      "Epoch [6/50], Step [735/735], Loss: 0.7223\n",
      "Epoch [7/50], Step [1/735], Loss: 0.1274\n",
      "Epoch [7/50], Step [2/735], Loss: 0.4791\n",
      "Epoch [7/50], Step [3/735], Loss: 0.2964\n",
      "Epoch [7/50], Step [4/735], Loss: 0.1294\n",
      "Epoch [7/50], Step [5/735], Loss: 0.1809\n",
      "Epoch [7/50], Step [6/735], Loss: 0.1843\n",
      "Epoch [7/50], Step [7/735], Loss: 0.1211\n",
      "Epoch [7/50], Step [8/735], Loss: 0.2065\n",
      "Epoch [7/50], Step [9/735], Loss: 0.2153\n",
      "Epoch [7/50], Step [10/735], Loss: 0.1552\n",
      "Epoch [7/50], Step [11/735], Loss: 0.1694\n",
      "Epoch [7/50], Step [12/735], Loss: 0.2045\n",
      "Epoch [7/50], Step [13/735], Loss: 0.4910\n",
      "Epoch [7/50], Step [14/735], Loss: 0.0877\n",
      "Epoch [7/50], Step [15/735], Loss: 0.4211\n",
      "Epoch [7/50], Step [16/735], Loss: 0.2949\n",
      "Epoch [7/50], Step [17/735], Loss: 0.1709\n",
      "Epoch [7/50], Step [18/735], Loss: 0.4311\n",
      "Epoch [7/50], Step [19/735], Loss: 0.1500\n",
      "Epoch [7/50], Step [20/735], Loss: 0.1171\n",
      "Epoch [7/50], Step [21/735], Loss: 0.0619\n",
      "Epoch [7/50], Step [22/735], Loss: 0.1168\n",
      "Epoch [7/50], Step [23/735], Loss: 0.1246\n",
      "Epoch [7/50], Step [24/735], Loss: 0.1741\n",
      "Epoch [7/50], Step [25/735], Loss: 0.7411\n",
      "Epoch [7/50], Step [26/735], Loss: 0.2039\n",
      "Epoch [7/50], Step [27/735], Loss: 0.1986\n",
      "Epoch [7/50], Step [28/735], Loss: 0.2040\n",
      "Epoch [7/50], Step [29/735], Loss: 0.1043\n",
      "Epoch [7/50], Step [30/735], Loss: 0.1399\n",
      "Epoch [7/50], Step [31/735], Loss: 0.2714\n",
      "Epoch [7/50], Step [32/735], Loss: 0.1786\n",
      "Epoch [7/50], Step [33/735], Loss: 0.2314\n",
      "Epoch [7/50], Step [34/735], Loss: 0.1308\n",
      "Epoch [7/50], Step [35/735], Loss: 0.3338\n",
      "Epoch [7/50], Step [36/735], Loss: 0.4360\n",
      "Epoch [7/50], Step [37/735], Loss: 0.2820\n",
      "Epoch [7/50], Step [38/735], Loss: 0.6591\n",
      "Epoch [7/50], Step [39/735], Loss: 0.3605\n",
      "Epoch [7/50], Step [40/735], Loss: 0.1801\n",
      "Epoch [7/50], Step [41/735], Loss: 0.2562\n",
      "Epoch [7/50], Step [42/735], Loss: 0.1752\n",
      "Epoch [7/50], Step [43/735], Loss: 0.3323\n",
      "Epoch [7/50], Step [44/735], Loss: 0.3264\n",
      "Epoch [7/50], Step [45/735], Loss: 0.1075\n",
      "Epoch [7/50], Step [46/735], Loss: 0.1680\n",
      "Epoch [7/50], Step [47/735], Loss: 0.1249\n",
      "Epoch [7/50], Step [48/735], Loss: 0.2415\n",
      "Epoch [7/50], Step [49/735], Loss: 0.1824\n",
      "Epoch [7/50], Step [50/735], Loss: 0.2336\n",
      "Epoch [7/50], Step [51/735], Loss: 0.0516\n",
      "Epoch [7/50], Step [52/735], Loss: 0.8068\n",
      "Epoch [7/50], Step [53/735], Loss: 0.5219\n",
      "Epoch [7/50], Step [54/735], Loss: 0.2845\n",
      "Epoch [7/50], Step [55/735], Loss: 0.2119\n",
      "Epoch [7/50], Step [56/735], Loss: 0.1653\n",
      "Epoch [7/50], Step [57/735], Loss: 0.2577\n",
      "Epoch [7/50], Step [58/735], Loss: 0.3609\n",
      "Epoch [7/50], Step [59/735], Loss: 0.1908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Step [60/735], Loss: 0.0814\n",
      "Epoch [7/50], Step [61/735], Loss: 0.2471\n",
      "Epoch [7/50], Step [62/735], Loss: 0.3467\n",
      "Epoch [7/50], Step [63/735], Loss: 0.4787\n",
      "Epoch [7/50], Step [64/735], Loss: 0.3442\n",
      "Epoch [7/50], Step [65/735], Loss: 0.3464\n",
      "Epoch [7/50], Step [66/735], Loss: 0.3312\n",
      "Epoch [7/50], Step [67/735], Loss: 0.1146\n",
      "Epoch [7/50], Step [68/735], Loss: 0.2311\n",
      "Epoch [7/50], Step [69/735], Loss: 0.1267\n",
      "Epoch [7/50], Step [70/735], Loss: 0.0991\n",
      "Epoch [7/50], Step [71/735], Loss: 0.0875\n",
      "Epoch [7/50], Step [72/735], Loss: 0.0851\n",
      "Epoch [7/50], Step [73/735], Loss: 0.1177\n",
      "Epoch [7/50], Step [74/735], Loss: 0.1650\n",
      "Epoch [7/50], Step [75/735], Loss: 0.1549\n",
      "Epoch [7/50], Step [76/735], Loss: 0.0712\n",
      "Epoch [7/50], Step [77/735], Loss: 0.2163\n",
      "Epoch [7/50], Step [78/735], Loss: 0.1348\n",
      "Epoch [7/50], Step [79/735], Loss: 0.2283\n",
      "Epoch [7/50], Step [80/735], Loss: 0.3720\n",
      "Epoch [7/50], Step [81/735], Loss: 0.1778\n",
      "Epoch [7/50], Step [82/735], Loss: 0.1067\n",
      "Epoch [7/50], Step [83/735], Loss: 0.0537\n",
      "Epoch [7/50], Step [84/735], Loss: 0.1498\n",
      "Epoch [7/50], Step [85/735], Loss: 0.1161\n",
      "Epoch [7/50], Step [86/735], Loss: 0.1902\n",
      "Epoch [7/50], Step [87/735], Loss: 0.1959\n",
      "Epoch [7/50], Step [88/735], Loss: 0.2073\n",
      "Epoch [7/50], Step [89/735], Loss: 0.0730\n",
      "Epoch [7/50], Step [90/735], Loss: 1.2994\n",
      "Epoch [7/50], Step [91/735], Loss: 0.1606\n",
      "Epoch [7/50], Step [92/735], Loss: 0.1546\n",
      "Epoch [7/50], Step [93/735], Loss: 0.3350\n",
      "Epoch [7/50], Step [94/735], Loss: 0.2983\n",
      "Epoch [7/50], Step [95/735], Loss: 0.2377\n",
      "Epoch [7/50], Step [96/735], Loss: 0.0763\n",
      "Epoch [7/50], Step [97/735], Loss: 0.0430\n",
      "Epoch [7/50], Step [98/735], Loss: 0.1417\n",
      "Epoch [7/50], Step [99/735], Loss: 0.2248\n",
      "Epoch [7/50], Step [100/735], Loss: 0.0693\n",
      "Epoch [7/50], Step [101/735], Loss: 1.1751\n",
      "Epoch [7/50], Step [102/735], Loss: 0.1381\n",
      "Epoch [7/50], Step [103/735], Loss: 0.1499\n",
      "Epoch [7/50], Step [104/735], Loss: 0.4316\n",
      "Epoch [7/50], Step [105/735], Loss: 0.3086\n",
      "Epoch [7/50], Step [106/735], Loss: 0.0628\n",
      "Epoch [7/50], Step [107/735], Loss: 0.2964\n",
      "Epoch [7/50], Step [108/735], Loss: 1.6351\n",
      "Epoch [7/50], Step [109/735], Loss: 0.3237\n",
      "Epoch [7/50], Step [110/735], Loss: 0.2056\n",
      "Epoch [7/50], Step [111/735], Loss: 0.1871\n",
      "Epoch [7/50], Step [112/735], Loss: 0.1939\n",
      "Epoch [7/50], Step [113/735], Loss: 0.1129\n",
      "Epoch [7/50], Step [114/735], Loss: 0.1648\n",
      "Epoch [7/50], Step [115/735], Loss: 0.0802\n",
      "Epoch [7/50], Step [116/735], Loss: 0.1521\n",
      "Epoch [7/50], Step [117/735], Loss: 0.1437\n",
      "Epoch [7/50], Step [118/735], Loss: 0.1966\n",
      "Epoch [7/50], Step [119/735], Loss: 0.1075\n",
      "Epoch [7/50], Step [120/735], Loss: 0.2688\n",
      "Epoch [7/50], Step [121/735], Loss: 0.3237\n",
      "Epoch [7/50], Step [122/735], Loss: 0.0748\n",
      "Epoch [7/50], Step [123/735], Loss: 0.3248\n",
      "Epoch [7/50], Step [124/735], Loss: 0.1585\n",
      "Epoch [7/50], Step [125/735], Loss: 0.4474\n",
      "Epoch [7/50], Step [126/735], Loss: 0.2082\n",
      "Epoch [7/50], Step [127/735], Loss: 0.2549\n",
      "Epoch [7/50], Step [128/735], Loss: 0.9676\n",
      "Epoch [7/50], Step [129/735], Loss: 0.4393\n",
      "Epoch [7/50], Step [130/735], Loss: 0.0708\n",
      "Epoch [7/50], Step [131/735], Loss: 1.0596\n",
      "Epoch [7/50], Step [132/735], Loss: 0.2088\n",
      "Epoch [7/50], Step [133/735], Loss: 0.2539\n",
      "Epoch [7/50], Step [134/735], Loss: 0.2785\n",
      "Epoch [7/50], Step [135/735], Loss: 0.1180\n",
      "Epoch [7/50], Step [136/735], Loss: 0.1054\n",
      "Epoch [7/50], Step [137/735], Loss: 0.1117\n",
      "Epoch [7/50], Step [138/735], Loss: 0.3100\n",
      "Epoch [7/50], Step [139/735], Loss: 0.1662\n",
      "Epoch [7/50], Step [140/735], Loss: 0.1365\n",
      "Epoch [7/50], Step [141/735], Loss: 1.1168\n",
      "Epoch [7/50], Step [142/735], Loss: 0.1622\n",
      "Epoch [7/50], Step [143/735], Loss: 0.5313\n",
      "Epoch [7/50], Step [144/735], Loss: 0.2661\n",
      "Epoch [7/50], Step [145/735], Loss: 1.0563\n",
      "Epoch [7/50], Step [146/735], Loss: 0.0872\n",
      "Epoch [7/50], Step [147/735], Loss: 0.1230\n",
      "Epoch [7/50], Step [148/735], Loss: 0.2775\n",
      "Epoch [7/50], Step [149/735], Loss: 0.0735\n",
      "Epoch [7/50], Step [150/735], Loss: 0.3219\n",
      "Epoch [7/50], Step [151/735], Loss: 0.2977\n",
      "Epoch [7/50], Step [152/735], Loss: 0.1422\n",
      "Epoch [7/50], Step [153/735], Loss: 0.0967\n",
      "Epoch [7/50], Step [154/735], Loss: 0.2594\n",
      "Epoch [7/50], Step [155/735], Loss: 0.2736\n",
      "Epoch [7/50], Step [156/735], Loss: 0.3170\n",
      "Epoch [7/50], Step [157/735], Loss: 0.1337\n",
      "Epoch [7/50], Step [158/735], Loss: 0.2976\n",
      "Epoch [7/50], Step [159/735], Loss: 0.1381\n",
      "Epoch [7/50], Step [160/735], Loss: 0.4703\n",
      "Epoch [7/50], Step [161/735], Loss: 1.3151\n",
      "Epoch [7/50], Step [162/735], Loss: 0.0807\n",
      "Epoch [7/50], Step [163/735], Loss: 0.2102\n",
      "Epoch [7/50], Step [164/735], Loss: 0.7698\n",
      "Epoch [7/50], Step [165/735], Loss: 0.2710\n",
      "Epoch [7/50], Step [166/735], Loss: 0.3489\n",
      "Epoch [7/50], Step [167/735], Loss: 0.5332\n",
      "Epoch [7/50], Step [168/735], Loss: 0.0705\n",
      "Epoch [7/50], Step [169/735], Loss: 0.1207\n",
      "Epoch [7/50], Step [170/735], Loss: 1.6111\n",
      "Epoch [7/50], Step [171/735], Loss: 0.1904\n",
      "Epoch [7/50], Step [172/735], Loss: 0.1839\n",
      "Epoch [7/50], Step [173/735], Loss: 0.1742\n",
      "Epoch [7/50], Step [174/735], Loss: 0.1522\n",
      "Epoch [7/50], Step [175/735], Loss: 0.5115\n",
      "Epoch [7/50], Step [176/735], Loss: 0.0642\n",
      "Epoch [7/50], Step [177/735], Loss: 0.2312\n",
      "Epoch [7/50], Step [178/735], Loss: 0.1190\n",
      "Epoch [7/50], Step [179/735], Loss: 0.1316\n",
      "Epoch [7/50], Step [180/735], Loss: 0.2324\n",
      "Epoch [7/50], Step [181/735], Loss: 0.1810\n",
      "Epoch [7/50], Step [182/735], Loss: 0.2903\n",
      "Epoch [7/50], Step [183/735], Loss: 0.1082\n",
      "Epoch [7/50], Step [184/735], Loss: 0.1878\n",
      "Epoch [7/50], Step [185/735], Loss: 0.1439\n",
      "Epoch [7/50], Step [186/735], Loss: 0.3323\n",
      "Epoch [7/50], Step [187/735], Loss: 0.2121\n",
      "Epoch [7/50], Step [188/735], Loss: 0.2859\n",
      "Epoch [7/50], Step [189/735], Loss: 0.1257\n",
      "Epoch [7/50], Step [190/735], Loss: 0.4570\n",
      "Epoch [7/50], Step [191/735], Loss: 0.3469\n",
      "Epoch [7/50], Step [192/735], Loss: 0.1633\n",
      "Epoch [7/50], Step [193/735], Loss: 0.3616\n",
      "Epoch [7/50], Step [194/735], Loss: 0.1593\n",
      "Epoch [7/50], Step [195/735], Loss: 0.1186\n",
      "Epoch [7/50], Step [196/735], Loss: 0.1185\n",
      "Epoch [7/50], Step [197/735], Loss: 0.2402\n",
      "Epoch [7/50], Step [198/735], Loss: 0.0601\n",
      "Epoch [7/50], Step [199/735], Loss: 0.0901\n",
      "Epoch [7/50], Step [200/735], Loss: 0.1834\n",
      "Epoch [7/50], Step [201/735], Loss: 0.0866\n",
      "Epoch [7/50], Step [202/735], Loss: 0.0807\n",
      "Epoch [7/50], Step [203/735], Loss: 0.2074\n",
      "Epoch [7/50], Step [204/735], Loss: 0.2724\n",
      "Epoch [7/50], Step [205/735], Loss: 0.2252\n",
      "Epoch [7/50], Step [206/735], Loss: 0.1147\n",
      "Epoch [7/50], Step [207/735], Loss: 1.2618\n",
      "Epoch [7/50], Step [208/735], Loss: 0.2037\n",
      "Epoch [7/50], Step [209/735], Loss: 0.2295\n",
      "Epoch [7/50], Step [210/735], Loss: 0.4778\n",
      "Epoch [7/50], Step [211/735], Loss: 0.1194\n",
      "Epoch [7/50], Step [212/735], Loss: 0.1701\n",
      "Epoch [7/50], Step [213/735], Loss: 0.1659\n",
      "Epoch [7/50], Step [214/735], Loss: 0.2569\n",
      "Epoch [7/50], Step [215/735], Loss: 0.2275\n",
      "Epoch [7/50], Step [216/735], Loss: 0.2436\n",
      "Epoch [7/50], Step [217/735], Loss: 0.1954\n",
      "Epoch [7/50], Step [218/735], Loss: 0.2967\n",
      "Epoch [7/50], Step [219/735], Loss: 0.2403\n",
      "Epoch [7/50], Step [220/735], Loss: 0.0822\n",
      "Epoch [7/50], Step [221/735], Loss: 0.1197\n",
      "Epoch [7/50], Step [222/735], Loss: 0.3930\n",
      "Epoch [7/50], Step [223/735], Loss: 0.1469\n",
      "Epoch [7/50], Step [224/735], Loss: 0.6740\n",
      "Epoch [7/50], Step [225/735], Loss: 0.2028\n",
      "Epoch [7/50], Step [226/735], Loss: 0.0531\n",
      "Epoch [7/50], Step [227/735], Loss: 0.1391\n",
      "Epoch [7/50], Step [228/735], Loss: 0.3673\n",
      "Epoch [7/50], Step [229/735], Loss: 0.4105\n",
      "Epoch [7/50], Step [230/735], Loss: 0.5634\n",
      "Epoch [7/50], Step [231/735], Loss: 0.1857\n",
      "Epoch [7/50], Step [232/735], Loss: 0.0958\n",
      "Epoch [7/50], Step [233/735], Loss: 0.4508\n",
      "Epoch [7/50], Step [234/735], Loss: 0.1740\n",
      "Epoch [7/50], Step [235/735], Loss: 0.1530\n",
      "Epoch [7/50], Step [236/735], Loss: 0.2073\n",
      "Epoch [7/50], Step [237/735], Loss: 0.0693\n",
      "Epoch [7/50], Step [238/735], Loss: 0.4433\n",
      "Epoch [7/50], Step [239/735], Loss: 0.1188\n",
      "Epoch [7/50], Step [240/735], Loss: 0.2109\n",
      "Epoch [7/50], Step [241/735], Loss: 0.1004\n",
      "Epoch [7/50], Step [242/735], Loss: 0.5821\n",
      "Epoch [7/50], Step [243/735], Loss: 0.1732\n",
      "Epoch [7/50], Step [244/735], Loss: 0.3374\n",
      "Epoch [7/50], Step [245/735], Loss: 0.1846\n",
      "Epoch [7/50], Step [246/735], Loss: 0.5329\n",
      "Epoch [7/50], Step [247/735], Loss: 0.2416\n",
      "Epoch [7/50], Step [248/735], Loss: 0.1297\n",
      "Epoch [7/50], Step [249/735], Loss: 0.2620\n",
      "Epoch [7/50], Step [250/735], Loss: 0.1136\n",
      "Epoch [7/50], Step [251/735], Loss: 0.1608\n",
      "Epoch [7/50], Step [252/735], Loss: 0.3461\n",
      "Epoch [7/50], Step [253/735], Loss: 0.0772\n",
      "Epoch [7/50], Step [254/735], Loss: 0.1715\n",
      "Epoch [7/50], Step [255/735], Loss: 0.1771\n",
      "Epoch [7/50], Step [256/735], Loss: 0.3235\n",
      "Epoch [7/50], Step [257/735], Loss: 0.1301\n",
      "Epoch [7/50], Step [258/735], Loss: 0.1709\n",
      "Epoch [7/50], Step [259/735], Loss: 0.1543\n",
      "Epoch [7/50], Step [260/735], Loss: 0.3450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Step [261/735], Loss: 0.6646\n",
      "Epoch [7/50], Step [262/735], Loss: 0.3424\n",
      "Epoch [7/50], Step [263/735], Loss: 0.0900\n",
      "Epoch [7/50], Step [264/735], Loss: 0.1448\n",
      "Epoch [7/50], Step [265/735], Loss: 0.0910\n",
      "Epoch [7/50], Step [266/735], Loss: 0.2858\n",
      "Epoch [7/50], Step [267/735], Loss: 0.6137\n",
      "Epoch [7/50], Step [268/735], Loss: 0.2575\n",
      "Epoch [7/50], Step [269/735], Loss: 0.2243\n",
      "Epoch [7/50], Step [270/735], Loss: 0.1228\n",
      "Epoch [7/50], Step [271/735], Loss: 1.2612\n",
      "Epoch [7/50], Step [272/735], Loss: 0.1087\n",
      "Epoch [7/50], Step [273/735], Loss: 0.7017\n",
      "Epoch [7/50], Step [274/735], Loss: 0.0845\n",
      "Epoch [7/50], Step [275/735], Loss: 0.0941\n",
      "Epoch [7/50], Step [276/735], Loss: 0.1573\n",
      "Epoch [7/50], Step [277/735], Loss: 0.2669\n",
      "Epoch [7/50], Step [278/735], Loss: 0.3102\n",
      "Epoch [7/50], Step [279/735], Loss: 0.1203\n",
      "Epoch [7/50], Step [280/735], Loss: 1.1245\n",
      "Epoch [7/50], Step [281/735], Loss: 0.1312\n",
      "Epoch [7/50], Step [282/735], Loss: 0.1439\n",
      "Epoch [7/50], Step [283/735], Loss: 0.1642\n",
      "Epoch [7/50], Step [284/735], Loss: 0.0833\n",
      "Epoch [7/50], Step [285/735], Loss: 0.0585\n",
      "Epoch [7/50], Step [286/735], Loss: 0.0845\n",
      "Epoch [7/50], Step [287/735], Loss: 0.0585\n",
      "Epoch [7/50], Step [288/735], Loss: 0.0813\n",
      "Epoch [7/50], Step [289/735], Loss: 0.4642\n",
      "Epoch [7/50], Step [290/735], Loss: 2.5158\n",
      "Epoch [7/50], Step [291/735], Loss: 0.9984\n",
      "Epoch [7/50], Step [292/735], Loss: 0.1228\n",
      "Epoch [7/50], Step [293/735], Loss: 0.1141\n",
      "Epoch [7/50], Step [294/735], Loss: 0.2091\n",
      "Epoch [7/50], Step [295/735], Loss: 0.2570\n",
      "Epoch [7/50], Step [296/735], Loss: 0.1931\n",
      "Epoch [7/50], Step [297/735], Loss: 0.1525\n",
      "Epoch [7/50], Step [298/735], Loss: 0.4789\n",
      "Epoch [7/50], Step [299/735], Loss: 0.1626\n",
      "Epoch [7/50], Step [300/735], Loss: 1.2763\n",
      "Epoch [7/50], Step [301/735], Loss: 0.4287\n",
      "Epoch [7/50], Step [302/735], Loss: 0.1441\n",
      "Epoch [7/50], Step [303/735], Loss: 0.1977\n",
      "Epoch [7/50], Step [304/735], Loss: 0.1884\n",
      "Epoch [7/50], Step [305/735], Loss: 0.2787\n",
      "Epoch [7/50], Step [306/735], Loss: 0.4375\n",
      "Epoch [7/50], Step [307/735], Loss: 0.1493\n",
      "Epoch [7/50], Step [308/735], Loss: 0.8880\n",
      "Epoch [7/50], Step [309/735], Loss: 0.1161\n",
      "Epoch [7/50], Step [310/735], Loss: 0.1087\n",
      "Epoch [7/50], Step [311/735], Loss: 0.1072\n",
      "Epoch [7/50], Step [312/735], Loss: 0.2971\n",
      "Epoch [7/50], Step [313/735], Loss: 0.1368\n",
      "Epoch [7/50], Step [314/735], Loss: 0.1397\n",
      "Epoch [7/50], Step [315/735], Loss: 0.0718\n",
      "Epoch [7/50], Step [316/735], Loss: 0.0681\n",
      "Epoch [7/50], Step [317/735], Loss: 0.4782\n",
      "Epoch [7/50], Step [318/735], Loss: 0.3895\n",
      "Epoch [7/50], Step [319/735], Loss: 0.2545\n",
      "Epoch [7/50], Step [320/735], Loss: 0.2424\n",
      "Epoch [7/50], Step [321/735], Loss: 0.2276\n",
      "Epoch [7/50], Step [322/735], Loss: 0.0761\n",
      "Epoch [7/50], Step [323/735], Loss: 0.2710\n",
      "Epoch [7/50], Step [324/735], Loss: 0.1407\n",
      "Epoch [7/50], Step [325/735], Loss: 0.1731\n",
      "Epoch [7/50], Step [326/735], Loss: 0.1338\n",
      "Epoch [7/50], Step [327/735], Loss: 0.1033\n",
      "Epoch [7/50], Step [328/735], Loss: 0.1549\n",
      "Epoch [7/50], Step [329/735], Loss: 0.0908\n",
      "Epoch [7/50], Step [330/735], Loss: 0.2448\n",
      "Epoch [7/50], Step [331/735], Loss: 0.2387\n",
      "Epoch [7/50], Step [332/735], Loss: 0.3256\n",
      "Epoch [7/50], Step [333/735], Loss: 0.2352\n",
      "Epoch [7/50], Step [334/735], Loss: 0.2053\n",
      "Epoch [7/50], Step [335/735], Loss: 0.3094\n",
      "Epoch [7/50], Step [336/735], Loss: 0.5930\n",
      "Epoch [7/50], Step [337/735], Loss: 0.1408\n",
      "Epoch [7/50], Step [338/735], Loss: 1.1981\n",
      "Epoch [7/50], Step [339/735], Loss: 0.1877\n",
      "Epoch [7/50], Step [340/735], Loss: 0.2685\n",
      "Epoch [7/50], Step [341/735], Loss: 0.0610\n",
      "Epoch [7/50], Step [342/735], Loss: 0.3504\n",
      "Epoch [7/50], Step [343/735], Loss: 0.0779\n",
      "Epoch [7/50], Step [344/735], Loss: 0.1640\n",
      "Epoch [7/50], Step [345/735], Loss: 0.0702\n",
      "Epoch [7/50], Step [346/735], Loss: 0.7006\n",
      "Epoch [7/50], Step [347/735], Loss: 1.3694\n",
      "Epoch [7/50], Step [348/735], Loss: 0.2467\n",
      "Epoch [7/50], Step [349/735], Loss: 0.1545\n",
      "Epoch [7/50], Step [350/735], Loss: 0.1262\n",
      "Epoch [7/50], Step [351/735], Loss: 0.1183\n",
      "Epoch [7/50], Step [352/735], Loss: 0.3201\n",
      "Epoch [7/50], Step [353/735], Loss: 0.4568\n",
      "Epoch [7/50], Step [354/735], Loss: 0.0989\n",
      "Epoch [7/50], Step [355/735], Loss: 0.4111\n",
      "Epoch [7/50], Step [356/735], Loss: 0.1218\n",
      "Epoch [7/50], Step [357/735], Loss: 3.3192\n",
      "Epoch [7/50], Step [358/735], Loss: 0.1513\n",
      "Epoch [7/50], Step [359/735], Loss: 0.4704\n",
      "Epoch [7/50], Step [360/735], Loss: 0.6018\n",
      "Epoch [7/50], Step [361/735], Loss: 3.0104\n",
      "Epoch [7/50], Step [362/735], Loss: 0.1927\n",
      "Epoch [7/50], Step [363/735], Loss: 1.0544\n",
      "Epoch [7/50], Step [364/735], Loss: 0.0726\n",
      "Epoch [7/50], Step [365/735], Loss: 0.1198\n",
      "Epoch [7/50], Step [366/735], Loss: 0.2091\n",
      "Epoch [7/50], Step [367/735], Loss: 0.2011\n",
      "Epoch [7/50], Step [368/735], Loss: 0.1871\n",
      "Epoch [7/50], Step [369/735], Loss: 0.7071\n",
      "Epoch [7/50], Step [370/735], Loss: 0.2173\n",
      "Epoch [7/50], Step [371/735], Loss: 0.3488\n",
      "Epoch [7/50], Step [372/735], Loss: 0.4006\n",
      "Epoch [7/50], Step [373/735], Loss: 0.1216\n",
      "Epoch [7/50], Step [374/735], Loss: 0.2376\n",
      "Epoch [7/50], Step [375/735], Loss: 0.0598\n",
      "Epoch [7/50], Step [376/735], Loss: 0.5265\n",
      "Epoch [7/50], Step [377/735], Loss: 0.3678\n",
      "Epoch [7/50], Step [378/735], Loss: 0.1724\n",
      "Epoch [7/50], Step [379/735], Loss: 0.2799\n",
      "Epoch [7/50], Step [380/735], Loss: 0.1366\n",
      "Epoch [7/50], Step [381/735], Loss: 0.4601\n",
      "Epoch [7/50], Step [382/735], Loss: 0.1415\n",
      "Epoch [7/50], Step [383/735], Loss: 0.1095\n",
      "Epoch [7/50], Step [384/735], Loss: 0.1398\n",
      "Epoch [7/50], Step [385/735], Loss: 0.3079\n",
      "Epoch [7/50], Step [386/735], Loss: 0.1456\n",
      "Epoch [7/50], Step [387/735], Loss: 0.1950\n",
      "Epoch [7/50], Step [388/735], Loss: 0.0935\n",
      "Epoch [7/50], Step [389/735], Loss: 0.2493\n",
      "Epoch [7/50], Step [390/735], Loss: 0.3054\n",
      "Epoch [7/50], Step [391/735], Loss: 0.1966\n",
      "Epoch [7/50], Step [392/735], Loss: 0.1484\n",
      "Epoch [7/50], Step [393/735], Loss: 0.3067\n",
      "Epoch [7/50], Step [394/735], Loss: 0.0731\n",
      "Epoch [7/50], Step [395/735], Loss: 0.6917\n",
      "Epoch [7/50], Step [396/735], Loss: 0.2493\n",
      "Epoch [7/50], Step [397/735], Loss: 0.1013\n",
      "Epoch [7/50], Step [398/735], Loss: 0.1005\n",
      "Epoch [7/50], Step [399/735], Loss: 0.0784\n",
      "Epoch [7/50], Step [400/735], Loss: 0.2147\n",
      "Epoch [7/50], Step [401/735], Loss: 0.0820\n",
      "Epoch [7/50], Step [402/735], Loss: 0.2193\n",
      "Epoch [7/50], Step [403/735], Loss: 0.4258\n",
      "Epoch [7/50], Step [404/735], Loss: 0.2874\n",
      "Epoch [7/50], Step [405/735], Loss: 0.5099\n",
      "Epoch [7/50], Step [406/735], Loss: 0.3631\n",
      "Epoch [7/50], Step [407/735], Loss: 0.3666\n",
      "Epoch [7/50], Step [408/735], Loss: 0.2828\n",
      "Epoch [7/50], Step [409/735], Loss: 0.2010\n",
      "Epoch [7/50], Step [410/735], Loss: 0.1198\n",
      "Epoch [7/50], Step [411/735], Loss: 0.1854\n",
      "Epoch [7/50], Step [412/735], Loss: 0.3557\n",
      "Epoch [7/50], Step [413/735], Loss: 2.6748\n",
      "Epoch [7/50], Step [414/735], Loss: 0.1758\n",
      "Epoch [7/50], Step [415/735], Loss: 0.1138\n",
      "Epoch [7/50], Step [416/735], Loss: 0.2942\n",
      "Epoch [7/50], Step [417/735], Loss: 0.1665\n",
      "Epoch [7/50], Step [418/735], Loss: 0.1355\n",
      "Epoch [7/50], Step [419/735], Loss: 0.0802\n",
      "Epoch [7/50], Step [420/735], Loss: 0.7111\n",
      "Epoch [7/50], Step [421/735], Loss: 0.1568\n",
      "Epoch [7/50], Step [422/735], Loss: 0.1432\n",
      "Epoch [7/50], Step [423/735], Loss: 0.1320\n",
      "Epoch [7/50], Step [424/735], Loss: 0.1397\n",
      "Epoch [7/50], Step [425/735], Loss: 0.2003\n",
      "Epoch [7/50], Step [426/735], Loss: 0.1586\n",
      "Epoch [7/50], Step [427/735], Loss: 0.1705\n",
      "Epoch [7/50], Step [428/735], Loss: 0.3608\n",
      "Epoch [7/50], Step [429/735], Loss: 0.2380\n",
      "Epoch [7/50], Step [430/735], Loss: 0.1506\n",
      "Epoch [7/50], Step [431/735], Loss: 0.2270\n",
      "Epoch [7/50], Step [432/735], Loss: 0.2138\n",
      "Epoch [7/50], Step [433/735], Loss: 0.9066\n",
      "Epoch [7/50], Step [434/735], Loss: 0.2033\n",
      "Epoch [7/50], Step [435/735], Loss: 0.2051\n",
      "Epoch [7/50], Step [436/735], Loss: 0.1275\n",
      "Epoch [7/50], Step [437/735], Loss: 0.1733\n",
      "Epoch [7/50], Step [438/735], Loss: 0.1381\n",
      "Epoch [7/50], Step [439/735], Loss: 0.0747\n",
      "Epoch [7/50], Step [440/735], Loss: 0.2562\n",
      "Epoch [7/50], Step [441/735], Loss: 0.2960\n",
      "Epoch [7/50], Step [442/735], Loss: 0.7012\n",
      "Epoch [7/50], Step [443/735], Loss: 0.1822\n",
      "Epoch [7/50], Step [444/735], Loss: 0.1207\n",
      "Epoch [7/50], Step [445/735], Loss: 0.0763\n",
      "Epoch [7/50], Step [446/735], Loss: 0.1523\n",
      "Epoch [7/50], Step [447/735], Loss: 0.1737\n",
      "Epoch [7/50], Step [448/735], Loss: 0.1650\n",
      "Epoch [7/50], Step [449/735], Loss: 0.2875\n",
      "Epoch [7/50], Step [450/735], Loss: 0.1216\n",
      "Epoch [7/50], Step [451/735], Loss: 0.2269\n",
      "Epoch [7/50], Step [452/735], Loss: 0.1044\n",
      "Epoch [7/50], Step [453/735], Loss: 0.0813\n",
      "Epoch [7/50], Step [454/735], Loss: 0.1964\n",
      "Epoch [7/50], Step [455/735], Loss: 0.0542\n",
      "Epoch [7/50], Step [456/735], Loss: 0.2058\n",
      "Epoch [7/50], Step [457/735], Loss: 0.1419\n",
      "Epoch [7/50], Step [458/735], Loss: 0.1562\n",
      "Epoch [7/50], Step [459/735], Loss: 0.1823\n",
      "Epoch [7/50], Step [460/735], Loss: 0.1305\n",
      "Epoch [7/50], Step [461/735], Loss: 0.2386\n",
      "Epoch [7/50], Step [462/735], Loss: 0.2245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Step [463/735], Loss: 0.1111\n",
      "Epoch [7/50], Step [464/735], Loss: 0.0800\n",
      "Epoch [7/50], Step [465/735], Loss: 0.0703\n",
      "Epoch [7/50], Step [466/735], Loss: 0.1594\n",
      "Epoch [7/50], Step [467/735], Loss: 0.0783\n",
      "Epoch [7/50], Step [468/735], Loss: 0.2876\n",
      "Epoch [7/50], Step [469/735], Loss: 0.1671\n",
      "Epoch [7/50], Step [470/735], Loss: 0.1470\n",
      "Epoch [7/50], Step [471/735], Loss: 0.4509\n",
      "Epoch [7/50], Step [472/735], Loss: 0.2069\n",
      "Epoch [7/50], Step [473/735], Loss: 0.1674\n",
      "Epoch [7/50], Step [474/735], Loss: 0.0722\n",
      "Epoch [7/50], Step [475/735], Loss: 0.3364\n",
      "Epoch [7/50], Step [476/735], Loss: 0.2371\n",
      "Epoch [7/50], Step [477/735], Loss: 0.1612\n",
      "Epoch [7/50], Step [478/735], Loss: 0.3063\n",
      "Epoch [7/50], Step [479/735], Loss: 0.1327\n",
      "Epoch [7/50], Step [480/735], Loss: 0.0603\n",
      "Epoch [7/50], Step [481/735], Loss: 0.6196\n",
      "Epoch [7/50], Step [482/735], Loss: 0.2634\n",
      "Epoch [7/50], Step [483/735], Loss: 0.1906\n",
      "Epoch [7/50], Step [484/735], Loss: 0.3278\n",
      "Epoch [7/50], Step [485/735], Loss: 0.3456\n",
      "Epoch [7/50], Step [486/735], Loss: 0.1485\n",
      "Epoch [7/50], Step [487/735], Loss: 0.2005\n",
      "Epoch [7/50], Step [488/735], Loss: 0.2067\n",
      "Epoch [7/50], Step [489/735], Loss: 0.1900\n",
      "Epoch [7/50], Step [490/735], Loss: 0.2056\n",
      "Epoch [7/50], Step [491/735], Loss: 0.1404\n",
      "Epoch [7/50], Step [492/735], Loss: 0.2037\n",
      "Epoch [7/50], Step [493/735], Loss: 0.0906\n",
      "Epoch [7/50], Step [494/735], Loss: 0.1019\n",
      "Epoch [7/50], Step [495/735], Loss: 0.4923\n",
      "Epoch [7/50], Step [496/735], Loss: 0.1613\n",
      "Epoch [7/50], Step [497/735], Loss: 0.1336\n",
      "Epoch [7/50], Step [498/735], Loss: 0.2800\n",
      "Epoch [7/50], Step [499/735], Loss: 0.1578\n",
      "Epoch [7/50], Step [500/735], Loss: 0.0453\n",
      "Epoch [7/50], Step [501/735], Loss: 0.0995\n",
      "Epoch [7/50], Step [502/735], Loss: 0.2292\n",
      "Epoch [7/50], Step [503/735], Loss: 0.1242\n",
      "Epoch [7/50], Step [504/735], Loss: 0.4400\n",
      "Epoch [7/50], Step [505/735], Loss: 0.2718\n",
      "Epoch [7/50], Step [506/735], Loss: 0.3267\n",
      "Epoch [7/50], Step [507/735], Loss: 0.2153\n",
      "Epoch [7/50], Step [508/735], Loss: 0.0903\n",
      "Epoch [7/50], Step [509/735], Loss: 0.0683\n",
      "Epoch [7/50], Step [510/735], Loss: 0.2030\n",
      "Epoch [7/50], Step [511/735], Loss: 0.1698\n",
      "Epoch [7/50], Step [512/735], Loss: 0.1008\n",
      "Epoch [7/50], Step [513/735], Loss: 0.1907\n",
      "Epoch [7/50], Step [514/735], Loss: 0.2885\n",
      "Epoch [7/50], Step [515/735], Loss: 0.1550\n",
      "Epoch [7/50], Step [516/735], Loss: 0.1844\n",
      "Epoch [7/50], Step [517/735], Loss: 0.2274\n",
      "Epoch [7/50], Step [518/735], Loss: 0.2247\n",
      "Epoch [7/50], Step [519/735], Loss: 0.1731\n",
      "Epoch [7/50], Step [520/735], Loss: 0.5749\n",
      "Epoch [7/50], Step [521/735], Loss: 0.4998\n",
      "Epoch [7/50], Step [522/735], Loss: 0.1384\n",
      "Epoch [7/50], Step [523/735], Loss: 0.1905\n",
      "Epoch [7/50], Step [524/735], Loss: 0.2962\n",
      "Epoch [7/50], Step [525/735], Loss: 0.1501\n",
      "Epoch [7/50], Step [526/735], Loss: 0.1493\n",
      "Epoch [7/50], Step [527/735], Loss: 0.1419\n",
      "Epoch [7/50], Step [528/735], Loss: 0.1658\n",
      "Epoch [7/50], Step [529/735], Loss: 0.2534\n",
      "Epoch [7/50], Step [530/735], Loss: 0.0837\n",
      "Epoch [7/50], Step [531/735], Loss: 0.2256\n",
      "Epoch [7/50], Step [532/735], Loss: 0.4620\n",
      "Epoch [7/50], Step [533/735], Loss: 0.1911\n",
      "Epoch [7/50], Step [534/735], Loss: 0.6160\n",
      "Epoch [7/50], Step [535/735], Loss: 0.1052\n",
      "Epoch [7/50], Step [536/735], Loss: 0.1172\n",
      "Epoch [7/50], Step [537/735], Loss: 0.1973\n",
      "Epoch [7/50], Step [538/735], Loss: 0.0736\n",
      "Epoch [7/50], Step [539/735], Loss: 0.3198\n",
      "Epoch [7/50], Step [540/735], Loss: 0.2076\n",
      "Epoch [7/50], Step [541/735], Loss: 0.1756\n",
      "Epoch [7/50], Step [542/735], Loss: 0.0861\n",
      "Epoch [7/50], Step [543/735], Loss: 0.0667\n",
      "Epoch [7/50], Step [544/735], Loss: 0.1074\n",
      "Epoch [7/50], Step [545/735], Loss: 0.1533\n",
      "Epoch [7/50], Step [546/735], Loss: 0.1609\n",
      "Epoch [7/50], Step [547/735], Loss: 0.3470\n",
      "Epoch [7/50], Step [548/735], Loss: 0.0866\n",
      "Epoch [7/50], Step [549/735], Loss: 0.5869\n",
      "Epoch [7/50], Step [550/735], Loss: 0.1029\n",
      "Epoch [7/50], Step [551/735], Loss: 0.0376\n",
      "Epoch [7/50], Step [552/735], Loss: 0.3350\n",
      "Epoch [7/50], Step [553/735], Loss: 0.4131\n",
      "Epoch [7/50], Step [554/735], Loss: 0.1475\n",
      "Epoch [7/50], Step [555/735], Loss: 0.3302\n",
      "Epoch [7/50], Step [556/735], Loss: 0.2205\n",
      "Epoch [7/50], Step [557/735], Loss: 0.7383\n",
      "Epoch [7/50], Step [558/735], Loss: 0.1739\n",
      "Epoch [7/50], Step [559/735], Loss: 0.2745\n",
      "Epoch [7/50], Step [560/735], Loss: 0.0618\n",
      "Epoch [7/50], Step [561/735], Loss: 1.0638\n",
      "Epoch [7/50], Step [562/735], Loss: 0.1269\n",
      "Epoch [7/50], Step [563/735], Loss: 0.1165\n",
      "Epoch [7/50], Step [564/735], Loss: 0.1812\n",
      "Epoch [7/50], Step [565/735], Loss: 0.0942\n",
      "Epoch [7/50], Step [566/735], Loss: 0.0715\n",
      "Epoch [7/50], Step [567/735], Loss: 0.1795\n",
      "Epoch [7/50], Step [568/735], Loss: 0.0937\n",
      "Epoch [7/50], Step [569/735], Loss: 0.0584\n",
      "Epoch [7/50], Step [570/735], Loss: 0.1129\n",
      "Epoch [7/50], Step [571/735], Loss: 0.0792\n",
      "Epoch [7/50], Step [572/735], Loss: 0.1472\n",
      "Epoch [7/50], Step [573/735], Loss: 0.1523\n",
      "Epoch [7/50], Step [574/735], Loss: 0.4331\n",
      "Epoch [7/50], Step [575/735], Loss: 0.2702\n",
      "Epoch [7/50], Step [576/735], Loss: 0.2548\n",
      "Epoch [7/50], Step [577/735], Loss: 0.4285\n",
      "Epoch [7/50], Step [578/735], Loss: 0.0650\n",
      "Epoch [7/50], Step [579/735], Loss: 0.0607\n",
      "Epoch [7/50], Step [580/735], Loss: 0.1248\n",
      "Epoch [7/50], Step [581/735], Loss: 0.0604\n",
      "Epoch [7/50], Step [582/735], Loss: 0.1646\n",
      "Epoch [7/50], Step [583/735], Loss: 0.1946\n",
      "Epoch [7/50], Step [584/735], Loss: 0.2488\n",
      "Epoch [7/50], Step [585/735], Loss: 0.3830\n",
      "Epoch [7/50], Step [586/735], Loss: 0.0526\n",
      "Epoch [7/50], Step [587/735], Loss: 0.1198\n",
      "Epoch [7/50], Step [588/735], Loss: 0.2076\n",
      "Epoch [7/50], Step [589/735], Loss: 0.1183\n",
      "Epoch [7/50], Step [590/735], Loss: 0.1204\n",
      "Epoch [7/50], Step [591/735], Loss: 0.2390\n",
      "Epoch [7/50], Step [592/735], Loss: 0.1769\n",
      "Epoch [7/50], Step [593/735], Loss: 0.2703\n",
      "Epoch [7/50], Step [594/735], Loss: 0.1454\n",
      "Epoch [7/50], Step [595/735], Loss: 0.2214\n",
      "Epoch [7/50], Step [596/735], Loss: 0.1055\n",
      "Epoch [7/50], Step [597/735], Loss: 0.2153\n",
      "Epoch [7/50], Step [598/735], Loss: 1.0581\n",
      "Epoch [7/50], Step [599/735], Loss: 0.1886\n",
      "Epoch [7/50], Step [600/735], Loss: 0.0714\n",
      "Epoch [7/50], Step [601/735], Loss: 0.3437\n",
      "Epoch [7/50], Step [602/735], Loss: 0.2333\n",
      "Epoch [7/50], Step [603/735], Loss: 0.1469\n",
      "Epoch [7/50], Step [604/735], Loss: 0.1660\n",
      "Epoch [7/50], Step [605/735], Loss: 0.2507\n",
      "Epoch [7/50], Step [606/735], Loss: 0.1032\n",
      "Epoch [7/50], Step [607/735], Loss: 0.1381\n",
      "Epoch [7/50], Step [608/735], Loss: 0.3333\n",
      "Epoch [7/50], Step [609/735], Loss: 0.1924\n",
      "Epoch [7/50], Step [610/735], Loss: 0.2388\n",
      "Epoch [7/50], Step [611/735], Loss: 0.1613\n",
      "Epoch [7/50], Step [612/735], Loss: 0.1020\n",
      "Epoch [7/50], Step [613/735], Loss: 0.2189\n",
      "Epoch [7/50], Step [614/735], Loss: 0.2531\n",
      "Epoch [7/50], Step [615/735], Loss: 0.0867\n",
      "Epoch [7/50], Step [616/735], Loss: 0.0882\n",
      "Epoch [7/50], Step [617/735], Loss: 0.0743\n",
      "Epoch [7/50], Step [618/735], Loss: 0.0829\n",
      "Epoch [7/50], Step [619/735], Loss: 0.1245\n",
      "Epoch [7/50], Step [620/735], Loss: 0.0717\n",
      "Epoch [7/50], Step [621/735], Loss: 0.2692\n",
      "Epoch [7/50], Step [622/735], Loss: 0.0492\n",
      "Epoch [7/50], Step [623/735], Loss: 0.0688\n",
      "Epoch [7/50], Step [624/735], Loss: 0.2287\n",
      "Epoch [7/50], Step [625/735], Loss: 0.1539\n",
      "Epoch [7/50], Step [626/735], Loss: 0.3405\n",
      "Epoch [7/50], Step [627/735], Loss: 0.1148\n",
      "Epoch [7/50], Step [628/735], Loss: 0.2675\n",
      "Epoch [7/50], Step [629/735], Loss: 0.1020\n",
      "Epoch [7/50], Step [630/735], Loss: 0.1838\n",
      "Epoch [7/50], Step [631/735], Loss: 0.1207\n",
      "Epoch [7/50], Step [632/735], Loss: 0.0663\n",
      "Epoch [7/50], Step [633/735], Loss: 0.1342\n",
      "Epoch [7/50], Step [634/735], Loss: 0.1518\n",
      "Epoch [7/50], Step [635/735], Loss: 0.1979\n",
      "Epoch [7/50], Step [636/735], Loss: 0.1725\n",
      "Epoch [7/50], Step [637/735], Loss: 0.1074\n",
      "Epoch [7/50], Step [638/735], Loss: 0.2228\n",
      "Epoch [7/50], Step [639/735], Loss: 0.1450\n",
      "Epoch [7/50], Step [640/735], Loss: 0.1023\n",
      "Epoch [7/50], Step [641/735], Loss: 0.3943\n",
      "Epoch [7/50], Step [642/735], Loss: 0.1160\n",
      "Epoch [7/50], Step [643/735], Loss: 0.2215\n",
      "Epoch [7/50], Step [644/735], Loss: 0.1411\n",
      "Epoch [7/50], Step [645/735], Loss: 0.1756\n",
      "Epoch [7/50], Step [646/735], Loss: 0.1260\n",
      "Epoch [7/50], Step [647/735], Loss: 0.2044\n",
      "Epoch [7/50], Step [648/735], Loss: 0.1063\n",
      "Epoch [7/50], Step [649/735], Loss: 0.0663\n",
      "Epoch [7/50], Step [650/735], Loss: 0.2847\n",
      "Epoch [7/50], Step [651/735], Loss: 0.2802\n",
      "Epoch [7/50], Step [652/735], Loss: 0.1151\n",
      "Epoch [7/50], Step [653/735], Loss: 0.2902\n",
      "Epoch [7/50], Step [654/735], Loss: 0.1203\n",
      "Epoch [7/50], Step [655/735], Loss: 0.0936\n",
      "Epoch [7/50], Step [656/735], Loss: 0.2371\n",
      "Epoch [7/50], Step [657/735], Loss: 0.1739\n",
      "Epoch [7/50], Step [658/735], Loss: 0.2822\n",
      "Epoch [7/50], Step [659/735], Loss: 0.1406\n",
      "Epoch [7/50], Step [660/735], Loss: 0.1729\n",
      "Epoch [7/50], Step [661/735], Loss: 0.0659\n",
      "Epoch [7/50], Step [662/735], Loss: 0.4789\n",
      "Epoch [7/50], Step [663/735], Loss: 0.0810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Step [664/735], Loss: 0.1573\n",
      "Epoch [7/50], Step [665/735], Loss: 0.2389\n",
      "Epoch [7/50], Step [666/735], Loss: 0.1905\n",
      "Epoch [7/50], Step [667/735], Loss: 0.2203\n",
      "Epoch [7/50], Step [668/735], Loss: 0.1396\n",
      "Epoch [7/50], Step [669/735], Loss: 0.0543\n",
      "Epoch [7/50], Step [670/735], Loss: 0.1668\n",
      "Epoch [7/50], Step [671/735], Loss: 0.0479\n",
      "Epoch [7/50], Step [672/735], Loss: 0.1116\n",
      "Epoch [7/50], Step [673/735], Loss: 0.1287\n",
      "Epoch [7/50], Step [674/735], Loss: 0.4203\n",
      "Epoch [7/50], Step [675/735], Loss: 0.1130\n",
      "Epoch [7/50], Step [676/735], Loss: 0.1612\n",
      "Epoch [7/50], Step [677/735], Loss: 2.7328\n",
      "Epoch [7/50], Step [678/735], Loss: 0.1064\n",
      "Epoch [7/50], Step [679/735], Loss: 0.3384\n",
      "Epoch [7/50], Step [680/735], Loss: 0.1520\n",
      "Epoch [7/50], Step [681/735], Loss: 0.1301\n",
      "Epoch [7/50], Step [682/735], Loss: 0.0683\n",
      "Epoch [7/50], Step [683/735], Loss: 0.0912\n",
      "Epoch [7/50], Step [684/735], Loss: 0.2129\n",
      "Epoch [7/50], Step [685/735], Loss: 0.2019\n",
      "Epoch [7/50], Step [686/735], Loss: 0.2990\n",
      "Epoch [7/50], Step [687/735], Loss: 0.1850\n",
      "Epoch [7/50], Step [688/735], Loss: 0.2262\n",
      "Epoch [7/50], Step [689/735], Loss: 0.1611\n",
      "Epoch [7/50], Step [690/735], Loss: 0.3040\n",
      "Epoch [7/50], Step [691/735], Loss: 0.1514\n",
      "Epoch [7/50], Step [692/735], Loss: 0.1249\n",
      "Epoch [7/50], Step [693/735], Loss: 0.1544\n",
      "Epoch [7/50], Step [694/735], Loss: 0.4643\n",
      "Epoch [7/50], Step [695/735], Loss: 0.1342\n",
      "Epoch [7/50], Step [696/735], Loss: 0.2669\n",
      "Epoch [7/50], Step [697/735], Loss: 0.1289\n",
      "Epoch [7/50], Step [698/735], Loss: 0.2615\n",
      "Epoch [7/50], Step [699/735], Loss: 0.1225\n",
      "Epoch [7/50], Step [700/735], Loss: 0.2872\n",
      "Epoch [7/50], Step [701/735], Loss: 0.0496\n",
      "Epoch [7/50], Step [702/735], Loss: 0.2651\n",
      "Epoch [7/50], Step [703/735], Loss: 0.1628\n",
      "Epoch [7/50], Step [704/735], Loss: 0.3974\n",
      "Epoch [7/50], Step [705/735], Loss: 0.6017\n",
      "Epoch [7/50], Step [706/735], Loss: 0.2708\n",
      "Epoch [7/50], Step [707/735], Loss: 0.1272\n",
      "Epoch [7/50], Step [708/735], Loss: 1.8542\n",
      "Epoch [7/50], Step [709/735], Loss: 0.2517\n",
      "Epoch [7/50], Step [710/735], Loss: 0.3026\n",
      "Epoch [7/50], Step [711/735], Loss: 0.1483\n",
      "Epoch [7/50], Step [712/735], Loss: 0.0704\n",
      "Epoch [7/50], Step [713/735], Loss: 0.1894\n",
      "Epoch [7/50], Step [714/735], Loss: 0.3037\n",
      "Epoch [7/50], Step [715/735], Loss: 0.6532\n",
      "Epoch [7/50], Step [716/735], Loss: 0.2780\n",
      "Epoch [7/50], Step [717/735], Loss: 0.3218\n",
      "Epoch [7/50], Step [718/735], Loss: 0.4566\n",
      "Epoch [7/50], Step [719/735], Loss: 0.2274\n",
      "Epoch [7/50], Step [720/735], Loss: 0.2002\n",
      "Epoch [7/50], Step [721/735], Loss: 0.2343\n",
      "Epoch [7/50], Step [722/735], Loss: 0.2040\n",
      "Epoch [7/50], Step [723/735], Loss: 0.1251\n",
      "Epoch [7/50], Step [724/735], Loss: 0.1398\n",
      "Epoch [7/50], Step [725/735], Loss: 0.2896\n",
      "Epoch [7/50], Step [726/735], Loss: 0.2657\n",
      "Epoch [7/50], Step [727/735], Loss: 0.1777\n",
      "Epoch [7/50], Step [728/735], Loss: 0.1216\n",
      "Epoch [7/50], Step [729/735], Loss: 0.0393\n",
      "Epoch [7/50], Step [730/735], Loss: 0.1281\n",
      "Epoch [7/50], Step [731/735], Loss: 0.3111\n",
      "Epoch [7/50], Step [732/735], Loss: 0.7410\n",
      "Epoch [7/50], Step [733/735], Loss: 0.2314\n",
      "Epoch [7/50], Step [734/735], Loss: 0.3815\n",
      "Epoch [7/50], Step [735/735], Loss: 0.0817\n",
      "Epoch [8/50], Step [1/735], Loss: 0.1641\n",
      "Epoch [8/50], Step [2/735], Loss: 0.2608\n",
      "Epoch [8/50], Step [3/735], Loss: 0.2864\n",
      "Epoch [8/50], Step [4/735], Loss: 1.2289\n",
      "Epoch [8/50], Step [5/735], Loss: 0.0593\n",
      "Epoch [8/50], Step [6/735], Loss: 0.2925\n",
      "Epoch [8/50], Step [7/735], Loss: 0.5668\n",
      "Epoch [8/50], Step [8/735], Loss: 0.0922\n",
      "Epoch [8/50], Step [9/735], Loss: 0.3033\n",
      "Epoch [8/50], Step [10/735], Loss: 0.2074\n",
      "Epoch [8/50], Step [11/735], Loss: 0.2456\n",
      "Epoch [8/50], Step [12/735], Loss: 0.0988\n",
      "Epoch [8/50], Step [13/735], Loss: 0.1794\n",
      "Epoch [8/50], Step [14/735], Loss: 0.1101\n",
      "Epoch [8/50], Step [15/735], Loss: 0.1354\n",
      "Epoch [8/50], Step [16/735], Loss: 0.2303\n",
      "Epoch [8/50], Step [17/735], Loss: 0.1047\n",
      "Epoch [8/50], Step [18/735], Loss: 0.0992\n",
      "Epoch [8/50], Step [19/735], Loss: 0.2759\n",
      "Epoch [8/50], Step [20/735], Loss: 0.7448\n",
      "Epoch [8/50], Step [21/735], Loss: 0.0849\n",
      "Epoch [8/50], Step [22/735], Loss: 0.3026\n",
      "Epoch [8/50], Step [23/735], Loss: 0.4618\n",
      "Epoch [8/50], Step [24/735], Loss: 0.2223\n",
      "Epoch [8/50], Step [25/735], Loss: 0.1636\n",
      "Epoch [8/50], Step [26/735], Loss: 0.1164\n",
      "Epoch [8/50], Step [27/735], Loss: 0.2689\n",
      "Epoch [8/50], Step [28/735], Loss: 0.1924\n",
      "Epoch [8/50], Step [29/735], Loss: 0.1010\n",
      "Epoch [8/50], Step [30/735], Loss: 0.2325\n",
      "Epoch [8/50], Step [31/735], Loss: 0.1327\n",
      "Epoch [8/50], Step [32/735], Loss: 0.2770\n",
      "Epoch [8/50], Step [33/735], Loss: 0.5577\n",
      "Epoch [8/50], Step [34/735], Loss: 0.2309\n",
      "Epoch [8/50], Step [35/735], Loss: 0.1829\n",
      "Epoch [8/50], Step [36/735], Loss: 0.1461\n",
      "Epoch [8/50], Step [37/735], Loss: 0.2132\n",
      "Epoch [8/50], Step [38/735], Loss: 0.2971\n",
      "Epoch [8/50], Step [39/735], Loss: 0.1623\n",
      "Epoch [8/50], Step [40/735], Loss: 0.1806\n",
      "Epoch [8/50], Step [41/735], Loss: 0.2992\n",
      "Epoch [8/50], Step [42/735], Loss: 0.0897\n",
      "Epoch [8/50], Step [43/735], Loss: 0.1234\n",
      "Epoch [8/50], Step [44/735], Loss: 0.2046\n",
      "Epoch [8/50], Step [45/735], Loss: 0.2162\n",
      "Epoch [8/50], Step [46/735], Loss: 0.3869\n",
      "Epoch [8/50], Step [47/735], Loss: 0.1331\n",
      "Epoch [8/50], Step [48/735], Loss: 0.1476\n",
      "Epoch [8/50], Step [49/735], Loss: 0.2042\n",
      "Epoch [8/50], Step [50/735], Loss: 0.1709\n",
      "Epoch [8/50], Step [51/735], Loss: 0.3695\n",
      "Epoch [8/50], Step [52/735], Loss: 0.1313\n",
      "Epoch [8/50], Step [53/735], Loss: 0.2522\n",
      "Epoch [8/50], Step [54/735], Loss: 0.0980\n",
      "Epoch [8/50], Step [55/735], Loss: 0.6216\n",
      "Epoch [8/50], Step [56/735], Loss: 0.1474\n",
      "Epoch [8/50], Step [57/735], Loss: 0.2879\n",
      "Epoch [8/50], Step [58/735], Loss: 0.1361\n",
      "Epoch [8/50], Step [59/735], Loss: 0.2275\n",
      "Epoch [8/50], Step [60/735], Loss: 0.4811\n",
      "Epoch [8/50], Step [61/735], Loss: 0.2315\n",
      "Epoch [8/50], Step [62/735], Loss: 0.0865\n",
      "Epoch [8/50], Step [63/735], Loss: 0.4314\n",
      "Epoch [8/50], Step [64/735], Loss: 0.3282\n",
      "Epoch [8/50], Step [65/735], Loss: 0.0534\n",
      "Epoch [8/50], Step [66/735], Loss: 0.1145\n",
      "Epoch [8/50], Step [67/735], Loss: 0.1737\n",
      "Epoch [8/50], Step [68/735], Loss: 0.5729\n",
      "Epoch [8/50], Step [69/735], Loss: 0.0754\n",
      "Epoch [8/50], Step [70/735], Loss: 0.0832\n",
      "Epoch [8/50], Step [71/735], Loss: 0.1346\n",
      "Epoch [8/50], Step [72/735], Loss: 0.1876\n",
      "Epoch [8/50], Step [73/735], Loss: 2.9415\n",
      "Epoch [8/50], Step [74/735], Loss: 0.4279\n",
      "Epoch [8/50], Step [75/735], Loss: 0.0624\n",
      "Epoch [8/50], Step [76/735], Loss: 0.3769\n",
      "Epoch [8/50], Step [77/735], Loss: 0.2534\n",
      "Epoch [8/50], Step [78/735], Loss: 0.1640\n",
      "Epoch [8/50], Step [79/735], Loss: 0.2685\n",
      "Epoch [8/50], Step [80/735], Loss: 0.2430\n",
      "Epoch [8/50], Step [81/735], Loss: 0.0636\n",
      "Epoch [8/50], Step [82/735], Loss: 0.1074\n",
      "Epoch [8/50], Step [83/735], Loss: 0.1964\n",
      "Epoch [8/50], Step [84/735], Loss: 0.2649\n",
      "Epoch [8/50], Step [85/735], Loss: 0.2097\n",
      "Epoch [8/50], Step [86/735], Loss: 0.0756\n",
      "Epoch [8/50], Step [87/735], Loss: 0.1458\n",
      "Epoch [8/50], Step [88/735], Loss: 0.3546\n",
      "Epoch [8/50], Step [89/735], Loss: 0.1678\n",
      "Epoch [8/50], Step [90/735], Loss: 0.0943\n",
      "Epoch [8/50], Step [91/735], Loss: 0.1266\n",
      "Epoch [8/50], Step [92/735], Loss: 0.1198\n",
      "Epoch [8/50], Step [93/735], Loss: 0.0618\n",
      "Epoch [8/50], Step [94/735], Loss: 0.1409\n",
      "Epoch [8/50], Step [95/735], Loss: 0.1108\n",
      "Epoch [8/50], Step [96/735], Loss: 0.1109\n",
      "Epoch [8/50], Step [97/735], Loss: 0.0687\n",
      "Epoch [8/50], Step [98/735], Loss: 0.1507\n",
      "Epoch [8/50], Step [99/735], Loss: 0.2974\n",
      "Epoch [8/50], Step [100/735], Loss: 0.3443\n",
      "Epoch [8/50], Step [101/735], Loss: 0.2073\n",
      "Epoch [8/50], Step [102/735], Loss: 0.0913\n",
      "Epoch [8/50], Step [103/735], Loss: 0.0323\n",
      "Epoch [8/50], Step [104/735], Loss: 0.2135\n",
      "Epoch [8/50], Step [105/735], Loss: 0.1939\n",
      "Epoch [8/50], Step [106/735], Loss: 0.2336\n",
      "Epoch [8/50], Step [107/735], Loss: 0.1113\n",
      "Epoch [8/50], Step [108/735], Loss: 0.8453\n",
      "Epoch [8/50], Step [109/735], Loss: 0.2627\n",
      "Epoch [8/50], Step [110/735], Loss: 0.1020\n",
      "Epoch [8/50], Step [111/735], Loss: 0.2435\n",
      "Epoch [8/50], Step [112/735], Loss: 0.2263\n",
      "Epoch [8/50], Step [113/735], Loss: 0.2236\n",
      "Epoch [8/50], Step [114/735], Loss: 0.1306\n",
      "Epoch [8/50], Step [115/735], Loss: 1.0145\n",
      "Epoch [8/50], Step [116/735], Loss: 0.0953\n",
      "Epoch [8/50], Step [117/735], Loss: 1.6105\n",
      "Epoch [8/50], Step [118/735], Loss: 1.0760\n",
      "Epoch [8/50], Step [119/735], Loss: 0.4113\n",
      "Epoch [8/50], Step [120/735], Loss: 0.1362\n",
      "Epoch [8/50], Step [121/735], Loss: 0.2368\n",
      "Epoch [8/50], Step [122/735], Loss: 0.1503\n",
      "Epoch [8/50], Step [123/735], Loss: 0.2208\n",
      "Epoch [8/50], Step [124/735], Loss: 0.1836\n",
      "Epoch [8/50], Step [125/735], Loss: 0.1693\n",
      "Epoch [8/50], Step [126/735], Loss: 0.1578\n",
      "Epoch [8/50], Step [127/735], Loss: 0.2329\n",
      "Epoch [8/50], Step [128/735], Loss: 0.1775\n",
      "Epoch [8/50], Step [129/735], Loss: 0.1532\n",
      "Epoch [8/50], Step [130/735], Loss: 0.1790\n",
      "Epoch [8/50], Step [131/735], Loss: 0.3436\n",
      "Epoch [8/50], Step [132/735], Loss: 0.2396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Step [133/735], Loss: 0.1257\n",
      "Epoch [8/50], Step [134/735], Loss: 0.4051\n",
      "Epoch [8/50], Step [135/735], Loss: 0.2577\n",
      "Epoch [8/50], Step [136/735], Loss: 0.2798\n",
      "Epoch [8/50], Step [137/735], Loss: 0.2285\n",
      "Epoch [8/50], Step [138/735], Loss: 0.1169\n",
      "Epoch [8/50], Step [139/735], Loss: 0.2527\n",
      "Epoch [8/50], Step [140/735], Loss: 0.2022\n",
      "Epoch [8/50], Step [141/735], Loss: 0.1955\n",
      "Epoch [8/50], Step [142/735], Loss: 0.0770\n",
      "Epoch [8/50], Step [143/735], Loss: 0.6954\n",
      "Epoch [8/50], Step [144/735], Loss: 0.1092\n",
      "Epoch [8/50], Step [145/735], Loss: 0.1925\n",
      "Epoch [8/50], Step [146/735], Loss: 0.1421\n",
      "Epoch [8/50], Step [147/735], Loss: 0.1152\n",
      "Epoch [8/50], Step [148/735], Loss: 0.3878\n",
      "Epoch [8/50], Step [149/735], Loss: 0.0984\n",
      "Epoch [8/50], Step [150/735], Loss: 0.1560\n",
      "Epoch [8/50], Step [151/735], Loss: 0.1130\n",
      "Epoch [8/50], Step [152/735], Loss: 0.2814\n",
      "Epoch [8/50], Step [153/735], Loss: 0.0864\n",
      "Epoch [8/50], Step [154/735], Loss: 0.3614\n",
      "Epoch [8/50], Step [155/735], Loss: 0.2248\n",
      "Epoch [8/50], Step [156/735], Loss: 1.1120\n",
      "Epoch [8/50], Step [157/735], Loss: 0.0621\n",
      "Epoch [8/50], Step [158/735], Loss: 0.7086\n",
      "Epoch [8/50], Step [159/735], Loss: 0.1044\n",
      "Epoch [8/50], Step [160/735], Loss: 0.3394\n",
      "Epoch [8/50], Step [161/735], Loss: 0.1503\n",
      "Epoch [8/50], Step [162/735], Loss: 0.1058\n",
      "Epoch [8/50], Step [163/735], Loss: 0.4554\n",
      "Epoch [8/50], Step [164/735], Loss: 0.1524\n",
      "Epoch [8/50], Step [165/735], Loss: 0.2242\n",
      "Epoch [8/50], Step [166/735], Loss: 0.1969\n",
      "Epoch [8/50], Step [167/735], Loss: 0.1470\n",
      "Epoch [8/50], Step [168/735], Loss: 0.1219\n",
      "Epoch [8/50], Step [169/735], Loss: 0.1007\n",
      "Epoch [8/50], Step [170/735], Loss: 0.1431\n",
      "Epoch [8/50], Step [171/735], Loss: 0.1013\n",
      "Epoch [8/50], Step [172/735], Loss: 0.1204\n",
      "Epoch [8/50], Step [173/735], Loss: 0.1907\n",
      "Epoch [8/50], Step [174/735], Loss: 0.9876\n",
      "Epoch [8/50], Step [175/735], Loss: 0.2702\n",
      "Epoch [8/50], Step [176/735], Loss: 0.2339\n",
      "Epoch [8/50], Step [177/735], Loss: 0.0822\n",
      "Epoch [8/50], Step [178/735], Loss: 0.1866\n",
      "Epoch [8/50], Step [179/735], Loss: 0.1610\n",
      "Epoch [8/50], Step [180/735], Loss: 0.3528\n",
      "Epoch [8/50], Step [181/735], Loss: 0.1337\n",
      "Epoch [8/50], Step [182/735], Loss: 0.2327\n",
      "Epoch [8/50], Step [183/735], Loss: 0.2005\n",
      "Epoch [8/50], Step [184/735], Loss: 0.0411\n",
      "Epoch [8/50], Step [185/735], Loss: 0.1562\n",
      "Epoch [8/50], Step [186/735], Loss: 0.3425\n",
      "Epoch [8/50], Step [187/735], Loss: 0.1545\n",
      "Epoch [8/50], Step [188/735], Loss: 0.2669\n",
      "Epoch [8/50], Step [189/735], Loss: 0.1345\n",
      "Epoch [8/50], Step [190/735], Loss: 0.1492\n",
      "Epoch [8/50], Step [191/735], Loss: 0.3004\n",
      "Epoch [8/50], Step [192/735], Loss: 0.2767\n",
      "Epoch [8/50], Step [193/735], Loss: 0.1082\n",
      "Epoch [8/50], Step [194/735], Loss: 0.0612\n",
      "Epoch [8/50], Step [195/735], Loss: 0.3735\n",
      "Epoch [8/50], Step [196/735], Loss: 0.0943\n",
      "Epoch [8/50], Step [197/735], Loss: 0.2086\n",
      "Epoch [8/50], Step [198/735], Loss: 0.5946\n",
      "Epoch [8/50], Step [199/735], Loss: 0.1662\n",
      "Epoch [8/50], Step [200/735], Loss: 0.1751\n",
      "Epoch [8/50], Step [201/735], Loss: 0.1571\n",
      "Epoch [8/50], Step [202/735], Loss: 0.1775\n",
      "Epoch [8/50], Step [203/735], Loss: 0.0913\n",
      "Epoch [8/50], Step [204/735], Loss: 0.3379\n",
      "Epoch [8/50], Step [205/735], Loss: 0.1545\n",
      "Epoch [8/50], Step [206/735], Loss: 0.1713\n",
      "Epoch [8/50], Step [207/735], Loss: 0.1305\n",
      "Epoch [8/50], Step [208/735], Loss: 0.3065\n",
      "Epoch [8/50], Step [209/735], Loss: 0.4097\n",
      "Epoch [8/50], Step [210/735], Loss: 0.2617\n",
      "Epoch [8/50], Step [211/735], Loss: 0.0853\n",
      "Epoch [8/50], Step [212/735], Loss: 0.1893\n",
      "Epoch [8/50], Step [213/735], Loss: 0.2689\n",
      "Epoch [8/50], Step [214/735], Loss: 0.1038\n",
      "Epoch [8/50], Step [215/735], Loss: 0.1162\n",
      "Epoch [8/50], Step [216/735], Loss: 0.2075\n",
      "Epoch [8/50], Step [217/735], Loss: 0.1507\n",
      "Epoch [8/50], Step [218/735], Loss: 0.2560\n",
      "Epoch [8/50], Step [219/735], Loss: 0.1937\n",
      "Epoch [8/50], Step [220/735], Loss: 0.1343\n",
      "Epoch [8/50], Step [221/735], Loss: 0.1081\n",
      "Epoch [8/50], Step [222/735], Loss: 0.3008\n",
      "Epoch [8/50], Step [223/735], Loss: 0.0774\n",
      "Epoch [8/50], Step [224/735], Loss: 0.0911\n",
      "Epoch [8/50], Step [225/735], Loss: 0.1194\n",
      "Epoch [8/50], Step [226/735], Loss: 0.0967\n",
      "Epoch [8/50], Step [227/735], Loss: 0.1104\n",
      "Epoch [8/50], Step [228/735], Loss: 0.1910\n",
      "Epoch [8/50], Step [229/735], Loss: 0.0824\n",
      "Epoch [8/50], Step [230/735], Loss: 0.1831\n",
      "Epoch [8/50], Step [231/735], Loss: 0.1151\n",
      "Epoch [8/50], Step [232/735], Loss: 0.1943\n",
      "Epoch [8/50], Step [233/735], Loss: 0.2092\n",
      "Epoch [8/50], Step [234/735], Loss: 0.1813\n",
      "Epoch [8/50], Step [235/735], Loss: 0.1622\n",
      "Epoch [8/50], Step [236/735], Loss: 0.5268\n",
      "Epoch [8/50], Step [237/735], Loss: 0.0938\n",
      "Epoch [8/50], Step [238/735], Loss: 0.1204\n",
      "Epoch [8/50], Step [239/735], Loss: 0.1938\n",
      "Epoch [8/50], Step [240/735], Loss: 0.1438\n",
      "Epoch [8/50], Step [241/735], Loss: 0.2893\n",
      "Epoch [8/50], Step [242/735], Loss: 0.1077\n",
      "Epoch [8/50], Step [243/735], Loss: 0.1933\n",
      "Epoch [8/50], Step [244/735], Loss: 0.2732\n",
      "Epoch [8/50], Step [245/735], Loss: 0.1560\n",
      "Epoch [8/50], Step [246/735], Loss: 0.2992\n",
      "Epoch [8/50], Step [247/735], Loss: 0.0736\n",
      "Epoch [8/50], Step [248/735], Loss: 0.2767\n",
      "Epoch [8/50], Step [249/735], Loss: 2.9937\n",
      "Epoch [8/50], Step [250/735], Loss: 0.1244\n",
      "Epoch [8/50], Step [251/735], Loss: 0.1355\n",
      "Epoch [8/50], Step [252/735], Loss: 0.2578\n",
      "Epoch [8/50], Step [253/735], Loss: 0.5417\n",
      "Epoch [8/50], Step [254/735], Loss: 0.2223\n",
      "Epoch [8/50], Step [255/735], Loss: 0.1899\n",
      "Epoch [8/50], Step [256/735], Loss: 1.4775\n",
      "Epoch [8/50], Step [257/735], Loss: 0.2569\n",
      "Epoch [8/50], Step [258/735], Loss: 0.3172\n",
      "Epoch [8/50], Step [259/735], Loss: 0.3456\n",
      "Epoch [8/50], Step [260/735], Loss: 0.3069\n",
      "Epoch [8/50], Step [261/735], Loss: 0.0978\n",
      "Epoch [8/50], Step [262/735], Loss: 2.2418\n",
      "Epoch [8/50], Step [263/735], Loss: 1.4956\n",
      "Epoch [8/50], Step [264/735], Loss: 0.3754\n",
      "Epoch [8/50], Step [265/735], Loss: 0.1933\n",
      "Epoch [8/50], Step [266/735], Loss: 0.2530\n",
      "Epoch [8/50], Step [267/735], Loss: 0.1115\n",
      "Epoch [8/50], Step [268/735], Loss: 0.2990\n",
      "Epoch [8/50], Step [269/735], Loss: 0.7341\n",
      "Epoch [8/50], Step [270/735], Loss: 0.1723\n",
      "Epoch [8/50], Step [271/735], Loss: 0.3441\n",
      "Epoch [8/50], Step [272/735], Loss: 0.1429\n",
      "Epoch [8/50], Step [273/735], Loss: 0.5966\n",
      "Epoch [8/50], Step [274/735], Loss: 0.0600\n",
      "Epoch [8/50], Step [275/735], Loss: 0.2762\n",
      "Epoch [8/50], Step [276/735], Loss: 0.1346\n",
      "Epoch [8/50], Step [277/735], Loss: 0.0652\n",
      "Epoch [8/50], Step [278/735], Loss: 0.1530\n",
      "Epoch [8/50], Step [279/735], Loss: 0.1711\n",
      "Epoch [8/50], Step [280/735], Loss: 0.0529\n",
      "Epoch [8/50], Step [281/735], Loss: 0.1564\n",
      "Epoch [8/50], Step [282/735], Loss: 0.1383\n",
      "Epoch [8/50], Step [283/735], Loss: 0.3919\n",
      "Epoch [8/50], Step [284/735], Loss: 0.1221\n",
      "Epoch [8/50], Step [285/735], Loss: 0.1453\n",
      "Epoch [8/50], Step [286/735], Loss: 1.1727\n",
      "Epoch [8/50], Step [287/735], Loss: 0.1502\n",
      "Epoch [8/50], Step [288/735], Loss: 0.1674\n",
      "Epoch [8/50], Step [289/735], Loss: 0.1119\n",
      "Epoch [8/50], Step [290/735], Loss: 0.2138\n",
      "Epoch [8/50], Step [291/735], Loss: 0.4450\n",
      "Epoch [8/50], Step [292/735], Loss: 0.1558\n",
      "Epoch [8/50], Step [293/735], Loss: 0.1983\n",
      "Epoch [8/50], Step [294/735], Loss: 0.1023\n",
      "Epoch [8/50], Step [295/735], Loss: 0.1035\n",
      "Epoch [8/50], Step [296/735], Loss: 0.2218\n",
      "Epoch [8/50], Step [297/735], Loss: 0.5840\n",
      "Epoch [8/50], Step [298/735], Loss: 0.1316\n",
      "Epoch [8/50], Step [299/735], Loss: 0.4070\n",
      "Epoch [8/50], Step [300/735], Loss: 0.1530\n",
      "Epoch [8/50], Step [301/735], Loss: 0.4472\n",
      "Epoch [8/50], Step [302/735], Loss: 0.0734\n",
      "Epoch [8/50], Step [303/735], Loss: 0.0826\n",
      "Epoch [8/50], Step [304/735], Loss: 0.0859\n",
      "Epoch [8/50], Step [305/735], Loss: 0.1185\n",
      "Epoch [8/50], Step [306/735], Loss: 0.3434\n",
      "Epoch [8/50], Step [307/735], Loss: 0.2851\n",
      "Epoch [8/50], Step [308/735], Loss: 0.3057\n",
      "Epoch [8/50], Step [309/735], Loss: 0.3095\n",
      "Epoch [8/50], Step [310/735], Loss: 0.1572\n",
      "Epoch [8/50], Step [311/735], Loss: 0.1724\n",
      "Epoch [8/50], Step [312/735], Loss: 0.4202\n",
      "Epoch [8/50], Step [313/735], Loss: 0.1793\n",
      "Epoch [8/50], Step [314/735], Loss: 0.3026\n",
      "Epoch [8/50], Step [315/735], Loss: 0.3617\n",
      "Epoch [8/50], Step [316/735], Loss: 0.3714\n",
      "Epoch [8/50], Step [317/735], Loss: 0.1074\n",
      "Epoch [8/50], Step [318/735], Loss: 0.3784\n",
      "Epoch [8/50], Step [319/735], Loss: 0.1982\n",
      "Epoch [8/50], Step [320/735], Loss: 0.0798\n",
      "Epoch [8/50], Step [321/735], Loss: 0.1231\n",
      "Epoch [8/50], Step [322/735], Loss: 0.1038\n",
      "Epoch [8/50], Step [323/735], Loss: 0.2362\n",
      "Epoch [8/50], Step [324/735], Loss: 0.2121\n",
      "Epoch [8/50], Step [325/735], Loss: 0.2065\n",
      "Epoch [8/50], Step [326/735], Loss: 0.3530\n",
      "Epoch [8/50], Step [327/735], Loss: 0.2451\n",
      "Epoch [8/50], Step [328/735], Loss: 0.1373\n",
      "Epoch [8/50], Step [329/735], Loss: 0.1230\n",
      "Epoch [8/50], Step [330/735], Loss: 0.1631\n",
      "Epoch [8/50], Step [331/735], Loss: 0.0529\n",
      "Epoch [8/50], Step [332/735], Loss: 0.2942\n",
      "Epoch [8/50], Step [333/735], Loss: 0.1232\n",
      "Epoch [8/50], Step [334/735], Loss: 0.0722\n",
      "Epoch [8/50], Step [335/735], Loss: 0.0637\n",
      "Epoch [8/50], Step [336/735], Loss: 0.0673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Step [337/735], Loss: 0.1321\n",
      "Epoch [8/50], Step [338/735], Loss: 0.2253\n",
      "Epoch [8/50], Step [339/735], Loss: 0.5231\n",
      "Epoch [8/50], Step [340/735], Loss: 0.3343\n",
      "Epoch [8/50], Step [341/735], Loss: 0.1682\n",
      "Epoch [8/50], Step [342/735], Loss: 0.1145\n",
      "Epoch [8/50], Step [343/735], Loss: 0.8845\n",
      "Epoch [8/50], Step [344/735], Loss: 0.0564\n",
      "Epoch [8/50], Step [345/735], Loss: 0.1600\n",
      "Epoch [8/50], Step [346/735], Loss: 0.1087\n",
      "Epoch [8/50], Step [347/735], Loss: 0.1562\n",
      "Epoch [8/50], Step [348/735], Loss: 0.3237\n",
      "Epoch [8/50], Step [349/735], Loss: 0.2890\n",
      "Epoch [8/50], Step [350/735], Loss: 0.1423\n",
      "Epoch [8/50], Step [351/735], Loss: 0.8124\n",
      "Epoch [8/50], Step [352/735], Loss: 0.5222\n",
      "Epoch [8/50], Step [353/735], Loss: 0.0860\n",
      "Epoch [8/50], Step [354/735], Loss: 0.2837\n",
      "Epoch [8/50], Step [355/735], Loss: 0.2817\n",
      "Epoch [8/50], Step [356/735], Loss: 0.0900\n",
      "Epoch [8/50], Step [357/735], Loss: 0.0805\n",
      "Epoch [8/50], Step [358/735], Loss: 0.1243\n",
      "Epoch [8/50], Step [359/735], Loss: 1.1484\n",
      "Epoch [8/50], Step [360/735], Loss: 0.0749\n",
      "Epoch [8/50], Step [361/735], Loss: 0.3517\n",
      "Epoch [8/50], Step [362/735], Loss: 0.1947\n",
      "Epoch [8/50], Step [363/735], Loss: 0.0702\n",
      "Epoch [8/50], Step [364/735], Loss: 0.1634\n",
      "Epoch [8/50], Step [365/735], Loss: 0.1214\n",
      "Epoch [8/50], Step [366/735], Loss: 0.0999\n",
      "Epoch [8/50], Step [367/735], Loss: 0.1163\n",
      "Epoch [8/50], Step [368/735], Loss: 0.1088\n",
      "Epoch [8/50], Step [369/735], Loss: 0.1252\n",
      "Epoch [8/50], Step [370/735], Loss: 0.3803\n",
      "Epoch [8/50], Step [371/735], Loss: 0.0977\n",
      "Epoch [8/50], Step [372/735], Loss: 0.1434\n",
      "Epoch [8/50], Step [373/735], Loss: 0.0917\n",
      "Epoch [8/50], Step [374/735], Loss: 0.2311\n",
      "Epoch [8/50], Step [375/735], Loss: 0.1370\n",
      "Epoch [8/50], Step [376/735], Loss: 0.2439\n",
      "Epoch [8/50], Step [377/735], Loss: 0.0950\n",
      "Epoch [8/50], Step [378/735], Loss: 0.3767\n",
      "Epoch [8/50], Step [379/735], Loss: 0.1125\n",
      "Epoch [8/50], Step [380/735], Loss: 0.2104\n",
      "Epoch [8/50], Step [381/735], Loss: 0.2234\n",
      "Epoch [8/50], Step [382/735], Loss: 0.1163\n",
      "Epoch [8/50], Step [383/735], Loss: 0.2533\n",
      "Epoch [8/50], Step [384/735], Loss: 0.1070\n",
      "Epoch [8/50], Step [385/735], Loss: 0.3245\n",
      "Epoch [8/50], Step [386/735], Loss: 0.0599\n",
      "Epoch [8/50], Step [387/735], Loss: 0.0541\n",
      "Epoch [8/50], Step [388/735], Loss: 0.1608\n",
      "Epoch [8/50], Step [389/735], Loss: 0.1795\n",
      "Epoch [8/50], Step [390/735], Loss: 0.3120\n",
      "Epoch [8/50], Step [391/735], Loss: 0.1431\n",
      "Epoch [8/50], Step [392/735], Loss: 0.1261\n",
      "Epoch [8/50], Step [393/735], Loss: 0.4991\n",
      "Epoch [8/50], Step [394/735], Loss: 1.4463\n",
      "Epoch [8/50], Step [395/735], Loss: 0.0978\n",
      "Epoch [8/50], Step [396/735], Loss: 0.0797\n",
      "Epoch [8/50], Step [397/735], Loss: 0.2098\n",
      "Epoch [8/50], Step [398/735], Loss: 0.6756\n",
      "Epoch [8/50], Step [399/735], Loss: 0.2998\n",
      "Epoch [8/50], Step [400/735], Loss: 0.2148\n",
      "Epoch [8/50], Step [401/735], Loss: 0.2453\n",
      "Epoch [8/50], Step [402/735], Loss: 0.2734\n",
      "Epoch [8/50], Step [403/735], Loss: 0.4716\n",
      "Epoch [8/50], Step [404/735], Loss: 0.0575\n",
      "Epoch [8/50], Step [405/735], Loss: 0.0821\n",
      "Epoch [8/50], Step [406/735], Loss: 0.1237\n",
      "Epoch [8/50], Step [407/735], Loss: 0.0753\n",
      "Epoch [8/50], Step [408/735], Loss: 0.1126\n",
      "Epoch [8/50], Step [409/735], Loss: 0.2039\n",
      "Epoch [8/50], Step [410/735], Loss: 0.0763\n",
      "Epoch [8/50], Step [411/735], Loss: 0.2054\n",
      "Epoch [8/50], Step [412/735], Loss: 2.1268\n",
      "Epoch [8/50], Step [413/735], Loss: 0.1825\n",
      "Epoch [8/50], Step [414/735], Loss: 0.2296\n",
      "Epoch [8/50], Step [415/735], Loss: 0.0616\n",
      "Epoch [8/50], Step [416/735], Loss: 0.4450\n",
      "Epoch [8/50], Step [417/735], Loss: 0.1689\n",
      "Epoch [8/50], Step [418/735], Loss: 0.1630\n",
      "Epoch [8/50], Step [419/735], Loss: 2.0096\n",
      "Epoch [8/50], Step [420/735], Loss: 0.1668\n",
      "Epoch [8/50], Step [421/735], Loss: 0.1618\n",
      "Epoch [8/50], Step [422/735], Loss: 0.0662\n",
      "Epoch [8/50], Step [423/735], Loss: 0.1556\n",
      "Epoch [8/50], Step [424/735], Loss: 0.3482\n",
      "Epoch [8/50], Step [425/735], Loss: 0.9331\n",
      "Epoch [8/50], Step [426/735], Loss: 0.2226\n",
      "Epoch [8/50], Step [427/735], Loss: 0.0808\n",
      "Epoch [8/50], Step [428/735], Loss: 0.2868\n",
      "Epoch [8/50], Step [429/735], Loss: 0.5297\n",
      "Epoch [8/50], Step [430/735], Loss: 0.0916\n",
      "Epoch [8/50], Step [431/735], Loss: 0.3090\n",
      "Epoch [8/50], Step [432/735], Loss: 0.6324\n",
      "Epoch [8/50], Step [433/735], Loss: 0.3014\n",
      "Epoch [8/50], Step [434/735], Loss: 0.7723\n",
      "Epoch [8/50], Step [435/735], Loss: 0.2686\n",
      "Epoch [8/50], Step [436/735], Loss: 0.0859\n",
      "Epoch [8/50], Step [437/735], Loss: 0.0599\n",
      "Epoch [8/50], Step [438/735], Loss: 0.2720\n",
      "Epoch [8/50], Step [439/735], Loss: 0.1963\n",
      "Epoch [8/50], Step [440/735], Loss: 0.1303\n",
      "Epoch [8/50], Step [441/735], Loss: 0.0848\n",
      "Epoch [8/50], Step [442/735], Loss: 0.0879\n",
      "Epoch [8/50], Step [443/735], Loss: 0.3185\n",
      "Epoch [8/50], Step [444/735], Loss: 0.0508\n",
      "Epoch [8/50], Step [445/735], Loss: 0.4955\n",
      "Epoch [8/50], Step [446/735], Loss: 0.4072\n",
      "Epoch [8/50], Step [447/735], Loss: 0.9689\n",
      "Epoch [8/50], Step [448/735], Loss: 0.5160\n",
      "Epoch [8/50], Step [449/735], Loss: 0.0566\n",
      "Epoch [8/50], Step [450/735], Loss: 0.0605\n",
      "Epoch [8/50], Step [451/735], Loss: 0.0645\n",
      "Epoch [8/50], Step [452/735], Loss: 0.2470\n",
      "Epoch [8/50], Step [453/735], Loss: 0.2420\n",
      "Epoch [8/50], Step [454/735], Loss: 0.2140\n",
      "Epoch [8/50], Step [455/735], Loss: 0.2151\n",
      "Epoch [8/50], Step [456/735], Loss: 0.1773\n",
      "Epoch [8/50], Step [457/735], Loss: 0.0700\n",
      "Epoch [8/50], Step [458/735], Loss: 0.1940\n",
      "Epoch [8/50], Step [459/735], Loss: 0.1139\n",
      "Epoch [8/50], Step [460/735], Loss: 0.2064\n",
      "Epoch [8/50], Step [461/735], Loss: 0.0948\n",
      "Epoch [8/50], Step [462/735], Loss: 0.0777\n",
      "Epoch [8/50], Step [463/735], Loss: 0.1283\n",
      "Epoch [8/50], Step [464/735], Loss: 0.1139\n",
      "Epoch [8/50], Step [465/735], Loss: 0.1237\n",
      "Epoch [8/50], Step [466/735], Loss: 0.0773\n",
      "Epoch [8/50], Step [467/735], Loss: 0.7845\n",
      "Epoch [8/50], Step [468/735], Loss: 0.2367\n",
      "Epoch [8/50], Step [469/735], Loss: 0.2087\n",
      "Epoch [8/50], Step [470/735], Loss: 0.1404\n",
      "Epoch [8/50], Step [471/735], Loss: 0.1989\n",
      "Epoch [8/50], Step [472/735], Loss: 0.4118\n",
      "Epoch [8/50], Step [473/735], Loss: 0.2746\n",
      "Epoch [8/50], Step [474/735], Loss: 0.0984\n",
      "Epoch [8/50], Step [475/735], Loss: 0.7618\n",
      "Epoch [8/50], Step [476/735], Loss: 0.2784\n",
      "Epoch [8/50], Step [477/735], Loss: 0.3736\n",
      "Epoch [8/50], Step [478/735], Loss: 0.4338\n",
      "Epoch [8/50], Step [479/735], Loss: 0.0968\n",
      "Epoch [8/50], Step [480/735], Loss: 0.1251\n",
      "Epoch [8/50], Step [481/735], Loss: 0.1968\n",
      "Epoch [8/50], Step [482/735], Loss: 1.7547\n",
      "Epoch [8/50], Step [483/735], Loss: 0.2385\n",
      "Epoch [8/50], Step [484/735], Loss: 0.2492\n",
      "Epoch [8/50], Step [485/735], Loss: 0.3777\n",
      "Epoch [8/50], Step [486/735], Loss: 0.3545\n",
      "Epoch [8/50], Step [487/735], Loss: 0.8581\n",
      "Epoch [8/50], Step [488/735], Loss: 0.0971\n",
      "Epoch [8/50], Step [489/735], Loss: 0.1787\n",
      "Epoch [8/50], Step [490/735], Loss: 0.2831\n",
      "Epoch [8/50], Step [491/735], Loss: 0.0666\n",
      "Epoch [8/50], Step [492/735], Loss: 0.2346\n",
      "Epoch [8/50], Step [493/735], Loss: 0.2188\n",
      "Epoch [8/50], Step [494/735], Loss: 0.2394\n",
      "Epoch [8/50], Step [495/735], Loss: 0.3405\n",
      "Epoch [8/50], Step [496/735], Loss: 0.2422\n",
      "Epoch [8/50], Step [497/735], Loss: 0.1611\n",
      "Epoch [8/50], Step [498/735], Loss: 0.1570\n",
      "Epoch [8/50], Step [499/735], Loss: 0.3812\n",
      "Epoch [8/50], Step [500/735], Loss: 0.0867\n",
      "Epoch [8/50], Step [501/735], Loss: 0.2310\n",
      "Epoch [8/50], Step [502/735], Loss: 0.2931\n",
      "Epoch [8/50], Step [503/735], Loss: 0.1215\n",
      "Epoch [8/50], Step [504/735], Loss: 0.1495\n",
      "Epoch [8/50], Step [505/735], Loss: 0.1622\n",
      "Epoch [8/50], Step [506/735], Loss: 0.0987\n",
      "Epoch [8/50], Step [507/735], Loss: 0.2075\n",
      "Epoch [8/50], Step [508/735], Loss: 0.3752\n",
      "Epoch [8/50], Step [509/735], Loss: 0.3082\n",
      "Epoch [8/50], Step [510/735], Loss: 0.5292\n",
      "Epoch [8/50], Step [511/735], Loss: 0.2223\n",
      "Epoch [8/50], Step [512/735], Loss: 0.1051\n",
      "Epoch [8/50], Step [513/735], Loss: 0.1716\n",
      "Epoch [8/50], Step [514/735], Loss: 0.3450\n",
      "Epoch [8/50], Step [515/735], Loss: 0.2303\n",
      "Epoch [8/50], Step [516/735], Loss: 0.1067\n",
      "Epoch [8/50], Step [517/735], Loss: 0.2651\n",
      "Epoch [8/50], Step [518/735], Loss: 0.3657\n",
      "Epoch [8/50], Step [519/735], Loss: 0.1311\n",
      "Epoch [8/50], Step [520/735], Loss: 0.2578\n",
      "Epoch [8/50], Step [521/735], Loss: 0.2835\n",
      "Epoch [8/50], Step [522/735], Loss: 0.0639\n",
      "Epoch [8/50], Step [523/735], Loss: 0.1938\n",
      "Epoch [8/50], Step [524/735], Loss: 0.0704\n",
      "Epoch [8/50], Step [525/735], Loss: 0.4268\n",
      "Epoch [8/50], Step [526/735], Loss: 0.3090\n",
      "Epoch [8/50], Step [527/735], Loss: 0.4479\n",
      "Epoch [8/50], Step [528/735], Loss: 0.2733\n",
      "Epoch [8/50], Step [529/735], Loss: 0.3995\n",
      "Epoch [8/50], Step [530/735], Loss: 0.1863\n",
      "Epoch [8/50], Step [531/735], Loss: 0.0809\n",
      "Epoch [8/50], Step [532/735], Loss: 0.6200\n",
      "Epoch [8/50], Step [533/735], Loss: 0.5187\n",
      "Epoch [8/50], Step [534/735], Loss: 0.3056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Step [535/735], Loss: 0.0987\n",
      "Epoch [8/50], Step [536/735], Loss: 0.0731\n",
      "Epoch [8/50], Step [537/735], Loss: 0.1580\n",
      "Epoch [8/50], Step [538/735], Loss: 0.1939\n",
      "Epoch [8/50], Step [539/735], Loss: 0.2630\n",
      "Epoch [8/50], Step [540/735], Loss: 0.1347\n",
      "Epoch [8/50], Step [541/735], Loss: 0.3290\n",
      "Epoch [8/50], Step [542/735], Loss: 0.1031\n",
      "Epoch [8/50], Step [543/735], Loss: 0.1736\n",
      "Epoch [8/50], Step [544/735], Loss: 0.2785\n",
      "Epoch [8/50], Step [545/735], Loss: 0.1401\n",
      "Epoch [8/50], Step [546/735], Loss: 0.0572\n",
      "Epoch [8/50], Step [547/735], Loss: 0.0598\n",
      "Epoch [8/50], Step [548/735], Loss: 0.1986\n",
      "Epoch [8/50], Step [549/735], Loss: 0.0786\n",
      "Epoch [8/50], Step [550/735], Loss: 0.2439\n",
      "Epoch [8/50], Step [551/735], Loss: 0.2504\n",
      "Epoch [8/50], Step [552/735], Loss: 0.1445\n",
      "Epoch [8/50], Step [553/735], Loss: 0.2306\n",
      "Epoch [8/50], Step [554/735], Loss: 0.2185\n",
      "Epoch [8/50], Step [555/735], Loss: 0.0658\n",
      "Epoch [8/50], Step [556/735], Loss: 0.1406\n",
      "Epoch [8/50], Step [557/735], Loss: 0.1129\n",
      "Epoch [8/50], Step [558/735], Loss: 0.1159\n",
      "Epoch [8/50], Step [559/735], Loss: 0.0850\n",
      "Epoch [8/50], Step [560/735], Loss: 0.1397\n",
      "Epoch [8/50], Step [561/735], Loss: 0.2573\n",
      "Epoch [8/50], Step [562/735], Loss: 0.4322\n",
      "Epoch [8/50], Step [563/735], Loss: 0.0860\n",
      "Epoch [8/50], Step [564/735], Loss: 0.4529\n",
      "Epoch [8/50], Step [565/735], Loss: 0.1355\n",
      "Epoch [8/50], Step [566/735], Loss: 0.1901\n",
      "Epoch [8/50], Step [567/735], Loss: 0.6551\n",
      "Epoch [8/50], Step [568/735], Loss: 0.0778\n",
      "Epoch [8/50], Step [569/735], Loss: 0.2194\n",
      "Epoch [8/50], Step [570/735], Loss: 0.1082\n",
      "Epoch [8/50], Step [571/735], Loss: 0.0917\n",
      "Epoch [8/50], Step [572/735], Loss: 0.3422\n",
      "Epoch [8/50], Step [573/735], Loss: 0.1204\n",
      "Epoch [8/50], Step [574/735], Loss: 0.1398\n",
      "Epoch [8/50], Step [575/735], Loss: 0.1360\n",
      "Epoch [8/50], Step [576/735], Loss: 0.1345\n",
      "Epoch [8/50], Step [577/735], Loss: 0.0962\n",
      "Epoch [8/50], Step [578/735], Loss: 0.2055\n",
      "Epoch [8/50], Step [579/735], Loss: 0.1642\n",
      "Epoch [8/50], Step [580/735], Loss: 0.2135\n",
      "Epoch [8/50], Step [581/735], Loss: 0.0939\n",
      "Epoch [8/50], Step [582/735], Loss: 0.0631\n",
      "Epoch [8/50], Step [583/735], Loss: 0.0837\n",
      "Epoch [8/50], Step [584/735], Loss: 0.1056\n",
      "Epoch [8/50], Step [585/735], Loss: 0.0961\n",
      "Epoch [8/50], Step [586/735], Loss: 0.0952\n",
      "Epoch [8/50], Step [587/735], Loss: 0.0772\n",
      "Epoch [8/50], Step [588/735], Loss: 0.1494\n",
      "Epoch [8/50], Step [589/735], Loss: 0.1457\n",
      "Epoch [8/50], Step [590/735], Loss: 0.2773\n",
      "Epoch [8/50], Step [591/735], Loss: 0.1613\n",
      "Epoch [8/50], Step [592/735], Loss: 0.0907\n",
      "Epoch [8/50], Step [593/735], Loss: 0.1451\n",
      "Epoch [8/50], Step [594/735], Loss: 0.1357\n",
      "Epoch [8/50], Step [595/735], Loss: 0.3662\n",
      "Epoch [8/50], Step [596/735], Loss: 0.0831\n",
      "Epoch [8/50], Step [597/735], Loss: 0.0929\n",
      "Epoch [8/50], Step [598/735], Loss: 0.0510\n",
      "Epoch [8/50], Step [599/735], Loss: 0.5470\n",
      "Epoch [8/50], Step [600/735], Loss: 0.3377\n",
      "Epoch [8/50], Step [601/735], Loss: 0.1683\n",
      "Epoch [8/50], Step [602/735], Loss: 0.6630\n",
      "Epoch [8/50], Step [603/735], Loss: 0.4187\n",
      "Epoch [8/50], Step [604/735], Loss: 1.2429\n",
      "Epoch [8/50], Step [605/735], Loss: 1.7934\n",
      "Epoch [8/50], Step [606/735], Loss: 0.2344\n",
      "Epoch [8/50], Step [607/735], Loss: 0.0755\n",
      "Epoch [8/50], Step [608/735], Loss: 1.4029\n",
      "Epoch [8/50], Step [609/735], Loss: 0.5010\n",
      "Epoch [8/50], Step [610/735], Loss: 0.0837\n",
      "Epoch [8/50], Step [611/735], Loss: 0.2830\n",
      "Epoch [8/50], Step [612/735], Loss: 0.0498\n",
      "Epoch [8/50], Step [613/735], Loss: 0.1247\n",
      "Epoch [8/50], Step [614/735], Loss: 0.7025\n",
      "Epoch [8/50], Step [615/735], Loss: 0.2128\n",
      "Epoch [8/50], Step [616/735], Loss: 0.1951\n",
      "Epoch [8/50], Step [617/735], Loss: 0.0601\n",
      "Epoch [8/50], Step [618/735], Loss: 0.2694\n",
      "Epoch [8/50], Step [619/735], Loss: 0.2420\n",
      "Epoch [8/50], Step [620/735], Loss: 0.1577\n",
      "Epoch [8/50], Step [621/735], Loss: 0.1025\n",
      "Epoch [8/50], Step [622/735], Loss: 0.3071\n",
      "Epoch [8/50], Step [623/735], Loss: 0.1520\n",
      "Epoch [8/50], Step [624/735], Loss: 0.4835\n",
      "Epoch [8/50], Step [625/735], Loss: 0.1290\n",
      "Epoch [8/50], Step [626/735], Loss: 0.2483\n",
      "Epoch [8/50], Step [627/735], Loss: 0.2316\n",
      "Epoch [8/50], Step [628/735], Loss: 0.1862\n",
      "Epoch [8/50], Step [629/735], Loss: 0.0928\n",
      "Epoch [8/50], Step [630/735], Loss: 0.1900\n",
      "Epoch [8/50], Step [631/735], Loss: 0.2986\n",
      "Epoch [8/50], Step [632/735], Loss: 0.3252\n",
      "Epoch [8/50], Step [633/735], Loss: 0.1370\n",
      "Epoch [8/50], Step [634/735], Loss: 0.2359\n",
      "Epoch [8/50], Step [635/735], Loss: 0.0971\n",
      "Epoch [8/50], Step [636/735], Loss: 0.3222\n",
      "Epoch [8/50], Step [637/735], Loss: 0.2882\n",
      "Epoch [8/50], Step [638/735], Loss: 0.5385\n",
      "Epoch [8/50], Step [639/735], Loss: 0.3087\n",
      "Epoch [8/50], Step [640/735], Loss: 0.1077\n",
      "Epoch [8/50], Step [641/735], Loss: 0.2309\n",
      "Epoch [8/50], Step [642/735], Loss: 0.2138\n",
      "Epoch [8/50], Step [643/735], Loss: 1.5267\n",
      "Epoch [8/50], Step [644/735], Loss: 0.3812\n",
      "Epoch [8/50], Step [645/735], Loss: 0.0699\n",
      "Epoch [8/50], Step [646/735], Loss: 0.3556\n",
      "Epoch [8/50], Step [647/735], Loss: 0.1332\n",
      "Epoch [8/50], Step [648/735], Loss: 0.4652\n",
      "Epoch [8/50], Step [649/735], Loss: 0.3864\n",
      "Epoch [8/50], Step [650/735], Loss: 0.2841\n",
      "Epoch [8/50], Step [651/735], Loss: 0.1614\n",
      "Epoch [8/50], Step [652/735], Loss: 0.3065\n",
      "Epoch [8/50], Step [653/735], Loss: 0.1664\n",
      "Epoch [8/50], Step [654/735], Loss: 0.1118\n",
      "Epoch [8/50], Step [655/735], Loss: 0.1372\n",
      "Epoch [8/50], Step [656/735], Loss: 0.2319\n",
      "Epoch [8/50], Step [657/735], Loss: 0.1735\n",
      "Epoch [8/50], Step [658/735], Loss: 0.2560\n",
      "Epoch [8/50], Step [659/735], Loss: 0.1104\n",
      "Epoch [8/50], Step [660/735], Loss: 0.1499\n",
      "Epoch [8/50], Step [661/735], Loss: 0.2856\n",
      "Epoch [8/50], Step [662/735], Loss: 0.1432\n",
      "Epoch [8/50], Step [663/735], Loss: 0.1132\n",
      "Epoch [8/50], Step [664/735], Loss: 0.0860\n",
      "Epoch [8/50], Step [665/735], Loss: 0.0841\n",
      "Epoch [8/50], Step [666/735], Loss: 0.1632\n",
      "Epoch [8/50], Step [667/735], Loss: 0.8102\n",
      "Epoch [8/50], Step [668/735], Loss: 0.2557\n",
      "Epoch [8/50], Step [669/735], Loss: 0.1005\n",
      "Epoch [8/50], Step [670/735], Loss: 0.1830\n",
      "Epoch [8/50], Step [671/735], Loss: 0.8174\n",
      "Epoch [8/50], Step [672/735], Loss: 0.3704\n",
      "Epoch [8/50], Step [673/735], Loss: 0.1113\n",
      "Epoch [8/50], Step [674/735], Loss: 0.1010\n",
      "Epoch [8/50], Step [675/735], Loss: 0.1428\n",
      "Epoch [8/50], Step [676/735], Loss: 0.1851\n",
      "Epoch [8/50], Step [677/735], Loss: 0.1646\n",
      "Epoch [8/50], Step [678/735], Loss: 0.0577\n",
      "Epoch [8/50], Step [679/735], Loss: 0.2688\n",
      "Epoch [8/50], Step [680/735], Loss: 0.0582\n",
      "Epoch [8/50], Step [681/735], Loss: 0.1310\n",
      "Epoch [8/50], Step [682/735], Loss: 0.1920\n",
      "Epoch [8/50], Step [683/735], Loss: 0.0947\n",
      "Epoch [8/50], Step [684/735], Loss: 0.1898\n",
      "Epoch [8/50], Step [685/735], Loss: 0.2372\n",
      "Epoch [8/50], Step [686/735], Loss: 0.0777\n",
      "Epoch [8/50], Step [687/735], Loss: 0.1376\n",
      "Epoch [8/50], Step [688/735], Loss: 0.3830\n",
      "Epoch [8/50], Step [689/735], Loss: 0.1386\n",
      "Epoch [8/50], Step [690/735], Loss: 0.1135\n",
      "Epoch [8/50], Step [691/735], Loss: 0.1513\n",
      "Epoch [8/50], Step [692/735], Loss: 0.4315\n",
      "Epoch [8/50], Step [693/735], Loss: 0.1488\n",
      "Epoch [8/50], Step [694/735], Loss: 0.5529\n",
      "Epoch [8/50], Step [695/735], Loss: 0.7045\n",
      "Epoch [8/50], Step [696/735], Loss: 0.1676\n",
      "Epoch [8/50], Step [697/735], Loss: 0.2026\n",
      "Epoch [8/50], Step [698/735], Loss: 0.1809\n",
      "Epoch [8/50], Step [699/735], Loss: 0.2078\n",
      "Epoch [8/50], Step [700/735], Loss: 0.0987\n",
      "Epoch [8/50], Step [701/735], Loss: 0.4318\n",
      "Epoch [8/50], Step [702/735], Loss: 0.2719\n",
      "Epoch [8/50], Step [703/735], Loss: 0.2209\n",
      "Epoch [8/50], Step [704/735], Loss: 0.1832\n",
      "Epoch [8/50], Step [705/735], Loss: 0.1467\n",
      "Epoch [8/50], Step [706/735], Loss: 0.2298\n",
      "Epoch [8/50], Step [707/735], Loss: 0.2135\n",
      "Epoch [8/50], Step [708/735], Loss: 0.1230\n",
      "Epoch [8/50], Step [709/735], Loss: 0.1156\n",
      "Epoch [8/50], Step [710/735], Loss: 0.1350\n",
      "Epoch [8/50], Step [711/735], Loss: 0.1424\n",
      "Epoch [8/50], Step [712/735], Loss: 0.1650\n",
      "Epoch [8/50], Step [713/735], Loss: 0.2048\n",
      "Epoch [8/50], Step [714/735], Loss: 0.0749\n",
      "Epoch [8/50], Step [715/735], Loss: 0.1250\n",
      "Epoch [8/50], Step [716/735], Loss: 0.2414\n",
      "Epoch [8/50], Step [717/735], Loss: 0.0857\n",
      "Epoch [8/50], Step [718/735], Loss: 0.0681\n",
      "Epoch [8/50], Step [719/735], Loss: 0.2201\n",
      "Epoch [8/50], Step [720/735], Loss: 0.0637\n",
      "Epoch [8/50], Step [721/735], Loss: 0.0767\n",
      "Epoch [8/50], Step [722/735], Loss: 0.0970\n",
      "Epoch [8/50], Step [723/735], Loss: 0.1428\n",
      "Epoch [8/50], Step [724/735], Loss: 0.1177\n",
      "Epoch [8/50], Step [725/735], Loss: 0.1240\n",
      "Epoch [8/50], Step [726/735], Loss: 0.1275\n",
      "Epoch [8/50], Step [727/735], Loss: 0.1608\n",
      "Epoch [8/50], Step [728/735], Loss: 0.0683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Step [729/735], Loss: 0.1526\n",
      "Epoch [8/50], Step [730/735], Loss: 0.1444\n",
      "Epoch [8/50], Step [731/735], Loss: 0.1602\n",
      "Epoch [8/50], Step [732/735], Loss: 0.1565\n",
      "Epoch [8/50], Step [733/735], Loss: 0.3356\n",
      "Epoch [8/50], Step [734/735], Loss: 0.1001\n",
      "Epoch [8/50], Step [735/735], Loss: 0.0692\n",
      "Epoch [9/50], Step [1/735], Loss: 0.0369\n",
      "Epoch [9/50], Step [2/735], Loss: 0.1119\n",
      "Epoch [9/50], Step [3/735], Loss: 0.1499\n",
      "Epoch [9/50], Step [4/735], Loss: 0.2181\n",
      "Epoch [9/50], Step [5/735], Loss: 0.0798\n",
      "Epoch [9/50], Step [6/735], Loss: 0.2132\n",
      "Epoch [9/50], Step [7/735], Loss: 0.1763\n",
      "Epoch [9/50], Step [8/735], Loss: 0.1201\n",
      "Epoch [9/50], Step [9/735], Loss: 1.6311\n",
      "Epoch [9/50], Step [10/735], Loss: 0.1463\n",
      "Epoch [9/50], Step [11/735], Loss: 0.4315\n",
      "Epoch [9/50], Step [12/735], Loss: 0.1213\n",
      "Epoch [9/50], Step [13/735], Loss: 0.1905\n",
      "Epoch [9/50], Step [14/735], Loss: 0.2124\n",
      "Epoch [9/50], Step [15/735], Loss: 0.3948\n",
      "Epoch [9/50], Step [16/735], Loss: 0.4900\n",
      "Epoch [9/50], Step [17/735], Loss: 0.1109\n",
      "Epoch [9/50], Step [18/735], Loss: 1.0290\n",
      "Epoch [9/50], Step [19/735], Loss: 0.0846\n",
      "Epoch [9/50], Step [20/735], Loss: 0.2895\n",
      "Epoch [9/50], Step [21/735], Loss: 0.3702\n",
      "Epoch [9/50], Step [22/735], Loss: 0.3791\n",
      "Epoch [9/50], Step [23/735], Loss: 0.1428\n",
      "Epoch [9/50], Step [24/735], Loss: 2.7374\n",
      "Epoch [9/50], Step [25/735], Loss: 0.2097\n",
      "Epoch [9/50], Step [26/735], Loss: 0.7786\n",
      "Epoch [9/50], Step [27/735], Loss: 0.0698\n",
      "Epoch [9/50], Step [28/735], Loss: 0.1435\n",
      "Epoch [9/50], Step [29/735], Loss: 0.1300\n",
      "Epoch [9/50], Step [30/735], Loss: 0.2613\n",
      "Epoch [9/50], Step [31/735], Loss: 0.1681\n",
      "Epoch [9/50], Step [32/735], Loss: 0.1706\n",
      "Epoch [9/50], Step [33/735], Loss: 0.1902\n",
      "Epoch [9/50], Step [34/735], Loss: 0.0686\n",
      "Epoch [9/50], Step [35/735], Loss: 0.1057\n",
      "Epoch [9/50], Step [36/735], Loss: 0.1405\n",
      "Epoch [9/50], Step [37/735], Loss: 0.1408\n",
      "Epoch [9/50], Step [38/735], Loss: 0.0881\n",
      "Epoch [9/50], Step [39/735], Loss: 0.1314\n",
      "Epoch [9/50], Step [40/735], Loss: 0.0910\n",
      "Epoch [9/50], Step [41/735], Loss: 0.1558\n",
      "Epoch [9/50], Step [42/735], Loss: 0.3174\n",
      "Epoch [9/50], Step [43/735], Loss: 0.3583\n",
      "Epoch [9/50], Step [44/735], Loss: 0.1771\n",
      "Epoch [9/50], Step [45/735], Loss: 0.1602\n",
      "Epoch [9/50], Step [46/735], Loss: 0.1410\n",
      "Epoch [9/50], Step [47/735], Loss: 0.1289\n",
      "Epoch [9/50], Step [48/735], Loss: 0.2404\n",
      "Epoch [9/50], Step [49/735], Loss: 0.1068\n",
      "Epoch [9/50], Step [50/735], Loss: 0.0799\n",
      "Epoch [9/50], Step [51/735], Loss: 0.1233\n",
      "Epoch [9/50], Step [52/735], Loss: 0.1412\n",
      "Epoch [9/50], Step [53/735], Loss: 0.4830\n",
      "Epoch [9/50], Step [54/735], Loss: 0.4247\n",
      "Epoch [9/50], Step [55/735], Loss: 0.1657\n",
      "Epoch [9/50], Step [56/735], Loss: 0.2418\n",
      "Epoch [9/50], Step [57/735], Loss: 0.4222\n",
      "Epoch [9/50], Step [58/735], Loss: 0.1636\n",
      "Epoch [9/50], Step [59/735], Loss: 0.1277\n",
      "Epoch [9/50], Step [60/735], Loss: 0.3510\n",
      "Epoch [9/50], Step [61/735], Loss: 0.3227\n",
      "Epoch [9/50], Step [62/735], Loss: 0.1499\n",
      "Epoch [9/50], Step [63/735], Loss: 0.0657\n",
      "Epoch [9/50], Step [64/735], Loss: 0.2752\n",
      "Epoch [9/50], Step [65/735], Loss: 1.0448\n",
      "Epoch [9/50], Step [66/735], Loss: 1.1240\n",
      "Epoch [9/50], Step [67/735], Loss: 0.1609\n",
      "Epoch [9/50], Step [68/735], Loss: 0.1123\n",
      "Epoch [9/50], Step [69/735], Loss: 0.0677\n",
      "Epoch [9/50], Step [70/735], Loss: 0.2417\n",
      "Epoch [9/50], Step [71/735], Loss: 0.3001\n",
      "Epoch [9/50], Step [72/735], Loss: 0.2025\n",
      "Epoch [9/50], Step [73/735], Loss: 0.9625\n",
      "Epoch [9/50], Step [74/735], Loss: 0.1365\n",
      "Epoch [9/50], Step [75/735], Loss: 0.2493\n",
      "Epoch [9/50], Step [76/735], Loss: 0.2222\n",
      "Epoch [9/50], Step [77/735], Loss: 0.7079\n",
      "Epoch [9/50], Step [78/735], Loss: 0.0721\n",
      "Epoch [9/50], Step [79/735], Loss: 0.1719\n",
      "Epoch [9/50], Step [80/735], Loss: 0.1022\n",
      "Epoch [9/50], Step [81/735], Loss: 0.1381\n",
      "Epoch [9/50], Step [82/735], Loss: 0.1896\n",
      "Epoch [9/50], Step [83/735], Loss: 0.2712\n",
      "Epoch [9/50], Step [84/735], Loss: 0.1602\n",
      "Epoch [9/50], Step [85/735], Loss: 0.1103\n",
      "Epoch [9/50], Step [86/735], Loss: 0.1736\n",
      "Epoch [9/50], Step [87/735], Loss: 0.1149\n",
      "Epoch [9/50], Step [88/735], Loss: 0.5738\n",
      "Epoch [9/50], Step [89/735], Loss: 0.1691\n",
      "Epoch [9/50], Step [90/735], Loss: 0.1816\n",
      "Epoch [9/50], Step [91/735], Loss: 0.0660\n",
      "Epoch [9/50], Step [92/735], Loss: 0.1088\n",
      "Epoch [9/50], Step [93/735], Loss: 0.2576\n",
      "Epoch [9/50], Step [94/735], Loss: 0.1744\n",
      "Epoch [9/50], Step [95/735], Loss: 0.1949\n",
      "Epoch [9/50], Step [96/735], Loss: 0.1692\n",
      "Epoch [9/50], Step [97/735], Loss: 2.4840\n",
      "Epoch [9/50], Step [98/735], Loss: 0.1032\n",
      "Epoch [9/50], Step [99/735], Loss: 0.2644\n",
      "Epoch [9/50], Step [100/735], Loss: 0.3742\n",
      "Epoch [9/50], Step [101/735], Loss: 0.1353\n",
      "Epoch [9/50], Step [102/735], Loss: 0.1653\n",
      "Epoch [9/50], Step [103/735], Loss: 0.1061\n",
      "Epoch [9/50], Step [104/735], Loss: 0.1098\n",
      "Epoch [9/50], Step [105/735], Loss: 0.0788\n",
      "Epoch [9/50], Step [106/735], Loss: 0.0603\n",
      "Epoch [9/50], Step [107/735], Loss: 0.2337\n",
      "Epoch [9/50], Step [108/735], Loss: 0.5634\n",
      "Epoch [9/50], Step [109/735], Loss: 0.2770\n",
      "Epoch [9/50], Step [110/735], Loss: 0.6054\n",
      "Epoch [9/50], Step [111/735], Loss: 0.1889\n",
      "Epoch [9/50], Step [112/735], Loss: 0.2079\n",
      "Epoch [9/50], Step [113/735], Loss: 0.1774\n",
      "Epoch [9/50], Step [114/735], Loss: 0.1239\n",
      "Epoch [9/50], Step [115/735], Loss: 0.0522\n",
      "Epoch [9/50], Step [116/735], Loss: 0.0810\n",
      "Epoch [9/50], Step [117/735], Loss: 0.3719\n",
      "Epoch [9/50], Step [118/735], Loss: 0.0690\n",
      "Epoch [9/50], Step [119/735], Loss: 0.1673\n",
      "Epoch [9/50], Step [120/735], Loss: 0.1710\n",
      "Epoch [9/50], Step [121/735], Loss: 0.1548\n",
      "Epoch [9/50], Step [122/735], Loss: 0.1783\n",
      "Epoch [9/50], Step [123/735], Loss: 0.2693\n",
      "Epoch [9/50], Step [124/735], Loss: 0.3738\n",
      "Epoch [9/50], Step [125/735], Loss: 1.3871\n",
      "Epoch [9/50], Step [126/735], Loss: 0.3090\n",
      "Epoch [9/50], Step [127/735], Loss: 0.1250\n",
      "Epoch [9/50], Step [128/735], Loss: 0.1123\n",
      "Epoch [9/50], Step [129/735], Loss: 0.1914\n",
      "Epoch [9/50], Step [130/735], Loss: 0.2785\n",
      "Epoch [9/50], Step [131/735], Loss: 0.1426\n",
      "Epoch [9/50], Step [132/735], Loss: 0.2153\n",
      "Epoch [9/50], Step [133/735], Loss: 0.2785\n",
      "Epoch [9/50], Step [134/735], Loss: 0.3848\n",
      "Epoch [9/50], Step [135/735], Loss: 0.1668\n",
      "Epoch [9/50], Step [136/735], Loss: 0.2582\n",
      "Epoch [9/50], Step [137/735], Loss: 0.3274\n",
      "Epoch [9/50], Step [138/735], Loss: 0.3056\n",
      "Epoch [9/50], Step [139/735], Loss: 0.4394\n",
      "Epoch [9/50], Step [140/735], Loss: 0.1176\n",
      "Epoch [9/50], Step [141/735], Loss: 0.0530\n",
      "Epoch [9/50], Step [142/735], Loss: 0.1354\n",
      "Epoch [9/50], Step [143/735], Loss: 0.4415\n",
      "Epoch [9/50], Step [144/735], Loss: 0.1992\n",
      "Epoch [9/50], Step [145/735], Loss: 0.2636\n",
      "Epoch [9/50], Step [146/735], Loss: 0.1652\n",
      "Epoch [9/50], Step [147/735], Loss: 0.1602\n",
      "Epoch [9/50], Step [148/735], Loss: 0.1691\n",
      "Epoch [9/50], Step [149/735], Loss: 0.1250\n",
      "Epoch [9/50], Step [150/735], Loss: 0.3734\n",
      "Epoch [9/50], Step [151/735], Loss: 0.7088\n",
      "Epoch [9/50], Step [152/735], Loss: 0.0542\n",
      "Epoch [9/50], Step [153/735], Loss: 0.1750\n",
      "Epoch [9/50], Step [154/735], Loss: 0.1192\n",
      "Epoch [9/50], Step [155/735], Loss: 0.0954\n",
      "Epoch [9/50], Step [156/735], Loss: 0.1226\n",
      "Epoch [9/50], Step [157/735], Loss: 0.2258\n",
      "Epoch [9/50], Step [158/735], Loss: 0.1322\n",
      "Epoch [9/50], Step [159/735], Loss: 0.3814\n",
      "Epoch [9/50], Step [160/735], Loss: 0.1393\n",
      "Epoch [9/50], Step [161/735], Loss: 0.0677\n",
      "Epoch [9/50], Step [162/735], Loss: 0.0678\n",
      "Epoch [9/50], Step [163/735], Loss: 0.1075\n",
      "Epoch [9/50], Step [164/735], Loss: 0.0921\n",
      "Epoch [9/50], Step [165/735], Loss: 0.1204\n",
      "Epoch [9/50], Step [166/735], Loss: 0.1359\n",
      "Epoch [9/50], Step [167/735], Loss: 0.1248\n",
      "Epoch [9/50], Step [168/735], Loss: 0.0365\n",
      "Epoch [9/50], Step [169/735], Loss: 0.3289\n",
      "Epoch [9/50], Step [170/735], Loss: 0.0619\n",
      "Epoch [9/50], Step [171/735], Loss: 0.1701\n",
      "Epoch [9/50], Step [172/735], Loss: 0.0426\n",
      "Epoch [9/50], Step [173/735], Loss: 0.4248\n",
      "Epoch [9/50], Step [174/735], Loss: 0.0945\n",
      "Epoch [9/50], Step [175/735], Loss: 0.3312\n",
      "Epoch [9/50], Step [176/735], Loss: 0.2536\n",
      "Epoch [9/50], Step [177/735], Loss: 0.1916\n",
      "Epoch [9/50], Step [178/735], Loss: 0.1748\n",
      "Epoch [9/50], Step [179/735], Loss: 0.2278\n",
      "Epoch [9/50], Step [180/735], Loss: 0.2232\n",
      "Epoch [9/50], Step [181/735], Loss: 0.0817\n",
      "Epoch [9/50], Step [182/735], Loss: 0.1920\n",
      "Epoch [9/50], Step [183/735], Loss: 0.0706\n",
      "Epoch [9/50], Step [184/735], Loss: 0.1809\n",
      "Epoch [9/50], Step [185/735], Loss: 0.1552\n",
      "Epoch [9/50], Step [186/735], Loss: 0.1093\n",
      "Epoch [9/50], Step [187/735], Loss: 0.1615\n",
      "Epoch [9/50], Step [188/735], Loss: 0.0853\n",
      "Epoch [9/50], Step [189/735], Loss: 0.3849\n",
      "Epoch [9/50], Step [190/735], Loss: 0.3406\n",
      "Epoch [9/50], Step [191/735], Loss: 0.1726\n",
      "Epoch [9/50], Step [192/735], Loss: 0.4907\n",
      "Epoch [9/50], Step [193/735], Loss: 0.0612\n",
      "Epoch [9/50], Step [194/735], Loss: 0.1104\n",
      "Epoch [9/50], Step [195/735], Loss: 0.0877\n",
      "Epoch [9/50], Step [196/735], Loss: 0.0836\n",
      "Epoch [9/50], Step [197/735], Loss: 0.0677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Step [198/735], Loss: 0.2398\n",
      "Epoch [9/50], Step [199/735], Loss: 0.3247\n",
      "Epoch [9/50], Step [200/735], Loss: 0.1436\n",
      "Epoch [9/50], Step [201/735], Loss: 0.2870\n",
      "Epoch [9/50], Step [202/735], Loss: 0.1286\n",
      "Epoch [9/50], Step [203/735], Loss: 0.1002\n",
      "Epoch [9/50], Step [204/735], Loss: 0.0915\n",
      "Epoch [9/50], Step [205/735], Loss: 0.2043\n",
      "Epoch [9/50], Step [206/735], Loss: 0.2067\n",
      "Epoch [9/50], Step [207/735], Loss: 0.0538\n",
      "Epoch [9/50], Step [208/735], Loss: 0.1896\n",
      "Epoch [9/50], Step [209/735], Loss: 0.2216\n",
      "Epoch [9/50], Step [210/735], Loss: 0.1547\n",
      "Epoch [9/50], Step [211/735], Loss: 0.1584\n",
      "Epoch [9/50], Step [212/735], Loss: 0.1292\n",
      "Epoch [9/50], Step [213/735], Loss: 0.0974\n",
      "Epoch [9/50], Step [214/735], Loss: 0.1192\n",
      "Epoch [9/50], Step [215/735], Loss: 0.1581\n",
      "Epoch [9/50], Step [216/735], Loss: 0.6212\n",
      "Epoch [9/50], Step [217/735], Loss: 0.1242\n",
      "Epoch [9/50], Step [218/735], Loss: 0.1132\n",
      "Epoch [9/50], Step [219/735], Loss: 0.5854\n",
      "Epoch [9/50], Step [220/735], Loss: 0.1554\n",
      "Epoch [9/50], Step [221/735], Loss: 0.1026\n",
      "Epoch [9/50], Step [222/735], Loss: 0.1920\n",
      "Epoch [9/50], Step [223/735], Loss: 0.3940\n",
      "Epoch [9/50], Step [224/735], Loss: 0.1753\n",
      "Epoch [9/50], Step [225/735], Loss: 0.3944\n",
      "Epoch [9/50], Step [226/735], Loss: 0.4751\n",
      "Epoch [9/50], Step [227/735], Loss: 0.3662\n",
      "Epoch [9/50], Step [228/735], Loss: 0.1477\n",
      "Epoch [9/50], Step [229/735], Loss: 0.1326\n",
      "Epoch [9/50], Step [230/735], Loss: 0.1659\n",
      "Epoch [9/50], Step [231/735], Loss: 0.2093\n",
      "Epoch [9/50], Step [232/735], Loss: 0.1080\n",
      "Epoch [9/50], Step [233/735], Loss: 0.1680\n",
      "Epoch [9/50], Step [234/735], Loss: 0.1462\n",
      "Epoch [9/50], Step [235/735], Loss: 0.2644\n",
      "Epoch [9/50], Step [236/735], Loss: 0.1501\n",
      "Epoch [9/50], Step [237/735], Loss: 0.1190\n",
      "Epoch [9/50], Step [238/735], Loss: 0.2996\n",
      "Epoch [9/50], Step [239/735], Loss: 0.1197\n",
      "Epoch [9/50], Step [240/735], Loss: 0.0462\n",
      "Epoch [9/50], Step [241/735], Loss: 0.1438\n",
      "Epoch [9/50], Step [242/735], Loss: 0.5521\n",
      "Epoch [9/50], Step [243/735], Loss: 1.3168\n",
      "Epoch [9/50], Step [244/735], Loss: 0.1298\n",
      "Epoch [9/50], Step [245/735], Loss: 0.1543\n",
      "Epoch [9/50], Step [246/735], Loss: 0.7936\n",
      "Epoch [9/50], Step [247/735], Loss: 0.2892\n",
      "Epoch [9/50], Step [248/735], Loss: 0.1025\n",
      "Epoch [9/50], Step [249/735], Loss: 0.3211\n",
      "Epoch [9/50], Step [250/735], Loss: 0.1005\n",
      "Epoch [9/50], Step [251/735], Loss: 0.3799\n",
      "Epoch [9/50], Step [252/735], Loss: 0.7687\n",
      "Epoch [9/50], Step [253/735], Loss: 0.1263\n",
      "Epoch [9/50], Step [254/735], Loss: 0.7422\n",
      "Epoch [9/50], Step [255/735], Loss: 0.2749\n",
      "Epoch [9/50], Step [256/735], Loss: 0.3219\n",
      "Epoch [9/50], Step [257/735], Loss: 0.3084\n",
      "Epoch [9/50], Step [258/735], Loss: 0.0628\n",
      "Epoch [9/50], Step [259/735], Loss: 0.2052\n",
      "Epoch [9/50], Step [260/735], Loss: 0.1993\n",
      "Epoch [9/50], Step [261/735], Loss: 0.1207\n",
      "Epoch [9/50], Step [262/735], Loss: 0.1125\n",
      "Epoch [9/50], Step [263/735], Loss: 1.0816\n",
      "Epoch [9/50], Step [264/735], Loss: 0.2786\n",
      "Epoch [9/50], Step [265/735], Loss: 0.1959\n",
      "Epoch [9/50], Step [266/735], Loss: 0.0931\n",
      "Epoch [9/50], Step [267/735], Loss: 0.2947\n",
      "Epoch [9/50], Step [268/735], Loss: 0.1610\n",
      "Epoch [9/50], Step [269/735], Loss: 0.1289\n",
      "Epoch [9/50], Step [270/735], Loss: 0.0878\n",
      "Epoch [9/50], Step [271/735], Loss: 0.1448\n",
      "Epoch [9/50], Step [272/735], Loss: 0.1032\n",
      "Epoch [9/50], Step [273/735], Loss: 0.2246\n",
      "Epoch [9/50], Step [274/735], Loss: 0.0954\n",
      "Epoch [9/50], Step [275/735], Loss: 0.1002\n",
      "Epoch [9/50], Step [276/735], Loss: 0.2648\n",
      "Epoch [9/50], Step [277/735], Loss: 0.0614\n",
      "Epoch [9/50], Step [278/735], Loss: 0.1659\n",
      "Epoch [9/50], Step [279/735], Loss: 0.1220\n",
      "Epoch [9/50], Step [280/735], Loss: 0.3831\n",
      "Epoch [9/50], Step [281/735], Loss: 0.1194\n",
      "Epoch [9/50], Step [282/735], Loss: 0.1645\n",
      "Epoch [9/50], Step [283/735], Loss: 0.0834\n",
      "Epoch [9/50], Step [284/735], Loss: 0.1249\n",
      "Epoch [9/50], Step [285/735], Loss: 0.2108\n",
      "Epoch [9/50], Step [286/735], Loss: 0.1168\n",
      "Epoch [9/50], Step [287/735], Loss: 0.2420\n",
      "Epoch [9/50], Step [288/735], Loss: 0.3240\n",
      "Epoch [9/50], Step [289/735], Loss: 0.1842\n",
      "Epoch [9/50], Step [290/735], Loss: 0.2346\n",
      "Epoch [9/50], Step [291/735], Loss: 0.1554\n",
      "Epoch [9/50], Step [292/735], Loss: 0.5878\n",
      "Epoch [9/50], Step [293/735], Loss: 0.1292\n",
      "Epoch [9/50], Step [294/735], Loss: 0.1135\n",
      "Epoch [9/50], Step [295/735], Loss: 0.1112\n",
      "Epoch [9/50], Step [296/735], Loss: 0.1125\n",
      "Epoch [9/50], Step [297/735], Loss: 0.1293\n",
      "Epoch [9/50], Step [298/735], Loss: 0.1402\n",
      "Epoch [9/50], Step [299/735], Loss: 0.1770\n",
      "Epoch [9/50], Step [300/735], Loss: 0.2267\n",
      "Epoch [9/50], Step [301/735], Loss: 0.4077\n",
      "Epoch [9/50], Step [302/735], Loss: 0.1732\n",
      "Epoch [9/50], Step [303/735], Loss: 0.1946\n",
      "Epoch [9/50], Step [304/735], Loss: 0.1525\n",
      "Epoch [9/50], Step [305/735], Loss: 0.2116\n",
      "Epoch [9/50], Step [306/735], Loss: 0.2772\n",
      "Epoch [9/50], Step [307/735], Loss: 0.1587\n",
      "Epoch [9/50], Step [308/735], Loss: 0.2661\n",
      "Epoch [9/50], Step [309/735], Loss: 0.1192\n",
      "Epoch [9/50], Step [310/735], Loss: 0.3114\n",
      "Epoch [9/50], Step [311/735], Loss: 0.1161\n",
      "Epoch [9/50], Step [312/735], Loss: 0.2216\n",
      "Epoch [9/50], Step [313/735], Loss: 0.2995\n",
      "Epoch [9/50], Step [314/735], Loss: 0.0558\n",
      "Epoch [9/50], Step [315/735], Loss: 0.0475\n",
      "Epoch [9/50], Step [316/735], Loss: 0.2772\n",
      "Epoch [9/50], Step [317/735], Loss: 0.9165\n",
      "Epoch [9/50], Step [318/735], Loss: 0.1779\n",
      "Epoch [9/50], Step [319/735], Loss: 0.6463\n",
      "Epoch [9/50], Step [320/735], Loss: 0.3353\n",
      "Epoch [9/50], Step [321/735], Loss: 0.6100\n",
      "Epoch [9/50], Step [322/735], Loss: 0.1495\n",
      "Epoch [9/50], Step [323/735], Loss: 0.1334\n",
      "Epoch [9/50], Step [324/735], Loss: 0.2480\n",
      "Epoch [9/50], Step [325/735], Loss: 0.1235\n",
      "Epoch [9/50], Step [326/735], Loss: 0.1543\n",
      "Epoch [9/50], Step [327/735], Loss: 0.1355\n",
      "Epoch [9/50], Step [328/735], Loss: 0.0812\n",
      "Epoch [9/50], Step [329/735], Loss: 0.1116\n",
      "Epoch [9/50], Step [330/735], Loss: 0.1168\n",
      "Epoch [9/50], Step [331/735], Loss: 0.1097\n",
      "Epoch [9/50], Step [332/735], Loss: 0.3786\n",
      "Epoch [9/50], Step [333/735], Loss: 0.1286\n",
      "Epoch [9/50], Step [334/735], Loss: 0.3401\n",
      "Epoch [9/50], Step [335/735], Loss: 0.1390\n",
      "Epoch [9/50], Step [336/735], Loss: 0.1945\n",
      "Epoch [9/50], Step [337/735], Loss: 0.1158\n",
      "Epoch [9/50], Step [338/735], Loss: 0.0544\n",
      "Epoch [9/50], Step [339/735], Loss: 0.1219\n",
      "Epoch [9/50], Step [340/735], Loss: 0.1222\n",
      "Epoch [9/50], Step [341/735], Loss: 0.1792\n",
      "Epoch [9/50], Step [342/735], Loss: 0.1529\n",
      "Epoch [9/50], Step [343/735], Loss: 0.2627\n",
      "Epoch [9/50], Step [344/735], Loss: 0.0677\n",
      "Epoch [9/50], Step [345/735], Loss: 0.1275\n",
      "Epoch [9/50], Step [346/735], Loss: 0.5982\n",
      "Epoch [9/50], Step [347/735], Loss: 0.1816\n",
      "Epoch [9/50], Step [348/735], Loss: 0.2279\n",
      "Epoch [9/50], Step [349/735], Loss: 0.2115\n",
      "Epoch [9/50], Step [350/735], Loss: 0.8544\n",
      "Epoch [9/50], Step [351/735], Loss: 0.3533\n",
      "Epoch [9/50], Step [352/735], Loss: 0.0951\n",
      "Epoch [9/50], Step [353/735], Loss: 0.1359\n",
      "Epoch [9/50], Step [354/735], Loss: 0.1295\n",
      "Epoch [9/50], Step [355/735], Loss: 0.3189\n",
      "Epoch [9/50], Step [356/735], Loss: 0.2075\n",
      "Epoch [9/50], Step [357/735], Loss: 0.1163\n",
      "Epoch [9/50], Step [358/735], Loss: 0.7390\n",
      "Epoch [9/50], Step [359/735], Loss: 0.2385\n",
      "Epoch [9/50], Step [360/735], Loss: 0.2814\n",
      "Epoch [9/50], Step [361/735], Loss: 0.1765\n",
      "Epoch [9/50], Step [362/735], Loss: 0.8684\n",
      "Epoch [9/50], Step [363/735], Loss: 0.1428\n",
      "Epoch [9/50], Step [364/735], Loss: 0.2045\n",
      "Epoch [9/50], Step [365/735], Loss: 0.2459\n",
      "Epoch [9/50], Step [366/735], Loss: 0.1434\n",
      "Epoch [9/50], Step [367/735], Loss: 0.1287\n",
      "Epoch [9/50], Step [368/735], Loss: 0.2084\n",
      "Epoch [9/50], Step [369/735], Loss: 0.2120\n",
      "Epoch [9/50], Step [370/735], Loss: 0.0990\n",
      "Epoch [9/50], Step [371/735], Loss: 0.2470\n",
      "Epoch [9/50], Step [372/735], Loss: 0.2086\n",
      "Epoch [9/50], Step [373/735], Loss: 0.1020\n",
      "Epoch [9/50], Step [374/735], Loss: 0.1897\n",
      "Epoch [9/50], Step [375/735], Loss: 0.4641\n",
      "Epoch [9/50], Step [376/735], Loss: 0.2417\n",
      "Epoch [9/50], Step [377/735], Loss: 0.1371\n",
      "Epoch [9/50], Step [378/735], Loss: 0.2875\n",
      "Epoch [9/50], Step [379/735], Loss: 0.4327\n",
      "Epoch [9/50], Step [380/735], Loss: 0.2682\n",
      "Epoch [9/50], Step [381/735], Loss: 0.2572\n",
      "Epoch [9/50], Step [382/735], Loss: 0.1990\n",
      "Epoch [9/50], Step [383/735], Loss: 0.1553\n",
      "Epoch [9/50], Step [384/735], Loss: 0.1347\n",
      "Epoch [9/50], Step [385/735], Loss: 0.1297\n",
      "Epoch [9/50], Step [386/735], Loss: 0.3048\n",
      "Epoch [9/50], Step [387/735], Loss: 0.2798\n",
      "Epoch [9/50], Step [388/735], Loss: 0.1221\n",
      "Epoch [9/50], Step [389/735], Loss: 0.2471\n",
      "Epoch [9/50], Step [390/735], Loss: 0.1607\n",
      "Epoch [9/50], Step [391/735], Loss: 0.0875\n",
      "Epoch [9/50], Step [392/735], Loss: 0.0950\n",
      "Epoch [9/50], Step [393/735], Loss: 0.2337\n",
      "Epoch [9/50], Step [394/735], Loss: 0.1580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Step [395/735], Loss: 0.3804\n",
      "Epoch [9/50], Step [396/735], Loss: 0.3732\n",
      "Epoch [9/50], Step [397/735], Loss: 0.1899\n",
      "Epoch [9/50], Step [398/735], Loss: 0.2060\n",
      "Epoch [9/50], Step [399/735], Loss: 0.3673\n",
      "Epoch [9/50], Step [400/735], Loss: 0.0963\n",
      "Epoch [9/50], Step [401/735], Loss: 0.0898\n",
      "Epoch [9/50], Step [402/735], Loss: 0.1687\n",
      "Epoch [9/50], Step [403/735], Loss: 0.1504\n",
      "Epoch [9/50], Step [404/735], Loss: 0.1750\n",
      "Epoch [9/50], Step [405/735], Loss: 0.2085\n",
      "Epoch [9/50], Step [406/735], Loss: 0.2495\n",
      "Epoch [9/50], Step [407/735], Loss: 0.1616\n",
      "Epoch [9/50], Step [408/735], Loss: 0.1126\n",
      "Epoch [9/50], Step [409/735], Loss: 0.1130\n",
      "Epoch [9/50], Step [410/735], Loss: 0.5997\n",
      "Epoch [9/50], Step [411/735], Loss: 0.1787\n",
      "Epoch [9/50], Step [412/735], Loss: 0.0773\n",
      "Epoch [9/50], Step [413/735], Loss: 0.0973\n",
      "Epoch [9/50], Step [414/735], Loss: 0.2691\n",
      "Epoch [9/50], Step [415/735], Loss: 0.1093\n",
      "Epoch [9/50], Step [416/735], Loss: 0.1352\n",
      "Epoch [9/50], Step [417/735], Loss: 0.1256\n",
      "Epoch [9/50], Step [418/735], Loss: 0.6134\n",
      "Epoch [9/50], Step [419/735], Loss: 0.1341\n",
      "Epoch [9/50], Step [420/735], Loss: 0.2267\n",
      "Epoch [9/50], Step [421/735], Loss: 0.1184\n",
      "Epoch [9/50], Step [422/735], Loss: 0.2139\n",
      "Epoch [9/50], Step [423/735], Loss: 0.2818\n",
      "Epoch [9/50], Step [424/735], Loss: 0.3195\n",
      "Epoch [9/50], Step [425/735], Loss: 0.1291\n",
      "Epoch [9/50], Step [426/735], Loss: 0.1808\n",
      "Epoch [9/50], Step [427/735], Loss: 0.1621\n",
      "Epoch [9/50], Step [428/735], Loss: 0.1770\n",
      "Epoch [9/50], Step [429/735], Loss: 0.1995\n",
      "Epoch [9/50], Step [430/735], Loss: 0.0717\n",
      "Epoch [9/50], Step [431/735], Loss: 0.0841\n",
      "Epoch [9/50], Step [432/735], Loss: 0.2080\n",
      "Epoch [9/50], Step [433/735], Loss: 0.0814\n",
      "Epoch [9/50], Step [434/735], Loss: 0.0668\n",
      "Epoch [9/50], Step [435/735], Loss: 0.6995\n",
      "Epoch [9/50], Step [436/735], Loss: 0.1401\n",
      "Epoch [9/50], Step [437/735], Loss: 0.1282\n",
      "Epoch [9/50], Step [438/735], Loss: 0.0966\n",
      "Epoch [9/50], Step [439/735], Loss: 0.0984\n",
      "Epoch [9/50], Step [440/735], Loss: 0.3277\n",
      "Epoch [9/50], Step [441/735], Loss: 0.1120\n",
      "Epoch [9/50], Step [442/735], Loss: 0.1575\n",
      "Epoch [9/50], Step [443/735], Loss: 0.1445\n",
      "Epoch [9/50], Step [444/735], Loss: 0.1047\n",
      "Epoch [9/50], Step [445/735], Loss: 0.1741\n",
      "Epoch [9/50], Step [446/735], Loss: 0.1217\n",
      "Epoch [9/50], Step [447/735], Loss: 0.2188\n",
      "Epoch [9/50], Step [448/735], Loss: 0.0533\n",
      "Epoch [9/50], Step [449/735], Loss: 0.1851\n",
      "Epoch [9/50], Step [450/735], Loss: 0.1420\n",
      "Epoch [9/50], Step [451/735], Loss: 0.1264\n",
      "Epoch [9/50], Step [452/735], Loss: 0.2944\n",
      "Epoch [9/50], Step [453/735], Loss: 0.2191\n",
      "Epoch [9/50], Step [454/735], Loss: 0.2291\n",
      "Epoch [9/50], Step [455/735], Loss: 0.3285\n",
      "Epoch [9/50], Step [456/735], Loss: 0.1668\n",
      "Epoch [9/50], Step [457/735], Loss: 0.2590\n",
      "Epoch [9/50], Step [458/735], Loss: 0.2790\n",
      "Epoch [9/50], Step [459/735], Loss: 0.1821\n",
      "Epoch [9/50], Step [460/735], Loss: 0.3697\n",
      "Epoch [9/50], Step [461/735], Loss: 0.0479\n",
      "Epoch [9/50], Step [462/735], Loss: 0.1257\n",
      "Epoch [9/50], Step [463/735], Loss: 1.3707\n",
      "Epoch [9/50], Step [464/735], Loss: 0.1780\n",
      "Epoch [9/50], Step [465/735], Loss: 0.1775\n",
      "Epoch [9/50], Step [466/735], Loss: 0.0971\n",
      "Epoch [9/50], Step [467/735], Loss: 0.1730\n",
      "Epoch [9/50], Step [468/735], Loss: 0.3547\n",
      "Epoch [9/50], Step [469/735], Loss: 0.2715\n",
      "Epoch [9/50], Step [470/735], Loss: 0.2606\n",
      "Epoch [9/50], Step [471/735], Loss: 0.2918\n",
      "Epoch [9/50], Step [472/735], Loss: 0.1349\n",
      "Epoch [9/50], Step [473/735], Loss: 0.1271\n",
      "Epoch [9/50], Step [474/735], Loss: 0.0628\n",
      "Epoch [9/50], Step [475/735], Loss: 0.1429\n",
      "Epoch [9/50], Step [476/735], Loss: 0.3783\n",
      "Epoch [9/50], Step [477/735], Loss: 0.2660\n",
      "Epoch [9/50], Step [478/735], Loss: 0.2252\n",
      "Epoch [9/50], Step [479/735], Loss: 0.2030\n",
      "Epoch [9/50], Step [480/735], Loss: 0.1452\n",
      "Epoch [9/50], Step [481/735], Loss: 0.0647\n",
      "Epoch [9/50], Step [482/735], Loss: 0.1047\n",
      "Epoch [9/50], Step [483/735], Loss: 0.3757\n",
      "Epoch [9/50], Step [484/735], Loss: 0.1089\n",
      "Epoch [9/50], Step [485/735], Loss: 0.6650\n",
      "Epoch [9/50], Step [486/735], Loss: 0.4645\n",
      "Epoch [9/50], Step [487/735], Loss: 0.0983\n",
      "Epoch [9/50], Step [488/735], Loss: 0.1106\n",
      "Epoch [9/50], Step [489/735], Loss: 0.0953\n",
      "Epoch [9/50], Step [490/735], Loss: 0.0654\n",
      "Epoch [9/50], Step [491/735], Loss: 0.2887\n",
      "Epoch [9/50], Step [492/735], Loss: 0.0735\n",
      "Epoch [9/50], Step [493/735], Loss: 0.5701\n",
      "Epoch [9/50], Step [494/735], Loss: 0.2000\n",
      "Epoch [9/50], Step [495/735], Loss: 0.2189\n",
      "Epoch [9/50], Step [496/735], Loss: 0.1510\n",
      "Epoch [9/50], Step [497/735], Loss: 0.2119\n",
      "Epoch [9/50], Step [498/735], Loss: 0.0938\n",
      "Epoch [9/50], Step [499/735], Loss: 0.6074\n",
      "Epoch [9/50], Step [500/735], Loss: 0.1066\n",
      "Epoch [9/50], Step [501/735], Loss: 0.2190\n",
      "Epoch [9/50], Step [502/735], Loss: 0.1720\n",
      "Epoch [9/50], Step [503/735], Loss: 0.1910\n",
      "Epoch [9/50], Step [504/735], Loss: 0.1000\n",
      "Epoch [9/50], Step [505/735], Loss: 2.5287\n",
      "Epoch [9/50], Step [506/735], Loss: 0.1337\n",
      "Epoch [9/50], Step [507/735], Loss: 0.1116\n",
      "Epoch [9/50], Step [508/735], Loss: 0.0926\n",
      "Epoch [9/50], Step [509/735], Loss: 0.3082\n",
      "Epoch [9/50], Step [510/735], Loss: 0.2649\n",
      "Epoch [9/50], Step [511/735], Loss: 0.1598\n",
      "Epoch [9/50], Step [512/735], Loss: 0.1875\n",
      "Epoch [9/50], Step [513/735], Loss: 0.1229\n",
      "Epoch [9/50], Step [514/735], Loss: 0.2605\n",
      "Epoch [9/50], Step [515/735], Loss: 0.0806\n",
      "Epoch [9/50], Step [516/735], Loss: 0.0461\n",
      "Epoch [9/50], Step [517/735], Loss: 0.2129\n",
      "Epoch [9/50], Step [518/735], Loss: 0.1751\n",
      "Epoch [9/50], Step [519/735], Loss: 0.2987\n",
      "Epoch [9/50], Step [520/735], Loss: 1.3863\n",
      "Epoch [9/50], Step [521/735], Loss: 0.1348\n",
      "Epoch [9/50], Step [522/735], Loss: 0.2205\n",
      "Epoch [9/50], Step [523/735], Loss: 0.0946\n",
      "Epoch [9/50], Step [524/735], Loss: 0.0744\n",
      "Epoch [9/50], Step [525/735], Loss: 0.1723\n",
      "Epoch [9/50], Step [526/735], Loss: 0.1927\n",
      "Epoch [9/50], Step [527/735], Loss: 0.2788\n",
      "Epoch [9/50], Step [528/735], Loss: 0.2262\n",
      "Epoch [9/50], Step [529/735], Loss: 0.1675\n",
      "Epoch [9/50], Step [530/735], Loss: 0.0804\n",
      "Epoch [9/50], Step [531/735], Loss: 0.2710\n",
      "Epoch [9/50], Step [532/735], Loss: 0.4288\n",
      "Epoch [9/50], Step [533/735], Loss: 0.1659\n",
      "Epoch [9/50], Step [534/735], Loss: 0.1107\n",
      "Epoch [9/50], Step [535/735], Loss: 2.0877\n",
      "Epoch [9/50], Step [536/735], Loss: 0.2286\n",
      "Epoch [9/50], Step [537/735], Loss: 1.1350\n",
      "Epoch [9/50], Step [538/735], Loss: 0.0772\n",
      "Epoch [9/50], Step [539/735], Loss: 0.1043\n",
      "Epoch [9/50], Step [540/735], Loss: 0.1779\n",
      "Epoch [9/50], Step [541/735], Loss: 0.0935\n",
      "Epoch [9/50], Step [542/735], Loss: 0.1618\n",
      "Epoch [9/50], Step [543/735], Loss: 0.5229\n",
      "Epoch [9/50], Step [544/735], Loss: 0.0772\n",
      "Epoch [9/50], Step [545/735], Loss: 0.0612\n",
      "Epoch [9/50], Step [546/735], Loss: 0.2060\n",
      "Epoch [9/50], Step [547/735], Loss: 0.0494\n",
      "Epoch [9/50], Step [548/735], Loss: 0.0636\n",
      "Epoch [9/50], Step [549/735], Loss: 0.2054\n",
      "Epoch [9/50], Step [550/735], Loss: 0.4197\n",
      "Epoch [9/50], Step [551/735], Loss: 0.9209\n",
      "Epoch [9/50], Step [552/735], Loss: 0.2419\n",
      "Epoch [9/50], Step [553/735], Loss: 0.2348\n",
      "Epoch [9/50], Step [554/735], Loss: 0.2928\n",
      "Epoch [9/50], Step [555/735], Loss: 0.1987\n",
      "Epoch [9/50], Step [556/735], Loss: 0.0743\n",
      "Epoch [9/50], Step [557/735], Loss: 0.0790\n",
      "Epoch [9/50], Step [558/735], Loss: 0.1030\n",
      "Epoch [9/50], Step [559/735], Loss: 0.0571\n",
      "Epoch [9/50], Step [560/735], Loss: 0.0664\n",
      "Epoch [9/50], Step [561/735], Loss: 0.1695\n",
      "Epoch [9/50], Step [562/735], Loss: 0.3784\n",
      "Epoch [9/50], Step [563/735], Loss: 0.3799\n",
      "Epoch [9/50], Step [564/735], Loss: 1.5253\n",
      "Epoch [9/50], Step [565/735], Loss: 0.5257\n",
      "Epoch [9/50], Step [566/735], Loss: 0.1997\n",
      "Epoch [9/50], Step [567/735], Loss: 0.0894\n",
      "Epoch [9/50], Step [568/735], Loss: 0.1455\n",
      "Epoch [9/50], Step [569/735], Loss: 0.7356\n",
      "Epoch [9/50], Step [570/735], Loss: 0.1300\n",
      "Epoch [9/50], Step [571/735], Loss: 0.1055\n",
      "Epoch [9/50], Step [572/735], Loss: 0.2211\n",
      "Epoch [9/50], Step [573/735], Loss: 0.1582\n",
      "Epoch [9/50], Step [574/735], Loss: 0.5644\n",
      "Epoch [9/50], Step [575/735], Loss: 0.1471\n",
      "Epoch [9/50], Step [576/735], Loss: 0.4015\n",
      "Epoch [9/50], Step [577/735], Loss: 0.3056\n",
      "Epoch [9/50], Step [578/735], Loss: 0.2031\n",
      "Epoch [9/50], Step [579/735], Loss: 0.1990\n",
      "Epoch [9/50], Step [580/735], Loss: 0.2043\n",
      "Epoch [9/50], Step [581/735], Loss: 0.1816\n",
      "Epoch [9/50], Step [582/735], Loss: 0.1651\n",
      "Epoch [9/50], Step [583/735], Loss: 0.6728\n",
      "Epoch [9/50], Step [584/735], Loss: 0.1653\n",
      "Epoch [9/50], Step [585/735], Loss: 0.8560\n",
      "Epoch [9/50], Step [586/735], Loss: 0.2174\n",
      "Epoch [9/50], Step [587/735], Loss: 0.1696\n",
      "Epoch [9/50], Step [588/735], Loss: 0.2401\n",
      "Epoch [9/50], Step [589/735], Loss: 0.2240\n",
      "Epoch [9/50], Step [590/735], Loss: 0.2319\n",
      "Epoch [9/50], Step [591/735], Loss: 0.2493\n",
      "Epoch [9/50], Step [592/735], Loss: 0.1227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Step [593/735], Loss: 0.1708\n",
      "Epoch [9/50], Step [594/735], Loss: 0.1514\n",
      "Epoch [9/50], Step [595/735], Loss: 0.2633\n",
      "Epoch [9/50], Step [596/735], Loss: 0.1850\n",
      "Epoch [9/50], Step [597/735], Loss: 0.2094\n",
      "Epoch [9/50], Step [598/735], Loss: 0.4818\n",
      "Epoch [9/50], Step [599/735], Loss: 0.0884\n",
      "Epoch [9/50], Step [600/735], Loss: 0.3771\n",
      "Epoch [9/50], Step [601/735], Loss: 0.2883\n",
      "Epoch [9/50], Step [602/735], Loss: 0.2847\n",
      "Epoch [9/50], Step [603/735], Loss: 0.1005\n",
      "Epoch [9/50], Step [604/735], Loss: 0.4415\n",
      "Epoch [9/50], Step [605/735], Loss: 0.1177\n",
      "Epoch [9/50], Step [606/735], Loss: 0.2047\n",
      "Epoch [9/50], Step [607/735], Loss: 0.0662\n",
      "Epoch [9/50], Step [608/735], Loss: 0.4716\n",
      "Epoch [9/50], Step [609/735], Loss: 0.2755\n",
      "Epoch [9/50], Step [610/735], Loss: 0.4025\n",
      "Epoch [9/50], Step [611/735], Loss: 0.1230\n",
      "Epoch [9/50], Step [612/735], Loss: 0.3233\n",
      "Epoch [9/50], Step [613/735], Loss: 0.1062\n",
      "Epoch [9/50], Step [614/735], Loss: 0.0761\n",
      "Epoch [9/50], Step [615/735], Loss: 0.1605\n",
      "Epoch [9/50], Step [616/735], Loss: 0.3452\n",
      "Epoch [9/50], Step [617/735], Loss: 0.1157\n",
      "Epoch [9/50], Step [618/735], Loss: 0.3026\n",
      "Epoch [9/50], Step [619/735], Loss: 0.2084\n",
      "Epoch [9/50], Step [620/735], Loss: 0.2465\n",
      "Epoch [9/50], Step [621/735], Loss: 0.2035\n",
      "Epoch [9/50], Step [622/735], Loss: 0.0913\n",
      "Epoch [9/50], Step [623/735], Loss: 0.1181\n",
      "Epoch [9/50], Step [624/735], Loss: 0.0609\n",
      "Epoch [9/50], Step [625/735], Loss: 0.2667\n",
      "Epoch [9/50], Step [626/735], Loss: 0.0606\n",
      "Epoch [9/50], Step [627/735], Loss: 0.1196\n",
      "Epoch [9/50], Step [628/735], Loss: 0.1482\n",
      "Epoch [9/50], Step [629/735], Loss: 0.4917\n",
      "Epoch [9/50], Step [630/735], Loss: 0.5500\n",
      "Epoch [9/50], Step [631/735], Loss: 0.0667\n",
      "Epoch [9/50], Step [632/735], Loss: 0.3893\n",
      "Epoch [9/50], Step [633/735], Loss: 0.0900\n",
      "Epoch [9/50], Step [634/735], Loss: 0.1539\n",
      "Epoch [9/50], Step [635/735], Loss: 0.3293\n",
      "Epoch [9/50], Step [636/735], Loss: 0.0813\n",
      "Epoch [9/50], Step [637/735], Loss: 0.1984\n",
      "Epoch [9/50], Step [638/735], Loss: 0.1229\n",
      "Epoch [9/50], Step [639/735], Loss: 0.1753\n",
      "Epoch [9/50], Step [640/735], Loss: 0.5278\n",
      "Epoch [9/50], Step [641/735], Loss: 0.1935\n",
      "Epoch [9/50], Step [642/735], Loss: 0.1127\n",
      "Epoch [9/50], Step [643/735], Loss: 0.1490\n",
      "Epoch [9/50], Step [644/735], Loss: 0.2211\n",
      "Epoch [9/50], Step [645/735], Loss: 0.1773\n",
      "Epoch [9/50], Step [646/735], Loss: 0.1215\n",
      "Epoch [9/50], Step [647/735], Loss: 0.1089\n",
      "Epoch [9/50], Step [648/735], Loss: 0.0752\n",
      "Epoch [9/50], Step [649/735], Loss: 0.0913\n",
      "Epoch [9/50], Step [650/735], Loss: 0.0661\n",
      "Epoch [9/50], Step [651/735], Loss: 0.1327\n",
      "Epoch [9/50], Step [652/735], Loss: 0.0761\n",
      "Epoch [9/50], Step [653/735], Loss: 0.0583\n",
      "Epoch [9/50], Step [654/735], Loss: 0.4300\n",
      "Epoch [9/50], Step [655/735], Loss: 0.0644\n",
      "Epoch [9/50], Step [656/735], Loss: 1.3691\n",
      "Epoch [9/50], Step [657/735], Loss: 0.3715\n",
      "Epoch [9/50], Step [658/735], Loss: 0.3584\n",
      "Epoch [9/50], Step [659/735], Loss: 0.9459\n",
      "Epoch [9/50], Step [660/735], Loss: 0.2968\n",
      "Epoch [9/50], Step [661/735], Loss: 0.1224\n",
      "Epoch [9/50], Step [662/735], Loss: 0.1127\n",
      "Epoch [9/50], Step [663/735], Loss: 0.0543\n",
      "Epoch [9/50], Step [664/735], Loss: 2.3258\n",
      "Epoch [9/50], Step [665/735], Loss: 0.0928\n",
      "Epoch [9/50], Step [666/735], Loss: 0.2787\n",
      "Epoch [9/50], Step [667/735], Loss: 0.0661\n",
      "Epoch [9/50], Step [668/735], Loss: 0.1360\n",
      "Epoch [9/50], Step [669/735], Loss: 0.1515\n",
      "Epoch [9/50], Step [670/735], Loss: 0.1024\n",
      "Epoch [9/50], Step [671/735], Loss: 0.0707\n",
      "Epoch [9/50], Step [672/735], Loss: 0.3515\n",
      "Epoch [9/50], Step [673/735], Loss: 0.2160\n",
      "Epoch [9/50], Step [674/735], Loss: 0.0479\n",
      "Epoch [9/50], Step [675/735], Loss: 0.1131\n",
      "Epoch [9/50], Step [676/735], Loss: 0.0825\n",
      "Epoch [9/50], Step [677/735], Loss: 0.1529\n",
      "Epoch [9/50], Step [678/735], Loss: 0.1388\n",
      "Epoch [9/50], Step [679/735], Loss: 0.3260\n",
      "Epoch [9/50], Step [680/735], Loss: 0.2449\n",
      "Epoch [9/50], Step [681/735], Loss: 0.1053\n",
      "Epoch [9/50], Step [682/735], Loss: 0.0764\n",
      "Epoch [9/50], Step [683/735], Loss: 0.0570\n",
      "Epoch [9/50], Step [684/735], Loss: 0.0940\n",
      "Epoch [9/50], Step [685/735], Loss: 0.1558\n",
      "Epoch [9/50], Step [686/735], Loss: 0.2598\n",
      "Epoch [9/50], Step [687/735], Loss: 0.2309\n",
      "Epoch [9/50], Step [688/735], Loss: 0.3757\n",
      "Epoch [9/50], Step [689/735], Loss: 0.2273\n",
      "Epoch [9/50], Step [690/735], Loss: 0.1705\n",
      "Epoch [9/50], Step [691/735], Loss: 0.2365\n",
      "Epoch [9/50], Step [692/735], Loss: 0.7038\n",
      "Epoch [9/50], Step [693/735], Loss: 0.0940\n",
      "Epoch [9/50], Step [694/735], Loss: 0.1515\n",
      "Epoch [9/50], Step [695/735], Loss: 0.0824\n",
      "Epoch [9/50], Step [696/735], Loss: 0.2272\n",
      "Epoch [9/50], Step [697/735], Loss: 0.1166\n",
      "Epoch [9/50], Step [698/735], Loss: 0.2476\n",
      "Epoch [9/50], Step [699/735], Loss: 0.1451\n",
      "Epoch [9/50], Step [700/735], Loss: 0.3043\n",
      "Epoch [9/50], Step [701/735], Loss: 0.3908\n",
      "Epoch [9/50], Step [702/735], Loss: 0.2512\n",
      "Epoch [9/50], Step [703/735], Loss: 0.2523\n",
      "Epoch [9/50], Step [704/735], Loss: 0.3819\n",
      "Epoch [9/50], Step [705/735], Loss: 0.1390\n",
      "Epoch [9/50], Step [706/735], Loss: 0.3611\n",
      "Epoch [9/50], Step [707/735], Loss: 0.2654\n",
      "Epoch [9/50], Step [708/735], Loss: 0.0955\n",
      "Epoch [9/50], Step [709/735], Loss: 0.3588\n",
      "Epoch [9/50], Step [710/735], Loss: 0.2299\n",
      "Epoch [9/50], Step [711/735], Loss: 0.1400\n",
      "Epoch [9/50], Step [712/735], Loss: 0.1400\n",
      "Epoch [9/50], Step [713/735], Loss: 0.0654\n",
      "Epoch [9/50], Step [714/735], Loss: 0.3397\n",
      "Epoch [9/50], Step [715/735], Loss: 0.1642\n",
      "Epoch [9/50], Step [716/735], Loss: 0.0958\n",
      "Epoch [9/50], Step [717/735], Loss: 0.3986\n",
      "Epoch [9/50], Step [718/735], Loss: 0.0652\n",
      "Epoch [9/50], Step [719/735], Loss: 0.0859\n",
      "Epoch [9/50], Step [720/735], Loss: 0.1426\n",
      "Epoch [9/50], Step [721/735], Loss: 0.2509\n",
      "Epoch [9/50], Step [722/735], Loss: 0.0496\n",
      "Epoch [9/50], Step [723/735], Loss: 0.1901\n",
      "Epoch [9/50], Step [724/735], Loss: 0.2524\n",
      "Epoch [9/50], Step [725/735], Loss: 0.1141\n",
      "Epoch [9/50], Step [726/735], Loss: 0.3258\n",
      "Epoch [9/50], Step [727/735], Loss: 0.1335\n",
      "Epoch [9/50], Step [728/735], Loss: 0.1616\n",
      "Epoch [9/50], Step [729/735], Loss: 0.2018\n",
      "Epoch [9/50], Step [730/735], Loss: 0.1734\n",
      "Epoch [9/50], Step [731/735], Loss: 0.3407\n",
      "Epoch [9/50], Step [732/735], Loss: 0.1626\n",
      "Epoch [9/50], Step [733/735], Loss: 0.3193\n",
      "Epoch [9/50], Step [734/735], Loss: 0.0784\n",
      "Epoch [9/50], Step [735/735], Loss: 0.2543\n",
      "Epoch [10/50], Step [1/735], Loss: 0.1867\n",
      "Epoch [10/50], Step [2/735], Loss: 0.1966\n",
      "Epoch [10/50], Step [3/735], Loss: 0.1889\n",
      "Epoch [10/50], Step [4/735], Loss: 0.1223\n",
      "Epoch [10/50], Step [5/735], Loss: 0.3309\n",
      "Epoch [10/50], Step [6/735], Loss: 0.1503\n",
      "Epoch [10/50], Step [7/735], Loss: 0.1175\n",
      "Epoch [10/50], Step [8/735], Loss: 0.1418\n",
      "Epoch [10/50], Step [9/735], Loss: 0.3006\n",
      "Epoch [10/50], Step [10/735], Loss: 0.1368\n",
      "Epoch [10/50], Step [11/735], Loss: 0.4229\n",
      "Epoch [10/50], Step [12/735], Loss: 0.0993\n",
      "Epoch [10/50], Step [13/735], Loss: 0.1414\n",
      "Epoch [10/50], Step [14/735], Loss: 0.1214\n",
      "Epoch [10/50], Step [15/735], Loss: 0.1545\n",
      "Epoch [10/50], Step [16/735], Loss: 0.8288\n",
      "Epoch [10/50], Step [17/735], Loss: 0.1748\n",
      "Epoch [10/50], Step [18/735], Loss: 0.0834\n",
      "Epoch [10/50], Step [19/735], Loss: 0.0488\n",
      "Epoch [10/50], Step [20/735], Loss: 0.1845\n",
      "Epoch [10/50], Step [21/735], Loss: 1.5438\n",
      "Epoch [10/50], Step [22/735], Loss: 0.1410\n",
      "Epoch [10/50], Step [23/735], Loss: 0.0757\n",
      "Epoch [10/50], Step [24/735], Loss: 0.2954\n",
      "Epoch [10/50], Step [25/735], Loss: 0.0706\n",
      "Epoch [10/50], Step [26/735], Loss: 0.1538\n",
      "Epoch [10/50], Step [27/735], Loss: 0.2676\n",
      "Epoch [10/50], Step [28/735], Loss: 0.1342\n",
      "Epoch [10/50], Step [29/735], Loss: 0.1799\n",
      "Epoch [10/50], Step [30/735], Loss: 0.1250\n",
      "Epoch [10/50], Step [31/735], Loss: 0.1480\n",
      "Epoch [10/50], Step [32/735], Loss: 0.0504\n",
      "Epoch [10/50], Step [33/735], Loss: 0.1035\n",
      "Epoch [10/50], Step [34/735], Loss: 0.1648\n",
      "Epoch [10/50], Step [35/735], Loss: 0.0452\n",
      "Epoch [10/50], Step [36/735], Loss: 0.0515\n",
      "Epoch [10/50], Step [37/735], Loss: 2.3400\n",
      "Epoch [10/50], Step [38/735], Loss: 0.1615\n",
      "Epoch [10/50], Step [39/735], Loss: 0.1337\n",
      "Epoch [10/50], Step [40/735], Loss: 0.3131\n",
      "Epoch [10/50], Step [41/735], Loss: 0.0653\n",
      "Epoch [10/50], Step [42/735], Loss: 0.3270\n",
      "Epoch [10/50], Step [43/735], Loss: 0.0808\n",
      "Epoch [10/50], Step [44/735], Loss: 0.1585\n",
      "Epoch [10/50], Step [45/735], Loss: 0.1243\n",
      "Epoch [10/50], Step [46/735], Loss: 0.2484\n",
      "Epoch [10/50], Step [47/735], Loss: 0.1080\n",
      "Epoch [10/50], Step [48/735], Loss: 0.3187\n",
      "Epoch [10/50], Step [49/735], Loss: 0.2793\n",
      "Epoch [10/50], Step [50/735], Loss: 0.0764\n",
      "Epoch [10/50], Step [51/735], Loss: 0.2887\n",
      "Epoch [10/50], Step [52/735], Loss: 0.4576\n",
      "Epoch [10/50], Step [53/735], Loss: 0.0926\n",
      "Epoch [10/50], Step [54/735], Loss: 0.1026\n",
      "Epoch [10/50], Step [55/735], Loss: 0.1151\n",
      "Epoch [10/50], Step [56/735], Loss: 0.1473\n",
      "Epoch [10/50], Step [57/735], Loss: 0.2557\n",
      "Epoch [10/50], Step [58/735], Loss: 0.2049\n",
      "Epoch [10/50], Step [59/735], Loss: 0.2044\n",
      "Epoch [10/50], Step [60/735], Loss: 0.1309\n",
      "Epoch [10/50], Step [61/735], Loss: 0.2634\n",
      "Epoch [10/50], Step [62/735], Loss: 0.1851\n",
      "Epoch [10/50], Step [63/735], Loss: 0.4204\n",
      "Epoch [10/50], Step [64/735], Loss: 0.8734\n",
      "Epoch [10/50], Step [65/735], Loss: 0.2445\n",
      "Epoch [10/50], Step [66/735], Loss: 0.0749\n",
      "Epoch [10/50], Step [67/735], Loss: 0.3290\n",
      "Epoch [10/50], Step [68/735], Loss: 0.0723\n",
      "Epoch [10/50], Step [69/735], Loss: 0.1093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Step [70/735], Loss: 0.3229\n",
      "Epoch [10/50], Step [71/735], Loss: 0.2140\n",
      "Epoch [10/50], Step [72/735], Loss: 0.1673\n",
      "Epoch [10/50], Step [73/735], Loss: 0.1070\n",
      "Epoch [10/50], Step [74/735], Loss: 0.1973\n",
      "Epoch [10/50], Step [75/735], Loss: 0.1469\n",
      "Epoch [10/50], Step [76/735], Loss: 0.2899\n",
      "Epoch [10/50], Step [77/735], Loss: 0.2144\n",
      "Epoch [10/50], Step [78/735], Loss: 0.2307\n",
      "Epoch [10/50], Step [79/735], Loss: 0.1752\n",
      "Epoch [10/50], Step [80/735], Loss: 0.0680\n",
      "Epoch [10/50], Step [81/735], Loss: 0.1371\n",
      "Epoch [10/50], Step [82/735], Loss: 0.1075\n",
      "Epoch [10/50], Step [83/735], Loss: 0.2601\n",
      "Epoch [10/50], Step [84/735], Loss: 0.1145\n",
      "Epoch [10/50], Step [85/735], Loss: 0.2409\n",
      "Epoch [10/50], Step [86/735], Loss: 0.0893\n",
      "Epoch [10/50], Step [87/735], Loss: 0.0947\n",
      "Epoch [10/50], Step [88/735], Loss: 0.3045\n",
      "Epoch [10/50], Step [89/735], Loss: 0.0701\n",
      "Epoch [10/50], Step [90/735], Loss: 0.0932\n",
      "Epoch [10/50], Step [91/735], Loss: 0.2446\n",
      "Epoch [10/50], Step [92/735], Loss: 0.6192\n",
      "Epoch [10/50], Step [93/735], Loss: 0.1946\n",
      "Epoch [10/50], Step [94/735], Loss: 0.2946\n",
      "Epoch [10/50], Step [95/735], Loss: 0.3460\n",
      "Epoch [10/50], Step [96/735], Loss: 0.1480\n",
      "Epoch [10/50], Step [97/735], Loss: 0.2614\n",
      "Epoch [10/50], Step [98/735], Loss: 0.1796\n",
      "Epoch [10/50], Step [99/735], Loss: 0.2666\n",
      "Epoch [10/50], Step [100/735], Loss: 0.1087\n",
      "Epoch [10/50], Step [101/735], Loss: 0.0797\n",
      "Epoch [10/50], Step [102/735], Loss: 0.2118\n",
      "Epoch [10/50], Step [103/735], Loss: 0.2071\n",
      "Epoch [10/50], Step [104/735], Loss: 0.1728\n",
      "Epoch [10/50], Step [105/735], Loss: 0.0760\n",
      "Epoch [10/50], Step [106/735], Loss: 0.0906\n",
      "Epoch [10/50], Step [107/735], Loss: 0.0949\n",
      "Epoch [10/50], Step [108/735], Loss: 0.2932\n",
      "Epoch [10/50], Step [109/735], Loss: 0.1798\n",
      "Epoch [10/50], Step [110/735], Loss: 0.1433\n",
      "Epoch [10/50], Step [111/735], Loss: 0.0772\n",
      "Epoch [10/50], Step [112/735], Loss: 0.0650\n",
      "Epoch [10/50], Step [113/735], Loss: 0.1148\n",
      "Epoch [10/50], Step [114/735], Loss: 0.0817\n",
      "Epoch [10/50], Step [115/735], Loss: 0.0512\n",
      "Epoch [10/50], Step [116/735], Loss: 0.0788\n",
      "Epoch [10/50], Step [117/735], Loss: 0.2182\n",
      "Epoch [10/50], Step [118/735], Loss: 0.2324\n",
      "Epoch [10/50], Step [119/735], Loss: 0.2349\n",
      "Epoch [10/50], Step [120/735], Loss: 0.2234\n",
      "Epoch [10/50], Step [121/735], Loss: 0.0371\n",
      "Epoch [10/50], Step [122/735], Loss: 0.3109\n",
      "Epoch [10/50], Step [123/735], Loss: 0.1081\n",
      "Epoch [10/50], Step [124/735], Loss: 2.3912\n",
      "Epoch [10/50], Step [125/735], Loss: 0.1058\n",
      "Epoch [10/50], Step [126/735], Loss: 0.0540\n",
      "Epoch [10/50], Step [127/735], Loss: 0.1229\n",
      "Epoch [10/50], Step [128/735], Loss: 0.1909\n",
      "Epoch [10/50], Step [129/735], Loss: 0.0626\n",
      "Epoch [10/50], Step [130/735], Loss: 0.2958\n",
      "Epoch [10/50], Step [131/735], Loss: 0.1124\n",
      "Epoch [10/50], Step [132/735], Loss: 0.1103\n",
      "Epoch [10/50], Step [133/735], Loss: 0.0834\n",
      "Epoch [10/50], Step [134/735], Loss: 0.2598\n",
      "Epoch [10/50], Step [135/735], Loss: 0.1519\n",
      "Epoch [10/50], Step [136/735], Loss: 0.3218\n",
      "Epoch [10/50], Step [137/735], Loss: 0.1605\n",
      "Epoch [10/50], Step [138/735], Loss: 0.2342\n",
      "Epoch [10/50], Step [139/735], Loss: 0.1246\n",
      "Epoch [10/50], Step [140/735], Loss: 0.0579\n",
      "Epoch [10/50], Step [141/735], Loss: 0.3727\n",
      "Epoch [10/50], Step [142/735], Loss: 0.1397\n",
      "Epoch [10/50], Step [143/735], Loss: 0.0688\n",
      "Epoch [10/50], Step [144/735], Loss: 0.0974\n",
      "Epoch [10/50], Step [145/735], Loss: 0.1617\n",
      "Epoch [10/50], Step [146/735], Loss: 0.3225\n",
      "Epoch [10/50], Step [147/735], Loss: 0.0776\n",
      "Epoch [10/50], Step [148/735], Loss: 0.4342\n",
      "Epoch [10/50], Step [149/735], Loss: 0.0744\n",
      "Epoch [10/50], Step [150/735], Loss: 0.1469\n",
      "Epoch [10/50], Step [151/735], Loss: 0.1145\n",
      "Epoch [10/50], Step [152/735], Loss: 0.2695\n",
      "Epoch [10/50], Step [153/735], Loss: 0.2616\n",
      "Epoch [10/50], Step [154/735], Loss: 0.3637\n",
      "Epoch [10/50], Step [155/735], Loss: 0.2814\n",
      "Epoch [10/50], Step [156/735], Loss: 0.1220\n",
      "Epoch [10/50], Step [157/735], Loss: 0.7257\n",
      "Epoch [10/50], Step [158/735], Loss: 0.3909\n",
      "Epoch [10/50], Step [159/735], Loss: 0.3046\n",
      "Epoch [10/50], Step [160/735], Loss: 0.3171\n",
      "Epoch [10/50], Step [161/735], Loss: 0.1417\n",
      "Epoch [10/50], Step [162/735], Loss: 1.2718\n",
      "Epoch [10/50], Step [163/735], Loss: 0.1873\n",
      "Epoch [10/50], Step [164/735], Loss: 0.2020\n",
      "Epoch [10/50], Step [165/735], Loss: 0.1568\n",
      "Epoch [10/50], Step [166/735], Loss: 0.1679\n",
      "Epoch [10/50], Step [167/735], Loss: 0.0981\n",
      "Epoch [10/50], Step [168/735], Loss: 0.0324\n",
      "Epoch [10/50], Step [169/735], Loss: 0.0965\n",
      "Epoch [10/50], Step [170/735], Loss: 0.2273\n",
      "Epoch [10/50], Step [171/735], Loss: 0.2412\n",
      "Epoch [10/50], Step [172/735], Loss: 0.0730\n",
      "Epoch [10/50], Step [173/735], Loss: 0.1124\n",
      "Epoch [10/50], Step [174/735], Loss: 0.2279\n",
      "Epoch [10/50], Step [175/735], Loss: 0.5038\n",
      "Epoch [10/50], Step [176/735], Loss: 0.3208\n",
      "Epoch [10/50], Step [177/735], Loss: 0.0769\n",
      "Epoch [10/50], Step [178/735], Loss: 0.1581\n",
      "Epoch [10/50], Step [179/735], Loss: 0.1595\n",
      "Epoch [10/50], Step [180/735], Loss: 0.1133\n",
      "Epoch [10/50], Step [181/735], Loss: 0.0447\n",
      "Epoch [10/50], Step [182/735], Loss: 0.1354\n",
      "Epoch [10/50], Step [183/735], Loss: 0.1255\n",
      "Epoch [10/50], Step [184/735], Loss: 0.1410\n",
      "Epoch [10/50], Step [185/735], Loss: 0.6847\n",
      "Epoch [10/50], Step [186/735], Loss: 0.3421\n",
      "Epoch [10/50], Step [187/735], Loss: 1.2048\n",
      "Epoch [10/50], Step [188/735], Loss: 0.2209\n",
      "Epoch [10/50], Step [189/735], Loss: 0.1393\n",
      "Epoch [10/50], Step [190/735], Loss: 0.2729\n",
      "Epoch [10/50], Step [191/735], Loss: 0.1296\n",
      "Epoch [10/50], Step [192/735], Loss: 0.2291\n",
      "Epoch [10/50], Step [193/735], Loss: 0.1999\n",
      "Epoch [10/50], Step [194/735], Loss: 0.0966\n",
      "Epoch [10/50], Step [195/735], Loss: 0.0982\n",
      "Epoch [10/50], Step [196/735], Loss: 0.0627\n",
      "Epoch [10/50], Step [197/735], Loss: 0.5859\n",
      "Epoch [10/50], Step [198/735], Loss: 0.0895\n",
      "Epoch [10/50], Step [199/735], Loss: 0.0797\n",
      "Epoch [10/50], Step [200/735], Loss: 0.3089\n",
      "Epoch [10/50], Step [201/735], Loss: 0.0418\n",
      "Epoch [10/50], Step [202/735], Loss: 0.1474\n",
      "Epoch [10/50], Step [203/735], Loss: 0.0457\n",
      "Epoch [10/50], Step [204/735], Loss: 0.3496\n",
      "Epoch [10/50], Step [205/735], Loss: 0.2780\n",
      "Epoch [10/50], Step [206/735], Loss: 0.1464\n",
      "Epoch [10/50], Step [207/735], Loss: 0.1568\n",
      "Epoch [10/50], Step [208/735], Loss: 0.1298\n",
      "Epoch [10/50], Step [209/735], Loss: 0.4096\n",
      "Epoch [10/50], Step [210/735], Loss: 0.0745\n",
      "Epoch [10/50], Step [211/735], Loss: 0.2908\n",
      "Epoch [10/50], Step [212/735], Loss: 0.0877\n",
      "Epoch [10/50], Step [213/735], Loss: 0.0864\n",
      "Epoch [10/50], Step [214/735], Loss: 0.0835\n",
      "Epoch [10/50], Step [215/735], Loss: 0.0778\n",
      "Epoch [10/50], Step [216/735], Loss: 0.1466\n",
      "Epoch [10/50], Step [217/735], Loss: 0.1802\n",
      "Epoch [10/50], Step [218/735], Loss: 0.1199\n",
      "Epoch [10/50], Step [219/735], Loss: 0.2590\n",
      "Epoch [10/50], Step [220/735], Loss: 0.0973\n",
      "Epoch [10/50], Step [221/735], Loss: 0.0772\n",
      "Epoch [10/50], Step [222/735], Loss: 0.2246\n",
      "Epoch [10/50], Step [223/735], Loss: 0.1269\n",
      "Epoch [10/50], Step [224/735], Loss: 0.4985\n",
      "Epoch [10/50], Step [225/735], Loss: 0.1689\n",
      "Epoch [10/50], Step [226/735], Loss: 0.1594\n",
      "Epoch [10/50], Step [227/735], Loss: 0.2757\n",
      "Epoch [10/50], Step [228/735], Loss: 0.0919\n",
      "Epoch [10/50], Step [229/735], Loss: 0.0705\n",
      "Epoch [10/50], Step [230/735], Loss: 0.1144\n",
      "Epoch [10/50], Step [231/735], Loss: 0.5267\n",
      "Epoch [10/50], Step [232/735], Loss: 0.1303\n",
      "Epoch [10/50], Step [233/735], Loss: 0.1463\n",
      "Epoch [10/50], Step [234/735], Loss: 0.4170\n",
      "Epoch [10/50], Step [235/735], Loss: 0.0852\n",
      "Epoch [10/50], Step [236/735], Loss: 0.2492\n",
      "Epoch [10/50], Step [237/735], Loss: 0.0805\n",
      "Epoch [10/50], Step [238/735], Loss: 0.2497\n",
      "Epoch [10/50], Step [239/735], Loss: 0.2385\n",
      "Epoch [10/50], Step [240/735], Loss: 0.1060\n",
      "Epoch [10/50], Step [241/735], Loss: 0.0934\n",
      "Epoch [10/50], Step [242/735], Loss: 0.0663\n",
      "Epoch [10/50], Step [243/735], Loss: 0.1463\n",
      "Epoch [10/50], Step [244/735], Loss: 0.1054\n",
      "Epoch [10/50], Step [245/735], Loss: 0.0328\n",
      "Epoch [10/50], Step [246/735], Loss: 0.1127\n",
      "Epoch [10/50], Step [247/735], Loss: 0.8263\n",
      "Epoch [10/50], Step [248/735], Loss: 0.0944\n",
      "Epoch [10/50], Step [249/735], Loss: 0.2070\n",
      "Epoch [10/50], Step [250/735], Loss: 0.2969\n",
      "Epoch [10/50], Step [251/735], Loss: 0.1532\n",
      "Epoch [10/50], Step [252/735], Loss: 0.1022\n",
      "Epoch [10/50], Step [253/735], Loss: 0.1818\n",
      "Epoch [10/50], Step [254/735], Loss: 0.2808\n",
      "Epoch [10/50], Step [255/735], Loss: 0.2323\n",
      "Epoch [10/50], Step [256/735], Loss: 0.1393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Step [257/735], Loss: 0.1866\n",
      "Epoch [10/50], Step [258/735], Loss: 0.2279\n",
      "Epoch [10/50], Step [259/735], Loss: 0.1000\n",
      "Epoch [10/50], Step [260/735], Loss: 0.2128\n",
      "Epoch [10/50], Step [261/735], Loss: 0.1740\n",
      "Epoch [10/50], Step [262/735], Loss: 0.1501\n",
      "Epoch [10/50], Step [263/735], Loss: 0.2297\n",
      "Epoch [10/50], Step [264/735], Loss: 0.0808\n",
      "Epoch [10/50], Step [265/735], Loss: 0.3225\n",
      "Epoch [10/50], Step [266/735], Loss: 0.1557\n",
      "Epoch [10/50], Step [267/735], Loss: 0.2501\n",
      "Epoch [10/50], Step [268/735], Loss: 0.9569\n",
      "Epoch [10/50], Step [269/735], Loss: 0.3912\n",
      "Epoch [10/50], Step [270/735], Loss: 0.3253\n",
      "Epoch [10/50], Step [271/735], Loss: 0.1317\n",
      "Epoch [10/50], Step [272/735], Loss: 0.7983\n",
      "Epoch [10/50], Step [273/735], Loss: 0.3513\n",
      "Epoch [10/50], Step [274/735], Loss: 0.8752\n",
      "Epoch [10/50], Step [275/735], Loss: 0.5732\n",
      "Epoch [10/50], Step [276/735], Loss: 0.1490\n",
      "Epoch [10/50], Step [277/735], Loss: 0.1421\n",
      "Epoch [10/50], Step [278/735], Loss: 0.1522\n",
      "Epoch [10/50], Step [279/735], Loss: 0.1178\n",
      "Epoch [10/50], Step [280/735], Loss: 0.0703\n",
      "Epoch [10/50], Step [281/735], Loss: 0.1738\n",
      "Epoch [10/50], Step [282/735], Loss: 0.0819\n",
      "Epoch [10/50], Step [283/735], Loss: 0.3522\n",
      "Epoch [10/50], Step [284/735], Loss: 0.7870\n",
      "Epoch [10/50], Step [285/735], Loss: 0.4637\n",
      "Epoch [10/50], Step [286/735], Loss: 0.1785\n",
      "Epoch [10/50], Step [287/735], Loss: 0.1053\n",
      "Epoch [10/50], Step [288/735], Loss: 0.1914\n",
      "Epoch [10/50], Step [289/735], Loss: 0.2077\n",
      "Epoch [10/50], Step [290/735], Loss: 0.1904\n",
      "Epoch [10/50], Step [291/735], Loss: 0.0637\n",
      "Epoch [10/50], Step [292/735], Loss: 0.1006\n",
      "Epoch [10/50], Step [293/735], Loss: 0.2524\n",
      "Epoch [10/50], Step [294/735], Loss: 0.2463\n",
      "Epoch [10/50], Step [295/735], Loss: 0.2358\n",
      "Epoch [10/50], Step [296/735], Loss: 0.1898\n",
      "Epoch [10/50], Step [297/735], Loss: 0.0619\n",
      "Epoch [10/50], Step [298/735], Loss: 0.0931\n",
      "Epoch [10/50], Step [299/735], Loss: 0.5253\n",
      "Epoch [10/50], Step [300/735], Loss: 0.1914\n",
      "Epoch [10/50], Step [301/735], Loss: 0.1159\n",
      "Epoch [10/50], Step [302/735], Loss: 0.4125\n",
      "Epoch [10/50], Step [303/735], Loss: 0.1675\n",
      "Epoch [10/50], Step [304/735], Loss: 1.0310\n",
      "Epoch [10/50], Step [305/735], Loss: 0.2498\n",
      "Epoch [10/50], Step [306/735], Loss: 0.1616\n",
      "Epoch [10/50], Step [307/735], Loss: 0.3630\n",
      "Epoch [10/50], Step [308/735], Loss: 0.0955\n",
      "Epoch [10/50], Step [309/735], Loss: 0.3015\n",
      "Epoch [10/50], Step [310/735], Loss: 0.0633\n",
      "Epoch [10/50], Step [311/735], Loss: 0.2369\n",
      "Epoch [10/50], Step [312/735], Loss: 0.2579\n",
      "Epoch [10/50], Step [313/735], Loss: 0.2187\n",
      "Epoch [10/50], Step [314/735], Loss: 0.1536\n",
      "Epoch [10/50], Step [315/735], Loss: 0.1108\n",
      "Epoch [10/50], Step [316/735], Loss: 0.1433\n",
      "Epoch [10/50], Step [317/735], Loss: 0.1965\n",
      "Epoch [10/50], Step [318/735], Loss: 0.0444\n",
      "Epoch [10/50], Step [319/735], Loss: 0.2681\n",
      "Epoch [10/50], Step [320/735], Loss: 0.1478\n",
      "Epoch [10/50], Step [321/735], Loss: 0.1143\n",
      "Epoch [10/50], Step [322/735], Loss: 0.2265\n",
      "Epoch [10/50], Step [323/735], Loss: 0.1679\n",
      "Epoch [10/50], Step [324/735], Loss: 0.1441\n",
      "Epoch [10/50], Step [325/735], Loss: 0.2495\n",
      "Epoch [10/50], Step [326/735], Loss: 0.0854\n",
      "Epoch [10/50], Step [327/735], Loss: 0.1644\n",
      "Epoch [10/50], Step [328/735], Loss: 0.1024\n",
      "Epoch [10/50], Step [329/735], Loss: 0.2788\n",
      "Epoch [10/50], Step [330/735], Loss: 0.1936\n",
      "Epoch [10/50], Step [331/735], Loss: 0.0612\n",
      "Epoch [10/50], Step [332/735], Loss: 0.0804\n",
      "Epoch [10/50], Step [333/735], Loss: 0.2178\n",
      "Epoch [10/50], Step [334/735], Loss: 0.0856\n",
      "Epoch [10/50], Step [335/735], Loss: 0.2301\n",
      "Epoch [10/50], Step [336/735], Loss: 0.8416\n",
      "Epoch [10/50], Step [337/735], Loss: 0.0546\n",
      "Epoch [10/50], Step [338/735], Loss: 0.2981\n",
      "Epoch [10/50], Step [339/735], Loss: 0.0880\n",
      "Epoch [10/50], Step [340/735], Loss: 0.1170\n",
      "Epoch [10/50], Step [341/735], Loss: 0.3111\n",
      "Epoch [10/50], Step [342/735], Loss: 0.0568\n",
      "Epoch [10/50], Step [343/735], Loss: 0.0865\n",
      "Epoch [10/50], Step [344/735], Loss: 0.1568\n",
      "Epoch [10/50], Step [345/735], Loss: 0.1454\n",
      "Epoch [10/50], Step [346/735], Loss: 0.0568\n",
      "Epoch [10/50], Step [347/735], Loss: 0.1941\n",
      "Epoch [10/50], Step [348/735], Loss: 0.1333\n",
      "Epoch [10/50], Step [349/735], Loss: 0.0739\n",
      "Epoch [10/50], Step [350/735], Loss: 0.3864\n",
      "Epoch [10/50], Step [351/735], Loss: 0.1463\n",
      "Epoch [10/50], Step [352/735], Loss: 0.1467\n",
      "Epoch [10/50], Step [353/735], Loss: 0.2026\n",
      "Epoch [10/50], Step [354/735], Loss: 0.0787\n",
      "Epoch [10/50], Step [355/735], Loss: 0.0868\n",
      "Epoch [10/50], Step [356/735], Loss: 0.0501\n",
      "Epoch [10/50], Step [357/735], Loss: 0.1581\n",
      "Epoch [10/50], Step [358/735], Loss: 0.9981\n",
      "Epoch [10/50], Step [359/735], Loss: 0.0986\n",
      "Epoch [10/50], Step [360/735], Loss: 0.1469\n",
      "Epoch [10/50], Step [361/735], Loss: 0.1400\n",
      "Epoch [10/50], Step [362/735], Loss: 0.1203\n",
      "Epoch [10/50], Step [363/735], Loss: 0.0444\n",
      "Epoch [10/50], Step [364/735], Loss: 0.0467\n",
      "Epoch [10/50], Step [365/735], Loss: 0.2847\n",
      "Epoch [10/50], Step [366/735], Loss: 0.1682\n",
      "Epoch [10/50], Step [367/735], Loss: 0.0794\n",
      "Epoch [10/50], Step [368/735], Loss: 0.2261\n",
      "Epoch [10/50], Step [369/735], Loss: 0.4565\n",
      "Epoch [10/50], Step [370/735], Loss: 0.1228\n",
      "Epoch [10/50], Step [371/735], Loss: 0.1000\n",
      "Epoch [10/50], Step [372/735], Loss: 0.1412\n",
      "Epoch [10/50], Step [373/735], Loss: 1.3227\n",
      "Epoch [10/50], Step [374/735], Loss: 0.1098\n",
      "Epoch [10/50], Step [375/735], Loss: 0.1418\n",
      "Epoch [10/50], Step [376/735], Loss: 0.1210\n",
      "Epoch [10/50], Step [377/735], Loss: 0.0583\n",
      "Epoch [10/50], Step [378/735], Loss: 0.0636\n",
      "Epoch [10/50], Step [379/735], Loss: 0.1177\n",
      "Epoch [10/50], Step [380/735], Loss: 0.0915\n",
      "Epoch [10/50], Step [381/735], Loss: 0.0694\n",
      "Epoch [10/50], Step [382/735], Loss: 1.0133\n",
      "Epoch [10/50], Step [383/735], Loss: 0.2384\n",
      "Epoch [10/50], Step [384/735], Loss: 0.1392\n",
      "Epoch [10/50], Step [385/735], Loss: 0.2540\n",
      "Epoch [10/50], Step [386/735], Loss: 0.1459\n",
      "Epoch [10/50], Step [387/735], Loss: 0.2496\n",
      "Epoch [10/50], Step [388/735], Loss: 0.2573\n",
      "Epoch [10/50], Step [389/735], Loss: 0.0673\n",
      "Epoch [10/50], Step [390/735], Loss: 0.1890\n",
      "Epoch [10/50], Step [391/735], Loss: 0.2347\n",
      "Epoch [10/50], Step [392/735], Loss: 0.1581\n",
      "Epoch [10/50], Step [393/735], Loss: 0.1361\n",
      "Epoch [10/50], Step [394/735], Loss: 0.6821\n",
      "Epoch [10/50], Step [395/735], Loss: 0.1397\n",
      "Epoch [10/50], Step [396/735], Loss: 0.0702\n",
      "Epoch [10/50], Step [397/735], Loss: 0.1783\n",
      "Epoch [10/50], Step [398/735], Loss: 0.0511\n",
      "Epoch [10/50], Step [399/735], Loss: 0.0784\n",
      "Epoch [10/50], Step [400/735], Loss: 0.1492\n",
      "Epoch [10/50], Step [401/735], Loss: 0.5526\n",
      "Epoch [10/50], Step [402/735], Loss: 0.1435\n",
      "Epoch [10/50], Step [403/735], Loss: 0.2939\n",
      "Epoch [10/50], Step [404/735], Loss: 0.1444\n",
      "Epoch [10/50], Step [405/735], Loss: 0.0779\n",
      "Epoch [10/50], Step [406/735], Loss: 0.0778\n",
      "Epoch [10/50], Step [407/735], Loss: 0.5040\n",
      "Epoch [10/50], Step [408/735], Loss: 0.2315\n",
      "Epoch [10/50], Step [409/735], Loss: 0.0711\n",
      "Epoch [10/50], Step [410/735], Loss: 0.1465\n",
      "Epoch [10/50], Step [411/735], Loss: 0.1944\n",
      "Epoch [10/50], Step [412/735], Loss: 0.1090\n",
      "Epoch [10/50], Step [413/735], Loss: 0.1056\n",
      "Epoch [10/50], Step [414/735], Loss: 0.0774\n",
      "Epoch [10/50], Step [415/735], Loss: 0.1592\n",
      "Epoch [10/50], Step [416/735], Loss: 0.1452\n",
      "Epoch [10/50], Step [417/735], Loss: 0.2199\n",
      "Epoch [10/50], Step [418/735], Loss: 0.4037\n",
      "Epoch [10/50], Step [419/735], Loss: 0.2278\n",
      "Epoch [10/50], Step [420/735], Loss: 0.1537\n",
      "Epoch [10/50], Step [421/735], Loss: 0.5051\n",
      "Epoch [10/50], Step [422/735], Loss: 0.2256\n",
      "Epoch [10/50], Step [423/735], Loss: 2.9470\n",
      "Epoch [10/50], Step [424/735], Loss: 0.2445\n",
      "Epoch [10/50], Step [425/735], Loss: 0.1460\n",
      "Epoch [10/50], Step [426/735], Loss: 0.9464\n",
      "Epoch [10/50], Step [427/735], Loss: 0.1013\n",
      "Epoch [10/50], Step [428/735], Loss: 0.2598\n",
      "Epoch [10/50], Step [429/735], Loss: 1.4461\n",
      "Epoch [10/50], Step [430/735], Loss: 0.2808\n",
      "Epoch [10/50], Step [431/735], Loss: 0.1018\n",
      "Epoch [10/50], Step [432/735], Loss: 0.0988\n",
      "Epoch [10/50], Step [433/735], Loss: 0.3044\n",
      "Epoch [10/50], Step [434/735], Loss: 0.0572\n",
      "Epoch [10/50], Step [435/735], Loss: 1.0101\n",
      "Epoch [10/50], Step [436/735], Loss: 0.1402\n",
      "Epoch [10/50], Step [437/735], Loss: 0.2605\n",
      "Epoch [10/50], Step [438/735], Loss: 1.9842\n",
      "Epoch [10/50], Step [439/735], Loss: 0.2829\n",
      "Epoch [10/50], Step [440/735], Loss: 0.2532\n",
      "Epoch [10/50], Step [441/735], Loss: 0.2684\n",
      "Epoch [10/50], Step [442/735], Loss: 0.2223\n",
      "Epoch [10/50], Step [443/735], Loss: 0.1356\n",
      "Epoch [10/50], Step [444/735], Loss: 0.0475\n",
      "Epoch [10/50], Step [445/735], Loss: 0.1089\n",
      "Epoch [10/50], Step [446/735], Loss: 0.1111\n",
      "Epoch [10/50], Step [447/735], Loss: 0.0886\n",
      "Epoch [10/50], Step [448/735], Loss: 0.1304\n",
      "Epoch [10/50], Step [449/735], Loss: 0.2948\n",
      "Epoch [10/50], Step [450/735], Loss: 0.1508\n",
      "Epoch [10/50], Step [451/735], Loss: 0.2288\n",
      "Epoch [10/50], Step [452/735], Loss: 0.2341\n",
      "Epoch [10/50], Step [453/735], Loss: 0.1207\n",
      "Epoch [10/50], Step [454/735], Loss: 0.0650\n",
      "Epoch [10/50], Step [455/735], Loss: 0.0490\n",
      "Epoch [10/50], Step [456/735], Loss: 0.3493\n",
      "Epoch [10/50], Step [457/735], Loss: 0.2509\n",
      "Epoch [10/50], Step [458/735], Loss: 0.2619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Step [459/735], Loss: 0.1762\n",
      "Epoch [10/50], Step [460/735], Loss: 0.2211\n",
      "Epoch [10/50], Step [461/735], Loss: 0.5012\n",
      "Epoch [10/50], Step [462/735], Loss: 0.0928\n",
      "Epoch [10/50], Step [463/735], Loss: 1.3474\n",
      "Epoch [10/50], Step [464/735], Loss: 0.2422\n",
      "Epoch [10/50], Step [465/735], Loss: 0.3292\n",
      "Epoch [10/50], Step [466/735], Loss: 0.1464\n",
      "Epoch [10/50], Step [467/735], Loss: 0.0441\n",
      "Epoch [10/50], Step [468/735], Loss: 0.2133\n",
      "Epoch [10/50], Step [469/735], Loss: 0.2194\n",
      "Epoch [10/50], Step [470/735], Loss: 0.2395\n",
      "Epoch [10/50], Step [471/735], Loss: 0.2514\n",
      "Epoch [10/50], Step [472/735], Loss: 0.0695\n",
      "Epoch [10/50], Step [473/735], Loss: 0.1299\n",
      "Epoch [10/50], Step [474/735], Loss: 0.2637\n",
      "Epoch [10/50], Step [475/735], Loss: 0.1154\n",
      "Epoch [10/50], Step [476/735], Loss: 0.2799\n",
      "Epoch [10/50], Step [477/735], Loss: 0.0754\n",
      "Epoch [10/50], Step [478/735], Loss: 0.0790\n",
      "Epoch [10/50], Step [479/735], Loss: 0.3579\n",
      "Epoch [10/50], Step [480/735], Loss: 0.3081\n",
      "Epoch [10/50], Step [481/735], Loss: 0.1526\n",
      "Epoch [10/50], Step [482/735], Loss: 0.2184\n",
      "Epoch [10/50], Step [483/735], Loss: 0.0550\n",
      "Epoch [10/50], Step [484/735], Loss: 0.0546\n",
      "Epoch [10/50], Step [485/735], Loss: 0.2779\n",
      "Epoch [10/50], Step [486/735], Loss: 0.1435\n",
      "Epoch [10/50], Step [487/735], Loss: 0.1040\n",
      "Epoch [10/50], Step [488/735], Loss: 0.2038\n",
      "Epoch [10/50], Step [489/735], Loss: 0.0919\n",
      "Epoch [10/50], Step [490/735], Loss: 0.3847\n",
      "Epoch [10/50], Step [491/735], Loss: 0.1191\n",
      "Epoch [10/50], Step [492/735], Loss: 0.3293\n",
      "Epoch [10/50], Step [493/735], Loss: 0.1686\n",
      "Epoch [10/50], Step [494/735], Loss: 0.1320\n",
      "Epoch [10/50], Step [495/735], Loss: 0.1119\n",
      "Epoch [10/50], Step [496/735], Loss: 0.1204\n",
      "Epoch [10/50], Step [497/735], Loss: 1.0968\n",
      "Epoch [10/50], Step [498/735], Loss: 0.3304\n",
      "Epoch [10/50], Step [499/735], Loss: 0.1477\n",
      "Epoch [10/50], Step [500/735], Loss: 0.2558\n",
      "Epoch [10/50], Step [501/735], Loss: 0.1922\n",
      "Epoch [10/50], Step [502/735], Loss: 0.2098\n",
      "Epoch [10/50], Step [503/735], Loss: 0.7178\n",
      "Epoch [10/50], Step [504/735], Loss: 0.4738\n",
      "Epoch [10/50], Step [505/735], Loss: 0.1387\n",
      "Epoch [10/50], Step [506/735], Loss: 0.0865\n",
      "Epoch [10/50], Step [507/735], Loss: 0.1107\n",
      "Epoch [10/50], Step [508/735], Loss: 0.2918\n",
      "Epoch [10/50], Step [509/735], Loss: 0.1482\n",
      "Epoch [10/50], Step [510/735], Loss: 0.1399\n",
      "Epoch [10/50], Step [511/735], Loss: 0.3050\n",
      "Epoch [10/50], Step [512/735], Loss: 0.1173\n",
      "Epoch [10/50], Step [513/735], Loss: 0.3794\n",
      "Epoch [10/50], Step [514/735], Loss: 0.4555\n",
      "Epoch [10/50], Step [515/735], Loss: 0.8606\n",
      "Epoch [10/50], Step [516/735], Loss: 0.2418\n",
      "Epoch [10/50], Step [517/735], Loss: 0.2919\n",
      "Epoch [10/50], Step [518/735], Loss: 0.1709\n",
      "Epoch [10/50], Step [519/735], Loss: 0.2393\n",
      "Epoch [10/50], Step [520/735], Loss: 0.0473\n",
      "Epoch [10/50], Step [521/735], Loss: 0.1211\n",
      "Epoch [10/50], Step [522/735], Loss: 0.3555\n",
      "Epoch [10/50], Step [523/735], Loss: 0.1148\n",
      "Epoch [10/50], Step [524/735], Loss: 1.1129\n",
      "Epoch [10/50], Step [525/735], Loss: 0.1044\n",
      "Epoch [10/50], Step [526/735], Loss: 0.1233\n",
      "Epoch [10/50], Step [527/735], Loss: 0.0465\n",
      "Epoch [10/50], Step [528/735], Loss: 0.3511\n",
      "Epoch [10/50], Step [529/735], Loss: 0.6347\n",
      "Epoch [10/50], Step [530/735], Loss: 0.2971\n",
      "Epoch [10/50], Step [531/735], Loss: 0.2658\n",
      "Epoch [10/50], Step [532/735], Loss: 0.2076\n",
      "Epoch [10/50], Step [533/735], Loss: 0.1073\n",
      "Epoch [10/50], Step [534/735], Loss: 0.2029\n",
      "Epoch [10/50], Step [535/735], Loss: 0.1986\n",
      "Epoch [10/50], Step [536/735], Loss: 0.2034\n",
      "Epoch [10/50], Step [537/735], Loss: 0.0942\n",
      "Epoch [10/50], Step [538/735], Loss: 0.0615\n",
      "Epoch [10/50], Step [539/735], Loss: 0.2512\n",
      "Epoch [10/50], Step [540/735], Loss: 0.0851\n",
      "Epoch [10/50], Step [541/735], Loss: 0.2367\n",
      "Epoch [10/50], Step [542/735], Loss: 0.1081\n",
      "Epoch [10/50], Step [543/735], Loss: 0.2768\n",
      "Epoch [10/50], Step [544/735], Loss: 0.3241\n",
      "Epoch [10/50], Step [545/735], Loss: 0.0786\n",
      "Epoch [10/50], Step [546/735], Loss: 0.1135\n",
      "Epoch [10/50], Step [547/735], Loss: 0.1842\n",
      "Epoch [10/50], Step [548/735], Loss: 0.1080\n",
      "Epoch [10/50], Step [549/735], Loss: 0.1279\n",
      "Epoch [10/50], Step [550/735], Loss: 0.3990\n",
      "Epoch [10/50], Step [551/735], Loss: 0.4169\n",
      "Epoch [10/50], Step [552/735], Loss: 0.0354\n",
      "Epoch [10/50], Step [553/735], Loss: 0.0857\n",
      "Epoch [10/50], Step [554/735], Loss: 0.1353\n",
      "Epoch [10/50], Step [555/735], Loss: 0.3379\n",
      "Epoch [10/50], Step [556/735], Loss: 0.1129\n",
      "Epoch [10/50], Step [557/735], Loss: 0.2785\n",
      "Epoch [10/50], Step [558/735], Loss: 0.3326\n",
      "Epoch [10/50], Step [559/735], Loss: 0.4189\n",
      "Epoch [10/50], Step [560/735], Loss: 0.1979\n",
      "Epoch [10/50], Step [561/735], Loss: 0.1777\n",
      "Epoch [10/50], Step [562/735], Loss: 0.1865\n",
      "Epoch [10/50], Step [563/735], Loss: 0.1464\n",
      "Epoch [10/50], Step [564/735], Loss: 0.3363\n",
      "Epoch [10/50], Step [565/735], Loss: 0.1111\n",
      "Epoch [10/50], Step [566/735], Loss: 0.7341\n",
      "Epoch [10/50], Step [567/735], Loss: 0.1798\n",
      "Epoch [10/50], Step [568/735], Loss: 0.1131\n",
      "Epoch [10/50], Step [569/735], Loss: 0.1823\n",
      "Epoch [10/50], Step [570/735], Loss: 0.0568\n",
      "Epoch [10/50], Step [571/735], Loss: 0.1145\n",
      "Epoch [10/50], Step [572/735], Loss: 0.3177\n",
      "Epoch [10/50], Step [573/735], Loss: 0.0878\n",
      "Epoch [10/50], Step [574/735], Loss: 0.0561\n",
      "Epoch [10/50], Step [575/735], Loss: 0.2701\n",
      "Epoch [10/50], Step [576/735], Loss: 2.6094\n",
      "Epoch [10/50], Step [577/735], Loss: 0.3925\n",
      "Epoch [10/50], Step [578/735], Loss: 0.1526\n",
      "Epoch [10/50], Step [579/735], Loss: 0.1628\n",
      "Epoch [10/50], Step [580/735], Loss: 0.1709\n",
      "Epoch [10/50], Step [581/735], Loss: 0.5129\n",
      "Epoch [10/50], Step [582/735], Loss: 0.1094\n",
      "Epoch [10/50], Step [583/735], Loss: 0.2411\n",
      "Epoch [10/50], Step [584/735], Loss: 0.1292\n",
      "Epoch [10/50], Step [585/735], Loss: 0.1423\n",
      "Epoch [10/50], Step [586/735], Loss: 0.2997\n",
      "Epoch [10/50], Step [587/735], Loss: 0.1404\n",
      "Epoch [10/50], Step [588/735], Loss: 0.1568\n",
      "Epoch [10/50], Step [589/735], Loss: 0.2291\n",
      "Epoch [10/50], Step [590/735], Loss: 0.2178\n",
      "Epoch [10/50], Step [591/735], Loss: 0.1751\n",
      "Epoch [10/50], Step [592/735], Loss: 0.0726\n",
      "Epoch [10/50], Step [593/735], Loss: 0.0701\n",
      "Epoch [10/50], Step [594/735], Loss: 0.1593\n",
      "Epoch [10/50], Step [595/735], Loss: 0.1056\n",
      "Epoch [10/50], Step [596/735], Loss: 0.2773\n",
      "Epoch [10/50], Step [597/735], Loss: 0.0738\n",
      "Epoch [10/50], Step [598/735], Loss: 0.0601\n",
      "Epoch [10/50], Step [599/735], Loss: 2.4949\n",
      "Epoch [10/50], Step [600/735], Loss: 0.1232\n",
      "Epoch [10/50], Step [601/735], Loss: 0.1739\n",
      "Epoch [10/50], Step [602/735], Loss: 0.1002\n",
      "Epoch [10/50], Step [603/735], Loss: 0.5509\n",
      "Epoch [10/50], Step [604/735], Loss: 0.4956\n",
      "Epoch [10/50], Step [605/735], Loss: 0.0483\n",
      "Epoch [10/50], Step [606/735], Loss: 0.0579\n",
      "Epoch [10/50], Step [607/735], Loss: 0.1371\n",
      "Epoch [10/50], Step [608/735], Loss: 0.0871\n",
      "Epoch [10/50], Step [609/735], Loss: 0.8633\n",
      "Epoch [10/50], Step [610/735], Loss: 0.1153\n",
      "Epoch [10/50], Step [611/735], Loss: 0.0812\n",
      "Epoch [10/50], Step [612/735], Loss: 0.1135\n",
      "Epoch [10/50], Step [613/735], Loss: 0.0842\n",
      "Epoch [10/50], Step [614/735], Loss: 0.2289\n",
      "Epoch [10/50], Step [615/735], Loss: 0.0934\n",
      "Epoch [10/50], Step [616/735], Loss: 0.1914\n",
      "Epoch [10/50], Step [617/735], Loss: 0.3315\n",
      "Epoch [10/50], Step [618/735], Loss: 0.1943\n",
      "Epoch [10/50], Step [619/735], Loss: 0.4484\n",
      "Epoch [10/50], Step [620/735], Loss: 0.3964\n",
      "Epoch [10/50], Step [621/735], Loss: 0.1799\n",
      "Epoch [10/50], Step [622/735], Loss: 0.1655\n",
      "Epoch [10/50], Step [623/735], Loss: 0.1316\n",
      "Epoch [10/50], Step [624/735], Loss: 0.0715\n",
      "Epoch [10/50], Step [625/735], Loss: 0.1533\n",
      "Epoch [10/50], Step [626/735], Loss: 0.2329\n",
      "Epoch [10/50], Step [627/735], Loss: 0.1302\n",
      "Epoch [10/50], Step [628/735], Loss: 0.3792\n",
      "Epoch [10/50], Step [629/735], Loss: 0.3350\n",
      "Epoch [10/50], Step [630/735], Loss: 0.0783\n",
      "Epoch [10/50], Step [631/735], Loss: 0.9833\n",
      "Epoch [10/50], Step [632/735], Loss: 0.2516\n",
      "Epoch [10/50], Step [633/735], Loss: 1.0523\n",
      "Epoch [10/50], Step [634/735], Loss: 0.2069\n",
      "Epoch [10/50], Step [635/735], Loss: 0.0593\n",
      "Epoch [10/50], Step [636/735], Loss: 0.2282\n",
      "Epoch [10/50], Step [637/735], Loss: 0.1017\n",
      "Epoch [10/50], Step [638/735], Loss: 0.0774\n",
      "Epoch [10/50], Step [639/735], Loss: 0.2048\n",
      "Epoch [10/50], Step [640/735], Loss: 0.5174\n",
      "Epoch [10/50], Step [641/735], Loss: 0.2578\n",
      "Epoch [10/50], Step [642/735], Loss: 0.1522\n",
      "Epoch [10/50], Step [643/735], Loss: 0.1869\n",
      "Epoch [10/50], Step [644/735], Loss: 0.0635\n",
      "Epoch [10/50], Step [645/735], Loss: 0.3120\n",
      "Epoch [10/50], Step [646/735], Loss: 0.1629\n",
      "Epoch [10/50], Step [647/735], Loss: 0.3288\n",
      "Epoch [10/50], Step [648/735], Loss: 0.0997\n",
      "Epoch [10/50], Step [649/735], Loss: 0.0966\n",
      "Epoch [10/50], Step [650/735], Loss: 0.2947\n",
      "Epoch [10/50], Step [651/735], Loss: 0.1175\n",
      "Epoch [10/50], Step [652/735], Loss: 0.5378\n",
      "Epoch [10/50], Step [653/735], Loss: 0.3242\n",
      "Epoch [10/50], Step [654/735], Loss: 0.2633\n",
      "Epoch [10/50], Step [655/735], Loss: 0.1644\n",
      "Epoch [10/50], Step [656/735], Loss: 0.1926\n",
      "Epoch [10/50], Step [657/735], Loss: 0.1087\n",
      "Epoch [10/50], Step [658/735], Loss: 0.0620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Step [659/735], Loss: 0.0366\n",
      "Epoch [10/50], Step [660/735], Loss: 0.3112\n",
      "Epoch [10/50], Step [661/735], Loss: 0.0670\n",
      "Epoch [10/50], Step [662/735], Loss: 0.0535\n",
      "Epoch [10/50], Step [663/735], Loss: 0.2942\n",
      "Epoch [10/50], Step [664/735], Loss: 0.2661\n",
      "Epoch [10/50], Step [665/735], Loss: 0.2624\n",
      "Epoch [10/50], Step [666/735], Loss: 0.1275\n",
      "Epoch [10/50], Step [667/735], Loss: 0.2658\n",
      "Epoch [10/50], Step [668/735], Loss: 0.6364\n",
      "Epoch [10/50], Step [669/735], Loss: 0.2859\n",
      "Epoch [10/50], Step [670/735], Loss: 0.2320\n",
      "Epoch [10/50], Step [671/735], Loss: 0.2353\n",
      "Epoch [10/50], Step [672/735], Loss: 0.3232\n",
      "Epoch [10/50], Step [673/735], Loss: 0.0622\n",
      "Epoch [10/50], Step [674/735], Loss: 0.1640\n",
      "Epoch [10/50], Step [675/735], Loss: 0.1751\n",
      "Epoch [10/50], Step [676/735], Loss: 0.0838\n",
      "Epoch [10/50], Step [677/735], Loss: 0.3051\n",
      "Epoch [10/50], Step [678/735], Loss: 0.2234\n",
      "Epoch [10/50], Step [679/735], Loss: 0.1749\n",
      "Epoch [10/50], Step [680/735], Loss: 0.1556\n",
      "Epoch [10/50], Step [681/735], Loss: 0.0565\n",
      "Epoch [10/50], Step [682/735], Loss: 0.7022\n",
      "Epoch [10/50], Step [683/735], Loss: 0.1594\n",
      "Epoch [10/50], Step [684/735], Loss: 0.1678\n",
      "Epoch [10/50], Step [685/735], Loss: 0.1980\n",
      "Epoch [10/50], Step [686/735], Loss: 0.1946\n",
      "Epoch [10/50], Step [687/735], Loss: 0.0611\n",
      "Epoch [10/50], Step [688/735], Loss: 0.8424\n",
      "Epoch [10/50], Step [689/735], Loss: 0.0550\n",
      "Epoch [10/50], Step [690/735], Loss: 0.6682\n",
      "Epoch [10/50], Step [691/735], Loss: 0.3356\n",
      "Epoch [10/50], Step [692/735], Loss: 0.1001\n",
      "Epoch [10/50], Step [693/735], Loss: 0.1151\n",
      "Epoch [10/50], Step [694/735], Loss: 0.1812\n",
      "Epoch [10/50], Step [695/735], Loss: 0.2566\n",
      "Epoch [10/50], Step [696/735], Loss: 0.3011\n",
      "Epoch [10/50], Step [697/735], Loss: 0.1607\n",
      "Epoch [10/50], Step [698/735], Loss: 0.2625\n",
      "Epoch [10/50], Step [699/735], Loss: 1.6252\n",
      "Epoch [10/50], Step [700/735], Loss: 0.2001\n",
      "Epoch [10/50], Step [701/735], Loss: 0.0768\n",
      "Epoch [10/50], Step [702/735], Loss: 0.0678\n",
      "Epoch [10/50], Step [703/735], Loss: 0.2441\n",
      "Epoch [10/50], Step [704/735], Loss: 0.1977\n",
      "Epoch [10/50], Step [705/735], Loss: 0.1784\n",
      "Epoch [10/50], Step [706/735], Loss: 0.3482\n",
      "Epoch [10/50], Step [707/735], Loss: 0.1953\n",
      "Epoch [10/50], Step [708/735], Loss: 0.6639\n",
      "Epoch [10/50], Step [709/735], Loss: 0.4324\n",
      "Epoch [10/50], Step [710/735], Loss: 0.2490\n",
      "Epoch [10/50], Step [711/735], Loss: 0.0645\n",
      "Epoch [10/50], Step [712/735], Loss: 0.1156\n",
      "Epoch [10/50], Step [713/735], Loss: 0.2905\n",
      "Epoch [10/50], Step [714/735], Loss: 0.4115\n",
      "Epoch [10/50], Step [715/735], Loss: 0.1940\n",
      "Epoch [10/50], Step [716/735], Loss: 0.1047\n",
      "Epoch [10/50], Step [717/735], Loss: 0.1303\n",
      "Epoch [10/50], Step [718/735], Loss: 0.1333\n",
      "Epoch [10/50], Step [719/735], Loss: 0.1501\n",
      "Epoch [10/50], Step [720/735], Loss: 0.1982\n",
      "Epoch [10/50], Step [721/735], Loss: 0.6245\n",
      "Epoch [10/50], Step [722/735], Loss: 0.0888\n",
      "Epoch [10/50], Step [723/735], Loss: 0.1987\n",
      "Epoch [10/50], Step [724/735], Loss: 0.1208\n",
      "Epoch [10/50], Step [725/735], Loss: 0.2172\n",
      "Epoch [10/50], Step [726/735], Loss: 0.0464\n",
      "Epoch [10/50], Step [727/735], Loss: 0.1280\n",
      "Epoch [10/50], Step [728/735], Loss: 0.0720\n",
      "Epoch [10/50], Step [729/735], Loss: 0.1548\n",
      "Epoch [10/50], Step [730/735], Loss: 0.1944\n",
      "Epoch [10/50], Step [731/735], Loss: 0.1784\n",
      "Epoch [10/50], Step [732/735], Loss: 0.1310\n",
      "Epoch [10/50], Step [733/735], Loss: 0.4124\n",
      "Epoch [10/50], Step [734/735], Loss: 0.1412\n",
      "Epoch [10/50], Step [735/735], Loss: 0.1391\n",
      "Epoch [11/50], Step [1/735], Loss: 0.1840\n",
      "Epoch [11/50], Step [2/735], Loss: 0.1749\n",
      "Epoch [11/50], Step [3/735], Loss: 0.2093\n",
      "Epoch [11/50], Step [4/735], Loss: 0.0995\n",
      "Epoch [11/50], Step [5/735], Loss: 0.0923\n",
      "Epoch [11/50], Step [6/735], Loss: 0.4190\n",
      "Epoch [11/50], Step [7/735], Loss: 0.0594\n",
      "Epoch [11/50], Step [8/735], Loss: 0.1120\n",
      "Epoch [11/50], Step [9/735], Loss: 0.1451\n",
      "Epoch [11/50], Step [10/735], Loss: 0.1082\n",
      "Epoch [11/50], Step [11/735], Loss: 0.1117\n",
      "Epoch [11/50], Step [12/735], Loss: 0.0641\n",
      "Epoch [11/50], Step [13/735], Loss: 0.3245\n",
      "Epoch [11/50], Step [14/735], Loss: 0.0993\n",
      "Epoch [11/50], Step [15/735], Loss: 0.1630\n",
      "Epoch [11/50], Step [16/735], Loss: 0.1062\n",
      "Epoch [11/50], Step [17/735], Loss: 0.1834\n",
      "Epoch [11/50], Step [18/735], Loss: 0.0790\n",
      "Epoch [11/50], Step [19/735], Loss: 0.0990\n",
      "Epoch [11/50], Step [20/735], Loss: 0.0823\n",
      "Epoch [11/50], Step [21/735], Loss: 0.1548\n",
      "Epoch [11/50], Step [22/735], Loss: 0.0554\n",
      "Epoch [11/50], Step [23/735], Loss: 0.3606\n",
      "Epoch [11/50], Step [24/735], Loss: 0.0805\n",
      "Epoch [11/50], Step [25/735], Loss: 0.1366\n",
      "Epoch [11/50], Step [26/735], Loss: 0.2483\n",
      "Epoch [11/50], Step [27/735], Loss: 0.1080\n",
      "Epoch [11/50], Step [28/735], Loss: 0.2349\n",
      "Epoch [11/50], Step [29/735], Loss: 0.1827\n",
      "Epoch [11/50], Step [30/735], Loss: 0.0605\n",
      "Epoch [11/50], Step [31/735], Loss: 0.2358\n",
      "Epoch [11/50], Step [32/735], Loss: 0.0502\n",
      "Epoch [11/50], Step [33/735], Loss: 0.0300\n",
      "Epoch [11/50], Step [34/735], Loss: 0.3167\n",
      "Epoch [11/50], Step [35/735], Loss: 0.3427\n",
      "Epoch [11/50], Step [36/735], Loss: 0.3498\n",
      "Epoch [11/50], Step [37/735], Loss: 0.2031\n",
      "Epoch [11/50], Step [38/735], Loss: 0.2416\n",
      "Epoch [11/50], Step [39/735], Loss: 0.0470\n",
      "Epoch [11/50], Step [40/735], Loss: 0.2486\n",
      "Epoch [11/50], Step [41/735], Loss: 0.0591\n",
      "Epoch [11/50], Step [42/735], Loss: 0.0765\n",
      "Epoch [11/50], Step [43/735], Loss: 0.1757\n",
      "Epoch [11/50], Step [44/735], Loss: 0.0520\n",
      "Epoch [11/50], Step [45/735], Loss: 0.3657\n",
      "Epoch [11/50], Step [46/735], Loss: 0.2224\n",
      "Epoch [11/50], Step [47/735], Loss: 0.2197\n",
      "Epoch [11/50], Step [48/735], Loss: 1.3639\n",
      "Epoch [11/50], Step [49/735], Loss: 1.5058\n",
      "Epoch [11/50], Step [50/735], Loss: 0.0990\n",
      "Epoch [11/50], Step [51/735], Loss: 0.3195\n",
      "Epoch [11/50], Step [52/735], Loss: 0.1618\n",
      "Epoch [11/50], Step [53/735], Loss: 0.2009\n",
      "Epoch [11/50], Step [54/735], Loss: 0.0729\n",
      "Epoch [11/50], Step [55/735], Loss: 0.2101\n",
      "Epoch [11/50], Step [56/735], Loss: 0.1607\n",
      "Epoch [11/50], Step [57/735], Loss: 0.1414\n",
      "Epoch [11/50], Step [58/735], Loss: 0.2644\n",
      "Epoch [11/50], Step [59/735], Loss: 0.4149\n",
      "Epoch [11/50], Step [60/735], Loss: 0.1973\n",
      "Epoch [11/50], Step [61/735], Loss: 0.2071\n",
      "Epoch [11/50], Step [62/735], Loss: 0.1635\n",
      "Epoch [11/50], Step [63/735], Loss: 0.0626\n",
      "Epoch [11/50], Step [64/735], Loss: 0.0731\n",
      "Epoch [11/50], Step [65/735], Loss: 0.1866\n",
      "Epoch [11/50], Step [66/735], Loss: 0.3086\n",
      "Epoch [11/50], Step [67/735], Loss: 0.0660\n",
      "Epoch [11/50], Step [68/735], Loss: 0.0591\n",
      "Epoch [11/50], Step [69/735], Loss: 0.2504\n",
      "Epoch [11/50], Step [70/735], Loss: 0.2628\n",
      "Epoch [11/50], Step [71/735], Loss: 0.1284\n",
      "Epoch [11/50], Step [72/735], Loss: 0.1824\n",
      "Epoch [11/50], Step [73/735], Loss: 0.3880\n",
      "Epoch [11/50], Step [74/735], Loss: 0.8136\n",
      "Epoch [11/50], Step [75/735], Loss: 0.0778\n",
      "Epoch [11/50], Step [76/735], Loss: 0.3241\n",
      "Epoch [11/50], Step [77/735], Loss: 0.1494\n",
      "Epoch [11/50], Step [78/735], Loss: 0.1140\n",
      "Epoch [11/50], Step [79/735], Loss: 0.9710\n",
      "Epoch [11/50], Step [80/735], Loss: 0.0796\n",
      "Epoch [11/50], Step [81/735], Loss: 0.2699\n",
      "Epoch [11/50], Step [82/735], Loss: 0.0617\n",
      "Epoch [11/50], Step [83/735], Loss: 0.1745\n",
      "Epoch [11/50], Step [84/735], Loss: 0.3015\n",
      "Epoch [11/50], Step [85/735], Loss: 0.1600\n",
      "Epoch [11/50], Step [86/735], Loss: 0.1213\n",
      "Epoch [11/50], Step [87/735], Loss: 0.0533\n",
      "Epoch [11/50], Step [88/735], Loss: 0.1314\n",
      "Epoch [11/50], Step [89/735], Loss: 0.1258\n",
      "Epoch [11/50], Step [90/735], Loss: 0.1345\n",
      "Epoch [11/50], Step [91/735], Loss: 0.1220\n",
      "Epoch [11/50], Step [92/735], Loss: 0.0340\n",
      "Epoch [11/50], Step [93/735], Loss: 0.1910\n",
      "Epoch [11/50], Step [94/735], Loss: 0.1406\n",
      "Epoch [11/50], Step [95/735], Loss: 2.2837\n",
      "Epoch [11/50], Step [96/735], Loss: 0.2483\n",
      "Epoch [11/50], Step [97/735], Loss: 0.9213\n",
      "Epoch [11/50], Step [98/735], Loss: 0.0827\n",
      "Epoch [11/50], Step [99/735], Loss: 0.1061\n",
      "Epoch [11/50], Step [100/735], Loss: 0.1375\n",
      "Epoch [11/50], Step [101/735], Loss: 0.1878\n",
      "Epoch [11/50], Step [102/735], Loss: 0.2934\n",
      "Epoch [11/50], Step [103/735], Loss: 0.2046\n",
      "Epoch [11/50], Step [104/735], Loss: 0.2027\n",
      "Epoch [11/50], Step [105/735], Loss: 1.2317\n",
      "Epoch [11/50], Step [106/735], Loss: 0.2955\n",
      "Epoch [11/50], Step [107/735], Loss: 0.3079\n",
      "Epoch [11/50], Step [108/735], Loss: 0.1165\n",
      "Epoch [11/50], Step [109/735], Loss: 0.2913\n",
      "Epoch [11/50], Step [110/735], Loss: 0.2958\n",
      "Epoch [11/50], Step [111/735], Loss: 0.1341\n",
      "Epoch [11/50], Step [112/735], Loss: 0.1563\n",
      "Epoch [11/50], Step [113/735], Loss: 0.2204\n",
      "Epoch [11/50], Step [114/735], Loss: 0.4275\n",
      "Epoch [11/50], Step [115/735], Loss: 0.2194\n",
      "Epoch [11/50], Step [116/735], Loss: 0.2475\n",
      "Epoch [11/50], Step [117/735], Loss: 0.1392\n",
      "Epoch [11/50], Step [118/735], Loss: 0.0924\n",
      "Epoch [11/50], Step [119/735], Loss: 0.1085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Step [120/735], Loss: 0.1949\n",
      "Epoch [11/50], Step [121/735], Loss: 0.0806\n",
      "Epoch [11/50], Step [122/735], Loss: 0.2396\n",
      "Epoch [11/50], Step [123/735], Loss: 0.0497\n",
      "Epoch [11/50], Step [124/735], Loss: 0.1048\n",
      "Epoch [11/50], Step [125/735], Loss: 0.1010\n",
      "Epoch [11/50], Step [126/735], Loss: 0.1181\n",
      "Epoch [11/50], Step [127/735], Loss: 0.2051\n",
      "Epoch [11/50], Step [128/735], Loss: 0.2301\n",
      "Epoch [11/50], Step [129/735], Loss: 0.0750\n",
      "Epoch [11/50], Step [130/735], Loss: 0.2142\n",
      "Epoch [11/50], Step [131/735], Loss: 0.2550\n",
      "Epoch [11/50], Step [132/735], Loss: 0.1684\n",
      "Epoch [11/50], Step [133/735], Loss: 0.4991\n",
      "Epoch [11/50], Step [134/735], Loss: 0.1614\n",
      "Epoch [11/50], Step [135/735], Loss: 0.0738\n",
      "Epoch [11/50], Step [136/735], Loss: 0.0757\n",
      "Epoch [11/50], Step [137/735], Loss: 0.5168\n",
      "Epoch [11/50], Step [138/735], Loss: 0.2132\n",
      "Epoch [11/50], Step [139/735], Loss: 0.0936\n",
      "Epoch [11/50], Step [140/735], Loss: 0.1032\n",
      "Epoch [11/50], Step [141/735], Loss: 0.2770\n",
      "Epoch [11/50], Step [142/735], Loss: 0.0676\n",
      "Epoch [11/50], Step [143/735], Loss: 0.3575\n",
      "Epoch [11/50], Step [144/735], Loss: 0.0859\n",
      "Epoch [11/50], Step [145/735], Loss: 0.3383\n",
      "Epoch [11/50], Step [146/735], Loss: 0.1431\n",
      "Epoch [11/50], Step [147/735], Loss: 0.1032\n",
      "Epoch [11/50], Step [148/735], Loss: 0.1228\n",
      "Epoch [11/50], Step [149/735], Loss: 0.2297\n",
      "Epoch [11/50], Step [150/735], Loss: 0.2426\n",
      "Epoch [11/50], Step [151/735], Loss: 0.1332\n",
      "Epoch [11/50], Step [152/735], Loss: 1.3364\n",
      "Epoch [11/50], Step [153/735], Loss: 0.1714\n",
      "Epoch [11/50], Step [154/735], Loss: 0.4445\n",
      "Epoch [11/50], Step [155/735], Loss: 0.5625\n",
      "Epoch [11/50], Step [156/735], Loss: 0.3228\n",
      "Epoch [11/50], Step [157/735], Loss: 0.2282\n",
      "Epoch [11/50], Step [158/735], Loss: 0.1072\n",
      "Epoch [11/50], Step [159/735], Loss: 0.1676\n",
      "Epoch [11/50], Step [160/735], Loss: 0.1101\n",
      "Epoch [11/50], Step [161/735], Loss: 0.0732\n",
      "Epoch [11/50], Step [162/735], Loss: 0.1360\n",
      "Epoch [11/50], Step [163/735], Loss: 0.3366\n",
      "Epoch [11/50], Step [164/735], Loss: 0.0955\n",
      "Epoch [11/50], Step [165/735], Loss: 0.0583\n",
      "Epoch [11/50], Step [166/735], Loss: 0.1296\n",
      "Epoch [11/50], Step [167/735], Loss: 0.3530\n",
      "Epoch [11/50], Step [168/735], Loss: 0.1403\n",
      "Epoch [11/50], Step [169/735], Loss: 0.1027\n",
      "Epoch [11/50], Step [170/735], Loss: 0.2112\n",
      "Epoch [11/50], Step [171/735], Loss: 0.0910\n",
      "Epoch [11/50], Step [172/735], Loss: 0.2075\n",
      "Epoch [11/50], Step [173/735], Loss: 0.0922\n",
      "Epoch [11/50], Step [174/735], Loss: 0.2725\n",
      "Epoch [11/50], Step [175/735], Loss: 0.0638\n",
      "Epoch [11/50], Step [176/735], Loss: 0.1819\n",
      "Epoch [11/50], Step [177/735], Loss: 0.1035\n",
      "Epoch [11/50], Step [178/735], Loss: 0.1650\n",
      "Epoch [11/50], Step [179/735], Loss: 0.0845\n",
      "Epoch [11/50], Step [180/735], Loss: 0.1660\n",
      "Epoch [11/50], Step [181/735], Loss: 0.1065\n",
      "Epoch [11/50], Step [182/735], Loss: 0.0587\n",
      "Epoch [11/50], Step [183/735], Loss: 0.1888\n",
      "Epoch [11/50], Step [184/735], Loss: 0.1128\n",
      "Epoch [11/50], Step [185/735], Loss: 0.6533\n",
      "Epoch [11/50], Step [186/735], Loss: 0.0453\n",
      "Epoch [11/50], Step [187/735], Loss: 0.2151\n",
      "Epoch [11/50], Step [188/735], Loss: 0.0540\n",
      "Epoch [11/50], Step [189/735], Loss: 0.0704\n",
      "Epoch [11/50], Step [190/735], Loss: 0.2834\n",
      "Epoch [11/50], Step [191/735], Loss: 0.1738\n",
      "Epoch [11/50], Step [192/735], Loss: 0.1534\n",
      "Epoch [11/50], Step [193/735], Loss: 0.0432\n",
      "Epoch [11/50], Step [194/735], Loss: 0.2875\n",
      "Epoch [11/50], Step [195/735], Loss: 0.2837\n",
      "Epoch [11/50], Step [196/735], Loss: 0.1112\n",
      "Epoch [11/50], Step [197/735], Loss: 0.0977\n",
      "Epoch [11/50], Step [198/735], Loss: 0.2508\n",
      "Epoch [11/50], Step [199/735], Loss: 1.9718\n",
      "Epoch [11/50], Step [200/735], Loss: 0.9274\n",
      "Epoch [11/50], Step [201/735], Loss: 0.2254\n",
      "Epoch [11/50], Step [202/735], Loss: 0.2498\n",
      "Epoch [11/50], Step [203/735], Loss: 1.0486\n",
      "Epoch [11/50], Step [204/735], Loss: 0.1927\n",
      "Epoch [11/50], Step [205/735], Loss: 0.1711\n",
      "Epoch [11/50], Step [206/735], Loss: 0.5600\n",
      "Epoch [11/50], Step [207/735], Loss: 0.1396\n",
      "Epoch [11/50], Step [208/735], Loss: 0.1292\n",
      "Epoch [11/50], Step [209/735], Loss: 0.3148\n",
      "Epoch [11/50], Step [210/735], Loss: 0.2871\n",
      "Epoch [11/50], Step [211/735], Loss: 0.3127\n",
      "Epoch [11/50], Step [212/735], Loss: 0.1464\n",
      "Epoch [11/50], Step [213/735], Loss: 0.1796\n",
      "Epoch [11/50], Step [214/735], Loss: 0.0720\n",
      "Epoch [11/50], Step [215/735], Loss: 0.0793\n",
      "Epoch [11/50], Step [216/735], Loss: 0.0541\n",
      "Epoch [11/50], Step [217/735], Loss: 0.0624\n",
      "Epoch [11/50], Step [218/735], Loss: 0.2823\n",
      "Epoch [11/50], Step [219/735], Loss: 0.1678\n",
      "Epoch [11/50], Step [220/735], Loss: 0.1483\n",
      "Epoch [11/50], Step [221/735], Loss: 0.2729\n",
      "Epoch [11/50], Step [222/735], Loss: 0.2076\n",
      "Epoch [11/50], Step [223/735], Loss: 0.0756\n",
      "Epoch [11/50], Step [224/735], Loss: 0.2791\n",
      "Epoch [11/50], Step [225/735], Loss: 0.0659\n",
      "Epoch [11/50], Step [226/735], Loss: 0.0813\n",
      "Epoch [11/50], Step [227/735], Loss: 0.1851\n",
      "Epoch [11/50], Step [228/735], Loss: 0.0912\n",
      "Epoch [11/50], Step [229/735], Loss: 0.1412\n",
      "Epoch [11/50], Step [230/735], Loss: 0.1230\n",
      "Epoch [11/50], Step [231/735], Loss: 0.0656\n",
      "Epoch [11/50], Step [232/735], Loss: 0.0967\n",
      "Epoch [11/50], Step [233/735], Loss: 0.9113\n",
      "Epoch [11/50], Step [234/735], Loss: 0.0813\n",
      "Epoch [11/50], Step [235/735], Loss: 0.1487\n",
      "Epoch [11/50], Step [236/735], Loss: 0.1982\n",
      "Epoch [11/50], Step [237/735], Loss: 0.0971\n",
      "Epoch [11/50], Step [238/735], Loss: 0.2743\n",
      "Epoch [11/50], Step [239/735], Loss: 0.1178\n",
      "Epoch [11/50], Step [240/735], Loss: 0.0756\n",
      "Epoch [11/50], Step [241/735], Loss: 0.0906\n",
      "Epoch [11/50], Step [242/735], Loss: 0.1131\n",
      "Epoch [11/50], Step [243/735], Loss: 0.1209\n",
      "Epoch [11/50], Step [244/735], Loss: 0.0761\n",
      "Epoch [11/50], Step [245/735], Loss: 0.1121\n",
      "Epoch [11/50], Step [246/735], Loss: 0.0984\n",
      "Epoch [11/50], Step [247/735], Loss: 0.1571\n",
      "Epoch [11/50], Step [248/735], Loss: 0.2358\n",
      "Epoch [11/50], Step [249/735], Loss: 0.1167\n",
      "Epoch [11/50], Step [250/735], Loss: 0.2981\n",
      "Epoch [11/50], Step [251/735], Loss: 0.1571\n",
      "Epoch [11/50], Step [252/735], Loss: 0.1663\n",
      "Epoch [11/50], Step [253/735], Loss: 0.1383\n",
      "Epoch [11/50], Step [254/735], Loss: 0.1337\n",
      "Epoch [11/50], Step [255/735], Loss: 0.2541\n",
      "Epoch [11/50], Step [256/735], Loss: 0.1326\n",
      "Epoch [11/50], Step [257/735], Loss: 0.2182\n",
      "Epoch [11/50], Step [258/735], Loss: 0.1799\n",
      "Epoch [11/50], Step [259/735], Loss: 0.1710\n",
      "Epoch [11/50], Step [260/735], Loss: 0.0664\n",
      "Epoch [11/50], Step [261/735], Loss: 0.1060\n",
      "Epoch [11/50], Step [262/735], Loss: 0.1507\n",
      "Epoch [11/50], Step [263/735], Loss: 0.2611\n",
      "Epoch [11/50], Step [264/735], Loss: 1.0672\n",
      "Epoch [11/50], Step [265/735], Loss: 0.2912\n",
      "Epoch [11/50], Step [266/735], Loss: 0.5062\n",
      "Epoch [11/50], Step [267/735], Loss: 1.0415\n",
      "Epoch [11/50], Step [268/735], Loss: 0.0578\n",
      "Epoch [11/50], Step [269/735], Loss: 0.1134\n",
      "Epoch [11/50], Step [270/735], Loss: 0.6439\n",
      "Epoch [11/50], Step [271/735], Loss: 0.2273\n",
      "Epoch [11/50], Step [272/735], Loss: 0.1770\n",
      "Epoch [11/50], Step [273/735], Loss: 0.1160\n",
      "Epoch [11/50], Step [274/735], Loss: 0.5365\n",
      "Epoch [11/50], Step [275/735], Loss: 0.1277\n",
      "Epoch [11/50], Step [276/735], Loss: 0.5704\n",
      "Epoch [11/50], Step [277/735], Loss: 0.2523\n",
      "Epoch [11/50], Step [278/735], Loss: 0.5174\n",
      "Epoch [11/50], Step [279/735], Loss: 0.1361\n",
      "Epoch [11/50], Step [280/735], Loss: 0.0855\n",
      "Epoch [11/50], Step [281/735], Loss: 0.4461\n",
      "Epoch [11/50], Step [282/735], Loss: 0.1311\n",
      "Epoch [11/50], Step [283/735], Loss: 0.1216\n",
      "Epoch [11/50], Step [284/735], Loss: 0.2603\n",
      "Epoch [11/50], Step [285/735], Loss: 0.1114\n",
      "Epoch [11/50], Step [286/735], Loss: 0.2456\n",
      "Epoch [11/50], Step [287/735], Loss: 1.4561\n",
      "Epoch [11/50], Step [288/735], Loss: 2.2452\n",
      "Epoch [11/50], Step [289/735], Loss: 0.1922\n",
      "Epoch [11/50], Step [290/735], Loss: 0.0597\n",
      "Epoch [11/50], Step [291/735], Loss: 0.0993\n",
      "Epoch [11/50], Step [292/735], Loss: 0.1309\n",
      "Epoch [11/50], Step [293/735], Loss: 0.1714\n",
      "Epoch [11/50], Step [294/735], Loss: 0.1452\n",
      "Epoch [11/50], Step [295/735], Loss: 0.3340\n",
      "Epoch [11/50], Step [296/735], Loss: 0.5114\n",
      "Epoch [11/50], Step [297/735], Loss: 0.1095\n",
      "Epoch [11/50], Step [298/735], Loss: 0.4378\n",
      "Epoch [11/50], Step [299/735], Loss: 0.3354\n",
      "Epoch [11/50], Step [300/735], Loss: 0.8828\n",
      "Epoch [11/50], Step [301/735], Loss: 0.0557\n",
      "Epoch [11/50], Step [302/735], Loss: 0.2024\n",
      "Epoch [11/50], Step [303/735], Loss: 0.1819\n",
      "Epoch [11/50], Step [304/735], Loss: 0.3889\n",
      "Epoch [11/50], Step [305/735], Loss: 0.1317\n",
      "Epoch [11/50], Step [306/735], Loss: 0.5447\n",
      "Epoch [11/50], Step [307/735], Loss: 0.2202\n",
      "Epoch [11/50], Step [308/735], Loss: 0.1330\n",
      "Epoch [11/50], Step [309/735], Loss: 0.0766\n",
      "Epoch [11/50], Step [310/735], Loss: 0.2112\n",
      "Epoch [11/50], Step [311/735], Loss: 0.1613\n",
      "Epoch [11/50], Step [312/735], Loss: 0.1366\n",
      "Epoch [11/50], Step [313/735], Loss: 0.0532\n",
      "Epoch [11/50], Step [314/735], Loss: 0.1882\n",
      "Epoch [11/50], Step [315/735], Loss: 0.1758\n",
      "Epoch [11/50], Step [316/735], Loss: 0.2017\n",
      "Epoch [11/50], Step [317/735], Loss: 0.1720\n",
      "Epoch [11/50], Step [318/735], Loss: 0.6432\n",
      "Epoch [11/50], Step [319/735], Loss: 0.0793\n",
      "Epoch [11/50], Step [320/735], Loss: 0.2475\n",
      "Epoch [11/50], Step [321/735], Loss: 0.1628\n",
      "Epoch [11/50], Step [322/735], Loss: 0.1415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Step [323/735], Loss: 0.3376\n",
      "Epoch [11/50], Step [324/735], Loss: 0.1986\n",
      "Epoch [11/50], Step [325/735], Loss: 0.3210\n",
      "Epoch [11/50], Step [326/735], Loss: 0.0952\n",
      "Epoch [11/50], Step [327/735], Loss: 0.1740\n",
      "Epoch [11/50], Step [328/735], Loss: 0.2237\n",
      "Epoch [11/50], Step [329/735], Loss: 0.4446\n",
      "Epoch [11/50], Step [330/735], Loss: 0.2720\n",
      "Epoch [11/50], Step [331/735], Loss: 0.2960\n",
      "Epoch [11/50], Step [332/735], Loss: 0.1251\n",
      "Epoch [11/50], Step [333/735], Loss: 0.0824\n",
      "Epoch [11/50], Step [334/735], Loss: 0.2125\n",
      "Epoch [11/50], Step [335/735], Loss: 0.1953\n",
      "Epoch [11/50], Step [336/735], Loss: 0.1250\n",
      "Epoch [11/50], Step [337/735], Loss: 0.2680\n",
      "Epoch [11/50], Step [338/735], Loss: 0.1073\n",
      "Epoch [11/50], Step [339/735], Loss: 0.0719\n",
      "Epoch [11/50], Step [340/735], Loss: 0.0680\n",
      "Epoch [11/50], Step [341/735], Loss: 0.1776\n",
      "Epoch [11/50], Step [342/735], Loss: 0.1002\n",
      "Epoch [11/50], Step [343/735], Loss: 0.1397\n",
      "Epoch [11/50], Step [344/735], Loss: 0.0722\n",
      "Epoch [11/50], Step [345/735], Loss: 0.0411\n",
      "Epoch [11/50], Step [346/735], Loss: 0.2154\n",
      "Epoch [11/50], Step [347/735], Loss: 0.4174\n",
      "Epoch [11/50], Step [348/735], Loss: 0.2826\n",
      "Epoch [11/50], Step [349/735], Loss: 0.1379\n",
      "Epoch [11/50], Step [350/735], Loss: 0.1244\n",
      "Epoch [11/50], Step [351/735], Loss: 0.1031\n",
      "Epoch [11/50], Step [352/735], Loss: 1.0395\n",
      "Epoch [11/50], Step [353/735], Loss: 0.1017\n",
      "Epoch [11/50], Step [354/735], Loss: 0.1625\n",
      "Epoch [11/50], Step [355/735], Loss: 0.3105\n",
      "Epoch [11/50], Step [356/735], Loss: 0.0768\n",
      "Epoch [11/50], Step [357/735], Loss: 0.0844\n",
      "Epoch [11/50], Step [358/735], Loss: 0.1219\n",
      "Epoch [11/50], Step [359/735], Loss: 0.3621\n",
      "Epoch [11/50], Step [360/735], Loss: 2.3309\n",
      "Epoch [11/50], Step [361/735], Loss: 0.1124\n",
      "Epoch [11/50], Step [362/735], Loss: 0.2132\n",
      "Epoch [11/50], Step [363/735], Loss: 0.2444\n",
      "Epoch [11/50], Step [364/735], Loss: 0.0966\n",
      "Epoch [11/50], Step [365/735], Loss: 0.1106\n",
      "Epoch [11/50], Step [366/735], Loss: 0.2376\n",
      "Epoch [11/50], Step [367/735], Loss: 0.2033\n",
      "Epoch [11/50], Step [368/735], Loss: 0.1391\n",
      "Epoch [11/50], Step [369/735], Loss: 0.0461\n",
      "Epoch [11/50], Step [370/735], Loss: 1.9285\n",
      "Epoch [11/50], Step [371/735], Loss: 0.3174\n",
      "Epoch [11/50], Step [372/735], Loss: 0.1950\n",
      "Epoch [11/50], Step [373/735], Loss: 0.1817\n",
      "Epoch [11/50], Step [374/735], Loss: 0.5190\n",
      "Epoch [11/50], Step [375/735], Loss: 0.4287\n",
      "Epoch [11/50], Step [376/735], Loss: 0.0664\n",
      "Epoch [11/50], Step [377/735], Loss: 0.1316\n",
      "Epoch [11/50], Step [378/735], Loss: 0.1357\n",
      "Epoch [11/50], Step [379/735], Loss: 0.1397\n",
      "Epoch [11/50], Step [380/735], Loss: 0.3745\n",
      "Epoch [11/50], Step [381/735], Loss: 0.1610\n",
      "Epoch [11/50], Step [382/735], Loss: 0.3026\n",
      "Epoch [11/50], Step [383/735], Loss: 0.3051\n",
      "Epoch [11/50], Step [384/735], Loss: 0.1261\n",
      "Epoch [11/50], Step [385/735], Loss: 0.1712\n",
      "Epoch [11/50], Step [386/735], Loss: 0.2451\n",
      "Epoch [11/50], Step [387/735], Loss: 0.2573\n",
      "Epoch [11/50], Step [388/735], Loss: 0.2659\n",
      "Epoch [11/50], Step [389/735], Loss: 0.0848\n",
      "Epoch [11/50], Step [390/735], Loss: 0.1522\n",
      "Epoch [11/50], Step [391/735], Loss: 0.2254\n",
      "Epoch [11/50], Step [392/735], Loss: 0.0867\n",
      "Epoch [11/50], Step [393/735], Loss: 0.1366\n",
      "Epoch [11/50], Step [394/735], Loss: 0.1382\n",
      "Epoch [11/50], Step [395/735], Loss: 0.4159\n",
      "Epoch [11/50], Step [396/735], Loss: 0.2571\n",
      "Epoch [11/50], Step [397/735], Loss: 0.2180\n",
      "Epoch [11/50], Step [398/735], Loss: 0.6086\n",
      "Epoch [11/50], Step [399/735], Loss: 0.2725\n",
      "Epoch [11/50], Step [400/735], Loss: 0.1121\n",
      "Epoch [11/50], Step [401/735], Loss: 0.2314\n",
      "Epoch [11/50], Step [402/735], Loss: 0.1461\n",
      "Epoch [11/50], Step [403/735], Loss: 0.0843\n",
      "Epoch [11/50], Step [404/735], Loss: 0.3184\n",
      "Epoch [11/50], Step [405/735], Loss: 0.2003\n",
      "Epoch [11/50], Step [406/735], Loss: 0.1769\n",
      "Epoch [11/50], Step [407/735], Loss: 0.1288\n",
      "Epoch [11/50], Step [408/735], Loss: 0.5187\n",
      "Epoch [11/50], Step [409/735], Loss: 0.1320\n",
      "Epoch [11/50], Step [410/735], Loss: 0.3400\n",
      "Epoch [11/50], Step [411/735], Loss: 0.1039\n",
      "Epoch [11/50], Step [412/735], Loss: 0.1836\n",
      "Epoch [11/50], Step [413/735], Loss: 0.2568\n",
      "Epoch [11/50], Step [414/735], Loss: 0.1472\n",
      "Epoch [11/50], Step [415/735], Loss: 0.0563\n",
      "Epoch [11/50], Step [416/735], Loss: 0.3176\n",
      "Epoch [11/50], Step [417/735], Loss: 2.2482\n",
      "Epoch [11/50], Step [418/735], Loss: 0.3113\n",
      "Epoch [11/50], Step [419/735], Loss: 0.0920\n",
      "Epoch [11/50], Step [420/735], Loss: 0.1269\n",
      "Epoch [11/50], Step [421/735], Loss: 0.1652\n",
      "Epoch [11/50], Step [422/735], Loss: 0.1802\n",
      "Epoch [11/50], Step [423/735], Loss: 0.1391\n",
      "Epoch [11/50], Step [424/735], Loss: 0.1086\n",
      "Epoch [11/50], Step [425/735], Loss: 0.1100\n",
      "Epoch [11/50], Step [426/735], Loss: 0.0996\n",
      "Epoch [11/50], Step [427/735], Loss: 0.1103\n",
      "Epoch [11/50], Step [428/735], Loss: 0.9097\n",
      "Epoch [11/50], Step [429/735], Loss: 0.1885\n",
      "Epoch [11/50], Step [430/735], Loss: 0.1726\n",
      "Epoch [11/50], Step [431/735], Loss: 0.1432\n",
      "Epoch [11/50], Step [432/735], Loss: 0.1507\n",
      "Epoch [11/50], Step [433/735], Loss: 0.1838\n",
      "Epoch [11/50], Step [434/735], Loss: 0.0664\n",
      "Epoch [11/50], Step [435/735], Loss: 0.3149\n",
      "Epoch [11/50], Step [436/735], Loss: 0.3429\n",
      "Epoch [11/50], Step [437/735], Loss: 0.1150\n",
      "Epoch [11/50], Step [438/735], Loss: 0.0958\n",
      "Epoch [11/50], Step [439/735], Loss: 0.2007\n",
      "Epoch [11/50], Step [440/735], Loss: 0.1290\n",
      "Epoch [11/50], Step [441/735], Loss: 0.1921\n",
      "Epoch [11/50], Step [442/735], Loss: 0.1975\n",
      "Epoch [11/50], Step [443/735], Loss: 0.1563\n",
      "Epoch [11/50], Step [444/735], Loss: 0.1660\n",
      "Epoch [11/50], Step [445/735], Loss: 0.1678\n",
      "Epoch [11/50], Step [446/735], Loss: 0.1870\n",
      "Epoch [11/50], Step [447/735], Loss: 0.1424\n",
      "Epoch [11/50], Step [448/735], Loss: 0.0972\n",
      "Epoch [11/50], Step [449/735], Loss: 0.0936\n",
      "Epoch [11/50], Step [450/735], Loss: 0.2447\n",
      "Epoch [11/50], Step [451/735], Loss: 0.1312\n",
      "Epoch [11/50], Step [452/735], Loss: 0.1718\n",
      "Epoch [11/50], Step [453/735], Loss: 0.7414\n",
      "Epoch [11/50], Step [454/735], Loss: 0.1174\n",
      "Epoch [11/50], Step [455/735], Loss: 0.1645\n",
      "Epoch [11/50], Step [456/735], Loss: 0.0860\n",
      "Epoch [11/50], Step [457/735], Loss: 0.0479\n",
      "Epoch [11/50], Step [458/735], Loss: 0.3852\n",
      "Epoch [11/50], Step [459/735], Loss: 0.0933\n",
      "Epoch [11/50], Step [460/735], Loss: 0.1142\n",
      "Epoch [11/50], Step [461/735], Loss: 0.9458\n",
      "Epoch [11/50], Step [462/735], Loss: 0.1650\n",
      "Epoch [11/50], Step [463/735], Loss: 0.1260\n",
      "Epoch [11/50], Step [464/735], Loss: 0.1773\n",
      "Epoch [11/50], Step [465/735], Loss: 0.2971\n",
      "Epoch [11/50], Step [466/735], Loss: 0.2513\n",
      "Epoch [11/50], Step [467/735], Loss: 0.1614\n",
      "Epoch [11/50], Step [468/735], Loss: 0.4218\n",
      "Epoch [11/50], Step [469/735], Loss: 0.1068\n",
      "Epoch [11/50], Step [470/735], Loss: 0.4354\n",
      "Epoch [11/50], Step [471/735], Loss: 0.1972\n",
      "Epoch [11/50], Step [472/735], Loss: 0.1025\n",
      "Epoch [11/50], Step [473/735], Loss: 0.0991\n",
      "Epoch [11/50], Step [474/735], Loss: 0.2242\n",
      "Epoch [11/50], Step [475/735], Loss: 0.1671\n",
      "Epoch [11/50], Step [476/735], Loss: 0.9753\n",
      "Epoch [11/50], Step [477/735], Loss: 1.0221\n",
      "Epoch [11/50], Step [478/735], Loss: 0.1407\n",
      "Epoch [11/50], Step [479/735], Loss: 0.2130\n",
      "Epoch [11/50], Step [480/735], Loss: 0.2368\n",
      "Epoch [11/50], Step [481/735], Loss: 0.6436\n",
      "Epoch [11/50], Step [482/735], Loss: 0.1725\n",
      "Epoch [11/50], Step [483/735], Loss: 0.2993\n",
      "Epoch [11/50], Step [484/735], Loss: 0.1978\n",
      "Epoch [11/50], Step [485/735], Loss: 1.2893\n",
      "Epoch [11/50], Step [486/735], Loss: 0.1524\n",
      "Epoch [11/50], Step [487/735], Loss: 0.0919\n",
      "Epoch [11/50], Step [488/735], Loss: 0.3630\n",
      "Epoch [11/50], Step [489/735], Loss: 0.2604\n",
      "Epoch [11/50], Step [490/735], Loss: 0.2571\n",
      "Epoch [11/50], Step [491/735], Loss: 0.2140\n",
      "Epoch [11/50], Step [492/735], Loss: 0.1236\n",
      "Epoch [11/50], Step [493/735], Loss: 0.1167\n",
      "Epoch [11/50], Step [494/735], Loss: 0.2232\n",
      "Epoch [11/50], Step [495/735], Loss: 0.0967\n",
      "Epoch [11/50], Step [496/735], Loss: 0.1920\n",
      "Epoch [11/50], Step [497/735], Loss: 2.1653\n",
      "Epoch [11/50], Step [498/735], Loss: 0.1814\n",
      "Epoch [11/50], Step [499/735], Loss: 0.4287\n",
      "Epoch [11/50], Step [500/735], Loss: 0.0711\n",
      "Epoch [11/50], Step [501/735], Loss: 0.2233\n",
      "Epoch [11/50], Step [502/735], Loss: 0.1265\n",
      "Epoch [11/50], Step [503/735], Loss: 0.2754\n",
      "Epoch [11/50], Step [504/735], Loss: 0.1247\n",
      "Epoch [11/50], Step [505/735], Loss: 0.2038\n",
      "Epoch [11/50], Step [506/735], Loss: 0.3993\n",
      "Epoch [11/50], Step [507/735], Loss: 0.2083\n",
      "Epoch [11/50], Step [508/735], Loss: 0.2284\n",
      "Epoch [11/50], Step [509/735], Loss: 0.2837\n",
      "Epoch [11/50], Step [510/735], Loss: 0.1322\n",
      "Epoch [11/50], Step [511/735], Loss: 0.2392\n",
      "Epoch [11/50], Step [512/735], Loss: 0.1328\n",
      "Epoch [11/50], Step [513/735], Loss: 0.1547\n",
      "Epoch [11/50], Step [514/735], Loss: 0.1586\n",
      "Epoch [11/50], Step [515/735], Loss: 0.1309\n",
      "Epoch [11/50], Step [516/735], Loss: 0.6052\n",
      "Epoch [11/50], Step [517/735], Loss: 0.1535\n",
      "Epoch [11/50], Step [518/735], Loss: 0.1704\n",
      "Epoch [11/50], Step [519/735], Loss: 0.1745\n",
      "Epoch [11/50], Step [520/735], Loss: 0.1381\n",
      "Epoch [11/50], Step [521/735], Loss: 0.3200\n",
      "Epoch [11/50], Step [522/735], Loss: 0.1471\n",
      "Epoch [11/50], Step [523/735], Loss: 0.1465\n",
      "Epoch [11/50], Step [524/735], Loss: 0.2302\n",
      "Epoch [11/50], Step [525/735], Loss: 0.0518\n",
      "Epoch [11/50], Step [526/735], Loss: 0.2294\n",
      "Epoch [11/50], Step [527/735], Loss: 0.3477\n",
      "Epoch [11/50], Step [528/735], Loss: 0.1136\n",
      "Epoch [11/50], Step [529/735], Loss: 0.0819\n",
      "Epoch [11/50], Step [530/735], Loss: 0.0500\n",
      "Epoch [11/50], Step [531/735], Loss: 0.1198\n",
      "Epoch [11/50], Step [532/735], Loss: 0.1575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Step [533/735], Loss: 0.2104\n",
      "Epoch [11/50], Step [534/735], Loss: 0.4508\n",
      "Epoch [11/50], Step [535/735], Loss: 0.2864\n",
      "Epoch [11/50], Step [536/735], Loss: 0.2451\n",
      "Epoch [11/50], Step [537/735], Loss: 0.2606\n",
      "Epoch [11/50], Step [538/735], Loss: 0.1363\n",
      "Epoch [11/50], Step [539/735], Loss: 0.0828\n",
      "Epoch [11/50], Step [540/735], Loss: 0.2778\n",
      "Epoch [11/50], Step [541/735], Loss: 0.2259\n",
      "Epoch [11/50], Step [542/735], Loss: 0.2337\n",
      "Epoch [11/50], Step [543/735], Loss: 0.1590\n",
      "Epoch [11/50], Step [544/735], Loss: 0.1033\n",
      "Epoch [11/50], Step [545/735], Loss: 0.2835\n",
      "Epoch [11/50], Step [546/735], Loss: 0.1451\n",
      "Epoch [11/50], Step [547/735], Loss: 0.3392\n",
      "Epoch [11/50], Step [548/735], Loss: 0.1018\n",
      "Epoch [11/50], Step [549/735], Loss: 0.1328\n",
      "Epoch [11/50], Step [550/735], Loss: 0.1917\n",
      "Epoch [11/50], Step [551/735], Loss: 0.0824\n",
      "Epoch [11/50], Step [552/735], Loss: 0.1058\n",
      "Epoch [11/50], Step [553/735], Loss: 0.1231\n",
      "Epoch [11/50], Step [554/735], Loss: 0.0509\n",
      "Epoch [11/50], Step [555/735], Loss: 0.0509\n",
      "Epoch [11/50], Step [556/735], Loss: 0.1985\n",
      "Epoch [11/50], Step [557/735], Loss: 0.1001\n",
      "Epoch [11/50], Step [558/735], Loss: 0.0827\n",
      "Epoch [11/50], Step [559/735], Loss: 0.4054\n",
      "Epoch [11/50], Step [560/735], Loss: 0.0907\n",
      "Epoch [11/50], Step [561/735], Loss: 0.1149\n",
      "Epoch [11/50], Step [562/735], Loss: 0.1344\n",
      "Epoch [11/50], Step [563/735], Loss: 0.2235\n",
      "Epoch [11/50], Step [564/735], Loss: 0.2312\n",
      "Epoch [11/50], Step [565/735], Loss: 0.1336\n",
      "Epoch [11/50], Step [566/735], Loss: 0.2478\n",
      "Epoch [11/50], Step [567/735], Loss: 0.1785\n",
      "Epoch [11/50], Step [568/735], Loss: 0.0680\n",
      "Epoch [11/50], Step [569/735], Loss: 0.1284\n",
      "Epoch [11/50], Step [570/735], Loss: 0.3643\n",
      "Epoch [11/50], Step [571/735], Loss: 0.1916\n",
      "Epoch [11/50], Step [572/735], Loss: 0.0623\n",
      "Epoch [11/50], Step [573/735], Loss: 0.1028\n",
      "Epoch [11/50], Step [574/735], Loss: 0.0652\n",
      "Epoch [11/50], Step [575/735], Loss: 0.0914\n",
      "Epoch [11/50], Step [576/735], Loss: 0.1451\n",
      "Epoch [11/50], Step [577/735], Loss: 0.2738\n",
      "Epoch [11/50], Step [578/735], Loss: 0.2188\n",
      "Epoch [11/50], Step [579/735], Loss: 0.0597\n",
      "Epoch [11/50], Step [580/735], Loss: 0.0813\n",
      "Epoch [11/50], Step [581/735], Loss: 0.0908\n",
      "Epoch [11/50], Step [582/735], Loss: 0.1053\n",
      "Epoch [11/50], Step [583/735], Loss: 0.1422\n",
      "Epoch [11/50], Step [584/735], Loss: 0.1621\n",
      "Epoch [11/50], Step [585/735], Loss: 0.1153\n",
      "Epoch [11/50], Step [586/735], Loss: 0.1148\n",
      "Epoch [11/50], Step [587/735], Loss: 0.1061\n",
      "Epoch [11/50], Step [588/735], Loss: 0.0467\n",
      "Epoch [11/50], Step [589/735], Loss: 0.5062\n",
      "Epoch [11/50], Step [590/735], Loss: 0.5545\n",
      "Epoch [11/50], Step [591/735], Loss: 0.2059\n",
      "Epoch [11/50], Step [592/735], Loss: 0.0853\n",
      "Epoch [11/50], Step [593/735], Loss: 0.3547\n",
      "Epoch [11/50], Step [594/735], Loss: 0.0385\n",
      "Epoch [11/50], Step [595/735], Loss: 0.9043\n",
      "Epoch [11/50], Step [596/735], Loss: 0.0974\n",
      "Epoch [11/50], Step [597/735], Loss: 0.2441\n",
      "Epoch [11/50], Step [598/735], Loss: 0.1677\n",
      "Epoch [11/50], Step [599/735], Loss: 0.1054\n",
      "Epoch [11/50], Step [600/735], Loss: 0.8909\n",
      "Epoch [11/50], Step [601/735], Loss: 0.3204\n",
      "Epoch [11/50], Step [602/735], Loss: 0.0672\n",
      "Epoch [11/50], Step [603/735], Loss: 0.7845\n",
      "Epoch [11/50], Step [604/735], Loss: 0.1394\n",
      "Epoch [11/50], Step [605/735], Loss: 0.0880\n",
      "Epoch [11/50], Step [606/735], Loss: 0.2107\n",
      "Epoch [11/50], Step [607/735], Loss: 0.0727\n",
      "Epoch [11/50], Step [608/735], Loss: 0.0577\n",
      "Epoch [11/50], Step [609/735], Loss: 0.2814\n",
      "Epoch [11/50], Step [610/735], Loss: 0.1654\n",
      "Epoch [11/50], Step [611/735], Loss: 0.0974\n",
      "Epoch [11/50], Step [612/735], Loss: 0.0882\n",
      "Epoch [11/50], Step [613/735], Loss: 0.0849\n",
      "Epoch [11/50], Step [614/735], Loss: 0.1110\n",
      "Epoch [11/50], Step [615/735], Loss: 0.2230\n",
      "Epoch [11/50], Step [616/735], Loss: 0.1114\n",
      "Epoch [11/50], Step [617/735], Loss: 0.1880\n",
      "Epoch [11/50], Step [618/735], Loss: 0.0566\n",
      "Epoch [11/50], Step [619/735], Loss: 0.1564\n",
      "Epoch [11/50], Step [620/735], Loss: 0.1609\n",
      "Epoch [11/50], Step [621/735], Loss: 0.1547\n",
      "Epoch [11/50], Step [622/735], Loss: 0.0563\n",
      "Epoch [11/50], Step [623/735], Loss: 0.1359\n",
      "Epoch [11/50], Step [624/735], Loss: 0.2225\n",
      "Epoch [11/50], Step [625/735], Loss: 0.3382\n",
      "Epoch [11/50], Step [626/735], Loss: 0.1501\n",
      "Epoch [11/50], Step [627/735], Loss: 0.4978\n",
      "Epoch [11/50], Step [628/735], Loss: 0.6169\n",
      "Epoch [11/50], Step [629/735], Loss: 0.3181\n",
      "Epoch [11/50], Step [630/735], Loss: 0.4565\n",
      "Epoch [11/50], Step [631/735], Loss: 0.1921\n",
      "Epoch [11/50], Step [632/735], Loss: 0.1497\n",
      "Epoch [11/50], Step [633/735], Loss: 0.0972\n",
      "Epoch [11/50], Step [634/735], Loss: 0.1882\n",
      "Epoch [11/50], Step [635/735], Loss: 0.1222\n",
      "Epoch [11/50], Step [636/735], Loss: 0.1528\n",
      "Epoch [11/50], Step [637/735], Loss: 1.1801\n",
      "Epoch [11/50], Step [638/735], Loss: 0.1139\n",
      "Epoch [11/50], Step [639/735], Loss: 0.0368\n",
      "Epoch [11/50], Step [640/735], Loss: 0.1965\n",
      "Epoch [11/50], Step [641/735], Loss: 0.1331\n",
      "Epoch [11/50], Step [642/735], Loss: 0.1200\n",
      "Epoch [11/50], Step [643/735], Loss: 0.1192\n",
      "Epoch [11/50], Step [644/735], Loss: 0.0988\n",
      "Epoch [11/50], Step [645/735], Loss: 0.1338\n",
      "Epoch [11/50], Step [646/735], Loss: 0.0520\n",
      "Epoch [11/50], Step [647/735], Loss: 0.1915\n",
      "Epoch [11/50], Step [648/735], Loss: 0.3682\n",
      "Epoch [11/50], Step [649/735], Loss: 0.4455\n",
      "Epoch [11/50], Step [650/735], Loss: 0.0474\n",
      "Epoch [11/50], Step [651/735], Loss: 0.0661\n",
      "Epoch [11/50], Step [652/735], Loss: 0.2182\n",
      "Epoch [11/50], Step [653/735], Loss: 0.1775\n",
      "Epoch [11/50], Step [654/735], Loss: 0.1485\n",
      "Epoch [11/50], Step [655/735], Loss: 0.0948\n",
      "Epoch [11/50], Step [656/735], Loss: 0.1340\n",
      "Epoch [11/50], Step [657/735], Loss: 0.0368\n",
      "Epoch [11/50], Step [658/735], Loss: 0.0620\n",
      "Epoch [11/50], Step [659/735], Loss: 0.2199\n",
      "Epoch [11/50], Step [660/735], Loss: 0.0585\n",
      "Epoch [11/50], Step [661/735], Loss: 0.0847\n",
      "Epoch [11/50], Step [662/735], Loss: 0.1952\n",
      "Epoch [11/50], Step [663/735], Loss: 0.1472\n",
      "Epoch [11/50], Step [664/735], Loss: 0.0637\n",
      "Epoch [11/50], Step [665/735], Loss: 0.2756\n",
      "Epoch [11/50], Step [666/735], Loss: 0.1030\n",
      "Epoch [11/50], Step [667/735], Loss: 0.0894\n",
      "Epoch [11/50], Step [668/735], Loss: 0.0460\n",
      "Epoch [11/50], Step [669/735], Loss: 0.0865\n",
      "Epoch [11/50], Step [670/735], Loss: 1.0827\n",
      "Epoch [11/50], Step [671/735], Loss: 0.1382\n",
      "Epoch [11/50], Step [672/735], Loss: 0.0980\n",
      "Epoch [11/50], Step [673/735], Loss: 0.0832\n",
      "Epoch [11/50], Step [674/735], Loss: 0.2970\n",
      "Epoch [11/50], Step [675/735], Loss: 0.1106\n",
      "Epoch [11/50], Step [676/735], Loss: 0.1818\n",
      "Epoch [11/50], Step [677/735], Loss: 0.1546\n",
      "Epoch [11/50], Step [678/735], Loss: 0.1461\n",
      "Epoch [11/50], Step [679/735], Loss: 0.1732\n",
      "Epoch [11/50], Step [680/735], Loss: 0.1529\n",
      "Epoch [11/50], Step [681/735], Loss: 0.1478\n",
      "Epoch [11/50], Step [682/735], Loss: 0.1181\n",
      "Epoch [11/50], Step [683/735], Loss: 0.0608\n",
      "Epoch [11/50], Step [684/735], Loss: 0.1282\n",
      "Epoch [11/50], Step [685/735], Loss: 0.2443\n",
      "Epoch [11/50], Step [686/735], Loss: 0.9826\n",
      "Epoch [11/50], Step [687/735], Loss: 0.1899\n",
      "Epoch [11/50], Step [688/735], Loss: 0.1366\n",
      "Epoch [11/50], Step [689/735], Loss: 0.3159\n",
      "Epoch [11/50], Step [690/735], Loss: 0.4076\n",
      "Epoch [11/50], Step [691/735], Loss: 0.1019\n",
      "Epoch [11/50], Step [692/735], Loss: 0.0634\n",
      "Epoch [11/50], Step [693/735], Loss: 0.0935\n",
      "Epoch [11/50], Step [694/735], Loss: 0.0933\n",
      "Epoch [11/50], Step [695/735], Loss: 0.0613\n",
      "Epoch [11/50], Step [696/735], Loss: 0.0740\n",
      "Epoch [11/50], Step [697/735], Loss: 0.4186\n",
      "Epoch [11/50], Step [698/735], Loss: 0.0822\n",
      "Epoch [11/50], Step [699/735], Loss: 0.1841\n",
      "Epoch [11/50], Step [700/735], Loss: 0.0806\n",
      "Epoch [11/50], Step [701/735], Loss: 0.1062\n",
      "Epoch [11/50], Step [702/735], Loss: 0.1307\n",
      "Epoch [11/50], Step [703/735], Loss: 0.2398\n",
      "Epoch [11/50], Step [704/735], Loss: 0.0783\n",
      "Epoch [11/50], Step [705/735], Loss: 0.1807\n",
      "Epoch [11/50], Step [706/735], Loss: 0.1746\n",
      "Epoch [11/50], Step [707/735], Loss: 0.1131\n",
      "Epoch [11/50], Step [708/735], Loss: 0.0833\n",
      "Epoch [11/50], Step [709/735], Loss: 0.0796\n",
      "Epoch [11/50], Step [710/735], Loss: 0.1368\n",
      "Epoch [11/50], Step [711/735], Loss: 0.1877\n",
      "Epoch [11/50], Step [712/735], Loss: 0.0944\n",
      "Epoch [11/50], Step [713/735], Loss: 0.3386\n",
      "Epoch [11/50], Step [714/735], Loss: 0.4802\n",
      "Epoch [11/50], Step [715/735], Loss: 0.2002\n",
      "Epoch [11/50], Step [716/735], Loss: 0.1632\n",
      "Epoch [11/50], Step [717/735], Loss: 0.0951\n",
      "Epoch [11/50], Step [718/735], Loss: 0.0794\n",
      "Epoch [11/50], Step [719/735], Loss: 0.3932\n",
      "Epoch [11/50], Step [720/735], Loss: 0.2916\n",
      "Epoch [11/50], Step [721/735], Loss: 0.1148\n",
      "Epoch [11/50], Step [722/735], Loss: 0.0806\n",
      "Epoch [11/50], Step [723/735], Loss: 0.2411\n",
      "Epoch [11/50], Step [724/735], Loss: 0.0976\n",
      "Epoch [11/50], Step [725/735], Loss: 0.6723\n",
      "Epoch [11/50], Step [726/735], Loss: 0.1455\n",
      "Epoch [11/50], Step [727/735], Loss: 0.2430\n",
      "Epoch [11/50], Step [728/735], Loss: 0.3670\n",
      "Epoch [11/50], Step [729/735], Loss: 0.0709\n",
      "Epoch [11/50], Step [730/735], Loss: 0.3282\n",
      "Epoch [11/50], Step [731/735], Loss: 0.0410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Step [732/735], Loss: 0.2625\n",
      "Epoch [11/50], Step [733/735], Loss: 0.1273\n",
      "Epoch [11/50], Step [734/735], Loss: 0.3522\n",
      "Epoch [11/50], Step [735/735], Loss: 0.3644\n",
      "Epoch [12/50], Step [1/735], Loss: 0.1566\n",
      "Epoch [12/50], Step [2/735], Loss: 0.4610\n",
      "Epoch [12/50], Step [3/735], Loss: 0.1165\n",
      "Epoch [12/50], Step [4/735], Loss: 0.2477\n",
      "Epoch [12/50], Step [5/735], Loss: 0.0873\n",
      "Epoch [12/50], Step [6/735], Loss: 0.1515\n",
      "Epoch [12/50], Step [7/735], Loss: 0.0895\n",
      "Epoch [12/50], Step [8/735], Loss: 0.2095\n",
      "Epoch [12/50], Step [9/735], Loss: 0.1315\n",
      "Epoch [12/50], Step [10/735], Loss: 0.0363\n",
      "Epoch [12/50], Step [11/735], Loss: 0.1495\n",
      "Epoch [12/50], Step [12/735], Loss: 0.1508\n",
      "Epoch [12/50], Step [13/735], Loss: 0.0844\n",
      "Epoch [12/50], Step [14/735], Loss: 0.1657\n",
      "Epoch [12/50], Step [15/735], Loss: 0.1260\n",
      "Epoch [12/50], Step [16/735], Loss: 0.1081\n",
      "Epoch [12/50], Step [17/735], Loss: 0.0874\n",
      "Epoch [12/50], Step [18/735], Loss: 0.7929\n",
      "Epoch [12/50], Step [19/735], Loss: 0.1706\n",
      "Epoch [12/50], Step [20/735], Loss: 0.2098\n",
      "Epoch [12/50], Step [21/735], Loss: 0.1058\n",
      "Epoch [12/50], Step [22/735], Loss: 0.2525\n",
      "Epoch [12/50], Step [23/735], Loss: 0.1278\n",
      "Epoch [12/50], Step [24/735], Loss: 0.2937\n",
      "Epoch [12/50], Step [25/735], Loss: 0.2078\n",
      "Epoch [12/50], Step [26/735], Loss: 0.0769\n",
      "Epoch [12/50], Step [27/735], Loss: 0.2382\n",
      "Epoch [12/50], Step [28/735], Loss: 0.0629\n",
      "Epoch [12/50], Step [29/735], Loss: 0.0581\n",
      "Epoch [12/50], Step [30/735], Loss: 0.1479\n",
      "Epoch [12/50], Step [31/735], Loss: 0.1295\n",
      "Epoch [12/50], Step [32/735], Loss: 0.0889\n",
      "Epoch [12/50], Step [33/735], Loss: 0.0792\n",
      "Epoch [12/50], Step [34/735], Loss: 0.1851\n",
      "Epoch [12/50], Step [35/735], Loss: 0.2598\n",
      "Epoch [12/50], Step [36/735], Loss: 0.2424\n",
      "Epoch [12/50], Step [37/735], Loss: 0.1084\n",
      "Epoch [12/50], Step [38/735], Loss: 0.1696\n",
      "Epoch [12/50], Step [39/735], Loss: 0.0840\n",
      "Epoch [12/50], Step [40/735], Loss: 0.1027\n",
      "Epoch [12/50], Step [41/735], Loss: 0.0933\n",
      "Epoch [12/50], Step [42/735], Loss: 0.0531\n",
      "Epoch [12/50], Step [43/735], Loss: 0.4467\n",
      "Epoch [12/50], Step [44/735], Loss: 0.1154\n",
      "Epoch [12/50], Step [45/735], Loss: 0.2528\n",
      "Epoch [12/50], Step [46/735], Loss: 0.0984\n",
      "Epoch [12/50], Step [47/735], Loss: 0.1067\n",
      "Epoch [12/50], Step [48/735], Loss: 0.0426\n",
      "Epoch [12/50], Step [49/735], Loss: 0.0828\n",
      "Epoch [12/50], Step [50/735], Loss: 0.2683\n",
      "Epoch [12/50], Step [51/735], Loss: 0.1094\n",
      "Epoch [12/50], Step [52/735], Loss: 1.1605\n",
      "Epoch [12/50], Step [53/735], Loss: 0.0814\n",
      "Epoch [12/50], Step [54/735], Loss: 0.3117\n",
      "Epoch [12/50], Step [55/735], Loss: 0.0908\n",
      "Epoch [12/50], Step [56/735], Loss: 0.3958\n",
      "Epoch [12/50], Step [57/735], Loss: 0.1323\n",
      "Epoch [12/50], Step [58/735], Loss: 0.2319\n",
      "Epoch [12/50], Step [59/735], Loss: 0.3432\n",
      "Epoch [12/50], Step [60/735], Loss: 0.1916\n",
      "Epoch [12/50], Step [61/735], Loss: 0.0580\n",
      "Epoch [12/50], Step [62/735], Loss: 0.0798\n",
      "Epoch [12/50], Step [63/735], Loss: 0.1288\n",
      "Epoch [12/50], Step [64/735], Loss: 0.0770\n",
      "Epoch [12/50], Step [65/735], Loss: 0.0499\n",
      "Epoch [12/50], Step [66/735], Loss: 0.0522\n",
      "Epoch [12/50], Step [67/735], Loss: 0.3764\n",
      "Epoch [12/50], Step [68/735], Loss: 0.1117\n",
      "Epoch [12/50], Step [69/735], Loss: 0.1343\n",
      "Epoch [12/50], Step [70/735], Loss: 0.2140\n",
      "Epoch [12/50], Step [71/735], Loss: 0.2341\n",
      "Epoch [12/50], Step [72/735], Loss: 0.3044\n",
      "Epoch [12/50], Step [73/735], Loss: 0.2315\n",
      "Epoch [12/50], Step [74/735], Loss: 0.1689\n",
      "Epoch [12/50], Step [75/735], Loss: 0.1518\n",
      "Epoch [12/50], Step [76/735], Loss: 0.3887\n",
      "Epoch [12/50], Step [77/735], Loss: 0.0474\n",
      "Epoch [12/50], Step [78/735], Loss: 0.2307\n",
      "Epoch [12/50], Step [79/735], Loss: 0.2179\n",
      "Epoch [12/50], Step [80/735], Loss: 0.1585\n",
      "Epoch [12/50], Step [81/735], Loss: 0.2040\n",
      "Epoch [12/50], Step [82/735], Loss: 0.2534\n",
      "Epoch [12/50], Step [83/735], Loss: 0.1057\n",
      "Epoch [12/50], Step [84/735], Loss: 0.0773\n",
      "Epoch [12/50], Step [85/735], Loss: 0.1478\n",
      "Epoch [12/50], Step [86/735], Loss: 0.0792\n",
      "Epoch [12/50], Step [87/735], Loss: 0.2589\n",
      "Epoch [12/50], Step [88/735], Loss: 0.2776\n",
      "Epoch [12/50], Step [89/735], Loss: 0.0577\n",
      "Epoch [12/50], Step [90/735], Loss: 0.3043\n",
      "Epoch [12/50], Step [91/735], Loss: 0.1445\n",
      "Epoch [12/50], Step [92/735], Loss: 0.9520\n",
      "Epoch [12/50], Step [93/735], Loss: 0.1371\n",
      "Epoch [12/50], Step [94/735], Loss: 0.0644\n",
      "Epoch [12/50], Step [95/735], Loss: 0.1511\n",
      "Epoch [12/50], Step [96/735], Loss: 0.9338\n",
      "Epoch [12/50], Step [97/735], Loss: 0.0908\n",
      "Epoch [12/50], Step [98/735], Loss: 0.2922\n",
      "Epoch [12/50], Step [99/735], Loss: 0.1998\n",
      "Epoch [12/50], Step [100/735], Loss: 0.1192\n",
      "Epoch [12/50], Step [101/735], Loss: 0.1542\n",
      "Epoch [12/50], Step [102/735], Loss: 0.0581\n",
      "Epoch [12/50], Step [103/735], Loss: 0.1547\n",
      "Epoch [12/50], Step [104/735], Loss: 0.1617\n",
      "Epoch [12/50], Step [105/735], Loss: 0.1323\n",
      "Epoch [12/50], Step [106/735], Loss: 0.4382\n",
      "Epoch [12/50], Step [107/735], Loss: 0.2125\n",
      "Epoch [12/50], Step [108/735], Loss: 0.0565\n",
      "Epoch [12/50], Step [109/735], Loss: 0.0864\n",
      "Epoch [12/50], Step [110/735], Loss: 0.0814\n",
      "Epoch [12/50], Step [111/735], Loss: 0.0856\n",
      "Epoch [12/50], Step [112/735], Loss: 0.4858\n",
      "Epoch [12/50], Step [113/735], Loss: 0.1652\n",
      "Epoch [12/50], Step [114/735], Loss: 0.3907\n",
      "Epoch [12/50], Step [115/735], Loss: 0.0912\n",
      "Epoch [12/50], Step [116/735], Loss: 0.3695\n",
      "Epoch [12/50], Step [117/735], Loss: 0.0756\n",
      "Epoch [12/50], Step [118/735], Loss: 0.1367\n",
      "Epoch [12/50], Step [119/735], Loss: 0.2064\n",
      "Epoch [12/50], Step [120/735], Loss: 0.1738\n",
      "Epoch [12/50], Step [121/735], Loss: 0.4201\n",
      "Epoch [12/50], Step [122/735], Loss: 0.3709\n",
      "Epoch [12/50], Step [123/735], Loss: 0.0921\n",
      "Epoch [12/50], Step [124/735], Loss: 0.0603\n",
      "Epoch [12/50], Step [125/735], Loss: 0.1973\n",
      "Epoch [12/50], Step [126/735], Loss: 0.2798\n",
      "Epoch [12/50], Step [127/735], Loss: 0.2270\n",
      "Epoch [12/50], Step [128/735], Loss: 0.0911\n",
      "Epoch [12/50], Step [129/735], Loss: 0.0685\n",
      "Epoch [12/50], Step [130/735], Loss: 0.0599\n",
      "Epoch [12/50], Step [131/735], Loss: 0.1014\n",
      "Epoch [12/50], Step [132/735], Loss: 0.0573\n",
      "Epoch [12/50], Step [133/735], Loss: 0.2523\n",
      "Epoch [12/50], Step [134/735], Loss: 0.1584\n",
      "Epoch [12/50], Step [135/735], Loss: 0.0811\n",
      "Epoch [12/50], Step [136/735], Loss: 0.1979\n",
      "Epoch [12/50], Step [137/735], Loss: 0.1775\n",
      "Epoch [12/50], Step [138/735], Loss: 0.1928\n",
      "Epoch [12/50], Step [139/735], Loss: 0.1638\n",
      "Epoch [12/50], Step [140/735], Loss: 0.2007\n",
      "Epoch [12/50], Step [141/735], Loss: 1.2074\n",
      "Epoch [12/50], Step [142/735], Loss: 0.0758\n",
      "Epoch [12/50], Step [143/735], Loss: 0.2240\n",
      "Epoch [12/50], Step [144/735], Loss: 0.2300\n",
      "Epoch [12/50], Step [145/735], Loss: 0.6849\n",
      "Epoch [12/50], Step [146/735], Loss: 0.2064\n",
      "Epoch [12/50], Step [147/735], Loss: 0.1585\n",
      "Epoch [12/50], Step [148/735], Loss: 0.1792\n",
      "Epoch [12/50], Step [149/735], Loss: 0.0780\n",
      "Epoch [12/50], Step [150/735], Loss: 0.0752\n",
      "Epoch [12/50], Step [151/735], Loss: 0.2606\n",
      "Epoch [12/50], Step [152/735], Loss: 0.1868\n",
      "Epoch [12/50], Step [153/735], Loss: 0.1537\n",
      "Epoch [12/50], Step [154/735], Loss: 0.1397\n",
      "Epoch [12/50], Step [155/735], Loss: 0.4460\n",
      "Epoch [12/50], Step [156/735], Loss: 0.1276\n",
      "Epoch [12/50], Step [157/735], Loss: 0.0656\n",
      "Epoch [12/50], Step [158/735], Loss: 0.0891\n",
      "Epoch [12/50], Step [159/735], Loss: 0.1995\n",
      "Epoch [12/50], Step [160/735], Loss: 0.0771\n",
      "Epoch [12/50], Step [161/735], Loss: 0.0692\n",
      "Epoch [12/50], Step [162/735], Loss: 0.2171\n",
      "Epoch [12/50], Step [163/735], Loss: 0.0772\n",
      "Epoch [12/50], Step [164/735], Loss: 0.1550\n",
      "Epoch [12/50], Step [165/735], Loss: 0.1098\n",
      "Epoch [12/50], Step [166/735], Loss: 1.2575\n",
      "Epoch [12/50], Step [167/735], Loss: 0.0674\n",
      "Epoch [12/50], Step [168/735], Loss: 0.0881\n",
      "Epoch [12/50], Step [169/735], Loss: 0.2720\n",
      "Epoch [12/50], Step [170/735], Loss: 0.0915\n",
      "Epoch [12/50], Step [171/735], Loss: 0.1909\n",
      "Epoch [12/50], Step [172/735], Loss: 1.1469\n",
      "Epoch [12/50], Step [173/735], Loss: 0.2036\n",
      "Epoch [12/50], Step [174/735], Loss: 0.0730\n",
      "Epoch [12/50], Step [175/735], Loss: 0.1120\n",
      "Epoch [12/50], Step [176/735], Loss: 0.1402\n",
      "Epoch [12/50], Step [177/735], Loss: 0.4534\n",
      "Epoch [12/50], Step [178/735], Loss: 0.0493\n",
      "Epoch [12/50], Step [179/735], Loss: 0.0737\n",
      "Epoch [12/50], Step [180/735], Loss: 0.0472\n",
      "Epoch [12/50], Step [181/735], Loss: 0.0466\n",
      "Epoch [12/50], Step [182/735], Loss: 0.1462\n",
      "Epoch [12/50], Step [183/735], Loss: 0.0714\n",
      "Epoch [12/50], Step [184/735], Loss: 2.5019\n",
      "Epoch [12/50], Step [185/735], Loss: 0.1778\n",
      "Epoch [12/50], Step [186/735], Loss: 0.0911\n",
      "Epoch [12/50], Step [187/735], Loss: 0.1824\n",
      "Epoch [12/50], Step [188/735], Loss: 0.1059\n",
      "Epoch [12/50], Step [189/735], Loss: 0.1156\n",
      "Epoch [12/50], Step [190/735], Loss: 0.1116\n",
      "Epoch [12/50], Step [191/735], Loss: 0.0994\n",
      "Epoch [12/50], Step [192/735], Loss: 0.1647\n",
      "Epoch [12/50], Step [193/735], Loss: 0.2851\n",
      "Epoch [12/50], Step [194/735], Loss: 0.0484\n",
      "Epoch [12/50], Step [195/735], Loss: 0.5774\n",
      "Epoch [12/50], Step [196/735], Loss: 0.3209\n",
      "Epoch [12/50], Step [197/735], Loss: 0.2243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Step [198/735], Loss: 0.3605\n",
      "Epoch [12/50], Step [199/735], Loss: 0.0493\n",
      "Epoch [12/50], Step [200/735], Loss: 0.1192\n",
      "Epoch [12/50], Step [201/735], Loss: 0.1684\n",
      "Epoch [12/50], Step [202/735], Loss: 1.1108\n",
      "Epoch [12/50], Step [203/735], Loss: 0.0610\n",
      "Epoch [12/50], Step [204/735], Loss: 0.1163\n",
      "Epoch [12/50], Step [205/735], Loss: 0.8501\n",
      "Epoch [12/50], Step [206/735], Loss: 0.0816\n",
      "Epoch [12/50], Step [207/735], Loss: 0.4146\n",
      "Epoch [12/50], Step [208/735], Loss: 0.1574\n",
      "Epoch [12/50], Step [209/735], Loss: 0.1402\n",
      "Epoch [12/50], Step [210/735], Loss: 0.0825\n",
      "Epoch [12/50], Step [211/735], Loss: 0.1378\n",
      "Epoch [12/50], Step [212/735], Loss: 0.5551\n",
      "Epoch [12/50], Step [213/735], Loss: 0.1103\n",
      "Epoch [12/50], Step [214/735], Loss: 0.2581\n",
      "Epoch [12/50], Step [215/735], Loss: 0.2064\n",
      "Epoch [12/50], Step [216/735], Loss: 0.8858\n",
      "Epoch [12/50], Step [217/735], Loss: 0.1550\n",
      "Epoch [12/50], Step [218/735], Loss: 0.5631\n",
      "Epoch [12/50], Step [219/735], Loss: 0.3245\n",
      "Epoch [12/50], Step [220/735], Loss: 0.0441\n",
      "Epoch [12/50], Step [221/735], Loss: 0.0929\n",
      "Epoch [12/50], Step [222/735], Loss: 0.3516\n",
      "Epoch [12/50], Step [223/735], Loss: 0.2781\n",
      "Epoch [12/50], Step [224/735], Loss: 0.0668\n",
      "Epoch [12/50], Step [225/735], Loss: 0.0972\n",
      "Epoch [12/50], Step [226/735], Loss: 0.2443\n",
      "Epoch [12/50], Step [227/735], Loss: 0.1608\n",
      "Epoch [12/50], Step [228/735], Loss: 0.1605\n",
      "Epoch [12/50], Step [229/735], Loss: 0.7687\n",
      "Epoch [12/50], Step [230/735], Loss: 0.5970\n",
      "Epoch [12/50], Step [231/735], Loss: 0.1242\n",
      "Epoch [12/50], Step [232/735], Loss: 0.2201\n",
      "Epoch [12/50], Step [233/735], Loss: 0.1712\n",
      "Epoch [12/50], Step [234/735], Loss: 0.1659\n",
      "Epoch [12/50], Step [235/735], Loss: 0.1599\n",
      "Epoch [12/50], Step [236/735], Loss: 0.1527\n",
      "Epoch [12/50], Step [237/735], Loss: 0.4583\n",
      "Epoch [12/50], Step [238/735], Loss: 0.1348\n",
      "Epoch [12/50], Step [239/735], Loss: 0.0815\n",
      "Epoch [12/50], Step [240/735], Loss: 0.0514\n",
      "Epoch [12/50], Step [241/735], Loss: 0.2176\n",
      "Epoch [12/50], Step [242/735], Loss: 0.0978\n",
      "Epoch [12/50], Step [243/735], Loss: 0.1602\n",
      "Epoch [12/50], Step [244/735], Loss: 0.1448\n",
      "Epoch [12/50], Step [245/735], Loss: 1.3623\n",
      "Epoch [12/50], Step [246/735], Loss: 0.1906\n",
      "Epoch [12/50], Step [247/735], Loss: 0.1311\n",
      "Epoch [12/50], Step [248/735], Loss: 0.1075\n",
      "Epoch [12/50], Step [249/735], Loss: 0.0901\n",
      "Epoch [12/50], Step [250/735], Loss: 0.3691\n",
      "Epoch [12/50], Step [251/735], Loss: 0.2079\n",
      "Epoch [12/50], Step [252/735], Loss: 0.3114\n",
      "Epoch [12/50], Step [253/735], Loss: 0.1928\n",
      "Epoch [12/50], Step [254/735], Loss: 0.0896\n",
      "Epoch [12/50], Step [255/735], Loss: 0.3028\n",
      "Epoch [12/50], Step [256/735], Loss: 0.0910\n",
      "Epoch [12/50], Step [257/735], Loss: 0.1245\n",
      "Epoch [12/50], Step [258/735], Loss: 0.1014\n",
      "Epoch [12/50], Step [259/735], Loss: 0.2287\n",
      "Epoch [12/50], Step [260/735], Loss: 0.1359\n",
      "Epoch [12/50], Step [261/735], Loss: 0.1920\n",
      "Epoch [12/50], Step [262/735], Loss: 0.1638\n",
      "Epoch [12/50], Step [263/735], Loss: 0.3728\n",
      "Epoch [12/50], Step [264/735], Loss: 0.0870\n",
      "Epoch [12/50], Step [265/735], Loss: 0.0909\n",
      "Epoch [12/50], Step [266/735], Loss: 0.0977\n",
      "Epoch [12/50], Step [267/735], Loss: 0.1643\n",
      "Epoch [12/50], Step [268/735], Loss: 0.0810\n",
      "Epoch [12/50], Step [269/735], Loss: 1.2603\n",
      "Epoch [12/50], Step [270/735], Loss: 0.1018\n",
      "Epoch [12/50], Step [271/735], Loss: 0.0505\n",
      "Epoch [12/50], Step [272/735], Loss: 0.1576\n",
      "Epoch [12/50], Step [273/735], Loss: 0.2143\n",
      "Epoch [12/50], Step [274/735], Loss: 0.1998\n",
      "Epoch [12/50], Step [275/735], Loss: 0.1372\n",
      "Epoch [12/50], Step [276/735], Loss: 0.6749\n",
      "Epoch [12/50], Step [277/735], Loss: 1.1059\n",
      "Epoch [12/50], Step [278/735], Loss: 0.2959\n",
      "Epoch [12/50], Step [279/735], Loss: 0.1694\n",
      "Epoch [12/50], Step [280/735], Loss: 0.2011\n",
      "Epoch [12/50], Step [281/735], Loss: 0.0954\n",
      "Epoch [12/50], Step [282/735], Loss: 0.1793\n",
      "Epoch [12/50], Step [283/735], Loss: 0.2256\n",
      "Epoch [12/50], Step [284/735], Loss: 0.1710\n",
      "Epoch [12/50], Step [285/735], Loss: 0.1745\n",
      "Epoch [12/50], Step [286/735], Loss: 0.1560\n",
      "Epoch [12/50], Step [287/735], Loss: 0.2921\n",
      "Epoch [12/50], Step [288/735], Loss: 0.0864\n",
      "Epoch [12/50], Step [289/735], Loss: 0.1231\n",
      "Epoch [12/50], Step [290/735], Loss: 0.2535\n",
      "Epoch [12/50], Step [291/735], Loss: 0.0476\n",
      "Epoch [12/50], Step [292/735], Loss: 0.3924\n",
      "Epoch [12/50], Step [293/735], Loss: 0.2185\n",
      "Epoch [12/50], Step [294/735], Loss: 0.2164\n",
      "Epoch [12/50], Step [295/735], Loss: 0.1358\n",
      "Epoch [12/50], Step [296/735], Loss: 0.1900\n",
      "Epoch [12/50], Step [297/735], Loss: 0.0808\n",
      "Epoch [12/50], Step [298/735], Loss: 0.1319\n",
      "Epoch [12/50], Step [299/735], Loss: 0.4053\n",
      "Epoch [12/50], Step [300/735], Loss: 0.1399\n",
      "Epoch [12/50], Step [301/735], Loss: 0.2857\n",
      "Epoch [12/50], Step [302/735], Loss: 2.5589\n",
      "Epoch [12/50], Step [303/735], Loss: 0.0935\n",
      "Epoch [12/50], Step [304/735], Loss: 0.3556\n",
      "Epoch [12/50], Step [305/735], Loss: 0.2037\n",
      "Epoch [12/50], Step [306/735], Loss: 0.2797\n",
      "Epoch [12/50], Step [307/735], Loss: 0.2105\n",
      "Epoch [12/50], Step [308/735], Loss: 0.1425\n",
      "Epoch [12/50], Step [309/735], Loss: 0.5005\n",
      "Epoch [12/50], Step [310/735], Loss: 0.3161\n",
      "Epoch [12/50], Step [311/735], Loss: 0.2372\n",
      "Epoch [12/50], Step [312/735], Loss: 0.4508\n",
      "Epoch [12/50], Step [313/735], Loss: 0.0844\n",
      "Epoch [12/50], Step [314/735], Loss: 0.0353\n",
      "Epoch [12/50], Step [315/735], Loss: 0.0507\n",
      "Epoch [12/50], Step [316/735], Loss: 0.0734\n",
      "Epoch [12/50], Step [317/735], Loss: 0.1087\n",
      "Epoch [12/50], Step [318/735], Loss: 0.0906\n",
      "Epoch [12/50], Step [319/735], Loss: 0.4577\n",
      "Epoch [12/50], Step [320/735], Loss: 0.4470\n",
      "Epoch [12/50], Step [321/735], Loss: 0.0981\n",
      "Epoch [12/50], Step [322/735], Loss: 0.2123\n",
      "Epoch [12/50], Step [323/735], Loss: 0.0813\n",
      "Epoch [12/50], Step [324/735], Loss: 0.1601\n",
      "Epoch [12/50], Step [325/735], Loss: 0.0802\n",
      "Epoch [12/50], Step [326/735], Loss: 0.1001\n",
      "Epoch [12/50], Step [327/735], Loss: 0.1122\n",
      "Epoch [12/50], Step [328/735], Loss: 0.1995\n",
      "Epoch [12/50], Step [329/735], Loss: 0.2670\n",
      "Epoch [12/50], Step [330/735], Loss: 0.2270\n",
      "Epoch [12/50], Step [331/735], Loss: 0.1209\n",
      "Epoch [12/50], Step [332/735], Loss: 2.4730\n",
      "Epoch [12/50], Step [333/735], Loss: 0.0548\n",
      "Epoch [12/50], Step [334/735], Loss: 0.2044\n",
      "Epoch [12/50], Step [335/735], Loss: 0.1093\n",
      "Epoch [12/50], Step [336/735], Loss: 0.0970\n",
      "Epoch [12/50], Step [337/735], Loss: 0.2539\n",
      "Epoch [12/50], Step [338/735], Loss: 1.4587\n",
      "Epoch [12/50], Step [339/735], Loss: 0.0774\n",
      "Epoch [12/50], Step [340/735], Loss: 0.3228\n",
      "Epoch [12/50], Step [341/735], Loss: 0.3392\n",
      "Epoch [12/50], Step [342/735], Loss: 0.0970\n",
      "Epoch [12/50], Step [343/735], Loss: 0.5930\n",
      "Epoch [12/50], Step [344/735], Loss: 0.3496\n",
      "Epoch [12/50], Step [345/735], Loss: 0.1570\n",
      "Epoch [12/50], Step [346/735], Loss: 0.1247\n",
      "Epoch [12/50], Step [347/735], Loss: 0.4025\n",
      "Epoch [12/50], Step [348/735], Loss: 0.1508\n",
      "Epoch [12/50], Step [349/735], Loss: 0.1763\n",
      "Epoch [12/50], Step [350/735], Loss: 0.1143\n",
      "Epoch [12/50], Step [351/735], Loss: 0.0832\n",
      "Epoch [12/50], Step [352/735], Loss: 0.0832\n",
      "Epoch [12/50], Step [353/735], Loss: 0.4028\n",
      "Epoch [12/50], Step [354/735], Loss: 0.1080\n",
      "Epoch [12/50], Step [355/735], Loss: 0.1646\n",
      "Epoch [12/50], Step [356/735], Loss: 0.0562\n",
      "Epoch [12/50], Step [357/735], Loss: 0.1752\n",
      "Epoch [12/50], Step [358/735], Loss: 0.3924\n",
      "Epoch [12/50], Step [359/735], Loss: 1.2412\n",
      "Epoch [12/50], Step [360/735], Loss: 0.1863\n",
      "Epoch [12/50], Step [361/735], Loss: 0.4010\n",
      "Epoch [12/50], Step [362/735], Loss: 0.0635\n",
      "Epoch [12/50], Step [363/735], Loss: 0.2160\n",
      "Epoch [12/50], Step [364/735], Loss: 0.1386\n",
      "Epoch [12/50], Step [365/735], Loss: 0.1439\n",
      "Epoch [12/50], Step [366/735], Loss: 0.4219\n",
      "Epoch [12/50], Step [367/735], Loss: 0.0931\n",
      "Epoch [12/50], Step [368/735], Loss: 1.4027\n",
      "Epoch [12/50], Step [369/735], Loss: 0.1618\n",
      "Epoch [12/50], Step [370/735], Loss: 0.2248\n",
      "Epoch [12/50], Step [371/735], Loss: 0.3124\n",
      "Epoch [12/50], Step [372/735], Loss: 0.0914\n",
      "Epoch [12/50], Step [373/735], Loss: 0.1442\n",
      "Epoch [12/50], Step [374/735], Loss: 0.1376\n",
      "Epoch [12/50], Step [375/735], Loss: 0.2812\n",
      "Epoch [12/50], Step [376/735], Loss: 0.1370\n",
      "Epoch [12/50], Step [377/735], Loss: 0.3873\n",
      "Epoch [12/50], Step [378/735], Loss: 0.1781\n",
      "Epoch [12/50], Step [379/735], Loss: 0.1788\n",
      "Epoch [12/50], Step [380/735], Loss: 0.1168\n",
      "Epoch [12/50], Step [381/735], Loss: 0.1109\n",
      "Epoch [12/50], Step [382/735], Loss: 0.0987\n",
      "Epoch [12/50], Step [383/735], Loss: 0.0922\n",
      "Epoch [12/50], Step [384/735], Loss: 0.1302\n",
      "Epoch [12/50], Step [385/735], Loss: 0.4168\n",
      "Epoch [12/50], Step [386/735], Loss: 0.1958\n",
      "Epoch [12/50], Step [387/735], Loss: 0.1383\n",
      "Epoch [12/50], Step [388/735], Loss: 0.1712\n",
      "Epoch [12/50], Step [389/735], Loss: 0.1894\n",
      "Epoch [12/50], Step [390/735], Loss: 0.0403\n",
      "Epoch [12/50], Step [391/735], Loss: 0.1437\n",
      "Epoch [12/50], Step [392/735], Loss: 0.0614\n",
      "Epoch [12/50], Step [393/735], Loss: 0.3503\n",
      "Epoch [12/50], Step [394/735], Loss: 0.4047\n",
      "Epoch [12/50], Step [395/735], Loss: 0.2141\n",
      "Epoch [12/50], Step [396/735], Loss: 0.0814\n",
      "Epoch [12/50], Step [397/735], Loss: 0.5071\n",
      "Epoch [12/50], Step [398/735], Loss: 0.1363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Step [399/735], Loss: 0.0963\n",
      "Epoch [12/50], Step [400/735], Loss: 0.1544\n",
      "Epoch [12/50], Step [401/735], Loss: 0.0719\n",
      "Epoch [12/50], Step [402/735], Loss: 0.4149\n",
      "Epoch [12/50], Step [403/735], Loss: 1.4664\n",
      "Epoch [12/50], Step [404/735], Loss: 0.3567\n",
      "Epoch [12/50], Step [405/735], Loss: 0.2538\n",
      "Epoch [12/50], Step [406/735], Loss: 0.1058\n",
      "Epoch [12/50], Step [407/735], Loss: 0.0947\n",
      "Epoch [12/50], Step [408/735], Loss: 2.2268\n",
      "Epoch [12/50], Step [409/735], Loss: 0.2099\n",
      "Epoch [12/50], Step [410/735], Loss: 0.1223\n",
      "Epoch [12/50], Step [411/735], Loss: 0.2103\n",
      "Epoch [12/50], Step [412/735], Loss: 0.1711\n",
      "Epoch [12/50], Step [413/735], Loss: 0.1280\n",
      "Epoch [12/50], Step [414/735], Loss: 0.1654\n",
      "Epoch [12/50], Step [415/735], Loss: 0.1235\n",
      "Epoch [12/50], Step [416/735], Loss: 0.1663\n",
      "Epoch [12/50], Step [417/735], Loss: 0.4024\n",
      "Epoch [12/50], Step [418/735], Loss: 0.0813\n",
      "Epoch [12/50], Step [419/735], Loss: 0.0901\n",
      "Epoch [12/50], Step [420/735], Loss: 0.0699\n",
      "Epoch [12/50], Step [421/735], Loss: 0.4549\n",
      "Epoch [12/50], Step [422/735], Loss: 0.1209\n",
      "Epoch [12/50], Step [423/735], Loss: 0.1798\n",
      "Epoch [12/50], Step [424/735], Loss: 0.2452\n",
      "Epoch [12/50], Step [425/735], Loss: 0.0519\n",
      "Epoch [12/50], Step [426/735], Loss: 0.0545\n",
      "Epoch [12/50], Step [427/735], Loss: 0.2349\n",
      "Epoch [12/50], Step [428/735], Loss: 0.1171\n",
      "Epoch [12/50], Step [429/735], Loss: 0.2166\n",
      "Epoch [12/50], Step [430/735], Loss: 0.3302\n",
      "Epoch [12/50], Step [431/735], Loss: 0.0482\n",
      "Epoch [12/50], Step [432/735], Loss: 0.3049\n",
      "Epoch [12/50], Step [433/735], Loss: 0.1386\n",
      "Epoch [12/50], Step [434/735], Loss: 0.3417\n",
      "Epoch [12/50], Step [435/735], Loss: 0.5583\n",
      "Epoch [12/50], Step [436/735], Loss: 0.3258\n",
      "Epoch [12/50], Step [437/735], Loss: 0.0515\n",
      "Epoch [12/50], Step [438/735], Loss: 0.4288\n",
      "Epoch [12/50], Step [439/735], Loss: 0.0898\n",
      "Epoch [12/50], Step [440/735], Loss: 0.1034\n",
      "Epoch [12/50], Step [441/735], Loss: 0.4344\n",
      "Epoch [12/50], Step [442/735], Loss: 0.2001\n",
      "Epoch [12/50], Step [443/735], Loss: 0.2387\n",
      "Epoch [12/50], Step [444/735], Loss: 0.1181\n",
      "Epoch [12/50], Step [445/735], Loss: 1.3672\n",
      "Epoch [12/50], Step [446/735], Loss: 0.0706\n",
      "Epoch [12/50], Step [447/735], Loss: 0.2899\n",
      "Epoch [12/50], Step [448/735], Loss: 0.0726\n",
      "Epoch [12/50], Step [449/735], Loss: 0.3531\n",
      "Epoch [12/50], Step [450/735], Loss: 1.0954\n",
      "Epoch [12/50], Step [451/735], Loss: 0.0803\n",
      "Epoch [12/50], Step [452/735], Loss: 0.2054\n",
      "Epoch [12/50], Step [453/735], Loss: 0.1932\n",
      "Epoch [12/50], Step [454/735], Loss: 0.1280\n",
      "Epoch [12/50], Step [455/735], Loss: 0.1051\n",
      "Epoch [12/50], Step [456/735], Loss: 0.1523\n",
      "Epoch [12/50], Step [457/735], Loss: 0.3642\n",
      "Epoch [12/50], Step [458/735], Loss: 0.0432\n",
      "Epoch [12/50], Step [459/735], Loss: 0.1043\n",
      "Epoch [12/50], Step [460/735], Loss: 0.0448\n",
      "Epoch [12/50], Step [461/735], Loss: 0.0933\n",
      "Epoch [12/50], Step [462/735], Loss: 0.6565\n",
      "Epoch [12/50], Step [463/735], Loss: 0.1082\n",
      "Epoch [12/50], Step [464/735], Loss: 0.4808\n",
      "Epoch [12/50], Step [465/735], Loss: 0.2672\n",
      "Epoch [12/50], Step [466/735], Loss: 0.1929\n",
      "Epoch [12/50], Step [467/735], Loss: 0.0589\n",
      "Epoch [12/50], Step [468/735], Loss: 0.0809\n",
      "Epoch [12/50], Step [469/735], Loss: 0.1696\n",
      "Epoch [12/50], Step [470/735], Loss: 0.1971\n",
      "Epoch [12/50], Step [471/735], Loss: 0.1638\n",
      "Epoch [12/50], Step [472/735], Loss: 0.0589\n",
      "Epoch [12/50], Step [473/735], Loss: 0.0868\n",
      "Epoch [12/50], Step [474/735], Loss: 0.0930\n",
      "Epoch [12/50], Step [475/735], Loss: 0.1149\n",
      "Epoch [12/50], Step [476/735], Loss: 0.1826\n",
      "Epoch [12/50], Step [477/735], Loss: 0.0710\n",
      "Epoch [12/50], Step [478/735], Loss: 0.2018\n",
      "Epoch [12/50], Step [479/735], Loss: 0.2516\n",
      "Epoch [12/50], Step [480/735], Loss: 0.3966\n",
      "Epoch [12/50], Step [481/735], Loss: 0.3288\n",
      "Epoch [12/50], Step [482/735], Loss: 0.0465\n",
      "Epoch [12/50], Step [483/735], Loss: 0.2222\n",
      "Epoch [12/50], Step [484/735], Loss: 0.2207\n",
      "Epoch [12/50], Step [485/735], Loss: 1.1064\n",
      "Epoch [12/50], Step [486/735], Loss: 0.2082\n",
      "Epoch [12/50], Step [487/735], Loss: 0.1890\n",
      "Epoch [12/50], Step [488/735], Loss: 0.0782\n",
      "Epoch [12/50], Step [489/735], Loss: 0.0504\n",
      "Epoch [12/50], Step [490/735], Loss: 0.9661\n",
      "Epoch [12/50], Step [491/735], Loss: 0.1259\n",
      "Epoch [12/50], Step [492/735], Loss: 0.0943\n",
      "Epoch [12/50], Step [493/735], Loss: 0.0627\n",
      "Epoch [12/50], Step [494/735], Loss: 0.1352\n",
      "Epoch [12/50], Step [495/735], Loss: 0.1521\n",
      "Epoch [12/50], Step [496/735], Loss: 0.1813\n",
      "Epoch [12/50], Step [497/735], Loss: 0.3663\n",
      "Epoch [12/50], Step [498/735], Loss: 0.1086\n",
      "Epoch [12/50], Step [499/735], Loss: 0.0504\n",
      "Epoch [12/50], Step [500/735], Loss: 1.6679\n",
      "Epoch [12/50], Step [501/735], Loss: 0.1864\n",
      "Epoch [12/50], Step [502/735], Loss: 0.0572\n",
      "Epoch [12/50], Step [503/735], Loss: 0.1862\n",
      "Epoch [12/50], Step [504/735], Loss: 0.1520\n",
      "Epoch [12/50], Step [505/735], Loss: 0.1685\n",
      "Epoch [12/50], Step [506/735], Loss: 0.1873\n",
      "Epoch [12/50], Step [507/735], Loss: 0.7930\n",
      "Epoch [12/50], Step [508/735], Loss: 0.1557\n",
      "Epoch [12/50], Step [509/735], Loss: 0.0946\n",
      "Epoch [12/50], Step [510/735], Loss: 0.1206\n",
      "Epoch [12/50], Step [511/735], Loss: 0.0992\n",
      "Epoch [12/50], Step [512/735], Loss: 0.2986\n",
      "Epoch [12/50], Step [513/735], Loss: 0.0561\n",
      "Epoch [12/50], Step [514/735], Loss: 0.2280\n",
      "Epoch [12/50], Step [515/735], Loss: 0.0636\n",
      "Epoch [12/50], Step [516/735], Loss: 0.2940\n",
      "Epoch [12/50], Step [517/735], Loss: 0.0809\n",
      "Epoch [12/50], Step [518/735], Loss: 0.1629\n",
      "Epoch [12/50], Step [519/735], Loss: 0.1150\n",
      "Epoch [12/50], Step [520/735], Loss: 0.0779\n",
      "Epoch [12/50], Step [521/735], Loss: 0.1400\n",
      "Epoch [12/50], Step [522/735], Loss: 0.2114\n",
      "Epoch [12/50], Step [523/735], Loss: 0.1396\n",
      "Epoch [12/50], Step [524/735], Loss: 0.1226\n",
      "Epoch [12/50], Step [525/735], Loss: 1.2951\n",
      "Epoch [12/50], Step [526/735], Loss: 0.0463\n",
      "Epoch [12/50], Step [527/735], Loss: 0.1503\n",
      "Epoch [12/50], Step [528/735], Loss: 0.0734\n",
      "Epoch [12/50], Step [529/735], Loss: 0.7091\n",
      "Epoch [12/50], Step [530/735], Loss: 0.1246\n",
      "Epoch [12/50], Step [531/735], Loss: 0.0720\n",
      "Epoch [12/50], Step [532/735], Loss: 0.1226\n",
      "Epoch [12/50], Step [533/735], Loss: 0.1133\n",
      "Epoch [12/50], Step [534/735], Loss: 0.4482\n",
      "Epoch [12/50], Step [535/735], Loss: 0.3103\n",
      "Epoch [12/50], Step [536/735], Loss: 0.0336\n",
      "Epoch [12/50], Step [537/735], Loss: 0.0644\n",
      "Epoch [12/50], Step [538/735], Loss: 0.3524\n",
      "Epoch [12/50], Step [539/735], Loss: 0.1773\n",
      "Epoch [12/50], Step [540/735], Loss: 0.2725\n",
      "Epoch [12/50], Step [541/735], Loss: 0.0989\n",
      "Epoch [12/50], Step [542/735], Loss: 0.3750\n",
      "Epoch [12/50], Step [543/735], Loss: 0.0502\n",
      "Epoch [12/50], Step [544/735], Loss: 0.2707\n",
      "Epoch [12/50], Step [545/735], Loss: 0.0330\n",
      "Epoch [12/50], Step [546/735], Loss: 0.1248\n",
      "Epoch [12/50], Step [547/735], Loss: 0.1250\n",
      "Epoch [12/50], Step [548/735], Loss: 0.1181\n",
      "Epoch [12/50], Step [549/735], Loss: 0.2502\n",
      "Epoch [12/50], Step [550/735], Loss: 0.1498\n",
      "Epoch [12/50], Step [551/735], Loss: 0.1095\n",
      "Epoch [12/50], Step [552/735], Loss: 0.1796\n",
      "Epoch [12/50], Step [553/735], Loss: 0.1173\n",
      "Epoch [12/50], Step [554/735], Loss: 0.2604\n",
      "Epoch [12/50], Step [555/735], Loss: 0.1607\n",
      "Epoch [12/50], Step [556/735], Loss: 0.1495\n",
      "Epoch [12/50], Step [557/735], Loss: 0.1760\n",
      "Epoch [12/50], Step [558/735], Loss: 0.2636\n",
      "Epoch [12/50], Step [559/735], Loss: 0.1144\n",
      "Epoch [12/50], Step [560/735], Loss: 0.2355\n",
      "Epoch [12/50], Step [561/735], Loss: 0.1308\n",
      "Epoch [12/50], Step [562/735], Loss: 0.1613\n",
      "Epoch [12/50], Step [563/735], Loss: 0.1693\n",
      "Epoch [12/50], Step [564/735], Loss: 0.4566\n",
      "Epoch [12/50], Step [565/735], Loss: 0.1855\n",
      "Epoch [12/50], Step [566/735], Loss: 0.2818\n",
      "Epoch [12/50], Step [567/735], Loss: 0.1169\n",
      "Epoch [12/50], Step [568/735], Loss: 0.1548\n",
      "Epoch [12/50], Step [569/735], Loss: 0.0970\n",
      "Epoch [12/50], Step [570/735], Loss: 0.0749\n",
      "Epoch [12/50], Step [571/735], Loss: 0.2131\n",
      "Epoch [12/50], Step [572/735], Loss: 0.1374\n",
      "Epoch [12/50], Step [573/735], Loss: 0.1942\n",
      "Epoch [12/50], Step [574/735], Loss: 0.0993\n",
      "Epoch [12/50], Step [575/735], Loss: 0.1615\n",
      "Epoch [12/50], Step [576/735], Loss: 0.0832\n",
      "Epoch [12/50], Step [577/735], Loss: 0.0751\n",
      "Epoch [12/50], Step [578/735], Loss: 0.1812\n",
      "Epoch [12/50], Step [579/735], Loss: 0.1119\n",
      "Epoch [12/50], Step [580/735], Loss: 0.0874\n",
      "Epoch [12/50], Step [581/735], Loss: 0.2988\n",
      "Epoch [12/50], Step [582/735], Loss: 0.1562\n",
      "Epoch [12/50], Step [583/735], Loss: 0.0954\n",
      "Epoch [12/50], Step [584/735], Loss: 0.1116\n",
      "Epoch [12/50], Step [585/735], Loss: 0.1199\n",
      "Epoch [12/50], Step [586/735], Loss: 0.4385\n",
      "Epoch [12/50], Step [587/735], Loss: 0.0747\n",
      "Epoch [12/50], Step [588/735], Loss: 1.4781\n",
      "Epoch [12/50], Step [589/735], Loss: 0.3033\n",
      "Epoch [12/50], Step [590/735], Loss: 0.1114\n",
      "Epoch [12/50], Step [591/735], Loss: 0.1567\n",
      "Epoch [12/50], Step [592/735], Loss: 0.0682\n",
      "Epoch [12/50], Step [593/735], Loss: 0.3087\n",
      "Epoch [12/50], Step [594/735], Loss: 0.1558\n",
      "Epoch [12/50], Step [595/735], Loss: 0.2017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Step [596/735], Loss: 0.1507\n",
      "Epoch [12/50], Step [597/735], Loss: 0.0573\n",
      "Epoch [12/50], Step [598/735], Loss: 0.1435\n",
      "Epoch [12/50], Step [599/735], Loss: 0.2320\n",
      "Epoch [12/50], Step [600/735], Loss: 0.5047\n",
      "Epoch [12/50], Step [601/735], Loss: 0.2553\n",
      "Epoch [12/50], Step [602/735], Loss: 0.2150\n",
      "Epoch [12/50], Step [603/735], Loss: 0.1937\n",
      "Epoch [12/50], Step [604/735], Loss: 0.2536\n",
      "Epoch [12/50], Step [605/735], Loss: 0.1484\n",
      "Epoch [12/50], Step [606/735], Loss: 2.1325\n",
      "Epoch [12/50], Step [607/735], Loss: 0.2352\n",
      "Epoch [12/50], Step [608/735], Loss: 0.0860\n",
      "Epoch [12/50], Step [609/735], Loss: 0.3175\n",
      "Epoch [12/50], Step [610/735], Loss: 0.4656\n",
      "Epoch [12/50], Step [611/735], Loss: 0.1683\n",
      "Epoch [12/50], Step [612/735], Loss: 0.1306\n",
      "Epoch [12/50], Step [613/735], Loss: 0.1333\n",
      "Epoch [12/50], Step [614/735], Loss: 0.1048\n",
      "Epoch [12/50], Step [615/735], Loss: 0.1045\n",
      "Epoch [12/50], Step [616/735], Loss: 0.5737\n",
      "Epoch [12/50], Step [617/735], Loss: 0.2105\n",
      "Epoch [12/50], Step [618/735], Loss: 0.2371\n",
      "Epoch [12/50], Step [619/735], Loss: 0.4846\n",
      "Epoch [12/50], Step [620/735], Loss: 0.1548\n",
      "Epoch [12/50], Step [621/735], Loss: 0.1571\n",
      "Epoch [12/50], Step [622/735], Loss: 0.1036\n",
      "Epoch [12/50], Step [623/735], Loss: 0.0963\n",
      "Epoch [12/50], Step [624/735], Loss: 0.1877\n",
      "Epoch [12/50], Step [625/735], Loss: 0.0580\n",
      "Epoch [12/50], Step [626/735], Loss: 0.2078\n",
      "Epoch [12/50], Step [627/735], Loss: 0.3456\n",
      "Epoch [12/50], Step [628/735], Loss: 0.1415\n",
      "Epoch [12/50], Step [629/735], Loss: 0.1510\n",
      "Epoch [12/50], Step [630/735], Loss: 0.3779\n",
      "Epoch [12/50], Step [631/735], Loss: 0.0927\n",
      "Epoch [12/50], Step [632/735], Loss: 0.3307\n",
      "Epoch [12/50], Step [633/735], Loss: 0.0589\n",
      "Epoch [12/50], Step [634/735], Loss: 0.1664\n",
      "Epoch [12/50], Step [635/735], Loss: 0.5311\n",
      "Epoch [12/50], Step [636/735], Loss: 0.2268\n",
      "Epoch [12/50], Step [637/735], Loss: 0.1605\n",
      "Epoch [12/50], Step [638/735], Loss: 0.4142\n",
      "Epoch [12/50], Step [639/735], Loss: 0.0947\n",
      "Epoch [12/50], Step [640/735], Loss: 0.0483\n",
      "Epoch [12/50], Step [641/735], Loss: 0.0986\n",
      "Epoch [12/50], Step [642/735], Loss: 0.0508\n",
      "Epoch [12/50], Step [643/735], Loss: 0.1441\n",
      "Epoch [12/50], Step [644/735], Loss: 0.0434\n",
      "Epoch [12/50], Step [645/735], Loss: 0.2303\n",
      "Epoch [12/50], Step [646/735], Loss: 0.1599\n",
      "Epoch [12/50], Step [647/735], Loss: 0.0400\n",
      "Epoch [12/50], Step [648/735], Loss: 0.1565\n",
      "Epoch [12/50], Step [649/735], Loss: 0.0940\n",
      "Epoch [12/50], Step [650/735], Loss: 0.1068\n",
      "Epoch [12/50], Step [651/735], Loss: 0.3055\n",
      "Epoch [12/50], Step [652/735], Loss: 0.0867\n",
      "Epoch [12/50], Step [653/735], Loss: 0.4645\n",
      "Epoch [12/50], Step [654/735], Loss: 0.1862\n",
      "Epoch [12/50], Step [655/735], Loss: 0.1477\n",
      "Epoch [12/50], Step [656/735], Loss: 0.2655\n",
      "Epoch [12/50], Step [657/735], Loss: 0.1340\n",
      "Epoch [12/50], Step [658/735], Loss: 0.2414\n",
      "Epoch [12/50], Step [659/735], Loss: 0.0230\n",
      "Epoch [12/50], Step [660/735], Loss: 0.2020\n",
      "Epoch [12/50], Step [661/735], Loss: 0.2002\n",
      "Epoch [12/50], Step [662/735], Loss: 0.1821\n",
      "Epoch [12/50], Step [663/735], Loss: 0.1691\n",
      "Epoch [12/50], Step [664/735], Loss: 0.1178\n",
      "Epoch [12/50], Step [665/735], Loss: 0.1020\n",
      "Epoch [12/50], Step [666/735], Loss: 0.0888\n",
      "Epoch [12/50], Step [667/735], Loss: 0.0925\n",
      "Epoch [12/50], Step [668/735], Loss: 0.1854\n",
      "Epoch [12/50], Step [669/735], Loss: 0.2991\n",
      "Epoch [12/50], Step [670/735], Loss: 0.1678\n",
      "Epoch [12/50], Step [671/735], Loss: 0.1129\n",
      "Epoch [12/50], Step [672/735], Loss: 0.0648\n",
      "Epoch [12/50], Step [673/735], Loss: 0.0834\n",
      "Epoch [12/50], Step [674/735], Loss: 0.2236\n",
      "Epoch [12/50], Step [675/735], Loss: 0.1223\n",
      "Epoch [12/50], Step [676/735], Loss: 0.1777\n",
      "Epoch [12/50], Step [677/735], Loss: 0.1198\n",
      "Epoch [12/50], Step [678/735], Loss: 0.0758\n",
      "Epoch [12/50], Step [679/735], Loss: 0.1660\n",
      "Epoch [12/50], Step [680/735], Loss: 0.0776\n",
      "Epoch [12/50], Step [681/735], Loss: 0.1522\n",
      "Epoch [12/50], Step [682/735], Loss: 0.1034\n",
      "Epoch [12/50], Step [683/735], Loss: 0.4607\n",
      "Epoch [12/50], Step [684/735], Loss: 0.2073\n",
      "Epoch [12/50], Step [685/735], Loss: 0.3972\n",
      "Epoch [12/50], Step [686/735], Loss: 0.1796\n",
      "Epoch [12/50], Step [687/735], Loss: 0.2163\n",
      "Epoch [12/50], Step [688/735], Loss: 0.2697\n",
      "Epoch [12/50], Step [689/735], Loss: 0.0580\n",
      "Epoch [12/50], Step [690/735], Loss: 0.1714\n",
      "Epoch [12/50], Step [691/735], Loss: 0.0686\n",
      "Epoch [12/50], Step [692/735], Loss: 0.1567\n",
      "Epoch [12/50], Step [693/735], Loss: 0.1304\n",
      "Epoch [12/50], Step [694/735], Loss: 0.2555\n",
      "Epoch [12/50], Step [695/735], Loss: 0.0443\n",
      "Epoch [12/50], Step [696/735], Loss: 0.0964\n",
      "Epoch [12/50], Step [697/735], Loss: 0.1072\n",
      "Epoch [12/50], Step [698/735], Loss: 0.0348\n",
      "Epoch [12/50], Step [699/735], Loss: 0.2319\n",
      "Epoch [12/50], Step [700/735], Loss: 0.2629\n",
      "Epoch [12/50], Step [701/735], Loss: 0.2394\n",
      "Epoch [12/50], Step [702/735], Loss: 0.1586\n",
      "Epoch [12/50], Step [703/735], Loss: 0.1142\n",
      "Epoch [12/50], Step [704/735], Loss: 0.1301\n",
      "Epoch [12/50], Step [705/735], Loss: 0.1280\n",
      "Epoch [12/50], Step [706/735], Loss: 0.1093\n",
      "Epoch [12/50], Step [707/735], Loss: 0.4562\n",
      "Epoch [12/50], Step [708/735], Loss: 0.1786\n",
      "Epoch [12/50], Step [709/735], Loss: 0.2309\n",
      "Epoch [12/50], Step [710/735], Loss: 0.2607\n",
      "Epoch [12/50], Step [711/735], Loss: 0.3759\n",
      "Epoch [12/50], Step [712/735], Loss: 0.0483\n",
      "Epoch [12/50], Step [713/735], Loss: 0.3707\n",
      "Epoch [12/50], Step [714/735], Loss: 0.2406\n",
      "Epoch [12/50], Step [715/735], Loss: 0.1043\n",
      "Epoch [12/50], Step [716/735], Loss: 0.1909\n",
      "Epoch [12/50], Step [717/735], Loss: 0.1141\n",
      "Epoch [12/50], Step [718/735], Loss: 0.1412\n",
      "Epoch [12/50], Step [719/735], Loss: 0.1203\n",
      "Epoch [12/50], Step [720/735], Loss: 0.3102\n",
      "Epoch [12/50], Step [721/735], Loss: 0.2972\n",
      "Epoch [12/50], Step [722/735], Loss: 0.1370\n",
      "Epoch [12/50], Step [723/735], Loss: 0.0604\n",
      "Epoch [12/50], Step [724/735], Loss: 0.3516\n",
      "Epoch [12/50], Step [725/735], Loss: 0.4200\n",
      "Epoch [12/50], Step [726/735], Loss: 0.5250\n",
      "Epoch [12/50], Step [727/735], Loss: 0.3778\n",
      "Epoch [12/50], Step [728/735], Loss: 0.0682\n",
      "Epoch [12/50], Step [729/735], Loss: 0.1619\n",
      "Epoch [12/50], Step [730/735], Loss: 0.0577\n",
      "Epoch [12/50], Step [731/735], Loss: 0.1357\n",
      "Epoch [12/50], Step [732/735], Loss: 0.1608\n",
      "Epoch [12/50], Step [733/735], Loss: 0.0834\n",
      "Epoch [12/50], Step [734/735], Loss: 0.3461\n",
      "Epoch [12/50], Step [735/735], Loss: 0.0340\n",
      "Epoch [13/50], Step [1/735], Loss: 0.0343\n",
      "Epoch [13/50], Step [2/735], Loss: 0.4513\n",
      "Epoch [13/50], Step [3/735], Loss: 0.9788\n",
      "Epoch [13/50], Step [4/735], Loss: 0.0997\n",
      "Epoch [13/50], Step [5/735], Loss: 0.1414\n",
      "Epoch [13/50], Step [6/735], Loss: 0.3114\n",
      "Epoch [13/50], Step [7/735], Loss: 0.3560\n",
      "Epoch [13/50], Step [8/735], Loss: 0.1371\n",
      "Epoch [13/50], Step [9/735], Loss: 0.1380\n",
      "Epoch [13/50], Step [10/735], Loss: 0.1582\n",
      "Epoch [13/50], Step [11/735], Loss: 0.1780\n",
      "Epoch [13/50], Step [12/735], Loss: 0.1112\n",
      "Epoch [13/50], Step [13/735], Loss: 1.1018\n",
      "Epoch [13/50], Step [14/735], Loss: 0.2094\n",
      "Epoch [13/50], Step [15/735], Loss: 0.6682\n",
      "Epoch [13/50], Step [16/735], Loss: 0.2990\n",
      "Epoch [13/50], Step [17/735], Loss: 0.1927\n",
      "Epoch [13/50], Step [18/735], Loss: 0.0372\n",
      "Epoch [13/50], Step [19/735], Loss: 0.2899\n",
      "Epoch [13/50], Step [20/735], Loss: 0.2009\n",
      "Epoch [13/50], Step [21/735], Loss: 0.3489\n",
      "Epoch [13/50], Step [22/735], Loss: 0.0791\n",
      "Epoch [13/50], Step [23/735], Loss: 0.1909\n",
      "Epoch [13/50], Step [24/735], Loss: 0.1518\n",
      "Epoch [13/50], Step [25/735], Loss: 0.1585\n",
      "Epoch [13/50], Step [26/735], Loss: 0.2627\n",
      "Epoch [13/50], Step [27/735], Loss: 0.0698\n",
      "Epoch [13/50], Step [28/735], Loss: 0.1847\n",
      "Epoch [13/50], Step [29/735], Loss: 0.4144\n",
      "Epoch [13/50], Step [30/735], Loss: 0.3088\n",
      "Epoch [13/50], Step [31/735], Loss: 0.1235\n",
      "Epoch [13/50], Step [32/735], Loss: 0.1130\n",
      "Epoch [13/50], Step [33/735], Loss: 0.0929\n",
      "Epoch [13/50], Step [34/735], Loss: 0.0725\n",
      "Epoch [13/50], Step [35/735], Loss: 0.2330\n",
      "Epoch [13/50], Step [36/735], Loss: 0.1472\n",
      "Epoch [13/50], Step [37/735], Loss: 1.5444\n",
      "Epoch [13/50], Step [38/735], Loss: 0.1327\n",
      "Epoch [13/50], Step [39/735], Loss: 0.2087\n",
      "Epoch [13/50], Step [40/735], Loss: 0.0348\n",
      "Epoch [13/50], Step [41/735], Loss: 0.2092\n",
      "Epoch [13/50], Step [42/735], Loss: 0.3528\n",
      "Epoch [13/50], Step [43/735], Loss: 0.0943\n",
      "Epoch [13/50], Step [44/735], Loss: 0.1603\n",
      "Epoch [13/50], Step [45/735], Loss: 0.1358\n",
      "Epoch [13/50], Step [46/735], Loss: 0.6343\n",
      "Epoch [13/50], Step [47/735], Loss: 0.0995\n",
      "Epoch [13/50], Step [48/735], Loss: 0.1473\n",
      "Epoch [13/50], Step [49/735], Loss: 0.0906\n",
      "Epoch [13/50], Step [50/735], Loss: 0.1200\n",
      "Epoch [13/50], Step [51/735], Loss: 0.1898\n",
      "Epoch [13/50], Step [52/735], Loss: 0.2800\n",
      "Epoch [13/50], Step [53/735], Loss: 0.1865\n",
      "Epoch [13/50], Step [54/735], Loss: 0.1696\n",
      "Epoch [13/50], Step [55/735], Loss: 0.1248\n",
      "Epoch [13/50], Step [56/735], Loss: 0.0575\n",
      "Epoch [13/50], Step [57/735], Loss: 0.1966\n",
      "Epoch [13/50], Step [58/735], Loss: 1.1807\n",
      "Epoch [13/50], Step [59/735], Loss: 0.2358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Step [60/735], Loss: 0.1706\n",
      "Epoch [13/50], Step [61/735], Loss: 0.1994\n",
      "Epoch [13/50], Step [62/735], Loss: 0.1304\n",
      "Epoch [13/50], Step [63/735], Loss: 0.0754\n",
      "Epoch [13/50], Step [64/735], Loss: 0.4595\n",
      "Epoch [13/50], Step [65/735], Loss: 0.3102\n",
      "Epoch [13/50], Step [66/735], Loss: 0.0743\n",
      "Epoch [13/50], Step [67/735], Loss: 0.3727\n",
      "Epoch [13/50], Step [68/735], Loss: 0.0361\n",
      "Epoch [13/50], Step [69/735], Loss: 0.4379\n",
      "Epoch [13/50], Step [70/735], Loss: 0.2811\n",
      "Epoch [13/50], Step [71/735], Loss: 0.1694\n",
      "Epoch [13/50], Step [72/735], Loss: 0.1044\n",
      "Epoch [13/50], Step [73/735], Loss: 0.0790\n",
      "Epoch [13/50], Step [74/735], Loss: 0.1245\n",
      "Epoch [13/50], Step [75/735], Loss: 0.0534\n",
      "Epoch [13/50], Step [76/735], Loss: 0.1573\n",
      "Epoch [13/50], Step [77/735], Loss: 0.1512\n",
      "Epoch [13/50], Step [78/735], Loss: 0.2059\n",
      "Epoch [13/50], Step [79/735], Loss: 0.1809\n",
      "Epoch [13/50], Step [80/735], Loss: 0.1690\n",
      "Epoch [13/50], Step [81/735], Loss: 0.3100\n",
      "Epoch [13/50], Step [82/735], Loss: 0.3146\n",
      "Epoch [13/50], Step [83/735], Loss: 0.1535\n",
      "Epoch [13/50], Step [84/735], Loss: 0.4319\n",
      "Epoch [13/50], Step [85/735], Loss: 0.1646\n",
      "Epoch [13/50], Step [86/735], Loss: 0.0953\n",
      "Epoch [13/50], Step [87/735], Loss: 0.0453\n",
      "Epoch [13/50], Step [88/735], Loss: 0.1657\n",
      "Epoch [13/50], Step [89/735], Loss: 0.1211\n",
      "Epoch [13/50], Step [90/735], Loss: 0.1278\n",
      "Epoch [13/50], Step [91/735], Loss: 0.1376\n",
      "Epoch [13/50], Step [92/735], Loss: 0.0770\n",
      "Epoch [13/50], Step [93/735], Loss: 0.0359\n",
      "Epoch [13/50], Step [94/735], Loss: 0.1281\n",
      "Epoch [13/50], Step [95/735], Loss: 0.3849\n",
      "Epoch [13/50], Step [96/735], Loss: 0.2632\n",
      "Epoch [13/50], Step [97/735], Loss: 0.2285\n",
      "Epoch [13/50], Step [98/735], Loss: 0.0292\n",
      "Epoch [13/50], Step [99/735], Loss: 0.1490\n",
      "Epoch [13/50], Step [100/735], Loss: 0.1755\n",
      "Epoch [13/50], Step [101/735], Loss: 0.2105\n",
      "Epoch [13/50], Step [102/735], Loss: 0.3032\n",
      "Epoch [13/50], Step [103/735], Loss: 0.2376\n",
      "Epoch [13/50], Step [104/735], Loss: 0.0852\n",
      "Epoch [13/50], Step [105/735], Loss: 0.0640\n",
      "Epoch [13/50], Step [106/735], Loss: 0.1111\n",
      "Epoch [13/50], Step [107/735], Loss: 0.1228\n",
      "Epoch [13/50], Step [108/735], Loss: 0.0341\n",
      "Epoch [13/50], Step [109/735], Loss: 0.5478\n",
      "Epoch [13/50], Step [110/735], Loss: 0.4274\n",
      "Epoch [13/50], Step [111/735], Loss: 0.1162\n",
      "Epoch [13/50], Step [112/735], Loss: 0.7914\n",
      "Epoch [13/50], Step [113/735], Loss: 0.0715\n",
      "Epoch [13/50], Step [114/735], Loss: 0.1416\n",
      "Epoch [13/50], Step [115/735], Loss: 0.3145\n",
      "Epoch [13/50], Step [116/735], Loss: 0.2625\n",
      "Epoch [13/50], Step [117/735], Loss: 0.0883\n",
      "Epoch [13/50], Step [118/735], Loss: 0.3746\n",
      "Epoch [13/50], Step [119/735], Loss: 0.1203\n",
      "Epoch [13/50], Step [120/735], Loss: 0.2028\n",
      "Epoch [13/50], Step [121/735], Loss: 0.0674\n",
      "Epoch [13/50], Step [122/735], Loss: 0.0924\n",
      "Epoch [13/50], Step [123/735], Loss: 0.1693\n",
      "Epoch [13/50], Step [124/735], Loss: 0.0600\n",
      "Epoch [13/50], Step [125/735], Loss: 0.0705\n",
      "Epoch [13/50], Step [126/735], Loss: 0.1332\n",
      "Epoch [13/50], Step [127/735], Loss: 0.1001\n",
      "Epoch [13/50], Step [128/735], Loss: 0.0753\n",
      "Epoch [13/50], Step [129/735], Loss: 0.0638\n",
      "Epoch [13/50], Step [130/735], Loss: 1.1496\n",
      "Epoch [13/50], Step [131/735], Loss: 0.2947\n",
      "Epoch [13/50], Step [132/735], Loss: 0.1364\n",
      "Epoch [13/50], Step [133/735], Loss: 0.1393\n",
      "Epoch [13/50], Step [134/735], Loss: 0.2015\n",
      "Epoch [13/50], Step [135/735], Loss: 0.1479\n",
      "Epoch [13/50], Step [136/735], Loss: 0.3840\n",
      "Epoch [13/50], Step [137/735], Loss: 0.0588\n",
      "Epoch [13/50], Step [138/735], Loss: 0.1812\n",
      "Epoch [13/50], Step [139/735], Loss: 0.2956\n",
      "Epoch [13/50], Step [140/735], Loss: 0.4722\n",
      "Epoch [13/50], Step [141/735], Loss: 0.0976\n",
      "Epoch [13/50], Step [142/735], Loss: 0.7753\n",
      "Epoch [13/50], Step [143/735], Loss: 0.0680\n",
      "Epoch [13/50], Step [144/735], Loss: 0.1518\n",
      "Epoch [13/50], Step [145/735], Loss: 0.1476\n",
      "Epoch [13/50], Step [146/735], Loss: 0.0741\n",
      "Epoch [13/50], Step [147/735], Loss: 0.1593\n",
      "Epoch [13/50], Step [148/735], Loss: 0.1189\n",
      "Epoch [13/50], Step [149/735], Loss: 0.3534\n",
      "Epoch [13/50], Step [150/735], Loss: 0.1385\n",
      "Epoch [13/50], Step [151/735], Loss: 0.2130\n",
      "Epoch [13/50], Step [152/735], Loss: 0.1371\n",
      "Epoch [13/50], Step [153/735], Loss: 0.0528\n",
      "Epoch [13/50], Step [154/735], Loss: 0.1644\n",
      "Epoch [13/50], Step [155/735], Loss: 0.6813\n",
      "Epoch [13/50], Step [156/735], Loss: 0.2886\n",
      "Epoch [13/50], Step [157/735], Loss: 0.1434\n",
      "Epoch [13/50], Step [158/735], Loss: 0.1016\n",
      "Epoch [13/50], Step [159/735], Loss: 0.2526\n",
      "Epoch [13/50], Step [160/735], Loss: 0.1685\n",
      "Epoch [13/50], Step [161/735], Loss: 0.0965\n",
      "Epoch [13/50], Step [162/735], Loss: 0.1237\n",
      "Epoch [13/50], Step [163/735], Loss: 0.9294\n",
      "Epoch [13/50], Step [164/735], Loss: 0.1008\n",
      "Epoch [13/50], Step [165/735], Loss: 0.2638\n",
      "Epoch [13/50], Step [166/735], Loss: 0.1700\n",
      "Epoch [13/50], Step [167/735], Loss: 0.0555\n",
      "Epoch [13/50], Step [168/735], Loss: 0.0556\n",
      "Epoch [13/50], Step [169/735], Loss: 0.1775\n",
      "Epoch [13/50], Step [170/735], Loss: 0.0785\n",
      "Epoch [13/50], Step [171/735], Loss: 0.1098\n",
      "Epoch [13/50], Step [172/735], Loss: 0.0711\n",
      "Epoch [13/50], Step [173/735], Loss: 0.2639\n",
      "Epoch [13/50], Step [174/735], Loss: 0.1143\n",
      "Epoch [13/50], Step [175/735], Loss: 0.0473\n",
      "Epoch [13/50], Step [176/735], Loss: 0.0595\n",
      "Epoch [13/50], Step [177/735], Loss: 0.1254\n",
      "Epoch [13/50], Step [178/735], Loss: 0.1631\n",
      "Epoch [13/50], Step [179/735], Loss: 0.1254\n",
      "Epoch [13/50], Step [180/735], Loss: 0.0817\n",
      "Epoch [13/50], Step [181/735], Loss: 0.0247\n",
      "Epoch [13/50], Step [182/735], Loss: 0.0948\n",
      "Epoch [13/50], Step [183/735], Loss: 0.1402\n",
      "Epoch [13/50], Step [184/735], Loss: 0.1942\n",
      "Epoch [13/50], Step [185/735], Loss: 0.0621\n",
      "Epoch [13/50], Step [186/735], Loss: 0.2531\n",
      "Epoch [13/50], Step [187/735], Loss: 0.0791\n",
      "Epoch [13/50], Step [188/735], Loss: 0.0672\n",
      "Epoch [13/50], Step [189/735], Loss: 0.0541\n",
      "Epoch [13/50], Step [190/735], Loss: 0.0574\n",
      "Epoch [13/50], Step [191/735], Loss: 0.1308\n",
      "Epoch [13/50], Step [192/735], Loss: 0.1747\n",
      "Epoch [13/50], Step [193/735], Loss: 0.0719\n",
      "Epoch [13/50], Step [194/735], Loss: 0.1686\n",
      "Epoch [13/50], Step [195/735], Loss: 0.2165\n",
      "Epoch [13/50], Step [196/735], Loss: 0.0784\n",
      "Epoch [13/50], Step [197/735], Loss: 0.0820\n",
      "Epoch [13/50], Step [198/735], Loss: 0.1173\n",
      "Epoch [13/50], Step [199/735], Loss: 0.2288\n",
      "Epoch [13/50], Step [200/735], Loss: 0.1890\n",
      "Epoch [13/50], Step [201/735], Loss: 0.2123\n",
      "Epoch [13/50], Step [202/735], Loss: 0.0680\n",
      "Epoch [13/50], Step [203/735], Loss: 0.0722\n",
      "Epoch [13/50], Step [204/735], Loss: 0.1216\n",
      "Epoch [13/50], Step [205/735], Loss: 0.1078\n",
      "Epoch [13/50], Step [206/735], Loss: 0.4507\n",
      "Epoch [13/50], Step [207/735], Loss: 0.0656\n",
      "Epoch [13/50], Step [208/735], Loss: 0.1827\n",
      "Epoch [13/50], Step [209/735], Loss: 0.1337\n",
      "Epoch [13/50], Step [210/735], Loss: 0.1247\n",
      "Epoch [13/50], Step [211/735], Loss: 0.0587\n",
      "Epoch [13/50], Step [212/735], Loss: 0.0900\n",
      "Epoch [13/50], Step [213/735], Loss: 0.1942\n",
      "Epoch [13/50], Step [214/735], Loss: 0.1248\n",
      "Epoch [13/50], Step [215/735], Loss: 0.2329\n",
      "Epoch [13/50], Step [216/735], Loss: 0.0756\n",
      "Epoch [13/50], Step [217/735], Loss: 0.1914\n",
      "Epoch [13/50], Step [218/735], Loss: 0.1201\n",
      "Epoch [13/50], Step [219/735], Loss: 0.2206\n",
      "Epoch [13/50], Step [220/735], Loss: 0.0591\n",
      "Epoch [13/50], Step [221/735], Loss: 0.1558\n",
      "Epoch [13/50], Step [222/735], Loss: 0.0785\n",
      "Epoch [13/50], Step [223/735], Loss: 0.0263\n",
      "Epoch [13/50], Step [224/735], Loss: 0.0836\n",
      "Epoch [13/50], Step [225/735], Loss: 0.0946\n",
      "Epoch [13/50], Step [226/735], Loss: 0.2022\n",
      "Epoch [13/50], Step [227/735], Loss: 0.1219\n",
      "Epoch [13/50], Step [228/735], Loss: 0.0883\n",
      "Epoch [13/50], Step [229/735], Loss: 0.0322\n",
      "Epoch [13/50], Step [230/735], Loss: 0.6330\n",
      "Epoch [13/50], Step [231/735], Loss: 0.1871\n",
      "Epoch [13/50], Step [232/735], Loss: 0.0775\n",
      "Epoch [13/50], Step [233/735], Loss: 0.5865\n",
      "Epoch [13/50], Step [234/735], Loss: 0.1454\n",
      "Epoch [13/50], Step [235/735], Loss: 0.1475\n",
      "Epoch [13/50], Step [236/735], Loss: 0.0413\n",
      "Epoch [13/50], Step [237/735], Loss: 0.3394\n",
      "Epoch [13/50], Step [238/735], Loss: 0.0592\n",
      "Epoch [13/50], Step [239/735], Loss: 0.3007\n",
      "Epoch [13/50], Step [240/735], Loss: 0.1341\n",
      "Epoch [13/50], Step [241/735], Loss: 0.1737\n",
      "Epoch [13/50], Step [242/735], Loss: 0.0623\n",
      "Epoch [13/50], Step [243/735], Loss: 0.4319\n",
      "Epoch [13/50], Step [244/735], Loss: 0.0773\n",
      "Epoch [13/50], Step [245/735], Loss: 0.2033\n",
      "Epoch [13/50], Step [246/735], Loss: 0.0369\n",
      "Epoch [13/50], Step [247/735], Loss: 0.1036\n",
      "Epoch [13/50], Step [248/735], Loss: 0.1816\n",
      "Epoch [13/50], Step [249/735], Loss: 0.3794\n",
      "Epoch [13/50], Step [250/735], Loss: 0.3184\n",
      "Epoch [13/50], Step [251/735], Loss: 0.0817\n",
      "Epoch [13/50], Step [252/735], Loss: 0.2730\n",
      "Epoch [13/50], Step [253/735], Loss: 0.0587\n",
      "Epoch [13/50], Step [254/735], Loss: 0.0790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Step [255/735], Loss: 0.3599\n",
      "Epoch [13/50], Step [256/735], Loss: 0.0791\n",
      "Epoch [13/50], Step [257/735], Loss: 0.2546\n",
      "Epoch [13/50], Step [258/735], Loss: 0.4417\n",
      "Epoch [13/50], Step [259/735], Loss: 0.2927\n",
      "Epoch [13/50], Step [260/735], Loss: 0.1379\n",
      "Epoch [13/50], Step [261/735], Loss: 0.8901\n",
      "Epoch [13/50], Step [262/735], Loss: 0.1993\n",
      "Epoch [13/50], Step [263/735], Loss: 0.2560\n",
      "Epoch [13/50], Step [264/735], Loss: 0.4353\n",
      "Epoch [13/50], Step [265/735], Loss: 0.3245\n",
      "Epoch [13/50], Step [266/735], Loss: 0.1851\n",
      "Epoch [13/50], Step [267/735], Loss: 0.0995\n",
      "Epoch [13/50], Step [268/735], Loss: 0.3912\n",
      "Epoch [13/50], Step [269/735], Loss: 0.0480\n",
      "Epoch [13/50], Step [270/735], Loss: 0.2267\n",
      "Epoch [13/50], Step [271/735], Loss: 0.2288\n",
      "Epoch [13/50], Step [272/735], Loss: 0.1527\n",
      "Epoch [13/50], Step [273/735], Loss: 0.1504\n",
      "Epoch [13/50], Step [274/735], Loss: 0.2923\n",
      "Epoch [13/50], Step [275/735], Loss: 0.0961\n",
      "Epoch [13/50], Step [276/735], Loss: 0.1136\n",
      "Epoch [13/50], Step [277/735], Loss: 0.0944\n",
      "Epoch [13/50], Step [278/735], Loss: 0.1002\n",
      "Epoch [13/50], Step [279/735], Loss: 0.0774\n",
      "Epoch [13/50], Step [280/735], Loss: 0.1590\n",
      "Epoch [13/50], Step [281/735], Loss: 0.0736\n",
      "Epoch [13/50], Step [282/735], Loss: 0.0781\n",
      "Epoch [13/50], Step [283/735], Loss: 0.1696\n",
      "Epoch [13/50], Step [284/735], Loss: 0.1883\n",
      "Epoch [13/50], Step [285/735], Loss: 0.4606\n",
      "Epoch [13/50], Step [286/735], Loss: 0.2117\n",
      "Epoch [13/50], Step [287/735], Loss: 0.5926\n",
      "Epoch [13/50], Step [288/735], Loss: 0.1075\n",
      "Epoch [13/50], Step [289/735], Loss: 0.0958\n",
      "Epoch [13/50], Step [290/735], Loss: 0.2876\n",
      "Epoch [13/50], Step [291/735], Loss: 0.1901\n",
      "Epoch [13/50], Step [292/735], Loss: 0.0631\n",
      "Epoch [13/50], Step [293/735], Loss: 0.1055\n",
      "Epoch [13/50], Step [294/735], Loss: 0.1426\n",
      "Epoch [13/50], Step [295/735], Loss: 0.1025\n",
      "Epoch [13/50], Step [296/735], Loss: 0.9570\n",
      "Epoch [13/50], Step [297/735], Loss: 0.0604\n",
      "Epoch [13/50], Step [298/735], Loss: 0.0729\n",
      "Epoch [13/50], Step [299/735], Loss: 0.1181\n",
      "Epoch [13/50], Step [300/735], Loss: 0.1965\n",
      "Epoch [13/50], Step [301/735], Loss: 0.2022\n",
      "Epoch [13/50], Step [302/735], Loss: 0.1709\n",
      "Epoch [13/50], Step [303/735], Loss: 0.0846\n",
      "Epoch [13/50], Step [304/735], Loss: 0.1387\n",
      "Epoch [13/50], Step [305/735], Loss: 0.0606\n",
      "Epoch [13/50], Step [306/735], Loss: 0.1784\n",
      "Epoch [13/50], Step [307/735], Loss: 0.1716\n",
      "Epoch [13/50], Step [308/735], Loss: 0.1224\n",
      "Epoch [13/50], Step [309/735], Loss: 0.0853\n",
      "Epoch [13/50], Step [310/735], Loss: 0.1276\n",
      "Epoch [13/50], Step [311/735], Loss: 0.2392\n",
      "Epoch [13/50], Step [312/735], Loss: 0.0888\n",
      "Epoch [13/50], Step [313/735], Loss: 0.1468\n",
      "Epoch [13/50], Step [314/735], Loss: 0.1491\n",
      "Epoch [13/50], Step [315/735], Loss: 0.2455\n",
      "Epoch [13/50], Step [316/735], Loss: 0.0740\n",
      "Epoch [13/50], Step [317/735], Loss: 0.1445\n",
      "Epoch [13/50], Step [318/735], Loss: 0.0943\n",
      "Epoch [13/50], Step [319/735], Loss: 0.2900\n",
      "Epoch [13/50], Step [320/735], Loss: 0.0882\n",
      "Epoch [13/50], Step [321/735], Loss: 0.1430\n",
      "Epoch [13/50], Step [322/735], Loss: 0.3518\n",
      "Epoch [13/50], Step [323/735], Loss: 0.0504\n",
      "Epoch [13/50], Step [324/735], Loss: 0.1436\n",
      "Epoch [13/50], Step [325/735], Loss: 0.1111\n",
      "Epoch [13/50], Step [326/735], Loss: 0.0763\n",
      "Epoch [13/50], Step [327/735], Loss: 0.2765\n",
      "Epoch [13/50], Step [328/735], Loss: 0.0683\n",
      "Epoch [13/50], Step [329/735], Loss: 0.2037\n",
      "Epoch [13/50], Step [330/735], Loss: 0.3771\n",
      "Epoch [13/50], Step [331/735], Loss: 1.1972\n",
      "Epoch [13/50], Step [332/735], Loss: 0.1487\n",
      "Epoch [13/50], Step [333/735], Loss: 0.2595\n",
      "Epoch [13/50], Step [334/735], Loss: 0.1263\n",
      "Epoch [13/50], Step [335/735], Loss: 0.1197\n",
      "Epoch [13/50], Step [336/735], Loss: 0.0654\n",
      "Epoch [13/50], Step [337/735], Loss: 0.0343\n",
      "Epoch [13/50], Step [338/735], Loss: 0.2322\n",
      "Epoch [13/50], Step [339/735], Loss: 0.0318\n",
      "Epoch [13/50], Step [340/735], Loss: 0.6766\n",
      "Epoch [13/50], Step [341/735], Loss: 0.2069\n",
      "Epoch [13/50], Step [342/735], Loss: 0.6964\n",
      "Epoch [13/50], Step [343/735], Loss: 0.1983\n",
      "Epoch [13/50], Step [344/735], Loss: 0.1020\n",
      "Epoch [13/50], Step [345/735], Loss: 0.2785\n",
      "Epoch [13/50], Step [346/735], Loss: 0.2419\n",
      "Epoch [13/50], Step [347/735], Loss: 0.0780\n",
      "Epoch [13/50], Step [348/735], Loss: 0.1323\n",
      "Epoch [13/50], Step [349/735], Loss: 0.0938\n",
      "Epoch [13/50], Step [350/735], Loss: 0.1565\n",
      "Epoch [13/50], Step [351/735], Loss: 0.1011\n",
      "Epoch [13/50], Step [352/735], Loss: 0.0583\n",
      "Epoch [13/50], Step [353/735], Loss: 0.1121\n",
      "Epoch [13/50], Step [354/735], Loss: 0.0511\n",
      "Epoch [13/50], Step [355/735], Loss: 0.1248\n",
      "Epoch [13/50], Step [356/735], Loss: 0.0501\n",
      "Epoch [13/50], Step [357/735], Loss: 0.1219\n",
      "Epoch [13/50], Step [358/735], Loss: 0.0827\n",
      "Epoch [13/50], Step [359/735], Loss: 0.0449\n",
      "Epoch [13/50], Step [360/735], Loss: 0.2555\n",
      "Epoch [13/50], Step [361/735], Loss: 0.1597\n",
      "Epoch [13/50], Step [362/735], Loss: 0.1613\n",
      "Epoch [13/50], Step [363/735], Loss: 0.3130\n",
      "Epoch [13/50], Step [364/735], Loss: 0.1314\n",
      "Epoch [13/50], Step [365/735], Loss: 0.0835\n",
      "Epoch [13/50], Step [366/735], Loss: 0.0901\n",
      "Epoch [13/50], Step [367/735], Loss: 0.2021\n",
      "Epoch [13/50], Step [368/735], Loss: 0.1316\n",
      "Epoch [13/50], Step [369/735], Loss: 0.1847\n",
      "Epoch [13/50], Step [370/735], Loss: 0.3995\n",
      "Epoch [13/50], Step [371/735], Loss: 0.1602\n",
      "Epoch [13/50], Step [372/735], Loss: 0.5292\n",
      "Epoch [13/50], Step [373/735], Loss: 0.0928\n",
      "Epoch [13/50], Step [374/735], Loss: 0.2148\n",
      "Epoch [13/50], Step [375/735], Loss: 0.1656\n",
      "Epoch [13/50], Step [376/735], Loss: 0.1156\n",
      "Epoch [13/50], Step [377/735], Loss: 1.2787\n",
      "Epoch [13/50], Step [378/735], Loss: 0.1358\n",
      "Epoch [13/50], Step [379/735], Loss: 0.1196\n",
      "Epoch [13/50], Step [380/735], Loss: 0.2340\n",
      "Epoch [13/50], Step [381/735], Loss: 0.1304\n",
      "Epoch [13/50], Step [382/735], Loss: 0.1559\n",
      "Epoch [13/50], Step [383/735], Loss: 0.2517\n",
      "Epoch [13/50], Step [384/735], Loss: 0.2212\n",
      "Epoch [13/50], Step [385/735], Loss: 0.1071\n",
      "Epoch [13/50], Step [386/735], Loss: 0.1279\n",
      "Epoch [13/50], Step [387/735], Loss: 0.1801\n",
      "Epoch [13/50], Step [388/735], Loss: 0.3833\n",
      "Epoch [13/50], Step [389/735], Loss: 0.0480\n",
      "Epoch [13/50], Step [390/735], Loss: 0.3673\n",
      "Epoch [13/50], Step [391/735], Loss: 0.0650\n",
      "Epoch [13/50], Step [392/735], Loss: 0.2110\n",
      "Epoch [13/50], Step [393/735], Loss: 0.1608\n",
      "Epoch [13/50], Step [394/735], Loss: 2.6361\n",
      "Epoch [13/50], Step [395/735], Loss: 0.0789\n",
      "Epoch [13/50], Step [396/735], Loss: 0.2338\n",
      "Epoch [13/50], Step [397/735], Loss: 0.1428\n",
      "Epoch [13/50], Step [398/735], Loss: 0.1479\n",
      "Epoch [13/50], Step [399/735], Loss: 0.2637\n",
      "Epoch [13/50], Step [400/735], Loss: 0.1987\n",
      "Epoch [13/50], Step [401/735], Loss: 0.2164\n",
      "Epoch [13/50], Step [402/735], Loss: 0.0400\n",
      "Epoch [13/50], Step [403/735], Loss: 0.2649\n",
      "Epoch [13/50], Step [404/735], Loss: 0.2817\n",
      "Epoch [13/50], Step [405/735], Loss: 0.1446\n",
      "Epoch [13/50], Step [406/735], Loss: 0.0415\n",
      "Epoch [13/50], Step [407/735], Loss: 0.3096\n",
      "Epoch [13/50], Step [408/735], Loss: 0.1659\n",
      "Epoch [13/50], Step [409/735], Loss: 0.1239\n",
      "Epoch [13/50], Step [410/735], Loss: 0.1740\n",
      "Epoch [13/50], Step [411/735], Loss: 0.0650\n",
      "Epoch [13/50], Step [412/735], Loss: 0.2724\n",
      "Epoch [13/50], Step [413/735], Loss: 0.1942\n",
      "Epoch [13/50], Step [414/735], Loss: 0.0422\n",
      "Epoch [13/50], Step [415/735], Loss: 0.0710\n",
      "Epoch [13/50], Step [416/735], Loss: 0.0439\n",
      "Epoch [13/50], Step [417/735], Loss: 0.2027\n",
      "Epoch [13/50], Step [418/735], Loss: 0.5574\n",
      "Epoch [13/50], Step [419/735], Loss: 0.7924\n",
      "Epoch [13/50], Step [420/735], Loss: 0.1905\n",
      "Epoch [13/50], Step [421/735], Loss: 0.1410\n",
      "Epoch [13/50], Step [422/735], Loss: 0.1429\n",
      "Epoch [13/50], Step [423/735], Loss: 0.1949\n",
      "Epoch [13/50], Step [424/735], Loss: 0.2437\n",
      "Epoch [13/50], Step [425/735], Loss: 0.1896\n",
      "Epoch [13/50], Step [426/735], Loss: 0.0724\n",
      "Epoch [13/50], Step [427/735], Loss: 0.1891\n",
      "Epoch [13/50], Step [428/735], Loss: 0.1088\n",
      "Epoch [13/50], Step [429/735], Loss: 0.0825\n",
      "Epoch [13/50], Step [430/735], Loss: 0.1081\n",
      "Epoch [13/50], Step [431/735], Loss: 0.2205\n",
      "Epoch [13/50], Step [432/735], Loss: 0.2256\n",
      "Epoch [13/50], Step [433/735], Loss: 0.0684\n",
      "Epoch [13/50], Step [434/735], Loss: 0.0552\n",
      "Epoch [13/50], Step [435/735], Loss: 0.1060\n",
      "Epoch [13/50], Step [436/735], Loss: 0.2775\n",
      "Epoch [13/50], Step [437/735], Loss: 0.1347\n",
      "Epoch [13/50], Step [438/735], Loss: 0.1521\n",
      "Epoch [13/50], Step [439/735], Loss: 0.1401\n",
      "Epoch [13/50], Step [440/735], Loss: 0.2915\n",
      "Epoch [13/50], Step [441/735], Loss: 0.1974\n",
      "Epoch [13/50], Step [442/735], Loss: 0.1595\n",
      "Epoch [13/50], Step [443/735], Loss: 0.1357\n",
      "Epoch [13/50], Step [444/735], Loss: 0.1451\n",
      "Epoch [13/50], Step [445/735], Loss: 0.1830\n",
      "Epoch [13/50], Step [446/735], Loss: 0.2089\n",
      "Epoch [13/50], Step [447/735], Loss: 0.0671\n",
      "Epoch [13/50], Step [448/735], Loss: 0.1430\n",
      "Epoch [13/50], Step [449/735], Loss: 0.1881\n",
      "Epoch [13/50], Step [450/735], Loss: 0.1736\n",
      "Epoch [13/50], Step [451/735], Loss: 2.6844\n",
      "Epoch [13/50], Step [452/735], Loss: 0.0790\n",
      "Epoch [13/50], Step [453/735], Loss: 0.1722\n",
      "Epoch [13/50], Step [454/735], Loss: 0.0343\n",
      "Epoch [13/50], Step [455/735], Loss: 0.3303\n",
      "Epoch [13/50], Step [456/735], Loss: 0.3200\n",
      "Epoch [13/50], Step [457/735], Loss: 0.4084\n",
      "Epoch [13/50], Step [458/735], Loss: 0.1224\n",
      "Epoch [13/50], Step [459/735], Loss: 0.1050\n",
      "Epoch [13/50], Step [460/735], Loss: 0.0530\n",
      "Epoch [13/50], Step [461/735], Loss: 0.1976\n",
      "Epoch [13/50], Step [462/735], Loss: 0.2728\n",
      "Epoch [13/50], Step [463/735], Loss: 0.1018\n",
      "Epoch [13/50], Step [464/735], Loss: 0.1032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Step [465/735], Loss: 0.1316\n",
      "Epoch [13/50], Step [466/735], Loss: 0.0779\n",
      "Epoch [13/50], Step [467/735], Loss: 0.5009\n",
      "Epoch [13/50], Step [468/735], Loss: 0.0784\n",
      "Epoch [13/50], Step [469/735], Loss: 0.3288\n",
      "Epoch [13/50], Step [470/735], Loss: 0.0866\n",
      "Epoch [13/50], Step [471/735], Loss: 0.2022\n",
      "Epoch [13/50], Step [472/735], Loss: 0.2644\n",
      "Epoch [13/50], Step [473/735], Loss: 0.0530\n",
      "Epoch [13/50], Step [474/735], Loss: 0.0433\n",
      "Epoch [13/50], Step [475/735], Loss: 0.1576\n",
      "Epoch [13/50], Step [476/735], Loss: 0.2585\n",
      "Epoch [13/50], Step [477/735], Loss: 0.1193\n",
      "Epoch [13/50], Step [478/735], Loss: 0.1265\n",
      "Epoch [13/50], Step [479/735], Loss: 0.0990\n",
      "Epoch [13/50], Step [480/735], Loss: 0.2949\n",
      "Epoch [13/50], Step [481/735], Loss: 0.0654\n",
      "Epoch [13/50], Step [482/735], Loss: 0.1121\n",
      "Epoch [13/50], Step [483/735], Loss: 0.2731\n",
      "Epoch [13/50], Step [484/735], Loss: 0.1735\n",
      "Epoch [13/50], Step [485/735], Loss: 0.1596\n",
      "Epoch [13/50], Step [486/735], Loss: 0.1812\n",
      "Epoch [13/50], Step [487/735], Loss: 0.1074\n",
      "Epoch [13/50], Step [488/735], Loss: 0.0578\n",
      "Epoch [13/50], Step [489/735], Loss: 0.1807\n",
      "Epoch [13/50], Step [490/735], Loss: 0.0437\n",
      "Epoch [13/50], Step [491/735], Loss: 0.2146\n",
      "Epoch [13/50], Step [492/735], Loss: 0.1115\n",
      "Epoch [13/50], Step [493/735], Loss: 0.0442\n",
      "Epoch [13/50], Step [494/735], Loss: 0.0703\n",
      "Epoch [13/50], Step [495/735], Loss: 0.2171\n",
      "Epoch [13/50], Step [496/735], Loss: 0.1060\n",
      "Epoch [13/50], Step [497/735], Loss: 0.0731\n",
      "Epoch [13/50], Step [498/735], Loss: 0.1426\n",
      "Epoch [13/50], Step [499/735], Loss: 0.1635\n",
      "Epoch [13/50], Step [500/735], Loss: 0.1400\n",
      "Epoch [13/50], Step [501/735], Loss: 0.3522\n",
      "Epoch [13/50], Step [502/735], Loss: 0.6012\n",
      "Epoch [13/50], Step [503/735], Loss: 0.2803\n",
      "Epoch [13/50], Step [504/735], Loss: 0.0964\n",
      "Epoch [13/50], Step [505/735], Loss: 3.9640\n",
      "Epoch [13/50], Step [506/735], Loss: 0.1372\n",
      "Epoch [13/50], Step [507/735], Loss: 0.1341\n",
      "Epoch [13/50], Step [508/735], Loss: 0.2521\n",
      "Epoch [13/50], Step [509/735], Loss: 0.1250\n",
      "Epoch [13/50], Step [510/735], Loss: 0.1399\n",
      "Epoch [13/50], Step [511/735], Loss: 0.0839\n",
      "Epoch [13/50], Step [512/735], Loss: 2.3281\n",
      "Epoch [13/50], Step [513/735], Loss: 0.0891\n",
      "Epoch [13/50], Step [514/735], Loss: 0.4126\n",
      "Epoch [13/50], Step [515/735], Loss: 0.2523\n",
      "Epoch [13/50], Step [516/735], Loss: 0.1890\n",
      "Epoch [13/50], Step [517/735], Loss: 0.1067\n",
      "Epoch [13/50], Step [518/735], Loss: 0.1281\n",
      "Epoch [13/50], Step [519/735], Loss: 0.2075\n",
      "Epoch [13/50], Step [520/735], Loss: 0.4203\n",
      "Epoch [13/50], Step [521/735], Loss: 0.0819\n",
      "Epoch [13/50], Step [522/735], Loss: 0.1413\n",
      "Epoch [13/50], Step [523/735], Loss: 0.4462\n",
      "Epoch [13/50], Step [524/735], Loss: 0.0588\n",
      "Epoch [13/50], Step [525/735], Loss: 0.0938\n",
      "Epoch [13/50], Step [526/735], Loss: 0.2239\n",
      "Epoch [13/50], Step [527/735], Loss: 0.1322\n",
      "Epoch [13/50], Step [528/735], Loss: 0.1352\n",
      "Epoch [13/50], Step [529/735], Loss: 0.0663\n",
      "Epoch [13/50], Step [530/735], Loss: 0.9934\n",
      "Epoch [13/50], Step [531/735], Loss: 0.1789\n",
      "Epoch [13/50], Step [532/735], Loss: 0.1707\n",
      "Epoch [13/50], Step [533/735], Loss: 0.1148\n",
      "Epoch [13/50], Step [534/735], Loss: 0.3706\n",
      "Epoch [13/50], Step [535/735], Loss: 0.4038\n",
      "Epoch [13/50], Step [536/735], Loss: 0.0557\n",
      "Epoch [13/50], Step [537/735], Loss: 0.1078\n",
      "Epoch [13/50], Step [538/735], Loss: 0.3222\n",
      "Epoch [13/50], Step [539/735], Loss: 0.1122\n",
      "Epoch [13/50], Step [540/735], Loss: 0.0810\n",
      "Epoch [13/50], Step [541/735], Loss: 0.0425\n",
      "Epoch [13/50], Step [542/735], Loss: 0.1494\n",
      "Epoch [13/50], Step [543/735], Loss: 0.0596\n",
      "Epoch [13/50], Step [544/735], Loss: 0.0507\n",
      "Epoch [13/50], Step [545/735], Loss: 0.3606\n",
      "Epoch [13/50], Step [546/735], Loss: 0.0899\n",
      "Epoch [13/50], Step [547/735], Loss: 0.1531\n",
      "Epoch [13/50], Step [548/735], Loss: 0.2894\n",
      "Epoch [13/50], Step [549/735], Loss: 0.1227\n",
      "Epoch [13/50], Step [550/735], Loss: 0.2847\n",
      "Epoch [13/50], Step [551/735], Loss: 0.2970\n",
      "Epoch [13/50], Step [552/735], Loss: 0.2004\n",
      "Epoch [13/50], Step [553/735], Loss: 0.4811\n",
      "Epoch [13/50], Step [554/735], Loss: 0.1956\n",
      "Epoch [13/50], Step [555/735], Loss: 0.1058\n",
      "Epoch [13/50], Step [556/735], Loss: 0.1384\n",
      "Epoch [13/50], Step [557/735], Loss: 0.1277\n",
      "Epoch [13/50], Step [558/735], Loss: 0.4346\n",
      "Epoch [13/50], Step [559/735], Loss: 0.5027\n",
      "Epoch [13/50], Step [560/735], Loss: 0.1334\n",
      "Epoch [13/50], Step [561/735], Loss: 0.1242\n",
      "Epoch [13/50], Step [562/735], Loss: 0.1832\n",
      "Epoch [13/50], Step [563/735], Loss: 0.1896\n",
      "Epoch [13/50], Step [564/735], Loss: 0.0559\n",
      "Epoch [13/50], Step [565/735], Loss: 0.3919\n",
      "Epoch [13/50], Step [566/735], Loss: 0.3153\n",
      "Epoch [13/50], Step [567/735], Loss: 0.2435\n",
      "Epoch [13/50], Step [568/735], Loss: 0.3390\n",
      "Epoch [13/50], Step [569/735], Loss: 0.1381\n",
      "Epoch [13/50], Step [570/735], Loss: 0.1186\n",
      "Epoch [13/50], Step [571/735], Loss: 0.1809\n",
      "Epoch [13/50], Step [572/735], Loss: 1.2057\n",
      "Epoch [13/50], Step [573/735], Loss: 0.0882\n",
      "Epoch [13/50], Step [574/735], Loss: 0.4013\n",
      "Epoch [13/50], Step [575/735], Loss: 0.6406\n",
      "Epoch [13/50], Step [576/735], Loss: 0.1608\n",
      "Epoch [13/50], Step [577/735], Loss: 0.1099\n",
      "Epoch [13/50], Step [578/735], Loss: 0.0960\n",
      "Epoch [13/50], Step [579/735], Loss: 0.2735\n",
      "Epoch [13/50], Step [580/735], Loss: 0.1094\n",
      "Epoch [13/50], Step [581/735], Loss: 0.1399\n",
      "Epoch [13/50], Step [582/735], Loss: 0.1590\n",
      "Epoch [13/50], Step [583/735], Loss: 0.1958\n",
      "Epoch [13/50], Step [584/735], Loss: 1.0721\n",
      "Epoch [13/50], Step [585/735], Loss: 0.2281\n",
      "Epoch [13/50], Step [586/735], Loss: 0.1511\n",
      "Epoch [13/50], Step [587/735], Loss: 0.2224\n",
      "Epoch [13/50], Step [588/735], Loss: 0.8064\n",
      "Epoch [13/50], Step [589/735], Loss: 0.1821\n",
      "Epoch [13/50], Step [590/735], Loss: 0.2411\n",
      "Epoch [13/50], Step [591/735], Loss: 0.4917\n",
      "Epoch [13/50], Step [592/735], Loss: 0.1930\n",
      "Epoch [13/50], Step [593/735], Loss: 0.1551\n",
      "Epoch [13/50], Step [594/735], Loss: 0.1444\n",
      "Epoch [13/50], Step [595/735], Loss: 0.6368\n",
      "Epoch [13/50], Step [596/735], Loss: 0.0781\n",
      "Epoch [13/50], Step [597/735], Loss: 0.1535\n",
      "Epoch [13/50], Step [598/735], Loss: 0.0684\n",
      "Epoch [13/50], Step [599/735], Loss: 0.1479\n",
      "Epoch [13/50], Step [600/735], Loss: 0.2343\n",
      "Epoch [13/50], Step [601/735], Loss: 0.0888\n",
      "Epoch [13/50], Step [602/735], Loss: 0.0911\n",
      "Epoch [13/50], Step [603/735], Loss: 0.1503\n",
      "Epoch [13/50], Step [604/735], Loss: 0.2263\n",
      "Epoch [13/50], Step [605/735], Loss: 0.1366\n",
      "Epoch [13/50], Step [606/735], Loss: 0.1111\n",
      "Epoch [13/50], Step [607/735], Loss: 0.4146\n",
      "Epoch [13/50], Step [608/735], Loss: 0.0400\n",
      "Epoch [13/50], Step [609/735], Loss: 0.0818\n",
      "Epoch [13/50], Step [610/735], Loss: 0.3366\n",
      "Epoch [13/50], Step [611/735], Loss: 0.1415\n",
      "Epoch [13/50], Step [612/735], Loss: 0.0834\n",
      "Epoch [13/50], Step [613/735], Loss: 0.1620\n",
      "Epoch [13/50], Step [614/735], Loss: 0.3328\n",
      "Epoch [13/50], Step [615/735], Loss: 0.2050\n",
      "Epoch [13/50], Step [616/735], Loss: 0.1151\n",
      "Epoch [13/50], Step [617/735], Loss: 0.1131\n",
      "Epoch [13/50], Step [618/735], Loss: 0.0666\n",
      "Epoch [13/50], Step [619/735], Loss: 0.0902\n",
      "Epoch [13/50], Step [620/735], Loss: 0.1722\n",
      "Epoch [13/50], Step [621/735], Loss: 0.0374\n",
      "Epoch [13/50], Step [622/735], Loss: 0.0721\n",
      "Epoch [13/50], Step [623/735], Loss: 0.7019\n",
      "Epoch [13/50], Step [624/735], Loss: 0.1461\n",
      "Epoch [13/50], Step [625/735], Loss: 0.1953\n",
      "Epoch [13/50], Step [626/735], Loss: 0.2077\n",
      "Epoch [13/50], Step [627/735], Loss: 1.6914\n",
      "Epoch [13/50], Step [628/735], Loss: 0.1203\n",
      "Epoch [13/50], Step [629/735], Loss: 1.0174\n",
      "Epoch [13/50], Step [630/735], Loss: 0.2539\n",
      "Epoch [13/50], Step [631/735], Loss: 0.1309\n",
      "Epoch [13/50], Step [632/735], Loss: 0.5820\n",
      "Epoch [13/50], Step [633/735], Loss: 0.0840\n",
      "Epoch [13/50], Step [634/735], Loss: 0.1779\n",
      "Epoch [13/50], Step [635/735], Loss: 0.0766\n",
      "Epoch [13/50], Step [636/735], Loss: 0.0597\n",
      "Epoch [13/50], Step [637/735], Loss: 0.3428\n",
      "Epoch [13/50], Step [638/735], Loss: 0.1249\n",
      "Epoch [13/50], Step [639/735], Loss: 0.6049\n",
      "Epoch [13/50], Step [640/735], Loss: 0.1042\n",
      "Epoch [13/50], Step [641/735], Loss: 0.3204\n",
      "Epoch [13/50], Step [642/735], Loss: 0.0887\n",
      "Epoch [13/50], Step [643/735], Loss: 0.2269\n",
      "Epoch [13/50], Step [644/735], Loss: 0.5356\n",
      "Epoch [13/50], Step [645/735], Loss: 0.1657\n",
      "Epoch [13/50], Step [646/735], Loss: 0.0790\n",
      "Epoch [13/50], Step [647/735], Loss: 0.1799\n",
      "Epoch [13/50], Step [648/735], Loss: 0.1597\n",
      "Epoch [13/50], Step [649/735], Loss: 1.5821\n",
      "Epoch [13/50], Step [650/735], Loss: 0.2288\n",
      "Epoch [13/50], Step [651/735], Loss: 0.1055\n",
      "Epoch [13/50], Step [652/735], Loss: 0.0615\n",
      "Epoch [13/50], Step [653/735], Loss: 0.1390\n",
      "Epoch [13/50], Step [654/735], Loss: 0.1851\n",
      "Epoch [13/50], Step [655/735], Loss: 0.1932\n",
      "Epoch [13/50], Step [656/735], Loss: 0.0872\n",
      "Epoch [13/50], Step [657/735], Loss: 1.1168\n",
      "Epoch [13/50], Step [658/735], Loss: 0.0967\n",
      "Epoch [13/50], Step [659/735], Loss: 0.2078\n",
      "Epoch [13/50], Step [660/735], Loss: 0.2146\n",
      "Epoch [13/50], Step [661/735], Loss: 0.0771\n",
      "Epoch [13/50], Step [662/735], Loss: 0.1165\n",
      "Epoch [13/50], Step [663/735], Loss: 0.1648\n",
      "Epoch [13/50], Step [664/735], Loss: 0.2637\n",
      "Epoch [13/50], Step [665/735], Loss: 0.2203\n",
      "Epoch [13/50], Step [666/735], Loss: 0.2546\n",
      "Epoch [13/50], Step [667/735], Loss: 0.0835\n",
      "Epoch [13/50], Step [668/735], Loss: 0.6907\n",
      "Epoch [13/50], Step [669/735], Loss: 0.0691\n",
      "Epoch [13/50], Step [670/735], Loss: 1.1075\n",
      "Epoch [13/50], Step [671/735], Loss: 0.2024\n",
      "Epoch [13/50], Step [672/735], Loss: 0.3609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Step [673/735], Loss: 0.2312\n",
      "Epoch [13/50], Step [674/735], Loss: 0.0932\n",
      "Epoch [13/50], Step [675/735], Loss: 0.1005\n",
      "Epoch [13/50], Step [676/735], Loss: 0.1614\n",
      "Epoch [13/50], Step [677/735], Loss: 0.2598\n",
      "Epoch [13/50], Step [678/735], Loss: 0.3324\n",
      "Epoch [13/50], Step [679/735], Loss: 0.1352\n",
      "Epoch [13/50], Step [680/735], Loss: 0.1806\n",
      "Epoch [13/50], Step [681/735], Loss: 0.2023\n",
      "Epoch [13/50], Step [682/735], Loss: 0.1450\n",
      "Epoch [13/50], Step [683/735], Loss: 0.3977\n",
      "Epoch [13/50], Step [684/735], Loss: 0.0857\n",
      "Epoch [13/50], Step [685/735], Loss: 0.2927\n",
      "Epoch [13/50], Step [686/735], Loss: 0.3807\n",
      "Epoch [13/50], Step [687/735], Loss: 0.1091\n",
      "Epoch [13/50], Step [688/735], Loss: 0.0829\n",
      "Epoch [13/50], Step [689/735], Loss: 0.1911\n",
      "Epoch [13/50], Step [690/735], Loss: 0.1822\n",
      "Epoch [13/50], Step [691/735], Loss: 0.1464\n",
      "Epoch [13/50], Step [692/735], Loss: 0.1003\n",
      "Epoch [13/50], Step [693/735], Loss: 0.1235\n",
      "Epoch [13/50], Step [694/735], Loss: 0.8951\n",
      "Epoch [13/50], Step [695/735], Loss: 0.1413\n",
      "Epoch [13/50], Step [696/735], Loss: 0.1180\n",
      "Epoch [13/50], Step [697/735], Loss: 0.0683\n",
      "Epoch [13/50], Step [698/735], Loss: 0.1197\n",
      "Epoch [13/50], Step [699/735], Loss: 0.0536\n",
      "Epoch [13/50], Step [700/735], Loss: 0.1102\n",
      "Epoch [13/50], Step [701/735], Loss: 0.1151\n",
      "Epoch [13/50], Step [702/735], Loss: 0.2796\n",
      "Epoch [13/50], Step [703/735], Loss: 0.1949\n",
      "Epoch [13/50], Step [704/735], Loss: 0.2242\n",
      "Epoch [13/50], Step [705/735], Loss: 0.4732\n",
      "Epoch [13/50], Step [706/735], Loss: 0.3370\n",
      "Epoch [13/50], Step [707/735], Loss: 0.1649\n",
      "Epoch [13/50], Step [708/735], Loss: 0.0538\n",
      "Epoch [13/50], Step [709/735], Loss: 0.0830\n",
      "Epoch [13/50], Step [710/735], Loss: 0.0932\n",
      "Epoch [13/50], Step [711/735], Loss: 0.0856\n",
      "Epoch [13/50], Step [712/735], Loss: 0.1794\n",
      "Epoch [13/50], Step [713/735], Loss: 0.1264\n",
      "Epoch [13/50], Step [714/735], Loss: 0.1166\n",
      "Epoch [13/50], Step [715/735], Loss: 0.1115\n",
      "Epoch [13/50], Step [716/735], Loss: 0.0729\n",
      "Epoch [13/50], Step [717/735], Loss: 0.0974\n",
      "Epoch [13/50], Step [718/735], Loss: 0.1885\n",
      "Epoch [13/50], Step [719/735], Loss: 0.1821\n",
      "Epoch [13/50], Step [720/735], Loss: 0.1818\n",
      "Epoch [13/50], Step [721/735], Loss: 2.0029\n",
      "Epoch [13/50], Step [722/735], Loss: 0.0619\n",
      "Epoch [13/50], Step [723/735], Loss: 0.4033\n",
      "Epoch [13/50], Step [724/735], Loss: 0.0733\n",
      "Epoch [13/50], Step [725/735], Loss: 0.0864\n",
      "Epoch [13/50], Step [726/735], Loss: 0.0665\n",
      "Epoch [13/50], Step [727/735], Loss: 0.1499\n",
      "Epoch [13/50], Step [728/735], Loss: 0.2876\n",
      "Epoch [13/50], Step [729/735], Loss: 0.3241\n",
      "Epoch [13/50], Step [730/735], Loss: 0.2858\n",
      "Epoch [13/50], Step [731/735], Loss: 0.0389\n",
      "Epoch [13/50], Step [732/735], Loss: 0.2204\n",
      "Epoch [13/50], Step [733/735], Loss: 0.0992\n",
      "Epoch [13/50], Step [734/735], Loss: 0.1902\n",
      "Epoch [13/50], Step [735/735], Loss: 0.0423\n",
      "Epoch [14/50], Step [1/735], Loss: 0.2086\n",
      "Epoch [14/50], Step [2/735], Loss: 0.0409\n",
      "Epoch [14/50], Step [3/735], Loss: 0.5207\n",
      "Epoch [14/50], Step [4/735], Loss: 0.0893\n",
      "Epoch [14/50], Step [5/735], Loss: 0.1832\n",
      "Epoch [14/50], Step [6/735], Loss: 0.2452\n",
      "Epoch [14/50], Step [7/735], Loss: 0.2243\n",
      "Epoch [14/50], Step [8/735], Loss: 0.1235\n",
      "Epoch [14/50], Step [9/735], Loss: 0.1985\n",
      "Epoch [14/50], Step [10/735], Loss: 0.1738\n",
      "Epoch [14/50], Step [11/735], Loss: 0.5082\n",
      "Epoch [14/50], Step [12/735], Loss: 1.0882\n",
      "Epoch [14/50], Step [13/735], Loss: 0.1176\n",
      "Epoch [14/50], Step [14/735], Loss: 0.1094\n",
      "Epoch [14/50], Step [15/735], Loss: 0.1407\n",
      "Epoch [14/50], Step [16/735], Loss: 0.2744\n",
      "Epoch [14/50], Step [17/735], Loss: 0.3266\n",
      "Epoch [14/50], Step [18/735], Loss: 1.0785\n",
      "Epoch [14/50], Step [19/735], Loss: 1.0514\n",
      "Epoch [14/50], Step [20/735], Loss: 0.0350\n",
      "Epoch [14/50], Step [21/735], Loss: 0.1351\n",
      "Epoch [14/50], Step [22/735], Loss: 0.6748\n",
      "Epoch [14/50], Step [23/735], Loss: 0.1340\n",
      "Epoch [14/50], Step [24/735], Loss: 0.0793\n",
      "Epoch [14/50], Step [25/735], Loss: 0.3271\n",
      "Epoch [14/50], Step [26/735], Loss: 0.2137\n",
      "Epoch [14/50], Step [27/735], Loss: 0.4906\n",
      "Epoch [14/50], Step [28/735], Loss: 0.1510\n",
      "Epoch [14/50], Step [29/735], Loss: 0.2794\n",
      "Epoch [14/50], Step [30/735], Loss: 1.8020\n",
      "Epoch [14/50], Step [31/735], Loss: 0.0627\n",
      "Epoch [14/50], Step [32/735], Loss: 0.2534\n",
      "Epoch [14/50], Step [33/735], Loss: 0.4560\n",
      "Epoch [14/50], Step [34/735], Loss: 0.1266\n",
      "Epoch [14/50], Step [35/735], Loss: 0.2222\n",
      "Epoch [14/50], Step [36/735], Loss: 0.4122\n",
      "Epoch [14/50], Step [37/735], Loss: 0.1488\n",
      "Epoch [14/50], Step [38/735], Loss: 0.3154\n",
      "Epoch [14/50], Step [39/735], Loss: 0.2589\n",
      "Epoch [14/50], Step [40/735], Loss: 0.1363\n",
      "Epoch [14/50], Step [41/735], Loss: 0.1214\n",
      "Epoch [14/50], Step [42/735], Loss: 0.0768\n",
      "Epoch [14/50], Step [43/735], Loss: 0.1395\n",
      "Epoch [14/50], Step [44/735], Loss: 0.1508\n",
      "Epoch [14/50], Step [45/735], Loss: 0.3058\n",
      "Epoch [14/50], Step [46/735], Loss: 0.1779\n",
      "Epoch [14/50], Step [47/735], Loss: 0.0598\n",
      "Epoch [14/50], Step [48/735], Loss: 0.1941\n",
      "Epoch [14/50], Step [49/735], Loss: 0.1540\n",
      "Epoch [14/50], Step [50/735], Loss: 0.1673\n",
      "Epoch [14/50], Step [51/735], Loss: 0.1638\n",
      "Epoch [14/50], Step [52/735], Loss: 0.1194\n",
      "Epoch [14/50], Step [53/735], Loss: 0.3914\n",
      "Epoch [14/50], Step [54/735], Loss: 0.1306\n",
      "Epoch [14/50], Step [55/735], Loss: 0.0920\n",
      "Epoch [14/50], Step [56/735], Loss: 0.2696\n",
      "Epoch [14/50], Step [57/735], Loss: 0.1070\n",
      "Epoch [14/50], Step [58/735], Loss: 0.5739\n",
      "Epoch [14/50], Step [59/735], Loss: 0.2646\n",
      "Epoch [14/50], Step [60/735], Loss: 0.1984\n",
      "Epoch [14/50], Step [61/735], Loss: 0.1531\n",
      "Epoch [14/50], Step [62/735], Loss: 0.1194\n",
      "Epoch [14/50], Step [63/735], Loss: 0.0703\n",
      "Epoch [14/50], Step [64/735], Loss: 0.2840\n",
      "Epoch [14/50], Step [65/735], Loss: 1.7745\n",
      "Epoch [14/50], Step [66/735], Loss: 0.1937\n",
      "Epoch [14/50], Step [67/735], Loss: 0.0896\n",
      "Epoch [14/50], Step [68/735], Loss: 0.1343\n",
      "Epoch [14/50], Step [69/735], Loss: 0.3660\n",
      "Epoch [14/50], Step [70/735], Loss: 1.4459\n",
      "Epoch [14/50], Step [71/735], Loss: 0.1593\n",
      "Epoch [14/50], Step [72/735], Loss: 0.1694\n",
      "Epoch [14/50], Step [73/735], Loss: 0.1943\n",
      "Epoch [14/50], Step [74/735], Loss: 0.1384\n",
      "Epoch [14/50], Step [75/735], Loss: 0.0815\n",
      "Epoch [14/50], Step [76/735], Loss: 0.0927\n",
      "Epoch [14/50], Step [77/735], Loss: 1.0401\n",
      "Epoch [14/50], Step [78/735], Loss: 0.4846\n",
      "Epoch [14/50], Step [79/735], Loss: 0.0616\n",
      "Epoch [14/50], Step [80/735], Loss: 0.3785\n",
      "Epoch [14/50], Step [81/735], Loss: 0.0634\n",
      "Epoch [14/50], Step [82/735], Loss: 0.1174\n",
      "Epoch [14/50], Step [83/735], Loss: 1.5745\n",
      "Epoch [14/50], Step [84/735], Loss: 0.3115\n",
      "Epoch [14/50], Step [85/735], Loss: 0.1530\n",
      "Epoch [14/50], Step [86/735], Loss: 0.0772\n",
      "Epoch [14/50], Step [87/735], Loss: 0.2404\n",
      "Epoch [14/50], Step [88/735], Loss: 0.1017\n",
      "Epoch [14/50], Step [89/735], Loss: 0.2173\n",
      "Epoch [14/50], Step [90/735], Loss: 0.2144\n",
      "Epoch [14/50], Step [91/735], Loss: 0.1074\n",
      "Epoch [14/50], Step [92/735], Loss: 0.1681\n",
      "Epoch [14/50], Step [93/735], Loss: 0.8572\n",
      "Epoch [14/50], Step [94/735], Loss: 0.2157\n",
      "Epoch [14/50], Step [95/735], Loss: 0.0862\n",
      "Epoch [14/50], Step [96/735], Loss: 0.1315\n",
      "Epoch [14/50], Step [97/735], Loss: 0.3090\n",
      "Epoch [14/50], Step [98/735], Loss: 0.0865\n",
      "Epoch [14/50], Step [99/735], Loss: 0.2083\n",
      "Epoch [14/50], Step [100/735], Loss: 0.1873\n",
      "Epoch [14/50], Step [101/735], Loss: 0.0923\n",
      "Epoch [14/50], Step [102/735], Loss: 0.1989\n",
      "Epoch [14/50], Step [103/735], Loss: 0.4836\n",
      "Epoch [14/50], Step [104/735], Loss: 1.0517\n",
      "Epoch [14/50], Step [105/735], Loss: 0.0726\n",
      "Epoch [14/50], Step [106/735], Loss: 0.2708\n",
      "Epoch [14/50], Step [107/735], Loss: 0.1773\n",
      "Epoch [14/50], Step [108/735], Loss: 0.1648\n",
      "Epoch [14/50], Step [109/735], Loss: 0.1920\n",
      "Epoch [14/50], Step [110/735], Loss: 0.4997\n",
      "Epoch [14/50], Step [111/735], Loss: 0.3182\n",
      "Epoch [14/50], Step [112/735], Loss: 0.1087\n",
      "Epoch [14/50], Step [113/735], Loss: 0.1883\n",
      "Epoch [14/50], Step [114/735], Loss: 0.0771\n",
      "Epoch [14/50], Step [115/735], Loss: 0.1094\n",
      "Epoch [14/50], Step [116/735], Loss: 0.0589\n",
      "Epoch [14/50], Step [117/735], Loss: 0.3372\n",
      "Epoch [14/50], Step [118/735], Loss: 0.3907\n",
      "Epoch [14/50], Step [119/735], Loss: 0.2319\n",
      "Epoch [14/50], Step [120/735], Loss: 0.2092\n",
      "Epoch [14/50], Step [121/735], Loss: 0.4738\n",
      "Epoch [14/50], Step [122/735], Loss: 0.1061\n",
      "Epoch [14/50], Step [123/735], Loss: 0.2423\n",
      "Epoch [14/50], Step [124/735], Loss: 0.1270\n",
      "Epoch [14/50], Step [125/735], Loss: 0.0555\n",
      "Epoch [14/50], Step [126/735], Loss: 0.0678\n",
      "Epoch [14/50], Step [127/735], Loss: 0.1497\n",
      "Epoch [14/50], Step [128/735], Loss: 0.0637\n",
      "Epoch [14/50], Step [129/735], Loss: 0.0777\n",
      "Epoch [14/50], Step [130/735], Loss: 0.1183\n",
      "Epoch [14/50], Step [131/735], Loss: 0.1154\n",
      "Epoch [14/50], Step [132/735], Loss: 0.0618\n",
      "Epoch [14/50], Step [133/735], Loss: 0.2896\n",
      "Epoch [14/50], Step [134/735], Loss: 0.1754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Step [135/735], Loss: 0.2261\n",
      "Epoch [14/50], Step [136/735], Loss: 1.1080\n",
      "Epoch [14/50], Step [137/735], Loss: 0.1556\n",
      "Epoch [14/50], Step [138/735], Loss: 0.0787\n",
      "Epoch [14/50], Step [139/735], Loss: 0.3228\n",
      "Epoch [14/50], Step [140/735], Loss: 0.1623\n",
      "Epoch [14/50], Step [141/735], Loss: 0.1294\n",
      "Epoch [14/50], Step [142/735], Loss: 0.1532\n",
      "Epoch [14/50], Step [143/735], Loss: 0.0921\n",
      "Epoch [14/50], Step [144/735], Loss: 0.1579\n",
      "Epoch [14/50], Step [145/735], Loss: 0.0999\n",
      "Epoch [14/50], Step [146/735], Loss: 0.0954\n",
      "Epoch [14/50], Step [147/735], Loss: 0.1445\n",
      "Epoch [14/50], Step [148/735], Loss: 0.0928\n",
      "Epoch [14/50], Step [149/735], Loss: 0.1140\n",
      "Epoch [14/50], Step [150/735], Loss: 0.1068\n",
      "Epoch [14/50], Step [151/735], Loss: 0.2310\n",
      "Epoch [14/50], Step [152/735], Loss: 0.1186\n",
      "Epoch [14/50], Step [153/735], Loss: 0.8104\n",
      "Epoch [14/50], Step [154/735], Loss: 0.1736\n",
      "Epoch [14/50], Step [155/735], Loss: 0.0810\n",
      "Epoch [14/50], Step [156/735], Loss: 0.4220\n",
      "Epoch [14/50], Step [157/735], Loss: 0.2520\n",
      "Epoch [14/50], Step [158/735], Loss: 0.2148\n",
      "Epoch [14/50], Step [159/735], Loss: 0.1073\n",
      "Epoch [14/50], Step [160/735], Loss: 0.2631\n",
      "Epoch [14/50], Step [161/735], Loss: 0.1574\n",
      "Epoch [14/50], Step [162/735], Loss: 0.1056\n",
      "Epoch [14/50], Step [163/735], Loss: 0.0735\n",
      "Epoch [14/50], Step [164/735], Loss: 0.1640\n",
      "Epoch [14/50], Step [165/735], Loss: 0.5670\n",
      "Epoch [14/50], Step [166/735], Loss: 0.1545\n",
      "Epoch [14/50], Step [167/735], Loss: 0.2612\n",
      "Epoch [14/50], Step [168/735], Loss: 0.2576\n",
      "Epoch [14/50], Step [169/735], Loss: 0.0766\n",
      "Epoch [14/50], Step [170/735], Loss: 0.0595\n",
      "Epoch [14/50], Step [171/735], Loss: 0.0870\n",
      "Epoch [14/50], Step [172/735], Loss: 0.1819\n",
      "Epoch [14/50], Step [173/735], Loss: 0.6441\n",
      "Epoch [14/50], Step [174/735], Loss: 0.1711\n",
      "Epoch [14/50], Step [175/735], Loss: 0.0978\n",
      "Epoch [14/50], Step [176/735], Loss: 0.2609\n",
      "Epoch [14/50], Step [177/735], Loss: 0.1523\n",
      "Epoch [14/50], Step [178/735], Loss: 0.1668\n",
      "Epoch [14/50], Step [179/735], Loss: 0.3421\n",
      "Epoch [14/50], Step [180/735], Loss: 0.5086\n",
      "Epoch [14/50], Step [181/735], Loss: 0.1121\n",
      "Epoch [14/50], Step [182/735], Loss: 0.1017\n",
      "Epoch [14/50], Step [183/735], Loss: 0.0926\n",
      "Epoch [14/50], Step [184/735], Loss: 0.2810\n",
      "Epoch [14/50], Step [185/735], Loss: 0.1114\n",
      "Epoch [14/50], Step [186/735], Loss: 0.1658\n",
      "Epoch [14/50], Step [187/735], Loss: 0.0756\n",
      "Epoch [14/50], Step [188/735], Loss: 0.2464\n",
      "Epoch [14/50], Step [189/735], Loss: 0.4184\n",
      "Epoch [14/50], Step [190/735], Loss: 0.1235\n",
      "Epoch [14/50], Step [191/735], Loss: 0.1096\n",
      "Epoch [14/50], Step [192/735], Loss: 0.0542\n",
      "Epoch [14/50], Step [193/735], Loss: 0.2698\n",
      "Epoch [14/50], Step [194/735], Loss: 0.0822\n",
      "Epoch [14/50], Step [195/735], Loss: 0.0999\n",
      "Epoch [14/50], Step [196/735], Loss: 0.0627\n",
      "Epoch [14/50], Step [197/735], Loss: 0.2581\n",
      "Epoch [14/50], Step [198/735], Loss: 0.1540\n",
      "Epoch [14/50], Step [199/735], Loss: 0.1060\n",
      "Epoch [14/50], Step [200/735], Loss: 0.2092\n",
      "Epoch [14/50], Step [201/735], Loss: 0.1427\n",
      "Epoch [14/50], Step [202/735], Loss: 0.0311\n",
      "Epoch [14/50], Step [203/735], Loss: 0.7902\n",
      "Epoch [14/50], Step [204/735], Loss: 0.0878\n",
      "Epoch [14/50], Step [205/735], Loss: 0.0806\n",
      "Epoch [14/50], Step [206/735], Loss: 0.1550\n",
      "Epoch [14/50], Step [207/735], Loss: 0.0484\n",
      "Epoch [14/50], Step [208/735], Loss: 0.0874\n",
      "Epoch [14/50], Step [209/735], Loss: 0.0368\n",
      "Epoch [14/50], Step [210/735], Loss: 0.0700\n",
      "Epoch [14/50], Step [211/735], Loss: 0.0949\n",
      "Epoch [14/50], Step [212/735], Loss: 0.0907\n",
      "Epoch [14/50], Step [213/735], Loss: 0.0493\n",
      "Epoch [14/50], Step [214/735], Loss: 0.0816\n",
      "Epoch [14/50], Step [215/735], Loss: 0.0312\n",
      "Epoch [14/50], Step [216/735], Loss: 0.0476\n",
      "Epoch [14/50], Step [217/735], Loss: 0.0526\n",
      "Epoch [14/50], Step [218/735], Loss: 0.1163\n",
      "Epoch [14/50], Step [219/735], Loss: 0.1094\n",
      "Epoch [14/50], Step [220/735], Loss: 0.0640\n",
      "Epoch [14/50], Step [221/735], Loss: 0.0653\n",
      "Epoch [14/50], Step [222/735], Loss: 0.3624\n",
      "Epoch [14/50], Step [223/735], Loss: 0.1446\n",
      "Epoch [14/50], Step [224/735], Loss: 0.1057\n",
      "Epoch [14/50], Step [225/735], Loss: 0.1697\n",
      "Epoch [14/50], Step [226/735], Loss: 1.1258\n",
      "Epoch [14/50], Step [227/735], Loss: 0.2135\n",
      "Epoch [14/50], Step [228/735], Loss: 0.0902\n",
      "Epoch [14/50], Step [229/735], Loss: 0.0899\n",
      "Epoch [14/50], Step [230/735], Loss: 0.3474\n",
      "Epoch [14/50], Step [231/735], Loss: 0.0487\n",
      "Epoch [14/50], Step [232/735], Loss: 0.1350\n",
      "Epoch [14/50], Step [233/735], Loss: 0.0423\n",
      "Epoch [14/50], Step [234/735], Loss: 0.1426\n",
      "Epoch [14/50], Step [235/735], Loss: 0.5926\n",
      "Epoch [14/50], Step [236/735], Loss: 0.0534\n",
      "Epoch [14/50], Step [237/735], Loss: 0.0792\n",
      "Epoch [14/50], Step [238/735], Loss: 0.1048\n",
      "Epoch [14/50], Step [239/735], Loss: 0.0530\n",
      "Epoch [14/50], Step [240/735], Loss: 0.1681\n",
      "Epoch [14/50], Step [241/735], Loss: 0.2969\n",
      "Epoch [14/50], Step [242/735], Loss: 0.1795\n",
      "Epoch [14/50], Step [243/735], Loss: 0.0799\n",
      "Epoch [14/50], Step [244/735], Loss: 0.1088\n",
      "Epoch [14/50], Step [245/735], Loss: 0.1481\n",
      "Epoch [14/50], Step [246/735], Loss: 0.2371\n",
      "Epoch [14/50], Step [247/735], Loss: 0.1306\n",
      "Epoch [14/50], Step [248/735], Loss: 0.2207\n",
      "Epoch [14/50], Step [249/735], Loss: 0.1264\n",
      "Epoch [14/50], Step [250/735], Loss: 0.1286\n",
      "Epoch [14/50], Step [251/735], Loss: 0.2244\n",
      "Epoch [14/50], Step [252/735], Loss: 0.3620\n",
      "Epoch [14/50], Step [253/735], Loss: 0.1349\n",
      "Epoch [14/50], Step [254/735], Loss: 0.0774\n",
      "Epoch [14/50], Step [255/735], Loss: 0.0642\n",
      "Epoch [14/50], Step [256/735], Loss: 0.4965\n",
      "Epoch [14/50], Step [257/735], Loss: 0.1498\n",
      "Epoch [14/50], Step [258/735], Loss: 0.5538\n",
      "Epoch [14/50], Step [259/735], Loss: 0.2415\n",
      "Epoch [14/50], Step [260/735], Loss: 0.1882\n",
      "Epoch [14/50], Step [261/735], Loss: 0.2780\n",
      "Epoch [14/50], Step [262/735], Loss: 0.0647\n",
      "Epoch [14/50], Step [263/735], Loss: 0.2173\n",
      "Epoch [14/50], Step [264/735], Loss: 0.1365\n",
      "Epoch [14/50], Step [265/735], Loss: 0.1209\n",
      "Epoch [14/50], Step [266/735], Loss: 0.3628\n",
      "Epoch [14/50], Step [267/735], Loss: 0.1512\n",
      "Epoch [14/50], Step [268/735], Loss: 0.0648\n",
      "Epoch [14/50], Step [269/735], Loss: 0.1080\n",
      "Epoch [14/50], Step [270/735], Loss: 0.1935\n",
      "Epoch [14/50], Step [271/735], Loss: 0.1141\n",
      "Epoch [14/50], Step [272/735], Loss: 0.9226\n",
      "Epoch [14/50], Step [273/735], Loss: 0.5384\n",
      "Epoch [14/50], Step [274/735], Loss: 0.1096\n",
      "Epoch [14/50], Step [275/735], Loss: 0.4155\n",
      "Epoch [14/50], Step [276/735], Loss: 0.1021\n",
      "Epoch [14/50], Step [277/735], Loss: 0.1898\n",
      "Epoch [14/50], Step [278/735], Loss: 0.2562\n",
      "Epoch [14/50], Step [279/735], Loss: 0.4917\n",
      "Epoch [14/50], Step [280/735], Loss: 2.1849\n",
      "Epoch [14/50], Step [281/735], Loss: 0.2130\n",
      "Epoch [14/50], Step [282/735], Loss: 0.1578\n",
      "Epoch [14/50], Step [283/735], Loss: 0.0430\n",
      "Epoch [14/50], Step [284/735], Loss: 0.1551\n",
      "Epoch [14/50], Step [285/735], Loss: 0.0844\n",
      "Epoch [14/50], Step [286/735], Loss: 0.1679\n",
      "Epoch [14/50], Step [287/735], Loss: 0.1374\n",
      "Epoch [14/50], Step [288/735], Loss: 0.1531\n",
      "Epoch [14/50], Step [289/735], Loss: 0.0838\n",
      "Epoch [14/50], Step [290/735], Loss: 0.3033\n",
      "Epoch [14/50], Step [291/735], Loss: 0.1394\n",
      "Epoch [14/50], Step [292/735], Loss: 0.1688\n",
      "Epoch [14/50], Step [293/735], Loss: 0.0666\n",
      "Epoch [14/50], Step [294/735], Loss: 0.3022\n",
      "Epoch [14/50], Step [295/735], Loss: 0.2714\n",
      "Epoch [14/50], Step [296/735], Loss: 0.3836\n",
      "Epoch [14/50], Step [297/735], Loss: 0.1730\n",
      "Epoch [14/50], Step [298/735], Loss: 0.1663\n",
      "Epoch [14/50], Step [299/735], Loss: 0.2279\n",
      "Epoch [14/50], Step [300/735], Loss: 0.0922\n",
      "Epoch [14/50], Step [301/735], Loss: 0.1237\n",
      "Epoch [14/50], Step [302/735], Loss: 0.1087\n",
      "Epoch [14/50], Step [303/735], Loss: 0.0681\n",
      "Epoch [14/50], Step [304/735], Loss: 0.0563\n",
      "Epoch [14/50], Step [305/735], Loss: 0.2893\n",
      "Epoch [14/50], Step [306/735], Loss: 0.0926\n",
      "Epoch [14/50], Step [307/735], Loss: 0.5826\n",
      "Epoch [14/50], Step [308/735], Loss: 0.1027\n",
      "Epoch [14/50], Step [309/735], Loss: 0.2218\n",
      "Epoch [14/50], Step [310/735], Loss: 0.1115\n",
      "Epoch [14/50], Step [311/735], Loss: 0.1110\n",
      "Epoch [14/50], Step [312/735], Loss: 0.2332\n",
      "Epoch [14/50], Step [313/735], Loss: 0.1831\n",
      "Epoch [14/50], Step [314/735], Loss: 0.0708\n",
      "Epoch [14/50], Step [315/735], Loss: 0.2087\n",
      "Epoch [14/50], Step [316/735], Loss: 0.2030\n",
      "Epoch [14/50], Step [317/735], Loss: 0.1487\n",
      "Epoch [14/50], Step [318/735], Loss: 0.1813\n",
      "Epoch [14/50], Step [319/735], Loss: 0.2371\n",
      "Epoch [14/50], Step [320/735], Loss: 1.8239\n",
      "Epoch [14/50], Step [321/735], Loss: 0.1408\n",
      "Epoch [14/50], Step [322/735], Loss: 0.1749\n",
      "Epoch [14/50], Step [323/735], Loss: 0.2026\n",
      "Epoch [14/50], Step [324/735], Loss: 0.3122\n",
      "Epoch [14/50], Step [325/735], Loss: 0.0756\n",
      "Epoch [14/50], Step [326/735], Loss: 0.0981\n",
      "Epoch [14/50], Step [327/735], Loss: 0.0395\n",
      "Epoch [14/50], Step [328/735], Loss: 0.2238\n",
      "Epoch [14/50], Step [329/735], Loss: 0.0770\n",
      "Epoch [14/50], Step [330/735], Loss: 0.1480\n",
      "Epoch [14/50], Step [331/735], Loss: 0.0569\n",
      "Epoch [14/50], Step [332/735], Loss: 0.0889\n",
      "Epoch [14/50], Step [333/735], Loss: 0.1239\n",
      "Epoch [14/50], Step [334/735], Loss: 0.2064\n",
      "Epoch [14/50], Step [335/735], Loss: 0.1050\n",
      "Epoch [14/50], Step [336/735], Loss: 0.6280\n",
      "Epoch [14/50], Step [337/735], Loss: 0.1653\n",
      "Epoch [14/50], Step [338/735], Loss: 0.0748\n",
      "Epoch [14/50], Step [339/735], Loss: 0.3003\n",
      "Epoch [14/50], Step [340/735], Loss: 0.3369\n",
      "Epoch [14/50], Step [341/735], Loss: 2.1106\n",
      "Epoch [14/50], Step [342/735], Loss: 0.9147\n",
      "Epoch [14/50], Step [343/735], Loss: 0.0962\n",
      "Epoch [14/50], Step [344/735], Loss: 0.0992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Step [345/735], Loss: 0.3083\n",
      "Epoch [14/50], Step [346/735], Loss: 1.0097\n",
      "Epoch [14/50], Step [347/735], Loss: 0.0682\n",
      "Epoch [14/50], Step [348/735], Loss: 0.0811\n",
      "Epoch [14/50], Step [349/735], Loss: 0.1199\n",
      "Epoch [14/50], Step [350/735], Loss: 0.1850\n",
      "Epoch [14/50], Step [351/735], Loss: 0.3082\n",
      "Epoch [14/50], Step [352/735], Loss: 0.4036\n",
      "Epoch [14/50], Step [353/735], Loss: 0.2403\n",
      "Epoch [14/50], Step [354/735], Loss: 0.0484\n",
      "Epoch [14/50], Step [355/735], Loss: 0.1429\n",
      "Epoch [14/50], Step [356/735], Loss: 0.6132\n",
      "Epoch [14/50], Step [357/735], Loss: 0.1330\n",
      "Epoch [14/50], Step [358/735], Loss: 0.0661\n",
      "Epoch [14/50], Step [359/735], Loss: 0.0498\n",
      "Epoch [14/50], Step [360/735], Loss: 0.1049\n",
      "Epoch [14/50], Step [361/735], Loss: 0.9026\n",
      "Epoch [14/50], Step [362/735], Loss: 0.2151\n",
      "Epoch [14/50], Step [363/735], Loss: 0.0481\n",
      "Epoch [14/50], Step [364/735], Loss: 0.3210\n",
      "Epoch [14/50], Step [365/735], Loss: 0.2236\n",
      "Epoch [14/50], Step [366/735], Loss: 0.3280\n",
      "Epoch [14/50], Step [367/735], Loss: 0.0590\n",
      "Epoch [14/50], Step [368/735], Loss: 0.2702\n",
      "Epoch [14/50], Step [369/735], Loss: 0.3537\n",
      "Epoch [14/50], Step [370/735], Loss: 0.1967\n",
      "Epoch [14/50], Step [371/735], Loss: 0.3143\n",
      "Epoch [14/50], Step [372/735], Loss: 0.1139\n",
      "Epoch [14/50], Step [373/735], Loss: 0.2874\n",
      "Epoch [14/50], Step [374/735], Loss: 0.2687\n",
      "Epoch [14/50], Step [375/735], Loss: 0.0925\n",
      "Epoch [14/50], Step [376/735], Loss: 0.1481\n",
      "Epoch [14/50], Step [377/735], Loss: 0.6923\n",
      "Epoch [14/50], Step [378/735], Loss: 1.1004\n",
      "Epoch [14/50], Step [379/735], Loss: 0.0821\n",
      "Epoch [14/50], Step [380/735], Loss: 0.0757\n",
      "Epoch [14/50], Step [381/735], Loss: 0.0917\n",
      "Epoch [14/50], Step [382/735], Loss: 0.1351\n",
      "Epoch [14/50], Step [383/735], Loss: 0.2245\n",
      "Epoch [14/50], Step [384/735], Loss: 0.1379\n",
      "Epoch [14/50], Step [385/735], Loss: 0.0606\n",
      "Epoch [14/50], Step [386/735], Loss: 0.2573\n",
      "Epoch [14/50], Step [387/735], Loss: 0.1707\n",
      "Epoch [14/50], Step [388/735], Loss: 0.2850\n",
      "Epoch [14/50], Step [389/735], Loss: 0.2122\n",
      "Epoch [14/50], Step [390/735], Loss: 0.5545\n",
      "Epoch [14/50], Step [391/735], Loss: 0.5342\n",
      "Epoch [14/50], Step [392/735], Loss: 0.1527\n",
      "Epoch [14/50], Step [393/735], Loss: 0.2139\n",
      "Epoch [14/50], Step [394/735], Loss: 0.0982\n",
      "Epoch [14/50], Step [395/735], Loss: 0.1012\n",
      "Epoch [14/50], Step [396/735], Loss: 0.2480\n",
      "Epoch [14/50], Step [397/735], Loss: 0.0897\n",
      "Epoch [14/50], Step [398/735], Loss: 0.1993\n",
      "Epoch [14/50], Step [399/735], Loss: 0.1697\n",
      "Epoch [14/50], Step [400/735], Loss: 0.1361\n",
      "Epoch [14/50], Step [401/735], Loss: 0.1901\n",
      "Epoch [14/50], Step [402/735], Loss: 0.4169\n",
      "Epoch [14/50], Step [403/735], Loss: 0.1604\n",
      "Epoch [14/50], Step [404/735], Loss: 0.6322\n",
      "Epoch [14/50], Step [405/735], Loss: 0.9671\n",
      "Epoch [14/50], Step [406/735], Loss: 0.1386\n",
      "Epoch [14/50], Step [407/735], Loss: 0.1058\n",
      "Epoch [14/50], Step [408/735], Loss: 0.0897\n",
      "Epoch [14/50], Step [409/735], Loss: 0.1998\n",
      "Epoch [14/50], Step [410/735], Loss: 1.0357\n",
      "Epoch [14/50], Step [411/735], Loss: 0.1210\n",
      "Epoch [14/50], Step [412/735], Loss: 0.1387\n",
      "Epoch [14/50], Step [413/735], Loss: 0.3002\n",
      "Epoch [14/50], Step [414/735], Loss: 0.1514\n",
      "Epoch [14/50], Step [415/735], Loss: 0.0987\n",
      "Epoch [14/50], Step [416/735], Loss: 0.1672\n",
      "Epoch [14/50], Step [417/735], Loss: 0.3721\n",
      "Epoch [14/50], Step [418/735], Loss: 0.1379\n",
      "Epoch [14/50], Step [419/735], Loss: 0.0674\n",
      "Epoch [14/50], Step [420/735], Loss: 0.0674\n",
      "Epoch [14/50], Step [421/735], Loss: 0.2872\n",
      "Epoch [14/50], Step [422/735], Loss: 0.1017\n",
      "Epoch [14/50], Step [423/735], Loss: 0.2262\n",
      "Epoch [14/50], Step [424/735], Loss: 0.0885\n",
      "Epoch [14/50], Step [425/735], Loss: 0.3373\n",
      "Epoch [14/50], Step [426/735], Loss: 0.0300\n",
      "Epoch [14/50], Step [427/735], Loss: 0.0777\n",
      "Epoch [14/50], Step [428/735], Loss: 0.2714\n",
      "Epoch [14/50], Step [429/735], Loss: 0.1940\n",
      "Epoch [14/50], Step [430/735], Loss: 0.0962\n",
      "Epoch [14/50], Step [431/735], Loss: 0.1156\n",
      "Epoch [14/50], Step [432/735], Loss: 0.4060\n",
      "Epoch [14/50], Step [433/735], Loss: 0.0964\n",
      "Epoch [14/50], Step [434/735], Loss: 0.1470\n",
      "Epoch [14/50], Step [435/735], Loss: 0.6035\n",
      "Epoch [14/50], Step [436/735], Loss: 0.0851\n",
      "Epoch [14/50], Step [437/735], Loss: 0.1797\n",
      "Epoch [14/50], Step [438/735], Loss: 0.2489\n",
      "Epoch [14/50], Step [439/735], Loss: 0.0925\n",
      "Epoch [14/50], Step [440/735], Loss: 0.1172\n",
      "Epoch [14/50], Step [441/735], Loss: 0.2783\n",
      "Epoch [14/50], Step [442/735], Loss: 0.6121\n",
      "Epoch [14/50], Step [443/735], Loss: 0.3280\n",
      "Epoch [14/50], Step [444/735], Loss: 0.1601\n",
      "Epoch [14/50], Step [445/735], Loss: 0.1598\n",
      "Epoch [14/50], Step [446/735], Loss: 0.2453\n",
      "Epoch [14/50], Step [447/735], Loss: 0.0858\n",
      "Epoch [14/50], Step [448/735], Loss: 0.1371\n",
      "Epoch [14/50], Step [449/735], Loss: 0.2445\n",
      "Epoch [14/50], Step [450/735], Loss: 0.1843\n",
      "Epoch [14/50], Step [451/735], Loss: 0.0881\n",
      "Epoch [14/50], Step [452/735], Loss: 0.1119\n",
      "Epoch [14/50], Step [453/735], Loss: 0.3870\n",
      "Epoch [14/50], Step [454/735], Loss: 0.5120\n",
      "Epoch [14/50], Step [455/735], Loss: 0.2282\n",
      "Epoch [14/50], Step [456/735], Loss: 0.1078\n",
      "Epoch [14/50], Step [457/735], Loss: 0.1186\n",
      "Epoch [14/50], Step [458/735], Loss: 0.1637\n",
      "Epoch [14/50], Step [459/735], Loss: 0.1143\n",
      "Epoch [14/50], Step [460/735], Loss: 0.1422\n",
      "Epoch [14/50], Step [461/735], Loss: 0.1622\n",
      "Epoch [14/50], Step [462/735], Loss: 0.1432\n",
      "Epoch [14/50], Step [463/735], Loss: 0.1402\n",
      "Epoch [14/50], Step [464/735], Loss: 0.1057\n",
      "Epoch [14/50], Step [465/735], Loss: 0.1103\n",
      "Epoch [14/50], Step [466/735], Loss: 0.1263\n",
      "Epoch [14/50], Step [467/735], Loss: 0.4082\n",
      "Epoch [14/50], Step [468/735], Loss: 0.2803\n",
      "Epoch [14/50], Step [469/735], Loss: 0.2421\n",
      "Epoch [14/50], Step [470/735], Loss: 0.1140\n",
      "Epoch [14/50], Step [471/735], Loss: 0.0614\n",
      "Epoch [14/50], Step [472/735], Loss: 0.1093\n",
      "Epoch [14/50], Step [473/735], Loss: 0.1511\n",
      "Epoch [14/50], Step [474/735], Loss: 0.2366\n",
      "Epoch [14/50], Step [475/735], Loss: 0.1468\n",
      "Epoch [14/50], Step [476/735], Loss: 0.1806\n",
      "Epoch [14/50], Step [477/735], Loss: 0.1260\n",
      "Epoch [14/50], Step [478/735], Loss: 0.0561\n",
      "Epoch [14/50], Step [479/735], Loss: 0.2622\n",
      "Epoch [14/50], Step [480/735], Loss: 0.0893\n",
      "Epoch [14/50], Step [481/735], Loss: 0.1680\n",
      "Epoch [14/50], Step [482/735], Loss: 0.0487\n",
      "Epoch [14/50], Step [483/735], Loss: 0.0803\n",
      "Epoch [14/50], Step [484/735], Loss: 0.0721\n",
      "Epoch [14/50], Step [485/735], Loss: 0.5360\n",
      "Epoch [14/50], Step [486/735], Loss: 0.3100\n",
      "Epoch [14/50], Step [487/735], Loss: 0.0974\n",
      "Epoch [14/50], Step [488/735], Loss: 0.1309\n",
      "Epoch [14/50], Step [489/735], Loss: 0.1795\n",
      "Epoch [14/50], Step [490/735], Loss: 1.0460\n",
      "Epoch [14/50], Step [491/735], Loss: 0.1798\n",
      "Epoch [14/50], Step [492/735], Loss: 0.0791\n",
      "Epoch [14/50], Step [493/735], Loss: 0.3720\n",
      "Epoch [14/50], Step [494/735], Loss: 0.1471\n",
      "Epoch [14/50], Step [495/735], Loss: 0.0401\n",
      "Epoch [14/50], Step [496/735], Loss: 0.0528\n",
      "Epoch [14/50], Step [497/735], Loss: 0.1578\n",
      "Epoch [14/50], Step [498/735], Loss: 0.0986\n",
      "Epoch [14/50], Step [499/735], Loss: 0.6512\n",
      "Epoch [14/50], Step [500/735], Loss: 0.0896\n",
      "Epoch [14/50], Step [501/735], Loss: 0.2556\n",
      "Epoch [14/50], Step [502/735], Loss: 0.1022\n",
      "Epoch [14/50], Step [503/735], Loss: 0.3083\n",
      "Epoch [14/50], Step [504/735], Loss: 0.3485\n",
      "Epoch [14/50], Step [505/735], Loss: 0.0950\n",
      "Epoch [14/50], Step [506/735], Loss: 0.0712\n",
      "Epoch [14/50], Step [507/735], Loss: 0.1512\n",
      "Epoch [14/50], Step [508/735], Loss: 0.0936\n",
      "Epoch [14/50], Step [509/735], Loss: 0.2015\n",
      "Epoch [14/50], Step [510/735], Loss: 0.3120\n",
      "Epoch [14/50], Step [511/735], Loss: 0.1021\n",
      "Epoch [14/50], Step [512/735], Loss: 0.2031\n",
      "Epoch [14/50], Step [513/735], Loss: 0.1779\n",
      "Epoch [14/50], Step [514/735], Loss: 0.2855\n",
      "Epoch [14/50], Step [515/735], Loss: 0.1057\n",
      "Epoch [14/50], Step [516/735], Loss: 0.0579\n",
      "Epoch [14/50], Step [517/735], Loss: 0.2185\n",
      "Epoch [14/50], Step [518/735], Loss: 0.4506\n",
      "Epoch [14/50], Step [519/735], Loss: 0.0934\n",
      "Epoch [14/50], Step [520/735], Loss: 0.3211\n",
      "Epoch [14/50], Step [521/735], Loss: 0.3570\n",
      "Epoch [14/50], Step [522/735], Loss: 0.0569\n",
      "Epoch [14/50], Step [523/735], Loss: 0.0540\n",
      "Epoch [14/50], Step [524/735], Loss: 0.0733\n",
      "Epoch [14/50], Step [525/735], Loss: 0.1703\n",
      "Epoch [14/50], Step [526/735], Loss: 0.0975\n",
      "Epoch [14/50], Step [527/735], Loss: 0.5720\n",
      "Epoch [14/50], Step [528/735], Loss: 0.1743\n",
      "Epoch [14/50], Step [529/735], Loss: 0.2641\n",
      "Epoch [14/50], Step [530/735], Loss: 0.1869\n",
      "Epoch [14/50], Step [531/735], Loss: 0.5215\n",
      "Epoch [14/50], Step [532/735], Loss: 0.0899\n",
      "Epoch [14/50], Step [533/735], Loss: 0.1043\n",
      "Epoch [14/50], Step [534/735], Loss: 0.1837\n",
      "Epoch [14/50], Step [535/735], Loss: 0.1514\n",
      "Epoch [14/50], Step [536/735], Loss: 0.2898\n",
      "Epoch [14/50], Step [537/735], Loss: 0.1996\n",
      "Epoch [14/50], Step [538/735], Loss: 0.0647\n",
      "Epoch [14/50], Step [539/735], Loss: 0.1625\n",
      "Epoch [14/50], Step [540/735], Loss: 0.0719\n",
      "Epoch [14/50], Step [541/735], Loss: 0.0831\n",
      "Epoch [14/50], Step [542/735], Loss: 0.0811\n",
      "Epoch [14/50], Step [543/735], Loss: 0.1124\n",
      "Epoch [14/50], Step [544/735], Loss: 0.1400\n",
      "Epoch [14/50], Step [545/735], Loss: 0.3517\n",
      "Epoch [14/50], Step [546/735], Loss: 0.3218\n",
      "Epoch [14/50], Step [547/735], Loss: 0.0717\n",
      "Epoch [14/50], Step [548/735], Loss: 0.2004\n",
      "Epoch [14/50], Step [549/735], Loss: 0.1743\n",
      "Epoch [14/50], Step [550/735], Loss: 0.1122\n",
      "Epoch [14/50], Step [551/735], Loss: 0.1547\n",
      "Epoch [14/50], Step [552/735], Loss: 0.5906\n",
      "Epoch [14/50], Step [553/735], Loss: 0.1214\n",
      "Epoch [14/50], Step [554/735], Loss: 0.0845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Step [555/735], Loss: 0.1791\n",
      "Epoch [14/50], Step [556/735], Loss: 0.1248\n",
      "Epoch [14/50], Step [557/735], Loss: 0.1036\n",
      "Epoch [14/50], Step [558/735], Loss: 0.0806\n",
      "Epoch [14/50], Step [559/735], Loss: 0.1238\n",
      "Epoch [14/50], Step [560/735], Loss: 1.7592\n",
      "Epoch [14/50], Step [561/735], Loss: 0.2066\n",
      "Epoch [14/50], Step [562/735], Loss: 1.5749\n",
      "Epoch [14/50], Step [563/735], Loss: 0.0512\n",
      "Epoch [14/50], Step [564/735], Loss: 0.2614\n",
      "Epoch [14/50], Step [565/735], Loss: 0.1692\n",
      "Epoch [14/50], Step [566/735], Loss: 0.3187\n",
      "Epoch [14/50], Step [567/735], Loss: 0.2516\n",
      "Epoch [14/50], Step [568/735], Loss: 0.2187\n",
      "Epoch [14/50], Step [569/735], Loss: 0.1584\n",
      "Epoch [14/50], Step [570/735], Loss: 0.1123\n",
      "Epoch [14/50], Step [571/735], Loss: 0.0613\n",
      "Epoch [14/50], Step [572/735], Loss: 0.8304\n",
      "Epoch [14/50], Step [573/735], Loss: 0.0631\n",
      "Epoch [14/50], Step [574/735], Loss: 0.1228\n",
      "Epoch [14/50], Step [575/735], Loss: 0.0795\n",
      "Epoch [14/50], Step [576/735], Loss: 0.1428\n",
      "Epoch [14/50], Step [577/735], Loss: 0.1090\n",
      "Epoch [14/50], Step [578/735], Loss: 0.1368\n",
      "Epoch [14/50], Step [579/735], Loss: 0.2524\n",
      "Epoch [14/50], Step [580/735], Loss: 0.1361\n",
      "Epoch [14/50], Step [581/735], Loss: 0.2251\n",
      "Epoch [14/50], Step [582/735], Loss: 0.0975\n",
      "Epoch [14/50], Step [583/735], Loss: 0.1546\n",
      "Epoch [14/50], Step [584/735], Loss: 0.1006\n",
      "Epoch [14/50], Step [585/735], Loss: 0.1042\n",
      "Epoch [14/50], Step [586/735], Loss: 0.1246\n",
      "Epoch [14/50], Step [587/735], Loss: 0.3267\n",
      "Epoch [14/50], Step [588/735], Loss: 0.0613\n",
      "Epoch [14/50], Step [589/735], Loss: 0.2329\n",
      "Epoch [14/50], Step [590/735], Loss: 0.0920\n",
      "Epoch [14/50], Step [591/735], Loss: 0.1609\n",
      "Epoch [14/50], Step [592/735], Loss: 0.0431\n",
      "Epoch [14/50], Step [593/735], Loss: 0.2811\n",
      "Epoch [14/50], Step [594/735], Loss: 0.0971\n",
      "Epoch [14/50], Step [595/735], Loss: 0.1848\n",
      "Epoch [14/50], Step [596/735], Loss: 0.1204\n",
      "Epoch [14/50], Step [597/735], Loss: 0.1028\n",
      "Epoch [14/50], Step [598/735], Loss: 0.0600\n",
      "Epoch [14/50], Step [599/735], Loss: 0.2124\n",
      "Epoch [14/50], Step [600/735], Loss: 0.1313\n",
      "Epoch [14/50], Step [601/735], Loss: 0.1709\n",
      "Epoch [14/50], Step [602/735], Loss: 0.1602\n",
      "Epoch [14/50], Step [603/735], Loss: 0.0727\n",
      "Epoch [14/50], Step [604/735], Loss: 0.0991\n",
      "Epoch [14/50], Step [605/735], Loss: 0.1386\n",
      "Epoch [14/50], Step [606/735], Loss: 0.8922\n",
      "Epoch [14/50], Step [607/735], Loss: 0.1014\n",
      "Epoch [14/50], Step [608/735], Loss: 0.4770\n",
      "Epoch [14/50], Step [609/735], Loss: 0.4223\n",
      "Epoch [14/50], Step [610/735], Loss: 0.1041\n",
      "Epoch [14/50], Step [611/735], Loss: 0.1009\n",
      "Epoch [14/50], Step [612/735], Loss: 0.1284\n",
      "Epoch [14/50], Step [613/735], Loss: 0.1865\n",
      "Epoch [14/50], Step [614/735], Loss: 0.0888\n",
      "Epoch [14/50], Step [615/735], Loss: 0.1230\n",
      "Epoch [14/50], Step [616/735], Loss: 0.3982\n",
      "Epoch [14/50], Step [617/735], Loss: 0.3612\n",
      "Epoch [14/50], Step [618/735], Loss: 0.1259\n",
      "Epoch [14/50], Step [619/735], Loss: 0.0538\n",
      "Epoch [14/50], Step [620/735], Loss: 0.0914\n",
      "Epoch [14/50], Step [621/735], Loss: 0.1553\n",
      "Epoch [14/50], Step [622/735], Loss: 0.0965\n",
      "Epoch [14/50], Step [623/735], Loss: 0.2691\n",
      "Epoch [14/50], Step [624/735], Loss: 0.1203\n",
      "Epoch [14/50], Step [625/735], Loss: 0.2768\n",
      "Epoch [14/50], Step [626/735], Loss: 0.3861\n",
      "Epoch [14/50], Step [627/735], Loss: 0.0294\n",
      "Epoch [14/50], Step [628/735], Loss: 0.2883\n",
      "Epoch [14/50], Step [629/735], Loss: 0.1844\n",
      "Epoch [14/50], Step [630/735], Loss: 0.0970\n",
      "Epoch [14/50], Step [631/735], Loss: 0.6205\n",
      "Epoch [14/50], Step [632/735], Loss: 0.6364\n",
      "Epoch [14/50], Step [633/735], Loss: 0.1869\n",
      "Epoch [14/50], Step [634/735], Loss: 0.1253\n",
      "Epoch [14/50], Step [635/735], Loss: 0.1165\n",
      "Epoch [14/50], Step [636/735], Loss: 0.2211\n",
      "Epoch [14/50], Step [637/735], Loss: 0.1634\n",
      "Epoch [14/50], Step [638/735], Loss: 0.1494\n",
      "Epoch [14/50], Step [639/735], Loss: 0.4005\n",
      "Epoch [14/50], Step [640/735], Loss: 0.1202\n",
      "Epoch [14/50], Step [641/735], Loss: 0.2391\n",
      "Epoch [14/50], Step [642/735], Loss: 0.2116\n",
      "Epoch [14/50], Step [643/735], Loss: 0.1410\n",
      "Epoch [14/50], Step [644/735], Loss: 0.3142\n",
      "Epoch [14/50], Step [645/735], Loss: 0.0939\n",
      "Epoch [14/50], Step [646/735], Loss: 0.4934\n",
      "Epoch [14/50], Step [647/735], Loss: 1.2086\n",
      "Epoch [14/50], Step [648/735], Loss: 0.0511\n",
      "Epoch [14/50], Step [649/735], Loss: 0.2266\n",
      "Epoch [14/50], Step [650/735], Loss: 0.3008\n",
      "Epoch [14/50], Step [651/735], Loss: 1.3760\n",
      "Epoch [14/50], Step [652/735], Loss: 0.1639\n",
      "Epoch [14/50], Step [653/735], Loss: 0.3460\n",
      "Epoch [14/50], Step [654/735], Loss: 0.1082\n",
      "Epoch [14/50], Step [655/735], Loss: 0.1126\n",
      "Epoch [14/50], Step [656/735], Loss: 0.0761\n",
      "Epoch [14/50], Step [657/735], Loss: 0.1527\n",
      "Epoch [14/50], Step [658/735], Loss: 0.1961\n",
      "Epoch [14/50], Step [659/735], Loss: 0.2264\n",
      "Epoch [14/50], Step [660/735], Loss: 0.1877\n",
      "Epoch [14/50], Step [661/735], Loss: 0.1097\n",
      "Epoch [14/50], Step [662/735], Loss: 0.3068\n",
      "Epoch [14/50], Step [663/735], Loss: 0.0601\n",
      "Epoch [14/50], Step [664/735], Loss: 0.1399\n",
      "Epoch [14/50], Step [665/735], Loss: 0.2279\n",
      "Epoch [14/50], Step [666/735], Loss: 0.2204\n",
      "Epoch [14/50], Step [667/735], Loss: 0.0825\n",
      "Epoch [14/50], Step [668/735], Loss: 0.1049\n",
      "Epoch [14/50], Step [669/735], Loss: 0.2721\n",
      "Epoch [14/50], Step [670/735], Loss: 0.1792\n",
      "Epoch [14/50], Step [671/735], Loss: 0.1104\n",
      "Epoch [14/50], Step [672/735], Loss: 0.0755\n",
      "Epoch [14/50], Step [673/735], Loss: 0.1933\n",
      "Epoch [14/50], Step [674/735], Loss: 0.1013\n",
      "Epoch [14/50], Step [675/735], Loss: 0.2143\n",
      "Epoch [14/50], Step [676/735], Loss: 0.1944\n",
      "Epoch [14/50], Step [677/735], Loss: 0.0685\n",
      "Epoch [14/50], Step [678/735], Loss: 0.2454\n",
      "Epoch [14/50], Step [679/735], Loss: 0.1312\n",
      "Epoch [14/50], Step [680/735], Loss: 0.1726\n",
      "Epoch [14/50], Step [681/735], Loss: 0.0422\n",
      "Epoch [14/50], Step [682/735], Loss: 0.2307\n",
      "Epoch [14/50], Step [683/735], Loss: 0.1931\n",
      "Epoch [14/50], Step [684/735], Loss: 0.1003\n",
      "Epoch [14/50], Step [685/735], Loss: 0.2780\n",
      "Epoch [14/50], Step [686/735], Loss: 0.0585\n",
      "Epoch [14/50], Step [687/735], Loss: 0.1379\n",
      "Epoch [14/50], Step [688/735], Loss: 0.1253\n",
      "Epoch [14/50], Step [689/735], Loss: 0.1276\n",
      "Epoch [14/50], Step [690/735], Loss: 0.1455\n",
      "Epoch [14/50], Step [691/735], Loss: 0.1462\n",
      "Epoch [14/50], Step [692/735], Loss: 0.0681\n",
      "Epoch [14/50], Step [693/735], Loss: 0.0313\n",
      "Epoch [14/50], Step [694/735], Loss: 0.1395\n",
      "Epoch [14/50], Step [695/735], Loss: 0.0593\n",
      "Epoch [14/50], Step [696/735], Loss: 0.1693\n",
      "Epoch [14/50], Step [697/735], Loss: 0.1125\n",
      "Epoch [14/50], Step [698/735], Loss: 0.0877\n",
      "Epoch [14/50], Step [699/735], Loss: 0.0743\n",
      "Epoch [14/50], Step [700/735], Loss: 0.3161\n",
      "Epoch [14/50], Step [701/735], Loss: 0.1043\n",
      "Epoch [14/50], Step [702/735], Loss: 0.1377\n",
      "Epoch [14/50], Step [703/735], Loss: 0.0947\n",
      "Epoch [14/50], Step [704/735], Loss: 0.1064\n",
      "Epoch [14/50], Step [705/735], Loss: 0.1686\n",
      "Epoch [14/50], Step [706/735], Loss: 0.2408\n",
      "Epoch [14/50], Step [707/735], Loss: 0.0748\n",
      "Epoch [14/50], Step [708/735], Loss: 0.0584\n",
      "Epoch [14/50], Step [709/735], Loss: 0.1995\n",
      "Epoch [14/50], Step [710/735], Loss: 0.0746\n",
      "Epoch [14/50], Step [711/735], Loss: 0.1497\n",
      "Epoch [14/50], Step [712/735], Loss: 0.1161\n",
      "Epoch [14/50], Step [713/735], Loss: 0.1217\n",
      "Epoch [14/50], Step [714/735], Loss: 0.2386\n",
      "Epoch [14/50], Step [715/735], Loss: 0.1225\n",
      "Epoch [14/50], Step [716/735], Loss: 0.1962\n",
      "Epoch [14/50], Step [717/735], Loss: 0.1828\n",
      "Epoch [14/50], Step [718/735], Loss: 0.0818\n",
      "Epoch [14/50], Step [719/735], Loss: 0.1575\n",
      "Epoch [14/50], Step [720/735], Loss: 0.0475\n",
      "Epoch [14/50], Step [721/735], Loss: 0.1398\n",
      "Epoch [14/50], Step [722/735], Loss: 0.3586\n",
      "Epoch [14/50], Step [723/735], Loss: 0.2109\n",
      "Epoch [14/50], Step [724/735], Loss: 0.0699\n",
      "Epoch [14/50], Step [725/735], Loss: 0.3147\n",
      "Epoch [14/50], Step [726/735], Loss: 0.0214\n",
      "Epoch [14/50], Step [727/735], Loss: 0.0965\n",
      "Epoch [14/50], Step [728/735], Loss: 0.1813\n",
      "Epoch [14/50], Step [729/735], Loss: 0.0753\n",
      "Epoch [14/50], Step [730/735], Loss: 1.2460\n",
      "Epoch [14/50], Step [731/735], Loss: 0.4778\n",
      "Epoch [14/50], Step [732/735], Loss: 0.2414\n",
      "Epoch [14/50], Step [733/735], Loss: 0.1168\n",
      "Epoch [14/50], Step [734/735], Loss: 0.1707\n",
      "Epoch [14/50], Step [735/735], Loss: 0.0674\n",
      "Epoch [15/50], Step [1/735], Loss: 0.1275\n",
      "Epoch [15/50], Step [2/735], Loss: 0.1363\n",
      "Epoch [15/50], Step [3/735], Loss: 0.7340\n",
      "Epoch [15/50], Step [4/735], Loss: 0.2493\n",
      "Epoch [15/50], Step [5/735], Loss: 0.3557\n",
      "Epoch [15/50], Step [6/735], Loss: 0.2040\n",
      "Epoch [15/50], Step [7/735], Loss: 0.0736\n",
      "Epoch [15/50], Step [8/735], Loss: 0.1418\n",
      "Epoch [15/50], Step [9/735], Loss: 0.1097\n",
      "Epoch [15/50], Step [10/735], Loss: 0.1194\n",
      "Epoch [15/50], Step [11/735], Loss: 0.4778\n",
      "Epoch [15/50], Step [12/735], Loss: 0.0595\n",
      "Epoch [15/50], Step [13/735], Loss: 0.1430\n",
      "Epoch [15/50], Step [14/735], Loss: 0.4834\n",
      "Epoch [15/50], Step [15/735], Loss: 0.3216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Step [16/735], Loss: 0.3645\n",
      "Epoch [15/50], Step [17/735], Loss: 0.3031\n",
      "Epoch [15/50], Step [18/735], Loss: 0.2123\n",
      "Epoch [15/50], Step [19/735], Loss: 0.1424\n",
      "Epoch [15/50], Step [20/735], Loss: 0.2579\n",
      "Epoch [15/50], Step [21/735], Loss: 0.1863\n",
      "Epoch [15/50], Step [22/735], Loss: 0.0878\n",
      "Epoch [15/50], Step [23/735], Loss: 0.1249\n",
      "Epoch [15/50], Step [24/735], Loss: 0.2303\n",
      "Epoch [15/50], Step [25/735], Loss: 0.1035\n",
      "Epoch [15/50], Step [26/735], Loss: 0.5432\n",
      "Epoch [15/50], Step [27/735], Loss: 0.1057\n",
      "Epoch [15/50], Step [28/735], Loss: 0.0604\n",
      "Epoch [15/50], Step [29/735], Loss: 0.1132\n",
      "Epoch [15/50], Step [30/735], Loss: 0.1067\n",
      "Epoch [15/50], Step [31/735], Loss: 0.0981\n",
      "Epoch [15/50], Step [32/735], Loss: 0.1323\n",
      "Epoch [15/50], Step [33/735], Loss: 0.1428\n",
      "Epoch [15/50], Step [34/735], Loss: 0.1896\n",
      "Epoch [15/50], Step [35/735], Loss: 0.0782\n",
      "Epoch [15/50], Step [36/735], Loss: 0.1039\n",
      "Epoch [15/50], Step [37/735], Loss: 0.0587\n",
      "Epoch [15/50], Step [38/735], Loss: 0.2222\n",
      "Epoch [15/50], Step [39/735], Loss: 0.2564\n",
      "Epoch [15/50], Step [40/735], Loss: 0.0918\n",
      "Epoch [15/50], Step [41/735], Loss: 0.1172\n",
      "Epoch [15/50], Step [42/735], Loss: 1.3694\n",
      "Epoch [15/50], Step [43/735], Loss: 0.2126\n",
      "Epoch [15/50], Step [44/735], Loss: 0.1070\n",
      "Epoch [15/50], Step [45/735], Loss: 0.0830\n",
      "Epoch [15/50], Step [46/735], Loss: 0.1284\n",
      "Epoch [15/50], Step [47/735], Loss: 0.0985\n",
      "Epoch [15/50], Step [48/735], Loss: 0.0333\n",
      "Epoch [15/50], Step [49/735], Loss: 0.2081\n",
      "Epoch [15/50], Step [50/735], Loss: 0.1976\n",
      "Epoch [15/50], Step [51/735], Loss: 0.0636\n",
      "Epoch [15/50], Step [52/735], Loss: 0.1549\n",
      "Epoch [15/50], Step [53/735], Loss: 0.0963\n",
      "Epoch [15/50], Step [54/735], Loss: 0.1456\n",
      "Epoch [15/50], Step [55/735], Loss: 0.0696\n",
      "Epoch [15/50], Step [56/735], Loss: 0.0291\n",
      "Epoch [15/50], Step [57/735], Loss: 0.0710\n",
      "Epoch [15/50], Step [58/735], Loss: 0.0536\n",
      "Epoch [15/50], Step [59/735], Loss: 0.1369\n",
      "Epoch [15/50], Step [60/735], Loss: 0.1338\n",
      "Epoch [15/50], Step [61/735], Loss: 0.0731\n",
      "Epoch [15/50], Step [62/735], Loss: 0.4719\n",
      "Epoch [15/50], Step [63/735], Loss: 0.0929\n",
      "Epoch [15/50], Step [64/735], Loss: 0.1042\n",
      "Epoch [15/50], Step [65/735], Loss: 0.0658\n",
      "Epoch [15/50], Step [66/735], Loss: 0.0602\n",
      "Epoch [15/50], Step [67/735], Loss: 0.0833\n",
      "Epoch [15/50], Step [68/735], Loss: 0.1462\n",
      "Epoch [15/50], Step [69/735], Loss: 0.1141\n",
      "Epoch [15/50], Step [70/735], Loss: 0.0814\n",
      "Epoch [15/50], Step [71/735], Loss: 0.0983\n",
      "Epoch [15/50], Step [72/735], Loss: 0.0885\n",
      "Epoch [15/50], Step [73/735], Loss: 0.1158\n",
      "Epoch [15/50], Step [74/735], Loss: 0.0985\n",
      "Epoch [15/50], Step [75/735], Loss: 0.1546\n",
      "Epoch [15/50], Step [76/735], Loss: 0.1452\n",
      "Epoch [15/50], Step [77/735], Loss: 0.1273\n",
      "Epoch [15/50], Step [78/735], Loss: 0.1276\n",
      "Epoch [15/50], Step [79/735], Loss: 0.3486\n",
      "Epoch [15/50], Step [80/735], Loss: 0.1489\n",
      "Epoch [15/50], Step [81/735], Loss: 0.2636\n",
      "Epoch [15/50], Step [82/735], Loss: 0.1368\n",
      "Epoch [15/50], Step [83/735], Loss: 0.1976\n",
      "Epoch [15/50], Step [84/735], Loss: 0.0802\n",
      "Epoch [15/50], Step [85/735], Loss: 0.1195\n",
      "Epoch [15/50], Step [86/735], Loss: 0.1536\n",
      "Epoch [15/50], Step [87/735], Loss: 0.5078\n",
      "Epoch [15/50], Step [88/735], Loss: 0.1901\n",
      "Epoch [15/50], Step [89/735], Loss: 0.1739\n",
      "Epoch [15/50], Step [90/735], Loss: 0.1771\n",
      "Epoch [15/50], Step [91/735], Loss: 0.1722\n",
      "Epoch [15/50], Step [92/735], Loss: 0.4503\n",
      "Epoch [15/50], Step [93/735], Loss: 0.2492\n",
      "Epoch [15/50], Step [94/735], Loss: 0.0864\n",
      "Epoch [15/50], Step [95/735], Loss: 0.0600\n",
      "Epoch [15/50], Step [96/735], Loss: 0.1199\n",
      "Epoch [15/50], Step [97/735], Loss: 0.1701\n",
      "Epoch [15/50], Step [98/735], Loss: 0.1733\n",
      "Epoch [15/50], Step [99/735], Loss: 0.0881\n",
      "Epoch [15/50], Step [100/735], Loss: 0.1815\n",
      "Epoch [15/50], Step [101/735], Loss: 0.0572\n",
      "Epoch [15/50], Step [102/735], Loss: 0.1051\n",
      "Epoch [15/50], Step [103/735], Loss: 0.0837\n",
      "Epoch [15/50], Step [104/735], Loss: 0.0794\n",
      "Epoch [15/50], Step [105/735], Loss: 0.0628\n",
      "Epoch [15/50], Step [106/735], Loss: 0.1028\n",
      "Epoch [15/50], Step [107/735], Loss: 0.0885\n",
      "Epoch [15/50], Step [108/735], Loss: 0.1399\n",
      "Epoch [15/50], Step [109/735], Loss: 0.2675\n",
      "Epoch [15/50], Step [110/735], Loss: 0.0860\n",
      "Epoch [15/50], Step [111/735], Loss: 0.2082\n",
      "Epoch [15/50], Step [112/735], Loss: 0.2463\n",
      "Epoch [15/50], Step [113/735], Loss: 0.0672\n",
      "Epoch [15/50], Step [114/735], Loss: 0.3311\n",
      "Epoch [15/50], Step [115/735], Loss: 0.2355\n",
      "Epoch [15/50], Step [116/735], Loss: 0.1889\n",
      "Epoch [15/50], Step [117/735], Loss: 0.0992\n",
      "Epoch [15/50], Step [118/735], Loss: 0.2800\n",
      "Epoch [15/50], Step [119/735], Loss: 0.0710\n",
      "Epoch [15/50], Step [120/735], Loss: 0.0584\n",
      "Epoch [15/50], Step [121/735], Loss: 0.0548\n",
      "Epoch [15/50], Step [122/735], Loss: 0.1775\n",
      "Epoch [15/50], Step [123/735], Loss: 0.1640\n",
      "Epoch [15/50], Step [124/735], Loss: 0.0314\n",
      "Epoch [15/50], Step [125/735], Loss: 0.1096\n",
      "Epoch [15/50], Step [126/735], Loss: 0.2538\n",
      "Epoch [15/50], Step [127/735], Loss: 0.1353\n",
      "Epoch [15/50], Step [128/735], Loss: 0.0510\n",
      "Epoch [15/50], Step [129/735], Loss: 0.1544\n",
      "Epoch [15/50], Step [130/735], Loss: 0.1107\n",
      "Epoch [15/50], Step [131/735], Loss: 0.0442\n",
      "Epoch [15/50], Step [132/735], Loss: 1.1717\n",
      "Epoch [15/50], Step [133/735], Loss: 0.1171\n",
      "Epoch [15/50], Step [134/735], Loss: 0.0985\n",
      "Epoch [15/50], Step [135/735], Loss: 0.1206\n",
      "Epoch [15/50], Step [136/735], Loss: 0.0882\n",
      "Epoch [15/50], Step [137/735], Loss: 0.0966\n",
      "Epoch [15/50], Step [138/735], Loss: 0.9457\n",
      "Epoch [15/50], Step [139/735], Loss: 0.1083\n",
      "Epoch [15/50], Step [140/735], Loss: 0.1625\n",
      "Epoch [15/50], Step [141/735], Loss: 0.1157\n",
      "Epoch [15/50], Step [142/735], Loss: 0.0457\n",
      "Epoch [15/50], Step [143/735], Loss: 0.0515\n",
      "Epoch [15/50], Step [144/735], Loss: 0.3117\n",
      "Epoch [15/50], Step [145/735], Loss: 0.0832\n",
      "Epoch [15/50], Step [146/735], Loss: 0.0746\n",
      "Epoch [15/50], Step [147/735], Loss: 0.1641\n",
      "Epoch [15/50], Step [148/735], Loss: 0.1765\n",
      "Epoch [15/50], Step [149/735], Loss: 0.0788\n",
      "Epoch [15/50], Step [150/735], Loss: 0.2152\n",
      "Epoch [15/50], Step [151/735], Loss: 0.0616\n",
      "Epoch [15/50], Step [152/735], Loss: 1.7567\n",
      "Epoch [15/50], Step [153/735], Loss: 0.2457\n",
      "Epoch [15/50], Step [154/735], Loss: 0.2064\n",
      "Epoch [15/50], Step [155/735], Loss: 0.4277\n",
      "Epoch [15/50], Step [156/735], Loss: 0.4039\n",
      "Epoch [15/50], Step [157/735], Loss: 0.1578\n",
      "Epoch [15/50], Step [158/735], Loss: 0.5261\n",
      "Epoch [15/50], Step [159/735], Loss: 0.1416\n",
      "Epoch [15/50], Step [160/735], Loss: 0.1805\n",
      "Epoch [15/50], Step [161/735], Loss: 0.0992\n",
      "Epoch [15/50], Step [162/735], Loss: 0.1239\n",
      "Epoch [15/50], Step [163/735], Loss: 0.0866\n",
      "Epoch [15/50], Step [164/735], Loss: 0.1176\n",
      "Epoch [15/50], Step [165/735], Loss: 0.1058\n",
      "Epoch [15/50], Step [166/735], Loss: 0.3155\n",
      "Epoch [15/50], Step [167/735], Loss: 0.2610\n",
      "Epoch [15/50], Step [168/735], Loss: 0.1635\n",
      "Epoch [15/50], Step [169/735], Loss: 0.5654\n",
      "Epoch [15/50], Step [170/735], Loss: 0.0903\n",
      "Epoch [15/50], Step [171/735], Loss: 0.1119\n",
      "Epoch [15/50], Step [172/735], Loss: 0.3324\n",
      "Epoch [15/50], Step [173/735], Loss: 0.0786\n",
      "Epoch [15/50], Step [174/735], Loss: 0.0609\n",
      "Epoch [15/50], Step [175/735], Loss: 0.3478\n",
      "Epoch [15/50], Step [176/735], Loss: 0.2433\n",
      "Epoch [15/50], Step [177/735], Loss: 0.0888\n",
      "Epoch [15/50], Step [178/735], Loss: 0.0725\n",
      "Epoch [15/50], Step [179/735], Loss: 0.1725\n",
      "Epoch [15/50], Step [180/735], Loss: 0.1091\n",
      "Epoch [15/50], Step [181/735], Loss: 0.1172\n",
      "Epoch [15/50], Step [182/735], Loss: 0.1568\n",
      "Epoch [15/50], Step [183/735], Loss: 0.1985\n",
      "Epoch [15/50], Step [184/735], Loss: 0.0554\n",
      "Epoch [15/50], Step [185/735], Loss: 0.6677\n",
      "Epoch [15/50], Step [186/735], Loss: 0.1874\n",
      "Epoch [15/50], Step [187/735], Loss: 0.0586\n",
      "Epoch [15/50], Step [188/735], Loss: 0.1290\n",
      "Epoch [15/50], Step [189/735], Loss: 0.1039\n",
      "Epoch [15/50], Step [190/735], Loss: 0.0761\n",
      "Epoch [15/50], Step [191/735], Loss: 0.1989\n",
      "Epoch [15/50], Step [192/735], Loss: 0.3191\n",
      "Epoch [15/50], Step [193/735], Loss: 0.1412\n",
      "Epoch [15/50], Step [194/735], Loss: 0.1525\n",
      "Epoch [15/50], Step [195/735], Loss: 0.0964\n",
      "Epoch [15/50], Step [196/735], Loss: 0.1236\n",
      "Epoch [15/50], Step [197/735], Loss: 0.1508\n",
      "Epoch [15/50], Step [198/735], Loss: 0.1101\n",
      "Epoch [15/50], Step [199/735], Loss: 0.1387\n",
      "Epoch [15/50], Step [200/735], Loss: 0.0634\n",
      "Epoch [15/50], Step [201/735], Loss: 0.2845\n",
      "Epoch [15/50], Step [202/735], Loss: 0.6174\n",
      "Epoch [15/50], Step [203/735], Loss: 0.1345\n",
      "Epoch [15/50], Step [204/735], Loss: 0.5290\n",
      "Epoch [15/50], Step [205/735], Loss: 0.2495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Step [206/735], Loss: 0.0675\n",
      "Epoch [15/50], Step [207/735], Loss: 0.1101\n",
      "Epoch [15/50], Step [208/735], Loss: 0.2408\n",
      "Epoch [15/50], Step [209/735], Loss: 0.1053\n",
      "Epoch [15/50], Step [210/735], Loss: 0.0963\n",
      "Epoch [15/50], Step [211/735], Loss: 0.2016\n",
      "Epoch [15/50], Step [212/735], Loss: 0.5527\n",
      "Epoch [15/50], Step [213/735], Loss: 0.0827\n",
      "Epoch [15/50], Step [214/735], Loss: 0.2018\n",
      "Epoch [15/50], Step [215/735], Loss: 0.3231\n",
      "Epoch [15/50], Step [216/735], Loss: 0.2945\n",
      "Epoch [15/50], Step [217/735], Loss: 0.1810\n",
      "Epoch [15/50], Step [218/735], Loss: 0.1980\n",
      "Epoch [15/50], Step [219/735], Loss: 0.0586\n",
      "Epoch [15/50], Step [220/735], Loss: 0.2981\n",
      "Epoch [15/50], Step [221/735], Loss: 0.0661\n",
      "Epoch [15/50], Step [222/735], Loss: 0.1743\n",
      "Epoch [15/50], Step [223/735], Loss: 0.2516\n",
      "Epoch [15/50], Step [224/735], Loss: 0.2186\n",
      "Epoch [15/50], Step [225/735], Loss: 2.0501\n",
      "Epoch [15/50], Step [226/735], Loss: 0.2715\n",
      "Epoch [15/50], Step [227/735], Loss: 0.1262\n",
      "Epoch [15/50], Step [228/735], Loss: 0.2230\n",
      "Epoch [15/50], Step [229/735], Loss: 0.0930\n",
      "Epoch [15/50], Step [230/735], Loss: 0.1003\n",
      "Epoch [15/50], Step [231/735], Loss: 0.0910\n",
      "Epoch [15/50], Step [232/735], Loss: 0.2828\n",
      "Epoch [15/50], Step [233/735], Loss: 0.0474\n",
      "Epoch [15/50], Step [234/735], Loss: 0.0668\n",
      "Epoch [15/50], Step [235/735], Loss: 0.3501\n",
      "Epoch [15/50], Step [236/735], Loss: 0.4087\n",
      "Epoch [15/50], Step [237/735], Loss: 0.1531\n",
      "Epoch [15/50], Step [238/735], Loss: 0.1061\n",
      "Epoch [15/50], Step [239/735], Loss: 0.1280\n",
      "Epoch [15/50], Step [240/735], Loss: 0.4882\n",
      "Epoch [15/50], Step [241/735], Loss: 0.3666\n",
      "Epoch [15/50], Step [242/735], Loss: 0.0955\n",
      "Epoch [15/50], Step [243/735], Loss: 0.1739\n",
      "Epoch [15/50], Step [244/735], Loss: 0.0534\n",
      "Epoch [15/50], Step [245/735], Loss: 0.3776\n",
      "Epoch [15/50], Step [246/735], Loss: 0.0933\n",
      "Epoch [15/50], Step [247/735], Loss: 0.1532\n",
      "Epoch [15/50], Step [248/735], Loss: 0.1032\n",
      "Epoch [15/50], Step [249/735], Loss: 0.1158\n",
      "Epoch [15/50], Step [250/735], Loss: 0.0540\n",
      "Epoch [15/50], Step [251/735], Loss: 0.0657\n",
      "Epoch [15/50], Step [252/735], Loss: 0.1859\n",
      "Epoch [15/50], Step [253/735], Loss: 0.4084\n",
      "Epoch [15/50], Step [254/735], Loss: 0.1037\n",
      "Epoch [15/50], Step [255/735], Loss: 1.7901\n",
      "Epoch [15/50], Step [256/735], Loss: 0.2432\n",
      "Epoch [15/50], Step [257/735], Loss: 0.4361\n",
      "Epoch [15/50], Step [258/735], Loss: 0.0469\n",
      "Epoch [15/50], Step [259/735], Loss: 0.1403\n",
      "Epoch [15/50], Step [260/735], Loss: 0.4645\n",
      "Epoch [15/50], Step [261/735], Loss: 0.1232\n",
      "Epoch [15/50], Step [262/735], Loss: 0.0939\n",
      "Epoch [15/50], Step [263/735], Loss: 0.2668\n",
      "Epoch [15/50], Step [264/735], Loss: 0.1458\n",
      "Epoch [15/50], Step [265/735], Loss: 0.1387\n",
      "Epoch [15/50], Step [266/735], Loss: 0.2331\n",
      "Epoch [15/50], Step [267/735], Loss: 0.0745\n",
      "Epoch [15/50], Step [268/735], Loss: 0.2261\n",
      "Epoch [15/50], Step [269/735], Loss: 0.9835\n",
      "Epoch [15/50], Step [270/735], Loss: 0.2415\n",
      "Epoch [15/50], Step [271/735], Loss: 0.0627\n",
      "Epoch [15/50], Step [272/735], Loss: 0.2710\n",
      "Epoch [15/50], Step [273/735], Loss: 0.1381\n",
      "Epoch [15/50], Step [274/735], Loss: 0.4804\n",
      "Epoch [15/50], Step [275/735], Loss: 0.0944\n",
      "Epoch [15/50], Step [276/735], Loss: 0.2105\n",
      "Epoch [15/50], Step [277/735], Loss: 0.1049\n",
      "Epoch [15/50], Step [278/735], Loss: 0.0745\n",
      "Epoch [15/50], Step [279/735], Loss: 0.1181\n",
      "Epoch [15/50], Step [280/735], Loss: 0.3460\n",
      "Epoch [15/50], Step [281/735], Loss: 0.3273\n",
      "Epoch [15/50], Step [282/735], Loss: 0.1335\n",
      "Epoch [15/50], Step [283/735], Loss: 0.0807\n",
      "Epoch [15/50], Step [284/735], Loss: 0.1251\n",
      "Epoch [15/50], Step [285/735], Loss: 0.1590\n",
      "Epoch [15/50], Step [286/735], Loss: 0.0800\n",
      "Epoch [15/50], Step [287/735], Loss: 0.0619\n",
      "Epoch [15/50], Step [288/735], Loss: 0.2115\n",
      "Epoch [15/50], Step [289/735], Loss: 0.2131\n",
      "Epoch [15/50], Step [290/735], Loss: 0.0637\n",
      "Epoch [15/50], Step [291/735], Loss: 0.1472\n",
      "Epoch [15/50], Step [292/735], Loss: 0.3388\n",
      "Epoch [15/50], Step [293/735], Loss: 0.0903\n",
      "Epoch [15/50], Step [294/735], Loss: 0.1524\n",
      "Epoch [15/50], Step [295/735], Loss: 0.0936\n",
      "Epoch [15/50], Step [296/735], Loss: 0.1908\n",
      "Epoch [15/50], Step [297/735], Loss: 0.0459\n",
      "Epoch [15/50], Step [298/735], Loss: 0.1003\n",
      "Epoch [15/50], Step [299/735], Loss: 0.0370\n",
      "Epoch [15/50], Step [300/735], Loss: 0.1364\n",
      "Epoch [15/50], Step [301/735], Loss: 0.1320\n",
      "Epoch [15/50], Step [302/735], Loss: 0.1651\n",
      "Epoch [15/50], Step [303/735], Loss: 0.0496\n",
      "Epoch [15/50], Step [304/735], Loss: 0.0875\n",
      "Epoch [15/50], Step [305/735], Loss: 0.2968\n",
      "Epoch [15/50], Step [306/735], Loss: 0.3475\n",
      "Epoch [15/50], Step [307/735], Loss: 0.3109\n",
      "Epoch [15/50], Step [308/735], Loss: 0.0510\n",
      "Epoch [15/50], Step [309/735], Loss: 0.1024\n",
      "Epoch [15/50], Step [310/735], Loss: 0.0925\n",
      "Epoch [15/50], Step [311/735], Loss: 0.0868\n",
      "Epoch [15/50], Step [312/735], Loss: 0.4567\n",
      "Epoch [15/50], Step [313/735], Loss: 0.1119\n",
      "Epoch [15/50], Step [314/735], Loss: 0.0884\n",
      "Epoch [15/50], Step [315/735], Loss: 0.0457\n",
      "Epoch [15/50], Step [316/735], Loss: 0.0742\n",
      "Epoch [15/50], Step [317/735], Loss: 0.2945\n",
      "Epoch [15/50], Step [318/735], Loss: 0.1068\n",
      "Epoch [15/50], Step [319/735], Loss: 0.1509\n",
      "Epoch [15/50], Step [320/735], Loss: 0.1696\n",
      "Epoch [15/50], Step [321/735], Loss: 0.0500\n",
      "Epoch [15/50], Step [322/735], Loss: 0.3277\n",
      "Epoch [15/50], Step [323/735], Loss: 0.0528\n",
      "Epoch [15/50], Step [324/735], Loss: 0.1296\n",
      "Epoch [15/50], Step [325/735], Loss: 0.2507\n",
      "Epoch [15/50], Step [326/735], Loss: 0.6661\n",
      "Epoch [15/50], Step [327/735], Loss: 0.4137\n",
      "Epoch [15/50], Step [328/735], Loss: 0.0890\n",
      "Epoch [15/50], Step [329/735], Loss: 0.1350\n",
      "Epoch [15/50], Step [330/735], Loss: 0.1964\n",
      "Epoch [15/50], Step [331/735], Loss: 0.1199\n",
      "Epoch [15/50], Step [332/735], Loss: 0.0910\n",
      "Epoch [15/50], Step [333/735], Loss: 0.0352\n",
      "Epoch [15/50], Step [334/735], Loss: 0.0542\n",
      "Epoch [15/50], Step [335/735], Loss: 0.0707\n",
      "Epoch [15/50], Step [336/735], Loss: 0.3270\n",
      "Epoch [15/50], Step [337/735], Loss: 0.0350\n",
      "Epoch [15/50], Step [338/735], Loss: 0.0692\n",
      "Epoch [15/50], Step [339/735], Loss: 0.5511\n",
      "Epoch [15/50], Step [340/735], Loss: 0.0473\n",
      "Epoch [15/50], Step [341/735], Loss: 0.0494\n",
      "Epoch [15/50], Step [342/735], Loss: 0.1748\n",
      "Epoch [15/50], Step [343/735], Loss: 0.1025\n",
      "Epoch [15/50], Step [344/735], Loss: 0.5352\n",
      "Epoch [15/50], Step [345/735], Loss: 0.2634\n",
      "Epoch [15/50], Step [346/735], Loss: 0.2650\n",
      "Epoch [15/50], Step [347/735], Loss: 0.2238\n",
      "Epoch [15/50], Step [348/735], Loss: 0.1237\n",
      "Epoch [15/50], Step [349/735], Loss: 0.1945\n",
      "Epoch [15/50], Step [350/735], Loss: 0.9961\n",
      "Epoch [15/50], Step [351/735], Loss: 0.2218\n",
      "Epoch [15/50], Step [352/735], Loss: 0.1407\n",
      "Epoch [15/50], Step [353/735], Loss: 0.2426\n",
      "Epoch [15/50], Step [354/735], Loss: 0.0502\n",
      "Epoch [15/50], Step [355/735], Loss: 0.2849\n",
      "Epoch [15/50], Step [356/735], Loss: 0.0654\n",
      "Epoch [15/50], Step [357/735], Loss: 0.1869\n",
      "Epoch [15/50], Step [358/735], Loss: 0.6923\n",
      "Epoch [15/50], Step [359/735], Loss: 0.3816\n",
      "Epoch [15/50], Step [360/735], Loss: 0.2930\n",
      "Epoch [15/50], Step [361/735], Loss: 0.1025\n",
      "Epoch [15/50], Step [362/735], Loss: 0.1049\n",
      "Epoch [15/50], Step [363/735], Loss: 0.2561\n",
      "Epoch [15/50], Step [364/735], Loss: 0.1375\n",
      "Epoch [15/50], Step [365/735], Loss: 0.2280\n",
      "Epoch [15/50], Step [366/735], Loss: 0.1151\n",
      "Epoch [15/50], Step [367/735], Loss: 0.2398\n",
      "Epoch [15/50], Step [368/735], Loss: 0.6995\n",
      "Epoch [15/50], Step [369/735], Loss: 0.2322\n",
      "Epoch [15/50], Step [370/735], Loss: 0.0418\n",
      "Epoch [15/50], Step [371/735], Loss: 0.3976\n",
      "Epoch [15/50], Step [372/735], Loss: 0.1102\n",
      "Epoch [15/50], Step [373/735], Loss: 0.1881\n",
      "Epoch [15/50], Step [374/735], Loss: 0.1215\n",
      "Epoch [15/50], Step [375/735], Loss: 0.3018\n",
      "Epoch [15/50], Step [376/735], Loss: 0.2679\n",
      "Epoch [15/50], Step [377/735], Loss: 0.1141\n",
      "Epoch [15/50], Step [378/735], Loss: 0.1299\n",
      "Epoch [15/50], Step [379/735], Loss: 0.0560\n",
      "Epoch [15/50], Step [380/735], Loss: 0.0461\n",
      "Epoch [15/50], Step [381/735], Loss: 0.2034\n",
      "Epoch [15/50], Step [382/735], Loss: 0.4200\n",
      "Epoch [15/50], Step [383/735], Loss: 0.0460\n",
      "Epoch [15/50], Step [384/735], Loss: 0.4967\n",
      "Epoch [15/50], Step [385/735], Loss: 0.1379\n",
      "Epoch [15/50], Step [386/735], Loss: 0.4513\n",
      "Epoch [15/50], Step [387/735], Loss: 0.1156\n",
      "Epoch [15/50], Step [388/735], Loss: 0.1147\n",
      "Epoch [15/50], Step [389/735], Loss: 0.1626\n",
      "Epoch [15/50], Step [390/735], Loss: 0.0612\n",
      "Epoch [15/50], Step [391/735], Loss: 0.1901\n",
      "Epoch [15/50], Step [392/735], Loss: 0.0723\n",
      "Epoch [15/50], Step [393/735], Loss: 0.1716\n",
      "Epoch [15/50], Step [394/735], Loss: 0.2833\n",
      "Epoch [15/50], Step [395/735], Loss: 0.0824\n",
      "Epoch [15/50], Step [396/735], Loss: 0.0391\n",
      "Epoch [15/50], Step [397/735], Loss: 0.4272\n",
      "Epoch [15/50], Step [398/735], Loss: 0.0923\n",
      "Epoch [15/50], Step [399/735], Loss: 0.0343\n",
      "Epoch [15/50], Step [400/735], Loss: 0.1447\n",
      "Epoch [15/50], Step [401/735], Loss: 0.0584\n",
      "Epoch [15/50], Step [402/735], Loss: 0.0953\n",
      "Epoch [15/50], Step [403/735], Loss: 0.0903\n",
      "Epoch [15/50], Step [404/735], Loss: 0.4061\n",
      "Epoch [15/50], Step [405/735], Loss: 0.1067\n",
      "Epoch [15/50], Step [406/735], Loss: 0.1749\n",
      "Epoch [15/50], Step [407/735], Loss: 0.2085\n",
      "Epoch [15/50], Step [408/735], Loss: 0.0608\n",
      "Epoch [15/50], Step [409/735], Loss: 0.1920\n",
      "Epoch [15/50], Step [410/735], Loss: 0.0900\n",
      "Epoch [15/50], Step [411/735], Loss: 0.1453\n",
      "Epoch [15/50], Step [412/735], Loss: 0.1292\n",
      "Epoch [15/50], Step [413/735], Loss: 0.2024\n",
      "Epoch [15/50], Step [414/735], Loss: 0.0932\n",
      "Epoch [15/50], Step [415/735], Loss: 1.7480\n",
      "Epoch [15/50], Step [416/735], Loss: 0.0534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Step [417/735], Loss: 0.4428\n",
      "Epoch [15/50], Step [418/735], Loss: 0.1694\n",
      "Epoch [15/50], Step [419/735], Loss: 0.1561\n",
      "Epoch [15/50], Step [420/735], Loss: 1.1260\n",
      "Epoch [15/50], Step [421/735], Loss: 0.1692\n",
      "Epoch [15/50], Step [422/735], Loss: 0.1198\n",
      "Epoch [15/50], Step [423/735], Loss: 0.3200\n",
      "Epoch [15/50], Step [424/735], Loss: 0.1584\n",
      "Epoch [15/50], Step [425/735], Loss: 0.0861\n",
      "Epoch [15/50], Step [426/735], Loss: 0.0885\n",
      "Epoch [15/50], Step [427/735], Loss: 0.0656\n",
      "Epoch [15/50], Step [428/735], Loss: 0.0490\n",
      "Epoch [15/50], Step [429/735], Loss: 0.0513\n",
      "Epoch [15/50], Step [430/735], Loss: 0.0872\n",
      "Epoch [15/50], Step [431/735], Loss: 0.0681\n",
      "Epoch [15/50], Step [432/735], Loss: 0.1104\n",
      "Epoch [15/50], Step [433/735], Loss: 0.0712\n",
      "Epoch [15/50], Step [434/735], Loss: 0.0614\n",
      "Epoch [15/50], Step [435/735], Loss: 0.2331\n",
      "Epoch [15/50], Step [436/735], Loss: 0.5780\n",
      "Epoch [15/50], Step [437/735], Loss: 0.0649\n",
      "Epoch [15/50], Step [438/735], Loss: 0.0815\n",
      "Epoch [15/50], Step [439/735], Loss: 0.0773\n",
      "Epoch [15/50], Step [440/735], Loss: 0.9124\n",
      "Epoch [15/50], Step [441/735], Loss: 1.9316\n",
      "Epoch [15/50], Step [442/735], Loss: 0.1371\n",
      "Epoch [15/50], Step [443/735], Loss: 0.0909\n",
      "Epoch [15/50], Step [444/735], Loss: 0.0469\n",
      "Epoch [15/50], Step [445/735], Loss: 0.0805\n",
      "Epoch [15/50], Step [446/735], Loss: 0.2102\n",
      "Epoch [15/50], Step [447/735], Loss: 0.2170\n",
      "Epoch [15/50], Step [448/735], Loss: 0.0917\n",
      "Epoch [15/50], Step [449/735], Loss: 0.0712\n",
      "Epoch [15/50], Step [450/735], Loss: 0.0746\n",
      "Epoch [15/50], Step [451/735], Loss: 0.2551\n",
      "Epoch [15/50], Step [452/735], Loss: 0.2223\n",
      "Epoch [15/50], Step [453/735], Loss: 0.0714\n",
      "Epoch [15/50], Step [454/735], Loss: 0.1013\n",
      "Epoch [15/50], Step [455/735], Loss: 0.2508\n",
      "Epoch [15/50], Step [456/735], Loss: 0.2846\n",
      "Epoch [15/50], Step [457/735], Loss: 0.1246\n",
      "Epoch [15/50], Step [458/735], Loss: 0.2488\n",
      "Epoch [15/50], Step [459/735], Loss: 0.1243\n",
      "Epoch [15/50], Step [460/735], Loss: 0.1527\n",
      "Epoch [15/50], Step [461/735], Loss: 1.1105\n",
      "Epoch [15/50], Step [462/735], Loss: 0.1028\n",
      "Epoch [15/50], Step [463/735], Loss: 0.1547\n",
      "Epoch [15/50], Step [464/735], Loss: 0.2519\n",
      "Epoch [15/50], Step [465/735], Loss: 0.2338\n",
      "Epoch [15/50], Step [466/735], Loss: 0.1592\n",
      "Epoch [15/50], Step [467/735], Loss: 0.2188\n",
      "Epoch [15/50], Step [468/735], Loss: 0.2306\n",
      "Epoch [15/50], Step [469/735], Loss: 1.1457\n",
      "Epoch [15/50], Step [470/735], Loss: 0.7761\n",
      "Epoch [15/50], Step [471/735], Loss: 0.1075\n",
      "Epoch [15/50], Step [472/735], Loss: 0.4680\n",
      "Epoch [15/50], Step [473/735], Loss: 0.2642\n",
      "Epoch [15/50], Step [474/735], Loss: 0.1225\n",
      "Epoch [15/50], Step [475/735], Loss: 0.3963\n",
      "Epoch [15/50], Step [476/735], Loss: 0.1650\n",
      "Epoch [15/50], Step [477/735], Loss: 0.3377\n",
      "Epoch [15/50], Step [478/735], Loss: 0.2471\n",
      "Epoch [15/50], Step [479/735], Loss: 0.1097\n",
      "Epoch [15/50], Step [480/735], Loss: 0.4551\n",
      "Epoch [15/50], Step [481/735], Loss: 0.2673\n",
      "Epoch [15/50], Step [482/735], Loss: 0.7697\n",
      "Epoch [15/50], Step [483/735], Loss: 0.3140\n",
      "Epoch [15/50], Step [484/735], Loss: 0.1697\n",
      "Epoch [15/50], Step [485/735], Loss: 0.1512\n",
      "Epoch [15/50], Step [486/735], Loss: 0.4486\n",
      "Epoch [15/50], Step [487/735], Loss: 0.0862\n",
      "Epoch [15/50], Step [488/735], Loss: 0.3106\n",
      "Epoch [15/50], Step [489/735], Loss: 0.1084\n",
      "Epoch [15/50], Step [490/735], Loss: 0.4271\n",
      "Epoch [15/50], Step [491/735], Loss: 0.1958\n",
      "Epoch [15/50], Step [492/735], Loss: 0.0891\n",
      "Epoch [15/50], Step [493/735], Loss: 0.1895\n",
      "Epoch [15/50], Step [494/735], Loss: 0.1850\n",
      "Epoch [15/50], Step [495/735], Loss: 0.0503\n",
      "Epoch [15/50], Step [496/735], Loss: 0.0894\n",
      "Epoch [15/50], Step [497/735], Loss: 0.1630\n",
      "Epoch [15/50], Step [498/735], Loss: 0.3176\n",
      "Epoch [15/50], Step [499/735], Loss: 0.4420\n",
      "Epoch [15/50], Step [500/735], Loss: 0.1068\n",
      "Epoch [15/50], Step [501/735], Loss: 0.1079\n",
      "Epoch [15/50], Step [502/735], Loss: 0.2319\n",
      "Epoch [15/50], Step [503/735], Loss: 0.1554\n",
      "Epoch [15/50], Step [504/735], Loss: 0.0916\n",
      "Epoch [15/50], Step [505/735], Loss: 0.1048\n",
      "Epoch [15/50], Step [506/735], Loss: 0.0376\n",
      "Epoch [15/50], Step [507/735], Loss: 0.1524\n",
      "Epoch [15/50], Step [508/735], Loss: 0.1066\n",
      "Epoch [15/50], Step [509/735], Loss: 0.1090\n",
      "Epoch [15/50], Step [510/735], Loss: 0.1140\n",
      "Epoch [15/50], Step [511/735], Loss: 0.0909\n",
      "Epoch [15/50], Step [512/735], Loss: 0.2192\n",
      "Epoch [15/50], Step [513/735], Loss: 0.3352\n",
      "Epoch [15/50], Step [514/735], Loss: 0.2892\n",
      "Epoch [15/50], Step [515/735], Loss: 0.1132\n",
      "Epoch [15/50], Step [516/735], Loss: 0.1161\n",
      "Epoch [15/50], Step [517/735], Loss: 0.1518\n",
      "Epoch [15/50], Step [518/735], Loss: 0.2526\n",
      "Epoch [15/50], Step [519/735], Loss: 0.5988\n",
      "Epoch [15/50], Step [520/735], Loss: 0.1483\n",
      "Epoch [15/50], Step [521/735], Loss: 0.2405\n",
      "Epoch [15/50], Step [522/735], Loss: 0.0493\n",
      "Epoch [15/50], Step [523/735], Loss: 0.1902\n",
      "Epoch [15/50], Step [524/735], Loss: 0.1107\n",
      "Epoch [15/50], Step [525/735], Loss: 0.4869\n",
      "Epoch [15/50], Step [526/735], Loss: 0.0354\n",
      "Epoch [15/50], Step [527/735], Loss: 0.0600\n",
      "Epoch [15/50], Step [528/735], Loss: 0.3160\n",
      "Epoch [15/50], Step [529/735], Loss: 0.1621\n",
      "Epoch [15/50], Step [530/735], Loss: 0.2541\n",
      "Epoch [15/50], Step [531/735], Loss: 0.0739\n",
      "Epoch [15/50], Step [532/735], Loss: 0.4183\n",
      "Epoch [15/50], Step [533/735], Loss: 0.1399\n",
      "Epoch [15/50], Step [534/735], Loss: 0.0743\n",
      "Epoch [15/50], Step [535/735], Loss: 0.0844\n",
      "Epoch [15/50], Step [536/735], Loss: 0.1065\n",
      "Epoch [15/50], Step [537/735], Loss: 0.3017\n",
      "Epoch [15/50], Step [538/735], Loss: 0.1796\n",
      "Epoch [15/50], Step [539/735], Loss: 2.2968\n",
      "Epoch [15/50], Step [540/735], Loss: 0.3320\n",
      "Epoch [15/50], Step [541/735], Loss: 0.1148\n",
      "Epoch [15/50], Step [542/735], Loss: 0.1230\n",
      "Epoch [15/50], Step [543/735], Loss: 1.5822\n",
      "Epoch [15/50], Step [544/735], Loss: 0.2612\n",
      "Epoch [15/50], Step [545/735], Loss: 0.4936\n",
      "Epoch [15/50], Step [546/735], Loss: 0.4024\n",
      "Epoch [15/50], Step [547/735], Loss: 0.2099\n",
      "Epoch [15/50], Step [548/735], Loss: 0.0845\n",
      "Epoch [15/50], Step [549/735], Loss: 0.0741\n",
      "Epoch [15/50], Step [550/735], Loss: 0.4570\n",
      "Epoch [15/50], Step [551/735], Loss: 0.4277\n",
      "Epoch [15/50], Step [552/735], Loss: 0.3657\n",
      "Epoch [15/50], Step [553/735], Loss: 0.1470\n",
      "Epoch [15/50], Step [554/735], Loss: 0.4317\n",
      "Epoch [15/50], Step [555/735], Loss: 0.1844\n",
      "Epoch [15/50], Step [556/735], Loss: 0.0916\n",
      "Epoch [15/50], Step [557/735], Loss: 0.1455\n",
      "Epoch [15/50], Step [558/735], Loss: 0.2051\n",
      "Epoch [15/50], Step [559/735], Loss: 1.0445\n",
      "Epoch [15/50], Step [560/735], Loss: 0.0404\n",
      "Epoch [15/50], Step [561/735], Loss: 0.3015\n",
      "Epoch [15/50], Step [562/735], Loss: 0.0992\n",
      "Epoch [15/50], Step [563/735], Loss: 0.2592\n",
      "Epoch [15/50], Step [564/735], Loss: 0.0879\n",
      "Epoch [15/50], Step [565/735], Loss: 0.4392\n",
      "Epoch [15/50], Step [566/735], Loss: 0.0431\n",
      "Epoch [15/50], Step [567/735], Loss: 0.1355\n",
      "Epoch [15/50], Step [568/735], Loss: 0.1709\n",
      "Epoch [15/50], Step [569/735], Loss: 0.0602\n",
      "Epoch [15/50], Step [570/735], Loss: 0.1111\n",
      "Epoch [15/50], Step [571/735], Loss: 0.1482\n",
      "Epoch [15/50], Step [572/735], Loss: 0.1384\n",
      "Epoch [15/50], Step [573/735], Loss: 0.2374\n",
      "Epoch [15/50], Step [574/735], Loss: 0.1610\n",
      "Epoch [15/50], Step [575/735], Loss: 0.7813\n",
      "Epoch [15/50], Step [576/735], Loss: 0.1042\n",
      "Epoch [15/50], Step [577/735], Loss: 0.1653\n",
      "Epoch [15/50], Step [578/735], Loss: 0.0911\n",
      "Epoch [15/50], Step [579/735], Loss: 0.2234\n",
      "Epoch [15/50], Step [580/735], Loss: 0.1281\n",
      "Epoch [15/50], Step [581/735], Loss: 0.1534\n",
      "Epoch [15/50], Step [582/735], Loss: 0.1756\n",
      "Epoch [15/50], Step [583/735], Loss: 0.3592\n",
      "Epoch [15/50], Step [584/735], Loss: 0.2244\n",
      "Epoch [15/50], Step [585/735], Loss: 0.1952\n",
      "Epoch [15/50], Step [586/735], Loss: 0.1487\n",
      "Epoch [15/50], Step [587/735], Loss: 0.3661\n",
      "Epoch [15/50], Step [588/735], Loss: 0.1393\n",
      "Epoch [15/50], Step [589/735], Loss: 0.0632\n",
      "Epoch [15/50], Step [590/735], Loss: 0.3594\n",
      "Epoch [15/50], Step [591/735], Loss: 0.1952\n",
      "Epoch [15/50], Step [592/735], Loss: 0.0516\n",
      "Epoch [15/50], Step [593/735], Loss: 0.4997\n",
      "Epoch [15/50], Step [594/735], Loss: 0.1095\n",
      "Epoch [15/50], Step [595/735], Loss: 0.1598\n",
      "Epoch [15/50], Step [596/735], Loss: 0.0858\n",
      "Epoch [15/50], Step [597/735], Loss: 0.1673\n",
      "Epoch [15/50], Step [598/735], Loss: 0.0941\n",
      "Epoch [15/50], Step [599/735], Loss: 0.1181\n",
      "Epoch [15/50], Step [600/735], Loss: 0.0641\n",
      "Epoch [15/50], Step [601/735], Loss: 0.1975\n",
      "Epoch [15/50], Step [602/735], Loss: 0.2620\n",
      "Epoch [15/50], Step [603/735], Loss: 0.0650\n",
      "Epoch [15/50], Step [604/735], Loss: 0.1092\n",
      "Epoch [15/50], Step [605/735], Loss: 0.2420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Step [606/735], Loss: 0.2162\n",
      "Epoch [15/50], Step [607/735], Loss: 2.0516\n",
      "Epoch [15/50], Step [608/735], Loss: 0.1346\n",
      "Epoch [15/50], Step [609/735], Loss: 0.3218\n",
      "Epoch [15/50], Step [610/735], Loss: 1.9662\n",
      "Epoch [15/50], Step [611/735], Loss: 0.0281\n",
      "Epoch [15/50], Step [612/735], Loss: 0.2029\n",
      "Epoch [15/50], Step [613/735], Loss: 0.0752\n",
      "Epoch [15/50], Step [614/735], Loss: 1.0496\n",
      "Epoch [15/50], Step [615/735], Loss: 0.3168\n",
      "Epoch [15/50], Step [616/735], Loss: 0.3174\n",
      "Epoch [15/50], Step [617/735], Loss: 0.2444\n",
      "Epoch [15/50], Step [618/735], Loss: 1.3803\n",
      "Epoch [15/50], Step [619/735], Loss: 0.0372\n",
      "Epoch [15/50], Step [620/735], Loss: 0.3047\n",
      "Epoch [15/50], Step [621/735], Loss: 0.1376\n",
      "Epoch [15/50], Step [622/735], Loss: 0.1305\n",
      "Epoch [15/50], Step [623/735], Loss: 0.2748\n",
      "Epoch [15/50], Step [624/735], Loss: 0.2884\n",
      "Epoch [15/50], Step [625/735], Loss: 0.2488\n",
      "Epoch [15/50], Step [626/735], Loss: 0.2748\n",
      "Epoch [15/50], Step [627/735], Loss: 0.0836\n",
      "Epoch [15/50], Step [628/735], Loss: 0.1720\n",
      "Epoch [15/50], Step [629/735], Loss: 0.3487\n",
      "Epoch [15/50], Step [630/735], Loss: 0.1414\n",
      "Epoch [15/50], Step [631/735], Loss: 0.2600\n",
      "Epoch [15/50], Step [632/735], Loss: 0.2363\n",
      "Epoch [15/50], Step [633/735], Loss: 0.0400\n",
      "Epoch [15/50], Step [634/735], Loss: 0.1330\n",
      "Epoch [15/50], Step [635/735], Loss: 0.0883\n",
      "Epoch [15/50], Step [636/735], Loss: 0.0623\n",
      "Epoch [15/50], Step [637/735], Loss: 0.1896\n",
      "Epoch [15/50], Step [638/735], Loss: 0.3027\n",
      "Epoch [15/50], Step [639/735], Loss: 0.1405\n",
      "Epoch [15/50], Step [640/735], Loss: 0.0754\n",
      "Epoch [15/50], Step [641/735], Loss: 0.8016\n",
      "Epoch [15/50], Step [642/735], Loss: 0.0676\n",
      "Epoch [15/50], Step [643/735], Loss: 0.2543\n",
      "Epoch [15/50], Step [644/735], Loss: 0.1383\n",
      "Epoch [15/50], Step [645/735], Loss: 0.1600\n",
      "Epoch [15/50], Step [646/735], Loss: 0.1225\n",
      "Epoch [15/50], Step [647/735], Loss: 0.3608\n",
      "Epoch [15/50], Step [648/735], Loss: 0.0946\n",
      "Epoch [15/50], Step [649/735], Loss: 0.1034\n",
      "Epoch [15/50], Step [650/735], Loss: 0.1306\n",
      "Epoch [15/50], Step [651/735], Loss: 0.1799\n",
      "Epoch [15/50], Step [652/735], Loss: 0.2704\n",
      "Epoch [15/50], Step [653/735], Loss: 0.1298\n",
      "Epoch [15/50], Step [654/735], Loss: 0.1199\n",
      "Epoch [15/50], Step [655/735], Loss: 0.2114\n",
      "Epoch [15/50], Step [656/735], Loss: 0.0550\n",
      "Epoch [15/50], Step [657/735], Loss: 0.1072\n",
      "Epoch [15/50], Step [658/735], Loss: 0.1947\n",
      "Epoch [15/50], Step [659/735], Loss: 0.1364\n",
      "Epoch [15/50], Step [660/735], Loss: 0.1208\n",
      "Epoch [15/50], Step [661/735], Loss: 0.5969\n",
      "Epoch [15/50], Step [662/735], Loss: 0.2379\n",
      "Epoch [15/50], Step [663/735], Loss: 0.1426\n",
      "Epoch [15/50], Step [664/735], Loss: 0.1064\n",
      "Epoch [15/50], Step [665/735], Loss: 0.2305\n",
      "Epoch [15/50], Step [666/735], Loss: 0.0745\n",
      "Epoch [15/50], Step [667/735], Loss: 0.0490\n",
      "Epoch [15/50], Step [668/735], Loss: 0.1167\n",
      "Epoch [15/50], Step [669/735], Loss: 0.1019\n",
      "Epoch [15/50], Step [670/735], Loss: 0.1150\n",
      "Epoch [15/50], Step [671/735], Loss: 0.1689\n",
      "Epoch [15/50], Step [672/735], Loss: 0.0645\n",
      "Epoch [15/50], Step [673/735], Loss: 0.1309\n",
      "Epoch [15/50], Step [674/735], Loss: 0.1060\n",
      "Epoch [15/50], Step [675/735], Loss: 0.1196\n",
      "Epoch [15/50], Step [676/735], Loss: 0.1225\n",
      "Epoch [15/50], Step [677/735], Loss: 0.1347\n",
      "Epoch [15/50], Step [678/735], Loss: 0.0787\n",
      "Epoch [15/50], Step [679/735], Loss: 0.0943\n",
      "Epoch [15/50], Step [680/735], Loss: 0.1117\n",
      "Epoch [15/50], Step [681/735], Loss: 0.0974\n",
      "Epoch [15/50], Step [682/735], Loss: 0.0591\n",
      "Epoch [15/50], Step [683/735], Loss: 0.1329\n",
      "Epoch [15/50], Step [684/735], Loss: 0.1322\n",
      "Epoch [15/50], Step [685/735], Loss: 0.0484\n",
      "Epoch [15/50], Step [686/735], Loss: 0.3199\n",
      "Epoch [15/50], Step [687/735], Loss: 0.1283\n",
      "Epoch [15/50], Step [688/735], Loss: 0.1949\n",
      "Epoch [15/50], Step [689/735], Loss: 0.1214\n",
      "Epoch [15/50], Step [690/735], Loss: 0.1224\n",
      "Epoch [15/50], Step [691/735], Loss: 0.0780\n",
      "Epoch [15/50], Step [692/735], Loss: 0.1851\n",
      "Epoch [15/50], Step [693/735], Loss: 0.1772\n",
      "Epoch [15/50], Step [694/735], Loss: 0.1268\n",
      "Epoch [15/50], Step [695/735], Loss: 0.0711\n",
      "Epoch [15/50], Step [696/735], Loss: 0.0834\n",
      "Epoch [15/50], Step [697/735], Loss: 0.1014\n",
      "Epoch [15/50], Step [698/735], Loss: 0.0968\n",
      "Epoch [15/50], Step [699/735], Loss: 0.6274\n",
      "Epoch [15/50], Step [700/735], Loss: 0.5988\n",
      "Epoch [15/50], Step [701/735], Loss: 0.1027\n",
      "Epoch [15/50], Step [702/735], Loss: 0.0857\n",
      "Epoch [15/50], Step [703/735], Loss: 0.1817\n",
      "Epoch [15/50], Step [704/735], Loss: 0.0839\n",
      "Epoch [15/50], Step [705/735], Loss: 0.2062\n",
      "Epoch [15/50], Step [706/735], Loss: 0.0916\n",
      "Epoch [15/50], Step [707/735], Loss: 0.1207\n",
      "Epoch [15/50], Step [708/735], Loss: 0.2456\n",
      "Epoch [15/50], Step [709/735], Loss: 0.0518\n",
      "Epoch [15/50], Step [710/735], Loss: 0.2647\n",
      "Epoch [15/50], Step [711/735], Loss: 0.1295\n",
      "Epoch [15/50], Step [712/735], Loss: 0.1752\n",
      "Epoch [15/50], Step [713/735], Loss: 0.2873\n",
      "Epoch [15/50], Step [714/735], Loss: 0.2282\n",
      "Epoch [15/50], Step [715/735], Loss: 1.1821\n",
      "Epoch [15/50], Step [716/735], Loss: 0.3121\n",
      "Epoch [15/50], Step [717/735], Loss: 0.2420\n",
      "Epoch [15/50], Step [718/735], Loss: 0.0917\n",
      "Epoch [15/50], Step [719/735], Loss: 0.0567\n",
      "Epoch [15/50], Step [720/735], Loss: 0.2464\n",
      "Epoch [15/50], Step [721/735], Loss: 0.0937\n",
      "Epoch [15/50], Step [722/735], Loss: 0.1913\n",
      "Epoch [15/50], Step [723/735], Loss: 0.0812\n",
      "Epoch [15/50], Step [724/735], Loss: 0.3376\n",
      "Epoch [15/50], Step [725/735], Loss: 0.1808\n",
      "Epoch [15/50], Step [726/735], Loss: 0.3243\n",
      "Epoch [15/50], Step [727/735], Loss: 0.2367\n",
      "Epoch [15/50], Step [728/735], Loss: 0.1242\n",
      "Epoch [15/50], Step [729/735], Loss: 1.1706\n",
      "Epoch [15/50], Step [730/735], Loss: 0.2297\n",
      "Epoch [15/50], Step [731/735], Loss: 0.0880\n",
      "Epoch [15/50], Step [732/735], Loss: 0.0498\n",
      "Epoch [15/50], Step [733/735], Loss: 0.0769\n",
      "Epoch [15/50], Step [734/735], Loss: 0.1573\n",
      "Epoch [15/50], Step [735/735], Loss: 0.1967\n",
      "Epoch [16/50], Step [1/735], Loss: 0.1412\n",
      "Epoch [16/50], Step [2/735], Loss: 0.3245\n",
      "Epoch [16/50], Step [3/735], Loss: 0.0927\n",
      "Epoch [16/50], Step [4/735], Loss: 0.1479\n",
      "Epoch [16/50], Step [5/735], Loss: 0.1463\n",
      "Epoch [16/50], Step [6/735], Loss: 0.1293\n",
      "Epoch [16/50], Step [7/735], Loss: 0.2476\n",
      "Epoch [16/50], Step [8/735], Loss: 0.1368\n",
      "Epoch [16/50], Step [9/735], Loss: 0.1189\n",
      "Epoch [16/50], Step [10/735], Loss: 0.2428\n",
      "Epoch [16/50], Step [11/735], Loss: 0.2326\n",
      "Epoch [16/50], Step [12/735], Loss: 0.4542\n",
      "Epoch [16/50], Step [13/735], Loss: 0.1543\n",
      "Epoch [16/50], Step [14/735], Loss: 0.3623\n",
      "Epoch [16/50], Step [15/735], Loss: 0.4196\n",
      "Epoch [16/50], Step [16/735], Loss: 0.0848\n",
      "Epoch [16/50], Step [17/735], Loss: 0.1574\n",
      "Epoch [16/50], Step [18/735], Loss: 0.2411\n",
      "Epoch [16/50], Step [19/735], Loss: 0.2152\n",
      "Epoch [16/50], Step [20/735], Loss: 0.1086\n",
      "Epoch [16/50], Step [21/735], Loss: 0.1856\n",
      "Epoch [16/50], Step [22/735], Loss: 0.0727\n",
      "Epoch [16/50], Step [23/735], Loss: 0.0513\n",
      "Epoch [16/50], Step [24/735], Loss: 0.1504\n",
      "Epoch [16/50], Step [25/735], Loss: 0.2305\n",
      "Epoch [16/50], Step [26/735], Loss: 0.1593\n",
      "Epoch [16/50], Step [27/735], Loss: 0.0749\n",
      "Epoch [16/50], Step [28/735], Loss: 0.1564\n",
      "Epoch [16/50], Step [29/735], Loss: 0.2257\n",
      "Epoch [16/50], Step [30/735], Loss: 0.1515\n",
      "Epoch [16/50], Step [31/735], Loss: 0.0849\n",
      "Epoch [16/50], Step [32/735], Loss: 0.0721\n",
      "Epoch [16/50], Step [33/735], Loss: 0.0473\n",
      "Epoch [16/50], Step [34/735], Loss: 0.2962\n",
      "Epoch [16/50], Step [35/735], Loss: 0.1658\n",
      "Epoch [16/50], Step [36/735], Loss: 0.0515\n",
      "Epoch [16/50], Step [37/735], Loss: 0.0449\n",
      "Epoch [16/50], Step [38/735], Loss: 0.0348\n",
      "Epoch [16/50], Step [39/735], Loss: 0.4152\n",
      "Epoch [16/50], Step [40/735], Loss: 0.2119\n",
      "Epoch [16/50], Step [41/735], Loss: 0.0832\n",
      "Epoch [16/50], Step [42/735], Loss: 0.0826\n",
      "Epoch [16/50], Step [43/735], Loss: 2.7455\n",
      "Epoch [16/50], Step [44/735], Loss: 0.1103\n",
      "Epoch [16/50], Step [45/735], Loss: 0.1242\n",
      "Epoch [16/50], Step [46/735], Loss: 0.5948\n",
      "Epoch [16/50], Step [47/735], Loss: 0.0831\n",
      "Epoch [16/50], Step [48/735], Loss: 0.1496\n",
      "Epoch [16/50], Step [49/735], Loss: 0.1007\n",
      "Epoch [16/50], Step [50/735], Loss: 0.1926\n",
      "Epoch [16/50], Step [51/735], Loss: 0.2145\n",
      "Epoch [16/50], Step [52/735], Loss: 0.1658\n",
      "Epoch [16/50], Step [53/735], Loss: 0.0862\n",
      "Epoch [16/50], Step [54/735], Loss: 0.2243\n",
      "Epoch [16/50], Step [55/735], Loss: 0.1991\n",
      "Epoch [16/50], Step [56/735], Loss: 0.1198\n",
      "Epoch [16/50], Step [57/735], Loss: 0.2713\n",
      "Epoch [16/50], Step [58/735], Loss: 0.1718\n",
      "Epoch [16/50], Step [59/735], Loss: 0.1300\n",
      "Epoch [16/50], Step [60/735], Loss: 0.2414\n",
      "Epoch [16/50], Step [61/735], Loss: 0.2913\n",
      "Epoch [16/50], Step [62/735], Loss: 0.2390\n",
      "Epoch [16/50], Step [63/735], Loss: 0.3079\n",
      "Epoch [16/50], Step [64/735], Loss: 0.3166\n",
      "Epoch [16/50], Step [65/735], Loss: 0.1322\n",
      "Epoch [16/50], Step [66/735], Loss: 0.0783\n",
      "Epoch [16/50], Step [67/735], Loss: 1.0316\n",
      "Epoch [16/50], Step [68/735], Loss: 0.1086\n",
      "Epoch [16/50], Step [69/735], Loss: 0.1913\n",
      "Epoch [16/50], Step [70/735], Loss: 0.2358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Step [71/735], Loss: 0.1092\n",
      "Epoch [16/50], Step [72/735], Loss: 0.2207\n",
      "Epoch [16/50], Step [73/735], Loss: 0.3647\n",
      "Epoch [16/50], Step [74/735], Loss: 0.0691\n",
      "Epoch [16/50], Step [75/735], Loss: 0.0781\n",
      "Epoch [16/50], Step [76/735], Loss: 0.1499\n",
      "Epoch [16/50], Step [77/735], Loss: 0.0939\n",
      "Epoch [16/50], Step [78/735], Loss: 0.4574\n",
      "Epoch [16/50], Step [79/735], Loss: 0.1286\n",
      "Epoch [16/50], Step [80/735], Loss: 0.1010\n",
      "Epoch [16/50], Step [81/735], Loss: 0.1089\n",
      "Epoch [16/50], Step [82/735], Loss: 0.5005\n",
      "Epoch [16/50], Step [83/735], Loss: 0.1250\n",
      "Epoch [16/50], Step [84/735], Loss: 0.2693\n",
      "Epoch [16/50], Step [85/735], Loss: 0.0456\n",
      "Epoch [16/50], Step [86/735], Loss: 0.1008\n",
      "Epoch [16/50], Step [87/735], Loss: 0.1728\n",
      "Epoch [16/50], Step [88/735], Loss: 0.1774\n",
      "Epoch [16/50], Step [89/735], Loss: 0.1455\n",
      "Epoch [16/50], Step [90/735], Loss: 1.0339\n",
      "Epoch [16/50], Step [91/735], Loss: 0.1026\n",
      "Epoch [16/50], Step [92/735], Loss: 0.1078\n",
      "Epoch [16/50], Step [93/735], Loss: 0.2351\n",
      "Epoch [16/50], Step [94/735], Loss: 0.0770\n",
      "Epoch [16/50], Step [95/735], Loss: 0.0881\n",
      "Epoch [16/50], Step [96/735], Loss: 0.0947\n",
      "Epoch [16/50], Step [97/735], Loss: 0.0879\n",
      "Epoch [16/50], Step [98/735], Loss: 0.1580\n",
      "Epoch [16/50], Step [99/735], Loss: 0.2405\n",
      "Epoch [16/50], Step [100/735], Loss: 0.0841\n",
      "Epoch [16/50], Step [101/735], Loss: 0.1069\n",
      "Epoch [16/50], Step [102/735], Loss: 0.0999\n",
      "Epoch [16/50], Step [103/735], Loss: 0.1007\n",
      "Epoch [16/50], Step [104/735], Loss: 0.1227\n",
      "Epoch [16/50], Step [105/735], Loss: 0.1455\n",
      "Epoch [16/50], Step [106/735], Loss: 0.1363\n",
      "Epoch [16/50], Step [107/735], Loss: 0.1361\n",
      "Epoch [16/50], Step [108/735], Loss: 0.1217\n",
      "Epoch [16/50], Step [109/735], Loss: 0.1003\n",
      "Epoch [16/50], Step [110/735], Loss: 0.2476\n",
      "Epoch [16/50], Step [111/735], Loss: 0.0619\n",
      "Epoch [16/50], Step [112/735], Loss: 0.1084\n",
      "Epoch [16/50], Step [113/735], Loss: 0.0617\n",
      "Epoch [16/50], Step [114/735], Loss: 0.1408\n",
      "Epoch [16/50], Step [115/735], Loss: 0.1117\n",
      "Epoch [16/50], Step [116/735], Loss: 0.1156\n",
      "Epoch [16/50], Step [117/735], Loss: 0.3597\n",
      "Epoch [16/50], Step [118/735], Loss: 0.1353\n",
      "Epoch [16/50], Step [119/735], Loss: 0.0574\n",
      "Epoch [16/50], Step [120/735], Loss: 0.1205\n",
      "Epoch [16/50], Step [121/735], Loss: 0.4030\n",
      "Epoch [16/50], Step [122/735], Loss: 0.1619\n",
      "Epoch [16/50], Step [123/735], Loss: 0.0479\n",
      "Epoch [16/50], Step [124/735], Loss: 0.0809\n",
      "Epoch [16/50], Step [125/735], Loss: 0.0781\n",
      "Epoch [16/50], Step [126/735], Loss: 0.1137\n",
      "Epoch [16/50], Step [127/735], Loss: 0.1041\n",
      "Epoch [16/50], Step [128/735], Loss: 0.0572\n",
      "Epoch [16/50], Step [129/735], Loss: 0.0561\n",
      "Epoch [16/50], Step [130/735], Loss: 0.1814\n",
      "Epoch [16/50], Step [131/735], Loss: 0.2199\n",
      "Epoch [16/50], Step [132/735], Loss: 0.1097\n",
      "Epoch [16/50], Step [133/735], Loss: 0.2944\n",
      "Epoch [16/50], Step [134/735], Loss: 0.1910\n",
      "Epoch [16/50], Step [135/735], Loss: 0.8011\n",
      "Epoch [16/50], Step [136/735], Loss: 0.2359\n",
      "Epoch [16/50], Step [137/735], Loss: 0.0703\n",
      "Epoch [16/50], Step [138/735], Loss: 0.0630\n",
      "Epoch [16/50], Step [139/735], Loss: 0.1271\n",
      "Epoch [16/50], Step [140/735], Loss: 0.1270\n",
      "Epoch [16/50], Step [141/735], Loss: 0.0809\n",
      "Epoch [16/50], Step [142/735], Loss: 0.1339\n",
      "Epoch [16/50], Step [143/735], Loss: 0.1682\n",
      "Epoch [16/50], Step [144/735], Loss: 0.3416\n",
      "Epoch [16/50], Step [145/735], Loss: 0.0494\n",
      "Epoch [16/50], Step [146/735], Loss: 0.4139\n",
      "Epoch [16/50], Step [147/735], Loss: 0.1210\n",
      "Epoch [16/50], Step [148/735], Loss: 0.0733\n",
      "Epoch [16/50], Step [149/735], Loss: 0.0537\n",
      "Epoch [16/50], Step [150/735], Loss: 0.0839\n",
      "Epoch [16/50], Step [151/735], Loss: 0.2101\n",
      "Epoch [16/50], Step [152/735], Loss: 0.1864\n",
      "Epoch [16/50], Step [153/735], Loss: 0.1314\n",
      "Epoch [16/50], Step [154/735], Loss: 0.0496\n",
      "Epoch [16/50], Step [155/735], Loss: 0.0670\n",
      "Epoch [16/50], Step [156/735], Loss: 0.1360\n",
      "Epoch [16/50], Step [157/735], Loss: 0.2521\n",
      "Epoch [16/50], Step [158/735], Loss: 0.1495\n",
      "Epoch [16/50], Step [159/735], Loss: 0.1532\n",
      "Epoch [16/50], Step [160/735], Loss: 0.0851\n",
      "Epoch [16/50], Step [161/735], Loss: 0.0429\n",
      "Epoch [16/50], Step [162/735], Loss: 0.4207\n",
      "Epoch [16/50], Step [163/735], Loss: 0.0818\n",
      "Epoch [16/50], Step [164/735], Loss: 0.0994\n",
      "Epoch [16/50], Step [165/735], Loss: 0.1254\n",
      "Epoch [16/50], Step [166/735], Loss: 0.1017\n",
      "Epoch [16/50], Step [167/735], Loss: 0.1537\n",
      "Epoch [16/50], Step [168/735], Loss: 1.4373\n",
      "Epoch [16/50], Step [169/735], Loss: 0.0849\n",
      "Epoch [16/50], Step [170/735], Loss: 0.1760\n",
      "Epoch [16/50], Step [171/735], Loss: 0.0810\n",
      "Epoch [16/50], Step [172/735], Loss: 0.1235\n",
      "Epoch [16/50], Step [173/735], Loss: 0.1637\n",
      "Epoch [16/50], Step [174/735], Loss: 0.0585\n",
      "Epoch [16/50], Step [175/735], Loss: 0.0990\n",
      "Epoch [16/50], Step [176/735], Loss: 0.0885\n",
      "Epoch [16/50], Step [177/735], Loss: 0.1109\n",
      "Epoch [16/50], Step [178/735], Loss: 0.0605\n",
      "Epoch [16/50], Step [179/735], Loss: 0.2848\n",
      "Epoch [16/50], Step [180/735], Loss: 0.4057\n",
      "Epoch [16/50], Step [181/735], Loss: 0.1158\n",
      "Epoch [16/50], Step [182/735], Loss: 0.2205\n",
      "Epoch [16/50], Step [183/735], Loss: 0.0522\n",
      "Epoch [16/50], Step [184/735], Loss: 0.3127\n",
      "Epoch [16/50], Step [185/735], Loss: 0.0714\n",
      "Epoch [16/50], Step [186/735], Loss: 0.1073\n",
      "Epoch [16/50], Step [187/735], Loss: 0.1216\n",
      "Epoch [16/50], Step [188/735], Loss: 0.2470\n",
      "Epoch [16/50], Step [189/735], Loss: 1.2496\n",
      "Epoch [16/50], Step [190/735], Loss: 0.4832\n",
      "Epoch [16/50], Step [191/735], Loss: 0.0772\n",
      "Epoch [16/50], Step [192/735], Loss: 0.1664\n",
      "Epoch [16/50], Step [193/735], Loss: 0.0567\n",
      "Epoch [16/50], Step [194/735], Loss: 0.0884\n",
      "Epoch [16/50], Step [195/735], Loss: 0.2282\n",
      "Epoch [16/50], Step [196/735], Loss: 0.3397\n",
      "Epoch [16/50], Step [197/735], Loss: 0.3688\n",
      "Epoch [16/50], Step [198/735], Loss: 0.4004\n",
      "Epoch [16/50], Step [199/735], Loss: 0.3026\n",
      "Epoch [16/50], Step [200/735], Loss: 0.0515\n",
      "Epoch [16/50], Step [201/735], Loss: 0.1717\n",
      "Epoch [16/50], Step [202/735], Loss: 0.1379\n",
      "Epoch [16/50], Step [203/735], Loss: 0.0582\n",
      "Epoch [16/50], Step [204/735], Loss: 0.1662\n",
      "Epoch [16/50], Step [205/735], Loss: 0.0439\n",
      "Epoch [16/50], Step [206/735], Loss: 0.2523\n",
      "Epoch [16/50], Step [207/735], Loss: 0.0900\n",
      "Epoch [16/50], Step [208/735], Loss: 0.2281\n",
      "Epoch [16/50], Step [209/735], Loss: 0.3569\n",
      "Epoch [16/50], Step [210/735], Loss: 0.2194\n",
      "Epoch [16/50], Step [211/735], Loss: 0.0367\n",
      "Epoch [16/50], Step [212/735], Loss: 0.1407\n",
      "Epoch [16/50], Step [213/735], Loss: 0.2193\n",
      "Epoch [16/50], Step [214/735], Loss: 0.1982\n",
      "Epoch [16/50], Step [215/735], Loss: 0.1552\n",
      "Epoch [16/50], Step [216/735], Loss: 0.1913\n",
      "Epoch [16/50], Step [217/735], Loss: 0.0722\n",
      "Epoch [16/50], Step [218/735], Loss: 0.0400\n",
      "Epoch [16/50], Step [219/735], Loss: 0.3954\n",
      "Epoch [16/50], Step [220/735], Loss: 0.3627\n",
      "Epoch [16/50], Step [221/735], Loss: 0.2133\n",
      "Epoch [16/50], Step [222/735], Loss: 0.1377\n",
      "Epoch [16/50], Step [223/735], Loss: 0.2755\n",
      "Epoch [16/50], Step [224/735], Loss: 0.1873\n",
      "Epoch [16/50], Step [225/735], Loss: 0.2265\n",
      "Epoch [16/50], Step [226/735], Loss: 0.0408\n",
      "Epoch [16/50], Step [227/735], Loss: 0.1131\n",
      "Epoch [16/50], Step [228/735], Loss: 0.0728\n",
      "Epoch [16/50], Step [229/735], Loss: 0.2142\n",
      "Epoch [16/50], Step [230/735], Loss: 0.0638\n",
      "Epoch [16/50], Step [231/735], Loss: 0.3410\n",
      "Epoch [16/50], Step [232/735], Loss: 0.1015\n",
      "Epoch [16/50], Step [233/735], Loss: 0.1591\n",
      "Epoch [16/50], Step [234/735], Loss: 0.2011\n",
      "Epoch [16/50], Step [235/735], Loss: 0.3946\n",
      "Epoch [16/50], Step [236/735], Loss: 0.0550\n",
      "Epoch [16/50], Step [237/735], Loss: 0.1192\n",
      "Epoch [16/50], Step [238/735], Loss: 0.3902\n",
      "Epoch [16/50], Step [239/735], Loss: 0.1108\n",
      "Epoch [16/50], Step [240/735], Loss: 0.1687\n",
      "Epoch [16/50], Step [241/735], Loss: 0.0428\n",
      "Epoch [16/50], Step [242/735], Loss: 0.1431\n",
      "Epoch [16/50], Step [243/735], Loss: 0.0514\n",
      "Epoch [16/50], Step [244/735], Loss: 0.1740\n",
      "Epoch [16/50], Step [245/735], Loss: 0.1294\n",
      "Epoch [16/50], Step [246/735], Loss: 0.0651\n",
      "Epoch [16/50], Step [247/735], Loss: 0.0979\n",
      "Epoch [16/50], Step [248/735], Loss: 0.1384\n",
      "Epoch [16/50], Step [249/735], Loss: 0.2769\n",
      "Epoch [16/50], Step [250/735], Loss: 0.1498\n",
      "Epoch [16/50], Step [251/735], Loss: 0.0738\n",
      "Epoch [16/50], Step [252/735], Loss: 0.0841\n",
      "Epoch [16/50], Step [253/735], Loss: 0.0709\n",
      "Epoch [16/50], Step [254/735], Loss: 0.1694\n",
      "Epoch [16/50], Step [255/735], Loss: 0.3717\n",
      "Epoch [16/50], Step [256/735], Loss: 0.2158\n",
      "Epoch [16/50], Step [257/735], Loss: 0.2263\n",
      "Epoch [16/50], Step [258/735], Loss: 0.0519\n",
      "Epoch [16/50], Step [259/735], Loss: 0.2814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Step [260/735], Loss: 0.3526\n",
      "Epoch [16/50], Step [261/735], Loss: 0.1322\n",
      "Epoch [16/50], Step [262/735], Loss: 0.1537\n",
      "Epoch [16/50], Step [263/735], Loss: 2.2854\n",
      "Epoch [16/50], Step [264/735], Loss: 0.1658\n",
      "Epoch [16/50], Step [265/735], Loss: 0.2353\n",
      "Epoch [16/50], Step [266/735], Loss: 0.2028\n",
      "Epoch [16/50], Step [267/735], Loss: 0.0493\n",
      "Epoch [16/50], Step [268/735], Loss: 0.1548\n",
      "Epoch [16/50], Step [269/735], Loss: 0.0949\n",
      "Epoch [16/50], Step [270/735], Loss: 0.1452\n",
      "Epoch [16/50], Step [271/735], Loss: 0.1517\n",
      "Epoch [16/50], Step [272/735], Loss: 0.1562\n",
      "Epoch [16/50], Step [273/735], Loss: 0.1633\n",
      "Epoch [16/50], Step [274/735], Loss: 0.2040\n",
      "Epoch [16/50], Step [275/735], Loss: 0.1511\n",
      "Epoch [16/50], Step [276/735], Loss: 0.0627\n",
      "Epoch [16/50], Step [277/735], Loss: 0.1998\n",
      "Epoch [16/50], Step [278/735], Loss: 1.7106\n",
      "Epoch [16/50], Step [279/735], Loss: 0.5476\n",
      "Epoch [16/50], Step [280/735], Loss: 0.2654\n",
      "Epoch [16/50], Step [281/735], Loss: 0.1974\n",
      "Epoch [16/50], Step [282/735], Loss: 0.0934\n",
      "Epoch [16/50], Step [283/735], Loss: 0.1776\n",
      "Epoch [16/50], Step [284/735], Loss: 0.1851\n",
      "Epoch [16/50], Step [285/735], Loss: 0.3365\n",
      "Epoch [16/50], Step [286/735], Loss: 0.1037\n",
      "Epoch [16/50], Step [287/735], Loss: 0.2580\n",
      "Epoch [16/50], Step [288/735], Loss: 0.1799\n",
      "Epoch [16/50], Step [289/735], Loss: 0.0341\n",
      "Epoch [16/50], Step [290/735], Loss: 0.2715\n",
      "Epoch [16/50], Step [291/735], Loss: 0.1635\n",
      "Epoch [16/50], Step [292/735], Loss: 0.1920\n",
      "Epoch [16/50], Step [293/735], Loss: 0.1296\n",
      "Epoch [16/50], Step [294/735], Loss: 0.2744\n",
      "Epoch [16/50], Step [295/735], Loss: 0.1493\n",
      "Epoch [16/50], Step [296/735], Loss: 0.1422\n",
      "Epoch [16/50], Step [297/735], Loss: 0.1704\n",
      "Epoch [16/50], Step [298/735], Loss: 0.2640\n",
      "Epoch [16/50], Step [299/735], Loss: 0.2756\n",
      "Epoch [16/50], Step [300/735], Loss: 0.0992\n",
      "Epoch [16/50], Step [301/735], Loss: 0.1919\n",
      "Epoch [16/50], Step [302/735], Loss: 0.1185\n",
      "Epoch [16/50], Step [303/735], Loss: 0.1724\n",
      "Epoch [16/50], Step [304/735], Loss: 0.3437\n",
      "Epoch [16/50], Step [305/735], Loss: 0.1041\n",
      "Epoch [16/50], Step [306/735], Loss: 0.1018\n",
      "Epoch [16/50], Step [307/735], Loss: 0.2037\n",
      "Epoch [16/50], Step [308/735], Loss: 0.1188\n",
      "Epoch [16/50], Step [309/735], Loss: 0.1527\n",
      "Epoch [16/50], Step [310/735], Loss: 0.1446\n",
      "Epoch [16/50], Step [311/735], Loss: 0.0756\n",
      "Epoch [16/50], Step [312/735], Loss: 0.1739\n",
      "Epoch [16/50], Step [313/735], Loss: 0.2803\n",
      "Epoch [16/50], Step [314/735], Loss: 0.1178\n",
      "Epoch [16/50], Step [315/735], Loss: 0.1435\n",
      "Epoch [16/50], Step [316/735], Loss: 0.0939\n",
      "Epoch [16/50], Step [317/735], Loss: 0.1529\n",
      "Epoch [16/50], Step [318/735], Loss: 0.0452\n",
      "Epoch [16/50], Step [319/735], Loss: 0.1690\n",
      "Epoch [16/50], Step [320/735], Loss: 0.0439\n",
      "Epoch [16/50], Step [321/735], Loss: 0.1682\n",
      "Epoch [16/50], Step [322/735], Loss: 0.0784\n",
      "Epoch [16/50], Step [323/735], Loss: 0.2959\n",
      "Epoch [16/50], Step [324/735], Loss: 1.4913\n",
      "Epoch [16/50], Step [325/735], Loss: 0.1688\n",
      "Epoch [16/50], Step [326/735], Loss: 0.2696\n",
      "Epoch [16/50], Step [327/735], Loss: 0.2556\n",
      "Epoch [16/50], Step [328/735], Loss: 0.1063\n",
      "Epoch [16/50], Step [329/735], Loss: 0.1920\n",
      "Epoch [16/50], Step [330/735], Loss: 0.1319\n",
      "Epoch [16/50], Step [331/735], Loss: 0.1990\n",
      "Epoch [16/50], Step [332/735], Loss: 0.2179\n",
      "Epoch [16/50], Step [333/735], Loss: 0.1274\n",
      "Epoch [16/50], Step [334/735], Loss: 0.3002\n",
      "Epoch [16/50], Step [335/735], Loss: 0.8240\n",
      "Epoch [16/50], Step [336/735], Loss: 1.1272\n",
      "Epoch [16/50], Step [337/735], Loss: 0.1120\n",
      "Epoch [16/50], Step [338/735], Loss: 0.1929\n",
      "Epoch [16/50], Step [339/735], Loss: 0.5947\n",
      "Epoch [16/50], Step [340/735], Loss: 0.0965\n",
      "Epoch [16/50], Step [341/735], Loss: 0.2566\n",
      "Epoch [16/50], Step [342/735], Loss: 0.1979\n",
      "Epoch [16/50], Step [343/735], Loss: 0.1497\n",
      "Epoch [16/50], Step [344/735], Loss: 0.1156\n",
      "Epoch [16/50], Step [345/735], Loss: 0.1389\n",
      "Epoch [16/50], Step [346/735], Loss: 0.0466\n",
      "Epoch [16/50], Step [347/735], Loss: 0.1772\n",
      "Epoch [16/50], Step [348/735], Loss: 0.2874\n",
      "Epoch [16/50], Step [349/735], Loss: 1.5149\n",
      "Epoch [16/50], Step [350/735], Loss: 0.1179\n",
      "Epoch [16/50], Step [351/735], Loss: 0.4399\n",
      "Epoch [16/50], Step [352/735], Loss: 0.3022\n",
      "Epoch [16/50], Step [353/735], Loss: 0.1118\n",
      "Epoch [16/50], Step [354/735], Loss: 0.1296\n",
      "Epoch [16/50], Step [355/735], Loss: 1.5534\n",
      "Epoch [16/50], Step [356/735], Loss: 0.2044\n",
      "Epoch [16/50], Step [357/735], Loss: 0.1073\n",
      "Epoch [16/50], Step [358/735], Loss: 0.0868\n",
      "Epoch [16/50], Step [359/735], Loss: 0.2340\n",
      "Epoch [16/50], Step [360/735], Loss: 0.1080\n",
      "Epoch [16/50], Step [361/735], Loss: 0.1067\n",
      "Epoch [16/50], Step [362/735], Loss: 0.2321\n",
      "Epoch [16/50], Step [363/735], Loss: 0.0447\n",
      "Epoch [16/50], Step [364/735], Loss: 0.3064\n",
      "Epoch [16/50], Step [365/735], Loss: 0.0812\n",
      "Epoch [16/50], Step [366/735], Loss: 0.2616\n",
      "Epoch [16/50], Step [367/735], Loss: 0.0684\n",
      "Epoch [16/50], Step [368/735], Loss: 0.1115\n",
      "Epoch [16/50], Step [369/735], Loss: 0.3304\n",
      "Epoch [16/50], Step [370/735], Loss: 0.1588\n",
      "Epoch [16/50], Step [371/735], Loss: 0.8759\n",
      "Epoch [16/50], Step [372/735], Loss: 0.1359\n",
      "Epoch [16/50], Step [373/735], Loss: 0.1584\n",
      "Epoch [16/50], Step [374/735], Loss: 0.1234\n",
      "Epoch [16/50], Step [375/735], Loss: 2.0862\n",
      "Epoch [16/50], Step [376/735], Loss: 0.0602\n",
      "Epoch [16/50], Step [377/735], Loss: 0.0821\n",
      "Epoch [16/50], Step [378/735], Loss: 0.0571\n",
      "Epoch [16/50], Step [379/735], Loss: 0.1834\n",
      "Epoch [16/50], Step [380/735], Loss: 0.1967\n",
      "Epoch [16/50], Step [381/735], Loss: 0.0786\n",
      "Epoch [16/50], Step [382/735], Loss: 0.1478\n",
      "Epoch [16/50], Step [383/735], Loss: 0.0850\n",
      "Epoch [16/50], Step [384/735], Loss: 0.1777\n",
      "Epoch [16/50], Step [385/735], Loss: 0.5219\n",
      "Epoch [16/50], Step [386/735], Loss: 0.1658\n",
      "Epoch [16/50], Step [387/735], Loss: 0.1931\n",
      "Epoch [16/50], Step [388/735], Loss: 0.0914\n",
      "Epoch [16/50], Step [389/735], Loss: 0.2781\n",
      "Epoch [16/50], Step [390/735], Loss: 0.0799\n",
      "Epoch [16/50], Step [391/735], Loss: 0.1456\n",
      "Epoch [16/50], Step [392/735], Loss: 0.1934\n",
      "Epoch [16/50], Step [393/735], Loss: 0.1324\n",
      "Epoch [16/50], Step [394/735], Loss: 0.1344\n",
      "Epoch [16/50], Step [395/735], Loss: 0.2124\n",
      "Epoch [16/50], Step [396/735], Loss: 0.0769\n",
      "Epoch [16/50], Step [397/735], Loss: 0.0601\n",
      "Epoch [16/50], Step [398/735], Loss: 0.0854\n",
      "Epoch [16/50], Step [399/735], Loss: 0.1107\n",
      "Epoch [16/50], Step [400/735], Loss: 0.1274\n",
      "Epoch [16/50], Step [401/735], Loss: 0.1514\n",
      "Epoch [16/50], Step [402/735], Loss: 0.0859\n",
      "Epoch [16/50], Step [403/735], Loss: 0.2094\n",
      "Epoch [16/50], Step [404/735], Loss: 0.0960\n",
      "Epoch [16/50], Step [405/735], Loss: 0.0288\n",
      "Epoch [16/50], Step [406/735], Loss: 0.1836\n",
      "Epoch [16/50], Step [407/735], Loss: 0.1231\n",
      "Epoch [16/50], Step [408/735], Loss: 0.0995\n",
      "Epoch [16/50], Step [409/735], Loss: 0.2447\n",
      "Epoch [16/50], Step [410/735], Loss: 0.1546\n",
      "Epoch [16/50], Step [411/735], Loss: 0.0959\n",
      "Epoch [16/50], Step [412/735], Loss: 0.0918\n",
      "Epoch [16/50], Step [413/735], Loss: 0.1768\n",
      "Epoch [16/50], Step [414/735], Loss: 0.2034\n",
      "Epoch [16/50], Step [415/735], Loss: 0.3880\n",
      "Epoch [16/50], Step [416/735], Loss: 0.2216\n",
      "Epoch [16/50], Step [417/735], Loss: 0.1387\n",
      "Epoch [16/50], Step [418/735], Loss: 0.1063\n",
      "Epoch [16/50], Step [419/735], Loss: 0.3361\n",
      "Epoch [16/50], Step [420/735], Loss: 0.0837\n",
      "Epoch [16/50], Step [421/735], Loss: 0.2994\n",
      "Epoch [16/50], Step [422/735], Loss: 0.5833\n",
      "Epoch [16/50], Step [423/735], Loss: 0.2948\n",
      "Epoch [16/50], Step [424/735], Loss: 0.1466\n",
      "Epoch [16/50], Step [425/735], Loss: 0.1270\n",
      "Epoch [16/50], Step [426/735], Loss: 0.1397\n",
      "Epoch [16/50], Step [427/735], Loss: 0.0502\n",
      "Epoch [16/50], Step [428/735], Loss: 0.3073\n",
      "Epoch [16/50], Step [429/735], Loss: 0.0796\n",
      "Epoch [16/50], Step [430/735], Loss: 0.5899\n",
      "Epoch [16/50], Step [431/735], Loss: 0.1258\n",
      "Epoch [16/50], Step [432/735], Loss: 0.1590\n",
      "Epoch [16/50], Step [433/735], Loss: 0.0671\n",
      "Epoch [16/50], Step [434/735], Loss: 0.0758\n",
      "Epoch [16/50], Step [435/735], Loss: 0.0990\n",
      "Epoch [16/50], Step [436/735], Loss: 0.2772\n",
      "Epoch [16/50], Step [437/735], Loss: 0.1447\n",
      "Epoch [16/50], Step [438/735], Loss: 0.1054\n",
      "Epoch [16/50], Step [439/735], Loss: 0.2043\n",
      "Epoch [16/50], Step [440/735], Loss: 0.1590\n",
      "Epoch [16/50], Step [441/735], Loss: 0.0791\n",
      "Epoch [16/50], Step [442/735], Loss: 0.0903\n",
      "Epoch [16/50], Step [443/735], Loss: 0.0823\n",
      "Epoch [16/50], Step [444/735], Loss: 0.1359\n",
      "Epoch [16/50], Step [445/735], Loss: 0.3543\n",
      "Epoch [16/50], Step [446/735], Loss: 0.1356\n",
      "Epoch [16/50], Step [447/735], Loss: 0.4907\n",
      "Epoch [16/50], Step [448/735], Loss: 0.1883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Step [449/735], Loss: 0.3165\n",
      "Epoch [16/50], Step [450/735], Loss: 0.2063\n",
      "Epoch [16/50], Step [451/735], Loss: 0.3727\n",
      "Epoch [16/50], Step [452/735], Loss: 0.0418\n",
      "Epoch [16/50], Step [453/735], Loss: 0.2945\n",
      "Epoch [16/50], Step [454/735], Loss: 0.0809\n",
      "Epoch [16/50], Step [455/735], Loss: 0.3090\n",
      "Epoch [16/50], Step [456/735], Loss: 0.1493\n",
      "Epoch [16/50], Step [457/735], Loss: 0.0498\n",
      "Epoch [16/50], Step [458/735], Loss: 0.2707\n",
      "Epoch [16/50], Step [459/735], Loss: 0.3027\n",
      "Epoch [16/50], Step [460/735], Loss: 0.0645\n",
      "Epoch [16/50], Step [461/735], Loss: 0.0801\n",
      "Epoch [16/50], Step [462/735], Loss: 0.0484\n",
      "Epoch [16/50], Step [463/735], Loss: 0.0483\n",
      "Epoch [16/50], Step [464/735], Loss: 0.2201\n",
      "Epoch [16/50], Step [465/735], Loss: 0.1420\n",
      "Epoch [16/50], Step [466/735], Loss: 0.1413\n",
      "Epoch [16/50], Step [467/735], Loss: 0.1910\n",
      "Epoch [16/50], Step [468/735], Loss: 0.0723\n",
      "Epoch [16/50], Step [469/735], Loss: 0.1816\n",
      "Epoch [16/50], Step [470/735], Loss: 0.0348\n",
      "Epoch [16/50], Step [471/735], Loss: 0.1082\n",
      "Epoch [16/50], Step [472/735], Loss: 0.2828\n",
      "Epoch [16/50], Step [473/735], Loss: 0.3744\n",
      "Epoch [16/50], Step [474/735], Loss: 0.1595\n",
      "Epoch [16/50], Step [475/735], Loss: 0.1060\n",
      "Epoch [16/50], Step [476/735], Loss: 0.2774\n",
      "Epoch [16/50], Step [477/735], Loss: 0.1695\n",
      "Epoch [16/50], Step [478/735], Loss: 0.4960\n",
      "Epoch [16/50], Step [479/735], Loss: 0.2572\n",
      "Epoch [16/50], Step [480/735], Loss: 0.1449\n",
      "Epoch [16/50], Step [481/735], Loss: 0.1272\n",
      "Epoch [16/50], Step [482/735], Loss: 0.0435\n",
      "Epoch [16/50], Step [483/735], Loss: 0.0977\n",
      "Epoch [16/50], Step [484/735], Loss: 0.2044\n",
      "Epoch [16/50], Step [485/735], Loss: 0.0618\n",
      "Epoch [16/50], Step [486/735], Loss: 0.0527\n",
      "Epoch [16/50], Step [487/735], Loss: 0.2434\n",
      "Epoch [16/50], Step [488/735], Loss: 0.1069\n",
      "Epoch [16/50], Step [489/735], Loss: 0.0602\n",
      "Epoch [16/50], Step [490/735], Loss: 0.3995\n",
      "Epoch [16/50], Step [491/735], Loss: 0.1111\n",
      "Epoch [16/50], Step [492/735], Loss: 0.0711\n",
      "Epoch [16/50], Step [493/735], Loss: 1.4478\n",
      "Epoch [16/50], Step [494/735], Loss: 0.1957\n",
      "Epoch [16/50], Step [495/735], Loss: 0.4579\n",
      "Epoch [16/50], Step [496/735], Loss: 0.1231\n",
      "Epoch [16/50], Step [497/735], Loss: 0.2147\n",
      "Epoch [16/50], Step [498/735], Loss: 0.2343\n",
      "Epoch [16/50], Step [499/735], Loss: 0.0675\n",
      "Epoch [16/50], Step [500/735], Loss: 0.2595\n",
      "Epoch [16/50], Step [501/735], Loss: 0.0631\n",
      "Epoch [16/50], Step [502/735], Loss: 0.4521\n",
      "Epoch [16/50], Step [503/735], Loss: 0.1782\n",
      "Epoch [16/50], Step [504/735], Loss: 0.0963\n",
      "Epoch [16/50], Step [505/735], Loss: 0.3574\n",
      "Epoch [16/50], Step [506/735], Loss: 0.1212\n",
      "Epoch [16/50], Step [507/735], Loss: 0.1776\n",
      "Epoch [16/50], Step [508/735], Loss: 0.0383\n",
      "Epoch [16/50], Step [509/735], Loss: 0.3025\n",
      "Epoch [16/50], Step [510/735], Loss: 0.1846\n",
      "Epoch [16/50], Step [511/735], Loss: 0.2128\n",
      "Epoch [16/50], Step [512/735], Loss: 0.1206\n",
      "Epoch [16/50], Step [513/735], Loss: 0.0649\n",
      "Epoch [16/50], Step [514/735], Loss: 0.1628\n",
      "Epoch [16/50], Step [515/735], Loss: 0.4788\n",
      "Epoch [16/50], Step [516/735], Loss: 1.1596\n",
      "Epoch [16/50], Step [517/735], Loss: 0.2372\n",
      "Epoch [16/50], Step [518/735], Loss: 0.3493\n",
      "Epoch [16/50], Step [519/735], Loss: 0.0541\n",
      "Epoch [16/50], Step [520/735], Loss: 0.0898\n",
      "Epoch [16/50], Step [521/735], Loss: 0.2436\n",
      "Epoch [16/50], Step [522/735], Loss: 0.2709\n",
      "Epoch [16/50], Step [523/735], Loss: 0.0587\n",
      "Epoch [16/50], Step [524/735], Loss: 0.2871\n",
      "Epoch [16/50], Step [525/735], Loss: 0.1628\n",
      "Epoch [16/50], Step [526/735], Loss: 0.0695\n",
      "Epoch [16/50], Step [527/735], Loss: 0.2785\n",
      "Epoch [16/50], Step [528/735], Loss: 0.1607\n",
      "Epoch [16/50], Step [529/735], Loss: 0.2429\n",
      "Epoch [16/50], Step [530/735], Loss: 0.1007\n",
      "Epoch [16/50], Step [531/735], Loss: 0.1316\n",
      "Epoch [16/50], Step [532/735], Loss: 0.0967\n",
      "Epoch [16/50], Step [533/735], Loss: 0.4086\n",
      "Epoch [16/50], Step [534/735], Loss: 0.0880\n",
      "Epoch [16/50], Step [535/735], Loss: 0.0825\n",
      "Epoch [16/50], Step [536/735], Loss: 0.0465\n",
      "Epoch [16/50], Step [537/735], Loss: 0.3086\n",
      "Epoch [16/50], Step [538/735], Loss: 0.0922\n",
      "Epoch [16/50], Step [539/735], Loss: 0.0872\n",
      "Epoch [16/50], Step [540/735], Loss: 0.1574\n",
      "Epoch [16/50], Step [541/735], Loss: 0.1444\n",
      "Epoch [16/50], Step [542/735], Loss: 0.1010\n",
      "Epoch [16/50], Step [543/735], Loss: 0.3264\n",
      "Epoch [16/50], Step [544/735], Loss: 0.0817\n",
      "Epoch [16/50], Step [545/735], Loss: 0.0991\n",
      "Epoch [16/50], Step [546/735], Loss: 0.0680\n",
      "Epoch [16/50], Step [547/735], Loss: 0.2026\n",
      "Epoch [16/50], Step [548/735], Loss: 0.0582\n",
      "Epoch [16/50], Step [549/735], Loss: 0.4717\n",
      "Epoch [16/50], Step [550/735], Loss: 0.2167\n",
      "Epoch [16/50], Step [551/735], Loss: 0.0409\n",
      "Epoch [16/50], Step [552/735], Loss: 0.3934\n",
      "Epoch [16/50], Step [553/735], Loss: 0.1254\n",
      "Epoch [16/50], Step [554/735], Loss: 0.2587\n",
      "Epoch [16/50], Step [555/735], Loss: 0.1225\n",
      "Epoch [16/50], Step [556/735], Loss: 0.0874\n",
      "Epoch [16/50], Step [557/735], Loss: 0.0593\n",
      "Epoch [16/50], Step [558/735], Loss: 0.1077\n",
      "Epoch [16/50], Step [559/735], Loss: 0.2603\n",
      "Epoch [16/50], Step [560/735], Loss: 0.0817\n",
      "Epoch [16/50], Step [561/735], Loss: 0.1362\n",
      "Epoch [16/50], Step [562/735], Loss: 0.1436\n",
      "Epoch [16/50], Step [563/735], Loss: 2.7178\n",
      "Epoch [16/50], Step [564/735], Loss: 0.0602\n",
      "Epoch [16/50], Step [565/735], Loss: 0.1263\n",
      "Epoch [16/50], Step [566/735], Loss: 0.3100\n",
      "Epoch [16/50], Step [567/735], Loss: 0.1196\n",
      "Epoch [16/50], Step [568/735], Loss: 0.0516\n",
      "Epoch [16/50], Step [569/735], Loss: 0.2831\n",
      "Epoch [16/50], Step [570/735], Loss: 0.2450\n",
      "Epoch [16/50], Step [571/735], Loss: 1.1871\n",
      "Epoch [16/50], Step [572/735], Loss: 0.0870\n",
      "Epoch [16/50], Step [573/735], Loss: 0.2095\n",
      "Epoch [16/50], Step [574/735], Loss: 0.1043\n",
      "Epoch [16/50], Step [575/735], Loss: 0.1034\n",
      "Epoch [16/50], Step [576/735], Loss: 0.1968\n",
      "Epoch [16/50], Step [577/735], Loss: 0.3088\n",
      "Epoch [16/50], Step [578/735], Loss: 0.4332\n",
      "Epoch [16/50], Step [579/735], Loss: 0.5375\n",
      "Epoch [16/50], Step [580/735], Loss: 0.0927\n",
      "Epoch [16/50], Step [581/735], Loss: 0.2227\n",
      "Epoch [16/50], Step [582/735], Loss: 0.0454\n",
      "Epoch [16/50], Step [583/735], Loss: 0.2228\n",
      "Epoch [16/50], Step [584/735], Loss: 0.2581\n",
      "Epoch [16/50], Step [585/735], Loss: 0.1200\n",
      "Epoch [16/50], Step [586/735], Loss: 0.1050\n",
      "Epoch [16/50], Step [587/735], Loss: 0.4208\n",
      "Epoch [16/50], Step [588/735], Loss: 0.3094\n",
      "Epoch [16/50], Step [589/735], Loss: 0.1038\n",
      "Epoch [16/50], Step [590/735], Loss: 0.0537\n",
      "Epoch [16/50], Step [591/735], Loss: 0.2249\n",
      "Epoch [16/50], Step [592/735], Loss: 1.1868\n",
      "Epoch [16/50], Step [593/735], Loss: 0.1037\n",
      "Epoch [16/50], Step [594/735], Loss: 0.1211\n",
      "Epoch [16/50], Step [595/735], Loss: 0.2368\n",
      "Epoch [16/50], Step [596/735], Loss: 0.1053\n",
      "Epoch [16/50], Step [597/735], Loss: 0.0895\n",
      "Epoch [16/50], Step [598/735], Loss: 0.0988\n",
      "Epoch [16/50], Step [599/735], Loss: 0.1326\n",
      "Epoch [16/50], Step [600/735], Loss: 0.0267\n",
      "Epoch [16/50], Step [601/735], Loss: 0.0399\n",
      "Epoch [16/50], Step [602/735], Loss: 0.0515\n",
      "Epoch [16/50], Step [603/735], Loss: 0.3254\n",
      "Epoch [16/50], Step [604/735], Loss: 0.0677\n",
      "Epoch [16/50], Step [605/735], Loss: 0.1101\n",
      "Epoch [16/50], Step [606/735], Loss: 0.1894\n",
      "Epoch [16/50], Step [607/735], Loss: 0.0676\n",
      "Epoch [16/50], Step [608/735], Loss: 0.0645\n",
      "Epoch [16/50], Step [609/735], Loss: 0.1079\n",
      "Epoch [16/50], Step [610/735], Loss: 0.3140\n",
      "Epoch [16/50], Step [611/735], Loss: 0.3044\n",
      "Epoch [16/50], Step [612/735], Loss: 0.0664\n",
      "Epoch [16/50], Step [613/735], Loss: 0.1077\n",
      "Epoch [16/50], Step [614/735], Loss: 0.1276\n",
      "Epoch [16/50], Step [615/735], Loss: 1.3327\n",
      "Epoch [16/50], Step [616/735], Loss: 0.3467\n",
      "Epoch [16/50], Step [617/735], Loss: 0.2288\n",
      "Epoch [16/50], Step [618/735], Loss: 0.2023\n",
      "Epoch [16/50], Step [619/735], Loss: 0.1308\n",
      "Epoch [16/50], Step [620/735], Loss: 0.2283\n",
      "Epoch [16/50], Step [621/735], Loss: 0.3557\n",
      "Epoch [16/50], Step [622/735], Loss: 0.0483\n",
      "Epoch [16/50], Step [623/735], Loss: 0.2992\n",
      "Epoch [16/50], Step [624/735], Loss: 0.1913\n",
      "Epoch [16/50], Step [625/735], Loss: 1.6269\n",
      "Epoch [16/50], Step [626/735], Loss: 0.1479\n",
      "Epoch [16/50], Step [627/735], Loss: 0.2700\n",
      "Epoch [16/50], Step [628/735], Loss: 0.1602\n",
      "Epoch [16/50], Step [629/735], Loss: 0.0515\n",
      "Epoch [16/50], Step [630/735], Loss: 0.1036\n",
      "Epoch [16/50], Step [631/735], Loss: 0.1156\n",
      "Epoch [16/50], Step [632/735], Loss: 0.2538\n",
      "Epoch [16/50], Step [633/735], Loss: 0.6260\n",
      "Epoch [16/50], Step [634/735], Loss: 0.1200\n",
      "Epoch [16/50], Step [635/735], Loss: 0.2107\n",
      "Epoch [16/50], Step [636/735], Loss: 0.1319\n",
      "Epoch [16/50], Step [637/735], Loss: 0.1523\n",
      "Epoch [16/50], Step [638/735], Loss: 0.1205\n",
      "Epoch [16/50], Step [639/735], Loss: 0.0677\n",
      "Epoch [16/50], Step [640/735], Loss: 0.2368\n",
      "Epoch [16/50], Step [641/735], Loss: 0.4805\n",
      "Epoch [16/50], Step [642/735], Loss: 0.0784\n",
      "Epoch [16/50], Step [643/735], Loss: 0.1212\n",
      "Epoch [16/50], Step [644/735], Loss: 0.5682\n",
      "Epoch [16/50], Step [645/735], Loss: 0.3931\n",
      "Epoch [16/50], Step [646/735], Loss: 0.1659\n",
      "Epoch [16/50], Step [647/735], Loss: 0.8246\n",
      "Epoch [16/50], Step [648/735], Loss: 0.1387\n",
      "Epoch [16/50], Step [649/735], Loss: 0.1244\n",
      "Epoch [16/50], Step [650/735], Loss: 0.0566\n",
      "Epoch [16/50], Step [651/735], Loss: 0.1412\n",
      "Epoch [16/50], Step [652/735], Loss: 0.0616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Step [653/735], Loss: 0.0640\n",
      "Epoch [16/50], Step [654/735], Loss: 0.0819\n",
      "Epoch [16/50], Step [655/735], Loss: 0.5878\n",
      "Epoch [16/50], Step [656/735], Loss: 0.0979\n",
      "Epoch [16/50], Step [657/735], Loss: 0.9056\n",
      "Epoch [16/50], Step [658/735], Loss: 0.1582\n",
      "Epoch [16/50], Step [659/735], Loss: 0.0688\n",
      "Epoch [16/50], Step [660/735], Loss: 0.1315\n",
      "Epoch [16/50], Step [661/735], Loss: 0.2273\n",
      "Epoch [16/50], Step [662/735], Loss: 0.2084\n",
      "Epoch [16/50], Step [663/735], Loss: 0.1039\n",
      "Epoch [16/50], Step [664/735], Loss: 0.1195\n",
      "Epoch [16/50], Step [665/735], Loss: 0.1043\n",
      "Epoch [16/50], Step [666/735], Loss: 0.1804\n",
      "Epoch [16/50], Step [667/735], Loss: 0.0845\n",
      "Epoch [16/50], Step [668/735], Loss: 2.5354\n",
      "Epoch [16/50], Step [669/735], Loss: 0.0843\n",
      "Epoch [16/50], Step [670/735], Loss: 0.0682\n",
      "Epoch [16/50], Step [671/735], Loss: 0.0717\n",
      "Epoch [16/50], Step [672/735], Loss: 0.0634\n",
      "Epoch [16/50], Step [673/735], Loss: 0.3483\n",
      "Epoch [16/50], Step [674/735], Loss: 0.2431\n",
      "Epoch [16/50], Step [675/735], Loss: 0.0833\n",
      "Epoch [16/50], Step [676/735], Loss: 0.2009\n",
      "Epoch [16/50], Step [677/735], Loss: 0.2224\n",
      "Epoch [16/50], Step [678/735], Loss: 0.1626\n",
      "Epoch [16/50], Step [679/735], Loss: 0.2388\n",
      "Epoch [16/50], Step [680/735], Loss: 0.2144\n",
      "Epoch [16/50], Step [681/735], Loss: 0.3040\n",
      "Epoch [16/50], Step [682/735], Loss: 0.1048\n",
      "Epoch [16/50], Step [683/735], Loss: 0.1258\n",
      "Epoch [16/50], Step [684/735], Loss: 2.1872\n",
      "Epoch [16/50], Step [685/735], Loss: 0.1385\n",
      "Epoch [16/50], Step [686/735], Loss: 0.1641\n",
      "Epoch [16/50], Step [687/735], Loss: 0.1942\n",
      "Epoch [16/50], Step [688/735], Loss: 0.1496\n",
      "Epoch [16/50], Step [689/735], Loss: 0.1770\n",
      "Epoch [16/50], Step [690/735], Loss: 0.1819\n",
      "Epoch [16/50], Step [691/735], Loss: 0.1265\n",
      "Epoch [16/50], Step [692/735], Loss: 0.1473\n",
      "Epoch [16/50], Step [693/735], Loss: 0.2032\n",
      "Epoch [16/50], Step [694/735], Loss: 0.1317\n",
      "Epoch [16/50], Step [695/735], Loss: 0.3172\n",
      "Epoch [16/50], Step [696/735], Loss: 0.0823\n",
      "Epoch [16/50], Step [697/735], Loss: 0.2887\n",
      "Epoch [16/50], Step [698/735], Loss: 0.1329\n",
      "Epoch [16/50], Step [699/735], Loss: 0.2578\n",
      "Epoch [16/50], Step [700/735], Loss: 0.2352\n",
      "Epoch [16/50], Step [701/735], Loss: 0.1363\n",
      "Epoch [16/50], Step [702/735], Loss: 0.3161\n",
      "Epoch [16/50], Step [703/735], Loss: 0.0682\n",
      "Epoch [16/50], Step [704/735], Loss: 0.2126\n",
      "Epoch [16/50], Step [705/735], Loss: 0.2183\n",
      "Epoch [16/50], Step [706/735], Loss: 0.2783\n",
      "Epoch [16/50], Step [707/735], Loss: 0.4390\n",
      "Epoch [16/50], Step [708/735], Loss: 0.2290\n",
      "Epoch [16/50], Step [709/735], Loss: 0.2720\n",
      "Epoch [16/50], Step [710/735], Loss: 0.3579\n",
      "Epoch [16/50], Step [711/735], Loss: 0.1228\n",
      "Epoch [16/50], Step [712/735], Loss: 0.1402\n",
      "Epoch [16/50], Step [713/735], Loss: 0.1465\n",
      "Epoch [16/50], Step [714/735], Loss: 0.1921\n",
      "Epoch [16/50], Step [715/735], Loss: 0.1973\n",
      "Epoch [16/50], Step [716/735], Loss: 0.1407\n",
      "Epoch [16/50], Step [717/735], Loss: 0.2154\n",
      "Epoch [16/50], Step [718/735], Loss: 0.1210\n",
      "Epoch [16/50], Step [719/735], Loss: 0.1706\n",
      "Epoch [16/50], Step [720/735], Loss: 0.1854\n",
      "Epoch [16/50], Step [721/735], Loss: 0.2804\n",
      "Epoch [16/50], Step [722/735], Loss: 1.0593\n",
      "Epoch [16/50], Step [723/735], Loss: 0.0665\n",
      "Epoch [16/50], Step [724/735], Loss: 0.1028\n",
      "Epoch [16/50], Step [725/735], Loss: 0.2128\n",
      "Epoch [16/50], Step [726/735], Loss: 0.1778\n",
      "Epoch [16/50], Step [727/735], Loss: 0.1498\n",
      "Epoch [16/50], Step [728/735], Loss: 0.0646\n",
      "Epoch [16/50], Step [729/735], Loss: 0.0629\n",
      "Epoch [16/50], Step [730/735], Loss: 0.7116\n",
      "Epoch [16/50], Step [731/735], Loss: 0.1855\n",
      "Epoch [16/50], Step [732/735], Loss: 0.3789\n",
      "Epoch [16/50], Step [733/735], Loss: 0.1201\n",
      "Epoch [16/50], Step [734/735], Loss: 0.3552\n",
      "Epoch [16/50], Step [735/735], Loss: 0.0836\n",
      "Epoch [17/50], Step [1/735], Loss: 0.0749\n",
      "Epoch [17/50], Step [2/735], Loss: 0.1612\n",
      "Epoch [17/50], Step [3/735], Loss: 0.1813\n",
      "Epoch [17/50], Step [4/735], Loss: 0.0956\n",
      "Epoch [17/50], Step [5/735], Loss: 0.1463\n",
      "Epoch [17/50], Step [6/735], Loss: 0.2400\n",
      "Epoch [17/50], Step [7/735], Loss: 0.1101\n",
      "Epoch [17/50], Step [8/735], Loss: 0.1665\n",
      "Epoch [17/50], Step [9/735], Loss: 0.3059\n",
      "Epoch [17/50], Step [10/735], Loss: 0.1830\n",
      "Epoch [17/50], Step [11/735], Loss: 0.2105\n",
      "Epoch [17/50], Step [12/735], Loss: 0.1033\n",
      "Epoch [17/50], Step [13/735], Loss: 0.1153\n",
      "Epoch [17/50], Step [14/735], Loss: 0.1447\n",
      "Epoch [17/50], Step [15/735], Loss: 0.3245\n",
      "Epoch [17/50], Step [16/735], Loss: 0.1924\n",
      "Epoch [17/50], Step [17/735], Loss: 0.2656\n",
      "Epoch [17/50], Step [18/735], Loss: 0.0778\n",
      "Epoch [17/50], Step [19/735], Loss: 0.1572\n",
      "Epoch [17/50], Step [20/735], Loss: 0.1522\n",
      "Epoch [17/50], Step [21/735], Loss: 0.0874\n",
      "Epoch [17/50], Step [22/735], Loss: 0.2439\n",
      "Epoch [17/50], Step [23/735], Loss: 0.1069\n",
      "Epoch [17/50], Step [24/735], Loss: 0.1919\n",
      "Epoch [17/50], Step [25/735], Loss: 0.0419\n",
      "Epoch [17/50], Step [26/735], Loss: 0.0925\n",
      "Epoch [17/50], Step [27/735], Loss: 0.0684\n",
      "Epoch [17/50], Step [28/735], Loss: 0.1035\n",
      "Epoch [17/50], Step [29/735], Loss: 0.2055\n",
      "Epoch [17/50], Step [30/735], Loss: 0.1187\n",
      "Epoch [17/50], Step [31/735], Loss: 0.0535\n",
      "Epoch [17/50], Step [32/735], Loss: 0.1521\n",
      "Epoch [17/50], Step [33/735], Loss: 0.0784\n",
      "Epoch [17/50], Step [34/735], Loss: 0.0847\n",
      "Epoch [17/50], Step [35/735], Loss: 0.6214\n",
      "Epoch [17/50], Step [36/735], Loss: 0.2725\n",
      "Epoch [17/50], Step [37/735], Loss: 1.0586\n",
      "Epoch [17/50], Step [38/735], Loss: 0.0909\n",
      "Epoch [17/50], Step [39/735], Loss: 0.1978\n",
      "Epoch [17/50], Step [40/735], Loss: 0.1039\n",
      "Epoch [17/50], Step [41/735], Loss: 0.0448\n",
      "Epoch [17/50], Step [42/735], Loss: 0.1631\n",
      "Epoch [17/50], Step [43/735], Loss: 0.1558\n",
      "Epoch [17/50], Step [44/735], Loss: 0.2282\n",
      "Epoch [17/50], Step [45/735], Loss: 0.0844\n",
      "Epoch [17/50], Step [46/735], Loss: 0.1869\n",
      "Epoch [17/50], Step [47/735], Loss: 0.0463\n",
      "Epoch [17/50], Step [48/735], Loss: 0.0849\n",
      "Epoch [17/50], Step [49/735], Loss: 0.0707\n",
      "Epoch [17/50], Step [50/735], Loss: 0.1197\n",
      "Epoch [17/50], Step [51/735], Loss: 0.9190\n",
      "Epoch [17/50], Step [52/735], Loss: 0.1109\n",
      "Epoch [17/50], Step [53/735], Loss: 0.5480\n",
      "Epoch [17/50], Step [54/735], Loss: 0.0535\n",
      "Epoch [17/50], Step [55/735], Loss: 0.1964\n",
      "Epoch [17/50], Step [56/735], Loss: 0.0567\n",
      "Epoch [17/50], Step [57/735], Loss: 0.6815\n",
      "Epoch [17/50], Step [58/735], Loss: 0.1368\n",
      "Epoch [17/50], Step [59/735], Loss: 0.1420\n",
      "Epoch [17/50], Step [60/735], Loss: 0.0787\n",
      "Epoch [17/50], Step [61/735], Loss: 0.2172\n",
      "Epoch [17/50], Step [62/735], Loss: 0.0712\n",
      "Epoch [17/50], Step [63/735], Loss: 0.2604\n",
      "Epoch [17/50], Step [64/735], Loss: 0.0839\n",
      "Epoch [17/50], Step [65/735], Loss: 0.2047\n",
      "Epoch [17/50], Step [66/735], Loss: 0.1590\n",
      "Epoch [17/50], Step [67/735], Loss: 0.1514\n",
      "Epoch [17/50], Step [68/735], Loss: 0.5461\n",
      "Epoch [17/50], Step [69/735], Loss: 0.1286\n",
      "Epoch [17/50], Step [70/735], Loss: 0.2191\n",
      "Epoch [17/50], Step [71/735], Loss: 0.1336\n",
      "Epoch [17/50], Step [72/735], Loss: 0.2025\n",
      "Epoch [17/50], Step [73/735], Loss: 1.2754\n",
      "Epoch [17/50], Step [74/735], Loss: 0.2106\n",
      "Epoch [17/50], Step [75/735], Loss: 0.4990\n",
      "Epoch [17/50], Step [76/735], Loss: 0.0915\n",
      "Epoch [17/50], Step [77/735], Loss: 0.0923\n",
      "Epoch [17/50], Step [78/735], Loss: 0.2007\n",
      "Epoch [17/50], Step [79/735], Loss: 0.1086\n",
      "Epoch [17/50], Step [80/735], Loss: 0.1252\n",
      "Epoch [17/50], Step [81/735], Loss: 0.1586\n",
      "Epoch [17/50], Step [82/735], Loss: 0.1080\n",
      "Epoch [17/50], Step [83/735], Loss: 0.2103\n",
      "Epoch [17/50], Step [84/735], Loss: 0.1435\n",
      "Epoch [17/50], Step [85/735], Loss: 0.1656\n",
      "Epoch [17/50], Step [86/735], Loss: 0.2192\n",
      "Epoch [17/50], Step [87/735], Loss: 0.0953\n",
      "Epoch [17/50], Step [88/735], Loss: 0.3097\n",
      "Epoch [17/50], Step [89/735], Loss: 0.2547\n",
      "Epoch [17/50], Step [90/735], Loss: 0.1001\n",
      "Epoch [17/50], Step [91/735], Loss: 0.1450\n",
      "Epoch [17/50], Step [92/735], Loss: 0.0891\n",
      "Epoch [17/50], Step [93/735], Loss: 0.3436\n",
      "Epoch [17/50], Step [94/735], Loss: 0.1863\n",
      "Epoch [17/50], Step [95/735], Loss: 0.0302\n",
      "Epoch [17/50], Step [96/735], Loss: 0.3567\n",
      "Epoch [17/50], Step [97/735], Loss: 0.1417\n",
      "Epoch [17/50], Step [98/735], Loss: 0.1119\n",
      "Epoch [17/50], Step [99/735], Loss: 0.0364\n",
      "Epoch [17/50], Step [100/735], Loss: 0.2799\n",
      "Epoch [17/50], Step [101/735], Loss: 0.1369\n",
      "Epoch [17/50], Step [102/735], Loss: 0.0690\n",
      "Epoch [17/50], Step [103/735], Loss: 0.2300\n",
      "Epoch [17/50], Step [104/735], Loss: 0.1275\n",
      "Epoch [17/50], Step [105/735], Loss: 0.2263\n",
      "Epoch [17/50], Step [106/735], Loss: 0.1473\n",
      "Epoch [17/50], Step [107/735], Loss: 0.1546\n",
      "Epoch [17/50], Step [108/735], Loss: 0.1269\n",
      "Epoch [17/50], Step [109/735], Loss: 0.0905\n",
      "Epoch [17/50], Step [110/735], Loss: 0.0651\n",
      "Epoch [17/50], Step [111/735], Loss: 0.0767\n",
      "Epoch [17/50], Step [112/735], Loss: 0.0779\n",
      "Epoch [17/50], Step [113/735], Loss: 0.0428\n",
      "Epoch [17/50], Step [114/735], Loss: 0.1438\n",
      "Epoch [17/50], Step [115/735], Loss: 0.1135\n",
      "Epoch [17/50], Step [116/735], Loss: 0.1086\n",
      "Epoch [17/50], Step [117/735], Loss: 0.1969\n",
      "Epoch [17/50], Step [118/735], Loss: 0.0519\n",
      "Epoch [17/50], Step [119/735], Loss: 0.1265\n",
      "Epoch [17/50], Step [120/735], Loss: 0.0734\n",
      "Epoch [17/50], Step [121/735], Loss: 0.2523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Step [122/735], Loss: 0.3065\n",
      "Epoch [17/50], Step [123/735], Loss: 0.0974\n",
      "Epoch [17/50], Step [124/735], Loss: 0.1017\n",
      "Epoch [17/50], Step [125/735], Loss: 0.0801\n",
      "Epoch [17/50], Step [126/735], Loss: 0.0644\n",
      "Epoch [17/50], Step [127/735], Loss: 0.0927\n",
      "Epoch [17/50], Step [128/735], Loss: 0.0918\n",
      "Epoch [17/50], Step [129/735], Loss: 0.2075\n",
      "Epoch [17/50], Step [130/735], Loss: 0.3080\n",
      "Epoch [17/50], Step [131/735], Loss: 0.0977\n",
      "Epoch [17/50], Step [132/735], Loss: 0.0842\n",
      "Epoch [17/50], Step [133/735], Loss: 0.1616\n",
      "Epoch [17/50], Step [134/735], Loss: 0.1327\n",
      "Epoch [17/50], Step [135/735], Loss: 0.0564\n",
      "Epoch [17/50], Step [136/735], Loss: 0.1373\n",
      "Epoch [17/50], Step [137/735], Loss: 0.0448\n",
      "Epoch [17/50], Step [138/735], Loss: 0.1219\n",
      "Epoch [17/50], Step [139/735], Loss: 0.0330\n",
      "Epoch [17/50], Step [140/735], Loss: 0.4309\n",
      "Epoch [17/50], Step [141/735], Loss: 0.0586\n",
      "Epoch [17/50], Step [142/735], Loss: 0.0842\n",
      "Epoch [17/50], Step [143/735], Loss: 0.0531\n",
      "Epoch [17/50], Step [144/735], Loss: 0.2710\n",
      "Epoch [17/50], Step [145/735], Loss: 0.2369\n",
      "Epoch [17/50], Step [146/735], Loss: 0.1342\n",
      "Epoch [17/50], Step [147/735], Loss: 1.0375\n",
      "Epoch [17/50], Step [148/735], Loss: 0.0958\n",
      "Epoch [17/50], Step [149/735], Loss: 0.2348\n",
      "Epoch [17/50], Step [150/735], Loss: 0.1363\n",
      "Epoch [17/50], Step [151/735], Loss: 0.0818\n",
      "Epoch [17/50], Step [152/735], Loss: 0.1122\n",
      "Epoch [17/50], Step [153/735], Loss: 0.1375\n",
      "Epoch [17/50], Step [154/735], Loss: 0.2024\n",
      "Epoch [17/50], Step [155/735], Loss: 0.1402\n",
      "Epoch [17/50], Step [156/735], Loss: 0.0883\n",
      "Epoch [17/50], Step [157/735], Loss: 0.1089\n",
      "Epoch [17/50], Step [158/735], Loss: 0.1047\n",
      "Epoch [17/50], Step [159/735], Loss: 0.0606\n",
      "Epoch [17/50], Step [160/735], Loss: 0.1610\n",
      "Epoch [17/50], Step [161/735], Loss: 0.1858\n",
      "Epoch [17/50], Step [162/735], Loss: 0.1161\n",
      "Epoch [17/50], Step [163/735], Loss: 0.0623\n",
      "Epoch [17/50], Step [164/735], Loss: 0.1176\n",
      "Epoch [17/50], Step [165/735], Loss: 0.2387\n",
      "Epoch [17/50], Step [166/735], Loss: 0.1208\n",
      "Epoch [17/50], Step [167/735], Loss: 0.0892\n",
      "Epoch [17/50], Step [168/735], Loss: 0.0729\n",
      "Epoch [17/50], Step [169/735], Loss: 0.1453\n",
      "Epoch [17/50], Step [170/735], Loss: 0.0802\n",
      "Epoch [17/50], Step [171/735], Loss: 0.4722\n",
      "Epoch [17/50], Step [172/735], Loss: 0.1971\n",
      "Epoch [17/50], Step [173/735], Loss: 0.1734\n",
      "Epoch [17/50], Step [174/735], Loss: 0.1217\n",
      "Epoch [17/50], Step [175/735], Loss: 0.1350\n",
      "Epoch [17/50], Step [176/735], Loss: 0.1424\n",
      "Epoch [17/50], Step [177/735], Loss: 0.0664\n",
      "Epoch [17/50], Step [178/735], Loss: 0.0689\n",
      "Epoch [17/50], Step [179/735], Loss: 0.1123\n",
      "Epoch [17/50], Step [180/735], Loss: 0.0914\n",
      "Epoch [17/50], Step [181/735], Loss: 0.2152\n",
      "Epoch [17/50], Step [182/735], Loss: 0.2070\n",
      "Epoch [17/50], Step [183/735], Loss: 0.1341\n",
      "Epoch [17/50], Step [184/735], Loss: 0.1087\n",
      "Epoch [17/50], Step [185/735], Loss: 0.2787\n",
      "Epoch [17/50], Step [186/735], Loss: 0.1172\n",
      "Epoch [17/50], Step [187/735], Loss: 0.1227\n",
      "Epoch [17/50], Step [188/735], Loss: 0.1348\n",
      "Epoch [17/50], Step [189/735], Loss: 0.4506\n",
      "Epoch [17/50], Step [190/735], Loss: 0.2173\n",
      "Epoch [17/50], Step [191/735], Loss: 0.0433\n",
      "Epoch [17/50], Step [192/735], Loss: 0.0779\n",
      "Epoch [17/50], Step [193/735], Loss: 0.1321\n",
      "Epoch [17/50], Step [194/735], Loss: 0.1067\n",
      "Epoch [17/50], Step [195/735], Loss: 0.6949\n",
      "Epoch [17/50], Step [196/735], Loss: 0.1694\n",
      "Epoch [17/50], Step [197/735], Loss: 0.0940\n",
      "Epoch [17/50], Step [198/735], Loss: 0.1872\n",
      "Epoch [17/50], Step [199/735], Loss: 0.1421\n",
      "Epoch [17/50], Step [200/735], Loss: 0.1378\n",
      "Epoch [17/50], Step [201/735], Loss: 0.1065\n",
      "Epoch [17/50], Step [202/735], Loss: 3.0093\n",
      "Epoch [17/50], Step [203/735], Loss: 0.0532\n",
      "Epoch [17/50], Step [204/735], Loss: 0.5724\n",
      "Epoch [17/50], Step [205/735], Loss: 0.1922\n",
      "Epoch [17/50], Step [206/735], Loss: 0.4842\n",
      "Epoch [17/50], Step [207/735], Loss: 0.1211\n",
      "Epoch [17/50], Step [208/735], Loss: 0.1976\n",
      "Epoch [17/50], Step [209/735], Loss: 0.0698\n",
      "Epoch [17/50], Step [210/735], Loss: 0.1182\n",
      "Epoch [17/50], Step [211/735], Loss: 0.1123\n",
      "Epoch [17/50], Step [212/735], Loss: 0.4356\n",
      "Epoch [17/50], Step [213/735], Loss: 0.1351\n",
      "Epoch [17/50], Step [214/735], Loss: 0.1339\n",
      "Epoch [17/50], Step [215/735], Loss: 0.2333\n",
      "Epoch [17/50], Step [216/735], Loss: 0.1420\n",
      "Epoch [17/50], Step [217/735], Loss: 0.1310\n",
      "Epoch [17/50], Step [218/735], Loss: 0.0571\n",
      "Epoch [17/50], Step [219/735], Loss: 1.0772\n",
      "Epoch [17/50], Step [220/735], Loss: 0.0926\n",
      "Epoch [17/50], Step [221/735], Loss: 0.0929\n",
      "Epoch [17/50], Step [222/735], Loss: 0.1121\n",
      "Epoch [17/50], Step [223/735], Loss: 0.1229\n",
      "Epoch [17/50], Step [224/735], Loss: 0.1233\n",
      "Epoch [17/50], Step [225/735], Loss: 0.0975\n",
      "Epoch [17/50], Step [226/735], Loss: 0.1406\n",
      "Epoch [17/50], Step [227/735], Loss: 0.0549\n",
      "Epoch [17/50], Step [228/735], Loss: 0.1485\n",
      "Epoch [17/50], Step [229/735], Loss: 0.2273\n",
      "Epoch [17/50], Step [230/735], Loss: 0.0885\n",
      "Epoch [17/50], Step [231/735], Loss: 0.3333\n",
      "Epoch [17/50], Step [232/735], Loss: 0.2456\n",
      "Epoch [17/50], Step [233/735], Loss: 0.1887\n",
      "Epoch [17/50], Step [234/735], Loss: 0.1365\n",
      "Epoch [17/50], Step [235/735], Loss: 0.4247\n",
      "Epoch [17/50], Step [236/735], Loss: 0.0606\n",
      "Epoch [17/50], Step [237/735], Loss: 0.0633\n",
      "Epoch [17/50], Step [238/735], Loss: 0.1267\n",
      "Epoch [17/50], Step [239/735], Loss: 0.2634\n",
      "Epoch [17/50], Step [240/735], Loss: 0.2614\n",
      "Epoch [17/50], Step [241/735], Loss: 0.0900\n",
      "Epoch [17/50], Step [242/735], Loss: 0.0922\n",
      "Epoch [17/50], Step [243/735], Loss: 0.1010\n",
      "Epoch [17/50], Step [244/735], Loss: 0.0644\n",
      "Epoch [17/50], Step [245/735], Loss: 0.2767\n",
      "Epoch [17/50], Step [246/735], Loss: 0.2108\n",
      "Epoch [17/50], Step [247/735], Loss: 0.1392\n",
      "Epoch [17/50], Step [248/735], Loss: 0.0964\n",
      "Epoch [17/50], Step [249/735], Loss: 0.1191\n",
      "Epoch [17/50], Step [250/735], Loss: 0.2609\n",
      "Epoch [17/50], Step [251/735], Loss: 0.2669\n",
      "Epoch [17/50], Step [252/735], Loss: 0.0637\n",
      "Epoch [17/50], Step [253/735], Loss: 0.1077\n",
      "Epoch [17/50], Step [254/735], Loss: 0.1081\n",
      "Epoch [17/50], Step [255/735], Loss: 0.4021\n",
      "Epoch [17/50], Step [256/735], Loss: 0.0711\n",
      "Epoch [17/50], Step [257/735], Loss: 0.1158\n",
      "Epoch [17/50], Step [258/735], Loss: 0.2863\n",
      "Epoch [17/50], Step [259/735], Loss: 0.1068\n",
      "Epoch [17/50], Step [260/735], Loss: 0.1198\n",
      "Epoch [17/50], Step [261/735], Loss: 0.1195\n",
      "Epoch [17/50], Step [262/735], Loss: 0.7063\n",
      "Epoch [17/50], Step [263/735], Loss: 0.3557\n",
      "Epoch [17/50], Step [264/735], Loss: 0.2244\n",
      "Epoch [17/50], Step [265/735], Loss: 0.1724\n",
      "Epoch [17/50], Step [266/735], Loss: 0.1466\n",
      "Epoch [17/50], Step [267/735], Loss: 0.0827\n",
      "Epoch [17/50], Step [268/735], Loss: 0.2115\n",
      "Epoch [17/50], Step [269/735], Loss: 0.2148\n",
      "Epoch [17/50], Step [270/735], Loss: 0.0538\n",
      "Epoch [17/50], Step [271/735], Loss: 0.0671\n",
      "Epoch [17/50], Step [272/735], Loss: 0.0895\n",
      "Epoch [17/50], Step [273/735], Loss: 0.0984\n",
      "Epoch [17/50], Step [274/735], Loss: 0.1344\n",
      "Epoch [17/50], Step [275/735], Loss: 0.0665\n",
      "Epoch [17/50], Step [276/735], Loss: 0.1304\n",
      "Epoch [17/50], Step [277/735], Loss: 0.0619\n",
      "Epoch [17/50], Step [278/735], Loss: 0.1267\n",
      "Epoch [17/50], Step [279/735], Loss: 0.1991\n",
      "Epoch [17/50], Step [280/735], Loss: 0.1292\n",
      "Epoch [17/50], Step [281/735], Loss: 0.1879\n",
      "Epoch [17/50], Step [282/735], Loss: 0.1416\n",
      "Epoch [17/50], Step [283/735], Loss: 0.0820\n",
      "Epoch [17/50], Step [284/735], Loss: 0.3672\n",
      "Epoch [17/50], Step [285/735], Loss: 0.1320\n",
      "Epoch [17/50], Step [286/735], Loss: 0.1938\n",
      "Epoch [17/50], Step [287/735], Loss: 0.1445\n",
      "Epoch [17/50], Step [288/735], Loss: 0.1242\n",
      "Epoch [17/50], Step [289/735], Loss: 0.0890\n",
      "Epoch [17/50], Step [290/735], Loss: 0.3365\n",
      "Epoch [17/50], Step [291/735], Loss: 0.2322\n",
      "Epoch [17/50], Step [292/735], Loss: 0.2470\n",
      "Epoch [17/50], Step [293/735], Loss: 0.4269\n",
      "Epoch [17/50], Step [294/735], Loss: 0.1135\n",
      "Epoch [17/50], Step [295/735], Loss: 0.0961\n",
      "Epoch [17/50], Step [296/735], Loss: 0.3068\n",
      "Epoch [17/50], Step [297/735], Loss: 0.1355\n",
      "Epoch [17/50], Step [298/735], Loss: 0.3539\n",
      "Epoch [17/50], Step [299/735], Loss: 0.2648\n",
      "Epoch [17/50], Step [300/735], Loss: 0.0848\n",
      "Epoch [17/50], Step [301/735], Loss: 1.5853\n",
      "Epoch [17/50], Step [302/735], Loss: 0.0905\n",
      "Epoch [17/50], Step [303/735], Loss: 0.0943\n",
      "Epoch [17/50], Step [304/735], Loss: 0.1232\n",
      "Epoch [17/50], Step [305/735], Loss: 0.2721\n",
      "Epoch [17/50], Step [306/735], Loss: 0.1099\n",
      "Epoch [17/50], Step [307/735], Loss: 0.4335\n",
      "Epoch [17/50], Step [308/735], Loss: 0.0911\n",
      "Epoch [17/50], Step [309/735], Loss: 0.1265\n",
      "Epoch [17/50], Step [310/735], Loss: 0.2135\n",
      "Epoch [17/50], Step [311/735], Loss: 0.1175\n",
      "Epoch [17/50], Step [312/735], Loss: 0.2625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Step [313/735], Loss: 0.0813\n",
      "Epoch [17/50], Step [314/735], Loss: 0.1416\n",
      "Epoch [17/50], Step [315/735], Loss: 0.0431\n",
      "Epoch [17/50], Step [316/735], Loss: 0.0630\n",
      "Epoch [17/50], Step [317/735], Loss: 0.1376\n",
      "Epoch [17/50], Step [318/735], Loss: 0.0566\n",
      "Epoch [17/50], Step [319/735], Loss: 0.2564\n",
      "Epoch [17/50], Step [320/735], Loss: 0.0597\n",
      "Epoch [17/50], Step [321/735], Loss: 0.0546\n",
      "Epoch [17/50], Step [322/735], Loss: 0.2648\n",
      "Epoch [17/50], Step [323/735], Loss: 0.0504\n",
      "Epoch [17/50], Step [324/735], Loss: 0.1345\n",
      "Epoch [17/50], Step [325/735], Loss: 0.1230\n",
      "Epoch [17/50], Step [326/735], Loss: 0.0592\n",
      "Epoch [17/50], Step [327/735], Loss: 0.2932\n",
      "Epoch [17/50], Step [328/735], Loss: 0.0540\n",
      "Epoch [17/50], Step [329/735], Loss: 0.0701\n",
      "Epoch [17/50], Step [330/735], Loss: 0.1361\n",
      "Epoch [17/50], Step [331/735], Loss: 0.1685\n",
      "Epoch [17/50], Step [332/735], Loss: 0.1087\n",
      "Epoch [17/50], Step [333/735], Loss: 0.2085\n",
      "Epoch [17/50], Step [334/735], Loss: 0.0641\n",
      "Epoch [17/50], Step [335/735], Loss: 0.0784\n",
      "Epoch [17/50], Step [336/735], Loss: 0.3872\n",
      "Epoch [17/50], Step [337/735], Loss: 0.0330\n",
      "Epoch [17/50], Step [338/735], Loss: 0.2176\n",
      "Epoch [17/50], Step [339/735], Loss: 0.1372\n",
      "Epoch [17/50], Step [340/735], Loss: 0.0412\n",
      "Epoch [17/50], Step [341/735], Loss: 0.1117\n",
      "Epoch [17/50], Step [342/735], Loss: 0.2274\n",
      "Epoch [17/50], Step [343/735], Loss: 0.4390\n",
      "Epoch [17/50], Step [344/735], Loss: 0.1470\n",
      "Epoch [17/50], Step [345/735], Loss: 0.1482\n",
      "Epoch [17/50], Step [346/735], Loss: 0.1205\n",
      "Epoch [17/50], Step [347/735], Loss: 0.2504\n",
      "Epoch [17/50], Step [348/735], Loss: 0.2707\n",
      "Epoch [17/50], Step [349/735], Loss: 0.1760\n",
      "Epoch [17/50], Step [350/735], Loss: 0.0776\n",
      "Epoch [17/50], Step [351/735], Loss: 0.2753\n",
      "Epoch [17/50], Step [352/735], Loss: 0.1562\n",
      "Epoch [17/50], Step [353/735], Loss: 0.0598\n",
      "Epoch [17/50], Step [354/735], Loss: 0.0927\n",
      "Epoch [17/50], Step [355/735], Loss: 0.1096\n",
      "Epoch [17/50], Step [356/735], Loss: 0.5295\n",
      "Epoch [17/50], Step [357/735], Loss: 0.1303\n",
      "Epoch [17/50], Step [358/735], Loss: 0.1207\n",
      "Epoch [17/50], Step [359/735], Loss: 0.0882\n",
      "Epoch [17/50], Step [360/735], Loss: 0.2489\n",
      "Epoch [17/50], Step [361/735], Loss: 0.2553\n",
      "Epoch [17/50], Step [362/735], Loss: 0.1267\n",
      "Epoch [17/50], Step [363/735], Loss: 0.1644\n",
      "Epoch [17/50], Step [364/735], Loss: 0.0657\n",
      "Epoch [17/50], Step [365/735], Loss: 0.2527\n",
      "Epoch [17/50], Step [366/735], Loss: 0.0949\n",
      "Epoch [17/50], Step [367/735], Loss: 0.2133\n",
      "Epoch [17/50], Step [368/735], Loss: 0.2520\n",
      "Epoch [17/50], Step [369/735], Loss: 0.2626\n",
      "Epoch [17/50], Step [370/735], Loss: 0.0544\n",
      "Epoch [17/50], Step [371/735], Loss: 0.1127\n",
      "Epoch [17/50], Step [372/735], Loss: 0.0943\n",
      "Epoch [17/50], Step [373/735], Loss: 0.4690\n",
      "Epoch [17/50], Step [374/735], Loss: 0.0301\n",
      "Epoch [17/50], Step [375/735], Loss: 0.0353\n",
      "Epoch [17/50], Step [376/735], Loss: 0.4288\n",
      "Epoch [17/50], Step [377/735], Loss: 0.1085\n",
      "Epoch [17/50], Step [378/735], Loss: 0.1199\n",
      "Epoch [17/50], Step [379/735], Loss: 0.1037\n",
      "Epoch [17/50], Step [380/735], Loss: 0.2006\n",
      "Epoch [17/50], Step [381/735], Loss: 0.1095\n",
      "Epoch [17/50], Step [382/735], Loss: 0.1127\n",
      "Epoch [17/50], Step [383/735], Loss: 0.0438\n",
      "Epoch [17/50], Step [384/735], Loss: 0.2766\n",
      "Epoch [17/50], Step [385/735], Loss: 0.2275\n",
      "Epoch [17/50], Step [386/735], Loss: 0.3373\n",
      "Epoch [17/50], Step [387/735], Loss: 1.2770\n",
      "Epoch [17/50], Step [388/735], Loss: 0.1797\n",
      "Epoch [17/50], Step [389/735], Loss: 0.1429\n",
      "Epoch [17/50], Step [390/735], Loss: 0.6157\n",
      "Epoch [17/50], Step [391/735], Loss: 1.2747\n",
      "Epoch [17/50], Step [392/735], Loss: 0.1248\n",
      "Epoch [17/50], Step [393/735], Loss: 0.1259\n",
      "Epoch [17/50], Step [394/735], Loss: 0.0593\n",
      "Epoch [17/50], Step [395/735], Loss: 0.0361\n",
      "Epoch [17/50], Step [396/735], Loss: 0.0727\n",
      "Epoch [17/50], Step [397/735], Loss: 0.0888\n",
      "Epoch [17/50], Step [398/735], Loss: 0.1959\n",
      "Epoch [17/50], Step [399/735], Loss: 0.1993\n",
      "Epoch [17/50], Step [400/735], Loss: 0.1951\n",
      "Epoch [17/50], Step [401/735], Loss: 0.3131\n",
      "Epoch [17/50], Step [402/735], Loss: 0.0441\n",
      "Epoch [17/50], Step [403/735], Loss: 0.1895\n",
      "Epoch [17/50], Step [404/735], Loss: 0.0743\n",
      "Epoch [17/50], Step [405/735], Loss: 0.1077\n",
      "Epoch [17/50], Step [406/735], Loss: 0.0748\n",
      "Epoch [17/50], Step [407/735], Loss: 0.1840\n",
      "Epoch [17/50], Step [408/735], Loss: 0.1319\n",
      "Epoch [17/50], Step [409/735], Loss: 0.1374\n",
      "Epoch [17/50], Step [410/735], Loss: 0.1204\n",
      "Epoch [17/50], Step [411/735], Loss: 0.0698\n",
      "Epoch [17/50], Step [412/735], Loss: 0.4049\n",
      "Epoch [17/50], Step [413/735], Loss: 0.0856\n",
      "Epoch [17/50], Step [414/735], Loss: 0.1065\n",
      "Epoch [17/50], Step [415/735], Loss: 0.0811\n",
      "Epoch [17/50], Step [416/735], Loss: 0.0895\n",
      "Epoch [17/50], Step [417/735], Loss: 0.1120\n",
      "Epoch [17/50], Step [418/735], Loss: 0.3936\n",
      "Epoch [17/50], Step [419/735], Loss: 0.8749\n",
      "Epoch [17/50], Step [420/735], Loss: 0.7278\n",
      "Epoch [17/50], Step [421/735], Loss: 0.6342\n",
      "Epoch [17/50], Step [422/735], Loss: 0.0875\n",
      "Epoch [17/50], Step [423/735], Loss: 0.2287\n",
      "Epoch [17/50], Step [424/735], Loss: 0.1746\n",
      "Epoch [17/50], Step [425/735], Loss: 0.1456\n",
      "Epoch [17/50], Step [426/735], Loss: 0.0767\n",
      "Epoch [17/50], Step [427/735], Loss: 3.5087\n",
      "Epoch [17/50], Step [428/735], Loss: 0.3307\n",
      "Epoch [17/50], Step [429/735], Loss: 0.0345\n",
      "Epoch [17/50], Step [430/735], Loss: 0.1486\n",
      "Epoch [17/50], Step [431/735], Loss: 0.0709\n",
      "Epoch [17/50], Step [432/735], Loss: 0.1171\n",
      "Epoch [17/50], Step [433/735], Loss: 0.1677\n",
      "Epoch [17/50], Step [434/735], Loss: 0.0877\n",
      "Epoch [17/50], Step [435/735], Loss: 0.2081\n",
      "Epoch [17/50], Step [436/735], Loss: 0.1512\n",
      "Epoch [17/50], Step [437/735], Loss: 0.0530\n",
      "Epoch [17/50], Step [438/735], Loss: 0.0782\n",
      "Epoch [17/50], Step [439/735], Loss: 0.1481\n",
      "Epoch [17/50], Step [440/735], Loss: 0.1138\n",
      "Epoch [17/50], Step [441/735], Loss: 0.1189\n",
      "Epoch [17/50], Step [442/735], Loss: 0.9543\n",
      "Epoch [17/50], Step [443/735], Loss: 0.2063\n",
      "Epoch [17/50], Step [444/735], Loss: 0.2519\n",
      "Epoch [17/50], Step [445/735], Loss: 0.2673\n",
      "Epoch [17/50], Step [446/735], Loss: 0.1574\n",
      "Epoch [17/50], Step [447/735], Loss: 0.1278\n",
      "Epoch [17/50], Step [448/735], Loss: 0.1452\n",
      "Epoch [17/50], Step [449/735], Loss: 0.2789\n",
      "Epoch [17/50], Step [450/735], Loss: 0.0500\n",
      "Epoch [17/50], Step [451/735], Loss: 0.3021\n",
      "Epoch [17/50], Step [452/735], Loss: 0.0863\n",
      "Epoch [17/50], Step [453/735], Loss: 0.2292\n",
      "Epoch [17/50], Step [454/735], Loss: 0.1856\n",
      "Epoch [17/50], Step [455/735], Loss: 0.2257\n",
      "Epoch [17/50], Step [456/735], Loss: 0.0306\n",
      "Epoch [17/50], Step [457/735], Loss: 0.1492\n",
      "Epoch [17/50], Step [458/735], Loss: 0.1506\n",
      "Epoch [17/50], Step [459/735], Loss: 0.2090\n",
      "Epoch [17/50], Step [460/735], Loss: 0.0546\n",
      "Epoch [17/50], Step [461/735], Loss: 0.0829\n",
      "Epoch [17/50], Step [462/735], Loss: 0.1332\n",
      "Epoch [17/50], Step [463/735], Loss: 0.1818\n",
      "Epoch [17/50], Step [464/735], Loss: 0.5717\n",
      "Epoch [17/50], Step [465/735], Loss: 0.3506\n",
      "Epoch [17/50], Step [466/735], Loss: 0.5504\n",
      "Epoch [17/50], Step [467/735], Loss: 0.2714\n",
      "Epoch [17/50], Step [468/735], Loss: 0.1981\n",
      "Epoch [17/50], Step [469/735], Loss: 0.0824\n",
      "Epoch [17/50], Step [470/735], Loss: 0.1422\n",
      "Epoch [17/50], Step [471/735], Loss: 2.0817\n",
      "Epoch [17/50], Step [472/735], Loss: 0.0554\n",
      "Epoch [17/50], Step [473/735], Loss: 0.2291\n",
      "Epoch [17/50], Step [474/735], Loss: 0.1119\n",
      "Epoch [17/50], Step [475/735], Loss: 0.1053\n",
      "Epoch [17/50], Step [476/735], Loss: 0.0775\n",
      "Epoch [17/50], Step [477/735], Loss: 0.1969\n",
      "Epoch [17/50], Step [478/735], Loss: 0.2009\n",
      "Epoch [17/50], Step [479/735], Loss: 0.3357\n",
      "Epoch [17/50], Step [480/735], Loss: 0.2763\n",
      "Epoch [17/50], Step [481/735], Loss: 0.1314\n",
      "Epoch [17/50], Step [482/735], Loss: 0.1608\n",
      "Epoch [17/50], Step [483/735], Loss: 0.0657\n",
      "Epoch [17/50], Step [484/735], Loss: 0.0760\n",
      "Epoch [17/50], Step [485/735], Loss: 0.1060\n",
      "Epoch [17/50], Step [486/735], Loss: 0.1281\n",
      "Epoch [17/50], Step [487/735], Loss: 0.3270\n",
      "Epoch [17/50], Step [488/735], Loss: 0.0996\n",
      "Epoch [17/50], Step [489/735], Loss: 0.0637\n",
      "Epoch [17/50], Step [490/735], Loss: 0.0583\n",
      "Epoch [17/50], Step [491/735], Loss: 0.2384\n",
      "Epoch [17/50], Step [492/735], Loss: 0.0446\n",
      "Epoch [17/50], Step [493/735], Loss: 0.1059\n",
      "Epoch [17/50], Step [494/735], Loss: 0.1884\n",
      "Epoch [17/50], Step [495/735], Loss: 0.0758\n",
      "Epoch [17/50], Step [496/735], Loss: 0.2073\n",
      "Epoch [17/50], Step [497/735], Loss: 0.1174\n",
      "Epoch [17/50], Step [498/735], Loss: 0.1573\n",
      "Epoch [17/50], Step [499/735], Loss: 0.0876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Step [500/735], Loss: 0.0756\n",
      "Epoch [17/50], Step [501/735], Loss: 0.1003\n",
      "Epoch [17/50], Step [502/735], Loss: 0.0938\n",
      "Epoch [17/50], Step [503/735], Loss: 0.1234\n",
      "Epoch [17/50], Step [504/735], Loss: 0.7733\n",
      "Epoch [17/50], Step [505/735], Loss: 0.1169\n",
      "Epoch [17/50], Step [506/735], Loss: 0.0926\n",
      "Epoch [17/50], Step [507/735], Loss: 0.1595\n",
      "Epoch [17/50], Step [508/735], Loss: 0.1013\n",
      "Epoch [17/50], Step [509/735], Loss: 1.4087\n",
      "Epoch [17/50], Step [510/735], Loss: 0.0459\n",
      "Epoch [17/50], Step [511/735], Loss: 0.9528\n",
      "Epoch [17/50], Step [512/735], Loss: 0.8036\n",
      "Epoch [17/50], Step [513/735], Loss: 0.0778\n",
      "Epoch [17/50], Step [514/735], Loss: 0.0874\n",
      "Epoch [17/50], Step [515/735], Loss: 0.0808\n",
      "Epoch [17/50], Step [516/735], Loss: 0.3694\n",
      "Epoch [17/50], Step [517/735], Loss: 0.4079\n",
      "Epoch [17/50], Step [518/735], Loss: 0.0413\n",
      "Epoch [17/50], Step [519/735], Loss: 0.1585\n",
      "Epoch [17/50], Step [520/735], Loss: 0.2149\n",
      "Epoch [17/50], Step [521/735], Loss: 0.2236\n",
      "Epoch [17/50], Step [522/735], Loss: 0.2160\n",
      "Epoch [17/50], Step [523/735], Loss: 0.0859\n",
      "Epoch [17/50], Step [524/735], Loss: 0.0517\n",
      "Epoch [17/50], Step [525/735], Loss: 0.1275\n",
      "Epoch [17/50], Step [526/735], Loss: 0.0615\n",
      "Epoch [17/50], Step [527/735], Loss: 0.0549\n",
      "Epoch [17/50], Step [528/735], Loss: 0.0621\n",
      "Epoch [17/50], Step [529/735], Loss: 0.1077\n",
      "Epoch [17/50], Step [530/735], Loss: 0.1106\n",
      "Epoch [17/50], Step [531/735], Loss: 0.0493\n",
      "Epoch [17/50], Step [532/735], Loss: 0.0798\n",
      "Epoch [17/50], Step [533/735], Loss: 0.0285\n",
      "Epoch [17/50], Step [534/735], Loss: 0.0974\n",
      "Epoch [17/50], Step [535/735], Loss: 0.1085\n",
      "Epoch [17/50], Step [536/735], Loss: 0.1391\n",
      "Epoch [17/50], Step [537/735], Loss: 0.1620\n",
      "Epoch [17/50], Step [538/735], Loss: 0.3278\n",
      "Epoch [17/50], Step [539/735], Loss: 0.0525\n",
      "Epoch [17/50], Step [540/735], Loss: 0.1274\n",
      "Epoch [17/50], Step [541/735], Loss: 0.1054\n",
      "Epoch [17/50], Step [542/735], Loss: 0.0616\n",
      "Epoch [17/50], Step [543/735], Loss: 0.2724\n",
      "Epoch [17/50], Step [544/735], Loss: 0.2576\n",
      "Epoch [17/50], Step [545/735], Loss: 0.0826\n",
      "Epoch [17/50], Step [546/735], Loss: 0.2386\n",
      "Epoch [17/50], Step [547/735], Loss: 0.1300\n",
      "Epoch [17/50], Step [548/735], Loss: 0.1145\n",
      "Epoch [17/50], Step [549/735], Loss: 0.4128\n",
      "Epoch [17/50], Step [550/735], Loss: 0.1476\n",
      "Epoch [17/50], Step [551/735], Loss: 0.0638\n",
      "Epoch [17/50], Step [552/735], Loss: 0.1620\n",
      "Epoch [17/50], Step [553/735], Loss: 0.3611\n",
      "Epoch [17/50], Step [554/735], Loss: 0.0956\n",
      "Epoch [17/50], Step [555/735], Loss: 0.1511\n",
      "Epoch [17/50], Step [556/735], Loss: 0.0481\n",
      "Epoch [17/50], Step [557/735], Loss: 0.1373\n",
      "Epoch [17/50], Step [558/735], Loss: 0.0830\n",
      "Epoch [17/50], Step [559/735], Loss: 0.1733\n",
      "Epoch [17/50], Step [560/735], Loss: 0.1060\n",
      "Epoch [17/50], Step [561/735], Loss: 0.1396\n",
      "Epoch [17/50], Step [562/735], Loss: 0.2515\n",
      "Epoch [17/50], Step [563/735], Loss: 0.0871\n",
      "Epoch [17/50], Step [564/735], Loss: 0.3187\n",
      "Epoch [17/50], Step [565/735], Loss: 0.2070\n",
      "Epoch [17/50], Step [566/735], Loss: 0.2133\n",
      "Epoch [17/50], Step [567/735], Loss: 0.0526\n",
      "Epoch [17/50], Step [568/735], Loss: 0.2764\n",
      "Epoch [17/50], Step [569/735], Loss: 0.3165\n",
      "Epoch [17/50], Step [570/735], Loss: 0.3584\n",
      "Epoch [17/50], Step [571/735], Loss: 0.2467\n",
      "Epoch [17/50], Step [572/735], Loss: 0.0790\n",
      "Epoch [17/50], Step [573/735], Loss: 0.1710\n",
      "Epoch [17/50], Step [574/735], Loss: 0.2607\n",
      "Epoch [17/50], Step [575/735], Loss: 0.1547\n",
      "Epoch [17/50], Step [576/735], Loss: 0.1455\n",
      "Epoch [17/50], Step [577/735], Loss: 0.1273\n",
      "Epoch [17/50], Step [578/735], Loss: 0.3294\n",
      "Epoch [17/50], Step [579/735], Loss: 2.1539\n",
      "Epoch [17/50], Step [580/735], Loss: 0.7630\n",
      "Epoch [17/50], Step [581/735], Loss: 0.1317\n",
      "Epoch [17/50], Step [582/735], Loss: 0.1046\n",
      "Epoch [17/50], Step [583/735], Loss: 0.1596\n",
      "Epoch [17/50], Step [584/735], Loss: 0.0919\n",
      "Epoch [17/50], Step [585/735], Loss: 0.0731\n",
      "Epoch [17/50], Step [586/735], Loss: 0.1135\n",
      "Epoch [17/50], Step [587/735], Loss: 0.2062\n",
      "Epoch [17/50], Step [588/735], Loss: 0.0340\n",
      "Epoch [17/50], Step [589/735], Loss: 0.1926\n",
      "Epoch [17/50], Step [590/735], Loss: 0.1243\n",
      "Epoch [17/50], Step [591/735], Loss: 0.4488\n",
      "Epoch [17/50], Step [592/735], Loss: 0.1807\n",
      "Epoch [17/50], Step [593/735], Loss: 0.8790\n",
      "Epoch [17/50], Step [594/735], Loss: 0.1075\n",
      "Epoch [17/50], Step [595/735], Loss: 0.2043\n",
      "Epoch [17/50], Step [596/735], Loss: 0.1193\n",
      "Epoch [17/50], Step [597/735], Loss: 0.8742\n",
      "Epoch [17/50], Step [598/735], Loss: 0.1011\n",
      "Epoch [17/50], Step [599/735], Loss: 0.0546\n",
      "Epoch [17/50], Step [600/735], Loss: 0.1546\n",
      "Epoch [17/50], Step [601/735], Loss: 0.2531\n",
      "Epoch [17/50], Step [602/735], Loss: 0.2925\n",
      "Epoch [17/50], Step [603/735], Loss: 0.9575\n",
      "Epoch [17/50], Step [604/735], Loss: 0.1164\n",
      "Epoch [17/50], Step [605/735], Loss: 0.1970\n",
      "Epoch [17/50], Step [606/735], Loss: 0.0465\n",
      "Epoch [17/50], Step [607/735], Loss: 0.0418\n",
      "Epoch [17/50], Step [608/735], Loss: 0.1601\n",
      "Epoch [17/50], Step [609/735], Loss: 0.3610\n",
      "Epoch [17/50], Step [610/735], Loss: 0.1718\n",
      "Epoch [17/50], Step [611/735], Loss: 0.0766\n",
      "Epoch [17/50], Step [612/735], Loss: 0.2743\n",
      "Epoch [17/50], Step [613/735], Loss: 0.1932\n",
      "Epoch [17/50], Step [614/735], Loss: 0.2867\n",
      "Epoch [17/50], Step [615/735], Loss: 0.1962\n",
      "Epoch [17/50], Step [616/735], Loss: 0.1138\n",
      "Epoch [17/50], Step [617/735], Loss: 0.1508\n",
      "Epoch [17/50], Step [618/735], Loss: 0.2187\n",
      "Epoch [17/50], Step [619/735], Loss: 0.3529\n",
      "Epoch [17/50], Step [620/735], Loss: 0.1220\n",
      "Epoch [17/50], Step [621/735], Loss: 0.1495\n",
      "Epoch [17/50], Step [622/735], Loss: 0.1685\n",
      "Epoch [17/50], Step [623/735], Loss: 0.5041\n",
      "Epoch [17/50], Step [624/735], Loss: 1.7777\n",
      "Epoch [17/50], Step [625/735], Loss: 0.1513\n",
      "Epoch [17/50], Step [626/735], Loss: 0.3714\n",
      "Epoch [17/50], Step [627/735], Loss: 0.0824\n",
      "Epoch [17/50], Step [628/735], Loss: 0.1083\n",
      "Epoch [17/50], Step [629/735], Loss: 0.1117\n",
      "Epoch [17/50], Step [630/735], Loss: 0.5239\n",
      "Epoch [17/50], Step [631/735], Loss: 0.0542\n",
      "Epoch [17/50], Step [632/735], Loss: 0.2971\n",
      "Epoch [17/50], Step [633/735], Loss: 0.1504\n",
      "Epoch [17/50], Step [634/735], Loss: 0.1748\n",
      "Epoch [17/50], Step [635/735], Loss: 0.1603\n",
      "Epoch [17/50], Step [636/735], Loss: 0.8212\n",
      "Epoch [17/50], Step [637/735], Loss: 0.2245\n",
      "Epoch [17/50], Step [638/735], Loss: 0.0962\n",
      "Epoch [17/50], Step [639/735], Loss: 0.3165\n",
      "Epoch [17/50], Step [640/735], Loss: 0.1941\n",
      "Epoch [17/50], Step [641/735], Loss: 0.1577\n",
      "Epoch [17/50], Step [642/735], Loss: 0.0639\n",
      "Epoch [17/50], Step [643/735], Loss: 0.1149\n",
      "Epoch [17/50], Step [644/735], Loss: 0.2321\n",
      "Epoch [17/50], Step [645/735], Loss: 0.0919\n",
      "Epoch [17/50], Step [646/735], Loss: 0.2755\n",
      "Epoch [17/50], Step [647/735], Loss: 0.1400\n",
      "Epoch [17/50], Step [648/735], Loss: 0.0488\n",
      "Epoch [17/50], Step [649/735], Loss: 0.3431\n",
      "Epoch [17/50], Step [650/735], Loss: 0.3147\n",
      "Epoch [17/50], Step [651/735], Loss: 0.1968\n",
      "Epoch [17/50], Step [652/735], Loss: 0.0757\n",
      "Epoch [17/50], Step [653/735], Loss: 0.3916\n",
      "Epoch [17/50], Step [654/735], Loss: 0.1628\n",
      "Epoch [17/50], Step [655/735], Loss: 0.2677\n",
      "Epoch [17/50], Step [656/735], Loss: 0.1231\n",
      "Epoch [17/50], Step [657/735], Loss: 0.3041\n",
      "Epoch [17/50], Step [658/735], Loss: 0.2346\n",
      "Epoch [17/50], Step [659/735], Loss: 0.2593\n",
      "Epoch [17/50], Step [660/735], Loss: 1.2244\n",
      "Epoch [17/50], Step [661/735], Loss: 0.2763\n",
      "Epoch [17/50], Step [662/735], Loss: 0.1067\n",
      "Epoch [17/50], Step [663/735], Loss: 0.0426\n",
      "Epoch [17/50], Step [664/735], Loss: 0.1669\n",
      "Epoch [17/50], Step [665/735], Loss: 0.1641\n",
      "Epoch [17/50], Step [666/735], Loss: 0.1113\n",
      "Epoch [17/50], Step [667/735], Loss: 0.5475\n",
      "Epoch [17/50], Step [668/735], Loss: 0.2109\n",
      "Epoch [17/50], Step [669/735], Loss: 0.2047\n",
      "Epoch [17/50], Step [670/735], Loss: 0.1197\n",
      "Epoch [17/50], Step [671/735], Loss: 0.1663\n",
      "Epoch [17/50], Step [672/735], Loss: 0.0676\n",
      "Epoch [17/50], Step [673/735], Loss: 0.1431\n",
      "Epoch [17/50], Step [674/735], Loss: 0.1133\n",
      "Epoch [17/50], Step [675/735], Loss: 0.1495\n",
      "Epoch [17/50], Step [676/735], Loss: 0.1119\n",
      "Epoch [17/50], Step [677/735], Loss: 0.4321\n",
      "Epoch [17/50], Step [678/735], Loss: 0.0462\n",
      "Epoch [17/50], Step [679/735], Loss: 0.0546\n",
      "Epoch [17/50], Step [680/735], Loss: 0.1827\n",
      "Epoch [17/50], Step [681/735], Loss: 0.1000\n",
      "Epoch [17/50], Step [682/735], Loss: 0.0256\n",
      "Epoch [17/50], Step [683/735], Loss: 0.0652\n",
      "Epoch [17/50], Step [684/735], Loss: 0.1588\n",
      "Epoch [17/50], Step [685/735], Loss: 0.0529\n",
      "Epoch [17/50], Step [686/735], Loss: 0.1896\n",
      "Epoch [17/50], Step [687/735], Loss: 0.1691\n",
      "Epoch [17/50], Step [688/735], Loss: 0.4770\n",
      "Epoch [17/50], Step [689/735], Loss: 0.3299\n",
      "Epoch [17/50], Step [690/735], Loss: 0.0528\n",
      "Epoch [17/50], Step [691/735], Loss: 0.1130\n",
      "Epoch [17/50], Step [692/735], Loss: 0.1090\n",
      "Epoch [17/50], Step [693/735], Loss: 0.0456\n",
      "Epoch [17/50], Step [694/735], Loss: 0.1123\n",
      "Epoch [17/50], Step [695/735], Loss: 0.1374\n",
      "Epoch [17/50], Step [696/735], Loss: 0.1222\n",
      "Epoch [17/50], Step [697/735], Loss: 0.0460\n",
      "Epoch [17/50], Step [698/735], Loss: 2.0200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Step [699/735], Loss: 0.0648\n",
      "Epoch [17/50], Step [700/735], Loss: 0.2096\n",
      "Epoch [17/50], Step [701/735], Loss: 0.2665\n",
      "Epoch [17/50], Step [702/735], Loss: 0.3171\n",
      "Epoch [17/50], Step [703/735], Loss: 0.3097\n",
      "Epoch [17/50], Step [704/735], Loss: 0.1203\n",
      "Epoch [17/50], Step [705/735], Loss: 0.1278\n",
      "Epoch [17/50], Step [706/735], Loss: 0.0787\n",
      "Epoch [17/50], Step [707/735], Loss: 0.2146\n",
      "Epoch [17/50], Step [708/735], Loss: 0.3054\n",
      "Epoch [17/50], Step [709/735], Loss: 0.1446\n",
      "Epoch [17/50], Step [710/735], Loss: 0.0745\n",
      "Epoch [17/50], Step [711/735], Loss: 0.1835\n",
      "Epoch [17/50], Step [712/735], Loss: 0.0839\n",
      "Epoch [17/50], Step [713/735], Loss: 0.4471\n",
      "Epoch [17/50], Step [714/735], Loss: 0.3443\n",
      "Epoch [17/50], Step [715/735], Loss: 0.1187\n",
      "Epoch [17/50], Step [716/735], Loss: 0.1969\n",
      "Epoch [17/50], Step [717/735], Loss: 0.6091\n",
      "Epoch [17/50], Step [718/735], Loss: 0.1545\n",
      "Epoch [17/50], Step [719/735], Loss: 0.1219\n",
      "Epoch [17/50], Step [720/735], Loss: 0.3044\n",
      "Epoch [17/50], Step [721/735], Loss: 0.1847\n",
      "Epoch [17/50], Step [722/735], Loss: 0.1914\n",
      "Epoch [17/50], Step [723/735], Loss: 0.1051\n",
      "Epoch [17/50], Step [724/735], Loss: 0.0440\n",
      "Epoch [17/50], Step [725/735], Loss: 0.1569\n",
      "Epoch [17/50], Step [726/735], Loss: 0.0647\n",
      "Epoch [17/50], Step [727/735], Loss: 0.2835\n",
      "Epoch [17/50], Step [728/735], Loss: 0.1520\n",
      "Epoch [17/50], Step [729/735], Loss: 0.2071\n",
      "Epoch [17/50], Step [730/735], Loss: 0.0362\n",
      "Epoch [17/50], Step [731/735], Loss: 0.1268\n",
      "Epoch [17/50], Step [732/735], Loss: 0.3132\n",
      "Epoch [17/50], Step [733/735], Loss: 0.1561\n",
      "Epoch [17/50], Step [734/735], Loss: 0.1535\n",
      "Epoch [17/50], Step [735/735], Loss: 0.1249\n",
      "Epoch [18/50], Step [1/735], Loss: 0.1341\n",
      "Epoch [18/50], Step [2/735], Loss: 0.1069\n",
      "Epoch [18/50], Step [3/735], Loss: 0.1499\n",
      "Epoch [18/50], Step [4/735], Loss: 0.1431\n",
      "Epoch [18/50], Step [5/735], Loss: 0.1376\n",
      "Epoch [18/50], Step [6/735], Loss: 0.2613\n",
      "Epoch [18/50], Step [7/735], Loss: 0.2001\n",
      "Epoch [18/50], Step [8/735], Loss: 0.0952\n",
      "Epoch [18/50], Step [9/735], Loss: 0.3277\n",
      "Epoch [18/50], Step [10/735], Loss: 0.0805\n",
      "Epoch [18/50], Step [11/735], Loss: 0.0787\n",
      "Epoch [18/50], Step [12/735], Loss: 0.1264\n",
      "Epoch [18/50], Step [13/735], Loss: 0.0732\n",
      "Epoch [18/50], Step [14/735], Loss: 0.0976\n",
      "Epoch [18/50], Step [15/735], Loss: 0.1677\n",
      "Epoch [18/50], Step [16/735], Loss: 0.0753\n",
      "Epoch [18/50], Step [17/735], Loss: 0.0454\n",
      "Epoch [18/50], Step [18/735], Loss: 0.1559\n",
      "Epoch [18/50], Step [19/735], Loss: 1.8002\n",
      "Epoch [18/50], Step [20/735], Loss: 0.1881\n",
      "Epoch [18/50], Step [21/735], Loss: 0.0729\n",
      "Epoch [18/50], Step [22/735], Loss: 0.7483\n",
      "Epoch [18/50], Step [23/735], Loss: 0.1586\n",
      "Epoch [18/50], Step [24/735], Loss: 0.1770\n",
      "Epoch [18/50], Step [25/735], Loss: 0.1943\n",
      "Epoch [18/50], Step [26/735], Loss: 0.1996\n",
      "Epoch [18/50], Step [27/735], Loss: 0.1054\n",
      "Epoch [18/50], Step [28/735], Loss: 0.0832\n",
      "Epoch [18/50], Step [29/735], Loss: 0.1841\n",
      "Epoch [18/50], Step [30/735], Loss: 0.1683\n",
      "Epoch [18/50], Step [31/735], Loss: 0.1745\n",
      "Epoch [18/50], Step [32/735], Loss: 0.3506\n",
      "Epoch [18/50], Step [33/735], Loss: 0.1145\n",
      "Epoch [18/50], Step [34/735], Loss: 0.0956\n",
      "Epoch [18/50], Step [35/735], Loss: 0.0862\n",
      "Epoch [18/50], Step [36/735], Loss: 0.0725\n",
      "Epoch [18/50], Step [37/735], Loss: 0.0848\n",
      "Epoch [18/50], Step [38/735], Loss: 0.0852\n",
      "Epoch [18/50], Step [39/735], Loss: 0.1845\n",
      "Epoch [18/50], Step [40/735], Loss: 0.0729\n",
      "Epoch [18/50], Step [41/735], Loss: 0.1518\n",
      "Epoch [18/50], Step [42/735], Loss: 0.1158\n",
      "Epoch [18/50], Step [43/735], Loss: 0.0860\n",
      "Epoch [18/50], Step [44/735], Loss: 0.1340\n",
      "Epoch [18/50], Step [45/735], Loss: 0.2512\n",
      "Epoch [18/50], Step [46/735], Loss: 0.1496\n",
      "Epoch [18/50], Step [47/735], Loss: 0.0725\n",
      "Epoch [18/50], Step [48/735], Loss: 0.1554\n",
      "Epoch [18/50], Step [49/735], Loss: 0.1188\n",
      "Epoch [18/50], Step [50/735], Loss: 0.1737\n",
      "Epoch [18/50], Step [51/735], Loss: 2.4385\n",
      "Epoch [18/50], Step [52/735], Loss: 0.1188\n",
      "Epoch [18/50], Step [53/735], Loss: 0.2550\n",
      "Epoch [18/50], Step [54/735], Loss: 0.1962\n",
      "Epoch [18/50], Step [55/735], Loss: 0.0718\n",
      "Epoch [18/50], Step [56/735], Loss: 0.1464\n",
      "Epoch [18/50], Step [57/735], Loss: 0.1312\n",
      "Epoch [18/50], Step [58/735], Loss: 0.1488\n",
      "Epoch [18/50], Step [59/735], Loss: 0.2096\n",
      "Epoch [18/50], Step [60/735], Loss: 0.1357\n",
      "Epoch [18/50], Step [61/735], Loss: 0.0754\n",
      "Epoch [18/50], Step [62/735], Loss: 0.2676\n",
      "Epoch [18/50], Step [63/735], Loss: 0.8154\n",
      "Epoch [18/50], Step [64/735], Loss: 0.1644\n",
      "Epoch [18/50], Step [65/735], Loss: 2.1844\n",
      "Epoch [18/50], Step [66/735], Loss: 0.1094\n",
      "Epoch [18/50], Step [67/735], Loss: 0.9940\n",
      "Epoch [18/50], Step [68/735], Loss: 0.0484\n",
      "Epoch [18/50], Step [69/735], Loss: 0.1866\n",
      "Epoch [18/50], Step [70/735], Loss: 0.2530\n",
      "Epoch [18/50], Step [71/735], Loss: 0.1252\n",
      "Epoch [18/50], Step [72/735], Loss: 0.0673\n",
      "Epoch [18/50], Step [73/735], Loss: 0.0758\n",
      "Epoch [18/50], Step [74/735], Loss: 0.0577\n",
      "Epoch [18/50], Step [75/735], Loss: 0.1445\n",
      "Epoch [18/50], Step [76/735], Loss: 0.2209\n",
      "Epoch [18/50], Step [77/735], Loss: 0.0961\n",
      "Epoch [18/50], Step [78/735], Loss: 0.0288\n",
      "Epoch [18/50], Step [79/735], Loss: 0.2395\n",
      "Epoch [18/50], Step [80/735], Loss: 0.2096\n",
      "Epoch [18/50], Step [81/735], Loss: 0.2812\n",
      "Epoch [18/50], Step [82/735], Loss: 0.3245\n",
      "Epoch [18/50], Step [83/735], Loss: 0.0966\n",
      "Epoch [18/50], Step [84/735], Loss: 0.0792\n",
      "Epoch [18/50], Step [85/735], Loss: 0.2486\n",
      "Epoch [18/50], Step [86/735], Loss: 0.1130\n",
      "Epoch [18/50], Step [87/735], Loss: 0.1285\n",
      "Epoch [18/50], Step [88/735], Loss: 0.1143\n",
      "Epoch [18/50], Step [89/735], Loss: 0.1618\n",
      "Epoch [18/50], Step [90/735], Loss: 0.7173\n",
      "Epoch [18/50], Step [91/735], Loss: 0.2340\n",
      "Epoch [18/50], Step [92/735], Loss: 0.3265\n",
      "Epoch [18/50], Step [93/735], Loss: 0.0455\n",
      "Epoch [18/50], Step [94/735], Loss: 0.2753\n",
      "Epoch [18/50], Step [95/735], Loss: 0.0709\n",
      "Epoch [18/50], Step [96/735], Loss: 0.0642\n",
      "Epoch [18/50], Step [97/735], Loss: 0.1097\n",
      "Epoch [18/50], Step [98/735], Loss: 0.3138\n",
      "Epoch [18/50], Step [99/735], Loss: 0.1847\n",
      "Epoch [18/50], Step [100/735], Loss: 0.1188\n",
      "Epoch [18/50], Step [101/735], Loss: 0.2318\n",
      "Epoch [18/50], Step [102/735], Loss: 0.0882\n",
      "Epoch [18/50], Step [103/735], Loss: 0.0595\n",
      "Epoch [18/50], Step [104/735], Loss: 0.0779\n",
      "Epoch [18/50], Step [105/735], Loss: 0.1019\n",
      "Epoch [18/50], Step [106/735], Loss: 0.4214\n",
      "Epoch [18/50], Step [107/735], Loss: 0.0728\n",
      "Epoch [18/50], Step [108/735], Loss: 0.7460\n",
      "Epoch [18/50], Step [109/735], Loss: 0.1266\n",
      "Epoch [18/50], Step [110/735], Loss: 0.0664\n",
      "Epoch [18/50], Step [111/735], Loss: 0.1836\n",
      "Epoch [18/50], Step [112/735], Loss: 1.4239\n",
      "Epoch [18/50], Step [113/735], Loss: 0.1185\n",
      "Epoch [18/50], Step [114/735], Loss: 0.1650\n",
      "Epoch [18/50], Step [115/735], Loss: 0.0837\n",
      "Epoch [18/50], Step [116/735], Loss: 0.1337\n",
      "Epoch [18/50], Step [117/735], Loss: 0.4605\n",
      "Epoch [18/50], Step [118/735], Loss: 0.1856\n",
      "Epoch [18/50], Step [119/735], Loss: 0.0611\n",
      "Epoch [18/50], Step [120/735], Loss: 0.0715\n",
      "Epoch [18/50], Step [121/735], Loss: 0.1376\n",
      "Epoch [18/50], Step [122/735], Loss: 0.1118\n",
      "Epoch [18/50], Step [123/735], Loss: 0.0830\n",
      "Epoch [18/50], Step [124/735], Loss: 0.6035\n",
      "Epoch [18/50], Step [125/735], Loss: 0.6334\n",
      "Epoch [18/50], Step [126/735], Loss: 0.0703\n",
      "Epoch [18/50], Step [127/735], Loss: 0.0788\n",
      "Epoch [18/50], Step [128/735], Loss: 0.9633\n",
      "Epoch [18/50], Step [129/735], Loss: 0.1151\n",
      "Epoch [18/50], Step [130/735], Loss: 0.1498\n",
      "Epoch [18/50], Step [131/735], Loss: 0.1955\n",
      "Epoch [18/50], Step [132/735], Loss: 0.1557\n",
      "Epoch [18/50], Step [133/735], Loss: 0.4861\n",
      "Epoch [18/50], Step [134/735], Loss: 0.1333\n",
      "Epoch [18/50], Step [135/735], Loss: 0.2033\n",
      "Epoch [18/50], Step [136/735], Loss: 0.1325\n",
      "Epoch [18/50], Step [137/735], Loss: 0.0850\n",
      "Epoch [18/50], Step [138/735], Loss: 0.0761\n",
      "Epoch [18/50], Step [139/735], Loss: 0.1609\n",
      "Epoch [18/50], Step [140/735], Loss: 0.1378\n",
      "Epoch [18/50], Step [141/735], Loss: 0.2360\n",
      "Epoch [18/50], Step [142/735], Loss: 0.0953\n",
      "Epoch [18/50], Step [143/735], Loss: 0.2159\n",
      "Epoch [18/50], Step [144/735], Loss: 0.0681\n",
      "Epoch [18/50], Step [145/735], Loss: 0.1173\n",
      "Epoch [18/50], Step [146/735], Loss: 0.0882\n",
      "Epoch [18/50], Step [147/735], Loss: 0.1075\n",
      "Epoch [18/50], Step [148/735], Loss: 0.0309\n",
      "Epoch [18/50], Step [149/735], Loss: 0.0417\n",
      "Epoch [18/50], Step [150/735], Loss: 0.0655\n",
      "Epoch [18/50], Step [151/735], Loss: 0.0493\n",
      "Epoch [18/50], Step [152/735], Loss: 2.3580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Step [153/735], Loss: 0.3695\n",
      "Epoch [18/50], Step [154/735], Loss: 0.0829\n",
      "Epoch [18/50], Step [155/735], Loss: 0.1373\n",
      "Epoch [18/50], Step [156/735], Loss: 0.0810\n",
      "Epoch [18/50], Step [157/735], Loss: 0.1216\n",
      "Epoch [18/50], Step [158/735], Loss: 0.1226\n",
      "Epoch [18/50], Step [159/735], Loss: 0.2126\n",
      "Epoch [18/50], Step [160/735], Loss: 0.2457\n",
      "Epoch [18/50], Step [161/735], Loss: 0.0528\n",
      "Epoch [18/50], Step [162/735], Loss: 0.1804\n",
      "Epoch [18/50], Step [163/735], Loss: 0.3649\n",
      "Epoch [18/50], Step [164/735], Loss: 0.0733\n",
      "Epoch [18/50], Step [165/735], Loss: 0.1404\n",
      "Epoch [18/50], Step [166/735], Loss: 0.4302\n",
      "Epoch [18/50], Step [167/735], Loss: 0.2456\n",
      "Epoch [18/50], Step [168/735], Loss: 0.1059\n",
      "Epoch [18/50], Step [169/735], Loss: 0.3305\n",
      "Epoch [18/50], Step [170/735], Loss: 0.0789\n",
      "Epoch [18/50], Step [171/735], Loss: 0.2255\n",
      "Epoch [18/50], Step [172/735], Loss: 0.1503\n",
      "Epoch [18/50], Step [173/735], Loss: 0.1304\n",
      "Epoch [18/50], Step [174/735], Loss: 0.0556\n",
      "Epoch [18/50], Step [175/735], Loss: 0.1174\n",
      "Epoch [18/50], Step [176/735], Loss: 0.4303\n",
      "Epoch [18/50], Step [177/735], Loss: 0.0790\n",
      "Epoch [18/50], Step [178/735], Loss: 1.1579\n",
      "Epoch [18/50], Step [179/735], Loss: 0.4543\n",
      "Epoch [18/50], Step [180/735], Loss: 0.3385\n",
      "Epoch [18/50], Step [181/735], Loss: 0.1521\n",
      "Epoch [18/50], Step [182/735], Loss: 0.0968\n",
      "Epoch [18/50], Step [183/735], Loss: 0.0554\n",
      "Epoch [18/50], Step [184/735], Loss: 0.1499\n",
      "Epoch [18/50], Step [185/735], Loss: 0.1078\n",
      "Epoch [18/50], Step [186/735], Loss: 0.0607\n",
      "Epoch [18/50], Step [187/735], Loss: 0.5951\n",
      "Epoch [18/50], Step [188/735], Loss: 0.0932\n",
      "Epoch [18/50], Step [189/735], Loss: 0.9583\n",
      "Epoch [18/50], Step [190/735], Loss: 0.1126\n",
      "Epoch [18/50], Step [191/735], Loss: 0.1408\n",
      "Epoch [18/50], Step [192/735], Loss: 0.0992\n",
      "Epoch [18/50], Step [193/735], Loss: 0.2750\n",
      "Epoch [18/50], Step [194/735], Loss: 0.1569\n",
      "Epoch [18/50], Step [195/735], Loss: 0.1525\n",
      "Epoch [18/50], Step [196/735], Loss: 0.0971\n",
      "Epoch [18/50], Step [197/735], Loss: 0.2079\n",
      "Epoch [18/50], Step [198/735], Loss: 0.0663\n",
      "Epoch [18/50], Step [199/735], Loss: 0.1835\n",
      "Epoch [18/50], Step [200/735], Loss: 0.1993\n",
      "Epoch [18/50], Step [201/735], Loss: 0.2504\n",
      "Epoch [18/50], Step [202/735], Loss: 0.0686\n",
      "Epoch [18/50], Step [203/735], Loss: 0.0760\n",
      "Epoch [18/50], Step [204/735], Loss: 0.2247\n",
      "Epoch [18/50], Step [205/735], Loss: 0.2917\n",
      "Epoch [18/50], Step [206/735], Loss: 0.1200\n",
      "Epoch [18/50], Step [207/735], Loss: 1.5207\n",
      "Epoch [18/50], Step [208/735], Loss: 0.1673\n",
      "Epoch [18/50], Step [209/735], Loss: 0.1290\n",
      "Epoch [18/50], Step [210/735], Loss: 0.2128\n",
      "Epoch [18/50], Step [211/735], Loss: 0.0725\n",
      "Epoch [18/50], Step [212/735], Loss: 0.1947\n",
      "Epoch [18/50], Step [213/735], Loss: 0.1657\n",
      "Epoch [18/50], Step [214/735], Loss: 0.0965\n",
      "Epoch [18/50], Step [215/735], Loss: 0.0545\n",
      "Epoch [18/50], Step [216/735], Loss: 0.1013\n",
      "Epoch [18/50], Step [217/735], Loss: 0.2510\n",
      "Epoch [18/50], Step [218/735], Loss: 0.1755\n",
      "Epoch [18/50], Step [219/735], Loss: 0.0722\n",
      "Epoch [18/50], Step [220/735], Loss: 0.0549\n",
      "Epoch [18/50], Step [221/735], Loss: 0.1056\n",
      "Epoch [18/50], Step [222/735], Loss: 0.2695\n",
      "Epoch [18/50], Step [223/735], Loss: 0.1690\n",
      "Epoch [18/50], Step [224/735], Loss: 0.5154\n",
      "Epoch [18/50], Step [225/735], Loss: 0.4926\n",
      "Epoch [18/50], Step [226/735], Loss: 0.1798\n",
      "Epoch [18/50], Step [227/735], Loss: 0.3900\n",
      "Epoch [18/50], Step [228/735], Loss: 0.1797\n",
      "Epoch [18/50], Step [229/735], Loss: 0.1009\n",
      "Epoch [18/50], Step [230/735], Loss: 0.0712\n",
      "Epoch [18/50], Step [231/735], Loss: 0.2269\n",
      "Epoch [18/50], Step [232/735], Loss: 0.1870\n",
      "Epoch [18/50], Step [233/735], Loss: 0.1469\n",
      "Epoch [18/50], Step [234/735], Loss: 0.2026\n",
      "Epoch [18/50], Step [235/735], Loss: 0.0878\n",
      "Epoch [18/50], Step [236/735], Loss: 0.1043\n",
      "Epoch [18/50], Step [237/735], Loss: 0.1522\n",
      "Epoch [18/50], Step [238/735], Loss: 0.3386\n",
      "Epoch [18/50], Step [239/735], Loss: 0.1776\n",
      "Epoch [18/50], Step [240/735], Loss: 0.0614\n",
      "Epoch [18/50], Step [241/735], Loss: 0.2660\n",
      "Epoch [18/50], Step [242/735], Loss: 0.1606\n",
      "Epoch [18/50], Step [243/735], Loss: 0.0668\n",
      "Epoch [18/50], Step [244/735], Loss: 0.0990\n",
      "Epoch [18/50], Step [245/735], Loss: 0.1607\n",
      "Epoch [18/50], Step [246/735], Loss: 0.1053\n",
      "Epoch [18/50], Step [247/735], Loss: 0.0758\n",
      "Epoch [18/50], Step [248/735], Loss: 0.1441\n",
      "Epoch [18/50], Step [249/735], Loss: 1.4367\n",
      "Epoch [18/50], Step [250/735], Loss: 0.3078\n",
      "Epoch [18/50], Step [251/735], Loss: 0.1155\n",
      "Epoch [18/50], Step [252/735], Loss: 0.2167\n",
      "Epoch [18/50], Step [253/735], Loss: 0.0468\n",
      "Epoch [18/50], Step [254/735], Loss: 0.1348\n",
      "Epoch [18/50], Step [255/735], Loss: 0.0383\n",
      "Epoch [18/50], Step [256/735], Loss: 0.1919\n",
      "Epoch [18/50], Step [257/735], Loss: 0.1799\n",
      "Epoch [18/50], Step [258/735], Loss: 0.0468\n",
      "Epoch [18/50], Step [259/735], Loss: 0.1820\n",
      "Epoch [18/50], Step [260/735], Loss: 1.0654\n",
      "Epoch [18/50], Step [261/735], Loss: 0.0759\n",
      "Epoch [18/50], Step [262/735], Loss: 0.4698\n",
      "Epoch [18/50], Step [263/735], Loss: 0.6155\n",
      "Epoch [18/50], Step [264/735], Loss: 0.2370\n",
      "Epoch [18/50], Step [265/735], Loss: 0.0932\n",
      "Epoch [18/50], Step [266/735], Loss: 0.0450\n",
      "Epoch [18/50], Step [267/735], Loss: 0.1263\n",
      "Epoch [18/50], Step [268/735], Loss: 0.1136\n",
      "Epoch [18/50], Step [269/735], Loss: 0.1214\n",
      "Epoch [18/50], Step [270/735], Loss: 0.3268\n",
      "Epoch [18/50], Step [271/735], Loss: 0.0733\n",
      "Epoch [18/50], Step [272/735], Loss: 0.1341\n",
      "Epoch [18/50], Step [273/735], Loss: 0.2781\n",
      "Epoch [18/50], Step [274/735], Loss: 0.1265\n",
      "Epoch [18/50], Step [275/735], Loss: 0.0803\n",
      "Epoch [18/50], Step [276/735], Loss: 0.2537\n",
      "Epoch [18/50], Step [277/735], Loss: 0.9022\n",
      "Epoch [18/50], Step [278/735], Loss: 0.2243\n",
      "Epoch [18/50], Step [279/735], Loss: 0.0854\n",
      "Epoch [18/50], Step [280/735], Loss: 0.0458\n",
      "Epoch [18/50], Step [281/735], Loss: 0.0712\n",
      "Epoch [18/50], Step [282/735], Loss: 0.1699\n",
      "Epoch [18/50], Step [283/735], Loss: 0.2327\n",
      "Epoch [18/50], Step [284/735], Loss: 0.2554\n",
      "Epoch [18/50], Step [285/735], Loss: 0.0794\n",
      "Epoch [18/50], Step [286/735], Loss: 0.2245\n",
      "Epoch [18/50], Step [287/735], Loss: 0.3721\n",
      "Epoch [18/50], Step [288/735], Loss: 0.1756\n",
      "Epoch [18/50], Step [289/735], Loss: 0.3355\n",
      "Epoch [18/50], Step [290/735], Loss: 0.4833\n",
      "Epoch [18/50], Step [291/735], Loss: 0.3291\n",
      "Epoch [18/50], Step [292/735], Loss: 0.1266\n",
      "Epoch [18/50], Step [293/735], Loss: 0.1458\n",
      "Epoch [18/50], Step [294/735], Loss: 0.1503\n",
      "Epoch [18/50], Step [295/735], Loss: 0.1118\n",
      "Epoch [18/50], Step [296/735], Loss: 0.1074\n",
      "Epoch [18/50], Step [297/735], Loss: 0.2179\n",
      "Epoch [18/50], Step [298/735], Loss: 0.3463\n",
      "Epoch [18/50], Step [299/735], Loss: 0.2464\n",
      "Epoch [18/50], Step [300/735], Loss: 0.1242\n",
      "Epoch [18/50], Step [301/735], Loss: 0.0793\n",
      "Epoch [18/50], Step [302/735], Loss: 0.2647\n",
      "Epoch [18/50], Step [303/735], Loss: 0.0766\n",
      "Epoch [18/50], Step [304/735], Loss: 0.1104\n",
      "Epoch [18/50], Step [305/735], Loss: 0.1216\n",
      "Epoch [18/50], Step [306/735], Loss: 0.2440\n",
      "Epoch [18/50], Step [307/735], Loss: 0.0793\n",
      "Epoch [18/50], Step [308/735], Loss: 0.1236\n",
      "Epoch [18/50], Step [309/735], Loss: 0.2000\n",
      "Epoch [18/50], Step [310/735], Loss: 0.0589\n",
      "Epoch [18/50], Step [311/735], Loss: 0.1309\n",
      "Epoch [18/50], Step [312/735], Loss: 0.0946\n",
      "Epoch [18/50], Step [313/735], Loss: 0.1259\n",
      "Epoch [18/50], Step [314/735], Loss: 0.1752\n",
      "Epoch [18/50], Step [315/735], Loss: 0.0706\n",
      "Epoch [18/50], Step [316/735], Loss: 0.1505\n",
      "Epoch [18/50], Step [317/735], Loss: 0.2472\n",
      "Epoch [18/50], Step [318/735], Loss: 0.1212\n",
      "Epoch [18/50], Step [319/735], Loss: 0.1203\n",
      "Epoch [18/50], Step [320/735], Loss: 0.0852\n",
      "Epoch [18/50], Step [321/735], Loss: 0.0440\n",
      "Epoch [18/50], Step [322/735], Loss: 0.0745\n",
      "Epoch [18/50], Step [323/735], Loss: 0.0506\n",
      "Epoch [18/50], Step [324/735], Loss: 0.0714\n",
      "Epoch [18/50], Step [325/735], Loss: 0.0611\n",
      "Epoch [18/50], Step [326/735], Loss: 0.1618\n",
      "Epoch [18/50], Step [327/735], Loss: 0.1738\n",
      "Epoch [18/50], Step [328/735], Loss: 0.2167\n",
      "Epoch [18/50], Step [329/735], Loss: 0.1231\n",
      "Epoch [18/50], Step [330/735], Loss: 0.2335\n",
      "Epoch [18/50], Step [331/735], Loss: 0.0682\n",
      "Epoch [18/50], Step [332/735], Loss: 0.1209\n",
      "Epoch [18/50], Step [333/735], Loss: 0.1715\n",
      "Epoch [18/50], Step [334/735], Loss: 0.7784\n",
      "Epoch [18/50], Step [335/735], Loss: 0.1578\n",
      "Epoch [18/50], Step [336/735], Loss: 0.6128\n",
      "Epoch [18/50], Step [337/735], Loss: 0.1703\n",
      "Epoch [18/50], Step [338/735], Loss: 0.1493\n",
      "Epoch [18/50], Step [339/735], Loss: 0.1049\n",
      "Epoch [18/50], Step [340/735], Loss: 0.0701\n",
      "Epoch [18/50], Step [341/735], Loss: 0.1877\n",
      "Epoch [18/50], Step [342/735], Loss: 0.0574\n",
      "Epoch [18/50], Step [343/735], Loss: 0.2737\n",
      "Epoch [18/50], Step [344/735], Loss: 0.1923\n",
      "Epoch [18/50], Step [345/735], Loss: 0.2015\n",
      "Epoch [18/50], Step [346/735], Loss: 0.1360\n",
      "Epoch [18/50], Step [347/735], Loss: 0.1307\n",
      "Epoch [18/50], Step [348/735], Loss: 0.9788\n",
      "Epoch [18/50], Step [349/735], Loss: 0.3272\n",
      "Epoch [18/50], Step [350/735], Loss: 0.1323\n",
      "Epoch [18/50], Step [351/735], Loss: 0.0997\n",
      "Epoch [18/50], Step [352/735], Loss: 1.6233\n",
      "Epoch [18/50], Step [353/735], Loss: 0.1187\n",
      "Epoch [18/50], Step [354/735], Loss: 0.0788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Step [355/735], Loss: 0.0580\n",
      "Epoch [18/50], Step [356/735], Loss: 0.1344\n",
      "Epoch [18/50], Step [357/735], Loss: 0.1659\n",
      "Epoch [18/50], Step [358/735], Loss: 0.0770\n",
      "Epoch [18/50], Step [359/735], Loss: 0.2582\n",
      "Epoch [18/50], Step [360/735], Loss: 0.1643\n",
      "Epoch [18/50], Step [361/735], Loss: 0.1111\n",
      "Epoch [18/50], Step [362/735], Loss: 0.1780\n",
      "Epoch [18/50], Step [363/735], Loss: 0.1352\n",
      "Epoch [18/50], Step [364/735], Loss: 0.0591\n",
      "Epoch [18/50], Step [365/735], Loss: 0.0622\n",
      "Epoch [18/50], Step [366/735], Loss: 0.0861\n",
      "Epoch [18/50], Step [367/735], Loss: 0.0509\n",
      "Epoch [18/50], Step [368/735], Loss: 0.5934\n",
      "Epoch [18/50], Step [369/735], Loss: 0.1396\n",
      "Epoch [18/50], Step [370/735], Loss: 0.1627\n",
      "Epoch [18/50], Step [371/735], Loss: 0.1100\n",
      "Epoch [18/50], Step [372/735], Loss: 0.0548\n",
      "Epoch [18/50], Step [373/735], Loss: 0.1261\n",
      "Epoch [18/50], Step [374/735], Loss: 0.3981\n",
      "Epoch [18/50], Step [375/735], Loss: 0.0838\n",
      "Epoch [18/50], Step [376/735], Loss: 0.0630\n",
      "Epoch [18/50], Step [377/735], Loss: 0.1106\n",
      "Epoch [18/50], Step [378/735], Loss: 0.2789\n",
      "Epoch [18/50], Step [379/735], Loss: 0.0493\n",
      "Epoch [18/50], Step [380/735], Loss: 0.0261\n",
      "Epoch [18/50], Step [381/735], Loss: 0.0475\n",
      "Epoch [18/50], Step [382/735], Loss: 0.2340\n",
      "Epoch [18/50], Step [383/735], Loss: 0.2005\n",
      "Epoch [18/50], Step [384/735], Loss: 0.3190\n",
      "Epoch [18/50], Step [385/735], Loss: 0.9644\n",
      "Epoch [18/50], Step [386/735], Loss: 0.2560\n",
      "Epoch [18/50], Step [387/735], Loss: 0.1046\n",
      "Epoch [18/50], Step [388/735], Loss: 0.1527\n",
      "Epoch [18/50], Step [389/735], Loss: 0.2243\n",
      "Epoch [18/50], Step [390/735], Loss: 0.0540\n",
      "Epoch [18/50], Step [391/735], Loss: 2.3708\n",
      "Epoch [18/50], Step [392/735], Loss: 0.3933\n",
      "Epoch [18/50], Step [393/735], Loss: 0.0790\n",
      "Epoch [18/50], Step [394/735], Loss: 0.0795\n",
      "Epoch [18/50], Step [395/735], Loss: 0.1260\n",
      "Epoch [18/50], Step [396/735], Loss: 0.4163\n",
      "Epoch [18/50], Step [397/735], Loss: 0.3325\n",
      "Epoch [18/50], Step [398/735], Loss: 0.1676\n",
      "Epoch [18/50], Step [399/735], Loss: 0.0779\n",
      "Epoch [18/50], Step [400/735], Loss: 0.1282\n",
      "Epoch [18/50], Step [401/735], Loss: 0.1816\n",
      "Epoch [18/50], Step [402/735], Loss: 0.1926\n",
      "Epoch [18/50], Step [403/735], Loss: 0.1255\n",
      "Epoch [18/50], Step [404/735], Loss: 0.3827\n",
      "Epoch [18/50], Step [405/735], Loss: 0.0934\n",
      "Epoch [18/50], Step [406/735], Loss: 0.2030\n",
      "Epoch [18/50], Step [407/735], Loss: 0.0757\n",
      "Epoch [18/50], Step [408/735], Loss: 0.1833\n",
      "Epoch [18/50], Step [409/735], Loss: 0.2506\n",
      "Epoch [18/50], Step [410/735], Loss: 0.1267\n",
      "Epoch [18/50], Step [411/735], Loss: 0.4927\n",
      "Epoch [18/50], Step [412/735], Loss: 0.3088\n",
      "Epoch [18/50], Step [413/735], Loss: 0.0757\n",
      "Epoch [18/50], Step [414/735], Loss: 0.0814\n",
      "Epoch [18/50], Step [415/735], Loss: 0.2364\n",
      "Epoch [18/50], Step [416/735], Loss: 0.0764\n",
      "Epoch [18/50], Step [417/735], Loss: 0.1612\n",
      "Epoch [18/50], Step [418/735], Loss: 0.1172\n",
      "Epoch [18/50], Step [419/735], Loss: 0.0912\n",
      "Epoch [18/50], Step [420/735], Loss: 0.2266\n",
      "Epoch [18/50], Step [421/735], Loss: 0.0688\n",
      "Epoch [18/50], Step [422/735], Loss: 0.2376\n",
      "Epoch [18/50], Step [423/735], Loss: 0.1253\n",
      "Epoch [18/50], Step [424/735], Loss: 0.1974\n",
      "Epoch [18/50], Step [425/735], Loss: 0.1287\n",
      "Epoch [18/50], Step [426/735], Loss: 0.1422\n",
      "Epoch [18/50], Step [427/735], Loss: 0.1554\n",
      "Epoch [18/50], Step [428/735], Loss: 0.1534\n",
      "Epoch [18/50], Step [429/735], Loss: 0.1938\n",
      "Epoch [18/50], Step [430/735], Loss: 0.3394\n",
      "Epoch [18/50], Step [431/735], Loss: 0.1210\n",
      "Epoch [18/50], Step [432/735], Loss: 0.1565\n",
      "Epoch [18/50], Step [433/735], Loss: 0.2058\n",
      "Epoch [18/50], Step [434/735], Loss: 0.1538\n",
      "Epoch [18/50], Step [435/735], Loss: 0.3498\n",
      "Epoch [18/50], Step [436/735], Loss: 0.1092\n",
      "Epoch [18/50], Step [437/735], Loss: 0.1350\n",
      "Epoch [18/50], Step [438/735], Loss: 0.0851\n",
      "Epoch [18/50], Step [439/735], Loss: 0.1526\n",
      "Epoch [18/50], Step [440/735], Loss: 0.2036\n",
      "Epoch [18/50], Step [441/735], Loss: 0.2982\n",
      "Epoch [18/50], Step [442/735], Loss: 0.1097\n",
      "Epoch [18/50], Step [443/735], Loss: 0.0664\n",
      "Epoch [18/50], Step [444/735], Loss: 0.3495\n",
      "Epoch [18/50], Step [445/735], Loss: 0.0675\n",
      "Epoch [18/50], Step [446/735], Loss: 0.1100\n",
      "Epoch [18/50], Step [447/735], Loss: 0.1237\n",
      "Epoch [18/50], Step [448/735], Loss: 0.1313\n",
      "Epoch [18/50], Step [449/735], Loss: 0.1570\n",
      "Epoch [18/50], Step [450/735], Loss: 0.1387\n",
      "Epoch [18/50], Step [451/735], Loss: 0.0963\n",
      "Epoch [18/50], Step [452/735], Loss: 0.0775\n",
      "Epoch [18/50], Step [453/735], Loss: 0.1816\n",
      "Epoch [18/50], Step [454/735], Loss: 0.1954\n",
      "Epoch [18/50], Step [455/735], Loss: 0.4469\n",
      "Epoch [18/50], Step [456/735], Loss: 0.1753\n",
      "Epoch [18/50], Step [457/735], Loss: 0.1028\n",
      "Epoch [18/50], Step [458/735], Loss: 0.0611\n",
      "Epoch [18/50], Step [459/735], Loss: 0.0689\n",
      "Epoch [18/50], Step [460/735], Loss: 0.1065\n",
      "Epoch [18/50], Step [461/735], Loss: 0.0782\n",
      "Epoch [18/50], Step [462/735], Loss: 0.2672\n",
      "Epoch [18/50], Step [463/735], Loss: 0.1788\n",
      "Epoch [18/50], Step [464/735], Loss: 0.2346\n",
      "Epoch [18/50], Step [465/735], Loss: 0.0801\n",
      "Epoch [18/50], Step [466/735], Loss: 0.1094\n",
      "Epoch [18/50], Step [467/735], Loss: 0.1269\n",
      "Epoch [18/50], Step [468/735], Loss: 0.1631\n",
      "Epoch [18/50], Step [469/735], Loss: 0.5053\n",
      "Epoch [18/50], Step [470/735], Loss: 0.1122\n",
      "Epoch [18/50], Step [471/735], Loss: 0.1758\n",
      "Epoch [18/50], Step [472/735], Loss: 0.0789\n",
      "Epoch [18/50], Step [473/735], Loss: 0.2078\n",
      "Epoch [18/50], Step [474/735], Loss: 0.2457\n",
      "Epoch [18/50], Step [475/735], Loss: 0.0633\n",
      "Epoch [18/50], Step [476/735], Loss: 0.1585\n",
      "Epoch [18/50], Step [477/735], Loss: 0.0467\n",
      "Epoch [18/50], Step [478/735], Loss: 0.0664\n",
      "Epoch [18/50], Step [479/735], Loss: 0.0829\n",
      "Epoch [18/50], Step [480/735], Loss: 0.1549\n",
      "Epoch [18/50], Step [481/735], Loss: 0.0701\n",
      "Epoch [18/50], Step [482/735], Loss: 0.1843\n",
      "Epoch [18/50], Step [483/735], Loss: 0.1026\n",
      "Epoch [18/50], Step [484/735], Loss: 0.2868\n",
      "Epoch [18/50], Step [485/735], Loss: 0.0737\n",
      "Epoch [18/50], Step [486/735], Loss: 0.3453\n",
      "Epoch [18/50], Step [487/735], Loss: 0.0999\n",
      "Epoch [18/50], Step [488/735], Loss: 0.2347\n",
      "Epoch [18/50], Step [489/735], Loss: 0.7146\n",
      "Epoch [18/50], Step [490/735], Loss: 0.1156\n",
      "Epoch [18/50], Step [491/735], Loss: 0.0766\n",
      "Epoch [18/50], Step [492/735], Loss: 0.1448\n",
      "Epoch [18/50], Step [493/735], Loss: 0.6151\n",
      "Epoch [18/50], Step [494/735], Loss: 0.1721\n",
      "Epoch [18/50], Step [495/735], Loss: 0.2309\n",
      "Epoch [18/50], Step [496/735], Loss: 0.1845\n",
      "Epoch [18/50], Step [497/735], Loss: 0.1423\n",
      "Epoch [18/50], Step [498/735], Loss: 0.2204\n",
      "Epoch [18/50], Step [499/735], Loss: 0.0613\n",
      "Epoch [18/50], Step [500/735], Loss: 0.0643\n",
      "Epoch [18/50], Step [501/735], Loss: 0.1891\n",
      "Epoch [18/50], Step [502/735], Loss: 0.2889\n",
      "Epoch [18/50], Step [503/735], Loss: 0.1089\n",
      "Epoch [18/50], Step [504/735], Loss: 0.0972\n",
      "Epoch [18/50], Step [505/735], Loss: 0.3465\n",
      "Epoch [18/50], Step [506/735], Loss: 0.1915\n",
      "Epoch [18/50], Step [507/735], Loss: 0.3319\n",
      "Epoch [18/50], Step [508/735], Loss: 1.0555\n",
      "Epoch [18/50], Step [509/735], Loss: 0.2465\n",
      "Epoch [18/50], Step [510/735], Loss: 0.0466\n",
      "Epoch [18/50], Step [511/735], Loss: 0.1011\n",
      "Epoch [18/50], Step [512/735], Loss: 0.1882\n",
      "Epoch [18/50], Step [513/735], Loss: 0.2301\n",
      "Epoch [18/50], Step [514/735], Loss: 1.4843\n",
      "Epoch [18/50], Step [515/735], Loss: 0.1936\n",
      "Epoch [18/50], Step [516/735], Loss: 0.0513\n",
      "Epoch [18/50], Step [517/735], Loss: 0.2242\n",
      "Epoch [18/50], Step [518/735], Loss: 0.2719\n",
      "Epoch [18/50], Step [519/735], Loss: 0.5912\n",
      "Epoch [18/50], Step [520/735], Loss: 0.1117\n",
      "Epoch [18/50], Step [521/735], Loss: 0.1644\n",
      "Epoch [18/50], Step [522/735], Loss: 0.1032\n",
      "Epoch [18/50], Step [523/735], Loss: 0.0638\n",
      "Epoch [18/50], Step [524/735], Loss: 0.0847\n",
      "Epoch [18/50], Step [525/735], Loss: 0.1289\n",
      "Epoch [18/50], Step [526/735], Loss: 0.1931\n",
      "Epoch [18/50], Step [527/735], Loss: 0.0989\n",
      "Epoch [18/50], Step [528/735], Loss: 0.1122\n",
      "Epoch [18/50], Step [529/735], Loss: 0.0681\n",
      "Epoch [18/50], Step [530/735], Loss: 0.0540\n",
      "Epoch [18/50], Step [531/735], Loss: 0.1127\n",
      "Epoch [18/50], Step [532/735], Loss: 0.6467\n",
      "Epoch [18/50], Step [533/735], Loss: 0.0578\n",
      "Epoch [18/50], Step [534/735], Loss: 0.0693\n",
      "Epoch [18/50], Step [535/735], Loss: 0.1516\n",
      "Epoch [18/50], Step [536/735], Loss: 0.2790\n",
      "Epoch [18/50], Step [537/735], Loss: 0.1161\n",
      "Epoch [18/50], Step [538/735], Loss: 0.0836\n",
      "Epoch [18/50], Step [539/735], Loss: 0.1433\n",
      "Epoch [18/50], Step [540/735], Loss: 0.2047\n",
      "Epoch [18/50], Step [541/735], Loss: 0.0863\n",
      "Epoch [18/50], Step [542/735], Loss: 0.0749\n",
      "Epoch [18/50], Step [543/735], Loss: 0.2509\n",
      "Epoch [18/50], Step [544/735], Loss: 0.0547\n",
      "Epoch [18/50], Step [545/735], Loss: 0.1910\n",
      "Epoch [18/50], Step [546/735], Loss: 0.2414\n",
      "Epoch [18/50], Step [547/735], Loss: 0.5445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Step [548/735], Loss: 0.0852\n",
      "Epoch [18/50], Step [549/735], Loss: 0.0883\n",
      "Epoch [18/50], Step [550/735], Loss: 0.1693\n",
      "Epoch [18/50], Step [551/735], Loss: 0.2030\n",
      "Epoch [18/50], Step [552/735], Loss: 0.1558\n",
      "Epoch [18/50], Step [553/735], Loss: 0.5703\n",
      "Epoch [18/50], Step [554/735], Loss: 0.0794\n",
      "Epoch [18/50], Step [555/735], Loss: 0.0568\n",
      "Epoch [18/50], Step [556/735], Loss: 0.1651\n",
      "Epoch [18/50], Step [557/735], Loss: 0.0535\n",
      "Epoch [18/50], Step [558/735], Loss: 0.5421\n",
      "Epoch [18/50], Step [559/735], Loss: 0.0499\n",
      "Epoch [18/50], Step [560/735], Loss: 0.0897\n",
      "Epoch [18/50], Step [561/735], Loss: 0.0449\n",
      "Epoch [18/50], Step [562/735], Loss: 0.0738\n",
      "Epoch [18/50], Step [563/735], Loss: 0.4729\n",
      "Epoch [18/50], Step [564/735], Loss: 0.0960\n",
      "Epoch [18/50], Step [565/735], Loss: 0.2514\n",
      "Epoch [18/50], Step [566/735], Loss: 0.2138\n",
      "Epoch [18/50], Step [567/735], Loss: 0.3150\n",
      "Epoch [18/50], Step [568/735], Loss: 0.0834\n",
      "Epoch [18/50], Step [569/735], Loss: 0.2970\n",
      "Epoch [18/50], Step [570/735], Loss: 0.0543\n",
      "Epoch [18/50], Step [571/735], Loss: 0.1066\n",
      "Epoch [18/50], Step [572/735], Loss: 0.0423\n",
      "Epoch [18/50], Step [573/735], Loss: 0.1287\n",
      "Epoch [18/50], Step [574/735], Loss: 0.1400\n",
      "Epoch [18/50], Step [575/735], Loss: 0.1757\n",
      "Epoch [18/50], Step [576/735], Loss: 0.2167\n",
      "Epoch [18/50], Step [577/735], Loss: 0.1294\n",
      "Epoch [18/50], Step [578/735], Loss: 0.0845\n",
      "Epoch [18/50], Step [579/735], Loss: 0.1017\n",
      "Epoch [18/50], Step [580/735], Loss: 0.1836\n",
      "Epoch [18/50], Step [581/735], Loss: 0.1995\n",
      "Epoch [18/50], Step [582/735], Loss: 0.6269\n",
      "Epoch [18/50], Step [583/735], Loss: 0.3825\n",
      "Epoch [18/50], Step [584/735], Loss: 0.1155\n",
      "Epoch [18/50], Step [585/735], Loss: 0.1331\n",
      "Epoch [18/50], Step [586/735], Loss: 0.2790\n",
      "Epoch [18/50], Step [587/735], Loss: 0.1600\n",
      "Epoch [18/50], Step [588/735], Loss: 0.0686\n",
      "Epoch [18/50], Step [589/735], Loss: 0.1901\n",
      "Epoch [18/50], Step [590/735], Loss: 0.0805\n",
      "Epoch [18/50], Step [591/735], Loss: 0.0781\n",
      "Epoch [18/50], Step [592/735], Loss: 0.1011\n",
      "Epoch [18/50], Step [593/735], Loss: 0.1593\n",
      "Epoch [18/50], Step [594/735], Loss: 0.3779\n",
      "Epoch [18/50], Step [595/735], Loss: 0.0842\n",
      "Epoch [18/50], Step [596/735], Loss: 0.0900\n",
      "Epoch [18/50], Step [597/735], Loss: 0.1414\n",
      "Epoch [18/50], Step [598/735], Loss: 0.3531\n",
      "Epoch [18/50], Step [599/735], Loss: 0.1219\n",
      "Epoch [18/50], Step [600/735], Loss: 0.2401\n",
      "Epoch [18/50], Step [601/735], Loss: 0.2384\n",
      "Epoch [18/50], Step [602/735], Loss: 0.1475\n",
      "Epoch [18/50], Step [603/735], Loss: 0.2878\n",
      "Epoch [18/50], Step [604/735], Loss: 0.2667\n",
      "Epoch [18/50], Step [605/735], Loss: 0.0636\n",
      "Epoch [18/50], Step [606/735], Loss: 0.2115\n",
      "Epoch [18/50], Step [607/735], Loss: 0.1510\n",
      "Epoch [18/50], Step [608/735], Loss: 0.1503\n",
      "Epoch [18/50], Step [609/735], Loss: 1.2214\n",
      "Epoch [18/50], Step [610/735], Loss: 0.0481\n",
      "Epoch [18/50], Step [611/735], Loss: 0.2135\n",
      "Epoch [18/50], Step [612/735], Loss: 0.1501\n",
      "Epoch [18/50], Step [613/735], Loss: 0.1268\n",
      "Epoch [18/50], Step [614/735], Loss: 0.0564\n",
      "Epoch [18/50], Step [615/735], Loss: 0.2691\n",
      "Epoch [18/50], Step [616/735], Loss: 0.0542\n",
      "Epoch [18/50], Step [617/735], Loss: 0.4551\n",
      "Epoch [18/50], Step [618/735], Loss: 0.3083\n",
      "Epoch [18/50], Step [619/735], Loss: 0.0973\n",
      "Epoch [18/50], Step [620/735], Loss: 0.8160\n",
      "Epoch [18/50], Step [621/735], Loss: 0.0935\n",
      "Epoch [18/50], Step [622/735], Loss: 0.1380\n",
      "Epoch [18/50], Step [623/735], Loss: 0.1246\n",
      "Epoch [18/50], Step [624/735], Loss: 0.1268\n",
      "Epoch [18/50], Step [625/735], Loss: 0.1127\n",
      "Epoch [18/50], Step [626/735], Loss: 0.1548\n",
      "Epoch [18/50], Step [627/735], Loss: 0.0986\n",
      "Epoch [18/50], Step [628/735], Loss: 0.4964\n",
      "Epoch [18/50], Step [629/735], Loss: 0.2697\n",
      "Epoch [18/50], Step [630/735], Loss: 0.1839\n",
      "Epoch [18/50], Step [631/735], Loss: 0.3684\n",
      "Epoch [18/50], Step [632/735], Loss: 0.1189\n",
      "Epoch [18/50], Step [633/735], Loss: 0.1707\n",
      "Epoch [18/50], Step [634/735], Loss: 0.3395\n",
      "Epoch [18/50], Step [635/735], Loss: 0.2119\n",
      "Epoch [18/50], Step [636/735], Loss: 0.1387\n",
      "Epoch [18/50], Step [637/735], Loss: 0.1123\n",
      "Epoch [18/50], Step [638/735], Loss: 0.0682\n",
      "Epoch [18/50], Step [639/735], Loss: 0.0617\n",
      "Epoch [18/50], Step [640/735], Loss: 0.0714\n",
      "Epoch [18/50], Step [641/735], Loss: 0.1444\n",
      "Epoch [18/50], Step [642/735], Loss: 0.0905\n",
      "Epoch [18/50], Step [643/735], Loss: 0.2775\n",
      "Epoch [18/50], Step [644/735], Loss: 0.0522\n",
      "Epoch [18/50], Step [645/735], Loss: 0.3016\n",
      "Epoch [18/50], Step [646/735], Loss: 0.5579\n",
      "Epoch [18/50], Step [647/735], Loss: 0.3764\n",
      "Epoch [18/50], Step [648/735], Loss: 0.1541\n",
      "Epoch [18/50], Step [649/735], Loss: 0.1765\n",
      "Epoch [18/50], Step [650/735], Loss: 1.0715\n",
      "Epoch [18/50], Step [651/735], Loss: 0.0869\n",
      "Epoch [18/50], Step [652/735], Loss: 0.1444\n",
      "Epoch [18/50], Step [653/735], Loss: 0.4055\n",
      "Epoch [18/50], Step [654/735], Loss: 0.1004\n",
      "Epoch [18/50], Step [655/735], Loss: 0.0780\n",
      "Epoch [18/50], Step [656/735], Loss: 0.0811\n",
      "Epoch [18/50], Step [657/735], Loss: 0.0543\n",
      "Epoch [18/50], Step [658/735], Loss: 0.1024\n",
      "Epoch [18/50], Step [659/735], Loss: 0.0455\n",
      "Epoch [18/50], Step [660/735], Loss: 0.0491\n",
      "Epoch [18/50], Step [661/735], Loss: 0.1128\n",
      "Epoch [18/50], Step [662/735], Loss: 0.1498\n",
      "Epoch [18/50], Step [663/735], Loss: 0.1349\n",
      "Epoch [18/50], Step [664/735], Loss: 2.3842\n",
      "Epoch [18/50], Step [665/735], Loss: 0.1196\n",
      "Epoch [18/50], Step [666/735], Loss: 0.2295\n",
      "Epoch [18/50], Step [667/735], Loss: 0.1096\n",
      "Epoch [18/50], Step [668/735], Loss: 0.1206\n",
      "Epoch [18/50], Step [669/735], Loss: 0.1241\n",
      "Epoch [18/50], Step [670/735], Loss: 0.1652\n",
      "Epoch [18/50], Step [671/735], Loss: 0.1457\n",
      "Epoch [18/50], Step [672/735], Loss: 0.0544\n",
      "Epoch [18/50], Step [673/735], Loss: 0.1823\n",
      "Epoch [18/50], Step [674/735], Loss: 0.2358\n",
      "Epoch [18/50], Step [675/735], Loss: 0.1581\n",
      "Epoch [18/50], Step [676/735], Loss: 0.2103\n",
      "Epoch [18/50], Step [677/735], Loss: 0.9374\n",
      "Epoch [18/50], Step [678/735], Loss: 0.1170\n",
      "Epoch [18/50], Step [679/735], Loss: 0.0756\n",
      "Epoch [18/50], Step [680/735], Loss: 0.0935\n",
      "Epoch [18/50], Step [681/735], Loss: 0.0858\n",
      "Epoch [18/50], Step [682/735], Loss: 0.0781\n",
      "Epoch [18/50], Step [683/735], Loss: 0.0697\n",
      "Epoch [18/50], Step [684/735], Loss: 0.7401\n",
      "Epoch [18/50], Step [685/735], Loss: 0.3291\n",
      "Epoch [18/50], Step [686/735], Loss: 0.1560\n",
      "Epoch [18/50], Step [687/735], Loss: 0.0958\n",
      "Epoch [18/50], Step [688/735], Loss: 0.0958\n",
      "Epoch [18/50], Step [689/735], Loss: 0.1064\n",
      "Epoch [18/50], Step [690/735], Loss: 0.1293\n",
      "Epoch [18/50], Step [691/735], Loss: 0.1905\n",
      "Epoch [18/50], Step [692/735], Loss: 0.1849\n",
      "Epoch [18/50], Step [693/735], Loss: 0.1123\n",
      "Epoch [18/50], Step [694/735], Loss: 0.1959\n",
      "Epoch [18/50], Step [695/735], Loss: 0.1934\n",
      "Epoch [18/50], Step [696/735], Loss: 0.1611\n",
      "Epoch [18/50], Step [697/735], Loss: 0.0625\n",
      "Epoch [18/50], Step [698/735], Loss: 0.1544\n",
      "Epoch [18/50], Step [699/735], Loss: 0.0892\n",
      "Epoch [18/50], Step [700/735], Loss: 0.3145\n",
      "Epoch [18/50], Step [701/735], Loss: 0.1651\n",
      "Epoch [18/50], Step [702/735], Loss: 0.0775\n",
      "Epoch [18/50], Step [703/735], Loss: 0.0810\n",
      "Epoch [18/50], Step [704/735], Loss: 0.1771\n",
      "Epoch [18/50], Step [705/735], Loss: 0.0601\n",
      "Epoch [18/50], Step [706/735], Loss: 0.1165\n",
      "Epoch [18/50], Step [707/735], Loss: 0.1715\n",
      "Epoch [18/50], Step [708/735], Loss: 0.1574\n",
      "Epoch [18/50], Step [709/735], Loss: 0.3554\n",
      "Epoch [18/50], Step [710/735], Loss: 0.0416\n",
      "Epoch [18/50], Step [711/735], Loss: 0.0857\n",
      "Epoch [18/50], Step [712/735], Loss: 0.1609\n",
      "Epoch [18/50], Step [713/735], Loss: 0.1416\n",
      "Epoch [18/50], Step [714/735], Loss: 0.1004\n",
      "Epoch [18/50], Step [715/735], Loss: 0.0420\n",
      "Epoch [18/50], Step [716/735], Loss: 0.1193\n",
      "Epoch [18/50], Step [717/735], Loss: 0.1381\n",
      "Epoch [18/50], Step [718/735], Loss: 0.1571\n",
      "Epoch [18/50], Step [719/735], Loss: 0.1043\n",
      "Epoch [18/50], Step [720/735], Loss: 0.0425\n",
      "Epoch [18/50], Step [721/735], Loss: 0.1597\n",
      "Epoch [18/50], Step [722/735], Loss: 0.2569\n",
      "Epoch [18/50], Step [723/735], Loss: 0.0899\n",
      "Epoch [18/50], Step [724/735], Loss: 0.0909\n",
      "Epoch [18/50], Step [725/735], Loss: 0.0985\n",
      "Epoch [18/50], Step [726/735], Loss: 0.4538\n",
      "Epoch [18/50], Step [727/735], Loss: 0.0679\n",
      "Epoch [18/50], Step [728/735], Loss: 0.0558\n",
      "Epoch [18/50], Step [729/735], Loss: 0.1828\n",
      "Epoch [18/50], Step [730/735], Loss: 0.1638\n",
      "Epoch [18/50], Step [731/735], Loss: 0.2463\n",
      "Epoch [18/50], Step [732/735], Loss: 0.8996\n",
      "Epoch [18/50], Step [733/735], Loss: 0.6971\n",
      "Epoch [18/50], Step [734/735], Loss: 0.0681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Step [735/735], Loss: 0.3285\n",
      "Epoch [19/50], Step [1/735], Loss: 0.1971\n",
      "Epoch [19/50], Step [2/735], Loss: 0.1614\n",
      "Epoch [19/50], Step [3/735], Loss: 0.1323\n",
      "Epoch [19/50], Step [4/735], Loss: 0.1008\n",
      "Epoch [19/50], Step [5/735], Loss: 0.2951\n",
      "Epoch [19/50], Step [6/735], Loss: 0.0617\n",
      "Epoch [19/50], Step [7/735], Loss: 0.1764\n",
      "Epoch [19/50], Step [8/735], Loss: 0.1085\n",
      "Epoch [19/50], Step [9/735], Loss: 0.1243\n",
      "Epoch [19/50], Step [10/735], Loss: 0.2259\n",
      "Epoch [19/50], Step [11/735], Loss: 0.0440\n",
      "Epoch [19/50], Step [12/735], Loss: 0.1435\n",
      "Epoch [19/50], Step [13/735], Loss: 0.1785\n",
      "Epoch [19/50], Step [14/735], Loss: 0.2339\n",
      "Epoch [19/50], Step [15/735], Loss: 0.1446\n",
      "Epoch [19/50], Step [16/735], Loss: 0.1185\n",
      "Epoch [19/50], Step [17/735], Loss: 0.5748\n",
      "Epoch [19/50], Step [18/735], Loss: 0.1117\n",
      "Epoch [19/50], Step [19/735], Loss: 0.1602\n",
      "Epoch [19/50], Step [20/735], Loss: 0.0695\n",
      "Epoch [19/50], Step [21/735], Loss: 0.1466\n",
      "Epoch [19/50], Step [22/735], Loss: 0.1081\n",
      "Epoch [19/50], Step [23/735], Loss: 0.1654\n",
      "Epoch [19/50], Step [24/735], Loss: 0.0669\n",
      "Epoch [19/50], Step [25/735], Loss: 0.0382\n",
      "Epoch [19/50], Step [26/735], Loss: 0.1865\n",
      "Epoch [19/50], Step [27/735], Loss: 0.0433\n",
      "Epoch [19/50], Step [28/735], Loss: 0.1181\n",
      "Epoch [19/50], Step [29/735], Loss: 0.0889\n",
      "Epoch [19/50], Step [30/735], Loss: 0.2373\n",
      "Epoch [19/50], Step [31/735], Loss: 0.2887\n",
      "Epoch [19/50], Step [32/735], Loss: 0.2005\n",
      "Epoch [19/50], Step [33/735], Loss: 0.1090\n",
      "Epoch [19/50], Step [34/735], Loss: 0.2360\n",
      "Epoch [19/50], Step [35/735], Loss: 0.0771\n",
      "Epoch [19/50], Step [36/735], Loss: 0.1677\n",
      "Epoch [19/50], Step [37/735], Loss: 0.1327\n",
      "Epoch [19/50], Step [38/735], Loss: 0.4850\n",
      "Epoch [19/50], Step [39/735], Loss: 0.1131\n",
      "Epoch [19/50], Step [40/735], Loss: 0.1048\n",
      "Epoch [19/50], Step [41/735], Loss: 0.1000\n",
      "Epoch [19/50], Step [42/735], Loss: 0.1504\n",
      "Epoch [19/50], Step [43/735], Loss: 0.1077\n",
      "Epoch [19/50], Step [44/735], Loss: 0.0806\n",
      "Epoch [19/50], Step [45/735], Loss: 0.1725\n",
      "Epoch [19/50], Step [46/735], Loss: 0.2745\n",
      "Epoch [19/50], Step [47/735], Loss: 0.1456\n",
      "Epoch [19/50], Step [48/735], Loss: 0.2715\n",
      "Epoch [19/50], Step [49/735], Loss: 0.1400\n",
      "Epoch [19/50], Step [50/735], Loss: 0.1641\n",
      "Epoch [19/50], Step [51/735], Loss: 0.1030\n",
      "Epoch [19/50], Step [52/735], Loss: 0.0684\n",
      "Epoch [19/50], Step [53/735], Loss: 1.1353\n",
      "Epoch [19/50], Step [54/735], Loss: 0.2187\n",
      "Epoch [19/50], Step [55/735], Loss: 0.1440\n",
      "Epoch [19/50], Step [56/735], Loss: 0.0960\n",
      "Epoch [19/50], Step [57/735], Loss: 0.2424\n",
      "Epoch [19/50], Step [58/735], Loss: 0.1108\n",
      "Epoch [19/50], Step [59/735], Loss: 0.0524\n",
      "Epoch [19/50], Step [60/735], Loss: 0.1299\n",
      "Epoch [19/50], Step [61/735], Loss: 0.1000\n",
      "Epoch [19/50], Step [62/735], Loss: 0.2090\n",
      "Epoch [19/50], Step [63/735], Loss: 0.0528\n",
      "Epoch [19/50], Step [64/735], Loss: 0.1007\n",
      "Epoch [19/50], Step [65/735], Loss: 0.0409\n",
      "Epoch [19/50], Step [66/735], Loss: 0.0639\n",
      "Epoch [19/50], Step [67/735], Loss: 0.0522\n",
      "Epoch [19/50], Step [68/735], Loss: 0.2989\n",
      "Epoch [19/50], Step [69/735], Loss: 0.2307\n",
      "Epoch [19/50], Step [70/735], Loss: 0.2302\n",
      "Epoch [19/50], Step [71/735], Loss: 0.0600\n",
      "Epoch [19/50], Step [72/735], Loss: 0.0406\n",
      "Epoch [19/50], Step [73/735], Loss: 0.1252\n",
      "Epoch [19/50], Step [74/735], Loss: 0.0838\n",
      "Epoch [19/50], Step [75/735], Loss: 0.2190\n",
      "Epoch [19/50], Step [76/735], Loss: 0.2138\n",
      "Epoch [19/50], Step [77/735], Loss: 0.0853\n",
      "Epoch [19/50], Step [78/735], Loss: 0.0502\n",
      "Epoch [19/50], Step [79/735], Loss: 0.0566\n",
      "Epoch [19/50], Step [80/735], Loss: 0.0993\n",
      "Epoch [19/50], Step [81/735], Loss: 0.2563\n",
      "Epoch [19/50], Step [82/735], Loss: 0.1417\n",
      "Epoch [19/50], Step [83/735], Loss: 0.1240\n",
      "Epoch [19/50], Step [84/735], Loss: 0.0875\n",
      "Epoch [19/50], Step [85/735], Loss: 0.0594\n",
      "Epoch [19/50], Step [86/735], Loss: 0.2445\n",
      "Epoch [19/50], Step [87/735], Loss: 0.0839\n",
      "Epoch [19/50], Step [88/735], Loss: 0.5234\n",
      "Epoch [19/50], Step [89/735], Loss: 0.1695\n",
      "Epoch [19/50], Step [90/735], Loss: 0.0871\n",
      "Epoch [19/50], Step [91/735], Loss: 0.0571\n",
      "Epoch [19/50], Step [92/735], Loss: 0.0861\n",
      "Epoch [19/50], Step [93/735], Loss: 0.2019\n",
      "Epoch [19/50], Step [94/735], Loss: 0.0900\n",
      "Epoch [19/50], Step [95/735], Loss: 0.3259\n",
      "Epoch [19/50], Step [96/735], Loss: 0.2035\n",
      "Epoch [19/50], Step [97/735], Loss: 0.1104\n",
      "Epoch [19/50], Step [98/735], Loss: 0.2715\n",
      "Epoch [19/50], Step [99/735], Loss: 0.1824\n",
      "Epoch [19/50], Step [100/735], Loss: 0.4638\n",
      "Epoch [19/50], Step [101/735], Loss: 0.1315\n",
      "Epoch [19/50], Step [102/735], Loss: 0.1359\n",
      "Epoch [19/50], Step [103/735], Loss: 0.6435\n",
      "Epoch [19/50], Step [104/735], Loss: 0.1406\n",
      "Epoch [19/50], Step [105/735], Loss: 0.0478\n",
      "Epoch [19/50], Step [106/735], Loss: 1.2792\n",
      "Epoch [19/50], Step [107/735], Loss: 1.1545\n",
      "Epoch [19/50], Step [108/735], Loss: 0.1948\n",
      "Epoch [19/50], Step [109/735], Loss: 0.0811\n",
      "Epoch [19/50], Step [110/735], Loss: 0.0632\n",
      "Epoch [19/50], Step [111/735], Loss: 0.1251\n",
      "Epoch [19/50], Step [112/735], Loss: 0.1399\n",
      "Epoch [19/50], Step [113/735], Loss: 0.1245\n",
      "Epoch [19/50], Step [114/735], Loss: 0.0520\n",
      "Epoch [19/50], Step [115/735], Loss: 0.2456\n",
      "Epoch [19/50], Step [116/735], Loss: 0.1162\n",
      "Epoch [19/50], Step [117/735], Loss: 0.0668\n",
      "Epoch [19/50], Step [118/735], Loss: 0.2021\n",
      "Epoch [19/50], Step [119/735], Loss: 0.1176\n",
      "Epoch [19/50], Step [120/735], Loss: 0.2276\n",
      "Epoch [19/50], Step [121/735], Loss: 0.0683\n",
      "Epoch [19/50], Step [122/735], Loss: 1.9553\n",
      "Epoch [19/50], Step [123/735], Loss: 0.0724\n",
      "Epoch [19/50], Step [124/735], Loss: 0.4891\n",
      "Epoch [19/50], Step [125/735], Loss: 0.1516\n",
      "Epoch [19/50], Step [126/735], Loss: 0.4107\n",
      "Epoch [19/50], Step [127/735], Loss: 0.3715\n",
      "Epoch [19/50], Step [128/735], Loss: 0.0999\n",
      "Epoch [19/50], Step [129/735], Loss: 1.7729\n",
      "Epoch [19/50], Step [130/735], Loss: 0.2971\n",
      "Epoch [19/50], Step [131/735], Loss: 0.0614\n",
      "Epoch [19/50], Step [132/735], Loss: 0.5507\n",
      "Epoch [19/50], Step [133/735], Loss: 0.1432\n",
      "Epoch [19/50], Step [134/735], Loss: 0.0553\n",
      "Epoch [19/50], Step [135/735], Loss: 1.2000\n",
      "Epoch [19/50], Step [136/735], Loss: 0.5962\n",
      "Epoch [19/50], Step [137/735], Loss: 0.1203\n",
      "Epoch [19/50], Step [138/735], Loss: 0.0987\n",
      "Epoch [19/50], Step [139/735], Loss: 0.2278\n",
      "Epoch [19/50], Step [140/735], Loss: 0.1272\n",
      "Epoch [19/50], Step [141/735], Loss: 0.1066\n",
      "Epoch [19/50], Step [142/735], Loss: 0.0818\n",
      "Epoch [19/50], Step [143/735], Loss: 0.3986\n",
      "Epoch [19/50], Step [144/735], Loss: 0.0752\n",
      "Epoch [19/50], Step [145/735], Loss: 0.0898\n",
      "Epoch [19/50], Step [146/735], Loss: 0.1088\n",
      "Epoch [19/50], Step [147/735], Loss: 0.1032\n",
      "Epoch [19/50], Step [148/735], Loss: 0.0792\n",
      "Epoch [19/50], Step [149/735], Loss: 0.1381\n",
      "Epoch [19/50], Step [150/735], Loss: 0.1065\n",
      "Epoch [19/50], Step [151/735], Loss: 0.2360\n",
      "Epoch [19/50], Step [152/735], Loss: 0.1573\n",
      "Epoch [19/50], Step [153/735], Loss: 0.3615\n",
      "Epoch [19/50], Step [154/735], Loss: 0.1045\n",
      "Epoch [19/50], Step [155/735], Loss: 0.1456\n",
      "Epoch [19/50], Step [156/735], Loss: 0.2447\n",
      "Epoch [19/50], Step [157/735], Loss: 0.2606\n",
      "Epoch [19/50], Step [158/735], Loss: 0.1336\n",
      "Epoch [19/50], Step [159/735], Loss: 0.4369\n",
      "Epoch [19/50], Step [160/735], Loss: 0.2480\n",
      "Epoch [19/50], Step [161/735], Loss: 0.0724\n",
      "Epoch [19/50], Step [162/735], Loss: 0.0691\n",
      "Epoch [19/50], Step [163/735], Loss: 0.8370\n",
      "Epoch [19/50], Step [164/735], Loss: 1.8908\n",
      "Epoch [19/50], Step [165/735], Loss: 0.0696\n",
      "Epoch [19/50], Step [166/735], Loss: 0.3637\n",
      "Epoch [19/50], Step [167/735], Loss: 0.2043\n",
      "Epoch [19/50], Step [168/735], Loss: 0.0831\n",
      "Epoch [19/50], Step [169/735], Loss: 0.2453\n",
      "Epoch [19/50], Step [170/735], Loss: 0.3284\n",
      "Epoch [19/50], Step [171/735], Loss: 0.1366\n",
      "Epoch [19/50], Step [172/735], Loss: 0.1527\n",
      "Epoch [19/50], Step [173/735], Loss: 0.0629\n",
      "Epoch [19/50], Step [174/735], Loss: 0.0843\n",
      "Epoch [19/50], Step [175/735], Loss: 0.2438\n",
      "Epoch [19/50], Step [176/735], Loss: 0.0736\n",
      "Epoch [19/50], Step [177/735], Loss: 0.0400\n",
      "Epoch [19/50], Step [178/735], Loss: 0.2068\n",
      "Epoch [19/50], Step [179/735], Loss: 0.1265\n",
      "Epoch [19/50], Step [180/735], Loss: 0.0609\n",
      "Epoch [19/50], Step [181/735], Loss: 0.1686\n",
      "Epoch [19/50], Step [182/735], Loss: 0.0762\n",
      "Epoch [19/50], Step [183/735], Loss: 0.1736\n",
      "Epoch [19/50], Step [184/735], Loss: 0.0688\n",
      "Epoch [19/50], Step [185/735], Loss: 0.5745\n",
      "Epoch [19/50], Step [186/735], Loss: 0.0378\n",
      "Epoch [19/50], Step [187/735], Loss: 0.1378\n",
      "Epoch [19/50], Step [188/735], Loss: 0.2119\n",
      "Epoch [19/50], Step [189/735], Loss: 0.0731\n",
      "Epoch [19/50], Step [190/735], Loss: 0.1194\n",
      "Epoch [19/50], Step [191/735], Loss: 0.3203\n",
      "Epoch [19/50], Step [192/735], Loss: 0.3106\n",
      "Epoch [19/50], Step [193/735], Loss: 0.0864\n",
      "Epoch [19/50], Step [194/735], Loss: 0.1422\n",
      "Epoch [19/50], Step [195/735], Loss: 0.1631\n",
      "Epoch [19/50], Step [196/735], Loss: 0.1204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Step [197/735], Loss: 0.1024\n",
      "Epoch [19/50], Step [198/735], Loss: 0.0379\n",
      "Epoch [19/50], Step [199/735], Loss: 0.1901\n",
      "Epoch [19/50], Step [200/735], Loss: 0.7553\n",
      "Epoch [19/50], Step [201/735], Loss: 0.1647\n",
      "Epoch [19/50], Step [202/735], Loss: 0.1568\n",
      "Epoch [19/50], Step [203/735], Loss: 0.1021\n",
      "Epoch [19/50], Step [204/735], Loss: 0.1139\n",
      "Epoch [19/50], Step [205/735], Loss: 0.6485\n",
      "Epoch [19/50], Step [206/735], Loss: 0.2212\n",
      "Epoch [19/50], Step [207/735], Loss: 0.5741\n",
      "Epoch [19/50], Step [208/735], Loss: 0.1346\n",
      "Epoch [19/50], Step [209/735], Loss: 0.0590\n",
      "Epoch [19/50], Step [210/735], Loss: 0.1869\n",
      "Epoch [19/50], Step [211/735], Loss: 0.0660\n",
      "Epoch [19/50], Step [212/735], Loss: 0.1228\n",
      "Epoch [19/50], Step [213/735], Loss: 0.0926\n",
      "Epoch [19/50], Step [214/735], Loss: 0.1383\n",
      "Epoch [19/50], Step [215/735], Loss: 0.0708\n",
      "Epoch [19/50], Step [216/735], Loss: 0.2493\n",
      "Epoch [19/50], Step [217/735], Loss: 0.1470\n",
      "Epoch [19/50], Step [218/735], Loss: 0.1780\n",
      "Epoch [19/50], Step [219/735], Loss: 0.2719\n",
      "Epoch [19/50], Step [220/735], Loss: 0.2149\n",
      "Epoch [19/50], Step [221/735], Loss: 0.1428\n",
      "Epoch [19/50], Step [222/735], Loss: 0.1267\n",
      "Epoch [19/50], Step [223/735], Loss: 0.0684\n",
      "Epoch [19/50], Step [224/735], Loss: 0.1187\n",
      "Epoch [19/50], Step [225/735], Loss: 0.1369\n",
      "Epoch [19/50], Step [226/735], Loss: 0.1297\n",
      "Epoch [19/50], Step [227/735], Loss: 0.0908\n",
      "Epoch [19/50], Step [228/735], Loss: 0.0744\n",
      "Epoch [19/50], Step [229/735], Loss: 0.2445\n",
      "Epoch [19/50], Step [230/735], Loss: 0.0965\n",
      "Epoch [19/50], Step [231/735], Loss: 0.1516\n",
      "Epoch [19/50], Step [232/735], Loss: 0.5000\n",
      "Epoch [19/50], Step [233/735], Loss: 0.2838\n",
      "Epoch [19/50], Step [234/735], Loss: 0.2084\n",
      "Epoch [19/50], Step [235/735], Loss: 0.8926\n",
      "Epoch [19/50], Step [236/735], Loss: 0.0673\n",
      "Epoch [19/50], Step [237/735], Loss: 0.2694\n",
      "Epoch [19/50], Step [238/735], Loss: 0.2006\n",
      "Epoch [19/50], Step [239/735], Loss: 0.2335\n",
      "Epoch [19/50], Step [240/735], Loss: 0.0895\n",
      "Epoch [19/50], Step [241/735], Loss: 0.2397\n",
      "Epoch [19/50], Step [242/735], Loss: 0.3887\n",
      "Epoch [19/50], Step [243/735], Loss: 0.0869\n",
      "Epoch [19/50], Step [244/735], Loss: 0.0563\n",
      "Epoch [19/50], Step [245/735], Loss: 0.1374\n",
      "Epoch [19/50], Step [246/735], Loss: 0.2788\n",
      "Epoch [19/50], Step [247/735], Loss: 0.1520\n",
      "Epoch [19/50], Step [248/735], Loss: 0.2292\n",
      "Epoch [19/50], Step [249/735], Loss: 0.0567\n",
      "Epoch [19/50], Step [250/735], Loss: 0.0879\n",
      "Epoch [19/50], Step [251/735], Loss: 0.1419\n",
      "Epoch [19/50], Step [252/735], Loss: 0.2019\n",
      "Epoch [19/50], Step [253/735], Loss: 0.2067\n",
      "Epoch [19/50], Step [254/735], Loss: 0.0865\n",
      "Epoch [19/50], Step [255/735], Loss: 0.0520\n",
      "Epoch [19/50], Step [256/735], Loss: 0.0561\n",
      "Epoch [19/50], Step [257/735], Loss: 0.3125\n",
      "Epoch [19/50], Step [258/735], Loss: 0.0995\n",
      "Epoch [19/50], Step [259/735], Loss: 0.1948\n",
      "Epoch [19/50], Step [260/735], Loss: 0.1501\n",
      "Epoch [19/50], Step [261/735], Loss: 0.0728\n",
      "Epoch [19/50], Step [262/735], Loss: 0.1344\n",
      "Epoch [19/50], Step [263/735], Loss: 0.1028\n",
      "Epoch [19/50], Step [264/735], Loss: 0.2973\n",
      "Epoch [19/50], Step [265/735], Loss: 0.2117\n",
      "Epoch [19/50], Step [266/735], Loss: 0.2477\n",
      "Epoch [19/50], Step [267/735], Loss: 0.0739\n",
      "Epoch [19/50], Step [268/735], Loss: 0.1085\n",
      "Epoch [19/50], Step [269/735], Loss: 0.0895\n",
      "Epoch [19/50], Step [270/735], Loss: 0.2723\n",
      "Epoch [19/50], Step [271/735], Loss: 0.1232\n",
      "Epoch [19/50], Step [272/735], Loss: 0.1323\n",
      "Epoch [19/50], Step [273/735], Loss: 0.0510\n",
      "Epoch [19/50], Step [274/735], Loss: 0.2171\n",
      "Epoch [19/50], Step [275/735], Loss: 0.1834\n",
      "Epoch [19/50], Step [276/735], Loss: 0.1031\n",
      "Epoch [19/50], Step [277/735], Loss: 0.1375\n",
      "Epoch [19/50], Step [278/735], Loss: 0.1544\n",
      "Epoch [19/50], Step [279/735], Loss: 0.2356\n",
      "Epoch [19/50], Step [280/735], Loss: 0.2000\n",
      "Epoch [19/50], Step [281/735], Loss: 0.1325\n",
      "Epoch [19/50], Step [282/735], Loss: 0.7334\n",
      "Epoch [19/50], Step [283/735], Loss: 0.4777\n",
      "Epoch [19/50], Step [284/735], Loss: 0.1042\n",
      "Epoch [19/50], Step [285/735], Loss: 0.1260\n",
      "Epoch [19/50], Step [286/735], Loss: 0.0920\n",
      "Epoch [19/50], Step [287/735], Loss: 0.0799\n",
      "Epoch [19/50], Step [288/735], Loss: 0.3486\n",
      "Epoch [19/50], Step [289/735], Loss: 0.3261\n",
      "Epoch [19/50], Step [290/735], Loss: 0.2006\n",
      "Epoch [19/50], Step [291/735], Loss: 0.1092\n",
      "Epoch [19/50], Step [292/735], Loss: 0.1206\n",
      "Epoch [19/50], Step [293/735], Loss: 0.2004\n",
      "Epoch [19/50], Step [294/735], Loss: 0.2138\n",
      "Epoch [19/50], Step [295/735], Loss: 0.1359\n",
      "Epoch [19/50], Step [296/735], Loss: 0.1170\n",
      "Epoch [19/50], Step [297/735], Loss: 0.1537\n",
      "Epoch [19/50], Step [298/735], Loss: 0.2727\n",
      "Epoch [19/50], Step [299/735], Loss: 0.1303\n",
      "Epoch [19/50], Step [300/735], Loss: 0.3032\n",
      "Epoch [19/50], Step [301/735], Loss: 0.3140\n",
      "Epoch [19/50], Step [302/735], Loss: 0.1801\n",
      "Epoch [19/50], Step [303/735], Loss: 0.1422\n",
      "Epoch [19/50], Step [304/735], Loss: 0.1521\n",
      "Epoch [19/50], Step [305/735], Loss: 0.8820\n",
      "Epoch [19/50], Step [306/735], Loss: 0.2139\n",
      "Epoch [19/50], Step [307/735], Loss: 0.1343\n",
      "Epoch [19/50], Step [308/735], Loss: 0.0875\n",
      "Epoch [19/50], Step [309/735], Loss: 0.4243\n",
      "Epoch [19/50], Step [310/735], Loss: 0.1210\n",
      "Epoch [19/50], Step [311/735], Loss: 0.1404\n",
      "Epoch [19/50], Step [312/735], Loss: 0.3152\n",
      "Epoch [19/50], Step [313/735], Loss: 0.1092\n",
      "Epoch [19/50], Step [314/735], Loss: 0.0500\n",
      "Epoch [19/50], Step [315/735], Loss: 0.0886\n",
      "Epoch [19/50], Step [316/735], Loss: 1.1210\n",
      "Epoch [19/50], Step [317/735], Loss: 0.2084\n",
      "Epoch [19/50], Step [318/735], Loss: 0.1700\n",
      "Epoch [19/50], Step [319/735], Loss: 0.1392\n",
      "Epoch [19/50], Step [320/735], Loss: 0.2229\n",
      "Epoch [19/50], Step [321/735], Loss: 0.2337\n",
      "Epoch [19/50], Step [322/735], Loss: 0.2416\n",
      "Epoch [19/50], Step [323/735], Loss: 0.2713\n",
      "Epoch [19/50], Step [324/735], Loss: 0.1005\n",
      "Epoch [19/50], Step [325/735], Loss: 0.1506\n",
      "Epoch [19/50], Step [326/735], Loss: 0.0445\n",
      "Epoch [19/50], Step [327/735], Loss: 0.0982\n",
      "Epoch [19/50], Step [328/735], Loss: 0.2141\n",
      "Epoch [19/50], Step [329/735], Loss: 0.4506\n",
      "Epoch [19/50], Step [330/735], Loss: 0.5185\n",
      "Epoch [19/50], Step [331/735], Loss: 0.0971\n",
      "Epoch [19/50], Step [332/735], Loss: 0.5198\n",
      "Epoch [19/50], Step [333/735], Loss: 0.2053\n",
      "Epoch [19/50], Step [334/735], Loss: 0.0515\n",
      "Epoch [19/50], Step [335/735], Loss: 0.1144\n",
      "Epoch [19/50], Step [336/735], Loss: 0.1686\n",
      "Epoch [19/50], Step [337/735], Loss: 0.1225\n",
      "Epoch [19/50], Step [338/735], Loss: 0.4765\n",
      "Epoch [19/50], Step [339/735], Loss: 0.1171\n",
      "Epoch [19/50], Step [340/735], Loss: 0.0914\n",
      "Epoch [19/50], Step [341/735], Loss: 0.1232\n",
      "Epoch [19/50], Step [342/735], Loss: 0.1220\n",
      "Epoch [19/50], Step [343/735], Loss: 0.0389\n",
      "Epoch [19/50], Step [344/735], Loss: 0.0806\n",
      "Epoch [19/50], Step [345/735], Loss: 0.0484\n",
      "Epoch [19/50], Step [346/735], Loss: 0.1981\n",
      "Epoch [19/50], Step [347/735], Loss: 0.0747\n",
      "Epoch [19/50], Step [348/735], Loss: 0.6442\n",
      "Epoch [19/50], Step [349/735], Loss: 0.1273\n",
      "Epoch [19/50], Step [350/735], Loss: 0.2716\n",
      "Epoch [19/50], Step [351/735], Loss: 0.0734\n",
      "Epoch [19/50], Step [352/735], Loss: 1.1045\n",
      "Epoch [19/50], Step [353/735], Loss: 0.4606\n",
      "Epoch [19/50], Step [354/735], Loss: 0.0554\n",
      "Epoch [19/50], Step [355/735], Loss: 0.1768\n",
      "Epoch [19/50], Step [356/735], Loss: 0.0989\n",
      "Epoch [19/50], Step [357/735], Loss: 0.1514\n",
      "Epoch [19/50], Step [358/735], Loss: 0.0584\n",
      "Epoch [19/50], Step [359/735], Loss: 0.0447\n",
      "Epoch [19/50], Step [360/735], Loss: 0.1140\n",
      "Epoch [19/50], Step [361/735], Loss: 0.2125\n",
      "Epoch [19/50], Step [362/735], Loss: 0.2383\n",
      "Epoch [19/50], Step [363/735], Loss: 0.0796\n",
      "Epoch [19/50], Step [364/735], Loss: 0.1921\n",
      "Epoch [19/50], Step [365/735], Loss: 0.0987\n",
      "Epoch [19/50], Step [366/735], Loss: 0.1178\n",
      "Epoch [19/50], Step [367/735], Loss: 0.1335\n",
      "Epoch [19/50], Step [368/735], Loss: 0.1637\n",
      "Epoch [19/50], Step [369/735], Loss: 0.1462\n",
      "Epoch [19/50], Step [370/735], Loss: 0.7128\n",
      "Epoch [19/50], Step [371/735], Loss: 0.0972\n",
      "Epoch [19/50], Step [372/735], Loss: 0.2041\n",
      "Epoch [19/50], Step [373/735], Loss: 0.0751\n",
      "Epoch [19/50], Step [374/735], Loss: 0.2693\n",
      "Epoch [19/50], Step [375/735], Loss: 0.1167\n",
      "Epoch [19/50], Step [376/735], Loss: 0.0583\n",
      "Epoch [19/50], Step [377/735], Loss: 0.1121\n",
      "Epoch [19/50], Step [378/735], Loss: 0.0564\n",
      "Epoch [19/50], Step [379/735], Loss: 0.5186\n",
      "Epoch [19/50], Step [380/735], Loss: 0.0835\n",
      "Epoch [19/50], Step [381/735], Loss: 0.1194\n",
      "Epoch [19/50], Step [382/735], Loss: 0.0957\n",
      "Epoch [19/50], Step [383/735], Loss: 0.1038\n",
      "Epoch [19/50], Step [384/735], Loss: 0.1244\n",
      "Epoch [19/50], Step [385/735], Loss: 0.2300\n",
      "Epoch [19/50], Step [386/735], Loss: 0.0779\n",
      "Epoch [19/50], Step [387/735], Loss: 0.1016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Step [388/735], Loss: 0.1202\n",
      "Epoch [19/50], Step [389/735], Loss: 0.1264\n",
      "Epoch [19/50], Step [390/735], Loss: 0.1231\n",
      "Epoch [19/50], Step [391/735], Loss: 0.0866\n",
      "Epoch [19/50], Step [392/735], Loss: 0.0756\n",
      "Epoch [19/50], Step [393/735], Loss: 0.1785\n",
      "Epoch [19/50], Step [394/735], Loss: 0.3164\n",
      "Epoch [19/50], Step [395/735], Loss: 0.0978\n",
      "Epoch [19/50], Step [396/735], Loss: 0.0422\n",
      "Epoch [19/50], Step [397/735], Loss: 0.3386\n",
      "Epoch [19/50], Step [398/735], Loss: 0.1883\n",
      "Epoch [19/50], Step [399/735], Loss: 0.2922\n",
      "Epoch [19/50], Step [400/735], Loss: 0.2341\n",
      "Epoch [19/50], Step [401/735], Loss: 0.0878\n",
      "Epoch [19/50], Step [402/735], Loss: 0.3896\n",
      "Epoch [19/50], Step [403/735], Loss: 0.1807\n",
      "Epoch [19/50], Step [404/735], Loss: 0.1708\n",
      "Epoch [19/50], Step [405/735], Loss: 0.0975\n",
      "Epoch [19/50], Step [406/735], Loss: 0.1554\n",
      "Epoch [19/50], Step [407/735], Loss: 0.0655\n",
      "Epoch [19/50], Step [408/735], Loss: 0.4607\n",
      "Epoch [19/50], Step [409/735], Loss: 0.2362\n",
      "Epoch [19/50], Step [410/735], Loss: 0.3573\n",
      "Epoch [19/50], Step [411/735], Loss: 0.1037\n",
      "Epoch [19/50], Step [412/735], Loss: 0.1504\n",
      "Epoch [19/50], Step [413/735], Loss: 0.1584\n",
      "Epoch [19/50], Step [414/735], Loss: 0.1272\n",
      "Epoch [19/50], Step [415/735], Loss: 0.4182\n",
      "Epoch [19/50], Step [416/735], Loss: 0.2237\n",
      "Epoch [19/50], Step [417/735], Loss: 0.1040\n",
      "Epoch [19/50], Step [418/735], Loss: 0.0524\n",
      "Epoch [19/50], Step [419/735], Loss: 0.1589\n",
      "Epoch [19/50], Step [420/735], Loss: 0.2234\n",
      "Epoch [19/50], Step [421/735], Loss: 0.1344\n",
      "Epoch [19/50], Step [422/735], Loss: 0.0748\n",
      "Epoch [19/50], Step [423/735], Loss: 0.1322\n",
      "Epoch [19/50], Step [424/735], Loss: 0.3323\n",
      "Epoch [19/50], Step [425/735], Loss: 0.1167\n",
      "Epoch [19/50], Step [426/735], Loss: 0.1952\n",
      "Epoch [19/50], Step [427/735], Loss: 0.2539\n",
      "Epoch [19/50], Step [428/735], Loss: 0.1028\n",
      "Epoch [19/50], Step [429/735], Loss: 0.2213\n",
      "Epoch [19/50], Step [430/735], Loss: 0.1060\n",
      "Epoch [19/50], Step [431/735], Loss: 0.0716\n",
      "Epoch [19/50], Step [432/735], Loss: 0.1061\n",
      "Epoch [19/50], Step [433/735], Loss: 0.0578\n",
      "Epoch [19/50], Step [434/735], Loss: 0.0910\n",
      "Epoch [19/50], Step [435/735], Loss: 0.0812\n",
      "Epoch [19/50], Step [436/735], Loss: 0.1465\n",
      "Epoch [19/50], Step [437/735], Loss: 0.1024\n",
      "Epoch [19/50], Step [438/735], Loss: 0.1515\n",
      "Epoch [19/50], Step [439/735], Loss: 0.1344\n",
      "Epoch [19/50], Step [440/735], Loss: 0.2526\n",
      "Epoch [19/50], Step [441/735], Loss: 0.2703\n",
      "Epoch [19/50], Step [442/735], Loss: 0.1129\n",
      "Epoch [19/50], Step [443/735], Loss: 0.1010\n",
      "Epoch [19/50], Step [444/735], Loss: 2.4945\n",
      "Epoch [19/50], Step [445/735], Loss: 0.2084\n",
      "Epoch [19/50], Step [446/735], Loss: 0.0669\n",
      "Epoch [19/50], Step [447/735], Loss: 0.1246\n",
      "Epoch [19/50], Step [448/735], Loss: 0.1550\n",
      "Epoch [19/50], Step [449/735], Loss: 0.1108\n",
      "Epoch [19/50], Step [450/735], Loss: 0.4478\n",
      "Epoch [19/50], Step [451/735], Loss: 0.1542\n",
      "Epoch [19/50], Step [452/735], Loss: 0.2348\n",
      "Epoch [19/50], Step [453/735], Loss: 0.1430\n",
      "Epoch [19/50], Step [454/735], Loss: 0.0804\n",
      "Epoch [19/50], Step [455/735], Loss: 0.2112\n",
      "Epoch [19/50], Step [456/735], Loss: 0.1234\n",
      "Epoch [19/50], Step [457/735], Loss: 0.1128\n",
      "Epoch [19/50], Step [458/735], Loss: 0.2743\n",
      "Epoch [19/50], Step [459/735], Loss: 0.2400\n",
      "Epoch [19/50], Step [460/735], Loss: 0.2278\n",
      "Epoch [19/50], Step [461/735], Loss: 0.1701\n",
      "Epoch [19/50], Step [462/735], Loss: 0.0990\n",
      "Epoch [19/50], Step [463/735], Loss: 0.0793\n",
      "Epoch [19/50], Step [464/735], Loss: 0.1223\n",
      "Epoch [19/50], Step [465/735], Loss: 0.1418\n",
      "Epoch [19/50], Step [466/735], Loss: 0.0702\n",
      "Epoch [19/50], Step [467/735], Loss: 0.1532\n",
      "Epoch [19/50], Step [468/735], Loss: 1.1890\n",
      "Epoch [19/50], Step [469/735], Loss: 0.1696\n",
      "Epoch [19/50], Step [470/735], Loss: 0.0232\n",
      "Epoch [19/50], Step [471/735], Loss: 0.2915\n",
      "Epoch [19/50], Step [472/735], Loss: 0.0540\n",
      "Epoch [19/50], Step [473/735], Loss: 0.2410\n",
      "Epoch [19/50], Step [474/735], Loss: 0.0985\n",
      "Epoch [19/50], Step [475/735], Loss: 0.1829\n",
      "Epoch [19/50], Step [476/735], Loss: 0.1288\n",
      "Epoch [19/50], Step [477/735], Loss: 0.3101\n",
      "Epoch [19/50], Step [478/735], Loss: 0.0338\n",
      "Epoch [19/50], Step [479/735], Loss: 0.1078\n",
      "Epoch [19/50], Step [480/735], Loss: 0.0844\n",
      "Epoch [19/50], Step [481/735], Loss: 0.1596\n",
      "Epoch [19/50], Step [482/735], Loss: 0.0859\n",
      "Epoch [19/50], Step [483/735], Loss: 0.0863\n",
      "Epoch [19/50], Step [484/735], Loss: 0.0565\n",
      "Epoch [19/50], Step [485/735], Loss: 0.0487\n",
      "Epoch [19/50], Step [486/735], Loss: 0.2393\n",
      "Epoch [19/50], Step [487/735], Loss: 1.8142\n",
      "Epoch [19/50], Step [488/735], Loss: 0.0529\n",
      "Epoch [19/50], Step [489/735], Loss: 0.1415\n",
      "Epoch [19/50], Step [490/735], Loss: 0.1620\n",
      "Epoch [19/50], Step [491/735], Loss: 0.1838\n",
      "Epoch [19/50], Step [492/735], Loss: 0.1079\n",
      "Epoch [19/50], Step [493/735], Loss: 0.1527\n",
      "Epoch [19/50], Step [494/735], Loss: 0.2868\n",
      "Epoch [19/50], Step [495/735], Loss: 0.1820\n",
      "Epoch [19/50], Step [496/735], Loss: 0.0795\n",
      "Epoch [19/50], Step [497/735], Loss: 0.1759\n",
      "Epoch [19/50], Step [498/735], Loss: 0.3502\n",
      "Epoch [19/50], Step [499/735], Loss: 0.2407\n",
      "Epoch [19/50], Step [500/735], Loss: 0.1363\n",
      "Epoch [19/50], Step [501/735], Loss: 0.1993\n",
      "Epoch [19/50], Step [502/735], Loss: 0.1338\n",
      "Epoch [19/50], Step [503/735], Loss: 0.2102\n",
      "Epoch [19/50], Step [504/735], Loss: 0.1115\n",
      "Epoch [19/50], Step [505/735], Loss: 0.0430\n",
      "Epoch [19/50], Step [506/735], Loss: 0.1481\n",
      "Epoch [19/50], Step [507/735], Loss: 0.1464\n",
      "Epoch [19/50], Step [508/735], Loss: 0.0967\n",
      "Epoch [19/50], Step [509/735], Loss: 0.4056\n",
      "Epoch [19/50], Step [510/735], Loss: 0.0941\n",
      "Epoch [19/50], Step [511/735], Loss: 0.0608\n",
      "Epoch [19/50], Step [512/735], Loss: 0.5604\n",
      "Epoch [19/50], Step [513/735], Loss: 0.1206\n",
      "Epoch [19/50], Step [514/735], Loss: 0.1429\n",
      "Epoch [19/50], Step [515/735], Loss: 0.1311\n",
      "Epoch [19/50], Step [516/735], Loss: 0.1215\n",
      "Epoch [19/50], Step [517/735], Loss: 0.0685\n",
      "Epoch [19/50], Step [518/735], Loss: 0.1005\n",
      "Epoch [19/50], Step [519/735], Loss: 0.1526\n",
      "Epoch [19/50], Step [520/735], Loss: 0.0772\n",
      "Epoch [19/50], Step [521/735], Loss: 0.1256\n",
      "Epoch [19/50], Step [522/735], Loss: 0.0584\n",
      "Epoch [19/50], Step [523/735], Loss: 0.1841\n",
      "Epoch [19/50], Step [524/735], Loss: 0.0726\n",
      "Epoch [19/50], Step [525/735], Loss: 0.1188\n",
      "Epoch [19/50], Step [526/735], Loss: 0.0720\n",
      "Epoch [19/50], Step [527/735], Loss: 0.4649\n",
      "Epoch [19/50], Step [528/735], Loss: 0.0802\n",
      "Epoch [19/50], Step [529/735], Loss: 0.1944\n",
      "Epoch [19/50], Step [530/735], Loss: 0.1256\n",
      "Epoch [19/50], Step [531/735], Loss: 0.0644\n",
      "Epoch [19/50], Step [532/735], Loss: 0.1585\n",
      "Epoch [19/50], Step [533/735], Loss: 0.1072\n",
      "Epoch [19/50], Step [534/735], Loss: 0.0586\n",
      "Epoch [19/50], Step [535/735], Loss: 0.0919\n",
      "Epoch [19/50], Step [536/735], Loss: 0.1385\n",
      "Epoch [19/50], Step [537/735], Loss: 0.2920\n",
      "Epoch [19/50], Step [538/735], Loss: 0.0879\n",
      "Epoch [19/50], Step [539/735], Loss: 0.0715\n",
      "Epoch [19/50], Step [540/735], Loss: 0.0663\n",
      "Epoch [19/50], Step [541/735], Loss: 0.0814\n",
      "Epoch [19/50], Step [542/735], Loss: 0.1153\n",
      "Epoch [19/50], Step [543/735], Loss: 0.1076\n",
      "Epoch [19/50], Step [544/735], Loss: 0.4068\n",
      "Epoch [19/50], Step [545/735], Loss: 0.2844\n",
      "Epoch [19/50], Step [546/735], Loss: 0.0923\n",
      "Epoch [19/50], Step [547/735], Loss: 0.0948\n",
      "Epoch [19/50], Step [548/735], Loss: 0.1089\n",
      "Epoch [19/50], Step [549/735], Loss: 0.0750\n",
      "Epoch [19/50], Step [550/735], Loss: 0.0926\n",
      "Epoch [19/50], Step [551/735], Loss: 0.0956\n",
      "Epoch [19/50], Step [552/735], Loss: 0.0639\n",
      "Epoch [19/50], Step [553/735], Loss: 0.1533\n",
      "Epoch [19/50], Step [554/735], Loss: 0.2233\n",
      "Epoch [19/50], Step [555/735], Loss: 0.2136\n",
      "Epoch [19/50], Step [556/735], Loss: 0.1211\n",
      "Epoch [19/50], Step [557/735], Loss: 0.1171\n",
      "Epoch [19/50], Step [558/735], Loss: 0.1807\n",
      "Epoch [19/50], Step [559/735], Loss: 0.0859\n",
      "Epoch [19/50], Step [560/735], Loss: 1.6908\n",
      "Epoch [19/50], Step [561/735], Loss: 0.0939\n",
      "Epoch [19/50], Step [562/735], Loss: 0.3745\n",
      "Epoch [19/50], Step [563/735], Loss: 0.1996\n",
      "Epoch [19/50], Step [564/735], Loss: 0.6230\n",
      "Epoch [19/50], Step [565/735], Loss: 0.0976\n",
      "Epoch [19/50], Step [566/735], Loss: 0.0756\n",
      "Epoch [19/50], Step [567/735], Loss: 0.3005\n",
      "Epoch [19/50], Step [568/735], Loss: 0.9106\n",
      "Epoch [19/50], Step [569/735], Loss: 0.0848\n",
      "Epoch [19/50], Step [570/735], Loss: 0.2313\n",
      "Epoch [19/50], Step [571/735], Loss: 0.1825\n",
      "Epoch [19/50], Step [572/735], Loss: 0.2937\n",
      "Epoch [19/50], Step [573/735], Loss: 0.2584\n",
      "Epoch [19/50], Step [574/735], Loss: 0.1245\n",
      "Epoch [19/50], Step [575/735], Loss: 0.0448\n",
      "Epoch [19/50], Step [576/735], Loss: 0.1319\n",
      "Epoch [19/50], Step [577/735], Loss: 0.2280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Step [578/735], Loss: 0.0681\n",
      "Epoch [19/50], Step [579/735], Loss: 0.1039\n",
      "Epoch [19/50], Step [580/735], Loss: 0.0901\n",
      "Epoch [19/50], Step [581/735], Loss: 0.9567\n",
      "Epoch [19/50], Step [582/735], Loss: 0.8831\n",
      "Epoch [19/50], Step [583/735], Loss: 0.0580\n",
      "Epoch [19/50], Step [584/735], Loss: 0.0625\n",
      "Epoch [19/50], Step [585/735], Loss: 0.2034\n",
      "Epoch [19/50], Step [586/735], Loss: 0.0736\n",
      "Epoch [19/50], Step [587/735], Loss: 1.8755\n",
      "Epoch [19/50], Step [588/735], Loss: 0.1396\n",
      "Epoch [19/50], Step [589/735], Loss: 0.0389\n",
      "Epoch [19/50], Step [590/735], Loss: 0.1305\n",
      "Epoch [19/50], Step [591/735], Loss: 1.3650\n",
      "Epoch [19/50], Step [592/735], Loss: 0.0384\n",
      "Epoch [19/50], Step [593/735], Loss: 0.1175\n",
      "Epoch [19/50], Step [594/735], Loss: 0.1603\n",
      "Epoch [19/50], Step [595/735], Loss: 0.1302\n",
      "Epoch [19/50], Step [596/735], Loss: 0.2339\n",
      "Epoch [19/50], Step [597/735], Loss: 0.2063\n",
      "Epoch [19/50], Step [598/735], Loss: 0.4499\n",
      "Epoch [19/50], Step [599/735], Loss: 0.1228\n",
      "Epoch [19/50], Step [600/735], Loss: 0.2644\n",
      "Epoch [19/50], Step [601/735], Loss: 0.3119\n",
      "Epoch [19/50], Step [602/735], Loss: 0.0803\n",
      "Epoch [19/50], Step [603/735], Loss: 0.4453\n",
      "Epoch [19/50], Step [604/735], Loss: 0.0626\n",
      "Epoch [19/50], Step [605/735], Loss: 0.1113\n",
      "Epoch [19/50], Step [606/735], Loss: 0.5187\n",
      "Epoch [19/50], Step [607/735], Loss: 0.2133\n",
      "Epoch [19/50], Step [608/735], Loss: 0.2433\n",
      "Epoch [19/50], Step [609/735], Loss: 0.1197\n",
      "Epoch [19/50], Step [610/735], Loss: 0.1089\n",
      "Epoch [19/50], Step [611/735], Loss: 0.1636\n",
      "Epoch [19/50], Step [612/735], Loss: 0.1611\n",
      "Epoch [19/50], Step [613/735], Loss: 0.2963\n",
      "Epoch [19/50], Step [614/735], Loss: 0.2493\n",
      "Epoch [19/50], Step [615/735], Loss: 0.1600\n",
      "Epoch [19/50], Step [616/735], Loss: 0.0284\n",
      "Epoch [19/50], Step [617/735], Loss: 0.5199\n",
      "Epoch [19/50], Step [618/735], Loss: 0.1003\n",
      "Epoch [19/50], Step [619/735], Loss: 0.0993\n",
      "Epoch [19/50], Step [620/735], Loss: 0.1872\n",
      "Epoch [19/50], Step [621/735], Loss: 0.9481\n",
      "Epoch [19/50], Step [622/735], Loss: 0.1728\n",
      "Epoch [19/50], Step [623/735], Loss: 0.0555\n",
      "Epoch [19/50], Step [624/735], Loss: 0.2492\n",
      "Epoch [19/50], Step [625/735], Loss: 0.1819\n",
      "Epoch [19/50], Step [626/735], Loss: 0.2315\n",
      "Epoch [19/50], Step [627/735], Loss: 0.1140\n",
      "Epoch [19/50], Step [628/735], Loss: 0.1130\n",
      "Epoch [19/50], Step [629/735], Loss: 0.1802\n",
      "Epoch [19/50], Step [630/735], Loss: 0.1818\n",
      "Epoch [19/50], Step [631/735], Loss: 0.0398\n",
      "Epoch [19/50], Step [632/735], Loss: 0.0802\n",
      "Epoch [19/50], Step [633/735], Loss: 0.2048\n",
      "Epoch [19/50], Step [634/735], Loss: 0.1715\n",
      "Epoch [19/50], Step [635/735], Loss: 0.0484\n",
      "Epoch [19/50], Step [636/735], Loss: 0.1846\n",
      "Epoch [19/50], Step [637/735], Loss: 0.0455\n",
      "Epoch [19/50], Step [638/735], Loss: 0.0651\n",
      "Epoch [19/50], Step [639/735], Loss: 0.1288\n",
      "Epoch [19/50], Step [640/735], Loss: 0.1941\n",
      "Epoch [19/50], Step [641/735], Loss: 0.0727\n",
      "Epoch [19/50], Step [642/735], Loss: 0.0913\n",
      "Epoch [19/50], Step [643/735], Loss: 0.1443\n",
      "Epoch [19/50], Step [644/735], Loss: 0.0586\n",
      "Epoch [19/50], Step [645/735], Loss: 0.1142\n",
      "Epoch [19/50], Step [646/735], Loss: 0.1007\n",
      "Epoch [19/50], Step [647/735], Loss: 0.0608\n",
      "Epoch [19/50], Step [648/735], Loss: 0.1178\n",
      "Epoch [19/50], Step [649/735], Loss: 0.0666\n",
      "Epoch [19/50], Step [650/735], Loss: 0.0998\n",
      "Epoch [19/50], Step [651/735], Loss: 0.0318\n",
      "Epoch [19/50], Step [652/735], Loss: 0.2130\n",
      "Epoch [19/50], Step [653/735], Loss: 0.1426\n",
      "Epoch [19/50], Step [654/735], Loss: 0.1252\n",
      "Epoch [19/50], Step [655/735], Loss: 0.2889\n",
      "Epoch [19/50], Step [656/735], Loss: 0.0578\n",
      "Epoch [19/50], Step [657/735], Loss: 0.2061\n",
      "Epoch [19/50], Step [658/735], Loss: 0.0578\n",
      "Epoch [19/50], Step [659/735], Loss: 0.5437\n",
      "Epoch [19/50], Step [660/735], Loss: 0.0945\n",
      "Epoch [19/50], Step [661/735], Loss: 0.1387\n",
      "Epoch [19/50], Step [662/735], Loss: 0.3520\n",
      "Epoch [19/50], Step [663/735], Loss: 0.1969\n",
      "Epoch [19/50], Step [664/735], Loss: 0.1055\n",
      "Epoch [19/50], Step [665/735], Loss: 0.0697\n",
      "Epoch [19/50], Step [666/735], Loss: 0.1797\n",
      "Epoch [19/50], Step [667/735], Loss: 0.0534\n",
      "Epoch [19/50], Step [668/735], Loss: 0.0900\n",
      "Epoch [19/50], Step [669/735], Loss: 0.1309\n",
      "Epoch [19/50], Step [670/735], Loss: 0.1429\n",
      "Epoch [19/50], Step [671/735], Loss: 0.1490\n",
      "Epoch [19/50], Step [672/735], Loss: 0.1321\n",
      "Epoch [19/50], Step [673/735], Loss: 0.2669\n",
      "Epoch [19/50], Step [674/735], Loss: 0.2579\n",
      "Epoch [19/50], Step [675/735], Loss: 0.1023\n",
      "Epoch [19/50], Step [676/735], Loss: 0.0475\n",
      "Epoch [19/50], Step [677/735], Loss: 0.1240\n",
      "Epoch [19/50], Step [678/735], Loss: 0.0659\n",
      "Epoch [19/50], Step [679/735], Loss: 0.1244\n",
      "Epoch [19/50], Step [680/735], Loss: 0.7365\n",
      "Epoch [19/50], Step [681/735], Loss: 0.0670\n",
      "Epoch [19/50], Step [682/735], Loss: 0.1082\n",
      "Epoch [19/50], Step [683/735], Loss: 0.3536\n",
      "Epoch [19/50], Step [684/735], Loss: 0.3221\n",
      "Epoch [19/50], Step [685/735], Loss: 0.2426\n",
      "Epoch [19/50], Step [686/735], Loss: 0.1399\n",
      "Epoch [19/50], Step [687/735], Loss: 0.1744\n",
      "Epoch [19/50], Step [688/735], Loss: 0.1210\n",
      "Epoch [19/50], Step [689/735], Loss: 0.1413\n",
      "Epoch [19/50], Step [690/735], Loss: 0.0825\n",
      "Epoch [19/50], Step [691/735], Loss: 0.0961\n",
      "Epoch [19/50], Step [692/735], Loss: 0.1286\n",
      "Epoch [19/50], Step [693/735], Loss: 0.0764\n",
      "Epoch [19/50], Step [694/735], Loss: 0.1485\n",
      "Epoch [19/50], Step [695/735], Loss: 0.2986\n",
      "Epoch [19/50], Step [696/735], Loss: 0.3386\n",
      "Epoch [19/50], Step [697/735], Loss: 0.0493\n",
      "Epoch [19/50], Step [698/735], Loss: 0.1754\n",
      "Epoch [19/50], Step [699/735], Loss: 0.0969\n",
      "Epoch [19/50], Step [700/735], Loss: 0.1627\n",
      "Epoch [19/50], Step [701/735], Loss: 0.0988\n",
      "Epoch [19/50], Step [702/735], Loss: 0.1486\n",
      "Epoch [19/50], Step [703/735], Loss: 0.8916\n",
      "Epoch [19/50], Step [704/735], Loss: 0.2526\n",
      "Epoch [19/50], Step [705/735], Loss: 0.1099\n",
      "Epoch [19/50], Step [706/735], Loss: 0.1552\n",
      "Epoch [19/50], Step [707/735], Loss: 0.0817\n",
      "Epoch [19/50], Step [708/735], Loss: 0.4769\n",
      "Epoch [19/50], Step [709/735], Loss: 0.1455\n",
      "Epoch [19/50], Step [710/735], Loss: 0.3322\n",
      "Epoch [19/50], Step [711/735], Loss: 0.3088\n",
      "Epoch [19/50], Step [712/735], Loss: 0.1628\n",
      "Epoch [19/50], Step [713/735], Loss: 0.2448\n",
      "Epoch [19/50], Step [714/735], Loss: 0.0908\n",
      "Epoch [19/50], Step [715/735], Loss: 0.1726\n",
      "Epoch [19/50], Step [716/735], Loss: 0.1286\n",
      "Epoch [19/50], Step [717/735], Loss: 0.1054\n",
      "Epoch [19/50], Step [718/735], Loss: 0.0562\n",
      "Epoch [19/50], Step [719/735], Loss: 0.7137\n",
      "Epoch [19/50], Step [720/735], Loss: 0.1527\n",
      "Epoch [19/50], Step [721/735], Loss: 0.1104\n",
      "Epoch [19/50], Step [722/735], Loss: 0.1163\n",
      "Epoch [19/50], Step [723/735], Loss: 0.0953\n",
      "Epoch [19/50], Step [724/735], Loss: 0.2075\n",
      "Epoch [19/50], Step [725/735], Loss: 0.1295\n",
      "Epoch [19/50], Step [726/735], Loss: 0.0512\n",
      "Epoch [19/50], Step [727/735], Loss: 0.2316\n",
      "Epoch [19/50], Step [728/735], Loss: 1.0250\n",
      "Epoch [19/50], Step [729/735], Loss: 0.1388\n",
      "Epoch [19/50], Step [730/735], Loss: 0.0774\n",
      "Epoch [19/50], Step [731/735], Loss: 0.0858\n",
      "Epoch [19/50], Step [732/735], Loss: 0.0750\n",
      "Epoch [19/50], Step [733/735], Loss: 0.7851\n",
      "Epoch [19/50], Step [734/735], Loss: 0.3587\n",
      "Epoch [19/50], Step [735/735], Loss: 0.0310\n",
      "Epoch [20/50], Step [1/735], Loss: 0.0554\n",
      "Epoch [20/50], Step [2/735], Loss: 0.1139\n",
      "Epoch [20/50], Step [3/735], Loss: 0.4148\n",
      "Epoch [20/50], Step [4/735], Loss: 0.0784\n",
      "Epoch [20/50], Step [5/735], Loss: 0.1225\n",
      "Epoch [20/50], Step [6/735], Loss: 0.2860\n",
      "Epoch [20/50], Step [7/735], Loss: 0.2204\n",
      "Epoch [20/50], Step [8/735], Loss: 0.1580\n",
      "Epoch [20/50], Step [9/735], Loss: 0.3914\n",
      "Epoch [20/50], Step [10/735], Loss: 0.0966\n",
      "Epoch [20/50], Step [11/735], Loss: 0.1418\n",
      "Epoch [20/50], Step [12/735], Loss: 0.0356\n",
      "Epoch [20/50], Step [13/735], Loss: 0.0977\n",
      "Epoch [20/50], Step [14/735], Loss: 0.2312\n",
      "Epoch [20/50], Step [15/735], Loss: 0.0770\n",
      "Epoch [20/50], Step [16/735], Loss: 0.1082\n",
      "Epoch [20/50], Step [17/735], Loss: 0.0778\n",
      "Epoch [20/50], Step [18/735], Loss: 0.8715\n",
      "Epoch [20/50], Step [19/735], Loss: 0.2727\n",
      "Epoch [20/50], Step [20/735], Loss: 0.0806\n",
      "Epoch [20/50], Step [21/735], Loss: 0.2416\n",
      "Epoch [20/50], Step [22/735], Loss: 0.0906\n",
      "Epoch [20/50], Step [23/735], Loss: 0.0637\n",
      "Epoch [20/50], Step [24/735], Loss: 0.0524\n",
      "Epoch [20/50], Step [25/735], Loss: 0.0522\n",
      "Epoch [20/50], Step [26/735], Loss: 0.0789\n",
      "Epoch [20/50], Step [27/735], Loss: 0.1874\n",
      "Epoch [20/50], Step [28/735], Loss: 0.1974\n",
      "Epoch [20/50], Step [29/735], Loss: 0.0666\n",
      "Epoch [20/50], Step [30/735], Loss: 0.2721\n",
      "Epoch [20/50], Step [31/735], Loss: 0.1556\n",
      "Epoch [20/50], Step [32/735], Loss: 0.1577\n",
      "Epoch [20/50], Step [33/735], Loss: 0.0901\n",
      "Epoch [20/50], Step [34/735], Loss: 0.8883\n",
      "Epoch [20/50], Step [35/735], Loss: 0.1013\n",
      "Epoch [20/50], Step [36/735], Loss: 0.1408\n",
      "Epoch [20/50], Step [37/735], Loss: 0.0597\n",
      "Epoch [20/50], Step [38/735], Loss: 0.2911\n",
      "Epoch [20/50], Step [39/735], Loss: 0.1561\n",
      "Epoch [20/50], Step [40/735], Loss: 0.1039\n",
      "Epoch [20/50], Step [41/735], Loss: 1.6360\n",
      "Epoch [20/50], Step [42/735], Loss: 0.1997\n",
      "Epoch [20/50], Step [43/735], Loss: 0.1561\n",
      "Epoch [20/50], Step [44/735], Loss: 0.0644\n",
      "Epoch [20/50], Step [45/735], Loss: 0.1692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Step [46/735], Loss: 0.0819\n",
      "Epoch [20/50], Step [47/735], Loss: 0.1670\n",
      "Epoch [20/50], Step [48/735], Loss: 0.1345\n",
      "Epoch [20/50], Step [49/735], Loss: 0.1715\n",
      "Epoch [20/50], Step [50/735], Loss: 0.0469\n",
      "Epoch [20/50], Step [51/735], Loss: 0.2936\n",
      "Epoch [20/50], Step [52/735], Loss: 0.1740\n",
      "Epoch [20/50], Step [53/735], Loss: 0.0934\n",
      "Epoch [20/50], Step [54/735], Loss: 0.2488\n",
      "Epoch [20/50], Step [55/735], Loss: 1.0283\n",
      "Epoch [20/50], Step [56/735], Loss: 0.0362\n",
      "Epoch [20/50], Step [57/735], Loss: 0.5962\n",
      "Epoch [20/50], Step [58/735], Loss: 0.0875\n",
      "Epoch [20/50], Step [59/735], Loss: 0.8170\n",
      "Epoch [20/50], Step [60/735], Loss: 0.1371\n",
      "Epoch [20/50], Step [61/735], Loss: 0.1285\n",
      "Epoch [20/50], Step [62/735], Loss: 0.3167\n",
      "Epoch [20/50], Step [63/735], Loss: 0.1558\n",
      "Epoch [20/50], Step [64/735], Loss: 0.0714\n",
      "Epoch [20/50], Step [65/735], Loss: 0.1282\n",
      "Epoch [20/50], Step [66/735], Loss: 0.0771\n",
      "Epoch [20/50], Step [67/735], Loss: 0.0795\n",
      "Epoch [20/50], Step [68/735], Loss: 0.3692\n",
      "Epoch [20/50], Step [69/735], Loss: 0.1618\n",
      "Epoch [20/50], Step [70/735], Loss: 0.4939\n",
      "Epoch [20/50], Step [71/735], Loss: 0.0326\n",
      "Epoch [20/50], Step [72/735], Loss: 0.2087\n",
      "Epoch [20/50], Step [73/735], Loss: 0.0446\n",
      "Epoch [20/50], Step [74/735], Loss: 0.3072\n",
      "Epoch [20/50], Step [75/735], Loss: 0.1679\n",
      "Epoch [20/50], Step [76/735], Loss: 0.1075\n",
      "Epoch [20/50], Step [77/735], Loss: 0.0768\n",
      "Epoch [20/50], Step [78/735], Loss: 0.1453\n",
      "Epoch [20/50], Step [79/735], Loss: 0.1636\n",
      "Epoch [20/50], Step [80/735], Loss: 0.1289\n",
      "Epoch [20/50], Step [81/735], Loss: 0.4548\n",
      "Epoch [20/50], Step [82/735], Loss: 0.2111\n",
      "Epoch [20/50], Step [83/735], Loss: 0.1159\n",
      "Epoch [20/50], Step [84/735], Loss: 0.1381\n",
      "Epoch [20/50], Step [85/735], Loss: 0.1597\n",
      "Epoch [20/50], Step [86/735], Loss: 0.1301\n",
      "Epoch [20/50], Step [87/735], Loss: 0.5856\n",
      "Epoch [20/50], Step [88/735], Loss: 0.0496\n",
      "Epoch [20/50], Step [89/735], Loss: 0.0437\n",
      "Epoch [20/50], Step [90/735], Loss: 0.1109\n",
      "Epoch [20/50], Step [91/735], Loss: 0.0692\n",
      "Epoch [20/50], Step [92/735], Loss: 0.0707\n",
      "Epoch [20/50], Step [93/735], Loss: 0.1048\n",
      "Epoch [20/50], Step [94/735], Loss: 0.2494\n",
      "Epoch [20/50], Step [95/735], Loss: 0.0598\n",
      "Epoch [20/50], Step [96/735], Loss: 0.0490\n",
      "Epoch [20/50], Step [97/735], Loss: 0.2010\n",
      "Epoch [20/50], Step [98/735], Loss: 0.4677\n",
      "Epoch [20/50], Step [99/735], Loss: 0.0724\n",
      "Epoch [20/50], Step [100/735], Loss: 0.2793\n",
      "Epoch [20/50], Step [101/735], Loss: 0.1082\n",
      "Epoch [20/50], Step [102/735], Loss: 0.1141\n",
      "Epoch [20/50], Step [103/735], Loss: 0.1017\n",
      "Epoch [20/50], Step [104/735], Loss: 0.1147\n",
      "Epoch [20/50], Step [105/735], Loss: 0.1115\n",
      "Epoch [20/50], Step [106/735], Loss: 0.0302\n",
      "Epoch [20/50], Step [107/735], Loss: 0.2520\n",
      "Epoch [20/50], Step [108/735], Loss: 0.2598\n",
      "Epoch [20/50], Step [109/735], Loss: 0.2435\n",
      "Epoch [20/50], Step [110/735], Loss: 0.1605\n",
      "Epoch [20/50], Step [111/735], Loss: 0.1204\n",
      "Epoch [20/50], Step [112/735], Loss: 0.0489\n",
      "Epoch [20/50], Step [113/735], Loss: 1.1047\n",
      "Epoch [20/50], Step [114/735], Loss: 0.2731\n",
      "Epoch [20/50], Step [115/735], Loss: 0.2327\n",
      "Epoch [20/50], Step [116/735], Loss: 0.1244\n",
      "Epoch [20/50], Step [117/735], Loss: 0.1386\n",
      "Epoch [20/50], Step [118/735], Loss: 0.1869\n",
      "Epoch [20/50], Step [119/735], Loss: 0.6428\n",
      "Epoch [20/50], Step [120/735], Loss: 0.2910\n",
      "Epoch [20/50], Step [121/735], Loss: 0.0383\n",
      "Epoch [20/50], Step [122/735], Loss: 0.0745\n",
      "Epoch [20/50], Step [123/735], Loss: 0.1025\n",
      "Epoch [20/50], Step [124/735], Loss: 0.1113\n",
      "Epoch [20/50], Step [125/735], Loss: 0.1021\n",
      "Epoch [20/50], Step [126/735], Loss: 0.0632\n",
      "Epoch [20/50], Step [127/735], Loss: 0.0719\n",
      "Epoch [20/50], Step [128/735], Loss: 0.3831\n",
      "Epoch [20/50], Step [129/735], Loss: 0.3164\n",
      "Epoch [20/50], Step [130/735], Loss: 0.2952\n",
      "Epoch [20/50], Step [131/735], Loss: 0.1166\n",
      "Epoch [20/50], Step [132/735], Loss: 0.0650\n",
      "Epoch [20/50], Step [133/735], Loss: 0.3004\n",
      "Epoch [20/50], Step [134/735], Loss: 0.7296\n",
      "Epoch [20/50], Step [135/735], Loss: 0.0832\n",
      "Epoch [20/50], Step [136/735], Loss: 0.3452\n",
      "Epoch [20/50], Step [137/735], Loss: 0.0730\n",
      "Epoch [20/50], Step [138/735], Loss: 0.0626\n",
      "Epoch [20/50], Step [139/735], Loss: 0.2054\n",
      "Epoch [20/50], Step [140/735], Loss: 0.3067\n",
      "Epoch [20/50], Step [141/735], Loss: 0.1611\n",
      "Epoch [20/50], Step [142/735], Loss: 0.2379\n",
      "Epoch [20/50], Step [143/735], Loss: 0.2138\n",
      "Epoch [20/50], Step [144/735], Loss: 0.1350\n",
      "Epoch [20/50], Step [145/735], Loss: 0.1675\n",
      "Epoch [20/50], Step [146/735], Loss: 0.1660\n",
      "Epoch [20/50], Step [147/735], Loss: 0.1043\n",
      "Epoch [20/50], Step [148/735], Loss: 0.0806\n",
      "Epoch [20/50], Step [149/735], Loss: 0.1593\n",
      "Epoch [20/50], Step [150/735], Loss: 0.2045\n",
      "Epoch [20/50], Step [151/735], Loss: 0.1172\n",
      "Epoch [20/50], Step [152/735], Loss: 0.1042\n",
      "Epoch [20/50], Step [153/735], Loss: 0.1275\n",
      "Epoch [20/50], Step [154/735], Loss: 0.1067\n",
      "Epoch [20/50], Step [155/735], Loss: 0.2694\n",
      "Epoch [20/50], Step [156/735], Loss: 0.1239\n",
      "Epoch [20/50], Step [157/735], Loss: 0.3345\n",
      "Epoch [20/50], Step [158/735], Loss: 0.2216\n",
      "Epoch [20/50], Step [159/735], Loss: 0.2047\n",
      "Epoch [20/50], Step [160/735], Loss: 0.1364\n",
      "Epoch [20/50], Step [161/735], Loss: 2.2472\n",
      "Epoch [20/50], Step [162/735], Loss: 0.5219\n",
      "Epoch [20/50], Step [163/735], Loss: 0.0765\n",
      "Epoch [20/50], Step [164/735], Loss: 0.1567\n",
      "Epoch [20/50], Step [165/735], Loss: 0.1609\n",
      "Epoch [20/50], Step [166/735], Loss: 0.1071\n",
      "Epoch [20/50], Step [167/735], Loss: 0.1318\n",
      "Epoch [20/50], Step [168/735], Loss: 0.1706\n",
      "Epoch [20/50], Step [169/735], Loss: 0.1237\n",
      "Epoch [20/50], Step [170/735], Loss: 0.3275\n",
      "Epoch [20/50], Step [171/735], Loss: 0.1506\n",
      "Epoch [20/50], Step [172/735], Loss: 0.1211\n",
      "Epoch [20/50], Step [173/735], Loss: 0.1176\n",
      "Epoch [20/50], Step [174/735], Loss: 0.6060\n",
      "Epoch [20/50], Step [175/735], Loss: 0.1205\n",
      "Epoch [20/50], Step [176/735], Loss: 0.4729\n",
      "Epoch [20/50], Step [177/735], Loss: 0.3571\n",
      "Epoch [20/50], Step [178/735], Loss: 0.0849\n",
      "Epoch [20/50], Step [179/735], Loss: 0.0896\n",
      "Epoch [20/50], Step [180/735], Loss: 0.1837\n",
      "Epoch [20/50], Step [181/735], Loss: 0.1246\n",
      "Epoch [20/50], Step [182/735], Loss: 0.1184\n",
      "Epoch [20/50], Step [183/735], Loss: 0.0829\n",
      "Epoch [20/50], Step [184/735], Loss: 0.1110\n",
      "Epoch [20/50], Step [185/735], Loss: 0.6794\n",
      "Epoch [20/50], Step [186/735], Loss: 0.4316\n",
      "Epoch [20/50], Step [187/735], Loss: 0.0826\n",
      "Epoch [20/50], Step [188/735], Loss: 0.0867\n",
      "Epoch [20/50], Step [189/735], Loss: 0.1529\n",
      "Epoch [20/50], Step [190/735], Loss: 0.1200\n",
      "Epoch [20/50], Step [191/735], Loss: 0.2090\n",
      "Epoch [20/50], Step [192/735], Loss: 0.3907\n",
      "Epoch [20/50], Step [193/735], Loss: 1.2382\n",
      "Epoch [20/50], Step [194/735], Loss: 0.0851\n",
      "Epoch [20/50], Step [195/735], Loss: 0.4411\n",
      "Epoch [20/50], Step [196/735], Loss: 0.3923\n",
      "Epoch [20/50], Step [197/735], Loss: 0.8061\n",
      "Epoch [20/50], Step [198/735], Loss: 0.0739\n",
      "Epoch [20/50], Step [199/735], Loss: 0.1188\n",
      "Epoch [20/50], Step [200/735], Loss: 0.1568\n",
      "Epoch [20/50], Step [201/735], Loss: 0.2195\n",
      "Epoch [20/50], Step [202/735], Loss: 0.0943\n",
      "Epoch [20/50], Step [203/735], Loss: 0.1684\n",
      "Epoch [20/50], Step [204/735], Loss: 0.0641\n",
      "Epoch [20/50], Step [205/735], Loss: 0.0628\n",
      "Epoch [20/50], Step [206/735], Loss: 0.0783\n",
      "Epoch [20/50], Step [207/735], Loss: 0.2953\n",
      "Epoch [20/50], Step [208/735], Loss: 0.1167\n",
      "Epoch [20/50], Step [209/735], Loss: 0.1048\n",
      "Epoch [20/50], Step [210/735], Loss: 0.1201\n",
      "Epoch [20/50], Step [211/735], Loss: 0.5811\n",
      "Epoch [20/50], Step [212/735], Loss: 0.1317\n",
      "Epoch [20/50], Step [213/735], Loss: 0.3018\n",
      "Epoch [20/50], Step [214/735], Loss: 0.0501\n",
      "Epoch [20/50], Step [215/735], Loss: 0.1115\n",
      "Epoch [20/50], Step [216/735], Loss: 0.3906\n",
      "Epoch [20/50], Step [217/735], Loss: 0.0778\n",
      "Epoch [20/50], Step [218/735], Loss: 0.0971\n",
      "Epoch [20/50], Step [219/735], Loss: 0.1413\n",
      "Epoch [20/50], Step [220/735], Loss: 0.0275\n",
      "Epoch [20/50], Step [221/735], Loss: 0.1322\n",
      "Epoch [20/50], Step [222/735], Loss: 0.1224\n",
      "Epoch [20/50], Step [223/735], Loss: 0.0565\n",
      "Epoch [20/50], Step [224/735], Loss: 0.1747\n",
      "Epoch [20/50], Step [225/735], Loss: 0.1640\n",
      "Epoch [20/50], Step [226/735], Loss: 0.1214\n",
      "Epoch [20/50], Step [227/735], Loss: 0.1360\n",
      "Epoch [20/50], Step [228/735], Loss: 0.0632\n",
      "Epoch [20/50], Step [229/735], Loss: 0.1119\n",
      "Epoch [20/50], Step [230/735], Loss: 0.1534\n",
      "Epoch [20/50], Step [231/735], Loss: 0.3596\n",
      "Epoch [20/50], Step [232/735], Loss: 0.2461\n",
      "Epoch [20/50], Step [233/735], Loss: 0.1361\n",
      "Epoch [20/50], Step [234/735], Loss: 0.2387\n",
      "Epoch [20/50], Step [235/735], Loss: 0.0415\n",
      "Epoch [20/50], Step [236/735], Loss: 0.3422\n",
      "Epoch [20/50], Step [237/735], Loss: 0.1660\n",
      "Epoch [20/50], Step [238/735], Loss: 0.1161\n",
      "Epoch [20/50], Step [239/735], Loss: 0.0849\n",
      "Epoch [20/50], Step [240/735], Loss: 0.1211\n",
      "Epoch [20/50], Step [241/735], Loss: 0.2183\n",
      "Epoch [20/50], Step [242/735], Loss: 0.1229\n",
      "Epoch [20/50], Step [243/735], Loss: 0.0524\n",
      "Epoch [20/50], Step [244/735], Loss: 0.1405\n",
      "Epoch [20/50], Step [245/735], Loss: 0.0490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Step [246/735], Loss: 0.0711\n",
      "Epoch [20/50], Step [247/735], Loss: 0.0748\n",
      "Epoch [20/50], Step [248/735], Loss: 0.1715\n",
      "Epoch [20/50], Step [249/735], Loss: 0.1001\n",
      "Epoch [20/50], Step [250/735], Loss: 0.1769\n",
      "Epoch [20/50], Step [251/735], Loss: 0.3184\n",
      "Epoch [20/50], Step [252/735], Loss: 0.1617\n",
      "Epoch [20/50], Step [253/735], Loss: 0.1596\n",
      "Epoch [20/50], Step [254/735], Loss: 0.0434\n",
      "Epoch [20/50], Step [255/735], Loss: 0.2829\n",
      "Epoch [20/50], Step [256/735], Loss: 0.1481\n",
      "Epoch [20/50], Step [257/735], Loss: 0.0842\n",
      "Epoch [20/50], Step [258/735], Loss: 0.0969\n",
      "Epoch [20/50], Step [259/735], Loss: 0.1049\n",
      "Epoch [20/50], Step [260/735], Loss: 0.0530\n",
      "Epoch [20/50], Step [261/735], Loss: 0.2414\n",
      "Epoch [20/50], Step [262/735], Loss: 0.2779\n",
      "Epoch [20/50], Step [263/735], Loss: 0.7858\n",
      "Epoch [20/50], Step [264/735], Loss: 0.1249\n",
      "Epoch [20/50], Step [265/735], Loss: 0.0968\n",
      "Epoch [20/50], Step [266/735], Loss: 0.3132\n",
      "Epoch [20/50], Step [267/735], Loss: 0.3435\n",
      "Epoch [20/50], Step [268/735], Loss: 0.1602\n",
      "Epoch [20/50], Step [269/735], Loss: 0.0885\n",
      "Epoch [20/50], Step [270/735], Loss: 0.0413\n",
      "Epoch [20/50], Step [271/735], Loss: 0.2191\n",
      "Epoch [20/50], Step [272/735], Loss: 0.1008\n",
      "Epoch [20/50], Step [273/735], Loss: 0.0957\n",
      "Epoch [20/50], Step [274/735], Loss: 0.8422\n",
      "Epoch [20/50], Step [275/735], Loss: 0.0487\n",
      "Epoch [20/50], Step [276/735], Loss: 0.0888\n",
      "Epoch [20/50], Step [277/735], Loss: 0.1618\n",
      "Epoch [20/50], Step [278/735], Loss: 0.2860\n",
      "Epoch [20/50], Step [279/735], Loss: 0.1969\n",
      "Epoch [20/50], Step [280/735], Loss: 0.0836\n",
      "Epoch [20/50], Step [281/735], Loss: 0.1472\n",
      "Epoch [20/50], Step [282/735], Loss: 0.1106\n",
      "Epoch [20/50], Step [283/735], Loss: 0.0739\n",
      "Epoch [20/50], Step [284/735], Loss: 0.1453\n",
      "Epoch [20/50], Step [285/735], Loss: 0.1736\n",
      "Epoch [20/50], Step [286/735], Loss: 0.0781\n",
      "Epoch [20/50], Step [287/735], Loss: 0.0458\n",
      "Epoch [20/50], Step [288/735], Loss: 1.0347\n",
      "Epoch [20/50], Step [289/735], Loss: 0.1724\n",
      "Epoch [20/50], Step [290/735], Loss: 0.1743\n",
      "Epoch [20/50], Step [291/735], Loss: 0.9733\n",
      "Epoch [20/50], Step [292/735], Loss: 0.2406\n",
      "Epoch [20/50], Step [293/735], Loss: 0.0613\n",
      "Epoch [20/50], Step [294/735], Loss: 0.0736\n",
      "Epoch [20/50], Step [295/735], Loss: 0.1323\n",
      "Epoch [20/50], Step [296/735], Loss: 0.1316\n",
      "Epoch [20/50], Step [297/735], Loss: 0.1448\n",
      "Epoch [20/50], Step [298/735], Loss: 0.0932\n",
      "Epoch [20/50], Step [299/735], Loss: 0.3742\n",
      "Epoch [20/50], Step [300/735], Loss: 0.2828\n",
      "Epoch [20/50], Step [301/735], Loss: 0.2157\n",
      "Epoch [20/50], Step [302/735], Loss: 0.1195\n",
      "Epoch [20/50], Step [303/735], Loss: 0.2408\n",
      "Epoch [20/50], Step [304/735], Loss: 0.1357\n",
      "Epoch [20/50], Step [305/735], Loss: 0.1090\n",
      "Epoch [20/50], Step [306/735], Loss: 0.1096\n",
      "Epoch [20/50], Step [307/735], Loss: 0.0888\n",
      "Epoch [20/50], Step [308/735], Loss: 0.1860\n",
      "Epoch [20/50], Step [309/735], Loss: 0.3189\n",
      "Epoch [20/50], Step [310/735], Loss: 0.1607\n",
      "Epoch [20/50], Step [311/735], Loss: 0.0645\n",
      "Epoch [20/50], Step [312/735], Loss: 0.0859\n",
      "Epoch [20/50], Step [313/735], Loss: 0.1852\n",
      "Epoch [20/50], Step [314/735], Loss: 0.0961\n",
      "Epoch [20/50], Step [315/735], Loss: 0.1953\n",
      "Epoch [20/50], Step [316/735], Loss: 0.3184\n",
      "Epoch [20/50], Step [317/735], Loss: 0.1221\n",
      "Epoch [20/50], Step [318/735], Loss: 0.0503\n",
      "Epoch [20/50], Step [319/735], Loss: 0.1158\n",
      "Epoch [20/50], Step [320/735], Loss: 0.1611\n",
      "Epoch [20/50], Step [321/735], Loss: 0.2787\n",
      "Epoch [20/50], Step [322/735], Loss: 0.0534\n",
      "Epoch [20/50], Step [323/735], Loss: 0.1656\n",
      "Epoch [20/50], Step [324/735], Loss: 0.1835\n",
      "Epoch [20/50], Step [325/735], Loss: 0.1130\n",
      "Epoch [20/50], Step [326/735], Loss: 0.0799\n",
      "Epoch [20/50], Step [327/735], Loss: 0.0698\n",
      "Epoch [20/50], Step [328/735], Loss: 0.4077\n",
      "Epoch [20/50], Step [329/735], Loss: 0.1166\n",
      "Epoch [20/50], Step [330/735], Loss: 0.1177\n",
      "Epoch [20/50], Step [331/735], Loss: 0.2026\n",
      "Epoch [20/50], Step [332/735], Loss: 0.0577\n",
      "Epoch [20/50], Step [333/735], Loss: 0.1856\n",
      "Epoch [20/50], Step [334/735], Loss: 0.2144\n",
      "Epoch [20/50], Step [335/735], Loss: 0.1152\n",
      "Epoch [20/50], Step [336/735], Loss: 0.2527\n",
      "Epoch [20/50], Step [337/735], Loss: 0.0681\n",
      "Epoch [20/50], Step [338/735], Loss: 0.2269\n",
      "Epoch [20/50], Step [339/735], Loss: 0.1392\n",
      "Epoch [20/50], Step [340/735], Loss: 0.1838\n",
      "Epoch [20/50], Step [341/735], Loss: 0.0379\n",
      "Epoch [20/50], Step [342/735], Loss: 0.1246\n",
      "Epoch [20/50], Step [343/735], Loss: 0.3191\n",
      "Epoch [20/50], Step [344/735], Loss: 0.7631\n",
      "Epoch [20/50], Step [345/735], Loss: 0.1583\n",
      "Epoch [20/50], Step [346/735], Loss: 0.1358\n",
      "Epoch [20/50], Step [347/735], Loss: 0.1825\n",
      "Epoch [20/50], Step [348/735], Loss: 0.1470\n",
      "Epoch [20/50], Step [349/735], Loss: 0.1199\n",
      "Epoch [20/50], Step [350/735], Loss: 0.1231\n",
      "Epoch [20/50], Step [351/735], Loss: 0.0450\n",
      "Epoch [20/50], Step [352/735], Loss: 0.0776\n",
      "Epoch [20/50], Step [353/735], Loss: 0.0466\n",
      "Epoch [20/50], Step [354/735], Loss: 0.0405\n",
      "Epoch [20/50], Step [355/735], Loss: 0.1206\n",
      "Epoch [20/50], Step [356/735], Loss: 0.2383\n",
      "Epoch [20/50], Step [357/735], Loss: 0.1059\n",
      "Epoch [20/50], Step [358/735], Loss: 0.0880\n",
      "Epoch [20/50], Step [359/735], Loss: 0.0451\n",
      "Epoch [20/50], Step [360/735], Loss: 0.0844\n",
      "Epoch [20/50], Step [361/735], Loss: 0.1723\n",
      "Epoch [20/50], Step [362/735], Loss: 0.1259\n",
      "Epoch [20/50], Step [363/735], Loss: 0.0374\n",
      "Epoch [20/50], Step [364/735], Loss: 0.1311\n",
      "Epoch [20/50], Step [365/735], Loss: 0.0612\n",
      "Epoch [20/50], Step [366/735], Loss: 0.1369\n",
      "Epoch [20/50], Step [367/735], Loss: 0.0787\n",
      "Epoch [20/50], Step [368/735], Loss: 0.0734\n",
      "Epoch [20/50], Step [369/735], Loss: 0.7541\n",
      "Epoch [20/50], Step [370/735], Loss: 0.0435\n",
      "Epoch [20/50], Step [371/735], Loss: 0.1764\n",
      "Epoch [20/50], Step [372/735], Loss: 0.0996\n",
      "Epoch [20/50], Step [373/735], Loss: 0.1908\n",
      "Epoch [20/50], Step [374/735], Loss: 0.3107\n",
      "Epoch [20/50], Step [375/735], Loss: 0.0469\n",
      "Epoch [20/50], Step [376/735], Loss: 0.0788\n",
      "Epoch [20/50], Step [377/735], Loss: 0.0835\n",
      "Epoch [20/50], Step [378/735], Loss: 0.1190\n",
      "Epoch [20/50], Step [379/735], Loss: 0.0954\n",
      "Epoch [20/50], Step [380/735], Loss: 0.3388\n",
      "Epoch [20/50], Step [381/735], Loss: 0.0271\n",
      "Epoch [20/50], Step [382/735], Loss: 0.1140\n",
      "Epoch [20/50], Step [383/735], Loss: 0.2525\n",
      "Epoch [20/50], Step [384/735], Loss: 0.0634\n",
      "Epoch [20/50], Step [385/735], Loss: 0.0676\n",
      "Epoch [20/50], Step [386/735], Loss: 0.2842\n",
      "Epoch [20/50], Step [387/735], Loss: 0.5613\n",
      "Epoch [20/50], Step [388/735], Loss: 0.0498\n",
      "Epoch [20/50], Step [389/735], Loss: 0.7760\n",
      "Epoch [20/50], Step [390/735], Loss: 0.0557\n",
      "Epoch [20/50], Step [391/735], Loss: 0.0295\n",
      "Epoch [20/50], Step [392/735], Loss: 0.1059\n",
      "Epoch [20/50], Step [393/735], Loss: 0.1338\n",
      "Epoch [20/50], Step [394/735], Loss: 0.2327\n",
      "Epoch [20/50], Step [395/735], Loss: 0.1610\n",
      "Epoch [20/50], Step [396/735], Loss: 0.1694\n",
      "Epoch [20/50], Step [397/735], Loss: 0.1433\n",
      "Epoch [20/50], Step [398/735], Loss: 0.1212\n",
      "Epoch [20/50], Step [399/735], Loss: 0.7484\n",
      "Epoch [20/50], Step [400/735], Loss: 0.2358\n",
      "Epoch [20/50], Step [401/735], Loss: 0.1288\n",
      "Epoch [20/50], Step [402/735], Loss: 0.0470\n",
      "Epoch [20/50], Step [403/735], Loss: 0.1945\n",
      "Epoch [20/50], Step [404/735], Loss: 0.1012\n",
      "Epoch [20/50], Step [405/735], Loss: 0.0354\n",
      "Epoch [20/50], Step [406/735], Loss: 0.3385\n",
      "Epoch [20/50], Step [407/735], Loss: 0.3057\n",
      "Epoch [20/50], Step [408/735], Loss: 0.1190\n",
      "Epoch [20/50], Step [409/735], Loss: 0.1714\n",
      "Epoch [20/50], Step [410/735], Loss: 0.1053\n",
      "Epoch [20/50], Step [411/735], Loss: 0.0396\n",
      "Epoch [20/50], Step [412/735], Loss: 0.3952\n",
      "Epoch [20/50], Step [413/735], Loss: 0.1475\n",
      "Epoch [20/50], Step [414/735], Loss: 0.2518\n",
      "Epoch [20/50], Step [415/735], Loss: 0.0705\n",
      "Epoch [20/50], Step [416/735], Loss: 0.2423\n",
      "Epoch [20/50], Step [417/735], Loss: 0.0396\n",
      "Epoch [20/50], Step [418/735], Loss: 0.2419\n",
      "Epoch [20/50], Step [419/735], Loss: 0.1972\n",
      "Epoch [20/50], Step [420/735], Loss: 0.2866\n",
      "Epoch [20/50], Step [421/735], Loss: 0.1673\n",
      "Epoch [20/50], Step [422/735], Loss: 0.2732\n",
      "Epoch [20/50], Step [423/735], Loss: 0.0558\n",
      "Epoch [20/50], Step [424/735], Loss: 0.4857\n",
      "Epoch [20/50], Step [425/735], Loss: 0.1200\n",
      "Epoch [20/50], Step [426/735], Loss: 0.0969\n",
      "Epoch [20/50], Step [427/735], Loss: 0.1891\n",
      "Epoch [20/50], Step [428/735], Loss: 0.1491\n",
      "Epoch [20/50], Step [429/735], Loss: 0.0478\n",
      "Epoch [20/50], Step [430/735], Loss: 0.1050\n",
      "Epoch [20/50], Step [431/735], Loss: 0.0897\n",
      "Epoch [20/50], Step [432/735], Loss: 0.1011\n",
      "Epoch [20/50], Step [433/735], Loss: 0.1033\n",
      "Epoch [20/50], Step [434/735], Loss: 0.1276\n",
      "Epoch [20/50], Step [435/735], Loss: 0.1407\n",
      "Epoch [20/50], Step [436/735], Loss: 0.7124\n",
      "Epoch [20/50], Step [437/735], Loss: 0.8986\n",
      "Epoch [20/50], Step [438/735], Loss: 0.2320\n",
      "Epoch [20/50], Step [439/735], Loss: 0.1651\n",
      "Epoch [20/50], Step [440/735], Loss: 0.1056\n",
      "Epoch [20/50], Step [441/735], Loss: 0.1410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Step [442/735], Loss: 0.3157\n",
      "Epoch [20/50], Step [443/735], Loss: 0.1346\n",
      "Epoch [20/50], Step [444/735], Loss: 0.0472\n",
      "Epoch [20/50], Step [445/735], Loss: 0.2322\n",
      "Epoch [20/50], Step [446/735], Loss: 0.1915\n",
      "Epoch [20/50], Step [447/735], Loss: 0.0700\n",
      "Epoch [20/50], Step [448/735], Loss: 0.2313\n",
      "Epoch [20/50], Step [449/735], Loss: 0.0801\n",
      "Epoch [20/50], Step [450/735], Loss: 0.0605\n",
      "Epoch [20/50], Step [451/735], Loss: 0.1149\n",
      "Epoch [20/50], Step [452/735], Loss: 0.0634\n",
      "Epoch [20/50], Step [453/735], Loss: 0.1821\n",
      "Epoch [20/50], Step [454/735], Loss: 0.0474\n",
      "Epoch [20/50], Step [455/735], Loss: 0.1229\n",
      "Epoch [20/50], Step [456/735], Loss: 0.1581\n",
      "Epoch [20/50], Step [457/735], Loss: 0.2432\n",
      "Epoch [20/50], Step [458/735], Loss: 0.0720\n",
      "Epoch [20/50], Step [459/735], Loss: 0.4051\n",
      "Epoch [20/50], Step [460/735], Loss: 0.1980\n",
      "Epoch [20/50], Step [461/735], Loss: 0.1375\n",
      "Epoch [20/50], Step [462/735], Loss: 0.2041\n",
      "Epoch [20/50], Step [463/735], Loss: 0.2878\n",
      "Epoch [20/50], Step [464/735], Loss: 0.0745\n",
      "Epoch [20/50], Step [465/735], Loss: 0.0562\n",
      "Epoch [20/50], Step [466/735], Loss: 0.0427\n",
      "Epoch [20/50], Step [467/735], Loss: 0.2821\n",
      "Epoch [20/50], Step [468/735], Loss: 0.1912\n",
      "Epoch [20/50], Step [469/735], Loss: 0.1201\n",
      "Epoch [20/50], Step [470/735], Loss: 0.0579\n",
      "Epoch [20/50], Step [471/735], Loss: 0.1132\n",
      "Epoch [20/50], Step [472/735], Loss: 0.1812\n",
      "Epoch [20/50], Step [473/735], Loss: 0.0409\n",
      "Epoch [20/50], Step [474/735], Loss: 0.1275\n",
      "Epoch [20/50], Step [475/735], Loss: 0.1198\n",
      "Epoch [20/50], Step [476/735], Loss: 0.0540\n",
      "Epoch [20/50], Step [477/735], Loss: 0.7506\n",
      "Epoch [20/50], Step [478/735], Loss: 0.1441\n",
      "Epoch [20/50], Step [479/735], Loss: 0.0704\n",
      "Epoch [20/50], Step [480/735], Loss: 0.2347\n",
      "Epoch [20/50], Step [481/735], Loss: 0.1669\n",
      "Epoch [20/50], Step [482/735], Loss: 0.0997\n",
      "Epoch [20/50], Step [483/735], Loss: 0.2698\n",
      "Epoch [20/50], Step [484/735], Loss: 0.3247\n",
      "Epoch [20/50], Step [485/735], Loss: 0.1588\n",
      "Epoch [20/50], Step [486/735], Loss: 0.0855\n",
      "Epoch [20/50], Step [487/735], Loss: 0.0990\n",
      "Epoch [20/50], Step [488/735], Loss: 0.2012\n",
      "Epoch [20/50], Step [489/735], Loss: 0.1194\n",
      "Epoch [20/50], Step [490/735], Loss: 0.1383\n",
      "Epoch [20/50], Step [491/735], Loss: 0.3281\n",
      "Epoch [20/50], Step [492/735], Loss: 0.0889\n",
      "Epoch [20/50], Step [493/735], Loss: 1.9641\n",
      "Epoch [20/50], Step [494/735], Loss: 0.1228\n",
      "Epoch [20/50], Step [495/735], Loss: 0.1672\n",
      "Epoch [20/50], Step [496/735], Loss: 0.2652\n",
      "Epoch [20/50], Step [497/735], Loss: 0.1427\n",
      "Epoch [20/50], Step [498/735], Loss: 0.1692\n",
      "Epoch [20/50], Step [499/735], Loss: 0.1939\n",
      "Epoch [20/50], Step [500/735], Loss: 0.1164\n",
      "Epoch [20/50], Step [501/735], Loss: 0.1644\n",
      "Epoch [20/50], Step [502/735], Loss: 0.0685\n",
      "Epoch [20/50], Step [503/735], Loss: 0.0851\n",
      "Epoch [20/50], Step [504/735], Loss: 0.2172\n",
      "Epoch [20/50], Step [505/735], Loss: 0.1523\n",
      "Epoch [20/50], Step [506/735], Loss: 0.1547\n",
      "Epoch [20/50], Step [507/735], Loss: 0.0707\n",
      "Epoch [20/50], Step [508/735], Loss: 0.1398\n",
      "Epoch [20/50], Step [509/735], Loss: 0.0693\n",
      "Epoch [20/50], Step [510/735], Loss: 0.2047\n",
      "Epoch [20/50], Step [511/735], Loss: 0.1453\n",
      "Epoch [20/50], Step [512/735], Loss: 0.2899\n",
      "Epoch [20/50], Step [513/735], Loss: 0.1534\n",
      "Epoch [20/50], Step [514/735], Loss: 0.0722\n",
      "Epoch [20/50], Step [515/735], Loss: 0.7773\n",
      "Epoch [20/50], Step [516/735], Loss: 0.0833\n",
      "Epoch [20/50], Step [517/735], Loss: 0.2021\n",
      "Epoch [20/50], Step [518/735], Loss: 0.1665\n",
      "Epoch [20/50], Step [519/735], Loss: 0.1126\n",
      "Epoch [20/50], Step [520/735], Loss: 0.0771\n",
      "Epoch [20/50], Step [521/735], Loss: 0.0992\n",
      "Epoch [20/50], Step [522/735], Loss: 0.0775\n",
      "Epoch [20/50], Step [523/735], Loss: 0.1637\n",
      "Epoch [20/50], Step [524/735], Loss: 0.1604\n",
      "Epoch [20/50], Step [525/735], Loss: 0.0810\n",
      "Epoch [20/50], Step [526/735], Loss: 0.0975\n",
      "Epoch [20/50], Step [527/735], Loss: 0.2230\n",
      "Epoch [20/50], Step [528/735], Loss: 0.0538\n",
      "Epoch [20/50], Step [529/735], Loss: 0.0417\n",
      "Epoch [20/50], Step [530/735], Loss: 0.1707\n",
      "Epoch [20/50], Step [531/735], Loss: 0.0848\n",
      "Epoch [20/50], Step [532/735], Loss: 0.1659\n",
      "Epoch [20/50], Step [533/735], Loss: 0.0646\n",
      "Epoch [20/50], Step [534/735], Loss: 0.1294\n",
      "Epoch [20/50], Step [535/735], Loss: 0.3251\n",
      "Epoch [20/50], Step [536/735], Loss: 0.4553\n",
      "Epoch [20/50], Step [537/735], Loss: 0.0854\n",
      "Epoch [20/50], Step [538/735], Loss: 0.4093\n",
      "Epoch [20/50], Step [539/735], Loss: 0.0680\n",
      "Epoch [20/50], Step [540/735], Loss: 0.0412\n",
      "Epoch [20/50], Step [541/735], Loss: 0.1576\n",
      "Epoch [20/50], Step [542/735], Loss: 0.0983\n",
      "Epoch [20/50], Step [543/735], Loss: 0.1535\n",
      "Epoch [20/50], Step [544/735], Loss: 0.0265\n",
      "Epoch [20/50], Step [545/735], Loss: 0.5336\n",
      "Epoch [20/50], Step [546/735], Loss: 0.0740\n",
      "Epoch [20/50], Step [547/735], Loss: 0.1901\n",
      "Epoch [20/50], Step [548/735], Loss: 0.0690\n",
      "Epoch [20/50], Step [549/735], Loss: 0.0806\n",
      "Epoch [20/50], Step [550/735], Loss: 0.2269\n",
      "Epoch [20/50], Step [551/735], Loss: 0.2138\n",
      "Epoch [20/50], Step [552/735], Loss: 0.0664\n",
      "Epoch [20/50], Step [553/735], Loss: 0.1292\n",
      "Epoch [20/50], Step [554/735], Loss: 0.0959\n",
      "Epoch [20/50], Step [555/735], Loss: 0.2097\n",
      "Epoch [20/50], Step [556/735], Loss: 0.1418\n",
      "Epoch [20/50], Step [557/735], Loss: 0.0392\n",
      "Epoch [20/50], Step [558/735], Loss: 0.1697\n",
      "Epoch [20/50], Step [559/735], Loss: 0.2666\n",
      "Epoch [20/50], Step [560/735], Loss: 0.0854\n",
      "Epoch [20/50], Step [561/735], Loss: 1.9924\n",
      "Epoch [20/50], Step [562/735], Loss: 0.0881\n",
      "Epoch [20/50], Step [563/735], Loss: 1.1421\n",
      "Epoch [20/50], Step [564/735], Loss: 0.1201\n",
      "Epoch [20/50], Step [565/735], Loss: 1.2933\n",
      "Epoch [20/50], Step [566/735], Loss: 0.0447\n",
      "Epoch [20/50], Step [567/735], Loss: 0.1825\n",
      "Epoch [20/50], Step [568/735], Loss: 0.1874\n",
      "Epoch [20/50], Step [569/735], Loss: 0.0982\n",
      "Epoch [20/50], Step [570/735], Loss: 0.2140\n",
      "Epoch [20/50], Step [571/735], Loss: 0.1199\n",
      "Epoch [20/50], Step [572/735], Loss: 0.5711\n",
      "Epoch [20/50], Step [573/735], Loss: 0.2518\n",
      "Epoch [20/50], Step [574/735], Loss: 0.1428\n",
      "Epoch [20/50], Step [575/735], Loss: 0.1222\n",
      "Epoch [20/50], Step [576/735], Loss: 0.7793\n",
      "Epoch [20/50], Step [577/735], Loss: 2.1764\n",
      "Epoch [20/50], Step [578/735], Loss: 0.1831\n",
      "Epoch [20/50], Step [579/735], Loss: 0.3274\n",
      "Epoch [20/50], Step [580/735], Loss: 0.1743\n",
      "Epoch [20/50], Step [581/735], Loss: 0.1360\n",
      "Epoch [20/50], Step [582/735], Loss: 0.1520\n",
      "Epoch [20/50], Step [583/735], Loss: 0.1099\n",
      "Epoch [20/50], Step [584/735], Loss: 0.1309\n",
      "Epoch [20/50], Step [585/735], Loss: 0.1648\n",
      "Epoch [20/50], Step [586/735], Loss: 0.1069\n",
      "Epoch [20/50], Step [587/735], Loss: 0.3510\n",
      "Epoch [20/50], Step [588/735], Loss: 0.2899\n",
      "Epoch [20/50], Step [589/735], Loss: 0.1617\n",
      "Epoch [20/50], Step [590/735], Loss: 0.0878\n",
      "Epoch [20/50], Step [591/735], Loss: 0.0965\n",
      "Epoch [20/50], Step [592/735], Loss: 0.0598\n",
      "Epoch [20/50], Step [593/735], Loss: 0.1337\n",
      "Epoch [20/50], Step [594/735], Loss: 0.2250\n",
      "Epoch [20/50], Step [595/735], Loss: 0.2158\n",
      "Epoch [20/50], Step [596/735], Loss: 0.2581\n",
      "Epoch [20/50], Step [597/735], Loss: 0.1681\n",
      "Epoch [20/50], Step [598/735], Loss: 0.1837\n",
      "Epoch [20/50], Step [599/735], Loss: 0.0962\n",
      "Epoch [20/50], Step [600/735], Loss: 0.1772\n",
      "Epoch [20/50], Step [601/735], Loss: 0.0868\n",
      "Epoch [20/50], Step [602/735], Loss: 1.5814\n",
      "Epoch [20/50], Step [603/735], Loss: 0.0586\n",
      "Epoch [20/50], Step [604/735], Loss: 0.0750\n",
      "Epoch [20/50], Step [605/735], Loss: 0.1926\n",
      "Epoch [20/50], Step [606/735], Loss: 0.1286\n",
      "Epoch [20/50], Step [607/735], Loss: 0.2338\n",
      "Epoch [20/50], Step [608/735], Loss: 0.0582\n",
      "Epoch [20/50], Step [609/735], Loss: 0.0576\n",
      "Epoch [20/50], Step [610/735], Loss: 0.0673\n",
      "Epoch [20/50], Step [611/735], Loss: 0.1923\n",
      "Epoch [20/50], Step [612/735], Loss: 0.0912\n",
      "Epoch [20/50], Step [613/735], Loss: 0.1554\n",
      "Epoch [20/50], Step [614/735], Loss: 0.1020\n",
      "Epoch [20/50], Step [615/735], Loss: 0.2396\n",
      "Epoch [20/50], Step [616/735], Loss: 0.0741\n",
      "Epoch [20/50], Step [617/735], Loss: 0.1558\n",
      "Epoch [20/50], Step [618/735], Loss: 0.1124\n",
      "Epoch [20/50], Step [619/735], Loss: 0.0862\n",
      "Epoch [20/50], Step [620/735], Loss: 0.1432\n",
      "Epoch [20/50], Step [621/735], Loss: 0.3103\n",
      "Epoch [20/50], Step [622/735], Loss: 0.0819\n",
      "Epoch [20/50], Step [623/735], Loss: 0.1449\n",
      "Epoch [20/50], Step [624/735], Loss: 0.1250\n",
      "Epoch [20/50], Step [625/735], Loss: 0.1368\n",
      "Epoch [20/50], Step [626/735], Loss: 0.0882\n",
      "Epoch [20/50], Step [627/735], Loss: 0.2250\n",
      "Epoch [20/50], Step [628/735], Loss: 0.1905\n",
      "Epoch [20/50], Step [629/735], Loss: 0.1453\n",
      "Epoch [20/50], Step [630/735], Loss: 0.1908\n",
      "Epoch [20/50], Step [631/735], Loss: 0.1418\n",
      "Epoch [20/50], Step [632/735], Loss: 0.0986\n",
      "Epoch [20/50], Step [633/735], Loss: 0.1389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Step [634/735], Loss: 0.1244\n",
      "Epoch [20/50], Step [635/735], Loss: 0.1382\n",
      "Epoch [20/50], Step [636/735], Loss: 0.0810\n",
      "Epoch [20/50], Step [637/735], Loss: 0.0673\n",
      "Epoch [20/50], Step [638/735], Loss: 0.2738\n",
      "Epoch [20/50], Step [639/735], Loss: 0.2686\n",
      "Epoch [20/50], Step [640/735], Loss: 0.0974\n",
      "Epoch [20/50], Step [641/735], Loss: 0.0958\n",
      "Epoch [20/50], Step [642/735], Loss: 0.1501\n",
      "Epoch [20/50], Step [643/735], Loss: 1.9084\n",
      "Epoch [20/50], Step [644/735], Loss: 0.0810\n",
      "Epoch [20/50], Step [645/735], Loss: 0.0871\n",
      "Epoch [20/50], Step [646/735], Loss: 0.2751\n",
      "Epoch [20/50], Step [647/735], Loss: 0.1970\n",
      "Epoch [20/50], Step [648/735], Loss: 0.0870\n",
      "Epoch [20/50], Step [649/735], Loss: 0.0837\n",
      "Epoch [20/50], Step [650/735], Loss: 0.4302\n",
      "Epoch [20/50], Step [651/735], Loss: 0.1089\n",
      "Epoch [20/50], Step [652/735], Loss: 0.5960\n",
      "Epoch [20/50], Step [653/735], Loss: 0.2829\n",
      "Epoch [20/50], Step [654/735], Loss: 0.2121\n",
      "Epoch [20/50], Step [655/735], Loss: 0.0948\n",
      "Epoch [20/50], Step [656/735], Loss: 0.0772\n",
      "Epoch [20/50], Step [657/735], Loss: 0.2023\n",
      "Epoch [20/50], Step [658/735], Loss: 0.1299\n",
      "Epoch [20/50], Step [659/735], Loss: 0.1656\n",
      "Epoch [20/50], Step [660/735], Loss: 0.1885\n",
      "Epoch [20/50], Step [661/735], Loss: 0.0640\n",
      "Epoch [20/50], Step [662/735], Loss: 0.1845\n",
      "Epoch [20/50], Step [663/735], Loss: 0.0706\n",
      "Epoch [20/50], Step [664/735], Loss: 0.1458\n",
      "Epoch [20/50], Step [665/735], Loss: 0.2235\n",
      "Epoch [20/50], Step [666/735], Loss: 0.1276\n",
      "Epoch [20/50], Step [667/735], Loss: 0.3694\n",
      "Epoch [20/50], Step [668/735], Loss: 0.1493\n",
      "Epoch [20/50], Step [669/735], Loss: 0.0714\n",
      "Epoch [20/50], Step [670/735], Loss: 0.3205\n",
      "Epoch [20/50], Step [671/735], Loss: 0.0997\n",
      "Epoch [20/50], Step [672/735], Loss: 0.1026\n",
      "Epoch [20/50], Step [673/735], Loss: 0.6041\n",
      "Epoch [20/50], Step [674/735], Loss: 0.0880\n",
      "Epoch [20/50], Step [675/735], Loss: 0.2364\n",
      "Epoch [20/50], Step [676/735], Loss: 0.1611\n",
      "Epoch [20/50], Step [677/735], Loss: 0.1160\n",
      "Epoch [20/50], Step [678/735], Loss: 0.1762\n",
      "Epoch [20/50], Step [679/735], Loss: 0.0721\n",
      "Epoch [20/50], Step [680/735], Loss: 0.0950\n",
      "Epoch [20/50], Step [681/735], Loss: 0.1436\n",
      "Epoch [20/50], Step [682/735], Loss: 0.1502\n",
      "Epoch [20/50], Step [683/735], Loss: 0.1229\n",
      "Epoch [20/50], Step [684/735], Loss: 0.1256\n",
      "Epoch [20/50], Step [685/735], Loss: 0.1059\n",
      "Epoch [20/50], Step [686/735], Loss: 0.1216\n",
      "Epoch [20/50], Step [687/735], Loss: 0.0608\n",
      "Epoch [20/50], Step [688/735], Loss: 0.3526\n",
      "Epoch [20/50], Step [689/735], Loss: 0.1723\n",
      "Epoch [20/50], Step [690/735], Loss: 0.1346\n",
      "Epoch [20/50], Step [691/735], Loss: 0.2960\n",
      "Epoch [20/50], Step [692/735], Loss: 0.0717\n",
      "Epoch [20/50], Step [693/735], Loss: 0.0754\n",
      "Epoch [20/50], Step [694/735], Loss: 0.2382\n",
      "Epoch [20/50], Step [695/735], Loss: 0.1202\n",
      "Epoch [20/50], Step [696/735], Loss: 0.0657\n",
      "Epoch [20/50], Step [697/735], Loss: 0.0996\n",
      "Epoch [20/50], Step [698/735], Loss: 0.0784\n",
      "Epoch [20/50], Step [699/735], Loss: 0.1577\n",
      "Epoch [20/50], Step [700/735], Loss: 0.0815\n",
      "Epoch [20/50], Step [701/735], Loss: 0.4904\n",
      "Epoch [20/50], Step [702/735], Loss: 0.1442\n",
      "Epoch [20/50], Step [703/735], Loss: 0.0612\n",
      "Epoch [20/50], Step [704/735], Loss: 0.1584\n",
      "Epoch [20/50], Step [705/735], Loss: 0.1004\n",
      "Epoch [20/50], Step [706/735], Loss: 0.0735\n",
      "Epoch [20/50], Step [707/735], Loss: 0.1406\n",
      "Epoch [20/50], Step [708/735], Loss: 0.1065\n",
      "Epoch [20/50], Step [709/735], Loss: 0.2854\n",
      "Epoch [20/50], Step [710/735], Loss: 0.1002\n",
      "Epoch [20/50], Step [711/735], Loss: 0.3096\n",
      "Epoch [20/50], Step [712/735], Loss: 0.1216\n",
      "Epoch [20/50], Step [713/735], Loss: 0.1535\n",
      "Epoch [20/50], Step [714/735], Loss: 0.1017\n",
      "Epoch [20/50], Step [715/735], Loss: 0.1105\n",
      "Epoch [20/50], Step [716/735], Loss: 0.1094\n",
      "Epoch [20/50], Step [717/735], Loss: 0.1974\n",
      "Epoch [20/50], Step [718/735], Loss: 0.4639\n",
      "Epoch [20/50], Step [719/735], Loss: 0.1319\n",
      "Epoch [20/50], Step [720/735], Loss: 0.1098\n",
      "Epoch [20/50], Step [721/735], Loss: 0.1332\n",
      "Epoch [20/50], Step [722/735], Loss: 0.1403\n",
      "Epoch [20/50], Step [723/735], Loss: 0.2343\n",
      "Epoch [20/50], Step [724/735], Loss: 0.1099\n",
      "Epoch [20/50], Step [725/735], Loss: 0.0609\n",
      "Epoch [20/50], Step [726/735], Loss: 0.0878\n",
      "Epoch [20/50], Step [727/735], Loss: 0.1712\n",
      "Epoch [20/50], Step [728/735], Loss: 0.0649\n",
      "Epoch [20/50], Step [729/735], Loss: 0.1105\n",
      "Epoch [20/50], Step [730/735], Loss: 0.6293\n",
      "Epoch [20/50], Step [731/735], Loss: 0.0577\n",
      "Epoch [20/50], Step [732/735], Loss: 0.4204\n",
      "Epoch [20/50], Step [733/735], Loss: 0.2923\n",
      "Epoch [20/50], Step [734/735], Loss: 0.1671\n",
      "Epoch [20/50], Step [735/735], Loss: 0.2206\n",
      "Epoch [21/50], Step [1/735], Loss: 0.1052\n",
      "Epoch [21/50], Step [2/735], Loss: 0.2264\n",
      "Epoch [21/50], Step [3/735], Loss: 0.5381\n",
      "Epoch [21/50], Step [4/735], Loss: 0.0781\n",
      "Epoch [21/50], Step [5/735], Loss: 0.1605\n",
      "Epoch [21/50], Step [6/735], Loss: 0.1382\n",
      "Epoch [21/50], Step [7/735], Loss: 0.2114\n",
      "Epoch [21/50], Step [8/735], Loss: 0.0632\n",
      "Epoch [21/50], Step [9/735], Loss: 0.2099\n",
      "Epoch [21/50], Step [10/735], Loss: 0.0578\n",
      "Epoch [21/50], Step [11/735], Loss: 0.1769\n",
      "Epoch [21/50], Step [12/735], Loss: 0.2188\n",
      "Epoch [21/50], Step [13/735], Loss: 0.1419\n",
      "Epoch [21/50], Step [14/735], Loss: 0.0933\n",
      "Epoch [21/50], Step [15/735], Loss: 0.0733\n",
      "Epoch [21/50], Step [16/735], Loss: 0.0837\n",
      "Epoch [21/50], Step [17/735], Loss: 0.0973\n",
      "Epoch [21/50], Step [18/735], Loss: 0.1192\n",
      "Epoch [21/50], Step [19/735], Loss: 0.2324\n",
      "Epoch [21/50], Step [20/735], Loss: 0.0832\n",
      "Epoch [21/50], Step [21/735], Loss: 0.1733\n",
      "Epoch [21/50], Step [22/735], Loss: 0.0622\n",
      "Epoch [21/50], Step [23/735], Loss: 0.1158\n",
      "Epoch [21/50], Step [24/735], Loss: 0.1128\n",
      "Epoch [21/50], Step [25/735], Loss: 0.0746\n",
      "Epoch [21/50], Step [26/735], Loss: 0.0510\n",
      "Epoch [21/50], Step [27/735], Loss: 0.1164\n",
      "Epoch [21/50], Step [28/735], Loss: 0.0583\n",
      "Epoch [21/50], Step [29/735], Loss: 0.0977\n",
      "Epoch [21/50], Step [30/735], Loss: 0.1588\n",
      "Epoch [21/50], Step [31/735], Loss: 0.0811\n",
      "Epoch [21/50], Step [32/735], Loss: 0.1423\n",
      "Epoch [21/50], Step [33/735], Loss: 0.1935\n",
      "Epoch [21/50], Step [34/735], Loss: 0.0686\n",
      "Epoch [21/50], Step [35/735], Loss: 0.1810\n",
      "Epoch [21/50], Step [36/735], Loss: 0.0647\n",
      "Epoch [21/50], Step [37/735], Loss: 0.2320\n",
      "Epoch [21/50], Step [38/735], Loss: 0.0990\n",
      "Epoch [21/50], Step [39/735], Loss: 2.2728\n",
      "Epoch [21/50], Step [40/735], Loss: 0.0291\n",
      "Epoch [21/50], Step [41/735], Loss: 0.0643\n",
      "Epoch [21/50], Step [42/735], Loss: 0.1326\n",
      "Epoch [21/50], Step [43/735], Loss: 0.0987\n",
      "Epoch [21/50], Step [44/735], Loss: 0.0876\n",
      "Epoch [21/50], Step [45/735], Loss: 0.0905\n",
      "Epoch [21/50], Step [46/735], Loss: 0.0898\n",
      "Epoch [21/50], Step [47/735], Loss: 0.1598\n",
      "Epoch [21/50], Step [48/735], Loss: 0.1321\n",
      "Epoch [21/50], Step [49/735], Loss: 0.1171\n",
      "Epoch [21/50], Step [50/735], Loss: 0.2126\n",
      "Epoch [21/50], Step [51/735], Loss: 0.2377\n",
      "Epoch [21/50], Step [52/735], Loss: 0.0552\n",
      "Epoch [21/50], Step [53/735], Loss: 0.0257\n",
      "Epoch [21/50], Step [54/735], Loss: 0.0417\n",
      "Epoch [21/50], Step [55/735], Loss: 0.1399\n",
      "Epoch [21/50], Step [56/735], Loss: 0.0772\n",
      "Epoch [21/50], Step [57/735], Loss: 0.1228\n",
      "Epoch [21/50], Step [58/735], Loss: 0.1906\n",
      "Epoch [21/50], Step [59/735], Loss: 0.1406\n",
      "Epoch [21/50], Step [60/735], Loss: 0.1029\n",
      "Epoch [21/50], Step [61/735], Loss: 0.1016\n",
      "Epoch [21/50], Step [62/735], Loss: 0.3265\n",
      "Epoch [21/50], Step [63/735], Loss: 0.0290\n",
      "Epoch [21/50], Step [64/735], Loss: 0.1060\n",
      "Epoch [21/50], Step [65/735], Loss: 0.0800\n",
      "Epoch [21/50], Step [66/735], Loss: 0.0965\n",
      "Epoch [21/50], Step [67/735], Loss: 0.0923\n",
      "Epoch [21/50], Step [68/735], Loss: 0.1516\n",
      "Epoch [21/50], Step [69/735], Loss: 0.2043\n",
      "Epoch [21/50], Step [70/735], Loss: 0.1013\n",
      "Epoch [21/50], Step [71/735], Loss: 0.0787\n",
      "Epoch [21/50], Step [72/735], Loss: 0.1396\n",
      "Epoch [21/50], Step [73/735], Loss: 0.1428\n",
      "Epoch [21/50], Step [74/735], Loss: 0.1661\n",
      "Epoch [21/50], Step [75/735], Loss: 0.1123\n",
      "Epoch [21/50], Step [76/735], Loss: 0.0680\n",
      "Epoch [21/50], Step [77/735], Loss: 0.1413\n",
      "Epoch [21/50], Step [78/735], Loss: 0.1281\n",
      "Epoch [21/50], Step [79/735], Loss: 0.1190\n",
      "Epoch [21/50], Step [80/735], Loss: 0.0549\n",
      "Epoch [21/50], Step [81/735], Loss: 0.1585\n",
      "Epoch [21/50], Step [82/735], Loss: 0.1463\n",
      "Epoch [21/50], Step [83/735], Loss: 0.8411\n",
      "Epoch [21/50], Step [84/735], Loss: 0.1705\n",
      "Epoch [21/50], Step [85/735], Loss: 0.1536\n",
      "Epoch [21/50], Step [86/735], Loss: 0.0539\n",
      "Epoch [21/50], Step [87/735], Loss: 0.1083\n",
      "Epoch [21/50], Step [88/735], Loss: 0.1592\n",
      "Epoch [21/50], Step [89/735], Loss: 0.2942\n",
      "Epoch [21/50], Step [90/735], Loss: 0.1138\n",
      "Epoch [21/50], Step [91/735], Loss: 0.2769\n",
      "Epoch [21/50], Step [92/735], Loss: 0.1602\n",
      "Epoch [21/50], Step [93/735], Loss: 0.1247\n",
      "Epoch [21/50], Step [94/735], Loss: 0.1681\n",
      "Epoch [21/50], Step [95/735], Loss: 0.1244\n",
      "Epoch [21/50], Step [96/735], Loss: 0.0607\n",
      "Epoch [21/50], Step [97/735], Loss: 0.0976\n",
      "Epoch [21/50], Step [98/735], Loss: 0.2494\n",
      "Epoch [21/50], Step [99/735], Loss: 0.1065\n",
      "Epoch [21/50], Step [100/735], Loss: 0.3173\n",
      "Epoch [21/50], Step [101/735], Loss: 0.0869\n",
      "Epoch [21/50], Step [102/735], Loss: 0.4935\n",
      "Epoch [21/50], Step [103/735], Loss: 0.1102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Step [104/735], Loss: 0.0883\n",
      "Epoch [21/50], Step [105/735], Loss: 0.7008\n",
      "Epoch [21/50], Step [106/735], Loss: 0.1394\n",
      "Epoch [21/50], Step [107/735], Loss: 0.0477\n",
      "Epoch [21/50], Step [108/735], Loss: 0.1004\n",
      "Epoch [21/50], Step [109/735], Loss: 0.1625\n",
      "Epoch [21/50], Step [110/735], Loss: 0.0968\n",
      "Epoch [21/50], Step [111/735], Loss: 0.1549\n",
      "Epoch [21/50], Step [112/735], Loss: 1.2339\n",
      "Epoch [21/50], Step [113/735], Loss: 0.0402\n",
      "Epoch [21/50], Step [114/735], Loss: 0.0493\n",
      "Epoch [21/50], Step [115/735], Loss: 0.1157\n",
      "Epoch [21/50], Step [116/735], Loss: 0.0977\n",
      "Epoch [21/50], Step [117/735], Loss: 0.2630\n",
      "Epoch [21/50], Step [118/735], Loss: 0.0328\n",
      "Epoch [21/50], Step [119/735], Loss: 0.1095\n",
      "Epoch [21/50], Step [120/735], Loss: 0.0689\n",
      "Epoch [21/50], Step [121/735], Loss: 0.0802\n",
      "Epoch [21/50], Step [122/735], Loss: 0.1212\n",
      "Epoch [21/50], Step [123/735], Loss: 0.3238\n",
      "Epoch [21/50], Step [124/735], Loss: 0.0374\n",
      "Epoch [21/50], Step [125/735], Loss: 0.2131\n",
      "Epoch [21/50], Step [126/735], Loss: 0.1616\n",
      "Epoch [21/50], Step [127/735], Loss: 0.1980\n",
      "Epoch [21/50], Step [128/735], Loss: 0.0689\n",
      "Epoch [21/50], Step [129/735], Loss: 0.1000\n",
      "Epoch [21/50], Step [130/735], Loss: 0.1210\n",
      "Epoch [21/50], Step [131/735], Loss: 0.9221\n",
      "Epoch [21/50], Step [132/735], Loss: 0.1669\n",
      "Epoch [21/50], Step [133/735], Loss: 0.4139\n",
      "Epoch [21/50], Step [134/735], Loss: 0.1550\n",
      "Epoch [21/50], Step [135/735], Loss: 0.0791\n",
      "Epoch [21/50], Step [136/735], Loss: 0.1374\n",
      "Epoch [21/50], Step [137/735], Loss: 0.3543\n",
      "Epoch [21/50], Step [138/735], Loss: 1.7939\n",
      "Epoch [21/50], Step [139/735], Loss: 0.1272\n",
      "Epoch [21/50], Step [140/735], Loss: 0.0673\n",
      "Epoch [21/50], Step [141/735], Loss: 0.2117\n",
      "Epoch [21/50], Step [142/735], Loss: 0.2549\n",
      "Epoch [21/50], Step [143/735], Loss: 0.1079\n",
      "Epoch [21/50], Step [144/735], Loss: 0.2783\n",
      "Epoch [21/50], Step [145/735], Loss: 0.1621\n",
      "Epoch [21/50], Step [146/735], Loss: 0.1735\n",
      "Epoch [21/50], Step [147/735], Loss: 0.0723\n",
      "Epoch [21/50], Step [148/735], Loss: 0.3059\n",
      "Epoch [21/50], Step [149/735], Loss: 0.3530\n",
      "Epoch [21/50], Step [150/735], Loss: 0.0758\n",
      "Epoch [21/50], Step [151/735], Loss: 0.2211\n",
      "Epoch [21/50], Step [152/735], Loss: 0.0765\n",
      "Epoch [21/50], Step [153/735], Loss: 0.0818\n",
      "Epoch [21/50], Step [154/735], Loss: 0.1760\n",
      "Epoch [21/50], Step [155/735], Loss: 0.1311\n",
      "Epoch [21/50], Step [156/735], Loss: 0.1371\n",
      "Epoch [21/50], Step [157/735], Loss: 0.2046\n",
      "Epoch [21/50], Step [158/735], Loss: 0.0253\n",
      "Epoch [21/50], Step [159/735], Loss: 0.1191\n",
      "Epoch [21/50], Step [160/735], Loss: 0.7066\n",
      "Epoch [21/50], Step [161/735], Loss: 0.1423\n",
      "Epoch [21/50], Step [162/735], Loss: 1.3012\n",
      "Epoch [21/50], Step [163/735], Loss: 0.3630\n",
      "Epoch [21/50], Step [164/735], Loss: 0.0922\n",
      "Epoch [21/50], Step [165/735], Loss: 0.1128\n",
      "Epoch [21/50], Step [166/735], Loss: 0.0846\n",
      "Epoch [21/50], Step [167/735], Loss: 0.1147\n",
      "Epoch [21/50], Step [168/735], Loss: 0.0897\n",
      "Epoch [21/50], Step [169/735], Loss: 0.1648\n",
      "Epoch [21/50], Step [170/735], Loss: 0.0626\n",
      "Epoch [21/50], Step [171/735], Loss: 0.2989\n",
      "Epoch [21/50], Step [172/735], Loss: 0.2263\n",
      "Epoch [21/50], Step [173/735], Loss: 0.0506\n",
      "Epoch [21/50], Step [174/735], Loss: 0.2808\n",
      "Epoch [21/50], Step [175/735], Loss: 0.1032\n",
      "Epoch [21/50], Step [176/735], Loss: 0.0781\n",
      "Epoch [21/50], Step [177/735], Loss: 0.6899\n",
      "Epoch [21/50], Step [178/735], Loss: 0.0574\n",
      "Epoch [21/50], Step [179/735], Loss: 0.1710\n",
      "Epoch [21/50], Step [180/735], Loss: 0.1200\n",
      "Epoch [21/50], Step [181/735], Loss: 0.1385\n",
      "Epoch [21/50], Step [182/735], Loss: 0.7761\n",
      "Epoch [21/50], Step [183/735], Loss: 0.0535\n",
      "Epoch [21/50], Step [184/735], Loss: 0.1138\n",
      "Epoch [21/50], Step [185/735], Loss: 0.1983\n",
      "Epoch [21/50], Step [186/735], Loss: 0.1836\n",
      "Epoch [21/50], Step [187/735], Loss: 0.1174\n",
      "Epoch [21/50], Step [188/735], Loss: 0.2052\n",
      "Epoch [21/50], Step [189/735], Loss: 0.2028\n",
      "Epoch [21/50], Step [190/735], Loss: 0.1192\n",
      "Epoch [21/50], Step [191/735], Loss: 0.1579\n",
      "Epoch [21/50], Step [192/735], Loss: 0.0672\n",
      "Epoch [21/50], Step [193/735], Loss: 0.1254\n",
      "Epoch [21/50], Step [194/735], Loss: 0.1029\n",
      "Epoch [21/50], Step [195/735], Loss: 0.1508\n",
      "Epoch [21/50], Step [196/735], Loss: 0.3174\n",
      "Epoch [21/50], Step [197/735], Loss: 0.6664\n",
      "Epoch [21/50], Step [198/735], Loss: 0.2247\n",
      "Epoch [21/50], Step [199/735], Loss: 0.4727\n",
      "Epoch [21/50], Step [200/735], Loss: 0.1432\n",
      "Epoch [21/50], Step [201/735], Loss: 0.0805\n",
      "Epoch [21/50], Step [202/735], Loss: 0.0997\n",
      "Epoch [21/50], Step [203/735], Loss: 0.4068\n",
      "Epoch [21/50], Step [204/735], Loss: 0.5973\n",
      "Epoch [21/50], Step [205/735], Loss: 0.2028\n",
      "Epoch [21/50], Step [206/735], Loss: 0.4121\n",
      "Epoch [21/50], Step [207/735], Loss: 0.0663\n",
      "Epoch [21/50], Step [208/735], Loss: 0.0984\n",
      "Epoch [21/50], Step [209/735], Loss: 0.0791\n",
      "Epoch [21/50], Step [210/735], Loss: 0.0655\n",
      "Epoch [21/50], Step [211/735], Loss: 0.3267\n",
      "Epoch [21/50], Step [212/735], Loss: 0.1928\n",
      "Epoch [21/50], Step [213/735], Loss: 0.1518\n",
      "Epoch [21/50], Step [214/735], Loss: 0.0724\n",
      "Epoch [21/50], Step [215/735], Loss: 0.2228\n",
      "Epoch [21/50], Step [216/735], Loss: 0.1134\n",
      "Epoch [21/50], Step [217/735], Loss: 0.1205\n",
      "Epoch [21/50], Step [218/735], Loss: 1.0502\n",
      "Epoch [21/50], Step [219/735], Loss: 0.1268\n",
      "Epoch [21/50], Step [220/735], Loss: 0.1807\n",
      "Epoch [21/50], Step [221/735], Loss: 0.1124\n",
      "Epoch [21/50], Step [222/735], Loss: 0.1035\n",
      "Epoch [21/50], Step [223/735], Loss: 0.0560\n",
      "Epoch [21/50], Step [224/735], Loss: 0.1473\n",
      "Epoch [21/50], Step [225/735], Loss: 0.0558\n",
      "Epoch [21/50], Step [226/735], Loss: 0.2296\n",
      "Epoch [21/50], Step [227/735], Loss: 0.1178\n",
      "Epoch [21/50], Step [228/735], Loss: 0.2084\n",
      "Epoch [21/50], Step [229/735], Loss: 0.2098\n",
      "Epoch [21/50], Step [230/735], Loss: 0.8709\n",
      "Epoch [21/50], Step [231/735], Loss: 0.0919\n",
      "Epoch [21/50], Step [232/735], Loss: 0.0809\n",
      "Epoch [21/50], Step [233/735], Loss: 0.0425\n",
      "Epoch [21/50], Step [234/735], Loss: 0.0752\n",
      "Epoch [21/50], Step [235/735], Loss: 0.1289\n",
      "Epoch [21/50], Step [236/735], Loss: 0.0302\n",
      "Epoch [21/50], Step [237/735], Loss: 0.2182\n",
      "Epoch [21/50], Step [238/735], Loss: 0.1322\n",
      "Epoch [21/50], Step [239/735], Loss: 0.0891\n",
      "Epoch [21/50], Step [240/735], Loss: 0.1863\n",
      "Epoch [21/50], Step [241/735], Loss: 0.0725\n",
      "Epoch [21/50], Step [242/735], Loss: 0.1657\n",
      "Epoch [21/50], Step [243/735], Loss: 0.0361\n",
      "Epoch [21/50], Step [244/735], Loss: 0.1349\n",
      "Epoch [21/50], Step [245/735], Loss: 0.2138\n",
      "Epoch [21/50], Step [246/735], Loss: 0.0466\n",
      "Epoch [21/50], Step [247/735], Loss: 0.0963\n",
      "Epoch [21/50], Step [248/735], Loss: 0.1790\n",
      "Epoch [21/50], Step [249/735], Loss: 0.0426\n",
      "Epoch [21/50], Step [250/735], Loss: 0.1388\n",
      "Epoch [21/50], Step [251/735], Loss: 0.1487\n",
      "Epoch [21/50], Step [252/735], Loss: 0.2141\n",
      "Epoch [21/50], Step [253/735], Loss: 0.1789\n",
      "Epoch [21/50], Step [254/735], Loss: 0.1905\n",
      "Epoch [21/50], Step [255/735], Loss: 0.2944\n",
      "Epoch [21/50], Step [256/735], Loss: 0.0453\n",
      "Epoch [21/50], Step [257/735], Loss: 0.1689\n",
      "Epoch [21/50], Step [258/735], Loss: 0.3092\n",
      "Epoch [21/50], Step [259/735], Loss: 0.0877\n",
      "Epoch [21/50], Step [260/735], Loss: 0.1058\n",
      "Epoch [21/50], Step [261/735], Loss: 0.2026\n",
      "Epoch [21/50], Step [262/735], Loss: 0.1449\n",
      "Epoch [21/50], Step [263/735], Loss: 0.1754\n",
      "Epoch [21/50], Step [264/735], Loss: 1.1570\n",
      "Epoch [21/50], Step [265/735], Loss: 0.2489\n",
      "Epoch [21/50], Step [266/735], Loss: 0.2694\n",
      "Epoch [21/50], Step [267/735], Loss: 0.1758\n",
      "Epoch [21/50], Step [268/735], Loss: 0.2540\n",
      "Epoch [21/50], Step [269/735], Loss: 0.0943\n",
      "Epoch [21/50], Step [270/735], Loss: 0.1182\n",
      "Epoch [21/50], Step [271/735], Loss: 0.1810\n",
      "Epoch [21/50], Step [272/735], Loss: 0.2470\n",
      "Epoch [21/50], Step [273/735], Loss: 0.1339\n",
      "Epoch [21/50], Step [274/735], Loss: 0.1890\n",
      "Epoch [21/50], Step [275/735], Loss: 0.1542\n",
      "Epoch [21/50], Step [276/735], Loss: 0.1032\n",
      "Epoch [21/50], Step [277/735], Loss: 0.1479\n",
      "Epoch [21/50], Step [278/735], Loss: 0.1558\n",
      "Epoch [21/50], Step [279/735], Loss: 0.1694\n",
      "Epoch [21/50], Step [280/735], Loss: 0.1132\n",
      "Epoch [21/50], Step [281/735], Loss: 0.3776\n",
      "Epoch [21/50], Step [282/735], Loss: 0.1402\n",
      "Epoch [21/50], Step [283/735], Loss: 0.0922\n",
      "Epoch [21/50], Step [284/735], Loss: 0.2574\n",
      "Epoch [21/50], Step [285/735], Loss: 0.1134\n",
      "Epoch [21/50], Step [286/735], Loss: 0.1357\n",
      "Epoch [21/50], Step [287/735], Loss: 0.0428\n",
      "Epoch [21/50], Step [288/735], Loss: 0.2946\n",
      "Epoch [21/50], Step [289/735], Loss: 0.1007\n",
      "Epoch [21/50], Step [290/735], Loss: 0.4072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Step [291/735], Loss: 0.1625\n",
      "Epoch [21/50], Step [292/735], Loss: 0.1022\n",
      "Epoch [21/50], Step [293/735], Loss: 0.2308\n",
      "Epoch [21/50], Step [294/735], Loss: 0.3088\n",
      "Epoch [21/50], Step [295/735], Loss: 1.3987\n",
      "Epoch [21/50], Step [296/735], Loss: 0.1080\n",
      "Epoch [21/50], Step [297/735], Loss: 0.1618\n",
      "Epoch [21/50], Step [298/735], Loss: 0.1473\n",
      "Epoch [21/50], Step [299/735], Loss: 0.0599\n",
      "Epoch [21/50], Step [300/735], Loss: 0.0856\n",
      "Epoch [21/50], Step [301/735], Loss: 0.0248\n",
      "Epoch [21/50], Step [302/735], Loss: 0.0303\n",
      "Epoch [21/50], Step [303/735], Loss: 0.2607\n",
      "Epoch [21/50], Step [304/735], Loss: 0.2894\n",
      "Epoch [21/50], Step [305/735], Loss: 0.1723\n",
      "Epoch [21/50], Step [306/735], Loss: 0.0389\n",
      "Epoch [21/50], Step [307/735], Loss: 0.0403\n",
      "Epoch [21/50], Step [308/735], Loss: 0.1231\n",
      "Epoch [21/50], Step [309/735], Loss: 0.0649\n",
      "Epoch [21/50], Step [310/735], Loss: 0.0907\n",
      "Epoch [21/50], Step [311/735], Loss: 0.2483\n",
      "Epoch [21/50], Step [312/735], Loss: 0.1176\n",
      "Epoch [21/50], Step [313/735], Loss: 0.5759\n",
      "Epoch [21/50], Step [314/735], Loss: 0.1539\n",
      "Epoch [21/50], Step [315/735], Loss: 0.0878\n",
      "Epoch [21/50], Step [316/735], Loss: 0.7790\n",
      "Epoch [21/50], Step [317/735], Loss: 0.1476\n",
      "Epoch [21/50], Step [318/735], Loss: 0.0828\n",
      "Epoch [21/50], Step [319/735], Loss: 0.0792\n",
      "Epoch [21/50], Step [320/735], Loss: 0.0501\n",
      "Epoch [21/50], Step [321/735], Loss: 0.5553\n",
      "Epoch [21/50], Step [322/735], Loss: 0.0935\n",
      "Epoch [21/50], Step [323/735], Loss: 0.0774\n",
      "Epoch [21/50], Step [324/735], Loss: 0.1305\n",
      "Epoch [21/50], Step [325/735], Loss: 0.0773\n",
      "Epoch [21/50], Step [326/735], Loss: 0.0686\n",
      "Epoch [21/50], Step [327/735], Loss: 0.0617\n",
      "Epoch [21/50], Step [328/735], Loss: 0.0873\n",
      "Epoch [21/50], Step [329/735], Loss: 0.0280\n",
      "Epoch [21/50], Step [330/735], Loss: 0.0862\n",
      "Epoch [21/50], Step [331/735], Loss: 0.4461\n",
      "Epoch [21/50], Step [332/735], Loss: 0.8209\n",
      "Epoch [21/50], Step [333/735], Loss: 0.4009\n",
      "Epoch [21/50], Step [334/735], Loss: 0.0809\n",
      "Epoch [21/50], Step [335/735], Loss: 0.1488\n",
      "Epoch [21/50], Step [336/735], Loss: 0.0849\n",
      "Epoch [21/50], Step [337/735], Loss: 0.1792\n",
      "Epoch [21/50], Step [338/735], Loss: 0.2859\n",
      "Epoch [21/50], Step [339/735], Loss: 0.1785\n",
      "Epoch [21/50], Step [340/735], Loss: 0.2603\n",
      "Epoch [21/50], Step [341/735], Loss: 0.1232\n",
      "Epoch [21/50], Step [342/735], Loss: 0.0589\n",
      "Epoch [21/50], Step [343/735], Loss: 0.1189\n",
      "Epoch [21/50], Step [344/735], Loss: 0.2903\n",
      "Epoch [21/50], Step [345/735], Loss: 0.1899\n",
      "Epoch [21/50], Step [346/735], Loss: 0.1339\n",
      "Epoch [21/50], Step [347/735], Loss: 0.0655\n",
      "Epoch [21/50], Step [348/735], Loss: 0.0831\n",
      "Epoch [21/50], Step [349/735], Loss: 0.2271\n",
      "Epoch [21/50], Step [350/735], Loss: 0.1735\n",
      "Epoch [21/50], Step [351/735], Loss: 0.3081\n",
      "Epoch [21/50], Step [352/735], Loss: 0.4270\n",
      "Epoch [21/50], Step [353/735], Loss: 0.0836\n",
      "Epoch [21/50], Step [354/735], Loss: 0.2116\n",
      "Epoch [21/50], Step [355/735], Loss: 0.2634\n",
      "Epoch [21/50], Step [356/735], Loss: 2.5723\n",
      "Epoch [21/50], Step [357/735], Loss: 0.4007\n",
      "Epoch [21/50], Step [358/735], Loss: 0.1513\n",
      "Epoch [21/50], Step [359/735], Loss: 0.1447\n",
      "Epoch [21/50], Step [360/735], Loss: 0.1541\n",
      "Epoch [21/50], Step [361/735], Loss: 0.0931\n",
      "Epoch [21/50], Step [362/735], Loss: 0.0681\n",
      "Epoch [21/50], Step [363/735], Loss: 0.1133\n",
      "Epoch [21/50], Step [364/735], Loss: 0.2401\n",
      "Epoch [21/50], Step [365/735], Loss: 0.0624\n",
      "Epoch [21/50], Step [366/735], Loss: 0.2195\n",
      "Epoch [21/50], Step [367/735], Loss: 0.0953\n",
      "Epoch [21/50], Step [368/735], Loss: 0.0753\n",
      "Epoch [21/50], Step [369/735], Loss: 0.1734\n",
      "Epoch [21/50], Step [370/735], Loss: 0.2345\n",
      "Epoch [21/50], Step [371/735], Loss: 0.1018\n",
      "Epoch [21/50], Step [372/735], Loss: 0.6044\n",
      "Epoch [21/50], Step [373/735], Loss: 0.1622\n",
      "Epoch [21/50], Step [374/735], Loss: 0.1308\n",
      "Epoch [21/50], Step [375/735], Loss: 0.1802\n",
      "Epoch [21/50], Step [376/735], Loss: 0.1648\n",
      "Epoch [21/50], Step [377/735], Loss: 0.2120\n",
      "Epoch [21/50], Step [378/735], Loss: 0.1182\n",
      "Epoch [21/50], Step [379/735], Loss: 0.1589\n",
      "Epoch [21/50], Step [380/735], Loss: 0.0813\n",
      "Epoch [21/50], Step [381/735], Loss: 0.6686\n",
      "Epoch [21/50], Step [382/735], Loss: 0.1195\n",
      "Epoch [21/50], Step [383/735], Loss: 0.2387\n",
      "Epoch [21/50], Step [384/735], Loss: 0.2198\n",
      "Epoch [21/50], Step [385/735], Loss: 0.2279\n",
      "Epoch [21/50], Step [386/735], Loss: 0.1348\n",
      "Epoch [21/50], Step [387/735], Loss: 0.0805\n",
      "Epoch [21/50], Step [388/735], Loss: 0.1603\n",
      "Epoch [21/50], Step [389/735], Loss: 0.1335\n",
      "Epoch [21/50], Step [390/735], Loss: 0.0862\n",
      "Epoch [21/50], Step [391/735], Loss: 0.1474\n",
      "Epoch [21/50], Step [392/735], Loss: 0.6637\n",
      "Epoch [21/50], Step [393/735], Loss: 0.0867\n",
      "Epoch [21/50], Step [394/735], Loss: 0.0373\n",
      "Epoch [21/50], Step [395/735], Loss: 0.1219\n",
      "Epoch [21/50], Step [396/735], Loss: 0.0845\n",
      "Epoch [21/50], Step [397/735], Loss: 0.0983\n",
      "Epoch [21/50], Step [398/735], Loss: 0.2419\n",
      "Epoch [21/50], Step [399/735], Loss: 0.0433\n",
      "Epoch [21/50], Step [400/735], Loss: 0.1177\n",
      "Epoch [21/50], Step [401/735], Loss: 0.0553\n",
      "Epoch [21/50], Step [402/735], Loss: 0.2789\n",
      "Epoch [21/50], Step [403/735], Loss: 0.1101\n",
      "Epoch [21/50], Step [404/735], Loss: 0.1059\n",
      "Epoch [21/50], Step [405/735], Loss: 0.0547\n",
      "Epoch [21/50], Step [406/735], Loss: 0.1368\n",
      "Epoch [21/50], Step [407/735], Loss: 0.1454\n",
      "Epoch [21/50], Step [408/735], Loss: 0.2148\n",
      "Epoch [21/50], Step [409/735], Loss: 0.1902\n",
      "Epoch [21/50], Step [410/735], Loss: 0.0661\n",
      "Epoch [21/50], Step [411/735], Loss: 0.1154\n",
      "Epoch [21/50], Step [412/735], Loss: 0.3085\n",
      "Epoch [21/50], Step [413/735], Loss: 0.0826\n",
      "Epoch [21/50], Step [414/735], Loss: 0.0660\n",
      "Epoch [21/50], Step [415/735], Loss: 0.1561\n",
      "Epoch [21/50], Step [416/735], Loss: 0.0710\n",
      "Epoch [21/50], Step [417/735], Loss: 0.0706\n",
      "Epoch [21/50], Step [418/735], Loss: 2.2226\n",
      "Epoch [21/50], Step [419/735], Loss: 0.0445\n",
      "Epoch [21/50], Step [420/735], Loss: 0.1386\n",
      "Epoch [21/50], Step [421/735], Loss: 0.4308\n",
      "Epoch [21/50], Step [422/735], Loss: 0.0392\n",
      "Epoch [21/50], Step [423/735], Loss: 0.2193\n",
      "Epoch [21/50], Step [424/735], Loss: 0.3202\n",
      "Epoch [21/50], Step [425/735], Loss: 0.1116\n",
      "Epoch [21/50], Step [426/735], Loss: 0.1711\n",
      "Epoch [21/50], Step [427/735], Loss: 0.1629\n",
      "Epoch [21/50], Step [428/735], Loss: 0.1234\n",
      "Epoch [21/50], Step [429/735], Loss: 0.0860\n",
      "Epoch [21/50], Step [430/735], Loss: 0.1518\n",
      "Epoch [21/50], Step [431/735], Loss: 0.4238\n",
      "Epoch [21/50], Step [432/735], Loss: 0.0569\n",
      "Epoch [21/50], Step [433/735], Loss: 0.2467\n",
      "Epoch [21/50], Step [434/735], Loss: 0.1528\n",
      "Epoch [21/50], Step [435/735], Loss: 0.1094\n",
      "Epoch [21/50], Step [436/735], Loss: 0.1100\n",
      "Epoch [21/50], Step [437/735], Loss: 0.1408\n",
      "Epoch [21/50], Step [438/735], Loss: 0.0974\n",
      "Epoch [21/50], Step [439/735], Loss: 0.0760\n",
      "Epoch [21/50], Step [440/735], Loss: 0.4071\n",
      "Epoch [21/50], Step [441/735], Loss: 0.2459\n",
      "Epoch [21/50], Step [442/735], Loss: 0.0973\n",
      "Epoch [21/50], Step [443/735], Loss: 0.1371\n",
      "Epoch [21/50], Step [444/735], Loss: 0.0958\n",
      "Epoch [21/50], Step [445/735], Loss: 0.1592\n",
      "Epoch [21/50], Step [446/735], Loss: 0.0835\n",
      "Epoch [21/50], Step [447/735], Loss: 0.1298\n",
      "Epoch [21/50], Step [448/735], Loss: 1.1686\n",
      "Epoch [21/50], Step [449/735], Loss: 0.1240\n",
      "Epoch [21/50], Step [450/735], Loss: 0.2103\n",
      "Epoch [21/50], Step [451/735], Loss: 0.1651\n",
      "Epoch [21/50], Step [452/735], Loss: 0.1081\n",
      "Epoch [21/50], Step [453/735], Loss: 0.1570\n",
      "Epoch [21/50], Step [454/735], Loss: 0.1098\n",
      "Epoch [21/50], Step [455/735], Loss: 0.1921\n",
      "Epoch [21/50], Step [456/735], Loss: 0.3388\n",
      "Epoch [21/50], Step [457/735], Loss: 0.0621\n",
      "Epoch [21/50], Step [458/735], Loss: 0.0948\n",
      "Epoch [21/50], Step [459/735], Loss: 0.3656\n",
      "Epoch [21/50], Step [460/735], Loss: 0.0382\n",
      "Epoch [21/50], Step [461/735], Loss: 0.2381\n",
      "Epoch [21/50], Step [462/735], Loss: 0.4088\n",
      "Epoch [21/50], Step [463/735], Loss: 0.5667\n",
      "Epoch [21/50], Step [464/735], Loss: 0.1248\n",
      "Epoch [21/50], Step [465/735], Loss: 0.0959\n",
      "Epoch [21/50], Step [466/735], Loss: 0.1845\n",
      "Epoch [21/50], Step [467/735], Loss: 0.1530\n",
      "Epoch [21/50], Step [468/735], Loss: 0.0664\n",
      "Epoch [21/50], Step [469/735], Loss: 0.2187\n",
      "Epoch [21/50], Step [470/735], Loss: 0.0547\n",
      "Epoch [21/50], Step [471/735], Loss: 0.2573\n",
      "Epoch [21/50], Step [472/735], Loss: 0.2179\n",
      "Epoch [21/50], Step [473/735], Loss: 0.0918\n",
      "Epoch [21/50], Step [474/735], Loss: 0.2588\n",
      "Epoch [21/50], Step [475/735], Loss: 0.2076\n",
      "Epoch [21/50], Step [476/735], Loss: 0.2144\n",
      "Epoch [21/50], Step [477/735], Loss: 1.2570\n",
      "Epoch [21/50], Step [478/735], Loss: 0.1371\n",
      "Epoch [21/50], Step [479/735], Loss: 0.1149\n",
      "Epoch [21/50], Step [480/735], Loss: 0.0766\n",
      "Epoch [21/50], Step [481/735], Loss: 0.1296\n",
      "Epoch [21/50], Step [482/735], Loss: 0.0324\n",
      "Epoch [21/50], Step [483/735], Loss: 0.1871\n",
      "Epoch [21/50], Step [484/735], Loss: 0.0650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Step [485/735], Loss: 0.2089\n",
      "Epoch [21/50], Step [486/735], Loss: 0.9749\n",
      "Epoch [21/50], Step [487/735], Loss: 0.0658\n",
      "Epoch [21/50], Step [488/735], Loss: 0.0403\n",
      "Epoch [21/50], Step [489/735], Loss: 0.0713\n",
      "Epoch [21/50], Step [490/735], Loss: 0.3135\n",
      "Epoch [21/50], Step [491/735], Loss: 0.1562\n",
      "Epoch [21/50], Step [492/735], Loss: 0.1764\n",
      "Epoch [21/50], Step [493/735], Loss: 0.0789\n",
      "Epoch [21/50], Step [494/735], Loss: 0.1213\n",
      "Epoch [21/50], Step [495/735], Loss: 0.3143\n",
      "Epoch [21/50], Step [496/735], Loss: 0.0754\n",
      "Epoch [21/50], Step [497/735], Loss: 0.1117\n",
      "Epoch [21/50], Step [498/735], Loss: 0.1760\n",
      "Epoch [21/50], Step [499/735], Loss: 0.0635\n",
      "Epoch [21/50], Step [500/735], Loss: 0.0552\n",
      "Epoch [21/50], Step [501/735], Loss: 0.0881\n",
      "Epoch [21/50], Step [502/735], Loss: 0.1528\n",
      "Epoch [21/50], Step [503/735], Loss: 0.0818\n",
      "Epoch [21/50], Step [504/735], Loss: 0.0869\n",
      "Epoch [21/50], Step [505/735], Loss: 0.6433\n",
      "Epoch [21/50], Step [506/735], Loss: 0.2486\n",
      "Epoch [21/50], Step [507/735], Loss: 0.1747\n",
      "Epoch [21/50], Step [508/735], Loss: 0.1061\n",
      "Epoch [21/50], Step [509/735], Loss: 0.1545\n",
      "Epoch [21/50], Step [510/735], Loss: 0.1178\n",
      "Epoch [21/50], Step [511/735], Loss: 0.0620\n",
      "Epoch [21/50], Step [512/735], Loss: 0.2166\n",
      "Epoch [21/50], Step [513/735], Loss: 0.0940\n",
      "Epoch [21/50], Step [514/735], Loss: 0.0669\n",
      "Epoch [21/50], Step [515/735], Loss: 0.1063\n",
      "Epoch [21/50], Step [516/735], Loss: 0.1460\n",
      "Epoch [21/50], Step [517/735], Loss: 0.0841\n",
      "Epoch [21/50], Step [518/735], Loss: 0.1254\n",
      "Epoch [21/50], Step [519/735], Loss: 0.1826\n",
      "Epoch [21/50], Step [520/735], Loss: 0.3204\n",
      "Epoch [21/50], Step [521/735], Loss: 0.1008\n",
      "Epoch [21/50], Step [522/735], Loss: 0.1529\n",
      "Epoch [21/50], Step [523/735], Loss: 0.2216\n",
      "Epoch [21/50], Step [524/735], Loss: 0.1485\n",
      "Epoch [21/50], Step [525/735], Loss: 0.0810\n",
      "Epoch [21/50], Step [526/735], Loss: 0.1096\n",
      "Epoch [21/50], Step [527/735], Loss: 0.1298\n",
      "Epoch [21/50], Step [528/735], Loss: 0.1465\n",
      "Epoch [21/50], Step [529/735], Loss: 1.1365\n",
      "Epoch [21/50], Step [530/735], Loss: 0.0985\n",
      "Epoch [21/50], Step [531/735], Loss: 0.2909\n",
      "Epoch [21/50], Step [532/735], Loss: 0.0828\n",
      "Epoch [21/50], Step [533/735], Loss: 0.1090\n",
      "Epoch [21/50], Step [534/735], Loss: 0.2365\n",
      "Epoch [21/50], Step [535/735], Loss: 0.1108\n",
      "Epoch [21/50], Step [536/735], Loss: 0.1286\n",
      "Epoch [21/50], Step [537/735], Loss: 0.1296\n",
      "Epoch [21/50], Step [538/735], Loss: 0.1126\n",
      "Epoch [21/50], Step [539/735], Loss: 0.1106\n",
      "Epoch [21/50], Step [540/735], Loss: 0.2157\n",
      "Epoch [21/50], Step [541/735], Loss: 0.0869\n",
      "Epoch [21/50], Step [542/735], Loss: 0.1004\n",
      "Epoch [21/50], Step [543/735], Loss: 0.1150\n",
      "Epoch [21/50], Step [544/735], Loss: 0.1452\n",
      "Epoch [21/50], Step [545/735], Loss: 0.1221\n",
      "Epoch [21/50], Step [546/735], Loss: 0.1230\n",
      "Epoch [21/50], Step [547/735], Loss: 0.0413\n",
      "Epoch [21/50], Step [548/735], Loss: 0.1033\n",
      "Epoch [21/50], Step [549/735], Loss: 0.1173\n",
      "Epoch [21/50], Step [550/735], Loss: 0.1650\n",
      "Epoch [21/50], Step [551/735], Loss: 0.3277\n",
      "Epoch [21/50], Step [552/735], Loss: 0.1744\n",
      "Epoch [21/50], Step [553/735], Loss: 0.1757\n",
      "Epoch [21/50], Step [554/735], Loss: 0.2759\n",
      "Epoch [21/50], Step [555/735], Loss: 0.2417\n",
      "Epoch [21/50], Step [556/735], Loss: 0.1399\n",
      "Epoch [21/50], Step [557/735], Loss: 0.1673\n",
      "Epoch [21/50], Step [558/735], Loss: 0.1881\n",
      "Epoch [21/50], Step [559/735], Loss: 0.1102\n",
      "Epoch [21/50], Step [560/735], Loss: 0.0653\n",
      "Epoch [21/50], Step [561/735], Loss: 0.1705\n",
      "Epoch [21/50], Step [562/735], Loss: 0.1511\n",
      "Epoch [21/50], Step [563/735], Loss: 0.0955\n",
      "Epoch [21/50], Step [564/735], Loss: 0.3655\n",
      "Epoch [21/50], Step [565/735], Loss: 0.2181\n",
      "Epoch [21/50], Step [566/735], Loss: 0.1574\n",
      "Epoch [21/50], Step [567/735], Loss: 0.1215\n",
      "Epoch [21/50], Step [568/735], Loss: 0.1568\n",
      "Epoch [21/50], Step [569/735], Loss: 0.0715\n",
      "Epoch [21/50], Step [570/735], Loss: 0.1101\n",
      "Epoch [21/50], Step [571/735], Loss: 0.2114\n",
      "Epoch [21/50], Step [572/735], Loss: 0.0588\n",
      "Epoch [21/50], Step [573/735], Loss: 0.1131\n",
      "Epoch [21/50], Step [574/735], Loss: 0.5135\n",
      "Epoch [21/50], Step [575/735], Loss: 0.0492\n",
      "Epoch [21/50], Step [576/735], Loss: 0.1420\n",
      "Epoch [21/50], Step [577/735], Loss: 0.1254\n",
      "Epoch [21/50], Step [578/735], Loss: 0.0754\n",
      "Epoch [21/50], Step [579/735], Loss: 0.1526\n",
      "Epoch [21/50], Step [580/735], Loss: 0.1185\n",
      "Epoch [21/50], Step [581/735], Loss: 0.2146\n",
      "Epoch [21/50], Step [582/735], Loss: 0.1831\n",
      "Epoch [21/50], Step [583/735], Loss: 0.0770\n",
      "Epoch [21/50], Step [584/735], Loss: 0.7830\n",
      "Epoch [21/50], Step [585/735], Loss: 0.0988\n",
      "Epoch [21/50], Step [586/735], Loss: 0.1184\n",
      "Epoch [21/50], Step [587/735], Loss: 0.0689\n",
      "Epoch [21/50], Step [588/735], Loss: 0.1645\n",
      "Epoch [21/50], Step [589/735], Loss: 0.0980\n",
      "Epoch [21/50], Step [590/735], Loss: 0.0516\n",
      "Epoch [21/50], Step [591/735], Loss: 0.1460\n",
      "Epoch [21/50], Step [592/735], Loss: 0.7790\n",
      "Epoch [21/50], Step [593/735], Loss: 0.1050\n",
      "Epoch [21/50], Step [594/735], Loss: 0.0566\n",
      "Epoch [21/50], Step [595/735], Loss: 0.1138\n",
      "Epoch [21/50], Step [596/735], Loss: 0.1094\n",
      "Epoch [21/50], Step [597/735], Loss: 0.0559\n",
      "Epoch [21/50], Step [598/735], Loss: 0.4278\n",
      "Epoch [21/50], Step [599/735], Loss: 0.0851\n",
      "Epoch [21/50], Step [600/735], Loss: 0.1707\n",
      "Epoch [21/50], Step [601/735], Loss: 0.1328\n",
      "Epoch [21/50], Step [602/735], Loss: 0.0501\n",
      "Epoch [21/50], Step [603/735], Loss: 0.0501\n",
      "Epoch [21/50], Step [604/735], Loss: 2.0682\n",
      "Epoch [21/50], Step [605/735], Loss: 0.0815\n",
      "Epoch [21/50], Step [606/735], Loss: 0.1440\n",
      "Epoch [21/50], Step [607/735], Loss: 0.2758\n",
      "Epoch [21/50], Step [608/735], Loss: 0.0858\n",
      "Epoch [21/50], Step [609/735], Loss: 0.1084\n",
      "Epoch [21/50], Step [610/735], Loss: 0.1239\n",
      "Epoch [21/50], Step [611/735], Loss: 0.1166\n",
      "Epoch [21/50], Step [612/735], Loss: 0.1284\n",
      "Epoch [21/50], Step [613/735], Loss: 0.8271\n",
      "Epoch [21/50], Step [614/735], Loss: 0.0357\n",
      "Epoch [21/50], Step [615/735], Loss: 0.0812\n",
      "Epoch [21/50], Step [616/735], Loss: 0.0769\n",
      "Epoch [21/50], Step [617/735], Loss: 0.1737\n",
      "Epoch [21/50], Step [618/735], Loss: 0.2613\n",
      "Epoch [21/50], Step [619/735], Loss: 0.1303\n",
      "Epoch [21/50], Step [620/735], Loss: 0.1166\n",
      "Epoch [21/50], Step [621/735], Loss: 0.1981\n",
      "Epoch [21/50], Step [622/735], Loss: 1.9701\n",
      "Epoch [21/50], Step [623/735], Loss: 0.1761\n",
      "Epoch [21/50], Step [624/735], Loss: 0.1118\n",
      "Epoch [21/50], Step [625/735], Loss: 0.0616\n",
      "Epoch [21/50], Step [626/735], Loss: 0.1958\n",
      "Epoch [21/50], Step [627/735], Loss: 0.1519\n",
      "Epoch [21/50], Step [628/735], Loss: 0.2368\n",
      "Epoch [21/50], Step [629/735], Loss: 0.0540\n",
      "Epoch [21/50], Step [630/735], Loss: 0.0799\n",
      "Epoch [21/50], Step [631/735], Loss: 0.1979\n",
      "Epoch [21/50], Step [632/735], Loss: 0.2887\n",
      "Epoch [21/50], Step [633/735], Loss: 0.0879\n",
      "Epoch [21/50], Step [634/735], Loss: 0.0607\n",
      "Epoch [21/50], Step [635/735], Loss: 0.0889\n",
      "Epoch [21/50], Step [636/735], Loss: 0.1796\n",
      "Epoch [21/50], Step [637/735], Loss: 0.0811\n",
      "Epoch [21/50], Step [638/735], Loss: 0.3843\n",
      "Epoch [21/50], Step [639/735], Loss: 0.1060\n",
      "Epoch [21/50], Step [640/735], Loss: 0.1090\n",
      "Epoch [21/50], Step [641/735], Loss: 0.2320\n",
      "Epoch [21/50], Step [642/735], Loss: 0.2458\n",
      "Epoch [21/50], Step [643/735], Loss: 0.3694\n",
      "Epoch [21/50], Step [644/735], Loss: 0.1286\n",
      "Epoch [21/50], Step [645/735], Loss: 0.0952\n",
      "Epoch [21/50], Step [646/735], Loss: 0.1046\n",
      "Epoch [21/50], Step [647/735], Loss: 0.1429\n",
      "Epoch [21/50], Step [648/735], Loss: 0.0906\n",
      "Epoch [21/50], Step [649/735], Loss: 0.3876\n",
      "Epoch [21/50], Step [650/735], Loss: 0.3212\n",
      "Epoch [21/50], Step [651/735], Loss: 0.0822\n",
      "Epoch [21/50], Step [652/735], Loss: 0.1951\n",
      "Epoch [21/50], Step [653/735], Loss: 0.1765\n",
      "Epoch [21/50], Step [654/735], Loss: 0.9220\n",
      "Epoch [21/50], Step [655/735], Loss: 0.1967\n",
      "Epoch [21/50], Step [656/735], Loss: 0.1270\n",
      "Epoch [21/50], Step [657/735], Loss: 0.0632\n",
      "Epoch [21/50], Step [658/735], Loss: 0.0721\n",
      "Epoch [21/50], Step [659/735], Loss: 0.2113\n",
      "Epoch [21/50], Step [660/735], Loss: 0.0658\n",
      "Epoch [21/50], Step [661/735], Loss: 0.1282\n",
      "Epoch [21/50], Step [662/735], Loss: 0.0830\n",
      "Epoch [21/50], Step [663/735], Loss: 0.1210\n",
      "Epoch [21/50], Step [664/735], Loss: 0.0611\n",
      "Epoch [21/50], Step [665/735], Loss: 0.8468\n",
      "Epoch [21/50], Step [666/735], Loss: 0.0974\n",
      "Epoch [21/50], Step [667/735], Loss: 0.0357\n",
      "Epoch [21/50], Step [668/735], Loss: 0.2841\n",
      "Epoch [21/50], Step [669/735], Loss: 0.1084\n",
      "Epoch [21/50], Step [670/735], Loss: 0.2305\n",
      "Epoch [21/50], Step [671/735], Loss: 0.0381\n",
      "Epoch [21/50], Step [672/735], Loss: 0.7994\n",
      "Epoch [21/50], Step [673/735], Loss: 0.0753\n",
      "Epoch [21/50], Step [674/735], Loss: 0.9113\n",
      "Epoch [21/50], Step [675/735], Loss: 0.1796\n",
      "Epoch [21/50], Step [676/735], Loss: 0.8677\n",
      "Epoch [21/50], Step [677/735], Loss: 0.0860\n",
      "Epoch [21/50], Step [678/735], Loss: 0.4682\n",
      "Epoch [21/50], Step [679/735], Loss: 0.0942\n",
      "Epoch [21/50], Step [680/735], Loss: 0.1332\n",
      "Epoch [21/50], Step [681/735], Loss: 1.1536\n",
      "Epoch [21/50], Step [682/735], Loss: 0.1203\n",
      "Epoch [21/50], Step [683/735], Loss: 0.1287\n",
      "Epoch [21/50], Step [684/735], Loss: 0.0391\n",
      "Epoch [21/50], Step [685/735], Loss: 0.2124\n",
      "Epoch [21/50], Step [686/735], Loss: 0.2312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Step [687/735], Loss: 0.0379\n",
      "Epoch [21/50], Step [688/735], Loss: 0.0434\n",
      "Epoch [21/50], Step [689/735], Loss: 0.1568\n",
      "Epoch [21/50], Step [690/735], Loss: 0.3916\n",
      "Epoch [21/50], Step [691/735], Loss: 0.1864\n",
      "Epoch [21/50], Step [692/735], Loss: 0.1305\n",
      "Epoch [21/50], Step [693/735], Loss: 0.0782\n",
      "Epoch [21/50], Step [694/735], Loss: 0.1231\n",
      "Epoch [21/50], Step [695/735], Loss: 0.1085\n",
      "Epoch [21/50], Step [696/735], Loss: 0.0562\n",
      "Epoch [21/50], Step [697/735], Loss: 0.5279\n",
      "Epoch [21/50], Step [698/735], Loss: 0.0482\n",
      "Epoch [21/50], Step [699/735], Loss: 0.1319\n",
      "Epoch [21/50], Step [700/735], Loss: 0.0697\n",
      "Epoch [21/50], Step [701/735], Loss: 0.2761\n",
      "Epoch [21/50], Step [702/735], Loss: 0.3148\n",
      "Epoch [21/50], Step [703/735], Loss: 0.0642\n",
      "Epoch [21/50], Step [704/735], Loss: 0.0515\n",
      "Epoch [21/50], Step [705/735], Loss: 0.0933\n",
      "Epoch [21/50], Step [706/735], Loss: 0.4066\n",
      "Epoch [21/50], Step [707/735], Loss: 0.0539\n",
      "Epoch [21/50], Step [708/735], Loss: 0.0966\n",
      "Epoch [21/50], Step [709/735], Loss: 0.1528\n",
      "Epoch [21/50], Step [710/735], Loss: 0.1662\n",
      "Epoch [21/50], Step [711/735], Loss: 0.1330\n",
      "Epoch [21/50], Step [712/735], Loss: 0.1575\n",
      "Epoch [21/50], Step [713/735], Loss: 0.1657\n",
      "Epoch [21/50], Step [714/735], Loss: 0.1389\n",
      "Epoch [21/50], Step [715/735], Loss: 0.0983\n",
      "Epoch [21/50], Step [716/735], Loss: 1.1983\n",
      "Epoch [21/50], Step [717/735], Loss: 0.0582\n",
      "Epoch [21/50], Step [718/735], Loss: 0.0921\n",
      "Epoch [21/50], Step [719/735], Loss: 0.0652\n",
      "Epoch [21/50], Step [720/735], Loss: 0.1196\n",
      "Epoch [21/50], Step [721/735], Loss: 0.0988\n",
      "Epoch [21/50], Step [722/735], Loss: 0.1134\n",
      "Epoch [21/50], Step [723/735], Loss: 0.0714\n",
      "Epoch [21/50], Step [724/735], Loss: 0.0543\n",
      "Epoch [21/50], Step [725/735], Loss: 0.0561\n",
      "Epoch [21/50], Step [726/735], Loss: 0.1071\n",
      "Epoch [21/50], Step [727/735], Loss: 0.1417\n",
      "Epoch [21/50], Step [728/735], Loss: 0.0707\n",
      "Epoch [21/50], Step [729/735], Loss: 0.0957\n",
      "Epoch [21/50], Step [730/735], Loss: 0.0485\n",
      "Epoch [21/50], Step [731/735], Loss: 0.1495\n",
      "Epoch [21/50], Step [732/735], Loss: 0.0533\n",
      "Epoch [21/50], Step [733/735], Loss: 0.2477\n",
      "Epoch [21/50], Step [734/735], Loss: 0.1639\n",
      "Epoch [21/50], Step [735/735], Loss: 0.0509\n",
      "Epoch [22/50], Step [1/735], Loss: 0.3064\n",
      "Epoch [22/50], Step [2/735], Loss: 0.0931\n",
      "Epoch [22/50], Step [3/735], Loss: 0.0527\n",
      "Epoch [22/50], Step [4/735], Loss: 0.0600\n",
      "Epoch [22/50], Step [5/735], Loss: 0.1539\n",
      "Epoch [22/50], Step [6/735], Loss: 0.1329\n",
      "Epoch [22/50], Step [7/735], Loss: 0.1567\n",
      "Epoch [22/50], Step [8/735], Loss: 0.0672\n",
      "Epoch [22/50], Step [9/735], Loss: 0.0425\n",
      "Epoch [22/50], Step [10/735], Loss: 0.1656\n",
      "Epoch [22/50], Step [11/735], Loss: 0.2114\n",
      "Epoch [22/50], Step [12/735], Loss: 0.0753\n",
      "Epoch [22/50], Step [13/735], Loss: 0.0568\n",
      "Epoch [22/50], Step [14/735], Loss: 0.1379\n",
      "Epoch [22/50], Step [15/735], Loss: 0.0935\n",
      "Epoch [22/50], Step [16/735], Loss: 0.1891\n",
      "Epoch [22/50], Step [17/735], Loss: 0.1152\n",
      "Epoch [22/50], Step [18/735], Loss: 0.1021\n",
      "Epoch [22/50], Step [19/735], Loss: 0.0544\n",
      "Epoch [22/50], Step [20/735], Loss: 0.1052\n",
      "Epoch [22/50], Step [21/735], Loss: 0.2774\n",
      "Epoch [22/50], Step [22/735], Loss: 0.2063\n",
      "Epoch [22/50], Step [23/735], Loss: 0.1776\n",
      "Epoch [22/50], Step [24/735], Loss: 0.3312\n",
      "Epoch [22/50], Step [25/735], Loss: 0.1407\n",
      "Epoch [22/50], Step [26/735], Loss: 0.1253\n",
      "Epoch [22/50], Step [27/735], Loss: 0.0811\n",
      "Epoch [22/50], Step [28/735], Loss: 0.1778\n",
      "Epoch [22/50], Step [29/735], Loss: 0.2370\n",
      "Epoch [22/50], Step [30/735], Loss: 0.2088\n",
      "Epoch [22/50], Step [31/735], Loss: 0.4425\n",
      "Epoch [22/50], Step [32/735], Loss: 0.1684\n",
      "Epoch [22/50], Step [33/735], Loss: 0.1620\n",
      "Epoch [22/50], Step [34/735], Loss: 0.0825\n",
      "Epoch [22/50], Step [35/735], Loss: 0.0685\n",
      "Epoch [22/50], Step [36/735], Loss: 0.2409\n",
      "Epoch [22/50], Step [37/735], Loss: 0.2661\n",
      "Epoch [22/50], Step [38/735], Loss: 0.2857\n",
      "Epoch [22/50], Step [39/735], Loss: 0.0533\n",
      "Epoch [22/50], Step [40/735], Loss: 0.0609\n",
      "Epoch [22/50], Step [41/735], Loss: 0.1773\n",
      "Epoch [22/50], Step [42/735], Loss: 1.0477\n",
      "Epoch [22/50], Step [43/735], Loss: 0.2101\n",
      "Epoch [22/50], Step [44/735], Loss: 0.1699\n",
      "Epoch [22/50], Step [45/735], Loss: 0.1103\n",
      "Epoch [22/50], Step [46/735], Loss: 0.1823\n",
      "Epoch [22/50], Step [47/735], Loss: 0.1102\n",
      "Epoch [22/50], Step [48/735], Loss: 0.0504\n",
      "Epoch [22/50], Step [49/735], Loss: 0.1347\n",
      "Epoch [22/50], Step [50/735], Loss: 0.1788\n",
      "Epoch [22/50], Step [51/735], Loss: 0.1187\n",
      "Epoch [22/50], Step [52/735], Loss: 0.1693\n",
      "Epoch [22/50], Step [53/735], Loss: 0.0716\n",
      "Epoch [22/50], Step [54/735], Loss: 0.0934\n",
      "Epoch [22/50], Step [55/735], Loss: 0.2338\n",
      "Epoch [22/50], Step [56/735], Loss: 0.2035\n",
      "Epoch [22/50], Step [57/735], Loss: 0.1035\n",
      "Epoch [22/50], Step [58/735], Loss: 0.1060\n",
      "Epoch [22/50], Step [59/735], Loss: 0.0937\n",
      "Epoch [22/50], Step [60/735], Loss: 0.2435\n",
      "Epoch [22/50], Step [61/735], Loss: 0.2696\n",
      "Epoch [22/50], Step [62/735], Loss: 0.1084\n",
      "Epoch [22/50], Step [63/735], Loss: 0.1693\n",
      "Epoch [22/50], Step [64/735], Loss: 0.1003\n",
      "Epoch [22/50], Step [65/735], Loss: 0.1308\n",
      "Epoch [22/50], Step [66/735], Loss: 0.2457\n",
      "Epoch [22/50], Step [67/735], Loss: 0.0472\n",
      "Epoch [22/50], Step [68/735], Loss: 0.0777\n",
      "Epoch [22/50], Step [69/735], Loss: 0.0674\n",
      "Epoch [22/50], Step [70/735], Loss: 0.0689\n",
      "Epoch [22/50], Step [71/735], Loss: 0.0988\n",
      "Epoch [22/50], Step [72/735], Loss: 0.1074\n",
      "Epoch [22/50], Step [73/735], Loss: 0.1489\n",
      "Epoch [22/50], Step [74/735], Loss: 0.1043\n",
      "Epoch [22/50], Step [75/735], Loss: 0.0969\n",
      "Epoch [22/50], Step [76/735], Loss: 0.0841\n",
      "Epoch [22/50], Step [77/735], Loss: 0.3350\n",
      "Epoch [22/50], Step [78/735], Loss: 0.0708\n",
      "Epoch [22/50], Step [79/735], Loss: 0.0768\n",
      "Epoch [22/50], Step [80/735], Loss: 0.3606\n",
      "Epoch [22/50], Step [81/735], Loss: 0.0628\n",
      "Epoch [22/50], Step [82/735], Loss: 0.2108\n",
      "Epoch [22/50], Step [83/735], Loss: 0.0929\n",
      "Epoch [22/50], Step [84/735], Loss: 0.1491\n",
      "Epoch [22/50], Step [85/735], Loss: 0.0742\n",
      "Epoch [22/50], Step [86/735], Loss: 0.3714\n",
      "Epoch [22/50], Step [87/735], Loss: 0.1280\n",
      "Epoch [22/50], Step [88/735], Loss: 0.1512\n",
      "Epoch [22/50], Step [89/735], Loss: 0.0317\n",
      "Epoch [22/50], Step [90/735], Loss: 0.0439\n",
      "Epoch [22/50], Step [91/735], Loss: 0.0319\n",
      "Epoch [22/50], Step [92/735], Loss: 0.2057\n",
      "Epoch [22/50], Step [93/735], Loss: 0.1780\n",
      "Epoch [22/50], Step [94/735], Loss: 0.0938\n",
      "Epoch [22/50], Step [95/735], Loss: 0.1179\n",
      "Epoch [22/50], Step [96/735], Loss: 0.5614\n",
      "Epoch [22/50], Step [97/735], Loss: 0.0763\n",
      "Epoch [22/50], Step [98/735], Loss: 0.0792\n",
      "Epoch [22/50], Step [99/735], Loss: 2.1251\n",
      "Epoch [22/50], Step [100/735], Loss: 0.1735\n",
      "Epoch [22/50], Step [101/735], Loss: 0.1210\n",
      "Epoch [22/50], Step [102/735], Loss: 0.0647\n",
      "Epoch [22/50], Step [103/735], Loss: 0.0667\n",
      "Epoch [22/50], Step [104/735], Loss: 0.2800\n",
      "Epoch [22/50], Step [105/735], Loss: 0.0786\n",
      "Epoch [22/50], Step [106/735], Loss: 0.3946\n",
      "Epoch [22/50], Step [107/735], Loss: 0.0922\n",
      "Epoch [22/50], Step [108/735], Loss: 0.1136\n",
      "Epoch [22/50], Step [109/735], Loss: 0.0983\n",
      "Epoch [22/50], Step [110/735], Loss: 0.1852\n",
      "Epoch [22/50], Step [111/735], Loss: 0.2156\n",
      "Epoch [22/50], Step [112/735], Loss: 0.2108\n",
      "Epoch [22/50], Step [113/735], Loss: 0.3146\n",
      "Epoch [22/50], Step [114/735], Loss: 0.2167\n",
      "Epoch [22/50], Step [115/735], Loss: 0.1886\n",
      "Epoch [22/50], Step [116/735], Loss: 0.1400\n",
      "Epoch [22/50], Step [117/735], Loss: 0.1554\n",
      "Epoch [22/50], Step [118/735], Loss: 0.0935\n",
      "Epoch [22/50], Step [119/735], Loss: 0.0355\n",
      "Epoch [22/50], Step [120/735], Loss: 0.1251\n",
      "Epoch [22/50], Step [121/735], Loss: 0.2001\n",
      "Epoch [22/50], Step [122/735], Loss: 0.1550\n",
      "Epoch [22/50], Step [123/735], Loss: 0.0946\n",
      "Epoch [22/50], Step [124/735], Loss: 0.4400\n",
      "Epoch [22/50], Step [125/735], Loss: 0.2759\n",
      "Epoch [22/50], Step [126/735], Loss: 0.2641\n",
      "Epoch [22/50], Step [127/735], Loss: 0.4578\n",
      "Epoch [22/50], Step [128/735], Loss: 0.2807\n",
      "Epoch [22/50], Step [129/735], Loss: 0.1082\n",
      "Epoch [22/50], Step [130/735], Loss: 0.3478\n",
      "Epoch [22/50], Step [131/735], Loss: 0.1075\n",
      "Epoch [22/50], Step [132/735], Loss: 0.2677\n",
      "Epoch [22/50], Step [133/735], Loss: 0.0972\n",
      "Epoch [22/50], Step [134/735], Loss: 0.0641\n",
      "Epoch [22/50], Step [135/735], Loss: 0.1003\n",
      "Epoch [22/50], Step [136/735], Loss: 0.0903\n",
      "Epoch [22/50], Step [137/735], Loss: 0.0956\n",
      "Epoch [22/50], Step [138/735], Loss: 0.1976\n",
      "Epoch [22/50], Step [139/735], Loss: 0.2552\n",
      "Epoch [22/50], Step [140/735], Loss: 0.1283\n",
      "Epoch [22/50], Step [141/735], Loss: 0.2145\n",
      "Epoch [22/50], Step [142/735], Loss: 0.0741\n",
      "Epoch [22/50], Step [143/735], Loss: 0.2627\n",
      "Epoch [22/50], Step [144/735], Loss: 0.7714\n",
      "Epoch [22/50], Step [145/735], Loss: 0.1782\n",
      "Epoch [22/50], Step [146/735], Loss: 0.1455\n",
      "Epoch [22/50], Step [147/735], Loss: 0.1487\n",
      "Epoch [22/50], Step [148/735], Loss: 0.1910\n",
      "Epoch [22/50], Step [149/735], Loss: 0.0744\n",
      "Epoch [22/50], Step [150/735], Loss: 0.1340\n",
      "Epoch [22/50], Step [151/735], Loss: 0.1715\n",
      "Epoch [22/50], Step [152/735], Loss: 0.0406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Step [153/735], Loss: 0.1236\n",
      "Epoch [22/50], Step [154/735], Loss: 0.2060\n",
      "Epoch [22/50], Step [155/735], Loss: 0.1963\n",
      "Epoch [22/50], Step [156/735], Loss: 0.1229\n",
      "Epoch [22/50], Step [157/735], Loss: 0.0533\n",
      "Epoch [22/50], Step [158/735], Loss: 0.1741\n",
      "Epoch [22/50], Step [159/735], Loss: 1.0003\n",
      "Epoch [22/50], Step [160/735], Loss: 0.1685\n",
      "Epoch [22/50], Step [161/735], Loss: 0.0883\n",
      "Epoch [22/50], Step [162/735], Loss: 0.0274\n",
      "Epoch [22/50], Step [163/735], Loss: 0.4030\n",
      "Epoch [22/50], Step [164/735], Loss: 0.1425\n",
      "Epoch [22/50], Step [165/735], Loss: 0.3563\n",
      "Epoch [22/50], Step [166/735], Loss: 0.0257\n",
      "Epoch [22/50], Step [167/735], Loss: 0.2428\n",
      "Epoch [22/50], Step [168/735], Loss: 0.0745\n",
      "Epoch [22/50], Step [169/735], Loss: 0.0370\n",
      "Epoch [22/50], Step [170/735], Loss: 0.0606\n",
      "Epoch [22/50], Step [171/735], Loss: 1.7253\n",
      "Epoch [22/50], Step [172/735], Loss: 0.0989\n",
      "Epoch [22/50], Step [173/735], Loss: 0.2869\n",
      "Epoch [22/50], Step [174/735], Loss: 0.1096\n",
      "Epoch [22/50], Step [175/735], Loss: 0.0709\n",
      "Epoch [22/50], Step [176/735], Loss: 0.1473\n",
      "Epoch [22/50], Step [177/735], Loss: 0.0853\n",
      "Epoch [22/50], Step [178/735], Loss: 0.1339\n",
      "Epoch [22/50], Step [179/735], Loss: 0.0621\n",
      "Epoch [22/50], Step [180/735], Loss: 0.1011\n",
      "Epoch [22/50], Step [181/735], Loss: 0.0908\n",
      "Epoch [22/50], Step [182/735], Loss: 0.1214\n",
      "Epoch [22/50], Step [183/735], Loss: 0.0551\n",
      "Epoch [22/50], Step [184/735], Loss: 0.2734\n",
      "Epoch [22/50], Step [185/735], Loss: 0.1769\n",
      "Epoch [22/50], Step [186/735], Loss: 0.1281\n",
      "Epoch [22/50], Step [187/735], Loss: 0.1187\n",
      "Epoch [22/50], Step [188/735], Loss: 0.2827\n",
      "Epoch [22/50], Step [189/735], Loss: 0.0595\n",
      "Epoch [22/50], Step [190/735], Loss: 0.0469\n",
      "Epoch [22/50], Step [191/735], Loss: 0.1749\n",
      "Epoch [22/50], Step [192/735], Loss: 0.1117\n",
      "Epoch [22/50], Step [193/735], Loss: 0.1612\n",
      "Epoch [22/50], Step [194/735], Loss: 0.1275\n",
      "Epoch [22/50], Step [195/735], Loss: 0.1084\n",
      "Epoch [22/50], Step [196/735], Loss: 0.2880\n",
      "Epoch [22/50], Step [197/735], Loss: 0.4261\n",
      "Epoch [22/50], Step [198/735], Loss: 0.1746\n",
      "Epoch [22/50], Step [199/735], Loss: 0.0587\n",
      "Epoch [22/50], Step [200/735], Loss: 0.1413\n",
      "Epoch [22/50], Step [201/735], Loss: 0.4562\n",
      "Epoch [22/50], Step [202/735], Loss: 0.2776\n",
      "Epoch [22/50], Step [203/735], Loss: 0.1345\n",
      "Epoch [22/50], Step [204/735], Loss: 0.0602\n",
      "Epoch [22/50], Step [205/735], Loss: 0.1053\n",
      "Epoch [22/50], Step [206/735], Loss: 0.1809\n",
      "Epoch [22/50], Step [207/735], Loss: 0.0856\n",
      "Epoch [22/50], Step [208/735], Loss: 0.0451\n",
      "Epoch [22/50], Step [209/735], Loss: 0.1819\n",
      "Epoch [22/50], Step [210/735], Loss: 0.1676\n",
      "Epoch [22/50], Step [211/735], Loss: 0.2226\n",
      "Epoch [22/50], Step [212/735], Loss: 0.1985\n",
      "Epoch [22/50], Step [213/735], Loss: 0.0636\n",
      "Epoch [22/50], Step [214/735], Loss: 0.1105\n",
      "Epoch [22/50], Step [215/735], Loss: 0.1439\n",
      "Epoch [22/50], Step [216/735], Loss: 0.2780\n",
      "Epoch [22/50], Step [217/735], Loss: 0.0927\n",
      "Epoch [22/50], Step [218/735], Loss: 0.3855\n",
      "Epoch [22/50], Step [219/735], Loss: 0.1068\n",
      "Epoch [22/50], Step [220/735], Loss: 0.0597\n",
      "Epoch [22/50], Step [221/735], Loss: 0.1609\n",
      "Epoch [22/50], Step [222/735], Loss: 0.1251\n",
      "Epoch [22/50], Step [223/735], Loss: 0.1047\n",
      "Epoch [22/50], Step [224/735], Loss: 0.1456\n",
      "Epoch [22/50], Step [225/735], Loss: 0.4104\n",
      "Epoch [22/50], Step [226/735], Loss: 0.1286\n",
      "Epoch [22/50], Step [227/735], Loss: 0.1416\n",
      "Epoch [22/50], Step [228/735], Loss: 0.0509\n",
      "Epoch [22/50], Step [229/735], Loss: 0.1458\n",
      "Epoch [22/50], Step [230/735], Loss: 0.0802\n",
      "Epoch [22/50], Step [231/735], Loss: 0.0694\n",
      "Epoch [22/50], Step [232/735], Loss: 0.2081\n",
      "Epoch [22/50], Step [233/735], Loss: 0.0942\n",
      "Epoch [22/50], Step [234/735], Loss: 0.2706\n",
      "Epoch [22/50], Step [235/735], Loss: 0.5977\n",
      "Epoch [22/50], Step [236/735], Loss: 0.0748\n",
      "Epoch [22/50], Step [237/735], Loss: 0.2193\n",
      "Epoch [22/50], Step [238/735], Loss: 0.0669\n",
      "Epoch [22/50], Step [239/735], Loss: 0.0505\n",
      "Epoch [22/50], Step [240/735], Loss: 0.2493\n",
      "Epoch [22/50], Step [241/735], Loss: 0.1140\n",
      "Epoch [22/50], Step [242/735], Loss: 0.2904\n",
      "Epoch [22/50], Step [243/735], Loss: 0.1078\n",
      "Epoch [22/50], Step [244/735], Loss: 2.4084\n",
      "Epoch [22/50], Step [245/735], Loss: 0.4065\n",
      "Epoch [22/50], Step [246/735], Loss: 0.1126\n",
      "Epoch [22/50], Step [247/735], Loss: 0.0814\n",
      "Epoch [22/50], Step [248/735], Loss: 0.3396\n",
      "Epoch [22/50], Step [249/735], Loss: 0.1117\n",
      "Epoch [22/50], Step [250/735], Loss: 0.0753\n",
      "Epoch [22/50], Step [251/735], Loss: 0.0556\n",
      "Epoch [22/50], Step [252/735], Loss: 0.1263\n",
      "Epoch [22/50], Step [253/735], Loss: 0.0635\n",
      "Epoch [22/50], Step [254/735], Loss: 0.5464\n",
      "Epoch [22/50], Step [255/735], Loss: 1.3395\n",
      "Epoch [22/50], Step [256/735], Loss: 0.2355\n",
      "Epoch [22/50], Step [257/735], Loss: 0.1058\n",
      "Epoch [22/50], Step [258/735], Loss: 0.3516\n",
      "Epoch [22/50], Step [259/735], Loss: 0.0540\n",
      "Epoch [22/50], Step [260/735], Loss: 0.1462\n",
      "Epoch [22/50], Step [261/735], Loss: 0.1498\n",
      "Epoch [22/50], Step [262/735], Loss: 0.3238\n",
      "Epoch [22/50], Step [263/735], Loss: 0.1117\n",
      "Epoch [22/50], Step [264/735], Loss: 0.1154\n",
      "Epoch [22/50], Step [265/735], Loss: 0.1023\n",
      "Epoch [22/50], Step [266/735], Loss: 0.1116\n",
      "Epoch [22/50], Step [267/735], Loss: 0.0883\n",
      "Epoch [22/50], Step [268/735], Loss: 0.0626\n",
      "Epoch [22/50], Step [269/735], Loss: 0.1147\n",
      "Epoch [22/50], Step [270/735], Loss: 0.0954\n",
      "Epoch [22/50], Step [271/735], Loss: 0.1516\n",
      "Epoch [22/50], Step [272/735], Loss: 0.1100\n",
      "Epoch [22/50], Step [273/735], Loss: 0.1363\n",
      "Epoch [22/50], Step [274/735], Loss: 0.1649\n",
      "Epoch [22/50], Step [275/735], Loss: 0.1241\n",
      "Epoch [22/50], Step [276/735], Loss: 0.4986\n",
      "Epoch [22/50], Step [277/735], Loss: 0.1177\n",
      "Epoch [22/50], Step [278/735], Loss: 0.1141\n",
      "Epoch [22/50], Step [279/735], Loss: 0.1109\n",
      "Epoch [22/50], Step [280/735], Loss: 0.0805\n",
      "Epoch [22/50], Step [281/735], Loss: 0.1243\n",
      "Epoch [22/50], Step [282/735], Loss: 0.0679\n",
      "Epoch [22/50], Step [283/735], Loss: 0.0698\n",
      "Epoch [22/50], Step [284/735], Loss: 0.0447\n",
      "Epoch [22/50], Step [285/735], Loss: 0.2621\n",
      "Epoch [22/50], Step [286/735], Loss: 0.1820\n",
      "Epoch [22/50], Step [287/735], Loss: 0.2005\n",
      "Epoch [22/50], Step [288/735], Loss: 0.1915\n",
      "Epoch [22/50], Step [289/735], Loss: 0.0412\n",
      "Epoch [22/50], Step [290/735], Loss: 0.2105\n",
      "Epoch [22/50], Step [291/735], Loss: 0.0858\n",
      "Epoch [22/50], Step [292/735], Loss: 0.0957\n",
      "Epoch [22/50], Step [293/735], Loss: 0.1576\n",
      "Epoch [22/50], Step [294/735], Loss: 0.1726\n",
      "Epoch [22/50], Step [295/735], Loss: 0.3731\n",
      "Epoch [22/50], Step [296/735], Loss: 0.5912\n",
      "Epoch [22/50], Step [297/735], Loss: 0.5053\n",
      "Epoch [22/50], Step [298/735], Loss: 0.2392\n",
      "Epoch [22/50], Step [299/735], Loss: 0.1387\n",
      "Epoch [22/50], Step [300/735], Loss: 0.2163\n",
      "Epoch [22/50], Step [301/735], Loss: 0.0588\n",
      "Epoch [22/50], Step [302/735], Loss: 0.3356\n",
      "Epoch [22/50], Step [303/735], Loss: 0.1079\n",
      "Epoch [22/50], Step [304/735], Loss: 0.1027\n",
      "Epoch [22/50], Step [305/735], Loss: 0.1927\n",
      "Epoch [22/50], Step [306/735], Loss: 0.2052\n",
      "Epoch [22/50], Step [307/735], Loss: 0.0502\n",
      "Epoch [22/50], Step [308/735], Loss: 0.0752\n",
      "Epoch [22/50], Step [309/735], Loss: 1.1050\n",
      "Epoch [22/50], Step [310/735], Loss: 0.1219\n",
      "Epoch [22/50], Step [311/735], Loss: 1.2973\n",
      "Epoch [22/50], Step [312/735], Loss: 0.0701\n",
      "Epoch [22/50], Step [313/735], Loss: 0.1545\n",
      "Epoch [22/50], Step [314/735], Loss: 0.0413\n",
      "Epoch [22/50], Step [315/735], Loss: 0.0673\n",
      "Epoch [22/50], Step [316/735], Loss: 0.0953\n",
      "Epoch [22/50], Step [317/735], Loss: 0.0597\n",
      "Epoch [22/50], Step [318/735], Loss: 0.4606\n",
      "Epoch [22/50], Step [319/735], Loss: 0.0728\n",
      "Epoch [22/50], Step [320/735], Loss: 0.7929\n",
      "Epoch [22/50], Step [321/735], Loss: 0.3007\n",
      "Epoch [22/50], Step [322/735], Loss: 0.0871\n",
      "Epoch [22/50], Step [323/735], Loss: 0.0887\n",
      "Epoch [22/50], Step [324/735], Loss: 0.0866\n",
      "Epoch [22/50], Step [325/735], Loss: 0.3293\n",
      "Epoch [22/50], Step [326/735], Loss: 0.0433\n",
      "Epoch [22/50], Step [327/735], Loss: 0.8192\n",
      "Epoch [22/50], Step [328/735], Loss: 0.3386\n",
      "Epoch [22/50], Step [329/735], Loss: 0.1158\n",
      "Epoch [22/50], Step [330/735], Loss: 0.1956\n",
      "Epoch [22/50], Step [331/735], Loss: 0.1659\n",
      "Epoch [22/50], Step [332/735], Loss: 0.2013\n",
      "Epoch [22/50], Step [333/735], Loss: 0.4478\n",
      "Epoch [22/50], Step [334/735], Loss: 0.1247\n",
      "Epoch [22/50], Step [335/735], Loss: 0.6075\n",
      "Epoch [22/50], Step [336/735], Loss: 0.1046\n",
      "Epoch [22/50], Step [337/735], Loss: 0.0868\n",
      "Epoch [22/50], Step [338/735], Loss: 2.0720\n",
      "Epoch [22/50], Step [339/735], Loss: 0.2717\n",
      "Epoch [22/50], Step [340/735], Loss: 0.0698\n",
      "Epoch [22/50], Step [341/735], Loss: 0.0698\n",
      "Epoch [22/50], Step [342/735], Loss: 0.1954\n",
      "Epoch [22/50], Step [343/735], Loss: 0.0430\n",
      "Epoch [22/50], Step [344/735], Loss: 0.1435\n",
      "Epoch [22/50], Step [345/735], Loss: 0.0911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Step [346/735], Loss: 0.8649\n",
      "Epoch [22/50], Step [347/735], Loss: 0.0961\n",
      "Epoch [22/50], Step [348/735], Loss: 0.0682\n",
      "Epoch [22/50], Step [349/735], Loss: 0.1026\n",
      "Epoch [22/50], Step [350/735], Loss: 0.1425\n",
      "Epoch [22/50], Step [351/735], Loss: 0.1173\n",
      "Epoch [22/50], Step [352/735], Loss: 0.0669\n",
      "Epoch [22/50], Step [353/735], Loss: 0.0842\n",
      "Epoch [22/50], Step [354/735], Loss: 0.1562\n",
      "Epoch [22/50], Step [355/735], Loss: 0.1388\n",
      "Epoch [22/50], Step [356/735], Loss: 0.1107\n",
      "Epoch [22/50], Step [357/735], Loss: 0.1680\n",
      "Epoch [22/50], Step [358/735], Loss: 0.2241\n",
      "Epoch [22/50], Step [359/735], Loss: 0.1111\n",
      "Epoch [22/50], Step [360/735], Loss: 0.2077\n",
      "Epoch [22/50], Step [361/735], Loss: 0.1595\n",
      "Epoch [22/50], Step [362/735], Loss: 0.0844\n",
      "Epoch [22/50], Step [363/735], Loss: 0.0723\n",
      "Epoch [22/50], Step [364/735], Loss: 0.0837\n",
      "Epoch [22/50], Step [365/735], Loss: 0.0910\n",
      "Epoch [22/50], Step [366/735], Loss: 0.0894\n",
      "Epoch [22/50], Step [367/735], Loss: 0.0929\n",
      "Epoch [22/50], Step [368/735], Loss: 0.2095\n",
      "Epoch [22/50], Step [369/735], Loss: 0.1033\n",
      "Epoch [22/50], Step [370/735], Loss: 0.0245\n",
      "Epoch [22/50], Step [371/735], Loss: 0.1297\n",
      "Epoch [22/50], Step [372/735], Loss: 0.0567\n",
      "Epoch [22/50], Step [373/735], Loss: 0.7760\n",
      "Epoch [22/50], Step [374/735], Loss: 0.1367\n",
      "Epoch [22/50], Step [375/735], Loss: 0.2134\n",
      "Epoch [22/50], Step [376/735], Loss: 0.5383\n",
      "Epoch [22/50], Step [377/735], Loss: 0.1384\n",
      "Epoch [22/50], Step [378/735], Loss: 0.0812\n",
      "Epoch [22/50], Step [379/735], Loss: 0.0585\n",
      "Epoch [22/50], Step [380/735], Loss: 0.3498\n",
      "Epoch [22/50], Step [381/735], Loss: 0.1356\n",
      "Epoch [22/50], Step [382/735], Loss: 0.1417\n",
      "Epoch [22/50], Step [383/735], Loss: 0.1066\n",
      "Epoch [22/50], Step [384/735], Loss: 0.1433\n",
      "Epoch [22/50], Step [385/735], Loss: 0.3064\n",
      "Epoch [22/50], Step [386/735], Loss: 0.2437\n",
      "Epoch [22/50], Step [387/735], Loss: 0.1718\n",
      "Epoch [22/50], Step [388/735], Loss: 0.2758\n",
      "Epoch [22/50], Step [389/735], Loss: 0.2304\n",
      "Epoch [22/50], Step [390/735], Loss: 0.0935\n",
      "Epoch [22/50], Step [391/735], Loss: 0.1966\n",
      "Epoch [22/50], Step [392/735], Loss: 0.0305\n",
      "Epoch [22/50], Step [393/735], Loss: 0.0804\n",
      "Epoch [22/50], Step [394/735], Loss: 0.0897\n",
      "Epoch [22/50], Step [395/735], Loss: 0.1125\n",
      "Epoch [22/50], Step [396/735], Loss: 0.1051\n",
      "Epoch [22/50], Step [397/735], Loss: 0.1435\n",
      "Epoch [22/50], Step [398/735], Loss: 0.2249\n",
      "Epoch [22/50], Step [399/735], Loss: 0.1982\n",
      "Epoch [22/50], Step [400/735], Loss: 0.1919\n",
      "Epoch [22/50], Step [401/735], Loss: 0.1777\n",
      "Epoch [22/50], Step [402/735], Loss: 0.1491\n",
      "Epoch [22/50], Step [403/735], Loss: 0.0993\n",
      "Epoch [22/50], Step [404/735], Loss: 0.1139\n",
      "Epoch [22/50], Step [405/735], Loss: 0.2419\n",
      "Epoch [22/50], Step [406/735], Loss: 0.1422\n",
      "Epoch [22/50], Step [407/735], Loss: 0.1358\n",
      "Epoch [22/50], Step [408/735], Loss: 0.9154\n",
      "Epoch [22/50], Step [409/735], Loss: 0.1691\n",
      "Epoch [22/50], Step [410/735], Loss: 0.2304\n",
      "Epoch [22/50], Step [411/735], Loss: 0.3425\n",
      "Epoch [22/50], Step [412/735], Loss: 0.0601\n",
      "Epoch [22/50], Step [413/735], Loss: 0.2320\n",
      "Epoch [22/50], Step [414/735], Loss: 0.1209\n",
      "Epoch [22/50], Step [415/735], Loss: 0.0878\n",
      "Epoch [22/50], Step [416/735], Loss: 0.0621\n",
      "Epoch [22/50], Step [417/735], Loss: 0.6871\n",
      "Epoch [22/50], Step [418/735], Loss: 0.1423\n",
      "Epoch [22/50], Step [419/735], Loss: 0.1258\n",
      "Epoch [22/50], Step [420/735], Loss: 0.0612\n",
      "Epoch [22/50], Step [421/735], Loss: 0.0862\n",
      "Epoch [22/50], Step [422/735], Loss: 0.1224\n",
      "Epoch [22/50], Step [423/735], Loss: 0.0719\n",
      "Epoch [22/50], Step [424/735], Loss: 0.2447\n",
      "Epoch [22/50], Step [425/735], Loss: 0.0572\n",
      "Epoch [22/50], Step [426/735], Loss: 0.0982\n",
      "Epoch [22/50], Step [427/735], Loss: 0.0955\n",
      "Epoch [22/50], Step [428/735], Loss: 0.3139\n",
      "Epoch [22/50], Step [429/735], Loss: 0.0692\n",
      "Epoch [22/50], Step [430/735], Loss: 0.0931\n",
      "Epoch [22/50], Step [431/735], Loss: 0.1727\n",
      "Epoch [22/50], Step [432/735], Loss: 0.0676\n",
      "Epoch [22/50], Step [433/735], Loss: 0.2109\n",
      "Epoch [22/50], Step [434/735], Loss: 0.6182\n",
      "Epoch [22/50], Step [435/735], Loss: 0.0830\n",
      "Epoch [22/50], Step [436/735], Loss: 0.0407\n",
      "Epoch [22/50], Step [437/735], Loss: 0.2212\n",
      "Epoch [22/50], Step [438/735], Loss: 0.7950\n",
      "Epoch [22/50], Step [439/735], Loss: 0.1207\n",
      "Epoch [22/50], Step [440/735], Loss: 0.0577\n",
      "Epoch [22/50], Step [441/735], Loss: 0.1245\n",
      "Epoch [22/50], Step [442/735], Loss: 0.1090\n",
      "Epoch [22/50], Step [443/735], Loss: 0.1612\n",
      "Epoch [22/50], Step [444/735], Loss: 0.6530\n",
      "Epoch [22/50], Step [445/735], Loss: 0.4180\n",
      "Epoch [22/50], Step [446/735], Loss: 0.1741\n",
      "Epoch [22/50], Step [447/735], Loss: 0.1642\n",
      "Epoch [22/50], Step [448/735], Loss: 0.2492\n",
      "Epoch [22/50], Step [449/735], Loss: 0.0729\n",
      "Epoch [22/50], Step [450/735], Loss: 0.1234\n",
      "Epoch [22/50], Step [451/735], Loss: 0.1327\n",
      "Epoch [22/50], Step [452/735], Loss: 0.1416\n",
      "Epoch [22/50], Step [453/735], Loss: 0.0909\n",
      "Epoch [22/50], Step [454/735], Loss: 0.0789\n",
      "Epoch [22/50], Step [455/735], Loss: 0.1068\n",
      "Epoch [22/50], Step [456/735], Loss: 0.3083\n",
      "Epoch [22/50], Step [457/735], Loss: 0.1859\n",
      "Epoch [22/50], Step [458/735], Loss: 0.1084\n",
      "Epoch [22/50], Step [459/735], Loss: 0.0744\n",
      "Epoch [22/50], Step [460/735], Loss: 0.1038\n",
      "Epoch [22/50], Step [461/735], Loss: 0.0665\n",
      "Epoch [22/50], Step [462/735], Loss: 0.1726\n",
      "Epoch [22/50], Step [463/735], Loss: 0.0708\n",
      "Epoch [22/50], Step [464/735], Loss: 0.1721\n",
      "Epoch [22/50], Step [465/735], Loss: 0.1640\n",
      "Epoch [22/50], Step [466/735], Loss: 0.7438\n",
      "Epoch [22/50], Step [467/735], Loss: 0.1338\n",
      "Epoch [22/50], Step [468/735], Loss: 0.1514\n",
      "Epoch [22/50], Step [469/735], Loss: 1.9243\n",
      "Epoch [22/50], Step [470/735], Loss: 0.0671\n",
      "Epoch [22/50], Step [471/735], Loss: 1.8277\n",
      "Epoch [22/50], Step [472/735], Loss: 0.1576\n",
      "Epoch [22/50], Step [473/735], Loss: 0.2003\n",
      "Epoch [22/50], Step [474/735], Loss: 0.0521\n",
      "Epoch [22/50], Step [475/735], Loss: 0.2351\n",
      "Epoch [22/50], Step [476/735], Loss: 1.2022\n",
      "Epoch [22/50], Step [477/735], Loss: 0.1350\n",
      "Epoch [22/50], Step [478/735], Loss: 0.0494\n",
      "Epoch [22/50], Step [479/735], Loss: 0.2176\n",
      "Epoch [22/50], Step [480/735], Loss: 0.1624\n",
      "Epoch [22/50], Step [481/735], Loss: 0.1787\n",
      "Epoch [22/50], Step [482/735], Loss: 0.2540\n",
      "Epoch [22/50], Step [483/735], Loss: 0.0708\n",
      "Epoch [22/50], Step [484/735], Loss: 0.1885\n",
      "Epoch [22/50], Step [485/735], Loss: 0.1259\n",
      "Epoch [22/50], Step [486/735], Loss: 0.0768\n",
      "Epoch [22/50], Step [487/735], Loss: 0.0818\n",
      "Epoch [22/50], Step [488/735], Loss: 0.1255\n",
      "Epoch [22/50], Step [489/735], Loss: 0.0857\n",
      "Epoch [22/50], Step [490/735], Loss: 0.0468\n",
      "Epoch [22/50], Step [491/735], Loss: 0.1130\n",
      "Epoch [22/50], Step [492/735], Loss: 1.5754\n",
      "Epoch [22/50], Step [493/735], Loss: 0.1490\n",
      "Epoch [22/50], Step [494/735], Loss: 0.0681\n",
      "Epoch [22/50], Step [495/735], Loss: 0.1186\n",
      "Epoch [22/50], Step [496/735], Loss: 0.1566\n",
      "Epoch [22/50], Step [497/735], Loss: 0.0941\n",
      "Epoch [22/50], Step [498/735], Loss: 0.2129\n",
      "Epoch [22/50], Step [499/735], Loss: 0.1927\n",
      "Epoch [22/50], Step [500/735], Loss: 0.2653\n",
      "Epoch [22/50], Step [501/735], Loss: 0.2639\n",
      "Epoch [22/50], Step [502/735], Loss: 0.1836\n",
      "Epoch [22/50], Step [503/735], Loss: 0.2175\n",
      "Epoch [22/50], Step [504/735], Loss: 0.0714\n",
      "Epoch [22/50], Step [505/735], Loss: 0.0929\n",
      "Epoch [22/50], Step [506/735], Loss: 0.1343\n",
      "Epoch [22/50], Step [507/735], Loss: 0.1168\n",
      "Epoch [22/50], Step [508/735], Loss: 0.2449\n",
      "Epoch [22/50], Step [509/735], Loss: 0.2370\n",
      "Epoch [22/50], Step [510/735], Loss: 0.1326\n",
      "Epoch [22/50], Step [511/735], Loss: 0.1034\n",
      "Epoch [22/50], Step [512/735], Loss: 0.0628\n",
      "Epoch [22/50], Step [513/735], Loss: 0.0713\n",
      "Epoch [22/50], Step [514/735], Loss: 0.0421\n",
      "Epoch [22/50], Step [515/735], Loss: 0.0726\n",
      "Epoch [22/50], Step [516/735], Loss: 0.0420\n",
      "Epoch [22/50], Step [517/735], Loss: 0.6057\n",
      "Epoch [22/50], Step [518/735], Loss: 0.0831\n",
      "Epoch [22/50], Step [519/735], Loss: 0.1625\n",
      "Epoch [22/50], Step [520/735], Loss: 0.3512\n",
      "Epoch [22/50], Step [521/735], Loss: 0.0770\n",
      "Epoch [22/50], Step [522/735], Loss: 0.1631\n",
      "Epoch [22/50], Step [523/735], Loss: 0.0728\n",
      "Epoch [22/50], Step [524/735], Loss: 0.1020\n",
      "Epoch [22/50], Step [525/735], Loss: 0.0509\n",
      "Epoch [22/50], Step [526/735], Loss: 0.1230\n",
      "Epoch [22/50], Step [527/735], Loss: 0.0443\n",
      "Epoch [22/50], Step [528/735], Loss: 0.0934\n",
      "Epoch [22/50], Step [529/735], Loss: 0.1188\n",
      "Epoch [22/50], Step [530/735], Loss: 0.3210\n",
      "Epoch [22/50], Step [531/735], Loss: 1.3368\n",
      "Epoch [22/50], Step [532/735], Loss: 0.3218\n",
      "Epoch [22/50], Step [533/735], Loss: 0.3214\n",
      "Epoch [22/50], Step [534/735], Loss: 0.2537\n",
      "Epoch [22/50], Step [535/735], Loss: 0.3438\n",
      "Epoch [22/50], Step [536/735], Loss: 0.0986\n",
      "Epoch [22/50], Step [537/735], Loss: 0.1600\n",
      "Epoch [22/50], Step [538/735], Loss: 0.9961\n",
      "Epoch [22/50], Step [539/735], Loss: 0.0776\n",
      "Epoch [22/50], Step [540/735], Loss: 0.0810\n",
      "Epoch [22/50], Step [541/735], Loss: 0.1037\n",
      "Epoch [22/50], Step [542/735], Loss: 0.2329\n",
      "Epoch [22/50], Step [543/735], Loss: 0.3206\n",
      "Epoch [22/50], Step [544/735], Loss: 0.0727\n",
      "Epoch [22/50], Step [545/735], Loss: 0.5992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Step [546/735], Loss: 0.0648\n",
      "Epoch [22/50], Step [547/735], Loss: 0.8684\n",
      "Epoch [22/50], Step [548/735], Loss: 0.0980\n",
      "Epoch [22/50], Step [549/735], Loss: 0.1258\n",
      "Epoch [22/50], Step [550/735], Loss: 0.1576\n",
      "Epoch [22/50], Step [551/735], Loss: 0.1618\n",
      "Epoch [22/50], Step [552/735], Loss: 0.0980\n",
      "Epoch [22/50], Step [553/735], Loss: 0.1941\n",
      "Epoch [22/50], Step [554/735], Loss: 0.0691\n",
      "Epoch [22/50], Step [555/735], Loss: 0.0975\n",
      "Epoch [22/50], Step [556/735], Loss: 0.2411\n",
      "Epoch [22/50], Step [557/735], Loss: 0.0482\n",
      "Epoch [22/50], Step [558/735], Loss: 0.0996\n",
      "Epoch [22/50], Step [559/735], Loss: 0.1801\n",
      "Epoch [22/50], Step [560/735], Loss: 0.1021\n",
      "Epoch [22/50], Step [561/735], Loss: 0.1727\n",
      "Epoch [22/50], Step [562/735], Loss: 0.1555\n",
      "Epoch [22/50], Step [563/735], Loss: 0.1199\n",
      "Epoch [22/50], Step [564/735], Loss: 0.2180\n",
      "Epoch [22/50], Step [565/735], Loss: 0.1289\n",
      "Epoch [22/50], Step [566/735], Loss: 0.1998\n",
      "Epoch [22/50], Step [567/735], Loss: 0.0447\n",
      "Epoch [22/50], Step [568/735], Loss: 0.1211\n",
      "Epoch [22/50], Step [569/735], Loss: 0.0820\n",
      "Epoch [22/50], Step [570/735], Loss: 0.5978\n",
      "Epoch [22/50], Step [571/735], Loss: 0.0522\n",
      "Epoch [22/50], Step [572/735], Loss: 0.1390\n",
      "Epoch [22/50], Step [573/735], Loss: 0.0716\n",
      "Epoch [22/50], Step [574/735], Loss: 0.1649\n",
      "Epoch [22/50], Step [575/735], Loss: 0.0917\n",
      "Epoch [22/50], Step [576/735], Loss: 0.1285\n",
      "Epoch [22/50], Step [577/735], Loss: 0.2100\n",
      "Epoch [22/50], Step [578/735], Loss: 0.2275\n",
      "Epoch [22/50], Step [579/735], Loss: 0.0940\n",
      "Epoch [22/50], Step [580/735], Loss: 0.0852\n",
      "Epoch [22/50], Step [581/735], Loss: 0.8546\n",
      "Epoch [22/50], Step [582/735], Loss: 0.2110\n",
      "Epoch [22/50], Step [583/735], Loss: 0.1098\n",
      "Epoch [22/50], Step [584/735], Loss: 0.1064\n",
      "Epoch [22/50], Step [585/735], Loss: 0.1230\n",
      "Epoch [22/50], Step [586/735], Loss: 0.1418\n",
      "Epoch [22/50], Step [587/735], Loss: 0.0552\n",
      "Epoch [22/50], Step [588/735], Loss: 0.0566\n",
      "Epoch [22/50], Step [589/735], Loss: 0.0729\n",
      "Epoch [22/50], Step [590/735], Loss: 0.2878\n",
      "Epoch [22/50], Step [591/735], Loss: 0.0791\n",
      "Epoch [22/50], Step [592/735], Loss: 0.1475\n",
      "Epoch [22/50], Step [593/735], Loss: 0.1029\n",
      "Epoch [22/50], Step [594/735], Loss: 0.1321\n",
      "Epoch [22/50], Step [595/735], Loss: 0.0996\n",
      "Epoch [22/50], Step [596/735], Loss: 0.0848\n",
      "Epoch [22/50], Step [597/735], Loss: 0.0722\n",
      "Epoch [22/50], Step [598/735], Loss: 0.0476\n",
      "Epoch [22/50], Step [599/735], Loss: 0.1145\n",
      "Epoch [22/50], Step [600/735], Loss: 0.5837\n",
      "Epoch [22/50], Step [601/735], Loss: 0.0943\n",
      "Epoch [22/50], Step [602/735], Loss: 0.7389\n",
      "Epoch [22/50], Step [603/735], Loss: 0.1129\n",
      "Epoch [22/50], Step [604/735], Loss: 0.0813\n",
      "Epoch [22/50], Step [605/735], Loss: 0.3356\n",
      "Epoch [22/50], Step [606/735], Loss: 0.1368\n",
      "Epoch [22/50], Step [607/735], Loss: 0.2991\n",
      "Epoch [22/50], Step [608/735], Loss: 0.1869\n",
      "Epoch [22/50], Step [609/735], Loss: 0.0573\n",
      "Epoch [22/50], Step [610/735], Loss: 0.1002\n",
      "Epoch [22/50], Step [611/735], Loss: 0.1227\n",
      "Epoch [22/50], Step [612/735], Loss: 0.1044\n",
      "Epoch [22/50], Step [613/735], Loss: 0.0881\n",
      "Epoch [22/50], Step [614/735], Loss: 0.1966\n",
      "Epoch [22/50], Step [615/735], Loss: 0.1453\n",
      "Epoch [22/50], Step [616/735], Loss: 0.1066\n",
      "Epoch [22/50], Step [617/735], Loss: 0.0750\n",
      "Epoch [22/50], Step [618/735], Loss: 0.1083\n",
      "Epoch [22/50], Step [619/735], Loss: 0.1149\n",
      "Epoch [22/50], Step [620/735], Loss: 0.2202\n",
      "Epoch [22/50], Step [621/735], Loss: 0.1529\n",
      "Epoch [22/50], Step [622/735], Loss: 0.2434\n",
      "Epoch [22/50], Step [623/735], Loss: 0.1989\n",
      "Epoch [22/50], Step [624/735], Loss: 0.2168\n",
      "Epoch [22/50], Step [625/735], Loss: 0.0431\n",
      "Epoch [22/50], Step [626/735], Loss: 0.1016\n",
      "Epoch [22/50], Step [627/735], Loss: 0.0578\n",
      "Epoch [22/50], Step [628/735], Loss: 0.0788\n",
      "Epoch [22/50], Step [629/735], Loss: 0.3429\n",
      "Epoch [22/50], Step [630/735], Loss: 0.1544\n",
      "Epoch [22/50], Step [631/735], Loss: 0.1191\n",
      "Epoch [22/50], Step [632/735], Loss: 0.1436\n",
      "Epoch [22/50], Step [633/735], Loss: 0.1932\n",
      "Epoch [22/50], Step [634/735], Loss: 0.0979\n",
      "Epoch [22/50], Step [635/735], Loss: 0.0910\n",
      "Epoch [22/50], Step [636/735], Loss: 0.0553\n",
      "Epoch [22/50], Step [637/735], Loss: 0.1276\n",
      "Epoch [22/50], Step [638/735], Loss: 0.2787\n",
      "Epoch [22/50], Step [639/735], Loss: 0.1136\n",
      "Epoch [22/50], Step [640/735], Loss: 0.0559\n",
      "Epoch [22/50], Step [641/735], Loss: 0.0332\n",
      "Epoch [22/50], Step [642/735], Loss: 0.0423\n",
      "Epoch [22/50], Step [643/735], Loss: 0.1219\n",
      "Epoch [22/50], Step [644/735], Loss: 0.1252\n",
      "Epoch [22/50], Step [645/735], Loss: 0.1510\n",
      "Epoch [22/50], Step [646/735], Loss: 0.1494\n",
      "Epoch [22/50], Step [647/735], Loss: 0.0674\n",
      "Epoch [22/50], Step [648/735], Loss: 0.1242\n",
      "Epoch [22/50], Step [649/735], Loss: 0.0588\n",
      "Epoch [22/50], Step [650/735], Loss: 0.0570\n",
      "Epoch [22/50], Step [651/735], Loss: 0.2221\n",
      "Epoch [22/50], Step [652/735], Loss: 0.0955\n",
      "Epoch [22/50], Step [653/735], Loss: 0.2107\n",
      "Epoch [22/50], Step [654/735], Loss: 0.1272\n",
      "Epoch [22/50], Step [655/735], Loss: 0.2317\n",
      "Epoch [22/50], Step [656/735], Loss: 0.1688\n",
      "Epoch [22/50], Step [657/735], Loss: 0.1772\n",
      "Epoch [22/50], Step [658/735], Loss: 0.1475\n",
      "Epoch [22/50], Step [659/735], Loss: 0.2023\n",
      "Epoch [22/50], Step [660/735], Loss: 0.0593\n",
      "Epoch [22/50], Step [661/735], Loss: 0.1566\n",
      "Epoch [22/50], Step [662/735], Loss: 0.2423\n",
      "Epoch [22/50], Step [663/735], Loss: 0.0750\n",
      "Epoch [22/50], Step [664/735], Loss: 0.0650\n",
      "Epoch [22/50], Step [665/735], Loss: 0.0331\n",
      "Epoch [22/50], Step [666/735], Loss: 0.1023\n",
      "Epoch [22/50], Step [667/735], Loss: 0.2192\n",
      "Epoch [22/50], Step [668/735], Loss: 0.0704\n",
      "Epoch [22/50], Step [669/735], Loss: 0.0848\n",
      "Epoch [22/50], Step [670/735], Loss: 0.2250\n",
      "Epoch [22/50], Step [671/735], Loss: 0.0948\n",
      "Epoch [22/50], Step [672/735], Loss: 0.1212\n",
      "Epoch [22/50], Step [673/735], Loss: 0.1267\n",
      "Epoch [22/50], Step [674/735], Loss: 0.0682\n",
      "Epoch [22/50], Step [675/735], Loss: 0.0720\n",
      "Epoch [22/50], Step [676/735], Loss: 0.0731\n",
      "Epoch [22/50], Step [677/735], Loss: 0.2223\n",
      "Epoch [22/50], Step [678/735], Loss: 0.1049\n",
      "Epoch [22/50], Step [679/735], Loss: 0.2029\n",
      "Epoch [22/50], Step [680/735], Loss: 0.1572\n",
      "Epoch [22/50], Step [681/735], Loss: 0.0392\n",
      "Epoch [22/50], Step [682/735], Loss: 0.1594\n",
      "Epoch [22/50], Step [683/735], Loss: 0.1383\n",
      "Epoch [22/50], Step [684/735], Loss: 0.1735\n",
      "Epoch [22/50], Step [685/735], Loss: 0.5641\n",
      "Epoch [22/50], Step [686/735], Loss: 0.1336\n",
      "Epoch [22/50], Step [687/735], Loss: 0.1057\n",
      "Epoch [22/50], Step [688/735], Loss: 0.1591\n",
      "Epoch [22/50], Step [689/735], Loss: 0.2291\n",
      "Epoch [22/50], Step [690/735], Loss: 0.0812\n",
      "Epoch [22/50], Step [691/735], Loss: 0.0563\n",
      "Epoch [22/50], Step [692/735], Loss: 0.1035\n",
      "Epoch [22/50], Step [693/735], Loss: 0.3662\n",
      "Epoch [22/50], Step [694/735], Loss: 0.0725\n",
      "Epoch [22/50], Step [695/735], Loss: 0.0366\n",
      "Epoch [22/50], Step [696/735], Loss: 0.0734\n",
      "Epoch [22/50], Step [697/735], Loss: 0.0777\n",
      "Epoch [22/50], Step [698/735], Loss: 0.1258\n",
      "Epoch [22/50], Step [699/735], Loss: 0.0394\n",
      "Epoch [22/50], Step [700/735], Loss: 0.1381\n",
      "Epoch [22/50], Step [701/735], Loss: 0.1998\n",
      "Epoch [22/50], Step [702/735], Loss: 0.0824\n",
      "Epoch [22/50], Step [703/735], Loss: 0.0639\n",
      "Epoch [22/50], Step [704/735], Loss: 0.2020\n",
      "Epoch [22/50], Step [705/735], Loss: 0.1645\n",
      "Epoch [22/50], Step [706/735], Loss: 0.1318\n",
      "Epoch [22/50], Step [707/735], Loss: 0.0887\n",
      "Epoch [22/50], Step [708/735], Loss: 0.0980\n",
      "Epoch [22/50], Step [709/735], Loss: 0.0640\n",
      "Epoch [22/50], Step [710/735], Loss: 0.0640\n",
      "Epoch [22/50], Step [711/735], Loss: 0.1221\n",
      "Epoch [22/50], Step [712/735], Loss: 0.1401\n",
      "Epoch [22/50], Step [713/735], Loss: 0.0319\n",
      "Epoch [22/50], Step [714/735], Loss: 0.1244\n",
      "Epoch [22/50], Step [715/735], Loss: 0.4001\n",
      "Epoch [22/50], Step [716/735], Loss: 0.2416\n",
      "Epoch [22/50], Step [717/735], Loss: 0.1802\n",
      "Epoch [22/50], Step [718/735], Loss: 0.1048\n",
      "Epoch [22/50], Step [719/735], Loss: 0.1482\n",
      "Epoch [22/50], Step [720/735], Loss: 0.0513\n",
      "Epoch [22/50], Step [721/735], Loss: 0.0720\n",
      "Epoch [22/50], Step [722/735], Loss: 0.2684\n",
      "Epoch [22/50], Step [723/735], Loss: 0.0698\n",
      "Epoch [22/50], Step [724/735], Loss: 0.0982\n",
      "Epoch [22/50], Step [725/735], Loss: 0.8189\n",
      "Epoch [22/50], Step [726/735], Loss: 0.2085\n",
      "Epoch [22/50], Step [727/735], Loss: 0.0833\n",
      "Epoch [22/50], Step [728/735], Loss: 0.0904\n",
      "Epoch [22/50], Step [729/735], Loss: 0.1141\n",
      "Epoch [22/50], Step [730/735], Loss: 0.1353\n",
      "Epoch [22/50], Step [731/735], Loss: 0.1134\n",
      "Epoch [22/50], Step [732/735], Loss: 0.1534\n",
      "Epoch [22/50], Step [733/735], Loss: 0.1996\n",
      "Epoch [22/50], Step [734/735], Loss: 0.7754\n",
      "Epoch [22/50], Step [735/735], Loss: 0.6768\n",
      "Epoch [23/50], Step [1/735], Loss: 0.0894\n",
      "Epoch [23/50], Step [2/735], Loss: 0.2370\n",
      "Epoch [23/50], Step [3/735], Loss: 0.1958\n",
      "Epoch [23/50], Step [4/735], Loss: 0.1080\n",
      "Epoch [23/50], Step [5/735], Loss: 0.3695\n",
      "Epoch [23/50], Step [6/735], Loss: 0.0577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Step [7/735], Loss: 0.0927\n",
      "Epoch [23/50], Step [8/735], Loss: 0.2162\n",
      "Epoch [23/50], Step [9/735], Loss: 0.1029\n",
      "Epoch [23/50], Step [10/735], Loss: 0.0992\n",
      "Epoch [23/50], Step [11/735], Loss: 0.1757\n",
      "Epoch [23/50], Step [12/735], Loss: 0.0933\n",
      "Epoch [23/50], Step [13/735], Loss: 0.0944\n",
      "Epoch [23/50], Step [14/735], Loss: 0.2286\n",
      "Epoch [23/50], Step [15/735], Loss: 0.0827\n",
      "Epoch [23/50], Step [16/735], Loss: 0.1199\n",
      "Epoch [23/50], Step [17/735], Loss: 0.1963\n",
      "Epoch [23/50], Step [18/735], Loss: 0.1489\n",
      "Epoch [23/50], Step [19/735], Loss: 0.1316\n",
      "Epoch [23/50], Step [20/735], Loss: 0.2250\n",
      "Epoch [23/50], Step [21/735], Loss: 0.1319\n",
      "Epoch [23/50], Step [22/735], Loss: 0.1286\n",
      "Epoch [23/50], Step [23/735], Loss: 0.0879\n",
      "Epoch [23/50], Step [24/735], Loss: 0.1500\n",
      "Epoch [23/50], Step [25/735], Loss: 0.1797\n",
      "Epoch [23/50], Step [26/735], Loss: 0.1028\n",
      "Epoch [23/50], Step [27/735], Loss: 0.1103\n",
      "Epoch [23/50], Step [28/735], Loss: 0.1992\n",
      "Epoch [23/50], Step [29/735], Loss: 0.3256\n",
      "Epoch [23/50], Step [30/735], Loss: 0.3260\n",
      "Epoch [23/50], Step [31/735], Loss: 0.1358\n",
      "Epoch [23/50], Step [32/735], Loss: 0.1413\n",
      "Epoch [23/50], Step [33/735], Loss: 0.1455\n",
      "Epoch [23/50], Step [34/735], Loss: 0.3859\n",
      "Epoch [23/50], Step [35/735], Loss: 0.3653\n",
      "Epoch [23/50], Step [36/735], Loss: 0.1587\n",
      "Epoch [23/50], Step [37/735], Loss: 0.3536\n",
      "Epoch [23/50], Step [38/735], Loss: 0.0366\n",
      "Epoch [23/50], Step [39/735], Loss: 0.7165\n",
      "Epoch [23/50], Step [40/735], Loss: 0.0566\n",
      "Epoch [23/50], Step [41/735], Loss: 0.1574\n",
      "Epoch [23/50], Step [42/735], Loss: 0.0689\n",
      "Epoch [23/50], Step [43/735], Loss: 0.2457\n",
      "Epoch [23/50], Step [44/735], Loss: 0.0936\n",
      "Epoch [23/50], Step [45/735], Loss: 0.2137\n",
      "Epoch [23/50], Step [46/735], Loss: 0.2101\n",
      "Epoch [23/50], Step [47/735], Loss: 0.1451\n",
      "Epoch [23/50], Step [48/735], Loss: 0.0945\n",
      "Epoch [23/50], Step [49/735], Loss: 0.0765\n",
      "Epoch [23/50], Step [50/735], Loss: 0.2048\n",
      "Epoch [23/50], Step [51/735], Loss: 0.0510\n",
      "Epoch [23/50], Step [52/735], Loss: 0.1380\n",
      "Epoch [23/50], Step [53/735], Loss: 0.1086\n",
      "Epoch [23/50], Step [54/735], Loss: 0.5135\n",
      "Epoch [23/50], Step [55/735], Loss: 0.1001\n",
      "Epoch [23/50], Step [56/735], Loss: 0.1354\n",
      "Epoch [23/50], Step [57/735], Loss: 0.0912\n",
      "Epoch [23/50], Step [58/735], Loss: 0.0878\n",
      "Epoch [23/50], Step [59/735], Loss: 0.1251\n",
      "Epoch [23/50], Step [60/735], Loss: 0.4281\n",
      "Epoch [23/50], Step [61/735], Loss: 0.1464\n",
      "Epoch [23/50], Step [62/735], Loss: 0.1258\n",
      "Epoch [23/50], Step [63/735], Loss: 0.0747\n",
      "Epoch [23/50], Step [64/735], Loss: 0.1338\n",
      "Epoch [23/50], Step [65/735], Loss: 0.1576\n",
      "Epoch [23/50], Step [66/735], Loss: 0.2980\n",
      "Epoch [23/50], Step [67/735], Loss: 0.0782\n",
      "Epoch [23/50], Step [68/735], Loss: 0.1214\n",
      "Epoch [23/50], Step [69/735], Loss: 0.0728\n",
      "Epoch [23/50], Step [70/735], Loss: 0.3206\n",
      "Epoch [23/50], Step [71/735], Loss: 0.2912\n",
      "Epoch [23/50], Step [72/735], Loss: 0.2024\n",
      "Epoch [23/50], Step [73/735], Loss: 0.2096\n",
      "Epoch [23/50], Step [74/735], Loss: 0.0700\n",
      "Epoch [23/50], Step [75/735], Loss: 0.1655\n",
      "Epoch [23/50], Step [76/735], Loss: 0.0635\n",
      "Epoch [23/50], Step [77/735], Loss: 0.2060\n",
      "Epoch [23/50], Step [78/735], Loss: 0.0639\n",
      "Epoch [23/50], Step [79/735], Loss: 0.2950\n",
      "Epoch [23/50], Step [80/735], Loss: 0.0604\n",
      "Epoch [23/50], Step [81/735], Loss: 0.1654\n",
      "Epoch [23/50], Step [82/735], Loss: 2.2692\n",
      "Epoch [23/50], Step [83/735], Loss: 0.0577\n",
      "Epoch [23/50], Step [84/735], Loss: 0.3393\n",
      "Epoch [23/50], Step [85/735], Loss: 0.1716\n",
      "Epoch [23/50], Step [86/735], Loss: 0.2661\n",
      "Epoch [23/50], Step [87/735], Loss: 0.0763\n",
      "Epoch [23/50], Step [88/735], Loss: 0.0677\n",
      "Epoch [23/50], Step [89/735], Loss: 0.0962\n",
      "Epoch [23/50], Step [90/735], Loss: 0.1064\n",
      "Epoch [23/50], Step [91/735], Loss: 0.2119\n",
      "Epoch [23/50], Step [92/735], Loss: 0.1796\n",
      "Epoch [23/50], Step [93/735], Loss: 0.2183\n",
      "Epoch [23/50], Step [94/735], Loss: 0.1120\n",
      "Epoch [23/50], Step [95/735], Loss: 0.2174\n",
      "Epoch [23/50], Step [96/735], Loss: 0.1262\n",
      "Epoch [23/50], Step [97/735], Loss: 0.0580\n",
      "Epoch [23/50], Step [98/735], Loss: 0.1752\n",
      "Epoch [23/50], Step [99/735], Loss: 0.1557\n",
      "Epoch [23/50], Step [100/735], Loss: 0.1291\n",
      "Epoch [23/50], Step [101/735], Loss: 0.0518\n",
      "Epoch [23/50], Step [102/735], Loss: 0.0946\n",
      "Epoch [23/50], Step [103/735], Loss: 0.4710\n",
      "Epoch [23/50], Step [104/735], Loss: 0.0928\n",
      "Epoch [23/50], Step [105/735], Loss: 0.3628\n",
      "Epoch [23/50], Step [106/735], Loss: 0.0823\n",
      "Epoch [23/50], Step [107/735], Loss: 0.1499\n",
      "Epoch [23/50], Step [108/735], Loss: 0.0988\n",
      "Epoch [23/50], Step [109/735], Loss: 0.0440\n",
      "Epoch [23/50], Step [110/735], Loss: 0.1604\n",
      "Epoch [23/50], Step [111/735], Loss: 0.1586\n",
      "Epoch [23/50], Step [112/735], Loss: 0.1442\n",
      "Epoch [23/50], Step [113/735], Loss: 0.2847\n",
      "Epoch [23/50], Step [114/735], Loss: 0.0892\n",
      "Epoch [23/50], Step [115/735], Loss: 0.3028\n",
      "Epoch [23/50], Step [116/735], Loss: 0.0535\n",
      "Epoch [23/50], Step [117/735], Loss: 0.1001\n",
      "Epoch [23/50], Step [118/735], Loss: 0.0991\n",
      "Epoch [23/50], Step [119/735], Loss: 0.3997\n",
      "Epoch [23/50], Step [120/735], Loss: 0.0853\n",
      "Epoch [23/50], Step [121/735], Loss: 0.0872\n",
      "Epoch [23/50], Step [122/735], Loss: 1.6311\n",
      "Epoch [23/50], Step [123/735], Loss: 0.1426\n",
      "Epoch [23/50], Step [124/735], Loss: 0.1281\n",
      "Epoch [23/50], Step [125/735], Loss: 0.1583\n",
      "Epoch [23/50], Step [126/735], Loss: 0.0569\n",
      "Epoch [23/50], Step [127/735], Loss: 0.1660\n",
      "Epoch [23/50], Step [128/735], Loss: 0.1920\n",
      "Epoch [23/50], Step [129/735], Loss: 0.1011\n",
      "Epoch [23/50], Step [130/735], Loss: 0.0903\n",
      "Epoch [23/50], Step [131/735], Loss: 0.1509\n",
      "Epoch [23/50], Step [132/735], Loss: 0.2930\n",
      "Epoch [23/50], Step [133/735], Loss: 0.2522\n",
      "Epoch [23/50], Step [134/735], Loss: 0.1589\n",
      "Epoch [23/50], Step [135/735], Loss: 0.1831\n",
      "Epoch [23/50], Step [136/735], Loss: 0.7422\n",
      "Epoch [23/50], Step [137/735], Loss: 0.0267\n",
      "Epoch [23/50], Step [138/735], Loss: 0.0552\n",
      "Epoch [23/50], Step [139/735], Loss: 0.0678\n",
      "Epoch [23/50], Step [140/735], Loss: 0.6558\n",
      "Epoch [23/50], Step [141/735], Loss: 0.0923\n",
      "Epoch [23/50], Step [142/735], Loss: 0.2108\n",
      "Epoch [23/50], Step [143/735], Loss: 0.1728\n",
      "Epoch [23/50], Step [144/735], Loss: 0.1222\n",
      "Epoch [23/50], Step [145/735], Loss: 0.0870\n",
      "Epoch [23/50], Step [146/735], Loss: 0.6540\n",
      "Epoch [23/50], Step [147/735], Loss: 0.0537\n",
      "Epoch [23/50], Step [148/735], Loss: 0.0929\n",
      "Epoch [23/50], Step [149/735], Loss: 0.2066\n",
      "Epoch [23/50], Step [150/735], Loss: 0.1838\n",
      "Epoch [23/50], Step [151/735], Loss: 0.1574\n",
      "Epoch [23/50], Step [152/735], Loss: 0.1437\n",
      "Epoch [23/50], Step [153/735], Loss: 0.0951\n",
      "Epoch [23/50], Step [154/735], Loss: 0.1034\n",
      "Epoch [23/50], Step [155/735], Loss: 0.0423\n",
      "Epoch [23/50], Step [156/735], Loss: 0.1708\n",
      "Epoch [23/50], Step [157/735], Loss: 0.0751\n",
      "Epoch [23/50], Step [158/735], Loss: 0.0716\n",
      "Epoch [23/50], Step [159/735], Loss: 0.1325\n",
      "Epoch [23/50], Step [160/735], Loss: 0.0702\n",
      "Epoch [23/50], Step [161/735], Loss: 0.1604\n",
      "Epoch [23/50], Step [162/735], Loss: 0.0821\n",
      "Epoch [23/50], Step [163/735], Loss: 0.0684\n",
      "Epoch [23/50], Step [164/735], Loss: 0.1448\n",
      "Epoch [23/50], Step [165/735], Loss: 0.0869\n",
      "Epoch [23/50], Step [166/735], Loss: 0.0796\n",
      "Epoch [23/50], Step [167/735], Loss: 0.0751\n",
      "Epoch [23/50], Step [168/735], Loss: 0.1069\n",
      "Epoch [23/50], Step [169/735], Loss: 0.0752\n",
      "Epoch [23/50], Step [170/735], Loss: 0.0817\n",
      "Epoch [23/50], Step [171/735], Loss: 0.0814\n",
      "Epoch [23/50], Step [172/735], Loss: 0.1228\n",
      "Epoch [23/50], Step [173/735], Loss: 0.2588\n",
      "Epoch [23/50], Step [174/735], Loss: 0.1050\n",
      "Epoch [23/50], Step [175/735], Loss: 0.0752\n",
      "Epoch [23/50], Step [176/735], Loss: 0.1042\n",
      "Epoch [23/50], Step [177/735], Loss: 0.0751\n",
      "Epoch [23/50], Step [178/735], Loss: 0.1338\n",
      "Epoch [23/50], Step [179/735], Loss: 0.4227\n",
      "Epoch [23/50], Step [180/735], Loss: 0.1671\n",
      "Epoch [23/50], Step [181/735], Loss: 0.1530\n",
      "Epoch [23/50], Step [182/735], Loss: 0.0704\n",
      "Epoch [23/50], Step [183/735], Loss: 0.2459\n",
      "Epoch [23/50], Step [184/735], Loss: 0.0830\n",
      "Epoch [23/50], Step [185/735], Loss: 0.0823\n",
      "Epoch [23/50], Step [186/735], Loss: 0.0737\n",
      "Epoch [23/50], Step [187/735], Loss: 0.1965\n",
      "Epoch [23/50], Step [188/735], Loss: 0.8860\n",
      "Epoch [23/50], Step [189/735], Loss: 0.7234\n",
      "Epoch [23/50], Step [190/735], Loss: 0.0927\n",
      "Epoch [23/50], Step [191/735], Loss: 0.1033\n",
      "Epoch [23/50], Step [192/735], Loss: 0.0614\n",
      "Epoch [23/50], Step [193/735], Loss: 0.1078\n",
      "Epoch [23/50], Step [194/735], Loss: 0.2583\n",
      "Epoch [23/50], Step [195/735], Loss: 0.1005\n",
      "Epoch [23/50], Step [196/735], Loss: 0.0493\n",
      "Epoch [23/50], Step [197/735], Loss: 0.0915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Step [198/735], Loss: 0.1029\n",
      "Epoch [23/50], Step [199/735], Loss: 0.0650\n",
      "Epoch [23/50], Step [200/735], Loss: 0.0454\n",
      "Epoch [23/50], Step [201/735], Loss: 0.1138\n",
      "Epoch [23/50], Step [202/735], Loss: 0.1114\n",
      "Epoch [23/50], Step [203/735], Loss: 0.2686\n",
      "Epoch [23/50], Step [204/735], Loss: 0.1001\n",
      "Epoch [23/50], Step [205/735], Loss: 0.2142\n",
      "Epoch [23/50], Step [206/735], Loss: 0.1037\n",
      "Epoch [23/50], Step [207/735], Loss: 0.1664\n",
      "Epoch [23/50], Step [208/735], Loss: 0.0676\n",
      "Epoch [23/50], Step [209/735], Loss: 0.2184\n",
      "Epoch [23/50], Step [210/735], Loss: 0.0446\n",
      "Epoch [23/50], Step [211/735], Loss: 0.1214\n",
      "Epoch [23/50], Step [212/735], Loss: 0.0526\n",
      "Epoch [23/50], Step [213/735], Loss: 0.1545\n",
      "Epoch [23/50], Step [214/735], Loss: 0.1777\n",
      "Epoch [23/50], Step [215/735], Loss: 0.1036\n",
      "Epoch [23/50], Step [216/735], Loss: 0.1317\n",
      "Epoch [23/50], Step [217/735], Loss: 0.2088\n",
      "Epoch [23/50], Step [218/735], Loss: 0.1466\n",
      "Epoch [23/50], Step [219/735], Loss: 0.1201\n",
      "Epoch [23/50], Step [220/735], Loss: 0.0960\n",
      "Epoch [23/50], Step [221/735], Loss: 0.1060\n",
      "Epoch [23/50], Step [222/735], Loss: 0.0473\n",
      "Epoch [23/50], Step [223/735], Loss: 0.0326\n",
      "Epoch [23/50], Step [224/735], Loss: 0.1828\n",
      "Epoch [23/50], Step [225/735], Loss: 0.0418\n",
      "Epoch [23/50], Step [226/735], Loss: 0.1062\n",
      "Epoch [23/50], Step [227/735], Loss: 0.1244\n",
      "Epoch [23/50], Step [228/735], Loss: 0.1224\n",
      "Epoch [23/50], Step [229/735], Loss: 0.0853\n",
      "Epoch [23/50], Step [230/735], Loss: 0.0781\n",
      "Epoch [23/50], Step [231/735], Loss: 0.0638\n",
      "Epoch [23/50], Step [232/735], Loss: 0.0812\n",
      "Epoch [23/50], Step [233/735], Loss: 0.0643\n",
      "Epoch [23/50], Step [234/735], Loss: 0.2218\n",
      "Epoch [23/50], Step [235/735], Loss: 0.1227\n",
      "Epoch [23/50], Step [236/735], Loss: 0.1342\n",
      "Epoch [23/50], Step [237/735], Loss: 0.0833\n",
      "Epoch [23/50], Step [238/735], Loss: 0.0595\n",
      "Epoch [23/50], Step [239/735], Loss: 0.7348\n",
      "Epoch [23/50], Step [240/735], Loss: 0.2080\n",
      "Epoch [23/50], Step [241/735], Loss: 0.1577\n",
      "Epoch [23/50], Step [242/735], Loss: 0.1371\n",
      "Epoch [23/50], Step [243/735], Loss: 0.1443\n",
      "Epoch [23/50], Step [244/735], Loss: 0.0886\n",
      "Epoch [23/50], Step [245/735], Loss: 0.1002\n",
      "Epoch [23/50], Step [246/735], Loss: 0.1708\n",
      "Epoch [23/50], Step [247/735], Loss: 0.1928\n",
      "Epoch [23/50], Step [248/735], Loss: 0.0965\n",
      "Epoch [23/50], Step [249/735], Loss: 0.1079\n",
      "Epoch [23/50], Step [250/735], Loss: 0.0430\n",
      "Epoch [23/50], Step [251/735], Loss: 0.1134\n",
      "Epoch [23/50], Step [252/735], Loss: 0.0618\n",
      "Epoch [23/50], Step [253/735], Loss: 0.1103\n",
      "Epoch [23/50], Step [254/735], Loss: 0.1376\n",
      "Epoch [23/50], Step [255/735], Loss: 0.1458\n",
      "Epoch [23/50], Step [256/735], Loss: 0.7107\n",
      "Epoch [23/50], Step [257/735], Loss: 0.0536\n",
      "Epoch [23/50], Step [258/735], Loss: 0.3347\n",
      "Epoch [23/50], Step [259/735], Loss: 0.2501\n",
      "Epoch [23/50], Step [260/735], Loss: 0.0752\n",
      "Epoch [23/50], Step [261/735], Loss: 0.1872\n",
      "Epoch [23/50], Step [262/735], Loss: 0.1596\n",
      "Epoch [23/50], Step [263/735], Loss: 0.0622\n",
      "Epoch [23/50], Step [264/735], Loss: 0.0996\n",
      "Epoch [23/50], Step [265/735], Loss: 0.3035\n",
      "Epoch [23/50], Step [266/735], Loss: 0.5713\n",
      "Epoch [23/50], Step [267/735], Loss: 0.1401\n",
      "Epoch [23/50], Step [268/735], Loss: 0.1257\n",
      "Epoch [23/50], Step [269/735], Loss: 0.1098\n",
      "Epoch [23/50], Step [270/735], Loss: 0.0724\n",
      "Epoch [23/50], Step [271/735], Loss: 0.0332\n",
      "Epoch [23/50], Step [272/735], Loss: 0.3572\n",
      "Epoch [23/50], Step [273/735], Loss: 0.0798\n",
      "Epoch [23/50], Step [274/735], Loss: 0.6952\n",
      "Epoch [23/50], Step [275/735], Loss: 0.0773\n",
      "Epoch [23/50], Step [276/735], Loss: 0.2867\n",
      "Epoch [23/50], Step [277/735], Loss: 0.0597\n",
      "Epoch [23/50], Step [278/735], Loss: 0.1489\n",
      "Epoch [23/50], Step [279/735], Loss: 0.8413\n",
      "Epoch [23/50], Step [280/735], Loss: 0.1665\n",
      "Epoch [23/50], Step [281/735], Loss: 0.4069\n",
      "Epoch [23/50], Step [282/735], Loss: 0.0965\n",
      "Epoch [23/50], Step [283/735], Loss: 0.0488\n",
      "Epoch [23/50], Step [284/735], Loss: 0.0943\n",
      "Epoch [23/50], Step [285/735], Loss: 0.0506\n",
      "Epoch [23/50], Step [286/735], Loss: 0.0752\n",
      "Epoch [23/50], Step [287/735], Loss: 0.4694\n",
      "Epoch [23/50], Step [288/735], Loss: 0.1152\n",
      "Epoch [23/50], Step [289/735], Loss: 0.3403\n",
      "Epoch [23/50], Step [290/735], Loss: 0.4048\n",
      "Epoch [23/50], Step [291/735], Loss: 0.2766\n",
      "Epoch [23/50], Step [292/735], Loss: 0.1255\n",
      "Epoch [23/50], Step [293/735], Loss: 0.1466\n",
      "Epoch [23/50], Step [294/735], Loss: 0.0641\n",
      "Epoch [23/50], Step [295/735], Loss: 0.2091\n",
      "Epoch [23/50], Step [296/735], Loss: 0.2487\n",
      "Epoch [23/50], Step [297/735], Loss: 0.0907\n",
      "Epoch [23/50], Step [298/735], Loss: 0.2402\n",
      "Epoch [23/50], Step [299/735], Loss: 0.1665\n",
      "Epoch [23/50], Step [300/735], Loss: 0.1558\n",
      "Epoch [23/50], Step [301/735], Loss: 0.0970\n",
      "Epoch [23/50], Step [302/735], Loss: 0.0817\n",
      "Epoch [23/50], Step [303/735], Loss: 0.2207\n",
      "Epoch [23/50], Step [304/735], Loss: 0.1996\n",
      "Epoch [23/50], Step [305/735], Loss: 0.1503\n",
      "Epoch [23/50], Step [306/735], Loss: 0.1388\n",
      "Epoch [23/50], Step [307/735], Loss: 0.1434\n",
      "Epoch [23/50], Step [308/735], Loss: 0.1403\n",
      "Epoch [23/50], Step [309/735], Loss: 2.1663\n",
      "Epoch [23/50], Step [310/735], Loss: 0.1201\n",
      "Epoch [23/50], Step [311/735], Loss: 0.1787\n",
      "Epoch [23/50], Step [312/735], Loss: 0.0802\n",
      "Epoch [23/50], Step [313/735], Loss: 0.0766\n",
      "Epoch [23/50], Step [314/735], Loss: 0.0667\n",
      "Epoch [23/50], Step [315/735], Loss: 0.1758\n",
      "Epoch [23/50], Step [316/735], Loss: 0.1493\n",
      "Epoch [23/50], Step [317/735], Loss: 0.1013\n",
      "Epoch [23/50], Step [318/735], Loss: 0.2583\n",
      "Epoch [23/50], Step [319/735], Loss: 0.3165\n",
      "Epoch [23/50], Step [320/735], Loss: 0.0814\n",
      "Epoch [23/50], Step [321/735], Loss: 0.2006\n",
      "Epoch [23/50], Step [322/735], Loss: 0.0750\n",
      "Epoch [23/50], Step [323/735], Loss: 0.1319\n",
      "Epoch [23/50], Step [324/735], Loss: 0.5223\n",
      "Epoch [23/50], Step [325/735], Loss: 0.8220\n",
      "Epoch [23/50], Step [326/735], Loss: 0.1775\n",
      "Epoch [23/50], Step [327/735], Loss: 0.5057\n",
      "Epoch [23/50], Step [328/735], Loss: 0.1758\n",
      "Epoch [23/50], Step [329/735], Loss: 0.1042\n",
      "Epoch [23/50], Step [330/735], Loss: 0.0685\n",
      "Epoch [23/50], Step [331/735], Loss: 0.1655\n",
      "Epoch [23/50], Step [332/735], Loss: 0.2156\n",
      "Epoch [23/50], Step [333/735], Loss: 0.1534\n",
      "Epoch [23/50], Step [334/735], Loss: 0.2596\n",
      "Epoch [23/50], Step [335/735], Loss: 0.1263\n",
      "Epoch [23/50], Step [336/735], Loss: 0.2092\n",
      "Epoch [23/50], Step [337/735], Loss: 0.0720\n",
      "Epoch [23/50], Step [338/735], Loss: 0.1382\n",
      "Epoch [23/50], Step [339/735], Loss: 0.1625\n",
      "Epoch [23/50], Step [340/735], Loss: 0.0510\n",
      "Epoch [23/50], Step [341/735], Loss: 0.0777\n",
      "Epoch [23/50], Step [342/735], Loss: 0.1248\n",
      "Epoch [23/50], Step [343/735], Loss: 0.0725\n",
      "Epoch [23/50], Step [344/735], Loss: 0.1876\n",
      "Epoch [23/50], Step [345/735], Loss: 0.4554\n",
      "Epoch [23/50], Step [346/735], Loss: 0.2840\n",
      "Epoch [23/50], Step [347/735], Loss: 0.0468\n",
      "Epoch [23/50], Step [348/735], Loss: 0.1221\n",
      "Epoch [23/50], Step [349/735], Loss: 0.2528\n",
      "Epoch [23/50], Step [350/735], Loss: 0.2654\n",
      "Epoch [23/50], Step [351/735], Loss: 0.0801\n",
      "Epoch [23/50], Step [352/735], Loss: 0.0500\n",
      "Epoch [23/50], Step [353/735], Loss: 0.8890\n",
      "Epoch [23/50], Step [354/735], Loss: 0.0822\n",
      "Epoch [23/50], Step [355/735], Loss: 0.1085\n",
      "Epoch [23/50], Step [356/735], Loss: 0.1163\n",
      "Epoch [23/50], Step [357/735], Loss: 0.1514\n",
      "Epoch [23/50], Step [358/735], Loss: 0.1361\n",
      "Epoch [23/50], Step [359/735], Loss: 0.0992\n",
      "Epoch [23/50], Step [360/735], Loss: 0.0688\n",
      "Epoch [23/50], Step [361/735], Loss: 0.0910\n",
      "Epoch [23/50], Step [362/735], Loss: 0.0593\n",
      "Epoch [23/50], Step [363/735], Loss: 0.1034\n",
      "Epoch [23/50], Step [364/735], Loss: 0.1939\n",
      "Epoch [23/50], Step [365/735], Loss: 0.0685\n",
      "Epoch [23/50], Step [366/735], Loss: 0.0558\n",
      "Epoch [23/50], Step [367/735], Loss: 0.1458\n",
      "Epoch [23/50], Step [368/735], Loss: 0.0874\n",
      "Epoch [23/50], Step [369/735], Loss: 0.1058\n",
      "Epoch [23/50], Step [370/735], Loss: 0.0467\n",
      "Epoch [23/50], Step [371/735], Loss: 0.0784\n",
      "Epoch [23/50], Step [372/735], Loss: 0.0510\n",
      "Epoch [23/50], Step [373/735], Loss: 0.1787\n",
      "Epoch [23/50], Step [374/735], Loss: 0.1220\n",
      "Epoch [23/50], Step [375/735], Loss: 0.1104\n",
      "Epoch [23/50], Step [376/735], Loss: 0.1090\n",
      "Epoch [23/50], Step [377/735], Loss: 0.6393\n",
      "Epoch [23/50], Step [378/735], Loss: 0.1521\n",
      "Epoch [23/50], Step [379/735], Loss: 0.0803\n",
      "Epoch [23/50], Step [380/735], Loss: 1.5768\n",
      "Epoch [23/50], Step [381/735], Loss: 0.1226\n",
      "Epoch [23/50], Step [382/735], Loss: 0.1471\n",
      "Epoch [23/50], Step [383/735], Loss: 0.0648\n",
      "Epoch [23/50], Step [384/735], Loss: 0.0515\n",
      "Epoch [23/50], Step [385/735], Loss: 0.0430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Step [386/735], Loss: 0.1334\n",
      "Epoch [23/50], Step [387/735], Loss: 0.0217\n",
      "Epoch [23/50], Step [388/735], Loss: 0.0579\n",
      "Epoch [23/50], Step [389/735], Loss: 0.0671\n",
      "Epoch [23/50], Step [390/735], Loss: 0.1188\n",
      "Epoch [23/50], Step [391/735], Loss: 0.1085\n",
      "Epoch [23/50], Step [392/735], Loss: 0.1358\n",
      "Epoch [23/50], Step [393/735], Loss: 0.1224\n",
      "Epoch [23/50], Step [394/735], Loss: 0.0792\n",
      "Epoch [23/50], Step [395/735], Loss: 0.2615\n",
      "Epoch [23/50], Step [396/735], Loss: 0.0363\n",
      "Epoch [23/50], Step [397/735], Loss: 0.1434\n",
      "Epoch [23/50], Step [398/735], Loss: 0.0913\n",
      "Epoch [23/50], Step [399/735], Loss: 0.1628\n",
      "Epoch [23/50], Step [400/735], Loss: 0.2160\n",
      "Epoch [23/50], Step [401/735], Loss: 0.0717\n",
      "Epoch [23/50], Step [402/735], Loss: 0.0587\n",
      "Epoch [23/50], Step [403/735], Loss: 0.1906\n",
      "Epoch [23/50], Step [404/735], Loss: 0.0986\n",
      "Epoch [23/50], Step [405/735], Loss: 0.1414\n",
      "Epoch [23/50], Step [406/735], Loss: 1.4201\n",
      "Epoch [23/50], Step [407/735], Loss: 0.2493\n",
      "Epoch [23/50], Step [408/735], Loss: 0.0982\n",
      "Epoch [23/50], Step [409/735], Loss: 0.1296\n",
      "Epoch [23/50], Step [410/735], Loss: 0.0438\n",
      "Epoch [23/50], Step [411/735], Loss: 0.1099\n",
      "Epoch [23/50], Step [412/735], Loss: 1.4774\n",
      "Epoch [23/50], Step [413/735], Loss: 0.0709\n",
      "Epoch [23/50], Step [414/735], Loss: 0.1272\n",
      "Epoch [23/50], Step [415/735], Loss: 0.0775\n",
      "Epoch [23/50], Step [416/735], Loss: 0.0631\n",
      "Epoch [23/50], Step [417/735], Loss: 0.0455\n",
      "Epoch [23/50], Step [418/735], Loss: 0.0666\n",
      "Epoch [23/50], Step [419/735], Loss: 0.0612\n",
      "Epoch [23/50], Step [420/735], Loss: 0.0791\n",
      "Epoch [23/50], Step [421/735], Loss: 0.1093\n",
      "Epoch [23/50], Step [422/735], Loss: 0.2989\n",
      "Epoch [23/50], Step [423/735], Loss: 0.1741\n",
      "Epoch [23/50], Step [424/735], Loss: 0.3007\n",
      "Epoch [23/50], Step [425/735], Loss: 0.2687\n",
      "Epoch [23/50], Step [426/735], Loss: 0.0471\n",
      "Epoch [23/50], Step [427/735], Loss: 1.8385\n",
      "Epoch [23/50], Step [428/735], Loss: 0.1036\n",
      "Epoch [23/50], Step [429/735], Loss: 0.0774\n",
      "Epoch [23/50], Step [430/735], Loss: 0.0647\n",
      "Epoch [23/50], Step [431/735], Loss: 0.1876\n",
      "Epoch [23/50], Step [432/735], Loss: 0.1388\n",
      "Epoch [23/50], Step [433/735], Loss: 0.0685\n",
      "Epoch [23/50], Step [434/735], Loss: 0.9036\n",
      "Epoch [23/50], Step [435/735], Loss: 0.1245\n",
      "Epoch [23/50], Step [436/735], Loss: 0.5926\n",
      "Epoch [23/50], Step [437/735], Loss: 0.1984\n",
      "Epoch [23/50], Step [438/735], Loss: 0.1077\n",
      "Epoch [23/50], Step [439/735], Loss: 0.0984\n",
      "Epoch [23/50], Step [440/735], Loss: 0.0990\n",
      "Epoch [23/50], Step [441/735], Loss: 0.0917\n",
      "Epoch [23/50], Step [442/735], Loss: 0.0791\n",
      "Epoch [23/50], Step [443/735], Loss: 0.5852\n",
      "Epoch [23/50], Step [444/735], Loss: 0.0747\n",
      "Epoch [23/50], Step [445/735], Loss: 0.2042\n",
      "Epoch [23/50], Step [446/735], Loss: 0.1803\n",
      "Epoch [23/50], Step [447/735], Loss: 0.1481\n",
      "Epoch [23/50], Step [448/735], Loss: 0.2033\n",
      "Epoch [23/50], Step [449/735], Loss: 0.0599\n",
      "Epoch [23/50], Step [450/735], Loss: 0.1204\n",
      "Epoch [23/50], Step [451/735], Loss: 0.1923\n",
      "Epoch [23/50], Step [452/735], Loss: 0.1273\n",
      "Epoch [23/50], Step [453/735], Loss: 0.1477\n",
      "Epoch [23/50], Step [454/735], Loss: 0.0598\n",
      "Epoch [23/50], Step [455/735], Loss: 0.1211\n",
      "Epoch [23/50], Step [456/735], Loss: 0.0710\n",
      "Epoch [23/50], Step [457/735], Loss: 0.2639\n",
      "Epoch [23/50], Step [458/735], Loss: 0.0885\n",
      "Epoch [23/50], Step [459/735], Loss: 0.1231\n",
      "Epoch [23/50], Step [460/735], Loss: 0.1562\n",
      "Epoch [23/50], Step [461/735], Loss: 0.1264\n",
      "Epoch [23/50], Step [462/735], Loss: 0.1992\n",
      "Epoch [23/50], Step [463/735], Loss: 0.1382\n",
      "Epoch [23/50], Step [464/735], Loss: 0.1124\n",
      "Epoch [23/50], Step [465/735], Loss: 0.1113\n",
      "Epoch [23/50], Step [466/735], Loss: 0.0586\n",
      "Epoch [23/50], Step [467/735], Loss: 0.1313\n",
      "Epoch [23/50], Step [468/735], Loss: 0.0354\n",
      "Epoch [23/50], Step [469/735], Loss: 0.2917\n",
      "Epoch [23/50], Step [470/735], Loss: 0.1578\n",
      "Epoch [23/50], Step [471/735], Loss: 0.1200\n",
      "Epoch [23/50], Step [472/735], Loss: 0.0632\n",
      "Epoch [23/50], Step [473/735], Loss: 0.1943\n",
      "Epoch [23/50], Step [474/735], Loss: 0.2192\n",
      "Epoch [23/50], Step [475/735], Loss: 0.1692\n",
      "Epoch [23/50], Step [476/735], Loss: 0.0686\n",
      "Epoch [23/50], Step [477/735], Loss: 0.7030\n",
      "Epoch [23/50], Step [478/735], Loss: 0.1645\n",
      "Epoch [23/50], Step [479/735], Loss: 0.0861\n",
      "Epoch [23/50], Step [480/735], Loss: 0.0930\n",
      "Epoch [23/50], Step [481/735], Loss: 0.1249\n",
      "Epoch [23/50], Step [482/735], Loss: 0.6219\n",
      "Epoch [23/50], Step [483/735], Loss: 0.0626\n",
      "Epoch [23/50], Step [484/735], Loss: 0.2345\n",
      "Epoch [23/50], Step [485/735], Loss: 0.2945\n",
      "Epoch [23/50], Step [486/735], Loss: 0.1437\n",
      "Epoch [23/50], Step [487/735], Loss: 0.0957\n",
      "Epoch [23/50], Step [488/735], Loss: 0.6770\n",
      "Epoch [23/50], Step [489/735], Loss: 0.1166\n",
      "Epoch [23/50], Step [490/735], Loss: 0.0711\n",
      "Epoch [23/50], Step [491/735], Loss: 0.1163\n",
      "Epoch [23/50], Step [492/735], Loss: 0.1371\n",
      "Epoch [23/50], Step [493/735], Loss: 0.0440\n",
      "Epoch [23/50], Step [494/735], Loss: 0.0671\n",
      "Epoch [23/50], Step [495/735], Loss: 0.2336\n",
      "Epoch [23/50], Step [496/735], Loss: 0.1677\n",
      "Epoch [23/50], Step [497/735], Loss: 0.1257\n",
      "Epoch [23/50], Step [498/735], Loss: 0.1399\n",
      "Epoch [23/50], Step [499/735], Loss: 0.0578\n",
      "Epoch [23/50], Step [500/735], Loss: 0.1049\n",
      "Epoch [23/50], Step [501/735], Loss: 0.2136\n",
      "Epoch [23/50], Step [502/735], Loss: 0.2114\n",
      "Epoch [23/50], Step [503/735], Loss: 0.1486\n",
      "Epoch [23/50], Step [504/735], Loss: 0.1660\n",
      "Epoch [23/50], Step [505/735], Loss: 0.1510\n",
      "Epoch [23/50], Step [506/735], Loss: 0.0723\n",
      "Epoch [23/50], Step [507/735], Loss: 0.1063\n",
      "Epoch [23/50], Step [508/735], Loss: 0.1310\n",
      "Epoch [23/50], Step [509/735], Loss: 0.2131\n",
      "Epoch [23/50], Step [510/735], Loss: 0.1399\n",
      "Epoch [23/50], Step [511/735], Loss: 0.0793\n",
      "Epoch [23/50], Step [512/735], Loss: 0.3200\n",
      "Epoch [23/50], Step [513/735], Loss: 0.0919\n",
      "Epoch [23/50], Step [514/735], Loss: 0.0693\n",
      "Epoch [23/50], Step [515/735], Loss: 0.0400\n",
      "Epoch [23/50], Step [516/735], Loss: 0.1164\n",
      "Epoch [23/50], Step [517/735], Loss: 2.0647\n",
      "Epoch [23/50], Step [518/735], Loss: 0.2517\n",
      "Epoch [23/50], Step [519/735], Loss: 0.1415\n",
      "Epoch [23/50], Step [520/735], Loss: 0.1287\n",
      "Epoch [23/50], Step [521/735], Loss: 0.2174\n",
      "Epoch [23/50], Step [522/735], Loss: 0.1340\n",
      "Epoch [23/50], Step [523/735], Loss: 0.8502\n",
      "Epoch [23/50], Step [524/735], Loss: 0.1578\n",
      "Epoch [23/50], Step [525/735], Loss: 0.1639\n",
      "Epoch [23/50], Step [526/735], Loss: 0.1391\n",
      "Epoch [23/50], Step [527/735], Loss: 0.1372\n",
      "Epoch [23/50], Step [528/735], Loss: 0.1684\n",
      "Epoch [23/50], Step [529/735], Loss: 0.5283\n",
      "Epoch [23/50], Step [530/735], Loss: 0.1061\n",
      "Epoch [23/50], Step [531/735], Loss: 0.0572\n",
      "Epoch [23/50], Step [532/735], Loss: 0.8544\n",
      "Epoch [23/50], Step [533/735], Loss: 0.1951\n",
      "Epoch [23/50], Step [534/735], Loss: 0.0523\n",
      "Epoch [23/50], Step [535/735], Loss: 0.1045\n",
      "Epoch [23/50], Step [536/735], Loss: 0.1543\n",
      "Epoch [23/50], Step [537/735], Loss: 0.1885\n",
      "Epoch [23/50], Step [538/735], Loss: 0.1518\n",
      "Epoch [23/50], Step [539/735], Loss: 0.1824\n",
      "Epoch [23/50], Step [540/735], Loss: 0.2656\n",
      "Epoch [23/50], Step [541/735], Loss: 0.0668\n",
      "Epoch [23/50], Step [542/735], Loss: 0.4947\n",
      "Epoch [23/50], Step [543/735], Loss: 0.9466\n",
      "Epoch [23/50], Step [544/735], Loss: 0.0809\n",
      "Epoch [23/50], Step [545/735], Loss: 0.2735\n",
      "Epoch [23/50], Step [546/735], Loss: 0.1025\n",
      "Epoch [23/50], Step [547/735], Loss: 0.5719\n",
      "Epoch [23/50], Step [548/735], Loss: 0.0704\n",
      "Epoch [23/50], Step [549/735], Loss: 0.2205\n",
      "Epoch [23/50], Step [550/735], Loss: 0.0506\n",
      "Epoch [23/50], Step [551/735], Loss: 0.1169\n",
      "Epoch [23/50], Step [552/735], Loss: 0.5823\n",
      "Epoch [23/50], Step [553/735], Loss: 0.1159\n",
      "Epoch [23/50], Step [554/735], Loss: 0.8259\n",
      "Epoch [23/50], Step [555/735], Loss: 0.0792\n",
      "Epoch [23/50], Step [556/735], Loss: 0.0884\n",
      "Epoch [23/50], Step [557/735], Loss: 0.1709\n",
      "Epoch [23/50], Step [558/735], Loss: 0.3740\n",
      "Epoch [23/50], Step [559/735], Loss: 0.0948\n",
      "Epoch [23/50], Step [560/735], Loss: 0.5717\n",
      "Epoch [23/50], Step [561/735], Loss: 0.2683\n",
      "Epoch [23/50], Step [562/735], Loss: 0.4590\n",
      "Epoch [23/50], Step [563/735], Loss: 2.1440\n",
      "Epoch [23/50], Step [564/735], Loss: 0.1255\n",
      "Epoch [23/50], Step [565/735], Loss: 0.0908\n",
      "Epoch [23/50], Step [566/735], Loss: 0.2800\n",
      "Epoch [23/50], Step [567/735], Loss: 0.1846\n",
      "Epoch [23/50], Step [568/735], Loss: 0.1777\n",
      "Epoch [23/50], Step [569/735], Loss: 0.1146\n",
      "Epoch [23/50], Step [570/735], Loss: 0.1803\n",
      "Epoch [23/50], Step [571/735], Loss: 0.1384\n",
      "Epoch [23/50], Step [572/735], Loss: 0.1131\n",
      "Epoch [23/50], Step [573/735], Loss: 0.1144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Step [574/735], Loss: 0.0908\n",
      "Epoch [23/50], Step [575/735], Loss: 0.3505\n",
      "Epoch [23/50], Step [576/735], Loss: 0.2479\n",
      "Epoch [23/50], Step [577/735], Loss: 0.0823\n",
      "Epoch [23/50], Step [578/735], Loss: 0.0812\n",
      "Epoch [23/50], Step [579/735], Loss: 0.1934\n",
      "Epoch [23/50], Step [580/735], Loss: 0.1042\n",
      "Epoch [23/50], Step [581/735], Loss: 0.0733\n",
      "Epoch [23/50], Step [582/735], Loss: 0.0645\n",
      "Epoch [23/50], Step [583/735], Loss: 0.1779\n",
      "Epoch [23/50], Step [584/735], Loss: 0.2706\n",
      "Epoch [23/50], Step [585/735], Loss: 0.2189\n",
      "Epoch [23/50], Step [586/735], Loss: 0.0730\n",
      "Epoch [23/50], Step [587/735], Loss: 0.1110\n",
      "Epoch [23/50], Step [588/735], Loss: 0.1221\n",
      "Epoch [23/50], Step [589/735], Loss: 0.0596\n",
      "Epoch [23/50], Step [590/735], Loss: 0.1310\n",
      "Epoch [23/50], Step [591/735], Loss: 0.1880\n",
      "Epoch [23/50], Step [592/735], Loss: 0.3380\n",
      "Epoch [23/50], Step [593/735], Loss: 0.1523\n",
      "Epoch [23/50], Step [594/735], Loss: 0.0800\n",
      "Epoch [23/50], Step [595/735], Loss: 0.0926\n",
      "Epoch [23/50], Step [596/735], Loss: 0.1306\n",
      "Epoch [23/50], Step [597/735], Loss: 0.0539\n",
      "Epoch [23/50], Step [598/735], Loss: 0.0602\n",
      "Epoch [23/50], Step [599/735], Loss: 0.2569\n",
      "Epoch [23/50], Step [600/735], Loss: 0.1165\n",
      "Epoch [23/50], Step [601/735], Loss: 0.1885\n",
      "Epoch [23/50], Step [602/735], Loss: 0.0465\n",
      "Epoch [23/50], Step [603/735], Loss: 0.1060\n",
      "Epoch [23/50], Step [604/735], Loss: 0.1269\n",
      "Epoch [23/50], Step [605/735], Loss: 0.1953\n",
      "Epoch [23/50], Step [606/735], Loss: 0.0533\n",
      "Epoch [23/50], Step [607/735], Loss: 0.2219\n",
      "Epoch [23/50], Step [608/735], Loss: 0.0960\n",
      "Epoch [23/50], Step [609/735], Loss: 0.0756\n",
      "Epoch [23/50], Step [610/735], Loss: 0.2203\n",
      "Epoch [23/50], Step [611/735], Loss: 0.1712\n",
      "Epoch [23/50], Step [612/735], Loss: 0.1336\n",
      "Epoch [23/50], Step [613/735], Loss: 0.0420\n",
      "Epoch [23/50], Step [614/735], Loss: 0.2038\n",
      "Epoch [23/50], Step [615/735], Loss: 0.1210\n",
      "Epoch [23/50], Step [616/735], Loss: 0.0473\n",
      "Epoch [23/50], Step [617/735], Loss: 0.1914\n",
      "Epoch [23/50], Step [618/735], Loss: 0.5178\n",
      "Epoch [23/50], Step [619/735], Loss: 0.0363\n",
      "Epoch [23/50], Step [620/735], Loss: 0.4358\n",
      "Epoch [23/50], Step [621/735], Loss: 0.0325\n",
      "Epoch [23/50], Step [622/735], Loss: 0.1788\n",
      "Epoch [23/50], Step [623/735], Loss: 0.1294\n",
      "Epoch [23/50], Step [624/735], Loss: 0.2230\n",
      "Epoch [23/50], Step [625/735], Loss: 0.2912\n",
      "Epoch [23/50], Step [626/735], Loss: 0.1419\n",
      "Epoch [23/50], Step [627/735], Loss: 0.1040\n",
      "Epoch [23/50], Step [628/735], Loss: 0.0614\n",
      "Epoch [23/50], Step [629/735], Loss: 0.1664\n",
      "Epoch [23/50], Step [630/735], Loss: 0.0700\n",
      "Epoch [23/50], Step [631/735], Loss: 0.1786\n",
      "Epoch [23/50], Step [632/735], Loss: 0.0771\n",
      "Epoch [23/50], Step [633/735], Loss: 0.0954\n",
      "Epoch [23/50], Step [634/735], Loss: 0.2500\n",
      "Epoch [23/50], Step [635/735], Loss: 0.9074\n",
      "Epoch [23/50], Step [636/735], Loss: 0.0622\n",
      "Epoch [23/50], Step [637/735], Loss: 0.2214\n",
      "Epoch [23/50], Step [638/735], Loss: 0.1297\n",
      "Epoch [23/50], Step [639/735], Loss: 0.0883\n",
      "Epoch [23/50], Step [640/735], Loss: 0.1692\n",
      "Epoch [23/50], Step [641/735], Loss: 0.0655\n",
      "Epoch [23/50], Step [642/735], Loss: 0.2076\n",
      "Epoch [23/50], Step [643/735], Loss: 0.0456\n",
      "Epoch [23/50], Step [644/735], Loss: 0.2680\n",
      "Epoch [23/50], Step [645/735], Loss: 0.0488\n",
      "Epoch [23/50], Step [646/735], Loss: 0.1283\n",
      "Epoch [23/50], Step [647/735], Loss: 0.0926\n",
      "Epoch [23/50], Step [648/735], Loss: 0.0575\n",
      "Epoch [23/50], Step [649/735], Loss: 0.1139\n",
      "Epoch [23/50], Step [650/735], Loss: 0.0898\n",
      "Epoch [23/50], Step [651/735], Loss: 0.5202\n",
      "Epoch [23/50], Step [652/735], Loss: 0.0549\n",
      "Epoch [23/50], Step [653/735], Loss: 0.0724\n",
      "Epoch [23/50], Step [654/735], Loss: 0.0935\n",
      "Epoch [23/50], Step [655/735], Loss: 0.0588\n",
      "Epoch [23/50], Step [656/735], Loss: 0.1554\n",
      "Epoch [23/50], Step [657/735], Loss: 0.1530\n",
      "Epoch [23/50], Step [658/735], Loss: 0.1467\n",
      "Epoch [23/50], Step [659/735], Loss: 0.0872\n",
      "Epoch [23/50], Step [660/735], Loss: 0.0992\n",
      "Epoch [23/50], Step [661/735], Loss: 0.2895\n",
      "Epoch [23/50], Step [662/735], Loss: 0.0885\n",
      "Epoch [23/50], Step [663/735], Loss: 0.2127\n",
      "Epoch [23/50], Step [664/735], Loss: 0.0426\n",
      "Epoch [23/50], Step [665/735], Loss: 0.0588\n",
      "Epoch [23/50], Step [666/735], Loss: 0.1193\n",
      "Epoch [23/50], Step [667/735], Loss: 0.1983\n",
      "Epoch [23/50], Step [668/735], Loss: 0.1709\n",
      "Epoch [23/50], Step [669/735], Loss: 0.0966\n",
      "Epoch [23/50], Step [670/735], Loss: 0.0395\n",
      "Epoch [23/50], Step [671/735], Loss: 0.2254\n",
      "Epoch [23/50], Step [672/735], Loss: 0.1497\n",
      "Epoch [23/50], Step [673/735], Loss: 0.0952\n",
      "Epoch [23/50], Step [674/735], Loss: 0.1588\n",
      "Epoch [23/50], Step [675/735], Loss: 0.0641\n",
      "Epoch [23/50], Step [676/735], Loss: 0.1344\n",
      "Epoch [23/50], Step [677/735], Loss: 0.1201\n",
      "Epoch [23/50], Step [678/735], Loss: 0.1643\n",
      "Epoch [23/50], Step [679/735], Loss: 0.1117\n",
      "Epoch [23/50], Step [680/735], Loss: 0.1664\n",
      "Epoch [23/50], Step [681/735], Loss: 0.0847\n",
      "Epoch [23/50], Step [682/735], Loss: 0.1822\n",
      "Epoch [23/50], Step [683/735], Loss: 0.0977\n",
      "Epoch [23/50], Step [684/735], Loss: 0.1687\n",
      "Epoch [23/50], Step [685/735], Loss: 0.0649\n",
      "Epoch [23/50], Step [686/735], Loss: 0.1333\n",
      "Epoch [23/50], Step [687/735], Loss: 0.0893\n",
      "Epoch [23/50], Step [688/735], Loss: 0.0449\n",
      "Epoch [23/50], Step [689/735], Loss: 0.0785\n",
      "Epoch [23/50], Step [690/735], Loss: 0.0410\n",
      "Epoch [23/50], Step [691/735], Loss: 0.1417\n",
      "Epoch [23/50], Step [692/735], Loss: 0.1293\n",
      "Epoch [23/50], Step [693/735], Loss: 0.0684\n",
      "Epoch [23/50], Step [694/735], Loss: 0.2542\n",
      "Epoch [23/50], Step [695/735], Loss: 0.1312\n",
      "Epoch [23/50], Step [696/735], Loss: 0.2942\n",
      "Epoch [23/50], Step [697/735], Loss: 0.0768\n",
      "Epoch [23/50], Step [698/735], Loss: 0.1685\n",
      "Epoch [23/50], Step [699/735], Loss: 0.1115\n",
      "Epoch [23/50], Step [700/735], Loss: 0.1345\n",
      "Epoch [23/50], Step [701/735], Loss: 0.0858\n",
      "Epoch [23/50], Step [702/735], Loss: 0.4942\n",
      "Epoch [23/50], Step [703/735], Loss: 0.0750\n",
      "Epoch [23/50], Step [704/735], Loss: 0.4012\n",
      "Epoch [23/50], Step [705/735], Loss: 0.1076\n",
      "Epoch [23/50], Step [706/735], Loss: 0.1533\n",
      "Epoch [23/50], Step [707/735], Loss: 0.0915\n",
      "Epoch [23/50], Step [708/735], Loss: 0.1263\n",
      "Epoch [23/50], Step [709/735], Loss: 0.1817\n",
      "Epoch [23/50], Step [710/735], Loss: 0.0523\n",
      "Epoch [23/50], Step [711/735], Loss: 0.2669\n",
      "Epoch [23/50], Step [712/735], Loss: 0.0816\n",
      "Epoch [23/50], Step [713/735], Loss: 1.7261\n",
      "Epoch [23/50], Step [714/735], Loss: 0.0594\n",
      "Epoch [23/50], Step [715/735], Loss: 0.1347\n",
      "Epoch [23/50], Step [716/735], Loss: 0.1796\n",
      "Epoch [23/50], Step [717/735], Loss: 0.1284\n",
      "Epoch [23/50], Step [718/735], Loss: 0.0426\n",
      "Epoch [23/50], Step [719/735], Loss: 0.1498\n",
      "Epoch [23/50], Step [720/735], Loss: 0.0697\n",
      "Epoch [23/50], Step [721/735], Loss: 0.2706\n",
      "Epoch [23/50], Step [722/735], Loss: 0.2359\n",
      "Epoch [23/50], Step [723/735], Loss: 0.1789\n",
      "Epoch [23/50], Step [724/735], Loss: 0.0525\n",
      "Epoch [23/50], Step [725/735], Loss: 0.0927\n",
      "Epoch [23/50], Step [726/735], Loss: 0.0498\n",
      "Epoch [23/50], Step [727/735], Loss: 0.1327\n",
      "Epoch [23/50], Step [728/735], Loss: 0.0932\n",
      "Epoch [23/50], Step [729/735], Loss: 0.0382\n",
      "Epoch [23/50], Step [730/735], Loss: 0.1817\n",
      "Epoch [23/50], Step [731/735], Loss: 0.0397\n",
      "Epoch [23/50], Step [732/735], Loss: 0.0769\n",
      "Epoch [23/50], Step [733/735], Loss: 0.2126\n",
      "Epoch [23/50], Step [734/735], Loss: 0.1458\n",
      "Epoch [23/50], Step [735/735], Loss: 0.0369\n",
      "Epoch [24/50], Step [1/735], Loss: 0.0698\n",
      "Epoch [24/50], Step [2/735], Loss: 0.9139\n",
      "Epoch [24/50], Step [3/735], Loss: 0.1273\n",
      "Epoch [24/50], Step [4/735], Loss: 0.3242\n",
      "Epoch [24/50], Step [5/735], Loss: 0.1174\n",
      "Epoch [24/50], Step [6/735], Loss: 0.4128\n",
      "Epoch [24/50], Step [7/735], Loss: 0.0417\n",
      "Epoch [24/50], Step [8/735], Loss: 0.1607\n",
      "Epoch [24/50], Step [9/735], Loss: 0.1069\n",
      "Epoch [24/50], Step [10/735], Loss: 0.1902\n",
      "Epoch [24/50], Step [11/735], Loss: 0.0449\n",
      "Epoch [24/50], Step [12/735], Loss: 0.1283\n",
      "Epoch [24/50], Step [13/735], Loss: 0.0896\n",
      "Epoch [24/50], Step [14/735], Loss: 0.6867\n",
      "Epoch [24/50], Step [15/735], Loss: 0.2289\n",
      "Epoch [24/50], Step [16/735], Loss: 0.2390\n",
      "Epoch [24/50], Step [17/735], Loss: 0.1450\n",
      "Epoch [24/50], Step [18/735], Loss: 0.0790\n",
      "Epoch [24/50], Step [19/735], Loss: 0.0781\n",
      "Epoch [24/50], Step [20/735], Loss: 0.2187\n",
      "Epoch [24/50], Step [21/735], Loss: 0.6442\n",
      "Epoch [24/50], Step [22/735], Loss: 0.0692\n",
      "Epoch [24/50], Step [23/735], Loss: 0.1458\n",
      "Epoch [24/50], Step [24/735], Loss: 0.0990\n",
      "Epoch [24/50], Step [25/735], Loss: 0.1102\n",
      "Epoch [24/50], Step [26/735], Loss: 0.0672\n",
      "Epoch [24/50], Step [27/735], Loss: 0.1404\n",
      "Epoch [24/50], Step [28/735], Loss: 0.2085\n",
      "Epoch [24/50], Step [29/735], Loss: 0.2303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Step [30/735], Loss: 0.1438\n",
      "Epoch [24/50], Step [31/735], Loss: 0.0907\n",
      "Epoch [24/50], Step [32/735], Loss: 0.1166\n",
      "Epoch [24/50], Step [33/735], Loss: 0.0858\n",
      "Epoch [24/50], Step [34/735], Loss: 0.1097\n",
      "Epoch [24/50], Step [35/735], Loss: 0.1724\n",
      "Epoch [24/50], Step [36/735], Loss: 0.0970\n",
      "Epoch [24/50], Step [37/735], Loss: 0.0749\n",
      "Epoch [24/50], Step [38/735], Loss: 0.2357\n",
      "Epoch [24/50], Step [39/735], Loss: 0.0681\n",
      "Epoch [24/50], Step [40/735], Loss: 0.6807\n",
      "Epoch [24/50], Step [41/735], Loss: 0.0743\n",
      "Epoch [24/50], Step [42/735], Loss: 0.0739\n",
      "Epoch [24/50], Step [43/735], Loss: 0.1236\n",
      "Epoch [24/50], Step [44/735], Loss: 0.0756\n",
      "Epoch [24/50], Step [45/735], Loss: 0.2095\n",
      "Epoch [24/50], Step [46/735], Loss: 0.0672\n",
      "Epoch [24/50], Step [47/735], Loss: 0.1989\n",
      "Epoch [24/50], Step [48/735], Loss: 0.3317\n",
      "Epoch [24/50], Step [49/735], Loss: 0.0539\n",
      "Epoch [24/50], Step [50/735], Loss: 0.0605\n",
      "Epoch [24/50], Step [51/735], Loss: 0.1619\n",
      "Epoch [24/50], Step [52/735], Loss: 0.1261\n",
      "Epoch [24/50], Step [53/735], Loss: 0.0628\n",
      "Epoch [24/50], Step [54/735], Loss: 0.1285\n",
      "Epoch [24/50], Step [55/735], Loss: 0.0354\n",
      "Epoch [24/50], Step [56/735], Loss: 0.1706\n",
      "Epoch [24/50], Step [57/735], Loss: 0.1009\n",
      "Epoch [24/50], Step [58/735], Loss: 0.1406\n",
      "Epoch [24/50], Step [59/735], Loss: 0.1111\n",
      "Epoch [24/50], Step [60/735], Loss: 0.1067\n",
      "Epoch [24/50], Step [61/735], Loss: 0.0496\n",
      "Epoch [24/50], Step [62/735], Loss: 0.1962\n",
      "Epoch [24/50], Step [63/735], Loss: 0.1290\n",
      "Epoch [24/50], Step [64/735], Loss: 0.1140\n",
      "Epoch [24/50], Step [65/735], Loss: 0.0924\n",
      "Epoch [24/50], Step [66/735], Loss: 0.5151\n",
      "Epoch [24/50], Step [67/735], Loss: 0.0832\n",
      "Epoch [24/50], Step [68/735], Loss: 0.0966\n",
      "Epoch [24/50], Step [69/735], Loss: 0.0712\n",
      "Epoch [24/50], Step [70/735], Loss: 0.0337\n",
      "Epoch [24/50], Step [71/735], Loss: 0.0807\n",
      "Epoch [24/50], Step [72/735], Loss: 0.0404\n",
      "Epoch [24/50], Step [73/735], Loss: 0.0789\n",
      "Epoch [24/50], Step [74/735], Loss: 0.1676\n",
      "Epoch [24/50], Step [75/735], Loss: 0.0252\n",
      "Epoch [24/50], Step [76/735], Loss: 1.9446\n",
      "Epoch [24/50], Step [77/735], Loss: 0.1030\n",
      "Epoch [24/50], Step [78/735], Loss: 0.1228\n",
      "Epoch [24/50], Step [79/735], Loss: 0.2843\n",
      "Epoch [24/50], Step [80/735], Loss: 0.0873\n",
      "Epoch [24/50], Step [81/735], Loss: 0.0795\n",
      "Epoch [24/50], Step [82/735], Loss: 0.1841\n",
      "Epoch [24/50], Step [83/735], Loss: 0.2125\n",
      "Epoch [24/50], Step [84/735], Loss: 0.2341\n",
      "Epoch [24/50], Step [85/735], Loss: 0.1200\n",
      "Epoch [24/50], Step [86/735], Loss: 0.1060\n",
      "Epoch [24/50], Step [87/735], Loss: 0.1376\n",
      "Epoch [24/50], Step [88/735], Loss: 0.1179\n",
      "Epoch [24/50], Step [89/735], Loss: 0.0877\n",
      "Epoch [24/50], Step [90/735], Loss: 0.1139\n",
      "Epoch [24/50], Step [91/735], Loss: 0.0871\n",
      "Epoch [24/50], Step [92/735], Loss: 0.7502\n",
      "Epoch [24/50], Step [93/735], Loss: 0.0637\n",
      "Epoch [24/50], Step [94/735], Loss: 0.1390\n",
      "Epoch [24/50], Step [95/735], Loss: 0.0559\n",
      "Epoch [24/50], Step [96/735], Loss: 0.1647\n",
      "Epoch [24/50], Step [97/735], Loss: 0.1067\n",
      "Epoch [24/50], Step [98/735], Loss: 0.1407\n",
      "Epoch [24/50], Step [99/735], Loss: 0.0535\n",
      "Epoch [24/50], Step [100/735], Loss: 0.1268\n",
      "Epoch [24/50], Step [101/735], Loss: 0.2145\n",
      "Epoch [24/50], Step [102/735], Loss: 0.1949\n",
      "Epoch [24/50], Step [103/735], Loss: 0.0874\n",
      "Epoch [24/50], Step [104/735], Loss: 0.1995\n",
      "Epoch [24/50], Step [105/735], Loss: 0.0609\n",
      "Epoch [24/50], Step [106/735], Loss: 0.1022\n",
      "Epoch [24/50], Step [107/735], Loss: 0.1001\n",
      "Epoch [24/50], Step [108/735], Loss: 0.0407\n",
      "Epoch [24/50], Step [109/735], Loss: 0.1011\n",
      "Epoch [24/50], Step [110/735], Loss: 0.0650\n",
      "Epoch [24/50], Step [111/735], Loss: 0.0757\n",
      "Epoch [24/50], Step [112/735], Loss: 0.2057\n",
      "Epoch [24/50], Step [113/735], Loss: 0.1071\n",
      "Epoch [24/50], Step [114/735], Loss: 0.0849\n",
      "Epoch [24/50], Step [115/735], Loss: 0.0497\n",
      "Epoch [24/50], Step [116/735], Loss: 0.0927\n",
      "Epoch [24/50], Step [117/735], Loss: 0.0892\n",
      "Epoch [24/50], Step [118/735], Loss: 0.0280\n",
      "Epoch [24/50], Step [119/735], Loss: 0.0495\n",
      "Epoch [24/50], Step [120/735], Loss: 0.0554\n",
      "Epoch [24/50], Step [121/735], Loss: 0.1164\n",
      "Epoch [24/50], Step [122/735], Loss: 0.8684\n",
      "Epoch [24/50], Step [123/735], Loss: 0.0842\n",
      "Epoch [24/50], Step [124/735], Loss: 0.1103\n",
      "Epoch [24/50], Step [125/735], Loss: 0.0647\n",
      "Epoch [24/50], Step [126/735], Loss: 0.0372\n",
      "Epoch [24/50], Step [127/735], Loss: 0.0923\n",
      "Epoch [24/50], Step [128/735], Loss: 0.0357\n",
      "Epoch [24/50], Step [129/735], Loss: 0.0938\n",
      "Epoch [24/50], Step [130/735], Loss: 0.1594\n",
      "Epoch [24/50], Step [131/735], Loss: 0.2319\n",
      "Epoch [24/50], Step [132/735], Loss: 0.3661\n",
      "Epoch [24/50], Step [133/735], Loss: 0.1519\n",
      "Epoch [24/50], Step [134/735], Loss: 0.0704\n",
      "Epoch [24/50], Step [135/735], Loss: 0.0769\n",
      "Epoch [24/50], Step [136/735], Loss: 0.0585\n",
      "Epoch [24/50], Step [137/735], Loss: 0.0510\n",
      "Epoch [24/50], Step [138/735], Loss: 0.0640\n",
      "Epoch [24/50], Step [139/735], Loss: 0.3626\n",
      "Epoch [24/50], Step [140/735], Loss: 0.1357\n",
      "Epoch [24/50], Step [141/735], Loss: 0.1753\n",
      "Epoch [24/50], Step [142/735], Loss: 0.1325\n",
      "Epoch [24/50], Step [143/735], Loss: 0.4865\n",
      "Epoch [24/50], Step [144/735], Loss: 0.0689\n",
      "Epoch [24/50], Step [145/735], Loss: 0.1176\n",
      "Epoch [24/50], Step [146/735], Loss: 0.0209\n",
      "Epoch [24/50], Step [147/735], Loss: 0.2085\n",
      "Epoch [24/50], Step [148/735], Loss: 0.0377\n",
      "Epoch [24/50], Step [149/735], Loss: 0.1413\n",
      "Epoch [24/50], Step [150/735], Loss: 0.0666\n",
      "Epoch [24/50], Step [151/735], Loss: 0.4668\n",
      "Epoch [24/50], Step [152/735], Loss: 0.0714\n",
      "Epoch [24/50], Step [153/735], Loss: 0.0803\n",
      "Epoch [24/50], Step [154/735], Loss: 0.1597\n",
      "Epoch [24/50], Step [155/735], Loss: 0.0692\n",
      "Epoch [24/50], Step [156/735], Loss: 0.1005\n",
      "Epoch [24/50], Step [157/735], Loss: 0.0760\n",
      "Epoch [24/50], Step [158/735], Loss: 0.0650\n",
      "Epoch [24/50], Step [159/735], Loss: 0.2158\n",
      "Epoch [24/50], Step [160/735], Loss: 0.0860\n",
      "Epoch [24/50], Step [161/735], Loss: 0.0668\n",
      "Epoch [24/50], Step [162/735], Loss: 0.2696\n",
      "Epoch [24/50], Step [163/735], Loss: 0.2035\n",
      "Epoch [24/50], Step [164/735], Loss: 0.0251\n",
      "Epoch [24/50], Step [165/735], Loss: 0.0303\n",
      "Epoch [24/50], Step [166/735], Loss: 0.0699\n",
      "Epoch [24/50], Step [167/735], Loss: 0.1525\n",
      "Epoch [24/50], Step [168/735], Loss: 0.1221\n",
      "Epoch [24/50], Step [169/735], Loss: 0.0389\n",
      "Epoch [24/50], Step [170/735], Loss: 0.1185\n",
      "Epoch [24/50], Step [171/735], Loss: 1.0463\n",
      "Epoch [24/50], Step [172/735], Loss: 0.0809\n",
      "Epoch [24/50], Step [173/735], Loss: 0.1127\n",
      "Epoch [24/50], Step [174/735], Loss: 0.0279\n",
      "Epoch [24/50], Step [175/735], Loss: 0.0697\n",
      "Epoch [24/50], Step [176/735], Loss: 0.0808\n",
      "Epoch [24/50], Step [177/735], Loss: 0.0352\n",
      "Epoch [24/50], Step [178/735], Loss: 0.0744\n",
      "Epoch [24/50], Step [179/735], Loss: 0.1325\n",
      "Epoch [24/50], Step [180/735], Loss: 0.1010\n",
      "Epoch [24/50], Step [181/735], Loss: 0.1976\n",
      "Epoch [24/50], Step [182/735], Loss: 0.0887\n",
      "Epoch [24/50], Step [183/735], Loss: 0.1890\n",
      "Epoch [24/50], Step [184/735], Loss: 0.0656\n",
      "Epoch [24/50], Step [185/735], Loss: 0.0464\n",
      "Epoch [24/50], Step [186/735], Loss: 0.2544\n",
      "Epoch [24/50], Step [187/735], Loss: 0.1015\n",
      "Epoch [24/50], Step [188/735], Loss: 0.0717\n",
      "Epoch [24/50], Step [189/735], Loss: 0.0646\n",
      "Epoch [24/50], Step [190/735], Loss: 0.1625\n",
      "Epoch [24/50], Step [191/735], Loss: 0.1025\n",
      "Epoch [24/50], Step [192/735], Loss: 0.2474\n",
      "Epoch [24/50], Step [193/735], Loss: 0.2435\n",
      "Epoch [24/50], Step [194/735], Loss: 0.1807\n",
      "Epoch [24/50], Step [195/735], Loss: 0.0473\n",
      "Epoch [24/50], Step [196/735], Loss: 0.0816\n",
      "Epoch [24/50], Step [197/735], Loss: 0.0587\n",
      "Epoch [24/50], Step [198/735], Loss: 0.1422\n",
      "Epoch [24/50], Step [199/735], Loss: 0.0891\n",
      "Epoch [24/50], Step [200/735], Loss: 0.1161\n",
      "Epoch [24/50], Step [201/735], Loss: 0.1444\n",
      "Epoch [24/50], Step [202/735], Loss: 0.2308\n",
      "Epoch [24/50], Step [203/735], Loss: 0.2245\n",
      "Epoch [24/50], Step [204/735], Loss: 0.0888\n",
      "Epoch [24/50], Step [205/735], Loss: 0.0553\n",
      "Epoch [24/50], Step [206/735], Loss: 0.0506\n",
      "Epoch [24/50], Step [207/735], Loss: 0.1452\n",
      "Epoch [24/50], Step [208/735], Loss: 0.1781\n",
      "Epoch [24/50], Step [209/735], Loss: 0.0941\n",
      "Epoch [24/50], Step [210/735], Loss: 0.1277\n",
      "Epoch [24/50], Step [211/735], Loss: 0.0831\n",
      "Epoch [24/50], Step [212/735], Loss: 0.1274\n",
      "Epoch [24/50], Step [213/735], Loss: 0.0851\n",
      "Epoch [24/50], Step [214/735], Loss: 0.1173\n",
      "Epoch [24/50], Step [215/735], Loss: 0.0801\n",
      "Epoch [24/50], Step [216/735], Loss: 0.2812\n",
      "Epoch [24/50], Step [217/735], Loss: 0.6661\n",
      "Epoch [24/50], Step [218/735], Loss: 0.2399\n",
      "Epoch [24/50], Step [219/735], Loss: 0.0625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Step [220/735], Loss: 0.2312\n",
      "Epoch [24/50], Step [221/735], Loss: 0.1790\n",
      "Epoch [24/50], Step [222/735], Loss: 0.1675\n",
      "Epoch [24/50], Step [223/735], Loss: 0.0967\n",
      "Epoch [24/50], Step [224/735], Loss: 0.0985\n",
      "Epoch [24/50], Step [225/735], Loss: 0.0987\n",
      "Epoch [24/50], Step [226/735], Loss: 0.1301\n",
      "Epoch [24/50], Step [227/735], Loss: 0.1850\n",
      "Epoch [24/50], Step [228/735], Loss: 0.1503\n",
      "Epoch [24/50], Step [229/735], Loss: 0.2484\n",
      "Epoch [24/50], Step [230/735], Loss: 0.0595\n",
      "Epoch [24/50], Step [231/735], Loss: 0.4689\n",
      "Epoch [24/50], Step [232/735], Loss: 0.0513\n",
      "Epoch [24/50], Step [233/735], Loss: 0.1281\n",
      "Epoch [24/50], Step [234/735], Loss: 0.1107\n",
      "Epoch [24/50], Step [235/735], Loss: 0.0875\n",
      "Epoch [24/50], Step [236/735], Loss: 0.1747\n",
      "Epoch [24/50], Step [237/735], Loss: 0.1390\n",
      "Epoch [24/50], Step [238/735], Loss: 0.1727\n",
      "Epoch [24/50], Step [239/735], Loss: 0.1409\n",
      "Epoch [24/50], Step [240/735], Loss: 0.1293\n",
      "Epoch [24/50], Step [241/735], Loss: 0.2066\n",
      "Epoch [24/50], Step [242/735], Loss: 1.0661\n",
      "Epoch [24/50], Step [243/735], Loss: 0.1067\n",
      "Epoch [24/50], Step [244/735], Loss: 0.0543\n",
      "Epoch [24/50], Step [245/735], Loss: 0.1150\n",
      "Epoch [24/50], Step [246/735], Loss: 0.0906\n",
      "Epoch [24/50], Step [247/735], Loss: 0.1014\n",
      "Epoch [24/50], Step [248/735], Loss: 0.2060\n",
      "Epoch [24/50], Step [249/735], Loss: 0.0776\n",
      "Epoch [24/50], Step [250/735], Loss: 0.1422\n",
      "Epoch [24/50], Step [251/735], Loss: 0.0584\n",
      "Epoch [24/50], Step [252/735], Loss: 0.1449\n",
      "Epoch [24/50], Step [253/735], Loss: 0.0626\n",
      "Epoch [24/50], Step [254/735], Loss: 0.8991\n",
      "Epoch [24/50], Step [255/735], Loss: 0.1951\n",
      "Epoch [24/50], Step [256/735], Loss: 0.2232\n",
      "Epoch [24/50], Step [257/735], Loss: 0.1306\n",
      "Epoch [24/50], Step [258/735], Loss: 0.0772\n",
      "Epoch [24/50], Step [259/735], Loss: 0.1454\n",
      "Epoch [24/50], Step [260/735], Loss: 0.0514\n",
      "Epoch [24/50], Step [261/735], Loss: 0.0702\n",
      "Epoch [24/50], Step [262/735], Loss: 0.1768\n",
      "Epoch [24/50], Step [263/735], Loss: 0.1628\n",
      "Epoch [24/50], Step [264/735], Loss: 0.5898\n",
      "Epoch [24/50], Step [265/735], Loss: 0.1876\n",
      "Epoch [24/50], Step [266/735], Loss: 0.1947\n",
      "Epoch [24/50], Step [267/735], Loss: 0.1636\n",
      "Epoch [24/50], Step [268/735], Loss: 0.0940\n",
      "Epoch [24/50], Step [269/735], Loss: 0.2673\n",
      "Epoch [24/50], Step [270/735], Loss: 0.1729\n",
      "Epoch [24/50], Step [271/735], Loss: 0.2228\n",
      "Epoch [24/50], Step [272/735], Loss: 0.7913\n",
      "Epoch [24/50], Step [273/735], Loss: 0.1278\n",
      "Epoch [24/50], Step [274/735], Loss: 0.0431\n",
      "Epoch [24/50], Step [275/735], Loss: 0.0948\n",
      "Epoch [24/50], Step [276/735], Loss: 0.1528\n",
      "Epoch [24/50], Step [277/735], Loss: 0.4031\n",
      "Epoch [24/50], Step [278/735], Loss: 0.1462\n",
      "Epoch [24/50], Step [279/735], Loss: 0.1398\n",
      "Epoch [24/50], Step [280/735], Loss: 0.0784\n",
      "Epoch [24/50], Step [281/735], Loss: 0.1531\n",
      "Epoch [24/50], Step [282/735], Loss: 0.1563\n",
      "Epoch [24/50], Step [283/735], Loss: 0.5702\n",
      "Epoch [24/50], Step [284/735], Loss: 0.0748\n",
      "Epoch [24/50], Step [285/735], Loss: 0.3159\n",
      "Epoch [24/50], Step [286/735], Loss: 0.1535\n",
      "Epoch [24/50], Step [287/735], Loss: 0.2532\n",
      "Epoch [24/50], Step [288/735], Loss: 0.1087\n",
      "Epoch [24/50], Step [289/735], Loss: 0.5326\n",
      "Epoch [24/50], Step [290/735], Loss: 0.0484\n",
      "Epoch [24/50], Step [291/735], Loss: 0.0486\n",
      "Epoch [24/50], Step [292/735], Loss: 0.0216\n",
      "Epoch [24/50], Step [293/735], Loss: 0.0991\n",
      "Epoch [24/50], Step [294/735], Loss: 0.1652\n",
      "Epoch [24/50], Step [295/735], Loss: 0.1293\n",
      "Epoch [24/50], Step [296/735], Loss: 0.3705\n",
      "Epoch [24/50], Step [297/735], Loss: 0.1097\n",
      "Epoch [24/50], Step [298/735], Loss: 0.0991\n",
      "Epoch [24/50], Step [299/735], Loss: 0.0696\n",
      "Epoch [24/50], Step [300/735], Loss: 0.0673\n",
      "Epoch [24/50], Step [301/735], Loss: 0.0825\n",
      "Epoch [24/50], Step [302/735], Loss: 0.2323\n",
      "Epoch [24/50], Step [303/735], Loss: 0.0369\n",
      "Epoch [24/50], Step [304/735], Loss: 0.2265\n",
      "Epoch [24/50], Step [305/735], Loss: 0.2949\n",
      "Epoch [24/50], Step [306/735], Loss: 0.0793\n",
      "Epoch [24/50], Step [307/735], Loss: 0.1956\n",
      "Epoch [24/50], Step [308/735], Loss: 0.2583\n",
      "Epoch [24/50], Step [309/735], Loss: 0.2947\n",
      "Epoch [24/50], Step [310/735], Loss: 0.1152\n",
      "Epoch [24/50], Step [311/735], Loss: 0.0534\n",
      "Epoch [24/50], Step [312/735], Loss: 0.0731\n",
      "Epoch [24/50], Step [313/735], Loss: 0.1010\n",
      "Epoch [24/50], Step [314/735], Loss: 0.1723\n",
      "Epoch [24/50], Step [315/735], Loss: 0.1314\n",
      "Epoch [24/50], Step [316/735], Loss: 0.1629\n",
      "Epoch [24/50], Step [317/735], Loss: 0.8314\n",
      "Epoch [24/50], Step [318/735], Loss: 0.2110\n",
      "Epoch [24/50], Step [319/735], Loss: 0.2279\n",
      "Epoch [24/50], Step [320/735], Loss: 0.0527\n",
      "Epoch [24/50], Step [321/735], Loss: 0.0591\n",
      "Epoch [24/50], Step [322/735], Loss: 0.1689\n",
      "Epoch [24/50], Step [323/735], Loss: 0.1404\n",
      "Epoch [24/50], Step [324/735], Loss: 0.0957\n",
      "Epoch [24/50], Step [325/735], Loss: 1.0932\n",
      "Epoch [24/50], Step [326/735], Loss: 0.1579\n",
      "Epoch [24/50], Step [327/735], Loss: 0.2214\n",
      "Epoch [24/50], Step [328/735], Loss: 0.0871\n",
      "Epoch [24/50], Step [329/735], Loss: 0.0718\n",
      "Epoch [24/50], Step [330/735], Loss: 0.0744\n",
      "Epoch [24/50], Step [331/735], Loss: 0.1888\n",
      "Epoch [24/50], Step [332/735], Loss: 0.2837\n",
      "Epoch [24/50], Step [333/735], Loss: 0.1561\n",
      "Epoch [24/50], Step [334/735], Loss: 0.2612\n",
      "Epoch [24/50], Step [335/735], Loss: 0.2189\n",
      "Epoch [24/50], Step [336/735], Loss: 0.0523\n",
      "Epoch [24/50], Step [337/735], Loss: 0.0814\n",
      "Epoch [24/50], Step [338/735], Loss: 0.0374\n",
      "Epoch [24/50], Step [339/735], Loss: 0.0624\n",
      "Epoch [24/50], Step [340/735], Loss: 0.1236\n",
      "Epoch [24/50], Step [341/735], Loss: 0.1613\n",
      "Epoch [24/50], Step [342/735], Loss: 0.0863\n",
      "Epoch [24/50], Step [343/735], Loss: 0.1025\n",
      "Epoch [24/50], Step [344/735], Loss: 0.0481\n",
      "Epoch [24/50], Step [345/735], Loss: 0.0937\n",
      "Epoch [24/50], Step [346/735], Loss: 0.0496\n",
      "Epoch [24/50], Step [347/735], Loss: 0.0824\n",
      "Epoch [24/50], Step [348/735], Loss: 0.2302\n",
      "Epoch [24/50], Step [349/735], Loss: 0.2800\n",
      "Epoch [24/50], Step [350/735], Loss: 0.4609\n",
      "Epoch [24/50], Step [351/735], Loss: 0.1663\n",
      "Epoch [24/50], Step [352/735], Loss: 0.0995\n",
      "Epoch [24/50], Step [353/735], Loss: 0.1290\n",
      "Epoch [24/50], Step [354/735], Loss: 0.0683\n",
      "Epoch [24/50], Step [355/735], Loss: 0.0585\n",
      "Epoch [24/50], Step [356/735], Loss: 0.1461\n",
      "Epoch [24/50], Step [357/735], Loss: 0.2341\n",
      "Epoch [24/50], Step [358/735], Loss: 0.0799\n",
      "Epoch [24/50], Step [359/735], Loss: 0.0821\n",
      "Epoch [24/50], Step [360/735], Loss: 0.0990\n",
      "Epoch [24/50], Step [361/735], Loss: 0.1495\n",
      "Epoch [24/50], Step [362/735], Loss: 0.1681\n",
      "Epoch [24/50], Step [363/735], Loss: 0.1222\n",
      "Epoch [24/50], Step [364/735], Loss: 0.1890\n",
      "Epoch [24/50], Step [365/735], Loss: 0.1202\n",
      "Epoch [24/50], Step [366/735], Loss: 0.0515\n",
      "Epoch [24/50], Step [367/735], Loss: 0.0518\n",
      "Epoch [24/50], Step [368/735], Loss: 0.0626\n",
      "Epoch [24/50], Step [369/735], Loss: 2.0547\n",
      "Epoch [24/50], Step [370/735], Loss: 0.1050\n",
      "Epoch [24/50], Step [371/735], Loss: 0.0879\n",
      "Epoch [24/50], Step [372/735], Loss: 0.1988\n",
      "Epoch [24/50], Step [373/735], Loss: 0.1707\n",
      "Epoch [24/50], Step [374/735], Loss: 0.3102\n",
      "Epoch [24/50], Step [375/735], Loss: 0.1884\n",
      "Epoch [24/50], Step [376/735], Loss: 0.1724\n",
      "Epoch [24/50], Step [377/735], Loss: 0.1741\n",
      "Epoch [24/50], Step [378/735], Loss: 0.1375\n",
      "Epoch [24/50], Step [379/735], Loss: 0.4910\n",
      "Epoch [24/50], Step [380/735], Loss: 0.1491\n",
      "Epoch [24/50], Step [381/735], Loss: 0.1006\n",
      "Epoch [24/50], Step [382/735], Loss: 0.1185\n",
      "Epoch [24/50], Step [383/735], Loss: 0.1715\n",
      "Epoch [24/50], Step [384/735], Loss: 0.0716\n",
      "Epoch [24/50], Step [385/735], Loss: 0.0401\n",
      "Epoch [24/50], Step [386/735], Loss: 0.0550\n",
      "Epoch [24/50], Step [387/735], Loss: 0.4851\n",
      "Epoch [24/50], Step [388/735], Loss: 0.1974\n",
      "Epoch [24/50], Step [389/735], Loss: 0.6884\n",
      "Epoch [24/50], Step [390/735], Loss: 0.0977\n",
      "Epoch [24/50], Step [391/735], Loss: 0.1399\n",
      "Epoch [24/50], Step [392/735], Loss: 0.2256\n",
      "Epoch [24/50], Step [393/735], Loss: 0.1479\n",
      "Epoch [24/50], Step [394/735], Loss: 0.1546\n",
      "Epoch [24/50], Step [395/735], Loss: 0.0344\n",
      "Epoch [24/50], Step [396/735], Loss: 0.1067\n",
      "Epoch [24/50], Step [397/735], Loss: 0.0860\n",
      "Epoch [24/50], Step [398/735], Loss: 0.2229\n",
      "Epoch [24/50], Step [399/735], Loss: 0.1215\n",
      "Epoch [24/50], Step [400/735], Loss: 0.0669\n",
      "Epoch [24/50], Step [401/735], Loss: 0.2003\n",
      "Epoch [24/50], Step [402/735], Loss: 0.0603\n",
      "Epoch [24/50], Step [403/735], Loss: 0.0361\n",
      "Epoch [24/50], Step [404/735], Loss: 0.1512\n",
      "Epoch [24/50], Step [405/735], Loss: 0.0275\n",
      "Epoch [24/50], Step [406/735], Loss: 0.1132\n",
      "Epoch [24/50], Step [407/735], Loss: 0.1318\n",
      "Epoch [24/50], Step [408/735], Loss: 0.0952\n",
      "Epoch [24/50], Step [409/735], Loss: 0.1072\n",
      "Epoch [24/50], Step [410/735], Loss: 0.1333\n",
      "Epoch [24/50], Step [411/735], Loss: 0.3053\n",
      "Epoch [24/50], Step [412/735], Loss: 0.1474\n",
      "Epoch [24/50], Step [413/735], Loss: 0.1277\n",
      "Epoch [24/50], Step [414/735], Loss: 0.1867\n",
      "Epoch [24/50], Step [415/735], Loss: 0.1127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Step [416/735], Loss: 0.3219\n",
      "Epoch [24/50], Step [417/735], Loss: 0.0891\n",
      "Epoch [24/50], Step [418/735], Loss: 0.0463\n",
      "Epoch [24/50], Step [419/735], Loss: 0.0453\n",
      "Epoch [24/50], Step [420/735], Loss: 0.0737\n",
      "Epoch [24/50], Step [421/735], Loss: 0.0909\n",
      "Epoch [24/50], Step [422/735], Loss: 0.1129\n",
      "Epoch [24/50], Step [423/735], Loss: 0.0591\n",
      "Epoch [24/50], Step [424/735], Loss: 0.2115\n",
      "Epoch [24/50], Step [425/735], Loss: 0.0875\n",
      "Epoch [24/50], Step [426/735], Loss: 0.0826\n",
      "Epoch [24/50], Step [427/735], Loss: 0.0939\n",
      "Epoch [24/50], Step [428/735], Loss: 0.1861\n",
      "Epoch [24/50], Step [429/735], Loss: 0.3341\n",
      "Epoch [24/50], Step [430/735], Loss: 0.1350\n",
      "Epoch [24/50], Step [431/735], Loss: 0.2226\n",
      "Epoch [24/50], Step [432/735], Loss: 0.0918\n",
      "Epoch [24/50], Step [433/735], Loss: 0.0939\n",
      "Epoch [24/50], Step [434/735], Loss: 0.2960\n",
      "Epoch [24/50], Step [435/735], Loss: 0.0616\n",
      "Epoch [24/50], Step [436/735], Loss: 0.0827\n",
      "Epoch [24/50], Step [437/735], Loss: 0.1752\n",
      "Epoch [24/50], Step [438/735], Loss: 0.0876\n",
      "Epoch [24/50], Step [439/735], Loss: 0.2438\n",
      "Epoch [24/50], Step [440/735], Loss: 0.1331\n",
      "Epoch [24/50], Step [441/735], Loss: 0.1846\n",
      "Epoch [24/50], Step [442/735], Loss: 0.1117\n",
      "Epoch [24/50], Step [443/735], Loss: 0.1094\n",
      "Epoch [24/50], Step [444/735], Loss: 0.0932\n",
      "Epoch [24/50], Step [445/735], Loss: 0.0653\n",
      "Epoch [24/50], Step [446/735], Loss: 0.2857\n",
      "Epoch [24/50], Step [447/735], Loss: 0.1579\n",
      "Epoch [24/50], Step [448/735], Loss: 0.1509\n",
      "Epoch [24/50], Step [449/735], Loss: 0.3213\n",
      "Epoch [24/50], Step [450/735], Loss: 0.1185\n",
      "Epoch [24/50], Step [451/735], Loss: 0.1415\n",
      "Epoch [24/50], Step [452/735], Loss: 0.1548\n",
      "Epoch [24/50], Step [453/735], Loss: 0.0651\n",
      "Epoch [24/50], Step [454/735], Loss: 0.1515\n",
      "Epoch [24/50], Step [455/735], Loss: 0.1067\n",
      "Epoch [24/50], Step [456/735], Loss: 0.1597\n",
      "Epoch [24/50], Step [457/735], Loss: 1.1816\n",
      "Epoch [24/50], Step [458/735], Loss: 0.2070\n",
      "Epoch [24/50], Step [459/735], Loss: 0.9620\n",
      "Epoch [24/50], Step [460/735], Loss: 0.3620\n",
      "Epoch [24/50], Step [461/735], Loss: 0.0828\n",
      "Epoch [24/50], Step [462/735], Loss: 0.0901\n",
      "Epoch [24/50], Step [463/735], Loss: 0.1477\n",
      "Epoch [24/50], Step [464/735], Loss: 0.8006\n",
      "Epoch [24/50], Step [465/735], Loss: 1.1533\n",
      "Epoch [24/50], Step [466/735], Loss: 0.1557\n",
      "Epoch [24/50], Step [467/735], Loss: 0.1060\n",
      "Epoch [24/50], Step [468/735], Loss: 0.0857\n",
      "Epoch [24/50], Step [469/735], Loss: 0.0347\n",
      "Epoch [24/50], Step [470/735], Loss: 0.0956\n",
      "Epoch [24/50], Step [471/735], Loss: 0.0565\n",
      "Epoch [24/50], Step [472/735], Loss: 0.1593\n",
      "Epoch [24/50], Step [473/735], Loss: 0.1277\n",
      "Epoch [24/50], Step [474/735], Loss: 0.0475\n",
      "Epoch [24/50], Step [475/735], Loss: 0.0714\n",
      "Epoch [24/50], Step [476/735], Loss: 0.0637\n",
      "Epoch [24/50], Step [477/735], Loss: 0.2871\n",
      "Epoch [24/50], Step [478/735], Loss: 0.1295\n",
      "Epoch [24/50], Step [479/735], Loss: 0.2457\n",
      "Epoch [24/50], Step [480/735], Loss: 0.4820\n",
      "Epoch [24/50], Step [481/735], Loss: 1.2772\n",
      "Epoch [24/50], Step [482/735], Loss: 0.0732\n",
      "Epoch [24/50], Step [483/735], Loss: 0.0731\n",
      "Epoch [24/50], Step [484/735], Loss: 0.1493\n",
      "Epoch [24/50], Step [485/735], Loss: 0.0776\n",
      "Epoch [24/50], Step [486/735], Loss: 0.0900\n",
      "Epoch [24/50], Step [487/735], Loss: 0.0703\n",
      "Epoch [24/50], Step [488/735], Loss: 0.2523\n",
      "Epoch [24/50], Step [489/735], Loss: 0.0834\n",
      "Epoch [24/50], Step [490/735], Loss: 0.0985\n",
      "Epoch [24/50], Step [491/735], Loss: 0.2860\n",
      "Epoch [24/50], Step [492/735], Loss: 0.3024\n",
      "Epoch [24/50], Step [493/735], Loss: 0.1789\n",
      "Epoch [24/50], Step [494/735], Loss: 0.6140\n",
      "Epoch [24/50], Step [495/735], Loss: 0.1318\n",
      "Epoch [24/50], Step [496/735], Loss: 0.0874\n",
      "Epoch [24/50], Step [497/735], Loss: 0.1021\n",
      "Epoch [24/50], Step [498/735], Loss: 0.1128\n",
      "Epoch [24/50], Step [499/735], Loss: 0.1872\n",
      "Epoch [24/50], Step [500/735], Loss: 0.2189\n",
      "Epoch [24/50], Step [501/735], Loss: 0.3061\n",
      "Epoch [24/50], Step [502/735], Loss: 0.3878\n",
      "Epoch [24/50], Step [503/735], Loss: 0.1586\n",
      "Epoch [24/50], Step [504/735], Loss: 0.2278\n",
      "Epoch [24/50], Step [505/735], Loss: 1.1096\n",
      "Epoch [24/50], Step [506/735], Loss: 0.5202\n",
      "Epoch [24/50], Step [507/735], Loss: 0.1347\n",
      "Epoch [24/50], Step [508/735], Loss: 0.1329\n",
      "Epoch [24/50], Step [509/735], Loss: 0.0873\n",
      "Epoch [24/50], Step [510/735], Loss: 0.3201\n",
      "Epoch [24/50], Step [511/735], Loss: 0.6316\n",
      "Epoch [24/50], Step [512/735], Loss: 0.1239\n",
      "Epoch [24/50], Step [513/735], Loss: 0.0717\n",
      "Epoch [24/50], Step [514/735], Loss: 0.2196\n",
      "Epoch [24/50], Step [515/735], Loss: 0.1220\n",
      "Epoch [24/50], Step [516/735], Loss: 0.4531\n",
      "Epoch [24/50], Step [517/735], Loss: 2.3188\n",
      "Epoch [24/50], Step [518/735], Loss: 0.2621\n",
      "Epoch [24/50], Step [519/735], Loss: 0.4334\n",
      "Epoch [24/50], Step [520/735], Loss: 0.0936\n",
      "Epoch [24/50], Step [521/735], Loss: 0.2507\n",
      "Epoch [24/50], Step [522/735], Loss: 0.2340\n",
      "Epoch [24/50], Step [523/735], Loss: 0.1055\n",
      "Epoch [24/50], Step [524/735], Loss: 1.3106\n",
      "Epoch [24/50], Step [525/735], Loss: 0.2290\n",
      "Epoch [24/50], Step [526/735], Loss: 0.1279\n",
      "Epoch [24/50], Step [527/735], Loss: 0.6690\n",
      "Epoch [24/50], Step [528/735], Loss: 0.1084\n",
      "Epoch [24/50], Step [529/735], Loss: 0.1657\n",
      "Epoch [24/50], Step [530/735], Loss: 0.1591\n",
      "Epoch [24/50], Step [531/735], Loss: 0.1011\n",
      "Epoch [24/50], Step [532/735], Loss: 0.0906\n",
      "Epoch [24/50], Step [533/735], Loss: 0.0953\n",
      "Epoch [24/50], Step [534/735], Loss: 0.1694\n",
      "Epoch [24/50], Step [535/735], Loss: 0.1597\n",
      "Epoch [24/50], Step [536/735], Loss: 0.3282\n",
      "Epoch [24/50], Step [537/735], Loss: 0.0912\n",
      "Epoch [24/50], Step [538/735], Loss: 0.2051\n",
      "Epoch [24/50], Step [539/735], Loss: 0.1082\n",
      "Epoch [24/50], Step [540/735], Loss: 0.1431\n",
      "Epoch [24/50], Step [541/735], Loss: 0.2170\n",
      "Epoch [24/50], Step [542/735], Loss: 0.0697\n",
      "Epoch [24/50], Step [543/735], Loss: 0.7303\n",
      "Epoch [24/50], Step [544/735], Loss: 0.0729\n",
      "Epoch [24/50], Step [545/735], Loss: 0.1549\n",
      "Epoch [24/50], Step [546/735], Loss: 0.0940\n",
      "Epoch [24/50], Step [547/735], Loss: 0.2016\n",
      "Epoch [24/50], Step [548/735], Loss: 0.0884\n",
      "Epoch [24/50], Step [549/735], Loss: 0.1313\n",
      "Epoch [24/50], Step [550/735], Loss: 0.0693\n",
      "Epoch [24/50], Step [551/735], Loss: 0.0584\n",
      "Epoch [24/50], Step [552/735], Loss: 0.2260\n",
      "Epoch [24/50], Step [553/735], Loss: 0.1075\n",
      "Epoch [24/50], Step [554/735], Loss: 0.9982\n",
      "Epoch [24/50], Step [555/735], Loss: 0.3402\n",
      "Epoch [24/50], Step [556/735], Loss: 0.1176\n",
      "Epoch [24/50], Step [557/735], Loss: 0.5910\n",
      "Epoch [24/50], Step [558/735], Loss: 0.2518\n",
      "Epoch [24/50], Step [559/735], Loss: 0.0800\n",
      "Epoch [24/50], Step [560/735], Loss: 0.0828\n",
      "Epoch [24/50], Step [561/735], Loss: 0.0806\n",
      "Epoch [24/50], Step [562/735], Loss: 0.1842\n",
      "Epoch [24/50], Step [563/735], Loss: 0.1427\n",
      "Epoch [24/50], Step [564/735], Loss: 0.1058\n",
      "Epoch [24/50], Step [565/735], Loss: 0.1395\n",
      "Epoch [24/50], Step [566/735], Loss: 0.3259\n",
      "Epoch [24/50], Step [567/735], Loss: 0.0896\n",
      "Epoch [24/50], Step [568/735], Loss: 0.1239\n",
      "Epoch [24/50], Step [569/735], Loss: 0.1070\n",
      "Epoch [24/50], Step [570/735], Loss: 0.1007\n",
      "Epoch [24/50], Step [571/735], Loss: 0.0840\n",
      "Epoch [24/50], Step [572/735], Loss: 0.1024\n",
      "Epoch [24/50], Step [573/735], Loss: 0.2411\n",
      "Epoch [24/50], Step [574/735], Loss: 0.1115\n",
      "Epoch [24/50], Step [575/735], Loss: 0.0662\n",
      "Epoch [24/50], Step [576/735], Loss: 0.0420\n",
      "Epoch [24/50], Step [577/735], Loss: 0.0681\n",
      "Epoch [24/50], Step [578/735], Loss: 0.1080\n",
      "Epoch [24/50], Step [579/735], Loss: 0.2717\n",
      "Epoch [24/50], Step [580/735], Loss: 0.1277\n",
      "Epoch [24/50], Step [581/735], Loss: 0.0461\n",
      "Epoch [24/50], Step [582/735], Loss: 0.1524\n",
      "Epoch [24/50], Step [583/735], Loss: 0.0954\n",
      "Epoch [24/50], Step [584/735], Loss: 0.1539\n",
      "Epoch [24/50], Step [585/735], Loss: 0.2089\n",
      "Epoch [24/50], Step [586/735], Loss: 0.1395\n",
      "Epoch [24/50], Step [587/735], Loss: 0.1117\n",
      "Epoch [24/50], Step [588/735], Loss: 0.2171\n",
      "Epoch [24/50], Step [589/735], Loss: 0.1038\n",
      "Epoch [24/50], Step [590/735], Loss: 1.4471\n",
      "Epoch [24/50], Step [591/735], Loss: 0.1707\n",
      "Epoch [24/50], Step [592/735], Loss: 0.0520\n",
      "Epoch [24/50], Step [593/735], Loss: 0.0885\n",
      "Epoch [24/50], Step [594/735], Loss: 0.0419\n",
      "Epoch [24/50], Step [595/735], Loss: 0.0790\n",
      "Epoch [24/50], Step [596/735], Loss: 0.2937\n",
      "Epoch [24/50], Step [597/735], Loss: 0.1844\n",
      "Epoch [24/50], Step [598/735], Loss: 0.1222\n",
      "Epoch [24/50], Step [599/735], Loss: 0.2105\n",
      "Epoch [24/50], Step [600/735], Loss: 0.1567\n",
      "Epoch [24/50], Step [601/735], Loss: 0.6503\n",
      "Epoch [24/50], Step [602/735], Loss: 0.1429\n",
      "Epoch [24/50], Step [603/735], Loss: 0.0705\n",
      "Epoch [24/50], Step [604/735], Loss: 0.1906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Step [605/735], Loss: 0.0900\n",
      "Epoch [24/50], Step [606/735], Loss: 0.0599\n",
      "Epoch [24/50], Step [607/735], Loss: 0.3568\n",
      "Epoch [24/50], Step [608/735], Loss: 0.0791\n",
      "Epoch [24/50], Step [609/735], Loss: 0.3501\n",
      "Epoch [24/50], Step [610/735], Loss: 0.1741\n",
      "Epoch [24/50], Step [611/735], Loss: 0.1168\n",
      "Epoch [24/50], Step [612/735], Loss: 0.4643\n",
      "Epoch [24/50], Step [613/735], Loss: 0.1213\n",
      "Epoch [24/50], Step [614/735], Loss: 0.1869\n",
      "Epoch [24/50], Step [615/735], Loss: 0.1399\n",
      "Epoch [24/50], Step [616/735], Loss: 0.1073\n",
      "Epoch [24/50], Step [617/735], Loss: 0.2766\n",
      "Epoch [24/50], Step [618/735], Loss: 0.1508\n",
      "Epoch [24/50], Step [619/735], Loss: 0.2087\n",
      "Epoch [24/50], Step [620/735], Loss: 0.1879\n",
      "Epoch [24/50], Step [621/735], Loss: 0.1138\n",
      "Epoch [24/50], Step [622/735], Loss: 0.2179\n",
      "Epoch [24/50], Step [623/735], Loss: 0.0856\n",
      "Epoch [24/50], Step [624/735], Loss: 0.0785\n",
      "Epoch [24/50], Step [625/735], Loss: 0.0624\n",
      "Epoch [24/50], Step [626/735], Loss: 0.1075\n",
      "Epoch [24/50], Step [627/735], Loss: 0.0502\n",
      "Epoch [24/50], Step [628/735], Loss: 0.1295\n",
      "Epoch [24/50], Step [629/735], Loss: 0.2765\n",
      "Epoch [24/50], Step [630/735], Loss: 0.0502\n",
      "Epoch [24/50], Step [631/735], Loss: 0.0835\n",
      "Epoch [24/50], Step [632/735], Loss: 0.2078\n",
      "Epoch [24/50], Step [633/735], Loss: 0.1161\n",
      "Epoch [24/50], Step [634/735], Loss: 0.0843\n",
      "Epoch [24/50], Step [635/735], Loss: 0.1131\n",
      "Epoch [24/50], Step [636/735], Loss: 0.1348\n",
      "Epoch [24/50], Step [637/735], Loss: 0.2481\n",
      "Epoch [24/50], Step [638/735], Loss: 0.1136\n",
      "Epoch [24/50], Step [639/735], Loss: 0.0588\n",
      "Epoch [24/50], Step [640/735], Loss: 0.0959\n",
      "Epoch [24/50], Step [641/735], Loss: 0.2224\n",
      "Epoch [24/50], Step [642/735], Loss: 2.4486\n",
      "Epoch [24/50], Step [643/735], Loss: 0.1779\n",
      "Epoch [24/50], Step [644/735], Loss: 0.2443\n",
      "Epoch [24/50], Step [645/735], Loss: 0.8115\n",
      "Epoch [24/50], Step [646/735], Loss: 0.1959\n",
      "Epoch [24/50], Step [647/735], Loss: 0.1566\n",
      "Epoch [24/50], Step [648/735], Loss: 0.1664\n",
      "Epoch [24/50], Step [649/735], Loss: 0.4743\n",
      "Epoch [24/50], Step [650/735], Loss: 0.0711\n",
      "Epoch [24/50], Step [651/735], Loss: 0.2841\n",
      "Epoch [24/50], Step [652/735], Loss: 0.1245\n",
      "Epoch [24/50], Step [653/735], Loss: 0.1539\n",
      "Epoch [24/50], Step [654/735], Loss: 0.2765\n",
      "Epoch [24/50], Step [655/735], Loss: 0.1831\n",
      "Epoch [24/50], Step [656/735], Loss: 0.1367\n",
      "Epoch [24/50], Step [657/735], Loss: 0.2013\n",
      "Epoch [24/50], Step [658/735], Loss: 0.1467\n",
      "Epoch [24/50], Step [659/735], Loss: 0.0978\n",
      "Epoch [24/50], Step [660/735], Loss: 0.1271\n",
      "Epoch [24/50], Step [661/735], Loss: 0.1464\n",
      "Epoch [24/50], Step [662/735], Loss: 0.1322\n",
      "Epoch [24/50], Step [663/735], Loss: 0.1536\n",
      "Epoch [24/50], Step [664/735], Loss: 0.1178\n",
      "Epoch [24/50], Step [665/735], Loss: 2.0951\n",
      "Epoch [24/50], Step [666/735], Loss: 0.2249\n",
      "Epoch [24/50], Step [667/735], Loss: 0.1477\n",
      "Epoch [24/50], Step [668/735], Loss: 0.0781\n",
      "Epoch [24/50], Step [669/735], Loss: 0.0815\n",
      "Epoch [24/50], Step [670/735], Loss: 0.1881\n",
      "Epoch [24/50], Step [671/735], Loss: 0.0489\n",
      "Epoch [24/50], Step [672/735], Loss: 0.1309\n",
      "Epoch [24/50], Step [673/735], Loss: 1.6130\n",
      "Epoch [24/50], Step [674/735], Loss: 0.1006\n",
      "Epoch [24/50], Step [675/735], Loss: 0.0810\n",
      "Epoch [24/50], Step [676/735], Loss: 0.0970\n",
      "Epoch [24/50], Step [677/735], Loss: 0.1109\n",
      "Epoch [24/50], Step [678/735], Loss: 0.0588\n",
      "Epoch [24/50], Step [679/735], Loss: 0.0542\n",
      "Epoch [24/50], Step [680/735], Loss: 0.7498\n",
      "Epoch [24/50], Step [681/735], Loss: 0.1761\n",
      "Epoch [24/50], Step [682/735], Loss: 0.1684\n",
      "Epoch [24/50], Step [683/735], Loss: 0.1246\n",
      "Epoch [24/50], Step [684/735], Loss: 0.3447\n",
      "Epoch [24/50], Step [685/735], Loss: 0.3816\n",
      "Epoch [24/50], Step [686/735], Loss: 0.0989\n",
      "Epoch [24/50], Step [687/735], Loss: 0.0560\n",
      "Epoch [24/50], Step [688/735], Loss: 0.0537\n",
      "Epoch [24/50], Step [689/735], Loss: 0.2716\n",
      "Epoch [24/50], Step [690/735], Loss: 0.0834\n",
      "Epoch [24/50], Step [691/735], Loss: 0.2291\n",
      "Epoch [24/50], Step [692/735], Loss: 0.0555\n",
      "Epoch [24/50], Step [693/735], Loss: 0.1194\n",
      "Epoch [24/50], Step [694/735], Loss: 0.1854\n",
      "Epoch [24/50], Step [695/735], Loss: 0.1914\n",
      "Epoch [24/50], Step [696/735], Loss: 0.2185\n",
      "Epoch [24/50], Step [697/735], Loss: 0.1496\n",
      "Epoch [24/50], Step [698/735], Loss: 0.0601\n",
      "Epoch [24/50], Step [699/735], Loss: 0.1303\n",
      "Epoch [24/50], Step [700/735], Loss: 0.0395\n",
      "Epoch [24/50], Step [701/735], Loss: 0.0892\n",
      "Epoch [24/50], Step [702/735], Loss: 0.0683\n",
      "Epoch [24/50], Step [703/735], Loss: 0.1609\n",
      "Epoch [24/50], Step [704/735], Loss: 0.1954\n",
      "Epoch [24/50], Step [705/735], Loss: 0.0851\n",
      "Epoch [24/50], Step [706/735], Loss: 0.0700\n",
      "Epoch [24/50], Step [707/735], Loss: 0.0554\n",
      "Epoch [24/50], Step [708/735], Loss: 0.1423\n",
      "Epoch [24/50], Step [709/735], Loss: 0.1026\n",
      "Epoch [24/50], Step [710/735], Loss: 0.0800\n",
      "Epoch [24/50], Step [711/735], Loss: 0.0817\n",
      "Epoch [24/50], Step [712/735], Loss: 0.2776\n",
      "Epoch [24/50], Step [713/735], Loss: 0.0336\n",
      "Epoch [24/50], Step [714/735], Loss: 0.2107\n",
      "Epoch [24/50], Step [715/735], Loss: 0.0664\n",
      "Epoch [24/50], Step [716/735], Loss: 0.1562\n",
      "Epoch [24/50], Step [717/735], Loss: 0.1438\n",
      "Epoch [24/50], Step [718/735], Loss: 0.1378\n",
      "Epoch [24/50], Step [719/735], Loss: 0.2200\n",
      "Epoch [24/50], Step [720/735], Loss: 0.1764\n",
      "Epoch [24/50], Step [721/735], Loss: 0.2603\n",
      "Epoch [24/50], Step [722/735], Loss: 0.0919\n",
      "Epoch [24/50], Step [723/735], Loss: 0.0329\n",
      "Epoch [24/50], Step [724/735], Loss: 0.1476\n",
      "Epoch [24/50], Step [725/735], Loss: 0.0948\n",
      "Epoch [24/50], Step [726/735], Loss: 0.1472\n",
      "Epoch [24/50], Step [727/735], Loss: 0.0662\n",
      "Epoch [24/50], Step [728/735], Loss: 0.0711\n",
      "Epoch [24/50], Step [729/735], Loss: 0.1769\n",
      "Epoch [24/50], Step [730/735], Loss: 0.1849\n",
      "Epoch [24/50], Step [731/735], Loss: 0.0446\n",
      "Epoch [24/50], Step [732/735], Loss: 0.2550\n",
      "Epoch [24/50], Step [733/735], Loss: 0.0821\n",
      "Epoch [24/50], Step [734/735], Loss: 0.3784\n",
      "Epoch [24/50], Step [735/735], Loss: 0.0185\n",
      "Epoch [25/50], Step [1/735], Loss: 0.1842\n",
      "Epoch [25/50], Step [2/735], Loss: 0.1053\n",
      "Epoch [25/50], Step [3/735], Loss: 0.1461\n",
      "Epoch [25/50], Step [4/735], Loss: 0.0384\n",
      "Epoch [25/50], Step [5/735], Loss: 0.2834\n",
      "Epoch [25/50], Step [6/735], Loss: 0.1649\n",
      "Epoch [25/50], Step [7/735], Loss: 0.1690\n",
      "Epoch [25/50], Step [8/735], Loss: 0.2749\n",
      "Epoch [25/50], Step [9/735], Loss: 0.1415\n",
      "Epoch [25/50], Step [10/735], Loss: 0.0968\n",
      "Epoch [25/50], Step [11/735], Loss: 0.1671\n",
      "Epoch [25/50], Step [12/735], Loss: 0.2505\n",
      "Epoch [25/50], Step [13/735], Loss: 0.1935\n",
      "Epoch [25/50], Step [14/735], Loss: 0.3594\n",
      "Epoch [25/50], Step [15/735], Loss: 0.1012\n",
      "Epoch [25/50], Step [16/735], Loss: 0.0799\n",
      "Epoch [25/50], Step [17/735], Loss: 0.0843\n",
      "Epoch [25/50], Step [18/735], Loss: 0.1410\n",
      "Epoch [25/50], Step [19/735], Loss: 0.0688\n",
      "Epoch [25/50], Step [20/735], Loss: 0.1825\n",
      "Epoch [25/50], Step [21/735], Loss: 0.1069\n",
      "Epoch [25/50], Step [22/735], Loss: 0.0435\n",
      "Epoch [25/50], Step [23/735], Loss: 0.1855\n",
      "Epoch [25/50], Step [24/735], Loss: 0.0716\n",
      "Epoch [25/50], Step [25/735], Loss: 0.0713\n",
      "Epoch [25/50], Step [26/735], Loss: 0.1738\n",
      "Epoch [25/50], Step [27/735], Loss: 0.2067\n",
      "Epoch [25/50], Step [28/735], Loss: 0.0855\n",
      "Epoch [25/50], Step [29/735], Loss: 0.1086\n",
      "Epoch [25/50], Step [30/735], Loss: 0.0947\n",
      "Epoch [25/50], Step [31/735], Loss: 0.2331\n",
      "Epoch [25/50], Step [32/735], Loss: 0.0857\n",
      "Epoch [25/50], Step [33/735], Loss: 0.0613\n",
      "Epoch [25/50], Step [34/735], Loss: 0.1260\n",
      "Epoch [25/50], Step [35/735], Loss: 0.1809\n",
      "Epoch [25/50], Step [36/735], Loss: 0.0928\n",
      "Epoch [25/50], Step [37/735], Loss: 0.0871\n",
      "Epoch [25/50], Step [38/735], Loss: 0.0764\n",
      "Epoch [25/50], Step [39/735], Loss: 0.1084\n",
      "Epoch [25/50], Step [40/735], Loss: 0.2364\n",
      "Epoch [25/50], Step [41/735], Loss: 0.0538\n",
      "Epoch [25/50], Step [42/735], Loss: 0.0834\n",
      "Epoch [25/50], Step [43/735], Loss: 0.1683\n",
      "Epoch [25/50], Step [44/735], Loss: 0.0743\n",
      "Epoch [25/50], Step [45/735], Loss: 0.1834\n",
      "Epoch [25/50], Step [46/735], Loss: 0.1533\n",
      "Epoch [25/50], Step [47/735], Loss: 0.0491\n",
      "Epoch [25/50], Step [48/735], Loss: 1.2034\n",
      "Epoch [25/50], Step [49/735], Loss: 0.1274\n",
      "Epoch [25/50], Step [50/735], Loss: 0.2068\n",
      "Epoch [25/50], Step [51/735], Loss: 0.1068\n",
      "Epoch [25/50], Step [52/735], Loss: 0.1043\n",
      "Epoch [25/50], Step [53/735], Loss: 0.2283\n",
      "Epoch [25/50], Step [54/735], Loss: 0.1173\n",
      "Epoch [25/50], Step [55/735], Loss: 0.0903\n",
      "Epoch [25/50], Step [56/735], Loss: 0.3328\n",
      "Epoch [25/50], Step [57/735], Loss: 0.1434\n",
      "Epoch [25/50], Step [58/735], Loss: 0.0686\n",
      "Epoch [25/50], Step [59/735], Loss: 0.2463\n",
      "Epoch [25/50], Step [60/735], Loss: 0.1003\n",
      "Epoch [25/50], Step [61/735], Loss: 0.0984\n",
      "Epoch [25/50], Step [62/735], Loss: 0.0685\n",
      "Epoch [25/50], Step [63/735], Loss: 0.2568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Step [64/735], Loss: 0.9816\n",
      "Epoch [25/50], Step [65/735], Loss: 0.1027\n",
      "Epoch [25/50], Step [66/735], Loss: 0.1165\n",
      "Epoch [25/50], Step [67/735], Loss: 0.0639\n",
      "Epoch [25/50], Step [68/735], Loss: 0.0888\n",
      "Epoch [25/50], Step [69/735], Loss: 0.2289\n",
      "Epoch [25/50], Step [70/735], Loss: 0.1092\n",
      "Epoch [25/50], Step [71/735], Loss: 0.2353\n",
      "Epoch [25/50], Step [72/735], Loss: 0.4252\n",
      "Epoch [25/50], Step [73/735], Loss: 0.1049\n",
      "Epoch [25/50], Step [74/735], Loss: 0.0891\n",
      "Epoch [25/50], Step [75/735], Loss: 0.0646\n",
      "Epoch [25/50], Step [76/735], Loss: 0.0933\n",
      "Epoch [25/50], Step [77/735], Loss: 0.0534\n",
      "Epoch [25/50], Step [78/735], Loss: 0.1552\n",
      "Epoch [25/50], Step [79/735], Loss: 0.6746\n",
      "Epoch [25/50], Step [80/735], Loss: 0.0730\n",
      "Epoch [25/50], Step [81/735], Loss: 0.2294\n",
      "Epoch [25/50], Step [82/735], Loss: 0.0601\n",
      "Epoch [25/50], Step [83/735], Loss: 0.0470\n",
      "Epoch [25/50], Step [84/735], Loss: 0.2018\n",
      "Epoch [25/50], Step [85/735], Loss: 0.0950\n",
      "Epoch [25/50], Step [86/735], Loss: 0.0373\n",
      "Epoch [25/50], Step [87/735], Loss: 0.2874\n",
      "Epoch [25/50], Step [88/735], Loss: 0.0781\n",
      "Epoch [25/50], Step [89/735], Loss: 0.0597\n",
      "Epoch [25/50], Step [90/735], Loss: 0.1930\n",
      "Epoch [25/50], Step [91/735], Loss: 0.1221\n",
      "Epoch [25/50], Step [92/735], Loss: 0.3770\n",
      "Epoch [25/50], Step [93/735], Loss: 2.0698\n",
      "Epoch [25/50], Step [94/735], Loss: 0.1732\n",
      "Epoch [25/50], Step [95/735], Loss: 0.0940\n",
      "Epoch [25/50], Step [96/735], Loss: 0.1283\n",
      "Epoch [25/50], Step [97/735], Loss: 0.1544\n",
      "Epoch [25/50], Step [98/735], Loss: 0.0720\n",
      "Epoch [25/50], Step [99/735], Loss: 0.1554\n",
      "Epoch [25/50], Step [100/735], Loss: 0.1448\n",
      "Epoch [25/50], Step [101/735], Loss: 0.1521\n",
      "Epoch [25/50], Step [102/735], Loss: 1.9500\n",
      "Epoch [25/50], Step [103/735], Loss: 0.0482\n",
      "Epoch [25/50], Step [104/735], Loss: 0.1928\n",
      "Epoch [25/50], Step [105/735], Loss: 0.2134\n",
      "Epoch [25/50], Step [106/735], Loss: 0.0879\n",
      "Epoch [25/50], Step [107/735], Loss: 0.2149\n",
      "Epoch [25/50], Step [108/735], Loss: 0.0967\n",
      "Epoch [25/50], Step [109/735], Loss: 0.3852\n",
      "Epoch [25/50], Step [110/735], Loss: 0.2162\n",
      "Epoch [25/50], Step [111/735], Loss: 0.0932\n",
      "Epoch [25/50], Step [112/735], Loss: 0.8281\n",
      "Epoch [25/50], Step [113/735], Loss: 0.1465\n",
      "Epoch [25/50], Step [114/735], Loss: 0.1022\n",
      "Epoch [25/50], Step [115/735], Loss: 0.2209\n",
      "Epoch [25/50], Step [116/735], Loss: 0.1700\n",
      "Epoch [25/50], Step [117/735], Loss: 0.0325\n",
      "Epoch [25/50], Step [118/735], Loss: 0.1032\n",
      "Epoch [25/50], Step [119/735], Loss: 0.0769\n",
      "Epoch [25/50], Step [120/735], Loss: 0.3325\n",
      "Epoch [25/50], Step [121/735], Loss: 0.0966\n",
      "Epoch [25/50], Step [122/735], Loss: 0.0756\n",
      "Epoch [25/50], Step [123/735], Loss: 0.1782\n",
      "Epoch [25/50], Step [124/735], Loss: 0.0697\n",
      "Epoch [25/50], Step [125/735], Loss: 0.1558\n",
      "Epoch [25/50], Step [126/735], Loss: 0.1122\n",
      "Epoch [25/50], Step [127/735], Loss: 0.3863\n",
      "Epoch [25/50], Step [128/735], Loss: 0.0854\n",
      "Epoch [25/50], Step [129/735], Loss: 0.1782\n",
      "Epoch [25/50], Step [130/735], Loss: 0.1341\n",
      "Epoch [25/50], Step [131/735], Loss: 0.0871\n",
      "Epoch [25/50], Step [132/735], Loss: 0.1794\n",
      "Epoch [25/50], Step [133/735], Loss: 0.0702\n",
      "Epoch [25/50], Step [134/735], Loss: 0.0620\n",
      "Epoch [25/50], Step [135/735], Loss: 0.2092\n",
      "Epoch [25/50], Step [136/735], Loss: 0.0896\n",
      "Epoch [25/50], Step [137/735], Loss: 0.0962\n",
      "Epoch [25/50], Step [138/735], Loss: 0.1448\n",
      "Epoch [25/50], Step [139/735], Loss: 0.3756\n",
      "Epoch [25/50], Step [140/735], Loss: 0.2568\n",
      "Epoch [25/50], Step [141/735], Loss: 0.0736\n",
      "Epoch [25/50], Step [142/735], Loss: 0.0645\n",
      "Epoch [25/50], Step [143/735], Loss: 0.1653\n",
      "Epoch [25/50], Step [144/735], Loss: 0.0706\n",
      "Epoch [25/50], Step [145/735], Loss: 0.2461\n",
      "Epoch [25/50], Step [146/735], Loss: 0.1541\n",
      "Epoch [25/50], Step [147/735], Loss: 0.0937\n",
      "Epoch [25/50], Step [148/735], Loss: 0.3010\n",
      "Epoch [25/50], Step [149/735], Loss: 0.5715\n",
      "Epoch [25/50], Step [150/735], Loss: 0.0938\n",
      "Epoch [25/50], Step [151/735], Loss: 0.1072\n",
      "Epoch [25/50], Step [152/735], Loss: 0.1760\n",
      "Epoch [25/50], Step [153/735], Loss: 0.1168\n",
      "Epoch [25/50], Step [154/735], Loss: 0.2117\n",
      "Epoch [25/50], Step [155/735], Loss: 0.1297\n",
      "Epoch [25/50], Step [156/735], Loss: 0.0536\n",
      "Epoch [25/50], Step [157/735], Loss: 0.6225\n",
      "Epoch [25/50], Step [158/735], Loss: 0.0899\n",
      "Epoch [25/50], Step [159/735], Loss: 0.1154\n",
      "Epoch [25/50], Step [160/735], Loss: 0.0629\n",
      "Epoch [25/50], Step [161/735], Loss: 1.3416\n",
      "Epoch [25/50], Step [162/735], Loss: 0.2107\n",
      "Epoch [25/50], Step [163/735], Loss: 0.1874\n",
      "Epoch [25/50], Step [164/735], Loss: 0.2155\n",
      "Epoch [25/50], Step [165/735], Loss: 0.0457\n",
      "Epoch [25/50], Step [166/735], Loss: 1.1621\n",
      "Epoch [25/50], Step [167/735], Loss: 0.1469\n",
      "Epoch [25/50], Step [168/735], Loss: 0.1438\n",
      "Epoch [25/50], Step [169/735], Loss: 0.1473\n",
      "Epoch [25/50], Step [170/735], Loss: 0.0862\n",
      "Epoch [25/50], Step [171/735], Loss: 0.4696\n",
      "Epoch [25/50], Step [172/735], Loss: 0.0378\n",
      "Epoch [25/50], Step [173/735], Loss: 0.0598\n",
      "Epoch [25/50], Step [174/735], Loss: 0.2076\n",
      "Epoch [25/50], Step [175/735], Loss: 0.0600\n",
      "Epoch [25/50], Step [176/735], Loss: 0.1290\n",
      "Epoch [25/50], Step [177/735], Loss: 0.1850\n",
      "Epoch [25/50], Step [178/735], Loss: 0.1312\n",
      "Epoch [25/50], Step [179/735], Loss: 0.1436\n",
      "Epoch [25/50], Step [180/735], Loss: 0.1667\n",
      "Epoch [25/50], Step [181/735], Loss: 0.1427\n",
      "Epoch [25/50], Step [182/735], Loss: 0.0975\n",
      "Epoch [25/50], Step [183/735], Loss: 0.2249\n",
      "Epoch [25/50], Step [184/735], Loss: 0.0774\n",
      "Epoch [25/50], Step [185/735], Loss: 0.1463\n",
      "Epoch [25/50], Step [186/735], Loss: 0.3166\n",
      "Epoch [25/50], Step [187/735], Loss: 0.3366\n",
      "Epoch [25/50], Step [188/735], Loss: 0.3267\n",
      "Epoch [25/50], Step [189/735], Loss: 0.1470\n",
      "Epoch [25/50], Step [190/735], Loss: 0.1211\n",
      "Epoch [25/50], Step [191/735], Loss: 0.3609\n",
      "Epoch [25/50], Step [192/735], Loss: 0.0761\n",
      "Epoch [25/50], Step [193/735], Loss: 0.2220\n",
      "Epoch [25/50], Step [194/735], Loss: 0.4396\n",
      "Epoch [25/50], Step [195/735], Loss: 0.0692\n",
      "Epoch [25/50], Step [196/735], Loss: 0.0603\n",
      "Epoch [25/50], Step [197/735], Loss: 0.4458\n",
      "Epoch [25/50], Step [198/735], Loss: 0.0556\n",
      "Epoch [25/50], Step [199/735], Loss: 0.1258\n",
      "Epoch [25/50], Step [200/735], Loss: 0.4093\n",
      "Epoch [25/50], Step [201/735], Loss: 0.0593\n",
      "Epoch [25/50], Step [202/735], Loss: 0.0545\n",
      "Epoch [25/50], Step [203/735], Loss: 0.1428\n",
      "Epoch [25/50], Step [204/735], Loss: 0.1912\n",
      "Epoch [25/50], Step [205/735], Loss: 0.4231\n",
      "Epoch [25/50], Step [206/735], Loss: 0.0731\n",
      "Epoch [25/50], Step [207/735], Loss: 0.0745\n",
      "Epoch [25/50], Step [208/735], Loss: 0.1056\n",
      "Epoch [25/50], Step [209/735], Loss: 0.0591\n",
      "Epoch [25/50], Step [210/735], Loss: 0.0770\n",
      "Epoch [25/50], Step [211/735], Loss: 0.1502\n",
      "Epoch [25/50], Step [212/735], Loss: 0.1085\n",
      "Epoch [25/50], Step [213/735], Loss: 0.1562\n",
      "Epoch [25/50], Step [214/735], Loss: 0.1607\n",
      "Epoch [25/50], Step [215/735], Loss: 0.0853\n",
      "Epoch [25/50], Step [216/735], Loss: 0.2142\n",
      "Epoch [25/50], Step [217/735], Loss: 0.0716\n",
      "Epoch [25/50], Step [218/735], Loss: 0.0951\n",
      "Epoch [25/50], Step [219/735], Loss: 0.0576\n",
      "Epoch [25/50], Step [220/735], Loss: 0.0854\n",
      "Epoch [25/50], Step [221/735], Loss: 0.1746\n",
      "Epoch [25/50], Step [222/735], Loss: 0.2528\n",
      "Epoch [25/50], Step [223/735], Loss: 0.0725\n",
      "Epoch [25/50], Step [224/735], Loss: 0.1859\n",
      "Epoch [25/50], Step [225/735], Loss: 0.3005\n",
      "Epoch [25/50], Step [226/735], Loss: 0.1735\n",
      "Epoch [25/50], Step [227/735], Loss: 0.2509\n",
      "Epoch [25/50], Step [228/735], Loss: 0.0307\n",
      "Epoch [25/50], Step [229/735], Loss: 0.1587\n",
      "Epoch [25/50], Step [230/735], Loss: 0.1071\n",
      "Epoch [25/50], Step [231/735], Loss: 0.1056\n",
      "Epoch [25/50], Step [232/735], Loss: 0.2625\n",
      "Epoch [25/50], Step [233/735], Loss: 0.1299\n",
      "Epoch [25/50], Step [234/735], Loss: 0.0848\n",
      "Epoch [25/50], Step [235/735], Loss: 0.0507\n",
      "Epoch [25/50], Step [236/735], Loss: 0.0655\n",
      "Epoch [25/50], Step [237/735], Loss: 0.0669\n",
      "Epoch [25/50], Step [238/735], Loss: 0.1813\n",
      "Epoch [25/50], Step [239/735], Loss: 0.9974\n",
      "Epoch [25/50], Step [240/735], Loss: 0.1047\n",
      "Epoch [25/50], Step [241/735], Loss: 0.1059\n",
      "Epoch [25/50], Step [242/735], Loss: 0.3861\n",
      "Epoch [25/50], Step [243/735], Loss: 0.1210\n",
      "Epoch [25/50], Step [244/735], Loss: 0.1070\n",
      "Epoch [25/50], Step [245/735], Loss: 0.3906\n",
      "Epoch [25/50], Step [246/735], Loss: 0.1845\n",
      "Epoch [25/50], Step [247/735], Loss: 0.7234\n",
      "Epoch [25/50], Step [248/735], Loss: 0.1099\n",
      "Epoch [25/50], Step [249/735], Loss: 0.3097\n",
      "Epoch [25/50], Step [250/735], Loss: 0.1028\n",
      "Epoch [25/50], Step [251/735], Loss: 0.2090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Step [252/735], Loss: 0.1034\n",
      "Epoch [25/50], Step [253/735], Loss: 0.0739\n",
      "Epoch [25/50], Step [254/735], Loss: 0.1785\n",
      "Epoch [25/50], Step [255/735], Loss: 0.2049\n",
      "Epoch [25/50], Step [256/735], Loss: 0.2456\n",
      "Epoch [25/50], Step [257/735], Loss: 0.0574\n",
      "Epoch [25/50], Step [258/735], Loss: 0.0579\n",
      "Epoch [25/50], Step [259/735], Loss: 0.1221\n",
      "Epoch [25/50], Step [260/735], Loss: 0.2440\n",
      "Epoch [25/50], Step [261/735], Loss: 0.1953\n",
      "Epoch [25/50], Step [262/735], Loss: 0.0475\n",
      "Epoch [25/50], Step [263/735], Loss: 0.2791\n",
      "Epoch [25/50], Step [264/735], Loss: 0.0942\n",
      "Epoch [25/50], Step [265/735], Loss: 0.1597\n",
      "Epoch [25/50], Step [266/735], Loss: 0.0533\n",
      "Epoch [25/50], Step [267/735], Loss: 0.0885\n",
      "Epoch [25/50], Step [268/735], Loss: 0.2324\n",
      "Epoch [25/50], Step [269/735], Loss: 0.0844\n",
      "Epoch [25/50], Step [270/735], Loss: 0.0224\n",
      "Epoch [25/50], Step [271/735], Loss: 0.0792\n",
      "Epoch [25/50], Step [272/735], Loss: 0.0707\n",
      "Epoch [25/50], Step [273/735], Loss: 0.0889\n",
      "Epoch [25/50], Step [274/735], Loss: 0.0793\n",
      "Epoch [25/50], Step [275/735], Loss: 0.0491\n",
      "Epoch [25/50], Step [276/735], Loss: 0.1041\n",
      "Epoch [25/50], Step [277/735], Loss: 0.0684\n",
      "Epoch [25/50], Step [278/735], Loss: 0.1716\n",
      "Epoch [25/50], Step [279/735], Loss: 0.1107\n",
      "Epoch [25/50], Step [280/735], Loss: 0.0849\n",
      "Epoch [25/50], Step [281/735], Loss: 0.0799\n",
      "Epoch [25/50], Step [282/735], Loss: 0.1076\n",
      "Epoch [25/50], Step [283/735], Loss: 0.2209\n",
      "Epoch [25/50], Step [284/735], Loss: 0.1634\n",
      "Epoch [25/50], Step [285/735], Loss: 0.1198\n",
      "Epoch [25/50], Step [286/735], Loss: 0.0727\n",
      "Epoch [25/50], Step [287/735], Loss: 0.0982\n",
      "Epoch [25/50], Step [288/735], Loss: 0.1799\n",
      "Epoch [25/50], Step [289/735], Loss: 0.1099\n",
      "Epoch [25/50], Step [290/735], Loss: 0.1033\n",
      "Epoch [25/50], Step [291/735], Loss: 0.1164\n",
      "Epoch [25/50], Step [292/735], Loss: 0.1018\n",
      "Epoch [25/50], Step [293/735], Loss: 0.0722\n",
      "Epoch [25/50], Step [294/735], Loss: 0.0315\n",
      "Epoch [25/50], Step [295/735], Loss: 0.0389\n",
      "Epoch [25/50], Step [296/735], Loss: 0.2190\n",
      "Epoch [25/50], Step [297/735], Loss: 0.1356\n",
      "Epoch [25/50], Step [298/735], Loss: 0.1306\n",
      "Epoch [25/50], Step [299/735], Loss: 0.0640\n",
      "Epoch [25/50], Step [300/735], Loss: 0.0659\n",
      "Epoch [25/50], Step [301/735], Loss: 0.0945\n",
      "Epoch [25/50], Step [302/735], Loss: 0.0718\n",
      "Epoch [25/50], Step [303/735], Loss: 0.0785\n",
      "Epoch [25/50], Step [304/735], Loss: 0.0543\n",
      "Epoch [25/50], Step [305/735], Loss: 0.1022\n",
      "Epoch [25/50], Step [306/735], Loss: 0.1725\n",
      "Epoch [25/50], Step [307/735], Loss: 0.0528\n",
      "Epoch [25/50], Step [308/735], Loss: 0.1065\n",
      "Epoch [25/50], Step [309/735], Loss: 0.0899\n",
      "Epoch [25/50], Step [310/735], Loss: 0.0319\n",
      "Epoch [25/50], Step [311/735], Loss: 0.1387\n",
      "Epoch [25/50], Step [312/735], Loss: 0.0394\n",
      "Epoch [25/50], Step [313/735], Loss: 0.1458\n",
      "Epoch [25/50], Step [314/735], Loss: 0.1240\n",
      "Epoch [25/50], Step [315/735], Loss: 0.1202\n",
      "Epoch [25/50], Step [316/735], Loss: 0.0804\n",
      "Epoch [25/50], Step [317/735], Loss: 0.0513\n",
      "Epoch [25/50], Step [318/735], Loss: 0.0761\n",
      "Epoch [25/50], Step [319/735], Loss: 0.0218\n",
      "Epoch [25/50], Step [320/735], Loss: 0.0499\n",
      "Epoch [25/50], Step [321/735], Loss: 0.0821\n",
      "Epoch [25/50], Step [322/735], Loss: 0.2806\n",
      "Epoch [25/50], Step [323/735], Loss: 0.0855\n",
      "Epoch [25/50], Step [324/735], Loss: 0.1053\n",
      "Epoch [25/50], Step [325/735], Loss: 0.0988\n",
      "Epoch [25/50], Step [326/735], Loss: 0.5058\n",
      "Epoch [25/50], Step [327/735], Loss: 0.1404\n",
      "Epoch [25/50], Step [328/735], Loss: 0.8106\n",
      "Epoch [25/50], Step [329/735], Loss: 0.0401\n",
      "Epoch [25/50], Step [330/735], Loss: 0.0952\n",
      "Epoch [25/50], Step [331/735], Loss: 0.0334\n",
      "Epoch [25/50], Step [332/735], Loss: 0.7379\n",
      "Epoch [25/50], Step [333/735], Loss: 0.1061\n",
      "Epoch [25/50], Step [334/735], Loss: 0.3375\n",
      "Epoch [25/50], Step [335/735], Loss: 0.1297\n",
      "Epoch [25/50], Step [336/735], Loss: 0.3501\n",
      "Epoch [25/50], Step [337/735], Loss: 0.0602\n",
      "Epoch [25/50], Step [338/735], Loss: 0.1044\n",
      "Epoch [25/50], Step [339/735], Loss: 0.1617\n",
      "Epoch [25/50], Step [340/735], Loss: 0.0598\n",
      "Epoch [25/50], Step [341/735], Loss: 0.0938\n",
      "Epoch [25/50], Step [342/735], Loss: 0.0659\n",
      "Epoch [25/50], Step [343/735], Loss: 0.4032\n",
      "Epoch [25/50], Step [344/735], Loss: 0.1124\n",
      "Epoch [25/50], Step [345/735], Loss: 0.1406\n",
      "Epoch [25/50], Step [346/735], Loss: 0.2083\n",
      "Epoch [25/50], Step [347/735], Loss: 0.2047\n",
      "Epoch [25/50], Step [348/735], Loss: 0.0351\n",
      "Epoch [25/50], Step [349/735], Loss: 0.1426\n",
      "Epoch [25/50], Step [350/735], Loss: 0.0794\n",
      "Epoch [25/50], Step [351/735], Loss: 0.0530\n",
      "Epoch [25/50], Step [352/735], Loss: 0.0927\n",
      "Epoch [25/50], Step [353/735], Loss: 0.0792\n",
      "Epoch [25/50], Step [354/735], Loss: 0.1715\n",
      "Epoch [25/50], Step [355/735], Loss: 0.1054\n",
      "Epoch [25/50], Step [356/735], Loss: 0.0410\n",
      "Epoch [25/50], Step [357/735], Loss: 0.0887\n",
      "Epoch [25/50], Step [358/735], Loss: 0.0870\n",
      "Epoch [25/50], Step [359/735], Loss: 0.2156\n",
      "Epoch [25/50], Step [360/735], Loss: 0.0821\n",
      "Epoch [25/50], Step [361/735], Loss: 0.1309\n",
      "Epoch [25/50], Step [362/735], Loss: 0.0837\n",
      "Epoch [25/50], Step [363/735], Loss: 0.1375\n",
      "Epoch [25/50], Step [364/735], Loss: 0.0945\n",
      "Epoch [25/50], Step [365/735], Loss: 0.5597\n",
      "Epoch [25/50], Step [366/735], Loss: 0.1872\n",
      "Epoch [25/50], Step [367/735], Loss: 0.1563\n",
      "Epoch [25/50], Step [368/735], Loss: 0.2156\n",
      "Epoch [25/50], Step [369/735], Loss: 0.0727\n",
      "Epoch [25/50], Step [370/735], Loss: 0.1857\n",
      "Epoch [25/50], Step [371/735], Loss: 0.0890\n",
      "Epoch [25/50], Step [372/735], Loss: 0.9860\n",
      "Epoch [25/50], Step [373/735], Loss: 0.1030\n",
      "Epoch [25/50], Step [374/735], Loss: 0.1983\n",
      "Epoch [25/50], Step [375/735], Loss: 0.7239\n",
      "Epoch [25/50], Step [376/735], Loss: 0.0907\n",
      "Epoch [25/50], Step [377/735], Loss: 0.1482\n",
      "Epoch [25/50], Step [378/735], Loss: 0.0744\n",
      "Epoch [25/50], Step [379/735], Loss: 0.1276\n",
      "Epoch [25/50], Step [380/735], Loss: 0.1015\n",
      "Epoch [25/50], Step [381/735], Loss: 2.2866\n",
      "Epoch [25/50], Step [382/735], Loss: 0.0615\n",
      "Epoch [25/50], Step [383/735], Loss: 0.2114\n",
      "Epoch [25/50], Step [384/735], Loss: 0.1337\n",
      "Epoch [25/50], Step [385/735], Loss: 0.2358\n",
      "Epoch [25/50], Step [386/735], Loss: 0.1678\n",
      "Epoch [25/50], Step [387/735], Loss: 0.1961\n",
      "Epoch [25/50], Step [388/735], Loss: 0.1195\n",
      "Epoch [25/50], Step [389/735], Loss: 0.1430\n",
      "Epoch [25/50], Step [390/735], Loss: 0.0405\n",
      "Epoch [25/50], Step [391/735], Loss: 0.0859\n",
      "Epoch [25/50], Step [392/735], Loss: 0.2098\n",
      "Epoch [25/50], Step [393/735], Loss: 0.7954\n",
      "Epoch [25/50], Step [394/735], Loss: 0.0830\n",
      "Epoch [25/50], Step [395/735], Loss: 0.0923\n",
      "Epoch [25/50], Step [396/735], Loss: 0.1373\n",
      "Epoch [25/50], Step [397/735], Loss: 0.0834\n",
      "Epoch [25/50], Step [398/735], Loss: 0.1162\n",
      "Epoch [25/50], Step [399/735], Loss: 0.0899\n",
      "Epoch [25/50], Step [400/735], Loss: 0.7297\n",
      "Epoch [25/50], Step [401/735], Loss: 0.0825\n",
      "Epoch [25/50], Step [402/735], Loss: 0.1508\n",
      "Epoch [25/50], Step [403/735], Loss: 0.0901\n",
      "Epoch [25/50], Step [404/735], Loss: 0.1427\n",
      "Epoch [25/50], Step [405/735], Loss: 0.0917\n",
      "Epoch [25/50], Step [406/735], Loss: 0.1952\n",
      "Epoch [25/50], Step [407/735], Loss: 0.0849\n",
      "Epoch [25/50], Step [408/735], Loss: 0.1490\n",
      "Epoch [25/50], Step [409/735], Loss: 0.1307\n",
      "Epoch [25/50], Step [410/735], Loss: 0.0782\n",
      "Epoch [25/50], Step [411/735], Loss: 0.1716\n",
      "Epoch [25/50], Step [412/735], Loss: 0.3575\n",
      "Epoch [25/50], Step [413/735], Loss: 0.0772\n",
      "Epoch [25/50], Step [414/735], Loss: 0.1537\n",
      "Epoch [25/50], Step [415/735], Loss: 0.1738\n",
      "Epoch [25/50], Step [416/735], Loss: 0.1951\n",
      "Epoch [25/50], Step [417/735], Loss: 0.1546\n",
      "Epoch [25/50], Step [418/735], Loss: 0.2090\n",
      "Epoch [25/50], Step [419/735], Loss: 0.2283\n",
      "Epoch [25/50], Step [420/735], Loss: 0.1336\n",
      "Epoch [25/50], Step [421/735], Loss: 0.0802\n",
      "Epoch [25/50], Step [422/735], Loss: 0.0801\n",
      "Epoch [25/50], Step [423/735], Loss: 0.1518\n",
      "Epoch [25/50], Step [424/735], Loss: 0.0723\n",
      "Epoch [25/50], Step [425/735], Loss: 0.2192\n",
      "Epoch [25/50], Step [426/735], Loss: 0.1618\n",
      "Epoch [25/50], Step [427/735], Loss: 0.1827\n",
      "Epoch [25/50], Step [428/735], Loss: 0.0887\n",
      "Epoch [25/50], Step [429/735], Loss: 0.1770\n",
      "Epoch [25/50], Step [430/735], Loss: 0.8212\n",
      "Epoch [25/50], Step [431/735], Loss: 0.2445\n",
      "Epoch [25/50], Step [432/735], Loss: 0.1057\n",
      "Epoch [25/50], Step [433/735], Loss: 0.1937\n",
      "Epoch [25/50], Step [434/735], Loss: 0.0714\n",
      "Epoch [25/50], Step [435/735], Loss: 0.1085\n",
      "Epoch [25/50], Step [436/735], Loss: 0.0655\n",
      "Epoch [25/50], Step [437/735], Loss: 0.0689\n",
      "Epoch [25/50], Step [438/735], Loss: 0.6900\n",
      "Epoch [25/50], Step [439/735], Loss: 0.1219\n",
      "Epoch [25/50], Step [440/735], Loss: 0.0351\n",
      "Epoch [25/50], Step [441/735], Loss: 0.1782\n",
      "Epoch [25/50], Step [442/735], Loss: 0.1780\n",
      "Epoch [25/50], Step [443/735], Loss: 0.1721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Step [444/735], Loss: 0.6079\n",
      "Epoch [25/50], Step [445/735], Loss: 0.0618\n",
      "Epoch [25/50], Step [446/735], Loss: 0.1298\n",
      "Epoch [25/50], Step [447/735], Loss: 0.1673\n",
      "Epoch [25/50], Step [448/735], Loss: 1.6489\n",
      "Epoch [25/50], Step [449/735], Loss: 0.2100\n",
      "Epoch [25/50], Step [450/735], Loss: 0.0770\n",
      "Epoch [25/50], Step [451/735], Loss: 0.0561\n",
      "Epoch [25/50], Step [452/735], Loss: 0.0859\n",
      "Epoch [25/50], Step [453/735], Loss: 0.1791\n",
      "Epoch [25/50], Step [454/735], Loss: 0.3814\n",
      "Epoch [25/50], Step [455/735], Loss: 0.1282\n",
      "Epoch [25/50], Step [456/735], Loss: 0.3107\n",
      "Epoch [25/50], Step [457/735], Loss: 0.0614\n",
      "Epoch [25/50], Step [458/735], Loss: 0.0535\n",
      "Epoch [25/50], Step [459/735], Loss: 0.0793\n",
      "Epoch [25/50], Step [460/735], Loss: 0.2796\n",
      "Epoch [25/50], Step [461/735], Loss: 0.0846\n",
      "Epoch [25/50], Step [462/735], Loss: 0.7129\n",
      "Epoch [25/50], Step [463/735], Loss: 0.0633\n",
      "Epoch [25/50], Step [464/735], Loss: 0.0619\n",
      "Epoch [25/50], Step [465/735], Loss: 0.0860\n",
      "Epoch [25/50], Step [466/735], Loss: 0.0646\n",
      "Epoch [25/50], Step [467/735], Loss: 0.1473\n",
      "Epoch [25/50], Step [468/735], Loss: 0.1891\n",
      "Epoch [25/50], Step [469/735], Loss: 0.2467\n",
      "Epoch [25/50], Step [470/735], Loss: 0.2082\n",
      "Epoch [25/50], Step [471/735], Loss: 0.1895\n",
      "Epoch [25/50], Step [472/735], Loss: 0.1567\n",
      "Epoch [25/50], Step [473/735], Loss: 0.0811\n",
      "Epoch [25/50], Step [474/735], Loss: 0.0478\n",
      "Epoch [25/50], Step [475/735], Loss: 0.1780\n",
      "Epoch [25/50], Step [476/735], Loss: 0.1738\n",
      "Epoch [25/50], Step [477/735], Loss: 0.0672\n",
      "Epoch [25/50], Step [478/735], Loss: 0.0555\n",
      "Epoch [25/50], Step [479/735], Loss: 0.0873\n",
      "Epoch [25/50], Step [480/735], Loss: 0.1906\n",
      "Epoch [25/50], Step [481/735], Loss: 0.1859\n",
      "Epoch [25/50], Step [482/735], Loss: 0.1375\n",
      "Epoch [25/50], Step [483/735], Loss: 0.1750\n",
      "Epoch [25/50], Step [484/735], Loss: 0.0618\n",
      "Epoch [25/50], Step [485/735], Loss: 0.1534\n",
      "Epoch [25/50], Step [486/735], Loss: 0.0447\n",
      "Epoch [25/50], Step [487/735], Loss: 0.1143\n",
      "Epoch [25/50], Step [488/735], Loss: 0.1322\n",
      "Epoch [25/50], Step [489/735], Loss: 0.2876\n",
      "Epoch [25/50], Step [490/735], Loss: 0.0844\n",
      "Epoch [25/50], Step [491/735], Loss: 0.1059\n",
      "Epoch [25/50], Step [492/735], Loss: 0.0552\n",
      "Epoch [25/50], Step [493/735], Loss: 0.0866\n",
      "Epoch [25/50], Step [494/735], Loss: 0.1442\n",
      "Epoch [25/50], Step [495/735], Loss: 0.2282\n",
      "Epoch [25/50], Step [496/735], Loss: 0.1119\n",
      "Epoch [25/50], Step [497/735], Loss: 1.3111\n",
      "Epoch [25/50], Step [498/735], Loss: 0.0385\n",
      "Epoch [25/50], Step [499/735], Loss: 0.2330\n",
      "Epoch [25/50], Step [500/735], Loss: 0.0490\n",
      "Epoch [25/50], Step [501/735], Loss: 0.0888\n",
      "Epoch [25/50], Step [502/735], Loss: 0.2322\n",
      "Epoch [25/50], Step [503/735], Loss: 0.3112\n",
      "Epoch [25/50], Step [504/735], Loss: 0.1346\n",
      "Epoch [25/50], Step [505/735], Loss: 0.0812\n",
      "Epoch [25/50], Step [506/735], Loss: 0.4630\n",
      "Epoch [25/50], Step [507/735], Loss: 0.0395\n",
      "Epoch [25/50], Step [508/735], Loss: 0.8190\n",
      "Epoch [25/50], Step [509/735], Loss: 0.0864\n",
      "Epoch [25/50], Step [510/735], Loss: 1.3714\n",
      "Epoch [25/50], Step [511/735], Loss: 0.1036\n",
      "Epoch [25/50], Step [512/735], Loss: 0.1092\n",
      "Epoch [25/50], Step [513/735], Loss: 0.0746\n",
      "Epoch [25/50], Step [514/735], Loss: 0.1294\n",
      "Epoch [25/50], Step [515/735], Loss: 0.1203\n",
      "Epoch [25/50], Step [516/735], Loss: 0.1867\n",
      "Epoch [25/50], Step [517/735], Loss: 0.0919\n",
      "Epoch [25/50], Step [518/735], Loss: 0.0960\n",
      "Epoch [25/50], Step [519/735], Loss: 0.2081\n",
      "Epoch [25/50], Step [520/735], Loss: 0.0326\n",
      "Epoch [25/50], Step [521/735], Loss: 0.2264\n",
      "Epoch [25/50], Step [522/735], Loss: 0.3034\n",
      "Epoch [25/50], Step [523/735], Loss: 0.1789\n",
      "Epoch [25/50], Step [524/735], Loss: 0.3953\n",
      "Epoch [25/50], Step [525/735], Loss: 0.0570\n",
      "Epoch [25/50], Step [526/735], Loss: 0.2722\n",
      "Epoch [25/50], Step [527/735], Loss: 0.1315\n",
      "Epoch [25/50], Step [528/735], Loss: 0.1947\n",
      "Epoch [25/50], Step [529/735], Loss: 0.0692\n",
      "Epoch [25/50], Step [530/735], Loss: 0.0555\n",
      "Epoch [25/50], Step [531/735], Loss: 0.1243\n",
      "Epoch [25/50], Step [532/735], Loss: 0.0324\n",
      "Epoch [25/50], Step [533/735], Loss: 0.1086\n",
      "Epoch [25/50], Step [534/735], Loss: 0.2616\n",
      "Epoch [25/50], Step [535/735], Loss: 0.2469\n",
      "Epoch [25/50], Step [536/735], Loss: 0.1217\n",
      "Epoch [25/50], Step [537/735], Loss: 0.0307\n",
      "Epoch [25/50], Step [538/735], Loss: 0.1111\n",
      "Epoch [25/50], Step [539/735], Loss: 0.1406\n",
      "Epoch [25/50], Step [540/735], Loss: 0.1873\n",
      "Epoch [25/50], Step [541/735], Loss: 0.0833\n",
      "Epoch [25/50], Step [542/735], Loss: 0.8758\n",
      "Epoch [25/50], Step [543/735], Loss: 0.0342\n",
      "Epoch [25/50], Step [544/735], Loss: 0.3632\n",
      "Epoch [25/50], Step [545/735], Loss: 0.3017\n",
      "Epoch [25/50], Step [546/735], Loss: 0.1376\n",
      "Epoch [25/50], Step [547/735], Loss: 0.1146\n",
      "Epoch [25/50], Step [548/735], Loss: 0.0814\n",
      "Epoch [25/50], Step [549/735], Loss: 0.3898\n",
      "Epoch [25/50], Step [550/735], Loss: 0.1422\n",
      "Epoch [25/50], Step [551/735], Loss: 0.0613\n",
      "Epoch [25/50], Step [552/735], Loss: 0.2721\n",
      "Epoch [25/50], Step [553/735], Loss: 0.0771\n",
      "Epoch [25/50], Step [554/735], Loss: 0.6460\n",
      "Epoch [25/50], Step [555/735], Loss: 0.1129\n",
      "Epoch [25/50], Step [556/735], Loss: 0.1245\n",
      "Epoch [25/50], Step [557/735], Loss: 0.2331\n",
      "Epoch [25/50], Step [558/735], Loss: 0.0441\n",
      "Epoch [25/50], Step [559/735], Loss: 0.3396\n",
      "Epoch [25/50], Step [560/735], Loss: 0.1433\n",
      "Epoch [25/50], Step [561/735], Loss: 0.0448\n",
      "Epoch [25/50], Step [562/735], Loss: 0.1829\n",
      "Epoch [25/50], Step [563/735], Loss: 0.1417\n",
      "Epoch [25/50], Step [564/735], Loss: 0.1834\n",
      "Epoch [25/50], Step [565/735], Loss: 0.0738\n",
      "Epoch [25/50], Step [566/735], Loss: 0.0864\n",
      "Epoch [25/50], Step [567/735], Loss: 0.1978\n",
      "Epoch [25/50], Step [568/735], Loss: 0.1505\n",
      "Epoch [25/50], Step [569/735], Loss: 0.3555\n",
      "Epoch [25/50], Step [570/735], Loss: 0.1132\n",
      "Epoch [25/50], Step [571/735], Loss: 0.0879\n",
      "Epoch [25/50], Step [572/735], Loss: 0.0825\n",
      "Epoch [25/50], Step [573/735], Loss: 0.4162\n",
      "Epoch [25/50], Step [574/735], Loss: 0.1887\n",
      "Epoch [25/50], Step [575/735], Loss: 0.1120\n",
      "Epoch [25/50], Step [576/735], Loss: 0.0809\n",
      "Epoch [25/50], Step [577/735], Loss: 0.0836\n",
      "Epoch [25/50], Step [578/735], Loss: 0.0970\n",
      "Epoch [25/50], Step [579/735], Loss: 0.0526\n",
      "Epoch [25/50], Step [580/735], Loss: 0.1630\n",
      "Epoch [25/50], Step [581/735], Loss: 0.1650\n",
      "Epoch [25/50], Step [582/735], Loss: 0.1126\n",
      "Epoch [25/50], Step [583/735], Loss: 0.0551\n",
      "Epoch [25/50], Step [584/735], Loss: 0.0456\n",
      "Epoch [25/50], Step [585/735], Loss: 0.1463\n",
      "Epoch [25/50], Step [586/735], Loss: 0.2217\n",
      "Epoch [25/50], Step [587/735], Loss: 0.0469\n",
      "Epoch [25/50], Step [588/735], Loss: 0.1603\n",
      "Epoch [25/50], Step [589/735], Loss: 0.1388\n",
      "Epoch [25/50], Step [590/735], Loss: 0.1556\n",
      "Epoch [25/50], Step [591/735], Loss: 0.2496\n",
      "Epoch [25/50], Step [592/735], Loss: 0.0609\n",
      "Epoch [25/50], Step [593/735], Loss: 0.1295\n",
      "Epoch [25/50], Step [594/735], Loss: 0.1012\n",
      "Epoch [25/50], Step [595/735], Loss: 0.1658\n",
      "Epoch [25/50], Step [596/735], Loss: 0.5394\n",
      "Epoch [25/50], Step [597/735], Loss: 0.0761\n",
      "Epoch [25/50], Step [598/735], Loss: 0.1968\n",
      "Epoch [25/50], Step [599/735], Loss: 0.0613\n",
      "Epoch [25/50], Step [600/735], Loss: 0.1432\n",
      "Epoch [25/50], Step [601/735], Loss: 0.1804\n",
      "Epoch [25/50], Step [602/735], Loss: 0.3357\n",
      "Epoch [25/50], Step [603/735], Loss: 0.2321\n",
      "Epoch [25/50], Step [604/735], Loss: 0.0882\n",
      "Epoch [25/50], Step [605/735], Loss: 0.1767\n",
      "Epoch [25/50], Step [606/735], Loss: 0.1085\n",
      "Epoch [25/50], Step [607/735], Loss: 0.1513\n",
      "Epoch [25/50], Step [608/735], Loss: 0.1124\n",
      "Epoch [25/50], Step [609/735], Loss: 0.0715\n",
      "Epoch [25/50], Step [610/735], Loss: 0.1107\n",
      "Epoch [25/50], Step [611/735], Loss: 0.0334\n",
      "Epoch [25/50], Step [612/735], Loss: 0.1295\n",
      "Epoch [25/50], Step [613/735], Loss: 0.1071\n",
      "Epoch [25/50], Step [614/735], Loss: 0.0571\n",
      "Epoch [25/50], Step [615/735], Loss: 0.0356\n",
      "Epoch [25/50], Step [616/735], Loss: 0.9920\n",
      "Epoch [25/50], Step [617/735], Loss: 0.0500\n",
      "Epoch [25/50], Step [618/735], Loss: 0.1693\n",
      "Epoch [25/50], Step [619/735], Loss: 0.1036\n",
      "Epoch [25/50], Step [620/735], Loss: 0.0485\n",
      "Epoch [25/50], Step [621/735], Loss: 0.0338\n",
      "Epoch [25/50], Step [622/735], Loss: 0.5782\n",
      "Epoch [25/50], Step [623/735], Loss: 0.0379\n",
      "Epoch [25/50], Step [624/735], Loss: 0.1633\n",
      "Epoch [25/50], Step [625/735], Loss: 0.0811\n",
      "Epoch [25/50], Step [626/735], Loss: 0.0942\n",
      "Epoch [25/50], Step [627/735], Loss: 0.1722\n",
      "Epoch [25/50], Step [628/735], Loss: 0.2060\n",
      "Epoch [25/50], Step [629/735], Loss: 0.1379\n",
      "Epoch [25/50], Step [630/735], Loss: 0.2386\n",
      "Epoch [25/50], Step [631/735], Loss: 0.0692\n",
      "Epoch [25/50], Step [632/735], Loss: 0.0526\n",
      "Epoch [25/50], Step [633/735], Loss: 0.1893\n",
      "Epoch [25/50], Step [634/735], Loss: 0.0504\n",
      "Epoch [25/50], Step [635/735], Loss: 0.1557\n",
      "Epoch [25/50], Step [636/735], Loss: 0.0631\n",
      "Epoch [25/50], Step [637/735], Loss: 0.0907\n",
      "Epoch [25/50], Step [638/735], Loss: 0.1143\n",
      "Epoch [25/50], Step [639/735], Loss: 0.2901\n",
      "Epoch [25/50], Step [640/735], Loss: 0.1362\n",
      "Epoch [25/50], Step [641/735], Loss: 0.2014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Step [642/735], Loss: 0.6819\n",
      "Epoch [25/50], Step [643/735], Loss: 0.0386\n",
      "Epoch [25/50], Step [644/735], Loss: 0.1805\n",
      "Epoch [25/50], Step [645/735], Loss: 1.4543\n",
      "Epoch [25/50], Step [646/735], Loss: 0.0806\n",
      "Epoch [25/50], Step [647/735], Loss: 0.1188\n",
      "Epoch [25/50], Step [648/735], Loss: 0.1808\n",
      "Epoch [25/50], Step [649/735], Loss: 0.1795\n",
      "Epoch [25/50], Step [650/735], Loss: 0.1591\n",
      "Epoch [25/50], Step [651/735], Loss: 0.2443\n",
      "Epoch [25/50], Step [652/735], Loss: 0.7156\n",
      "Epoch [25/50], Step [653/735], Loss: 0.1041\n",
      "Epoch [25/50], Step [654/735], Loss: 0.0746\n",
      "Epoch [25/50], Step [655/735], Loss: 0.0576\n",
      "Epoch [25/50], Step [656/735], Loss: 0.0585\n",
      "Epoch [25/50], Step [657/735], Loss: 0.0809\n",
      "Epoch [25/50], Step [658/735], Loss: 0.1273\n",
      "Epoch [25/50], Step [659/735], Loss: 0.0792\n",
      "Epoch [25/50], Step [660/735], Loss: 0.1493\n",
      "Epoch [25/50], Step [661/735], Loss: 0.1093\n",
      "Epoch [25/50], Step [662/735], Loss: 0.1524\n",
      "Epoch [25/50], Step [663/735], Loss: 0.0594\n",
      "Epoch [25/50], Step [664/735], Loss: 0.0667\n",
      "Epoch [25/50], Step [665/735], Loss: 0.1580\n",
      "Epoch [25/50], Step [666/735], Loss: 0.1564\n",
      "Epoch [25/50], Step [667/735], Loss: 0.0704\n",
      "Epoch [25/50], Step [668/735], Loss: 0.1340\n",
      "Epoch [25/50], Step [669/735], Loss: 0.1228\n",
      "Epoch [25/50], Step [670/735], Loss: 0.1104\n",
      "Epoch [25/50], Step [671/735], Loss: 0.1218\n",
      "Epoch [25/50], Step [672/735], Loss: 0.2070\n",
      "Epoch [25/50], Step [673/735], Loss: 0.0562\n",
      "Epoch [25/50], Step [674/735], Loss: 0.0485\n",
      "Epoch [25/50], Step [675/735], Loss: 0.1096\n",
      "Epoch [25/50], Step [676/735], Loss: 0.0801\n",
      "Epoch [25/50], Step [677/735], Loss: 0.0576\n",
      "Epoch [25/50], Step [678/735], Loss: 0.0473\n",
      "Epoch [25/50], Step [679/735], Loss: 0.0686\n",
      "Epoch [25/50], Step [680/735], Loss: 0.1867\n",
      "Epoch [25/50], Step [681/735], Loss: 0.1320\n",
      "Epoch [25/50], Step [682/735], Loss: 0.1212\n",
      "Epoch [25/50], Step [683/735], Loss: 0.1165\n",
      "Epoch [25/50], Step [684/735], Loss: 0.0459\n",
      "Epoch [25/50], Step [685/735], Loss: 0.1107\n",
      "Epoch [25/50], Step [686/735], Loss: 0.1252\n",
      "Epoch [25/50], Step [687/735], Loss: 0.0879\n",
      "Epoch [25/50], Step [688/735], Loss: 0.1717\n",
      "Epoch [25/50], Step [689/735], Loss: 0.1133\n",
      "Epoch [25/50], Step [690/735], Loss: 0.1304\n",
      "Epoch [25/50], Step [691/735], Loss: 0.1550\n",
      "Epoch [25/50], Step [692/735], Loss: 0.0933\n",
      "Epoch [25/50], Step [693/735], Loss: 0.1035\n",
      "Epoch [25/50], Step [694/735], Loss: 0.2010\n",
      "Epoch [25/50], Step [695/735], Loss: 0.0810\n",
      "Epoch [25/50], Step [696/735], Loss: 0.1456\n",
      "Epoch [25/50], Step [697/735], Loss: 0.2031\n",
      "Epoch [25/50], Step [698/735], Loss: 0.1027\n",
      "Epoch [25/50], Step [699/735], Loss: 0.0955\n",
      "Epoch [25/50], Step [700/735], Loss: 0.0616\n",
      "Epoch [25/50], Step [701/735], Loss: 0.5151\n",
      "Epoch [25/50], Step [702/735], Loss: 0.0653\n",
      "Epoch [25/50], Step [703/735], Loss: 0.0808\n",
      "Epoch [25/50], Step [704/735], Loss: 0.1318\n",
      "Epoch [25/50], Step [705/735], Loss: 0.2517\n",
      "Epoch [25/50], Step [706/735], Loss: 0.1769\n",
      "Epoch [25/50], Step [707/735], Loss: 0.0799\n",
      "Epoch [25/50], Step [708/735], Loss: 2.8780\n",
      "Epoch [25/50], Step [709/735], Loss: 0.2073\n",
      "Epoch [25/50], Step [710/735], Loss: 0.0876\n",
      "Epoch [25/50], Step [711/735], Loss: 0.1271\n",
      "Epoch [25/50], Step [712/735], Loss: 0.2526\n",
      "Epoch [25/50], Step [713/735], Loss: 0.1165\n",
      "Epoch [25/50], Step [714/735], Loss: 0.5713\n",
      "Epoch [25/50], Step [715/735], Loss: 0.1156\n",
      "Epoch [25/50], Step [716/735], Loss: 0.1237\n",
      "Epoch [25/50], Step [717/735], Loss: 0.3412\n",
      "Epoch [25/50], Step [718/735], Loss: 0.2084\n",
      "Epoch [25/50], Step [719/735], Loss: 0.1438\n",
      "Epoch [25/50], Step [720/735], Loss: 0.0675\n",
      "Epoch [25/50], Step [721/735], Loss: 0.1104\n",
      "Epoch [25/50], Step [722/735], Loss: 0.0606\n",
      "Epoch [25/50], Step [723/735], Loss: 0.8334\n",
      "Epoch [25/50], Step [724/735], Loss: 0.1884\n",
      "Epoch [25/50], Step [725/735], Loss: 0.0914\n",
      "Epoch [25/50], Step [726/735], Loss: 0.2356\n",
      "Epoch [25/50], Step [727/735], Loss: 0.0752\n",
      "Epoch [25/50], Step [728/735], Loss: 2.4393\n",
      "Epoch [25/50], Step [729/735], Loss: 0.1839\n",
      "Epoch [25/50], Step [730/735], Loss: 0.0551\n",
      "Epoch [25/50], Step [731/735], Loss: 0.0928\n",
      "Epoch [25/50], Step [732/735], Loss: 0.0976\n",
      "Epoch [25/50], Step [733/735], Loss: 0.1384\n",
      "Epoch [25/50], Step [734/735], Loss: 0.1107\n",
      "Epoch [25/50], Step [735/735], Loss: 0.2361\n",
      "Epoch [26/50], Step [1/735], Loss: 0.2349\n",
      "Epoch [26/50], Step [2/735], Loss: 0.2034\n",
      "Epoch [26/50], Step [3/735], Loss: 0.0894\n",
      "Epoch [26/50], Step [4/735], Loss: 0.2736\n",
      "Epoch [26/50], Step [5/735], Loss: 0.1103\n",
      "Epoch [26/50], Step [6/735], Loss: 0.1539\n",
      "Epoch [26/50], Step [7/735], Loss: 0.0540\n",
      "Epoch [26/50], Step [8/735], Loss: 0.2598\n",
      "Epoch [26/50], Step [9/735], Loss: 0.0861\n",
      "Epoch [26/50], Step [10/735], Loss: 0.1891\n",
      "Epoch [26/50], Step [11/735], Loss: 0.0585\n",
      "Epoch [26/50], Step [12/735], Loss: 0.1664\n",
      "Epoch [26/50], Step [13/735], Loss: 0.2066\n",
      "Epoch [26/50], Step [14/735], Loss: 0.0947\n",
      "Epoch [26/50], Step [15/735], Loss: 0.0453\n",
      "Epoch [26/50], Step [16/735], Loss: 0.0583\n",
      "Epoch [26/50], Step [17/735], Loss: 0.0563\n",
      "Epoch [26/50], Step [18/735], Loss: 0.2576\n",
      "Epoch [26/50], Step [19/735], Loss: 0.1057\n",
      "Epoch [26/50], Step [20/735], Loss: 0.0335\n",
      "Epoch [26/50], Step [21/735], Loss: 0.0485\n",
      "Epoch [26/50], Step [22/735], Loss: 0.2067\n",
      "Epoch [26/50], Step [23/735], Loss: 0.1175\n",
      "Epoch [26/50], Step [24/735], Loss: 0.0584\n",
      "Epoch [26/50], Step [25/735], Loss: 0.1100\n",
      "Epoch [26/50], Step [26/735], Loss: 0.5902\n",
      "Epoch [26/50], Step [27/735], Loss: 0.0978\n",
      "Epoch [26/50], Step [28/735], Loss: 0.0746\n",
      "Epoch [26/50], Step [29/735], Loss: 0.1107\n",
      "Epoch [26/50], Step [30/735], Loss: 0.2489\n",
      "Epoch [26/50], Step [31/735], Loss: 0.0567\n",
      "Epoch [26/50], Step [32/735], Loss: 0.0652\n",
      "Epoch [26/50], Step [33/735], Loss: 0.2075\n",
      "Epoch [26/50], Step [34/735], Loss: 0.0614\n",
      "Epoch [26/50], Step [35/735], Loss: 0.1739\n",
      "Epoch [26/50], Step [36/735], Loss: 0.0342\n",
      "Epoch [26/50], Step [37/735], Loss: 0.1102\n",
      "Epoch [26/50], Step [38/735], Loss: 0.0673\n",
      "Epoch [26/50], Step [39/735], Loss: 0.7531\n",
      "Epoch [26/50], Step [40/735], Loss: 0.1227\n",
      "Epoch [26/50], Step [41/735], Loss: 0.1978\n",
      "Epoch [26/50], Step [42/735], Loss: 0.0663\n",
      "Epoch [26/50], Step [43/735], Loss: 0.2118\n",
      "Epoch [26/50], Step [44/735], Loss: 0.0895\n",
      "Epoch [26/50], Step [45/735], Loss: 0.1602\n",
      "Epoch [26/50], Step [46/735], Loss: 0.0605\n",
      "Epoch [26/50], Step [47/735], Loss: 0.1658\n",
      "Epoch [26/50], Step [48/735], Loss: 0.4356\n",
      "Epoch [26/50], Step [49/735], Loss: 0.1679\n",
      "Epoch [26/50], Step [50/735], Loss: 0.1088\n",
      "Epoch [26/50], Step [51/735], Loss: 0.0733\n",
      "Epoch [26/50], Step [52/735], Loss: 0.0485\n",
      "Epoch [26/50], Step [53/735], Loss: 0.1100\n",
      "Epoch [26/50], Step [54/735], Loss: 0.0584\n",
      "Epoch [26/50], Step [55/735], Loss: 0.1293\n",
      "Epoch [26/50], Step [56/735], Loss: 0.1016\n",
      "Epoch [26/50], Step [57/735], Loss: 0.1562\n",
      "Epoch [26/50], Step [58/735], Loss: 0.0648\n",
      "Epoch [26/50], Step [59/735], Loss: 0.7845\n",
      "Epoch [26/50], Step [60/735], Loss: 0.6680\n",
      "Epoch [26/50], Step [61/735], Loss: 0.4234\n",
      "Epoch [26/50], Step [62/735], Loss: 0.1521\n",
      "Epoch [26/50], Step [63/735], Loss: 0.2384\n",
      "Epoch [26/50], Step [64/735], Loss: 0.1314\n",
      "Epoch [26/50], Step [65/735], Loss: 0.1272\n",
      "Epoch [26/50], Step [66/735], Loss: 0.1000\n",
      "Epoch [26/50], Step [67/735], Loss: 0.1415\n",
      "Epoch [26/50], Step [68/735], Loss: 0.2069\n",
      "Epoch [26/50], Step [69/735], Loss: 0.0960\n",
      "Epoch [26/50], Step [70/735], Loss: 0.1639\n",
      "Epoch [26/50], Step [71/735], Loss: 0.1187\n",
      "Epoch [26/50], Step [72/735], Loss: 0.2555\n",
      "Epoch [26/50], Step [73/735], Loss: 0.0873\n",
      "Epoch [26/50], Step [74/735], Loss: 0.0626\n",
      "Epoch [26/50], Step [75/735], Loss: 0.0392\n",
      "Epoch [26/50], Step [76/735], Loss: 0.0952\n",
      "Epoch [26/50], Step [77/735], Loss: 0.2209\n",
      "Epoch [26/50], Step [78/735], Loss: 0.1424\n",
      "Epoch [26/50], Step [79/735], Loss: 0.0313\n",
      "Epoch [26/50], Step [80/735], Loss: 0.4601\n",
      "Epoch [26/50], Step [81/735], Loss: 0.0756\n",
      "Epoch [26/50], Step [82/735], Loss: 0.7366\n",
      "Epoch [26/50], Step [83/735], Loss: 0.0727\n",
      "Epoch [26/50], Step [84/735], Loss: 0.1312\n",
      "Epoch [26/50], Step [85/735], Loss: 0.0823\n",
      "Epoch [26/50], Step [86/735], Loss: 0.0507\n",
      "Epoch [26/50], Step [87/735], Loss: 0.0665\n",
      "Epoch [26/50], Step [88/735], Loss: 0.0884\n",
      "Epoch [26/50], Step [89/735], Loss: 0.2047\n",
      "Epoch [26/50], Step [90/735], Loss: 0.2129\n",
      "Epoch [26/50], Step [91/735], Loss: 0.1016\n",
      "Epoch [26/50], Step [92/735], Loss: 0.0578\n",
      "Epoch [26/50], Step [93/735], Loss: 0.1457\n",
      "Epoch [26/50], Step [94/735], Loss: 0.0990\n",
      "Epoch [26/50], Step [95/735], Loss: 0.1493\n",
      "Epoch [26/50], Step [96/735], Loss: 0.1114\n",
      "Epoch [26/50], Step [97/735], Loss: 0.0854\n",
      "Epoch [26/50], Step [98/735], Loss: 0.1684\n",
      "Epoch [26/50], Step [99/735], Loss: 0.2416\n",
      "Epoch [26/50], Step [100/735], Loss: 0.1918\n",
      "Epoch [26/50], Step [101/735], Loss: 0.0646\n",
      "Epoch [26/50], Step [102/735], Loss: 0.0745\n",
      "Epoch [26/50], Step [103/735], Loss: 0.0864\n",
      "Epoch [26/50], Step [104/735], Loss: 0.1605\n",
      "Epoch [26/50], Step [105/735], Loss: 0.1023\n",
      "Epoch [26/50], Step [106/735], Loss: 0.0610\n",
      "Epoch [26/50], Step [107/735], Loss: 0.1362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Step [108/735], Loss: 0.0605\n",
      "Epoch [26/50], Step [109/735], Loss: 0.2428\n",
      "Epoch [26/50], Step [110/735], Loss: 0.0556\n",
      "Epoch [26/50], Step [111/735], Loss: 0.2127\n",
      "Epoch [26/50], Step [112/735], Loss: 0.1989\n",
      "Epoch [26/50], Step [113/735], Loss: 0.3460\n",
      "Epoch [26/50], Step [114/735], Loss: 0.0962\n",
      "Epoch [26/50], Step [115/735], Loss: 0.1516\n",
      "Epoch [26/50], Step [116/735], Loss: 0.0411\n",
      "Epoch [26/50], Step [117/735], Loss: 0.0702\n",
      "Epoch [26/50], Step [118/735], Loss: 0.2272\n",
      "Epoch [26/50], Step [119/735], Loss: 0.1374\n",
      "Epoch [26/50], Step [120/735], Loss: 0.2616\n",
      "Epoch [26/50], Step [121/735], Loss: 0.0992\n",
      "Epoch [26/50], Step [122/735], Loss: 0.0595\n",
      "Epoch [26/50], Step [123/735], Loss: 0.0575\n",
      "Epoch [26/50], Step [124/735], Loss: 0.0945\n",
      "Epoch [26/50], Step [125/735], Loss: 0.1562\n",
      "Epoch [26/50], Step [126/735], Loss: 0.0506\n",
      "Epoch [26/50], Step [127/735], Loss: 0.0348\n",
      "Epoch [26/50], Step [128/735], Loss: 0.0957\n",
      "Epoch [26/50], Step [129/735], Loss: 0.6261\n",
      "Epoch [26/50], Step [130/735], Loss: 0.0720\n",
      "Epoch [26/50], Step [131/735], Loss: 0.2911\n",
      "Epoch [26/50], Step [132/735], Loss: 0.0847\n",
      "Epoch [26/50], Step [133/735], Loss: 0.1671\n",
      "Epoch [26/50], Step [134/735], Loss: 0.1239\n",
      "Epoch [26/50], Step [135/735], Loss: 0.1722\n",
      "Epoch [26/50], Step [136/735], Loss: 0.0750\n",
      "Epoch [26/50], Step [137/735], Loss: 0.1604\n",
      "Epoch [26/50], Step [138/735], Loss: 0.1992\n",
      "Epoch [26/50], Step [139/735], Loss: 0.0385\n",
      "Epoch [26/50], Step [140/735], Loss: 0.0775\n",
      "Epoch [26/50], Step [141/735], Loss: 0.2429\n",
      "Epoch [26/50], Step [142/735], Loss: 0.0981\n",
      "Epoch [26/50], Step [143/735], Loss: 0.1546\n",
      "Epoch [26/50], Step [144/735], Loss: 0.0556\n",
      "Epoch [26/50], Step [145/735], Loss: 0.0802\n",
      "Epoch [26/50], Step [146/735], Loss: 0.6707\n",
      "Epoch [26/50], Step [147/735], Loss: 0.1162\n",
      "Epoch [26/50], Step [148/735], Loss: 0.1349\n",
      "Epoch [26/50], Step [149/735], Loss: 0.1672\n",
      "Epoch [26/50], Step [150/735], Loss: 0.0899\n",
      "Epoch [26/50], Step [151/735], Loss: 0.1304\n",
      "Epoch [26/50], Step [152/735], Loss: 2.4507\n",
      "Epoch [26/50], Step [153/735], Loss: 0.2384\n",
      "Epoch [26/50], Step [154/735], Loss: 0.0741\n",
      "Epoch [26/50], Step [155/735], Loss: 0.1840\n",
      "Epoch [26/50], Step [156/735], Loss: 0.1921\n",
      "Epoch [26/50], Step [157/735], Loss: 0.0729\n",
      "Epoch [26/50], Step [158/735], Loss: 0.1342\n",
      "Epoch [26/50], Step [159/735], Loss: 2.2911\n",
      "Epoch [26/50], Step [160/735], Loss: 0.1686\n",
      "Epoch [26/50], Step [161/735], Loss: 0.0788\n",
      "Epoch [26/50], Step [162/735], Loss: 0.1273\n",
      "Epoch [26/50], Step [163/735], Loss: 0.0717\n",
      "Epoch [26/50], Step [164/735], Loss: 0.1175\n",
      "Epoch [26/50], Step [165/735], Loss: 0.2467\n",
      "Epoch [26/50], Step [166/735], Loss: 0.1317\n",
      "Epoch [26/50], Step [167/735], Loss: 0.0495\n",
      "Epoch [26/50], Step [168/735], Loss: 0.0355\n",
      "Epoch [26/50], Step [169/735], Loss: 0.1396\n",
      "Epoch [26/50], Step [170/735], Loss: 0.1261\n",
      "Epoch [26/50], Step [171/735], Loss: 0.0879\n",
      "Epoch [26/50], Step [172/735], Loss: 0.5196\n",
      "Epoch [26/50], Step [173/735], Loss: 0.0573\n",
      "Epoch [26/50], Step [174/735], Loss: 0.0590\n",
      "Epoch [26/50], Step [175/735], Loss: 0.0949\n",
      "Epoch [26/50], Step [176/735], Loss: 0.1232\n",
      "Epoch [26/50], Step [177/735], Loss: 0.3037\n",
      "Epoch [26/50], Step [178/735], Loss: 0.0397\n",
      "Epoch [26/50], Step [179/735], Loss: 0.0816\n",
      "Epoch [26/50], Step [180/735], Loss: 0.1760\n",
      "Epoch [26/50], Step [181/735], Loss: 0.0888\n",
      "Epoch [26/50], Step [182/735], Loss: 0.1091\n",
      "Epoch [26/50], Step [183/735], Loss: 0.1019\n",
      "Epoch [26/50], Step [184/735], Loss: 0.1622\n",
      "Epoch [26/50], Step [185/735], Loss: 0.1059\n",
      "Epoch [26/50], Step [186/735], Loss: 0.0581\n",
      "Epoch [26/50], Step [187/735], Loss: 0.0603\n",
      "Epoch [26/50], Step [188/735], Loss: 0.0714\n",
      "Epoch [26/50], Step [189/735], Loss: 0.2237\n",
      "Epoch [26/50], Step [190/735], Loss: 0.0807\n",
      "Epoch [26/50], Step [191/735], Loss: 0.1497\n",
      "Epoch [26/50], Step [192/735], Loss: 0.3183\n",
      "Epoch [26/50], Step [193/735], Loss: 0.0582\n",
      "Epoch [26/50], Step [194/735], Loss: 0.1051\n",
      "Epoch [26/50], Step [195/735], Loss: 0.1562\n",
      "Epoch [26/50], Step [196/735], Loss: 0.1740\n",
      "Epoch [26/50], Step [197/735], Loss: 0.0861\n",
      "Epoch [26/50], Step [198/735], Loss: 0.0386\n",
      "Epoch [26/50], Step [199/735], Loss: 1.8458\n",
      "Epoch [26/50], Step [200/735], Loss: 0.2392\n",
      "Epoch [26/50], Step [201/735], Loss: 0.1123\n",
      "Epoch [26/50], Step [202/735], Loss: 0.1151\n",
      "Epoch [26/50], Step [203/735], Loss: 0.3852\n",
      "Epoch [26/50], Step [204/735], Loss: 0.1180\n",
      "Epoch [26/50], Step [205/735], Loss: 0.1022\n",
      "Epoch [26/50], Step [206/735], Loss: 0.2271\n",
      "Epoch [26/50], Step [207/735], Loss: 0.0625\n",
      "Epoch [26/50], Step [208/735], Loss: 0.2270\n",
      "Epoch [26/50], Step [209/735], Loss: 0.5975\n",
      "Epoch [26/50], Step [210/735], Loss: 0.8511\n",
      "Epoch [26/50], Step [211/735], Loss: 0.1681\n",
      "Epoch [26/50], Step [212/735], Loss: 0.1754\n",
      "Epoch [26/50], Step [213/735], Loss: 0.2381\n",
      "Epoch [26/50], Step [214/735], Loss: 0.2150\n",
      "Epoch [26/50], Step [215/735], Loss: 0.8334\n",
      "Epoch [26/50], Step [216/735], Loss: 0.2361\n",
      "Epoch [26/50], Step [217/735], Loss: 0.1326\n",
      "Epoch [26/50], Step [218/735], Loss: 0.5953\n",
      "Epoch [26/50], Step [219/735], Loss: 0.1233\n",
      "Epoch [26/50], Step [220/735], Loss: 0.1749\n",
      "Epoch [26/50], Step [221/735], Loss: 0.1099\n",
      "Epoch [26/50], Step [222/735], Loss: 0.1087\n",
      "Epoch [26/50], Step [223/735], Loss: 0.0893\n",
      "Epoch [26/50], Step [224/735], Loss: 0.0696\n",
      "Epoch [26/50], Step [225/735], Loss: 0.1823\n",
      "Epoch [26/50], Step [226/735], Loss: 0.0865\n",
      "Epoch [26/50], Step [227/735], Loss: 0.2170\n",
      "Epoch [26/50], Step [228/735], Loss: 0.2619\n",
      "Epoch [26/50], Step [229/735], Loss: 0.0416\n",
      "Epoch [26/50], Step [230/735], Loss: 0.1597\n",
      "Epoch [26/50], Step [231/735], Loss: 0.0426\n",
      "Epoch [26/50], Step [232/735], Loss: 0.1579\n",
      "Epoch [26/50], Step [233/735], Loss: 0.0959\n",
      "Epoch [26/50], Step [234/735], Loss: 0.3630\n",
      "Epoch [26/50], Step [235/735], Loss: 0.0797\n",
      "Epoch [26/50], Step [236/735], Loss: 0.1989\n",
      "Epoch [26/50], Step [237/735], Loss: 0.0967\n",
      "Epoch [26/50], Step [238/735], Loss: 0.0869\n",
      "Epoch [26/50], Step [239/735], Loss: 0.2798\n",
      "Epoch [26/50], Step [240/735], Loss: 0.7554\n",
      "Epoch [26/50], Step [241/735], Loss: 0.1343\n",
      "Epoch [26/50], Step [242/735], Loss: 0.1204\n",
      "Epoch [26/50], Step [243/735], Loss: 0.1411\n",
      "Epoch [26/50], Step [244/735], Loss: 0.1446\n",
      "Epoch [26/50], Step [245/735], Loss: 0.1436\n",
      "Epoch [26/50], Step [246/735], Loss: 0.1068\n",
      "Epoch [26/50], Step [247/735], Loss: 0.1990\n",
      "Epoch [26/50], Step [248/735], Loss: 0.0668\n",
      "Epoch [26/50], Step [249/735], Loss: 0.1068\n",
      "Epoch [26/50], Step [250/735], Loss: 0.2036\n",
      "Epoch [26/50], Step [251/735], Loss: 0.1347\n",
      "Epoch [26/50], Step [252/735], Loss: 0.0578\n",
      "Epoch [26/50], Step [253/735], Loss: 0.0803\n",
      "Epoch [26/50], Step [254/735], Loss: 0.2511\n",
      "Epoch [26/50], Step [255/735], Loss: 0.0950\n",
      "Epoch [26/50], Step [256/735], Loss: 0.1071\n",
      "Epoch [26/50], Step [257/735], Loss: 0.0279\n",
      "Epoch [26/50], Step [258/735], Loss: 0.0377\n",
      "Epoch [26/50], Step [259/735], Loss: 0.1192\n",
      "Epoch [26/50], Step [260/735], Loss: 0.0372\n",
      "Epoch [26/50], Step [261/735], Loss: 0.2875\n",
      "Epoch [26/50], Step [262/735], Loss: 0.1312\n",
      "Epoch [26/50], Step [263/735], Loss: 0.1333\n",
      "Epoch [26/50], Step [264/735], Loss: 0.0497\n",
      "Epoch [26/50], Step [265/735], Loss: 0.0915\n",
      "Epoch [26/50], Step [266/735], Loss: 1.7253\n",
      "Epoch [26/50], Step [267/735], Loss: 0.0501\n",
      "Epoch [26/50], Step [268/735], Loss: 0.0430\n",
      "Epoch [26/50], Step [269/735], Loss: 0.1165\n",
      "Epoch [26/50], Step [270/735], Loss: 0.0909\n",
      "Epoch [26/50], Step [271/735], Loss: 0.1265\n",
      "Epoch [26/50], Step [272/735], Loss: 0.2422\n",
      "Epoch [26/50], Step [273/735], Loss: 0.0656\n",
      "Epoch [26/50], Step [274/735], Loss: 0.1396\n",
      "Epoch [26/50], Step [275/735], Loss: 1.3249\n",
      "Epoch [26/50], Step [276/735], Loss: 0.0267\n",
      "Epoch [26/50], Step [277/735], Loss: 0.1350\n",
      "Epoch [26/50], Step [278/735], Loss: 0.2005\n",
      "Epoch [26/50], Step [279/735], Loss: 0.0921\n",
      "Epoch [26/50], Step [280/735], Loss: 0.4431\n",
      "Epoch [26/50], Step [281/735], Loss: 0.0779\n",
      "Epoch [26/50], Step [282/735], Loss: 0.0936\n",
      "Epoch [26/50], Step [283/735], Loss: 0.1985\n",
      "Epoch [26/50], Step [284/735], Loss: 0.2059\n",
      "Epoch [26/50], Step [285/735], Loss: 0.2240\n",
      "Epoch [26/50], Step [286/735], Loss: 0.0824\n",
      "Epoch [26/50], Step [287/735], Loss: 0.1303\n",
      "Epoch [26/50], Step [288/735], Loss: 0.0862\n",
      "Epoch [26/50], Step [289/735], Loss: 0.1893\n",
      "Epoch [26/50], Step [290/735], Loss: 0.2143\n",
      "Epoch [26/50], Step [291/735], Loss: 0.1243\n",
      "Epoch [26/50], Step [292/735], Loss: 0.0898\n",
      "Epoch [26/50], Step [293/735], Loss: 0.2336\n",
      "Epoch [26/50], Step [294/735], Loss: 0.0721\n",
      "Epoch [26/50], Step [295/735], Loss: 0.0473\n",
      "Epoch [26/50], Step [296/735], Loss: 0.0758\n",
      "Epoch [26/50], Step [297/735], Loss: 0.1516\n",
      "Epoch [26/50], Step [298/735], Loss: 0.1312\n",
      "Epoch [26/50], Step [299/735], Loss: 0.0674\n",
      "Epoch [26/50], Step [300/735], Loss: 0.1757\n",
      "Epoch [26/50], Step [301/735], Loss: 0.1729\n",
      "Epoch [26/50], Step [302/735], Loss: 0.5820\n",
      "Epoch [26/50], Step [303/735], Loss: 0.1401\n",
      "Epoch [26/50], Step [304/735], Loss: 0.1820\n",
      "Epoch [26/50], Step [305/735], Loss: 0.0998\n",
      "Epoch [26/50], Step [306/735], Loss: 0.3658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Step [307/735], Loss: 0.0404\n",
      "Epoch [26/50], Step [308/735], Loss: 0.1212\n",
      "Epoch [26/50], Step [309/735], Loss: 0.1847\n",
      "Epoch [26/50], Step [310/735], Loss: 0.0851\n",
      "Epoch [26/50], Step [311/735], Loss: 0.0833\n",
      "Epoch [26/50], Step [312/735], Loss: 0.1030\n",
      "Epoch [26/50], Step [313/735], Loss: 0.1632\n",
      "Epoch [26/50], Step [314/735], Loss: 0.0692\n",
      "Epoch [26/50], Step [315/735], Loss: 0.0994\n",
      "Epoch [26/50], Step [316/735], Loss: 0.2322\n",
      "Epoch [26/50], Step [317/735], Loss: 0.2174\n",
      "Epoch [26/50], Step [318/735], Loss: 0.1422\n",
      "Epoch [26/50], Step [319/735], Loss: 0.1733\n",
      "Epoch [26/50], Step [320/735], Loss: 0.1366\n",
      "Epoch [26/50], Step [321/735], Loss: 0.1061\n",
      "Epoch [26/50], Step [322/735], Loss: 0.0836\n",
      "Epoch [26/50], Step [323/735], Loss: 0.5987\n",
      "Epoch [26/50], Step [324/735], Loss: 1.1094\n",
      "Epoch [26/50], Step [325/735], Loss: 0.0331\n",
      "Epoch [26/50], Step [326/735], Loss: 0.0458\n",
      "Epoch [26/50], Step [327/735], Loss: 0.1219\n",
      "Epoch [26/50], Step [328/735], Loss: 0.0427\n",
      "Epoch [26/50], Step [329/735], Loss: 0.1753\n",
      "Epoch [26/50], Step [330/735], Loss: 0.0523\n",
      "Epoch [26/50], Step [331/735], Loss: 0.1194\n",
      "Epoch [26/50], Step [332/735], Loss: 0.1087\n",
      "Epoch [26/50], Step [333/735], Loss: 0.0489\n",
      "Epoch [26/50], Step [334/735], Loss: 0.0906\n",
      "Epoch [26/50], Step [335/735], Loss: 0.2230\n",
      "Epoch [26/50], Step [336/735], Loss: 0.1270\n",
      "Epoch [26/50], Step [337/735], Loss: 0.1134\n",
      "Epoch [26/50], Step [338/735], Loss: 0.1473\n",
      "Epoch [26/50], Step [339/735], Loss: 0.1030\n",
      "Epoch [26/50], Step [340/735], Loss: 0.1026\n",
      "Epoch [26/50], Step [341/735], Loss: 0.0757\n",
      "Epoch [26/50], Step [342/735], Loss: 0.1669\n",
      "Epoch [26/50], Step [343/735], Loss: 0.0500\n",
      "Epoch [26/50], Step [344/735], Loss: 0.5027\n",
      "Epoch [26/50], Step [345/735], Loss: 0.1409\n",
      "Epoch [26/50], Step [346/735], Loss: 0.0937\n",
      "Epoch [26/50], Step [347/735], Loss: 0.0522\n",
      "Epoch [26/50], Step [348/735], Loss: 0.2061\n",
      "Epoch [26/50], Step [349/735], Loss: 0.0463\n",
      "Epoch [26/50], Step [350/735], Loss: 2.2985\n",
      "Epoch [26/50], Step [351/735], Loss: 0.0563\n",
      "Epoch [26/50], Step [352/735], Loss: 0.0394\n",
      "Epoch [26/50], Step [353/735], Loss: 0.0961\n",
      "Epoch [26/50], Step [354/735], Loss: 0.3964\n",
      "Epoch [26/50], Step [355/735], Loss: 0.2974\n",
      "Epoch [26/50], Step [356/735], Loss: 0.2413\n",
      "Epoch [26/50], Step [357/735], Loss: 0.0710\n",
      "Epoch [26/50], Step [358/735], Loss: 1.4671\n",
      "Epoch [26/50], Step [359/735], Loss: 0.0951\n",
      "Epoch [26/50], Step [360/735], Loss: 0.2088\n",
      "Epoch [26/50], Step [361/735], Loss: 0.1995\n",
      "Epoch [26/50], Step [362/735], Loss: 1.0113\n",
      "Epoch [26/50], Step [363/735], Loss: 0.1803\n",
      "Epoch [26/50], Step [364/735], Loss: 0.1752\n",
      "Epoch [26/50], Step [365/735], Loss: 0.9400\n",
      "Epoch [26/50], Step [366/735], Loss: 0.1170\n",
      "Epoch [26/50], Step [367/735], Loss: 0.1642\n",
      "Epoch [26/50], Step [368/735], Loss: 0.1031\n",
      "Epoch [26/50], Step [369/735], Loss: 0.2898\n",
      "Epoch [26/50], Step [370/735], Loss: 0.0932\n",
      "Epoch [26/50], Step [371/735], Loss: 0.0520\n",
      "Epoch [26/50], Step [372/735], Loss: 0.2216\n",
      "Epoch [26/50], Step [373/735], Loss: 0.2467\n",
      "Epoch [26/50], Step [374/735], Loss: 2.2472\n",
      "Epoch [26/50], Step [375/735], Loss: 0.3657\n",
      "Epoch [26/50], Step [376/735], Loss: 0.1404\n",
      "Epoch [26/50], Step [377/735], Loss: 0.3856\n",
      "Epoch [26/50], Step [378/735], Loss: 0.1142\n",
      "Epoch [26/50], Step [379/735], Loss: 0.0657\n",
      "Epoch [26/50], Step [380/735], Loss: 0.0371\n",
      "Epoch [26/50], Step [381/735], Loss: 0.0651\n",
      "Epoch [26/50], Step [382/735], Loss: 0.1744\n",
      "Epoch [26/50], Step [383/735], Loss: 0.1131\n",
      "Epoch [26/50], Step [384/735], Loss: 0.0826\n",
      "Epoch [26/50], Step [385/735], Loss: 0.2229\n",
      "Epoch [26/50], Step [386/735], Loss: 0.1368\n",
      "Epoch [26/50], Step [387/735], Loss: 0.0604\n",
      "Epoch [26/50], Step [388/735], Loss: 0.1078\n",
      "Epoch [26/50], Step [389/735], Loss: 0.1454\n",
      "Epoch [26/50], Step [390/735], Loss: 0.1325\n",
      "Epoch [26/50], Step [391/735], Loss: 0.6583\n",
      "Epoch [26/50], Step [392/735], Loss: 0.1726\n",
      "Epoch [26/50], Step [393/735], Loss: 0.1422\n",
      "Epoch [26/50], Step [394/735], Loss: 0.1197\n",
      "Epoch [26/50], Step [395/735], Loss: 0.2764\n",
      "Epoch [26/50], Step [396/735], Loss: 0.7625\n",
      "Epoch [26/50], Step [397/735], Loss: 0.2596\n",
      "Epoch [26/50], Step [398/735], Loss: 0.1636\n",
      "Epoch [26/50], Step [399/735], Loss: 0.0539\n",
      "Epoch [26/50], Step [400/735], Loss: 0.0925\n",
      "Epoch [26/50], Step [401/735], Loss: 0.0889\n",
      "Epoch [26/50], Step [402/735], Loss: 0.2713\n",
      "Epoch [26/50], Step [403/735], Loss: 0.0652\n",
      "Epoch [26/50], Step [404/735], Loss: 0.2472\n",
      "Epoch [26/50], Step [405/735], Loss: 0.1358\n",
      "Epoch [26/50], Step [406/735], Loss: 0.3077\n",
      "Epoch [26/50], Step [407/735], Loss: 0.1814\n",
      "Epoch [26/50], Step [408/735], Loss: 0.1098\n",
      "Epoch [26/50], Step [409/735], Loss: 0.1384\n",
      "Epoch [26/50], Step [410/735], Loss: 0.0871\n",
      "Epoch [26/50], Step [411/735], Loss: 0.1571\n",
      "Epoch [26/50], Step [412/735], Loss: 0.1091\n",
      "Epoch [26/50], Step [413/735], Loss: 0.0624\n",
      "Epoch [26/50], Step [414/735], Loss: 0.3005\n",
      "Epoch [26/50], Step [415/735], Loss: 0.2055\n",
      "Epoch [26/50], Step [416/735], Loss: 0.1354\n",
      "Epoch [26/50], Step [417/735], Loss: 0.0969\n",
      "Epoch [26/50], Step [418/735], Loss: 0.0955\n",
      "Epoch [26/50], Step [419/735], Loss: 0.1484\n",
      "Epoch [26/50], Step [420/735], Loss: 0.0659\n",
      "Epoch [26/50], Step [421/735], Loss: 0.0713\n",
      "Epoch [26/50], Step [422/735], Loss: 0.0891\n",
      "Epoch [26/50], Step [423/735], Loss: 0.2071\n",
      "Epoch [26/50], Step [424/735], Loss: 0.0311\n",
      "Epoch [26/50], Step [425/735], Loss: 0.1013\n",
      "Epoch [26/50], Step [426/735], Loss: 0.0451\n",
      "Epoch [26/50], Step [427/735], Loss: 0.1803\n",
      "Epoch [26/50], Step [428/735], Loss: 0.0812\n",
      "Epoch [26/50], Step [429/735], Loss: 0.3061\n",
      "Epoch [26/50], Step [430/735], Loss: 0.2986\n",
      "Epoch [26/50], Step [431/735], Loss: 0.1005\n",
      "Epoch [26/50], Step [432/735], Loss: 0.0739\n",
      "Epoch [26/50], Step [433/735], Loss: 0.0783\n",
      "Epoch [26/50], Step [434/735], Loss: 0.2014\n",
      "Epoch [26/50], Step [435/735], Loss: 0.0418\n",
      "Epoch [26/50], Step [436/735], Loss: 0.0829\n",
      "Epoch [26/50], Step [437/735], Loss: 0.1037\n",
      "Epoch [26/50], Step [438/735], Loss: 0.2362\n",
      "Epoch [26/50], Step [439/735], Loss: 0.0666\n",
      "Epoch [26/50], Step [440/735], Loss: 0.1744\n",
      "Epoch [26/50], Step [441/735], Loss: 0.1771\n",
      "Epoch [26/50], Step [442/735], Loss: 0.1668\n",
      "Epoch [26/50], Step [443/735], Loss: 0.7702\n",
      "Epoch [26/50], Step [444/735], Loss: 0.1246\n",
      "Epoch [26/50], Step [445/735], Loss: 0.0605\n",
      "Epoch [26/50], Step [446/735], Loss: 0.1146\n",
      "Epoch [26/50], Step [447/735], Loss: 0.0556\n",
      "Epoch [26/50], Step [448/735], Loss: 0.1306\n",
      "Epoch [26/50], Step [449/735], Loss: 0.0320\n",
      "Epoch [26/50], Step [450/735], Loss: 0.1550\n",
      "Epoch [26/50], Step [451/735], Loss: 0.2038\n",
      "Epoch [26/50], Step [452/735], Loss: 0.0566\n",
      "Epoch [26/50], Step [453/735], Loss: 0.0531\n",
      "Epoch [26/50], Step [454/735], Loss: 0.0440\n",
      "Epoch [26/50], Step [455/735], Loss: 0.3889\n",
      "Epoch [26/50], Step [456/735], Loss: 0.1182\n",
      "Epoch [26/50], Step [457/735], Loss: 0.0624\n",
      "Epoch [26/50], Step [458/735], Loss: 0.5991\n",
      "Epoch [26/50], Step [459/735], Loss: 0.1161\n",
      "Epoch [26/50], Step [460/735], Loss: 0.1133\n",
      "Epoch [26/50], Step [461/735], Loss: 0.1873\n",
      "Epoch [26/50], Step [462/735], Loss: 0.1422\n",
      "Epoch [26/50], Step [463/735], Loss: 0.0819\n",
      "Epoch [26/50], Step [464/735], Loss: 0.0648\n",
      "Epoch [26/50], Step [465/735], Loss: 0.1497\n",
      "Epoch [26/50], Step [466/735], Loss: 0.1672\n",
      "Epoch [26/50], Step [467/735], Loss: 0.2035\n",
      "Epoch [26/50], Step [468/735], Loss: 0.1712\n",
      "Epoch [26/50], Step [469/735], Loss: 0.0357\n",
      "Epoch [26/50], Step [470/735], Loss: 0.1133\n",
      "Epoch [26/50], Step [471/735], Loss: 0.6170\n",
      "Epoch [26/50], Step [472/735], Loss: 0.1436\n",
      "Epoch [26/50], Step [473/735], Loss: 0.0794\n",
      "Epoch [26/50], Step [474/735], Loss: 0.1024\n",
      "Epoch [26/50], Step [475/735], Loss: 0.1135\n",
      "Epoch [26/50], Step [476/735], Loss: 0.1130\n",
      "Epoch [26/50], Step [477/735], Loss: 0.2751\n",
      "Epoch [26/50], Step [478/735], Loss: 0.4365\n",
      "Epoch [26/50], Step [479/735], Loss: 0.0684\n",
      "Epoch [26/50], Step [480/735], Loss: 0.1069\n",
      "Epoch [26/50], Step [481/735], Loss: 0.4360\n",
      "Epoch [26/50], Step [482/735], Loss: 0.2522\n",
      "Epoch [26/50], Step [483/735], Loss: 0.0178\n",
      "Epoch [26/50], Step [484/735], Loss: 0.0385\n",
      "Epoch [26/50], Step [485/735], Loss: 0.0704\n",
      "Epoch [26/50], Step [486/735], Loss: 0.0462\n",
      "Epoch [26/50], Step [487/735], Loss: 0.0466\n",
      "Epoch [26/50], Step [488/735], Loss: 0.1348\n",
      "Epoch [26/50], Step [489/735], Loss: 0.1096\n",
      "Epoch [26/50], Step [490/735], Loss: 0.0247\n",
      "Epoch [26/50], Step [491/735], Loss: 0.0827\n",
      "Epoch [26/50], Step [492/735], Loss: 0.2692\n",
      "Epoch [26/50], Step [493/735], Loss: 0.1397\n",
      "Epoch [26/50], Step [494/735], Loss: 0.0369\n",
      "Epoch [26/50], Step [495/735], Loss: 0.8075\n",
      "Epoch [26/50], Step [496/735], Loss: 0.1915\n",
      "Epoch [26/50], Step [497/735], Loss: 0.0962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Step [498/735], Loss: 0.0440\n",
      "Epoch [26/50], Step [499/735], Loss: 0.0548\n",
      "Epoch [26/50], Step [500/735], Loss: 0.1160\n",
      "Epoch [26/50], Step [501/735], Loss: 0.1066\n",
      "Epoch [26/50], Step [502/735], Loss: 0.0684\n",
      "Epoch [26/50], Step [503/735], Loss: 0.4272\n",
      "Epoch [26/50], Step [504/735], Loss: 0.1373\n",
      "Epoch [26/50], Step [505/735], Loss: 0.0845\n",
      "Epoch [26/50], Step [506/735], Loss: 0.1951\n",
      "Epoch [26/50], Step [507/735], Loss: 0.1047\n",
      "Epoch [26/50], Step [508/735], Loss: 0.1217\n",
      "Epoch [26/50], Step [509/735], Loss: 0.0646\n",
      "Epoch [26/50], Step [510/735], Loss: 0.1759\n",
      "Epoch [26/50], Step [511/735], Loss: 0.3542\n",
      "Epoch [26/50], Step [512/735], Loss: 0.0567\n",
      "Epoch [26/50], Step [513/735], Loss: 0.1150\n",
      "Epoch [26/50], Step [514/735], Loss: 0.2014\n",
      "Epoch [26/50], Step [515/735], Loss: 0.1919\n",
      "Epoch [26/50], Step [516/735], Loss: 0.1957\n",
      "Epoch [26/50], Step [517/735], Loss: 0.0631\n",
      "Epoch [26/50], Step [518/735], Loss: 0.1518\n",
      "Epoch [26/50], Step [519/735], Loss: 0.2219\n",
      "Epoch [26/50], Step [520/735], Loss: 0.2214\n",
      "Epoch [26/50], Step [521/735], Loss: 1.6762\n",
      "Epoch [26/50], Step [522/735], Loss: 0.1682\n",
      "Epoch [26/50], Step [523/735], Loss: 0.0655\n",
      "Epoch [26/50], Step [524/735], Loss: 0.1075\n",
      "Epoch [26/50], Step [525/735], Loss: 0.2565\n",
      "Epoch [26/50], Step [526/735], Loss: 0.0990\n",
      "Epoch [26/50], Step [527/735], Loss: 0.0955\n",
      "Epoch [26/50], Step [528/735], Loss: 0.2160\n",
      "Epoch [26/50], Step [529/735], Loss: 0.0533\n",
      "Epoch [26/50], Step [530/735], Loss: 0.0640\n",
      "Epoch [26/50], Step [531/735], Loss: 0.1396\n",
      "Epoch [26/50], Step [532/735], Loss: 0.0916\n",
      "Epoch [26/50], Step [533/735], Loss: 0.2562\n",
      "Epoch [26/50], Step [534/735], Loss: 0.2274\n",
      "Epoch [26/50], Step [535/735], Loss: 0.0724\n",
      "Epoch [26/50], Step [536/735], Loss: 0.1266\n",
      "Epoch [26/50], Step [537/735], Loss: 0.0895\n",
      "Epoch [26/50], Step [538/735], Loss: 0.1287\n",
      "Epoch [26/50], Step [539/735], Loss: 0.1415\n",
      "Epoch [26/50], Step [540/735], Loss: 0.1177\n",
      "Epoch [26/50], Step [541/735], Loss: 0.0379\n",
      "Epoch [26/50], Step [542/735], Loss: 0.0527\n",
      "Epoch [26/50], Step [543/735], Loss: 0.1278\n",
      "Epoch [26/50], Step [544/735], Loss: 0.1556\n",
      "Epoch [26/50], Step [545/735], Loss: 0.0596\n",
      "Epoch [26/50], Step [546/735], Loss: 0.1341\n",
      "Epoch [26/50], Step [547/735], Loss: 0.1694\n",
      "Epoch [26/50], Step [548/735], Loss: 0.1276\n",
      "Epoch [26/50], Step [549/735], Loss: 0.0739\n",
      "Epoch [26/50], Step [550/735], Loss: 0.1338\n",
      "Epoch [26/50], Step [551/735], Loss: 0.0340\n",
      "Epoch [26/50], Step [552/735], Loss: 0.1253\n",
      "Epoch [26/50], Step [553/735], Loss: 0.0778\n",
      "Epoch [26/50], Step [554/735], Loss: 0.4114\n",
      "Epoch [26/50], Step [555/735], Loss: 0.7002\n",
      "Epoch [26/50], Step [556/735], Loss: 0.1150\n",
      "Epoch [26/50], Step [557/735], Loss: 0.0426\n",
      "Epoch [26/50], Step [558/735], Loss: 0.1505\n",
      "Epoch [26/50], Step [559/735], Loss: 0.3254\n",
      "Epoch [26/50], Step [560/735], Loss: 0.1072\n",
      "Epoch [26/50], Step [561/735], Loss: 0.0747\n",
      "Epoch [26/50], Step [562/735], Loss: 0.1269\n",
      "Epoch [26/50], Step [563/735], Loss: 0.0864\n",
      "Epoch [26/50], Step [564/735], Loss: 0.1025\n",
      "Epoch [26/50], Step [565/735], Loss: 0.0897\n",
      "Epoch [26/50], Step [566/735], Loss: 0.0463\n",
      "Epoch [26/50], Step [567/735], Loss: 0.2055\n",
      "Epoch [26/50], Step [568/735], Loss: 0.1603\n",
      "Epoch [26/50], Step [569/735], Loss: 0.0877\n",
      "Epoch [26/50], Step [570/735], Loss: 0.0620\n",
      "Epoch [26/50], Step [571/735], Loss: 0.1651\n",
      "Epoch [26/50], Step [572/735], Loss: 0.1301\n",
      "Epoch [26/50], Step [573/735], Loss: 0.2346\n",
      "Epoch [26/50], Step [574/735], Loss: 0.1217\n",
      "Epoch [26/50], Step [575/735], Loss: 0.0680\n",
      "Epoch [26/50], Step [576/735], Loss: 0.1427\n",
      "Epoch [26/50], Step [577/735], Loss: 0.0521\n",
      "Epoch [26/50], Step [578/735], Loss: 0.1257\n",
      "Epoch [26/50], Step [579/735], Loss: 0.5289\n",
      "Epoch [26/50], Step [580/735], Loss: 0.1149\n",
      "Epoch [26/50], Step [581/735], Loss: 0.1196\n",
      "Epoch [26/50], Step [582/735], Loss: 0.1236\n",
      "Epoch [26/50], Step [583/735], Loss: 0.0862\n",
      "Epoch [26/50], Step [584/735], Loss: 0.4447\n",
      "Epoch [26/50], Step [585/735], Loss: 0.1069\n",
      "Epoch [26/50], Step [586/735], Loss: 0.0869\n",
      "Epoch [26/50], Step [587/735], Loss: 0.0875\n",
      "Epoch [26/50], Step [588/735], Loss: 0.2634\n",
      "Epoch [26/50], Step [589/735], Loss: 0.0496\n",
      "Epoch [26/50], Step [590/735], Loss: 0.0493\n",
      "Epoch [26/50], Step [591/735], Loss: 0.1074\n",
      "Epoch [26/50], Step [592/735], Loss: 0.1726\n",
      "Epoch [26/50], Step [593/735], Loss: 0.0615\n",
      "Epoch [26/50], Step [594/735], Loss: 0.1174\n",
      "Epoch [26/50], Step [595/735], Loss: 0.2199\n",
      "Epoch [26/50], Step [596/735], Loss: 0.1847\n",
      "Epoch [26/50], Step [597/735], Loss: 0.0697\n",
      "Epoch [26/50], Step [598/735], Loss: 0.1107\n",
      "Epoch [26/50], Step [599/735], Loss: 0.2118\n",
      "Epoch [26/50], Step [600/735], Loss: 0.1874\n",
      "Epoch [26/50], Step [601/735], Loss: 0.0756\n",
      "Epoch [26/50], Step [602/735], Loss: 0.1375\n",
      "Epoch [26/50], Step [603/735], Loss: 0.0503\n",
      "Epoch [26/50], Step [604/735], Loss: 0.0683\n",
      "Epoch [26/50], Step [605/735], Loss: 0.1316\n",
      "Epoch [26/50], Step [606/735], Loss: 0.2511\n",
      "Epoch [26/50], Step [607/735], Loss: 0.0285\n",
      "Epoch [26/50], Step [608/735], Loss: 0.1828\n",
      "Epoch [26/50], Step [609/735], Loss: 2.0068\n",
      "Epoch [26/50], Step [610/735], Loss: 0.0670\n",
      "Epoch [26/50], Step [611/735], Loss: 0.2295\n",
      "Epoch [26/50], Step [612/735], Loss: 0.1411\n",
      "Epoch [26/50], Step [613/735], Loss: 0.0800\n",
      "Epoch [26/50], Step [614/735], Loss: 0.0610\n",
      "Epoch [26/50], Step [615/735], Loss: 0.0858\n",
      "Epoch [26/50], Step [616/735], Loss: 0.1186\n",
      "Epoch [26/50], Step [617/735], Loss: 0.0876\n",
      "Epoch [26/50], Step [618/735], Loss: 0.1611\n",
      "Epoch [26/50], Step [619/735], Loss: 0.0697\n",
      "Epoch [26/50], Step [620/735], Loss: 0.1353\n",
      "Epoch [26/50], Step [621/735], Loss: 0.1355\n",
      "Epoch [26/50], Step [622/735], Loss: 0.1144\n",
      "Epoch [26/50], Step [623/735], Loss: 0.0784\n",
      "Epoch [26/50], Step [624/735], Loss: 0.0568\n",
      "Epoch [26/50], Step [625/735], Loss: 0.0781\n",
      "Epoch [26/50], Step [626/735], Loss: 0.1685\n",
      "Epoch [26/50], Step [627/735], Loss: 0.2291\n",
      "Epoch [26/50], Step [628/735], Loss: 0.1812\n",
      "Epoch [26/50], Step [629/735], Loss: 0.0869\n",
      "Epoch [26/50], Step [630/735], Loss: 0.1733\n",
      "Epoch [26/50], Step [631/735], Loss: 0.0437\n",
      "Epoch [26/50], Step [632/735], Loss: 0.1848\n",
      "Epoch [26/50], Step [633/735], Loss: 0.2310\n",
      "Epoch [26/50], Step [634/735], Loss: 1.1481\n",
      "Epoch [26/50], Step [635/735], Loss: 0.0616\n",
      "Epoch [26/50], Step [636/735], Loss: 0.2192\n",
      "Epoch [26/50], Step [637/735], Loss: 0.1293\n",
      "Epoch [26/50], Step [638/735], Loss: 0.0793\n",
      "Epoch [26/50], Step [639/735], Loss: 0.1476\n",
      "Epoch [26/50], Step [640/735], Loss: 0.1520\n",
      "Epoch [26/50], Step [641/735], Loss: 0.1167\n",
      "Epoch [26/50], Step [642/735], Loss: 0.1799\n",
      "Epoch [26/50], Step [643/735], Loss: 0.0784\n",
      "Epoch [26/50], Step [644/735], Loss: 0.1089\n",
      "Epoch [26/50], Step [645/735], Loss: 0.1358\n",
      "Epoch [26/50], Step [646/735], Loss: 0.0541\n",
      "Epoch [26/50], Step [647/735], Loss: 0.0982\n",
      "Epoch [26/50], Step [648/735], Loss: 0.0802\n",
      "Epoch [26/50], Step [649/735], Loss: 0.1021\n",
      "Epoch [26/50], Step [650/735], Loss: 0.1483\n",
      "Epoch [26/50], Step [651/735], Loss: 0.1529\n",
      "Epoch [26/50], Step [652/735], Loss: 0.0539\n",
      "Epoch [26/50], Step [653/735], Loss: 0.1206\n",
      "Epoch [26/50], Step [654/735], Loss: 0.1291\n",
      "Epoch [26/50], Step [655/735], Loss: 0.1968\n",
      "Epoch [26/50], Step [656/735], Loss: 0.0818\n",
      "Epoch [26/50], Step [657/735], Loss: 0.0680\n",
      "Epoch [26/50], Step [658/735], Loss: 0.5149\n",
      "Epoch [26/50], Step [659/735], Loss: 0.1808\n",
      "Epoch [26/50], Step [660/735], Loss: 0.1479\n",
      "Epoch [26/50], Step [661/735], Loss: 0.1972\n",
      "Epoch [26/50], Step [662/735], Loss: 0.2065\n",
      "Epoch [26/50], Step [663/735], Loss: 0.3278\n",
      "Epoch [26/50], Step [664/735], Loss: 0.0906\n",
      "Epoch [26/50], Step [665/735], Loss: 0.0593\n",
      "Epoch [26/50], Step [666/735], Loss: 0.0742\n",
      "Epoch [26/50], Step [667/735], Loss: 0.1366\n",
      "Epoch [26/50], Step [668/735], Loss: 0.3238\n",
      "Epoch [26/50], Step [669/735], Loss: 0.1022\n",
      "Epoch [26/50], Step [670/735], Loss: 0.1096\n",
      "Epoch [26/50], Step [671/735], Loss: 0.1594\n",
      "Epoch [26/50], Step [672/735], Loss: 0.0825\n",
      "Epoch [26/50], Step [673/735], Loss: 0.1731\n",
      "Epoch [26/50], Step [674/735], Loss: 0.1081\n",
      "Epoch [26/50], Step [675/735], Loss: 0.0711\n",
      "Epoch [26/50], Step [676/735], Loss: 0.0857\n",
      "Epoch [26/50], Step [677/735], Loss: 0.0596\n",
      "Epoch [26/50], Step [678/735], Loss: 0.1226\n",
      "Epoch [26/50], Step [679/735], Loss: 0.1304\n",
      "Epoch [26/50], Step [680/735], Loss: 0.4707\n",
      "Epoch [26/50], Step [681/735], Loss: 0.2339\n",
      "Epoch [26/50], Step [682/735], Loss: 0.1827\n",
      "Epoch [26/50], Step [683/735], Loss: 0.0864\n",
      "Epoch [26/50], Step [684/735], Loss: 0.0412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Step [685/735], Loss: 0.1177\n",
      "Epoch [26/50], Step [686/735], Loss: 0.1776\n",
      "Epoch [26/50], Step [687/735], Loss: 0.1011\n",
      "Epoch [26/50], Step [688/735], Loss: 0.0926\n",
      "Epoch [26/50], Step [689/735], Loss: 0.1847\n",
      "Epoch [26/50], Step [690/735], Loss: 0.0616\n",
      "Epoch [26/50], Step [691/735], Loss: 0.1251\n",
      "Epoch [26/50], Step [692/735], Loss: 0.1078\n",
      "Epoch [26/50], Step [693/735], Loss: 0.1775\n",
      "Epoch [26/50], Step [694/735], Loss: 0.4315\n",
      "Epoch [26/50], Step [695/735], Loss: 0.1151\n",
      "Epoch [26/50], Step [696/735], Loss: 0.7836\n",
      "Epoch [26/50], Step [697/735], Loss: 0.1482\n",
      "Epoch [26/50], Step [698/735], Loss: 0.1210\n",
      "Epoch [26/50], Step [699/735], Loss: 0.0475\n",
      "Epoch [26/50], Step [700/735], Loss: 0.0769\n",
      "Epoch [26/50], Step [701/735], Loss: 0.0596\n",
      "Epoch [26/50], Step [702/735], Loss: 0.3558\n",
      "Epoch [26/50], Step [703/735], Loss: 0.0608\n",
      "Epoch [26/50], Step [704/735], Loss: 0.1619\n",
      "Epoch [26/50], Step [705/735], Loss: 0.1645\n",
      "Epoch [26/50], Step [706/735], Loss: 0.0824\n",
      "Epoch [26/50], Step [707/735], Loss: 0.4095\n",
      "Epoch [26/50], Step [708/735], Loss: 0.1506\n",
      "Epoch [26/50], Step [709/735], Loss: 0.0285\n",
      "Epoch [26/50], Step [710/735], Loss: 0.0734\n",
      "Epoch [26/50], Step [711/735], Loss: 0.1046\n",
      "Epoch [26/50], Step [712/735], Loss: 0.1072\n",
      "Epoch [26/50], Step [713/735], Loss: 0.1838\n",
      "Epoch [26/50], Step [714/735], Loss: 0.0690\n",
      "Epoch [26/50], Step [715/735], Loss: 0.0367\n",
      "Epoch [26/50], Step [716/735], Loss: 0.0601\n",
      "Epoch [26/50], Step [717/735], Loss: 0.7763\n",
      "Epoch [26/50], Step [718/735], Loss: 0.1078\n",
      "Epoch [26/50], Step [719/735], Loss: 0.0619\n",
      "Epoch [26/50], Step [720/735], Loss: 0.1791\n",
      "Epoch [26/50], Step [721/735], Loss: 0.0373\n",
      "Epoch [26/50], Step [722/735], Loss: 0.0991\n",
      "Epoch [26/50], Step [723/735], Loss: 0.0286\n",
      "Epoch [26/50], Step [724/735], Loss: 0.1565\n",
      "Epoch [26/50], Step [725/735], Loss: 0.0627\n",
      "Epoch [26/50], Step [726/735], Loss: 0.1038\n",
      "Epoch [26/50], Step [727/735], Loss: 0.5061\n",
      "Epoch [26/50], Step [728/735], Loss: 0.0402\n",
      "Epoch [26/50], Step [729/735], Loss: 0.0907\n",
      "Epoch [26/50], Step [730/735], Loss: 0.1340\n",
      "Epoch [26/50], Step [731/735], Loss: 0.1183\n",
      "Epoch [26/50], Step [732/735], Loss: 0.1623\n",
      "Epoch [26/50], Step [733/735], Loss: 0.1237\n",
      "Epoch [26/50], Step [734/735], Loss: 0.1518\n",
      "Epoch [26/50], Step [735/735], Loss: 0.0962\n",
      "Epoch [27/50], Step [1/735], Loss: 0.1334\n",
      "Epoch [27/50], Step [2/735], Loss: 0.2321\n",
      "Epoch [27/50], Step [3/735], Loss: 0.0976\n",
      "Epoch [27/50], Step [4/735], Loss: 0.2567\n",
      "Epoch [27/50], Step [5/735], Loss: 0.1454\n",
      "Epoch [27/50], Step [6/735], Loss: 0.4119\n",
      "Epoch [27/50], Step [7/735], Loss: 0.2502\n",
      "Epoch [27/50], Step [8/735], Loss: 0.1525\n",
      "Epoch [27/50], Step [9/735], Loss: 0.0801\n",
      "Epoch [27/50], Step [10/735], Loss: 0.1367\n",
      "Epoch [27/50], Step [11/735], Loss: 0.0522\n",
      "Epoch [27/50], Step [12/735], Loss: 0.0826\n",
      "Epoch [27/50], Step [13/735], Loss: 0.1030\n",
      "Epoch [27/50], Step [14/735], Loss: 0.0834\n",
      "Epoch [27/50], Step [15/735], Loss: 0.2731\n",
      "Epoch [27/50], Step [16/735], Loss: 0.2066\n",
      "Epoch [27/50], Step [17/735], Loss: 0.1212\n",
      "Epoch [27/50], Step [18/735], Loss: 0.1228\n",
      "Epoch [27/50], Step [19/735], Loss: 0.1005\n",
      "Epoch [27/50], Step [20/735], Loss: 0.1583\n",
      "Epoch [27/50], Step [21/735], Loss: 0.0526\n",
      "Epoch [27/50], Step [22/735], Loss: 1.9779\n",
      "Epoch [27/50], Step [23/735], Loss: 0.0776\n",
      "Epoch [27/50], Step [24/735], Loss: 0.0779\n",
      "Epoch [27/50], Step [25/735], Loss: 0.1906\n",
      "Epoch [27/50], Step [26/735], Loss: 0.0761\n",
      "Epoch [27/50], Step [27/735], Loss: 0.0535\n",
      "Epoch [27/50], Step [28/735], Loss: 0.1230\n",
      "Epoch [27/50], Step [29/735], Loss: 0.0931\n",
      "Epoch [27/50], Step [30/735], Loss: 0.1584\n",
      "Epoch [27/50], Step [31/735], Loss: 0.1885\n",
      "Epoch [27/50], Step [32/735], Loss: 0.0346\n",
      "Epoch [27/50], Step [33/735], Loss: 0.0989\n",
      "Epoch [27/50], Step [34/735], Loss: 0.3804\n",
      "Epoch [27/50], Step [35/735], Loss: 0.1917\n",
      "Epoch [27/50], Step [36/735], Loss: 0.1171\n",
      "Epoch [27/50], Step [37/735], Loss: 0.1258\n",
      "Epoch [27/50], Step [38/735], Loss: 0.8274\n",
      "Epoch [27/50], Step [39/735], Loss: 0.1258\n",
      "Epoch [27/50], Step [40/735], Loss: 0.9031\n",
      "Epoch [27/50], Step [41/735], Loss: 0.2744\n",
      "Epoch [27/50], Step [42/735], Loss: 0.0807\n",
      "Epoch [27/50], Step [43/735], Loss: 0.3960\n",
      "Epoch [27/50], Step [44/735], Loss: 0.2787\n",
      "Epoch [27/50], Step [45/735], Loss: 0.0572\n",
      "Epoch [27/50], Step [46/735], Loss: 0.1528\n",
      "Epoch [27/50], Step [47/735], Loss: 0.2136\n",
      "Epoch [27/50], Step [48/735], Loss: 0.0453\n",
      "Epoch [27/50], Step [49/735], Loss: 0.0495\n",
      "Epoch [27/50], Step [50/735], Loss: 0.1456\n",
      "Epoch [27/50], Step [51/735], Loss: 0.0883\n",
      "Epoch [27/50], Step [52/735], Loss: 0.1143\n",
      "Epoch [27/50], Step [53/735], Loss: 0.1502\n",
      "Epoch [27/50], Step [54/735], Loss: 0.2218\n",
      "Epoch [27/50], Step [55/735], Loss: 0.0921\n",
      "Epoch [27/50], Step [56/735], Loss: 0.1471\n",
      "Epoch [27/50], Step [57/735], Loss: 0.0756\n",
      "Epoch [27/50], Step [58/735], Loss: 0.0935\n",
      "Epoch [27/50], Step [59/735], Loss: 0.3292\n",
      "Epoch [27/50], Step [60/735], Loss: 0.0531\n",
      "Epoch [27/50], Step [61/735], Loss: 0.0754\n",
      "Epoch [27/50], Step [62/735], Loss: 0.0818\n",
      "Epoch [27/50], Step [63/735], Loss: 0.1867\n",
      "Epoch [27/50], Step [64/735], Loss: 0.0627\n",
      "Epoch [27/50], Step [65/735], Loss: 0.1122\n",
      "Epoch [27/50], Step [66/735], Loss: 0.0519\n",
      "Epoch [27/50], Step [67/735], Loss: 0.1384\n",
      "Epoch [27/50], Step [68/735], Loss: 0.1844\n",
      "Epoch [27/50], Step [69/735], Loss: 0.1346\n",
      "Epoch [27/50], Step [70/735], Loss: 0.1420\n",
      "Epoch [27/50], Step [71/735], Loss: 0.1663\n",
      "Epoch [27/50], Step [72/735], Loss: 0.0666\n",
      "Epoch [27/50], Step [73/735], Loss: 0.1942\n",
      "Epoch [27/50], Step [74/735], Loss: 0.1800\n",
      "Epoch [27/50], Step [75/735], Loss: 0.1129\n",
      "Epoch [27/50], Step [76/735], Loss: 0.1690\n",
      "Epoch [27/50], Step [77/735], Loss: 0.0493\n",
      "Epoch [27/50], Step [78/735], Loss: 0.0734\n",
      "Epoch [27/50], Step [79/735], Loss: 0.0610\n",
      "Epoch [27/50], Step [80/735], Loss: 0.0682\n",
      "Epoch [27/50], Step [81/735], Loss: 0.0352\n",
      "Epoch [27/50], Step [82/735], Loss: 0.0566\n",
      "Epoch [27/50], Step [83/735], Loss: 0.2945\n",
      "Epoch [27/50], Step [84/735], Loss: 1.5892\n",
      "Epoch [27/50], Step [85/735], Loss: 0.0797\n",
      "Epoch [27/50], Step [86/735], Loss: 0.1225\n",
      "Epoch [27/50], Step [87/735], Loss: 0.0195\n",
      "Epoch [27/50], Step [88/735], Loss: 0.0827\n",
      "Epoch [27/50], Step [89/735], Loss: 0.1071\n",
      "Epoch [27/50], Step [90/735], Loss: 0.0858\n",
      "Epoch [27/50], Step [91/735], Loss: 0.0724\n",
      "Epoch [27/50], Step [92/735], Loss: 0.0850\n",
      "Epoch [27/50], Step [93/735], Loss: 0.0732\n",
      "Epoch [27/50], Step [94/735], Loss: 0.0608\n",
      "Epoch [27/50], Step [95/735], Loss: 0.0855\n",
      "Epoch [27/50], Step [96/735], Loss: 0.0275\n",
      "Epoch [27/50], Step [97/735], Loss: 0.0623\n",
      "Epoch [27/50], Step [98/735], Loss: 0.0626\n",
      "Epoch [27/50], Step [99/735], Loss: 0.1127\n",
      "Epoch [27/50], Step [100/735], Loss: 0.1017\n",
      "Epoch [27/50], Step [101/735], Loss: 0.1101\n",
      "Epoch [27/50], Step [102/735], Loss: 0.0922\n",
      "Epoch [27/50], Step [103/735], Loss: 0.1104\n",
      "Epoch [27/50], Step [104/735], Loss: 0.0514\n",
      "Epoch [27/50], Step [105/735], Loss: 0.0494\n",
      "Epoch [27/50], Step [106/735], Loss: 0.0907\n",
      "Epoch [27/50], Step [107/735], Loss: 0.1734\n",
      "Epoch [27/50], Step [108/735], Loss: 0.1249\n",
      "Epoch [27/50], Step [109/735], Loss: 0.0662\n",
      "Epoch [27/50], Step [110/735], Loss: 0.1332\n",
      "Epoch [27/50], Step [111/735], Loss: 0.0537\n",
      "Epoch [27/50], Step [112/735], Loss: 0.2517\n",
      "Epoch [27/50], Step [113/735], Loss: 0.1151\n",
      "Epoch [27/50], Step [114/735], Loss: 0.2570\n",
      "Epoch [27/50], Step [115/735], Loss: 0.0558\n",
      "Epoch [27/50], Step [116/735], Loss: 0.4568\n",
      "Epoch [27/50], Step [117/735], Loss: 0.1551\n",
      "Epoch [27/50], Step [118/735], Loss: 0.0510\n",
      "Epoch [27/50], Step [119/735], Loss: 0.0888\n",
      "Epoch [27/50], Step [120/735], Loss: 0.0767\n",
      "Epoch [27/50], Step [121/735], Loss: 0.2663\n",
      "Epoch [27/50], Step [122/735], Loss: 0.1483\n",
      "Epoch [27/50], Step [123/735], Loss: 0.2311\n",
      "Epoch [27/50], Step [124/735], Loss: 0.0402\n",
      "Epoch [27/50], Step [125/735], Loss: 0.0770\n",
      "Epoch [27/50], Step [126/735], Loss: 0.1533\n",
      "Epoch [27/50], Step [127/735], Loss: 0.0779\n",
      "Epoch [27/50], Step [128/735], Loss: 0.0905\n",
      "Epoch [27/50], Step [129/735], Loss: 0.1380\n",
      "Epoch [27/50], Step [130/735], Loss: 0.6411\n",
      "Epoch [27/50], Step [131/735], Loss: 1.0281\n",
      "Epoch [27/50], Step [132/735], Loss: 0.1464\n",
      "Epoch [27/50], Step [133/735], Loss: 0.1378\n",
      "Epoch [27/50], Step [134/735], Loss: 0.0439\n",
      "Epoch [27/50], Step [135/735], Loss: 0.1039\n",
      "Epoch [27/50], Step [136/735], Loss: 0.0730\n",
      "Epoch [27/50], Step [137/735], Loss: 0.9822\n",
      "Epoch [27/50], Step [138/735], Loss: 0.1837\n",
      "Epoch [27/50], Step [139/735], Loss: 0.1513\n",
      "Epoch [27/50], Step [140/735], Loss: 0.1336\n",
      "Epoch [27/50], Step [141/735], Loss: 0.1677\n",
      "Epoch [27/50], Step [142/735], Loss: 0.0943\n",
      "Epoch [27/50], Step [143/735], Loss: 0.0961\n",
      "Epoch [27/50], Step [144/735], Loss: 0.4437\n",
      "Epoch [27/50], Step [145/735], Loss: 0.0946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Step [146/735], Loss: 0.1003\n",
      "Epoch [27/50], Step [147/735], Loss: 0.1834\n",
      "Epoch [27/50], Step [148/735], Loss: 0.1069\n",
      "Epoch [27/50], Step [149/735], Loss: 0.0869\n",
      "Epoch [27/50], Step [150/735], Loss: 0.3067\n",
      "Epoch [27/50], Step [151/735], Loss: 0.1395\n",
      "Epoch [27/50], Step [152/735], Loss: 0.1876\n",
      "Epoch [27/50], Step [153/735], Loss: 0.0840\n",
      "Epoch [27/50], Step [154/735], Loss: 0.2302\n",
      "Epoch [27/50], Step [155/735], Loss: 0.0931\n",
      "Epoch [27/50], Step [156/735], Loss: 0.0739\n",
      "Epoch [27/50], Step [157/735], Loss: 0.1417\n",
      "Epoch [27/50], Step [158/735], Loss: 0.2877\n",
      "Epoch [27/50], Step [159/735], Loss: 0.2508\n",
      "Epoch [27/50], Step [160/735], Loss: 0.0700\n",
      "Epoch [27/50], Step [161/735], Loss: 0.1664\n",
      "Epoch [27/50], Step [162/735], Loss: 0.0990\n",
      "Epoch [27/50], Step [163/735], Loss: 0.1780\n",
      "Epoch [27/50], Step [164/735], Loss: 0.2466\n",
      "Epoch [27/50], Step [165/735], Loss: 0.0676\n",
      "Epoch [27/50], Step [166/735], Loss: 0.0795\n",
      "Epoch [27/50], Step [167/735], Loss: 0.2296\n",
      "Epoch [27/50], Step [168/735], Loss: 0.1453\n",
      "Epoch [27/50], Step [169/735], Loss: 0.0359\n",
      "Epoch [27/50], Step [170/735], Loss: 0.1417\n",
      "Epoch [27/50], Step [171/735], Loss: 0.0765\n",
      "Epoch [27/50], Step [172/735], Loss: 0.1459\n",
      "Epoch [27/50], Step [173/735], Loss: 0.0822\n",
      "Epoch [27/50], Step [174/735], Loss: 0.1458\n",
      "Epoch [27/50], Step [175/735], Loss: 0.0680\n",
      "Epoch [27/50], Step [176/735], Loss: 0.3771\n",
      "Epoch [27/50], Step [177/735], Loss: 0.1105\n",
      "Epoch [27/50], Step [178/735], Loss: 0.1102\n",
      "Epoch [27/50], Step [179/735], Loss: 0.0849\n",
      "Epoch [27/50], Step [180/735], Loss: 0.0443\n",
      "Epoch [27/50], Step [181/735], Loss: 0.0761\n",
      "Epoch [27/50], Step [182/735], Loss: 0.0932\n",
      "Epoch [27/50], Step [183/735], Loss: 0.6172\n",
      "Epoch [27/50], Step [184/735], Loss: 0.1011\n",
      "Epoch [27/50], Step [185/735], Loss: 0.0941\n",
      "Epoch [27/50], Step [186/735], Loss: 0.4289\n",
      "Epoch [27/50], Step [187/735], Loss: 0.2456\n",
      "Epoch [27/50], Step [188/735], Loss: 0.0906\n",
      "Epoch [27/50], Step [189/735], Loss: 0.0723\n",
      "Epoch [27/50], Step [190/735], Loss: 0.1014\n",
      "Epoch [27/50], Step [191/735], Loss: 0.2528\n",
      "Epoch [27/50], Step [192/735], Loss: 0.0565\n",
      "Epoch [27/50], Step [193/735], Loss: 0.1225\n",
      "Epoch [27/50], Step [194/735], Loss: 0.3143\n",
      "Epoch [27/50], Step [195/735], Loss: 0.1529\n",
      "Epoch [27/50], Step [196/735], Loss: 0.1145\n",
      "Epoch [27/50], Step [197/735], Loss: 0.0586\n",
      "Epoch [27/50], Step [198/735], Loss: 0.1474\n",
      "Epoch [27/50], Step [199/735], Loss: 0.0737\n",
      "Epoch [27/50], Step [200/735], Loss: 0.2619\n",
      "Epoch [27/50], Step [201/735], Loss: 0.0633\n",
      "Epoch [27/50], Step [202/735], Loss: 0.1810\n",
      "Epoch [27/50], Step [203/735], Loss: 0.1642\n",
      "Epoch [27/50], Step [204/735], Loss: 0.1519\n",
      "Epoch [27/50], Step [205/735], Loss: 0.1422\n",
      "Epoch [27/50], Step [206/735], Loss: 0.6800\n",
      "Epoch [27/50], Step [207/735], Loss: 0.0854\n",
      "Epoch [27/50], Step [208/735], Loss: 0.1437\n",
      "Epoch [27/50], Step [209/735], Loss: 0.0421\n",
      "Epoch [27/50], Step [210/735], Loss: 0.0570\n",
      "Epoch [27/50], Step [211/735], Loss: 0.1817\n",
      "Epoch [27/50], Step [212/735], Loss: 0.1819\n",
      "Epoch [27/50], Step [213/735], Loss: 0.1522\n",
      "Epoch [27/50], Step [214/735], Loss: 0.2212\n",
      "Epoch [27/50], Step [215/735], Loss: 0.2720\n",
      "Epoch [27/50], Step [216/735], Loss: 0.0857\n",
      "Epoch [27/50], Step [217/735], Loss: 0.1612\n",
      "Epoch [27/50], Step [218/735], Loss: 0.0979\n",
      "Epoch [27/50], Step [219/735], Loss: 0.1240\n",
      "Epoch [27/50], Step [220/735], Loss: 0.0747\n",
      "Epoch [27/50], Step [221/735], Loss: 0.7139\n",
      "Epoch [27/50], Step [222/735], Loss: 0.1379\n",
      "Epoch [27/50], Step [223/735], Loss: 0.1143\n",
      "Epoch [27/50], Step [224/735], Loss: 0.0741\n",
      "Epoch [27/50], Step [225/735], Loss: 0.1398\n",
      "Epoch [27/50], Step [226/735], Loss: 0.2267\n",
      "Epoch [27/50], Step [227/735], Loss: 0.2775\n",
      "Epoch [27/50], Step [228/735], Loss: 0.1180\n",
      "Epoch [27/50], Step [229/735], Loss: 0.0979\n",
      "Epoch [27/50], Step [230/735], Loss: 0.7764\n",
      "Epoch [27/50], Step [231/735], Loss: 0.0713\n",
      "Epoch [27/50], Step [232/735], Loss: 0.0773\n",
      "Epoch [27/50], Step [233/735], Loss: 0.0992\n",
      "Epoch [27/50], Step [234/735], Loss: 0.0846\n",
      "Epoch [27/50], Step [235/735], Loss: 0.0691\n",
      "Epoch [27/50], Step [236/735], Loss: 0.2097\n",
      "Epoch [27/50], Step [237/735], Loss: 0.1053\n",
      "Epoch [27/50], Step [238/735], Loss: 0.2125\n",
      "Epoch [27/50], Step [239/735], Loss: 0.1032\n",
      "Epoch [27/50], Step [240/735], Loss: 0.0728\n",
      "Epoch [27/50], Step [241/735], Loss: 0.1227\n",
      "Epoch [27/50], Step [242/735], Loss: 0.2474\n",
      "Epoch [27/50], Step [243/735], Loss: 0.1232\n",
      "Epoch [27/50], Step [244/735], Loss: 0.0909\n",
      "Epoch [27/50], Step [245/735], Loss: 0.0487\n",
      "Epoch [27/50], Step [246/735], Loss: 0.0779\n",
      "Epoch [27/50], Step [247/735], Loss: 0.1396\n",
      "Epoch [27/50], Step [248/735], Loss: 0.1417\n",
      "Epoch [27/50], Step [249/735], Loss: 0.1241\n",
      "Epoch [27/50], Step [250/735], Loss: 0.1195\n",
      "Epoch [27/50], Step [251/735], Loss: 0.0602\n",
      "Epoch [27/50], Step [252/735], Loss: 0.3205\n",
      "Epoch [27/50], Step [253/735], Loss: 0.1173\n",
      "Epoch [27/50], Step [254/735], Loss: 0.1153\n",
      "Epoch [27/50], Step [255/735], Loss: 0.0885\n",
      "Epoch [27/50], Step [256/735], Loss: 0.0715\n",
      "Epoch [27/50], Step [257/735], Loss: 0.0518\n",
      "Epoch [27/50], Step [258/735], Loss: 0.1239\n",
      "Epoch [27/50], Step [259/735], Loss: 0.1965\n",
      "Epoch [27/50], Step [260/735], Loss: 0.1924\n",
      "Epoch [27/50], Step [261/735], Loss: 0.1341\n",
      "Epoch [27/50], Step [262/735], Loss: 0.1204\n",
      "Epoch [27/50], Step [263/735], Loss: 0.7548\n",
      "Epoch [27/50], Step [264/735], Loss: 0.0823\n",
      "Epoch [27/50], Step [265/735], Loss: 0.1048\n",
      "Epoch [27/50], Step [266/735], Loss: 0.0635\n",
      "Epoch [27/50], Step [267/735], Loss: 0.3418\n",
      "Epoch [27/50], Step [268/735], Loss: 0.3092\n",
      "Epoch [27/50], Step [269/735], Loss: 0.3896\n",
      "Epoch [27/50], Step [270/735], Loss: 0.0760\n",
      "Epoch [27/50], Step [271/735], Loss: 0.1368\n",
      "Epoch [27/50], Step [272/735], Loss: 0.1670\n",
      "Epoch [27/50], Step [273/735], Loss: 0.1497\n",
      "Epoch [27/50], Step [274/735], Loss: 0.1319\n",
      "Epoch [27/50], Step [275/735], Loss: 0.6498\n",
      "Epoch [27/50], Step [276/735], Loss: 0.1490\n",
      "Epoch [27/50], Step [277/735], Loss: 0.0801\n",
      "Epoch [27/50], Step [278/735], Loss: 0.1826\n",
      "Epoch [27/50], Step [279/735], Loss: 0.0807\n",
      "Epoch [27/50], Step [280/735], Loss: 0.1024\n",
      "Epoch [27/50], Step [281/735], Loss: 0.2581\n",
      "Epoch [27/50], Step [282/735], Loss: 0.1603\n",
      "Epoch [27/50], Step [283/735], Loss: 0.3138\n",
      "Epoch [27/50], Step [284/735], Loss: 0.0871\n",
      "Epoch [27/50], Step [285/735], Loss: 0.2633\n",
      "Epoch [27/50], Step [286/735], Loss: 0.6949\n",
      "Epoch [27/50], Step [287/735], Loss: 0.0522\n",
      "Epoch [27/50], Step [288/735], Loss: 0.0822\n",
      "Epoch [27/50], Step [289/735], Loss: 0.0894\n",
      "Epoch [27/50], Step [290/735], Loss: 0.1252\n",
      "Epoch [27/50], Step [291/735], Loss: 0.1714\n",
      "Epoch [27/50], Step [292/735], Loss: 0.0762\n",
      "Epoch [27/50], Step [293/735], Loss: 0.0841\n",
      "Epoch [27/50], Step [294/735], Loss: 0.1689\n",
      "Epoch [27/50], Step [295/735], Loss: 2.2183\n",
      "Epoch [27/50], Step [296/735], Loss: 0.0600\n",
      "Epoch [27/50], Step [297/735], Loss: 0.1330\n",
      "Epoch [27/50], Step [298/735], Loss: 0.0721\n",
      "Epoch [27/50], Step [299/735], Loss: 0.0487\n",
      "Epoch [27/50], Step [300/735], Loss: 0.1876\n",
      "Epoch [27/50], Step [301/735], Loss: 0.0634\n",
      "Epoch [27/50], Step [302/735], Loss: 0.2099\n",
      "Epoch [27/50], Step [303/735], Loss: 0.1301\n",
      "Epoch [27/50], Step [304/735], Loss: 0.1415\n",
      "Epoch [27/50], Step [305/735], Loss: 0.1039\n",
      "Epoch [27/50], Step [306/735], Loss: 0.1677\n",
      "Epoch [27/50], Step [307/735], Loss: 0.6552\n",
      "Epoch [27/50], Step [308/735], Loss: 0.1036\n",
      "Epoch [27/50], Step [309/735], Loss: 0.0530\n",
      "Epoch [27/50], Step [310/735], Loss: 0.2355\n",
      "Epoch [27/50], Step [311/735], Loss: 0.4191\n",
      "Epoch [27/50], Step [312/735], Loss: 0.0835\n",
      "Epoch [27/50], Step [313/735], Loss: 0.1079\n",
      "Epoch [27/50], Step [314/735], Loss: 0.1585\n",
      "Epoch [27/50], Step [315/735], Loss: 0.0713\n",
      "Epoch [27/50], Step [316/735], Loss: 0.6861\n",
      "Epoch [27/50], Step [317/735], Loss: 0.0442\n",
      "Epoch [27/50], Step [318/735], Loss: 0.0716\n",
      "Epoch [27/50], Step [319/735], Loss: 0.1201\n",
      "Epoch [27/50], Step [320/735], Loss: 0.0899\n",
      "Epoch [27/50], Step [321/735], Loss: 0.0785\n",
      "Epoch [27/50], Step [322/735], Loss: 0.0991\n",
      "Epoch [27/50], Step [323/735], Loss: 0.3035\n",
      "Epoch [27/50], Step [324/735], Loss: 0.0791\n",
      "Epoch [27/50], Step [325/735], Loss: 0.0874\n",
      "Epoch [27/50], Step [326/735], Loss: 0.0927\n",
      "Epoch [27/50], Step [327/735], Loss: 0.1442\n",
      "Epoch [27/50], Step [328/735], Loss: 0.1254\n",
      "Epoch [27/50], Step [329/735], Loss: 0.0570\n",
      "Epoch [27/50], Step [330/735], Loss: 0.1379\n",
      "Epoch [27/50], Step [331/735], Loss: 0.0595\n",
      "Epoch [27/50], Step [332/735], Loss: 0.0488\n",
      "Epoch [27/50], Step [333/735], Loss: 0.0256\n",
      "Epoch [27/50], Step [334/735], Loss: 0.1068\n",
      "Epoch [27/50], Step [335/735], Loss: 0.0618\n",
      "Epoch [27/50], Step [336/735], Loss: 0.1298\n",
      "Epoch [27/50], Step [337/735], Loss: 0.1049\n",
      "Epoch [27/50], Step [338/735], Loss: 0.2714\n",
      "Epoch [27/50], Step [339/735], Loss: 0.1913\n",
      "Epoch [27/50], Step [340/735], Loss: 0.1439\n",
      "Epoch [27/50], Step [341/735], Loss: 0.0535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Step [342/735], Loss: 0.0457\n",
      "Epoch [27/50], Step [343/735], Loss: 0.4388\n",
      "Epoch [27/50], Step [344/735], Loss: 0.2358\n",
      "Epoch [27/50], Step [345/735], Loss: 0.0951\n",
      "Epoch [27/50], Step [346/735], Loss: 0.0863\n",
      "Epoch [27/50], Step [347/735], Loss: 0.1539\n",
      "Epoch [27/50], Step [348/735], Loss: 0.2304\n",
      "Epoch [27/50], Step [349/735], Loss: 0.2037\n",
      "Epoch [27/50], Step [350/735], Loss: 0.0818\n",
      "Epoch [27/50], Step [351/735], Loss: 0.0644\n",
      "Epoch [27/50], Step [352/735], Loss: 0.1360\n",
      "Epoch [27/50], Step [353/735], Loss: 0.0943\n",
      "Epoch [27/50], Step [354/735], Loss: 0.1153\n",
      "Epoch [27/50], Step [355/735], Loss: 0.1503\n",
      "Epoch [27/50], Step [356/735], Loss: 0.0558\n",
      "Epoch [27/50], Step [357/735], Loss: 0.0420\n",
      "Epoch [27/50], Step [358/735], Loss: 0.1652\n",
      "Epoch [27/50], Step [359/735], Loss: 0.0754\n",
      "Epoch [27/50], Step [360/735], Loss: 0.1078\n",
      "Epoch [27/50], Step [361/735], Loss: 0.0951\n",
      "Epoch [27/50], Step [362/735], Loss: 0.0742\n",
      "Epoch [27/50], Step [363/735], Loss: 0.1815\n",
      "Epoch [27/50], Step [364/735], Loss: 0.2499\n",
      "Epoch [27/50], Step [365/735], Loss: 0.0783\n",
      "Epoch [27/50], Step [366/735], Loss: 0.1078\n",
      "Epoch [27/50], Step [367/735], Loss: 0.1546\n",
      "Epoch [27/50], Step [368/735], Loss: 0.2290\n",
      "Epoch [27/50], Step [369/735], Loss: 0.0615\n",
      "Epoch [27/50], Step [370/735], Loss: 0.6323\n",
      "Epoch [27/50], Step [371/735], Loss: 0.2238\n",
      "Epoch [27/50], Step [372/735], Loss: 0.0697\n",
      "Epoch [27/50], Step [373/735], Loss: 0.2546\n",
      "Epoch [27/50], Step [374/735], Loss: 0.7238\n",
      "Epoch [27/50], Step [375/735], Loss: 0.0434\n",
      "Epoch [27/50], Step [376/735], Loss: 0.0443\n",
      "Epoch [27/50], Step [377/735], Loss: 0.1808\n",
      "Epoch [27/50], Step [378/735], Loss: 0.1092\n",
      "Epoch [27/50], Step [379/735], Loss: 0.1990\n",
      "Epoch [27/50], Step [380/735], Loss: 0.0925\n",
      "Epoch [27/50], Step [381/735], Loss: 0.0793\n",
      "Epoch [27/50], Step [382/735], Loss: 0.1037\n",
      "Epoch [27/50], Step [383/735], Loss: 1.0216\n",
      "Epoch [27/50], Step [384/735], Loss: 0.0975\n",
      "Epoch [27/50], Step [385/735], Loss: 0.1223\n",
      "Epoch [27/50], Step [386/735], Loss: 0.0897\n",
      "Epoch [27/50], Step [387/735], Loss: 0.1368\n",
      "Epoch [27/50], Step [388/735], Loss: 0.1640\n",
      "Epoch [27/50], Step [389/735], Loss: 0.1070\n",
      "Epoch [27/50], Step [390/735], Loss: 0.0881\n",
      "Epoch [27/50], Step [391/735], Loss: 0.0905\n",
      "Epoch [27/50], Step [392/735], Loss: 0.1666\n",
      "Epoch [27/50], Step [393/735], Loss: 0.2590\n",
      "Epoch [27/50], Step [394/735], Loss: 0.1580\n",
      "Epoch [27/50], Step [395/735], Loss: 0.1919\n",
      "Epoch [27/50], Step [396/735], Loss: 0.0684\n",
      "Epoch [27/50], Step [397/735], Loss: 0.1149\n",
      "Epoch [27/50], Step [398/735], Loss: 0.0911\n",
      "Epoch [27/50], Step [399/735], Loss: 0.0627\n",
      "Epoch [27/50], Step [400/735], Loss: 0.2462\n",
      "Epoch [27/50], Step [401/735], Loss: 0.0915\n",
      "Epoch [27/50], Step [402/735], Loss: 0.1985\n",
      "Epoch [27/50], Step [403/735], Loss: 0.1077\n",
      "Epoch [27/50], Step [404/735], Loss: 0.3558\n",
      "Epoch [27/50], Step [405/735], Loss: 0.1082\n",
      "Epoch [27/50], Step [406/735], Loss: 0.0467\n",
      "Epoch [27/50], Step [407/735], Loss: 0.0961\n",
      "Epoch [27/50], Step [408/735], Loss: 0.1330\n",
      "Epoch [27/50], Step [409/735], Loss: 0.1350\n",
      "Epoch [27/50], Step [410/735], Loss: 0.0828\n",
      "Epoch [27/50], Step [411/735], Loss: 0.0628\n",
      "Epoch [27/50], Step [412/735], Loss: 0.2797\n",
      "Epoch [27/50], Step [413/735], Loss: 0.3041\n",
      "Epoch [27/50], Step [414/735], Loss: 0.0870\n",
      "Epoch [27/50], Step [415/735], Loss: 0.0757\n",
      "Epoch [27/50], Step [416/735], Loss: 0.0651\n",
      "Epoch [27/50], Step [417/735], Loss: 0.2322\n",
      "Epoch [27/50], Step [418/735], Loss: 0.0938\n",
      "Epoch [27/50], Step [419/735], Loss: 0.3191\n",
      "Epoch [27/50], Step [420/735], Loss: 0.0932\n",
      "Epoch [27/50], Step [421/735], Loss: 0.1140\n",
      "Epoch [27/50], Step [422/735], Loss: 0.0452\n",
      "Epoch [27/50], Step [423/735], Loss: 0.0662\n",
      "Epoch [27/50], Step [424/735], Loss: 0.0365\n",
      "Epoch [27/50], Step [425/735], Loss: 0.0682\n",
      "Epoch [27/50], Step [426/735], Loss: 0.1283\n",
      "Epoch [27/50], Step [427/735], Loss: 0.0424\n",
      "Epoch [27/50], Step [428/735], Loss: 0.1872\n",
      "Epoch [27/50], Step [429/735], Loss: 0.1420\n",
      "Epoch [27/50], Step [430/735], Loss: 2.0568\n",
      "Epoch [27/50], Step [431/735], Loss: 0.0510\n",
      "Epoch [27/50], Step [432/735], Loss: 0.0968\n",
      "Epoch [27/50], Step [433/735], Loss: 0.0593\n",
      "Epoch [27/50], Step [434/735], Loss: 0.0757\n",
      "Epoch [27/50], Step [435/735], Loss: 0.1402\n",
      "Epoch [27/50], Step [436/735], Loss: 0.1676\n",
      "Epoch [27/50], Step [437/735], Loss: 0.1242\n",
      "Epoch [27/50], Step [438/735], Loss: 0.1800\n",
      "Epoch [27/50], Step [439/735], Loss: 0.0409\n",
      "Epoch [27/50], Step [440/735], Loss: 0.0611\n",
      "Epoch [27/50], Step [441/735], Loss: 0.4980\n",
      "Epoch [27/50], Step [442/735], Loss: 0.0775\n",
      "Epoch [27/50], Step [443/735], Loss: 0.1545\n",
      "Epoch [27/50], Step [444/735], Loss: 0.1010\n",
      "Epoch [27/50], Step [445/735], Loss: 0.0721\n",
      "Epoch [27/50], Step [446/735], Loss: 0.1046\n",
      "Epoch [27/50], Step [447/735], Loss: 0.0630\n",
      "Epoch [27/50], Step [448/735], Loss: 0.4042\n",
      "Epoch [27/50], Step [449/735], Loss: 0.2314\n",
      "Epoch [27/50], Step [450/735], Loss: 0.9944\n",
      "Epoch [27/50], Step [451/735], Loss: 0.1058\n",
      "Epoch [27/50], Step [452/735], Loss: 0.1073\n",
      "Epoch [27/50], Step [453/735], Loss: 0.1510\n",
      "Epoch [27/50], Step [454/735], Loss: 0.1149\n",
      "Epoch [27/50], Step [455/735], Loss: 0.1891\n",
      "Epoch [27/50], Step [456/735], Loss: 0.0864\n",
      "Epoch [27/50], Step [457/735], Loss: 0.1351\n",
      "Epoch [27/50], Step [458/735], Loss: 0.1102\n",
      "Epoch [27/50], Step [459/735], Loss: 0.0594\n",
      "Epoch [27/50], Step [460/735], Loss: 0.0754\n",
      "Epoch [27/50], Step [461/735], Loss: 1.3206\n",
      "Epoch [27/50], Step [462/735], Loss: 0.0406\n",
      "Epoch [27/50], Step [463/735], Loss: 0.0767\n",
      "Epoch [27/50], Step [464/735], Loss: 0.1729\n",
      "Epoch [27/50], Step [465/735], Loss: 0.1499\n",
      "Epoch [27/50], Step [466/735], Loss: 1.1976\n",
      "Epoch [27/50], Step [467/735], Loss: 0.1959\n",
      "Epoch [27/50], Step [468/735], Loss: 0.1916\n",
      "Epoch [27/50], Step [469/735], Loss: 0.1309\n",
      "Epoch [27/50], Step [470/735], Loss: 0.1693\n",
      "Epoch [27/50], Step [471/735], Loss: 0.1042\n",
      "Epoch [27/50], Step [472/735], Loss: 0.0635\n",
      "Epoch [27/50], Step [473/735], Loss: 0.2868\n",
      "Epoch [27/50], Step [474/735], Loss: 0.0508\n",
      "Epoch [27/50], Step [475/735], Loss: 0.1185\n",
      "Epoch [27/50], Step [476/735], Loss: 0.0852\n",
      "Epoch [27/50], Step [477/735], Loss: 0.0838\n",
      "Epoch [27/50], Step [478/735], Loss: 0.1282\n",
      "Epoch [27/50], Step [479/735], Loss: 0.0553\n",
      "Epoch [27/50], Step [480/735], Loss: 0.1179\n",
      "Epoch [27/50], Step [481/735], Loss: 0.2649\n",
      "Epoch [27/50], Step [482/735], Loss: 0.1748\n",
      "Epoch [27/50], Step [483/735], Loss: 0.0741\n",
      "Epoch [27/50], Step [484/735], Loss: 0.0620\n",
      "Epoch [27/50], Step [485/735], Loss: 0.0831\n",
      "Epoch [27/50], Step [486/735], Loss: 0.3731\n",
      "Epoch [27/50], Step [487/735], Loss: 0.0536\n",
      "Epoch [27/50], Step [488/735], Loss: 0.1414\n",
      "Epoch [27/50], Step [489/735], Loss: 0.1604\n",
      "Epoch [27/50], Step [490/735], Loss: 0.0662\n",
      "Epoch [27/50], Step [491/735], Loss: 0.0815\n",
      "Epoch [27/50], Step [492/735], Loss: 0.1989\n",
      "Epoch [27/50], Step [493/735], Loss: 0.0667\n",
      "Epoch [27/50], Step [494/735], Loss: 0.2483\n",
      "Epoch [27/50], Step [495/735], Loss: 0.1604\n",
      "Epoch [27/50], Step [496/735], Loss: 0.1313\n",
      "Epoch [27/50], Step [497/735], Loss: 0.0338\n",
      "Epoch [27/50], Step [498/735], Loss: 0.0645\n",
      "Epoch [27/50], Step [499/735], Loss: 0.2966\n",
      "Epoch [27/50], Step [500/735], Loss: 0.1728\n",
      "Epoch [27/50], Step [501/735], Loss: 0.2079\n",
      "Epoch [27/50], Step [502/735], Loss: 0.1867\n",
      "Epoch [27/50], Step [503/735], Loss: 0.1600\n",
      "Epoch [27/50], Step [504/735], Loss: 0.0328\n",
      "Epoch [27/50], Step [505/735], Loss: 0.1584\n",
      "Epoch [27/50], Step [506/735], Loss: 0.1144\n",
      "Epoch [27/50], Step [507/735], Loss: 0.0301\n",
      "Epoch [27/50], Step [508/735], Loss: 0.2321\n",
      "Epoch [27/50], Step [509/735], Loss: 0.2417\n",
      "Epoch [27/50], Step [510/735], Loss: 0.1126\n",
      "Epoch [27/50], Step [511/735], Loss: 0.0977\n",
      "Epoch [27/50], Step [512/735], Loss: 0.0538\n",
      "Epoch [27/50], Step [513/735], Loss: 0.0323\n",
      "Epoch [27/50], Step [514/735], Loss: 0.1352\n",
      "Epoch [27/50], Step [515/735], Loss: 0.0535\n",
      "Epoch [27/50], Step [516/735], Loss: 0.1706\n",
      "Epoch [27/50], Step [517/735], Loss: 0.1130\n",
      "Epoch [27/50], Step [518/735], Loss: 0.0972\n",
      "Epoch [27/50], Step [519/735], Loss: 0.0558\n",
      "Epoch [27/50], Step [520/735], Loss: 0.0617\n",
      "Epoch [27/50], Step [521/735], Loss: 0.0733\n",
      "Epoch [27/50], Step [522/735], Loss: 0.1763\n",
      "Epoch [27/50], Step [523/735], Loss: 0.1039\n",
      "Epoch [27/50], Step [524/735], Loss: 0.1493\n",
      "Epoch [27/50], Step [525/735], Loss: 0.0771\n",
      "Epoch [27/50], Step [526/735], Loss: 0.1859\n",
      "Epoch [27/50], Step [527/735], Loss: 0.0455\n",
      "Epoch [27/50], Step [528/735], Loss: 0.1930\n",
      "Epoch [27/50], Step [529/735], Loss: 0.0602\n",
      "Epoch [27/50], Step [530/735], Loss: 0.0854\n",
      "Epoch [27/50], Step [531/735], Loss: 0.0439\n",
      "Epoch [27/50], Step [532/735], Loss: 0.2144\n",
      "Epoch [27/50], Step [533/735], Loss: 0.0973\n",
      "Epoch [27/50], Step [534/735], Loss: 0.2347\n",
      "Epoch [27/50], Step [535/735], Loss: 0.1014\n",
      "Epoch [27/50], Step [536/735], Loss: 0.0729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Step [537/735], Loss: 0.1199\n",
      "Epoch [27/50], Step [538/735], Loss: 0.1572\n",
      "Epoch [27/50], Step [539/735], Loss: 1.2734\n",
      "Epoch [27/50], Step [540/735], Loss: 0.2892\n",
      "Epoch [27/50], Step [541/735], Loss: 0.0972\n",
      "Epoch [27/50], Step [542/735], Loss: 0.0979\n",
      "Epoch [27/50], Step [543/735], Loss: 0.0689\n",
      "Epoch [27/50], Step [544/735], Loss: 0.0449\n",
      "Epoch [27/50], Step [545/735], Loss: 0.2629\n",
      "Epoch [27/50], Step [546/735], Loss: 0.1371\n",
      "Epoch [27/50], Step [547/735], Loss: 0.1632\n",
      "Epoch [27/50], Step [548/735], Loss: 0.0972\n",
      "Epoch [27/50], Step [549/735], Loss: 0.0933\n",
      "Epoch [27/50], Step [550/735], Loss: 0.0987\n",
      "Epoch [27/50], Step [551/735], Loss: 0.0668\n",
      "Epoch [27/50], Step [552/735], Loss: 0.1477\n",
      "Epoch [27/50], Step [553/735], Loss: 0.0504\n",
      "Epoch [27/50], Step [554/735], Loss: 0.0598\n",
      "Epoch [27/50], Step [555/735], Loss: 0.2434\n",
      "Epoch [27/50], Step [556/735], Loss: 0.0762\n",
      "Epoch [27/50], Step [557/735], Loss: 0.0769\n",
      "Epoch [27/50], Step [558/735], Loss: 0.3479\n",
      "Epoch [27/50], Step [559/735], Loss: 0.0732\n",
      "Epoch [27/50], Step [560/735], Loss: 0.4349\n",
      "Epoch [27/50], Step [561/735], Loss: 0.0475\n",
      "Epoch [27/50], Step [562/735], Loss: 0.0784\n",
      "Epoch [27/50], Step [563/735], Loss: 0.0759\n",
      "Epoch [27/50], Step [564/735], Loss: 0.0720\n",
      "Epoch [27/50], Step [565/735], Loss: 0.2247\n",
      "Epoch [27/50], Step [566/735], Loss: 0.0965\n",
      "Epoch [27/50], Step [567/735], Loss: 0.0563\n",
      "Epoch [27/50], Step [568/735], Loss: 0.0798\n",
      "Epoch [27/50], Step [569/735], Loss: 0.1395\n",
      "Epoch [27/50], Step [570/735], Loss: 0.2395\n",
      "Epoch [27/50], Step [571/735], Loss: 0.0501\n",
      "Epoch [27/50], Step [572/735], Loss: 0.2590\n",
      "Epoch [27/50], Step [573/735], Loss: 0.0618\n",
      "Epoch [27/50], Step [574/735], Loss: 0.1344\n",
      "Epoch [27/50], Step [575/735], Loss: 0.1383\n",
      "Epoch [27/50], Step [576/735], Loss: 0.3868\n",
      "Epoch [27/50], Step [577/735], Loss: 0.1322\n",
      "Epoch [27/50], Step [578/735], Loss: 0.0438\n",
      "Epoch [27/50], Step [579/735], Loss: 0.6045\n",
      "Epoch [27/50], Step [580/735], Loss: 0.0687\n",
      "Epoch [27/50], Step [581/735], Loss: 0.0455\n",
      "Epoch [27/50], Step [582/735], Loss: 0.1804\n",
      "Epoch [27/50], Step [583/735], Loss: 0.0759\n",
      "Epoch [27/50], Step [584/735], Loss: 0.0832\n",
      "Epoch [27/50], Step [585/735], Loss: 0.0629\n",
      "Epoch [27/50], Step [586/735], Loss: 0.1147\n",
      "Epoch [27/50], Step [587/735], Loss: 0.0616\n",
      "Epoch [27/50], Step [588/735], Loss: 0.0787\n",
      "Epoch [27/50], Step [589/735], Loss: 0.2670\n",
      "Epoch [27/50], Step [590/735], Loss: 0.0733\n",
      "Epoch [27/50], Step [591/735], Loss: 0.4800\n",
      "Epoch [27/50], Step [592/735], Loss: 1.8591\n",
      "Epoch [27/50], Step [593/735], Loss: 0.1273\n",
      "Epoch [27/50], Step [594/735], Loss: 0.0922\n",
      "Epoch [27/50], Step [595/735], Loss: 0.0941\n",
      "Epoch [27/50], Step [596/735], Loss: 0.1962\n",
      "Epoch [27/50], Step [597/735], Loss: 0.2075\n",
      "Epoch [27/50], Step [598/735], Loss: 0.3241\n",
      "Epoch [27/50], Step [599/735], Loss: 0.1421\n",
      "Epoch [27/50], Step [600/735], Loss: 0.1404\n",
      "Epoch [27/50], Step [601/735], Loss: 0.0403\n",
      "Epoch [27/50], Step [602/735], Loss: 0.3747\n",
      "Epoch [27/50], Step [603/735], Loss: 0.0812\n",
      "Epoch [27/50], Step [604/735], Loss: 0.1554\n",
      "Epoch [27/50], Step [605/735], Loss: 0.1260\n",
      "Epoch [27/50], Step [606/735], Loss: 0.1036\n",
      "Epoch [27/50], Step [607/735], Loss: 0.1087\n",
      "Epoch [27/50], Step [608/735], Loss: 0.1633\n",
      "Epoch [27/50], Step [609/735], Loss: 0.1164\n",
      "Epoch [27/50], Step [610/735], Loss: 0.1782\n",
      "Epoch [27/50], Step [611/735], Loss: 0.2156\n",
      "Epoch [27/50], Step [612/735], Loss: 0.1090\n",
      "Epoch [27/50], Step [613/735], Loss: 0.2733\n",
      "Epoch [27/50], Step [614/735], Loss: 0.1545\n",
      "Epoch [27/50], Step [615/735], Loss: 0.2316\n",
      "Epoch [27/50], Step [616/735], Loss: 0.1822\n",
      "Epoch [27/50], Step [617/735], Loss: 0.1463\n",
      "Epoch [27/50], Step [618/735], Loss: 1.9300\n",
      "Epoch [27/50], Step [619/735], Loss: 0.1018\n",
      "Epoch [27/50], Step [620/735], Loss: 0.2101\n",
      "Epoch [27/50], Step [621/735], Loss: 0.5150\n",
      "Epoch [27/50], Step [622/735], Loss: 0.0741\n",
      "Epoch [27/50], Step [623/735], Loss: 0.3065\n",
      "Epoch [27/50], Step [624/735], Loss: 0.1946\n",
      "Epoch [27/50], Step [625/735], Loss: 0.0395\n",
      "Epoch [27/50], Step [626/735], Loss: 0.0554\n",
      "Epoch [27/50], Step [627/735], Loss: 0.0689\n",
      "Epoch [27/50], Step [628/735], Loss: 0.1460\n",
      "Epoch [27/50], Step [629/735], Loss: 0.2359\n",
      "Epoch [27/50], Step [630/735], Loss: 0.1176\n",
      "Epoch [27/50], Step [631/735], Loss: 0.1626\n",
      "Epoch [27/50], Step [632/735], Loss: 0.0769\n",
      "Epoch [27/50], Step [633/735], Loss: 0.2945\n",
      "Epoch [27/50], Step [634/735], Loss: 0.0830\n",
      "Epoch [27/50], Step [635/735], Loss: 0.1372\n",
      "Epoch [27/50], Step [636/735], Loss: 0.2115\n",
      "Epoch [27/50], Step [637/735], Loss: 0.0724\n",
      "Epoch [27/50], Step [638/735], Loss: 0.2469\n",
      "Epoch [27/50], Step [639/735], Loss: 0.0444\n",
      "Epoch [27/50], Step [640/735], Loss: 0.0595\n",
      "Epoch [27/50], Step [641/735], Loss: 0.5969\n",
      "Epoch [27/50], Step [642/735], Loss: 0.1058\n",
      "Epoch [27/50], Step [643/735], Loss: 0.0855\n",
      "Epoch [27/50], Step [644/735], Loss: 0.6734\n",
      "Epoch [27/50], Step [645/735], Loss: 0.1907\n",
      "Epoch [27/50], Step [646/735], Loss: 0.1884\n",
      "Epoch [27/50], Step [647/735], Loss: 0.0560\n",
      "Epoch [27/50], Step [648/735], Loss: 0.1495\n",
      "Epoch [27/50], Step [649/735], Loss: 0.0756\n",
      "Epoch [27/50], Step [650/735], Loss: 0.0820\n",
      "Epoch [27/50], Step [651/735], Loss: 0.0632\n",
      "Epoch [27/50], Step [652/735], Loss: 0.2025\n",
      "Epoch [27/50], Step [653/735], Loss: 0.1079\n",
      "Epoch [27/50], Step [654/735], Loss: 0.2196\n",
      "Epoch [27/50], Step [655/735], Loss: 0.0277\n",
      "Epoch [27/50], Step [656/735], Loss: 0.1083\n",
      "Epoch [27/50], Step [657/735], Loss: 0.2146\n",
      "Epoch [27/50], Step [658/735], Loss: 0.1615\n",
      "Epoch [27/50], Step [659/735], Loss: 0.1133\n",
      "Epoch [27/50], Step [660/735], Loss: 0.2993\n",
      "Epoch [27/50], Step [661/735], Loss: 0.1267\n",
      "Epoch [27/50], Step [662/735], Loss: 0.1698\n",
      "Epoch [27/50], Step [663/735], Loss: 0.1213\n",
      "Epoch [27/50], Step [664/735], Loss: 0.2408\n",
      "Epoch [27/50], Step [665/735], Loss: 0.2280\n",
      "Epoch [27/50], Step [666/735], Loss: 0.2342\n",
      "Epoch [27/50], Step [667/735], Loss: 0.8564\n",
      "Epoch [27/50], Step [668/735], Loss: 0.0992\n",
      "Epoch [27/50], Step [669/735], Loss: 0.2030\n",
      "Epoch [27/50], Step [670/735], Loss: 0.2237\n",
      "Epoch [27/50], Step [671/735], Loss: 0.1128\n",
      "Epoch [27/50], Step [672/735], Loss: 0.2108\n",
      "Epoch [27/50], Step [673/735], Loss: 0.1335\n",
      "Epoch [27/50], Step [674/735], Loss: 0.0967\n",
      "Epoch [27/50], Step [675/735], Loss: 0.1466\n",
      "Epoch [27/50], Step [676/735], Loss: 0.1343\n",
      "Epoch [27/50], Step [677/735], Loss: 0.3848\n",
      "Epoch [27/50], Step [678/735], Loss: 0.0777\n",
      "Epoch [27/50], Step [679/735], Loss: 0.1163\n",
      "Epoch [27/50], Step [680/735], Loss: 0.0808\n",
      "Epoch [27/50], Step [681/735], Loss: 0.0851\n",
      "Epoch [27/50], Step [682/735], Loss: 0.3732\n",
      "Epoch [27/50], Step [683/735], Loss: 0.0701\n",
      "Epoch [27/50], Step [684/735], Loss: 0.2616\n",
      "Epoch [27/50], Step [685/735], Loss: 0.0583\n",
      "Epoch [27/50], Step [686/735], Loss: 0.0910\n",
      "Epoch [27/50], Step [687/735], Loss: 0.1742\n",
      "Epoch [27/50], Step [688/735], Loss: 0.1032\n",
      "Epoch [27/50], Step [689/735], Loss: 0.0882\n",
      "Epoch [27/50], Step [690/735], Loss: 0.1095\n",
      "Epoch [27/50], Step [691/735], Loss: 0.7969\n",
      "Epoch [27/50], Step [692/735], Loss: 0.0907\n",
      "Epoch [27/50], Step [693/735], Loss: 0.0869\n",
      "Epoch [27/50], Step [694/735], Loss: 0.0492\n",
      "Epoch [27/50], Step [695/735], Loss: 0.7124\n",
      "Epoch [27/50], Step [696/735], Loss: 0.1133\n",
      "Epoch [27/50], Step [697/735], Loss: 0.1050\n",
      "Epoch [27/50], Step [698/735], Loss: 0.1401\n",
      "Epoch [27/50], Step [699/735], Loss: 0.1066\n",
      "Epoch [27/50], Step [700/735], Loss: 0.0776\n",
      "Epoch [27/50], Step [701/735], Loss: 0.1220\n",
      "Epoch [27/50], Step [702/735], Loss: 0.1385\n",
      "Epoch [27/50], Step [703/735], Loss: 0.0648\n",
      "Epoch [27/50], Step [704/735], Loss: 0.1953\n",
      "Epoch [27/50], Step [705/735], Loss: 0.2078\n",
      "Epoch [27/50], Step [706/735], Loss: 0.1096\n",
      "Epoch [27/50], Step [707/735], Loss: 0.2104\n",
      "Epoch [27/50], Step [708/735], Loss: 0.0778\n",
      "Epoch [27/50], Step [709/735], Loss: 0.2498\n",
      "Epoch [27/50], Step [710/735], Loss: 0.1493\n",
      "Epoch [27/50], Step [711/735], Loss: 0.1868\n",
      "Epoch [27/50], Step [712/735], Loss: 0.7711\n",
      "Epoch [27/50], Step [713/735], Loss: 0.1899\n",
      "Epoch [27/50], Step [714/735], Loss: 0.0831\n",
      "Epoch [27/50], Step [715/735], Loss: 0.1563\n",
      "Epoch [27/50], Step [716/735], Loss: 0.3019\n",
      "Epoch [27/50], Step [717/735], Loss: 0.1220\n",
      "Epoch [27/50], Step [718/735], Loss: 0.0883\n",
      "Epoch [27/50], Step [719/735], Loss: 0.5614\n",
      "Epoch [27/50], Step [720/735], Loss: 0.1223\n",
      "Epoch [27/50], Step [721/735], Loss: 0.0895\n",
      "Epoch [27/50], Step [722/735], Loss: 0.1100\n",
      "Epoch [27/50], Step [723/735], Loss: 0.0714\n",
      "Epoch [27/50], Step [724/735], Loss: 0.1182\n",
      "Epoch [27/50], Step [725/735], Loss: 0.0747\n",
      "Epoch [27/50], Step [726/735], Loss: 0.1250\n",
      "Epoch [27/50], Step [727/735], Loss: 0.0612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Step [728/735], Loss: 0.1355\n",
      "Epoch [27/50], Step [729/735], Loss: 0.2715\n",
      "Epoch [27/50], Step [730/735], Loss: 0.1223\n",
      "Epoch [27/50], Step [731/735], Loss: 0.1482\n",
      "Epoch [27/50], Step [732/735], Loss: 0.1293\n",
      "Epoch [27/50], Step [733/735], Loss: 0.1349\n",
      "Epoch [27/50], Step [734/735], Loss: 0.7637\n",
      "Epoch [27/50], Step [735/735], Loss: 0.0452\n",
      "Epoch [28/50], Step [1/735], Loss: 0.1503\n",
      "Epoch [28/50], Step [2/735], Loss: 0.0826\n",
      "Epoch [28/50], Step [3/735], Loss: 0.1548\n",
      "Epoch [28/50], Step [4/735], Loss: 0.0598\n",
      "Epoch [28/50], Step [5/735], Loss: 0.0662\n",
      "Epoch [28/50], Step [6/735], Loss: 0.0546\n",
      "Epoch [28/50], Step [7/735], Loss: 0.1217\n",
      "Epoch [28/50], Step [8/735], Loss: 0.0800\n",
      "Epoch [28/50], Step [9/735], Loss: 0.4588\n",
      "Epoch [28/50], Step [10/735], Loss: 0.0449\n",
      "Epoch [28/50], Step [11/735], Loss: 0.1214\n",
      "Epoch [28/50], Step [12/735], Loss: 0.1016\n",
      "Epoch [28/50], Step [13/735], Loss: 0.0856\n",
      "Epoch [28/50], Step [14/735], Loss: 0.2968\n",
      "Epoch [28/50], Step [15/735], Loss: 0.0875\n",
      "Epoch [28/50], Step [16/735], Loss: 0.3702\n",
      "Epoch [28/50], Step [17/735], Loss: 0.0741\n",
      "Epoch [28/50], Step [18/735], Loss: 0.1089\n",
      "Epoch [28/50], Step [19/735], Loss: 0.5299\n",
      "Epoch [28/50], Step [20/735], Loss: 0.1445\n",
      "Epoch [28/50], Step [21/735], Loss: 0.0619\n",
      "Epoch [28/50], Step [22/735], Loss: 0.0823\n",
      "Epoch [28/50], Step [23/735], Loss: 0.0720\n",
      "Epoch [28/50], Step [24/735], Loss: 0.0723\n",
      "Epoch [28/50], Step [25/735], Loss: 0.0992\n",
      "Epoch [28/50], Step [26/735], Loss: 0.2536\n",
      "Epoch [28/50], Step [27/735], Loss: 0.0862\n",
      "Epoch [28/50], Step [28/735], Loss: 0.2494\n",
      "Epoch [28/50], Step [29/735], Loss: 0.1055\n",
      "Epoch [28/50], Step [30/735], Loss: 0.0991\n",
      "Epoch [28/50], Step [31/735], Loss: 0.1986\n",
      "Epoch [28/50], Step [32/735], Loss: 0.0641\n",
      "Epoch [28/50], Step [33/735], Loss: 0.1528\n",
      "Epoch [28/50], Step [34/735], Loss: 0.7174\n",
      "Epoch [28/50], Step [35/735], Loss: 0.0475\n",
      "Epoch [28/50], Step [36/735], Loss: 0.0980\n",
      "Epoch [28/50], Step [37/735], Loss: 0.0947\n",
      "Epoch [28/50], Step [38/735], Loss: 0.0606\n",
      "Epoch [28/50], Step [39/735], Loss: 0.1225\n",
      "Epoch [28/50], Step [40/735], Loss: 0.0615\n",
      "Epoch [28/50], Step [41/735], Loss: 0.1571\n",
      "Epoch [28/50], Step [42/735], Loss: 0.1795\n",
      "Epoch [28/50], Step [43/735], Loss: 0.0687\n",
      "Epoch [28/50], Step [44/735], Loss: 0.2716\n",
      "Epoch [28/50], Step [45/735], Loss: 0.0690\n",
      "Epoch [28/50], Step [46/735], Loss: 0.1166\n",
      "Epoch [28/50], Step [47/735], Loss: 0.1469\n",
      "Epoch [28/50], Step [48/735], Loss: 0.1765\n",
      "Epoch [28/50], Step [49/735], Loss: 0.0949\n",
      "Epoch [28/50], Step [50/735], Loss: 0.0898\n",
      "Epoch [28/50], Step [51/735], Loss: 0.2704\n",
      "Epoch [28/50], Step [52/735], Loss: 0.1192\n",
      "Epoch [28/50], Step [53/735], Loss: 0.1118\n",
      "Epoch [28/50], Step [54/735], Loss: 0.1550\n",
      "Epoch [28/50], Step [55/735], Loss: 0.1086\n",
      "Epoch [28/50], Step [56/735], Loss: 0.0612\n",
      "Epoch [28/50], Step [57/735], Loss: 0.0887\n",
      "Epoch [28/50], Step [58/735], Loss: 0.1932\n",
      "Epoch [28/50], Step [59/735], Loss: 0.1036\n",
      "Epoch [28/50], Step [60/735], Loss: 0.0442\n",
      "Epoch [28/50], Step [61/735], Loss: 0.2444\n",
      "Epoch [28/50], Step [62/735], Loss: 0.1242\n",
      "Epoch [28/50], Step [63/735], Loss: 0.2012\n",
      "Epoch [28/50], Step [64/735], Loss: 1.0409\n",
      "Epoch [28/50], Step [65/735], Loss: 0.1210\n",
      "Epoch [28/50], Step [66/735], Loss: 0.1760\n",
      "Epoch [28/50], Step [67/735], Loss: 0.0818\n",
      "Epoch [28/50], Step [68/735], Loss: 0.1410\n",
      "Epoch [28/50], Step [69/735], Loss: 0.1366\n",
      "Epoch [28/50], Step [70/735], Loss: 0.0760\n",
      "Epoch [28/50], Step [71/735], Loss: 0.0929\n",
      "Epoch [28/50], Step [72/735], Loss: 0.6125\n",
      "Epoch [28/50], Step [73/735], Loss: 0.1446\n",
      "Epoch [28/50], Step [74/735], Loss: 0.1006\n",
      "Epoch [28/50], Step [75/735], Loss: 0.0639\n",
      "Epoch [28/50], Step [76/735], Loss: 0.2017\n",
      "Epoch [28/50], Step [77/735], Loss: 0.0819\n",
      "Epoch [28/50], Step [78/735], Loss: 0.0852\n",
      "Epoch [28/50], Step [79/735], Loss: 0.0986\n",
      "Epoch [28/50], Step [80/735], Loss: 0.0555\n",
      "Epoch [28/50], Step [81/735], Loss: 0.0821\n",
      "Epoch [28/50], Step [82/735], Loss: 0.0697\n",
      "Epoch [28/50], Step [83/735], Loss: 0.1469\n",
      "Epoch [28/50], Step [84/735], Loss: 0.1636\n",
      "Epoch [28/50], Step [85/735], Loss: 0.1457\n",
      "Epoch [28/50], Step [86/735], Loss: 0.1341\n",
      "Epoch [28/50], Step [87/735], Loss: 0.0651\n",
      "Epoch [28/50], Step [88/735], Loss: 0.0731\n",
      "Epoch [28/50], Step [89/735], Loss: 0.0633\n",
      "Epoch [28/50], Step [90/735], Loss: 0.0903\n",
      "Epoch [28/50], Step [91/735], Loss: 0.1747\n",
      "Epoch [28/50], Step [92/735], Loss: 0.1188\n",
      "Epoch [28/50], Step [93/735], Loss: 0.1655\n",
      "Epoch [28/50], Step [94/735], Loss: 0.1040\n",
      "Epoch [28/50], Step [95/735], Loss: 0.5963\n",
      "Epoch [28/50], Step [96/735], Loss: 0.0561\n",
      "Epoch [28/50], Step [97/735], Loss: 0.1469\n",
      "Epoch [28/50], Step [98/735], Loss: 1.5188\n",
      "Epoch [28/50], Step [99/735], Loss: 0.1320\n",
      "Epoch [28/50], Step [100/735], Loss: 0.2830\n",
      "Epoch [28/50], Step [101/735], Loss: 0.0669\n",
      "Epoch [28/50], Step [102/735], Loss: 0.0852\n",
      "Epoch [28/50], Step [103/735], Loss: 0.6962\n",
      "Epoch [28/50], Step [104/735], Loss: 0.1599\n",
      "Epoch [28/50], Step [105/735], Loss: 0.1178\n",
      "Epoch [28/50], Step [106/735], Loss: 0.1215\n",
      "Epoch [28/50], Step [107/735], Loss: 0.1068\n",
      "Epoch [28/50], Step [108/735], Loss: 0.1363\n",
      "Epoch [28/50], Step [109/735], Loss: 0.7147\n",
      "Epoch [28/50], Step [110/735], Loss: 0.0844\n",
      "Epoch [28/50], Step [111/735], Loss: 0.0689\n",
      "Epoch [28/50], Step [112/735], Loss: 0.5936\n",
      "Epoch [28/50], Step [113/735], Loss: 0.2868\n",
      "Epoch [28/50], Step [114/735], Loss: 0.1575\n",
      "Epoch [28/50], Step [115/735], Loss: 0.0518\n",
      "Epoch [28/50], Step [116/735], Loss: 0.1036\n",
      "Epoch [28/50], Step [117/735], Loss: 0.1168\n",
      "Epoch [28/50], Step [118/735], Loss: 0.0528\n",
      "Epoch [28/50], Step [119/735], Loss: 0.5857\n",
      "Epoch [28/50], Step [120/735], Loss: 0.8518\n",
      "Epoch [28/50], Step [121/735], Loss: 0.5326\n",
      "Epoch [28/50], Step [122/735], Loss: 0.0795\n",
      "Epoch [28/50], Step [123/735], Loss: 0.1669\n",
      "Epoch [28/50], Step [124/735], Loss: 0.1201\n",
      "Epoch [28/50], Step [125/735], Loss: 0.1027\n",
      "Epoch [28/50], Step [126/735], Loss: 0.1046\n",
      "Epoch [28/50], Step [127/735], Loss: 0.1827\n",
      "Epoch [28/50], Step [128/735], Loss: 0.0386\n",
      "Epoch [28/50], Step [129/735], Loss: 0.0704\n",
      "Epoch [28/50], Step [130/735], Loss: 0.3864\n",
      "Epoch [28/50], Step [131/735], Loss: 0.1471\n",
      "Epoch [28/50], Step [132/735], Loss: 0.1447\n",
      "Epoch [28/50], Step [133/735], Loss: 0.1028\n",
      "Epoch [28/50], Step [134/735], Loss: 0.0717\n",
      "Epoch [28/50], Step [135/735], Loss: 0.0781\n",
      "Epoch [28/50], Step [136/735], Loss: 0.0661\n",
      "Epoch [28/50], Step [137/735], Loss: 0.1532\n",
      "Epoch [28/50], Step [138/735], Loss: 0.1963\n",
      "Epoch [28/50], Step [139/735], Loss: 0.1581\n",
      "Epoch [28/50], Step [140/735], Loss: 0.1136\n",
      "Epoch [28/50], Step [141/735], Loss: 0.0778\n",
      "Epoch [28/50], Step [142/735], Loss: 0.0286\n",
      "Epoch [28/50], Step [143/735], Loss: 0.2328\n",
      "Epoch [28/50], Step [144/735], Loss: 0.1358\n",
      "Epoch [28/50], Step [145/735], Loss: 0.1132\n",
      "Epoch [28/50], Step [146/735], Loss: 0.0737\n",
      "Epoch [28/50], Step [147/735], Loss: 0.0649\n",
      "Epoch [28/50], Step [148/735], Loss: 0.0749\n",
      "Epoch [28/50], Step [149/735], Loss: 0.0956\n",
      "Epoch [28/50], Step [150/735], Loss: 0.0725\n",
      "Epoch [28/50], Step [151/735], Loss: 0.2508\n",
      "Epoch [28/50], Step [152/735], Loss: 0.0930\n",
      "Epoch [28/50], Step [153/735], Loss: 0.1593\n",
      "Epoch [28/50], Step [154/735], Loss: 0.0629\n",
      "Epoch [28/50], Step [155/735], Loss: 0.1409\n",
      "Epoch [28/50], Step [156/735], Loss: 0.1373\n",
      "Epoch [28/50], Step [157/735], Loss: 0.2513\n",
      "Epoch [28/50], Step [158/735], Loss: 0.0893\n",
      "Epoch [28/50], Step [159/735], Loss: 0.9407\n",
      "Epoch [28/50], Step [160/735], Loss: 0.1214\n",
      "Epoch [28/50], Step [161/735], Loss: 0.0397\n",
      "Epoch [28/50], Step [162/735], Loss: 0.0957\n",
      "Epoch [28/50], Step [163/735], Loss: 0.1666\n",
      "Epoch [28/50], Step [164/735], Loss: 0.1563\n",
      "Epoch [28/50], Step [165/735], Loss: 0.1277\n",
      "Epoch [28/50], Step [166/735], Loss: 0.2100\n",
      "Epoch [28/50], Step [167/735], Loss: 0.1281\n",
      "Epoch [28/50], Step [168/735], Loss: 0.3789\n",
      "Epoch [28/50], Step [169/735], Loss: 0.0568\n",
      "Epoch [28/50], Step [170/735], Loss: 0.1216\n",
      "Epoch [28/50], Step [171/735], Loss: 0.1522\n",
      "Epoch [28/50], Step [172/735], Loss: 0.2144\n",
      "Epoch [28/50], Step [173/735], Loss: 0.3867\n",
      "Epoch [28/50], Step [174/735], Loss: 0.1122\n",
      "Epoch [28/50], Step [175/735], Loss: 0.1805\n",
      "Epoch [28/50], Step [176/735], Loss: 0.0879\n",
      "Epoch [28/50], Step [177/735], Loss: 0.1234\n",
      "Epoch [28/50], Step [178/735], Loss: 0.0933\n",
      "Epoch [28/50], Step [179/735], Loss: 0.1078\n",
      "Epoch [28/50], Step [180/735], Loss: 0.0508\n",
      "Epoch [28/50], Step [181/735], Loss: 0.2673\n",
      "Epoch [28/50], Step [182/735], Loss: 0.1096\n",
      "Epoch [28/50], Step [183/735], Loss: 0.0566\n",
      "Epoch [28/50], Step [184/735], Loss: 0.0985\n",
      "Epoch [28/50], Step [185/735], Loss: 0.1004\n",
      "Epoch [28/50], Step [186/735], Loss: 0.4612\n",
      "Epoch [28/50], Step [187/735], Loss: 0.0273\n",
      "Epoch [28/50], Step [188/735], Loss: 0.0926\n",
      "Epoch [28/50], Step [189/735], Loss: 0.1172\n",
      "Epoch [28/50], Step [190/735], Loss: 0.0565\n",
      "Epoch [28/50], Step [191/735], Loss: 0.1131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Step [192/735], Loss: 0.0880\n",
      "Epoch [28/50], Step [193/735], Loss: 0.1780\n",
      "Epoch [28/50], Step [194/735], Loss: 0.1291\n",
      "Epoch [28/50], Step [195/735], Loss: 0.1146\n",
      "Epoch [28/50], Step [196/735], Loss: 0.9573\n",
      "Epoch [28/50], Step [197/735], Loss: 0.1703\n",
      "Epoch [28/50], Step [198/735], Loss: 0.1364\n",
      "Epoch [28/50], Step [199/735], Loss: 0.1231\n",
      "Epoch [28/50], Step [200/735], Loss: 0.2760\n",
      "Epoch [28/50], Step [201/735], Loss: 0.1762\n",
      "Epoch [28/50], Step [202/735], Loss: 0.0826\n",
      "Epoch [28/50], Step [203/735], Loss: 0.1484\n",
      "Epoch [28/50], Step [204/735], Loss: 0.1124\n",
      "Epoch [28/50], Step [205/735], Loss: 0.3049\n",
      "Epoch [28/50], Step [206/735], Loss: 0.0433\n",
      "Epoch [28/50], Step [207/735], Loss: 0.4401\n",
      "Epoch [28/50], Step [208/735], Loss: 0.1287\n",
      "Epoch [28/50], Step [209/735], Loss: 0.2540\n",
      "Epoch [28/50], Step [210/735], Loss: 0.0807\n",
      "Epoch [28/50], Step [211/735], Loss: 0.1281\n",
      "Epoch [28/50], Step [212/735], Loss: 0.1027\n",
      "Epoch [28/50], Step [213/735], Loss: 0.0943\n",
      "Epoch [28/50], Step [214/735], Loss: 0.0674\n",
      "Epoch [28/50], Step [215/735], Loss: 0.1615\n",
      "Epoch [28/50], Step [216/735], Loss: 0.0864\n",
      "Epoch [28/50], Step [217/735], Loss: 0.0981\n",
      "Epoch [28/50], Step [218/735], Loss: 0.2030\n",
      "Epoch [28/50], Step [219/735], Loss: 0.1292\n",
      "Epoch [28/50], Step [220/735], Loss: 0.0730\n",
      "Epoch [28/50], Step [221/735], Loss: 0.0785\n",
      "Epoch [28/50], Step [222/735], Loss: 0.1898\n",
      "Epoch [28/50], Step [223/735], Loss: 0.0766\n",
      "Epoch [28/50], Step [224/735], Loss: 0.1417\n",
      "Epoch [28/50], Step [225/735], Loss: 0.2204\n",
      "Epoch [28/50], Step [226/735], Loss: 0.0663\n",
      "Epoch [28/50], Step [227/735], Loss: 0.1724\n",
      "Epoch [28/50], Step [228/735], Loss: 0.0634\n",
      "Epoch [28/50], Step [229/735], Loss: 0.1336\n",
      "Epoch [28/50], Step [230/735], Loss: 0.5184\n",
      "Epoch [28/50], Step [231/735], Loss: 0.2512\n",
      "Epoch [28/50], Step [232/735], Loss: 0.0609\n",
      "Epoch [28/50], Step [233/735], Loss: 0.1722\n",
      "Epoch [28/50], Step [234/735], Loss: 0.1456\n",
      "Epoch [28/50], Step [235/735], Loss: 0.1568\n",
      "Epoch [28/50], Step [236/735], Loss: 0.0991\n",
      "Epoch [28/50], Step [237/735], Loss: 0.0917\n",
      "Epoch [28/50], Step [238/735], Loss: 0.1568\n",
      "Epoch [28/50], Step [239/735], Loss: 0.1656\n",
      "Epoch [28/50], Step [240/735], Loss: 0.1546\n",
      "Epoch [28/50], Step [241/735], Loss: 0.0763\n",
      "Epoch [28/50], Step [242/735], Loss: 0.2652\n",
      "Epoch [28/50], Step [243/735], Loss: 0.0752\n",
      "Epoch [28/50], Step [244/735], Loss: 0.2971\n",
      "Epoch [28/50], Step [245/735], Loss: 0.0782\n",
      "Epoch [28/50], Step [246/735], Loss: 0.1268\n",
      "Epoch [28/50], Step [247/735], Loss: 0.1972\n",
      "Epoch [28/50], Step [248/735], Loss: 0.1069\n",
      "Epoch [28/50], Step [249/735], Loss: 0.1872\n",
      "Epoch [28/50], Step [250/735], Loss: 0.1633\n",
      "Epoch [28/50], Step [251/735], Loss: 0.2137\n",
      "Epoch [28/50], Step [252/735], Loss: 0.1260\n",
      "Epoch [28/50], Step [253/735], Loss: 0.1605\n",
      "Epoch [28/50], Step [254/735], Loss: 0.4589\n",
      "Epoch [28/50], Step [255/735], Loss: 0.1485\n",
      "Epoch [28/50], Step [256/735], Loss: 1.2388\n",
      "Epoch [28/50], Step [257/735], Loss: 0.1405\n",
      "Epoch [28/50], Step [258/735], Loss: 0.0997\n",
      "Epoch [28/50], Step [259/735], Loss: 0.1403\n",
      "Epoch [28/50], Step [260/735], Loss: 0.1830\n",
      "Epoch [28/50], Step [261/735], Loss: 0.0545\n",
      "Epoch [28/50], Step [262/735], Loss: 0.2221\n",
      "Epoch [28/50], Step [263/735], Loss: 0.1465\n",
      "Epoch [28/50], Step [264/735], Loss: 0.2801\n",
      "Epoch [28/50], Step [265/735], Loss: 0.0688\n",
      "Epoch [28/50], Step [266/735], Loss: 0.0283\n",
      "Epoch [28/50], Step [267/735], Loss: 0.0680\n",
      "Epoch [28/50], Step [268/735], Loss: 0.0901\n",
      "Epoch [28/50], Step [269/735], Loss: 0.2397\n",
      "Epoch [28/50], Step [270/735], Loss: 0.0512\n",
      "Epoch [28/50], Step [271/735], Loss: 0.1392\n",
      "Epoch [28/50], Step [272/735], Loss: 0.1287\n",
      "Epoch [28/50], Step [273/735], Loss: 0.1626\n",
      "Epoch [28/50], Step [274/735], Loss: 0.0711\n",
      "Epoch [28/50], Step [275/735], Loss: 0.0656\n",
      "Epoch [28/50], Step [276/735], Loss: 0.0604\n",
      "Epoch [28/50], Step [277/735], Loss: 0.0362\n",
      "Epoch [28/50], Step [278/735], Loss: 0.1642\n",
      "Epoch [28/50], Step [279/735], Loss: 0.1569\n",
      "Epoch [28/50], Step [280/735], Loss: 0.1777\n",
      "Epoch [28/50], Step [281/735], Loss: 0.0803\n",
      "Epoch [28/50], Step [282/735], Loss: 0.1172\n",
      "Epoch [28/50], Step [283/735], Loss: 0.1180\n",
      "Epoch [28/50], Step [284/735], Loss: 0.2042\n",
      "Epoch [28/50], Step [285/735], Loss: 0.0858\n",
      "Epoch [28/50], Step [286/735], Loss: 0.0486\n",
      "Epoch [28/50], Step [287/735], Loss: 0.1018\n",
      "Epoch [28/50], Step [288/735], Loss: 0.0696\n",
      "Epoch [28/50], Step [289/735], Loss: 0.1331\n",
      "Epoch [28/50], Step [290/735], Loss: 0.1583\n",
      "Epoch [28/50], Step [291/735], Loss: 0.0975\n",
      "Epoch [28/50], Step [292/735], Loss: 0.1153\n",
      "Epoch [28/50], Step [293/735], Loss: 1.2022\n",
      "Epoch [28/50], Step [294/735], Loss: 0.0556\n",
      "Epoch [28/50], Step [295/735], Loss: 0.1064\n",
      "Epoch [28/50], Step [296/735], Loss: 0.2140\n",
      "Epoch [28/50], Step [297/735], Loss: 0.2253\n",
      "Epoch [28/50], Step [298/735], Loss: 0.1018\n",
      "Epoch [28/50], Step [299/735], Loss: 0.0849\n",
      "Epoch [28/50], Step [300/735], Loss: 0.0444\n",
      "Epoch [28/50], Step [301/735], Loss: 0.0477\n",
      "Epoch [28/50], Step [302/735], Loss: 0.0750\n",
      "Epoch [28/50], Step [303/735], Loss: 0.0943\n",
      "Epoch [28/50], Step [304/735], Loss: 0.1004\n",
      "Epoch [28/50], Step [305/735], Loss: 0.3340\n",
      "Epoch [28/50], Step [306/735], Loss: 0.0807\n",
      "Epoch [28/50], Step [307/735], Loss: 0.0623\n",
      "Epoch [28/50], Step [308/735], Loss: 0.1504\n",
      "Epoch [28/50], Step [309/735], Loss: 0.1048\n",
      "Epoch [28/50], Step [310/735], Loss: 0.0734\n",
      "Epoch [28/50], Step [311/735], Loss: 0.0815\n",
      "Epoch [28/50], Step [312/735], Loss: 0.1054\n",
      "Epoch [28/50], Step [313/735], Loss: 0.0614\n",
      "Epoch [28/50], Step [314/735], Loss: 0.1302\n",
      "Epoch [28/50], Step [315/735], Loss: 0.1442\n",
      "Epoch [28/50], Step [316/735], Loss: 0.0868\n",
      "Epoch [28/50], Step [317/735], Loss: 0.1493\n",
      "Epoch [28/50], Step [318/735], Loss: 0.0833\n",
      "Epoch [28/50], Step [319/735], Loss: 0.0424\n",
      "Epoch [28/50], Step [320/735], Loss: 0.0858\n",
      "Epoch [28/50], Step [321/735], Loss: 1.6158\n",
      "Epoch [28/50], Step [322/735], Loss: 0.0427\n",
      "Epoch [28/50], Step [323/735], Loss: 0.1831\n",
      "Epoch [28/50], Step [324/735], Loss: 0.1753\n",
      "Epoch [28/50], Step [325/735], Loss: 0.0741\n",
      "Epoch [28/50], Step [326/735], Loss: 0.0859\n",
      "Epoch [28/50], Step [327/735], Loss: 0.1592\n",
      "Epoch [28/50], Step [328/735], Loss: 0.9679\n",
      "Epoch [28/50], Step [329/735], Loss: 0.0386\n",
      "Epoch [28/50], Step [330/735], Loss: 0.1976\n",
      "Epoch [28/50], Step [331/735], Loss: 0.1792\n",
      "Epoch [28/50], Step [332/735], Loss: 0.0947\n",
      "Epoch [28/50], Step [333/735], Loss: 0.0651\n",
      "Epoch [28/50], Step [334/735], Loss: 0.1015\n",
      "Epoch [28/50], Step [335/735], Loss: 0.1350\n",
      "Epoch [28/50], Step [336/735], Loss: 0.0361\n",
      "Epoch [28/50], Step [337/735], Loss: 0.0673\n",
      "Epoch [28/50], Step [338/735], Loss: 0.1547\n",
      "Epoch [28/50], Step [339/735], Loss: 0.1539\n",
      "Epoch [28/50], Step [340/735], Loss: 0.1558\n",
      "Epoch [28/50], Step [341/735], Loss: 0.3545\n",
      "Epoch [28/50], Step [342/735], Loss: 0.0757\n",
      "Epoch [28/50], Step [343/735], Loss: 0.0298\n",
      "Epoch [28/50], Step [344/735], Loss: 0.0997\n",
      "Epoch [28/50], Step [345/735], Loss: 0.1054\n",
      "Epoch [28/50], Step [346/735], Loss: 0.0472\n",
      "Epoch [28/50], Step [347/735], Loss: 0.0630\n",
      "Epoch [28/50], Step [348/735], Loss: 0.2226\n",
      "Epoch [28/50], Step [349/735], Loss: 0.0880\n",
      "Epoch [28/50], Step [350/735], Loss: 0.2872\n",
      "Epoch [28/50], Step [351/735], Loss: 0.3151\n",
      "Epoch [28/50], Step [352/735], Loss: 0.1092\n",
      "Epoch [28/50], Step [353/735], Loss: 0.1012\n",
      "Epoch [28/50], Step [354/735], Loss: 0.9587\n",
      "Epoch [28/50], Step [355/735], Loss: 0.0779\n",
      "Epoch [28/50], Step [356/735], Loss: 0.0661\n",
      "Epoch [28/50], Step [357/735], Loss: 0.0593\n",
      "Epoch [28/50], Step [358/735], Loss: 0.0575\n",
      "Epoch [28/50], Step [359/735], Loss: 0.1118\n",
      "Epoch [28/50], Step [360/735], Loss: 0.0631\n",
      "Epoch [28/50], Step [361/735], Loss: 0.1561\n",
      "Epoch [28/50], Step [362/735], Loss: 0.0404\n",
      "Epoch [28/50], Step [363/735], Loss: 0.1523\n",
      "Epoch [28/50], Step [364/735], Loss: 0.0729\n",
      "Epoch [28/50], Step [365/735], Loss: 0.0491\n",
      "Epoch [28/50], Step [366/735], Loss: 0.1289\n",
      "Epoch [28/50], Step [367/735], Loss: 0.1738\n",
      "Epoch [28/50], Step [368/735], Loss: 0.2177\n",
      "Epoch [28/50], Step [369/735], Loss: 0.1573\n",
      "Epoch [28/50], Step [370/735], Loss: 0.1705\n",
      "Epoch [28/50], Step [371/735], Loss: 0.1904\n",
      "Epoch [28/50], Step [372/735], Loss: 0.1434\n",
      "Epoch [28/50], Step [373/735], Loss: 0.1703\n",
      "Epoch [28/50], Step [374/735], Loss: 0.1135\n",
      "Epoch [28/50], Step [375/735], Loss: 0.1601\n",
      "Epoch [28/50], Step [376/735], Loss: 0.2893\n",
      "Epoch [28/50], Step [377/735], Loss: 0.2346\n",
      "Epoch [28/50], Step [378/735], Loss: 0.1406\n",
      "Epoch [28/50], Step [379/735], Loss: 0.1901\n",
      "Epoch [28/50], Step [380/735], Loss: 0.2075\n",
      "Epoch [28/50], Step [381/735], Loss: 0.1374\n",
      "Epoch [28/50], Step [382/735], Loss: 0.0945\n",
      "Epoch [28/50], Step [383/735], Loss: 0.1894\n",
      "Epoch [28/50], Step [384/735], Loss: 0.0812\n",
      "Epoch [28/50], Step [385/735], Loss: 0.0599\n",
      "Epoch [28/50], Step [386/735], Loss: 0.1160\n",
      "Epoch [28/50], Step [387/735], Loss: 0.0535\n",
      "Epoch [28/50], Step [388/735], Loss: 0.1145\n",
      "Epoch [28/50], Step [389/735], Loss: 0.1126\n",
      "Epoch [28/50], Step [390/735], Loss: 0.0822\n",
      "Epoch [28/50], Step [391/735], Loss: 0.0384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Step [392/735], Loss: 0.2053\n",
      "Epoch [28/50], Step [393/735], Loss: 0.0786\n",
      "Epoch [28/50], Step [394/735], Loss: 0.0878\n",
      "Epoch [28/50], Step [395/735], Loss: 0.0594\n",
      "Epoch [28/50], Step [396/735], Loss: 0.1531\n",
      "Epoch [28/50], Step [397/735], Loss: 0.0986\n",
      "Epoch [28/50], Step [398/735], Loss: 0.0618\n",
      "Epoch [28/50], Step [399/735], Loss: 0.3474\n",
      "Epoch [28/50], Step [400/735], Loss: 0.0753\n",
      "Epoch [28/50], Step [401/735], Loss: 0.1517\n",
      "Epoch [28/50], Step [402/735], Loss: 0.0557\n",
      "Epoch [28/50], Step [403/735], Loss: 0.0836\n",
      "Epoch [28/50], Step [404/735], Loss: 0.1863\n",
      "Epoch [28/50], Step [405/735], Loss: 0.0445\n",
      "Epoch [28/50], Step [406/735], Loss: 0.1309\n",
      "Epoch [28/50], Step [407/735], Loss: 0.0306\n",
      "Epoch [28/50], Step [408/735], Loss: 0.1957\n",
      "Epoch [28/50], Step [409/735], Loss: 0.0729\n",
      "Epoch [28/50], Step [410/735], Loss: 0.1613\n",
      "Epoch [28/50], Step [411/735], Loss: 0.3162\n",
      "Epoch [28/50], Step [412/735], Loss: 0.1133\n",
      "Epoch [28/50], Step [413/735], Loss: 0.1361\n",
      "Epoch [28/50], Step [414/735], Loss: 0.1580\n",
      "Epoch [28/50], Step [415/735], Loss: 0.1298\n",
      "Epoch [28/50], Step [416/735], Loss: 0.1213\n",
      "Epoch [28/50], Step [417/735], Loss: 0.1122\n",
      "Epoch [28/50], Step [418/735], Loss: 0.0808\n",
      "Epoch [28/50], Step [419/735], Loss: 0.0318\n",
      "Epoch [28/50], Step [420/735], Loss: 0.1539\n",
      "Epoch [28/50], Step [421/735], Loss: 0.1302\n",
      "Epoch [28/50], Step [422/735], Loss: 0.0726\n",
      "Epoch [28/50], Step [423/735], Loss: 0.0880\n",
      "Epoch [28/50], Step [424/735], Loss: 0.0912\n",
      "Epoch [28/50], Step [425/735], Loss: 0.0552\n",
      "Epoch [28/50], Step [426/735], Loss: 0.0943\n",
      "Epoch [28/50], Step [427/735], Loss: 0.1540\n",
      "Epoch [28/50], Step [428/735], Loss: 0.1982\n",
      "Epoch [28/50], Step [429/735], Loss: 0.1124\n",
      "Epoch [28/50], Step [430/735], Loss: 0.1726\n",
      "Epoch [28/50], Step [431/735], Loss: 0.2443\n",
      "Epoch [28/50], Step [432/735], Loss: 0.2083\n",
      "Epoch [28/50], Step [433/735], Loss: 0.2011\n",
      "Epoch [28/50], Step [434/735], Loss: 0.1190\n",
      "Epoch [28/50], Step [435/735], Loss: 0.1402\n",
      "Epoch [28/50], Step [436/735], Loss: 0.1864\n",
      "Epoch [28/50], Step [437/735], Loss: 0.1065\n",
      "Epoch [28/50], Step [438/735], Loss: 0.0719\n",
      "Epoch [28/50], Step [439/735], Loss: 0.0800\n",
      "Epoch [28/50], Step [440/735], Loss: 0.0741\n",
      "Epoch [28/50], Step [441/735], Loss: 0.0605\n",
      "Epoch [28/50], Step [442/735], Loss: 0.2240\n",
      "Epoch [28/50], Step [443/735], Loss: 0.1226\n",
      "Epoch [28/50], Step [444/735], Loss: 0.0619\n",
      "Epoch [28/50], Step [445/735], Loss: 0.0493\n",
      "Epoch [28/50], Step [446/735], Loss: 0.0574\n",
      "Epoch [28/50], Step [447/735], Loss: 0.3170\n",
      "Epoch [28/50], Step [448/735], Loss: 0.1620\n",
      "Epoch [28/50], Step [449/735], Loss: 0.0837\n",
      "Epoch [28/50], Step [450/735], Loss: 0.0839\n",
      "Epoch [28/50], Step [451/735], Loss: 1.8859\n",
      "Epoch [28/50], Step [452/735], Loss: 0.1673\n",
      "Epoch [28/50], Step [453/735], Loss: 0.1691\n",
      "Epoch [28/50], Step [454/735], Loss: 0.1401\n",
      "Epoch [28/50], Step [455/735], Loss: 0.1514\n",
      "Epoch [28/50], Step [456/735], Loss: 0.0612\n",
      "Epoch [28/50], Step [457/735], Loss: 0.0546\n",
      "Epoch [28/50], Step [458/735], Loss: 0.1990\n",
      "Epoch [28/50], Step [459/735], Loss: 0.3415\n",
      "Epoch [28/50], Step [460/735], Loss: 0.2483\n",
      "Epoch [28/50], Step [461/735], Loss: 0.0445\n",
      "Epoch [28/50], Step [462/735], Loss: 0.2625\n",
      "Epoch [28/50], Step [463/735], Loss: 0.0680\n",
      "Epoch [28/50], Step [464/735], Loss: 0.0610\n",
      "Epoch [28/50], Step [465/735], Loss: 0.1430\n",
      "Epoch [28/50], Step [466/735], Loss: 0.1357\n",
      "Epoch [28/50], Step [467/735], Loss: 0.0739\n",
      "Epoch [28/50], Step [468/735], Loss: 0.1225\n",
      "Epoch [28/50], Step [469/735], Loss: 0.1081\n",
      "Epoch [28/50], Step [470/735], Loss: 0.1112\n",
      "Epoch [28/50], Step [471/735], Loss: 0.0396\n",
      "Epoch [28/50], Step [472/735], Loss: 0.0949\n",
      "Epoch [28/50], Step [473/735], Loss: 0.1042\n",
      "Epoch [28/50], Step [474/735], Loss: 0.0514\n",
      "Epoch [28/50], Step [475/735], Loss: 0.2288\n",
      "Epoch [28/50], Step [476/735], Loss: 0.0570\n",
      "Epoch [28/50], Step [477/735], Loss: 0.0322\n",
      "Epoch [28/50], Step [478/735], Loss: 0.0618\n",
      "Epoch [28/50], Step [479/735], Loss: 0.1391\n",
      "Epoch [28/50], Step [480/735], Loss: 0.1591\n",
      "Epoch [28/50], Step [481/735], Loss: 0.2148\n",
      "Epoch [28/50], Step [482/735], Loss: 0.1133\n",
      "Epoch [28/50], Step [483/735], Loss: 0.1005\n",
      "Epoch [28/50], Step [484/735], Loss: 0.1686\n",
      "Epoch [28/50], Step [485/735], Loss: 0.1317\n",
      "Epoch [28/50], Step [486/735], Loss: 0.0879\n",
      "Epoch [28/50], Step [487/735], Loss: 0.1282\n",
      "Epoch [28/50], Step [488/735], Loss: 0.0564\n",
      "Epoch [28/50], Step [489/735], Loss: 0.1406\n",
      "Epoch [28/50], Step [490/735], Loss: 0.1032\n",
      "Epoch [28/50], Step [491/735], Loss: 0.2291\n",
      "Epoch [28/50], Step [492/735], Loss: 0.0784\n",
      "Epoch [28/50], Step [493/735], Loss: 0.0945\n",
      "Epoch [28/50], Step [494/735], Loss: 0.1965\n",
      "Epoch [28/50], Step [495/735], Loss: 0.0308\n",
      "Epoch [28/50], Step [496/735], Loss: 0.1978\n",
      "Epoch [28/50], Step [497/735], Loss: 0.0800\n",
      "Epoch [28/50], Step [498/735], Loss: 0.0601\n",
      "Epoch [28/50], Step [499/735], Loss: 0.1336\n",
      "Epoch [28/50], Step [500/735], Loss: 0.0533\n",
      "Epoch [28/50], Step [501/735], Loss: 0.1902\n",
      "Epoch [28/50], Step [502/735], Loss: 0.1341\n",
      "Epoch [28/50], Step [503/735], Loss: 0.0876\n",
      "Epoch [28/50], Step [504/735], Loss: 0.1707\n",
      "Epoch [28/50], Step [505/735], Loss: 1.0102\n",
      "Epoch [28/50], Step [506/735], Loss: 0.0390\n",
      "Epoch [28/50], Step [507/735], Loss: 0.0999\n",
      "Epoch [28/50], Step [508/735], Loss: 0.1672\n",
      "Epoch [28/50], Step [509/735], Loss: 0.1735\n",
      "Epoch [28/50], Step [510/735], Loss: 0.0946\n",
      "Epoch [28/50], Step [511/735], Loss: 0.0608\n",
      "Epoch [28/50], Step [512/735], Loss: 0.0753\n",
      "Epoch [28/50], Step [513/735], Loss: 0.2055\n",
      "Epoch [28/50], Step [514/735], Loss: 0.0892\n",
      "Epoch [28/50], Step [515/735], Loss: 0.2236\n",
      "Epoch [28/50], Step [516/735], Loss: 0.0496\n",
      "Epoch [28/50], Step [517/735], Loss: 0.1064\n",
      "Epoch [28/50], Step [518/735], Loss: 0.1034\n",
      "Epoch [28/50], Step [519/735], Loss: 0.0940\n",
      "Epoch [28/50], Step [520/735], Loss: 0.0393\n",
      "Epoch [28/50], Step [521/735], Loss: 0.2227\n",
      "Epoch [28/50], Step [522/735], Loss: 0.2556\n",
      "Epoch [28/50], Step [523/735], Loss: 0.0622\n",
      "Epoch [28/50], Step [524/735], Loss: 0.1663\n",
      "Epoch [28/50], Step [525/735], Loss: 0.1336\n",
      "Epoch [28/50], Step [526/735], Loss: 0.1930\n",
      "Epoch [28/50], Step [527/735], Loss: 0.3968\n",
      "Epoch [28/50], Step [528/735], Loss: 0.0703\n",
      "Epoch [28/50], Step [529/735], Loss: 0.1642\n",
      "Epoch [28/50], Step [530/735], Loss: 0.2348\n",
      "Epoch [28/50], Step [531/735], Loss: 0.0913\n",
      "Epoch [28/50], Step [532/735], Loss: 0.1066\n",
      "Epoch [28/50], Step [533/735], Loss: 0.1292\n",
      "Epoch [28/50], Step [534/735], Loss: 0.0738\n",
      "Epoch [28/50], Step [535/735], Loss: 0.0845\n",
      "Epoch [28/50], Step [536/735], Loss: 0.0642\n",
      "Epoch [28/50], Step [537/735], Loss: 0.1219\n",
      "Epoch [28/50], Step [538/735], Loss: 0.1302\n",
      "Epoch [28/50], Step [539/735], Loss: 0.1987\n",
      "Epoch [28/50], Step [540/735], Loss: 0.0944\n",
      "Epoch [28/50], Step [541/735], Loss: 0.1672\n",
      "Epoch [28/50], Step [542/735], Loss: 0.3272\n",
      "Epoch [28/50], Step [543/735], Loss: 0.0966\n",
      "Epoch [28/50], Step [544/735], Loss: 0.1013\n",
      "Epoch [28/50], Step [545/735], Loss: 0.1239\n",
      "Epoch [28/50], Step [546/735], Loss: 0.1107\n",
      "Epoch [28/50], Step [547/735], Loss: 0.0840\n",
      "Epoch [28/50], Step [548/735], Loss: 0.0722\n",
      "Epoch [28/50], Step [549/735], Loss: 2.5154\n",
      "Epoch [28/50], Step [550/735], Loss: 0.1581\n",
      "Epoch [28/50], Step [551/735], Loss: 0.1382\n",
      "Epoch [28/50], Step [552/735], Loss: 0.1422\n",
      "Epoch [28/50], Step [553/735], Loss: 0.0777\n",
      "Epoch [28/50], Step [554/735], Loss: 0.1243\n",
      "Epoch [28/50], Step [555/735], Loss: 0.1893\n",
      "Epoch [28/50], Step [556/735], Loss: 0.3463\n",
      "Epoch [28/50], Step [557/735], Loss: 0.0344\n",
      "Epoch [28/50], Step [558/735], Loss: 2.1974\n",
      "Epoch [28/50], Step [559/735], Loss: 0.1040\n",
      "Epoch [28/50], Step [560/735], Loss: 0.0584\n",
      "Epoch [28/50], Step [561/735], Loss: 0.1654\n",
      "Epoch [28/50], Step [562/735], Loss: 0.1265\n",
      "Epoch [28/50], Step [563/735], Loss: 0.1232\n",
      "Epoch [28/50], Step [564/735], Loss: 0.1025\n",
      "Epoch [28/50], Step [565/735], Loss: 0.0363\n",
      "Epoch [28/50], Step [566/735], Loss: 0.1052\n",
      "Epoch [28/50], Step [567/735], Loss: 0.0620\n",
      "Epoch [28/50], Step [568/735], Loss: 0.0670\n",
      "Epoch [28/50], Step [569/735], Loss: 0.1789\n",
      "Epoch [28/50], Step [570/735], Loss: 0.1645\n",
      "Epoch [28/50], Step [571/735], Loss: 0.0946\n",
      "Epoch [28/50], Step [572/735], Loss: 0.0321\n",
      "Epoch [28/50], Step [573/735], Loss: 0.1550\n",
      "Epoch [28/50], Step [574/735], Loss: 0.1015\n",
      "Epoch [28/50], Step [575/735], Loss: 0.0460\n",
      "Epoch [28/50], Step [576/735], Loss: 0.3867\n",
      "Epoch [28/50], Step [577/735], Loss: 0.0651\n",
      "Epoch [28/50], Step [578/735], Loss: 0.1206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Step [579/735], Loss: 0.1031\n",
      "Epoch [28/50], Step [580/735], Loss: 0.0350\n",
      "Epoch [28/50], Step [581/735], Loss: 0.0741\n",
      "Epoch [28/50], Step [582/735], Loss: 0.2434\n",
      "Epoch [28/50], Step [583/735], Loss: 0.1361\n",
      "Epoch [28/50], Step [584/735], Loss: 0.1435\n",
      "Epoch [28/50], Step [585/735], Loss: 0.0774\n",
      "Epoch [28/50], Step [586/735], Loss: 0.1824\n",
      "Epoch [28/50], Step [587/735], Loss: 0.0949\n",
      "Epoch [28/50], Step [588/735], Loss: 0.1579\n",
      "Epoch [28/50], Step [589/735], Loss: 0.1173\n",
      "Epoch [28/50], Step [590/735], Loss: 0.2662\n",
      "Epoch [28/50], Step [591/735], Loss: 0.2310\n",
      "Epoch [28/50], Step [592/735], Loss: 2.2034\n",
      "Epoch [28/50], Step [593/735], Loss: 0.0467\n",
      "Epoch [28/50], Step [594/735], Loss: 0.2221\n",
      "Epoch [28/50], Step [595/735], Loss: 0.1402\n",
      "Epoch [28/50], Step [596/735], Loss: 0.4524\n",
      "Epoch [28/50], Step [597/735], Loss: 0.1095\n",
      "Epoch [28/50], Step [598/735], Loss: 0.1781\n",
      "Epoch [28/50], Step [599/735], Loss: 0.0683\n",
      "Epoch [28/50], Step [600/735], Loss: 0.1431\n",
      "Epoch [28/50], Step [601/735], Loss: 0.1426\n",
      "Epoch [28/50], Step [602/735], Loss: 0.0720\n",
      "Epoch [28/50], Step [603/735], Loss: 0.0565\n",
      "Epoch [28/50], Step [604/735], Loss: 0.0799\n",
      "Epoch [28/50], Step [605/735], Loss: 0.1245\n",
      "Epoch [28/50], Step [606/735], Loss: 0.0693\n",
      "Epoch [28/50], Step [607/735], Loss: 0.1072\n",
      "Epoch [28/50], Step [608/735], Loss: 0.1442\n",
      "Epoch [28/50], Step [609/735], Loss: 0.1399\n",
      "Epoch [28/50], Step [610/735], Loss: 0.2725\n",
      "Epoch [28/50], Step [611/735], Loss: 0.1448\n",
      "Epoch [28/50], Step [612/735], Loss: 0.0651\n",
      "Epoch [28/50], Step [613/735], Loss: 0.0835\n",
      "Epoch [28/50], Step [614/735], Loss: 0.1321\n",
      "Epoch [28/50], Step [615/735], Loss: 0.1839\n",
      "Epoch [28/50], Step [616/735], Loss: 0.0699\n",
      "Epoch [28/50], Step [617/735], Loss: 0.1062\n",
      "Epoch [28/50], Step [618/735], Loss: 0.1085\n",
      "Epoch [28/50], Step [619/735], Loss: 0.0559\n",
      "Epoch [28/50], Step [620/735], Loss: 0.0950\n",
      "Epoch [28/50], Step [621/735], Loss: 0.1276\n",
      "Epoch [28/50], Step [622/735], Loss: 0.0987\n",
      "Epoch [28/50], Step [623/735], Loss: 0.1828\n",
      "Epoch [28/50], Step [624/735], Loss: 0.2171\n",
      "Epoch [28/50], Step [625/735], Loss: 0.0999\n",
      "Epoch [28/50], Step [626/735], Loss: 0.1001\n",
      "Epoch [28/50], Step [627/735], Loss: 0.1472\n",
      "Epoch [28/50], Step [628/735], Loss: 0.0889\n",
      "Epoch [28/50], Step [629/735], Loss: 0.0568\n",
      "Epoch [28/50], Step [630/735], Loss: 0.0756\n",
      "Epoch [28/50], Step [631/735], Loss: 0.0865\n",
      "Epoch [28/50], Step [632/735], Loss: 0.1766\n",
      "Epoch [28/50], Step [633/735], Loss: 0.0950\n",
      "Epoch [28/50], Step [634/735], Loss: 0.9418\n",
      "Epoch [28/50], Step [635/735], Loss: 0.0757\n",
      "Epoch [28/50], Step [636/735], Loss: 0.0902\n",
      "Epoch [28/50], Step [637/735], Loss: 0.0820\n",
      "Epoch [28/50], Step [638/735], Loss: 0.1960\n",
      "Epoch [28/50], Step [639/735], Loss: 0.0696\n",
      "Epoch [28/50], Step [640/735], Loss: 0.0888\n",
      "Epoch [28/50], Step [641/735], Loss: 0.0506\n",
      "Epoch [28/50], Step [642/735], Loss: 0.1076\n",
      "Epoch [28/50], Step [643/735], Loss: 0.0693\n",
      "Epoch [28/50], Step [644/735], Loss: 0.0837\n",
      "Epoch [28/50], Step [645/735], Loss: 2.1093\n",
      "Epoch [28/50], Step [646/735], Loss: 0.1166\n",
      "Epoch [28/50], Step [647/735], Loss: 1.1891\n",
      "Epoch [28/50], Step [648/735], Loss: 1.6715\n",
      "Epoch [28/50], Step [649/735], Loss: 0.0985\n",
      "Epoch [28/50], Step [650/735], Loss: 0.0852\n",
      "Epoch [28/50], Step [651/735], Loss: 0.1492\n",
      "Epoch [28/50], Step [652/735], Loss: 0.0901\n",
      "Epoch [28/50], Step [653/735], Loss: 0.1668\n",
      "Epoch [28/50], Step [654/735], Loss: 0.3769\n",
      "Epoch [28/50], Step [655/735], Loss: 0.0503\n",
      "Epoch [28/50], Step [656/735], Loss: 0.1571\n",
      "Epoch [28/50], Step [657/735], Loss: 0.0888\n",
      "Epoch [28/50], Step [658/735], Loss: 0.1027\n",
      "Epoch [28/50], Step [659/735], Loss: 0.1430\n",
      "Epoch [28/50], Step [660/735], Loss: 0.0544\n",
      "Epoch [28/50], Step [661/735], Loss: 0.4534\n",
      "Epoch [28/50], Step [662/735], Loss: 0.0987\n",
      "Epoch [28/50], Step [663/735], Loss: 0.0686\n",
      "Epoch [28/50], Step [664/735], Loss: 0.2727\n",
      "Epoch [28/50], Step [665/735], Loss: 0.1466\n",
      "Epoch [28/50], Step [666/735], Loss: 0.1094\n",
      "Epoch [28/50], Step [667/735], Loss: 0.1751\n",
      "Epoch [28/50], Step [668/735], Loss: 0.1501\n",
      "Epoch [28/50], Step [669/735], Loss: 0.1034\n",
      "Epoch [28/50], Step [670/735], Loss: 0.0534\n",
      "Epoch [28/50], Step [671/735], Loss: 0.1038\n",
      "Epoch [28/50], Step [672/735], Loss: 0.0822\n",
      "Epoch [28/50], Step [673/735], Loss: 0.1303\n",
      "Epoch [28/50], Step [674/735], Loss: 0.0869\n",
      "Epoch [28/50], Step [675/735], Loss: 0.1114\n",
      "Epoch [28/50], Step [676/735], Loss: 0.0872\n",
      "Epoch [28/50], Step [677/735], Loss: 0.1461\n",
      "Epoch [28/50], Step [678/735], Loss: 0.0824\n",
      "Epoch [28/50], Step [679/735], Loss: 0.1398\n",
      "Epoch [28/50], Step [680/735], Loss: 0.0948\n",
      "Epoch [28/50], Step [681/735], Loss: 0.0360\n",
      "Epoch [28/50], Step [682/735], Loss: 0.3941\n",
      "Epoch [28/50], Step [683/735], Loss: 0.0339\n",
      "Epoch [28/50], Step [684/735], Loss: 0.5002\n",
      "Epoch [28/50], Step [685/735], Loss: 0.1717\n",
      "Epoch [28/50], Step [686/735], Loss: 0.0482\n",
      "Epoch [28/50], Step [687/735], Loss: 0.1501\n",
      "Epoch [28/50], Step [688/735], Loss: 0.0496\n",
      "Epoch [28/50], Step [689/735], Loss: 0.0560\n",
      "Epoch [28/50], Step [690/735], Loss: 0.0989\n",
      "Epoch [28/50], Step [691/735], Loss: 0.1805\n",
      "Epoch [28/50], Step [692/735], Loss: 0.7059\n",
      "Epoch [28/50], Step [693/735], Loss: 0.0682\n",
      "Epoch [28/50], Step [694/735], Loss: 0.0911\n",
      "Epoch [28/50], Step [695/735], Loss: 0.1749\n",
      "Epoch [28/50], Step [696/735], Loss: 0.1272\n",
      "Epoch [28/50], Step [697/735], Loss: 0.1000\n",
      "Epoch [28/50], Step [698/735], Loss: 0.1274\n",
      "Epoch [28/50], Step [699/735], Loss: 0.0677\n",
      "Epoch [28/50], Step [700/735], Loss: 0.3130\n",
      "Epoch [28/50], Step [701/735], Loss: 0.1141\n",
      "Epoch [28/50], Step [702/735], Loss: 0.0902\n",
      "Epoch [28/50], Step [703/735], Loss: 0.6173\n",
      "Epoch [28/50], Step [704/735], Loss: 1.2736\n",
      "Epoch [28/50], Step [705/735], Loss: 0.0452\n",
      "Epoch [28/50], Step [706/735], Loss: 0.1867\n",
      "Epoch [28/50], Step [707/735], Loss: 0.1304\n",
      "Epoch [28/50], Step [708/735], Loss: 0.0464\n",
      "Epoch [28/50], Step [709/735], Loss: 0.0654\n",
      "Epoch [28/50], Step [710/735], Loss: 0.0893\n",
      "Epoch [28/50], Step [711/735], Loss: 0.1157\n",
      "Epoch [28/50], Step [712/735], Loss: 0.0983\n",
      "Epoch [28/50], Step [713/735], Loss: 0.1931\n",
      "Epoch [28/50], Step [714/735], Loss: 0.2319\n",
      "Epoch [28/50], Step [715/735], Loss: 0.1843\n",
      "Epoch [28/50], Step [716/735], Loss: 0.1815\n",
      "Epoch [28/50], Step [717/735], Loss: 0.0771\n",
      "Epoch [28/50], Step [718/735], Loss: 0.0681\n",
      "Epoch [28/50], Step [719/735], Loss: 0.0417\n",
      "Epoch [28/50], Step [720/735], Loss: 0.1790\n",
      "Epoch [28/50], Step [721/735], Loss: 0.0432\n",
      "Epoch [28/50], Step [722/735], Loss: 0.4233\n",
      "Epoch [28/50], Step [723/735], Loss: 0.0515\n",
      "Epoch [28/50], Step [724/735], Loss: 0.1525\n",
      "Epoch [28/50], Step [725/735], Loss: 0.5242\n",
      "Epoch [28/50], Step [726/735], Loss: 0.1482\n",
      "Epoch [28/50], Step [727/735], Loss: 0.1054\n",
      "Epoch [28/50], Step [728/735], Loss: 0.1198\n",
      "Epoch [28/50], Step [729/735], Loss: 0.1050\n",
      "Epoch [28/50], Step [730/735], Loss: 0.1603\n",
      "Epoch [28/50], Step [731/735], Loss: 0.1642\n",
      "Epoch [28/50], Step [732/735], Loss: 0.0686\n",
      "Epoch [28/50], Step [733/735], Loss: 0.0820\n",
      "Epoch [28/50], Step [734/735], Loss: 0.0827\n",
      "Epoch [28/50], Step [735/735], Loss: 0.1606\n",
      "Epoch [29/50], Step [1/735], Loss: 0.3913\n",
      "Epoch [29/50], Step [2/735], Loss: 0.1386\n",
      "Epoch [29/50], Step [3/735], Loss: 0.1578\n",
      "Epoch [29/50], Step [4/735], Loss: 0.3375\n",
      "Epoch [29/50], Step [5/735], Loss: 0.0747\n",
      "Epoch [29/50], Step [6/735], Loss: 0.2990\n",
      "Epoch [29/50], Step [7/735], Loss: 0.2158\n",
      "Epoch [29/50], Step [8/735], Loss: 0.1189\n",
      "Epoch [29/50], Step [9/735], Loss: 0.0742\n",
      "Epoch [29/50], Step [10/735], Loss: 0.0877\n",
      "Epoch [29/50], Step [11/735], Loss: 0.2487\n",
      "Epoch [29/50], Step [12/735], Loss: 0.0873\n",
      "Epoch [29/50], Step [13/735], Loss: 0.0907\n",
      "Epoch [29/50], Step [14/735], Loss: 0.1224\n",
      "Epoch [29/50], Step [15/735], Loss: 0.1014\n",
      "Epoch [29/50], Step [16/735], Loss: 0.0601\n",
      "Epoch [29/50], Step [17/735], Loss: 0.1233\n",
      "Epoch [29/50], Step [18/735], Loss: 0.0991\n",
      "Epoch [29/50], Step [19/735], Loss: 0.0808\n",
      "Epoch [29/50], Step [20/735], Loss: 0.0479\n",
      "Epoch [29/50], Step [21/735], Loss: 0.0562\n",
      "Epoch [29/50], Step [22/735], Loss: 0.0639\n",
      "Epoch [29/50], Step [23/735], Loss: 0.1335\n",
      "Epoch [29/50], Step [24/735], Loss: 0.0952\n",
      "Epoch [29/50], Step [25/735], Loss: 0.1495\n",
      "Epoch [29/50], Step [26/735], Loss: 0.3398\n",
      "Epoch [29/50], Step [27/735], Loss: 0.1186\n",
      "Epoch [29/50], Step [28/735], Loss: 0.0852\n",
      "Epoch [29/50], Step [29/735], Loss: 0.2235\n",
      "Epoch [29/50], Step [30/735], Loss: 0.2224\n",
      "Epoch [29/50], Step [31/735], Loss: 0.0699\n",
      "Epoch [29/50], Step [32/735], Loss: 0.0677\n",
      "Epoch [29/50], Step [33/735], Loss: 0.0722\n",
      "Epoch [29/50], Step [34/735], Loss: 0.0885\n",
      "Epoch [29/50], Step [35/735], Loss: 0.0511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Step [36/735], Loss: 0.1625\n",
      "Epoch [29/50], Step [37/735], Loss: 0.1100\n",
      "Epoch [29/50], Step [38/735], Loss: 0.1363\n",
      "Epoch [29/50], Step [39/735], Loss: 0.1378\n",
      "Epoch [29/50], Step [40/735], Loss: 0.2603\n",
      "Epoch [29/50], Step [41/735], Loss: 0.1574\n",
      "Epoch [29/50], Step [42/735], Loss: 0.5680\n",
      "Epoch [29/50], Step [43/735], Loss: 0.1762\n",
      "Epoch [29/50], Step [44/735], Loss: 0.1692\n",
      "Epoch [29/50], Step [45/735], Loss: 0.2583\n",
      "Epoch [29/50], Step [46/735], Loss: 0.0850\n",
      "Epoch [29/50], Step [47/735], Loss: 0.1777\n",
      "Epoch [29/50], Step [48/735], Loss: 0.4410\n",
      "Epoch [29/50], Step [49/735], Loss: 0.0897\n",
      "Epoch [29/50], Step [50/735], Loss: 0.1661\n",
      "Epoch [29/50], Step [51/735], Loss: 0.2442\n",
      "Epoch [29/50], Step [52/735], Loss: 0.0932\n",
      "Epoch [29/50], Step [53/735], Loss: 0.0780\n",
      "Epoch [29/50], Step [54/735], Loss: 0.0730\n",
      "Epoch [29/50], Step [55/735], Loss: 0.1608\n",
      "Epoch [29/50], Step [56/735], Loss: 0.1012\n",
      "Epoch [29/50], Step [57/735], Loss: 0.0667\n",
      "Epoch [29/50], Step [58/735], Loss: 0.1554\n",
      "Epoch [29/50], Step [59/735], Loss: 0.0620\n",
      "Epoch [29/50], Step [60/735], Loss: 0.0654\n",
      "Epoch [29/50], Step [61/735], Loss: 0.1496\n",
      "Epoch [29/50], Step [62/735], Loss: 0.1965\n",
      "Epoch [29/50], Step [63/735], Loss: 0.1336\n",
      "Epoch [29/50], Step [64/735], Loss: 0.1116\n",
      "Epoch [29/50], Step [65/735], Loss: 0.1654\n",
      "Epoch [29/50], Step [66/735], Loss: 0.1029\n",
      "Epoch [29/50], Step [67/735], Loss: 0.2363\n",
      "Epoch [29/50], Step [68/735], Loss: 0.2171\n",
      "Epoch [29/50], Step [69/735], Loss: 0.1142\n",
      "Epoch [29/50], Step [70/735], Loss: 0.0760\n",
      "Epoch [29/50], Step [71/735], Loss: 0.0342\n",
      "Epoch [29/50], Step [72/735], Loss: 0.1028\n",
      "Epoch [29/50], Step [73/735], Loss: 0.1675\n",
      "Epoch [29/50], Step [74/735], Loss: 0.2233\n",
      "Epoch [29/50], Step [75/735], Loss: 0.0796\n",
      "Epoch [29/50], Step [76/735], Loss: 0.1228\n",
      "Epoch [29/50], Step [77/735], Loss: 0.0956\n",
      "Epoch [29/50], Step [78/735], Loss: 0.1347\n",
      "Epoch [29/50], Step [79/735], Loss: 1.2691\n",
      "Epoch [29/50], Step [80/735], Loss: 0.0319\n",
      "Epoch [29/50], Step [81/735], Loss: 0.3061\n",
      "Epoch [29/50], Step [82/735], Loss: 0.0615\n",
      "Epoch [29/50], Step [83/735], Loss: 0.2452\n",
      "Epoch [29/50], Step [84/735], Loss: 0.1922\n",
      "Epoch [29/50], Step [85/735], Loss: 0.0424\n",
      "Epoch [29/50], Step [86/735], Loss: 0.5116\n",
      "Epoch [29/50], Step [87/735], Loss: 0.0391\n",
      "Epoch [29/50], Step [88/735], Loss: 0.1348\n",
      "Epoch [29/50], Step [89/735], Loss: 1.1922\n",
      "Epoch [29/50], Step [90/735], Loss: 0.1615\n",
      "Epoch [29/50], Step [91/735], Loss: 0.0917\n",
      "Epoch [29/50], Step [92/735], Loss: 0.1231\n",
      "Epoch [29/50], Step [93/735], Loss: 0.0592\n",
      "Epoch [29/50], Step [94/735], Loss: 0.1973\n",
      "Epoch [29/50], Step [95/735], Loss: 0.1124\n",
      "Epoch [29/50], Step [96/735], Loss: 0.1996\n",
      "Epoch [29/50], Step [97/735], Loss: 0.2049\n",
      "Epoch [29/50], Step [98/735], Loss: 0.1853\n",
      "Epoch [29/50], Step [99/735], Loss: 0.1452\n",
      "Epoch [29/50], Step [100/735], Loss: 0.2099\n",
      "Epoch [29/50], Step [101/735], Loss: 0.0609\n",
      "Epoch [29/50], Step [102/735], Loss: 0.1130\n",
      "Epoch [29/50], Step [103/735], Loss: 0.2099\n",
      "Epoch [29/50], Step [104/735], Loss: 0.0597\n",
      "Epoch [29/50], Step [105/735], Loss: 0.6563\n",
      "Epoch [29/50], Step [106/735], Loss: 0.0773\n",
      "Epoch [29/50], Step [107/735], Loss: 0.0972\n",
      "Epoch [29/50], Step [108/735], Loss: 0.1383\n",
      "Epoch [29/50], Step [109/735], Loss: 0.0811\n",
      "Epoch [29/50], Step [110/735], Loss: 0.1323\n",
      "Epoch [29/50], Step [111/735], Loss: 0.1929\n",
      "Epoch [29/50], Step [112/735], Loss: 0.1939\n",
      "Epoch [29/50], Step [113/735], Loss: 0.0747\n",
      "Epoch [29/50], Step [114/735], Loss: 0.0809\n",
      "Epoch [29/50], Step [115/735], Loss: 0.1658\n",
      "Epoch [29/50], Step [116/735], Loss: 0.1641\n",
      "Epoch [29/50], Step [117/735], Loss: 0.1382\n",
      "Epoch [29/50], Step [118/735], Loss: 0.0549\n",
      "Epoch [29/50], Step [119/735], Loss: 0.0719\n",
      "Epoch [29/50], Step [120/735], Loss: 0.1294\n",
      "Epoch [29/50], Step [121/735], Loss: 0.1296\n",
      "Epoch [29/50], Step [122/735], Loss: 0.0635\n",
      "Epoch [29/50], Step [123/735], Loss: 0.1076\n",
      "Epoch [29/50], Step [124/735], Loss: 0.0670\n",
      "Epoch [29/50], Step [125/735], Loss: 0.0583\n",
      "Epoch [29/50], Step [126/735], Loss: 0.0802\n",
      "Epoch [29/50], Step [127/735], Loss: 0.0896\n",
      "Epoch [29/50], Step [128/735], Loss: 0.1459\n",
      "Epoch [29/50], Step [129/735], Loss: 0.1818\n",
      "Epoch [29/50], Step [130/735], Loss: 0.1124\n",
      "Epoch [29/50], Step [131/735], Loss: 0.1262\n",
      "Epoch [29/50], Step [132/735], Loss: 0.0692\n",
      "Epoch [29/50], Step [133/735], Loss: 0.2117\n",
      "Epoch [29/50], Step [134/735], Loss: 0.1091\n",
      "Epoch [29/50], Step [135/735], Loss: 0.0621\n",
      "Epoch [29/50], Step [136/735], Loss: 0.2027\n",
      "Epoch [29/50], Step [137/735], Loss: 0.2149\n",
      "Epoch [29/50], Step [138/735], Loss: 0.0970\n",
      "Epoch [29/50], Step [139/735], Loss: 0.0744\n",
      "Epoch [29/50], Step [140/735], Loss: 0.0694\n",
      "Epoch [29/50], Step [141/735], Loss: 0.0950\n",
      "Epoch [29/50], Step [142/735], Loss: 0.2461\n",
      "Epoch [29/50], Step [143/735], Loss: 0.2476\n",
      "Epoch [29/50], Step [144/735], Loss: 0.1369\n",
      "Epoch [29/50], Step [145/735], Loss: 0.0692\n",
      "Epoch [29/50], Step [146/735], Loss: 0.1187\n",
      "Epoch [29/50], Step [147/735], Loss: 0.1455\n",
      "Epoch [29/50], Step [148/735], Loss: 0.1369\n",
      "Epoch [29/50], Step [149/735], Loss: 0.0996\n",
      "Epoch [29/50], Step [150/735], Loss: 0.0795\n",
      "Epoch [29/50], Step [151/735], Loss: 0.0750\n",
      "Epoch [29/50], Step [152/735], Loss: 0.3070\n",
      "Epoch [29/50], Step [153/735], Loss: 0.0949\n",
      "Epoch [29/50], Step [154/735], Loss: 0.1346\n",
      "Epoch [29/50], Step [155/735], Loss: 0.0699\n",
      "Epoch [29/50], Step [156/735], Loss: 0.1258\n",
      "Epoch [29/50], Step [157/735], Loss: 0.0822\n",
      "Epoch [29/50], Step [158/735], Loss: 0.0867\n",
      "Epoch [29/50], Step [159/735], Loss: 0.1103\n",
      "Epoch [29/50], Step [160/735], Loss: 0.1117\n",
      "Epoch [29/50], Step [161/735], Loss: 0.1324\n",
      "Epoch [29/50], Step [162/735], Loss: 0.0728\n",
      "Epoch [29/50], Step [163/735], Loss: 0.1794\n",
      "Epoch [29/50], Step [164/735], Loss: 0.0956\n",
      "Epoch [29/50], Step [165/735], Loss: 0.0866\n",
      "Epoch [29/50], Step [166/735], Loss: 0.1418\n",
      "Epoch [29/50], Step [167/735], Loss: 0.1080\n",
      "Epoch [29/50], Step [168/735], Loss: 0.0662\n",
      "Epoch [29/50], Step [169/735], Loss: 0.1625\n",
      "Epoch [29/50], Step [170/735], Loss: 0.0679\n",
      "Epoch [29/50], Step [171/735], Loss: 0.3250\n",
      "Epoch [29/50], Step [172/735], Loss: 0.1161\n",
      "Epoch [29/50], Step [173/735], Loss: 0.1461\n",
      "Epoch [29/50], Step [174/735], Loss: 0.0295\n",
      "Epoch [29/50], Step [175/735], Loss: 0.1114\n",
      "Epoch [29/50], Step [176/735], Loss: 0.1440\n",
      "Epoch [29/50], Step [177/735], Loss: 0.1651\n",
      "Epoch [29/50], Step [178/735], Loss: 0.1205\n",
      "Epoch [29/50], Step [179/735], Loss: 0.0567\n",
      "Epoch [29/50], Step [180/735], Loss: 0.2918\n",
      "Epoch [29/50], Step [181/735], Loss: 0.2569\n",
      "Epoch [29/50], Step [182/735], Loss: 0.0352\n",
      "Epoch [29/50], Step [183/735], Loss: 0.1648\n",
      "Epoch [29/50], Step [184/735], Loss: 0.1965\n",
      "Epoch [29/50], Step [185/735], Loss: 0.1697\n",
      "Epoch [29/50], Step [186/735], Loss: 0.0803\n",
      "Epoch [29/50], Step [187/735], Loss: 0.0783\n",
      "Epoch [29/50], Step [188/735], Loss: 0.1368\n",
      "Epoch [29/50], Step [189/735], Loss: 0.1010\n",
      "Epoch [29/50], Step [190/735], Loss: 0.1704\n",
      "Epoch [29/50], Step [191/735], Loss: 0.1987\n",
      "Epoch [29/50], Step [192/735], Loss: 0.0812\n",
      "Epoch [29/50], Step [193/735], Loss: 0.1783\n",
      "Epoch [29/50], Step [194/735], Loss: 0.1097\n",
      "Epoch [29/50], Step [195/735], Loss: 0.0775\n",
      "Epoch [29/50], Step [196/735], Loss: 0.0621\n",
      "Epoch [29/50], Step [197/735], Loss: 0.0532\n",
      "Epoch [29/50], Step [198/735], Loss: 0.1395\n",
      "Epoch [29/50], Step [199/735], Loss: 0.0803\n",
      "Epoch [29/50], Step [200/735], Loss: 0.1431\n",
      "Epoch [29/50], Step [201/735], Loss: 0.0851\n",
      "Epoch [29/50], Step [202/735], Loss: 0.2323\n",
      "Epoch [29/50], Step [203/735], Loss: 0.2633\n",
      "Epoch [29/50], Step [204/735], Loss: 0.1092\n",
      "Epoch [29/50], Step [205/735], Loss: 0.1243\n",
      "Epoch [29/50], Step [206/735], Loss: 0.1261\n",
      "Epoch [29/50], Step [207/735], Loss: 0.0623\n",
      "Epoch [29/50], Step [208/735], Loss: 1.5775\n",
      "Epoch [29/50], Step [209/735], Loss: 0.0678\n",
      "Epoch [29/50], Step [210/735], Loss: 0.1267\n",
      "Epoch [29/50], Step [211/735], Loss: 0.0337\n",
      "Epoch [29/50], Step [212/735], Loss: 0.1991\n",
      "Epoch [29/50], Step [213/735], Loss: 0.0825\n",
      "Epoch [29/50], Step [214/735], Loss: 0.0958\n",
      "Epoch [29/50], Step [215/735], Loss: 0.0874\n",
      "Epoch [29/50], Step [216/735], Loss: 0.1237\n",
      "Epoch [29/50], Step [217/735], Loss: 0.0767\n",
      "Epoch [29/50], Step [218/735], Loss: 0.1071\n",
      "Epoch [29/50], Step [219/735], Loss: 0.0828\n",
      "Epoch [29/50], Step [220/735], Loss: 0.0390\n",
      "Epoch [29/50], Step [221/735], Loss: 0.1934\n",
      "Epoch [29/50], Step [222/735], Loss: 0.8765\n",
      "Epoch [29/50], Step [223/735], Loss: 0.0231\n",
      "Epoch [29/50], Step [224/735], Loss: 2.3627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Step [225/735], Loss: 0.1391\n",
      "Epoch [29/50], Step [226/735], Loss: 0.1141\n",
      "Epoch [29/50], Step [227/735], Loss: 0.0817\n",
      "Epoch [29/50], Step [228/735], Loss: 0.0881\n",
      "Epoch [29/50], Step [229/735], Loss: 0.1391\n",
      "Epoch [29/50], Step [230/735], Loss: 0.0384\n",
      "Epoch [29/50], Step [231/735], Loss: 0.1040\n",
      "Epoch [29/50], Step [232/735], Loss: 0.1318\n",
      "Epoch [29/50], Step [233/735], Loss: 0.0525\n",
      "Epoch [29/50], Step [234/735], Loss: 0.0454\n",
      "Epoch [29/50], Step [235/735], Loss: 0.4442\n",
      "Epoch [29/50], Step [236/735], Loss: 0.6528\n",
      "Epoch [29/50], Step [237/735], Loss: 0.4595\n",
      "Epoch [29/50], Step [238/735], Loss: 0.1337\n",
      "Epoch [29/50], Step [239/735], Loss: 0.2926\n",
      "Epoch [29/50], Step [240/735], Loss: 0.1357\n",
      "Epoch [29/50], Step [241/735], Loss: 0.1635\n",
      "Epoch [29/50], Step [242/735], Loss: 0.2101\n",
      "Epoch [29/50], Step [243/735], Loss: 0.2912\n",
      "Epoch [29/50], Step [244/735], Loss: 0.1359\n",
      "Epoch [29/50], Step [245/735], Loss: 0.1417\n",
      "Epoch [29/50], Step [246/735], Loss: 0.1098\n",
      "Epoch [29/50], Step [247/735], Loss: 0.1839\n",
      "Epoch [29/50], Step [248/735], Loss: 0.1455\n",
      "Epoch [29/50], Step [249/735], Loss: 0.0621\n",
      "Epoch [29/50], Step [250/735], Loss: 0.0934\n",
      "Epoch [29/50], Step [251/735], Loss: 0.1510\n",
      "Epoch [29/50], Step [252/735], Loss: 0.0991\n",
      "Epoch [29/50], Step [253/735], Loss: 0.1145\n",
      "Epoch [29/50], Step [254/735], Loss: 0.0848\n",
      "Epoch [29/50], Step [255/735], Loss: 0.0659\n",
      "Epoch [29/50], Step [256/735], Loss: 0.0422\n",
      "Epoch [29/50], Step [257/735], Loss: 0.4445\n",
      "Epoch [29/50], Step [258/735], Loss: 0.0752\n",
      "Epoch [29/50], Step [259/735], Loss: 0.0426\n",
      "Epoch [29/50], Step [260/735], Loss: 0.0426\n",
      "Epoch [29/50], Step [261/735], Loss: 0.1011\n",
      "Epoch [29/50], Step [262/735], Loss: 0.0560\n",
      "Epoch [29/50], Step [263/735], Loss: 0.2087\n",
      "Epoch [29/50], Step [264/735], Loss: 0.0776\n",
      "Epoch [29/50], Step [265/735], Loss: 0.0978\n",
      "Epoch [29/50], Step [266/735], Loss: 0.4132\n",
      "Epoch [29/50], Step [267/735], Loss: 0.1674\n",
      "Epoch [29/50], Step [268/735], Loss: 0.1918\n",
      "Epoch [29/50], Step [269/735], Loss: 0.1311\n",
      "Epoch [29/50], Step [270/735], Loss: 0.0666\n",
      "Epoch [29/50], Step [271/735], Loss: 0.1552\n",
      "Epoch [29/50], Step [272/735], Loss: 0.1189\n",
      "Epoch [29/50], Step [273/735], Loss: 0.0770\n",
      "Epoch [29/50], Step [274/735], Loss: 0.0441\n",
      "Epoch [29/50], Step [275/735], Loss: 0.0887\n",
      "Epoch [29/50], Step [276/735], Loss: 0.0883\n",
      "Epoch [29/50], Step [277/735], Loss: 0.1304\n",
      "Epoch [29/50], Step [278/735], Loss: 0.1809\n",
      "Epoch [29/50], Step [279/735], Loss: 0.5289\n",
      "Epoch [29/50], Step [280/735], Loss: 0.1039\n",
      "Epoch [29/50], Step [281/735], Loss: 0.0975\n",
      "Epoch [29/50], Step [282/735], Loss: 0.1978\n",
      "Epoch [29/50], Step [283/735], Loss: 0.0722\n",
      "Epoch [29/50], Step [284/735], Loss: 0.1140\n",
      "Epoch [29/50], Step [285/735], Loss: 0.0982\n",
      "Epoch [29/50], Step [286/735], Loss: 0.0884\n",
      "Epoch [29/50], Step [287/735], Loss: 0.3687\n",
      "Epoch [29/50], Step [288/735], Loss: 0.0907\n",
      "Epoch [29/50], Step [289/735], Loss: 0.0860\n",
      "Epoch [29/50], Step [290/735], Loss: 0.2025\n",
      "Epoch [29/50], Step [291/735], Loss: 0.0913\n",
      "Epoch [29/50], Step [292/735], Loss: 0.1546\n",
      "Epoch [29/50], Step [293/735], Loss: 0.0750\n",
      "Epoch [29/50], Step [294/735], Loss: 0.1136\n",
      "Epoch [29/50], Step [295/735], Loss: 0.0846\n",
      "Epoch [29/50], Step [296/735], Loss: 0.1105\n",
      "Epoch [29/50], Step [297/735], Loss: 0.0804\n",
      "Epoch [29/50], Step [298/735], Loss: 0.1057\n",
      "Epoch [29/50], Step [299/735], Loss: 0.2478\n",
      "Epoch [29/50], Step [300/735], Loss: 0.0718\n",
      "Epoch [29/50], Step [301/735], Loss: 0.2527\n",
      "Epoch [29/50], Step [302/735], Loss: 0.0625\n",
      "Epoch [29/50], Step [303/735], Loss: 0.1662\n",
      "Epoch [29/50], Step [304/735], Loss: 0.0724\n",
      "Epoch [29/50], Step [305/735], Loss: 0.0652\n",
      "Epoch [29/50], Step [306/735], Loss: 0.2245\n",
      "Epoch [29/50], Step [307/735], Loss: 0.1062\n",
      "Epoch [29/50], Step [308/735], Loss: 0.0559\n",
      "Epoch [29/50], Step [309/735], Loss: 0.0487\n",
      "Epoch [29/50], Step [310/735], Loss: 0.0978\n",
      "Epoch [29/50], Step [311/735], Loss: 0.1997\n",
      "Epoch [29/50], Step [312/735], Loss: 0.0597\n",
      "Epoch [29/50], Step [313/735], Loss: 0.0833\n",
      "Epoch [29/50], Step [314/735], Loss: 0.1710\n",
      "Epoch [29/50], Step [315/735], Loss: 0.0664\n",
      "Epoch [29/50], Step [316/735], Loss: 0.0738\n",
      "Epoch [29/50], Step [317/735], Loss: 0.1647\n",
      "Epoch [29/50], Step [318/735], Loss: 0.1337\n",
      "Epoch [29/50], Step [319/735], Loss: 0.1208\n",
      "Epoch [29/50], Step [320/735], Loss: 0.0856\n",
      "Epoch [29/50], Step [321/735], Loss: 0.0732\n",
      "Epoch [29/50], Step [322/735], Loss: 0.1551\n",
      "Epoch [29/50], Step [323/735], Loss: 0.0719\n",
      "Epoch [29/50], Step [324/735], Loss: 2.0946\n",
      "Epoch [29/50], Step [325/735], Loss: 0.1448\n",
      "Epoch [29/50], Step [326/735], Loss: 0.1059\n",
      "Epoch [29/50], Step [327/735], Loss: 0.1551\n",
      "Epoch [29/50], Step [328/735], Loss: 0.0430\n",
      "Epoch [29/50], Step [329/735], Loss: 0.0504\n",
      "Epoch [29/50], Step [330/735], Loss: 0.1918\n",
      "Epoch [29/50], Step [331/735], Loss: 0.1382\n",
      "Epoch [29/50], Step [332/735], Loss: 0.0481\n",
      "Epoch [29/50], Step [333/735], Loss: 0.1029\n",
      "Epoch [29/50], Step [334/735], Loss: 0.0342\n",
      "Epoch [29/50], Step [335/735], Loss: 0.0937\n",
      "Epoch [29/50], Step [336/735], Loss: 0.0612\n",
      "Epoch [29/50], Step [337/735], Loss: 1.0326\n",
      "Epoch [29/50], Step [338/735], Loss: 0.1930\n",
      "Epoch [29/50], Step [339/735], Loss: 0.2612\n",
      "Epoch [29/50], Step [340/735], Loss: 0.0542\n",
      "Epoch [29/50], Step [341/735], Loss: 0.0711\n",
      "Epoch [29/50], Step [342/735], Loss: 0.0958\n",
      "Epoch [29/50], Step [343/735], Loss: 0.1160\n",
      "Epoch [29/50], Step [344/735], Loss: 0.9489\n",
      "Epoch [29/50], Step [345/735], Loss: 0.1000\n",
      "Epoch [29/50], Step [346/735], Loss: 0.2078\n",
      "Epoch [29/50], Step [347/735], Loss: 0.1724\n",
      "Epoch [29/50], Step [348/735], Loss: 0.1362\n",
      "Epoch [29/50], Step [349/735], Loss: 0.0692\n",
      "Epoch [29/50], Step [350/735], Loss: 0.8096\n",
      "Epoch [29/50], Step [351/735], Loss: 0.2362\n",
      "Epoch [29/50], Step [352/735], Loss: 0.2114\n",
      "Epoch [29/50], Step [353/735], Loss: 0.0501\n",
      "Epoch [29/50], Step [354/735], Loss: 0.1089\n",
      "Epoch [29/50], Step [355/735], Loss: 0.4255\n",
      "Epoch [29/50], Step [356/735], Loss: 0.0820\n",
      "Epoch [29/50], Step [357/735], Loss: 0.1028\n",
      "Epoch [29/50], Step [358/735], Loss: 0.1914\n",
      "Epoch [29/50], Step [359/735], Loss: 0.2373\n",
      "Epoch [29/50], Step [360/735], Loss: 0.0896\n",
      "Epoch [29/50], Step [361/735], Loss: 0.1660\n",
      "Epoch [29/50], Step [362/735], Loss: 0.0695\n",
      "Epoch [29/50], Step [363/735], Loss: 0.1360\n",
      "Epoch [29/50], Step [364/735], Loss: 0.1154\n",
      "Epoch [29/50], Step [365/735], Loss: 0.2214\n",
      "Epoch [29/50], Step [366/735], Loss: 0.0722\n",
      "Epoch [29/50], Step [367/735], Loss: 0.7127\n",
      "Epoch [29/50], Step [368/735], Loss: 0.0830\n",
      "Epoch [29/50], Step [369/735], Loss: 0.0635\n",
      "Epoch [29/50], Step [370/735], Loss: 0.0633\n",
      "Epoch [29/50], Step [371/735], Loss: 0.1799\n",
      "Epoch [29/50], Step [372/735], Loss: 0.1026\n",
      "Epoch [29/50], Step [373/735], Loss: 0.1507\n",
      "Epoch [29/50], Step [374/735], Loss: 0.2337\n",
      "Epoch [29/50], Step [375/735], Loss: 0.0640\n",
      "Epoch [29/50], Step [376/735], Loss: 0.0555\n",
      "Epoch [29/50], Step [377/735], Loss: 0.0756\n",
      "Epoch [29/50], Step [378/735], Loss: 0.0657\n",
      "Epoch [29/50], Step [379/735], Loss: 0.1111\n",
      "Epoch [29/50], Step [380/735], Loss: 0.0622\n",
      "Epoch [29/50], Step [381/735], Loss: 0.1461\n",
      "Epoch [29/50], Step [382/735], Loss: 0.0728\n",
      "Epoch [29/50], Step [383/735], Loss: 0.1229\n",
      "Epoch [29/50], Step [384/735], Loss: 0.0400\n",
      "Epoch [29/50], Step [385/735], Loss: 0.1019\n",
      "Epoch [29/50], Step [386/735], Loss: 0.2357\n",
      "Epoch [29/50], Step [387/735], Loss: 0.1224\n",
      "Epoch [29/50], Step [388/735], Loss: 0.1155\n",
      "Epoch [29/50], Step [389/735], Loss: 0.0556\n",
      "Epoch [29/50], Step [390/735], Loss: 0.0966\n",
      "Epoch [29/50], Step [391/735], Loss: 0.0847\n",
      "Epoch [29/50], Step [392/735], Loss: 0.0324\n",
      "Epoch [29/50], Step [393/735], Loss: 0.5029\n",
      "Epoch [29/50], Step [394/735], Loss: 0.1526\n",
      "Epoch [29/50], Step [395/735], Loss: 0.1073\n",
      "Epoch [29/50], Step [396/735], Loss: 0.1732\n",
      "Epoch [29/50], Step [397/735], Loss: 0.0983\n",
      "Epoch [29/50], Step [398/735], Loss: 0.0730\n",
      "Epoch [29/50], Step [399/735], Loss: 0.1649\n",
      "Epoch [29/50], Step [400/735], Loss: 0.0873\n",
      "Epoch [29/50], Step [401/735], Loss: 0.2451\n",
      "Epoch [29/50], Step [402/735], Loss: 0.0624\n",
      "Epoch [29/50], Step [403/735], Loss: 0.1703\n",
      "Epoch [29/50], Step [404/735], Loss: 0.2129\n",
      "Epoch [29/50], Step [405/735], Loss: 0.0453\n",
      "Epoch [29/50], Step [406/735], Loss: 0.1055\n",
      "Epoch [29/50], Step [407/735], Loss: 0.4409\n",
      "Epoch [29/50], Step [408/735], Loss: 0.0797\n",
      "Epoch [29/50], Step [409/735], Loss: 0.0971\n",
      "Epoch [29/50], Step [410/735], Loss: 0.1544\n",
      "Epoch [29/50], Step [411/735], Loss: 0.0793\n",
      "Epoch [29/50], Step [412/735], Loss: 0.0939\n",
      "Epoch [29/50], Step [413/735], Loss: 0.2167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Step [414/735], Loss: 0.0493\n",
      "Epoch [29/50], Step [415/735], Loss: 0.0971\n",
      "Epoch [29/50], Step [416/735], Loss: 0.0650\n",
      "Epoch [29/50], Step [417/735], Loss: 0.0805\n",
      "Epoch [29/50], Step [418/735], Loss: 0.0646\n",
      "Epoch [29/50], Step [419/735], Loss: 0.0458\n",
      "Epoch [29/50], Step [420/735], Loss: 0.0317\n",
      "Epoch [29/50], Step [421/735], Loss: 0.1217\n",
      "Epoch [29/50], Step [422/735], Loss: 0.1768\n",
      "Epoch [29/50], Step [423/735], Loss: 0.1747\n",
      "Epoch [29/50], Step [424/735], Loss: 0.0997\n",
      "Epoch [29/50], Step [425/735], Loss: 0.1043\n",
      "Epoch [29/50], Step [426/735], Loss: 0.1131\n",
      "Epoch [29/50], Step [427/735], Loss: 0.3911\n",
      "Epoch [29/50], Step [428/735], Loss: 0.1039\n",
      "Epoch [29/50], Step [429/735], Loss: 0.1717\n",
      "Epoch [29/50], Step [430/735], Loss: 0.1001\n",
      "Epoch [29/50], Step [431/735], Loss: 0.1915\n",
      "Epoch [29/50], Step [432/735], Loss: 0.0954\n",
      "Epoch [29/50], Step [433/735], Loss: 1.6917\n",
      "Epoch [29/50], Step [434/735], Loss: 1.1057\n",
      "Epoch [29/50], Step [435/735], Loss: 0.0737\n",
      "Epoch [29/50], Step [436/735], Loss: 0.3348\n",
      "Epoch [29/50], Step [437/735], Loss: 0.0634\n",
      "Epoch [29/50], Step [438/735], Loss: 0.1442\n",
      "Epoch [29/50], Step [439/735], Loss: 0.3516\n",
      "Epoch [29/50], Step [440/735], Loss: 0.0659\n",
      "Epoch [29/50], Step [441/735], Loss: 0.1844\n",
      "Epoch [29/50], Step [442/735], Loss: 0.2660\n",
      "Epoch [29/50], Step [443/735], Loss: 0.7768\n",
      "Epoch [29/50], Step [444/735], Loss: 0.1071\n",
      "Epoch [29/50], Step [445/735], Loss: 0.1010\n",
      "Epoch [29/50], Step [446/735], Loss: 0.1323\n",
      "Epoch [29/50], Step [447/735], Loss: 0.1715\n",
      "Epoch [29/50], Step [448/735], Loss: 0.0464\n",
      "Epoch [29/50], Step [449/735], Loss: 0.0811\n",
      "Epoch [29/50], Step [450/735], Loss: 0.0886\n",
      "Epoch [29/50], Step [451/735], Loss: 0.3351\n",
      "Epoch [29/50], Step [452/735], Loss: 0.4132\n",
      "Epoch [29/50], Step [453/735], Loss: 0.1225\n",
      "Epoch [29/50], Step [454/735], Loss: 0.8411\n",
      "Epoch [29/50], Step [455/735], Loss: 0.0663\n",
      "Epoch [29/50], Step [456/735], Loss: 0.1256\n",
      "Epoch [29/50], Step [457/735], Loss: 0.1001\n",
      "Epoch [29/50], Step [458/735], Loss: 0.1802\n",
      "Epoch [29/50], Step [459/735], Loss: 0.1651\n",
      "Epoch [29/50], Step [460/735], Loss: 0.0876\n",
      "Epoch [29/50], Step [461/735], Loss: 0.1313\n",
      "Epoch [29/50], Step [462/735], Loss: 0.1524\n",
      "Epoch [29/50], Step [463/735], Loss: 0.0815\n",
      "Epoch [29/50], Step [464/735], Loss: 0.6622\n",
      "Epoch [29/50], Step [465/735], Loss: 0.1154\n",
      "Epoch [29/50], Step [466/735], Loss: 0.1909\n",
      "Epoch [29/50], Step [467/735], Loss: 0.1069\n",
      "Epoch [29/50], Step [468/735], Loss: 0.2037\n",
      "Epoch [29/50], Step [469/735], Loss: 0.0756\n",
      "Epoch [29/50], Step [470/735], Loss: 0.1250\n",
      "Epoch [29/50], Step [471/735], Loss: 0.1534\n",
      "Epoch [29/50], Step [472/735], Loss: 0.1064\n",
      "Epoch [29/50], Step [473/735], Loss: 0.2659\n",
      "Epoch [29/50], Step [474/735], Loss: 0.1967\n",
      "Epoch [29/50], Step [475/735], Loss: 0.2095\n",
      "Epoch [29/50], Step [476/735], Loss: 0.0834\n",
      "Epoch [29/50], Step [477/735], Loss: 0.1293\n",
      "Epoch [29/50], Step [478/735], Loss: 0.1447\n",
      "Epoch [29/50], Step [479/735], Loss: 0.1271\n",
      "Epoch [29/50], Step [480/735], Loss: 0.0513\n",
      "Epoch [29/50], Step [481/735], Loss: 2.0619\n",
      "Epoch [29/50], Step [482/735], Loss: 0.0637\n",
      "Epoch [29/50], Step [483/735], Loss: 0.0856\n",
      "Epoch [29/50], Step [484/735], Loss: 0.1484\n",
      "Epoch [29/50], Step [485/735], Loss: 0.1426\n",
      "Epoch [29/50], Step [486/735], Loss: 0.0517\n",
      "Epoch [29/50], Step [487/735], Loss: 0.0793\n",
      "Epoch [29/50], Step [488/735], Loss: 0.1965\n",
      "Epoch [29/50], Step [489/735], Loss: 0.2322\n",
      "Epoch [29/50], Step [490/735], Loss: 0.0629\n",
      "Epoch [29/50], Step [491/735], Loss: 0.1224\n",
      "Epoch [29/50], Step [492/735], Loss: 0.0763\n",
      "Epoch [29/50], Step [493/735], Loss: 0.0684\n",
      "Epoch [29/50], Step [494/735], Loss: 0.0746\n",
      "Epoch [29/50], Step [495/735], Loss: 0.0933\n",
      "Epoch [29/50], Step [496/735], Loss: 0.0835\n",
      "Epoch [29/50], Step [497/735], Loss: 0.3770\n",
      "Epoch [29/50], Step [498/735], Loss: 0.1097\n",
      "Epoch [29/50], Step [499/735], Loss: 0.0963\n",
      "Epoch [29/50], Step [500/735], Loss: 0.0826\n",
      "Epoch [29/50], Step [501/735], Loss: 1.3593\n",
      "Epoch [29/50], Step [502/735], Loss: 0.8914\n",
      "Epoch [29/50], Step [503/735], Loss: 0.0626\n",
      "Epoch [29/50], Step [504/735], Loss: 0.1068\n",
      "Epoch [29/50], Step [505/735], Loss: 0.0446\n",
      "Epoch [29/50], Step [506/735], Loss: 0.1953\n",
      "Epoch [29/50], Step [507/735], Loss: 0.1002\n",
      "Epoch [29/50], Step [508/735], Loss: 0.1068\n",
      "Epoch [29/50], Step [509/735], Loss: 0.1237\n",
      "Epoch [29/50], Step [510/735], Loss: 0.0861\n",
      "Epoch [29/50], Step [511/735], Loss: 0.1968\n",
      "Epoch [29/50], Step [512/735], Loss: 0.0330\n",
      "Epoch [29/50], Step [513/735], Loss: 0.1631\n",
      "Epoch [29/50], Step [514/735], Loss: 0.1096\n",
      "Epoch [29/50], Step [515/735], Loss: 0.0654\n",
      "Epoch [29/50], Step [516/735], Loss: 0.0945\n",
      "Epoch [29/50], Step [517/735], Loss: 0.1051\n",
      "Epoch [29/50], Step [518/735], Loss: 0.1491\n",
      "Epoch [29/50], Step [519/735], Loss: 0.8293\n",
      "Epoch [29/50], Step [520/735], Loss: 0.0583\n",
      "Epoch [29/50], Step [521/735], Loss: 0.0991\n",
      "Epoch [29/50], Step [522/735], Loss: 0.0714\n",
      "Epoch [29/50], Step [523/735], Loss: 0.0670\n",
      "Epoch [29/50], Step [524/735], Loss: 0.1764\n",
      "Epoch [29/50], Step [525/735], Loss: 0.3110\n",
      "Epoch [29/50], Step [526/735], Loss: 0.0604\n",
      "Epoch [29/50], Step [527/735], Loss: 0.4039\n",
      "Epoch [29/50], Step [528/735], Loss: 0.2587\n",
      "Epoch [29/50], Step [529/735], Loss: 0.2087\n",
      "Epoch [29/50], Step [530/735], Loss: 0.1726\n",
      "Epoch [29/50], Step [531/735], Loss: 0.1107\n",
      "Epoch [29/50], Step [532/735], Loss: 0.1710\n",
      "Epoch [29/50], Step [533/735], Loss: 0.1079\n",
      "Epoch [29/50], Step [534/735], Loss: 0.0662\n",
      "Epoch [29/50], Step [535/735], Loss: 0.2115\n",
      "Epoch [29/50], Step [536/735], Loss: 0.0741\n",
      "Epoch [29/50], Step [537/735], Loss: 0.1382\n",
      "Epoch [29/50], Step [538/735], Loss: 0.5569\n",
      "Epoch [29/50], Step [539/735], Loss: 0.1671\n",
      "Epoch [29/50], Step [540/735], Loss: 1.1370\n",
      "Epoch [29/50], Step [541/735], Loss: 0.1187\n",
      "Epoch [29/50], Step [542/735], Loss: 0.2897\n",
      "Epoch [29/50], Step [543/735], Loss: 0.0572\n",
      "Epoch [29/50], Step [544/735], Loss: 0.0859\n",
      "Epoch [29/50], Step [545/735], Loss: 0.2986\n",
      "Epoch [29/50], Step [546/735], Loss: 0.0765\n",
      "Epoch [29/50], Step [547/735], Loss: 0.0370\n",
      "Epoch [29/50], Step [548/735], Loss: 0.1385\n",
      "Epoch [29/50], Step [549/735], Loss: 0.2205\n",
      "Epoch [29/50], Step [550/735], Loss: 1.7926\n",
      "Epoch [29/50], Step [551/735], Loss: 0.1326\n",
      "Epoch [29/50], Step [552/735], Loss: 0.1966\n",
      "Epoch [29/50], Step [553/735], Loss: 0.0589\n",
      "Epoch [29/50], Step [554/735], Loss: 0.2800\n",
      "Epoch [29/50], Step [555/735], Loss: 0.1720\n",
      "Epoch [29/50], Step [556/735], Loss: 0.0801\n",
      "Epoch [29/50], Step [557/735], Loss: 0.0896\n",
      "Epoch [29/50], Step [558/735], Loss: 0.0688\n",
      "Epoch [29/50], Step [559/735], Loss: 0.1403\n",
      "Epoch [29/50], Step [560/735], Loss: 0.2366\n",
      "Epoch [29/50], Step [561/735], Loss: 0.1299\n",
      "Epoch [29/50], Step [562/735], Loss: 0.1241\n",
      "Epoch [29/50], Step [563/735], Loss: 0.0539\n",
      "Epoch [29/50], Step [564/735], Loss: 0.1684\n",
      "Epoch [29/50], Step [565/735], Loss: 0.2144\n",
      "Epoch [29/50], Step [566/735], Loss: 0.1231\n",
      "Epoch [29/50], Step [567/735], Loss: 0.0750\n",
      "Epoch [29/50], Step [568/735], Loss: 0.0824\n",
      "Epoch [29/50], Step [569/735], Loss: 0.0933\n",
      "Epoch [29/50], Step [570/735], Loss: 0.1933\n",
      "Epoch [29/50], Step [571/735], Loss: 0.0713\n",
      "Epoch [29/50], Step [572/735], Loss: 0.1159\n",
      "Epoch [29/50], Step [573/735], Loss: 0.1202\n",
      "Epoch [29/50], Step [574/735], Loss: 0.1609\n",
      "Epoch [29/50], Step [575/735], Loss: 0.2308\n",
      "Epoch [29/50], Step [576/735], Loss: 0.6001\n",
      "Epoch [29/50], Step [577/735], Loss: 0.2110\n",
      "Epoch [29/50], Step [578/735], Loss: 0.0647\n",
      "Epoch [29/50], Step [579/735], Loss: 0.0492\n",
      "Epoch [29/50], Step [580/735], Loss: 0.4563\n",
      "Epoch [29/50], Step [581/735], Loss: 0.0289\n",
      "Epoch [29/50], Step [582/735], Loss: 0.0820\n",
      "Epoch [29/50], Step [583/735], Loss: 0.1095\n",
      "Epoch [29/50], Step [584/735], Loss: 0.0801\n",
      "Epoch [29/50], Step [585/735], Loss: 0.0928\n",
      "Epoch [29/50], Step [586/735], Loss: 0.0482\n",
      "Epoch [29/50], Step [587/735], Loss: 0.0721\n",
      "Epoch [29/50], Step [588/735], Loss: 0.7256\n",
      "Epoch [29/50], Step [589/735], Loss: 0.2012\n",
      "Epoch [29/50], Step [590/735], Loss: 0.0883\n",
      "Epoch [29/50], Step [591/735], Loss: 0.1579\n",
      "Epoch [29/50], Step [592/735], Loss: 0.1596\n",
      "Epoch [29/50], Step [593/735], Loss: 0.0429\n",
      "Epoch [29/50], Step [594/735], Loss: 0.1654\n",
      "Epoch [29/50], Step [595/735], Loss: 0.1451\n",
      "Epoch [29/50], Step [596/735], Loss: 0.0906\n",
      "Epoch [29/50], Step [597/735], Loss: 0.0873\n",
      "Epoch [29/50], Step [598/735], Loss: 0.1522\n",
      "Epoch [29/50], Step [599/735], Loss: 0.1170\n",
      "Epoch [29/50], Step [600/735], Loss: 0.0710\n",
      "Epoch [29/50], Step [601/735], Loss: 0.2845\n",
      "Epoch [29/50], Step [602/735], Loss: 0.1126\n",
      "Epoch [29/50], Step [603/735], Loss: 0.2082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Step [604/735], Loss: 0.8951\n",
      "Epoch [29/50], Step [605/735], Loss: 0.0819\n",
      "Epoch [29/50], Step [606/735], Loss: 0.2535\n",
      "Epoch [29/50], Step [607/735], Loss: 0.0696\n",
      "Epoch [29/50], Step [608/735], Loss: 0.0688\n",
      "Epoch [29/50], Step [609/735], Loss: 0.1579\n",
      "Epoch [29/50], Step [610/735], Loss: 0.1815\n",
      "Epoch [29/50], Step [611/735], Loss: 0.1573\n",
      "Epoch [29/50], Step [612/735], Loss: 0.3168\n",
      "Epoch [29/50], Step [613/735], Loss: 0.0838\n",
      "Epoch [29/50], Step [614/735], Loss: 0.1028\n",
      "Epoch [29/50], Step [615/735], Loss: 0.1107\n",
      "Epoch [29/50], Step [616/735], Loss: 0.1299\n",
      "Epoch [29/50], Step [617/735], Loss: 0.1124\n",
      "Epoch [29/50], Step [618/735], Loss: 0.1000\n",
      "Epoch [29/50], Step [619/735], Loss: 0.0622\n",
      "Epoch [29/50], Step [620/735], Loss: 0.0503\n",
      "Epoch [29/50], Step [621/735], Loss: 0.0744\n",
      "Epoch [29/50], Step [622/735], Loss: 0.0665\n",
      "Epoch [29/50], Step [623/735], Loss: 0.0956\n",
      "Epoch [29/50], Step [624/735], Loss: 0.2281\n",
      "Epoch [29/50], Step [625/735], Loss: 0.2966\n",
      "Epoch [29/50], Step [626/735], Loss: 0.4661\n",
      "Epoch [29/50], Step [627/735], Loss: 0.1238\n",
      "Epoch [29/50], Step [628/735], Loss: 0.1846\n",
      "Epoch [29/50], Step [629/735], Loss: 0.1130\n",
      "Epoch [29/50], Step [630/735], Loss: 0.2243\n",
      "Epoch [29/50], Step [631/735], Loss: 0.0605\n",
      "Epoch [29/50], Step [632/735], Loss: 0.0722\n",
      "Epoch [29/50], Step [633/735], Loss: 0.6009\n",
      "Epoch [29/50], Step [634/735], Loss: 0.1489\n",
      "Epoch [29/50], Step [635/735], Loss: 0.0339\n",
      "Epoch [29/50], Step [636/735], Loss: 0.1149\n",
      "Epoch [29/50], Step [637/735], Loss: 0.4459\n",
      "Epoch [29/50], Step [638/735], Loss: 0.2647\n",
      "Epoch [29/50], Step [639/735], Loss: 0.1816\n",
      "Epoch [29/50], Step [640/735], Loss: 0.1083\n",
      "Epoch [29/50], Step [641/735], Loss: 0.1015\n",
      "Epoch [29/50], Step [642/735], Loss: 0.0781\n",
      "Epoch [29/50], Step [643/735], Loss: 0.0560\n",
      "Epoch [29/50], Step [644/735], Loss: 0.0792\n",
      "Epoch [29/50], Step [645/735], Loss: 0.1965\n",
      "Epoch [29/50], Step [646/735], Loss: 0.1201\n",
      "Epoch [29/50], Step [647/735], Loss: 0.0522\n",
      "Epoch [29/50], Step [648/735], Loss: 0.1060\n",
      "Epoch [29/50], Step [649/735], Loss: 0.0844\n",
      "Epoch [29/50], Step [650/735], Loss: 0.1812\n",
      "Epoch [29/50], Step [651/735], Loss: 0.2674\n",
      "Epoch [29/50], Step [652/735], Loss: 0.2181\n",
      "Epoch [29/50], Step [653/735], Loss: 0.0843\n",
      "Epoch [29/50], Step [654/735], Loss: 0.2731\n",
      "Epoch [29/50], Step [655/735], Loss: 0.0815\n",
      "Epoch [29/50], Step [656/735], Loss: 0.0606\n",
      "Epoch [29/50], Step [657/735], Loss: 0.0698\n",
      "Epoch [29/50], Step [658/735], Loss: 0.0776\n",
      "Epoch [29/50], Step [659/735], Loss: 0.2391\n",
      "Epoch [29/50], Step [660/735], Loss: 0.1588\n",
      "Epoch [29/50], Step [661/735], Loss: 0.0733\n",
      "Epoch [29/50], Step [662/735], Loss: 0.2114\n",
      "Epoch [29/50], Step [663/735], Loss: 0.2081\n",
      "Epoch [29/50], Step [664/735], Loss: 0.1699\n",
      "Epoch [29/50], Step [665/735], Loss: 0.0549\n",
      "Epoch [29/50], Step [666/735], Loss: 0.2406\n",
      "Epoch [29/50], Step [667/735], Loss: 0.1154\n",
      "Epoch [29/50], Step [668/735], Loss: 0.4078\n",
      "Epoch [29/50], Step [669/735], Loss: 0.1044\n",
      "Epoch [29/50], Step [670/735], Loss: 0.0797\n",
      "Epoch [29/50], Step [671/735], Loss: 0.2075\n",
      "Epoch [29/50], Step [672/735], Loss: 0.1770\n",
      "Epoch [29/50], Step [673/735], Loss: 0.0987\n",
      "Epoch [29/50], Step [674/735], Loss: 0.1908\n",
      "Epoch [29/50], Step [675/735], Loss: 0.1548\n",
      "Epoch [29/50], Step [676/735], Loss: 0.1098\n",
      "Epoch [29/50], Step [677/735], Loss: 0.0911\n",
      "Epoch [29/50], Step [678/735], Loss: 0.1572\n",
      "Epoch [29/50], Step [679/735], Loss: 0.1428\n",
      "Epoch [29/50], Step [680/735], Loss: 0.0984\n",
      "Epoch [29/50], Step [681/735], Loss: 2.0382\n",
      "Epoch [29/50], Step [682/735], Loss: 0.0429\n",
      "Epoch [29/50], Step [683/735], Loss: 0.1244\n",
      "Epoch [29/50], Step [684/735], Loss: 0.2681\n",
      "Epoch [29/50], Step [685/735], Loss: 0.8165\n",
      "Epoch [29/50], Step [686/735], Loss: 0.0539\n",
      "Epoch [29/50], Step [687/735], Loss: 0.0707\n",
      "Epoch [29/50], Step [688/735], Loss: 0.1141\n",
      "Epoch [29/50], Step [689/735], Loss: 0.0903\n",
      "Epoch [29/50], Step [690/735], Loss: 0.0591\n",
      "Epoch [29/50], Step [691/735], Loss: 0.0588\n",
      "Epoch [29/50], Step [692/735], Loss: 0.0787\n",
      "Epoch [29/50], Step [693/735], Loss: 0.0629\n",
      "Epoch [29/50], Step [694/735], Loss: 0.1554\n",
      "Epoch [29/50], Step [695/735], Loss: 0.0905\n",
      "Epoch [29/50], Step [696/735], Loss: 0.1930\n",
      "Epoch [29/50], Step [697/735], Loss: 0.6027\n",
      "Epoch [29/50], Step [698/735], Loss: 0.1140\n",
      "Epoch [29/50], Step [699/735], Loss: 0.1394\n",
      "Epoch [29/50], Step [700/735], Loss: 0.0770\n",
      "Epoch [29/50], Step [701/735], Loss: 0.1974\n",
      "Epoch [29/50], Step [702/735], Loss: 0.0977\n",
      "Epoch [29/50], Step [703/735], Loss: 0.1189\n",
      "Epoch [29/50], Step [704/735], Loss: 0.0821\n",
      "Epoch [29/50], Step [705/735], Loss: 0.1508\n",
      "Epoch [29/50], Step [706/735], Loss: 0.1335\n",
      "Epoch [29/50], Step [707/735], Loss: 0.0774\n",
      "Epoch [29/50], Step [708/735], Loss: 0.6990\n",
      "Epoch [29/50], Step [709/735], Loss: 0.1292\n",
      "Epoch [29/50], Step [710/735], Loss: 0.1482\n",
      "Epoch [29/50], Step [711/735], Loss: 0.6869\n",
      "Epoch [29/50], Step [712/735], Loss: 0.5676\n",
      "Epoch [29/50], Step [713/735], Loss: 0.1023\n",
      "Epoch [29/50], Step [714/735], Loss: 0.1337\n",
      "Epoch [29/50], Step [715/735], Loss: 0.0754\n",
      "Epoch [29/50], Step [716/735], Loss: 0.0895\n",
      "Epoch [29/50], Step [717/735], Loss: 0.0603\n",
      "Epoch [29/50], Step [718/735], Loss: 0.2156\n",
      "Epoch [29/50], Step [719/735], Loss: 0.0630\n",
      "Epoch [29/50], Step [720/735], Loss: 0.1658\n",
      "Epoch [29/50], Step [721/735], Loss: 0.1671\n",
      "Epoch [29/50], Step [722/735], Loss: 0.1704\n",
      "Epoch [29/50], Step [723/735], Loss: 0.0742\n",
      "Epoch [29/50], Step [724/735], Loss: 0.1512\n",
      "Epoch [29/50], Step [725/735], Loss: 0.1512\n",
      "Epoch [29/50], Step [726/735], Loss: 0.0702\n",
      "Epoch [29/50], Step [727/735], Loss: 0.0571\n",
      "Epoch [29/50], Step [728/735], Loss: 0.1145\n",
      "Epoch [29/50], Step [729/735], Loss: 0.1243\n",
      "Epoch [29/50], Step [730/735], Loss: 0.0679\n",
      "Epoch [29/50], Step [731/735], Loss: 0.1837\n",
      "Epoch [29/50], Step [732/735], Loss: 0.0628\n",
      "Epoch [29/50], Step [733/735], Loss: 0.1078\n",
      "Epoch [29/50], Step [734/735], Loss: 0.4641\n",
      "Epoch [29/50], Step [735/735], Loss: 0.1277\n",
      "Epoch [30/50], Step [1/735], Loss: 0.0883\n",
      "Epoch [30/50], Step [2/735], Loss: 0.1477\n",
      "Epoch [30/50], Step [3/735], Loss: 0.0773\n",
      "Epoch [30/50], Step [4/735], Loss: 0.6732\n",
      "Epoch [30/50], Step [5/735], Loss: 0.1266\n",
      "Epoch [30/50], Step [6/735], Loss: 0.0560\n",
      "Epoch [30/50], Step [7/735], Loss: 0.0659\n",
      "Epoch [30/50], Step [8/735], Loss: 0.0887\n",
      "Epoch [30/50], Step [9/735], Loss: 0.1617\n",
      "Epoch [30/50], Step [10/735], Loss: 0.0377\n",
      "Epoch [30/50], Step [11/735], Loss: 0.1096\n",
      "Epoch [30/50], Step [12/735], Loss: 0.1412\n",
      "Epoch [30/50], Step [13/735], Loss: 0.0642\n",
      "Epoch [30/50], Step [14/735], Loss: 0.0774\n",
      "Epoch [30/50], Step [15/735], Loss: 0.0578\n",
      "Epoch [30/50], Step [16/735], Loss: 0.1082\n",
      "Epoch [30/50], Step [17/735], Loss: 0.0584\n",
      "Epoch [30/50], Step [18/735], Loss: 0.0866\n",
      "Epoch [30/50], Step [19/735], Loss: 0.0789\n",
      "Epoch [30/50], Step [20/735], Loss: 0.0533\n",
      "Epoch [30/50], Step [21/735], Loss: 0.0469\n",
      "Epoch [30/50], Step [22/735], Loss: 0.1903\n",
      "Epoch [30/50], Step [23/735], Loss: 0.0351\n",
      "Epoch [30/50], Step [24/735], Loss: 0.0918\n",
      "Epoch [30/50], Step [25/735], Loss: 0.1860\n",
      "Epoch [30/50], Step [26/735], Loss: 0.0983\n",
      "Epoch [30/50], Step [27/735], Loss: 0.0870\n",
      "Epoch [30/50], Step [28/735], Loss: 0.0650\n",
      "Epoch [30/50], Step [29/735], Loss: 0.1325\n",
      "Epoch [30/50], Step [30/735], Loss: 0.0877\n",
      "Epoch [30/50], Step [31/735], Loss: 0.1101\n",
      "Epoch [30/50], Step [32/735], Loss: 0.0669\n",
      "Epoch [30/50], Step [33/735], Loss: 0.2814\n",
      "Epoch [30/50], Step [34/735], Loss: 0.1158\n",
      "Epoch [30/50], Step [35/735], Loss: 0.0893\n",
      "Epoch [30/50], Step [36/735], Loss: 0.1782\n",
      "Epoch [30/50], Step [37/735], Loss: 0.2233\n",
      "Epoch [30/50], Step [38/735], Loss: 0.0701\n",
      "Epoch [30/50], Step [39/735], Loss: 0.0551\n",
      "Epoch [30/50], Step [40/735], Loss: 0.0701\n",
      "Epoch [30/50], Step [41/735], Loss: 0.0846\n",
      "Epoch [30/50], Step [42/735], Loss: 0.1393\n",
      "Epoch [30/50], Step [43/735], Loss: 0.1550\n",
      "Epoch [30/50], Step [44/735], Loss: 0.0670\n",
      "Epoch [30/50], Step [45/735], Loss: 0.1491\n",
      "Epoch [30/50], Step [46/735], Loss: 0.0878\n",
      "Epoch [30/50], Step [47/735], Loss: 0.1452\n",
      "Epoch [30/50], Step [48/735], Loss: 0.1510\n",
      "Epoch [30/50], Step [49/735], Loss: 0.0743\n",
      "Epoch [30/50], Step [50/735], Loss: 0.0622\n",
      "Epoch [30/50], Step [51/735], Loss: 0.0704\n",
      "Epoch [30/50], Step [52/735], Loss: 0.0983\n",
      "Epoch [30/50], Step [53/735], Loss: 0.0693\n",
      "Epoch [30/50], Step [54/735], Loss: 0.0441\n",
      "Epoch [30/50], Step [55/735], Loss: 0.0190\n",
      "Epoch [30/50], Step [56/735], Loss: 1.7002\n",
      "Epoch [30/50], Step [57/735], Loss: 0.2012\n",
      "Epoch [30/50], Step [58/735], Loss: 0.1754\n",
      "Epoch [30/50], Step [59/735], Loss: 0.1536\n",
      "Epoch [30/50], Step [60/735], Loss: 0.0705\n",
      "Epoch [30/50], Step [61/735], Loss: 0.0758\n",
      "Epoch [30/50], Step [62/735], Loss: 0.1872\n",
      "Epoch [30/50], Step [63/735], Loss: 0.1913\n",
      "Epoch [30/50], Step [64/735], Loss: 0.3918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Step [65/735], Loss: 0.3249\n",
      "Epoch [30/50], Step [66/735], Loss: 0.1108\n",
      "Epoch [30/50], Step [67/735], Loss: 1.0701\n",
      "Epoch [30/50], Step [68/735], Loss: 0.1301\n",
      "Epoch [30/50], Step [69/735], Loss: 0.2146\n",
      "Epoch [30/50], Step [70/735], Loss: 0.0897\n",
      "Epoch [30/50], Step [71/735], Loss: 0.1248\n",
      "Epoch [30/50], Step [72/735], Loss: 0.0774\n",
      "Epoch [30/50], Step [73/735], Loss: 0.0718\n",
      "Epoch [30/50], Step [74/735], Loss: 0.1414\n",
      "Epoch [30/50], Step [75/735], Loss: 0.1375\n",
      "Epoch [30/50], Step [76/735], Loss: 0.2812\n",
      "Epoch [30/50], Step [77/735], Loss: 0.1345\n",
      "Epoch [30/50], Step [78/735], Loss: 0.0758\n",
      "Epoch [30/50], Step [79/735], Loss: 0.7531\n",
      "Epoch [30/50], Step [80/735], Loss: 0.1017\n",
      "Epoch [30/50], Step [81/735], Loss: 0.0725\n",
      "Epoch [30/50], Step [82/735], Loss: 0.0488\n",
      "Epoch [30/50], Step [83/735], Loss: 0.6730\n",
      "Epoch [30/50], Step [84/735], Loss: 0.1567\n",
      "Epoch [30/50], Step [85/735], Loss: 0.0763\n",
      "Epoch [30/50], Step [86/735], Loss: 0.2412\n",
      "Epoch [30/50], Step [87/735], Loss: 0.1300\n",
      "Epoch [30/50], Step [88/735], Loss: 0.0572\n",
      "Epoch [30/50], Step [89/735], Loss: 0.3440\n",
      "Epoch [30/50], Step [90/735], Loss: 0.2336\n",
      "Epoch [30/50], Step [91/735], Loss: 0.1991\n",
      "Epoch [30/50], Step [92/735], Loss: 0.1601\n",
      "Epoch [30/50], Step [93/735], Loss: 0.0388\n",
      "Epoch [30/50], Step [94/735], Loss: 0.2113\n",
      "Epoch [30/50], Step [95/735], Loss: 0.0882\n",
      "Epoch [30/50], Step [96/735], Loss: 0.1341\n",
      "Epoch [30/50], Step [97/735], Loss: 0.0393\n",
      "Epoch [30/50], Step [98/735], Loss: 0.0502\n",
      "Epoch [30/50], Step [99/735], Loss: 0.0519\n",
      "Epoch [30/50], Step [100/735], Loss: 0.2264\n",
      "Epoch [30/50], Step [101/735], Loss: 0.0978\n",
      "Epoch [30/50], Step [102/735], Loss: 0.1436\n",
      "Epoch [30/50], Step [103/735], Loss: 0.1219\n",
      "Epoch [30/50], Step [104/735], Loss: 0.0681\n",
      "Epoch [30/50], Step [105/735], Loss: 0.0655\n",
      "Epoch [30/50], Step [106/735], Loss: 0.3299\n",
      "Epoch [30/50], Step [107/735], Loss: 0.1558\n",
      "Epoch [30/50], Step [108/735], Loss: 0.0578\n",
      "Epoch [30/50], Step [109/735], Loss: 0.1631\n",
      "Epoch [30/50], Step [110/735], Loss: 0.0835\n",
      "Epoch [30/50], Step [111/735], Loss: 0.1269\n",
      "Epoch [30/50], Step [112/735], Loss: 0.0579\n",
      "Epoch [30/50], Step [113/735], Loss: 0.2516\n",
      "Epoch [30/50], Step [114/735], Loss: 0.0966\n",
      "Epoch [30/50], Step [115/735], Loss: 0.0633\n",
      "Epoch [30/50], Step [116/735], Loss: 0.0768\n",
      "Epoch [30/50], Step [117/735], Loss: 0.0367\n",
      "Epoch [30/50], Step [118/735], Loss: 0.3537\n",
      "Epoch [30/50], Step [119/735], Loss: 0.1714\n",
      "Epoch [30/50], Step [120/735], Loss: 0.1020\n",
      "Epoch [30/50], Step [121/735], Loss: 0.6421\n",
      "Epoch [30/50], Step [122/735], Loss: 0.1393\n",
      "Epoch [30/50], Step [123/735], Loss: 0.1389\n",
      "Epoch [30/50], Step [124/735], Loss: 0.0900\n",
      "Epoch [30/50], Step [125/735], Loss: 0.1070\n",
      "Epoch [30/50], Step [126/735], Loss: 0.0870\n",
      "Epoch [30/50], Step [127/735], Loss: 0.2120\n",
      "Epoch [30/50], Step [128/735], Loss: 0.0532\n",
      "Epoch [30/50], Step [129/735], Loss: 0.0622\n",
      "Epoch [30/50], Step [130/735], Loss: 0.1129\n",
      "Epoch [30/50], Step [131/735], Loss: 0.1264\n",
      "Epoch [30/50], Step [132/735], Loss: 0.1109\n",
      "Epoch [30/50], Step [133/735], Loss: 0.1994\n",
      "Epoch [30/50], Step [134/735], Loss: 0.0615\n",
      "Epoch [30/50], Step [135/735], Loss: 0.8206\n",
      "Epoch [30/50], Step [136/735], Loss: 0.1772\n",
      "Epoch [30/50], Step [137/735], Loss: 0.1819\n",
      "Epoch [30/50], Step [138/735], Loss: 0.0823\n",
      "Epoch [30/50], Step [139/735], Loss: 0.0921\n",
      "Epoch [30/50], Step [140/735], Loss: 0.0969\n",
      "Epoch [30/50], Step [141/735], Loss: 0.1565\n",
      "Epoch [30/50], Step [142/735], Loss: 0.0744\n",
      "Epoch [30/50], Step [143/735], Loss: 0.1061\n",
      "Epoch [30/50], Step [144/735], Loss: 0.1304\n",
      "Epoch [30/50], Step [145/735], Loss: 0.1025\n",
      "Epoch [30/50], Step [146/735], Loss: 0.0546\n",
      "Epoch [30/50], Step [147/735], Loss: 0.0902\n",
      "Epoch [30/50], Step [148/735], Loss: 0.3235\n",
      "Epoch [30/50], Step [149/735], Loss: 0.0792\n",
      "Epoch [30/50], Step [150/735], Loss: 0.0753\n",
      "Epoch [30/50], Step [151/735], Loss: 0.0493\n",
      "Epoch [30/50], Step [152/735], Loss: 0.1274\n",
      "Epoch [30/50], Step [153/735], Loss: 1.8720\n",
      "Epoch [30/50], Step [154/735], Loss: 0.1138\n",
      "Epoch [30/50], Step [155/735], Loss: 0.3720\n",
      "Epoch [30/50], Step [156/735], Loss: 0.0554\n",
      "Epoch [30/50], Step [157/735], Loss: 0.6637\n",
      "Epoch [30/50], Step [158/735], Loss: 0.0967\n",
      "Epoch [30/50], Step [159/735], Loss: 0.0923\n",
      "Epoch [30/50], Step [160/735], Loss: 0.0918\n",
      "Epoch [30/50], Step [161/735], Loss: 0.5662\n",
      "Epoch [30/50], Step [162/735], Loss: 0.6318\n",
      "Epoch [30/50], Step [163/735], Loss: 0.0813\n",
      "Epoch [30/50], Step [164/735], Loss: 0.1006\n",
      "Epoch [30/50], Step [165/735], Loss: 0.0534\n",
      "Epoch [30/50], Step [166/735], Loss: 0.4188\n",
      "Epoch [30/50], Step [167/735], Loss: 0.0497\n",
      "Epoch [30/50], Step [168/735], Loss: 0.0693\n",
      "Epoch [30/50], Step [169/735], Loss: 0.1190\n",
      "Epoch [30/50], Step [170/735], Loss: 0.0636\n",
      "Epoch [30/50], Step [171/735], Loss: 0.0989\n",
      "Epoch [30/50], Step [172/735], Loss: 0.7069\n",
      "Epoch [30/50], Step [173/735], Loss: 0.0375\n",
      "Epoch [30/50], Step [174/735], Loss: 0.0581\n",
      "Epoch [30/50], Step [175/735], Loss: 0.1079\n",
      "Epoch [30/50], Step [176/735], Loss: 1.8175\n",
      "Epoch [30/50], Step [177/735], Loss: 0.0548\n",
      "Epoch [30/50], Step [178/735], Loss: 0.4829\n",
      "Epoch [30/50], Step [179/735], Loss: 0.0922\n",
      "Epoch [30/50], Step [180/735], Loss: 0.1317\n",
      "Epoch [30/50], Step [181/735], Loss: 0.4151\n",
      "Epoch [30/50], Step [182/735], Loss: 0.1190\n",
      "Epoch [30/50], Step [183/735], Loss: 0.0994\n",
      "Epoch [30/50], Step [184/735], Loss: 0.1325\n",
      "Epoch [30/50], Step [185/735], Loss: 0.0768\n",
      "Epoch [30/50], Step [186/735], Loss: 0.0688\n",
      "Epoch [30/50], Step [187/735], Loss: 0.0621\n",
      "Epoch [30/50], Step [188/735], Loss: 0.1530\n",
      "Epoch [30/50], Step [189/735], Loss: 0.2204\n",
      "Epoch [30/50], Step [190/735], Loss: 0.0843\n",
      "Epoch [30/50], Step [191/735], Loss: 0.1045\n",
      "Epoch [30/50], Step [192/735], Loss: 0.1238\n",
      "Epoch [30/50], Step [193/735], Loss: 0.0864\n",
      "Epoch [30/50], Step [194/735], Loss: 0.0849\n",
      "Epoch [30/50], Step [195/735], Loss: 0.4138\n",
      "Epoch [30/50], Step [196/735], Loss: 0.1749\n",
      "Epoch [30/50], Step [197/735], Loss: 0.0869\n",
      "Epoch [30/50], Step [198/735], Loss: 0.1106\n",
      "Epoch [30/50], Step [199/735], Loss: 0.1656\n",
      "Epoch [30/50], Step [200/735], Loss: 0.1012\n",
      "Epoch [30/50], Step [201/735], Loss: 0.2447\n",
      "Epoch [30/50], Step [202/735], Loss: 0.1123\n",
      "Epoch [30/50], Step [203/735], Loss: 0.1874\n",
      "Epoch [30/50], Step [204/735], Loss: 0.1281\n",
      "Epoch [30/50], Step [205/735], Loss: 0.1520\n",
      "Epoch [30/50], Step [206/735], Loss: 0.1862\n",
      "Epoch [30/50], Step [207/735], Loss: 0.0836\n",
      "Epoch [30/50], Step [208/735], Loss: 0.2985\n",
      "Epoch [30/50], Step [209/735], Loss: 0.1170\n",
      "Epoch [30/50], Step [210/735], Loss: 0.1764\n",
      "Epoch [30/50], Step [211/735], Loss: 0.0778\n",
      "Epoch [30/50], Step [212/735], Loss: 0.1374\n",
      "Epoch [30/50], Step [213/735], Loss: 0.0611\n",
      "Epoch [30/50], Step [214/735], Loss: 0.1302\n",
      "Epoch [30/50], Step [215/735], Loss: 0.2540\n",
      "Epoch [30/50], Step [216/735], Loss: 0.1027\n",
      "Epoch [30/50], Step [217/735], Loss: 0.1318\n",
      "Epoch [30/50], Step [218/735], Loss: 0.1330\n",
      "Epoch [30/50], Step [219/735], Loss: 0.0691\n",
      "Epoch [30/50], Step [220/735], Loss: 0.1246\n",
      "Epoch [30/50], Step [221/735], Loss: 0.0577\n",
      "Epoch [30/50], Step [222/735], Loss: 0.0900\n",
      "Epoch [30/50], Step [223/735], Loss: 0.2786\n",
      "Epoch [30/50], Step [224/735], Loss: 0.1490\n",
      "Epoch [30/50], Step [225/735], Loss: 0.0344\n",
      "Epoch [30/50], Step [226/735], Loss: 2.1885\n",
      "Epoch [30/50], Step [227/735], Loss: 0.1188\n",
      "Epoch [30/50], Step [228/735], Loss: 0.2415\n",
      "Epoch [30/50], Step [229/735], Loss: 0.1386\n",
      "Epoch [30/50], Step [230/735], Loss: 0.0621\n",
      "Epoch [30/50], Step [231/735], Loss: 0.0753\n",
      "Epoch [30/50], Step [232/735], Loss: 0.2416\n",
      "Epoch [30/50], Step [233/735], Loss: 0.3278\n",
      "Epoch [30/50], Step [234/735], Loss: 0.1715\n",
      "Epoch [30/50], Step [235/735], Loss: 0.0486\n",
      "Epoch [30/50], Step [236/735], Loss: 0.0730\n",
      "Epoch [30/50], Step [237/735], Loss: 0.1091\n",
      "Epoch [30/50], Step [238/735], Loss: 0.6554\n",
      "Epoch [30/50], Step [239/735], Loss: 0.0702\n",
      "Epoch [30/50], Step [240/735], Loss: 0.0921\n",
      "Epoch [30/50], Step [241/735], Loss: 0.0742\n",
      "Epoch [30/50], Step [242/735], Loss: 0.1321\n",
      "Epoch [30/50], Step [243/735], Loss: 0.2330\n",
      "Epoch [30/50], Step [244/735], Loss: 0.0928\n",
      "Epoch [30/50], Step [245/735], Loss: 0.0576\n",
      "Epoch [30/50], Step [246/735], Loss: 0.0733\n",
      "Epoch [30/50], Step [247/735], Loss: 0.2168\n",
      "Epoch [30/50], Step [248/735], Loss: 0.0558\n",
      "Epoch [30/50], Step [249/735], Loss: 0.6657\n",
      "Epoch [30/50], Step [250/735], Loss: 1.9193\n",
      "Epoch [30/50], Step [251/735], Loss: 0.0410\n",
      "Epoch [30/50], Step [252/735], Loss: 0.0471\n",
      "Epoch [30/50], Step [253/735], Loss: 0.0863\n",
      "Epoch [30/50], Step [254/735], Loss: 0.0738\n",
      "Epoch [30/50], Step [255/735], Loss: 0.2582\n",
      "Epoch [30/50], Step [256/735], Loss: 0.1167\n",
      "Epoch [30/50], Step [257/735], Loss: 0.0824\n",
      "Epoch [30/50], Step [258/735], Loss: 0.1442\n",
      "Epoch [30/50], Step [259/735], Loss: 0.3486\n",
      "Epoch [30/50], Step [260/735], Loss: 0.3554\n",
      "Epoch [30/50], Step [261/735], Loss: 0.1090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Step [262/735], Loss: 0.3488\n",
      "Epoch [30/50], Step [263/735], Loss: 0.1258\n",
      "Epoch [30/50], Step [264/735], Loss: 0.1398\n",
      "Epoch [30/50], Step [265/735], Loss: 0.1055\n",
      "Epoch [30/50], Step [266/735], Loss: 0.1047\n",
      "Epoch [30/50], Step [267/735], Loss: 0.1218\n",
      "Epoch [30/50], Step [268/735], Loss: 0.1104\n",
      "Epoch [30/50], Step [269/735], Loss: 0.1467\n",
      "Epoch [30/50], Step [270/735], Loss: 0.1004\n",
      "Epoch [30/50], Step [271/735], Loss: 0.5253\n",
      "Epoch [30/50], Step [272/735], Loss: 0.3114\n",
      "Epoch [30/50], Step [273/735], Loss: 0.0806\n",
      "Epoch [30/50], Step [274/735], Loss: 0.2045\n",
      "Epoch [30/50], Step [275/735], Loss: 0.2160\n",
      "Epoch [30/50], Step [276/735], Loss: 0.1442\n",
      "Epoch [30/50], Step [277/735], Loss: 0.1719\n",
      "Epoch [30/50], Step [278/735], Loss: 0.0944\n",
      "Epoch [30/50], Step [279/735], Loss: 0.1161\n",
      "Epoch [30/50], Step [280/735], Loss: 0.1658\n",
      "Epoch [30/50], Step [281/735], Loss: 0.1170\n",
      "Epoch [30/50], Step [282/735], Loss: 0.2160\n",
      "Epoch [30/50], Step [283/735], Loss: 0.1856\n",
      "Epoch [30/50], Step [284/735], Loss: 0.1859\n",
      "Epoch [30/50], Step [285/735], Loss: 0.0959\n",
      "Epoch [30/50], Step [286/735], Loss: 0.1593\n",
      "Epoch [30/50], Step [287/735], Loss: 0.1611\n",
      "Epoch [30/50], Step [288/735], Loss: 0.1770\n",
      "Epoch [30/50], Step [289/735], Loss: 0.0798\n",
      "Epoch [30/50], Step [290/735], Loss: 0.1154\n",
      "Epoch [30/50], Step [291/735], Loss: 0.1050\n",
      "Epoch [30/50], Step [292/735], Loss: 0.1076\n",
      "Epoch [30/50], Step [293/735], Loss: 0.1567\n",
      "Epoch [30/50], Step [294/735], Loss: 0.3201\n",
      "Epoch [30/50], Step [295/735], Loss: 0.0646\n",
      "Epoch [30/50], Step [296/735], Loss: 0.1041\n",
      "Epoch [30/50], Step [297/735], Loss: 0.0627\n",
      "Epoch [30/50], Step [298/735], Loss: 0.0475\n",
      "Epoch [30/50], Step [299/735], Loss: 0.1565\n",
      "Epoch [30/50], Step [300/735], Loss: 0.0969\n",
      "Epoch [30/50], Step [301/735], Loss: 0.1513\n",
      "Epoch [30/50], Step [302/735], Loss: 0.0755\n",
      "Epoch [30/50], Step [303/735], Loss: 0.1105\n",
      "Epoch [30/50], Step [304/735], Loss: 0.0249\n",
      "Epoch [30/50], Step [305/735], Loss: 0.1077\n",
      "Epoch [30/50], Step [306/735], Loss: 0.0915\n",
      "Epoch [30/50], Step [307/735], Loss: 0.2541\n",
      "Epoch [30/50], Step [308/735], Loss: 0.1385\n",
      "Epoch [30/50], Step [309/735], Loss: 0.1286\n",
      "Epoch [30/50], Step [310/735], Loss: 1.1670\n",
      "Epoch [30/50], Step [311/735], Loss: 0.1147\n",
      "Epoch [30/50], Step [312/735], Loss: 0.1659\n",
      "Epoch [30/50], Step [313/735], Loss: 0.0646\n",
      "Epoch [30/50], Step [314/735], Loss: 0.1203\n",
      "Epoch [30/50], Step [315/735], Loss: 0.0921\n",
      "Epoch [30/50], Step [316/735], Loss: 0.1083\n",
      "Epoch [30/50], Step [317/735], Loss: 0.0804\n",
      "Epoch [30/50], Step [318/735], Loss: 0.0940\n",
      "Epoch [30/50], Step [319/735], Loss: 0.0935\n",
      "Epoch [30/50], Step [320/735], Loss: 0.1906\n",
      "Epoch [30/50], Step [321/735], Loss: 0.1684\n",
      "Epoch [30/50], Step [322/735], Loss: 0.0881\n",
      "Epoch [30/50], Step [323/735], Loss: 0.0990\n",
      "Epoch [30/50], Step [324/735], Loss: 0.0557\n",
      "Epoch [30/50], Step [325/735], Loss: 0.0554\n",
      "Epoch [30/50], Step [326/735], Loss: 0.0927\n",
      "Epoch [30/50], Step [327/735], Loss: 0.1040\n",
      "Epoch [30/50], Step [328/735], Loss: 0.4275\n",
      "Epoch [30/50], Step [329/735], Loss: 0.1747\n",
      "Epoch [30/50], Step [330/735], Loss: 0.2509\n",
      "Epoch [30/50], Step [331/735], Loss: 0.0950\n",
      "Epoch [30/50], Step [332/735], Loss: 0.0519\n",
      "Epoch [30/50], Step [333/735], Loss: 0.5485\n",
      "Epoch [30/50], Step [334/735], Loss: 0.0577\n",
      "Epoch [30/50], Step [335/735], Loss: 0.0454\n",
      "Epoch [30/50], Step [336/735], Loss: 0.1559\n",
      "Epoch [30/50], Step [337/735], Loss: 0.0388\n",
      "Epoch [30/50], Step [338/735], Loss: 0.2267\n",
      "Epoch [30/50], Step [339/735], Loss: 0.3601\n",
      "Epoch [30/50], Step [340/735], Loss: 0.2538\n",
      "Epoch [30/50], Step [341/735], Loss: 0.1809\n",
      "Epoch [30/50], Step [342/735], Loss: 0.0683\n",
      "Epoch [30/50], Step [343/735], Loss: 0.2649\n",
      "Epoch [30/50], Step [344/735], Loss: 0.5831\n",
      "Epoch [30/50], Step [345/735], Loss: 0.0968\n",
      "Epoch [30/50], Step [346/735], Loss: 0.3381\n",
      "Epoch [30/50], Step [347/735], Loss: 0.1882\n",
      "Epoch [30/50], Step [348/735], Loss: 0.0386\n",
      "Epoch [30/50], Step [349/735], Loss: 0.0534\n",
      "Epoch [30/50], Step [350/735], Loss: 0.3190\n",
      "Epoch [30/50], Step [351/735], Loss: 0.0844\n",
      "Epoch [30/50], Step [352/735], Loss: 0.1861\n",
      "Epoch [30/50], Step [353/735], Loss: 0.1261\n",
      "Epoch [30/50], Step [354/735], Loss: 1.3086\n",
      "Epoch [30/50], Step [355/735], Loss: 0.0949\n",
      "Epoch [30/50], Step [356/735], Loss: 0.1401\n",
      "Epoch [30/50], Step [357/735], Loss: 0.1187\n",
      "Epoch [30/50], Step [358/735], Loss: 0.5015\n",
      "Epoch [30/50], Step [359/735], Loss: 0.1235\n",
      "Epoch [30/50], Step [360/735], Loss: 0.0657\n",
      "Epoch [30/50], Step [361/735], Loss: 0.1082\n",
      "Epoch [30/50], Step [362/735], Loss: 0.1857\n",
      "Epoch [30/50], Step [363/735], Loss: 0.0791\n",
      "Epoch [30/50], Step [364/735], Loss: 0.1213\n",
      "Epoch [30/50], Step [365/735], Loss: 0.2386\n",
      "Epoch [30/50], Step [366/735], Loss: 0.0977\n",
      "Epoch [30/50], Step [367/735], Loss: 0.0666\n",
      "Epoch [30/50], Step [368/735], Loss: 0.0919\n",
      "Epoch [30/50], Step [369/735], Loss: 0.1633\n",
      "Epoch [30/50], Step [370/735], Loss: 0.1052\n",
      "Epoch [30/50], Step [371/735], Loss: 0.1068\n",
      "Epoch [30/50], Step [372/735], Loss: 0.1649\n",
      "Epoch [30/50], Step [373/735], Loss: 0.2097\n",
      "Epoch [30/50], Step [374/735], Loss: 0.1570\n",
      "Epoch [30/50], Step [375/735], Loss: 0.1304\n",
      "Epoch [30/50], Step [376/735], Loss: 0.0855\n",
      "Epoch [30/50], Step [377/735], Loss: 0.0457\n",
      "Epoch [30/50], Step [378/735], Loss: 0.1789\n",
      "Epoch [30/50], Step [379/735], Loss: 0.1516\n",
      "Epoch [30/50], Step [380/735], Loss: 0.0640\n",
      "Epoch [30/50], Step [381/735], Loss: 0.1567\n",
      "Epoch [30/50], Step [382/735], Loss: 0.0472\n",
      "Epoch [30/50], Step [383/735], Loss: 0.1680\n",
      "Epoch [30/50], Step [384/735], Loss: 0.1177\n",
      "Epoch [30/50], Step [385/735], Loss: 0.0783\n",
      "Epoch [30/50], Step [386/735], Loss: 0.0719\n",
      "Epoch [30/50], Step [387/735], Loss: 0.1423\n",
      "Epoch [30/50], Step [388/735], Loss: 0.1002\n",
      "Epoch [30/50], Step [389/735], Loss: 0.3366\n",
      "Epoch [30/50], Step [390/735], Loss: 0.2028\n",
      "Epoch [30/50], Step [391/735], Loss: 0.0802\n",
      "Epoch [30/50], Step [392/735], Loss: 0.1556\n",
      "Epoch [30/50], Step [393/735], Loss: 0.1580\n",
      "Epoch [30/50], Step [394/735], Loss: 0.0750\n",
      "Epoch [30/50], Step [395/735], Loss: 0.7767\n",
      "Epoch [30/50], Step [396/735], Loss: 0.1289\n",
      "Epoch [30/50], Step [397/735], Loss: 0.0594\n",
      "Epoch [30/50], Step [398/735], Loss: 0.6040\n",
      "Epoch [30/50], Step [399/735], Loss: 0.2474\n",
      "Epoch [30/50], Step [400/735], Loss: 0.0354\n",
      "Epoch [30/50], Step [401/735], Loss: 0.0717\n",
      "Epoch [30/50], Step [402/735], Loss: 0.1829\n",
      "Epoch [30/50], Step [403/735], Loss: 0.1724\n",
      "Epoch [30/50], Step [404/735], Loss: 0.0649\n",
      "Epoch [30/50], Step [405/735], Loss: 0.0437\n",
      "Epoch [30/50], Step [406/735], Loss: 0.1356\n",
      "Epoch [30/50], Step [407/735], Loss: 0.1590\n",
      "Epoch [30/50], Step [408/735], Loss: 0.2127\n",
      "Epoch [30/50], Step [409/735], Loss: 0.0999\n",
      "Epoch [30/50], Step [410/735], Loss: 0.2667\n",
      "Epoch [30/50], Step [411/735], Loss: 0.4452\n",
      "Epoch [30/50], Step [412/735], Loss: 0.1921\n",
      "Epoch [30/50], Step [413/735], Loss: 0.0922\n",
      "Epoch [30/50], Step [414/735], Loss: 0.0899\n",
      "Epoch [30/50], Step [415/735], Loss: 0.0828\n",
      "Epoch [30/50], Step [416/735], Loss: 0.0696\n",
      "Epoch [30/50], Step [417/735], Loss: 0.1378\n",
      "Epoch [30/50], Step [418/735], Loss: 0.3608\n",
      "Epoch [30/50], Step [419/735], Loss: 0.5101\n",
      "Epoch [30/50], Step [420/735], Loss: 0.2089\n",
      "Epoch [30/50], Step [421/735], Loss: 0.0874\n",
      "Epoch [30/50], Step [422/735], Loss: 0.0458\n",
      "Epoch [30/50], Step [423/735], Loss: 0.2067\n",
      "Epoch [30/50], Step [424/735], Loss: 0.1150\n",
      "Epoch [30/50], Step [425/735], Loss: 0.0902\n",
      "Epoch [30/50], Step [426/735], Loss: 0.0739\n",
      "Epoch [30/50], Step [427/735], Loss: 0.1822\n",
      "Epoch [30/50], Step [428/735], Loss: 0.0741\n",
      "Epoch [30/50], Step [429/735], Loss: 0.8464\n",
      "Epoch [30/50], Step [430/735], Loss: 0.0558\n",
      "Epoch [30/50], Step [431/735], Loss: 0.1331\n",
      "Epoch [30/50], Step [432/735], Loss: 0.2088\n",
      "Epoch [30/50], Step [433/735], Loss: 0.1303\n",
      "Epoch [30/50], Step [434/735], Loss: 0.0878\n",
      "Epoch [30/50], Step [435/735], Loss: 0.1004\n",
      "Epoch [30/50], Step [436/735], Loss: 0.0848\n",
      "Epoch [30/50], Step [437/735], Loss: 0.2556\n",
      "Epoch [30/50], Step [438/735], Loss: 0.0693\n",
      "Epoch [30/50], Step [439/735], Loss: 0.0858\n",
      "Epoch [30/50], Step [440/735], Loss: 0.1766\n",
      "Epoch [30/50], Step [441/735], Loss: 0.0360\n",
      "Epoch [30/50], Step [442/735], Loss: 0.0640\n",
      "Epoch [30/50], Step [443/735], Loss: 0.0698\n",
      "Epoch [30/50], Step [444/735], Loss: 0.2718\n",
      "Epoch [30/50], Step [445/735], Loss: 0.1119\n",
      "Epoch [30/50], Step [446/735], Loss: 0.0820\n",
      "Epoch [30/50], Step [447/735], Loss: 0.1146\n",
      "Epoch [30/50], Step [448/735], Loss: 0.5479\n",
      "Epoch [30/50], Step [449/735], Loss: 0.0496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Step [450/735], Loss: 0.1105\n",
      "Epoch [30/50], Step [451/735], Loss: 0.1983\n",
      "Epoch [30/50], Step [452/735], Loss: 0.0663\n",
      "Epoch [30/50], Step [453/735], Loss: 0.0957\n",
      "Epoch [30/50], Step [454/735], Loss: 0.0385\n",
      "Epoch [30/50], Step [455/735], Loss: 0.0174\n",
      "Epoch [30/50], Step [456/735], Loss: 0.1189\n",
      "Epoch [30/50], Step [457/735], Loss: 0.1311\n",
      "Epoch [30/50], Step [458/735], Loss: 0.1640\n",
      "Epoch [30/50], Step [459/735], Loss: 0.0889\n",
      "Epoch [30/50], Step [460/735], Loss: 0.1087\n",
      "Epoch [30/50], Step [461/735], Loss: 0.1404\n",
      "Epoch [30/50], Step [462/735], Loss: 0.0399\n",
      "Epoch [30/50], Step [463/735], Loss: 0.0660\n",
      "Epoch [30/50], Step [464/735], Loss: 0.2328\n",
      "Epoch [30/50], Step [465/735], Loss: 0.0918\n",
      "Epoch [30/50], Step [466/735], Loss: 0.2014\n",
      "Epoch [30/50], Step [467/735], Loss: 0.1357\n",
      "Epoch [30/50], Step [468/735], Loss: 0.0508\n",
      "Epoch [30/50], Step [469/735], Loss: 0.0738\n",
      "Epoch [30/50], Step [470/735], Loss: 0.1697\n",
      "Epoch [30/50], Step [471/735], Loss: 0.0704\n",
      "Epoch [30/50], Step [472/735], Loss: 0.1013\n",
      "Epoch [30/50], Step [473/735], Loss: 0.1822\n",
      "Epoch [30/50], Step [474/735], Loss: 0.0907\n",
      "Epoch [30/50], Step [475/735], Loss: 0.0992\n",
      "Epoch [30/50], Step [476/735], Loss: 0.4841\n",
      "Epoch [30/50], Step [477/735], Loss: 0.1804\n",
      "Epoch [30/50], Step [478/735], Loss: 0.5087\n",
      "Epoch [30/50], Step [479/735], Loss: 0.0542\n",
      "Epoch [30/50], Step [480/735], Loss: 0.0829\n",
      "Epoch [30/50], Step [481/735], Loss: 0.0844\n",
      "Epoch [30/50], Step [482/735], Loss: 0.0920\n",
      "Epoch [30/50], Step [483/735], Loss: 0.1164\n",
      "Epoch [30/50], Step [484/735], Loss: 0.2030\n",
      "Epoch [30/50], Step [485/735], Loss: 0.1808\n",
      "Epoch [30/50], Step [486/735], Loss: 0.0893\n",
      "Epoch [30/50], Step [487/735], Loss: 0.1598\n",
      "Epoch [30/50], Step [488/735], Loss: 0.0660\n",
      "Epoch [30/50], Step [489/735], Loss: 0.1161\n",
      "Epoch [30/50], Step [490/735], Loss: 0.1785\n",
      "Epoch [30/50], Step [491/735], Loss: 0.6303\n",
      "Epoch [30/50], Step [492/735], Loss: 0.1174\n",
      "Epoch [30/50], Step [493/735], Loss: 0.1315\n",
      "Epoch [30/50], Step [494/735], Loss: 0.0979\n",
      "Epoch [30/50], Step [495/735], Loss: 0.1301\n",
      "Epoch [30/50], Step [496/735], Loss: 0.2336\n",
      "Epoch [30/50], Step [497/735], Loss: 0.1099\n",
      "Epoch [30/50], Step [498/735], Loss: 0.0541\n",
      "Epoch [30/50], Step [499/735], Loss: 0.0945\n",
      "Epoch [30/50], Step [500/735], Loss: 0.2562\n",
      "Epoch [30/50], Step [501/735], Loss: 0.1301\n",
      "Epoch [30/50], Step [502/735], Loss: 0.0505\n",
      "Epoch [30/50], Step [503/735], Loss: 0.0707\n",
      "Epoch [30/50], Step [504/735], Loss: 0.0745\n",
      "Epoch [30/50], Step [505/735], Loss: 0.1131\n",
      "Epoch [30/50], Step [506/735], Loss: 0.0599\n",
      "Epoch [30/50], Step [507/735], Loss: 0.2175\n",
      "Epoch [30/50], Step [508/735], Loss: 0.0863\n",
      "Epoch [30/50], Step [509/735], Loss: 0.0724\n",
      "Epoch [30/50], Step [510/735], Loss: 0.0466\n",
      "Epoch [30/50], Step [511/735], Loss: 0.0902\n",
      "Epoch [30/50], Step [512/735], Loss: 0.0546\n",
      "Epoch [30/50], Step [513/735], Loss: 0.1685\n",
      "Epoch [30/50], Step [514/735], Loss: 0.0727\n",
      "Epoch [30/50], Step [515/735], Loss: 0.3081\n",
      "Epoch [30/50], Step [516/735], Loss: 0.0510\n",
      "Epoch [30/50], Step [517/735], Loss: 0.2840\n",
      "Epoch [30/50], Step [518/735], Loss: 0.1527\n",
      "Epoch [30/50], Step [519/735], Loss: 0.1105\n",
      "Epoch [30/50], Step [520/735], Loss: 0.2683\n",
      "Epoch [30/50], Step [521/735], Loss: 0.0396\n",
      "Epoch [30/50], Step [522/735], Loss: 0.0732\n",
      "Epoch [30/50], Step [523/735], Loss: 0.0786\n",
      "Epoch [30/50], Step [524/735], Loss: 0.1849\n",
      "Epoch [30/50], Step [525/735], Loss: 0.1269\n",
      "Epoch [30/50], Step [526/735], Loss: 0.4948\n",
      "Epoch [30/50], Step [527/735], Loss: 0.1523\n",
      "Epoch [30/50], Step [528/735], Loss: 0.0719\n",
      "Epoch [30/50], Step [529/735], Loss: 0.2903\n",
      "Epoch [30/50], Step [530/735], Loss: 0.1605\n",
      "Epoch [30/50], Step [531/735], Loss: 0.1174\n",
      "Epoch [30/50], Step [532/735], Loss: 0.0496\n",
      "Epoch [30/50], Step [533/735], Loss: 0.1600\n",
      "Epoch [30/50], Step [534/735], Loss: 0.0830\n",
      "Epoch [30/50], Step [535/735], Loss: 0.1375\n",
      "Epoch [30/50], Step [536/735], Loss: 0.1918\n",
      "Epoch [30/50], Step [537/735], Loss: 0.1984\n",
      "Epoch [30/50], Step [538/735], Loss: 0.1456\n",
      "Epoch [30/50], Step [539/735], Loss: 0.1468\n",
      "Epoch [30/50], Step [540/735], Loss: 0.0784\n",
      "Epoch [30/50], Step [541/735], Loss: 0.1050\n",
      "Epoch [30/50], Step [542/735], Loss: 0.1331\n",
      "Epoch [30/50], Step [543/735], Loss: 0.0611\n",
      "Epoch [30/50], Step [544/735], Loss: 0.0444\n",
      "Epoch [30/50], Step [545/735], Loss: 0.5195\n",
      "Epoch [30/50], Step [546/735], Loss: 0.0679\n",
      "Epoch [30/50], Step [547/735], Loss: 0.0983\n",
      "Epoch [30/50], Step [548/735], Loss: 0.1093\n",
      "Epoch [30/50], Step [549/735], Loss: 0.1614\n",
      "Epoch [30/50], Step [550/735], Loss: 0.0895\n",
      "Epoch [30/50], Step [551/735], Loss: 0.1373\n",
      "Epoch [30/50], Step [552/735], Loss: 0.4692\n",
      "Epoch [30/50], Step [553/735], Loss: 0.0800\n",
      "Epoch [30/50], Step [554/735], Loss: 0.1528\n",
      "Epoch [30/50], Step [555/735], Loss: 0.0442\n",
      "Epoch [30/50], Step [556/735], Loss: 0.6025\n",
      "Epoch [30/50], Step [557/735], Loss: 0.1024\n",
      "Epoch [30/50], Step [558/735], Loss: 0.0958\n",
      "Epoch [30/50], Step [559/735], Loss: 0.0717\n",
      "Epoch [30/50], Step [560/735], Loss: 0.0589\n",
      "Epoch [30/50], Step [561/735], Loss: 0.0533\n",
      "Epoch [30/50], Step [562/735], Loss: 0.2049\n",
      "Epoch [30/50], Step [563/735], Loss: 0.1119\n",
      "Epoch [30/50], Step [564/735], Loss: 0.0815\n",
      "Epoch [30/50], Step [565/735], Loss: 0.1729\n",
      "Epoch [30/50], Step [566/735], Loss: 0.0468\n",
      "Epoch [30/50], Step [567/735], Loss: 0.0763\n",
      "Epoch [30/50], Step [568/735], Loss: 0.1274\n",
      "Epoch [30/50], Step [569/735], Loss: 0.0581\n",
      "Epoch [30/50], Step [570/735], Loss: 0.0503\n",
      "Epoch [30/50], Step [571/735], Loss: 0.0468\n",
      "Epoch [30/50], Step [572/735], Loss: 0.1131\n",
      "Epoch [30/50], Step [573/735], Loss: 0.0575\n",
      "Epoch [30/50], Step [574/735], Loss: 0.1145\n",
      "Epoch [30/50], Step [575/735], Loss: 0.1207\n",
      "Epoch [30/50], Step [576/735], Loss: 0.1579\n",
      "Epoch [30/50], Step [577/735], Loss: 0.1789\n",
      "Epoch [30/50], Step [578/735], Loss: 0.1693\n",
      "Epoch [30/50], Step [579/735], Loss: 0.1445\n",
      "Epoch [30/50], Step [580/735], Loss: 0.0603\n",
      "Epoch [30/50], Step [581/735], Loss: 2.2550\n",
      "Epoch [30/50], Step [582/735], Loss: 0.0998\n",
      "Epoch [30/50], Step [583/735], Loss: 0.0653\n",
      "Epoch [30/50], Step [584/735], Loss: 0.2787\n",
      "Epoch [30/50], Step [585/735], Loss: 0.1305\n",
      "Epoch [30/50], Step [586/735], Loss: 0.1268\n",
      "Epoch [30/50], Step [587/735], Loss: 0.1384\n",
      "Epoch [30/50], Step [588/735], Loss: 0.1614\n",
      "Epoch [30/50], Step [589/735], Loss: 0.1946\n",
      "Epoch [30/50], Step [590/735], Loss: 0.1036\n",
      "Epoch [30/50], Step [591/735], Loss: 0.0700\n",
      "Epoch [30/50], Step [592/735], Loss: 0.1804\n",
      "Epoch [30/50], Step [593/735], Loss: 0.1408\n",
      "Epoch [30/50], Step [594/735], Loss: 0.1318\n",
      "Epoch [30/50], Step [595/735], Loss: 0.1651\n",
      "Epoch [30/50], Step [596/735], Loss: 0.1212\n",
      "Epoch [30/50], Step [597/735], Loss: 0.0908\n",
      "Epoch [30/50], Step [598/735], Loss: 0.2126\n",
      "Epoch [30/50], Step [599/735], Loss: 0.1145\n",
      "Epoch [30/50], Step [600/735], Loss: 0.4099\n",
      "Epoch [30/50], Step [601/735], Loss: 0.1711\n",
      "Epoch [30/50], Step [602/735], Loss: 0.1138\n",
      "Epoch [30/50], Step [603/735], Loss: 0.0519\n",
      "Epoch [30/50], Step [604/735], Loss: 0.0988\n",
      "Epoch [30/50], Step [605/735], Loss: 0.1213\n",
      "Epoch [30/50], Step [606/735], Loss: 0.1310\n",
      "Epoch [30/50], Step [607/735], Loss: 0.1422\n",
      "Epoch [30/50], Step [608/735], Loss: 0.1892\n",
      "Epoch [30/50], Step [609/735], Loss: 0.0956\n",
      "Epoch [30/50], Step [610/735], Loss: 0.1337\n",
      "Epoch [30/50], Step [611/735], Loss: 0.0499\n",
      "Epoch [30/50], Step [612/735], Loss: 0.0648\n",
      "Epoch [30/50], Step [613/735], Loss: 0.8228\n",
      "Epoch [30/50], Step [614/735], Loss: 0.2877\n",
      "Epoch [30/50], Step [615/735], Loss: 0.0866\n",
      "Epoch [30/50], Step [616/735], Loss: 0.1680\n",
      "Epoch [30/50], Step [617/735], Loss: 0.1801\n",
      "Epoch [30/50], Step [618/735], Loss: 0.0956\n",
      "Epoch [30/50], Step [619/735], Loss: 0.3072\n",
      "Epoch [30/50], Step [620/735], Loss: 0.2585\n",
      "Epoch [30/50], Step [621/735], Loss: 0.1074\n",
      "Epoch [30/50], Step [622/735], Loss: 1.5130\n",
      "Epoch [30/50], Step [623/735], Loss: 0.1192\n",
      "Epoch [30/50], Step [624/735], Loss: 0.2037\n",
      "Epoch [30/50], Step [625/735], Loss: 0.5361\n",
      "Epoch [30/50], Step [626/735], Loss: 0.2415\n",
      "Epoch [30/50], Step [627/735], Loss: 0.1024\n",
      "Epoch [30/50], Step [628/735], Loss: 0.1294\n",
      "Epoch [30/50], Step [629/735], Loss: 0.6696\n",
      "Epoch [30/50], Step [630/735], Loss: 0.1278\n",
      "Epoch [30/50], Step [631/735], Loss: 0.0597\n",
      "Epoch [30/50], Step [632/735], Loss: 0.0865\n",
      "Epoch [30/50], Step [633/735], Loss: 0.1688\n",
      "Epoch [30/50], Step [634/735], Loss: 0.0655\n",
      "Epoch [30/50], Step [635/735], Loss: 0.2595\n",
      "Epoch [30/50], Step [636/735], Loss: 0.2618\n",
      "Epoch [30/50], Step [637/735], Loss: 0.0639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Step [638/735], Loss: 0.0821\n",
      "Epoch [30/50], Step [639/735], Loss: 0.0452\n",
      "Epoch [30/50], Step [640/735], Loss: 0.0757\n",
      "Epoch [30/50], Step [641/735], Loss: 0.0699\n",
      "Epoch [30/50], Step [642/735], Loss: 0.0653\n",
      "Epoch [30/50], Step [643/735], Loss: 0.0923\n",
      "Epoch [30/50], Step [644/735], Loss: 0.0420\n",
      "Epoch [30/50], Step [645/735], Loss: 0.0588\n",
      "Epoch [30/50], Step [646/735], Loss: 0.0733\n",
      "Epoch [30/50], Step [647/735], Loss: 0.2363\n",
      "Epoch [30/50], Step [648/735], Loss: 0.1162\n",
      "Epoch [30/50], Step [649/735], Loss: 0.0701\n",
      "Epoch [30/50], Step [650/735], Loss: 0.0780\n",
      "Epoch [30/50], Step [651/735], Loss: 0.1406\n",
      "Epoch [30/50], Step [652/735], Loss: 0.1199\n",
      "Epoch [30/50], Step [653/735], Loss: 0.1173\n",
      "Epoch [30/50], Step [654/735], Loss: 0.0380\n",
      "Epoch [30/50], Step [655/735], Loss: 0.0536\n",
      "Epoch [30/50], Step [656/735], Loss: 0.1416\n",
      "Epoch [30/50], Step [657/735], Loss: 0.0553\n",
      "Epoch [30/50], Step [658/735], Loss: 0.1831\n",
      "Epoch [30/50], Step [659/735], Loss: 0.2803\n",
      "Epoch [30/50], Step [660/735], Loss: 0.1304\n",
      "Epoch [30/50], Step [661/735], Loss: 0.3283\n",
      "Epoch [30/50], Step [662/735], Loss: 0.0600\n",
      "Epoch [30/50], Step [663/735], Loss: 0.0984\n",
      "Epoch [30/50], Step [664/735], Loss: 0.1789\n",
      "Epoch [30/50], Step [665/735], Loss: 0.1727\n",
      "Epoch [30/50], Step [666/735], Loss: 0.2353\n",
      "Epoch [30/50], Step [667/735], Loss: 0.1854\n",
      "Epoch [30/50], Step [668/735], Loss: 1.0234\n",
      "Epoch [30/50], Step [669/735], Loss: 0.1433\n",
      "Epoch [30/50], Step [670/735], Loss: 0.4629\n",
      "Epoch [30/50], Step [671/735], Loss: 0.1287\n",
      "Epoch [30/50], Step [672/735], Loss: 0.1016\n",
      "Epoch [30/50], Step [673/735], Loss: 0.1096\n",
      "Epoch [30/50], Step [674/735], Loss: 0.1395\n",
      "Epoch [30/50], Step [675/735], Loss: 0.1482\n",
      "Epoch [30/50], Step [676/735], Loss: 0.0803\n",
      "Epoch [30/50], Step [677/735], Loss: 0.2320\n",
      "Epoch [30/50], Step [678/735], Loss: 0.0631\n",
      "Epoch [30/50], Step [679/735], Loss: 0.0785\n",
      "Epoch [30/50], Step [680/735], Loss: 0.0917\n",
      "Epoch [30/50], Step [681/735], Loss: 0.2087\n",
      "Epoch [30/50], Step [682/735], Loss: 0.1589\n",
      "Epoch [30/50], Step [683/735], Loss: 0.1548\n",
      "Epoch [30/50], Step [684/735], Loss: 0.1794\n",
      "Epoch [30/50], Step [685/735], Loss: 0.1435\n",
      "Epoch [30/50], Step [686/735], Loss: 0.0764\n",
      "Epoch [30/50], Step [687/735], Loss: 0.0477\n",
      "Epoch [30/50], Step [688/735], Loss: 0.1026\n",
      "Epoch [30/50], Step [689/735], Loss: 0.0351\n",
      "Epoch [30/50], Step [690/735], Loss: 0.7615\n",
      "Epoch [30/50], Step [691/735], Loss: 0.0350\n",
      "Epoch [30/50], Step [692/735], Loss: 0.1108\n",
      "Epoch [30/50], Step [693/735], Loss: 0.1568\n",
      "Epoch [30/50], Step [694/735], Loss: 0.2662\n",
      "Epoch [30/50], Step [695/735], Loss: 0.1071\n",
      "Epoch [30/50], Step [696/735], Loss: 0.1162\n",
      "Epoch [30/50], Step [697/735], Loss: 0.0717\n",
      "Epoch [30/50], Step [698/735], Loss: 0.0914\n",
      "Epoch [30/50], Step [699/735], Loss: 0.0410\n",
      "Epoch [30/50], Step [700/735], Loss: 0.2179\n",
      "Epoch [30/50], Step [701/735], Loss: 0.0648\n",
      "Epoch [30/50], Step [702/735], Loss: 0.2955\n",
      "Epoch [30/50], Step [703/735], Loss: 0.1062\n",
      "Epoch [30/50], Step [704/735], Loss: 0.0860\n",
      "Epoch [30/50], Step [705/735], Loss: 0.0464\n",
      "Epoch [30/50], Step [706/735], Loss: 0.0781\n",
      "Epoch [30/50], Step [707/735], Loss: 0.0623\n",
      "Epoch [30/50], Step [708/735], Loss: 0.0450\n",
      "Epoch [30/50], Step [709/735], Loss: 0.0435\n",
      "Epoch [30/50], Step [710/735], Loss: 0.0798\n",
      "Epoch [30/50], Step [711/735], Loss: 0.1672\n",
      "Epoch [30/50], Step [712/735], Loss: 0.1070\n",
      "Epoch [30/50], Step [713/735], Loss: 0.0772\n",
      "Epoch [30/50], Step [714/735], Loss: 0.5382\n",
      "Epoch [30/50], Step [715/735], Loss: 0.0441\n",
      "Epoch [30/50], Step [716/735], Loss: 0.1476\n",
      "Epoch [30/50], Step [717/735], Loss: 0.0783\n",
      "Epoch [30/50], Step [718/735], Loss: 0.0836\n",
      "Epoch [30/50], Step [719/735], Loss: 0.1153\n",
      "Epoch [30/50], Step [720/735], Loss: 0.0885\n",
      "Epoch [30/50], Step [721/735], Loss: 0.0930\n",
      "Epoch [30/50], Step [722/735], Loss: 0.0648\n",
      "Epoch [30/50], Step [723/735], Loss: 0.0493\n",
      "Epoch [30/50], Step [724/735], Loss: 0.0785\n",
      "Epoch [30/50], Step [725/735], Loss: 0.0618\n",
      "Epoch [30/50], Step [726/735], Loss: 0.3868\n",
      "Epoch [30/50], Step [727/735], Loss: 0.1138\n",
      "Epoch [30/50], Step [728/735], Loss: 0.1249\n",
      "Epoch [30/50], Step [729/735], Loss: 0.0512\n",
      "Epoch [30/50], Step [730/735], Loss: 0.6191\n",
      "Epoch [30/50], Step [731/735], Loss: 0.0816\n",
      "Epoch [30/50], Step [732/735], Loss: 0.0549\n",
      "Epoch [30/50], Step [733/735], Loss: 0.0689\n",
      "Epoch [30/50], Step [734/735], Loss: 0.0472\n",
      "Epoch [30/50], Step [735/735], Loss: 0.0456\n",
      "Epoch [31/50], Step [1/735], Loss: 0.1103\n",
      "Epoch [31/50], Step [2/735], Loss: 0.1435\n",
      "Epoch [31/50], Step [3/735], Loss: 0.1251\n",
      "Epoch [31/50], Step [4/735], Loss: 0.1446\n",
      "Epoch [31/50], Step [5/735], Loss: 0.7859\n",
      "Epoch [31/50], Step [6/735], Loss: 0.0734\n",
      "Epoch [31/50], Step [7/735], Loss: 0.0943\n",
      "Epoch [31/50], Step [8/735], Loss: 0.0421\n",
      "Epoch [31/50], Step [9/735], Loss: 0.0369\n",
      "Epoch [31/50], Step [10/735], Loss: 0.0616\n",
      "Epoch [31/50], Step [11/735], Loss: 1.8123\n",
      "Epoch [31/50], Step [12/735], Loss: 0.0587\n",
      "Epoch [31/50], Step [13/735], Loss: 0.1133\n",
      "Epoch [31/50], Step [14/735], Loss: 0.0815\n",
      "Epoch [31/50], Step [15/735], Loss: 0.1588\n",
      "Epoch [31/50], Step [16/735], Loss: 0.1345\n",
      "Epoch [31/50], Step [17/735], Loss: 0.1820\n",
      "Epoch [31/50], Step [18/735], Loss: 0.1451\n",
      "Epoch [31/50], Step [19/735], Loss: 0.1160\n",
      "Epoch [31/50], Step [20/735], Loss: 0.0539\n",
      "Epoch [31/50], Step [21/735], Loss: 0.2142\n",
      "Epoch [31/50], Step [22/735], Loss: 0.0338\n",
      "Epoch [31/50], Step [23/735], Loss: 0.1565\n",
      "Epoch [31/50], Step [24/735], Loss: 0.0806\n",
      "Epoch [31/50], Step [25/735], Loss: 0.1522\n",
      "Epoch [31/50], Step [26/735], Loss: 0.0536\n",
      "Epoch [31/50], Step [27/735], Loss: 0.0607\n",
      "Epoch [31/50], Step [28/735], Loss: 0.1651\n",
      "Epoch [31/50], Step [29/735], Loss: 0.2228\n",
      "Epoch [31/50], Step [30/735], Loss: 0.2388\n",
      "Epoch [31/50], Step [31/735], Loss: 0.1091\n",
      "Epoch [31/50], Step [32/735], Loss: 0.1458\n",
      "Epoch [31/50], Step [33/735], Loss: 0.1095\n",
      "Epoch [31/50], Step [34/735], Loss: 0.0603\n",
      "Epoch [31/50], Step [35/735], Loss: 0.2467\n",
      "Epoch [31/50], Step [36/735], Loss: 0.0571\n",
      "Epoch [31/50], Step [37/735], Loss: 0.0502\n",
      "Epoch [31/50], Step [38/735], Loss: 0.2950\n",
      "Epoch [31/50], Step [39/735], Loss: 0.0578\n",
      "Epoch [31/50], Step [40/735], Loss: 0.1488\n",
      "Epoch [31/50], Step [41/735], Loss: 0.1156\n",
      "Epoch [31/50], Step [42/735], Loss: 0.1302\n",
      "Epoch [31/50], Step [43/735], Loss: 0.0428\n",
      "Epoch [31/50], Step [44/735], Loss: 0.0751\n",
      "Epoch [31/50], Step [45/735], Loss: 0.1673\n",
      "Epoch [31/50], Step [46/735], Loss: 0.0766\n",
      "Epoch [31/50], Step [47/735], Loss: 0.0524\n",
      "Epoch [31/50], Step [48/735], Loss: 0.6473\n",
      "Epoch [31/50], Step [49/735], Loss: 0.5326\n",
      "Epoch [31/50], Step [50/735], Loss: 0.0533\n",
      "Epoch [31/50], Step [51/735], Loss: 0.1377\n",
      "Epoch [31/50], Step [52/735], Loss: 0.1283\n",
      "Epoch [31/50], Step [53/735], Loss: 0.0402\n",
      "Epoch [31/50], Step [54/735], Loss: 0.1065\n",
      "Epoch [31/50], Step [55/735], Loss: 0.2863\n",
      "Epoch [31/50], Step [56/735], Loss: 0.1349\n",
      "Epoch [31/50], Step [57/735], Loss: 0.0601\n",
      "Epoch [31/50], Step [58/735], Loss: 0.6756\n",
      "Epoch [31/50], Step [59/735], Loss: 0.0635\n",
      "Epoch [31/50], Step [60/735], Loss: 1.1300\n",
      "Epoch [31/50], Step [61/735], Loss: 0.0514\n",
      "Epoch [31/50], Step [62/735], Loss: 1.6459\n",
      "Epoch [31/50], Step [63/735], Loss: 0.1207\n",
      "Epoch [31/50], Step [64/735], Loss: 0.1040\n",
      "Epoch [31/50], Step [65/735], Loss: 0.2049\n",
      "Epoch [31/50], Step [66/735], Loss: 0.5314\n",
      "Epoch [31/50], Step [67/735], Loss: 0.1035\n",
      "Epoch [31/50], Step [68/735], Loss: 0.0978\n",
      "Epoch [31/50], Step [69/735], Loss: 0.1741\n",
      "Epoch [31/50], Step [70/735], Loss: 0.1185\n",
      "Epoch [31/50], Step [71/735], Loss: 0.1497\n",
      "Epoch [31/50], Step [72/735], Loss: 0.1812\n",
      "Epoch [31/50], Step [73/735], Loss: 0.1277\n",
      "Epoch [31/50], Step [74/735], Loss: 0.0610\n",
      "Epoch [31/50], Step [75/735], Loss: 0.1061\n",
      "Epoch [31/50], Step [76/735], Loss: 0.1217\n",
      "Epoch [31/50], Step [77/735], Loss: 0.1052\n",
      "Epoch [31/50], Step [78/735], Loss: 0.1208\n",
      "Epoch [31/50], Step [79/735], Loss: 0.1315\n",
      "Epoch [31/50], Step [80/735], Loss: 0.1533\n",
      "Epoch [31/50], Step [81/735], Loss: 0.1314\n",
      "Epoch [31/50], Step [82/735], Loss: 0.1728\n",
      "Epoch [31/50], Step [83/735], Loss: 0.0693\n",
      "Epoch [31/50], Step [84/735], Loss: 0.1180\n",
      "Epoch [31/50], Step [85/735], Loss: 0.1972\n",
      "Epoch [31/50], Step [86/735], Loss: 0.1057\n",
      "Epoch [31/50], Step [87/735], Loss: 0.0276\n",
      "Epoch [31/50], Step [88/735], Loss: 0.2896\n",
      "Epoch [31/50], Step [89/735], Loss: 0.1025\n",
      "Epoch [31/50], Step [90/735], Loss: 0.2220\n",
      "Epoch [31/50], Step [91/735], Loss: 0.2290\n",
      "Epoch [31/50], Step [92/735], Loss: 0.0865\n",
      "Epoch [31/50], Step [93/735], Loss: 0.0998\n",
      "Epoch [31/50], Step [94/735], Loss: 0.4882\n",
      "Epoch [31/50], Step [95/735], Loss: 0.1187\n",
      "Epoch [31/50], Step [96/735], Loss: 0.2458\n",
      "Epoch [31/50], Step [97/735], Loss: 0.4938\n",
      "Epoch [31/50], Step [98/735], Loss: 0.1341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Step [99/735], Loss: 0.1465\n",
      "Epoch [31/50], Step [100/735], Loss: 0.0799\n",
      "Epoch [31/50], Step [101/735], Loss: 0.1618\n",
      "Epoch [31/50], Step [102/735], Loss: 0.1051\n",
      "Epoch [31/50], Step [103/735], Loss: 0.1317\n",
      "Epoch [31/50], Step [104/735], Loss: 0.2142\n",
      "Epoch [31/50], Step [105/735], Loss: 0.0994\n",
      "Epoch [31/50], Step [106/735], Loss: 0.1442\n",
      "Epoch [31/50], Step [107/735], Loss: 0.1336\n",
      "Epoch [31/50], Step [108/735], Loss: 0.2260\n",
      "Epoch [31/50], Step [109/735], Loss: 0.1346\n",
      "Epoch [31/50], Step [110/735], Loss: 0.1009\n",
      "Epoch [31/50], Step [111/735], Loss: 0.0615\n",
      "Epoch [31/50], Step [112/735], Loss: 0.0350\n",
      "Epoch [31/50], Step [113/735], Loss: 0.1068\n",
      "Epoch [31/50], Step [114/735], Loss: 0.1974\n",
      "Epoch [31/50], Step [115/735], Loss: 0.1506\n",
      "Epoch [31/50], Step [116/735], Loss: 0.0771\n",
      "Epoch [31/50], Step [117/735], Loss: 0.2759\n",
      "Epoch [31/50], Step [118/735], Loss: 0.0888\n",
      "Epoch [31/50], Step [119/735], Loss: 0.0826\n",
      "Epoch [31/50], Step [120/735], Loss: 0.0972\n",
      "Epoch [31/50], Step [121/735], Loss: 0.0712\n",
      "Epoch [31/50], Step [122/735], Loss: 0.1590\n",
      "Epoch [31/50], Step [123/735], Loss: 0.1534\n",
      "Epoch [31/50], Step [124/735], Loss: 0.1098\n",
      "Epoch [31/50], Step [125/735], Loss: 0.1245\n",
      "Epoch [31/50], Step [126/735], Loss: 0.1374\n",
      "Epoch [31/50], Step [127/735], Loss: 0.0900\n",
      "Epoch [31/50], Step [128/735], Loss: 0.0915\n",
      "Epoch [31/50], Step [129/735], Loss: 0.1162\n",
      "Epoch [31/50], Step [130/735], Loss: 0.0458\n",
      "Epoch [31/50], Step [131/735], Loss: 0.0792\n",
      "Epoch [31/50], Step [132/735], Loss: 0.0626\n",
      "Epoch [31/50], Step [133/735], Loss: 0.1025\n",
      "Epoch [31/50], Step [134/735], Loss: 0.1067\n",
      "Epoch [31/50], Step [135/735], Loss: 0.0913\n",
      "Epoch [31/50], Step [136/735], Loss: 0.1050\n",
      "Epoch [31/50], Step [137/735], Loss: 0.1526\n",
      "Epoch [31/50], Step [138/735], Loss: 0.0849\n",
      "Epoch [31/50], Step [139/735], Loss: 0.3713\n",
      "Epoch [31/50], Step [140/735], Loss: 0.1584\n",
      "Epoch [31/50], Step [141/735], Loss: 0.2198\n",
      "Epoch [31/50], Step [142/735], Loss: 0.1956\n",
      "Epoch [31/50], Step [143/735], Loss: 0.0666\n",
      "Epoch [31/50], Step [144/735], Loss: 0.0971\n",
      "Epoch [31/50], Step [145/735], Loss: 0.0747\n",
      "Epoch [31/50], Step [146/735], Loss: 0.1115\n",
      "Epoch [31/50], Step [147/735], Loss: 0.2129\n",
      "Epoch [31/50], Step [148/735], Loss: 0.0637\n",
      "Epoch [31/50], Step [149/735], Loss: 0.0649\n",
      "Epoch [31/50], Step [150/735], Loss: 0.0380\n",
      "Epoch [31/50], Step [151/735], Loss: 0.0684\n",
      "Epoch [31/50], Step [152/735], Loss: 0.5904\n",
      "Epoch [31/50], Step [153/735], Loss: 0.0993\n",
      "Epoch [31/50], Step [154/735], Loss: 0.0786\n",
      "Epoch [31/50], Step [155/735], Loss: 0.1285\n",
      "Epoch [31/50], Step [156/735], Loss: 0.1404\n",
      "Epoch [31/50], Step [157/735], Loss: 0.1763\n",
      "Epoch [31/50], Step [158/735], Loss: 0.4747\n",
      "Epoch [31/50], Step [159/735], Loss: 0.1194\n",
      "Epoch [31/50], Step [160/735], Loss: 0.1064\n",
      "Epoch [31/50], Step [161/735], Loss: 0.1883\n",
      "Epoch [31/50], Step [162/735], Loss: 0.0780\n",
      "Epoch [31/50], Step [163/735], Loss: 0.0831\n",
      "Epoch [31/50], Step [164/735], Loss: 0.1019\n",
      "Epoch [31/50], Step [165/735], Loss: 0.1104\n",
      "Epoch [31/50], Step [166/735], Loss: 0.0620\n",
      "Epoch [31/50], Step [167/735], Loss: 0.1880\n",
      "Epoch [31/50], Step [168/735], Loss: 0.0720\n",
      "Epoch [31/50], Step [169/735], Loss: 0.0884\n",
      "Epoch [31/50], Step [170/735], Loss: 0.0682\n",
      "Epoch [31/50], Step [171/735], Loss: 1.3518\n",
      "Epoch [31/50], Step [172/735], Loss: 0.1044\n",
      "Epoch [31/50], Step [173/735], Loss: 0.0756\n",
      "Epoch [31/50], Step [174/735], Loss: 0.0972\n",
      "Epoch [31/50], Step [175/735], Loss: 0.1411\n",
      "Epoch [31/50], Step [176/735], Loss: 0.1990\n",
      "Epoch [31/50], Step [177/735], Loss: 0.1341\n",
      "Epoch [31/50], Step [178/735], Loss: 0.0967\n",
      "Epoch [31/50], Step [179/735], Loss: 0.1849\n",
      "Epoch [31/50], Step [180/735], Loss: 0.1249\n",
      "Epoch [31/50], Step [181/735], Loss: 0.1304\n",
      "Epoch [31/50], Step [182/735], Loss: 0.0611\n",
      "Epoch [31/50], Step [183/735], Loss: 0.1813\n",
      "Epoch [31/50], Step [184/735], Loss: 0.0445\n",
      "Epoch [31/50], Step [185/735], Loss: 0.0954\n",
      "Epoch [31/50], Step [186/735], Loss: 0.0759\n",
      "Epoch [31/50], Step [187/735], Loss: 0.1040\n",
      "Epoch [31/50], Step [188/735], Loss: 0.0808\n",
      "Epoch [31/50], Step [189/735], Loss: 0.1102\n",
      "Epoch [31/50], Step [190/735], Loss: 0.3643\n",
      "Epoch [31/50], Step [191/735], Loss: 0.0560\n",
      "Epoch [31/50], Step [192/735], Loss: 2.0348\n",
      "Epoch [31/50], Step [193/735], Loss: 0.0750\n",
      "Epoch [31/50], Step [194/735], Loss: 0.1386\n",
      "Epoch [31/50], Step [195/735], Loss: 0.0742\n",
      "Epoch [31/50], Step [196/735], Loss: 0.0852\n",
      "Epoch [31/50], Step [197/735], Loss: 0.0718\n",
      "Epoch [31/50], Step [198/735], Loss: 0.0713\n",
      "Epoch [31/50], Step [199/735], Loss: 0.1352\n",
      "Epoch [31/50], Step [200/735], Loss: 0.0625\n",
      "Epoch [31/50], Step [201/735], Loss: 0.1158\n",
      "Epoch [31/50], Step [202/735], Loss: 0.0855\n",
      "Epoch [31/50], Step [203/735], Loss: 0.1799\n",
      "Epoch [31/50], Step [204/735], Loss: 0.0345\n",
      "Epoch [31/50], Step [205/735], Loss: 0.0544\n",
      "Epoch [31/50], Step [206/735], Loss: 0.0879\n",
      "Epoch [31/50], Step [207/735], Loss: 0.1286\n",
      "Epoch [31/50], Step [208/735], Loss: 0.0561\n",
      "Epoch [31/50], Step [209/735], Loss: 0.1344\n",
      "Epoch [31/50], Step [210/735], Loss: 0.1321\n",
      "Epoch [31/50], Step [211/735], Loss: 0.8780\n",
      "Epoch [31/50], Step [212/735], Loss: 0.2015\n",
      "Epoch [31/50], Step [213/735], Loss: 0.0762\n",
      "Epoch [31/50], Step [214/735], Loss: 0.1728\n",
      "Epoch [31/50], Step [215/735], Loss: 0.1671\n",
      "Epoch [31/50], Step [216/735], Loss: 0.0938\n",
      "Epoch [31/50], Step [217/735], Loss: 0.4278\n",
      "Epoch [31/50], Step [218/735], Loss: 0.1289\n",
      "Epoch [31/50], Step [219/735], Loss: 0.0906\n",
      "Epoch [31/50], Step [220/735], Loss: 0.0321\n",
      "Epoch [31/50], Step [221/735], Loss: 0.3435\n",
      "Epoch [31/50], Step [222/735], Loss: 0.1399\n",
      "Epoch [31/50], Step [223/735], Loss: 0.2167\n",
      "Epoch [31/50], Step [224/735], Loss: 0.1078\n",
      "Epoch [31/50], Step [225/735], Loss: 0.1489\n",
      "Epoch [31/50], Step [226/735], Loss: 0.0979\n",
      "Epoch [31/50], Step [227/735], Loss: 0.1310\n",
      "Epoch [31/50], Step [228/735], Loss: 0.0987\n",
      "Epoch [31/50], Step [229/735], Loss: 0.0872\n",
      "Epoch [31/50], Step [230/735], Loss: 0.0552\n",
      "Epoch [31/50], Step [231/735], Loss: 0.0536\n",
      "Epoch [31/50], Step [232/735], Loss: 0.0581\n",
      "Epoch [31/50], Step [233/735], Loss: 0.1812\n",
      "Epoch [31/50], Step [234/735], Loss: 0.1430\n",
      "Epoch [31/50], Step [235/735], Loss: 0.1663\n",
      "Epoch [31/50], Step [236/735], Loss: 0.0526\n",
      "Epoch [31/50], Step [237/735], Loss: 0.1698\n",
      "Epoch [31/50], Step [238/735], Loss: 0.0911\n",
      "Epoch [31/50], Step [239/735], Loss: 0.0613\n",
      "Epoch [31/50], Step [240/735], Loss: 0.0618\n",
      "Epoch [31/50], Step [241/735], Loss: 0.0382\n",
      "Epoch [31/50], Step [242/735], Loss: 0.1301\n",
      "Epoch [31/50], Step [243/735], Loss: 0.0696\n",
      "Epoch [31/50], Step [244/735], Loss: 0.2888\n",
      "Epoch [31/50], Step [245/735], Loss: 0.2902\n",
      "Epoch [31/50], Step [246/735], Loss: 0.0751\n",
      "Epoch [31/50], Step [247/735], Loss: 0.0843\n",
      "Epoch [31/50], Step [248/735], Loss: 0.0705\n",
      "Epoch [31/50], Step [249/735], Loss: 0.1176\n",
      "Epoch [31/50], Step [250/735], Loss: 0.1640\n",
      "Epoch [31/50], Step [251/735], Loss: 0.1170\n",
      "Epoch [31/50], Step [252/735], Loss: 0.0971\n",
      "Epoch [31/50], Step [253/735], Loss: 0.0958\n",
      "Epoch [31/50], Step [254/735], Loss: 0.0962\n",
      "Epoch [31/50], Step [255/735], Loss: 0.1955\n",
      "Epoch [31/50], Step [256/735], Loss: 0.0439\n",
      "Epoch [31/50], Step [257/735], Loss: 0.1440\n",
      "Epoch [31/50], Step [258/735], Loss: 0.1641\n",
      "Epoch [31/50], Step [259/735], Loss: 0.4310\n",
      "Epoch [31/50], Step [260/735], Loss: 0.4507\n",
      "Epoch [31/50], Step [261/735], Loss: 0.1641\n",
      "Epoch [31/50], Step [262/735], Loss: 0.1536\n",
      "Epoch [31/50], Step [263/735], Loss: 0.0770\n",
      "Epoch [31/50], Step [264/735], Loss: 0.1223\n",
      "Epoch [31/50], Step [265/735], Loss: 0.2608\n",
      "Epoch [31/50], Step [266/735], Loss: 0.0400\n",
      "Epoch [31/50], Step [267/735], Loss: 0.0998\n",
      "Epoch [31/50], Step [268/735], Loss: 0.0912\n",
      "Epoch [31/50], Step [269/735], Loss: 0.2074\n",
      "Epoch [31/50], Step [270/735], Loss: 0.0649\n",
      "Epoch [31/50], Step [271/735], Loss: 0.6042\n",
      "Epoch [31/50], Step [272/735], Loss: 0.1144\n",
      "Epoch [31/50], Step [273/735], Loss: 0.1449\n",
      "Epoch [31/50], Step [274/735], Loss: 0.0597\n",
      "Epoch [31/50], Step [275/735], Loss: 0.1331\n",
      "Epoch [31/50], Step [276/735], Loss: 0.0307\n",
      "Epoch [31/50], Step [277/735], Loss: 0.0954\n",
      "Epoch [31/50], Step [278/735], Loss: 0.0775\n",
      "Epoch [31/50], Step [279/735], Loss: 0.0669\n",
      "Epoch [31/50], Step [280/735], Loss: 0.0976\n",
      "Epoch [31/50], Step [281/735], Loss: 0.1043\n",
      "Epoch [31/50], Step [282/735], Loss: 0.1214\n",
      "Epoch [31/50], Step [283/735], Loss: 0.1340\n",
      "Epoch [31/50], Step [284/735], Loss: 0.1045\n",
      "Epoch [31/50], Step [285/735], Loss: 0.1096\n",
      "Epoch [31/50], Step [286/735], Loss: 0.0821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Step [287/735], Loss: 0.1470\n",
      "Epoch [31/50], Step [288/735], Loss: 0.1317\n",
      "Epoch [31/50], Step [289/735], Loss: 0.1573\n",
      "Epoch [31/50], Step [290/735], Loss: 0.1062\n",
      "Epoch [31/50], Step [291/735], Loss: 0.2529\n",
      "Epoch [31/50], Step [292/735], Loss: 0.0507\n",
      "Epoch [31/50], Step [293/735], Loss: 0.2257\n",
      "Epoch [31/50], Step [294/735], Loss: 0.1434\n",
      "Epoch [31/50], Step [295/735], Loss: 0.0659\n",
      "Epoch [31/50], Step [296/735], Loss: 0.1816\n",
      "Epoch [31/50], Step [297/735], Loss: 0.1305\n",
      "Epoch [31/50], Step [298/735], Loss: 0.0406\n",
      "Epoch [31/50], Step [299/735], Loss: 0.0914\n",
      "Epoch [31/50], Step [300/735], Loss: 0.0565\n",
      "Epoch [31/50], Step [301/735], Loss: 0.0415\n",
      "Epoch [31/50], Step [302/735], Loss: 0.0699\n",
      "Epoch [31/50], Step [303/735], Loss: 0.1479\n",
      "Epoch [31/50], Step [304/735], Loss: 0.0565\n",
      "Epoch [31/50], Step [305/735], Loss: 0.0752\n",
      "Epoch [31/50], Step [306/735], Loss: 0.0510\n",
      "Epoch [31/50], Step [307/735], Loss: 0.0794\n",
      "Epoch [31/50], Step [308/735], Loss: 0.1420\n",
      "Epoch [31/50], Step [309/735], Loss: 0.0781\n",
      "Epoch [31/50], Step [310/735], Loss: 0.0351\n",
      "Epoch [31/50], Step [311/735], Loss: 0.0529\n",
      "Epoch [31/50], Step [312/735], Loss: 0.1598\n",
      "Epoch [31/50], Step [313/735], Loss: 0.0254\n",
      "Epoch [31/50], Step [314/735], Loss: 0.1590\n",
      "Epoch [31/50], Step [315/735], Loss: 0.5404\n",
      "Epoch [31/50], Step [316/735], Loss: 0.1671\n",
      "Epoch [31/50], Step [317/735], Loss: 0.0775\n",
      "Epoch [31/50], Step [318/735], Loss: 0.0826\n",
      "Epoch [31/50], Step [319/735], Loss: 0.1232\n",
      "Epoch [31/50], Step [320/735], Loss: 0.1463\n",
      "Epoch [31/50], Step [321/735], Loss: 0.1247\n",
      "Epoch [31/50], Step [322/735], Loss: 0.1241\n",
      "Epoch [31/50], Step [323/735], Loss: 0.1237\n",
      "Epoch [31/50], Step [324/735], Loss: 0.1201\n",
      "Epoch [31/50], Step [325/735], Loss: 0.1061\n",
      "Epoch [31/50], Step [326/735], Loss: 0.8192\n",
      "Epoch [31/50], Step [327/735], Loss: 0.1548\n",
      "Epoch [31/50], Step [328/735], Loss: 0.1911\n",
      "Epoch [31/50], Step [329/735], Loss: 0.0942\n",
      "Epoch [31/50], Step [330/735], Loss: 0.0460\n",
      "Epoch [31/50], Step [331/735], Loss: 0.1194\n",
      "Epoch [31/50], Step [332/735], Loss: 0.0298\n",
      "Epoch [31/50], Step [333/735], Loss: 0.0548\n",
      "Epoch [31/50], Step [334/735], Loss: 0.0681\n",
      "Epoch [31/50], Step [335/735], Loss: 0.1855\n",
      "Epoch [31/50], Step [336/735], Loss: 0.0845\n",
      "Epoch [31/50], Step [337/735], Loss: 0.0741\n",
      "Epoch [31/50], Step [338/735], Loss: 0.0381\n",
      "Epoch [31/50], Step [339/735], Loss: 0.2365\n",
      "Epoch [31/50], Step [340/735], Loss: 0.0821\n",
      "Epoch [31/50], Step [341/735], Loss: 0.0324\n",
      "Epoch [31/50], Step [342/735], Loss: 0.1342\n",
      "Epoch [31/50], Step [343/735], Loss: 0.1872\n",
      "Epoch [31/50], Step [344/735], Loss: 0.1258\n",
      "Epoch [31/50], Step [345/735], Loss: 0.1513\n",
      "Epoch [31/50], Step [346/735], Loss: 0.2162\n",
      "Epoch [31/50], Step [347/735], Loss: 0.1233\n",
      "Epoch [31/50], Step [348/735], Loss: 0.0930\n",
      "Epoch [31/50], Step [349/735], Loss: 0.1199\n",
      "Epoch [31/50], Step [350/735], Loss: 0.1055\n",
      "Epoch [31/50], Step [351/735], Loss: 0.0388\n",
      "Epoch [31/50], Step [352/735], Loss: 0.1791\n",
      "Epoch [31/50], Step [353/735], Loss: 0.0892\n",
      "Epoch [31/50], Step [354/735], Loss: 0.1575\n",
      "Epoch [31/50], Step [355/735], Loss: 0.5646\n",
      "Epoch [31/50], Step [356/735], Loss: 0.0760\n",
      "Epoch [31/50], Step [357/735], Loss: 0.0495\n",
      "Epoch [31/50], Step [358/735], Loss: 1.3385\n",
      "Epoch [31/50], Step [359/735], Loss: 0.0558\n",
      "Epoch [31/50], Step [360/735], Loss: 0.2900\n",
      "Epoch [31/50], Step [361/735], Loss: 0.0833\n",
      "Epoch [31/50], Step [362/735], Loss: 0.1507\n",
      "Epoch [31/50], Step [363/735], Loss: 0.1946\n",
      "Epoch [31/50], Step [364/735], Loss: 0.1444\n",
      "Epoch [31/50], Step [365/735], Loss: 0.0704\n",
      "Epoch [31/50], Step [366/735], Loss: 0.0551\n",
      "Epoch [31/50], Step [367/735], Loss: 0.4872\n",
      "Epoch [31/50], Step [368/735], Loss: 0.2980\n",
      "Epoch [31/50], Step [369/735], Loss: 0.0479\n",
      "Epoch [31/50], Step [370/735], Loss: 0.3042\n",
      "Epoch [31/50], Step [371/735], Loss: 0.0873\n",
      "Epoch [31/50], Step [372/735], Loss: 0.1375\n",
      "Epoch [31/50], Step [373/735], Loss: 0.1498\n",
      "Epoch [31/50], Step [374/735], Loss: 0.0942\n",
      "Epoch [31/50], Step [375/735], Loss: 0.1197\n",
      "Epoch [31/50], Step [376/735], Loss: 0.1556\n",
      "Epoch [31/50], Step [377/735], Loss: 0.1432\n",
      "Epoch [31/50], Step [378/735], Loss: 0.0893\n",
      "Epoch [31/50], Step [379/735], Loss: 0.0564\n",
      "Epoch [31/50], Step [380/735], Loss: 0.0555\n",
      "Epoch [31/50], Step [381/735], Loss: 0.0644\n",
      "Epoch [31/50], Step [382/735], Loss: 0.1429\n",
      "Epoch [31/50], Step [383/735], Loss: 0.1610\n",
      "Epoch [31/50], Step [384/735], Loss: 0.0472\n",
      "Epoch [31/50], Step [385/735], Loss: 0.2919\n",
      "Epoch [31/50], Step [386/735], Loss: 0.1394\n",
      "Epoch [31/50], Step [387/735], Loss: 0.1209\n",
      "Epoch [31/50], Step [388/735], Loss: 0.2246\n",
      "Epoch [31/50], Step [389/735], Loss: 0.1083\n",
      "Epoch [31/50], Step [390/735], Loss: 0.1118\n",
      "Epoch [31/50], Step [391/735], Loss: 0.0741\n",
      "Epoch [31/50], Step [392/735], Loss: 0.0514\n",
      "Epoch [31/50], Step [393/735], Loss: 0.1351\n",
      "Epoch [31/50], Step [394/735], Loss: 1.2980\n",
      "Epoch [31/50], Step [395/735], Loss: 0.1591\n",
      "Epoch [31/50], Step [396/735], Loss: 0.1061\n",
      "Epoch [31/50], Step [397/735], Loss: 0.1468\n",
      "Epoch [31/50], Step [398/735], Loss: 0.1719\n",
      "Epoch [31/50], Step [399/735], Loss: 0.1166\n",
      "Epoch [31/50], Step [400/735], Loss: 0.4014\n",
      "Epoch [31/50], Step [401/735], Loss: 0.1197\n",
      "Epoch [31/50], Step [402/735], Loss: 0.3603\n",
      "Epoch [31/50], Step [403/735], Loss: 0.0730\n",
      "Epoch [31/50], Step [404/735], Loss: 0.1120\n",
      "Epoch [31/50], Step [405/735], Loss: 0.1753\n",
      "Epoch [31/50], Step [406/735], Loss: 0.1508\n",
      "Epoch [31/50], Step [407/735], Loss: 0.0808\n",
      "Epoch [31/50], Step [408/735], Loss: 0.2363\n",
      "Epoch [31/50], Step [409/735], Loss: 0.0613\n",
      "Epoch [31/50], Step [410/735], Loss: 0.1486\n",
      "Epoch [31/50], Step [411/735], Loss: 0.4057\n",
      "Epoch [31/50], Step [412/735], Loss: 0.2462\n",
      "Epoch [31/50], Step [413/735], Loss: 0.0424\n",
      "Epoch [31/50], Step [414/735], Loss: 0.1256\n",
      "Epoch [31/50], Step [415/735], Loss: 0.0461\n",
      "Epoch [31/50], Step [416/735], Loss: 0.0687\n",
      "Epoch [31/50], Step [417/735], Loss: 0.1120\n",
      "Epoch [31/50], Step [418/735], Loss: 0.0842\n",
      "Epoch [31/50], Step [419/735], Loss: 0.1717\n",
      "Epoch [31/50], Step [420/735], Loss: 0.1321\n",
      "Epoch [31/50], Step [421/735], Loss: 0.1750\n",
      "Epoch [31/50], Step [422/735], Loss: 0.0495\n",
      "Epoch [31/50], Step [423/735], Loss: 0.0866\n",
      "Epoch [31/50], Step [424/735], Loss: 0.0856\n",
      "Epoch [31/50], Step [425/735], Loss: 0.2293\n",
      "Epoch [31/50], Step [426/735], Loss: 0.0904\n",
      "Epoch [31/50], Step [427/735], Loss: 0.0586\n",
      "Epoch [31/50], Step [428/735], Loss: 0.0390\n",
      "Epoch [31/50], Step [429/735], Loss: 0.1903\n",
      "Epoch [31/50], Step [430/735], Loss: 0.2739\n",
      "Epoch [31/50], Step [431/735], Loss: 0.0899\n",
      "Epoch [31/50], Step [432/735], Loss: 1.1551\n",
      "Epoch [31/50], Step [433/735], Loss: 0.3686\n",
      "Epoch [31/50], Step [434/735], Loss: 0.2449\n",
      "Epoch [31/50], Step [435/735], Loss: 0.4850\n",
      "Epoch [31/50], Step [436/735], Loss: 0.0764\n",
      "Epoch [31/50], Step [437/735], Loss: 0.1071\n",
      "Epoch [31/50], Step [438/735], Loss: 0.0617\n",
      "Epoch [31/50], Step [439/735], Loss: 0.3206\n",
      "Epoch [31/50], Step [440/735], Loss: 0.2156\n",
      "Epoch [31/50], Step [441/735], Loss: 0.0909\n",
      "Epoch [31/50], Step [442/735], Loss: 0.0985\n",
      "Epoch [31/50], Step [443/735], Loss: 0.0871\n",
      "Epoch [31/50], Step [444/735], Loss: 0.1173\n",
      "Epoch [31/50], Step [445/735], Loss: 0.2898\n",
      "Epoch [31/50], Step [446/735], Loss: 0.1390\n",
      "Epoch [31/50], Step [447/735], Loss: 0.2027\n",
      "Epoch [31/50], Step [448/735], Loss: 0.1376\n",
      "Epoch [31/50], Step [449/735], Loss: 0.0843\n",
      "Epoch [31/50], Step [450/735], Loss: 0.0621\n",
      "Epoch [31/50], Step [451/735], Loss: 0.0375\n",
      "Epoch [31/50], Step [452/735], Loss: 0.1615\n",
      "Epoch [31/50], Step [453/735], Loss: 0.0974\n",
      "Epoch [31/50], Step [454/735], Loss: 0.1404\n",
      "Epoch [31/50], Step [455/735], Loss: 0.4538\n",
      "Epoch [31/50], Step [456/735], Loss: 0.2531\n",
      "Epoch [31/50], Step [457/735], Loss: 0.0774\n",
      "Epoch [31/50], Step [458/735], Loss: 0.0698\n",
      "Epoch [31/50], Step [459/735], Loss: 0.1167\n",
      "Epoch [31/50], Step [460/735], Loss: 0.1090\n",
      "Epoch [31/50], Step [461/735], Loss: 0.0606\n",
      "Epoch [31/50], Step [462/735], Loss: 0.1307\n",
      "Epoch [31/50], Step [463/735], Loss: 0.1617\n",
      "Epoch [31/50], Step [464/735], Loss: 0.1026\n",
      "Epoch [31/50], Step [465/735], Loss: 0.0882\n",
      "Epoch [31/50], Step [466/735], Loss: 0.1040\n",
      "Epoch [31/50], Step [467/735], Loss: 0.1116\n",
      "Epoch [31/50], Step [468/735], Loss: 0.1065\n",
      "Epoch [31/50], Step [469/735], Loss: 0.2427\n",
      "Epoch [31/50], Step [470/735], Loss: 0.0439\n",
      "Epoch [31/50], Step [471/735], Loss: 0.1079\n",
      "Epoch [31/50], Step [472/735], Loss: 0.0230\n",
      "Epoch [31/50], Step [473/735], Loss: 0.1706\n",
      "Epoch [31/50], Step [474/735], Loss: 0.1777\n",
      "Epoch [31/50], Step [475/735], Loss: 0.1203\n",
      "Epoch [31/50], Step [476/735], Loss: 0.1191\n",
      "Epoch [31/50], Step [477/735], Loss: 0.0423\n",
      "Epoch [31/50], Step [478/735], Loss: 0.0505\n",
      "Epoch [31/50], Step [479/735], Loss: 0.1465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Step [480/735], Loss: 0.0576\n",
      "Epoch [31/50], Step [481/735], Loss: 0.1234\n",
      "Epoch [31/50], Step [482/735], Loss: 0.2117\n",
      "Epoch [31/50], Step [483/735], Loss: 0.0485\n",
      "Epoch [31/50], Step [484/735], Loss: 0.0279\n",
      "Epoch [31/50], Step [485/735], Loss: 0.1179\n",
      "Epoch [31/50], Step [486/735], Loss: 0.0647\n",
      "Epoch [31/50], Step [487/735], Loss: 1.8403\n",
      "Epoch [31/50], Step [488/735], Loss: 0.0535\n",
      "Epoch [31/50], Step [489/735], Loss: 0.0295\n",
      "Epoch [31/50], Step [490/735], Loss: 0.0455\n",
      "Epoch [31/50], Step [491/735], Loss: 0.0856\n",
      "Epoch [31/50], Step [492/735], Loss: 0.0612\n",
      "Epoch [31/50], Step [493/735], Loss: 0.0683\n",
      "Epoch [31/50], Step [494/735], Loss: 0.7518\n",
      "Epoch [31/50], Step [495/735], Loss: 0.0733\n",
      "Epoch [31/50], Step [496/735], Loss: 0.1728\n",
      "Epoch [31/50], Step [497/735], Loss: 0.0884\n",
      "Epoch [31/50], Step [498/735], Loss: 0.4031\n",
      "Epoch [31/50], Step [499/735], Loss: 0.0760\n",
      "Epoch [31/50], Step [500/735], Loss: 0.1141\n",
      "Epoch [31/50], Step [501/735], Loss: 0.4495\n",
      "Epoch [31/50], Step [502/735], Loss: 0.0756\n",
      "Epoch [31/50], Step [503/735], Loss: 0.0957\n",
      "Epoch [31/50], Step [504/735], Loss: 0.0541\n",
      "Epoch [31/50], Step [505/735], Loss: 0.1346\n",
      "Epoch [31/50], Step [506/735], Loss: 0.1414\n",
      "Epoch [31/50], Step [507/735], Loss: 0.0921\n",
      "Epoch [31/50], Step [508/735], Loss: 0.0878\n",
      "Epoch [31/50], Step [509/735], Loss: 0.0583\n",
      "Epoch [31/50], Step [510/735], Loss: 0.0499\n",
      "Epoch [31/50], Step [511/735], Loss: 0.1071\n",
      "Epoch [31/50], Step [512/735], Loss: 0.2143\n",
      "Epoch [31/50], Step [513/735], Loss: 0.1810\n",
      "Epoch [31/50], Step [514/735], Loss: 0.5927\n",
      "Epoch [31/50], Step [515/735], Loss: 0.0927\n",
      "Epoch [31/50], Step [516/735], Loss: 0.2524\n",
      "Epoch [31/50], Step [517/735], Loss: 0.0863\n",
      "Epoch [31/50], Step [518/735], Loss: 0.2384\n",
      "Epoch [31/50], Step [519/735], Loss: 0.1429\n",
      "Epoch [31/50], Step [520/735], Loss: 0.0534\n",
      "Epoch [31/50], Step [521/735], Loss: 0.1240\n",
      "Epoch [31/50], Step [522/735], Loss: 0.1804\n",
      "Epoch [31/50], Step [523/735], Loss: 0.7793\n",
      "Epoch [31/50], Step [524/735], Loss: 0.0738\n",
      "Epoch [31/50], Step [525/735], Loss: 0.1946\n",
      "Epoch [31/50], Step [526/735], Loss: 0.1390\n",
      "Epoch [31/50], Step [527/735], Loss: 0.1256\n",
      "Epoch [31/50], Step [528/735], Loss: 0.0373\n",
      "Epoch [31/50], Step [529/735], Loss: 0.0550\n",
      "Epoch [31/50], Step [530/735], Loss: 0.1313\n",
      "Epoch [31/50], Step [531/735], Loss: 0.0820\n",
      "Epoch [31/50], Step [532/735], Loss: 0.0468\n",
      "Epoch [31/50], Step [533/735], Loss: 0.0820\n",
      "Epoch [31/50], Step [534/735], Loss: 0.1461\n",
      "Epoch [31/50], Step [535/735], Loss: 0.1237\n",
      "Epoch [31/50], Step [536/735], Loss: 0.1801\n",
      "Epoch [31/50], Step [537/735], Loss: 0.0879\n",
      "Epoch [31/50], Step [538/735], Loss: 0.2872\n",
      "Epoch [31/50], Step [539/735], Loss: 0.2187\n",
      "Epoch [31/50], Step [540/735], Loss: 0.0474\n",
      "Epoch [31/50], Step [541/735], Loss: 0.2628\n",
      "Epoch [31/50], Step [542/735], Loss: 0.1275\n",
      "Epoch [31/50], Step [543/735], Loss: 0.8554\n",
      "Epoch [31/50], Step [544/735], Loss: 0.0660\n",
      "Epoch [31/50], Step [545/735], Loss: 0.1314\n",
      "Epoch [31/50], Step [546/735], Loss: 0.0980\n",
      "Epoch [31/50], Step [547/735], Loss: 0.1385\n",
      "Epoch [31/50], Step [548/735], Loss: 0.1132\n",
      "Epoch [31/50], Step [549/735], Loss: 0.1046\n",
      "Epoch [31/50], Step [550/735], Loss: 0.0289\n",
      "Epoch [31/50], Step [551/735], Loss: 0.0506\n",
      "Epoch [31/50], Step [552/735], Loss: 0.1006\n",
      "Epoch [31/50], Step [553/735], Loss: 0.1671\n",
      "Epoch [31/50], Step [554/735], Loss: 0.1661\n",
      "Epoch [31/50], Step [555/735], Loss: 0.1159\n",
      "Epoch [31/50], Step [556/735], Loss: 0.0576\n",
      "Epoch [31/50], Step [557/735], Loss: 0.0913\n",
      "Epoch [31/50], Step [558/735], Loss: 0.0818\n",
      "Epoch [31/50], Step [559/735], Loss: 0.1404\n",
      "Epoch [31/50], Step [560/735], Loss: 0.0780\n",
      "Epoch [31/50], Step [561/735], Loss: 0.0293\n",
      "Epoch [31/50], Step [562/735], Loss: 0.1384\n",
      "Epoch [31/50], Step [563/735], Loss: 0.1837\n",
      "Epoch [31/50], Step [564/735], Loss: 0.1410\n",
      "Epoch [31/50], Step [565/735], Loss: 0.1375\n",
      "Epoch [31/50], Step [566/735], Loss: 0.1148\n",
      "Epoch [31/50], Step [567/735], Loss: 0.1492\n",
      "Epoch [31/50], Step [568/735], Loss: 0.1075\n",
      "Epoch [31/50], Step [569/735], Loss: 0.1358\n",
      "Epoch [31/50], Step [570/735], Loss: 0.1691\n",
      "Epoch [31/50], Step [571/735], Loss: 0.1168\n",
      "Epoch [31/50], Step [572/735], Loss: 0.0448\n",
      "Epoch [31/50], Step [573/735], Loss: 0.1130\n",
      "Epoch [31/50], Step [574/735], Loss: 0.0388\n",
      "Epoch [31/50], Step [575/735], Loss: 0.1173\n",
      "Epoch [31/50], Step [576/735], Loss: 0.0905\n",
      "Epoch [31/50], Step [577/735], Loss: 1.7459\n",
      "Epoch [31/50], Step [578/735], Loss: 0.0708\n",
      "Epoch [31/50], Step [579/735], Loss: 0.0736\n",
      "Epoch [31/50], Step [580/735], Loss: 0.0951\n",
      "Epoch [31/50], Step [581/735], Loss: 0.0639\n",
      "Epoch [31/50], Step [582/735], Loss: 0.0818\n",
      "Epoch [31/50], Step [583/735], Loss: 0.5870\n",
      "Epoch [31/50], Step [584/735], Loss: 0.0747\n",
      "Epoch [31/50], Step [585/735], Loss: 0.2155\n",
      "Epoch [31/50], Step [586/735], Loss: 0.1051\n",
      "Epoch [31/50], Step [587/735], Loss: 0.0348\n",
      "Epoch [31/50], Step [588/735], Loss: 0.1416\n",
      "Epoch [31/50], Step [589/735], Loss: 0.0983\n",
      "Epoch [31/50], Step [590/735], Loss: 0.4910\n",
      "Epoch [31/50], Step [591/735], Loss: 0.0843\n",
      "Epoch [31/50], Step [592/735], Loss: 0.0608\n",
      "Epoch [31/50], Step [593/735], Loss: 0.1039\n",
      "Epoch [31/50], Step [594/735], Loss: 0.0982\n",
      "Epoch [31/50], Step [595/735], Loss: 0.1100\n",
      "Epoch [31/50], Step [596/735], Loss: 0.0488\n",
      "Epoch [31/50], Step [597/735], Loss: 0.1905\n",
      "Epoch [31/50], Step [598/735], Loss: 0.1293\n",
      "Epoch [31/50], Step [599/735], Loss: 0.1544\n",
      "Epoch [31/50], Step [600/735], Loss: 0.2032\n",
      "Epoch [31/50], Step [601/735], Loss: 0.1361\n",
      "Epoch [31/50], Step [602/735], Loss: 0.1601\n",
      "Epoch [31/50], Step [603/735], Loss: 0.0924\n",
      "Epoch [31/50], Step [604/735], Loss: 0.1428\n",
      "Epoch [31/50], Step [605/735], Loss: 0.1360\n",
      "Epoch [31/50], Step [606/735], Loss: 0.1487\n",
      "Epoch [31/50], Step [607/735], Loss: 0.1163\n",
      "Epoch [31/50], Step [608/735], Loss: 0.4931\n",
      "Epoch [31/50], Step [609/735], Loss: 0.0642\n",
      "Epoch [31/50], Step [610/735], Loss: 0.1321\n",
      "Epoch [31/50], Step [611/735], Loss: 0.0432\n",
      "Epoch [31/50], Step [612/735], Loss: 0.0891\n",
      "Epoch [31/50], Step [613/735], Loss: 0.6165\n",
      "Epoch [31/50], Step [614/735], Loss: 0.2153\n",
      "Epoch [31/50], Step [615/735], Loss: 0.1062\n",
      "Epoch [31/50], Step [616/735], Loss: 0.0538\n",
      "Epoch [31/50], Step [617/735], Loss: 0.2060\n",
      "Epoch [31/50], Step [618/735], Loss: 0.0659\n",
      "Epoch [31/50], Step [619/735], Loss: 0.2305\n",
      "Epoch [31/50], Step [620/735], Loss: 0.1806\n",
      "Epoch [31/50], Step [621/735], Loss: 0.0925\n",
      "Epoch [31/50], Step [622/735], Loss: 0.1246\n",
      "Epoch [31/50], Step [623/735], Loss: 0.1203\n",
      "Epoch [31/50], Step [624/735], Loss: 0.0598\n",
      "Epoch [31/50], Step [625/735], Loss: 0.0999\n",
      "Epoch [31/50], Step [626/735], Loss: 0.1411\n",
      "Epoch [31/50], Step [627/735], Loss: 0.1754\n",
      "Epoch [31/50], Step [628/735], Loss: 0.0633\n",
      "Epoch [31/50], Step [629/735], Loss: 0.1001\n",
      "Epoch [31/50], Step [630/735], Loss: 0.0901\n",
      "Epoch [31/50], Step [631/735], Loss: 0.1328\n",
      "Epoch [31/50], Step [632/735], Loss: 0.0994\n",
      "Epoch [31/50], Step [633/735], Loss: 0.1572\n",
      "Epoch [31/50], Step [634/735], Loss: 0.0439\n",
      "Epoch [31/50], Step [635/735], Loss: 0.0696\n",
      "Epoch [31/50], Step [636/735], Loss: 0.0820\n",
      "Epoch [31/50], Step [637/735], Loss: 0.0808\n",
      "Epoch [31/50], Step [638/735], Loss: 0.0704\n",
      "Epoch [31/50], Step [639/735], Loss: 0.5559\n",
      "Epoch [31/50], Step [640/735], Loss: 0.0483\n",
      "Epoch [31/50], Step [641/735], Loss: 0.0576\n",
      "Epoch [31/50], Step [642/735], Loss: 0.2583\n",
      "Epoch [31/50], Step [643/735], Loss: 0.1078\n",
      "Epoch [31/50], Step [644/735], Loss: 0.0439\n",
      "Epoch [31/50], Step [645/735], Loss: 0.1332\n",
      "Epoch [31/50], Step [646/735], Loss: 0.1917\n",
      "Epoch [31/50], Step [647/735], Loss: 0.0635\n",
      "Epoch [31/50], Step [648/735], Loss: 0.0939\n",
      "Epoch [31/50], Step [649/735], Loss: 0.1266\n",
      "Epoch [31/50], Step [650/735], Loss: 0.0548\n",
      "Epoch [31/50], Step [651/735], Loss: 0.1283\n",
      "Epoch [31/50], Step [652/735], Loss: 0.1948\n",
      "Epoch [31/50], Step [653/735], Loss: 0.1437\n",
      "Epoch [31/50], Step [654/735], Loss: 0.3894\n",
      "Epoch [31/50], Step [655/735], Loss: 0.0866\n",
      "Epoch [31/50], Step [656/735], Loss: 0.0869\n",
      "Epoch [31/50], Step [657/735], Loss: 0.0419\n",
      "Epoch [31/50], Step [658/735], Loss: 0.2299\n",
      "Epoch [31/50], Step [659/735], Loss: 0.0948\n",
      "Epoch [31/50], Step [660/735], Loss: 0.0395\n",
      "Epoch [31/50], Step [661/735], Loss: 0.1121\n",
      "Epoch [31/50], Step [662/735], Loss: 0.1173\n",
      "Epoch [31/50], Step [663/735], Loss: 0.1755\n",
      "Epoch [31/50], Step [664/735], Loss: 0.1076\n",
      "Epoch [31/50], Step [665/735], Loss: 0.0453\n",
      "Epoch [31/50], Step [666/735], Loss: 0.2180\n",
      "Epoch [31/50], Step [667/735], Loss: 0.4166\n",
      "Epoch [31/50], Step [668/735], Loss: 0.1874\n",
      "Epoch [31/50], Step [669/735], Loss: 0.0479\n",
      "Epoch [31/50], Step [670/735], Loss: 0.1618\n",
      "Epoch [31/50], Step [671/735], Loss: 0.0657\n",
      "Epoch [31/50], Step [672/735], Loss: 0.0573\n",
      "Epoch [31/50], Step [673/735], Loss: 0.4263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Step [674/735], Loss: 0.0822\n",
      "Epoch [31/50], Step [675/735], Loss: 0.1554\n",
      "Epoch [31/50], Step [676/735], Loss: 0.0969\n",
      "Epoch [31/50], Step [677/735], Loss: 0.0888\n",
      "Epoch [31/50], Step [678/735], Loss: 0.0584\n",
      "Epoch [31/50], Step [679/735], Loss: 0.0915\n",
      "Epoch [31/50], Step [680/735], Loss: 0.0646\n",
      "Epoch [31/50], Step [681/735], Loss: 0.2170\n",
      "Epoch [31/50], Step [682/735], Loss: 0.1218\n",
      "Epoch [31/50], Step [683/735], Loss: 0.1246\n",
      "Epoch [31/50], Step [684/735], Loss: 0.1289\n",
      "Epoch [31/50], Step [685/735], Loss: 0.1270\n",
      "Epoch [31/50], Step [686/735], Loss: 0.3024\n",
      "Epoch [31/50], Step [687/735], Loss: 0.0251\n",
      "Epoch [31/50], Step [688/735], Loss: 0.0984\n",
      "Epoch [31/50], Step [689/735], Loss: 0.1844\n",
      "Epoch [31/50], Step [690/735], Loss: 0.0832\n",
      "Epoch [31/50], Step [691/735], Loss: 0.2074\n",
      "Epoch [31/50], Step [692/735], Loss: 0.1385\n",
      "Epoch [31/50], Step [693/735], Loss: 0.0893\n",
      "Epoch [31/50], Step [694/735], Loss: 0.0562\n",
      "Epoch [31/50], Step [695/735], Loss: 0.2310\n",
      "Epoch [31/50], Step [696/735], Loss: 0.2173\n",
      "Epoch [31/50], Step [697/735], Loss: 0.1053\n",
      "Epoch [31/50], Step [698/735], Loss: 0.0844\n",
      "Epoch [31/50], Step [699/735], Loss: 0.1352\n",
      "Epoch [31/50], Step [700/735], Loss: 0.0287\n",
      "Epoch [31/50], Step [701/735], Loss: 0.0520\n",
      "Epoch [31/50], Step [702/735], Loss: 1.0015\n",
      "Epoch [31/50], Step [703/735], Loss: 0.0493\n",
      "Epoch [31/50], Step [704/735], Loss: 0.0753\n",
      "Epoch [31/50], Step [705/735], Loss: 0.1094\n",
      "Epoch [31/50], Step [706/735], Loss: 0.1605\n",
      "Epoch [31/50], Step [707/735], Loss: 0.1329\n",
      "Epoch [31/50], Step [708/735], Loss: 0.1585\n",
      "Epoch [31/50], Step [709/735], Loss: 0.0540\n",
      "Epoch [31/50], Step [710/735], Loss: 0.1855\n",
      "Epoch [31/50], Step [711/735], Loss: 0.1105\n",
      "Epoch [31/50], Step [712/735], Loss: 0.0363\n",
      "Epoch [31/50], Step [713/735], Loss: 0.1005\n",
      "Epoch [31/50], Step [714/735], Loss: 0.1041\n",
      "Epoch [31/50], Step [715/735], Loss: 0.0509\n",
      "Epoch [31/50], Step [716/735], Loss: 0.0913\n",
      "Epoch [31/50], Step [717/735], Loss: 0.0524\n",
      "Epoch [31/50], Step [718/735], Loss: 0.0994\n",
      "Epoch [31/50], Step [719/735], Loss: 0.0904\n",
      "Epoch [31/50], Step [720/735], Loss: 0.0891\n",
      "Epoch [31/50], Step [721/735], Loss: 0.0591\n",
      "Epoch [31/50], Step [722/735], Loss: 0.0765\n",
      "Epoch [31/50], Step [723/735], Loss: 0.0827\n",
      "Epoch [31/50], Step [724/735], Loss: 0.4929\n",
      "Epoch [31/50], Step [725/735], Loss: 0.1417\n",
      "Epoch [31/50], Step [726/735], Loss: 0.0302\n",
      "Epoch [31/50], Step [727/735], Loss: 0.8582\n",
      "Epoch [31/50], Step [728/735], Loss: 0.0410\n",
      "Epoch [31/50], Step [729/735], Loss: 0.0923\n",
      "Epoch [31/50], Step [730/735], Loss: 1.6750\n",
      "Epoch [31/50], Step [731/735], Loss: 0.1466\n",
      "Epoch [31/50], Step [732/735], Loss: 0.7400\n",
      "Epoch [31/50], Step [733/735], Loss: 0.2415\n",
      "Epoch [31/50], Step [734/735], Loss: 0.0590\n",
      "Epoch [31/50], Step [735/735], Loss: 0.0674\n",
      "Epoch [32/50], Step [1/735], Loss: 0.0666\n",
      "Epoch [32/50], Step [2/735], Loss: 0.2009\n",
      "Epoch [32/50], Step [3/735], Loss: 0.1466\n",
      "Epoch [32/50], Step [4/735], Loss: 0.0501\n",
      "Epoch [32/50], Step [5/735], Loss: 0.0679\n",
      "Epoch [32/50], Step [6/735], Loss: 0.1161\n",
      "Epoch [32/50], Step [7/735], Loss: 0.0690\n",
      "Epoch [32/50], Step [8/735], Loss: 0.1224\n",
      "Epoch [32/50], Step [9/735], Loss: 0.0676\n",
      "Epoch [32/50], Step [10/735], Loss: 0.1668\n",
      "Epoch [32/50], Step [11/735], Loss: 0.1013\n",
      "Epoch [32/50], Step [12/735], Loss: 0.2017\n",
      "Epoch [32/50], Step [13/735], Loss: 0.0854\n",
      "Epoch [32/50], Step [14/735], Loss: 0.1631\n",
      "Epoch [32/50], Step [15/735], Loss: 0.0930\n",
      "Epoch [32/50], Step [16/735], Loss: 0.0418\n",
      "Epoch [32/50], Step [17/735], Loss: 0.0811\n",
      "Epoch [32/50], Step [18/735], Loss: 0.1139\n",
      "Epoch [32/50], Step [19/735], Loss: 0.3012\n",
      "Epoch [32/50], Step [20/735], Loss: 0.0398\n",
      "Epoch [32/50], Step [21/735], Loss: 0.0331\n",
      "Epoch [32/50], Step [22/735], Loss: 0.1668\n",
      "Epoch [32/50], Step [23/735], Loss: 0.0631\n",
      "Epoch [32/50], Step [24/735], Loss: 0.0853\n",
      "Epoch [32/50], Step [25/735], Loss: 0.0764\n",
      "Epoch [32/50], Step [26/735], Loss: 0.0477\n",
      "Epoch [32/50], Step [27/735], Loss: 0.0578\n",
      "Epoch [32/50], Step [28/735], Loss: 0.1053\n",
      "Epoch [32/50], Step [29/735], Loss: 0.0459\n",
      "Epoch [32/50], Step [30/735], Loss: 0.1162\n",
      "Epoch [32/50], Step [31/735], Loss: 0.1292\n",
      "Epoch [32/50], Step [32/735], Loss: 0.1440\n",
      "Epoch [32/50], Step [33/735], Loss: 0.1104\n",
      "Epoch [32/50], Step [34/735], Loss: 0.0972\n",
      "Epoch [32/50], Step [35/735], Loss: 0.1019\n",
      "Epoch [32/50], Step [36/735], Loss: 0.9575\n",
      "Epoch [32/50], Step [37/735], Loss: 0.0635\n",
      "Epoch [32/50], Step [38/735], Loss: 0.0630\n",
      "Epoch [32/50], Step [39/735], Loss: 0.0283\n",
      "Epoch [32/50], Step [40/735], Loss: 0.0748\n",
      "Epoch [32/50], Step [41/735], Loss: 0.8695\n",
      "Epoch [32/50], Step [42/735], Loss: 0.0468\n",
      "Epoch [32/50], Step [43/735], Loss: 0.3064\n",
      "Epoch [32/50], Step [44/735], Loss: 0.2167\n",
      "Epoch [32/50], Step [45/735], Loss: 0.1283\n",
      "Epoch [32/50], Step [46/735], Loss: 0.2468\n",
      "Epoch [32/50], Step [47/735], Loss: 0.1271\n",
      "Epoch [32/50], Step [48/735], Loss: 0.0672\n",
      "Epoch [32/50], Step [49/735], Loss: 0.0950\n",
      "Epoch [32/50], Step [50/735], Loss: 0.1081\n",
      "Epoch [32/50], Step [51/735], Loss: 0.0850\n",
      "Epoch [32/50], Step [52/735], Loss: 0.1181\n",
      "Epoch [32/50], Step [53/735], Loss: 0.1048\n",
      "Epoch [32/50], Step [54/735], Loss: 0.0621\n",
      "Epoch [32/50], Step [55/735], Loss: 0.0670\n",
      "Epoch [32/50], Step [56/735], Loss: 0.0599\n",
      "Epoch [32/50], Step [57/735], Loss: 0.0997\n",
      "Epoch [32/50], Step [58/735], Loss: 0.0332\n",
      "Epoch [32/50], Step [59/735], Loss: 0.1287\n",
      "Epoch [32/50], Step [60/735], Loss: 0.0612\n",
      "Epoch [32/50], Step [61/735], Loss: 1.1461\n",
      "Epoch [32/50], Step [62/735], Loss: 0.1702\n",
      "Epoch [32/50], Step [63/735], Loss: 0.1292\n",
      "Epoch [32/50], Step [64/735], Loss: 0.0534\n",
      "Epoch [32/50], Step [65/735], Loss: 0.0710\n",
      "Epoch [32/50], Step [66/735], Loss: 0.1354\n",
      "Epoch [32/50], Step [67/735], Loss: 0.0558\n",
      "Epoch [32/50], Step [68/735], Loss: 0.1469\n",
      "Epoch [32/50], Step [69/735], Loss: 0.1203\n",
      "Epoch [32/50], Step [70/735], Loss: 0.1479\n",
      "Epoch [32/50], Step [71/735], Loss: 0.1815\n",
      "Epoch [32/50], Step [72/735], Loss: 0.3055\n",
      "Epoch [32/50], Step [73/735], Loss: 0.0394\n",
      "Epoch [32/50], Step [74/735], Loss: 0.0710\n",
      "Epoch [32/50], Step [75/735], Loss: 0.5249\n",
      "Epoch [32/50], Step [76/735], Loss: 0.0505\n",
      "Epoch [32/50], Step [77/735], Loss: 0.0975\n",
      "Epoch [32/50], Step [78/735], Loss: 0.1180\n",
      "Epoch [32/50], Step [79/735], Loss: 0.0721\n",
      "Epoch [32/50], Step [80/735], Loss: 0.1366\n",
      "Epoch [32/50], Step [81/735], Loss: 0.0960\n",
      "Epoch [32/50], Step [82/735], Loss: 0.1521\n",
      "Epoch [32/50], Step [83/735], Loss: 0.5616\n",
      "Epoch [32/50], Step [84/735], Loss: 0.0808\n",
      "Epoch [32/50], Step [85/735], Loss: 0.2036\n",
      "Epoch [32/50], Step [86/735], Loss: 0.0811\n",
      "Epoch [32/50], Step [87/735], Loss: 0.1246\n",
      "Epoch [32/50], Step [88/735], Loss: 0.0405\n",
      "Epoch [32/50], Step [89/735], Loss: 0.0941\n",
      "Epoch [32/50], Step [90/735], Loss: 0.0740\n",
      "Epoch [32/50], Step [91/735], Loss: 0.0746\n",
      "Epoch [32/50], Step [92/735], Loss: 0.1166\n",
      "Epoch [32/50], Step [93/735], Loss: 0.1213\n",
      "Epoch [32/50], Step [94/735], Loss: 0.0540\n",
      "Epoch [32/50], Step [95/735], Loss: 0.1076\n",
      "Epoch [32/50], Step [96/735], Loss: 0.0631\n",
      "Epoch [32/50], Step [97/735], Loss: 0.0872\n",
      "Epoch [32/50], Step [98/735], Loss: 0.6065\n",
      "Epoch [32/50], Step [99/735], Loss: 0.0790\n",
      "Epoch [32/50], Step [100/735], Loss: 0.1649\n",
      "Epoch [32/50], Step [101/735], Loss: 0.1243\n",
      "Epoch [32/50], Step [102/735], Loss: 0.1952\n",
      "Epoch [32/50], Step [103/735], Loss: 0.0543\n",
      "Epoch [32/50], Step [104/735], Loss: 0.1247\n",
      "Epoch [32/50], Step [105/735], Loss: 0.1333\n",
      "Epoch [32/50], Step [106/735], Loss: 0.1526\n",
      "Epoch [32/50], Step [107/735], Loss: 0.1258\n",
      "Epoch [32/50], Step [108/735], Loss: 0.0535\n",
      "Epoch [32/50], Step [109/735], Loss: 0.1774\n",
      "Epoch [32/50], Step [110/735], Loss: 0.0897\n",
      "Epoch [32/50], Step [111/735], Loss: 0.2737\n",
      "Epoch [32/50], Step [112/735], Loss: 0.0792\n",
      "Epoch [32/50], Step [113/735], Loss: 0.1965\n",
      "Epoch [32/50], Step [114/735], Loss: 0.1168\n",
      "Epoch [32/50], Step [115/735], Loss: 0.1164\n",
      "Epoch [32/50], Step [116/735], Loss: 0.2496\n",
      "Epoch [32/50], Step [117/735], Loss: 0.1457\n",
      "Epoch [32/50], Step [118/735], Loss: 0.0858\n",
      "Epoch [32/50], Step [119/735], Loss: 0.0946\n",
      "Epoch [32/50], Step [120/735], Loss: 0.0808\n",
      "Epoch [32/50], Step [121/735], Loss: 0.1694\n",
      "Epoch [32/50], Step [122/735], Loss: 0.6073\n",
      "Epoch [32/50], Step [123/735], Loss: 0.1336\n",
      "Epoch [32/50], Step [124/735], Loss: 0.3019\n",
      "Epoch [32/50], Step [125/735], Loss: 0.0809\n",
      "Epoch [32/50], Step [126/735], Loss: 0.0918\n",
      "Epoch [32/50], Step [127/735], Loss: 0.1203\n",
      "Epoch [32/50], Step [128/735], Loss: 0.0629\n",
      "Epoch [32/50], Step [129/735], Loss: 0.1005\n",
      "Epoch [32/50], Step [130/735], Loss: 0.0931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Step [131/735], Loss: 0.1071\n",
      "Epoch [32/50], Step [132/735], Loss: 0.6317\n",
      "Epoch [32/50], Step [133/735], Loss: 0.0574\n",
      "Epoch [32/50], Step [134/735], Loss: 0.1101\n",
      "Epoch [32/50], Step [135/735], Loss: 0.1004\n",
      "Epoch [32/50], Step [136/735], Loss: 0.0963\n",
      "Epoch [32/50], Step [137/735], Loss: 0.0919\n",
      "Epoch [32/50], Step [138/735], Loss: 0.5368\n",
      "Epoch [32/50], Step [139/735], Loss: 0.0940\n",
      "Epoch [32/50], Step [140/735], Loss: 0.1172\n",
      "Epoch [32/50], Step [141/735], Loss: 0.1194\n",
      "Epoch [32/50], Step [142/735], Loss: 0.0530\n",
      "Epoch [32/50], Step [143/735], Loss: 0.0695\n",
      "Epoch [32/50], Step [144/735], Loss: 0.0444\n",
      "Epoch [32/50], Step [145/735], Loss: 0.1086\n",
      "Epoch [32/50], Step [146/735], Loss: 0.0868\n",
      "Epoch [32/50], Step [147/735], Loss: 0.1171\n",
      "Epoch [32/50], Step [148/735], Loss: 0.0898\n",
      "Epoch [32/50], Step [149/735], Loss: 0.0431\n",
      "Epoch [32/50], Step [150/735], Loss: 0.1179\n",
      "Epoch [32/50], Step [151/735], Loss: 0.1702\n",
      "Epoch [32/50], Step [152/735], Loss: 0.0664\n",
      "Epoch [32/50], Step [153/735], Loss: 0.1060\n",
      "Epoch [32/50], Step [154/735], Loss: 0.0467\n",
      "Epoch [32/50], Step [155/735], Loss: 0.0893\n",
      "Epoch [32/50], Step [156/735], Loss: 0.0679\n",
      "Epoch [32/50], Step [157/735], Loss: 0.0595\n",
      "Epoch [32/50], Step [158/735], Loss: 0.0697\n",
      "Epoch [32/50], Step [159/735], Loss: 0.1657\n",
      "Epoch [32/50], Step [160/735], Loss: 0.1189\n",
      "Epoch [32/50], Step [161/735], Loss: 0.0648\n",
      "Epoch [32/50], Step [162/735], Loss: 0.0857\n",
      "Epoch [32/50], Step [163/735], Loss: 0.1424\n",
      "Epoch [32/50], Step [164/735], Loss: 0.1520\n",
      "Epoch [32/50], Step [165/735], Loss: 0.1024\n",
      "Epoch [32/50], Step [166/735], Loss: 0.0585\n",
      "Epoch [32/50], Step [167/735], Loss: 0.2203\n",
      "Epoch [32/50], Step [168/735], Loss: 0.0937\n",
      "Epoch [32/50], Step [169/735], Loss: 0.6914\n",
      "Epoch [32/50], Step [170/735], Loss: 0.1431\n",
      "Epoch [32/50], Step [171/735], Loss: 0.0512\n",
      "Epoch [32/50], Step [172/735], Loss: 0.0798\n",
      "Epoch [32/50], Step [173/735], Loss: 0.1089\n",
      "Epoch [32/50], Step [174/735], Loss: 0.1230\n",
      "Epoch [32/50], Step [175/735], Loss: 0.2533\n",
      "Epoch [32/50], Step [176/735], Loss: 0.1301\n",
      "Epoch [32/50], Step [177/735], Loss: 0.1169\n",
      "Epoch [32/50], Step [178/735], Loss: 0.1955\n",
      "Epoch [32/50], Step [179/735], Loss: 0.0732\n",
      "Epoch [32/50], Step [180/735], Loss: 0.1581\n",
      "Epoch [32/50], Step [181/735], Loss: 0.1273\n",
      "Epoch [32/50], Step [182/735], Loss: 0.0530\n",
      "Epoch [32/50], Step [183/735], Loss: 0.0747\n",
      "Epoch [32/50], Step [184/735], Loss: 0.0430\n",
      "Epoch [32/50], Step [185/735], Loss: 0.0614\n",
      "Epoch [32/50], Step [186/735], Loss: 0.6541\n",
      "Epoch [32/50], Step [187/735], Loss: 0.0523\n",
      "Epoch [32/50], Step [188/735], Loss: 0.0528\n",
      "Epoch [32/50], Step [189/735], Loss: 0.1033\n",
      "Epoch [32/50], Step [190/735], Loss: 0.1371\n",
      "Epoch [32/50], Step [191/735], Loss: 0.0943\n",
      "Epoch [32/50], Step [192/735], Loss: 0.0700\n",
      "Epoch [32/50], Step [193/735], Loss: 0.2136\n",
      "Epoch [32/50], Step [194/735], Loss: 0.0448\n",
      "Epoch [32/50], Step [195/735], Loss: 0.1324\n",
      "Epoch [32/50], Step [196/735], Loss: 0.1562\n",
      "Epoch [32/50], Step [197/735], Loss: 0.0680\n",
      "Epoch [32/50], Step [198/735], Loss: 0.0423\n",
      "Epoch [32/50], Step [199/735], Loss: 0.0263\n",
      "Epoch [32/50], Step [200/735], Loss: 0.0350\n",
      "Epoch [32/50], Step [201/735], Loss: 0.0848\n",
      "Epoch [32/50], Step [202/735], Loss: 0.1159\n",
      "Epoch [32/50], Step [203/735], Loss: 0.0563\n",
      "Epoch [32/50], Step [204/735], Loss: 0.0699\n",
      "Epoch [32/50], Step [205/735], Loss: 0.0674\n",
      "Epoch [32/50], Step [206/735], Loss: 0.1007\n",
      "Epoch [32/50], Step [207/735], Loss: 0.1760\n",
      "Epoch [32/50], Step [208/735], Loss: 0.0795\n",
      "Epoch [32/50], Step [209/735], Loss: 0.0723\n",
      "Epoch [32/50], Step [210/735], Loss: 0.1182\n",
      "Epoch [32/50], Step [211/735], Loss: 0.1344\n",
      "Epoch [32/50], Step [212/735], Loss: 0.1193\n",
      "Epoch [32/50], Step [213/735], Loss: 0.0766\n",
      "Epoch [32/50], Step [214/735], Loss: 0.0358\n",
      "Epoch [32/50], Step [215/735], Loss: 0.0696\n",
      "Epoch [32/50], Step [216/735], Loss: 0.0902\n",
      "Epoch [32/50], Step [217/735], Loss: 0.0848\n",
      "Epoch [32/50], Step [218/735], Loss: 0.0720\n",
      "Epoch [32/50], Step [219/735], Loss: 0.1091\n",
      "Epoch [32/50], Step [220/735], Loss: 0.0569\n",
      "Epoch [32/50], Step [221/735], Loss: 0.0377\n",
      "Epoch [32/50], Step [222/735], Loss: 0.0804\n",
      "Epoch [32/50], Step [223/735], Loss: 0.0992\n",
      "Epoch [32/50], Step [224/735], Loss: 0.0963\n",
      "Epoch [32/50], Step [225/735], Loss: 0.1204\n",
      "Epoch [32/50], Step [226/735], Loss: 0.0598\n",
      "Epoch [32/50], Step [227/735], Loss: 0.0933\n",
      "Epoch [32/50], Step [228/735], Loss: 0.0892\n",
      "Epoch [32/50], Step [229/735], Loss: 0.1116\n",
      "Epoch [32/50], Step [230/735], Loss: 0.1270\n",
      "Epoch [32/50], Step [231/735], Loss: 0.1079\n",
      "Epoch [32/50], Step [232/735], Loss: 0.0657\n",
      "Epoch [32/50], Step [233/735], Loss: 0.1101\n",
      "Epoch [32/50], Step [234/735], Loss: 0.4078\n",
      "Epoch [32/50], Step [235/735], Loss: 0.1187\n",
      "Epoch [32/50], Step [236/735], Loss: 0.0503\n",
      "Epoch [32/50], Step [237/735], Loss: 0.0842\n",
      "Epoch [32/50], Step [238/735], Loss: 0.0733\n",
      "Epoch [32/50], Step [239/735], Loss: 0.0661\n",
      "Epoch [32/50], Step [240/735], Loss: 0.1327\n",
      "Epoch [32/50], Step [241/735], Loss: 0.1272\n",
      "Epoch [32/50], Step [242/735], Loss: 0.1222\n",
      "Epoch [32/50], Step [243/735], Loss: 0.1064\n",
      "Epoch [32/50], Step [244/735], Loss: 0.0541\n",
      "Epoch [32/50], Step [245/735], Loss: 0.1851\n",
      "Epoch [32/50], Step [246/735], Loss: 0.0688\n",
      "Epoch [32/50], Step [247/735], Loss: 0.1636\n",
      "Epoch [32/50], Step [248/735], Loss: 0.0854\n",
      "Epoch [32/50], Step [249/735], Loss: 0.0736\n",
      "Epoch [32/50], Step [250/735], Loss: 0.0456\n",
      "Epoch [32/50], Step [251/735], Loss: 0.1929\n",
      "Epoch [32/50], Step [252/735], Loss: 0.0845\n",
      "Epoch [32/50], Step [253/735], Loss: 0.1002\n",
      "Epoch [32/50], Step [254/735], Loss: 0.1078\n",
      "Epoch [32/50], Step [255/735], Loss: 0.1328\n",
      "Epoch [32/50], Step [256/735], Loss: 0.1303\n",
      "Epoch [32/50], Step [257/735], Loss: 0.0577\n",
      "Epoch [32/50], Step [258/735], Loss: 0.0552\n",
      "Epoch [32/50], Step [259/735], Loss: 0.0774\n",
      "Epoch [32/50], Step [260/735], Loss: 0.1763\n",
      "Epoch [32/50], Step [261/735], Loss: 0.0605\n",
      "Epoch [32/50], Step [262/735], Loss: 0.0738\n",
      "Epoch [32/50], Step [263/735], Loss: 0.4442\n",
      "Epoch [32/50], Step [264/735], Loss: 0.0424\n",
      "Epoch [32/50], Step [265/735], Loss: 0.0606\n",
      "Epoch [32/50], Step [266/735], Loss: 0.0931\n",
      "Epoch [32/50], Step [267/735], Loss: 0.2268\n",
      "Epoch [32/50], Step [268/735], Loss: 0.0909\n",
      "Epoch [32/50], Step [269/735], Loss: 0.0742\n",
      "Epoch [32/50], Step [270/735], Loss: 0.1740\n",
      "Epoch [32/50], Step [271/735], Loss: 0.0321\n",
      "Epoch [32/50], Step [272/735], Loss: 1.1757\n",
      "Epoch [32/50], Step [273/735], Loss: 0.4129\n",
      "Epoch [32/50], Step [274/735], Loss: 0.0600\n",
      "Epoch [32/50], Step [275/735], Loss: 0.0985\n",
      "Epoch [32/50], Step [276/735], Loss: 0.0998\n",
      "Epoch [32/50], Step [277/735], Loss: 0.2096\n",
      "Epoch [32/50], Step [278/735], Loss: 0.0478\n",
      "Epoch [32/50], Step [279/735], Loss: 0.2835\n",
      "Epoch [32/50], Step [280/735], Loss: 0.1357\n",
      "Epoch [32/50], Step [281/735], Loss: 0.4610\n",
      "Epoch [32/50], Step [282/735], Loss: 0.0946\n",
      "Epoch [32/50], Step [283/735], Loss: 0.0921\n",
      "Epoch [32/50], Step [284/735], Loss: 0.0529\n",
      "Epoch [32/50], Step [285/735], Loss: 0.3585\n",
      "Epoch [32/50], Step [286/735], Loss: 0.0524\n",
      "Epoch [32/50], Step [287/735], Loss: 0.2597\n",
      "Epoch [32/50], Step [288/735], Loss: 0.1467\n",
      "Epoch [32/50], Step [289/735], Loss: 0.0968\n",
      "Epoch [32/50], Step [290/735], Loss: 0.2181\n",
      "Epoch [32/50], Step [291/735], Loss: 0.1697\n",
      "Epoch [32/50], Step [292/735], Loss: 0.1611\n",
      "Epoch [32/50], Step [293/735], Loss: 0.0919\n",
      "Epoch [32/50], Step [294/735], Loss: 0.1400\n",
      "Epoch [32/50], Step [295/735], Loss: 0.0617\n",
      "Epoch [32/50], Step [296/735], Loss: 0.0494\n",
      "Epoch [32/50], Step [297/735], Loss: 0.1663\n",
      "Epoch [32/50], Step [298/735], Loss: 0.1566\n",
      "Epoch [32/50], Step [299/735], Loss: 0.0837\n",
      "Epoch [32/50], Step [300/735], Loss: 0.1323\n",
      "Epoch [32/50], Step [301/735], Loss: 0.0855\n",
      "Epoch [32/50], Step [302/735], Loss: 0.1281\n",
      "Epoch [32/50], Step [303/735], Loss: 0.1241\n",
      "Epoch [32/50], Step [304/735], Loss: 0.1357\n",
      "Epoch [32/50], Step [305/735], Loss: 0.0858\n",
      "Epoch [32/50], Step [306/735], Loss: 0.1556\n",
      "Epoch [32/50], Step [307/735], Loss: 0.1831\n",
      "Epoch [32/50], Step [308/735], Loss: 0.1627\n",
      "Epoch [32/50], Step [309/735], Loss: 0.0854\n",
      "Epoch [32/50], Step [310/735], Loss: 0.2273\n",
      "Epoch [32/50], Step [311/735], Loss: 0.1210\n",
      "Epoch [32/50], Step [312/735], Loss: 0.0817\n",
      "Epoch [32/50], Step [313/735], Loss: 0.1437\n",
      "Epoch [32/50], Step [314/735], Loss: 0.0914\n",
      "Epoch [32/50], Step [315/735], Loss: 0.3279\n",
      "Epoch [32/50], Step [316/735], Loss: 0.1724\n",
      "Epoch [32/50], Step [317/735], Loss: 0.0525\n",
      "Epoch [32/50], Step [318/735], Loss: 0.1233\n",
      "Epoch [32/50], Step [319/735], Loss: 0.1128\n",
      "Epoch [32/50], Step [320/735], Loss: 0.0992\n",
      "Epoch [32/50], Step [321/735], Loss: 0.0728\n",
      "Epoch [32/50], Step [322/735], Loss: 0.2599\n",
      "Epoch [32/50], Step [323/735], Loss: 0.0580\n",
      "Epoch [32/50], Step [324/735], Loss: 0.2481\n",
      "Epoch [32/50], Step [325/735], Loss: 1.3286\n",
      "Epoch [32/50], Step [326/735], Loss: 0.0447\n",
      "Epoch [32/50], Step [327/735], Loss: 0.2818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Step [328/735], Loss: 0.1917\n",
      "Epoch [32/50], Step [329/735], Loss: 0.0504\n",
      "Epoch [32/50], Step [330/735], Loss: 0.0640\n",
      "Epoch [32/50], Step [331/735], Loss: 0.1148\n",
      "Epoch [32/50], Step [332/735], Loss: 0.0386\n",
      "Epoch [32/50], Step [333/735], Loss: 0.0631\n",
      "Epoch [32/50], Step [334/735], Loss: 0.2486\n",
      "Epoch [32/50], Step [335/735], Loss: 0.0851\n",
      "Epoch [32/50], Step [336/735], Loss: 0.0535\n",
      "Epoch [32/50], Step [337/735], Loss: 0.0887\n",
      "Epoch [32/50], Step [338/735], Loss: 0.0972\n",
      "Epoch [32/50], Step [339/735], Loss: 0.0796\n",
      "Epoch [32/50], Step [340/735], Loss: 0.1038\n",
      "Epoch [32/50], Step [341/735], Loss: 0.0606\n",
      "Epoch [32/50], Step [342/735], Loss: 0.0918\n",
      "Epoch [32/50], Step [343/735], Loss: 0.1163\n",
      "Epoch [32/50], Step [344/735], Loss: 0.0974\n",
      "Epoch [32/50], Step [345/735], Loss: 0.1036\n",
      "Epoch [32/50], Step [346/735], Loss: 0.1273\n",
      "Epoch [32/50], Step [347/735], Loss: 0.0779\n",
      "Epoch [32/50], Step [348/735], Loss: 0.1566\n",
      "Epoch [32/50], Step [349/735], Loss: 0.0883\n",
      "Epoch [32/50], Step [350/735], Loss: 0.3058\n",
      "Epoch [32/50], Step [351/735], Loss: 0.0313\n",
      "Epoch [32/50], Step [352/735], Loss: 0.1182\n",
      "Epoch [32/50], Step [353/735], Loss: 0.0586\n",
      "Epoch [32/50], Step [354/735], Loss: 0.1114\n",
      "Epoch [32/50], Step [355/735], Loss: 0.2214\n",
      "Epoch [32/50], Step [356/735], Loss: 0.1237\n",
      "Epoch [32/50], Step [357/735], Loss: 0.8635\n",
      "Epoch [32/50], Step [358/735], Loss: 0.1051\n",
      "Epoch [32/50], Step [359/735], Loss: 0.0611\n",
      "Epoch [32/50], Step [360/735], Loss: 0.0801\n",
      "Epoch [32/50], Step [361/735], Loss: 0.0928\n",
      "Epoch [32/50], Step [362/735], Loss: 0.1936\n",
      "Epoch [32/50], Step [363/735], Loss: 0.1205\n",
      "Epoch [32/50], Step [364/735], Loss: 0.1008\n",
      "Epoch [32/50], Step [365/735], Loss: 0.1192\n",
      "Epoch [32/50], Step [366/735], Loss: 0.0665\n",
      "Epoch [32/50], Step [367/735], Loss: 0.0605\n",
      "Epoch [32/50], Step [368/735], Loss: 0.0743\n",
      "Epoch [32/50], Step [369/735], Loss: 0.1880\n",
      "Epoch [32/50], Step [370/735], Loss: 0.0615\n",
      "Epoch [32/50], Step [371/735], Loss: 0.0784\n",
      "Epoch [32/50], Step [372/735], Loss: 0.6447\n",
      "Epoch [32/50], Step [373/735], Loss: 0.2624\n",
      "Epoch [32/50], Step [374/735], Loss: 0.0970\n",
      "Epoch [32/50], Step [375/735], Loss: 0.1837\n",
      "Epoch [32/50], Step [376/735], Loss: 0.0638\n",
      "Epoch [32/50], Step [377/735], Loss: 0.2230\n",
      "Epoch [32/50], Step [378/735], Loss: 0.0848\n",
      "Epoch [32/50], Step [379/735], Loss: 0.1177\n",
      "Epoch [32/50], Step [380/735], Loss: 0.1336\n",
      "Epoch [32/50], Step [381/735], Loss: 0.1494\n",
      "Epoch [32/50], Step [382/735], Loss: 0.0638\n",
      "Epoch [32/50], Step [383/735], Loss: 0.1736\n",
      "Epoch [32/50], Step [384/735], Loss: 0.0906\n",
      "Epoch [32/50], Step [385/735], Loss: 0.1467\n",
      "Epoch [32/50], Step [386/735], Loss: 0.1408\n",
      "Epoch [32/50], Step [387/735], Loss: 0.1100\n",
      "Epoch [32/50], Step [388/735], Loss: 0.1328\n",
      "Epoch [32/50], Step [389/735], Loss: 0.3330\n",
      "Epoch [32/50], Step [390/735], Loss: 0.1336\n",
      "Epoch [32/50], Step [391/735], Loss: 0.0767\n",
      "Epoch [32/50], Step [392/735], Loss: 0.1407\n",
      "Epoch [32/50], Step [393/735], Loss: 0.0709\n",
      "Epoch [32/50], Step [394/735], Loss: 0.0929\n",
      "Epoch [32/50], Step [395/735], Loss: 0.1560\n",
      "Epoch [32/50], Step [396/735], Loss: 0.3778\n",
      "Epoch [32/50], Step [397/735], Loss: 0.0567\n",
      "Epoch [32/50], Step [398/735], Loss: 0.0619\n",
      "Epoch [32/50], Step [399/735], Loss: 0.0898\n",
      "Epoch [32/50], Step [400/735], Loss: 0.1305\n",
      "Epoch [32/50], Step [401/735], Loss: 0.0624\n",
      "Epoch [32/50], Step [402/735], Loss: 0.1572\n",
      "Epoch [32/50], Step [403/735], Loss: 0.0866\n",
      "Epoch [32/50], Step [404/735], Loss: 0.0595\n",
      "Epoch [32/50], Step [405/735], Loss: 0.0919\n",
      "Epoch [32/50], Step [406/735], Loss: 0.1009\n",
      "Epoch [32/50], Step [407/735], Loss: 0.0800\n",
      "Epoch [32/50], Step [408/735], Loss: 0.0569\n",
      "Epoch [32/50], Step [409/735], Loss: 0.0745\n",
      "Epoch [32/50], Step [410/735], Loss: 0.2067\n",
      "Epoch [32/50], Step [411/735], Loss: 0.0654\n",
      "Epoch [32/50], Step [412/735], Loss: 0.1040\n",
      "Epoch [32/50], Step [413/735], Loss: 0.1210\n",
      "Epoch [32/50], Step [414/735], Loss: 0.0850\n",
      "Epoch [32/50], Step [415/735], Loss: 2.0492\n",
      "Epoch [32/50], Step [416/735], Loss: 0.1871\n",
      "Epoch [32/50], Step [417/735], Loss: 0.2212\n",
      "Epoch [32/50], Step [418/735], Loss: 0.1002\n",
      "Epoch [32/50], Step [419/735], Loss: 0.1757\n",
      "Epoch [32/50], Step [420/735], Loss: 0.0684\n",
      "Epoch [32/50], Step [421/735], Loss: 0.1078\n",
      "Epoch [32/50], Step [422/735], Loss: 0.1598\n",
      "Epoch [32/50], Step [423/735], Loss: 0.1057\n",
      "Epoch [32/50], Step [424/735], Loss: 0.2456\n",
      "Epoch [32/50], Step [425/735], Loss: 0.0731\n",
      "Epoch [32/50], Step [426/735], Loss: 0.1202\n",
      "Epoch [32/50], Step [427/735], Loss: 0.0936\n",
      "Epoch [32/50], Step [428/735], Loss: 0.2559\n",
      "Epoch [32/50], Step [429/735], Loss: 0.0705\n",
      "Epoch [32/50], Step [430/735], Loss: 0.0643\n",
      "Epoch [32/50], Step [431/735], Loss: 0.1534\n",
      "Epoch [32/50], Step [432/735], Loss: 0.0717\n",
      "Epoch [32/50], Step [433/735], Loss: 0.1288\n",
      "Epoch [32/50], Step [434/735], Loss: 0.3241\n",
      "Epoch [32/50], Step [435/735], Loss: 0.1800\n",
      "Epoch [32/50], Step [436/735], Loss: 0.1152\n",
      "Epoch [32/50], Step [437/735], Loss: 0.2001\n",
      "Epoch [32/50], Step [438/735], Loss: 0.0753\n",
      "Epoch [32/50], Step [439/735], Loss: 0.0522\n",
      "Epoch [32/50], Step [440/735], Loss: 0.0414\n",
      "Epoch [32/50], Step [441/735], Loss: 0.0877\n",
      "Epoch [32/50], Step [442/735], Loss: 0.1125\n",
      "Epoch [32/50], Step [443/735], Loss: 1.6760\n",
      "Epoch [32/50], Step [444/735], Loss: 0.1232\n",
      "Epoch [32/50], Step [445/735], Loss: 0.0245\n",
      "Epoch [32/50], Step [446/735], Loss: 0.0431\n",
      "Epoch [32/50], Step [447/735], Loss: 1.6045\n",
      "Epoch [32/50], Step [448/735], Loss: 0.1466\n",
      "Epoch [32/50], Step [449/735], Loss: 0.1353\n",
      "Epoch [32/50], Step [450/735], Loss: 0.2175\n",
      "Epoch [32/50], Step [451/735], Loss: 0.0583\n",
      "Epoch [32/50], Step [452/735], Loss: 0.1638\n",
      "Epoch [32/50], Step [453/735], Loss: 0.0998\n",
      "Epoch [32/50], Step [454/735], Loss: 0.1015\n",
      "Epoch [32/50], Step [455/735], Loss: 0.1751\n",
      "Epoch [32/50], Step [456/735], Loss: 0.1798\n",
      "Epoch [32/50], Step [457/735], Loss: 0.0881\n",
      "Epoch [32/50], Step [458/735], Loss: 0.1037\n",
      "Epoch [32/50], Step [459/735], Loss: 0.0773\n",
      "Epoch [32/50], Step [460/735], Loss: 0.0902\n",
      "Epoch [32/50], Step [461/735], Loss: 0.0847\n",
      "Epoch [32/50], Step [462/735], Loss: 0.2690\n",
      "Epoch [32/50], Step [463/735], Loss: 0.0413\n",
      "Epoch [32/50], Step [464/735], Loss: 0.2020\n",
      "Epoch [32/50], Step [465/735], Loss: 0.0961\n",
      "Epoch [32/50], Step [466/735], Loss: 0.0301\n",
      "Epoch [32/50], Step [467/735], Loss: 0.0592\n",
      "Epoch [32/50], Step [468/735], Loss: 0.1294\n",
      "Epoch [32/50], Step [469/735], Loss: 0.1009\n",
      "Epoch [32/50], Step [470/735], Loss: 0.0920\n",
      "Epoch [32/50], Step [471/735], Loss: 0.0403\n",
      "Epoch [32/50], Step [472/735], Loss: 0.1863\n",
      "Epoch [32/50], Step [473/735], Loss: 0.2349\n",
      "Epoch [32/50], Step [474/735], Loss: 0.0781\n",
      "Epoch [32/50], Step [475/735], Loss: 0.0685\n",
      "Epoch [32/50], Step [476/735], Loss: 0.1155\n",
      "Epoch [32/50], Step [477/735], Loss: 0.0936\n",
      "Epoch [32/50], Step [478/735], Loss: 0.1347\n",
      "Epoch [32/50], Step [479/735], Loss: 0.1230\n",
      "Epoch [32/50], Step [480/735], Loss: 0.3171\n",
      "Epoch [32/50], Step [481/735], Loss: 0.5839\n",
      "Epoch [32/50], Step [482/735], Loss: 0.0630\n",
      "Epoch [32/50], Step [483/735], Loss: 0.0881\n",
      "Epoch [32/50], Step [484/735], Loss: 0.1503\n",
      "Epoch [32/50], Step [485/735], Loss: 0.3196\n",
      "Epoch [32/50], Step [486/735], Loss: 0.1640\n",
      "Epoch [32/50], Step [487/735], Loss: 0.0608\n",
      "Epoch [32/50], Step [488/735], Loss: 0.1186\n",
      "Epoch [32/50], Step [489/735], Loss: 0.1430\n",
      "Epoch [32/50], Step [490/735], Loss: 0.1642\n",
      "Epoch [32/50], Step [491/735], Loss: 0.0416\n",
      "Epoch [32/50], Step [492/735], Loss: 0.1994\n",
      "Epoch [32/50], Step [493/735], Loss: 0.1011\n",
      "Epoch [32/50], Step [494/735], Loss: 0.1410\n",
      "Epoch [32/50], Step [495/735], Loss: 0.0718\n",
      "Epoch [32/50], Step [496/735], Loss: 0.1056\n",
      "Epoch [32/50], Step [497/735], Loss: 0.0372\n",
      "Epoch [32/50], Step [498/735], Loss: 0.1174\n",
      "Epoch [32/50], Step [499/735], Loss: 0.1343\n",
      "Epoch [32/50], Step [500/735], Loss: 1.0467\n",
      "Epoch [32/50], Step [501/735], Loss: 0.0489\n",
      "Epoch [32/50], Step [502/735], Loss: 0.0701\n",
      "Epoch [32/50], Step [503/735], Loss: 0.0855\n",
      "Epoch [32/50], Step [504/735], Loss: 0.1001\n",
      "Epoch [32/50], Step [505/735], Loss: 0.0708\n",
      "Epoch [32/50], Step [506/735], Loss: 0.1218\n",
      "Epoch [32/50], Step [507/735], Loss: 0.1586\n",
      "Epoch [32/50], Step [508/735], Loss: 0.1387\n",
      "Epoch [32/50], Step [509/735], Loss: 0.6927\n",
      "Epoch [32/50], Step [510/735], Loss: 0.1347\n",
      "Epoch [32/50], Step [511/735], Loss: 0.8978\n",
      "Epoch [32/50], Step [512/735], Loss: 0.0513\n",
      "Epoch [32/50], Step [513/735], Loss: 0.1723\n",
      "Epoch [32/50], Step [514/735], Loss: 0.6319\n",
      "Epoch [32/50], Step [515/735], Loss: 0.1528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Step [516/735], Loss: 0.1382\n",
      "Epoch [32/50], Step [517/735], Loss: 0.0397\n",
      "Epoch [32/50], Step [518/735], Loss: 0.1552\n",
      "Epoch [32/50], Step [519/735], Loss: 0.1290\n",
      "Epoch [32/50], Step [520/735], Loss: 0.1953\n",
      "Epoch [32/50], Step [521/735], Loss: 0.0643\n",
      "Epoch [32/50], Step [522/735], Loss: 0.2138\n",
      "Epoch [32/50], Step [523/735], Loss: 0.1013\n",
      "Epoch [32/50], Step [524/735], Loss: 0.0459\n",
      "Epoch [32/50], Step [525/735], Loss: 0.0651\n",
      "Epoch [32/50], Step [526/735], Loss: 0.0708\n",
      "Epoch [32/50], Step [527/735], Loss: 0.4252\n",
      "Epoch [32/50], Step [528/735], Loss: 0.1324\n",
      "Epoch [32/50], Step [529/735], Loss: 0.0540\n",
      "Epoch [32/50], Step [530/735], Loss: 0.0429\n",
      "Epoch [32/50], Step [531/735], Loss: 0.0445\n",
      "Epoch [32/50], Step [532/735], Loss: 0.0605\n",
      "Epoch [32/50], Step [533/735], Loss: 0.1621\n",
      "Epoch [32/50], Step [534/735], Loss: 0.1027\n",
      "Epoch [32/50], Step [535/735], Loss: 0.0818\n",
      "Epoch [32/50], Step [536/735], Loss: 0.1620\n",
      "Epoch [32/50], Step [537/735], Loss: 0.3267\n",
      "Epoch [32/50], Step [538/735], Loss: 0.0270\n",
      "Epoch [32/50], Step [539/735], Loss: 0.1226\n",
      "Epoch [32/50], Step [540/735], Loss: 0.2065\n",
      "Epoch [32/50], Step [541/735], Loss: 0.1126\n",
      "Epoch [32/50], Step [542/735], Loss: 0.1468\n",
      "Epoch [32/50], Step [543/735], Loss: 0.0887\n",
      "Epoch [32/50], Step [544/735], Loss: 0.1052\n",
      "Epoch [32/50], Step [545/735], Loss: 0.1179\n",
      "Epoch [32/50], Step [546/735], Loss: 0.1957\n",
      "Epoch [32/50], Step [547/735], Loss: 0.1703\n",
      "Epoch [32/50], Step [548/735], Loss: 0.0946\n",
      "Epoch [32/50], Step [549/735], Loss: 0.0943\n",
      "Epoch [32/50], Step [550/735], Loss: 0.1264\n",
      "Epoch [32/50], Step [551/735], Loss: 0.0770\n",
      "Epoch [32/50], Step [552/735], Loss: 0.4061\n",
      "Epoch [32/50], Step [553/735], Loss: 0.0787\n",
      "Epoch [32/50], Step [554/735], Loss: 0.1491\n",
      "Epoch [32/50], Step [555/735], Loss: 0.1022\n",
      "Epoch [32/50], Step [556/735], Loss: 0.2672\n",
      "Epoch [32/50], Step [557/735], Loss: 1.2642\n",
      "Epoch [32/50], Step [558/735], Loss: 0.0835\n",
      "Epoch [32/50], Step [559/735], Loss: 0.1496\n",
      "Epoch [32/50], Step [560/735], Loss: 0.1332\n",
      "Epoch [32/50], Step [561/735], Loss: 0.6478\n",
      "Epoch [32/50], Step [562/735], Loss: 0.4528\n",
      "Epoch [32/50], Step [563/735], Loss: 0.1137\n",
      "Epoch [32/50], Step [564/735], Loss: 0.1694\n",
      "Epoch [32/50], Step [565/735], Loss: 0.0843\n",
      "Epoch [32/50], Step [566/735], Loss: 0.0560\n",
      "Epoch [32/50], Step [567/735], Loss: 0.3190\n",
      "Epoch [32/50], Step [568/735], Loss: 0.0960\n",
      "Epoch [32/50], Step [569/735], Loss: 0.0486\n",
      "Epoch [32/50], Step [570/735], Loss: 0.0557\n",
      "Epoch [32/50], Step [571/735], Loss: 0.1125\n",
      "Epoch [32/50], Step [572/735], Loss: 0.1485\n",
      "Epoch [32/50], Step [573/735], Loss: 0.0949\n",
      "Epoch [32/50], Step [574/735], Loss: 0.5889\n",
      "Epoch [32/50], Step [575/735], Loss: 0.2730\n",
      "Epoch [32/50], Step [576/735], Loss: 0.1427\n",
      "Epoch [32/50], Step [577/735], Loss: 0.0751\n",
      "Epoch [32/50], Step [578/735], Loss: 0.0672\n",
      "Epoch [32/50], Step [579/735], Loss: 0.1310\n",
      "Epoch [32/50], Step [580/735], Loss: 0.2258\n",
      "Epoch [32/50], Step [581/735], Loss: 0.4946\n",
      "Epoch [32/50], Step [582/735], Loss: 0.0774\n",
      "Epoch [32/50], Step [583/735], Loss: 0.0455\n",
      "Epoch [32/50], Step [584/735], Loss: 0.0788\n",
      "Epoch [32/50], Step [585/735], Loss: 0.0434\n",
      "Epoch [32/50], Step [586/735], Loss: 0.0826\n",
      "Epoch [32/50], Step [587/735], Loss: 0.0719\n",
      "Epoch [32/50], Step [588/735], Loss: 0.0652\n",
      "Epoch [32/50], Step [589/735], Loss: 0.0325\n",
      "Epoch [32/50], Step [590/735], Loss: 0.0280\n",
      "Epoch [32/50], Step [591/735], Loss: 0.0656\n",
      "Epoch [32/50], Step [592/735], Loss: 0.0914\n",
      "Epoch [32/50], Step [593/735], Loss: 0.3922\n",
      "Epoch [32/50], Step [594/735], Loss: 0.2496\n",
      "Epoch [32/50], Step [595/735], Loss: 0.0716\n",
      "Epoch [32/50], Step [596/735], Loss: 0.1217\n",
      "Epoch [32/50], Step [597/735], Loss: 0.1015\n",
      "Epoch [32/50], Step [598/735], Loss: 0.3364\n",
      "Epoch [32/50], Step [599/735], Loss: 0.0707\n",
      "Epoch [32/50], Step [600/735], Loss: 0.0415\n",
      "Epoch [32/50], Step [601/735], Loss: 0.1561\n",
      "Epoch [32/50], Step [602/735], Loss: 0.6959\n",
      "Epoch [32/50], Step [603/735], Loss: 0.1295\n",
      "Epoch [32/50], Step [604/735], Loss: 0.0788\n",
      "Epoch [32/50], Step [605/735], Loss: 0.2915\n",
      "Epoch [32/50], Step [606/735], Loss: 0.1589\n",
      "Epoch [32/50], Step [607/735], Loss: 0.1543\n",
      "Epoch [32/50], Step [608/735], Loss: 0.3341\n",
      "Epoch [32/50], Step [609/735], Loss: 0.1003\n",
      "Epoch [32/50], Step [610/735], Loss: 0.1929\n",
      "Epoch [32/50], Step [611/735], Loss: 0.0893\n",
      "Epoch [32/50], Step [612/735], Loss: 0.1206\n",
      "Epoch [32/50], Step [613/735], Loss: 0.1553\n",
      "Epoch [32/50], Step [614/735], Loss: 0.0561\n",
      "Epoch [32/50], Step [615/735], Loss: 0.0947\n",
      "Epoch [32/50], Step [616/735], Loss: 0.1460\n",
      "Epoch [32/50], Step [617/735], Loss: 0.0886\n",
      "Epoch [32/50], Step [618/735], Loss: 0.1287\n",
      "Epoch [32/50], Step [619/735], Loss: 0.2404\n",
      "Epoch [32/50], Step [620/735], Loss: 0.2010\n",
      "Epoch [32/50], Step [621/735], Loss: 0.1186\n",
      "Epoch [32/50], Step [622/735], Loss: 0.1932\n",
      "Epoch [32/50], Step [623/735], Loss: 0.1510\n",
      "Epoch [32/50], Step [624/735], Loss: 0.3524\n",
      "Epoch [32/50], Step [625/735], Loss: 0.5651\n",
      "Epoch [32/50], Step [626/735], Loss: 0.1168\n",
      "Epoch [32/50], Step [627/735], Loss: 0.1800\n",
      "Epoch [32/50], Step [628/735], Loss: 0.2188\n",
      "Epoch [32/50], Step [629/735], Loss: 0.1285\n",
      "Epoch [32/50], Step [630/735], Loss: 0.2091\n",
      "Epoch [32/50], Step [631/735], Loss: 0.5369\n",
      "Epoch [32/50], Step [632/735], Loss: 0.6953\n",
      "Epoch [32/50], Step [633/735], Loss: 0.0970\n",
      "Epoch [32/50], Step [634/735], Loss: 0.0963\n",
      "Epoch [32/50], Step [635/735], Loss: 0.1087\n",
      "Epoch [32/50], Step [636/735], Loss: 0.0553\n",
      "Epoch [32/50], Step [637/735], Loss: 0.1244\n",
      "Epoch [32/50], Step [638/735], Loss: 0.0528\n",
      "Epoch [32/50], Step [639/735], Loss: 0.0597\n",
      "Epoch [32/50], Step [640/735], Loss: 0.0348\n",
      "Epoch [32/50], Step [641/735], Loss: 0.1777\n",
      "Epoch [32/50], Step [642/735], Loss: 0.1270\n",
      "Epoch [32/50], Step [643/735], Loss: 0.0726\n",
      "Epoch [32/50], Step [644/735], Loss: 0.1826\n",
      "Epoch [32/50], Step [645/735], Loss: 0.0990\n",
      "Epoch [32/50], Step [646/735], Loss: 0.0621\n",
      "Epoch [32/50], Step [647/735], Loss: 0.5426\n",
      "Epoch [32/50], Step [648/735], Loss: 0.1023\n",
      "Epoch [32/50], Step [649/735], Loss: 0.1728\n",
      "Epoch [32/50], Step [650/735], Loss: 0.0943\n",
      "Epoch [32/50], Step [651/735], Loss: 0.0950\n",
      "Epoch [32/50], Step [652/735], Loss: 0.0760\n",
      "Epoch [32/50], Step [653/735], Loss: 0.0687\n",
      "Epoch [32/50], Step [654/735], Loss: 0.0788\n",
      "Epoch [32/50], Step [655/735], Loss: 0.0542\n",
      "Epoch [32/50], Step [656/735], Loss: 0.6018\n",
      "Epoch [32/50], Step [657/735], Loss: 0.0830\n",
      "Epoch [32/50], Step [658/735], Loss: 0.1983\n",
      "Epoch [32/50], Step [659/735], Loss: 0.0936\n",
      "Epoch [32/50], Step [660/735], Loss: 0.1331\n",
      "Epoch [32/50], Step [661/735], Loss: 0.1954\n",
      "Epoch [32/50], Step [662/735], Loss: 0.0826\n",
      "Epoch [32/50], Step [663/735], Loss: 0.9872\n",
      "Epoch [32/50], Step [664/735], Loss: 0.0885\n",
      "Epoch [32/50], Step [665/735], Loss: 0.1781\n",
      "Epoch [32/50], Step [666/735], Loss: 0.1286\n",
      "Epoch [32/50], Step [667/735], Loss: 0.1205\n",
      "Epoch [32/50], Step [668/735], Loss: 0.0589\n",
      "Epoch [32/50], Step [669/735], Loss: 0.1370\n",
      "Epoch [32/50], Step [670/735], Loss: 0.0864\n",
      "Epoch [32/50], Step [671/735], Loss: 0.1286\n",
      "Epoch [32/50], Step [672/735], Loss: 0.1107\n",
      "Epoch [32/50], Step [673/735], Loss: 0.0903\n",
      "Epoch [32/50], Step [674/735], Loss: 0.1142\n",
      "Epoch [32/50], Step [675/735], Loss: 0.1280\n",
      "Epoch [32/50], Step [676/735], Loss: 0.0601\n",
      "Epoch [32/50], Step [677/735], Loss: 0.1661\n",
      "Epoch [32/50], Step [678/735], Loss: 0.2446\n",
      "Epoch [32/50], Step [679/735], Loss: 0.1179\n",
      "Epoch [32/50], Step [680/735], Loss: 0.1200\n",
      "Epoch [32/50], Step [681/735], Loss: 0.2049\n",
      "Epoch [32/50], Step [682/735], Loss: 0.3830\n",
      "Epoch [32/50], Step [683/735], Loss: 0.1241\n",
      "Epoch [32/50], Step [684/735], Loss: 0.0402\n",
      "Epoch [32/50], Step [685/735], Loss: 0.1025\n",
      "Epoch [32/50], Step [686/735], Loss: 0.2198\n",
      "Epoch [32/50], Step [687/735], Loss: 0.1278\n",
      "Epoch [32/50], Step [688/735], Loss: 0.1016\n",
      "Epoch [32/50], Step [689/735], Loss: 0.0494\n",
      "Epoch [32/50], Step [690/735], Loss: 0.8128\n",
      "Epoch [32/50], Step [691/735], Loss: 0.0785\n",
      "Epoch [32/50], Step [692/735], Loss: 0.0371\n",
      "Epoch [32/50], Step [693/735], Loss: 0.0911\n",
      "Epoch [32/50], Step [694/735], Loss: 0.2801\n",
      "Epoch [32/50], Step [695/735], Loss: 0.0315\n",
      "Epoch [32/50], Step [696/735], Loss: 0.0448\n",
      "Epoch [32/50], Step [697/735], Loss: 0.1202\n",
      "Epoch [32/50], Step [698/735], Loss: 0.4247\n",
      "Epoch [32/50], Step [699/735], Loss: 1.4241\n",
      "Epoch [32/50], Step [700/735], Loss: 0.1244\n",
      "Epoch [32/50], Step [701/735], Loss: 0.0815\n",
      "Epoch [32/50], Step [702/735], Loss: 0.0571\n",
      "Epoch [32/50], Step [703/735], Loss: 0.0626\n",
      "Epoch [32/50], Step [704/735], Loss: 0.3023\n",
      "Epoch [32/50], Step [705/735], Loss: 0.0820\n",
      "Epoch [32/50], Step [706/735], Loss: 0.2555\n",
      "Epoch [32/50], Step [707/735], Loss: 0.1278\n",
      "Epoch [32/50], Step [708/735], Loss: 0.0746\n",
      "Epoch [32/50], Step [709/735], Loss: 0.2977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Step [710/735], Loss: 0.0359\n",
      "Epoch [32/50], Step [711/735], Loss: 0.2411\n",
      "Epoch [32/50], Step [712/735], Loss: 0.1385\n",
      "Epoch [32/50], Step [713/735], Loss: 0.1198\n",
      "Epoch [32/50], Step [714/735], Loss: 0.1679\n",
      "Epoch [32/50], Step [715/735], Loss: 0.1082\n",
      "Epoch [32/50], Step [716/735], Loss: 0.3622\n",
      "Epoch [32/50], Step [717/735], Loss: 0.1687\n",
      "Epoch [32/50], Step [718/735], Loss: 0.1360\n",
      "Epoch [32/50], Step [719/735], Loss: 0.1299\n",
      "Epoch [32/50], Step [720/735], Loss: 0.0379\n",
      "Epoch [32/50], Step [721/735], Loss: 0.2587\n",
      "Epoch [32/50], Step [722/735], Loss: 0.1001\n",
      "Epoch [32/50], Step [723/735], Loss: 0.2667\n",
      "Epoch [32/50], Step [724/735], Loss: 2.0421\n",
      "Epoch [32/50], Step [725/735], Loss: 0.2200\n",
      "Epoch [32/50], Step [726/735], Loss: 0.0876\n",
      "Epoch [32/50], Step [727/735], Loss: 0.1431\n",
      "Epoch [32/50], Step [728/735], Loss: 0.0782\n",
      "Epoch [32/50], Step [729/735], Loss: 0.1498\n",
      "Epoch [32/50], Step [730/735], Loss: 0.1421\n",
      "Epoch [32/50], Step [731/735], Loss: 1.9351\n",
      "Epoch [32/50], Step [732/735], Loss: 0.1288\n",
      "Epoch [32/50], Step [733/735], Loss: 0.1003\n",
      "Epoch [32/50], Step [734/735], Loss: 0.1420\n",
      "Epoch [32/50], Step [735/735], Loss: 0.1807\n",
      "Epoch [33/50], Step [1/735], Loss: 0.1431\n",
      "Epoch [33/50], Step [2/735], Loss: 0.1025\n",
      "Epoch [33/50], Step [3/735], Loss: 0.1329\n",
      "Epoch [33/50], Step [4/735], Loss: 0.0848\n",
      "Epoch [33/50], Step [5/735], Loss: 0.1723\n",
      "Epoch [33/50], Step [6/735], Loss: 0.0540\n",
      "Epoch [33/50], Step [7/735], Loss: 0.1696\n",
      "Epoch [33/50], Step [8/735], Loss: 0.0503\n",
      "Epoch [33/50], Step [9/735], Loss: 0.2043\n",
      "Epoch [33/50], Step [10/735], Loss: 0.1069\n",
      "Epoch [33/50], Step [11/735], Loss: 0.1252\n",
      "Epoch [33/50], Step [12/735], Loss: 0.0703\n",
      "Epoch [33/50], Step [13/735], Loss: 0.1714\n",
      "Epoch [33/50], Step [14/735], Loss: 0.1843\n",
      "Epoch [33/50], Step [15/735], Loss: 0.0491\n",
      "Epoch [33/50], Step [16/735], Loss: 0.2713\n",
      "Epoch [33/50], Step [17/735], Loss: 0.2065\n",
      "Epoch [33/50], Step [18/735], Loss: 0.1056\n",
      "Epoch [33/50], Step [19/735], Loss: 0.0768\n",
      "Epoch [33/50], Step [20/735], Loss: 0.1607\n",
      "Epoch [33/50], Step [21/735], Loss: 0.1190\n",
      "Epoch [33/50], Step [22/735], Loss: 0.1133\n",
      "Epoch [33/50], Step [23/735], Loss: 0.2015\n",
      "Epoch [33/50], Step [24/735], Loss: 0.0732\n",
      "Epoch [33/50], Step [25/735], Loss: 0.1716\n",
      "Epoch [33/50], Step [26/735], Loss: 0.0873\n",
      "Epoch [33/50], Step [27/735], Loss: 0.0875\n",
      "Epoch [33/50], Step [28/735], Loss: 0.0764\n",
      "Epoch [33/50], Step [29/735], Loss: 0.1038\n",
      "Epoch [33/50], Step [30/735], Loss: 1.2309\n",
      "Epoch [33/50], Step [31/735], Loss: 0.0862\n",
      "Epoch [33/50], Step [32/735], Loss: 0.0355\n",
      "Epoch [33/50], Step [33/735], Loss: 0.0770\n",
      "Epoch [33/50], Step [34/735], Loss: 0.1685\n",
      "Epoch [33/50], Step [35/735], Loss: 0.1812\n",
      "Epoch [33/50], Step [36/735], Loss: 0.0340\n",
      "Epoch [33/50], Step [37/735], Loss: 0.1854\n",
      "Epoch [33/50], Step [38/735], Loss: 0.0576\n",
      "Epoch [33/50], Step [39/735], Loss: 0.0696\n",
      "Epoch [33/50], Step [40/735], Loss: 0.1680\n",
      "Epoch [33/50], Step [41/735], Loss: 0.0837\n",
      "Epoch [33/50], Step [42/735], Loss: 0.3507\n",
      "Epoch [33/50], Step [43/735], Loss: 0.1348\n",
      "Epoch [33/50], Step [44/735], Loss: 0.0406\n",
      "Epoch [33/50], Step [45/735], Loss: 0.0635\n",
      "Epoch [33/50], Step [46/735], Loss: 0.2068\n",
      "Epoch [33/50], Step [47/735], Loss: 0.0536\n",
      "Epoch [33/50], Step [48/735], Loss: 0.0954\n",
      "Epoch [33/50], Step [49/735], Loss: 0.0503\n",
      "Epoch [33/50], Step [50/735], Loss: 0.0727\n",
      "Epoch [33/50], Step [51/735], Loss: 0.1020\n",
      "Epoch [33/50], Step [52/735], Loss: 0.1081\n",
      "Epoch [33/50], Step [53/735], Loss: 0.0450\n",
      "Epoch [33/50], Step [54/735], Loss: 0.0876\n",
      "Epoch [33/50], Step [55/735], Loss: 0.1092\n",
      "Epoch [33/50], Step [56/735], Loss: 0.1364\n",
      "Epoch [33/50], Step [57/735], Loss: 0.0717\n",
      "Epoch [33/50], Step [58/735], Loss: 0.1513\n",
      "Epoch [33/50], Step [59/735], Loss: 0.0750\n",
      "Epoch [33/50], Step [60/735], Loss: 0.0812\n",
      "Epoch [33/50], Step [61/735], Loss: 0.1540\n",
      "Epoch [33/50], Step [62/735], Loss: 0.3097\n",
      "Epoch [33/50], Step [63/735], Loss: 0.1033\n",
      "Epoch [33/50], Step [64/735], Loss: 0.1322\n",
      "Epoch [33/50], Step [65/735], Loss: 0.0806\n",
      "Epoch [33/50], Step [66/735], Loss: 0.0258\n",
      "Epoch [33/50], Step [67/735], Loss: 0.1189\n",
      "Epoch [33/50], Step [68/735], Loss: 0.0771\n",
      "Epoch [33/50], Step [69/735], Loss: 0.0346\n",
      "Epoch [33/50], Step [70/735], Loss: 0.1319\n",
      "Epoch [33/50], Step [71/735], Loss: 0.1109\n",
      "Epoch [33/50], Step [72/735], Loss: 0.1073\n",
      "Epoch [33/50], Step [73/735], Loss: 0.0666\n",
      "Epoch [33/50], Step [74/735], Loss: 0.8107\n",
      "Epoch [33/50], Step [75/735], Loss: 0.1196\n",
      "Epoch [33/50], Step [76/735], Loss: 0.1165\n",
      "Epoch [33/50], Step [77/735], Loss: 0.1106\n",
      "Epoch [33/50], Step [78/735], Loss: 0.0649\n",
      "Epoch [33/50], Step [79/735], Loss: 0.2825\n",
      "Epoch [33/50], Step [80/735], Loss: 0.2357\n",
      "Epoch [33/50], Step [81/735], Loss: 0.1232\n",
      "Epoch [33/50], Step [82/735], Loss: 0.6834\n",
      "Epoch [33/50], Step [83/735], Loss: 0.2439\n",
      "Epoch [33/50], Step [84/735], Loss: 0.1466\n",
      "Epoch [33/50], Step [85/735], Loss: 0.1292\n",
      "Epoch [33/50], Step [86/735], Loss: 0.2160\n",
      "Epoch [33/50], Step [87/735], Loss: 0.0520\n",
      "Epoch [33/50], Step [88/735], Loss: 0.1118\n",
      "Epoch [33/50], Step [89/735], Loss: 0.2078\n",
      "Epoch [33/50], Step [90/735], Loss: 0.2654\n",
      "Epoch [33/50], Step [91/735], Loss: 0.0548\n",
      "Epoch [33/50], Step [92/735], Loss: 0.1548\n",
      "Epoch [33/50], Step [93/735], Loss: 0.0802\n",
      "Epoch [33/50], Step [94/735], Loss: 0.0763\n",
      "Epoch [33/50], Step [95/735], Loss: 0.0828\n",
      "Epoch [33/50], Step [96/735], Loss: 0.2602\n",
      "Epoch [33/50], Step [97/735], Loss: 0.1013\n",
      "Epoch [33/50], Step [98/735], Loss: 0.0992\n",
      "Epoch [33/50], Step [99/735], Loss: 0.1057\n",
      "Epoch [33/50], Step [100/735], Loss: 0.0812\n",
      "Epoch [33/50], Step [101/735], Loss: 0.1949\n",
      "Epoch [33/50], Step [102/735], Loss: 0.4265\n",
      "Epoch [33/50], Step [103/735], Loss: 0.0994\n",
      "Epoch [33/50], Step [104/735], Loss: 0.0688\n",
      "Epoch [33/50], Step [105/735], Loss: 0.0964\n",
      "Epoch [33/50], Step [106/735], Loss: 0.1382\n",
      "Epoch [33/50], Step [107/735], Loss: 0.4702\n",
      "Epoch [33/50], Step [108/735], Loss: 0.0618\n",
      "Epoch [33/50], Step [109/735], Loss: 0.0829\n",
      "Epoch [33/50], Step [110/735], Loss: 0.0730\n",
      "Epoch [33/50], Step [111/735], Loss: 0.1000\n",
      "Epoch [33/50], Step [112/735], Loss: 0.0614\n",
      "Epoch [33/50], Step [113/735], Loss: 0.1026\n",
      "Epoch [33/50], Step [114/735], Loss: 0.0828\n",
      "Epoch [33/50], Step [115/735], Loss: 0.1166\n",
      "Epoch [33/50], Step [116/735], Loss: 0.1132\n",
      "Epoch [33/50], Step [117/735], Loss: 0.1049\n",
      "Epoch [33/50], Step [118/735], Loss: 0.3199\n",
      "Epoch [33/50], Step [119/735], Loss: 0.1631\n",
      "Epoch [33/50], Step [120/735], Loss: 0.1662\n",
      "Epoch [33/50], Step [121/735], Loss: 0.0631\n",
      "Epoch [33/50], Step [122/735], Loss: 0.0325\n",
      "Epoch [33/50], Step [123/735], Loss: 0.1874\n",
      "Epoch [33/50], Step [124/735], Loss: 0.2729\n",
      "Epoch [33/50], Step [125/735], Loss: 0.1753\n",
      "Epoch [33/50], Step [126/735], Loss: 0.1529\n",
      "Epoch [33/50], Step [127/735], Loss: 0.0909\n",
      "Epoch [33/50], Step [128/735], Loss: 0.2228\n",
      "Epoch [33/50], Step [129/735], Loss: 0.1005\n",
      "Epoch [33/50], Step [130/735], Loss: 2.0158\n",
      "Epoch [33/50], Step [131/735], Loss: 0.1341\n",
      "Epoch [33/50], Step [132/735], Loss: 0.0974\n",
      "Epoch [33/50], Step [133/735], Loss: 0.1508\n",
      "Epoch [33/50], Step [134/735], Loss: 0.0652\n",
      "Epoch [33/50], Step [135/735], Loss: 0.7078\n",
      "Epoch [33/50], Step [136/735], Loss: 0.0748\n",
      "Epoch [33/50], Step [137/735], Loss: 0.3373\n",
      "Epoch [33/50], Step [138/735], Loss: 0.1756\n",
      "Epoch [33/50], Step [139/735], Loss: 0.0879\n",
      "Epoch [33/50], Step [140/735], Loss: 0.0588\n",
      "Epoch [33/50], Step [141/735], Loss: 0.0655\n",
      "Epoch [33/50], Step [142/735], Loss: 0.0651\n",
      "Epoch [33/50], Step [143/735], Loss: 0.0859\n",
      "Epoch [33/50], Step [144/735], Loss: 0.1706\n",
      "Epoch [33/50], Step [145/735], Loss: 0.0877\n",
      "Epoch [33/50], Step [146/735], Loss: 0.0815\n",
      "Epoch [33/50], Step [147/735], Loss: 0.0996\n",
      "Epoch [33/50], Step [148/735], Loss: 0.0461\n",
      "Epoch [33/50], Step [149/735], Loss: 0.0997\n",
      "Epoch [33/50], Step [150/735], Loss: 0.2293\n",
      "Epoch [33/50], Step [151/735], Loss: 0.5269\n",
      "Epoch [33/50], Step [152/735], Loss: 0.1200\n",
      "Epoch [33/50], Step [153/735], Loss: 0.1408\n",
      "Epoch [33/50], Step [154/735], Loss: 0.0955\n",
      "Epoch [33/50], Step [155/735], Loss: 0.0955\n",
      "Epoch [33/50], Step [156/735], Loss: 0.8071\n",
      "Epoch [33/50], Step [157/735], Loss: 0.0969\n",
      "Epoch [33/50], Step [158/735], Loss: 0.0984\n",
      "Epoch [33/50], Step [159/735], Loss: 0.1532\n",
      "Epoch [33/50], Step [160/735], Loss: 0.0913\n",
      "Epoch [33/50], Step [161/735], Loss: 0.1123\n",
      "Epoch [33/50], Step [162/735], Loss: 0.1010\n",
      "Epoch [33/50], Step [163/735], Loss: 0.1339\n",
      "Epoch [33/50], Step [164/735], Loss: 0.1399\n",
      "Epoch [33/50], Step [165/735], Loss: 0.0974\n",
      "Epoch [33/50], Step [166/735], Loss: 0.0824\n",
      "Epoch [33/50], Step [167/735], Loss: 0.0799\n",
      "Epoch [33/50], Step [168/735], Loss: 0.1565\n",
      "Epoch [33/50], Step [169/735], Loss: 0.6442\n",
      "Epoch [33/50], Step [170/735], Loss: 0.0700\n",
      "Epoch [33/50], Step [171/735], Loss: 0.0755\n",
      "Epoch [33/50], Step [172/735], Loss: 0.1503\n",
      "Epoch [33/50], Step [173/735], Loss: 0.0777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Step [174/735], Loss: 0.1517\n",
      "Epoch [33/50], Step [175/735], Loss: 0.1526\n",
      "Epoch [33/50], Step [176/735], Loss: 0.2819\n",
      "Epoch [33/50], Step [177/735], Loss: 0.1176\n",
      "Epoch [33/50], Step [178/735], Loss: 0.1948\n",
      "Epoch [33/50], Step [179/735], Loss: 0.0774\n",
      "Epoch [33/50], Step [180/735], Loss: 0.0651\n",
      "Epoch [33/50], Step [181/735], Loss: 0.0957\n",
      "Epoch [33/50], Step [182/735], Loss: 0.0538\n",
      "Epoch [33/50], Step [183/735], Loss: 0.0737\n",
      "Epoch [33/50], Step [184/735], Loss: 0.1370\n",
      "Epoch [33/50], Step [185/735], Loss: 0.1005\n",
      "Epoch [33/50], Step [186/735], Loss: 0.1680\n",
      "Epoch [33/50], Step [187/735], Loss: 0.0712\n",
      "Epoch [33/50], Step [188/735], Loss: 0.0636\n",
      "Epoch [33/50], Step [189/735], Loss: 0.0514\n",
      "Epoch [33/50], Step [190/735], Loss: 0.1310\n",
      "Epoch [33/50], Step [191/735], Loss: 0.0996\n",
      "Epoch [33/50], Step [192/735], Loss: 0.0563\n",
      "Epoch [33/50], Step [193/735], Loss: 0.0865\n",
      "Epoch [33/50], Step [194/735], Loss: 0.4428\n",
      "Epoch [33/50], Step [195/735], Loss: 0.1777\n",
      "Epoch [33/50], Step [196/735], Loss: 0.1770\n",
      "Epoch [33/50], Step [197/735], Loss: 0.1054\n",
      "Epoch [33/50], Step [198/735], Loss: 0.0881\n",
      "Epoch [33/50], Step [199/735], Loss: 0.1848\n",
      "Epoch [33/50], Step [200/735], Loss: 0.1017\n",
      "Epoch [33/50], Step [201/735], Loss: 0.1034\n",
      "Epoch [33/50], Step [202/735], Loss: 0.1408\n",
      "Epoch [33/50], Step [203/735], Loss: 0.1596\n",
      "Epoch [33/50], Step [204/735], Loss: 0.1385\n",
      "Epoch [33/50], Step [205/735], Loss: 0.0656\n",
      "Epoch [33/50], Step [206/735], Loss: 0.2604\n",
      "Epoch [33/50], Step [207/735], Loss: 0.1102\n",
      "Epoch [33/50], Step [208/735], Loss: 0.0761\n",
      "Epoch [33/50], Step [209/735], Loss: 0.1069\n",
      "Epoch [33/50], Step [210/735], Loss: 0.1172\n",
      "Epoch [33/50], Step [211/735], Loss: 0.1388\n",
      "Epoch [33/50], Step [212/735], Loss: 0.1025\n",
      "Epoch [33/50], Step [213/735], Loss: 0.4944\n",
      "Epoch [33/50], Step [214/735], Loss: 0.0500\n",
      "Epoch [33/50], Step [215/735], Loss: 0.0342\n",
      "Epoch [33/50], Step [216/735], Loss: 0.1318\n",
      "Epoch [33/50], Step [217/735], Loss: 0.1383\n",
      "Epoch [33/50], Step [218/735], Loss: 0.0994\n",
      "Epoch [33/50], Step [219/735], Loss: 0.0408\n",
      "Epoch [33/50], Step [220/735], Loss: 0.0633\n",
      "Epoch [33/50], Step [221/735], Loss: 0.2721\n",
      "Epoch [33/50], Step [222/735], Loss: 0.0456\n",
      "Epoch [33/50], Step [223/735], Loss: 0.1326\n",
      "Epoch [33/50], Step [224/735], Loss: 0.1084\n",
      "Epoch [33/50], Step [225/735], Loss: 0.1379\n",
      "Epoch [33/50], Step [226/735], Loss: 0.1111\n",
      "Epoch [33/50], Step [227/735], Loss: 0.0436\n",
      "Epoch [33/50], Step [228/735], Loss: 0.0837\n",
      "Epoch [33/50], Step [229/735], Loss: 0.0586\n",
      "Epoch [33/50], Step [230/735], Loss: 0.0897\n",
      "Epoch [33/50], Step [231/735], Loss: 0.1087\n",
      "Epoch [33/50], Step [232/735], Loss: 0.2595\n",
      "Epoch [33/50], Step [233/735], Loss: 0.9646\n",
      "Epoch [33/50], Step [234/735], Loss: 0.1016\n",
      "Epoch [33/50], Step [235/735], Loss: 0.0535\n",
      "Epoch [33/50], Step [236/735], Loss: 0.1052\n",
      "Epoch [33/50], Step [237/735], Loss: 0.1295\n",
      "Epoch [33/50], Step [238/735], Loss: 0.0546\n",
      "Epoch [33/50], Step [239/735], Loss: 1.6544\n",
      "Epoch [33/50], Step [240/735], Loss: 0.0997\n",
      "Epoch [33/50], Step [241/735], Loss: 0.1311\n",
      "Epoch [33/50], Step [242/735], Loss: 0.1446\n",
      "Epoch [33/50], Step [243/735], Loss: 0.0831\n",
      "Epoch [33/50], Step [244/735], Loss: 0.4686\n",
      "Epoch [33/50], Step [245/735], Loss: 0.1259\n",
      "Epoch [33/50], Step [246/735], Loss: 0.0974\n",
      "Epoch [33/50], Step [247/735], Loss: 0.1622\n",
      "Epoch [33/50], Step [248/735], Loss: 0.6278\n",
      "Epoch [33/50], Step [249/735], Loss: 0.0670\n",
      "Epoch [33/50], Step [250/735], Loss: 0.1039\n",
      "Epoch [33/50], Step [251/735], Loss: 0.0764\n",
      "Epoch [33/50], Step [252/735], Loss: 0.0966\n",
      "Epoch [33/50], Step [253/735], Loss: 0.0827\n",
      "Epoch [33/50], Step [254/735], Loss: 0.1747\n",
      "Epoch [33/50], Step [255/735], Loss: 0.9189\n",
      "Epoch [33/50], Step [256/735], Loss: 0.0824\n",
      "Epoch [33/50], Step [257/735], Loss: 0.1615\n",
      "Epoch [33/50], Step [258/735], Loss: 0.2015\n",
      "Epoch [33/50], Step [259/735], Loss: 0.1781\n",
      "Epoch [33/50], Step [260/735], Loss: 0.1967\n",
      "Epoch [33/50], Step [261/735], Loss: 0.0682\n",
      "Epoch [33/50], Step [262/735], Loss: 0.1081\n",
      "Epoch [33/50], Step [263/735], Loss: 0.2114\n",
      "Epoch [33/50], Step [264/735], Loss: 0.0608\n",
      "Epoch [33/50], Step [265/735], Loss: 0.1362\n",
      "Epoch [33/50], Step [266/735], Loss: 0.1516\n",
      "Epoch [33/50], Step [267/735], Loss: 0.2483\n",
      "Epoch [33/50], Step [268/735], Loss: 0.5377\n",
      "Epoch [33/50], Step [269/735], Loss: 0.1045\n",
      "Epoch [33/50], Step [270/735], Loss: 0.0897\n",
      "Epoch [33/50], Step [271/735], Loss: 0.1514\n",
      "Epoch [33/50], Step [272/735], Loss: 0.1040\n",
      "Epoch [33/50], Step [273/735], Loss: 0.0951\n",
      "Epoch [33/50], Step [274/735], Loss: 0.1293\n",
      "Epoch [33/50], Step [275/735], Loss: 0.0609\n",
      "Epoch [33/50], Step [276/735], Loss: 0.1098\n",
      "Epoch [33/50], Step [277/735], Loss: 0.1303\n",
      "Epoch [33/50], Step [278/735], Loss: 0.3536\n",
      "Epoch [33/50], Step [279/735], Loss: 0.2346\n",
      "Epoch [33/50], Step [280/735], Loss: 0.0905\n",
      "Epoch [33/50], Step [281/735], Loss: 0.3420\n",
      "Epoch [33/50], Step [282/735], Loss: 0.0627\n",
      "Epoch [33/50], Step [283/735], Loss: 0.2346\n",
      "Epoch [33/50], Step [284/735], Loss: 0.0713\n",
      "Epoch [33/50], Step [285/735], Loss: 0.0638\n",
      "Epoch [33/50], Step [286/735], Loss: 0.0649\n",
      "Epoch [33/50], Step [287/735], Loss: 0.0810\n",
      "Epoch [33/50], Step [288/735], Loss: 0.0531\n",
      "Epoch [33/50], Step [289/735], Loss: 0.0973\n",
      "Epoch [33/50], Step [290/735], Loss: 0.1264\n",
      "Epoch [33/50], Step [291/735], Loss: 0.0612\n",
      "Epoch [33/50], Step [292/735], Loss: 0.3566\n",
      "Epoch [33/50], Step [293/735], Loss: 0.0880\n",
      "Epoch [33/50], Step [294/735], Loss: 0.1126\n",
      "Epoch [33/50], Step [295/735], Loss: 0.1922\n",
      "Epoch [33/50], Step [296/735], Loss: 0.1769\n",
      "Epoch [33/50], Step [297/735], Loss: 0.0527\n",
      "Epoch [33/50], Step [298/735], Loss: 0.2670\n",
      "Epoch [33/50], Step [299/735], Loss: 0.0295\n",
      "Epoch [33/50], Step [300/735], Loss: 0.0847\n",
      "Epoch [33/50], Step [301/735], Loss: 0.1254\n",
      "Epoch [33/50], Step [302/735], Loss: 0.0297\n",
      "Epoch [33/50], Step [303/735], Loss: 0.0796\n",
      "Epoch [33/50], Step [304/735], Loss: 0.0531\n",
      "Epoch [33/50], Step [305/735], Loss: 0.0890\n",
      "Epoch [33/50], Step [306/735], Loss: 0.1881\n",
      "Epoch [33/50], Step [307/735], Loss: 0.0947\n",
      "Epoch [33/50], Step [308/735], Loss: 0.1152\n",
      "Epoch [33/50], Step [309/735], Loss: 0.0654\n",
      "Epoch [33/50], Step [310/735], Loss: 0.1710\n",
      "Epoch [33/50], Step [311/735], Loss: 0.0796\n",
      "Epoch [33/50], Step [312/735], Loss: 0.0629\n",
      "Epoch [33/50], Step [313/735], Loss: 0.0920\n",
      "Epoch [33/50], Step [314/735], Loss: 0.1011\n",
      "Epoch [33/50], Step [315/735], Loss: 0.0852\n",
      "Epoch [33/50], Step [316/735], Loss: 0.0986\n",
      "Epoch [33/50], Step [317/735], Loss: 0.6221\n",
      "Epoch [33/50], Step [318/735], Loss: 0.0583\n",
      "Epoch [33/50], Step [319/735], Loss: 0.0774\n",
      "Epoch [33/50], Step [320/735], Loss: 0.4020\n",
      "Epoch [33/50], Step [321/735], Loss: 0.1271\n",
      "Epoch [33/50], Step [322/735], Loss: 0.0689\n",
      "Epoch [33/50], Step [323/735], Loss: 0.8086\n",
      "Epoch [33/50], Step [324/735], Loss: 0.3533\n",
      "Epoch [33/50], Step [325/735], Loss: 0.0594\n",
      "Epoch [33/50], Step [326/735], Loss: 0.1296\n",
      "Epoch [33/50], Step [327/735], Loss: 0.1489\n",
      "Epoch [33/50], Step [328/735], Loss: 0.0778\n",
      "Epoch [33/50], Step [329/735], Loss: 0.1835\n",
      "Epoch [33/50], Step [330/735], Loss: 0.1470\n",
      "Epoch [33/50], Step [331/735], Loss: 0.9358\n",
      "Epoch [33/50], Step [332/735], Loss: 0.0673\n",
      "Epoch [33/50], Step [333/735], Loss: 0.3406\n",
      "Epoch [33/50], Step [334/735], Loss: 0.0734\n",
      "Epoch [33/50], Step [335/735], Loss: 0.2014\n",
      "Epoch [33/50], Step [336/735], Loss: 1.1676\n",
      "Epoch [33/50], Step [337/735], Loss: 0.1062\n",
      "Epoch [33/50], Step [338/735], Loss: 0.0691\n",
      "Epoch [33/50], Step [339/735], Loss: 0.0982\n",
      "Epoch [33/50], Step [340/735], Loss: 0.0800\n",
      "Epoch [33/50], Step [341/735], Loss: 0.1050\n",
      "Epoch [33/50], Step [342/735], Loss: 0.1267\n",
      "Epoch [33/50], Step [343/735], Loss: 0.1493\n",
      "Epoch [33/50], Step [344/735], Loss: 0.0320\n",
      "Epoch [33/50], Step [345/735], Loss: 0.1216\n",
      "Epoch [33/50], Step [346/735], Loss: 0.0360\n",
      "Epoch [33/50], Step [347/735], Loss: 0.1882\n",
      "Epoch [33/50], Step [348/735], Loss: 0.0732\n",
      "Epoch [33/50], Step [349/735], Loss: 0.1682\n",
      "Epoch [33/50], Step [350/735], Loss: 0.0904\n",
      "Epoch [33/50], Step [351/735], Loss: 0.0479\n",
      "Epoch [33/50], Step [352/735], Loss: 0.0578\n",
      "Epoch [33/50], Step [353/735], Loss: 0.0845\n",
      "Epoch [33/50], Step [354/735], Loss: 0.1806\n",
      "Epoch [33/50], Step [355/735], Loss: 0.3217\n",
      "Epoch [33/50], Step [356/735], Loss: 0.5378\n",
      "Epoch [33/50], Step [357/735], Loss: 0.1303\n",
      "Epoch [33/50], Step [358/735], Loss: 0.1166\n",
      "Epoch [33/50], Step [359/735], Loss: 0.2067\n",
      "Epoch [33/50], Step [360/735], Loss: 0.0651\n",
      "Epoch [33/50], Step [361/735], Loss: 0.1163\n",
      "Epoch [33/50], Step [362/735], Loss: 0.1755\n",
      "Epoch [33/50], Step [363/735], Loss: 0.1218\n",
      "Epoch [33/50], Step [364/735], Loss: 0.1031\n",
      "Epoch [33/50], Step [365/735], Loss: 0.1567\n",
      "Epoch [33/50], Step [366/735], Loss: 0.0556\n",
      "Epoch [33/50], Step [367/735], Loss: 0.1289\n",
      "Epoch [33/50], Step [368/735], Loss: 0.1493\n",
      "Epoch [33/50], Step [369/735], Loss: 0.2508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Step [370/735], Loss: 0.1842\n",
      "Epoch [33/50], Step [371/735], Loss: 0.0443\n",
      "Epoch [33/50], Step [372/735], Loss: 0.7330\n",
      "Epoch [33/50], Step [373/735], Loss: 0.0684\n",
      "Epoch [33/50], Step [374/735], Loss: 0.1308\n",
      "Epoch [33/50], Step [375/735], Loss: 0.1025\n",
      "Epoch [33/50], Step [376/735], Loss: 0.0734\n",
      "Epoch [33/50], Step [377/735], Loss: 0.1376\n",
      "Epoch [33/50], Step [378/735], Loss: 0.0873\n",
      "Epoch [33/50], Step [379/735], Loss: 0.0469\n",
      "Epoch [33/50], Step [380/735], Loss: 0.0554\n",
      "Epoch [33/50], Step [381/735], Loss: 0.0709\n",
      "Epoch [33/50], Step [382/735], Loss: 0.3203\n",
      "Epoch [33/50], Step [383/735], Loss: 0.0458\n",
      "Epoch [33/50], Step [384/735], Loss: 0.0957\n",
      "Epoch [33/50], Step [385/735], Loss: 0.1881\n",
      "Epoch [33/50], Step [386/735], Loss: 0.1125\n",
      "Epoch [33/50], Step [387/735], Loss: 0.2012\n",
      "Epoch [33/50], Step [388/735], Loss: 0.1380\n",
      "Epoch [33/50], Step [389/735], Loss: 0.5195\n",
      "Epoch [33/50], Step [390/735], Loss: 0.0881\n",
      "Epoch [33/50], Step [391/735], Loss: 0.1638\n",
      "Epoch [33/50], Step [392/735], Loss: 0.2146\n",
      "Epoch [33/50], Step [393/735], Loss: 0.0523\n",
      "Epoch [33/50], Step [394/735], Loss: 0.1624\n",
      "Epoch [33/50], Step [395/735], Loss: 0.1163\n",
      "Epoch [33/50], Step [396/735], Loss: 0.0947\n",
      "Epoch [33/50], Step [397/735], Loss: 0.0650\n",
      "Epoch [33/50], Step [398/735], Loss: 0.2212\n",
      "Epoch [33/50], Step [399/735], Loss: 0.0864\n",
      "Epoch [33/50], Step [400/735], Loss: 0.1537\n",
      "Epoch [33/50], Step [401/735], Loss: 0.0387\n",
      "Epoch [33/50], Step [402/735], Loss: 0.0652\n",
      "Epoch [33/50], Step [403/735], Loss: 0.0737\n",
      "Epoch [33/50], Step [404/735], Loss: 0.0971\n",
      "Epoch [33/50], Step [405/735], Loss: 0.0991\n",
      "Epoch [33/50], Step [406/735], Loss: 0.0775\n",
      "Epoch [33/50], Step [407/735], Loss: 0.2381\n",
      "Epoch [33/50], Step [408/735], Loss: 0.1008\n",
      "Epoch [33/50], Step [409/735], Loss: 0.2280\n",
      "Epoch [33/50], Step [410/735], Loss: 0.0875\n",
      "Epoch [33/50], Step [411/735], Loss: 0.4553\n",
      "Epoch [33/50], Step [412/735], Loss: 0.1842\n",
      "Epoch [33/50], Step [413/735], Loss: 0.0670\n",
      "Epoch [33/50], Step [414/735], Loss: 0.0496\n",
      "Epoch [33/50], Step [415/735], Loss: 0.0791\n",
      "Epoch [33/50], Step [416/735], Loss: 0.0681\n",
      "Epoch [33/50], Step [417/735], Loss: 0.0913\n",
      "Epoch [33/50], Step [418/735], Loss: 0.2056\n",
      "Epoch [33/50], Step [419/735], Loss: 0.1749\n",
      "Epoch [33/50], Step [420/735], Loss: 0.0992\n",
      "Epoch [33/50], Step [421/735], Loss: 0.1049\n",
      "Epoch [33/50], Step [422/735], Loss: 0.0524\n",
      "Epoch [33/50], Step [423/735], Loss: 0.0659\n",
      "Epoch [33/50], Step [424/735], Loss: 0.1957\n",
      "Epoch [33/50], Step [425/735], Loss: 0.1874\n",
      "Epoch [33/50], Step [426/735], Loss: 0.0748\n",
      "Epoch [33/50], Step [427/735], Loss: 0.1328\n",
      "Epoch [33/50], Step [428/735], Loss: 0.1230\n",
      "Epoch [33/50], Step [429/735], Loss: 0.0710\n",
      "Epoch [33/50], Step [430/735], Loss: 0.1234\n",
      "Epoch [33/50], Step [431/735], Loss: 0.0648\n",
      "Epoch [33/50], Step [432/735], Loss: 0.0556\n",
      "Epoch [33/50], Step [433/735], Loss: 0.0724\n",
      "Epoch [33/50], Step [434/735], Loss: 0.0948\n",
      "Epoch [33/50], Step [435/735], Loss: 0.2369\n",
      "Epoch [33/50], Step [436/735], Loss: 0.0957\n",
      "Epoch [33/50], Step [437/735], Loss: 0.0814\n",
      "Epoch [33/50], Step [438/735], Loss: 0.3621\n",
      "Epoch [33/50], Step [439/735], Loss: 0.2888\n",
      "Epoch [33/50], Step [440/735], Loss: 0.0300\n",
      "Epoch [33/50], Step [441/735], Loss: 0.4047\n",
      "Epoch [33/50], Step [442/735], Loss: 0.0607\n",
      "Epoch [33/50], Step [443/735], Loss: 0.4186\n",
      "Epoch [33/50], Step [444/735], Loss: 0.1343\n",
      "Epoch [33/50], Step [445/735], Loss: 0.0490\n",
      "Epoch [33/50], Step [446/735], Loss: 0.0606\n",
      "Epoch [33/50], Step [447/735], Loss: 0.1101\n",
      "Epoch [33/50], Step [448/735], Loss: 0.2935\n",
      "Epoch [33/50], Step [449/735], Loss: 0.1973\n",
      "Epoch [33/50], Step [450/735], Loss: 0.1267\n",
      "Epoch [33/50], Step [451/735], Loss: 0.1613\n",
      "Epoch [33/50], Step [452/735], Loss: 0.2577\n",
      "Epoch [33/50], Step [453/735], Loss: 2.0091\n",
      "Epoch [33/50], Step [454/735], Loss: 0.0949\n",
      "Epoch [33/50], Step [455/735], Loss: 0.0948\n",
      "Epoch [33/50], Step [456/735], Loss: 0.1434\n",
      "Epoch [33/50], Step [457/735], Loss: 0.1357\n",
      "Epoch [33/50], Step [458/735], Loss: 0.0703\n",
      "Epoch [33/50], Step [459/735], Loss: 0.1884\n",
      "Epoch [33/50], Step [460/735], Loss: 0.2953\n",
      "Epoch [33/50], Step [461/735], Loss: 0.0600\n",
      "Epoch [33/50], Step [462/735], Loss: 0.2305\n",
      "Epoch [33/50], Step [463/735], Loss: 0.1261\n",
      "Epoch [33/50], Step [464/735], Loss: 0.1489\n",
      "Epoch [33/50], Step [465/735], Loss: 0.1150\n",
      "Epoch [33/50], Step [466/735], Loss: 0.1717\n",
      "Epoch [33/50], Step [467/735], Loss: 0.1273\n",
      "Epoch [33/50], Step [468/735], Loss: 0.0732\n",
      "Epoch [33/50], Step [469/735], Loss: 0.0826\n",
      "Epoch [33/50], Step [470/735], Loss: 0.0990\n",
      "Epoch [33/50], Step [471/735], Loss: 0.1150\n",
      "Epoch [33/50], Step [472/735], Loss: 0.0941\n",
      "Epoch [33/50], Step [473/735], Loss: 0.0443\n",
      "Epoch [33/50], Step [474/735], Loss: 0.0852\n",
      "Epoch [33/50], Step [475/735], Loss: 0.0416\n",
      "Epoch [33/50], Step [476/735], Loss: 0.1369\n",
      "Epoch [33/50], Step [477/735], Loss: 0.0881\n",
      "Epoch [33/50], Step [478/735], Loss: 0.1129\n",
      "Epoch [33/50], Step [479/735], Loss: 0.0564\n",
      "Epoch [33/50], Step [480/735], Loss: 0.6391\n",
      "Epoch [33/50], Step [481/735], Loss: 0.0832\n",
      "Epoch [33/50], Step [482/735], Loss: 0.1158\n",
      "Epoch [33/50], Step [483/735], Loss: 0.0908\n",
      "Epoch [33/50], Step [484/735], Loss: 0.0749\n",
      "Epoch [33/50], Step [485/735], Loss: 0.1783\n",
      "Epoch [33/50], Step [486/735], Loss: 0.9002\n",
      "Epoch [33/50], Step [487/735], Loss: 0.0567\n",
      "Epoch [33/50], Step [488/735], Loss: 0.1694\n",
      "Epoch [33/50], Step [489/735], Loss: 0.0553\n",
      "Epoch [33/50], Step [490/735], Loss: 0.0963\n",
      "Epoch [33/50], Step [491/735], Loss: 0.0422\n",
      "Epoch [33/50], Step [492/735], Loss: 0.2918\n",
      "Epoch [33/50], Step [493/735], Loss: 0.0624\n",
      "Epoch [33/50], Step [494/735], Loss: 0.0625\n",
      "Epoch [33/50], Step [495/735], Loss: 0.0853\n",
      "Epoch [33/50], Step [496/735], Loss: 0.2164\n",
      "Epoch [33/50], Step [497/735], Loss: 0.0564\n",
      "Epoch [33/50], Step [498/735], Loss: 0.8525\n",
      "Epoch [33/50], Step [499/735], Loss: 0.0767\n",
      "Epoch [33/50], Step [500/735], Loss: 0.2044\n",
      "Epoch [33/50], Step [501/735], Loss: 0.0636\n",
      "Epoch [33/50], Step [502/735], Loss: 0.1167\n",
      "Epoch [33/50], Step [503/735], Loss: 0.0803\n",
      "Epoch [33/50], Step [504/735], Loss: 0.1895\n",
      "Epoch [33/50], Step [505/735], Loss: 0.5780\n",
      "Epoch [33/50], Step [506/735], Loss: 0.1120\n",
      "Epoch [33/50], Step [507/735], Loss: 0.1025\n",
      "Epoch [33/50], Step [508/735], Loss: 0.1812\n",
      "Epoch [33/50], Step [509/735], Loss: 0.1487\n",
      "Epoch [33/50], Step [510/735], Loss: 0.2916\n",
      "Epoch [33/50], Step [511/735], Loss: 0.1285\n",
      "Epoch [33/50], Step [512/735], Loss: 0.1522\n",
      "Epoch [33/50], Step [513/735], Loss: 0.1303\n",
      "Epoch [33/50], Step [514/735], Loss: 0.1428\n",
      "Epoch [33/50], Step [515/735], Loss: 0.1112\n",
      "Epoch [33/50], Step [516/735], Loss: 0.1115\n",
      "Epoch [33/50], Step [517/735], Loss: 0.1026\n",
      "Epoch [33/50], Step [518/735], Loss: 0.1136\n",
      "Epoch [33/50], Step [519/735], Loss: 0.1515\n",
      "Epoch [33/50], Step [520/735], Loss: 0.1012\n",
      "Epoch [33/50], Step [521/735], Loss: 0.0930\n",
      "Epoch [33/50], Step [522/735], Loss: 0.1324\n",
      "Epoch [33/50], Step [523/735], Loss: 0.0636\n",
      "Epoch [33/50], Step [524/735], Loss: 0.5766\n",
      "Epoch [33/50], Step [525/735], Loss: 0.1662\n",
      "Epoch [33/50], Step [526/735], Loss: 0.1570\n",
      "Epoch [33/50], Step [527/735], Loss: 0.1505\n",
      "Epoch [33/50], Step [528/735], Loss: 0.3670\n",
      "Epoch [33/50], Step [529/735], Loss: 0.4351\n",
      "Epoch [33/50], Step [530/735], Loss: 0.9032\n",
      "Epoch [33/50], Step [531/735], Loss: 0.0806\n",
      "Epoch [33/50], Step [532/735], Loss: 0.0784\n",
      "Epoch [33/50], Step [533/735], Loss: 0.1012\n",
      "Epoch [33/50], Step [534/735], Loss: 0.1248\n",
      "Epoch [33/50], Step [535/735], Loss: 0.1235\n",
      "Epoch [33/50], Step [536/735], Loss: 0.1000\n",
      "Epoch [33/50], Step [537/735], Loss: 0.1000\n",
      "Epoch [33/50], Step [538/735], Loss: 0.0861\n",
      "Epoch [33/50], Step [539/735], Loss: 0.1252\n",
      "Epoch [33/50], Step [540/735], Loss: 0.0991\n",
      "Epoch [33/50], Step [541/735], Loss: 0.1474\n",
      "Epoch [33/50], Step [542/735], Loss: 0.0820\n",
      "Epoch [33/50], Step [543/735], Loss: 0.1058\n",
      "Epoch [33/50], Step [544/735], Loss: 0.1013\n",
      "Epoch [33/50], Step [545/735], Loss: 0.1603\n",
      "Epoch [33/50], Step [546/735], Loss: 0.1323\n",
      "Epoch [33/50], Step [547/735], Loss: 0.1678\n",
      "Epoch [33/50], Step [548/735], Loss: 0.1223\n",
      "Epoch [33/50], Step [549/735], Loss: 1.7136\n",
      "Epoch [33/50], Step [550/735], Loss: 0.1712\n",
      "Epoch [33/50], Step [551/735], Loss: 0.0507\n",
      "Epoch [33/50], Step [552/735], Loss: 0.0588\n",
      "Epoch [33/50], Step [553/735], Loss: 0.1211\n",
      "Epoch [33/50], Step [554/735], Loss: 0.1182\n",
      "Epoch [33/50], Step [555/735], Loss: 0.1105\n",
      "Epoch [33/50], Step [556/735], Loss: 0.0762\n",
      "Epoch [33/50], Step [557/735], Loss: 0.1246\n",
      "Epoch [33/50], Step [558/735], Loss: 0.1579\n",
      "Epoch [33/50], Step [559/735], Loss: 0.0845\n",
      "Epoch [33/50], Step [560/735], Loss: 0.1276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Step [561/735], Loss: 0.1066\n",
      "Epoch [33/50], Step [562/735], Loss: 0.5061\n",
      "Epoch [33/50], Step [563/735], Loss: 0.0679\n",
      "Epoch [33/50], Step [564/735], Loss: 0.0599\n",
      "Epoch [33/50], Step [565/735], Loss: 0.1282\n",
      "Epoch [33/50], Step [566/735], Loss: 0.0686\n",
      "Epoch [33/50], Step [567/735], Loss: 1.5545\n",
      "Epoch [33/50], Step [568/735], Loss: 0.0919\n",
      "Epoch [33/50], Step [569/735], Loss: 0.1417\n",
      "Epoch [33/50], Step [570/735], Loss: 0.0625\n",
      "Epoch [33/50], Step [571/735], Loss: 0.1276\n",
      "Epoch [33/50], Step [572/735], Loss: 0.0429\n",
      "Epoch [33/50], Step [573/735], Loss: 0.0767\n",
      "Epoch [33/50], Step [574/735], Loss: 0.0794\n",
      "Epoch [33/50], Step [575/735], Loss: 0.0970\n",
      "Epoch [33/50], Step [576/735], Loss: 0.0884\n",
      "Epoch [33/50], Step [577/735], Loss: 0.0829\n",
      "Epoch [33/50], Step [578/735], Loss: 0.1151\n",
      "Epoch [33/50], Step [579/735], Loss: 0.1057\n",
      "Epoch [33/50], Step [580/735], Loss: 0.0471\n",
      "Epoch [33/50], Step [581/735], Loss: 0.0460\n",
      "Epoch [33/50], Step [582/735], Loss: 0.0522\n",
      "Epoch [33/50], Step [583/735], Loss: 0.0454\n",
      "Epoch [33/50], Step [584/735], Loss: 0.1357\n",
      "Epoch [33/50], Step [585/735], Loss: 0.1033\n",
      "Epoch [33/50], Step [586/735], Loss: 0.0901\n",
      "Epoch [33/50], Step [587/735], Loss: 0.6294\n",
      "Epoch [33/50], Step [588/735], Loss: 0.0991\n",
      "Epoch [33/50], Step [589/735], Loss: 0.4704\n",
      "Epoch [33/50], Step [590/735], Loss: 0.9800\n",
      "Epoch [33/50], Step [591/735], Loss: 0.0528\n",
      "Epoch [33/50], Step [592/735], Loss: 0.1272\n",
      "Epoch [33/50], Step [593/735], Loss: 0.1241\n",
      "Epoch [33/50], Step [594/735], Loss: 0.1740\n",
      "Epoch [33/50], Step [595/735], Loss: 0.1343\n",
      "Epoch [33/50], Step [596/735], Loss: 0.0997\n",
      "Epoch [33/50], Step [597/735], Loss: 0.1275\n",
      "Epoch [33/50], Step [598/735], Loss: 0.0647\n",
      "Epoch [33/50], Step [599/735], Loss: 0.0724\n",
      "Epoch [33/50], Step [600/735], Loss: 0.2062\n",
      "Epoch [33/50], Step [601/735], Loss: 0.0965\n",
      "Epoch [33/50], Step [602/735], Loss: 0.0888\n",
      "Epoch [33/50], Step [603/735], Loss: 0.0629\n",
      "Epoch [33/50], Step [604/735], Loss: 0.0474\n",
      "Epoch [33/50], Step [605/735], Loss: 0.0538\n",
      "Epoch [33/50], Step [606/735], Loss: 0.0480\n",
      "Epoch [33/50], Step [607/735], Loss: 0.0356\n",
      "Epoch [33/50], Step [608/735], Loss: 0.1570\n",
      "Epoch [33/50], Step [609/735], Loss: 0.2324\n",
      "Epoch [33/50], Step [610/735], Loss: 0.2826\n",
      "Epoch [33/50], Step [611/735], Loss: 0.0802\n",
      "Epoch [33/50], Step [612/735], Loss: 0.0680\n",
      "Epoch [33/50], Step [613/735], Loss: 0.0883\n",
      "Epoch [33/50], Step [614/735], Loss: 0.4129\n",
      "Epoch [33/50], Step [615/735], Loss: 0.0484\n",
      "Epoch [33/50], Step [616/735], Loss: 0.1048\n",
      "Epoch [33/50], Step [617/735], Loss: 0.0767\n",
      "Epoch [33/50], Step [618/735], Loss: 0.0703\n",
      "Epoch [33/50], Step [619/735], Loss: 0.3620\n",
      "Epoch [33/50], Step [620/735], Loss: 0.0898\n",
      "Epoch [33/50], Step [621/735], Loss: 0.1226\n",
      "Epoch [33/50], Step [622/735], Loss: 0.1357\n",
      "Epoch [33/50], Step [623/735], Loss: 0.0321\n",
      "Epoch [33/50], Step [624/735], Loss: 0.1104\n",
      "Epoch [33/50], Step [625/735], Loss: 0.0786\n",
      "Epoch [33/50], Step [626/735], Loss: 0.0451\n",
      "Epoch [33/50], Step [627/735], Loss: 0.0687\n",
      "Epoch [33/50], Step [628/735], Loss: 0.1516\n",
      "Epoch [33/50], Step [629/735], Loss: 0.1311\n",
      "Epoch [33/50], Step [630/735], Loss: 0.0273\n",
      "Epoch [33/50], Step [631/735], Loss: 0.1153\n",
      "Epoch [33/50], Step [632/735], Loss: 0.1486\n",
      "Epoch [33/50], Step [633/735], Loss: 0.1002\n",
      "Epoch [33/50], Step [634/735], Loss: 0.0602\n",
      "Epoch [33/50], Step [635/735], Loss: 0.0255\n",
      "Epoch [33/50], Step [636/735], Loss: 0.0424\n",
      "Epoch [33/50], Step [637/735], Loss: 0.0701\n",
      "Epoch [33/50], Step [638/735], Loss: 0.0775\n",
      "Epoch [33/50], Step [639/735], Loss: 0.0479\n",
      "Epoch [33/50], Step [640/735], Loss: 0.0585\n",
      "Epoch [33/50], Step [641/735], Loss: 0.0336\n",
      "Epoch [33/50], Step [642/735], Loss: 0.1464\n",
      "Epoch [33/50], Step [643/735], Loss: 0.2433\n",
      "Epoch [33/50], Step [644/735], Loss: 0.0674\n",
      "Epoch [33/50], Step [645/735], Loss: 0.0638\n",
      "Epoch [33/50], Step [646/735], Loss: 0.1451\n",
      "Epoch [33/50], Step [647/735], Loss: 0.1176\n",
      "Epoch [33/50], Step [648/735], Loss: 0.1429\n",
      "Epoch [33/50], Step [649/735], Loss: 0.1320\n",
      "Epoch [33/50], Step [650/735], Loss: 0.1110\n",
      "Epoch [33/50], Step [651/735], Loss: 0.0504\n",
      "Epoch [33/50], Step [652/735], Loss: 0.1393\n",
      "Epoch [33/50], Step [653/735], Loss: 0.0357\n",
      "Epoch [33/50], Step [654/735], Loss: 0.0579\n",
      "Epoch [33/50], Step [655/735], Loss: 0.1342\n",
      "Epoch [33/50], Step [656/735], Loss: 0.0562\n",
      "Epoch [33/50], Step [657/735], Loss: 0.0767\n",
      "Epoch [33/50], Step [658/735], Loss: 1.6128\n",
      "Epoch [33/50], Step [659/735], Loss: 0.1862\n",
      "Epoch [33/50], Step [660/735], Loss: 0.0418\n",
      "Epoch [33/50], Step [661/735], Loss: 0.1089\n",
      "Epoch [33/50], Step [662/735], Loss: 0.2297\n",
      "Epoch [33/50], Step [663/735], Loss: 0.1219\n",
      "Epoch [33/50], Step [664/735], Loss: 0.1159\n",
      "Epoch [33/50], Step [665/735], Loss: 0.1729\n",
      "Epoch [33/50], Step [666/735], Loss: 0.2097\n",
      "Epoch [33/50], Step [667/735], Loss: 0.0353\n",
      "Epoch [33/50], Step [668/735], Loss: 0.1358\n",
      "Epoch [33/50], Step [669/735], Loss: 0.2171\n",
      "Epoch [33/50], Step [670/735], Loss: 0.1293\n",
      "Epoch [33/50], Step [671/735], Loss: 0.1557\n",
      "Epoch [33/50], Step [672/735], Loss: 0.1165\n",
      "Epoch [33/50], Step [673/735], Loss: 0.2200\n",
      "Epoch [33/50], Step [674/735], Loss: 0.1095\n",
      "Epoch [33/50], Step [675/735], Loss: 0.0981\n",
      "Epoch [33/50], Step [676/735], Loss: 0.0548\n",
      "Epoch [33/50], Step [677/735], Loss: 0.0964\n",
      "Epoch [33/50], Step [678/735], Loss: 0.0915\n",
      "Epoch [33/50], Step [679/735], Loss: 0.1275\n",
      "Epoch [33/50], Step [680/735], Loss: 0.2327\n",
      "Epoch [33/50], Step [681/735], Loss: 0.0682\n",
      "Epoch [33/50], Step [682/735], Loss: 0.1385\n",
      "Epoch [33/50], Step [683/735], Loss: 0.1089\n",
      "Epoch [33/50], Step [684/735], Loss: 0.0436\n",
      "Epoch [33/50], Step [685/735], Loss: 0.1243\n",
      "Epoch [33/50], Step [686/735], Loss: 0.0732\n",
      "Epoch [33/50], Step [687/735], Loss: 0.2516\n",
      "Epoch [33/50], Step [688/735], Loss: 0.0623\n",
      "Epoch [33/50], Step [689/735], Loss: 0.3793\n",
      "Epoch [33/50], Step [690/735], Loss: 0.0872\n",
      "Epoch [33/50], Step [691/735], Loss: 0.2768\n",
      "Epoch [33/50], Step [692/735], Loss: 0.1527\n",
      "Epoch [33/50], Step [693/735], Loss: 0.0404\n",
      "Epoch [33/50], Step [694/735], Loss: 0.1086\n",
      "Epoch [33/50], Step [695/735], Loss: 0.1276\n",
      "Epoch [33/50], Step [696/735], Loss: 0.1346\n",
      "Epoch [33/50], Step [697/735], Loss: 0.0888\n",
      "Epoch [33/50], Step [698/735], Loss: 0.1754\n",
      "Epoch [33/50], Step [699/735], Loss: 0.1033\n",
      "Epoch [33/50], Step [700/735], Loss: 0.0989\n",
      "Epoch [33/50], Step [701/735], Loss: 0.1850\n",
      "Epoch [33/50], Step [702/735], Loss: 0.1584\n",
      "Epoch [33/50], Step [703/735], Loss: 0.1966\n",
      "Epoch [33/50], Step [704/735], Loss: 0.1621\n",
      "Epoch [33/50], Step [705/735], Loss: 0.1048\n",
      "Epoch [33/50], Step [706/735], Loss: 0.1013\n",
      "Epoch [33/50], Step [707/735], Loss: 0.0992\n",
      "Epoch [33/50], Step [708/735], Loss: 0.0539\n",
      "Epoch [33/50], Step [709/735], Loss: 0.1708\n",
      "Epoch [33/50], Step [710/735], Loss: 0.1525\n",
      "Epoch [33/50], Step [711/735], Loss: 0.1738\n",
      "Epoch [33/50], Step [712/735], Loss: 0.2452\n",
      "Epoch [33/50], Step [713/735], Loss: 0.1486\n",
      "Epoch [33/50], Step [714/735], Loss: 0.5123\n",
      "Epoch [33/50], Step [715/735], Loss: 0.0690\n",
      "Epoch [33/50], Step [716/735], Loss: 0.1759\n",
      "Epoch [33/50], Step [717/735], Loss: 0.3583\n",
      "Epoch [33/50], Step [718/735], Loss: 0.0748\n",
      "Epoch [33/50], Step [719/735], Loss: 0.0873\n",
      "Epoch [33/50], Step [720/735], Loss: 0.1526\n",
      "Epoch [33/50], Step [721/735], Loss: 0.0551\n",
      "Epoch [33/50], Step [722/735], Loss: 0.0619\n",
      "Epoch [33/50], Step [723/735], Loss: 0.1240\n",
      "Epoch [33/50], Step [724/735], Loss: 0.1266\n",
      "Epoch [33/50], Step [725/735], Loss: 0.1089\n",
      "Epoch [33/50], Step [726/735], Loss: 0.1631\n",
      "Epoch [33/50], Step [727/735], Loss: 0.1457\n",
      "Epoch [33/50], Step [728/735], Loss: 0.0770\n",
      "Epoch [33/50], Step [729/735], Loss: 0.0563\n",
      "Epoch [33/50], Step [730/735], Loss: 0.0622\n",
      "Epoch [33/50], Step [731/735], Loss: 0.0944\n",
      "Epoch [33/50], Step [732/735], Loss: 0.0948\n",
      "Epoch [33/50], Step [733/735], Loss: 0.0688\n",
      "Epoch [33/50], Step [734/735], Loss: 0.0798\n",
      "Epoch [33/50], Step [735/735], Loss: 0.0347\n",
      "Epoch [34/50], Step [1/735], Loss: 0.1351\n",
      "Epoch [34/50], Step [2/735], Loss: 0.2425\n",
      "Epoch [34/50], Step [3/735], Loss: 0.0616\n",
      "Epoch [34/50], Step [4/735], Loss: 0.1173\n",
      "Epoch [34/50], Step [5/735], Loss: 0.0494\n",
      "Epoch [34/50], Step [6/735], Loss: 0.1209\n",
      "Epoch [34/50], Step [7/735], Loss: 0.0497\n",
      "Epoch [34/50], Step [8/735], Loss: 0.1574\n",
      "Epoch [34/50], Step [9/735], Loss: 0.1375\n",
      "Epoch [34/50], Step [10/735], Loss: 0.1869\n",
      "Epoch [34/50], Step [11/735], Loss: 0.1009\n",
      "Epoch [34/50], Step [12/735], Loss: 0.1296\n",
      "Epoch [34/50], Step [13/735], Loss: 0.0789\n",
      "Epoch [34/50], Step [14/735], Loss: 0.1755\n",
      "Epoch [34/50], Step [15/735], Loss: 0.1351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Step [16/735], Loss: 0.1147\n",
      "Epoch [34/50], Step [17/735], Loss: 0.2638\n",
      "Epoch [34/50], Step [18/735], Loss: 0.0923\n",
      "Epoch [34/50], Step [19/735], Loss: 0.1466\n",
      "Epoch [34/50], Step [20/735], Loss: 0.1537\n",
      "Epoch [34/50], Step [21/735], Loss: 0.1472\n",
      "Epoch [34/50], Step [22/735], Loss: 0.2971\n",
      "Epoch [34/50], Step [23/735], Loss: 0.1567\n",
      "Epoch [34/50], Step [24/735], Loss: 0.0779\n",
      "Epoch [34/50], Step [25/735], Loss: 0.0723\n",
      "Epoch [34/50], Step [26/735], Loss: 0.0643\n",
      "Epoch [34/50], Step [27/735], Loss: 0.0742\n",
      "Epoch [34/50], Step [28/735], Loss: 0.0818\n",
      "Epoch [34/50], Step [29/735], Loss: 0.1095\n",
      "Epoch [34/50], Step [30/735], Loss: 0.2459\n",
      "Epoch [34/50], Step [31/735], Loss: 0.2004\n",
      "Epoch [34/50], Step [32/735], Loss: 0.1042\n",
      "Epoch [34/50], Step [33/735], Loss: 0.0677\n",
      "Epoch [34/50], Step [34/735], Loss: 2.1447\n",
      "Epoch [34/50], Step [35/735], Loss: 0.1258\n",
      "Epoch [34/50], Step [36/735], Loss: 0.0518\n",
      "Epoch [34/50], Step [37/735], Loss: 0.5236\n",
      "Epoch [34/50], Step [38/735], Loss: 0.0564\n",
      "Epoch [34/50], Step [39/735], Loss: 0.1127\n",
      "Epoch [34/50], Step [40/735], Loss: 0.0769\n",
      "Epoch [34/50], Step [41/735], Loss: 0.1388\n",
      "Epoch [34/50], Step [42/735], Loss: 0.1035\n",
      "Epoch [34/50], Step [43/735], Loss: 0.0888\n",
      "Epoch [34/50], Step [44/735], Loss: 0.0810\n",
      "Epoch [34/50], Step [45/735], Loss: 0.0704\n",
      "Epoch [34/50], Step [46/735], Loss: 0.0507\n",
      "Epoch [34/50], Step [47/735], Loss: 0.1022\n",
      "Epoch [34/50], Step [48/735], Loss: 0.2038\n",
      "Epoch [34/50], Step [49/735], Loss: 0.0562\n",
      "Epoch [34/50], Step [50/735], Loss: 0.0971\n",
      "Epoch [34/50], Step [51/735], Loss: 0.1253\n",
      "Epoch [34/50], Step [52/735], Loss: 0.0851\n",
      "Epoch [34/50], Step [53/735], Loss: 0.0918\n",
      "Epoch [34/50], Step [54/735], Loss: 0.8393\n",
      "Epoch [34/50], Step [55/735], Loss: 0.0721\n",
      "Epoch [34/50], Step [56/735], Loss: 0.0808\n",
      "Epoch [34/50], Step [57/735], Loss: 0.0852\n",
      "Epoch [34/50], Step [58/735], Loss: 0.1112\n",
      "Epoch [34/50], Step [59/735], Loss: 0.0812\n",
      "Epoch [34/50], Step [60/735], Loss: 0.2113\n",
      "Epoch [34/50], Step [61/735], Loss: 0.1219\n",
      "Epoch [34/50], Step [62/735], Loss: 0.1145\n",
      "Epoch [34/50], Step [63/735], Loss: 0.1559\n",
      "Epoch [34/50], Step [64/735], Loss: 0.1265\n",
      "Epoch [34/50], Step [65/735], Loss: 1.2048\n",
      "Epoch [34/50], Step [66/735], Loss: 0.0675\n",
      "Epoch [34/50], Step [67/735], Loss: 0.0831\n",
      "Epoch [34/50], Step [68/735], Loss: 0.1050\n",
      "Epoch [34/50], Step [69/735], Loss: 0.1725\n",
      "Epoch [34/50], Step [70/735], Loss: 0.0678\n",
      "Epoch [34/50], Step [71/735], Loss: 0.0624\n",
      "Epoch [34/50], Step [72/735], Loss: 0.5622\n",
      "Epoch [34/50], Step [73/735], Loss: 0.0691\n",
      "Epoch [34/50], Step [74/735], Loss: 0.1497\n",
      "Epoch [34/50], Step [75/735], Loss: 0.0747\n",
      "Epoch [34/50], Step [76/735], Loss: 0.1415\n",
      "Epoch [34/50], Step [77/735], Loss: 0.1202\n",
      "Epoch [34/50], Step [78/735], Loss: 0.0981\n",
      "Epoch [34/50], Step [79/735], Loss: 0.1033\n",
      "Epoch [34/50], Step [80/735], Loss: 0.1265\n",
      "Epoch [34/50], Step [81/735], Loss: 0.1619\n",
      "Epoch [34/50], Step [82/735], Loss: 0.0668\n",
      "Epoch [34/50], Step [83/735], Loss: 0.1047\n",
      "Epoch [34/50], Step [84/735], Loss: 0.0546\n",
      "Epoch [34/50], Step [85/735], Loss: 0.1143\n",
      "Epoch [34/50], Step [86/735], Loss: 0.1676\n",
      "Epoch [34/50], Step [87/735], Loss: 0.2047\n",
      "Epoch [34/50], Step [88/735], Loss: 0.1372\n",
      "Epoch [34/50], Step [89/735], Loss: 0.1640\n",
      "Epoch [34/50], Step [90/735], Loss: 0.0400\n",
      "Epoch [34/50], Step [91/735], Loss: 0.1468\n",
      "Epoch [34/50], Step [92/735], Loss: 0.0794\n",
      "Epoch [34/50], Step [93/735], Loss: 0.0461\n",
      "Epoch [34/50], Step [94/735], Loss: 0.0771\n",
      "Epoch [34/50], Step [95/735], Loss: 0.0868\n",
      "Epoch [34/50], Step [96/735], Loss: 0.0630\n",
      "Epoch [34/50], Step [97/735], Loss: 0.1401\n",
      "Epoch [34/50], Step [98/735], Loss: 0.1279\n",
      "Epoch [34/50], Step [99/735], Loss: 0.0817\n",
      "Epoch [34/50], Step [100/735], Loss: 0.0683\n",
      "Epoch [34/50], Step [101/735], Loss: 0.1864\n",
      "Epoch [34/50], Step [102/735], Loss: 0.1412\n",
      "Epoch [34/50], Step [103/735], Loss: 0.0925\n",
      "Epoch [34/50], Step [104/735], Loss: 0.1050\n",
      "Epoch [34/50], Step [105/735], Loss: 0.0761\n",
      "Epoch [34/50], Step [106/735], Loss: 0.1063\n",
      "Epoch [34/50], Step [107/735], Loss: 0.0380\n",
      "Epoch [34/50], Step [108/735], Loss: 0.0651\n",
      "Epoch [34/50], Step [109/735], Loss: 0.1050\n",
      "Epoch [34/50], Step [110/735], Loss: 0.1200\n",
      "Epoch [34/50], Step [111/735], Loss: 0.0631\n",
      "Epoch [34/50], Step [112/735], Loss: 0.0974\n",
      "Epoch [34/50], Step [113/735], Loss: 0.0477\n",
      "Epoch [34/50], Step [114/735], Loss: 0.0751\n",
      "Epoch [34/50], Step [115/735], Loss: 0.0435\n",
      "Epoch [34/50], Step [116/735], Loss: 0.3074\n",
      "Epoch [34/50], Step [117/735], Loss: 0.2273\n",
      "Epoch [34/50], Step [118/735], Loss: 0.2421\n",
      "Epoch [34/50], Step [119/735], Loss: 0.1363\n",
      "Epoch [34/50], Step [120/735], Loss: 0.0675\n",
      "Epoch [34/50], Step [121/735], Loss: 0.1131\n",
      "Epoch [34/50], Step [122/735], Loss: 0.3724\n",
      "Epoch [34/50], Step [123/735], Loss: 0.1929\n",
      "Epoch [34/50], Step [124/735], Loss: 0.1865\n",
      "Epoch [34/50], Step [125/735], Loss: 0.8155\n",
      "Epoch [34/50], Step [126/735], Loss: 0.1636\n",
      "Epoch [34/50], Step [127/735], Loss: 0.1454\n",
      "Epoch [34/50], Step [128/735], Loss: 0.1178\n",
      "Epoch [34/50], Step [129/735], Loss: 0.1694\n",
      "Epoch [34/50], Step [130/735], Loss: 0.1403\n",
      "Epoch [34/50], Step [131/735], Loss: 0.1236\n",
      "Epoch [34/50], Step [132/735], Loss: 0.1752\n",
      "Epoch [34/50], Step [133/735], Loss: 0.1610\n",
      "Epoch [34/50], Step [134/735], Loss: 0.0737\n",
      "Epoch [34/50], Step [135/735], Loss: 0.2050\n",
      "Epoch [34/50], Step [136/735], Loss: 0.0919\n",
      "Epoch [34/50], Step [137/735], Loss: 0.1227\n",
      "Epoch [34/50], Step [138/735], Loss: 0.1489\n",
      "Epoch [34/50], Step [139/735], Loss: 0.1532\n",
      "Epoch [34/50], Step [140/735], Loss: 0.0518\n",
      "Epoch [34/50], Step [141/735], Loss: 0.1023\n",
      "Epoch [34/50], Step [142/735], Loss: 0.1491\n",
      "Epoch [34/50], Step [143/735], Loss: 0.1015\n",
      "Epoch [34/50], Step [144/735], Loss: 0.0901\n",
      "Epoch [34/50], Step [145/735], Loss: 0.1097\n",
      "Epoch [34/50], Step [146/735], Loss: 0.1908\n",
      "Epoch [34/50], Step [147/735], Loss: 0.1060\n",
      "Epoch [34/50], Step [148/735], Loss: 0.1269\n",
      "Epoch [34/50], Step [149/735], Loss: 0.1214\n",
      "Epoch [34/50], Step [150/735], Loss: 0.0564\n",
      "Epoch [34/50], Step [151/735], Loss: 0.7013\n",
      "Epoch [34/50], Step [152/735], Loss: 0.1110\n",
      "Epoch [34/50], Step [153/735], Loss: 0.1370\n",
      "Epoch [34/50], Step [154/735], Loss: 0.6549\n",
      "Epoch [34/50], Step [155/735], Loss: 0.4714\n",
      "Epoch [34/50], Step [156/735], Loss: 0.1081\n",
      "Epoch [34/50], Step [157/735], Loss: 0.0931\n",
      "Epoch [34/50], Step [158/735], Loss: 0.0781\n",
      "Epoch [34/50], Step [159/735], Loss: 0.2523\n",
      "Epoch [34/50], Step [160/735], Loss: 0.0684\n",
      "Epoch [34/50], Step [161/735], Loss: 0.4482\n",
      "Epoch [34/50], Step [162/735], Loss: 0.1268\n",
      "Epoch [34/50], Step [163/735], Loss: 0.1371\n",
      "Epoch [34/50], Step [164/735], Loss: 0.1252\n",
      "Epoch [34/50], Step [165/735], Loss: 0.1122\n",
      "Epoch [34/50], Step [166/735], Loss: 0.4210\n",
      "Epoch [34/50], Step [167/735], Loss: 0.0914\n",
      "Epoch [34/50], Step [168/735], Loss: 0.0973\n",
      "Epoch [34/50], Step [169/735], Loss: 0.2343\n",
      "Epoch [34/50], Step [170/735], Loss: 0.1315\n",
      "Epoch [34/50], Step [171/735], Loss: 0.2044\n",
      "Epoch [34/50], Step [172/735], Loss: 0.2217\n",
      "Epoch [34/50], Step [173/735], Loss: 0.1030\n",
      "Epoch [34/50], Step [174/735], Loss: 0.1361\n",
      "Epoch [34/50], Step [175/735], Loss: 0.0756\n",
      "Epoch [34/50], Step [176/735], Loss: 0.0924\n",
      "Epoch [34/50], Step [177/735], Loss: 1.8021\n",
      "Epoch [34/50], Step [178/735], Loss: 0.1789\n",
      "Epoch [34/50], Step [179/735], Loss: 0.3091\n",
      "Epoch [34/50], Step [180/735], Loss: 0.5850\n",
      "Epoch [34/50], Step [181/735], Loss: 0.1029\n",
      "Epoch [34/50], Step [182/735], Loss: 0.1211\n",
      "Epoch [34/50], Step [183/735], Loss: 0.1301\n",
      "Epoch [34/50], Step [184/735], Loss: 0.1444\n",
      "Epoch [34/50], Step [185/735], Loss: 0.0652\n",
      "Epoch [34/50], Step [186/735], Loss: 0.0716\n",
      "Epoch [34/50], Step [187/735], Loss: 0.1642\n",
      "Epoch [34/50], Step [188/735], Loss: 0.1112\n",
      "Epoch [34/50], Step [189/735], Loss: 0.0829\n",
      "Epoch [34/50], Step [190/735], Loss: 0.0708\n",
      "Epoch [34/50], Step [191/735], Loss: 0.1253\n",
      "Epoch [34/50], Step [192/735], Loss: 0.0712\n",
      "Epoch [34/50], Step [193/735], Loss: 0.3852\n",
      "Epoch [34/50], Step [194/735], Loss: 0.0436\n",
      "Epoch [34/50], Step [195/735], Loss: 0.1600\n",
      "Epoch [34/50], Step [196/735], Loss: 0.1738\n",
      "Epoch [34/50], Step [197/735], Loss: 0.1767\n",
      "Epoch [34/50], Step [198/735], Loss: 0.1452\n",
      "Epoch [34/50], Step [199/735], Loss: 0.0998\n",
      "Epoch [34/50], Step [200/735], Loss: 0.0574\n",
      "Epoch [34/50], Step [201/735], Loss: 0.1377\n",
      "Epoch [34/50], Step [202/735], Loss: 0.0881\n",
      "Epoch [34/50], Step [203/735], Loss: 0.1443\n",
      "Epoch [34/50], Step [204/735], Loss: 2.1436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Step [205/735], Loss: 0.0738\n",
      "Epoch [34/50], Step [206/735], Loss: 0.1473\n",
      "Epoch [34/50], Step [207/735], Loss: 0.0792\n",
      "Epoch [34/50], Step [208/735], Loss: 0.1496\n",
      "Epoch [34/50], Step [209/735], Loss: 0.1203\n",
      "Epoch [34/50], Step [210/735], Loss: 0.2255\n",
      "Epoch [34/50], Step [211/735], Loss: 0.4420\n",
      "Epoch [34/50], Step [212/735], Loss: 0.1103\n",
      "Epoch [34/50], Step [213/735], Loss: 0.1583\n",
      "Epoch [34/50], Step [214/735], Loss: 0.1197\n",
      "Epoch [34/50], Step [215/735], Loss: 0.0427\n",
      "Epoch [34/50], Step [216/735], Loss: 0.1200\n",
      "Epoch [34/50], Step [217/735], Loss: 0.1785\n",
      "Epoch [34/50], Step [218/735], Loss: 0.2066\n",
      "Epoch [34/50], Step [219/735], Loss: 0.3775\n",
      "Epoch [34/50], Step [220/735], Loss: 0.0726\n",
      "Epoch [34/50], Step [221/735], Loss: 0.1283\n",
      "Epoch [34/50], Step [222/735], Loss: 0.0668\n",
      "Epoch [34/50], Step [223/735], Loss: 0.0821\n",
      "Epoch [34/50], Step [224/735], Loss: 0.5498\n",
      "Epoch [34/50], Step [225/735], Loss: 0.1206\n",
      "Epoch [34/50], Step [226/735], Loss: 0.0630\n",
      "Epoch [34/50], Step [227/735], Loss: 0.1944\n",
      "Epoch [34/50], Step [228/735], Loss: 0.0695\n",
      "Epoch [34/50], Step [229/735], Loss: 0.3079\n",
      "Epoch [34/50], Step [230/735], Loss: 0.0991\n",
      "Epoch [34/50], Step [231/735], Loss: 0.0807\n",
      "Epoch [34/50], Step [232/735], Loss: 0.0859\n",
      "Epoch [34/50], Step [233/735], Loss: 0.2219\n",
      "Epoch [34/50], Step [234/735], Loss: 0.0860\n",
      "Epoch [34/50], Step [235/735], Loss: 0.2272\n",
      "Epoch [34/50], Step [236/735], Loss: 0.1138\n",
      "Epoch [34/50], Step [237/735], Loss: 0.0880\n",
      "Epoch [34/50], Step [238/735], Loss: 0.0539\n",
      "Epoch [34/50], Step [239/735], Loss: 0.0586\n",
      "Epoch [34/50], Step [240/735], Loss: 0.1310\n",
      "Epoch [34/50], Step [241/735], Loss: 0.0642\n",
      "Epoch [34/50], Step [242/735], Loss: 0.1002\n",
      "Epoch [34/50], Step [243/735], Loss: 0.0634\n",
      "Epoch [34/50], Step [244/735], Loss: 0.1996\n",
      "Epoch [34/50], Step [245/735], Loss: 0.1185\n",
      "Epoch [34/50], Step [246/735], Loss: 0.1670\n",
      "Epoch [34/50], Step [247/735], Loss: 0.1323\n",
      "Epoch [34/50], Step [248/735], Loss: 0.0275\n",
      "Epoch [34/50], Step [249/735], Loss: 0.1505\n",
      "Epoch [34/50], Step [250/735], Loss: 0.1404\n",
      "Epoch [34/50], Step [251/735], Loss: 0.0809\n",
      "Epoch [34/50], Step [252/735], Loss: 0.0858\n",
      "Epoch [34/50], Step [253/735], Loss: 0.1018\n",
      "Epoch [34/50], Step [254/735], Loss: 0.1161\n",
      "Epoch [34/50], Step [255/735], Loss: 0.0851\n",
      "Epoch [34/50], Step [256/735], Loss: 0.1869\n",
      "Epoch [34/50], Step [257/735], Loss: 0.4380\n",
      "Epoch [34/50], Step [258/735], Loss: 0.3892\n",
      "Epoch [34/50], Step [259/735], Loss: 0.1098\n",
      "Epoch [34/50], Step [260/735], Loss: 0.0904\n",
      "Epoch [34/50], Step [261/735], Loss: 0.0914\n",
      "Epoch [34/50], Step [262/735], Loss: 0.1181\n",
      "Epoch [34/50], Step [263/735], Loss: 0.0467\n",
      "Epoch [34/50], Step [264/735], Loss: 0.1129\n",
      "Epoch [34/50], Step [265/735], Loss: 0.1085\n",
      "Epoch [34/50], Step [266/735], Loss: 0.0825\n",
      "Epoch [34/50], Step [267/735], Loss: 0.0684\n",
      "Epoch [34/50], Step [268/735], Loss: 0.1316\n",
      "Epoch [34/50], Step [269/735], Loss: 0.0600\n",
      "Epoch [34/50], Step [270/735], Loss: 0.1509\n",
      "Epoch [34/50], Step [271/735], Loss: 0.0662\n",
      "Epoch [34/50], Step [272/735], Loss: 0.1039\n",
      "Epoch [34/50], Step [273/735], Loss: 0.0792\n",
      "Epoch [34/50], Step [274/735], Loss: 0.0521\n",
      "Epoch [34/50], Step [275/735], Loss: 0.0964\n",
      "Epoch [34/50], Step [276/735], Loss: 1.9526\n",
      "Epoch [34/50], Step [277/735], Loss: 0.0642\n",
      "Epoch [34/50], Step [278/735], Loss: 0.1159\n",
      "Epoch [34/50], Step [279/735], Loss: 0.0903\n",
      "Epoch [34/50], Step [280/735], Loss: 0.0898\n",
      "Epoch [34/50], Step [281/735], Loss: 0.1112\n",
      "Epoch [34/50], Step [282/735], Loss: 0.1277\n",
      "Epoch [34/50], Step [283/735], Loss: 0.1040\n",
      "Epoch [34/50], Step [284/735], Loss: 0.0944\n",
      "Epoch [34/50], Step [285/735], Loss: 0.2007\n",
      "Epoch [34/50], Step [286/735], Loss: 0.2813\n",
      "Epoch [34/50], Step [287/735], Loss: 0.0582\n",
      "Epoch [34/50], Step [288/735], Loss: 0.0755\n",
      "Epoch [34/50], Step [289/735], Loss: 0.1233\n",
      "Epoch [34/50], Step [290/735], Loss: 0.2096\n",
      "Epoch [34/50], Step [291/735], Loss: 0.0749\n",
      "Epoch [34/50], Step [292/735], Loss: 0.2360\n",
      "Epoch [34/50], Step [293/735], Loss: 0.0455\n",
      "Epoch [34/50], Step [294/735], Loss: 0.1109\n",
      "Epoch [34/50], Step [295/735], Loss: 0.0429\n",
      "Epoch [34/50], Step [296/735], Loss: 0.3784\n",
      "Epoch [34/50], Step [297/735], Loss: 0.0830\n",
      "Epoch [34/50], Step [298/735], Loss: 0.0971\n",
      "Epoch [34/50], Step [299/735], Loss: 0.1587\n",
      "Epoch [34/50], Step [300/735], Loss: 0.1074\n",
      "Epoch [34/50], Step [301/735], Loss: 0.0810\n",
      "Epoch [34/50], Step [302/735], Loss: 0.5095\n",
      "Epoch [34/50], Step [303/735], Loss: 0.0675\n",
      "Epoch [34/50], Step [304/735], Loss: 0.1420\n",
      "Epoch [34/50], Step [305/735], Loss: 0.9813\n",
      "Epoch [34/50], Step [306/735], Loss: 0.1250\n",
      "Epoch [34/50], Step [307/735], Loss: 0.2443\n",
      "Epoch [34/50], Step [308/735], Loss: 0.5297\n",
      "Epoch [34/50], Step [309/735], Loss: 0.1281\n",
      "Epoch [34/50], Step [310/735], Loss: 0.4485\n",
      "Epoch [34/50], Step [311/735], Loss: 0.1223\n",
      "Epoch [34/50], Step [312/735], Loss: 0.1273\n",
      "Epoch [34/50], Step [313/735], Loss: 0.2950\n",
      "Epoch [34/50], Step [314/735], Loss: 0.0955\n",
      "Epoch [34/50], Step [315/735], Loss: 0.2275\n",
      "Epoch [34/50], Step [316/735], Loss: 0.0332\n",
      "Epoch [34/50], Step [317/735], Loss: 0.1653\n",
      "Epoch [34/50], Step [318/735], Loss: 0.0877\n",
      "Epoch [34/50], Step [319/735], Loss: 0.4029\n",
      "Epoch [34/50], Step [320/735], Loss: 0.0946\n",
      "Epoch [34/50], Step [321/735], Loss: 0.1104\n",
      "Epoch [34/50], Step [322/735], Loss: 0.0506\n",
      "Epoch [34/50], Step [323/735], Loss: 0.1594\n",
      "Epoch [34/50], Step [324/735], Loss: 0.1928\n",
      "Epoch [34/50], Step [325/735], Loss: 0.0709\n",
      "Epoch [34/50], Step [326/735], Loss: 0.0412\n",
      "Epoch [34/50], Step [327/735], Loss: 0.2684\n",
      "Epoch [34/50], Step [328/735], Loss: 0.0665\n",
      "Epoch [34/50], Step [329/735], Loss: 0.0442\n",
      "Epoch [34/50], Step [330/735], Loss: 0.0684\n",
      "Epoch [34/50], Step [331/735], Loss: 0.0327\n",
      "Epoch [34/50], Step [332/735], Loss: 0.0987\n",
      "Epoch [34/50], Step [333/735], Loss: 0.2112\n",
      "Epoch [34/50], Step [334/735], Loss: 0.2873\n",
      "Epoch [34/50], Step [335/735], Loss: 0.1219\n",
      "Epoch [34/50], Step [336/735], Loss: 0.0742\n",
      "Epoch [34/50], Step [337/735], Loss: 0.0820\n",
      "Epoch [34/50], Step [338/735], Loss: 0.1316\n",
      "Epoch [34/50], Step [339/735], Loss: 0.1888\n",
      "Epoch [34/50], Step [340/735], Loss: 0.1154\n",
      "Epoch [34/50], Step [341/735], Loss: 0.0725\n",
      "Epoch [34/50], Step [342/735], Loss: 0.0395\n",
      "Epoch [34/50], Step [343/735], Loss: 0.0887\n",
      "Epoch [34/50], Step [344/735], Loss: 0.0990\n",
      "Epoch [34/50], Step [345/735], Loss: 0.1812\n",
      "Epoch [34/50], Step [346/735], Loss: 0.1211\n",
      "Epoch [34/50], Step [347/735], Loss: 0.1868\n",
      "Epoch [34/50], Step [348/735], Loss: 0.0775\n",
      "Epoch [34/50], Step [349/735], Loss: 0.0403\n",
      "Epoch [34/50], Step [350/735], Loss: 0.0492\n",
      "Epoch [34/50], Step [351/735], Loss: 0.0723\n",
      "Epoch [34/50], Step [352/735], Loss: 0.0382\n",
      "Epoch [34/50], Step [353/735], Loss: 0.0438\n",
      "Epoch [34/50], Step [354/735], Loss: 0.0807\n",
      "Epoch [34/50], Step [355/735], Loss: 0.0803\n",
      "Epoch [34/50], Step [356/735], Loss: 0.0788\n",
      "Epoch [34/50], Step [357/735], Loss: 0.0497\n",
      "Epoch [34/50], Step [358/735], Loss: 0.0535\n",
      "Epoch [34/50], Step [359/735], Loss: 0.0815\n",
      "Epoch [34/50], Step [360/735], Loss: 0.1000\n",
      "Epoch [34/50], Step [361/735], Loss: 0.0839\n",
      "Epoch [34/50], Step [362/735], Loss: 0.8393\n",
      "Epoch [34/50], Step [363/735], Loss: 0.0319\n",
      "Epoch [34/50], Step [364/735], Loss: 0.1470\n",
      "Epoch [34/50], Step [365/735], Loss: 0.1896\n",
      "Epoch [34/50], Step [366/735], Loss: 0.0946\n",
      "Epoch [34/50], Step [367/735], Loss: 0.1017\n",
      "Epoch [34/50], Step [368/735], Loss: 0.0368\n",
      "Epoch [34/50], Step [369/735], Loss: 0.0533\n",
      "Epoch [34/50], Step [370/735], Loss: 0.0392\n",
      "Epoch [34/50], Step [371/735], Loss: 0.0978\n",
      "Epoch [34/50], Step [372/735], Loss: 0.0742\n",
      "Epoch [34/50], Step [373/735], Loss: 0.0284\n",
      "Epoch [34/50], Step [374/735], Loss: 0.0665\n",
      "Epoch [34/50], Step [375/735], Loss: 0.1047\n",
      "Epoch [34/50], Step [376/735], Loss: 0.0987\n",
      "Epoch [34/50], Step [377/735], Loss: 0.0568\n",
      "Epoch [34/50], Step [378/735], Loss: 0.0812\n",
      "Epoch [34/50], Step [379/735], Loss: 0.1039\n",
      "Epoch [34/50], Step [380/735], Loss: 0.1538\n",
      "Epoch [34/50], Step [381/735], Loss: 0.0471\n",
      "Epoch [34/50], Step [382/735], Loss: 0.1946\n",
      "Epoch [34/50], Step [383/735], Loss: 0.2728\n",
      "Epoch [34/50], Step [384/735], Loss: 0.0665\n",
      "Epoch [34/50], Step [385/735], Loss: 0.0761\n",
      "Epoch [34/50], Step [386/735], Loss: 0.0834\n",
      "Epoch [34/50], Step [387/735], Loss: 0.1864\n",
      "Epoch [34/50], Step [388/735], Loss: 0.0870\n",
      "Epoch [34/50], Step [389/735], Loss: 0.0837\n",
      "Epoch [34/50], Step [390/735], Loss: 0.1226\n",
      "Epoch [34/50], Step [391/735], Loss: 0.0383\n",
      "Epoch [34/50], Step [392/735], Loss: 0.2577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Step [393/735], Loss: 0.2247\n",
      "Epoch [34/50], Step [394/735], Loss: 0.1316\n",
      "Epoch [34/50], Step [395/735], Loss: 0.1385\n",
      "Epoch [34/50], Step [396/735], Loss: 0.0904\n",
      "Epoch [34/50], Step [397/735], Loss: 0.1606\n",
      "Epoch [34/50], Step [398/735], Loss: 0.2044\n",
      "Epoch [34/50], Step [399/735], Loss: 0.1056\n",
      "Epoch [34/50], Step [400/735], Loss: 0.0362\n",
      "Epoch [34/50], Step [401/735], Loss: 0.0411\n",
      "Epoch [34/50], Step [402/735], Loss: 0.1365\n",
      "Epoch [34/50], Step [403/735], Loss: 0.1297\n",
      "Epoch [34/50], Step [404/735], Loss: 0.1016\n",
      "Epoch [34/50], Step [405/735], Loss: 0.3065\n",
      "Epoch [34/50], Step [406/735], Loss: 0.0661\n",
      "Epoch [34/50], Step [407/735], Loss: 0.0872\n",
      "Epoch [34/50], Step [408/735], Loss: 0.1566\n",
      "Epoch [34/50], Step [409/735], Loss: 0.0779\n",
      "Epoch [34/50], Step [410/735], Loss: 0.0787\n",
      "Epoch [34/50], Step [411/735], Loss: 0.0406\n",
      "Epoch [34/50], Step [412/735], Loss: 0.0437\n",
      "Epoch [34/50], Step [413/735], Loss: 0.1330\n",
      "Epoch [34/50], Step [414/735], Loss: 0.0446\n",
      "Epoch [34/50], Step [415/735], Loss: 1.8364\n",
      "Epoch [34/50], Step [416/735], Loss: 0.0752\n",
      "Epoch [34/50], Step [417/735], Loss: 0.1739\n",
      "Epoch [34/50], Step [418/735], Loss: 0.1128\n",
      "Epoch [34/50], Step [419/735], Loss: 0.0830\n",
      "Epoch [34/50], Step [420/735], Loss: 0.1853\n",
      "Epoch [34/50], Step [421/735], Loss: 0.0486\n",
      "Epoch [34/50], Step [422/735], Loss: 0.0823\n",
      "Epoch [34/50], Step [423/735], Loss: 0.1271\n",
      "Epoch [34/50], Step [424/735], Loss: 0.0685\n",
      "Epoch [34/50], Step [425/735], Loss: 0.0715\n",
      "Epoch [34/50], Step [426/735], Loss: 0.1789\n",
      "Epoch [34/50], Step [427/735], Loss: 0.0560\n",
      "Epoch [34/50], Step [428/735], Loss: 0.0749\n",
      "Epoch [34/50], Step [429/735], Loss: 0.1255\n",
      "Epoch [34/50], Step [430/735], Loss: 0.0483\n",
      "Epoch [34/50], Step [431/735], Loss: 0.1719\n",
      "Epoch [34/50], Step [432/735], Loss: 0.1125\n",
      "Epoch [34/50], Step [433/735], Loss: 0.1479\n",
      "Epoch [34/50], Step [434/735], Loss: 0.0621\n",
      "Epoch [34/50], Step [435/735], Loss: 0.0512\n",
      "Epoch [34/50], Step [436/735], Loss: 0.0217\n",
      "Epoch [34/50], Step [437/735], Loss: 0.1065\n",
      "Epoch [34/50], Step [438/735], Loss: 0.2070\n",
      "Epoch [34/50], Step [439/735], Loss: 0.0298\n",
      "Epoch [34/50], Step [440/735], Loss: 0.0382\n",
      "Epoch [34/50], Step [441/735], Loss: 0.0914\n",
      "Epoch [34/50], Step [442/735], Loss: 0.1112\n",
      "Epoch [34/50], Step [443/735], Loss: 0.1197\n",
      "Epoch [34/50], Step [444/735], Loss: 0.0579\n",
      "Epoch [34/50], Step [445/735], Loss: 0.1110\n",
      "Epoch [34/50], Step [446/735], Loss: 0.1075\n",
      "Epoch [34/50], Step [447/735], Loss: 0.0443\n",
      "Epoch [34/50], Step [448/735], Loss: 0.1985\n",
      "Epoch [34/50], Step [449/735], Loss: 0.1083\n",
      "Epoch [34/50], Step [450/735], Loss: 0.0543\n",
      "Epoch [34/50], Step [451/735], Loss: 0.1014\n",
      "Epoch [34/50], Step [452/735], Loss: 0.4080\n",
      "Epoch [34/50], Step [453/735], Loss: 0.1345\n",
      "Epoch [34/50], Step [454/735], Loss: 0.0844\n",
      "Epoch [34/50], Step [455/735], Loss: 0.5325\n",
      "Epoch [34/50], Step [456/735], Loss: 0.4794\n",
      "Epoch [34/50], Step [457/735], Loss: 0.0813\n",
      "Epoch [34/50], Step [458/735], Loss: 0.1531\n",
      "Epoch [34/50], Step [459/735], Loss: 0.0951\n",
      "Epoch [34/50], Step [460/735], Loss: 0.0809\n",
      "Epoch [34/50], Step [461/735], Loss: 0.2549\n",
      "Epoch [34/50], Step [462/735], Loss: 0.0949\n",
      "Epoch [34/50], Step [463/735], Loss: 0.0995\n",
      "Epoch [34/50], Step [464/735], Loss: 0.1011\n",
      "Epoch [34/50], Step [465/735], Loss: 0.1409\n",
      "Epoch [34/50], Step [466/735], Loss: 0.1254\n",
      "Epoch [34/50], Step [467/735], Loss: 0.1636\n",
      "Epoch [34/50], Step [468/735], Loss: 0.2049\n",
      "Epoch [34/50], Step [469/735], Loss: 0.0996\n",
      "Epoch [34/50], Step [470/735], Loss: 0.2464\n",
      "Epoch [34/50], Step [471/735], Loss: 0.1068\n",
      "Epoch [34/50], Step [472/735], Loss: 0.0920\n",
      "Epoch [34/50], Step [473/735], Loss: 0.0927\n",
      "Epoch [34/50], Step [474/735], Loss: 0.1045\n",
      "Epoch [34/50], Step [475/735], Loss: 0.1143\n",
      "Epoch [34/50], Step [476/735], Loss: 0.1668\n",
      "Epoch [34/50], Step [477/735], Loss: 0.1252\n",
      "Epoch [34/50], Step [478/735], Loss: 0.1028\n",
      "Epoch [34/50], Step [479/735], Loss: 0.1374\n",
      "Epoch [34/50], Step [480/735], Loss: 0.8879\n",
      "Epoch [34/50], Step [481/735], Loss: 0.1233\n",
      "Epoch [34/50], Step [482/735], Loss: 0.2736\n",
      "Epoch [34/50], Step [483/735], Loss: 0.1215\n",
      "Epoch [34/50], Step [484/735], Loss: 0.0761\n",
      "Epoch [34/50], Step [485/735], Loss: 0.0884\n",
      "Epoch [34/50], Step [486/735], Loss: 0.1079\n",
      "Epoch [34/50], Step [487/735], Loss: 0.1137\n",
      "Epoch [34/50], Step [488/735], Loss: 0.1287\n",
      "Epoch [34/50], Step [489/735], Loss: 0.1202\n",
      "Epoch [34/50], Step [490/735], Loss: 0.0570\n",
      "Epoch [34/50], Step [491/735], Loss: 1.4592\n",
      "Epoch [34/50], Step [492/735], Loss: 0.0533\n",
      "Epoch [34/50], Step [493/735], Loss: 0.1081\n",
      "Epoch [34/50], Step [494/735], Loss: 0.1178\n",
      "Epoch [34/50], Step [495/735], Loss: 0.1213\n",
      "Epoch [34/50], Step [496/735], Loss: 0.1876\n",
      "Epoch [34/50], Step [497/735], Loss: 0.1243\n",
      "Epoch [34/50], Step [498/735], Loss: 0.0994\n",
      "Epoch [34/50], Step [499/735], Loss: 0.1495\n",
      "Epoch [34/50], Step [500/735], Loss: 0.0442\n",
      "Epoch [34/50], Step [501/735], Loss: 0.1852\n",
      "Epoch [34/50], Step [502/735], Loss: 0.0743\n",
      "Epoch [34/50], Step [503/735], Loss: 0.1075\n",
      "Epoch [34/50], Step [504/735], Loss: 0.1078\n",
      "Epoch [34/50], Step [505/735], Loss: 0.1156\n",
      "Epoch [34/50], Step [506/735], Loss: 0.0752\n",
      "Epoch [34/50], Step [507/735], Loss: 0.1492\n",
      "Epoch [34/50], Step [508/735], Loss: 0.1413\n",
      "Epoch [34/50], Step [509/735], Loss: 0.1576\n",
      "Epoch [34/50], Step [510/735], Loss: 0.2820\n",
      "Epoch [34/50], Step [511/735], Loss: 0.2187\n",
      "Epoch [34/50], Step [512/735], Loss: 0.0549\n",
      "Epoch [34/50], Step [513/735], Loss: 0.1825\n",
      "Epoch [34/50], Step [514/735], Loss: 0.2935\n",
      "Epoch [34/50], Step [515/735], Loss: 0.1054\n",
      "Epoch [34/50], Step [516/735], Loss: 0.1052\n",
      "Epoch [34/50], Step [517/735], Loss: 0.2326\n",
      "Epoch [34/50], Step [518/735], Loss: 0.3789\n",
      "Epoch [34/50], Step [519/735], Loss: 0.1452\n",
      "Epoch [34/50], Step [520/735], Loss: 0.1106\n",
      "Epoch [34/50], Step [521/735], Loss: 0.0698\n",
      "Epoch [34/50], Step [522/735], Loss: 0.1333\n",
      "Epoch [34/50], Step [523/735], Loss: 0.0454\n",
      "Epoch [34/50], Step [524/735], Loss: 0.0752\n",
      "Epoch [34/50], Step [525/735], Loss: 0.3552\n",
      "Epoch [34/50], Step [526/735], Loss: 0.1515\n",
      "Epoch [34/50], Step [527/735], Loss: 0.0797\n",
      "Epoch [34/50], Step [528/735], Loss: 0.1657\n",
      "Epoch [34/50], Step [529/735], Loss: 0.3656\n",
      "Epoch [34/50], Step [530/735], Loss: 0.4013\n",
      "Epoch [34/50], Step [531/735], Loss: 0.2406\n",
      "Epoch [34/50], Step [532/735], Loss: 0.1319\n",
      "Epoch [34/50], Step [533/735], Loss: 0.0818\n",
      "Epoch [34/50], Step [534/735], Loss: 0.2747\n",
      "Epoch [34/50], Step [535/735], Loss: 0.0917\n",
      "Epoch [34/50], Step [536/735], Loss: 0.0365\n",
      "Epoch [34/50], Step [537/735], Loss: 0.0478\n",
      "Epoch [34/50], Step [538/735], Loss: 0.1133\n",
      "Epoch [34/50], Step [539/735], Loss: 0.0781\n",
      "Epoch [34/50], Step [540/735], Loss: 0.1414\n",
      "Epoch [34/50], Step [541/735], Loss: 0.0398\n",
      "Epoch [34/50], Step [542/735], Loss: 0.1185\n",
      "Epoch [34/50], Step [543/735], Loss: 0.1114\n",
      "Epoch [34/50], Step [544/735], Loss: 0.0562\n",
      "Epoch [34/50], Step [545/735], Loss: 0.0693\n",
      "Epoch [34/50], Step [546/735], Loss: 0.1671\n",
      "Epoch [34/50], Step [547/735], Loss: 0.1264\n",
      "Epoch [34/50], Step [548/735], Loss: 0.2602\n",
      "Epoch [34/50], Step [549/735], Loss: 0.1696\n",
      "Epoch [34/50], Step [550/735], Loss: 0.0907\n",
      "Epoch [34/50], Step [551/735], Loss: 0.1756\n",
      "Epoch [34/50], Step [552/735], Loss: 0.1449\n",
      "Epoch [34/50], Step [553/735], Loss: 0.0785\n",
      "Epoch [34/50], Step [554/735], Loss: 0.6419\n",
      "Epoch [34/50], Step [555/735], Loss: 0.0705\n",
      "Epoch [34/50], Step [556/735], Loss: 0.0483\n",
      "Epoch [34/50], Step [557/735], Loss: 0.1155\n",
      "Epoch [34/50], Step [558/735], Loss: 0.0898\n",
      "Epoch [34/50], Step [559/735], Loss: 0.1118\n",
      "Epoch [34/50], Step [560/735], Loss: 0.1082\n",
      "Epoch [34/50], Step [561/735], Loss: 0.2643\n",
      "Epoch [34/50], Step [562/735], Loss: 0.0538\n",
      "Epoch [34/50], Step [563/735], Loss: 0.0577\n",
      "Epoch [34/50], Step [564/735], Loss: 0.0983\n",
      "Epoch [34/50], Step [565/735], Loss: 0.1594\n",
      "Epoch [34/50], Step [566/735], Loss: 0.0468\n",
      "Epoch [34/50], Step [567/735], Loss: 0.1115\n",
      "Epoch [34/50], Step [568/735], Loss: 0.1587\n",
      "Epoch [34/50], Step [569/735], Loss: 2.0908\n",
      "Epoch [34/50], Step [570/735], Loss: 0.4553\n",
      "Epoch [34/50], Step [571/735], Loss: 0.0937\n",
      "Epoch [34/50], Step [572/735], Loss: 0.0594\n",
      "Epoch [34/50], Step [573/735], Loss: 0.2192\n",
      "Epoch [34/50], Step [574/735], Loss: 0.2183\n",
      "Epoch [34/50], Step [575/735], Loss: 0.1828\n",
      "Epoch [34/50], Step [576/735], Loss: 0.0811\n",
      "Epoch [34/50], Step [577/735], Loss: 0.1614\n",
      "Epoch [34/50], Step [578/735], Loss: 0.0526\n",
      "Epoch [34/50], Step [579/735], Loss: 0.1425\n",
      "Epoch [34/50], Step [580/735], Loss: 0.2102\n",
      "Epoch [34/50], Step [581/735], Loss: 0.0454\n",
      "Epoch [34/50], Step [582/735], Loss: 0.3558\n",
      "Epoch [34/50], Step [583/735], Loss: 0.0735\n",
      "Epoch [34/50], Step [584/735], Loss: 0.1844\n",
      "Epoch [34/50], Step [585/735], Loss: 0.1152\n",
      "Epoch [34/50], Step [586/735], Loss: 0.1619\n",
      "Epoch [34/50], Step [587/735], Loss: 0.1565\n",
      "Epoch [34/50], Step [588/735], Loss: 0.0981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Step [589/735], Loss: 0.0732\n",
      "Epoch [34/50], Step [590/735], Loss: 0.1027\n",
      "Epoch [34/50], Step [591/735], Loss: 0.1507\n",
      "Epoch [34/50], Step [592/735], Loss: 0.0787\n",
      "Epoch [34/50], Step [593/735], Loss: 0.1032\n",
      "Epoch [34/50], Step [594/735], Loss: 0.0548\n",
      "Epoch [34/50], Step [595/735], Loss: 0.0881\n",
      "Epoch [34/50], Step [596/735], Loss: 0.0490\n",
      "Epoch [34/50], Step [597/735], Loss: 0.4055\n",
      "Epoch [34/50], Step [598/735], Loss: 0.1469\n",
      "Epoch [34/50], Step [599/735], Loss: 0.1407\n",
      "Epoch [34/50], Step [600/735], Loss: 0.0756\n",
      "Epoch [34/50], Step [601/735], Loss: 0.1661\n",
      "Epoch [34/50], Step [602/735], Loss: 0.4399\n",
      "Epoch [34/50], Step [603/735], Loss: 0.0809\n",
      "Epoch [34/50], Step [604/735], Loss: 0.1118\n",
      "Epoch [34/50], Step [605/735], Loss: 0.1873\n",
      "Epoch [34/50], Step [606/735], Loss: 0.0953\n",
      "Epoch [34/50], Step [607/735], Loss: 0.1707\n",
      "Epoch [34/50], Step [608/735], Loss: 0.1668\n",
      "Epoch [34/50], Step [609/735], Loss: 0.0683\n",
      "Epoch [34/50], Step [610/735], Loss: 0.1194\n",
      "Epoch [34/50], Step [611/735], Loss: 0.0701\n",
      "Epoch [34/50], Step [612/735], Loss: 0.1272\n",
      "Epoch [34/50], Step [613/735], Loss: 0.1579\n",
      "Epoch [34/50], Step [614/735], Loss: 0.1115\n",
      "Epoch [34/50], Step [615/735], Loss: 0.0827\n",
      "Epoch [34/50], Step [616/735], Loss: 0.1163\n",
      "Epoch [34/50], Step [617/735], Loss: 0.6796\n",
      "Epoch [34/50], Step [618/735], Loss: 0.0589\n",
      "Epoch [34/50], Step [619/735], Loss: 0.0964\n",
      "Epoch [34/50], Step [620/735], Loss: 0.1611\n",
      "Epoch [34/50], Step [621/735], Loss: 0.1524\n",
      "Epoch [34/50], Step [622/735], Loss: 0.0711\n",
      "Epoch [34/50], Step [623/735], Loss: 0.0962\n",
      "Epoch [34/50], Step [624/735], Loss: 0.2140\n",
      "Epoch [34/50], Step [625/735], Loss: 0.1508\n",
      "Epoch [34/50], Step [626/735], Loss: 0.0968\n",
      "Epoch [34/50], Step [627/735], Loss: 0.3309\n",
      "Epoch [34/50], Step [628/735], Loss: 0.1251\n",
      "Epoch [34/50], Step [629/735], Loss: 0.0798\n",
      "Epoch [34/50], Step [630/735], Loss: 0.2366\n",
      "Epoch [34/50], Step [631/735], Loss: 0.0647\n",
      "Epoch [34/50], Step [632/735], Loss: 0.2651\n",
      "Epoch [34/50], Step [633/735], Loss: 0.2860\n",
      "Epoch [34/50], Step [634/735], Loss: 1.2775\n",
      "Epoch [34/50], Step [635/735], Loss: 0.0940\n",
      "Epoch [34/50], Step [636/735], Loss: 0.0822\n",
      "Epoch [34/50], Step [637/735], Loss: 0.1402\n",
      "Epoch [34/50], Step [638/735], Loss: 0.1289\n",
      "Epoch [34/50], Step [639/735], Loss: 0.0623\n",
      "Epoch [34/50], Step [640/735], Loss: 0.1573\n",
      "Epoch [34/50], Step [641/735], Loss: 0.2513\n",
      "Epoch [34/50], Step [642/735], Loss: 0.2057\n",
      "Epoch [34/50], Step [643/735], Loss: 0.0708\n",
      "Epoch [34/50], Step [644/735], Loss: 0.0836\n",
      "Epoch [34/50], Step [645/735], Loss: 0.0933\n",
      "Epoch [34/50], Step [646/735], Loss: 0.1427\n",
      "Epoch [34/50], Step [647/735], Loss: 0.0767\n",
      "Epoch [34/50], Step [648/735], Loss: 0.1345\n",
      "Epoch [34/50], Step [649/735], Loss: 0.9424\n",
      "Epoch [34/50], Step [650/735], Loss: 0.1084\n",
      "Epoch [34/50], Step [651/735], Loss: 0.0749\n",
      "Epoch [34/50], Step [652/735], Loss: 0.0912\n",
      "Epoch [34/50], Step [653/735], Loss: 0.0683\n",
      "Epoch [34/50], Step [654/735], Loss: 0.0370\n",
      "Epoch [34/50], Step [655/735], Loss: 0.0781\n",
      "Epoch [34/50], Step [656/735], Loss: 0.0889\n",
      "Epoch [34/50], Step [657/735], Loss: 0.1823\n",
      "Epoch [34/50], Step [658/735], Loss: 0.2956\n",
      "Epoch [34/50], Step [659/735], Loss: 0.1107\n",
      "Epoch [34/50], Step [660/735], Loss: 0.1374\n",
      "Epoch [34/50], Step [661/735], Loss: 0.0962\n",
      "Epoch [34/50], Step [662/735], Loss: 0.0703\n",
      "Epoch [34/50], Step [663/735], Loss: 0.1529\n",
      "Epoch [34/50], Step [664/735], Loss: 0.0571\n",
      "Epoch [34/50], Step [665/735], Loss: 0.1363\n",
      "Epoch [34/50], Step [666/735], Loss: 0.0355\n",
      "Epoch [34/50], Step [667/735], Loss: 0.0847\n",
      "Epoch [34/50], Step [668/735], Loss: 0.2072\n",
      "Epoch [34/50], Step [669/735], Loss: 0.1164\n",
      "Epoch [34/50], Step [670/735], Loss: 0.0715\n",
      "Epoch [34/50], Step [671/735], Loss: 0.0962\n",
      "Epoch [34/50], Step [672/735], Loss: 0.0342\n",
      "Epoch [34/50], Step [673/735], Loss: 0.0715\n",
      "Epoch [34/50], Step [674/735], Loss: 0.0799\n",
      "Epoch [34/50], Step [675/735], Loss: 0.1299\n",
      "Epoch [34/50], Step [676/735], Loss: 0.1692\n",
      "Epoch [34/50], Step [677/735], Loss: 0.0806\n",
      "Epoch [34/50], Step [678/735], Loss: 0.1914\n",
      "Epoch [34/50], Step [679/735], Loss: 0.0840\n",
      "Epoch [34/50], Step [680/735], Loss: 0.0861\n",
      "Epoch [34/50], Step [681/735], Loss: 0.1289\n",
      "Epoch [34/50], Step [682/735], Loss: 0.1375\n",
      "Epoch [34/50], Step [683/735], Loss: 0.0630\n",
      "Epoch [34/50], Step [684/735], Loss: 0.0610\n",
      "Epoch [34/50], Step [685/735], Loss: 0.0530\n",
      "Epoch [34/50], Step [686/735], Loss: 0.5825\n",
      "Epoch [34/50], Step [687/735], Loss: 0.0550\n",
      "Epoch [34/50], Step [688/735], Loss: 0.1016\n",
      "Epoch [34/50], Step [689/735], Loss: 0.1156\n",
      "Epoch [34/50], Step [690/735], Loss: 0.1354\n",
      "Epoch [34/50], Step [691/735], Loss: 0.1691\n",
      "Epoch [34/50], Step [692/735], Loss: 0.0700\n",
      "Epoch [34/50], Step [693/735], Loss: 0.0582\n",
      "Epoch [34/50], Step [694/735], Loss: 0.0296\n",
      "Epoch [34/50], Step [695/735], Loss: 0.0407\n",
      "Epoch [34/50], Step [696/735], Loss: 0.0858\n",
      "Epoch [34/50], Step [697/735], Loss: 0.0655\n",
      "Epoch [34/50], Step [698/735], Loss: 0.0792\n",
      "Epoch [34/50], Step [699/735], Loss: 0.0884\n",
      "Epoch [34/50], Step [700/735], Loss: 0.0793\n",
      "Epoch [34/50], Step [701/735], Loss: 0.0731\n",
      "Epoch [34/50], Step [702/735], Loss: 0.1128\n",
      "Epoch [34/50], Step [703/735], Loss: 1.8872\n",
      "Epoch [34/50], Step [704/735], Loss: 0.0813\n",
      "Epoch [34/50], Step [705/735], Loss: 0.0675\n",
      "Epoch [34/50], Step [706/735], Loss: 0.1419\n",
      "Epoch [34/50], Step [707/735], Loss: 0.0699\n",
      "Epoch [34/50], Step [708/735], Loss: 0.2545\n",
      "Epoch [34/50], Step [709/735], Loss: 0.0736\n",
      "Epoch [34/50], Step [710/735], Loss: 0.0952\n",
      "Epoch [34/50], Step [711/735], Loss: 0.1600\n",
      "Epoch [34/50], Step [712/735], Loss: 0.4410\n",
      "Epoch [34/50], Step [713/735], Loss: 0.1277\n",
      "Epoch [34/50], Step [714/735], Loss: 0.0736\n",
      "Epoch [34/50], Step [715/735], Loss: 0.1487\n",
      "Epoch [34/50], Step [716/735], Loss: 0.2531\n",
      "Epoch [34/50], Step [717/735], Loss: 0.0508\n",
      "Epoch [34/50], Step [718/735], Loss: 0.1411\n",
      "Epoch [34/50], Step [719/735], Loss: 0.0312\n",
      "Epoch [34/50], Step [720/735], Loss: 0.0863\n",
      "Epoch [34/50], Step [721/735], Loss: 0.0772\n",
      "Epoch [34/50], Step [722/735], Loss: 0.1127\n",
      "Epoch [34/50], Step [723/735], Loss: 1.3942\n",
      "Epoch [34/50], Step [724/735], Loss: 0.0767\n",
      "Epoch [34/50], Step [725/735], Loss: 0.0930\n",
      "Epoch [34/50], Step [726/735], Loss: 0.0753\n",
      "Epoch [34/50], Step [727/735], Loss: 0.2021\n",
      "Epoch [34/50], Step [728/735], Loss: 0.0601\n",
      "Epoch [34/50], Step [729/735], Loss: 0.0433\n",
      "Epoch [34/50], Step [730/735], Loss: 0.1073\n",
      "Epoch [34/50], Step [731/735], Loss: 0.1014\n",
      "Epoch [34/50], Step [732/735], Loss: 0.1143\n",
      "Epoch [34/50], Step [733/735], Loss: 0.1419\n",
      "Epoch [34/50], Step [734/735], Loss: 0.0816\n",
      "Epoch [34/50], Step [735/735], Loss: 0.3700\n",
      "Epoch [35/50], Step [1/735], Loss: 0.2007\n",
      "Epoch [35/50], Step [2/735], Loss: 0.0909\n",
      "Epoch [35/50], Step [3/735], Loss: 0.1771\n",
      "Epoch [35/50], Step [4/735], Loss: 0.0644\n",
      "Epoch [35/50], Step [5/735], Loss: 0.1331\n",
      "Epoch [35/50], Step [6/735], Loss: 0.1432\n",
      "Epoch [35/50], Step [7/735], Loss: 0.0591\n",
      "Epoch [35/50], Step [8/735], Loss: 0.0398\n",
      "Epoch [35/50], Step [9/735], Loss: 0.0901\n",
      "Epoch [35/50], Step [10/735], Loss: 0.0532\n",
      "Epoch [35/50], Step [11/735], Loss: 0.8621\n",
      "Epoch [35/50], Step [12/735], Loss: 0.0455\n",
      "Epoch [35/50], Step [13/735], Loss: 0.1095\n",
      "Epoch [35/50], Step [14/735], Loss: 0.0665\n",
      "Epoch [35/50], Step [15/735], Loss: 0.0929\n",
      "Epoch [35/50], Step [16/735], Loss: 0.3217\n",
      "Epoch [35/50], Step [17/735], Loss: 0.0698\n",
      "Epoch [35/50], Step [18/735], Loss: 0.1418\n",
      "Epoch [35/50], Step [19/735], Loss: 0.1059\n",
      "Epoch [35/50], Step [20/735], Loss: 0.1140\n",
      "Epoch [35/50], Step [21/735], Loss: 0.0867\n",
      "Epoch [35/50], Step [22/735], Loss: 0.0962\n",
      "Epoch [35/50], Step [23/735], Loss: 0.2549\n",
      "Epoch [35/50], Step [24/735], Loss: 0.0667\n",
      "Epoch [35/50], Step [25/735], Loss: 0.0715\n",
      "Epoch [35/50], Step [26/735], Loss: 0.1058\n",
      "Epoch [35/50], Step [27/735], Loss: 0.1231\n",
      "Epoch [35/50], Step [28/735], Loss: 0.0720\n",
      "Epoch [35/50], Step [29/735], Loss: 0.1269\n",
      "Epoch [35/50], Step [30/735], Loss: 0.0747\n",
      "Epoch [35/50], Step [31/735], Loss: 0.1274\n",
      "Epoch [35/50], Step [32/735], Loss: 0.1839\n",
      "Epoch [35/50], Step [33/735], Loss: 0.3873\n",
      "Epoch [35/50], Step [34/735], Loss: 0.0784\n",
      "Epoch [35/50], Step [35/735], Loss: 0.0945\n",
      "Epoch [35/50], Step [36/735], Loss: 0.0943\n",
      "Epoch [35/50], Step [37/735], Loss: 0.0971\n",
      "Epoch [35/50], Step [38/735], Loss: 0.0606\n",
      "Epoch [35/50], Step [39/735], Loss: 0.2780\n",
      "Epoch [35/50], Step [40/735], Loss: 0.1226\n",
      "Epoch [35/50], Step [41/735], Loss: 0.0706\n",
      "Epoch [35/50], Step [42/735], Loss: 0.1332\n",
      "Epoch [35/50], Step [43/735], Loss: 0.0491\n",
      "Epoch [35/50], Step [44/735], Loss: 0.1830\n",
      "Epoch [35/50], Step [45/735], Loss: 0.1814\n",
      "Epoch [35/50], Step [46/735], Loss: 0.0909\n",
      "Epoch [35/50], Step [47/735], Loss: 0.1077\n",
      "Epoch [35/50], Step [48/735], Loss: 0.0966\n",
      "Epoch [35/50], Step [49/735], Loss: 0.5204\n",
      "Epoch [35/50], Step [50/735], Loss: 0.0858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Step [51/735], Loss: 0.1098\n",
      "Epoch [35/50], Step [52/735], Loss: 0.0574\n",
      "Epoch [35/50], Step [53/735], Loss: 0.1015\n",
      "Epoch [35/50], Step [54/735], Loss: 1.1913\n",
      "Epoch [35/50], Step [55/735], Loss: 0.1055\n",
      "Epoch [35/50], Step [56/735], Loss: 0.1447\n",
      "Epoch [35/50], Step [57/735], Loss: 0.0748\n",
      "Epoch [35/50], Step [58/735], Loss: 0.0640\n",
      "Epoch [35/50], Step [59/735], Loss: 0.0810\n",
      "Epoch [35/50], Step [60/735], Loss: 0.0775\n",
      "Epoch [35/50], Step [61/735], Loss: 0.0690\n",
      "Epoch [35/50], Step [62/735], Loss: 0.0219\n",
      "Epoch [35/50], Step [63/735], Loss: 0.1592\n",
      "Epoch [35/50], Step [64/735], Loss: 0.2077\n",
      "Epoch [35/50], Step [65/735], Loss: 0.0763\n",
      "Epoch [35/50], Step [66/735], Loss: 0.0965\n",
      "Epoch [35/50], Step [67/735], Loss: 0.0987\n",
      "Epoch [35/50], Step [68/735], Loss: 0.0566\n",
      "Epoch [35/50], Step [69/735], Loss: 0.0577\n",
      "Epoch [35/50], Step [70/735], Loss: 0.0870\n",
      "Epoch [35/50], Step [71/735], Loss: 0.3685\n",
      "Epoch [35/50], Step [72/735], Loss: 0.0806\n",
      "Epoch [35/50], Step [73/735], Loss: 0.0845\n",
      "Epoch [35/50], Step [74/735], Loss: 0.1491\n",
      "Epoch [35/50], Step [75/735], Loss: 0.1323\n",
      "Epoch [35/50], Step [76/735], Loss: 0.0599\n",
      "Epoch [35/50], Step [77/735], Loss: 0.0539\n",
      "Epoch [35/50], Step [78/735], Loss: 0.0361\n",
      "Epoch [35/50], Step [79/735], Loss: 0.2006\n",
      "Epoch [35/50], Step [80/735], Loss: 2.1666\n",
      "Epoch [35/50], Step [81/735], Loss: 0.0891\n",
      "Epoch [35/50], Step [82/735], Loss: 0.0959\n",
      "Epoch [35/50], Step [83/735], Loss: 0.0548\n",
      "Epoch [35/50], Step [84/735], Loss: 0.0704\n",
      "Epoch [35/50], Step [85/735], Loss: 0.1958\n",
      "Epoch [35/50], Step [86/735], Loss: 0.1684\n",
      "Epoch [35/50], Step [87/735], Loss: 0.1375\n",
      "Epoch [35/50], Step [88/735], Loss: 0.1584\n",
      "Epoch [35/50], Step [89/735], Loss: 0.0900\n",
      "Epoch [35/50], Step [90/735], Loss: 0.0735\n",
      "Epoch [35/50], Step [91/735], Loss: 0.0944\n",
      "Epoch [35/50], Step [92/735], Loss: 0.1926\n",
      "Epoch [35/50], Step [93/735], Loss: 0.0504\n",
      "Epoch [35/50], Step [94/735], Loss: 0.0763\n",
      "Epoch [35/50], Step [95/735], Loss: 0.0749\n",
      "Epoch [35/50], Step [96/735], Loss: 0.1981\n",
      "Epoch [35/50], Step [97/735], Loss: 0.0753\n",
      "Epoch [35/50], Step [98/735], Loss: 0.4802\n",
      "Epoch [35/50], Step [99/735], Loss: 0.1817\n",
      "Epoch [35/50], Step [100/735], Loss: 0.1084\n",
      "Epoch [35/50], Step [101/735], Loss: 0.4535\n",
      "Epoch [35/50], Step [102/735], Loss: 0.1163\n",
      "Epoch [35/50], Step [103/735], Loss: 0.0844\n",
      "Epoch [35/50], Step [104/735], Loss: 0.4772\n",
      "Epoch [35/50], Step [105/735], Loss: 0.1485\n",
      "Epoch [35/50], Step [106/735], Loss: 0.0938\n",
      "Epoch [35/50], Step [107/735], Loss: 0.0649\n",
      "Epoch [35/50], Step [108/735], Loss: 0.1271\n",
      "Epoch [35/50], Step [109/735], Loss: 0.1777\n",
      "Epoch [35/50], Step [110/735], Loss: 0.1213\n",
      "Epoch [35/50], Step [111/735], Loss: 0.0793\n",
      "Epoch [35/50], Step [112/735], Loss: 0.1664\n",
      "Epoch [35/50], Step [113/735], Loss: 0.5712\n",
      "Epoch [35/50], Step [114/735], Loss: 0.0753\n",
      "Epoch [35/50], Step [115/735], Loss: 0.1125\n",
      "Epoch [35/50], Step [116/735], Loss: 0.0778\n",
      "Epoch [35/50], Step [117/735], Loss: 0.1034\n",
      "Epoch [35/50], Step [118/735], Loss: 0.1739\n",
      "Epoch [35/50], Step [119/735], Loss: 0.1984\n",
      "Epoch [35/50], Step [120/735], Loss: 0.0474\n",
      "Epoch [35/50], Step [121/735], Loss: 0.0312\n",
      "Epoch [35/50], Step [122/735], Loss: 0.1158\n",
      "Epoch [35/50], Step [123/735], Loss: 0.0557\n",
      "Epoch [35/50], Step [124/735], Loss: 0.0421\n",
      "Epoch [35/50], Step [125/735], Loss: 0.0477\n",
      "Epoch [35/50], Step [126/735], Loss: 0.1473\n",
      "Epoch [35/50], Step [127/735], Loss: 0.0462\n",
      "Epoch [35/50], Step [128/735], Loss: 1.5474\n",
      "Epoch [35/50], Step [129/735], Loss: 0.1464\n",
      "Epoch [35/50], Step [130/735], Loss: 0.3843\n",
      "Epoch [35/50], Step [131/735], Loss: 0.0780\n",
      "Epoch [35/50], Step [132/735], Loss: 0.0927\n",
      "Epoch [35/50], Step [133/735], Loss: 0.0994\n",
      "Epoch [35/50], Step [134/735], Loss: 0.1034\n",
      "Epoch [35/50], Step [135/735], Loss: 0.1493\n",
      "Epoch [35/50], Step [136/735], Loss: 0.2772\n",
      "Epoch [35/50], Step [137/735], Loss: 0.1550\n",
      "Epoch [35/50], Step [138/735], Loss: 0.0788\n",
      "Epoch [35/50], Step [139/735], Loss: 0.0581\n",
      "Epoch [35/50], Step [140/735], Loss: 0.0784\n",
      "Epoch [35/50], Step [141/735], Loss: 0.2514\n",
      "Epoch [35/50], Step [142/735], Loss: 0.2062\n",
      "Epoch [35/50], Step [143/735], Loss: 0.0523\n",
      "Epoch [35/50], Step [144/735], Loss: 0.0864\n",
      "Epoch [35/50], Step [145/735], Loss: 0.0924\n",
      "Epoch [35/50], Step [146/735], Loss: 0.3852\n",
      "Epoch [35/50], Step [147/735], Loss: 0.0985\n",
      "Epoch [35/50], Step [148/735], Loss: 0.0493\n",
      "Epoch [35/50], Step [149/735], Loss: 0.1070\n",
      "Epoch [35/50], Step [150/735], Loss: 0.0200\n",
      "Epoch [35/50], Step [151/735], Loss: 0.0404\n",
      "Epoch [35/50], Step [152/735], Loss: 1.1046\n",
      "Epoch [35/50], Step [153/735], Loss: 0.1467\n",
      "Epoch [35/50], Step [154/735], Loss: 1.0469\n",
      "Epoch [35/50], Step [155/735], Loss: 0.1168\n",
      "Epoch [35/50], Step [156/735], Loss: 0.2758\n",
      "Epoch [35/50], Step [157/735], Loss: 0.1109\n",
      "Epoch [35/50], Step [158/735], Loss: 0.1272\n",
      "Epoch [35/50], Step [159/735], Loss: 0.1167\n",
      "Epoch [35/50], Step [160/735], Loss: 0.1638\n",
      "Epoch [35/50], Step [161/735], Loss: 0.2191\n",
      "Epoch [35/50], Step [162/735], Loss: 0.1255\n",
      "Epoch [35/50], Step [163/735], Loss: 0.3133\n",
      "Epoch [35/50], Step [164/735], Loss: 0.0318\n",
      "Epoch [35/50], Step [165/735], Loss: 0.1462\n",
      "Epoch [35/50], Step [166/735], Loss: 0.0356\n",
      "Epoch [35/50], Step [167/735], Loss: 0.1409\n",
      "Epoch [35/50], Step [168/735], Loss: 0.0366\n",
      "Epoch [35/50], Step [169/735], Loss: 1.5556\n",
      "Epoch [35/50], Step [170/735], Loss: 0.1969\n",
      "Epoch [35/50], Step [171/735], Loss: 0.0534\n",
      "Epoch [35/50], Step [172/735], Loss: 0.1310\n",
      "Epoch [35/50], Step [173/735], Loss: 0.2407\n",
      "Epoch [35/50], Step [174/735], Loss: 0.0562\n",
      "Epoch [35/50], Step [175/735], Loss: 0.1888\n",
      "Epoch [35/50], Step [176/735], Loss: 0.0611\n",
      "Epoch [35/50], Step [177/735], Loss: 0.0721\n",
      "Epoch [35/50], Step [178/735], Loss: 0.1427\n",
      "Epoch [35/50], Step [179/735], Loss: 0.0888\n",
      "Epoch [35/50], Step [180/735], Loss: 0.1142\n",
      "Epoch [35/50], Step [181/735], Loss: 0.1392\n",
      "Epoch [35/50], Step [182/735], Loss: 0.1280\n",
      "Epoch [35/50], Step [183/735], Loss: 0.0960\n",
      "Epoch [35/50], Step [184/735], Loss: 0.1568\n",
      "Epoch [35/50], Step [185/735], Loss: 0.0596\n",
      "Epoch [35/50], Step [186/735], Loss: 0.0939\n",
      "Epoch [35/50], Step [187/735], Loss: 0.1226\n",
      "Epoch [35/50], Step [188/735], Loss: 0.6450\n",
      "Epoch [35/50], Step [189/735], Loss: 0.1164\n",
      "Epoch [35/50], Step [190/735], Loss: 0.0735\n",
      "Epoch [35/50], Step [191/735], Loss: 0.1265\n",
      "Epoch [35/50], Step [192/735], Loss: 0.1014\n",
      "Epoch [35/50], Step [193/735], Loss: 0.1907\n",
      "Epoch [35/50], Step [194/735], Loss: 0.0607\n",
      "Epoch [35/50], Step [195/735], Loss: 0.1792\n",
      "Epoch [35/50], Step [196/735], Loss: 0.1564\n",
      "Epoch [35/50], Step [197/735], Loss: 0.1621\n",
      "Epoch [35/50], Step [198/735], Loss: 0.0791\n",
      "Epoch [35/50], Step [199/735], Loss: 0.3354\n",
      "Epoch [35/50], Step [200/735], Loss: 0.1550\n",
      "Epoch [35/50], Step [201/735], Loss: 0.1978\n",
      "Epoch [35/50], Step [202/735], Loss: 0.1267\n",
      "Epoch [35/50], Step [203/735], Loss: 0.1057\n",
      "Epoch [35/50], Step [204/735], Loss: 0.1236\n",
      "Epoch [35/50], Step [205/735], Loss: 0.1112\n",
      "Epoch [35/50], Step [206/735], Loss: 0.4195\n",
      "Epoch [35/50], Step [207/735], Loss: 0.0924\n",
      "Epoch [35/50], Step [208/735], Loss: 0.1790\n",
      "Epoch [35/50], Step [209/735], Loss: 0.3229\n",
      "Epoch [35/50], Step [210/735], Loss: 0.0567\n",
      "Epoch [35/50], Step [211/735], Loss: 0.2455\n",
      "Epoch [35/50], Step [212/735], Loss: 0.0847\n",
      "Epoch [35/50], Step [213/735], Loss: 0.0803\n",
      "Epoch [35/50], Step [214/735], Loss: 0.1600\n",
      "Epoch [35/50], Step [215/735], Loss: 0.1314\n",
      "Epoch [35/50], Step [216/735], Loss: 0.1806\n",
      "Epoch [35/50], Step [217/735], Loss: 0.0639\n",
      "Epoch [35/50], Step [218/735], Loss: 0.1992\n",
      "Epoch [35/50], Step [219/735], Loss: 0.0686\n",
      "Epoch [35/50], Step [220/735], Loss: 0.0968\n",
      "Epoch [35/50], Step [221/735], Loss: 0.7953\n",
      "Epoch [35/50], Step [222/735], Loss: 0.0421\n",
      "Epoch [35/50], Step [223/735], Loss: 0.0679\n",
      "Epoch [35/50], Step [224/735], Loss: 0.1195\n",
      "Epoch [35/50], Step [225/735], Loss: 0.1175\n",
      "Epoch [35/50], Step [226/735], Loss: 0.0628\n",
      "Epoch [35/50], Step [227/735], Loss: 0.1072\n",
      "Epoch [35/50], Step [228/735], Loss: 0.0925\n",
      "Epoch [35/50], Step [229/735], Loss: 0.0468\n",
      "Epoch [35/50], Step [230/735], Loss: 0.0830\n",
      "Epoch [35/50], Step [231/735], Loss: 0.1211\n",
      "Epoch [35/50], Step [232/735], Loss: 0.0916\n",
      "Epoch [35/50], Step [233/735], Loss: 0.0781\n",
      "Epoch [35/50], Step [234/735], Loss: 0.1547\n",
      "Epoch [35/50], Step [235/735], Loss: 0.1765\n",
      "Epoch [35/50], Step [236/735], Loss: 0.0805\n",
      "Epoch [35/50], Step [237/735], Loss: 0.1026\n",
      "Epoch [35/50], Step [238/735], Loss: 0.1305\n",
      "Epoch [35/50], Step [239/735], Loss: 1.0253\n",
      "Epoch [35/50], Step [240/735], Loss: 0.1729\n",
      "Epoch [35/50], Step [241/735], Loss: 0.0562\n",
      "Epoch [35/50], Step [242/735], Loss: 0.0298\n",
      "Epoch [35/50], Step [243/735], Loss: 0.0672\n",
      "Epoch [35/50], Step [244/735], Loss: 0.0801\n",
      "Epoch [35/50], Step [245/735], Loss: 0.1910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Step [246/735], Loss: 0.1383\n",
      "Epoch [35/50], Step [247/735], Loss: 0.2232\n",
      "Epoch [35/50], Step [248/735], Loss: 0.2456\n",
      "Epoch [35/50], Step [249/735], Loss: 0.1473\n",
      "Epoch [35/50], Step [250/735], Loss: 0.0630\n",
      "Epoch [35/50], Step [251/735], Loss: 0.0903\n",
      "Epoch [35/50], Step [252/735], Loss: 0.2050\n",
      "Epoch [35/50], Step [253/735], Loss: 0.1715\n",
      "Epoch [35/50], Step [254/735], Loss: 0.1593\n",
      "Epoch [35/50], Step [255/735], Loss: 0.1574\n",
      "Epoch [35/50], Step [256/735], Loss: 0.0788\n",
      "Epoch [35/50], Step [257/735], Loss: 0.1915\n",
      "Epoch [35/50], Step [258/735], Loss: 0.1205\n",
      "Epoch [35/50], Step [259/735], Loss: 0.0521\n",
      "Epoch [35/50], Step [260/735], Loss: 0.1218\n",
      "Epoch [35/50], Step [261/735], Loss: 0.0553\n",
      "Epoch [35/50], Step [262/735], Loss: 0.0565\n",
      "Epoch [35/50], Step [263/735], Loss: 0.5853\n",
      "Epoch [35/50], Step [264/735], Loss: 0.2047\n",
      "Epoch [35/50], Step [265/735], Loss: 0.1977\n",
      "Epoch [35/50], Step [266/735], Loss: 0.0761\n",
      "Epoch [35/50], Step [267/735], Loss: 0.2793\n",
      "Epoch [35/50], Step [268/735], Loss: 0.1770\n",
      "Epoch [35/50], Step [269/735], Loss: 0.2844\n",
      "Epoch [35/50], Step [270/735], Loss: 0.2692\n",
      "Epoch [35/50], Step [271/735], Loss: 0.0560\n",
      "Epoch [35/50], Step [272/735], Loss: 0.3942\n",
      "Epoch [35/50], Step [273/735], Loss: 0.0855\n",
      "Epoch [35/50], Step [274/735], Loss: 0.2996\n",
      "Epoch [35/50], Step [275/735], Loss: 0.1355\n",
      "Epoch [35/50], Step [276/735], Loss: 0.1745\n",
      "Epoch [35/50], Step [277/735], Loss: 0.1375\n",
      "Epoch [35/50], Step [278/735], Loss: 0.1085\n",
      "Epoch [35/50], Step [279/735], Loss: 0.2560\n",
      "Epoch [35/50], Step [280/735], Loss: 0.1569\n",
      "Epoch [35/50], Step [281/735], Loss: 0.0762\n",
      "Epoch [35/50], Step [282/735], Loss: 0.0830\n",
      "Epoch [35/50], Step [283/735], Loss: 0.0719\n",
      "Epoch [35/50], Step [284/735], Loss: 0.5011\n",
      "Epoch [35/50], Step [285/735], Loss: 0.0998\n",
      "Epoch [35/50], Step [286/735], Loss: 0.2015\n",
      "Epoch [35/50], Step [287/735], Loss: 0.0365\n",
      "Epoch [35/50], Step [288/735], Loss: 0.1031\n",
      "Epoch [35/50], Step [289/735], Loss: 0.1554\n",
      "Epoch [35/50], Step [290/735], Loss: 0.1096\n",
      "Epoch [35/50], Step [291/735], Loss: 0.1752\n",
      "Epoch [35/50], Step [292/735], Loss: 0.2990\n",
      "Epoch [35/50], Step [293/735], Loss: 0.2467\n",
      "Epoch [35/50], Step [294/735], Loss: 0.1694\n",
      "Epoch [35/50], Step [295/735], Loss: 0.3180\n",
      "Epoch [35/50], Step [296/735], Loss: 0.0858\n",
      "Epoch [35/50], Step [297/735], Loss: 0.2046\n",
      "Epoch [35/50], Step [298/735], Loss: 0.1584\n",
      "Epoch [35/50], Step [299/735], Loss: 0.2207\n",
      "Epoch [35/50], Step [300/735], Loss: 0.0988\n",
      "Epoch [35/50], Step [301/735], Loss: 0.1702\n",
      "Epoch [35/50], Step [302/735], Loss: 0.0910\n",
      "Epoch [35/50], Step [303/735], Loss: 0.2070\n",
      "Epoch [35/50], Step [304/735], Loss: 0.0778\n",
      "Epoch [35/50], Step [305/735], Loss: 0.0868\n",
      "Epoch [35/50], Step [306/735], Loss: 0.0808\n",
      "Epoch [35/50], Step [307/735], Loss: 0.0309\n",
      "Epoch [35/50], Step [308/735], Loss: 0.1136\n",
      "Epoch [35/50], Step [309/735], Loss: 0.0722\n",
      "Epoch [35/50], Step [310/735], Loss: 0.1529\n",
      "Epoch [35/50], Step [311/735], Loss: 0.0760\n",
      "Epoch [35/50], Step [312/735], Loss: 0.1570\n",
      "Epoch [35/50], Step [313/735], Loss: 0.1128\n",
      "Epoch [35/50], Step [314/735], Loss: 0.1649\n",
      "Epoch [35/50], Step [315/735], Loss: 0.0574\n",
      "Epoch [35/50], Step [316/735], Loss: 0.1205\n",
      "Epoch [35/50], Step [317/735], Loss: 0.1111\n",
      "Epoch [35/50], Step [318/735], Loss: 0.1234\n",
      "Epoch [35/50], Step [319/735], Loss: 0.1329\n",
      "Epoch [35/50], Step [320/735], Loss: 0.0498\n",
      "Epoch [35/50], Step [321/735], Loss: 0.0795\n",
      "Epoch [35/50], Step [322/735], Loss: 0.1471\n",
      "Epoch [35/50], Step [323/735], Loss: 0.0636\n",
      "Epoch [35/50], Step [324/735], Loss: 0.0602\n",
      "Epoch [35/50], Step [325/735], Loss: 0.0400\n",
      "Epoch [35/50], Step [326/735], Loss: 0.5146\n",
      "Epoch [35/50], Step [327/735], Loss: 0.1580\n",
      "Epoch [35/50], Step [328/735], Loss: 0.0649\n",
      "Epoch [35/50], Step [329/735], Loss: 0.0826\n",
      "Epoch [35/50], Step [330/735], Loss: 0.0482\n",
      "Epoch [35/50], Step [331/735], Loss: 0.1253\n",
      "Epoch [35/50], Step [332/735], Loss: 0.1022\n",
      "Epoch [35/50], Step [333/735], Loss: 0.1652\n",
      "Epoch [35/50], Step [334/735], Loss: 0.2198\n",
      "Epoch [35/50], Step [335/735], Loss: 0.0611\n",
      "Epoch [35/50], Step [336/735], Loss: 0.0610\n",
      "Epoch [35/50], Step [337/735], Loss: 0.0998\n",
      "Epoch [35/50], Step [338/735], Loss: 0.0320\n",
      "Epoch [35/50], Step [339/735], Loss: 0.0791\n",
      "Epoch [35/50], Step [340/735], Loss: 0.1270\n",
      "Epoch [35/50], Step [341/735], Loss: 0.1035\n",
      "Epoch [35/50], Step [342/735], Loss: 0.1624\n",
      "Epoch [35/50], Step [343/735], Loss: 0.0880\n",
      "Epoch [35/50], Step [344/735], Loss: 0.5589\n",
      "Epoch [35/50], Step [345/735], Loss: 0.1008\n",
      "Epoch [35/50], Step [346/735], Loss: 0.0870\n",
      "Epoch [35/50], Step [347/735], Loss: 0.2617\n",
      "Epoch [35/50], Step [348/735], Loss: 0.1354\n",
      "Epoch [35/50], Step [349/735], Loss: 0.0955\n",
      "Epoch [35/50], Step [350/735], Loss: 0.1747\n",
      "Epoch [35/50], Step [351/735], Loss: 0.0383\n",
      "Epoch [35/50], Step [352/735], Loss: 0.0945\n",
      "Epoch [35/50], Step [353/735], Loss: 0.1653\n",
      "Epoch [35/50], Step [354/735], Loss: 0.0436\n",
      "Epoch [35/50], Step [355/735], Loss: 0.1473\n",
      "Epoch [35/50], Step [356/735], Loss: 0.1023\n",
      "Epoch [35/50], Step [357/735], Loss: 0.5396\n",
      "Epoch [35/50], Step [358/735], Loss: 0.0903\n",
      "Epoch [35/50], Step [359/735], Loss: 0.1159\n",
      "Epoch [35/50], Step [360/735], Loss: 0.0888\n",
      "Epoch [35/50], Step [361/735], Loss: 0.0846\n",
      "Epoch [35/50], Step [362/735], Loss: 0.1400\n",
      "Epoch [35/50], Step [363/735], Loss: 0.1088\n",
      "Epoch [35/50], Step [364/735], Loss: 0.1080\n",
      "Epoch [35/50], Step [365/735], Loss: 0.0901\n",
      "Epoch [35/50], Step [366/735], Loss: 0.1092\n",
      "Epoch [35/50], Step [367/735], Loss: 0.0715\n",
      "Epoch [35/50], Step [368/735], Loss: 0.5918\n",
      "Epoch [35/50], Step [369/735], Loss: 0.1231\n",
      "Epoch [35/50], Step [370/735], Loss: 0.0881\n",
      "Epoch [35/50], Step [371/735], Loss: 0.1026\n",
      "Epoch [35/50], Step [372/735], Loss: 0.4874\n",
      "Epoch [35/50], Step [373/735], Loss: 0.3020\n",
      "Epoch [35/50], Step [374/735], Loss: 0.0842\n",
      "Epoch [35/50], Step [375/735], Loss: 0.1045\n",
      "Epoch [35/50], Step [376/735], Loss: 0.1881\n",
      "Epoch [35/50], Step [377/735], Loss: 0.2085\n",
      "Epoch [35/50], Step [378/735], Loss: 0.2411\n",
      "Epoch [35/50], Step [379/735], Loss: 0.1138\n",
      "Epoch [35/50], Step [380/735], Loss: 0.0808\n",
      "Epoch [35/50], Step [381/735], Loss: 0.1657\n",
      "Epoch [35/50], Step [382/735], Loss: 0.0781\n",
      "Epoch [35/50], Step [383/735], Loss: 0.0900\n",
      "Epoch [35/50], Step [384/735], Loss: 0.1388\n",
      "Epoch [35/50], Step [385/735], Loss: 0.2856\n",
      "Epoch [35/50], Step [386/735], Loss: 0.0663\n",
      "Epoch [35/50], Step [387/735], Loss: 0.1186\n",
      "Epoch [35/50], Step [388/735], Loss: 0.1333\n",
      "Epoch [35/50], Step [389/735], Loss: 0.0844\n",
      "Epoch [35/50], Step [390/735], Loss: 0.0466\n",
      "Epoch [35/50], Step [391/735], Loss: 0.0432\n",
      "Epoch [35/50], Step [392/735], Loss: 0.1134\n",
      "Epoch [35/50], Step [393/735], Loss: 0.0736\n",
      "Epoch [35/50], Step [394/735], Loss: 0.0982\n",
      "Epoch [35/50], Step [395/735], Loss: 0.0522\n",
      "Epoch [35/50], Step [396/735], Loss: 0.1156\n",
      "Epoch [35/50], Step [397/735], Loss: 0.2365\n",
      "Epoch [35/50], Step [398/735], Loss: 0.7644\n",
      "Epoch [35/50], Step [399/735], Loss: 0.0385\n",
      "Epoch [35/50], Step [400/735], Loss: 0.1023\n",
      "Epoch [35/50], Step [401/735], Loss: 0.1263\n",
      "Epoch [35/50], Step [402/735], Loss: 0.0546\n",
      "Epoch [35/50], Step [403/735], Loss: 0.0637\n",
      "Epoch [35/50], Step [404/735], Loss: 0.2287\n",
      "Epoch [35/50], Step [405/735], Loss: 0.0549\n",
      "Epoch [35/50], Step [406/735], Loss: 0.1745\n",
      "Epoch [35/50], Step [407/735], Loss: 0.0461\n",
      "Epoch [35/50], Step [408/735], Loss: 0.7861\n",
      "Epoch [35/50], Step [409/735], Loss: 0.5030\n",
      "Epoch [35/50], Step [410/735], Loss: 0.1881\n",
      "Epoch [35/50], Step [411/735], Loss: 0.0628\n",
      "Epoch [35/50], Step [412/735], Loss: 0.1761\n",
      "Epoch [35/50], Step [413/735], Loss: 0.0562\n",
      "Epoch [35/50], Step [414/735], Loss: 0.0708\n",
      "Epoch [35/50], Step [415/735], Loss: 0.0930\n",
      "Epoch [35/50], Step [416/735], Loss: 0.0656\n",
      "Epoch [35/50], Step [417/735], Loss: 0.1226\n",
      "Epoch [35/50], Step [418/735], Loss: 0.0699\n",
      "Epoch [35/50], Step [419/735], Loss: 0.0829\n",
      "Epoch [35/50], Step [420/735], Loss: 0.0356\n",
      "Epoch [35/50], Step [421/735], Loss: 0.0725\n",
      "Epoch [35/50], Step [422/735], Loss: 0.0642\n",
      "Epoch [35/50], Step [423/735], Loss: 0.2146\n",
      "Epoch [35/50], Step [424/735], Loss: 0.1175\n",
      "Epoch [35/50], Step [425/735], Loss: 0.0499\n",
      "Epoch [35/50], Step [426/735], Loss: 0.0870\n",
      "Epoch [35/50], Step [427/735], Loss: 0.1005\n",
      "Epoch [35/50], Step [428/735], Loss: 0.1029\n",
      "Epoch [35/50], Step [429/735], Loss: 0.0797\n",
      "Epoch [35/50], Step [430/735], Loss: 0.0304\n",
      "Epoch [35/50], Step [431/735], Loss: 0.0565\n",
      "Epoch [35/50], Step [432/735], Loss: 0.1520\n",
      "Epoch [35/50], Step [433/735], Loss: 0.1025\n",
      "Epoch [35/50], Step [434/735], Loss: 0.1100\n",
      "Epoch [35/50], Step [435/735], Loss: 0.1616\n",
      "Epoch [35/50], Step [436/735], Loss: 0.0519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Step [437/735], Loss: 0.1235\n",
      "Epoch [35/50], Step [438/735], Loss: 0.1202\n",
      "Epoch [35/50], Step [439/735], Loss: 0.0569\n",
      "Epoch [35/50], Step [440/735], Loss: 0.1216\n",
      "Epoch [35/50], Step [441/735], Loss: 0.0630\n",
      "Epoch [35/50], Step [442/735], Loss: 0.2230\n",
      "Epoch [35/50], Step [443/735], Loss: 0.0730\n",
      "Epoch [35/50], Step [444/735], Loss: 0.1035\n",
      "Epoch [35/50], Step [445/735], Loss: 0.2232\n",
      "Epoch [35/50], Step [446/735], Loss: 0.0637\n",
      "Epoch [35/50], Step [447/735], Loss: 0.3020\n",
      "Epoch [35/50], Step [448/735], Loss: 0.0711\n",
      "Epoch [35/50], Step [449/735], Loss: 0.0691\n",
      "Epoch [35/50], Step [450/735], Loss: 0.2840\n",
      "Epoch [35/50], Step [451/735], Loss: 0.0354\n",
      "Epoch [35/50], Step [452/735], Loss: 0.0738\n",
      "Epoch [35/50], Step [453/735], Loss: 0.0476\n",
      "Epoch [35/50], Step [454/735], Loss: 0.0527\n",
      "Epoch [35/50], Step [455/735], Loss: 0.0331\n",
      "Epoch [35/50], Step [456/735], Loss: 0.0889\n",
      "Epoch [35/50], Step [457/735], Loss: 0.0982\n",
      "Epoch [35/50], Step [458/735], Loss: 0.0980\n",
      "Epoch [35/50], Step [459/735], Loss: 0.0531\n",
      "Epoch [35/50], Step [460/735], Loss: 0.6738\n",
      "Epoch [35/50], Step [461/735], Loss: 0.0848\n",
      "Epoch [35/50], Step [462/735], Loss: 0.1419\n",
      "Epoch [35/50], Step [463/735], Loss: 0.0517\n",
      "Epoch [35/50], Step [464/735], Loss: 0.0505\n",
      "Epoch [35/50], Step [465/735], Loss: 0.1383\n",
      "Epoch [35/50], Step [466/735], Loss: 0.0840\n",
      "Epoch [35/50], Step [467/735], Loss: 0.1323\n",
      "Epoch [35/50], Step [468/735], Loss: 0.0718\n",
      "Epoch [35/50], Step [469/735], Loss: 0.0755\n",
      "Epoch [35/50], Step [470/735], Loss: 0.0824\n",
      "Epoch [35/50], Step [471/735], Loss: 0.0888\n",
      "Epoch [35/50], Step [472/735], Loss: 0.1414\n",
      "Epoch [35/50], Step [473/735], Loss: 0.8661\n",
      "Epoch [35/50], Step [474/735], Loss: 0.0827\n",
      "Epoch [35/50], Step [475/735], Loss: 0.0776\n",
      "Epoch [35/50], Step [476/735], Loss: 0.0597\n",
      "Epoch [35/50], Step [477/735], Loss: 0.0669\n",
      "Epoch [35/50], Step [478/735], Loss: 0.0631\n",
      "Epoch [35/50], Step [479/735], Loss: 0.3663\n",
      "Epoch [35/50], Step [480/735], Loss: 0.1367\n",
      "Epoch [35/50], Step [481/735], Loss: 0.1495\n",
      "Epoch [35/50], Step [482/735], Loss: 0.3082\n",
      "Epoch [35/50], Step [483/735], Loss: 0.0570\n",
      "Epoch [35/50], Step [484/735], Loss: 0.0893\n",
      "Epoch [35/50], Step [485/735], Loss: 0.1516\n",
      "Epoch [35/50], Step [486/735], Loss: 0.1269\n",
      "Epoch [35/50], Step [487/735], Loss: 0.0252\n",
      "Epoch [35/50], Step [488/735], Loss: 0.1484\n",
      "Epoch [35/50], Step [489/735], Loss: 0.0584\n",
      "Epoch [35/50], Step [490/735], Loss: 0.4498\n",
      "Epoch [35/50], Step [491/735], Loss: 0.2255\n",
      "Epoch [35/50], Step [492/735], Loss: 0.2784\n",
      "Epoch [35/50], Step [493/735], Loss: 0.0744\n",
      "Epoch [35/50], Step [494/735], Loss: 0.1847\n",
      "Epoch [35/50], Step [495/735], Loss: 0.1266\n",
      "Epoch [35/50], Step [496/735], Loss: 0.0978\n",
      "Epoch [35/50], Step [497/735], Loss: 0.2372\n",
      "Epoch [35/50], Step [498/735], Loss: 0.1564\n",
      "Epoch [35/50], Step [499/735], Loss: 0.0867\n",
      "Epoch [35/50], Step [500/735], Loss: 0.0623\n",
      "Epoch [35/50], Step [501/735], Loss: 0.1470\n",
      "Epoch [35/50], Step [502/735], Loss: 0.0837\n",
      "Epoch [35/50], Step [503/735], Loss: 0.1612\n",
      "Epoch [35/50], Step [504/735], Loss: 0.1729\n",
      "Epoch [35/50], Step [505/735], Loss: 0.0781\n",
      "Epoch [35/50], Step [506/735], Loss: 0.0805\n",
      "Epoch [35/50], Step [507/735], Loss: 0.0789\n",
      "Epoch [35/50], Step [508/735], Loss: 0.1246\n",
      "Epoch [35/50], Step [509/735], Loss: 0.0907\n",
      "Epoch [35/50], Step [510/735], Loss: 0.0454\n",
      "Epoch [35/50], Step [511/735], Loss: 0.0808\n",
      "Epoch [35/50], Step [512/735], Loss: 0.0992\n",
      "Epoch [35/50], Step [513/735], Loss: 0.0762\n",
      "Epoch [35/50], Step [514/735], Loss: 0.1090\n",
      "Epoch [35/50], Step [515/735], Loss: 0.0303\n",
      "Epoch [35/50], Step [516/735], Loss: 0.0801\n",
      "Epoch [35/50], Step [517/735], Loss: 0.1017\n",
      "Epoch [35/50], Step [518/735], Loss: 0.0895\n",
      "Epoch [35/50], Step [519/735], Loss: 0.0595\n",
      "Epoch [35/50], Step [520/735], Loss: 0.0900\n",
      "Epoch [35/50], Step [521/735], Loss: 0.0989\n",
      "Epoch [35/50], Step [522/735], Loss: 0.0806\n",
      "Epoch [35/50], Step [523/735], Loss: 0.5715\n",
      "Epoch [35/50], Step [524/735], Loss: 0.1881\n",
      "Epoch [35/50], Step [525/735], Loss: 0.1045\n",
      "Epoch [35/50], Step [526/735], Loss: 0.0517\n",
      "Epoch [35/50], Step [527/735], Loss: 0.0714\n",
      "Epoch [35/50], Step [528/735], Loss: 0.1825\n",
      "Epoch [35/50], Step [529/735], Loss: 0.1313\n",
      "Epoch [35/50], Step [530/735], Loss: 0.1110\n",
      "Epoch [35/50], Step [531/735], Loss: 0.0844\n",
      "Epoch [35/50], Step [532/735], Loss: 0.1531\n",
      "Epoch [35/50], Step [533/735], Loss: 0.2920\n",
      "Epoch [35/50], Step [534/735], Loss: 0.0966\n",
      "Epoch [35/50], Step [535/735], Loss: 0.0275\n",
      "Epoch [35/50], Step [536/735], Loss: 0.1001\n",
      "Epoch [35/50], Step [537/735], Loss: 0.0872\n",
      "Epoch [35/50], Step [538/735], Loss: 0.1999\n",
      "Epoch [35/50], Step [539/735], Loss: 0.1136\n",
      "Epoch [35/50], Step [540/735], Loss: 0.1174\n",
      "Epoch [35/50], Step [541/735], Loss: 0.1173\n",
      "Epoch [35/50], Step [542/735], Loss: 0.1067\n",
      "Epoch [35/50], Step [543/735], Loss: 0.1318\n",
      "Epoch [35/50], Step [544/735], Loss: 0.0496\n",
      "Epoch [35/50], Step [545/735], Loss: 0.3618\n",
      "Epoch [35/50], Step [546/735], Loss: 0.0451\n",
      "Epoch [35/50], Step [547/735], Loss: 0.0373\n",
      "Epoch [35/50], Step [548/735], Loss: 0.0977\n",
      "Epoch [35/50], Step [549/735], Loss: 0.0811\n",
      "Epoch [35/50], Step [550/735], Loss: 0.0502\n",
      "Epoch [35/50], Step [551/735], Loss: 0.0896\n",
      "Epoch [35/50], Step [552/735], Loss: 0.5194\n",
      "Epoch [35/50], Step [553/735], Loss: 0.0936\n",
      "Epoch [35/50], Step [554/735], Loss: 0.0484\n",
      "Epoch [35/50], Step [555/735], Loss: 0.0832\n",
      "Epoch [35/50], Step [556/735], Loss: 0.0495\n",
      "Epoch [35/50], Step [557/735], Loss: 0.1117\n",
      "Epoch [35/50], Step [558/735], Loss: 0.0641\n",
      "Epoch [35/50], Step [559/735], Loss: 0.0571\n",
      "Epoch [35/50], Step [560/735], Loss: 0.1196\n",
      "Epoch [35/50], Step [561/735], Loss: 0.0412\n",
      "Epoch [35/50], Step [562/735], Loss: 0.0363\n",
      "Epoch [35/50], Step [563/735], Loss: 0.0879\n",
      "Epoch [35/50], Step [564/735], Loss: 0.2067\n",
      "Epoch [35/50], Step [565/735], Loss: 0.0620\n",
      "Epoch [35/50], Step [566/735], Loss: 0.0455\n",
      "Epoch [35/50], Step [567/735], Loss: 0.0746\n",
      "Epoch [35/50], Step [568/735], Loss: 0.0872\n",
      "Epoch [35/50], Step [569/735], Loss: 0.1143\n",
      "Epoch [35/50], Step [570/735], Loss: 0.0400\n",
      "Epoch [35/50], Step [571/735], Loss: 0.0799\n",
      "Epoch [35/50], Step [572/735], Loss: 0.0682\n",
      "Epoch [35/50], Step [573/735], Loss: 0.0795\n",
      "Epoch [35/50], Step [574/735], Loss: 0.2050\n",
      "Epoch [35/50], Step [575/735], Loss: 0.0456\n",
      "Epoch [35/50], Step [576/735], Loss: 0.0467\n",
      "Epoch [35/50], Step [577/735], Loss: 0.0892\n",
      "Epoch [35/50], Step [578/735], Loss: 0.0910\n",
      "Epoch [35/50], Step [579/735], Loss: 0.5277\n",
      "Epoch [35/50], Step [580/735], Loss: 0.0772\n",
      "Epoch [35/50], Step [581/735], Loss: 0.1362\n",
      "Epoch [35/50], Step [582/735], Loss: 0.1087\n",
      "Epoch [35/50], Step [583/735], Loss: 0.1231\n",
      "Epoch [35/50], Step [584/735], Loss: 0.0685\n",
      "Epoch [35/50], Step [585/735], Loss: 0.1506\n",
      "Epoch [35/50], Step [586/735], Loss: 0.0819\n",
      "Epoch [35/50], Step [587/735], Loss: 0.4787\n",
      "Epoch [35/50], Step [588/735], Loss: 0.0727\n",
      "Epoch [35/50], Step [589/735], Loss: 0.1591\n",
      "Epoch [35/50], Step [590/735], Loss: 0.0982\n",
      "Epoch [35/50], Step [591/735], Loss: 0.1007\n",
      "Epoch [35/50], Step [592/735], Loss: 0.1921\n",
      "Epoch [35/50], Step [593/735], Loss: 0.5988\n",
      "Epoch [35/50], Step [594/735], Loss: 0.0418\n",
      "Epoch [35/50], Step [595/735], Loss: 0.1066\n",
      "Epoch [35/50], Step [596/735], Loss: 0.1152\n",
      "Epoch [35/50], Step [597/735], Loss: 1.7679\n",
      "Epoch [35/50], Step [598/735], Loss: 0.1570\n",
      "Epoch [35/50], Step [599/735], Loss: 0.1266\n",
      "Epoch [35/50], Step [600/735], Loss: 0.1447\n",
      "Epoch [35/50], Step [601/735], Loss: 0.1164\n",
      "Epoch [35/50], Step [602/735], Loss: 0.0476\n",
      "Epoch [35/50], Step [603/735], Loss: 0.2418\n",
      "Epoch [35/50], Step [604/735], Loss: 0.0844\n",
      "Epoch [35/50], Step [605/735], Loss: 0.1646\n",
      "Epoch [35/50], Step [606/735], Loss: 0.1209\n",
      "Epoch [35/50], Step [607/735], Loss: 0.0993\n",
      "Epoch [35/50], Step [608/735], Loss: 0.8471\n",
      "Epoch [35/50], Step [609/735], Loss: 0.0883\n",
      "Epoch [35/50], Step [610/735], Loss: 0.0878\n",
      "Epoch [35/50], Step [611/735], Loss: 0.0758\n",
      "Epoch [35/50], Step [612/735], Loss: 0.0661\n",
      "Epoch [35/50], Step [613/735], Loss: 0.0971\n",
      "Epoch [35/50], Step [614/735], Loss: 0.1646\n",
      "Epoch [35/50], Step [615/735], Loss: 0.0822\n",
      "Epoch [35/50], Step [616/735], Loss: 0.1032\n",
      "Epoch [35/50], Step [617/735], Loss: 0.1657\n",
      "Epoch [35/50], Step [618/735], Loss: 0.5740\n",
      "Epoch [35/50], Step [619/735], Loss: 0.2081\n",
      "Epoch [35/50], Step [620/735], Loss: 0.0531\n",
      "Epoch [35/50], Step [621/735], Loss: 0.0437\n",
      "Epoch [35/50], Step [622/735], Loss: 0.0567\n",
      "Epoch [35/50], Step [623/735], Loss: 0.0951\n",
      "Epoch [35/50], Step [624/735], Loss: 0.4709\n",
      "Epoch [35/50], Step [625/735], Loss: 0.1206\n",
      "Epoch [35/50], Step [626/735], Loss: 0.1795\n",
      "Epoch [35/50], Step [627/735], Loss: 0.3306\n",
      "Epoch [35/50], Step [628/735], Loss: 0.0823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Step [629/735], Loss: 0.2199\n",
      "Epoch [35/50], Step [630/735], Loss: 0.0368\n",
      "Epoch [35/50], Step [631/735], Loss: 0.0566\n",
      "Epoch [35/50], Step [632/735], Loss: 0.0970\n",
      "Epoch [35/50], Step [633/735], Loss: 0.0875\n",
      "Epoch [35/50], Step [634/735], Loss: 0.0593\n",
      "Epoch [35/50], Step [635/735], Loss: 0.1929\n",
      "Epoch [35/50], Step [636/735], Loss: 0.0379\n",
      "Epoch [35/50], Step [637/735], Loss: 0.0229\n",
      "Epoch [35/50], Step [638/735], Loss: 0.0666\n",
      "Epoch [35/50], Step [639/735], Loss: 0.0908\n",
      "Epoch [35/50], Step [640/735], Loss: 0.0518\n",
      "Epoch [35/50], Step [641/735], Loss: 0.1148\n",
      "Epoch [35/50], Step [642/735], Loss: 0.0334\n",
      "Epoch [35/50], Step [643/735], Loss: 0.0599\n",
      "Epoch [35/50], Step [644/735], Loss: 0.0575\n",
      "Epoch [35/50], Step [645/735], Loss: 0.1088\n",
      "Epoch [35/50], Step [646/735], Loss: 0.0613\n",
      "Epoch [35/50], Step [647/735], Loss: 0.2081\n",
      "Epoch [35/50], Step [648/735], Loss: 0.0647\n",
      "Epoch [35/50], Step [649/735], Loss: 0.4715\n",
      "Epoch [35/50], Step [650/735], Loss: 0.0845\n",
      "Epoch [35/50], Step [651/735], Loss: 0.0915\n",
      "Epoch [35/50], Step [652/735], Loss: 0.1519\n",
      "Epoch [35/50], Step [653/735], Loss: 0.0648\n",
      "Epoch [35/50], Step [654/735], Loss: 0.0537\n",
      "Epoch [35/50], Step [655/735], Loss: 0.0769\n",
      "Epoch [35/50], Step [656/735], Loss: 0.0804\n",
      "Epoch [35/50], Step [657/735], Loss: 0.0292\n",
      "Epoch [35/50], Step [658/735], Loss: 0.1373\n",
      "Epoch [35/50], Step [659/735], Loss: 0.0667\n",
      "Epoch [35/50], Step [660/735], Loss: 0.0400\n",
      "Epoch [35/50], Step [661/735], Loss: 0.0790\n",
      "Epoch [35/50], Step [662/735], Loss: 0.0433\n",
      "Epoch [35/50], Step [663/735], Loss: 0.2343\n",
      "Epoch [35/50], Step [664/735], Loss: 0.0578\n",
      "Epoch [35/50], Step [665/735], Loss: 0.0301\n",
      "Epoch [35/50], Step [666/735], Loss: 0.0373\n",
      "Epoch [35/50], Step [667/735], Loss: 0.1016\n",
      "Epoch [35/50], Step [668/735], Loss: 0.0898\n",
      "Epoch [35/50], Step [669/735], Loss: 0.0891\n",
      "Epoch [35/50], Step [670/735], Loss: 0.0742\n",
      "Epoch [35/50], Step [671/735], Loss: 0.2069\n",
      "Epoch [35/50], Step [672/735], Loss: 0.0330\n",
      "Epoch [35/50], Step [673/735], Loss: 0.0616\n",
      "Epoch [35/50], Step [674/735], Loss: 0.0981\n",
      "Epoch [35/50], Step [675/735], Loss: 0.2304\n",
      "Epoch [35/50], Step [676/735], Loss: 0.0590\n",
      "Epoch [35/50], Step [677/735], Loss: 0.1422\n",
      "Epoch [35/50], Step [678/735], Loss: 0.1563\n",
      "Epoch [35/50], Step [679/735], Loss: 0.1334\n",
      "Epoch [35/50], Step [680/735], Loss: 0.0799\n",
      "Epoch [35/50], Step [681/735], Loss: 0.4010\n",
      "Epoch [35/50], Step [682/735], Loss: 0.2691\n",
      "Epoch [35/50], Step [683/735], Loss: 0.1594\n",
      "Epoch [35/50], Step [684/735], Loss: 0.1251\n",
      "Epoch [35/50], Step [685/735], Loss: 0.0550\n",
      "Epoch [35/50], Step [686/735], Loss: 0.1189\n",
      "Epoch [35/50], Step [687/735], Loss: 0.0596\n",
      "Epoch [35/50], Step [688/735], Loss: 0.0927\n",
      "Epoch [35/50], Step [689/735], Loss: 0.1352\n",
      "Epoch [35/50], Step [690/735], Loss: 0.0764\n",
      "Epoch [35/50], Step [691/735], Loss: 0.1454\n",
      "Epoch [35/50], Step [692/735], Loss: 0.9218\n",
      "Epoch [35/50], Step [693/735], Loss: 0.0897\n",
      "Epoch [35/50], Step [694/735], Loss: 0.2470\n",
      "Epoch [35/50], Step [695/735], Loss: 0.0608\n",
      "Epoch [35/50], Step [696/735], Loss: 0.1178\n",
      "Epoch [35/50], Step [697/735], Loss: 0.1107\n",
      "Epoch [35/50], Step [698/735], Loss: 0.0946\n",
      "Epoch [35/50], Step [699/735], Loss: 0.0722\n",
      "Epoch [35/50], Step [700/735], Loss: 0.0584\n",
      "Epoch [35/50], Step [701/735], Loss: 0.0452\n",
      "Epoch [35/50], Step [702/735], Loss: 0.1089\n",
      "Epoch [35/50], Step [703/735], Loss: 0.0389\n",
      "Epoch [35/50], Step [704/735], Loss: 0.0317\n",
      "Epoch [35/50], Step [705/735], Loss: 0.1074\n",
      "Epoch [35/50], Step [706/735], Loss: 0.1115\n",
      "Epoch [35/50], Step [707/735], Loss: 1.7532\n",
      "Epoch [35/50], Step [708/735], Loss: 0.1189\n",
      "Epoch [35/50], Step [709/735], Loss: 0.0627\n",
      "Epoch [35/50], Step [710/735], Loss: 0.1588\n",
      "Epoch [35/50], Step [711/735], Loss: 0.1127\n",
      "Epoch [35/50], Step [712/735], Loss: 0.0387\n",
      "Epoch [35/50], Step [713/735], Loss: 0.0697\n",
      "Epoch [35/50], Step [714/735], Loss: 0.0525\n",
      "Epoch [35/50], Step [715/735], Loss: 0.1214\n",
      "Epoch [35/50], Step [716/735], Loss: 0.0834\n",
      "Epoch [35/50], Step [717/735], Loss: 0.0239\n",
      "Epoch [35/50], Step [718/735], Loss: 0.0784\n",
      "Epoch [35/50], Step [719/735], Loss: 0.4463\n",
      "Epoch [35/50], Step [720/735], Loss: 0.0314\n",
      "Epoch [35/50], Step [721/735], Loss: 0.0940\n",
      "Epoch [35/50], Step [722/735], Loss: 0.1518\n",
      "Epoch [35/50], Step [723/735], Loss: 0.1545\n",
      "Epoch [35/50], Step [724/735], Loss: 0.0634\n",
      "Epoch [35/50], Step [725/735], Loss: 0.0574\n",
      "Epoch [35/50], Step [726/735], Loss: 0.0415\n",
      "Epoch [35/50], Step [727/735], Loss: 0.1380\n",
      "Epoch [35/50], Step [728/735], Loss: 0.0504\n",
      "Epoch [35/50], Step [729/735], Loss: 0.1273\n",
      "Epoch [35/50], Step [730/735], Loss: 0.1742\n",
      "Epoch [35/50], Step [731/735], Loss: 0.1882\n",
      "Epoch [35/50], Step [732/735], Loss: 0.0221\n",
      "Epoch [35/50], Step [733/735], Loss: 0.1361\n",
      "Epoch [35/50], Step [734/735], Loss: 0.1164\n",
      "Epoch [35/50], Step [735/735], Loss: 0.0836\n",
      "Epoch [36/50], Step [1/735], Loss: 1.6427\n",
      "Epoch [36/50], Step [2/735], Loss: 0.0582\n",
      "Epoch [36/50], Step [3/735], Loss: 0.0737\n",
      "Epoch [36/50], Step [4/735], Loss: 0.1202\n",
      "Epoch [36/50], Step [5/735], Loss: 0.0479\n",
      "Epoch [36/50], Step [6/735], Loss: 0.0392\n",
      "Epoch [36/50], Step [7/735], Loss: 0.0295\n",
      "Epoch [36/50], Step [8/735], Loss: 0.1145\n",
      "Epoch [36/50], Step [9/735], Loss: 0.0778\n",
      "Epoch [36/50], Step [10/735], Loss: 0.0956\n",
      "Epoch [36/50], Step [11/735], Loss: 0.0383\n",
      "Epoch [36/50], Step [12/735], Loss: 0.1285\n",
      "Epoch [36/50], Step [13/735], Loss: 0.0956\n",
      "Epoch [36/50], Step [14/735], Loss: 0.0619\n",
      "Epoch [36/50], Step [15/735], Loss: 0.1188\n",
      "Epoch [36/50], Step [16/735], Loss: 0.0708\n",
      "Epoch [36/50], Step [17/735], Loss: 0.0505\n",
      "Epoch [36/50], Step [18/735], Loss: 0.0499\n",
      "Epoch [36/50], Step [19/735], Loss: 0.1545\n",
      "Epoch [36/50], Step [20/735], Loss: 0.0847\n",
      "Epoch [36/50], Step [21/735], Loss: 0.0886\n",
      "Epoch [36/50], Step [22/735], Loss: 0.1281\n",
      "Epoch [36/50], Step [23/735], Loss: 0.1587\n",
      "Epoch [36/50], Step [24/735], Loss: 0.0582\n",
      "Epoch [36/50], Step [25/735], Loss: 0.1188\n",
      "Epoch [36/50], Step [26/735], Loss: 0.0850\n",
      "Epoch [36/50], Step [27/735], Loss: 0.0828\n",
      "Epoch [36/50], Step [28/735], Loss: 0.0839\n",
      "Epoch [36/50], Step [29/735], Loss: 0.0442\n",
      "Epoch [36/50], Step [30/735], Loss: 0.0703\n",
      "Epoch [36/50], Step [31/735], Loss: 0.0755\n",
      "Epoch [36/50], Step [32/735], Loss: 0.1997\n",
      "Epoch [36/50], Step [33/735], Loss: 0.1499\n",
      "Epoch [36/50], Step [34/735], Loss: 0.0667\n",
      "Epoch [36/50], Step [35/735], Loss: 0.0614\n",
      "Epoch [36/50], Step [36/735], Loss: 0.0664\n",
      "Epoch [36/50], Step [37/735], Loss: 0.0887\n",
      "Epoch [36/50], Step [38/735], Loss: 0.0453\n",
      "Epoch [36/50], Step [39/735], Loss: 0.1098\n",
      "Epoch [36/50], Step [40/735], Loss: 0.0766\n",
      "Epoch [36/50], Step [41/735], Loss: 0.0238\n",
      "Epoch [36/50], Step [42/735], Loss: 0.0688\n",
      "Epoch [36/50], Step [43/735], Loss: 0.0764\n",
      "Epoch [36/50], Step [44/735], Loss: 0.0589\n",
      "Epoch [36/50], Step [45/735], Loss: 0.1191\n",
      "Epoch [36/50], Step [46/735], Loss: 0.1605\n",
      "Epoch [36/50], Step [47/735], Loss: 0.1650\n",
      "Epoch [36/50], Step [48/735], Loss: 0.1037\n",
      "Epoch [36/50], Step [49/735], Loss: 0.0509\n",
      "Epoch [36/50], Step [50/735], Loss: 0.0515\n",
      "Epoch [36/50], Step [51/735], Loss: 0.0869\n",
      "Epoch [36/50], Step [52/735], Loss: 0.0939\n",
      "Epoch [36/50], Step [53/735], Loss: 0.0686\n",
      "Epoch [36/50], Step [54/735], Loss: 0.0903\n",
      "Epoch [36/50], Step [55/735], Loss: 0.2283\n",
      "Epoch [36/50], Step [56/735], Loss: 0.1229\n",
      "Epoch [36/50], Step [57/735], Loss: 0.0529\n",
      "Epoch [36/50], Step [58/735], Loss: 0.0846\n",
      "Epoch [36/50], Step [59/735], Loss: 0.2319\n",
      "Epoch [36/50], Step [60/735], Loss: 0.0620\n",
      "Epoch [36/50], Step [61/735], Loss: 0.1751\n",
      "Epoch [36/50], Step [62/735], Loss: 0.1030\n",
      "Epoch [36/50], Step [63/735], Loss: 0.0729\n",
      "Epoch [36/50], Step [64/735], Loss: 0.0960\n",
      "Epoch [36/50], Step [65/735], Loss: 0.1781\n",
      "Epoch [36/50], Step [66/735], Loss: 0.0776\n",
      "Epoch [36/50], Step [67/735], Loss: 0.0934\n",
      "Epoch [36/50], Step [68/735], Loss: 0.0585\n",
      "Epoch [36/50], Step [69/735], Loss: 0.0717\n",
      "Epoch [36/50], Step [70/735], Loss: 0.0672\n",
      "Epoch [36/50], Step [71/735], Loss: 0.1169\n",
      "Epoch [36/50], Step [72/735], Loss: 0.0777\n",
      "Epoch [36/50], Step [73/735], Loss: 0.7770\n",
      "Epoch [36/50], Step [74/735], Loss: 0.1169\n",
      "Epoch [36/50], Step [75/735], Loss: 0.0472\n",
      "Epoch [36/50], Step [76/735], Loss: 0.1699\n",
      "Epoch [36/50], Step [77/735], Loss: 0.0894\n",
      "Epoch [36/50], Step [78/735], Loss: 0.2074\n",
      "Epoch [36/50], Step [79/735], Loss: 0.0957\n",
      "Epoch [36/50], Step [80/735], Loss: 0.1528\n",
      "Epoch [36/50], Step [81/735], Loss: 0.5113\n",
      "Epoch [36/50], Step [82/735], Loss: 0.2947\n",
      "Epoch [36/50], Step [83/735], Loss: 0.2122\n",
      "Epoch [36/50], Step [84/735], Loss: 0.1635\n",
      "Epoch [36/50], Step [85/735], Loss: 0.0625\n",
      "Epoch [36/50], Step [86/735], Loss: 0.0728\n",
      "Epoch [36/50], Step [87/735], Loss: 0.1658\n",
      "Epoch [36/50], Step [88/735], Loss: 0.0999\n",
      "Epoch [36/50], Step [89/735], Loss: 0.4626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Step [90/735], Loss: 0.0718\n",
      "Epoch [36/50], Step [91/735], Loss: 0.3876\n",
      "Epoch [36/50], Step [92/735], Loss: 0.0400\n",
      "Epoch [36/50], Step [93/735], Loss: 0.2063\n",
      "Epoch [36/50], Step [94/735], Loss: 0.0621\n",
      "Epoch [36/50], Step [95/735], Loss: 0.1005\n",
      "Epoch [36/50], Step [96/735], Loss: 0.1463\n",
      "Epoch [36/50], Step [97/735], Loss: 2.2427\n",
      "Epoch [36/50], Step [98/735], Loss: 0.0842\n",
      "Epoch [36/50], Step [99/735], Loss: 0.0957\n",
      "Epoch [36/50], Step [100/735], Loss: 0.1161\n",
      "Epoch [36/50], Step [101/735], Loss: 0.1253\n",
      "Epoch [36/50], Step [102/735], Loss: 0.1285\n",
      "Epoch [36/50], Step [103/735], Loss: 0.0824\n",
      "Epoch [36/50], Step [104/735], Loss: 0.1505\n",
      "Epoch [36/50], Step [105/735], Loss: 0.0542\n",
      "Epoch [36/50], Step [106/735], Loss: 0.0503\n",
      "Epoch [36/50], Step [107/735], Loss: 0.9796\n",
      "Epoch [36/50], Step [108/735], Loss: 0.1183\n",
      "Epoch [36/50], Step [109/735], Loss: 0.1572\n",
      "Epoch [36/50], Step [110/735], Loss: 0.0487\n",
      "Epoch [36/50], Step [111/735], Loss: 0.1250\n",
      "Epoch [36/50], Step [112/735], Loss: 0.0782\n",
      "Epoch [36/50], Step [113/735], Loss: 0.0805\n",
      "Epoch [36/50], Step [114/735], Loss: 0.1258\n",
      "Epoch [36/50], Step [115/735], Loss: 0.2001\n",
      "Epoch [36/50], Step [116/735], Loss: 0.1927\n",
      "Epoch [36/50], Step [117/735], Loss: 0.2117\n",
      "Epoch [36/50], Step [118/735], Loss: 0.0940\n",
      "Epoch [36/50], Step [119/735], Loss: 0.2111\n",
      "Epoch [36/50], Step [120/735], Loss: 0.1910\n",
      "Epoch [36/50], Step [121/735], Loss: 0.1521\n",
      "Epoch [36/50], Step [122/735], Loss: 0.0837\n",
      "Epoch [36/50], Step [123/735], Loss: 0.0393\n",
      "Epoch [36/50], Step [124/735], Loss: 0.0411\n",
      "Epoch [36/50], Step [125/735], Loss: 0.0420\n",
      "Epoch [36/50], Step [126/735], Loss: 0.1645\n",
      "Epoch [36/50], Step [127/735], Loss: 0.0469\n",
      "Epoch [36/50], Step [128/735], Loss: 0.0763\n",
      "Epoch [36/50], Step [129/735], Loss: 0.0244\n",
      "Epoch [36/50], Step [130/735], Loss: 0.0456\n",
      "Epoch [36/50], Step [131/735], Loss: 0.0811\n",
      "Epoch [36/50], Step [132/735], Loss: 0.0937\n",
      "Epoch [36/50], Step [133/735], Loss: 0.0266\n",
      "Epoch [36/50], Step [134/735], Loss: 0.0811\n",
      "Epoch [36/50], Step [135/735], Loss: 0.1287\n",
      "Epoch [36/50], Step [136/735], Loss: 0.3356\n",
      "Epoch [36/50], Step [137/735], Loss: 0.1296\n",
      "Epoch [36/50], Step [138/735], Loss: 0.1627\n",
      "Epoch [36/50], Step [139/735], Loss: 0.1087\n",
      "Epoch [36/50], Step [140/735], Loss: 0.1687\n",
      "Epoch [36/50], Step [141/735], Loss: 0.0863\n",
      "Epoch [36/50], Step [142/735], Loss: 1.0054\n",
      "Epoch [36/50], Step [143/735], Loss: 0.0522\n",
      "Epoch [36/50], Step [144/735], Loss: 0.0551\n",
      "Epoch [36/50], Step [145/735], Loss: 0.1281\n",
      "Epoch [36/50], Step [146/735], Loss: 0.2549\n",
      "Epoch [36/50], Step [147/735], Loss: 0.0558\n",
      "Epoch [36/50], Step [148/735], Loss: 0.0752\n",
      "Epoch [36/50], Step [149/735], Loss: 0.0908\n",
      "Epoch [36/50], Step [150/735], Loss: 0.2062\n",
      "Epoch [36/50], Step [151/735], Loss: 0.2165\n",
      "Epoch [36/50], Step [152/735], Loss: 0.0480\n",
      "Epoch [36/50], Step [153/735], Loss: 0.1076\n",
      "Epoch [36/50], Step [154/735], Loss: 0.0559\n",
      "Epoch [36/50], Step [155/735], Loss: 0.0487\n",
      "Epoch [36/50], Step [156/735], Loss: 0.1183\n",
      "Epoch [36/50], Step [157/735], Loss: 0.1382\n",
      "Epoch [36/50], Step [158/735], Loss: 0.0761\n",
      "Epoch [36/50], Step [159/735], Loss: 0.1195\n",
      "Epoch [36/50], Step [160/735], Loss: 0.1540\n",
      "Epoch [36/50], Step [161/735], Loss: 0.1139\n",
      "Epoch [36/50], Step [162/735], Loss: 0.0767\n",
      "Epoch [36/50], Step [163/735], Loss: 0.1416\n",
      "Epoch [36/50], Step [164/735], Loss: 0.0987\n",
      "Epoch [36/50], Step [165/735], Loss: 0.1098\n",
      "Epoch [36/50], Step [166/735], Loss: 0.0224\n",
      "Epoch [36/50], Step [167/735], Loss: 0.1374\n",
      "Epoch [36/50], Step [168/735], Loss: 0.7802\n",
      "Epoch [36/50], Step [169/735], Loss: 0.0821\n",
      "Epoch [36/50], Step [170/735], Loss: 0.1632\n",
      "Epoch [36/50], Step [171/735], Loss: 0.1878\n",
      "Epoch [36/50], Step [172/735], Loss: 0.1351\n",
      "Epoch [36/50], Step [173/735], Loss: 0.0637\n",
      "Epoch [36/50], Step [174/735], Loss: 0.1817\n",
      "Epoch [36/50], Step [175/735], Loss: 0.0958\n",
      "Epoch [36/50], Step [176/735], Loss: 0.0885\n",
      "Epoch [36/50], Step [177/735], Loss: 0.1481\n",
      "Epoch [36/50], Step [178/735], Loss: 0.1045\n",
      "Epoch [36/50], Step [179/735], Loss: 0.1776\n",
      "Epoch [36/50], Step [180/735], Loss: 0.0637\n",
      "Epoch [36/50], Step [181/735], Loss: 0.0744\n",
      "Epoch [36/50], Step [182/735], Loss: 0.0336\n",
      "Epoch [36/50], Step [183/735], Loss: 0.0407\n",
      "Epoch [36/50], Step [184/735], Loss: 0.0925\n",
      "Epoch [36/50], Step [185/735], Loss: 0.1227\n",
      "Epoch [36/50], Step [186/735], Loss: 0.0684\n",
      "Epoch [36/50], Step [187/735], Loss: 0.0636\n",
      "Epoch [36/50], Step [188/735], Loss: 0.1156\n",
      "Epoch [36/50], Step [189/735], Loss: 0.1360\n",
      "Epoch [36/50], Step [190/735], Loss: 0.0918\n",
      "Epoch [36/50], Step [191/735], Loss: 0.0986\n",
      "Epoch [36/50], Step [192/735], Loss: 0.0449\n",
      "Epoch [36/50], Step [193/735], Loss: 0.1096\n",
      "Epoch [36/50], Step [194/735], Loss: 0.1064\n",
      "Epoch [36/50], Step [195/735], Loss: 0.0249\n",
      "Epoch [36/50], Step [196/735], Loss: 0.1252\n",
      "Epoch [36/50], Step [197/735], Loss: 0.0511\n",
      "Epoch [36/50], Step [198/735], Loss: 0.0690\n",
      "Epoch [36/50], Step [199/735], Loss: 0.0728\n",
      "Epoch [36/50], Step [200/735], Loss: 0.3888\n",
      "Epoch [36/50], Step [201/735], Loss: 0.1500\n",
      "Epoch [36/50], Step [202/735], Loss: 0.0396\n",
      "Epoch [36/50], Step [203/735], Loss: 0.0874\n",
      "Epoch [36/50], Step [204/735], Loss: 0.0615\n",
      "Epoch [36/50], Step [205/735], Loss: 0.1019\n",
      "Epoch [36/50], Step [206/735], Loss: 0.0309\n",
      "Epoch [36/50], Step [207/735], Loss: 0.0734\n",
      "Epoch [36/50], Step [208/735], Loss: 0.1326\n",
      "Epoch [36/50], Step [209/735], Loss: 0.1010\n",
      "Epoch [36/50], Step [210/735], Loss: 0.0871\n",
      "Epoch [36/50], Step [211/735], Loss: 0.0991\n",
      "Epoch [36/50], Step [212/735], Loss: 0.0245\n",
      "Epoch [36/50], Step [213/735], Loss: 0.0478\n",
      "Epoch [36/50], Step [214/735], Loss: 0.3953\n",
      "Epoch [36/50], Step [215/735], Loss: 0.0736\n",
      "Epoch [36/50], Step [216/735], Loss: 0.0628\n",
      "Epoch [36/50], Step [217/735], Loss: 0.0993\n",
      "Epoch [36/50], Step [218/735], Loss: 0.2401\n",
      "Epoch [36/50], Step [219/735], Loss: 0.1019\n",
      "Epoch [36/50], Step [220/735], Loss: 0.2056\n",
      "Epoch [36/50], Step [221/735], Loss: 0.0642\n",
      "Epoch [36/50], Step [222/735], Loss: 0.0613\n",
      "Epoch [36/50], Step [223/735], Loss: 0.0988\n",
      "Epoch [36/50], Step [224/735], Loss: 0.0784\n",
      "Epoch [36/50], Step [225/735], Loss: 0.0638\n",
      "Epoch [36/50], Step [226/735], Loss: 0.0939\n",
      "Epoch [36/50], Step [227/735], Loss: 0.1133\n",
      "Epoch [36/50], Step [228/735], Loss: 0.2194\n",
      "Epoch [36/50], Step [229/735], Loss: 0.0722\n",
      "Epoch [36/50], Step [230/735], Loss: 0.0565\n",
      "Epoch [36/50], Step [231/735], Loss: 0.1398\n",
      "Epoch [36/50], Step [232/735], Loss: 0.0527\n",
      "Epoch [36/50], Step [233/735], Loss: 0.3563\n",
      "Epoch [36/50], Step [234/735], Loss: 0.0694\n",
      "Epoch [36/50], Step [235/735], Loss: 0.0798\n",
      "Epoch [36/50], Step [236/735], Loss: 0.0287\n",
      "Epoch [36/50], Step [237/735], Loss: 0.1920\n",
      "Epoch [36/50], Step [238/735], Loss: 0.0688\n",
      "Epoch [36/50], Step [239/735], Loss: 0.0853\n",
      "Epoch [36/50], Step [240/735], Loss: 0.0678\n",
      "Epoch [36/50], Step [241/735], Loss: 0.0840\n",
      "Epoch [36/50], Step [242/735], Loss: 0.1160\n",
      "Epoch [36/50], Step [243/735], Loss: 0.0843\n",
      "Epoch [36/50], Step [244/735], Loss: 0.0808\n",
      "Epoch [36/50], Step [245/735], Loss: 0.0845\n",
      "Epoch [36/50], Step [246/735], Loss: 0.1445\n",
      "Epoch [36/50], Step [247/735], Loss: 0.0583\n",
      "Epoch [36/50], Step [248/735], Loss: 0.0555\n",
      "Epoch [36/50], Step [249/735], Loss: 0.1208\n",
      "Epoch [36/50], Step [250/735], Loss: 0.3508\n",
      "Epoch [36/50], Step [251/735], Loss: 0.1072\n",
      "Epoch [36/50], Step [252/735], Loss: 0.0526\n",
      "Epoch [36/50], Step [253/735], Loss: 0.1087\n",
      "Epoch [36/50], Step [254/735], Loss: 0.1134\n",
      "Epoch [36/50], Step [255/735], Loss: 0.0563\n",
      "Epoch [36/50], Step [256/735], Loss: 0.1494\n",
      "Epoch [36/50], Step [257/735], Loss: 0.0635\n",
      "Epoch [36/50], Step [258/735], Loss: 0.0484\n",
      "Epoch [36/50], Step [259/735], Loss: 0.0646\n",
      "Epoch [36/50], Step [260/735], Loss: 0.0691\n",
      "Epoch [36/50], Step [261/735], Loss: 0.1126\n",
      "Epoch [36/50], Step [262/735], Loss: 0.0363\n",
      "Epoch [36/50], Step [263/735], Loss: 0.0954\n",
      "Epoch [36/50], Step [264/735], Loss: 0.1037\n",
      "Epoch [36/50], Step [265/735], Loss: 0.0957\n",
      "Epoch [36/50], Step [266/735], Loss: 0.3969\n",
      "Epoch [36/50], Step [267/735], Loss: 0.1273\n",
      "Epoch [36/50], Step [268/735], Loss: 0.1267\n",
      "Epoch [36/50], Step [269/735], Loss: 0.1735\n",
      "Epoch [36/50], Step [270/735], Loss: 0.0819\n",
      "Epoch [36/50], Step [271/735], Loss: 0.1001\n",
      "Epoch [36/50], Step [272/735], Loss: 0.2290\n",
      "Epoch [36/50], Step [273/735], Loss: 0.0978\n",
      "Epoch [36/50], Step [274/735], Loss: 0.0951\n",
      "Epoch [36/50], Step [275/735], Loss: 0.0745\n",
      "Epoch [36/50], Step [276/735], Loss: 0.0743\n",
      "Epoch [36/50], Step [277/735], Loss: 0.0451\n",
      "Epoch [36/50], Step [278/735], Loss: 0.2459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Step [279/735], Loss: 0.0783\n",
      "Epoch [36/50], Step [280/735], Loss: 0.0470\n",
      "Epoch [36/50], Step [281/735], Loss: 0.0497\n",
      "Epoch [36/50], Step [282/735], Loss: 0.0888\n",
      "Epoch [36/50], Step [283/735], Loss: 0.1728\n",
      "Epoch [36/50], Step [284/735], Loss: 0.6359\n",
      "Epoch [36/50], Step [285/735], Loss: 0.0542\n",
      "Epoch [36/50], Step [286/735], Loss: 0.1784\n",
      "Epoch [36/50], Step [287/735], Loss: 0.0960\n",
      "Epoch [36/50], Step [288/735], Loss: 0.1641\n",
      "Epoch [36/50], Step [289/735], Loss: 0.1176\n",
      "Epoch [36/50], Step [290/735], Loss: 0.0750\n",
      "Epoch [36/50], Step [291/735], Loss: 0.1159\n",
      "Epoch [36/50], Step [292/735], Loss: 0.0819\n",
      "Epoch [36/50], Step [293/735], Loss: 0.1023\n",
      "Epoch [36/50], Step [294/735], Loss: 0.1928\n",
      "Epoch [36/50], Step [295/735], Loss: 0.1103\n",
      "Epoch [36/50], Step [296/735], Loss: 0.1018\n",
      "Epoch [36/50], Step [297/735], Loss: 0.0753\n",
      "Epoch [36/50], Step [298/735], Loss: 0.1336\n",
      "Epoch [36/50], Step [299/735], Loss: 0.1853\n",
      "Epoch [36/50], Step [300/735], Loss: 0.0620\n",
      "Epoch [36/50], Step [301/735], Loss: 0.1197\n",
      "Epoch [36/50], Step [302/735], Loss: 0.1732\n",
      "Epoch [36/50], Step [303/735], Loss: 0.1428\n",
      "Epoch [36/50], Step [304/735], Loss: 0.1351\n",
      "Epoch [36/50], Step [305/735], Loss: 0.1360\n",
      "Epoch [36/50], Step [306/735], Loss: 0.1574\n",
      "Epoch [36/50], Step [307/735], Loss: 0.0952\n",
      "Epoch [36/50], Step [308/735], Loss: 0.0692\n",
      "Epoch [36/50], Step [309/735], Loss: 1.0272\n",
      "Epoch [36/50], Step [310/735], Loss: 0.1217\n",
      "Epoch [36/50], Step [311/735], Loss: 0.0732\n",
      "Epoch [36/50], Step [312/735], Loss: 0.1619\n",
      "Epoch [36/50], Step [313/735], Loss: 0.1761\n",
      "Epoch [36/50], Step [314/735], Loss: 0.0771\n",
      "Epoch [36/50], Step [315/735], Loss: 1.2675\n",
      "Epoch [36/50], Step [316/735], Loss: 0.0718\n",
      "Epoch [36/50], Step [317/735], Loss: 0.1564\n",
      "Epoch [36/50], Step [318/735], Loss: 0.0355\n",
      "Epoch [36/50], Step [319/735], Loss: 0.2253\n",
      "Epoch [36/50], Step [320/735], Loss: 0.0632\n",
      "Epoch [36/50], Step [321/735], Loss: 0.1428\n",
      "Epoch [36/50], Step [322/735], Loss: 0.1687\n",
      "Epoch [36/50], Step [323/735], Loss: 0.0728\n",
      "Epoch [36/50], Step [324/735], Loss: 0.1522\n",
      "Epoch [36/50], Step [325/735], Loss: 0.1467\n",
      "Epoch [36/50], Step [326/735], Loss: 0.0751\n",
      "Epoch [36/50], Step [327/735], Loss: 0.1795\n",
      "Epoch [36/50], Step [328/735], Loss: 0.0955\n",
      "Epoch [36/50], Step [329/735], Loss: 0.0552\n",
      "Epoch [36/50], Step [330/735], Loss: 0.0817\n",
      "Epoch [36/50], Step [331/735], Loss: 0.2788\n",
      "Epoch [36/50], Step [332/735], Loss: 0.0697\n",
      "Epoch [36/50], Step [333/735], Loss: 0.0303\n",
      "Epoch [36/50], Step [334/735], Loss: 0.1235\n",
      "Epoch [36/50], Step [335/735], Loss: 0.0735\n",
      "Epoch [36/50], Step [336/735], Loss: 0.7806\n",
      "Epoch [36/50], Step [337/735], Loss: 0.0672\n",
      "Epoch [36/50], Step [338/735], Loss: 0.1559\n",
      "Epoch [36/50], Step [339/735], Loss: 0.0804\n",
      "Epoch [36/50], Step [340/735], Loss: 0.0367\n",
      "Epoch [36/50], Step [341/735], Loss: 0.0846\n",
      "Epoch [36/50], Step [342/735], Loss: 0.0764\n",
      "Epoch [36/50], Step [343/735], Loss: 0.1088\n",
      "Epoch [36/50], Step [344/735], Loss: 0.1555\n",
      "Epoch [36/50], Step [345/735], Loss: 0.1340\n",
      "Epoch [36/50], Step [346/735], Loss: 0.2014\n",
      "Epoch [36/50], Step [347/735], Loss: 0.0621\n",
      "Epoch [36/50], Step [348/735], Loss: 0.0898\n",
      "Epoch [36/50], Step [349/735], Loss: 0.0786\n",
      "Epoch [36/50], Step [350/735], Loss: 0.1052\n",
      "Epoch [36/50], Step [351/735], Loss: 0.2229\n",
      "Epoch [36/50], Step [352/735], Loss: 0.1344\n",
      "Epoch [36/50], Step [353/735], Loss: 0.1051\n",
      "Epoch [36/50], Step [354/735], Loss: 0.0646\n",
      "Epoch [36/50], Step [355/735], Loss: 0.1143\n",
      "Epoch [36/50], Step [356/735], Loss: 0.1110\n",
      "Epoch [36/50], Step [357/735], Loss: 0.0422\n",
      "Epoch [36/50], Step [358/735], Loss: 0.0550\n",
      "Epoch [36/50], Step [359/735], Loss: 0.0939\n",
      "Epoch [36/50], Step [360/735], Loss: 0.0642\n",
      "Epoch [36/50], Step [361/735], Loss: 0.0483\n",
      "Epoch [36/50], Step [362/735], Loss: 0.0729\n",
      "Epoch [36/50], Step [363/735], Loss: 0.0696\n",
      "Epoch [36/50], Step [364/735], Loss: 0.0617\n",
      "Epoch [36/50], Step [365/735], Loss: 0.3037\n",
      "Epoch [36/50], Step [366/735], Loss: 0.0593\n",
      "Epoch [36/50], Step [367/735], Loss: 0.0547\n",
      "Epoch [36/50], Step [368/735], Loss: 0.3387\n",
      "Epoch [36/50], Step [369/735], Loss: 0.0812\n",
      "Epoch [36/50], Step [370/735], Loss: 0.0502\n",
      "Epoch [36/50], Step [371/735], Loss: 0.0831\n",
      "Epoch [36/50], Step [372/735], Loss: 0.1460\n",
      "Epoch [36/50], Step [373/735], Loss: 0.0565\n",
      "Epoch [36/50], Step [374/735], Loss: 0.0934\n",
      "Epoch [36/50], Step [375/735], Loss: 0.0802\n",
      "Epoch [36/50], Step [376/735], Loss: 0.0706\n",
      "Epoch [36/50], Step [377/735], Loss: 0.1054\n",
      "Epoch [36/50], Step [378/735], Loss: 0.6518\n",
      "Epoch [36/50], Step [379/735], Loss: 0.0719\n",
      "Epoch [36/50], Step [380/735], Loss: 0.1406\n",
      "Epoch [36/50], Step [381/735], Loss: 0.1448\n",
      "Epoch [36/50], Step [382/735], Loss: 0.1090\n",
      "Epoch [36/50], Step [383/735], Loss: 0.0537\n",
      "Epoch [36/50], Step [384/735], Loss: 0.0411\n",
      "Epoch [36/50], Step [385/735], Loss: 0.0632\n",
      "Epoch [36/50], Step [386/735], Loss: 0.0460\n",
      "Epoch [36/50], Step [387/735], Loss: 0.1186\n",
      "Epoch [36/50], Step [388/735], Loss: 0.1523\n",
      "Epoch [36/50], Step [389/735], Loss: 0.0978\n",
      "Epoch [36/50], Step [390/735], Loss: 0.0640\n",
      "Epoch [36/50], Step [391/735], Loss: 0.0452\n",
      "Epoch [36/50], Step [392/735], Loss: 0.1147\n",
      "Epoch [36/50], Step [393/735], Loss: 0.0455\n",
      "Epoch [36/50], Step [394/735], Loss: 0.0286\n",
      "Epoch [36/50], Step [395/735], Loss: 0.0564\n",
      "Epoch [36/50], Step [396/735], Loss: 0.0837\n",
      "Epoch [36/50], Step [397/735], Loss: 0.0908\n",
      "Epoch [36/50], Step [398/735], Loss: 0.0740\n",
      "Epoch [36/50], Step [399/735], Loss: 0.0272\n",
      "Epoch [36/50], Step [400/735], Loss: 0.0467\n",
      "Epoch [36/50], Step [401/735], Loss: 0.1007\n",
      "Epoch [36/50], Step [402/735], Loss: 0.1165\n",
      "Epoch [36/50], Step [403/735], Loss: 0.1336\n",
      "Epoch [36/50], Step [404/735], Loss: 0.0954\n",
      "Epoch [36/50], Step [405/735], Loss: 0.0453\n",
      "Epoch [36/50], Step [406/735], Loss: 0.1473\n",
      "Epoch [36/50], Step [407/735], Loss: 0.1133\n",
      "Epoch [36/50], Step [408/735], Loss: 0.0429\n",
      "Epoch [36/50], Step [409/735], Loss: 0.1072\n",
      "Epoch [36/50], Step [410/735], Loss: 0.1429\n",
      "Epoch [36/50], Step [411/735], Loss: 0.0506\n",
      "Epoch [36/50], Step [412/735], Loss: 0.0499\n",
      "Epoch [36/50], Step [413/735], Loss: 0.1075\n",
      "Epoch [36/50], Step [414/735], Loss: 0.0577\n",
      "Epoch [36/50], Step [415/735], Loss: 0.2299\n",
      "Epoch [36/50], Step [416/735], Loss: 0.1379\n",
      "Epoch [36/50], Step [417/735], Loss: 0.1103\n",
      "Epoch [36/50], Step [418/735], Loss: 0.1036\n",
      "Epoch [36/50], Step [419/735], Loss: 0.2153\n",
      "Epoch [36/50], Step [420/735], Loss: 0.1115\n",
      "Epoch [36/50], Step [421/735], Loss: 0.1932\n",
      "Epoch [36/50], Step [422/735], Loss: 0.0944\n",
      "Epoch [36/50], Step [423/735], Loss: 0.1228\n",
      "Epoch [36/50], Step [424/735], Loss: 0.1027\n",
      "Epoch [36/50], Step [425/735], Loss: 1.6874\n",
      "Epoch [36/50], Step [426/735], Loss: 0.0621\n",
      "Epoch [36/50], Step [427/735], Loss: 0.1829\n",
      "Epoch [36/50], Step [428/735], Loss: 0.0931\n",
      "Epoch [36/50], Step [429/735], Loss: 0.1594\n",
      "Epoch [36/50], Step [430/735], Loss: 0.3416\n",
      "Epoch [36/50], Step [431/735], Loss: 0.1452\n",
      "Epoch [36/50], Step [432/735], Loss: 0.0660\n",
      "Epoch [36/50], Step [433/735], Loss: 0.0683\n",
      "Epoch [36/50], Step [434/735], Loss: 0.1352\n",
      "Epoch [36/50], Step [435/735], Loss: 0.3439\n",
      "Epoch [36/50], Step [436/735], Loss: 0.1988\n",
      "Epoch [36/50], Step [437/735], Loss: 0.1730\n",
      "Epoch [36/50], Step [438/735], Loss: 0.1119\n",
      "Epoch [36/50], Step [439/735], Loss: 0.0497\n",
      "Epoch [36/50], Step [440/735], Loss: 0.0783\n",
      "Epoch [36/50], Step [441/735], Loss: 0.1056\n",
      "Epoch [36/50], Step [442/735], Loss: 0.0525\n",
      "Epoch [36/50], Step [443/735], Loss: 0.0536\n",
      "Epoch [36/50], Step [444/735], Loss: 0.0623\n",
      "Epoch [36/50], Step [445/735], Loss: 0.0388\n",
      "Epoch [36/50], Step [446/735], Loss: 0.1639\n",
      "Epoch [36/50], Step [447/735], Loss: 0.0665\n",
      "Epoch [36/50], Step [448/735], Loss: 0.2425\n",
      "Epoch [36/50], Step [449/735], Loss: 0.0758\n",
      "Epoch [36/50], Step [450/735], Loss: 0.1560\n",
      "Epoch [36/50], Step [451/735], Loss: 0.1285\n",
      "Epoch [36/50], Step [452/735], Loss: 0.0799\n",
      "Epoch [36/50], Step [453/735], Loss: 0.0588\n",
      "Epoch [36/50], Step [454/735], Loss: 0.1461\n",
      "Epoch [36/50], Step [455/735], Loss: 0.1857\n",
      "Epoch [36/50], Step [456/735], Loss: 0.0433\n",
      "Epoch [36/50], Step [457/735], Loss: 0.0534\n",
      "Epoch [36/50], Step [458/735], Loss: 0.0945\n",
      "Epoch [36/50], Step [459/735], Loss: 0.0331\n",
      "Epoch [36/50], Step [460/735], Loss: 0.0511\n",
      "Epoch [36/50], Step [461/735], Loss: 0.4508\n",
      "Epoch [36/50], Step [462/735], Loss: 0.1355\n",
      "Epoch [36/50], Step [463/735], Loss: 0.0672\n",
      "Epoch [36/50], Step [464/735], Loss: 0.2625\n",
      "Epoch [36/50], Step [465/735], Loss: 0.0345\n",
      "Epoch [36/50], Step [466/735], Loss: 0.0838\n",
      "Epoch [36/50], Step [467/735], Loss: 0.0518\n",
      "Epoch [36/50], Step [468/735], Loss: 0.0892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Step [469/735], Loss: 0.0776\n",
      "Epoch [36/50], Step [470/735], Loss: 0.1147\n",
      "Epoch [36/50], Step [471/735], Loss: 0.0402\n",
      "Epoch [36/50], Step [472/735], Loss: 0.0423\n",
      "Epoch [36/50], Step [473/735], Loss: 0.1068\n",
      "Epoch [36/50], Step [474/735], Loss: 0.0391\n",
      "Epoch [36/50], Step [475/735], Loss: 0.1271\n",
      "Epoch [36/50], Step [476/735], Loss: 0.1296\n",
      "Epoch [36/50], Step [477/735], Loss: 0.1488\n",
      "Epoch [36/50], Step [478/735], Loss: 0.1262\n",
      "Epoch [36/50], Step [479/735], Loss: 0.0413\n",
      "Epoch [36/50], Step [480/735], Loss: 0.1367\n",
      "Epoch [36/50], Step [481/735], Loss: 0.0431\n",
      "Epoch [36/50], Step [482/735], Loss: 0.0388\n",
      "Epoch [36/50], Step [483/735], Loss: 0.0650\n",
      "Epoch [36/50], Step [484/735], Loss: 0.8078\n",
      "Epoch [36/50], Step [485/735], Loss: 0.1301\n",
      "Epoch [36/50], Step [486/735], Loss: 0.1950\n",
      "Epoch [36/50], Step [487/735], Loss: 0.0970\n",
      "Epoch [36/50], Step [488/735], Loss: 0.1141\n",
      "Epoch [36/50], Step [489/735], Loss: 0.1158\n",
      "Epoch [36/50], Step [490/735], Loss: 0.1272\n",
      "Epoch [36/50], Step [491/735], Loss: 0.0293\n",
      "Epoch [36/50], Step [492/735], Loss: 0.0440\n",
      "Epoch [36/50], Step [493/735], Loss: 0.0350\n",
      "Epoch [36/50], Step [494/735], Loss: 0.1289\n",
      "Epoch [36/50], Step [495/735], Loss: 0.0829\n",
      "Epoch [36/50], Step [496/735], Loss: 0.2160\n",
      "Epoch [36/50], Step [497/735], Loss: 0.0494\n",
      "Epoch [36/50], Step [498/735], Loss: 0.0794\n",
      "Epoch [36/50], Step [499/735], Loss: 0.0749\n",
      "Epoch [36/50], Step [500/735], Loss: 0.0540\n",
      "Epoch [36/50], Step [501/735], Loss: 0.1750\n",
      "Epoch [36/50], Step [502/735], Loss: 0.0626\n",
      "Epoch [36/50], Step [503/735], Loss: 0.0545\n",
      "Epoch [36/50], Step [504/735], Loss: 0.0501\n",
      "Epoch [36/50], Step [505/735], Loss: 0.1232\n",
      "Epoch [36/50], Step [506/735], Loss: 2.2301\n",
      "Epoch [36/50], Step [507/735], Loss: 0.1595\n",
      "Epoch [36/50], Step [508/735], Loss: 0.5532\n",
      "Epoch [36/50], Step [509/735], Loss: 0.0674\n",
      "Epoch [36/50], Step [510/735], Loss: 0.1287\n",
      "Epoch [36/50], Step [511/735], Loss: 0.0598\n",
      "Epoch [36/50], Step [512/735], Loss: 0.4857\n",
      "Epoch [36/50], Step [513/735], Loss: 0.5783\n",
      "Epoch [36/50], Step [514/735], Loss: 0.1020\n",
      "Epoch [36/50], Step [515/735], Loss: 0.1251\n",
      "Epoch [36/50], Step [516/735], Loss: 0.0571\n",
      "Epoch [36/50], Step [517/735], Loss: 0.0835\n",
      "Epoch [36/50], Step [518/735], Loss: 0.0827\n",
      "Epoch [36/50], Step [519/735], Loss: 0.0936\n",
      "Epoch [36/50], Step [520/735], Loss: 0.0697\n",
      "Epoch [36/50], Step [521/735], Loss: 0.1829\n",
      "Epoch [36/50], Step [522/735], Loss: 0.3346\n",
      "Epoch [36/50], Step [523/735], Loss: 0.0763\n",
      "Epoch [36/50], Step [524/735], Loss: 0.0664\n",
      "Epoch [36/50], Step [525/735], Loss: 0.1281\n",
      "Epoch [36/50], Step [526/735], Loss: 0.1147\n",
      "Epoch [36/50], Step [527/735], Loss: 0.0638\n",
      "Epoch [36/50], Step [528/735], Loss: 0.0305\n",
      "Epoch [36/50], Step [529/735], Loss: 0.2363\n",
      "Epoch [36/50], Step [530/735], Loss: 0.3196\n",
      "Epoch [36/50], Step [531/735], Loss: 0.0778\n",
      "Epoch [36/50], Step [532/735], Loss: 0.1057\n",
      "Epoch [36/50], Step [533/735], Loss: 0.7831\n",
      "Epoch [36/50], Step [534/735], Loss: 0.0495\n",
      "Epoch [36/50], Step [535/735], Loss: 0.1049\n",
      "Epoch [36/50], Step [536/735], Loss: 0.1267\n",
      "Epoch [36/50], Step [537/735], Loss: 0.0434\n",
      "Epoch [36/50], Step [538/735], Loss: 0.0823\n",
      "Epoch [36/50], Step [539/735], Loss: 0.0520\n",
      "Epoch [36/50], Step [540/735], Loss: 0.1067\n",
      "Epoch [36/50], Step [541/735], Loss: 0.1208\n",
      "Epoch [36/50], Step [542/735], Loss: 0.0472\n",
      "Epoch [36/50], Step [543/735], Loss: 0.1294\n",
      "Epoch [36/50], Step [544/735], Loss: 0.1364\n",
      "Epoch [36/50], Step [545/735], Loss: 0.0971\n",
      "Epoch [36/50], Step [546/735], Loss: 0.0777\n",
      "Epoch [36/50], Step [547/735], Loss: 0.0550\n",
      "Epoch [36/50], Step [548/735], Loss: 0.0821\n",
      "Epoch [36/50], Step [549/735], Loss: 0.0640\n",
      "Epoch [36/50], Step [550/735], Loss: 0.0866\n",
      "Epoch [36/50], Step [551/735], Loss: 0.0627\n",
      "Epoch [36/50], Step [552/735], Loss: 0.2746\n",
      "Epoch [36/50], Step [553/735], Loss: 0.1252\n",
      "Epoch [36/50], Step [554/735], Loss: 0.1055\n",
      "Epoch [36/50], Step [555/735], Loss: 0.1477\n",
      "Epoch [36/50], Step [556/735], Loss: 0.1094\n",
      "Epoch [36/50], Step [557/735], Loss: 0.0604\n",
      "Epoch [36/50], Step [558/735], Loss: 0.1644\n",
      "Epoch [36/50], Step [559/735], Loss: 0.0677\n",
      "Epoch [36/50], Step [560/735], Loss: 0.0960\n",
      "Epoch [36/50], Step [561/735], Loss: 0.0593\n",
      "Epoch [36/50], Step [562/735], Loss: 0.0800\n",
      "Epoch [36/50], Step [563/735], Loss: 0.0973\n",
      "Epoch [36/50], Step [564/735], Loss: 0.0853\n",
      "Epoch [36/50], Step [565/735], Loss: 0.4251\n",
      "Epoch [36/50], Step [566/735], Loss: 0.0626\n",
      "Epoch [36/50], Step [567/735], Loss: 0.0961\n",
      "Epoch [36/50], Step [568/735], Loss: 0.0651\n",
      "Epoch [36/50], Step [569/735], Loss: 0.1563\n",
      "Epoch [36/50], Step [570/735], Loss: 0.0476\n",
      "Epoch [36/50], Step [571/735], Loss: 0.0980\n",
      "Epoch [36/50], Step [572/735], Loss: 0.4659\n",
      "Epoch [36/50], Step [573/735], Loss: 0.1139\n",
      "Epoch [36/50], Step [574/735], Loss: 0.1446\n",
      "Epoch [36/50], Step [575/735], Loss: 0.0497\n",
      "Epoch [36/50], Step [576/735], Loss: 0.2496\n",
      "Epoch [36/50], Step [577/735], Loss: 0.1105\n",
      "Epoch [36/50], Step [578/735], Loss: 0.1872\n",
      "Epoch [36/50], Step [579/735], Loss: 0.0575\n",
      "Epoch [36/50], Step [580/735], Loss: 0.0734\n",
      "Epoch [36/50], Step [581/735], Loss: 0.1997\n",
      "Epoch [36/50], Step [582/735], Loss: 0.0968\n",
      "Epoch [36/50], Step [583/735], Loss: 0.0856\n",
      "Epoch [36/50], Step [584/735], Loss: 0.0327\n",
      "Epoch [36/50], Step [585/735], Loss: 0.0450\n",
      "Epoch [36/50], Step [586/735], Loss: 0.1229\n",
      "Epoch [36/50], Step [587/735], Loss: 0.0710\n",
      "Epoch [36/50], Step [588/735], Loss: 0.1067\n",
      "Epoch [36/50], Step [589/735], Loss: 0.6269\n",
      "Epoch [36/50], Step [590/735], Loss: 0.0445\n",
      "Epoch [36/50], Step [591/735], Loss: 0.0806\n",
      "Epoch [36/50], Step [592/735], Loss: 0.1335\n",
      "Epoch [36/50], Step [593/735], Loss: 0.1197\n",
      "Epoch [36/50], Step [594/735], Loss: 0.1928\n",
      "Epoch [36/50], Step [595/735], Loss: 0.0414\n",
      "Epoch [36/50], Step [596/735], Loss: 0.0511\n",
      "Epoch [36/50], Step [597/735], Loss: 0.0651\n",
      "Epoch [36/50], Step [598/735], Loss: 0.0415\n",
      "Epoch [36/50], Step [599/735], Loss: 0.0554\n",
      "Epoch [36/50], Step [600/735], Loss: 0.1564\n",
      "Epoch [36/50], Step [601/735], Loss: 0.1349\n",
      "Epoch [36/50], Step [602/735], Loss: 1.0326\n",
      "Epoch [36/50], Step [603/735], Loss: 0.2358\n",
      "Epoch [36/50], Step [604/735], Loss: 0.7109\n",
      "Epoch [36/50], Step [605/735], Loss: 0.0419\n",
      "Epoch [36/50], Step [606/735], Loss: 0.1703\n",
      "Epoch [36/50], Step [607/735], Loss: 0.0874\n",
      "Epoch [36/50], Step [608/735], Loss: 0.0469\n",
      "Epoch [36/50], Step [609/735], Loss: 0.0752\n",
      "Epoch [36/50], Step [610/735], Loss: 0.3738\n",
      "Epoch [36/50], Step [611/735], Loss: 0.1260\n",
      "Epoch [36/50], Step [612/735], Loss: 0.0551\n",
      "Epoch [36/50], Step [613/735], Loss: 0.1666\n",
      "Epoch [36/50], Step [614/735], Loss: 0.1243\n",
      "Epoch [36/50], Step [615/735], Loss: 0.2117\n",
      "Epoch [36/50], Step [616/735], Loss: 0.1316\n",
      "Epoch [36/50], Step [617/735], Loss: 0.5510\n",
      "Epoch [36/50], Step [618/735], Loss: 0.1214\n",
      "Epoch [36/50], Step [619/735], Loss: 0.0666\n",
      "Epoch [36/50], Step [620/735], Loss: 0.1254\n",
      "Epoch [36/50], Step [621/735], Loss: 0.0766\n",
      "Epoch [36/50], Step [622/735], Loss: 0.0413\n",
      "Epoch [36/50], Step [623/735], Loss: 0.2543\n",
      "Epoch [36/50], Step [624/735], Loss: 0.1131\n",
      "Epoch [36/50], Step [625/735], Loss: 0.1003\n",
      "Epoch [36/50], Step [626/735], Loss: 0.1272\n",
      "Epoch [36/50], Step [627/735], Loss: 0.1230\n",
      "Epoch [36/50], Step [628/735], Loss: 0.1165\n",
      "Epoch [36/50], Step [629/735], Loss: 0.3679\n",
      "Epoch [36/50], Step [630/735], Loss: 0.1009\n",
      "Epoch [36/50], Step [631/735], Loss: 0.0583\n",
      "Epoch [36/50], Step [632/735], Loss: 0.0935\n",
      "Epoch [36/50], Step [633/735], Loss: 0.0783\n",
      "Epoch [36/50], Step [634/735], Loss: 0.0762\n",
      "Epoch [36/50], Step [635/735], Loss: 0.0895\n",
      "Epoch [36/50], Step [636/735], Loss: 0.0569\n",
      "Epoch [36/50], Step [637/735], Loss: 0.1480\n",
      "Epoch [36/50], Step [638/735], Loss: 0.0513\n",
      "Epoch [36/50], Step [639/735], Loss: 0.1140\n",
      "Epoch [36/50], Step [640/735], Loss: 0.0567\n",
      "Epoch [36/50], Step [641/735], Loss: 0.0322\n",
      "Epoch [36/50], Step [642/735], Loss: 0.1783\n",
      "Epoch [36/50], Step [643/735], Loss: 0.9472\n",
      "Epoch [36/50], Step [644/735], Loss: 0.2223\n",
      "Epoch [36/50], Step [645/735], Loss: 0.1235\n",
      "Epoch [36/50], Step [646/735], Loss: 0.1400\n",
      "Epoch [36/50], Step [647/735], Loss: 0.0314\n",
      "Epoch [36/50], Step [648/735], Loss: 0.0895\n",
      "Epoch [36/50], Step [649/735], Loss: 0.3686\n",
      "Epoch [36/50], Step [650/735], Loss: 0.0345\n",
      "Epoch [36/50], Step [651/735], Loss: 0.0481\n",
      "Epoch [36/50], Step [652/735], Loss: 0.1778\n",
      "Epoch [36/50], Step [653/735], Loss: 0.0371\n",
      "Epoch [36/50], Step [654/735], Loss: 0.1373\n",
      "Epoch [36/50], Step [655/735], Loss: 1.9695\n",
      "Epoch [36/50], Step [656/735], Loss: 0.1173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Step [657/735], Loss: 0.0664\n",
      "Epoch [36/50], Step [658/735], Loss: 0.1038\n",
      "Epoch [36/50], Step [659/735], Loss: 0.0590\n",
      "Epoch [36/50], Step [660/735], Loss: 0.1258\n",
      "Epoch [36/50], Step [661/735], Loss: 0.1067\n",
      "Epoch [36/50], Step [662/735], Loss: 0.0896\n",
      "Epoch [36/50], Step [663/735], Loss: 0.2041\n",
      "Epoch [36/50], Step [664/735], Loss: 0.5801\n",
      "Epoch [36/50], Step [665/735], Loss: 0.1976\n",
      "Epoch [36/50], Step [666/735], Loss: 0.0818\n",
      "Epoch [36/50], Step [667/735], Loss: 0.1793\n",
      "Epoch [36/50], Step [668/735], Loss: 0.0615\n",
      "Epoch [36/50], Step [669/735], Loss: 0.0707\n",
      "Epoch [36/50], Step [670/735], Loss: 0.9376\n",
      "Epoch [36/50], Step [671/735], Loss: 0.0903\n",
      "Epoch [36/50], Step [672/735], Loss: 0.2017\n",
      "Epoch [36/50], Step [673/735], Loss: 0.1252\n",
      "Epoch [36/50], Step [674/735], Loss: 0.0919\n",
      "Epoch [36/50], Step [675/735], Loss: 0.1435\n",
      "Epoch [36/50], Step [676/735], Loss: 0.2222\n",
      "Epoch [36/50], Step [677/735], Loss: 0.2811\n",
      "Epoch [36/50], Step [678/735], Loss: 0.4001\n",
      "Epoch [36/50], Step [679/735], Loss: 0.0543\n",
      "Epoch [36/50], Step [680/735], Loss: 0.1130\n",
      "Epoch [36/50], Step [681/735], Loss: 0.1092\n",
      "Epoch [36/50], Step [682/735], Loss: 0.1223\n",
      "Epoch [36/50], Step [683/735], Loss: 0.0669\n",
      "Epoch [36/50], Step [684/735], Loss: 0.0814\n",
      "Epoch [36/50], Step [685/735], Loss: 0.0452\n",
      "Epoch [36/50], Step [686/735], Loss: 0.0929\n",
      "Epoch [36/50], Step [687/735], Loss: 0.3679\n",
      "Epoch [36/50], Step [688/735], Loss: 0.1752\n",
      "Epoch [36/50], Step [689/735], Loss: 0.2929\n",
      "Epoch [36/50], Step [690/735], Loss: 0.1879\n",
      "Epoch [36/50], Step [691/735], Loss: 0.0962\n",
      "Epoch [36/50], Step [692/735], Loss: 0.0969\n",
      "Epoch [36/50], Step [693/735], Loss: 0.1064\n",
      "Epoch [36/50], Step [694/735], Loss: 0.1037\n",
      "Epoch [36/50], Step [695/735], Loss: 0.0610\n",
      "Epoch [36/50], Step [696/735], Loss: 0.1206\n",
      "Epoch [36/50], Step [697/735], Loss: 0.0451\n",
      "Epoch [36/50], Step [698/735], Loss: 0.0607\n",
      "Epoch [36/50], Step [699/735], Loss: 1.4737\n",
      "Epoch [36/50], Step [700/735], Loss: 0.0657\n",
      "Epoch [36/50], Step [701/735], Loss: 0.1008\n",
      "Epoch [36/50], Step [702/735], Loss: 0.5147\n",
      "Epoch [36/50], Step [703/735], Loss: 0.1295\n",
      "Epoch [36/50], Step [704/735], Loss: 0.1015\n",
      "Epoch [36/50], Step [705/735], Loss: 1.4793\n",
      "Epoch [36/50], Step [706/735], Loss: 0.1327\n",
      "Epoch [36/50], Step [707/735], Loss: 0.1499\n",
      "Epoch [36/50], Step [708/735], Loss: 0.2329\n",
      "Epoch [36/50], Step [709/735], Loss: 0.0541\n",
      "Epoch [36/50], Step [710/735], Loss: 0.5297\n",
      "Epoch [36/50], Step [711/735], Loss: 0.0951\n",
      "Epoch [36/50], Step [712/735], Loss: 0.0432\n",
      "Epoch [36/50], Step [713/735], Loss: 0.0631\n",
      "Epoch [36/50], Step [714/735], Loss: 0.1508\n",
      "Epoch [36/50], Step [715/735], Loss: 0.1670\n",
      "Epoch [36/50], Step [716/735], Loss: 0.2077\n",
      "Epoch [36/50], Step [717/735], Loss: 0.0621\n",
      "Epoch [36/50], Step [718/735], Loss: 0.1192\n",
      "Epoch [36/50], Step [719/735], Loss: 0.1404\n",
      "Epoch [36/50], Step [720/735], Loss: 0.0922\n",
      "Epoch [36/50], Step [721/735], Loss: 0.1679\n",
      "Epoch [36/50], Step [722/735], Loss: 0.3327\n",
      "Epoch [36/50], Step [723/735], Loss: 0.0839\n",
      "Epoch [36/50], Step [724/735], Loss: 0.1826\n",
      "Epoch [36/50], Step [725/735], Loss: 0.0982\n",
      "Epoch [36/50], Step [726/735], Loss: 0.1265\n",
      "Epoch [36/50], Step [727/735], Loss: 0.0731\n",
      "Epoch [36/50], Step [728/735], Loss: 0.0800\n",
      "Epoch [36/50], Step [729/735], Loss: 0.1268\n",
      "Epoch [36/50], Step [730/735], Loss: 0.0698\n",
      "Epoch [36/50], Step [731/735], Loss: 0.0607\n",
      "Epoch [36/50], Step [732/735], Loss: 0.0868\n",
      "Epoch [36/50], Step [733/735], Loss: 0.1407\n",
      "Epoch [36/50], Step [734/735], Loss: 0.1711\n",
      "Epoch [36/50], Step [735/735], Loss: 0.0619\n",
      "Epoch [37/50], Step [1/735], Loss: 0.1544\n",
      "Epoch [37/50], Step [2/735], Loss: 0.0602\n",
      "Epoch [37/50], Step [3/735], Loss: 0.0812\n",
      "Epoch [37/50], Step [4/735], Loss: 0.0746\n",
      "Epoch [37/50], Step [5/735], Loss: 0.0769\n",
      "Epoch [37/50], Step [6/735], Loss: 0.1854\n",
      "Epoch [37/50], Step [7/735], Loss: 0.1529\n",
      "Epoch [37/50], Step [8/735], Loss: 0.0870\n",
      "Epoch [37/50], Step [9/735], Loss: 0.0692\n",
      "Epoch [37/50], Step [10/735], Loss: 0.1605\n",
      "Epoch [37/50], Step [11/735], Loss: 0.2067\n",
      "Epoch [37/50], Step [12/735], Loss: 0.0941\n",
      "Epoch [37/50], Step [13/735], Loss: 0.0769\n",
      "Epoch [37/50], Step [14/735], Loss: 0.1059\n",
      "Epoch [37/50], Step [15/735], Loss: 0.4363\n",
      "Epoch [37/50], Step [16/735], Loss: 0.1543\n",
      "Epoch [37/50], Step [17/735], Loss: 0.1141\n",
      "Epoch [37/50], Step [18/735], Loss: 0.3221\n",
      "Epoch [37/50], Step [19/735], Loss: 0.2743\n",
      "Epoch [37/50], Step [20/735], Loss: 0.0377\n",
      "Epoch [37/50], Step [21/735], Loss: 0.0964\n",
      "Epoch [37/50], Step [22/735], Loss: 0.1173\n",
      "Epoch [37/50], Step [23/735], Loss: 0.0704\n",
      "Epoch [37/50], Step [24/735], Loss: 0.3062\n",
      "Epoch [37/50], Step [25/735], Loss: 0.0800\n",
      "Epoch [37/50], Step [26/735], Loss: 0.0951\n",
      "Epoch [37/50], Step [27/735], Loss: 0.6365\n",
      "Epoch [37/50], Step [28/735], Loss: 0.0630\n",
      "Epoch [37/50], Step [29/735], Loss: 0.1614\n",
      "Epoch [37/50], Step [30/735], Loss: 0.6224\n",
      "Epoch [37/50], Step [31/735], Loss: 0.1652\n",
      "Epoch [37/50], Step [32/735], Loss: 0.0664\n",
      "Epoch [37/50], Step [33/735], Loss: 0.0485\n",
      "Epoch [37/50], Step [34/735], Loss: 0.0449\n",
      "Epoch [37/50], Step [35/735], Loss: 0.2143\n",
      "Epoch [37/50], Step [36/735], Loss: 0.1883\n",
      "Epoch [37/50], Step [37/735], Loss: 0.0772\n",
      "Epoch [37/50], Step [38/735], Loss: 0.0662\n",
      "Epoch [37/50], Step [39/735], Loss: 0.1186\n",
      "Epoch [37/50], Step [40/735], Loss: 0.0908\n",
      "Epoch [37/50], Step [41/735], Loss: 0.0723\n",
      "Epoch [37/50], Step [42/735], Loss: 0.0781\n",
      "Epoch [37/50], Step [43/735], Loss: 0.1497\n",
      "Epoch [37/50], Step [44/735], Loss: 0.0703\n",
      "Epoch [37/50], Step [45/735], Loss: 0.1161\n",
      "Epoch [37/50], Step [46/735], Loss: 0.1697\n",
      "Epoch [37/50], Step [47/735], Loss: 0.0761\n",
      "Epoch [37/50], Step [48/735], Loss: 0.1313\n",
      "Epoch [37/50], Step [49/735], Loss: 0.0803\n",
      "Epoch [37/50], Step [50/735], Loss: 0.0777\n",
      "Epoch [37/50], Step [51/735], Loss: 0.2307\n",
      "Epoch [37/50], Step [52/735], Loss: 1.5882\n",
      "Epoch [37/50], Step [53/735], Loss: 0.0645\n",
      "Epoch [37/50], Step [54/735], Loss: 0.2810\n",
      "Epoch [37/50], Step [55/735], Loss: 0.0627\n",
      "Epoch [37/50], Step [56/735], Loss: 0.1202\n",
      "Epoch [37/50], Step [57/735], Loss: 0.0801\n",
      "Epoch [37/50], Step [58/735], Loss: 0.0526\n",
      "Epoch [37/50], Step [59/735], Loss: 0.0852\n",
      "Epoch [37/50], Step [60/735], Loss: 0.1630\n",
      "Epoch [37/50], Step [61/735], Loss: 0.0589\n",
      "Epoch [37/50], Step [62/735], Loss: 0.0459\n",
      "Epoch [37/50], Step [63/735], Loss: 0.1111\n",
      "Epoch [37/50], Step [64/735], Loss: 0.1384\n",
      "Epoch [37/50], Step [65/735], Loss: 0.0700\n",
      "Epoch [37/50], Step [66/735], Loss: 0.1185\n",
      "Epoch [37/50], Step [67/735], Loss: 0.1302\n",
      "Epoch [37/50], Step [68/735], Loss: 0.1058\n",
      "Epoch [37/50], Step [69/735], Loss: 0.2454\n",
      "Epoch [37/50], Step [70/735], Loss: 0.0475\n",
      "Epoch [37/50], Step [71/735], Loss: 0.1600\n",
      "Epoch [37/50], Step [72/735], Loss: 0.0976\n",
      "Epoch [37/50], Step [73/735], Loss: 0.0924\n",
      "Epoch [37/50], Step [74/735], Loss: 0.1042\n",
      "Epoch [37/50], Step [75/735], Loss: 0.0816\n",
      "Epoch [37/50], Step [76/735], Loss: 0.0494\n",
      "Epoch [37/50], Step [77/735], Loss: 0.1208\n",
      "Epoch [37/50], Step [78/735], Loss: 0.0926\n",
      "Epoch [37/50], Step [79/735], Loss: 0.0500\n",
      "Epoch [37/50], Step [80/735], Loss: 0.0639\n",
      "Epoch [37/50], Step [81/735], Loss: 0.1171\n",
      "Epoch [37/50], Step [82/735], Loss: 0.0749\n",
      "Epoch [37/50], Step [83/735], Loss: 0.1887\n",
      "Epoch [37/50], Step [84/735], Loss: 0.1797\n",
      "Epoch [37/50], Step [85/735], Loss: 0.1334\n",
      "Epoch [37/50], Step [86/735], Loss: 0.1630\n",
      "Epoch [37/50], Step [87/735], Loss: 0.1446\n",
      "Epoch [37/50], Step [88/735], Loss: 0.1660\n",
      "Epoch [37/50], Step [89/735], Loss: 0.0953\n",
      "Epoch [37/50], Step [90/735], Loss: 0.0591\n",
      "Epoch [37/50], Step [91/735], Loss: 0.0502\n",
      "Epoch [37/50], Step [92/735], Loss: 0.0681\n",
      "Epoch [37/50], Step [93/735], Loss: 0.0637\n",
      "Epoch [37/50], Step [94/735], Loss: 0.5369\n",
      "Epoch [37/50], Step [95/735], Loss: 0.0798\n",
      "Epoch [37/50], Step [96/735], Loss: 0.0647\n",
      "Epoch [37/50], Step [97/735], Loss: 0.0648\n",
      "Epoch [37/50], Step [98/735], Loss: 0.0395\n",
      "Epoch [37/50], Step [99/735], Loss: 0.1918\n",
      "Epoch [37/50], Step [100/735], Loss: 0.1590\n",
      "Epoch [37/50], Step [101/735], Loss: 0.0331\n",
      "Epoch [37/50], Step [102/735], Loss: 0.1379\n",
      "Epoch [37/50], Step [103/735], Loss: 0.0697\n",
      "Epoch [37/50], Step [104/735], Loss: 1.2010\n",
      "Epoch [37/50], Step [105/735], Loss: 0.0426\n",
      "Epoch [37/50], Step [106/735], Loss: 0.1088\n",
      "Epoch [37/50], Step [107/735], Loss: 0.1653\n",
      "Epoch [37/50], Step [108/735], Loss: 0.1972\n",
      "Epoch [37/50], Step [109/735], Loss: 0.0719\n",
      "Epoch [37/50], Step [110/735], Loss: 0.1402\n",
      "Epoch [37/50], Step [111/735], Loss: 0.1191\n",
      "Epoch [37/50], Step [112/735], Loss: 0.0677\n",
      "Epoch [37/50], Step [113/735], Loss: 0.2123\n",
      "Epoch [37/50], Step [114/735], Loss: 0.0717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Step [115/735], Loss: 0.0897\n",
      "Epoch [37/50], Step [116/735], Loss: 0.8603\n",
      "Epoch [37/50], Step [117/735], Loss: 0.0862\n",
      "Epoch [37/50], Step [118/735], Loss: 0.3972\n",
      "Epoch [37/50], Step [119/735], Loss: 0.1160\n",
      "Epoch [37/50], Step [120/735], Loss: 0.0458\n",
      "Epoch [37/50], Step [121/735], Loss: 0.0965\n",
      "Epoch [37/50], Step [122/735], Loss: 0.1675\n",
      "Epoch [37/50], Step [123/735], Loss: 0.1236\n",
      "Epoch [37/50], Step [124/735], Loss: 0.0828\n",
      "Epoch [37/50], Step [125/735], Loss: 0.1499\n",
      "Epoch [37/50], Step [126/735], Loss: 0.0570\n",
      "Epoch [37/50], Step [127/735], Loss: 0.2131\n",
      "Epoch [37/50], Step [128/735], Loss: 0.2185\n",
      "Epoch [37/50], Step [129/735], Loss: 0.0825\n",
      "Epoch [37/50], Step [130/735], Loss: 0.1128\n",
      "Epoch [37/50], Step [131/735], Loss: 0.0936\n",
      "Epoch [37/50], Step [132/735], Loss: 0.0806\n",
      "Epoch [37/50], Step [133/735], Loss: 0.1228\n",
      "Epoch [37/50], Step [134/735], Loss: 0.0498\n",
      "Epoch [37/50], Step [135/735], Loss: 0.0633\n",
      "Epoch [37/50], Step [136/735], Loss: 0.1155\n",
      "Epoch [37/50], Step [137/735], Loss: 0.1460\n",
      "Epoch [37/50], Step [138/735], Loss: 0.1405\n",
      "Epoch [37/50], Step [139/735], Loss: 0.1663\n",
      "Epoch [37/50], Step [140/735], Loss: 0.0775\n",
      "Epoch [37/50], Step [141/735], Loss: 0.0822\n",
      "Epoch [37/50], Step [142/735], Loss: 0.0287\n",
      "Epoch [37/50], Step [143/735], Loss: 0.1478\n",
      "Epoch [37/50], Step [144/735], Loss: 0.4598\n",
      "Epoch [37/50], Step [145/735], Loss: 0.0940\n",
      "Epoch [37/50], Step [146/735], Loss: 0.5655\n",
      "Epoch [37/50], Step [147/735], Loss: 0.1170\n",
      "Epoch [37/50], Step [148/735], Loss: 0.0331\n",
      "Epoch [37/50], Step [149/735], Loss: 0.0850\n",
      "Epoch [37/50], Step [150/735], Loss: 0.0521\n",
      "Epoch [37/50], Step [151/735], Loss: 0.0812\n",
      "Epoch [37/50], Step [152/735], Loss: 0.1606\n",
      "Epoch [37/50], Step [153/735], Loss: 0.0729\n",
      "Epoch [37/50], Step [154/735], Loss: 0.0475\n",
      "Epoch [37/50], Step [155/735], Loss: 0.1041\n",
      "Epoch [37/50], Step [156/735], Loss: 0.0774\n",
      "Epoch [37/50], Step [157/735], Loss: 0.1445\n",
      "Epoch [37/50], Step [158/735], Loss: 0.1034\n",
      "Epoch [37/50], Step [159/735], Loss: 0.0378\n",
      "Epoch [37/50], Step [160/735], Loss: 0.0585\n",
      "Epoch [37/50], Step [161/735], Loss: 0.0586\n",
      "Epoch [37/50], Step [162/735], Loss: 0.0564\n",
      "Epoch [37/50], Step [163/735], Loss: 0.9677\n",
      "Epoch [37/50], Step [164/735], Loss: 0.4248\n",
      "Epoch [37/50], Step [165/735], Loss: 0.0816\n",
      "Epoch [37/50], Step [166/735], Loss: 0.0737\n",
      "Epoch [37/50], Step [167/735], Loss: 0.1140\n",
      "Epoch [37/50], Step [168/735], Loss: 0.0563\n",
      "Epoch [37/50], Step [169/735], Loss: 0.1108\n",
      "Epoch [37/50], Step [170/735], Loss: 0.0863\n",
      "Epoch [37/50], Step [171/735], Loss: 0.1123\n",
      "Epoch [37/50], Step [172/735], Loss: 0.1423\n",
      "Epoch [37/50], Step [173/735], Loss: 0.0589\n",
      "Epoch [37/50], Step [174/735], Loss: 0.0522\n",
      "Epoch [37/50], Step [175/735], Loss: 0.0987\n",
      "Epoch [37/50], Step [176/735], Loss: 0.0647\n",
      "Epoch [37/50], Step [177/735], Loss: 0.1444\n",
      "Epoch [37/50], Step [178/735], Loss: 0.0562\n",
      "Epoch [37/50], Step [179/735], Loss: 0.1023\n",
      "Epoch [37/50], Step [180/735], Loss: 0.0695\n",
      "Epoch [37/50], Step [181/735], Loss: 0.0456\n",
      "Epoch [37/50], Step [182/735], Loss: 0.1122\n",
      "Epoch [37/50], Step [183/735], Loss: 0.1436\n",
      "Epoch [37/50], Step [184/735], Loss: 0.1091\n",
      "Epoch [37/50], Step [185/735], Loss: 0.1462\n",
      "Epoch [37/50], Step [186/735], Loss: 1.4670\n",
      "Epoch [37/50], Step [187/735], Loss: 0.0918\n",
      "Epoch [37/50], Step [188/735], Loss: 0.0948\n",
      "Epoch [37/50], Step [189/735], Loss: 0.0866\n",
      "Epoch [37/50], Step [190/735], Loss: 0.0919\n",
      "Epoch [37/50], Step [191/735], Loss: 0.0840\n",
      "Epoch [37/50], Step [192/735], Loss: 0.1337\n",
      "Epoch [37/50], Step [193/735], Loss: 0.0577\n",
      "Epoch [37/50], Step [194/735], Loss: 0.0482\n",
      "Epoch [37/50], Step [195/735], Loss: 0.1281\n",
      "Epoch [37/50], Step [196/735], Loss: 1.0482\n",
      "Epoch [37/50], Step [197/735], Loss: 0.0553\n",
      "Epoch [37/50], Step [198/735], Loss: 0.3917\n",
      "Epoch [37/50], Step [199/735], Loss: 0.3437\n",
      "Epoch [37/50], Step [200/735], Loss: 0.1247\n",
      "Epoch [37/50], Step [201/735], Loss: 0.0957\n",
      "Epoch [37/50], Step [202/735], Loss: 0.7513\n",
      "Epoch [37/50], Step [203/735], Loss: 0.0818\n",
      "Epoch [37/50], Step [204/735], Loss: 0.1346\n",
      "Epoch [37/50], Step [205/735], Loss: 0.0698\n",
      "Epoch [37/50], Step [206/735], Loss: 0.0994\n",
      "Epoch [37/50], Step [207/735], Loss: 0.2453\n",
      "Epoch [37/50], Step [208/735], Loss: 0.1703\n",
      "Epoch [37/50], Step [209/735], Loss: 0.0927\n",
      "Epoch [37/50], Step [210/735], Loss: 0.1774\n",
      "Epoch [37/50], Step [211/735], Loss: 0.0610\n",
      "Epoch [37/50], Step [212/735], Loss: 0.0637\n",
      "Epoch [37/50], Step [213/735], Loss: 0.1303\n",
      "Epoch [37/50], Step [214/735], Loss: 0.0982\n",
      "Epoch [37/50], Step [215/735], Loss: 0.0687\n",
      "Epoch [37/50], Step [216/735], Loss: 0.1191\n",
      "Epoch [37/50], Step [217/735], Loss: 0.1323\n",
      "Epoch [37/50], Step [218/735], Loss: 0.1420\n",
      "Epoch [37/50], Step [219/735], Loss: 0.0829\n",
      "Epoch [37/50], Step [220/735], Loss: 0.1370\n",
      "Epoch [37/50], Step [221/735], Loss: 0.3695\n",
      "Epoch [37/50], Step [222/735], Loss: 0.0418\n",
      "Epoch [37/50], Step [223/735], Loss: 0.0629\n",
      "Epoch [37/50], Step [224/735], Loss: 0.1293\n",
      "Epoch [37/50], Step [225/735], Loss: 0.1691\n",
      "Epoch [37/50], Step [226/735], Loss: 0.1403\n",
      "Epoch [37/50], Step [227/735], Loss: 0.1250\n",
      "Epoch [37/50], Step [228/735], Loss: 0.0374\n",
      "Epoch [37/50], Step [229/735], Loss: 0.0416\n",
      "Epoch [37/50], Step [230/735], Loss: 0.0496\n",
      "Epoch [37/50], Step [231/735], Loss: 0.0888\n",
      "Epoch [37/50], Step [232/735], Loss: 0.1237\n",
      "Epoch [37/50], Step [233/735], Loss: 0.0792\n",
      "Epoch [37/50], Step [234/735], Loss: 0.1107\n",
      "Epoch [37/50], Step [235/735], Loss: 0.0947\n",
      "Epoch [37/50], Step [236/735], Loss: 0.0554\n",
      "Epoch [37/50], Step [237/735], Loss: 0.0867\n",
      "Epoch [37/50], Step [238/735], Loss: 0.0968\n",
      "Epoch [37/50], Step [239/735], Loss: 0.1018\n",
      "Epoch [37/50], Step [240/735], Loss: 0.0349\n",
      "Epoch [37/50], Step [241/735], Loss: 0.0321\n",
      "Epoch [37/50], Step [242/735], Loss: 0.0860\n",
      "Epoch [37/50], Step [243/735], Loss: 0.1659\n",
      "Epoch [37/50], Step [244/735], Loss: 0.4458\n",
      "Epoch [37/50], Step [245/735], Loss: 0.1312\n",
      "Epoch [37/50], Step [246/735], Loss: 0.0247\n",
      "Epoch [37/50], Step [247/735], Loss: 0.4447\n",
      "Epoch [37/50], Step [248/735], Loss: 0.0950\n",
      "Epoch [37/50], Step [249/735], Loss: 0.0651\n",
      "Epoch [37/50], Step [250/735], Loss: 0.0894\n",
      "Epoch [37/50], Step [251/735], Loss: 0.1439\n",
      "Epoch [37/50], Step [252/735], Loss: 0.1758\n",
      "Epoch [37/50], Step [253/735], Loss: 0.1081\n",
      "Epoch [37/50], Step [254/735], Loss: 0.1795\n",
      "Epoch [37/50], Step [255/735], Loss: 0.1031\n",
      "Epoch [37/50], Step [256/735], Loss: 0.0385\n",
      "Epoch [37/50], Step [257/735], Loss: 0.0696\n",
      "Epoch [37/50], Step [258/735], Loss: 0.0443\n",
      "Epoch [37/50], Step [259/735], Loss: 0.0917\n",
      "Epoch [37/50], Step [260/735], Loss: 0.4598\n",
      "Epoch [37/50], Step [261/735], Loss: 0.0866\n",
      "Epoch [37/50], Step [262/735], Loss: 0.5108\n",
      "Epoch [37/50], Step [263/735], Loss: 0.2436\n",
      "Epoch [37/50], Step [264/735], Loss: 0.0877\n",
      "Epoch [37/50], Step [265/735], Loss: 0.2506\n",
      "Epoch [37/50], Step [266/735], Loss: 0.0285\n",
      "Epoch [37/50], Step [267/735], Loss: 0.1344\n",
      "Epoch [37/50], Step [268/735], Loss: 0.0921\n",
      "Epoch [37/50], Step [269/735], Loss: 0.0853\n",
      "Epoch [37/50], Step [270/735], Loss: 0.0748\n",
      "Epoch [37/50], Step [271/735], Loss: 0.0833\n",
      "Epoch [37/50], Step [272/735], Loss: 0.0607\n",
      "Epoch [37/50], Step [273/735], Loss: 0.0885\n",
      "Epoch [37/50], Step [274/735], Loss: 0.1427\n",
      "Epoch [37/50], Step [275/735], Loss: 0.1575\n",
      "Epoch [37/50], Step [276/735], Loss: 0.0669\n",
      "Epoch [37/50], Step [277/735], Loss: 0.1481\n",
      "Epoch [37/50], Step [278/735], Loss: 0.1005\n",
      "Epoch [37/50], Step [279/735], Loss: 0.1271\n",
      "Epoch [37/50], Step [280/735], Loss: 0.2156\n",
      "Epoch [37/50], Step [281/735], Loss: 0.3643\n",
      "Epoch [37/50], Step [282/735], Loss: 0.1136\n",
      "Epoch [37/50], Step [283/735], Loss: 0.0427\n",
      "Epoch [37/50], Step [284/735], Loss: 0.1191\n",
      "Epoch [37/50], Step [285/735], Loss: 0.0379\n",
      "Epoch [37/50], Step [286/735], Loss: 0.1430\n",
      "Epoch [37/50], Step [287/735], Loss: 0.0713\n",
      "Epoch [37/50], Step [288/735], Loss: 0.0502\n",
      "Epoch [37/50], Step [289/735], Loss: 0.1616\n",
      "Epoch [37/50], Step [290/735], Loss: 0.0923\n",
      "Epoch [37/50], Step [291/735], Loss: 0.0702\n",
      "Epoch [37/50], Step [292/735], Loss: 0.0558\n",
      "Epoch [37/50], Step [293/735], Loss: 0.0550\n",
      "Epoch [37/50], Step [294/735], Loss: 0.0516\n",
      "Epoch [37/50], Step [295/735], Loss: 0.0590\n",
      "Epoch [37/50], Step [296/735], Loss: 0.0903\n",
      "Epoch [37/50], Step [297/735], Loss: 0.0441\n",
      "Epoch [37/50], Step [298/735], Loss: 0.1106\n",
      "Epoch [37/50], Step [299/735], Loss: 0.0479\n",
      "Epoch [37/50], Step [300/735], Loss: 0.0830\n",
      "Epoch [37/50], Step [301/735], Loss: 0.1078\n",
      "Epoch [37/50], Step [302/735], Loss: 0.0650\n",
      "Epoch [37/50], Step [303/735], Loss: 0.0981\n",
      "Epoch [37/50], Step [304/735], Loss: 0.0409\n",
      "Epoch [37/50], Step [305/735], Loss: 0.1026\n",
      "Epoch [37/50], Step [306/735], Loss: 0.2052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Step [307/735], Loss: 0.0645\n",
      "Epoch [37/50], Step [308/735], Loss: 0.0673\n",
      "Epoch [37/50], Step [309/735], Loss: 0.1576\n",
      "Epoch [37/50], Step [310/735], Loss: 0.0290\n",
      "Epoch [37/50], Step [311/735], Loss: 0.0491\n",
      "Epoch [37/50], Step [312/735], Loss: 0.2098\n",
      "Epoch [37/50], Step [313/735], Loss: 0.0431\n",
      "Epoch [37/50], Step [314/735], Loss: 0.1769\n",
      "Epoch [37/50], Step [315/735], Loss: 0.1879\n",
      "Epoch [37/50], Step [316/735], Loss: 0.0585\n",
      "Epoch [37/50], Step [317/735], Loss: 0.1478\n",
      "Epoch [37/50], Step [318/735], Loss: 0.1052\n",
      "Epoch [37/50], Step [319/735], Loss: 0.0537\n",
      "Epoch [37/50], Step [320/735], Loss: 0.2438\n",
      "Epoch [37/50], Step [321/735], Loss: 0.2710\n",
      "Epoch [37/50], Step [322/735], Loss: 0.0808\n",
      "Epoch [37/50], Step [323/735], Loss: 0.0858\n",
      "Epoch [37/50], Step [324/735], Loss: 0.1276\n",
      "Epoch [37/50], Step [325/735], Loss: 0.1246\n",
      "Epoch [37/50], Step [326/735], Loss: 0.0807\n",
      "Epoch [37/50], Step [327/735], Loss: 0.1324\n",
      "Epoch [37/50], Step [328/735], Loss: 0.1262\n",
      "Epoch [37/50], Step [329/735], Loss: 0.3247\n",
      "Epoch [37/50], Step [330/735], Loss: 0.0995\n",
      "Epoch [37/50], Step [331/735], Loss: 0.0783\n",
      "Epoch [37/50], Step [332/735], Loss: 0.1081\n",
      "Epoch [37/50], Step [333/735], Loss: 0.0578\n",
      "Epoch [37/50], Step [334/735], Loss: 0.1178\n",
      "Epoch [37/50], Step [335/735], Loss: 0.0940\n",
      "Epoch [37/50], Step [336/735], Loss: 0.1944\n",
      "Epoch [37/50], Step [337/735], Loss: 0.0502\n",
      "Epoch [37/50], Step [338/735], Loss: 0.1701\n",
      "Epoch [37/50], Step [339/735], Loss: 0.2018\n",
      "Epoch [37/50], Step [340/735], Loss: 0.1376\n",
      "Epoch [37/50], Step [341/735], Loss: 0.0726\n",
      "Epoch [37/50], Step [342/735], Loss: 0.0948\n",
      "Epoch [37/50], Step [343/735], Loss: 0.1826\n",
      "Epoch [37/50], Step [344/735], Loss: 0.1204\n",
      "Epoch [37/50], Step [345/735], Loss: 0.0843\n",
      "Epoch [37/50], Step [346/735], Loss: 0.0495\n",
      "Epoch [37/50], Step [347/735], Loss: 0.0631\n",
      "Epoch [37/50], Step [348/735], Loss: 1.6030\n",
      "Epoch [37/50], Step [349/735], Loss: 0.1571\n",
      "Epoch [37/50], Step [350/735], Loss: 0.0596\n",
      "Epoch [37/50], Step [351/735], Loss: 0.1398\n",
      "Epoch [37/50], Step [352/735], Loss: 0.1892\n",
      "Epoch [37/50], Step [353/735], Loss: 0.1288\n",
      "Epoch [37/50], Step [354/735], Loss: 0.0342\n",
      "Epoch [37/50], Step [355/735], Loss: 0.0540\n",
      "Epoch [37/50], Step [356/735], Loss: 0.1677\n",
      "Epoch [37/50], Step [357/735], Loss: 0.1548\n",
      "Epoch [37/50], Step [358/735], Loss: 0.0800\n",
      "Epoch [37/50], Step [359/735], Loss: 0.0951\n",
      "Epoch [37/50], Step [360/735], Loss: 0.2506\n",
      "Epoch [37/50], Step [361/735], Loss: 0.0447\n",
      "Epoch [37/50], Step [362/735], Loss: 0.1946\n",
      "Epoch [37/50], Step [363/735], Loss: 0.0712\n",
      "Epoch [37/50], Step [364/735], Loss: 0.4471\n",
      "Epoch [37/50], Step [365/735], Loss: 0.0948\n",
      "Epoch [37/50], Step [366/735], Loss: 0.0990\n",
      "Epoch [37/50], Step [367/735], Loss: 0.0723\n",
      "Epoch [37/50], Step [368/735], Loss: 0.0862\n",
      "Epoch [37/50], Step [369/735], Loss: 0.0518\n",
      "Epoch [37/50], Step [370/735], Loss: 0.0903\n",
      "Epoch [37/50], Step [371/735], Loss: 0.0763\n",
      "Epoch [37/50], Step [372/735], Loss: 0.0816\n",
      "Epoch [37/50], Step [373/735], Loss: 0.0681\n",
      "Epoch [37/50], Step [374/735], Loss: 0.7776\n",
      "Epoch [37/50], Step [375/735], Loss: 0.0730\n",
      "Epoch [37/50], Step [376/735], Loss: 0.1315\n",
      "Epoch [37/50], Step [377/735], Loss: 0.4704\n",
      "Epoch [37/50], Step [378/735], Loss: 0.1683\n",
      "Epoch [37/50], Step [379/735], Loss: 0.1051\n",
      "Epoch [37/50], Step [380/735], Loss: 0.1358\n",
      "Epoch [37/50], Step [381/735], Loss: 0.3135\n",
      "Epoch [37/50], Step [382/735], Loss: 0.0674\n",
      "Epoch [37/50], Step [383/735], Loss: 0.0965\n",
      "Epoch [37/50], Step [384/735], Loss: 0.0268\n",
      "Epoch [37/50], Step [385/735], Loss: 0.0653\n",
      "Epoch [37/50], Step [386/735], Loss: 0.1378\n",
      "Epoch [37/50], Step [387/735], Loss: 0.1427\n",
      "Epoch [37/50], Step [388/735], Loss: 0.0932\n",
      "Epoch [37/50], Step [389/735], Loss: 0.0542\n",
      "Epoch [37/50], Step [390/735], Loss: 0.0830\n",
      "Epoch [37/50], Step [391/735], Loss: 0.0809\n",
      "Epoch [37/50], Step [392/735], Loss: 0.0450\n",
      "Epoch [37/50], Step [393/735], Loss: 0.4227\n",
      "Epoch [37/50], Step [394/735], Loss: 0.1378\n",
      "Epoch [37/50], Step [395/735], Loss: 1.5190\n",
      "Epoch [37/50], Step [396/735], Loss: 0.0877\n",
      "Epoch [37/50], Step [397/735], Loss: 0.1256\n",
      "Epoch [37/50], Step [398/735], Loss: 0.0803\n",
      "Epoch [37/50], Step [399/735], Loss: 0.1383\n",
      "Epoch [37/50], Step [400/735], Loss: 0.1405\n",
      "Epoch [37/50], Step [401/735], Loss: 0.1565\n",
      "Epoch [37/50], Step [402/735], Loss: 0.0956\n",
      "Epoch [37/50], Step [403/735], Loss: 0.1048\n",
      "Epoch [37/50], Step [404/735], Loss: 0.0376\n",
      "Epoch [37/50], Step [405/735], Loss: 0.1942\n",
      "Epoch [37/50], Step [406/735], Loss: 0.0856\n",
      "Epoch [37/50], Step [407/735], Loss: 0.1216\n",
      "Epoch [37/50], Step [408/735], Loss: 0.0965\n",
      "Epoch [37/50], Step [409/735], Loss: 0.0650\n",
      "Epoch [37/50], Step [410/735], Loss: 0.3085\n",
      "Epoch [37/50], Step [411/735], Loss: 0.0777\n",
      "Epoch [37/50], Step [412/735], Loss: 0.0490\n",
      "Epoch [37/50], Step [413/735], Loss: 0.0423\n",
      "Epoch [37/50], Step [414/735], Loss: 0.0507\n",
      "Epoch [37/50], Step [415/735], Loss: 0.0833\n",
      "Epoch [37/50], Step [416/735], Loss: 0.1462\n",
      "Epoch [37/50], Step [417/735], Loss: 0.9371\n",
      "Epoch [37/50], Step [418/735], Loss: 0.0472\n",
      "Epoch [37/50], Step [419/735], Loss: 0.1104\n",
      "Epoch [37/50], Step [420/735], Loss: 0.1579\n",
      "Epoch [37/50], Step [421/735], Loss: 0.2295\n",
      "Epoch [37/50], Step [422/735], Loss: 0.1215\n",
      "Epoch [37/50], Step [423/735], Loss: 0.1053\n",
      "Epoch [37/50], Step [424/735], Loss: 0.0660\n",
      "Epoch [37/50], Step [425/735], Loss: 0.1309\n",
      "Epoch [37/50], Step [426/735], Loss: 0.1073\n",
      "Epoch [37/50], Step [427/735], Loss: 0.0466\n",
      "Epoch [37/50], Step [428/735], Loss: 0.0614\n",
      "Epoch [37/50], Step [429/735], Loss: 0.1169\n",
      "Epoch [37/50], Step [430/735], Loss: 0.0454\n",
      "Epoch [37/50], Step [431/735], Loss: 0.0711\n",
      "Epoch [37/50], Step [432/735], Loss: 0.0585\n",
      "Epoch [37/50], Step [433/735], Loss: 0.0953\n",
      "Epoch [37/50], Step [434/735], Loss: 0.1782\n",
      "Epoch [37/50], Step [435/735], Loss: 0.0802\n",
      "Epoch [37/50], Step [436/735], Loss: 0.2211\n",
      "Epoch [37/50], Step [437/735], Loss: 0.0361\n",
      "Epoch [37/50], Step [438/735], Loss: 0.1113\n",
      "Epoch [37/50], Step [439/735], Loss: 0.1529\n",
      "Epoch [37/50], Step [440/735], Loss: 0.6294\n",
      "Epoch [37/50], Step [441/735], Loss: 0.0772\n",
      "Epoch [37/50], Step [442/735], Loss: 0.0744\n",
      "Epoch [37/50], Step [443/735], Loss: 0.1252\n",
      "Epoch [37/50], Step [444/735], Loss: 0.1190\n",
      "Epoch [37/50], Step [445/735], Loss: 0.7252\n",
      "Epoch [37/50], Step [446/735], Loss: 0.1707\n",
      "Epoch [37/50], Step [447/735], Loss: 0.0449\n",
      "Epoch [37/50], Step [448/735], Loss: 0.1156\n",
      "Epoch [37/50], Step [449/735], Loss: 0.0670\n",
      "Epoch [37/50], Step [450/735], Loss: 0.0613\n",
      "Epoch [37/50], Step [451/735], Loss: 0.1875\n",
      "Epoch [37/50], Step [452/735], Loss: 0.0646\n",
      "Epoch [37/50], Step [453/735], Loss: 0.0864\n",
      "Epoch [37/50], Step [454/735], Loss: 0.0503\n",
      "Epoch [37/50], Step [455/735], Loss: 0.0596\n",
      "Epoch [37/50], Step [456/735], Loss: 0.1490\n",
      "Epoch [37/50], Step [457/735], Loss: 0.0360\n",
      "Epoch [37/50], Step [458/735], Loss: 0.4583\n",
      "Epoch [37/50], Step [459/735], Loss: 0.0985\n",
      "Epoch [37/50], Step [460/735], Loss: 0.0605\n",
      "Epoch [37/50], Step [461/735], Loss: 0.0652\n",
      "Epoch [37/50], Step [462/735], Loss: 0.8150\n",
      "Epoch [37/50], Step [463/735], Loss: 0.2261\n",
      "Epoch [37/50], Step [464/735], Loss: 0.1225\n",
      "Epoch [37/50], Step [465/735], Loss: 0.0382\n",
      "Epoch [37/50], Step [466/735], Loss: 0.1086\n",
      "Epoch [37/50], Step [467/735], Loss: 0.0709\n",
      "Epoch [37/50], Step [468/735], Loss: 0.0689\n",
      "Epoch [37/50], Step [469/735], Loss: 0.0730\n",
      "Epoch [37/50], Step [470/735], Loss: 0.0858\n",
      "Epoch [37/50], Step [471/735], Loss: 0.1086\n",
      "Epoch [37/50], Step [472/735], Loss: 0.0237\n",
      "Epoch [37/50], Step [473/735], Loss: 0.0984\n",
      "Epoch [37/50], Step [474/735], Loss: 0.1356\n",
      "Epoch [37/50], Step [475/735], Loss: 0.0240\n",
      "Epoch [37/50], Step [476/735], Loss: 0.7304\n",
      "Epoch [37/50], Step [477/735], Loss: 0.0693\n",
      "Epoch [37/50], Step [478/735], Loss: 0.1292\n",
      "Epoch [37/50], Step [479/735], Loss: 0.1832\n",
      "Epoch [37/50], Step [480/735], Loss: 0.0577\n",
      "Epoch [37/50], Step [481/735], Loss: 0.0848\n",
      "Epoch [37/50], Step [482/735], Loss: 0.1044\n",
      "Epoch [37/50], Step [483/735], Loss: 0.1438\n",
      "Epoch [37/50], Step [484/735], Loss: 0.1626\n",
      "Epoch [37/50], Step [485/735], Loss: 0.1432\n",
      "Epoch [37/50], Step [486/735], Loss: 0.0616\n",
      "Epoch [37/50], Step [487/735], Loss: 0.0622\n",
      "Epoch [37/50], Step [488/735], Loss: 0.0420\n",
      "Epoch [37/50], Step [489/735], Loss: 0.0852\n",
      "Epoch [37/50], Step [490/735], Loss: 0.0450\n",
      "Epoch [37/50], Step [491/735], Loss: 0.1650\n",
      "Epoch [37/50], Step [492/735], Loss: 0.0296\n",
      "Epoch [37/50], Step [493/735], Loss: 0.1452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Step [494/735], Loss: 0.0527\n",
      "Epoch [37/50], Step [495/735], Loss: 0.8224\n",
      "Epoch [37/50], Step [496/735], Loss: 0.1214\n",
      "Epoch [37/50], Step [497/735], Loss: 0.5262\n",
      "Epoch [37/50], Step [498/735], Loss: 0.0645\n",
      "Epoch [37/50], Step [499/735], Loss: 0.0809\n",
      "Epoch [37/50], Step [500/735], Loss: 0.0794\n",
      "Epoch [37/50], Step [501/735], Loss: 0.0757\n",
      "Epoch [37/50], Step [502/735], Loss: 0.2012\n",
      "Epoch [37/50], Step [503/735], Loss: 0.0782\n",
      "Epoch [37/50], Step [504/735], Loss: 0.1221\n",
      "Epoch [37/50], Step [505/735], Loss: 0.0481\n",
      "Epoch [37/50], Step [506/735], Loss: 0.1431\n",
      "Epoch [37/50], Step [507/735], Loss: 0.0708\n",
      "Epoch [37/50], Step [508/735], Loss: 0.0626\n",
      "Epoch [37/50], Step [509/735], Loss: 0.0791\n",
      "Epoch [37/50], Step [510/735], Loss: 0.0511\n",
      "Epoch [37/50], Step [511/735], Loss: 0.0446\n",
      "Epoch [37/50], Step [512/735], Loss: 0.0777\n",
      "Epoch [37/50], Step [513/735], Loss: 1.0079\n",
      "Epoch [37/50], Step [514/735], Loss: 0.0836\n",
      "Epoch [37/50], Step [515/735], Loss: 0.1236\n",
      "Epoch [37/50], Step [516/735], Loss: 0.2112\n",
      "Epoch [37/50], Step [517/735], Loss: 0.0709\n",
      "Epoch [37/50], Step [518/735], Loss: 0.0459\n",
      "Epoch [37/50], Step [519/735], Loss: 0.1276\n",
      "Epoch [37/50], Step [520/735], Loss: 0.0822\n",
      "Epoch [37/50], Step [521/735], Loss: 0.0687\n",
      "Epoch [37/50], Step [522/735], Loss: 0.0941\n",
      "Epoch [37/50], Step [523/735], Loss: 0.0433\n",
      "Epoch [37/50], Step [524/735], Loss: 0.0664\n",
      "Epoch [37/50], Step [525/735], Loss: 0.0441\n",
      "Epoch [37/50], Step [526/735], Loss: 0.0661\n",
      "Epoch [37/50], Step [527/735], Loss: 0.0755\n",
      "Epoch [37/50], Step [528/735], Loss: 0.0282\n",
      "Epoch [37/50], Step [529/735], Loss: 0.0404\n",
      "Epoch [37/50], Step [530/735], Loss: 0.0743\n",
      "Epoch [37/50], Step [531/735], Loss: 0.0552\n",
      "Epoch [37/50], Step [532/735], Loss: 0.2122\n",
      "Epoch [37/50], Step [533/735], Loss: 0.0923\n",
      "Epoch [37/50], Step [534/735], Loss: 0.0526\n",
      "Epoch [37/50], Step [535/735], Loss: 0.1134\n",
      "Epoch [37/50], Step [536/735], Loss: 0.0979\n",
      "Epoch [37/50], Step [537/735], Loss: 0.1990\n",
      "Epoch [37/50], Step [538/735], Loss: 0.0457\n",
      "Epoch [37/50], Step [539/735], Loss: 0.1168\n",
      "Epoch [37/50], Step [540/735], Loss: 0.1703\n",
      "Epoch [37/50], Step [541/735], Loss: 0.1173\n",
      "Epoch [37/50], Step [542/735], Loss: 0.0316\n",
      "Epoch [37/50], Step [543/735], Loss: 0.0882\n",
      "Epoch [37/50], Step [544/735], Loss: 0.1219\n",
      "Epoch [37/50], Step [545/735], Loss: 0.0846\n",
      "Epoch [37/50], Step [546/735], Loss: 0.1295\n",
      "Epoch [37/50], Step [547/735], Loss: 0.0463\n",
      "Epoch [37/50], Step [548/735], Loss: 0.0478\n",
      "Epoch [37/50], Step [549/735], Loss: 0.2141\n",
      "Epoch [37/50], Step [550/735], Loss: 0.3530\n",
      "Epoch [37/50], Step [551/735], Loss: 0.0766\n",
      "Epoch [37/50], Step [552/735], Loss: 0.1683\n",
      "Epoch [37/50], Step [553/735], Loss: 0.1259\n",
      "Epoch [37/50], Step [554/735], Loss: 0.1139\n",
      "Epoch [37/50], Step [555/735], Loss: 0.0753\n",
      "Epoch [37/50], Step [556/735], Loss: 0.1308\n",
      "Epoch [37/50], Step [557/735], Loss: 0.1392\n",
      "Epoch [37/50], Step [558/735], Loss: 0.1429\n",
      "Epoch [37/50], Step [559/735], Loss: 0.4329\n",
      "Epoch [37/50], Step [560/735], Loss: 0.1312\n",
      "Epoch [37/50], Step [561/735], Loss: 0.1736\n",
      "Epoch [37/50], Step [562/735], Loss: 0.1459\n",
      "Epoch [37/50], Step [563/735], Loss: 0.1662\n",
      "Epoch [37/50], Step [564/735], Loss: 0.1789\n",
      "Epoch [37/50], Step [565/735], Loss: 0.0849\n",
      "Epoch [37/50], Step [566/735], Loss: 0.0910\n",
      "Epoch [37/50], Step [567/735], Loss: 0.0404\n",
      "Epoch [37/50], Step [568/735], Loss: 0.0731\n",
      "Epoch [37/50], Step [569/735], Loss: 0.3680\n",
      "Epoch [37/50], Step [570/735], Loss: 0.1283\n",
      "Epoch [37/50], Step [571/735], Loss: 0.1339\n",
      "Epoch [37/50], Step [572/735], Loss: 0.0663\n",
      "Epoch [37/50], Step [573/735], Loss: 0.0707\n",
      "Epoch [37/50], Step [574/735], Loss: 0.0987\n",
      "Epoch [37/50], Step [575/735], Loss: 0.0495\n",
      "Epoch [37/50], Step [576/735], Loss: 0.0897\n",
      "Epoch [37/50], Step [577/735], Loss: 0.2618\n",
      "Epoch [37/50], Step [578/735], Loss: 0.1299\n",
      "Epoch [37/50], Step [579/735], Loss: 0.0967\n",
      "Epoch [37/50], Step [580/735], Loss: 0.0652\n",
      "Epoch [37/50], Step [581/735], Loss: 0.0646\n",
      "Epoch [37/50], Step [582/735], Loss: 0.0330\n",
      "Epoch [37/50], Step [583/735], Loss: 0.0841\n",
      "Epoch [37/50], Step [584/735], Loss: 0.1665\n",
      "Epoch [37/50], Step [585/735], Loss: 0.2004\n",
      "Epoch [37/50], Step [586/735], Loss: 0.0625\n",
      "Epoch [37/50], Step [587/735], Loss: 0.1149\n",
      "Epoch [37/50], Step [588/735], Loss: 0.0804\n",
      "Epoch [37/50], Step [589/735], Loss: 0.1017\n",
      "Epoch [37/50], Step [590/735], Loss: 0.0934\n",
      "Epoch [37/50], Step [591/735], Loss: 0.1054\n",
      "Epoch [37/50], Step [592/735], Loss: 0.0413\n",
      "Epoch [37/50], Step [593/735], Loss: 0.1685\n",
      "Epoch [37/50], Step [594/735], Loss: 0.0894\n",
      "Epoch [37/50], Step [595/735], Loss: 0.1019\n",
      "Epoch [37/50], Step [596/735], Loss: 0.0658\n",
      "Epoch [37/50], Step [597/735], Loss: 0.0454\n",
      "Epoch [37/50], Step [598/735], Loss: 0.0786\n",
      "Epoch [37/50], Step [599/735], Loss: 0.1996\n",
      "Epoch [37/50], Step [600/735], Loss: 0.0464\n",
      "Epoch [37/50], Step [601/735], Loss: 0.0729\n",
      "Epoch [37/50], Step [602/735], Loss: 0.0398\n",
      "Epoch [37/50], Step [603/735], Loss: 0.1398\n",
      "Epoch [37/50], Step [604/735], Loss: 0.1200\n",
      "Epoch [37/50], Step [605/735], Loss: 0.0819\n",
      "Epoch [37/50], Step [606/735], Loss: 0.1109\n",
      "Epoch [37/50], Step [607/735], Loss: 0.2241\n",
      "Epoch [37/50], Step [608/735], Loss: 0.0432\n",
      "Epoch [37/50], Step [609/735], Loss: 0.0346\n",
      "Epoch [37/50], Step [610/735], Loss: 0.0589\n",
      "Epoch [37/50], Step [611/735], Loss: 0.0428\n",
      "Epoch [37/50], Step [612/735], Loss: 0.0409\n",
      "Epoch [37/50], Step [613/735], Loss: 0.0464\n",
      "Epoch [37/50], Step [614/735], Loss: 0.0435\n",
      "Epoch [37/50], Step [615/735], Loss: 0.0870\n",
      "Epoch [37/50], Step [616/735], Loss: 0.0786\n",
      "Epoch [37/50], Step [617/735], Loss: 0.1427\n",
      "Epoch [37/50], Step [618/735], Loss: 0.0737\n",
      "Epoch [37/50], Step [619/735], Loss: 0.0290\n",
      "Epoch [37/50], Step [620/735], Loss: 0.1221\n",
      "Epoch [37/50], Step [621/735], Loss: 0.0643\n",
      "Epoch [37/50], Step [622/735], Loss: 0.1983\n",
      "Epoch [37/50], Step [623/735], Loss: 0.0390\n",
      "Epoch [37/50], Step [624/735], Loss: 0.0631\n",
      "Epoch [37/50], Step [625/735], Loss: 0.0484\n",
      "Epoch [37/50], Step [626/735], Loss: 0.0697\n",
      "Epoch [37/50], Step [627/735], Loss: 0.0892\n",
      "Epoch [37/50], Step [628/735], Loss: 0.0629\n",
      "Epoch [37/50], Step [629/735], Loss: 0.1375\n",
      "Epoch [37/50], Step [630/735], Loss: 0.1334\n",
      "Epoch [37/50], Step [631/735], Loss: 0.1096\n",
      "Epoch [37/50], Step [632/735], Loss: 0.5192\n",
      "Epoch [37/50], Step [633/735], Loss: 0.0432\n",
      "Epoch [37/50], Step [634/735], Loss: 0.0362\n",
      "Epoch [37/50], Step [635/735], Loss: 0.0724\n",
      "Epoch [37/50], Step [636/735], Loss: 0.0568\n",
      "Epoch [37/50], Step [637/735], Loss: 0.0793\n",
      "Epoch [37/50], Step [638/735], Loss: 0.1067\n",
      "Epoch [37/50], Step [639/735], Loss: 0.0766\n",
      "Epoch [37/50], Step [640/735], Loss: 0.2226\n",
      "Epoch [37/50], Step [641/735], Loss: 0.0668\n",
      "Epoch [37/50], Step [642/735], Loss: 0.0316\n",
      "Epoch [37/50], Step [643/735], Loss: 0.1257\n",
      "Epoch [37/50], Step [644/735], Loss: 0.1346\n",
      "Epoch [37/50], Step [645/735], Loss: 0.1331\n",
      "Epoch [37/50], Step [646/735], Loss: 0.0871\n",
      "Epoch [37/50], Step [647/735], Loss: 0.1043\n",
      "Epoch [37/50], Step [648/735], Loss: 0.0590\n",
      "Epoch [37/50], Step [649/735], Loss: 0.1252\n",
      "Epoch [37/50], Step [650/735], Loss: 0.0365\n",
      "Epoch [37/50], Step [651/735], Loss: 0.1285\n",
      "Epoch [37/50], Step [652/735], Loss: 0.1184\n",
      "Epoch [37/50], Step [653/735], Loss: 0.2241\n",
      "Epoch [37/50], Step [654/735], Loss: 0.0614\n",
      "Epoch [37/50], Step [655/735], Loss: 0.0724\n",
      "Epoch [37/50], Step [656/735], Loss: 0.1260\n",
      "Epoch [37/50], Step [657/735], Loss: 0.0744\n",
      "Epoch [37/50], Step [658/735], Loss: 0.0886\n",
      "Epoch [37/50], Step [659/735], Loss: 0.0712\n",
      "Epoch [37/50], Step [660/735], Loss: 0.0485\n",
      "Epoch [37/50], Step [661/735], Loss: 0.7411\n",
      "Epoch [37/50], Step [662/735], Loss: 0.1768\n",
      "Epoch [37/50], Step [663/735], Loss: 0.1241\n",
      "Epoch [37/50], Step [664/735], Loss: 0.1032\n",
      "Epoch [37/50], Step [665/735], Loss: 0.0914\n",
      "Epoch [37/50], Step [666/735], Loss: 0.1021\n",
      "Epoch [37/50], Step [667/735], Loss: 0.0948\n",
      "Epoch [37/50], Step [668/735], Loss: 0.0928\n",
      "Epoch [37/50], Step [669/735], Loss: 0.0546\n",
      "Epoch [37/50], Step [670/735], Loss: 1.5974\n",
      "Epoch [37/50], Step [671/735], Loss: 1.8675\n",
      "Epoch [37/50], Step [672/735], Loss: 0.1419\n",
      "Epoch [37/50], Step [673/735], Loss: 0.0900\n",
      "Epoch [37/50], Step [674/735], Loss: 0.1125\n",
      "Epoch [37/50], Step [675/735], Loss: 0.1035\n",
      "Epoch [37/50], Step [676/735], Loss: 0.1028\n",
      "Epoch [37/50], Step [677/735], Loss: 0.1022\n",
      "Epoch [37/50], Step [678/735], Loss: 0.1087\n",
      "Epoch [37/50], Step [679/735], Loss: 0.6250\n",
      "Epoch [37/50], Step [680/735], Loss: 0.0909\n",
      "Epoch [37/50], Step [681/735], Loss: 0.2417\n",
      "Epoch [37/50], Step [682/735], Loss: 0.1549\n",
      "Epoch [37/50], Step [683/735], Loss: 0.0500\n",
      "Epoch [37/50], Step [684/735], Loss: 0.6974\n",
      "Epoch [37/50], Step [685/735], Loss: 0.0806\n",
      "Epoch [37/50], Step [686/735], Loss: 0.0626\n",
      "Epoch [37/50], Step [687/735], Loss: 0.0858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Step [688/735], Loss: 0.0750\n",
      "Epoch [37/50], Step [689/735], Loss: 0.3725\n",
      "Epoch [37/50], Step [690/735], Loss: 0.0614\n",
      "Epoch [37/50], Step [691/735], Loss: 0.1077\n",
      "Epoch [37/50], Step [692/735], Loss: 0.0558\n",
      "Epoch [37/50], Step [693/735], Loss: 0.0504\n",
      "Epoch [37/50], Step [694/735], Loss: 0.0837\n",
      "Epoch [37/50], Step [695/735], Loss: 0.1027\n",
      "Epoch [37/50], Step [696/735], Loss: 0.1833\n",
      "Epoch [37/50], Step [697/735], Loss: 0.1915\n",
      "Epoch [37/50], Step [698/735], Loss: 0.0940\n",
      "Epoch [37/50], Step [699/735], Loss: 0.1755\n",
      "Epoch [37/50], Step [700/735], Loss: 0.1475\n",
      "Epoch [37/50], Step [701/735], Loss: 0.2025\n",
      "Epoch [37/50], Step [702/735], Loss: 0.1092\n",
      "Epoch [37/50], Step [703/735], Loss: 0.1064\n",
      "Epoch [37/50], Step [704/735], Loss: 0.1069\n",
      "Epoch [37/50], Step [705/735], Loss: 0.1101\n",
      "Epoch [37/50], Step [706/735], Loss: 0.0715\n",
      "Epoch [37/50], Step [707/735], Loss: 0.1357\n",
      "Epoch [37/50], Step [708/735], Loss: 0.0480\n",
      "Epoch [37/50], Step [709/735], Loss: 0.0325\n",
      "Epoch [37/50], Step [710/735], Loss: 0.0551\n",
      "Epoch [37/50], Step [711/735], Loss: 0.4124\n",
      "Epoch [37/50], Step [712/735], Loss: 0.0400\n",
      "Epoch [37/50], Step [713/735], Loss: 0.0324\n",
      "Epoch [37/50], Step [714/735], Loss: 0.1465\n",
      "Epoch [37/50], Step [715/735], Loss: 0.6298\n",
      "Epoch [37/50], Step [716/735], Loss: 0.0308\n",
      "Epoch [37/50], Step [717/735], Loss: 0.0351\n",
      "Epoch [37/50], Step [718/735], Loss: 0.5465\n",
      "Epoch [37/50], Step [719/735], Loss: 0.0991\n",
      "Epoch [37/50], Step [720/735], Loss: 0.1565\n",
      "Epoch [37/50], Step [721/735], Loss: 0.0848\n",
      "Epoch [37/50], Step [722/735], Loss: 0.1036\n",
      "Epoch [37/50], Step [723/735], Loss: 0.0845\n",
      "Epoch [37/50], Step [724/735], Loss: 0.0940\n",
      "Epoch [37/50], Step [725/735], Loss: 0.0763\n",
      "Epoch [37/50], Step [726/735], Loss: 0.0683\n",
      "Epoch [37/50], Step [727/735], Loss: 0.1632\n",
      "Epoch [37/50], Step [728/735], Loss: 0.1100\n",
      "Epoch [37/50], Step [729/735], Loss: 0.1272\n",
      "Epoch [37/50], Step [730/735], Loss: 0.7187\n",
      "Epoch [37/50], Step [731/735], Loss: 0.0798\n",
      "Epoch [37/50], Step [732/735], Loss: 0.0916\n",
      "Epoch [37/50], Step [733/735], Loss: 0.0683\n",
      "Epoch [37/50], Step [734/735], Loss: 0.0915\n",
      "Epoch [37/50], Step [735/735], Loss: 0.0814\n",
      "Epoch [38/50], Step [1/735], Loss: 0.0762\n",
      "Epoch [38/50], Step [2/735], Loss: 0.0473\n",
      "Epoch [38/50], Step [3/735], Loss: 0.0753\n",
      "Epoch [38/50], Step [4/735], Loss: 0.6548\n",
      "Epoch [38/50], Step [5/735], Loss: 0.0330\n",
      "Epoch [38/50], Step [6/735], Loss: 0.0619\n",
      "Epoch [38/50], Step [7/735], Loss: 0.0552\n",
      "Epoch [38/50], Step [8/735], Loss: 0.1270\n",
      "Epoch [38/50], Step [9/735], Loss: 0.0584\n",
      "Epoch [38/50], Step [10/735], Loss: 0.4074\n",
      "Epoch [38/50], Step [11/735], Loss: 0.2046\n",
      "Epoch [38/50], Step [12/735], Loss: 0.1027\n",
      "Epoch [38/50], Step [13/735], Loss: 0.0220\n",
      "Epoch [38/50], Step [14/735], Loss: 0.0424\n",
      "Epoch [38/50], Step [15/735], Loss: 0.0613\n",
      "Epoch [38/50], Step [16/735], Loss: 0.0712\n",
      "Epoch [38/50], Step [17/735], Loss: 0.0700\n",
      "Epoch [38/50], Step [18/735], Loss: 0.0631\n",
      "Epoch [38/50], Step [19/735], Loss: 0.1024\n",
      "Epoch [38/50], Step [20/735], Loss: 0.1047\n",
      "Epoch [38/50], Step [21/735], Loss: 0.0859\n",
      "Epoch [38/50], Step [22/735], Loss: 0.1065\n",
      "Epoch [38/50], Step [23/735], Loss: 0.1161\n",
      "Epoch [38/50], Step [24/735], Loss: 0.0635\n",
      "Epoch [38/50], Step [25/735], Loss: 0.0399\n",
      "Epoch [38/50], Step [26/735], Loss: 0.0381\n",
      "Epoch [38/50], Step [27/735], Loss: 0.1031\n",
      "Epoch [38/50], Step [28/735], Loss: 0.0988\n",
      "Epoch [38/50], Step [29/735], Loss: 0.0424\n",
      "Epoch [38/50], Step [30/735], Loss: 0.0778\n",
      "Epoch [38/50], Step [31/735], Loss: 0.1212\n",
      "Epoch [38/50], Step [32/735], Loss: 0.0561\n",
      "Epoch [38/50], Step [33/735], Loss: 0.2383\n",
      "Epoch [38/50], Step [34/735], Loss: 0.1788\n",
      "Epoch [38/50], Step [35/735], Loss: 0.0602\n",
      "Epoch [38/50], Step [36/735], Loss: 0.2116\n",
      "Epoch [38/50], Step [37/735], Loss: 0.0680\n",
      "Epoch [38/50], Step [38/735], Loss: 0.0627\n",
      "Epoch [38/50], Step [39/735], Loss: 0.0591\n",
      "Epoch [38/50], Step [40/735], Loss: 0.1783\n",
      "Epoch [38/50], Step [41/735], Loss: 0.1321\n",
      "Epoch [38/50], Step [42/735], Loss: 0.0847\n",
      "Epoch [38/50], Step [43/735], Loss: 0.0629\n",
      "Epoch [38/50], Step [44/735], Loss: 0.2507\n",
      "Epoch [38/50], Step [45/735], Loss: 0.2387\n",
      "Epoch [38/50], Step [46/735], Loss: 0.0962\n",
      "Epoch [38/50], Step [47/735], Loss: 0.1126\n",
      "Epoch [38/50], Step [48/735], Loss: 0.8822\n",
      "Epoch [38/50], Step [49/735], Loss: 0.1545\n",
      "Epoch [38/50], Step [50/735], Loss: 0.0682\n",
      "Epoch [38/50], Step [51/735], Loss: 0.0995\n",
      "Epoch [38/50], Step [52/735], Loss: 0.0791\n",
      "Epoch [38/50], Step [53/735], Loss: 0.0794\n",
      "Epoch [38/50], Step [54/735], Loss: 0.1099\n",
      "Epoch [38/50], Step [55/735], Loss: 0.0663\n",
      "Epoch [38/50], Step [56/735], Loss: 0.1238\n",
      "Epoch [38/50], Step [57/735], Loss: 0.1017\n",
      "Epoch [38/50], Step [58/735], Loss: 0.0732\n",
      "Epoch [38/50], Step [59/735], Loss: 0.2320\n",
      "Epoch [38/50], Step [60/735], Loss: 0.1577\n",
      "Epoch [38/50], Step [61/735], Loss: 0.1149\n",
      "Epoch [38/50], Step [62/735], Loss: 0.0727\n",
      "Epoch [38/50], Step [63/735], Loss: 0.1950\n",
      "Epoch [38/50], Step [64/735], Loss: 0.0355\n",
      "Epoch [38/50], Step [65/735], Loss: 1.0003\n",
      "Epoch [38/50], Step [66/735], Loss: 0.1329\n",
      "Epoch [38/50], Step [67/735], Loss: 0.1028\n",
      "Epoch [38/50], Step [68/735], Loss: 0.0670\n",
      "Epoch [38/50], Step [69/735], Loss: 0.1567\n",
      "Epoch [38/50], Step [70/735], Loss: 0.0711\n",
      "Epoch [38/50], Step [71/735], Loss: 0.0412\n",
      "Epoch [38/50], Step [72/735], Loss: 1.8431\n",
      "Epoch [38/50], Step [73/735], Loss: 0.0730\n",
      "Epoch [38/50], Step [74/735], Loss: 0.0415\n",
      "Epoch [38/50], Step [75/735], Loss: 0.2595\n",
      "Epoch [38/50], Step [76/735], Loss: 0.1296\n",
      "Epoch [38/50], Step [77/735], Loss: 0.1077\n",
      "Epoch [38/50], Step [78/735], Loss: 0.0668\n",
      "Epoch [38/50], Step [79/735], Loss: 0.0814\n",
      "Epoch [38/50], Step [80/735], Loss: 0.2518\n",
      "Epoch [38/50], Step [81/735], Loss: 0.0759\n",
      "Epoch [38/50], Step [82/735], Loss: 0.0625\n",
      "Epoch [38/50], Step [83/735], Loss: 0.0445\n",
      "Epoch [38/50], Step [84/735], Loss: 0.0795\n",
      "Epoch [38/50], Step [85/735], Loss: 0.0993\n",
      "Epoch [38/50], Step [86/735], Loss: 0.0900\n",
      "Epoch [38/50], Step [87/735], Loss: 0.0641\n",
      "Epoch [38/50], Step [88/735], Loss: 0.0851\n",
      "Epoch [38/50], Step [89/735], Loss: 0.1255\n",
      "Epoch [38/50], Step [90/735], Loss: 0.0681\n",
      "Epoch [38/50], Step [91/735], Loss: 0.0297\n",
      "Epoch [38/50], Step [92/735], Loss: 0.2025\n",
      "Epoch [38/50], Step [93/735], Loss: 0.0712\n",
      "Epoch [38/50], Step [94/735], Loss: 0.0916\n",
      "Epoch [38/50], Step [95/735], Loss: 0.0815\n",
      "Epoch [38/50], Step [96/735], Loss: 0.1491\n",
      "Epoch [38/50], Step [97/735], Loss: 0.2450\n",
      "Epoch [38/50], Step [98/735], Loss: 0.0384\n",
      "Epoch [38/50], Step [99/735], Loss: 0.0488\n",
      "Epoch [38/50], Step [100/735], Loss: 0.2415\n",
      "Epoch [38/50], Step [101/735], Loss: 0.6167\n",
      "Epoch [38/50], Step [102/735], Loss: 0.0934\n",
      "Epoch [38/50], Step [103/735], Loss: 0.0575\n",
      "Epoch [38/50], Step [104/735], Loss: 0.0441\n",
      "Epoch [38/50], Step [105/735], Loss: 0.0666\n",
      "Epoch [38/50], Step [106/735], Loss: 0.0677\n",
      "Epoch [38/50], Step [107/735], Loss: 0.0343\n",
      "Epoch [38/50], Step [108/735], Loss: 0.0846\n",
      "Epoch [38/50], Step [109/735], Loss: 0.0306\n",
      "Epoch [38/50], Step [110/735], Loss: 0.1553\n",
      "Epoch [38/50], Step [111/735], Loss: 0.2194\n",
      "Epoch [38/50], Step [112/735], Loss: 0.1465\n",
      "Epoch [38/50], Step [113/735], Loss: 0.0903\n",
      "Epoch [38/50], Step [114/735], Loss: 0.1280\n",
      "Epoch [38/50], Step [115/735], Loss: 0.0876\n",
      "Epoch [38/50], Step [116/735], Loss: 0.0504\n",
      "Epoch [38/50], Step [117/735], Loss: 0.2166\n",
      "Epoch [38/50], Step [118/735], Loss: 0.1291\n",
      "Epoch [38/50], Step [119/735], Loss: 0.1284\n",
      "Epoch [38/50], Step [120/735], Loss: 0.0521\n",
      "Epoch [38/50], Step [121/735], Loss: 0.0461\n",
      "Epoch [38/50], Step [122/735], Loss: 0.0522\n",
      "Epoch [38/50], Step [123/735], Loss: 0.1030\n",
      "Epoch [38/50], Step [124/735], Loss: 0.1417\n",
      "Epoch [38/50], Step [125/735], Loss: 0.1363\n",
      "Epoch [38/50], Step [126/735], Loss: 0.0369\n",
      "Epoch [38/50], Step [127/735], Loss: 0.0664\n",
      "Epoch [38/50], Step [128/735], Loss: 0.0804\n",
      "Epoch [38/50], Step [129/735], Loss: 0.0599\n",
      "Epoch [38/50], Step [130/735], Loss: 0.1790\n",
      "Epoch [38/50], Step [131/735], Loss: 0.1630\n",
      "Epoch [38/50], Step [132/735], Loss: 0.1066\n",
      "Epoch [38/50], Step [133/735], Loss: 0.0948\n",
      "Epoch [38/50], Step [134/735], Loss: 0.0458\n",
      "Epoch [38/50], Step [135/735], Loss: 0.0515\n",
      "Epoch [38/50], Step [136/735], Loss: 0.1147\n",
      "Epoch [38/50], Step [137/735], Loss: 0.0627\n",
      "Epoch [38/50], Step [138/735], Loss: 0.3636\n",
      "Epoch [38/50], Step [139/735], Loss: 0.0282\n",
      "Epoch [38/50], Step [140/735], Loss: 0.0904\n",
      "Epoch [38/50], Step [141/735], Loss: 0.0645\n",
      "Epoch [38/50], Step [142/735], Loss: 0.0879\n",
      "Epoch [38/50], Step [143/735], Loss: 0.1753\n",
      "Epoch [38/50], Step [144/735], Loss: 0.1194\n",
      "Epoch [38/50], Step [145/735], Loss: 0.0585\n",
      "Epoch [38/50], Step [146/735], Loss: 0.0813\n",
      "Epoch [38/50], Step [147/735], Loss: 0.0826\n",
      "Epoch [38/50], Step [148/735], Loss: 0.1657\n",
      "Epoch [38/50], Step [149/735], Loss: 0.1151\n",
      "Epoch [38/50], Step [150/735], Loss: 0.1503\n",
      "Epoch [38/50], Step [151/735], Loss: 0.1680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Step [152/735], Loss: 0.0337\n",
      "Epoch [38/50], Step [153/735], Loss: 0.1675\n",
      "Epoch [38/50], Step [154/735], Loss: 0.0629\n",
      "Epoch [38/50], Step [155/735], Loss: 0.1698\n",
      "Epoch [38/50], Step [156/735], Loss: 0.0811\n",
      "Epoch [38/50], Step [157/735], Loss: 0.0416\n",
      "Epoch [38/50], Step [158/735], Loss: 0.1066\n",
      "Epoch [38/50], Step [159/735], Loss: 0.1276\n",
      "Epoch [38/50], Step [160/735], Loss: 0.0958\n",
      "Epoch [38/50], Step [161/735], Loss: 0.2083\n",
      "Epoch [38/50], Step [162/735], Loss: 0.1341\n",
      "Epoch [38/50], Step [163/735], Loss: 0.1210\n",
      "Epoch [38/50], Step [164/735], Loss: 0.0807\n",
      "Epoch [38/50], Step [165/735], Loss: 0.1129\n",
      "Epoch [38/50], Step [166/735], Loss: 1.6653\n",
      "Epoch [38/50], Step [167/735], Loss: 0.0921\n",
      "Epoch [38/50], Step [168/735], Loss: 0.2796\n",
      "Epoch [38/50], Step [169/735], Loss: 0.1596\n",
      "Epoch [38/50], Step [170/735], Loss: 0.0769\n",
      "Epoch [38/50], Step [171/735], Loss: 0.0802\n",
      "Epoch [38/50], Step [172/735], Loss: 0.1089\n",
      "Epoch [38/50], Step [173/735], Loss: 0.0852\n",
      "Epoch [38/50], Step [174/735], Loss: 0.9344\n",
      "Epoch [38/50], Step [175/735], Loss: 0.6486\n",
      "Epoch [38/50], Step [176/735], Loss: 0.0839\n",
      "Epoch [38/50], Step [177/735], Loss: 0.1321\n",
      "Epoch [38/50], Step [178/735], Loss: 0.1272\n",
      "Epoch [38/50], Step [179/735], Loss: 0.0304\n",
      "Epoch [38/50], Step [180/735], Loss: 0.0699\n",
      "Epoch [38/50], Step [181/735], Loss: 0.0593\n",
      "Epoch [38/50], Step [182/735], Loss: 0.0516\n",
      "Epoch [38/50], Step [183/735], Loss: 0.1047\n",
      "Epoch [38/50], Step [184/735], Loss: 0.0594\n",
      "Epoch [38/50], Step [185/735], Loss: 0.1611\n",
      "Epoch [38/50], Step [186/735], Loss: 0.0369\n",
      "Epoch [38/50], Step [187/735], Loss: 0.0857\n",
      "Epoch [38/50], Step [188/735], Loss: 0.1252\n",
      "Epoch [38/50], Step [189/735], Loss: 0.0792\n",
      "Epoch [38/50], Step [190/735], Loss: 0.0886\n",
      "Epoch [38/50], Step [191/735], Loss: 0.5951\n",
      "Epoch [38/50], Step [192/735], Loss: 0.0950\n",
      "Epoch [38/50], Step [193/735], Loss: 1.1736\n",
      "Epoch [38/50], Step [194/735], Loss: 0.0888\n",
      "Epoch [38/50], Step [195/735], Loss: 0.0462\n",
      "Epoch [38/50], Step [196/735], Loss: 0.1659\n",
      "Epoch [38/50], Step [197/735], Loss: 0.0370\n",
      "Epoch [38/50], Step [198/735], Loss: 0.0562\n",
      "Epoch [38/50], Step [199/735], Loss: 0.0782\n",
      "Epoch [38/50], Step [200/735], Loss: 0.1541\n",
      "Epoch [38/50], Step [201/735], Loss: 0.1049\n",
      "Epoch [38/50], Step [202/735], Loss: 0.0775\n",
      "Epoch [38/50], Step [203/735], Loss: 0.1393\n",
      "Epoch [38/50], Step [204/735], Loss: 0.1473\n",
      "Epoch [38/50], Step [205/735], Loss: 0.0534\n",
      "Epoch [38/50], Step [206/735], Loss: 0.1019\n",
      "Epoch [38/50], Step [207/735], Loss: 0.1433\n",
      "Epoch [38/50], Step [208/735], Loss: 0.0830\n",
      "Epoch [38/50], Step [209/735], Loss: 0.0665\n",
      "Epoch [38/50], Step [210/735], Loss: 0.0568\n",
      "Epoch [38/50], Step [211/735], Loss: 0.1048\n",
      "Epoch [38/50], Step [212/735], Loss: 0.0519\n",
      "Epoch [38/50], Step [213/735], Loss: 0.0550\n",
      "Epoch [38/50], Step [214/735], Loss: 0.0480\n",
      "Epoch [38/50], Step [215/735], Loss: 0.0718\n",
      "Epoch [38/50], Step [216/735], Loss: 0.0713\n",
      "Epoch [38/50], Step [217/735], Loss: 0.5053\n",
      "Epoch [38/50], Step [218/735], Loss: 0.1153\n",
      "Epoch [38/50], Step [219/735], Loss: 0.0250\n",
      "Epoch [38/50], Step [220/735], Loss: 0.0940\n",
      "Epoch [38/50], Step [221/735], Loss: 0.1060\n",
      "Epoch [38/50], Step [222/735], Loss: 0.1006\n",
      "Epoch [38/50], Step [223/735], Loss: 0.0769\n",
      "Epoch [38/50], Step [224/735], Loss: 0.1004\n",
      "Epoch [38/50], Step [225/735], Loss: 1.7034\n",
      "Epoch [38/50], Step [226/735], Loss: 0.0687\n",
      "Epoch [38/50], Step [227/735], Loss: 0.0657\n",
      "Epoch [38/50], Step [228/735], Loss: 0.3852\n",
      "Epoch [38/50], Step [229/735], Loss: 0.0959\n",
      "Epoch [38/50], Step [230/735], Loss: 0.0409\n",
      "Epoch [38/50], Step [231/735], Loss: 0.1465\n",
      "Epoch [38/50], Step [232/735], Loss: 0.0613\n",
      "Epoch [38/50], Step [233/735], Loss: 1.2613\n",
      "Epoch [38/50], Step [234/735], Loss: 0.1223\n",
      "Epoch [38/50], Step [235/735], Loss: 0.0875\n",
      "Epoch [38/50], Step [236/735], Loss: 0.6783\n",
      "Epoch [38/50], Step [237/735], Loss: 0.1224\n",
      "Epoch [38/50], Step [238/735], Loss: 0.1182\n",
      "Epoch [38/50], Step [239/735], Loss: 0.0223\n",
      "Epoch [38/50], Step [240/735], Loss: 0.0662\n",
      "Epoch [38/50], Step [241/735], Loss: 0.1531\n",
      "Epoch [38/50], Step [242/735], Loss: 0.0693\n",
      "Epoch [38/50], Step [243/735], Loss: 0.0896\n",
      "Epoch [38/50], Step [244/735], Loss: 0.0400\n",
      "Epoch [38/50], Step [245/735], Loss: 0.0905\n",
      "Epoch [38/50], Step [246/735], Loss: 0.0678\n",
      "Epoch [38/50], Step [247/735], Loss: 0.1839\n",
      "Epoch [38/50], Step [248/735], Loss: 0.0670\n",
      "Epoch [38/50], Step [249/735], Loss: 0.0886\n",
      "Epoch [38/50], Step [250/735], Loss: 0.1553\n",
      "Epoch [38/50], Step [251/735], Loss: 0.0678\n",
      "Epoch [38/50], Step [252/735], Loss: 0.2452\n",
      "Epoch [38/50], Step [253/735], Loss: 0.5706\n",
      "Epoch [38/50], Step [254/735], Loss: 0.6430\n",
      "Epoch [38/50], Step [255/735], Loss: 0.1103\n",
      "Epoch [38/50], Step [256/735], Loss: 0.2264\n",
      "Epoch [38/50], Step [257/735], Loss: 0.1476\n",
      "Epoch [38/50], Step [258/735], Loss: 0.1848\n",
      "Epoch [38/50], Step [259/735], Loss: 0.0587\n",
      "Epoch [38/50], Step [260/735], Loss: 0.0804\n",
      "Epoch [38/50], Step [261/735], Loss: 0.0783\n",
      "Epoch [38/50], Step [262/735], Loss: 0.5337\n",
      "Epoch [38/50], Step [263/735], Loss: 0.1547\n",
      "Epoch [38/50], Step [264/735], Loss: 0.0841\n",
      "Epoch [38/50], Step [265/735], Loss: 0.1524\n",
      "Epoch [38/50], Step [266/735], Loss: 0.4699\n",
      "Epoch [38/50], Step [267/735], Loss: 1.4702\n",
      "Epoch [38/50], Step [268/735], Loss: 0.0579\n",
      "Epoch [38/50], Step [269/735], Loss: 0.0653\n",
      "Epoch [38/50], Step [270/735], Loss: 0.1056\n",
      "Epoch [38/50], Step [271/735], Loss: 0.0617\n",
      "Epoch [38/50], Step [272/735], Loss: 0.0507\n",
      "Epoch [38/50], Step [273/735], Loss: 0.0860\n",
      "Epoch [38/50], Step [274/735], Loss: 0.2803\n",
      "Epoch [38/50], Step [275/735], Loss: 0.1185\n",
      "Epoch [38/50], Step [276/735], Loss: 0.1134\n",
      "Epoch [38/50], Step [277/735], Loss: 0.0850\n",
      "Epoch [38/50], Step [278/735], Loss: 0.0846\n",
      "Epoch [38/50], Step [279/735], Loss: 0.0368\n",
      "Epoch [38/50], Step [280/735], Loss: 0.0612\n",
      "Epoch [38/50], Step [281/735], Loss: 0.0914\n",
      "Epoch [38/50], Step [282/735], Loss: 0.2058\n",
      "Epoch [38/50], Step [283/735], Loss: 0.1121\n",
      "Epoch [38/50], Step [284/735], Loss: 0.0790\n",
      "Epoch [38/50], Step [285/735], Loss: 0.0721\n",
      "Epoch [38/50], Step [286/735], Loss: 0.0481\n",
      "Epoch [38/50], Step [287/735], Loss: 0.0654\n",
      "Epoch [38/50], Step [288/735], Loss: 0.0617\n",
      "Epoch [38/50], Step [289/735], Loss: 0.0601\n",
      "Epoch [38/50], Step [290/735], Loss: 0.1224\n",
      "Epoch [38/50], Step [291/735], Loss: 0.1267\n",
      "Epoch [38/50], Step [292/735], Loss: 0.3048\n",
      "Epoch [38/50], Step [293/735], Loss: 0.0697\n",
      "Epoch [38/50], Step [294/735], Loss: 0.1340\n",
      "Epoch [38/50], Step [295/735], Loss: 0.0421\n",
      "Epoch [38/50], Step [296/735], Loss: 0.1061\n",
      "Epoch [38/50], Step [297/735], Loss: 0.5026\n",
      "Epoch [38/50], Step [298/735], Loss: 0.0844\n",
      "Epoch [38/50], Step [299/735], Loss: 0.1062\n",
      "Epoch [38/50], Step [300/735], Loss: 0.0740\n",
      "Epoch [38/50], Step [301/735], Loss: 0.3127\n",
      "Epoch [38/50], Step [302/735], Loss: 0.2246\n",
      "Epoch [38/50], Step [303/735], Loss: 0.3216\n",
      "Epoch [38/50], Step [304/735], Loss: 0.1028\n",
      "Epoch [38/50], Step [305/735], Loss: 0.0984\n",
      "Epoch [38/50], Step [306/735], Loss: 0.0994\n",
      "Epoch [38/50], Step [307/735], Loss: 0.0261\n",
      "Epoch [38/50], Step [308/735], Loss: 0.0593\n",
      "Epoch [38/50], Step [309/735], Loss: 0.0574\n",
      "Epoch [38/50], Step [310/735], Loss: 0.1648\n",
      "Epoch [38/50], Step [311/735], Loss: 0.0793\n",
      "Epoch [38/50], Step [312/735], Loss: 0.0592\n",
      "Epoch [38/50], Step [313/735], Loss: 0.0646\n",
      "Epoch [38/50], Step [314/735], Loss: 0.0604\n",
      "Epoch [38/50], Step [315/735], Loss: 0.0261\n",
      "Epoch [38/50], Step [316/735], Loss: 0.0677\n",
      "Epoch [38/50], Step [317/735], Loss: 0.1027\n",
      "Epoch [38/50], Step [318/735], Loss: 0.0995\n",
      "Epoch [38/50], Step [319/735], Loss: 0.0300\n",
      "Epoch [38/50], Step [320/735], Loss: 0.0828\n",
      "Epoch [38/50], Step [321/735], Loss: 0.0738\n",
      "Epoch [38/50], Step [322/735], Loss: 0.1071\n",
      "Epoch [38/50], Step [323/735], Loss: 0.1516\n",
      "Epoch [38/50], Step [324/735], Loss: 0.1331\n",
      "Epoch [38/50], Step [325/735], Loss: 0.1517\n",
      "Epoch [38/50], Step [326/735], Loss: 0.1199\n",
      "Epoch [38/50], Step [327/735], Loss: 0.1556\n",
      "Epoch [38/50], Step [328/735], Loss: 0.1186\n",
      "Epoch [38/50], Step [329/735], Loss: 0.0666\n",
      "Epoch [38/50], Step [330/735], Loss: 0.1728\n",
      "Epoch [38/50], Step [331/735], Loss: 0.0394\n",
      "Epoch [38/50], Step [332/735], Loss: 0.1180\n",
      "Epoch [38/50], Step [333/735], Loss: 0.0560\n",
      "Epoch [38/50], Step [334/735], Loss: 0.5719\n",
      "Epoch [38/50], Step [335/735], Loss: 0.1242\n",
      "Epoch [38/50], Step [336/735], Loss: 0.1005\n",
      "Epoch [38/50], Step [337/735], Loss: 0.1347\n",
      "Epoch [38/50], Step [338/735], Loss: 0.0832\n",
      "Epoch [38/50], Step [339/735], Loss: 0.0485\n",
      "Epoch [38/50], Step [340/735], Loss: 0.0759\n",
      "Epoch [38/50], Step [341/735], Loss: 0.0680\n",
      "Epoch [38/50], Step [342/735], Loss: 0.1047\n",
      "Epoch [38/50], Step [343/735], Loss: 0.1589\n",
      "Epoch [38/50], Step [344/735], Loss: 0.3135\n",
      "Epoch [38/50], Step [345/735], Loss: 0.0666\n",
      "Epoch [38/50], Step [346/735], Loss: 0.0754\n",
      "Epoch [38/50], Step [347/735], Loss: 0.2102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Step [348/735], Loss: 0.0618\n",
      "Epoch [38/50], Step [349/735], Loss: 0.2155\n",
      "Epoch [38/50], Step [350/735], Loss: 0.1064\n",
      "Epoch [38/50], Step [351/735], Loss: 0.1219\n",
      "Epoch [38/50], Step [352/735], Loss: 0.0961\n",
      "Epoch [38/50], Step [353/735], Loss: 0.0615\n",
      "Epoch [38/50], Step [354/735], Loss: 0.0711\n",
      "Epoch [38/50], Step [355/735], Loss: 0.1245\n",
      "Epoch [38/50], Step [356/735], Loss: 0.0861\n",
      "Epoch [38/50], Step [357/735], Loss: 0.1432\n",
      "Epoch [38/50], Step [358/735], Loss: 0.0951\n",
      "Epoch [38/50], Step [359/735], Loss: 0.1522\n",
      "Epoch [38/50], Step [360/735], Loss: 0.0410\n",
      "Epoch [38/50], Step [361/735], Loss: 0.1537\n",
      "Epoch [38/50], Step [362/735], Loss: 0.0700\n",
      "Epoch [38/50], Step [363/735], Loss: 0.0806\n",
      "Epoch [38/50], Step [364/735], Loss: 0.0777\n",
      "Epoch [38/50], Step [365/735], Loss: 0.1227\n",
      "Epoch [38/50], Step [366/735], Loss: 0.0987\n",
      "Epoch [38/50], Step [367/735], Loss: 0.0806\n",
      "Epoch [38/50], Step [368/735], Loss: 0.2052\n",
      "Epoch [38/50], Step [369/735], Loss: 0.0912\n",
      "Epoch [38/50], Step [370/735], Loss: 0.1017\n",
      "Epoch [38/50], Step [371/735], Loss: 0.0773\n",
      "Epoch [38/50], Step [372/735], Loss: 0.0831\n",
      "Epoch [38/50], Step [373/735], Loss: 0.0791\n",
      "Epoch [38/50], Step [374/735], Loss: 0.2392\n",
      "Epoch [38/50], Step [375/735], Loss: 0.1140\n",
      "Epoch [38/50], Step [376/735], Loss: 0.0926\n",
      "Epoch [38/50], Step [377/735], Loss: 0.0925\n",
      "Epoch [38/50], Step [378/735], Loss: 0.1119\n",
      "Epoch [38/50], Step [379/735], Loss: 0.0551\n",
      "Epoch [38/50], Step [380/735], Loss: 0.0643\n",
      "Epoch [38/50], Step [381/735], Loss: 0.1128\n",
      "Epoch [38/50], Step [382/735], Loss: 0.0518\n",
      "Epoch [38/50], Step [383/735], Loss: 0.1252\n",
      "Epoch [38/50], Step [384/735], Loss: 0.0369\n",
      "Epoch [38/50], Step [385/735], Loss: 1.9270\n",
      "Epoch [38/50], Step [386/735], Loss: 0.1135\n",
      "Epoch [38/50], Step [387/735], Loss: 0.1102\n",
      "Epoch [38/50], Step [388/735], Loss: 0.0541\n",
      "Epoch [38/50], Step [389/735], Loss: 0.1324\n",
      "Epoch [38/50], Step [390/735], Loss: 0.0775\n",
      "Epoch [38/50], Step [391/735], Loss: 0.0992\n",
      "Epoch [38/50], Step [392/735], Loss: 0.0232\n",
      "Epoch [38/50], Step [393/735], Loss: 0.0731\n",
      "Epoch [38/50], Step [394/735], Loss: 0.0622\n",
      "Epoch [38/50], Step [395/735], Loss: 0.0928\n",
      "Epoch [38/50], Step [396/735], Loss: 0.0929\n",
      "Epoch [38/50], Step [397/735], Loss: 0.0682\n",
      "Epoch [38/50], Step [398/735], Loss: 0.0723\n",
      "Epoch [38/50], Step [399/735], Loss: 0.0610\n",
      "Epoch [38/50], Step [400/735], Loss: 0.0646\n",
      "Epoch [38/50], Step [401/735], Loss: 0.0688\n",
      "Epoch [38/50], Step [402/735], Loss: 0.1408\n",
      "Epoch [38/50], Step [403/735], Loss: 0.1293\n",
      "Epoch [38/50], Step [404/735], Loss: 0.0959\n",
      "Epoch [38/50], Step [405/735], Loss: 0.1437\n",
      "Epoch [38/50], Step [406/735], Loss: 0.0565\n",
      "Epoch [38/50], Step [407/735], Loss: 0.0550\n",
      "Epoch [38/50], Step [408/735], Loss: 0.1616\n",
      "Epoch [38/50], Step [409/735], Loss: 0.1043\n",
      "Epoch [38/50], Step [410/735], Loss: 0.0558\n",
      "Epoch [38/50], Step [411/735], Loss: 0.1682\n",
      "Epoch [38/50], Step [412/735], Loss: 0.0376\n",
      "Epoch [38/50], Step [413/735], Loss: 0.0653\n",
      "Epoch [38/50], Step [414/735], Loss: 0.0575\n",
      "Epoch [38/50], Step [415/735], Loss: 0.1607\n",
      "Epoch [38/50], Step [416/735], Loss: 0.0706\n",
      "Epoch [38/50], Step [417/735], Loss: 0.8312\n",
      "Epoch [38/50], Step [418/735], Loss: 0.2149\n",
      "Epoch [38/50], Step [419/735], Loss: 0.0984\n",
      "Epoch [38/50], Step [420/735], Loss: 0.0581\n",
      "Epoch [38/50], Step [421/735], Loss: 0.1941\n",
      "Epoch [38/50], Step [422/735], Loss: 0.0507\n",
      "Epoch [38/50], Step [423/735], Loss: 0.0882\n",
      "Epoch [38/50], Step [424/735], Loss: 0.1724\n",
      "Epoch [38/50], Step [425/735], Loss: 0.6842\n",
      "Epoch [38/50], Step [426/735], Loss: 0.0467\n",
      "Epoch [38/50], Step [427/735], Loss: 0.1714\n",
      "Epoch [38/50], Step [428/735], Loss: 0.0692\n",
      "Epoch [38/50], Step [429/735], Loss: 0.1195\n",
      "Epoch [38/50], Step [430/735], Loss: 0.0425\n",
      "Epoch [38/50], Step [431/735], Loss: 0.0623\n",
      "Epoch [38/50], Step [432/735], Loss: 0.0575\n",
      "Epoch [38/50], Step [433/735], Loss: 0.1612\n",
      "Epoch [38/50], Step [434/735], Loss: 0.0939\n",
      "Epoch [38/50], Step [435/735], Loss: 0.0377\n",
      "Epoch [38/50], Step [436/735], Loss: 0.2979\n",
      "Epoch [38/50], Step [437/735], Loss: 0.1063\n",
      "Epoch [38/50], Step [438/735], Loss: 0.1726\n",
      "Epoch [38/50], Step [439/735], Loss: 1.0069\n",
      "Epoch [38/50], Step [440/735], Loss: 0.0268\n",
      "Epoch [38/50], Step [441/735], Loss: 0.1458\n",
      "Epoch [38/50], Step [442/735], Loss: 0.0532\n",
      "Epoch [38/50], Step [443/735], Loss: 0.0797\n",
      "Epoch [38/50], Step [444/735], Loss: 0.0492\n",
      "Epoch [38/50], Step [445/735], Loss: 0.1336\n",
      "Epoch [38/50], Step [446/735], Loss: 0.0494\n",
      "Epoch [38/50], Step [447/735], Loss: 0.0768\n",
      "Epoch [38/50], Step [448/735], Loss: 0.0984\n",
      "Epoch [38/50], Step [449/735], Loss: 0.1230\n",
      "Epoch [38/50], Step [450/735], Loss: 0.0784\n",
      "Epoch [38/50], Step [451/735], Loss: 0.1018\n",
      "Epoch [38/50], Step [452/735], Loss: 0.2790\n",
      "Epoch [38/50], Step [453/735], Loss: 0.0587\n",
      "Epoch [38/50], Step [454/735], Loss: 0.1404\n",
      "Epoch [38/50], Step [455/735], Loss: 0.2797\n",
      "Epoch [38/50], Step [456/735], Loss: 0.0835\n",
      "Epoch [38/50], Step [457/735], Loss: 0.1314\n",
      "Epoch [38/50], Step [458/735], Loss: 0.0755\n",
      "Epoch [38/50], Step [459/735], Loss: 0.1964\n",
      "Epoch [38/50], Step [460/735], Loss: 0.0938\n",
      "Epoch [38/50], Step [461/735], Loss: 0.1167\n",
      "Epoch [38/50], Step [462/735], Loss: 0.0658\n",
      "Epoch [38/50], Step [463/735], Loss: 0.0668\n",
      "Epoch [38/50], Step [464/735], Loss: 0.3401\n",
      "Epoch [38/50], Step [465/735], Loss: 0.0355\n",
      "Epoch [38/50], Step [466/735], Loss: 0.1438\n",
      "Epoch [38/50], Step [467/735], Loss: 0.0722\n",
      "Epoch [38/50], Step [468/735], Loss: 0.0537\n",
      "Epoch [38/50], Step [469/735], Loss: 0.2246\n",
      "Epoch [38/50], Step [470/735], Loss: 0.0821\n",
      "Epoch [38/50], Step [471/735], Loss: 0.0727\n",
      "Epoch [38/50], Step [472/735], Loss: 0.0474\n",
      "Epoch [38/50], Step [473/735], Loss: 0.0864\n",
      "Epoch [38/50], Step [474/735], Loss: 0.0256\n",
      "Epoch [38/50], Step [475/735], Loss: 0.2552\n",
      "Epoch [38/50], Step [476/735], Loss: 0.1842\n",
      "Epoch [38/50], Step [477/735], Loss: 0.1308\n",
      "Epoch [38/50], Step [478/735], Loss: 0.4840\n",
      "Epoch [38/50], Step [479/735], Loss: 0.0803\n",
      "Epoch [38/50], Step [480/735], Loss: 0.0656\n",
      "Epoch [38/50], Step [481/735], Loss: 0.1114\n",
      "Epoch [38/50], Step [482/735], Loss: 0.0993\n",
      "Epoch [38/50], Step [483/735], Loss: 0.0635\n",
      "Epoch [38/50], Step [484/735], Loss: 0.0294\n",
      "Epoch [38/50], Step [485/735], Loss: 0.1061\n",
      "Epoch [38/50], Step [486/735], Loss: 0.0843\n",
      "Epoch [38/50], Step [487/735], Loss: 0.0855\n",
      "Epoch [38/50], Step [488/735], Loss: 0.4111\n",
      "Epoch [38/50], Step [489/735], Loss: 0.3913\n",
      "Epoch [38/50], Step [490/735], Loss: 0.1833\n",
      "Epoch [38/50], Step [491/735], Loss: 0.0985\n",
      "Epoch [38/50], Step [492/735], Loss: 0.2189\n",
      "Epoch [38/50], Step [493/735], Loss: 0.4698\n",
      "Epoch [38/50], Step [494/735], Loss: 0.1191\n",
      "Epoch [38/50], Step [495/735], Loss: 0.7706\n",
      "Epoch [38/50], Step [496/735], Loss: 0.1399\n",
      "Epoch [38/50], Step [497/735], Loss: 0.0970\n",
      "Epoch [38/50], Step [498/735], Loss: 0.1579\n",
      "Epoch [38/50], Step [499/735], Loss: 0.2239\n",
      "Epoch [38/50], Step [500/735], Loss: 0.1926\n",
      "Epoch [38/50], Step [501/735], Loss: 0.1285\n",
      "Epoch [38/50], Step [502/735], Loss: 0.4025\n",
      "Epoch [38/50], Step [503/735], Loss: 0.0589\n",
      "Epoch [38/50], Step [504/735], Loss: 0.1261\n",
      "Epoch [38/50], Step [505/735], Loss: 0.0913\n",
      "Epoch [38/50], Step [506/735], Loss: 0.1335\n",
      "Epoch [38/50], Step [507/735], Loss: 0.6213\n",
      "Epoch [38/50], Step [508/735], Loss: 0.0807\n",
      "Epoch [38/50], Step [509/735], Loss: 0.1201\n",
      "Epoch [38/50], Step [510/735], Loss: 0.4803\n",
      "Epoch [38/50], Step [511/735], Loss: 0.1067\n",
      "Epoch [38/50], Step [512/735], Loss: 0.1640\n",
      "Epoch [38/50], Step [513/735], Loss: 0.1997\n",
      "Epoch [38/50], Step [514/735], Loss: 0.0488\n",
      "Epoch [38/50], Step [515/735], Loss: 0.1264\n",
      "Epoch [38/50], Step [516/735], Loss: 0.1516\n",
      "Epoch [38/50], Step [517/735], Loss: 0.1104\n",
      "Epoch [38/50], Step [518/735], Loss: 0.0407\n",
      "Epoch [38/50], Step [519/735], Loss: 0.0875\n",
      "Epoch [38/50], Step [520/735], Loss: 0.0888\n",
      "Epoch [38/50], Step [521/735], Loss: 0.7514\n",
      "Epoch [38/50], Step [522/735], Loss: 0.0663\n",
      "Epoch [38/50], Step [523/735], Loss: 0.1714\n",
      "Epoch [38/50], Step [524/735], Loss: 0.0438\n",
      "Epoch [38/50], Step [525/735], Loss: 0.0471\n",
      "Epoch [38/50], Step [526/735], Loss: 0.1511\n",
      "Epoch [38/50], Step [527/735], Loss: 0.1831\n",
      "Epoch [38/50], Step [528/735], Loss: 0.1322\n",
      "Epoch [38/50], Step [529/735], Loss: 0.1248\n",
      "Epoch [38/50], Step [530/735], Loss: 0.4157\n",
      "Epoch [38/50], Step [531/735], Loss: 0.2016\n",
      "Epoch [38/50], Step [532/735], Loss: 0.4154\n",
      "Epoch [38/50], Step [533/735], Loss: 0.1044\n",
      "Epoch [38/50], Step [534/735], Loss: 0.0421\n",
      "Epoch [38/50], Step [535/735], Loss: 0.0998\n",
      "Epoch [38/50], Step [536/735], Loss: 0.0550\n",
      "Epoch [38/50], Step [537/735], Loss: 0.1855\n",
      "Epoch [38/50], Step [538/735], Loss: 0.0795\n",
      "Epoch [38/50], Step [539/735], Loss: 0.1110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Step [540/735], Loss: 0.2333\n",
      "Epoch [38/50], Step [541/735], Loss: 0.0621\n",
      "Epoch [38/50], Step [542/735], Loss: 0.1024\n",
      "Epoch [38/50], Step [543/735], Loss: 0.1142\n",
      "Epoch [38/50], Step [544/735], Loss: 0.0909\n",
      "Epoch [38/50], Step [545/735], Loss: 0.1122\n",
      "Epoch [38/50], Step [546/735], Loss: 0.1812\n",
      "Epoch [38/50], Step [547/735], Loss: 0.0645\n",
      "Epoch [38/50], Step [548/735], Loss: 0.0821\n",
      "Epoch [38/50], Step [549/735], Loss: 0.0728\n",
      "Epoch [38/50], Step [550/735], Loss: 0.0757\n",
      "Epoch [38/50], Step [551/735], Loss: 0.2715\n",
      "Epoch [38/50], Step [552/735], Loss: 0.0985\n",
      "Epoch [38/50], Step [553/735], Loss: 0.1392\n",
      "Epoch [38/50], Step [554/735], Loss: 0.0855\n",
      "Epoch [38/50], Step [555/735], Loss: 0.0608\n",
      "Epoch [38/50], Step [556/735], Loss: 0.2419\n",
      "Epoch [38/50], Step [557/735], Loss: 0.0642\n",
      "Epoch [38/50], Step [558/735], Loss: 0.3147\n",
      "Epoch [38/50], Step [559/735], Loss: 0.1337\n",
      "Epoch [38/50], Step [560/735], Loss: 0.0999\n",
      "Epoch [38/50], Step [561/735], Loss: 0.4457\n",
      "Epoch [38/50], Step [562/735], Loss: 0.0727\n",
      "Epoch [38/50], Step [563/735], Loss: 0.1553\n",
      "Epoch [38/50], Step [564/735], Loss: 0.2898\n",
      "Epoch [38/50], Step [565/735], Loss: 0.0474\n",
      "Epoch [38/50], Step [566/735], Loss: 0.3715\n",
      "Epoch [38/50], Step [567/735], Loss: 0.1187\n",
      "Epoch [38/50], Step [568/735], Loss: 0.0966\n",
      "Epoch [38/50], Step [569/735], Loss: 0.0981\n",
      "Epoch [38/50], Step [570/735], Loss: 0.0755\n",
      "Epoch [38/50], Step [571/735], Loss: 0.0651\n",
      "Epoch [38/50], Step [572/735], Loss: 0.1477\n",
      "Epoch [38/50], Step [573/735], Loss: 0.3055\n",
      "Epoch [38/50], Step [574/735], Loss: 0.2977\n",
      "Epoch [38/50], Step [575/735], Loss: 0.1013\n",
      "Epoch [38/50], Step [576/735], Loss: 0.0994\n",
      "Epoch [38/50], Step [577/735], Loss: 0.0754\n",
      "Epoch [38/50], Step [578/735], Loss: 0.0799\n",
      "Epoch [38/50], Step [579/735], Loss: 0.0639\n",
      "Epoch [38/50], Step [580/735], Loss: 0.1380\n",
      "Epoch [38/50], Step [581/735], Loss: 0.1177\n",
      "Epoch [38/50], Step [582/735], Loss: 0.1598\n",
      "Epoch [38/50], Step [583/735], Loss: 0.1878\n",
      "Epoch [38/50], Step [584/735], Loss: 0.1002\n",
      "Epoch [38/50], Step [585/735], Loss: 0.1094\n",
      "Epoch [38/50], Step [586/735], Loss: 0.1131\n",
      "Epoch [38/50], Step [587/735], Loss: 0.0814\n",
      "Epoch [38/50], Step [588/735], Loss: 0.0975\n",
      "Epoch [38/50], Step [589/735], Loss: 0.0919\n",
      "Epoch [38/50], Step [590/735], Loss: 0.1072\n",
      "Epoch [38/50], Step [591/735], Loss: 0.0598\n",
      "Epoch [38/50], Step [592/735], Loss: 0.2241\n",
      "Epoch [38/50], Step [593/735], Loss: 0.1475\n",
      "Epoch [38/50], Step [594/735], Loss: 0.0796\n",
      "Epoch [38/50], Step [595/735], Loss: 0.3401\n",
      "Epoch [38/50], Step [596/735], Loss: 0.1182\n",
      "Epoch [38/50], Step [597/735], Loss: 0.1441\n",
      "Epoch [38/50], Step [598/735], Loss: 0.3902\n",
      "Epoch [38/50], Step [599/735], Loss: 0.0465\n",
      "Epoch [38/50], Step [600/735], Loss: 0.2103\n",
      "Epoch [38/50], Step [601/735], Loss: 0.0870\n",
      "Epoch [38/50], Step [602/735], Loss: 0.0586\n",
      "Epoch [38/50], Step [603/735], Loss: 0.0603\n",
      "Epoch [38/50], Step [604/735], Loss: 0.1412\n",
      "Epoch [38/50], Step [605/735], Loss: 0.1396\n",
      "Epoch [38/50], Step [606/735], Loss: 0.1308\n",
      "Epoch [38/50], Step [607/735], Loss: 0.0799\n",
      "Epoch [38/50], Step [608/735], Loss: 0.0900\n",
      "Epoch [38/50], Step [609/735], Loss: 0.1609\n",
      "Epoch [38/50], Step [610/735], Loss: 0.0774\n",
      "Epoch [38/50], Step [611/735], Loss: 0.1022\n",
      "Epoch [38/50], Step [612/735], Loss: 0.0866\n",
      "Epoch [38/50], Step [613/735], Loss: 0.1028\n",
      "Epoch [38/50], Step [614/735], Loss: 0.0652\n",
      "Epoch [38/50], Step [615/735], Loss: 0.0331\n",
      "Epoch [38/50], Step [616/735], Loss: 0.0639\n",
      "Epoch [38/50], Step [617/735], Loss: 0.0857\n",
      "Epoch [38/50], Step [618/735], Loss: 0.0439\n",
      "Epoch [38/50], Step [619/735], Loss: 0.0626\n",
      "Epoch [38/50], Step [620/735], Loss: 0.0697\n",
      "Epoch [38/50], Step [621/735], Loss: 0.0807\n",
      "Epoch [38/50], Step [622/735], Loss: 0.2375\n",
      "Epoch [38/50], Step [623/735], Loss: 0.1247\n",
      "Epoch [38/50], Step [624/735], Loss: 0.1354\n",
      "Epoch [38/50], Step [625/735], Loss: 0.1764\n",
      "Epoch [38/50], Step [626/735], Loss: 0.0319\n",
      "Epoch [38/50], Step [627/735], Loss: 0.0433\n",
      "Epoch [38/50], Step [628/735], Loss: 0.0499\n",
      "Epoch [38/50], Step [629/735], Loss: 0.0527\n",
      "Epoch [38/50], Step [630/735], Loss: 0.0857\n",
      "Epoch [38/50], Step [631/735], Loss: 0.0545\n",
      "Epoch [38/50], Step [632/735], Loss: 0.0984\n",
      "Epoch [38/50], Step [633/735], Loss: 0.0606\n",
      "Epoch [38/50], Step [634/735], Loss: 0.0697\n",
      "Epoch [38/50], Step [635/735], Loss: 0.0548\n",
      "Epoch [38/50], Step [636/735], Loss: 0.4104\n",
      "Epoch [38/50], Step [637/735], Loss: 0.1079\n",
      "Epoch [38/50], Step [638/735], Loss: 0.0607\n",
      "Epoch [38/50], Step [639/735], Loss: 0.0865\n",
      "Epoch [38/50], Step [640/735], Loss: 0.1880\n",
      "Epoch [38/50], Step [641/735], Loss: 0.1469\n",
      "Epoch [38/50], Step [642/735], Loss: 0.0367\n",
      "Epoch [38/50], Step [643/735], Loss: 0.0673\n",
      "Epoch [38/50], Step [644/735], Loss: 0.0667\n",
      "Epoch [38/50], Step [645/735], Loss: 0.1082\n",
      "Epoch [38/50], Step [646/735], Loss: 0.1353\n",
      "Epoch [38/50], Step [647/735], Loss: 0.1612\n",
      "Epoch [38/50], Step [648/735], Loss: 0.1425\n",
      "Epoch [38/50], Step [649/735], Loss: 0.0960\n",
      "Epoch [38/50], Step [650/735], Loss: 0.0690\n",
      "Epoch [38/50], Step [651/735], Loss: 0.0923\n",
      "Epoch [38/50], Step [652/735], Loss: 0.0513\n",
      "Epoch [38/50], Step [653/735], Loss: 0.0746\n",
      "Epoch [38/50], Step [654/735], Loss: 0.0730\n",
      "Epoch [38/50], Step [655/735], Loss: 0.1230\n",
      "Epoch [38/50], Step [656/735], Loss: 0.0881\n",
      "Epoch [38/50], Step [657/735], Loss: 0.1463\n",
      "Epoch [38/50], Step [658/735], Loss: 0.1098\n",
      "Epoch [38/50], Step [659/735], Loss: 0.0689\n",
      "Epoch [38/50], Step [660/735], Loss: 0.0870\n",
      "Epoch [38/50], Step [661/735], Loss: 0.1341\n",
      "Epoch [38/50], Step [662/735], Loss: 0.0970\n",
      "Epoch [38/50], Step [663/735], Loss: 0.0663\n",
      "Epoch [38/50], Step [664/735], Loss: 0.0473\n",
      "Epoch [38/50], Step [665/735], Loss: 0.0665\n",
      "Epoch [38/50], Step [666/735], Loss: 0.1276\n",
      "Epoch [38/50], Step [667/735], Loss: 0.1315\n",
      "Epoch [38/50], Step [668/735], Loss: 0.0836\n",
      "Epoch [38/50], Step [669/735], Loss: 0.0517\n",
      "Epoch [38/50], Step [670/735], Loss: 0.0875\n",
      "Epoch [38/50], Step [671/735], Loss: 0.0960\n",
      "Epoch [38/50], Step [672/735], Loss: 0.0725\n",
      "Epoch [38/50], Step [673/735], Loss: 1.7201\n",
      "Epoch [38/50], Step [674/735], Loss: 0.0582\n",
      "Epoch [38/50], Step [675/735], Loss: 0.0506\n",
      "Epoch [38/50], Step [676/735], Loss: 0.0678\n",
      "Epoch [38/50], Step [677/735], Loss: 0.8543\n",
      "Epoch [38/50], Step [678/735], Loss: 0.3482\n",
      "Epoch [38/50], Step [679/735], Loss: 0.0375\n",
      "Epoch [38/50], Step [680/735], Loss: 0.0759\n",
      "Epoch [38/50], Step [681/735], Loss: 0.0902\n",
      "Epoch [38/50], Step [682/735], Loss: 0.0906\n",
      "Epoch [38/50], Step [683/735], Loss: 0.1249\n",
      "Epoch [38/50], Step [684/735], Loss: 0.1542\n",
      "Epoch [38/50], Step [685/735], Loss: 0.1759\n",
      "Epoch [38/50], Step [686/735], Loss: 0.1274\n",
      "Epoch [38/50], Step [687/735], Loss: 0.0981\n",
      "Epoch [38/50], Step [688/735], Loss: 0.0294\n",
      "Epoch [38/50], Step [689/735], Loss: 0.0588\n",
      "Epoch [38/50], Step [690/735], Loss: 0.0650\n",
      "Epoch [38/50], Step [691/735], Loss: 0.1300\n",
      "Epoch [38/50], Step [692/735], Loss: 0.1757\n",
      "Epoch [38/50], Step [693/735], Loss: 0.0494\n",
      "Epoch [38/50], Step [694/735], Loss: 0.1070\n",
      "Epoch [38/50], Step [695/735], Loss: 0.1022\n",
      "Epoch [38/50], Step [696/735], Loss: 0.1575\n",
      "Epoch [38/50], Step [697/735], Loss: 0.0997\n",
      "Epoch [38/50], Step [698/735], Loss: 0.1266\n",
      "Epoch [38/50], Step [699/735], Loss: 0.1021\n",
      "Epoch [38/50], Step [700/735], Loss: 0.2983\n",
      "Epoch [38/50], Step [701/735], Loss: 0.1993\n",
      "Epoch [38/50], Step [702/735], Loss: 0.1005\n",
      "Epoch [38/50], Step [703/735], Loss: 0.0519\n",
      "Epoch [38/50], Step [704/735], Loss: 0.1307\n",
      "Epoch [38/50], Step [705/735], Loss: 0.1054\n",
      "Epoch [38/50], Step [706/735], Loss: 0.0519\n",
      "Epoch [38/50], Step [707/735], Loss: 0.0642\n",
      "Epoch [38/50], Step [708/735], Loss: 0.0988\n",
      "Epoch [38/50], Step [709/735], Loss: 0.3487\n",
      "Epoch [38/50], Step [710/735], Loss: 0.2485\n",
      "Epoch [38/50], Step [711/735], Loss: 0.1379\n",
      "Epoch [38/50], Step [712/735], Loss: 0.1030\n",
      "Epoch [38/50], Step [713/735], Loss: 0.0696\n",
      "Epoch [38/50], Step [714/735], Loss: 0.0706\n",
      "Epoch [38/50], Step [715/735], Loss: 0.0570\n",
      "Epoch [38/50], Step [716/735], Loss: 0.0586\n",
      "Epoch [38/50], Step [717/735], Loss: 0.0461\n",
      "Epoch [38/50], Step [718/735], Loss: 0.8589\n",
      "Epoch [38/50], Step [719/735], Loss: 0.0484\n",
      "Epoch [38/50], Step [720/735], Loss: 0.0949\n",
      "Epoch [38/50], Step [721/735], Loss: 0.0693\n",
      "Epoch [38/50], Step [722/735], Loss: 0.1799\n",
      "Epoch [38/50], Step [723/735], Loss: 0.1616\n",
      "Epoch [38/50], Step [724/735], Loss: 0.1845\n",
      "Epoch [38/50], Step [725/735], Loss: 0.6011\n",
      "Epoch [38/50], Step [726/735], Loss: 0.0986\n",
      "Epoch [38/50], Step [727/735], Loss: 0.1645\n",
      "Epoch [38/50], Step [728/735], Loss: 0.0453\n",
      "Epoch [38/50], Step [729/735], Loss: 0.1053\n",
      "Epoch [38/50], Step [730/735], Loss: 0.4580\n",
      "Epoch [38/50], Step [731/735], Loss: 0.1653\n",
      "Epoch [38/50], Step [732/735], Loss: 0.1088\n",
      "Epoch [38/50], Step [733/735], Loss: 0.0923\n",
      "Epoch [38/50], Step [734/735], Loss: 0.1155\n",
      "Epoch [38/50], Step [735/735], Loss: 0.0431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Step [1/735], Loss: 0.1389\n",
      "Epoch [39/50], Step [2/735], Loss: 0.1315\n",
      "Epoch [39/50], Step [3/735], Loss: 0.2046\n",
      "Epoch [39/50], Step [4/735], Loss: 0.2600\n",
      "Epoch [39/50], Step [5/735], Loss: 0.4875\n",
      "Epoch [39/50], Step [6/735], Loss: 0.1370\n",
      "Epoch [39/50], Step [7/735], Loss: 0.0622\n",
      "Epoch [39/50], Step [8/735], Loss: 0.0853\n",
      "Epoch [39/50], Step [9/735], Loss: 1.3289\n",
      "Epoch [39/50], Step [10/735], Loss: 0.0775\n",
      "Epoch [39/50], Step [11/735], Loss: 0.0337\n",
      "Epoch [39/50], Step [12/735], Loss: 0.1936\n",
      "Epoch [39/50], Step [13/735], Loss: 0.0724\n",
      "Epoch [39/50], Step [14/735], Loss: 0.1063\n",
      "Epoch [39/50], Step [15/735], Loss: 0.0750\n",
      "Epoch [39/50], Step [16/735], Loss: 0.0574\n",
      "Epoch [39/50], Step [17/735], Loss: 0.0260\n",
      "Epoch [39/50], Step [18/735], Loss: 0.0697\n",
      "Epoch [39/50], Step [19/735], Loss: 0.1172\n",
      "Epoch [39/50], Step [20/735], Loss: 0.1388\n",
      "Epoch [39/50], Step [21/735], Loss: 0.0556\n",
      "Epoch [39/50], Step [22/735], Loss: 0.1195\n",
      "Epoch [39/50], Step [23/735], Loss: 0.1263\n",
      "Epoch [39/50], Step [24/735], Loss: 0.2168\n",
      "Epoch [39/50], Step [25/735], Loss: 0.0621\n",
      "Epoch [39/50], Step [26/735], Loss: 0.3444\n",
      "Epoch [39/50], Step [27/735], Loss: 0.1028\n",
      "Epoch [39/50], Step [28/735], Loss: 0.1517\n",
      "Epoch [39/50], Step [29/735], Loss: 0.1487\n",
      "Epoch [39/50], Step [30/735], Loss: 0.1228\n",
      "Epoch [39/50], Step [31/735], Loss: 0.0902\n",
      "Epoch [39/50], Step [32/735], Loss: 0.0998\n",
      "Epoch [39/50], Step [33/735], Loss: 0.0295\n",
      "Epoch [39/50], Step [34/735], Loss: 0.0493\n",
      "Epoch [39/50], Step [35/735], Loss: 0.0409\n",
      "Epoch [39/50], Step [36/735], Loss: 0.1627\n",
      "Epoch [39/50], Step [37/735], Loss: 0.0471\n",
      "Epoch [39/50], Step [38/735], Loss: 0.0782\n",
      "Epoch [39/50], Step [39/735], Loss: 0.0850\n",
      "Epoch [39/50], Step [40/735], Loss: 0.0856\n",
      "Epoch [39/50], Step [41/735], Loss: 0.0354\n",
      "Epoch [39/50], Step [42/735], Loss: 0.0505\n",
      "Epoch [39/50], Step [43/735], Loss: 0.1267\n",
      "Epoch [39/50], Step [44/735], Loss: 0.1171\n",
      "Epoch [39/50], Step [45/735], Loss: 0.0700\n",
      "Epoch [39/50], Step [46/735], Loss: 0.0919\n",
      "Epoch [39/50], Step [47/735], Loss: 0.2273\n",
      "Epoch [39/50], Step [48/735], Loss: 0.0450\n",
      "Epoch [39/50], Step [49/735], Loss: 0.1093\n",
      "Epoch [39/50], Step [50/735], Loss: 0.0831\n",
      "Epoch [39/50], Step [51/735], Loss: 0.0497\n",
      "Epoch [39/50], Step [52/735], Loss: 0.0897\n",
      "Epoch [39/50], Step [53/735], Loss: 0.0558\n",
      "Epoch [39/50], Step [54/735], Loss: 0.1169\n",
      "Epoch [39/50], Step [55/735], Loss: 0.1212\n",
      "Epoch [39/50], Step [56/735], Loss: 0.0745\n",
      "Epoch [39/50], Step [57/735], Loss: 0.1345\n",
      "Epoch [39/50], Step [58/735], Loss: 0.1132\n",
      "Epoch [39/50], Step [59/735], Loss: 0.2267\n",
      "Epoch [39/50], Step [60/735], Loss: 0.1729\n",
      "Epoch [39/50], Step [61/735], Loss: 0.0540\n",
      "Epoch [39/50], Step [62/735], Loss: 0.1218\n",
      "Epoch [39/50], Step [63/735], Loss: 0.0855\n",
      "Epoch [39/50], Step [64/735], Loss: 0.1610\n",
      "Epoch [39/50], Step [65/735], Loss: 0.0945\n",
      "Epoch [39/50], Step [66/735], Loss: 0.0588\n",
      "Epoch [39/50], Step [67/735], Loss: 0.1626\n",
      "Epoch [39/50], Step [68/735], Loss: 0.1413\n",
      "Epoch [39/50], Step [69/735], Loss: 0.0430\n",
      "Epoch [39/50], Step [70/735], Loss: 0.0803\n",
      "Epoch [39/50], Step [71/735], Loss: 0.0597\n",
      "Epoch [39/50], Step [72/735], Loss: 0.1067\n",
      "Epoch [39/50], Step [73/735], Loss: 0.1727\n",
      "Epoch [39/50], Step [74/735], Loss: 0.0415\n",
      "Epoch [39/50], Step [75/735], Loss: 0.1163\n",
      "Epoch [39/50], Step [76/735], Loss: 0.8954\n",
      "Epoch [39/50], Step [77/735], Loss: 0.1409\n",
      "Epoch [39/50], Step [78/735], Loss: 0.0781\n",
      "Epoch [39/50], Step [79/735], Loss: 0.2169\n",
      "Epoch [39/50], Step [80/735], Loss: 0.0724\n",
      "Epoch [39/50], Step [81/735], Loss: 0.1093\n",
      "Epoch [39/50], Step [82/735], Loss: 0.0531\n",
      "Epoch [39/50], Step [83/735], Loss: 0.0935\n",
      "Epoch [39/50], Step [84/735], Loss: 0.0993\n",
      "Epoch [39/50], Step [85/735], Loss: 0.0693\n",
      "Epoch [39/50], Step [86/735], Loss: 0.2869\n",
      "Epoch [39/50], Step [87/735], Loss: 0.0447\n",
      "Epoch [39/50], Step [88/735], Loss: 0.0664\n",
      "Epoch [39/50], Step [89/735], Loss: 0.1482\n",
      "Epoch [39/50], Step [90/735], Loss: 0.1274\n",
      "Epoch [39/50], Step [91/735], Loss: 0.3494\n",
      "Epoch [39/50], Step [92/735], Loss: 0.1307\n",
      "Epoch [39/50], Step [93/735], Loss: 0.2418\n",
      "Epoch [39/50], Step [94/735], Loss: 0.1900\n",
      "Epoch [39/50], Step [95/735], Loss: 0.0883\n",
      "Epoch [39/50], Step [96/735], Loss: 0.1126\n",
      "Epoch [39/50], Step [97/735], Loss: 0.6233\n",
      "Epoch [39/50], Step [98/735], Loss: 0.0518\n",
      "Epoch [39/50], Step [99/735], Loss: 0.1611\n",
      "Epoch [39/50], Step [100/735], Loss: 0.0819\n",
      "Epoch [39/50], Step [101/735], Loss: 0.3520\n",
      "Epoch [39/50], Step [102/735], Loss: 0.3477\n",
      "Epoch [39/50], Step [103/735], Loss: 0.1051\n",
      "Epoch [39/50], Step [104/735], Loss: 0.1699\n",
      "Epoch [39/50], Step [105/735], Loss: 0.0834\n",
      "Epoch [39/50], Step [106/735], Loss: 0.0925\n",
      "Epoch [39/50], Step [107/735], Loss: 0.0773\n",
      "Epoch [39/50], Step [108/735], Loss: 0.6349\n",
      "Epoch [39/50], Step [109/735], Loss: 0.1161\n",
      "Epoch [39/50], Step [110/735], Loss: 0.1040\n",
      "Epoch [39/50], Step [111/735], Loss: 0.0499\n",
      "Epoch [39/50], Step [112/735], Loss: 0.1107\n",
      "Epoch [39/50], Step [113/735], Loss: 0.1260\n",
      "Epoch [39/50], Step [114/735], Loss: 0.0416\n",
      "Epoch [39/50], Step [115/735], Loss: 0.1362\n",
      "Epoch [39/50], Step [116/735], Loss: 0.1404\n",
      "Epoch [39/50], Step [117/735], Loss: 0.0338\n",
      "Epoch [39/50], Step [118/735], Loss: 0.0506\n",
      "Epoch [39/50], Step [119/735], Loss: 0.6730\n",
      "Epoch [39/50], Step [120/735], Loss: 0.0801\n",
      "Epoch [39/50], Step [121/735], Loss: 0.0452\n",
      "Epoch [39/50], Step [122/735], Loss: 1.5508\n",
      "Epoch [39/50], Step [123/735], Loss: 0.1721\n",
      "Epoch [39/50], Step [124/735], Loss: 0.0763\n",
      "Epoch [39/50], Step [125/735], Loss: 0.0327\n",
      "Epoch [39/50], Step [126/735], Loss: 0.0647\n",
      "Epoch [39/50], Step [127/735], Loss: 0.0629\n",
      "Epoch [39/50], Step [128/735], Loss: 0.1108\n",
      "Epoch [39/50], Step [129/735], Loss: 0.0679\n",
      "Epoch [39/50], Step [130/735], Loss: 0.0974\n",
      "Epoch [39/50], Step [131/735], Loss: 0.0960\n",
      "Epoch [39/50], Step [132/735], Loss: 0.1973\n",
      "Epoch [39/50], Step [133/735], Loss: 0.0961\n",
      "Epoch [39/50], Step [134/735], Loss: 0.1141\n",
      "Epoch [39/50], Step [135/735], Loss: 0.6530\n",
      "Epoch [39/50], Step [136/735], Loss: 0.1664\n",
      "Epoch [39/50], Step [137/735], Loss: 0.0797\n",
      "Epoch [39/50], Step [138/735], Loss: 0.0906\n",
      "Epoch [39/50], Step [139/735], Loss: 0.0999\n",
      "Epoch [39/50], Step [140/735], Loss: 0.0418\n",
      "Epoch [39/50], Step [141/735], Loss: 0.1475\n",
      "Epoch [39/50], Step [142/735], Loss: 0.0792\n",
      "Epoch [39/50], Step [143/735], Loss: 0.0678\n",
      "Epoch [39/50], Step [144/735], Loss: 0.1275\n",
      "Epoch [39/50], Step [145/735], Loss: 0.0720\n",
      "Epoch [39/50], Step [146/735], Loss: 0.0903\n",
      "Epoch [39/50], Step [147/735], Loss: 0.0497\n",
      "Epoch [39/50], Step [148/735], Loss: 0.0974\n",
      "Epoch [39/50], Step [149/735], Loss: 0.0885\n",
      "Epoch [39/50], Step [150/735], Loss: 0.4391\n",
      "Epoch [39/50], Step [151/735], Loss: 0.4590\n",
      "Epoch [39/50], Step [152/735], Loss: 0.0633\n",
      "Epoch [39/50], Step [153/735], Loss: 0.0428\n",
      "Epoch [39/50], Step [154/735], Loss: 0.0758\n",
      "Epoch [39/50], Step [155/735], Loss: 0.1453\n",
      "Epoch [39/50], Step [156/735], Loss: 0.0766\n",
      "Epoch [39/50], Step [157/735], Loss: 0.0538\n",
      "Epoch [39/50], Step [158/735], Loss: 0.0471\n",
      "Epoch [39/50], Step [159/735], Loss: 0.1381\n",
      "Epoch [39/50], Step [160/735], Loss: 0.4045\n",
      "Epoch [39/50], Step [161/735], Loss: 0.0536\n",
      "Epoch [39/50], Step [162/735], Loss: 0.2262\n",
      "Epoch [39/50], Step [163/735], Loss: 0.0765\n",
      "Epoch [39/50], Step [164/735], Loss: 0.0464\n",
      "Epoch [39/50], Step [165/735], Loss: 0.3848\n",
      "Epoch [39/50], Step [166/735], Loss: 0.1089\n",
      "Epoch [39/50], Step [167/735], Loss: 0.0535\n",
      "Epoch [39/50], Step [168/735], Loss: 0.1503\n",
      "Epoch [39/50], Step [169/735], Loss: 0.0545\n",
      "Epoch [39/50], Step [170/735], Loss: 0.0718\n",
      "Epoch [39/50], Step [171/735], Loss: 0.0478\n",
      "Epoch [39/50], Step [172/735], Loss: 0.0381\n",
      "Epoch [39/50], Step [173/735], Loss: 0.2898\n",
      "Epoch [39/50], Step [174/735], Loss: 0.1065\n",
      "Epoch [39/50], Step [175/735], Loss: 0.3849\n",
      "Epoch [39/50], Step [176/735], Loss: 0.1588\n",
      "Epoch [39/50], Step [177/735], Loss: 0.0792\n",
      "Epoch [39/50], Step [178/735], Loss: 0.0660\n",
      "Epoch [39/50], Step [179/735], Loss: 0.6079\n",
      "Epoch [39/50], Step [180/735], Loss: 0.1509\n",
      "Epoch [39/50], Step [181/735], Loss: 0.0669\n",
      "Epoch [39/50], Step [182/735], Loss: 0.0904\n",
      "Epoch [39/50], Step [183/735], Loss: 0.1978\n",
      "Epoch [39/50], Step [184/735], Loss: 0.0574\n",
      "Epoch [39/50], Step [185/735], Loss: 0.1562\n",
      "Epoch [39/50], Step [186/735], Loss: 0.0857\n",
      "Epoch [39/50], Step [187/735], Loss: 0.1006\n",
      "Epoch [39/50], Step [188/735], Loss: 0.2572\n",
      "Epoch [39/50], Step [189/735], Loss: 0.1604\n",
      "Epoch [39/50], Step [190/735], Loss: 0.1067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Step [191/735], Loss: 0.1011\n",
      "Epoch [39/50], Step [192/735], Loss: 0.1043\n",
      "Epoch [39/50], Step [193/735], Loss: 0.1365\n",
      "Epoch [39/50], Step [194/735], Loss: 0.0575\n",
      "Epoch [39/50], Step [195/735], Loss: 0.0830\n",
      "Epoch [39/50], Step [196/735], Loss: 0.0644\n",
      "Epoch [39/50], Step [197/735], Loss: 0.1178\n",
      "Epoch [39/50], Step [198/735], Loss: 0.0665\n",
      "Epoch [39/50], Step [199/735], Loss: 0.0853\n",
      "Epoch [39/50], Step [200/735], Loss: 0.0490\n",
      "Epoch [39/50], Step [201/735], Loss: 0.1007\n",
      "Epoch [39/50], Step [202/735], Loss: 0.1116\n",
      "Epoch [39/50], Step [203/735], Loss: 0.0874\n",
      "Epoch [39/50], Step [204/735], Loss: 0.0546\n",
      "Epoch [39/50], Step [205/735], Loss: 0.0800\n",
      "Epoch [39/50], Step [206/735], Loss: 0.1129\n",
      "Epoch [39/50], Step [207/735], Loss: 0.0557\n",
      "Epoch [39/50], Step [208/735], Loss: 0.0638\n",
      "Epoch [39/50], Step [209/735], Loss: 0.1378\n",
      "Epoch [39/50], Step [210/735], Loss: 0.0820\n",
      "Epoch [39/50], Step [211/735], Loss: 0.0733\n",
      "Epoch [39/50], Step [212/735], Loss: 0.0624\n",
      "Epoch [39/50], Step [213/735], Loss: 0.1081\n",
      "Epoch [39/50], Step [214/735], Loss: 0.1869\n",
      "Epoch [39/50], Step [215/735], Loss: 0.1300\n",
      "Epoch [39/50], Step [216/735], Loss: 0.5714\n",
      "Epoch [39/50], Step [217/735], Loss: 0.0654\n",
      "Epoch [39/50], Step [218/735], Loss: 0.1923\n",
      "Epoch [39/50], Step [219/735], Loss: 0.0811\n",
      "Epoch [39/50], Step [220/735], Loss: 0.0570\n",
      "Epoch [39/50], Step [221/735], Loss: 0.1773\n",
      "Epoch [39/50], Step [222/735], Loss: 0.0622\n",
      "Epoch [39/50], Step [223/735], Loss: 0.0305\n",
      "Epoch [39/50], Step [224/735], Loss: 0.1253\n",
      "Epoch [39/50], Step [225/735], Loss: 0.0398\n",
      "Epoch [39/50], Step [226/735], Loss: 0.0601\n",
      "Epoch [39/50], Step [227/735], Loss: 0.0955\n",
      "Epoch [39/50], Step [228/735], Loss: 0.1128\n",
      "Epoch [39/50], Step [229/735], Loss: 0.0821\n",
      "Epoch [39/50], Step [230/735], Loss: 0.0437\n",
      "Epoch [39/50], Step [231/735], Loss: 0.0962\n",
      "Epoch [39/50], Step [232/735], Loss: 0.0431\n",
      "Epoch [39/50], Step [233/735], Loss: 0.0968\n",
      "Epoch [39/50], Step [234/735], Loss: 0.0894\n",
      "Epoch [39/50], Step [235/735], Loss: 0.0418\n",
      "Epoch [39/50], Step [236/735], Loss: 0.0825\n",
      "Epoch [39/50], Step [237/735], Loss: 0.0511\n",
      "Epoch [39/50], Step [238/735], Loss: 0.0795\n",
      "Epoch [39/50], Step [239/735], Loss: 0.0924\n",
      "Epoch [39/50], Step [240/735], Loss: 0.1021\n",
      "Epoch [39/50], Step [241/735], Loss: 0.1384\n",
      "Epoch [39/50], Step [242/735], Loss: 0.0662\n",
      "Epoch [39/50], Step [243/735], Loss: 0.0439\n",
      "Epoch [39/50], Step [244/735], Loss: 0.0453\n",
      "Epoch [39/50], Step [245/735], Loss: 0.0435\n",
      "Epoch [39/50], Step [246/735], Loss: 0.0490\n",
      "Epoch [39/50], Step [247/735], Loss: 0.1654\n",
      "Epoch [39/50], Step [248/735], Loss: 0.1831\n",
      "Epoch [39/50], Step [249/735], Loss: 0.2903\n",
      "Epoch [39/50], Step [250/735], Loss: 0.1681\n",
      "Epoch [39/50], Step [251/735], Loss: 0.1173\n",
      "Epoch [39/50], Step [252/735], Loss: 0.1329\n",
      "Epoch [39/50], Step [253/735], Loss: 0.1365\n",
      "Epoch [39/50], Step [254/735], Loss: 0.0539\n",
      "Epoch [39/50], Step [255/735], Loss: 0.0606\n",
      "Epoch [39/50], Step [256/735], Loss: 0.1094\n",
      "Epoch [39/50], Step [257/735], Loss: 0.0718\n",
      "Epoch [39/50], Step [258/735], Loss: 0.0682\n",
      "Epoch [39/50], Step [259/735], Loss: 0.0605\n",
      "Epoch [39/50], Step [260/735], Loss: 0.0534\n",
      "Epoch [39/50], Step [261/735], Loss: 0.0517\n",
      "Epoch [39/50], Step [262/735], Loss: 0.0383\n",
      "Epoch [39/50], Step [263/735], Loss: 0.1406\n",
      "Epoch [39/50], Step [264/735], Loss: 0.1005\n",
      "Epoch [39/50], Step [265/735], Loss: 0.3181\n",
      "Epoch [39/50], Step [266/735], Loss: 0.0327\n",
      "Epoch [39/50], Step [267/735], Loss: 0.1605\n",
      "Epoch [39/50], Step [268/735], Loss: 0.1096\n",
      "Epoch [39/50], Step [269/735], Loss: 0.2285\n",
      "Epoch [39/50], Step [270/735], Loss: 0.1915\n",
      "Epoch [39/50], Step [271/735], Loss: 0.1116\n",
      "Epoch [39/50], Step [272/735], Loss: 0.1257\n",
      "Epoch [39/50], Step [273/735], Loss: 0.2082\n",
      "Epoch [39/50], Step [274/735], Loss: 0.1139\n",
      "Epoch [39/50], Step [275/735], Loss: 0.1325\n",
      "Epoch [39/50], Step [276/735], Loss: 0.1324\n",
      "Epoch [39/50], Step [277/735], Loss: 0.0501\n",
      "Epoch [39/50], Step [278/735], Loss: 0.0579\n",
      "Epoch [39/50], Step [279/735], Loss: 0.0895\n",
      "Epoch [39/50], Step [280/735], Loss: 0.0926\n",
      "Epoch [39/50], Step [281/735], Loss: 0.1101\n",
      "Epoch [39/50], Step [282/735], Loss: 0.0909\n",
      "Epoch [39/50], Step [283/735], Loss: 0.0965\n",
      "Epoch [39/50], Step [284/735], Loss: 0.4325\n",
      "Epoch [39/50], Step [285/735], Loss: 0.0995\n",
      "Epoch [39/50], Step [286/735], Loss: 0.0904\n",
      "Epoch [39/50], Step [287/735], Loss: 0.1275\n",
      "Epoch [39/50], Step [288/735], Loss: 0.1737\n",
      "Epoch [39/50], Step [289/735], Loss: 0.1025\n",
      "Epoch [39/50], Step [290/735], Loss: 0.0925\n",
      "Epoch [39/50], Step [291/735], Loss: 0.0810\n",
      "Epoch [39/50], Step [292/735], Loss: 0.1096\n",
      "Epoch [39/50], Step [293/735], Loss: 0.1664\n",
      "Epoch [39/50], Step [294/735], Loss: 0.2461\n",
      "Epoch [39/50], Step [295/735], Loss: 0.0742\n",
      "Epoch [39/50], Step [296/735], Loss: 0.1161\n",
      "Epoch [39/50], Step [297/735], Loss: 0.0799\n",
      "Epoch [39/50], Step [298/735], Loss: 0.0517\n",
      "Epoch [39/50], Step [299/735], Loss: 0.0553\n",
      "Epoch [39/50], Step [300/735], Loss: 0.0862\n",
      "Epoch [39/50], Step [301/735], Loss: 0.0858\n",
      "Epoch [39/50], Step [302/735], Loss: 0.6026\n",
      "Epoch [39/50], Step [303/735], Loss: 0.1587\n",
      "Epoch [39/50], Step [304/735], Loss: 0.0682\n",
      "Epoch [39/50], Step [305/735], Loss: 0.1071\n",
      "Epoch [39/50], Step [306/735], Loss: 0.0517\n",
      "Epoch [39/50], Step [307/735], Loss: 0.1237\n",
      "Epoch [39/50], Step [308/735], Loss: 0.1069\n",
      "Epoch [39/50], Step [309/735], Loss: 0.1134\n",
      "Epoch [39/50], Step [310/735], Loss: 0.0696\n",
      "Epoch [39/50], Step [311/735], Loss: 0.1175\n",
      "Epoch [39/50], Step [312/735], Loss: 0.0504\n",
      "Epoch [39/50], Step [313/735], Loss: 1.1370\n",
      "Epoch [39/50], Step [314/735], Loss: 0.0613\n",
      "Epoch [39/50], Step [315/735], Loss: 0.0889\n",
      "Epoch [39/50], Step [316/735], Loss: 0.2003\n",
      "Epoch [39/50], Step [317/735], Loss: 0.0756\n",
      "Epoch [39/50], Step [318/735], Loss: 0.0659\n",
      "Epoch [39/50], Step [319/735], Loss: 0.1118\n",
      "Epoch [39/50], Step [320/735], Loss: 0.1366\n",
      "Epoch [39/50], Step [321/735], Loss: 0.1075\n",
      "Epoch [39/50], Step [322/735], Loss: 0.2725\n",
      "Epoch [39/50], Step [323/735], Loss: 0.8312\n",
      "Epoch [39/50], Step [324/735], Loss: 0.0887\n",
      "Epoch [39/50], Step [325/735], Loss: 0.1741\n",
      "Epoch [39/50], Step [326/735], Loss: 0.0893\n",
      "Epoch [39/50], Step [327/735], Loss: 1.4390\n",
      "Epoch [39/50], Step [328/735], Loss: 0.0650\n",
      "Epoch [39/50], Step [329/735], Loss: 0.0476\n",
      "Epoch [39/50], Step [330/735], Loss: 0.6986\n",
      "Epoch [39/50], Step [331/735], Loss: 0.5328\n",
      "Epoch [39/50], Step [332/735], Loss: 0.5444\n",
      "Epoch [39/50], Step [333/735], Loss: 0.0808\n",
      "Epoch [39/50], Step [334/735], Loss: 0.0612\n",
      "Epoch [39/50], Step [335/735], Loss: 0.1753\n",
      "Epoch [39/50], Step [336/735], Loss: 0.1151\n",
      "Epoch [39/50], Step [337/735], Loss: 0.1034\n",
      "Epoch [39/50], Step [338/735], Loss: 0.0731\n",
      "Epoch [39/50], Step [339/735], Loss: 0.0646\n",
      "Epoch [39/50], Step [340/735], Loss: 0.4049\n",
      "Epoch [39/50], Step [341/735], Loss: 0.0797\n",
      "Epoch [39/50], Step [342/735], Loss: 0.0530\n",
      "Epoch [39/50], Step [343/735], Loss: 0.2009\n",
      "Epoch [39/50], Step [344/735], Loss: 0.0942\n",
      "Epoch [39/50], Step [345/735], Loss: 0.0656\n",
      "Epoch [39/50], Step [346/735], Loss: 0.2606\n",
      "Epoch [39/50], Step [347/735], Loss: 0.1818\n",
      "Epoch [39/50], Step [348/735], Loss: 0.1004\n",
      "Epoch [39/50], Step [349/735], Loss: 0.3413\n",
      "Epoch [39/50], Step [350/735], Loss: 0.0878\n",
      "Epoch [39/50], Step [351/735], Loss: 0.0623\n",
      "Epoch [39/50], Step [352/735], Loss: 0.0988\n",
      "Epoch [39/50], Step [353/735], Loss: 0.0892\n",
      "Epoch [39/50], Step [354/735], Loss: 0.1416\n",
      "Epoch [39/50], Step [355/735], Loss: 0.1317\n",
      "Epoch [39/50], Step [356/735], Loss: 0.0671\n",
      "Epoch [39/50], Step [357/735], Loss: 0.1460\n",
      "Epoch [39/50], Step [358/735], Loss: 0.0519\n",
      "Epoch [39/50], Step [359/735], Loss: 0.0946\n",
      "Epoch [39/50], Step [360/735], Loss: 0.0852\n",
      "Epoch [39/50], Step [361/735], Loss: 0.0241\n",
      "Epoch [39/50], Step [362/735], Loss: 0.1418\n",
      "Epoch [39/50], Step [363/735], Loss: 0.0572\n",
      "Epoch [39/50], Step [364/735], Loss: 0.0502\n",
      "Epoch [39/50], Step [365/735], Loss: 0.1806\n",
      "Epoch [39/50], Step [366/735], Loss: 0.1217\n",
      "Epoch [39/50], Step [367/735], Loss: 0.0428\n",
      "Epoch [39/50], Step [368/735], Loss: 0.1608\n",
      "Epoch [39/50], Step [369/735], Loss: 0.0837\n",
      "Epoch [39/50], Step [370/735], Loss: 0.1396\n",
      "Epoch [39/50], Step [371/735], Loss: 0.0535\n",
      "Epoch [39/50], Step [372/735], Loss: 0.0442\n",
      "Epoch [39/50], Step [373/735], Loss: 0.1233\n",
      "Epoch [39/50], Step [374/735], Loss: 0.0491\n",
      "Epoch [39/50], Step [375/735], Loss: 0.0396\n",
      "Epoch [39/50], Step [376/735], Loss: 0.0730\n",
      "Epoch [39/50], Step [377/735], Loss: 0.0832\n",
      "Epoch [39/50], Step [378/735], Loss: 0.1080\n",
      "Epoch [39/50], Step [379/735], Loss: 0.1353\n",
      "Epoch [39/50], Step [380/735], Loss: 0.0449\n",
      "Epoch [39/50], Step [381/735], Loss: 0.2250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Step [382/735], Loss: 0.2869\n",
      "Epoch [39/50], Step [383/735], Loss: 0.1474\n",
      "Epoch [39/50], Step [384/735], Loss: 0.3995\n",
      "Epoch [39/50], Step [385/735], Loss: 0.0607\n",
      "Epoch [39/50], Step [386/735], Loss: 0.0978\n",
      "Epoch [39/50], Step [387/735], Loss: 0.1414\n",
      "Epoch [39/50], Step [388/735], Loss: 0.1135\n",
      "Epoch [39/50], Step [389/735], Loss: 0.0867\n",
      "Epoch [39/50], Step [390/735], Loss: 0.0648\n",
      "Epoch [39/50], Step [391/735], Loss: 0.1781\n",
      "Epoch [39/50], Step [392/735], Loss: 0.1968\n",
      "Epoch [39/50], Step [393/735], Loss: 0.0963\n",
      "Epoch [39/50], Step [394/735], Loss: 0.1852\n",
      "Epoch [39/50], Step [395/735], Loss: 0.2717\n",
      "Epoch [39/50], Step [396/735], Loss: 0.1060\n",
      "Epoch [39/50], Step [397/735], Loss: 0.1101\n",
      "Epoch [39/50], Step [398/735], Loss: 0.0788\n",
      "Epoch [39/50], Step [399/735], Loss: 0.0742\n",
      "Epoch [39/50], Step [400/735], Loss: 0.1790\n",
      "Epoch [39/50], Step [401/735], Loss: 0.0737\n",
      "Epoch [39/50], Step [402/735], Loss: 0.1448\n",
      "Epoch [39/50], Step [403/735], Loss: 0.1475\n",
      "Epoch [39/50], Step [404/735], Loss: 0.0706\n",
      "Epoch [39/50], Step [405/735], Loss: 0.1633\n",
      "Epoch [39/50], Step [406/735], Loss: 0.0974\n",
      "Epoch [39/50], Step [407/735], Loss: 0.0412\n",
      "Epoch [39/50], Step [408/735], Loss: 0.0606\n",
      "Epoch [39/50], Step [409/735], Loss: 0.1165\n",
      "Epoch [39/50], Step [410/735], Loss: 0.0918\n",
      "Epoch [39/50], Step [411/735], Loss: 0.0881\n",
      "Epoch [39/50], Step [412/735], Loss: 0.1055\n",
      "Epoch [39/50], Step [413/735], Loss: 0.0972\n",
      "Epoch [39/50], Step [414/735], Loss: 0.0721\n",
      "Epoch [39/50], Step [415/735], Loss: 0.0624\n",
      "Epoch [39/50], Step [416/735], Loss: 0.1298\n",
      "Epoch [39/50], Step [417/735], Loss: 0.7746\n",
      "Epoch [39/50], Step [418/735], Loss: 0.1105\n",
      "Epoch [39/50], Step [419/735], Loss: 0.0626\n",
      "Epoch [39/50], Step [420/735], Loss: 0.0989\n",
      "Epoch [39/50], Step [421/735], Loss: 0.1402\n",
      "Epoch [39/50], Step [422/735], Loss: 1.9165\n",
      "Epoch [39/50], Step [423/735], Loss: 0.1920\n",
      "Epoch [39/50], Step [424/735], Loss: 0.5403\n",
      "Epoch [39/50], Step [425/735], Loss: 0.1154\n",
      "Epoch [39/50], Step [426/735], Loss: 0.1835\n",
      "Epoch [39/50], Step [427/735], Loss: 0.4859\n",
      "Epoch [39/50], Step [428/735], Loss: 0.2598\n",
      "Epoch [39/50], Step [429/735], Loss: 0.1664\n",
      "Epoch [39/50], Step [430/735], Loss: 0.1144\n",
      "Epoch [39/50], Step [431/735], Loss: 0.0643\n",
      "Epoch [39/50], Step [432/735], Loss: 0.0826\n",
      "Epoch [39/50], Step [433/735], Loss: 0.1989\n",
      "Epoch [39/50], Step [434/735], Loss: 0.3239\n",
      "Epoch [39/50], Step [435/735], Loss: 0.1744\n",
      "Epoch [39/50], Step [436/735], Loss: 0.0808\n",
      "Epoch [39/50], Step [437/735], Loss: 0.1455\n",
      "Epoch [39/50], Step [438/735], Loss: 0.1707\n",
      "Epoch [39/50], Step [439/735], Loss: 0.0660\n",
      "Epoch [39/50], Step [440/735], Loss: 0.0777\n",
      "Epoch [39/50], Step [441/735], Loss: 0.0849\n",
      "Epoch [39/50], Step [442/735], Loss: 0.2859\n",
      "Epoch [39/50], Step [443/735], Loss: 0.0698\n",
      "Epoch [39/50], Step [444/735], Loss: 0.7774\n",
      "Epoch [39/50], Step [445/735], Loss: 0.0735\n",
      "Epoch [39/50], Step [446/735], Loss: 0.0538\n",
      "Epoch [39/50], Step [447/735], Loss: 0.1118\n",
      "Epoch [39/50], Step [448/735], Loss: 0.0644\n",
      "Epoch [39/50], Step [449/735], Loss: 0.1187\n",
      "Epoch [39/50], Step [450/735], Loss: 0.0576\n",
      "Epoch [39/50], Step [451/735], Loss: 0.1134\n",
      "Epoch [39/50], Step [452/735], Loss: 0.0710\n",
      "Epoch [39/50], Step [453/735], Loss: 0.0691\n",
      "Epoch [39/50], Step [454/735], Loss: 0.1154\n",
      "Epoch [39/50], Step [455/735], Loss: 0.0679\n",
      "Epoch [39/50], Step [456/735], Loss: 0.0815\n",
      "Epoch [39/50], Step [457/735], Loss: 0.0464\n",
      "Epoch [39/50], Step [458/735], Loss: 0.0665\n",
      "Epoch [39/50], Step [459/735], Loss: 0.1447\n",
      "Epoch [39/50], Step [460/735], Loss: 0.3009\n",
      "Epoch [39/50], Step [461/735], Loss: 0.1924\n",
      "Epoch [39/50], Step [462/735], Loss: 0.0887\n",
      "Epoch [39/50], Step [463/735], Loss: 0.0396\n",
      "Epoch [39/50], Step [464/735], Loss: 0.1315\n",
      "Epoch [39/50], Step [465/735], Loss: 0.0843\n",
      "Epoch [39/50], Step [466/735], Loss: 0.0692\n",
      "Epoch [39/50], Step [467/735], Loss: 0.7073\n",
      "Epoch [39/50], Step [468/735], Loss: 0.0856\n",
      "Epoch [39/50], Step [469/735], Loss: 0.0959\n",
      "Epoch [39/50], Step [470/735], Loss: 0.2331\n",
      "Epoch [39/50], Step [471/735], Loss: 0.5754\n",
      "Epoch [39/50], Step [472/735], Loss: 0.1814\n",
      "Epoch [39/50], Step [473/735], Loss: 0.0760\n",
      "Epoch [39/50], Step [474/735], Loss: 0.0916\n",
      "Epoch [39/50], Step [475/735], Loss: 0.0614\n",
      "Epoch [39/50], Step [476/735], Loss: 0.1418\n",
      "Epoch [39/50], Step [477/735], Loss: 0.3259\n",
      "Epoch [39/50], Step [478/735], Loss: 0.1282\n",
      "Epoch [39/50], Step [479/735], Loss: 0.0319\n",
      "Epoch [39/50], Step [480/735], Loss: 0.0363\n",
      "Epoch [39/50], Step [481/735], Loss: 0.1030\n",
      "Epoch [39/50], Step [482/735], Loss: 0.0531\n",
      "Epoch [39/50], Step [483/735], Loss: 0.0758\n",
      "Epoch [39/50], Step [484/735], Loss: 0.1355\n",
      "Epoch [39/50], Step [485/735], Loss: 0.0425\n",
      "Epoch [39/50], Step [486/735], Loss: 0.0412\n",
      "Epoch [39/50], Step [487/735], Loss: 0.0364\n",
      "Epoch [39/50], Step [488/735], Loss: 0.1550\n",
      "Epoch [39/50], Step [489/735], Loss: 0.0803\n",
      "Epoch [39/50], Step [490/735], Loss: 1.0559\n",
      "Epoch [39/50], Step [491/735], Loss: 0.0705\n",
      "Epoch [39/50], Step [492/735], Loss: 0.0637\n",
      "Epoch [39/50], Step [493/735], Loss: 0.0834\n",
      "Epoch [39/50], Step [494/735], Loss: 0.0876\n",
      "Epoch [39/50], Step [495/735], Loss: 0.1090\n",
      "Epoch [39/50], Step [496/735], Loss: 0.0660\n",
      "Epoch [39/50], Step [497/735], Loss: 0.1060\n",
      "Epoch [39/50], Step [498/735], Loss: 0.1229\n",
      "Epoch [39/50], Step [499/735], Loss: 0.1367\n",
      "Epoch [39/50], Step [500/735], Loss: 0.0469\n",
      "Epoch [39/50], Step [501/735], Loss: 0.0692\n",
      "Epoch [39/50], Step [502/735], Loss: 0.0718\n",
      "Epoch [39/50], Step [503/735], Loss: 0.1425\n",
      "Epoch [39/50], Step [504/735], Loss: 0.0824\n",
      "Epoch [39/50], Step [505/735], Loss: 0.0707\n",
      "Epoch [39/50], Step [506/735], Loss: 0.1087\n",
      "Epoch [39/50], Step [507/735], Loss: 0.1906\n",
      "Epoch [39/50], Step [508/735], Loss: 0.0813\n",
      "Epoch [39/50], Step [509/735], Loss: 0.1537\n",
      "Epoch [39/50], Step [510/735], Loss: 0.1098\n",
      "Epoch [39/50], Step [511/735], Loss: 0.2016\n",
      "Epoch [39/50], Step [512/735], Loss: 0.2437\n",
      "Epoch [39/50], Step [513/735], Loss: 0.0851\n",
      "Epoch [39/50], Step [514/735], Loss: 0.1818\n",
      "Epoch [39/50], Step [515/735], Loss: 0.1085\n",
      "Epoch [39/50], Step [516/735], Loss: 0.1705\n",
      "Epoch [39/50], Step [517/735], Loss: 0.0866\n",
      "Epoch [39/50], Step [518/735], Loss: 0.0917\n",
      "Epoch [39/50], Step [519/735], Loss: 0.1112\n",
      "Epoch [39/50], Step [520/735], Loss: 0.1217\n",
      "Epoch [39/50], Step [521/735], Loss: 0.0869\n",
      "Epoch [39/50], Step [522/735], Loss: 0.1106\n",
      "Epoch [39/50], Step [523/735], Loss: 0.0751\n",
      "Epoch [39/50], Step [524/735], Loss: 0.1696\n",
      "Epoch [39/50], Step [525/735], Loss: 0.1643\n",
      "Epoch [39/50], Step [526/735], Loss: 0.1004\n",
      "Epoch [39/50], Step [527/735], Loss: 0.0790\n",
      "Epoch [39/50], Step [528/735], Loss: 0.1170\n",
      "Epoch [39/50], Step [529/735], Loss: 0.0457\n",
      "Epoch [39/50], Step [530/735], Loss: 0.1059\n",
      "Epoch [39/50], Step [531/735], Loss: 0.1549\n",
      "Epoch [39/50], Step [532/735], Loss: 0.1109\n",
      "Epoch [39/50], Step [533/735], Loss: 0.5846\n",
      "Epoch [39/50], Step [534/735], Loss: 0.1273\n",
      "Epoch [39/50], Step [535/735], Loss: 0.0942\n",
      "Epoch [39/50], Step [536/735], Loss: 0.1336\n",
      "Epoch [39/50], Step [537/735], Loss: 0.0655\n",
      "Epoch [39/50], Step [538/735], Loss: 0.1724\n",
      "Epoch [39/50], Step [539/735], Loss: 0.0948\n",
      "Epoch [39/50], Step [540/735], Loss: 0.0948\n",
      "Epoch [39/50], Step [541/735], Loss: 0.0952\n",
      "Epoch [39/50], Step [542/735], Loss: 0.0996\n",
      "Epoch [39/50], Step [543/735], Loss: 0.1705\n",
      "Epoch [39/50], Step [544/735], Loss: 0.0796\n",
      "Epoch [39/50], Step [545/735], Loss: 0.7023\n",
      "Epoch [39/50], Step [546/735], Loss: 0.1840\n",
      "Epoch [39/50], Step [547/735], Loss: 0.1132\n",
      "Epoch [39/50], Step [548/735], Loss: 0.1236\n",
      "Epoch [39/50], Step [549/735], Loss: 0.0722\n",
      "Epoch [39/50], Step [550/735], Loss: 0.1013\n",
      "Epoch [39/50], Step [551/735], Loss: 0.0736\n",
      "Epoch [39/50], Step [552/735], Loss: 0.0479\n",
      "Epoch [39/50], Step [553/735], Loss: 0.0497\n",
      "Epoch [39/50], Step [554/735], Loss: 0.0327\n",
      "Epoch [39/50], Step [555/735], Loss: 0.0867\n",
      "Epoch [39/50], Step [556/735], Loss: 0.0696\n",
      "Epoch [39/50], Step [557/735], Loss: 0.1590\n",
      "Epoch [39/50], Step [558/735], Loss: 0.1211\n",
      "Epoch [39/50], Step [559/735], Loss: 0.6413\n",
      "Epoch [39/50], Step [560/735], Loss: 0.0999\n",
      "Epoch [39/50], Step [561/735], Loss: 0.0888\n",
      "Epoch [39/50], Step [562/735], Loss: 0.0449\n",
      "Epoch [39/50], Step [563/735], Loss: 0.0748\n",
      "Epoch [39/50], Step [564/735], Loss: 0.0356\n",
      "Epoch [39/50], Step [565/735], Loss: 0.0686\n",
      "Epoch [39/50], Step [566/735], Loss: 0.0707\n",
      "Epoch [39/50], Step [567/735], Loss: 0.2480\n",
      "Epoch [39/50], Step [568/735], Loss: 0.0976\n",
      "Epoch [39/50], Step [569/735], Loss: 0.0435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Step [570/735], Loss: 0.1202\n",
      "Epoch [39/50], Step [571/735], Loss: 0.0681\n",
      "Epoch [39/50], Step [572/735], Loss: 0.1274\n",
      "Epoch [39/50], Step [573/735], Loss: 0.0965\n",
      "Epoch [39/50], Step [574/735], Loss: 0.1562\n",
      "Epoch [39/50], Step [575/735], Loss: 0.0993\n",
      "Epoch [39/50], Step [576/735], Loss: 0.0949\n",
      "Epoch [39/50], Step [577/735], Loss: 0.0619\n",
      "Epoch [39/50], Step [578/735], Loss: 0.1313\n",
      "Epoch [39/50], Step [579/735], Loss: 0.0905\n",
      "Epoch [39/50], Step [580/735], Loss: 0.0632\n",
      "Epoch [39/50], Step [581/735], Loss: 0.0397\n",
      "Epoch [39/50], Step [582/735], Loss: 0.0805\n",
      "Epoch [39/50], Step [583/735], Loss: 0.0891\n",
      "Epoch [39/50], Step [584/735], Loss: 0.1794\n",
      "Epoch [39/50], Step [585/735], Loss: 0.0433\n",
      "Epoch [39/50], Step [586/735], Loss: 0.0369\n",
      "Epoch [39/50], Step [587/735], Loss: 0.1280\n",
      "Epoch [39/50], Step [588/735], Loss: 0.0905\n",
      "Epoch [39/50], Step [589/735], Loss: 0.0525\n",
      "Epoch [39/50], Step [590/735], Loss: 0.0754\n",
      "Epoch [39/50], Step [591/735], Loss: 0.0770\n",
      "Epoch [39/50], Step [592/735], Loss: 0.0686\n",
      "Epoch [39/50], Step [593/735], Loss: 0.0373\n",
      "Epoch [39/50], Step [594/735], Loss: 0.1495\n",
      "Epoch [39/50], Step [595/735], Loss: 0.1129\n",
      "Epoch [39/50], Step [596/735], Loss: 0.1780\n",
      "Epoch [39/50], Step [597/735], Loss: 0.0710\n",
      "Epoch [39/50], Step [598/735], Loss: 0.3371\n",
      "Epoch [39/50], Step [599/735], Loss: 0.0694\n",
      "Epoch [39/50], Step [600/735], Loss: 0.1247\n",
      "Epoch [39/50], Step [601/735], Loss: 0.0713\n",
      "Epoch [39/50], Step [602/735], Loss: 0.0818\n",
      "Epoch [39/50], Step [603/735], Loss: 0.0737\n",
      "Epoch [39/50], Step [604/735], Loss: 0.1347\n",
      "Epoch [39/50], Step [605/735], Loss: 0.1520\n",
      "Epoch [39/50], Step [606/735], Loss: 0.4635\n",
      "Epoch [39/50], Step [607/735], Loss: 0.1059\n",
      "Epoch [39/50], Step [608/735], Loss: 0.0694\n",
      "Epoch [39/50], Step [609/735], Loss: 0.0462\n",
      "Epoch [39/50], Step [610/735], Loss: 0.0477\n",
      "Epoch [39/50], Step [611/735], Loss: 0.0345\n",
      "Epoch [39/50], Step [612/735], Loss: 0.2714\n",
      "Epoch [39/50], Step [613/735], Loss: 0.0622\n",
      "Epoch [39/50], Step [614/735], Loss: 0.0852\n",
      "Epoch [39/50], Step [615/735], Loss: 0.0999\n",
      "Epoch [39/50], Step [616/735], Loss: 1.9831\n",
      "Epoch [39/50], Step [617/735], Loss: 1.7845\n",
      "Epoch [39/50], Step [618/735], Loss: 0.1136\n",
      "Epoch [39/50], Step [619/735], Loss: 0.1839\n",
      "Epoch [39/50], Step [620/735], Loss: 0.0740\n",
      "Epoch [39/50], Step [621/735], Loss: 0.0656\n",
      "Epoch [39/50], Step [622/735], Loss: 0.5856\n",
      "Epoch [39/50], Step [623/735], Loss: 0.1412\n",
      "Epoch [39/50], Step [624/735], Loss: 0.0665\n",
      "Epoch [39/50], Step [625/735], Loss: 0.0730\n",
      "Epoch [39/50], Step [626/735], Loss: 0.0535\n",
      "Epoch [39/50], Step [627/735], Loss: 0.1065\n",
      "Epoch [39/50], Step [628/735], Loss: 0.0818\n",
      "Epoch [39/50], Step [629/735], Loss: 0.2760\n",
      "Epoch [39/50], Step [630/735], Loss: 0.0632\n",
      "Epoch [39/50], Step [631/735], Loss: 0.0603\n",
      "Epoch [39/50], Step [632/735], Loss: 0.1425\n",
      "Epoch [39/50], Step [633/735], Loss: 0.1577\n",
      "Epoch [39/50], Step [634/735], Loss: 0.0826\n",
      "Epoch [39/50], Step [635/735], Loss: 0.1567\n",
      "Epoch [39/50], Step [636/735], Loss: 0.2365\n",
      "Epoch [39/50], Step [637/735], Loss: 0.0871\n",
      "Epoch [39/50], Step [638/735], Loss: 0.1193\n",
      "Epoch [39/50], Step [639/735], Loss: 0.0678\n",
      "Epoch [39/50], Step [640/735], Loss: 0.1863\n",
      "Epoch [39/50], Step [641/735], Loss: 0.0777\n",
      "Epoch [39/50], Step [642/735], Loss: 0.0995\n",
      "Epoch [39/50], Step [643/735], Loss: 0.0643\n",
      "Epoch [39/50], Step [644/735], Loss: 0.0394\n",
      "Epoch [39/50], Step [645/735], Loss: 0.2082\n",
      "Epoch [39/50], Step [646/735], Loss: 0.1034\n",
      "Epoch [39/50], Step [647/735], Loss: 0.1027\n",
      "Epoch [39/50], Step [648/735], Loss: 0.0456\n",
      "Epoch [39/50], Step [649/735], Loss: 0.6173\n",
      "Epoch [39/50], Step [650/735], Loss: 0.0539\n",
      "Epoch [39/50], Step [651/735], Loss: 0.0734\n",
      "Epoch [39/50], Step [652/735], Loss: 0.0826\n",
      "Epoch [39/50], Step [653/735], Loss: 0.0937\n",
      "Epoch [39/50], Step [654/735], Loss: 0.3687\n",
      "Epoch [39/50], Step [655/735], Loss: 0.1142\n",
      "Epoch [39/50], Step [656/735], Loss: 0.2210\n",
      "Epoch [39/50], Step [657/735], Loss: 0.1451\n",
      "Epoch [39/50], Step [658/735], Loss: 0.0778\n",
      "Epoch [39/50], Step [659/735], Loss: 0.4781\n",
      "Epoch [39/50], Step [660/735], Loss: 0.1178\n",
      "Epoch [39/50], Step [661/735], Loss: 0.0791\n",
      "Epoch [39/50], Step [662/735], Loss: 0.0416\n",
      "Epoch [39/50], Step [663/735], Loss: 0.1611\n",
      "Epoch [39/50], Step [664/735], Loss: 0.0930\n",
      "Epoch [39/50], Step [665/735], Loss: 0.0611\n",
      "Epoch [39/50], Step [666/735], Loss: 0.0630\n",
      "Epoch [39/50], Step [667/735], Loss: 0.0595\n",
      "Epoch [39/50], Step [668/735], Loss: 0.3881\n",
      "Epoch [39/50], Step [669/735], Loss: 0.0827\n",
      "Epoch [39/50], Step [670/735], Loss: 0.0724\n",
      "Epoch [39/50], Step [671/735], Loss: 0.0405\n",
      "Epoch [39/50], Step [672/735], Loss: 0.0909\n",
      "Epoch [39/50], Step [673/735], Loss: 0.1379\n",
      "Epoch [39/50], Step [674/735], Loss: 0.0527\n",
      "Epoch [39/50], Step [675/735], Loss: 0.2043\n",
      "Epoch [39/50], Step [676/735], Loss: 0.0911\n",
      "Epoch [39/50], Step [677/735], Loss: 0.1419\n",
      "Epoch [39/50], Step [678/735], Loss: 0.1728\n",
      "Epoch [39/50], Step [679/735], Loss: 0.0653\n",
      "Epoch [39/50], Step [680/735], Loss: 0.4592\n",
      "Epoch [39/50], Step [681/735], Loss: 0.0771\n",
      "Epoch [39/50], Step [682/735], Loss: 0.1310\n",
      "Epoch [39/50], Step [683/735], Loss: 0.0535\n",
      "Epoch [39/50], Step [684/735], Loss: 0.0736\n",
      "Epoch [39/50], Step [685/735], Loss: 0.1167\n",
      "Epoch [39/50], Step [686/735], Loss: 0.0907\n",
      "Epoch [39/50], Step [687/735], Loss: 0.1475\n",
      "Epoch [39/50], Step [688/735], Loss: 0.5959\n",
      "Epoch [39/50], Step [689/735], Loss: 0.0727\n",
      "Epoch [39/50], Step [690/735], Loss: 0.1003\n",
      "Epoch [39/50], Step [691/735], Loss: 0.0920\n",
      "Epoch [39/50], Step [692/735], Loss: 0.0767\n",
      "Epoch [39/50], Step [693/735], Loss: 0.1124\n",
      "Epoch [39/50], Step [694/735], Loss: 0.0365\n",
      "Epoch [39/50], Step [695/735], Loss: 0.1485\n",
      "Epoch [39/50], Step [696/735], Loss: 0.0513\n",
      "Epoch [39/50], Step [697/735], Loss: 0.0404\n",
      "Epoch [39/50], Step [698/735], Loss: 0.1446\n",
      "Epoch [39/50], Step [699/735], Loss: 0.4785\n",
      "Epoch [39/50], Step [700/735], Loss: 0.6889\n",
      "Epoch [39/50], Step [701/735], Loss: 0.0314\n",
      "Epoch [39/50], Step [702/735], Loss: 0.1409\n",
      "Epoch [39/50], Step [703/735], Loss: 0.1171\n",
      "Epoch [39/50], Step [704/735], Loss: 0.0480\n",
      "Epoch [39/50], Step [705/735], Loss: 0.0387\n",
      "Epoch [39/50], Step [706/735], Loss: 0.1080\n",
      "Epoch [39/50], Step [707/735], Loss: 0.0590\n",
      "Epoch [39/50], Step [708/735], Loss: 0.0523\n",
      "Epoch [39/50], Step [709/735], Loss: 0.1054\n",
      "Epoch [39/50], Step [710/735], Loss: 0.1209\n",
      "Epoch [39/50], Step [711/735], Loss: 0.4035\n",
      "Epoch [39/50], Step [712/735], Loss: 0.4409\n",
      "Epoch [39/50], Step [713/735], Loss: 0.1258\n",
      "Epoch [39/50], Step [714/735], Loss: 0.1117\n",
      "Epoch [39/50], Step [715/735], Loss: 0.0480\n",
      "Epoch [39/50], Step [716/735], Loss: 0.0857\n",
      "Epoch [39/50], Step [717/735], Loss: 0.0450\n",
      "Epoch [39/50], Step [718/735], Loss: 0.2714\n",
      "Epoch [39/50], Step [719/735], Loss: 0.0690\n",
      "Epoch [39/50], Step [720/735], Loss: 0.0823\n",
      "Epoch [39/50], Step [721/735], Loss: 0.7724\n",
      "Epoch [39/50], Step [722/735], Loss: 0.1021\n",
      "Epoch [39/50], Step [723/735], Loss: 0.3746\n",
      "Epoch [39/50], Step [724/735], Loss: 0.0465\n",
      "Epoch [39/50], Step [725/735], Loss: 0.0586\n",
      "Epoch [39/50], Step [726/735], Loss: 0.0538\n",
      "Epoch [39/50], Step [727/735], Loss: 0.0647\n",
      "Epoch [39/50], Step [728/735], Loss: 0.0779\n",
      "Epoch [39/50], Step [729/735], Loss: 0.0769\n",
      "Epoch [39/50], Step [730/735], Loss: 0.1092\n",
      "Epoch [39/50], Step [731/735], Loss: 0.0633\n",
      "Epoch [39/50], Step [732/735], Loss: 0.1424\n",
      "Epoch [39/50], Step [733/735], Loss: 0.1539\n",
      "Epoch [39/50], Step [734/735], Loss: 0.0582\n",
      "Epoch [39/50], Step [735/735], Loss: 0.1253\n",
      "Epoch [40/50], Step [1/735], Loss: 0.0974\n",
      "Epoch [40/50], Step [2/735], Loss: 0.1316\n",
      "Epoch [40/50], Step [3/735], Loss: 0.1158\n",
      "Epoch [40/50], Step [4/735], Loss: 0.0879\n",
      "Epoch [40/50], Step [5/735], Loss: 0.1214\n",
      "Epoch [40/50], Step [6/735], Loss: 0.1265\n",
      "Epoch [40/50], Step [7/735], Loss: 0.0706\n",
      "Epoch [40/50], Step [8/735], Loss: 0.0606\n",
      "Epoch [40/50], Step [9/735], Loss: 0.9803\n",
      "Epoch [40/50], Step [10/735], Loss: 0.0427\n",
      "Epoch [40/50], Step [11/735], Loss: 0.1732\n",
      "Epoch [40/50], Step [12/735], Loss: 0.0586\n",
      "Epoch [40/50], Step [13/735], Loss: 0.0627\n",
      "Epoch [40/50], Step [14/735], Loss: 0.2008\n",
      "Epoch [40/50], Step [15/735], Loss: 0.0839\n",
      "Epoch [40/50], Step [16/735], Loss: 0.0530\n",
      "Epoch [40/50], Step [17/735], Loss: 0.0550\n",
      "Epoch [40/50], Step [18/735], Loss: 0.0471\n",
      "Epoch [40/50], Step [19/735], Loss: 0.0990\n",
      "Epoch [40/50], Step [20/735], Loss: 0.1185\n",
      "Epoch [40/50], Step [21/735], Loss: 0.0539\n",
      "Epoch [40/50], Step [22/735], Loss: 0.2089\n",
      "Epoch [40/50], Step [23/735], Loss: 0.2284\n",
      "Epoch [40/50], Step [24/735], Loss: 0.0708\n",
      "Epoch [40/50], Step [25/735], Loss: 0.1186\n",
      "Epoch [40/50], Step [26/735], Loss: 0.1967\n",
      "Epoch [40/50], Step [27/735], Loss: 0.0884\n",
      "Epoch [40/50], Step [28/735], Loss: 0.4239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Step [29/735], Loss: 0.0902\n",
      "Epoch [40/50], Step [30/735], Loss: 0.0481\n",
      "Epoch [40/50], Step [31/735], Loss: 0.0305\n",
      "Epoch [40/50], Step [32/735], Loss: 0.0524\n",
      "Epoch [40/50], Step [33/735], Loss: 0.1346\n",
      "Epoch [40/50], Step [34/735], Loss: 0.0636\n",
      "Epoch [40/50], Step [35/735], Loss: 0.0755\n",
      "Epoch [40/50], Step [36/735], Loss: 0.1424\n",
      "Epoch [40/50], Step [37/735], Loss: 0.0650\n",
      "Epoch [40/50], Step [38/735], Loss: 0.1048\n",
      "Epoch [40/50], Step [39/735], Loss: 0.0847\n",
      "Epoch [40/50], Step [40/735], Loss: 0.0495\n",
      "Epoch [40/50], Step [41/735], Loss: 0.0779\n",
      "Epoch [40/50], Step [42/735], Loss: 0.1842\n",
      "Epoch [40/50], Step [43/735], Loss: 0.0752\n",
      "Epoch [40/50], Step [44/735], Loss: 0.1237\n",
      "Epoch [40/50], Step [45/735], Loss: 0.0805\n",
      "Epoch [40/50], Step [46/735], Loss: 0.1088\n",
      "Epoch [40/50], Step [47/735], Loss: 0.0852\n",
      "Epoch [40/50], Step [48/735], Loss: 0.0665\n",
      "Epoch [40/50], Step [49/735], Loss: 0.0724\n",
      "Epoch [40/50], Step [50/735], Loss: 0.1232\n",
      "Epoch [40/50], Step [51/735], Loss: 0.1013\n",
      "Epoch [40/50], Step [52/735], Loss: 0.0614\n",
      "Epoch [40/50], Step [53/735], Loss: 0.0779\n",
      "Epoch [40/50], Step [54/735], Loss: 0.1876\n",
      "Epoch [40/50], Step [55/735], Loss: 0.1175\n",
      "Epoch [40/50], Step [56/735], Loss: 0.2329\n",
      "Epoch [40/50], Step [57/735], Loss: 0.5576\n",
      "Epoch [40/50], Step [58/735], Loss: 0.0920\n",
      "Epoch [40/50], Step [59/735], Loss: 0.0717\n",
      "Epoch [40/50], Step [60/735], Loss: 0.1815\n",
      "Epoch [40/50], Step [61/735], Loss: 0.0397\n",
      "Epoch [40/50], Step [62/735], Loss: 0.0423\n",
      "Epoch [40/50], Step [63/735], Loss: 0.0678\n",
      "Epoch [40/50], Step [64/735], Loss: 0.0866\n",
      "Epoch [40/50], Step [65/735], Loss: 0.1214\n",
      "Epoch [40/50], Step [66/735], Loss: 0.0621\n",
      "Epoch [40/50], Step [67/735], Loss: 0.0733\n",
      "Epoch [40/50], Step [68/735], Loss: 0.1962\n",
      "Epoch [40/50], Step [69/735], Loss: 0.0947\n",
      "Epoch [40/50], Step [70/735], Loss: 0.7769\n",
      "Epoch [40/50], Step [71/735], Loss: 0.1221\n",
      "Epoch [40/50], Step [72/735], Loss: 0.0536\n",
      "Epoch [40/50], Step [73/735], Loss: 0.2403\n",
      "Epoch [40/50], Step [74/735], Loss: 0.0959\n",
      "Epoch [40/50], Step [75/735], Loss: 0.0819\n",
      "Epoch [40/50], Step [76/735], Loss: 0.0471\n",
      "Epoch [40/50], Step [77/735], Loss: 0.1057\n",
      "Epoch [40/50], Step [78/735], Loss: 0.0550\n",
      "Epoch [40/50], Step [79/735], Loss: 0.1138\n",
      "Epoch [40/50], Step [80/735], Loss: 0.0737\n",
      "Epoch [40/50], Step [81/735], Loss: 0.0843\n",
      "Epoch [40/50], Step [82/735], Loss: 0.0594\n",
      "Epoch [40/50], Step [83/735], Loss: 0.0644\n",
      "Epoch [40/50], Step [84/735], Loss: 0.2090\n",
      "Epoch [40/50], Step [85/735], Loss: 0.2381\n",
      "Epoch [40/50], Step [86/735], Loss: 0.0991\n",
      "Epoch [40/50], Step [87/735], Loss: 0.1474\n",
      "Epoch [40/50], Step [88/735], Loss: 0.1523\n",
      "Epoch [40/50], Step [89/735], Loss: 0.1748\n",
      "Epoch [40/50], Step [90/735], Loss: 0.1548\n",
      "Epoch [40/50], Step [91/735], Loss: 0.1018\n",
      "Epoch [40/50], Step [92/735], Loss: 0.0915\n",
      "Epoch [40/50], Step [93/735], Loss: 0.1250\n",
      "Epoch [40/50], Step [94/735], Loss: 0.0959\n",
      "Epoch [40/50], Step [95/735], Loss: 0.1347\n",
      "Epoch [40/50], Step [96/735], Loss: 0.7923\n",
      "Epoch [40/50], Step [97/735], Loss: 0.1737\n",
      "Epoch [40/50], Step [98/735], Loss: 0.1743\n",
      "Epoch [40/50], Step [99/735], Loss: 0.1342\n",
      "Epoch [40/50], Step [100/735], Loss: 0.0997\n",
      "Epoch [40/50], Step [101/735], Loss: 0.1441\n",
      "Epoch [40/50], Step [102/735], Loss: 0.1263\n",
      "Epoch [40/50], Step [103/735], Loss: 0.0946\n",
      "Epoch [40/50], Step [104/735], Loss: 0.1160\n",
      "Epoch [40/50], Step [105/735], Loss: 0.1240\n",
      "Epoch [40/50], Step [106/735], Loss: 0.0861\n",
      "Epoch [40/50], Step [107/735], Loss: 0.0830\n",
      "Epoch [40/50], Step [108/735], Loss: 0.0658\n",
      "Epoch [40/50], Step [109/735], Loss: 0.0890\n",
      "Epoch [40/50], Step [110/735], Loss: 0.0792\n",
      "Epoch [40/50], Step [111/735], Loss: 0.0720\n",
      "Epoch [40/50], Step [112/735], Loss: 0.1460\n",
      "Epoch [40/50], Step [113/735], Loss: 0.1361\n",
      "Epoch [40/50], Step [114/735], Loss: 0.0602\n",
      "Epoch [40/50], Step [115/735], Loss: 0.0404\n",
      "Epoch [40/50], Step [116/735], Loss: 0.0635\n",
      "Epoch [40/50], Step [117/735], Loss: 0.0707\n",
      "Epoch [40/50], Step [118/735], Loss: 0.0436\n",
      "Epoch [40/50], Step [119/735], Loss: 0.1159\n",
      "Epoch [40/50], Step [120/735], Loss: 0.1232\n",
      "Epoch [40/50], Step [121/735], Loss: 0.4537\n",
      "Epoch [40/50], Step [122/735], Loss: 0.0652\n",
      "Epoch [40/50], Step [123/735], Loss: 0.2161\n",
      "Epoch [40/50], Step [124/735], Loss: 0.3954\n",
      "Epoch [40/50], Step [125/735], Loss: 0.0512\n",
      "Epoch [40/50], Step [126/735], Loss: 0.0828\n",
      "Epoch [40/50], Step [127/735], Loss: 0.3465\n",
      "Epoch [40/50], Step [128/735], Loss: 0.0630\n",
      "Epoch [40/50], Step [129/735], Loss: 0.0813\n",
      "Epoch [40/50], Step [130/735], Loss: 0.3446\n",
      "Epoch [40/50], Step [131/735], Loss: 0.0984\n",
      "Epoch [40/50], Step [132/735], Loss: 0.1524\n",
      "Epoch [40/50], Step [133/735], Loss: 0.1359\n",
      "Epoch [40/50], Step [134/735], Loss: 0.1492\n",
      "Epoch [40/50], Step [135/735], Loss: 0.2294\n",
      "Epoch [40/50], Step [136/735], Loss: 0.0503\n",
      "Epoch [40/50], Step [137/735], Loss: 0.1862\n",
      "Epoch [40/50], Step [138/735], Loss: 0.0560\n",
      "Epoch [40/50], Step [139/735], Loss: 0.0579\n",
      "Epoch [40/50], Step [140/735], Loss: 0.0552\n",
      "Epoch [40/50], Step [141/735], Loss: 0.0462\n",
      "Epoch [40/50], Step [142/735], Loss: 0.0892\n",
      "Epoch [40/50], Step [143/735], Loss: 0.1440\n",
      "Epoch [40/50], Step [144/735], Loss: 0.0443\n",
      "Epoch [40/50], Step [145/735], Loss: 0.1116\n",
      "Epoch [40/50], Step [146/735], Loss: 0.1756\n",
      "Epoch [40/50], Step [147/735], Loss: 0.0662\n",
      "Epoch [40/50], Step [148/735], Loss: 0.0821\n",
      "Epoch [40/50], Step [149/735], Loss: 0.0699\n",
      "Epoch [40/50], Step [150/735], Loss: 0.0734\n",
      "Epoch [40/50], Step [151/735], Loss: 0.0706\n",
      "Epoch [40/50], Step [152/735], Loss: 0.0670\n",
      "Epoch [40/50], Step [153/735], Loss: 0.0935\n",
      "Epoch [40/50], Step [154/735], Loss: 0.1132\n",
      "Epoch [40/50], Step [155/735], Loss: 0.0573\n",
      "Epoch [40/50], Step [156/735], Loss: 0.0798\n",
      "Epoch [40/50], Step [157/735], Loss: 0.0480\n",
      "Epoch [40/50], Step [158/735], Loss: 0.3658\n",
      "Epoch [40/50], Step [159/735], Loss: 0.0960\n",
      "Epoch [40/50], Step [160/735], Loss: 0.0244\n",
      "Epoch [40/50], Step [161/735], Loss: 0.2305\n",
      "Epoch [40/50], Step [162/735], Loss: 0.0294\n",
      "Epoch [40/50], Step [163/735], Loss: 0.0639\n",
      "Epoch [40/50], Step [164/735], Loss: 0.0814\n",
      "Epoch [40/50], Step [165/735], Loss: 0.0703\n",
      "Epoch [40/50], Step [166/735], Loss: 0.1660\n",
      "Epoch [40/50], Step [167/735], Loss: 0.1111\n",
      "Epoch [40/50], Step [168/735], Loss: 0.0367\n",
      "Epoch [40/50], Step [169/735], Loss: 0.0691\n",
      "Epoch [40/50], Step [170/735], Loss: 0.0990\n",
      "Epoch [40/50], Step [171/735], Loss: 0.1366\n",
      "Epoch [40/50], Step [172/735], Loss: 0.0845\n",
      "Epoch [40/50], Step [173/735], Loss: 0.0930\n",
      "Epoch [40/50], Step [174/735], Loss: 0.2564\n",
      "Epoch [40/50], Step [175/735], Loss: 0.1211\n",
      "Epoch [40/50], Step [176/735], Loss: 0.0846\n",
      "Epoch [40/50], Step [177/735], Loss: 0.0258\n",
      "Epoch [40/50], Step [178/735], Loss: 0.0302\n",
      "Epoch [40/50], Step [179/735], Loss: 0.0451\n",
      "Epoch [40/50], Step [180/735], Loss: 0.1251\n",
      "Epoch [40/50], Step [181/735], Loss: 0.0600\n",
      "Epoch [40/50], Step [182/735], Loss: 0.0503\n",
      "Epoch [40/50], Step [183/735], Loss: 0.0925\n",
      "Epoch [40/50], Step [184/735], Loss: 0.0566\n",
      "Epoch [40/50], Step [185/735], Loss: 0.0815\n",
      "Epoch [40/50], Step [186/735], Loss: 1.5256\n",
      "Epoch [40/50], Step [187/735], Loss: 0.0778\n",
      "Epoch [40/50], Step [188/735], Loss: 0.1370\n",
      "Epoch [40/50], Step [189/735], Loss: 0.0937\n",
      "Epoch [40/50], Step [190/735], Loss: 0.3771\n",
      "Epoch [40/50], Step [191/735], Loss: 0.0849\n",
      "Epoch [40/50], Step [192/735], Loss: 0.1753\n",
      "Epoch [40/50], Step [193/735], Loss: 0.1196\n",
      "Epoch [40/50], Step [194/735], Loss: 0.0464\n",
      "Epoch [40/50], Step [195/735], Loss: 0.1942\n",
      "Epoch [40/50], Step [196/735], Loss: 0.0859\n",
      "Epoch [40/50], Step [197/735], Loss: 0.0438\n",
      "Epoch [40/50], Step [198/735], Loss: 0.0820\n",
      "Epoch [40/50], Step [199/735], Loss: 0.0823\n",
      "Epoch [40/50], Step [200/735], Loss: 0.2863\n",
      "Epoch [40/50], Step [201/735], Loss: 0.0746\n",
      "Epoch [40/50], Step [202/735], Loss: 0.1314\n",
      "Epoch [40/50], Step [203/735], Loss: 0.1549\n",
      "Epoch [40/50], Step [204/735], Loss: 0.1008\n",
      "Epoch [40/50], Step [205/735], Loss: 0.0408\n",
      "Epoch [40/50], Step [206/735], Loss: 0.0993\n",
      "Epoch [40/50], Step [207/735], Loss: 0.0850\n",
      "Epoch [40/50], Step [208/735], Loss: 0.0519\n",
      "Epoch [40/50], Step [209/735], Loss: 0.0803\n",
      "Epoch [40/50], Step [210/735], Loss: 0.0447\n",
      "Epoch [40/50], Step [211/735], Loss: 0.0994\n",
      "Epoch [40/50], Step [212/735], Loss: 0.0462\n",
      "Epoch [40/50], Step [213/735], Loss: 0.0594\n",
      "Epoch [40/50], Step [214/735], Loss: 0.1308\n",
      "Epoch [40/50], Step [215/735], Loss: 0.3950\n",
      "Epoch [40/50], Step [216/735], Loss: 1.4917\n",
      "Epoch [40/50], Step [217/735], Loss: 0.1151\n",
      "Epoch [40/50], Step [218/735], Loss: 0.0768\n",
      "Epoch [40/50], Step [219/735], Loss: 0.1063\n",
      "Epoch [40/50], Step [220/735], Loss: 0.0747\n",
      "Epoch [40/50], Step [221/735], Loss: 0.1257\n",
      "Epoch [40/50], Step [222/735], Loss: 0.1051\n",
      "Epoch [40/50], Step [223/735], Loss: 0.0625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Step [224/735], Loss: 0.2705\n",
      "Epoch [40/50], Step [225/735], Loss: 0.1984\n",
      "Epoch [40/50], Step [226/735], Loss: 0.0984\n",
      "Epoch [40/50], Step [227/735], Loss: 0.1281\n",
      "Epoch [40/50], Step [228/735], Loss: 0.1362\n",
      "Epoch [40/50], Step [229/735], Loss: 0.1241\n",
      "Epoch [40/50], Step [230/735], Loss: 0.0649\n",
      "Epoch [40/50], Step [231/735], Loss: 0.0548\n",
      "Epoch [40/50], Step [232/735], Loss: 0.1478\n",
      "Epoch [40/50], Step [233/735], Loss: 0.0676\n",
      "Epoch [40/50], Step [234/735], Loss: 0.0733\n",
      "Epoch [40/50], Step [235/735], Loss: 0.0754\n",
      "Epoch [40/50], Step [236/735], Loss: 0.1569\n",
      "Epoch [40/50], Step [237/735], Loss: 0.1907\n",
      "Epoch [40/50], Step [238/735], Loss: 0.0740\n",
      "Epoch [40/50], Step [239/735], Loss: 0.0759\n",
      "Epoch [40/50], Step [240/735], Loss: 0.1680\n",
      "Epoch [40/50], Step [241/735], Loss: 0.0910\n",
      "Epoch [40/50], Step [242/735], Loss: 0.1235\n",
      "Epoch [40/50], Step [243/735], Loss: 0.1114\n",
      "Epoch [40/50], Step [244/735], Loss: 0.1196\n",
      "Epoch [40/50], Step [245/735], Loss: 0.0659\n",
      "Epoch [40/50], Step [246/735], Loss: 0.1006\n",
      "Epoch [40/50], Step [247/735], Loss: 0.0894\n",
      "Epoch [40/50], Step [248/735], Loss: 0.1243\n",
      "Epoch [40/50], Step [249/735], Loss: 0.7673\n",
      "Epoch [40/50], Step [250/735], Loss: 0.0493\n",
      "Epoch [40/50], Step [251/735], Loss: 0.0538\n",
      "Epoch [40/50], Step [252/735], Loss: 1.6034\n",
      "Epoch [40/50], Step [253/735], Loss: 0.1619\n",
      "Epoch [40/50], Step [254/735], Loss: 0.2373\n",
      "Epoch [40/50], Step [255/735], Loss: 0.1077\n",
      "Epoch [40/50], Step [256/735], Loss: 0.2085\n",
      "Epoch [40/50], Step [257/735], Loss: 0.0889\n",
      "Epoch [40/50], Step [258/735], Loss: 0.0933\n",
      "Epoch [40/50], Step [259/735], Loss: 0.1150\n",
      "Epoch [40/50], Step [260/735], Loss: 0.1787\n",
      "Epoch [40/50], Step [261/735], Loss: 0.1554\n",
      "Epoch [40/50], Step [262/735], Loss: 0.0624\n",
      "Epoch [40/50], Step [263/735], Loss: 0.0501\n",
      "Epoch [40/50], Step [264/735], Loss: 0.3702\n",
      "Epoch [40/50], Step [265/735], Loss: 0.1108\n",
      "Epoch [40/50], Step [266/735], Loss: 0.1795\n",
      "Epoch [40/50], Step [267/735], Loss: 0.1250\n",
      "Epoch [40/50], Step [268/735], Loss: 0.0847\n",
      "Epoch [40/50], Step [269/735], Loss: 0.0518\n",
      "Epoch [40/50], Step [270/735], Loss: 0.0864\n",
      "Epoch [40/50], Step [271/735], Loss: 0.1866\n",
      "Epoch [40/50], Step [272/735], Loss: 0.0516\n",
      "Epoch [40/50], Step [273/735], Loss: 0.0951\n",
      "Epoch [40/50], Step [274/735], Loss: 0.0553\n",
      "Epoch [40/50], Step [275/735], Loss: 0.1182\n",
      "Epoch [40/50], Step [276/735], Loss: 0.1042\n",
      "Epoch [40/50], Step [277/735], Loss: 0.0615\n",
      "Epoch [40/50], Step [278/735], Loss: 0.0891\n",
      "Epoch [40/50], Step [279/735], Loss: 0.0539\n",
      "Epoch [40/50], Step [280/735], Loss: 0.3207\n",
      "Epoch [40/50], Step [281/735], Loss: 0.1144\n",
      "Epoch [40/50], Step [282/735], Loss: 0.0721\n",
      "Epoch [40/50], Step [283/735], Loss: 0.1409\n",
      "Epoch [40/50], Step [284/735], Loss: 0.2250\n",
      "Epoch [40/50], Step [285/735], Loss: 0.1369\n",
      "Epoch [40/50], Step [286/735], Loss: 0.1007\n",
      "Epoch [40/50], Step [287/735], Loss: 0.0756\n",
      "Epoch [40/50], Step [288/735], Loss: 0.1010\n",
      "Epoch [40/50], Step [289/735], Loss: 0.0628\n",
      "Epoch [40/50], Step [290/735], Loss: 0.1177\n",
      "Epoch [40/50], Step [291/735], Loss: 0.0832\n",
      "Epoch [40/50], Step [292/735], Loss: 0.1387\n",
      "Epoch [40/50], Step [293/735], Loss: 0.1139\n",
      "Epoch [40/50], Step [294/735], Loss: 0.0827\n",
      "Epoch [40/50], Step [295/735], Loss: 0.1216\n",
      "Epoch [40/50], Step [296/735], Loss: 0.0880\n",
      "Epoch [40/50], Step [297/735], Loss: 0.2003\n",
      "Epoch [40/50], Step [298/735], Loss: 0.1090\n",
      "Epoch [40/50], Step [299/735], Loss: 0.0811\n",
      "Epoch [40/50], Step [300/735], Loss: 0.1298\n",
      "Epoch [40/50], Step [301/735], Loss: 0.2095\n",
      "Epoch [40/50], Step [302/735], Loss: 0.0576\n",
      "Epoch [40/50], Step [303/735], Loss: 0.0889\n",
      "Epoch [40/50], Step [304/735], Loss: 0.0552\n",
      "Epoch [40/50], Step [305/735], Loss: 0.0766\n",
      "Epoch [40/50], Step [306/735], Loss: 0.0751\n",
      "Epoch [40/50], Step [307/735], Loss: 0.6669\n",
      "Epoch [40/50], Step [308/735], Loss: 0.0896\n",
      "Epoch [40/50], Step [309/735], Loss: 0.1062\n",
      "Epoch [40/50], Step [310/735], Loss: 0.1293\n",
      "Epoch [40/50], Step [311/735], Loss: 0.0399\n",
      "Epoch [40/50], Step [312/735], Loss: 1.5130\n",
      "Epoch [40/50], Step [313/735], Loss: 0.1169\n",
      "Epoch [40/50], Step [314/735], Loss: 0.1110\n",
      "Epoch [40/50], Step [315/735], Loss: 0.0804\n",
      "Epoch [40/50], Step [316/735], Loss: 0.0705\n",
      "Epoch [40/50], Step [317/735], Loss: 0.1630\n",
      "Epoch [40/50], Step [318/735], Loss: 0.0911\n",
      "Epoch [40/50], Step [319/735], Loss: 0.0657\n",
      "Epoch [40/50], Step [320/735], Loss: 0.1466\n",
      "Epoch [40/50], Step [321/735], Loss: 0.0419\n",
      "Epoch [40/50], Step [322/735], Loss: 0.0990\n",
      "Epoch [40/50], Step [323/735], Loss: 0.0426\n",
      "Epoch [40/50], Step [324/735], Loss: 0.0661\n",
      "Epoch [40/50], Step [325/735], Loss: 0.0718\n",
      "Epoch [40/50], Step [326/735], Loss: 0.0848\n",
      "Epoch [40/50], Step [327/735], Loss: 0.0597\n",
      "Epoch [40/50], Step [328/735], Loss: 0.1047\n",
      "Epoch [40/50], Step [329/735], Loss: 0.0692\n",
      "Epoch [40/50], Step [330/735], Loss: 0.2189\n",
      "Epoch [40/50], Step [331/735], Loss: 0.1072\n",
      "Epoch [40/50], Step [332/735], Loss: 0.0834\n",
      "Epoch [40/50], Step [333/735], Loss: 0.0406\n",
      "Epoch [40/50], Step [334/735], Loss: 0.0626\n",
      "Epoch [40/50], Step [335/735], Loss: 0.0651\n",
      "Epoch [40/50], Step [336/735], Loss: 0.1255\n",
      "Epoch [40/50], Step [337/735], Loss: 0.1977\n",
      "Epoch [40/50], Step [338/735], Loss: 0.3122\n",
      "Epoch [40/50], Step [339/735], Loss: 0.1055\n",
      "Epoch [40/50], Step [340/735], Loss: 0.0641\n",
      "Epoch [40/50], Step [341/735], Loss: 0.0353\n",
      "Epoch [40/50], Step [342/735], Loss: 0.1233\n",
      "Epoch [40/50], Step [343/735], Loss: 0.0316\n",
      "Epoch [40/50], Step [344/735], Loss: 0.1259\n",
      "Epoch [40/50], Step [345/735], Loss: 0.0311\n",
      "Epoch [40/50], Step [346/735], Loss: 0.1227\n",
      "Epoch [40/50], Step [347/735], Loss: 0.0524\n",
      "Epoch [40/50], Step [348/735], Loss: 0.0827\n",
      "Epoch [40/50], Step [349/735], Loss: 0.0547\n",
      "Epoch [40/50], Step [350/735], Loss: 0.0910\n",
      "Epoch [40/50], Step [351/735], Loss: 0.1410\n",
      "Epoch [40/50], Step [352/735], Loss: 0.0449\n",
      "Epoch [40/50], Step [353/735], Loss: 0.0732\n",
      "Epoch [40/50], Step [354/735], Loss: 0.0695\n",
      "Epoch [40/50], Step [355/735], Loss: 0.0873\n",
      "Epoch [40/50], Step [356/735], Loss: 0.0711\n",
      "Epoch [40/50], Step [357/735], Loss: 0.0345\n",
      "Epoch [40/50], Step [358/735], Loss: 0.0839\n",
      "Epoch [40/50], Step [359/735], Loss: 0.0921\n",
      "Epoch [40/50], Step [360/735], Loss: 0.1421\n",
      "Epoch [40/50], Step [361/735], Loss: 0.1358\n",
      "Epoch [40/50], Step [362/735], Loss: 0.1089\n",
      "Epoch [40/50], Step [363/735], Loss: 0.0259\n",
      "Epoch [40/50], Step [364/735], Loss: 0.0587\n",
      "Epoch [40/50], Step [365/735], Loss: 0.0337\n",
      "Epoch [40/50], Step [366/735], Loss: 0.0899\n",
      "Epoch [40/50], Step [367/735], Loss: 0.1001\n",
      "Epoch [40/50], Step [368/735], Loss: 0.0764\n",
      "Epoch [40/50], Step [369/735], Loss: 0.0841\n",
      "Epoch [40/50], Step [370/735], Loss: 0.1001\n",
      "Epoch [40/50], Step [371/735], Loss: 0.0978\n",
      "Epoch [40/50], Step [372/735], Loss: 0.0664\n",
      "Epoch [40/50], Step [373/735], Loss: 0.0880\n",
      "Epoch [40/50], Step [374/735], Loss: 0.0502\n",
      "Epoch [40/50], Step [375/735], Loss: 0.0651\n",
      "Epoch [40/50], Step [376/735], Loss: 0.0975\n",
      "Epoch [40/50], Step [377/735], Loss: 0.1615\n",
      "Epoch [40/50], Step [378/735], Loss: 0.1062\n",
      "Epoch [40/50], Step [379/735], Loss: 0.0871\n",
      "Epoch [40/50], Step [380/735], Loss: 0.0641\n",
      "Epoch [40/50], Step [381/735], Loss: 0.0865\n",
      "Epoch [40/50], Step [382/735], Loss: 0.5108\n",
      "Epoch [40/50], Step [383/735], Loss: 0.0886\n",
      "Epoch [40/50], Step [384/735], Loss: 0.0859\n",
      "Epoch [40/50], Step [385/735], Loss: 0.1402\n",
      "Epoch [40/50], Step [386/735], Loss: 0.0602\n",
      "Epoch [40/50], Step [387/735], Loss: 0.1621\n",
      "Epoch [40/50], Step [388/735], Loss: 0.0818\n",
      "Epoch [40/50], Step [389/735], Loss: 1.2915\n",
      "Epoch [40/50], Step [390/735], Loss: 0.0623\n",
      "Epoch [40/50], Step [391/735], Loss: 0.1079\n",
      "Epoch [40/50], Step [392/735], Loss: 0.1193\n",
      "Epoch [40/50], Step [393/735], Loss: 0.0481\n",
      "Epoch [40/50], Step [394/735], Loss: 0.0450\n",
      "Epoch [40/50], Step [395/735], Loss: 0.0809\n",
      "Epoch [40/50], Step [396/735], Loss: 0.0749\n",
      "Epoch [40/50], Step [397/735], Loss: 0.1300\n",
      "Epoch [40/50], Step [398/735], Loss: 0.1134\n",
      "Epoch [40/50], Step [399/735], Loss: 0.7784\n",
      "Epoch [40/50], Step [400/735], Loss: 0.1107\n",
      "Epoch [40/50], Step [401/735], Loss: 0.0422\n",
      "Epoch [40/50], Step [402/735], Loss: 0.0647\n",
      "Epoch [40/50], Step [403/735], Loss: 0.0412\n",
      "Epoch [40/50], Step [404/735], Loss: 0.0517\n",
      "Epoch [40/50], Step [405/735], Loss: 0.1033\n",
      "Epoch [40/50], Step [406/735], Loss: 0.1251\n",
      "Epoch [40/50], Step [407/735], Loss: 0.6991\n",
      "Epoch [40/50], Step [408/735], Loss: 0.1372\n",
      "Epoch [40/50], Step [409/735], Loss: 0.1378\n",
      "Epoch [40/50], Step [410/735], Loss: 0.0884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Step [411/735], Loss: 0.0385\n",
      "Epoch [40/50], Step [412/735], Loss: 0.1492\n",
      "Epoch [40/50], Step [413/735], Loss: 0.1397\n",
      "Epoch [40/50], Step [414/735], Loss: 0.0678\n",
      "Epoch [40/50], Step [415/735], Loss: 0.0856\n",
      "Epoch [40/50], Step [416/735], Loss: 0.0726\n",
      "Epoch [40/50], Step [417/735], Loss: 0.2082\n",
      "Epoch [40/50], Step [418/735], Loss: 0.3125\n",
      "Epoch [40/50], Step [419/735], Loss: 0.0878\n",
      "Epoch [40/50], Step [420/735], Loss: 0.2964\n",
      "Epoch [40/50], Step [421/735], Loss: 0.2296\n",
      "Epoch [40/50], Step [422/735], Loss: 0.0869\n",
      "Epoch [40/50], Step [423/735], Loss: 0.4216\n",
      "Epoch [40/50], Step [424/735], Loss: 0.6869\n",
      "Epoch [40/50], Step [425/735], Loss: 0.1538\n",
      "Epoch [40/50], Step [426/735], Loss: 0.0411\n",
      "Epoch [40/50], Step [427/735], Loss: 0.0449\n",
      "Epoch [40/50], Step [428/735], Loss: 0.0607\n",
      "Epoch [40/50], Step [429/735], Loss: 0.0468\n",
      "Epoch [40/50], Step [430/735], Loss: 0.0696\n",
      "Epoch [40/50], Step [431/735], Loss: 0.1252\n",
      "Epoch [40/50], Step [432/735], Loss: 0.0451\n",
      "Epoch [40/50], Step [433/735], Loss: 0.0879\n",
      "Epoch [40/50], Step [434/735], Loss: 0.0599\n",
      "Epoch [40/50], Step [435/735], Loss: 0.0528\n",
      "Epoch [40/50], Step [436/735], Loss: 0.0707\n",
      "Epoch [40/50], Step [437/735], Loss: 0.0589\n",
      "Epoch [40/50], Step [438/735], Loss: 0.0720\n",
      "Epoch [40/50], Step [439/735], Loss: 0.1232\n",
      "Epoch [40/50], Step [440/735], Loss: 0.0348\n",
      "Epoch [40/50], Step [441/735], Loss: 0.1256\n",
      "Epoch [40/50], Step [442/735], Loss: 0.5470\n",
      "Epoch [40/50], Step [443/735], Loss: 0.4451\n",
      "Epoch [40/50], Step [444/735], Loss: 0.0393\n",
      "Epoch [40/50], Step [445/735], Loss: 0.1090\n",
      "Epoch [40/50], Step [446/735], Loss: 0.0483\n",
      "Epoch [40/50], Step [447/735], Loss: 0.1283\n",
      "Epoch [40/50], Step [448/735], Loss: 0.0699\n",
      "Epoch [40/50], Step [449/735], Loss: 0.0352\n",
      "Epoch [40/50], Step [450/735], Loss: 0.0556\n",
      "Epoch [40/50], Step [451/735], Loss: 0.1019\n",
      "Epoch [40/50], Step [452/735], Loss: 0.1293\n",
      "Epoch [40/50], Step [453/735], Loss: 0.0439\n",
      "Epoch [40/50], Step [454/735], Loss: 0.1720\n",
      "Epoch [40/50], Step [455/735], Loss: 0.0332\n",
      "Epoch [40/50], Step [456/735], Loss: 0.1499\n",
      "Epoch [40/50], Step [457/735], Loss: 0.0702\n",
      "Epoch [40/50], Step [458/735], Loss: 0.0820\n",
      "Epoch [40/50], Step [459/735], Loss: 0.0503\n",
      "Epoch [40/50], Step [460/735], Loss: 0.2456\n",
      "Epoch [40/50], Step [461/735], Loss: 0.0462\n",
      "Epoch [40/50], Step [462/735], Loss: 0.2001\n",
      "Epoch [40/50], Step [463/735], Loss: 0.0753\n",
      "Epoch [40/50], Step [464/735], Loss: 0.1611\n",
      "Epoch [40/50], Step [465/735], Loss: 0.0998\n",
      "Epoch [40/50], Step [466/735], Loss: 0.0374\n",
      "Epoch [40/50], Step [467/735], Loss: 0.0588\n",
      "Epoch [40/50], Step [468/735], Loss: 0.0851\n",
      "Epoch [40/50], Step [469/735], Loss: 0.0902\n",
      "Epoch [40/50], Step [470/735], Loss: 0.1084\n",
      "Epoch [40/50], Step [471/735], Loss: 0.1222\n",
      "Epoch [40/50], Step [472/735], Loss: 0.0479\n",
      "Epoch [40/50], Step [473/735], Loss: 0.0522\n",
      "Epoch [40/50], Step [474/735], Loss: 0.0343\n",
      "Epoch [40/50], Step [475/735], Loss: 0.1804\n",
      "Epoch [40/50], Step [476/735], Loss: 0.0966\n",
      "Epoch [40/50], Step [477/735], Loss: 0.0676\n",
      "Epoch [40/50], Step [478/735], Loss: 0.1282\n",
      "Epoch [40/50], Step [479/735], Loss: 0.0546\n",
      "Epoch [40/50], Step [480/735], Loss: 0.0744\n",
      "Epoch [40/50], Step [481/735], Loss: 0.0956\n",
      "Epoch [40/50], Step [482/735], Loss: 0.0690\n",
      "Epoch [40/50], Step [483/735], Loss: 0.1317\n",
      "Epoch [40/50], Step [484/735], Loss: 0.2132\n",
      "Epoch [40/50], Step [485/735], Loss: 0.0577\n",
      "Epoch [40/50], Step [486/735], Loss: 0.0664\n",
      "Epoch [40/50], Step [487/735], Loss: 0.5889\n",
      "Epoch [40/50], Step [488/735], Loss: 0.0391\n",
      "Epoch [40/50], Step [489/735], Loss: 0.0547\n",
      "Epoch [40/50], Step [490/735], Loss: 0.1027\n",
      "Epoch [40/50], Step [491/735], Loss: 0.0474\n",
      "Epoch [40/50], Step [492/735], Loss: 0.0692\n",
      "Epoch [40/50], Step [493/735], Loss: 0.1006\n",
      "Epoch [40/50], Step [494/735], Loss: 1.0911\n",
      "Epoch [40/50], Step [495/735], Loss: 0.1614\n",
      "Epoch [40/50], Step [496/735], Loss: 0.1276\n",
      "Epoch [40/50], Step [497/735], Loss: 0.0933\n",
      "Epoch [40/50], Step [498/735], Loss: 0.1230\n",
      "Epoch [40/50], Step [499/735], Loss: 0.1441\n",
      "Epoch [40/50], Step [500/735], Loss: 0.1062\n",
      "Epoch [40/50], Step [501/735], Loss: 0.1840\n",
      "Epoch [40/50], Step [502/735], Loss: 0.0602\n",
      "Epoch [40/50], Step [503/735], Loss: 0.0820\n",
      "Epoch [40/50], Step [504/735], Loss: 0.0968\n",
      "Epoch [40/50], Step [505/735], Loss: 0.1058\n",
      "Epoch [40/50], Step [506/735], Loss: 0.0399\n",
      "Epoch [40/50], Step [507/735], Loss: 0.0459\n",
      "Epoch [40/50], Step [508/735], Loss: 0.0719\n",
      "Epoch [40/50], Step [509/735], Loss: 0.2991\n",
      "Epoch [40/50], Step [510/735], Loss: 0.1051\n",
      "Epoch [40/50], Step [511/735], Loss: 0.0634\n",
      "Epoch [40/50], Step [512/735], Loss: 0.0642\n",
      "Epoch [40/50], Step [513/735], Loss: 0.0523\n",
      "Epoch [40/50], Step [514/735], Loss: 0.0466\n",
      "Epoch [40/50], Step [515/735], Loss: 0.8591\n",
      "Epoch [40/50], Step [516/735], Loss: 0.1178\n",
      "Epoch [40/50], Step [517/735], Loss: 0.0659\n",
      "Epoch [40/50], Step [518/735], Loss: 0.5109\n",
      "Epoch [40/50], Step [519/735], Loss: 0.0931\n",
      "Epoch [40/50], Step [520/735], Loss: 0.0575\n",
      "Epoch [40/50], Step [521/735], Loss: 0.2083\n",
      "Epoch [40/50], Step [522/735], Loss: 0.1660\n",
      "Epoch [40/50], Step [523/735], Loss: 0.0466\n",
      "Epoch [40/50], Step [524/735], Loss: 0.1790\n",
      "Epoch [40/50], Step [525/735], Loss: 0.0967\n",
      "Epoch [40/50], Step [526/735], Loss: 0.1928\n",
      "Epoch [40/50], Step [527/735], Loss: 0.1213\n",
      "Epoch [40/50], Step [528/735], Loss: 0.0698\n",
      "Epoch [40/50], Step [529/735], Loss: 0.0754\n",
      "Epoch [40/50], Step [530/735], Loss: 0.0450\n",
      "Epoch [40/50], Step [531/735], Loss: 0.1040\n",
      "Epoch [40/50], Step [532/735], Loss: 0.7254\n",
      "Epoch [40/50], Step [533/735], Loss: 0.0287\n",
      "Epoch [40/50], Step [534/735], Loss: 0.1018\n",
      "Epoch [40/50], Step [535/735], Loss: 0.0718\n",
      "Epoch [40/50], Step [536/735], Loss: 0.1006\n",
      "Epoch [40/50], Step [537/735], Loss: 0.0707\n",
      "Epoch [40/50], Step [538/735], Loss: 0.0698\n",
      "Epoch [40/50], Step [539/735], Loss: 0.0510\n",
      "Epoch [40/50], Step [540/735], Loss: 0.0286\n",
      "Epoch [40/50], Step [541/735], Loss: 0.1426\n",
      "Epoch [40/50], Step [542/735], Loss: 0.0424\n",
      "Epoch [40/50], Step [543/735], Loss: 0.1245\n",
      "Epoch [40/50], Step [544/735], Loss: 0.0468\n",
      "Epoch [40/50], Step [545/735], Loss: 0.2352\n",
      "Epoch [40/50], Step [546/735], Loss: 0.1017\n",
      "Epoch [40/50], Step [547/735], Loss: 0.1218\n",
      "Epoch [40/50], Step [548/735], Loss: 0.4698\n",
      "Epoch [40/50], Step [549/735], Loss: 0.0540\n",
      "Epoch [40/50], Step [550/735], Loss: 0.0592\n",
      "Epoch [40/50], Step [551/735], Loss: 0.1002\n",
      "Epoch [40/50], Step [552/735], Loss: 0.0939\n",
      "Epoch [40/50], Step [553/735], Loss: 0.0415\n",
      "Epoch [40/50], Step [554/735], Loss: 0.1003\n",
      "Epoch [40/50], Step [555/735], Loss: 0.1035\n",
      "Epoch [40/50], Step [556/735], Loss: 0.0465\n",
      "Epoch [40/50], Step [557/735], Loss: 0.0443\n",
      "Epoch [40/50], Step [558/735], Loss: 0.0832\n",
      "Epoch [40/50], Step [559/735], Loss: 0.1524\n",
      "Epoch [40/50], Step [560/735], Loss: 0.0863\n",
      "Epoch [40/50], Step [561/735], Loss: 0.0698\n",
      "Epoch [40/50], Step [562/735], Loss: 0.1662\n",
      "Epoch [40/50], Step [563/735], Loss: 0.0958\n",
      "Epoch [40/50], Step [564/735], Loss: 0.0346\n",
      "Epoch [40/50], Step [565/735], Loss: 0.0652\n",
      "Epoch [40/50], Step [566/735], Loss: 0.0353\n",
      "Epoch [40/50], Step [567/735], Loss: 0.0624\n",
      "Epoch [40/50], Step [568/735], Loss: 0.1073\n",
      "Epoch [40/50], Step [569/735], Loss: 0.0938\n",
      "Epoch [40/50], Step [570/735], Loss: 0.0321\n",
      "Epoch [40/50], Step [571/735], Loss: 0.0810\n",
      "Epoch [40/50], Step [572/735], Loss: 0.3778\n",
      "Epoch [40/50], Step [573/735], Loss: 0.0907\n",
      "Epoch [40/50], Step [574/735], Loss: 0.0693\n",
      "Epoch [40/50], Step [575/735], Loss: 0.0970\n",
      "Epoch [40/50], Step [576/735], Loss: 0.0594\n",
      "Epoch [40/50], Step [577/735], Loss: 0.1492\n",
      "Epoch [40/50], Step [578/735], Loss: 0.0505\n",
      "Epoch [40/50], Step [579/735], Loss: 0.0510\n",
      "Epoch [40/50], Step [580/735], Loss: 0.4733\n",
      "Epoch [40/50], Step [581/735], Loss: 0.0496\n",
      "Epoch [40/50], Step [582/735], Loss: 1.0082\n",
      "Epoch [40/50], Step [583/735], Loss: 0.1335\n",
      "Epoch [40/50], Step [584/735], Loss: 0.1431\n",
      "Epoch [40/50], Step [585/735], Loss: 0.1119\n",
      "Epoch [40/50], Step [586/735], Loss: 0.1830\n",
      "Epoch [40/50], Step [587/735], Loss: 0.1648\n",
      "Epoch [40/50], Step [588/735], Loss: 0.8340\n",
      "Epoch [40/50], Step [589/735], Loss: 0.0723\n",
      "Epoch [40/50], Step [590/735], Loss: 0.1873\n",
      "Epoch [40/50], Step [591/735], Loss: 0.1226\n",
      "Epoch [40/50], Step [592/735], Loss: 0.0755\n",
      "Epoch [40/50], Step [593/735], Loss: 0.0960\n",
      "Epoch [40/50], Step [594/735], Loss: 0.1479\n",
      "Epoch [40/50], Step [595/735], Loss: 0.1582\n",
      "Epoch [40/50], Step [596/735], Loss: 0.1865\n",
      "Epoch [40/50], Step [597/735], Loss: 0.1160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Step [598/735], Loss: 0.0610\n",
      "Epoch [40/50], Step [599/735], Loss: 0.0739\n",
      "Epoch [40/50], Step [600/735], Loss: 0.3197\n",
      "Epoch [40/50], Step [601/735], Loss: 0.0509\n",
      "Epoch [40/50], Step [602/735], Loss: 0.1553\n",
      "Epoch [40/50], Step [603/735], Loss: 0.0570\n",
      "Epoch [40/50], Step [604/735], Loss: 0.0430\n",
      "Epoch [40/50], Step [605/735], Loss: 0.0714\n",
      "Epoch [40/50], Step [606/735], Loss: 0.4715\n",
      "Epoch [40/50], Step [607/735], Loss: 0.0809\n",
      "Epoch [40/50], Step [608/735], Loss: 0.1348\n",
      "Epoch [40/50], Step [609/735], Loss: 0.0571\n",
      "Epoch [40/50], Step [610/735], Loss: 0.0849\n",
      "Epoch [40/50], Step [611/735], Loss: 0.2250\n",
      "Epoch [40/50], Step [612/735], Loss: 0.0995\n",
      "Epoch [40/50], Step [613/735], Loss: 0.2608\n",
      "Epoch [40/50], Step [614/735], Loss: 0.1072\n",
      "Epoch [40/50], Step [615/735], Loss: 0.1251\n",
      "Epoch [40/50], Step [616/735], Loss: 0.0613\n",
      "Epoch [40/50], Step [617/735], Loss: 0.2068\n",
      "Epoch [40/50], Step [618/735], Loss: 0.0936\n",
      "Epoch [40/50], Step [619/735], Loss: 0.1175\n",
      "Epoch [40/50], Step [620/735], Loss: 0.0474\n",
      "Epoch [40/50], Step [621/735], Loss: 0.1448\n",
      "Epoch [40/50], Step [622/735], Loss: 0.0882\n",
      "Epoch [40/50], Step [623/735], Loss: 0.0848\n",
      "Epoch [40/50], Step [624/735], Loss: 0.0666\n",
      "Epoch [40/50], Step [625/735], Loss: 0.1158\n",
      "Epoch [40/50], Step [626/735], Loss: 0.0338\n",
      "Epoch [40/50], Step [627/735], Loss: 0.0549\n",
      "Epoch [40/50], Step [628/735], Loss: 0.0307\n",
      "Epoch [40/50], Step [629/735], Loss: 0.0429\n",
      "Epoch [40/50], Step [630/735], Loss: 0.1316\n",
      "Epoch [40/50], Step [631/735], Loss: 0.1181\n",
      "Epoch [40/50], Step [632/735], Loss: 0.0553\n",
      "Epoch [40/50], Step [633/735], Loss: 0.1920\n",
      "Epoch [40/50], Step [634/735], Loss: 0.1054\n",
      "Epoch [40/50], Step [635/735], Loss: 0.0725\n",
      "Epoch [40/50], Step [636/735], Loss: 0.1481\n",
      "Epoch [40/50], Step [637/735], Loss: 0.0776\n",
      "Epoch [40/50], Step [638/735], Loss: 0.2052\n",
      "Epoch [40/50], Step [639/735], Loss: 0.1516\n",
      "Epoch [40/50], Step [640/735], Loss: 2.0569\n",
      "Epoch [40/50], Step [641/735], Loss: 0.0452\n",
      "Epoch [40/50], Step [642/735], Loss: 0.3553\n",
      "Epoch [40/50], Step [643/735], Loss: 0.8455\n",
      "Epoch [40/50], Step [644/735], Loss: 0.1003\n",
      "Epoch [40/50], Step [645/735], Loss: 0.0787\n",
      "Epoch [40/50], Step [646/735], Loss: 0.0788\n",
      "Epoch [40/50], Step [647/735], Loss: 0.0834\n",
      "Epoch [40/50], Step [648/735], Loss: 0.1411\n",
      "Epoch [40/50], Step [649/735], Loss: 0.0631\n",
      "Epoch [40/50], Step [650/735], Loss: 0.0597\n",
      "Epoch [40/50], Step [651/735], Loss: 0.0847\n",
      "Epoch [40/50], Step [652/735], Loss: 0.3113\n",
      "Epoch [40/50], Step [653/735], Loss: 0.0471\n",
      "Epoch [40/50], Step [654/735], Loss: 0.0866\n",
      "Epoch [40/50], Step [655/735], Loss: 0.0433\n",
      "Epoch [40/50], Step [656/735], Loss: 0.2061\n",
      "Epoch [40/50], Step [657/735], Loss: 0.1790\n",
      "Epoch [40/50], Step [658/735], Loss: 0.0898\n",
      "Epoch [40/50], Step [659/735], Loss: 0.1185\n",
      "Epoch [40/50], Step [660/735], Loss: 0.1429\n",
      "Epoch [40/50], Step [661/735], Loss: 0.2271\n",
      "Epoch [40/50], Step [662/735], Loss: 0.0552\n",
      "Epoch [40/50], Step [663/735], Loss: 0.1450\n",
      "Epoch [40/50], Step [664/735], Loss: 0.0635\n",
      "Epoch [40/50], Step [665/735], Loss: 0.2148\n",
      "Epoch [40/50], Step [666/735], Loss: 0.2238\n",
      "Epoch [40/50], Step [667/735], Loss: 0.1276\n",
      "Epoch [40/50], Step [668/735], Loss: 0.1494\n",
      "Epoch [40/50], Step [669/735], Loss: 0.3602\n",
      "Epoch [40/50], Step [670/735], Loss: 0.2127\n",
      "Epoch [40/50], Step [671/735], Loss: 0.0937\n",
      "Epoch [40/50], Step [672/735], Loss: 0.0699\n",
      "Epoch [40/50], Step [673/735], Loss: 0.0963\n",
      "Epoch [40/50], Step [674/735], Loss: 0.0428\n",
      "Epoch [40/50], Step [675/735], Loss: 0.0410\n",
      "Epoch [40/50], Step [676/735], Loss: 0.2379\n",
      "Epoch [40/50], Step [677/735], Loss: 0.0594\n",
      "Epoch [40/50], Step [678/735], Loss: 0.0534\n",
      "Epoch [40/50], Step [679/735], Loss: 0.0980\n",
      "Epoch [40/50], Step [680/735], Loss: 0.0623\n",
      "Epoch [40/50], Step [681/735], Loss: 0.0659\n",
      "Epoch [40/50], Step [682/735], Loss: 0.1148\n",
      "Epoch [40/50], Step [683/735], Loss: 0.2473\n",
      "Epoch [40/50], Step [684/735], Loss: 0.1120\n",
      "Epoch [40/50], Step [685/735], Loss: 0.0836\n",
      "Epoch [40/50], Step [686/735], Loss: 0.1575\n",
      "Epoch [40/50], Step [687/735], Loss: 0.0381\n",
      "Epoch [40/50], Step [688/735], Loss: 0.0559\n",
      "Epoch [40/50], Step [689/735], Loss: 0.1061\n",
      "Epoch [40/50], Step [690/735], Loss: 0.0727\n",
      "Epoch [40/50], Step [691/735], Loss: 0.0645\n",
      "Epoch [40/50], Step [692/735], Loss: 0.1810\n",
      "Epoch [40/50], Step [693/735], Loss: 0.1459\n",
      "Epoch [40/50], Step [694/735], Loss: 0.0274\n",
      "Epoch [40/50], Step [695/735], Loss: 0.0984\n",
      "Epoch [40/50], Step [696/735], Loss: 1.5790\n",
      "Epoch [40/50], Step [697/735], Loss: 0.4819\n",
      "Epoch [40/50], Step [698/735], Loss: 0.0614\n",
      "Epoch [40/50], Step [699/735], Loss: 0.1879\n",
      "Epoch [40/50], Step [700/735], Loss: 0.0846\n",
      "Epoch [40/50], Step [701/735], Loss: 0.1310\n",
      "Epoch [40/50], Step [702/735], Loss: 0.1013\n",
      "Epoch [40/50], Step [703/735], Loss: 0.3411\n",
      "Epoch [40/50], Step [704/735], Loss: 0.3127\n",
      "Epoch [40/50], Step [705/735], Loss: 0.0666\n",
      "Epoch [40/50], Step [706/735], Loss: 0.1591\n",
      "Epoch [40/50], Step [707/735], Loss: 0.2735\n",
      "Epoch [40/50], Step [708/735], Loss: 0.1882\n",
      "Epoch [40/50], Step [709/735], Loss: 0.1106\n",
      "Epoch [40/50], Step [710/735], Loss: 0.0342\n",
      "Epoch [40/50], Step [711/735], Loss: 0.1531\n",
      "Epoch [40/50], Step [712/735], Loss: 0.1356\n",
      "Epoch [40/50], Step [713/735], Loss: 0.0986\n",
      "Epoch [40/50], Step [714/735], Loss: 0.1300\n",
      "Epoch [40/50], Step [715/735], Loss: 0.1499\n",
      "Epoch [40/50], Step [716/735], Loss: 0.0769\n",
      "Epoch [40/50], Step [717/735], Loss: 0.0496\n",
      "Epoch [40/50], Step [718/735], Loss: 0.1477\n",
      "Epoch [40/50], Step [719/735], Loss: 0.1135\n",
      "Epoch [40/50], Step [720/735], Loss: 0.0584\n",
      "Epoch [40/50], Step [721/735], Loss: 0.0655\n",
      "Epoch [40/50], Step [722/735], Loss: 0.0669\n",
      "Epoch [40/50], Step [723/735], Loss: 0.1112\n",
      "Epoch [40/50], Step [724/735], Loss: 0.1552\n",
      "Epoch [40/50], Step [725/735], Loss: 0.2262\n",
      "Epoch [40/50], Step [726/735], Loss: 0.0777\n",
      "Epoch [40/50], Step [727/735], Loss: 0.0958\n",
      "Epoch [40/50], Step [728/735], Loss: 0.0526\n",
      "Epoch [40/50], Step [729/735], Loss: 0.1669\n",
      "Epoch [40/50], Step [730/735], Loss: 0.0913\n",
      "Epoch [40/50], Step [731/735], Loss: 0.1354\n",
      "Epoch [40/50], Step [732/735], Loss: 0.0633\n",
      "Epoch [40/50], Step [733/735], Loss: 0.1902\n",
      "Epoch [40/50], Step [734/735], Loss: 0.1340\n",
      "Epoch [40/50], Step [735/735], Loss: 0.1008\n",
      "Epoch [41/50], Step [1/735], Loss: 0.0599\n",
      "Epoch [41/50], Step [2/735], Loss: 0.2459\n",
      "Epoch [41/50], Step [3/735], Loss: 0.0815\n",
      "Epoch [41/50], Step [4/735], Loss: 0.0969\n",
      "Epoch [41/50], Step [5/735], Loss: 0.0726\n",
      "Epoch [41/50], Step [6/735], Loss: 0.1795\n",
      "Epoch [41/50], Step [7/735], Loss: 0.6212\n",
      "Epoch [41/50], Step [8/735], Loss: 0.1504\n",
      "Epoch [41/50], Step [9/735], Loss: 0.1252\n",
      "Epoch [41/50], Step [10/735], Loss: 0.1560\n",
      "Epoch [41/50], Step [11/735], Loss: 0.1077\n",
      "Epoch [41/50], Step [12/735], Loss: 0.0829\n",
      "Epoch [41/50], Step [13/735], Loss: 0.1080\n",
      "Epoch [41/50], Step [14/735], Loss: 0.1706\n",
      "Epoch [41/50], Step [15/735], Loss: 0.0841\n",
      "Epoch [41/50], Step [16/735], Loss: 0.1477\n",
      "Epoch [41/50], Step [17/735], Loss: 0.0460\n",
      "Epoch [41/50], Step [18/735], Loss: 0.3855\n",
      "Epoch [41/50], Step [19/735], Loss: 0.0848\n",
      "Epoch [41/50], Step [20/735], Loss: 0.1457\n",
      "Epoch [41/50], Step [21/735], Loss: 0.0545\n",
      "Epoch [41/50], Step [22/735], Loss: 0.2308\n",
      "Epoch [41/50], Step [23/735], Loss: 0.0637\n",
      "Epoch [41/50], Step [24/735], Loss: 0.0862\n",
      "Epoch [41/50], Step [25/735], Loss: 0.0667\n",
      "Epoch [41/50], Step [26/735], Loss: 0.1032\n",
      "Epoch [41/50], Step [27/735], Loss: 0.1017\n",
      "Epoch [41/50], Step [28/735], Loss: 0.1029\n",
      "Epoch [41/50], Step [29/735], Loss: 0.0727\n",
      "Epoch [41/50], Step [30/735], Loss: 0.1809\n",
      "Epoch [41/50], Step [31/735], Loss: 0.0878\n",
      "Epoch [41/50], Step [32/735], Loss: 0.1076\n",
      "Epoch [41/50], Step [33/735], Loss: 0.2032\n",
      "Epoch [41/50], Step [34/735], Loss: 0.1284\n",
      "Epoch [41/50], Step [35/735], Loss: 0.0818\n",
      "Epoch [41/50], Step [36/735], Loss: 0.1378\n",
      "Epoch [41/50], Step [37/735], Loss: 0.1277\n",
      "Epoch [41/50], Step [38/735], Loss: 0.0523\n",
      "Epoch [41/50], Step [39/735], Loss: 0.1587\n",
      "Epoch [41/50], Step [40/735], Loss: 0.0988\n",
      "Epoch [41/50], Step [41/735], Loss: 0.1538\n",
      "Epoch [41/50], Step [42/735], Loss: 0.1108\n",
      "Epoch [41/50], Step [43/735], Loss: 0.1022\n",
      "Epoch [41/50], Step [44/735], Loss: 0.1525\n",
      "Epoch [41/50], Step [45/735], Loss: 0.0661\n",
      "Epoch [41/50], Step [46/735], Loss: 0.0373\n",
      "Epoch [41/50], Step [47/735], Loss: 0.0463\n",
      "Epoch [41/50], Step [48/735], Loss: 0.0651\n",
      "Epoch [41/50], Step [49/735], Loss: 2.3096\n",
      "Epoch [41/50], Step [50/735], Loss: 0.0392\n",
      "Epoch [41/50], Step [51/735], Loss: 0.0648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Step [52/735], Loss: 0.0712\n",
      "Epoch [41/50], Step [53/735], Loss: 0.1584\n",
      "Epoch [41/50], Step [54/735], Loss: 0.0857\n",
      "Epoch [41/50], Step [55/735], Loss: 0.1279\n",
      "Epoch [41/50], Step [56/735], Loss: 0.1108\n",
      "Epoch [41/50], Step [57/735], Loss: 0.0699\n",
      "Epoch [41/50], Step [58/735], Loss: 0.0626\n",
      "Epoch [41/50], Step [59/735], Loss: 0.1186\n",
      "Epoch [41/50], Step [60/735], Loss: 0.0331\n",
      "Epoch [41/50], Step [61/735], Loss: 0.1384\n",
      "Epoch [41/50], Step [62/735], Loss: 0.1634\n",
      "Epoch [41/50], Step [63/735], Loss: 0.1395\n",
      "Epoch [41/50], Step [64/735], Loss: 0.0821\n",
      "Epoch [41/50], Step [65/735], Loss: 0.0791\n",
      "Epoch [41/50], Step [66/735], Loss: 0.1265\n",
      "Epoch [41/50], Step [67/735], Loss: 0.0748\n",
      "Epoch [41/50], Step [68/735], Loss: 0.0697\n",
      "Epoch [41/50], Step [69/735], Loss: 0.1371\n",
      "Epoch [41/50], Step [70/735], Loss: 0.0975\n",
      "Epoch [41/50], Step [71/735], Loss: 0.0947\n",
      "Epoch [41/50], Step [72/735], Loss: 0.0506\n",
      "Epoch [41/50], Step [73/735], Loss: 0.1557\n",
      "Epoch [41/50], Step [74/735], Loss: 0.1442\n",
      "Epoch [41/50], Step [75/735], Loss: 0.0745\n",
      "Epoch [41/50], Step [76/735], Loss: 0.1459\n",
      "Epoch [41/50], Step [77/735], Loss: 0.1262\n",
      "Epoch [41/50], Step [78/735], Loss: 0.0493\n",
      "Epoch [41/50], Step [79/735], Loss: 0.3367\n",
      "Epoch [41/50], Step [80/735], Loss: 0.0878\n",
      "Epoch [41/50], Step [81/735], Loss: 0.0631\n",
      "Epoch [41/50], Step [82/735], Loss: 0.0645\n",
      "Epoch [41/50], Step [83/735], Loss: 0.1343\n",
      "Epoch [41/50], Step [84/735], Loss: 0.1197\n",
      "Epoch [41/50], Step [85/735], Loss: 0.1750\n",
      "Epoch [41/50], Step [86/735], Loss: 0.0554\n",
      "Epoch [41/50], Step [87/735], Loss: 0.1540\n",
      "Epoch [41/50], Step [88/735], Loss: 0.0531\n",
      "Epoch [41/50], Step [89/735], Loss: 0.0406\n",
      "Epoch [41/50], Step [90/735], Loss: 0.0567\n",
      "Epoch [41/50], Step [91/735], Loss: 0.0286\n",
      "Epoch [41/50], Step [92/735], Loss: 0.0967\n",
      "Epoch [41/50], Step [93/735], Loss: 0.0816\n",
      "Epoch [41/50], Step [94/735], Loss: 0.6482\n",
      "Epoch [41/50], Step [95/735], Loss: 0.0769\n",
      "Epoch [41/50], Step [96/735], Loss: 0.0596\n",
      "Epoch [41/50], Step [97/735], Loss: 0.1258\n",
      "Epoch [41/50], Step [98/735], Loss: 0.0294\n",
      "Epoch [41/50], Step [99/735], Loss: 1.3008\n",
      "Epoch [41/50], Step [100/735], Loss: 0.1569\n",
      "Epoch [41/50], Step [101/735], Loss: 0.0322\n",
      "Epoch [41/50], Step [102/735], Loss: 0.0484\n",
      "Epoch [41/50], Step [103/735], Loss: 0.0496\n",
      "Epoch [41/50], Step [104/735], Loss: 0.0978\n",
      "Epoch [41/50], Step [105/735], Loss: 0.4954\n",
      "Epoch [41/50], Step [106/735], Loss: 0.2198\n",
      "Epoch [41/50], Step [107/735], Loss: 0.0482\n",
      "Epoch [41/50], Step [108/735], Loss: 0.1291\n",
      "Epoch [41/50], Step [109/735], Loss: 0.0816\n",
      "Epoch [41/50], Step [110/735], Loss: 0.1069\n",
      "Epoch [41/50], Step [111/735], Loss: 0.0750\n",
      "Epoch [41/50], Step [112/735], Loss: 0.0852\n",
      "Epoch [41/50], Step [113/735], Loss: 0.0831\n",
      "Epoch [41/50], Step [114/735], Loss: 0.1417\n",
      "Epoch [41/50], Step [115/735], Loss: 0.1318\n",
      "Epoch [41/50], Step [116/735], Loss: 0.0393\n",
      "Epoch [41/50], Step [117/735], Loss: 0.0647\n",
      "Epoch [41/50], Step [118/735], Loss: 0.0489\n",
      "Epoch [41/50], Step [119/735], Loss: 0.0874\n",
      "Epoch [41/50], Step [120/735], Loss: 0.1191\n",
      "Epoch [41/50], Step [121/735], Loss: 0.0178\n",
      "Epoch [41/50], Step [122/735], Loss: 0.2046\n",
      "Epoch [41/50], Step [123/735], Loss: 0.0921\n",
      "Epoch [41/50], Step [124/735], Loss: 0.0736\n",
      "Epoch [41/50], Step [125/735], Loss: 0.1464\n",
      "Epoch [41/50], Step [126/735], Loss: 0.6693\n",
      "Epoch [41/50], Step [127/735], Loss: 0.0737\n",
      "Epoch [41/50], Step [128/735], Loss: 0.0680\n",
      "Epoch [41/50], Step [129/735], Loss: 0.0321\n",
      "Epoch [41/50], Step [130/735], Loss: 0.0561\n",
      "Epoch [41/50], Step [131/735], Loss: 0.1965\n",
      "Epoch [41/50], Step [132/735], Loss: 0.0645\n",
      "Epoch [41/50], Step [133/735], Loss: 0.0614\n",
      "Epoch [41/50], Step [134/735], Loss: 0.0666\n",
      "Epoch [41/50], Step [135/735], Loss: 0.1137\n",
      "Epoch [41/50], Step [136/735], Loss: 0.2653\n",
      "Epoch [41/50], Step [137/735], Loss: 0.0914\n",
      "Epoch [41/50], Step [138/735], Loss: 0.0635\n",
      "Epoch [41/50], Step [139/735], Loss: 0.0353\n",
      "Epoch [41/50], Step [140/735], Loss: 0.0984\n",
      "Epoch [41/50], Step [141/735], Loss: 1.4784\n",
      "Epoch [41/50], Step [142/735], Loss: 0.3317\n",
      "Epoch [41/50], Step [143/735], Loss: 0.1164\n",
      "Epoch [41/50], Step [144/735], Loss: 0.0369\n",
      "Epoch [41/50], Step [145/735], Loss: 0.0838\n",
      "Epoch [41/50], Step [146/735], Loss: 0.0590\n",
      "Epoch [41/50], Step [147/735], Loss: 0.1302\n",
      "Epoch [41/50], Step [148/735], Loss: 0.0923\n",
      "Epoch [41/50], Step [149/735], Loss: 0.1715\n",
      "Epoch [41/50], Step [150/735], Loss: 0.0806\n",
      "Epoch [41/50], Step [151/735], Loss: 0.0983\n",
      "Epoch [41/50], Step [152/735], Loss: 0.0480\n",
      "Epoch [41/50], Step [153/735], Loss: 0.0600\n",
      "Epoch [41/50], Step [154/735], Loss: 0.0502\n",
      "Epoch [41/50], Step [155/735], Loss: 0.0534\n",
      "Epoch [41/50], Step [156/735], Loss: 0.0626\n",
      "Epoch [41/50], Step [157/735], Loss: 0.4068\n",
      "Epoch [41/50], Step [158/735], Loss: 0.0527\n",
      "Epoch [41/50], Step [159/735], Loss: 0.0709\n",
      "Epoch [41/50], Step [160/735], Loss: 0.1015\n",
      "Epoch [41/50], Step [161/735], Loss: 0.1017\n",
      "Epoch [41/50], Step [162/735], Loss: 0.0394\n",
      "Epoch [41/50], Step [163/735], Loss: 0.0364\n",
      "Epoch [41/50], Step [164/735], Loss: 0.0679\n",
      "Epoch [41/50], Step [165/735], Loss: 0.1303\n",
      "Epoch [41/50], Step [166/735], Loss: 0.0661\n",
      "Epoch [41/50], Step [167/735], Loss: 0.3298\n",
      "Epoch [41/50], Step [168/735], Loss: 0.0806\n",
      "Epoch [41/50], Step [169/735], Loss: 0.0677\n",
      "Epoch [41/50], Step [170/735], Loss: 0.0994\n",
      "Epoch [41/50], Step [171/735], Loss: 0.0743\n",
      "Epoch [41/50], Step [172/735], Loss: 0.1282\n",
      "Epoch [41/50], Step [173/735], Loss: 0.1139\n",
      "Epoch [41/50], Step [174/735], Loss: 0.0700\n",
      "Epoch [41/50], Step [175/735], Loss: 0.5142\n",
      "Epoch [41/50], Step [176/735], Loss: 0.1343\n",
      "Epoch [41/50], Step [177/735], Loss: 0.0773\n",
      "Epoch [41/50], Step [178/735], Loss: 0.2149\n",
      "Epoch [41/50], Step [179/735], Loss: 0.0255\n",
      "Epoch [41/50], Step [180/735], Loss: 0.1032\n",
      "Epoch [41/50], Step [181/735], Loss: 0.0435\n",
      "Epoch [41/50], Step [182/735], Loss: 0.0922\n",
      "Epoch [41/50], Step [183/735], Loss: 0.0379\n",
      "Epoch [41/50], Step [184/735], Loss: 0.0477\n",
      "Epoch [41/50], Step [185/735], Loss: 0.0479\n",
      "Epoch [41/50], Step [186/735], Loss: 0.1253\n",
      "Epoch [41/50], Step [187/735], Loss: 0.0426\n",
      "Epoch [41/50], Step [188/735], Loss: 0.1070\n",
      "Epoch [41/50], Step [189/735], Loss: 0.0360\n",
      "Epoch [41/50], Step [190/735], Loss: 0.2466\n",
      "Epoch [41/50], Step [191/735], Loss: 0.2997\n",
      "Epoch [41/50], Step [192/735], Loss: 0.0757\n",
      "Epoch [41/50], Step [193/735], Loss: 0.1353\n",
      "Epoch [41/50], Step [194/735], Loss: 0.1479\n",
      "Epoch [41/50], Step [195/735], Loss: 0.2463\n",
      "Epoch [41/50], Step [196/735], Loss: 0.0730\n",
      "Epoch [41/50], Step [197/735], Loss: 0.1149\n",
      "Epoch [41/50], Step [198/735], Loss: 0.0565\n",
      "Epoch [41/50], Step [199/735], Loss: 0.0882\n",
      "Epoch [41/50], Step [200/735], Loss: 0.0985\n",
      "Epoch [41/50], Step [201/735], Loss: 1.0743\n",
      "Epoch [41/50], Step [202/735], Loss: 0.1742\n",
      "Epoch [41/50], Step [203/735], Loss: 0.3446\n",
      "Epoch [41/50], Step [204/735], Loss: 0.1188\n",
      "Epoch [41/50], Step [205/735], Loss: 0.0676\n",
      "Epoch [41/50], Step [206/735], Loss: 0.1014\n",
      "Epoch [41/50], Step [207/735], Loss: 0.0485\n",
      "Epoch [41/50], Step [208/735], Loss: 0.1042\n",
      "Epoch [41/50], Step [209/735], Loss: 0.0432\n",
      "Epoch [41/50], Step [210/735], Loss: 0.1335\n",
      "Epoch [41/50], Step [211/735], Loss: 0.0915\n",
      "Epoch [41/50], Step [212/735], Loss: 0.2621\n",
      "Epoch [41/50], Step [213/735], Loss: 0.0758\n",
      "Epoch [41/50], Step [214/735], Loss: 0.1078\n",
      "Epoch [41/50], Step [215/735], Loss: 0.3853\n",
      "Epoch [41/50], Step [216/735], Loss: 0.0738\n",
      "Epoch [41/50], Step [217/735], Loss: 0.1115\n",
      "Epoch [41/50], Step [218/735], Loss: 0.1918\n",
      "Epoch [41/50], Step [219/735], Loss: 0.0938\n",
      "Epoch [41/50], Step [220/735], Loss: 0.0547\n",
      "Epoch [41/50], Step [221/735], Loss: 0.1243\n",
      "Epoch [41/50], Step [222/735], Loss: 0.0347\n",
      "Epoch [41/50], Step [223/735], Loss: 0.0475\n",
      "Epoch [41/50], Step [224/735], Loss: 0.2041\n",
      "Epoch [41/50], Step [225/735], Loss: 1.4206\n",
      "Epoch [41/50], Step [226/735], Loss: 0.0466\n",
      "Epoch [41/50], Step [227/735], Loss: 0.0746\n",
      "Epoch [41/50], Step [228/735], Loss: 0.1074\n",
      "Epoch [41/50], Step [229/735], Loss: 0.0530\n",
      "Epoch [41/50], Step [230/735], Loss: 0.0760\n",
      "Epoch [41/50], Step [231/735], Loss: 0.1862\n",
      "Epoch [41/50], Step [232/735], Loss: 0.1516\n",
      "Epoch [41/50], Step [233/735], Loss: 0.0788\n",
      "Epoch [41/50], Step [234/735], Loss: 0.1324\n",
      "Epoch [41/50], Step [235/735], Loss: 0.1523\n",
      "Epoch [41/50], Step [236/735], Loss: 0.1616\n",
      "Epoch [41/50], Step [237/735], Loss: 0.0571\n",
      "Epoch [41/50], Step [238/735], Loss: 0.0689\n",
      "Epoch [41/50], Step [239/735], Loss: 0.0970\n",
      "Epoch [41/50], Step [240/735], Loss: 0.1692\n",
      "Epoch [41/50], Step [241/735], Loss: 0.0899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Step [242/735], Loss: 0.2506\n",
      "Epoch [41/50], Step [243/735], Loss: 0.1467\n",
      "Epoch [41/50], Step [244/735], Loss: 0.1183\n",
      "Epoch [41/50], Step [245/735], Loss: 0.1318\n",
      "Epoch [41/50], Step [246/735], Loss: 0.4662\n",
      "Epoch [41/50], Step [247/735], Loss: 0.1957\n",
      "Epoch [41/50], Step [248/735], Loss: 0.0737\n",
      "Epoch [41/50], Step [249/735], Loss: 0.0579\n",
      "Epoch [41/50], Step [250/735], Loss: 0.0373\n",
      "Epoch [41/50], Step [251/735], Loss: 0.6528\n",
      "Epoch [41/50], Step [252/735], Loss: 0.0833\n",
      "Epoch [41/50], Step [253/735], Loss: 0.1150\n",
      "Epoch [41/50], Step [254/735], Loss: 0.0770\n",
      "Epoch [41/50], Step [255/735], Loss: 0.2681\n",
      "Epoch [41/50], Step [256/735], Loss: 0.0444\n",
      "Epoch [41/50], Step [257/735], Loss: 0.2877\n",
      "Epoch [41/50], Step [258/735], Loss: 0.0546\n",
      "Epoch [41/50], Step [259/735], Loss: 0.0958\n",
      "Epoch [41/50], Step [260/735], Loss: 0.2031\n",
      "Epoch [41/50], Step [261/735], Loss: 0.0801\n",
      "Epoch [41/50], Step [262/735], Loss: 0.0697\n",
      "Epoch [41/50], Step [263/735], Loss: 0.0513\n",
      "Epoch [41/50], Step [264/735], Loss: 0.1655\n",
      "Epoch [41/50], Step [265/735], Loss: 1.4339\n",
      "Epoch [41/50], Step [266/735], Loss: 0.0433\n",
      "Epoch [41/50], Step [267/735], Loss: 0.0641\n",
      "Epoch [41/50], Step [268/735], Loss: 0.1822\n",
      "Epoch [41/50], Step [269/735], Loss: 0.0927\n",
      "Epoch [41/50], Step [270/735], Loss: 0.4612\n",
      "Epoch [41/50], Step [271/735], Loss: 0.1147\n",
      "Epoch [41/50], Step [272/735], Loss: 0.0802\n",
      "Epoch [41/50], Step [273/735], Loss: 0.0546\n",
      "Epoch [41/50], Step [274/735], Loss: 0.0894\n",
      "Epoch [41/50], Step [275/735], Loss: 0.0797\n",
      "Epoch [41/50], Step [276/735], Loss: 0.2082\n",
      "Epoch [41/50], Step [277/735], Loss: 0.0899\n",
      "Epoch [41/50], Step [278/735], Loss: 0.0982\n",
      "Epoch [41/50], Step [279/735], Loss: 0.1779\n",
      "Epoch [41/50], Step [280/735], Loss: 0.1516\n",
      "Epoch [41/50], Step [281/735], Loss: 0.1260\n",
      "Epoch [41/50], Step [282/735], Loss: 0.1042\n",
      "Epoch [41/50], Step [283/735], Loss: 1.4786\n",
      "Epoch [41/50], Step [284/735], Loss: 0.1383\n",
      "Epoch [41/50], Step [285/735], Loss: 0.0785\n",
      "Epoch [41/50], Step [286/735], Loss: 0.1139\n",
      "Epoch [41/50], Step [287/735], Loss: 0.0822\n",
      "Epoch [41/50], Step [288/735], Loss: 0.0900\n",
      "Epoch [41/50], Step [289/735], Loss: 0.1081\n",
      "Epoch [41/50], Step [290/735], Loss: 0.0654\n",
      "Epoch [41/50], Step [291/735], Loss: 0.0629\n",
      "Epoch [41/50], Step [292/735], Loss: 0.1059\n",
      "Epoch [41/50], Step [293/735], Loss: 0.1118\n",
      "Epoch [41/50], Step [294/735], Loss: 0.0448\n",
      "Epoch [41/50], Step [295/735], Loss: 0.1219\n",
      "Epoch [41/50], Step [296/735], Loss: 0.0507\n",
      "Epoch [41/50], Step [297/735], Loss: 0.6702\n",
      "Epoch [41/50], Step [298/735], Loss: 0.0762\n",
      "Epoch [41/50], Step [299/735], Loss: 0.3489\n",
      "Epoch [41/50], Step [300/735], Loss: 0.0634\n",
      "Epoch [41/50], Step [301/735], Loss: 0.1452\n",
      "Epoch [41/50], Step [302/735], Loss: 0.0947\n",
      "Epoch [41/50], Step [303/735], Loss: 0.2342\n",
      "Epoch [41/50], Step [304/735], Loss: 0.4576\n",
      "Epoch [41/50], Step [305/735], Loss: 0.0379\n",
      "Epoch [41/50], Step [306/735], Loss: 0.1504\n",
      "Epoch [41/50], Step [307/735], Loss: 0.1813\n",
      "Epoch [41/50], Step [308/735], Loss: 0.0893\n",
      "Epoch [41/50], Step [309/735], Loss: 0.0353\n",
      "Epoch [41/50], Step [310/735], Loss: 0.0966\n",
      "Epoch [41/50], Step [311/735], Loss: 0.1457\n",
      "Epoch [41/50], Step [312/735], Loss: 0.2352\n",
      "Epoch [41/50], Step [313/735], Loss: 0.2634\n",
      "Epoch [41/50], Step [314/735], Loss: 0.1261\n",
      "Epoch [41/50], Step [315/735], Loss: 0.1940\n",
      "Epoch [41/50], Step [316/735], Loss: 0.0327\n",
      "Epoch [41/50], Step [317/735], Loss: 0.0615\n",
      "Epoch [41/50], Step [318/735], Loss: 0.1695\n",
      "Epoch [41/50], Step [319/735], Loss: 0.1131\n",
      "Epoch [41/50], Step [320/735], Loss: 0.1207\n",
      "Epoch [41/50], Step [321/735], Loss: 0.3248\n",
      "Epoch [41/50], Step [322/735], Loss: 0.0792\n",
      "Epoch [41/50], Step [323/735], Loss: 0.0485\n",
      "Epoch [41/50], Step [324/735], Loss: 0.1035\n",
      "Epoch [41/50], Step [325/735], Loss: 0.1670\n",
      "Epoch [41/50], Step [326/735], Loss: 0.0778\n",
      "Epoch [41/50], Step [327/735], Loss: 0.0957\n",
      "Epoch [41/50], Step [328/735], Loss: 0.1353\n",
      "Epoch [41/50], Step [329/735], Loss: 0.0874\n",
      "Epoch [41/50], Step [330/735], Loss: 0.1018\n",
      "Epoch [41/50], Step [331/735], Loss: 0.1458\n",
      "Epoch [41/50], Step [332/735], Loss: 0.1386\n",
      "Epoch [41/50], Step [333/735], Loss: 0.1009\n",
      "Epoch [41/50], Step [334/735], Loss: 0.0485\n",
      "Epoch [41/50], Step [335/735], Loss: 0.0657\n",
      "Epoch [41/50], Step [336/735], Loss: 0.1237\n",
      "Epoch [41/50], Step [337/735], Loss: 0.1297\n",
      "Epoch [41/50], Step [338/735], Loss: 0.7411\n",
      "Epoch [41/50], Step [339/735], Loss: 0.1068\n",
      "Epoch [41/50], Step [340/735], Loss: 0.2011\n",
      "Epoch [41/50], Step [341/735], Loss: 0.0251\n",
      "Epoch [41/50], Step [342/735], Loss: 0.0462\n",
      "Epoch [41/50], Step [343/735], Loss: 0.1006\n",
      "Epoch [41/50], Step [344/735], Loss: 0.0604\n",
      "Epoch [41/50], Step [345/735], Loss: 0.1367\n",
      "Epoch [41/50], Step [346/735], Loss: 0.3945\n",
      "Epoch [41/50], Step [347/735], Loss: 0.1132\n",
      "Epoch [41/50], Step [348/735], Loss: 0.0421\n",
      "Epoch [41/50], Step [349/735], Loss: 0.1028\n",
      "Epoch [41/50], Step [350/735], Loss: 0.1430\n",
      "Epoch [41/50], Step [351/735], Loss: 0.2509\n",
      "Epoch [41/50], Step [352/735], Loss: 0.0503\n",
      "Epoch [41/50], Step [353/735], Loss: 0.0751\n",
      "Epoch [41/50], Step [354/735], Loss: 0.0595\n",
      "Epoch [41/50], Step [355/735], Loss: 0.2007\n",
      "Epoch [41/50], Step [356/735], Loss: 0.0830\n",
      "Epoch [41/50], Step [357/735], Loss: 0.1084\n",
      "Epoch [41/50], Step [358/735], Loss: 0.0756\n",
      "Epoch [41/50], Step [359/735], Loss: 0.0407\n",
      "Epoch [41/50], Step [360/735], Loss: 0.1056\n",
      "Epoch [41/50], Step [361/735], Loss: 0.1027\n",
      "Epoch [41/50], Step [362/735], Loss: 0.0834\n",
      "Epoch [41/50], Step [363/735], Loss: 0.0597\n",
      "Epoch [41/50], Step [364/735], Loss: 0.0741\n",
      "Epoch [41/50], Step [365/735], Loss: 0.1365\n",
      "Epoch [41/50], Step [366/735], Loss: 0.4744\n",
      "Epoch [41/50], Step [367/735], Loss: 0.0682\n",
      "Epoch [41/50], Step [368/735], Loss: 0.1775\n",
      "Epoch [41/50], Step [369/735], Loss: 0.1151\n",
      "Epoch [41/50], Step [370/735], Loss: 0.0586\n",
      "Epoch [41/50], Step [371/735], Loss: 0.0671\n",
      "Epoch [41/50], Step [372/735], Loss: 0.1048\n",
      "Epoch [41/50], Step [373/735], Loss: 0.0975\n",
      "Epoch [41/50], Step [374/735], Loss: 0.0776\n",
      "Epoch [41/50], Step [375/735], Loss: 0.0901\n",
      "Epoch [41/50], Step [376/735], Loss: 0.0749\n",
      "Epoch [41/50], Step [377/735], Loss: 0.0814\n",
      "Epoch [41/50], Step [378/735], Loss: 0.0397\n",
      "Epoch [41/50], Step [379/735], Loss: 0.0679\n",
      "Epoch [41/50], Step [380/735], Loss: 0.0401\n",
      "Epoch [41/50], Step [381/735], Loss: 0.0406\n",
      "Epoch [41/50], Step [382/735], Loss: 0.0522\n",
      "Epoch [41/50], Step [383/735], Loss: 0.0485\n",
      "Epoch [41/50], Step [384/735], Loss: 0.1348\n",
      "Epoch [41/50], Step [385/735], Loss: 0.0880\n",
      "Epoch [41/50], Step [386/735], Loss: 0.2676\n",
      "Epoch [41/50], Step [387/735], Loss: 0.0485\n",
      "Epoch [41/50], Step [388/735], Loss: 0.0552\n",
      "Epoch [41/50], Step [389/735], Loss: 0.1714\n",
      "Epoch [41/50], Step [390/735], Loss: 0.0482\n",
      "Epoch [41/50], Step [391/735], Loss: 0.1129\n",
      "Epoch [41/50], Step [392/735], Loss: 0.1088\n",
      "Epoch [41/50], Step [393/735], Loss: 0.1187\n",
      "Epoch [41/50], Step [394/735], Loss: 0.0730\n",
      "Epoch [41/50], Step [395/735], Loss: 0.2080\n",
      "Epoch [41/50], Step [396/735], Loss: 0.0378\n",
      "Epoch [41/50], Step [397/735], Loss: 0.1138\n",
      "Epoch [41/50], Step [398/735], Loss: 0.0446\n",
      "Epoch [41/50], Step [399/735], Loss: 0.0850\n",
      "Epoch [41/50], Step [400/735], Loss: 0.1357\n",
      "Epoch [41/50], Step [401/735], Loss: 0.1593\n",
      "Epoch [41/50], Step [402/735], Loss: 0.0736\n",
      "Epoch [41/50], Step [403/735], Loss: 0.0914\n",
      "Epoch [41/50], Step [404/735], Loss: 0.1098\n",
      "Epoch [41/50], Step [405/735], Loss: 0.0694\n",
      "Epoch [41/50], Step [406/735], Loss: 0.1594\n",
      "Epoch [41/50], Step [407/735], Loss: 0.1108\n",
      "Epoch [41/50], Step [408/735], Loss: 0.1011\n",
      "Epoch [41/50], Step [409/735], Loss: 0.0684\n",
      "Epoch [41/50], Step [410/735], Loss: 0.0912\n",
      "Epoch [41/50], Step [411/735], Loss: 0.0640\n",
      "Epoch [41/50], Step [412/735], Loss: 0.0830\n",
      "Epoch [41/50], Step [413/735], Loss: 0.2090\n",
      "Epoch [41/50], Step [414/735], Loss: 0.0791\n",
      "Epoch [41/50], Step [415/735], Loss: 0.0630\n",
      "Epoch [41/50], Step [416/735], Loss: 0.0415\n",
      "Epoch [41/50], Step [417/735], Loss: 0.1177\n",
      "Epoch [41/50], Step [418/735], Loss: 0.0318\n",
      "Epoch [41/50], Step [419/735], Loss: 0.0661\n",
      "Epoch [41/50], Step [420/735], Loss: 0.0588\n",
      "Epoch [41/50], Step [421/735], Loss: 0.1106\n",
      "Epoch [41/50], Step [422/735], Loss: 0.1141\n",
      "Epoch [41/50], Step [423/735], Loss: 1.7042\n",
      "Epoch [41/50], Step [424/735], Loss: 0.0766\n",
      "Epoch [41/50], Step [425/735], Loss: 0.0449\n",
      "Epoch [41/50], Step [426/735], Loss: 0.0319\n",
      "Epoch [41/50], Step [427/735], Loss: 0.1731\n",
      "Epoch [41/50], Step [428/735], Loss: 0.0758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Step [429/735], Loss: 0.0538\n",
      "Epoch [41/50], Step [430/735], Loss: 0.0813\n",
      "Epoch [41/50], Step [431/735], Loss: 0.1654\n",
      "Epoch [41/50], Step [432/735], Loss: 0.0914\n",
      "Epoch [41/50], Step [433/735], Loss: 0.0883\n",
      "Epoch [41/50], Step [434/735], Loss: 0.2538\n",
      "Epoch [41/50], Step [435/735], Loss: 0.1322\n",
      "Epoch [41/50], Step [436/735], Loss: 0.0334\n",
      "Epoch [41/50], Step [437/735], Loss: 0.7513\n",
      "Epoch [41/50], Step [438/735], Loss: 0.1347\n",
      "Epoch [41/50], Step [439/735], Loss: 0.0478\n",
      "Epoch [41/50], Step [440/735], Loss: 0.0891\n",
      "Epoch [41/50], Step [441/735], Loss: 0.0823\n",
      "Epoch [41/50], Step [442/735], Loss: 0.0554\n",
      "Epoch [41/50], Step [443/735], Loss: 0.1470\n",
      "Epoch [41/50], Step [444/735], Loss: 0.2302\n",
      "Epoch [41/50], Step [445/735], Loss: 0.1975\n",
      "Epoch [41/50], Step [446/735], Loss: 0.5213\n",
      "Epoch [41/50], Step [447/735], Loss: 0.1163\n",
      "Epoch [41/50], Step [448/735], Loss: 0.2392\n",
      "Epoch [41/50], Step [449/735], Loss: 0.0857\n",
      "Epoch [41/50], Step [450/735], Loss: 0.0804\n",
      "Epoch [41/50], Step [451/735], Loss: 0.1152\n",
      "Epoch [41/50], Step [452/735], Loss: 0.1715\n",
      "Epoch [41/50], Step [453/735], Loss: 0.2591\n",
      "Epoch [41/50], Step [454/735], Loss: 0.1284\n",
      "Epoch [41/50], Step [455/735], Loss: 0.0873\n",
      "Epoch [41/50], Step [456/735], Loss: 0.1847\n",
      "Epoch [41/50], Step [457/735], Loss: 0.0906\n",
      "Epoch [41/50], Step [458/735], Loss: 0.0814\n",
      "Epoch [41/50], Step [459/735], Loss: 0.0840\n",
      "Epoch [41/50], Step [460/735], Loss: 0.1075\n",
      "Epoch [41/50], Step [461/735], Loss: 0.1324\n",
      "Epoch [41/50], Step [462/735], Loss: 0.1160\n",
      "Epoch [41/50], Step [463/735], Loss: 0.0508\n",
      "Epoch [41/50], Step [464/735], Loss: 0.0492\n",
      "Epoch [41/50], Step [465/735], Loss: 0.0802\n",
      "Epoch [41/50], Step [466/735], Loss: 0.2158\n",
      "Epoch [41/50], Step [467/735], Loss: 0.0656\n",
      "Epoch [41/50], Step [468/735], Loss: 0.0694\n",
      "Epoch [41/50], Step [469/735], Loss: 0.0489\n",
      "Epoch [41/50], Step [470/735], Loss: 0.0464\n",
      "Epoch [41/50], Step [471/735], Loss: 0.1152\n",
      "Epoch [41/50], Step [472/735], Loss: 0.0822\n",
      "Epoch [41/50], Step [473/735], Loss: 0.0362\n",
      "Epoch [41/50], Step [474/735], Loss: 0.1561\n",
      "Epoch [41/50], Step [475/735], Loss: 0.0692\n",
      "Epoch [41/50], Step [476/735], Loss: 0.1792\n",
      "Epoch [41/50], Step [477/735], Loss: 0.1573\n",
      "Epoch [41/50], Step [478/735], Loss: 0.0931\n",
      "Epoch [41/50], Step [479/735], Loss: 0.4513\n",
      "Epoch [41/50], Step [480/735], Loss: 0.1074\n",
      "Epoch [41/50], Step [481/735], Loss: 0.1226\n",
      "Epoch [41/50], Step [482/735], Loss: 0.1894\n",
      "Epoch [41/50], Step [483/735], Loss: 0.0570\n",
      "Epoch [41/50], Step [484/735], Loss: 0.0607\n",
      "Epoch [41/50], Step [485/735], Loss: 0.0441\n",
      "Epoch [41/50], Step [486/735], Loss: 0.2946\n",
      "Epoch [41/50], Step [487/735], Loss: 0.1272\n",
      "Epoch [41/50], Step [488/735], Loss: 0.0604\n",
      "Epoch [41/50], Step [489/735], Loss: 0.0589\n",
      "Epoch [41/50], Step [490/735], Loss: 0.2087\n",
      "Epoch [41/50], Step [491/735], Loss: 0.0830\n",
      "Epoch [41/50], Step [492/735], Loss: 0.1267\n",
      "Epoch [41/50], Step [493/735], Loss: 0.0773\n",
      "Epoch [41/50], Step [494/735], Loss: 0.0500\n",
      "Epoch [41/50], Step [495/735], Loss: 0.0395\n",
      "Epoch [41/50], Step [496/735], Loss: 0.0595\n",
      "Epoch [41/50], Step [497/735], Loss: 0.1252\n",
      "Epoch [41/50], Step [498/735], Loss: 0.1355\n",
      "Epoch [41/50], Step [499/735], Loss: 0.0473\n",
      "Epoch [41/50], Step [500/735], Loss: 0.0605\n",
      "Epoch [41/50], Step [501/735], Loss: 0.0571\n",
      "Epoch [41/50], Step [502/735], Loss: 0.1511\n",
      "Epoch [41/50], Step [503/735], Loss: 0.0852\n",
      "Epoch [41/50], Step [504/735], Loss: 0.0681\n",
      "Epoch [41/50], Step [505/735], Loss: 0.0568\n",
      "Epoch [41/50], Step [506/735], Loss: 0.1317\n",
      "Epoch [41/50], Step [507/735], Loss: 0.0995\n",
      "Epoch [41/50], Step [508/735], Loss: 0.0523\n",
      "Epoch [41/50], Step [509/735], Loss: 0.1176\n",
      "Epoch [41/50], Step [510/735], Loss: 0.1092\n",
      "Epoch [41/50], Step [511/735], Loss: 0.1034\n",
      "Epoch [41/50], Step [512/735], Loss: 0.3183\n",
      "Epoch [41/50], Step [513/735], Loss: 0.0810\n",
      "Epoch [41/50], Step [514/735], Loss: 0.0727\n",
      "Epoch [41/50], Step [515/735], Loss: 0.0372\n",
      "Epoch [41/50], Step [516/735], Loss: 0.1086\n",
      "Epoch [41/50], Step [517/735], Loss: 0.1648\n",
      "Epoch [41/50], Step [518/735], Loss: 0.0693\n",
      "Epoch [41/50], Step [519/735], Loss: 0.0727\n",
      "Epoch [41/50], Step [520/735], Loss: 0.1029\n",
      "Epoch [41/50], Step [521/735], Loss: 0.1407\n",
      "Epoch [41/50], Step [522/735], Loss: 0.1074\n",
      "Epoch [41/50], Step [523/735], Loss: 0.0899\n",
      "Epoch [41/50], Step [524/735], Loss: 0.0659\n",
      "Epoch [41/50], Step [525/735], Loss: 0.1303\n",
      "Epoch [41/50], Step [526/735], Loss: 0.1173\n",
      "Epoch [41/50], Step [527/735], Loss: 0.0763\n",
      "Epoch [41/50], Step [528/735], Loss: 0.0844\n",
      "Epoch [41/50], Step [529/735], Loss: 0.0522\n",
      "Epoch [41/50], Step [530/735], Loss: 0.0472\n",
      "Epoch [41/50], Step [531/735], Loss: 0.0738\n",
      "Epoch [41/50], Step [532/735], Loss: 0.1332\n",
      "Epoch [41/50], Step [533/735], Loss: 0.0970\n",
      "Epoch [41/50], Step [534/735], Loss: 0.1253\n",
      "Epoch [41/50], Step [535/735], Loss: 0.2367\n",
      "Epoch [41/50], Step [536/735], Loss: 0.3318\n",
      "Epoch [41/50], Step [537/735], Loss: 0.0714\n",
      "Epoch [41/50], Step [538/735], Loss: 0.0572\n",
      "Epoch [41/50], Step [539/735], Loss: 0.0594\n",
      "Epoch [41/50], Step [540/735], Loss: 0.1328\n",
      "Epoch [41/50], Step [541/735], Loss: 0.0725\n",
      "Epoch [41/50], Step [542/735], Loss: 0.1240\n",
      "Epoch [41/50], Step [543/735], Loss: 0.0737\n",
      "Epoch [41/50], Step [544/735], Loss: 0.0465\n",
      "Epoch [41/50], Step [545/735], Loss: 0.0538\n",
      "Epoch [41/50], Step [546/735], Loss: 0.0819\n",
      "Epoch [41/50], Step [547/735], Loss: 0.0856\n",
      "Epoch [41/50], Step [548/735], Loss: 0.1127\n",
      "Epoch [41/50], Step [549/735], Loss: 0.0800\n",
      "Epoch [41/50], Step [550/735], Loss: 0.0966\n",
      "Epoch [41/50], Step [551/735], Loss: 0.1817\n",
      "Epoch [41/50], Step [552/735], Loss: 0.0925\n",
      "Epoch [41/50], Step [553/735], Loss: 0.0672\n",
      "Epoch [41/50], Step [554/735], Loss: 0.0317\n",
      "Epoch [41/50], Step [555/735], Loss: 0.0990\n",
      "Epoch [41/50], Step [556/735], Loss: 0.0887\n",
      "Epoch [41/50], Step [557/735], Loss: 0.0546\n",
      "Epoch [41/50], Step [558/735], Loss: 0.0387\n",
      "Epoch [41/50], Step [559/735], Loss: 0.0582\n",
      "Epoch [41/50], Step [560/735], Loss: 0.0742\n",
      "Epoch [41/50], Step [561/735], Loss: 0.1070\n",
      "Epoch [41/50], Step [562/735], Loss: 0.0561\n",
      "Epoch [41/50], Step [563/735], Loss: 0.0648\n",
      "Epoch [41/50], Step [564/735], Loss: 0.0566\n",
      "Epoch [41/50], Step [565/735], Loss: 0.0599\n",
      "Epoch [41/50], Step [566/735], Loss: 0.0495\n",
      "Epoch [41/50], Step [567/735], Loss: 0.1257\n",
      "Epoch [41/50], Step [568/735], Loss: 0.0507\n",
      "Epoch [41/50], Step [569/735], Loss: 0.0428\n",
      "Epoch [41/50], Step [570/735], Loss: 0.0673\n",
      "Epoch [41/50], Step [571/735], Loss: 0.0728\n",
      "Epoch [41/50], Step [572/735], Loss: 0.0628\n",
      "Epoch [41/50], Step [573/735], Loss: 0.1000\n",
      "Epoch [41/50], Step [574/735], Loss: 0.1194\n",
      "Epoch [41/50], Step [575/735], Loss: 0.1430\n",
      "Epoch [41/50], Step [576/735], Loss: 0.0366\n",
      "Epoch [41/50], Step [577/735], Loss: 0.0433\n",
      "Epoch [41/50], Step [578/735], Loss: 0.4454\n",
      "Epoch [41/50], Step [579/735], Loss: 0.0622\n",
      "Epoch [41/50], Step [580/735], Loss: 0.1346\n",
      "Epoch [41/50], Step [581/735], Loss: 0.1272\n",
      "Epoch [41/50], Step [582/735], Loss: 0.3238\n",
      "Epoch [41/50], Step [583/735], Loss: 0.0876\n",
      "Epoch [41/50], Step [584/735], Loss: 0.0806\n",
      "Epoch [41/50], Step [585/735], Loss: 0.0585\n",
      "Epoch [41/50], Step [586/735], Loss: 0.0910\n",
      "Epoch [41/50], Step [587/735], Loss: 0.0626\n",
      "Epoch [41/50], Step [588/735], Loss: 0.0527\n",
      "Epoch [41/50], Step [589/735], Loss: 0.0498\n",
      "Epoch [41/50], Step [590/735], Loss: 0.0613\n",
      "Epoch [41/50], Step [591/735], Loss: 0.1222\n",
      "Epoch [41/50], Step [592/735], Loss: 0.1581\n",
      "Epoch [41/50], Step [593/735], Loss: 0.1341\n",
      "Epoch [41/50], Step [594/735], Loss: 0.0875\n",
      "Epoch [41/50], Step [595/735], Loss: 0.0785\n",
      "Epoch [41/50], Step [596/735], Loss: 0.0979\n",
      "Epoch [41/50], Step [597/735], Loss: 0.1699\n",
      "Epoch [41/50], Step [598/735], Loss: 0.0633\n",
      "Epoch [41/50], Step [599/735], Loss: 0.0602\n",
      "Epoch [41/50], Step [600/735], Loss: 1.0130\n",
      "Epoch [41/50], Step [601/735], Loss: 0.1386\n",
      "Epoch [41/50], Step [602/735], Loss: 0.0714\n",
      "Epoch [41/50], Step [603/735], Loss: 0.0737\n",
      "Epoch [41/50], Step [604/735], Loss: 0.0858\n",
      "Epoch [41/50], Step [605/735], Loss: 0.0687\n",
      "Epoch [41/50], Step [606/735], Loss: 0.0610\n",
      "Epoch [41/50], Step [607/735], Loss: 0.0932\n",
      "Epoch [41/50], Step [608/735], Loss: 0.1111\n",
      "Epoch [41/50], Step [609/735], Loss: 0.1737\n",
      "Epoch [41/50], Step [610/735], Loss: 0.0812\n",
      "Epoch [41/50], Step [611/735], Loss: 0.1007\n",
      "Epoch [41/50], Step [612/735], Loss: 0.1018\n",
      "Epoch [41/50], Step [613/735], Loss: 0.0602\n",
      "Epoch [41/50], Step [614/735], Loss: 0.0694\n",
      "Epoch [41/50], Step [615/735], Loss: 0.0304\n",
      "Epoch [41/50], Step [616/735], Loss: 0.3142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Step [617/735], Loss: 0.0477\n",
      "Epoch [41/50], Step [618/735], Loss: 0.1461\n",
      "Epoch [41/50], Step [619/735], Loss: 0.0432\n",
      "Epoch [41/50], Step [620/735], Loss: 0.1183\n",
      "Epoch [41/50], Step [621/735], Loss: 0.0954\n",
      "Epoch [41/50], Step [622/735], Loss: 0.0653\n",
      "Epoch [41/50], Step [623/735], Loss: 0.0731\n",
      "Epoch [41/50], Step [624/735], Loss: 0.0616\n",
      "Epoch [41/50], Step [625/735], Loss: 0.0819\n",
      "Epoch [41/50], Step [626/735], Loss: 0.1934\n",
      "Epoch [41/50], Step [627/735], Loss: 0.1241\n",
      "Epoch [41/50], Step [628/735], Loss: 0.0987\n",
      "Epoch [41/50], Step [629/735], Loss: 0.0759\n",
      "Epoch [41/50], Step [630/735], Loss: 0.0904\n",
      "Epoch [41/50], Step [631/735], Loss: 0.0983\n",
      "Epoch [41/50], Step [632/735], Loss: 0.0675\n",
      "Epoch [41/50], Step [633/735], Loss: 0.1407\n",
      "Epoch [41/50], Step [634/735], Loss: 0.0681\n",
      "Epoch [41/50], Step [635/735], Loss: 0.2786\n",
      "Epoch [41/50], Step [636/735], Loss: 0.1286\n",
      "Epoch [41/50], Step [637/735], Loss: 0.0504\n",
      "Epoch [41/50], Step [638/735], Loss: 0.3264\n",
      "Epoch [41/50], Step [639/735], Loss: 0.0463\n",
      "Epoch [41/50], Step [640/735], Loss: 0.0651\n",
      "Epoch [41/50], Step [641/735], Loss: 0.0349\n",
      "Epoch [41/50], Step [642/735], Loss: 0.0827\n",
      "Epoch [41/50], Step [643/735], Loss: 0.0603\n",
      "Epoch [41/50], Step [644/735], Loss: 0.9584\n",
      "Epoch [41/50], Step [645/735], Loss: 0.5163\n",
      "Epoch [41/50], Step [646/735], Loss: 0.1453\n",
      "Epoch [41/50], Step [647/735], Loss: 0.4696\n",
      "Epoch [41/50], Step [648/735], Loss: 0.1624\n",
      "Epoch [41/50], Step [649/735], Loss: 0.1103\n",
      "Epoch [41/50], Step [650/735], Loss: 1.0119\n",
      "Epoch [41/50], Step [651/735], Loss: 0.1317\n",
      "Epoch [41/50], Step [652/735], Loss: 0.1198\n",
      "Epoch [41/50], Step [653/735], Loss: 0.1444\n",
      "Epoch [41/50], Step [654/735], Loss: 0.0855\n",
      "Epoch [41/50], Step [655/735], Loss: 0.1153\n",
      "Epoch [41/50], Step [656/735], Loss: 0.0557\n",
      "Epoch [41/50], Step [657/735], Loss: 0.5259\n",
      "Epoch [41/50], Step [658/735], Loss: 0.1344\n",
      "Epoch [41/50], Step [659/735], Loss: 0.0979\n",
      "Epoch [41/50], Step [660/735], Loss: 0.1399\n",
      "Epoch [41/50], Step [661/735], Loss: 0.1547\n",
      "Epoch [41/50], Step [662/735], Loss: 0.1196\n",
      "Epoch [41/50], Step [663/735], Loss: 0.1387\n",
      "Epoch [41/50], Step [664/735], Loss: 0.1065\n",
      "Epoch [41/50], Step [665/735], Loss: 0.0998\n",
      "Epoch [41/50], Step [666/735], Loss: 0.0567\n",
      "Epoch [41/50], Step [667/735], Loss: 0.2261\n",
      "Epoch [41/50], Step [668/735], Loss: 0.0779\n",
      "Epoch [41/50], Step [669/735], Loss: 0.1124\n",
      "Epoch [41/50], Step [670/735], Loss: 0.0616\n",
      "Epoch [41/50], Step [671/735], Loss: 0.1270\n",
      "Epoch [41/50], Step [672/735], Loss: 0.0977\n",
      "Epoch [41/50], Step [673/735], Loss: 0.1203\n",
      "Epoch [41/50], Step [674/735], Loss: 0.0989\n",
      "Epoch [41/50], Step [675/735], Loss: 0.2673\n",
      "Epoch [41/50], Step [676/735], Loss: 0.0619\n",
      "Epoch [41/50], Step [677/735], Loss: 0.1217\n",
      "Epoch [41/50], Step [678/735], Loss: 0.0750\n",
      "Epoch [41/50], Step [679/735], Loss: 0.1037\n",
      "Epoch [41/50], Step [680/735], Loss: 0.1486\n",
      "Epoch [41/50], Step [681/735], Loss: 0.2239\n",
      "Epoch [41/50], Step [682/735], Loss: 0.1918\n",
      "Epoch [41/50], Step [683/735], Loss: 0.1108\n",
      "Epoch [41/50], Step [684/735], Loss: 0.0900\n",
      "Epoch [41/50], Step [685/735], Loss: 0.1371\n",
      "Epoch [41/50], Step [686/735], Loss: 0.1161\n",
      "Epoch [41/50], Step [687/735], Loss: 0.0652\n",
      "Epoch [41/50], Step [688/735], Loss: 0.1232\n",
      "Epoch [41/50], Step [689/735], Loss: 0.4609\n",
      "Epoch [41/50], Step [690/735], Loss: 0.1503\n",
      "Epoch [41/50], Step [691/735], Loss: 0.0573\n",
      "Epoch [41/50], Step [692/735], Loss: 0.0675\n",
      "Epoch [41/50], Step [693/735], Loss: 0.0756\n",
      "Epoch [41/50], Step [694/735], Loss: 0.1252\n",
      "Epoch [41/50], Step [695/735], Loss: 0.0783\n",
      "Epoch [41/50], Step [696/735], Loss: 0.0979\n",
      "Epoch [41/50], Step [697/735], Loss: 0.1608\n",
      "Epoch [41/50], Step [698/735], Loss: 0.0980\n",
      "Epoch [41/50], Step [699/735], Loss: 1.3230\n",
      "Epoch [41/50], Step [700/735], Loss: 0.1022\n",
      "Epoch [41/50], Step [701/735], Loss: 0.0755\n",
      "Epoch [41/50], Step [702/735], Loss: 0.0770\n",
      "Epoch [41/50], Step [703/735], Loss: 0.0730\n",
      "Epoch [41/50], Step [704/735], Loss: 0.0759\n",
      "Epoch [41/50], Step [705/735], Loss: 0.4807\n",
      "Epoch [41/50], Step [706/735], Loss: 0.0791\n",
      "Epoch [41/50], Step [707/735], Loss: 0.1192\n",
      "Epoch [41/50], Step [708/735], Loss: 0.0515\n",
      "Epoch [41/50], Step [709/735], Loss: 0.0697\n",
      "Epoch [41/50], Step [710/735], Loss: 0.0822\n",
      "Epoch [41/50], Step [711/735], Loss: 0.1049\n",
      "Epoch [41/50], Step [712/735], Loss: 0.0767\n",
      "Epoch [41/50], Step [713/735], Loss: 0.0667\n",
      "Epoch [41/50], Step [714/735], Loss: 0.1668\n",
      "Epoch [41/50], Step [715/735], Loss: 0.0416\n",
      "Epoch [41/50], Step [716/735], Loss: 0.0386\n",
      "Epoch [41/50], Step [717/735], Loss: 0.1108\n",
      "Epoch [41/50], Step [718/735], Loss: 0.1128\n",
      "Epoch [41/50], Step [719/735], Loss: 0.0820\n",
      "Epoch [41/50], Step [720/735], Loss: 0.1279\n",
      "Epoch [41/50], Step [721/735], Loss: 0.1914\n",
      "Epoch [41/50], Step [722/735], Loss: 0.0258\n",
      "Epoch [41/50], Step [723/735], Loss: 0.0747\n",
      "Epoch [41/50], Step [724/735], Loss: 0.0753\n",
      "Epoch [41/50], Step [725/735], Loss: 0.0434\n",
      "Epoch [41/50], Step [726/735], Loss: 0.1078\n",
      "Epoch [41/50], Step [727/735], Loss: 0.1638\n",
      "Epoch [41/50], Step [728/735], Loss: 0.1680\n",
      "Epoch [41/50], Step [729/735], Loss: 0.1155\n",
      "Epoch [41/50], Step [730/735], Loss: 0.4078\n",
      "Epoch [41/50], Step [731/735], Loss: 0.3780\n",
      "Epoch [41/50], Step [732/735], Loss: 0.1591\n",
      "Epoch [41/50], Step [733/735], Loss: 0.0266\n",
      "Epoch [41/50], Step [734/735], Loss: 1.7322\n",
      "Epoch [41/50], Step [735/735], Loss: 0.0248\n",
      "Epoch [42/50], Step [1/735], Loss: 0.1538\n",
      "Epoch [42/50], Step [2/735], Loss: 0.0729\n",
      "Epoch [42/50], Step [3/735], Loss: 0.0752\n",
      "Epoch [42/50], Step [4/735], Loss: 0.0713\n",
      "Epoch [42/50], Step [5/735], Loss: 0.0947\n",
      "Epoch [42/50], Step [6/735], Loss: 0.0947\n",
      "Epoch [42/50], Step [7/735], Loss: 0.0771\n",
      "Epoch [42/50], Step [8/735], Loss: 0.0807\n",
      "Epoch [42/50], Step [9/735], Loss: 0.0485\n",
      "Epoch [42/50], Step [10/735], Loss: 0.1957\n",
      "Epoch [42/50], Step [11/735], Loss: 0.0685\n",
      "Epoch [42/50], Step [12/735], Loss: 0.1114\n",
      "Epoch [42/50], Step [13/735], Loss: 0.1110\n",
      "Epoch [42/50], Step [14/735], Loss: 0.0517\n",
      "Epoch [42/50], Step [15/735], Loss: 0.1169\n",
      "Epoch [42/50], Step [16/735], Loss: 0.1119\n",
      "Epoch [42/50], Step [17/735], Loss: 0.0981\n",
      "Epoch [42/50], Step [18/735], Loss: 0.0469\n",
      "Epoch [42/50], Step [19/735], Loss: 0.0806\n",
      "Epoch [42/50], Step [20/735], Loss: 0.0661\n",
      "Epoch [42/50], Step [21/735], Loss: 0.0631\n",
      "Epoch [42/50], Step [22/735], Loss: 0.0985\n",
      "Epoch [42/50], Step [23/735], Loss: 0.1307\n",
      "Epoch [42/50], Step [24/735], Loss: 0.0814\n",
      "Epoch [42/50], Step [25/735], Loss: 0.0904\n",
      "Epoch [42/50], Step [26/735], Loss: 0.0425\n",
      "Epoch [42/50], Step [27/735], Loss: 0.0474\n",
      "Epoch [42/50], Step [28/735], Loss: 0.0584\n",
      "Epoch [42/50], Step [29/735], Loss: 0.0694\n",
      "Epoch [42/50], Step [30/735], Loss: 0.1065\n",
      "Epoch [42/50], Step [31/735], Loss: 0.0501\n",
      "Epoch [42/50], Step [32/735], Loss: 0.1610\n",
      "Epoch [42/50], Step [33/735], Loss: 0.0437\n",
      "Epoch [42/50], Step [34/735], Loss: 0.0561\n",
      "Epoch [42/50], Step [35/735], Loss: 0.0841\n",
      "Epoch [42/50], Step [36/735], Loss: 0.0999\n",
      "Epoch [42/50], Step [37/735], Loss: 0.0715\n",
      "Epoch [42/50], Step [38/735], Loss: 0.4146\n",
      "Epoch [42/50], Step [39/735], Loss: 0.1642\n",
      "Epoch [42/50], Step [40/735], Loss: 0.0870\n",
      "Epoch [42/50], Step [41/735], Loss: 0.2026\n",
      "Epoch [42/50], Step [42/735], Loss: 0.2330\n",
      "Epoch [42/50], Step [43/735], Loss: 0.2752\n",
      "Epoch [42/50], Step [44/735], Loss: 0.0655\n",
      "Epoch [42/50], Step [45/735], Loss: 0.1088\n",
      "Epoch [42/50], Step [46/735], Loss: 0.1141\n",
      "Epoch [42/50], Step [47/735], Loss: 0.2977\n",
      "Epoch [42/50], Step [48/735], Loss: 0.0822\n",
      "Epoch [42/50], Step [49/735], Loss: 0.1091\n",
      "Epoch [42/50], Step [50/735], Loss: 0.0711\n",
      "Epoch [42/50], Step [51/735], Loss: 0.1720\n",
      "Epoch [42/50], Step [52/735], Loss: 0.0631\n",
      "Epoch [42/50], Step [53/735], Loss: 0.0812\n",
      "Epoch [42/50], Step [54/735], Loss: 0.2838\n",
      "Epoch [42/50], Step [55/735], Loss: 0.0573\n",
      "Epoch [42/50], Step [56/735], Loss: 0.2026\n",
      "Epoch [42/50], Step [57/735], Loss: 0.2151\n",
      "Epoch [42/50], Step [58/735], Loss: 0.1154\n",
      "Epoch [42/50], Step [59/735], Loss: 0.1065\n",
      "Epoch [42/50], Step [60/735], Loss: 0.0401\n",
      "Epoch [42/50], Step [61/735], Loss: 0.0462\n",
      "Epoch [42/50], Step [62/735], Loss: 0.0940\n",
      "Epoch [42/50], Step [63/735], Loss: 0.1072\n",
      "Epoch [42/50], Step [64/735], Loss: 0.0914\n",
      "Epoch [42/50], Step [65/735], Loss: 0.0778\n",
      "Epoch [42/50], Step [66/735], Loss: 0.6348\n",
      "Epoch [42/50], Step [67/735], Loss: 0.3452\n",
      "Epoch [42/50], Step [68/735], Loss: 0.1403\n",
      "Epoch [42/50], Step [69/735], Loss: 0.0708\n",
      "Epoch [42/50], Step [70/735], Loss: 0.0732\n",
      "Epoch [42/50], Step [71/735], Loss: 0.0352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Step [72/735], Loss: 0.0453\n",
      "Epoch [42/50], Step [73/735], Loss: 0.0760\n",
      "Epoch [42/50], Step [74/735], Loss: 0.0806\n",
      "Epoch [42/50], Step [75/735], Loss: 0.1059\n",
      "Epoch [42/50], Step [76/735], Loss: 0.0469\n",
      "Epoch [42/50], Step [77/735], Loss: 0.0630\n",
      "Epoch [42/50], Step [78/735], Loss: 0.0336\n",
      "Epoch [42/50], Step [79/735], Loss: 0.0780\n",
      "Epoch [42/50], Step [80/735], Loss: 0.1213\n",
      "Epoch [42/50], Step [81/735], Loss: 0.0287\n",
      "Epoch [42/50], Step [82/735], Loss: 0.0665\n",
      "Epoch [42/50], Step [83/735], Loss: 0.1040\n",
      "Epoch [42/50], Step [84/735], Loss: 0.0894\n",
      "Epoch [42/50], Step [85/735], Loss: 0.0669\n",
      "Epoch [42/50], Step [86/735], Loss: 0.0415\n",
      "Epoch [42/50], Step [87/735], Loss: 0.0458\n",
      "Epoch [42/50], Step [88/735], Loss: 0.0532\n",
      "Epoch [42/50], Step [89/735], Loss: 0.0613\n",
      "Epoch [42/50], Step [90/735], Loss: 0.1000\n",
      "Epoch [42/50], Step [91/735], Loss: 0.1683\n",
      "Epoch [42/50], Step [92/735], Loss: 0.0398\n",
      "Epoch [42/50], Step [93/735], Loss: 0.1266\n",
      "Epoch [42/50], Step [94/735], Loss: 0.2694\n",
      "Epoch [42/50], Step [95/735], Loss: 0.0985\n",
      "Epoch [42/50], Step [96/735], Loss: 0.0830\n",
      "Epoch [42/50], Step [97/735], Loss: 0.0292\n",
      "Epoch [42/50], Step [98/735], Loss: 0.1187\n",
      "Epoch [42/50], Step [99/735], Loss: 0.0554\n",
      "Epoch [42/50], Step [100/735], Loss: 0.1027\n",
      "Epoch [42/50], Step [101/735], Loss: 0.0931\n",
      "Epoch [42/50], Step [102/735], Loss: 0.2044\n",
      "Epoch [42/50], Step [103/735], Loss: 0.0808\n",
      "Epoch [42/50], Step [104/735], Loss: 0.1159\n",
      "Epoch [42/50], Step [105/735], Loss: 0.0674\n",
      "Epoch [42/50], Step [106/735], Loss: 0.0632\n",
      "Epoch [42/50], Step [107/735], Loss: 0.0600\n",
      "Epoch [42/50], Step [108/735], Loss: 0.0564\n",
      "Epoch [42/50], Step [109/735], Loss: 0.2230\n",
      "Epoch [42/50], Step [110/735], Loss: 0.0417\n",
      "Epoch [42/50], Step [111/735], Loss: 0.0440\n",
      "Epoch [42/50], Step [112/735], Loss: 0.1164\n",
      "Epoch [42/50], Step [113/735], Loss: 0.0733\n",
      "Epoch [42/50], Step [114/735], Loss: 0.1704\n",
      "Epoch [42/50], Step [115/735], Loss: 0.1244\n",
      "Epoch [42/50], Step [116/735], Loss: 0.1581\n",
      "Epoch [42/50], Step [117/735], Loss: 0.1051\n",
      "Epoch [42/50], Step [118/735], Loss: 0.0851\n",
      "Epoch [42/50], Step [119/735], Loss: 0.1332\n",
      "Epoch [42/50], Step [120/735], Loss: 0.0221\n",
      "Epoch [42/50], Step [121/735], Loss: 0.6723\n",
      "Epoch [42/50], Step [122/735], Loss: 0.1336\n",
      "Epoch [42/50], Step [123/735], Loss: 0.0536\n",
      "Epoch [42/50], Step [124/735], Loss: 0.1634\n",
      "Epoch [42/50], Step [125/735], Loss: 0.3798\n",
      "Epoch [42/50], Step [126/735], Loss: 0.0700\n",
      "Epoch [42/50], Step [127/735], Loss: 0.0620\n",
      "Epoch [42/50], Step [128/735], Loss: 0.1388\n",
      "Epoch [42/50], Step [129/735], Loss: 0.1346\n",
      "Epoch [42/50], Step [130/735], Loss: 0.0865\n",
      "Epoch [42/50], Step [131/735], Loss: 0.1434\n",
      "Epoch [42/50], Step [132/735], Loss: 0.0593\n",
      "Epoch [42/50], Step [133/735], Loss: 0.9232\n",
      "Epoch [42/50], Step [134/735], Loss: 0.0541\n",
      "Epoch [42/50], Step [135/735], Loss: 0.4258\n",
      "Epoch [42/50], Step [136/735], Loss: 0.1525\n",
      "Epoch [42/50], Step [137/735], Loss: 0.1208\n",
      "Epoch [42/50], Step [138/735], Loss: 0.1182\n",
      "Epoch [42/50], Step [139/735], Loss: 0.0532\n",
      "Epoch [42/50], Step [140/735], Loss: 0.0974\n",
      "Epoch [42/50], Step [141/735], Loss: 0.1887\n",
      "Epoch [42/50], Step [142/735], Loss: 0.0808\n",
      "Epoch [42/50], Step [143/735], Loss: 0.1397\n",
      "Epoch [42/50], Step [144/735], Loss: 0.1395\n",
      "Epoch [42/50], Step [145/735], Loss: 0.0982\n",
      "Epoch [42/50], Step [146/735], Loss: 0.1531\n",
      "Epoch [42/50], Step [147/735], Loss: 0.0895\n",
      "Epoch [42/50], Step [148/735], Loss: 0.0864\n",
      "Epoch [42/50], Step [149/735], Loss: 0.0533\n",
      "Epoch [42/50], Step [150/735], Loss: 0.0761\n",
      "Epoch [42/50], Step [151/735], Loss: 0.0985\n",
      "Epoch [42/50], Step [152/735], Loss: 0.1250\n",
      "Epoch [42/50], Step [153/735], Loss: 0.1204\n",
      "Epoch [42/50], Step [154/735], Loss: 0.0988\n",
      "Epoch [42/50], Step [155/735], Loss: 0.1844\n",
      "Epoch [42/50], Step [156/735], Loss: 0.1029\n",
      "Epoch [42/50], Step [157/735], Loss: 0.1913\n",
      "Epoch [42/50], Step [158/735], Loss: 0.1440\n",
      "Epoch [42/50], Step [159/735], Loss: 0.0501\n",
      "Epoch [42/50], Step [160/735], Loss: 0.1234\n",
      "Epoch [42/50], Step [161/735], Loss: 0.1112\n",
      "Epoch [42/50], Step [162/735], Loss: 0.0472\n",
      "Epoch [42/50], Step [163/735], Loss: 0.0324\n",
      "Epoch [42/50], Step [164/735], Loss: 0.1618\n",
      "Epoch [42/50], Step [165/735], Loss: 0.0642\n",
      "Epoch [42/50], Step [166/735], Loss: 0.0670\n",
      "Epoch [42/50], Step [167/735], Loss: 0.1359\n",
      "Epoch [42/50], Step [168/735], Loss: 0.0442\n",
      "Epoch [42/50], Step [169/735], Loss: 0.1138\n",
      "Epoch [42/50], Step [170/735], Loss: 0.1382\n",
      "Epoch [42/50], Step [171/735], Loss: 0.1318\n",
      "Epoch [42/50], Step [172/735], Loss: 0.0809\n",
      "Epoch [42/50], Step [173/735], Loss: 0.0766\n",
      "Epoch [42/50], Step [174/735], Loss: 0.1100\n",
      "Epoch [42/50], Step [175/735], Loss: 0.0680\n",
      "Epoch [42/50], Step [176/735], Loss: 0.0555\n",
      "Epoch [42/50], Step [177/735], Loss: 0.0763\n",
      "Epoch [42/50], Step [178/735], Loss: 0.1321\n",
      "Epoch [42/50], Step [179/735], Loss: 0.0641\n",
      "Epoch [42/50], Step [180/735], Loss: 0.3510\n",
      "Epoch [42/50], Step [181/735], Loss: 0.1423\n",
      "Epoch [42/50], Step [182/735], Loss: 0.1481\n",
      "Epoch [42/50], Step [183/735], Loss: 0.1553\n",
      "Epoch [42/50], Step [184/735], Loss: 0.0510\n",
      "Epoch [42/50], Step [185/735], Loss: 0.1015\n",
      "Epoch [42/50], Step [186/735], Loss: 0.1417\n",
      "Epoch [42/50], Step [187/735], Loss: 0.0715\n",
      "Epoch [42/50], Step [188/735], Loss: 0.1535\n",
      "Epoch [42/50], Step [189/735], Loss: 1.2585\n",
      "Epoch [42/50], Step [190/735], Loss: 0.0937\n",
      "Epoch [42/50], Step [191/735], Loss: 0.1191\n",
      "Epoch [42/50], Step [192/735], Loss: 0.0716\n",
      "Epoch [42/50], Step [193/735], Loss: 0.1614\n",
      "Epoch [42/50], Step [194/735], Loss: 0.0954\n",
      "Epoch [42/50], Step [195/735], Loss: 0.1712\n",
      "Epoch [42/50], Step [196/735], Loss: 0.0634\n",
      "Epoch [42/50], Step [197/735], Loss: 0.1561\n",
      "Epoch [42/50], Step [198/735], Loss: 0.0767\n",
      "Epoch [42/50], Step [199/735], Loss: 0.1933\n",
      "Epoch [42/50], Step [200/735], Loss: 0.1704\n",
      "Epoch [42/50], Step [201/735], Loss: 0.1021\n",
      "Epoch [42/50], Step [202/735], Loss: 0.0724\n",
      "Epoch [42/50], Step [203/735], Loss: 0.0567\n",
      "Epoch [42/50], Step [204/735], Loss: 0.0938\n",
      "Epoch [42/50], Step [205/735], Loss: 0.2088\n",
      "Epoch [42/50], Step [206/735], Loss: 0.0509\n",
      "Epoch [42/50], Step [207/735], Loss: 0.1087\n",
      "Epoch [42/50], Step [208/735], Loss: 0.0718\n",
      "Epoch [42/50], Step [209/735], Loss: 0.1175\n",
      "Epoch [42/50], Step [210/735], Loss: 0.1076\n",
      "Epoch [42/50], Step [211/735], Loss: 0.0648\n",
      "Epoch [42/50], Step [212/735], Loss: 0.0797\n",
      "Epoch [42/50], Step [213/735], Loss: 0.1065\n",
      "Epoch [42/50], Step [214/735], Loss: 0.1020\n",
      "Epoch [42/50], Step [215/735], Loss: 0.1118\n",
      "Epoch [42/50], Step [216/735], Loss: 0.1696\n",
      "Epoch [42/50], Step [217/735], Loss: 0.4633\n",
      "Epoch [42/50], Step [218/735], Loss: 0.3783\n",
      "Epoch [42/50], Step [219/735], Loss: 0.0418\n",
      "Epoch [42/50], Step [220/735], Loss: 0.6174\n",
      "Epoch [42/50], Step [221/735], Loss: 0.1079\n",
      "Epoch [42/50], Step [222/735], Loss: 0.0586\n",
      "Epoch [42/50], Step [223/735], Loss: 0.0576\n",
      "Epoch [42/50], Step [224/735], Loss: 0.0858\n",
      "Epoch [42/50], Step [225/735], Loss: 0.0885\n",
      "Epoch [42/50], Step [226/735], Loss: 0.0592\n",
      "Epoch [42/50], Step [227/735], Loss: 0.0543\n",
      "Epoch [42/50], Step [228/735], Loss: 0.0776\n",
      "Epoch [42/50], Step [229/735], Loss: 0.0675\n",
      "Epoch [42/50], Step [230/735], Loss: 0.3946\n",
      "Epoch [42/50], Step [231/735], Loss: 0.0519\n",
      "Epoch [42/50], Step [232/735], Loss: 0.2641\n",
      "Epoch [42/50], Step [233/735], Loss: 0.1533\n",
      "Epoch [42/50], Step [234/735], Loss: 0.2053\n",
      "Epoch [42/50], Step [235/735], Loss: 0.1208\n",
      "Epoch [42/50], Step [236/735], Loss: 0.0992\n",
      "Epoch [42/50], Step [237/735], Loss: 0.0319\n",
      "Epoch [42/50], Step [238/735], Loss: 0.0398\n",
      "Epoch [42/50], Step [239/735], Loss: 0.0948\n",
      "Epoch [42/50], Step [240/735], Loss: 0.0669\n",
      "Epoch [42/50], Step [241/735], Loss: 0.5170\n",
      "Epoch [42/50], Step [242/735], Loss: 0.0784\n",
      "Epoch [42/50], Step [243/735], Loss: 0.1416\n",
      "Epoch [42/50], Step [244/735], Loss: 0.3282\n",
      "Epoch [42/50], Step [245/735], Loss: 0.0759\n",
      "Epoch [42/50], Step [246/735], Loss: 0.1495\n",
      "Epoch [42/50], Step [247/735], Loss: 0.0636\n",
      "Epoch [42/50], Step [248/735], Loss: 0.0686\n",
      "Epoch [42/50], Step [249/735], Loss: 0.0575\n",
      "Epoch [42/50], Step [250/735], Loss: 0.1528\n",
      "Epoch [42/50], Step [251/735], Loss: 0.1307\n",
      "Epoch [42/50], Step [252/735], Loss: 0.1445\n",
      "Epoch [42/50], Step [253/735], Loss: 0.1284\n",
      "Epoch [42/50], Step [254/735], Loss: 0.1256\n",
      "Epoch [42/50], Step [255/735], Loss: 0.0527\n",
      "Epoch [42/50], Step [256/735], Loss: 0.0537\n",
      "Epoch [42/50], Step [257/735], Loss: 0.1720\n",
      "Epoch [42/50], Step [258/735], Loss: 0.1160\n",
      "Epoch [42/50], Step [259/735], Loss: 0.1051\n",
      "Epoch [42/50], Step [260/735], Loss: 0.2234\n",
      "Epoch [42/50], Step [261/735], Loss: 0.0688\n",
      "Epoch [42/50], Step [262/735], Loss: 0.3077\n",
      "Epoch [42/50], Step [263/735], Loss: 0.1156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Step [264/735], Loss: 0.0982\n",
      "Epoch [42/50], Step [265/735], Loss: 0.1379\n",
      "Epoch [42/50], Step [266/735], Loss: 0.1443\n",
      "Epoch [42/50], Step [267/735], Loss: 0.0498\n",
      "Epoch [42/50], Step [268/735], Loss: 0.1471\n",
      "Epoch [42/50], Step [269/735], Loss: 0.0440\n",
      "Epoch [42/50], Step [270/735], Loss: 1.0685\n",
      "Epoch [42/50], Step [271/735], Loss: 0.0519\n",
      "Epoch [42/50], Step [272/735], Loss: 0.1308\n",
      "Epoch [42/50], Step [273/735], Loss: 0.2072\n",
      "Epoch [42/50], Step [274/735], Loss: 0.0341\n",
      "Epoch [42/50], Step [275/735], Loss: 0.1367\n",
      "Epoch [42/50], Step [276/735], Loss: 0.0312\n",
      "Epoch [42/50], Step [277/735], Loss: 0.0852\n",
      "Epoch [42/50], Step [278/735], Loss: 0.0657\n",
      "Epoch [42/50], Step [279/735], Loss: 0.1093\n",
      "Epoch [42/50], Step [280/735], Loss: 0.0960\n",
      "Epoch [42/50], Step [281/735], Loss: 0.4417\n",
      "Epoch [42/50], Step [282/735], Loss: 0.0571\n",
      "Epoch [42/50], Step [283/735], Loss: 0.1173\n",
      "Epoch [42/50], Step [284/735], Loss: 0.0874\n",
      "Epoch [42/50], Step [285/735], Loss: 0.0797\n",
      "Epoch [42/50], Step [286/735], Loss: 0.0706\n",
      "Epoch [42/50], Step [287/735], Loss: 0.0851\n",
      "Epoch [42/50], Step [288/735], Loss: 0.0859\n",
      "Epoch [42/50], Step [289/735], Loss: 0.5046\n",
      "Epoch [42/50], Step [290/735], Loss: 0.1141\n",
      "Epoch [42/50], Step [291/735], Loss: 0.0758\n",
      "Epoch [42/50], Step [292/735], Loss: 0.1380\n",
      "Epoch [42/50], Step [293/735], Loss: 0.0712\n",
      "Epoch [42/50], Step [294/735], Loss: 0.0923\n",
      "Epoch [42/50], Step [295/735], Loss: 0.0660\n",
      "Epoch [42/50], Step [296/735], Loss: 0.0542\n",
      "Epoch [42/50], Step [297/735], Loss: 0.0753\n",
      "Epoch [42/50], Step [298/735], Loss: 0.0629\n",
      "Epoch [42/50], Step [299/735], Loss: 0.1008\n",
      "Epoch [42/50], Step [300/735], Loss: 0.3874\n",
      "Epoch [42/50], Step [301/735], Loss: 0.3644\n",
      "Epoch [42/50], Step [302/735], Loss: 0.0750\n",
      "Epoch [42/50], Step [303/735], Loss: 0.1833\n",
      "Epoch [42/50], Step [304/735], Loss: 0.0426\n",
      "Epoch [42/50], Step [305/735], Loss: 0.1589\n",
      "Epoch [42/50], Step [306/735], Loss: 0.4825\n",
      "Epoch [42/50], Step [307/735], Loss: 0.0785\n",
      "Epoch [42/50], Step [308/735], Loss: 0.1291\n",
      "Epoch [42/50], Step [309/735], Loss: 0.1023\n",
      "Epoch [42/50], Step [310/735], Loss: 0.0892\n",
      "Epoch [42/50], Step [311/735], Loss: 0.2441\n",
      "Epoch [42/50], Step [312/735], Loss: 0.1070\n",
      "Epoch [42/50], Step [313/735], Loss: 0.0878\n",
      "Epoch [42/50], Step [314/735], Loss: 0.2064\n",
      "Epoch [42/50], Step [315/735], Loss: 0.0722\n",
      "Epoch [42/50], Step [316/735], Loss: 0.0883\n",
      "Epoch [42/50], Step [317/735], Loss: 0.0660\n",
      "Epoch [42/50], Step [318/735], Loss: 0.6247\n",
      "Epoch [42/50], Step [319/735], Loss: 0.1253\n",
      "Epoch [42/50], Step [320/735], Loss: 0.0652\n",
      "Epoch [42/50], Step [321/735], Loss: 0.0533\n",
      "Epoch [42/50], Step [322/735], Loss: 0.0655\n",
      "Epoch [42/50], Step [323/735], Loss: 0.0674\n",
      "Epoch [42/50], Step [324/735], Loss: 0.1043\n",
      "Epoch [42/50], Step [325/735], Loss: 0.2555\n",
      "Epoch [42/50], Step [326/735], Loss: 0.1247\n",
      "Epoch [42/50], Step [327/735], Loss: 0.0871\n",
      "Epoch [42/50], Step [328/735], Loss: 0.1745\n",
      "Epoch [42/50], Step [329/735], Loss: 0.0950\n",
      "Epoch [42/50], Step [330/735], Loss: 0.1694\n",
      "Epoch [42/50], Step [331/735], Loss: 0.0768\n",
      "Epoch [42/50], Step [332/735], Loss: 0.0617\n",
      "Epoch [42/50], Step [333/735], Loss: 0.1203\n",
      "Epoch [42/50], Step [334/735], Loss: 0.1340\n",
      "Epoch [42/50], Step [335/735], Loss: 0.0415\n",
      "Epoch [42/50], Step [336/735], Loss: 0.1260\n",
      "Epoch [42/50], Step [337/735], Loss: 0.0370\n",
      "Epoch [42/50], Step [338/735], Loss: 0.0473\n",
      "Epoch [42/50], Step [339/735], Loss: 0.0463\n",
      "Epoch [42/50], Step [340/735], Loss: 0.0784\n",
      "Epoch [42/50], Step [341/735], Loss: 0.0541\n",
      "Epoch [42/50], Step [342/735], Loss: 0.0828\n",
      "Epoch [42/50], Step [343/735], Loss: 0.1266\n",
      "Epoch [42/50], Step [344/735], Loss: 0.0299\n",
      "Epoch [42/50], Step [345/735], Loss: 0.0311\n",
      "Epoch [42/50], Step [346/735], Loss: 0.0653\n",
      "Epoch [42/50], Step [347/735], Loss: 0.0577\n",
      "Epoch [42/50], Step [348/735], Loss: 0.0299\n",
      "Epoch [42/50], Step [349/735], Loss: 0.0466\n",
      "Epoch [42/50], Step [350/735], Loss: 0.1074\n",
      "Epoch [42/50], Step [351/735], Loss: 0.0253\n",
      "Epoch [42/50], Step [352/735], Loss: 0.4280\n",
      "Epoch [42/50], Step [353/735], Loss: 0.4419\n",
      "Epoch [42/50], Step [354/735], Loss: 0.0686\n",
      "Epoch [42/50], Step [355/735], Loss: 0.0542\n",
      "Epoch [42/50], Step [356/735], Loss: 0.0989\n",
      "Epoch [42/50], Step [357/735], Loss: 0.0739\n",
      "Epoch [42/50], Step [358/735], Loss: 0.0829\n",
      "Epoch [42/50], Step [359/735], Loss: 0.0689\n",
      "Epoch [42/50], Step [360/735], Loss: 0.0493\n",
      "Epoch [42/50], Step [361/735], Loss: 0.0417\n",
      "Epoch [42/50], Step [362/735], Loss: 0.0410\n",
      "Epoch [42/50], Step [363/735], Loss: 0.0585\n",
      "Epoch [42/50], Step [364/735], Loss: 0.0384\n",
      "Epoch [42/50], Step [365/735], Loss: 0.0614\n",
      "Epoch [42/50], Step [366/735], Loss: 0.2506\n",
      "Epoch [42/50], Step [367/735], Loss: 0.0669\n",
      "Epoch [42/50], Step [368/735], Loss: 0.0294\n",
      "Epoch [42/50], Step [369/735], Loss: 0.0484\n",
      "Epoch [42/50], Step [370/735], Loss: 0.0597\n",
      "Epoch [42/50], Step [371/735], Loss: 0.0985\n",
      "Epoch [42/50], Step [372/735], Loss: 0.0589\n",
      "Epoch [42/50], Step [373/735], Loss: 0.1974\n",
      "Epoch [42/50], Step [374/735], Loss: 0.0955\n",
      "Epoch [42/50], Step [375/735], Loss: 0.1765\n",
      "Epoch [42/50], Step [376/735], Loss: 0.0871\n",
      "Epoch [42/50], Step [377/735], Loss: 0.0614\n",
      "Epoch [42/50], Step [378/735], Loss: 0.0489\n",
      "Epoch [42/50], Step [379/735], Loss: 0.0439\n",
      "Epoch [42/50], Step [380/735], Loss: 0.0449\n",
      "Epoch [42/50], Step [381/735], Loss: 0.1212\n",
      "Epoch [42/50], Step [382/735], Loss: 0.4562\n",
      "Epoch [42/50], Step [383/735], Loss: 0.1576\n",
      "Epoch [42/50], Step [384/735], Loss: 0.0669\n",
      "Epoch [42/50], Step [385/735], Loss: 0.0315\n",
      "Epoch [42/50], Step [386/735], Loss: 0.1237\n",
      "Epoch [42/50], Step [387/735], Loss: 0.0852\n",
      "Epoch [42/50], Step [388/735], Loss: 0.0484\n",
      "Epoch [42/50], Step [389/735], Loss: 0.1743\n",
      "Epoch [42/50], Step [390/735], Loss: 0.0582\n",
      "Epoch [42/50], Step [391/735], Loss: 0.0645\n",
      "Epoch [42/50], Step [392/735], Loss: 0.0663\n",
      "Epoch [42/50], Step [393/735], Loss: 0.0581\n",
      "Epoch [42/50], Step [394/735], Loss: 0.0931\n",
      "Epoch [42/50], Step [395/735], Loss: 0.1306\n",
      "Epoch [42/50], Step [396/735], Loss: 0.0889\n",
      "Epoch [42/50], Step [397/735], Loss: 0.0852\n",
      "Epoch [42/50], Step [398/735], Loss: 0.0670\n",
      "Epoch [42/50], Step [399/735], Loss: 0.0523\n",
      "Epoch [42/50], Step [400/735], Loss: 0.0814\n",
      "Epoch [42/50], Step [401/735], Loss: 0.1833\n",
      "Epoch [42/50], Step [402/735], Loss: 1.3198\n",
      "Epoch [42/50], Step [403/735], Loss: 0.0906\n",
      "Epoch [42/50], Step [404/735], Loss: 0.0469\n",
      "Epoch [42/50], Step [405/735], Loss: 0.0884\n",
      "Epoch [42/50], Step [406/735], Loss: 0.0962\n",
      "Epoch [42/50], Step [407/735], Loss: 0.0779\n",
      "Epoch [42/50], Step [408/735], Loss: 0.0778\n",
      "Epoch [42/50], Step [409/735], Loss: 0.1223\n",
      "Epoch [42/50], Step [410/735], Loss: 0.0506\n",
      "Epoch [42/50], Step [411/735], Loss: 0.2566\n",
      "Epoch [42/50], Step [412/735], Loss: 0.1050\n",
      "Epoch [42/50], Step [413/735], Loss: 0.1042\n",
      "Epoch [42/50], Step [414/735], Loss: 0.0953\n",
      "Epoch [42/50], Step [415/735], Loss: 0.1175\n",
      "Epoch [42/50], Step [416/735], Loss: 1.6731\n",
      "Epoch [42/50], Step [417/735], Loss: 0.3084\n",
      "Epoch [42/50], Step [418/735], Loss: 0.0541\n",
      "Epoch [42/50], Step [419/735], Loss: 2.0296\n",
      "Epoch [42/50], Step [420/735], Loss: 0.1510\n",
      "Epoch [42/50], Step [421/735], Loss: 0.0808\n",
      "Epoch [42/50], Step [422/735], Loss: 0.0716\n",
      "Epoch [42/50], Step [423/735], Loss: 0.1105\n",
      "Epoch [42/50], Step [424/735], Loss: 0.0920\n",
      "Epoch [42/50], Step [425/735], Loss: 0.0854\n",
      "Epoch [42/50], Step [426/735], Loss: 0.1902\n",
      "Epoch [42/50], Step [427/735], Loss: 0.0769\n",
      "Epoch [42/50], Step [428/735], Loss: 0.0811\n",
      "Epoch [42/50], Step [429/735], Loss: 0.0781\n",
      "Epoch [42/50], Step [430/735], Loss: 0.0329\n",
      "Epoch [42/50], Step [431/735], Loss: 0.2639\n",
      "Epoch [42/50], Step [432/735], Loss: 0.0567\n",
      "Epoch [42/50], Step [433/735], Loss: 0.0800\n",
      "Epoch [42/50], Step [434/735], Loss: 0.0289\n",
      "Epoch [42/50], Step [435/735], Loss: 0.1001\n",
      "Epoch [42/50], Step [436/735], Loss: 0.0795\n",
      "Epoch [42/50], Step [437/735], Loss: 0.0967\n",
      "Epoch [42/50], Step [438/735], Loss: 0.0451\n",
      "Epoch [42/50], Step [439/735], Loss: 0.0960\n",
      "Epoch [42/50], Step [440/735], Loss: 0.0556\n",
      "Epoch [42/50], Step [441/735], Loss: 0.0523\n",
      "Epoch [42/50], Step [442/735], Loss: 0.0719\n",
      "Epoch [42/50], Step [443/735], Loss: 0.0667\n",
      "Epoch [42/50], Step [444/735], Loss: 0.1102\n",
      "Epoch [42/50], Step [445/735], Loss: 0.2264\n",
      "Epoch [42/50], Step [446/735], Loss: 0.0815\n",
      "Epoch [42/50], Step [447/735], Loss: 0.5199\n",
      "Epoch [42/50], Step [448/735], Loss: 0.0448\n",
      "Epoch [42/50], Step [449/735], Loss: 0.0255\n",
      "Epoch [42/50], Step [450/735], Loss: 0.3263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Step [451/735], Loss: 0.0713\n",
      "Epoch [42/50], Step [452/735], Loss: 0.0931\n",
      "Epoch [42/50], Step [453/735], Loss: 0.0755\n",
      "Epoch [42/50], Step [454/735], Loss: 1.1246\n",
      "Epoch [42/50], Step [455/735], Loss: 0.0719\n",
      "Epoch [42/50], Step [456/735], Loss: 0.0854\n",
      "Epoch [42/50], Step [457/735], Loss: 0.1100\n",
      "Epoch [42/50], Step [458/735], Loss: 0.0971\n",
      "Epoch [42/50], Step [459/735], Loss: 0.0940\n",
      "Epoch [42/50], Step [460/735], Loss: 0.0745\n",
      "Epoch [42/50], Step [461/735], Loss: 0.0892\n",
      "Epoch [42/50], Step [462/735], Loss: 0.2001\n",
      "Epoch [42/50], Step [463/735], Loss: 0.1211\n",
      "Epoch [42/50], Step [464/735], Loss: 0.0901\n",
      "Epoch [42/50], Step [465/735], Loss: 0.1769\n",
      "Epoch [42/50], Step [466/735], Loss: 0.0474\n",
      "Epoch [42/50], Step [467/735], Loss: 0.0688\n",
      "Epoch [42/50], Step [468/735], Loss: 0.3497\n",
      "Epoch [42/50], Step [469/735], Loss: 0.0556\n",
      "Epoch [42/50], Step [470/735], Loss: 0.1278\n",
      "Epoch [42/50], Step [471/735], Loss: 0.0528\n",
      "Epoch [42/50], Step [472/735], Loss: 0.3247\n",
      "Epoch [42/50], Step [473/735], Loss: 0.1378\n",
      "Epoch [42/50], Step [474/735], Loss: 0.1019\n",
      "Epoch [42/50], Step [475/735], Loss: 0.1138\n",
      "Epoch [42/50], Step [476/735], Loss: 0.0709\n",
      "Epoch [42/50], Step [477/735], Loss: 0.0639\n",
      "Epoch [42/50], Step [478/735], Loss: 0.0425\n",
      "Epoch [42/50], Step [479/735], Loss: 0.1172\n",
      "Epoch [42/50], Step [480/735], Loss: 0.0664\n",
      "Epoch [42/50], Step [481/735], Loss: 0.1157\n",
      "Epoch [42/50], Step [482/735], Loss: 0.0630\n",
      "Epoch [42/50], Step [483/735], Loss: 0.0527\n",
      "Epoch [42/50], Step [484/735], Loss: 0.4734\n",
      "Epoch [42/50], Step [485/735], Loss: 0.0621\n",
      "Epoch [42/50], Step [486/735], Loss: 0.1545\n",
      "Epoch [42/50], Step [487/735], Loss: 0.0776\n",
      "Epoch [42/50], Step [488/735], Loss: 0.1637\n",
      "Epoch [42/50], Step [489/735], Loss: 0.0737\n",
      "Epoch [42/50], Step [490/735], Loss: 0.1096\n",
      "Epoch [42/50], Step [491/735], Loss: 0.0468\n",
      "Epoch [42/50], Step [492/735], Loss: 0.1021\n",
      "Epoch [42/50], Step [493/735], Loss: 0.1622\n",
      "Epoch [42/50], Step [494/735], Loss: 0.0344\n",
      "Epoch [42/50], Step [495/735], Loss: 0.0907\n",
      "Epoch [42/50], Step [496/735], Loss: 0.9807\n",
      "Epoch [42/50], Step [497/735], Loss: 0.0835\n",
      "Epoch [42/50], Step [498/735], Loss: 0.0717\n",
      "Epoch [42/50], Step [499/735], Loss: 0.0408\n",
      "Epoch [42/50], Step [500/735], Loss: 0.0996\n",
      "Epoch [42/50], Step [501/735], Loss: 0.1051\n",
      "Epoch [42/50], Step [502/735], Loss: 0.1150\n",
      "Epoch [42/50], Step [503/735], Loss: 0.0642\n",
      "Epoch [42/50], Step [504/735], Loss: 0.2357\n",
      "Epoch [42/50], Step [505/735], Loss: 0.1218\n",
      "Epoch [42/50], Step [506/735], Loss: 0.0658\n",
      "Epoch [42/50], Step [507/735], Loss: 0.1533\n",
      "Epoch [42/50], Step [508/735], Loss: 0.1156\n",
      "Epoch [42/50], Step [509/735], Loss: 0.3522\n",
      "Epoch [42/50], Step [510/735], Loss: 0.0521\n",
      "Epoch [42/50], Step [511/735], Loss: 0.0620\n",
      "Epoch [42/50], Step [512/735], Loss: 0.1838\n",
      "Epoch [42/50], Step [513/735], Loss: 0.0830\n",
      "Epoch [42/50], Step [514/735], Loss: 0.0835\n",
      "Epoch [42/50], Step [515/735], Loss: 0.0480\n",
      "Epoch [42/50], Step [516/735], Loss: 0.2356\n",
      "Epoch [42/50], Step [517/735], Loss: 0.1275\n",
      "Epoch [42/50], Step [518/735], Loss: 0.0302\n",
      "Epoch [42/50], Step [519/735], Loss: 0.0730\n",
      "Epoch [42/50], Step [520/735], Loss: 0.1128\n",
      "Epoch [42/50], Step [521/735], Loss: 0.1403\n",
      "Epoch [42/50], Step [522/735], Loss: 0.0493\n",
      "Epoch [42/50], Step [523/735], Loss: 0.0810\n",
      "Epoch [42/50], Step [524/735], Loss: 0.2240\n",
      "Epoch [42/50], Step [525/735], Loss: 0.5737\n",
      "Epoch [42/50], Step [526/735], Loss: 0.1431\n",
      "Epoch [42/50], Step [527/735], Loss: 0.6603\n",
      "Epoch [42/50], Step [528/735], Loss: 0.0790\n",
      "Epoch [42/50], Step [529/735], Loss: 0.1273\n",
      "Epoch [42/50], Step [530/735], Loss: 0.0809\n",
      "Epoch [42/50], Step [531/735], Loss: 0.0822\n",
      "Epoch [42/50], Step [532/735], Loss: 0.1119\n",
      "Epoch [42/50], Step [533/735], Loss: 0.0639\n",
      "Epoch [42/50], Step [534/735], Loss: 0.0539\n",
      "Epoch [42/50], Step [535/735], Loss: 0.0744\n",
      "Epoch [42/50], Step [536/735], Loss: 0.0800\n",
      "Epoch [42/50], Step [537/735], Loss: 0.1411\n",
      "Epoch [42/50], Step [538/735], Loss: 0.1531\n",
      "Epoch [42/50], Step [539/735], Loss: 0.0647\n",
      "Epoch [42/50], Step [540/735], Loss: 0.1571\n",
      "Epoch [42/50], Step [541/735], Loss: 0.0662\n",
      "Epoch [42/50], Step [542/735], Loss: 0.1504\n",
      "Epoch [42/50], Step [543/735], Loss: 0.3721\n",
      "Epoch [42/50], Step [544/735], Loss: 0.1170\n",
      "Epoch [42/50], Step [545/735], Loss: 0.0928\n",
      "Epoch [42/50], Step [546/735], Loss: 0.2260\n",
      "Epoch [42/50], Step [547/735], Loss: 0.1670\n",
      "Epoch [42/50], Step [548/735], Loss: 0.0397\n",
      "Epoch [42/50], Step [549/735], Loss: 0.1180\n",
      "Epoch [42/50], Step [550/735], Loss: 0.0701\n",
      "Epoch [42/50], Step [551/735], Loss: 0.0547\n",
      "Epoch [42/50], Step [552/735], Loss: 0.2370\n",
      "Epoch [42/50], Step [553/735], Loss: 0.0530\n",
      "Epoch [42/50], Step [554/735], Loss: 0.1743\n",
      "Epoch [42/50], Step [555/735], Loss: 0.1545\n",
      "Epoch [42/50], Step [556/735], Loss: 0.1014\n",
      "Epoch [42/50], Step [557/735], Loss: 0.3502\n",
      "Epoch [42/50], Step [558/735], Loss: 0.2075\n",
      "Epoch [42/50], Step [559/735], Loss: 0.1760\n",
      "Epoch [42/50], Step [560/735], Loss: 0.0611\n",
      "Epoch [42/50], Step [561/735], Loss: 0.0534\n",
      "Epoch [42/50], Step [562/735], Loss: 0.0280\n",
      "Epoch [42/50], Step [563/735], Loss: 0.0641\n",
      "Epoch [42/50], Step [564/735], Loss: 0.0721\n",
      "Epoch [42/50], Step [565/735], Loss: 0.0937\n",
      "Epoch [42/50], Step [566/735], Loss: 0.0432\n",
      "Epoch [42/50], Step [567/735], Loss: 0.0328\n",
      "Epoch [42/50], Step [568/735], Loss: 0.1237\n",
      "Epoch [42/50], Step [569/735], Loss: 0.0531\n",
      "Epoch [42/50], Step [570/735], Loss: 0.0811\n",
      "Epoch [42/50], Step [571/735], Loss: 0.0807\n",
      "Epoch [42/50], Step [572/735], Loss: 1.9839\n",
      "Epoch [42/50], Step [573/735], Loss: 0.0393\n",
      "Epoch [42/50], Step [574/735], Loss: 0.3295\n",
      "Epoch [42/50], Step [575/735], Loss: 0.0350\n",
      "Epoch [42/50], Step [576/735], Loss: 0.0958\n",
      "Epoch [42/50], Step [577/735], Loss: 0.0592\n",
      "Epoch [42/50], Step [578/735], Loss: 0.2899\n",
      "Epoch [42/50], Step [579/735], Loss: 0.0597\n",
      "Epoch [42/50], Step [580/735], Loss: 0.3658\n",
      "Epoch [42/50], Step [581/735], Loss: 0.1159\n",
      "Epoch [42/50], Step [582/735], Loss: 0.0626\n",
      "Epoch [42/50], Step [583/735], Loss: 0.1398\n",
      "Epoch [42/50], Step [584/735], Loss: 0.0526\n",
      "Epoch [42/50], Step [585/735], Loss: 0.0689\n",
      "Epoch [42/50], Step [586/735], Loss: 0.1684\n",
      "Epoch [42/50], Step [587/735], Loss: 0.0601\n",
      "Epoch [42/50], Step [588/735], Loss: 0.6670\n",
      "Epoch [42/50], Step [589/735], Loss: 0.0734\n",
      "Epoch [42/50], Step [590/735], Loss: 0.0333\n",
      "Epoch [42/50], Step [591/735], Loss: 0.1682\n",
      "Epoch [42/50], Step [592/735], Loss: 0.0490\n",
      "Epoch [42/50], Step [593/735], Loss: 0.0994\n",
      "Epoch [42/50], Step [594/735], Loss: 0.1450\n",
      "Epoch [42/50], Step [595/735], Loss: 0.0738\n",
      "Epoch [42/50], Step [596/735], Loss: 0.1408\n",
      "Epoch [42/50], Step [597/735], Loss: 0.0870\n",
      "Epoch [42/50], Step [598/735], Loss: 0.0902\n",
      "Epoch [42/50], Step [599/735], Loss: 0.1169\n",
      "Epoch [42/50], Step [600/735], Loss: 0.0882\n",
      "Epoch [42/50], Step [601/735], Loss: 0.1729\n",
      "Epoch [42/50], Step [602/735], Loss: 0.0316\n",
      "Epoch [42/50], Step [603/735], Loss: 0.0666\n",
      "Epoch [42/50], Step [604/735], Loss: 0.1350\n",
      "Epoch [42/50], Step [605/735], Loss: 0.0288\n",
      "Epoch [42/50], Step [606/735], Loss: 0.1776\n",
      "Epoch [42/50], Step [607/735], Loss: 0.0686\n",
      "Epoch [42/50], Step [608/735], Loss: 0.0671\n",
      "Epoch [42/50], Step [609/735], Loss: 0.0662\n",
      "Epoch [42/50], Step [610/735], Loss: 0.2405\n",
      "Epoch [42/50], Step [611/735], Loss: 0.0654\n",
      "Epoch [42/50], Step [612/735], Loss: 0.1329\n",
      "Epoch [42/50], Step [613/735], Loss: 0.1236\n",
      "Epoch [42/50], Step [614/735], Loss: 0.0952\n",
      "Epoch [42/50], Step [615/735], Loss: 0.1507\n",
      "Epoch [42/50], Step [616/735], Loss: 0.0573\n",
      "Epoch [42/50], Step [617/735], Loss: 0.0598\n",
      "Epoch [42/50], Step [618/735], Loss: 0.1555\n",
      "Epoch [42/50], Step [619/735], Loss: 0.0373\n",
      "Epoch [42/50], Step [620/735], Loss: 0.0706\n",
      "Epoch [42/50], Step [621/735], Loss: 0.0865\n",
      "Epoch [42/50], Step [622/735], Loss: 0.1264\n",
      "Epoch [42/50], Step [623/735], Loss: 0.0948\n",
      "Epoch [42/50], Step [624/735], Loss: 0.1526\n",
      "Epoch [42/50], Step [625/735], Loss: 0.1764\n",
      "Epoch [42/50], Step [626/735], Loss: 0.1380\n",
      "Epoch [42/50], Step [627/735], Loss: 0.0660\n",
      "Epoch [42/50], Step [628/735], Loss: 0.0387\n",
      "Epoch [42/50], Step [629/735], Loss: 0.1094\n",
      "Epoch [42/50], Step [630/735], Loss: 0.0725\n",
      "Epoch [42/50], Step [631/735], Loss: 0.0771\n",
      "Epoch [42/50], Step [632/735], Loss: 0.1826\n",
      "Epoch [42/50], Step [633/735], Loss: 0.1175\n",
      "Epoch [42/50], Step [634/735], Loss: 0.2205\n",
      "Epoch [42/50], Step [635/735], Loss: 0.1057\n",
      "Epoch [42/50], Step [636/735], Loss: 1.1892\n",
      "Epoch [42/50], Step [637/735], Loss: 0.0678\n",
      "Epoch [42/50], Step [638/735], Loss: 1.9190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Step [639/735], Loss: 0.0501\n",
      "Epoch [42/50], Step [640/735], Loss: 0.0260\n",
      "Epoch [42/50], Step [641/735], Loss: 0.1087\n",
      "Epoch [42/50], Step [642/735], Loss: 0.0378\n",
      "Epoch [42/50], Step [643/735], Loss: 0.0650\n",
      "Epoch [42/50], Step [644/735], Loss: 0.0399\n",
      "Epoch [42/50], Step [645/735], Loss: 0.1159\n",
      "Epoch [42/50], Step [646/735], Loss: 0.1124\n",
      "Epoch [42/50], Step [647/735], Loss: 0.0388\n",
      "Epoch [42/50], Step [648/735], Loss: 0.1109\n",
      "Epoch [42/50], Step [649/735], Loss: 0.1104\n",
      "Epoch [42/50], Step [650/735], Loss: 0.0907\n",
      "Epoch [42/50], Step [651/735], Loss: 0.0825\n",
      "Epoch [42/50], Step [652/735], Loss: 0.2386\n",
      "Epoch [42/50], Step [653/735], Loss: 0.1709\n",
      "Epoch [42/50], Step [654/735], Loss: 0.1232\n",
      "Epoch [42/50], Step [655/735], Loss: 0.0536\n",
      "Epoch [42/50], Step [656/735], Loss: 0.1443\n",
      "Epoch [42/50], Step [657/735], Loss: 0.0837\n",
      "Epoch [42/50], Step [658/735], Loss: 0.2199\n",
      "Epoch [42/50], Step [659/735], Loss: 0.0781\n",
      "Epoch [42/50], Step [660/735], Loss: 0.0746\n",
      "Epoch [42/50], Step [661/735], Loss: 0.0987\n",
      "Epoch [42/50], Step [662/735], Loss: 0.1146\n",
      "Epoch [42/50], Step [663/735], Loss: 0.0757\n",
      "Epoch [42/50], Step [664/735], Loss: 0.0966\n",
      "Epoch [42/50], Step [665/735], Loss: 0.0901\n",
      "Epoch [42/50], Step [666/735], Loss: 0.0336\n",
      "Epoch [42/50], Step [667/735], Loss: 0.0721\n",
      "Epoch [42/50], Step [668/735], Loss: 0.1109\n",
      "Epoch [42/50], Step [669/735], Loss: 0.0989\n",
      "Epoch [42/50], Step [670/735], Loss: 0.1111\n",
      "Epoch [42/50], Step [671/735], Loss: 0.1312\n",
      "Epoch [42/50], Step [672/735], Loss: 0.0831\n",
      "Epoch [42/50], Step [673/735], Loss: 0.1450\n",
      "Epoch [42/50], Step [674/735], Loss: 0.0755\n",
      "Epoch [42/50], Step [675/735], Loss: 0.0645\n",
      "Epoch [42/50], Step [676/735], Loss: 0.0378\n",
      "Epoch [42/50], Step [677/735], Loss: 0.1561\n",
      "Epoch [42/50], Step [678/735], Loss: 0.0860\n",
      "Epoch [42/50], Step [679/735], Loss: 0.0650\n",
      "Epoch [42/50], Step [680/735], Loss: 0.1251\n",
      "Epoch [42/50], Step [681/735], Loss: 0.1115\n",
      "Epoch [42/50], Step [682/735], Loss: 0.0617\n",
      "Epoch [42/50], Step [683/735], Loss: 0.0447\n",
      "Epoch [42/50], Step [684/735], Loss: 0.0644\n",
      "Epoch [42/50], Step [685/735], Loss: 0.0978\n",
      "Epoch [42/50], Step [686/735], Loss: 0.0761\n",
      "Epoch [42/50], Step [687/735], Loss: 0.0336\n",
      "Epoch [42/50], Step [688/735], Loss: 0.3666\n",
      "Epoch [42/50], Step [689/735], Loss: 0.0543\n",
      "Epoch [42/50], Step [690/735], Loss: 0.0989\n",
      "Epoch [42/50], Step [691/735], Loss: 0.0479\n",
      "Epoch [42/50], Step [692/735], Loss: 0.0441\n",
      "Epoch [42/50], Step [693/735], Loss: 1.6932\n",
      "Epoch [42/50], Step [694/735], Loss: 0.1157\n",
      "Epoch [42/50], Step [695/735], Loss: 0.1343\n",
      "Epoch [42/50], Step [696/735], Loss: 0.0437\n",
      "Epoch [42/50], Step [697/735], Loss: 0.3974\n",
      "Epoch [42/50], Step [698/735], Loss: 0.0830\n",
      "Epoch [42/50], Step [699/735], Loss: 0.1172\n",
      "Epoch [42/50], Step [700/735], Loss: 0.0410\n",
      "Epoch [42/50], Step [701/735], Loss: 0.1021\n",
      "Epoch [42/50], Step [702/735], Loss: 0.1577\n",
      "Epoch [42/50], Step [703/735], Loss: 0.0356\n",
      "Epoch [42/50], Step [704/735], Loss: 0.0789\n",
      "Epoch [42/50], Step [705/735], Loss: 0.0601\n",
      "Epoch [42/50], Step [706/735], Loss: 0.1350\n",
      "Epoch [42/50], Step [707/735], Loss: 0.0901\n",
      "Epoch [42/50], Step [708/735], Loss: 0.0434\n",
      "Epoch [42/50], Step [709/735], Loss: 0.0391\n",
      "Epoch [42/50], Step [710/735], Loss: 0.0600\n",
      "Epoch [42/50], Step [711/735], Loss: 1.6749\n",
      "Epoch [42/50], Step [712/735], Loss: 0.0967\n",
      "Epoch [42/50], Step [713/735], Loss: 0.0467\n",
      "Epoch [42/50], Step [714/735], Loss: 0.0520\n",
      "Epoch [42/50], Step [715/735], Loss: 0.0582\n",
      "Epoch [42/50], Step [716/735], Loss: 0.0367\n",
      "Epoch [42/50], Step [717/735], Loss: 0.0661\n",
      "Epoch [42/50], Step [718/735], Loss: 0.0680\n",
      "Epoch [42/50], Step [719/735], Loss: 0.0319\n",
      "Epoch [42/50], Step [720/735], Loss: 0.0541\n",
      "Epoch [42/50], Step [721/735], Loss: 0.0384\n",
      "Epoch [42/50], Step [722/735], Loss: 0.1813\n",
      "Epoch [42/50], Step [723/735], Loss: 0.8113\n",
      "Epoch [42/50], Step [724/735], Loss: 0.0805\n",
      "Epoch [42/50], Step [725/735], Loss: 0.0829\n",
      "Epoch [42/50], Step [726/735], Loss: 0.0704\n",
      "Epoch [42/50], Step [727/735], Loss: 0.1696\n",
      "Epoch [42/50], Step [728/735], Loss: 0.1045\n",
      "Epoch [42/50], Step [729/735], Loss: 0.0902\n",
      "Epoch [42/50], Step [730/735], Loss: 0.0346\n",
      "Epoch [42/50], Step [731/735], Loss: 0.0371\n",
      "Epoch [42/50], Step [732/735], Loss: 0.1026\n",
      "Epoch [42/50], Step [733/735], Loss: 0.0986\n",
      "Epoch [42/50], Step [734/735], Loss: 0.0597\n",
      "Epoch [42/50], Step [735/735], Loss: 0.1132\n",
      "Epoch [43/50], Step [1/735], Loss: 0.0680\n",
      "Epoch [43/50], Step [2/735], Loss: 0.0613\n",
      "Epoch [43/50], Step [3/735], Loss: 0.1017\n",
      "Epoch [43/50], Step [4/735], Loss: 0.0422\n",
      "Epoch [43/50], Step [5/735], Loss: 0.0612\n",
      "Epoch [43/50], Step [6/735], Loss: 0.0696\n",
      "Epoch [43/50], Step [7/735], Loss: 0.1889\n",
      "Epoch [43/50], Step [8/735], Loss: 0.0658\n",
      "Epoch [43/50], Step [9/735], Loss: 0.1263\n",
      "Epoch [43/50], Step [10/735], Loss: 0.1525\n",
      "Epoch [43/50], Step [11/735], Loss: 0.0581\n",
      "Epoch [43/50], Step [12/735], Loss: 0.0471\n",
      "Epoch [43/50], Step [13/735], Loss: 0.4836\n",
      "Epoch [43/50], Step [14/735], Loss: 0.6431\n",
      "Epoch [43/50], Step [15/735], Loss: 0.1147\n",
      "Epoch [43/50], Step [16/735], Loss: 0.1311\n",
      "Epoch [43/50], Step [17/735], Loss: 0.0447\n",
      "Epoch [43/50], Step [18/735], Loss: 0.1642\n",
      "Epoch [43/50], Step [19/735], Loss: 0.1109\n",
      "Epoch [43/50], Step [20/735], Loss: 0.0665\n",
      "Epoch [43/50], Step [21/735], Loss: 0.1629\n",
      "Epoch [43/50], Step [22/735], Loss: 0.0417\n",
      "Epoch [43/50], Step [23/735], Loss: 0.0594\n",
      "Epoch [43/50], Step [24/735], Loss: 0.0454\n",
      "Epoch [43/50], Step [25/735], Loss: 0.1816\n",
      "Epoch [43/50], Step [26/735], Loss: 0.0911\n",
      "Epoch [43/50], Step [27/735], Loss: 0.1038\n",
      "Epoch [43/50], Step [28/735], Loss: 0.0699\n",
      "Epoch [43/50], Step [29/735], Loss: 0.0559\n",
      "Epoch [43/50], Step [30/735], Loss: 0.5382\n",
      "Epoch [43/50], Step [31/735], Loss: 0.0742\n",
      "Epoch [43/50], Step [32/735], Loss: 0.1611\n",
      "Epoch [43/50], Step [33/735], Loss: 0.3694\n",
      "Epoch [43/50], Step [34/735], Loss: 0.1152\n",
      "Epoch [43/50], Step [35/735], Loss: 0.0858\n",
      "Epoch [43/50], Step [36/735], Loss: 0.1225\n",
      "Epoch [43/50], Step [37/735], Loss: 0.0443\n",
      "Epoch [43/50], Step [38/735], Loss: 0.3753\n",
      "Epoch [43/50], Step [39/735], Loss: 0.1044\n",
      "Epoch [43/50], Step [40/735], Loss: 0.0378\n",
      "Epoch [43/50], Step [41/735], Loss: 0.0947\n",
      "Epoch [43/50], Step [42/735], Loss: 0.0435\n",
      "Epoch [43/50], Step [43/735], Loss: 0.2565\n",
      "Epoch [43/50], Step [44/735], Loss: 0.0890\n",
      "Epoch [43/50], Step [45/735], Loss: 0.1042\n",
      "Epoch [43/50], Step [46/735], Loss: 0.0770\n",
      "Epoch [43/50], Step [47/735], Loss: 0.3424\n",
      "Epoch [43/50], Step [48/735], Loss: 0.0951\n",
      "Epoch [43/50], Step [49/735], Loss: 0.4295\n",
      "Epoch [43/50], Step [50/735], Loss: 0.1055\n",
      "Epoch [43/50], Step [51/735], Loss: 0.4396\n",
      "Epoch [43/50], Step [52/735], Loss: 0.1815\n",
      "Epoch [43/50], Step [53/735], Loss: 0.1156\n",
      "Epoch [43/50], Step [54/735], Loss: 0.1719\n",
      "Epoch [43/50], Step [55/735], Loss: 0.1382\n",
      "Epoch [43/50], Step [56/735], Loss: 0.0620\n",
      "Epoch [43/50], Step [57/735], Loss: 0.0657\n",
      "Epoch [43/50], Step [58/735], Loss: 0.0543\n",
      "Epoch [43/50], Step [59/735], Loss: 1.6578\n",
      "Epoch [43/50], Step [60/735], Loss: 0.0725\n",
      "Epoch [43/50], Step [61/735], Loss: 0.1042\n",
      "Epoch [43/50], Step [62/735], Loss: 0.7613\n",
      "Epoch [43/50], Step [63/735], Loss: 0.1004\n",
      "Epoch [43/50], Step [64/735], Loss: 0.1174\n",
      "Epoch [43/50], Step [65/735], Loss: 0.0463\n",
      "Epoch [43/50], Step [66/735], Loss: 0.1396\n",
      "Epoch [43/50], Step [67/735], Loss: 0.3744\n",
      "Epoch [43/50], Step [68/735], Loss: 0.0642\n",
      "Epoch [43/50], Step [69/735], Loss: 0.1855\n",
      "Epoch [43/50], Step [70/735], Loss: 0.0749\n",
      "Epoch [43/50], Step [71/735], Loss: 0.3062\n",
      "Epoch [43/50], Step [72/735], Loss: 0.1398\n",
      "Epoch [43/50], Step [73/735], Loss: 0.2125\n",
      "Epoch [43/50], Step [74/735], Loss: 0.0759\n",
      "Epoch [43/50], Step [75/735], Loss: 0.0932\n",
      "Epoch [43/50], Step [76/735], Loss: 0.0844\n",
      "Epoch [43/50], Step [77/735], Loss: 0.0966\n",
      "Epoch [43/50], Step [78/735], Loss: 0.0228\n",
      "Epoch [43/50], Step [79/735], Loss: 0.0616\n",
      "Epoch [43/50], Step [80/735], Loss: 0.0536\n",
      "Epoch [43/50], Step [81/735], Loss: 0.0379\n",
      "Epoch [43/50], Step [82/735], Loss: 0.0281\n",
      "Epoch [43/50], Step [83/735], Loss: 0.0618\n",
      "Epoch [43/50], Step [84/735], Loss: 0.0846\n",
      "Epoch [43/50], Step [85/735], Loss: 0.0359\n",
      "Epoch [43/50], Step [86/735], Loss: 0.0885\n",
      "Epoch [43/50], Step [87/735], Loss: 0.1110\n",
      "Epoch [43/50], Step [88/735], Loss: 0.0769\n",
      "Epoch [43/50], Step [89/735], Loss: 0.1178\n",
      "Epoch [43/50], Step [90/735], Loss: 0.0619\n",
      "Epoch [43/50], Step [91/735], Loss: 0.1134\n",
      "Epoch [43/50], Step [92/735], Loss: 0.0766\n",
      "Epoch [43/50], Step [93/735], Loss: 0.0451\n",
      "Epoch [43/50], Step [94/735], Loss: 0.0781\n",
      "Epoch [43/50], Step [95/735], Loss: 0.0773\n",
      "Epoch [43/50], Step [96/735], Loss: 0.1620\n",
      "Epoch [43/50], Step [97/735], Loss: 0.0788\n",
      "Epoch [43/50], Step [98/735], Loss: 0.0603\n",
      "Epoch [43/50], Step [99/735], Loss: 0.0586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Step [100/735], Loss: 0.2633\n",
      "Epoch [43/50], Step [101/735], Loss: 0.1587\n",
      "Epoch [43/50], Step [102/735], Loss: 0.1557\n",
      "Epoch [43/50], Step [103/735], Loss: 0.1425\n",
      "Epoch [43/50], Step [104/735], Loss: 0.0937\n",
      "Epoch [43/50], Step [105/735], Loss: 0.1297\n",
      "Epoch [43/50], Step [106/735], Loss: 0.0906\n",
      "Epoch [43/50], Step [107/735], Loss: 0.1220\n",
      "Epoch [43/50], Step [108/735], Loss: 0.0383\n",
      "Epoch [43/50], Step [109/735], Loss: 1.4718\n",
      "Epoch [43/50], Step [110/735], Loss: 0.3759\n",
      "Epoch [43/50], Step [111/735], Loss: 0.0952\n",
      "Epoch [43/50], Step [112/735], Loss: 0.0426\n",
      "Epoch [43/50], Step [113/735], Loss: 0.1519\n",
      "Epoch [43/50], Step [114/735], Loss: 0.2902\n",
      "Epoch [43/50], Step [115/735], Loss: 0.0640\n",
      "Epoch [43/50], Step [116/735], Loss: 0.0603\n",
      "Epoch [43/50], Step [117/735], Loss: 0.0770\n",
      "Epoch [43/50], Step [118/735], Loss: 0.0916\n",
      "Epoch [43/50], Step [119/735], Loss: 0.0962\n",
      "Epoch [43/50], Step [120/735], Loss: 0.0856\n",
      "Epoch [43/50], Step [121/735], Loss: 0.1244\n",
      "Epoch [43/50], Step [122/735], Loss: 0.0773\n",
      "Epoch [43/50], Step [123/735], Loss: 0.2212\n",
      "Epoch [43/50], Step [124/735], Loss: 0.1997\n",
      "Epoch [43/50], Step [125/735], Loss: 0.0610\n",
      "Epoch [43/50], Step [126/735], Loss: 0.1133\n",
      "Epoch [43/50], Step [127/735], Loss: 0.5286\n",
      "Epoch [43/50], Step [128/735], Loss: 0.1531\n",
      "Epoch [43/50], Step [129/735], Loss: 0.2106\n",
      "Epoch [43/50], Step [130/735], Loss: 0.0662\n",
      "Epoch [43/50], Step [131/735], Loss: 0.0821\n",
      "Epoch [43/50], Step [132/735], Loss: 0.0905\n",
      "Epoch [43/50], Step [133/735], Loss: 0.1011\n",
      "Epoch [43/50], Step [134/735], Loss: 0.1128\n",
      "Epoch [43/50], Step [135/735], Loss: 0.1374\n",
      "Epoch [43/50], Step [136/735], Loss: 0.1254\n",
      "Epoch [43/50], Step [137/735], Loss: 0.0922\n",
      "Epoch [43/50], Step [138/735], Loss: 0.3125\n",
      "Epoch [43/50], Step [139/735], Loss: 0.0789\n",
      "Epoch [43/50], Step [140/735], Loss: 0.1087\n",
      "Epoch [43/50], Step [141/735], Loss: 0.0922\n",
      "Epoch [43/50], Step [142/735], Loss: 0.0773\n",
      "Epoch [43/50], Step [143/735], Loss: 0.0614\n",
      "Epoch [43/50], Step [144/735], Loss: 0.0905\n",
      "Epoch [43/50], Step [145/735], Loss: 0.2312\n",
      "Epoch [43/50], Step [146/735], Loss: 0.0670\n",
      "Epoch [43/50], Step [147/735], Loss: 0.1535\n",
      "Epoch [43/50], Step [148/735], Loss: 0.0578\n",
      "Epoch [43/50], Step [149/735], Loss: 0.0896\n",
      "Epoch [43/50], Step [150/735], Loss: 0.1500\n",
      "Epoch [43/50], Step [151/735], Loss: 0.0308\n",
      "Epoch [43/50], Step [152/735], Loss: 0.0559\n",
      "Epoch [43/50], Step [153/735], Loss: 0.1137\n",
      "Epoch [43/50], Step [154/735], Loss: 0.0776\n",
      "Epoch [43/50], Step [155/735], Loss: 0.0883\n",
      "Epoch [43/50], Step [156/735], Loss: 0.0486\n",
      "Epoch [43/50], Step [157/735], Loss: 0.0671\n",
      "Epoch [43/50], Step [158/735], Loss: 0.1096\n",
      "Epoch [43/50], Step [159/735], Loss: 0.0353\n",
      "Epoch [43/50], Step [160/735], Loss: 0.1739\n",
      "Epoch [43/50], Step [161/735], Loss: 0.0687\n",
      "Epoch [43/50], Step [162/735], Loss: 0.0327\n",
      "Epoch [43/50], Step [163/735], Loss: 0.2950\n",
      "Epoch [43/50], Step [164/735], Loss: 0.0545\n",
      "Epoch [43/50], Step [165/735], Loss: 0.1038\n",
      "Epoch [43/50], Step [166/735], Loss: 0.0900\n",
      "Epoch [43/50], Step [167/735], Loss: 0.1877\n",
      "Epoch [43/50], Step [168/735], Loss: 0.2637\n",
      "Epoch [43/50], Step [169/735], Loss: 0.1125\n",
      "Epoch [43/50], Step [170/735], Loss: 0.1186\n",
      "Epoch [43/50], Step [171/735], Loss: 0.1030\n",
      "Epoch [43/50], Step [172/735], Loss: 0.1500\n",
      "Epoch [43/50], Step [173/735], Loss: 0.0714\n",
      "Epoch [43/50], Step [174/735], Loss: 0.1835\n",
      "Epoch [43/50], Step [175/735], Loss: 0.3246\n",
      "Epoch [43/50], Step [176/735], Loss: 0.0329\n",
      "Epoch [43/50], Step [177/735], Loss: 0.0334\n",
      "Epoch [43/50], Step [178/735], Loss: 0.1085\n",
      "Epoch [43/50], Step [179/735], Loss: 0.5015\n",
      "Epoch [43/50], Step [180/735], Loss: 0.0774\n",
      "Epoch [43/50], Step [181/735], Loss: 0.0732\n",
      "Epoch [43/50], Step [182/735], Loss: 0.1084\n",
      "Epoch [43/50], Step [183/735], Loss: 0.0306\n",
      "Epoch [43/50], Step [184/735], Loss: 0.0599\n",
      "Epoch [43/50], Step [185/735], Loss: 0.1200\n",
      "Epoch [43/50], Step [186/735], Loss: 0.0889\n",
      "Epoch [43/50], Step [187/735], Loss: 0.0941\n",
      "Epoch [43/50], Step [188/735], Loss: 0.2109\n",
      "Epoch [43/50], Step [189/735], Loss: 0.5084\n",
      "Epoch [43/50], Step [190/735], Loss: 0.0934\n",
      "Epoch [43/50], Step [191/735], Loss: 0.1079\n",
      "Epoch [43/50], Step [192/735], Loss: 0.2126\n",
      "Epoch [43/50], Step [193/735], Loss: 0.1039\n",
      "Epoch [43/50], Step [194/735], Loss: 0.0685\n",
      "Epoch [43/50], Step [195/735], Loss: 0.0402\n",
      "Epoch [43/50], Step [196/735], Loss: 0.1350\n",
      "Epoch [43/50], Step [197/735], Loss: 0.0970\n",
      "Epoch [43/50], Step [198/735], Loss: 0.0866\n",
      "Epoch [43/50], Step [199/735], Loss: 0.1586\n",
      "Epoch [43/50], Step [200/735], Loss: 0.0512\n",
      "Epoch [43/50], Step [201/735], Loss: 0.0770\n",
      "Epoch [43/50], Step [202/735], Loss: 0.0518\n",
      "Epoch [43/50], Step [203/735], Loss: 0.1649\n",
      "Epoch [43/50], Step [204/735], Loss: 0.4409\n",
      "Epoch [43/50], Step [205/735], Loss: 0.0755\n",
      "Epoch [43/50], Step [206/735], Loss: 0.0303\n",
      "Epoch [43/50], Step [207/735], Loss: 0.2388\n",
      "Epoch [43/50], Step [208/735], Loss: 0.1136\n",
      "Epoch [43/50], Step [209/735], Loss: 0.0806\n",
      "Epoch [43/50], Step [210/735], Loss: 0.1803\n",
      "Epoch [43/50], Step [211/735], Loss: 0.1074\n",
      "Epoch [43/50], Step [212/735], Loss: 0.0692\n",
      "Epoch [43/50], Step [213/735], Loss: 0.4720\n",
      "Epoch [43/50], Step [214/735], Loss: 0.1124\n",
      "Epoch [43/50], Step [215/735], Loss: 0.2054\n",
      "Epoch [43/50], Step [216/735], Loss: 0.0425\n",
      "Epoch [43/50], Step [217/735], Loss: 0.0365\n",
      "Epoch [43/50], Step [218/735], Loss: 0.0895\n",
      "Epoch [43/50], Step [219/735], Loss: 0.0962\n",
      "Epoch [43/50], Step [220/735], Loss: 0.1732\n",
      "Epoch [43/50], Step [221/735], Loss: 0.1280\n",
      "Epoch [43/50], Step [222/735], Loss: 0.1203\n",
      "Epoch [43/50], Step [223/735], Loss: 0.0456\n",
      "Epoch [43/50], Step [224/735], Loss: 0.0623\n",
      "Epoch [43/50], Step [225/735], Loss: 0.0843\n",
      "Epoch [43/50], Step [226/735], Loss: 0.1195\n",
      "Epoch [43/50], Step [227/735], Loss: 0.0661\n",
      "Epoch [43/50], Step [228/735], Loss: 0.1456\n",
      "Epoch [43/50], Step [229/735], Loss: 0.0625\n",
      "Epoch [43/50], Step [230/735], Loss: 0.0735\n",
      "Epoch [43/50], Step [231/735], Loss: 0.1607\n",
      "Epoch [43/50], Step [232/735], Loss: 0.0457\n",
      "Epoch [43/50], Step [233/735], Loss: 0.3973\n",
      "Epoch [43/50], Step [234/735], Loss: 0.1021\n",
      "Epoch [43/50], Step [235/735], Loss: 0.0998\n",
      "Epoch [43/50], Step [236/735], Loss: 0.1086\n",
      "Epoch [43/50], Step [237/735], Loss: 0.0453\n",
      "Epoch [43/50], Step [238/735], Loss: 0.1273\n",
      "Epoch [43/50], Step [239/735], Loss: 0.0837\n",
      "Epoch [43/50], Step [240/735], Loss: 0.0936\n",
      "Epoch [43/50], Step [241/735], Loss: 0.0448\n",
      "Epoch [43/50], Step [242/735], Loss: 0.0645\n",
      "Epoch [43/50], Step [243/735], Loss: 0.1136\n",
      "Epoch [43/50], Step [244/735], Loss: 0.0673\n",
      "Epoch [43/50], Step [245/735], Loss: 0.1142\n",
      "Epoch [43/50], Step [246/735], Loss: 0.0549\n",
      "Epoch [43/50], Step [247/735], Loss: 0.0402\n",
      "Epoch [43/50], Step [248/735], Loss: 0.0541\n",
      "Epoch [43/50], Step [249/735], Loss: 0.4948\n",
      "Epoch [43/50], Step [250/735], Loss: 0.0874\n",
      "Epoch [43/50], Step [251/735], Loss: 0.2447\n",
      "Epoch [43/50], Step [252/735], Loss: 0.0554\n",
      "Epoch [43/50], Step [253/735], Loss: 0.0657\n",
      "Epoch [43/50], Step [254/735], Loss: 0.0748\n",
      "Epoch [43/50], Step [255/735], Loss: 0.0658\n",
      "Epoch [43/50], Step [256/735], Loss: 0.2159\n",
      "Epoch [43/50], Step [257/735], Loss: 0.1751\n",
      "Epoch [43/50], Step [258/735], Loss: 0.7964\n",
      "Epoch [43/50], Step [259/735], Loss: 0.0842\n",
      "Epoch [43/50], Step [260/735], Loss: 0.0909\n",
      "Epoch [43/50], Step [261/735], Loss: 0.3566\n",
      "Epoch [43/50], Step [262/735], Loss: 0.0803\n",
      "Epoch [43/50], Step [263/735], Loss: 0.1674\n",
      "Epoch [43/50], Step [264/735], Loss: 0.0544\n",
      "Epoch [43/50], Step [265/735], Loss: 0.0774\n",
      "Epoch [43/50], Step [266/735], Loss: 0.1212\n",
      "Epoch [43/50], Step [267/735], Loss: 0.1003\n",
      "Epoch [43/50], Step [268/735], Loss: 0.0988\n",
      "Epoch [43/50], Step [269/735], Loss: 0.0479\n",
      "Epoch [43/50], Step [270/735], Loss: 0.0971\n",
      "Epoch [43/50], Step [271/735], Loss: 0.2240\n",
      "Epoch [43/50], Step [272/735], Loss: 0.0403\n",
      "Epoch [43/50], Step [273/735], Loss: 0.0620\n",
      "Epoch [43/50], Step [274/735], Loss: 0.0686\n",
      "Epoch [43/50], Step [275/735], Loss: 0.0787\n",
      "Epoch [43/50], Step [276/735], Loss: 0.0832\n",
      "Epoch [43/50], Step [277/735], Loss: 0.1281\n",
      "Epoch [43/50], Step [278/735], Loss: 0.0331\n",
      "Epoch [43/50], Step [279/735], Loss: 0.0752\n",
      "Epoch [43/50], Step [280/735], Loss: 0.0522\n",
      "Epoch [43/50], Step [281/735], Loss: 0.1472\n",
      "Epoch [43/50], Step [282/735], Loss: 0.0365\n",
      "Epoch [43/50], Step [283/735], Loss: 0.1427\n",
      "Epoch [43/50], Step [284/735], Loss: 0.0481\n",
      "Epoch [43/50], Step [285/735], Loss: 0.0571\n",
      "Epoch [43/50], Step [286/735], Loss: 0.1110\n",
      "Epoch [43/50], Step [287/735], Loss: 0.1512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Step [288/735], Loss: 0.0789\n",
      "Epoch [43/50], Step [289/735], Loss: 0.0987\n",
      "Epoch [43/50], Step [290/735], Loss: 0.5201\n",
      "Epoch [43/50], Step [291/735], Loss: 0.0583\n",
      "Epoch [43/50], Step [292/735], Loss: 0.2550\n",
      "Epoch [43/50], Step [293/735], Loss: 0.1006\n",
      "Epoch [43/50], Step [294/735], Loss: 0.1804\n",
      "Epoch [43/50], Step [295/735], Loss: 0.0684\n",
      "Epoch [43/50], Step [296/735], Loss: 0.1076\n",
      "Epoch [43/50], Step [297/735], Loss: 0.0743\n",
      "Epoch [43/50], Step [298/735], Loss: 0.1041\n",
      "Epoch [43/50], Step [299/735], Loss: 0.5331\n",
      "Epoch [43/50], Step [300/735], Loss: 0.0665\n",
      "Epoch [43/50], Step [301/735], Loss: 0.0626\n",
      "Epoch [43/50], Step [302/735], Loss: 0.1548\n",
      "Epoch [43/50], Step [303/735], Loss: 0.0793\n",
      "Epoch [43/50], Step [304/735], Loss: 0.0487\n",
      "Epoch [43/50], Step [305/735], Loss: 0.1306\n",
      "Epoch [43/50], Step [306/735], Loss: 0.1582\n",
      "Epoch [43/50], Step [307/735], Loss: 0.0632\n",
      "Epoch [43/50], Step [308/735], Loss: 0.0811\n",
      "Epoch [43/50], Step [309/735], Loss: 0.1254\n",
      "Epoch [43/50], Step [310/735], Loss: 0.0998\n",
      "Epoch [43/50], Step [311/735], Loss: 0.0852\n",
      "Epoch [43/50], Step [312/735], Loss: 0.0540\n",
      "Epoch [43/50], Step [313/735], Loss: 0.0474\n",
      "Epoch [43/50], Step [314/735], Loss: 0.0609\n",
      "Epoch [43/50], Step [315/735], Loss: 0.1209\n",
      "Epoch [43/50], Step [316/735], Loss: 0.8166\n",
      "Epoch [43/50], Step [317/735], Loss: 0.2310\n",
      "Epoch [43/50], Step [318/735], Loss: 0.1526\n",
      "Epoch [43/50], Step [319/735], Loss: 0.1547\n",
      "Epoch [43/50], Step [320/735], Loss: 0.0485\n",
      "Epoch [43/50], Step [321/735], Loss: 0.1189\n",
      "Epoch [43/50], Step [322/735], Loss: 0.0964\n",
      "Epoch [43/50], Step [323/735], Loss: 0.0770\n",
      "Epoch [43/50], Step [324/735], Loss: 0.0693\n",
      "Epoch [43/50], Step [325/735], Loss: 0.1051\n",
      "Epoch [43/50], Step [326/735], Loss: 0.0682\n",
      "Epoch [43/50], Step [327/735], Loss: 0.0737\n",
      "Epoch [43/50], Step [328/735], Loss: 0.1574\n",
      "Epoch [43/50], Step [329/735], Loss: 0.0577\n",
      "Epoch [43/50], Step [330/735], Loss: 0.0418\n",
      "Epoch [43/50], Step [331/735], Loss: 0.0398\n",
      "Epoch [43/50], Step [332/735], Loss: 0.0322\n",
      "Epoch [43/50], Step [333/735], Loss: 0.0605\n",
      "Epoch [43/50], Step [334/735], Loss: 0.0560\n",
      "Epoch [43/50], Step [335/735], Loss: 0.0563\n",
      "Epoch [43/50], Step [336/735], Loss: 0.0695\n",
      "Epoch [43/50], Step [337/735], Loss: 0.1492\n",
      "Epoch [43/50], Step [338/735], Loss: 0.0740\n",
      "Epoch [43/50], Step [339/735], Loss: 0.0582\n",
      "Epoch [43/50], Step [340/735], Loss: 0.0697\n",
      "Epoch [43/50], Step [341/735], Loss: 0.0437\n",
      "Epoch [43/50], Step [342/735], Loss: 0.0673\n",
      "Epoch [43/50], Step [343/735], Loss: 0.0747\n",
      "Epoch [43/50], Step [344/735], Loss: 0.0848\n",
      "Epoch [43/50], Step [345/735], Loss: 0.1991\n",
      "Epoch [43/50], Step [346/735], Loss: 0.1084\n",
      "Epoch [43/50], Step [347/735], Loss: 0.0353\n",
      "Epoch [43/50], Step [348/735], Loss: 0.0474\n",
      "Epoch [43/50], Step [349/735], Loss: 0.0337\n",
      "Epoch [43/50], Step [350/735], Loss: 0.1129\n",
      "Epoch [43/50], Step [351/735], Loss: 0.0362\n",
      "Epoch [43/50], Step [352/735], Loss: 0.5860\n",
      "Epoch [43/50], Step [353/735], Loss: 0.0630\n",
      "Epoch [43/50], Step [354/735], Loss: 0.0481\n",
      "Epoch [43/50], Step [355/735], Loss: 0.0610\n",
      "Epoch [43/50], Step [356/735], Loss: 0.0975\n",
      "Epoch [43/50], Step [357/735], Loss: 0.0826\n",
      "Epoch [43/50], Step [358/735], Loss: 0.1259\n",
      "Epoch [43/50], Step [359/735], Loss: 0.1466\n",
      "Epoch [43/50], Step [360/735], Loss: 0.1141\n",
      "Epoch [43/50], Step [361/735], Loss: 0.2774\n",
      "Epoch [43/50], Step [362/735], Loss: 0.0724\n",
      "Epoch [43/50], Step [363/735], Loss: 0.0652\n",
      "Epoch [43/50], Step [364/735], Loss: 0.1145\n",
      "Epoch [43/50], Step [365/735], Loss: 0.0992\n",
      "Epoch [43/50], Step [366/735], Loss: 0.1373\n",
      "Epoch [43/50], Step [367/735], Loss: 0.0827\n",
      "Epoch [43/50], Step [368/735], Loss: 0.0414\n",
      "Epoch [43/50], Step [369/735], Loss: 0.0648\n",
      "Epoch [43/50], Step [370/735], Loss: 0.1360\n",
      "Epoch [43/50], Step [371/735], Loss: 1.4363\n",
      "Epoch [43/50], Step [372/735], Loss: 0.0598\n",
      "Epoch [43/50], Step [373/735], Loss: 0.0781\n",
      "Epoch [43/50], Step [374/735], Loss: 0.0559\n",
      "Epoch [43/50], Step [375/735], Loss: 0.0614\n",
      "Epoch [43/50], Step [376/735], Loss: 0.4126\n",
      "Epoch [43/50], Step [377/735], Loss: 0.1039\n",
      "Epoch [43/50], Step [378/735], Loss: 0.0672\n",
      "Epoch [43/50], Step [379/735], Loss: 0.0485\n",
      "Epoch [43/50], Step [380/735], Loss: 0.1533\n",
      "Epoch [43/50], Step [381/735], Loss: 0.0378\n",
      "Epoch [43/50], Step [382/735], Loss: 0.0492\n",
      "Epoch [43/50], Step [383/735], Loss: 0.0299\n",
      "Epoch [43/50], Step [384/735], Loss: 0.0442\n",
      "Epoch [43/50], Step [385/735], Loss: 0.0586\n",
      "Epoch [43/50], Step [386/735], Loss: 0.0893\n",
      "Epoch [43/50], Step [387/735], Loss: 0.0646\n",
      "Epoch [43/50], Step [388/735], Loss: 0.1501\n",
      "Epoch [43/50], Step [389/735], Loss: 0.1544\n",
      "Epoch [43/50], Step [390/735], Loss: 0.0392\n",
      "Epoch [43/50], Step [391/735], Loss: 0.0961\n",
      "Epoch [43/50], Step [392/735], Loss: 0.1564\n",
      "Epoch [43/50], Step [393/735], Loss: 0.0840\n",
      "Epoch [43/50], Step [394/735], Loss: 0.0949\n",
      "Epoch [43/50], Step [395/735], Loss: 0.0718\n",
      "Epoch [43/50], Step [396/735], Loss: 0.0520\n",
      "Epoch [43/50], Step [397/735], Loss: 0.1587\n",
      "Epoch [43/50], Step [398/735], Loss: 0.1761\n",
      "Epoch [43/50], Step [399/735], Loss: 0.0739\n",
      "Epoch [43/50], Step [400/735], Loss: 0.1632\n",
      "Epoch [43/50], Step [401/735], Loss: 1.0667\n",
      "Epoch [43/50], Step [402/735], Loss: 0.0660\n",
      "Epoch [43/50], Step [403/735], Loss: 0.1165\n",
      "Epoch [43/50], Step [404/735], Loss: 0.2715\n",
      "Epoch [43/50], Step [405/735], Loss: 0.0917\n",
      "Epoch [43/50], Step [406/735], Loss: 0.1182\n",
      "Epoch [43/50], Step [407/735], Loss: 0.0791\n",
      "Epoch [43/50], Step [408/735], Loss: 0.0765\n",
      "Epoch [43/50], Step [409/735], Loss: 0.0730\n",
      "Epoch [43/50], Step [410/735], Loss: 0.0822\n",
      "Epoch [43/50], Step [411/735], Loss: 0.0212\n",
      "Epoch [43/50], Step [412/735], Loss: 0.1719\n",
      "Epoch [43/50], Step [413/735], Loss: 0.1698\n",
      "Epoch [43/50], Step [414/735], Loss: 0.0459\n",
      "Epoch [43/50], Step [415/735], Loss: 0.0918\n",
      "Epoch [43/50], Step [416/735], Loss: 0.0395\n",
      "Epoch [43/50], Step [417/735], Loss: 0.0557\n",
      "Epoch [43/50], Step [418/735], Loss: 0.0848\n",
      "Epoch [43/50], Step [419/735], Loss: 0.1225\n",
      "Epoch [43/50], Step [420/735], Loss: 0.0277\n",
      "Epoch [43/50], Step [421/735], Loss: 0.0629\n",
      "Epoch [43/50], Step [422/735], Loss: 0.0916\n",
      "Epoch [43/50], Step [423/735], Loss: 0.0296\n",
      "Epoch [43/50], Step [424/735], Loss: 0.0665\n",
      "Epoch [43/50], Step [425/735], Loss: 0.1433\n",
      "Epoch [43/50], Step [426/735], Loss: 0.0793\n",
      "Epoch [43/50], Step [427/735], Loss: 0.0539\n",
      "Epoch [43/50], Step [428/735], Loss: 1.0373\n",
      "Epoch [43/50], Step [429/735], Loss: 0.0674\n",
      "Epoch [43/50], Step [430/735], Loss: 0.1245\n",
      "Epoch [43/50], Step [431/735], Loss: 0.0818\n",
      "Epoch [43/50], Step [432/735], Loss: 0.0631\n",
      "Epoch [43/50], Step [433/735], Loss: 0.0674\n",
      "Epoch [43/50], Step [434/735], Loss: 0.0597\n",
      "Epoch [43/50], Step [435/735], Loss: 0.0845\n",
      "Epoch [43/50], Step [436/735], Loss: 0.0589\n",
      "Epoch [43/50], Step [437/735], Loss: 0.0647\n",
      "Epoch [43/50], Step [438/735], Loss: 0.1162\n",
      "Epoch [43/50], Step [439/735], Loss: 0.1178\n",
      "Epoch [43/50], Step [440/735], Loss: 0.0377\n",
      "Epoch [43/50], Step [441/735], Loss: 0.1073\n",
      "Epoch [43/50], Step [442/735], Loss: 0.0648\n",
      "Epoch [43/50], Step [443/735], Loss: 0.0882\n",
      "Epoch [43/50], Step [444/735], Loss: 0.0442\n",
      "Epoch [43/50], Step [445/735], Loss: 0.0391\n",
      "Epoch [43/50], Step [446/735], Loss: 0.0266\n",
      "Epoch [43/50], Step [447/735], Loss: 0.0673\n",
      "Epoch [43/50], Step [448/735], Loss: 0.0836\n",
      "Epoch [43/50], Step [449/735], Loss: 0.0844\n",
      "Epoch [43/50], Step [450/735], Loss: 0.0241\n",
      "Epoch [43/50], Step [451/735], Loss: 0.0719\n",
      "Epoch [43/50], Step [452/735], Loss: 0.1312\n",
      "Epoch [43/50], Step [453/735], Loss: 0.0668\n",
      "Epoch [43/50], Step [454/735], Loss: 0.0481\n",
      "Epoch [43/50], Step [455/735], Loss: 0.1070\n",
      "Epoch [43/50], Step [456/735], Loss: 0.0291\n",
      "Epoch [43/50], Step [457/735], Loss: 0.9825\n",
      "Epoch [43/50], Step [458/735], Loss: 0.0513\n",
      "Epoch [43/50], Step [459/735], Loss: 0.1167\n",
      "Epoch [43/50], Step [460/735], Loss: 0.1621\n",
      "Epoch [43/50], Step [461/735], Loss: 0.1052\n",
      "Epoch [43/50], Step [462/735], Loss: 0.0704\n",
      "Epoch [43/50], Step [463/735], Loss: 0.1606\n",
      "Epoch [43/50], Step [464/735], Loss: 0.0864\n",
      "Epoch [43/50], Step [465/735], Loss: 0.1186\n",
      "Epoch [43/50], Step [466/735], Loss: 0.1244\n",
      "Epoch [43/50], Step [467/735], Loss: 0.1612\n",
      "Epoch [43/50], Step [468/735], Loss: 0.0503\n",
      "Epoch [43/50], Step [469/735], Loss: 0.0790\n",
      "Epoch [43/50], Step [470/735], Loss: 0.2456\n",
      "Epoch [43/50], Step [471/735], Loss: 0.0822\n",
      "Epoch [43/50], Step [472/735], Loss: 0.0997\n",
      "Epoch [43/50], Step [473/735], Loss: 0.0421\n",
      "Epoch [43/50], Step [474/735], Loss: 0.0718\n",
      "Epoch [43/50], Step [475/735], Loss: 0.1147\n",
      "Epoch [43/50], Step [476/735], Loss: 0.0457\n",
      "Epoch [43/50], Step [477/735], Loss: 0.0993\n",
      "Epoch [43/50], Step [478/735], Loss: 0.0628\n",
      "Epoch [43/50], Step [479/735], Loss: 0.0679\n",
      "Epoch [43/50], Step [480/735], Loss: 0.0645\n",
      "Epoch [43/50], Step [481/735], Loss: 0.0632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Step [482/735], Loss: 0.1491\n",
      "Epoch [43/50], Step [483/735], Loss: 0.0796\n",
      "Epoch [43/50], Step [484/735], Loss: 0.1257\n",
      "Epoch [43/50], Step [485/735], Loss: 0.0598\n",
      "Epoch [43/50], Step [486/735], Loss: 0.0417\n",
      "Epoch [43/50], Step [487/735], Loss: 0.0487\n",
      "Epoch [43/50], Step [488/735], Loss: 0.0451\n",
      "Epoch [43/50], Step [489/735], Loss: 0.1031\n",
      "Epoch [43/50], Step [490/735], Loss: 0.0735\n",
      "Epoch [43/50], Step [491/735], Loss: 0.1070\n",
      "Epoch [43/50], Step [492/735], Loss: 0.0889\n",
      "Epoch [43/50], Step [493/735], Loss: 0.0697\n",
      "Epoch [43/50], Step [494/735], Loss: 0.0257\n",
      "Epoch [43/50], Step [495/735], Loss: 0.0959\n",
      "Epoch [43/50], Step [496/735], Loss: 0.0810\n",
      "Epoch [43/50], Step [497/735], Loss: 0.0817\n",
      "Epoch [43/50], Step [498/735], Loss: 0.2862\n",
      "Epoch [43/50], Step [499/735], Loss: 0.0559\n",
      "Epoch [43/50], Step [500/735], Loss: 0.1381\n",
      "Epoch [43/50], Step [501/735], Loss: 0.0614\n",
      "Epoch [43/50], Step [502/735], Loss: 0.0912\n",
      "Epoch [43/50], Step [503/735], Loss: 0.3717\n",
      "Epoch [43/50], Step [504/735], Loss: 0.0358\n",
      "Epoch [43/50], Step [505/735], Loss: 0.0325\n",
      "Epoch [43/50], Step [506/735], Loss: 0.0565\n",
      "Epoch [43/50], Step [507/735], Loss: 0.0546\n",
      "Epoch [43/50], Step [508/735], Loss: 0.0516\n",
      "Epoch [43/50], Step [509/735], Loss: 0.0643\n",
      "Epoch [43/50], Step [510/735], Loss: 0.0755\n",
      "Epoch [43/50], Step [511/735], Loss: 0.2034\n",
      "Epoch [43/50], Step [512/735], Loss: 0.0366\n",
      "Epoch [43/50], Step [513/735], Loss: 0.1255\n",
      "Epoch [43/50], Step [514/735], Loss: 0.0924\n",
      "Epoch [43/50], Step [515/735], Loss: 0.0571\n",
      "Epoch [43/50], Step [516/735], Loss: 0.0761\n",
      "Epoch [43/50], Step [517/735], Loss: 0.5311\n",
      "Epoch [43/50], Step [518/735], Loss: 0.0722\n",
      "Epoch [43/50], Step [519/735], Loss: 0.0654\n",
      "Epoch [43/50], Step [520/735], Loss: 0.0595\n",
      "Epoch [43/50], Step [521/735], Loss: 0.0733\n",
      "Epoch [43/50], Step [522/735], Loss: 0.0718\n",
      "Epoch [43/50], Step [523/735], Loss: 0.0737\n",
      "Epoch [43/50], Step [524/735], Loss: 0.1691\n",
      "Epoch [43/50], Step [525/735], Loss: 0.0873\n",
      "Epoch [43/50], Step [526/735], Loss: 0.2087\n",
      "Epoch [43/50], Step [527/735], Loss: 0.0753\n",
      "Epoch [43/50], Step [528/735], Loss: 0.1259\n",
      "Epoch [43/50], Step [529/735], Loss: 0.0567\n",
      "Epoch [43/50], Step [530/735], Loss: 0.0942\n",
      "Epoch [43/50], Step [531/735], Loss: 0.9093\n",
      "Epoch [43/50], Step [532/735], Loss: 0.0527\n",
      "Epoch [43/50], Step [533/735], Loss: 0.1137\n",
      "Epoch [43/50], Step [534/735], Loss: 0.1392\n",
      "Epoch [43/50], Step [535/735], Loss: 0.0443\n",
      "Epoch [43/50], Step [536/735], Loss: 0.0519\n",
      "Epoch [43/50], Step [537/735], Loss: 0.0450\n",
      "Epoch [43/50], Step [538/735], Loss: 0.0453\n",
      "Epoch [43/50], Step [539/735], Loss: 0.1108\n",
      "Epoch [43/50], Step [540/735], Loss: 0.0818\n",
      "Epoch [43/50], Step [541/735], Loss: 0.0807\n",
      "Epoch [43/50], Step [542/735], Loss: 0.1130\n",
      "Epoch [43/50], Step [543/735], Loss: 0.0882\n",
      "Epoch [43/50], Step [544/735], Loss: 0.0573\n",
      "Epoch [43/50], Step [545/735], Loss: 0.0653\n",
      "Epoch [43/50], Step [546/735], Loss: 0.0752\n",
      "Epoch [43/50], Step [547/735], Loss: 1.8388\n",
      "Epoch [43/50], Step [548/735], Loss: 0.0768\n",
      "Epoch [43/50], Step [549/735], Loss: 0.1109\n",
      "Epoch [43/50], Step [550/735], Loss: 0.0562\n",
      "Epoch [43/50], Step [551/735], Loss: 0.0599\n",
      "Epoch [43/50], Step [552/735], Loss: 0.0628\n",
      "Epoch [43/50], Step [553/735], Loss: 0.0734\n",
      "Epoch [43/50], Step [554/735], Loss: 0.2656\n",
      "Epoch [43/50], Step [555/735], Loss: 0.1728\n",
      "Epoch [43/50], Step [556/735], Loss: 0.1484\n",
      "Epoch [43/50], Step [557/735], Loss: 0.1309\n",
      "Epoch [43/50], Step [558/735], Loss: 0.1243\n",
      "Epoch [43/50], Step [559/735], Loss: 0.0949\n",
      "Epoch [43/50], Step [560/735], Loss: 0.0924\n",
      "Epoch [43/50], Step [561/735], Loss: 0.0423\n",
      "Epoch [43/50], Step [562/735], Loss: 0.1205\n",
      "Epoch [43/50], Step [563/735], Loss: 0.1787\n",
      "Epoch [43/50], Step [564/735], Loss: 0.0613\n",
      "Epoch [43/50], Step [565/735], Loss: 0.0319\n",
      "Epoch [43/50], Step [566/735], Loss: 0.1404\n",
      "Epoch [43/50], Step [567/735], Loss: 0.0743\n",
      "Epoch [43/50], Step [568/735], Loss: 0.0731\n",
      "Epoch [43/50], Step [569/735], Loss: 0.1171\n",
      "Epoch [43/50], Step [570/735], Loss: 0.0455\n",
      "Epoch [43/50], Step [571/735], Loss: 0.0718\n",
      "Epoch [43/50], Step [572/735], Loss: 0.1655\n",
      "Epoch [43/50], Step [573/735], Loss: 0.0823\n",
      "Epoch [43/50], Step [574/735], Loss: 0.0736\n",
      "Epoch [43/50], Step [575/735], Loss: 0.0667\n",
      "Epoch [43/50], Step [576/735], Loss: 0.0434\n",
      "Epoch [43/50], Step [577/735], Loss: 0.0620\n",
      "Epoch [43/50], Step [578/735], Loss: 0.0795\n",
      "Epoch [43/50], Step [579/735], Loss: 0.0490\n",
      "Epoch [43/50], Step [580/735], Loss: 0.0598\n",
      "Epoch [43/50], Step [581/735], Loss: 0.1855\n",
      "Epoch [43/50], Step [582/735], Loss: 0.0762\n",
      "Epoch [43/50], Step [583/735], Loss: 0.0631\n",
      "Epoch [43/50], Step [584/735], Loss: 0.0455\n",
      "Epoch [43/50], Step [585/735], Loss: 0.0671\n",
      "Epoch [43/50], Step [586/735], Loss: 0.1046\n",
      "Epoch [43/50], Step [587/735], Loss: 0.0876\n",
      "Epoch [43/50], Step [588/735], Loss: 0.1446\n",
      "Epoch [43/50], Step [589/735], Loss: 0.0734\n",
      "Epoch [43/50], Step [590/735], Loss: 0.0568\n",
      "Epoch [43/50], Step [591/735], Loss: 0.1868\n",
      "Epoch [43/50], Step [592/735], Loss: 0.1008\n",
      "Epoch [43/50], Step [593/735], Loss: 0.0604\n",
      "Epoch [43/50], Step [594/735], Loss: 0.0707\n",
      "Epoch [43/50], Step [595/735], Loss: 0.0829\n",
      "Epoch [43/50], Step [596/735], Loss: 0.0561\n",
      "Epoch [43/50], Step [597/735], Loss: 0.0426\n",
      "Epoch [43/50], Step [598/735], Loss: 0.1143\n",
      "Epoch [43/50], Step [599/735], Loss: 0.0380\n",
      "Epoch [43/50], Step [600/735], Loss: 0.0706\n",
      "Epoch [43/50], Step [601/735], Loss: 0.0785\n",
      "Epoch [43/50], Step [602/735], Loss: 0.0381\n",
      "Epoch [43/50], Step [603/735], Loss: 1.4254\n",
      "Epoch [43/50], Step [604/735], Loss: 0.0375\n",
      "Epoch [43/50], Step [605/735], Loss: 0.0452\n",
      "Epoch [43/50], Step [606/735], Loss: 0.1028\n",
      "Epoch [43/50], Step [607/735], Loss: 0.0816\n",
      "Epoch [43/50], Step [608/735], Loss: 0.0511\n",
      "Epoch [43/50], Step [609/735], Loss: 0.0549\n",
      "Epoch [43/50], Step [610/735], Loss: 0.2356\n",
      "Epoch [43/50], Step [611/735], Loss: 0.1071\n",
      "Epoch [43/50], Step [612/735], Loss: 0.0508\n",
      "Epoch [43/50], Step [613/735], Loss: 0.0459\n",
      "Epoch [43/50], Step [614/735], Loss: 0.0577\n",
      "Epoch [43/50], Step [615/735], Loss: 0.1888\n",
      "Epoch [43/50], Step [616/735], Loss: 0.0806\n",
      "Epoch [43/50], Step [617/735], Loss: 0.0657\n",
      "Epoch [43/50], Step [618/735], Loss: 0.0496\n",
      "Epoch [43/50], Step [619/735], Loss: 0.1029\n",
      "Epoch [43/50], Step [620/735], Loss: 0.0538\n",
      "Epoch [43/50], Step [621/735], Loss: 0.1643\n",
      "Epoch [43/50], Step [622/735], Loss: 0.1272\n",
      "Epoch [43/50], Step [623/735], Loss: 0.1338\n",
      "Epoch [43/50], Step [624/735], Loss: 0.0815\n",
      "Epoch [43/50], Step [625/735], Loss: 0.0697\n",
      "Epoch [43/50], Step [626/735], Loss: 0.5883\n",
      "Epoch [43/50], Step [627/735], Loss: 0.1084\n",
      "Epoch [43/50], Step [628/735], Loss: 0.0858\n",
      "Epoch [43/50], Step [629/735], Loss: 0.1238\n",
      "Epoch [43/50], Step [630/735], Loss: 0.0786\n",
      "Epoch [43/50], Step [631/735], Loss: 0.0493\n",
      "Epoch [43/50], Step [632/735], Loss: 0.1116\n",
      "Epoch [43/50], Step [633/735], Loss: 0.1381\n",
      "Epoch [43/50], Step [634/735], Loss: 0.0896\n",
      "Epoch [43/50], Step [635/735], Loss: 0.1887\n",
      "Epoch [43/50], Step [636/735], Loss: 0.0693\n",
      "Epoch [43/50], Step [637/735], Loss: 0.0880\n",
      "Epoch [43/50], Step [638/735], Loss: 0.0646\n",
      "Epoch [43/50], Step [639/735], Loss: 0.8240\n",
      "Epoch [43/50], Step [640/735], Loss: 0.1349\n",
      "Epoch [43/50], Step [641/735], Loss: 0.1129\n",
      "Epoch [43/50], Step [642/735], Loss: 0.1077\n",
      "Epoch [43/50], Step [643/735], Loss: 0.2080\n",
      "Epoch [43/50], Step [644/735], Loss: 0.0848\n",
      "Epoch [43/50], Step [645/735], Loss: 0.4073\n",
      "Epoch [43/50], Step [646/735], Loss: 0.5509\n",
      "Epoch [43/50], Step [647/735], Loss: 0.4325\n",
      "Epoch [43/50], Step [648/735], Loss: 0.0399\n",
      "Epoch [43/50], Step [649/735], Loss: 0.0501\n",
      "Epoch [43/50], Step [650/735], Loss: 0.2160\n",
      "Epoch [43/50], Step [651/735], Loss: 0.0749\n",
      "Epoch [43/50], Step [652/735], Loss: 0.0318\n",
      "Epoch [43/50], Step [653/735], Loss: 0.0837\n",
      "Epoch [43/50], Step [654/735], Loss: 0.1723\n",
      "Epoch [43/50], Step [655/735], Loss: 0.0786\n",
      "Epoch [43/50], Step [656/735], Loss: 0.0941\n",
      "Epoch [43/50], Step [657/735], Loss: 0.0825\n",
      "Epoch [43/50], Step [658/735], Loss: 0.0793\n",
      "Epoch [43/50], Step [659/735], Loss: 0.1096\n",
      "Epoch [43/50], Step [660/735], Loss: 0.0844\n",
      "Epoch [43/50], Step [661/735], Loss: 0.0456\n",
      "Epoch [43/50], Step [662/735], Loss: 0.4034\n",
      "Epoch [43/50], Step [663/735], Loss: 0.0721\n",
      "Epoch [43/50], Step [664/735], Loss: 0.3708\n",
      "Epoch [43/50], Step [665/735], Loss: 0.0827\n",
      "Epoch [43/50], Step [666/735], Loss: 0.0950\n",
      "Epoch [43/50], Step [667/735], Loss: 0.1392\n",
      "Epoch [43/50], Step [668/735], Loss: 0.2368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Step [669/735], Loss: 0.1567\n",
      "Epoch [43/50], Step [670/735], Loss: 0.2780\n",
      "Epoch [43/50], Step [671/735], Loss: 0.2450\n",
      "Epoch [43/50], Step [672/735], Loss: 0.0350\n",
      "Epoch [43/50], Step [673/735], Loss: 0.0818\n",
      "Epoch [43/50], Step [674/735], Loss: 0.0446\n",
      "Epoch [43/50], Step [675/735], Loss: 0.0997\n",
      "Epoch [43/50], Step [676/735], Loss: 0.0679\n",
      "Epoch [43/50], Step [677/735], Loss: 0.1073\n",
      "Epoch [43/50], Step [678/735], Loss: 0.0555\n",
      "Epoch [43/50], Step [679/735], Loss: 0.0877\n",
      "Epoch [43/50], Step [680/735], Loss: 0.1032\n",
      "Epoch [43/50], Step [681/735], Loss: 0.4443\n",
      "Epoch [43/50], Step [682/735], Loss: 0.0909\n",
      "Epoch [43/50], Step [683/735], Loss: 0.0662\n",
      "Epoch [43/50], Step [684/735], Loss: 0.0868\n",
      "Epoch [43/50], Step [685/735], Loss: 0.1212\n",
      "Epoch [43/50], Step [686/735], Loss: 0.0746\n",
      "Epoch [43/50], Step [687/735], Loss: 0.0255\n",
      "Epoch [43/50], Step [688/735], Loss: 0.1386\n",
      "Epoch [43/50], Step [689/735], Loss: 0.0676\n",
      "Epoch [43/50], Step [690/735], Loss: 0.5701\n",
      "Epoch [43/50], Step [691/735], Loss: 0.0897\n",
      "Epoch [43/50], Step [692/735], Loss: 0.1063\n",
      "Epoch [43/50], Step [693/735], Loss: 0.0762\n",
      "Epoch [43/50], Step [694/735], Loss: 0.0974\n",
      "Epoch [43/50], Step [695/735], Loss: 0.0869\n",
      "Epoch [43/50], Step [696/735], Loss: 0.1116\n",
      "Epoch [43/50], Step [697/735], Loss: 0.0585\n",
      "Epoch [43/50], Step [698/735], Loss: 0.1142\n",
      "Epoch [43/50], Step [699/735], Loss: 0.0593\n",
      "Epoch [43/50], Step [700/735], Loss: 0.0625\n",
      "Epoch [43/50], Step [701/735], Loss: 0.1248\n",
      "Epoch [43/50], Step [702/735], Loss: 0.1378\n",
      "Epoch [43/50], Step [703/735], Loss: 0.1698\n",
      "Epoch [43/50], Step [704/735], Loss: 0.0711\n",
      "Epoch [43/50], Step [705/735], Loss: 0.1266\n",
      "Epoch [43/50], Step [706/735], Loss: 0.0676\n",
      "Epoch [43/50], Step [707/735], Loss: 0.0411\n",
      "Epoch [43/50], Step [708/735], Loss: 0.2694\n",
      "Epoch [43/50], Step [709/735], Loss: 0.0938\n",
      "Epoch [43/50], Step [710/735], Loss: 0.2610\n",
      "Epoch [43/50], Step [711/735], Loss: 1.2594\n",
      "Epoch [43/50], Step [712/735], Loss: 0.1731\n",
      "Epoch [43/50], Step [713/735], Loss: 0.0613\n",
      "Epoch [43/50], Step [714/735], Loss: 0.1183\n",
      "Epoch [43/50], Step [715/735], Loss: 0.1412\n",
      "Epoch [43/50], Step [716/735], Loss: 0.0647\n",
      "Epoch [43/50], Step [717/735], Loss: 0.1682\n",
      "Epoch [43/50], Step [718/735], Loss: 0.0765\n",
      "Epoch [43/50], Step [719/735], Loss: 0.0861\n",
      "Epoch [43/50], Step [720/735], Loss: 0.0811\n",
      "Epoch [43/50], Step [721/735], Loss: 0.2447\n",
      "Epoch [43/50], Step [722/735], Loss: 0.1164\n",
      "Epoch [43/50], Step [723/735], Loss: 0.1001\n",
      "Epoch [43/50], Step [724/735], Loss: 0.1443\n",
      "Epoch [43/50], Step [725/735], Loss: 0.0618\n",
      "Epoch [43/50], Step [726/735], Loss: 0.1353\n",
      "Epoch [43/50], Step [727/735], Loss: 0.0478\n",
      "Epoch [43/50], Step [728/735], Loss: 0.0556\n",
      "Epoch [43/50], Step [729/735], Loss: 0.0298\n",
      "Epoch [43/50], Step [730/735], Loss: 0.0640\n",
      "Epoch [43/50], Step [731/735], Loss: 0.5253\n",
      "Epoch [43/50], Step [732/735], Loss: 0.1161\n",
      "Epoch [43/50], Step [733/735], Loss: 0.1091\n",
      "Epoch [43/50], Step [734/735], Loss: 0.2121\n",
      "Epoch [43/50], Step [735/735], Loss: 0.1270\n",
      "Epoch [44/50], Step [1/735], Loss: 0.1581\n",
      "Epoch [44/50], Step [2/735], Loss: 0.0663\n",
      "Epoch [44/50], Step [3/735], Loss: 0.0934\n",
      "Epoch [44/50], Step [4/735], Loss: 0.0786\n",
      "Epoch [44/50], Step [5/735], Loss: 0.1020\n",
      "Epoch [44/50], Step [6/735], Loss: 0.1213\n",
      "Epoch [44/50], Step [7/735], Loss: 0.0610\n",
      "Epoch [44/50], Step [8/735], Loss: 0.0921\n",
      "Epoch [44/50], Step [9/735], Loss: 0.2964\n",
      "Epoch [44/50], Step [10/735], Loss: 0.1090\n",
      "Epoch [44/50], Step [11/735], Loss: 0.0684\n",
      "Epoch [44/50], Step [12/735], Loss: 0.1393\n",
      "Epoch [44/50], Step [13/735], Loss: 0.1505\n",
      "Epoch [44/50], Step [14/735], Loss: 0.1481\n",
      "Epoch [44/50], Step [15/735], Loss: 0.0286\n",
      "Epoch [44/50], Step [16/735], Loss: 0.3904\n",
      "Epoch [44/50], Step [17/735], Loss: 0.1708\n",
      "Epoch [44/50], Step [18/735], Loss: 0.0698\n",
      "Epoch [44/50], Step [19/735], Loss: 0.0466\n",
      "Epoch [44/50], Step [20/735], Loss: 0.1559\n",
      "Epoch [44/50], Step [21/735], Loss: 0.1214\n",
      "Epoch [44/50], Step [22/735], Loss: 0.2846\n",
      "Epoch [44/50], Step [23/735], Loss: 0.1332\n",
      "Epoch [44/50], Step [24/735], Loss: 0.1284\n",
      "Epoch [44/50], Step [25/735], Loss: 0.1675\n",
      "Epoch [44/50], Step [26/735], Loss: 1.3710\n",
      "Epoch [44/50], Step [27/735], Loss: 0.0217\n",
      "Epoch [44/50], Step [28/735], Loss: 0.1796\n",
      "Epoch [44/50], Step [29/735], Loss: 0.1269\n",
      "Epoch [44/50], Step [30/735], Loss: 0.0570\n",
      "Epoch [44/50], Step [31/735], Loss: 0.0591\n",
      "Epoch [44/50], Step [32/735], Loss: 0.0878\n",
      "Epoch [44/50], Step [33/735], Loss: 0.1049\n",
      "Epoch [44/50], Step [34/735], Loss: 0.0464\n",
      "Epoch [44/50], Step [35/735], Loss: 0.1076\n",
      "Epoch [44/50], Step [36/735], Loss: 0.0370\n",
      "Epoch [44/50], Step [37/735], Loss: 0.0858\n",
      "Epoch [44/50], Step [38/735], Loss: 0.0884\n",
      "Epoch [44/50], Step [39/735], Loss: 0.1597\n",
      "Epoch [44/50], Step [40/735], Loss: 0.0807\n",
      "Epoch [44/50], Step [41/735], Loss: 0.0848\n",
      "Epoch [44/50], Step [42/735], Loss: 0.0783\n",
      "Epoch [44/50], Step [43/735], Loss: 0.0654\n",
      "Epoch [44/50], Step [44/735], Loss: 0.1237\n",
      "Epoch [44/50], Step [45/735], Loss: 0.1489\n",
      "Epoch [44/50], Step [46/735], Loss: 0.0399\n",
      "Epoch [44/50], Step [47/735], Loss: 0.0501\n",
      "Epoch [44/50], Step [48/735], Loss: 0.5246\n",
      "Epoch [44/50], Step [49/735], Loss: 0.0782\n",
      "Epoch [44/50], Step [50/735], Loss: 0.1330\n",
      "Epoch [44/50], Step [51/735], Loss: 0.1736\n",
      "Epoch [44/50], Step [52/735], Loss: 0.1182\n",
      "Epoch [44/50], Step [53/735], Loss: 0.0770\n",
      "Epoch [44/50], Step [54/735], Loss: 0.0621\n",
      "Epoch [44/50], Step [55/735], Loss: 0.1485\n",
      "Epoch [44/50], Step [56/735], Loss: 0.1723\n",
      "Epoch [44/50], Step [57/735], Loss: 0.1052\n",
      "Epoch [44/50], Step [58/735], Loss: 0.1148\n",
      "Epoch [44/50], Step [59/735], Loss: 0.0628\n",
      "Epoch [44/50], Step [60/735], Loss: 0.0575\n",
      "Epoch [44/50], Step [61/735], Loss: 0.0484\n",
      "Epoch [44/50], Step [62/735], Loss: 0.0908\n",
      "Epoch [44/50], Step [63/735], Loss: 0.0630\n",
      "Epoch [44/50], Step [64/735], Loss: 0.0737\n",
      "Epoch [44/50], Step [65/735], Loss: 0.0958\n",
      "Epoch [44/50], Step [66/735], Loss: 0.1158\n",
      "Epoch [44/50], Step [67/735], Loss: 0.0906\n",
      "Epoch [44/50], Step [68/735], Loss: 0.1128\n",
      "Epoch [44/50], Step [69/735], Loss: 0.1622\n",
      "Epoch [44/50], Step [70/735], Loss: 0.0798\n",
      "Epoch [44/50], Step [71/735], Loss: 0.0756\n",
      "Epoch [44/50], Step [72/735], Loss: 0.0445\n",
      "Epoch [44/50], Step [73/735], Loss: 0.1364\n",
      "Epoch [44/50], Step [74/735], Loss: 0.1324\n",
      "Epoch [44/50], Step [75/735], Loss: 0.0285\n",
      "Epoch [44/50], Step [76/735], Loss: 0.0635\n",
      "Epoch [44/50], Step [77/735], Loss: 0.0362\n",
      "Epoch [44/50], Step [78/735], Loss: 0.0298\n",
      "Epoch [44/50], Step [79/735], Loss: 0.0670\n",
      "Epoch [44/50], Step [80/735], Loss: 0.0698\n",
      "Epoch [44/50], Step [81/735], Loss: 0.0563\n",
      "Epoch [44/50], Step [82/735], Loss: 0.0794\n",
      "Epoch [44/50], Step [83/735], Loss: 0.0707\n",
      "Epoch [44/50], Step [84/735], Loss: 0.0862\n",
      "Epoch [44/50], Step [85/735], Loss: 0.0805\n",
      "Epoch [44/50], Step [86/735], Loss: 0.1276\n",
      "Epoch [44/50], Step [87/735], Loss: 0.0464\n",
      "Epoch [44/50], Step [88/735], Loss: 0.0631\n",
      "Epoch [44/50], Step [89/735], Loss: 0.0519\n",
      "Epoch [44/50], Step [90/735], Loss: 0.1109\n",
      "Epoch [44/50], Step [91/735], Loss: 0.0591\n",
      "Epoch [44/50], Step [92/735], Loss: 0.1686\n",
      "Epoch [44/50], Step [93/735], Loss: 0.0859\n",
      "Epoch [44/50], Step [94/735], Loss: 0.0667\n",
      "Epoch [44/50], Step [95/735], Loss: 0.1143\n",
      "Epoch [44/50], Step [96/735], Loss: 0.0648\n",
      "Epoch [44/50], Step [97/735], Loss: 0.0956\n",
      "Epoch [44/50], Step [98/735], Loss: 0.0532\n",
      "Epoch [44/50], Step [99/735], Loss: 0.1175\n",
      "Epoch [44/50], Step [100/735], Loss: 0.0821\n",
      "Epoch [44/50], Step [101/735], Loss: 0.1423\n",
      "Epoch [44/50], Step [102/735], Loss: 0.0720\n",
      "Epoch [44/50], Step [103/735], Loss: 0.0443\n",
      "Epoch [44/50], Step [104/735], Loss: 0.0790\n",
      "Epoch [44/50], Step [105/735], Loss: 0.3051\n",
      "Epoch [44/50], Step [106/735], Loss: 0.0469\n",
      "Epoch [44/50], Step [107/735], Loss: 0.0281\n",
      "Epoch [44/50], Step [108/735], Loss: 0.0609\n",
      "Epoch [44/50], Step [109/735], Loss: 0.4611\n",
      "Epoch [44/50], Step [110/735], Loss: 0.0520\n",
      "Epoch [44/50], Step [111/735], Loss: 0.0512\n",
      "Epoch [44/50], Step [112/735], Loss: 0.4682\n",
      "Epoch [44/50], Step [113/735], Loss: 0.0822\n",
      "Epoch [44/50], Step [114/735], Loss: 0.0869\n",
      "Epoch [44/50], Step [115/735], Loss: 0.0421\n",
      "Epoch [44/50], Step [116/735], Loss: 0.0363\n",
      "Epoch [44/50], Step [117/735], Loss: 0.1021\n",
      "Epoch [44/50], Step [118/735], Loss: 0.0455\n",
      "Epoch [44/50], Step [119/735], Loss: 0.0471\n",
      "Epoch [44/50], Step [120/735], Loss: 0.1567\n",
      "Epoch [44/50], Step [121/735], Loss: 0.1777\n",
      "Epoch [44/50], Step [122/735], Loss: 0.7593\n",
      "Epoch [44/50], Step [123/735], Loss: 0.0971\n",
      "Epoch [44/50], Step [124/735], Loss: 0.0229\n",
      "Epoch [44/50], Step [125/735], Loss: 0.1211\n",
      "Epoch [44/50], Step [126/735], Loss: 0.1002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Step [127/735], Loss: 0.1375\n",
      "Epoch [44/50], Step [128/735], Loss: 0.1041\n",
      "Epoch [44/50], Step [129/735], Loss: 0.0947\n",
      "Epoch [44/50], Step [130/735], Loss: 0.2313\n",
      "Epoch [44/50], Step [131/735], Loss: 0.0962\n",
      "Epoch [44/50], Step [132/735], Loss: 0.6453\n",
      "Epoch [44/50], Step [133/735], Loss: 0.0999\n",
      "Epoch [44/50], Step [134/735], Loss: 0.1256\n",
      "Epoch [44/50], Step [135/735], Loss: 0.0602\n",
      "Epoch [44/50], Step [136/735], Loss: 0.0409\n",
      "Epoch [44/50], Step [137/735], Loss: 0.0874\n",
      "Epoch [44/50], Step [138/735], Loss: 0.1036\n",
      "Epoch [44/50], Step [139/735], Loss: 0.1563\n",
      "Epoch [44/50], Step [140/735], Loss: 0.1034\n",
      "Epoch [44/50], Step [141/735], Loss: 0.0776\n",
      "Epoch [44/50], Step [142/735], Loss: 0.0464\n",
      "Epoch [44/50], Step [143/735], Loss: 0.0663\n",
      "Epoch [44/50], Step [144/735], Loss: 0.2165\n",
      "Epoch [44/50], Step [145/735], Loss: 0.1108\n",
      "Epoch [44/50], Step [146/735], Loss: 0.0838\n",
      "Epoch [44/50], Step [147/735], Loss: 0.0952\n",
      "Epoch [44/50], Step [148/735], Loss: 0.0837\n",
      "Epoch [44/50], Step [149/735], Loss: 0.0651\n",
      "Epoch [44/50], Step [150/735], Loss: 0.1026\n",
      "Epoch [44/50], Step [151/735], Loss: 0.0542\n",
      "Epoch [44/50], Step [152/735], Loss: 0.0822\n",
      "Epoch [44/50], Step [153/735], Loss: 0.0566\n",
      "Epoch [44/50], Step [154/735], Loss: 0.1299\n",
      "Epoch [44/50], Step [155/735], Loss: 0.0581\n",
      "Epoch [44/50], Step [156/735], Loss: 0.0712\n",
      "Epoch [44/50], Step [157/735], Loss: 0.1282\n",
      "Epoch [44/50], Step [158/735], Loss: 0.0738\n",
      "Epoch [44/50], Step [159/735], Loss: 0.0816\n",
      "Epoch [44/50], Step [160/735], Loss: 0.0853\n",
      "Epoch [44/50], Step [161/735], Loss: 0.3208\n",
      "Epoch [44/50], Step [162/735], Loss: 0.1252\n",
      "Epoch [44/50], Step [163/735], Loss: 0.1333\n",
      "Epoch [44/50], Step [164/735], Loss: 1.1895\n",
      "Epoch [44/50], Step [165/735], Loss: 0.0495\n",
      "Epoch [44/50], Step [166/735], Loss: 0.0684\n",
      "Epoch [44/50], Step [167/735], Loss: 0.1419\n",
      "Epoch [44/50], Step [168/735], Loss: 1.2346\n",
      "Epoch [44/50], Step [169/735], Loss: 0.1929\n",
      "Epoch [44/50], Step [170/735], Loss: 0.1394\n",
      "Epoch [44/50], Step [171/735], Loss: 0.0819\n",
      "Epoch [44/50], Step [172/735], Loss: 0.1685\n",
      "Epoch [44/50], Step [173/735], Loss: 0.1316\n",
      "Epoch [44/50], Step [174/735], Loss: 0.1127\n",
      "Epoch [44/50], Step [175/735], Loss: 0.0977\n",
      "Epoch [44/50], Step [176/735], Loss: 0.0763\n",
      "Epoch [44/50], Step [177/735], Loss: 0.1320\n",
      "Epoch [44/50], Step [178/735], Loss: 0.1530\n",
      "Epoch [44/50], Step [179/735], Loss: 0.1432\n",
      "Epoch [44/50], Step [180/735], Loss: 0.1852\n",
      "Epoch [44/50], Step [181/735], Loss: 1.3507\n",
      "Epoch [44/50], Step [182/735], Loss: 0.0698\n",
      "Epoch [44/50], Step [183/735], Loss: 0.1489\n",
      "Epoch [44/50], Step [184/735], Loss: 0.0684\n",
      "Epoch [44/50], Step [185/735], Loss: 0.0512\n",
      "Epoch [44/50], Step [186/735], Loss: 0.0754\n",
      "Epoch [44/50], Step [187/735], Loss: 0.0654\n",
      "Epoch [44/50], Step [188/735], Loss: 0.4114\n",
      "Epoch [44/50], Step [189/735], Loss: 0.1404\n",
      "Epoch [44/50], Step [190/735], Loss: 0.1155\n",
      "Epoch [44/50], Step [191/735], Loss: 0.1832\n",
      "Epoch [44/50], Step [192/735], Loss: 0.2025\n",
      "Epoch [44/50], Step [193/735], Loss: 0.0789\n",
      "Epoch [44/50], Step [194/735], Loss: 0.0854\n",
      "Epoch [44/50], Step [195/735], Loss: 0.0356\n",
      "Epoch [44/50], Step [196/735], Loss: 0.0691\n",
      "Epoch [44/50], Step [197/735], Loss: 0.1852\n",
      "Epoch [44/50], Step [198/735], Loss: 0.0452\n",
      "Epoch [44/50], Step [199/735], Loss: 0.0627\n",
      "Epoch [44/50], Step [200/735], Loss: 0.0875\n",
      "Epoch [44/50], Step [201/735], Loss: 0.2142\n",
      "Epoch [44/50], Step [202/735], Loss: 0.0654\n",
      "Epoch [44/50], Step [203/735], Loss: 0.0336\n",
      "Epoch [44/50], Step [204/735], Loss: 0.1095\n",
      "Epoch [44/50], Step [205/735], Loss: 0.0648\n",
      "Epoch [44/50], Step [206/735], Loss: 0.0988\n",
      "Epoch [44/50], Step [207/735], Loss: 0.1415\n",
      "Epoch [44/50], Step [208/735], Loss: 0.1054\n",
      "Epoch [44/50], Step [209/735], Loss: 0.0655\n",
      "Epoch [44/50], Step [210/735], Loss: 0.1463\n",
      "Epoch [44/50], Step [211/735], Loss: 0.0882\n",
      "Epoch [44/50], Step [212/735], Loss: 0.0713\n",
      "Epoch [44/50], Step [213/735], Loss: 0.0903\n",
      "Epoch [44/50], Step [214/735], Loss: 0.0909\n",
      "Epoch [44/50], Step [215/735], Loss: 0.0788\n",
      "Epoch [44/50], Step [216/735], Loss: 0.1113\n",
      "Epoch [44/50], Step [217/735], Loss: 0.0920\n",
      "Epoch [44/50], Step [218/735], Loss: 0.0469\n",
      "Epoch [44/50], Step [219/735], Loss: 0.0544\n",
      "Epoch [44/50], Step [220/735], Loss: 0.1159\n",
      "Epoch [44/50], Step [221/735], Loss: 0.1758\n",
      "Epoch [44/50], Step [222/735], Loss: 0.0447\n",
      "Epoch [44/50], Step [223/735], Loss: 0.1491\n",
      "Epoch [44/50], Step [224/735], Loss: 0.0831\n",
      "Epoch [44/50], Step [225/735], Loss: 0.0850\n",
      "Epoch [44/50], Step [226/735], Loss: 0.0659\n",
      "Epoch [44/50], Step [227/735], Loss: 0.0863\n",
      "Epoch [44/50], Step [228/735], Loss: 0.0732\n",
      "Epoch [44/50], Step [229/735], Loss: 0.0917\n",
      "Epoch [44/50], Step [230/735], Loss: 0.1055\n",
      "Epoch [44/50], Step [231/735], Loss: 0.0409\n",
      "Epoch [44/50], Step [232/735], Loss: 0.0406\n",
      "Epoch [44/50], Step [233/735], Loss: 0.0943\n",
      "Epoch [44/50], Step [234/735], Loss: 0.1203\n",
      "Epoch [44/50], Step [235/735], Loss: 0.0842\n",
      "Epoch [44/50], Step [236/735], Loss: 0.0471\n",
      "Epoch [44/50], Step [237/735], Loss: 0.2149\n",
      "Epoch [44/50], Step [238/735], Loss: 0.1051\n",
      "Epoch [44/50], Step [239/735], Loss: 0.0813\n",
      "Epoch [44/50], Step [240/735], Loss: 0.1373\n",
      "Epoch [44/50], Step [241/735], Loss: 0.0441\n",
      "Epoch [44/50], Step [242/735], Loss: 0.0497\n",
      "Epoch [44/50], Step [243/735], Loss: 0.3072\n",
      "Epoch [44/50], Step [244/735], Loss: 0.0449\n",
      "Epoch [44/50], Step [245/735], Loss: 0.1215\n",
      "Epoch [44/50], Step [246/735], Loss: 0.0770\n",
      "Epoch [44/50], Step [247/735], Loss: 0.1638\n",
      "Epoch [44/50], Step [248/735], Loss: 0.3327\n",
      "Epoch [44/50], Step [249/735], Loss: 0.0808\n",
      "Epoch [44/50], Step [250/735], Loss: 0.1152\n",
      "Epoch [44/50], Step [251/735], Loss: 0.0527\n",
      "Epoch [44/50], Step [252/735], Loss: 0.0881\n",
      "Epoch [44/50], Step [253/735], Loss: 0.0908\n",
      "Epoch [44/50], Step [254/735], Loss: 0.0743\n",
      "Epoch [44/50], Step [255/735], Loss: 0.0670\n",
      "Epoch [44/50], Step [256/735], Loss: 0.1611\n",
      "Epoch [44/50], Step [257/735], Loss: 0.0489\n",
      "Epoch [44/50], Step [258/735], Loss: 0.0776\n",
      "Epoch [44/50], Step [259/735], Loss: 0.1358\n",
      "Epoch [44/50], Step [260/735], Loss: 0.3696\n",
      "Epoch [44/50], Step [261/735], Loss: 0.0394\n",
      "Epoch [44/50], Step [262/735], Loss: 0.0374\n",
      "Epoch [44/50], Step [263/735], Loss: 0.0364\n",
      "Epoch [44/50], Step [264/735], Loss: 0.1273\n",
      "Epoch [44/50], Step [265/735], Loss: 0.0461\n",
      "Epoch [44/50], Step [266/735], Loss: 0.0690\n",
      "Epoch [44/50], Step [267/735], Loss: 0.0539\n",
      "Epoch [44/50], Step [268/735], Loss: 0.0800\n",
      "Epoch [44/50], Step [269/735], Loss: 0.1182\n",
      "Epoch [44/50], Step [270/735], Loss: 0.2045\n",
      "Epoch [44/50], Step [271/735], Loss: 0.0992\n",
      "Epoch [44/50], Step [272/735], Loss: 0.0617\n",
      "Epoch [44/50], Step [273/735], Loss: 0.1401\n",
      "Epoch [44/50], Step [274/735], Loss: 0.0401\n",
      "Epoch [44/50], Step [275/735], Loss: 0.1631\n",
      "Epoch [44/50], Step [276/735], Loss: 0.0396\n",
      "Epoch [44/50], Step [277/735], Loss: 0.0910\n",
      "Epoch [44/50], Step [278/735], Loss: 0.0433\n",
      "Epoch [44/50], Step [279/735], Loss: 0.1479\n",
      "Epoch [44/50], Step [280/735], Loss: 0.0949\n",
      "Epoch [44/50], Step [281/735], Loss: 0.0581\n",
      "Epoch [44/50], Step [282/735], Loss: 0.0493\n",
      "Epoch [44/50], Step [283/735], Loss: 0.1078\n",
      "Epoch [44/50], Step [284/735], Loss: 0.0422\n",
      "Epoch [44/50], Step [285/735], Loss: 0.0367\n",
      "Epoch [44/50], Step [286/735], Loss: 0.1850\n",
      "Epoch [44/50], Step [287/735], Loss: 0.1161\n",
      "Epoch [44/50], Step [288/735], Loss: 0.0969\n",
      "Epoch [44/50], Step [289/735], Loss: 0.0899\n",
      "Epoch [44/50], Step [290/735], Loss: 0.4303\n",
      "Epoch [44/50], Step [291/735], Loss: 0.0528\n",
      "Epoch [44/50], Step [292/735], Loss: 0.3134\n",
      "Epoch [44/50], Step [293/735], Loss: 0.2185\n",
      "Epoch [44/50], Step [294/735], Loss: 0.2047\n",
      "Epoch [44/50], Step [295/735], Loss: 0.1903\n",
      "Epoch [44/50], Step [296/735], Loss: 0.0935\n",
      "Epoch [44/50], Step [297/735], Loss: 0.0929\n",
      "Epoch [44/50], Step [298/735], Loss: 0.1407\n",
      "Epoch [44/50], Step [299/735], Loss: 0.1627\n",
      "Epoch [44/50], Step [300/735], Loss: 0.0539\n",
      "Epoch [44/50], Step [301/735], Loss: 0.1018\n",
      "Epoch [44/50], Step [302/735], Loss: 0.1495\n",
      "Epoch [44/50], Step [303/735], Loss: 0.0991\n",
      "Epoch [44/50], Step [304/735], Loss: 0.0822\n",
      "Epoch [44/50], Step [305/735], Loss: 0.0356\n",
      "Epoch [44/50], Step [306/735], Loss: 0.0953\n",
      "Epoch [44/50], Step [307/735], Loss: 0.1452\n",
      "Epoch [44/50], Step [308/735], Loss: 0.0909\n",
      "Epoch [44/50], Step [309/735], Loss: 0.1780\n",
      "Epoch [44/50], Step [310/735], Loss: 0.0583\n",
      "Epoch [44/50], Step [311/735], Loss: 0.0372\n",
      "Epoch [44/50], Step [312/735], Loss: 0.0698\n",
      "Epoch [44/50], Step [313/735], Loss: 0.0941\n",
      "Epoch [44/50], Step [314/735], Loss: 0.1433\n",
      "Epoch [44/50], Step [315/735], Loss: 0.5309\n",
      "Epoch [44/50], Step [316/735], Loss: 0.0880\n",
      "Epoch [44/50], Step [317/735], Loss: 1.8127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Step [318/735], Loss: 0.3356\n",
      "Epoch [44/50], Step [319/735], Loss: 0.0690\n",
      "Epoch [44/50], Step [320/735], Loss: 0.1109\n",
      "Epoch [44/50], Step [321/735], Loss: 0.1023\n",
      "Epoch [44/50], Step [322/735], Loss: 0.0488\n",
      "Epoch [44/50], Step [323/735], Loss: 0.1587\n",
      "Epoch [44/50], Step [324/735], Loss: 0.1028\n",
      "Epoch [44/50], Step [325/735], Loss: 0.1087\n",
      "Epoch [44/50], Step [326/735], Loss: 0.1493\n",
      "Epoch [44/50], Step [327/735], Loss: 0.0677\n",
      "Epoch [44/50], Step [328/735], Loss: 0.1254\n",
      "Epoch [44/50], Step [329/735], Loss: 0.4413\n",
      "Epoch [44/50], Step [330/735], Loss: 0.9874\n",
      "Epoch [44/50], Step [331/735], Loss: 0.0733\n",
      "Epoch [44/50], Step [332/735], Loss: 0.1626\n",
      "Epoch [44/50], Step [333/735], Loss: 0.1164\n",
      "Epoch [44/50], Step [334/735], Loss: 0.1549\n",
      "Epoch [44/50], Step [335/735], Loss: 0.1833\n",
      "Epoch [44/50], Step [336/735], Loss: 0.1213\n",
      "Epoch [44/50], Step [337/735], Loss: 0.0914\n",
      "Epoch [44/50], Step [338/735], Loss: 0.1027\n",
      "Epoch [44/50], Step [339/735], Loss: 0.0886\n",
      "Epoch [44/50], Step [340/735], Loss: 0.0549\n",
      "Epoch [44/50], Step [341/735], Loss: 0.1037\n",
      "Epoch [44/50], Step [342/735], Loss: 0.0537\n",
      "Epoch [44/50], Step [343/735], Loss: 0.0347\n",
      "Epoch [44/50], Step [344/735], Loss: 0.0826\n",
      "Epoch [44/50], Step [345/735], Loss: 0.0576\n",
      "Epoch [44/50], Step [346/735], Loss: 0.0614\n",
      "Epoch [44/50], Step [347/735], Loss: 0.0726\n",
      "Epoch [44/50], Step [348/735], Loss: 0.0657\n",
      "Epoch [44/50], Step [349/735], Loss: 0.0645\n",
      "Epoch [44/50], Step [350/735], Loss: 0.1207\n",
      "Epoch [44/50], Step [351/735], Loss: 0.7503\n",
      "Epoch [44/50], Step [352/735], Loss: 0.1106\n",
      "Epoch [44/50], Step [353/735], Loss: 0.0535\n",
      "Epoch [44/50], Step [354/735], Loss: 0.0762\n",
      "Epoch [44/50], Step [355/735], Loss: 0.3108\n",
      "Epoch [44/50], Step [356/735], Loss: 0.1445\n",
      "Epoch [44/50], Step [357/735], Loss: 0.0513\n",
      "Epoch [44/50], Step [358/735], Loss: 0.0697\n",
      "Epoch [44/50], Step [359/735], Loss: 0.0828\n",
      "Epoch [44/50], Step [360/735], Loss: 0.0639\n",
      "Epoch [44/50], Step [361/735], Loss: 0.0789\n",
      "Epoch [44/50], Step [362/735], Loss: 0.1556\n",
      "Epoch [44/50], Step [363/735], Loss: 0.1123\n",
      "Epoch [44/50], Step [364/735], Loss: 0.1810\n",
      "Epoch [44/50], Step [365/735], Loss: 0.0603\n",
      "Epoch [44/50], Step [366/735], Loss: 0.1746\n",
      "Epoch [44/50], Step [367/735], Loss: 0.0782\n",
      "Epoch [44/50], Step [368/735], Loss: 0.1249\n",
      "Epoch [44/50], Step [369/735], Loss: 0.1184\n",
      "Epoch [44/50], Step [370/735], Loss: 0.0694\n",
      "Epoch [44/50], Step [371/735], Loss: 0.0597\n",
      "Epoch [44/50], Step [372/735], Loss: 0.1082\n",
      "Epoch [44/50], Step [373/735], Loss: 0.0409\n",
      "Epoch [44/50], Step [374/735], Loss: 0.0489\n",
      "Epoch [44/50], Step [375/735], Loss: 0.0654\n",
      "Epoch [44/50], Step [376/735], Loss: 0.2698\n",
      "Epoch [44/50], Step [377/735], Loss: 0.1002\n",
      "Epoch [44/50], Step [378/735], Loss: 0.0879\n",
      "Epoch [44/50], Step [379/735], Loss: 0.1486\n",
      "Epoch [44/50], Step [380/735], Loss: 0.0396\n",
      "Epoch [44/50], Step [381/735], Loss: 0.0466\n",
      "Epoch [44/50], Step [382/735], Loss: 0.0418\n",
      "Epoch [44/50], Step [383/735], Loss: 0.0404\n",
      "Epoch [44/50], Step [384/735], Loss: 0.0509\n",
      "Epoch [44/50], Step [385/735], Loss: 0.0636\n",
      "Epoch [44/50], Step [386/735], Loss: 0.0606\n",
      "Epoch [44/50], Step [387/735], Loss: 0.0750\n",
      "Epoch [44/50], Step [388/735], Loss: 0.1677\n",
      "Epoch [44/50], Step [389/735], Loss: 0.0684\n",
      "Epoch [44/50], Step [390/735], Loss: 0.0950\n",
      "Epoch [44/50], Step [391/735], Loss: 0.1144\n",
      "Epoch [44/50], Step [392/735], Loss: 0.0791\n",
      "Epoch [44/50], Step [393/735], Loss: 0.1194\n",
      "Epoch [44/50], Step [394/735], Loss: 0.0898\n",
      "Epoch [44/50], Step [395/735], Loss: 0.0830\n",
      "Epoch [44/50], Step [396/735], Loss: 0.1030\n",
      "Epoch [44/50], Step [397/735], Loss: 0.0924\n",
      "Epoch [44/50], Step [398/735], Loss: 0.1116\n",
      "Epoch [44/50], Step [399/735], Loss: 0.0690\n",
      "Epoch [44/50], Step [400/735], Loss: 0.0722\n",
      "Epoch [44/50], Step [401/735], Loss: 0.0540\n",
      "Epoch [44/50], Step [402/735], Loss: 0.0843\n",
      "Epoch [44/50], Step [403/735], Loss: 0.1153\n",
      "Epoch [44/50], Step [404/735], Loss: 0.0350\n",
      "Epoch [44/50], Step [405/735], Loss: 0.1083\n",
      "Epoch [44/50], Step [406/735], Loss: 0.0601\n",
      "Epoch [44/50], Step [407/735], Loss: 0.0799\n",
      "Epoch [44/50], Step [408/735], Loss: 0.0555\n",
      "Epoch [44/50], Step [409/735], Loss: 0.0626\n",
      "Epoch [44/50], Step [410/735], Loss: 0.0945\n",
      "Epoch [44/50], Step [411/735], Loss: 0.0949\n",
      "Epoch [44/50], Step [412/735], Loss: 0.0642\n",
      "Epoch [44/50], Step [413/735], Loss: 0.0890\n",
      "Epoch [44/50], Step [414/735], Loss: 0.0866\n",
      "Epoch [44/50], Step [415/735], Loss: 0.1201\n",
      "Epoch [44/50], Step [416/735], Loss: 0.0457\n",
      "Epoch [44/50], Step [417/735], Loss: 0.3417\n",
      "Epoch [44/50], Step [418/735], Loss: 0.0462\n",
      "Epoch [44/50], Step [419/735], Loss: 1.3994\n",
      "Epoch [44/50], Step [420/735], Loss: 0.1916\n",
      "Epoch [44/50], Step [421/735], Loss: 0.0769\n",
      "Epoch [44/50], Step [422/735], Loss: 0.0549\n",
      "Epoch [44/50], Step [423/735], Loss: 0.0544\n",
      "Epoch [44/50], Step [424/735], Loss: 0.1145\n",
      "Epoch [44/50], Step [425/735], Loss: 0.0654\n",
      "Epoch [44/50], Step [426/735], Loss: 0.0536\n",
      "Epoch [44/50], Step [427/735], Loss: 0.0981\n",
      "Epoch [44/50], Step [428/735], Loss: 0.0898\n",
      "Epoch [44/50], Step [429/735], Loss: 0.0728\n",
      "Epoch [44/50], Step [430/735], Loss: 0.0558\n",
      "Epoch [44/50], Step [431/735], Loss: 0.6702\n",
      "Epoch [44/50], Step [432/735], Loss: 0.0610\n",
      "Epoch [44/50], Step [433/735], Loss: 0.2008\n",
      "Epoch [44/50], Step [434/735], Loss: 0.0860\n",
      "Epoch [44/50], Step [435/735], Loss: 0.0827\n",
      "Epoch [44/50], Step [436/735], Loss: 0.0586\n",
      "Epoch [44/50], Step [437/735], Loss: 0.0952\n",
      "Epoch [44/50], Step [438/735], Loss: 0.1260\n",
      "Epoch [44/50], Step [439/735], Loss: 0.1003\n",
      "Epoch [44/50], Step [440/735], Loss: 0.0826\n",
      "Epoch [44/50], Step [441/735], Loss: 0.0447\n",
      "Epoch [44/50], Step [442/735], Loss: 0.0880\n",
      "Epoch [44/50], Step [443/735], Loss: 0.3023\n",
      "Epoch [44/50], Step [444/735], Loss: 0.1056\n",
      "Epoch [44/50], Step [445/735], Loss: 0.1560\n",
      "Epoch [44/50], Step [446/735], Loss: 0.2901\n",
      "Epoch [44/50], Step [447/735], Loss: 0.0825\n",
      "Epoch [44/50], Step [448/735], Loss: 0.1097\n",
      "Epoch [44/50], Step [449/735], Loss: 0.0400\n",
      "Epoch [44/50], Step [450/735], Loss: 0.1059\n",
      "Epoch [44/50], Step [451/735], Loss: 0.2342\n",
      "Epoch [44/50], Step [452/735], Loss: 0.1253\n",
      "Epoch [44/50], Step [453/735], Loss: 0.1466\n",
      "Epoch [44/50], Step [454/735], Loss: 0.2582\n",
      "Epoch [44/50], Step [455/735], Loss: 0.1167\n",
      "Epoch [44/50], Step [456/735], Loss: 0.1107\n",
      "Epoch [44/50], Step [457/735], Loss: 0.1950\n",
      "Epoch [44/50], Step [458/735], Loss: 0.0673\n",
      "Epoch [44/50], Step [459/735], Loss: 0.0909\n",
      "Epoch [44/50], Step [460/735], Loss: 0.0697\n",
      "Epoch [44/50], Step [461/735], Loss: 0.0536\n",
      "Epoch [44/50], Step [462/735], Loss: 0.0577\n",
      "Epoch [44/50], Step [463/735], Loss: 0.0995\n",
      "Epoch [44/50], Step [464/735], Loss: 0.1487\n",
      "Epoch [44/50], Step [465/735], Loss: 0.1389\n",
      "Epoch [44/50], Step [466/735], Loss: 0.0861\n",
      "Epoch [44/50], Step [467/735], Loss: 0.1668\n",
      "Epoch [44/50], Step [468/735], Loss: 0.1067\n",
      "Epoch [44/50], Step [469/735], Loss: 0.1628\n",
      "Epoch [44/50], Step [470/735], Loss: 0.0727\n",
      "Epoch [44/50], Step [471/735], Loss: 0.1055\n",
      "Epoch [44/50], Step [472/735], Loss: 0.0867\n",
      "Epoch [44/50], Step [473/735], Loss: 1.4729\n",
      "Epoch [44/50], Step [474/735], Loss: 0.0696\n",
      "Epoch [44/50], Step [475/735], Loss: 0.0613\n",
      "Epoch [44/50], Step [476/735], Loss: 0.0930\n",
      "Epoch [44/50], Step [477/735], Loss: 0.1860\n",
      "Epoch [44/50], Step [478/735], Loss: 0.1005\n",
      "Epoch [44/50], Step [479/735], Loss: 0.0964\n",
      "Epoch [44/50], Step [480/735], Loss: 0.0745\n",
      "Epoch [44/50], Step [481/735], Loss: 0.0433\n",
      "Epoch [44/50], Step [482/735], Loss: 0.0552\n",
      "Epoch [44/50], Step [483/735], Loss: 0.0888\n",
      "Epoch [44/50], Step [484/735], Loss: 0.1179\n",
      "Epoch [44/50], Step [485/735], Loss: 0.1228\n",
      "Epoch [44/50], Step [486/735], Loss: 0.0474\n",
      "Epoch [44/50], Step [487/735], Loss: 0.7027\n",
      "Epoch [44/50], Step [488/735], Loss: 0.0558\n",
      "Epoch [44/50], Step [489/735], Loss: 0.1496\n",
      "Epoch [44/50], Step [490/735], Loss: 0.1150\n",
      "Epoch [44/50], Step [491/735], Loss: 0.0707\n",
      "Epoch [44/50], Step [492/735], Loss: 0.1917\n",
      "Epoch [44/50], Step [493/735], Loss: 0.0837\n",
      "Epoch [44/50], Step [494/735], Loss: 0.1170\n",
      "Epoch [44/50], Step [495/735], Loss: 0.0185\n",
      "Epoch [44/50], Step [496/735], Loss: 0.0569\n",
      "Epoch [44/50], Step [497/735], Loss: 0.0684\n",
      "Epoch [44/50], Step [498/735], Loss: 0.1869\n",
      "Epoch [44/50], Step [499/735], Loss: 0.0755\n",
      "Epoch [44/50], Step [500/735], Loss: 0.0544\n",
      "Epoch [44/50], Step [501/735], Loss: 0.1067\n",
      "Epoch [44/50], Step [502/735], Loss: 0.0378\n",
      "Epoch [44/50], Step [503/735], Loss: 0.0542\n",
      "Epoch [44/50], Step [504/735], Loss: 0.0776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Step [505/735], Loss: 0.0607\n",
      "Epoch [44/50], Step [506/735], Loss: 0.0518\n",
      "Epoch [44/50], Step [507/735], Loss: 0.0882\n",
      "Epoch [44/50], Step [508/735], Loss: 0.0370\n",
      "Epoch [44/50], Step [509/735], Loss: 0.1015\n",
      "Epoch [44/50], Step [510/735], Loss: 0.0624\n",
      "Epoch [44/50], Step [511/735], Loss: 0.0413\n",
      "Epoch [44/50], Step [512/735], Loss: 0.0663\n",
      "Epoch [44/50], Step [513/735], Loss: 0.0488\n",
      "Epoch [44/50], Step [514/735], Loss: 0.1026\n",
      "Epoch [44/50], Step [515/735], Loss: 0.0511\n",
      "Epoch [44/50], Step [516/735], Loss: 0.0933\n",
      "Epoch [44/50], Step [517/735], Loss: 0.0482\n",
      "Epoch [44/50], Step [518/735], Loss: 0.0769\n",
      "Epoch [44/50], Step [519/735], Loss: 0.1213\n",
      "Epoch [44/50], Step [520/735], Loss: 0.0619\n",
      "Epoch [44/50], Step [521/735], Loss: 0.0725\n",
      "Epoch [44/50], Step [522/735], Loss: 0.1190\n",
      "Epoch [44/50], Step [523/735], Loss: 0.4087\n",
      "Epoch [44/50], Step [524/735], Loss: 0.1094\n",
      "Epoch [44/50], Step [525/735], Loss: 0.0600\n",
      "Epoch [44/50], Step [526/735], Loss: 0.0812\n",
      "Epoch [44/50], Step [527/735], Loss: 0.0682\n",
      "Epoch [44/50], Step [528/735], Loss: 0.0433\n",
      "Epoch [44/50], Step [529/735], Loss: 0.0790\n",
      "Epoch [44/50], Step [530/735], Loss: 0.1397\n",
      "Epoch [44/50], Step [531/735], Loss: 1.2191\n",
      "Epoch [44/50], Step [532/735], Loss: 0.1082\n",
      "Epoch [44/50], Step [533/735], Loss: 0.0794\n",
      "Epoch [44/50], Step [534/735], Loss: 0.1067\n",
      "Epoch [44/50], Step [535/735], Loss: 0.1570\n",
      "Epoch [44/50], Step [536/735], Loss: 0.0980\n",
      "Epoch [44/50], Step [537/735], Loss: 0.0805\n",
      "Epoch [44/50], Step [538/735], Loss: 0.0586\n",
      "Epoch [44/50], Step [539/735], Loss: 0.1898\n",
      "Epoch [44/50], Step [540/735], Loss: 0.0496\n",
      "Epoch [44/50], Step [541/735], Loss: 0.1512\n",
      "Epoch [44/50], Step [542/735], Loss: 0.0742\n",
      "Epoch [44/50], Step [543/735], Loss: 0.0655\n",
      "Epoch [44/50], Step [544/735], Loss: 0.0426\n",
      "Epoch [44/50], Step [545/735], Loss: 0.0950\n",
      "Epoch [44/50], Step [546/735], Loss: 0.0590\n",
      "Epoch [44/50], Step [547/735], Loss: 0.0502\n",
      "Epoch [44/50], Step [548/735], Loss: 0.0455\n",
      "Epoch [44/50], Step [549/735], Loss: 0.1126\n",
      "Epoch [44/50], Step [550/735], Loss: 0.1146\n",
      "Epoch [44/50], Step [551/735], Loss: 0.5214\n",
      "Epoch [44/50], Step [552/735], Loss: 0.0926\n",
      "Epoch [44/50], Step [553/735], Loss: 0.0752\n",
      "Epoch [44/50], Step [554/735], Loss: 0.0327\n",
      "Epoch [44/50], Step [555/735], Loss: 0.0639\n",
      "Epoch [44/50], Step [556/735], Loss: 0.1326\n",
      "Epoch [44/50], Step [557/735], Loss: 0.0849\n",
      "Epoch [44/50], Step [558/735], Loss: 0.0782\n",
      "Epoch [44/50], Step [559/735], Loss: 0.0950\n",
      "Epoch [44/50], Step [560/735], Loss: 0.0622\n",
      "Epoch [44/50], Step [561/735], Loss: 0.0718\n",
      "Epoch [44/50], Step [562/735], Loss: 0.1091\n",
      "Epoch [44/50], Step [563/735], Loss: 0.0896\n",
      "Epoch [44/50], Step [564/735], Loss: 0.0670\n",
      "Epoch [44/50], Step [565/735], Loss: 0.1539\n",
      "Epoch [44/50], Step [566/735], Loss: 0.0881\n",
      "Epoch [44/50], Step [567/735], Loss: 0.0972\n",
      "Epoch [44/50], Step [568/735], Loss: 0.3711\n",
      "Epoch [44/50], Step [569/735], Loss: 0.1203\n",
      "Epoch [44/50], Step [570/735], Loss: 0.0339\n",
      "Epoch [44/50], Step [571/735], Loss: 0.1054\n",
      "Epoch [44/50], Step [572/735], Loss: 0.0665\n",
      "Epoch [44/50], Step [573/735], Loss: 0.0811\n",
      "Epoch [44/50], Step [574/735], Loss: 0.0686\n",
      "Epoch [44/50], Step [575/735], Loss: 0.0885\n",
      "Epoch [44/50], Step [576/735], Loss: 0.1339\n",
      "Epoch [44/50], Step [577/735], Loss: 0.0501\n",
      "Epoch [44/50], Step [578/735], Loss: 0.0864\n",
      "Epoch [44/50], Step [579/735], Loss: 0.0924\n",
      "Epoch [44/50], Step [580/735], Loss: 0.0689\n",
      "Epoch [44/50], Step [581/735], Loss: 0.0855\n",
      "Epoch [44/50], Step [582/735], Loss: 0.0219\n",
      "Epoch [44/50], Step [583/735], Loss: 0.6390\n",
      "Epoch [44/50], Step [584/735], Loss: 0.0538\n",
      "Epoch [44/50], Step [585/735], Loss: 0.1783\n",
      "Epoch [44/50], Step [586/735], Loss: 0.0526\n",
      "Epoch [44/50], Step [587/735], Loss: 0.0502\n",
      "Epoch [44/50], Step [588/735], Loss: 0.1057\n",
      "Epoch [44/50], Step [589/735], Loss: 0.1965\n",
      "Epoch [44/50], Step [590/735], Loss: 0.0669\n",
      "Epoch [44/50], Step [591/735], Loss: 0.0507\n",
      "Epoch [44/50], Step [592/735], Loss: 0.0759\n",
      "Epoch [44/50], Step [593/735], Loss: 0.4490\n",
      "Epoch [44/50], Step [594/735], Loss: 0.0472\n",
      "Epoch [44/50], Step [595/735], Loss: 0.0322\n",
      "Epoch [44/50], Step [596/735], Loss: 0.1438\n",
      "Epoch [44/50], Step [597/735], Loss: 0.0888\n",
      "Epoch [44/50], Step [598/735], Loss: 0.1075\n",
      "Epoch [44/50], Step [599/735], Loss: 1.3111\n",
      "Epoch [44/50], Step [600/735], Loss: 0.0851\n",
      "Epoch [44/50], Step [601/735], Loss: 0.0655\n",
      "Epoch [44/50], Step [602/735], Loss: 0.0924\n",
      "Epoch [44/50], Step [603/735], Loss: 0.1524\n",
      "Epoch [44/50], Step [604/735], Loss: 0.0886\n",
      "Epoch [44/50], Step [605/735], Loss: 0.1119\n",
      "Epoch [44/50], Step [606/735], Loss: 0.0803\n",
      "Epoch [44/50], Step [607/735], Loss: 0.0590\n",
      "Epoch [44/50], Step [608/735], Loss: 0.0775\n",
      "Epoch [44/50], Step [609/735], Loss: 0.1049\n",
      "Epoch [44/50], Step [610/735], Loss: 0.1135\n",
      "Epoch [44/50], Step [611/735], Loss: 0.4553\n",
      "Epoch [44/50], Step [612/735], Loss: 0.4383\n",
      "Epoch [44/50], Step [613/735], Loss: 0.0415\n",
      "Epoch [44/50], Step [614/735], Loss: 0.0722\n",
      "Epoch [44/50], Step [615/735], Loss: 0.0649\n",
      "Epoch [44/50], Step [616/735], Loss: 0.0563\n",
      "Epoch [44/50], Step [617/735], Loss: 0.0345\n",
      "Epoch [44/50], Step [618/735], Loss: 0.1135\n",
      "Epoch [44/50], Step [619/735], Loss: 0.1297\n",
      "Epoch [44/50], Step [620/735], Loss: 0.1170\n",
      "Epoch [44/50], Step [621/735], Loss: 0.1686\n",
      "Epoch [44/50], Step [622/735], Loss: 0.0481\n",
      "Epoch [44/50], Step [623/735], Loss: 0.0910\n",
      "Epoch [44/50], Step [624/735], Loss: 0.0470\n",
      "Epoch [44/50], Step [625/735], Loss: 0.0317\n",
      "Epoch [44/50], Step [626/735], Loss: 0.0590\n",
      "Epoch [44/50], Step [627/735], Loss: 0.6747\n",
      "Epoch [44/50], Step [628/735], Loss: 0.0818\n",
      "Epoch [44/50], Step [629/735], Loss: 0.0851\n",
      "Epoch [44/50], Step [630/735], Loss: 0.0628\n",
      "Epoch [44/50], Step [631/735], Loss: 0.0714\n",
      "Epoch [44/50], Step [632/735], Loss: 0.1337\n",
      "Epoch [44/50], Step [633/735], Loss: 0.0619\n",
      "Epoch [44/50], Step [634/735], Loss: 0.0810\n",
      "Epoch [44/50], Step [635/735], Loss: 0.0788\n",
      "Epoch [44/50], Step [636/735], Loss: 0.0524\n",
      "Epoch [44/50], Step [637/735], Loss: 0.0678\n",
      "Epoch [44/50], Step [638/735], Loss: 0.0713\n",
      "Epoch [44/50], Step [639/735], Loss: 1.4388\n",
      "Epoch [44/50], Step [640/735], Loss: 0.1582\n",
      "Epoch [44/50], Step [641/735], Loss: 0.0597\n",
      "Epoch [44/50], Step [642/735], Loss: 0.1234\n",
      "Epoch [44/50], Step [643/735], Loss: 0.0493\n",
      "Epoch [44/50], Step [644/735], Loss: 0.0530\n",
      "Epoch [44/50], Step [645/735], Loss: 0.1056\n",
      "Epoch [44/50], Step [646/735], Loss: 0.0921\n",
      "Epoch [44/50], Step [647/735], Loss: 0.1615\n",
      "Epoch [44/50], Step [648/735], Loss: 0.1475\n",
      "Epoch [44/50], Step [649/735], Loss: 0.0644\n",
      "Epoch [44/50], Step [650/735], Loss: 0.1346\n",
      "Epoch [44/50], Step [651/735], Loss: 0.0401\n",
      "Epoch [44/50], Step [652/735], Loss: 0.6833\n",
      "Epoch [44/50], Step [653/735], Loss: 0.1394\n",
      "Epoch [44/50], Step [654/735], Loss: 0.0790\n",
      "Epoch [44/50], Step [655/735], Loss: 0.0682\n",
      "Epoch [44/50], Step [656/735], Loss: 0.0756\n",
      "Epoch [44/50], Step [657/735], Loss: 0.1442\n",
      "Epoch [44/50], Step [658/735], Loss: 0.0658\n",
      "Epoch [44/50], Step [659/735], Loss: 0.2576\n",
      "Epoch [44/50], Step [660/735], Loss: 0.0570\n",
      "Epoch [44/50], Step [661/735], Loss: 0.0766\n",
      "Epoch [44/50], Step [662/735], Loss: 0.0801\n",
      "Epoch [44/50], Step [663/735], Loss: 0.0800\n",
      "Epoch [44/50], Step [664/735], Loss: 0.0404\n",
      "Epoch [44/50], Step [665/735], Loss: 0.1191\n",
      "Epoch [44/50], Step [666/735], Loss: 0.1370\n",
      "Epoch [44/50], Step [667/735], Loss: 0.0547\n",
      "Epoch [44/50], Step [668/735], Loss: 0.1282\n",
      "Epoch [44/50], Step [669/735], Loss: 0.1093\n",
      "Epoch [44/50], Step [670/735], Loss: 0.0647\n",
      "Epoch [44/50], Step [671/735], Loss: 1.0735\n",
      "Epoch [44/50], Step [672/735], Loss: 0.0861\n",
      "Epoch [44/50], Step [673/735], Loss: 0.1084\n",
      "Epoch [44/50], Step [674/735], Loss: 0.1032\n",
      "Epoch [44/50], Step [675/735], Loss: 0.1147\n",
      "Epoch [44/50], Step [676/735], Loss: 0.0637\n",
      "Epoch [44/50], Step [677/735], Loss: 0.0971\n",
      "Epoch [44/50], Step [678/735], Loss: 0.0966\n",
      "Epoch [44/50], Step [679/735], Loss: 0.0852\n",
      "Epoch [44/50], Step [680/735], Loss: 0.0617\n",
      "Epoch [44/50], Step [681/735], Loss: 0.0435\n",
      "Epoch [44/50], Step [682/735], Loss: 0.0715\n",
      "Epoch [44/50], Step [683/735], Loss: 0.0801\n",
      "Epoch [44/50], Step [684/735], Loss: 0.0809\n",
      "Epoch [44/50], Step [685/735], Loss: 0.1561\n",
      "Epoch [44/50], Step [686/735], Loss: 0.1062\n",
      "Epoch [44/50], Step [687/735], Loss: 0.1067\n",
      "Epoch [44/50], Step [688/735], Loss: 0.1662\n",
      "Epoch [44/50], Step [689/735], Loss: 0.0905\n",
      "Epoch [44/50], Step [690/735], Loss: 0.1213\n",
      "Epoch [44/50], Step [691/735], Loss: 0.0810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Step [692/735], Loss: 0.0514\n",
      "Epoch [44/50], Step [693/735], Loss: 0.0811\n",
      "Epoch [44/50], Step [694/735], Loss: 0.0933\n",
      "Epoch [44/50], Step [695/735], Loss: 0.2236\n",
      "Epoch [44/50], Step [696/735], Loss: 0.0489\n",
      "Epoch [44/50], Step [697/735], Loss: 0.1210\n",
      "Epoch [44/50], Step [698/735], Loss: 0.1178\n",
      "Epoch [44/50], Step [699/735], Loss: 0.0810\n",
      "Epoch [44/50], Step [700/735], Loss: 0.0637\n",
      "Epoch [44/50], Step [701/735], Loss: 0.1387\n",
      "Epoch [44/50], Step [702/735], Loss: 0.0941\n",
      "Epoch [44/50], Step [703/735], Loss: 0.0540\n",
      "Epoch [44/50], Step [704/735], Loss: 0.0776\n",
      "Epoch [44/50], Step [705/735], Loss: 0.0773\n",
      "Epoch [44/50], Step [706/735], Loss: 0.1091\n",
      "Epoch [44/50], Step [707/735], Loss: 0.0835\n",
      "Epoch [44/50], Step [708/735], Loss: 0.5469\n",
      "Epoch [44/50], Step [709/735], Loss: 0.1768\n",
      "Epoch [44/50], Step [710/735], Loss: 0.1080\n",
      "Epoch [44/50], Step [711/735], Loss: 0.3200\n",
      "Epoch [44/50], Step [712/735], Loss: 0.4632\n",
      "Epoch [44/50], Step [713/735], Loss: 0.1213\n",
      "Epoch [44/50], Step [714/735], Loss: 0.0946\n",
      "Epoch [44/50], Step [715/735], Loss: 0.0568\n",
      "Epoch [44/50], Step [716/735], Loss: 0.0601\n",
      "Epoch [44/50], Step [717/735], Loss: 0.0423\n",
      "Epoch [44/50], Step [718/735], Loss: 0.0602\n",
      "Epoch [44/50], Step [719/735], Loss: 0.0888\n",
      "Epoch [44/50], Step [720/735], Loss: 0.1461\n",
      "Epoch [44/50], Step [721/735], Loss: 0.1462\n",
      "Epoch [44/50], Step [722/735], Loss: 0.1010\n",
      "Epoch [44/50], Step [723/735], Loss: 0.0716\n",
      "Epoch [44/50], Step [724/735], Loss: 0.1751\n",
      "Epoch [44/50], Step [725/735], Loss: 0.0653\n",
      "Epoch [44/50], Step [726/735], Loss: 0.3995\n",
      "Epoch [44/50], Step [727/735], Loss: 0.1350\n",
      "Epoch [44/50], Step [728/735], Loss: 0.1979\n",
      "Epoch [44/50], Step [729/735], Loss: 0.0860\n",
      "Epoch [44/50], Step [730/735], Loss: 0.0826\n",
      "Epoch [44/50], Step [731/735], Loss: 0.0991\n",
      "Epoch [44/50], Step [732/735], Loss: 0.0899\n",
      "Epoch [44/50], Step [733/735], Loss: 0.0968\n",
      "Epoch [44/50], Step [734/735], Loss: 0.1664\n",
      "Epoch [44/50], Step [735/735], Loss: 0.1827\n",
      "Epoch [45/50], Step [1/735], Loss: 0.0826\n",
      "Epoch [45/50], Step [2/735], Loss: 0.5518\n",
      "Epoch [45/50], Step [3/735], Loss: 0.1038\n",
      "Epoch [45/50], Step [4/735], Loss: 0.1213\n",
      "Epoch [45/50], Step [5/735], Loss: 0.3428\n",
      "Epoch [45/50], Step [6/735], Loss: 0.1461\n",
      "Epoch [45/50], Step [7/735], Loss: 0.1194\n",
      "Epoch [45/50], Step [8/735], Loss: 0.0913\n",
      "Epoch [45/50], Step [9/735], Loss: 0.0871\n",
      "Epoch [45/50], Step [10/735], Loss: 0.0709\n",
      "Epoch [45/50], Step [11/735], Loss: 0.0795\n",
      "Epoch [45/50], Step [12/735], Loss: 0.1121\n",
      "Epoch [45/50], Step [13/735], Loss: 0.0590\n",
      "Epoch [45/50], Step [14/735], Loss: 0.0663\n",
      "Epoch [45/50], Step [15/735], Loss: 0.0582\n",
      "Epoch [45/50], Step [16/735], Loss: 0.0476\n",
      "Epoch [45/50], Step [17/735], Loss: 0.2290\n",
      "Epoch [45/50], Step [18/735], Loss: 0.1945\n",
      "Epoch [45/50], Step [19/735], Loss: 0.0774\n",
      "Epoch [45/50], Step [20/735], Loss: 0.0806\n",
      "Epoch [45/50], Step [21/735], Loss: 0.0697\n",
      "Epoch [45/50], Step [22/735], Loss: 0.6435\n",
      "Epoch [45/50], Step [23/735], Loss: 0.1064\n",
      "Epoch [45/50], Step [24/735], Loss: 0.0570\n",
      "Epoch [45/50], Step [25/735], Loss: 0.1265\n",
      "Epoch [45/50], Step [26/735], Loss: 0.1006\n",
      "Epoch [45/50], Step [27/735], Loss: 0.0432\n",
      "Epoch [45/50], Step [28/735], Loss: 0.5857\n",
      "Epoch [45/50], Step [29/735], Loss: 0.0628\n",
      "Epoch [45/50], Step [30/735], Loss: 0.1349\n",
      "Epoch [45/50], Step [31/735], Loss: 0.0310\n",
      "Epoch [45/50], Step [32/735], Loss: 0.0969\n",
      "Epoch [45/50], Step [33/735], Loss: 0.0544\n",
      "Epoch [45/50], Step [34/735], Loss: 0.0767\n",
      "Epoch [45/50], Step [35/735], Loss: 0.0704\n",
      "Epoch [45/50], Step [36/735], Loss: 0.0612\n",
      "Epoch [45/50], Step [37/735], Loss: 0.0337\n",
      "Epoch [45/50], Step [38/735], Loss: 0.0699\n",
      "Epoch [45/50], Step [39/735], Loss: 0.1283\n",
      "Epoch [45/50], Step [40/735], Loss: 0.0573\n",
      "Epoch [45/50], Step [41/735], Loss: 0.0237\n",
      "Epoch [45/50], Step [42/735], Loss: 0.0402\n",
      "Epoch [45/50], Step [43/735], Loss: 0.0680\n",
      "Epoch [45/50], Step [44/735], Loss: 0.1913\n",
      "Epoch [45/50], Step [45/735], Loss: 0.2296\n",
      "Epoch [45/50], Step [46/735], Loss: 0.0414\n",
      "Epoch [45/50], Step [47/735], Loss: 0.0341\n",
      "Epoch [45/50], Step [48/735], Loss: 0.1012\n",
      "Epoch [45/50], Step [49/735], Loss: 0.0600\n",
      "Epoch [45/50], Step [50/735], Loss: 0.1257\n",
      "Epoch [45/50], Step [51/735], Loss: 0.0652\n",
      "Epoch [45/50], Step [52/735], Loss: 0.0697\n",
      "Epoch [45/50], Step [53/735], Loss: 0.1061\n",
      "Epoch [45/50], Step [54/735], Loss: 0.0365\n",
      "Epoch [45/50], Step [55/735], Loss: 0.1078\n",
      "Epoch [45/50], Step [56/735], Loss: 0.0740\n",
      "Epoch [45/50], Step [57/735], Loss: 0.0659\n",
      "Epoch [45/50], Step [58/735], Loss: 0.0882\n",
      "Epoch [45/50], Step [59/735], Loss: 0.0553\n",
      "Epoch [45/50], Step [60/735], Loss: 0.5181\n",
      "Epoch [45/50], Step [61/735], Loss: 0.1303\n",
      "Epoch [45/50], Step [62/735], Loss: 0.0818\n",
      "Epoch [45/50], Step [63/735], Loss: 0.0325\n",
      "Epoch [45/50], Step [64/735], Loss: 0.1177\n",
      "Epoch [45/50], Step [65/735], Loss: 0.0413\n",
      "Epoch [45/50], Step [66/735], Loss: 0.1879\n",
      "Epoch [45/50], Step [67/735], Loss: 0.0826\n",
      "Epoch [45/50], Step [68/735], Loss: 0.6712\n",
      "Epoch [45/50], Step [69/735], Loss: 0.0355\n",
      "Epoch [45/50], Step [70/735], Loss: 0.1418\n",
      "Epoch [45/50], Step [71/735], Loss: 0.0367\n",
      "Epoch [45/50], Step [72/735], Loss: 0.6169\n",
      "Epoch [45/50], Step [73/735], Loss: 0.0548\n",
      "Epoch [45/50], Step [74/735], Loss: 0.0335\n",
      "Epoch [45/50], Step [75/735], Loss: 0.1088\n",
      "Epoch [45/50], Step [76/735], Loss: 0.0698\n",
      "Epoch [45/50], Step [77/735], Loss: 0.0804\n",
      "Epoch [45/50], Step [78/735], Loss: 0.0641\n",
      "Epoch [45/50], Step [79/735], Loss: 0.0994\n",
      "Epoch [45/50], Step [80/735], Loss: 0.0986\n",
      "Epoch [45/50], Step [81/735], Loss: 0.0966\n",
      "Epoch [45/50], Step [82/735], Loss: 0.0746\n",
      "Epoch [45/50], Step [83/735], Loss: 0.0818\n",
      "Epoch [45/50], Step [84/735], Loss: 0.0821\n",
      "Epoch [45/50], Step [85/735], Loss: 0.1385\n",
      "Epoch [45/50], Step [86/735], Loss: 0.1550\n",
      "Epoch [45/50], Step [87/735], Loss: 0.0462\n",
      "Epoch [45/50], Step [88/735], Loss: 0.0853\n",
      "Epoch [45/50], Step [89/735], Loss: 0.1214\n",
      "Epoch [45/50], Step [90/735], Loss: 0.0397\n",
      "Epoch [45/50], Step [91/735], Loss: 0.0700\n",
      "Epoch [45/50], Step [92/735], Loss: 0.0453\n",
      "Epoch [45/50], Step [93/735], Loss: 0.0583\n",
      "Epoch [45/50], Step [94/735], Loss: 0.1095\n",
      "Epoch [45/50], Step [95/735], Loss: 0.1020\n",
      "Epoch [45/50], Step [96/735], Loss: 0.0527\n",
      "Epoch [45/50], Step [97/735], Loss: 0.1153\n",
      "Epoch [45/50], Step [98/735], Loss: 0.0919\n",
      "Epoch [45/50], Step [99/735], Loss: 0.1283\n",
      "Epoch [45/50], Step [100/735], Loss: 0.2353\n",
      "Epoch [45/50], Step [101/735], Loss: 0.0669\n",
      "Epoch [45/50], Step [102/735], Loss: 0.1032\n",
      "Epoch [45/50], Step [103/735], Loss: 0.2628\n",
      "Epoch [45/50], Step [104/735], Loss: 0.0642\n",
      "Epoch [45/50], Step [105/735], Loss: 0.0519\n",
      "Epoch [45/50], Step [106/735], Loss: 0.0853\n",
      "Epoch [45/50], Step [107/735], Loss: 0.1259\n",
      "Epoch [45/50], Step [108/735], Loss: 0.0862\n",
      "Epoch [45/50], Step [109/735], Loss: 0.1210\n",
      "Epoch [45/50], Step [110/735], Loss: 0.1616\n",
      "Epoch [45/50], Step [111/735], Loss: 0.0759\n",
      "Epoch [45/50], Step [112/735], Loss: 0.9728\n",
      "Epoch [45/50], Step [113/735], Loss: 0.1132\n",
      "Epoch [45/50], Step [114/735], Loss: 0.1013\n",
      "Epoch [45/50], Step [115/735], Loss: 0.1650\n",
      "Epoch [45/50], Step [116/735], Loss: 0.3763\n",
      "Epoch [45/50], Step [117/735], Loss: 0.1505\n",
      "Epoch [45/50], Step [118/735], Loss: 0.0390\n",
      "Epoch [45/50], Step [119/735], Loss: 0.0635\n",
      "Epoch [45/50], Step [120/735], Loss: 0.1829\n",
      "Epoch [45/50], Step [121/735], Loss: 0.0634\n",
      "Epoch [45/50], Step [122/735], Loss: 0.1244\n",
      "Epoch [45/50], Step [123/735], Loss: 0.0812\n",
      "Epoch [45/50], Step [124/735], Loss: 0.0781\n",
      "Epoch [45/50], Step [125/735], Loss: 0.1910\n",
      "Epoch [45/50], Step [126/735], Loss: 0.0411\n",
      "Epoch [45/50], Step [127/735], Loss: 0.1260\n",
      "Epoch [45/50], Step [128/735], Loss: 0.1912\n",
      "Epoch [45/50], Step [129/735], Loss: 0.0763\n",
      "Epoch [45/50], Step [130/735], Loss: 0.0589\n",
      "Epoch [45/50], Step [131/735], Loss: 0.2569\n",
      "Epoch [45/50], Step [132/735], Loss: 0.0653\n",
      "Epoch [45/50], Step [133/735], Loss: 0.8359\n",
      "Epoch [45/50], Step [134/735], Loss: 0.2501\n",
      "Epoch [45/50], Step [135/735], Loss: 0.1233\n",
      "Epoch [45/50], Step [136/735], Loss: 0.1398\n",
      "Epoch [45/50], Step [137/735], Loss: 0.0996\n",
      "Epoch [45/50], Step [138/735], Loss: 0.2498\n",
      "Epoch [45/50], Step [139/735], Loss: 0.0526\n",
      "Epoch [45/50], Step [140/735], Loss: 0.1322\n",
      "Epoch [45/50], Step [141/735], Loss: 0.0536\n",
      "Epoch [45/50], Step [142/735], Loss: 0.0544\n",
      "Epoch [45/50], Step [143/735], Loss: 0.1199\n",
      "Epoch [45/50], Step [144/735], Loss: 0.2145\n",
      "Epoch [45/50], Step [145/735], Loss: 0.1728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Step [146/735], Loss: 0.0852\n",
      "Epoch [45/50], Step [147/735], Loss: 0.1318\n",
      "Epoch [45/50], Step [148/735], Loss: 0.1436\n",
      "Epoch [45/50], Step [149/735], Loss: 0.1441\n",
      "Epoch [45/50], Step [150/735], Loss: 0.1325\n",
      "Epoch [45/50], Step [151/735], Loss: 0.3625\n",
      "Epoch [45/50], Step [152/735], Loss: 0.4324\n",
      "Epoch [45/50], Step [153/735], Loss: 0.1124\n",
      "Epoch [45/50], Step [154/735], Loss: 0.0490\n",
      "Epoch [45/50], Step [155/735], Loss: 0.0814\n",
      "Epoch [45/50], Step [156/735], Loss: 0.0947\n",
      "Epoch [45/50], Step [157/735], Loss: 0.0497\n",
      "Epoch [45/50], Step [158/735], Loss: 0.1548\n",
      "Epoch [45/50], Step [159/735], Loss: 0.1279\n",
      "Epoch [45/50], Step [160/735], Loss: 0.2157\n",
      "Epoch [45/50], Step [161/735], Loss: 0.0969\n",
      "Epoch [45/50], Step [162/735], Loss: 0.0992\n",
      "Epoch [45/50], Step [163/735], Loss: 0.1441\n",
      "Epoch [45/50], Step [164/735], Loss: 0.1338\n",
      "Epoch [45/50], Step [165/735], Loss: 0.0520\n",
      "Epoch [45/50], Step [166/735], Loss: 0.0756\n",
      "Epoch [45/50], Step [167/735], Loss: 0.1323\n",
      "Epoch [45/50], Step [168/735], Loss: 0.0363\n",
      "Epoch [45/50], Step [169/735], Loss: 0.0930\n",
      "Epoch [45/50], Step [170/735], Loss: 0.1280\n",
      "Epoch [45/50], Step [171/735], Loss: 0.0950\n",
      "Epoch [45/50], Step [172/735], Loss: 0.0696\n",
      "Epoch [45/50], Step [173/735], Loss: 0.1619\n",
      "Epoch [45/50], Step [174/735], Loss: 0.0779\n",
      "Epoch [45/50], Step [175/735], Loss: 0.0699\n",
      "Epoch [45/50], Step [176/735], Loss: 0.0459\n",
      "Epoch [45/50], Step [177/735], Loss: 0.1498\n",
      "Epoch [45/50], Step [178/735], Loss: 0.1083\n",
      "Epoch [45/50], Step [179/735], Loss: 0.1101\n",
      "Epoch [45/50], Step [180/735], Loss: 0.0513\n",
      "Epoch [45/50], Step [181/735], Loss: 0.3794\n",
      "Epoch [45/50], Step [182/735], Loss: 0.0987\n",
      "Epoch [45/50], Step [183/735], Loss: 0.0516\n",
      "Epoch [45/50], Step [184/735], Loss: 0.0879\n",
      "Epoch [45/50], Step [185/735], Loss: 0.0565\n",
      "Epoch [45/50], Step [186/735], Loss: 0.0963\n",
      "Epoch [45/50], Step [187/735], Loss: 0.1193\n",
      "Epoch [45/50], Step [188/735], Loss: 0.1375\n",
      "Epoch [45/50], Step [189/735], Loss: 0.0836\n",
      "Epoch [45/50], Step [190/735], Loss: 0.0839\n",
      "Epoch [45/50], Step [191/735], Loss: 0.0786\n",
      "Epoch [45/50], Step [192/735], Loss: 0.1549\n",
      "Epoch [45/50], Step [193/735], Loss: 0.1010\n",
      "Epoch [45/50], Step [194/735], Loss: 0.1592\n",
      "Epoch [45/50], Step [195/735], Loss: 0.3670\n",
      "Epoch [45/50], Step [196/735], Loss: 0.1617\n",
      "Epoch [45/50], Step [197/735], Loss: 0.0696\n",
      "Epoch [45/50], Step [198/735], Loss: 0.1333\n",
      "Epoch [45/50], Step [199/735], Loss: 0.2170\n",
      "Epoch [45/50], Step [200/735], Loss: 0.0621\n",
      "Epoch [45/50], Step [201/735], Loss: 0.0883\n",
      "Epoch [45/50], Step [202/735], Loss: 0.0568\n",
      "Epoch [45/50], Step [203/735], Loss: 0.2181\n",
      "Epoch [45/50], Step [204/735], Loss: 0.2068\n",
      "Epoch [45/50], Step [205/735], Loss: 0.0433\n",
      "Epoch [45/50], Step [206/735], Loss: 0.0789\n",
      "Epoch [45/50], Step [207/735], Loss: 0.1266\n",
      "Epoch [45/50], Step [208/735], Loss: 0.2744\n",
      "Epoch [45/50], Step [209/735], Loss: 0.2187\n",
      "Epoch [45/50], Step [210/735], Loss: 0.1377\n",
      "Epoch [45/50], Step [211/735], Loss: 0.0587\n",
      "Epoch [45/50], Step [212/735], Loss: 0.0613\n",
      "Epoch [45/50], Step [213/735], Loss: 0.1146\n",
      "Epoch [45/50], Step [214/735], Loss: 0.0653\n",
      "Epoch [45/50], Step [215/735], Loss: 0.1160\n",
      "Epoch [45/50], Step [216/735], Loss: 0.0662\n",
      "Epoch [45/50], Step [217/735], Loss: 0.1335\n",
      "Epoch [45/50], Step [218/735], Loss: 0.1596\n",
      "Epoch [45/50], Step [219/735], Loss: 0.1582\n",
      "Epoch [45/50], Step [220/735], Loss: 0.0740\n",
      "Epoch [45/50], Step [221/735], Loss: 0.0698\n",
      "Epoch [45/50], Step [222/735], Loss: 0.3680\n",
      "Epoch [45/50], Step [223/735], Loss: 0.1095\n",
      "Epoch [45/50], Step [224/735], Loss: 0.0929\n",
      "Epoch [45/50], Step [225/735], Loss: 0.1428\n",
      "Epoch [45/50], Step [226/735], Loss: 0.0677\n",
      "Epoch [45/50], Step [227/735], Loss: 0.0633\n",
      "Epoch [45/50], Step [228/735], Loss: 0.0503\n",
      "Epoch [45/50], Step [229/735], Loss: 0.0943\n",
      "Epoch [45/50], Step [230/735], Loss: 0.0486\n",
      "Epoch [45/50], Step [231/735], Loss: 0.0825\n",
      "Epoch [45/50], Step [232/735], Loss: 0.0394\n",
      "Epoch [45/50], Step [233/735], Loss: 0.1742\n",
      "Epoch [45/50], Step [234/735], Loss: 0.0448\n",
      "Epoch [45/50], Step [235/735], Loss: 0.0656\n",
      "Epoch [45/50], Step [236/735], Loss: 0.1017\n",
      "Epoch [45/50], Step [237/735], Loss: 0.1286\n",
      "Epoch [45/50], Step [238/735], Loss: 0.1378\n",
      "Epoch [45/50], Step [239/735], Loss: 0.1693\n",
      "Epoch [45/50], Step [240/735], Loss: 0.0665\n",
      "Epoch [45/50], Step [241/735], Loss: 0.0647\n",
      "Epoch [45/50], Step [242/735], Loss: 0.0652\n",
      "Epoch [45/50], Step [243/735], Loss: 0.0991\n",
      "Epoch [45/50], Step [244/735], Loss: 0.1136\n",
      "Epoch [45/50], Step [245/735], Loss: 0.1302\n",
      "Epoch [45/50], Step [246/735], Loss: 0.0467\n",
      "Epoch [45/50], Step [247/735], Loss: 0.0971\n",
      "Epoch [45/50], Step [248/735], Loss: 0.1345\n",
      "Epoch [45/50], Step [249/735], Loss: 0.0883\n",
      "Epoch [45/50], Step [250/735], Loss: 0.4325\n",
      "Epoch [45/50], Step [251/735], Loss: 0.0771\n",
      "Epoch [45/50], Step [252/735], Loss: 0.0767\n",
      "Epoch [45/50], Step [253/735], Loss: 1.6453\n",
      "Epoch [45/50], Step [254/735], Loss: 0.0691\n",
      "Epoch [45/50], Step [255/735], Loss: 0.1178\n",
      "Epoch [45/50], Step [256/735], Loss: 0.0579\n",
      "Epoch [45/50], Step [257/735], Loss: 0.1704\n",
      "Epoch [45/50], Step [258/735], Loss: 0.1977\n",
      "Epoch [45/50], Step [259/735], Loss: 0.1869\n",
      "Epoch [45/50], Step [260/735], Loss: 0.1328\n",
      "Epoch [45/50], Step [261/735], Loss: 0.0903\n",
      "Epoch [45/50], Step [262/735], Loss: 0.1069\n",
      "Epoch [45/50], Step [263/735], Loss: 0.0544\n",
      "Epoch [45/50], Step [264/735], Loss: 0.0530\n",
      "Epoch [45/50], Step [265/735], Loss: 0.1620\n",
      "Epoch [45/50], Step [266/735], Loss: 0.0305\n",
      "Epoch [45/50], Step [267/735], Loss: 0.0856\n",
      "Epoch [45/50], Step [268/735], Loss: 0.1111\n",
      "Epoch [45/50], Step [269/735], Loss: 0.0820\n",
      "Epoch [45/50], Step [270/735], Loss: 0.0558\n",
      "Epoch [45/50], Step [271/735], Loss: 0.1021\n",
      "Epoch [45/50], Step [272/735], Loss: 0.0786\n",
      "Epoch [45/50], Step [273/735], Loss: 0.0801\n",
      "Epoch [45/50], Step [274/735], Loss: 0.2186\n",
      "Epoch [45/50], Step [275/735], Loss: 0.0446\n",
      "Epoch [45/50], Step [276/735], Loss: 0.0751\n",
      "Epoch [45/50], Step [277/735], Loss: 0.1879\n",
      "Epoch [45/50], Step [278/735], Loss: 0.1619\n",
      "Epoch [45/50], Step [279/735], Loss: 0.0699\n",
      "Epoch [45/50], Step [280/735], Loss: 0.0451\n",
      "Epoch [45/50], Step [281/735], Loss: 0.1255\n",
      "Epoch [45/50], Step [282/735], Loss: 0.1682\n",
      "Epoch [45/50], Step [283/735], Loss: 0.1054\n",
      "Epoch [45/50], Step [284/735], Loss: 0.0513\n",
      "Epoch [45/50], Step [285/735], Loss: 0.1064\n",
      "Epoch [45/50], Step [286/735], Loss: 0.1040\n",
      "Epoch [45/50], Step [287/735], Loss: 0.0794\n",
      "Epoch [45/50], Step [288/735], Loss: 0.0431\n",
      "Epoch [45/50], Step [289/735], Loss: 0.1156\n",
      "Epoch [45/50], Step [290/735], Loss: 0.1873\n",
      "Epoch [45/50], Step [291/735], Loss: 0.0957\n",
      "Epoch [45/50], Step [292/735], Loss: 0.1111\n",
      "Epoch [45/50], Step [293/735], Loss: 0.0575\n",
      "Epoch [45/50], Step [294/735], Loss: 0.0908\n",
      "Epoch [45/50], Step [295/735], Loss: 0.0594\n",
      "Epoch [45/50], Step [296/735], Loss: 0.1497\n",
      "Epoch [45/50], Step [297/735], Loss: 0.0656\n",
      "Epoch [45/50], Step [298/735], Loss: 0.0597\n",
      "Epoch [45/50], Step [299/735], Loss: 0.1248\n",
      "Epoch [45/50], Step [300/735], Loss: 0.0436\n",
      "Epoch [45/50], Step [301/735], Loss: 0.0348\n",
      "Epoch [45/50], Step [302/735], Loss: 0.1092\n",
      "Epoch [45/50], Step [303/735], Loss: 0.0705\n",
      "Epoch [45/50], Step [304/735], Loss: 0.0898\n",
      "Epoch [45/50], Step [305/735], Loss: 0.1235\n",
      "Epoch [45/50], Step [306/735], Loss: 0.0929\n",
      "Epoch [45/50], Step [307/735], Loss: 0.1027\n",
      "Epoch [45/50], Step [308/735], Loss: 0.1820\n",
      "Epoch [45/50], Step [309/735], Loss: 0.0590\n",
      "Epoch [45/50], Step [310/735], Loss: 0.0746\n",
      "Epoch [45/50], Step [311/735], Loss: 0.2560\n",
      "Epoch [45/50], Step [312/735], Loss: 0.1044\n",
      "Epoch [45/50], Step [313/735], Loss: 0.0480\n",
      "Epoch [45/50], Step [314/735], Loss: 0.0336\n",
      "Epoch [45/50], Step [315/735], Loss: 0.1643\n",
      "Epoch [45/50], Step [316/735], Loss: 0.0830\n",
      "Epoch [45/50], Step [317/735], Loss: 0.0408\n",
      "Epoch [45/50], Step [318/735], Loss: 0.1588\n",
      "Epoch [45/50], Step [319/735], Loss: 0.0848\n",
      "Epoch [45/50], Step [320/735], Loss: 0.0686\n",
      "Epoch [45/50], Step [321/735], Loss: 0.0711\n",
      "Epoch [45/50], Step [322/735], Loss: 0.0884\n",
      "Epoch [45/50], Step [323/735], Loss: 0.0895\n",
      "Epoch [45/50], Step [324/735], Loss: 0.1681\n",
      "Epoch [45/50], Step [325/735], Loss: 0.5171\n",
      "Epoch [45/50], Step [326/735], Loss: 0.0980\n",
      "Epoch [45/50], Step [327/735], Loss: 0.0560\n",
      "Epoch [45/50], Step [328/735], Loss: 0.1254\n",
      "Epoch [45/50], Step [329/735], Loss: 0.1157\n",
      "Epoch [45/50], Step [330/735], Loss: 0.1012\n",
      "Epoch [45/50], Step [331/735], Loss: 0.1489\n",
      "Epoch [45/50], Step [332/735], Loss: 0.0674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Step [333/735], Loss: 0.1339\n",
      "Epoch [45/50], Step [334/735], Loss: 0.2308\n",
      "Epoch [45/50], Step [335/735], Loss: 0.1903\n",
      "Epoch [45/50], Step [336/735], Loss: 0.0907\n",
      "Epoch [45/50], Step [337/735], Loss: 0.1107\n",
      "Epoch [45/50], Step [338/735], Loss: 0.0976\n",
      "Epoch [45/50], Step [339/735], Loss: 0.1211\n",
      "Epoch [45/50], Step [340/735], Loss: 0.7955\n",
      "Epoch [45/50], Step [341/735], Loss: 0.1226\n",
      "Epoch [45/50], Step [342/735], Loss: 0.1432\n",
      "Epoch [45/50], Step [343/735], Loss: 0.1244\n",
      "Epoch [45/50], Step [344/735], Loss: 0.1195\n",
      "Epoch [45/50], Step [345/735], Loss: 0.0785\n",
      "Epoch [45/50], Step [346/735], Loss: 0.0915\n",
      "Epoch [45/50], Step [347/735], Loss: 0.1344\n",
      "Epoch [45/50], Step [348/735], Loss: 0.0986\n",
      "Epoch [45/50], Step [349/735], Loss: 0.0826\n",
      "Epoch [45/50], Step [350/735], Loss: 0.0656\n",
      "Epoch [45/50], Step [351/735], Loss: 0.0759\n",
      "Epoch [45/50], Step [352/735], Loss: 0.1214\n",
      "Epoch [45/50], Step [353/735], Loss: 0.0782\n",
      "Epoch [45/50], Step [354/735], Loss: 0.0534\n",
      "Epoch [45/50], Step [355/735], Loss: 0.1273\n",
      "Epoch [45/50], Step [356/735], Loss: 0.1143\n",
      "Epoch [45/50], Step [357/735], Loss: 0.0591\n",
      "Epoch [45/50], Step [358/735], Loss: 0.0587\n",
      "Epoch [45/50], Step [359/735], Loss: 0.0744\n",
      "Epoch [45/50], Step [360/735], Loss: 0.1699\n",
      "Epoch [45/50], Step [361/735], Loss: 0.0427\n",
      "Epoch [45/50], Step [362/735], Loss: 0.0673\n",
      "Epoch [45/50], Step [363/735], Loss: 0.0680\n",
      "Epoch [45/50], Step [364/735], Loss: 0.1567\n",
      "Epoch [45/50], Step [365/735], Loss: 0.2909\n",
      "Epoch [45/50], Step [366/735], Loss: 0.1452\n",
      "Epoch [45/50], Step [367/735], Loss: 0.0519\n",
      "Epoch [45/50], Step [368/735], Loss: 0.1446\n",
      "Epoch [45/50], Step [369/735], Loss: 0.0512\n",
      "Epoch [45/50], Step [370/735], Loss: 0.1581\n",
      "Epoch [45/50], Step [371/735], Loss: 0.0629\n",
      "Epoch [45/50], Step [372/735], Loss: 0.1029\n",
      "Epoch [45/50], Step [373/735], Loss: 0.0501\n",
      "Epoch [45/50], Step [374/735], Loss: 0.0637\n",
      "Epoch [45/50], Step [375/735], Loss: 0.0996\n",
      "Epoch [45/50], Step [376/735], Loss: 0.0424\n",
      "Epoch [45/50], Step [377/735], Loss: 0.0617\n",
      "Epoch [45/50], Step [378/735], Loss: 0.0856\n",
      "Epoch [45/50], Step [379/735], Loss: 0.0392\n",
      "Epoch [45/50], Step [380/735], Loss: 0.1017\n",
      "Epoch [45/50], Step [381/735], Loss: 0.0407\n",
      "Epoch [45/50], Step [382/735], Loss: 0.0633\n",
      "Epoch [45/50], Step [383/735], Loss: 0.0621\n",
      "Epoch [45/50], Step [384/735], Loss: 0.0450\n",
      "Epoch [45/50], Step [385/735], Loss: 0.0425\n",
      "Epoch [45/50], Step [386/735], Loss: 0.1586\n",
      "Epoch [45/50], Step [387/735], Loss: 0.0360\n",
      "Epoch [45/50], Step [388/735], Loss: 0.0329\n",
      "Epoch [45/50], Step [389/735], Loss: 0.0402\n",
      "Epoch [45/50], Step [390/735], Loss: 0.1163\n",
      "Epoch [45/50], Step [391/735], Loss: 0.1174\n",
      "Epoch [45/50], Step [392/735], Loss: 0.0840\n",
      "Epoch [45/50], Step [393/735], Loss: 0.0582\n",
      "Epoch [45/50], Step [394/735], Loss: 0.0554\n",
      "Epoch [45/50], Step [395/735], Loss: 0.1423\n",
      "Epoch [45/50], Step [396/735], Loss: 0.1589\n",
      "Epoch [45/50], Step [397/735], Loss: 0.1126\n",
      "Epoch [45/50], Step [398/735], Loss: 0.0306\n",
      "Epoch [45/50], Step [399/735], Loss: 0.0846\n",
      "Epoch [45/50], Step [400/735], Loss: 0.0887\n",
      "Epoch [45/50], Step [401/735], Loss: 0.0402\n",
      "Epoch [45/50], Step [402/735], Loss: 0.6176\n",
      "Epoch [45/50], Step [403/735], Loss: 0.1159\n",
      "Epoch [45/50], Step [404/735], Loss: 0.1358\n",
      "Epoch [45/50], Step [405/735], Loss: 0.0387\n",
      "Epoch [45/50], Step [406/735], Loss: 0.1049\n",
      "Epoch [45/50], Step [407/735], Loss: 0.0721\n",
      "Epoch [45/50], Step [408/735], Loss: 0.0904\n",
      "Epoch [45/50], Step [409/735], Loss: 0.0762\n",
      "Epoch [45/50], Step [410/735], Loss: 0.1293\n",
      "Epoch [45/50], Step [411/735], Loss: 0.0645\n",
      "Epoch [45/50], Step [412/735], Loss: 0.1849\n",
      "Epoch [45/50], Step [413/735], Loss: 0.0609\n",
      "Epoch [45/50], Step [414/735], Loss: 0.0667\n",
      "Epoch [45/50], Step [415/735], Loss: 0.1084\n",
      "Epoch [45/50], Step [416/735], Loss: 0.0389\n",
      "Epoch [45/50], Step [417/735], Loss: 0.1219\n",
      "Epoch [45/50], Step [418/735], Loss: 0.0535\n",
      "Epoch [45/50], Step [419/735], Loss: 0.1386\n",
      "Epoch [45/50], Step [420/735], Loss: 0.0354\n",
      "Epoch [45/50], Step [421/735], Loss: 0.1404\n",
      "Epoch [45/50], Step [422/735], Loss: 0.0581\n",
      "Epoch [45/50], Step [423/735], Loss: 0.3337\n",
      "Epoch [45/50], Step [424/735], Loss: 0.0466\n",
      "Epoch [45/50], Step [425/735], Loss: 0.1022\n",
      "Epoch [45/50], Step [426/735], Loss: 0.1983\n",
      "Epoch [45/50], Step [427/735], Loss: 0.0949\n",
      "Epoch [45/50], Step [428/735], Loss: 0.0514\n",
      "Epoch [45/50], Step [429/735], Loss: 0.0632\n",
      "Epoch [45/50], Step [430/735], Loss: 0.0644\n",
      "Epoch [45/50], Step [431/735], Loss: 0.3463\n",
      "Epoch [45/50], Step [432/735], Loss: 0.0625\n",
      "Epoch [45/50], Step [433/735], Loss: 1.0190\n",
      "Epoch [45/50], Step [434/735], Loss: 0.1492\n",
      "Epoch [45/50], Step [435/735], Loss: 0.1160\n",
      "Epoch [45/50], Step [436/735], Loss: 0.1231\n",
      "Epoch [45/50], Step [437/735], Loss: 0.0398\n",
      "Epoch [45/50], Step [438/735], Loss: 0.1778\n",
      "Epoch [45/50], Step [439/735], Loss: 0.0625\n",
      "Epoch [45/50], Step [440/735], Loss: 0.0901\n",
      "Epoch [45/50], Step [441/735], Loss: 0.1234\n",
      "Epoch [45/50], Step [442/735], Loss: 0.1079\n",
      "Epoch [45/50], Step [443/735], Loss: 0.0858\n",
      "Epoch [45/50], Step [444/735], Loss: 0.1217\n",
      "Epoch [45/50], Step [445/735], Loss: 0.1021\n",
      "Epoch [45/50], Step [446/735], Loss: 0.1030\n",
      "Epoch [45/50], Step [447/735], Loss: 0.0646\n",
      "Epoch [45/50], Step [448/735], Loss: 0.0431\n",
      "Epoch [45/50], Step [449/735], Loss: 0.0422\n",
      "Epoch [45/50], Step [450/735], Loss: 0.1580\n",
      "Epoch [45/50], Step [451/735], Loss: 0.2452\n",
      "Epoch [45/50], Step [452/735], Loss: 0.0797\n",
      "Epoch [45/50], Step [453/735], Loss: 0.0375\n",
      "Epoch [45/50], Step [454/735], Loss: 0.0665\n",
      "Epoch [45/50], Step [455/735], Loss: 0.0736\n",
      "Epoch [45/50], Step [456/735], Loss: 0.2112\n",
      "Epoch [45/50], Step [457/735], Loss: 0.0762\n",
      "Epoch [45/50], Step [458/735], Loss: 0.0963\n",
      "Epoch [45/50], Step [459/735], Loss: 0.0767\n",
      "Epoch [45/50], Step [460/735], Loss: 0.1054\n",
      "Epoch [45/50], Step [461/735], Loss: 0.2850\n",
      "Epoch [45/50], Step [462/735], Loss: 0.0477\n",
      "Epoch [45/50], Step [463/735], Loss: 0.1528\n",
      "Epoch [45/50], Step [464/735], Loss: 0.1841\n",
      "Epoch [45/50], Step [465/735], Loss: 0.0351\n",
      "Epoch [45/50], Step [466/735], Loss: 0.0402\n",
      "Epoch [45/50], Step [467/735], Loss: 0.0956\n",
      "Epoch [45/50], Step [468/735], Loss: 0.0821\n",
      "Epoch [45/50], Step [469/735], Loss: 0.0244\n",
      "Epoch [45/50], Step [470/735], Loss: 0.1151\n",
      "Epoch [45/50], Step [471/735], Loss: 0.0748\n",
      "Epoch [45/50], Step [472/735], Loss: 0.0769\n",
      "Epoch [45/50], Step [473/735], Loss: 0.0381\n",
      "Epoch [45/50], Step [474/735], Loss: 0.0718\n",
      "Epoch [45/50], Step [475/735], Loss: 0.1653\n",
      "Epoch [45/50], Step [476/735], Loss: 0.0910\n",
      "Epoch [45/50], Step [477/735], Loss: 0.0925\n",
      "Epoch [45/50], Step [478/735], Loss: 0.0366\n",
      "Epoch [45/50], Step [479/735], Loss: 0.0568\n",
      "Epoch [45/50], Step [480/735], Loss: 0.1066\n",
      "Epoch [45/50], Step [481/735], Loss: 0.0822\n",
      "Epoch [45/50], Step [482/735], Loss: 0.0560\n",
      "Epoch [45/50], Step [483/735], Loss: 0.2426\n",
      "Epoch [45/50], Step [484/735], Loss: 0.1626\n",
      "Epoch [45/50], Step [485/735], Loss: 0.1603\n",
      "Epoch [45/50], Step [486/735], Loss: 0.1112\n",
      "Epoch [45/50], Step [487/735], Loss: 0.0707\n",
      "Epoch [45/50], Step [488/735], Loss: 0.0535\n",
      "Epoch [45/50], Step [489/735], Loss: 0.1305\n",
      "Epoch [45/50], Step [490/735], Loss: 0.1673\n",
      "Epoch [45/50], Step [491/735], Loss: 0.0807\n",
      "Epoch [45/50], Step [492/735], Loss: 0.1170\n",
      "Epoch [45/50], Step [493/735], Loss: 0.0593\n",
      "Epoch [45/50], Step [494/735], Loss: 0.1006\n",
      "Epoch [45/50], Step [495/735], Loss: 0.1101\n",
      "Epoch [45/50], Step [496/735], Loss: 0.0447\n",
      "Epoch [45/50], Step [497/735], Loss: 0.0471\n",
      "Epoch [45/50], Step [498/735], Loss: 0.0584\n",
      "Epoch [45/50], Step [499/735], Loss: 0.0948\n",
      "Epoch [45/50], Step [500/735], Loss: 0.0760\n",
      "Epoch [45/50], Step [501/735], Loss: 0.0622\n",
      "Epoch [45/50], Step [502/735], Loss: 0.0444\n",
      "Epoch [45/50], Step [503/735], Loss: 0.1403\n",
      "Epoch [45/50], Step [504/735], Loss: 0.0493\n",
      "Epoch [45/50], Step [505/735], Loss: 0.0435\n",
      "Epoch [45/50], Step [506/735], Loss: 0.0285\n",
      "Epoch [45/50], Step [507/735], Loss: 0.0772\n",
      "Epoch [45/50], Step [508/735], Loss: 0.9927\n",
      "Epoch [45/50], Step [509/735], Loss: 0.0573\n",
      "Epoch [45/50], Step [510/735], Loss: 0.1256\n",
      "Epoch [45/50], Step [511/735], Loss: 0.0681\n",
      "Epoch [45/50], Step [512/735], Loss: 0.0769\n",
      "Epoch [45/50], Step [513/735], Loss: 0.0567\n",
      "Epoch [45/50], Step [514/735], Loss: 0.0484\n",
      "Epoch [45/50], Step [515/735], Loss: 0.1094\n",
      "Epoch [45/50], Step [516/735], Loss: 0.1370\n",
      "Epoch [45/50], Step [517/735], Loss: 0.2145\n",
      "Epoch [45/50], Step [518/735], Loss: 0.0753\n",
      "Epoch [45/50], Step [519/735], Loss: 0.0471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Step [520/735], Loss: 0.0877\n",
      "Epoch [45/50], Step [521/735], Loss: 0.0496\n",
      "Epoch [45/50], Step [522/735], Loss: 0.6723\n",
      "Epoch [45/50], Step [523/735], Loss: 0.0427\n",
      "Epoch [45/50], Step [524/735], Loss: 0.1154\n",
      "Epoch [45/50], Step [525/735], Loss: 0.0840\n",
      "Epoch [45/50], Step [526/735], Loss: 0.1263\n",
      "Epoch [45/50], Step [527/735], Loss: 0.0766\n",
      "Epoch [45/50], Step [528/735], Loss: 0.0637\n",
      "Epoch [45/50], Step [529/735], Loss: 0.0545\n",
      "Epoch [45/50], Step [530/735], Loss: 0.0649\n",
      "Epoch [45/50], Step [531/735], Loss: 0.0556\n",
      "Epoch [45/50], Step [532/735], Loss: 0.1894\n",
      "Epoch [45/50], Step [533/735], Loss: 0.0361\n",
      "Epoch [45/50], Step [534/735], Loss: 0.0785\n",
      "Epoch [45/50], Step [535/735], Loss: 0.2407\n",
      "Epoch [45/50], Step [536/735], Loss: 0.0931\n",
      "Epoch [45/50], Step [537/735], Loss: 0.1212\n",
      "Epoch [45/50], Step [538/735], Loss: 0.0508\n",
      "Epoch [45/50], Step [539/735], Loss: 0.0331\n",
      "Epoch [45/50], Step [540/735], Loss: 0.0357\n",
      "Epoch [45/50], Step [541/735], Loss: 0.0462\n",
      "Epoch [45/50], Step [542/735], Loss: 0.0966\n",
      "Epoch [45/50], Step [543/735], Loss: 0.0416\n",
      "Epoch [45/50], Step [544/735], Loss: 0.0626\n",
      "Epoch [45/50], Step [545/735], Loss: 0.0777\n",
      "Epoch [45/50], Step [546/735], Loss: 0.1150\n",
      "Epoch [45/50], Step [547/735], Loss: 0.1533\n",
      "Epoch [45/50], Step [548/735], Loss: 0.0334\n",
      "Epoch [45/50], Step [549/735], Loss: 1.5140\n",
      "Epoch [45/50], Step [550/735], Loss: 0.0467\n",
      "Epoch [45/50], Step [551/735], Loss: 0.1427\n",
      "Epoch [45/50], Step [552/735], Loss: 0.1061\n",
      "Epoch [45/50], Step [553/735], Loss: 0.0354\n",
      "Epoch [45/50], Step [554/735], Loss: 0.1054\n",
      "Epoch [45/50], Step [555/735], Loss: 0.0898\n",
      "Epoch [45/50], Step [556/735], Loss: 0.0237\n",
      "Epoch [45/50], Step [557/735], Loss: 0.0442\n",
      "Epoch [45/50], Step [558/735], Loss: 0.1051\n",
      "Epoch [45/50], Step [559/735], Loss: 0.0805\n",
      "Epoch [45/50], Step [560/735], Loss: 0.0894\n",
      "Epoch [45/50], Step [561/735], Loss: 0.0820\n",
      "Epoch [45/50], Step [562/735], Loss: 0.0662\n",
      "Epoch [45/50], Step [563/735], Loss: 0.1321\n",
      "Epoch [45/50], Step [564/735], Loss: 0.0906\n",
      "Epoch [45/50], Step [565/735], Loss: 0.1050\n",
      "Epoch [45/50], Step [566/735], Loss: 0.0675\n",
      "Epoch [45/50], Step [567/735], Loss: 0.0454\n",
      "Epoch [45/50], Step [568/735], Loss: 0.3471\n",
      "Epoch [45/50], Step [569/735], Loss: 0.0833\n",
      "Epoch [45/50], Step [570/735], Loss: 0.0629\n",
      "Epoch [45/50], Step [571/735], Loss: 0.0742\n",
      "Epoch [45/50], Step [572/735], Loss: 0.0840\n",
      "Epoch [45/50], Step [573/735], Loss: 0.0967\n",
      "Epoch [45/50], Step [574/735], Loss: 0.0969\n",
      "Epoch [45/50], Step [575/735], Loss: 0.1404\n",
      "Epoch [45/50], Step [576/735], Loss: 0.0904\n",
      "Epoch [45/50], Step [577/735], Loss: 0.0760\n",
      "Epoch [45/50], Step [578/735], Loss: 0.0708\n",
      "Epoch [45/50], Step [579/735], Loss: 0.0568\n",
      "Epoch [45/50], Step [580/735], Loss: 0.1310\n",
      "Epoch [45/50], Step [581/735], Loss: 0.0599\n",
      "Epoch [45/50], Step [582/735], Loss: 0.0823\n",
      "Epoch [45/50], Step [583/735], Loss: 0.2742\n",
      "Epoch [45/50], Step [584/735], Loss: 0.1261\n",
      "Epoch [45/50], Step [585/735], Loss: 0.0350\n",
      "Epoch [45/50], Step [586/735], Loss: 0.0286\n",
      "Epoch [45/50], Step [587/735], Loss: 0.0703\n",
      "Epoch [45/50], Step [588/735], Loss: 0.0657\n",
      "Epoch [45/50], Step [589/735], Loss: 0.4971\n",
      "Epoch [45/50], Step [590/735], Loss: 0.1623\n",
      "Epoch [45/50], Step [591/735], Loss: 0.1022\n",
      "Epoch [45/50], Step [592/735], Loss: 0.0716\n",
      "Epoch [45/50], Step [593/735], Loss: 0.1200\n",
      "Epoch [45/50], Step [594/735], Loss: 0.0343\n",
      "Epoch [45/50], Step [595/735], Loss: 0.1297\n",
      "Epoch [45/50], Step [596/735], Loss: 0.0649\n",
      "Epoch [45/50], Step [597/735], Loss: 0.0810\n",
      "Epoch [45/50], Step [598/735], Loss: 1.5249\n",
      "Epoch [45/50], Step [599/735], Loss: 0.1142\n",
      "Epoch [45/50], Step [600/735], Loss: 0.0474\n",
      "Epoch [45/50], Step [601/735], Loss: 0.0979\n",
      "Epoch [45/50], Step [602/735], Loss: 0.0435\n",
      "Epoch [45/50], Step [603/735], Loss: 0.0443\n",
      "Epoch [45/50], Step [604/735], Loss: 0.1452\n",
      "Epoch [45/50], Step [605/735], Loss: 0.0726\n",
      "Epoch [45/50], Step [606/735], Loss: 0.1998\n",
      "Epoch [45/50], Step [607/735], Loss: 0.0642\n",
      "Epoch [45/50], Step [608/735], Loss: 0.2280\n",
      "Epoch [45/50], Step [609/735], Loss: 0.0715\n",
      "Epoch [45/50], Step [610/735], Loss: 0.0526\n",
      "Epoch [45/50], Step [611/735], Loss: 0.1317\n",
      "Epoch [45/50], Step [612/735], Loss: 0.0374\n",
      "Epoch [45/50], Step [613/735], Loss: 0.0625\n",
      "Epoch [45/50], Step [614/735], Loss: 0.0862\n",
      "Epoch [45/50], Step [615/735], Loss: 1.1895\n",
      "Epoch [45/50], Step [616/735], Loss: 1.2181\n",
      "Epoch [45/50], Step [617/735], Loss: 0.0658\n",
      "Epoch [45/50], Step [618/735], Loss: 0.0617\n",
      "Epoch [45/50], Step [619/735], Loss: 0.0685\n",
      "Epoch [45/50], Step [620/735], Loss: 0.0448\n",
      "Epoch [45/50], Step [621/735], Loss: 0.1010\n",
      "Epoch [45/50], Step [622/735], Loss: 0.1643\n",
      "Epoch [45/50], Step [623/735], Loss: 0.4751\n",
      "Epoch [45/50], Step [624/735], Loss: 0.1354\n",
      "Epoch [45/50], Step [625/735], Loss: 0.0635\n",
      "Epoch [45/50], Step [626/735], Loss: 0.0712\n",
      "Epoch [45/50], Step [627/735], Loss: 0.2539\n",
      "Epoch [45/50], Step [628/735], Loss: 0.0805\n",
      "Epoch [45/50], Step [629/735], Loss: 0.0924\n",
      "Epoch [45/50], Step [630/735], Loss: 0.0862\n",
      "Epoch [45/50], Step [631/735], Loss: 0.1713\n",
      "Epoch [45/50], Step [632/735], Loss: 0.0702\n",
      "Epoch [45/50], Step [633/735], Loss: 0.0622\n",
      "Epoch [45/50], Step [634/735], Loss: 0.1005\n",
      "Epoch [45/50], Step [635/735], Loss: 0.1103\n",
      "Epoch [45/50], Step [636/735], Loss: 0.0822\n",
      "Epoch [45/50], Step [637/735], Loss: 0.1270\n",
      "Epoch [45/50], Step [638/735], Loss: 0.0804\n",
      "Epoch [45/50], Step [639/735], Loss: 0.1541\n",
      "Epoch [45/50], Step [640/735], Loss: 0.0822\n",
      "Epoch [45/50], Step [641/735], Loss: 0.0608\n",
      "Epoch [45/50], Step [642/735], Loss: 0.0742\n",
      "Epoch [45/50], Step [643/735], Loss: 1.0939\n",
      "Epoch [45/50], Step [644/735], Loss: 0.0734\n",
      "Epoch [45/50], Step [645/735], Loss: 0.1133\n",
      "Epoch [45/50], Step [646/735], Loss: 0.0743\n",
      "Epoch [45/50], Step [647/735], Loss: 0.1306\n",
      "Epoch [45/50], Step [648/735], Loss: 0.0467\n",
      "Epoch [45/50], Step [649/735], Loss: 0.0643\n",
      "Epoch [45/50], Step [650/735], Loss: 0.1250\n",
      "Epoch [45/50], Step [651/735], Loss: 0.0909\n",
      "Epoch [45/50], Step [652/735], Loss: 0.1323\n",
      "Epoch [45/50], Step [653/735], Loss: 0.1219\n",
      "Epoch [45/50], Step [654/735], Loss: 0.0487\n",
      "Epoch [45/50], Step [655/735], Loss: 0.1195\n",
      "Epoch [45/50], Step [656/735], Loss: 0.1203\n",
      "Epoch [45/50], Step [657/735], Loss: 0.0924\n",
      "Epoch [45/50], Step [658/735], Loss: 0.1139\n",
      "Epoch [45/50], Step [659/735], Loss: 0.0816\n",
      "Epoch [45/50], Step [660/735], Loss: 0.0604\n",
      "Epoch [45/50], Step [661/735], Loss: 0.2982\n",
      "Epoch [45/50], Step [662/735], Loss: 0.1198\n",
      "Epoch [45/50], Step [663/735], Loss: 0.0997\n",
      "Epoch [45/50], Step [664/735], Loss: 1.0705\n",
      "Epoch [45/50], Step [665/735], Loss: 0.0556\n",
      "Epoch [45/50], Step [666/735], Loss: 0.1231\n",
      "Epoch [45/50], Step [667/735], Loss: 0.0907\n",
      "Epoch [45/50], Step [668/735], Loss: 0.0765\n",
      "Epoch [45/50], Step [669/735], Loss: 0.4859\n",
      "Epoch [45/50], Step [670/735], Loss: 0.4543\n",
      "Epoch [45/50], Step [671/735], Loss: 0.2862\n",
      "Epoch [45/50], Step [672/735], Loss: 0.1198\n",
      "Epoch [45/50], Step [673/735], Loss: 0.1643\n",
      "Epoch [45/50], Step [674/735], Loss: 0.0802\n",
      "Epoch [45/50], Step [675/735], Loss: 0.1168\n",
      "Epoch [45/50], Step [676/735], Loss: 0.0618\n",
      "Epoch [45/50], Step [677/735], Loss: 0.1221\n",
      "Epoch [45/50], Step [678/735], Loss: 0.1516\n",
      "Epoch [45/50], Step [679/735], Loss: 0.8986\n",
      "Epoch [45/50], Step [680/735], Loss: 0.0415\n",
      "Epoch [45/50], Step [681/735], Loss: 0.0466\n",
      "Epoch [45/50], Step [682/735], Loss: 0.0984\n",
      "Epoch [45/50], Step [683/735], Loss: 0.0402\n",
      "Epoch [45/50], Step [684/735], Loss: 0.0678\n",
      "Epoch [45/50], Step [685/735], Loss: 0.0732\n",
      "Epoch [45/50], Step [686/735], Loss: 0.3319\n",
      "Epoch [45/50], Step [687/735], Loss: 0.1270\n",
      "Epoch [45/50], Step [688/735], Loss: 0.0763\n",
      "Epoch [45/50], Step [689/735], Loss: 1.2703\n",
      "Epoch [45/50], Step [690/735], Loss: 0.1645\n",
      "Epoch [45/50], Step [691/735], Loss: 0.0679\n",
      "Epoch [45/50], Step [692/735], Loss: 0.1696\n",
      "Epoch [45/50], Step [693/735], Loss: 0.0775\n",
      "Epoch [45/50], Step [694/735], Loss: 0.0634\n",
      "Epoch [45/50], Step [695/735], Loss: 0.3818\n",
      "Epoch [45/50], Step [696/735], Loss: 0.1019\n",
      "Epoch [45/50], Step [697/735], Loss: 0.0930\n",
      "Epoch [45/50], Step [698/735], Loss: 0.1072\n",
      "Epoch [45/50], Step [699/735], Loss: 0.1220\n",
      "Epoch [45/50], Step [700/735], Loss: 0.0827\n",
      "Epoch [45/50], Step [701/735], Loss: 0.0735\n",
      "Epoch [45/50], Step [702/735], Loss: 0.1714\n",
      "Epoch [45/50], Step [703/735], Loss: 0.0799\n",
      "Epoch [45/50], Step [704/735], Loss: 0.0694\n",
      "Epoch [45/50], Step [705/735], Loss: 0.1012\n",
      "Epoch [45/50], Step [706/735], Loss: 0.0394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Step [707/735], Loss: 0.0921\n",
      "Epoch [45/50], Step [708/735], Loss: 0.0507\n",
      "Epoch [45/50], Step [709/735], Loss: 0.1061\n",
      "Epoch [45/50], Step [710/735], Loss: 0.0274\n",
      "Epoch [45/50], Step [711/735], Loss: 0.1636\n",
      "Epoch [45/50], Step [712/735], Loss: 0.0613\n",
      "Epoch [45/50], Step [713/735], Loss: 0.0987\n",
      "Epoch [45/50], Step [714/735], Loss: 0.1110\n",
      "Epoch [45/50], Step [715/735], Loss: 0.1311\n",
      "Epoch [45/50], Step [716/735], Loss: 0.0888\n",
      "Epoch [45/50], Step [717/735], Loss: 0.1930\n",
      "Epoch [45/50], Step [718/735], Loss: 1.0351\n",
      "Epoch [45/50], Step [719/735], Loss: 0.0477\n",
      "Epoch [45/50], Step [720/735], Loss: 0.0974\n",
      "Epoch [45/50], Step [721/735], Loss: 0.0969\n",
      "Epoch [45/50], Step [722/735], Loss: 0.0424\n",
      "Epoch [45/50], Step [723/735], Loss: 0.0578\n",
      "Epoch [45/50], Step [724/735], Loss: 0.0697\n",
      "Epoch [45/50], Step [725/735], Loss: 0.0489\n",
      "Epoch [45/50], Step [726/735], Loss: 0.0507\n",
      "Epoch [45/50], Step [727/735], Loss: 0.0727\n",
      "Epoch [45/50], Step [728/735], Loss: 0.0273\n",
      "Epoch [45/50], Step [729/735], Loss: 0.0949\n",
      "Epoch [45/50], Step [730/735], Loss: 0.1364\n",
      "Epoch [45/50], Step [731/735], Loss: 0.2057\n",
      "Epoch [45/50], Step [732/735], Loss: 0.0445\n",
      "Epoch [45/50], Step [733/735], Loss: 0.1202\n",
      "Epoch [45/50], Step [734/735], Loss: 0.0700\n",
      "Epoch [45/50], Step [735/735], Loss: 0.1015\n",
      "Epoch [46/50], Step [1/735], Loss: 0.3876\n",
      "Epoch [46/50], Step [2/735], Loss: 0.2164\n",
      "Epoch [46/50], Step [3/735], Loss: 0.1039\n",
      "Epoch [46/50], Step [4/735], Loss: 0.0890\n",
      "Epoch [46/50], Step [5/735], Loss: 0.0891\n",
      "Epoch [46/50], Step [6/735], Loss: 0.0296\n",
      "Epoch [46/50], Step [7/735], Loss: 0.3701\n",
      "Epoch [46/50], Step [8/735], Loss: 0.0448\n",
      "Epoch [46/50], Step [9/735], Loss: 0.1036\n",
      "Epoch [46/50], Step [10/735], Loss: 0.5959\n",
      "Epoch [46/50], Step [11/735], Loss: 0.2082\n",
      "Epoch [46/50], Step [12/735], Loss: 0.0265\n",
      "Epoch [46/50], Step [13/735], Loss: 0.0958\n",
      "Epoch [46/50], Step [14/735], Loss: 0.0921\n",
      "Epoch [46/50], Step [15/735], Loss: 0.0959\n",
      "Epoch [46/50], Step [16/735], Loss: 0.0785\n",
      "Epoch [46/50], Step [17/735], Loss: 0.1884\n",
      "Epoch [46/50], Step [18/735], Loss: 0.0766\n",
      "Epoch [46/50], Step [19/735], Loss: 0.0515\n",
      "Epoch [46/50], Step [20/735], Loss: 0.1066\n",
      "Epoch [46/50], Step [21/735], Loss: 0.1183\n",
      "Epoch [46/50], Step [22/735], Loss: 0.0747\n",
      "Epoch [46/50], Step [23/735], Loss: 0.0574\n",
      "Epoch [46/50], Step [24/735], Loss: 0.0774\n",
      "Epoch [46/50], Step [25/735], Loss: 0.0331\n",
      "Epoch [46/50], Step [26/735], Loss: 0.0306\n",
      "Epoch [46/50], Step [27/735], Loss: 0.0541\n",
      "Epoch [46/50], Step [28/735], Loss: 0.0915\n",
      "Epoch [46/50], Step [29/735], Loss: 0.0452\n",
      "Epoch [46/50], Step [30/735], Loss: 0.1046\n",
      "Epoch [46/50], Step [31/735], Loss: 0.7188\n",
      "Epoch [46/50], Step [32/735], Loss: 0.1020\n",
      "Epoch [46/50], Step [33/735], Loss: 0.0993\n",
      "Epoch [46/50], Step [34/735], Loss: 0.1216\n",
      "Epoch [46/50], Step [35/735], Loss: 0.1318\n",
      "Epoch [46/50], Step [36/735], Loss: 0.0314\n",
      "Epoch [46/50], Step [37/735], Loss: 0.6408\n",
      "Epoch [46/50], Step [38/735], Loss: 0.0778\n",
      "Epoch [46/50], Step [39/735], Loss: 0.0794\n",
      "Epoch [46/50], Step [40/735], Loss: 0.0704\n",
      "Epoch [46/50], Step [41/735], Loss: 0.0715\n",
      "Epoch [46/50], Step [42/735], Loss: 0.1184\n",
      "Epoch [46/50], Step [43/735], Loss: 0.0567\n",
      "Epoch [46/50], Step [44/735], Loss: 0.0882\n",
      "Epoch [46/50], Step [45/735], Loss: 0.1770\n",
      "Epoch [46/50], Step [46/735], Loss: 0.0371\n",
      "Epoch [46/50], Step [47/735], Loss: 0.0455\n",
      "Epoch [46/50], Step [48/735], Loss: 0.0675\n",
      "Epoch [46/50], Step [49/735], Loss: 0.2997\n",
      "Epoch [46/50], Step [50/735], Loss: 0.1258\n",
      "Epoch [46/50], Step [51/735], Loss: 0.1985\n",
      "Epoch [46/50], Step [52/735], Loss: 0.0358\n",
      "Epoch [46/50], Step [53/735], Loss: 0.0523\n",
      "Epoch [46/50], Step [54/735], Loss: 0.0240\n",
      "Epoch [46/50], Step [55/735], Loss: 0.0535\n",
      "Epoch [46/50], Step [56/735], Loss: 0.1188\n",
      "Epoch [46/50], Step [57/735], Loss: 0.0631\n",
      "Epoch [46/50], Step [58/735], Loss: 0.0683\n",
      "Epoch [46/50], Step [59/735], Loss: 0.1101\n",
      "Epoch [46/50], Step [60/735], Loss: 0.0379\n",
      "Epoch [46/50], Step [61/735], Loss: 0.1060\n",
      "Epoch [46/50], Step [62/735], Loss: 0.0439\n",
      "Epoch [46/50], Step [63/735], Loss: 0.0914\n",
      "Epoch [46/50], Step [64/735], Loss: 0.2093\n",
      "Epoch [46/50], Step [65/735], Loss: 0.1067\n",
      "Epoch [46/50], Step [66/735], Loss: 0.1268\n",
      "Epoch [46/50], Step [67/735], Loss: 0.0373\n",
      "Epoch [46/50], Step [68/735], Loss: 0.0969\n",
      "Epoch [46/50], Step [69/735], Loss: 0.1902\n",
      "Epoch [46/50], Step [70/735], Loss: 0.0780\n",
      "Epoch [46/50], Step [71/735], Loss: 0.1237\n",
      "Epoch [46/50], Step [72/735], Loss: 0.1139\n",
      "Epoch [46/50], Step [73/735], Loss: 0.1588\n",
      "Epoch [46/50], Step [74/735], Loss: 0.2153\n",
      "Epoch [46/50], Step [75/735], Loss: 0.1114\n",
      "Epoch [46/50], Step [76/735], Loss: 0.5148\n",
      "Epoch [46/50], Step [77/735], Loss: 0.1214\n",
      "Epoch [46/50], Step [78/735], Loss: 0.0782\n",
      "Epoch [46/50], Step [79/735], Loss: 0.1333\n",
      "Epoch [46/50], Step [80/735], Loss: 0.1505\n",
      "Epoch [46/50], Step [81/735], Loss: 0.0660\n",
      "Epoch [46/50], Step [82/735], Loss: 0.0696\n",
      "Epoch [46/50], Step [83/735], Loss: 0.0968\n",
      "Epoch [46/50], Step [84/735], Loss: 0.1212\n",
      "Epoch [46/50], Step [85/735], Loss: 0.0730\n",
      "Epoch [46/50], Step [86/735], Loss: 0.3072\n",
      "Epoch [46/50], Step [87/735], Loss: 0.0745\n",
      "Epoch [46/50], Step [88/735], Loss: 0.1066\n",
      "Epoch [46/50], Step [89/735], Loss: 0.1166\n",
      "Epoch [46/50], Step [90/735], Loss: 0.1646\n",
      "Epoch [46/50], Step [91/735], Loss: 0.1719\n",
      "Epoch [46/50], Step [92/735], Loss: 0.1095\n",
      "Epoch [46/50], Step [93/735], Loss: 0.0880\n",
      "Epoch [46/50], Step [94/735], Loss: 0.1457\n",
      "Epoch [46/50], Step [95/735], Loss: 0.0721\n",
      "Epoch [46/50], Step [96/735], Loss: 0.1155\n",
      "Epoch [46/50], Step [97/735], Loss: 0.2062\n",
      "Epoch [46/50], Step [98/735], Loss: 0.2910\n",
      "Epoch [46/50], Step [99/735], Loss: 0.0425\n",
      "Epoch [46/50], Step [100/735], Loss: 0.0875\n",
      "Epoch [46/50], Step [101/735], Loss: 0.0544\n",
      "Epoch [46/50], Step [102/735], Loss: 0.0865\n",
      "Epoch [46/50], Step [103/735], Loss: 0.0458\n",
      "Epoch [46/50], Step [104/735], Loss: 1.4941\n",
      "Epoch [46/50], Step [105/735], Loss: 0.1096\n",
      "Epoch [46/50], Step [106/735], Loss: 0.1539\n",
      "Epoch [46/50], Step [107/735], Loss: 0.2643\n",
      "Epoch [46/50], Step [108/735], Loss: 0.0876\n",
      "Epoch [46/50], Step [109/735], Loss: 0.1127\n",
      "Epoch [46/50], Step [110/735], Loss: 0.0900\n",
      "Epoch [46/50], Step [111/735], Loss: 0.0845\n",
      "Epoch [46/50], Step [112/735], Loss: 0.0663\n",
      "Epoch [46/50], Step [113/735], Loss: 0.0950\n",
      "Epoch [46/50], Step [114/735], Loss: 0.1945\n",
      "Epoch [46/50], Step [115/735], Loss: 0.1345\n",
      "Epoch [46/50], Step [116/735], Loss: 0.0698\n",
      "Epoch [46/50], Step [117/735], Loss: 0.0798\n",
      "Epoch [46/50], Step [118/735], Loss: 0.0404\n",
      "Epoch [46/50], Step [119/735], Loss: 0.0427\n",
      "Epoch [46/50], Step [120/735], Loss: 0.1219\n",
      "Epoch [46/50], Step [121/735], Loss: 0.1197\n",
      "Epoch [46/50], Step [122/735], Loss: 0.0505\n",
      "Epoch [46/50], Step [123/735], Loss: 0.0562\n",
      "Epoch [46/50], Step [124/735], Loss: 0.1907\n",
      "Epoch [46/50], Step [125/735], Loss: 0.1342\n",
      "Epoch [46/50], Step [126/735], Loss: 0.0769\n",
      "Epoch [46/50], Step [127/735], Loss: 0.1385\n",
      "Epoch [46/50], Step [128/735], Loss: 0.0448\n",
      "Epoch [46/50], Step [129/735], Loss: 0.0520\n",
      "Epoch [46/50], Step [130/735], Loss: 0.1023\n",
      "Epoch [46/50], Step [131/735], Loss: 0.1746\n",
      "Epoch [46/50], Step [132/735], Loss: 0.0405\n",
      "Epoch [46/50], Step [133/735], Loss: 0.1132\n",
      "Epoch [46/50], Step [134/735], Loss: 0.0626\n",
      "Epoch [46/50], Step [135/735], Loss: 0.0604\n",
      "Epoch [46/50], Step [136/735], Loss: 0.0740\n",
      "Epoch [46/50], Step [137/735], Loss: 0.1109\n",
      "Epoch [46/50], Step [138/735], Loss: 0.0930\n",
      "Epoch [46/50], Step [139/735], Loss: 0.0807\n",
      "Epoch [46/50], Step [140/735], Loss: 0.0762\n",
      "Epoch [46/50], Step [141/735], Loss: 0.1034\n",
      "Epoch [46/50], Step [142/735], Loss: 0.1114\n",
      "Epoch [46/50], Step [143/735], Loss: 0.7106\n",
      "Epoch [46/50], Step [144/735], Loss: 0.0871\n",
      "Epoch [46/50], Step [145/735], Loss: 0.0708\n",
      "Epoch [46/50], Step [146/735], Loss: 0.6090\n",
      "Epoch [46/50], Step [147/735], Loss: 0.1176\n",
      "Epoch [46/50], Step [148/735], Loss: 0.1190\n",
      "Epoch [46/50], Step [149/735], Loss: 0.0932\n",
      "Epoch [46/50], Step [150/735], Loss: 0.0859\n",
      "Epoch [46/50], Step [151/735], Loss: 0.1520\n",
      "Epoch [46/50], Step [152/735], Loss: 0.0937\n",
      "Epoch [46/50], Step [153/735], Loss: 0.0681\n",
      "Epoch [46/50], Step [154/735], Loss: 0.1063\n",
      "Epoch [46/50], Step [155/735], Loss: 0.3408\n",
      "Epoch [46/50], Step [156/735], Loss: 0.0693\n",
      "Epoch [46/50], Step [157/735], Loss: 0.0779\n",
      "Epoch [46/50], Step [158/735], Loss: 0.0679\n",
      "Epoch [46/50], Step [159/735], Loss: 0.1719\n",
      "Epoch [46/50], Step [160/735], Loss: 0.0552\n",
      "Epoch [46/50], Step [161/735], Loss: 0.1250\n",
      "Epoch [46/50], Step [162/735], Loss: 0.4443\n",
      "Epoch [46/50], Step [163/735], Loss: 0.0448\n",
      "Epoch [46/50], Step [164/735], Loss: 0.0278\n",
      "Epoch [46/50], Step [165/735], Loss: 0.0436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Step [166/735], Loss: 0.2295\n",
      "Epoch [46/50], Step [167/735], Loss: 0.0937\n",
      "Epoch [46/50], Step [168/735], Loss: 0.1280\n",
      "Epoch [46/50], Step [169/735], Loss: 0.0835\n",
      "Epoch [46/50], Step [170/735], Loss: 0.0883\n",
      "Epoch [46/50], Step [171/735], Loss: 0.3156\n",
      "Epoch [46/50], Step [172/735], Loss: 0.0932\n",
      "Epoch [46/50], Step [173/735], Loss: 0.1124\n",
      "Epoch [46/50], Step [174/735], Loss: 0.2041\n",
      "Epoch [46/50], Step [175/735], Loss: 0.0609\n",
      "Epoch [46/50], Step [176/735], Loss: 0.0455\n",
      "Epoch [46/50], Step [177/735], Loss: 0.3848\n",
      "Epoch [46/50], Step [178/735], Loss: 0.0347\n",
      "Epoch [46/50], Step [179/735], Loss: 0.0813\n",
      "Epoch [46/50], Step [180/735], Loss: 0.1050\n",
      "Epoch [46/50], Step [181/735], Loss: 0.1936\n",
      "Epoch [46/50], Step [182/735], Loss: 0.0591\n",
      "Epoch [46/50], Step [183/735], Loss: 0.0456\n",
      "Epoch [46/50], Step [184/735], Loss: 0.0785\n",
      "Epoch [46/50], Step [185/735], Loss: 0.2658\n",
      "Epoch [46/50], Step [186/735], Loss: 0.0461\n",
      "Epoch [46/50], Step [187/735], Loss: 0.1562\n",
      "Epoch [46/50], Step [188/735], Loss: 0.2950\n",
      "Epoch [46/50], Step [189/735], Loss: 0.1874\n",
      "Epoch [46/50], Step [190/735], Loss: 0.0812\n",
      "Epoch [46/50], Step [191/735], Loss: 0.0861\n",
      "Epoch [46/50], Step [192/735], Loss: 0.1019\n",
      "Epoch [46/50], Step [193/735], Loss: 0.1012\n",
      "Epoch [46/50], Step [194/735], Loss: 0.0666\n",
      "Epoch [46/50], Step [195/735], Loss: 0.1052\n",
      "Epoch [46/50], Step [196/735], Loss: 0.1430\n",
      "Epoch [46/50], Step [197/735], Loss: 0.0818\n",
      "Epoch [46/50], Step [198/735], Loss: 0.0845\n",
      "Epoch [46/50], Step [199/735], Loss: 0.0524\n",
      "Epoch [46/50], Step [200/735], Loss: 0.1723\n",
      "Epoch [46/50], Step [201/735], Loss: 0.0373\n",
      "Epoch [46/50], Step [202/735], Loss: 0.7688\n",
      "Epoch [46/50], Step [203/735], Loss: 0.0684\n",
      "Epoch [46/50], Step [204/735], Loss: 0.0831\n",
      "Epoch [46/50], Step [205/735], Loss: 0.1028\n",
      "Epoch [46/50], Step [206/735], Loss: 0.4849\n",
      "Epoch [46/50], Step [207/735], Loss: 0.3090\n",
      "Epoch [46/50], Step [208/735], Loss: 0.0622\n",
      "Epoch [46/50], Step [209/735], Loss: 0.0754\n",
      "Epoch [46/50], Step [210/735], Loss: 0.1710\n",
      "Epoch [46/50], Step [211/735], Loss: 0.0430\n",
      "Epoch [46/50], Step [212/735], Loss: 0.2225\n",
      "Epoch [46/50], Step [213/735], Loss: 0.1444\n",
      "Epoch [46/50], Step [214/735], Loss: 0.0982\n",
      "Epoch [46/50], Step [215/735], Loss: 0.1122\n",
      "Epoch [46/50], Step [216/735], Loss: 0.0740\n",
      "Epoch [46/50], Step [217/735], Loss: 0.1161\n",
      "Epoch [46/50], Step [218/735], Loss: 0.0341\n",
      "Epoch [46/50], Step [219/735], Loss: 0.0387\n",
      "Epoch [46/50], Step [220/735], Loss: 0.0898\n",
      "Epoch [46/50], Step [221/735], Loss: 0.0388\n",
      "Epoch [46/50], Step [222/735], Loss: 0.0909\n",
      "Epoch [46/50], Step [223/735], Loss: 0.0441\n",
      "Epoch [46/50], Step [224/735], Loss: 0.1809\n",
      "Epoch [46/50], Step [225/735], Loss: 0.0991\n",
      "Epoch [46/50], Step [226/735], Loss: 0.0679\n",
      "Epoch [46/50], Step [227/735], Loss: 0.1192\n",
      "Epoch [46/50], Step [228/735], Loss: 0.2639\n",
      "Epoch [46/50], Step [229/735], Loss: 0.0887\n",
      "Epoch [46/50], Step [230/735], Loss: 0.0606\n",
      "Epoch [46/50], Step [231/735], Loss: 0.1552\n",
      "Epoch [46/50], Step [232/735], Loss: 0.1144\n",
      "Epoch [46/50], Step [233/735], Loss: 0.0561\n",
      "Epoch [46/50], Step [234/735], Loss: 0.0669\n",
      "Epoch [46/50], Step [235/735], Loss: 0.0393\n",
      "Epoch [46/50], Step [236/735], Loss: 0.0421\n",
      "Epoch [46/50], Step [237/735], Loss: 0.2766\n",
      "Epoch [46/50], Step [238/735], Loss: 0.1058\n",
      "Epoch [46/50], Step [239/735], Loss: 0.0491\n",
      "Epoch [46/50], Step [240/735], Loss: 0.0612\n",
      "Epoch [46/50], Step [241/735], Loss: 0.0729\n",
      "Epoch [46/50], Step [242/735], Loss: 0.1256\n",
      "Epoch [46/50], Step [243/735], Loss: 0.0676\n",
      "Epoch [46/50], Step [244/735], Loss: 0.1282\n",
      "Epoch [46/50], Step [245/735], Loss: 0.0883\n",
      "Epoch [46/50], Step [246/735], Loss: 0.1727\n",
      "Epoch [46/50], Step [247/735], Loss: 0.1000\n",
      "Epoch [46/50], Step [248/735], Loss: 0.1021\n",
      "Epoch [46/50], Step [249/735], Loss: 0.0564\n",
      "Epoch [46/50], Step [250/735], Loss: 0.1719\n",
      "Epoch [46/50], Step [251/735], Loss: 0.1163\n",
      "Epoch [46/50], Step [252/735], Loss: 0.0862\n",
      "Epoch [46/50], Step [253/735], Loss: 0.0942\n",
      "Epoch [46/50], Step [254/735], Loss: 1.1878\n",
      "Epoch [46/50], Step [255/735], Loss: 0.1616\n",
      "Epoch [46/50], Step [256/735], Loss: 0.2077\n",
      "Epoch [46/50], Step [257/735], Loss: 0.1163\n",
      "Epoch [46/50], Step [258/735], Loss: 0.1069\n",
      "Epoch [46/50], Step [259/735], Loss: 0.0995\n",
      "Epoch [46/50], Step [260/735], Loss: 0.0420\n",
      "Epoch [46/50], Step [261/735], Loss: 0.0676\n",
      "Epoch [46/50], Step [262/735], Loss: 0.0621\n",
      "Epoch [46/50], Step [263/735], Loss: 0.0887\n",
      "Epoch [46/50], Step [264/735], Loss: 0.4329\n",
      "Epoch [46/50], Step [265/735], Loss: 0.0841\n",
      "Epoch [46/50], Step [266/735], Loss: 0.0604\n",
      "Epoch [46/50], Step [267/735], Loss: 0.0843\n",
      "Epoch [46/50], Step [268/735], Loss: 0.0987\n",
      "Epoch [46/50], Step [269/735], Loss: 0.1087\n",
      "Epoch [46/50], Step [270/735], Loss: 0.1385\n",
      "Epoch [46/50], Step [271/735], Loss: 0.1632\n",
      "Epoch [46/50], Step [272/735], Loss: 0.1026\n",
      "Epoch [46/50], Step [273/735], Loss: 0.8964\n",
      "Epoch [46/50], Step [274/735], Loss: 0.0903\n",
      "Epoch [46/50], Step [275/735], Loss: 0.0495\n",
      "Epoch [46/50], Step [276/735], Loss: 0.0865\n",
      "Epoch [46/50], Step [277/735], Loss: 0.1406\n",
      "Epoch [46/50], Step [278/735], Loss: 0.1508\n",
      "Epoch [46/50], Step [279/735], Loss: 0.5729\n",
      "Epoch [46/50], Step [280/735], Loss: 1.6898\n",
      "Epoch [46/50], Step [281/735], Loss: 0.0780\n",
      "Epoch [46/50], Step [282/735], Loss: 0.1420\n",
      "Epoch [46/50], Step [283/735], Loss: 0.1972\n",
      "Epoch [46/50], Step [284/735], Loss: 0.1413\n",
      "Epoch [46/50], Step [285/735], Loss: 0.2382\n",
      "Epoch [46/50], Step [286/735], Loss: 0.0786\n",
      "Epoch [46/50], Step [287/735], Loss: 0.0808\n",
      "Epoch [46/50], Step [288/735], Loss: 0.1524\n",
      "Epoch [46/50], Step [289/735], Loss: 0.1188\n",
      "Epoch [46/50], Step [290/735], Loss: 0.0728\n",
      "Epoch [46/50], Step [291/735], Loss: 0.1852\n",
      "Epoch [46/50], Step [292/735], Loss: 0.1159\n",
      "Epoch [46/50], Step [293/735], Loss: 0.0445\n",
      "Epoch [46/50], Step [294/735], Loss: 0.3035\n",
      "Epoch [46/50], Step [295/735], Loss: 0.5683\n",
      "Epoch [46/50], Step [296/735], Loss: 0.0897\n",
      "Epoch [46/50], Step [297/735], Loss: 0.0680\n",
      "Epoch [46/50], Step [298/735], Loss: 0.1189\n",
      "Epoch [46/50], Step [299/735], Loss: 0.0667\n",
      "Epoch [46/50], Step [300/735], Loss: 0.0693\n",
      "Epoch [46/50], Step [301/735], Loss: 0.0909\n",
      "Epoch [46/50], Step [302/735], Loss: 0.0579\n",
      "Epoch [46/50], Step [303/735], Loss: 0.0926\n",
      "Epoch [46/50], Step [304/735], Loss: 0.0578\n",
      "Epoch [46/50], Step [305/735], Loss: 0.1049\n",
      "Epoch [46/50], Step [306/735], Loss: 0.1087\n",
      "Epoch [46/50], Step [307/735], Loss: 0.1075\n",
      "Epoch [46/50], Step [308/735], Loss: 0.0791\n",
      "Epoch [46/50], Step [309/735], Loss: 0.2379\n",
      "Epoch [46/50], Step [310/735], Loss: 0.3893\n",
      "Epoch [46/50], Step [311/735], Loss: 0.0794\n",
      "Epoch [46/50], Step [312/735], Loss: 0.1229\n",
      "Epoch [46/50], Step [313/735], Loss: 0.0782\n",
      "Epoch [46/50], Step [314/735], Loss: 0.0385\n",
      "Epoch [46/50], Step [315/735], Loss: 0.0845\n",
      "Epoch [46/50], Step [316/735], Loss: 0.0515\n",
      "Epoch [46/50], Step [317/735], Loss: 0.0790\n",
      "Epoch [46/50], Step [318/735], Loss: 0.1360\n",
      "Epoch [46/50], Step [319/735], Loss: 0.4084\n",
      "Epoch [46/50], Step [320/735], Loss: 0.0847\n",
      "Epoch [46/50], Step [321/735], Loss: 0.2123\n",
      "Epoch [46/50], Step [322/735], Loss: 0.0452\n",
      "Epoch [46/50], Step [323/735], Loss: 0.1110\n",
      "Epoch [46/50], Step [324/735], Loss: 0.1179\n",
      "Epoch [46/50], Step [325/735], Loss: 0.0790\n",
      "Epoch [46/50], Step [326/735], Loss: 0.1251\n",
      "Epoch [46/50], Step [327/735], Loss: 0.1307\n",
      "Epoch [46/50], Step [328/735], Loss: 0.1383\n",
      "Epoch [46/50], Step [329/735], Loss: 0.1452\n",
      "Epoch [46/50], Step [330/735], Loss: 0.2016\n",
      "Epoch [46/50], Step [331/735], Loss: 0.0564\n",
      "Epoch [46/50], Step [332/735], Loss: 1.1870\n",
      "Epoch [46/50], Step [333/735], Loss: 0.0803\n",
      "Epoch [46/50], Step [334/735], Loss: 0.1182\n",
      "Epoch [46/50], Step [335/735], Loss: 0.0691\n",
      "Epoch [46/50], Step [336/735], Loss: 0.1361\n",
      "Epoch [46/50], Step [337/735], Loss: 0.0489\n",
      "Epoch [46/50], Step [338/735], Loss: 0.1437\n",
      "Epoch [46/50], Step [339/735], Loss: 0.1337\n",
      "Epoch [46/50], Step [340/735], Loss: 0.1168\n",
      "Epoch [46/50], Step [341/735], Loss: 0.1012\n",
      "Epoch [46/50], Step [342/735], Loss: 0.0994\n",
      "Epoch [46/50], Step [343/735], Loss: 0.1910\n",
      "Epoch [46/50], Step [344/735], Loss: 0.0837\n",
      "Epoch [46/50], Step [345/735], Loss: 0.0530\n",
      "Epoch [46/50], Step [346/735], Loss: 0.0835\n",
      "Epoch [46/50], Step [347/735], Loss: 0.2350\n",
      "Epoch [46/50], Step [348/735], Loss: 0.1181\n",
      "Epoch [46/50], Step [349/735], Loss: 1.1536\n",
      "Epoch [46/50], Step [350/735], Loss: 0.1094\n",
      "Epoch [46/50], Step [351/735], Loss: 0.2651\n",
      "Epoch [46/50], Step [352/735], Loss: 0.1189\n",
      "Epoch [46/50], Step [353/735], Loss: 0.0900\n",
      "Epoch [46/50], Step [354/735], Loss: 0.1206\n",
      "Epoch [46/50], Step [355/735], Loss: 0.1264\n",
      "Epoch [46/50], Step [356/735], Loss: 0.0618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Step [357/735], Loss: 0.0406\n",
      "Epoch [46/50], Step [358/735], Loss: 0.2047\n",
      "Epoch [46/50], Step [359/735], Loss: 0.0775\n",
      "Epoch [46/50], Step [360/735], Loss: 0.0458\n",
      "Epoch [46/50], Step [361/735], Loss: 0.0705\n",
      "Epoch [46/50], Step [362/735], Loss: 0.1013\n",
      "Epoch [46/50], Step [363/735], Loss: 0.1231\n",
      "Epoch [46/50], Step [364/735], Loss: 0.0657\n",
      "Epoch [46/50], Step [365/735], Loss: 0.1066\n",
      "Epoch [46/50], Step [366/735], Loss: 0.1060\n",
      "Epoch [46/50], Step [367/735], Loss: 0.1073\n",
      "Epoch [46/50], Step [368/735], Loss: 0.1557\n",
      "Epoch [46/50], Step [369/735], Loss: 0.2032\n",
      "Epoch [46/50], Step [370/735], Loss: 0.1144\n",
      "Epoch [46/50], Step [371/735], Loss: 0.0894\n",
      "Epoch [46/50], Step [372/735], Loss: 0.0546\n",
      "Epoch [46/50], Step [373/735], Loss: 0.1213\n",
      "Epoch [46/50], Step [374/735], Loss: 0.1211\n",
      "Epoch [46/50], Step [375/735], Loss: 0.0725\n",
      "Epoch [46/50], Step [376/735], Loss: 0.0523\n",
      "Epoch [46/50], Step [377/735], Loss: 0.0733\n",
      "Epoch [46/50], Step [378/735], Loss: 0.1738\n",
      "Epoch [46/50], Step [379/735], Loss: 0.1240\n",
      "Epoch [46/50], Step [380/735], Loss: 0.0645\n",
      "Epoch [46/50], Step [381/735], Loss: 0.1260\n",
      "Epoch [46/50], Step [382/735], Loss: 0.2326\n",
      "Epoch [46/50], Step [383/735], Loss: 0.0942\n",
      "Epoch [46/50], Step [384/735], Loss: 0.0962\n",
      "Epoch [46/50], Step [385/735], Loss: 0.1218\n",
      "Epoch [46/50], Step [386/735], Loss: 0.0657\n",
      "Epoch [46/50], Step [387/735], Loss: 0.1429\n",
      "Epoch [46/50], Step [388/735], Loss: 0.0583\n",
      "Epoch [46/50], Step [389/735], Loss: 0.2193\n",
      "Epoch [46/50], Step [390/735], Loss: 0.1107\n",
      "Epoch [46/50], Step [391/735], Loss: 0.1741\n",
      "Epoch [46/50], Step [392/735], Loss: 0.1105\n",
      "Epoch [46/50], Step [393/735], Loss: 0.1824\n",
      "Epoch [46/50], Step [394/735], Loss: 0.0808\n",
      "Epoch [46/50], Step [395/735], Loss: 0.0436\n",
      "Epoch [46/50], Step [396/735], Loss: 0.1440\n",
      "Epoch [46/50], Step [397/735], Loss: 0.9689\n",
      "Epoch [46/50], Step [398/735], Loss: 0.1329\n",
      "Epoch [46/50], Step [399/735], Loss: 0.0885\n",
      "Epoch [46/50], Step [400/735], Loss: 0.1225\n",
      "Epoch [46/50], Step [401/735], Loss: 1.2218\n",
      "Epoch [46/50], Step [402/735], Loss: 0.0570\n",
      "Epoch [46/50], Step [403/735], Loss: 0.0683\n",
      "Epoch [46/50], Step [404/735], Loss: 0.1325\n",
      "Epoch [46/50], Step [405/735], Loss: 0.0857\n",
      "Epoch [46/50], Step [406/735], Loss: 0.0248\n",
      "Epoch [46/50], Step [407/735], Loss: 0.1031\n",
      "Epoch [46/50], Step [408/735], Loss: 0.0606\n",
      "Epoch [46/50], Step [409/735], Loss: 0.1182\n",
      "Epoch [46/50], Step [410/735], Loss: 0.0475\n",
      "Epoch [46/50], Step [411/735], Loss: 0.0932\n",
      "Epoch [46/50], Step [412/735], Loss: 0.0971\n",
      "Epoch [46/50], Step [413/735], Loss: 0.1211\n",
      "Epoch [46/50], Step [414/735], Loss: 0.0874\n",
      "Epoch [46/50], Step [415/735], Loss: 0.0464\n",
      "Epoch [46/50], Step [416/735], Loss: 0.0836\n",
      "Epoch [46/50], Step [417/735], Loss: 0.0969\n",
      "Epoch [46/50], Step [418/735], Loss: 0.1087\n",
      "Epoch [46/50], Step [419/735], Loss: 0.0837\n",
      "Epoch [46/50], Step [420/735], Loss: 0.0591\n",
      "Epoch [46/50], Step [421/735], Loss: 0.1250\n",
      "Epoch [46/50], Step [422/735], Loss: 0.0860\n",
      "Epoch [46/50], Step [423/735], Loss: 0.0916\n",
      "Epoch [46/50], Step [424/735], Loss: 0.0711\n",
      "Epoch [46/50], Step [425/735], Loss: 0.0994\n",
      "Epoch [46/50], Step [426/735], Loss: 0.1027\n",
      "Epoch [46/50], Step [427/735], Loss: 0.0491\n",
      "Epoch [46/50], Step [428/735], Loss: 0.4055\n",
      "Epoch [46/50], Step [429/735], Loss: 0.0373\n",
      "Epoch [46/50], Step [430/735], Loss: 0.0663\n",
      "Epoch [46/50], Step [431/735], Loss: 0.0834\n",
      "Epoch [46/50], Step [432/735], Loss: 0.2990\n",
      "Epoch [46/50], Step [433/735], Loss: 0.6833\n",
      "Epoch [46/50], Step [434/735], Loss: 0.2795\n",
      "Epoch [46/50], Step [435/735], Loss: 0.0566\n",
      "Epoch [46/50], Step [436/735], Loss: 0.1449\n",
      "Epoch [46/50], Step [437/735], Loss: 0.1378\n",
      "Epoch [46/50], Step [438/735], Loss: 0.0331\n",
      "Epoch [46/50], Step [439/735], Loss: 0.0868\n",
      "Epoch [46/50], Step [440/735], Loss: 0.5456\n",
      "Epoch [46/50], Step [441/735], Loss: 0.0781\n",
      "Epoch [46/50], Step [442/735], Loss: 0.2272\n",
      "Epoch [46/50], Step [443/735], Loss: 0.0913\n",
      "Epoch [46/50], Step [444/735], Loss: 0.2963\n",
      "Epoch [46/50], Step [445/735], Loss: 0.1028\n",
      "Epoch [46/50], Step [446/735], Loss: 0.3240\n",
      "Epoch [46/50], Step [447/735], Loss: 0.1219\n",
      "Epoch [46/50], Step [448/735], Loss: 0.1755\n",
      "Epoch [46/50], Step [449/735], Loss: 0.0762\n",
      "Epoch [46/50], Step [450/735], Loss: 0.1580\n",
      "Epoch [46/50], Step [451/735], Loss: 0.0713\n",
      "Epoch [46/50], Step [452/735], Loss: 0.0286\n",
      "Epoch [46/50], Step [453/735], Loss: 0.1364\n",
      "Epoch [46/50], Step [454/735], Loss: 0.0624\n",
      "Epoch [46/50], Step [455/735], Loss: 0.1222\n",
      "Epoch [46/50], Step [456/735], Loss: 0.1108\n",
      "Epoch [46/50], Step [457/735], Loss: 0.1317\n",
      "Epoch [46/50], Step [458/735], Loss: 0.0762\n",
      "Epoch [46/50], Step [459/735], Loss: 0.0804\n",
      "Epoch [46/50], Step [460/735], Loss: 0.1160\n",
      "Epoch [46/50], Step [461/735], Loss: 0.2027\n",
      "Epoch [46/50], Step [462/735], Loss: 0.0953\n",
      "Epoch [46/50], Step [463/735], Loss: 0.0676\n",
      "Epoch [46/50], Step [464/735], Loss: 0.0780\n",
      "Epoch [46/50], Step [465/735], Loss: 0.0454\n",
      "Epoch [46/50], Step [466/735], Loss: 0.2235\n",
      "Epoch [46/50], Step [467/735], Loss: 0.0343\n",
      "Epoch [46/50], Step [468/735], Loss: 0.2895\n",
      "Epoch [46/50], Step [469/735], Loss: 0.1562\n",
      "Epoch [46/50], Step [470/735], Loss: 0.0516\n",
      "Epoch [46/50], Step [471/735], Loss: 0.0719\n",
      "Epoch [46/50], Step [472/735], Loss: 0.1673\n",
      "Epoch [46/50], Step [473/735], Loss: 0.1390\n",
      "Epoch [46/50], Step [474/735], Loss: 0.1098\n",
      "Epoch [46/50], Step [475/735], Loss: 0.0581\n",
      "Epoch [46/50], Step [476/735], Loss: 0.1895\n",
      "Epoch [46/50], Step [477/735], Loss: 0.1109\n",
      "Epoch [46/50], Step [478/735], Loss: 0.0852\n",
      "Epoch [46/50], Step [479/735], Loss: 0.0744\n",
      "Epoch [46/50], Step [480/735], Loss: 0.0469\n",
      "Epoch [46/50], Step [481/735], Loss: 0.0914\n",
      "Epoch [46/50], Step [482/735], Loss: 0.1103\n",
      "Epoch [46/50], Step [483/735], Loss: 0.1338\n",
      "Epoch [46/50], Step [484/735], Loss: 0.0809\n",
      "Epoch [46/50], Step [485/735], Loss: 0.1037\n",
      "Epoch [46/50], Step [486/735], Loss: 0.1171\n",
      "Epoch [46/50], Step [487/735], Loss: 0.0979\n",
      "Epoch [46/50], Step [488/735], Loss: 0.1106\n",
      "Epoch [46/50], Step [489/735], Loss: 0.3674\n",
      "Epoch [46/50], Step [490/735], Loss: 0.2646\n",
      "Epoch [46/50], Step [491/735], Loss: 0.0456\n",
      "Epoch [46/50], Step [492/735], Loss: 0.0680\n",
      "Epoch [46/50], Step [493/735], Loss: 0.2024\n",
      "Epoch [46/50], Step [494/735], Loss: 0.1972\n",
      "Epoch [46/50], Step [495/735], Loss: 0.1849\n",
      "Epoch [46/50], Step [496/735], Loss: 0.1916\n",
      "Epoch [46/50], Step [497/735], Loss: 0.1341\n",
      "Epoch [46/50], Step [498/735], Loss: 0.1177\n",
      "Epoch [46/50], Step [499/735], Loss: 0.1412\n",
      "Epoch [46/50], Step [500/735], Loss: 0.1273\n",
      "Epoch [46/50], Step [501/735], Loss: 0.0649\n",
      "Epoch [46/50], Step [502/735], Loss: 0.0945\n",
      "Epoch [46/50], Step [503/735], Loss: 0.0766\n",
      "Epoch [46/50], Step [504/735], Loss: 0.0233\n",
      "Epoch [46/50], Step [505/735], Loss: 0.2936\n",
      "Epoch [46/50], Step [506/735], Loss: 0.0393\n",
      "Epoch [46/50], Step [507/735], Loss: 0.0520\n",
      "Epoch [46/50], Step [508/735], Loss: 0.0630\n",
      "Epoch [46/50], Step [509/735], Loss: 0.0836\n",
      "Epoch [46/50], Step [510/735], Loss: 0.1223\n",
      "Epoch [46/50], Step [511/735], Loss: 0.1300\n",
      "Epoch [46/50], Step [512/735], Loss: 0.1410\n",
      "Epoch [46/50], Step [513/735], Loss: 0.0586\n",
      "Epoch [46/50], Step [514/735], Loss: 0.0700\n",
      "Epoch [46/50], Step [515/735], Loss: 0.0943\n",
      "Epoch [46/50], Step [516/735], Loss: 0.1037\n",
      "Epoch [46/50], Step [517/735], Loss: 0.1513\n",
      "Epoch [46/50], Step [518/735], Loss: 0.1381\n",
      "Epoch [46/50], Step [519/735], Loss: 0.3406\n",
      "Epoch [46/50], Step [520/735], Loss: 0.0240\n",
      "Epoch [46/50], Step [521/735], Loss: 0.0470\n",
      "Epoch [46/50], Step [522/735], Loss: 0.0720\n",
      "Epoch [46/50], Step [523/735], Loss: 0.0973\n",
      "Epoch [46/50], Step [524/735], Loss: 0.0931\n",
      "Epoch [46/50], Step [525/735], Loss: 0.1571\n",
      "Epoch [46/50], Step [526/735], Loss: 0.0201\n",
      "Epoch [46/50], Step [527/735], Loss: 0.0441\n",
      "Epoch [46/50], Step [528/735], Loss: 0.0738\n",
      "Epoch [46/50], Step [529/735], Loss: 0.0431\n",
      "Epoch [46/50], Step [530/735], Loss: 0.0639\n",
      "Epoch [46/50], Step [531/735], Loss: 0.0421\n",
      "Epoch [46/50], Step [532/735], Loss: 0.0395\n",
      "Epoch [46/50], Step [533/735], Loss: 0.0653\n",
      "Epoch [46/50], Step [534/735], Loss: 0.1623\n",
      "Epoch [46/50], Step [535/735], Loss: 0.0275\n",
      "Epoch [46/50], Step [536/735], Loss: 0.1913\n",
      "Epoch [46/50], Step [537/735], Loss: 0.2366\n",
      "Epoch [46/50], Step [538/735], Loss: 0.1730\n",
      "Epoch [46/50], Step [539/735], Loss: 0.0296\n",
      "Epoch [46/50], Step [540/735], Loss: 0.0736\n",
      "Epoch [46/50], Step [541/735], Loss: 0.0569\n",
      "Epoch [46/50], Step [542/735], Loss: 0.1410\n",
      "Epoch [46/50], Step [543/735], Loss: 0.0568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Step [544/735], Loss: 0.0277\n",
      "Epoch [46/50], Step [545/735], Loss: 0.0730\n",
      "Epoch [46/50], Step [546/735], Loss: 0.1207\n",
      "Epoch [46/50], Step [547/735], Loss: 0.0835\n",
      "Epoch [46/50], Step [548/735], Loss: 0.0856\n",
      "Epoch [46/50], Step [549/735], Loss: 0.7730\n",
      "Epoch [46/50], Step [550/735], Loss: 0.2099\n",
      "Epoch [46/50], Step [551/735], Loss: 0.1418\n",
      "Epoch [46/50], Step [552/735], Loss: 0.1819\n",
      "Epoch [46/50], Step [553/735], Loss: 0.1052\n",
      "Epoch [46/50], Step [554/735], Loss: 0.1231\n",
      "Epoch [46/50], Step [555/735], Loss: 0.0567\n",
      "Epoch [46/50], Step [556/735], Loss: 0.0800\n",
      "Epoch [46/50], Step [557/735], Loss: 0.0723\n",
      "Epoch [46/50], Step [558/735], Loss: 0.1514\n",
      "Epoch [46/50], Step [559/735], Loss: 0.2163\n",
      "Epoch [46/50], Step [560/735], Loss: 0.0559\n",
      "Epoch [46/50], Step [561/735], Loss: 0.3522\n",
      "Epoch [46/50], Step [562/735], Loss: 0.1083\n",
      "Epoch [46/50], Step [563/735], Loss: 0.0906\n",
      "Epoch [46/50], Step [564/735], Loss: 0.2646\n",
      "Epoch [46/50], Step [565/735], Loss: 0.0441\n",
      "Epoch [46/50], Step [566/735], Loss: 0.0850\n",
      "Epoch [46/50], Step [567/735], Loss: 0.1342\n",
      "Epoch [46/50], Step [568/735], Loss: 0.0581\n",
      "Epoch [46/50], Step [569/735], Loss: 1.2794\n",
      "Epoch [46/50], Step [570/735], Loss: 0.1001\n",
      "Epoch [46/50], Step [571/735], Loss: 0.1107\n",
      "Epoch [46/50], Step [572/735], Loss: 0.0354\n",
      "Epoch [46/50], Step [573/735], Loss: 0.0532\n",
      "Epoch [46/50], Step [574/735], Loss: 0.0810\n",
      "Epoch [46/50], Step [575/735], Loss: 0.0940\n",
      "Epoch [46/50], Step [576/735], Loss: 0.0661\n",
      "Epoch [46/50], Step [577/735], Loss: 0.0746\n",
      "Epoch [46/50], Step [578/735], Loss: 0.0951\n",
      "Epoch [46/50], Step [579/735], Loss: 0.1996\n",
      "Epoch [46/50], Step [580/735], Loss: 0.1257\n",
      "Epoch [46/50], Step [581/735], Loss: 0.1304\n",
      "Epoch [46/50], Step [582/735], Loss: 0.1087\n",
      "Epoch [46/50], Step [583/735], Loss: 0.1735\n",
      "Epoch [46/50], Step [584/735], Loss: 0.0798\n",
      "Epoch [46/50], Step [585/735], Loss: 0.1782\n",
      "Epoch [46/50], Step [586/735], Loss: 0.4703\n",
      "Epoch [46/50], Step [587/735], Loss: 0.1792\n",
      "Epoch [46/50], Step [588/735], Loss: 0.0495\n",
      "Epoch [46/50], Step [589/735], Loss: 0.1619\n",
      "Epoch [46/50], Step [590/735], Loss: 0.1917\n",
      "Epoch [46/50], Step [591/735], Loss: 0.1285\n",
      "Epoch [46/50], Step [592/735], Loss: 0.0418\n",
      "Epoch [46/50], Step [593/735], Loss: 0.1416\n",
      "Epoch [46/50], Step [594/735], Loss: 0.0823\n",
      "Epoch [46/50], Step [595/735], Loss: 0.1256\n",
      "Epoch [46/50], Step [596/735], Loss: 0.1019\n",
      "Epoch [46/50], Step [597/735], Loss: 0.0374\n",
      "Epoch [46/50], Step [598/735], Loss: 0.1123\n",
      "Epoch [46/50], Step [599/735], Loss: 0.0439\n",
      "Epoch [46/50], Step [600/735], Loss: 0.1178\n",
      "Epoch [46/50], Step [601/735], Loss: 0.1224\n",
      "Epoch [46/50], Step [602/735], Loss: 0.1284\n",
      "Epoch [46/50], Step [603/735], Loss: 0.1616\n",
      "Epoch [46/50], Step [604/735], Loss: 0.0552\n",
      "Epoch [46/50], Step [605/735], Loss: 0.1146\n",
      "Epoch [46/50], Step [606/735], Loss: 0.0921\n",
      "Epoch [46/50], Step [607/735], Loss: 0.0763\n",
      "Epoch [46/50], Step [608/735], Loss: 0.0906\n",
      "Epoch [46/50], Step [609/735], Loss: 0.0654\n",
      "Epoch [46/50], Step [610/735], Loss: 0.1596\n",
      "Epoch [46/50], Step [611/735], Loss: 0.1741\n",
      "Epoch [46/50], Step [612/735], Loss: 0.3417\n",
      "Epoch [46/50], Step [613/735], Loss: 0.1488\n",
      "Epoch [46/50], Step [614/735], Loss: 0.0928\n",
      "Epoch [46/50], Step [615/735], Loss: 0.0777\n",
      "Epoch [46/50], Step [616/735], Loss: 0.0919\n",
      "Epoch [46/50], Step [617/735], Loss: 0.0950\n",
      "Epoch [46/50], Step [618/735], Loss: 0.2312\n",
      "Epoch [46/50], Step [619/735], Loss: 0.1813\n",
      "Epoch [46/50], Step [620/735], Loss: 0.0618\n",
      "Epoch [46/50], Step [621/735], Loss: 0.0445\n",
      "Epoch [46/50], Step [622/735], Loss: 0.1156\n",
      "Epoch [46/50], Step [623/735], Loss: 0.0650\n",
      "Epoch [46/50], Step [624/735], Loss: 0.0413\n",
      "Epoch [46/50], Step [625/735], Loss: 0.1254\n",
      "Epoch [46/50], Step [626/735], Loss: 0.0852\n",
      "Epoch [46/50], Step [627/735], Loss: 0.0556\n",
      "Epoch [46/50], Step [628/735], Loss: 0.0408\n",
      "Epoch [46/50], Step [629/735], Loss: 0.0952\n",
      "Epoch [46/50], Step [630/735], Loss: 0.0743\n",
      "Epoch [46/50], Step [631/735], Loss: 0.0495\n",
      "Epoch [46/50], Step [632/735], Loss: 0.1130\n",
      "Epoch [46/50], Step [633/735], Loss: 0.1087\n",
      "Epoch [46/50], Step [634/735], Loss: 0.0587\n",
      "Epoch [46/50], Step [635/735], Loss: 0.2012\n",
      "Epoch [46/50], Step [636/735], Loss: 0.1320\n",
      "Epoch [46/50], Step [637/735], Loss: 0.0451\n",
      "Epoch [46/50], Step [638/735], Loss: 0.0623\n",
      "Epoch [46/50], Step [639/735], Loss: 0.1068\n",
      "Epoch [46/50], Step [640/735], Loss: 0.0364\n",
      "Epoch [46/50], Step [641/735], Loss: 0.1302\n",
      "Epoch [46/50], Step [642/735], Loss: 0.1570\n",
      "Epoch [46/50], Step [643/735], Loss: 0.0603\n",
      "Epoch [46/50], Step [644/735], Loss: 0.0339\n",
      "Epoch [46/50], Step [645/735], Loss: 0.0798\n",
      "Epoch [46/50], Step [646/735], Loss: 0.8711\n",
      "Epoch [46/50], Step [647/735], Loss: 0.0902\n",
      "Epoch [46/50], Step [648/735], Loss: 1.4319\n",
      "Epoch [46/50], Step [649/735], Loss: 0.0538\n",
      "Epoch [46/50], Step [650/735], Loss: 0.1000\n",
      "Epoch [46/50], Step [651/735], Loss: 0.0448\n",
      "Epoch [46/50], Step [652/735], Loss: 0.1034\n",
      "Epoch [46/50], Step [653/735], Loss: 0.1820\n",
      "Epoch [46/50], Step [654/735], Loss: 0.1344\n",
      "Epoch [46/50], Step [655/735], Loss: 0.3043\n",
      "Epoch [46/50], Step [656/735], Loss: 0.3956\n",
      "Epoch [46/50], Step [657/735], Loss: 0.1411\n",
      "Epoch [46/50], Step [658/735], Loss: 0.0501\n",
      "Epoch [46/50], Step [659/735], Loss: 0.0388\n",
      "Epoch [46/50], Step [660/735], Loss: 0.1310\n",
      "Epoch [46/50], Step [661/735], Loss: 0.0825\n",
      "Epoch [46/50], Step [662/735], Loss: 0.1340\n",
      "Epoch [46/50], Step [663/735], Loss: 0.1254\n",
      "Epoch [46/50], Step [664/735], Loss: 0.1177\n",
      "Epoch [46/50], Step [665/735], Loss: 0.2828\n",
      "Epoch [46/50], Step [666/735], Loss: 0.0989\n",
      "Epoch [46/50], Step [667/735], Loss: 0.0958\n",
      "Epoch [46/50], Step [668/735], Loss: 0.0813\n",
      "Epoch [46/50], Step [669/735], Loss: 0.0368\n",
      "Epoch [46/50], Step [670/735], Loss: 0.0721\n",
      "Epoch [46/50], Step [671/735], Loss: 0.1427\n",
      "Epoch [46/50], Step [672/735], Loss: 0.0655\n",
      "Epoch [46/50], Step [673/735], Loss: 0.0840\n",
      "Epoch [46/50], Step [674/735], Loss: 0.0501\n",
      "Epoch [46/50], Step [675/735], Loss: 0.0707\n",
      "Epoch [46/50], Step [676/735], Loss: 0.0936\n",
      "Epoch [46/50], Step [677/735], Loss: 0.0930\n",
      "Epoch [46/50], Step [678/735], Loss: 0.0588\n",
      "Epoch [46/50], Step [679/735], Loss: 0.1099\n",
      "Epoch [46/50], Step [680/735], Loss: 0.1857\n",
      "Epoch [46/50], Step [681/735], Loss: 0.0665\n",
      "Epoch [46/50], Step [682/735], Loss: 0.0449\n",
      "Epoch [46/50], Step [683/735], Loss: 0.0859\n",
      "Epoch [46/50], Step [684/735], Loss: 0.1236\n",
      "Epoch [46/50], Step [685/735], Loss: 0.0292\n",
      "Epoch [46/50], Step [686/735], Loss: 0.1054\n",
      "Epoch [46/50], Step [687/735], Loss: 0.0646\n",
      "Epoch [46/50], Step [688/735], Loss: 0.1508\n",
      "Epoch [46/50], Step [689/735], Loss: 0.0783\n",
      "Epoch [46/50], Step [690/735], Loss: 0.0404\n",
      "Epoch [46/50], Step [691/735], Loss: 0.0356\n",
      "Epoch [46/50], Step [692/735], Loss: 0.0859\n",
      "Epoch [46/50], Step [693/735], Loss: 0.0814\n",
      "Epoch [46/50], Step [694/735], Loss: 0.0461\n",
      "Epoch [46/50], Step [695/735], Loss: 0.0800\n",
      "Epoch [46/50], Step [696/735], Loss: 0.0426\n",
      "Epoch [46/50], Step [697/735], Loss: 0.0557\n",
      "Epoch [46/50], Step [698/735], Loss: 0.0899\n",
      "Epoch [46/50], Step [699/735], Loss: 0.1009\n",
      "Epoch [46/50], Step [700/735], Loss: 0.0679\n",
      "Epoch [46/50], Step [701/735], Loss: 0.1006\n",
      "Epoch [46/50], Step [702/735], Loss: 0.1500\n",
      "Epoch [46/50], Step [703/735], Loss: 0.0907\n",
      "Epoch [46/50], Step [704/735], Loss: 0.1518\n",
      "Epoch [46/50], Step [705/735], Loss: 0.2172\n",
      "Epoch [46/50], Step [706/735], Loss: 0.1022\n",
      "Epoch [46/50], Step [707/735], Loss: 0.0869\n",
      "Epoch [46/50], Step [708/735], Loss: 0.1430\n",
      "Epoch [46/50], Step [709/735], Loss: 0.1271\n",
      "Epoch [46/50], Step [710/735], Loss: 0.0461\n",
      "Epoch [46/50], Step [711/735], Loss: 0.1949\n",
      "Epoch [46/50], Step [712/735], Loss: 0.0850\n",
      "Epoch [46/50], Step [713/735], Loss: 0.0836\n",
      "Epoch [46/50], Step [714/735], Loss: 0.0709\n",
      "Epoch [46/50], Step [715/735], Loss: 0.1428\n",
      "Epoch [46/50], Step [716/735], Loss: 0.0311\n",
      "Epoch [46/50], Step [717/735], Loss: 0.1343\n",
      "Epoch [46/50], Step [718/735], Loss: 0.0668\n",
      "Epoch [46/50], Step [719/735], Loss: 0.1045\n",
      "Epoch [46/50], Step [720/735], Loss: 0.1427\n",
      "Epoch [46/50], Step [721/735], Loss: 0.1385\n",
      "Epoch [46/50], Step [722/735], Loss: 0.0687\n",
      "Epoch [46/50], Step [723/735], Loss: 0.1274\n",
      "Epoch [46/50], Step [724/735], Loss: 0.0471\n",
      "Epoch [46/50], Step [725/735], Loss: 0.0690\n",
      "Epoch [46/50], Step [726/735], Loss: 0.0716\n",
      "Epoch [46/50], Step [727/735], Loss: 0.0369\n",
      "Epoch [46/50], Step [728/735], Loss: 0.0279\n",
      "Epoch [46/50], Step [729/735], Loss: 0.0613\n",
      "Epoch [46/50], Step [730/735], Loss: 0.0922\n",
      "Epoch [46/50], Step [731/735], Loss: 0.0769\n",
      "Epoch [46/50], Step [732/735], Loss: 0.0866\n",
      "Epoch [46/50], Step [733/735], Loss: 0.0768\n",
      "Epoch [46/50], Step [734/735], Loss: 0.0527\n",
      "Epoch [46/50], Step [735/735], Loss: 3.3292\n",
      "Epoch [47/50], Step [1/735], Loss: 0.0701\n",
      "Epoch [47/50], Step [2/735], Loss: 0.0735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Step [3/735], Loss: 0.0393\n",
      "Epoch [47/50], Step [4/735], Loss: 0.0858\n",
      "Epoch [47/50], Step [5/735], Loss: 0.1806\n",
      "Epoch [47/50], Step [6/735], Loss: 0.0703\n",
      "Epoch [47/50], Step [7/735], Loss: 0.0749\n",
      "Epoch [47/50], Step [8/735], Loss: 0.0845\n",
      "Epoch [47/50], Step [9/735], Loss: 0.1653\n",
      "Epoch [47/50], Step [10/735], Loss: 0.0552\n",
      "Epoch [47/50], Step [11/735], Loss: 0.0775\n",
      "Epoch [47/50], Step [12/735], Loss: 0.2635\n",
      "Epoch [47/50], Step [13/735], Loss: 0.0591\n",
      "Epoch [47/50], Step [14/735], Loss: 0.1548\n",
      "Epoch [47/50], Step [15/735], Loss: 0.0849\n",
      "Epoch [47/50], Step [16/735], Loss: 0.0874\n",
      "Epoch [47/50], Step [17/735], Loss: 0.1467\n",
      "Epoch [47/50], Step [18/735], Loss: 0.1937\n",
      "Epoch [47/50], Step [19/735], Loss: 0.1439\n",
      "Epoch [47/50], Step [20/735], Loss: 0.1533\n",
      "Epoch [47/50], Step [21/735], Loss: 0.3025\n",
      "Epoch [47/50], Step [22/735], Loss: 0.0780\n",
      "Epoch [47/50], Step [23/735], Loss: 0.1026\n",
      "Epoch [47/50], Step [24/735], Loss: 0.1214\n",
      "Epoch [47/50], Step [25/735], Loss: 0.1093\n",
      "Epoch [47/50], Step [26/735], Loss: 0.1034\n",
      "Epoch [47/50], Step [27/735], Loss: 0.0548\n",
      "Epoch [47/50], Step [28/735], Loss: 0.0824\n",
      "Epoch [47/50], Step [29/735], Loss: 0.0352\n",
      "Epoch [47/50], Step [30/735], Loss: 0.1166\n",
      "Epoch [47/50], Step [31/735], Loss: 0.0844\n",
      "Epoch [47/50], Step [32/735], Loss: 0.1322\n",
      "Epoch [47/50], Step [33/735], Loss: 0.0696\n",
      "Epoch [47/50], Step [34/735], Loss: 0.0932\n",
      "Epoch [47/50], Step [35/735], Loss: 1.0106\n",
      "Epoch [47/50], Step [36/735], Loss: 0.0883\n",
      "Epoch [47/50], Step [37/735], Loss: 0.1573\n",
      "Epoch [47/50], Step [38/735], Loss: 0.0407\n",
      "Epoch [47/50], Step [39/735], Loss: 0.1403\n",
      "Epoch [47/50], Step [40/735], Loss: 0.1114\n",
      "Epoch [47/50], Step [41/735], Loss: 0.0908\n",
      "Epoch [47/50], Step [42/735], Loss: 0.3492\n",
      "Epoch [47/50], Step [43/735], Loss: 0.1326\n",
      "Epoch [47/50], Step [44/735], Loss: 0.0606\n",
      "Epoch [47/50], Step [45/735], Loss: 0.0538\n",
      "Epoch [47/50], Step [46/735], Loss: 0.3004\n",
      "Epoch [47/50], Step [47/735], Loss: 0.0993\n",
      "Epoch [47/50], Step [48/735], Loss: 0.1432\n",
      "Epoch [47/50], Step [49/735], Loss: 0.0721\n",
      "Epoch [47/50], Step [50/735], Loss: 0.0604\n",
      "Epoch [47/50], Step [51/735], Loss: 0.0298\n",
      "Epoch [47/50], Step [52/735], Loss: 0.1547\n",
      "Epoch [47/50], Step [53/735], Loss: 0.0509\n",
      "Epoch [47/50], Step [54/735], Loss: 0.0515\n",
      "Epoch [47/50], Step [55/735], Loss: 0.1763\n",
      "Epoch [47/50], Step [56/735], Loss: 0.1083\n",
      "Epoch [47/50], Step [57/735], Loss: 0.0753\n",
      "Epoch [47/50], Step [58/735], Loss: 0.0655\n",
      "Epoch [47/50], Step [59/735], Loss: 0.0774\n",
      "Epoch [47/50], Step [60/735], Loss: 0.0868\n",
      "Epoch [47/50], Step [61/735], Loss: 0.5717\n",
      "Epoch [47/50], Step [62/735], Loss: 0.1018\n",
      "Epoch [47/50], Step [63/735], Loss: 0.0909\n",
      "Epoch [47/50], Step [64/735], Loss: 0.1604\n",
      "Epoch [47/50], Step [65/735], Loss: 0.0999\n",
      "Epoch [47/50], Step [66/735], Loss: 0.1296\n",
      "Epoch [47/50], Step [67/735], Loss: 0.1072\n",
      "Epoch [47/50], Step [68/735], Loss: 0.1174\n",
      "Epoch [47/50], Step [69/735], Loss: 0.1708\n",
      "Epoch [47/50], Step [70/735], Loss: 0.4540\n",
      "Epoch [47/50], Step [71/735], Loss: 0.0903\n",
      "Epoch [47/50], Step [72/735], Loss: 0.0467\n",
      "Epoch [47/50], Step [73/735], Loss: 0.1063\n",
      "Epoch [47/50], Step [74/735], Loss: 0.1122\n",
      "Epoch [47/50], Step [75/735], Loss: 0.0227\n",
      "Epoch [47/50], Step [76/735], Loss: 0.0375\n",
      "Epoch [47/50], Step [77/735], Loss: 0.0525\n",
      "Epoch [47/50], Step [78/735], Loss: 0.1335\n",
      "Epoch [47/50], Step [79/735], Loss: 0.0762\n",
      "Epoch [47/50], Step [80/735], Loss: 0.0899\n",
      "Epoch [47/50], Step [81/735], Loss: 0.1576\n",
      "Epoch [47/50], Step [82/735], Loss: 0.0860\n",
      "Epoch [47/50], Step [83/735], Loss: 0.0466\n",
      "Epoch [47/50], Step [84/735], Loss: 0.1241\n",
      "Epoch [47/50], Step [85/735], Loss: 0.1298\n",
      "Epoch [47/50], Step [86/735], Loss: 0.0804\n",
      "Epoch [47/50], Step [87/735], Loss: 0.2067\n",
      "Epoch [47/50], Step [88/735], Loss: 0.0768\n",
      "Epoch [47/50], Step [89/735], Loss: 0.1281\n",
      "Epoch [47/50], Step [90/735], Loss: 0.1015\n",
      "Epoch [47/50], Step [91/735], Loss: 0.0831\n",
      "Epoch [47/50], Step [92/735], Loss: 0.0989\n",
      "Epoch [47/50], Step [93/735], Loss: 0.0893\n",
      "Epoch [47/50], Step [94/735], Loss: 0.1594\n",
      "Epoch [47/50], Step [95/735], Loss: 0.1336\n",
      "Epoch [47/50], Step [96/735], Loss: 0.0906\n",
      "Epoch [47/50], Step [97/735], Loss: 0.1602\n",
      "Epoch [47/50], Step [98/735], Loss: 0.1260\n",
      "Epoch [47/50], Step [99/735], Loss: 0.1844\n",
      "Epoch [47/50], Step [100/735], Loss: 0.1716\n",
      "Epoch [47/50], Step [101/735], Loss: 0.1212\n",
      "Epoch [47/50], Step [102/735], Loss: 0.0869\n",
      "Epoch [47/50], Step [103/735], Loss: 0.1485\n",
      "Epoch [47/50], Step [104/735], Loss: 1.0878\n",
      "Epoch [47/50], Step [105/735], Loss: 0.0896\n",
      "Epoch [47/50], Step [106/735], Loss: 0.0624\n",
      "Epoch [47/50], Step [107/735], Loss: 0.1767\n",
      "Epoch [47/50], Step [108/735], Loss: 0.2880\n",
      "Epoch [47/50], Step [109/735], Loss: 0.1268\n",
      "Epoch [47/50], Step [110/735], Loss: 0.0523\n",
      "Epoch [47/50], Step [111/735], Loss: 0.0811\n",
      "Epoch [47/50], Step [112/735], Loss: 0.1524\n",
      "Epoch [47/50], Step [113/735], Loss: 0.1179\n",
      "Epoch [47/50], Step [114/735], Loss: 0.2569\n",
      "Epoch [47/50], Step [115/735], Loss: 0.2324\n",
      "Epoch [47/50], Step [116/735], Loss: 0.1561\n",
      "Epoch [47/50], Step [117/735], Loss: 0.0645\n",
      "Epoch [47/50], Step [118/735], Loss: 0.1477\n",
      "Epoch [47/50], Step [119/735], Loss: 0.0637\n",
      "Epoch [47/50], Step [120/735], Loss: 0.0552\n",
      "Epoch [47/50], Step [121/735], Loss: 0.0675\n",
      "Epoch [47/50], Step [122/735], Loss: 0.2114\n",
      "Epoch [47/50], Step [123/735], Loss: 0.0530\n",
      "Epoch [47/50], Step [124/735], Loss: 0.0450\n",
      "Epoch [47/50], Step [125/735], Loss: 0.0970\n",
      "Epoch [47/50], Step [126/735], Loss: 0.0546\n",
      "Epoch [47/50], Step [127/735], Loss: 0.1048\n",
      "Epoch [47/50], Step [128/735], Loss: 0.1102\n",
      "Epoch [47/50], Step [129/735], Loss: 0.1167\n",
      "Epoch [47/50], Step [130/735], Loss: 0.1026\n",
      "Epoch [47/50], Step [131/735], Loss: 0.0271\n",
      "Epoch [47/50], Step [132/735], Loss: 0.0438\n",
      "Epoch [47/50], Step [133/735], Loss: 0.1628\n",
      "Epoch [47/50], Step [134/735], Loss: 0.1376\n",
      "Epoch [47/50], Step [135/735], Loss: 0.0522\n",
      "Epoch [47/50], Step [136/735], Loss: 0.0674\n",
      "Epoch [47/50], Step [137/735], Loss: 0.0205\n",
      "Epoch [47/50], Step [138/735], Loss: 0.0969\n",
      "Epoch [47/50], Step [139/735], Loss: 0.0627\n",
      "Epoch [47/50], Step [140/735], Loss: 0.0573\n",
      "Epoch [47/50], Step [141/735], Loss: 0.0817\n",
      "Epoch [47/50], Step [142/735], Loss: 0.0783\n",
      "Epoch [47/50], Step [143/735], Loss: 1.4081\n",
      "Epoch [47/50], Step [144/735], Loss: 0.1622\n",
      "Epoch [47/50], Step [145/735], Loss: 0.0489\n",
      "Epoch [47/50], Step [146/735], Loss: 1.6793\n",
      "Epoch [47/50], Step [147/735], Loss: 0.1686\n",
      "Epoch [47/50], Step [148/735], Loss: 0.1549\n",
      "Epoch [47/50], Step [149/735], Loss: 0.0590\n",
      "Epoch [47/50], Step [150/735], Loss: 0.0957\n",
      "Epoch [47/50], Step [151/735], Loss: 0.0283\n",
      "Epoch [47/50], Step [152/735], Loss: 0.0686\n",
      "Epoch [47/50], Step [153/735], Loss: 0.0811\n",
      "Epoch [47/50], Step [154/735], Loss: 0.0926\n",
      "Epoch [47/50], Step [155/735], Loss: 0.2693\n",
      "Epoch [47/50], Step [156/735], Loss: 0.0853\n",
      "Epoch [47/50], Step [157/735], Loss: 0.0904\n",
      "Epoch [47/50], Step [158/735], Loss: 0.1599\n",
      "Epoch [47/50], Step [159/735], Loss: 0.0355\n",
      "Epoch [47/50], Step [160/735], Loss: 0.0634\n",
      "Epoch [47/50], Step [161/735], Loss: 0.0966\n",
      "Epoch [47/50], Step [162/735], Loss: 0.1047\n",
      "Epoch [47/50], Step [163/735], Loss: 0.0949\n",
      "Epoch [47/50], Step [164/735], Loss: 0.0569\n",
      "Epoch [47/50], Step [165/735], Loss: 0.1106\n",
      "Epoch [47/50], Step [166/735], Loss: 0.0943\n",
      "Epoch [47/50], Step [167/735], Loss: 0.0819\n",
      "Epoch [47/50], Step [168/735], Loss: 0.0380\n",
      "Epoch [47/50], Step [169/735], Loss: 0.0771\n",
      "Epoch [47/50], Step [170/735], Loss: 0.1410\n",
      "Epoch [47/50], Step [171/735], Loss: 0.1202\n",
      "Epoch [47/50], Step [172/735], Loss: 0.0499\n",
      "Epoch [47/50], Step [173/735], Loss: 0.0604\n",
      "Epoch [47/50], Step [174/735], Loss: 0.0574\n",
      "Epoch [47/50], Step [175/735], Loss: 0.0968\n",
      "Epoch [47/50], Step [176/735], Loss: 0.0966\n",
      "Epoch [47/50], Step [177/735], Loss: 0.1845\n",
      "Epoch [47/50], Step [178/735], Loss: 0.1274\n",
      "Epoch [47/50], Step [179/735], Loss: 0.1271\n",
      "Epoch [47/50], Step [180/735], Loss: 0.0586\n",
      "Epoch [47/50], Step [181/735], Loss: 0.0684\n",
      "Epoch [47/50], Step [182/735], Loss: 0.0786\n",
      "Epoch [47/50], Step [183/735], Loss: 0.0332\n",
      "Epoch [47/50], Step [184/735], Loss: 0.1102\n",
      "Epoch [47/50], Step [185/735], Loss: 0.3532\n",
      "Epoch [47/50], Step [186/735], Loss: 0.1789\n",
      "Epoch [47/50], Step [187/735], Loss: 0.1301\n",
      "Epoch [47/50], Step [188/735], Loss: 0.0468\n",
      "Epoch [47/50], Step [189/735], Loss: 0.1477\n",
      "Epoch [47/50], Step [190/735], Loss: 0.1146\n",
      "Epoch [47/50], Step [191/735], Loss: 0.1329\n",
      "Epoch [47/50], Step [192/735], Loss: 0.0934\n",
      "Epoch [47/50], Step [193/735], Loss: 0.0814\n",
      "Epoch [47/50], Step [194/735], Loss: 0.1164\n",
      "Epoch [47/50], Step [195/735], Loss: 0.0930\n",
      "Epoch [47/50], Step [196/735], Loss: 0.2200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Step [197/735], Loss: 0.8709\n",
      "Epoch [47/50], Step [198/735], Loss: 0.0966\n",
      "Epoch [47/50], Step [199/735], Loss: 0.0970\n",
      "Epoch [47/50], Step [200/735], Loss: 0.0498\n",
      "Epoch [47/50], Step [201/735], Loss: 0.0722\n",
      "Epoch [47/50], Step [202/735], Loss: 0.1772\n",
      "Epoch [47/50], Step [203/735], Loss: 0.0986\n",
      "Epoch [47/50], Step [204/735], Loss: 0.0586\n",
      "Epoch [47/50], Step [205/735], Loss: 0.0848\n",
      "Epoch [47/50], Step [206/735], Loss: 0.0618\n",
      "Epoch [47/50], Step [207/735], Loss: 0.1033\n",
      "Epoch [47/50], Step [208/735], Loss: 0.1046\n",
      "Epoch [47/50], Step [209/735], Loss: 0.1192\n",
      "Epoch [47/50], Step [210/735], Loss: 0.1737\n",
      "Epoch [47/50], Step [211/735], Loss: 0.0531\n",
      "Epoch [47/50], Step [212/735], Loss: 0.1094\n",
      "Epoch [47/50], Step [213/735], Loss: 0.0805\n",
      "Epoch [47/50], Step [214/735], Loss: 0.1232\n",
      "Epoch [47/50], Step [215/735], Loss: 0.1947\n",
      "Epoch [47/50], Step [216/735], Loss: 0.0619\n",
      "Epoch [47/50], Step [217/735], Loss: 0.0311\n",
      "Epoch [47/50], Step [218/735], Loss: 1.5330\n",
      "Epoch [47/50], Step [219/735], Loss: 0.0466\n",
      "Epoch [47/50], Step [220/735], Loss: 0.3909\n",
      "Epoch [47/50], Step [221/735], Loss: 0.0940\n",
      "Epoch [47/50], Step [222/735], Loss: 0.1305\n",
      "Epoch [47/50], Step [223/735], Loss: 0.1464\n",
      "Epoch [47/50], Step [224/735], Loss: 0.0838\n",
      "Epoch [47/50], Step [225/735], Loss: 0.0636\n",
      "Epoch [47/50], Step [226/735], Loss: 0.1229\n",
      "Epoch [47/50], Step [227/735], Loss: 0.1313\n",
      "Epoch [47/50], Step [228/735], Loss: 0.1259\n",
      "Epoch [47/50], Step [229/735], Loss: 0.0407\n",
      "Epoch [47/50], Step [230/735], Loss: 0.0965\n",
      "Epoch [47/50], Step [231/735], Loss: 0.1390\n",
      "Epoch [47/50], Step [232/735], Loss: 0.0596\n",
      "Epoch [47/50], Step [233/735], Loss: 0.0598\n",
      "Epoch [47/50], Step [234/735], Loss: 0.0935\n",
      "Epoch [47/50], Step [235/735], Loss: 0.0783\n",
      "Epoch [47/50], Step [236/735], Loss: 0.0402\n",
      "Epoch [47/50], Step [237/735], Loss: 0.1029\n",
      "Epoch [47/50], Step [238/735], Loss: 0.1301\n",
      "Epoch [47/50], Step [239/735], Loss: 1.2303\n",
      "Epoch [47/50], Step [240/735], Loss: 0.3428\n",
      "Epoch [47/50], Step [241/735], Loss: 0.1217\n",
      "Epoch [47/50], Step [242/735], Loss: 0.1796\n",
      "Epoch [47/50], Step [243/735], Loss: 0.0855\n",
      "Epoch [47/50], Step [244/735], Loss: 1.0565\n",
      "Epoch [47/50], Step [245/735], Loss: 0.1263\n",
      "Epoch [47/50], Step [246/735], Loss: 0.0710\n",
      "Epoch [47/50], Step [247/735], Loss: 0.2183\n",
      "Epoch [47/50], Step [248/735], Loss: 0.0390\n",
      "Epoch [47/50], Step [249/735], Loss: 0.0798\n",
      "Epoch [47/50], Step [250/735], Loss: 0.6014\n",
      "Epoch [47/50], Step [251/735], Loss: 0.1261\n",
      "Epoch [47/50], Step [252/735], Loss: 0.0423\n",
      "Epoch [47/50], Step [253/735], Loss: 0.0415\n",
      "Epoch [47/50], Step [254/735], Loss: 0.0723\n",
      "Epoch [47/50], Step [255/735], Loss: 0.1202\n",
      "Epoch [47/50], Step [256/735], Loss: 0.0717\n",
      "Epoch [47/50], Step [257/735], Loss: 0.0474\n",
      "Epoch [47/50], Step [258/735], Loss: 0.1425\n",
      "Epoch [47/50], Step [259/735], Loss: 0.0525\n",
      "Epoch [47/50], Step [260/735], Loss: 0.1748\n",
      "Epoch [47/50], Step [261/735], Loss: 0.0455\n",
      "Epoch [47/50], Step [262/735], Loss: 0.2447\n",
      "Epoch [47/50], Step [263/735], Loss: 0.0261\n",
      "Epoch [47/50], Step [264/735], Loss: 0.0556\n",
      "Epoch [47/50], Step [265/735], Loss: 0.0577\n",
      "Epoch [47/50], Step [266/735], Loss: 0.3067\n",
      "Epoch [47/50], Step [267/735], Loss: 0.0744\n",
      "Epoch [47/50], Step [268/735], Loss: 0.2452\n",
      "Epoch [47/50], Step [269/735], Loss: 0.0599\n",
      "Epoch [47/50], Step [270/735], Loss: 0.1487\n",
      "Epoch [47/50], Step [271/735], Loss: 0.0879\n",
      "Epoch [47/50], Step [272/735], Loss: 0.0449\n",
      "Epoch [47/50], Step [273/735], Loss: 0.1009\n",
      "Epoch [47/50], Step [274/735], Loss: 0.0900\n",
      "Epoch [47/50], Step [275/735], Loss: 0.1895\n",
      "Epoch [47/50], Step [276/735], Loss: 0.1147\n",
      "Epoch [47/50], Step [277/735], Loss: 0.0982\n",
      "Epoch [47/50], Step [278/735], Loss: 0.0652\n",
      "Epoch [47/50], Step [279/735], Loss: 0.0536\n",
      "Epoch [47/50], Step [280/735], Loss: 0.1511\n",
      "Epoch [47/50], Step [281/735], Loss: 0.1192\n",
      "Epoch [47/50], Step [282/735], Loss: 0.0378\n",
      "Epoch [47/50], Step [283/735], Loss: 0.0341\n",
      "Epoch [47/50], Step [284/735], Loss: 0.0446\n",
      "Epoch [47/50], Step [285/735], Loss: 1.6139\n",
      "Epoch [47/50], Step [286/735], Loss: 0.2297\n",
      "Epoch [47/50], Step [287/735], Loss: 0.0900\n",
      "Epoch [47/50], Step [288/735], Loss: 0.0403\n",
      "Epoch [47/50], Step [289/735], Loss: 0.0624\n",
      "Epoch [47/50], Step [290/735], Loss: 0.1867\n",
      "Epoch [47/50], Step [291/735], Loss: 0.1121\n",
      "Epoch [47/50], Step [292/735], Loss: 0.0877\n",
      "Epoch [47/50], Step [293/735], Loss: 0.1252\n",
      "Epoch [47/50], Step [294/735], Loss: 0.0493\n",
      "Epoch [47/50], Step [295/735], Loss: 0.0662\n",
      "Epoch [47/50], Step [296/735], Loss: 0.0502\n",
      "Epoch [47/50], Step [297/735], Loss: 0.0500\n",
      "Epoch [47/50], Step [298/735], Loss: 0.0393\n",
      "Epoch [47/50], Step [299/735], Loss: 0.0509\n",
      "Epoch [47/50], Step [300/735], Loss: 0.0467\n",
      "Epoch [47/50], Step [301/735], Loss: 0.0278\n",
      "Epoch [47/50], Step [302/735], Loss: 0.0805\n",
      "Epoch [47/50], Step [303/735], Loss: 0.1048\n",
      "Epoch [47/50], Step [304/735], Loss: 0.0596\n",
      "Epoch [47/50], Step [305/735], Loss: 0.1738\n",
      "Epoch [47/50], Step [306/735], Loss: 0.1018\n",
      "Epoch [47/50], Step [307/735], Loss: 0.0256\n",
      "Epoch [47/50], Step [308/735], Loss: 0.1140\n",
      "Epoch [47/50], Step [309/735], Loss: 0.0758\n",
      "Epoch [47/50], Step [310/735], Loss: 0.0907\n",
      "Epoch [47/50], Step [311/735], Loss: 0.0479\n",
      "Epoch [47/50], Step [312/735], Loss: 0.1039\n",
      "Epoch [47/50], Step [313/735], Loss: 0.0552\n",
      "Epoch [47/50], Step [314/735], Loss: 0.0926\n",
      "Epoch [47/50], Step [315/735], Loss: 0.1435\n",
      "Epoch [47/50], Step [316/735], Loss: 0.0940\n",
      "Epoch [47/50], Step [317/735], Loss: 0.0438\n",
      "Epoch [47/50], Step [318/735], Loss: 0.0686\n",
      "Epoch [47/50], Step [319/735], Loss: 0.1741\n",
      "Epoch [47/50], Step [320/735], Loss: 0.0594\n",
      "Epoch [47/50], Step [321/735], Loss: 0.1073\n",
      "Epoch [47/50], Step [322/735], Loss: 0.0629\n",
      "Epoch [47/50], Step [323/735], Loss: 0.1969\n",
      "Epoch [47/50], Step [324/735], Loss: 0.0836\n",
      "Epoch [47/50], Step [325/735], Loss: 0.1521\n",
      "Epoch [47/50], Step [326/735], Loss: 0.0277\n",
      "Epoch [47/50], Step [327/735], Loss: 1.0753\n",
      "Epoch [47/50], Step [328/735], Loss: 0.0941\n",
      "Epoch [47/50], Step [329/735], Loss: 0.0480\n",
      "Epoch [47/50], Step [330/735], Loss: 0.0579\n",
      "Epoch [47/50], Step [331/735], Loss: 0.0981\n",
      "Epoch [47/50], Step [332/735], Loss: 0.2040\n",
      "Epoch [47/50], Step [333/735], Loss: 0.0278\n",
      "Epoch [47/50], Step [334/735], Loss: 0.9052\n",
      "Epoch [47/50], Step [335/735], Loss: 0.0914\n",
      "Epoch [47/50], Step [336/735], Loss: 0.0477\n",
      "Epoch [47/50], Step [337/735], Loss: 0.1097\n",
      "Epoch [47/50], Step [338/735], Loss: 0.0964\n",
      "Epoch [47/50], Step [339/735], Loss: 0.0592\n",
      "Epoch [47/50], Step [340/735], Loss: 0.0675\n",
      "Epoch [47/50], Step [341/735], Loss: 0.0828\n",
      "Epoch [47/50], Step [342/735], Loss: 0.0657\n",
      "Epoch [47/50], Step [343/735], Loss: 0.0448\n",
      "Epoch [47/50], Step [344/735], Loss: 0.0854\n",
      "Epoch [47/50], Step [345/735], Loss: 0.0967\n",
      "Epoch [47/50], Step [346/735], Loss: 0.2144\n",
      "Epoch [47/50], Step [347/735], Loss: 0.0718\n",
      "Epoch [47/50], Step [348/735], Loss: 0.3274\n",
      "Epoch [47/50], Step [349/735], Loss: 0.0783\n",
      "Epoch [47/50], Step [350/735], Loss: 0.1006\n",
      "Epoch [47/50], Step [351/735], Loss: 0.0892\n",
      "Epoch [47/50], Step [352/735], Loss: 0.1859\n",
      "Epoch [47/50], Step [353/735], Loss: 0.0487\n",
      "Epoch [47/50], Step [354/735], Loss: 0.0838\n",
      "Epoch [47/50], Step [355/735], Loss: 0.1240\n",
      "Epoch [47/50], Step [356/735], Loss: 0.1067\n",
      "Epoch [47/50], Step [357/735], Loss: 0.0305\n",
      "Epoch [47/50], Step [358/735], Loss: 0.0426\n",
      "Epoch [47/50], Step [359/735], Loss: 0.1412\n",
      "Epoch [47/50], Step [360/735], Loss: 0.0630\n",
      "Epoch [47/50], Step [361/735], Loss: 0.0482\n",
      "Epoch [47/50], Step [362/735], Loss: 0.0890\n",
      "Epoch [47/50], Step [363/735], Loss: 0.1049\n",
      "Epoch [47/50], Step [364/735], Loss: 0.0810\n",
      "Epoch [47/50], Step [365/735], Loss: 0.0731\n",
      "Epoch [47/50], Step [366/735], Loss: 0.3629\n",
      "Epoch [47/50], Step [367/735], Loss: 0.1274\n",
      "Epoch [47/50], Step [368/735], Loss: 0.0932\n",
      "Epoch [47/50], Step [369/735], Loss: 0.0849\n",
      "Epoch [47/50], Step [370/735], Loss: 0.1139\n",
      "Epoch [47/50], Step [371/735], Loss: 0.0770\n",
      "Epoch [47/50], Step [372/735], Loss: 0.1639\n",
      "Epoch [47/50], Step [373/735], Loss: 0.1030\n",
      "Epoch [47/50], Step [374/735], Loss: 0.0529\n",
      "Epoch [47/50], Step [375/735], Loss: 0.0494\n",
      "Epoch [47/50], Step [376/735], Loss: 0.1206\n",
      "Epoch [47/50], Step [377/735], Loss: 0.0440\n",
      "Epoch [47/50], Step [378/735], Loss: 0.1426\n",
      "Epoch [47/50], Step [379/735], Loss: 0.1056\n",
      "Epoch [47/50], Step [380/735], Loss: 0.0812\n",
      "Epoch [47/50], Step [381/735], Loss: 0.1101\n",
      "Epoch [47/50], Step [382/735], Loss: 0.0521\n",
      "Epoch [47/50], Step [383/735], Loss: 0.1259\n",
      "Epoch [47/50], Step [384/735], Loss: 0.0455\n",
      "Epoch [47/50], Step [385/735], Loss: 0.0672\n",
      "Epoch [47/50], Step [386/735], Loss: 0.0897\n",
      "Epoch [47/50], Step [387/735], Loss: 0.0989\n",
      "Epoch [47/50], Step [388/735], Loss: 0.0778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Step [389/735], Loss: 0.1284\n",
      "Epoch [47/50], Step [390/735], Loss: 0.0755\n",
      "Epoch [47/50], Step [391/735], Loss: 0.0786\n",
      "Epoch [47/50], Step [392/735], Loss: 0.0802\n",
      "Epoch [47/50], Step [393/735], Loss: 0.0360\n",
      "Epoch [47/50], Step [394/735], Loss: 0.0647\n",
      "Epoch [47/50], Step [395/735], Loss: 0.0563\n",
      "Epoch [47/50], Step [396/735], Loss: 0.3090\n",
      "Epoch [47/50], Step [397/735], Loss: 0.1143\n",
      "Epoch [47/50], Step [398/735], Loss: 0.0580\n",
      "Epoch [47/50], Step [399/735], Loss: 0.0898\n",
      "Epoch [47/50], Step [400/735], Loss: 0.3628\n",
      "Epoch [47/50], Step [401/735], Loss: 0.0983\n",
      "Epoch [47/50], Step [402/735], Loss: 0.0832\n",
      "Epoch [47/50], Step [403/735], Loss: 0.1361\n",
      "Epoch [47/50], Step [404/735], Loss: 0.0673\n",
      "Epoch [47/50], Step [405/735], Loss: 0.0442\n",
      "Epoch [47/50], Step [406/735], Loss: 0.3242\n",
      "Epoch [47/50], Step [407/735], Loss: 1.5302\n",
      "Epoch [47/50], Step [408/735], Loss: 0.1240\n",
      "Epoch [47/50], Step [409/735], Loss: 0.0921\n",
      "Epoch [47/50], Step [410/735], Loss: 0.0378\n",
      "Epoch [47/50], Step [411/735], Loss: 0.0568\n",
      "Epoch [47/50], Step [412/735], Loss: 0.1296\n",
      "Epoch [47/50], Step [413/735], Loss: 0.0596\n",
      "Epoch [47/50], Step [414/735], Loss: 0.1142\n",
      "Epoch [47/50], Step [415/735], Loss: 0.1074\n",
      "Epoch [47/50], Step [416/735], Loss: 0.1557\n",
      "Epoch [47/50], Step [417/735], Loss: 0.0984\n",
      "Epoch [47/50], Step [418/735], Loss: 0.0997\n",
      "Epoch [47/50], Step [419/735], Loss: 0.0739\n",
      "Epoch [47/50], Step [420/735], Loss: 0.2159\n",
      "Epoch [47/50], Step [421/735], Loss: 0.1238\n",
      "Epoch [47/50], Step [422/735], Loss: 0.1092\n",
      "Epoch [47/50], Step [423/735], Loss: 0.1389\n",
      "Epoch [47/50], Step [424/735], Loss: 0.1301\n",
      "Epoch [47/50], Step [425/735], Loss: 0.0863\n",
      "Epoch [47/50], Step [426/735], Loss: 0.1652\n",
      "Epoch [47/50], Step [427/735], Loss: 0.1214\n",
      "Epoch [47/50], Step [428/735], Loss: 0.1071\n",
      "Epoch [47/50], Step [429/735], Loss: 0.1220\n",
      "Epoch [47/50], Step [430/735], Loss: 0.1188\n",
      "Epoch [47/50], Step [431/735], Loss: 0.1354\n",
      "Epoch [47/50], Step [432/735], Loss: 0.0880\n",
      "Epoch [47/50], Step [433/735], Loss: 0.0767\n",
      "Epoch [47/50], Step [434/735], Loss: 0.0906\n",
      "Epoch [47/50], Step [435/735], Loss: 0.2066\n",
      "Epoch [47/50], Step [436/735], Loss: 0.1143\n",
      "Epoch [47/50], Step [437/735], Loss: 0.1085\n",
      "Epoch [47/50], Step [438/735], Loss: 0.1109\n",
      "Epoch [47/50], Step [439/735], Loss: 0.0617\n",
      "Epoch [47/50], Step [440/735], Loss: 0.0812\n",
      "Epoch [47/50], Step [441/735], Loss: 0.0793\n",
      "Epoch [47/50], Step [442/735], Loss: 0.0741\n",
      "Epoch [47/50], Step [443/735], Loss: 0.5387\n",
      "Epoch [47/50], Step [444/735], Loss: 0.2434\n",
      "Epoch [47/50], Step [445/735], Loss: 0.0654\n",
      "Epoch [47/50], Step [446/735], Loss: 0.0900\n",
      "Epoch [47/50], Step [447/735], Loss: 0.6823\n",
      "Epoch [47/50], Step [448/735], Loss: 0.0948\n",
      "Epoch [47/50], Step [449/735], Loss: 0.2271\n",
      "Epoch [47/50], Step [450/735], Loss: 0.0647\n",
      "Epoch [47/50], Step [451/735], Loss: 0.1063\n",
      "Epoch [47/50], Step [452/735], Loss: 0.1114\n",
      "Epoch [47/50], Step [453/735], Loss: 0.1169\n",
      "Epoch [47/50], Step [454/735], Loss: 0.0581\n",
      "Epoch [47/50], Step [455/735], Loss: 0.0461\n",
      "Epoch [47/50], Step [456/735], Loss: 0.1207\n",
      "Epoch [47/50], Step [457/735], Loss: 0.1017\n",
      "Epoch [47/50], Step [458/735], Loss: 0.0774\n",
      "Epoch [47/50], Step [459/735], Loss: 0.0566\n",
      "Epoch [47/50], Step [460/735], Loss: 0.0494\n",
      "Epoch [47/50], Step [461/735], Loss: 0.1525\n",
      "Epoch [47/50], Step [462/735], Loss: 0.5340\n",
      "Epoch [47/50], Step [463/735], Loss: 0.1387\n",
      "Epoch [47/50], Step [464/735], Loss: 0.0764\n",
      "Epoch [47/50], Step [465/735], Loss: 0.0714\n",
      "Epoch [47/50], Step [466/735], Loss: 0.2148\n",
      "Epoch [47/50], Step [467/735], Loss: 0.0412\n",
      "Epoch [47/50], Step [468/735], Loss: 0.2126\n",
      "Epoch [47/50], Step [469/735], Loss: 0.1595\n",
      "Epoch [47/50], Step [470/735], Loss: 0.1070\n",
      "Epoch [47/50], Step [471/735], Loss: 0.0412\n",
      "Epoch [47/50], Step [472/735], Loss: 0.1005\n",
      "Epoch [47/50], Step [473/735], Loss: 0.0500\n",
      "Epoch [47/50], Step [474/735], Loss: 0.0666\n",
      "Epoch [47/50], Step [475/735], Loss: 0.0744\n",
      "Epoch [47/50], Step [476/735], Loss: 0.0424\n",
      "Epoch [47/50], Step [477/735], Loss: 0.1473\n",
      "Epoch [47/50], Step [478/735], Loss: 0.0249\n",
      "Epoch [47/50], Step [479/735], Loss: 0.0729\n",
      "Epoch [47/50], Step [480/735], Loss: 0.0750\n",
      "Epoch [47/50], Step [481/735], Loss: 0.1459\n",
      "Epoch [47/50], Step [482/735], Loss: 0.0511\n",
      "Epoch [47/50], Step [483/735], Loss: 0.0386\n",
      "Epoch [47/50], Step [484/735], Loss: 0.1650\n",
      "Epoch [47/50], Step [485/735], Loss: 0.3260\n",
      "Epoch [47/50], Step [486/735], Loss: 0.2197\n",
      "Epoch [47/50], Step [487/735], Loss: 0.0962\n",
      "Epoch [47/50], Step [488/735], Loss: 0.4098\n",
      "Epoch [47/50], Step [489/735], Loss: 0.1218\n",
      "Epoch [47/50], Step [490/735], Loss: 0.3594\n",
      "Epoch [47/50], Step [491/735], Loss: 0.0392\n",
      "Epoch [47/50], Step [492/735], Loss: 0.1672\n",
      "Epoch [47/50], Step [493/735], Loss: 0.0997\n",
      "Epoch [47/50], Step [494/735], Loss: 0.0636\n",
      "Epoch [47/50], Step [495/735], Loss: 0.0626\n",
      "Epoch [47/50], Step [496/735], Loss: 0.0940\n",
      "Epoch [47/50], Step [497/735], Loss: 0.1026\n",
      "Epoch [47/50], Step [498/735], Loss: 0.2310\n",
      "Epoch [47/50], Step [499/735], Loss: 0.1083\n",
      "Epoch [47/50], Step [500/735], Loss: 0.1174\n",
      "Epoch [47/50], Step [501/735], Loss: 0.1483\n",
      "Epoch [47/50], Step [502/735], Loss: 0.0706\n",
      "Epoch [47/50], Step [503/735], Loss: 0.0707\n",
      "Epoch [47/50], Step [504/735], Loss: 0.0297\n",
      "Epoch [47/50], Step [505/735], Loss: 0.1153\n",
      "Epoch [47/50], Step [506/735], Loss: 1.4191\n",
      "Epoch [47/50], Step [507/735], Loss: 0.1239\n",
      "Epoch [47/50], Step [508/735], Loss: 0.0528\n",
      "Epoch [47/50], Step [509/735], Loss: 0.1683\n",
      "Epoch [47/50], Step [510/735], Loss: 0.4393\n",
      "Epoch [47/50], Step [511/735], Loss: 0.0533\n",
      "Epoch [47/50], Step [512/735], Loss: 0.0457\n",
      "Epoch [47/50], Step [513/735], Loss: 0.0721\n",
      "Epoch [47/50], Step [514/735], Loss: 0.0864\n",
      "Epoch [47/50], Step [515/735], Loss: 0.1006\n",
      "Epoch [47/50], Step [516/735], Loss: 0.0684\n",
      "Epoch [47/50], Step [517/735], Loss: 0.0931\n",
      "Epoch [47/50], Step [518/735], Loss: 0.0712\n",
      "Epoch [47/50], Step [519/735], Loss: 0.0958\n",
      "Epoch [47/50], Step [520/735], Loss: 0.0362\n",
      "Epoch [47/50], Step [521/735], Loss: 0.1490\n",
      "Epoch [47/50], Step [522/735], Loss: 0.0383\n",
      "Epoch [47/50], Step [523/735], Loss: 0.0985\n",
      "Epoch [47/50], Step [524/735], Loss: 0.1248\n",
      "Epoch [47/50], Step [525/735], Loss: 0.0703\n",
      "Epoch [47/50], Step [526/735], Loss: 0.1482\n",
      "Epoch [47/50], Step [527/735], Loss: 0.1477\n",
      "Epoch [47/50], Step [528/735], Loss: 0.1584\n",
      "Epoch [47/50], Step [529/735], Loss: 0.0658\n",
      "Epoch [47/50], Step [530/735], Loss: 0.0622\n",
      "Epoch [47/50], Step [531/735], Loss: 0.1559\n",
      "Epoch [47/50], Step [532/735], Loss: 0.1200\n",
      "Epoch [47/50], Step [533/735], Loss: 0.0708\n",
      "Epoch [47/50], Step [534/735], Loss: 0.0893\n",
      "Epoch [47/50], Step [535/735], Loss: 0.1466\n",
      "Epoch [47/50], Step [536/735], Loss: 0.1438\n",
      "Epoch [47/50], Step [537/735], Loss: 0.0527\n",
      "Epoch [47/50], Step [538/735], Loss: 0.1212\n",
      "Epoch [47/50], Step [539/735], Loss: 0.1020\n",
      "Epoch [47/50], Step [540/735], Loss: 0.2845\n",
      "Epoch [47/50], Step [541/735], Loss: 0.0719\n",
      "Epoch [47/50], Step [542/735], Loss: 0.1106\n",
      "Epoch [47/50], Step [543/735], Loss: 0.0704\n",
      "Epoch [47/50], Step [544/735], Loss: 0.1429\n",
      "Epoch [47/50], Step [545/735], Loss: 0.1039\n",
      "Epoch [47/50], Step [546/735], Loss: 0.0794\n",
      "Epoch [47/50], Step [547/735], Loss: 0.1757\n",
      "Epoch [47/50], Step [548/735], Loss: 0.0970\n",
      "Epoch [47/50], Step [549/735], Loss: 0.0863\n",
      "Epoch [47/50], Step [550/735], Loss: 0.1225\n",
      "Epoch [47/50], Step [551/735], Loss: 0.0585\n",
      "Epoch [47/50], Step [552/735], Loss: 0.0460\n",
      "Epoch [47/50], Step [553/735], Loss: 0.0587\n",
      "Epoch [47/50], Step [554/735], Loss: 0.1946\n",
      "Epoch [47/50], Step [555/735], Loss: 0.1190\n",
      "Epoch [47/50], Step [556/735], Loss: 0.0840\n",
      "Epoch [47/50], Step [557/735], Loss: 0.1407\n",
      "Epoch [47/50], Step [558/735], Loss: 0.0635\n",
      "Epoch [47/50], Step [559/735], Loss: 0.1303\n",
      "Epoch [47/50], Step [560/735], Loss: 0.0628\n",
      "Epoch [47/50], Step [561/735], Loss: 0.0882\n",
      "Epoch [47/50], Step [562/735], Loss: 0.0515\n",
      "Epoch [47/50], Step [563/735], Loss: 0.1011\n",
      "Epoch [47/50], Step [564/735], Loss: 0.0652\n",
      "Epoch [47/50], Step [565/735], Loss: 0.0644\n",
      "Epoch [47/50], Step [566/735], Loss: 0.0878\n",
      "Epoch [47/50], Step [567/735], Loss: 0.1274\n",
      "Epoch [47/50], Step [568/735], Loss: 0.0476\n",
      "Epoch [47/50], Step [569/735], Loss: 0.3634\n",
      "Epoch [47/50], Step [570/735], Loss: 0.0659\n",
      "Epoch [47/50], Step [571/735], Loss: 0.1578\n",
      "Epoch [47/50], Step [572/735], Loss: 0.1387\n",
      "Epoch [47/50], Step [573/735], Loss: 0.1163\n",
      "Epoch [47/50], Step [574/735], Loss: 0.0496\n",
      "Epoch [47/50], Step [575/735], Loss: 0.0493\n",
      "Epoch [47/50], Step [576/735], Loss: 0.1548\n",
      "Epoch [47/50], Step [577/735], Loss: 0.1612\n",
      "Epoch [47/50], Step [578/735], Loss: 0.1057\n",
      "Epoch [47/50], Step [579/735], Loss: 0.0718\n",
      "Epoch [47/50], Step [580/735], Loss: 0.0754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Step [581/735], Loss: 0.0889\n",
      "Epoch [47/50], Step [582/735], Loss: 0.2426\n",
      "Epoch [47/50], Step [583/735], Loss: 0.0544\n",
      "Epoch [47/50], Step [584/735], Loss: 0.0421\n",
      "Epoch [47/50], Step [585/735], Loss: 0.0847\n",
      "Epoch [47/50], Step [586/735], Loss: 0.0750\n",
      "Epoch [47/50], Step [587/735], Loss: 0.1230\n",
      "Epoch [47/50], Step [588/735], Loss: 0.1205\n",
      "Epoch [47/50], Step [589/735], Loss: 0.0527\n",
      "Epoch [47/50], Step [590/735], Loss: 0.1091\n",
      "Epoch [47/50], Step [591/735], Loss: 0.0934\n",
      "Epoch [47/50], Step [592/735], Loss: 0.0978\n",
      "Epoch [47/50], Step [593/735], Loss: 0.1212\n",
      "Epoch [47/50], Step [594/735], Loss: 0.2103\n",
      "Epoch [47/50], Step [595/735], Loss: 0.0477\n",
      "Epoch [47/50], Step [596/735], Loss: 0.0595\n",
      "Epoch [47/50], Step [597/735], Loss: 0.0466\n",
      "Epoch [47/50], Step [598/735], Loss: 0.1026\n",
      "Epoch [47/50], Step [599/735], Loss: 0.0562\n",
      "Epoch [47/50], Step [600/735], Loss: 0.0495\n",
      "Epoch [47/50], Step [601/735], Loss: 0.8924\n",
      "Epoch [47/50], Step [602/735], Loss: 1.6433\n",
      "Epoch [47/50], Step [603/735], Loss: 0.0803\n",
      "Epoch [47/50], Step [604/735], Loss: 0.0928\n",
      "Epoch [47/50], Step [605/735], Loss: 0.0792\n",
      "Epoch [47/50], Step [606/735], Loss: 0.0831\n",
      "Epoch [47/50], Step [607/735], Loss: 0.0852\n",
      "Epoch [47/50], Step [608/735], Loss: 0.0439\n",
      "Epoch [47/50], Step [609/735], Loss: 0.0527\n",
      "Epoch [47/50], Step [610/735], Loss: 0.0963\n",
      "Epoch [47/50], Step [611/735], Loss: 0.0632\n",
      "Epoch [47/50], Step [612/735], Loss: 0.1036\n",
      "Epoch [47/50], Step [613/735], Loss: 0.0520\n",
      "Epoch [47/50], Step [614/735], Loss: 0.1452\n",
      "Epoch [47/50], Step [615/735], Loss: 0.0731\n",
      "Epoch [47/50], Step [616/735], Loss: 0.0494\n",
      "Epoch [47/50], Step [617/735], Loss: 0.0740\n",
      "Epoch [47/50], Step [618/735], Loss: 0.1018\n",
      "Epoch [47/50], Step [619/735], Loss: 0.0526\n",
      "Epoch [47/50], Step [620/735], Loss: 0.0598\n",
      "Epoch [47/50], Step [621/735], Loss: 0.0897\n",
      "Epoch [47/50], Step [622/735], Loss: 0.0516\n",
      "Epoch [47/50], Step [623/735], Loss: 0.0881\n",
      "Epoch [47/50], Step [624/735], Loss: 0.0921\n",
      "Epoch [47/50], Step [625/735], Loss: 0.0667\n",
      "Epoch [47/50], Step [626/735], Loss: 0.0987\n",
      "Epoch [47/50], Step [627/735], Loss: 0.0481\n",
      "Epoch [47/50], Step [628/735], Loss: 0.2930\n",
      "Epoch [47/50], Step [629/735], Loss: 0.0865\n",
      "Epoch [47/50], Step [630/735], Loss: 0.1381\n",
      "Epoch [47/50], Step [631/735], Loss: 0.0654\n",
      "Epoch [47/50], Step [632/735], Loss: 0.0472\n",
      "Epoch [47/50], Step [633/735], Loss: 0.1712\n",
      "Epoch [47/50], Step [634/735], Loss: 0.1421\n",
      "Epoch [47/50], Step [635/735], Loss: 0.1040\n",
      "Epoch [47/50], Step [636/735], Loss: 0.1441\n",
      "Epoch [47/50], Step [637/735], Loss: 0.0958\n",
      "Epoch [47/50], Step [638/735], Loss: 0.4732\n",
      "Epoch [47/50], Step [639/735], Loss: 0.1310\n",
      "Epoch [47/50], Step [640/735], Loss: 0.0752\n",
      "Epoch [47/50], Step [641/735], Loss: 0.1249\n",
      "Epoch [47/50], Step [642/735], Loss: 0.0876\n",
      "Epoch [47/50], Step [643/735], Loss: 0.1694\n",
      "Epoch [47/50], Step [644/735], Loss: 0.0853\n",
      "Epoch [47/50], Step [645/735], Loss: 0.1030\n",
      "Epoch [47/50], Step [646/735], Loss: 0.0937\n",
      "Epoch [47/50], Step [647/735], Loss: 0.0808\n",
      "Epoch [47/50], Step [648/735], Loss: 0.0799\n",
      "Epoch [47/50], Step [649/735], Loss: 0.1799\n",
      "Epoch [47/50], Step [650/735], Loss: 0.0433\n",
      "Epoch [47/50], Step [651/735], Loss: 0.0437\n",
      "Epoch [47/50], Step [652/735], Loss: 0.1554\n",
      "Epoch [47/50], Step [653/735], Loss: 0.1431\n",
      "Epoch [47/50], Step [654/735], Loss: 0.0548\n",
      "Epoch [47/50], Step [655/735], Loss: 0.1171\n",
      "Epoch [47/50], Step [656/735], Loss: 0.0364\n",
      "Epoch [47/50], Step [657/735], Loss: 0.4722\n",
      "Epoch [47/50], Step [658/735], Loss: 0.0860\n",
      "Epoch [47/50], Step [659/735], Loss: 0.3411\n",
      "Epoch [47/50], Step [660/735], Loss: 0.0873\n",
      "Epoch [47/50], Step [661/735], Loss: 0.9154\n",
      "Epoch [47/50], Step [662/735], Loss: 0.0446\n",
      "Epoch [47/50], Step [663/735], Loss: 0.0516\n",
      "Epoch [47/50], Step [664/735], Loss: 0.0540\n",
      "Epoch [47/50], Step [665/735], Loss: 0.0329\n",
      "Epoch [47/50], Step [666/735], Loss: 0.0811\n",
      "Epoch [47/50], Step [667/735], Loss: 0.3547\n",
      "Epoch [47/50], Step [668/735], Loss: 0.0701\n",
      "Epoch [47/50], Step [669/735], Loss: 0.2087\n",
      "Epoch [47/50], Step [670/735], Loss: 0.0768\n",
      "Epoch [47/50], Step [671/735], Loss: 0.0544\n",
      "Epoch [47/50], Step [672/735], Loss: 0.0481\n",
      "Epoch [47/50], Step [673/735], Loss: 0.0804\n",
      "Epoch [47/50], Step [674/735], Loss: 0.0559\n",
      "Epoch [47/50], Step [675/735], Loss: 0.1337\n",
      "Epoch [47/50], Step [676/735], Loss: 0.1686\n",
      "Epoch [47/50], Step [677/735], Loss: 0.3889\n",
      "Epoch [47/50], Step [678/735], Loss: 0.0610\n",
      "Epoch [47/50], Step [679/735], Loss: 0.1579\n",
      "Epoch [47/50], Step [680/735], Loss: 0.0576\n",
      "Epoch [47/50], Step [681/735], Loss: 0.0547\n",
      "Epoch [47/50], Step [682/735], Loss: 0.0699\n",
      "Epoch [47/50], Step [683/735], Loss: 0.0798\n",
      "Epoch [47/50], Step [684/735], Loss: 0.0768\n",
      "Epoch [47/50], Step [685/735], Loss: 0.1817\n",
      "Epoch [47/50], Step [686/735], Loss: 0.0939\n",
      "Epoch [47/50], Step [687/735], Loss: 0.1005\n",
      "Epoch [47/50], Step [688/735], Loss: 0.1187\n",
      "Epoch [47/50], Step [689/735], Loss: 0.1544\n",
      "Epoch [47/50], Step [690/735], Loss: 0.1426\n",
      "Epoch [47/50], Step [691/735], Loss: 0.1381\n",
      "Epoch [47/50], Step [692/735], Loss: 0.0885\n",
      "Epoch [47/50], Step [693/735], Loss: 0.1105\n",
      "Epoch [47/50], Step [694/735], Loss: 0.0713\n",
      "Epoch [47/50], Step [695/735], Loss: 0.1025\n",
      "Epoch [47/50], Step [696/735], Loss: 0.1227\n",
      "Epoch [47/50], Step [697/735], Loss: 0.2921\n",
      "Epoch [47/50], Step [698/735], Loss: 0.2571\n",
      "Epoch [47/50], Step [699/735], Loss: 0.3226\n",
      "Epoch [47/50], Step [700/735], Loss: 0.0832\n",
      "Epoch [47/50], Step [701/735], Loss: 0.0839\n",
      "Epoch [47/50], Step [702/735], Loss: 0.0764\n",
      "Epoch [47/50], Step [703/735], Loss: 0.0541\n",
      "Epoch [47/50], Step [704/735], Loss: 0.1113\n",
      "Epoch [47/50], Step [705/735], Loss: 0.0784\n",
      "Epoch [47/50], Step [706/735], Loss: 0.0844\n",
      "Epoch [47/50], Step [707/735], Loss: 0.0399\n",
      "Epoch [47/50], Step [708/735], Loss: 0.0308\n",
      "Epoch [47/50], Step [709/735], Loss: 0.0902\n",
      "Epoch [47/50], Step [710/735], Loss: 0.2395\n",
      "Epoch [47/50], Step [711/735], Loss: 0.0636\n",
      "Epoch [47/50], Step [712/735], Loss: 0.0716\n",
      "Epoch [47/50], Step [713/735], Loss: 0.0982\n",
      "Epoch [47/50], Step [714/735], Loss: 0.0636\n",
      "Epoch [47/50], Step [715/735], Loss: 0.0729\n",
      "Epoch [47/50], Step [716/735], Loss: 0.0854\n",
      "Epoch [47/50], Step [717/735], Loss: 0.1347\n",
      "Epoch [47/50], Step [718/735], Loss: 0.1182\n",
      "Epoch [47/50], Step [719/735], Loss: 0.5030\n",
      "Epoch [47/50], Step [720/735], Loss: 0.1549\n",
      "Epoch [47/50], Step [721/735], Loss: 0.0277\n",
      "Epoch [47/50], Step [722/735], Loss: 0.0490\n",
      "Epoch [47/50], Step [723/735], Loss: 0.1475\n",
      "Epoch [47/50], Step [724/735], Loss: 0.0624\n",
      "Epoch [47/50], Step [725/735], Loss: 0.0386\n",
      "Epoch [47/50], Step [726/735], Loss: 0.0432\n",
      "Epoch [47/50], Step [727/735], Loss: 0.0367\n",
      "Epoch [47/50], Step [728/735], Loss: 0.1247\n",
      "Epoch [47/50], Step [729/735], Loss: 0.0808\n",
      "Epoch [47/50], Step [730/735], Loss: 0.0771\n",
      "Epoch [47/50], Step [731/735], Loss: 0.0675\n",
      "Epoch [47/50], Step [732/735], Loss: 0.0922\n",
      "Epoch [47/50], Step [733/735], Loss: 0.0962\n",
      "Epoch [47/50], Step [734/735], Loss: 0.1313\n",
      "Epoch [47/50], Step [735/735], Loss: 0.1375\n",
      "Epoch [48/50], Step [1/735], Loss: 0.1362\n",
      "Epoch [48/50], Step [2/735], Loss: 0.0292\n",
      "Epoch [48/50], Step [3/735], Loss: 0.0461\n",
      "Epoch [48/50], Step [4/735], Loss: 0.0482\n",
      "Epoch [48/50], Step [5/735], Loss: 0.1079\n",
      "Epoch [48/50], Step [6/735], Loss: 0.0475\n",
      "Epoch [48/50], Step [7/735], Loss: 0.0847\n",
      "Epoch [48/50], Step [8/735], Loss: 0.0755\n",
      "Epoch [48/50], Step [9/735], Loss: 0.2334\n",
      "Epoch [48/50], Step [10/735], Loss: 0.1388\n",
      "Epoch [48/50], Step [11/735], Loss: 0.1847\n",
      "Epoch [48/50], Step [12/735], Loss: 0.0496\n",
      "Epoch [48/50], Step [13/735], Loss: 0.0317\n",
      "Epoch [48/50], Step [14/735], Loss: 0.1170\n",
      "Epoch [48/50], Step [15/735], Loss: 0.0844\n",
      "Epoch [48/50], Step [16/735], Loss: 0.0798\n",
      "Epoch [48/50], Step [17/735], Loss: 0.0540\n",
      "Epoch [48/50], Step [18/735], Loss: 0.0841\n",
      "Epoch [48/50], Step [19/735], Loss: 0.0338\n",
      "Epoch [48/50], Step [20/735], Loss: 0.2189\n",
      "Epoch [48/50], Step [21/735], Loss: 0.0394\n",
      "Epoch [48/50], Step [22/735], Loss: 0.0303\n",
      "Epoch [48/50], Step [23/735], Loss: 0.0511\n",
      "Epoch [48/50], Step [24/735], Loss: 0.0740\n",
      "Epoch [48/50], Step [25/735], Loss: 0.0577\n",
      "Epoch [48/50], Step [26/735], Loss: 0.5416\n",
      "Epoch [48/50], Step [27/735], Loss: 0.0786\n",
      "Epoch [48/50], Step [28/735], Loss: 0.4404\n",
      "Epoch [48/50], Step [29/735], Loss: 0.0886\n",
      "Epoch [48/50], Step [30/735], Loss: 0.0894\n",
      "Epoch [48/50], Step [31/735], Loss: 0.0720\n",
      "Epoch [48/50], Step [32/735], Loss: 0.0605\n",
      "Epoch [48/50], Step [33/735], Loss: 0.1339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Step [34/735], Loss: 0.0231\n",
      "Epoch [48/50], Step [35/735], Loss: 0.0737\n",
      "Epoch [48/50], Step [36/735], Loss: 0.1795\n",
      "Epoch [48/50], Step [37/735], Loss: 0.0435\n",
      "Epoch [48/50], Step [38/735], Loss: 0.1326\n",
      "Epoch [48/50], Step [39/735], Loss: 0.1606\n",
      "Epoch [48/50], Step [40/735], Loss: 0.2213\n",
      "Epoch [48/50], Step [41/735], Loss: 0.0285\n",
      "Epoch [48/50], Step [42/735], Loss: 0.0480\n",
      "Epoch [48/50], Step [43/735], Loss: 0.2929\n",
      "Epoch [48/50], Step [44/735], Loss: 0.0709\n",
      "Epoch [48/50], Step [45/735], Loss: 0.8057\n",
      "Epoch [48/50], Step [46/735], Loss: 0.0813\n",
      "Epoch [48/50], Step [47/735], Loss: 0.0648\n",
      "Epoch [48/50], Step [48/735], Loss: 0.0556\n",
      "Epoch [48/50], Step [49/735], Loss: 0.0826\n",
      "Epoch [48/50], Step [50/735], Loss: 0.0511\n",
      "Epoch [48/50], Step [51/735], Loss: 0.0910\n",
      "Epoch [48/50], Step [52/735], Loss: 0.0619\n",
      "Epoch [48/50], Step [53/735], Loss: 0.3760\n",
      "Epoch [48/50], Step [54/735], Loss: 0.1327\n",
      "Epoch [48/50], Step [55/735], Loss: 0.1302\n",
      "Epoch [48/50], Step [56/735], Loss: 0.0986\n",
      "Epoch [48/50], Step [57/735], Loss: 0.0602\n",
      "Epoch [48/50], Step [58/735], Loss: 0.0901\n",
      "Epoch [48/50], Step [59/735], Loss: 0.0935\n",
      "Epoch [48/50], Step [60/735], Loss: 0.0843\n",
      "Epoch [48/50], Step [61/735], Loss: 0.0993\n",
      "Epoch [48/50], Step [62/735], Loss: 0.0763\n",
      "Epoch [48/50], Step [63/735], Loss: 0.0611\n",
      "Epoch [48/50], Step [64/735], Loss: 0.0484\n",
      "Epoch [48/50], Step [65/735], Loss: 0.0492\n",
      "Epoch [48/50], Step [66/735], Loss: 0.0738\n",
      "Epoch [48/50], Step [67/735], Loss: 0.1169\n",
      "Epoch [48/50], Step [68/735], Loss: 0.1045\n",
      "Epoch [48/50], Step [69/735], Loss: 0.0594\n",
      "Epoch [48/50], Step [70/735], Loss: 0.0814\n",
      "Epoch [48/50], Step [71/735], Loss: 0.1119\n",
      "Epoch [48/50], Step [72/735], Loss: 0.0951\n",
      "Epoch [48/50], Step [73/735], Loss: 0.0603\n",
      "Epoch [48/50], Step [74/735], Loss: 0.0945\n",
      "Epoch [48/50], Step [75/735], Loss: 0.2064\n",
      "Epoch [48/50], Step [76/735], Loss: 0.0464\n",
      "Epoch [48/50], Step [77/735], Loss: 0.2420\n",
      "Epoch [48/50], Step [78/735], Loss: 0.0590\n",
      "Epoch [48/50], Step [79/735], Loss: 0.0507\n",
      "Epoch [48/50], Step [80/735], Loss: 0.0936\n",
      "Epoch [48/50], Step [81/735], Loss: 0.0448\n",
      "Epoch [48/50], Step [82/735], Loss: 0.1833\n",
      "Epoch [48/50], Step [83/735], Loss: 0.1632\n",
      "Epoch [48/50], Step [84/735], Loss: 0.0939\n",
      "Epoch [48/50], Step [85/735], Loss: 0.1084\n",
      "Epoch [48/50], Step [86/735], Loss: 0.1587\n",
      "Epoch [48/50], Step [87/735], Loss: 0.0803\n",
      "Epoch [48/50], Step [88/735], Loss: 0.0272\n",
      "Epoch [48/50], Step [89/735], Loss: 0.0915\n",
      "Epoch [48/50], Step [90/735], Loss: 0.0980\n",
      "Epoch [48/50], Step [91/735], Loss: 0.1693\n",
      "Epoch [48/50], Step [92/735], Loss: 0.0705\n",
      "Epoch [48/50], Step [93/735], Loss: 0.0663\n",
      "Epoch [48/50], Step [94/735], Loss: 0.0665\n",
      "Epoch [48/50], Step [95/735], Loss: 0.0280\n",
      "Epoch [48/50], Step [96/735], Loss: 0.0827\n",
      "Epoch [48/50], Step [97/735], Loss: 0.2229\n",
      "Epoch [48/50], Step [98/735], Loss: 0.1437\n",
      "Epoch [48/50], Step [99/735], Loss: 0.0671\n",
      "Epoch [48/50], Step [100/735], Loss: 0.0947\n",
      "Epoch [48/50], Step [101/735], Loss: 0.2662\n",
      "Epoch [48/50], Step [102/735], Loss: 0.0692\n",
      "Epoch [48/50], Step [103/735], Loss: 0.0668\n",
      "Epoch [48/50], Step [104/735], Loss: 0.0989\n",
      "Epoch [48/50], Step [105/735], Loss: 0.2909\n",
      "Epoch [48/50], Step [106/735], Loss: 0.1104\n",
      "Epoch [48/50], Step [107/735], Loss: 0.1001\n",
      "Epoch [48/50], Step [108/735], Loss: 0.1810\n",
      "Epoch [48/50], Step [109/735], Loss: 0.0457\n",
      "Epoch [48/50], Step [110/735], Loss: 0.0794\n",
      "Epoch [48/50], Step [111/735], Loss: 0.3860\n",
      "Epoch [48/50], Step [112/735], Loss: 0.0648\n",
      "Epoch [48/50], Step [113/735], Loss: 0.0354\n",
      "Epoch [48/50], Step [114/735], Loss: 0.1209\n",
      "Epoch [48/50], Step [115/735], Loss: 0.0552\n",
      "Epoch [48/50], Step [116/735], Loss: 0.1095\n",
      "Epoch [48/50], Step [117/735], Loss: 0.0543\n",
      "Epoch [48/50], Step [118/735], Loss: 0.0652\n",
      "Epoch [48/50], Step [119/735], Loss: 0.1639\n",
      "Epoch [48/50], Step [120/735], Loss: 0.1254\n",
      "Epoch [48/50], Step [121/735], Loss: 0.0868\n",
      "Epoch [48/50], Step [122/735], Loss: 0.0807\n",
      "Epoch [48/50], Step [123/735], Loss: 0.0744\n",
      "Epoch [48/50], Step [124/735], Loss: 0.1821\n",
      "Epoch [48/50], Step [125/735], Loss: 0.1425\n",
      "Epoch [48/50], Step [126/735], Loss: 0.1519\n",
      "Epoch [48/50], Step [127/735], Loss: 0.1293\n",
      "Epoch [48/50], Step [128/735], Loss: 0.1635\n",
      "Epoch [48/50], Step [129/735], Loss: 0.1197\n",
      "Epoch [48/50], Step [130/735], Loss: 0.1431\n",
      "Epoch [48/50], Step [131/735], Loss: 0.0696\n",
      "Epoch [48/50], Step [132/735], Loss: 0.0813\n",
      "Epoch [48/50], Step [133/735], Loss: 0.1022\n",
      "Epoch [48/50], Step [134/735], Loss: 0.0720\n",
      "Epoch [48/50], Step [135/735], Loss: 0.0729\n",
      "Epoch [48/50], Step [136/735], Loss: 0.0587\n",
      "Epoch [48/50], Step [137/735], Loss: 0.0967\n",
      "Epoch [48/50], Step [138/735], Loss: 0.1954\n",
      "Epoch [48/50], Step [139/735], Loss: 0.8981\n",
      "Epoch [48/50], Step [140/735], Loss: 0.1176\n",
      "Epoch [48/50], Step [141/735], Loss: 0.0879\n",
      "Epoch [48/50], Step [142/735], Loss: 0.0518\n",
      "Epoch [48/50], Step [143/735], Loss: 0.1972\n",
      "Epoch [48/50], Step [144/735], Loss: 0.3930\n",
      "Epoch [48/50], Step [145/735], Loss: 0.0764\n",
      "Epoch [48/50], Step [146/735], Loss: 0.1315\n",
      "Epoch [48/50], Step [147/735], Loss: 0.1456\n",
      "Epoch [48/50], Step [148/735], Loss: 0.0535\n",
      "Epoch [48/50], Step [149/735], Loss: 0.0625\n",
      "Epoch [48/50], Step [150/735], Loss: 0.0784\n",
      "Epoch [48/50], Step [151/735], Loss: 0.0725\n",
      "Epoch [48/50], Step [152/735], Loss: 0.0363\n",
      "Epoch [48/50], Step [153/735], Loss: 0.0787\n",
      "Epoch [48/50], Step [154/735], Loss: 0.0366\n",
      "Epoch [48/50], Step [155/735], Loss: 0.0574\n",
      "Epoch [48/50], Step [156/735], Loss: 0.0730\n",
      "Epoch [48/50], Step [157/735], Loss: 0.0782\n",
      "Epoch [48/50], Step [158/735], Loss: 0.2977\n",
      "Epoch [48/50], Step [159/735], Loss: 0.0645\n",
      "Epoch [48/50], Step [160/735], Loss: 0.0752\n",
      "Epoch [48/50], Step [161/735], Loss: 0.0791\n",
      "Epoch [48/50], Step [162/735], Loss: 0.0571\n",
      "Epoch [48/50], Step [163/735], Loss: 0.0683\n",
      "Epoch [48/50], Step [164/735], Loss: 0.0978\n",
      "Epoch [48/50], Step [165/735], Loss: 0.1305\n",
      "Epoch [48/50], Step [166/735], Loss: 0.0411\n",
      "Epoch [48/50], Step [167/735], Loss: 0.2227\n",
      "Epoch [48/50], Step [168/735], Loss: 0.1305\n",
      "Epoch [48/50], Step [169/735], Loss: 0.0906\n",
      "Epoch [48/50], Step [170/735], Loss: 0.0511\n",
      "Epoch [48/50], Step [171/735], Loss: 0.3770\n",
      "Epoch [48/50], Step [172/735], Loss: 0.0906\n",
      "Epoch [48/50], Step [173/735], Loss: 0.0739\n",
      "Epoch [48/50], Step [174/735], Loss: 0.0594\n",
      "Epoch [48/50], Step [175/735], Loss: 0.0370\n",
      "Epoch [48/50], Step [176/735], Loss: 0.0681\n",
      "Epoch [48/50], Step [177/735], Loss: 0.0939\n",
      "Epoch [48/50], Step [178/735], Loss: 0.0747\n",
      "Epoch [48/50], Step [179/735], Loss: 0.0374\n",
      "Epoch [48/50], Step [180/735], Loss: 0.1184\n",
      "Epoch [48/50], Step [181/735], Loss: 0.0999\n",
      "Epoch [48/50], Step [182/735], Loss: 0.0425\n",
      "Epoch [48/50], Step [183/735], Loss: 0.1502\n",
      "Epoch [48/50], Step [184/735], Loss: 0.1190\n",
      "Epoch [48/50], Step [185/735], Loss: 0.0816\n",
      "Epoch [48/50], Step [186/735], Loss: 0.1449\n",
      "Epoch [48/50], Step [187/735], Loss: 0.0616\n",
      "Epoch [48/50], Step [188/735], Loss: 0.1503\n",
      "Epoch [48/50], Step [189/735], Loss: 0.0794\n",
      "Epoch [48/50], Step [190/735], Loss: 0.1361\n",
      "Epoch [48/50], Step [191/735], Loss: 0.0327\n",
      "Epoch [48/50], Step [192/735], Loss: 0.0885\n",
      "Epoch [48/50], Step [193/735], Loss: 0.1301\n",
      "Epoch [48/50], Step [194/735], Loss: 0.0505\n",
      "Epoch [48/50], Step [195/735], Loss: 0.0266\n",
      "Epoch [48/50], Step [196/735], Loss: 0.2494\n",
      "Epoch [48/50], Step [197/735], Loss: 0.1419\n",
      "Epoch [48/50], Step [198/735], Loss: 0.0923\n",
      "Epoch [48/50], Step [199/735], Loss: 0.0916\n",
      "Epoch [48/50], Step [200/735], Loss: 0.1164\n",
      "Epoch [48/50], Step [201/735], Loss: 0.0695\n",
      "Epoch [48/50], Step [202/735], Loss: 0.0620\n",
      "Epoch [48/50], Step [203/735], Loss: 0.0698\n",
      "Epoch [48/50], Step [204/735], Loss: 0.0688\n",
      "Epoch [48/50], Step [205/735], Loss: 0.2101\n",
      "Epoch [48/50], Step [206/735], Loss: 0.0532\n",
      "Epoch [48/50], Step [207/735], Loss: 0.0879\n",
      "Epoch [48/50], Step [208/735], Loss: 0.0785\n",
      "Epoch [48/50], Step [209/735], Loss: 0.0534\n",
      "Epoch [48/50], Step [210/735], Loss: 0.0781\n",
      "Epoch [48/50], Step [211/735], Loss: 0.0960\n",
      "Epoch [48/50], Step [212/735], Loss: 0.0446\n",
      "Epoch [48/50], Step [213/735], Loss: 0.1207\n",
      "Epoch [48/50], Step [214/735], Loss: 0.0932\n",
      "Epoch [48/50], Step [215/735], Loss: 0.4843\n",
      "Epoch [48/50], Step [216/735], Loss: 0.0584\n",
      "Epoch [48/50], Step [217/735], Loss: 0.8796\n",
      "Epoch [48/50], Step [218/735], Loss: 0.0947\n",
      "Epoch [48/50], Step [219/735], Loss: 0.0957\n",
      "Epoch [48/50], Step [220/735], Loss: 0.1051\n",
      "Epoch [48/50], Step [221/735], Loss: 0.1541\n",
      "Epoch [48/50], Step [222/735], Loss: 0.0413\n",
      "Epoch [48/50], Step [223/735], Loss: 0.1066\n",
      "Epoch [48/50], Step [224/735], Loss: 0.0413\n",
      "Epoch [48/50], Step [225/735], Loss: 0.0955\n",
      "Epoch [48/50], Step [226/735], Loss: 0.1066\n",
      "Epoch [48/50], Step [227/735], Loss: 0.0835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Step [228/735], Loss: 0.0882\n",
      "Epoch [48/50], Step [229/735], Loss: 0.0490\n",
      "Epoch [48/50], Step [230/735], Loss: 0.0764\n",
      "Epoch [48/50], Step [231/735], Loss: 0.0925\n",
      "Epoch [48/50], Step [232/735], Loss: 0.2079\n",
      "Epoch [48/50], Step [233/735], Loss: 0.1359\n",
      "Epoch [48/50], Step [234/735], Loss: 0.0885\n",
      "Epoch [48/50], Step [235/735], Loss: 0.0444\n",
      "Epoch [48/50], Step [236/735], Loss: 0.0401\n",
      "Epoch [48/50], Step [237/735], Loss: 0.0569\n",
      "Epoch [48/50], Step [238/735], Loss: 0.0604\n",
      "Epoch [48/50], Step [239/735], Loss: 0.3005\n",
      "Epoch [48/50], Step [240/735], Loss: 0.2343\n",
      "Epoch [48/50], Step [241/735], Loss: 0.0441\n",
      "Epoch [48/50], Step [242/735], Loss: 0.1602\n",
      "Epoch [48/50], Step [243/735], Loss: 0.0445\n",
      "Epoch [48/50], Step [244/735], Loss: 0.0588\n",
      "Epoch [48/50], Step [245/735], Loss: 0.1054\n",
      "Epoch [48/50], Step [246/735], Loss: 0.0790\n",
      "Epoch [48/50], Step [247/735], Loss: 0.1329\n",
      "Epoch [48/50], Step [248/735], Loss: 0.0895\n",
      "Epoch [48/50], Step [249/735], Loss: 0.0954\n",
      "Epoch [48/50], Step [250/735], Loss: 0.1349\n",
      "Epoch [48/50], Step [251/735], Loss: 0.0666\n",
      "Epoch [48/50], Step [252/735], Loss: 0.0938\n",
      "Epoch [48/50], Step [253/735], Loss: 0.0505\n",
      "Epoch [48/50], Step [254/735], Loss: 0.0849\n",
      "Epoch [48/50], Step [255/735], Loss: 0.3520\n",
      "Epoch [48/50], Step [256/735], Loss: 0.0956\n",
      "Epoch [48/50], Step [257/735], Loss: 0.1131\n",
      "Epoch [48/50], Step [258/735], Loss: 0.0579\n",
      "Epoch [48/50], Step [259/735], Loss: 0.1096\n",
      "Epoch [48/50], Step [260/735], Loss: 0.0516\n",
      "Epoch [48/50], Step [261/735], Loss: 0.0613\n",
      "Epoch [48/50], Step [262/735], Loss: 0.0408\n",
      "Epoch [48/50], Step [263/735], Loss: 0.1785\n",
      "Epoch [48/50], Step [264/735], Loss: 0.0313\n",
      "Epoch [48/50], Step [265/735], Loss: 0.0661\n",
      "Epoch [48/50], Step [266/735], Loss: 0.0510\n",
      "Epoch [48/50], Step [267/735], Loss: 0.0651\n",
      "Epoch [48/50], Step [268/735], Loss: 0.2813\n",
      "Epoch [48/50], Step [269/735], Loss: 0.0754\n",
      "Epoch [48/50], Step [270/735], Loss: 0.1160\n",
      "Epoch [48/50], Step [271/735], Loss: 0.3989\n",
      "Epoch [48/50], Step [272/735], Loss: 0.1460\n",
      "Epoch [48/50], Step [273/735], Loss: 0.1428\n",
      "Epoch [48/50], Step [274/735], Loss: 0.0753\n",
      "Epoch [48/50], Step [275/735], Loss: 0.0655\n",
      "Epoch [48/50], Step [276/735], Loss: 0.1008\n",
      "Epoch [48/50], Step [277/735], Loss: 0.5328\n",
      "Epoch [48/50], Step [278/735], Loss: 0.1057\n",
      "Epoch [48/50], Step [279/735], Loss: 0.1066\n",
      "Epoch [48/50], Step [280/735], Loss: 0.0465\n",
      "Epoch [48/50], Step [281/735], Loss: 0.0448\n",
      "Epoch [48/50], Step [282/735], Loss: 0.1010\n",
      "Epoch [48/50], Step [283/735], Loss: 0.1311\n",
      "Epoch [48/50], Step [284/735], Loss: 0.0574\n",
      "Epoch [48/50], Step [285/735], Loss: 0.0797\n",
      "Epoch [48/50], Step [286/735], Loss: 0.0445\n",
      "Epoch [48/50], Step [287/735], Loss: 0.0614\n",
      "Epoch [48/50], Step [288/735], Loss: 0.0683\n",
      "Epoch [48/50], Step [289/735], Loss: 0.0345\n",
      "Epoch [48/50], Step [290/735], Loss: 0.0992\n",
      "Epoch [48/50], Step [291/735], Loss: 0.0743\n",
      "Epoch [48/50], Step [292/735], Loss: 0.1109\n",
      "Epoch [48/50], Step [293/735], Loss: 0.0550\n",
      "Epoch [48/50], Step [294/735], Loss: 0.0946\n",
      "Epoch [48/50], Step [295/735], Loss: 0.0974\n",
      "Epoch [48/50], Step [296/735], Loss: 0.0732\n",
      "Epoch [48/50], Step [297/735], Loss: 0.0303\n",
      "Epoch [48/50], Step [298/735], Loss: 0.5416\n",
      "Epoch [48/50], Step [299/735], Loss: 0.2233\n",
      "Epoch [48/50], Step [300/735], Loss: 0.0499\n",
      "Epoch [48/50], Step [301/735], Loss: 0.0289\n",
      "Epoch [48/50], Step [302/735], Loss: 0.0749\n",
      "Epoch [48/50], Step [303/735], Loss: 0.0765\n",
      "Epoch [48/50], Step [304/735], Loss: 0.1244\n",
      "Epoch [48/50], Step [305/735], Loss: 0.1064\n",
      "Epoch [48/50], Step [306/735], Loss: 0.0700\n",
      "Epoch [48/50], Step [307/735], Loss: 0.2371\n",
      "Epoch [48/50], Step [308/735], Loss: 0.0542\n",
      "Epoch [48/50], Step [309/735], Loss: 0.1968\n",
      "Epoch [48/50], Step [310/735], Loss: 0.0390\n",
      "Epoch [48/50], Step [311/735], Loss: 0.1002\n",
      "Epoch [48/50], Step [312/735], Loss: 0.0688\n",
      "Epoch [48/50], Step [313/735], Loss: 0.0900\n",
      "Epoch [48/50], Step [314/735], Loss: 0.0546\n",
      "Epoch [48/50], Step [315/735], Loss: 0.0366\n",
      "Epoch [48/50], Step [316/735], Loss: 0.0983\n",
      "Epoch [48/50], Step [317/735], Loss: 0.0840\n",
      "Epoch [48/50], Step [318/735], Loss: 0.0896\n",
      "Epoch [48/50], Step [319/735], Loss: 0.1054\n",
      "Epoch [48/50], Step [320/735], Loss: 0.1570\n",
      "Epoch [48/50], Step [321/735], Loss: 0.1586\n",
      "Epoch [48/50], Step [322/735], Loss: 0.0631\n",
      "Epoch [48/50], Step [323/735], Loss: 0.0508\n",
      "Epoch [48/50], Step [324/735], Loss: 0.0657\n",
      "Epoch [48/50], Step [325/735], Loss: 0.0448\n",
      "Epoch [48/50], Step [326/735], Loss: 0.0521\n",
      "Epoch [48/50], Step [327/735], Loss: 0.1660\n",
      "Epoch [48/50], Step [328/735], Loss: 0.0727\n",
      "Epoch [48/50], Step [329/735], Loss: 0.0700\n",
      "Epoch [48/50], Step [330/735], Loss: 0.0742\n",
      "Epoch [48/50], Step [331/735], Loss: 0.1217\n",
      "Epoch [48/50], Step [332/735], Loss: 0.1710\n",
      "Epoch [48/50], Step [333/735], Loss: 0.1121\n",
      "Epoch [48/50], Step [334/735], Loss: 0.1366\n",
      "Epoch [48/50], Step [335/735], Loss: 0.0695\n",
      "Epoch [48/50], Step [336/735], Loss: 0.1459\n",
      "Epoch [48/50], Step [337/735], Loss: 0.1308\n",
      "Epoch [48/50], Step [338/735], Loss: 0.0823\n",
      "Epoch [48/50], Step [339/735], Loss: 0.1002\n",
      "Epoch [48/50], Step [340/735], Loss: 0.0749\n",
      "Epoch [48/50], Step [341/735], Loss: 0.2350\n",
      "Epoch [48/50], Step [342/735], Loss: 0.0577\n",
      "Epoch [48/50], Step [343/735], Loss: 0.0590\n",
      "Epoch [48/50], Step [344/735], Loss: 0.1008\n",
      "Epoch [48/50], Step [345/735], Loss: 0.1504\n",
      "Epoch [48/50], Step [346/735], Loss: 0.0541\n",
      "Epoch [48/50], Step [347/735], Loss: 0.0737\n",
      "Epoch [48/50], Step [348/735], Loss: 0.0304\n",
      "Epoch [48/50], Step [349/735], Loss: 0.0614\n",
      "Epoch [48/50], Step [350/735], Loss: 0.0589\n",
      "Epoch [48/50], Step [351/735], Loss: 0.1715\n",
      "Epoch [48/50], Step [352/735], Loss: 0.0683\n",
      "Epoch [48/50], Step [353/735], Loss: 0.0344\n",
      "Epoch [48/50], Step [354/735], Loss: 0.0548\n",
      "Epoch [48/50], Step [355/735], Loss: 0.0736\n",
      "Epoch [48/50], Step [356/735], Loss: 0.1082\n",
      "Epoch [48/50], Step [357/735], Loss: 1.2964\n",
      "Epoch [48/50], Step [358/735], Loss: 0.0470\n",
      "Epoch [48/50], Step [359/735], Loss: 0.1730\n",
      "Epoch [48/50], Step [360/735], Loss: 0.0812\n",
      "Epoch [48/50], Step [361/735], Loss: 0.1040\n",
      "Epoch [48/50], Step [362/735], Loss: 0.2773\n",
      "Epoch [48/50], Step [363/735], Loss: 0.1720\n",
      "Epoch [48/50], Step [364/735], Loss: 0.0819\n",
      "Epoch [48/50], Step [365/735], Loss: 0.2369\n",
      "Epoch [48/50], Step [366/735], Loss: 0.0683\n",
      "Epoch [48/50], Step [367/735], Loss: 0.1035\n",
      "Epoch [48/50], Step [368/735], Loss: 0.0308\n",
      "Epoch [48/50], Step [369/735], Loss: 0.0751\n",
      "Epoch [48/50], Step [370/735], Loss: 0.0646\n",
      "Epoch [48/50], Step [371/735], Loss: 0.0512\n",
      "Epoch [48/50], Step [372/735], Loss: 0.1535\n",
      "Epoch [48/50], Step [373/735], Loss: 0.0493\n",
      "Epoch [48/50], Step [374/735], Loss: 0.0719\n",
      "Epoch [48/50], Step [375/735], Loss: 0.0589\n",
      "Epoch [48/50], Step [376/735], Loss: 0.0583\n",
      "Epoch [48/50], Step [377/735], Loss: 0.0751\n",
      "Epoch [48/50], Step [378/735], Loss: 0.0246\n",
      "Epoch [48/50], Step [379/735], Loss: 0.0875\n",
      "Epoch [48/50], Step [380/735], Loss: 0.0619\n",
      "Epoch [48/50], Step [381/735], Loss: 0.0299\n",
      "Epoch [48/50], Step [382/735], Loss: 0.0729\n",
      "Epoch [48/50], Step [383/735], Loss: 0.0802\n",
      "Epoch [48/50], Step [384/735], Loss: 0.0896\n",
      "Epoch [48/50], Step [385/735], Loss: 0.0434\n",
      "Epoch [48/50], Step [386/735], Loss: 0.2553\n",
      "Epoch [48/50], Step [387/735], Loss: 0.0647\n",
      "Epoch [48/50], Step [388/735], Loss: 0.0269\n",
      "Epoch [48/50], Step [389/735], Loss: 0.0634\n",
      "Epoch [48/50], Step [390/735], Loss: 0.1116\n",
      "Epoch [48/50], Step [391/735], Loss: 0.0340\n",
      "Epoch [48/50], Step [392/735], Loss: 0.0306\n",
      "Epoch [48/50], Step [393/735], Loss: 0.0643\n",
      "Epoch [48/50], Step [394/735], Loss: 0.0512\n",
      "Epoch [48/50], Step [395/735], Loss: 0.0927\n",
      "Epoch [48/50], Step [396/735], Loss: 0.1029\n",
      "Epoch [48/50], Step [397/735], Loss: 0.0547\n",
      "Epoch [48/50], Step [398/735], Loss: 1.5019\n",
      "Epoch [48/50], Step [399/735], Loss: 0.1337\n",
      "Epoch [48/50], Step [400/735], Loss: 0.0877\n",
      "Epoch [48/50], Step [401/735], Loss: 0.0440\n",
      "Epoch [48/50], Step [402/735], Loss: 0.0331\n",
      "Epoch [48/50], Step [403/735], Loss: 0.1521\n",
      "Epoch [48/50], Step [404/735], Loss: 0.2534\n",
      "Epoch [48/50], Step [405/735], Loss: 0.0358\n",
      "Epoch [48/50], Step [406/735], Loss: 0.0841\n",
      "Epoch [48/50], Step [407/735], Loss: 0.1045\n",
      "Epoch [48/50], Step [408/735], Loss: 0.0914\n",
      "Epoch [48/50], Step [409/735], Loss: 0.0504\n",
      "Epoch [48/50], Step [410/735], Loss: 0.0724\n",
      "Epoch [48/50], Step [411/735], Loss: 0.0631\n",
      "Epoch [48/50], Step [412/735], Loss: 0.1963\n",
      "Epoch [48/50], Step [413/735], Loss: 0.0756\n",
      "Epoch [48/50], Step [414/735], Loss: 0.1425\n",
      "Epoch [48/50], Step [415/735], Loss: 0.0614\n",
      "Epoch [48/50], Step [416/735], Loss: 0.1580\n",
      "Epoch [48/50], Step [417/735], Loss: 0.0579\n",
      "Epoch [48/50], Step [418/735], Loss: 0.0688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Step [419/735], Loss: 0.3855\n",
      "Epoch [48/50], Step [420/735], Loss: 0.0986\n",
      "Epoch [48/50], Step [421/735], Loss: 0.0582\n",
      "Epoch [48/50], Step [422/735], Loss: 0.1008\n",
      "Epoch [48/50], Step [423/735], Loss: 0.0656\n",
      "Epoch [48/50], Step [424/735], Loss: 0.0616\n",
      "Epoch [48/50], Step [425/735], Loss: 0.0645\n",
      "Epoch [48/50], Step [426/735], Loss: 0.0812\n",
      "Epoch [48/50], Step [427/735], Loss: 0.1468\n",
      "Epoch [48/50], Step [428/735], Loss: 0.0651\n",
      "Epoch [48/50], Step [429/735], Loss: 0.0570\n",
      "Epoch [48/50], Step [430/735], Loss: 0.0459\n",
      "Epoch [48/50], Step [431/735], Loss: 0.0843\n",
      "Epoch [48/50], Step [432/735], Loss: 0.0685\n",
      "Epoch [48/50], Step [433/735], Loss: 0.1056\n",
      "Epoch [48/50], Step [434/735], Loss: 0.1403\n",
      "Epoch [48/50], Step [435/735], Loss: 0.0534\n",
      "Epoch [48/50], Step [436/735], Loss: 0.0871\n",
      "Epoch [48/50], Step [437/735], Loss: 0.0739\n",
      "Epoch [48/50], Step [438/735], Loss: 0.0816\n",
      "Epoch [48/50], Step [439/735], Loss: 0.0960\n",
      "Epoch [48/50], Step [440/735], Loss: 0.0853\n",
      "Epoch [48/50], Step [441/735], Loss: 0.3116\n",
      "Epoch [48/50], Step [442/735], Loss: 0.0594\n",
      "Epoch [48/50], Step [443/735], Loss: 0.0822\n",
      "Epoch [48/50], Step [444/735], Loss: 0.0666\n",
      "Epoch [48/50], Step [445/735], Loss: 0.0716\n",
      "Epoch [48/50], Step [446/735], Loss: 0.0523\n",
      "Epoch [48/50], Step [447/735], Loss: 0.0200\n",
      "Epoch [48/50], Step [448/735], Loss: 0.0635\n",
      "Epoch [48/50], Step [449/735], Loss: 0.2130\n",
      "Epoch [48/50], Step [450/735], Loss: 0.1005\n",
      "Epoch [48/50], Step [451/735], Loss: 0.0906\n",
      "Epoch [48/50], Step [452/735], Loss: 0.7896\n",
      "Epoch [48/50], Step [453/735], Loss: 0.0647\n",
      "Epoch [48/50], Step [454/735], Loss: 0.0633\n",
      "Epoch [48/50], Step [455/735], Loss: 0.0628\n",
      "Epoch [48/50], Step [456/735], Loss: 0.1887\n",
      "Epoch [48/50], Step [457/735], Loss: 0.1073\n",
      "Epoch [48/50], Step [458/735], Loss: 0.0259\n",
      "Epoch [48/50], Step [459/735], Loss: 0.0413\n",
      "Epoch [48/50], Step [460/735], Loss: 0.1107\n",
      "Epoch [48/50], Step [461/735], Loss: 0.0887\n",
      "Epoch [48/50], Step [462/735], Loss: 0.1013\n",
      "Epoch [48/50], Step [463/735], Loss: 0.0893\n",
      "Epoch [48/50], Step [464/735], Loss: 0.0694\n",
      "Epoch [48/50], Step [465/735], Loss: 0.0449\n",
      "Epoch [48/50], Step [466/735], Loss: 0.0503\n",
      "Epoch [48/50], Step [467/735], Loss: 1.3254\n",
      "Epoch [48/50], Step [468/735], Loss: 0.0705\n",
      "Epoch [48/50], Step [469/735], Loss: 0.0915\n",
      "Epoch [48/50], Step [470/735], Loss: 0.0383\n",
      "Epoch [48/50], Step [471/735], Loss: 0.0717\n",
      "Epoch [48/50], Step [472/735], Loss: 0.1541\n",
      "Epoch [48/50], Step [473/735], Loss: 0.2223\n",
      "Epoch [48/50], Step [474/735], Loss: 0.0833\n",
      "Epoch [48/50], Step [475/735], Loss: 0.0674\n",
      "Epoch [48/50], Step [476/735], Loss: 0.0639\n",
      "Epoch [48/50], Step [477/735], Loss: 0.0726\n",
      "Epoch [48/50], Step [478/735], Loss: 0.0438\n",
      "Epoch [48/50], Step [479/735], Loss: 0.0905\n",
      "Epoch [48/50], Step [480/735], Loss: 0.1046\n",
      "Epoch [48/50], Step [481/735], Loss: 0.1347\n",
      "Epoch [48/50], Step [482/735], Loss: 0.1773\n",
      "Epoch [48/50], Step [483/735], Loss: 0.0202\n",
      "Epoch [48/50], Step [484/735], Loss: 0.0717\n",
      "Epoch [48/50], Step [485/735], Loss: 0.0932\n",
      "Epoch [48/50], Step [486/735], Loss: 0.0799\n",
      "Epoch [48/50], Step [487/735], Loss: 0.0537\n",
      "Epoch [48/50], Step [488/735], Loss: 0.1781\n",
      "Epoch [48/50], Step [489/735], Loss: 0.0930\n",
      "Epoch [48/50], Step [490/735], Loss: 0.0817\n",
      "Epoch [48/50], Step [491/735], Loss: 0.0819\n",
      "Epoch [48/50], Step [492/735], Loss: 0.0576\n",
      "Epoch [48/50], Step [493/735], Loss: 0.0821\n",
      "Epoch [48/50], Step [494/735], Loss: 0.0665\n",
      "Epoch [48/50], Step [495/735], Loss: 0.0646\n",
      "Epoch [48/50], Step [496/735], Loss: 0.0603\n",
      "Epoch [48/50], Step [497/735], Loss: 0.0942\n",
      "Epoch [48/50], Step [498/735], Loss: 0.1417\n",
      "Epoch [48/50], Step [499/735], Loss: 0.0916\n",
      "Epoch [48/50], Step [500/735], Loss: 0.9752\n",
      "Epoch [48/50], Step [501/735], Loss: 0.1340\n",
      "Epoch [48/50], Step [502/735], Loss: 0.1277\n",
      "Epoch [48/50], Step [503/735], Loss: 0.0714\n",
      "Epoch [48/50], Step [504/735], Loss: 0.0766\n",
      "Epoch [48/50], Step [505/735], Loss: 0.1053\n",
      "Epoch [48/50], Step [506/735], Loss: 0.0727\n",
      "Epoch [48/50], Step [507/735], Loss: 0.0482\n",
      "Epoch [48/50], Step [508/735], Loss: 0.0783\n",
      "Epoch [48/50], Step [509/735], Loss: 0.0237\n",
      "Epoch [48/50], Step [510/735], Loss: 0.0508\n",
      "Epoch [48/50], Step [511/735], Loss: 0.3675\n",
      "Epoch [48/50], Step [512/735], Loss: 0.8344\n",
      "Epoch [48/50], Step [513/735], Loss: 0.1470\n",
      "Epoch [48/50], Step [514/735], Loss: 0.0645\n",
      "Epoch [48/50], Step [515/735], Loss: 0.0619\n",
      "Epoch [48/50], Step [516/735], Loss: 0.0661\n",
      "Epoch [48/50], Step [517/735], Loss: 0.0868\n",
      "Epoch [48/50], Step [518/735], Loss: 0.0478\n",
      "Epoch [48/50], Step [519/735], Loss: 0.1032\n",
      "Epoch [48/50], Step [520/735], Loss: 0.0358\n",
      "Epoch [48/50], Step [521/735], Loss: 0.0942\n",
      "Epoch [48/50], Step [522/735], Loss: 0.0580\n",
      "Epoch [48/50], Step [523/735], Loss: 0.0440\n",
      "Epoch [48/50], Step [524/735], Loss: 0.0523\n",
      "Epoch [48/50], Step [525/735], Loss: 0.0858\n",
      "Epoch [48/50], Step [526/735], Loss: 0.0726\n",
      "Epoch [48/50], Step [527/735], Loss: 0.1002\n",
      "Epoch [48/50], Step [528/735], Loss: 0.0459\n",
      "Epoch [48/50], Step [529/735], Loss: 0.0662\n",
      "Epoch [48/50], Step [530/735], Loss: 0.1181\n",
      "Epoch [48/50], Step [531/735], Loss: 0.0568\n",
      "Epoch [48/50], Step [532/735], Loss: 0.1456\n",
      "Epoch [48/50], Step [533/735], Loss: 0.4737\n",
      "Epoch [48/50], Step [534/735], Loss: 0.0505\n",
      "Epoch [48/50], Step [535/735], Loss: 0.0843\n",
      "Epoch [48/50], Step [536/735], Loss: 0.0732\n",
      "Epoch [48/50], Step [537/735], Loss: 0.2683\n",
      "Epoch [48/50], Step [538/735], Loss: 0.0672\n",
      "Epoch [48/50], Step [539/735], Loss: 0.0356\n",
      "Epoch [48/50], Step [540/735], Loss: 0.3356\n",
      "Epoch [48/50], Step [541/735], Loss: 0.1079\n",
      "Epoch [48/50], Step [542/735], Loss: 0.1092\n",
      "Epoch [48/50], Step [543/735], Loss: 0.0519\n",
      "Epoch [48/50], Step [544/735], Loss: 0.0787\n",
      "Epoch [48/50], Step [545/735], Loss: 0.0527\n",
      "Epoch [48/50], Step [546/735], Loss: 0.0318\n",
      "Epoch [48/50], Step [547/735], Loss: 0.0542\n",
      "Epoch [48/50], Step [548/735], Loss: 0.0452\n",
      "Epoch [48/50], Step [549/735], Loss: 0.0601\n",
      "Epoch [48/50], Step [550/735], Loss: 0.0962\n",
      "Epoch [48/50], Step [551/735], Loss: 0.0574\n",
      "Epoch [48/50], Step [552/735], Loss: 0.1068\n",
      "Epoch [48/50], Step [553/735], Loss: 0.1388\n",
      "Epoch [48/50], Step [554/735], Loss: 0.2532\n",
      "Epoch [48/50], Step [555/735], Loss: 0.0673\n",
      "Epoch [48/50], Step [556/735], Loss: 0.0965\n",
      "Epoch [48/50], Step [557/735], Loss: 0.0789\n",
      "Epoch [48/50], Step [558/735], Loss: 0.6353\n",
      "Epoch [48/50], Step [559/735], Loss: 0.0592\n",
      "Epoch [48/50], Step [560/735], Loss: 0.0910\n",
      "Epoch [48/50], Step [561/735], Loss: 0.1404\n",
      "Epoch [48/50], Step [562/735], Loss: 0.0571\n",
      "Epoch [48/50], Step [563/735], Loss: 1.4381\n",
      "Epoch [48/50], Step [564/735], Loss: 0.0640\n",
      "Epoch [48/50], Step [565/735], Loss: 0.0324\n",
      "Epoch [48/50], Step [566/735], Loss: 0.0643\n",
      "Epoch [48/50], Step [567/735], Loss: 0.0473\n",
      "Epoch [48/50], Step [568/735], Loss: 0.1016\n",
      "Epoch [48/50], Step [569/735], Loss: 0.0622\n",
      "Epoch [48/50], Step [570/735], Loss: 0.1640\n",
      "Epoch [48/50], Step [571/735], Loss: 0.1418\n",
      "Epoch [48/50], Step [572/735], Loss: 0.0856\n",
      "Epoch [48/50], Step [573/735], Loss: 0.2088\n",
      "Epoch [48/50], Step [574/735], Loss: 0.0881\n",
      "Epoch [48/50], Step [575/735], Loss: 0.0592\n",
      "Epoch [48/50], Step [576/735], Loss: 0.3445\n",
      "Epoch [48/50], Step [577/735], Loss: 0.0668\n",
      "Epoch [48/50], Step [578/735], Loss: 0.0670\n",
      "Epoch [48/50], Step [579/735], Loss: 0.0914\n",
      "Epoch [48/50], Step [580/735], Loss: 0.1314\n",
      "Epoch [48/50], Step [581/735], Loss: 0.1689\n",
      "Epoch [48/50], Step [582/735], Loss: 0.0734\n",
      "Epoch [48/50], Step [583/735], Loss: 0.3575\n",
      "Epoch [48/50], Step [584/735], Loss: 0.0446\n",
      "Epoch [48/50], Step [585/735], Loss: 0.0597\n",
      "Epoch [48/50], Step [586/735], Loss: 0.0565\n",
      "Epoch [48/50], Step [587/735], Loss: 0.0518\n",
      "Epoch [48/50], Step [588/735], Loss: 0.1082\n",
      "Epoch [48/50], Step [589/735], Loss: 0.0557\n",
      "Epoch [48/50], Step [590/735], Loss: 0.0799\n",
      "Epoch [48/50], Step [591/735], Loss: 0.0615\n",
      "Epoch [48/50], Step [592/735], Loss: 0.0657\n",
      "Epoch [48/50], Step [593/735], Loss: 0.0457\n",
      "Epoch [48/50], Step [594/735], Loss: 0.0530\n",
      "Epoch [48/50], Step [595/735], Loss: 0.0804\n",
      "Epoch [48/50], Step [596/735], Loss: 0.0706\n",
      "Epoch [48/50], Step [597/735], Loss: 0.0854\n",
      "Epoch [48/50], Step [598/735], Loss: 0.0769\n",
      "Epoch [48/50], Step [599/735], Loss: 0.0352\n",
      "Epoch [48/50], Step [600/735], Loss: 0.0799\n",
      "Epoch [48/50], Step [601/735], Loss: 0.0330\n",
      "Epoch [48/50], Step [602/735], Loss: 0.0386\n",
      "Epoch [48/50], Step [603/735], Loss: 0.0555\n",
      "Epoch [48/50], Step [604/735], Loss: 0.0502\n",
      "Epoch [48/50], Step [605/735], Loss: 0.0653\n",
      "Epoch [48/50], Step [606/735], Loss: 0.1070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Step [607/735], Loss: 0.0681\n",
      "Epoch [48/50], Step [608/735], Loss: 0.0350\n",
      "Epoch [48/50], Step [609/735], Loss: 0.0554\n",
      "Epoch [48/50], Step [610/735], Loss: 0.0459\n",
      "Epoch [48/50], Step [611/735], Loss: 0.0466\n",
      "Epoch [48/50], Step [612/735], Loss: 0.0366\n",
      "Epoch [48/50], Step [613/735], Loss: 0.1236\n",
      "Epoch [48/50], Step [614/735], Loss: 0.2217\n",
      "Epoch [48/50], Step [615/735], Loss: 0.0898\n",
      "Epoch [48/50], Step [616/735], Loss: 0.2606\n",
      "Epoch [48/50], Step [617/735], Loss: 0.0806\n",
      "Epoch [48/50], Step [618/735], Loss: 0.0886\n",
      "Epoch [48/50], Step [619/735], Loss: 0.0676\n",
      "Epoch [48/50], Step [620/735], Loss: 0.0508\n",
      "Epoch [48/50], Step [621/735], Loss: 0.1955\n",
      "Epoch [48/50], Step [622/735], Loss: 0.1031\n",
      "Epoch [48/50], Step [623/735], Loss: 0.1324\n",
      "Epoch [48/50], Step [624/735], Loss: 0.0625\n",
      "Epoch [48/50], Step [625/735], Loss: 0.0971\n",
      "Epoch [48/50], Step [626/735], Loss: 0.0811\n",
      "Epoch [48/50], Step [627/735], Loss: 0.0545\n",
      "Epoch [48/50], Step [628/735], Loss: 0.1112\n",
      "Epoch [48/50], Step [629/735], Loss: 0.1255\n",
      "Epoch [48/50], Step [630/735], Loss: 0.0517\n",
      "Epoch [48/50], Step [631/735], Loss: 0.2532\n",
      "Epoch [48/50], Step [632/735], Loss: 2.5807\n",
      "Epoch [48/50], Step [633/735], Loss: 0.4143\n",
      "Epoch [48/50], Step [634/735], Loss: 0.1784\n",
      "Epoch [48/50], Step [635/735], Loss: 0.1158\n",
      "Epoch [48/50], Step [636/735], Loss: 0.0580\n",
      "Epoch [48/50], Step [637/735], Loss: 0.1107\n",
      "Epoch [48/50], Step [638/735], Loss: 0.4263\n",
      "Epoch [48/50], Step [639/735], Loss: 0.1620\n",
      "Epoch [48/50], Step [640/735], Loss: 0.0656\n",
      "Epoch [48/50], Step [641/735], Loss: 0.0558\n",
      "Epoch [48/50], Step [642/735], Loss: 0.0421\n",
      "Epoch [48/50], Step [643/735], Loss: 0.4665\n",
      "Epoch [48/50], Step [644/735], Loss: 0.1477\n",
      "Epoch [48/50], Step [645/735], Loss: 0.0729\n",
      "Epoch [48/50], Step [646/735], Loss: 0.0768\n",
      "Epoch [48/50], Step [647/735], Loss: 0.1205\n",
      "Epoch [48/50], Step [648/735], Loss: 0.0874\n",
      "Epoch [48/50], Step [649/735], Loss: 0.1610\n",
      "Epoch [48/50], Step [650/735], Loss: 0.1264\n",
      "Epoch [48/50], Step [651/735], Loss: 0.0962\n",
      "Epoch [48/50], Step [652/735], Loss: 0.2281\n",
      "Epoch [48/50], Step [653/735], Loss: 0.0691\n",
      "Epoch [48/50], Step [654/735], Loss: 0.1528\n",
      "Epoch [48/50], Step [655/735], Loss: 1.5431\n",
      "Epoch [48/50], Step [656/735], Loss: 0.1067\n",
      "Epoch [48/50], Step [657/735], Loss: 0.1420\n",
      "Epoch [48/50], Step [658/735], Loss: 0.1073\n",
      "Epoch [48/50], Step [659/735], Loss: 0.1643\n",
      "Epoch [48/50], Step [660/735], Loss: 0.1056\n",
      "Epoch [48/50], Step [661/735], Loss: 0.8590\n",
      "Epoch [48/50], Step [662/735], Loss: 0.1087\n",
      "Epoch [48/50], Step [663/735], Loss: 0.1333\n",
      "Epoch [48/50], Step [664/735], Loss: 0.1642\n",
      "Epoch [48/50], Step [665/735], Loss: 0.0870\n",
      "Epoch [48/50], Step [666/735], Loss: 0.2020\n",
      "Epoch [48/50], Step [667/735], Loss: 0.1140\n",
      "Epoch [48/50], Step [668/735], Loss: 0.1043\n",
      "Epoch [48/50], Step [669/735], Loss: 0.0458\n",
      "Epoch [48/50], Step [670/735], Loss: 0.1106\n",
      "Epoch [48/50], Step [671/735], Loss: 0.1516\n",
      "Epoch [48/50], Step [672/735], Loss: 0.3185\n",
      "Epoch [48/50], Step [673/735], Loss: 0.3206\n",
      "Epoch [48/50], Step [674/735], Loss: 0.0809\n",
      "Epoch [48/50], Step [675/735], Loss: 0.0694\n",
      "Epoch [48/50], Step [676/735], Loss: 0.0906\n",
      "Epoch [48/50], Step [677/735], Loss: 0.2607\n",
      "Epoch [48/50], Step [678/735], Loss: 0.0899\n",
      "Epoch [48/50], Step [679/735], Loss: 0.0942\n",
      "Epoch [48/50], Step [680/735], Loss: 0.0816\n",
      "Epoch [48/50], Step [681/735], Loss: 0.1509\n",
      "Epoch [48/50], Step [682/735], Loss: 0.1349\n",
      "Epoch [48/50], Step [683/735], Loss: 0.0769\n",
      "Epoch [48/50], Step [684/735], Loss: 0.0688\n",
      "Epoch [48/50], Step [685/735], Loss: 0.2439\n",
      "Epoch [48/50], Step [686/735], Loss: 0.1104\n",
      "Epoch [48/50], Step [687/735], Loss: 0.2106\n",
      "Epoch [48/50], Step [688/735], Loss: 0.0420\n",
      "Epoch [48/50], Step [689/735], Loss: 0.1280\n",
      "Epoch [48/50], Step [690/735], Loss: 0.0778\n",
      "Epoch [48/50], Step [691/735], Loss: 0.0661\n",
      "Epoch [48/50], Step [692/735], Loss: 0.0825\n",
      "Epoch [48/50], Step [693/735], Loss: 0.0708\n",
      "Epoch [48/50], Step [694/735], Loss: 0.0635\n",
      "Epoch [48/50], Step [695/735], Loss: 0.1338\n",
      "Epoch [48/50], Step [696/735], Loss: 0.0716\n",
      "Epoch [48/50], Step [697/735], Loss: 0.0510\n",
      "Epoch [48/50], Step [698/735], Loss: 0.0531\n",
      "Epoch [48/50], Step [699/735], Loss: 0.1723\n",
      "Epoch [48/50], Step [700/735], Loss: 0.0602\n",
      "Epoch [48/50], Step [701/735], Loss: 0.0838\n",
      "Epoch [48/50], Step [702/735], Loss: 0.0367\n",
      "Epoch [48/50], Step [703/735], Loss: 0.0568\n",
      "Epoch [48/50], Step [704/735], Loss: 0.1732\n",
      "Epoch [48/50], Step [705/735], Loss: 0.0753\n",
      "Epoch [48/50], Step [706/735], Loss: 0.0913\n",
      "Epoch [48/50], Step [707/735], Loss: 0.1072\n",
      "Epoch [48/50], Step [708/735], Loss: 0.1204\n",
      "Epoch [48/50], Step [709/735], Loss: 0.0793\n",
      "Epoch [48/50], Step [710/735], Loss: 0.1011\n",
      "Epoch [48/50], Step [711/735], Loss: 0.1926\n",
      "Epoch [48/50], Step [712/735], Loss: 0.4546\n",
      "Epoch [48/50], Step [713/735], Loss: 0.0819\n",
      "Epoch [48/50], Step [714/735], Loss: 0.0295\n",
      "Epoch [48/50], Step [715/735], Loss: 0.0529\n",
      "Epoch [48/50], Step [716/735], Loss: 0.0880\n",
      "Epoch [48/50], Step [717/735], Loss: 0.1283\n",
      "Epoch [48/50], Step [718/735], Loss: 0.0739\n",
      "Epoch [48/50], Step [719/735], Loss: 0.0759\n",
      "Epoch [48/50], Step [720/735], Loss: 0.1977\n",
      "Epoch [48/50], Step [721/735], Loss: 0.0848\n",
      "Epoch [48/50], Step [722/735], Loss: 0.1101\n",
      "Epoch [48/50], Step [723/735], Loss: 0.0319\n",
      "Epoch [48/50], Step [724/735], Loss: 0.0621\n",
      "Epoch [48/50], Step [725/735], Loss: 0.0230\n",
      "Epoch [48/50], Step [726/735], Loss: 0.0631\n",
      "Epoch [48/50], Step [727/735], Loss: 0.1115\n",
      "Epoch [48/50], Step [728/735], Loss: 0.1172\n",
      "Epoch [48/50], Step [729/735], Loss: 0.0582\n",
      "Epoch [48/50], Step [730/735], Loss: 0.0711\n",
      "Epoch [48/50], Step [731/735], Loss: 0.0817\n",
      "Epoch [48/50], Step [732/735], Loss: 0.0500\n",
      "Epoch [48/50], Step [733/735], Loss: 0.8288\n",
      "Epoch [48/50], Step [734/735], Loss: 0.0782\n",
      "Epoch [48/50], Step [735/735], Loss: 0.1766\n",
      "Epoch [49/50], Step [1/735], Loss: 0.1811\n",
      "Epoch [49/50], Step [2/735], Loss: 0.1334\n",
      "Epoch [49/50], Step [3/735], Loss: 0.1419\n",
      "Epoch [49/50], Step [4/735], Loss: 0.1020\n",
      "Epoch [49/50], Step [5/735], Loss: 0.3133\n",
      "Epoch [49/50], Step [6/735], Loss: 0.1144\n",
      "Epoch [49/50], Step [7/735], Loss: 1.4936\n",
      "Epoch [49/50], Step [8/735], Loss: 1.4288\n",
      "Epoch [49/50], Step [9/735], Loss: 0.1455\n",
      "Epoch [49/50], Step [10/735], Loss: 0.1516\n",
      "Epoch [49/50], Step [11/735], Loss: 0.1069\n",
      "Epoch [49/50], Step [12/735], Loss: 0.4647\n",
      "Epoch [49/50], Step [13/735], Loss: 0.1038\n",
      "Epoch [49/50], Step [14/735], Loss: 0.1244\n",
      "Epoch [49/50], Step [15/735], Loss: 0.1162\n",
      "Epoch [49/50], Step [16/735], Loss: 0.2450\n",
      "Epoch [49/50], Step [17/735], Loss: 0.0679\n",
      "Epoch [49/50], Step [18/735], Loss: 0.6450\n",
      "Epoch [49/50], Step [19/735], Loss: 0.1148\n",
      "Epoch [49/50], Step [20/735], Loss: 0.0859\n",
      "Epoch [49/50], Step [21/735], Loss: 0.1524\n",
      "Epoch [49/50], Step [22/735], Loss: 0.2329\n",
      "Epoch [49/50], Step [23/735], Loss: 0.0391\n",
      "Epoch [49/50], Step [24/735], Loss: 0.0739\n",
      "Epoch [49/50], Step [25/735], Loss: 0.0656\n",
      "Epoch [49/50], Step [26/735], Loss: 0.0539\n",
      "Epoch [49/50], Step [27/735], Loss: 0.0682\n",
      "Epoch [49/50], Step [28/735], Loss: 0.0860\n",
      "Epoch [49/50], Step [29/735], Loss: 0.0991\n",
      "Epoch [49/50], Step [30/735], Loss: 0.1403\n",
      "Epoch [49/50], Step [31/735], Loss: 0.1030\n",
      "Epoch [49/50], Step [32/735], Loss: 0.0666\n",
      "Epoch [49/50], Step [33/735], Loss: 0.0549\n",
      "Epoch [49/50], Step [34/735], Loss: 0.0591\n",
      "Epoch [49/50], Step [35/735], Loss: 0.0780\n",
      "Epoch [49/50], Step [36/735], Loss: 0.0314\n",
      "Epoch [49/50], Step [37/735], Loss: 0.2395\n",
      "Epoch [49/50], Step [38/735], Loss: 0.0952\n",
      "Epoch [49/50], Step [39/735], Loss: 0.0327\n",
      "Epoch [49/50], Step [40/735], Loss: 0.0544\n",
      "Epoch [49/50], Step [41/735], Loss: 0.0912\n",
      "Epoch [49/50], Step [42/735], Loss: 0.0821\n",
      "Epoch [49/50], Step [43/735], Loss: 0.0506\n",
      "Epoch [49/50], Step [44/735], Loss: 0.0900\n",
      "Epoch [49/50], Step [45/735], Loss: 0.2197\n",
      "Epoch [49/50], Step [46/735], Loss: 0.0984\n",
      "Epoch [49/50], Step [47/735], Loss: 0.0303\n",
      "Epoch [49/50], Step [48/735], Loss: 0.0973\n",
      "Epoch [49/50], Step [49/735], Loss: 0.0836\n",
      "Epoch [49/50], Step [50/735], Loss: 0.2245\n",
      "Epoch [49/50], Step [51/735], Loss: 0.2378\n",
      "Epoch [49/50], Step [52/735], Loss: 0.0338\n",
      "Epoch [49/50], Step [53/735], Loss: 0.2240\n",
      "Epoch [49/50], Step [54/735], Loss: 0.1258\n",
      "Epoch [49/50], Step [55/735], Loss: 0.1069\n",
      "Epoch [49/50], Step [56/735], Loss: 0.0446\n",
      "Epoch [49/50], Step [57/735], Loss: 0.0891\n",
      "Epoch [49/50], Step [58/735], Loss: 0.1025\n",
      "Epoch [49/50], Step [59/735], Loss: 0.0780\n",
      "Epoch [49/50], Step [60/735], Loss: 0.1007\n",
      "Epoch [49/50], Step [61/735], Loss: 0.0611\n",
      "Epoch [49/50], Step [62/735], Loss: 0.0788\n",
      "Epoch [49/50], Step [63/735], Loss: 0.0691\n",
      "Epoch [49/50], Step [64/735], Loss: 0.0780\n",
      "Epoch [49/50], Step [65/735], Loss: 0.0725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Step [66/735], Loss: 0.1078\n",
      "Epoch [49/50], Step [67/735], Loss: 0.0496\n",
      "Epoch [49/50], Step [68/735], Loss: 0.0569\n",
      "Epoch [49/50], Step [69/735], Loss: 0.2533\n",
      "Epoch [49/50], Step [70/735], Loss: 0.0802\n",
      "Epoch [49/50], Step [71/735], Loss: 0.0618\n",
      "Epoch [49/50], Step [72/735], Loss: 0.0570\n",
      "Epoch [49/50], Step [73/735], Loss: 0.1507\n",
      "Epoch [49/50], Step [74/735], Loss: 0.0720\n",
      "Epoch [49/50], Step [75/735], Loss: 0.0619\n",
      "Epoch [49/50], Step [76/735], Loss: 0.1113\n",
      "Epoch [49/50], Step [77/735], Loss: 0.0617\n",
      "Epoch [49/50], Step [78/735], Loss: 0.0958\n",
      "Epoch [49/50], Step [79/735], Loss: 0.0474\n",
      "Epoch [49/50], Step [80/735], Loss: 0.0902\n",
      "Epoch [49/50], Step [81/735], Loss: 0.0753\n",
      "Epoch [49/50], Step [82/735], Loss: 0.0369\n",
      "Epoch [49/50], Step [83/735], Loss: 0.0940\n",
      "Epoch [49/50], Step [84/735], Loss: 0.6293\n",
      "Epoch [49/50], Step [85/735], Loss: 0.1350\n",
      "Epoch [49/50], Step [86/735], Loss: 0.0594\n",
      "Epoch [49/50], Step [87/735], Loss: 0.1255\n",
      "Epoch [49/50], Step [88/735], Loss: 0.0546\n",
      "Epoch [49/50], Step [89/735], Loss: 0.2838\n",
      "Epoch [49/50], Step [90/735], Loss: 0.0838\n",
      "Epoch [49/50], Step [91/735], Loss: 0.0452\n",
      "Epoch [49/50], Step [92/735], Loss: 0.1078\n",
      "Epoch [49/50], Step [93/735], Loss: 0.0574\n",
      "Epoch [49/50], Step [94/735], Loss: 0.0461\n",
      "Epoch [49/50], Step [95/735], Loss: 0.1063\n",
      "Epoch [49/50], Step [96/735], Loss: 0.0462\n",
      "Epoch [49/50], Step [97/735], Loss: 0.0864\n",
      "Epoch [49/50], Step [98/735], Loss: 0.0457\n",
      "Epoch [49/50], Step [99/735], Loss: 0.1407\n",
      "Epoch [49/50], Step [100/735], Loss: 0.0474\n",
      "Epoch [49/50], Step [101/735], Loss: 0.1002\n",
      "Epoch [49/50], Step [102/735], Loss: 0.0396\n",
      "Epoch [49/50], Step [103/735], Loss: 0.0892\n",
      "Epoch [49/50], Step [104/735], Loss: 0.0340\n",
      "Epoch [49/50], Step [105/735], Loss: 0.0414\n",
      "Epoch [49/50], Step [106/735], Loss: 0.1439\n",
      "Epoch [49/50], Step [107/735], Loss: 0.0491\n",
      "Epoch [49/50], Step [108/735], Loss: 0.1090\n",
      "Epoch [49/50], Step [109/735], Loss: 0.1138\n",
      "Epoch [49/50], Step [110/735], Loss: 0.0468\n",
      "Epoch [49/50], Step [111/735], Loss: 0.0677\n",
      "Epoch [49/50], Step [112/735], Loss: 0.0778\n",
      "Epoch [49/50], Step [113/735], Loss: 0.0951\n",
      "Epoch [49/50], Step [114/735], Loss: 0.0648\n",
      "Epoch [49/50], Step [115/735], Loss: 0.1058\n",
      "Epoch [49/50], Step [116/735], Loss: 0.0596\n",
      "Epoch [49/50], Step [117/735], Loss: 0.0564\n",
      "Epoch [49/50], Step [118/735], Loss: 0.0743\n",
      "Epoch [49/50], Step [119/735], Loss: 0.0482\n",
      "Epoch [49/50], Step [120/735], Loss: 0.0303\n",
      "Epoch [49/50], Step [121/735], Loss: 0.0319\n",
      "Epoch [49/50], Step [122/735], Loss: 0.0859\n",
      "Epoch [49/50], Step [123/735], Loss: 0.0520\n",
      "Epoch [49/50], Step [124/735], Loss: 0.0704\n",
      "Epoch [49/50], Step [125/735], Loss: 0.1120\n",
      "Epoch [49/50], Step [126/735], Loss: 0.0900\n",
      "Epoch [49/50], Step [127/735], Loss: 0.8128\n",
      "Epoch [49/50], Step [128/735], Loss: 0.0709\n",
      "Epoch [49/50], Step [129/735], Loss: 0.3301\n",
      "Epoch [49/50], Step [130/735], Loss: 0.0686\n",
      "Epoch [49/50], Step [131/735], Loss: 0.0445\n",
      "Epoch [49/50], Step [132/735], Loss: 0.0982\n",
      "Epoch [49/50], Step [133/735], Loss: 0.0773\n",
      "Epoch [49/50], Step [134/735], Loss: 0.1468\n",
      "Epoch [49/50], Step [135/735], Loss: 0.0659\n",
      "Epoch [49/50], Step [136/735], Loss: 0.0748\n",
      "Epoch [49/50], Step [137/735], Loss: 0.0737\n",
      "Epoch [49/50], Step [138/735], Loss: 0.0556\n",
      "Epoch [49/50], Step [139/735], Loss: 0.1159\n",
      "Epoch [49/50], Step [140/735], Loss: 0.1020\n",
      "Epoch [49/50], Step [141/735], Loss: 0.1395\n",
      "Epoch [49/50], Step [142/735], Loss: 0.0526\n",
      "Epoch [49/50], Step [143/735], Loss: 0.0995\n",
      "Epoch [49/50], Step [144/735], Loss: 0.1134\n",
      "Epoch [49/50], Step [145/735], Loss: 0.0460\n",
      "Epoch [49/50], Step [146/735], Loss: 0.0538\n",
      "Epoch [49/50], Step [147/735], Loss: 0.0285\n",
      "Epoch [49/50], Step [148/735], Loss: 0.1139\n",
      "Epoch [49/50], Step [149/735], Loss: 0.0688\n",
      "Epoch [49/50], Step [150/735], Loss: 0.1222\n",
      "Epoch [49/50], Step [151/735], Loss: 0.0410\n",
      "Epoch [49/50], Step [152/735], Loss: 0.0400\n",
      "Epoch [49/50], Step [153/735], Loss: 0.0547\n",
      "Epoch [49/50], Step [154/735], Loss: 0.1052\n",
      "Epoch [49/50], Step [155/735], Loss: 0.0523\n",
      "Epoch [49/50], Step [156/735], Loss: 0.0601\n",
      "Epoch [49/50], Step [157/735], Loss: 0.0428\n",
      "Epoch [49/50], Step [158/735], Loss: 0.0920\n",
      "Epoch [49/50], Step [159/735], Loss: 0.8264\n",
      "Epoch [49/50], Step [160/735], Loss: 0.1906\n",
      "Epoch [49/50], Step [161/735], Loss: 0.0697\n",
      "Epoch [49/50], Step [162/735], Loss: 0.4762\n",
      "Epoch [49/50], Step [163/735], Loss: 0.1118\n",
      "Epoch [49/50], Step [164/735], Loss: 0.0577\n",
      "Epoch [49/50], Step [165/735], Loss: 0.0683\n",
      "Epoch [49/50], Step [166/735], Loss: 0.1126\n",
      "Epoch [49/50], Step [167/735], Loss: 0.0553\n",
      "Epoch [49/50], Step [168/735], Loss: 0.1452\n",
      "Epoch [49/50], Step [169/735], Loss: 0.0826\n",
      "Epoch [49/50], Step [170/735], Loss: 0.0430\n",
      "Epoch [49/50], Step [171/735], Loss: 0.1243\n",
      "Epoch [49/50], Step [172/735], Loss: 0.0643\n",
      "Epoch [49/50], Step [173/735], Loss: 0.0334\n",
      "Epoch [49/50], Step [174/735], Loss: 0.0711\n",
      "Epoch [49/50], Step [175/735], Loss: 0.0501\n",
      "Epoch [49/50], Step [176/735], Loss: 0.1377\n",
      "Epoch [49/50], Step [177/735], Loss: 0.0708\n",
      "Epoch [49/50], Step [178/735], Loss: 0.3781\n",
      "Epoch [49/50], Step [179/735], Loss: 0.0749\n",
      "Epoch [49/50], Step [180/735], Loss: 0.0521\n",
      "Epoch [49/50], Step [181/735], Loss: 0.0438\n",
      "Epoch [49/50], Step [182/735], Loss: 0.0696\n",
      "Epoch [49/50], Step [183/735], Loss: 0.0481\n",
      "Epoch [49/50], Step [184/735], Loss: 0.0481\n",
      "Epoch [49/50], Step [185/735], Loss: 0.1593\n",
      "Epoch [49/50], Step [186/735], Loss: 0.0627\n",
      "Epoch [49/50], Step [187/735], Loss: 0.0725\n",
      "Epoch [49/50], Step [188/735], Loss: 0.0487\n",
      "Epoch [49/50], Step [189/735], Loss: 0.1366\n",
      "Epoch [49/50], Step [190/735], Loss: 0.4185\n",
      "Epoch [49/50], Step [191/735], Loss: 0.2095\n",
      "Epoch [49/50], Step [192/735], Loss: 0.1152\n",
      "Epoch [49/50], Step [193/735], Loss: 0.1362\n",
      "Epoch [49/50], Step [194/735], Loss: 0.1248\n",
      "Epoch [49/50], Step [195/735], Loss: 0.0942\n",
      "Epoch [49/50], Step [196/735], Loss: 0.0998\n",
      "Epoch [49/50], Step [197/735], Loss: 0.0242\n",
      "Epoch [49/50], Step [198/735], Loss: 0.0927\n",
      "Epoch [49/50], Step [199/735], Loss: 0.1535\n",
      "Epoch [49/50], Step [200/735], Loss: 0.0763\n",
      "Epoch [49/50], Step [201/735], Loss: 0.0976\n",
      "Epoch [49/50], Step [202/735], Loss: 0.1339\n",
      "Epoch [49/50], Step [203/735], Loss: 0.0522\n",
      "Epoch [49/50], Step [204/735], Loss: 0.1188\n",
      "Epoch [49/50], Step [205/735], Loss: 0.0650\n",
      "Epoch [49/50], Step [206/735], Loss: 0.0769\n",
      "Epoch [49/50], Step [207/735], Loss: 0.1160\n",
      "Epoch [49/50], Step [208/735], Loss: 0.0713\n",
      "Epoch [49/50], Step [209/735], Loss: 0.0498\n",
      "Epoch [49/50], Step [210/735], Loss: 0.1202\n",
      "Epoch [49/50], Step [211/735], Loss: 0.0482\n",
      "Epoch [49/50], Step [212/735], Loss: 0.0494\n",
      "Epoch [49/50], Step [213/735], Loss: 0.1905\n",
      "Epoch [49/50], Step [214/735], Loss: 0.0500\n",
      "Epoch [49/50], Step [215/735], Loss: 0.0383\n",
      "Epoch [49/50], Step [216/735], Loss: 0.0739\n",
      "Epoch [49/50], Step [217/735], Loss: 0.0804\n",
      "Epoch [49/50], Step [218/735], Loss: 0.2794\n",
      "Epoch [49/50], Step [219/735], Loss: 0.2789\n",
      "Epoch [49/50], Step [220/735], Loss: 0.1271\n",
      "Epoch [49/50], Step [221/735], Loss: 0.1659\n",
      "Epoch [49/50], Step [222/735], Loss: 0.0883\n",
      "Epoch [49/50], Step [223/735], Loss: 0.0500\n",
      "Epoch [49/50], Step [224/735], Loss: 0.0360\n",
      "Epoch [49/50], Step [225/735], Loss: 0.2758\n",
      "Epoch [49/50], Step [226/735], Loss: 0.0738\n",
      "Epoch [49/50], Step [227/735], Loss: 0.0728\n",
      "Epoch [49/50], Step [228/735], Loss: 0.1290\n",
      "Epoch [49/50], Step [229/735], Loss: 0.1128\n",
      "Epoch [49/50], Step [230/735], Loss: 0.0805\n",
      "Epoch [49/50], Step [231/735], Loss: 0.1071\n",
      "Epoch [49/50], Step [232/735], Loss: 0.1364\n",
      "Epoch [49/50], Step [233/735], Loss: 0.0611\n",
      "Epoch [49/50], Step [234/735], Loss: 0.0336\n",
      "Epoch [49/50], Step [235/735], Loss: 0.0856\n",
      "Epoch [49/50], Step [236/735], Loss: 0.0517\n",
      "Epoch [49/50], Step [237/735], Loss: 0.0937\n",
      "Epoch [49/50], Step [238/735], Loss: 0.0574\n",
      "Epoch [49/50], Step [239/735], Loss: 0.0679\n",
      "Epoch [49/50], Step [240/735], Loss: 0.0510\n",
      "Epoch [49/50], Step [241/735], Loss: 0.0649\n",
      "Epoch [49/50], Step [242/735], Loss: 0.0664\n",
      "Epoch [49/50], Step [243/735], Loss: 0.0942\n",
      "Epoch [49/50], Step [244/735], Loss: 0.0306\n",
      "Epoch [49/50], Step [245/735], Loss: 0.0481\n",
      "Epoch [49/50], Step [246/735], Loss: 0.1043\n",
      "Epoch [49/50], Step [247/735], Loss: 0.0405\n",
      "Epoch [49/50], Step [248/735], Loss: 0.0736\n",
      "Epoch [49/50], Step [249/735], Loss: 0.1718\n",
      "Epoch [49/50], Step [250/735], Loss: 0.0462\n",
      "Epoch [49/50], Step [251/735], Loss: 0.0513\n",
      "Epoch [49/50], Step [252/735], Loss: 0.0394\n",
      "Epoch [49/50], Step [253/735], Loss: 0.0344\n",
      "Epoch [49/50], Step [254/735], Loss: 0.0845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Step [255/735], Loss: 0.0381\n",
      "Epoch [49/50], Step [256/735], Loss: 0.0865\n",
      "Epoch [49/50], Step [257/735], Loss: 0.0647\n",
      "Epoch [49/50], Step [258/735], Loss: 0.1027\n",
      "Epoch [49/50], Step [259/735], Loss: 0.0747\n",
      "Epoch [49/50], Step [260/735], Loss: 0.0873\n",
      "Epoch [49/50], Step [261/735], Loss: 0.1109\n",
      "Epoch [49/50], Step [262/735], Loss: 0.0793\n",
      "Epoch [49/50], Step [263/735], Loss: 0.0695\n",
      "Epoch [49/50], Step [264/735], Loss: 0.1091\n",
      "Epoch [49/50], Step [265/735], Loss: 0.0453\n",
      "Epoch [49/50], Step [266/735], Loss: 0.0429\n",
      "Epoch [49/50], Step [267/735], Loss: 0.1185\n",
      "Epoch [49/50], Step [268/735], Loss: 0.0643\n",
      "Epoch [49/50], Step [269/735], Loss: 0.0507\n",
      "Epoch [49/50], Step [270/735], Loss: 0.0502\n",
      "Epoch [49/50], Step [271/735], Loss: 0.0331\n",
      "Epoch [49/50], Step [272/735], Loss: 0.0539\n",
      "Epoch [49/50], Step [273/735], Loss: 0.0668\n",
      "Epoch [49/50], Step [274/735], Loss: 0.3903\n",
      "Epoch [49/50], Step [275/735], Loss: 0.0741\n",
      "Epoch [49/50], Step [276/735], Loss: 0.0773\n",
      "Epoch [49/50], Step [277/735], Loss: 0.1192\n",
      "Epoch [49/50], Step [278/735], Loss: 0.1361\n",
      "Epoch [49/50], Step [279/735], Loss: 0.0394\n",
      "Epoch [49/50], Step [280/735], Loss: 0.0372\n",
      "Epoch [49/50], Step [281/735], Loss: 0.0885\n",
      "Epoch [49/50], Step [282/735], Loss: 0.0632\n",
      "Epoch [49/50], Step [283/735], Loss: 0.0448\n",
      "Epoch [49/50], Step [284/735], Loss: 0.0596\n",
      "Epoch [49/50], Step [285/735], Loss: 0.0483\n",
      "Epoch [49/50], Step [286/735], Loss: 0.0480\n",
      "Epoch [49/50], Step [287/735], Loss: 0.0714\n",
      "Epoch [49/50], Step [288/735], Loss: 0.0327\n",
      "Epoch [49/50], Step [289/735], Loss: 0.2325\n",
      "Epoch [49/50], Step [290/735], Loss: 0.0498\n",
      "Epoch [49/50], Step [291/735], Loss: 0.0819\n",
      "Epoch [49/50], Step [292/735], Loss: 0.1233\n",
      "Epoch [49/50], Step [293/735], Loss: 0.0607\n",
      "Epoch [49/50], Step [294/735], Loss: 0.0472\n",
      "Epoch [49/50], Step [295/735], Loss: 0.0326\n",
      "Epoch [49/50], Step [296/735], Loss: 0.6447\n",
      "Epoch [49/50], Step [297/735], Loss: 0.1065\n",
      "Epoch [49/50], Step [298/735], Loss: 0.1391\n",
      "Epoch [49/50], Step [299/735], Loss: 0.0704\n",
      "Epoch [49/50], Step [300/735], Loss: 0.0441\n",
      "Epoch [49/50], Step [301/735], Loss: 0.0380\n",
      "Epoch [49/50], Step [302/735], Loss: 1.5960\n",
      "Epoch [49/50], Step [303/735], Loss: 1.5211\n",
      "Epoch [49/50], Step [304/735], Loss: 0.0630\n",
      "Epoch [49/50], Step [305/735], Loss: 0.1369\n",
      "Epoch [49/50], Step [306/735], Loss: 0.0289\n",
      "Epoch [49/50], Step [307/735], Loss: 0.0720\n",
      "Epoch [49/50], Step [308/735], Loss: 0.0289\n",
      "Epoch [49/50], Step [309/735], Loss: 0.0408\n",
      "Epoch [49/50], Step [310/735], Loss: 0.0323\n",
      "Epoch [49/50], Step [311/735], Loss: 0.8074\n",
      "Epoch [49/50], Step [312/735], Loss: 0.1464\n",
      "Epoch [49/50], Step [313/735], Loss: 0.2000\n",
      "Epoch [49/50], Step [314/735], Loss: 0.0899\n",
      "Epoch [49/50], Step [315/735], Loss: 0.2103\n",
      "Epoch [49/50], Step [316/735], Loss: 0.0487\n",
      "Epoch [49/50], Step [317/735], Loss: 0.3056\n",
      "Epoch [49/50], Step [318/735], Loss: 0.0687\n",
      "Epoch [49/50], Step [319/735], Loss: 0.0848\n",
      "Epoch [49/50], Step [320/735], Loss: 0.0614\n",
      "Epoch [49/50], Step [321/735], Loss: 0.0284\n",
      "Epoch [49/50], Step [322/735], Loss: 0.0876\n",
      "Epoch [49/50], Step [323/735], Loss: 0.1643\n",
      "Epoch [49/50], Step [324/735], Loss: 0.1365\n",
      "Epoch [49/50], Step [325/735], Loss: 0.0682\n",
      "Epoch [49/50], Step [326/735], Loss: 0.6701\n",
      "Epoch [49/50], Step [327/735], Loss: 0.0699\n",
      "Epoch [49/50], Step [328/735], Loss: 0.1337\n",
      "Epoch [49/50], Step [329/735], Loss: 0.1362\n",
      "Epoch [49/50], Step [330/735], Loss: 0.0440\n",
      "Epoch [49/50], Step [331/735], Loss: 0.0664\n",
      "Epoch [49/50], Step [332/735], Loss: 0.1270\n",
      "Epoch [49/50], Step [333/735], Loss: 0.1238\n",
      "Epoch [49/50], Step [334/735], Loss: 0.1636\n",
      "Epoch [49/50], Step [335/735], Loss: 0.0450\n",
      "Epoch [49/50], Step [336/735], Loss: 0.0735\n",
      "Epoch [49/50], Step [337/735], Loss: 0.0839\n",
      "Epoch [49/50], Step [338/735], Loss: 1.0205\n",
      "Epoch [49/50], Step [339/735], Loss: 0.0672\n",
      "Epoch [49/50], Step [340/735], Loss: 0.0430\n",
      "Epoch [49/50], Step [341/735], Loss: 0.0758\n",
      "Epoch [49/50], Step [342/735], Loss: 0.0551\n",
      "Epoch [49/50], Step [343/735], Loss: 0.0705\n",
      "Epoch [49/50], Step [344/735], Loss: 0.2740\n",
      "Epoch [49/50], Step [345/735], Loss: 0.0503\n",
      "Epoch [49/50], Step [346/735], Loss: 0.1039\n",
      "Epoch [49/50], Step [347/735], Loss: 0.2096\n",
      "Epoch [49/50], Step [348/735], Loss: 0.0373\n",
      "Epoch [49/50], Step [349/735], Loss: 0.0985\n",
      "Epoch [49/50], Step [350/735], Loss: 0.0458\n",
      "Epoch [49/50], Step [351/735], Loss: 0.0738\n",
      "Epoch [49/50], Step [352/735], Loss: 0.0805\n",
      "Epoch [49/50], Step [353/735], Loss: 0.2171\n",
      "Epoch [49/50], Step [354/735], Loss: 0.0447\n",
      "Epoch [49/50], Step [355/735], Loss: 0.1021\n",
      "Epoch [49/50], Step [356/735], Loss: 0.0745\n",
      "Epoch [49/50], Step [357/735], Loss: 0.0605\n",
      "Epoch [49/50], Step [358/735], Loss: 0.1016\n",
      "Epoch [49/50], Step [359/735], Loss: 0.0866\n",
      "Epoch [49/50], Step [360/735], Loss: 0.1838\n",
      "Epoch [49/50], Step [361/735], Loss: 0.0506\n",
      "Epoch [49/50], Step [362/735], Loss: 0.0621\n",
      "Epoch [49/50], Step [363/735], Loss: 0.0552\n",
      "Epoch [49/50], Step [364/735], Loss: 0.0701\n",
      "Epoch [49/50], Step [365/735], Loss: 0.0314\n",
      "Epoch [49/50], Step [366/735], Loss: 0.2913\n",
      "Epoch [49/50], Step [367/735], Loss: 0.1390\n",
      "Epoch [49/50], Step [368/735], Loss: 0.0580\n",
      "Epoch [49/50], Step [369/735], Loss: 0.0481\n",
      "Epoch [49/50], Step [370/735], Loss: 0.0301\n",
      "Epoch [49/50], Step [371/735], Loss: 0.1343\n",
      "Epoch [49/50], Step [372/735], Loss: 0.0729\n",
      "Epoch [49/50], Step [373/735], Loss: 0.1245\n",
      "Epoch [49/50], Step [374/735], Loss: 0.0653\n",
      "Epoch [49/50], Step [375/735], Loss: 0.0595\n",
      "Epoch [49/50], Step [376/735], Loss: 0.0442\n",
      "Epoch [49/50], Step [377/735], Loss: 0.0757\n",
      "Epoch [49/50], Step [378/735], Loss: 0.1044\n",
      "Epoch [49/50], Step [379/735], Loss: 0.0983\n",
      "Epoch [49/50], Step [380/735], Loss: 0.7594\n",
      "Epoch [49/50], Step [381/735], Loss: 0.0518\n",
      "Epoch [49/50], Step [382/735], Loss: 0.0637\n",
      "Epoch [49/50], Step [383/735], Loss: 0.0492\n",
      "Epoch [49/50], Step [384/735], Loss: 0.0820\n",
      "Epoch [49/50], Step [385/735], Loss: 0.0627\n",
      "Epoch [49/50], Step [386/735], Loss: 0.0484\n",
      "Epoch [49/50], Step [387/735], Loss: 0.0451\n",
      "Epoch [49/50], Step [388/735], Loss: 0.1073\n",
      "Epoch [49/50], Step [389/735], Loss: 0.0834\n",
      "Epoch [49/50], Step [390/735], Loss: 0.0793\n",
      "Epoch [49/50], Step [391/735], Loss: 0.1016\n",
      "Epoch [49/50], Step [392/735], Loss: 0.0877\n",
      "Epoch [49/50], Step [393/735], Loss: 0.1927\n",
      "Epoch [49/50], Step [394/735], Loss: 0.0429\n",
      "Epoch [49/50], Step [395/735], Loss: 0.0830\n",
      "Epoch [49/50], Step [396/735], Loss: 0.1618\n",
      "Epoch [49/50], Step [397/735], Loss: 0.0988\n",
      "Epoch [49/50], Step [398/735], Loss: 0.0632\n",
      "Epoch [49/50], Step [399/735], Loss: 0.0897\n",
      "Epoch [49/50], Step [400/735], Loss: 0.0617\n",
      "Epoch [49/50], Step [401/735], Loss: 0.0459\n",
      "Epoch [49/50], Step [402/735], Loss: 0.1776\n",
      "Epoch [49/50], Step [403/735], Loss: 0.2234\n",
      "Epoch [49/50], Step [404/735], Loss: 0.1209\n",
      "Epoch [49/50], Step [405/735], Loss: 0.1307\n",
      "Epoch [49/50], Step [406/735], Loss: 0.1207\n",
      "Epoch [49/50], Step [407/735], Loss: 0.0538\n",
      "Epoch [49/50], Step [408/735], Loss: 0.0766\n",
      "Epoch [49/50], Step [409/735], Loss: 0.0955\n",
      "Epoch [49/50], Step [410/735], Loss: 0.0936\n",
      "Epoch [49/50], Step [411/735], Loss: 0.1392\n",
      "Epoch [49/50], Step [412/735], Loss: 0.0933\n",
      "Epoch [49/50], Step [413/735], Loss: 0.0445\n",
      "Epoch [49/50], Step [414/735], Loss: 0.1609\n",
      "Epoch [49/50], Step [415/735], Loss: 0.1227\n",
      "Epoch [49/50], Step [416/735], Loss: 0.3064\n",
      "Epoch [49/50], Step [417/735], Loss: 0.5040\n",
      "Epoch [49/50], Step [418/735], Loss: 0.0679\n",
      "Epoch [49/50], Step [419/735], Loss: 0.0611\n",
      "Epoch [49/50], Step [420/735], Loss: 0.1094\n",
      "Epoch [49/50], Step [421/735], Loss: 0.2056\n",
      "Epoch [49/50], Step [422/735], Loss: 0.0621\n",
      "Epoch [49/50], Step [423/735], Loss: 0.0611\n",
      "Epoch [49/50], Step [424/735], Loss: 0.1833\n",
      "Epoch [49/50], Step [425/735], Loss: 0.0753\n",
      "Epoch [49/50], Step [426/735], Loss: 0.1131\n",
      "Epoch [49/50], Step [427/735], Loss: 0.1121\n",
      "Epoch [49/50], Step [428/735], Loss: 0.0717\n",
      "Epoch [49/50], Step [429/735], Loss: 0.0711\n",
      "Epoch [49/50], Step [430/735], Loss: 0.0815\n",
      "Epoch [49/50], Step [431/735], Loss: 0.0837\n",
      "Epoch [49/50], Step [432/735], Loss: 0.1316\n",
      "Epoch [49/50], Step [433/735], Loss: 0.0424\n",
      "Epoch [49/50], Step [434/735], Loss: 0.1074\n",
      "Epoch [49/50], Step [435/735], Loss: 0.1804\n",
      "Epoch [49/50], Step [436/735], Loss: 0.1062\n",
      "Epoch [49/50], Step [437/735], Loss: 0.0883\n",
      "Epoch [49/50], Step [438/735], Loss: 0.0306\n",
      "Epoch [49/50], Step [439/735], Loss: 0.1012\n",
      "Epoch [49/50], Step [440/735], Loss: 0.0514\n",
      "Epoch [49/50], Step [441/735], Loss: 0.0366\n",
      "Epoch [49/50], Step [442/735], Loss: 0.0694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Step [443/735], Loss: 0.0578\n",
      "Epoch [49/50], Step [444/735], Loss: 0.0657\n",
      "Epoch [49/50], Step [445/735], Loss: 0.8936\n",
      "Epoch [49/50], Step [446/735], Loss: 0.1122\n",
      "Epoch [49/50], Step [447/735], Loss: 0.2711\n",
      "Epoch [49/50], Step [448/735], Loss: 0.1253\n",
      "Epoch [49/50], Step [449/735], Loss: 0.1399\n",
      "Epoch [49/50], Step [450/735], Loss: 0.0609\n",
      "Epoch [49/50], Step [451/735], Loss: 0.6618\n",
      "Epoch [49/50], Step [452/735], Loss: 0.1685\n",
      "Epoch [49/50], Step [453/735], Loss: 0.0806\n",
      "Epoch [49/50], Step [454/735], Loss: 0.0564\n",
      "Epoch [49/50], Step [455/735], Loss: 0.3891\n",
      "Epoch [49/50], Step [456/735], Loss: 0.0975\n",
      "Epoch [49/50], Step [457/735], Loss: 0.0944\n",
      "Epoch [49/50], Step [458/735], Loss: 0.1640\n",
      "Epoch [49/50], Step [459/735], Loss: 0.1093\n",
      "Epoch [49/50], Step [460/735], Loss: 0.0575\n",
      "Epoch [49/50], Step [461/735], Loss: 0.0606\n",
      "Epoch [49/50], Step [462/735], Loss: 0.1699\n",
      "Epoch [49/50], Step [463/735], Loss: 0.1082\n",
      "Epoch [49/50], Step [464/735], Loss: 0.0712\n",
      "Epoch [49/50], Step [465/735], Loss: 0.0836\n",
      "Epoch [49/50], Step [466/735], Loss: 0.1896\n",
      "Epoch [49/50], Step [467/735], Loss: 0.0898\n",
      "Epoch [49/50], Step [468/735], Loss: 0.2453\n",
      "Epoch [49/50], Step [469/735], Loss: 0.0803\n",
      "Epoch [49/50], Step [470/735], Loss: 0.1444\n",
      "Epoch [49/50], Step [471/735], Loss: 0.0920\n",
      "Epoch [49/50], Step [472/735], Loss: 0.1679\n",
      "Epoch [49/50], Step [473/735], Loss: 0.0605\n",
      "Epoch [49/50], Step [474/735], Loss: 0.1280\n",
      "Epoch [49/50], Step [475/735], Loss: 0.0748\n",
      "Epoch [49/50], Step [476/735], Loss: 0.1674\n",
      "Epoch [49/50], Step [477/735], Loss: 0.0480\n",
      "Epoch [49/50], Step [478/735], Loss: 0.2079\n",
      "Epoch [49/50], Step [479/735], Loss: 0.0870\n",
      "Epoch [49/50], Step [480/735], Loss: 0.0606\n",
      "Epoch [49/50], Step [481/735], Loss: 0.0906\n",
      "Epoch [49/50], Step [482/735], Loss: 0.0740\n",
      "Epoch [49/50], Step [483/735], Loss: 0.1191\n",
      "Epoch [49/50], Step [484/735], Loss: 0.1071\n",
      "Epoch [49/50], Step [485/735], Loss: 0.1742\n",
      "Epoch [49/50], Step [486/735], Loss: 0.0523\n",
      "Epoch [49/50], Step [487/735], Loss: 0.0753\n",
      "Epoch [49/50], Step [488/735], Loss: 0.1002\n",
      "Epoch [49/50], Step [489/735], Loss: 0.1516\n",
      "Epoch [49/50], Step [490/735], Loss: 0.0885\n",
      "Epoch [49/50], Step [491/735], Loss: 0.0828\n",
      "Epoch [49/50], Step [492/735], Loss: 0.0410\n",
      "Epoch [49/50], Step [493/735], Loss: 0.3265\n",
      "Epoch [49/50], Step [494/735], Loss: 0.1505\n",
      "Epoch [49/50], Step [495/735], Loss: 0.1059\n",
      "Epoch [49/50], Step [496/735], Loss: 0.1006\n",
      "Epoch [49/50], Step [497/735], Loss: 0.0931\n",
      "Epoch [49/50], Step [498/735], Loss: 0.0552\n",
      "Epoch [49/50], Step [499/735], Loss: 0.0958\n",
      "Epoch [49/50], Step [500/735], Loss: 0.1137\n",
      "Epoch [49/50], Step [501/735], Loss: 0.0807\n",
      "Epoch [49/50], Step [502/735], Loss: 0.0711\n",
      "Epoch [49/50], Step [503/735], Loss: 0.0918\n",
      "Epoch [49/50], Step [504/735], Loss: 0.0735\n",
      "Epoch [49/50], Step [505/735], Loss: 0.0719\n",
      "Epoch [49/50], Step [506/735], Loss: 0.3091\n",
      "Epoch [49/50], Step [507/735], Loss: 0.5591\n",
      "Epoch [49/50], Step [508/735], Loss: 0.1003\n",
      "Epoch [49/50], Step [509/735], Loss: 0.5007\n",
      "Epoch [49/50], Step [510/735], Loss: 0.1294\n",
      "Epoch [49/50], Step [511/735], Loss: 0.2155\n",
      "Epoch [49/50], Step [512/735], Loss: 0.0924\n",
      "Epoch [49/50], Step [513/735], Loss: 0.0729\n",
      "Epoch [49/50], Step [514/735], Loss: 0.0919\n",
      "Epoch [49/50], Step [515/735], Loss: 0.1707\n",
      "Epoch [49/50], Step [516/735], Loss: 0.0923\n",
      "Epoch [49/50], Step [517/735], Loss: 0.0816\n",
      "Epoch [49/50], Step [518/735], Loss: 0.1242\n",
      "Epoch [49/50], Step [519/735], Loss: 0.1180\n",
      "Epoch [49/50], Step [520/735], Loss: 0.1499\n",
      "Epoch [49/50], Step [521/735], Loss: 0.1049\n",
      "Epoch [49/50], Step [522/735], Loss: 0.1406\n",
      "Epoch [49/50], Step [523/735], Loss: 0.1276\n",
      "Epoch [49/50], Step [524/735], Loss: 0.0916\n",
      "Epoch [49/50], Step [525/735], Loss: 0.1134\n",
      "Epoch [49/50], Step [526/735], Loss: 0.0757\n",
      "Epoch [49/50], Step [527/735], Loss: 0.0615\n",
      "Epoch [49/50], Step [528/735], Loss: 0.0579\n",
      "Epoch [49/50], Step [529/735], Loss: 0.0780\n",
      "Epoch [49/50], Step [530/735], Loss: 0.1523\n",
      "Epoch [49/50], Step [531/735], Loss: 0.1043\n",
      "Epoch [49/50], Step [532/735], Loss: 0.0324\n",
      "Epoch [49/50], Step [533/735], Loss: 0.1288\n",
      "Epoch [49/50], Step [534/735], Loss: 0.1439\n",
      "Epoch [49/50], Step [535/735], Loss: 0.9233\n",
      "Epoch [49/50], Step [536/735], Loss: 0.1120\n",
      "Epoch [49/50], Step [537/735], Loss: 0.2234\n",
      "Epoch [49/50], Step [538/735], Loss: 0.0502\n",
      "Epoch [49/50], Step [539/735], Loss: 0.0631\n",
      "Epoch [49/50], Step [540/735], Loss: 0.0405\n",
      "Epoch [49/50], Step [541/735], Loss: 0.2760\n",
      "Epoch [49/50], Step [542/735], Loss: 0.1263\n",
      "Epoch [49/50], Step [543/735], Loss: 0.0450\n",
      "Epoch [49/50], Step [544/735], Loss: 0.1226\n",
      "Epoch [49/50], Step [545/735], Loss: 0.1636\n",
      "Epoch [49/50], Step [546/735], Loss: 0.0846\n",
      "Epoch [49/50], Step [547/735], Loss: 0.0914\n",
      "Epoch [49/50], Step [548/735], Loss: 0.0697\n",
      "Epoch [49/50], Step [549/735], Loss: 0.0816\n",
      "Epoch [49/50], Step [550/735], Loss: 0.1159\n",
      "Epoch [49/50], Step [551/735], Loss: 0.0658\n",
      "Epoch [49/50], Step [552/735], Loss: 0.0538\n",
      "Epoch [49/50], Step [553/735], Loss: 0.0332\n",
      "Epoch [49/50], Step [554/735], Loss: 0.0882\n",
      "Epoch [49/50], Step [555/735], Loss: 0.0949\n",
      "Epoch [49/50], Step [556/735], Loss: 0.0913\n",
      "Epoch [49/50], Step [557/735], Loss: 0.1368\n",
      "Epoch [49/50], Step [558/735], Loss: 0.0503\n",
      "Epoch [49/50], Step [559/735], Loss: 0.0895\n",
      "Epoch [49/50], Step [560/735], Loss: 0.1018\n",
      "Epoch [49/50], Step [561/735], Loss: 0.0684\n",
      "Epoch [49/50], Step [562/735], Loss: 0.0699\n",
      "Epoch [49/50], Step [563/735], Loss: 0.2182\n",
      "Epoch [49/50], Step [564/735], Loss: 0.1224\n",
      "Epoch [49/50], Step [565/735], Loss: 0.1891\n",
      "Epoch [49/50], Step [566/735], Loss: 0.1119\n",
      "Epoch [49/50], Step [567/735], Loss: 0.5390\n",
      "Epoch [49/50], Step [568/735], Loss: 0.0525\n",
      "Epoch [49/50], Step [569/735], Loss: 0.0722\n",
      "Epoch [49/50], Step [570/735], Loss: 0.1187\n",
      "Epoch [49/50], Step [571/735], Loss: 0.0489\n",
      "Epoch [49/50], Step [572/735], Loss: 0.0931\n",
      "Epoch [49/50], Step [573/735], Loss: 0.1332\n",
      "Epoch [49/50], Step [574/735], Loss: 0.0807\n",
      "Epoch [49/50], Step [575/735], Loss: 0.0626\n",
      "Epoch [49/50], Step [576/735], Loss: 0.0663\n",
      "Epoch [49/50], Step [577/735], Loss: 0.0938\n",
      "Epoch [49/50], Step [578/735], Loss: 0.0389\n",
      "Epoch [49/50], Step [579/735], Loss: 0.0535\n",
      "Epoch [49/50], Step [580/735], Loss: 0.0418\n",
      "Epoch [49/50], Step [581/735], Loss: 0.1006\n",
      "Epoch [49/50], Step [582/735], Loss: 0.0848\n",
      "Epoch [49/50], Step [583/735], Loss: 0.1080\n",
      "Epoch [49/50], Step [584/735], Loss: 0.9229\n",
      "Epoch [49/50], Step [585/735], Loss: 0.0905\n",
      "Epoch [49/50], Step [586/735], Loss: 0.1913\n",
      "Epoch [49/50], Step [587/735], Loss: 0.0546\n",
      "Epoch [49/50], Step [588/735], Loss: 0.0564\n",
      "Epoch [49/50], Step [589/735], Loss: 0.0875\n",
      "Epoch [49/50], Step [590/735], Loss: 0.1572\n",
      "Epoch [49/50], Step [591/735], Loss: 0.0684\n",
      "Epoch [49/50], Step [592/735], Loss: 0.0997\n",
      "Epoch [49/50], Step [593/735], Loss: 0.1200\n",
      "Epoch [49/50], Step [594/735], Loss: 0.1157\n",
      "Epoch [49/50], Step [595/735], Loss: 0.0972\n",
      "Epoch [49/50], Step [596/735], Loss: 0.1120\n",
      "Epoch [49/50], Step [597/735], Loss: 0.1586\n",
      "Epoch [49/50], Step [598/735], Loss: 0.0642\n",
      "Epoch [49/50], Step [599/735], Loss: 0.0290\n",
      "Epoch [49/50], Step [600/735], Loss: 0.1869\n",
      "Epoch [49/50], Step [601/735], Loss: 0.0795\n",
      "Epoch [49/50], Step [602/735], Loss: 0.0534\n",
      "Epoch [49/50], Step [603/735], Loss: 0.0837\n",
      "Epoch [49/50], Step [604/735], Loss: 0.1535\n",
      "Epoch [49/50], Step [605/735], Loss: 0.0943\n",
      "Epoch [49/50], Step [606/735], Loss: 0.0642\n",
      "Epoch [49/50], Step [607/735], Loss: 0.1389\n",
      "Epoch [49/50], Step [608/735], Loss: 0.0824\n",
      "Epoch [49/50], Step [609/735], Loss: 0.0959\n",
      "Epoch [49/50], Step [610/735], Loss: 0.0668\n",
      "Epoch [49/50], Step [611/735], Loss: 0.1391\n",
      "Epoch [49/50], Step [612/735], Loss: 0.1620\n",
      "Epoch [49/50], Step [613/735], Loss: 0.1026\n",
      "Epoch [49/50], Step [614/735], Loss: 0.1413\n",
      "Epoch [49/50], Step [615/735], Loss: 0.4326\n",
      "Epoch [49/50], Step [616/735], Loss: 0.0983\n",
      "Epoch [49/50], Step [617/735], Loss: 0.0892\n",
      "Epoch [49/50], Step [618/735], Loss: 0.0824\n",
      "Epoch [49/50], Step [619/735], Loss: 0.0731\n",
      "Epoch [49/50], Step [620/735], Loss: 0.0514\n",
      "Epoch [49/50], Step [621/735], Loss: 0.0659\n",
      "Epoch [49/50], Step [622/735], Loss: 0.0685\n",
      "Epoch [49/50], Step [623/735], Loss: 0.3954\n",
      "Epoch [49/50], Step [624/735], Loss: 0.1529\n",
      "Epoch [49/50], Step [625/735], Loss: 0.0305\n",
      "Epoch [49/50], Step [626/735], Loss: 0.1025\n",
      "Epoch [49/50], Step [627/735], Loss: 0.1669\n",
      "Epoch [49/50], Step [628/735], Loss: 0.0858\n",
      "Epoch [49/50], Step [629/735], Loss: 0.1471\n",
      "Epoch [49/50], Step [630/735], Loss: 0.1130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Step [631/735], Loss: 0.1331\n",
      "Epoch [49/50], Step [632/735], Loss: 0.1127\n",
      "Epoch [49/50], Step [633/735], Loss: 0.1287\n",
      "Epoch [49/50], Step [634/735], Loss: 0.0598\n",
      "Epoch [49/50], Step [635/735], Loss: 0.0550\n",
      "Epoch [49/50], Step [636/735], Loss: 0.0379\n",
      "Epoch [49/50], Step [637/735], Loss: 0.1565\n",
      "Epoch [49/50], Step [638/735], Loss: 0.0664\n",
      "Epoch [49/50], Step [639/735], Loss: 0.0750\n",
      "Epoch [49/50], Step [640/735], Loss: 0.1074\n",
      "Epoch [49/50], Step [641/735], Loss: 0.0986\n",
      "Epoch [49/50], Step [642/735], Loss: 0.1292\n",
      "Epoch [49/50], Step [643/735], Loss: 0.1020\n",
      "Epoch [49/50], Step [644/735], Loss: 0.1085\n",
      "Epoch [49/50], Step [645/735], Loss: 0.2589\n",
      "Epoch [49/50], Step [646/735], Loss: 0.1128\n",
      "Epoch [49/50], Step [647/735], Loss: 0.0779\n",
      "Epoch [49/50], Step [648/735], Loss: 0.1151\n",
      "Epoch [49/50], Step [649/735], Loss: 0.6337\n",
      "Epoch [49/50], Step [650/735], Loss: 0.1532\n",
      "Epoch [49/50], Step [651/735], Loss: 0.1716\n",
      "Epoch [49/50], Step [652/735], Loss: 0.0583\n",
      "Epoch [49/50], Step [653/735], Loss: 0.1747\n",
      "Epoch [49/50], Step [654/735], Loss: 0.0912\n",
      "Epoch [49/50], Step [655/735], Loss: 0.2021\n",
      "Epoch [49/50], Step [656/735], Loss: 0.0908\n",
      "Epoch [49/50], Step [657/735], Loss: 0.0681\n",
      "Epoch [49/50], Step [658/735], Loss: 0.1185\n",
      "Epoch [49/50], Step [659/735], Loss: 0.0379\n",
      "Epoch [49/50], Step [660/735], Loss: 0.2836\n",
      "Epoch [49/50], Step [661/735], Loss: 0.0419\n",
      "Epoch [49/50], Step [662/735], Loss: 0.6684\n",
      "Epoch [49/50], Step [663/735], Loss: 0.1027\n",
      "Epoch [49/50], Step [664/735], Loss: 0.0928\n",
      "Epoch [49/50], Step [665/735], Loss: 0.2490\n",
      "Epoch [49/50], Step [666/735], Loss: 0.0703\n",
      "Epoch [49/50], Step [667/735], Loss: 0.1268\n",
      "Epoch [49/50], Step [668/735], Loss: 0.0636\n",
      "Epoch [49/50], Step [669/735], Loss: 0.0682\n",
      "Epoch [49/50], Step [670/735], Loss: 0.3607\n",
      "Epoch [49/50], Step [671/735], Loss: 0.0821\n",
      "Epoch [49/50], Step [672/735], Loss: 0.1638\n",
      "Epoch [49/50], Step [673/735], Loss: 0.1950\n",
      "Epoch [49/50], Step [674/735], Loss: 0.2299\n",
      "Epoch [49/50], Step [675/735], Loss: 0.1381\n",
      "Epoch [49/50], Step [676/735], Loss: 0.1020\n",
      "Epoch [49/50], Step [677/735], Loss: 0.0924\n",
      "Epoch [49/50], Step [678/735], Loss: 0.1021\n",
      "Epoch [49/50], Step [679/735], Loss: 0.1860\n",
      "Epoch [49/50], Step [680/735], Loss: 0.0815\n",
      "Epoch [49/50], Step [681/735], Loss: 0.0848\n",
      "Epoch [49/50], Step [682/735], Loss: 0.1313\n",
      "Epoch [49/50], Step [683/735], Loss: 0.1344\n",
      "Epoch [49/50], Step [684/735], Loss: 0.1186\n",
      "Epoch [49/50], Step [685/735], Loss: 0.1464\n",
      "Epoch [49/50], Step [686/735], Loss: 0.0615\n",
      "Epoch [49/50], Step [687/735], Loss: 0.0461\n",
      "Epoch [49/50], Step [688/735], Loss: 0.0823\n",
      "Epoch [49/50], Step [689/735], Loss: 0.1407\n",
      "Epoch [49/50], Step [690/735], Loss: 0.0962\n",
      "Epoch [49/50], Step [691/735], Loss: 0.1172\n",
      "Epoch [49/50], Step [692/735], Loss: 0.2346\n",
      "Epoch [49/50], Step [693/735], Loss: 0.1111\n",
      "Epoch [49/50], Step [694/735], Loss: 0.2015\n",
      "Epoch [49/50], Step [695/735], Loss: 0.0678\n",
      "Epoch [49/50], Step [696/735], Loss: 0.1326\n",
      "Epoch [49/50], Step [697/735], Loss: 0.0967\n",
      "Epoch [49/50], Step [698/735], Loss: 0.0458\n",
      "Epoch [49/50], Step [699/735], Loss: 1.0914\n",
      "Epoch [49/50], Step [700/735], Loss: 0.0445\n",
      "Epoch [49/50], Step [701/735], Loss: 0.1369\n",
      "Epoch [49/50], Step [702/735], Loss: 0.0802\n",
      "Epoch [49/50], Step [703/735], Loss: 0.0414\n",
      "Epoch [49/50], Step [704/735], Loss: 0.0676\n",
      "Epoch [49/50], Step [705/735], Loss: 0.2846\n",
      "Epoch [49/50], Step [706/735], Loss: 0.1254\n",
      "Epoch [49/50], Step [707/735], Loss: 0.0578\n",
      "Epoch [49/50], Step [708/735], Loss: 0.1367\n",
      "Epoch [49/50], Step [709/735], Loss: 0.0580\n",
      "Epoch [49/50], Step [710/735], Loss: 0.1019\n",
      "Epoch [49/50], Step [711/735], Loss: 0.0674\n",
      "Epoch [49/50], Step [712/735], Loss: 0.0610\n",
      "Epoch [49/50], Step [713/735], Loss: 0.0617\n",
      "Epoch [49/50], Step [714/735], Loss: 0.1546\n",
      "Epoch [49/50], Step [715/735], Loss: 0.0759\n",
      "Epoch [49/50], Step [716/735], Loss: 0.0622\n",
      "Epoch [49/50], Step [717/735], Loss: 0.0811\n",
      "Epoch [49/50], Step [718/735], Loss: 0.0532\n",
      "Epoch [49/50], Step [719/735], Loss: 0.0687\n",
      "Epoch [49/50], Step [720/735], Loss: 0.0953\n",
      "Epoch [49/50], Step [721/735], Loss: 0.4091\n",
      "Epoch [49/50], Step [722/735], Loss: 0.1196\n",
      "Epoch [49/50], Step [723/735], Loss: 0.0651\n",
      "Epoch [49/50], Step [724/735], Loss: 0.1145\n",
      "Epoch [49/50], Step [725/735], Loss: 0.2381\n",
      "Epoch [49/50], Step [726/735], Loss: 0.0911\n",
      "Epoch [49/50], Step [727/735], Loss: 0.0953\n",
      "Epoch [49/50], Step [728/735], Loss: 0.0497\n",
      "Epoch [49/50], Step [729/735], Loss: 0.2655\n",
      "Epoch [49/50], Step [730/735], Loss: 0.0632\n",
      "Epoch [49/50], Step [731/735], Loss: 0.0756\n",
      "Epoch [49/50], Step [732/735], Loss: 0.0770\n",
      "Epoch [49/50], Step [733/735], Loss: 0.0994\n",
      "Epoch [49/50], Step [734/735], Loss: 0.1048\n",
      "Epoch [49/50], Step [735/735], Loss: 0.0298\n",
      "Epoch [50/50], Step [1/735], Loss: 0.0488\n",
      "Epoch [50/50], Step [2/735], Loss: 0.0480\n",
      "Epoch [50/50], Step [3/735], Loss: 0.0798\n",
      "Epoch [50/50], Step [4/735], Loss: 0.1151\n",
      "Epoch [50/50], Step [5/735], Loss: 0.0504\n",
      "Epoch [50/50], Step [6/735], Loss: 0.0829\n",
      "Epoch [50/50], Step [7/735], Loss: 0.0940\n",
      "Epoch [50/50], Step [8/735], Loss: 0.0478\n",
      "Epoch [50/50], Step [9/735], Loss: 0.0290\n",
      "Epoch [50/50], Step [10/735], Loss: 0.0630\n",
      "Epoch [50/50], Step [11/735], Loss: 0.1899\n",
      "Epoch [50/50], Step [12/735], Loss: 0.1240\n",
      "Epoch [50/50], Step [13/735], Loss: 0.0793\n",
      "Epoch [50/50], Step [14/735], Loss: 0.0591\n",
      "Epoch [50/50], Step [15/735], Loss: 0.0676\n",
      "Epoch [50/50], Step [16/735], Loss: 0.1181\n",
      "Epoch [50/50], Step [17/735], Loss: 0.0528\n",
      "Epoch [50/50], Step [18/735], Loss: 0.0989\n",
      "Epoch [50/50], Step [19/735], Loss: 0.1090\n",
      "Epoch [50/50], Step [20/735], Loss: 0.1756\n",
      "Epoch [50/50], Step [21/735], Loss: 0.0559\n",
      "Epoch [50/50], Step [22/735], Loss: 0.0726\n",
      "Epoch [50/50], Step [23/735], Loss: 0.0284\n",
      "Epoch [50/50], Step [24/735], Loss: 0.1151\n",
      "Epoch [50/50], Step [25/735], Loss: 0.0543\n",
      "Epoch [50/50], Step [26/735], Loss: 0.0901\n",
      "Epoch [50/50], Step [27/735], Loss: 0.0583\n",
      "Epoch [50/50], Step [28/735], Loss: 0.5323\n",
      "Epoch [50/50], Step [29/735], Loss: 0.0956\n",
      "Epoch [50/50], Step [30/735], Loss: 0.0927\n",
      "Epoch [50/50], Step [31/735], Loss: 0.0563\n",
      "Epoch [50/50], Step [32/735], Loss: 0.1376\n",
      "Epoch [50/50], Step [33/735], Loss: 0.0761\n",
      "Epoch [50/50], Step [34/735], Loss: 0.1002\n",
      "Epoch [50/50], Step [35/735], Loss: 0.0538\n",
      "Epoch [50/50], Step [36/735], Loss: 0.0763\n",
      "Epoch [50/50], Step [37/735], Loss: 0.0810\n",
      "Epoch [50/50], Step [38/735], Loss: 0.0825\n",
      "Epoch [50/50], Step [39/735], Loss: 0.1677\n",
      "Epoch [50/50], Step [40/735], Loss: 0.1244\n",
      "Epoch [50/50], Step [41/735], Loss: 0.0424\n",
      "Epoch [50/50], Step [42/735], Loss: 0.0488\n",
      "Epoch [50/50], Step [43/735], Loss: 0.0895\n",
      "Epoch [50/50], Step [44/735], Loss: 0.0514\n",
      "Epoch [50/50], Step [45/735], Loss: 0.0379\n",
      "Epoch [50/50], Step [46/735], Loss: 0.0667\n",
      "Epoch [50/50], Step [47/735], Loss: 0.2229\n",
      "Epoch [50/50], Step [48/735], Loss: 0.0999\n",
      "Epoch [50/50], Step [49/735], Loss: 0.0356\n",
      "Epoch [50/50], Step [50/735], Loss: 0.0469\n",
      "Epoch [50/50], Step [51/735], Loss: 0.0778\n",
      "Epoch [50/50], Step [52/735], Loss: 0.0649\n",
      "Epoch [50/50], Step [53/735], Loss: 0.1083\n",
      "Epoch [50/50], Step [54/735], Loss: 0.0290\n",
      "Epoch [50/50], Step [55/735], Loss: 0.1390\n",
      "Epoch [50/50], Step [56/735], Loss: 0.0471\n",
      "Epoch [50/50], Step [57/735], Loss: 0.0925\n",
      "Epoch [50/50], Step [58/735], Loss: 0.0462\n",
      "Epoch [50/50], Step [59/735], Loss: 0.0740\n",
      "Epoch [50/50], Step [60/735], Loss: 0.0711\n",
      "Epoch [50/50], Step [61/735], Loss: 0.0430\n",
      "Epoch [50/50], Step [62/735], Loss: 0.0554\n",
      "Epoch [50/50], Step [63/735], Loss: 0.0562\n",
      "Epoch [50/50], Step [64/735], Loss: 0.0299\n",
      "Epoch [50/50], Step [65/735], Loss: 0.0392\n",
      "Epoch [50/50], Step [66/735], Loss: 0.0686\n",
      "Epoch [50/50], Step [67/735], Loss: 0.0548\n",
      "Epoch [50/50], Step [68/735], Loss: 0.1016\n",
      "Epoch [50/50], Step [69/735], Loss: 0.1172\n",
      "Epoch [50/50], Step [70/735], Loss: 0.0600\n",
      "Epoch [50/50], Step [71/735], Loss: 0.0388\n",
      "Epoch [50/50], Step [72/735], Loss: 0.0271\n",
      "Epoch [50/50], Step [73/735], Loss: 0.0577\n",
      "Epoch [50/50], Step [74/735], Loss: 0.2487\n",
      "Epoch [50/50], Step [75/735], Loss: 0.0623\n",
      "Epoch [50/50], Step [76/735], Loss: 0.0468\n",
      "Epoch [50/50], Step [77/735], Loss: 0.1007\n",
      "Epoch [50/50], Step [78/735], Loss: 0.0813\n",
      "Epoch [50/50], Step [79/735], Loss: 1.3766\n",
      "Epoch [50/50], Step [80/735], Loss: 0.0868\n",
      "Epoch [50/50], Step [81/735], Loss: 0.1118\n",
      "Epoch [50/50], Step [82/735], Loss: 0.0802\n",
      "Epoch [50/50], Step [83/735], Loss: 0.0751\n",
      "Epoch [50/50], Step [84/735], Loss: 0.0949\n",
      "Epoch [50/50], Step [85/735], Loss: 0.0541\n",
      "Epoch [50/50], Step [86/735], Loss: 0.0944\n",
      "Epoch [50/50], Step [87/735], Loss: 0.0582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Step [88/735], Loss: 0.3085\n",
      "Epoch [50/50], Step [89/735], Loss: 0.1925\n",
      "Epoch [50/50], Step [90/735], Loss: 0.0935\n",
      "Epoch [50/50], Step [91/735], Loss: 0.1106\n",
      "Epoch [50/50], Step [92/735], Loss: 0.0698\n",
      "Epoch [50/50], Step [93/735], Loss: 0.1165\n",
      "Epoch [50/50], Step [94/735], Loss: 0.1292\n",
      "Epoch [50/50], Step [95/735], Loss: 0.0874\n",
      "Epoch [50/50], Step [96/735], Loss: 0.1196\n",
      "Epoch [50/50], Step [97/735], Loss: 0.2935\n",
      "Epoch [50/50], Step [98/735], Loss: 0.0844\n",
      "Epoch [50/50], Step [99/735], Loss: 0.1223\n",
      "Epoch [50/50], Step [100/735], Loss: 0.0587\n",
      "Epoch [50/50], Step [101/735], Loss: 0.0734\n",
      "Epoch [50/50], Step [102/735], Loss: 0.5787\n",
      "Epoch [50/50], Step [103/735], Loss: 0.0329\n",
      "Epoch [50/50], Step [104/735], Loss: 0.0506\n",
      "Epoch [50/50], Step [105/735], Loss: 0.1055\n",
      "Epoch [50/50], Step [106/735], Loss: 0.1676\n",
      "Epoch [50/50], Step [107/735], Loss: 0.1100\n",
      "Epoch [50/50], Step [108/735], Loss: 0.0554\n",
      "Epoch [50/50], Step [109/735], Loss: 0.0962\n",
      "Epoch [50/50], Step [110/735], Loss: 0.0741\n",
      "Epoch [50/50], Step [111/735], Loss: 0.0971\n",
      "Epoch [50/50], Step [112/735], Loss: 0.1334\n",
      "Epoch [50/50], Step [113/735], Loss: 0.0708\n",
      "Epoch [50/50], Step [114/735], Loss: 0.5960\n",
      "Epoch [50/50], Step [115/735], Loss: 0.1870\n",
      "Epoch [50/50], Step [116/735], Loss: 0.0961\n",
      "Epoch [50/50], Step [117/735], Loss: 0.1023\n",
      "Epoch [50/50], Step [118/735], Loss: 0.1208\n",
      "Epoch [50/50], Step [119/735], Loss: 0.0966\n",
      "Epoch [50/50], Step [120/735], Loss: 0.1559\n",
      "Epoch [50/50], Step [121/735], Loss: 0.5443\n",
      "Epoch [50/50], Step [122/735], Loss: 0.1804\n",
      "Epoch [50/50], Step [123/735], Loss: 0.0736\n",
      "Epoch [50/50], Step [124/735], Loss: 0.0767\n",
      "Epoch [50/50], Step [125/735], Loss: 0.1646\n",
      "Epoch [50/50], Step [126/735], Loss: 0.0992\n",
      "Epoch [50/50], Step [127/735], Loss: 0.1464\n",
      "Epoch [50/50], Step [128/735], Loss: 0.0878\n",
      "Epoch [50/50], Step [129/735], Loss: 0.3125\n",
      "Epoch [50/50], Step [130/735], Loss: 0.0702\n",
      "Epoch [50/50], Step [131/735], Loss: 0.1094\n",
      "Epoch [50/50], Step [132/735], Loss: 0.2727\n",
      "Epoch [50/50], Step [133/735], Loss: 0.1781\n",
      "Epoch [50/50], Step [134/735], Loss: 1.2221\n",
      "Epoch [50/50], Step [135/735], Loss: 0.1188\n",
      "Epoch [50/50], Step [136/735], Loss: 0.1124\n",
      "Epoch [50/50], Step [137/735], Loss: 0.1551\n",
      "Epoch [50/50], Step [138/735], Loss: 0.2043\n",
      "Epoch [50/50], Step [139/735], Loss: 0.3762\n",
      "Epoch [50/50], Step [140/735], Loss: 0.0795\n",
      "Epoch [50/50], Step [141/735], Loss: 0.0999\n",
      "Epoch [50/50], Step [142/735], Loss: 0.0933\n",
      "Epoch [50/50], Step [143/735], Loss: 0.0819\n",
      "Epoch [50/50], Step [144/735], Loss: 0.4602\n",
      "Epoch [50/50], Step [145/735], Loss: 0.2383\n",
      "Epoch [50/50], Step [146/735], Loss: 0.1880\n",
      "Epoch [50/50], Step [147/735], Loss: 0.1636\n",
      "Epoch [50/50], Step [148/735], Loss: 0.1084\n",
      "Epoch [50/50], Step [149/735], Loss: 0.1264\n",
      "Epoch [50/50], Step [150/735], Loss: 0.1303\n",
      "Epoch [50/50], Step [151/735], Loss: 0.1071\n",
      "Epoch [50/50], Step [152/735], Loss: 0.0729\n",
      "Epoch [50/50], Step [153/735], Loss: 0.0595\n",
      "Epoch [50/50], Step [154/735], Loss: 0.1333\n",
      "Epoch [50/50], Step [155/735], Loss: 0.0690\n",
      "Epoch [50/50], Step [156/735], Loss: 0.0785\n",
      "Epoch [50/50], Step [157/735], Loss: 0.1004\n",
      "Epoch [50/50], Step [158/735], Loss: 0.0749\n",
      "Epoch [50/50], Step [159/735], Loss: 0.0737\n",
      "Epoch [50/50], Step [160/735], Loss: 0.0852\n",
      "Epoch [50/50], Step [161/735], Loss: 0.1473\n",
      "Epoch [50/50], Step [162/735], Loss: 0.0175\n",
      "Epoch [50/50], Step [163/735], Loss: 0.1318\n",
      "Epoch [50/50], Step [164/735], Loss: 0.0739\n",
      "Epoch [50/50], Step [165/735], Loss: 0.0920\n",
      "Epoch [50/50], Step [166/735], Loss: 0.0540\n",
      "Epoch [50/50], Step [167/735], Loss: 0.1108\n",
      "Epoch [50/50], Step [168/735], Loss: 0.0413\n",
      "Epoch [50/50], Step [169/735], Loss: 0.0779\n",
      "Epoch [50/50], Step [170/735], Loss: 0.0277\n",
      "Epoch [50/50], Step [171/735], Loss: 0.0628\n",
      "Epoch [50/50], Step [172/735], Loss: 0.0571\n",
      "Epoch [50/50], Step [173/735], Loss: 0.0928\n",
      "Epoch [50/50], Step [174/735], Loss: 0.0497\n",
      "Epoch [50/50], Step [175/735], Loss: 0.0901\n",
      "Epoch [50/50], Step [176/735], Loss: 0.0674\n",
      "Epoch [50/50], Step [177/735], Loss: 0.1691\n",
      "Epoch [50/50], Step [178/735], Loss: 0.0849\n",
      "Epoch [50/50], Step [179/735], Loss: 0.0370\n",
      "Epoch [50/50], Step [180/735], Loss: 0.0517\n",
      "Epoch [50/50], Step [181/735], Loss: 0.0768\n",
      "Epoch [50/50], Step [182/735], Loss: 0.0413\n",
      "Epoch [50/50], Step [183/735], Loss: 0.1476\n",
      "Epoch [50/50], Step [184/735], Loss: 0.0935\n",
      "Epoch [50/50], Step [185/735], Loss: 0.0541\n",
      "Epoch [50/50], Step [186/735], Loss: 0.1185\n",
      "Epoch [50/50], Step [187/735], Loss: 0.0454\n",
      "Epoch [50/50], Step [188/735], Loss: 0.0812\n",
      "Epoch [50/50], Step [189/735], Loss: 0.0468\n",
      "Epoch [50/50], Step [190/735], Loss: 0.0743\n",
      "Epoch [50/50], Step [191/735], Loss: 0.0860\n",
      "Epoch [50/50], Step [192/735], Loss: 0.0753\n",
      "Epoch [50/50], Step [193/735], Loss: 0.0812\n",
      "Epoch [50/50], Step [194/735], Loss: 0.0585\n",
      "Epoch [50/50], Step [195/735], Loss: 0.0352\n",
      "Epoch [50/50], Step [196/735], Loss: 0.0717\n",
      "Epoch [50/50], Step [197/735], Loss: 0.0381\n",
      "Epoch [50/50], Step [198/735], Loss: 0.1161\n",
      "Epoch [50/50], Step [199/735], Loss: 0.0745\n",
      "Epoch [50/50], Step [200/735], Loss: 0.1003\n",
      "Epoch [50/50], Step [201/735], Loss: 0.0407\n",
      "Epoch [50/50], Step [202/735], Loss: 1.0624\n",
      "Epoch [50/50], Step [203/735], Loss: 0.1129\n",
      "Epoch [50/50], Step [204/735], Loss: 0.0389\n",
      "Epoch [50/50], Step [205/735], Loss: 0.0536\n",
      "Epoch [50/50], Step [206/735], Loss: 0.1234\n",
      "Epoch [50/50], Step [207/735], Loss: 0.1241\n",
      "Epoch [50/50], Step [208/735], Loss: 0.0721\n",
      "Epoch [50/50], Step [209/735], Loss: 0.1112\n",
      "Epoch [50/50], Step [210/735], Loss: 0.0449\n",
      "Epoch [50/50], Step [211/735], Loss: 0.6514\n",
      "Epoch [50/50], Step [212/735], Loss: 0.1658\n",
      "Epoch [50/50], Step [213/735], Loss: 0.0437\n",
      "Epoch [50/50], Step [214/735], Loss: 0.0741\n",
      "Epoch [50/50], Step [215/735], Loss: 0.0739\n",
      "Epoch [50/50], Step [216/735], Loss: 0.3661\n",
      "Epoch [50/50], Step [217/735], Loss: 0.2573\n",
      "Epoch [50/50], Step [218/735], Loss: 0.0371\n",
      "Epoch [50/50], Step [219/735], Loss: 0.0278\n",
      "Epoch [50/50], Step [220/735], Loss: 0.0990\n",
      "Epoch [50/50], Step [221/735], Loss: 0.1011\n",
      "Epoch [50/50], Step [222/735], Loss: 0.0480\n",
      "Epoch [50/50], Step [223/735], Loss: 0.0498\n",
      "Epoch [50/50], Step [224/735], Loss: 0.0826\n",
      "Epoch [50/50], Step [225/735], Loss: 0.1139\n",
      "Epoch [50/50], Step [226/735], Loss: 0.2560\n",
      "Epoch [50/50], Step [227/735], Loss: 0.2280\n",
      "Epoch [50/50], Step [228/735], Loss: 0.0720\n",
      "Epoch [50/50], Step [229/735], Loss: 0.0980\n",
      "Epoch [50/50], Step [230/735], Loss: 0.0844\n",
      "Epoch [50/50], Step [231/735], Loss: 0.0457\n",
      "Epoch [50/50], Step [232/735], Loss: 0.0559\n",
      "Epoch [50/50], Step [233/735], Loss: 1.3046\n",
      "Epoch [50/50], Step [234/735], Loss: 0.0633\n",
      "Epoch [50/50], Step [235/735], Loss: 0.1237\n",
      "Epoch [50/50], Step [236/735], Loss: 1.1190\n",
      "Epoch [50/50], Step [237/735], Loss: 0.0587\n",
      "Epoch [50/50], Step [238/735], Loss: 0.0773\n",
      "Epoch [50/50], Step [239/735], Loss: 0.0466\n",
      "Epoch [50/50], Step [240/735], Loss: 0.1375\n",
      "Epoch [50/50], Step [241/735], Loss: 0.0395\n",
      "Epoch [50/50], Step [242/735], Loss: 0.0817\n",
      "Epoch [50/50], Step [243/735], Loss: 0.0739\n",
      "Epoch [50/50], Step [244/735], Loss: 0.0356\n",
      "Epoch [50/50], Step [245/735], Loss: 0.0326\n",
      "Epoch [50/50], Step [246/735], Loss: 0.1997\n",
      "Epoch [50/50], Step [247/735], Loss: 0.0653\n",
      "Epoch [50/50], Step [248/735], Loss: 0.0922\n",
      "Epoch [50/50], Step [249/735], Loss: 0.0558\n",
      "Epoch [50/50], Step [250/735], Loss: 0.0615\n",
      "Epoch [50/50], Step [251/735], Loss: 0.0614\n",
      "Epoch [50/50], Step [252/735], Loss: 0.1302\n",
      "Epoch [50/50], Step [253/735], Loss: 0.0867\n",
      "Epoch [50/50], Step [254/735], Loss: 0.0785\n",
      "Epoch [50/50], Step [255/735], Loss: 0.0578\n",
      "Epoch [50/50], Step [256/735], Loss: 0.1137\n",
      "Epoch [50/50], Step [257/735], Loss: 0.1213\n",
      "Epoch [50/50], Step [258/735], Loss: 0.0921\n",
      "Epoch [50/50], Step [259/735], Loss: 0.1152\n",
      "Epoch [50/50], Step [260/735], Loss: 0.1251\n",
      "Epoch [50/50], Step [261/735], Loss: 0.0531\n",
      "Epoch [50/50], Step [262/735], Loss: 0.1098\n",
      "Epoch [50/50], Step [263/735], Loss: 0.0807\n",
      "Epoch [50/50], Step [264/735], Loss: 0.0374\n",
      "Epoch [50/50], Step [265/735], Loss: 0.0604\n",
      "Epoch [50/50], Step [266/735], Loss: 0.0684\n",
      "Epoch [50/50], Step [267/735], Loss: 0.1238\n",
      "Epoch [50/50], Step [268/735], Loss: 0.2355\n",
      "Epoch [50/50], Step [269/735], Loss: 0.1037\n",
      "Epoch [50/50], Step [270/735], Loss: 0.1342\n",
      "Epoch [50/50], Step [271/735], Loss: 0.0624\n",
      "Epoch [50/50], Step [272/735], Loss: 0.0746\n",
      "Epoch [50/50], Step [273/735], Loss: 0.0684\n",
      "Epoch [50/50], Step [274/735], Loss: 0.2155\n",
      "Epoch [50/50], Step [275/735], Loss: 0.0836\n",
      "Epoch [50/50], Step [276/735], Loss: 0.0555\n",
      "Epoch [50/50], Step [277/735], Loss: 0.0871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Step [278/735], Loss: 0.3632\n",
      "Epoch [50/50], Step [279/735], Loss: 0.1146\n",
      "Epoch [50/50], Step [280/735], Loss: 0.2623\n",
      "Epoch [50/50], Step [281/735], Loss: 0.1280\n",
      "Epoch [50/50], Step [282/735], Loss: 0.0721\n",
      "Epoch [50/50], Step [283/735], Loss: 0.2282\n",
      "Epoch [50/50], Step [284/735], Loss: 0.0449\n",
      "Epoch [50/50], Step [285/735], Loss: 0.0530\n",
      "Epoch [50/50], Step [286/735], Loss: 0.1243\n",
      "Epoch [50/50], Step [287/735], Loss: 0.0973\n",
      "Epoch [50/50], Step [288/735], Loss: 0.0553\n",
      "Epoch [50/50], Step [289/735], Loss: 0.0423\n",
      "Epoch [50/50], Step [290/735], Loss: 0.0839\n",
      "Epoch [50/50], Step [291/735], Loss: 0.1563\n",
      "Epoch [50/50], Step [292/735], Loss: 0.2384\n",
      "Epoch [50/50], Step [293/735], Loss: 0.1002\n",
      "Epoch [50/50], Step [294/735], Loss: 0.1170\n",
      "Epoch [50/50], Step [295/735], Loss: 0.0481\n",
      "Epoch [50/50], Step [296/735], Loss: 0.0402\n",
      "Epoch [50/50], Step [297/735], Loss: 0.0770\n",
      "Epoch [50/50], Step [298/735], Loss: 0.0592\n",
      "Epoch [50/50], Step [299/735], Loss: 0.1128\n",
      "Epoch [50/50], Step [300/735], Loss: 0.1898\n",
      "Epoch [50/50], Step [301/735], Loss: 0.0367\n",
      "Epoch [50/50], Step [302/735], Loss: 0.0553\n",
      "Epoch [50/50], Step [303/735], Loss: 0.0505\n",
      "Epoch [50/50], Step [304/735], Loss: 0.5465\n",
      "Epoch [50/50], Step [305/735], Loss: 0.0376\n",
      "Epoch [50/50], Step [306/735], Loss: 0.1629\n",
      "Epoch [50/50], Step [307/735], Loss: 0.0790\n",
      "Epoch [50/50], Step [308/735], Loss: 0.0565\n",
      "Epoch [50/50], Step [309/735], Loss: 0.0732\n",
      "Epoch [50/50], Step [310/735], Loss: 0.1116\n",
      "Epoch [50/50], Step [311/735], Loss: 0.1422\n",
      "Epoch [50/50], Step [312/735], Loss: 0.0714\n",
      "Epoch [50/50], Step [313/735], Loss: 0.0769\n",
      "Epoch [50/50], Step [314/735], Loss: 0.0957\n",
      "Epoch [50/50], Step [315/735], Loss: 0.0471\n",
      "Epoch [50/50], Step [316/735], Loss: 0.0693\n",
      "Epoch [50/50], Step [317/735], Loss: 0.0506\n",
      "Epoch [50/50], Step [318/735], Loss: 0.0740\n",
      "Epoch [50/50], Step [319/735], Loss: 0.0817\n",
      "Epoch [50/50], Step [320/735], Loss: 0.1054\n",
      "Epoch [50/50], Step [321/735], Loss: 0.0777\n",
      "Epoch [50/50], Step [322/735], Loss: 0.0748\n",
      "Epoch [50/50], Step [323/735], Loss: 0.1108\n",
      "Epoch [50/50], Step [324/735], Loss: 0.0458\n",
      "Epoch [50/50], Step [325/735], Loss: 0.0352\n",
      "Epoch [50/50], Step [326/735], Loss: 0.6988\n",
      "Epoch [50/50], Step [327/735], Loss: 0.0523\n",
      "Epoch [50/50], Step [328/735], Loss: 0.0670\n",
      "Epoch [50/50], Step [329/735], Loss: 0.2013\n",
      "Epoch [50/50], Step [330/735], Loss: 0.1102\n",
      "Epoch [50/50], Step [331/735], Loss: 0.2363\n",
      "Epoch [50/50], Step [332/735], Loss: 0.0471\n",
      "Epoch [50/50], Step [333/735], Loss: 0.1194\n",
      "Epoch [50/50], Step [334/735], Loss: 0.0420\n",
      "Epoch [50/50], Step [335/735], Loss: 0.0716\n",
      "Epoch [50/50], Step [336/735], Loss: 0.1582\n",
      "Epoch [50/50], Step [337/735], Loss: 0.0926\n",
      "Epoch [50/50], Step [338/735], Loss: 0.0382\n",
      "Epoch [50/50], Step [339/735], Loss: 0.0976\n",
      "Epoch [50/50], Step [340/735], Loss: 1.0354\n",
      "Epoch [50/50], Step [341/735], Loss: 0.1437\n",
      "Epoch [50/50], Step [342/735], Loss: 0.0646\n",
      "Epoch [50/50], Step [343/735], Loss: 0.0880\n",
      "Epoch [50/50], Step [344/735], Loss: 0.0760\n",
      "Epoch [50/50], Step [345/735], Loss: 0.0454\n",
      "Epoch [50/50], Step [346/735], Loss: 0.0570\n",
      "Epoch [50/50], Step [347/735], Loss: 0.0734\n",
      "Epoch [50/50], Step [348/735], Loss: 0.0419\n",
      "Epoch [50/50], Step [349/735], Loss: 0.3709\n",
      "Epoch [50/50], Step [350/735], Loss: 0.0956\n",
      "Epoch [50/50], Step [351/735], Loss: 0.1691\n",
      "Epoch [50/50], Step [352/735], Loss: 0.0649\n",
      "Epoch [50/50], Step [353/735], Loss: 0.0844\n",
      "Epoch [50/50], Step [354/735], Loss: 0.0492\n",
      "Epoch [50/50], Step [355/735], Loss: 0.0535\n",
      "Epoch [50/50], Step [356/735], Loss: 0.0731\n",
      "Epoch [50/50], Step [357/735], Loss: 0.0972\n",
      "Epoch [50/50], Step [358/735], Loss: 0.1513\n",
      "Epoch [50/50], Step [359/735], Loss: 0.1419\n",
      "Epoch [50/50], Step [360/735], Loss: 0.0843\n",
      "Epoch [50/50], Step [361/735], Loss: 0.1500\n",
      "Epoch [50/50], Step [362/735], Loss: 0.0832\n",
      "Epoch [50/50], Step [363/735], Loss: 0.0521\n",
      "Epoch [50/50], Step [364/735], Loss: 0.0675\n",
      "Epoch [50/50], Step [365/735], Loss: 0.0602\n",
      "Epoch [50/50], Step [366/735], Loss: 0.0525\n",
      "Epoch [50/50], Step [367/735], Loss: 0.0959\n",
      "Epoch [50/50], Step [368/735], Loss: 0.1025\n",
      "Epoch [50/50], Step [369/735], Loss: 0.1562\n",
      "Epoch [50/50], Step [370/735], Loss: 0.1034\n",
      "Epoch [50/50], Step [371/735], Loss: 0.0874\n",
      "Epoch [50/50], Step [372/735], Loss: 0.0826\n",
      "Epoch [50/50], Step [373/735], Loss: 0.1729\n",
      "Epoch [50/50], Step [374/735], Loss: 0.1029\n",
      "Epoch [50/50], Step [375/735], Loss: 0.0683\n",
      "Epoch [50/50], Step [376/735], Loss: 0.0518\n",
      "Epoch [50/50], Step [377/735], Loss: 0.0751\n",
      "Epoch [50/50], Step [378/735], Loss: 0.0940\n",
      "Epoch [50/50], Step [379/735], Loss: 0.0480\n",
      "Epoch [50/50], Step [380/735], Loss: 0.0763\n",
      "Epoch [50/50], Step [381/735], Loss: 0.8257\n",
      "Epoch [50/50], Step [382/735], Loss: 0.1152\n",
      "Epoch [50/50], Step [383/735], Loss: 0.1709\n",
      "Epoch [50/50], Step [384/735], Loss: 0.0792\n",
      "Epoch [50/50], Step [385/735], Loss: 0.0609\n",
      "Epoch [50/50], Step [386/735], Loss: 0.1588\n",
      "Epoch [50/50], Step [387/735], Loss: 0.1717\n",
      "Epoch [50/50], Step [388/735], Loss: 0.0656\n",
      "Epoch [50/50], Step [389/735], Loss: 0.0251\n",
      "Epoch [50/50], Step [390/735], Loss: 0.0628\n",
      "Epoch [50/50], Step [391/735], Loss: 0.0410\n",
      "Epoch [50/50], Step [392/735], Loss: 0.1579\n",
      "Epoch [50/50], Step [393/735], Loss: 0.0451\n",
      "Epoch [50/50], Step [394/735], Loss: 0.0755\n",
      "Epoch [50/50], Step [395/735], Loss: 0.0611\n",
      "Epoch [50/50], Step [396/735], Loss: 0.0802\n",
      "Epoch [50/50], Step [397/735], Loss: 0.0822\n",
      "Epoch [50/50], Step [398/735], Loss: 0.0373\n",
      "Epoch [50/50], Step [399/735], Loss: 0.0654\n",
      "Epoch [50/50], Step [400/735], Loss: 0.1435\n",
      "Epoch [50/50], Step [401/735], Loss: 0.0616\n",
      "Epoch [50/50], Step [402/735], Loss: 0.0844\n",
      "Epoch [50/50], Step [403/735], Loss: 0.0741\n",
      "Epoch [50/50], Step [404/735], Loss: 0.0848\n",
      "Epoch [50/50], Step [405/735], Loss: 0.0392\n",
      "Epoch [50/50], Step [406/735], Loss: 0.0289\n",
      "Epoch [50/50], Step [407/735], Loss: 0.0732\n",
      "Epoch [50/50], Step [408/735], Loss: 0.0704\n",
      "Epoch [50/50], Step [409/735], Loss: 0.0301\n",
      "Epoch [50/50], Step [410/735], Loss: 0.1256\n",
      "Epoch [50/50], Step [411/735], Loss: 0.0724\n",
      "Epoch [50/50], Step [412/735], Loss: 0.0606\n",
      "Epoch [50/50], Step [413/735], Loss: 0.0705\n",
      "Epoch [50/50], Step [414/735], Loss: 0.1115\n",
      "Epoch [50/50], Step [415/735], Loss: 0.0236\n",
      "Epoch [50/50], Step [416/735], Loss: 0.0714\n",
      "Epoch [50/50], Step [417/735], Loss: 0.4229\n",
      "Epoch [50/50], Step [418/735], Loss: 0.0681\n",
      "Epoch [50/50], Step [419/735], Loss: 0.0917\n",
      "Epoch [50/50], Step [420/735], Loss: 0.0852\n",
      "Epoch [50/50], Step [421/735], Loss: 0.0807\n",
      "Epoch [50/50], Step [422/735], Loss: 0.0278\n",
      "Epoch [50/50], Step [423/735], Loss: 0.0874\n",
      "Epoch [50/50], Step [424/735], Loss: 0.0758\n",
      "Epoch [50/50], Step [425/735], Loss: 0.2395\n",
      "Epoch [50/50], Step [426/735], Loss: 0.0593\n",
      "Epoch [50/50], Step [427/735], Loss: 0.1406\n",
      "Epoch [50/50], Step [428/735], Loss: 0.0687\n",
      "Epoch [50/50], Step [429/735], Loss: 0.0718\n",
      "Epoch [50/50], Step [430/735], Loss: 0.0907\n",
      "Epoch [50/50], Step [431/735], Loss: 0.1359\n",
      "Epoch [50/50], Step [432/735], Loss: 0.0495\n",
      "Epoch [50/50], Step [433/735], Loss: 0.0599\n",
      "Epoch [50/50], Step [434/735], Loss: 0.0995\n",
      "Epoch [50/50], Step [435/735], Loss: 0.0875\n",
      "Epoch [50/50], Step [436/735], Loss: 0.2423\n",
      "Epoch [50/50], Step [437/735], Loss: 0.0853\n",
      "Epoch [50/50], Step [438/735], Loss: 0.1181\n",
      "Epoch [50/50], Step [439/735], Loss: 0.0391\n",
      "Epoch [50/50], Step [440/735], Loss: 0.0880\n",
      "Epoch [50/50], Step [441/735], Loss: 0.1310\n",
      "Epoch [50/50], Step [442/735], Loss: 0.0260\n",
      "Epoch [50/50], Step [443/735], Loss: 0.0749\n",
      "Epoch [50/50], Step [444/735], Loss: 0.0660\n",
      "Epoch [50/50], Step [445/735], Loss: 0.1033\n",
      "Epoch [50/50], Step [446/735], Loss: 0.0307\n",
      "Epoch [50/50], Step [447/735], Loss: 0.1086\n",
      "Epoch [50/50], Step [448/735], Loss: 0.0631\n",
      "Epoch [50/50], Step [449/735], Loss: 0.3426\n",
      "Epoch [50/50], Step [450/735], Loss: 0.0432\n",
      "Epoch [50/50], Step [451/735], Loss: 0.0730\n",
      "Epoch [50/50], Step [452/735], Loss: 0.0967\n",
      "Epoch [50/50], Step [453/735], Loss: 0.0589\n",
      "Epoch [50/50], Step [454/735], Loss: 0.0808\n",
      "Epoch [50/50], Step [455/735], Loss: 0.0826\n",
      "Epoch [50/50], Step [456/735], Loss: 0.0767\n",
      "Epoch [50/50], Step [457/735], Loss: 0.0328\n",
      "Epoch [50/50], Step [458/735], Loss: 0.0298\n",
      "Epoch [50/50], Step [459/735], Loss: 0.0437\n",
      "Epoch [50/50], Step [460/735], Loss: 0.0703\n",
      "Epoch [50/50], Step [461/735], Loss: 0.3405\n",
      "Epoch [50/50], Step [462/735], Loss: 0.0691\n",
      "Epoch [50/50], Step [463/735], Loss: 0.1426\n",
      "Epoch [50/50], Step [464/735], Loss: 0.0957\n",
      "Epoch [50/50], Step [465/735], Loss: 0.0748\n",
      "Epoch [50/50], Step [466/735], Loss: 0.1169\n",
      "Epoch [50/50], Step [467/735], Loss: 0.0853\n",
      "Epoch [50/50], Step [468/735], Loss: 0.0551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Step [469/735], Loss: 0.0513\n",
      "Epoch [50/50], Step [470/735], Loss: 0.0656\n",
      "Epoch [50/50], Step [471/735], Loss: 0.1410\n",
      "Epoch [50/50], Step [472/735], Loss: 0.1899\n",
      "Epoch [50/50], Step [473/735], Loss: 0.0768\n",
      "Epoch [50/50], Step [474/735], Loss: 0.0806\n",
      "Epoch [50/50], Step [475/735], Loss: 0.1014\n",
      "Epoch [50/50], Step [476/735], Loss: 0.1733\n",
      "Epoch [50/50], Step [477/735], Loss: 0.0881\n",
      "Epoch [50/50], Step [478/735], Loss: 0.1574\n",
      "Epoch [50/50], Step [479/735], Loss: 0.1089\n",
      "Epoch [50/50], Step [480/735], Loss: 0.0799\n",
      "Epoch [50/50], Step [481/735], Loss: 0.1199\n",
      "Epoch [50/50], Step [482/735], Loss: 0.9365\n",
      "Epoch [50/50], Step [483/735], Loss: 0.0345\n",
      "Epoch [50/50], Step [484/735], Loss: 0.0820\n",
      "Epoch [50/50], Step [485/735], Loss: 0.0566\n",
      "Epoch [50/50], Step [486/735], Loss: 0.0756\n",
      "Epoch [50/50], Step [487/735], Loss: 0.2042\n",
      "Epoch [50/50], Step [488/735], Loss: 0.0802\n",
      "Epoch [50/50], Step [489/735], Loss: 0.1274\n",
      "Epoch [50/50], Step [490/735], Loss: 0.0912\n",
      "Epoch [50/50], Step [491/735], Loss: 0.0506\n",
      "Epoch [50/50], Step [492/735], Loss: 0.2684\n",
      "Epoch [50/50], Step [493/735], Loss: 0.1027\n",
      "Epoch [50/50], Step [494/735], Loss: 0.0408\n",
      "Epoch [50/50], Step [495/735], Loss: 0.0679\n",
      "Epoch [50/50], Step [496/735], Loss: 0.0576\n",
      "Epoch [50/50], Step [497/735], Loss: 0.0389\n",
      "Epoch [50/50], Step [498/735], Loss: 0.1166\n",
      "Epoch [50/50], Step [499/735], Loss: 0.2091\n",
      "Epoch [50/50], Step [500/735], Loss: 0.0406\n",
      "Epoch [50/50], Step [501/735], Loss: 0.0920\n",
      "Epoch [50/50], Step [502/735], Loss: 0.0571\n",
      "Epoch [50/50], Step [503/735], Loss: 0.0999\n",
      "Epoch [50/50], Step [504/735], Loss: 0.0582\n",
      "Epoch [50/50], Step [505/735], Loss: 0.1833\n",
      "Epoch [50/50], Step [506/735], Loss: 0.0956\n",
      "Epoch [50/50], Step [507/735], Loss: 0.2719\n",
      "Epoch [50/50], Step [508/735], Loss: 0.0382\n",
      "Epoch [50/50], Step [509/735], Loss: 0.0795\n",
      "Epoch [50/50], Step [510/735], Loss: 0.0791\n",
      "Epoch [50/50], Step [511/735], Loss: 0.5969\n",
      "Epoch [50/50], Step [512/735], Loss: 0.1397\n",
      "Epoch [50/50], Step [513/735], Loss: 0.1174\n",
      "Epoch [50/50], Step [514/735], Loss: 0.0519\n",
      "Epoch [50/50], Step [515/735], Loss: 0.0880\n",
      "Epoch [50/50], Step [516/735], Loss: 0.0884\n",
      "Epoch [50/50], Step [517/735], Loss: 0.2788\n",
      "Epoch [50/50], Step [518/735], Loss: 0.1677\n",
      "Epoch [50/50], Step [519/735], Loss: 0.0720\n",
      "Epoch [50/50], Step [520/735], Loss: 0.0479\n",
      "Epoch [50/50], Step [521/735], Loss: 0.0697\n",
      "Epoch [50/50], Step [522/735], Loss: 0.1050\n",
      "Epoch [50/50], Step [523/735], Loss: 0.0762\n",
      "Epoch [50/50], Step [524/735], Loss: 0.1718\n",
      "Epoch [50/50], Step [525/735], Loss: 0.1094\n",
      "Epoch [50/50], Step [526/735], Loss: 0.1061\n",
      "Epoch [50/50], Step [527/735], Loss: 0.0702\n",
      "Epoch [50/50], Step [528/735], Loss: 0.1128\n",
      "Epoch [50/50], Step [529/735], Loss: 0.0455\n",
      "Epoch [50/50], Step [530/735], Loss: 0.0343\n",
      "Epoch [50/50], Step [531/735], Loss: 0.1262\n",
      "Epoch [50/50], Step [532/735], Loss: 0.0605\n",
      "Epoch [50/50], Step [533/735], Loss: 0.0792\n",
      "Epoch [50/50], Step [534/735], Loss: 0.1289\n",
      "Epoch [50/50], Step [535/735], Loss: 0.1483\n",
      "Epoch [50/50], Step [536/735], Loss: 0.0931\n",
      "Epoch [50/50], Step [537/735], Loss: 0.0665\n",
      "Epoch [50/50], Step [538/735], Loss: 0.0528\n",
      "Epoch [50/50], Step [539/735], Loss: 0.0805\n",
      "Epoch [50/50], Step [540/735], Loss: 0.0611\n",
      "Epoch [50/50], Step [541/735], Loss: 0.0817\n",
      "Epoch [50/50], Step [542/735], Loss: 0.0881\n",
      "Epoch [50/50], Step [543/735], Loss: 0.1964\n",
      "Epoch [50/50], Step [544/735], Loss: 0.1005\n",
      "Epoch [50/50], Step [545/735], Loss: 0.0642\n",
      "Epoch [50/50], Step [546/735], Loss: 0.0489\n",
      "Epoch [50/50], Step [547/735], Loss: 0.0364\n",
      "Epoch [50/50], Step [548/735], Loss: 0.0629\n",
      "Epoch [50/50], Step [549/735], Loss: 0.0567\n",
      "Epoch [50/50], Step [550/735], Loss: 0.0507\n",
      "Epoch [50/50], Step [551/735], Loss: 0.0381\n",
      "Epoch [50/50], Step [552/735], Loss: 0.1220\n",
      "Epoch [50/50], Step [553/735], Loss: 0.0371\n",
      "Epoch [50/50], Step [554/735], Loss: 0.0280\n",
      "Epoch [50/50], Step [555/735], Loss: 0.0637\n",
      "Epoch [50/50], Step [556/735], Loss: 0.3489\n",
      "Epoch [50/50], Step [557/735], Loss: 0.1451\n",
      "Epoch [50/50], Step [558/735], Loss: 0.0507\n",
      "Epoch [50/50], Step [559/735], Loss: 0.0242\n",
      "Epoch [50/50], Step [560/735], Loss: 0.4970\n",
      "Epoch [50/50], Step [561/735], Loss: 0.1287\n",
      "Epoch [50/50], Step [562/735], Loss: 0.0830\n",
      "Epoch [50/50], Step [563/735], Loss: 0.0573\n",
      "Epoch [50/50], Step [564/735], Loss: 0.0806\n",
      "Epoch [50/50], Step [565/735], Loss: 0.0559\n",
      "Epoch [50/50], Step [566/735], Loss: 0.0982\n",
      "Epoch [50/50], Step [567/735], Loss: 0.0568\n",
      "Epoch [50/50], Step [568/735], Loss: 0.0637\n",
      "Epoch [50/50], Step [569/735], Loss: 0.0335\n",
      "Epoch [50/50], Step [570/735], Loss: 0.0427\n",
      "Epoch [50/50], Step [571/735], Loss: 0.0820\n",
      "Epoch [50/50], Step [572/735], Loss: 0.1134\n",
      "Epoch [50/50], Step [573/735], Loss: 0.0789\n",
      "Epoch [50/50], Step [574/735], Loss: 0.0603\n",
      "Epoch [50/50], Step [575/735], Loss: 0.3517\n",
      "Epoch [50/50], Step [576/735], Loss: 0.0861\n",
      "Epoch [50/50], Step [577/735], Loss: 0.1080\n",
      "Epoch [50/50], Step [578/735], Loss: 0.0740\n",
      "Epoch [50/50], Step [579/735], Loss: 0.0854\n",
      "Epoch [50/50], Step [580/735], Loss: 0.5015\n",
      "Epoch [50/50], Step [581/735], Loss: 0.0974\n",
      "Epoch [50/50], Step [582/735], Loss: 0.0549\n",
      "Epoch [50/50], Step [583/735], Loss: 0.0884\n",
      "Epoch [50/50], Step [584/735], Loss: 0.1285\n",
      "Epoch [50/50], Step [585/735], Loss: 0.0865\n",
      "Epoch [50/50], Step [586/735], Loss: 0.0770\n",
      "Epoch [50/50], Step [587/735], Loss: 0.0998\n",
      "Epoch [50/50], Step [588/735], Loss: 0.0415\n",
      "Epoch [50/50], Step [589/735], Loss: 0.1778\n",
      "Epoch [50/50], Step [590/735], Loss: 0.3418\n",
      "Epoch [50/50], Step [591/735], Loss: 0.3334\n",
      "Epoch [50/50], Step [592/735], Loss: 0.0508\n",
      "Epoch [50/50], Step [593/735], Loss: 0.0764\n",
      "Epoch [50/50], Step [594/735], Loss: 0.2114\n",
      "Epoch [50/50], Step [595/735], Loss: 0.2204\n",
      "Epoch [50/50], Step [596/735], Loss: 0.1399\n",
      "Epoch [50/50], Step [597/735], Loss: 0.0730\n",
      "Epoch [50/50], Step [598/735], Loss: 0.0590\n",
      "Epoch [50/50], Step [599/735], Loss: 0.0811\n",
      "Epoch [50/50], Step [600/735], Loss: 0.0818\n",
      "Epoch [50/50], Step [601/735], Loss: 0.0774\n",
      "Epoch [50/50], Step [602/735], Loss: 0.1582\n",
      "Epoch [50/50], Step [603/735], Loss: 0.2143\n",
      "Epoch [50/50], Step [604/735], Loss: 0.1378\n",
      "Epoch [50/50], Step [605/735], Loss: 0.1092\n",
      "Epoch [50/50], Step [606/735], Loss: 0.1187\n",
      "Epoch [50/50], Step [607/735], Loss: 0.4593\n",
      "Epoch [50/50], Step [608/735], Loss: 0.1975\n",
      "Epoch [50/50], Step [609/735], Loss: 0.0714\n",
      "Epoch [50/50], Step [610/735], Loss: 0.0924\n",
      "Epoch [50/50], Step [611/735], Loss: 0.0664\n",
      "Epoch [50/50], Step [612/735], Loss: 0.1093\n",
      "Epoch [50/50], Step [613/735], Loss: 0.0466\n",
      "Epoch [50/50], Step [614/735], Loss: 0.0965\n",
      "Epoch [50/50], Step [615/735], Loss: 0.1186\n",
      "Epoch [50/50], Step [616/735], Loss: 0.0669\n",
      "Epoch [50/50], Step [617/735], Loss: 0.0862\n",
      "Epoch [50/50], Step [618/735], Loss: 0.1181\n",
      "Epoch [50/50], Step [619/735], Loss: 1.2670\n",
      "Epoch [50/50], Step [620/735], Loss: 0.0379\n",
      "Epoch [50/50], Step [621/735], Loss: 0.0726\n",
      "Epoch [50/50], Step [622/735], Loss: 0.1248\n",
      "Epoch [50/50], Step [623/735], Loss: 0.0777\n",
      "Epoch [50/50], Step [624/735], Loss: 0.0315\n",
      "Epoch [50/50], Step [625/735], Loss: 0.1177\n",
      "Epoch [50/50], Step [626/735], Loss: 0.0538\n",
      "Epoch [50/50], Step [627/735], Loss: 0.0893\n",
      "Epoch [50/50], Step [628/735], Loss: 0.0959\n",
      "Epoch [50/50], Step [629/735], Loss: 0.0635\n",
      "Epoch [50/50], Step [630/735], Loss: 0.0232\n",
      "Epoch [50/50], Step [631/735], Loss: 0.0791\n",
      "Epoch [50/50], Step [632/735], Loss: 0.0872\n",
      "Epoch [50/50], Step [633/735], Loss: 0.1156\n",
      "Epoch [50/50], Step [634/735], Loss: 0.0426\n",
      "Epoch [50/50], Step [635/735], Loss: 0.0910\n",
      "Epoch [50/50], Step [636/735], Loss: 0.0436\n",
      "Epoch [50/50], Step [637/735], Loss: 0.5029\n",
      "Epoch [50/50], Step [638/735], Loss: 0.2091\n",
      "Epoch [50/50], Step [639/735], Loss: 0.0719\n",
      "Epoch [50/50], Step [640/735], Loss: 0.0690\n",
      "Epoch [50/50], Step [641/735], Loss: 0.0601\n",
      "Epoch [50/50], Step [642/735], Loss: 0.2830\n",
      "Epoch [50/50], Step [643/735], Loss: 0.1408\n",
      "Epoch [50/50], Step [644/735], Loss: 0.1317\n",
      "Epoch [50/50], Step [645/735], Loss: 0.0599\n",
      "Epoch [50/50], Step [646/735], Loss: 0.0800\n",
      "Epoch [50/50], Step [647/735], Loss: 0.0534\n",
      "Epoch [50/50], Step [648/735], Loss: 0.2133\n",
      "Epoch [50/50], Step [649/735], Loss: 0.0647\n",
      "Epoch [50/50], Step [650/735], Loss: 0.0556\n",
      "Epoch [50/50], Step [651/735], Loss: 0.1018\n",
      "Epoch [50/50], Step [652/735], Loss: 0.0884\n",
      "Epoch [50/50], Step [653/735], Loss: 0.1499\n",
      "Epoch [50/50], Step [654/735], Loss: 0.1167\n",
      "Epoch [50/50], Step [655/735], Loss: 0.0681\n",
      "Epoch [50/50], Step [656/735], Loss: 0.2355\n",
      "Epoch [50/50], Step [657/735], Loss: 0.0578\n",
      "Epoch [50/50], Step [658/735], Loss: 0.1785\n",
      "Epoch [50/50], Step [659/735], Loss: 0.2178\n",
      "Epoch [50/50], Step [660/735], Loss: 0.0408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Step [661/735], Loss: 0.2137\n",
      "Epoch [50/50], Step [662/735], Loss: 0.1435\n",
      "Epoch [50/50], Step [663/735], Loss: 0.1615\n",
      "Epoch [50/50], Step [664/735], Loss: 0.2220\n",
      "Epoch [50/50], Step [665/735], Loss: 0.0741\n",
      "Epoch [50/50], Step [666/735], Loss: 0.0738\n",
      "Epoch [50/50], Step [667/735], Loss: 0.1002\n",
      "Epoch [50/50], Step [668/735], Loss: 0.0495\n",
      "Epoch [50/50], Step [669/735], Loss: 0.0848\n",
      "Epoch [50/50], Step [670/735], Loss: 0.0488\n",
      "Epoch [50/50], Step [671/735], Loss: 0.0791\n",
      "Epoch [50/50], Step [672/735], Loss: 0.2585\n",
      "Epoch [50/50], Step [673/735], Loss: 0.1083\n",
      "Epoch [50/50], Step [674/735], Loss: 0.0365\n",
      "Epoch [50/50], Step [675/735], Loss: 0.1395\n",
      "Epoch [50/50], Step [676/735], Loss: 0.0531\n",
      "Epoch [50/50], Step [677/735], Loss: 0.0482\n",
      "Epoch [50/50], Step [678/735], Loss: 0.0825\n",
      "Epoch [50/50], Step [679/735], Loss: 0.0937\n",
      "Epoch [50/50], Step [680/735], Loss: 0.0737\n",
      "Epoch [50/50], Step [681/735], Loss: 0.0867\n",
      "Epoch [50/50], Step [682/735], Loss: 0.0509\n",
      "Epoch [50/50], Step [683/735], Loss: 0.1957\n",
      "Epoch [50/50], Step [684/735], Loss: 0.3890\n",
      "Epoch [50/50], Step [685/735], Loss: 0.0639\n",
      "Epoch [50/50], Step [686/735], Loss: 0.0926\n",
      "Epoch [50/50], Step [687/735], Loss: 0.0668\n",
      "Epoch [50/50], Step [688/735], Loss: 0.3485\n",
      "Epoch [50/50], Step [689/735], Loss: 0.0981\n",
      "Epoch [50/50], Step [690/735], Loss: 0.0799\n",
      "Epoch [50/50], Step [691/735], Loss: 0.1018\n",
      "Epoch [50/50], Step [692/735], Loss: 0.0814\n",
      "Epoch [50/50], Step [693/735], Loss: 0.0537\n",
      "Epoch [50/50], Step [694/735], Loss: 0.2949\n",
      "Epoch [50/50], Step [695/735], Loss: 0.8549\n",
      "Epoch [50/50], Step [696/735], Loss: 0.0508\n",
      "Epoch [50/50], Step [697/735], Loss: 0.0857\n",
      "Epoch [50/50], Step [698/735], Loss: 0.1265\n",
      "Epoch [50/50], Step [699/735], Loss: 0.1405\n",
      "Epoch [50/50], Step [700/735], Loss: 0.1208\n",
      "Epoch [50/50], Step [701/735], Loss: 0.0655\n",
      "Epoch [50/50], Step [702/735], Loss: 0.0609\n",
      "Epoch [50/50], Step [703/735], Loss: 0.0427\n",
      "Epoch [50/50], Step [704/735], Loss: 0.0309\n",
      "Epoch [50/50], Step [705/735], Loss: 0.1154\n",
      "Epoch [50/50], Step [706/735], Loss: 0.0810\n",
      "Epoch [50/50], Step [707/735], Loss: 0.1761\n",
      "Epoch [50/50], Step [708/735], Loss: 0.0327\n",
      "Epoch [50/50], Step [709/735], Loss: 0.1233\n",
      "Epoch [50/50], Step [710/735], Loss: 0.1368\n",
      "Epoch [50/50], Step [711/735], Loss: 0.0824\n",
      "Epoch [50/50], Step [712/735], Loss: 0.1007\n",
      "Epoch [50/50], Step [713/735], Loss: 0.1454\n",
      "Epoch [50/50], Step [714/735], Loss: 0.1052\n",
      "Epoch [50/50], Step [715/735], Loss: 0.0707\n",
      "Epoch [50/50], Step [716/735], Loss: 0.1027\n",
      "Epoch [50/50], Step [717/735], Loss: 0.0828\n",
      "Epoch [50/50], Step [718/735], Loss: 0.1465\n",
      "Epoch [50/50], Step [719/735], Loss: 0.0765\n",
      "Epoch [50/50], Step [720/735], Loss: 0.1266\n",
      "Epoch [50/50], Step [721/735], Loss: 0.1367\n",
      "Epoch [50/50], Step [722/735], Loss: 0.3531\n",
      "Epoch [50/50], Step [723/735], Loss: 0.0995\n",
      "Epoch [50/50], Step [724/735], Loss: 0.0596\n",
      "Epoch [50/50], Step [725/735], Loss: 0.1097\n",
      "Epoch [50/50], Step [726/735], Loss: 0.0383\n",
      "Epoch [50/50], Step [727/735], Loss: 0.1506\n",
      "Epoch [50/50], Step [728/735], Loss: 0.4807\n",
      "Epoch [50/50], Step [729/735], Loss: 0.0868\n",
      "Epoch [50/50], Step [730/735], Loss: 0.0382\n",
      "Epoch [50/50], Step [731/735], Loss: 0.0888\n",
      "Epoch [50/50], Step [732/735], Loss: 0.0302\n",
      "Epoch [50/50], Step [733/735], Loss: 0.0612\n",
      "Epoch [50/50], Step [734/735], Loss: 0.0745\n",
      "Epoch [50/50], Step [735/735], Loss: 0.0978\n"
     ]
    }
   ],
   "source": [
    "# Set device (CPU or GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Model parameters\n",
    "input_dim = N\n",
    "hidden_dim = 128\n",
    "output_dim = N\n",
    "num_layers = 1\n",
    "num_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Initialize the model, loss function and optimizer\n",
    "model = LSTMModel(input_dim, hidden_dim, output_dim, num_layers).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "epoch_loss = []\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "        #if (i+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf052e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.figure(1, figsize = [20,10])\n",
    "plt.semilogy(epoch_loss)\n",
    "plt.ylabel('Loss(log scale)')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6c66ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriniva3\\AppData\\Local\\Temp\\ipykernel_6440\\1681708791.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_inputs = torch.tensor(inp_test_data, dtype=torch.float32).to(device)\n",
      "C:\\Users\\sriniva3\\AppData\\Local\\Temp\\ipykernel_6440\\1681708791.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_targets = torch.tensor(out_test_data, dtype=torch.float32).to(device)\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    test_inputs = torch.tensor(inp_test_data, dtype=torch.float32).to(device)\n",
    "    test_targets = torch.tensor(out_test_data, dtype=torch.float32).to(device)\n",
    "    test_outputs = model(test_inputs)\n",
    "    test_loss = criterion(test_outputs, test_targets)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce79837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, 'LSTM.pth')\n",
    "#torch.save(model.state_dict(), 'LSTM_state_dict.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "199e3c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## CDF plots ###########\n",
    "pred = test_outputs.detach().numpy()\n",
    "tgt = test_targets.detach().numpy()\n",
    "error = tgt - pred\n",
    "#pred = pred.flatten()\n",
    "#tgt = tgt.flatten()\n",
    "sortd_pred, a_pred = return_cdf(pred[:,0])\n",
    "sortd_tgt, a_tgt = return_cdf(tgt[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "044e0a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(sortd_pred, a_pred)\n",
    "#plt.plot(sortd_tgt, a_tgt, alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4bf13b9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pred[:,0], alpha = 1, label = 'predicted')\n",
    "plt.plot(tgt[:,0], label = 'target', alpha = 0.8)\n",
    "plt.legend()\n",
    "plt.ylabel('SINR(dB)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd1b93a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bcb3af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4f334e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1cdc4fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error = pred[:,0].flatten() - tgt[:,0].flatten()\n",
    "sortd_error, a_error = return_cdf(error.flatten())\n",
    "plt.plot(sortd_error, a_error)\n",
    "plt.title('CDF of error between predicted and ground truth SINR')\n",
    "plt.xlabel('SINRS(dB)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d2a5d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1996, 2004, 2005, 2006, 2017], dtype=int64),)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(error >=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68f6da9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13.34621"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[1996,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b089c9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-17.573128"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt[1996,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249d895c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8dd6cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
